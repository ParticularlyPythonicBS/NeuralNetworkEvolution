{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "import optax\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.style as mplstyle\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "sns.set_theme(context='paper', style='white', palette='icefire', font='serif',\n",
    "            font_scale=2, color_codes=True, rc={'text.usetex' : True})\n",
    "mplstyle.use('fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron(eqx.Module):\n",
    "    weight: jax.Array\n",
    "    bias: jax.Array\n",
    "    activation: callable\n",
    "\n",
    "    def __init__(self, in_features, activation=jax.nn.relu, key=None):\n",
    "        if key is None:\n",
    "            key = jax.random.PRNGKey(0)\n",
    "            key, _ = jax.random.split(key)\n",
    "        w_key, b_key = jax.random.split(key)\n",
    "        self.weight = jax.random.normal(w_key, (in_features,))\n",
    "        self.bias = jax.random.normal(b_key, ())\n",
    "\n",
    "        self.activation = activation\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.activation(jnp.dot(self.weight, x) + self.bias)\n",
    "    \n",
    "    def importance(self):\n",
    "        return jnp.linalg.norm(self.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity(x):\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMLP(eqx.Module):\n",
    "    layers: list\n",
    "\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, key=None):\n",
    "        if key is None:\n",
    "            key = jax.random.PRNGKey(0)\n",
    "        keys = jax.random.split(key, len(hidden_sizes) + 1)\n",
    "        act_key = jax.random.split(keys[-1], 1)[0]\n",
    "        activation_list = [jax.nn.relu, jax.nn.sigmoid, jax.nn.tanh]\n",
    "        layers = []\n",
    "        in_features = input_size\n",
    "\n",
    "        # Create hidden layers\n",
    "        for i, out_features in enumerate(hidden_sizes):\n",
    "            layer = [Neuron(in_features, activation_list[0], key=keys[i]) for _ in range(out_features)]\n",
    "            layers.append(layer)\n",
    "            in_features = out_features\n",
    "\n",
    "        # Create output layer\n",
    "        output_layer = [Neuron(in_features, activation=identity, key=keys[-1]) for _ in range(output_size)]\n",
    "        layers.append(output_layer)\n",
    "\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = jnp.array([neuron(x) for neuron in layer])\n",
    "        return x[0]  # Since output layer is a single neuron\n",
    "\n",
    "    def add_neuron(self, layer_index, activation=jax.nn.relu, key=None):\n",
    "        if key is None:\n",
    "            key = jax.random.PRNGKey(0)\n",
    "        in_features = self.layers[layer_index][0].weight.shape[0]\n",
    "        new_neuron = Neuron(in_features, activation, key)\n",
    "        self.layers[layer_index].append(new_neuron)\n",
    "\n",
    "        # Adjust the next layer's weight matrix to include the new neuron\n",
    "        if layer_index + 1 < len(self.layers):\n",
    "            for i, next_neuron in enumerate(self.layers[layer_index + 1]):\n",
    "                new_weight = jax.random.normal(key, (1,))\n",
    "                updated_weights = jnp.append(next_neuron.weight, new_weight)\n",
    "                self.layers[layer_index + 1][i] = eqx.tree_at(lambda n: n.weight, next_neuron, updated_weights)\n",
    "\n",
    "    def remove_neuron(self, layer_index, neuron_index):\n",
    "        if len(self.layers[layer_index]) > 0:\n",
    "            del self.layers[layer_index][neuron_index]\n",
    "        \n",
    "        # Adjust the next layer's weight matrix to remove the corresponding weight\n",
    "        if layer_index + 1 < len(self.layers):\n",
    "            for i, next_neuron in enumerate(self.layers[layer_index + 1]):\n",
    "                updated_weights = jnp.delete(next_neuron.weight, neuron_index)\n",
    "                self.layers[layer_index + 1][i] = eqx.tree_at(lambda n: n.weight, next_neuron, updated_weights)\n",
    "    \n",
    "    def get_shape(self):\n",
    "        return [len(layer) for layer in self.layers]\n",
    "\n",
    "    def least_important_neuron(self):\n",
    "        all_importances = []\n",
    "        layer_sizes = []\n",
    "        for layer in self.layers:\n",
    "            importances = [n.importance() for n in layer]\n",
    "            all_importances.append(jnp.array(importances).flatten())  # Flatten the importances\n",
    "            layer_sizes.append(len(layer))\n",
    "\n",
    "        all_importances = jnp.concatenate(all_importances)\n",
    "        sorted_indices = jnp.argsort(all_importances)\n",
    "\n",
    "        # Locate the layer and neuron index\n",
    "        cum_neurons = jnp.cumsum(jnp.array(layer_sizes))\n",
    "        for min_importance_index in sorted_indices:\n",
    "            layer_index = jnp.searchsorted(cum_neurons, min_importance_index, side=\"right\")\n",
    "            neuron_index = min_importance_index - (cum_neurons[layer_index - 1] if layer_index > 0 else 0)\n",
    "            if neuron_index != len(self.layers[layer_index]) - 1:  # If the neuron is not the last one of its layer\n",
    "                return layer_index, neuron_index\n",
    "        \n",
    "        raise ValueError(\"All neurons are the last ones of their layers\")\n",
    "\n",
    "    def most_important_layer(self):\n",
    "        # Calculate the total importance of each layer\n",
    "        layer_importances = [jnp.sum(jnp.array([n.importance() for n in layer])) for layer in self.layers[:-1]]\n",
    "        most_important_layer_index = jnp.argmax(jnp.array(layer_importances))  # Convert to Jax array\n",
    "\n",
    "        return most_important_layer_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_optimizer_state(mlp, optimizer):\n",
    "    return optimizer.init(eqx.filter(mlp, eqx.is_inexact_array))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 19:24:07.533744: W external/xla/xla/service/gpu/nvptx_compiler.cc:760] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.4.131). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_size = 3\n",
    "hidden_sizes = [2, 3]  # Two hidden layers with 4 and 5 neurons respectively\n",
    "output_size = 1\n",
    "key = jax.random.PRNGKey(42)\n",
    "mlp = CustomMLP(input_size, hidden_sizes, output_size, key)\n",
    "opt = optax.sgd(learning_rate=1e-2)\n",
    "opt_state = initialize_optimizer_state(mlp, opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 1]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.array([1.0, 2.0, 3.0])\n",
    "y = jnp.array([1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_value_and_grad()\n",
    "def compute_loss(mlp, x, y):\n",
    "    pred = mlp(x)\n",
    "    return jnp.mean((pred - y) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit()\n",
    "def train_step(mlp, x, y, opt_state, opt_update):\n",
    "    loss, grads = compute_loss(mlp, x, y)\n",
    "    updates, opt_state = opt_update(grads, opt_state)\n",
    "    mlp = eqx.apply_updates(mlp, updates)\n",
    "    return loss, mlp, opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = CustomMLP(input_size, hidden_sizes, output_size, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(2, dtype=int32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_list = [jax.nn.relu, jax.nn.sigmoid, jax.nn.tanh]\n",
    "jax.random.choice(key, jnp.arange(len(activation_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_list = [jax.nn.relu, jax.nn.sigmoid, jax.nn.tanh]\n",
    "num_epochs = 1000\n",
    "add_node_every = 10\n",
    "remove_node_every = 10\n",
    "Loss_history = []\n",
    "Node_history = []\n",
    "Update_history = []\n",
    "threshold = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mlp.layers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Prediction: -0.10243986546993256, Loss: 1.2654868364334106\n",
      "Epoch 1, Prediction: -0.080391064286232, Loss: 1.2153736352920532\n",
      "Epoch 2, Prediction: -0.05878324434161186, Loss: 1.167244791984558\n",
      "Epoch 3, Prediction: -0.0376075804233551, Loss: 1.12102210521698\n",
      "Epoch 4, Prediction: -0.016855429857969284, Loss: 1.076629400253296\n",
      "Epoch 5, Prediction: 0.0034816786646842957, Loss: 1.0339950323104858\n",
      "Epoch 6, Prediction: 0.02341204509139061, Loss: 0.9930487275123596\n",
      "Epoch 7, Prediction: 0.0429438054561615, Loss: 0.9537240266799927\n",
      "Epoch 8, Prediction: 0.062084928154945374, Loss: 0.9159564971923828\n",
      "Epoch 9, Prediction: 0.08084322512149811, Loss: 0.8796846866607666\n",
      "Added neuron to hidden layer 2 with activation sigmoid\n",
      "[2, 4, 1]\n",
      "Epoch 10, Prediction: -0.49277108907699585, Loss: 2.356466054916382\n",
      "Epoch 11, Prediction: -0.451762318611145, Loss: 2.228365659713745\n",
      "Epoch 12, Prediction: -0.4120034873485565, Loss: 2.1076138019561768\n",
      "Epoch 13, Prediction: -0.37344861030578613, Loss: 1.9937539100646973\n",
      "Epoch 14, Prediction: -0.33605366945266724, Loss: 1.8863611221313477\n",
      "Epoch 15, Prediction: -0.2997767925262451, Loss: 1.7850393056869507\n",
      "Epoch 16, Prediction: -0.26457807421684265, Loss: 1.6894197463989258\n",
      "Epoch 17, Prediction: -0.23041948676109314, Loss: 1.5991578102111816\n",
      "Epoch 18, Prediction: -0.19726461172103882, Loss: 1.513932228088379\n",
      "Epoch 19, Prediction: -0.16507890820503235, Loss: 1.4334427118301392\n",
      "Removing neuron from hidden layer 1 at index 0\n",
      "Rejecting last addition,\n",
      " Removed neuron from hidden layer 1 at index 0\n",
      "[1, 4, 1]\n",
      "Epoch 20, Prediction: -0.1338290572166443, Loss: 1.3574087619781494\n",
      "Epoch 21, Prediction: -0.10348337888717651, Loss: 1.2855684757232666\n",
      "Epoch 22, Prediction: -0.07401150465011597, Loss: 1.2176756858825684\n",
      "Epoch 23, Prediction: -0.04538440704345703, Loss: 1.1535007953643799\n",
      "Epoch 24, Prediction: -0.01757410168647766, Loss: 1.0928285121917725\n",
      "Epoch 25, Prediction: 0.009445875883102417, Loss: 1.0354570150375366\n",
      "Epoch 26, Prediction: 0.03570142388343811, Loss: 0.9811974167823792\n",
      "Epoch 27, Prediction: 0.06121686100959778, Loss: 0.9298717975616455\n",
      "Epoch 28, Prediction: 0.08601588010787964, Loss: 0.8813138604164124\n",
      "Epoch 29, Prediction: 0.11012127995491028, Loss: 0.83536696434021\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "[1, 5, 1]\n",
      "Epoch 30, Prediction: 0.258575975894928, Loss: 0.5851967334747314\n",
      "Epoch 31, Prediction: 0.2814614772796631, Loss: 0.5497095584869385\n",
      "Epoch 32, Prediction: 0.3036919832229614, Loss: 0.5162976384162903\n",
      "Epoch 33, Prediction: 0.32528430223464966, Loss: 0.4848448634147644\n",
      "Epoch 34, Prediction: 0.34625494480133057, Loss: 0.45524126291275024\n",
      "Epoch 35, Prediction: 0.36661970615386963, Loss: 0.42738258838653564\n",
      "Epoch 36, Prediction: 0.386394202709198, Loss: 0.40117061138153076\n",
      "Epoch 37, Prediction: 0.4055936932563782, Loss: 0.3765120804309845\n",
      "Epoch 38, Prediction: 0.4242328405380249, Loss: 0.35331887006759644\n",
      "Epoch 39, Prediction: 0.44232624769210815, Loss: 0.3315078318119049\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "[1, 6, 1]\n",
      "Epoch 40, Prediction: 0.320559024810791, Loss: 0.49807268381118774\n",
      "Epoch 41, Prediction: 0.34587591886520386, Loss: 0.46164003014564514\n",
      "Epoch 42, Prediction: 0.37024736404418945, Loss: 0.42787832021713257\n",
      "Epoch 43, Prediction: 0.3937106132507324, Loss: 0.39658838510513306\n",
      "Epoch 44, Prediction: 0.4163011312484741, Loss: 0.36758682131767273\n",
      "Epoch 45, Prediction: 0.4380527436733246, Loss: 0.34070438146591187\n",
      "Epoch 46, Prediction: 0.4589977264404297, Loss: 0.3157846927642822\n",
      "Epoch 47, Prediction: 0.47916683554649353, Loss: 0.2926834523677826\n",
      "Epoch 48, Prediction: 0.49858957529067993, Loss: 0.2712671458721161\n",
      "Epoch 49, Prediction: 0.5172938108444214, Loss: 0.25141242146492004\n",
      "Added neuron to hidden layer 2 with activation sigmoid\n",
      "[1, 7, 1]\n",
      "Epoch 50, Prediction: 1.390690565109253, Loss: 0.16847456991672516\n",
      "Epoch 51, Prediction: 1.3718903064727783, Loss: 0.15263912081718445\n",
      "Epoch 52, Prediction: 1.3540072441101074, Loss: 0.13830240070819855\n",
      "Epoch 53, Prediction: 1.3369947671890259, Loss: 0.1253211349248886\n",
      "Epoch 54, Prediction: 1.3208096027374268, Loss: 0.11356547474861145\n",
      "Epoch 55, Prediction: 1.3054099082946777, Loss: 0.10291880369186401\n",
      "Epoch 56, Prediction: 1.2907569408416748, Loss: 0.09327521175146103\n",
      "Epoch 57, Prediction: 1.2768135070800781, Loss: 0.08453959971666336\n",
      "Epoch 58, Prediction: 1.2635442018508911, Loss: 0.07662571966648102\n",
      "Epoch 59, Prediction: 1.2509162425994873, Loss: 0.06945554912090302\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "[1, 8, 1]\n",
      "Epoch 60, Prediction: 2.102130651473999, Loss: 1.388906478881836\n",
      "Epoch 61, Prediction: 2.0308303833007812, Loss: 1.2146919965744019\n",
      "Epoch 62, Prediction: 1.964253544807434, Loss: 1.0626112222671509\n",
      "Epoch 63, Prediction: 1.9020659923553467, Loss: 0.929784893989563\n",
      "Epoch 64, Prediction: 1.8439607620239258, Loss: 0.8137230277061462\n",
      "Epoch 65, Prediction: 1.7896568775177002, Loss: 0.7122697830200195\n",
      "Epoch 66, Prediction: 1.7388935089111328, Loss: 0.623557984828949\n",
      "Epoch 67, Prediction: 1.6914312839508057, Loss: 0.5459636449813843\n",
      "Epoch 68, Prediction: 1.647047996520996, Loss: 0.478077232837677\n",
      "Epoch 69, Prediction: 1.6055378913879395, Loss: 0.4186711013317108\n",
      "Removing neuron from hidden layer 2 at index 4\n",
      "Rejecting last addition,\n",
      " Removed neuron from hidden layer 2 at index 4\n",
      "[1, 7, 1]\n",
      "Epoch 70, Prediction: 1.4506505727767944, Loss: 0.22967445850372314\n",
      "Epoch 71, Prediction: 1.4237440824508667, Loss: 0.20308594405651093\n",
      "Epoch 72, Prediction: 1.3984262943267822, Loss: 0.17955905199050903\n",
      "Epoch 73, Prediction: 1.374605417251587, Loss: 0.15874351561069489\n",
      "Epoch 74, Prediction: 1.35219407081604, Loss: 0.14032921195030212\n",
      "Epoch 75, Prediction: 1.3311107158660889, Loss: 0.12404066324234009\n",
      "Epoch 76, Prediction: 1.3112783432006836, Loss: 0.10963430255651474\n",
      "Epoch 77, Prediction: 1.2926230430603027, Loss: 0.09689420461654663\n",
      "Epoch 78, Prediction: 1.2750768661499023, Loss: 0.08562824875116348\n",
      "Epoch 79, Prediction: 1.2585744857788086, Loss: 0.07566728442907333\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "[1, 8, 1]\n",
      "Epoch 80, Prediction: 1.2095357179641724, Loss: 0.05077070742845535\n",
      "Epoch 81, Prediction: 1.1948480606079102, Loss: 0.043905217200517654\n",
      "Epoch 82, Prediction: 1.1811854839324951, Loss: 0.037965767085552216\n",
      "Epoch 83, Prediction: 1.1684763431549072, Loss: 0.03282817825675011\n",
      "Epoch 84, Prediction: 1.1566555500030518, Loss: 0.02838427759706974\n",
      "Epoch 85, Prediction: 1.1456602811813354, Loss: 0.024540960788726807\n",
      "Epoch 86, Prediction: 1.1354341506958008, Loss: 0.021216917783021927\n",
      "Epoch 87, Prediction: 1.1259233951568604, Loss: 0.018342409282922745\n",
      "Epoch 88, Prediction: 1.1170786619186401, Loss: 0.015856701880693436\n",
      "Epoch 89, Prediction: 1.1088528633117676, Loss: 0.013707413338124752\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "[1, 9, 1]\n",
      "Epoch 90, Prediction: 0.13592475652694702, Loss: 1.0126491785049438\n",
      "Epoch 91, Prediction: 0.2564938962459564, Loss: 0.7466260194778442\n",
      "Epoch 92, Prediction: 0.3591577410697937, Loss: 0.5528013110160828\n",
      "Epoch 93, Prediction: 0.4468867778778076, Loss: 0.41067880392074585\n",
      "Epoch 94, Prediction: 0.5220688581466675, Loss: 0.30593425035476685\n",
      "Epoch 95, Prediction: 0.5866488218307495, Loss: 0.22841817140579224\n",
      "Epoch 96, Prediction: 0.642227053642273, Loss: 0.1708592027425766\n",
      "Epoch 97, Prediction: 0.6901333332061768, Loss: 0.12800148129463196\n",
      "Epoch 98, Prediction: 0.7314802408218384, Loss: 0.09601735323667526\n",
      "Epoch 99, Prediction: 0.7672046422958374, Loss: 0.0721028596162796\n",
      "Removing neuron from hidden layer 2 at index 7\n",
      "Rejecting last addition,\n",
      " Removed neuron from hidden layer 2 at index 7\n",
      "[1, 8, 1]\n",
      "Epoch 100, Prediction: 0.789951741695404, Loss: 0.057322677224874496\n",
      "Epoch 101, Prediction: 0.8156601190567017, Loss: 0.044120270758867264\n",
      "Epoch 102, Prediction: 0.8381757140159607, Loss: 0.033981192857027054\n",
      "Epoch 103, Prediction: 0.8579061627388, Loss: 0.026187099516391754\n",
      "Epoch 104, Prediction: 0.8752045035362244, Loss: 0.020190658047795296\n",
      "Epoch 105, Prediction: 0.890376627445221, Loss: 0.015573916025459766\n",
      "Epoch 106, Prediction: 0.903688907623291, Loss: 0.012017283588647842\n",
      "Epoch 107, Prediction: 0.9153725504875183, Loss: 0.009275826625525951\n",
      "Epoch 108, Prediction: 0.9256298542022705, Loss: 0.007161805406212807\n",
      "Epoch 109, Prediction: 0.9346370697021484, Loss: 0.00553091848269105\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "[1, 9, 1]\n",
      "Epoch 110, Prediction: 0.6950219869613647, Loss: 0.12285275012254715\n",
      "Epoch 111, Prediction: 0.7344999313354492, Loss: 0.09301158785820007\n",
      "Epoch 112, Prediction: 0.7687681317329407, Loss: 0.0704902857542038\n",
      "Epoch 113, Prediction: 0.7985401153564453, Loss: 0.05346817523241043\n",
      "Epoch 114, Prediction: 0.8244244456291199, Loss: 0.04058608412742615\n",
      "Epoch 115, Prediction: 0.8469418287277222, Loss: 0.03082677535712719\n",
      "Epoch 116, Prediction: 0.8665412664413452, Loss: 0.023426804691553116\n",
      "Epoch 117, Prediction: 0.8836080431938171, Loss: 0.017811233177781105\n",
      "Epoch 118, Prediction: 0.8984752297401428, Loss: 0.013547088019549847\n",
      "Epoch 119, Prediction: 0.9114304780960083, Loss: 0.010307279415428638\n",
      "Removing neuron from hidden layer 2 at index 7\n",
      "Rejecting last addition,\n",
      " Removed neuron from hidden layer 2 at index 7\n",
      "[1, 8, 1]\n",
      "Epoch 120, Prediction: 1.4054124355316162, Loss: 0.18918035924434662\n",
      "Epoch 121, Prediction: 1.377834677696228, Loss: 0.16435924172401428\n",
      "Epoch 122, Prediction: 1.3520915508270264, Loss: 0.1427590399980545\n",
      "Epoch 123, Prediction: 1.3280662298202515, Loss: 0.1239684596657753\n",
      "Epoch 124, Prediction: 1.3056484460830688, Loss: 0.10762745141983032\n",
      "Epoch 125, Prediction: 1.2847349643707275, Loss: 0.09342097491025925\n",
      "Epoch 126, Prediction: 1.2652287483215332, Loss: 0.08107399940490723\n",
      "Epoch 127, Prediction: 1.247037410736084, Loss: 0.07034628838300705\n",
      "Epoch 128, Prediction: 1.2300755977630615, Loss: 0.06102748215198517\n",
      "Epoch 129, Prediction: 1.2142622470855713, Loss: 0.05293478071689606\n",
      "Added neuron to hidden layer 2 with activation sigmoid\n",
      "[1, 9, 1]\n",
      "Epoch 130, Prediction: 1.4540539979934692, Loss: 0.24513736367225647\n",
      "Epoch 131, Prediction: 1.4163382053375244, Loss: 0.20616503059864044\n",
      "Epoch 132, Prediction: 1.3817024230957031, Loss: 0.17333750426769257\n",
      "Epoch 133, Prediction: 1.34990394115448, Loss: 0.1456967443227768\n",
      "Epoch 134, Prediction: 1.3207168579101562, Loss: 0.12243276834487915\n",
      "Epoch 135, Prediction: 1.2939327955245972, Loss: 0.10285930335521698\n",
      "Epoch 136, Prediction: 1.2693588733673096, Loss: 0.0863964855670929\n",
      "Epoch 137, Prediction: 1.2468163967132568, Loss: 0.07255420088768005\n",
      "Epoch 138, Prediction: 1.2261415719985962, Loss: 0.06091833487153053\n",
      "Epoch 139, Prediction: 1.2071828842163086, Loss: 0.051140010356903076\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "[1, 10, 1]\n",
      "Epoch 140, Prediction: 0.5370463132858276, Loss: 0.26601871848106384\n",
      "Epoch 141, Prediction: 0.5843841433525085, Loss: 0.21432611346244812\n",
      "Epoch 142, Prediction: 0.6268250942230225, Loss: 0.1727365404367447\n",
      "Epoch 143, Prediction: 0.6648873686790466, Loss: 0.13925951719284058\n",
      "Epoch 144, Prediction: 0.6990311741828918, Loss: 0.11230047792196274\n",
      "Epoch 145, Prediction: 0.7296674251556396, Loss: 0.0905822366476059\n",
      "Epoch 146, Prediction: 0.7571617960929871, Loss: 0.07307969778776169\n",
      "Epoch 147, Prediction: 0.7818413376808167, Loss: 0.05897039175033569\n",
      "Epoch 148, Prediction: 0.8039978742599487, Loss: 0.04759320244193077\n",
      "Epoch 149, Prediction: 0.8238919973373413, Loss: 0.03841683268547058\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "[1, 11, 1]\n",
      "Epoch 150, Prediction: 0.8417574167251587, Loss: 0.031014028936624527\n",
      "Epoch 151, Prediction: 0.8578023314476013, Loss: 0.02504071593284607\n",
      "Epoch 152, Prediction: 0.8722144365310669, Loss: 0.020220177248120308\n",
      "Epoch 153, Prediction: 0.8851606249809265, Loss: 0.016329150646924973\n",
      "Epoch 154, Prediction: 0.8967913389205933, Loss: 0.013188081793487072\n",
      "Epoch 155, Prediction: 0.9072405099868774, Loss: 0.010652028024196625\n",
      "Epoch 156, Prediction: 0.916629433631897, Loss: 0.00860432256013155\n",
      "Epoch 157, Prediction: 0.9250658750534058, Loss: 0.006950651295483112\n",
      "Epoch 158, Prediction: 0.9326466917991638, Loss: 0.0056151230819523335\n",
      "Epoch 159, Prediction: 0.9394593238830566, Loss: 0.00453646807000041\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "[1, 12, 1]\n",
      "Epoch 160, Prediction: 1.707277774810791, Loss: 0.9038922190666199\n",
      "Epoch 161, Prediction: 1.5269367694854736, Loss: 0.5002418756484985\n",
      "Epoch 162, Prediction: 1.3929333686828613, Loss: 0.27766236662864685\n",
      "Epoch 163, Prediction: 1.2931742668151855, Loss: 0.1543966382741928\n",
      "Epoch 164, Prediction: 1.218822717666626, Loss: 0.08595114946365356\n",
      "Epoch 165, Prediction: 1.163366675376892, Loss: 0.04788338020443916\n",
      "Epoch 166, Prediction: 1.1219849586486816, Loss: 0.026688670739531517\n",
      "Epoch 167, Prediction: 1.0910953283309937, Loss: 0.014880330301821232\n",
      "Epoch 168, Prediction: 1.06803297996521, Loss: 0.008298358879983425\n",
      "Epoch 169, Prediction: 1.0508123636245728, Loss: 0.004628486465662718\n",
      "Removing neuron from hidden layer 2 at index 10\n",
      "Rejecting last addition,\n",
      " Removed neuron from hidden layer 2 at index 10\n",
      "[1, 11, 1]\n",
      "Epoch 170, Prediction: 1.037951946258545, Loss: 0.002581896260380745\n",
      "Epoch 171, Prediction: 1.0283472537994385, Loss: 0.0014403501991182566\n",
      "Epoch 172, Prediction: 1.0211738348007202, Loss: 0.0008035667706280947\n",
      "Epoch 173, Prediction: 1.0158157348632812, Loss: 0.0004483312659431249\n",
      "Epoch 174, Prediction: 1.0118136405944824, Loss: 0.00025013746926561\n",
      "Epoch 175, Prediction: 1.0088245868682861, Loss: 0.00013956210750620812\n",
      "Epoch 176, Prediction: 1.0065916776657104, Loss: 7.787333015585318e-05\n",
      "Epoch 177, Prediction: 1.0049238204956055, Loss: 4.34502144344151e-05\n",
      "Epoch 178, Prediction: 1.0036780834197998, Loss: 2.4244007363449782e-05\n",
      "Epoch 179, Prediction: 1.0027472972869873, Loss: 1.3528298040910158e-05\n",
      "Added neuron to hidden layer 2 with activation sigmoid\n",
      "[1, 12, 1]\n",
      "Epoch 180, Prediction: 1.5118446350097656, Loss: 0.48151424527168274\n",
      "Epoch 181, Prediction: 1.3776755332946777, Loss: 0.2619849443435669\n",
      "Epoch 182, Prediction: 1.2787182331085205, Loss: 0.14263880252838135\n",
      "Epoch 183, Prediction: 1.2057017087936401, Loss: 0.07768385112285614\n",
      "Epoch 184, Prediction: 1.15181565284729, Loss: 0.042313192039728165\n",
      "Epoch 185, Prediction: 1.112045407295227, Loss: 0.02304799295961857\n",
      "Epoch 186, Prediction: 1.0826923847198486, Loss: 0.012554173357784748\n",
      "Epoch 187, Prediction: 1.0610283613204956, Loss: 0.006838030647486448\n",
      "Epoch 188, Prediction: 1.045039415359497, Loss: 0.003724460955709219\n",
      "Epoch 189, Prediction: 1.0332390069961548, Loss: 0.0020285488571971655\n",
      "Removing neuron from hidden layer 2 at index 10\n",
      "Rejecting last addition,\n",
      " Removed neuron from hidden layer 2 at index 10\n",
      "[1, 11, 1]\n",
      "Epoch 190, Prediction: 0.9733842611312866, Loss: 0.000898918544407934\n",
      "Epoch 191, Prediction: 0.9763723015785217, Loss: 0.00070839753607288\n",
      "Epoch 192, Prediction: 0.9790246486663818, Loss: 0.0005582681042142212\n",
      "Epoch 193, Prediction: 0.9813792109489441, Loss: 0.0004399653698783368\n",
      "Epoch 194, Prediction: 0.9834693670272827, Loss: 0.0003467337810434401\n",
      "Epoch 195, Prediction: 0.985325038433075, Loss: 0.0002732618304435164\n",
      "Epoch 196, Prediction: 0.9869719743728638, Loss: 0.000215354491956532\n",
      "Epoch 197, Prediction: 0.9884340763092041, Loss: 0.0001697294501354918\n",
      "Epoch 198, Prediction: 0.9897322654724121, Loss: 0.0001337705907644704\n",
      "Epoch 199, Prediction: 0.99088454246521, Loss: 0.00010542637028265744\n",
      "Added neuron to hidden layer 2 with activation sigmoid\n",
      "[1, 12, 1]\n",
      "Epoch 200, Prediction: 0.7047938108444214, Loss: 0.11241111904382706\n",
      "Epoch 201, Prediction: 0.7400484085083008, Loss: 0.08714669197797775\n",
      "Epoch 202, Prediction: 0.7710717916488647, Loss: 0.06757482886314392\n",
      "Epoch 203, Prediction: 0.7983764410018921, Loss: 0.0524081252515316\n",
      "Epoch 204, Prediction: 0.8224120140075684, Loss: 0.04065205901861191\n",
      "Epoch 205, Prediction: 0.8435723781585693, Loss: 0.0315374918282032\n",
      "Epoch 206, Prediction: 0.8622041344642639, Loss: 0.02446960099041462\n",
      "Epoch 207, Prediction: 0.8786107897758484, Loss: 0.01898770034313202\n",
      "Epoch 208, Prediction: 0.8930593132972717, Loss: 0.014735340140759945\n",
      "Epoch 209, Prediction: 0.9057848453521729, Loss: 0.011436310596764088\n",
      "Removing neuron from hidden layer 2 at index 10\n",
      "Rejecting last addition,\n",
      " Removed neuron from hidden layer 2 at index 10\n",
      "[1, 11, 1]\n",
      "Epoch 210, Prediction: 0.3032590448856354, Loss: 0.6121538877487183\n",
      "Epoch 211, Prediction: 0.37936776876449585, Loss: 0.4854480028152466\n",
      "Epoch 212, Prediction: 0.4470261335372925, Loss: 0.3851843774318695\n",
      "Epoch 213, Prediction: 0.5072015523910522, Loss: 0.3057800829410553\n",
      "Epoch 214, Prediction: 0.5607446432113647, Loss: 0.24285030364990234\n",
      "Epoch 215, Prediction: 0.6084040403366089, Loss: 0.19294527173042297\n",
      "Epoch 216, Prediction: 0.6508402824401855, Loss: 0.15334740281105042\n",
      "Epoch 217, Prediction: 0.6886366605758667, Loss: 0.12191250920295715\n",
      "Epoch 218, Prediction: 0.7223091721534729, Loss: 0.09694712609052658\n",
      "Epoch 219, Prediction: 0.7523147463798523, Loss: 0.07711219787597656\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "[1, 12, 1]\n",
      "Epoch 220, Prediction: -0.8241764307022095, Loss: 5.201132297515869\n",
      "Epoch 221, Prediction: -0.47249138355255127, Loss: 3.3276195526123047\n",
      "Epoch 222, Prediction: -0.19647932052612305, Loss: 2.1682307720184326\n",
      "Epoch 223, Prediction: 0.02301734685897827, Loss: 1.4315627813339233\n",
      "Epoch 224, Prediction: 0.199274480342865, Loss: 0.9544951319694519\n",
      "Epoch 225, Prediction: 0.34184730052948, Loss: 0.6411613821983337\n",
      "Epoch 226, Prediction: 0.4578200578689575, Loss: 0.4331649839878082\n",
      "Epoch 227, Prediction: 0.552565336227417, Loss: 0.2939590811729431\n",
      "Epoch 228, Prediction: 0.6302317380905151, Loss: 0.20019777119159698\n",
      "Epoch 229, Prediction: 0.6940699815750122, Loss: 0.13672856986522675\n",
      "Removing neuron from hidden layer 2 at index 10\n",
      "Rejecting last addition,\n",
      " Removed neuron from hidden layer 2 at index 10\n",
      "[1, 11, 1]\n",
      "Epoch 230, Prediction: 0.913336992263794, Loss: 0.01077492255717516\n",
      "Epoch 231, Prediction: 0.9276283383369446, Loss: 0.007510476745665073\n",
      "Epoch 232, Prediction: 0.9395505785942078, Loss: 0.005237657576799393\n",
      "Epoch 233, Prediction: 0.9494998455047607, Loss: 0.0036541325971484184\n",
      "Epoch 234, Prediction: 0.9578056931495667, Loss: 0.002550265518948436\n",
      "Epoch 235, Prediction: 0.9647412896156311, Loss: 0.0017803595401346684\n",
      "Epoch 236, Prediction: 0.9705337285995483, Loss: 0.0012431766372174025\n",
      "Epoch 237, Prediction: 0.9753726124763489, Loss: 0.0008682611514814198\n",
      "Epoch 238, Prediction: 0.9794154763221741, Loss: 0.0006065082270652056\n",
      "Epoch 239, Prediction: 0.9827936887741089, Loss: 0.0004237226094119251\n",
      "Added neuron to hidden layer 2 with activation sigmoid\n",
      "[1, 12, 1]\n",
      "Epoch 240, Prediction: 0.6752395033836365, Loss: 0.15530818700790405\n",
      "Epoch 241, Prediction: 0.7321237325668335, Loss: 0.10546938329935074\n",
      "Epoch 242, Prediction: 0.778877854347229, Loss: 0.07175769656896591\n",
      "Epoch 243, Prediction: 0.8173606395721436, Loss: 0.04889500513672829\n",
      "Epoch 244, Prediction: 0.8490713834762573, Loss: 0.03335713595151901\n",
      "Epoch 245, Prediction: 0.8752257823944092, Loss: 0.022779447957873344\n",
      "Epoch 246, Prediction: 0.8968135118484497, Loss: 0.015568605624139309\n",
      "Epoch 247, Prediction: 0.9146431088447571, Loss: 0.010647451505064964\n",
      "Epoch 248, Prediction: 0.9293764233589172, Loss: 0.007285798899829388\n",
      "Epoch 249, Prediction: 0.9415558576583862, Loss: 0.004987689666450024\n",
      "Removing neuron from hidden layer 2 at index 5\n",
      "Rejecting last addition,\n",
      " Removed neuron from hidden layer 2 at index 5\n",
      "[1, 11, 1]\n",
      "Epoch 250, Prediction: 0.17240601778030396, Loss: 0.9726257920265198\n",
      "Epoch 251, Prediction: 0.30406075716018677, Loss: 0.6849117875099182\n",
      "Epoch 252, Prediction: 0.4137973189353943, Loss: 0.4843314290046692\n",
      "Epoch 253, Prediction: 0.5055717825889587, Loss: 0.34363359212875366\n",
      "Epoch 254, Prediction: 0.5825284123420715, Loss: 0.24445925652980804\n",
      "Epoch 255, Prediction: 0.6471972465515137, Loss: 0.1742825210094452\n",
      "Epoch 256, Prediction: 0.7016340494155884, Loss: 0.12446977943181992\n",
      "Epoch 257, Prediction: 0.7475219368934631, Loss: 0.08902224153280258\n",
      "Epoch 258, Prediction: 0.7862478494644165, Loss: 0.0637451708316803\n",
      "Epoch 259, Prediction: 0.8189601898193359, Loss: 0.04568998143076897\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "[1, 12, 1]\n",
      "Epoch 260, Prediction: 0.846614420413971, Loss: 0.03277541324496269\n",
      "Epoch 261, Prediction: 0.8700076341629028, Loss: 0.02352713607251644\n",
      "Epoch 262, Prediction: 0.8898071050643921, Loss: 0.01689801551401615\n",
      "Epoch 263, Prediction: 0.9065722227096558, Loss: 0.012142473831772804\n",
      "Epoch 264, Prediction: 0.9207735061645508, Loss: 0.008728749118745327\n",
      "Epoch 265, Prediction: 0.9328067898750305, Loss: 0.006276837550103664\n",
      "Epoch 266, Prediction: 0.9430056214332581, Loss: 0.004514927510172129\n",
      "Epoch 267, Prediction: 0.9516516327857971, Loss: 0.003248359076678753\n",
      "Epoch 268, Prediction: 0.9589824080467224, Loss: 0.0023375647142529488\n",
      "Epoch 269, Prediction: 0.9651994109153748, Loss: 0.0016824428457766771\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "[1, 13, 1]\n",
      "Epoch 270, Prediction: 0.6128238439559937, Loss: 0.21872617304325104\n",
      "Epoch 271, Prediction: 0.679132342338562, Loss: 0.14990536868572235\n",
      "Epoch 272, Prediction: 0.7338590621948242, Loss: 0.10295605659484863\n",
      "Epoch 273, Prediction: 0.779099702835083, Loss: 0.07083100080490112\n",
      "Epoch 274, Prediction: 0.8165474534034729, Loss: 0.048796940594911575\n",
      "Epoch 275, Prediction: 0.8475778102874756, Loss: 0.03365483507514\n",
      "Epoch 276, Prediction: 0.8733123540878296, Loss: 0.02323252335190773\n",
      "Epoch 277, Prediction: 0.8946696519851685, Loss: 0.016049759462475777\n",
      "Epoch 278, Prediction: 0.9124043583869934, Loss: 0.011094482615590096\n",
      "Epoch 279, Prediction: 0.927138090133667, Loss: 0.007672996260225773\n",
      "Removing neuron from hidden layer 2 at index 10\n",
      "Rejecting last addition,\n",
      " Removed neuron from hidden layer 2 at index 10\n",
      "[1, 12, 1]\n",
      "Epoch 280, Prediction: 1.1522306203842163, Loss: 0.0325540155172348\n",
      "Epoch 281, Prediction: 1.128395676612854, Loss: 0.023174161091446877\n",
      "Epoch 282, Prediction: 1.1082608699798584, Loss: 0.01648544892668724\n",
      "Epoch 283, Prediction: 1.0912601947784424, Loss: 0.011720416136085987\n",
      "Epoch 284, Prediction: 1.0769128799438477, Loss: 0.008328422904014587\n",
      "Epoch 285, Prediction: 1.0648090839385986, Loss: 0.005915591027587652\n",
      "Epoch 286, Prediction: 1.0546016693115234, Loss: 0.004200217314064503\n",
      "Epoch 287, Prediction: 1.0459959506988525, Loss: 0.002981342375278473\n",
      "Epoch 288, Prediction: 1.0387423038482666, Loss: 0.0021156275179237127\n",
      "Epoch 289, Prediction: 1.032629370689392, Loss: 0.0015009661437943578\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "[1, 13, 1]\n",
      "Epoch 290, Prediction: 1.0274789333343506, Loss: 0.001064675860106945\n",
      "Epoch 291, Prediction: 1.0231397151947021, Loss: 0.0007550917798653245\n",
      "Epoch 292, Prediction: 1.0194851160049438, Loss: 0.0005354463937692344\n",
      "Epoch 293, Prediction: 1.016406774520874, Loss: 0.0003796697419602424\n",
      "Epoch 294, Prediction: 1.013813853263855, Loss: 0.00026918225921690464\n",
      "Epoch 295, Prediction: 1.0116307735443115, Loss: 0.0001908225385705009\n",
      "Epoch 296, Prediction: 1.0097918510437012, Loss: 0.00013527489500120282\n",
      "Epoch 297, Prediction: 1.0082435607910156, Loss: 9.588035027263686e-05\n",
      "Epoch 298, Prediction: 1.0069401264190674, Loss: 6.795629451517016e-05\n",
      "Epoch 299, Prediction: 1.005842685699463, Loss: 4.8165355110540986e-05\n",
      "Added neuron to hidden layer 2 with activation sigmoid\n",
      "[1, 14, 1]\n",
      "Epoch 300, Prediction: 1.3640261888504028, Loss: 0.18913617730140686\n",
      "Epoch 301, Prediction: 1.3044309616088867, Loss: 0.1325150728225708\n",
      "Epoch 302, Prediction: 1.2543951272964478, Loss: 0.09267821162939072\n",
      "Epoch 303, Prediction: 1.2124427556991577, Loss: 0.0647168830037117\n",
      "Epoch 304, Prediction: 1.1773087978363037, Loss: 0.045131925493478775\n",
      "Epoch 305, Prediction: 1.1479144096374512, Loss: 0.03143841028213501\n",
      "Epoch 306, Prediction: 1.1233429908752441, Loss: 0.021878672763705254\n",
      "Epoch 307, Prediction: 1.1028187274932861, Loss: 0.015213493257761002\n",
      "Epoch 308, Prediction: 1.085684895515442, Loss: 0.010571690276265144\n",
      "Epoch 309, Prediction: 1.0713891983032227, Loss: 0.007341901306062937\n",
      "Removing neuron from hidden layer 2 at index 11\n",
      "Rejecting last addition,\n",
      " Removed neuron from hidden layer 2 at index 11\n",
      "[1, 13, 1]\n",
      "Epoch 310, Prediction: 1.4487369060516357, Loss: 0.2758484482765198\n",
      "Epoch 311, Prediction: 1.383089303970337, Loss: 0.20136481523513794\n",
      "Epoch 312, Prediction: 1.3268131017684937, Loss: 0.14675740897655487\n",
      "Epoch 313, Prediction: 1.278630018234253, Loss: 0.10680679976940155\n",
      "Epoch 314, Prediction: 1.2374207973480225, Loss: 0.07763468474149704\n",
      "Epoch 315, Prediction: 1.2022104263305664, Loss: 0.0563686341047287\n",
      "Epoch 316, Prediction: 1.17215096950531, Loss: 0.040889058262109756\n",
      "Epoch 317, Prediction: 1.146507978439331, Loss: 0.02963595651090145\n",
      "Epoch 318, Prediction: 1.1246461868286133, Loss: 0.02146458812057972\n",
      "Epoch 319, Prediction: 1.1060185432434082, Loss: 0.015536671504378319\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "[1, 14, 1]\n",
      "Epoch 320, Prediction: 0.8528381586074829, Loss: 0.03079875558614731\n",
      "Epoch 321, Prediction: 0.8765537142753601, Loss: 0.02165660820901394\n",
      "Epoch 322, Prediction: 0.8964173793792725, Loss: 0.015238985419273376\n",
      "Epoch 323, Prediction: 0.9130632877349854, Loss: 0.010729359462857246\n",
      "Epoch 324, Prediction: 0.9270191192626953, Loss: 0.0075579918920993805\n",
      "Epoch 325, Prediction: 0.9387245774269104, Loss: 0.005326209124177694\n",
      "Epoch 326, Prediction: 0.9485450983047485, Loss: 0.0037546774838119745\n",
      "Epoch 327, Prediction: 0.9567866921424866, Loss: 0.0026476068887859583\n",
      "Epoch 328, Prediction: 0.9637043476104736, Loss: 0.0018673900049179792\n",
      "Epoch 329, Prediction: 0.9695121049880981, Loss: 0.0013173744082450867\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "[1, 15, 1]\n",
      "Epoch 330, Prediction: 1.7150626182556152, Loss: 0.838110625743866\n",
      "Epoch 331, Prediction: 1.5583655834197998, Loss: 0.5113145709037781\n",
      "Epoch 332, Prediction: 1.4358525276184082, Loss: 0.3117721378803253\n",
      "Epoch 333, Prediction: 1.3400976657867432, Loss: 0.18996742367744446\n",
      "Epoch 334, Prediction: 1.2652909755706787, Loss: 0.11566641926765442\n",
      "Epoch 335, Prediction: 1.2068778276443481, Loss: 0.07037930190563202\n",
      "Epoch 336, Prediction: 1.1612865924835205, Loss: 0.04279843717813492\n",
      "Epoch 337, Prediction: 1.1257164478302002, Loss: 0.026013365015387535\n",
      "Epoch 338, Prediction: 1.0979746580123901, Loss: 0.015804626047611237\n",
      "Epoch 339, Prediction: 1.0763447284698486, Loss: 0.009599033743143082\n",
      "Removing neuron from hidden layer 2 at index 12\n",
      "Rejecting last addition,\n",
      " Removed neuron from hidden layer 2 at index 12\n",
      "[1, 14, 1]\n",
      "Epoch 340, Prediction: 0.7515542507171631, Loss: 0.10053973644971848\n",
      "Epoch 341, Prediction: 0.8052634596824646, Loss: 0.06172528862953186\n",
      "Epoch 342, Prediction: 0.8473216891288757, Loss: 0.037922319024801254\n",
      "Epoch 343, Prediction: 0.8802734017372131, Loss: 0.023310666903853416\n",
      "Epoch 344, Prediction: 0.906099796295166, Loss: 0.01433445792645216\n",
      "Epoch 345, Prediction: 0.9263468384742737, Loss: 0.008817248046398163\n",
      "Epoch 346, Prediction: 0.9422234296798706, Loss: 0.005424788221716881\n",
      "Epoch 347, Prediction: 0.9546746015548706, Loss: 0.0033381320536136627\n",
      "Epoch 348, Prediction: 0.9644407033920288, Loss: 0.002054391661658883\n",
      "Epoch 349, Prediction: 0.9721017479896545, Loss: 0.001264463528059423\n",
      "Added neuron to hidden layer 2 with activation sigmoid\n",
      "[1, 15, 1]\n",
      "Epoch 350, Prediction: 1.0548107624053955, Loss: 0.004903011955320835\n",
      "Epoch 351, Prediction: 1.0429021120071411, Loss: 0.003004219615831971\n",
      "Epoch 352, Prediction: 1.0335791110992432, Loss: 0.0018405911978334188\n",
      "Epoch 353, Prediction: 1.0262811183929443, Loss: 0.0011275566648691893\n",
      "Epoch 354, Prediction: 1.02056884765625, Loss: 0.0006906971684657037\n",
      "Epoch 355, Prediction: 1.0160976648330688, Loss: 0.0004230774939060211\n",
      "Epoch 356, Prediction: 1.012597918510437, Loss: 0.0002591348020359874\n",
      "Epoch 357, Prediction: 1.0098592042922974, Loss: 0.0001587075530551374\n",
      "Epoch 358, Prediction: 1.0077158212661743, Loss: 9.720391244627535e-05\n",
      "Epoch 359, Prediction: 1.0060381889343262, Loss: 5.953389700152911e-05\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "[1, 16, 1]\n",
      "Epoch 360, Prediction: 0.7261945009231567, Loss: 0.12865155935287476\n",
      "Epoch 361, Prediction: 0.7909198999404907, Loss: 0.07496944814920425\n",
      "Epoch 362, Prediction: 0.8403096199035645, Loss: 0.043714489787817\n",
      "Epoch 363, Prediction: 0.8780136108398438, Loss: 0.02550101839005947\n",
      "Epoch 364, Prediction: 0.9068047404289246, Loss: 0.014880679547786713\n",
      "Epoch 365, Prediction: 0.9287954568862915, Loss: 0.008685356006026268\n",
      "Epoch 366, Prediction: 0.9455936551094055, Loss: 0.005070087034255266\n",
      "Epoch 367, Prediction: 0.958426833152771, Loss: 0.002960050478577614\n",
      "Epoch 368, Prediction: 0.9682325124740601, Loss: 0.0017283281777054071\n",
      "Epoch 369, Prediction: 0.9757243394851685, Loss: 0.0010091732256114483\n",
      "Removing neuron from hidden layer 2 at index 14\n",
      "Rejecting last addition,\n",
      " Removed neuron from hidden layer 2 at index 14\n",
      "[1, 15, 1]\n",
      "Epoch 370, Prediction: 0.9048547744750977, Loss: 0.015428627841174603\n",
      "Epoch 371, Prediction: 0.9271144866943359, Loss: 0.009052613750100136\n",
      "Epoch 372, Prediction: 0.94416344165802, Loss: 0.005312297958880663\n",
      "Epoch 373, Prediction: 0.9572226405143738, Loss: 0.0031177212949842215\n",
      "Epoch 374, Prediction: 0.9672271013259888, Loss: 0.0018299025250598788\n",
      "Epoch 375, Prediction: 0.9748910665512085, Loss: 0.001074062893167138\n",
      "Epoch 376, Prediction: 0.9807624816894531, Loss: 0.0006304585258476436\n",
      "Epoch 377, Prediction: 0.9852607250213623, Loss: 0.00037008209619671106\n",
      "Epoch 378, Prediction: 0.9887070655822754, Loss: 0.00021724622638430446\n",
      "Epoch 379, Prediction: 0.9913476705551147, Loss: 0.00012753036571666598\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "[1, 16, 1]\n",
      "Epoch 380, Prediction: 0.9920521974563599, Loss: 0.00010788241343107074\n",
      "Epoch 381, Prediction: 0.9939183592796326, Loss: 6.316756480373442e-05\n",
      "Epoch 382, Prediction: 0.9953460693359375, Loss: 3.6986355553381145e-05\n",
      "Epoch 383, Prediction: 0.99643874168396, Loss: 2.1659070625901222e-05\n",
      "Epoch 384, Prediction: 0.9972750544548035, Loss: 1.2682560736720916e-05\n",
      "Epoch 385, Prediction: 0.9979148507118225, Loss: 7.425328021781752e-06\n",
      "Epoch 386, Prediction: 0.9984044432640076, Loss: 4.347847607277799e-06\n",
      "Epoch 387, Prediction: 0.9987789392471313, Loss: 2.5458014079049462e-06\n",
      "Epoch 388, Prediction: 0.9990658760070801, Loss: 1.4909893479853054e-06\n",
      "Epoch 389, Prediction: 0.9992849230766296, Loss: 8.725876341486583e-07\n",
      "Added neuron to hidden layer 2 with activation sigmoid\n",
      "[1, 17, 1]\n",
      "Epoch 390, Prediction: 1.3687853813171387, Loss: 0.23558326065540314\n",
      "Epoch 391, Prediction: 1.2801430225372314, Loss: 0.13600265979766846\n",
      "Epoch 392, Prediction: 1.2127631902694702, Loss: 0.07848010957241058\n",
      "Epoch 393, Prediction: 1.1615608930587769, Loss: 0.04526817426085472\n",
      "Epoch 394, Prediction: 1.1226624250411987, Loss: 0.02610192261636257\n",
      "Epoch 395, Prediction: 1.0931179523468018, Loss: 0.015046070329844952\n",
      "Epoch 396, Prediction: 1.0706828832626343, Loss: 0.00867095310240984\n",
      "Epoch 397, Prediction: 1.0536489486694336, Loss: 0.004996070172637701\n",
      "Epoch 398, Prediction: 1.0407177209854126, Loss: 0.0028782098088413477\n",
      "Epoch 399, Prediction: 1.0309021472930908, Loss: 0.0016579327639192343\n",
      "Removing neuron from hidden layer 2 at index 12\n",
      "Rejecting last addition,\n",
      " Removed neuron from hidden layer 2 at index 12\n",
      "[1, 16, 1]\n",
      "Epoch 400, Prediction: 1.2576875686645508, Loss: 0.11168288439512253\n",
      "Epoch 401, Prediction: 1.1986526250839233, Loss: 0.06640288233757019\n",
      "Epoch 402, Prediction: 1.1531121730804443, Loss: 0.0394628643989563\n",
      "Epoch 403, Prediction: 1.1179924011230469, Loss: 0.02344333752989769\n",
      "Epoch 404, Prediction: 1.0909160375595093, Loss: 0.013922207057476044\n",
      "Epoch 405, Prediction: 1.0700457096099854, Loss: 0.008265726268291473\n",
      "Epoch 406, Prediction: 1.053961992263794, Loss: 0.004906401503831148\n",
      "Epoch 407, Prediction: 1.041568636894226, Loss: 0.002911896677687764\n",
      "Epoch 408, Prediction: 1.032019853591919, Loss: 0.001727951574139297\n",
      "Epoch 409, Prediction: 1.0246634483337402, Loss: 0.001025271019898355\n",
      "Added neuron to hidden layer 2 with activation sigmoid\n",
      "[1, 17, 1]\n",
      "Epoch 410, Prediction: 1.311899185180664, Loss: 0.16542400419712067\n",
      "Epoch 411, Prediction: 1.2390865087509155, Loss: 0.09728109836578369\n",
      "Epoch 412, Prediction: 1.1832102537155151, Loss: 0.05716235935688019\n",
      "Epoch 413, Prediction: 1.1403546333312988, Loss: 0.03356599807739258\n",
      "Epoch 414, Prediction: 1.1075000762939453, Loss: 0.019699422642588615\n",
      "Epoch 415, Prediction: 1.0823220014572144, Loss: 0.01155626680701971\n",
      "Epoch 416, Prediction: 1.0630323886871338, Loss: 0.00677691213786602\n",
      "Epoch 417, Prediction: 1.04825758934021, Loss: 0.003973082173615694\n",
      "Epoch 418, Prediction: 1.036942720413208, Loss: 0.002328794915229082\n",
      "Epoch 419, Prediction: 1.0282790660858154, Loss: 0.0013647646410390735\n",
      "Removing neuron from hidden layer 2 at index 12\n",
      "Rejecting last addition,\n",
      " Removed neuron from hidden layer 2 at index 12\n",
      "[1, 16, 1]\n",
      "Epoch 420, Prediction: 0.5067827701568604, Loss: 0.36403709650039673\n",
      "Epoch 421, Prediction: 0.5962293148040771, Loss: 0.24326322972774506\n",
      "Epoch 422, Prediction: 0.6690738201141357, Loss: 0.16303077340126038\n",
      "Epoch 423, Prediction: 0.7285279631614685, Loss: 0.10951213538646698\n",
      "Epoch 424, Prediction: 0.7771367430686951, Loss: 0.07369706779718399\n",
      "Epoch 425, Prediction: 0.8169337511062622, Loss: 0.04966803267598152\n",
      "Epoch 426, Prediction: 0.8495519757270813, Loss: 0.033513251692056656\n",
      "Epoch 427, Prediction: 0.8763105869293213, Loss: 0.022634608671069145\n",
      "Epoch 428, Prediction: 0.8982776403427124, Loss: 0.015299070626497269\n",
      "Epoch 429, Prediction: 0.9163217544555664, Loss: 0.010347438044846058\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "[1, 17, 1]\n",
      "Epoch 430, Prediction: 0.9337272047996521, Loss: 0.006492492277175188\n",
      "Epoch 431, Prediction: 0.9454818964004517, Loss: 0.004392083268612623\n",
      "Epoch 432, Prediction: 0.9551460146903992, Loss: 0.002972223563119769\n",
      "Epoch 433, Prediction: 0.9630926251411438, Loss: 0.0020118800457566977\n",
      "Epoch 434, Prediction: 0.9696285128593445, Loss: 0.00136215437669307\n",
      "Epoch 435, Prediction: 0.9750053286552429, Loss: 0.0009224272216670215\n",
      "Epoch 436, Prediction: 0.9794291257858276, Loss: 0.0006247335695661604\n",
      "Epoch 437, Prediction: 0.9830689430236816, Loss: 0.00042316087638027966\n",
      "Epoch 438, Prediction: 0.986064076423645, Loss: 0.0002866606810130179\n",
      "Epoch 439, Prediction: 0.9885289072990417, Loss: 0.0001942099625011906\n",
      "Added neuron to hidden layer 2 with activation sigmoid\n",
      "[1, 18, 1]\n",
      "Epoch 440, Prediction: 1.102401614189148, Loss: 0.016037316992878914\n",
      "Epoch 441, Prediction: 1.0827821493148804, Loss: 0.010486090555787086\n",
      "Epoch 442, Prediction: 1.0669078826904297, Loss: 0.0068528843112289906\n",
      "Epoch 443, Prediction: 1.0540679693222046, Loss: 0.004476664587855339\n",
      "Epoch 444, Prediction: 1.0436861515045166, Loss: 0.0029233451932668686\n",
      "Epoch 445, Prediction: 1.0352939367294312, Loss: 0.0019084798404946923\n",
      "Epoch 446, Prediction: 1.0285110473632812, Loss: 0.0012456619879230857\n",
      "Epoch 447, Prediction: 1.023030161857605, Loss: 0.0008128798217512667\n",
      "Epoch 448, Prediction: 1.018601655960083, Loss: 0.0005303883808664978\n",
      "Epoch 449, Prediction: 1.015024185180664, Loss: 0.00034602161031216383\n",
      "Removing neuron from hidden layer 2 at index 13\n",
      "Rejecting last addition,\n",
      " Removed neuron from hidden layer 2 at index 13\n",
      "[1, 17, 1]\n",
      "Epoch 450, Prediction: 1.0152554512023926, Loss: 0.0003559013130143285\n",
      "Epoch 451, Prediction: 1.0123355388641357, Loss: 0.0002327287947991863\n",
      "Epoch 452, Prediction: 1.0099742412567139, Loss: 0.00015216552128549665\n",
      "Epoch 453, Prediction: 1.0080645084381104, Loss: 9.948548540705815e-05\n",
      "Epoch 454, Prediction: 1.006520390510559, Loss: 6.503629992948845e-05\n",
      "Epoch 455, Prediction: 1.0052722692489624, Loss: 4.25154939875938e-05\n",
      "Epoch 456, Prediction: 1.0042625665664673, Loss: 2.779682290565688e-05\n",
      "Epoch 457, Prediction: 1.003446340560913, Loss: 1.816947406041436e-05\n",
      "Epoch 458, Prediction: 1.00278639793396, Loss: 1.1877263204951305e-05\n",
      "Epoch 459, Prediction: 1.0022528171539307, Loss: 7.76401338953292e-06\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "[1, 18, 1]\n",
      "Epoch 460, Prediction: 1.0018212795257568, Loss: 5.0751850722008385e-06\n",
      "Epoch 461, Prediction: 1.0014725923538208, Loss: 3.3170590540976264e-06\n",
      "Epoch 462, Prediction: 1.0011905431747437, Loss: 2.168528226320632e-06\n",
      "Epoch 463, Prediction: 1.000962257385254, Loss: 1.41739303671784e-06\n",
      "Epoch 464, Prediction: 1.0007781982421875, Loss: 9.259392754756846e-07\n",
      "Epoch 465, Prediction: 1.000629186630249, Loss: 6.055925041437149e-07\n",
      "Epoch 466, Prediction: 1.0005085468292236, Loss: 3.9587581568412133e-07\n",
      "Epoch 467, Prediction: 1.0004113912582397, Loss: 2.5861987751341076e-07\n",
      "Epoch 468, Prediction: 1.0003325939178467, Loss: 1.6924276735608146e-07\n",
      "Epoch 469, Prediction: 1.0002689361572266, Loss: 1.1061871418860392e-07\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "[1, 19, 1]\n",
      "Epoch 470, Prediction: 0.47819939255714417, Loss: 0.4318121671676636\n",
      "Epoch 471, Prediction: 0.585034966468811, Loss: 0.2722758948802948\n",
      "Epoch 472, Prediction: 0.6696172952651978, Loss: 0.17219598591327667\n",
      "Epoch 473, Prediction: 0.7367250919342041, Loss: 0.10915273427963257\n",
      "Epoch 474, Prediction: 0.7900567054748535, Loss: 0.06931367516517639\n",
      "Epoch 475, Prediction: 0.8324943780899048, Loss: 0.044076185673475266\n",
      "Epoch 476, Prediction: 0.8662968277931213, Loss: 0.028058134019374847\n",
      "Epoch 477, Prediction: 0.8932421803474426, Loss: 0.017876537516713142\n",
      "Epoch 478, Prediction: 0.9147346019744873, Loss: 0.011397232301533222\n",
      "Epoch 479, Prediction: 0.9318857789039612, Loss: 0.007270188070833683\n",
      "Removing neuron from hidden layer 2 at index 17\n",
      "Rejecting last addition,\n",
      " Removed neuron from hidden layer 2 at index 17\n",
      "[1, 18, 1]\n",
      "Epoch 480, Prediction: 0.9455779194831848, Loss: 0.0046395473182201385\n",
      "Epoch 481, Prediction: 0.9565119743347168, Loss: 0.002961762947961688\n",
      "Epoch 482, Prediction: 0.9652453064918518, Loss: 0.0018912083469331264\n",
      "Epoch 483, Prediction: 0.9722229838371277, Loss: 0.0012078887084499002\n",
      "Epoch 484, Prediction: 0.9777976274490356, Loss: 0.0007715626270510256\n",
      "Epoch 485, Prediction: 0.9822530150413513, Loss: 0.0004929453716613352\n",
      "Epoch 486, Prediction: 0.9858136177062988, Loss: 0.0003149554831907153\n",
      "Epoch 487, Prediction: 0.9886592030525208, Loss: 0.00020125343871768564\n",
      "Epoch 488, Prediction: 0.9909340143203735, Loss: 0.00012861366849392653\n",
      "Epoch 489, Prediction: 0.9927525520324707, Loss: 8.21920984890312e-05\n",
      "Added neuron to hidden layer 2 with activation sigmoid\n",
      "[1, 19, 1]\n",
      "Epoch 490, Prediction: 1.312868356704712, Loss: 0.15482927858829498\n",
      "Epoch 491, Prediction: 1.2485835552215576, Loss: 0.09788660705089569\n",
      "Epoch 492, Prediction: 1.1973872184753418, Loss: 0.06179378554224968\n",
      "Epoch 493, Prediction: 1.1566578149795532, Loss: 0.03896171227097511\n",
      "Epoch 494, Prediction: 1.1242835521697998, Loss: 0.024541670456528664\n",
      "Epoch 495, Prediction: 1.098568320274353, Loss: 0.015446401201188564\n",
      "Epoch 496, Prediction: 1.0781537294387817, Loss: 0.009715713560581207\n",
      "Epoch 497, Prediction: 1.0619547367095947, Loss: 0.006108005531132221\n",
      "Epoch 498, Prediction: 1.0491054058074951, Loss: 0.003838389413431287\n",
      "Epoch 499, Prediction: 1.0389158725738525, Loss: 0.002411340828984976\n",
      "Removing neuron from hidden layer 2 at index 17\n",
      "Rejecting last addition,\n",
      " Removed neuron from hidden layer 2 at index 17\n",
      "[1, 18, 1]\n",
      "Epoch 500, Prediction: 1.5442757606506348, Loss: 0.45525163412094116\n",
      "Epoch 501, Prediction: 1.4384796619415283, Loss: 0.2962360978126526\n",
      "Epoch 502, Prediction: 1.3528645038604736, Loss: 0.1922644078731537\n",
      "Epoch 503, Prediction: 1.283709168434143, Loss: 0.12451335787773132\n",
      "Epoch 504, Prediction: 1.2279367446899414, Loss: 0.08049089461565018\n",
      "Epoch 505, Prediction: 1.1830161809921265, Loss: 0.05195515975356102\n",
      "Epoch 506, Prediction: 1.1468746662139893, Loss: 0.03349492326378822\n",
      "Epoch 507, Prediction: 1.1178226470947266, Loss: 0.021572167053818703\n",
      "Epoch 508, Prediction: 1.0944859981536865, Loss: 0.013882176019251347\n",
      "Epoch 509, Prediction: 1.075751543045044, Loss: 0.00892760418355465\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "[1, 19, 1]\n",
      "Epoch 510, Prediction: 1.060718059539795, Loss: 0.005738296080380678\n",
      "Epoch 511, Prediction: 1.0486600399017334, Loss: 0.0036866827867925167\n",
      "Epoch 512, Prediction: 1.0389909744262695, Loss: 0.0023677994031459093\n",
      "Epoch 513, Prediction: 1.0312401056289673, Loss: 0.0015202960930764675\n",
      "Epoch 514, Prediction: 1.0250271558761597, Loss: 0.0009759442182257771\n",
      "Epoch 515, Prediction: 1.0200488567352295, Loss: 0.0006263585528358817\n",
      "Epoch 516, Prediction: 1.0160598754882812, Loss: 0.00040195666952058673\n",
      "Epoch 517, Prediction: 1.0128637552261353, Loss: 0.0002579196006990969\n",
      "Epoch 518, Prediction: 1.0103037357330322, Loss: 0.0001654762018006295\n",
      "Epoch 519, Prediction: 1.008252501487732, Loss: 0.00010616696818033233\n",
      "Added neuron to hidden layer 2 with activation sigmoid\n",
      "[1, 20, 1]\n",
      "Epoch 520, Prediction: 0.4981409013271332, Loss: 0.3987348973751068\n",
      "Epoch 521, Prediction: 0.6005380749702454, Loss: 0.2518625259399414\n",
      "Epoch 522, Prediction: 0.6816748976707458, Loss: 0.15956982970237732\n",
      "Epoch 523, Prediction: 0.7461042404174805, Loss: 0.10133086889982224\n",
      "Epoch 524, Prediction: 0.7973517179489136, Loss: 0.0644630566239357\n",
      "Epoch 525, Prediction: 0.8381670117378235, Loss: 0.04106632620096207\n",
      "Epoch 526, Prediction: 0.8707060813903809, Loss: 0.02618991583585739\n",
      "Epoch 527, Prediction: 0.89666748046875, Loss: 0.016716917976737022\n",
      "Epoch 528, Prediction: 0.917393684387207, Loss: 0.010677609592676163\n",
      "Epoch 529, Prediction: 0.9339486360549927, Loss: 0.006823803298175335\n",
      "Removing neuron from hidden layer 2 at index 18\n",
      "Rejecting last addition,\n",
      " Removed neuron from hidden layer 2 at index 18\n",
      "[1, 19, 1]\n",
      "Epoch 530, Prediction: 0.9471769332885742, Loss: 0.004362782463431358\n",
      "Epoch 531, Prediction: 0.9577504992485046, Loss: 0.002790276426821947\n",
      "Epoch 532, Prediction: 0.9662036895751953, Loss: 0.0017850203439593315\n",
      "Epoch 533, Prediction: 0.9729634523391724, Loss: 0.001142190652899444\n",
      "Epoch 534, Prediction: 0.9783694744110107, Loss: 0.0007309748907573521\n",
      "Epoch 535, Prediction: 0.9826936721801758, Loss: 0.0004678796394728124\n",
      "Epoch 536, Prediction: 0.9861525893211365, Loss: 0.0002995089744217694\n",
      "Epoch 537, Prediction: 0.9889201521873474, Loss: 0.00019175077613908798\n",
      "Epoch 538, Prediction: 0.9911343455314636, Loss: 0.00012276302732061595\n",
      "Epoch 539, Prediction: 0.9929057359695435, Loss: 7.859982724767178e-05\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "[1, 20, 1]\n",
      "Epoch 540, Prediction: 0.4096248745918274, Loss: 0.588763415813446\n",
      "Epoch 541, Prediction: 0.5445427298545837, Loss: 0.3485427796840668\n",
      "Epoch 542, Prediction: 0.6479324698448181, Loss: 0.2074413299560547\n",
      "Epoch 543, Prediction: 0.7274494767189026, Loss: 0.12395154684782028\n",
      "Epoch 544, Prediction: 0.788771390914917, Loss: 0.07428378611803055\n",
      "Epoch 545, Prediction: 0.8361576199531555, Loss: 0.04461752623319626\n",
      "Epoch 546, Prediction: 0.8728309869766235, Loss: 0.0268443264067173\n",
      "Epoch 547, Prediction: 0.9012466669082642, Loss: 0.016171958297491074\n",
      "Epoch 548, Prediction: 0.9232835173606873, Loss: 0.00975222047418356\n",
      "Epoch 549, Prediction: 0.9403859376907349, Loss: 0.005885418504476547\n",
      "Removing neuron from hidden layer 2 at index 18\n",
      "Rejecting last addition,\n",
      " Removed neuron from hidden layer 2 at index 18\n",
      "[1, 19, 1]\n",
      "Epoch 550, Prediction: 1.4237293004989624, Loss: 0.29287439584732056\n",
      "Epoch 551, Prediction: 1.3312468528747559, Loss: 0.179546520113945\n",
      "Epoch 552, Prediction: 1.2586203813552856, Loss: 0.10972447693347931\n",
      "Epoch 553, Prediction: 1.2017120122909546, Loss: 0.06688450276851654\n",
      "Epoch 554, Prediction: 1.1571991443634033, Loss: 0.04068773612380028\n",
      "Epoch 555, Prediction: 1.1224308013916016, Loss: 0.024711571633815765\n",
      "Epoch 556, Prediction: 1.095304250717163, Loss: 0.014989301562309265\n",
      "Epoch 557, Prediction: 1.0741586685180664, Loss: 0.009082900360226631\n",
      "Epoch 558, Prediction: 1.057686686515808, Loss: 0.005499508231878281\n",
      "Epoch 559, Prediction: 1.044862985610962, Loss: 0.003327753860503435\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "[1, 20, 1]\n",
      "Epoch 560, Prediction: -0.3981534242630005, Loss: 4.3074164390563965\n",
      "Epoch 561, Prediction: 0.04265874624252319, Loss: 1.9548330307006836\n",
      "Epoch 562, Prediction: 0.3380250930786133, Loss: 0.9165022969245911\n",
      "Epoch 563, Prediction: 0.5394043922424316, Loss: 0.43821078538894653\n",
      "Epoch 564, Prediction: 0.6782122850418091, Loss: 0.21214830875396729\n",
      "Epoch 565, Prediction: 0.7745730876922607, Loss: 0.10354733467102051\n",
      "Epoch 566, Prediction: 0.8417842388153076, Loss: 0.05081729218363762\n",
      "Epoch 567, Prediction: 0.8888145685195923, Loss: 0.025032227858901024\n",
      "Epoch 568, Prediction: 0.9217958450317383, Loss: 0.01236219983547926\n",
      "Epoch 569, Prediction: 0.9449596405029297, Loss: 0.0061158896423876286\n",
      "Removing neuron from hidden layer 2 at index 16\n",
      "Rejecting last addition,\n",
      " Removed neuron from hidden layer 2 at index 16\n",
      "[1, 19, 1]\n",
      "Epoch 570, Prediction: 0.7802540063858032, Loss: 0.09344115853309631\n",
      "Epoch 571, Prediction: 0.8417720794677734, Loss: 0.04828830063343048\n",
      "Epoch 572, Prediction: 0.8859362602233887, Loss: 0.025036074221134186\n",
      "Epoch 573, Prediction: 0.9177064895629883, Loss: 0.013010536320507526\n",
      "Epoch 574, Prediction: 0.9405931234359741, Loss: 0.006772221997380257\n",
      "Epoch 575, Prediction: 0.9570962190628052, Loss: 0.0035291770473122597\n",
      "Epoch 576, Prediction: 0.969005823135376, Loss: 0.001840734388679266\n",
      "Epoch 577, Prediction: 0.9776045083999634, Loss: 0.0009606389794498682\n",
      "Epoch 578, Prediction: 0.9838151931762695, Loss: 0.0005015580682083964\n",
      "Epoch 579, Prediction: 0.9883017539978027, Loss: 0.00026194797828793526\n",
      "Added neuron to hidden layer 2 with activation sigmoid\n",
      "[1, 20, 1]\n",
      "Epoch 580, Prediction: 1.0881158113479614, Loss: 0.015125634148716927\n",
      "Epoch 581, Prediction: 1.0630930662155151, Loss: 0.007764396257698536\n",
      "Epoch 582, Prediction: 1.045155644416809, Loss: 0.003980734851211309\n",
      "Epoch 583, Prediction: 1.0323073863983154, Loss: 0.0020390322897583246\n",
      "Epoch 584, Prediction: 1.0231096744537354, Loss: 0.0010437672026455402\n",
      "Epoch 585, Prediction: 1.0165278911590576, Loss: 0.0005340570351108909\n",
      "Epoch 586, Prediction: 1.0118192434310913, Loss: 0.00027317117201164365\n",
      "Epoch 587, Prediction: 1.008450984954834, Loss: 0.00013969451538287103\n",
      "Epoch 588, Prediction: 1.006042718887329, Loss: 7.141914829844609e-05\n",
      "Epoch 589, Prediction: 1.0043202638626099, Loss: 3.6514451494440436e-05\n",
      "Added neuron to hidden layer 2 with activation sigmoid\n",
      "[1, 21, 1]\n",
      "Epoch 590, Prediction: 1.2434346675872803, Loss: 0.11686357110738754\n",
      "Epoch 591, Prediction: 1.1730402708053589, Loss: 0.05926043912768364\n",
      "Epoch 592, Prediction: 1.122842788696289, Loss: 0.029942935332655907\n",
      "Epoch 593, Prediction: 1.0871250629425049, Loss: 0.01509035099297762\n",
      "Epoch 594, Prediction: 1.061751127243042, Loss: 0.007590776775032282\n",
      "Epoch 595, Prediction: 1.043745517730713, Loss: 0.003813201794400811\n",
      "Epoch 596, Prediction: 1.030979871749878, Loss: 0.001913670334033668\n",
      "Epoch 597, Prediction: 1.021933674812317, Loss: 0.0009597524767741561\n",
      "Epoch 598, Prediction: 1.015526533126831, Loss: 0.00048108608461916447\n",
      "Epoch 599, Prediction: 1.0109899044036865, Loss: 0.00024107322678901255\n",
      "Removing neuron from hidden layer 2 at index 19\n",
      "Rejecting last addition,\n",
      " Removed neuron from hidden layer 2 at index 19\n",
      "[1, 20, 1]\n",
      "Epoch 600, Prediction: 0.9185962677001953, Loss: 0.01299580093473196\n",
      "Epoch 601, Prediction: 0.9418342113494873, Loss: 0.006626567803323269\n",
      "Epoch 602, Prediction: 0.9584205150604248, Loss: 0.003383259056136012\n",
      "Epoch 603, Prediction: 0.970267653465271, Loss: 0.001728853560052812\n",
      "Epoch 604, Prediction: 0.9787337183952332, Loss: 0.0008840124355629086\n",
      "Epoch 605, Prediction: 0.9847873449325562, Loss: 0.0004522547242231667\n",
      "Epoch 606, Prediction: 0.9891160726547241, Loss: 0.00023142487043514848\n",
      "Epoch 607, Prediction: 0.9922125339508057, Loss: 0.00011845987319247797\n",
      "Epoch 608, Prediction: 0.9944275617599487, Loss: 6.064462650101632e-05\n",
      "Epoch 609, Prediction: 0.996012806892395, Loss: 3.105206633335911e-05\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "[1, 21, 1]\n",
      "Epoch 610, Prediction: 1.3249635696411133, Loss: 0.21791857481002808\n",
      "Epoch 611, Prediction: 1.2257251739501953, Loss: 0.10560131818056107\n",
      "Epoch 612, Prediction: 1.1565473079681396, Loss: 0.05095185339450836\n",
      "Epoch 613, Prediction: 1.1084493398666382, Loss: 0.024507058784365654\n",
      "Epoch 614, Prediction: 1.0750701427459717, Loss: 0.011761259287595749\n",
      "Epoch 615, Prediction: 1.0519356727600098, Loss: 0.005635526496917009\n",
      "Epoch 616, Prediction: 1.0359171628952026, Loss: 0.0026973141357302666\n",
      "Epoch 617, Prediction: 1.0248327255249023, Loss: 0.0012900425354018807\n",
      "Epoch 618, Prediction: 1.0171655416488647, Loss: 0.0006166642415337265\n",
      "Epoch 619, Prediction: 1.0118639469146729, Loss: 0.00029465582338161767\n",
      "Removing neuron from hidden layer 2 at index 19\n",
      "Rejecting last addition,\n",
      " Removed neuron from hidden layer 2 at index 19\n",
      "[1, 20, 1]\n",
      "Epoch 620, Prediction: 0.7778835296630859, Loss: 0.1024707704782486\n",
      "Epoch 621, Prediction: 0.8456249237060547, Loss: 0.049335725605487823\n",
      "Epoch 622, Prediction: 0.892586886882782, Loss: 0.02383166365325451\n",
      "Epoch 623, Prediction: 0.9252052903175354, Loss: 0.011537577025592327\n",
      "Epoch 624, Prediction: 0.9478910565376282, Loss: 0.005594248417764902\n",
      "Epoch 625, Prediction: 0.963683009147644, Loss: 0.002715341979637742\n",
      "Epoch 626, Prediction: 0.9746824502944946, Loss: 0.0013189237797632813\n",
      "Epoch 627, Prediction: 0.982347846031189, Loss: 0.0006409783381968737\n",
      "Epoch 628, Prediction: 0.9876908659934998, Loss: 0.0003115985309705138\n",
      "Epoch 629, Prediction: 0.9914155006408691, Loss: 0.00015151477418839931\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "[1, 21, 1]\n",
      "Epoch 630, Prediction: 0.6707302927970886, Loss: 0.2626153528690338\n",
      "Epoch 631, Prediction: 0.7877724170684814, Loss: 0.1084185391664505\n",
      "Epoch 632, Prediction: 0.8629465103149414, Loss: 0.0450405478477478\n",
      "Epoch 633, Prediction: 0.9113863110542297, Loss: 0.018783658742904663\n",
      "Epoch 634, Prediction: 0.9426614046096802, Loss: 0.007852385751903057\n",
      "Epoch 635, Prediction: 0.9628800749778748, Loss: 0.0032877144403755665\n",
      "Epoch 636, Prediction: 0.9759618043899536, Loss: 0.0013778888387605548\n",
      "Epoch 637, Prediction: 0.984430193901062, Loss: 0.000577834842260927\n",
      "Epoch 638, Prediction: 0.989914059638977, Loss: 0.00024241885694209486\n",
      "Epoch 639, Prediction: 0.9934655427932739, Loss: 0.00010172619658987969\n",
      "Added neuron to hidden layer 2 with activation sigmoid\n",
      "[1, 22, 1]\n",
      "Epoch 640, Prediction: 1.4263399839401245, Loss: 0.442961722612381\n",
      "Epoch 641, Prediction: 1.2720983028411865, Loss: 0.18176577985286713\n",
      "Epoch 642, Prediction: 1.1732250452041626, Loss: 0.07403748482465744\n",
      "Epoch 643, Prediction: 1.1100971698760986, Loss: 0.03000691719353199\n",
      "Epoch 644, Prediction: 1.0699000358581543, Loss: 0.01212138682603836\n",
      "Epoch 645, Prediction: 1.044348120689392, Loss: 0.004886014852672815\n",
      "Epoch 646, Prediction: 1.0281243324279785, Loss: 0.001966755837202072\n",
      "Epoch 647, Prediction: 1.0178303718566895, Loss: 0.0007909780833870173\n",
      "Epoch 648, Prediction: 1.0113022327423096, Loss: 0.000317922153044492\n",
      "Epoch 649, Prediction: 1.0071632862091064, Loss: 0.00012774046626873314\n",
      "Removing neuron from hidden layer 2 at index 19\n",
      "Rejecting last addition,\n",
      " Removed neuron from hidden layer 2 at index 19\n",
      "[1, 21, 1]\n",
      "Epoch 650, Prediction: 0.7080900073051453, Loss: 0.1999807506799698\n",
      "Epoch 651, Prediction: 0.8088392615318298, Loss: 0.08521144092082977\n",
      "Epoch 652, Prediction: 0.8745609521865845, Loss: 0.03654242679476738\n",
      "Epoch 653, Prediction: 0.9175795912742615, Loss: 0.015734953805804253\n",
      "Epoch 654, Prediction: 0.9457994699478149, Loss: 0.006793123669922352\n",
      "Epoch 655, Prediction: 0.9643370509147644, Loss: 0.002937697572633624\n",
      "Epoch 656, Prediction: 0.9765264391899109, Loss: 0.0012718458892777562\n",
      "Epoch 657, Prediction: 0.9845455884933472, Loss: 0.0005510080372914672\n",
      "Epoch 658, Prediction: 0.9898239970207214, Loss: 0.00023883883841335773\n",
      "Epoch 659, Prediction: 0.9932987689971924, Loss: 0.00010355103586334735\n",
      "Added neuron to hidden layer 2 with activation sigmoid\n",
      "[1, 22, 1]\n",
      "Epoch 660, Prediction: 1.0618959665298462, Loss: 0.009067886509001255\n",
      "Epoch 661, Prediction: 1.0402066707611084, Loss: 0.0038311106618493795\n",
      "Epoch 662, Prediction: 1.026106595993042, Loss: 0.0016165763372555375\n",
      "Epoch 663, Prediction: 1.016946792602539, Loss: 0.0006815543747507036\n",
      "Epoch 664, Prediction: 1.0109989643096924, Loss: 0.0002871937758754939\n",
      "Epoch 665, Prediction: 1.007137417793274, Loss: 0.00012097721628379077\n",
      "Epoch 666, Prediction: 1.004631519317627, Loss: 5.0942733651027083e-05\n",
      "Epoch 667, Prediction: 1.0030052661895752, Loss: 2.1450970962177962e-05\n",
      "Epoch 668, Prediction: 1.0019502639770508, Loss: 9.031625268107746e-06\n",
      "Epoch 669, Prediction: 1.0012654066085815, Loss: 3.8035295801819302e-06\n",
      "Added neuron to hidden layer 2 with activation sigmoid\n",
      "[1, 23, 1]\n",
      "Epoch 670, Prediction: 1.2072120904922485, Loss: 0.10352424532175064\n",
      "Epoch 671, Prediction: 1.1331522464752197, Loss: 0.04293685033917427\n",
      "Epoch 672, Prediction: 1.0854371786117554, Loss: 0.017729520797729492\n",
      "Epoch 673, Prediction: 1.0547690391540527, Loss: 0.007299511693418026\n",
      "Epoch 674, Prediction: 1.0350875854492188, Loss: 0.002999647753313184\n",
      "Epoch 675, Prediction: 1.0224697589874268, Loss: 0.0012311385944485664\n",
      "Epoch 676, Prediction: 1.0143859386444092, Loss: 0.000504890049342066\n",
      "Epoch 677, Prediction: 1.0092084407806396, Loss: 0.00020695522835012525\n",
      "Epoch 678, Prediction: 1.0058943033218384, Loss: 8.479538519168273e-05\n",
      "Epoch 679, Prediction: 1.003772258758545, Loss: 3.474281038506888e-05\n",
      "Removing neuron from hidden layer 2 at index 20\n",
      "Rejecting last addition,\n",
      " Removed neuron from hidden layer 2 at index 20\n",
      "[1, 22, 1]\n",
      "Epoch 680, Prediction: 0.5746203660964966, Loss: 0.4317202866077423\n",
      "Epoch 681, Prediction: 0.7233095765113831, Loss: 0.18094784021377563\n",
      "Epoch 682, Prediction: 0.8194993734359741, Loss: 0.07655759155750275\n",
      "Epoch 683, Prediction: 0.8820323944091797, Loss: 0.03258047625422478\n",
      "Epoch 684, Prediction: 0.9228105545043945, Loss: 0.013916355557739735\n",
      "Epoch 685, Prediction: 0.9494536519050598, Loss: 0.005958210676908493\n",
      "Epoch 686, Prediction: 0.9668847322463989, Loss: 0.0025549333076924086\n",
      "Epoch 687, Prediction: 0.9782974123954773, Loss: 0.001096620922908187\n",
      "Epoch 688, Prediction: 0.985774040222168, Loss: 0.0004710023058578372\n",
      "Epoch 689, Prediction: 0.9906735420227051, Loss: 0.0002023779379669577\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "[1, 23, 1]\n",
      "Epoch 690, Prediction: 0.9586191177368164, Loss: 0.004041541833430529\n",
      "Epoch 691, Prediction: 0.9730538129806519, Loss: 0.0017123774159699678\n",
      "Epoch 692, Prediction: 0.982448160648346, Loss: 0.0007260969723574817\n",
      "Epoch 693, Prediction: 0.9885658025741577, Loss: 0.00030806707218289375\n",
      "Epoch 694, Prediction: 0.9925501346588135, Loss: 0.0001307408674620092\n",
      "Epoch 695, Prediction: 0.9951456785202026, Loss: 5.550049536395818e-05\n",
      "Epoch 696, Prediction: 0.99683678150177, Loss: 2.3564436560263857e-05\n",
      "Epoch 697, Prediction: 0.997938871383667, Loss: 1.0005951480707154e-05\n",
      "Epoch 698, Prediction: 0.998656690120697, Loss: 4.2482511162234005e-06\n",
      "Epoch 699, Prediction: 0.9991246461868286, Loss: 1.8044814851236879e-06\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "[1, 24, 1]\n",
      "Epoch 700, Prediction: 0.830568790435791, Loss: 0.07578222453594208\n",
      "Epoch 701, Prediction: 0.8955110311508179, Loss: 0.028706934303045273\n",
      "Epoch 702, Prediction: 0.9354829788208008, Loss: 0.010917944833636284\n",
      "Epoch 703, Prediction: 0.9601352214813232, Loss: 0.00416244613006711\n",
      "Epoch 704, Prediction: 0.97535640001297, Loss: 0.0015892005758360028\n",
      "Epoch 705, Prediction: 0.9847615361213684, Loss: 0.0006073070107959211\n",
      "Epoch 706, Prediction: 0.9905754923820496, Loss: 0.00023221077572088689\n",
      "Epoch 707, Prediction: 0.9941710829734802, Loss: 8.882134716259316e-05\n",
      "Epoch 708, Prediction: 0.9963945150375366, Loss: 3.3976273698499426e-05\n",
      "Epoch 709, Prediction: 0.9977700710296631, Loss: 1.2999521459278185e-05\n",
      "Removing neuron from hidden layer 2 at index 21\n",
      "Rejecting last addition,\n",
      " Removed neuron from hidden layer 2 at index 21\n",
      "[1, 23, 1]\n",
      "Epoch 710, Prediction: 0.79364013671875, Loss: 0.10954996943473816\n",
      "Epoch 711, Prediction: 0.8710513114929199, Loss: 0.04258439317345619\n",
      "Epoch 712, Prediction: 0.9193135499954224, Loss: 0.016627764329314232\n",
      "Epoch 713, Prediction: 0.9494701027870178, Loss: 0.006510303355753422\n",
      "Epoch 714, Prediction: 0.9683392643928528, Loss: 0.0025532704312354326\n",
      "Epoch 715, Prediction: 0.9801555275917053, Loss: 0.0010024021612480283\n",
      "Epoch 716, Prediction: 0.9875591993331909, Loss: 0.0003938030858989805\n",
      "Epoch 717, Prediction: 0.9922000169754028, Loss: 0.00015477351553272456\n",
      "Epoch 718, Prediction: 0.9951090812683105, Loss: 6.0839734942419454e-05\n",
      "Epoch 719, Prediction: 0.9969332218170166, Loss: 2.3921085812617093e-05\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "[1, 24, 1]\n",
      "Epoch 720, Prediction: 0.9362610578536987, Loss: 0.010474606417119503\n",
      "Epoch 721, Prediction: 0.9602779746055603, Loss: 0.004062652587890625\n",
      "Epoch 722, Prediction: 0.9752358794212341, Loss: 0.0015778392553329468\n",
      "Epoch 723, Prediction: 0.9845560789108276, Loss: 0.0006132616545073688\n",
      "Epoch 724, Prediction: 0.9903678894042969, Loss: 0.00023851469450164586\n",
      "Epoch 725, Prediction: 0.9939916729927063, Loss: 9.277755452785641e-05\n",
      "Epoch 726, Prediction: 0.996252179145813, Loss: 3.609999475884251e-05\n",
      "Epoch 727, Prediction: 0.9976620078086853, Loss: 1.4046161595615558e-05\n",
      "Epoch 728, Prediction: 0.9985415935516357, Loss: 5.46620731256553e-06\n",
      "Epoch 729, Prediction: 0.999089777469635, Loss: 2.1269493117870297e-06\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "[1, 25, 1]\n",
      "Epoch 730, Prediction: 0.9994323253631592, Loss: 8.285050512313319e-07\n",
      "Epoch 731, Prediction: 0.999646008014679, Loss: 3.222544933123572e-07\n",
      "Epoch 732, Prediction: 0.9997788071632385, Loss: 1.253103221188212e-07\n",
      "Epoch 733, Prediction: 0.9998621940612793, Loss: 4.8926271034588353e-08\n",
      "Epoch 734, Prediction: 0.9999138116836548, Loss: 1.8990476746694185e-08\n",
      "Epoch 735, Prediction: 0.9999462366104126, Loss: 7.428425874422828e-09\n",
      "Threshold reached, stopping training at epoch 735\n",
      "Final Prediction: 0.99994624\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    loss, mlp, opt_state = train_step(mlp, x, y, opt_state, opt.update)\n",
    "    print(f\"Epoch {epoch}, Prediction: {mlp(x)}, Loss: {loss}\")\n",
    "\n",
    "    key, add_key, sub_key = jax.random.split(key,3)\n",
    "    n_neurons = sum(mlp.get_shape())\n",
    "    Loss_history.append(loss)\n",
    "    Node_history.append(n_neurons)\n",
    "\n",
    "\n",
    "    # Dynamically add or remove neurons\n",
    "    if (epoch + 1) % add_node_every == 0:\n",
    "        if len(Update_history) == 0 or Update_history[-1][2] > loss or Update_history[-1][3] == \"removed\":\n",
    "            # if no previous addition or last addition was rejected, add a neuron\n",
    "            # if last addition was accepted, add a neuron\n",
    "            add_key, act_key = jax.random.split(add_key)\n",
    "            activation = activation_list[jax.random.choice(key, jnp.arange(len(activation_list)))]\n",
    "            layer_idx = mlp.most_important_layer()\n",
    "            mlp.add_neuron(layer_index=layer_idx, activation=activation, key=act_key)\n",
    "            opt_state = initialize_optimizer_state(mlp, opt)\n",
    "\n",
    "            Update_history.append((epoch, n_neurons, loss, activation.__name__, layer_idx))\n",
    "            print(f\"Added neuron to hidden layer {layer_idx+1} with activation {activation.__name__}\")\n",
    "            print(mlp.get_shape())\n",
    "        \n",
    "        elif Update_history[-1][2] < loss:\n",
    "            # if last addition doesn't improve loss, remove the worst neuron\n",
    "\n",
    "            layer_idx, neuron_idx = mlp.least_important_neuron()\n",
    "            print(f\"Removing neuron from hidden layer {layer_idx+1} at index {neuron_idx}\")\n",
    "            mlp.remove_neuron(layer_index=layer_idx, neuron_index=neuron_idx)\n",
    "            opt_state = initialize_optimizer_state(mlp, opt)\n",
    "            Update_history.append((epoch, n_neurons, loss, \"removed\", layer_idx))\n",
    "            print(f\"Rejecting last addition,\\n Removed neuron from hidden layer {layer_idx+1} at index {neuron_idx}\")\n",
    "            print(mlp.get_shape())\n",
    "        \n",
    "    if loss < threshold:\n",
    "        # if loss is below threshold, stop training\n",
    "        print(f\"Threshold reached, stopping training at epoch {epoch}\")\n",
    "        break\n",
    "    \n",
    "\n",
    "\n",
    "print(\"Final Prediction:\", mlp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9, 6, Array(0.8796847, dtype=float32), 'sigmoid', Array(1, dtype=int32)),\n",
       " (19, 7, Array(1.4334427, dtype=float32), 'removed', Array(0, dtype=int32)),\n",
       " (29, 6, Array(0.83536696, dtype=float32), 'tanh', Array(1, dtype=int32)),\n",
       " (39, 7, Array(0.33150783, dtype=float32), 'tanh', Array(1, dtype=int32)),\n",
       " (49, 8, Array(0.25141242, dtype=float32), 'sigmoid', Array(1, dtype=int32)),\n",
       " (59, 9, Array(0.06945555, dtype=float32), 'tanh', Array(1, dtype=int32)),\n",
       " (69, 10, Array(0.4186711, dtype=float32), 'removed', Array(1, dtype=int32)),\n",
       " (79, 9, Array(0.07566728, dtype=float32), 'tanh', Array(1, dtype=int32)),\n",
       " (89, 10, Array(0.01370741, dtype=float32), 'relu', Array(1, dtype=int32)),\n",
       " (99, 11, Array(0.07210286, dtype=float32), 'removed', Array(1, dtype=int32)),\n",
       " (109, 10, Array(0.00553092, dtype=float32), 'tanh', Array(1, dtype=int32)),\n",
       " (119, 11, Array(0.01030728, dtype=float32), 'removed', Array(1, dtype=int32)),\n",
       " (129, 10, Array(0.05293478, dtype=float32), 'sigmoid', Array(1, dtype=int32)),\n",
       " (139, 11, Array(0.05114001, dtype=float32), 'tanh', Array(1, dtype=int32)),\n",
       " (149, 12, Array(0.03841683, dtype=float32), 'relu', Array(1, dtype=int32)),\n",
       " (159, 13, Array(0.00453647, dtype=float32), 'relu', Array(1, dtype=int32)),\n",
       " (169, 14, Array(0.00462849, dtype=float32), 'removed', Array(1, dtype=int32)),\n",
       " (179,\n",
       "  13,\n",
       "  Array(1.3528298e-05, dtype=float32),\n",
       "  'sigmoid',\n",
       "  Array(1, dtype=int32)),\n",
       " (189, 14, Array(0.00202855, dtype=float32), 'removed', Array(1, dtype=int32)),\n",
       " (199, 13, Array(0.00010543, dtype=float32), 'sigmoid', Array(1, dtype=int32)),\n",
       " (209, 14, Array(0.01143631, dtype=float32), 'removed', Array(1, dtype=int32)),\n",
       " (219, 13, Array(0.0771122, dtype=float32), 'relu', Array(1, dtype=int32)),\n",
       " (229, 14, Array(0.13672857, dtype=float32), 'removed', Array(1, dtype=int32)),\n",
       " (239, 13, Array(0.00042372, dtype=float32), 'sigmoid', Array(1, dtype=int32)),\n",
       " (249, 14, Array(0.00498769, dtype=float32), 'removed', Array(1, dtype=int32)),\n",
       " (259, 13, Array(0.04568998, dtype=float32), 'relu', Array(1, dtype=int32)),\n",
       " (269, 14, Array(0.00168244, dtype=float32), 'relu', Array(1, dtype=int32)),\n",
       " (279, 15, Array(0.007673, dtype=float32), 'removed', Array(1, dtype=int32)),\n",
       " (289, 14, Array(0.00150097, dtype=float32), 'relu', Array(1, dtype=int32)),\n",
       " (299,\n",
       "  15,\n",
       "  Array(4.8165355e-05, dtype=float32),\n",
       "  'sigmoid',\n",
       "  Array(1, dtype=int32)),\n",
       " (309, 16, Array(0.0073419, dtype=float32), 'removed', Array(1, dtype=int32)),\n",
       " (319, 15, Array(0.01553667, dtype=float32), 'tanh', Array(1, dtype=int32)),\n",
       " (329, 16, Array(0.00131737, dtype=float32), 'relu', Array(1, dtype=int32)),\n",
       " (339, 17, Array(0.00959903, dtype=float32), 'removed', Array(1, dtype=int32)),\n",
       " (349, 16, Array(0.00126446, dtype=float32), 'sigmoid', Array(1, dtype=int32)),\n",
       " (359, 17, Array(5.9533897e-05, dtype=float32), 'tanh', Array(1, dtype=int32)),\n",
       " (369, 18, Array(0.00100917, dtype=float32), 'removed', Array(1, dtype=int32)),\n",
       " (379, 17, Array(0.00012753, dtype=float32), 'relu', Array(1, dtype=int32)),\n",
       " (389,\n",
       "  18,\n",
       "  Array(8.7258763e-07, dtype=float32),\n",
       "  'sigmoid',\n",
       "  Array(1, dtype=int32)),\n",
       " (399, 19, Array(0.00165793, dtype=float32), 'removed', Array(1, dtype=int32)),\n",
       " (409, 18, Array(0.00102527, dtype=float32), 'sigmoid', Array(1, dtype=int32)),\n",
       " (419, 19, Array(0.00136476, dtype=float32), 'removed', Array(1, dtype=int32)),\n",
       " (429, 18, Array(0.01034744, dtype=float32), 'tanh', Array(1, dtype=int32)),\n",
       " (439, 19, Array(0.00019421, dtype=float32), 'sigmoid', Array(1, dtype=int32)),\n",
       " (449, 20, Array(0.00034602, dtype=float32), 'removed', Array(1, dtype=int32)),\n",
       " (459, 19, Array(7.764013e-06, dtype=float32), 'relu', Array(1, dtype=int32)),\n",
       " (469,\n",
       "  20,\n",
       "  Array(1.10618714e-07, dtype=float32),\n",
       "  'tanh',\n",
       "  Array(1, dtype=int32)),\n",
       " (479, 21, Array(0.00727019, dtype=float32), 'removed', Array(1, dtype=int32)),\n",
       " (489,\n",
       "  20,\n",
       "  Array(8.21921e-05, dtype=float32),\n",
       "  'sigmoid',\n",
       "  Array(1, dtype=int32)),\n",
       " (499, 21, Array(0.00241134, dtype=float32), 'removed', Array(1, dtype=int32)),\n",
       " (509, 20, Array(0.0089276, dtype=float32), 'relu', Array(1, dtype=int32)),\n",
       " (519, 21, Array(0.00010617, dtype=float32), 'sigmoid', Array(1, dtype=int32)),\n",
       " (529, 22, Array(0.0068238, dtype=float32), 'removed', Array(1, dtype=int32)),\n",
       " (539, 21, Array(7.859983e-05, dtype=float32), 'relu', Array(1, dtype=int32)),\n",
       " (549, 22, Array(0.00588542, dtype=float32), 'removed', Array(1, dtype=int32)),\n",
       " (559, 21, Array(0.00332775, dtype=float32), 'relu', Array(1, dtype=int32)),\n",
       " (569, 22, Array(0.00611589, dtype=float32), 'removed', Array(1, dtype=int32)),\n",
       " (579, 21, Array(0.00026195, dtype=float32), 'sigmoid', Array(1, dtype=int32)),\n",
       " (589,\n",
       "  22,\n",
       "  Array(3.651445e-05, dtype=float32),\n",
       "  'sigmoid',\n",
       "  Array(1, dtype=int32)),\n",
       " (599, 23, Array(0.00024107, dtype=float32), 'removed', Array(1, dtype=int32)),\n",
       " (609, 22, Array(3.1052066e-05, dtype=float32), 'relu', Array(1, dtype=int32)),\n",
       " (619, 23, Array(0.00029466, dtype=float32), 'removed', Array(1, dtype=int32)),\n",
       " (629, 22, Array(0.00015151, dtype=float32), 'relu', Array(1, dtype=int32)),\n",
       " (639, 23, Array(0.00010173, dtype=float32), 'sigmoid', Array(1, dtype=int32)),\n",
       " (649, 24, Array(0.00012774, dtype=float32), 'removed', Array(1, dtype=int32)),\n",
       " (659, 23, Array(0.00010355, dtype=float32), 'sigmoid', Array(1, dtype=int32)),\n",
       " (669,\n",
       "  24,\n",
       "  Array(3.8035296e-06, dtype=float32),\n",
       "  'sigmoid',\n",
       "  Array(1, dtype=int32)),\n",
       " (679,\n",
       "  25,\n",
       "  Array(3.474281e-05, dtype=float32),\n",
       "  'removed',\n",
       "  Array(1, dtype=int32)),\n",
       " (689, 24, Array(0.00020238, dtype=float32), 'relu', Array(1, dtype=int32)),\n",
       " (699, 25, Array(1.8044815e-06, dtype=float32), 'relu', Array(1, dtype=int32)),\n",
       " (709,\n",
       "  26,\n",
       "  Array(1.29995215e-05, dtype=float32),\n",
       "  'removed',\n",
       "  Array(1, dtype=int32)),\n",
       " (719, 25, Array(2.3921086e-05, dtype=float32), 'tanh', Array(1, dtype=int32)),\n",
       " (729, 26, Array(2.1269493e-06, dtype=float32), 'relu', Array(1, dtype=int32))]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Update_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss', color=color)\n",
    "ax1.plot(np.arange(0,len(Loss_history)), Loss_history, \".\", color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.set_yscale(\"log\")\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Number of Nodes', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(np.arange(0,len(Node_history)), Node_history, \".\", color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "plt.suptitle(\"Homogenous init Neural Network with Loss+Weight\\n strategy Node Addition and Removal\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers (2201454092.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[19], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    009, 06, 0.8796847, 'sigmoid', 1\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers\n"
     ]
    }
   ],
   "source": [
    "009, 06, 0.8796847, 'sigmoid', 1\n",
    "019, 07, 1.4334427, 'removed', 0\n",
    "029, 06, 0.83536696, 'tanh', 1\n",
    "039, 07, 0.33150783, 'tanh', 1\n",
    "049, 08, 0.25141242, 'sigmoid', 1\n",
    "059, 09, 0.06945555, 'tanh', 1\n",
    "069, 10, 0.4186711, 'removed', 1\n",
    "079, 09, 0.07566728, 'tanh', 1\n",
    "089, 10, 0.01370741, 'relu', 1\n",
    "099, 11, 0.07210286, 'removed', 1\n",
    "109, 10, 0.00553092, 'tanh', 1\n",
    "119, 11, 0.01030728, 'removed', 1\n",
    "129, 10, 0.05293478, 'sigmoid', 1\n",
    "139, 11, 0.05114001, 'tanh', 1\n",
    "149, 12, 0.03841683, 'relu', 1\n",
    "159, 13, 0.00453647, 'relu', 1\n",
    "169, 14, 0.00462849, 'removed', 1\n",
    "179, 13, 1.3528298e-05, 'sigmoid', 1\n",
    "189, 14, 0.00202855, 'removed', 1\n",
    "199, 13, 0.00010543, 'sigmoid', 1\n",
    "209, 14, 0.01143631, 'removed', 1\n",
    "219, 13, 0.0771122, 'relu', 1\n",
    "229, 14, 0.13672857, 'removed', 1\n",
    "239, 13, 0.00042372, 'sigmoid', 1\n",
    "249, 14, 0.00498769, 'removed', 1\n",
    "259, 13, 0.04568998, 'relu', 1\n",
    "269, 14, 0.00168244, 'relu', 1\n",
    "279, 15, 0.007673, 'removed', 1\n",
    "289, 14, 0.00150097, 'relu', 1\n",
    "299, 15, 4.8165355e-05, 'sigmoid', 1\n",
    "309, 16, 0.0073419, 'removed', 1\n",
    "319, 15, 0.01553667, 'tanh', 1\n",
    "329, 16, 0.00131737, 'relu', 1\n",
    "339, 17, 0.00959903, 'removed', 1\n",
    "349, 16, 0.00126446, 'sigmoid', 1\n",
    "359, 17, 5.9533897e-05, 'tanh', 1\n",
    "369, 18, 0.00100917, 'removed', 1\n",
    "379, 17, 0.00012753, 'relu', 1\n",
    "389, 18, 8.7258763e-07, 'sigmoid', 1\n",
    "399, 19, 0.00165793, 'removed', 1\n",
    "409, 18, 0.00102527, 'sigmoid', 1\n",
    "419, 19, 0.00136476, 'removed', 1\n",
    "429, 18, 0.01034744, 'tanh', 1\n",
    "439, 19, 0.00019421, 'sigmoid', 1\n",
    "449, 20, 0.00034602, 'removed', 1\n",
    "459, 19, 7.764013e-06, 'relu', 1\n",
    "469, 20, 1.10618714e-07, 'tanh', 1\n",
    "479, 21, 0.00727019, 'removed', 1\n",
    "489, 20, 8.21921e-05, 'sigmoid', 1\n",
    "499, 21, 0.00241134, 'removed', 1\n",
    "509, 20, 0.0089276, 'relu', 1\n",
    "519, 21, 0.00010617, 'sigmoid', 1\n",
    "529, 22, 0.0068238, 'removed', 1\n",
    "539, 21, 7.859983e-05, 'relu', 1\n",
    "549, 22, 0.00588542, 'removed', 1\n",
    "559, 21, 0.00332775, 'relu', 1\n",
    "569, 22, 0.00611589, 'removed', 1\n",
    "579, 21, 0.00026195, 'sigmoid', 1\n",
    "589, 22, 3.651445e-05, 'sigmoid', 1\n",
    "599, 23, 0.00024107, 'removed', 1\n",
    "609, 22, 3.1052066e-05, 'relu', 1\n",
    "619, 23, 0.00029466, 'removed', 1\n",
    "629, 22, 0.00015151, 'relu', 1\n",
    "639, 23, 0.00010173, 'sigmoid', 1\n",
    "649, 24, 0.00012774, 'removed', 1\n",
    "659, 23, 0.00010355, 'sigmoid', 1\n",
    "669, 24, 3.8035296e-06, 'sigmoid', 1\n",
    "679, 25, 3.474281e-05, 'removed', 1\n",
    "689, 24, 0.00020238, 'relu', 1\n",
    "699, 25, 1.8044815e-06, 'relu', 1\n",
    "709, 26, 1.29995215e-05, 'removed', 1\n",
    "719, 25, 2.3921086e-05, 'tanh', 1\n",
    "729, 26, 2.1269493e-06, 'relu', 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
