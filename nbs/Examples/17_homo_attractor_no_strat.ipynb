{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: \"WANDB_NOTEBOOK_NAME\"=\"17_homo_attractor_no_strat.ipynb\"\n",
      "env: WANDB_SILENT=True\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "env: XLA_PYTHON_CLIENT_MEM_FRACTION=0.5\n"
     ]
    }
   ],
   "source": [
    "%env \"WANDB_NOTEBOOK_NAME\" \"17_homo_attractor_no_strat.ipynb\"\n",
    "%env WANDB_SILENT=True\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%env XLA_PYTHON_CLIENT_MEM_FRACTION=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "import optax\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.style as mplstyle\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from tqdm.notebook import trange\n",
    "import wandb\n",
    "\n",
    "from dysts.flows import Lorenz, Rossler\n",
    "\n",
    "\n",
    "from NeuralNetworkEvolution.config import MLPConfig\n",
    "from NeuralNetworkEvolution.activations import sin\n",
    "from NeuralNetworkEvolution.mlp import CustomMLP, mlp_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "sns.set_theme(context='paper', style='white', palette='viridis', font='serif',\n",
    "            font_scale=2, color_codes=True, rc={'text.usetex' : True})\n",
    "mplstyle.use('fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "hidden_sizes = [100, 100] \n",
    "output_size = 1\n",
    "initial_activation_list = [jax.nn.relu]\n",
    "activation_list = [jax.nn.relu]\n",
    "bias = True\n",
    "num_epochs = 10000\n",
    "add_node_every = 50\n",
    "seed = 42\n",
    "key = jax.random.PRNGKey(seed)\n",
    "threshold = 1e-4\n",
    "n_samples = 10000\n",
    "learning_rate = 3e-4\n",
    "\n",
    "config = MLPConfig(input_size=input_size,\n",
    "                output_size=output_size,\n",
    "                hidden_sizes=hidden_sizes,\n",
    "                initial_activation_list=initial_activation_list,\n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.__dict__.update({'n_samples': n_samples,\n",
    "                        'learning_rate': learning_rate,\n",
    "                        'num_epochs': num_epochs,\n",
    "                        'add_node_every': add_node_every,\n",
    "                        'threshold': threshold,\n",
    "                        'activation_list': activation_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jax.config.update(\"jax_enable_x64\", True)\n",
    "# jax.config.update('jax_platform_name', 'cpu')\n",
    "Description = f\"Homo_attractor_no_strat__no_bias_{hidden_sizes[0]}_{hidden_sizes[1]}_{num_epochs}_{add_node_every}_{threshold}_{seed}\"\n",
    "fig_folder = f\"../../figures/{Description}\"\n",
    "out_folder = f\"../../output/{Description}\"\n",
    "os.makedirs(fig_folder, exist_ok=True)\n",
    "os.makedirs(out_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# devices: 4\n",
      "Description: Homo_attractor_no_strat__no_bias_100_100_10000_50_0.0001_42\n",
      "Description: Homo_attractor_no_strat__no_bias_100_100_10000_50_0.0001_42\n",
      "jax backend: gpu\n",
      "jax backend: gpu\n",
      "jax devices: [cuda(id=0), cuda(id=1), cuda(id=2), cuda(id=3)]\n",
      "jax devices: [cuda(id=0), cuda(id=1), cuda(id=2), cuda(id=3)]\n"
     ]
    }
   ],
   "source": [
    "print(f\"# devices: {jax.local_device_count()}\")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, filename=f\"{out_folder}/info.log\", filemode=\"w\")\n",
    "console = logging.StreamHandler(sys.stdout)\n",
    "console.setLevel(logging.INFO)\n",
    "logging.getLogger(\"\").addHandler(console)\n",
    "logging.info(f\"Description: {Description}\")\n",
    "logging.info(f\"jax backend: {jax.lib.xla_bridge.get_backend().platform}\")\n",
    "logging.info(f\"jax devices: {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=\"neural-network-evolution\", name=Description, config=config.__dict__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_optimizer_state(mlp, optimizer):\n",
    "    return optimizer.init(eqx.filter(mlp, eqx.is_inexact_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = CustomMLP(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G, neuron_labels, neuron_importances = mlp.visualize_graph()\n",
    "# fig = mlp_plot(G, neuron_labels, neuron_importances)\n",
    "# plt.savefig(f\"{fig_folder}/initial_graph.png\")\n",
    "# wandb.log({\"initial neural network\": wandb.Image(plt, caption=\"initial neural network\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_value_and_grad()\n",
    "def compute_loss(mlp, x, y):\n",
    "    pred = jax.vmap(mlp)(x)\n",
    "    return jnp.mean((pred - y) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit()\n",
    "def train_step(mlp, x, y, opt_state, opt_update):\n",
    "    loss, grads = compute_loss(mlp, x, y)\n",
    "    updates, opt_state = opt_update(grads, opt_state)\n",
    "    mlp = eqx.apply_updates(mlp, updates)\n",
    "    return loss, mlp, opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_norm(grads):\n",
    "    return jnp.sqrt(sum(jnp.sum(jnp.square(p)) for p in jax.tree_util.tree_leaves(grads)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lorenz()\n",
    "lorenz = model.make_trajectory(n_samples, resample=True)\n",
    "# x = jnp.cos(jnp.linspace(0, 2 * jnp.pi, n_samples)).reshape(-1, 1)\n",
    "# x = jnp.linspace(0, 2 * jnp.pi, n_samples).reshape(-1, 1)\n",
    "# y = jnp.sin(jnp.linspace(0, 2 * jnp.pi, n_samples)).reshape(-1, 1)\n",
    "x = jnp.array(lorenz[:, :-1])\n",
    "y = jnp.array(lorenz[:, -1])\n",
    "# x = jnp.arange(0, n_samples).reshape(-1, 1)\n",
    "x_test = x[::10]\n",
    "y_test = y[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 2), (10000,))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<mpl_toolkits.mplot3d.art3d.Line3D>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,6)).add_subplot(projection='3d')\n",
    "plt.plot(lorenz[:, 0], lorenz[:, 1], lorenz[:,2], label=\"3d attractor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optax.adabelief(learning_rate=learning_rate)\n",
    "opt_state = initialize_optimizer_state(mlp, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_adjacency_matrix = mlp.adjacency_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(initial_adjacency_matrix, cmap=plt.cm.viridis)\n",
    "plt.colorbar()\n",
    "plt.title(\"Initial adjacency matrix\")\n",
    "plt.savefig(f\"{fig_folder}/initial_adjacency_matrix.png\")\n",
    "wandb.log({\"initial adjacency matrix\": wandb.Image(plt, caption=\"initial adjacency matrix\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss_history = []\n",
    "Node_history = []\n",
    "grad_norm_history = []\n",
    "graph_history = []\n",
    "Update_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000, Loss: 646.7657242540422, Neurons: 201, Grad norm: 559.4539968050453\n",
      "Epoch 000, Loss: 646.7657242540422, Neurons: 201, Grad norm: 559.4539968050453\n",
      "Epoch 001, Loss: 639.1079995314267, Neurons: 201, Grad norm: 551.1557059095652\n",
      "Epoch 001, Loss: 639.1079995314267, Neurons: 201, Grad norm: 551.1557059095652\n",
      "Epoch 002, Loss: 631.2335060884872, Neurons: 201, Grad norm: 539.9286209925405\n",
      "Epoch 002, Loss: 631.2335060884872, Neurons: 201, Grad norm: 539.9286209925405\n",
      "Epoch 003, Loss: 623.2486184568021, Neurons: 201, Grad norm: 532.4379432054924\n",
      "Epoch 003, Loss: 623.2486184568021, Neurons: 201, Grad norm: 532.4379432054924\n",
      "Epoch 004, Loss: 615.199620517729, Neurons: 201, Grad norm: 526.673900635808\n",
      "Epoch 004, Loss: 615.199620517729, Neurons: 201, Grad norm: 526.673900635808\n",
      "Epoch 005, Loss: 607.0509886891508, Neurons: 201, Grad norm: 521.8081968333086\n",
      "Epoch 005, Loss: 607.0509886891508, Neurons: 201, Grad norm: 521.8081968333086\n",
      "Epoch 006, Loss: 598.7526198510062, Neurons: 201, Grad norm: 516.8545474291226\n",
      "Epoch 006, Loss: 598.7526198510062, Neurons: 201, Grad norm: 516.8545474291226\n",
      "Epoch 007, Loss: 590.3282731104417, Neurons: 201, Grad norm: 512.2771684191332\n",
      "Epoch 007, Loss: 590.3282731104417, Neurons: 201, Grad norm: 512.2771684191332\n",
      "Epoch 008, Loss: 581.8446824580901, Neurons: 201, Grad norm: 507.7987166418287\n",
      "Epoch 008, Loss: 581.8446824580901, Neurons: 201, Grad norm: 507.7987166418287\n",
      "Epoch 009, Loss: 573.3912378019475, Neurons: 201, Grad norm: 505.25534141927204\n",
      "Epoch 009, Loss: 573.3912378019475, Neurons: 201, Grad norm: 505.25534141927204\n",
      "Epoch 010, Loss: 564.9602644220844, Neurons: 201, Grad norm: 503.86254597669034\n",
      "Epoch 010, Loss: 564.9602644220844, Neurons: 201, Grad norm: 503.86254597669034\n",
      "Epoch 011, Loss: 556.5031046014972, Neurons: 201, Grad norm: 503.95442623326977\n",
      "Epoch 011, Loss: 556.5031046014972, Neurons: 201, Grad norm: 503.95442623326977\n",
      "Epoch 012, Loss: 548.0081625888267, Neurons: 201, Grad norm: 505.28693780897254\n",
      "Epoch 012, Loss: 548.0081625888267, Neurons: 201, Grad norm: 505.28693780897254\n",
      "Epoch 013, Loss: 539.46885162195, Neurons: 201, Grad norm: 506.747316386\n",
      "Epoch 013, Loss: 539.46885162195, Neurons: 201, Grad norm: 506.747316386\n",
      "Epoch 014, Loss: 530.8917568322111, Neurons: 201, Grad norm: 509.5674626929526\n",
      "Epoch 014, Loss: 530.8917568322111, Neurons: 201, Grad norm: 509.5674626929526\n",
      "Epoch 015, Loss: 522.2598234178777, Neurons: 201, Grad norm: 513.2486355186136\n",
      "Epoch 015, Loss: 522.2598234178777, Neurons: 201, Grad norm: 513.2486355186136\n",
      "Epoch 016, Loss: 513.6075451023182, Neurons: 201, Grad norm: 517.1472967037421\n",
      "Epoch 016, Loss: 513.6075451023182, Neurons: 201, Grad norm: 517.1472967037421\n",
      "Epoch 017, Loss: 504.87746311816875, Neurons: 201, Grad norm: 521.7107496421479\n",
      "Epoch 017, Loss: 504.87746311816875, Neurons: 201, Grad norm: 521.7107496421479\n",
      "Epoch 018, Loss: 496.07747802680416, Neurons: 201, Grad norm: 527.126346899072\n",
      "Epoch 018, Loss: 496.07747802680416, Neurons: 201, Grad norm: 527.126346899072\n",
      "Epoch 019, Loss: 487.1632969217085, Neurons: 201, Grad norm: 533.5535195457439\n",
      "Epoch 019, Loss: 487.1632969217085, Neurons: 201, Grad norm: 533.5535195457439\n",
      "Epoch 020, Loss: 478.08851162475656, Neurons: 201, Grad norm: 538.9873916058161\n",
      "Epoch 020, Loss: 478.08851162475656, Neurons: 201, Grad norm: 538.9873916058161\n",
      "Epoch 021, Loss: 468.8964872210086, Neurons: 201, Grad norm: 544.7605831270839\n",
      "Epoch 021, Loss: 468.8964872210086, Neurons: 201, Grad norm: 544.7605831270839\n",
      "Epoch 022, Loss: 459.5588835091373, Neurons: 201, Grad norm: 550.3247442348792\n",
      "Epoch 022, Loss: 459.5588835091373, Neurons: 201, Grad norm: 550.3247442348792\n",
      "Epoch 023, Loss: 450.0335297192105, Neurons: 201, Grad norm: 554.2885501402662\n",
      "Epoch 023, Loss: 450.0335297192105, Neurons: 201, Grad norm: 554.2885501402662\n",
      "Epoch 024, Loss: 440.39189021702975, Neurons: 201, Grad norm: 557.4893566144032\n",
      "Epoch 024, Loss: 440.39189021702975, Neurons: 201, Grad norm: 557.4893566144032\n",
      "Epoch 025, Loss: 430.6285258763451, Neurons: 201, Grad norm: 559.599981816829\n",
      "Epoch 025, Loss: 430.6285258763451, Neurons: 201, Grad norm: 559.599981816829\n",
      "Epoch 026, Loss: 420.7373459325583, Neurons: 201, Grad norm: 560.1915780717032\n",
      "Epoch 026, Loss: 420.7373459325583, Neurons: 201, Grad norm: 560.1915780717032\n",
      "Epoch 027, Loss: 410.73943987570124, Neurons: 201, Grad norm: 559.6633988509146\n",
      "Epoch 027, Loss: 410.73943987570124, Neurons: 201, Grad norm: 559.6633988509146\n",
      "Epoch 028, Loss: 400.6749430897424, Neurons: 201, Grad norm: 557.7142628732851\n",
      "Epoch 028, Loss: 400.6749430897424, Neurons: 201, Grad norm: 557.7142628732851\n",
      "Epoch 029, Loss: 390.55466401922394, Neurons: 201, Grad norm: 554.144473848576\n",
      "Epoch 029, Loss: 390.55466401922394, Neurons: 201, Grad norm: 554.144473848576\n",
      "Epoch 030, Loss: 380.393125105663, Neurons: 201, Grad norm: 548.4912583216634\n",
      "Epoch 030, Loss: 380.393125105663, Neurons: 201, Grad norm: 548.4912583216634\n",
      "Epoch 031, Loss: 370.25620152730966, Neurons: 201, Grad norm: 540.7532446709495\n",
      "Epoch 031, Loss: 370.25620152730966, Neurons: 201, Grad norm: 540.7532446709495\n",
      "Epoch 032, Loss: 360.20021130149735, Neurons: 201, Grad norm: 530.8493726437256\n",
      "Epoch 032, Loss: 360.20021130149735, Neurons: 201, Grad norm: 530.8493726437256\n",
      "Epoch 033, Loss: 350.2729097237726, Neurons: 201, Grad norm: 518.505820296813\n",
      "Epoch 033, Loss: 350.2729097237726, Neurons: 201, Grad norm: 518.505820296813\n",
      "Epoch 034, Loss: 340.52617555369164, Neurons: 201, Grad norm: 503.7144414728604\n",
      "Epoch 034, Loss: 340.52617555369164, Neurons: 201, Grad norm: 503.7144414728604\n",
      "Epoch 035, Loss: 331.0161018616472, Neurons: 201, Grad norm: 486.23687055130057\n",
      "Epoch 035, Loss: 331.0161018616472, Neurons: 201, Grad norm: 486.23687055130057\n",
      "Epoch 036, Loss: 321.8006865828488, Neurons: 201, Grad norm: 465.9750268031549\n",
      "Epoch 036, Loss: 321.8006865828488, Neurons: 201, Grad norm: 465.9750268031549\n",
      "Epoch 037, Loss: 312.9169121140562, Neurons: 201, Grad norm: 442.31325847171064\n",
      "Epoch 037, Loss: 312.9169121140562, Neurons: 201, Grad norm: 442.31325847171064\n",
      "Epoch 038, Loss: 304.51020186087624, Neurons: 201, Grad norm: 415.692120905896\n",
      "Epoch 038, Loss: 304.51020186087624, Neurons: 201, Grad norm: 415.692120905896\n",
      "Epoch 039, Loss: 296.6438246971867, Neurons: 201, Grad norm: 386.2484812031345\n",
      "Epoch 039, Loss: 296.6438246971867, Neurons: 201, Grad norm: 386.2484812031345\n",
      "Epoch 040, Loss: 289.38337142316544, Neurons: 201, Grad norm: 354.01562197212075\n",
      "Epoch 040, Loss: 289.38337142316544, Neurons: 201, Grad norm: 354.01562197212075\n",
      "Epoch 041, Loss: 282.79695838729623, Neurons: 201, Grad norm: 319.3617456585303\n",
      "Epoch 041, Loss: 282.79695838729623, Neurons: 201, Grad norm: 319.3617456585303\n",
      "Epoch 042, Loss: 276.9357618393659, Neurons: 201, Grad norm: 282.6286722041397\n",
      "Epoch 042, Loss: 276.9357618393659, Neurons: 201, Grad norm: 282.6286722041397\n",
      "Epoch 043, Loss: 271.8420793305365, Neurons: 201, Grad norm: 244.38484849597538\n",
      "Epoch 043, Loss: 271.8420793305365, Neurons: 201, Grad norm: 244.38484849597538\n",
      "Epoch 044, Loss: 267.53614652688924, Neurons: 201, Grad norm: 205.26194180210837\n",
      "Epoch 044, Loss: 267.53614652688924, Neurons: 201, Grad norm: 205.26194180210837\n",
      "Epoch 045, Loss: 264.01099583466487, Neurons: 201, Grad norm: 166.0014442168975\n",
      "Epoch 045, Loss: 264.01099583466487, Neurons: 201, Grad norm: 166.0014442168975\n",
      "Epoch 046, Loss: 261.2365925207433, Neurons: 201, Grad norm: 127.56487956650427\n",
      "Epoch 046, Loss: 261.2365925207433, Neurons: 201, Grad norm: 127.56487956650427\n",
      "Epoch 047, Loss: 259.15647405191095, Neurons: 201, Grad norm: 91.09066014262561\n",
      "Epoch 047, Loss: 259.15647405191095, Neurons: 201, Grad norm: 91.09066014262561\n",
      "Epoch 048, Loss: 257.6911748653318, Neurons: 201, Grad norm: 58.76070477921556\n",
      "Epoch 048, Loss: 257.6911748653318, Neurons: 201, Grad norm: 58.76070477921556\n",
      "Epoch 049, Loss: 256.7489421053492, Neurons: 201, Grad norm: 37.18496092265321\n",
      "Epoch 049, Loss: 256.7489421053492, Neurons: 201, Grad norm: 37.18496092265321\n",
      "Epoch 050, Loss: 256.2301834455923, Neurons: 201, Grad norm: 40.07358402887074\n",
      "Epoch 050, Loss: 256.2301834455923, Neurons: 201, Grad norm: 40.07358402887074\n",
      "Epoch 051, Loss: 256.0353289950393, Neurons: 201, Grad norm: 59.78927977651344\n",
      "Epoch 051, Loss: 256.0353289950393, Neurons: 201, Grad norm: 59.78927977651344\n",
      "Epoch 052, Loss: 256.0702635134646, Neurons: 201, Grad norm: 82.03475507902316\n",
      "Epoch 052, Loss: 256.0702635134646, Neurons: 201, Grad norm: 82.03475507902316\n",
      "Epoch 053, Loss: 256.2505516053643, Neurons: 201, Grad norm: 102.67220226755677\n",
      "Epoch 053, Loss: 256.2505516053643, Neurons: 201, Grad norm: 102.67220226755677\n",
      "Epoch 054, Loss: 256.5045757468217, Neurons: 201, Grad norm: 120.61036436557632\n",
      "Epoch 054, Loss: 256.5045757468217, Neurons: 201, Grad norm: 120.61036436557632\n",
      "Epoch 055, Loss: 256.77423039404204, Neurons: 201, Grad norm: 135.50812524538384\n",
      "Epoch 055, Loss: 256.77423039404204, Neurons: 201, Grad norm: 135.50812524538384\n",
      "Epoch 056, Loss: 257.0144225702607, Neurons: 201, Grad norm: 147.2915634159854\n",
      "Epoch 056, Loss: 257.0144225702607, Neurons: 201, Grad norm: 147.2915634159854\n",
      "Epoch 057, Loss: 257.1925784496267, Neurons: 201, Grad norm: 156.02035508014077\n",
      "Epoch 057, Loss: 257.1925784496267, Neurons: 201, Grad norm: 156.02035508014077\n",
      "Epoch 058, Loss: 257.2872096389134, Neurons: 201, Grad norm: 161.8222219176386\n",
      "Epoch 058, Loss: 257.2872096389134, Neurons: 201, Grad norm: 161.8222219176386\n",
      "Epoch 059, Loss: 257.28653779495573, Neurons: 201, Grad norm: 164.88185204923005\n",
      "Epoch 059, Loss: 257.28653779495573, Neurons: 201, Grad norm: 164.88185204923005\n",
      "Epoch 060, Loss: 257.18682353694487, Neurons: 201, Grad norm: 165.4090788248855\n",
      "Epoch 060, Loss: 257.18682353694487, Neurons: 201, Grad norm: 165.4090788248855\n",
      "Epoch 061, Loss: 256.9907028729688, Neurons: 201, Grad norm: 163.64206085341536\n",
      "Epoch 061, Loss: 256.9907028729688, Neurons: 201, Grad norm: 163.64206085341536\n",
      "Epoch 062, Loss: 256.7059985650944, Neurons: 201, Grad norm: 159.82913879870512\n",
      "Epoch 062, Loss: 256.7059985650944, Neurons: 201, Grad norm: 159.82913879870512\n",
      "Epoch 063, Loss: 256.3440171473331, Neurons: 201, Grad norm: 154.2352646124811\n",
      "Epoch 063, Loss: 256.3440171473331, Neurons: 201, Grad norm: 154.2352646124811\n",
      "Epoch 064, Loss: 255.91847133547265, Neurons: 201, Grad norm: 147.1243777702209\n",
      "Epoch 064, Loss: 255.91847133547265, Neurons: 201, Grad norm: 147.1243777702209\n",
      "Epoch 065, Loss: 255.44428267408134, Neurons: 201, Grad norm: 138.75915643692682\n",
      "Epoch 065, Loss: 255.44428267408134, Neurons: 201, Grad norm: 138.75915643692682\n",
      "Epoch 066, Loss: 254.9365004298137, Neurons: 201, Grad norm: 129.39867014248003\n",
      "Epoch 066, Loss: 254.9365004298137, Neurons: 201, Grad norm: 129.39867014248003\n",
      "Epoch 067, Loss: 254.4097328963678, Neurons: 201, Grad norm: 119.29709586062198\n",
      "Epoch 067, Loss: 254.4097328963678, Neurons: 201, Grad norm: 119.29709586062198\n",
      "Epoch 068, Loss: 253.87718309337075, Neurons: 201, Grad norm: 108.6988790992547\n",
      "Epoch 068, Loss: 253.87718309337075, Neurons: 201, Grad norm: 108.6988790992547\n",
      "Epoch 069, Loss: 253.35052732907678, Neurons: 201, Grad norm: 97.83781685414341\n",
      "Epoch 069, Loss: 253.35052732907678, Neurons: 201, Grad norm: 97.83781685414341\n",
      "Epoch 070, Loss: 252.8395556412249, Neurons: 201, Grad norm: 86.93923294149216\n",
      "Epoch 070, Loss: 252.8395556412249, Neurons: 201, Grad norm: 86.93923294149216\n",
      "Epoch 071, Loss: 252.35166567391533, Neurons: 201, Grad norm: 76.22686542945405\n",
      "Epoch 071, Loss: 252.35166567391533, Neurons: 201, Grad norm: 76.22686542945405\n",
      "Epoch 072, Loss: 251.8921988882698, Neurons: 201, Grad norm: 65.9289944972821\n",
      "Epoch 072, Loss: 251.8921988882698, Neurons: 201, Grad norm: 65.9289944972821\n",
      "Epoch 073, Loss: 251.4642073705411, Neurons: 201, Grad norm: 56.27441659171954\n",
      "Epoch 073, Loss: 251.4642073705411, Neurons: 201, Grad norm: 56.27441659171954\n",
      "Epoch 074, Loss: 251.06889065843072, Neurons: 201, Grad norm: 47.547713820280514\n",
      "Epoch 074, Loss: 251.06889065843072, Neurons: 201, Grad norm: 47.547713820280514\n",
      "Epoch 075, Loss: 250.70613999394288, Neurons: 201, Grad norm: 40.09225133323658\n",
      "Epoch 075, Loss: 250.70613999394288, Neurons: 201, Grad norm: 40.09225133323658\n",
      "Epoch 076, Loss: 250.37582403184646, Neurons: 201, Grad norm: 34.382367566222\n",
      "Epoch 076, Loss: 250.37582403184646, Neurons: 201, Grad norm: 34.382367566222\n",
      "Epoch 077, Loss: 250.07514939165864, Neurons: 201, Grad norm: 30.826160045813157\n",
      "Epoch 077, Loss: 250.07514939165864, Neurons: 201, Grad norm: 30.826160045813157\n",
      "Epoch 078, Loss: 249.7998177361554, Neurons: 201, Grad norm: 29.57599375080356\n",
      "Epoch 078, Loss: 249.7998177361554, Neurons: 201, Grad norm: 29.57599375080356\n",
      "Epoch 079, Loss: 249.54518656718685, Neurons: 201, Grad norm: 30.37492491146964\n",
      "Epoch 079, Loss: 249.54518656718685, Neurons: 201, Grad norm: 30.37492491146964\n",
      "Epoch 080, Loss: 249.30696945705773, Neurons: 201, Grad norm: 32.55978211296384\n",
      "Epoch 080, Loss: 249.30696945705773, Neurons: 201, Grad norm: 32.55978211296384\n",
      "Epoch 081, Loss: 249.0810253329664, Neurons: 201, Grad norm: 35.48003535288581\n",
      "Epoch 081, Loss: 249.0810253329664, Neurons: 201, Grad norm: 35.48003535288581\n",
      "Epoch 082, Loss: 248.86358630383356, Neurons: 201, Grad norm: 38.633988445777575\n",
      "Epoch 082, Loss: 248.86358630383356, Neurons: 201, Grad norm: 38.633988445777575\n",
      "Epoch 083, Loss: 248.6513434847284, Neurons: 201, Grad norm: 41.70924197334953\n",
      "Epoch 083, Loss: 248.6513434847284, Neurons: 201, Grad norm: 41.70924197334953\n",
      "Epoch 084, Loss: 248.44156577140924, Neurons: 201, Grad norm: 44.50744411496636\n",
      "Epoch 084, Loss: 248.44156577140924, Neurons: 201, Grad norm: 44.50744411496636\n",
      "Epoch 085, Loss: 248.23202120250608, Neurons: 201, Grad norm: 46.938710292915324\n",
      "Epoch 085, Loss: 248.23202120250608, Neurons: 201, Grad norm: 46.938710292915324\n",
      "Epoch 086, Loss: 248.02089144741348, Neurons: 201, Grad norm: 48.94972646415259\n",
      "Epoch 086, Loss: 248.02089144741348, Neurons: 201, Grad norm: 48.94972646415259\n",
      "Epoch 087, Loss: 247.80682725020597, Neurons: 201, Grad norm: 50.50071724339393\n",
      "Epoch 087, Loss: 247.80682725020597, Neurons: 201, Grad norm: 50.50071724339393\n",
      "Epoch 088, Loss: 247.58906484657876, Neurons: 201, Grad norm: 51.620351294272965\n",
      "Epoch 088, Loss: 247.58906484657876, Neurons: 201, Grad norm: 51.620351294272965\n",
      "Epoch 089, Loss: 247.36709401064633, Neurons: 201, Grad norm: 52.305954149173566\n",
      "Epoch 089, Loss: 247.36709401064633, Neurons: 201, Grad norm: 52.305954149173566\n",
      "Epoch 090, Loss: 247.14080851848652, Neurons: 201, Grad norm: 52.59289497993802\n",
      "Epoch 090, Loss: 247.14080851848652, Neurons: 201, Grad norm: 52.59289497993802\n",
      "Epoch 091, Loss: 246.91044628900516, Neurons: 201, Grad norm: 52.50755585638195\n",
      "Epoch 091, Loss: 246.91044628900516, Neurons: 201, Grad norm: 52.50755585638195\n",
      "Epoch 092, Loss: 246.67631548397833, Neurons: 201, Grad norm: 52.090788405065425\n",
      "Epoch 092, Loss: 246.67631548397833, Neurons: 201, Grad norm: 52.090788405065425\n",
      "Epoch 093, Loss: 246.4392353679712, Neurons: 201, Grad norm: 51.38339649435935\n",
      "Epoch 093, Loss: 246.4392353679712, Neurons: 201, Grad norm: 51.38339649435935\n",
      "Epoch 094, Loss: 246.19965438303387, Neurons: 201, Grad norm: 50.43309130710795\n",
      "Epoch 094, Loss: 246.19965438303387, Neurons: 201, Grad norm: 50.43309130710795\n",
      "Epoch 095, Loss: 245.9577378552105, Neurons: 201, Grad norm: 49.273426505013084\n",
      "Epoch 095, Loss: 245.9577378552105, Neurons: 201, Grad norm: 49.273426505013084\n",
      "Epoch 096, Loss: 245.71422334522876, Neurons: 201, Grad norm: 47.95119690657816\n",
      "Epoch 096, Loss: 245.71422334522876, Neurons: 201, Grad norm: 47.95119690657816\n",
      "Epoch 097, Loss: 245.4698755270304, Neurons: 201, Grad norm: 46.5102975670844\n",
      "Epoch 097, Loss: 245.4698755270304, Neurons: 201, Grad norm: 46.5102975670844\n",
      "Epoch 098, Loss: 245.22528170570976, Neurons: 201, Grad norm: 44.996035081205925\n",
      "Epoch 098, Loss: 245.22528170570976, Neurons: 201, Grad norm: 44.996035081205925\n",
      "Epoch 099, Loss: 244.98102618378041, Neurons: 201, Grad norm: 43.438878245744995\n",
      "Epoch 099, Loss: 244.98102618378041, Neurons: 201, Grad norm: 43.438878245744995\n",
      "Epoch 100, Loss: 244.73753649813585, Neurons: 201, Grad norm: 41.884714908151345\n",
      "Epoch 100, Loss: 244.73753649813585, Neurons: 201, Grad norm: 41.884714908151345\n",
      "Epoch 101, Loss: 244.4952204505388, Neurons: 201, Grad norm: 40.36884162760298\n",
      "Epoch 101, Loss: 244.4952204505388, Neurons: 201, Grad norm: 40.36884162760298\n",
      "Epoch 102, Loss: 244.25435520112882, Neurons: 201, Grad norm: 38.920866607135544\n",
      "Epoch 102, Loss: 244.25435520112882, Neurons: 201, Grad norm: 38.920866607135544\n",
      "Epoch 103, Loss: 244.0151179894867, Neurons: 201, Grad norm: 37.55621845374741\n",
      "Epoch 103, Loss: 244.0151179894867, Neurons: 201, Grad norm: 37.55621845374741\n",
      "Epoch 104, Loss: 243.7776002714193, Neurons: 201, Grad norm: 36.31289079322264\n",
      "Epoch 104, Loss: 243.7776002714193, Neurons: 201, Grad norm: 36.31289079322264\n",
      "Epoch 105, Loss: 243.54181065709085, Neurons: 201, Grad norm: 35.185085850384546\n",
      "Epoch 105, Loss: 243.54181065709085, Neurons: 201, Grad norm: 35.185085850384546\n",
      "Epoch 106, Loss: 243.30770271956007, Neurons: 201, Grad norm: 34.212521318589744\n",
      "Epoch 106, Loss: 243.30770271956007, Neurons: 201, Grad norm: 34.212521318589744\n",
      "Epoch 107, Loss: 243.0751060071199, Neurons: 201, Grad norm: 33.3633704399181\n",
      "Epoch 107, Loss: 243.0751060071199, Neurons: 201, Grad norm: 33.3633704399181\n",
      "Epoch 108, Loss: 242.84384877780957, Neurons: 201, Grad norm: 32.657794119583926\n",
      "Epoch 108, Loss: 242.84384877780957, Neurons: 201, Grad norm: 32.657794119583926\n",
      "Epoch 109, Loss: 242.61377584657887, Neurons: 201, Grad norm: 32.05841231145284\n",
      "Epoch 109, Loss: 242.61377584657887, Neurons: 201, Grad norm: 32.05841231145284\n",
      "Epoch 110, Loss: 242.38467065071603, Neurons: 201, Grad norm: 31.575929750497238\n",
      "Epoch 110, Loss: 242.38467065071603, Neurons: 201, Grad norm: 31.575929750497238\n",
      "Epoch 111, Loss: 242.1564080037061, Neurons: 201, Grad norm: 31.205457988622868\n",
      "Epoch 111, Loss: 242.1564080037061, Neurons: 201, Grad norm: 31.205457988622868\n",
      "Epoch 112, Loss: 241.92871510746647, Neurons: 201, Grad norm: 30.88921177161289\n",
      "Epoch 112, Loss: 241.92871510746647, Neurons: 201, Grad norm: 30.88921177161289\n",
      "Epoch 113, Loss: 241.7015210107181, Neurons: 201, Grad norm: 30.670318860511323\n",
      "Epoch 113, Loss: 241.7015210107181, Neurons: 201, Grad norm: 30.670318860511323\n",
      "Epoch 114, Loss: 241.47470813001064, Neurons: 201, Grad norm: 30.486428156438667\n",
      "Epoch 114, Loss: 241.47470813001064, Neurons: 201, Grad norm: 30.486428156438667\n",
      "Epoch 115, Loss: 241.24818589189408, Neurons: 201, Grad norm: 30.383137226269337\n",
      "Epoch 115, Loss: 241.24818589189408, Neurons: 201, Grad norm: 30.383137226269337\n",
      "Epoch 116, Loss: 241.02185144852157, Neurons: 201, Grad norm: 30.30491099560646\n",
      "Epoch 116, Loss: 241.02185144852157, Neurons: 201, Grad norm: 30.30491099560646\n",
      "Epoch 117, Loss: 240.79553105610833, Neurons: 201, Grad norm: 30.269951107098855\n",
      "Epoch 117, Loss: 240.79553105610833, Neurons: 201, Grad norm: 30.269951107098855\n",
      "Epoch 118, Loss: 240.56925570176378, Neurons: 201, Grad norm: 30.252752528280727\n",
      "Epoch 118, Loss: 240.56925570176378, Neurons: 201, Grad norm: 30.252752528280727\n",
      "Epoch 119, Loss: 240.3429831852096, Neurons: 201, Grad norm: 30.253047628813768\n",
      "Epoch 119, Loss: 240.3429831852096, Neurons: 201, Grad norm: 30.253047628813768\n",
      "Epoch 120, Loss: 240.11682197320138, Neurons: 201, Grad norm: 30.294695831894757\n",
      "Epoch 120, Loss: 240.11682197320138, Neurons: 201, Grad norm: 30.294695831894757\n",
      "Epoch 121, Loss: 239.89079733355018, Neurons: 201, Grad norm: 30.34441262187439\n",
      "Epoch 121, Loss: 239.89079733355018, Neurons: 201, Grad norm: 30.34441262187439\n",
      "Epoch 122, Loss: 239.66498847374055, Neurons: 201, Grad norm: 30.413791205123864\n",
      "Epoch 122, Loss: 239.66498847374055, Neurons: 201, Grad norm: 30.413791205123864\n",
      "Epoch 123, Loss: 239.43943936757728, Neurons: 201, Grad norm: 30.502519347137973\n",
      "Epoch 123, Loss: 239.43943936757728, Neurons: 201, Grad norm: 30.502519347137973\n",
      "Epoch 124, Loss: 239.21426297435548, Neurons: 201, Grad norm: 30.61270094460937\n",
      "Epoch 124, Loss: 239.21426297435548, Neurons: 201, Grad norm: 30.61270094460937\n",
      "Epoch 125, Loss: 238.98954045721183, Neurons: 201, Grad norm: 30.744138151469674\n",
      "Epoch 125, Loss: 238.98954045721183, Neurons: 201, Grad norm: 30.744138151469674\n",
      "Epoch 126, Loss: 238.76541898972778, Neurons: 201, Grad norm: 30.895716170573017\n",
      "Epoch 126, Loss: 238.76541898972778, Neurons: 201, Grad norm: 30.895716170573017\n",
      "Epoch 127, Loss: 238.5419743735442, Neurons: 201, Grad norm: 31.063947539192093\n",
      "Epoch 127, Loss: 238.5419743735442, Neurons: 201, Grad norm: 31.063947539192093\n",
      "Epoch 128, Loss: 238.3193246203309, Neurons: 201, Grad norm: 31.23429590515521\n",
      "Epoch 128, Loss: 238.3193246203309, Neurons: 201, Grad norm: 31.23429590515521\n",
      "Epoch 129, Loss: 238.09735427106673, Neurons: 201, Grad norm: 31.41426854397898\n",
      "Epoch 129, Loss: 238.09735427106673, Neurons: 201, Grad norm: 31.41426854397898\n",
      "Epoch 130, Loss: 237.87616902332624, Neurons: 201, Grad norm: 31.59604878229241\n",
      "Epoch 130, Loss: 237.87616902332624, Neurons: 201, Grad norm: 31.59604878229241\n",
      "Epoch 131, Loss: 237.65569268102968, Neurons: 201, Grad norm: 31.77805361914303\n",
      "Epoch 131, Loss: 237.65569268102968, Neurons: 201, Grad norm: 31.77805361914303\n",
      "Epoch 132, Loss: 237.43597876566872, Neurons: 201, Grad norm: 31.944359517882486\n",
      "Epoch 132, Loss: 237.43597876566872, Neurons: 201, Grad norm: 31.944359517882486\n",
      "Epoch 133, Loss: 237.21694246013863, Neurons: 201, Grad norm: 32.1077714859478\n",
      "Epoch 133, Loss: 237.21694246013863, Neurons: 201, Grad norm: 32.1077714859478\n",
      "Epoch 134, Loss: 236.9985968244727, Neurons: 201, Grad norm: 32.25505896302668\n",
      "Epoch 134, Loss: 236.9985968244727, Neurons: 201, Grad norm: 32.25505896302668\n",
      "Epoch 135, Loss: 236.78090126332697, Neurons: 201, Grad norm: 32.39274058198712\n",
      "Epoch 135, Loss: 236.78090126332697, Neurons: 201, Grad norm: 32.39274058198712\n",
      "Epoch 136, Loss: 236.5638592205538, Neurons: 201, Grad norm: 32.49154538219587\n",
      "Epoch 136, Loss: 236.5638592205538, Neurons: 201, Grad norm: 32.49154538219587\n",
      "Epoch 137, Loss: 236.34752736949036, Neurons: 201, Grad norm: 32.578120330593734\n",
      "Epoch 137, Loss: 236.34752736949036, Neurons: 201, Grad norm: 32.578120330593734\n",
      "Epoch 138, Loss: 236.13183280580247, Neurons: 201, Grad norm: 32.65211205762236\n",
      "Epoch 138, Loss: 236.13183280580247, Neurons: 201, Grad norm: 32.65211205762236\n",
      "Epoch 139, Loss: 235.91680358115983, Neurons: 201, Grad norm: 32.68902594303578\n",
      "Epoch 139, Loss: 235.91680358115983, Neurons: 201, Grad norm: 32.68902594303578\n",
      "Epoch 140, Loss: 235.7023831818506, Neurons: 201, Grad norm: 32.68845538687967\n",
      "Epoch 140, Loss: 235.7023831818506, Neurons: 201, Grad norm: 32.68845538687967\n",
      "Epoch 141, Loss: 235.48867962427713, Neurons: 201, Grad norm: 32.67720519937946\n",
      "Epoch 141, Loss: 235.48867962427713, Neurons: 201, Grad norm: 32.67720519937946\n",
      "Epoch 142, Loss: 235.27586064417622, Neurons: 201, Grad norm: 32.63910816449187\n",
      "Epoch 142, Loss: 235.27586064417622, Neurons: 201, Grad norm: 32.63910816449187\n",
      "Epoch 143, Loss: 235.06380615396537, Neurons: 201, Grad norm: 32.59030229001266\n",
      "Epoch 143, Loss: 235.06380615396537, Neurons: 201, Grad norm: 32.59030229001266\n",
      "Epoch 144, Loss: 234.85258300912793, Neurons: 201, Grad norm: 32.5170035344907\n",
      "Epoch 144, Loss: 234.85258300912793, Neurons: 201, Grad norm: 32.5170035344907\n",
      "Epoch 145, Loss: 234.64224808270654, Neurons: 201, Grad norm: 32.43792044635839\n",
      "Epoch 145, Loss: 234.64224808270654, Neurons: 201, Grad norm: 32.43792044635839\n",
      "Epoch 146, Loss: 234.43273063607293, Neurons: 201, Grad norm: 32.33898497081122\n",
      "Epoch 146, Loss: 234.43273063607293, Neurons: 201, Grad norm: 32.33898497081122\n",
      "Epoch 147, Loss: 234.22402677853898, Neurons: 201, Grad norm: 32.229170483126126\n",
      "Epoch 147, Loss: 234.22402677853898, Neurons: 201, Grad norm: 32.229170483126126\n",
      "Epoch 148, Loss: 234.01623055439302, Neurons: 201, Grad norm: 32.11183675687967\n",
      "Epoch 148, Loss: 234.01623055439302, Neurons: 201, Grad norm: 32.11183675687967\n",
      "Epoch 149, Loss: 233.8092970528621, Neurons: 201, Grad norm: 31.9762115582523\n",
      "Epoch 149, Loss: 233.8092970528621, Neurons: 201, Grad norm: 31.9762115582523\n",
      "Epoch 150, Loss: 233.6032825111491, Neurons: 201, Grad norm: 31.84774683172078\n",
      "Epoch 150, Loss: 233.6032825111491, Neurons: 201, Grad norm: 31.84774683172078\n",
      "Epoch 151, Loss: 233.3983128137734, Neurons: 201, Grad norm: 31.719453875751768\n",
      "Epoch 151, Loss: 233.3983128137734, Neurons: 201, Grad norm: 31.719453875751768\n",
      "Epoch 152, Loss: 233.19423159202532, Neurons: 201, Grad norm: 31.569313563414152\n",
      "Epoch 152, Loss: 233.19423159202532, Neurons: 201, Grad norm: 31.569313563414152\n",
      "Epoch 153, Loss: 232.9912018605926, Neurons: 201, Grad norm: 31.42001830219755\n",
      "Epoch 153, Loss: 232.9912018605926, Neurons: 201, Grad norm: 31.42001830219755\n",
      "Epoch 154, Loss: 232.78929435191102, Neurons: 201, Grad norm: 31.274687085394774\n",
      "Epoch 154, Loss: 232.78929435191102, Neurons: 201, Grad norm: 31.274687085394774\n",
      "Epoch 155, Loss: 232.5885438343239, Neurons: 201, Grad norm: 31.139150316034442\n",
      "Epoch 155, Loss: 232.5885438343239, Neurons: 201, Grad norm: 31.139150316034442\n",
      "Epoch 156, Loss: 232.38883870149488, Neurons: 201, Grad norm: 31.006400688613933\n",
      "Epoch 156, Loss: 232.38883870149488, Neurons: 201, Grad norm: 31.006400688613933\n",
      "Epoch 157, Loss: 232.19020959502663, Neurons: 201, Grad norm: 30.882682579282818\n",
      "Epoch 157, Loss: 232.19020959502663, Neurons: 201, Grad norm: 30.882682579282818\n",
      "Epoch 158, Loss: 231.99259597088883, Neurons: 201, Grad norm: 30.759888480083386\n",
      "Epoch 158, Loss: 231.99259597088883, Neurons: 201, Grad norm: 30.759888480083386\n",
      "Epoch 159, Loss: 231.79602792688306, Neurons: 201, Grad norm: 30.620538494944316\n",
      "Epoch 159, Loss: 231.79602792688306, Neurons: 201, Grad norm: 30.620538494944316\n",
      "Epoch 160, Loss: 231.60062951634754, Neurons: 201, Grad norm: 30.49071230521259\n",
      "Epoch 160, Loss: 231.60062951634754, Neurons: 201, Grad norm: 30.49071230521259\n",
      "Epoch 161, Loss: 231.40649173230787, Neurons: 201, Grad norm: 30.360249111718318\n",
      "Epoch 161, Loss: 231.40649173230787, Neurons: 201, Grad norm: 30.360249111718318\n",
      "Epoch 162, Loss: 231.2135929638138, Neurons: 201, Grad norm: 30.2399049514925\n",
      "Epoch 162, Loss: 231.2135929638138, Neurons: 201, Grad norm: 30.2399049514925\n",
      "Epoch 163, Loss: 231.0219296962732, Neurons: 201, Grad norm: 30.11942724595971\n",
      "Epoch 163, Loss: 231.0219296962732, Neurons: 201, Grad norm: 30.11942724595971\n",
      "Epoch 164, Loss: 230.83159761528592, Neurons: 201, Grad norm: 29.99790940968837\n",
      "Epoch 164, Loss: 230.83159761528592, Neurons: 201, Grad norm: 29.99790940968837\n",
      "Epoch 165, Loss: 230.64269611652153, Neurons: 201, Grad norm: 29.889334837800792\n",
      "Epoch 165, Loss: 230.64269611652153, Neurons: 201, Grad norm: 29.889334837800792\n",
      "Epoch 166, Loss: 230.4551491578821, Neurons: 201, Grad norm: 29.778433917420877\n",
      "Epoch 166, Loss: 230.4551491578821, Neurons: 201, Grad norm: 29.778433917420877\n",
      "Epoch 167, Loss: 230.26889491408025, Neurons: 201, Grad norm: 29.665405799712037\n",
      "Epoch 167, Loss: 230.26889491408025, Neurons: 201, Grad norm: 29.665405799712037\n",
      "Epoch 168, Loss: 230.08412201632626, Neurons: 201, Grad norm: 29.551851698705885\n",
      "Epoch 168, Loss: 230.08412201632626, Neurons: 201, Grad norm: 29.551851698705885\n",
      "Epoch 169, Loss: 229.90084905073402, Neurons: 201, Grad norm: 29.423232367953997\n",
      "Epoch 169, Loss: 229.90084905073402, Neurons: 201, Grad norm: 29.423232367953997\n",
      "Epoch 170, Loss: 229.71917391745285, Neurons: 201, Grad norm: 29.317463821857846\n",
      "Epoch 170, Loss: 229.71917391745285, Neurons: 201, Grad norm: 29.317463821857846\n",
      "Epoch 171, Loss: 229.5390669417785, Neurons: 201, Grad norm: 29.20403006492014\n",
      "Epoch 171, Loss: 229.5390669417785, Neurons: 201, Grad norm: 29.20403006492014\n",
      "Epoch 172, Loss: 229.36053602168556, Neurons: 201, Grad norm: 29.104604756027715\n",
      "Epoch 172, Loss: 229.36053602168556, Neurons: 201, Grad norm: 29.104604756027715\n",
      "Epoch 173, Loss: 229.1835393816684, Neurons: 201, Grad norm: 28.983953545320375\n",
      "Epoch 173, Loss: 229.1835393816684, Neurons: 201, Grad norm: 28.983953545320375\n",
      "Epoch 174, Loss: 229.0081111438459, Neurons: 201, Grad norm: 28.884384940976634\n",
      "Epoch 174, Loss: 229.0081111438459, Neurons: 201, Grad norm: 28.884384940976634\n",
      "Epoch 175, Loss: 228.8342104466797, Neurons: 201, Grad norm: 28.761423126327173\n",
      "Epoch 175, Loss: 228.8342104466797, Neurons: 201, Grad norm: 28.761423126327173\n",
      "Epoch 176, Loss: 228.66189327041772, Neurons: 201, Grad norm: 28.640156548005994\n",
      "Epoch 176, Loss: 228.66189327041772, Neurons: 201, Grad norm: 28.640156548005994\n",
      "Epoch 177, Loss: 228.4912981882666, Neurons: 201, Grad norm: 28.499199876678617\n",
      "Epoch 177, Loss: 228.4912981882666, Neurons: 201, Grad norm: 28.499199876678617\n",
      "Epoch 178, Loss: 228.32244613805696, Neurons: 201, Grad norm: 28.3545298674689\n",
      "Epoch 178, Loss: 228.32244613805696, Neurons: 201, Grad norm: 28.3545298674689\n",
      "Epoch 179, Loss: 228.15548177684894, Neurons: 201, Grad norm: 28.210877327150566\n",
      "Epoch 179, Loss: 228.15548177684894, Neurons: 201, Grad norm: 28.210877327150566\n",
      "Epoch 180, Loss: 227.99028996675833, Neurons: 201, Grad norm: 28.069555680863793\n",
      "Epoch 180, Loss: 227.99028996675833, Neurons: 201, Grad norm: 28.069555680863793\n",
      "Epoch 181, Loss: 227.82694783837266, Neurons: 201, Grad norm: 27.91894862970196\n",
      "Epoch 181, Loss: 227.82694783837266, Neurons: 201, Grad norm: 27.91894862970196\n",
      "Epoch 182, Loss: 227.66539872869484, Neurons: 201, Grad norm: 27.7743844102397\n",
      "Epoch 182, Loss: 227.66539872869484, Neurons: 201, Grad norm: 27.7743844102397\n",
      "Epoch 183, Loss: 227.50557938669098, Neurons: 201, Grad norm: 27.604304067862735\n",
      "Epoch 183, Loss: 227.50557938669098, Neurons: 201, Grad norm: 27.604304067862735\n",
      "Epoch 184, Loss: 227.34763063822297, Neurons: 201, Grad norm: 27.43154144393327\n",
      "Epoch 184, Loss: 227.34763063822297, Neurons: 201, Grad norm: 27.43154144393327\n",
      "Epoch 185, Loss: 227.1915941652975, Neurons: 201, Grad norm: 27.257503216323776\n",
      "Epoch 185, Loss: 227.1915941652975, Neurons: 201, Grad norm: 27.257503216323776\n",
      "Epoch 186, Loss: 227.0374683900213, Neurons: 201, Grad norm: 27.07260645890273\n",
      "Epoch 186, Loss: 227.0374683900213, Neurons: 201, Grad norm: 27.07260645890273\n",
      "Epoch 187, Loss: 226.8852964512804, Neurons: 201, Grad norm: 26.87283423428547\n",
      "Epoch 187, Loss: 226.8852964512804, Neurons: 201, Grad norm: 26.87283423428547\n",
      "Epoch 188, Loss: 226.73507919975464, Neurons: 201, Grad norm: 26.669217048362437\n",
      "Epoch 188, Loss: 226.73507919975464, Neurons: 201, Grad norm: 26.669217048362437\n",
      "Epoch 189, Loss: 226.58685992587456, Neurons: 201, Grad norm: 26.46845654919095\n",
      "Epoch 189, Loss: 226.58685992587456, Neurons: 201, Grad norm: 26.46845654919095\n",
      "Epoch 190, Loss: 226.44074241290792, Neurons: 201, Grad norm: 26.270679479961135\n",
      "Epoch 190, Loss: 226.44074241290792, Neurons: 201, Grad norm: 26.270679479961135\n",
      "Epoch 191, Loss: 226.29660051776284, Neurons: 201, Grad norm: 26.07936147369617\n",
      "Epoch 191, Loss: 226.29660051776284, Neurons: 201, Grad norm: 26.07936147369617\n",
      "Epoch 192, Loss: 226.1544175226494, Neurons: 201, Grad norm: 25.870731730013187\n",
      "Epoch 192, Loss: 226.1544175226494, Neurons: 201, Grad norm: 25.870731730013187\n",
      "Epoch 193, Loss: 226.0141327451864, Neurons: 201, Grad norm: 25.67121759548257\n",
      "Epoch 193, Loss: 226.0141327451864, Neurons: 201, Grad norm: 25.67121759548257\n",
      "Epoch 194, Loss: 225.87586373554865, Neurons: 201, Grad norm: 25.46107465026468\n",
      "Epoch 194, Loss: 225.87586373554865, Neurons: 201, Grad norm: 25.46107465026468\n",
      "Epoch 195, Loss: 225.73956531902203, Neurons: 201, Grad norm: 25.23507554348481\n",
      "Epoch 195, Loss: 225.73956531902203, Neurons: 201, Grad norm: 25.23507554348481\n",
      "Epoch 196, Loss: 225.6053076530736, Neurons: 201, Grad norm: 25.018261085462697\n",
      "Epoch 196, Loss: 225.6053076530736, Neurons: 201, Grad norm: 25.018261085462697\n",
      "Epoch 197, Loss: 225.47322723378312, Neurons: 201, Grad norm: 24.825557040830574\n",
      "Epoch 197, Loss: 225.47322723378312, Neurons: 201, Grad norm: 24.825557040830574\n",
      "Epoch 198, Loss: 225.3431546572493, Neurons: 201, Grad norm: 24.62030546987518\n",
      "Epoch 198, Loss: 225.3431546572493, Neurons: 201, Grad norm: 24.62030546987518\n",
      "Epoch 199, Loss: 225.21503563512147, Neurons: 201, Grad norm: 24.406418591658085\n",
      "Epoch 199, Loss: 225.21503563512147, Neurons: 201, Grad norm: 24.406418591658085\n",
      "Epoch 200, Loss: 225.08896597928097, Neurons: 201, Grad norm: 24.18671063243623\n",
      "Epoch 200, Loss: 225.08896597928097, Neurons: 201, Grad norm: 24.18671063243623\n",
      "Epoch 201, Loss: 224.96502730754094, Neurons: 201, Grad norm: 24.000749337425418\n",
      "Epoch 201, Loss: 224.96502730754094, Neurons: 201, Grad norm: 24.000749337425418\n",
      "Epoch 202, Loss: 224.84308366278304, Neurons: 201, Grad norm: 23.796477948667928\n",
      "Epoch 202, Loss: 224.84308366278304, Neurons: 201, Grad norm: 23.796477948667928\n",
      "Epoch 203, Loss: 224.72301564400448, Neurons: 201, Grad norm: 23.599799498155605\n",
      "Epoch 203, Loss: 224.72301564400448, Neurons: 201, Grad norm: 23.599799498155605\n",
      "Epoch 204, Loss: 224.60492443250206, Neurons: 201, Grad norm: 23.4110598318769\n",
      "Epoch 204, Loss: 224.60492443250206, Neurons: 201, Grad norm: 23.4110598318769\n",
      "Epoch 205, Loss: 224.48870872213712, Neurons: 201, Grad norm: 23.20350399108947\n",
      "Epoch 205, Loss: 224.48870872213712, Neurons: 201, Grad norm: 23.20350399108947\n",
      "Epoch 206, Loss: 224.37442876410248, Neurons: 201, Grad norm: 23.007024216261392\n",
      "Epoch 206, Loss: 224.37442876410248, Neurons: 201, Grad norm: 23.007024216261392\n",
      "Epoch 207, Loss: 224.26214227876244, Neurons: 201, Grad norm: 22.813082651853342\n",
      "Epoch 207, Loss: 224.26214227876244, Neurons: 201, Grad norm: 22.813082651853342\n",
      "Epoch 208, Loss: 224.15173274893434, Neurons: 201, Grad norm: 22.61329264829268\n",
      "Epoch 208, Loss: 224.15173274893434, Neurons: 201, Grad norm: 22.61329264829268\n",
      "Epoch 209, Loss: 224.04322797531253, Neurons: 201, Grad norm: 22.41902057539531\n",
      "Epoch 209, Loss: 224.04322797531253, Neurons: 201, Grad norm: 22.41902057539531\n",
      "Epoch 210, Loss: 223.93664430414208, Neurons: 201, Grad norm: 22.21209259599747\n",
      "Epoch 210, Loss: 223.93664430414208, Neurons: 201, Grad norm: 22.21209259599747\n",
      "Epoch 211, Loss: 223.83199672733468, Neurons: 201, Grad norm: 22.010399292543582\n",
      "Epoch 211, Loss: 223.83199672733468, Neurons: 201, Grad norm: 22.010399292543582\n",
      "Epoch 212, Loss: 223.72927154011143, Neurons: 201, Grad norm: 21.810968642055602\n",
      "Epoch 212, Loss: 223.72927154011143, Neurons: 201, Grad norm: 21.810968642055602\n",
      "Epoch 213, Loss: 223.62844503698417, Neurons: 201, Grad norm: 21.60083195276119\n",
      "Epoch 213, Loss: 223.62844503698417, Neurons: 201, Grad norm: 21.60083195276119\n",
      "Epoch 214, Loss: 223.52949292887143, Neurons: 201, Grad norm: 21.40054033245092\n",
      "Epoch 214, Loss: 223.52949292887143, Neurons: 201, Grad norm: 21.40054033245092\n",
      "Epoch 215, Loss: 223.43243836410684, Neurons: 201, Grad norm: 21.206032865157997\n",
      "Epoch 215, Loss: 223.43243836410684, Neurons: 201, Grad norm: 21.206032865157997\n",
      "Epoch 216, Loss: 223.33715686997132, Neurons: 201, Grad norm: 20.99367721183866\n",
      "Epoch 216, Loss: 223.33715686997132, Neurons: 201, Grad norm: 20.99367721183866\n",
      "Epoch 217, Loss: 223.2437195186337, Neurons: 201, Grad norm: 20.781581853381486\n",
      "Epoch 217, Loss: 223.2437195186337, Neurons: 201, Grad norm: 20.781581853381486\n",
      "Epoch 218, Loss: 223.15214900509588, Neurons: 201, Grad norm: 20.574539799678\n",
      "Epoch 218, Loss: 223.15214900509588, Neurons: 201, Grad norm: 20.574539799678\n",
      "Epoch 219, Loss: 223.06239847871834, Neurons: 201, Grad norm: 20.371341861353596\n",
      "Epoch 219, Loss: 223.06239847871834, Neurons: 201, Grad norm: 20.371341861353596\n",
      "Epoch 220, Loss: 222.97443153244294, Neurons: 201, Grad norm: 20.16641871910783\n",
      "Epoch 220, Loss: 222.97443153244294, Neurons: 201, Grad norm: 20.16641871910783\n",
      "Epoch 221, Loss: 222.88816098366885, Neurons: 201, Grad norm: 19.965812338793274\n",
      "Epoch 221, Loss: 222.88816098366885, Neurons: 201, Grad norm: 19.965812338793274\n",
      "Epoch 222, Loss: 222.80358162113296, Neurons: 201, Grad norm: 19.771308958815297\n",
      "Epoch 222, Loss: 222.80358162113296, Neurons: 201, Grad norm: 19.771308958815297\n",
      "Epoch 223, Loss: 222.72058497911254, Neurons: 201, Grad norm: 19.574255150010377\n",
      "Epoch 223, Loss: 222.72058497911254, Neurons: 201, Grad norm: 19.574255150010377\n",
      "Epoch 224, Loss: 222.63910275007493, Neurons: 201, Grad norm: 19.368961404644477\n",
      "Epoch 224, Loss: 222.63910275007493, Neurons: 201, Grad norm: 19.368961404644477\n",
      "Epoch 225, Loss: 222.5591523714692, Neurons: 201, Grad norm: 19.160814490575518\n",
      "Epoch 225, Loss: 222.5591523714692, Neurons: 201, Grad norm: 19.160814490575518\n",
      "Epoch 226, Loss: 222.48073164197152, Neurons: 201, Grad norm: 18.96099732615227\n",
      "Epoch 226, Loss: 222.48073164197152, Neurons: 201, Grad norm: 18.96099732615227\n",
      "Epoch 227, Loss: 222.4038209148341, Neurons: 201, Grad norm: 18.755661277532\n",
      "Epoch 227, Loss: 222.4038209148341, Neurons: 201, Grad norm: 18.755661277532\n",
      "Epoch 228, Loss: 222.32835583585785, Neurons: 201, Grad norm: 18.55199243424849\n",
      "Epoch 228, Loss: 222.32835583585785, Neurons: 201, Grad norm: 18.55199243424849\n",
      "Epoch 229, Loss: 222.25437143103954, Neurons: 201, Grad norm: 18.342824176711627\n",
      "Epoch 229, Loss: 222.25437143103954, Neurons: 201, Grad norm: 18.342824176711627\n",
      "Epoch 230, Loss: 222.18182304922783, Neurons: 201, Grad norm: 18.13243698346314\n",
      "Epoch 230, Loss: 222.18182304922783, Neurons: 201, Grad norm: 18.13243698346314\n",
      "Epoch 231, Loss: 222.1107345892107, Neurons: 201, Grad norm: 17.925413572138154\n",
      "Epoch 231, Loss: 222.1107345892107, Neurons: 201, Grad norm: 17.925413572138154\n",
      "Epoch 232, Loss: 222.04107882274457, Neurons: 201, Grad norm: 17.714243333259997\n",
      "Epoch 232, Loss: 222.04107882274457, Neurons: 201, Grad norm: 17.714243333259997\n",
      "Epoch 233, Loss: 221.97285458637344, Neurons: 201, Grad norm: 17.509067398418672\n",
      "Epoch 233, Loss: 221.97285458637344, Neurons: 201, Grad norm: 17.509067398418672\n",
      "Epoch 234, Loss: 221.90604855332452, Neurons: 201, Grad norm: 17.308838091137126\n",
      "Epoch 234, Loss: 221.90604855332452, Neurons: 201, Grad norm: 17.308838091137126\n",
      "Epoch 235, Loss: 221.8406055293757, Neurons: 201, Grad norm: 17.121714257829876\n",
      "Epoch 235, Loss: 221.8406055293757, Neurons: 201, Grad norm: 17.121714257829876\n",
      "Epoch 236, Loss: 221.77642566899308, Neurons: 201, Grad norm: 16.932135560758006\n",
      "Epoch 236, Loss: 221.77642566899308, Neurons: 201, Grad norm: 16.932135560758006\n",
      "Epoch 237, Loss: 221.71348318589858, Neurons: 201, Grad norm: 16.744089517875107\n",
      "Epoch 237, Loss: 221.71348318589858, Neurons: 201, Grad norm: 16.744089517875107\n",
      "Epoch 238, Loss: 221.65173757090858, Neurons: 201, Grad norm: 16.55237825189368\n",
      "Epoch 238, Loss: 221.65173757090858, Neurons: 201, Grad norm: 16.55237825189368\n",
      "Epoch 239, Loss: 221.59121176916855, Neurons: 201, Grad norm: 16.356248743107674\n",
      "Epoch 239, Loss: 221.59121176916855, Neurons: 201, Grad norm: 16.356248743107674\n",
      "Epoch 240, Loss: 221.531930896578, Neurons: 201, Grad norm: 16.16705153683527\n",
      "Epoch 240, Loss: 221.531930896578, Neurons: 201, Grad norm: 16.16705153683527\n",
      "Epoch 241, Loss: 221.4739063293908, Neurons: 201, Grad norm: 15.982239313443891\n",
      "Epoch 241, Loss: 221.4739063293908, Neurons: 201, Grad norm: 15.982239313443891\n",
      "Epoch 242, Loss: 221.41704608783544, Neurons: 201, Grad norm: 15.797856856218141\n",
      "Epoch 242, Loss: 221.41704608783544, Neurons: 201, Grad norm: 15.797856856218141\n",
      "Epoch 243, Loss: 221.3613625895129, Neurons: 201, Grad norm: 15.603281978305883\n",
      "Epoch 243, Loss: 221.3613625895129, Neurons: 201, Grad norm: 15.603281978305883\n",
      "Epoch 244, Loss: 221.3069036603997, Neurons: 201, Grad norm: 15.422035479078092\n",
      "Epoch 244, Loss: 221.3069036603997, Neurons: 201, Grad norm: 15.422035479078092\n",
      "Epoch 245, Loss: 221.2535513570086, Neurons: 201, Grad norm: 15.253213447140297\n",
      "Epoch 245, Loss: 221.2535513570086, Neurons: 201, Grad norm: 15.253213447140297\n",
      "Epoch 246, Loss: 221.2012814000436, Neurons: 201, Grad norm: 15.075635886379587\n",
      "Epoch 246, Loss: 221.2012814000436, Neurons: 201, Grad norm: 15.075635886379587\n",
      "Epoch 247, Loss: 221.15003840020387, Neurons: 201, Grad norm: 14.890136366575323\n",
      "Epoch 247, Loss: 221.15003840020387, Neurons: 201, Grad norm: 14.890136366575323\n",
      "Epoch 248, Loss: 221.0999061067759, Neurons: 201, Grad norm: 14.714734215226986\n",
      "Epoch 248, Loss: 221.0999061067759, Neurons: 201, Grad norm: 14.714734215226986\n",
      "Epoch 249, Loss: 221.05088339318567, Neurons: 201, Grad norm: 14.531062777070886\n",
      "Epoch 249, Loss: 221.05088339318567, Neurons: 201, Grad norm: 14.531062777070886\n",
      "Epoch 250, Loss: 221.002913122978, Neurons: 201, Grad norm: 14.370497878834643\n",
      "Epoch 250, Loss: 221.002913122978, Neurons: 201, Grad norm: 14.370497878834643\n",
      "Epoch 251, Loss: 220.95594741880777, Neurons: 201, Grad norm: 14.209123093904214\n",
      "Epoch 251, Loss: 220.95594741880777, Neurons: 201, Grad norm: 14.209123093904214\n",
      "Epoch 252, Loss: 220.90990415778535, Neurons: 201, Grad norm: 14.032111724507525\n",
      "Epoch 252, Loss: 220.90990415778535, Neurons: 201, Grad norm: 14.032111724507525\n",
      "Epoch 253, Loss: 220.86479622181596, Neurons: 201, Grad norm: 13.86731044454722\n",
      "Epoch 253, Loss: 220.86479622181596, Neurons: 201, Grad norm: 13.86731044454722\n",
      "Epoch 254, Loss: 220.82066353550354, Neurons: 201, Grad norm: 13.709702038735216\n",
      "Epoch 254, Loss: 220.82066353550354, Neurons: 201, Grad norm: 13.709702038735216\n",
      "Epoch 255, Loss: 220.77736576709447, Neurons: 201, Grad norm: 13.551099402318693\n",
      "Epoch 255, Loss: 220.77736576709447, Neurons: 201, Grad norm: 13.551099402318693\n",
      "Epoch 256, Loss: 220.73491124795464, Neurons: 201, Grad norm: 13.374564291433272\n",
      "Epoch 256, Loss: 220.73491124795464, Neurons: 201, Grad norm: 13.374564291433272\n",
      "Epoch 257, Loss: 220.6933381171325, Neurons: 201, Grad norm: 13.217063175454669\n",
      "Epoch 257, Loss: 220.6933381171325, Neurons: 201, Grad norm: 13.217063175454669\n",
      "Epoch 258, Loss: 220.6526737481871, Neurons: 201, Grad norm: 13.052690998584584\n",
      "Epoch 258, Loss: 220.6526737481871, Neurons: 201, Grad norm: 13.052690998584584\n",
      "Epoch 259, Loss: 220.612880900945, Neurons: 201, Grad norm: 12.897358008028796\n",
      "Epoch 259, Loss: 220.612880900945, Neurons: 201, Grad norm: 12.897358008028796\n",
      "Epoch 260, Loss: 220.5738984258589, Neurons: 201, Grad norm: 12.733556082342567\n",
      "Epoch 260, Loss: 220.5738984258589, Neurons: 201, Grad norm: 12.733556082342567\n",
      "Epoch 261, Loss: 220.53571348897438, Neurons: 201, Grad norm: 12.575626538585848\n",
      "Epoch 261, Loss: 220.53571348897438, Neurons: 201, Grad norm: 12.575626538585848\n",
      "Epoch 262, Loss: 220.49831526757424, Neurons: 201, Grad norm: 12.41898038541501\n",
      "Epoch 262, Loss: 220.49831526757424, Neurons: 201, Grad norm: 12.41898038541501\n",
      "Epoch 263, Loss: 220.46169686663683, Neurons: 201, Grad norm: 12.272765886611522\n",
      "Epoch 263, Loss: 220.46169686663683, Neurons: 201, Grad norm: 12.272765886611522\n",
      "Epoch 264, Loss: 220.42578496233517, Neurons: 201, Grad norm: 12.121587260644283\n",
      "Epoch 264, Loss: 220.42578496233517, Neurons: 201, Grad norm: 12.121587260644283\n",
      "Epoch 265, Loss: 220.39060112705704, Neurons: 201, Grad norm: 11.977459814716676\n",
      "Epoch 265, Loss: 220.39060112705704, Neurons: 201, Grad norm: 11.977459814716676\n",
      "Epoch 266, Loss: 220.35613290377975, Neurons: 201, Grad norm: 11.845294978394003\n",
      "Epoch 266, Loss: 220.35613290377975, Neurons: 201, Grad norm: 11.845294978394003\n",
      "Epoch 267, Loss: 220.32234793479532, Neurons: 201, Grad norm: 11.713579169581799\n",
      "Epoch 267, Loss: 220.32234793479532, Neurons: 201, Grad norm: 11.713579169581799\n",
      "Epoch 268, Loss: 220.2891856294452, Neurons: 201, Grad norm: 11.574345343714889\n",
      "Epoch 268, Loss: 220.2891856294452, Neurons: 201, Grad norm: 11.574345343714889\n",
      "Epoch 269, Loss: 220.25666013851637, Neurons: 201, Grad norm: 11.441245868397534\n",
      "Epoch 269, Loss: 220.25666013851637, Neurons: 201, Grad norm: 11.441245868397534\n",
      "Epoch 270, Loss: 220.224759579226, Neurons: 201, Grad norm: 11.309948380449423\n",
      "Epoch 270, Loss: 220.224759579226, Neurons: 201, Grad norm: 11.309948380449423\n",
      "Epoch 271, Loss: 220.19347655799874, Neurons: 201, Grad norm: 11.16811858224365\n",
      "Epoch 271, Loss: 220.19347655799874, Neurons: 201, Grad norm: 11.16811858224365\n",
      "Epoch 272, Loss: 220.16280489866088, Neurons: 201, Grad norm: 11.02736302711058\n",
      "Epoch 272, Loss: 220.16280489866088, Neurons: 201, Grad norm: 11.02736302711058\n",
      "Epoch 273, Loss: 220.13278182282568, Neurons: 201, Grad norm: 10.912772785682513\n",
      "Epoch 273, Loss: 220.13278182282568, Neurons: 201, Grad norm: 10.912772785682513\n",
      "Epoch 274, Loss: 220.1032994534764, Neurons: 201, Grad norm: 10.78715029557474\n",
      "Epoch 274, Loss: 220.1032994534764, Neurons: 201, Grad norm: 10.78715029557474\n",
      "Epoch 275, Loss: 220.0743241380629, Neurons: 201, Grad norm: 10.660208251975806\n",
      "Epoch 275, Loss: 220.0743241380629, Neurons: 201, Grad norm: 10.660208251975806\n",
      "Epoch 276, Loss: 220.04587933442758, Neurons: 201, Grad norm: 10.539950770251988\n",
      "Epoch 276, Loss: 220.04587933442758, Neurons: 201, Grad norm: 10.539950770251988\n",
      "Epoch 277, Loss: 220.01793020324632, Neurons: 201, Grad norm: 10.403777443003168\n",
      "Epoch 277, Loss: 220.01793020324632, Neurons: 201, Grad norm: 10.403777443003168\n",
      "Epoch 278, Loss: 219.99054273094384, Neurons: 201, Grad norm: 10.298035855138988\n",
      "Epoch 278, Loss: 219.99054273094384, Neurons: 201, Grad norm: 10.298035855138988\n",
      "Epoch 279, Loss: 219.96360685164467, Neurons: 201, Grad norm: 10.181837732666649\n",
      "Epoch 279, Loss: 219.96360685164467, Neurons: 201, Grad norm: 10.181837732666649\n",
      "Epoch 280, Loss: 219.9371210815419, Neurons: 201, Grad norm: 10.078945730602157\n",
      "Epoch 280, Loss: 219.9371210815419, Neurons: 201, Grad norm: 10.078945730602157\n",
      "Epoch 281, Loss: 219.91102927472494, Neurons: 201, Grad norm: 9.954753236532616\n",
      "Epoch 281, Loss: 219.91102927472494, Neurons: 201, Grad norm: 9.954753236532616\n",
      "Epoch 282, Loss: 219.88533964264332, Neurons: 201, Grad norm: 9.836086071608245\n",
      "Epoch 282, Loss: 219.88533964264332, Neurons: 201, Grad norm: 9.836086071608245\n",
      "Epoch 283, Loss: 219.86012686091186, Neurons: 201, Grad norm: 9.728395860022433\n",
      "Epoch 283, Loss: 219.86012686091186, Neurons: 201, Grad norm: 9.728395860022433\n",
      "Epoch 284, Loss: 219.83536040950227, Neurons: 201, Grad norm: 9.621235287300857\n",
      "Epoch 284, Loss: 219.83536040950227, Neurons: 201, Grad norm: 9.621235287300857\n",
      "Epoch 285, Loss: 219.81096826309962, Neurons: 201, Grad norm: 9.502851573422095\n",
      "Epoch 285, Loss: 219.81096826309962, Neurons: 201, Grad norm: 9.502851573422095\n",
      "Epoch 286, Loss: 219.78701383738658, Neurons: 201, Grad norm: 9.394174554888698\n",
      "Epoch 286, Loss: 219.78701383738658, Neurons: 201, Grad norm: 9.394174554888698\n",
      "Epoch 287, Loss: 219.7634391945692, Neurons: 201, Grad norm: 9.29072734999526\n",
      "Epoch 287, Loss: 219.7634391945692, Neurons: 201, Grad norm: 9.29072734999526\n",
      "Epoch 288, Loss: 219.74027777971864, Neurons: 201, Grad norm: 9.199259860993168\n",
      "Epoch 288, Loss: 219.74027777971864, Neurons: 201, Grad norm: 9.199259860993168\n",
      "Epoch 289, Loss: 219.71744596380265, Neurons: 201, Grad norm: 9.109707399281328\n",
      "Epoch 289, Loss: 219.71744596380265, Neurons: 201, Grad norm: 9.109707399281328\n",
      "Epoch 290, Loss: 219.6949120024342, Neurons: 201, Grad norm: 9.023266580751814\n",
      "Epoch 290, Loss: 219.6949120024342, Neurons: 201, Grad norm: 9.023266580751814\n",
      "Epoch 291, Loss: 219.67266188119325, Neurons: 201, Grad norm: 8.933567141164643\n",
      "Epoch 291, Loss: 219.67266188119325, Neurons: 201, Grad norm: 8.933567141164643\n",
      "Epoch 292, Loss: 219.65071301551376, Neurons: 201, Grad norm: 8.8462423883056\n",
      "Epoch 292, Loss: 219.65071301551376, Neurons: 201, Grad norm: 8.8462423883056\n",
      "Epoch 293, Loss: 219.6290716417815, Neurons: 201, Grad norm: 8.755851602212546\n",
      "Epoch 293, Loss: 219.6290716417815, Neurons: 201, Grad norm: 8.755851602212546\n",
      "Epoch 294, Loss: 219.60771812368404, Neurons: 201, Grad norm: 8.665274704708706\n",
      "Epoch 294, Loss: 219.60771812368404, Neurons: 201, Grad norm: 8.665274704708706\n",
      "Epoch 295, Loss: 219.58665199934137, Neurons: 201, Grad norm: 8.58079313977661\n",
      "Epoch 295, Loss: 219.58665199934137, Neurons: 201, Grad norm: 8.58079313977661\n",
      "Epoch 296, Loss: 219.56584072720352, Neurons: 201, Grad norm: 8.509613441810387\n",
      "Epoch 296, Loss: 219.56584072720352, Neurons: 201, Grad norm: 8.509613441810387\n",
      "Epoch 297, Loss: 219.5452650088687, Neurons: 201, Grad norm: 8.423121190323556\n",
      "Epoch 297, Loss: 219.5452650088687, Neurons: 201, Grad norm: 8.423121190323556\n",
      "Epoch 298, Loss: 219.5248979427346, Neurons: 201, Grad norm: 8.344126192241077\n",
      "Epoch 298, Loss: 219.5248979427346, Neurons: 201, Grad norm: 8.344126192241077\n",
      "Epoch 299, Loss: 219.50473342988565, Neurons: 201, Grad norm: 8.28306246656313\n",
      "Epoch 299, Loss: 219.50473342988565, Neurons: 201, Grad norm: 8.28306246656313\n",
      "Epoch 300, Loss: 219.4847451636091, Neurons: 201, Grad norm: 8.20737664008953\n",
      "Epoch 300, Loss: 219.4847451636091, Neurons: 201, Grad norm: 8.20737664008953\n",
      "Epoch 301, Loss: 219.46493948762316, Neurons: 201, Grad norm: 8.136773019041591\n",
      "Epoch 301, Loss: 219.46493948762316, Neurons: 201, Grad norm: 8.136773019041591\n",
      "Epoch 302, Loss: 219.4453485946232, Neurons: 201, Grad norm: 8.060840704332922\n",
      "Epoch 302, Loss: 219.4453485946232, Neurons: 201, Grad norm: 8.060840704332922\n",
      "Epoch 303, Loss: 219.4259651234747, Neurons: 201, Grad norm: 7.997183332041586\n",
      "Epoch 303, Loss: 219.4259651234747, Neurons: 201, Grad norm: 7.997183332041586\n",
      "Epoch 304, Loss: 219.4067896919987, Neurons: 201, Grad norm: 7.931989794769743\n",
      "Epoch 304, Loss: 219.4067896919987, Neurons: 201, Grad norm: 7.931989794769743\n",
      "Epoch 305, Loss: 219.3877591903205, Neurons: 201, Grad norm: 7.875136003756885\n",
      "Epoch 305, Loss: 219.3877591903205, Neurons: 201, Grad norm: 7.875136003756885\n",
      "Epoch 306, Loss: 219.3689054920018, Neurons: 201, Grad norm: 7.821341921662424\n",
      "Epoch 306, Loss: 219.3689054920018, Neurons: 201, Grad norm: 7.821341921662424\n",
      "Epoch 307, Loss: 219.35017857703323, Neurons: 201, Grad norm: 7.775199397256225\n",
      "Epoch 307, Loss: 219.35017857703323, Neurons: 201, Grad norm: 7.775199397256225\n",
      "Epoch 308, Loss: 219.3315596199379, Neurons: 201, Grad norm: 7.728066867531154\n",
      "Epoch 308, Loss: 219.3315596199379, Neurons: 201, Grad norm: 7.728066867531154\n",
      "Epoch 309, Loss: 219.3130239979654, Neurons: 201, Grad norm: 7.680524330867736\n",
      "Epoch 309, Loss: 219.3130239979654, Neurons: 201, Grad norm: 7.680524330867736\n",
      "Epoch 310, Loss: 219.29460755925638, Neurons: 201, Grad norm: 7.632862239627125\n",
      "Epoch 310, Loss: 219.29460755925638, Neurons: 201, Grad norm: 7.632862239627125\n",
      "Epoch 311, Loss: 219.2763138709401, Neurons: 201, Grad norm: 7.583184513423446\n",
      "Epoch 311, Loss: 219.2763138709401, Neurons: 201, Grad norm: 7.583184513423446\n",
      "Epoch 312, Loss: 219.2581158581472, Neurons: 201, Grad norm: 7.533517700790764\n",
      "Epoch 312, Loss: 219.2581158581472, Neurons: 201, Grad norm: 7.533517700790764\n",
      "Epoch 313, Loss: 219.24006072999592, Neurons: 201, Grad norm: 7.49135800507703\n",
      "Epoch 313, Loss: 219.24006072999592, Neurons: 201, Grad norm: 7.49135800507703\n",
      "Epoch 314, Loss: 219.22212690710631, Neurons: 201, Grad norm: 7.451296033931803\n",
      "Epoch 314, Loss: 219.22212690710631, Neurons: 201, Grad norm: 7.451296033931803\n",
      "Epoch 315, Loss: 219.2042662279178, Neurons: 201, Grad norm: 7.408091393295832\n",
      "Epoch 315, Loss: 219.2042662279178, Neurons: 201, Grad norm: 7.408091393295832\n",
      "Epoch 316, Loss: 219.186516724957, Neurons: 201, Grad norm: 7.360644919117544\n",
      "Epoch 316, Loss: 219.186516724957, Neurons: 201, Grad norm: 7.360644919117544\n",
      "Epoch 317, Loss: 219.16888364771359, Neurons: 201, Grad norm: 7.317308902148061\n",
      "Epoch 317, Loss: 219.16888364771359, Neurons: 201, Grad norm: 7.317308902148061\n",
      "Epoch 318, Loss: 219.15136426133358, Neurons: 201, Grad norm: 7.2819769226396\n",
      "Epoch 318, Loss: 219.15136426133358, Neurons: 201, Grad norm: 7.2819769226396\n",
      "Epoch 319, Loss: 219.13394861036153, Neurons: 201, Grad norm: 7.240069205523472\n",
      "Epoch 319, Loss: 219.13394861036153, Neurons: 201, Grad norm: 7.240069205523472\n",
      "Epoch 320, Loss: 219.1165842722323, Neurons: 201, Grad norm: 7.200726354255366\n",
      "Epoch 320, Loss: 219.1165842722323, Neurons: 201, Grad norm: 7.200726354255366\n",
      "Epoch 321, Loss: 219.09929437973045, Neurons: 201, Grad norm: 7.166419611291108\n",
      "Epoch 321, Loss: 219.09929437973045, Neurons: 201, Grad norm: 7.166419611291108\n",
      "Epoch 322, Loss: 219.082049326576, Neurons: 201, Grad norm: 7.128513707927323\n",
      "Epoch 322, Loss: 219.082049326576, Neurons: 201, Grad norm: 7.128513707927323\n",
      "Epoch 323, Loss: 219.0648615526304, Neurons: 201, Grad norm: 7.09391832760552\n",
      "Epoch 323, Loss: 219.0648615526304, Neurons: 201, Grad norm: 7.09391832760552\n",
      "Epoch 324, Loss: 219.04774322218026, Neurons: 201, Grad norm: 7.060617775455218\n",
      "Epoch 324, Loss: 219.04774322218026, Neurons: 201, Grad norm: 7.060617775455218\n",
      "Epoch 325, Loss: 219.03064724669994, Neurons: 201, Grad norm: 7.020352464894563\n",
      "Epoch 325, Loss: 219.03064724669994, Neurons: 201, Grad norm: 7.020352464894563\n",
      "Epoch 326, Loss: 219.01361386436574, Neurons: 201, Grad norm: 6.989200139521001\n",
      "Epoch 326, Loss: 219.01361386436574, Neurons: 201, Grad norm: 6.989200139521001\n",
      "Epoch 327, Loss: 218.99667944116982, Neurons: 201, Grad norm: 6.95455901621748\n",
      "Epoch 327, Loss: 218.99667944116982, Neurons: 201, Grad norm: 6.95455901621748\n",
      "Epoch 328, Loss: 218.9797920692557, Neurons: 201, Grad norm: 6.92262291914048\n",
      "Epoch 328, Loss: 218.9797920692557, Neurons: 201, Grad norm: 6.92262291914048\n",
      "Epoch 329, Loss: 218.96299126482916, Neurons: 201, Grad norm: 6.900794074880004\n",
      "Epoch 329, Loss: 218.96299126482916, Neurons: 201, Grad norm: 6.900794074880004\n",
      "Epoch 330, Loss: 218.94620369013933, Neurons: 201, Grad norm: 6.858862697976119\n",
      "Epoch 330, Loss: 218.94620369013933, Neurons: 201, Grad norm: 6.858862697976119\n",
      "Epoch 331, Loss: 218.92945559808976, Neurons: 201, Grad norm: 6.82536433806392\n",
      "Epoch 331, Loss: 218.92945559808976, Neurons: 201, Grad norm: 6.82536433806392\n",
      "Epoch 332, Loss: 218.912758241311, Neurons: 201, Grad norm: 6.801918855229365\n",
      "Epoch 332, Loss: 218.912758241311, Neurons: 201, Grad norm: 6.801918855229365\n",
      "Epoch 333, Loss: 218.89610272553185, Neurons: 201, Grad norm: 6.776786284576918\n",
      "Epoch 333, Loss: 218.89610272553185, Neurons: 201, Grad norm: 6.776786284576918\n",
      "Epoch 334, Loss: 218.87947755494713, Neurons: 201, Grad norm: 6.746917936090492\n",
      "Epoch 334, Loss: 218.87947755494713, Neurons: 201, Grad norm: 6.746917936090492\n",
      "Epoch 335, Loss: 218.86289266459923, Neurons: 201, Grad norm: 6.719899688897733\n",
      "Epoch 335, Loss: 218.86289266459923, Neurons: 201, Grad norm: 6.719899688897733\n",
      "Epoch 336, Loss: 218.84636366159538, Neurons: 201, Grad norm: 6.691137410139324\n",
      "Epoch 336, Loss: 218.84636366159538, Neurons: 201, Grad norm: 6.691137410139324\n",
      "Epoch 337, Loss: 218.82986271025322, Neurons: 201, Grad norm: 6.668991750003343\n",
      "Epoch 337, Loss: 218.82986271025322, Neurons: 201, Grad norm: 6.668991750003343\n",
      "Epoch 338, Loss: 218.81339645118194, Neurons: 201, Grad norm: 6.646142797056963\n",
      "Epoch 338, Loss: 218.81339645118194, Neurons: 201, Grad norm: 6.646142797056963\n",
      "Epoch 339, Loss: 218.79697659300996, Neurons: 201, Grad norm: 6.615990471770757\n",
      "Epoch 339, Loss: 218.79697659300996, Neurons: 201, Grad norm: 6.615990471770757\n",
      "Epoch 340, Loss: 218.7805928405746, Neurons: 201, Grad norm: 6.588844735364747\n",
      "Epoch 340, Loss: 218.7805928405746, Neurons: 201, Grad norm: 6.588844735364747\n",
      "Epoch 341, Loss: 218.76425891346773, Neurons: 201, Grad norm: 6.567295246591189\n",
      "Epoch 341, Loss: 218.76425891346773, Neurons: 201, Grad norm: 6.567295246591189\n",
      "Epoch 342, Loss: 218.74796488814823, Neurons: 201, Grad norm: 6.543704847788706\n",
      "Epoch 342, Loss: 218.74796488814823, Neurons: 201, Grad norm: 6.543704847788706\n",
      "Epoch 343, Loss: 218.73171968505497, Neurons: 201, Grad norm: 6.521169902126558\n",
      "Epoch 343, Loss: 218.73171968505497, Neurons: 201, Grad norm: 6.521169902126558\n",
      "Epoch 344, Loss: 218.71548200185265, Neurons: 201, Grad norm: 6.492202986570492\n",
      "Epoch 344, Loss: 218.71548200185265, Neurons: 201, Grad norm: 6.492202986570492\n",
      "Epoch 345, Loss: 218.69929537987088, Neurons: 201, Grad norm: 6.474319954019652\n",
      "Epoch 345, Loss: 218.69929537987088, Neurons: 201, Grad norm: 6.474319954019652\n",
      "Epoch 346, Loss: 218.68319839704284, Neurons: 201, Grad norm: 6.4500122157610775\n",
      "Epoch 346, Loss: 218.68319839704284, Neurons: 201, Grad norm: 6.4500122157610775\n",
      "Epoch 347, Loss: 218.66712688575925, Neurons: 201, Grad norm: 6.421169596149698\n",
      "Epoch 347, Loss: 218.66712688575925, Neurons: 201, Grad norm: 6.421169596149698\n",
      "Epoch 348, Loss: 218.65111790408815, Neurons: 201, Grad norm: 6.394625928155445\n",
      "Epoch 348, Loss: 218.65111790408815, Neurons: 201, Grad norm: 6.394625928155445\n",
      "Epoch 349, Loss: 218.63517502674782, Neurons: 201, Grad norm: 6.372571151468341\n",
      "Epoch 349, Loss: 218.63517502674782, Neurons: 201, Grad norm: 6.372571151468341\n",
      "Epoch 350, Loss: 218.6193268854352, Neurons: 201, Grad norm: 6.355807194598216\n",
      "Epoch 350, Loss: 218.6193268854352, Neurons: 201, Grad norm: 6.355807194598216\n",
      "Epoch 351, Loss: 218.6034878923536, Neurons: 201, Grad norm: 6.338126237115362\n",
      "Epoch 351, Loss: 218.6034878923536, Neurons: 201, Grad norm: 6.338126237115362\n",
      "Epoch 352, Loss: 218.5876859444355, Neurons: 201, Grad norm: 6.32737619440285\n",
      "Epoch 352, Loss: 218.5876859444355, Neurons: 201, Grad norm: 6.32737619440285\n",
      "Epoch 353, Loss: 218.57191622884724, Neurons: 201, Grad norm: 6.304783154106738\n",
      "Epoch 353, Loss: 218.57191622884724, Neurons: 201, Grad norm: 6.304783154106738\n",
      "Epoch 354, Loss: 218.55618292564182, Neurons: 201, Grad norm: 6.299082477379175\n",
      "Epoch 354, Loss: 218.55618292564182, Neurons: 201, Grad norm: 6.299082477379175\n",
      "Epoch 355, Loss: 218.5404628063382, Neurons: 201, Grad norm: 6.286617144957804\n",
      "Epoch 355, Loss: 218.5404628063382, Neurons: 201, Grad norm: 6.286617144957804\n",
      "Epoch 356, Loss: 218.52473779163438, Neurons: 201, Grad norm: 6.267589435061481\n",
      "Epoch 356, Loss: 218.52473779163438, Neurons: 201, Grad norm: 6.267589435061481\n",
      "Epoch 357, Loss: 218.50904196520105, Neurons: 201, Grad norm: 6.24747449565321\n",
      "Epoch 357, Loss: 218.50904196520105, Neurons: 201, Grad norm: 6.24747449565321\n",
      "Epoch 358, Loss: 218.4934127546486, Neurons: 201, Grad norm: 6.223907962717161\n",
      "Epoch 358, Loss: 218.4934127546486, Neurons: 201, Grad norm: 6.223907962717161\n",
      "Epoch 359, Loss: 218.4778648105961, Neurons: 201, Grad norm: 6.218485850346154\n",
      "Epoch 359, Loss: 218.4778648105961, Neurons: 201, Grad norm: 6.218485850346154\n",
      "Epoch 360, Loss: 218.46234404720136, Neurons: 201, Grad norm: 6.193826490306565\n",
      "Epoch 360, Loss: 218.46234404720136, Neurons: 201, Grad norm: 6.193826490306565\n",
      "Epoch 361, Loss: 218.44689464608888, Neurons: 201, Grad norm: 6.186692285381013\n",
      "Epoch 361, Loss: 218.44689464608888, Neurons: 201, Grad norm: 6.186692285381013\n",
      "Epoch 362, Loss: 218.43151797850243, Neurons: 201, Grad norm: 6.171621757189568\n",
      "Epoch 362, Loss: 218.43151797850243, Neurons: 201, Grad norm: 6.171621757189568\n",
      "Epoch 363, Loss: 218.41616716473996, Neurons: 201, Grad norm: 6.158371913701586\n",
      "Epoch 363, Loss: 218.41616716473996, Neurons: 201, Grad norm: 6.158371913701586\n",
      "Epoch 364, Loss: 218.40086684504234, Neurons: 201, Grad norm: 6.1498033638747795\n",
      "Epoch 364, Loss: 218.40086684504234, Neurons: 201, Grad norm: 6.1498033638747795\n",
      "Epoch 365, Loss: 218.38562196355645, Neurons: 201, Grad norm: 6.133454121875878\n",
      "Epoch 365, Loss: 218.38562196355645, Neurons: 201, Grad norm: 6.133454121875878\n",
      "Epoch 366, Loss: 218.37040355085782, Neurons: 201, Grad norm: 6.115110292422912\n",
      "Epoch 366, Loss: 218.37040355085782, Neurons: 201, Grad norm: 6.115110292422912\n",
      "Epoch 367, Loss: 218.3552642906654, Neurons: 201, Grad norm: 6.107072842010143\n",
      "Epoch 367, Loss: 218.3552642906654, Neurons: 201, Grad norm: 6.107072842010143\n",
      "Epoch 368, Loss: 218.34016945821014, Neurons: 201, Grad norm: 6.0980109313837065\n",
      "Epoch 368, Loss: 218.34016945821014, Neurons: 201, Grad norm: 6.0980109313837065\n",
      "Epoch 369, Loss: 218.3251243188136, Neurons: 201, Grad norm: 6.086757049112873\n",
      "Epoch 369, Loss: 218.3251243188136, Neurons: 201, Grad norm: 6.086757049112873\n",
      "Epoch 370, Loss: 218.31014082440763, Neurons: 201, Grad norm: 6.0830417485779895\n",
      "Epoch 370, Loss: 218.31014082440763, Neurons: 201, Grad norm: 6.0830417485779895\n",
      "Epoch 371, Loss: 218.29517182170463, Neurons: 201, Grad norm: 6.076177595992932\n",
      "Epoch 371, Loss: 218.29517182170463, Neurons: 201, Grad norm: 6.076177595992932\n",
      "Epoch 372, Loss: 218.28023685902377, Neurons: 201, Grad norm: 6.060962198006275\n",
      "Epoch 372, Loss: 218.28023685902377, Neurons: 201, Grad norm: 6.060962198006275\n",
      "Epoch 373, Loss: 218.26536581989487, Neurons: 201, Grad norm: 6.049219855837135\n",
      "Epoch 373, Loss: 218.26536581989487, Neurons: 201, Grad norm: 6.049219855837135\n",
      "Epoch 374, Loss: 218.25057131788978, Neurons: 201, Grad norm: 6.036879628692275\n",
      "Epoch 374, Loss: 218.25057131788978, Neurons: 201, Grad norm: 6.036879628692275\n",
      "Epoch 375, Loss: 218.23587190212746, Neurons: 201, Grad norm: 6.032789443974623\n",
      "Epoch 375, Loss: 218.23587190212746, Neurons: 201, Grad norm: 6.032789443974623\n",
      "Epoch 376, Loss: 218.22119459687875, Neurons: 201, Grad norm: 6.023080322821608\n",
      "Epoch 376, Loss: 218.22119459687875, Neurons: 201, Grad norm: 6.023080322821608\n",
      "Epoch 377, Loss: 218.20658890085113, Neurons: 201, Grad norm: 6.0142593414141565\n",
      "Epoch 377, Loss: 218.20658890085113, Neurons: 201, Grad norm: 6.0142593414141565\n",
      "Epoch 378, Loss: 218.1920347508377, Neurons: 201, Grad norm: 6.012307995082583\n",
      "Epoch 378, Loss: 218.1920347508377, Neurons: 201, Grad norm: 6.012307995082583\n",
      "Epoch 379, Loss: 218.17754270294017, Neurons: 201, Grad norm: 6.004811757483022\n",
      "Epoch 379, Loss: 218.17754270294017, Neurons: 201, Grad norm: 6.004811757483022\n",
      "Epoch 380, Loss: 218.16309414956422, Neurons: 201, Grad norm: 6.004642715110152\n",
      "Epoch 380, Loss: 218.16309414956422, Neurons: 201, Grad norm: 6.004642715110152\n",
      "Epoch 381, Loss: 218.148690337516, Neurons: 201, Grad norm: 5.996205555855139\n",
      "Epoch 381, Loss: 218.148690337516, Neurons: 201, Grad norm: 5.996205555855139\n",
      "Epoch 382, Loss: 218.1343233956013, Neurons: 201, Grad norm: 5.988278926339912\n",
      "Epoch 382, Loss: 218.1343233956013, Neurons: 201, Grad norm: 5.988278926339912\n",
      "Epoch 383, Loss: 218.12002994240777, Neurons: 201, Grad norm: 5.976332794678913\n",
      "Epoch 383, Loss: 218.12002994240777, Neurons: 201, Grad norm: 5.976332794678913\n",
      "Epoch 384, Loss: 218.1058261263093, Neurons: 201, Grad norm: 5.977170755890011\n",
      "Epoch 384, Loss: 218.1058261263093, Neurons: 201, Grad norm: 5.977170755890011\n",
      "Epoch 385, Loss: 218.09167660638374, Neurons: 201, Grad norm: 5.97088843905774\n",
      "Epoch 385, Loss: 218.09167660638374, Neurons: 201, Grad norm: 5.97088843905774\n",
      "Epoch 386, Loss: 218.07756245460064, Neurons: 201, Grad norm: 5.955540424831193\n",
      "Epoch 386, Loss: 218.07756245460064, Neurons: 201, Grad norm: 5.955540424831193\n",
      "Epoch 387, Loss: 218.06351323086332, Neurons: 201, Grad norm: 5.936389580369338\n",
      "Epoch 387, Loss: 218.06351323086332, Neurons: 201, Grad norm: 5.936389580369338\n",
      "Epoch 388, Loss: 218.04958310698234, Neurons: 201, Grad norm: 5.936741618943186\n",
      "Epoch 388, Loss: 218.04958310698234, Neurons: 201, Grad norm: 5.936741618943186\n",
      "Epoch 389, Loss: 218.03572391572618, Neurons: 201, Grad norm: 5.9303342619585955\n",
      "Epoch 389, Loss: 218.03572391572618, Neurons: 201, Grad norm: 5.9303342619585955\n",
      "Epoch 390, Loss: 218.02189614658593, Neurons: 201, Grad norm: 5.919965725700244\n",
      "Epoch 390, Loss: 218.02189614658593, Neurons: 201, Grad norm: 5.919965725700244\n",
      "Epoch 391, Loss: 218.00813370575833, Neurons: 201, Grad norm: 5.91543784353524\n",
      "Epoch 391, Loss: 218.00813370575833, Neurons: 201, Grad norm: 5.91543784353524\n",
      "Epoch 392, Loss: 217.99441983810522, Neurons: 201, Grad norm: 5.907674192274937\n",
      "Epoch 392, Loss: 217.99441983810522, Neurons: 201, Grad norm: 5.907674192274937\n",
      "Epoch 393, Loss: 217.98075287785127, Neurons: 201, Grad norm: 5.898689350746024\n",
      "Epoch 393, Loss: 217.98075287785127, Neurons: 201, Grad norm: 5.898689350746024\n",
      "Epoch 394, Loss: 217.96715261291456, Neurons: 201, Grad norm: 5.896520399316635\n",
      "Epoch 394, Loss: 217.96715261291456, Neurons: 201, Grad norm: 5.896520399316635\n",
      "Epoch 395, Loss: 217.95361139955864, Neurons: 201, Grad norm: 5.888219794819161\n",
      "Epoch 395, Loss: 217.95361139955864, Neurons: 201, Grad norm: 5.888219794819161\n",
      "Epoch 396, Loss: 217.9400989082051, Neurons: 201, Grad norm: 5.877096735844782\n",
      "Epoch 396, Loss: 217.9400989082051, Neurons: 201, Grad norm: 5.877096735844782\n",
      "Epoch 397, Loss: 217.92664918511727, Neurons: 201, Grad norm: 5.863428961849314\n",
      "Epoch 397, Loss: 217.92664918511727, Neurons: 201, Grad norm: 5.863428961849314\n",
      "Epoch 398, Loss: 217.91330108694206, Neurons: 201, Grad norm: 5.852874204992157\n",
      "Epoch 398, Loss: 217.91330108694206, Neurons: 201, Grad norm: 5.852874204992157\n",
      "Epoch 399, Loss: 217.90002304750487, Neurons: 201, Grad norm: 5.847409846865666\n",
      "Epoch 399, Loss: 217.90002304750487, Neurons: 201, Grad norm: 5.847409846865666\n",
      "Epoch 400, Loss: 217.88681415750403, Neurons: 201, Grad norm: 5.832040476297158\n",
      "Epoch 400, Loss: 217.88681415750403, Neurons: 201, Grad norm: 5.832040476297158\n",
      "Epoch 401, Loss: 217.87371078942712, Neurons: 201, Grad norm: 5.823688100965437\n",
      "Epoch 401, Loss: 217.87371078942712, Neurons: 201, Grad norm: 5.823688100965437\n",
      "Epoch 402, Loss: 217.86068613550168, Neurons: 201, Grad norm: 5.811457243724673\n",
      "Epoch 402, Loss: 217.86068613550168, Neurons: 201, Grad norm: 5.811457243724673\n",
      "Epoch 403, Loss: 217.84775510209863, Neurons: 201, Grad norm: 5.801953339868405\n",
      "Epoch 403, Loss: 217.84775510209863, Neurons: 201, Grad norm: 5.801953339868405\n",
      "Epoch 404, Loss: 217.83488127111866, Neurons: 201, Grad norm: 5.797767890645385\n",
      "Epoch 404, Loss: 217.83488127111866, Neurons: 201, Grad norm: 5.797767890645385\n",
      "Epoch 405, Loss: 217.82206700962078, Neurons: 201, Grad norm: 5.7921592322708495\n",
      "Epoch 405, Loss: 217.82206700962078, Neurons: 201, Grad norm: 5.7921592322708495\n",
      "Epoch 406, Loss: 217.80929948124643, Neurons: 201, Grad norm: 5.782401364243329\n",
      "Epoch 406, Loss: 217.80929948124643, Neurons: 201, Grad norm: 5.782401364243329\n",
      "Epoch 407, Loss: 217.79660727688878, Neurons: 201, Grad norm: 5.775605885920713\n",
      "Epoch 407, Loss: 217.79660727688878, Neurons: 201, Grad norm: 5.775605885920713\n",
      "Epoch 408, Loss: 217.78398044047808, Neurons: 201, Grad norm: 5.775152876962498\n",
      "Epoch 408, Loss: 217.78398044047808, Neurons: 201, Grad norm: 5.775152876962498\n",
      "Epoch 409, Loss: 217.77139675715927, Neurons: 201, Grad norm: 5.768470837853858\n",
      "Epoch 409, Loss: 217.77139675715927, Neurons: 201, Grad norm: 5.768470837853858\n",
      "Epoch 410, Loss: 217.75888203317376, Neurons: 201, Grad norm: 5.766854200766294\n",
      "Epoch 410, Loss: 217.75888203317376, Neurons: 201, Grad norm: 5.766854200766294\n",
      "Epoch 411, Loss: 217.7463772455806, Neurons: 201, Grad norm: 5.760543151681618\n",
      "Epoch 411, Loss: 217.7463772455806, Neurons: 201, Grad norm: 5.760543151681618\n",
      "Epoch 412, Loss: 217.73389327876274, Neurons: 201, Grad norm: 5.756847677663235\n",
      "Epoch 412, Loss: 217.73389327876274, Neurons: 201, Grad norm: 5.756847677663235\n",
      "Epoch 413, Loss: 217.72147838225322, Neurons: 201, Grad norm: 5.744321943933291\n",
      "Epoch 413, Loss: 217.72147838225322, Neurons: 201, Grad norm: 5.744321943933291\n",
      "Epoch 414, Loss: 217.7090893659047, Neurons: 201, Grad norm: 5.733431964927976\n",
      "Epoch 414, Loss: 217.7090893659047, Neurons: 201, Grad norm: 5.733431964927976\n",
      "Epoch 415, Loss: 217.696767662536, Neurons: 201, Grad norm: 5.721307536423256\n",
      "Epoch 415, Loss: 217.696767662536, Neurons: 201, Grad norm: 5.721307536423256\n",
      "Epoch 416, Loss: 217.684528130011, Neurons: 201, Grad norm: 5.709089581560493\n",
      "Epoch 416, Loss: 217.684528130011, Neurons: 201, Grad norm: 5.709089581560493\n",
      "Epoch 417, Loss: 217.67239311604317, Neurons: 201, Grad norm: 5.69651000788608\n",
      "Epoch 417, Loss: 217.67239311604317, Neurons: 201, Grad norm: 5.69651000788608\n",
      "Epoch 418, Loss: 217.66033581767095, Neurons: 201, Grad norm: 5.687517401736971\n",
      "Epoch 418, Loss: 217.66033581767095, Neurons: 201, Grad norm: 5.687517401736971\n",
      "Epoch 419, Loss: 217.64834814012988, Neurons: 201, Grad norm: 5.682051354383308\n",
      "Epoch 419, Loss: 217.64834814012988, Neurons: 201, Grad norm: 5.682051354383308\n",
      "Epoch 420, Loss: 217.63641943050143, Neurons: 201, Grad norm: 5.672366915947084\n",
      "Epoch 420, Loss: 217.63641943050143, Neurons: 201, Grad norm: 5.672366915947084\n",
      "Epoch 421, Loss: 217.62453139791816, Neurons: 201, Grad norm: 5.66510758294178\n",
      "Epoch 421, Loss: 217.62453139791816, Neurons: 201, Grad norm: 5.66510758294178\n",
      "Epoch 422, Loss: 217.61269723076254, Neurons: 201, Grad norm: 5.658745584913135\n",
      "Epoch 422, Loss: 217.61269723076254, Neurons: 201, Grad norm: 5.658745584913135\n",
      "Epoch 423, Loss: 217.60090023260972, Neurons: 201, Grad norm: 5.653225491957857\n",
      "Epoch 423, Loss: 217.60090023260972, Neurons: 201, Grad norm: 5.653225491957857\n",
      "Epoch 424, Loss: 217.5891405115071, Neurons: 201, Grad norm: 5.640132588046836\n",
      "Epoch 424, Loss: 217.5891405115071, Neurons: 201, Grad norm: 5.640132588046836\n",
      "Epoch 425, Loss: 217.57742095248284, Neurons: 201, Grad norm: 5.632813014144287\n",
      "Epoch 425, Loss: 217.57742095248284, Neurons: 201, Grad norm: 5.632813014144287\n",
      "Epoch 426, Loss: 217.5657636667257, Neurons: 201, Grad norm: 5.619626702778141\n",
      "Epoch 426, Loss: 217.5657636667257, Neurons: 201, Grad norm: 5.619626702778141\n",
      "Epoch 427, Loss: 217.55415404403908, Neurons: 201, Grad norm: 5.607142471621145\n",
      "Epoch 427, Loss: 217.55415404403908, Neurons: 201, Grad norm: 5.607142471621145\n",
      "Epoch 428, Loss: 217.5425889335614, Neurons: 201, Grad norm: 5.602842711366746\n",
      "Epoch 428, Loss: 217.5425889335614, Neurons: 201, Grad norm: 5.602842711366746\n",
      "Epoch 429, Loss: 217.53105089960636, Neurons: 201, Grad norm: 5.5952628648849085\n",
      "Epoch 429, Loss: 217.53105089960636, Neurons: 201, Grad norm: 5.5952628648849085\n",
      "Epoch 430, Loss: 217.51953266526422, Neurons: 201, Grad norm: 5.588075642906516\n",
      "Epoch 430, Loss: 217.51953266526422, Neurons: 201, Grad norm: 5.588075642906516\n",
      "Epoch 431, Loss: 217.50808105078445, Neurons: 201, Grad norm: 5.573432123858493\n",
      "Epoch 431, Loss: 217.50808105078445, Neurons: 201, Grad norm: 5.573432123858493\n",
      "Epoch 432, Loss: 217.49668174283553, Neurons: 201, Grad norm: 5.56311374609119\n",
      "Epoch 432, Loss: 217.49668174283553, Neurons: 201, Grad norm: 5.56311374609119\n",
      "Epoch 433, Loss: 217.48535725788545, Neurons: 201, Grad norm: 5.55550240661464\n",
      "Epoch 433, Loss: 217.48535725788545, Neurons: 201, Grad norm: 5.55550240661464\n",
      "Epoch 434, Loss: 217.47409667263855, Neurons: 201, Grad norm: 5.551746365016715\n",
      "Epoch 434, Loss: 217.47409667263855, Neurons: 201, Grad norm: 5.551746365016715\n",
      "Epoch 435, Loss: 217.46284865699897, Neurons: 201, Grad norm: 5.541878725379547\n",
      "Epoch 435, Loss: 217.46284865699897, Neurons: 201, Grad norm: 5.541878725379547\n",
      "Epoch 436, Loss: 217.45166747611466, Neurons: 201, Grad norm: 5.533501191838035\n",
      "Epoch 436, Loss: 217.45166747611466, Neurons: 201, Grad norm: 5.533501191838035\n",
      "Epoch 437, Loss: 217.44053114742897, Neurons: 201, Grad norm: 5.52640439853655\n",
      "Epoch 437, Loss: 217.44053114742897, Neurons: 201, Grad norm: 5.52640439853655\n",
      "Epoch 438, Loss: 217.4294407739109, Neurons: 201, Grad norm: 5.516794379853597\n",
      "Epoch 438, Loss: 217.4294407739109, Neurons: 201, Grad norm: 5.516794379853597\n",
      "Epoch 439, Loss: 217.41838093789394, Neurons: 201, Grad norm: 5.507954011301062\n",
      "Epoch 439, Loss: 217.41838093789394, Neurons: 201, Grad norm: 5.507954011301062\n",
      "Epoch 440, Loss: 217.407356725683, Neurons: 201, Grad norm: 5.497335293787109\n",
      "Epoch 440, Loss: 217.407356725683, Neurons: 201, Grad norm: 5.497335293787109\n",
      "Epoch 441, Loss: 217.3963949416595, Neurons: 201, Grad norm: 5.485366040410871\n",
      "Epoch 441, Loss: 217.3963949416595, Neurons: 201, Grad norm: 5.485366040410871\n",
      "Epoch 442, Loss: 217.3854765050112, Neurons: 201, Grad norm: 5.4749018620262735\n",
      "Epoch 442, Loss: 217.3854765050112, Neurons: 201, Grad norm: 5.4749018620262735\n",
      "Epoch 443, Loss: 217.3746467046885, Neurons: 201, Grad norm: 5.47054280003388\n",
      "Epoch 443, Loss: 217.3746467046885, Neurons: 201, Grad norm: 5.47054280003388\n",
      "Epoch 444, Loss: 217.3638461172628, Neurons: 201, Grad norm: 5.462753689462093\n",
      "Epoch 444, Loss: 217.3638461172628, Neurons: 201, Grad norm: 5.462753689462093\n",
      "Epoch 445, Loss: 217.35306030723896, Neurons: 201, Grad norm: 5.454813054443713\n",
      "Epoch 445, Loss: 217.35306030723896, Neurons: 201, Grad norm: 5.454813054443713\n",
      "Epoch 446, Loss: 217.34230931609304, Neurons: 201, Grad norm: 5.451507266023442\n",
      "Epoch 446, Loss: 217.34230931609304, Neurons: 201, Grad norm: 5.451507266023442\n",
      "Epoch 447, Loss: 217.3315915399357, Neurons: 201, Grad norm: 5.442230754751064\n",
      "Epoch 447, Loss: 217.3315915399357, Neurons: 201, Grad norm: 5.442230754751064\n",
      "Epoch 448, Loss: 217.32090171759305, Neurons: 201, Grad norm: 5.430942957561413\n",
      "Epoch 448, Loss: 217.32090171759305, Neurons: 201, Grad norm: 5.430942957561413\n",
      "Epoch 449, Loss: 217.31026384716935, Neurons: 201, Grad norm: 5.422745003451586\n",
      "Epoch 449, Loss: 217.31026384716935, Neurons: 201, Grad norm: 5.422745003451586\n",
      "Epoch 450, Loss: 217.299669820583, Neurons: 201, Grad norm: 5.41443791730957\n",
      "Epoch 450, Loss: 217.299669820583, Neurons: 201, Grad norm: 5.41443791730957\n",
      "Epoch 451, Loss: 217.28910811477596, Neurons: 201, Grad norm: 5.402345277640435\n",
      "Epoch 451, Loss: 217.28910811477596, Neurons: 201, Grad norm: 5.402345277640435\n",
      "Epoch 452, Loss: 217.27859063860527, Neurons: 201, Grad norm: 5.394005987102697\n",
      "Epoch 452, Loss: 217.27859063860527, Neurons: 201, Grad norm: 5.394005987102697\n",
      "Epoch 453, Loss: 217.26811586048473, Neurons: 201, Grad norm: 5.384105670664473\n",
      "Epoch 453, Loss: 217.26811586048473, Neurons: 201, Grad norm: 5.384105670664473\n",
      "Epoch 454, Loss: 217.25767578822084, Neurons: 201, Grad norm: 5.375969443173181\n",
      "Epoch 454, Loss: 217.25767578822084, Neurons: 201, Grad norm: 5.375969443173181\n",
      "Epoch 455, Loss: 217.24725231023612, Neurons: 201, Grad norm: 5.36688546123704\n",
      "Epoch 455, Loss: 217.24725231023612, Neurons: 201, Grad norm: 5.36688546123704\n",
      "Epoch 456, Loss: 217.2368684399021, Neurons: 201, Grad norm: 5.356710431323167\n",
      "Epoch 456, Loss: 217.2368684399021, Neurons: 201, Grad norm: 5.356710431323167\n",
      "Epoch 457, Loss: 217.22652747127674, Neurons: 201, Grad norm: 5.345280695697685\n",
      "Epoch 457, Loss: 217.22652747127674, Neurons: 201, Grad norm: 5.345280695697685\n",
      "Epoch 458, Loss: 217.21624085856178, Neurons: 201, Grad norm: 5.336884116490341\n",
      "Epoch 458, Loss: 217.21624085856178, Neurons: 201, Grad norm: 5.336884116490341\n",
      "Epoch 459, Loss: 217.2059945865707, Neurons: 201, Grad norm: 5.328921972817929\n",
      "Epoch 459, Loss: 217.2059945865707, Neurons: 201, Grad norm: 5.328921972817929\n",
      "Epoch 460, Loss: 217.19578384375455, Neurons: 201, Grad norm: 5.325034336753765\n",
      "Epoch 460, Loss: 217.19578384375455, Neurons: 201, Grad norm: 5.325034336753765\n",
      "Epoch 461, Loss: 217.18559189312475, Neurons: 201, Grad norm: 5.322676372856585\n",
      "Epoch 461, Loss: 217.18559189312475, Neurons: 201, Grad norm: 5.322676372856585\n",
      "Epoch 462, Loss: 217.17543251215412, Neurons: 201, Grad norm: 5.314745761978047\n",
      "Epoch 462, Loss: 217.17543251215412, Neurons: 201, Grad norm: 5.314745761978047\n",
      "Epoch 463, Loss: 217.16529439069885, Neurons: 201, Grad norm: 5.306890445940221\n",
      "Epoch 463, Loss: 217.16529439069885, Neurons: 201, Grad norm: 5.306890445940221\n",
      "Epoch 464, Loss: 217.15519184579838, Neurons: 201, Grad norm: 5.302637828420774\n",
      "Epoch 464, Loss: 217.15519184579838, Neurons: 201, Grad norm: 5.302637828420774\n",
      "Epoch 465, Loss: 217.14511733104996, Neurons: 201, Grad norm: 5.302206382348281\n",
      "Epoch 465, Loss: 217.14511733104996, Neurons: 201, Grad norm: 5.302206382348281\n",
      "Epoch 466, Loss: 217.1350640670325, Neurons: 201, Grad norm: 5.291358328010947\n",
      "Epoch 466, Loss: 217.1350640670325, Neurons: 201, Grad norm: 5.291358328010947\n",
      "Epoch 467, Loss: 217.1250105760756, Neurons: 201, Grad norm: 5.2888159154054595\n",
      "Epoch 467, Loss: 217.1250105760756, Neurons: 201, Grad norm: 5.2888159154054595\n",
      "Epoch 468, Loss: 217.11500661321972, Neurons: 201, Grad norm: 5.281709146637038\n",
      "Epoch 468, Loss: 217.11500661321972, Neurons: 201, Grad norm: 5.281709146637038\n",
      "Epoch 469, Loss: 217.10501564642178, Neurons: 201, Grad norm: 5.267349537074244\n",
      "Epoch 469, Loss: 217.10501564642178, Neurons: 201, Grad norm: 5.267349537074244\n",
      "Epoch 470, Loss: 217.09509242825402, Neurons: 201, Grad norm: 5.2577100557709\n",
      "Epoch 470, Loss: 217.09509242825402, Neurons: 201, Grad norm: 5.2577100557709\n",
      "Epoch 471, Loss: 217.0852136725241, Neurons: 201, Grad norm: 5.258877869179617\n",
      "Epoch 471, Loss: 217.0852136725241, Neurons: 201, Grad norm: 5.258877869179617\n",
      "Epoch 472, Loss: 217.07535989298233, Neurons: 201, Grad norm: 5.2471851515795604\n",
      "Epoch 472, Loss: 217.07535989298233, Neurons: 201, Grad norm: 5.2471851515795604\n",
      "Epoch 473, Loss: 217.0655145982564, Neurons: 201, Grad norm: 5.23411990017052\n",
      "Epoch 473, Loss: 217.0655145982564, Neurons: 201, Grad norm: 5.23411990017052\n",
      "Epoch 474, Loss: 217.0557477306406, Neurons: 201, Grad norm: 5.22964870784915\n",
      "Epoch 474, Loss: 217.0557477306406, Neurons: 201, Grad norm: 5.22964870784915\n",
      "Epoch 475, Loss: 217.04599643125985, Neurons: 201, Grad norm: 5.218831732632005\n",
      "Epoch 475, Loss: 217.04599643125985, Neurons: 201, Grad norm: 5.218831732632005\n",
      "Epoch 476, Loss: 217.03627153412683, Neurons: 201, Grad norm: 5.207019372634927\n",
      "Epoch 476, Loss: 217.03627153412683, Neurons: 201, Grad norm: 5.207019372634927\n",
      "Epoch 477, Loss: 217.02660069162476, Neurons: 201, Grad norm: 5.197443209875713\n",
      "Epoch 477, Loss: 217.02660069162476, Neurons: 201, Grad norm: 5.197443209875713\n",
      "Epoch 478, Loss: 217.01695699696558, Neurons: 201, Grad norm: 5.186879416764503\n",
      "Epoch 478, Loss: 217.01695699696558, Neurons: 201, Grad norm: 5.186879416764503\n",
      "Epoch 479, Loss: 217.00733732500592, Neurons: 201, Grad norm: 5.180576250265718\n",
      "Epoch 479, Loss: 217.00733732500592, Neurons: 201, Grad norm: 5.180576250265718\n",
      "Epoch 480, Loss: 216.99774904782333, Neurons: 201, Grad norm: 5.175819862560311\n",
      "Epoch 480, Loss: 216.99774904782333, Neurons: 201, Grad norm: 5.175819862560311\n",
      "Epoch 481, Loss: 216.98818078617876, Neurons: 201, Grad norm: 5.166130383069582\n",
      "Epoch 481, Loss: 216.98818078617876, Neurons: 201, Grad norm: 5.166130383069582\n",
      "Epoch 482, Loss: 216.97861422216914, Neurons: 201, Grad norm: 5.152755123273532\n",
      "Epoch 482, Loss: 216.97861422216914, Neurons: 201, Grad norm: 5.152755123273532\n",
      "Epoch 483, Loss: 216.96909105034302, Neurons: 201, Grad norm: 5.143650224144003\n",
      "Epoch 483, Loss: 216.96909105034302, Neurons: 201, Grad norm: 5.143650224144003\n",
      "Epoch 484, Loss: 216.9596086839891, Neurons: 201, Grad norm: 5.141915860939261\n",
      "Epoch 484, Loss: 216.9596086839891, Neurons: 201, Grad norm: 5.141915860939261\n",
      "Epoch 485, Loss: 216.9501327463517, Neurons: 201, Grad norm: 5.137343117010336\n",
      "Epoch 485, Loss: 216.9501327463517, Neurons: 201, Grad norm: 5.137343117010336\n",
      "Epoch 486, Loss: 216.94065542689623, Neurons: 201, Grad norm: 5.126795328728283\n",
      "Epoch 486, Loss: 216.94065542689623, Neurons: 201, Grad norm: 5.126795328728283\n",
      "Epoch 487, Loss: 216.93119785741166, Neurons: 201, Grad norm: 5.118161278654335\n",
      "Epoch 487, Loss: 216.93119785741166, Neurons: 201, Grad norm: 5.118161278654335\n",
      "Epoch 488, Loss: 216.92174769335205, Neurons: 201, Grad norm: 5.113069341166838\n",
      "Epoch 488, Loss: 216.92174769335205, Neurons: 201, Grad norm: 5.113069341166838\n",
      "Epoch 489, Loss: 216.9123269315971, Neurons: 201, Grad norm: 5.111028795790847\n",
      "Epoch 489, Loss: 216.9123269315971, Neurons: 201, Grad norm: 5.111028795790847\n",
      "Epoch 490, Loss: 216.90292787464742, Neurons: 201, Grad norm: 5.095567004372454\n",
      "Epoch 490, Loss: 216.90292787464742, Neurons: 201, Grad norm: 5.095567004372454\n",
      "Epoch 491, Loss: 216.89355575154016, Neurons: 201, Grad norm: 5.097288726775112\n",
      "Epoch 491, Loss: 216.89355575154016, Neurons: 201, Grad norm: 5.097288726775112\n",
      "Epoch 492, Loss: 216.88420111315384, Neurons: 201, Grad norm: 5.088963565852285\n",
      "Epoch 492, Loss: 216.88420111315384, Neurons: 201, Grad norm: 5.088963565852285\n",
      "Epoch 493, Loss: 216.8748748598718, Neurons: 201, Grad norm: 5.087932604988422\n",
      "Epoch 493, Loss: 216.8748748598718, Neurons: 201, Grad norm: 5.087932604988422\n",
      "Epoch 494, Loss: 216.8655645918667, Neurons: 201, Grad norm: 5.082171812182178\n",
      "Epoch 494, Loss: 216.8655645918667, Neurons: 201, Grad norm: 5.082171812182178\n",
      "Epoch 495, Loss: 216.8562804645414, Neurons: 201, Grad norm: 5.076174733248363\n",
      "Epoch 495, Loss: 216.8562804645414, Neurons: 201, Grad norm: 5.076174733248363\n",
      "Epoch 496, Loss: 216.84702638127985, Neurons: 201, Grad norm: 5.069321478091949\n",
      "Epoch 496, Loss: 216.84702638127985, Neurons: 201, Grad norm: 5.069321478091949\n",
      "Epoch 497, Loss: 216.83783013015002, Neurons: 201, Grad norm: 5.074710789186102\n",
      "Epoch 497, Loss: 216.83783013015002, Neurons: 201, Grad norm: 5.074710789186102\n",
      "Epoch 498, Loss: 216.82865682889732, Neurons: 201, Grad norm: 5.0712506398509944\n",
      "Epoch 498, Loss: 216.82865682889732, Neurons: 201, Grad norm: 5.0712506398509944\n",
      "Epoch 499, Loss: 216.81948446186806, Neurons: 201, Grad norm: 5.071904430548317\n",
      "Epoch 499, Loss: 216.81948446186806, Neurons: 201, Grad norm: 5.071904430548317\n",
      "Epoch 500, Loss: 216.81033114584397, Neurons: 201, Grad norm: 5.076431360267797\n",
      "Epoch 500, Loss: 216.81033114584397, Neurons: 201, Grad norm: 5.076431360267797\n",
      "Epoch 501, Loss: 216.80119000435383, Neurons: 201, Grad norm: 5.074976224619037\n",
      "Epoch 501, Loss: 216.80119000435383, Neurons: 201, Grad norm: 5.074976224619037\n",
      "Epoch 502, Loss: 216.79205642451822, Neurons: 201, Grad norm: 5.066122577433114\n",
      "Epoch 502, Loss: 216.79205642451822, Neurons: 201, Grad norm: 5.066122577433114\n",
      "Epoch 503, Loss: 216.7829485506091, Neurons: 201, Grad norm: 5.0607637848354985\n",
      "Epoch 503, Loss: 216.7829485506091, Neurons: 201, Grad norm: 5.0607637848354985\n",
      "Epoch 504, Loss: 216.7738782971991, Neurons: 201, Grad norm: 5.058412827416572\n",
      "Epoch 504, Loss: 216.7738782971991, Neurons: 201, Grad norm: 5.058412827416572\n",
      "Epoch 505, Loss: 216.7648272805983, Neurons: 201, Grad norm: 5.058491827996986\n",
      "Epoch 505, Loss: 216.7648272805983, Neurons: 201, Grad norm: 5.058491827996986\n",
      "Epoch 506, Loss: 216.75579700739044, Neurons: 201, Grad norm: 5.050709720506714\n",
      "Epoch 506, Loss: 216.75579700739044, Neurons: 201, Grad norm: 5.050709720506714\n",
      "Epoch 507, Loss: 216.74679334094253, Neurons: 201, Grad norm: 5.052304331149881\n",
      "Epoch 507, Loss: 216.74679334094253, Neurons: 201, Grad norm: 5.052304331149881\n",
      "Epoch 508, Loss: 216.73781481820322, Neurons: 201, Grad norm: 5.053974260888067\n",
      "Epoch 508, Loss: 216.73781481820322, Neurons: 201, Grad norm: 5.053974260888067\n",
      "Epoch 509, Loss: 216.72882437684524, Neurons: 201, Grad norm: 5.053549679625531\n",
      "Epoch 509, Loss: 216.72882437684524, Neurons: 201, Grad norm: 5.053549679625531\n",
      "Epoch 510, Loss: 216.71982593970003, Neurons: 201, Grad norm: 5.048583649927018\n",
      "Epoch 510, Loss: 216.71982593970003, Neurons: 201, Grad norm: 5.048583649927018\n",
      "Epoch 511, Loss: 216.71082053431905, Neurons: 201, Grad norm: 5.044117453133536\n",
      "Epoch 511, Loss: 216.71082053431905, Neurons: 201, Grad norm: 5.044117453133536\n",
      "Epoch 512, Loss: 216.70180294830953, Neurons: 201, Grad norm: 5.044625435684818\n",
      "Epoch 512, Loss: 216.70180294830953, Neurons: 201, Grad norm: 5.044625435684818\n",
      "Epoch 513, Loss: 216.69279138475574, Neurons: 201, Grad norm: 5.036959762937463\n",
      "Epoch 513, Loss: 216.69279138475574, Neurons: 201, Grad norm: 5.036959762937463\n",
      "Epoch 514, Loss: 216.68377619251083, Neurons: 201, Grad norm: 5.0333477896170695\n",
      "Epoch 514, Loss: 216.68377619251083, Neurons: 201, Grad norm: 5.0333477896170695\n",
      "Epoch 515, Loss: 216.67477194609992, Neurons: 201, Grad norm: 5.022350101391821\n",
      "Epoch 515, Loss: 216.67477194609992, Neurons: 201, Grad norm: 5.022350101391821\n",
      "Epoch 516, Loss: 216.66576068237717, Neurons: 201, Grad norm: 5.018388096540029\n",
      "Epoch 516, Loss: 216.66576068237717, Neurons: 201, Grad norm: 5.018388096540029\n",
      "Epoch 517, Loss: 216.6567723298774, Neurons: 201, Grad norm: 5.0128117597904716\n",
      "Epoch 517, Loss: 216.6567723298774, Neurons: 201, Grad norm: 5.0128117597904716\n",
      "Epoch 518, Loss: 216.64779239309308, Neurons: 201, Grad norm: 5.009426941036548\n",
      "Epoch 518, Loss: 216.64779239309308, Neurons: 201, Grad norm: 5.009426941036548\n",
      "Epoch 519, Loss: 216.63881439538468, Neurons: 201, Grad norm: 4.996903184193077\n",
      "Epoch 519, Loss: 216.63881439538468, Neurons: 201, Grad norm: 4.996903184193077\n",
      "Epoch 520, Loss: 216.62984405914582, Neurons: 201, Grad norm: 4.982376011643586\n",
      "Epoch 520, Loss: 216.62984405914582, Neurons: 201, Grad norm: 4.982376011643586\n",
      "Epoch 521, Loss: 216.62090717992768, Neurons: 201, Grad norm: 4.9808222058299645\n",
      "Epoch 521, Loss: 216.62090717992768, Neurons: 201, Grad norm: 4.9808222058299645\n",
      "Epoch 522, Loss: 216.61197597316445, Neurons: 201, Grad norm: 4.980373024043647\n",
      "Epoch 522, Loss: 216.61197597316445, Neurons: 201, Grad norm: 4.980373024043647\n",
      "Epoch 523, Loss: 216.60303942768724, Neurons: 201, Grad norm: 4.969443409472192\n",
      "Epoch 523, Loss: 216.60303942768724, Neurons: 201, Grad norm: 4.969443409472192\n",
      "Epoch 524, Loss: 216.59411152614422, Neurons: 201, Grad norm: 4.951212975390296\n",
      "Epoch 524, Loss: 216.59411152614422, Neurons: 201, Grad norm: 4.951212975390296\n",
      "Epoch 525, Loss: 216.585256276417, Neurons: 201, Grad norm: 4.947287361640241\n",
      "Epoch 525, Loss: 216.585256276417, Neurons: 201, Grad norm: 4.947287361640241\n",
      "Epoch 526, Loss: 216.5764259718891, Neurons: 201, Grad norm: 4.934279058411792\n",
      "Epoch 526, Loss: 216.5764259718891, Neurons: 201, Grad norm: 4.934279058411792\n",
      "Epoch 527, Loss: 216.5676318196502, Neurons: 201, Grad norm: 4.923501047450342\n",
      "Epoch 527, Loss: 216.5676318196502, Neurons: 201, Grad norm: 4.923501047450342\n",
      "Epoch 528, Loss: 216.5589191083622, Neurons: 201, Grad norm: 4.920260078557947\n",
      "Epoch 528, Loss: 216.5589191083622, Neurons: 201, Grad norm: 4.920260078557947\n",
      "Epoch 529, Loss: 216.5502359501133, Neurons: 201, Grad norm: 4.912606742253483\n",
      "Epoch 529, Loss: 216.5502359501133, Neurons: 201, Grad norm: 4.912606742253483\n",
      "Epoch 530, Loss: 216.5415910346521, Neurons: 201, Grad norm: 4.908738162444378\n",
      "Epoch 530, Loss: 216.5415910346521, Neurons: 201, Grad norm: 4.908738162444378\n",
      "Epoch 531, Loss: 216.53295944149, Neurons: 201, Grad norm: 4.899366201332329\n",
      "Epoch 531, Loss: 216.53295944149, Neurons: 201, Grad norm: 4.899366201332329\n",
      "Epoch 532, Loss: 216.5243627126585, Neurons: 201, Grad norm: 4.9006777506747685\n",
      "Epoch 532, Loss: 216.5243627126585, Neurons: 201, Grad norm: 4.9006777506747685\n",
      "Epoch 533, Loss: 216.51580811001836, Neurons: 201, Grad norm: 4.892876474723987\n",
      "Epoch 533, Loss: 216.51580811001836, Neurons: 201, Grad norm: 4.892876474723987\n",
      "Epoch 534, Loss: 216.50726871555275, Neurons: 201, Grad norm: 4.877758998521131\n",
      "Epoch 534, Loss: 216.50726871555275, Neurons: 201, Grad norm: 4.877758998521131\n",
      "Epoch 535, Loss: 216.49878038450242, Neurons: 201, Grad norm: 4.869134617153688\n",
      "Epoch 535, Loss: 216.49878038450242, Neurons: 201, Grad norm: 4.869134617153688\n",
      "Epoch 536, Loss: 216.49033712665704, Neurons: 201, Grad norm: 4.860707610637745\n",
      "Epoch 536, Loss: 216.49033712665704, Neurons: 201, Grad norm: 4.860707610637745\n",
      "Epoch 537, Loss: 216.48193246290077, Neurons: 201, Grad norm: 4.857479380998443\n",
      "Epoch 537, Loss: 216.48193246290077, Neurons: 201, Grad norm: 4.857479380998443\n",
      "Epoch 538, Loss: 216.47354740434534, Neurons: 201, Grad norm: 4.849044279598522\n",
      "Epoch 538, Loss: 216.47354740434534, Neurons: 201, Grad norm: 4.849044279598522\n",
      "Epoch 539, Loss: 216.46518875322732, Neurons: 201, Grad norm: 4.846523383425496\n",
      "Epoch 539, Loss: 216.46518875322732, Neurons: 201, Grad norm: 4.846523383425496\n",
      "Epoch 540, Loss: 216.45685604312698, Neurons: 201, Grad norm: 4.839660735831423\n",
      "Epoch 540, Loss: 216.45685604312698, Neurons: 201, Grad norm: 4.839660735831423\n",
      "Epoch 541, Loss: 216.44852155597755, Neurons: 201, Grad norm: 4.835343199672038\n",
      "Epoch 541, Loss: 216.44852155597755, Neurons: 201, Grad norm: 4.835343199672038\n",
      "Epoch 542, Loss: 216.44018751742772, Neurons: 201, Grad norm: 4.820553718095059\n",
      "Epoch 542, Loss: 216.44018751742772, Neurons: 201, Grad norm: 4.820553718095059\n",
      "Epoch 543, Loss: 216.4318755395965, Neurons: 201, Grad norm: 4.81281340238453\n",
      "Epoch 543, Loss: 216.4318755395965, Neurons: 201, Grad norm: 4.81281340238453\n",
      "Epoch 544, Loss: 216.42359451032837, Neurons: 201, Grad norm: 4.808392349083026\n",
      "Epoch 544, Loss: 216.42359451032837, Neurons: 201, Grad norm: 4.808392349083026\n",
      "Epoch 545, Loss: 216.41533361029067, Neurons: 201, Grad norm: 4.7988822930127615\n",
      "Epoch 545, Loss: 216.41533361029067, Neurons: 201, Grad norm: 4.7988822930127615\n",
      "Epoch 546, Loss: 216.40708470946691, Neurons: 201, Grad norm: 4.79189404270688\n",
      "Epoch 546, Loss: 216.40708470946691, Neurons: 201, Grad norm: 4.79189404270688\n",
      "Epoch 547, Loss: 216.3988523216327, Neurons: 201, Grad norm: 4.780909158538711\n",
      "Epoch 547, Loss: 216.3988523216327, Neurons: 201, Grad norm: 4.780909158538711\n",
      "Epoch 548, Loss: 216.39064280328, Neurons: 201, Grad norm: 4.771665267580451\n",
      "Epoch 548, Loss: 216.39064280328, Neurons: 201, Grad norm: 4.771665267580451\n",
      "Epoch 549, Loss: 216.3824818085225, Neurons: 201, Grad norm: 4.760057351298669\n",
      "Epoch 549, Loss: 216.3824818085225, Neurons: 201, Grad norm: 4.760057351298669\n",
      "Epoch 550, Loss: 216.37434085798134, Neurons: 201, Grad norm: 4.758728774845061\n",
      "Epoch 550, Loss: 216.37434085798134, Neurons: 201, Grad norm: 4.758728774845061\n",
      "Epoch 551, Loss: 216.36620356393354, Neurons: 201, Grad norm: 4.750476759060029\n",
      "Epoch 551, Loss: 216.36620356393354, Neurons: 201, Grad norm: 4.750476759060029\n",
      "Epoch 552, Loss: 216.35808681871174, Neurons: 201, Grad norm: 4.740136749953431\n",
      "Epoch 552, Loss: 216.35808681871174, Neurons: 201, Grad norm: 4.740136749953431\n",
      "Epoch 553, Loss: 216.34999603007037, Neurons: 201, Grad norm: 4.741428386917279\n",
      "Epoch 553, Loss: 216.34999603007037, Neurons: 201, Grad norm: 4.741428386917279\n",
      "Epoch 554, Loss: 216.3418931165468, Neurons: 201, Grad norm: 4.738045881619947\n",
      "Epoch 554, Loss: 216.3418931165468, Neurons: 201, Grad norm: 4.738045881619947\n",
      "Epoch 555, Loss: 216.33381036306525, Neurons: 201, Grad norm: 4.735026845208053\n",
      "Epoch 555, Loss: 216.33381036306525, Neurons: 201, Grad norm: 4.735026845208053\n",
      "Epoch 556, Loss: 216.32574130411834, Neurons: 201, Grad norm: 4.734721740576727\n",
      "Epoch 556, Loss: 216.32574130411834, Neurons: 201, Grad norm: 4.734721740576727\n",
      "Epoch 557, Loss: 216.31767306300964, Neurons: 201, Grad norm: 4.727473894876818\n",
      "Epoch 557, Loss: 216.31767306300964, Neurons: 201, Grad norm: 4.727473894876818\n",
      "Epoch 558, Loss: 216.30962762214455, Neurons: 201, Grad norm: 4.725389809740377\n",
      "Epoch 558, Loss: 216.30962762214455, Neurons: 201, Grad norm: 4.725389809740377\n",
      "Epoch 559, Loss: 216.30158350423233, Neurons: 201, Grad norm: 4.719978393685544\n",
      "Epoch 559, Loss: 216.30158350423233, Neurons: 201, Grad norm: 4.719978393685544\n",
      "Epoch 560, Loss: 216.29355609722353, Neurons: 201, Grad norm: 4.714436079786809\n",
      "Epoch 560, Loss: 216.29355609722353, Neurons: 201, Grad norm: 4.714436079786809\n",
      "Epoch 561, Loss: 216.28551377759695, Neurons: 201, Grad norm: 4.709363771848158\n",
      "Epoch 561, Loss: 216.28551377759695, Neurons: 201, Grad norm: 4.709363771848158\n",
      "Epoch 562, Loss: 216.2775077426845, Neurons: 201, Grad norm: 4.707822035790695\n",
      "Epoch 562, Loss: 216.2775077426845, Neurons: 201, Grad norm: 4.707822035790695\n",
      "Epoch 563, Loss: 216.2694958246679, Neurons: 201, Grad norm: 4.7058649789457325\n",
      "Epoch 563, Loss: 216.2694958246679, Neurons: 201, Grad norm: 4.7058649789457325\n",
      "Epoch 564, Loss: 216.2614804822924, Neurons: 201, Grad norm: 4.6979209465871\n",
      "Epoch 564, Loss: 216.2614804822924, Neurons: 201, Grad norm: 4.6979209465871\n",
      "Epoch 565, Loss: 216.25347300980172, Neurons: 201, Grad norm: 4.692349820081363\n",
      "Epoch 565, Loss: 216.25347300980172, Neurons: 201, Grad norm: 4.692349820081363\n",
      "Epoch 566, Loss: 216.2454625435465, Neurons: 201, Grad norm: 4.684884747005721\n",
      "Epoch 566, Loss: 216.2454625435465, Neurons: 201, Grad norm: 4.684884747005721\n",
      "Epoch 567, Loss: 216.23746626859918, Neurons: 201, Grad norm: 4.681351935841212\n",
      "Epoch 567, Loss: 216.23746626859918, Neurons: 201, Grad norm: 4.681351935841212\n",
      "Epoch 568, Loss: 216.22948349019154, Neurons: 201, Grad norm: 4.673588653938412\n",
      "Epoch 568, Loss: 216.22948349019154, Neurons: 201, Grad norm: 4.673588653938412\n",
      "Epoch 569, Loss: 216.22151989008026, Neurons: 201, Grad norm: 4.667533287368291\n",
      "Epoch 569, Loss: 216.22151989008026, Neurons: 201, Grad norm: 4.667533287368291\n",
      "Epoch 570, Loss: 216.2135600761136, Neurons: 201, Grad norm: 4.661630129109983\n",
      "Epoch 570, Loss: 216.2135600761136, Neurons: 201, Grad norm: 4.661630129109983\n",
      "Epoch 571, Loss: 216.20558980579503, Neurons: 201, Grad norm: 4.654348290808189\n",
      "Epoch 571, Loss: 216.20558980579503, Neurons: 201, Grad norm: 4.654348290808189\n",
      "Epoch 572, Loss: 216.19763313677925, Neurons: 201, Grad norm: 4.646785913932415\n",
      "Epoch 572, Loss: 216.19763313677925, Neurons: 201, Grad norm: 4.646785913932415\n",
      "Epoch 573, Loss: 216.1896951450746, Neurons: 201, Grad norm: 4.639326925654166\n",
      "Epoch 573, Loss: 216.1896951450746, Neurons: 201, Grad norm: 4.639326925654166\n",
      "Epoch 574, Loss: 216.18178690811885, Neurons: 201, Grad norm: 4.635865201584422\n",
      "Epoch 574, Loss: 216.18178690811885, Neurons: 201, Grad norm: 4.635865201584422\n",
      "Epoch 575, Loss: 216.17388671047362, Neurons: 201, Grad norm: 4.635677215957127\n",
      "Epoch 575, Loss: 216.17388671047362, Neurons: 201, Grad norm: 4.635677215957127\n",
      "Epoch 576, Loss: 216.16600245005912, Neurons: 201, Grad norm: 4.628319432423823\n",
      "Epoch 576, Loss: 216.16600245005912, Neurons: 201, Grad norm: 4.628319432423823\n",
      "Epoch 577, Loss: 216.15813286282236, Neurons: 201, Grad norm: 4.630625503000953\n",
      "Epoch 577, Loss: 216.15813286282236, Neurons: 201, Grad norm: 4.630625503000953\n",
      "Epoch 578, Loss: 216.15027643694233, Neurons: 201, Grad norm: 4.63370096231101\n",
      "Epoch 578, Loss: 216.15027643694233, Neurons: 201, Grad norm: 4.63370096231101\n",
      "Epoch 579, Loss: 216.14243700141762, Neurons: 201, Grad norm: 4.634712307942765\n",
      "Epoch 579, Loss: 216.14243700141762, Neurons: 201, Grad norm: 4.634712307942765\n",
      "Epoch 580, Loss: 216.13459998260663, Neurons: 201, Grad norm: 4.628099071844258\n",
      "Epoch 580, Loss: 216.13459998260663, Neurons: 201, Grad norm: 4.628099071844258\n",
      "Epoch 581, Loss: 216.12677919940197, Neurons: 201, Grad norm: 4.62670999906175\n",
      "Epoch 581, Loss: 216.12677919940197, Neurons: 201, Grad norm: 4.62670999906175\n",
      "Epoch 582, Loss: 216.11900819881924, Neurons: 201, Grad norm: 4.6166729584518595\n",
      "Epoch 582, Loss: 216.11900819881924, Neurons: 201, Grad norm: 4.6166729584518595\n",
      "Epoch 583, Loss: 216.11125572873377, Neurons: 201, Grad norm: 4.614372666144611\n",
      "Epoch 583, Loss: 216.11125572873377, Neurons: 201, Grad norm: 4.614372666144611\n",
      "Epoch 584, Loss: 216.1035316296512, Neurons: 201, Grad norm: 4.607785220376939\n",
      "Epoch 584, Loss: 216.1035316296512, Neurons: 201, Grad norm: 4.607785220376939\n",
      "Epoch 585, Loss: 216.09584078686538, Neurons: 201, Grad norm: 4.604524089028193\n",
      "Epoch 585, Loss: 216.09584078686538, Neurons: 201, Grad norm: 4.604524089028193\n",
      "Epoch 586, Loss: 216.08815749184197, Neurons: 201, Grad norm: 4.594359481393611\n",
      "Epoch 586, Loss: 216.08815749184197, Neurons: 201, Grad norm: 4.594359481393611\n",
      "Epoch 587, Loss: 216.08048501401743, Neurons: 201, Grad norm: 4.588429611058495\n",
      "Epoch 587, Loss: 216.08048501401743, Neurons: 201, Grad norm: 4.588429611058495\n",
      "Epoch 588, Loss: 216.0728490794148, Neurons: 201, Grad norm: 4.573990031839144\n",
      "Epoch 588, Loss: 216.0728490794148, Neurons: 201, Grad norm: 4.573990031839144\n",
      "Epoch 589, Loss: 216.06523867813863, Neurons: 201, Grad norm: 4.565356269222441\n",
      "Epoch 589, Loss: 216.06523867813863, Neurons: 201, Grad norm: 4.565356269222441\n",
      "Epoch 590, Loss: 216.0576557290085, Neurons: 201, Grad norm: 4.55628541210911\n",
      "Epoch 590, Loss: 216.0576557290085, Neurons: 201, Grad norm: 4.55628541210911\n",
      "Epoch 591, Loss: 216.0500859213096, Neurons: 201, Grad norm: 4.55134809747369\n",
      "Epoch 591, Loss: 216.0500859213096, Neurons: 201, Grad norm: 4.55134809747369\n",
      "Epoch 592, Loss: 216.04254242352835, Neurons: 201, Grad norm: 4.5423021275970585\n",
      "Epoch 592, Loss: 216.04254242352835, Neurons: 201, Grad norm: 4.5423021275970585\n",
      "Epoch 593, Loss: 216.03501765270354, Neurons: 201, Grad norm: 4.547590373148856\n",
      "Epoch 593, Loss: 216.03501765270354, Neurons: 201, Grad norm: 4.547590373148856\n",
      "Epoch 594, Loss: 216.02749914710066, Neurons: 201, Grad norm: 4.539679624300993\n",
      "Epoch 594, Loss: 216.02749914710066, Neurons: 201, Grad norm: 4.539679624300993\n",
      "Epoch 595, Loss: 216.02000865846423, Neurons: 201, Grad norm: 4.540290976238498\n",
      "Epoch 595, Loss: 216.02000865846423, Neurons: 201, Grad norm: 4.540290976238498\n",
      "Epoch 596, Loss: 216.01254978997093, Neurons: 201, Grad norm: 4.539714833387068\n",
      "Epoch 596, Loss: 216.01254978997093, Neurons: 201, Grad norm: 4.539714833387068\n",
      "Epoch 597, Loss: 216.00509970711923, Neurons: 201, Grad norm: 4.544340739235181\n",
      "Epoch 597, Loss: 216.00509970711923, Neurons: 201, Grad norm: 4.544340739235181\n",
      "Epoch 598, Loss: 215.99766815651844, Neurons: 201, Grad norm: 4.547535511788077\n",
      "Epoch 598, Loss: 215.99766815651844, Neurons: 201, Grad norm: 4.547535511788077\n",
      "Epoch 599, Loss: 215.99022996058662, Neurons: 201, Grad norm: 4.546708835875354\n",
      "Epoch 599, Loss: 215.99022996058662, Neurons: 201, Grad norm: 4.546708835875354\n",
      "Epoch 600, Loss: 215.9827989424651, Neurons: 201, Grad norm: 4.546350359172968\n",
      "Epoch 600, Loss: 215.9827989424651, Neurons: 201, Grad norm: 4.546350359172968\n",
      "Epoch 601, Loss: 215.97538571691888, Neurons: 201, Grad norm: 4.549021700402204\n",
      "Epoch 601, Loss: 215.97538571691888, Neurons: 201, Grad norm: 4.549021700402204\n",
      "Epoch 602, Loss: 215.96799293501175, Neurons: 201, Grad norm: 4.544898129145228\n",
      "Epoch 602, Loss: 215.96799293501175, Neurons: 201, Grad norm: 4.544898129145228\n",
      "Epoch 603, Loss: 215.96061823156862, Neurons: 201, Grad norm: 4.543325005602937\n",
      "Epoch 603, Loss: 215.96061823156862, Neurons: 201, Grad norm: 4.543325005602937\n",
      "Epoch 604, Loss: 215.9532481378895, Neurons: 201, Grad norm: 4.536406487750771\n",
      "Epoch 604, Loss: 215.9532481378895, Neurons: 201, Grad norm: 4.536406487750771\n",
      "Epoch 605, Loss: 215.94589571043304, Neurons: 201, Grad norm: 4.533943398714297\n",
      "Epoch 605, Loss: 215.94589571043304, Neurons: 201, Grad norm: 4.533943398714297\n",
      "Epoch 606, Loss: 215.9385553912439, Neurons: 201, Grad norm: 4.5292807047787225\n",
      "Epoch 606, Loss: 215.9385553912439, Neurons: 201, Grad norm: 4.5292807047787225\n",
      "Epoch 607, Loss: 215.9312202438577, Neurons: 201, Grad norm: 4.5169066076114905\n",
      "Epoch 607, Loss: 215.9312202438577, Neurons: 201, Grad norm: 4.5169066076114905\n",
      "Epoch 608, Loss: 215.92389916357936, Neurons: 201, Grad norm: 4.511847045728882\n",
      "Epoch 608, Loss: 215.92389916357936, Neurons: 201, Grad norm: 4.511847045728882\n",
      "Epoch 609, Loss: 215.9165993460368, Neurons: 201, Grad norm: 4.499443052754368\n",
      "Epoch 609, Loss: 215.9165993460368, Neurons: 201, Grad norm: 4.499443052754368\n",
      "Epoch 610, Loss: 215.90930499403044, Neurons: 201, Grad norm: 4.495852845633847\n",
      "Epoch 610, Loss: 215.90930499403044, Neurons: 201, Grad norm: 4.495852845633847\n",
      "Epoch 611, Loss: 215.9020437756194, Neurons: 201, Grad norm: 4.483868566268797\n",
      "Epoch 611, Loss: 215.9020437756194, Neurons: 201, Grad norm: 4.483868566268797\n",
      "Epoch 612, Loss: 215.89479780077409, Neurons: 201, Grad norm: 4.474401948248545\n",
      "Epoch 612, Loss: 215.89479780077409, Neurons: 201, Grad norm: 4.474401948248545\n",
      "Epoch 613, Loss: 215.8875942993355, Neurons: 201, Grad norm: 4.454012757515804\n",
      "Epoch 613, Loss: 215.8875942993355, Neurons: 201, Grad norm: 4.454012757515804\n",
      "Epoch 614, Loss: 215.88041975300087, Neurons: 201, Grad norm: 4.45183014819286\n",
      "Epoch 614, Loss: 215.88041975300087, Neurons: 201, Grad norm: 4.45183014819286\n",
      "Epoch 615, Loss: 215.87330434388986, Neurons: 201, Grad norm: 4.4426152652444\n",
      "Epoch 615, Loss: 215.87330434388986, Neurons: 201, Grad norm: 4.4426152652444\n",
      "Epoch 616, Loss: 215.8662009418379, Neurons: 201, Grad norm: 4.438365848268141\n",
      "Epoch 616, Loss: 215.8662009418379, Neurons: 201, Grad norm: 4.438365848268141\n",
      "Epoch 617, Loss: 215.85913203958955, Neurons: 201, Grad norm: 4.435059009759237\n",
      "Epoch 617, Loss: 215.85913203958955, Neurons: 201, Grad norm: 4.435059009759237\n",
      "Epoch 618, Loss: 215.85207391441185, Neurons: 201, Grad norm: 4.433868973170679\n",
      "Epoch 618, Loss: 215.85207391441185, Neurons: 201, Grad norm: 4.433868973170679\n",
      "Epoch 619, Loss: 215.84502954279236, Neurons: 201, Grad norm: 4.430650462895238\n",
      "Epoch 619, Loss: 215.84502954279236, Neurons: 201, Grad norm: 4.430650462895238\n",
      "Epoch 620, Loss: 215.83799223362462, Neurons: 201, Grad norm: 4.425555760652519\n",
      "Epoch 620, Loss: 215.83799223362462, Neurons: 201, Grad norm: 4.425555760652519\n",
      "Epoch 621, Loss: 215.83099042272318, Neurons: 201, Grad norm: 4.426460894603351\n",
      "Epoch 621, Loss: 215.83099042272318, Neurons: 201, Grad norm: 4.426460894603351\n",
      "Epoch 622, Loss: 215.82400502945404, Neurons: 201, Grad norm: 4.423543194201927\n",
      "Epoch 622, Loss: 215.82400502945404, Neurons: 201, Grad norm: 4.423543194201927\n",
      "Epoch 623, Loss: 215.8170290183494, Neurons: 201, Grad norm: 4.425320335163192\n",
      "Epoch 623, Loss: 215.8170290183494, Neurons: 201, Grad norm: 4.425320335163192\n",
      "Epoch 624, Loss: 215.810059509425, Neurons: 201, Grad norm: 4.4248411292745695\n",
      "Epoch 624, Loss: 215.810059509425, Neurons: 201, Grad norm: 4.4248411292745695\n",
      "Epoch 625, Loss: 215.80309090452613, Neurons: 201, Grad norm: 4.422537198112216\n",
      "Epoch 625, Loss: 215.80309090452613, Neurons: 201, Grad norm: 4.422537198112216\n",
      "Epoch 626, Loss: 215.7961303843301, Neurons: 201, Grad norm: 4.4253498690002475\n",
      "Epoch 626, Loss: 215.7961303843301, Neurons: 201, Grad norm: 4.4253498690002475\n",
      "Epoch 627, Loss: 215.78916737106948, Neurons: 201, Grad norm: 4.425066924307173\n",
      "Epoch 627, Loss: 215.78916737106948, Neurons: 201, Grad norm: 4.425066924307173\n",
      "Epoch 628, Loss: 215.7821841143335, Neurons: 201, Grad norm: 4.4239316436507385\n",
      "Epoch 628, Loss: 215.7821841143335, Neurons: 201, Grad norm: 4.4239316436507385\n",
      "Epoch 629, Loss: 215.7751928781118, Neurons: 201, Grad norm: 4.41706822108319\n",
      "Epoch 629, Loss: 215.7751928781118, Neurons: 201, Grad norm: 4.41706822108319\n",
      "Epoch 630, Loss: 215.7682413534582, Neurons: 201, Grad norm: 4.414555413352221\n",
      "Epoch 630, Loss: 215.7682413534582, Neurons: 201, Grad norm: 4.414555413352221\n",
      "Epoch 631, Loss: 215.76131285021484, Neurons: 201, Grad norm: 4.412318124537015\n",
      "Epoch 631, Loss: 215.76131285021484, Neurons: 201, Grad norm: 4.412318124537015\n",
      "Epoch 632, Loss: 215.75438366104171, Neurons: 201, Grad norm: 4.411416955454395\n",
      "Epoch 632, Loss: 215.75438366104171, Neurons: 201, Grad norm: 4.411416955454395\n",
      "Epoch 633, Loss: 215.74746152551637, Neurons: 201, Grad norm: 4.4016898529952355\n",
      "Epoch 633, Loss: 215.74746152551637, Neurons: 201, Grad norm: 4.4016898529952355\n",
      "Epoch 634, Loss: 215.74056864570926, Neurons: 201, Grad norm: 4.3941264187719185\n",
      "Epoch 634, Loss: 215.74056864570926, Neurons: 201, Grad norm: 4.3941264187719185\n",
      "Epoch 635, Loss: 215.73371788542383, Neurons: 201, Grad norm: 4.3907067077578255\n",
      "Epoch 635, Loss: 215.73371788542383, Neurons: 201, Grad norm: 4.3907067077578255\n",
      "Epoch 636, Loss: 215.726901487488, Neurons: 201, Grad norm: 4.385408152281005\n",
      "Epoch 636, Loss: 215.726901487488, Neurons: 201, Grad norm: 4.385408152281005\n",
      "Epoch 637, Loss: 215.7201127173786, Neurons: 201, Grad norm: 4.37866014038719\n",
      "Epoch 637, Loss: 215.7201127173786, Neurons: 201, Grad norm: 4.37866014038719\n",
      "Epoch 638, Loss: 215.71334392670042, Neurons: 201, Grad norm: 4.3736772941448905\n",
      "Epoch 638, Loss: 215.71334392670042, Neurons: 201, Grad norm: 4.3736772941448905\n",
      "Epoch 639, Loss: 215.70660539339508, Neurons: 201, Grad norm: 4.373748232146339\n",
      "Epoch 639, Loss: 215.70660539339508, Neurons: 201, Grad norm: 4.373748232146339\n",
      "Epoch 640, Loss: 215.69989141178962, Neurons: 201, Grad norm: 4.368384873680778\n",
      "Epoch 640, Loss: 215.69989141178962, Neurons: 201, Grad norm: 4.368384873680778\n",
      "Epoch 641, Loss: 215.69318536486375, Neurons: 201, Grad norm: 4.357313366266352\n",
      "Epoch 641, Loss: 215.69318536486375, Neurons: 201, Grad norm: 4.357313366266352\n",
      "Epoch 642, Loss: 215.68649685071838, Neurons: 201, Grad norm: 4.357951520320748\n",
      "Epoch 642, Loss: 215.68649685071838, Neurons: 201, Grad norm: 4.357951520320748\n",
      "Epoch 643, Loss: 215.67982506537103, Neurons: 201, Grad norm: 4.351699265256396\n",
      "Epoch 643, Loss: 215.67982506537103, Neurons: 201, Grad norm: 4.351699265256396\n",
      "Epoch 644, Loss: 215.67315249898508, Neurons: 201, Grad norm: 4.349412599341814\n",
      "Epoch 644, Loss: 215.67315249898508, Neurons: 201, Grad norm: 4.349412599341814\n",
      "Epoch 645, Loss: 215.66650182550435, Neurons: 201, Grad norm: 4.348118552608751\n",
      "Epoch 645, Loss: 215.66650182550435, Neurons: 201, Grad norm: 4.348118552608751\n",
      "Epoch 646, Loss: 215.6598408240458, Neurons: 201, Grad norm: 4.344110387081513\n",
      "Epoch 646, Loss: 215.6598408240458, Neurons: 201, Grad norm: 4.344110387081513\n",
      "Epoch 647, Loss: 215.65317598107478, Neurons: 201, Grad norm: 4.341845124151711\n",
      "Epoch 647, Loss: 215.65317598107478, Neurons: 201, Grad norm: 4.341845124151711\n",
      "Epoch 648, Loss: 215.6465228785513, Neurons: 201, Grad norm: 4.337630886217327\n",
      "Epoch 648, Loss: 215.6465228785513, Neurons: 201, Grad norm: 4.337630886217327\n",
      "Epoch 649, Loss: 215.63986481702415, Neurons: 201, Grad norm: 4.334593130323158\n",
      "Epoch 649, Loss: 215.63986481702415, Neurons: 201, Grad norm: 4.334593130323158\n",
      "Epoch 650, Loss: 215.63320262880842, Neurons: 201, Grad norm: 4.3274670325056555\n",
      "Epoch 650, Loss: 215.63320262880842, Neurons: 201, Grad norm: 4.3274670325056555\n",
      "Epoch 651, Loss: 215.62655600047165, Neurons: 201, Grad norm: 4.332305981348298\n",
      "Epoch 651, Loss: 215.62655600047165, Neurons: 201, Grad norm: 4.332305981348298\n",
      "Epoch 652, Loss: 215.61987611654828, Neurons: 201, Grad norm: 4.330645710311558\n",
      "Epoch 652, Loss: 215.61987611654828, Neurons: 201, Grad norm: 4.330645710311558\n",
      "Epoch 653, Loss: 215.61316168849822, Neurons: 201, Grad norm: 4.325565234825384\n",
      "Epoch 653, Loss: 215.61316168849822, Neurons: 201, Grad norm: 4.325565234825384\n",
      "Epoch 654, Loss: 215.6064344464621, Neurons: 201, Grad norm: 4.32477051875064\n",
      "Epoch 654, Loss: 215.6064344464621, Neurons: 201, Grad norm: 4.32477051875064\n",
      "Epoch 655, Loss: 215.59970134564693, Neurons: 201, Grad norm: 4.322261579326677\n",
      "Epoch 655, Loss: 215.59970134564693, Neurons: 201, Grad norm: 4.322261579326677\n",
      "Epoch 656, Loss: 215.5929513519651, Neurons: 201, Grad norm: 4.320461667665696\n",
      "Epoch 656, Loss: 215.5929513519651, Neurons: 201, Grad norm: 4.320461667665696\n",
      "Epoch 657, Loss: 215.58618340238635, Neurons: 201, Grad norm: 4.319433015836383\n",
      "Epoch 657, Loss: 215.58618340238635, Neurons: 201, Grad norm: 4.319433015836383\n",
      "Epoch 658, Loss: 215.57940674003777, Neurons: 201, Grad norm: 4.321148985680964\n",
      "Epoch 658, Loss: 215.57940674003777, Neurons: 201, Grad norm: 4.321148985680964\n",
      "Epoch 659, Loss: 215.57262583158922, Neurons: 201, Grad norm: 4.3226684523716585\n",
      "Epoch 659, Loss: 215.57262583158922, Neurons: 201, Grad norm: 4.3226684523716585\n",
      "Epoch 660, Loss: 215.56582681332944, Neurons: 201, Grad norm: 4.318616329853611\n",
      "Epoch 660, Loss: 215.56582681332944, Neurons: 201, Grad norm: 4.318616329853611\n",
      "Epoch 661, Loss: 215.55901686004066, Neurons: 201, Grad norm: 4.317809753588833\n",
      "Epoch 661, Loss: 215.55901686004066, Neurons: 201, Grad norm: 4.317809753588833\n",
      "Epoch 662, Loss: 215.55220656459332, Neurons: 201, Grad norm: 4.31803430758369\n",
      "Epoch 662, Loss: 215.55220656459332, Neurons: 201, Grad norm: 4.31803430758369\n",
      "Epoch 663, Loss: 215.5453841358681, Neurons: 201, Grad norm: 4.319589683100435\n",
      "Epoch 663, Loss: 215.5453841358681, Neurons: 201, Grad norm: 4.319589683100435\n",
      "Epoch 664, Loss: 215.53855296318443, Neurons: 201, Grad norm: 4.314465467894708\n",
      "Epoch 664, Loss: 215.53855296318443, Neurons: 201, Grad norm: 4.314465467894708\n",
      "Epoch 665, Loss: 215.53171953957437, Neurons: 201, Grad norm: 4.315443464246695\n",
      "Epoch 665, Loss: 215.53171953957437, Neurons: 201, Grad norm: 4.315443464246695\n",
      "Epoch 666, Loss: 215.52490291349199, Neurons: 201, Grad norm: 4.316987821119405\n",
      "Epoch 666, Loss: 215.52490291349199, Neurons: 201, Grad norm: 4.316987821119405\n",
      "Epoch 667, Loss: 215.51807848978893, Neurons: 201, Grad norm: 4.318862232841677\n",
      "Epoch 667, Loss: 215.51807848978893, Neurons: 201, Grad norm: 4.318862232841677\n",
      "Epoch 668, Loss: 215.51123944582415, Neurons: 201, Grad norm: 4.320786034246373\n",
      "Epoch 668, Loss: 215.51123944582415, Neurons: 201, Grad norm: 4.320786034246373\n",
      "Epoch 669, Loss: 215.50441712147042, Neurons: 201, Grad norm: 4.322559300250648\n",
      "Epoch 669, Loss: 215.50441712147042, Neurons: 201, Grad norm: 4.322559300250648\n",
      "Epoch 670, Loss: 215.4976109294558, Neurons: 201, Grad norm: 4.327416577477706\n",
      "Epoch 670, Loss: 215.4976109294558, Neurons: 201, Grad norm: 4.327416577477706\n",
      "Epoch 671, Loss: 215.4907934420393, Neurons: 201, Grad norm: 4.3278088978544105\n",
      "Epoch 671, Loss: 215.4907934420393, Neurons: 201, Grad norm: 4.3278088978544105\n",
      "Epoch 672, Loss: 215.48399070286874, Neurons: 201, Grad norm: 4.330261817698186\n",
      "Epoch 672, Loss: 215.48399070286874, Neurons: 201, Grad norm: 4.330261817698186\n",
      "Epoch 673, Loss: 215.47719766924342, Neurons: 201, Grad norm: 4.331892361244648\n",
      "Epoch 673, Loss: 215.47719766924342, Neurons: 201, Grad norm: 4.331892361244648\n",
      "Epoch 674, Loss: 215.47039510769764, Neurons: 201, Grad norm: 4.32824938687755\n",
      "Epoch 674, Loss: 215.47039510769764, Neurons: 201, Grad norm: 4.32824938687755\n",
      "Epoch 675, Loss: 215.46362550624366, Neurons: 201, Grad norm: 4.328551554851042\n",
      "Epoch 675, Loss: 215.46362550624366, Neurons: 201, Grad norm: 4.328551554851042\n",
      "Epoch 676, Loss: 215.45689944435753, Neurons: 201, Grad norm: 4.322531057106421\n",
      "Epoch 676, Loss: 215.45689944435753, Neurons: 201, Grad norm: 4.322531057106421\n",
      "Epoch 677, Loss: 215.4502202074569, Neurons: 201, Grad norm: 4.320047763255606\n",
      "Epoch 677, Loss: 215.4502202074569, Neurons: 201, Grad norm: 4.320047763255606\n",
      "Epoch 678, Loss: 215.44360622592572, Neurons: 201, Grad norm: 4.3132135788767805\n",
      "Epoch 678, Loss: 215.44360622592572, Neurons: 201, Grad norm: 4.3132135788767805\n",
      "Epoch 679, Loss: 215.43703232617204, Neurons: 201, Grad norm: 4.305639148468294\n",
      "Epoch 679, Loss: 215.43703232617204, Neurons: 201, Grad norm: 4.305639148468294\n",
      "Epoch 680, Loss: 215.4304735513292, Neurons: 201, Grad norm: 4.299673716258472\n",
      "Epoch 680, Loss: 215.4304735513292, Neurons: 201, Grad norm: 4.299673716258472\n",
      "Epoch 681, Loss: 215.42390042342183, Neurons: 201, Grad norm: 4.290361021919182\n",
      "Epoch 681, Loss: 215.42390042342183, Neurons: 201, Grad norm: 4.290361021919182\n",
      "Epoch 682, Loss: 215.41733662470898, Neurons: 201, Grad norm: 4.2827362886516935\n",
      "Epoch 682, Loss: 215.41733662470898, Neurons: 201, Grad norm: 4.2827362886516935\n",
      "Epoch 683, Loss: 215.41077436497483, Neurons: 201, Grad norm: 4.272386662061764\n",
      "Epoch 683, Loss: 215.41077436497483, Neurons: 201, Grad norm: 4.272386662061764\n",
      "Epoch 684, Loss: 215.40422965329586, Neurons: 201, Grad norm: 4.268404947350497\n",
      "Epoch 684, Loss: 215.40422965329586, Neurons: 201, Grad norm: 4.268404947350497\n",
      "Epoch 685, Loss: 215.39769634175522, Neurons: 201, Grad norm: 4.2629278142170515\n",
      "Epoch 685, Loss: 215.39769634175522, Neurons: 201, Grad norm: 4.2629278142170515\n",
      "Epoch 686, Loss: 215.39118481789689, Neurons: 201, Grad norm: 4.255693077301869\n",
      "Epoch 686, Loss: 215.39118481789689, Neurons: 201, Grad norm: 4.255693077301869\n",
      "Epoch 687, Loss: 215.38470143675943, Neurons: 201, Grad norm: 4.25534448351315\n",
      "Epoch 687, Loss: 215.38470143675943, Neurons: 201, Grad norm: 4.25534448351315\n",
      "Epoch 688, Loss: 215.37825398726537, Neurons: 201, Grad norm: 4.250655766627859\n",
      "Epoch 688, Loss: 215.37825398726537, Neurons: 201, Grad norm: 4.250655766627859\n",
      "Epoch 689, Loss: 215.3718187875312, Neurons: 201, Grad norm: 4.249820136585281\n",
      "Epoch 689, Loss: 215.3718187875312, Neurons: 201, Grad norm: 4.249820136585281\n",
      "Epoch 690, Loss: 215.3653937790983, Neurons: 201, Grad norm: 4.242693880519462\n",
      "Epoch 690, Loss: 215.3653937790983, Neurons: 201, Grad norm: 4.242693880519462\n",
      "Epoch 691, Loss: 215.35898911383848, Neurons: 201, Grad norm: 4.241878379376514\n",
      "Epoch 691, Loss: 215.35898911383848, Neurons: 201, Grad norm: 4.241878379376514\n",
      "Epoch 692, Loss: 215.35261430450805, Neurons: 201, Grad norm: 4.241004196013086\n",
      "Epoch 692, Loss: 215.35261430450805, Neurons: 201, Grad norm: 4.241004196013086\n",
      "Epoch 693, Loss: 215.3462577090512, Neurons: 201, Grad norm: 4.2425969289569965\n",
      "Epoch 693, Loss: 215.3462577090512, Neurons: 201, Grad norm: 4.2425969289569965\n",
      "Epoch 694, Loss: 215.33990628255506, Neurons: 201, Grad norm: 4.2418264452556365\n",
      "Epoch 694, Loss: 215.33990628255506, Neurons: 201, Grad norm: 4.2418264452556365\n",
      "Epoch 695, Loss: 215.33356589995051, Neurons: 201, Grad norm: 4.238689324464492\n",
      "Epoch 695, Loss: 215.33356589995051, Neurons: 201, Grad norm: 4.238689324464492\n",
      "Epoch 696, Loss: 215.3272550147395, Neurons: 201, Grad norm: 4.235116958591418\n",
      "Epoch 696, Loss: 215.3272550147395, Neurons: 201, Grad norm: 4.235116958591418\n",
      "Epoch 697, Loss: 215.3209583341363, Neurons: 201, Grad norm: 4.2292987313378285\n",
      "Epoch 697, Loss: 215.3209583341363, Neurons: 201, Grad norm: 4.2292987313378285\n",
      "Epoch 698, Loss: 215.31466905432458, Neurons: 201, Grad norm: 4.2266907343499\n",
      "Epoch 698, Loss: 215.31466905432458, Neurons: 201, Grad norm: 4.2266907343499\n",
      "Epoch 699, Loss: 215.30837266906823, Neurons: 201, Grad norm: 4.220115213841177\n",
      "Epoch 699, Loss: 215.30837266906823, Neurons: 201, Grad norm: 4.220115213841177\n",
      "Epoch 700, Loss: 215.30206509670086, Neurons: 201, Grad norm: 4.210507897353522\n",
      "Epoch 700, Loss: 215.30206509670086, Neurons: 201, Grad norm: 4.210507897353522\n",
      "Epoch 701, Loss: 215.29575214199483, Neurons: 201, Grad norm: 4.200522074959203\n",
      "Epoch 701, Loss: 215.29575214199483, Neurons: 201, Grad norm: 4.200522074959203\n",
      "Epoch 702, Loss: 215.28946145972054, Neurons: 201, Grad norm: 4.186908982480707\n",
      "Epoch 702, Loss: 215.28946145972054, Neurons: 201, Grad norm: 4.186908982480707\n",
      "Epoch 703, Loss: 215.28319535925277, Neurons: 201, Grad norm: 4.1746938216292016\n",
      "Epoch 703, Loss: 215.28319535925277, Neurons: 201, Grad norm: 4.1746938216292016\n",
      "Epoch 704, Loss: 215.27695294092103, Neurons: 201, Grad norm: 4.165067619620522\n",
      "Epoch 704, Loss: 215.27695294092103, Neurons: 201, Grad norm: 4.165067619620522\n",
      "Epoch 705, Loss: 215.27074444761135, Neurons: 201, Grad norm: 4.159086362991825\n",
      "Epoch 705, Loss: 215.27074444761135, Neurons: 201, Grad norm: 4.159086362991825\n",
      "Epoch 706, Loss: 215.26454438244554, Neurons: 201, Grad norm: 4.154368535871974\n",
      "Epoch 706, Loss: 215.26454438244554, Neurons: 201, Grad norm: 4.154368535871974\n",
      "Epoch 707, Loss: 215.25833894042322, Neurons: 201, Grad norm: 4.143845340914843\n",
      "Epoch 707, Loss: 215.25833894042322, Neurons: 201, Grad norm: 4.143845340914843\n",
      "Epoch 708, Loss: 215.25216088681583, Neurons: 201, Grad norm: 4.135679475217314\n",
      "Epoch 708, Loss: 215.25216088681583, Neurons: 201, Grad norm: 4.135679475217314\n",
      "Epoch 709, Loss: 215.24600672022103, Neurons: 201, Grad norm: 4.13270537463378\n",
      "Epoch 709, Loss: 215.24600672022103, Neurons: 201, Grad norm: 4.13270537463378\n",
      "Epoch 710, Loss: 215.2398574370607, Neurons: 201, Grad norm: 4.124240686810067\n",
      "Epoch 710, Loss: 215.2398574370607, Neurons: 201, Grad norm: 4.124240686810067\n",
      "Epoch 711, Loss: 215.23373860221812, Neurons: 201, Grad norm: 4.11882925598053\n",
      "Epoch 711, Loss: 215.23373860221812, Neurons: 201, Grad norm: 4.11882925598053\n",
      "Epoch 712, Loss: 215.22767766416305, Neurons: 201, Grad norm: 4.118342359777888\n",
      "Epoch 712, Loss: 215.22767766416305, Neurons: 201, Grad norm: 4.118342359777888\n",
      "Epoch 713, Loss: 215.22162180170258, Neurons: 201, Grad norm: 4.113127365174709\n",
      "Epoch 713, Loss: 215.22162180170258, Neurons: 201, Grad norm: 4.113127365174709\n",
      "Epoch 714, Loss: 215.2155935988048, Neurons: 201, Grad norm: 4.105366234221258\n",
      "Epoch 714, Loss: 215.2155935988048, Neurons: 201, Grad norm: 4.105366234221258\n",
      "Epoch 715, Loss: 215.2095912560949, Neurons: 201, Grad norm: 4.094967319486841\n",
      "Epoch 715, Loss: 215.2095912560949, Neurons: 201, Grad norm: 4.094967319486841\n",
      "Epoch 716, Loss: 215.20364127043834, Neurons: 201, Grad norm: 4.087251282113245\n",
      "Epoch 716, Loss: 215.20364127043834, Neurons: 201, Grad norm: 4.087251282113245\n",
      "Epoch 717, Loss: 215.19772264145456, Neurons: 201, Grad norm: 4.0730997396003765\n",
      "Epoch 717, Loss: 215.19772264145456, Neurons: 201, Grad norm: 4.0730997396003765\n",
      "Epoch 718, Loss: 215.19181872855106, Neurons: 201, Grad norm: 4.064857198245837\n",
      "Epoch 718, Loss: 215.19181872855106, Neurons: 201, Grad norm: 4.064857198245837\n",
      "Epoch 719, Loss: 215.1859319695997, Neurons: 201, Grad norm: 4.052528374623924\n",
      "Epoch 719, Loss: 215.1859319695997, Neurons: 201, Grad norm: 4.052528374623924\n",
      "Epoch 720, Loss: 215.18005069182215, Neurons: 201, Grad norm: 4.04082019153828\n",
      "Epoch 720, Loss: 215.18005069182215, Neurons: 201, Grad norm: 4.04082019153828\n",
      "Epoch 721, Loss: 215.17416688512597, Neurons: 201, Grad norm: 4.028693326175494\n",
      "Epoch 721, Loss: 215.17416688512597, Neurons: 201, Grad norm: 4.028693326175494\n",
      "Epoch 722, Loss: 215.16827432074467, Neurons: 201, Grad norm: 4.015685226796706\n",
      "Epoch 722, Loss: 215.16827432074467, Neurons: 201, Grad norm: 4.015685226796706\n",
      "Epoch 723, Loss: 215.1624012177559, Neurons: 201, Grad norm: 4.001347235553147\n",
      "Epoch 723, Loss: 215.1624012177559, Neurons: 201, Grad norm: 4.001347235553147\n",
      "Epoch 724, Loss: 215.1565511464862, Neurons: 201, Grad norm: 3.9917649131902104\n",
      "Epoch 724, Loss: 215.1565511464862, Neurons: 201, Grad norm: 3.9917649131902104\n",
      "Epoch 725, Loss: 215.1507248671251, Neurons: 201, Grad norm: 3.986650452673929\n",
      "Epoch 725, Loss: 215.1507248671251, Neurons: 201, Grad norm: 3.986650452673929\n",
      "Epoch 726, Loss: 215.14490393038497, Neurons: 201, Grad norm: 3.9820918421203833\n",
      "Epoch 726, Loss: 215.14490393038497, Neurons: 201, Grad norm: 3.9820918421203833\n",
      "Epoch 727, Loss: 215.13908195847353, Neurons: 201, Grad norm: 3.9794043052413204\n",
      "Epoch 727, Loss: 215.13908195847353, Neurons: 201, Grad norm: 3.9794043052413204\n",
      "Epoch 728, Loss: 215.1332580433342, Neurons: 201, Grad norm: 3.9758288904408405\n",
      "Epoch 728, Loss: 215.1332580433342, Neurons: 201, Grad norm: 3.9758288904408405\n",
      "Epoch 729, Loss: 215.1274247969359, Neurons: 201, Grad norm: 3.967948071998582\n",
      "Epoch 729, Loss: 215.1274247969359, Neurons: 201, Grad norm: 3.967948071998582\n",
      "Epoch 730, Loss: 215.12159877777114, Neurons: 201, Grad norm: 3.9620919009921494\n",
      "Epoch 730, Loss: 215.12159877777114, Neurons: 201, Grad norm: 3.9620919009921494\n",
      "Epoch 731, Loss: 215.11580510931543, Neurons: 201, Grad norm: 3.950581824653504\n",
      "Epoch 731, Loss: 215.11580510931543, Neurons: 201, Grad norm: 3.950581824653504\n",
      "Epoch 732, Loss: 215.11002796774818, Neurons: 201, Grad norm: 3.946083091056929\n",
      "Epoch 732, Loss: 215.11002796774818, Neurons: 201, Grad norm: 3.946083091056929\n",
      "Epoch 733, Loss: 215.10428650429517, Neurons: 201, Grad norm: 3.932714952569209\n",
      "Epoch 733, Loss: 215.10428650429517, Neurons: 201, Grad norm: 3.932714952569209\n",
      "Epoch 734, Loss: 215.09858311286155, Neurons: 201, Grad norm: 3.9254319475504973\n",
      "Epoch 734, Loss: 215.09858311286155, Neurons: 201, Grad norm: 3.9254319475504973\n",
      "Epoch 735, Loss: 215.09292805274143, Neurons: 201, Grad norm: 3.9224899391299317\n",
      "Epoch 735, Loss: 215.09292805274143, Neurons: 201, Grad norm: 3.9224899391299317\n",
      "Epoch 736, Loss: 215.0872984577411, Neurons: 201, Grad norm: 3.9204840154649405\n",
      "Epoch 736, Loss: 215.0872984577411, Neurons: 201, Grad norm: 3.9204840154649405\n",
      "Epoch 737, Loss: 215.08167884744705, Neurons: 201, Grad norm: 3.9186253643216338\n",
      "Epoch 737, Loss: 215.08167884744705, Neurons: 201, Grad norm: 3.9186253643216338\n",
      "Epoch 738, Loss: 215.0760718852099, Neurons: 201, Grad norm: 3.917796360595338\n",
      "Epoch 738, Loss: 215.0760718852099, Neurons: 201, Grad norm: 3.917796360595338\n",
      "Epoch 739, Loss: 215.07047652370514, Neurons: 201, Grad norm: 3.914657653167169\n",
      "Epoch 739, Loss: 215.07047652370514, Neurons: 201, Grad norm: 3.914657653167169\n",
      "Epoch 740, Loss: 215.06488302538781, Neurons: 201, Grad norm: 3.912101868907451\n",
      "Epoch 740, Loss: 215.06488302538781, Neurons: 201, Grad norm: 3.912101868907451\n",
      "Epoch 741, Loss: 215.0593164710196, Neurons: 201, Grad norm: 3.9096342436982927\n",
      "Epoch 741, Loss: 215.0593164710196, Neurons: 201, Grad norm: 3.9096342436982927\n",
      "Epoch 742, Loss: 215.05374198578298, Neurons: 201, Grad norm: 3.9031285181060484\n",
      "Epoch 742, Loss: 215.05374198578298, Neurons: 201, Grad norm: 3.9031285181060484\n",
      "Epoch 743, Loss: 215.04818100485963, Neurons: 201, Grad norm: 3.8989970054168253\n",
      "Epoch 743, Loss: 215.04818100485963, Neurons: 201, Grad norm: 3.8989970054168253\n",
      "Epoch 744, Loss: 215.04264116781277, Neurons: 201, Grad norm: 3.8935902747215825\n",
      "Epoch 744, Loss: 215.04264116781277, Neurons: 201, Grad norm: 3.8935902747215825\n",
      "Epoch 745, Loss: 215.03711061968576, Neurons: 201, Grad norm: 3.886967859488739\n",
      "Epoch 745, Loss: 215.03711061968576, Neurons: 201, Grad norm: 3.886967859488739\n",
      "Epoch 746, Loss: 215.03158901410217, Neurons: 201, Grad norm: 3.8784309829293324\n",
      "Epoch 746, Loss: 215.03158901410217, Neurons: 201, Grad norm: 3.8784309829293324\n",
      "Epoch 747, Loss: 215.02608865960715, Neurons: 201, Grad norm: 3.8725514377747743\n",
      "Epoch 747, Loss: 215.02608865960715, Neurons: 201, Grad norm: 3.8725514377747743\n",
      "Epoch 748, Loss: 215.02059579675247, Neurons: 201, Grad norm: 3.8591310250107735\n",
      "Epoch 748, Loss: 215.02059579675247, Neurons: 201, Grad norm: 3.8591310250107735\n",
      "Epoch 749, Loss: 215.01513258333839, Neurons: 201, Grad norm: 3.852757188629885\n",
      "Epoch 749, Loss: 215.01513258333839, Neurons: 201, Grad norm: 3.852757188629885\n",
      "Epoch 750, Loss: 215.00969954660317, Neurons: 201, Grad norm: 3.841370136889154\n",
      "Epoch 750, Loss: 215.00969954660317, Neurons: 201, Grad norm: 3.841370136889154\n",
      "Epoch 751, Loss: 215.0042879378473, Neurons: 201, Grad norm: 3.834296062975334\n",
      "Epoch 751, Loss: 215.0042879378473, Neurons: 201, Grad norm: 3.834296062975334\n",
      "Epoch 752, Loss: 214.99890426612853, Neurons: 201, Grad norm: 3.8284136934273265\n",
      "Epoch 752, Loss: 214.99890426612853, Neurons: 201, Grad norm: 3.8284136934273265\n",
      "Epoch 753, Loss: 214.99353643894395, Neurons: 201, Grad norm: 3.8234713707882038\n",
      "Epoch 753, Loss: 214.99353643894395, Neurons: 201, Grad norm: 3.8234713707882038\n",
      "Epoch 754, Loss: 214.98817198297974, Neurons: 201, Grad norm: 3.8157683999789507\n",
      "Epoch 754, Loss: 214.98817198297974, Neurons: 201, Grad norm: 3.8157683999789507\n",
      "Epoch 755, Loss: 214.98283490984625, Neurons: 201, Grad norm: 3.8135281494758364\n",
      "Epoch 755, Loss: 214.98283490984625, Neurons: 201, Grad norm: 3.8135281494758364\n",
      "Epoch 756, Loss: 214.9775057564592, Neurons: 201, Grad norm: 3.8101435946951265\n",
      "Epoch 756, Loss: 214.9775057564592, Neurons: 201, Grad norm: 3.8101435946951265\n",
      "Epoch 757, Loss: 214.9721918184206, Neurons: 201, Grad norm: 3.808374187950879\n",
      "Epoch 757, Loss: 214.9721918184206, Neurons: 201, Grad norm: 3.808374187950879\n",
      "Epoch 758, Loss: 214.96688926982887, Neurons: 201, Grad norm: 3.8077618919727185\n",
      "Epoch 758, Loss: 214.96688926982887, Neurons: 201, Grad norm: 3.8077618919727185\n",
      "Epoch 759, Loss: 214.96159241480603, Neurons: 201, Grad norm: 3.807362594091939\n",
      "Epoch 759, Loss: 214.96159241480603, Neurons: 201, Grad norm: 3.807362594091939\n",
      "Epoch 760, Loss: 214.95630212348266, Neurons: 201, Grad norm: 3.8046301740437998\n",
      "Epoch 760, Loss: 214.95630212348266, Neurons: 201, Grad norm: 3.8046301740437998\n",
      "Epoch 761, Loss: 214.9510109312989, Neurons: 201, Grad norm: 3.8040636047774585\n",
      "Epoch 761, Loss: 214.9510109312989, Neurons: 201, Grad norm: 3.8040636047774585\n",
      "Epoch 762, Loss: 214.94572233152604, Neurons: 201, Grad norm: 3.798125233793078\n",
      "Epoch 762, Loss: 214.94572233152604, Neurons: 201, Grad norm: 3.798125233793078\n",
      "Epoch 763, Loss: 214.94044452623208, Neurons: 201, Grad norm: 3.7929307042276137\n",
      "Epoch 763, Loss: 214.94044452623208, Neurons: 201, Grad norm: 3.7929307042276137\n",
      "Epoch 764, Loss: 214.93518442538883, Neurons: 201, Grad norm: 3.7847086228859896\n",
      "Epoch 764, Loss: 214.93518442538883, Neurons: 201, Grad norm: 3.7847086228859896\n",
      "Epoch 765, Loss: 214.92994055121304, Neurons: 201, Grad norm: 3.7796249009912186\n",
      "Epoch 765, Loss: 214.92994055121304, Neurons: 201, Grad norm: 3.7796249009912186\n",
      "Epoch 766, Loss: 214.92471126543938, Neurons: 201, Grad norm: 3.772189750795069\n",
      "Epoch 766, Loss: 214.92471126543938, Neurons: 201, Grad norm: 3.772189750795069\n",
      "Epoch 767, Loss: 214.91949905276184, Neurons: 201, Grad norm: 3.7653771448744386\n",
      "Epoch 767, Loss: 214.91949905276184, Neurons: 201, Grad norm: 3.7653771448744386\n",
      "Epoch 768, Loss: 214.9142995973618, Neurons: 201, Grad norm: 3.7565055335150856\n",
      "Epoch 768, Loss: 214.9142995973618, Neurons: 201, Grad norm: 3.7565055335150856\n",
      "Epoch 769, Loss: 214.90909912619793, Neurons: 201, Grad norm: 3.7449133521792386\n",
      "Epoch 769, Loss: 214.90909912619793, Neurons: 201, Grad norm: 3.7449133521792386\n",
      "Epoch 770, Loss: 214.903911846997, Neurons: 201, Grad norm: 3.7377024693042538\n",
      "Epoch 770, Loss: 214.903911846997, Neurons: 201, Grad norm: 3.7377024693042538\n",
      "Epoch 771, Loss: 214.8987360345514, Neurons: 201, Grad norm: 3.7308919216560397\n",
      "Epoch 771, Loss: 214.8987360345514, Neurons: 201, Grad norm: 3.7308919216560397\n",
      "Epoch 772, Loss: 214.89356018787365, Neurons: 201, Grad norm: 3.723051540158202\n",
      "Epoch 772, Loss: 214.89356018787365, Neurons: 201, Grad norm: 3.723051540158202\n",
      "Epoch 773, Loss: 214.88838626493242, Neurons: 201, Grad norm: 3.7176936676378936\n",
      "Epoch 773, Loss: 214.88838626493242, Neurons: 201, Grad norm: 3.7176936676378936\n",
      "Epoch 774, Loss: 214.88320817886887, Neurons: 201, Grad norm: 3.71174700093427\n",
      "Epoch 774, Loss: 214.88320817886887, Neurons: 201, Grad norm: 3.71174700093427\n",
      "Epoch 775, Loss: 214.8780323564614, Neurons: 201, Grad norm: 3.7088681594971877\n",
      "Epoch 775, Loss: 214.8780323564614, Neurons: 201, Grad norm: 3.7088681594971877\n",
      "Epoch 776, Loss: 214.87285825534929, Neurons: 201, Grad norm: 3.704122850717337\n",
      "Epoch 776, Loss: 214.87285825534929, Neurons: 201, Grad norm: 3.704122850717337\n",
      "Epoch 777, Loss: 214.86768624416962, Neurons: 201, Grad norm: 3.7014733948011203\n",
      "Epoch 777, Loss: 214.86768624416962, Neurons: 201, Grad norm: 3.7014733948011203\n",
      "Epoch 778, Loss: 214.86253119659196, Neurons: 201, Grad norm: 3.6963067286923903\n",
      "Epoch 778, Loss: 214.86253119659196, Neurons: 201, Grad norm: 3.6963067286923903\n",
      "Epoch 779, Loss: 214.8573924083303, Neurons: 201, Grad norm: 3.6916153926334325\n",
      "Epoch 779, Loss: 214.8573924083303, Neurons: 201, Grad norm: 3.6916153926334325\n",
      "Epoch 780, Loss: 214.85227131548135, Neurons: 201, Grad norm: 3.6913230281120337\n",
      "Epoch 780, Loss: 214.85227131548135, Neurons: 201, Grad norm: 3.6913230281120337\n",
      "Epoch 781, Loss: 214.84715157148116, Neurons: 201, Grad norm: 3.6930284417284764\n",
      "Epoch 781, Loss: 214.84715157148116, Neurons: 201, Grad norm: 3.6930284417284764\n",
      "Epoch 782, Loss: 214.8420324146184, Neurons: 201, Grad norm: 3.6922894024499824\n",
      "Epoch 782, Loss: 214.8420324146184, Neurons: 201, Grad norm: 3.6922894024499824\n",
      "Epoch 783, Loss: 214.836915701977, Neurons: 201, Grad norm: 3.6945982747846493\n",
      "Epoch 783, Loss: 214.836915701977, Neurons: 201, Grad norm: 3.6945982747846493\n",
      "Epoch 784, Loss: 214.83181924193732, Neurons: 201, Grad norm: 3.6952164167567654\n",
      "Epoch 784, Loss: 214.83181924193732, Neurons: 201, Grad norm: 3.6952164167567654\n",
      "Epoch 785, Loss: 214.82672721923774, Neurons: 201, Grad norm: 3.693919500139288\n",
      "Epoch 785, Loss: 214.82672721923774, Neurons: 201, Grad norm: 3.693919500139288\n",
      "Epoch 786, Loss: 214.8216558939779, Neurons: 201, Grad norm: 3.692417518858952\n",
      "Epoch 786, Loss: 214.8216558939779, Neurons: 201, Grad norm: 3.692417518858952\n",
      "Epoch 787, Loss: 214.8166023183462, Neurons: 201, Grad norm: 3.6918129984585155\n",
      "Epoch 787, Loss: 214.8166023183462, Neurons: 201, Grad norm: 3.6918129984585155\n",
      "Epoch 788, Loss: 214.81155603309526, Neurons: 201, Grad norm: 3.69135001953769\n",
      "Epoch 788, Loss: 214.81155603309526, Neurons: 201, Grad norm: 3.69135001953769\n",
      "Epoch 789, Loss: 214.8065074071336, Neurons: 201, Grad norm: 3.6894769470328446\n",
      "Epoch 789, Loss: 214.8065074071336, Neurons: 201, Grad norm: 3.6894769470328446\n",
      "Epoch 790, Loss: 214.8014575929576, Neurons: 201, Grad norm: 3.6838573808094495\n",
      "Epoch 790, Loss: 214.8014575929576, Neurons: 201, Grad norm: 3.6838573808094495\n",
      "Epoch 791, Loss: 214.79641085426755, Neurons: 201, Grad norm: 3.6821011653106224\n",
      "Epoch 791, Loss: 214.79641085426755, Neurons: 201, Grad norm: 3.6821011653106224\n",
      "Epoch 792, Loss: 214.79137890628073, Neurons: 201, Grad norm: 3.694836618779402\n",
      "Epoch 792, Loss: 214.79137890628073, Neurons: 201, Grad norm: 3.694836618779402\n",
      "Epoch 793, Loss: 214.7862633030452, Neurons: 201, Grad norm: 3.739314202568825\n",
      "Epoch 793, Loss: 214.7862633030452, Neurons: 201, Grad norm: 3.739314202568825\n",
      "Epoch 794, Loss: 214.78082110351608, Neurons: 201, Grad norm: 3.817758047192691\n",
      "Epoch 794, Loss: 214.78082110351608, Neurons: 201, Grad norm: 3.817758047192691\n",
      "Epoch 795, Loss: 214.7744016395782, Neurons: 201, Grad norm: 3.927008042724475\n",
      "Epoch 795, Loss: 214.7744016395782, Neurons: 201, Grad norm: 3.927008042724475\n",
      "Epoch 796, Loss: 214.76797229941283, Neurons: 201, Grad norm: 4.075653724579083\n",
      "Epoch 796, Loss: 214.76797229941283, Neurons: 201, Grad norm: 4.075653724579083\n",
      "Epoch 797, Loss: 214.76229431332115, Neurons: 201, Grad norm: 4.1896525111452565\n",
      "Epoch 797, Loss: 214.76229431332115, Neurons: 201, Grad norm: 4.1896525111452565\n",
      "Epoch 798, Loss: 214.75704545967076, Neurons: 201, Grad norm: 4.21112844434155\n",
      "Epoch 798, Loss: 214.75704545967076, Neurons: 201, Grad norm: 4.21112844434155\n",
      "Epoch 799, Loss: 214.75195803319966, Neurons: 201, Grad norm: 4.134082149339806\n",
      "Epoch 799, Loss: 214.75195803319966, Neurons: 201, Grad norm: 4.134082149339806\n",
      "Epoch 800, Loss: 214.7467903558056, Neurons: 201, Grad norm: 3.979565974226171\n",
      "Epoch 800, Loss: 214.7467903558056, Neurons: 201, Grad norm: 3.979565974226171\n",
      "Epoch 801, Loss: 214.74155555181454, Neurons: 201, Grad norm: 3.8056460401046945\n",
      "Epoch 801, Loss: 214.74155555181454, Neurons: 201, Grad norm: 3.8056460401046945\n",
      "Epoch 802, Loss: 214.7363336123136, Neurons: 201, Grad norm: 3.653801215825476\n",
      "Epoch 802, Loss: 214.7363336123136, Neurons: 201, Grad norm: 3.653801215825476\n",
      "Epoch 803, Loss: 214.7311585549044, Neurons: 201, Grad norm: 3.5526950507797723\n",
      "Epoch 803, Loss: 214.7311585549044, Neurons: 201, Grad norm: 3.5526950507797723\n",
      "Epoch 804, Loss: 214.72604336140176, Neurons: 201, Grad norm: 3.504901615021828\n",
      "Epoch 804, Loss: 214.72604336140176, Neurons: 201, Grad norm: 3.504901615021828\n",
      "Epoch 805, Loss: 214.72097429205286, Neurons: 201, Grad norm: 3.4896673849904603\n",
      "Epoch 805, Loss: 214.72097429205286, Neurons: 201, Grad norm: 3.4896673849904603\n",
      "Epoch 806, Loss: 214.71590042081573, Neurons: 201, Grad norm: 3.481660148844073\n",
      "Epoch 806, Loss: 214.71590042081573, Neurons: 201, Grad norm: 3.481660148844073\n",
      "Epoch 807, Loss: 214.71075098969658, Neurons: 201, Grad norm: 3.4709678862715374\n",
      "Epoch 807, Loss: 214.71075098969658, Neurons: 201, Grad norm: 3.4709678862715374\n",
      "Epoch 808, Loss: 214.70550792301185, Neurons: 201, Grad norm: 3.461647219636556\n",
      "Epoch 808, Loss: 214.70550792301185, Neurons: 201, Grad norm: 3.461647219636556\n",
      "Epoch 809, Loss: 214.70019502907724, Neurons: 201, Grad norm: 3.469678105454236\n",
      "Epoch 809, Loss: 214.70019502907724, Neurons: 201, Grad norm: 3.469678105454236\n",
      "Epoch 810, Loss: 214.6948629207392, Neurons: 201, Grad norm: 3.50472642766721\n",
      "Epoch 810, Loss: 214.6948629207392, Neurons: 201, Grad norm: 3.50472642766721\n",
      "Epoch 811, Loss: 214.68957268134025, Neurons: 201, Grad norm: 3.568114162607666\n",
      "Epoch 811, Loss: 214.68957268134025, Neurons: 201, Grad norm: 3.568114162607666\n",
      "Epoch 812, Loss: 214.68434593458434, Neurons: 201, Grad norm: 3.6466560769802383\n",
      "Epoch 812, Loss: 214.68434593458434, Neurons: 201, Grad norm: 3.6466560769802383\n",
      "Epoch 813, Loss: 214.67922227625215, Neurons: 201, Grad norm: 3.726253047776314\n",
      "Epoch 813, Loss: 214.67922227625215, Neurons: 201, Grad norm: 3.726253047776314\n",
      "Epoch 814, Loss: 214.67417318853805, Neurons: 201, Grad norm: 3.7889985191890374\n",
      "Epoch 814, Loss: 214.67417318853805, Neurons: 201, Grad norm: 3.7889985191890374\n",
      "Epoch 815, Loss: 214.66910596278848, Neurons: 201, Grad norm: 3.8234596917996955\n",
      "Epoch 815, Loss: 214.66910596278848, Neurons: 201, Grad norm: 3.8234596917996955\n",
      "Epoch 816, Loss: 214.663985289172, Neurons: 201, Grad norm: 3.8227402234293106\n",
      "Epoch 816, Loss: 214.663985289172, Neurons: 201, Grad norm: 3.8227402234293106\n",
      "Epoch 817, Loss: 214.65885777275335, Neurons: 201, Grad norm: 3.797978811388507\n",
      "Epoch 817, Loss: 214.65885777275335, Neurons: 201, Grad norm: 3.797978811388507\n",
      "Epoch 818, Loss: 214.65375839920887, Neurons: 201, Grad norm: 3.756748112500735\n",
      "Epoch 818, Loss: 214.65375839920887, Neurons: 201, Grad norm: 3.756748112500735\n",
      "Epoch 819, Loss: 214.64867648309234, Neurons: 201, Grad norm: 3.70490233174594\n",
      "Epoch 819, Loss: 214.64867648309234, Neurons: 201, Grad norm: 3.70490233174594\n",
      "Epoch 820, Loss: 214.64360606697275, Neurons: 201, Grad norm: 3.65657428976604\n",
      "Epoch 820, Loss: 214.64360606697275, Neurons: 201, Grad norm: 3.65657428976604\n",
      "Epoch 821, Loss: 214.63853304430248, Neurons: 201, Grad norm: 3.6127684244238756\n",
      "Epoch 821, Loss: 214.63853304430248, Neurons: 201, Grad norm: 3.6127684244238756\n",
      "Epoch 822, Loss: 214.63345562856705, Neurons: 201, Grad norm: 3.5804714749159086\n",
      "Epoch 822, Loss: 214.63345562856705, Neurons: 201, Grad norm: 3.5804714749159086\n",
      "Epoch 823, Loss: 214.62837120049062, Neurons: 201, Grad norm: 3.5536243395875777\n",
      "Epoch 823, Loss: 214.62837120049062, Neurons: 201, Grad norm: 3.5536243395875777\n",
      "Epoch 824, Loss: 214.62328143506923, Neurons: 201, Grad norm: 3.535575725757221\n",
      "Epoch 824, Loss: 214.62328143506923, Neurons: 201, Grad norm: 3.535575725757221\n",
      "Epoch 825, Loss: 214.6182172913568, Neurons: 201, Grad norm: 3.5252873703365917\n",
      "Epoch 825, Loss: 214.6182172913568, Neurons: 201, Grad norm: 3.5252873703365917\n",
      "Epoch 826, Loss: 214.61317629873884, Neurons: 201, Grad norm: 3.526086684012671\n",
      "Epoch 826, Loss: 214.61317629873884, Neurons: 201, Grad norm: 3.526086684012671\n",
      "Epoch 827, Loss: 214.608158037511, Neurons: 201, Grad norm: 3.5312429351150323\n",
      "Epoch 827, Loss: 214.608158037511, Neurons: 201, Grad norm: 3.5312429351150323\n",
      "Epoch 828, Loss: 214.60316969800382, Neurons: 201, Grad norm: 3.5443974845057085\n",
      "Epoch 828, Loss: 214.60316969800382, Neurons: 201, Grad norm: 3.5443974845057085\n",
      "Epoch 829, Loss: 214.59819580701767, Neurons: 201, Grad norm: 3.5584794227958336\n",
      "Epoch 829, Loss: 214.59819580701767, Neurons: 201, Grad norm: 3.5584794227958336\n",
      "Epoch 830, Loss: 214.59321991921837, Neurons: 201, Grad norm: 3.5722195246754636\n",
      "Epoch 830, Loss: 214.59321991921837, Neurons: 201, Grad norm: 3.5722195246754636\n",
      "Epoch 831, Loss: 214.58823482686554, Neurons: 201, Grad norm: 3.5815274519847033\n",
      "Epoch 831, Loss: 214.58823482686554, Neurons: 201, Grad norm: 3.5815274519847033\n",
      "Epoch 832, Loss: 214.58325681999398, Neurons: 201, Grad norm: 3.5831566265971446\n",
      "Epoch 832, Loss: 214.58325681999398, Neurons: 201, Grad norm: 3.5831566265971446\n",
      "Epoch 833, Loss: 214.57828581009426, Neurons: 201, Grad norm: 3.5793345074878147\n",
      "Epoch 833, Loss: 214.57828581009426, Neurons: 201, Grad norm: 3.5793345074878147\n",
      "Epoch 834, Loss: 214.57332837190975, Neurons: 201, Grad norm: 3.568628843964915\n",
      "Epoch 834, Loss: 214.57332837190975, Neurons: 201, Grad norm: 3.568628843964915\n",
      "Epoch 835, Loss: 214.56838653628716, Neurons: 201, Grad norm: 3.5580976733184704\n",
      "Epoch 835, Loss: 214.56838653628716, Neurons: 201, Grad norm: 3.5580976733184704\n",
      "Epoch 836, Loss: 214.56345095562645, Neurons: 201, Grad norm: 3.54552153880323\n",
      "Epoch 836, Loss: 214.56345095562645, Neurons: 201, Grad norm: 3.54552153880323\n",
      "Epoch 837, Loss: 214.55851229641144, Neurons: 201, Grad norm: 3.5326464230707715\n",
      "Epoch 837, Loss: 214.55851229641144, Neurons: 201, Grad norm: 3.5326464230707715\n",
      "Epoch 838, Loss: 214.55357138163495, Neurons: 201, Grad norm: 3.518449385799788\n",
      "Epoch 838, Loss: 214.55357138163495, Neurons: 201, Grad norm: 3.518449385799788\n",
      "Epoch 839, Loss: 214.54863117647332, Neurons: 201, Grad norm: 3.501266807404399\n",
      "Epoch 839, Loss: 214.54863117647332, Neurons: 201, Grad norm: 3.501266807404399\n",
      "Epoch 840, Loss: 214.54370988205247, Neurons: 201, Grad norm: 3.4915271985802203\n",
      "Epoch 840, Loss: 214.54370988205247, Neurons: 201, Grad norm: 3.4915271985802203\n",
      "Epoch 841, Loss: 214.5387993491736, Neurons: 201, Grad norm: 3.4832927156148035\n",
      "Epoch 841, Loss: 214.5387993491736, Neurons: 201, Grad norm: 3.4832927156148035\n",
      "Epoch 842, Loss: 214.53388966600878, Neurons: 201, Grad norm: 3.4739186119412544\n",
      "Epoch 842, Loss: 214.53388966600878, Neurons: 201, Grad norm: 3.4739186119412544\n",
      "Epoch 843, Loss: 214.52897585564435, Neurons: 201, Grad norm: 3.4618625220861476\n",
      "Epoch 843, Loss: 214.52897585564435, Neurons: 201, Grad norm: 3.4618625220861476\n",
      "Epoch 844, Loss: 214.5240741610811, Neurons: 201, Grad norm: 3.4500455944273734\n",
      "Epoch 844, Loss: 214.5240741610811, Neurons: 201, Grad norm: 3.4500455944273734\n",
      "Epoch 845, Loss: 214.5191897575761, Neurons: 201, Grad norm: 3.4419043921275843\n",
      "Epoch 845, Loss: 214.5191897575761, Neurons: 201, Grad norm: 3.4419043921275843\n",
      "Epoch 846, Loss: 214.51432835998529, Neurons: 201, Grad norm: 3.4360045947958167\n",
      "Epoch 846, Loss: 214.51432835998529, Neurons: 201, Grad norm: 3.4360045947958167\n",
      "Epoch 847, Loss: 214.50948153424943, Neurons: 201, Grad norm: 3.4322463291274494\n",
      "Epoch 847, Loss: 214.50948153424943, Neurons: 201, Grad norm: 3.4322463291274494\n",
      "Epoch 848, Loss: 214.50462948011275, Neurons: 201, Grad norm: 3.4280897488111464\n",
      "Epoch 848, Loss: 214.50462948011275, Neurons: 201, Grad norm: 3.4280897488111464\n",
      "Epoch 849, Loss: 214.4997772045722, Neurons: 201, Grad norm: 3.424957438739576\n",
      "Epoch 849, Loss: 214.4997772045722, Neurons: 201, Grad norm: 3.424957438739576\n",
      "Epoch 850, Loss: 214.49492871735063, Neurons: 201, Grad norm: 3.421125322148313\n",
      "Epoch 850, Loss: 214.49492871735063, Neurons: 201, Grad norm: 3.421125322148313\n",
      "Epoch 851, Loss: 214.49007465771462, Neurons: 201, Grad norm: 3.419518774904201\n",
      "Epoch 851, Loss: 214.49007465771462, Neurons: 201, Grad norm: 3.419518774904201\n",
      "Epoch 852, Loss: 214.48521893254994, Neurons: 201, Grad norm: 3.416574895005191\n",
      "Epoch 852, Loss: 214.48521893254994, Neurons: 201, Grad norm: 3.416574895005191\n",
      "Epoch 853, Loss: 214.48036035449076, Neurons: 201, Grad norm: 3.414086103105576\n",
      "Epoch 853, Loss: 214.48036035449076, Neurons: 201, Grad norm: 3.414086103105576\n",
      "Epoch 854, Loss: 214.47550741560138, Neurons: 201, Grad norm: 3.412951575740132\n",
      "Epoch 854, Loss: 214.47550741560138, Neurons: 201, Grad norm: 3.412951575740132\n",
      "Epoch 855, Loss: 214.470649622746, Neurons: 201, Grad norm: 3.4120566825043777\n",
      "Epoch 855, Loss: 214.470649622746, Neurons: 201, Grad norm: 3.4120566825043777\n",
      "Epoch 856, Loss: 214.46579680831047, Neurons: 201, Grad norm: 3.4159046033570375\n",
      "Epoch 856, Loss: 214.46579680831047, Neurons: 201, Grad norm: 3.4159046033570375\n",
      "Epoch 857, Loss: 214.4609441012452, Neurons: 201, Grad norm: 3.4184185615788336\n",
      "Epoch 857, Loss: 214.4609441012452, Neurons: 201, Grad norm: 3.4184185615788336\n",
      "Epoch 858, Loss: 214.4560895884909, Neurons: 201, Grad norm: 3.418558011582596\n",
      "Epoch 858, Loss: 214.4560895884909, Neurons: 201, Grad norm: 3.418558011582596\n",
      "Epoch 859, Loss: 214.45123708338681, Neurons: 201, Grad norm: 3.4195219457550667\n",
      "Epoch 859, Loss: 214.45123708338681, Neurons: 201, Grad norm: 3.4195219457550667\n",
      "Epoch 860, Loss: 214.44638654201333, Neurons: 201, Grad norm: 3.4203130756355624\n",
      "Epoch 860, Loss: 214.44638654201333, Neurons: 201, Grad norm: 3.4203130756355624\n",
      "Epoch 861, Loss: 214.44153108876782, Neurons: 201, Grad norm: 3.417833670008052\n",
      "Epoch 861, Loss: 214.44153108876782, Neurons: 201, Grad norm: 3.417833670008052\n",
      "Epoch 862, Loss: 214.436666649267, Neurons: 201, Grad norm: 3.4133241457743644\n",
      "Epoch 862, Loss: 214.436666649267, Neurons: 201, Grad norm: 3.4133241457743644\n",
      "Epoch 863, Loss: 214.43179330375244, Neurons: 201, Grad norm: 3.4051722620715346\n",
      "Epoch 863, Loss: 214.43179330375244, Neurons: 201, Grad norm: 3.4051722620715346\n",
      "Epoch 864, Loss: 214.42693025224548, Neurons: 201, Grad norm: 3.399402093296117\n",
      "Epoch 864, Loss: 214.42693025224548, Neurons: 201, Grad norm: 3.399402093296117\n",
      "Epoch 865, Loss: 214.42207132429536, Neurons: 201, Grad norm: 3.3940642789667055\n",
      "Epoch 865, Loss: 214.42207132429536, Neurons: 201, Grad norm: 3.3940642789667055\n",
      "Epoch 866, Loss: 214.4172133036468, Neurons: 201, Grad norm: 3.392774837576409\n",
      "Epoch 866, Loss: 214.4172133036468, Neurons: 201, Grad norm: 3.392774837576409\n",
      "Epoch 867, Loss: 214.41235583923174, Neurons: 201, Grad norm: 3.391593657691505\n",
      "Epoch 867, Loss: 214.41235583923174, Neurons: 201, Grad norm: 3.391593657691505\n",
      "Epoch 868, Loss: 214.40749502608506, Neurons: 201, Grad norm: 3.3966494769261484\n",
      "Epoch 868, Loss: 214.40749502608506, Neurons: 201, Grad norm: 3.3966494769261484\n",
      "Epoch 869, Loss: 214.40263002095827, Neurons: 201, Grad norm: 3.399347623766526\n",
      "Epoch 869, Loss: 214.40263002095827, Neurons: 201, Grad norm: 3.399347623766526\n",
      "Epoch 870, Loss: 214.397754721808, Neurons: 201, Grad norm: 3.399158495320572\n",
      "Epoch 870, Loss: 214.397754721808, Neurons: 201, Grad norm: 3.399158495320572\n",
      "Epoch 871, Loss: 214.39288567082482, Neurons: 201, Grad norm: 3.401915329565137\n",
      "Epoch 871, Loss: 214.39288567082482, Neurons: 201, Grad norm: 3.401915329565137\n",
      "Epoch 872, Loss: 214.3880387489821, Neurons: 201, Grad norm: 3.401143731471986\n",
      "Epoch 872, Loss: 214.3880387489821, Neurons: 201, Grad norm: 3.401143731471986\n",
      "Epoch 873, Loss: 214.38320465878024, Neurons: 201, Grad norm: 3.4040456013613967\n",
      "Epoch 873, Loss: 214.38320465878024, Neurons: 201, Grad norm: 3.4040456013613967\n",
      "Epoch 874, Loss: 214.37838593139548, Neurons: 201, Grad norm: 3.405447239911075\n",
      "Epoch 874, Loss: 214.37838593139548, Neurons: 201, Grad norm: 3.405447239911075\n",
      "Epoch 875, Loss: 214.3735665432567, Neurons: 201, Grad norm: 3.4044549076220894\n",
      "Epoch 875, Loss: 214.3735665432567, Neurons: 201, Grad norm: 3.4044549076220894\n",
      "Epoch 876, Loss: 214.36876190781072, Neurons: 201, Grad norm: 3.4076407331105165\n",
      "Epoch 876, Loss: 214.36876190781072, Neurons: 201, Grad norm: 3.4076407331105165\n",
      "Epoch 877, Loss: 214.36396405306016, Neurons: 201, Grad norm: 3.4126433277417565\n",
      "Epoch 877, Loss: 214.36396405306016, Neurons: 201, Grad norm: 3.4126433277417565\n",
      "Epoch 878, Loss: 214.3591592007298, Neurons: 201, Grad norm: 3.4172035241568617\n",
      "Epoch 878, Loss: 214.3591592007298, Neurons: 201, Grad norm: 3.4172035241568617\n",
      "Epoch 879, Loss: 214.35434728450159, Neurons: 201, Grad norm: 3.4210276953723664\n",
      "Epoch 879, Loss: 214.35434728450159, Neurons: 201, Grad norm: 3.4210276953723664\n",
      "Epoch 880, Loss: 214.34952058992383, Neurons: 201, Grad norm: 3.4175483765708354\n",
      "Epoch 880, Loss: 214.34952058992383, Neurons: 201, Grad norm: 3.4175483765708354\n",
      "Epoch 881, Loss: 214.34469642937125, Neurons: 201, Grad norm: 3.416027934889098\n",
      "Epoch 881, Loss: 214.34469642937125, Neurons: 201, Grad norm: 3.416027934889098\n",
      "Epoch 882, Loss: 214.33988301546867, Neurons: 201, Grad norm: 3.4164505302743344\n",
      "Epoch 882, Loss: 214.33988301546867, Neurons: 201, Grad norm: 3.4164505302743344\n",
      "Epoch 883, Loss: 214.33507455473722, Neurons: 201, Grad norm: 3.417033268395552\n",
      "Epoch 883, Loss: 214.33507455473722, Neurons: 201, Grad norm: 3.417033268395552\n",
      "Epoch 884, Loss: 214.3302595621148, Neurons: 201, Grad norm: 3.4153292995534597\n",
      "Epoch 884, Loss: 214.3302595621148, Neurons: 201, Grad norm: 3.4153292995534597\n",
      "Epoch 885, Loss: 214.32545036527765, Neurons: 201, Grad norm: 3.4183493661294846\n",
      "Epoch 885, Loss: 214.32545036527765, Neurons: 201, Grad norm: 3.4183493661294846\n",
      "Epoch 886, Loss: 214.32063944796707, Neurons: 201, Grad norm: 3.419731649648986\n",
      "Epoch 886, Loss: 214.32063944796707, Neurons: 201, Grad norm: 3.419731649648986\n",
      "Epoch 887, Loss: 214.31581381100418, Neurons: 201, Grad norm: 3.4205296294028966\n",
      "Epoch 887, Loss: 214.31581381100418, Neurons: 201, Grad norm: 3.4205296294028966\n",
      "Epoch 888, Loss: 214.3109750167943, Neurons: 201, Grad norm: 3.424602332619787\n",
      "Epoch 888, Loss: 214.3109750167943, Neurons: 201, Grad norm: 3.424602332619787\n",
      "Epoch 889, Loss: 214.3061238222628, Neurons: 201, Grad norm: 3.427287389048385\n",
      "Epoch 889, Loss: 214.3061238222628, Neurons: 201, Grad norm: 3.427287389048385\n",
      "Epoch 890, Loss: 214.30125612756294, Neurons: 201, Grad norm: 3.4332015122121624\n",
      "Epoch 890, Loss: 214.30125612756294, Neurons: 201, Grad norm: 3.4332015122121624\n",
      "Epoch 891, Loss: 214.29637359251163, Neurons: 201, Grad norm: 3.431726042418207\n",
      "Epoch 891, Loss: 214.29637359251163, Neurons: 201, Grad norm: 3.431726042418207\n",
      "Epoch 892, Loss: 214.29148124014748, Neurons: 201, Grad norm: 3.4336323690765838\n",
      "Epoch 892, Loss: 214.29148124014748, Neurons: 201, Grad norm: 3.4336323690765838\n",
      "Epoch 893, Loss: 214.28659040296083, Neurons: 201, Grad norm: 3.4375398670102295\n",
      "Epoch 893, Loss: 214.28659040296083, Neurons: 201, Grad norm: 3.4375398670102295\n",
      "Epoch 894, Loss: 214.28167270116012, Neurons: 201, Grad norm: 3.436892224207932\n",
      "Epoch 894, Loss: 214.28167270116012, Neurons: 201, Grad norm: 3.436892224207932\n",
      "Epoch 895, Loss: 214.27674078262368, Neurons: 201, Grad norm: 3.44043592716213\n",
      "Epoch 895, Loss: 214.27674078262368, Neurons: 201, Grad norm: 3.44043592716213\n",
      "Epoch 896, Loss: 214.27180966040794, Neurons: 201, Grad norm: 3.4413340324407424\n",
      "Epoch 896, Loss: 214.27180966040794, Neurons: 201, Grad norm: 3.4413340324407424\n",
      "Epoch 897, Loss: 214.26686812185528, Neurons: 201, Grad norm: 3.4434146464910182\n",
      "Epoch 897, Loss: 214.26686812185528, Neurons: 201, Grad norm: 3.4434146464910182\n",
      "Epoch 898, Loss: 214.26195131305653, Neurons: 201, Grad norm: 3.4504887097145662\n",
      "Epoch 898, Loss: 214.26195131305653, Neurons: 201, Grad norm: 3.4504887097145662\n",
      "Epoch 899, Loss: 214.25702381777822, Neurons: 201, Grad norm: 3.456927531291723\n",
      "Epoch 899, Loss: 214.25702381777822, Neurons: 201, Grad norm: 3.456927531291723\n",
      "Epoch 900, Loss: 214.25206596274631, Neurons: 201, Grad norm: 3.4616247706750496\n",
      "Epoch 900, Loss: 214.25206596274631, Neurons: 201, Grad norm: 3.4616247706750496\n",
      "Epoch 901, Loss: 214.2471145556071, Neurons: 201, Grad norm: 3.4678696304651826\n",
      "Epoch 901, Loss: 214.2471145556071, Neurons: 201, Grad norm: 3.4678696304651826\n",
      "Epoch 902, Loss: 214.2421569296587, Neurons: 201, Grad norm: 3.470554874069903\n",
      "Epoch 902, Loss: 214.2421569296587, Neurons: 201, Grad norm: 3.470554874069903\n",
      "Epoch 903, Loss: 214.23719537502527, Neurons: 201, Grad norm: 3.4711721248116456\n",
      "Epoch 903, Loss: 214.23719537502527, Neurons: 201, Grad norm: 3.4711721248116456\n",
      "Epoch 904, Loss: 214.23224195548576, Neurons: 201, Grad norm: 3.471394318531914\n",
      "Epoch 904, Loss: 214.23224195548576, Neurons: 201, Grad norm: 3.471394318531914\n",
      "Epoch 905, Loss: 214.22728983743272, Neurons: 201, Grad norm: 3.4707002545691314\n",
      "Epoch 905, Loss: 214.22728983743272, Neurons: 201, Grad norm: 3.4707002545691314\n",
      "Epoch 906, Loss: 214.22232386275178, Neurons: 201, Grad norm: 3.47047595387921\n",
      "Epoch 906, Loss: 214.22232386275178, Neurons: 201, Grad norm: 3.47047595387921\n",
      "Epoch 907, Loss: 214.21734001555612, Neurons: 201, Grad norm: 3.4690930402577997\n",
      "Epoch 907, Loss: 214.21734001555612, Neurons: 201, Grad norm: 3.4690930402577997\n",
      "Epoch 908, Loss: 214.2123463505085, Neurons: 201, Grad norm: 3.473202942883735\n",
      "Epoch 908, Loss: 214.2123463505085, Neurons: 201, Grad norm: 3.473202942883735\n",
      "Epoch 909, Loss: 214.20734849974, Neurons: 201, Grad norm: 3.4839334410549077\n",
      "Epoch 909, Loss: 214.20734849974, Neurons: 201, Grad norm: 3.4839334410549077\n",
      "Epoch 910, Loss: 214.20231006576597, Neurons: 201, Grad norm: 3.493177865870241\n",
      "Epoch 910, Loss: 214.20231006576597, Neurons: 201, Grad norm: 3.493177865870241\n",
      "Epoch 911, Loss: 214.19721972783765, Neurons: 201, Grad norm: 3.497266389989416\n",
      "Epoch 911, Loss: 214.19721972783765, Neurons: 201, Grad norm: 3.497266389989416\n",
      "Epoch 912, Loss: 214.19211923911575, Neurons: 201, Grad norm: 3.5008960860321867\n",
      "Epoch 912, Loss: 214.19211923911575, Neurons: 201, Grad norm: 3.5008960860321867\n",
      "Epoch 913, Loss: 214.18707555173899, Neurons: 201, Grad norm: 3.5061103320739733\n",
      "Epoch 913, Loss: 214.18707555173899, Neurons: 201, Grad norm: 3.5061103320739733\n",
      "Epoch 914, Loss: 214.18206093674775, Neurons: 201, Grad norm: 3.509206394316459\n",
      "Epoch 914, Loss: 214.18206093674775, Neurons: 201, Grad norm: 3.509206394316459\n",
      "Epoch 915, Loss: 214.1770255019796, Neurons: 201, Grad norm: 3.5014178634112914\n",
      "Epoch 915, Loss: 214.1770255019796, Neurons: 201, Grad norm: 3.5014178634112914\n",
      "Epoch 916, Loss: 214.17199039218872, Neurons: 201, Grad norm: 3.4916140201943064\n",
      "Epoch 916, Loss: 214.17199039218872, Neurons: 201, Grad norm: 3.4916140201943064\n",
      "Epoch 917, Loss: 214.16700486468858, Neurons: 201, Grad norm: 3.4818942586406396\n",
      "Epoch 917, Loss: 214.16700486468858, Neurons: 201, Grad norm: 3.4818942586406396\n",
      "Epoch 918, Loss: 214.16204935260393, Neurons: 201, Grad norm: 3.4670884597772598\n",
      "Epoch 918, Loss: 214.16204935260393, Neurons: 201, Grad norm: 3.4670884597772598\n",
      "Epoch 919, Loss: 214.15708981791192, Neurons: 201, Grad norm: 3.450309446625445\n",
      "Epoch 919, Loss: 214.15708981791192, Neurons: 201, Grad norm: 3.450309446625445\n",
      "Epoch 920, Loss: 214.15213535470795, Neurons: 201, Grad norm: 3.4353663597195356\n",
      "Epoch 920, Loss: 214.15213535470795, Neurons: 201, Grad norm: 3.4353663597195356\n",
      "Epoch 921, Loss: 214.14718192489627, Neurons: 201, Grad norm: 3.4188948669930372\n",
      "Epoch 921, Loss: 214.14718192489627, Neurons: 201, Grad norm: 3.4188948669930372\n",
      "Epoch 922, Loss: 214.14225436087227, Neurons: 201, Grad norm: 3.4043516493732526\n",
      "Epoch 922, Loss: 214.14225436087227, Neurons: 201, Grad norm: 3.4043516493732526\n",
      "Epoch 923, Loss: 214.13737149816646, Neurons: 201, Grad norm: 3.3932358754974765\n",
      "Epoch 923, Loss: 214.13737149816646, Neurons: 201, Grad norm: 3.3932358754974765\n",
      "Epoch 924, Loss: 214.13252341037682, Neurons: 201, Grad norm: 3.378123641967819\n",
      "Epoch 924, Loss: 214.13252341037682, Neurons: 201, Grad norm: 3.378123641967819\n",
      "Epoch 925, Loss: 214.1276877988546, Neurons: 201, Grad norm: 3.365729313634342\n",
      "Epoch 925, Loss: 214.1276877988546, Neurons: 201, Grad norm: 3.365729313634342\n",
      "Epoch 926, Loss: 214.1228540090708, Neurons: 201, Grad norm: 3.3553610959276603\n",
      "Epoch 926, Loss: 214.1228540090708, Neurons: 201, Grad norm: 3.3553610959276603\n",
      "Epoch 927, Loss: 214.11801206287106, Neurons: 201, Grad norm: 3.3427101594456485\n",
      "Epoch 927, Loss: 214.11801206287106, Neurons: 201, Grad norm: 3.3427101594456485\n",
      "Epoch 928, Loss: 214.113172714804, Neurons: 201, Grad norm: 3.331632595909098\n",
      "Epoch 928, Loss: 214.113172714804, Neurons: 201, Grad norm: 3.331632595909098\n",
      "Epoch 929, Loss: 214.10833188956084, Neurons: 201, Grad norm: 3.3227218513212224\n",
      "Epoch 929, Loss: 214.10833188956084, Neurons: 201, Grad norm: 3.3227218513212224\n",
      "Epoch 930, Loss: 214.10349553406198, Neurons: 201, Grad norm: 3.317370441677782\n",
      "Epoch 930, Loss: 214.10349553406198, Neurons: 201, Grad norm: 3.317370441677782\n",
      "Epoch 931, Loss: 214.09866197633957, Neurons: 201, Grad norm: 3.3160410551573944\n",
      "Epoch 931, Loss: 214.09866197633957, Neurons: 201, Grad norm: 3.3160410551573944\n",
      "Epoch 932, Loss: 214.09382711840942, Neurons: 201, Grad norm: 3.316808009825198\n",
      "Epoch 932, Loss: 214.09382711840942, Neurons: 201, Grad norm: 3.316808009825198\n",
      "Epoch 933, Loss: 214.08900179593599, Neurons: 201, Grad norm: 3.32012457022917\n",
      "Epoch 933, Loss: 214.08900179593599, Neurons: 201, Grad norm: 3.32012457022917\n",
      "Epoch 934, Loss: 214.08417640854444, Neurons: 201, Grad norm: 3.327017292773539\n",
      "Epoch 934, Loss: 214.08417640854444, Neurons: 201, Grad norm: 3.327017292773539\n",
      "Epoch 935, Loss: 214.07935077759973, Neurons: 201, Grad norm: 3.3322395593637757\n",
      "Epoch 935, Loss: 214.07935077759973, Neurons: 201, Grad norm: 3.3322395593637757\n",
      "Epoch 936, Loss: 214.07451908904025, Neurons: 201, Grad norm: 3.3335547595187647\n",
      "Epoch 936, Loss: 214.07451908904025, Neurons: 201, Grad norm: 3.3335547595187647\n",
      "Epoch 937, Loss: 214.06969545270263, Neurons: 201, Grad norm: 3.3285095687981503\n",
      "Epoch 937, Loss: 214.06969545270263, Neurons: 201, Grad norm: 3.3285095687981503\n",
      "Epoch 938, Loss: 214.0648800565786, Neurons: 201, Grad norm: 3.321131162784129\n",
      "Epoch 938, Loss: 214.0648800565786, Neurons: 201, Grad norm: 3.321131162784129\n",
      "Epoch 939, Loss: 214.0600958010263, Neurons: 201, Grad norm: 3.3113848271853223\n",
      "Epoch 939, Loss: 214.0600958010263, Neurons: 201, Grad norm: 3.3113848271853223\n",
      "Epoch 940, Loss: 214.05532187917512, Neurons: 201, Grad norm: 3.2981525866128663\n",
      "Epoch 940, Loss: 214.05532187917512, Neurons: 201, Grad norm: 3.2981525866128663\n",
      "Epoch 941, Loss: 214.05055400567605, Neurons: 201, Grad norm: 3.281230230394157\n",
      "Epoch 941, Loss: 214.05055400567605, Neurons: 201, Grad norm: 3.281230230394157\n",
      "Epoch 942, Loss: 214.04578293791855, Neurons: 201, Grad norm: 3.2666708715906143\n",
      "Epoch 942, Loss: 214.04578293791855, Neurons: 201, Grad norm: 3.2666708715906143\n",
      "Epoch 943, Loss: 214.04101683908607, Neurons: 201, Grad norm: 3.250730643424037\n",
      "Epoch 943, Loss: 214.04101683908607, Neurons: 201, Grad norm: 3.250730643424037\n",
      "Epoch 944, Loss: 214.03625607290897, Neurons: 201, Grad norm: 3.2361312055798472\n",
      "Epoch 944, Loss: 214.03625607290897, Neurons: 201, Grad norm: 3.2361312055798472\n",
      "Epoch 945, Loss: 214.03149130586854, Neurons: 201, Grad norm: 3.2265037445341127\n",
      "Epoch 945, Loss: 214.03149130586854, Neurons: 201, Grad norm: 3.2265037445341127\n",
      "Epoch 946, Loss: 214.02672322498444, Neurons: 201, Grad norm: 3.2182091186020045\n",
      "Epoch 946, Loss: 214.02672322498444, Neurons: 201, Grad norm: 3.2182091186020045\n",
      "Epoch 947, Loss: 214.02194719319962, Neurons: 201, Grad norm: 3.215667354245666\n",
      "Epoch 947, Loss: 214.02194719319962, Neurons: 201, Grad norm: 3.215667354245666\n",
      "Epoch 948, Loss: 214.01717010713196, Neurons: 201, Grad norm: 3.212618647374525\n",
      "Epoch 948, Loss: 214.01717010713196, Neurons: 201, Grad norm: 3.212618647374525\n",
      "Epoch 949, Loss: 214.01239820241966, Neurons: 201, Grad norm: 3.21498841766669\n",
      "Epoch 949, Loss: 214.01239820241966, Neurons: 201, Grad norm: 3.21498841766669\n",
      "Epoch 950, Loss: 214.0076327846975, Neurons: 201, Grad norm: 3.219753643568525\n",
      "Epoch 950, Loss: 214.0076327846975, Neurons: 201, Grad norm: 3.219753643568525\n",
      "Epoch 951, Loss: 214.00287699317548, Neurons: 201, Grad norm: 3.2247742083358295\n",
      "Epoch 951, Loss: 214.00287699317548, Neurons: 201, Grad norm: 3.2247742083358295\n",
      "Epoch 952, Loss: 213.99812028448233, Neurons: 201, Grad norm: 3.2264896618363235\n",
      "Epoch 952, Loss: 213.99812028448233, Neurons: 201, Grad norm: 3.2264896618363235\n",
      "Epoch 953, Loss: 213.99336655989944, Neurons: 201, Grad norm: 3.2298661407320552\n",
      "Epoch 953, Loss: 213.99336655989944, Neurons: 201, Grad norm: 3.2298661407320552\n",
      "Epoch 954, Loss: 213.98862462571236, Neurons: 201, Grad norm: 3.2292129162531817\n",
      "Epoch 954, Loss: 213.98862462571236, Neurons: 201, Grad norm: 3.2292129162531817\n",
      "Epoch 955, Loss: 213.98389700321647, Neurons: 201, Grad norm: 3.228102251020369\n",
      "Epoch 955, Loss: 213.98389700321647, Neurons: 201, Grad norm: 3.228102251020369\n",
      "Epoch 956, Loss: 213.97917787751152, Neurons: 201, Grad norm: 3.2266723644972677\n",
      "Epoch 956, Loss: 213.97917787751152, Neurons: 201, Grad norm: 3.2266723644972677\n",
      "Epoch 957, Loss: 213.97446898707474, Neurons: 201, Grad norm: 3.223944083966554\n",
      "Epoch 957, Loss: 213.97446898707474, Neurons: 201, Grad norm: 3.223944083966554\n",
      "Epoch 958, Loss: 213.9697875506461, Neurons: 201, Grad norm: 3.221384719605212\n",
      "Epoch 958, Loss: 213.9697875506461, Neurons: 201, Grad norm: 3.221384719605212\n",
      "Epoch 959, Loss: 213.9651127979576, Neurons: 201, Grad norm: 3.2189537869734224\n",
      "Epoch 959, Loss: 213.9651127979576, Neurons: 201, Grad norm: 3.2189537869734224\n",
      "Epoch 960, Loss: 213.96044147361573, Neurons: 201, Grad norm: 3.218183707826203\n",
      "Epoch 960, Loss: 213.96044147361573, Neurons: 201, Grad norm: 3.218183707826203\n",
      "Epoch 961, Loss: 213.95577518355714, Neurons: 201, Grad norm: 3.218051277184595\n",
      "Epoch 961, Loss: 213.95577518355714, Neurons: 201, Grad norm: 3.218051277184595\n",
      "Epoch 962, Loss: 213.95111840166913, Neurons: 201, Grad norm: 3.2186115247984484\n",
      "Epoch 962, Loss: 213.95111840166913, Neurons: 201, Grad norm: 3.2186115247984484\n",
      "Epoch 963, Loss: 213.9464876894399, Neurons: 201, Grad norm: 3.2202058752583755\n",
      "Epoch 963, Loss: 213.9464876894399, Neurons: 201, Grad norm: 3.2202058752583755\n",
      "Epoch 964, Loss: 213.9418801094176, Neurons: 201, Grad norm: 3.2223230400692398\n",
      "Epoch 964, Loss: 213.9418801094176, Neurons: 201, Grad norm: 3.2223230400692398\n",
      "Epoch 965, Loss: 213.9372841235926, Neurons: 201, Grad norm: 3.224563469587781\n",
      "Epoch 965, Loss: 213.9372841235926, Neurons: 201, Grad norm: 3.224563469587781\n",
      "Epoch 966, Loss: 213.93269751967156, Neurons: 201, Grad norm: 3.22367134203592\n",
      "Epoch 966, Loss: 213.93269751967156, Neurons: 201, Grad norm: 3.22367134203592\n",
      "Epoch 967, Loss: 213.92810805548538, Neurons: 201, Grad norm: 3.2216106000281437\n",
      "Epoch 967, Loss: 213.92810805548538, Neurons: 201, Grad norm: 3.2216106000281437\n",
      "Epoch 968, Loss: 213.92352107832562, Neurons: 201, Grad norm: 3.215863771303051\n",
      "Epoch 968, Loss: 213.92352107832562, Neurons: 201, Grad norm: 3.215863771303051\n",
      "Epoch 969, Loss: 213.9189309782748, Neurons: 201, Grad norm: 3.2105098748982117\n",
      "Epoch 969, Loss: 213.9189309782748, Neurons: 201, Grad norm: 3.2105098748982117\n",
      "Epoch 970, Loss: 213.91434449697613, Neurons: 201, Grad norm: 3.207600311626487\n",
      "Epoch 970, Loss: 213.91434449697613, Neurons: 201, Grad norm: 3.207600311626487\n",
      "Epoch 971, Loss: 213.9097676605915, Neurons: 201, Grad norm: 3.20675845972485\n",
      "Epoch 971, Loss: 213.9097676605915, Neurons: 201, Grad norm: 3.20675845972485\n",
      "Epoch 972, Loss: 213.90519535214273, Neurons: 201, Grad norm: 3.2069353533414366\n",
      "Epoch 972, Loss: 213.90519535214273, Neurons: 201, Grad norm: 3.2069353533414366\n",
      "Epoch 973, Loss: 213.90062656279073, Neurons: 201, Grad norm: 3.205625907989195\n",
      "Epoch 973, Loss: 213.90062656279073, Neurons: 201, Grad norm: 3.205625907989195\n",
      "Epoch 974, Loss: 213.8960601690497, Neurons: 201, Grad norm: 3.205133661431827\n",
      "Epoch 974, Loss: 213.8960601690497, Neurons: 201, Grad norm: 3.205133661431827\n",
      "Epoch 975, Loss: 213.89148992721468, Neurons: 201, Grad norm: 3.1999792784068095\n",
      "Epoch 975, Loss: 213.89148992721468, Neurons: 201, Grad norm: 3.1999792784068095\n",
      "Epoch 976, Loss: 213.88690648453831, Neurons: 201, Grad norm: 3.1916543773920676\n",
      "Epoch 976, Loss: 213.88690648453831, Neurons: 201, Grad norm: 3.1916543773920676\n",
      "Epoch 977, Loss: 213.8823214185167, Neurons: 201, Grad norm: 3.182610968042759\n",
      "Epoch 977, Loss: 213.8823214185167, Neurons: 201, Grad norm: 3.182610968042759\n",
      "Epoch 978, Loss: 213.8777333362973, Neurons: 201, Grad norm: 3.1762249386605683\n",
      "Epoch 978, Loss: 213.8777333362973, Neurons: 201, Grad norm: 3.1762249386605683\n",
      "Epoch 979, Loss: 213.87313874876827, Neurons: 201, Grad norm: 3.1697815560657014\n",
      "Epoch 979, Loss: 213.87313874876827, Neurons: 201, Grad norm: 3.1697815560657014\n",
      "Epoch 980, Loss: 213.8685420236673, Neurons: 201, Grad norm: 3.1661573381142225\n",
      "Epoch 980, Loss: 213.8685420236673, Neurons: 201, Grad norm: 3.1661573381142225\n",
      "Epoch 981, Loss: 213.86393499913532, Neurons: 201, Grad norm: 3.1611322300885765\n",
      "Epoch 981, Loss: 213.86393499913532, Neurons: 201, Grad norm: 3.1611322300885765\n",
      "Epoch 982, Loss: 213.85931978993253, Neurons: 201, Grad norm: 3.1594953232482474\n",
      "Epoch 982, Loss: 213.85931978993253, Neurons: 201, Grad norm: 3.1594953232482474\n",
      "Epoch 983, Loss: 213.85470161596336, Neurons: 201, Grad norm: 3.1579393201285444\n",
      "Epoch 983, Loss: 213.85470161596336, Neurons: 201, Grad norm: 3.1579393201285444\n",
      "Epoch 984, Loss: 213.85008256762939, Neurons: 201, Grad norm: 3.1589251292841247\n",
      "Epoch 984, Loss: 213.85008256762939, Neurons: 201, Grad norm: 3.1589251292841247\n",
      "Epoch 985, Loss: 213.8454580912719, Neurons: 201, Grad norm: 3.1591419507207044\n",
      "Epoch 985, Loss: 213.8454580912719, Neurons: 201, Grad norm: 3.1591419507207044\n",
      "Epoch 986, Loss: 213.84083625535686, Neurons: 201, Grad norm: 3.1616606070366933\n",
      "Epoch 986, Loss: 213.84083625535686, Neurons: 201, Grad norm: 3.1616606070366933\n",
      "Epoch 987, Loss: 213.83621933725362, Neurons: 201, Grad norm: 3.158816568250524\n",
      "Epoch 987, Loss: 213.83621933725362, Neurons: 201, Grad norm: 3.158816568250524\n",
      "Epoch 988, Loss: 213.8315945466787, Neurons: 201, Grad norm: 3.155813416264153\n",
      "Epoch 988, Loss: 213.8315945466787, Neurons: 201, Grad norm: 3.155813416264153\n",
      "Epoch 989, Loss: 213.82697166052816, Neurons: 201, Grad norm: 3.1507686879761425\n",
      "Epoch 989, Loss: 213.82697166052816, Neurons: 201, Grad norm: 3.1507686879761425\n",
      "Epoch 990, Loss: 213.82235159878152, Neurons: 201, Grad norm: 3.149228148100072\n",
      "Epoch 990, Loss: 213.82235159878152, Neurons: 201, Grad norm: 3.149228148100072\n",
      "Epoch 991, Loss: 213.81772488484484, Neurons: 201, Grad norm: 3.14421413725423\n",
      "Epoch 991, Loss: 213.81772488484484, Neurons: 201, Grad norm: 3.14421413725423\n",
      "Epoch 992, Loss: 213.81310950279308, Neurons: 201, Grad norm: 3.141984746216286\n",
      "Epoch 992, Loss: 213.81310950279308, Neurons: 201, Grad norm: 3.141984746216286\n",
      "Epoch 993, Loss: 213.8085111021639, Neurons: 201, Grad norm: 3.1409771890842184\n",
      "Epoch 993, Loss: 213.8085111021639, Neurons: 201, Grad norm: 3.1409771890842184\n",
      "Epoch 994, Loss: 213.80391390657633, Neurons: 201, Grad norm: 3.1391589945720892\n",
      "Epoch 994, Loss: 213.80391390657633, Neurons: 201, Grad norm: 3.1391589945720892\n",
      "Epoch 995, Loss: 213.79931382376176, Neurons: 201, Grad norm: 3.1386868247013617\n",
      "Epoch 995, Loss: 213.79931382376176, Neurons: 201, Grad norm: 3.1386868247013617\n",
      "Epoch 996, Loss: 213.7947162732489, Neurons: 201, Grad norm: 3.1411967318748295\n",
      "Epoch 996, Loss: 213.7947162732489, Neurons: 201, Grad norm: 3.1411967318748295\n",
      "Epoch 997, Loss: 213.7901208168041, Neurons: 201, Grad norm: 3.1440170359531208\n",
      "Epoch 997, Loss: 213.7901208168041, Neurons: 201, Grad norm: 3.1440170359531208\n",
      "Epoch 998, Loss: 213.78552435665824, Neurons: 201, Grad norm: 3.148056797770964\n",
      "Epoch 998, Loss: 213.78552435665824, Neurons: 201, Grad norm: 3.148056797770964\n",
      "Epoch 999, Loss: 213.7809266600486, Neurons: 201, Grad norm: 3.1540660225810893\n",
      "Epoch 999, Loss: 213.7809266600486, Neurons: 201, Grad norm: 3.1540660225810893\n",
      "Epoch 1000, Loss: 213.7763250665824, Neurons: 201, Grad norm: 3.1620245712912673\n",
      "Epoch 1000, Loss: 213.7763250665824, Neurons: 201, Grad norm: 3.1620245712912673\n",
      "Epoch 1001, Loss: 213.77171068689645, Neurons: 201, Grad norm: 3.170369423702436\n",
      "Epoch 1001, Loss: 213.77171068689645, Neurons: 201, Grad norm: 3.170369423702436\n",
      "Epoch 1002, Loss: 213.76709172181504, Neurons: 201, Grad norm: 3.1801202876621915\n",
      "Epoch 1002, Loss: 213.76709172181504, Neurons: 201, Grad norm: 3.1801202876621915\n",
      "Epoch 1003, Loss: 213.76246617013618, Neurons: 201, Grad norm: 3.1840814885425575\n",
      "Epoch 1003, Loss: 213.76246617013618, Neurons: 201, Grad norm: 3.1840814885425575\n",
      "Epoch 1004, Loss: 213.75781571611532, Neurons: 201, Grad norm: 3.1946968937117504\n",
      "Epoch 1004, Loss: 213.75781571611532, Neurons: 201, Grad norm: 3.1946968937117504\n",
      "Epoch 1005, Loss: 213.75316241791197, Neurons: 201, Grad norm: 3.2101639722728303\n",
      "Epoch 1005, Loss: 213.75316241791197, Neurons: 201, Grad norm: 3.2101639722728303\n",
      "Epoch 1006, Loss: 213.74848768304582, Neurons: 201, Grad norm: 3.230919588013597\n",
      "Epoch 1006, Loss: 213.74848768304582, Neurons: 201, Grad norm: 3.230919588013597\n",
      "Epoch 1007, Loss: 213.74377979510223, Neurons: 201, Grad norm: 3.2524142176189534\n",
      "Epoch 1007, Loss: 213.74377979510223, Neurons: 201, Grad norm: 3.2524142176189534\n",
      "Epoch 1008, Loss: 213.7390537438897, Neurons: 201, Grad norm: 3.2704184096966444\n",
      "Epoch 1008, Loss: 213.7390537438897, Neurons: 201, Grad norm: 3.2704184096966444\n",
      "Epoch 1009, Loss: 213.73431125499704, Neurons: 201, Grad norm: 3.2776764182307647\n",
      "Epoch 1009, Loss: 213.73431125499704, Neurons: 201, Grad norm: 3.2776764182307647\n",
      "Epoch 1010, Loss: 213.72954201478132, Neurons: 201, Grad norm: 3.276568902479348\n",
      "Epoch 1010, Loss: 213.72954201478132, Neurons: 201, Grad norm: 3.276568902479348\n",
      "Epoch 1011, Loss: 213.72477941551895, Neurons: 201, Grad norm: 3.2699181583563584\n",
      "Epoch 1011, Loss: 213.72477941551895, Neurons: 201, Grad norm: 3.2699181583563584\n",
      "Epoch 1012, Loss: 213.7199917618432, Neurons: 201, Grad norm: 3.2647145414248215\n",
      "Epoch 1012, Loss: 213.7199917618432, Neurons: 201, Grad norm: 3.2647145414248215\n",
      "Epoch 1013, Loss: 213.71514715132244, Neurons: 201, Grad norm: 3.2557126551407927\n",
      "Epoch 1013, Loss: 213.71514715132244, Neurons: 201, Grad norm: 3.2557126551407927\n",
      "Epoch 1014, Loss: 213.71023540859358, Neurons: 201, Grad norm: 3.2522100310826114\n",
      "Epoch 1014, Loss: 213.71023540859358, Neurons: 201, Grad norm: 3.2522100310826114\n",
      "Epoch 1015, Loss: 213.7053120576179, Neurons: 201, Grad norm: 3.2421214763839523\n",
      "Epoch 1015, Loss: 213.7053120576179, Neurons: 201, Grad norm: 3.2421214763839523\n",
      "Epoch 1016, Loss: 213.70039175609017, Neurons: 201, Grad norm: 3.227123274273047\n",
      "Epoch 1016, Loss: 213.70039175609017, Neurons: 201, Grad norm: 3.227123274273047\n",
      "Epoch 1017, Loss: 213.69549705780258, Neurons: 201, Grad norm: 3.1994365275146603\n",
      "Epoch 1017, Loss: 213.69549705780258, Neurons: 201, Grad norm: 3.1994365275146603\n",
      "Epoch 1018, Loss: 213.69063547405, Neurons: 201, Grad norm: 3.171579913703334\n",
      "Epoch 1018, Loss: 213.69063547405, Neurons: 201, Grad norm: 3.171579913703334\n",
      "Epoch 1019, Loss: 213.6857552922536, Neurons: 201, Grad norm: 3.136558913906332\n",
      "Epoch 1019, Loss: 213.6857552922536, Neurons: 201, Grad norm: 3.136558913906332\n",
      "Epoch 1020, Loss: 213.68085677467224, Neurons: 201, Grad norm: 3.1237683662493487\n",
      "Epoch 1020, Loss: 213.68085677467224, Neurons: 201, Grad norm: 3.1237683662493487\n",
      "Epoch 1021, Loss: 213.67594239941704, Neurons: 201, Grad norm: 3.1132366628048613\n",
      "Epoch 1021, Loss: 213.67594239941704, Neurons: 201, Grad norm: 3.1132366628048613\n",
      "Epoch 1022, Loss: 213.6709747122592, Neurons: 201, Grad norm: 3.1229461797349374\n",
      "Epoch 1022, Loss: 213.6709747122592, Neurons: 201, Grad norm: 3.1229461797349374\n",
      "Epoch 1023, Loss: 213.66594230448533, Neurons: 201, Grad norm: 3.1377326723925174\n",
      "Epoch 1023, Loss: 213.66594230448533, Neurons: 201, Grad norm: 3.1377326723925174\n",
      "Epoch 1024, Loss: 213.6608888504744, Neurons: 201, Grad norm: 3.180942507282507\n",
      "Epoch 1024, Loss: 213.6608888504744, Neurons: 201, Grad norm: 3.180942507282507\n",
      "Epoch 1025, Loss: 213.65570190956174, Neurons: 201, Grad norm: 3.2124505839090522\n",
      "Epoch 1025, Loss: 213.65570190956174, Neurons: 201, Grad norm: 3.2124505839090522\n",
      "Epoch 1026, Loss: 213.65038631290471, Neurons: 201, Grad norm: 3.232678943905728\n",
      "Epoch 1026, Loss: 213.65038631290471, Neurons: 201, Grad norm: 3.232678943905728\n",
      "Epoch 1027, Loss: 213.64498983538465, Neurons: 201, Grad norm: 3.249376303270346\n",
      "Epoch 1027, Loss: 213.64498983538465, Neurons: 201, Grad norm: 3.249376303270346\n",
      "Epoch 1028, Loss: 213.63950555225023, Neurons: 201, Grad norm: 3.2655742505428105\n",
      "Epoch 1028, Loss: 213.63950555225023, Neurons: 201, Grad norm: 3.2655742505428105\n",
      "Epoch 1029, Loss: 213.6339420583682, Neurons: 201, Grad norm: 3.322754801465443\n",
      "Epoch 1029, Loss: 213.6339420583682, Neurons: 201, Grad norm: 3.322754801465443\n",
      "Epoch 1030, Loss: 213.62819734702134, Neurons: 201, Grad norm: 3.308482827615738\n",
      "Epoch 1030, Loss: 213.62819734702134, Neurons: 201, Grad norm: 3.308482827615738\n",
      "Epoch 1031, Loss: 213.6222268613353, Neurons: 201, Grad norm: 3.3079566916859515\n",
      "Epoch 1031, Loss: 213.6222268613353, Neurons: 201, Grad norm: 3.3079566916859515\n",
      "Epoch 1032, Loss: 213.61629793235394, Neurons: 201, Grad norm: 3.272893642484295\n",
      "Epoch 1032, Loss: 213.61629793235394, Neurons: 201, Grad norm: 3.272893642484295\n",
      "Epoch 1033, Loss: 213.61051532653, Neurons: 201, Grad norm: 3.266750583953544\n",
      "Epoch 1033, Loss: 213.61051532653, Neurons: 201, Grad norm: 3.266750583953544\n",
      "Epoch 1034, Loss: 213.60484330000222, Neurons: 201, Grad norm: 3.263073256558348\n",
      "Epoch 1034, Loss: 213.60484330000222, Neurons: 201, Grad norm: 3.263073256558348\n",
      "Epoch 1035, Loss: 213.59933787489197, Neurons: 201, Grad norm: 3.2926824012762252\n",
      "Epoch 1035, Loss: 213.59933787489197, Neurons: 201, Grad norm: 3.2926824012762252\n",
      "Epoch 1036, Loss: 213.59375575254978, Neurons: 201, Grad norm: 3.328337806495635\n",
      "Epoch 1036, Loss: 213.59375575254978, Neurons: 201, Grad norm: 3.328337806495635\n",
      "Epoch 1037, Loss: 213.58807098801307, Neurons: 201, Grad norm: 3.305465781138542\n",
      "Epoch 1037, Loss: 213.58807098801307, Neurons: 201, Grad norm: 3.305465781138542\n",
      "Epoch 1038, Loss: 213.5823172198111, Neurons: 201, Grad norm: 3.291054290246479\n",
      "Epoch 1038, Loss: 213.5823172198111, Neurons: 201, Grad norm: 3.291054290246479\n",
      "Epoch 1039, Loss: 213.57675199021955, Neurons: 201, Grad norm: 3.2950098596724966\n",
      "Epoch 1039, Loss: 213.57675199021955, Neurons: 201, Grad norm: 3.2950098596724966\n",
      "Epoch 1040, Loss: 213.57119755476742, Neurons: 201, Grad norm: 3.3041038628021573\n",
      "Epoch 1040, Loss: 213.57119755476742, Neurons: 201, Grad norm: 3.3041038628021573\n",
      "Epoch 1041, Loss: 213.56562941576775, Neurons: 201, Grad norm: 3.276849608991082\n",
      "Epoch 1041, Loss: 213.56562941576775, Neurons: 201, Grad norm: 3.276849608991082\n",
      "Epoch 1042, Loss: 213.56015056738258, Neurons: 201, Grad norm: 3.278595118925384\n",
      "Epoch 1042, Loss: 213.56015056738258, Neurons: 201, Grad norm: 3.278595118925384\n",
      "Epoch 1043, Loss: 213.55478662282448, Neurons: 201, Grad norm: 3.280639749264843\n",
      "Epoch 1043, Loss: 213.55478662282448, Neurons: 201, Grad norm: 3.280639749264843\n",
      "Epoch 1044, Loss: 213.54948576396393, Neurons: 201, Grad norm: 3.2943217105957814\n",
      "Epoch 1044, Loss: 213.54948576396393, Neurons: 201, Grad norm: 3.2943217105957814\n",
      "Epoch 1045, Loss: 213.54420055479375, Neurons: 201, Grad norm: 3.3279449073674563\n",
      "Epoch 1045, Loss: 213.54420055479375, Neurons: 201, Grad norm: 3.3279449073674563\n",
      "Epoch 1046, Loss: 213.53879893286629, Neurons: 201, Grad norm: 3.3473322011657762\n",
      "Epoch 1046, Loss: 213.53879893286629, Neurons: 201, Grad norm: 3.3473322011657762\n",
      "Epoch 1047, Loss: 213.53326800865983, Neurons: 201, Grad norm: 3.362288207555419\n",
      "Epoch 1047, Loss: 213.53326800865983, Neurons: 201, Grad norm: 3.362288207555419\n",
      "Epoch 1048, Loss: 213.52763842157523, Neurons: 201, Grad norm: 3.363525478663832\n",
      "Epoch 1048, Loss: 213.52763842157523, Neurons: 201, Grad norm: 3.363525478663832\n",
      "Epoch 1049, Loss: 213.5219940436766, Neurons: 201, Grad norm: 3.3769258355599394\n",
      "Epoch 1049, Loss: 213.5219940436766, Neurons: 201, Grad norm: 3.3769258355599394\n",
      "Epoch 1050, Loss: 213.51627502671073, Neurons: 201, Grad norm: 3.387607390008862\n",
      "Epoch 1050, Loss: 213.51627502671073, Neurons: 201, Grad norm: 3.387607390008862\n",
      "Epoch 1051, Loss: 213.5105568399173, Neurons: 201, Grad norm: 3.39958868767155\n",
      "Epoch 1051, Loss: 213.5105568399173, Neurons: 201, Grad norm: 3.39958868767155\n",
      "Epoch 1052, Loss: 213.50484022752732, Neurons: 201, Grad norm: 3.4113108754032324\n",
      "Epoch 1052, Loss: 213.50484022752732, Neurons: 201, Grad norm: 3.4113108754032324\n",
      "Epoch 1053, Loss: 213.49909778822078, Neurons: 201, Grad norm: 3.448256445261805\n",
      "Epoch 1053, Loss: 213.49909778822078, Neurons: 201, Grad norm: 3.448256445261805\n",
      "Epoch 1054, Loss: 213.4932583384072, Neurons: 201, Grad norm: 3.469113917312252\n",
      "Epoch 1054, Loss: 213.4932583384072, Neurons: 201, Grad norm: 3.469113917312252\n",
      "Epoch 1055, Loss: 213.48728872072522, Neurons: 201, Grad norm: 3.451873509493675\n",
      "Epoch 1055, Loss: 213.48728872072522, Neurons: 201, Grad norm: 3.451873509493675\n",
      "Epoch 1056, Loss: 213.4813187816909, Neurons: 201, Grad norm: 3.4545011494831623\n",
      "Epoch 1056, Loss: 213.4813187816909, Neurons: 201, Grad norm: 3.4545011494831623\n",
      "Epoch 1057, Loss: 213.47537845085938, Neurons: 201, Grad norm: 3.4189835115845586\n",
      "Epoch 1057, Loss: 213.47537845085938, Neurons: 201, Grad norm: 3.4189835115845586\n",
      "Epoch 1058, Loss: 213.46952080456484, Neurons: 201, Grad norm: 3.415330016765416\n",
      "Epoch 1058, Loss: 213.46952080456484, Neurons: 201, Grad norm: 3.415330016765416\n",
      "Epoch 1059, Loss: 213.46378942871263, Neurons: 201, Grad norm: 3.3950121679910006\n",
      "Epoch 1059, Loss: 213.46378942871263, Neurons: 201, Grad norm: 3.3950121679910006\n",
      "Epoch 1060, Loss: 213.45811371040733, Neurons: 201, Grad norm: 3.382019823417811\n",
      "Epoch 1060, Loss: 213.45811371040733, Neurons: 201, Grad norm: 3.382019823417811\n",
      "Epoch 1061, Loss: 213.4525527141684, Neurons: 201, Grad norm: 3.384517926075195\n",
      "Epoch 1061, Loss: 213.4525527141684, Neurons: 201, Grad norm: 3.384517926075195\n",
      "Epoch 1062, Loss: 213.44700374492345, Neurons: 201, Grad norm: 3.3907306131766157\n",
      "Epoch 1062, Loss: 213.44700374492345, Neurons: 201, Grad norm: 3.3907306131766157\n",
      "Epoch 1063, Loss: 213.44130753212914, Neurons: 201, Grad norm: 3.3944340136724613\n",
      "Epoch 1063, Loss: 213.44130753212914, Neurons: 201, Grad norm: 3.3944340136724613\n",
      "Epoch 1064, Loss: 213.43557135785798, Neurons: 201, Grad norm: 3.3996988049939363\n",
      "Epoch 1064, Loss: 213.43557135785798, Neurons: 201, Grad norm: 3.3996988049939363\n",
      "Epoch 1065, Loss: 213.42965996700258, Neurons: 201, Grad norm: 3.373660739649943\n",
      "Epoch 1065, Loss: 213.42965996700258, Neurons: 201, Grad norm: 3.373660739649943\n",
      "Epoch 1066, Loss: 213.42391031367873, Neurons: 201, Grad norm: 3.362803619709866\n",
      "Epoch 1066, Loss: 213.42391031367873, Neurons: 201, Grad norm: 3.362803619709866\n",
      "Epoch 1067, Loss: 213.41823902668008, Neurons: 201, Grad norm: 3.3563010144714562\n",
      "Epoch 1067, Loss: 213.41823902668008, Neurons: 201, Grad norm: 3.3563010144714562\n",
      "Epoch 1068, Loss: 213.4126240530173, Neurons: 201, Grad norm: 3.35940978948804\n",
      "Epoch 1068, Loss: 213.4126240530173, Neurons: 201, Grad norm: 3.35940978948804\n",
      "Epoch 1069, Loss: 213.4069893224299, Neurons: 201, Grad norm: 3.366825678555578\n",
      "Epoch 1069, Loss: 213.4069893224299, Neurons: 201, Grad norm: 3.366825678555578\n",
      "Epoch 1070, Loss: 213.40138200440805, Neurons: 201, Grad norm: 3.3715800453477978\n",
      "Epoch 1070, Loss: 213.40138200440805, Neurons: 201, Grad norm: 3.3715800453477978\n",
      "Epoch 1071, Loss: 213.39571272150903, Neurons: 201, Grad norm: 3.3689221903670816\n",
      "Epoch 1071, Loss: 213.39571272150903, Neurons: 201, Grad norm: 3.3689221903670816\n",
      "Epoch 1072, Loss: 213.39017266780004, Neurons: 201, Grad norm: 3.380358435369323\n",
      "Epoch 1072, Loss: 213.39017266780004, Neurons: 201, Grad norm: 3.380358435369323\n",
      "Epoch 1073, Loss: 213.38474092864442, Neurons: 201, Grad norm: 3.378004035448198\n",
      "Epoch 1073, Loss: 213.38474092864442, Neurons: 201, Grad norm: 3.378004035448198\n",
      "Epoch 1074, Loss: 213.3793596912603, Neurons: 201, Grad norm: 3.371758827027789\n",
      "Epoch 1074, Loss: 213.3793596912603, Neurons: 201, Grad norm: 3.371758827027789\n",
      "Epoch 1075, Loss: 213.37401932295913, Neurons: 201, Grad norm: 3.360067969939611\n",
      "Epoch 1075, Loss: 213.37401932295913, Neurons: 201, Grad norm: 3.360067969939611\n",
      "Epoch 1076, Loss: 213.36869530847798, Neurons: 201, Grad norm: 3.353987566723039\n",
      "Epoch 1076, Loss: 213.36869530847798, Neurons: 201, Grad norm: 3.353987566723039\n",
      "Epoch 1077, Loss: 213.36336687501566, Neurons: 201, Grad norm: 3.354972238864157\n",
      "Epoch 1077, Loss: 213.36336687501566, Neurons: 201, Grad norm: 3.354972238864157\n",
      "Epoch 1078, Loss: 213.35801151230564, Neurons: 201, Grad norm: 3.35083284145142\n",
      "Epoch 1078, Loss: 213.35801151230564, Neurons: 201, Grad norm: 3.35083284145142\n",
      "Epoch 1079, Loss: 213.35260074942568, Neurons: 201, Grad norm: 3.3435142941905283\n",
      "Epoch 1079, Loss: 213.35260074942568, Neurons: 201, Grad norm: 3.3435142941905283\n",
      "Epoch 1080, Loss: 213.34716032354697, Neurons: 201, Grad norm: 3.345786226868716\n",
      "Epoch 1080, Loss: 213.34716032354697, Neurons: 201, Grad norm: 3.345786226868716\n",
      "Epoch 1081, Loss: 213.34173321256733, Neurons: 201, Grad norm: 3.3312894929515173\n",
      "Epoch 1081, Loss: 213.34173321256733, Neurons: 201, Grad norm: 3.3312894929515173\n",
      "Epoch 1082, Loss: 213.3362513220045, Neurons: 201, Grad norm: 3.3268953892474475\n",
      "Epoch 1082, Loss: 213.3362513220045, Neurons: 201, Grad norm: 3.3268953892474475\n",
      "Epoch 1083, Loss: 213.33075524182567, Neurons: 201, Grad norm: 3.314833722988104\n",
      "Epoch 1083, Loss: 213.33075524182567, Neurons: 201, Grad norm: 3.314833722988104\n",
      "Epoch 1084, Loss: 213.32525551326165, Neurons: 201, Grad norm: 3.319843816205927\n",
      "Epoch 1084, Loss: 213.32525551326165, Neurons: 201, Grad norm: 3.319843816205927\n",
      "Epoch 1085, Loss: 213.31974119831912, Neurons: 201, Grad norm: 3.331961458929022\n",
      "Epoch 1085, Loss: 213.31974119831912, Neurons: 201, Grad norm: 3.331961458929022\n",
      "Epoch 1086, Loss: 213.31417701382898, Neurons: 201, Grad norm: 3.338742617999729\n",
      "Epoch 1086, Loss: 213.31417701382898, Neurons: 201, Grad norm: 3.338742617999729\n",
      "Epoch 1087, Loss: 213.30860995666762, Neurons: 201, Grad norm: 3.351686373428064\n",
      "Epoch 1087, Loss: 213.30860995666762, Neurons: 201, Grad norm: 3.351686373428064\n",
      "Epoch 1088, Loss: 213.3030483183305, Neurons: 201, Grad norm: 3.370946721981587\n",
      "Epoch 1088, Loss: 213.3030483183305, Neurons: 201, Grad norm: 3.370946721981587\n",
      "Epoch 1089, Loss: 213.2975546596094, Neurons: 201, Grad norm: 3.3823623426011995\n",
      "Epoch 1089, Loss: 213.2975546596094, Neurons: 201, Grad norm: 3.3823623426011995\n",
      "Epoch 1090, Loss: 213.29211255838393, Neurons: 201, Grad norm: 3.3953588358306606\n",
      "Epoch 1090, Loss: 213.29211255838393, Neurons: 201, Grad norm: 3.3953588358306606\n",
      "Epoch 1091, Loss: 213.28666861917932, Neurons: 201, Grad norm: 3.398637423315826\n",
      "Epoch 1091, Loss: 213.28666861917932, Neurons: 201, Grad norm: 3.398637423315826\n",
      "Epoch 1092, Loss: 213.28123853796296, Neurons: 201, Grad norm: 3.3951869529905174\n",
      "Epoch 1092, Loss: 213.28123853796296, Neurons: 201, Grad norm: 3.3951869529905174\n",
      "Epoch 1093, Loss: 213.2758390629859, Neurons: 201, Grad norm: 3.383389488489002\n",
      "Epoch 1093, Loss: 213.2758390629859, Neurons: 201, Grad norm: 3.383389488489002\n",
      "Epoch 1094, Loss: 213.2704910913, Neurons: 201, Grad norm: 3.371390130252042\n",
      "Epoch 1094, Loss: 213.2704910913, Neurons: 201, Grad norm: 3.371390130252042\n",
      "Epoch 1095, Loss: 213.26512438208832, Neurons: 201, Grad norm: 3.361003482645889\n",
      "Epoch 1095, Loss: 213.26512438208832, Neurons: 201, Grad norm: 3.361003482645889\n",
      "Epoch 1096, Loss: 213.25975445401102, Neurons: 201, Grad norm: 3.3584701128058443\n",
      "Epoch 1096, Loss: 213.25975445401102, Neurons: 201, Grad norm: 3.3584701128058443\n",
      "Epoch 1097, Loss: 213.25440313296846, Neurons: 201, Grad norm: 3.3566723895257486\n",
      "Epoch 1097, Loss: 213.25440313296846, Neurons: 201, Grad norm: 3.3566723895257486\n",
      "Epoch 1098, Loss: 213.24905705582597, Neurons: 201, Grad norm: 3.3591168087992975\n",
      "Epoch 1098, Loss: 213.24905705582597, Neurons: 201, Grad norm: 3.3591168087992975\n",
      "Epoch 1099, Loss: 213.24374940581086, Neurons: 201, Grad norm: 3.363646649333008\n",
      "Epoch 1099, Loss: 213.24374940581086, Neurons: 201, Grad norm: 3.363646649333008\n",
      "Epoch 1100, Loss: 213.23843037404708, Neurons: 201, Grad norm: 3.3646937174075924\n",
      "Epoch 1100, Loss: 213.23843037404708, Neurons: 201, Grad norm: 3.3646937174075924\n",
      "Epoch 1101, Loss: 213.23309808584546, Neurons: 201, Grad norm: 3.3634472651993135\n",
      "Epoch 1101, Loss: 213.23309808584546, Neurons: 201, Grad norm: 3.3634472651993135\n",
      "Epoch 1102, Loss: 213.2277546770601, Neurons: 201, Grad norm: 3.363187843978578\n",
      "Epoch 1102, Loss: 213.2277546770601, Neurons: 201, Grad norm: 3.363187843978578\n",
      "Epoch 1103, Loss: 213.22239912226215, Neurons: 201, Grad norm: 3.363765964343986\n",
      "Epoch 1103, Loss: 213.22239912226215, Neurons: 201, Grad norm: 3.363765964343986\n",
      "Epoch 1104, Loss: 213.21705140164758, Neurons: 201, Grad norm: 3.360808557886642\n",
      "Epoch 1104, Loss: 213.21705140164758, Neurons: 201, Grad norm: 3.360808557886642\n",
      "Epoch 1105, Loss: 213.21171237350103, Neurons: 201, Grad norm: 3.350305197562238\n",
      "Epoch 1105, Loss: 213.21171237350103, Neurons: 201, Grad norm: 3.350305197562238\n",
      "Epoch 1106, Loss: 213.20637817290273, Neurons: 201, Grad norm: 3.3349721381818647\n",
      "Epoch 1106, Loss: 213.20637817290273, Neurons: 201, Grad norm: 3.3349721381818647\n",
      "Epoch 1107, Loss: 213.2010454656946, Neurons: 201, Grad norm: 3.315066259729592\n",
      "Epoch 1107, Loss: 213.2010454656946, Neurons: 201, Grad norm: 3.315066259729592\n",
      "Epoch 1108, Loss: 213.19571838991578, Neurons: 201, Grad norm: 3.3008621926886685\n",
      "Epoch 1108, Loss: 213.19571838991578, Neurons: 201, Grad norm: 3.3008621926886685\n",
      "Epoch 1109, Loss: 213.1904251912062, Neurons: 201, Grad norm: 3.2953724394604667\n",
      "Epoch 1109, Loss: 213.1904251912062, Neurons: 201, Grad norm: 3.2953724394604667\n",
      "Epoch 1110, Loss: 213.1851402212414, Neurons: 201, Grad norm: 3.2964804487111317\n",
      "Epoch 1110, Loss: 213.1851402212414, Neurons: 201, Grad norm: 3.2964804487111317\n",
      "Epoch 1111, Loss: 213.17987186811837, Neurons: 201, Grad norm: 3.2967724085651517\n",
      "Epoch 1111, Loss: 213.17987186811837, Neurons: 201, Grad norm: 3.2967724085651517\n",
      "Epoch 1112, Loss: 213.1746102052592, Neurons: 201, Grad norm: 3.29059228221938\n",
      "Epoch 1112, Loss: 213.1746102052592, Neurons: 201, Grad norm: 3.29059228221938\n",
      "Epoch 1113, Loss: 213.16937673281745, Neurons: 201, Grad norm: 3.2822482476218315\n",
      "Epoch 1113, Loss: 213.16937673281745, Neurons: 201, Grad norm: 3.2822482476218315\n",
      "Epoch 1114, Loss: 213.1641626308225, Neurons: 201, Grad norm: 3.2695287787901823\n",
      "Epoch 1114, Loss: 213.1641626308225, Neurons: 201, Grad norm: 3.2695287787901823\n",
      "Epoch 1115, Loss: 213.15894865969312, Neurons: 201, Grad norm: 3.2632020476533037\n",
      "Epoch 1115, Loss: 213.15894865969312, Neurons: 201, Grad norm: 3.2632020476533037\n",
      "Epoch 1116, Loss: 213.15372153973618, Neurons: 201, Grad norm: 3.2600309769239453\n",
      "Epoch 1116, Loss: 213.15372153973618, Neurons: 201, Grad norm: 3.2600309769239453\n",
      "Epoch 1117, Loss: 213.14848390931917, Neurons: 201, Grad norm: 3.264548248039648\n",
      "Epoch 1117, Loss: 213.14848390931917, Neurons: 201, Grad norm: 3.264548248039648\n",
      "Epoch 1118, Loss: 213.1432379337586, Neurons: 201, Grad norm: 3.2712410205699283\n",
      "Epoch 1118, Loss: 213.1432379337586, Neurons: 201, Grad norm: 3.2712410205699283\n",
      "Epoch 1119, Loss: 213.13800512246576, Neurons: 201, Grad norm: 3.276537669315002\n",
      "Epoch 1119, Loss: 213.13800512246576, Neurons: 201, Grad norm: 3.276537669315002\n",
      "Epoch 1120, Loss: 213.13276698054594, Neurons: 201, Grad norm: 3.2810480206928787\n",
      "Epoch 1120, Loss: 213.13276698054594, Neurons: 201, Grad norm: 3.2810480206928787\n",
      "Epoch 1121, Loss: 213.12753496599197, Neurons: 201, Grad norm: 3.282622495576576\n",
      "Epoch 1121, Loss: 213.12753496599197, Neurons: 201, Grad norm: 3.282622495576576\n",
      "Epoch 1122, Loss: 213.12231085000528, Neurons: 201, Grad norm: 3.2761697658818423\n",
      "Epoch 1122, Loss: 213.12231085000528, Neurons: 201, Grad norm: 3.2761697658818423\n",
      "Epoch 1123, Loss: 213.11709119247232, Neurons: 201, Grad norm: 3.2607777046219892\n",
      "Epoch 1123, Loss: 213.11709119247232, Neurons: 201, Grad norm: 3.2607777046219892\n",
      "Epoch 1124, Loss: 213.11186931777002, Neurons: 201, Grad norm: 3.2427697718387427\n",
      "Epoch 1124, Loss: 213.11186931777002, Neurons: 201, Grad norm: 3.2427697718387427\n",
      "Epoch 1125, Loss: 213.1066520587227, Neurons: 201, Grad norm: 3.2262647502830646\n",
      "Epoch 1125, Loss: 213.1066520587227, Neurons: 201, Grad norm: 3.2262647502830646\n",
      "Epoch 1126, Loss: 213.10144029147705, Neurons: 201, Grad norm: 3.211677252622938\n",
      "Epoch 1126, Loss: 213.10144029147705, Neurons: 201, Grad norm: 3.211677252622938\n",
      "Epoch 1127, Loss: 213.09622672580255, Neurons: 201, Grad norm: 3.206648821142339\n",
      "Epoch 1127, Loss: 213.09622672580255, Neurons: 201, Grad norm: 3.206648821142339\n",
      "Epoch 1128, Loss: 213.0910173750181, Neurons: 201, Grad norm: 3.209328147972683\n",
      "Epoch 1128, Loss: 213.0910173750181, Neurons: 201, Grad norm: 3.209328147972683\n",
      "Epoch 1129, Loss: 213.085817739769, Neurons: 201, Grad norm: 3.2100397435120125\n",
      "Epoch 1129, Loss: 213.085817739769, Neurons: 201, Grad norm: 3.2100397435120125\n",
      "Epoch 1130, Loss: 213.08062511156177, Neurons: 201, Grad norm: 3.2079117112255733\n",
      "Epoch 1130, Loss: 213.08062511156177, Neurons: 201, Grad norm: 3.2079117112255733\n",
      "Epoch 1131, Loss: 213.07544142261125, Neurons: 201, Grad norm: 3.2067156091875697\n",
      "Epoch 1131, Loss: 213.07544142261125, Neurons: 201, Grad norm: 3.2067156091875697\n",
      "Epoch 1132, Loss: 213.07028614848565, Neurons: 201, Grad norm: 3.210091195414657\n",
      "Epoch 1132, Loss: 213.07028614848565, Neurons: 201, Grad norm: 3.210091195414657\n",
      "Epoch 1133, Loss: 213.0651274451162, Neurons: 201, Grad norm: 3.217309099571547\n",
      "Epoch 1133, Loss: 213.0651274451162, Neurons: 201, Grad norm: 3.217309099571547\n",
      "Epoch 1134, Loss: 213.05996501685078, Neurons: 201, Grad norm: 3.236948155092763\n",
      "Epoch 1134, Loss: 213.05996501685078, Neurons: 201, Grad norm: 3.236948155092763\n",
      "Epoch 1135, Loss: 213.05480704838044, Neurons: 201, Grad norm: 3.2593251548139133\n",
      "Epoch 1135, Loss: 213.05480704838044, Neurons: 201, Grad norm: 3.2593251548139133\n",
      "Epoch 1136, Loss: 213.0496455008011, Neurons: 201, Grad norm: 3.2840613990360406\n",
      "Epoch 1136, Loss: 213.0496455008011, Neurons: 201, Grad norm: 3.2840613990360406\n",
      "Epoch 1137, Loss: 213.04449233742997, Neurons: 201, Grad norm: 3.307257297315302\n",
      "Epoch 1137, Loss: 213.04449233742997, Neurons: 201, Grad norm: 3.307257297315302\n",
      "Epoch 1138, Loss: 213.0393437090966, Neurons: 201, Grad norm: 3.320200894624396\n",
      "Epoch 1138, Loss: 213.0393437090966, Neurons: 201, Grad norm: 3.320200894624396\n",
      "Epoch 1139, Loss: 213.03419332871232, Neurons: 201, Grad norm: 3.3218455010795083\n",
      "Epoch 1139, Loss: 213.03419332871232, Neurons: 201, Grad norm: 3.3218455010795083\n",
      "Epoch 1140, Loss: 213.0290512331292, Neurons: 201, Grad norm: 3.308564026028289\n",
      "Epoch 1140, Loss: 213.0290512331292, Neurons: 201, Grad norm: 3.308564026028289\n",
      "Epoch 1141, Loss: 213.02393232884415, Neurons: 201, Grad norm: 3.288446904181539\n",
      "Epoch 1141, Loss: 213.02393232884415, Neurons: 201, Grad norm: 3.288446904181539\n",
      "Epoch 1142, Loss: 213.01883052394626, Neurons: 201, Grad norm: 3.2683110878068957\n",
      "Epoch 1142, Loss: 213.01883052394626, Neurons: 201, Grad norm: 3.2683110878068957\n",
      "Epoch 1143, Loss: 213.01373190285554, Neurons: 201, Grad norm: 3.2445415740378234\n",
      "Epoch 1143, Loss: 213.01373190285554, Neurons: 201, Grad norm: 3.2445415740378234\n",
      "Epoch 1144, Loss: 213.00865424366754, Neurons: 201, Grad norm: 3.2290302168929523\n",
      "Epoch 1144, Loss: 213.00865424366754, Neurons: 201, Grad norm: 3.2290302168929523\n",
      "Epoch 1145, Loss: 213.0035811715293, Neurons: 201, Grad norm: 3.220727865240549\n",
      "Epoch 1145, Loss: 213.0035811715293, Neurons: 201, Grad norm: 3.220727865240549\n",
      "Epoch 1146, Loss: 212.99852888212757, Neurons: 201, Grad norm: 3.2224847671563137\n",
      "Epoch 1146, Loss: 212.99852888212757, Neurons: 201, Grad norm: 3.2224847671563137\n",
      "Epoch 1147, Loss: 212.99348980534356, Neurons: 201, Grad norm: 3.225262362808984\n",
      "Epoch 1147, Loss: 212.99348980534356, Neurons: 201, Grad norm: 3.225262362808984\n",
      "Epoch 1148, Loss: 212.98845216252988, Neurons: 201, Grad norm: 3.2275297460441323\n",
      "Epoch 1148, Loss: 212.98845216252988, Neurons: 201, Grad norm: 3.2275297460441323\n",
      "Epoch 1149, Loss: 212.98341374565484, Neurons: 201, Grad norm: 3.2245597438282223\n",
      "Epoch 1149, Loss: 212.98341374565484, Neurons: 201, Grad norm: 3.2245597438282223\n",
      "Epoch 1150, Loss: 212.97837539062766, Neurons: 201, Grad norm: 3.2236428904161496\n",
      "Epoch 1150, Loss: 212.97837539062766, Neurons: 201, Grad norm: 3.2236428904161496\n",
      "Epoch 1151, Loss: 212.9733282325731, Neurons: 201, Grad norm: 3.2250094774800138\n",
      "Epoch 1151, Loss: 212.9733282325731, Neurons: 201, Grad norm: 3.2250094774800138\n",
      "Epoch 1152, Loss: 212.96827110923059, Neurons: 201, Grad norm: 3.2199747298682797\n",
      "Epoch 1152, Loss: 212.96827110923059, Neurons: 201, Grad norm: 3.2199747298682797\n",
      "Epoch 1153, Loss: 212.9632253372102, Neurons: 201, Grad norm: 3.22374287537303\n",
      "Epoch 1153, Loss: 212.9632253372102, Neurons: 201, Grad norm: 3.22374287537303\n",
      "Epoch 1154, Loss: 212.95819277049182, Neurons: 201, Grad norm: 3.2261885799458963\n",
      "Epoch 1154, Loss: 212.95819277049182, Neurons: 201, Grad norm: 3.2261885799458963\n",
      "Epoch 1155, Loss: 212.9531429867798, Neurons: 201, Grad norm: 3.228327993556138\n",
      "Epoch 1155, Loss: 212.9531429867798, Neurons: 201, Grad norm: 3.228327993556138\n",
      "Epoch 1156, Loss: 212.9481249049643, Neurons: 201, Grad norm: 3.228122795456001\n",
      "Epoch 1156, Loss: 212.9481249049643, Neurons: 201, Grad norm: 3.228122795456001\n",
      "Epoch 1157, Loss: 212.94313650089364, Neurons: 201, Grad norm: 3.227086865889264\n",
      "Epoch 1157, Loss: 212.94313650089364, Neurons: 201, Grad norm: 3.227086865889264\n",
      "Epoch 1158, Loss: 212.93813369766144, Neurons: 201, Grad norm: 3.221384395980289\n",
      "Epoch 1158, Loss: 212.93813369766144, Neurons: 201, Grad norm: 3.221384395980289\n",
      "Epoch 1159, Loss: 212.9331403942598, Neurons: 201, Grad norm: 3.2113241698296866\n",
      "Epoch 1159, Loss: 212.9331403942598, Neurons: 201, Grad norm: 3.2113241698296866\n",
      "Epoch 1160, Loss: 212.92821356256303, Neurons: 201, Grad norm: 3.200107362291156\n",
      "Epoch 1160, Loss: 212.92821356256303, Neurons: 201, Grad norm: 3.200107362291156\n",
      "Epoch 1161, Loss: 212.9233357675425, Neurons: 201, Grad norm: 3.1826987787776346\n",
      "Epoch 1161, Loss: 212.9233357675425, Neurons: 201, Grad norm: 3.1826987787776346\n",
      "Epoch 1162, Loss: 212.91846048600732, Neurons: 201, Grad norm: 3.1637269365410305\n",
      "Epoch 1162, Loss: 212.91846048600732, Neurons: 201, Grad norm: 3.1637269365410305\n",
      "Epoch 1163, Loss: 212.91355726859803, Neurons: 201, Grad norm: 3.1417211397268807\n",
      "Epoch 1163, Loss: 212.91355726859803, Neurons: 201, Grad norm: 3.1417211397268807\n",
      "Epoch 1164, Loss: 212.9086633246071, Neurons: 201, Grad norm: 3.1220743941776656\n",
      "Epoch 1164, Loss: 212.9086633246071, Neurons: 201, Grad norm: 3.1220743941776656\n",
      "Epoch 1165, Loss: 212.90375300460113, Neurons: 201, Grad norm: 3.110075822981784\n",
      "Epoch 1165, Loss: 212.90375300460113, Neurons: 201, Grad norm: 3.110075822981784\n",
      "Epoch 1166, Loss: 212.89883375243372, Neurons: 201, Grad norm: 3.1033711054809934\n",
      "Epoch 1166, Loss: 212.89883375243372, Neurons: 201, Grad norm: 3.1033711054809934\n",
      "Epoch 1167, Loss: 212.89391155446, Neurons: 201, Grad norm: 3.1034380547643923\n",
      "Epoch 1167, Loss: 212.89391155446, Neurons: 201, Grad norm: 3.1034380547643923\n",
      "Epoch 1168, Loss: 212.8890141004914, Neurons: 201, Grad norm: 3.10477895953606\n",
      "Epoch 1168, Loss: 212.8890141004914, Neurons: 201, Grad norm: 3.10477895953606\n",
      "Epoch 1169, Loss: 212.88413379230622, Neurons: 201, Grad norm: 3.1016946443011086\n",
      "Epoch 1169, Loss: 212.88413379230622, Neurons: 201, Grad norm: 3.1016946443011086\n",
      "Epoch 1170, Loss: 212.87926681508014, Neurons: 201, Grad norm: 3.0980334706734745\n",
      "Epoch 1170, Loss: 212.87926681508014, Neurons: 201, Grad norm: 3.0980334706734745\n",
      "Epoch 1171, Loss: 212.87443785556516, Neurons: 201, Grad norm: 3.0916304291753747\n",
      "Epoch 1171, Loss: 212.87443785556516, Neurons: 201, Grad norm: 3.0916304291753747\n",
      "Epoch 1172, Loss: 212.86960833750769, Neurons: 201, Grad norm: 3.086151525082875\n",
      "Epoch 1172, Loss: 212.86960833750769, Neurons: 201, Grad norm: 3.086151525082875\n",
      "Epoch 1173, Loss: 212.86481389074854, Neurons: 201, Grad norm: 3.0867683257937224\n",
      "Epoch 1173, Loss: 212.86481389074854, Neurons: 201, Grad norm: 3.0867683257937224\n",
      "Epoch 1174, Loss: 212.86005106752214, Neurons: 201, Grad norm: 3.0896798121570606\n",
      "Epoch 1174, Loss: 212.86005106752214, Neurons: 201, Grad norm: 3.0896798121570606\n",
      "Epoch 1175, Loss: 212.85529058077248, Neurons: 201, Grad norm: 3.0892411898978946\n",
      "Epoch 1175, Loss: 212.85529058077248, Neurons: 201, Grad norm: 3.0892411898978946\n",
      "Epoch 1176, Loss: 212.85053431755898, Neurons: 201, Grad norm: 3.0811196146021858\n",
      "Epoch 1176, Loss: 212.85053431755898, Neurons: 201, Grad norm: 3.0811196146021858\n",
      "Epoch 1177, Loss: 212.84577825453707, Neurons: 201, Grad norm: 3.0721996282753072\n",
      "Epoch 1177, Loss: 212.84577825453707, Neurons: 201, Grad norm: 3.0721996282753072\n",
      "Epoch 1178, Loss: 212.84102933145073, Neurons: 201, Grad norm: 3.0619470341105903\n",
      "Epoch 1178, Loss: 212.84102933145073, Neurons: 201, Grad norm: 3.0619470341105903\n",
      "Epoch 1179, Loss: 212.83630060907723, Neurons: 201, Grad norm: 3.0488264074847806\n",
      "Epoch 1179, Loss: 212.83630060907723, Neurons: 201, Grad norm: 3.0488264074847806\n",
      "Epoch 1180, Loss: 212.83158036695846, Neurons: 201, Grad norm: 3.036135322281485\n",
      "Epoch 1180, Loss: 212.83158036695846, Neurons: 201, Grad norm: 3.036135322281485\n",
      "Epoch 1181, Loss: 212.82686558680172, Neurons: 201, Grad norm: 3.0265656321091203\n",
      "Epoch 1181, Loss: 212.82686558680172, Neurons: 201, Grad norm: 3.0265656321091203\n",
      "Epoch 1182, Loss: 212.8221576120694, Neurons: 201, Grad norm: 3.027934540933529\n",
      "Epoch 1182, Loss: 212.8221576120694, Neurons: 201, Grad norm: 3.027934540933529\n",
      "Epoch 1183, Loss: 212.81743413274583, Neurons: 201, Grad norm: 3.035580405449704\n",
      "Epoch 1183, Loss: 212.81743413274583, Neurons: 201, Grad norm: 3.035580405449704\n",
      "Epoch 1184, Loss: 212.81268627436577, Neurons: 201, Grad norm: 3.045682827437615\n",
      "Epoch 1184, Loss: 212.81268627436577, Neurons: 201, Grad norm: 3.045682827437615\n",
      "Epoch 1185, Loss: 212.80791436391243, Neurons: 201, Grad norm: 3.0546856674661873\n",
      "Epoch 1185, Loss: 212.80791436391243, Neurons: 201, Grad norm: 3.0546856674661873\n",
      "Epoch 1186, Loss: 212.8031386150275, Neurons: 201, Grad norm: 3.057820145083604\n",
      "Epoch 1186, Loss: 212.8031386150275, Neurons: 201, Grad norm: 3.057820145083604\n",
      "Epoch 1187, Loss: 212.7983600544005, Neurons: 201, Grad norm: 3.0608191472376416\n",
      "Epoch 1187, Loss: 212.7983600544005, Neurons: 201, Grad norm: 3.0608191472376416\n",
      "Epoch 1188, Loss: 212.79359774635506, Neurons: 201, Grad norm: 3.0600819152536927\n",
      "Epoch 1188, Loss: 212.79359774635506, Neurons: 201, Grad norm: 3.0600819152536927\n",
      "Epoch 1189, Loss: 212.7888240191958, Neurons: 201, Grad norm: 3.062362022382602\n",
      "Epoch 1189, Loss: 212.7888240191958, Neurons: 201, Grad norm: 3.062362022382602\n",
      "Epoch 1190, Loss: 212.7840417712763, Neurons: 201, Grad norm: 3.064129215455492\n",
      "Epoch 1190, Loss: 212.7840417712763, Neurons: 201, Grad norm: 3.064129215455492\n",
      "Epoch 1191, Loss: 212.77923554011323, Neurons: 201, Grad norm: 3.0728199184198703\n",
      "Epoch 1191, Loss: 212.77923554011323, Neurons: 201, Grad norm: 3.0728199184198703\n",
      "Epoch 1192, Loss: 212.77442587841773, Neurons: 201, Grad norm: 3.0784290099496197\n",
      "Epoch 1192, Loss: 212.77442587841773, Neurons: 201, Grad norm: 3.0784290099496197\n",
      "Epoch 1193, Loss: 212.76963606173783, Neurons: 201, Grad norm: 3.0826169764569356\n",
      "Epoch 1193, Loss: 212.76963606173783, Neurons: 201, Grad norm: 3.0826169764569356\n",
      "Epoch 1194, Loss: 212.76484642532583, Neurons: 201, Grad norm: 3.0820430381421366\n",
      "Epoch 1194, Loss: 212.76484642532583, Neurons: 201, Grad norm: 3.0820430381421366\n",
      "Epoch 1195, Loss: 212.76003178887748, Neurons: 201, Grad norm: 3.073187558397524\n",
      "Epoch 1195, Loss: 212.76003178887748, Neurons: 201, Grad norm: 3.073187558397524\n",
      "Epoch 1196, Loss: 212.75517968681916, Neurons: 201, Grad norm: 3.0632518059793767\n",
      "Epoch 1196, Loss: 212.75517968681916, Neurons: 201, Grad norm: 3.0632518059793767\n",
      "Epoch 1197, Loss: 212.7503045732845, Neurons: 201, Grad norm: 3.0633739041377095\n",
      "Epoch 1197, Loss: 212.7503045732845, Neurons: 201, Grad norm: 3.0633739041377095\n",
      "Epoch 1198, Loss: 212.74543209677057, Neurons: 201, Grad norm: 3.07283459101254\n",
      "Epoch 1198, Loss: 212.74543209677057, Neurons: 201, Grad norm: 3.07283459101254\n",
      "Epoch 1199, Loss: 212.74054784690284, Neurons: 201, Grad norm: 3.07760691228553\n",
      "Epoch 1199, Loss: 212.74054784690284, Neurons: 201, Grad norm: 3.07760691228553\n",
      "Epoch 1200, Loss: 212.73565142864578, Neurons: 201, Grad norm: 3.089169046210769\n",
      "Epoch 1200, Loss: 212.73565142864578, Neurons: 201, Grad norm: 3.089169046210769\n",
      "Epoch 1201, Loss: 212.73075598693168, Neurons: 201, Grad norm: 3.112698043821255\n",
      "Epoch 1201, Loss: 212.73075598693168, Neurons: 201, Grad norm: 3.112698043821255\n",
      "Epoch 1202, Loss: 212.72587218540582, Neurons: 201, Grad norm: 3.129277774762839\n",
      "Epoch 1202, Loss: 212.72587218540582, Neurons: 201, Grad norm: 3.129277774762839\n",
      "Epoch 1203, Loss: 212.72097419334213, Neurons: 201, Grad norm: 3.1353481189316215\n",
      "Epoch 1203, Loss: 212.72097419334213, Neurons: 201, Grad norm: 3.1353481189316215\n",
      "Epoch 1204, Loss: 212.71608025140839, Neurons: 201, Grad norm: 3.1348181791563916\n",
      "Epoch 1204, Loss: 212.71608025140839, Neurons: 201, Grad norm: 3.1348181791563916\n",
      "Epoch 1205, Loss: 212.7111708031702, Neurons: 201, Grad norm: 3.131527075650221\n",
      "Epoch 1205, Loss: 212.7111708031702, Neurons: 201, Grad norm: 3.131527075650221\n",
      "Epoch 1206, Loss: 212.70624395935874, Neurons: 201, Grad norm: 3.1130888712891216\n",
      "Epoch 1206, Loss: 212.70624395935874, Neurons: 201, Grad norm: 3.1130888712891216\n",
      "Epoch 1207, Loss: 212.70128726133552, Neurons: 201, Grad norm: 3.1069436582114576\n",
      "Epoch 1207, Loss: 212.70128726133552, Neurons: 201, Grad norm: 3.1069436582114576\n",
      "Epoch 1208, Loss: 212.69631029076044, Neurons: 201, Grad norm: 3.1080043101329693\n",
      "Epoch 1208, Loss: 212.69631029076044, Neurons: 201, Grad norm: 3.1080043101329693\n",
      "Epoch 1209, Loss: 212.69132050999127, Neurons: 201, Grad norm: 3.122227310412928\n",
      "Epoch 1209, Loss: 212.69132050999127, Neurons: 201, Grad norm: 3.122227310412928\n",
      "Epoch 1210, Loss: 212.6863003313155, Neurons: 201, Grad norm: 3.1490990448497835\n",
      "Epoch 1210, Loss: 212.6863003313155, Neurons: 201, Grad norm: 3.1490990448497835\n",
      "Epoch 1211, Loss: 212.68123250507318, Neurons: 201, Grad norm: 3.177357194712883\n",
      "Epoch 1211, Loss: 212.68123250507318, Neurons: 201, Grad norm: 3.177357194712883\n",
      "Epoch 1212, Loss: 212.6761197200805, Neurons: 201, Grad norm: 3.1965811332485465\n",
      "Epoch 1212, Loss: 212.6761197200805, Neurons: 201, Grad norm: 3.1965811332485465\n",
      "Epoch 1213, Loss: 212.67093465661546, Neurons: 201, Grad norm: 3.1680668002397687\n",
      "Epoch 1213, Loss: 212.67093465661546, Neurons: 201, Grad norm: 3.1680668002397687\n",
      "Epoch 1214, Loss: 212.66573120510972, Neurons: 201, Grad norm: 3.170044828430757\n",
      "Epoch 1214, Loss: 212.66573120510972, Neurons: 201, Grad norm: 3.170044828430757\n",
      "Epoch 1215, Loss: 212.66057614743082, Neurons: 201, Grad norm: 3.1550579492371345\n",
      "Epoch 1215, Loss: 212.66057614743082, Neurons: 201, Grad norm: 3.1550579492371345\n",
      "Epoch 1216, Loss: 212.65535819569286, Neurons: 201, Grad norm: 3.1618384174213627\n",
      "Epoch 1216, Loss: 212.65535819569286, Neurons: 201, Grad norm: 3.1618384174213627\n",
      "Epoch 1217, Loss: 212.65015507945483, Neurons: 201, Grad norm: 3.1911345427207207\n",
      "Epoch 1217, Loss: 212.65015507945483, Neurons: 201, Grad norm: 3.1911345427207207\n",
      "Epoch 1218, Loss: 212.64491311203565, Neurons: 201, Grad norm: 3.219800726386934\n",
      "Epoch 1218, Loss: 212.64491311203565, Neurons: 201, Grad norm: 3.219800726386934\n",
      "Epoch 1219, Loss: 212.63967328003974, Neurons: 201, Grad norm: 3.2478742145041584\n",
      "Epoch 1219, Loss: 212.63967328003974, Neurons: 201, Grad norm: 3.2478742145041584\n",
      "Epoch 1220, Loss: 212.63435174377744, Neurons: 201, Grad norm: 3.2533046434666897\n",
      "Epoch 1220, Loss: 212.63435174377744, Neurons: 201, Grad norm: 3.2533046434666897\n",
      "Epoch 1221, Loss: 212.62895841093774, Neurons: 201, Grad norm: 3.287422462855252\n",
      "Epoch 1221, Loss: 212.62895841093774, Neurons: 201, Grad norm: 3.287422462855252\n",
      "Epoch 1222, Loss: 212.62344049493402, Neurons: 201, Grad norm: 3.29499522773703\n",
      "Epoch 1222, Loss: 212.62344049493402, Neurons: 201, Grad norm: 3.29499522773703\n",
      "Epoch 1223, Loss: 212.61767244184318, Neurons: 201, Grad norm: 3.2940366590707173\n",
      "Epoch 1223, Loss: 212.61767244184318, Neurons: 201, Grad norm: 3.2940366590707173\n",
      "Epoch 1224, Loss: 212.61175930255945, Neurons: 201, Grad norm: 3.3167149720827847\n",
      "Epoch 1224, Loss: 212.61175930255945, Neurons: 201, Grad norm: 3.3167149720827847\n",
      "Epoch 1225, Loss: 212.60577084994756, Neurons: 201, Grad norm: 3.3638488272345657\n",
      "Epoch 1225, Loss: 212.60577084994756, Neurons: 201, Grad norm: 3.3638488272345657\n",
      "Epoch 1226, Loss: 212.5996775066226, Neurons: 201, Grad norm: 3.385780116546113\n",
      "Epoch 1226, Loss: 212.5996775066226, Neurons: 201, Grad norm: 3.385780116546113\n",
      "Epoch 1227, Loss: 212.59336956140297, Neurons: 201, Grad norm: 3.4712892397408335\n",
      "Epoch 1227, Loss: 212.59336956140297, Neurons: 201, Grad norm: 3.4712892397408335\n",
      "Epoch 1228, Loss: 212.586840800027, Neurons: 201, Grad norm: 3.482197252408142\n",
      "Epoch 1228, Loss: 212.586840800027, Neurons: 201, Grad norm: 3.482197252408142\n",
      "Epoch 1229, Loss: 212.5797733601566, Neurons: 201, Grad norm: 3.4190507637767626\n",
      "Epoch 1229, Loss: 212.5797733601566, Neurons: 201, Grad norm: 3.4190507637767626\n",
      "Epoch 1230, Loss: 212.57279152746827, Neurons: 201, Grad norm: 3.3804687405451608\n",
      "Epoch 1230, Loss: 212.57279152746827, Neurons: 201, Grad norm: 3.3804687405451608\n",
      "Epoch 1231, Loss: 212.56589293547017, Neurons: 201, Grad norm: 3.3901269338347744\n",
      "Epoch 1231, Loss: 212.56589293547017, Neurons: 201, Grad norm: 3.3901269338347744\n",
      "Epoch 1232, Loss: 212.55943246245934, Neurons: 201, Grad norm: 3.395137680328483\n",
      "Epoch 1232, Loss: 212.55943246245934, Neurons: 201, Grad norm: 3.395137680328483\n",
      "Epoch 1233, Loss: 212.55313448697308, Neurons: 201, Grad norm: 3.400931605884189\n",
      "Epoch 1233, Loss: 212.55313448697308, Neurons: 201, Grad norm: 3.400931605884189\n",
      "Epoch 1234, Loss: 212.54712660421535, Neurons: 201, Grad norm: 3.406823316862579\n",
      "Epoch 1234, Loss: 212.54712660421535, Neurons: 201, Grad norm: 3.406823316862579\n",
      "Epoch 1235, Loss: 212.54103309344165, Neurons: 201, Grad norm: 3.3694897183808967\n",
      "Epoch 1235, Loss: 212.54103309344165, Neurons: 201, Grad norm: 3.3694897183808967\n",
      "Epoch 1236, Loss: 212.53475509919147, Neurons: 201, Grad norm: 3.3524116644783257\n",
      "Epoch 1236, Loss: 212.53475509919147, Neurons: 201, Grad norm: 3.3524116644783257\n",
      "Epoch 1237, Loss: 212.52814530649735, Neurons: 201, Grad norm: 3.2884590249697565\n",
      "Epoch 1237, Loss: 212.52814530649735, Neurons: 201, Grad norm: 3.2884590249697565\n",
      "Epoch 1238, Loss: 212.5219607417058, Neurons: 201, Grad norm: 3.2958184610776367\n",
      "Epoch 1238, Loss: 212.5219607417058, Neurons: 201, Grad norm: 3.2958184610776367\n",
      "Epoch 1239, Loss: 212.5159384457919, Neurons: 201, Grad norm: 3.320548733441947\n",
      "Epoch 1239, Loss: 212.5159384457919, Neurons: 201, Grad norm: 3.320548733441947\n",
      "Epoch 1240, Loss: 212.50993939591308, Neurons: 201, Grad norm: 3.3542477119010097\n",
      "Epoch 1240, Loss: 212.50993939591308, Neurons: 201, Grad norm: 3.3542477119010097\n",
      "Epoch 1241, Loss: 212.50393665922806, Neurons: 201, Grad norm: 3.342973168558297\n",
      "Epoch 1241, Loss: 212.50393665922806, Neurons: 201, Grad norm: 3.342973168558297\n",
      "Epoch 1242, Loss: 212.49787987868262, Neurons: 201, Grad norm: 3.3266560189822605\n",
      "Epoch 1242, Loss: 212.49787987868262, Neurons: 201, Grad norm: 3.3266560189822605\n",
      "Epoch 1243, Loss: 212.4921644983013, Neurons: 201, Grad norm: 3.3114031971708155\n",
      "Epoch 1243, Loss: 212.4921644983013, Neurons: 201, Grad norm: 3.3114031971708155\n",
      "Epoch 1244, Loss: 212.4865512023484, Neurons: 201, Grad norm: 3.3111596392166693\n",
      "Epoch 1244, Loss: 212.4865512023484, Neurons: 201, Grad norm: 3.3111596392166693\n",
      "Epoch 1245, Loss: 212.48113008351808, Neurons: 201, Grad norm: 3.324526255926253\n",
      "Epoch 1245, Loss: 212.48113008351808, Neurons: 201, Grad norm: 3.324526255926253\n",
      "Epoch 1246, Loss: 212.47574536575675, Neurons: 201, Grad norm: 3.3410050016464536\n",
      "Epoch 1246, Loss: 212.47574536575675, Neurons: 201, Grad norm: 3.3410050016464536\n",
      "Epoch 1247, Loss: 212.4702419614634, Neurons: 201, Grad norm: 3.328903376796381\n",
      "Epoch 1247, Loss: 212.4702419614634, Neurons: 201, Grad norm: 3.328903376796381\n",
      "Epoch 1248, Loss: 212.4646144513315, Neurons: 201, Grad norm: 3.3124871015262993\n",
      "Epoch 1248, Loss: 212.4646144513315, Neurons: 201, Grad norm: 3.3124871015262993\n",
      "Epoch 1249, Loss: 212.45892251699053, Neurons: 201, Grad norm: 3.2792497521765296\n",
      "Epoch 1249, Loss: 212.45892251699053, Neurons: 201, Grad norm: 3.2792497521765296\n",
      "Epoch 1250, Loss: 212.4532006650732, Neurons: 201, Grad norm: 3.256744260469034\n",
      "Epoch 1250, Loss: 212.4532006650732, Neurons: 201, Grad norm: 3.256744260469034\n",
      "Epoch 1251, Loss: 212.4474952828228, Neurons: 201, Grad norm: 3.2407886549968383\n",
      "Epoch 1251, Loss: 212.4474952828228, Neurons: 201, Grad norm: 3.2407886549968383\n",
      "Epoch 1252, Loss: 212.44168395192062, Neurons: 201, Grad norm: 3.221623546022342\n",
      "Epoch 1252, Loss: 212.44168395192062, Neurons: 201, Grad norm: 3.221623546022342\n",
      "Epoch 1253, Loss: 212.43595243353877, Neurons: 201, Grad norm: 3.239266745825607\n",
      "Epoch 1253, Loss: 212.43595243353877, Neurons: 201, Grad norm: 3.239266745825607\n",
      "Epoch 1254, Loss: 212.43043479236104, Neurons: 201, Grad norm: 3.237294295568895\n",
      "Epoch 1254, Loss: 212.43043479236104, Neurons: 201, Grad norm: 3.237294295568895\n",
      "Epoch 1255, Loss: 212.4249487462042, Neurons: 201, Grad norm: 3.209491767217411\n",
      "Epoch 1255, Loss: 212.4249487462042, Neurons: 201, Grad norm: 3.209491767217411\n",
      "Epoch 1256, Loss: 212.41976763497613, Neurons: 201, Grad norm: 3.189888765909049\n",
      "Epoch 1256, Loss: 212.41976763497613, Neurons: 201, Grad norm: 3.189888765909049\n",
      "Epoch 1257, Loss: 212.4147319315409, Neurons: 201, Grad norm: 3.1747509492962642\n",
      "Epoch 1257, Loss: 212.4147319315409, Neurons: 201, Grad norm: 3.1747509492962642\n",
      "Epoch 1258, Loss: 212.4097426459353, Neurons: 201, Grad norm: 3.156720278025334\n",
      "Epoch 1258, Loss: 212.4097426459353, Neurons: 201, Grad norm: 3.156720278025334\n",
      "Epoch 1259, Loss: 212.40478640913005, Neurons: 201, Grad norm: 3.160582675000602\n",
      "Epoch 1259, Loss: 212.40478640913005, Neurons: 201, Grad norm: 3.160582675000602\n",
      "Epoch 1260, Loss: 212.39996848284844, Neurons: 201, Grad norm: 3.1783898159778716\n",
      "Epoch 1260, Loss: 212.39996848284844, Neurons: 201, Grad norm: 3.1783898159778716\n",
      "Epoch 1261, Loss: 212.3951426192515, Neurons: 201, Grad norm: 3.192568092776553\n",
      "Epoch 1261, Loss: 212.3951426192515, Neurons: 201, Grad norm: 3.192568092776553\n",
      "Epoch 1262, Loss: 212.39033209431133, Neurons: 201, Grad norm: 3.1957504251126867\n",
      "Epoch 1262, Loss: 212.39033209431133, Neurons: 201, Grad norm: 3.1957504251126867\n",
      "Epoch 1263, Loss: 212.38559112501133, Neurons: 201, Grad norm: 3.194431700177834\n",
      "Epoch 1263, Loss: 212.38559112501133, Neurons: 201, Grad norm: 3.194431700177834\n",
      "Epoch 1264, Loss: 212.38089760157578, Neurons: 201, Grad norm: 3.192734568839247\n",
      "Epoch 1264, Loss: 212.38089760157578, Neurons: 201, Grad norm: 3.192734568839247\n",
      "Epoch 1265, Loss: 212.37622555659317, Neurons: 201, Grad norm: 3.2016967307391777\n",
      "Epoch 1265, Loss: 212.37622555659317, Neurons: 201, Grad norm: 3.2016967307391777\n",
      "Epoch 1266, Loss: 212.3715399943401, Neurons: 201, Grad norm: 3.2191419307430693\n",
      "Epoch 1266, Loss: 212.3715399943401, Neurons: 201, Grad norm: 3.2191419307430693\n",
      "Epoch 1267, Loss: 212.36682485090097, Neurons: 201, Grad norm: 3.2188187507047825\n",
      "Epoch 1267, Loss: 212.36682485090097, Neurons: 201, Grad norm: 3.2188187507047825\n",
      "Epoch 1268, Loss: 212.36213212775837, Neurons: 201, Grad norm: 3.199099257845302\n",
      "Epoch 1268, Loss: 212.36213212775837, Neurons: 201, Grad norm: 3.199099257845302\n",
      "Epoch 1269, Loss: 212.35748877974854, Neurons: 201, Grad norm: 3.1644678839030367\n",
      "Epoch 1269, Loss: 212.35748877974854, Neurons: 201, Grad norm: 3.1644678839030367\n",
      "Epoch 1270, Loss: 212.35284685858323, Neurons: 201, Grad norm: 3.1276501204124787\n",
      "Epoch 1270, Loss: 212.35284685858323, Neurons: 201, Grad norm: 3.1276501204124787\n",
      "Epoch 1271, Loss: 212.34821694687344, Neurons: 201, Grad norm: 3.09925885073901\n",
      "Epoch 1271, Loss: 212.34821694687344, Neurons: 201, Grad norm: 3.09925885073901\n",
      "Epoch 1272, Loss: 212.3435960287616, Neurons: 201, Grad norm: 3.087028965578187\n",
      "Epoch 1272, Loss: 212.3435960287616, Neurons: 201, Grad norm: 3.087028965578187\n",
      "Epoch 1273, Loss: 212.33899932296677, Neurons: 201, Grad norm: 3.0893410530514047\n",
      "Epoch 1273, Loss: 212.33899932296677, Neurons: 201, Grad norm: 3.0893410530514047\n",
      "Epoch 1274, Loss: 212.33442771629066, Neurons: 201, Grad norm: 3.0973316092259764\n",
      "Epoch 1274, Loss: 212.33442771629066, Neurons: 201, Grad norm: 3.0973316092259764\n",
      "Epoch 1275, Loss: 212.32987325264156, Neurons: 201, Grad norm: 3.0870812524561377\n",
      "Epoch 1275, Loss: 212.32987325264156, Neurons: 201, Grad norm: 3.0870812524561377\n",
      "Epoch 1276, Loss: 212.32532879612637, Neurons: 201, Grad norm: 3.0665902679175083\n",
      "Epoch 1276, Loss: 212.32532879612637, Neurons: 201, Grad norm: 3.0665902679175083\n",
      "Epoch 1277, Loss: 212.32080145569643, Neurons: 201, Grad norm: 3.0475332565014197\n",
      "Epoch 1277, Loss: 212.32080145569643, Neurons: 201, Grad norm: 3.0475332565014197\n",
      "Epoch 1278, Loss: 212.31627689192834, Neurons: 201, Grad norm: 3.029566640302219\n",
      "Epoch 1278, Loss: 212.31627689192834, Neurons: 201, Grad norm: 3.029566640302219\n",
      "Epoch 1279, Loss: 212.3117813539461, Neurons: 201, Grad norm: 3.0295746930687977\n",
      "Epoch 1279, Loss: 212.3117813539461, Neurons: 201, Grad norm: 3.0295746930687977\n",
      "Epoch 1280, Loss: 212.30733068947492, Neurons: 201, Grad norm: 3.040807455361049\n",
      "Epoch 1280, Loss: 212.30733068947492, Neurons: 201, Grad norm: 3.040807455361049\n",
      "Epoch 1281, Loss: 212.30289695530087, Neurons: 201, Grad norm: 3.033284818474507\n",
      "Epoch 1281, Loss: 212.30289695530087, Neurons: 201, Grad norm: 3.033284818474507\n",
      "Epoch 1282, Loss: 212.29847950957813, Neurons: 201, Grad norm: 3.015501435935527\n",
      "Epoch 1282, Loss: 212.29847950957813, Neurons: 201, Grad norm: 3.015501435935527\n",
      "Epoch 1283, Loss: 212.29407582196424, Neurons: 201, Grad norm: 2.9940832733897125\n",
      "Epoch 1283, Loss: 212.29407582196424, Neurons: 201, Grad norm: 2.9940832733897125\n",
      "Epoch 1284, Loss: 212.28970365475843, Neurons: 201, Grad norm: 2.9838180633718037\n",
      "Epoch 1284, Loss: 212.28970365475843, Neurons: 201, Grad norm: 2.9838180633718037\n",
      "Epoch 1285, Loss: 212.2853691403048, Neurons: 201, Grad norm: 2.97914226503636\n",
      "Epoch 1285, Loss: 212.2853691403048, Neurons: 201, Grad norm: 2.97914226503636\n",
      "Epoch 1286, Loss: 212.28105406241204, Neurons: 201, Grad norm: 2.969469035768969\n",
      "Epoch 1286, Loss: 212.28105406241204, Neurons: 201, Grad norm: 2.969469035768969\n",
      "Epoch 1287, Loss: 212.2767564528829, Neurons: 201, Grad norm: 2.959754392943233\n",
      "Epoch 1287, Loss: 212.2767564528829, Neurons: 201, Grad norm: 2.959754392943233\n",
      "Epoch 1288, Loss: 212.27247487634148, Neurons: 201, Grad norm: 2.9488602513253435\n",
      "Epoch 1288, Loss: 212.27247487634148, Neurons: 201, Grad norm: 2.9488602513253435\n",
      "Epoch 1289, Loss: 212.26821367254212, Neurons: 201, Grad norm: 2.94189579735253\n",
      "Epoch 1289, Loss: 212.26821367254212, Neurons: 201, Grad norm: 2.94189579735253\n",
      "Epoch 1290, Loss: 212.26396207628304, Neurons: 201, Grad norm: 2.9401719633034276\n",
      "Epoch 1290, Loss: 212.26396207628304, Neurons: 201, Grad norm: 2.9401719633034276\n",
      "Epoch 1291, Loss: 212.25972119518403, Neurons: 201, Grad norm: 2.956414839894763\n",
      "Epoch 1291, Loss: 212.25972119518403, Neurons: 201, Grad norm: 2.956414839894763\n",
      "Epoch 1292, Loss: 212.2555060268967, Neurons: 201, Grad norm: 2.9697255704654495\n",
      "Epoch 1292, Loss: 212.2555060268967, Neurons: 201, Grad norm: 2.9697255704654495\n",
      "Epoch 1293, Loss: 212.25131564573587, Neurons: 201, Grad norm: 2.96896167881368\n",
      "Epoch 1293, Loss: 212.25131564573587, Neurons: 201, Grad norm: 2.96896167881368\n",
      "Epoch 1294, Loss: 212.24713197360757, Neurons: 201, Grad norm: 2.948913509753468\n",
      "Epoch 1294, Loss: 212.24713197360757, Neurons: 201, Grad norm: 2.948913509753468\n",
      "Epoch 1295, Loss: 212.24295275019608, Neurons: 201, Grad norm: 2.9305388460292403\n",
      "Epoch 1295, Loss: 212.24295275019608, Neurons: 201, Grad norm: 2.9305388460292403\n",
      "Epoch 1296, Loss: 212.23878257668164, Neurons: 201, Grad norm: 2.913801653268606\n",
      "Epoch 1296, Loss: 212.23878257668164, Neurons: 201, Grad norm: 2.913801653268606\n",
      "Epoch 1297, Loss: 212.23463219317608, Neurons: 201, Grad norm: 2.9039986426701048\n",
      "Epoch 1297, Loss: 212.23463219317608, Neurons: 201, Grad norm: 2.9039986426701048\n",
      "Epoch 1298, Loss: 212.23049679225312, Neurons: 201, Grad norm: 2.8910149474416538\n",
      "Epoch 1298, Loss: 212.23049679225312, Neurons: 201, Grad norm: 2.8910149474416538\n",
      "Epoch 1299, Loss: 212.22637575344956, Neurons: 201, Grad norm: 2.885715941713864\n",
      "Epoch 1299, Loss: 212.22637575344956, Neurons: 201, Grad norm: 2.885715941713864\n",
      "Epoch 1300, Loss: 212.2222644716969, Neurons: 201, Grad norm: 2.8903240008550424\n",
      "Epoch 1300, Loss: 212.2222644716969, Neurons: 201, Grad norm: 2.8903240008550424\n",
      "Epoch 1301, Loss: 212.21818602998178, Neurons: 201, Grad norm: 2.9061314998649057\n",
      "Epoch 1301, Loss: 212.21818602998178, Neurons: 201, Grad norm: 2.9061314998649057\n",
      "Epoch 1302, Loss: 212.21411458571396, Neurons: 201, Grad norm: 2.9224650864067687\n",
      "Epoch 1302, Loss: 212.21411458571396, Neurons: 201, Grad norm: 2.9224650864067687\n",
      "Epoch 1303, Loss: 212.21004890612357, Neurons: 201, Grad norm: 2.9239775915876742\n",
      "Epoch 1303, Loss: 212.21004890612357, Neurons: 201, Grad norm: 2.9239775915876742\n",
      "Epoch 1304, Loss: 212.20597824156286, Neurons: 201, Grad norm: 2.9074573518470364\n",
      "Epoch 1304, Loss: 212.20597824156286, Neurons: 201, Grad norm: 2.9074573518470364\n",
      "Epoch 1305, Loss: 212.2019140185311, Neurons: 201, Grad norm: 2.8935984264833685\n",
      "Epoch 1305, Loss: 212.2019140185311, Neurons: 201, Grad norm: 2.8935984264833685\n",
      "Epoch 1306, Loss: 212.1978794473626, Neurons: 201, Grad norm: 2.8950870236769126\n",
      "Epoch 1306, Loss: 212.1978794473626, Neurons: 201, Grad norm: 2.8950870236769126\n",
      "Epoch 1307, Loss: 212.19386299029324, Neurons: 201, Grad norm: 2.9049211771203\n",
      "Epoch 1307, Loss: 212.19386299029324, Neurons: 201, Grad norm: 2.9049211771203\n",
      "Epoch 1308, Loss: 212.18981220107415, Neurons: 201, Grad norm: 2.8947372927015915\n",
      "Epoch 1308, Loss: 212.18981220107415, Neurons: 201, Grad norm: 2.8947372927015915\n",
      "Epoch 1309, Loss: 212.185740968828, Neurons: 201, Grad norm: 2.8776817923068325\n",
      "Epoch 1309, Loss: 212.185740968828, Neurons: 201, Grad norm: 2.8776817923068325\n",
      "Epoch 1310, Loss: 212.18168361189115, Neurons: 201, Grad norm: 2.8622013173795766\n",
      "Epoch 1310, Loss: 212.18168361189115, Neurons: 201, Grad norm: 2.8622013173795766\n",
      "Epoch 1311, Loss: 212.17768672502888, Neurons: 201, Grad norm: 2.8719241469232286\n",
      "Epoch 1311, Loss: 212.17768672502888, Neurons: 201, Grad norm: 2.8719241469232286\n",
      "Epoch 1312, Loss: 212.17373382691505, Neurons: 201, Grad norm: 2.8834225191603857\n",
      "Epoch 1312, Loss: 212.17373382691505, Neurons: 201, Grad norm: 2.8834225191603857\n",
      "Epoch 1313, Loss: 212.16976772012268, Neurons: 201, Grad norm: 2.8995111920264858\n",
      "Epoch 1313, Loss: 212.16976772012268, Neurons: 201, Grad norm: 2.8995111920264858\n",
      "Epoch 1314, Loss: 212.16578070031244, Neurons: 201, Grad norm: 2.9282832390097826\n",
      "Epoch 1314, Loss: 212.16578070031244, Neurons: 201, Grad norm: 2.9282832390097826\n",
      "Epoch 1315, Loss: 212.16175938708764, Neurons: 201, Grad norm: 2.9291197739118293\n",
      "Epoch 1315, Loss: 212.16175938708764, Neurons: 201, Grad norm: 2.9291197739118293\n",
      "Epoch 1316, Loss: 212.15772652588842, Neurons: 201, Grad norm: 2.9112126276631685\n",
      "Epoch 1316, Loss: 212.15772652588842, Neurons: 201, Grad norm: 2.9112126276631685\n",
      "Epoch 1317, Loss: 212.15368692946083, Neurons: 201, Grad norm: 2.895950261813275\n",
      "Epoch 1317, Loss: 212.15368692946083, Neurons: 201, Grad norm: 2.895950261813275\n",
      "Epoch 1318, Loss: 212.14969931407967, Neurons: 201, Grad norm: 2.8904779829944025\n",
      "Epoch 1318, Loss: 212.14969931407967, Neurons: 201, Grad norm: 2.8904779829944025\n",
      "Epoch 1319, Loss: 212.14574307669312, Neurons: 201, Grad norm: 2.8914729899367093\n",
      "Epoch 1319, Loss: 212.14574307669312, Neurons: 201, Grad norm: 2.8914729899367093\n",
      "Epoch 1320, Loss: 212.14180237581328, Neurons: 201, Grad norm: 2.892698861321744\n",
      "Epoch 1320, Loss: 212.14180237581328, Neurons: 201, Grad norm: 2.892698861321744\n",
      "Epoch 1321, Loss: 212.1378718527245, Neurons: 201, Grad norm: 2.8837201468682765\n",
      "Epoch 1321, Loss: 212.1378718527245, Neurons: 201, Grad norm: 2.8837201468682765\n",
      "Epoch 1322, Loss: 212.13392979318016, Neurons: 201, Grad norm: 2.8551525043750394\n",
      "Epoch 1322, Loss: 212.13392979318016, Neurons: 201, Grad norm: 2.8551525043750394\n",
      "Epoch 1323, Loss: 212.13000819769144, Neurons: 201, Grad norm: 2.8261902157204997\n",
      "Epoch 1323, Loss: 212.13000819769144, Neurons: 201, Grad norm: 2.8261902157204997\n",
      "Epoch 1324, Loss: 212.12607564836318, Neurons: 201, Grad norm: 2.779583309078122\n",
      "Epoch 1324, Loss: 212.12607564836318, Neurons: 201, Grad norm: 2.779583309078122\n",
      "Epoch 1325, Loss: 212.12210566942863, Neurons: 201, Grad norm: 2.767265204704748\n",
      "Epoch 1325, Loss: 212.12210566942863, Neurons: 201, Grad norm: 2.767265204704748\n",
      "Epoch 1326, Loss: 212.11811816483177, Neurons: 201, Grad norm: 2.788658809387966\n",
      "Epoch 1326, Loss: 212.11811816483177, Neurons: 201, Grad norm: 2.788658809387966\n",
      "Epoch 1327, Loss: 212.1141027599009, Neurons: 201, Grad norm: 2.819663391453496\n",
      "Epoch 1327, Loss: 212.1141027599009, Neurons: 201, Grad norm: 2.819663391453496\n",
      "Epoch 1328, Loss: 212.11008939126526, Neurons: 201, Grad norm: 2.8326477705092117\n",
      "Epoch 1328, Loss: 212.11008939126526, Neurons: 201, Grad norm: 2.8326477705092117\n",
      "Epoch 1329, Loss: 212.10612752226456, Neurons: 201, Grad norm: 2.8056363244027103\n",
      "Epoch 1329, Loss: 212.10612752226456, Neurons: 201, Grad norm: 2.8056363244027103\n",
      "Epoch 1330, Loss: 212.10219469162897, Neurons: 201, Grad norm: 2.7796546199517396\n",
      "Epoch 1330, Loss: 212.10219469162897, Neurons: 201, Grad norm: 2.7796546199517396\n",
      "Epoch 1331, Loss: 212.09826317587783, Neurons: 201, Grad norm: 2.764971526862721\n",
      "Epoch 1331, Loss: 212.09826317587783, Neurons: 201, Grad norm: 2.764971526862721\n",
      "Epoch 1332, Loss: 212.09437649163587, Neurons: 201, Grad norm: 2.7432140454582616\n",
      "Epoch 1332, Loss: 212.09437649163587, Neurons: 201, Grad norm: 2.7432140454582616\n",
      "Epoch 1333, Loss: 212.09052126081252, Neurons: 201, Grad norm: 2.737042372731261\n",
      "Epoch 1333, Loss: 212.09052126081252, Neurons: 201, Grad norm: 2.737042372731261\n",
      "Epoch 1334, Loss: 212.08665447125733, Neurons: 201, Grad norm: 2.7501556283011626\n",
      "Epoch 1334, Loss: 212.08665447125733, Neurons: 201, Grad norm: 2.7501556283011626\n",
      "Epoch 1335, Loss: 212.0827552298605, Neurons: 201, Grad norm: 2.776678720022515\n",
      "Epoch 1335, Loss: 212.0827552298605, Neurons: 201, Grad norm: 2.776678720022515\n",
      "Epoch 1336, Loss: 212.07880356793564, Neurons: 201, Grad norm: 2.7976421467327075\n",
      "Epoch 1336, Loss: 212.07880356793564, Neurons: 201, Grad norm: 2.7976421467327075\n",
      "Epoch 1337, Loss: 212.07480328234138, Neurons: 201, Grad norm: 2.7774345165249255\n",
      "Epoch 1337, Loss: 212.07480328234138, Neurons: 201, Grad norm: 2.7774345165249255\n",
      "Epoch 1338, Loss: 212.07084691364489, Neurons: 201, Grad norm: 2.755462733520055\n",
      "Epoch 1338, Loss: 212.07084691364489, Neurons: 201, Grad norm: 2.755462733520055\n",
      "Epoch 1339, Loss: 212.06693360838975, Neurons: 201, Grad norm: 2.740685041856378\n",
      "Epoch 1339, Loss: 212.06693360838975, Neurons: 201, Grad norm: 2.740685041856378\n",
      "Epoch 1340, Loss: 212.0630521945726, Neurons: 201, Grad norm: 2.7504536149003576\n",
      "Epoch 1340, Loss: 212.0630521945726, Neurons: 201, Grad norm: 2.7504536149003576\n",
      "Epoch 1341, Loss: 212.05919191611167, Neurons: 201, Grad norm: 2.7718557749127397\n",
      "Epoch 1341, Loss: 212.05919191611167, Neurons: 201, Grad norm: 2.7718557749127397\n",
      "Epoch 1342, Loss: 212.05534252114674, Neurons: 201, Grad norm: 2.780704282232875\n",
      "Epoch 1342, Loss: 212.05534252114674, Neurons: 201, Grad norm: 2.780704282232875\n",
      "Epoch 1343, Loss: 212.05145105259064, Neurons: 201, Grad norm: 2.7552729800716413\n",
      "Epoch 1343, Loss: 212.05145105259064, Neurons: 201, Grad norm: 2.7552729800716413\n",
      "Epoch 1344, Loss: 212.04750120431908, Neurons: 201, Grad norm: 2.732280302566539\n",
      "Epoch 1344, Loss: 212.04750120431908, Neurons: 201, Grad norm: 2.732280302566539\n",
      "Epoch 1345, Loss: 212.04354886531058, Neurons: 201, Grad norm: 2.740599095972438\n",
      "Epoch 1345, Loss: 212.04354886531058, Neurons: 201, Grad norm: 2.740599095972438\n",
      "Epoch 1346, Loss: 212.03962449108332, Neurons: 201, Grad norm: 2.7736253602204264\n",
      "Epoch 1346, Loss: 212.03962449108332, Neurons: 201, Grad norm: 2.7736253602204264\n",
      "Epoch 1347, Loss: 212.03569309703903, Neurons: 201, Grad norm: 2.793889780968475\n",
      "Epoch 1347, Loss: 212.03569309703903, Neurons: 201, Grad norm: 2.793889780968475\n",
      "Epoch 1348, Loss: 212.0318252309913, Neurons: 201, Grad norm: 2.7951429497770977\n",
      "Epoch 1348, Loss: 212.0318252309913, Neurons: 201, Grad norm: 2.7951429497770977\n",
      "Epoch 1349, Loss: 212.0279517078335, Neurons: 201, Grad norm: 2.7658471114023966\n",
      "Epoch 1349, Loss: 212.0279517078335, Neurons: 201, Grad norm: 2.7658471114023966\n",
      "Epoch 1350, Loss: 212.02414835995873, Neurons: 201, Grad norm: 2.739174283393477\n",
      "Epoch 1350, Loss: 212.02414835995873, Neurons: 201, Grad norm: 2.739174283393477\n",
      "Epoch 1351, Loss: 212.02041095724618, Neurons: 201, Grad norm: 2.749187775689513\n",
      "Epoch 1351, Loss: 212.02041095724618, Neurons: 201, Grad norm: 2.749187775689513\n",
      "Epoch 1352, Loss: 212.0166794124332, Neurons: 201, Grad norm: 2.79053093993965\n",
      "Epoch 1352, Loss: 212.0166794124332, Neurons: 201, Grad norm: 2.79053093993965\n",
      "Epoch 1353, Loss: 212.0129692148379, Neurons: 201, Grad norm: 2.8092565083178025\n",
      "Epoch 1353, Loss: 212.0129692148379, Neurons: 201, Grad norm: 2.8092565083178025\n",
      "Epoch 1354, Loss: 212.00928307711342, Neurons: 201, Grad norm: 2.7838649963745827\n",
      "Epoch 1354, Loss: 212.00928307711342, Neurons: 201, Grad norm: 2.7838649963745827\n",
      "Epoch 1355, Loss: 212.00555618497054, Neurons: 201, Grad norm: 2.74529821210083\n",
      "Epoch 1355, Loss: 212.00555618497054, Neurons: 201, Grad norm: 2.74529821210083\n",
      "Epoch 1356, Loss: 212.00181343043695, Neurons: 201, Grad norm: 2.7290438137451627\n",
      "Epoch 1356, Loss: 212.00181343043695, Neurons: 201, Grad norm: 2.7290438137451627\n",
      "Epoch 1357, Loss: 211.9980529813714, Neurons: 201, Grad norm: 2.7234585237662396\n",
      "Epoch 1357, Loss: 211.9980529813714, Neurons: 201, Grad norm: 2.7234585237662396\n",
      "Epoch 1358, Loss: 211.9942815042042, Neurons: 201, Grad norm: 2.7206845097703685\n",
      "Epoch 1358, Loss: 211.9942815042042, Neurons: 201, Grad norm: 2.7206845097703685\n",
      "Epoch 1359, Loss: 211.99055671509566, Neurons: 201, Grad norm: 2.714750216257735\n",
      "Epoch 1359, Loss: 211.99055671509566, Neurons: 201, Grad norm: 2.714750216257735\n",
      "Epoch 1360, Loss: 211.98684808811836, Neurons: 201, Grad norm: 2.708947400089719\n",
      "Epoch 1360, Loss: 211.98684808811836, Neurons: 201, Grad norm: 2.708947400089719\n",
      "Epoch 1361, Loss: 211.98315211508577, Neurons: 201, Grad norm: 2.7383671966039786\n",
      "Epoch 1361, Loss: 211.98315211508577, Neurons: 201, Grad norm: 2.7383671966039786\n",
      "Epoch 1362, Loss: 211.97947125348495, Neurons: 201, Grad norm: 2.7498348545591793\n",
      "Epoch 1362, Loss: 211.97947125348495, Neurons: 201, Grad norm: 2.7498348545591793\n",
      "Epoch 1363, Loss: 211.9758234787478, Neurons: 201, Grad norm: 2.724060413414546\n",
      "Epoch 1363, Loss: 211.9758234787478, Neurons: 201, Grad norm: 2.724060413414546\n",
      "Epoch 1364, Loss: 211.9721651549566, Neurons: 201, Grad norm: 2.678631232409384\n",
      "Epoch 1364, Loss: 211.9721651549566, Neurons: 201, Grad norm: 2.678631232409384\n",
      "Epoch 1365, Loss: 211.96850502116203, Neurons: 201, Grad norm: 2.672860839457272\n",
      "Epoch 1365, Loss: 211.96850502116203, Neurons: 201, Grad norm: 2.672860839457272\n",
      "Epoch 1366, Loss: 211.96484951203902, Neurons: 201, Grad norm: 2.705693631348061\n",
      "Epoch 1366, Loss: 211.96484951203902, Neurons: 201, Grad norm: 2.705693631348061\n",
      "Epoch 1367, Loss: 211.96118158882066, Neurons: 201, Grad norm: 2.7529595368028885\n",
      "Epoch 1367, Loss: 211.96118158882066, Neurons: 201, Grad norm: 2.7529595368028885\n",
      "Epoch 1368, Loss: 211.9574999743964, Neurons: 201, Grad norm: 2.7568769670457725\n",
      "Epoch 1368, Loss: 211.9574999743964, Neurons: 201, Grad norm: 2.7568769670457725\n",
      "Epoch 1369, Loss: 211.9538066440667, Neurons: 201, Grad norm: 2.702914472829175\n",
      "Epoch 1369, Loss: 211.9538066440667, Neurons: 201, Grad norm: 2.702914472829175\n",
      "Epoch 1370, Loss: 211.95009795309716, Neurons: 201, Grad norm: 2.66842262193044\n",
      "Epoch 1370, Loss: 211.95009795309716, Neurons: 201, Grad norm: 2.66842262193044\n",
      "Epoch 1371, Loss: 211.94638945759667, Neurons: 201, Grad norm: 2.686796640373796\n",
      "Epoch 1371, Loss: 211.94638945759667, Neurons: 201, Grad norm: 2.686796640373796\n",
      "Epoch 1372, Loss: 211.94267847482163, Neurons: 201, Grad norm: 2.75158669046414\n",
      "Epoch 1372, Loss: 211.94267847482163, Neurons: 201, Grad norm: 2.75158669046414\n",
      "Epoch 1373, Loss: 211.93896584694673, Neurons: 201, Grad norm: 2.7871378800179087\n",
      "Epoch 1373, Loss: 211.93896584694673, Neurons: 201, Grad norm: 2.7871378800179087\n",
      "Epoch 1374, Loss: 211.93526818705703, Neurons: 201, Grad norm: 2.7485328927647843\n",
      "Epoch 1374, Loss: 211.93526818705703, Neurons: 201, Grad norm: 2.7485328927647843\n",
      "Epoch 1375, Loss: 211.93153430968314, Neurons: 201, Grad norm: 2.6936884850102447\n",
      "Epoch 1375, Loss: 211.93153430968314, Neurons: 201, Grad norm: 2.6936884850102447\n",
      "Epoch 1376, Loss: 211.9277921158403, Neurons: 201, Grad norm: 2.6739989773349007\n",
      "Epoch 1376, Loss: 211.9277921158403, Neurons: 201, Grad norm: 2.6739989773349007\n",
      "Epoch 1377, Loss: 211.92404182406327, Neurons: 201, Grad norm: 2.677574952842236\n",
      "Epoch 1377, Loss: 211.92404182406327, Neurons: 201, Grad norm: 2.677574952842236\n",
      "Epoch 1378, Loss: 211.92030987634004, Neurons: 201, Grad norm: 2.6759250798204506\n",
      "Epoch 1378, Loss: 211.92030987634004, Neurons: 201, Grad norm: 2.6759250798204506\n",
      "Epoch 1379, Loss: 211.91659119847665, Neurons: 201, Grad norm: 2.6707489888304345\n",
      "Epoch 1379, Loss: 211.91659119847665, Neurons: 201, Grad norm: 2.6707489888304345\n",
      "Epoch 1380, Loss: 211.91285418988784, Neurons: 201, Grad norm: 2.6631256903895375\n",
      "Epoch 1380, Loss: 211.91285418988784, Neurons: 201, Grad norm: 2.6631256903895375\n",
      "Epoch 1381, Loss: 211.90914047924912, Neurons: 201, Grad norm: 2.6689783463475854\n",
      "Epoch 1381, Loss: 211.90914047924912, Neurons: 201, Grad norm: 2.6689783463475854\n",
      "Epoch 1382, Loss: 211.90541292218109, Neurons: 201, Grad norm: 2.6771846093733154\n",
      "Epoch 1382, Loss: 211.90541292218109, Neurons: 201, Grad norm: 2.6771846093733154\n",
      "Epoch 1383, Loss: 211.90170662716073, Neurons: 201, Grad norm: 2.686192572760248\n",
      "Epoch 1383, Loss: 211.90170662716073, Neurons: 201, Grad norm: 2.686192572760248\n",
      "Epoch 1384, Loss: 211.8980383876193, Neurons: 201, Grad norm: 2.695923555035291\n",
      "Epoch 1384, Loss: 211.8980383876193, Neurons: 201, Grad norm: 2.695923555035291\n",
      "Epoch 1385, Loss: 211.89441834128124, Neurons: 201, Grad norm: 2.7049248340816883\n",
      "Epoch 1385, Loss: 211.89441834128124, Neurons: 201, Grad norm: 2.7049248340816883\n",
      "Epoch 1386, Loss: 211.89082292572252, Neurons: 201, Grad norm: 2.7023456281970093\n",
      "Epoch 1386, Loss: 211.89082292572252, Neurons: 201, Grad norm: 2.7023456281970093\n",
      "Epoch 1387, Loss: 211.88720765080936, Neurons: 201, Grad norm: 2.688561584093921\n",
      "Epoch 1387, Loss: 211.88720765080936, Neurons: 201, Grad norm: 2.688561584093921\n",
      "Epoch 1388, Loss: 211.88358567992591, Neurons: 201, Grad norm: 2.672782693591135\n",
      "Epoch 1388, Loss: 211.88358567992591, Neurons: 201, Grad norm: 2.672782693591135\n",
      "Epoch 1389, Loss: 211.87997518462456, Neurons: 201, Grad norm: 2.674843641532222\n",
      "Epoch 1389, Loss: 211.87997518462456, Neurons: 201, Grad norm: 2.674843641532222\n",
      "Epoch 1390, Loss: 211.87638823888946, Neurons: 201, Grad norm: 2.667266221057993\n",
      "Epoch 1390, Loss: 211.87638823888946, Neurons: 201, Grad norm: 2.667266221057993\n",
      "Epoch 1391, Loss: 211.87284239925629, Neurons: 201, Grad norm: 2.652228416278732\n",
      "Epoch 1391, Loss: 211.87284239925629, Neurons: 201, Grad norm: 2.652228416278732\n",
      "Epoch 1392, Loss: 211.8693028315289, Neurons: 201, Grad norm: 2.6276600456622257\n",
      "Epoch 1392, Loss: 211.8693028315289, Neurons: 201, Grad norm: 2.6276600456622257\n",
      "Epoch 1393, Loss: 211.8657593328188, Neurons: 201, Grad norm: 2.6132626971148936\n",
      "Epoch 1393, Loss: 211.8657593328188, Neurons: 201, Grad norm: 2.6132626971148936\n",
      "Epoch 1394, Loss: 211.8622455256242, Neurons: 201, Grad norm: 2.600109610261495\n",
      "Epoch 1394, Loss: 211.8622455256242, Neurons: 201, Grad norm: 2.600109610261495\n",
      "Epoch 1395, Loss: 211.85876142486467, Neurons: 201, Grad norm: 2.5810597610308643\n",
      "Epoch 1395, Loss: 211.85876142486467, Neurons: 201, Grad norm: 2.5810597610308643\n",
      "Epoch 1396, Loss: 211.8552939509788, Neurons: 201, Grad norm: 2.5658918305909415\n",
      "Epoch 1396, Loss: 211.8552939509788, Neurons: 201, Grad norm: 2.5658918305909415\n",
      "Epoch 1397, Loss: 211.8518167586688, Neurons: 201, Grad norm: 2.5567896996061905\n",
      "Epoch 1397, Loss: 211.8518167586688, Neurons: 201, Grad norm: 2.5567896996061905\n",
      "Epoch 1398, Loss: 211.8483336539032, Neurons: 201, Grad norm: 2.547908105377636\n",
      "Epoch 1398, Loss: 211.8483336539032, Neurons: 201, Grad norm: 2.547908105377636\n",
      "Epoch 1399, Loss: 211.84485590577745, Neurons: 201, Grad norm: 2.543715450675139\n",
      "Epoch 1399, Loss: 211.84485590577745, Neurons: 201, Grad norm: 2.543715450675139\n",
      "Epoch 1400, Loss: 211.84134185865028, Neurons: 201, Grad norm: 2.5853037827171614\n",
      "Epoch 1400, Loss: 211.84134185865028, Neurons: 201, Grad norm: 2.5853037827171614\n",
      "Epoch 1401, Loss: 211.83778527731133, Neurons: 201, Grad norm: 2.589311355108461\n",
      "Epoch 1401, Loss: 211.83778527731133, Neurons: 201, Grad norm: 2.589311355108461\n",
      "Epoch 1402, Loss: 211.83422104068146, Neurons: 201, Grad norm: 2.5441647451934095\n",
      "Epoch 1402, Loss: 211.83422104068146, Neurons: 201, Grad norm: 2.5441647451934095\n",
      "Epoch 1403, Loss: 211.83064194347313, Neurons: 201, Grad norm: 2.501391622271922\n",
      "Epoch 1403, Loss: 211.83064194347313, Neurons: 201, Grad norm: 2.501391622271922\n",
      "Epoch 1404, Loss: 211.82702012385556, Neurons: 201, Grad norm: 2.460281408758498\n",
      "Epoch 1404, Loss: 211.82702012385556, Neurons: 201, Grad norm: 2.460281408758498\n",
      "Epoch 1405, Loss: 211.82342800110894, Neurons: 201, Grad norm: 2.469295875767377\n",
      "Epoch 1405, Loss: 211.82342800110894, Neurons: 201, Grad norm: 2.469295875767377\n",
      "Epoch 1406, Loss: 211.8198961646603, Neurons: 201, Grad norm: 2.500567779927757\n",
      "Epoch 1406, Loss: 211.8198961646603, Neurons: 201, Grad norm: 2.500567779927757\n",
      "Epoch 1407, Loss: 211.81636679890977, Neurons: 201, Grad norm: 2.4618187050718423\n",
      "Epoch 1407, Loss: 211.81636679890977, Neurons: 201, Grad norm: 2.4618187050718423\n",
      "Epoch 1408, Loss: 211.8127758009179, Neurons: 201, Grad norm: 2.3921173771498014\n",
      "Epoch 1408, Loss: 211.8127758009179, Neurons: 201, Grad norm: 2.3921173771498014\n",
      "Epoch 1409, Loss: 211.80924763274925, Neurons: 201, Grad norm: 2.3943118741818417\n",
      "Epoch 1409, Loss: 211.80924763274925, Neurons: 201, Grad norm: 2.3943118741818417\n",
      "Epoch 1410, Loss: 211.80578590354432, Neurons: 201, Grad norm: 2.4614931886796483\n",
      "Epoch 1410, Loss: 211.80578590354432, Neurons: 201, Grad norm: 2.4614931886796483\n",
      "Epoch 1411, Loss: 211.8022632475434, Neurons: 201, Grad norm: 2.5089562099277334\n",
      "Epoch 1411, Loss: 211.8022632475434, Neurons: 201, Grad norm: 2.5089562099277334\n",
      "Epoch 1412, Loss: 211.79876002067795, Neurons: 201, Grad norm: 2.5209157117641787\n",
      "Epoch 1412, Loss: 211.79876002067795, Neurons: 201, Grad norm: 2.5209157117641787\n",
      "Epoch 1413, Loss: 211.7952145894049, Neurons: 201, Grad norm: 2.517707925878819\n",
      "Epoch 1413, Loss: 211.7952145894049, Neurons: 201, Grad norm: 2.517707925878819\n",
      "Epoch 1414, Loss: 211.79167172060104, Neurons: 201, Grad norm: 2.5218458015726513\n",
      "Epoch 1414, Loss: 211.79167172060104, Neurons: 201, Grad norm: 2.5218458015726513\n",
      "Epoch 1415, Loss: 211.788176825346, Neurons: 201, Grad norm: 2.5800084912805863\n",
      "Epoch 1415, Loss: 211.788176825346, Neurons: 201, Grad norm: 2.5800084912805863\n",
      "Epoch 1416, Loss: 211.78473340063852, Neurons: 201, Grad norm: 2.611031239277942\n",
      "Epoch 1416, Loss: 211.78473340063852, Neurons: 201, Grad norm: 2.611031239277942\n",
      "Epoch 1417, Loss: 211.78141408270204, Neurons: 201, Grad norm: 2.610723300193846\n",
      "Epoch 1417, Loss: 211.78141408270204, Neurons: 201, Grad norm: 2.610723300193846\n",
      "Epoch 1418, Loss: 211.77809740902222, Neurons: 201, Grad norm: 2.5612189196485438\n",
      "Epoch 1418, Loss: 211.77809740902222, Neurons: 201, Grad norm: 2.5612189196485438\n",
      "Epoch 1419, Loss: 211.7747055997466, Neurons: 201, Grad norm: 2.5418636428592207\n",
      "Epoch 1419, Loss: 211.7747055997466, Neurons: 201, Grad norm: 2.5418636428592207\n",
      "Epoch 1420, Loss: 211.77124073770807, Neurons: 201, Grad norm: 2.563460556087538\n",
      "Epoch 1420, Loss: 211.77124073770807, Neurons: 201, Grad norm: 2.563460556087538\n",
      "Epoch 1421, Loss: 211.76769279577843, Neurons: 201, Grad norm: 2.6080076024004124\n",
      "Epoch 1421, Loss: 211.76769279577843, Neurons: 201, Grad norm: 2.6080076024004124\n",
      "Epoch 1422, Loss: 211.7641459376899, Neurons: 201, Grad norm: 2.6107869237232473\n",
      "Epoch 1422, Loss: 211.7641459376899, Neurons: 201, Grad norm: 2.6107869237232473\n",
      "Epoch 1423, Loss: 211.76067308552027, Neurons: 201, Grad norm: 2.5850039496797796\n",
      "Epoch 1423, Loss: 211.76067308552027, Neurons: 201, Grad norm: 2.5850039496797796\n",
      "Epoch 1424, Loss: 211.75723589065964, Neurons: 201, Grad norm: 2.57940390586287\n",
      "Epoch 1424, Loss: 211.75723589065964, Neurons: 201, Grad norm: 2.57940390586287\n",
      "Epoch 1425, Loss: 211.7537958710686, Neurons: 201, Grad norm: 2.5821284570971232\n",
      "Epoch 1425, Loss: 211.7537958710686, Neurons: 201, Grad norm: 2.5821284570971232\n",
      "Epoch 1426, Loss: 211.75033454909436, Neurons: 201, Grad norm: 2.585052756409946\n",
      "Epoch 1426, Loss: 211.75033454909436, Neurons: 201, Grad norm: 2.585052756409946\n",
      "Epoch 1427, Loss: 211.74685509459474, Neurons: 201, Grad norm: 2.5656178050752674\n",
      "Epoch 1427, Loss: 211.74685509459474, Neurons: 201, Grad norm: 2.5656178050752674\n",
      "Epoch 1428, Loss: 211.74345647527386, Neurons: 201, Grad norm: 2.564697860113422\n",
      "Epoch 1428, Loss: 211.74345647527386, Neurons: 201, Grad norm: 2.564697860113422\n",
      "Epoch 1429, Loss: 211.74014766965146, Neurons: 201, Grad norm: 2.5680191738233513\n",
      "Epoch 1429, Loss: 211.74014766965146, Neurons: 201, Grad norm: 2.5680191738233513\n",
      "Epoch 1430, Loss: 211.73684938662407, Neurons: 201, Grad norm: 2.5526627087144513\n",
      "Epoch 1430, Loss: 211.73684938662407, Neurons: 201, Grad norm: 2.5526627087144513\n",
      "Epoch 1431, Loss: 211.73354936890618, Neurons: 201, Grad norm: 2.520331336768147\n",
      "Epoch 1431, Loss: 211.73354936890618, Neurons: 201, Grad norm: 2.520331336768147\n",
      "Epoch 1432, Loss: 211.73022803895782, Neurons: 201, Grad norm: 2.4838212562598216\n",
      "Epoch 1432, Loss: 211.73022803895782, Neurons: 201, Grad norm: 2.4838212562598216\n",
      "Epoch 1433, Loss: 211.7269124444815, Neurons: 201, Grad norm: 2.470174040275135\n",
      "Epoch 1433, Loss: 211.7269124444815, Neurons: 201, Grad norm: 2.470174040275135\n",
      "Epoch 1434, Loss: 211.72361501633344, Neurons: 201, Grad norm: 2.4870563821737495\n",
      "Epoch 1434, Loss: 211.72361501633344, Neurons: 201, Grad norm: 2.4870563821737495\n",
      "Epoch 1435, Loss: 211.7203059276288, Neurons: 201, Grad norm: 2.5147624780189597\n",
      "Epoch 1435, Loss: 211.7203059276288, Neurons: 201, Grad norm: 2.5147624780189597\n",
      "Epoch 1436, Loss: 211.71696023362637, Neurons: 201, Grad norm: 2.522117344120935\n",
      "Epoch 1436, Loss: 211.71696023362637, Neurons: 201, Grad norm: 2.522117344120935\n",
      "Epoch 1437, Loss: 211.7136266141698, Neurons: 201, Grad norm: 2.498422467573251\n",
      "Epoch 1437, Loss: 211.7136266141698, Neurons: 201, Grad norm: 2.498422467573251\n",
      "Epoch 1438, Loss: 211.71028012581039, Neurons: 201, Grad norm: 2.4744618197019315\n",
      "Epoch 1438, Loss: 211.71028012581039, Neurons: 201, Grad norm: 2.4744618197019315\n",
      "Epoch 1439, Loss: 211.70694069147476, Neurons: 201, Grad norm: 2.474214781069658\n",
      "Epoch 1439, Loss: 211.70694069147476, Neurons: 201, Grad norm: 2.474214781069658\n",
      "Epoch 1440, Loss: 211.70363308489675, Neurons: 201, Grad norm: 2.4930984561065683\n",
      "Epoch 1440, Loss: 211.70363308489675, Neurons: 201, Grad norm: 2.4930984561065683\n",
      "Epoch 1441, Loss: 211.7003565053528, Neurons: 201, Grad norm: 2.48601501122731\n",
      "Epoch 1441, Loss: 211.7003565053528, Neurons: 201, Grad norm: 2.48601501122731\n",
      "Epoch 1442, Loss: 211.69711804997135, Neurons: 201, Grad norm: 2.443101596390056\n",
      "Epoch 1442, Loss: 211.69711804997135, Neurons: 201, Grad norm: 2.443101596390056\n",
      "Epoch 1443, Loss: 211.69394649991622, Neurons: 201, Grad norm: 2.411936559313082\n",
      "Epoch 1443, Loss: 211.69394649991622, Neurons: 201, Grad norm: 2.411936559313082\n",
      "Epoch 1444, Loss: 211.69078185844606, Neurons: 201, Grad norm: 2.397880816000803\n",
      "Epoch 1444, Loss: 211.69078185844606, Neurons: 201, Grad norm: 2.397880816000803\n",
      "Epoch 1445, Loss: 211.6876441399166, Neurons: 201, Grad norm: 2.397293487139246\n",
      "Epoch 1445, Loss: 211.6876441399166, Neurons: 201, Grad norm: 2.397293487139246\n",
      "Epoch 1446, Loss: 211.6845041617632, Neurons: 201, Grad norm: 2.3838265126089127\n",
      "Epoch 1446, Loss: 211.6845041617632, Neurons: 201, Grad norm: 2.3838265126089127\n",
      "Epoch 1447, Loss: 211.68137256614202, Neurons: 201, Grad norm: 2.369809309209078\n",
      "Epoch 1447, Loss: 211.68137256614202, Neurons: 201, Grad norm: 2.369809309209078\n",
      "Epoch 1448, Loss: 211.6782333598795, Neurons: 201, Grad norm: 2.3505311315516293\n",
      "Epoch 1448, Loss: 211.6782333598795, Neurons: 201, Grad norm: 2.3505311315516293\n",
      "Epoch 1449, Loss: 211.6751090433561, Neurons: 201, Grad norm: 2.3423703070248343\n",
      "Epoch 1449, Loss: 211.6751090433561, Neurons: 201, Grad norm: 2.3423703070248343\n",
      "Epoch 1450, Loss: 211.67202201587597, Neurons: 201, Grad norm: 2.3193385016253827\n",
      "Epoch 1450, Loss: 211.67202201587597, Neurons: 201, Grad norm: 2.3193385016253827\n",
      "Epoch 1451, Loss: 211.66892980730958, Neurons: 201, Grad norm: 2.286345188746275\n",
      "Epoch 1451, Loss: 211.66892980730958, Neurons: 201, Grad norm: 2.286345188746275\n",
      "Epoch 1452, Loss: 211.66585284136323, Neurons: 201, Grad norm: 2.275601362791361\n",
      "Epoch 1452, Loss: 211.66585284136323, Neurons: 201, Grad norm: 2.275601362791361\n",
      "Epoch 1453, Loss: 211.66277658498535, Neurons: 201, Grad norm: 2.298770568033042\n",
      "Epoch 1453, Loss: 211.66277658498535, Neurons: 201, Grad norm: 2.298770568033042\n",
      "Epoch 1454, Loss: 211.65970288903722, Neurons: 201, Grad norm: 2.3190864192911995\n",
      "Epoch 1454, Loss: 211.65970288903722, Neurons: 201, Grad norm: 2.3190864192911995\n",
      "Epoch 1455, Loss: 211.65662734820953, Neurons: 201, Grad norm: 2.3068278200426486\n",
      "Epoch 1455, Loss: 211.65662734820953, Neurons: 201, Grad norm: 2.3068278200426486\n",
      "Epoch 1456, Loss: 211.6535510115242, Neurons: 201, Grad norm: 2.279741577980816\n",
      "Epoch 1456, Loss: 211.6535510115242, Neurons: 201, Grad norm: 2.279741577980816\n",
      "Epoch 1457, Loss: 211.65047430869268, Neurons: 201, Grad norm: 2.2915667253292864\n",
      "Epoch 1457, Loss: 211.65047430869268, Neurons: 201, Grad norm: 2.2915667253292864\n",
      "Epoch 1458, Loss: 211.64739522391204, Neurons: 201, Grad norm: 2.3500407383863697\n",
      "Epoch 1458, Loss: 211.64739522391204, Neurons: 201, Grad norm: 2.3500407383863697\n",
      "Epoch 1459, Loss: 211.64432485281296, Neurons: 201, Grad norm: 2.3650239728103313\n",
      "Epoch 1459, Loss: 211.64432485281296, Neurons: 201, Grad norm: 2.3650239728103313\n",
      "Epoch 1460, Loss: 211.6412649440317, Neurons: 201, Grad norm: 2.3030544679275518\n",
      "Epoch 1460, Loss: 211.6412649440317, Neurons: 201, Grad norm: 2.3030544679275518\n",
      "Epoch 1461, Loss: 211.63820445650848, Neurons: 201, Grad norm: 2.2828127038321107\n",
      "Epoch 1461, Loss: 211.63820445650848, Neurons: 201, Grad norm: 2.2828127038321107\n",
      "Epoch 1462, Loss: 211.63517111392, Neurons: 201, Grad norm: 2.324564495170295\n",
      "Epoch 1462, Loss: 211.63517111392, Neurons: 201, Grad norm: 2.324564495170295\n",
      "Epoch 1463, Loss: 211.63214826242333, Neurons: 201, Grad norm: 2.3449998901851\n",
      "Epoch 1463, Loss: 211.63214826242333, Neurons: 201, Grad norm: 2.3449998901851\n",
      "Epoch 1464, Loss: 211.6291166634409, Neurons: 201, Grad norm: 2.3041664833251057\n",
      "Epoch 1464, Loss: 211.6291166634409, Neurons: 201, Grad norm: 2.3041664833251057\n",
      "Epoch 1465, Loss: 211.62608465827748, Neurons: 201, Grad norm: 2.2829852064235534\n",
      "Epoch 1465, Loss: 211.62608465827748, Neurons: 201, Grad norm: 2.2829852064235534\n",
      "Epoch 1466, Loss: 211.62304975802542, Neurons: 201, Grad norm: 2.298013474790955\n",
      "Epoch 1466, Loss: 211.62304975802542, Neurons: 201, Grad norm: 2.298013474790955\n",
      "Epoch 1467, Loss: 211.6200131956691, Neurons: 201, Grad norm: 2.3247777622364993\n",
      "Epoch 1467, Loss: 211.6200131956691, Neurons: 201, Grad norm: 2.3247777622364993\n",
      "Epoch 1468, Loss: 211.61700535658224, Neurons: 201, Grad norm: 2.2832392862964457\n",
      "Epoch 1468, Loss: 211.61700535658224, Neurons: 201, Grad norm: 2.2832392862964457\n",
      "Epoch 1469, Loss: 211.6140031381215, Neurons: 201, Grad norm: 2.229083734046888\n",
      "Epoch 1469, Loss: 211.6140031381215, Neurons: 201, Grad norm: 2.229083734046888\n",
      "Epoch 1470, Loss: 211.6110227607044, Neurons: 201, Grad norm: 2.2232500305051848\n",
      "Epoch 1470, Loss: 211.6110227607044, Neurons: 201, Grad norm: 2.2232500305051848\n",
      "Epoch 1471, Loss: 211.6080424024637, Neurons: 201, Grad norm: 2.248101597437616\n",
      "Epoch 1471, Loss: 211.6080424024637, Neurons: 201, Grad norm: 2.248101597437616\n",
      "Epoch 1472, Loss: 211.60505114565103, Neurons: 201, Grad norm: 2.2506637603451227\n",
      "Epoch 1472, Loss: 211.60505114565103, Neurons: 201, Grad norm: 2.2506637603451227\n",
      "Epoch 1473, Loss: 211.60204450015385, Neurons: 201, Grad norm: 2.2152525093704445\n",
      "Epoch 1473, Loss: 211.60204450015385, Neurons: 201, Grad norm: 2.2152525093704445\n",
      "Epoch 1474, Loss: 211.59902035843965, Neurons: 201, Grad norm: 2.1986722563566\n",
      "Epoch 1474, Loss: 211.59902035843965, Neurons: 201, Grad norm: 2.1986722563566\n",
      "Epoch 1475, Loss: 211.59599772257806, Neurons: 201, Grad norm: 2.22463065476985\n",
      "Epoch 1475, Loss: 211.59599772257806, Neurons: 201, Grad norm: 2.22463065476985\n",
      "Epoch 1476, Loss: 211.5929823543971, Neurons: 201, Grad norm: 2.2729693716228665\n",
      "Epoch 1476, Loss: 211.5929823543971, Neurons: 201, Grad norm: 2.2729693716228665\n",
      "Epoch 1477, Loss: 211.58999428641533, Neurons: 201, Grad norm: 2.2690782388908772\n",
      "Epoch 1477, Loss: 211.58999428641533, Neurons: 201, Grad norm: 2.2690782388908772\n",
      "Epoch 1478, Loss: 211.58702204198923, Neurons: 201, Grad norm: 2.2328536851617056\n",
      "Epoch 1478, Loss: 211.58702204198923, Neurons: 201, Grad norm: 2.2328536851617056\n",
      "Epoch 1479, Loss: 211.5840637635223, Neurons: 201, Grad norm: 2.2304848649064053\n",
      "Epoch 1479, Loss: 211.5840637635223, Neurons: 201, Grad norm: 2.2304848649064053\n",
      "Epoch 1480, Loss: 211.58111627609244, Neurons: 201, Grad norm: 2.268865912393017\n",
      "Epoch 1480, Loss: 211.58111627609244, Neurons: 201, Grad norm: 2.268865912393017\n",
      "Epoch 1481, Loss: 211.57816067896377, Neurons: 201, Grad norm: 2.2808723982441905\n",
      "Epoch 1481, Loss: 211.57816067896377, Neurons: 201, Grad norm: 2.2808723982441905\n",
      "Epoch 1482, Loss: 211.57521122112496, Neurons: 201, Grad norm: 2.2596410972116496\n",
      "Epoch 1482, Loss: 211.57521122112496, Neurons: 201, Grad norm: 2.2596410972116496\n",
      "Epoch 1483, Loss: 211.57227261993148, Neurons: 201, Grad norm: 2.2382805801426557\n",
      "Epoch 1483, Loss: 211.57227261993148, Neurons: 201, Grad norm: 2.2382805801426557\n",
      "Epoch 1484, Loss: 211.56934173699014, Neurons: 201, Grad norm: 2.2606740335084097\n",
      "Epoch 1484, Loss: 211.56934173699014, Neurons: 201, Grad norm: 2.2606740335084097\n",
      "Epoch 1485, Loss: 211.56641086559654, Neurons: 201, Grad norm: 2.3085736645289088\n",
      "Epoch 1485, Loss: 211.56641086559654, Neurons: 201, Grad norm: 2.3085736645289088\n",
      "Epoch 1486, Loss: 211.56350538855125, Neurons: 201, Grad norm: 2.272640538574086\n",
      "Epoch 1486, Loss: 211.56350538855125, Neurons: 201, Grad norm: 2.272640538574086\n",
      "Epoch 1487, Loss: 211.56057043961601, Neurons: 201, Grad norm: 2.2600053039906953\n",
      "Epoch 1487, Loss: 211.56057043961601, Neurons: 201, Grad norm: 2.2600053039906953\n",
      "Epoch 1488, Loss: 211.55765824460497, Neurons: 201, Grad norm: 2.2939943638619167\n",
      "Epoch 1488, Loss: 211.55765824460497, Neurons: 201, Grad norm: 2.2939943638619167\n",
      "Epoch 1489, Loss: 211.55476390439603, Neurons: 201, Grad norm: 2.329719337907136\n",
      "Epoch 1489, Loss: 211.55476390439603, Neurons: 201, Grad norm: 2.329719337907136\n",
      "Epoch 1490, Loss: 211.5518862924903, Neurons: 201, Grad norm: 2.3145314696385615\n",
      "Epoch 1490, Loss: 211.5518862924903, Neurons: 201, Grad norm: 2.3145314696385615\n",
      "Epoch 1491, Loss: 211.54897540956497, Neurons: 201, Grad norm: 2.2711790177549194\n",
      "Epoch 1491, Loss: 211.54897540956497, Neurons: 201, Grad norm: 2.2711790177549194\n",
      "Epoch 1492, Loss: 211.54604667416305, Neurons: 201, Grad norm: 2.274275970867379\n",
      "Epoch 1492, Loss: 211.54604667416305, Neurons: 201, Grad norm: 2.274275970867379\n",
      "Epoch 1493, Loss: 211.5431140409152, Neurons: 201, Grad norm: 2.2953251933913297\n",
      "Epoch 1493, Loss: 211.5431140409152, Neurons: 201, Grad norm: 2.2953251933913297\n",
      "Epoch 1494, Loss: 211.54023264681604, Neurons: 201, Grad norm: 2.2986421445786176\n",
      "Epoch 1494, Loss: 211.54023264681604, Neurons: 201, Grad norm: 2.2986421445786176\n",
      "Epoch 1495, Loss: 211.53738191909116, Neurons: 201, Grad norm: 2.2688825977677323\n",
      "Epoch 1495, Loss: 211.53738191909116, Neurons: 201, Grad norm: 2.2688825977677323\n",
      "Epoch 1496, Loss: 211.5345150832245, Neurons: 201, Grad norm: 2.2649599163233534\n",
      "Epoch 1496, Loss: 211.5345150832245, Neurons: 201, Grad norm: 2.2649599163233534\n",
      "Epoch 1497, Loss: 211.53165437035668, Neurons: 201, Grad norm: 2.3078100273958264\n",
      "Epoch 1497, Loss: 211.53165437035668, Neurons: 201, Grad norm: 2.3078100273958264\n",
      "Epoch 1498, Loss: 211.52880742069885, Neurons: 201, Grad norm: 2.329631568838644\n",
      "Epoch 1498, Loss: 211.52880742069885, Neurons: 201, Grad norm: 2.329631568838644\n",
      "Epoch 1499, Loss: 211.52596164449562, Neurons: 201, Grad norm: 2.2903591615505356\n",
      "Epoch 1499, Loss: 211.52596164449562, Neurons: 201, Grad norm: 2.2903591615505356\n",
      "Epoch 1500, Loss: 211.52311848514924, Neurons: 201, Grad norm: 2.2414609705660555\n",
      "Epoch 1500, Loss: 211.52311848514924, Neurons: 201, Grad norm: 2.2414609705660555\n",
      "Epoch 1501, Loss: 211.5202742436528, Neurons: 201, Grad norm: 2.243555048782927\n",
      "Epoch 1501, Loss: 211.5202742436528, Neurons: 201, Grad norm: 2.243555048782927\n",
      "Epoch 1502, Loss: 211.5174392651001, Neurons: 201, Grad norm: 2.24061945596043\n",
      "Epoch 1502, Loss: 211.5174392651001, Neurons: 201, Grad norm: 2.24061945596043\n",
      "Epoch 1503, Loss: 211.5146201838405, Neurons: 201, Grad norm: 2.2077741146611443\n",
      "Epoch 1503, Loss: 211.5146201838405, Neurons: 201, Grad norm: 2.2077741146611443\n",
      "Epoch 1504, Loss: 211.51180263655309, Neurons: 201, Grad norm: 2.148175038872907\n",
      "Epoch 1504, Loss: 211.51180263655309, Neurons: 201, Grad norm: 2.148175038872907\n",
      "Epoch 1505, Loss: 211.50898731612892, Neurons: 201, Grad norm: 2.1143912680365746\n",
      "Epoch 1505, Loss: 211.50898731612892, Neurons: 201, Grad norm: 2.1143912680365746\n",
      "Epoch 1506, Loss: 211.50615788144324, Neurons: 201, Grad norm: 2.1106595401085615\n",
      "Epoch 1506, Loss: 211.50615788144324, Neurons: 201, Grad norm: 2.1106595401085615\n",
      "Epoch 1507, Loss: 211.50330930264266, Neurons: 201, Grad norm: 2.1288567952995696\n",
      "Epoch 1507, Loss: 211.50330930264266, Neurons: 201, Grad norm: 2.1288567952995696\n",
      "Epoch 1508, Loss: 211.50046943889714, Neurons: 201, Grad norm: 2.1344667557336967\n",
      "Epoch 1508, Loss: 211.50046943889714, Neurons: 201, Grad norm: 2.1344667557336967\n",
      "Epoch 1509, Loss: 211.49764217240886, Neurons: 201, Grad norm: 2.1223167750498466\n",
      "Epoch 1509, Loss: 211.49764217240886, Neurons: 201, Grad norm: 2.1223167750498466\n",
      "Epoch 1510, Loss: 211.49479974333428, Neurons: 201, Grad norm: 2.1395972118655324\n",
      "Epoch 1510, Loss: 211.49479974333428, Neurons: 201, Grad norm: 2.1395972118655324\n",
      "Epoch 1511, Loss: 211.49189556847543, Neurons: 201, Grad norm: 2.193262181555129\n",
      "Epoch 1511, Loss: 211.49189556847543, Neurons: 201, Grad norm: 2.193262181555129\n",
      "Epoch 1512, Loss: 211.4889837030018, Neurons: 201, Grad norm: 2.2336759692193544\n",
      "Epoch 1512, Loss: 211.4889837030018, Neurons: 201, Grad norm: 2.2336759692193544\n",
      "Epoch 1513, Loss: 211.4860634905201, Neurons: 201, Grad norm: 2.2426467793749922\n",
      "Epoch 1513, Loss: 211.4860634905201, Neurons: 201, Grad norm: 2.2426467793749922\n",
      "Epoch 1514, Loss: 211.48311489880365, Neurons: 201, Grad norm: 2.249760321535387\n",
      "Epoch 1514, Loss: 211.48311489880365, Neurons: 201, Grad norm: 2.249760321535387\n",
      "Epoch 1515, Loss: 211.48015136907355, Neurons: 201, Grad norm: 2.258934678684697\n",
      "Epoch 1515, Loss: 211.48015136907355, Neurons: 201, Grad norm: 2.258934678684697\n",
      "Epoch 1516, Loss: 211.47719893839405, Neurons: 201, Grad norm: 2.238051354462403\n",
      "Epoch 1516, Loss: 211.47719893839405, Neurons: 201, Grad norm: 2.238051354462403\n",
      "Epoch 1517, Loss: 211.47426443052964, Neurons: 201, Grad norm: 2.2166432245019583\n",
      "Epoch 1517, Loss: 211.47426443052964, Neurons: 201, Grad norm: 2.2166432245019583\n",
      "Epoch 1518, Loss: 211.47133949617088, Neurons: 201, Grad norm: 2.1998133266710664\n",
      "Epoch 1518, Loss: 211.47133949617088, Neurons: 201, Grad norm: 2.1998133266710664\n",
      "Epoch 1519, Loss: 211.46842482140914, Neurons: 201, Grad norm: 2.1814059440593336\n",
      "Epoch 1519, Loss: 211.46842482140914, Neurons: 201, Grad norm: 2.1814059440593336\n",
      "Epoch 1520, Loss: 211.465515321251, Neurons: 201, Grad norm: 2.1553681083073517\n",
      "Epoch 1520, Loss: 211.465515321251, Neurons: 201, Grad norm: 2.1553681083073517\n",
      "Epoch 1521, Loss: 211.46260859247536, Neurons: 201, Grad norm: 2.142459640509659\n",
      "Epoch 1521, Loss: 211.46260859247536, Neurons: 201, Grad norm: 2.142459640509659\n",
      "Epoch 1522, Loss: 211.45970594162173, Neurons: 201, Grad norm: 2.1506653294734597\n",
      "Epoch 1522, Loss: 211.45970594162173, Neurons: 201, Grad norm: 2.1506653294734597\n",
      "Epoch 1523, Loss: 211.45680918771203, Neurons: 201, Grad norm: 2.179638568022239\n",
      "Epoch 1523, Loss: 211.45680918771203, Neurons: 201, Grad norm: 2.179638568022239\n",
      "Epoch 1524, Loss: 211.45392063742088, Neurons: 201, Grad norm: 2.1958879956813604\n",
      "Epoch 1524, Loss: 211.45392063742088, Neurons: 201, Grad norm: 2.1958879956813604\n",
      "Epoch 1525, Loss: 211.4510813654166, Neurons: 201, Grad norm: 2.170984240884176\n",
      "Epoch 1525, Loss: 211.4510813654166, Neurons: 201, Grad norm: 2.170984240884176\n",
      "Epoch 1526, Loss: 211.4482841469475, Neurons: 201, Grad norm: 2.1529668427901387\n",
      "Epoch 1526, Loss: 211.4482841469475, Neurons: 201, Grad norm: 2.1529668427901387\n",
      "Epoch 1527, Loss: 211.44550647409307, Neurons: 201, Grad norm: 2.1767306824496693\n",
      "Epoch 1527, Loss: 211.44550647409307, Neurons: 201, Grad norm: 2.1767306824496693\n",
      "Epoch 1528, Loss: 211.44272447525617, Neurons: 201, Grad norm: 2.2115375514971234\n",
      "Epoch 1528, Loss: 211.44272447525617, Neurons: 201, Grad norm: 2.2115375514971234\n",
      "Epoch 1529, Loss: 211.43993507266788, Neurons: 201, Grad norm: 2.181430545012862\n",
      "Epoch 1529, Loss: 211.43993507266788, Neurons: 201, Grad norm: 2.181430545012862\n",
      "Epoch 1530, Loss: 211.43712175088814, Neurons: 201, Grad norm: 2.163103995861977\n",
      "Epoch 1530, Loss: 211.43712175088814, Neurons: 201, Grad norm: 2.163103995861977\n",
      "Epoch 1531, Loss: 211.434284781605, Neurons: 201, Grad norm: 2.1744811678547693\n",
      "Epoch 1531, Loss: 211.434284781605, Neurons: 201, Grad norm: 2.1744811678547693\n",
      "Epoch 1532, Loss: 211.43143980734956, Neurons: 201, Grad norm: 2.1730374282095726\n",
      "Epoch 1532, Loss: 211.43143980734956, Neurons: 201, Grad norm: 2.1730374282095726\n",
      "Epoch 1533, Loss: 211.4285972648176, Neurons: 201, Grad norm: 2.146707008288702\n",
      "Epoch 1533, Loss: 211.4285972648176, Neurons: 201, Grad norm: 2.146707008288702\n",
      "Epoch 1534, Loss: 211.42572430181755, Neurons: 201, Grad norm: 2.149265744257013\n",
      "Epoch 1534, Loss: 211.42572430181755, Neurons: 201, Grad norm: 2.149265744257013\n",
      "Epoch 1535, Loss: 211.4228306437517, Neurons: 201, Grad norm: 2.1668318779276565\n",
      "Epoch 1535, Loss: 211.4228306437517, Neurons: 201, Grad norm: 2.1668318779276565\n",
      "Epoch 1536, Loss: 211.4199365543614, Neurons: 201, Grad norm: 2.161785987060886\n",
      "Epoch 1536, Loss: 211.4199365543614, Neurons: 201, Grad norm: 2.161785987060886\n",
      "Epoch 1537, Loss: 211.41703166350936, Neurons: 201, Grad norm: 2.1217069187361375\n",
      "Epoch 1537, Loss: 211.41703166350936, Neurons: 201, Grad norm: 2.1217069187361375\n",
      "Epoch 1538, Loss: 211.4140827402594, Neurons: 201, Grad norm: 2.129278821178406\n",
      "Epoch 1538, Loss: 211.4140827402594, Neurons: 201, Grad norm: 2.129278821178406\n",
      "Epoch 1539, Loss: 211.41109895051224, Neurons: 201, Grad norm: 2.161067536411237\n",
      "Epoch 1539, Loss: 211.41109895051224, Neurons: 201, Grad norm: 2.161067536411237\n",
      "Epoch 1540, Loss: 211.40810607298815, Neurons: 201, Grad norm: 2.151606798773009\n",
      "Epoch 1540, Loss: 211.40810607298815, Neurons: 201, Grad norm: 2.151606798773009\n",
      "Epoch 1541, Loss: 211.40511410384403, Neurons: 201, Grad norm: 2.127390228854388\n",
      "Epoch 1541, Loss: 211.40511410384403, Neurons: 201, Grad norm: 2.127390228854388\n",
      "Epoch 1542, Loss: 211.4020670651524, Neurons: 201, Grad norm: 2.167607577151724\n",
      "Epoch 1542, Loss: 211.4020670651524, Neurons: 201, Grad norm: 2.167607577151724\n",
      "Epoch 1543, Loss: 211.39895356557216, Neurons: 201, Grad norm: 2.207570949574002\n",
      "Epoch 1543, Loss: 211.39895356557216, Neurons: 201, Grad norm: 2.207570949574002\n",
      "Epoch 1544, Loss: 211.3958166521562, Neurons: 201, Grad norm: 2.1900020044298856\n",
      "Epoch 1544, Loss: 211.3958166521562, Neurons: 201, Grad norm: 2.1900020044298856\n",
      "Epoch 1545, Loss: 211.39266045840142, Neurons: 201, Grad norm: 2.1612794199663603\n",
      "Epoch 1545, Loss: 211.39266045840142, Neurons: 201, Grad norm: 2.1612794199663603\n",
      "Epoch 1546, Loss: 211.38952623517125, Neurons: 201, Grad norm: 2.235033602303354\n",
      "Epoch 1546, Loss: 211.38952623517125, Neurons: 201, Grad norm: 2.235033602303354\n",
      "Epoch 1547, Loss: 211.38642739953096, Neurons: 201, Grad norm: 2.2540926321859622\n",
      "Epoch 1547, Loss: 211.38642739953096, Neurons: 201, Grad norm: 2.2540926321859622\n",
      "Epoch 1548, Loss: 211.3833223978299, Neurons: 201, Grad norm: 2.169352793615078\n",
      "Epoch 1548, Loss: 211.3833223978299, Neurons: 201, Grad norm: 2.169352793615078\n",
      "Epoch 1549, Loss: 211.38022654661626, Neurons: 201, Grad norm: 2.1541038437570847\n",
      "Epoch 1549, Loss: 211.38022654661626, Neurons: 201, Grad norm: 2.1541038437570847\n",
      "Epoch 1550, Loss: 211.37714832935296, Neurons: 201, Grad norm: 2.2129901792839513\n",
      "Epoch 1550, Loss: 211.37714832935296, Neurons: 201, Grad norm: 2.2129901792839513\n",
      "Epoch 1551, Loss: 211.37404610757875, Neurons: 201, Grad norm: 2.1891101877241166\n",
      "Epoch 1551, Loss: 211.37404610757875, Neurons: 201, Grad norm: 2.1891101877241166\n",
      "Epoch 1552, Loss: 211.37091953051052, Neurons: 201, Grad norm: 2.1500206273531695\n",
      "Epoch 1552, Loss: 211.37091953051052, Neurons: 201, Grad norm: 2.1500206273531695\n",
      "Epoch 1553, Loss: 211.36786327937676, Neurons: 201, Grad norm: 2.163432364559776\n",
      "Epoch 1553, Loss: 211.36786327937676, Neurons: 201, Grad norm: 2.163432364559776\n",
      "Epoch 1554, Loss: 211.36484586320253, Neurons: 201, Grad norm: 2.2149563174544276\n",
      "Epoch 1554, Loss: 211.36484586320253, Neurons: 201, Grad norm: 2.2149563174544276\n",
      "Epoch 1555, Loss: 211.36187350462546, Neurons: 201, Grad norm: 2.196305283000134\n",
      "Epoch 1555, Loss: 211.36187350462546, Neurons: 201, Grad norm: 2.196305283000134\n",
      "Epoch 1556, Loss: 211.35888492436905, Neurons: 201, Grad norm: 2.184271930497995\n",
      "Epoch 1556, Loss: 211.35888492436905, Neurons: 201, Grad norm: 2.184271930497995\n",
      "Epoch 1557, Loss: 211.35591902319518, Neurons: 201, Grad norm: 2.2031765108290804\n",
      "Epoch 1557, Loss: 211.35591902319518, Neurons: 201, Grad norm: 2.2031765108290804\n",
      "Epoch 1558, Loss: 211.3529096001719, Neurons: 201, Grad norm: 2.1911947918763395\n",
      "Epoch 1558, Loss: 211.3529096001719, Neurons: 201, Grad norm: 2.1911947918763395\n",
      "Epoch 1559, Loss: 211.3498671676583, Neurons: 201, Grad norm: 2.184174746762307\n",
      "Epoch 1559, Loss: 211.3498671676583, Neurons: 201, Grad norm: 2.184174746762307\n",
      "Epoch 1560, Loss: 211.34685145154558, Neurons: 201, Grad norm: 2.162991101154062\n",
      "Epoch 1560, Loss: 211.34685145154558, Neurons: 201, Grad norm: 2.162991101154062\n",
      "Epoch 1561, Loss: 211.34388292374757, Neurons: 201, Grad norm: 2.1340809766571707\n",
      "Epoch 1561, Loss: 211.34388292374757, Neurons: 201, Grad norm: 2.1340809766571707\n",
      "Epoch 1562, Loss: 211.34093104024663, Neurons: 201, Grad norm: 2.137937290419442\n",
      "Epoch 1562, Loss: 211.34093104024663, Neurons: 201, Grad norm: 2.137937290419442\n",
      "Epoch 1563, Loss: 211.3380278145508, Neurons: 201, Grad norm: 2.1442855712031785\n",
      "Epoch 1563, Loss: 211.3380278145508, Neurons: 201, Grad norm: 2.1442855712031785\n",
      "Epoch 1564, Loss: 211.33512938689333, Neurons: 201, Grad norm: 2.1262829213682677\n",
      "Epoch 1564, Loss: 211.33512938689333, Neurons: 201, Grad norm: 2.1262829213682677\n",
      "Epoch 1565, Loss: 211.33224278859046, Neurons: 201, Grad norm: 2.1009002439590296\n",
      "Epoch 1565, Loss: 211.33224278859046, Neurons: 201, Grad norm: 2.1009002439590296\n",
      "Epoch 1566, Loss: 211.32937831498097, Neurons: 201, Grad norm: 2.127575168283833\n",
      "Epoch 1566, Loss: 211.32937831498097, Neurons: 201, Grad norm: 2.127575168283833\n",
      "Epoch 1567, Loss: 211.3265306940806, Neurons: 201, Grad norm: 2.0990291476141536\n",
      "Epoch 1567, Loss: 211.3265306940806, Neurons: 201, Grad norm: 2.0990291476141536\n",
      "Epoch 1568, Loss: 211.32371316757698, Neurons: 201, Grad norm: 2.0653193833066306\n",
      "Epoch 1568, Loss: 211.32371316757698, Neurons: 201, Grad norm: 2.0653193833066306\n",
      "Epoch 1569, Loss: 211.32088503232816, Neurons: 201, Grad norm: 2.0715985454390333\n",
      "Epoch 1569, Loss: 211.32088503232816, Neurons: 201, Grad norm: 2.0715985454390333\n",
      "Epoch 1570, Loss: 211.31805588000526, Neurons: 201, Grad norm: 2.0464700877760094\n",
      "Epoch 1570, Loss: 211.31805588000526, Neurons: 201, Grad norm: 2.0464700877760094\n",
      "Epoch 1571, Loss: 211.31525564121986, Neurons: 201, Grad norm: 2.0409334501504\n",
      "Epoch 1571, Loss: 211.31525564121986, Neurons: 201, Grad norm: 2.0409334501504\n",
      "Epoch 1572, Loss: 211.3124780550781, Neurons: 201, Grad norm: 2.05744930377427\n",
      "Epoch 1572, Loss: 211.3124780550781, Neurons: 201, Grad norm: 2.05744930377427\n",
      "Epoch 1573, Loss: 211.30970881023075, Neurons: 201, Grad norm: 2.022965667679641\n",
      "Epoch 1573, Loss: 211.30970881023075, Neurons: 201, Grad norm: 2.022965667679641\n",
      "Epoch 1574, Loss: 211.30695213193002, Neurons: 201, Grad norm: 2.0551989125372176\n",
      "Epoch 1574, Loss: 211.30695213193002, Neurons: 201, Grad norm: 2.0551989125372176\n",
      "Epoch 1575, Loss: 211.3042009612903, Neurons: 201, Grad norm: 2.0755402282176822\n",
      "Epoch 1575, Loss: 211.3042009612903, Neurons: 201, Grad norm: 2.0755402282176822\n",
      "Epoch 1576, Loss: 211.3014617891404, Neurons: 201, Grad norm: 2.040626368982209\n",
      "Epoch 1576, Loss: 211.3014617891404, Neurons: 201, Grad norm: 2.040626368982209\n",
      "Epoch 1577, Loss: 211.29872190615353, Neurons: 201, Grad norm: 2.0432426736540727\n",
      "Epoch 1577, Loss: 211.29872190615353, Neurons: 201, Grad norm: 2.0432426736540727\n",
      "Epoch 1578, Loss: 211.29596112742317, Neurons: 201, Grad norm: 2.080554114291106\n",
      "Epoch 1578, Loss: 211.29596112742317, Neurons: 201, Grad norm: 2.080554114291106\n",
      "Epoch 1579, Loss: 211.29318184399307, Neurons: 201, Grad norm: 2.0228985155337518\n",
      "Epoch 1579, Loss: 211.29318184399307, Neurons: 201, Grad norm: 2.0228985155337518\n",
      "Epoch 1580, Loss: 211.2903937947776, Neurons: 201, Grad norm: 2.0106141642516726\n",
      "Epoch 1580, Loss: 211.2903937947776, Neurons: 201, Grad norm: 2.0106141642516726\n",
      "Epoch 1581, Loss: 211.28763163171516, Neurons: 201, Grad norm: 2.053878497635549\n",
      "Epoch 1581, Loss: 211.28763163171516, Neurons: 201, Grad norm: 2.053878497635549\n",
      "Epoch 1582, Loss: 211.2848684886233, Neurons: 201, Grad norm: 2.0454848512766963\n",
      "Epoch 1582, Loss: 211.2848684886233, Neurons: 201, Grad norm: 2.0454848512766963\n",
      "Epoch 1583, Loss: 211.2820669260725, Neurons: 201, Grad norm: 2.0182478199942984\n",
      "Epoch 1583, Loss: 211.2820669260725, Neurons: 201, Grad norm: 2.0182478199942984\n",
      "Epoch 1584, Loss: 211.2792546046182, Neurons: 201, Grad norm: 2.0326295131115235\n",
      "Epoch 1584, Loss: 211.2792546046182, Neurons: 201, Grad norm: 2.0326295131115235\n",
      "Epoch 1585, Loss: 211.27645949742308, Neurons: 201, Grad norm: 2.0563840092233283\n",
      "Epoch 1585, Loss: 211.27645949742308, Neurons: 201, Grad norm: 2.0563840092233283\n",
      "Epoch 1586, Loss: 211.2736815302789, Neurons: 201, Grad norm: 2.0230357947365665\n",
      "Epoch 1586, Loss: 211.2736815302789, Neurons: 201, Grad norm: 2.0230357947365665\n",
      "Epoch 1587, Loss: 211.27089366036012, Neurons: 201, Grad norm: 2.0551242990689\n",
      "Epoch 1587, Loss: 211.27089366036012, Neurons: 201, Grad norm: 2.0551242990689\n",
      "Epoch 1588, Loss: 211.26810524620097, Neurons: 201, Grad norm: 2.1084541863992112\n",
      "Epoch 1588, Loss: 211.26810524620097, Neurons: 201, Grad norm: 2.1084541863992112\n",
      "Epoch 1589, Loss: 211.26529811386698, Neurons: 201, Grad norm: 2.061651433415036\n",
      "Epoch 1589, Loss: 211.26529811386698, Neurons: 201, Grad norm: 2.061651433415036\n",
      "Epoch 1590, Loss: 211.26248422622336, Neurons: 201, Grad norm: 2.075966942166055\n",
      "Epoch 1590, Loss: 211.26248422622336, Neurons: 201, Grad norm: 2.075966942166055\n",
      "Epoch 1591, Loss: 211.2596703050459, Neurons: 201, Grad norm: 2.1213172581973674\n",
      "Epoch 1591, Loss: 211.2596703050459, Neurons: 201, Grad norm: 2.1213172581973674\n",
      "Epoch 1592, Loss: 211.25689038973618, Neurons: 201, Grad norm: 2.085518699298824\n",
      "Epoch 1592, Loss: 211.25689038973618, Neurons: 201, Grad norm: 2.085518699298824\n",
      "Epoch 1593, Loss: 211.2541646523754, Neurons: 201, Grad norm: 2.0722771113662524\n",
      "Epoch 1593, Loss: 211.2541646523754, Neurons: 201, Grad norm: 2.0722771113662524\n",
      "Epoch 1594, Loss: 211.25145540705788, Neurons: 201, Grad norm: 2.0950643876678483\n",
      "Epoch 1594, Loss: 211.25145540705788, Neurons: 201, Grad norm: 2.0950643876678483\n",
      "Epoch 1595, Loss: 211.24874105434694, Neurons: 201, Grad norm: 2.105551451839609\n",
      "Epoch 1595, Loss: 211.24874105434694, Neurons: 201, Grad norm: 2.105551451839609\n",
      "Epoch 1596, Loss: 211.24602230382538, Neurons: 201, Grad norm: 2.062298963170773\n",
      "Epoch 1596, Loss: 211.24602230382538, Neurons: 201, Grad norm: 2.062298963170773\n",
      "Epoch 1597, Loss: 211.24331867435748, Neurons: 201, Grad norm: 2.067739733618326\n",
      "Epoch 1597, Loss: 211.24331867435748, Neurons: 201, Grad norm: 2.067739733618326\n",
      "Epoch 1598, Loss: 211.24063566203327, Neurons: 201, Grad norm: 2.0844751465741695\n",
      "Epoch 1598, Loss: 211.24063566203327, Neurons: 201, Grad norm: 2.0844751465741695\n",
      "Epoch 1599, Loss: 211.23795356475574, Neurons: 201, Grad norm: 2.04992115367613\n",
      "Epoch 1599, Loss: 211.23795356475574, Neurons: 201, Grad norm: 2.04992115367613\n",
      "Epoch 1600, Loss: 211.23525973400643, Neurons: 201, Grad norm: 2.004771692518679\n",
      "Epoch 1600, Loss: 211.23525973400643, Neurons: 201, Grad norm: 2.004771692518679\n",
      "Epoch 1601, Loss: 211.23256965406, Neurons: 201, Grad norm: 1.998157845108166\n",
      "Epoch 1601, Loss: 211.23256965406, Neurons: 201, Grad norm: 1.998157845108166\n",
      "Epoch 1602, Loss: 211.22989523140825, Neurons: 201, Grad norm: 1.9915954243889262\n",
      "Epoch 1602, Loss: 211.22989523140825, Neurons: 201, Grad norm: 1.9915954243889262\n",
      "Epoch 1603, Loss: 211.22723954254516, Neurons: 201, Grad norm: 1.978950815741988\n",
      "Epoch 1603, Loss: 211.22723954254516, Neurons: 201, Grad norm: 1.978950815741988\n",
      "Epoch 1604, Loss: 211.22459822815594, Neurons: 201, Grad norm: 1.9838997105909726\n",
      "Epoch 1604, Loss: 211.22459822815594, Neurons: 201, Grad norm: 1.9838997105909726\n",
      "Epoch 1605, Loss: 211.22195042979035, Neurons: 201, Grad norm: 1.9858780837385206\n",
      "Epoch 1605, Loss: 211.22195042979035, Neurons: 201, Grad norm: 1.9858780837385206\n",
      "Epoch 1606, Loss: 211.21926801505822, Neurons: 201, Grad norm: 1.9861210947350392\n",
      "Epoch 1606, Loss: 211.21926801505822, Neurons: 201, Grad norm: 1.9861210947350392\n",
      "Epoch 1607, Loss: 211.21657902547528, Neurons: 201, Grad norm: 1.9140473919066072\n",
      "Epoch 1607, Loss: 211.21657902547528, Neurons: 201, Grad norm: 1.9140473919066072\n",
      "Epoch 1608, Loss: 211.21388032106637, Neurons: 201, Grad norm: 1.9322456740163865\n",
      "Epoch 1608, Loss: 211.21388032106637, Neurons: 201, Grad norm: 1.9322456740163865\n",
      "Epoch 1609, Loss: 211.21118072417553, Neurons: 201, Grad norm: 1.987654563473234\n",
      "Epoch 1609, Loss: 211.21118072417553, Neurons: 201, Grad norm: 1.987654563473234\n",
      "Epoch 1610, Loss: 211.20847981051938, Neurons: 201, Grad norm: 1.957661537848314\n",
      "Epoch 1610, Loss: 211.20847981051938, Neurons: 201, Grad norm: 1.957661537848314\n",
      "Epoch 1611, Loss: 211.20578169579636, Neurons: 201, Grad norm: 1.9537037031130686\n",
      "Epoch 1611, Loss: 211.20578169579636, Neurons: 201, Grad norm: 1.9537037031130686\n",
      "Epoch 1612, Loss: 211.20310134185047, Neurons: 201, Grad norm: 2.021100114410817\n",
      "Epoch 1612, Loss: 211.20310134185047, Neurons: 201, Grad norm: 2.021100114410817\n",
      "Epoch 1613, Loss: 211.20042761376544, Neurons: 201, Grad norm: 2.0252004211275736\n",
      "Epoch 1613, Loss: 211.20042761376544, Neurons: 201, Grad norm: 2.0252004211275736\n",
      "Epoch 1614, Loss: 211.19774950953197, Neurons: 201, Grad norm: 1.9448818143836013\n",
      "Epoch 1614, Loss: 211.19774950953197, Neurons: 201, Grad norm: 1.9448818143836013\n",
      "Epoch 1615, Loss: 211.19510250046096, Neurons: 201, Grad norm: 1.994316034702277\n",
      "Epoch 1615, Loss: 211.19510250046096, Neurons: 201, Grad norm: 1.994316034702277\n",
      "Epoch 1616, Loss: 211.19247233695177, Neurons: 201, Grad norm: 2.052330983874533\n",
      "Epoch 1616, Loss: 211.19247233695177, Neurons: 201, Grad norm: 2.052330983874533\n",
      "Epoch 1617, Loss: 211.18986895981274, Neurons: 201, Grad norm: 1.9963316321461007\n",
      "Epoch 1617, Loss: 211.18986895981274, Neurons: 201, Grad norm: 1.9963316321461007\n",
      "Epoch 1618, Loss: 211.18726236521593, Neurons: 201, Grad norm: 1.9581750656893626\n",
      "Epoch 1618, Loss: 211.18726236521593, Neurons: 201, Grad norm: 1.9581750656893626\n",
      "Epoch 1619, Loss: 211.18465142708618, Neurons: 201, Grad norm: 2.0011450711364356\n",
      "Epoch 1619, Loss: 211.18465142708618, Neurons: 201, Grad norm: 2.0011450711364356\n",
      "Epoch 1620, Loss: 211.18203706156223, Neurons: 201, Grad norm: 2.0155429207467885\n",
      "Epoch 1620, Loss: 211.18203706156223, Neurons: 201, Grad norm: 2.0155429207467885\n",
      "Epoch 1621, Loss: 211.17943212380777, Neurons: 201, Grad norm: 1.9572256777059918\n",
      "Epoch 1621, Loss: 211.17943212380777, Neurons: 201, Grad norm: 1.9572256777059918\n",
      "Epoch 1622, Loss: 211.17683409104524, Neurons: 201, Grad norm: 1.9532593435453323\n",
      "Epoch 1622, Loss: 211.17683409104524, Neurons: 201, Grad norm: 1.9532593435453323\n",
      "Epoch 1623, Loss: 211.1742438018567, Neurons: 201, Grad norm: 1.9837851482634878\n",
      "Epoch 1623, Loss: 211.1742438018567, Neurons: 201, Grad norm: 1.9837851482634878\n",
      "Epoch 1624, Loss: 211.17165692363733, Neurons: 201, Grad norm: 1.9578391983398846\n",
      "Epoch 1624, Loss: 211.17165692363733, Neurons: 201, Grad norm: 1.9578391983398846\n",
      "Epoch 1625, Loss: 211.1690713442263, Neurons: 201, Grad norm: 1.911656545084245\n",
      "Epoch 1625, Loss: 211.1690713442263, Neurons: 201, Grad norm: 1.911656545084245\n",
      "Epoch 1626, Loss: 211.16648215761043, Neurons: 201, Grad norm: 1.9538277875527539\n",
      "Epoch 1626, Loss: 211.16648215761043, Neurons: 201, Grad norm: 1.9538277875527539\n",
      "Epoch 1627, Loss: 211.1638705712698, Neurons: 201, Grad norm: 1.9923128363548541\n",
      "Epoch 1627, Loss: 211.1638705712698, Neurons: 201, Grad norm: 1.9923128363548541\n",
      "Epoch 1628, Loss: 211.16125143187028, Neurons: 201, Grad norm: 1.9399095929630696\n",
      "Epoch 1628, Loss: 211.16125143187028, Neurons: 201, Grad norm: 1.9399095929630696\n",
      "Epoch 1629, Loss: 211.15862077173523, Neurons: 201, Grad norm: 1.9244873812034866\n",
      "Epoch 1629, Loss: 211.15862077173523, Neurons: 201, Grad norm: 1.9244873812034866\n",
      "Epoch 1630, Loss: 211.15598965686675, Neurons: 201, Grad norm: 1.9955573267002495\n",
      "Epoch 1630, Loss: 211.15598965686675, Neurons: 201, Grad norm: 1.9955573267002495\n",
      "Epoch 1631, Loss: 211.15333731092835, Neurons: 201, Grad norm: 1.9788212245906596\n",
      "Epoch 1631, Loss: 211.15333731092835, Neurons: 201, Grad norm: 1.9788212245906596\n",
      "Epoch 1632, Loss: 211.15066183695205, Neurons: 201, Grad norm: 1.9133114468746293\n",
      "Epoch 1632, Loss: 211.15066183695205, Neurons: 201, Grad norm: 1.9133114468746293\n",
      "Epoch 1633, Loss: 211.1479819025274, Neurons: 201, Grad norm: 1.932801243529404\n",
      "Epoch 1633, Loss: 211.1479819025274, Neurons: 201, Grad norm: 1.932801243529404\n",
      "Epoch 1634, Loss: 211.14531218121044, Neurons: 201, Grad norm: 1.9786106798882812\n",
      "Epoch 1634, Loss: 211.14531218121044, Neurons: 201, Grad norm: 1.9786106798882812\n",
      "Epoch 1635, Loss: 211.14259763190753, Neurons: 201, Grad norm: 1.9358262718256927\n",
      "Epoch 1635, Loss: 211.14259763190753, Neurons: 201, Grad norm: 1.9358262718256927\n",
      "Epoch 1636, Loss: 211.1398269004091, Neurons: 201, Grad norm: 1.934021093911781\n",
      "Epoch 1636, Loss: 211.1398269004091, Neurons: 201, Grad norm: 1.934021093911781\n",
      "Epoch 1637, Loss: 211.13704273143514, Neurons: 201, Grad norm: 1.982283265793028\n",
      "Epoch 1637, Loss: 211.13704273143514, Neurons: 201, Grad norm: 1.982283265793028\n",
      "Epoch 1638, Loss: 211.13429401915496, Neurons: 201, Grad norm: 1.9860265219371385\n",
      "Epoch 1638, Loss: 211.13429401915496, Neurons: 201, Grad norm: 1.9860265219371385\n",
      "Epoch 1639, Loss: 211.13156656940652, Neurons: 201, Grad norm: 1.9431523241001356\n",
      "Epoch 1639, Loss: 211.13156656940652, Neurons: 201, Grad norm: 1.9431523241001356\n",
      "Epoch 1640, Loss: 211.1288199596035, Neurons: 201, Grad norm: 1.9874452188712688\n",
      "Epoch 1640, Loss: 211.1288199596035, Neurons: 201, Grad norm: 1.9874452188712688\n",
      "Epoch 1641, Loss: 211.12603296701957, Neurons: 201, Grad norm: 2.01392103851979\n",
      "Epoch 1641, Loss: 211.12603296701957, Neurons: 201, Grad norm: 2.01392103851979\n",
      "Epoch 1642, Loss: 211.123291641969, Neurons: 201, Grad norm: 1.9916733129617163\n",
      "Epoch 1642, Loss: 211.123291641969, Neurons: 201, Grad norm: 1.9916733129617163\n",
      "Epoch 1643, Loss: 211.12059899913942, Neurons: 201, Grad norm: 1.9917430923427022\n",
      "Epoch 1643, Loss: 211.12059899913942, Neurons: 201, Grad norm: 1.9917430923427022\n",
      "Epoch 1644, Loss: 211.11796663397806, Neurons: 201, Grad norm: 2.035683773938925\n",
      "Epoch 1644, Loss: 211.11796663397806, Neurons: 201, Grad norm: 2.035683773938925\n",
      "Epoch 1645, Loss: 211.11529317088966, Neurons: 201, Grad norm: 2.0087791511871487\n",
      "Epoch 1645, Loss: 211.11529317088966, Neurons: 201, Grad norm: 2.0087791511871487\n",
      "Epoch 1646, Loss: 211.1126189471569, Neurons: 201, Grad norm: 2.0007866844995488\n",
      "Epoch 1646, Loss: 211.1126189471569, Neurons: 201, Grad norm: 2.0007866844995488\n",
      "Epoch 1647, Loss: 211.11007245523132, Neurons: 201, Grad norm: 2.0076589543585914\n",
      "Epoch 1647, Loss: 211.11007245523132, Neurons: 201, Grad norm: 2.0076589543585914\n",
      "Epoch 1648, Loss: 211.1074931166006, Neurons: 201, Grad norm: 1.994925198821978\n",
      "Epoch 1648, Loss: 211.1074931166006, Neurons: 201, Grad norm: 1.994925198821978\n",
      "Epoch 1649, Loss: 211.10490976633633, Neurons: 201, Grad norm: 1.9612265955247306\n",
      "Epoch 1649, Loss: 211.10490976633633, Neurons: 201, Grad norm: 1.9612265955247306\n",
      "Epoch 1650, Loss: 211.1023283771878, Neurons: 201, Grad norm: 1.9920728048727372\n",
      "Epoch 1650, Loss: 211.1023283771878, Neurons: 201, Grad norm: 1.9920728048727372\n",
      "Epoch 1651, Loss: 211.09973130584706, Neurons: 201, Grad norm: 2.002636836076906\n",
      "Epoch 1651, Loss: 211.09973130584706, Neurons: 201, Grad norm: 2.002636836076906\n",
      "Epoch 1652, Loss: 211.09712087758993, Neurons: 201, Grad norm: 1.9787407031190036\n",
      "Epoch 1652, Loss: 211.09712087758993, Neurons: 201, Grad norm: 1.9787407031190036\n",
      "Epoch 1653, Loss: 211.09450428353128, Neurons: 201, Grad norm: 2.018914846098198\n",
      "Epoch 1653, Loss: 211.09450428353128, Neurons: 201, Grad norm: 2.018914846098198\n",
      "Epoch 1654, Loss: 211.09191386919326, Neurons: 201, Grad norm: 2.097713325290774\n",
      "Epoch 1654, Loss: 211.09191386919326, Neurons: 201, Grad norm: 2.097713325290774\n",
      "Epoch 1655, Loss: 211.08933132753242, Neurons: 201, Grad norm: 2.085392113425862\n",
      "Epoch 1655, Loss: 211.08933132753242, Neurons: 201, Grad norm: 2.085392113425862\n",
      "Epoch 1656, Loss: 211.08672442660097, Neurons: 201, Grad norm: 2.029271156071356\n",
      "Epoch 1656, Loss: 211.08672442660097, Neurons: 201, Grad norm: 2.029271156071356\n",
      "Epoch 1657, Loss: 211.08409819415326, Neurons: 201, Grad norm: 2.0323308199731436\n",
      "Epoch 1657, Loss: 211.08409819415326, Neurons: 201, Grad norm: 2.0323308199731436\n",
      "Epoch 1658, Loss: 211.0814617063514, Neurons: 201, Grad norm: 2.0046046710868692\n",
      "Epoch 1658, Loss: 211.0814617063514, Neurons: 201, Grad norm: 2.0046046710868692\n",
      "Epoch 1659, Loss: 211.0788472386338, Neurons: 201, Grad norm: 1.9415829573940258\n",
      "Epoch 1659, Loss: 211.0788472386338, Neurons: 201, Grad norm: 1.9415829573940258\n",
      "Epoch 1660, Loss: 211.07621170156335, Neurons: 201, Grad norm: 1.965825524268533\n",
      "Epoch 1660, Loss: 211.07621170156335, Neurons: 201, Grad norm: 1.965825524268533\n",
      "Epoch 1661, Loss: 211.07355302961037, Neurons: 201, Grad norm: 2.025255429296998\n",
      "Epoch 1661, Loss: 211.07355302961037, Neurons: 201, Grad norm: 2.025255429296998\n",
      "Epoch 1662, Loss: 211.070862917083, Neurons: 201, Grad norm: 1.9857834224050135\n",
      "Epoch 1662, Loss: 211.070862917083, Neurons: 201, Grad norm: 1.9857834224050135\n",
      "Epoch 1663, Loss: 211.0681349448567, Neurons: 201, Grad norm: 1.9812057358751916\n",
      "Epoch 1663, Loss: 211.0681349448567, Neurons: 201, Grad norm: 1.9812057358751916\n",
      "Epoch 1664, Loss: 211.0653887577774, Neurons: 201, Grad norm: 2.057590619616396\n",
      "Epoch 1664, Loss: 211.0653887577774, Neurons: 201, Grad norm: 2.057590619616396\n",
      "Epoch 1665, Loss: 211.06266760344016, Neurons: 201, Grad norm: 2.004812672354914\n",
      "Epoch 1665, Loss: 211.06266760344016, Neurons: 201, Grad norm: 2.004812672354914\n",
      "Epoch 1666, Loss: 211.05993661106638, Neurons: 201, Grad norm: 1.9154744574042124\n",
      "Epoch 1666, Loss: 211.05993661106638, Neurons: 201, Grad norm: 1.9154744574042124\n",
      "Epoch 1667, Loss: 211.0571690294156, Neurons: 201, Grad norm: 1.9800566057276126\n",
      "Epoch 1667, Loss: 211.0571690294156, Neurons: 201, Grad norm: 1.9800566057276126\n",
      "Epoch 1668, Loss: 211.05438806266181, Neurons: 201, Grad norm: 1.9986580003503702\n",
      "Epoch 1668, Loss: 211.05438806266181, Neurons: 201, Grad norm: 1.9986580003503702\n",
      "Epoch 1669, Loss: 211.05155535233322, Neurons: 201, Grad norm: 1.9414001334792463\n",
      "Epoch 1669, Loss: 211.05155535233322, Neurons: 201, Grad norm: 1.9414001334792463\n",
      "Epoch 1670, Loss: 211.0485839961688, Neurons: 201, Grad norm: 2.010185081298324\n",
      "Epoch 1670, Loss: 211.0485839961688, Neurons: 201, Grad norm: 2.010185081298324\n",
      "Epoch 1671, Loss: 211.045473027658, Neurons: 201, Grad norm: 2.122281514822581\n",
      "Epoch 1671, Loss: 211.045473027658, Neurons: 201, Grad norm: 2.122281514822581\n",
      "Epoch 1672, Loss: 211.04227758151467, Neurons: 201, Grad norm: 2.103627208333939\n",
      "Epoch 1672, Loss: 211.04227758151467, Neurons: 201, Grad norm: 2.103627208333939\n",
      "Epoch 1673, Loss: 211.03904555085626, Neurons: 201, Grad norm: 2.1249570662232684\n",
      "Epoch 1673, Loss: 211.03904555085626, Neurons: 201, Grad norm: 2.1249570662232684\n",
      "Epoch 1674, Loss: 211.03572047287912, Neurons: 201, Grad norm: 2.1719353930475798\n",
      "Epoch 1674, Loss: 211.03572047287912, Neurons: 201, Grad norm: 2.1719353930475798\n",
      "Epoch 1675, Loss: 211.03234599262802, Neurons: 201, Grad norm: 2.1375061214141935\n",
      "Epoch 1675, Loss: 211.03234599262802, Neurons: 201, Grad norm: 2.1375061214141935\n",
      "Epoch 1676, Loss: 211.0287209224683, Neurons: 201, Grad norm: 2.1297892238820824\n",
      "Epoch 1676, Loss: 211.0287209224683, Neurons: 201, Grad norm: 2.1297892238820824\n",
      "Epoch 1677, Loss: 211.02499552292008, Neurons: 201, Grad norm: 2.1103480396048546\n",
      "Epoch 1677, Loss: 211.02499552292008, Neurons: 201, Grad norm: 2.1103480396048546\n",
      "Epoch 1678, Loss: 211.0214742920081, Neurons: 201, Grad norm: 2.122504225184258\n",
      "Epoch 1678, Loss: 211.0214742920081, Neurons: 201, Grad norm: 2.122504225184258\n",
      "Epoch 1679, Loss: 211.0181411034549, Neurons: 201, Grad norm: 2.09737204327022\n",
      "Epoch 1679, Loss: 211.0181411034549, Neurons: 201, Grad norm: 2.09737204327022\n",
      "Epoch 1680, Loss: 211.01520497039934, Neurons: 201, Grad norm: 2.052626211174533\n",
      "Epoch 1680, Loss: 211.01520497039934, Neurons: 201, Grad norm: 2.052626211174533\n",
      "Epoch 1681, Loss: 211.012375724361, Neurons: 201, Grad norm: 1.9717178721022892\n",
      "Epoch 1681, Loss: 211.012375724361, Neurons: 201, Grad norm: 1.9717178721022892\n",
      "Epoch 1682, Loss: 211.00961438106614, Neurons: 201, Grad norm: 1.9689261672207043\n",
      "Epoch 1682, Loss: 211.00961438106614, Neurons: 201, Grad norm: 1.9689261672207043\n",
      "Epoch 1683, Loss: 211.00695022570167, Neurons: 201, Grad norm: 1.9871062519464393\n",
      "Epoch 1683, Loss: 211.00695022570167, Neurons: 201, Grad norm: 1.9871062519464393\n",
      "Epoch 1684, Loss: 211.00430846160756, Neurons: 201, Grad norm: 1.9647901349209618\n",
      "Epoch 1684, Loss: 211.00430846160756, Neurons: 201, Grad norm: 1.9647901349209618\n",
      "Epoch 1685, Loss: 211.00158621417228, Neurons: 201, Grad norm: 1.9146467123470146\n",
      "Epoch 1685, Loss: 211.00158621417228, Neurons: 201, Grad norm: 1.9146467123470146\n",
      "Epoch 1686, Loss: 210.9988751560693, Neurons: 201, Grad norm: 1.9921201547812837\n",
      "Epoch 1686, Loss: 210.9988751560693, Neurons: 201, Grad norm: 1.9921201547812837\n",
      "Epoch 1687, Loss: 210.99615315510988, Neurons: 201, Grad norm: 1.9534368669215996\n",
      "Epoch 1687, Loss: 210.99615315510988, Neurons: 201, Grad norm: 1.9534368669215996\n",
      "Epoch 1688, Loss: 210.99339902008936, Neurons: 201, Grad norm: 2.0301077762518305\n",
      "Epoch 1688, Loss: 210.99339902008936, Neurons: 201, Grad norm: 2.0301077762518305\n",
      "Epoch 1689, Loss: 210.990736502747, Neurons: 201, Grad norm: 2.1343400230012537\n",
      "Epoch 1689, Loss: 210.990736502747, Neurons: 201, Grad norm: 2.1343400230012537\n",
      "Epoch 1690, Loss: 210.98812879999784, Neurons: 201, Grad norm: 2.0368553081835876\n",
      "Epoch 1690, Loss: 210.98812879999784, Neurons: 201, Grad norm: 2.0368553081835876\n",
      "Epoch 1691, Loss: 210.98546431744919, Neurons: 201, Grad norm: 1.9946747908692535\n",
      "Epoch 1691, Loss: 210.98546431744919, Neurons: 201, Grad norm: 1.9946747908692535\n",
      "Epoch 1692, Loss: 210.98275525603054, Neurons: 201, Grad norm: 2.130013201910151\n",
      "Epoch 1692, Loss: 210.98275525603054, Neurons: 201, Grad norm: 2.130013201910151\n",
      "Epoch 1693, Loss: 210.98002346629417, Neurons: 201, Grad norm: 2.1045665400494804\n",
      "Epoch 1693, Loss: 210.98002346629417, Neurons: 201, Grad norm: 2.1045665400494804\n",
      "Epoch 1694, Loss: 210.97733780429039, Neurons: 201, Grad norm: 1.9857532880829447\n",
      "Epoch 1694, Loss: 210.97733780429039, Neurons: 201, Grad norm: 1.9857532880829447\n",
      "Epoch 1695, Loss: 210.9746657736687, Neurons: 201, Grad norm: 1.9480540119318448\n",
      "Epoch 1695, Loss: 210.9746657736687, Neurons: 201, Grad norm: 1.9480540119318448\n",
      "Epoch 1696, Loss: 210.97197691207703, Neurons: 201, Grad norm: 2.027502201045426\n",
      "Epoch 1696, Loss: 210.97197691207703, Neurons: 201, Grad norm: 2.027502201045426\n",
      "Epoch 1697, Loss: 210.96929734876443, Neurons: 201, Grad norm: 1.9122723552455936\n",
      "Epoch 1697, Loss: 210.96929734876443, Neurons: 201, Grad norm: 1.9122723552455936\n",
      "Epoch 1698, Loss: 210.96658889773076, Neurons: 201, Grad norm: 1.9291158155565717\n",
      "Epoch 1698, Loss: 210.96658889773076, Neurons: 201, Grad norm: 1.9291158155565717\n",
      "Epoch 1699, Loss: 210.96387508383975, Neurons: 201, Grad norm: 2.124325761679915\n",
      "Epoch 1699, Loss: 210.96387508383975, Neurons: 201, Grad norm: 2.124325761679915\n",
      "Epoch 1700, Loss: 210.96117632127428, Neurons: 201, Grad norm: 2.0527109050007724\n",
      "Epoch 1700, Loss: 210.96117632127428, Neurons: 201, Grad norm: 2.0527109050007724\n",
      "Epoch 1701, Loss: 210.95847758558693, Neurons: 201, Grad norm: 1.9750016920822542\n",
      "Epoch 1701, Loss: 210.95847758558693, Neurons: 201, Grad norm: 1.9750016920822542\n",
      "Epoch 1702, Loss: 210.95583174293077, Neurons: 201, Grad norm: 2.1390795352208873\n",
      "Epoch 1702, Loss: 210.95583174293077, Neurons: 201, Grad norm: 2.1390795352208873\n",
      "Epoch 1703, Loss: 210.95311578456284, Neurons: 201, Grad norm: 2.112427270090928\n",
      "Epoch 1703, Loss: 210.95311578456284, Neurons: 201, Grad norm: 2.112427270090928\n",
      "Epoch 1704, Loss: 210.95041097247753, Neurons: 201, Grad norm: 1.9367090844441677\n",
      "Epoch 1704, Loss: 210.95041097247753, Neurons: 201, Grad norm: 1.9367090844441677\n",
      "Epoch 1705, Loss: 210.94774100088662, Neurons: 201, Grad norm: 2.00807982935958\n",
      "Epoch 1705, Loss: 210.94774100088662, Neurons: 201, Grad norm: 2.00807982935958\n",
      "Epoch 1706, Loss: 210.94508021355026, Neurons: 201, Grad norm: 2.0394006930160726\n",
      "Epoch 1706, Loss: 210.94508021355026, Neurons: 201, Grad norm: 2.0394006930160726\n",
      "Epoch 1707, Loss: 210.94243803645676, Neurons: 201, Grad norm: 1.8692278197146324\n",
      "Epoch 1707, Loss: 210.94243803645676, Neurons: 201, Grad norm: 1.8692278197146324\n",
      "Epoch 1708, Loss: 210.93979027640796, Neurons: 201, Grad norm: 1.9085565037198473\n",
      "Epoch 1708, Loss: 210.93979027640796, Neurons: 201, Grad norm: 1.9085565037198473\n",
      "Epoch 1709, Loss: 210.93715337718874, Neurons: 201, Grad norm: 1.9297036334803586\n",
      "Epoch 1709, Loss: 210.93715337718874, Neurons: 201, Grad norm: 1.9297036334803586\n",
      "Epoch 1710, Loss: 210.93453203883973, Neurons: 201, Grad norm: 1.8729305442830784\n",
      "Epoch 1710, Loss: 210.93453203883973, Neurons: 201, Grad norm: 1.8729305442830784\n",
      "Epoch 1711, Loss: 210.93190681317475, Neurons: 201, Grad norm: 1.9331714708231122\n",
      "Epoch 1711, Loss: 210.93190681317475, Neurons: 201, Grad norm: 1.9331714708231122\n",
      "Epoch 1712, Loss: 210.9292714815411, Neurons: 201, Grad norm: 1.9519219334434936\n",
      "Epoch 1712, Loss: 210.9292714815411, Neurons: 201, Grad norm: 1.9519219334434936\n",
      "Epoch 1713, Loss: 210.9266232415926, Neurons: 201, Grad norm: 1.925354629510847\n",
      "Epoch 1713, Loss: 210.9266232415926, Neurons: 201, Grad norm: 1.925354629510847\n",
      "Epoch 1714, Loss: 210.92397024575368, Neurons: 201, Grad norm: 1.9656549323938022\n",
      "Epoch 1714, Loss: 210.92397024575368, Neurons: 201, Grad norm: 1.9656549323938022\n",
      "Epoch 1715, Loss: 210.9213168198003, Neurons: 201, Grad norm: 1.9616991923907678\n",
      "Epoch 1715, Loss: 210.9213168198003, Neurons: 201, Grad norm: 1.9616991923907678\n",
      "Epoch 1716, Loss: 210.9186836143288, Neurons: 201, Grad norm: 1.9148374132805812\n",
      "Epoch 1716, Loss: 210.9186836143288, Neurons: 201, Grad norm: 1.9148374132805812\n",
      "Epoch 1717, Loss: 210.91607782221038, Neurons: 201, Grad norm: 1.9189620952757085\n",
      "Epoch 1717, Loss: 210.91607782221038, Neurons: 201, Grad norm: 1.9189620952757085\n",
      "Epoch 1718, Loss: 210.9134673351104, Neurons: 201, Grad norm: 1.9614885299151714\n",
      "Epoch 1718, Loss: 210.9134673351104, Neurons: 201, Grad norm: 1.9614885299151714\n",
      "Epoch 1719, Loss: 210.91087290103295, Neurons: 201, Grad norm: 1.9033523392438725\n",
      "Epoch 1719, Loss: 210.91087290103295, Neurons: 201, Grad norm: 1.9033523392438725\n",
      "Epoch 1720, Loss: 210.90830124959692, Neurons: 201, Grad norm: 1.9219117645932613\n",
      "Epoch 1720, Loss: 210.90830124959692, Neurons: 201, Grad norm: 1.9219117645932613\n",
      "Epoch 1721, Loss: 210.90572204755875, Neurons: 201, Grad norm: 1.8862919297887228\n",
      "Epoch 1721, Loss: 210.90572204755875, Neurons: 201, Grad norm: 1.8862919297887228\n",
      "Epoch 1722, Loss: 210.9031575577899, Neurons: 201, Grad norm: 1.869459398987192\n",
      "Epoch 1722, Loss: 210.9031575577899, Neurons: 201, Grad norm: 1.869459398987192\n",
      "Epoch 1723, Loss: 210.90060503076717, Neurons: 201, Grad norm: 1.8803448223936539\n",
      "Epoch 1723, Loss: 210.90060503076717, Neurons: 201, Grad norm: 1.8803448223936539\n",
      "Epoch 1724, Loss: 210.89805940034782, Neurons: 201, Grad norm: 1.9042137589313273\n",
      "Epoch 1724, Loss: 210.89805940034782, Neurons: 201, Grad norm: 1.9042137589313273\n",
      "Epoch 1725, Loss: 210.89552836432523, Neurons: 201, Grad norm: 1.882534985855141\n",
      "Epoch 1725, Loss: 210.89552836432523, Neurons: 201, Grad norm: 1.882534985855141\n",
      "Epoch 1726, Loss: 210.892989170345, Neurons: 201, Grad norm: 1.915369471284578\n",
      "Epoch 1726, Loss: 210.892989170345, Neurons: 201, Grad norm: 1.915369471284578\n",
      "Epoch 1727, Loss: 210.89044121160583, Neurons: 201, Grad norm: 1.950116891709786\n",
      "Epoch 1727, Loss: 210.89044121160583, Neurons: 201, Grad norm: 1.950116891709786\n",
      "Epoch 1728, Loss: 210.88789171724923, Neurons: 201, Grad norm: 1.8681932757590813\n",
      "Epoch 1728, Loss: 210.88789171724923, Neurons: 201, Grad norm: 1.8681932757590813\n",
      "Epoch 1729, Loss: 210.88536734600632, Neurons: 201, Grad norm: 1.9068320223162882\n",
      "Epoch 1729, Loss: 210.88536734600632, Neurons: 201, Grad norm: 1.9068320223162882\n",
      "Epoch 1730, Loss: 210.88285071117843, Neurons: 201, Grad norm: 1.9168848494239699\n",
      "Epoch 1730, Loss: 210.88285071117843, Neurons: 201, Grad norm: 1.9168848494239699\n",
      "Epoch 1731, Loss: 210.88034295398458, Neurons: 201, Grad norm: 1.8456306911495572\n",
      "Epoch 1731, Loss: 210.88034295398458, Neurons: 201, Grad norm: 1.8456306911495572\n",
      "Epoch 1732, Loss: 210.8778421709552, Neurons: 201, Grad norm: 1.871977344184351\n",
      "Epoch 1732, Loss: 210.8778421709552, Neurons: 201, Grad norm: 1.871977344184351\n",
      "Epoch 1733, Loss: 210.87534054085972, Neurons: 201, Grad norm: 1.8811416357039537\n",
      "Epoch 1733, Loss: 210.87534054085972, Neurons: 201, Grad norm: 1.8811416357039537\n",
      "Epoch 1734, Loss: 210.87284967645525, Neurons: 201, Grad norm: 1.838594346830278\n",
      "Epoch 1734, Loss: 210.87284967645525, Neurons: 201, Grad norm: 1.838594346830278\n",
      "Epoch 1735, Loss: 210.87036183051381, Neurons: 201, Grad norm: 1.8485134522952156\n",
      "Epoch 1735, Loss: 210.87036183051381, Neurons: 201, Grad norm: 1.8485134522952156\n",
      "Epoch 1736, Loss: 210.86787898327287, Neurons: 201, Grad norm: 1.7940664800995267\n",
      "Epoch 1736, Loss: 210.86787898327287, Neurons: 201, Grad norm: 1.7940664800995267\n",
      "Epoch 1737, Loss: 210.8654088330623, Neurons: 201, Grad norm: 1.848527251376435\n",
      "Epoch 1737, Loss: 210.8654088330623, Neurons: 201, Grad norm: 1.848527251376435\n",
      "Epoch 1738, Loss: 210.86294036272201, Neurons: 201, Grad norm: 1.843529250583296\n",
      "Epoch 1738, Loss: 210.86294036272201, Neurons: 201, Grad norm: 1.843529250583296\n",
      "Epoch 1739, Loss: 210.86047433511789, Neurons: 201, Grad norm: 1.8303922709502425\n",
      "Epoch 1739, Loss: 210.86047433511789, Neurons: 201, Grad norm: 1.8303922709502425\n",
      "Epoch 1740, Loss: 210.85801341354943, Neurons: 201, Grad norm: 1.873080706221517\n",
      "Epoch 1740, Loss: 210.85801341354943, Neurons: 201, Grad norm: 1.873080706221517\n",
      "Epoch 1741, Loss: 210.85557471789738, Neurons: 201, Grad norm: 1.8650221807002172\n",
      "Epoch 1741, Loss: 210.85557471789738, Neurons: 201, Grad norm: 1.8650221807002172\n",
      "Epoch 1742, Loss: 210.853137329833, Neurons: 201, Grad norm: 1.809622696791555\n",
      "Epoch 1742, Loss: 210.853137329833, Neurons: 201, Grad norm: 1.809622696791555\n",
      "Epoch 1743, Loss: 210.85070071987016, Neurons: 201, Grad norm: 1.8229544867525478\n",
      "Epoch 1743, Loss: 210.85070071987016, Neurons: 201, Grad norm: 1.8229544867525478\n",
      "Epoch 1744, Loss: 210.84828889039917, Neurons: 201, Grad norm: 1.853133827011207\n",
      "Epoch 1744, Loss: 210.84828889039917, Neurons: 201, Grad norm: 1.853133827011207\n",
      "Epoch 1745, Loss: 210.84587839758302, Neurons: 201, Grad norm: 1.803655590261408\n",
      "Epoch 1745, Loss: 210.84587839758302, Neurons: 201, Grad norm: 1.803655590261408\n",
      "Epoch 1746, Loss: 210.84346978210408, Neurons: 201, Grad norm: 1.8283830739305365\n",
      "Epoch 1746, Loss: 210.84346978210408, Neurons: 201, Grad norm: 1.8283830739305365\n",
      "Epoch 1747, Loss: 210.8410675628173, Neurons: 201, Grad norm: 1.798002468105467\n",
      "Epoch 1747, Loss: 210.8410675628173, Neurons: 201, Grad norm: 1.798002468105467\n",
      "Epoch 1748, Loss: 210.8386593459021, Neurons: 201, Grad norm: 1.7771480307552547\n",
      "Epoch 1748, Loss: 210.8386593459021, Neurons: 201, Grad norm: 1.7771480307552547\n",
      "Epoch 1749, Loss: 210.83625060643615, Neurons: 201, Grad norm: 1.8286823754737929\n",
      "Epoch 1749, Loss: 210.83625060643615, Neurons: 201, Grad norm: 1.8286823754737929\n",
      "Epoch 1750, Loss: 210.83384758908142, Neurons: 201, Grad norm: 1.7867116907020337\n",
      "Epoch 1750, Loss: 210.83384758908142, Neurons: 201, Grad norm: 1.7867116907020337\n",
      "Epoch 1751, Loss: 210.83143364386407, Neurons: 201, Grad norm: 1.7715540164606673\n",
      "Epoch 1751, Loss: 210.83143364386407, Neurons: 201, Grad norm: 1.7715540164606673\n",
      "Epoch 1752, Loss: 210.82902968799186, Neurons: 201, Grad norm: 1.836291997390371\n",
      "Epoch 1752, Loss: 210.82902968799186, Neurons: 201, Grad norm: 1.836291997390371\n",
      "Epoch 1753, Loss: 210.82661962365816, Neurons: 201, Grad norm: 1.7666274480121065\n",
      "Epoch 1753, Loss: 210.82661962365816, Neurons: 201, Grad norm: 1.7666274480121065\n",
      "Epoch 1754, Loss: 210.824195744132, Neurons: 201, Grad norm: 1.8273945425473008\n",
      "Epoch 1754, Loss: 210.824195744132, Neurons: 201, Grad norm: 1.8273945425473008\n",
      "Epoch 1755, Loss: 210.82177712974544, Neurons: 201, Grad norm: 1.8273481746045925\n",
      "Epoch 1755, Loss: 210.82177712974544, Neurons: 201, Grad norm: 1.8273481746045925\n",
      "Epoch 1756, Loss: 210.81935885205635, Neurons: 201, Grad norm: 1.740531059223219\n",
      "Epoch 1756, Loss: 210.81935885205635, Neurons: 201, Grad norm: 1.740531059223219\n",
      "Epoch 1757, Loss: 210.8169432511746, Neurons: 201, Grad norm: 1.806078789167824\n",
      "Epoch 1757, Loss: 210.8169432511746, Neurons: 201, Grad norm: 1.806078789167824\n",
      "Epoch 1758, Loss: 210.81453345810036, Neurons: 201, Grad norm: 1.7823235676772742\n",
      "Epoch 1758, Loss: 210.81453345810036, Neurons: 201, Grad norm: 1.7823235676772742\n",
      "Epoch 1759, Loss: 210.81211796370636, Neurons: 201, Grad norm: 1.7646392776497988\n",
      "Epoch 1759, Loss: 210.81211796370636, Neurons: 201, Grad norm: 1.7646392776497988\n",
      "Epoch 1760, Loss: 210.80970159920193, Neurons: 201, Grad norm: 1.8343041199135561\n",
      "Epoch 1760, Loss: 210.80970159920193, Neurons: 201, Grad norm: 1.8343041199135561\n",
      "Epoch 1761, Loss: 210.80728253035767, Neurons: 201, Grad norm: 1.7770646730045365\n",
      "Epoch 1761, Loss: 210.80728253035767, Neurons: 201, Grad norm: 1.7770646730045365\n",
      "Epoch 1762, Loss: 210.80486566627656, Neurons: 201, Grad norm: 1.7745676043566383\n",
      "Epoch 1762, Loss: 210.80486566627656, Neurons: 201, Grad norm: 1.7745676043566383\n",
      "Epoch 1763, Loss: 210.80244938920936, Neurons: 201, Grad norm: 1.811973421271539\n",
      "Epoch 1763, Loss: 210.80244938920936, Neurons: 201, Grad norm: 1.811973421271539\n",
      "Epoch 1764, Loss: 210.8000261576352, Neurons: 201, Grad norm: 1.8054636069307575\n",
      "Epoch 1764, Loss: 210.8000261576352, Neurons: 201, Grad norm: 1.8054636069307575\n",
      "Epoch 1765, Loss: 210.7975959446849, Neurons: 201, Grad norm: 1.8101185081815194\n",
      "Epoch 1765, Loss: 210.7975959446849, Neurons: 201, Grad norm: 1.8101185081815194\n",
      "Epoch 1766, Loss: 210.7951463714338, Neurons: 201, Grad norm: 1.822816582818168\n",
      "Epoch 1766, Loss: 210.7951463714338, Neurons: 201, Grad norm: 1.822816582818168\n",
      "Epoch 1767, Loss: 210.7926888477247, Neurons: 201, Grad norm: 1.7863810055010145\n",
      "Epoch 1767, Loss: 210.7926888477247, Neurons: 201, Grad norm: 1.7863810055010145\n",
      "Epoch 1768, Loss: 210.79023949717754, Neurons: 201, Grad norm: 1.8436765315187065\n",
      "Epoch 1768, Loss: 210.79023949717754, Neurons: 201, Grad norm: 1.8436765315187065\n",
      "Epoch 1769, Loss: 210.7877693014146, Neurons: 201, Grad norm: 1.856557715707418\n",
      "Epoch 1769, Loss: 210.7877693014146, Neurons: 201, Grad norm: 1.856557715707418\n",
      "Epoch 1770, Loss: 210.78531038695763, Neurons: 201, Grad norm: 1.826713693396271\n",
      "Epoch 1770, Loss: 210.78531038695763, Neurons: 201, Grad norm: 1.826713693396271\n",
      "Epoch 1771, Loss: 210.7828649130727, Neurons: 201, Grad norm: 1.8434831836130179\n",
      "Epoch 1771, Loss: 210.7828649130727, Neurons: 201, Grad norm: 1.8434831836130179\n",
      "Epoch 1772, Loss: 210.78040421644837, Neurons: 201, Grad norm: 1.8326066235482763\n",
      "Epoch 1772, Loss: 210.78040421644837, Neurons: 201, Grad norm: 1.8326066235482763\n",
      "Epoch 1773, Loss: 210.77794843183173, Neurons: 201, Grad norm: 1.7814719251201072\n",
      "Epoch 1773, Loss: 210.77794843183173, Neurons: 201, Grad norm: 1.7814719251201072\n",
      "Epoch 1774, Loss: 210.77551933426744, Neurons: 201, Grad norm: 1.8245942521671938\n",
      "Epoch 1774, Loss: 210.77551933426744, Neurons: 201, Grad norm: 1.8245942521671938\n",
      "Epoch 1775, Loss: 210.7731089745442, Neurons: 201, Grad norm: 1.8182931635568593\n",
      "Epoch 1775, Loss: 210.7731089745442, Neurons: 201, Grad norm: 1.8182931635568593\n",
      "Epoch 1776, Loss: 210.77065833644207, Neurons: 201, Grad norm: 1.775498068204408\n",
      "Epoch 1776, Loss: 210.77065833644207, Neurons: 201, Grad norm: 1.775498068204408\n",
      "Epoch 1777, Loss: 210.7681695689346, Neurons: 201, Grad norm: 1.7967560583639195\n",
      "Epoch 1777, Loss: 210.7681695689346, Neurons: 201, Grad norm: 1.7967560583639195\n",
      "Epoch 1778, Loss: 210.76563035572144, Neurons: 201, Grad norm: 1.8355669842853106\n",
      "Epoch 1778, Loss: 210.76563035572144, Neurons: 201, Grad norm: 1.8355669842853106\n",
      "Epoch 1779, Loss: 210.76307304665872, Neurons: 201, Grad norm: 1.8448053782345106\n",
      "Epoch 1779, Loss: 210.76307304665872, Neurons: 201, Grad norm: 1.8448053782345106\n",
      "Epoch 1780, Loss: 210.76049366649147, Neurons: 201, Grad norm: 1.8707993995211327\n",
      "Epoch 1780, Loss: 210.76049366649147, Neurons: 201, Grad norm: 1.8707993995211327\n",
      "Epoch 1781, Loss: 210.75786424452195, Neurons: 201, Grad norm: 1.9138827350016914\n",
      "Epoch 1781, Loss: 210.75786424452195, Neurons: 201, Grad norm: 1.9138827350016914\n",
      "Epoch 1782, Loss: 210.75519544673244, Neurons: 201, Grad norm: 1.8426913738962185\n",
      "Epoch 1782, Loss: 210.75519544673244, Neurons: 201, Grad norm: 1.8426913738962185\n",
      "Epoch 1783, Loss: 210.7525030512639, Neurons: 201, Grad norm: 1.9930735620165683\n",
      "Epoch 1783, Loss: 210.7525030512639, Neurons: 201, Grad norm: 1.9930735620165683\n",
      "Epoch 1784, Loss: 210.7498138082991, Neurons: 201, Grad norm: 1.878498514752854\n",
      "Epoch 1784, Loss: 210.7498138082991, Neurons: 201, Grad norm: 1.878498514752854\n",
      "Epoch 1785, Loss: 210.74708350727602, Neurons: 201, Grad norm: 1.903420270403843\n",
      "Epoch 1785, Loss: 210.74708350727602, Neurons: 201, Grad norm: 1.903420270403843\n",
      "Epoch 1786, Loss: 210.7444204327488, Neurons: 201, Grad norm: 1.9512486237450306\n",
      "Epoch 1786, Loss: 210.7444204327488, Neurons: 201, Grad norm: 1.9512486237450306\n",
      "Epoch 1787, Loss: 210.74184416485272, Neurons: 201, Grad norm: 1.8309631676926947\n",
      "Epoch 1787, Loss: 210.74184416485272, Neurons: 201, Grad norm: 1.8309631676926947\n",
      "Epoch 1788, Loss: 210.73927348967626, Neurons: 201, Grad norm: 1.8224525670027916\n",
      "Epoch 1788, Loss: 210.73927348967626, Neurons: 201, Grad norm: 1.8224525670027916\n",
      "Epoch 1789, Loss: 210.73676622164288, Neurons: 201, Grad norm: 1.9323403061949984\n",
      "Epoch 1789, Loss: 210.73676622164288, Neurons: 201, Grad norm: 1.9323403061949984\n",
      "Epoch 1790, Loss: 210.73428374558273, Neurons: 201, Grad norm: 1.8136878165977577\n",
      "Epoch 1790, Loss: 210.73428374558273, Neurons: 201, Grad norm: 1.8136878165977577\n",
      "Epoch 1791, Loss: 210.73178164125864, Neurons: 201, Grad norm: 1.8883281713988525\n",
      "Epoch 1791, Loss: 210.73178164125864, Neurons: 201, Grad norm: 1.8883281713988525\n",
      "Epoch 1792, Loss: 210.72930491866342, Neurons: 201, Grad norm: 1.9148035526921188\n",
      "Epoch 1792, Loss: 210.72930491866342, Neurons: 201, Grad norm: 1.9148035526921188\n",
      "Epoch 1793, Loss: 210.72688916653928, Neurons: 201, Grad norm: 1.7818053808651095\n",
      "Epoch 1793, Loss: 210.72688916653928, Neurons: 201, Grad norm: 1.7818053808651095\n",
      "Epoch 1794, Loss: 210.7244979216978, Neurons: 201, Grad norm: 1.8920682654951964\n",
      "Epoch 1794, Loss: 210.7244979216978, Neurons: 201, Grad norm: 1.8920682654951964\n",
      "Epoch 1795, Loss: 210.72207222652384, Neurons: 201, Grad norm: 1.8800517323999086\n",
      "Epoch 1795, Loss: 210.72207222652384, Neurons: 201, Grad norm: 1.8800517323999086\n",
      "Epoch 1796, Loss: 210.71963510863546, Neurons: 201, Grad norm: 1.7803053742164683\n",
      "Epoch 1796, Loss: 210.71963510863546, Neurons: 201, Grad norm: 1.7803053742164683\n",
      "Epoch 1797, Loss: 210.7171713058107, Neurons: 201, Grad norm: 1.9573355869072862\n",
      "Epoch 1797, Loss: 210.7171713058107, Neurons: 201, Grad norm: 1.9573355869072862\n",
      "Epoch 1798, Loss: 210.71468743463677, Neurons: 201, Grad norm: 1.7680190132609173\n",
      "Epoch 1798, Loss: 210.71468743463677, Neurons: 201, Grad norm: 1.7680190132609173\n",
      "Epoch 1799, Loss: 210.71217950210195, Neurons: 201, Grad norm: 1.776472751584897\n",
      "Epoch 1799, Loss: 210.71217950210195, Neurons: 201, Grad norm: 1.776472751584897\n",
      "Epoch 1800, Loss: 210.70966730429956, Neurons: 201, Grad norm: 1.8728556607604276\n",
      "Epoch 1800, Loss: 210.70966730429956, Neurons: 201, Grad norm: 1.8728556607604276\n",
      "Epoch 1801, Loss: 210.7071393801917, Neurons: 201, Grad norm: 1.7484962878439232\n",
      "Epoch 1801, Loss: 210.7071393801917, Neurons: 201, Grad norm: 1.7484962878439232\n",
      "Epoch 1802, Loss: 210.70460998846923, Neurons: 201, Grad norm: 1.8272229005968468\n",
      "Epoch 1802, Loss: 210.70460998846923, Neurons: 201, Grad norm: 1.8272229005968468\n",
      "Epoch 1803, Loss: 210.70210100178798, Neurons: 201, Grad norm: 1.853690098391885\n",
      "Epoch 1803, Loss: 210.70210100178798, Neurons: 201, Grad norm: 1.853690098391885\n",
      "Epoch 1804, Loss: 210.69957696146687, Neurons: 201, Grad norm: 1.7325466778663965\n",
      "Epoch 1804, Loss: 210.69957696146687, Neurons: 201, Grad norm: 1.7325466778663965\n",
      "Epoch 1805, Loss: 210.69705731873978, Neurons: 201, Grad norm: 1.9745555402934771\n",
      "Epoch 1805, Loss: 210.69705731873978, Neurons: 201, Grad norm: 1.9745555402934771\n",
      "Epoch 1806, Loss: 210.694532965562, Neurons: 201, Grad norm: 1.7329225358820772\n",
      "Epoch 1806, Loss: 210.694532965562, Neurons: 201, Grad norm: 1.7329225358820772\n",
      "Epoch 1807, Loss: 210.69199384988883, Neurons: 201, Grad norm: 1.7237777988556118\n",
      "Epoch 1807, Loss: 210.69199384988883, Neurons: 201, Grad norm: 1.7237777988556118\n",
      "Epoch 1808, Loss: 210.6895048748195, Neurons: 201, Grad norm: 2.084085538812082\n",
      "Epoch 1808, Loss: 210.6895048748195, Neurons: 201, Grad norm: 2.084085538812082\n",
      "Epoch 1809, Loss: 210.6870657530447, Neurons: 201, Grad norm: 1.7199717567220498\n",
      "Epoch 1809, Loss: 210.6870657530447, Neurons: 201, Grad norm: 1.7199717567220498\n",
      "Epoch 1810, Loss: 210.68454309652864, Neurons: 201, Grad norm: 1.7280554829094323\n",
      "Epoch 1810, Loss: 210.68454309652864, Neurons: 201, Grad norm: 1.7280554829094323\n",
      "Epoch 1811, Loss: 210.6819991630123, Neurons: 201, Grad norm: 2.124221160656058\n",
      "Epoch 1811, Loss: 210.6819991630123, Neurons: 201, Grad norm: 2.124221160656058\n",
      "Epoch 1812, Loss: 210.67951617280076, Neurons: 201, Grad norm: 1.7678299339682186\n",
      "Epoch 1812, Loss: 210.67951617280076, Neurons: 201, Grad norm: 1.7678299339682186\n",
      "Epoch 1813, Loss: 210.6769915940367, Neurons: 201, Grad norm: 1.8838456853668484\n",
      "Epoch 1813, Loss: 210.6769915940367, Neurons: 201, Grad norm: 1.8838456853668484\n",
      "Epoch 1814, Loss: 210.674509493154, Neurons: 201, Grad norm: 2.0549073394636492\n",
      "Epoch 1814, Loss: 210.674509493154, Neurons: 201, Grad norm: 2.0549073394636492\n",
      "Epoch 1815, Loss: 210.67204387605088, Neurons: 201, Grad norm: 1.803617277454031\n",
      "Epoch 1815, Loss: 210.67204387605088, Neurons: 201, Grad norm: 1.803617277454031\n",
      "Epoch 1816, Loss: 210.66957768516937, Neurons: 201, Grad norm: 1.8482349078291747\n",
      "Epoch 1816, Loss: 210.66957768516937, Neurons: 201, Grad norm: 1.8482349078291747\n",
      "Epoch 1817, Loss: 210.66708969883592, Neurons: 201, Grad norm: 1.932512689240506\n",
      "Epoch 1817, Loss: 210.66708969883592, Neurons: 201, Grad norm: 1.932512689240506\n",
      "Epoch 1818, Loss: 210.66464768347092, Neurons: 201, Grad norm: 1.737088968532267\n",
      "Epoch 1818, Loss: 210.66464768347092, Neurons: 201, Grad norm: 1.737088968532267\n",
      "Epoch 1819, Loss: 210.6621860835843, Neurons: 201, Grad norm: 1.7740680236435544\n",
      "Epoch 1819, Loss: 210.6621860835843, Neurons: 201, Grad norm: 1.7740680236435544\n",
      "Epoch 1820, Loss: 210.65969808064492, Neurons: 201, Grad norm: 1.8266219686156697\n",
      "Epoch 1820, Loss: 210.65969808064492, Neurons: 201, Grad norm: 1.8266219686156697\n",
      "Epoch 1821, Loss: 210.65726673762313, Neurons: 201, Grad norm: 1.7556060411665002\n",
      "Epoch 1821, Loss: 210.65726673762313, Neurons: 201, Grad norm: 1.7556060411665002\n",
      "Epoch 1822, Loss: 210.65490806229295, Neurons: 201, Grad norm: 1.7909684001380024\n",
      "Epoch 1822, Loss: 210.65490806229295, Neurons: 201, Grad norm: 1.7909684001380024\n",
      "Epoch 1823, Loss: 210.65255430870246, Neurons: 201, Grad norm: 1.7766599602189657\n",
      "Epoch 1823, Loss: 210.65255430870246, Neurons: 201, Grad norm: 1.7766599602189657\n",
      "Epoch 1824, Loss: 210.65021196608902, Neurons: 201, Grad norm: 1.7222329772565195\n",
      "Epoch 1824, Loss: 210.65021196608902, Neurons: 201, Grad norm: 1.7222329772565195\n",
      "Epoch 1825, Loss: 210.6478640618686, Neurons: 201, Grad norm: 1.8160381361705384\n",
      "Epoch 1825, Loss: 210.6478640618686, Neurons: 201, Grad norm: 1.8160381361705384\n",
      "Epoch 1826, Loss: 210.645520432423, Neurons: 201, Grad norm: 1.762147007755695\n",
      "Epoch 1826, Loss: 210.645520432423, Neurons: 201, Grad norm: 1.762147007755695\n",
      "Epoch 1827, Loss: 210.64316968463777, Neurons: 201, Grad norm: 1.7217684326520568\n",
      "Epoch 1827, Loss: 210.64316968463777, Neurons: 201, Grad norm: 1.7217684326520568\n",
      "Epoch 1828, Loss: 210.64081727063638, Neurons: 201, Grad norm: 1.7849214115380714\n",
      "Epoch 1828, Loss: 210.64081727063638, Neurons: 201, Grad norm: 1.7849214115380714\n",
      "Epoch 1829, Loss: 210.638455479767, Neurons: 201, Grad norm: 1.6900843437133999\n",
      "Epoch 1829, Loss: 210.638455479767, Neurons: 201, Grad norm: 1.6900843437133999\n",
      "Epoch 1830, Loss: 210.63607804795353, Neurons: 201, Grad norm: 1.6943946457584544\n",
      "Epoch 1830, Loss: 210.63607804795353, Neurons: 201, Grad norm: 1.6943946457584544\n",
      "Epoch 1831, Loss: 210.63370114583756, Neurons: 201, Grad norm: 1.7428099253978644\n",
      "Epoch 1831, Loss: 210.63370114583756, Neurons: 201, Grad norm: 1.7428099253978644\n",
      "Epoch 1832, Loss: 210.63131650030263, Neurons: 201, Grad norm: 1.753054551706905\n",
      "Epoch 1832, Loss: 210.63131650030263, Neurons: 201, Grad norm: 1.753054551706905\n",
      "Epoch 1833, Loss: 210.62892605987983, Neurons: 201, Grad norm: 1.7518434542320929\n",
      "Epoch 1833, Loss: 210.62892605987983, Neurons: 201, Grad norm: 1.7518434542320929\n",
      "Epoch 1834, Loss: 210.62655785171822, Neurons: 201, Grad norm: 1.849953500962949\n",
      "Epoch 1834, Loss: 210.62655785171822, Neurons: 201, Grad norm: 1.849953500962949\n",
      "Epoch 1835, Loss: 210.62421913792238, Neurons: 201, Grad norm: 1.7672332194521734\n",
      "Epoch 1835, Loss: 210.62421913792238, Neurons: 201, Grad norm: 1.7672332194521734\n",
      "Epoch 1836, Loss: 210.62188074918853, Neurons: 201, Grad norm: 1.764461990081495\n",
      "Epoch 1836, Loss: 210.62188074918853, Neurons: 201, Grad norm: 1.764461990081495\n",
      "Epoch 1837, Loss: 210.6195368998932, Neurons: 201, Grad norm: 1.742651164349002\n",
      "Epoch 1837, Loss: 210.6195368998932, Neurons: 201, Grad norm: 1.742651164349002\n",
      "Epoch 1838, Loss: 210.6171946595333, Neurons: 201, Grad norm: 1.6956845735828314\n",
      "Epoch 1838, Loss: 210.6171946595333, Neurons: 201, Grad norm: 1.6956845735828314\n",
      "Epoch 1839, Loss: 210.61483999067156, Neurons: 201, Grad norm: 1.7182417809688164\n",
      "Epoch 1839, Loss: 210.61483999067156, Neurons: 201, Grad norm: 1.7182417809688164\n",
      "Epoch 1840, Loss: 210.61251227611044, Neurons: 201, Grad norm: 1.7502051687720581\n",
      "Epoch 1840, Loss: 210.61251227611044, Neurons: 201, Grad norm: 1.7502051687720581\n",
      "Epoch 1841, Loss: 210.61014817006284, Neurons: 201, Grad norm: 1.7102183182297048\n",
      "Epoch 1841, Loss: 210.61014817006284, Neurons: 201, Grad norm: 1.7102183182297048\n",
      "Epoch 1842, Loss: 210.6078026050196, Neurons: 201, Grad norm: 1.725042458963744\n",
      "Epoch 1842, Loss: 210.6078026050196, Neurons: 201, Grad norm: 1.725042458963744\n",
      "Epoch 1843, Loss: 210.60547462848203, Neurons: 201, Grad norm: 1.8006509153042858\n",
      "Epoch 1843, Loss: 210.60547462848203, Neurons: 201, Grad norm: 1.8006509153042858\n",
      "Epoch 1844, Loss: 210.6031875567553, Neurons: 201, Grad norm: 1.7305644478626094\n",
      "Epoch 1844, Loss: 210.6031875567553, Neurons: 201, Grad norm: 1.7305644478626094\n",
      "Epoch 1845, Loss: 210.6009004808215, Neurons: 201, Grad norm: 1.7830276958875404\n",
      "Epoch 1845, Loss: 210.6009004808215, Neurons: 201, Grad norm: 1.7830276958875404\n",
      "Epoch 1846, Loss: 210.59859529609628, Neurons: 201, Grad norm: 1.7090000599890103\n",
      "Epoch 1846, Loss: 210.59859529609628, Neurons: 201, Grad norm: 1.7090000599890103\n",
      "Epoch 1847, Loss: 210.59630655316573, Neurons: 201, Grad norm: 1.7026113914313248\n",
      "Epoch 1847, Loss: 210.59630655316573, Neurons: 201, Grad norm: 1.7026113914313248\n",
      "Epoch 1848, Loss: 210.59403897376998, Neurons: 201, Grad norm: 1.7584136954795342\n",
      "Epoch 1848, Loss: 210.59403897376998, Neurons: 201, Grad norm: 1.7584136954795342\n",
      "Epoch 1849, Loss: 210.59177341963272, Neurons: 201, Grad norm: 1.6708814079487313\n",
      "Epoch 1849, Loss: 210.59177341963272, Neurons: 201, Grad norm: 1.6708814079487313\n",
      "Epoch 1850, Loss: 210.5895019865656, Neurons: 201, Grad norm: 1.7885062587413578\n",
      "Epoch 1850, Loss: 210.5895019865656, Neurons: 201, Grad norm: 1.7885062587413578\n",
      "Epoch 1851, Loss: 210.5872364146931, Neurons: 201, Grad norm: 1.6940751418566629\n",
      "Epoch 1851, Loss: 210.5872364146931, Neurons: 201, Grad norm: 1.6940751418566629\n",
      "Epoch 1852, Loss: 210.58497130312637, Neurons: 201, Grad norm: 1.8595678699155895\n",
      "Epoch 1852, Loss: 210.58497130312637, Neurons: 201, Grad norm: 1.8595678699155895\n",
      "Epoch 1853, Loss: 210.5827236472406, Neurons: 201, Grad norm: 1.709819332914969\n",
      "Epoch 1853, Loss: 210.5827236472406, Neurons: 201, Grad norm: 1.709819332914969\n",
      "Epoch 1854, Loss: 210.58047393120702, Neurons: 201, Grad norm: 1.7789347241212865\n",
      "Epoch 1854, Loss: 210.58047393120702, Neurons: 201, Grad norm: 1.7789347241212865\n",
      "Epoch 1855, Loss: 210.5782140018989, Neurons: 201, Grad norm: 1.6704529554458798\n",
      "Epoch 1855, Loss: 210.5782140018989, Neurons: 201, Grad norm: 1.6704529554458798\n",
      "Epoch 1856, Loss: 210.5759556058205, Neurons: 201, Grad norm: 1.668288689121184\n",
      "Epoch 1856, Loss: 210.5759556058205, Neurons: 201, Grad norm: 1.668288689121184\n",
      "Epoch 1857, Loss: 210.5737183190297, Neurons: 201, Grad norm: 1.6946602254959715\n",
      "Epoch 1857, Loss: 210.5737183190297, Neurons: 201, Grad norm: 1.6946602254959715\n",
      "Epoch 1858, Loss: 210.57148339333534, Neurons: 201, Grad norm: 1.6481302659219728\n",
      "Epoch 1858, Loss: 210.57148339333534, Neurons: 201, Grad norm: 1.6481302659219728\n",
      "Epoch 1859, Loss: 210.5692441507213, Neurons: 201, Grad norm: 1.7415036493527385\n",
      "Epoch 1859, Loss: 210.5692441507213, Neurons: 201, Grad norm: 1.7415036493527385\n",
      "Epoch 1860, Loss: 210.56700835953714, Neurons: 201, Grad norm: 1.6595600153400507\n",
      "Epoch 1860, Loss: 210.56700835953714, Neurons: 201, Grad norm: 1.6595600153400507\n",
      "Epoch 1861, Loss: 210.56477685482105, Neurons: 201, Grad norm: 1.7379780432591665\n",
      "Epoch 1861, Loss: 210.56477685482105, Neurons: 201, Grad norm: 1.7379780432591665\n",
      "Epoch 1862, Loss: 210.5625493454668, Neurons: 201, Grad norm: 1.7320340662335696\n",
      "Epoch 1862, Loss: 210.5625493454668, Neurons: 201, Grad norm: 1.7320340662335696\n",
      "Epoch 1863, Loss: 210.56032037664423, Neurons: 201, Grad norm: 1.6753254312777897\n",
      "Epoch 1863, Loss: 210.56032037664423, Neurons: 201, Grad norm: 1.6753254312777897\n",
      "Epoch 1864, Loss: 210.55808256497403, Neurons: 201, Grad norm: 1.7056452761898333\n",
      "Epoch 1864, Loss: 210.55808256497403, Neurons: 201, Grad norm: 1.7056452761898333\n",
      "Epoch 1865, Loss: 210.5558427873035, Neurons: 201, Grad norm: 1.6209268305391642\n",
      "Epoch 1865, Loss: 210.5558427873035, Neurons: 201, Grad norm: 1.6209268305391642\n",
      "Epoch 1866, Loss: 210.55359785961878, Neurons: 201, Grad norm: 1.6306883830252106\n",
      "Epoch 1866, Loss: 210.55359785961878, Neurons: 201, Grad norm: 1.6306883830252106\n",
      "Epoch 1867, Loss: 210.55133955936157, Neurons: 201, Grad norm: 1.7220031821636008\n",
      "Epoch 1867, Loss: 210.55133955936157, Neurons: 201, Grad norm: 1.7220031821636008\n",
      "Epoch 1868, Loss: 210.54910366416027, Neurons: 201, Grad norm: 1.5949202812097492\n",
      "Epoch 1868, Loss: 210.54910366416027, Neurons: 201, Grad norm: 1.5949202812097492\n",
      "Epoch 1869, Loss: 210.54688199798207, Neurons: 201, Grad norm: 1.7360180927947004\n",
      "Epoch 1869, Loss: 210.54688199798207, Neurons: 201, Grad norm: 1.7360180927947004\n",
      "Epoch 1870, Loss: 210.54466819121743, Neurons: 201, Grad norm: 1.6711538215657318\n",
      "Epoch 1870, Loss: 210.54466819121743, Neurons: 201, Grad norm: 1.6711538215657318\n",
      "Epoch 1871, Loss: 210.542438128466, Neurons: 201, Grad norm: 1.64486905755576\n",
      "Epoch 1871, Loss: 210.542438128466, Neurons: 201, Grad norm: 1.64486905755576\n",
      "Epoch 1872, Loss: 210.54019369905376, Neurons: 201, Grad norm: 1.7857639540888375\n",
      "Epoch 1872, Loss: 210.54019369905376, Neurons: 201, Grad norm: 1.7857639540888375\n",
      "Epoch 1873, Loss: 210.5379336609908, Neurons: 201, Grad norm: 1.6265535210832929\n",
      "Epoch 1873, Loss: 210.5379336609908, Neurons: 201, Grad norm: 1.6265535210832929\n",
      "Epoch 1874, Loss: 210.53566615455776, Neurons: 201, Grad norm: 1.729926993451474\n",
      "Epoch 1874, Loss: 210.53566615455776, Neurons: 201, Grad norm: 1.729926993451474\n",
      "Epoch 1875, Loss: 210.53337535884393, Neurons: 201, Grad norm: 1.678920426327474\n",
      "Epoch 1875, Loss: 210.53337535884393, Neurons: 201, Grad norm: 1.678920426327474\n",
      "Epoch 1876, Loss: 210.53111545315477, Neurons: 201, Grad norm: 1.6626175940772128\n",
      "Epoch 1876, Loss: 210.53111545315477, Neurons: 201, Grad norm: 1.6626175940772128\n",
      "Epoch 1877, Loss: 210.52888824602852, Neurons: 201, Grad norm: 1.696469110313819\n",
      "Epoch 1877, Loss: 210.52888824602852, Neurons: 201, Grad norm: 1.696469110313819\n",
      "Epoch 1878, Loss: 210.52664521457618, Neurons: 201, Grad norm: 1.662484559154719\n",
      "Epoch 1878, Loss: 210.52664521457618, Neurons: 201, Grad norm: 1.662484559154719\n",
      "Epoch 1879, Loss: 210.5243974552005, Neurons: 201, Grad norm: 1.6511849804710819\n",
      "Epoch 1879, Loss: 210.5243974552005, Neurons: 201, Grad norm: 1.6511849804710819\n",
      "Epoch 1880, Loss: 210.52213285544778, Neurons: 201, Grad norm: 1.6906432213485652\n",
      "Epoch 1880, Loss: 210.52213285544778, Neurons: 201, Grad norm: 1.6906432213485652\n",
      "Epoch 1881, Loss: 210.51983623244476, Neurons: 201, Grad norm: 1.6497080573283933\n",
      "Epoch 1881, Loss: 210.51983623244476, Neurons: 201, Grad norm: 1.6497080573283933\n",
      "Epoch 1882, Loss: 210.51755285580327, Neurons: 201, Grad norm: 1.631686925440658\n",
      "Epoch 1882, Loss: 210.51755285580327, Neurons: 201, Grad norm: 1.631686925440658\n",
      "Epoch 1883, Loss: 210.51528944222076, Neurons: 201, Grad norm: 1.714934499550252\n",
      "Epoch 1883, Loss: 210.51528944222076, Neurons: 201, Grad norm: 1.714934499550252\n",
      "Epoch 1884, Loss: 210.51303106951082, Neurons: 201, Grad norm: 1.6169992406721438\n",
      "Epoch 1884, Loss: 210.51303106951082, Neurons: 201, Grad norm: 1.6169992406721438\n",
      "Epoch 1885, Loss: 210.51073255387024, Neurons: 201, Grad norm: 1.6951295614859687\n",
      "Epoch 1885, Loss: 210.51073255387024, Neurons: 201, Grad norm: 1.6951295614859687\n",
      "Epoch 1886, Loss: 210.50840203684302, Neurons: 201, Grad norm: 1.6629177144908138\n",
      "Epoch 1886, Loss: 210.50840203684302, Neurons: 201, Grad norm: 1.6629177144908138\n",
      "Epoch 1887, Loss: 210.50609606097512, Neurons: 201, Grad norm: 1.6680845946314726\n",
      "Epoch 1887, Loss: 210.50609606097512, Neurons: 201, Grad norm: 1.6680845946314726\n",
      "Epoch 1888, Loss: 210.50380926567598, Neurons: 201, Grad norm: 1.7429180306745133\n",
      "Epoch 1888, Loss: 210.50380926567598, Neurons: 201, Grad norm: 1.7429180306745133\n",
      "Epoch 1889, Loss: 210.50153637629842, Neurons: 201, Grad norm: 1.6859699509913562\n",
      "Epoch 1889, Loss: 210.50153637629842, Neurons: 201, Grad norm: 1.6859699509913562\n",
      "Epoch 1890, Loss: 210.49924762439926, Neurons: 201, Grad norm: 1.7009054317737906\n",
      "Epoch 1890, Loss: 210.49924762439926, Neurons: 201, Grad norm: 1.7009054317737906\n",
      "Epoch 1891, Loss: 210.49695256508608, Neurons: 201, Grad norm: 1.7595227426378324\n",
      "Epoch 1891, Loss: 210.49695256508608, Neurons: 201, Grad norm: 1.7595227426378324\n",
      "Epoch 1892, Loss: 210.49479393775445, Neurons: 201, Grad norm: 1.664358899639507\n",
      "Epoch 1892, Loss: 210.49479393775445, Neurons: 201, Grad norm: 1.664358899639507\n",
      "Epoch 1893, Loss: 210.4926440972963, Neurons: 201, Grad norm: 1.751170911267927\n",
      "Epoch 1893, Loss: 210.4926440972963, Neurons: 201, Grad norm: 1.751170911267927\n",
      "Epoch 1894, Loss: 210.49047552053426, Neurons: 201, Grad norm: 1.663370780863941\n",
      "Epoch 1894, Loss: 210.49047552053426, Neurons: 201, Grad norm: 1.663370780863941\n",
      "Epoch 1895, Loss: 210.48830760796358, Neurons: 201, Grad norm: 1.6580559060194213\n",
      "Epoch 1895, Loss: 210.48830760796358, Neurons: 201, Grad norm: 1.6580559060194213\n",
      "Epoch 1896, Loss: 210.48614473518296, Neurons: 201, Grad norm: 1.7127320499611907\n",
      "Epoch 1896, Loss: 210.48614473518296, Neurons: 201, Grad norm: 1.7127320499611907\n",
      "Epoch 1897, Loss: 210.48398296858596, Neurons: 201, Grad norm: 1.598968159485174\n",
      "Epoch 1897, Loss: 210.48398296858596, Neurons: 201, Grad norm: 1.598968159485174\n",
      "Epoch 1898, Loss: 210.48183962634042, Neurons: 201, Grad norm: 1.8114740464163073\n",
      "Epoch 1898, Loss: 210.48183962634042, Neurons: 201, Grad norm: 1.8114740464163073\n",
      "Epoch 1899, Loss: 210.47971426043716, Neurons: 201, Grad norm: 1.6310257889106479\n",
      "Epoch 1899, Loss: 210.47971426043716, Neurons: 201, Grad norm: 1.6310257889106479\n",
      "Epoch 1900, Loss: 210.4775774689926, Neurons: 201, Grad norm: 1.6758689157594946\n",
      "Epoch 1900, Loss: 210.4775774689926, Neurons: 201, Grad norm: 1.6758689157594946\n",
      "Epoch 1901, Loss: 210.47541370677376, Neurons: 201, Grad norm: 1.6485719687805351\n",
      "Epoch 1901, Loss: 210.47541370677376, Neurons: 201, Grad norm: 1.6485719687805351\n",
      "Epoch 1902, Loss: 210.47325537031074, Neurons: 201, Grad norm: 1.5474151310498903\n",
      "Epoch 1902, Loss: 210.47325537031074, Neurons: 201, Grad norm: 1.5474151310498903\n",
      "Epoch 1903, Loss: 210.47110794121863, Neurons: 201, Grad norm: 1.685022855048679\n",
      "Epoch 1903, Loss: 210.47110794121863, Neurons: 201, Grad norm: 1.685022855048679\n",
      "Epoch 1904, Loss: 210.46897492303512, Neurons: 201, Grad norm: 1.5793080429550304\n",
      "Epoch 1904, Loss: 210.46897492303512, Neurons: 201, Grad norm: 1.5793080429550304\n",
      "Epoch 1905, Loss: 210.46685977348847, Neurons: 201, Grad norm: 1.6136026930317677\n",
      "Epoch 1905, Loss: 210.46685977348847, Neurons: 201, Grad norm: 1.6136026930317677\n",
      "Epoch 1906, Loss: 210.46475106037667, Neurons: 201, Grad norm: 1.6729486142201628\n",
      "Epoch 1906, Loss: 210.46475106037667, Neurons: 201, Grad norm: 1.6729486142201628\n",
      "Epoch 1907, Loss: 210.46264549378853, Neurons: 201, Grad norm: 1.5696282230456498\n",
      "Epoch 1907, Loss: 210.46264549378853, Neurons: 201, Grad norm: 1.5696282230456498\n",
      "Epoch 1908, Loss: 210.46053547424592, Neurons: 201, Grad norm: 1.6015848730278217\n",
      "Epoch 1908, Loss: 210.46053547424592, Neurons: 201, Grad norm: 1.6015848730278217\n",
      "Epoch 1909, Loss: 210.45842893523897, Neurons: 201, Grad norm: 1.5883419431691703\n",
      "Epoch 1909, Loss: 210.45842893523897, Neurons: 201, Grad norm: 1.5883419431691703\n",
      "Epoch 1910, Loss: 210.45633123296386, Neurons: 201, Grad norm: 1.5296501561531668\n",
      "Epoch 1910, Loss: 210.45633123296386, Neurons: 201, Grad norm: 1.5296501561531668\n",
      "Epoch 1911, Loss: 210.45423350224718, Neurons: 201, Grad norm: 1.592023261948393\n",
      "Epoch 1911, Loss: 210.45423350224718, Neurons: 201, Grad norm: 1.592023261948393\n",
      "Epoch 1912, Loss: 210.45212802434392, Neurons: 201, Grad norm: 1.5457424922371867\n",
      "Epoch 1912, Loss: 210.45212802434392, Neurons: 201, Grad norm: 1.5457424922371867\n",
      "Epoch 1913, Loss: 210.45003436862535, Neurons: 201, Grad norm: 1.5552897292694767\n",
      "Epoch 1913, Loss: 210.45003436862535, Neurons: 201, Grad norm: 1.5552897292694767\n",
      "Epoch 1914, Loss: 210.44795225333246, Neurons: 201, Grad norm: 1.5919665272342716\n",
      "Epoch 1914, Loss: 210.44795225333246, Neurons: 201, Grad norm: 1.5919665272342716\n",
      "Epoch 1915, Loss: 210.44587881921234, Neurons: 201, Grad norm: 1.5774529852551082\n",
      "Epoch 1915, Loss: 210.44587881921234, Neurons: 201, Grad norm: 1.5774529852551082\n",
      "Epoch 1916, Loss: 210.44379834541687, Neurons: 201, Grad norm: 1.5723274529427536\n",
      "Epoch 1916, Loss: 210.44379834541687, Neurons: 201, Grad norm: 1.5723274529427536\n",
      "Epoch 1917, Loss: 210.44172481707443, Neurons: 201, Grad norm: 1.6338087014711955\n",
      "Epoch 1917, Loss: 210.44172481707443, Neurons: 201, Grad norm: 1.6338087014711955\n",
      "Epoch 1918, Loss: 210.4396611603938, Neurons: 201, Grad norm: 1.5201299846479068\n",
      "Epoch 1918, Loss: 210.4396611603938, Neurons: 201, Grad norm: 1.5201299846479068\n",
      "Epoch 1919, Loss: 210.4375810956534, Neurons: 201, Grad norm: 1.5696223165834018\n",
      "Epoch 1919, Loss: 210.4375810956534, Neurons: 201, Grad norm: 1.5696223165834018\n",
      "Epoch 1920, Loss: 210.43552212374686, Neurons: 201, Grad norm: 1.579564564491987\n",
      "Epoch 1920, Loss: 210.43552212374686, Neurons: 201, Grad norm: 1.579564564491987\n",
      "Epoch 1921, Loss: 210.4334709702128, Neurons: 201, Grad norm: 1.5664922194795243\n",
      "Epoch 1921, Loss: 210.4334709702128, Neurons: 201, Grad norm: 1.5664922194795243\n",
      "Epoch 1922, Loss: 210.43142611306175, Neurons: 201, Grad norm: 1.676485726356358\n",
      "Epoch 1922, Loss: 210.43142611306175, Neurons: 201, Grad norm: 1.676485726356358\n",
      "Epoch 1923, Loss: 210.4293825103996, Neurons: 201, Grad norm: 1.5577196434765928\n",
      "Epoch 1923, Loss: 210.4293825103996, Neurons: 201, Grad norm: 1.5577196434765928\n",
      "Epoch 1924, Loss: 210.42733238310342, Neurons: 201, Grad norm: 1.6417678382777467\n",
      "Epoch 1924, Loss: 210.42733238310342, Neurons: 201, Grad norm: 1.6417678382777467\n",
      "Epoch 1925, Loss: 210.4252872232279, Neurons: 201, Grad norm: 1.527860879371084\n",
      "Epoch 1925, Loss: 210.4252872232279, Neurons: 201, Grad norm: 1.527860879371084\n",
      "Epoch 1926, Loss: 210.42325225800255, Neurons: 201, Grad norm: 1.498502594144321\n",
      "Epoch 1926, Loss: 210.42325225800255, Neurons: 201, Grad norm: 1.498502594144321\n",
      "Epoch 1927, Loss: 210.42121832118406, Neurons: 201, Grad norm: 1.6630452917731224\n",
      "Epoch 1927, Loss: 210.42121832118406, Neurons: 201, Grad norm: 1.6630452917731224\n",
      "Epoch 1928, Loss: 210.41917539733006, Neurons: 201, Grad norm: 1.498005227578347\n",
      "Epoch 1928, Loss: 210.41917539733006, Neurons: 201, Grad norm: 1.498005227578347\n",
      "Epoch 1929, Loss: 210.41714045721608, Neurons: 201, Grad norm: 1.7122168809605007\n",
      "Epoch 1929, Loss: 210.41714045721608, Neurons: 201, Grad norm: 1.7122168809605007\n",
      "Epoch 1930, Loss: 210.41509563659685, Neurons: 201, Grad norm: 1.4839934635953247\n",
      "Epoch 1930, Loss: 210.41509563659685, Neurons: 201, Grad norm: 1.4839934635953247\n",
      "Epoch 1931, Loss: 210.41303561296127, Neurons: 201, Grad norm: 1.5693041820027076\n",
      "Epoch 1931, Loss: 210.41303561296127, Neurons: 201, Grad norm: 1.5693041820027076\n",
      "Epoch 1932, Loss: 210.4109764813873, Neurons: 201, Grad norm: 1.6386164828619205\n",
      "Epoch 1932, Loss: 210.4109764813873, Neurons: 201, Grad norm: 1.6386164828619205\n",
      "Epoch 1933, Loss: 210.40892717905265, Neurons: 201, Grad norm: 1.5377350780603838\n",
      "Epoch 1933, Loss: 210.40892717905265, Neurons: 201, Grad norm: 1.5377350780603838\n",
      "Epoch 1934, Loss: 210.40688652280568, Neurons: 201, Grad norm: 1.668814637422528\n",
      "Epoch 1934, Loss: 210.40688652280568, Neurons: 201, Grad norm: 1.668814637422528\n",
      "Epoch 1935, Loss: 210.40483476128693, Neurons: 201, Grad norm: 1.526918703227026\n",
      "Epoch 1935, Loss: 210.40483476128693, Neurons: 201, Grad norm: 1.526918703227026\n",
      "Epoch 1936, Loss: 210.4027844036735, Neurons: 201, Grad norm: 1.520617344007631\n",
      "Epoch 1936, Loss: 210.4027844036735, Neurons: 201, Grad norm: 1.520617344007631\n",
      "Epoch 1937, Loss: 210.40077350551297, Neurons: 201, Grad norm: 1.7123118498270171\n",
      "Epoch 1937, Loss: 210.40077350551297, Neurons: 201, Grad norm: 1.7123118498270171\n",
      "Epoch 1938, Loss: 210.3987903799748, Neurons: 201, Grad norm: 1.5306062328208265\n",
      "Epoch 1938, Loss: 210.3987903799748, Neurons: 201, Grad norm: 1.5306062328208265\n",
      "Epoch 1939, Loss: 210.39678939854736, Neurons: 201, Grad norm: 1.7094903003712631\n",
      "Epoch 1939, Loss: 210.39678939854736, Neurons: 201, Grad norm: 1.7094903003712631\n",
      "Epoch 1940, Loss: 210.3947897960987, Neurons: 201, Grad norm: 1.512397182996455\n",
      "Epoch 1940, Loss: 210.3947897960987, Neurons: 201, Grad norm: 1.512397182996455\n",
      "Epoch 1941, Loss: 210.39278661098075, Neurons: 201, Grad norm: 1.5863313875602052\n",
      "Epoch 1941, Loss: 210.39278661098075, Neurons: 201, Grad norm: 1.5863313875602052\n",
      "Epoch 1942, Loss: 210.3907773112359, Neurons: 201, Grad norm: 1.621949935571536\n",
      "Epoch 1942, Loss: 210.3907773112359, Neurons: 201, Grad norm: 1.621949935571536\n",
      "Epoch 1943, Loss: 210.38877067997095, Neurons: 201, Grad norm: 1.512296632699974\n",
      "Epoch 1943, Loss: 210.38877067997095, Neurons: 201, Grad norm: 1.512296632699974\n",
      "Epoch 1944, Loss: 210.38677146524628, Neurons: 201, Grad norm: 1.628746924885409\n",
      "Epoch 1944, Loss: 210.38677146524628, Neurons: 201, Grad norm: 1.628746924885409\n",
      "Epoch 1945, Loss: 210.38475798099586, Neurons: 201, Grad norm: 1.484265331291385\n",
      "Epoch 1945, Loss: 210.38475798099586, Neurons: 201, Grad norm: 1.484265331291385\n",
      "Epoch 1946, Loss: 210.38276231760346, Neurons: 201, Grad norm: 1.482500316285238\n",
      "Epoch 1946, Loss: 210.38276231760346, Neurons: 201, Grad norm: 1.482500316285238\n",
      "Epoch 1947, Loss: 210.38078004212358, Neurons: 201, Grad norm: 1.5668867973685892\n",
      "Epoch 1947, Loss: 210.38078004212358, Neurons: 201, Grad norm: 1.5668867973685892\n",
      "Epoch 1948, Loss: 210.37879137817788, Neurons: 201, Grad norm: 1.4451014393000214\n",
      "Epoch 1948, Loss: 210.37879137817788, Neurons: 201, Grad norm: 1.4451014393000214\n",
      "Epoch 1949, Loss: 210.37679745046833, Neurons: 201, Grad norm: 1.5497466793721375\n",
      "Epoch 1949, Loss: 210.37679745046833, Neurons: 201, Grad norm: 1.5497466793721375\n",
      "Epoch 1950, Loss: 210.3747908349624, Neurons: 201, Grad norm: 1.4628740437750745\n",
      "Epoch 1950, Loss: 210.3747908349624, Neurons: 201, Grad norm: 1.4628740437750745\n",
      "Epoch 1951, Loss: 210.37279506028503, Neurons: 201, Grad norm: 1.518730931889167\n",
      "Epoch 1951, Loss: 210.37279506028503, Neurons: 201, Grad norm: 1.518730931889167\n",
      "Epoch 1952, Loss: 210.3707753207669, Neurons: 201, Grad norm: 1.5405764927444427\n",
      "Epoch 1952, Loss: 210.3707753207669, Neurons: 201, Grad norm: 1.5405764927444427\n",
      "Epoch 1953, Loss: 210.36875874324676, Neurons: 201, Grad norm: 1.471942162810404\n",
      "Epoch 1953, Loss: 210.36875874324676, Neurons: 201, Grad norm: 1.471942162810404\n",
      "Epoch 1954, Loss: 210.36673981943107, Neurons: 201, Grad norm: 1.6121347735077964\n",
      "Epoch 1954, Loss: 210.36673981943107, Neurons: 201, Grad norm: 1.6121347735077964\n",
      "Epoch 1955, Loss: 210.3647151415736, Neurons: 201, Grad norm: 1.4355053112789158\n",
      "Epoch 1955, Loss: 210.3647151415736, Neurons: 201, Grad norm: 1.4355053112789158\n",
      "Epoch 1956, Loss: 210.3626818854284, Neurons: 201, Grad norm: 1.632220905663923\n",
      "Epoch 1956, Loss: 210.3626818854284, Neurons: 201, Grad norm: 1.632220905663923\n",
      "Epoch 1957, Loss: 210.36066271358098, Neurons: 201, Grad norm: 1.521231968403565\n",
      "Epoch 1957, Loss: 210.36066271358098, Neurons: 201, Grad norm: 1.521231968403565\n",
      "Epoch 1958, Loss: 210.35873572052816, Neurons: 201, Grad norm: 1.6552756042931829\n",
      "Epoch 1958, Loss: 210.35873572052816, Neurons: 201, Grad norm: 1.6552756042931829\n",
      "Epoch 1959, Loss: 210.35679847467574, Neurons: 201, Grad norm: 1.5642664030921933\n",
      "Epoch 1959, Loss: 210.35679847467574, Neurons: 201, Grad norm: 1.5642664030921933\n",
      "Epoch 1960, Loss: 210.35485876116695, Neurons: 201, Grad norm: 1.5097996151208115\n",
      "Epoch 1960, Loss: 210.35485876116695, Neurons: 201, Grad norm: 1.5097996151208115\n",
      "Epoch 1961, Loss: 210.35290115282, Neurons: 201, Grad norm: 1.556427564518128\n",
      "Epoch 1961, Loss: 210.35290115282, Neurons: 201, Grad norm: 1.556427564518128\n",
      "Epoch 1962, Loss: 210.35093500910767, Neurons: 201, Grad norm: 1.4967611558685714\n",
      "Epoch 1962, Loss: 210.35093500910767, Neurons: 201, Grad norm: 1.4967611558685714\n",
      "Epoch 1963, Loss: 210.34894202204538, Neurons: 201, Grad norm: 1.6647737409346541\n",
      "Epoch 1963, Loss: 210.34894202204538, Neurons: 201, Grad norm: 1.6647737409346541\n",
      "Epoch 1964, Loss: 210.34695071502, Neurons: 201, Grad norm: 1.5023813841378195\n",
      "Epoch 1964, Loss: 210.34695071502, Neurons: 201, Grad norm: 1.5023813841378195\n",
      "Epoch 1965, Loss: 210.34493260581075, Neurons: 201, Grad norm: 1.5356393008250215\n",
      "Epoch 1965, Loss: 210.34493260581075, Neurons: 201, Grad norm: 1.5356393008250215\n",
      "Epoch 1966, Loss: 210.34294424601006, Neurons: 201, Grad norm: 1.5471712460707052\n",
      "Epoch 1966, Loss: 210.34294424601006, Neurons: 201, Grad norm: 1.5471712460707052\n",
      "Epoch 1967, Loss: 210.34094304927055, Neurons: 201, Grad norm: 1.4580891852971818\n",
      "Epoch 1967, Loss: 210.34094304927055, Neurons: 201, Grad norm: 1.4580891852971818\n",
      "Epoch 1968, Loss: 210.3389377349845, Neurons: 201, Grad norm: 1.7378617686494595\n",
      "Epoch 1968, Loss: 210.3389377349845, Neurons: 201, Grad norm: 1.7378617686494595\n",
      "Epoch 1969, Loss: 210.33698909111015, Neurons: 201, Grad norm: 1.4659876708599766\n",
      "Epoch 1969, Loss: 210.33698909111015, Neurons: 201, Grad norm: 1.4659876708599766\n",
      "Epoch 1970, Loss: 210.33504325790017, Neurons: 201, Grad norm: 1.610043788491406\n",
      "Epoch 1970, Loss: 210.33504325790017, Neurons: 201, Grad norm: 1.610043788491406\n",
      "Epoch 1971, Loss: 210.33307210470613, Neurons: 201, Grad norm: 1.4426168064015181\n",
      "Epoch 1971, Loss: 210.33307210470613, Neurons: 201, Grad norm: 1.4426168064015181\n",
      "Epoch 1972, Loss: 210.3310859057991, Neurons: 201, Grad norm: 1.4425004063867657\n",
      "Epoch 1972, Loss: 210.3310859057991, Neurons: 201, Grad norm: 1.4425004063867657\n",
      "Epoch 1973, Loss: 210.32912735915994, Neurons: 201, Grad norm: 1.6595476563510332\n",
      "Epoch 1973, Loss: 210.32912735915994, Neurons: 201, Grad norm: 1.6595476563510332\n",
      "Epoch 1974, Loss: 210.3271912136047, Neurons: 201, Grad norm: 1.4950063997970537\n",
      "Epoch 1974, Loss: 210.3271912136047, Neurons: 201, Grad norm: 1.4950063997970537\n",
      "Epoch 1975, Loss: 210.32524738007385, Neurons: 201, Grad norm: 1.7299435518228132\n",
      "Epoch 1975, Loss: 210.32524738007385, Neurons: 201, Grad norm: 1.7299435518228132\n",
      "Epoch 1976, Loss: 210.32333093759502, Neurons: 201, Grad norm: 1.46953094402586\n",
      "Epoch 1976, Loss: 210.32333093759502, Neurons: 201, Grad norm: 1.46953094402586\n",
      "Epoch 1977, Loss: 210.32141706788065, Neurons: 201, Grad norm: 1.611075386150417\n",
      "Epoch 1977, Loss: 210.32141706788065, Neurons: 201, Grad norm: 1.611075386150417\n",
      "Epoch 1978, Loss: 210.31950396561982, Neurons: 201, Grad norm: 1.5179085857871613\n",
      "Epoch 1978, Loss: 210.31950396561982, Neurons: 201, Grad norm: 1.5179085857871613\n",
      "Epoch 1979, Loss: 210.31759251780994, Neurons: 201, Grad norm: 1.502444328630049\n",
      "Epoch 1979, Loss: 210.31759251780994, Neurons: 201, Grad norm: 1.502444328630049\n",
      "Epoch 1980, Loss: 210.31569133380796, Neurons: 201, Grad norm: 1.5728433894333094\n",
      "Epoch 1980, Loss: 210.31569133380796, Neurons: 201, Grad norm: 1.5728433894333094\n",
      "Epoch 1981, Loss: 210.3137946956154, Neurons: 201, Grad norm: 1.4668742468716915\n",
      "Epoch 1981, Loss: 210.3137946956154, Neurons: 201, Grad norm: 1.4668742468716915\n",
      "Epoch 1982, Loss: 210.31190326614862, Neurons: 201, Grad norm: 1.5475714772921485\n",
      "Epoch 1982, Loss: 210.31190326614862, Neurons: 201, Grad norm: 1.5475714772921485\n",
      "Epoch 1983, Loss: 210.31001178100078, Neurons: 201, Grad norm: 1.4598456511881535\n",
      "Epoch 1983, Loss: 210.31001178100078, Neurons: 201, Grad norm: 1.4598456511881535\n",
      "Epoch 1984, Loss: 210.3081264271706, Neurons: 201, Grad norm: 1.4334119242602374\n",
      "Epoch 1984, Loss: 210.3081264271706, Neurons: 201, Grad norm: 1.4334119242602374\n",
      "Epoch 1985, Loss: 210.3062453264063, Neurons: 201, Grad norm: 1.496377395112971\n",
      "Epoch 1985, Loss: 210.3062453264063, Neurons: 201, Grad norm: 1.496377395112971\n",
      "Epoch 1986, Loss: 210.30436910254764, Neurons: 201, Grad norm: 1.396818790828043\n",
      "Epoch 1986, Loss: 210.30436910254764, Neurons: 201, Grad norm: 1.396818790828043\n",
      "Epoch 1987, Loss: 210.30249108289337, Neurons: 201, Grad norm: 1.40404245486546\n",
      "Epoch 1987, Loss: 210.30249108289337, Neurons: 201, Grad norm: 1.40404245486546\n",
      "Epoch 1988, Loss: 210.30060612242013, Neurons: 201, Grad norm: 1.423901072504665\n",
      "Epoch 1988, Loss: 210.30060612242013, Neurons: 201, Grad norm: 1.423901072504665\n",
      "Epoch 1989, Loss: 210.29872008560878, Neurons: 201, Grad norm: 1.3630820384308728\n",
      "Epoch 1989, Loss: 210.29872008560878, Neurons: 201, Grad norm: 1.3630820384308728\n",
      "Epoch 1990, Loss: 210.29683412834174, Neurons: 201, Grad norm: 1.501978077759403\n",
      "Epoch 1990, Loss: 210.29683412834174, Neurons: 201, Grad norm: 1.501978077759403\n",
      "Epoch 1991, Loss: 210.2949487734275, Neurons: 201, Grad norm: 1.3914520670498123\n",
      "Epoch 1991, Loss: 210.2949487734275, Neurons: 201, Grad norm: 1.3914520670498123\n",
      "Epoch 1992, Loss: 210.29305041090615, Neurons: 201, Grad norm: 1.546413782909312\n",
      "Epoch 1992, Loss: 210.29305041090615, Neurons: 201, Grad norm: 1.546413782909312\n",
      "Epoch 1993, Loss: 210.29114929006337, Neurons: 201, Grad norm: 1.4593608438821082\n",
      "Epoch 1993, Loss: 210.29114929006337, Neurons: 201, Grad norm: 1.4593608438821082\n",
      "Epoch 1994, Loss: 210.28926301748191, Neurons: 201, Grad norm: 1.4697155307266099\n",
      "Epoch 1994, Loss: 210.28926301748191, Neurons: 201, Grad norm: 1.4697155307266099\n",
      "Epoch 1995, Loss: 210.28738104156406, Neurons: 201, Grad norm: 1.530827068766565\n",
      "Epoch 1995, Loss: 210.28738104156406, Neurons: 201, Grad norm: 1.530827068766565\n",
      "Epoch 1996, Loss: 210.28551222406128, Neurons: 201, Grad norm: 1.4138683700285806\n",
      "Epoch 1996, Loss: 210.28551222406128, Neurons: 201, Grad norm: 1.4138683700285806\n",
      "Epoch 1997, Loss: 210.2836449323869, Neurons: 201, Grad norm: 1.5115330936619353\n",
      "Epoch 1997, Loss: 210.2836449323869, Neurons: 201, Grad norm: 1.5115330936619353\n",
      "Epoch 1998, Loss: 210.28178153550706, Neurons: 201, Grad norm: 1.4210417208113713\n",
      "Epoch 1998, Loss: 210.28178153550706, Neurons: 201, Grad norm: 1.4210417208113713\n",
      "Epoch 1999, Loss: 210.27990844929408, Neurons: 201, Grad norm: 1.4330743107328703\n",
      "Epoch 1999, Loss: 210.27990844929408, Neurons: 201, Grad norm: 1.4330743107328703\n",
      "Epoch 2000, Loss: 210.27802513746911, Neurons: 201, Grad norm: 1.5282691677833633\n",
      "Epoch 2000, Loss: 210.27802513746911, Neurons: 201, Grad norm: 1.5282691677833633\n",
      "Epoch 2001, Loss: 210.2761247467711, Neurons: 201, Grad norm: 1.4249346088537262\n",
      "Epoch 2001, Loss: 210.2761247467711, Neurons: 201, Grad norm: 1.4249346088537262\n",
      "Epoch 2002, Loss: 210.27421104696884, Neurons: 201, Grad norm: 1.593536593628136\n",
      "Epoch 2002, Loss: 210.27421104696884, Neurons: 201, Grad norm: 1.593536593628136\n",
      "Epoch 2003, Loss: 210.27228936344804, Neurons: 201, Grad norm: 1.4700613046294841\n",
      "Epoch 2003, Loss: 210.27228936344804, Neurons: 201, Grad norm: 1.4700613046294841\n",
      "Epoch 2004, Loss: 210.27035215809403, Neurons: 201, Grad norm: 1.5324049639248267\n",
      "Epoch 2004, Loss: 210.27035215809403, Neurons: 201, Grad norm: 1.5324049639248267\n",
      "Epoch 2005, Loss: 210.26841068635986, Neurons: 201, Grad norm: 1.589872880477052\n",
      "Epoch 2005, Loss: 210.26841068635986, Neurons: 201, Grad norm: 1.589872880477052\n",
      "Epoch 2006, Loss: 210.2664209549662, Neurons: 201, Grad norm: 1.4838411487009058\n",
      "Epoch 2006, Loss: 210.2664209549662, Neurons: 201, Grad norm: 1.4838411487009058\n",
      "Epoch 2007, Loss: 210.26447066553985, Neurons: 201, Grad norm: 1.6498725683645474\n",
      "Epoch 2007, Loss: 210.26447066553985, Neurons: 201, Grad norm: 1.6498725683645474\n",
      "Epoch 2008, Loss: 210.26250140183694, Neurons: 201, Grad norm: 1.4827577698799355\n",
      "Epoch 2008, Loss: 210.26250140183694, Neurons: 201, Grad norm: 1.4827577698799355\n",
      "Epoch 2009, Loss: 210.26048754734796, Neurons: 201, Grad norm: 1.6533092779881355\n",
      "Epoch 2009, Loss: 210.26048754734796, Neurons: 201, Grad norm: 1.6533092779881355\n",
      "Epoch 2010, Loss: 210.25846452154377, Neurons: 201, Grad norm: 1.4418171526048713\n",
      "Epoch 2010, Loss: 210.25846452154377, Neurons: 201, Grad norm: 1.4418171526048713\n",
      "Epoch 2011, Loss: 210.25651636577894, Neurons: 201, Grad norm: 1.7340715707672907\n",
      "Epoch 2011, Loss: 210.25651636577894, Neurons: 201, Grad norm: 1.7340715707672907\n",
      "Epoch 2012, Loss: 210.25454906208077, Neurons: 201, Grad norm: 1.4474042718610887\n",
      "Epoch 2012, Loss: 210.25454906208077, Neurons: 201, Grad norm: 1.4474042718610887\n",
      "Epoch 2013, Loss: 210.25264785160897, Neurons: 201, Grad norm: 1.7295563038331758\n",
      "Epoch 2013, Loss: 210.25264785160897, Neurons: 201, Grad norm: 1.7295563038331758\n",
      "Epoch 2014, Loss: 210.25074320550962, Neurons: 201, Grad norm: 1.4446281194302042\n",
      "Epoch 2014, Loss: 210.25074320550962, Neurons: 201, Grad norm: 1.4446281194302042\n",
      "Epoch 2015, Loss: 210.24884058444815, Neurons: 201, Grad norm: 1.5129389281415944\n",
      "Epoch 2015, Loss: 210.24884058444815, Neurons: 201, Grad norm: 1.5129389281415944\n",
      "Epoch 2016, Loss: 210.24707605685882, Neurons: 201, Grad norm: 1.5364867299491651\n",
      "Epoch 2016, Loss: 210.24707605685882, Neurons: 201, Grad norm: 1.5364867299491651\n",
      "Epoch 2017, Loss: 210.24531684412992, Neurons: 201, Grad norm: 1.446405913501817\n",
      "Epoch 2017, Loss: 210.24531684412992, Neurons: 201, Grad norm: 1.446405913501817\n",
      "Epoch 2018, Loss: 210.2435097865252, Neurons: 201, Grad norm: 1.673808322886176\n",
      "Epoch 2018, Loss: 210.2435097865252, Neurons: 201, Grad norm: 1.673808322886176\n",
      "Epoch 2019, Loss: 210.24168655350135, Neurons: 201, Grad norm: 1.4503810687764094\n",
      "Epoch 2019, Loss: 210.24168655350135, Neurons: 201, Grad norm: 1.4503810687764094\n",
      "Epoch 2020, Loss: 210.23983023753604, Neurons: 201, Grad norm: 1.9117109780147914\n",
      "Epoch 2020, Loss: 210.23983023753604, Neurons: 201, Grad norm: 1.9117109780147914\n",
      "Epoch 2021, Loss: 210.23796564619525, Neurons: 201, Grad norm: 1.5412496473522888\n",
      "Epoch 2021, Loss: 210.23796564619525, Neurons: 201, Grad norm: 1.5412496473522888\n",
      "Epoch 2022, Loss: 210.23608890361092, Neurons: 201, Grad norm: 1.9425422872659284\n",
      "Epoch 2022, Loss: 210.23608890361092, Neurons: 201, Grad norm: 1.9425422872659284\n",
      "Epoch 2023, Loss: 210.2341488477576, Neurons: 201, Grad norm: 1.4393440109404427\n",
      "Epoch 2023, Loss: 210.2341488477576, Neurons: 201, Grad norm: 1.4393440109404427\n",
      "Epoch 2024, Loss: 210.23223835437085, Neurons: 201, Grad norm: 1.6057070271533604\n",
      "Epoch 2024, Loss: 210.23223835437085, Neurons: 201, Grad norm: 1.6057070271533604\n",
      "Epoch 2025, Loss: 210.23034511278766, Neurons: 201, Grad norm: 1.6189278197345407\n",
      "Epoch 2025, Loss: 210.23034511278766, Neurons: 201, Grad norm: 1.6189278197345407\n",
      "Epoch 2026, Loss: 210.228518827829, Neurons: 201, Grad norm: 1.4724954795848677\n",
      "Epoch 2026, Loss: 210.228518827829, Neurons: 201, Grad norm: 1.4724954795848677\n",
      "Epoch 2027, Loss: 210.22670378086556, Neurons: 201, Grad norm: 2.0048328457193403\n",
      "Epoch 2027, Loss: 210.22670378086556, Neurons: 201, Grad norm: 2.0048328457193403\n",
      "Epoch 2028, Loss: 210.22488507293735, Neurons: 201, Grad norm: 1.494627662011033\n",
      "Epoch 2028, Loss: 210.22488507293735, Neurons: 201, Grad norm: 1.494627662011033\n",
      "Epoch 2029, Loss: 210.2230168765335, Neurons: 201, Grad norm: 1.6744575398475992\n",
      "Epoch 2029, Loss: 210.2230168765335, Neurons: 201, Grad norm: 1.6744575398475992\n",
      "Epoch 2030, Loss: 210.2211342322599, Neurons: 201, Grad norm: 1.4173014657982514\n",
      "Epoch 2030, Loss: 210.2211342322599, Neurons: 201, Grad norm: 1.4173014657982514\n",
      "Epoch 2031, Loss: 210.21927551132757, Neurons: 201, Grad norm: 1.4139636894793934\n",
      "Epoch 2031, Loss: 210.21927551132757, Neurons: 201, Grad norm: 1.4139636894793934\n",
      "Epoch 2032, Loss: 210.21746469100046, Neurons: 201, Grad norm: 1.6128685607669564\n",
      "Epoch 2032, Loss: 210.21746469100046, Neurons: 201, Grad norm: 1.6128685607669564\n",
      "Epoch 2033, Loss: 210.21569415182282, Neurons: 201, Grad norm: 1.3890615601644907\n",
      "Epoch 2033, Loss: 210.21569415182282, Neurons: 201, Grad norm: 1.3890615601644907\n",
      "Epoch 2034, Loss: 210.21392561997803, Neurons: 201, Grad norm: 1.631532021142531\n",
      "Epoch 2034, Loss: 210.21392561997803, Neurons: 201, Grad norm: 1.631532021142531\n",
      "Epoch 2035, Loss: 210.21213052901626, Neurons: 201, Grad norm: 1.3547463501487733\n",
      "Epoch 2035, Loss: 210.21213052901626, Neurons: 201, Grad norm: 1.3547463501487733\n",
      "Epoch 2036, Loss: 210.21032494293115, Neurons: 201, Grad norm: 1.4839101650420234\n",
      "Epoch 2036, Loss: 210.21032494293115, Neurons: 201, Grad norm: 1.4839101650420234\n",
      "Epoch 2037, Loss: 210.2085132088775, Neurons: 201, Grad norm: 1.3135162308810002\n",
      "Epoch 2037, Loss: 210.2085132088775, Neurons: 201, Grad norm: 1.3135162308810002\n",
      "Epoch 2038, Loss: 210.20673201704975, Neurons: 201, Grad norm: 1.4640374124198292\n",
      "Epoch 2038, Loss: 210.20673201704975, Neurons: 201, Grad norm: 1.4640374124198292\n",
      "Epoch 2039, Loss: 210.204954905142, Neurons: 201, Grad norm: 1.3613279434972836\n",
      "Epoch 2039, Loss: 210.204954905142, Neurons: 201, Grad norm: 1.3613279434972836\n",
      "Epoch 2040, Loss: 210.20318055393096, Neurons: 201, Grad norm: 1.5660808507111625\n",
      "Epoch 2040, Loss: 210.20318055393096, Neurons: 201, Grad norm: 1.5660808507111625\n",
      "Epoch 2041, Loss: 210.20142247107674, Neurons: 201, Grad norm: 1.4164045614539018\n",
      "Epoch 2041, Loss: 210.20142247107674, Neurons: 201, Grad norm: 1.4164045614539018\n",
      "Epoch 2042, Loss: 210.19968786315567, Neurons: 201, Grad norm: 1.5794364713131148\n",
      "Epoch 2042, Loss: 210.19968786315567, Neurons: 201, Grad norm: 1.5794364713131148\n",
      "Epoch 2043, Loss: 210.1979651432592, Neurons: 201, Grad norm: 1.3518756403139087\n",
      "Epoch 2043, Loss: 210.1979651432592, Neurons: 201, Grad norm: 1.3518756403139087\n",
      "Epoch 2044, Loss: 210.19624510100746, Neurons: 201, Grad norm: 1.4737026214735698\n",
      "Epoch 2044, Loss: 210.19624510100746, Neurons: 201, Grad norm: 1.4737026214735698\n",
      "Epoch 2045, Loss: 210.19453161292557, Neurons: 201, Grad norm: 1.3287980461210938\n",
      "Epoch 2045, Loss: 210.19453161292557, Neurons: 201, Grad norm: 1.3287980461210938\n",
      "Epoch 2046, Loss: 210.19282548246295, Neurons: 201, Grad norm: 1.355637728717453\n",
      "Epoch 2046, Loss: 210.19282548246295, Neurons: 201, Grad norm: 1.355637728717453\n",
      "Epoch 2047, Loss: 210.19112322643596, Neurons: 201, Grad norm: 1.415297018798181\n",
      "Epoch 2047, Loss: 210.19112322643596, Neurons: 201, Grad norm: 1.415297018798181\n",
      "Epoch 2048, Loss: 210.18941443322242, Neurons: 201, Grad norm: 1.3126190300487852\n",
      "Epoch 2048, Loss: 210.18941443322242, Neurons: 201, Grad norm: 1.3126190300487852\n",
      "Epoch 2049, Loss: 210.1877116492328, Neurons: 201, Grad norm: 1.5468822739764807\n",
      "Epoch 2049, Loss: 210.1877116492328, Neurons: 201, Grad norm: 1.5468822739764807\n",
      "Epoch 2050, Loss: 210.18600987406577, Neurons: 201, Grad norm: 1.3305584134737543\n",
      "Epoch 2050, Loss: 210.18600987406577, Neurons: 201, Grad norm: 1.3305584134737543\n",
      "Epoch 2051, Loss: 210.18430563105267, Neurons: 201, Grad norm: 1.5290101098852784\n",
      "Epoch 2051, Loss: 210.18430563105267, Neurons: 201, Grad norm: 1.5290101098852784\n",
      "Epoch 2052, Loss: 210.18258996188766, Neurons: 201, Grad norm: 1.387085948649393\n",
      "Epoch 2052, Loss: 210.18258996188766, Neurons: 201, Grad norm: 1.387085948649393\n",
      "Epoch 2053, Loss: 210.18087562619144, Neurons: 201, Grad norm: 1.3852236249877246\n",
      "Epoch 2053, Loss: 210.18087562619144, Neurons: 201, Grad norm: 1.3852236249877246\n",
      "Epoch 2054, Loss: 210.17915647207676, Neurons: 201, Grad norm: 1.509094588803333\n",
      "Epoch 2054, Loss: 210.17915647207676, Neurons: 201, Grad norm: 1.509094588803333\n",
      "Epoch 2055, Loss: 210.17743554963704, Neurons: 201, Grad norm: 1.3263271207395235\n",
      "Epoch 2055, Loss: 210.17743554963704, Neurons: 201, Grad norm: 1.3263271207395235\n",
      "Epoch 2056, Loss: 210.17572685118125, Neurons: 201, Grad norm: 1.4893939075196443\n",
      "Epoch 2056, Loss: 210.17572685118125, Neurons: 201, Grad norm: 1.4893939075196443\n",
      "Epoch 2057, Loss: 210.17401337723706, Neurons: 201, Grad norm: 1.3102937030539734\n",
      "Epoch 2057, Loss: 210.17401337723706, Neurons: 201, Grad norm: 1.3102937030539734\n",
      "Epoch 2058, Loss: 210.17230302752216, Neurons: 201, Grad norm: 1.3839627249593571\n",
      "Epoch 2058, Loss: 210.17230302752216, Neurons: 201, Grad norm: 1.3839627249593571\n",
      "Epoch 2059, Loss: 210.1705839435077, Neurons: 201, Grad norm: 1.3940576883734204\n",
      "Epoch 2059, Loss: 210.1705839435077, Neurons: 201, Grad norm: 1.3940576883734204\n",
      "Epoch 2060, Loss: 210.16886619531746, Neurons: 201, Grad norm: 1.3132650709722613\n",
      "Epoch 2060, Loss: 210.16886619531746, Neurons: 201, Grad norm: 1.3132650709722613\n",
      "Epoch 2061, Loss: 210.16715934892403, Neurons: 201, Grad norm: 1.5531432221380692\n",
      "Epoch 2061, Loss: 210.16715934892403, Neurons: 201, Grad norm: 1.5531432221380692\n",
      "Epoch 2062, Loss: 210.16545863881026, Neurons: 201, Grad norm: 1.3537657741923628\n",
      "Epoch 2062, Loss: 210.16545863881026, Neurons: 201, Grad norm: 1.3537657741923628\n",
      "Epoch 2063, Loss: 210.1637836916436, Neurons: 201, Grad norm: 1.760719630937819\n",
      "Epoch 2063, Loss: 210.1637836916436, Neurons: 201, Grad norm: 1.760719630937819\n",
      "Epoch 2064, Loss: 210.16212583548256, Neurons: 201, Grad norm: 1.3530864312293818\n",
      "Epoch 2064, Loss: 210.16212583548256, Neurons: 201, Grad norm: 1.3530864312293818\n",
      "Epoch 2065, Loss: 210.16045382417343, Neurons: 201, Grad norm: 1.5280196734978007\n",
      "Epoch 2065, Loss: 210.16045382417343, Neurons: 201, Grad norm: 1.5280196734978007\n",
      "Epoch 2066, Loss: 210.1587746681241, Neurons: 201, Grad norm: 1.4605989982915275\n",
      "Epoch 2066, Loss: 210.1587746681241, Neurons: 201, Grad norm: 1.4605989982915275\n",
      "Epoch 2067, Loss: 210.15710790167032, Neurons: 201, Grad norm: 1.3836405908790497\n",
      "Epoch 2067, Loss: 210.15710790167032, Neurons: 201, Grad norm: 1.3836405908790497\n",
      "Epoch 2068, Loss: 210.155448139274, Neurons: 201, Grad norm: 1.7562594894364847\n",
      "Epoch 2068, Loss: 210.155448139274, Neurons: 201, Grad norm: 1.7562594894364847\n",
      "Epoch 2069, Loss: 210.15378090750312, Neurons: 201, Grad norm: 1.4168273134088587\n",
      "Epoch 2069, Loss: 210.15378090750312, Neurons: 201, Grad norm: 1.4168273134088587\n",
      "Epoch 2070, Loss: 210.15208699645189, Neurons: 201, Grad norm: 1.6679051954377284\n",
      "Epoch 2070, Loss: 210.15208699645189, Neurons: 201, Grad norm: 1.6679051954377284\n",
      "Epoch 2071, Loss: 210.15036289736733, Neurons: 201, Grad norm: 1.3501605773490617\n",
      "Epoch 2071, Loss: 210.15036289736733, Neurons: 201, Grad norm: 1.3501605773490617\n",
      "Epoch 2072, Loss: 210.1486461201826, Neurons: 201, Grad norm: 1.430326055660047\n",
      "Epoch 2072, Loss: 210.1486461201826, Neurons: 201, Grad norm: 1.430326055660047\n",
      "Epoch 2073, Loss: 210.14690882647767, Neurons: 201, Grad norm: 1.4397340850816873\n",
      "Epoch 2073, Loss: 210.14690882647767, Neurons: 201, Grad norm: 1.4397340850816873\n",
      "Epoch 2074, Loss: 210.1451658797908, Neurons: 201, Grad norm: 1.3877710386163655\n",
      "Epoch 2074, Loss: 210.1451658797908, Neurons: 201, Grad norm: 1.3877710386163655\n",
      "Epoch 2075, Loss: 210.1434482373266, Neurons: 201, Grad norm: 1.4681808173549613\n",
      "Epoch 2075, Loss: 210.1434482373266, Neurons: 201, Grad norm: 1.4681808173549613\n",
      "Epoch 2076, Loss: 210.14176426102662, Neurons: 201, Grad norm: 1.3696500064370862\n",
      "Epoch 2076, Loss: 210.14176426102662, Neurons: 201, Grad norm: 1.3696500064370862\n",
      "Epoch 2077, Loss: 210.14008459120012, Neurons: 201, Grad norm: 1.5001047887996777\n",
      "Epoch 2077, Loss: 210.14008459120012, Neurons: 201, Grad norm: 1.5001047887996777\n",
      "Epoch 2078, Loss: 210.1384692637214, Neurons: 201, Grad norm: 1.3581849249328097\n",
      "Epoch 2078, Loss: 210.1384692637214, Neurons: 201, Grad norm: 1.3581849249328097\n",
      "Epoch 2079, Loss: 210.13685718105395, Neurons: 201, Grad norm: 1.4838758024987013\n",
      "Epoch 2079, Loss: 210.13685718105395, Neurons: 201, Grad norm: 1.4838758024987013\n",
      "Epoch 2080, Loss: 210.1352214606768, Neurons: 201, Grad norm: 1.3884018584199092\n",
      "Epoch 2080, Loss: 210.1352214606768, Neurons: 201, Grad norm: 1.3884018584199092\n",
      "Epoch 2081, Loss: 210.13357764350465, Neurons: 201, Grad norm: 1.3666557521832354\n",
      "Epoch 2081, Loss: 210.13357764350465, Neurons: 201, Grad norm: 1.3666557521832354\n",
      "Epoch 2082, Loss: 210.13194756040494, Neurons: 201, Grad norm: 1.4705311288899097\n",
      "Epoch 2082, Loss: 210.13194756040494, Neurons: 201, Grad norm: 1.4705311288899097\n",
      "Epoch 2083, Loss: 210.13028202559278, Neurons: 201, Grad norm: 1.3773253159392358\n",
      "Epoch 2083, Loss: 210.13028202559278, Neurons: 201, Grad norm: 1.3773253159392358\n",
      "Epoch 2084, Loss: 210.12864057181508, Neurons: 201, Grad norm: 1.4863027094829329\n",
      "Epoch 2084, Loss: 210.12864057181508, Neurons: 201, Grad norm: 1.4863027094829329\n",
      "Epoch 2085, Loss: 210.1270032903894, Neurons: 201, Grad norm: 1.3351259496196253\n",
      "Epoch 2085, Loss: 210.1270032903894, Neurons: 201, Grad norm: 1.3351259496196253\n",
      "Epoch 2086, Loss: 210.1254134980234, Neurons: 201, Grad norm: 1.5389045394206333\n",
      "Epoch 2086, Loss: 210.1254134980234, Neurons: 201, Grad norm: 1.5389045394206333\n",
      "Epoch 2087, Loss: 210.12381148793978, Neurons: 201, Grad norm: 1.3471141595362708\n",
      "Epoch 2087, Loss: 210.12381148793978, Neurons: 201, Grad norm: 1.3471141595362708\n",
      "Epoch 2088, Loss: 210.12219313764328, Neurons: 201, Grad norm: 1.4353512744875176\n",
      "Epoch 2088, Loss: 210.12219313764328, Neurons: 201, Grad norm: 1.4353512744875176\n",
      "Epoch 2089, Loss: 210.1205942637299, Neurons: 201, Grad norm: 1.4773409654465117\n",
      "Epoch 2089, Loss: 210.1205942637299, Neurons: 201, Grad norm: 1.4773409654465117\n",
      "Epoch 2090, Loss: 210.11899277345387, Neurons: 201, Grad norm: 1.3775007013932574\n",
      "Epoch 2090, Loss: 210.11899277345387, Neurons: 201, Grad norm: 1.3775007013932574\n",
      "Epoch 2091, Loss: 210.1173934067163, Neurons: 201, Grad norm: 1.5452702727609389\n",
      "Epoch 2091, Loss: 210.1173934067163, Neurons: 201, Grad norm: 1.5452702727609389\n",
      "Epoch 2092, Loss: 210.11579201785324, Neurons: 201, Grad norm: 1.333001185192204\n",
      "Epoch 2092, Loss: 210.11579201785324, Neurons: 201, Grad norm: 1.333001185192204\n",
      "Epoch 2093, Loss: 210.11418009338465, Neurons: 201, Grad norm: 1.4160054190764344\n",
      "Epoch 2093, Loss: 210.11418009338465, Neurons: 201, Grad norm: 1.4160054190764344\n",
      "Epoch 2094, Loss: 210.11257992435768, Neurons: 201, Grad norm: 1.3242150785894362\n",
      "Epoch 2094, Loss: 210.11257992435768, Neurons: 201, Grad norm: 1.3242150785894362\n",
      "Epoch 2095, Loss: 210.1109906142239, Neurons: 201, Grad norm: 1.305004659952036\n",
      "Epoch 2095, Loss: 210.1109906142239, Neurons: 201, Grad norm: 1.305004659952036\n",
      "Epoch 2096, Loss: 210.10941097474526, Neurons: 201, Grad norm: 1.363079801170197\n",
      "Epoch 2096, Loss: 210.10941097474526, Neurons: 201, Grad norm: 1.363079801170197\n",
      "Epoch 2097, Loss: 210.10783554674316, Neurons: 201, Grad norm: 1.300816604712082\n",
      "Epoch 2097, Loss: 210.10783554674316, Neurons: 201, Grad norm: 1.300816604712082\n",
      "Epoch 2098, Loss: 210.1062584036748, Neurons: 201, Grad norm: 1.3558560265091288\n",
      "Epoch 2098, Loss: 210.1062584036748, Neurons: 201, Grad norm: 1.3558560265091288\n",
      "Epoch 2099, Loss: 210.10467790520718, Neurons: 201, Grad norm: 1.3701470352035965\n",
      "Epoch 2099, Loss: 210.10467790520718, Neurons: 201, Grad norm: 1.3701470352035965\n",
      "Epoch 2100, Loss: 210.10310252820824, Neurons: 201, Grad norm: 1.2812783394258138\n",
      "Epoch 2100, Loss: 210.10310252820824, Neurons: 201, Grad norm: 1.2812783394258138\n",
      "Epoch 2101, Loss: 210.1015353777003, Neurons: 201, Grad norm: 1.4552211004935238\n",
      "Epoch 2101, Loss: 210.1015353777003, Neurons: 201, Grad norm: 1.4552211004935238\n",
      "Epoch 2102, Loss: 210.09997358256257, Neurons: 201, Grad norm: 1.28368629730424\n",
      "Epoch 2102, Loss: 210.09997358256257, Neurons: 201, Grad norm: 1.28368629730424\n",
      "Epoch 2103, Loss: 210.09841110205335, Neurons: 201, Grad norm: 1.4400623060627689\n",
      "Epoch 2103, Loss: 210.09841110205335, Neurons: 201, Grad norm: 1.4400623060627689\n",
      "Epoch 2104, Loss: 210.09684462124633, Neurons: 201, Grad norm: 1.295200465854181\n",
      "Epoch 2104, Loss: 210.09684462124633, Neurons: 201, Grad norm: 1.295200465854181\n",
      "Epoch 2105, Loss: 210.09527815120452, Neurons: 201, Grad norm: 1.4295349847472534\n",
      "Epoch 2105, Loss: 210.09527815120452, Neurons: 201, Grad norm: 1.4295349847472534\n",
      "Epoch 2106, Loss: 210.09371357028894, Neurons: 201, Grad norm: 1.303996874013661\n",
      "Epoch 2106, Loss: 210.09371357028894, Neurons: 201, Grad norm: 1.303996874013661\n",
      "Epoch 2107, Loss: 210.09215319728256, Neurons: 201, Grad norm: 1.3743521646898715\n",
      "Epoch 2107, Loss: 210.09215319728256, Neurons: 201, Grad norm: 1.3743521646898715\n",
      "Epoch 2108, Loss: 210.09059676870086, Neurons: 201, Grad norm: 1.2830893978595694\n",
      "Epoch 2108, Loss: 210.09059676870086, Neurons: 201, Grad norm: 1.2830893978595694\n",
      "Epoch 2109, Loss: 210.0890484585404, Neurons: 201, Grad norm: 1.353764986248989\n",
      "Epoch 2109, Loss: 210.0890484585404, Neurons: 201, Grad norm: 1.353764986248989\n",
      "Epoch 2110, Loss: 210.08750227317933, Neurons: 201, Grad norm: 1.3163841963011735\n",
      "Epoch 2110, Loss: 210.08750227317933, Neurons: 201, Grad norm: 1.3163841963011735\n",
      "Epoch 2111, Loss: 210.0859493421189, Neurons: 201, Grad norm: 1.351357121238407\n",
      "Epoch 2111, Loss: 210.0859493421189, Neurons: 201, Grad norm: 1.351357121238407\n",
      "Epoch 2112, Loss: 210.0843976526007, Neurons: 201, Grad norm: 1.3722187610336136\n",
      "Epoch 2112, Loss: 210.0843976526007, Neurons: 201, Grad norm: 1.3722187610336136\n",
      "Epoch 2113, Loss: 210.08285776423344, Neurons: 201, Grad norm: 1.340537595169016\n",
      "Epoch 2113, Loss: 210.08285776423344, Neurons: 201, Grad norm: 1.340537595169016\n",
      "Epoch 2114, Loss: 210.08135521040788, Neurons: 201, Grad norm: 1.3422451364378163\n",
      "Epoch 2114, Loss: 210.08135521040788, Neurons: 201, Grad norm: 1.3422451364378163\n",
      "Epoch 2115, Loss: 210.07984236088066, Neurons: 201, Grad norm: 1.2705957958742202\n",
      "Epoch 2115, Loss: 210.07984236088066, Neurons: 201, Grad norm: 1.2705957958742202\n",
      "Epoch 2116, Loss: 210.07831805640794, Neurons: 201, Grad norm: 1.310665657708018\n",
      "Epoch 2116, Loss: 210.07831805640794, Neurons: 201, Grad norm: 1.310665657708018\n",
      "Epoch 2117, Loss: 210.07680402195257, Neurons: 201, Grad norm: 1.2737570417143376\n",
      "Epoch 2117, Loss: 210.07680402195257, Neurons: 201, Grad norm: 1.2737570417143376\n",
      "Epoch 2118, Loss: 210.0752743051663, Neurons: 201, Grad norm: 1.3246709239924679\n",
      "Epoch 2118, Loss: 210.0752743051663, Neurons: 201, Grad norm: 1.3246709239924679\n",
      "Epoch 2119, Loss: 210.07372650455972, Neurons: 201, Grad norm: 1.3462877686675074\n",
      "Epoch 2119, Loss: 210.07372650455972, Neurons: 201, Grad norm: 1.3462877686675074\n",
      "Epoch 2120, Loss: 210.07221331309665, Neurons: 201, Grad norm: 1.2719168823492377\n",
      "Epoch 2120, Loss: 210.07221331309665, Neurons: 201, Grad norm: 1.2719168823492377\n",
      "Epoch 2121, Loss: 210.0707100711289, Neurons: 201, Grad norm: 1.4473046198600754\n",
      "Epoch 2121, Loss: 210.0707100711289, Neurons: 201, Grad norm: 1.4473046198600754\n",
      "Epoch 2122, Loss: 210.06920202356756, Neurons: 201, Grad norm: 1.2718294554450187\n",
      "Epoch 2122, Loss: 210.06920202356756, Neurons: 201, Grad norm: 1.2718294554450187\n",
      "Epoch 2123, Loss: 210.06771072559457, Neurons: 201, Grad norm: 1.4730721436995755\n",
      "Epoch 2123, Loss: 210.06771072559457, Neurons: 201, Grad norm: 1.4730721436995755\n",
      "Epoch 2124, Loss: 210.0662215499844, Neurons: 201, Grad norm: 1.3216330213811678\n",
      "Epoch 2124, Loss: 210.0662215499844, Neurons: 201, Grad norm: 1.3216330213811678\n",
      "Epoch 2125, Loss: 210.0647663349583, Neurons: 201, Grad norm: 1.5396038074447826\n",
      "Epoch 2125, Loss: 210.0647663349583, Neurons: 201, Grad norm: 1.5396038074447826\n",
      "Epoch 2126, Loss: 210.0632776158181, Neurons: 201, Grad norm: 1.2818757344098075\n",
      "Epoch 2126, Loss: 210.0632776158181, Neurons: 201, Grad norm: 1.2818757344098075\n",
      "Epoch 2127, Loss: 210.06178188706863, Neurons: 201, Grad norm: 1.4354903483493133\n",
      "Epoch 2127, Loss: 210.06178188706863, Neurons: 201, Grad norm: 1.4354903483493133\n",
      "Epoch 2128, Loss: 210.06027067104452, Neurons: 201, Grad norm: 1.2454909919397177\n",
      "Epoch 2128, Loss: 210.06027067104452, Neurons: 201, Grad norm: 1.2454909919397177\n",
      "Epoch 2129, Loss: 210.05879803071304, Neurons: 201, Grad norm: 1.2730150868003727\n",
      "Epoch 2129, Loss: 210.05879803071304, Neurons: 201, Grad norm: 1.2730150868003727\n",
      "Epoch 2130, Loss: 210.0573337269893, Neurons: 201, Grad norm: 1.3035246833584857\n",
      "Epoch 2130, Loss: 210.0573337269893, Neurons: 201, Grad norm: 1.3035246833584857\n",
      "Epoch 2131, Loss: 210.0559015492907, Neurons: 201, Grad norm: 1.2094302700233714\n",
      "Epoch 2131, Loss: 210.0559015492907, Neurons: 201, Grad norm: 1.2094302700233714\n",
      "Epoch 2132, Loss: 210.05446163985542, Neurons: 201, Grad norm: 1.4258890655828738\n",
      "Epoch 2132, Loss: 210.05446163985542, Neurons: 201, Grad norm: 1.4258890655828738\n",
      "Epoch 2133, Loss: 210.05299906442954, Neurons: 201, Grad norm: 1.2488335154935257\n",
      "Epoch 2133, Loss: 210.05299906442954, Neurons: 201, Grad norm: 1.2488335154935257\n",
      "Epoch 2134, Loss: 210.0515236780785, Neurons: 201, Grad norm: 1.548572707340737\n",
      "Epoch 2134, Loss: 210.0515236780785, Neurons: 201, Grad norm: 1.548572707340737\n",
      "Epoch 2135, Loss: 210.0500698899951, Neurons: 201, Grad norm: 1.24625522394278\n",
      "Epoch 2135, Loss: 210.0500698899951, Neurons: 201, Grad norm: 1.24625522394278\n",
      "Epoch 2136, Loss: 210.04862032903787, Neurons: 201, Grad norm: 1.5035207597137212\n",
      "Epoch 2136, Loss: 210.04862032903787, Neurons: 201, Grad norm: 1.5035207597137212\n",
      "Epoch 2137, Loss: 210.0471645999216, Neurons: 201, Grad norm: 1.2568383083462518\n",
      "Epoch 2137, Loss: 210.0471645999216, Neurons: 201, Grad norm: 1.2568383083462518\n",
      "Epoch 2138, Loss: 210.0457368013402, Neurons: 201, Grad norm: 1.4358436845221823\n",
      "Epoch 2138, Loss: 210.0457368013402, Neurons: 201, Grad norm: 1.4358436845221823\n",
      "Epoch 2139, Loss: 210.04430098832842, Neurons: 201, Grad norm: 1.228046971545411\n",
      "Epoch 2139, Loss: 210.04430098832842, Neurons: 201, Grad norm: 1.228046971545411\n",
      "Epoch 2140, Loss: 210.04285203481282, Neurons: 201, Grad norm: 1.2926813657364606\n",
      "Epoch 2140, Loss: 210.04285203481282, Neurons: 201, Grad norm: 1.2926813657364606\n",
      "Epoch 2141, Loss: 210.04138989581966, Neurons: 201, Grad norm: 1.2827047403796785\n",
      "Epoch 2141, Loss: 210.04138989581966, Neurons: 201, Grad norm: 1.2827047403796785\n",
      "Epoch 2142, Loss: 210.0399191427148, Neurons: 201, Grad norm: 1.2192590469865363\n",
      "Epoch 2142, Loss: 210.0399191427148, Neurons: 201, Grad norm: 1.2192590469865363\n",
      "Epoch 2143, Loss: 210.038460114686, Neurons: 201, Grad norm: 1.2533823076760156\n",
      "Epoch 2143, Loss: 210.038460114686, Neurons: 201, Grad norm: 1.2533823076760156\n",
      "Epoch 2144, Loss: 210.0369948332635, Neurons: 201, Grad norm: 1.2506662857122668\n",
      "Epoch 2144, Loss: 210.0369948332635, Neurons: 201, Grad norm: 1.2506662857122668\n",
      "Epoch 2145, Loss: 210.0355362188343, Neurons: 201, Grad norm: 1.2268994372741495\n",
      "Epoch 2145, Loss: 210.0355362188343, Neurons: 201, Grad norm: 1.2268994372741495\n",
      "Epoch 2146, Loss: 210.03408107471157, Neurons: 201, Grad norm: 1.274840080131591\n",
      "Epoch 2146, Loss: 210.03408107471157, Neurons: 201, Grad norm: 1.274840080131591\n",
      "Epoch 2147, Loss: 210.0326311589576, Neurons: 201, Grad norm: 1.1891039024461416\n",
      "Epoch 2147, Loss: 210.0326311589576, Neurons: 201, Grad norm: 1.1891039024461416\n",
      "Epoch 2148, Loss: 210.03118128838662, Neurons: 201, Grad norm: 1.3853638968897728\n",
      "Epoch 2148, Loss: 210.03118128838662, Neurons: 201, Grad norm: 1.3853638968897728\n",
      "Epoch 2149, Loss: 210.02972422491337, Neurons: 201, Grad norm: 1.2146575665216743\n",
      "Epoch 2149, Loss: 210.02972422491337, Neurons: 201, Grad norm: 1.2146575665216743\n",
      "Epoch 2150, Loss: 210.02827280318965, Neurons: 201, Grad norm: 1.5055615693630018\n",
      "Epoch 2150, Loss: 210.02827280318965, Neurons: 201, Grad norm: 1.5055615693630018\n",
      "Epoch 2151, Loss: 210.02682003857902, Neurons: 201, Grad norm: 1.2898986099602572\n",
      "Epoch 2151, Loss: 210.02682003857902, Neurons: 201, Grad norm: 1.2898986099602572\n",
      "Epoch 2152, Loss: 210.025336082951, Neurons: 201, Grad norm: 1.6767718502921969\n",
      "Epoch 2152, Loss: 210.025336082951, Neurons: 201, Grad norm: 1.6767718502921969\n",
      "Epoch 2153, Loss: 210.02385521789984, Neurons: 201, Grad norm: 1.5543296692324877\n",
      "Epoch 2153, Loss: 210.02385521789984, Neurons: 201, Grad norm: 1.5543296692324877\n",
      "Epoch 2154, Loss: 210.02237306331884, Neurons: 201, Grad norm: 2.1184188362179492\n",
      "Epoch 2154, Loss: 210.02237306331884, Neurons: 201, Grad norm: 2.1184188362179492\n",
      "Epoch 2155, Loss: 210.0208524861581, Neurons: 201, Grad norm: 2.1087160053607388\n",
      "Epoch 2155, Loss: 210.0208524861581, Neurons: 201, Grad norm: 2.1087160053607388\n",
      "Epoch 2156, Loss: 210.01939599825698, Neurons: 201, Grad norm: 2.806364895741153\n",
      "Epoch 2156, Loss: 210.01939599825698, Neurons: 201, Grad norm: 2.806364895741153\n",
      "Epoch 2157, Loss: 210.01795493605385, Neurons: 201, Grad norm: 2.244315349344724\n",
      "Epoch 2157, Loss: 210.01795493605385, Neurons: 201, Grad norm: 2.244315349344724\n",
      "Epoch 2158, Loss: 210.01647106534173, Neurons: 201, Grad norm: 2.261998019283018\n",
      "Epoch 2158, Loss: 210.01647106534173, Neurons: 201, Grad norm: 2.261998019283018\n",
      "Epoch 2159, Loss: 210.01490401172833, Neurons: 201, Grad norm: 1.2383754803655649\n",
      "Epoch 2159, Loss: 210.01490401172833, Neurons: 201, Grad norm: 1.2383754803655649\n",
      "Epoch 2160, Loss: 210.01338198185013, Neurons: 201, Grad norm: 1.3636116367055844\n",
      "Epoch 2160, Loss: 210.01338198185013, Neurons: 201, Grad norm: 1.3636116367055844\n",
      "Epoch 2161, Loss: 210.0119806902759, Neurons: 201, Grad norm: 2.470728698872663\n",
      "Epoch 2161, Loss: 210.0119806902759, Neurons: 201, Grad norm: 2.470728698872663\n",
      "Epoch 2162, Loss: 210.01068320559685, Neurons: 201, Grad norm: 1.9844346938437512\n",
      "Epoch 2162, Loss: 210.01068320559685, Neurons: 201, Grad norm: 1.9844346938437512\n",
      "Epoch 2163, Loss: 210.00933040528375, Neurons: 201, Grad norm: 2.0036738764115607\n",
      "Epoch 2163, Loss: 210.00933040528375, Neurons: 201, Grad norm: 2.0036738764115607\n",
      "Epoch 2164, Loss: 210.00783932846818, Neurons: 201, Grad norm: 1.3459724894593774\n",
      "Epoch 2164, Loss: 210.00783932846818, Neurons: 201, Grad norm: 1.3459724894593774\n",
      "Epoch 2165, Loss: 210.0063604083664, Neurons: 201, Grad norm: 1.3199385082013186\n",
      "Epoch 2165, Loss: 210.0063604083664, Neurons: 201, Grad norm: 1.3199385082013186\n",
      "Epoch 2166, Loss: 210.00497505545212, Neurons: 201, Grad norm: 2.0654387733600466\n",
      "Epoch 2166, Loss: 210.00497505545212, Neurons: 201, Grad norm: 2.0654387733600466\n",
      "Epoch 2167, Loss: 210.00364731353105, Neurons: 201, Grad norm: 1.7222210544284366\n",
      "Epoch 2167, Loss: 210.00364731353105, Neurons: 201, Grad norm: 1.7222210544284366\n",
      "Epoch 2168, Loss: 210.00225837386583, Neurons: 201, Grad norm: 1.7795866954231563\n",
      "Epoch 2168, Loss: 210.00225837386583, Neurons: 201, Grad norm: 1.7795866954231563\n",
      "Epoch 2169, Loss: 210.00082435915908, Neurons: 201, Grad norm: 1.222237120975899\n",
      "Epoch 2169, Loss: 210.00082435915908, Neurons: 201, Grad norm: 1.222237120975899\n",
      "Epoch 2170, Loss: 209.9994055986853, Neurons: 201, Grad norm: 1.1884562999237918\n",
      "Epoch 2170, Loss: 209.9994055986853, Neurons: 201, Grad norm: 1.1884562999237918\n",
      "Epoch 2171, Loss: 209.99802559080726, Neurons: 201, Grad norm: 1.6622393897586656\n",
      "Epoch 2171, Loss: 209.99802559080726, Neurons: 201, Grad norm: 1.6622393897586656\n",
      "Epoch 2172, Loss: 209.99665682024892, Neurons: 201, Grad norm: 1.357968443487559\n",
      "Epoch 2172, Loss: 209.99665682024892, Neurons: 201, Grad norm: 1.357968443487559\n",
      "Epoch 2173, Loss: 209.9952595273719, Neurons: 201, Grad norm: 1.3927697045563403\n",
      "Epoch 2173, Loss: 209.9952595273719, Neurons: 201, Grad norm: 1.3927697045563403\n",
      "Epoch 2174, Loss: 209.9938373555066, Neurons: 201, Grad norm: 1.2454860506262013\n",
      "Epoch 2174, Loss: 209.9938373555066, Neurons: 201, Grad norm: 1.2454860506262013\n",
      "Epoch 2175, Loss: 209.9924392495527, Neurons: 201, Grad norm: 1.2007387571220645\n",
      "Epoch 2175, Loss: 209.9924392495527, Neurons: 201, Grad norm: 1.2007387571220645\n",
      "Epoch 2176, Loss: 209.99106341261356, Neurons: 201, Grad norm: 1.455621137320343\n",
      "Epoch 2176, Loss: 209.99106341261356, Neurons: 201, Grad norm: 1.455621137320343\n",
      "Epoch 2177, Loss: 209.98968756800943, Neurons: 201, Grad norm: 1.2454477644649973\n",
      "Epoch 2177, Loss: 209.98968756800943, Neurons: 201, Grad norm: 1.2454477644649973\n",
      "Epoch 2178, Loss: 209.98831673656127, Neurons: 201, Grad norm: 1.286879679846299\n",
      "Epoch 2178, Loss: 209.98831673656127, Neurons: 201, Grad norm: 1.286879679846299\n",
      "Epoch 2179, Loss: 209.98693304709795, Neurons: 201, Grad norm: 1.331837338390789\n",
      "Epoch 2179, Loss: 209.98693304709795, Neurons: 201, Grad norm: 1.331837338390789\n",
      "Epoch 2180, Loss: 209.98556530510422, Neurons: 201, Grad norm: 1.2180477492089077\n",
      "Epoch 2180, Loss: 209.98556530510422, Neurons: 201, Grad norm: 1.2180477492089077\n",
      "Epoch 2181, Loss: 209.9842019202378, Neurons: 201, Grad norm: 1.506331516291853\n",
      "Epoch 2181, Loss: 209.9842019202378, Neurons: 201, Grad norm: 1.506331516291853\n",
      "Epoch 2182, Loss: 209.98284659017258, Neurons: 201, Grad norm: 1.1980662175409313\n",
      "Epoch 2182, Loss: 209.98284659017258, Neurons: 201, Grad norm: 1.1980662175409313\n",
      "Epoch 2183, Loss: 209.9814751396967, Neurons: 201, Grad norm: 1.286596667648554\n",
      "Epoch 2183, Loss: 209.9814751396967, Neurons: 201, Grad norm: 1.286596667648554\n",
      "Epoch 2184, Loss: 209.98010806842072, Neurons: 201, Grad norm: 1.3160439937152497\n",
      "Epoch 2184, Loss: 209.98010806842072, Neurons: 201, Grad norm: 1.3160439937152497\n",
      "Epoch 2185, Loss: 209.9787458652623, Neurons: 201, Grad norm: 1.193344375404828\n",
      "Epoch 2185, Loss: 209.9787458652623, Neurons: 201, Grad norm: 1.193344375404828\n",
      "Epoch 2186, Loss: 209.97739209651903, Neurons: 201, Grad norm: 1.422758316150182\n",
      "Epoch 2186, Loss: 209.97739209651903, Neurons: 201, Grad norm: 1.422758316150182\n",
      "Epoch 2187, Loss: 209.97603945270026, Neurons: 201, Grad norm: 1.2234306385845328\n",
      "Epoch 2187, Loss: 209.97603945270026, Neurons: 201, Grad norm: 1.2234306385845328\n",
      "Epoch 2188, Loss: 209.9746928801633, Neurons: 201, Grad norm: 1.2848500055715693\n",
      "Epoch 2188, Loss: 209.9746928801633, Neurons: 201, Grad norm: 1.2848500055715693\n",
      "Epoch 2189, Loss: 209.97334885070248, Neurons: 201, Grad norm: 1.198962884102663\n",
      "Epoch 2189, Loss: 209.97334885070248, Neurons: 201, Grad norm: 1.198962884102663\n",
      "Epoch 2190, Loss: 209.97199650457466, Neurons: 201, Grad norm: 1.1917559196457357\n",
      "Epoch 2190, Loss: 209.97199650457466, Neurons: 201, Grad norm: 1.1917559196457357\n",
      "Epoch 2191, Loss: 209.97065396743665, Neurons: 201, Grad norm: 1.360865814290999\n",
      "Epoch 2191, Loss: 209.97065396743665, Neurons: 201, Grad norm: 1.360865814290999\n",
      "Epoch 2192, Loss: 209.96931731171006, Neurons: 201, Grad norm: 1.203281217465567\n",
      "Epoch 2192, Loss: 209.96931731171006, Neurons: 201, Grad norm: 1.203281217465567\n",
      "Epoch 2193, Loss: 209.967995049731, Neurons: 201, Grad norm: 1.4721386005237336\n",
      "Epoch 2193, Loss: 209.967995049731, Neurons: 201, Grad norm: 1.4721386005237336\n",
      "Epoch 2194, Loss: 209.96666289955436, Neurons: 201, Grad norm: 1.1956393532707845\n",
      "Epoch 2194, Loss: 209.96666289955436, Neurons: 201, Grad norm: 1.1956393532707845\n",
      "Epoch 2195, Loss: 209.9653234212884, Neurons: 201, Grad norm: 1.3226477752308456\n",
      "Epoch 2195, Loss: 209.9653234212884, Neurons: 201, Grad norm: 1.3226477752308456\n",
      "Epoch 2196, Loss: 209.96399023684998, Neurons: 201, Grad norm: 1.183157167235685\n",
      "Epoch 2196, Loss: 209.96399023684998, Neurons: 201, Grad norm: 1.183157167235685\n",
      "Epoch 2197, Loss: 209.9626640761249, Neurons: 201, Grad norm: 1.1606912124355142\n",
      "Epoch 2197, Loss: 209.9626640761249, Neurons: 201, Grad norm: 1.1606912124355142\n",
      "Epoch 2198, Loss: 209.9613468933119, Neurons: 201, Grad norm: 1.20867027583058\n",
      "Epoch 2198, Loss: 209.9613468933119, Neurons: 201, Grad norm: 1.20867027583058\n",
      "Epoch 2199, Loss: 209.96003091181825, Neurons: 201, Grad norm: 1.1560794651838355\n",
      "Epoch 2199, Loss: 209.96003091181825, Neurons: 201, Grad norm: 1.1560794651838355\n",
      "Epoch 2200, Loss: 209.95871294142452, Neurons: 201, Grad norm: 1.3244671685315133\n",
      "Epoch 2200, Loss: 209.95871294142452, Neurons: 201, Grad norm: 1.3244671685315133\n",
      "Epoch 2201, Loss: 209.95739719657624, Neurons: 201, Grad norm: 1.2232497216037028\n",
      "Epoch 2201, Loss: 209.95739719657624, Neurons: 201, Grad norm: 1.2232497216037028\n",
      "Epoch 2202, Loss: 209.95608851937317, Neurons: 201, Grad norm: 1.4472686538849093\n",
      "Epoch 2202, Loss: 209.95608851937317, Neurons: 201, Grad norm: 1.4472686538849093\n",
      "Epoch 2203, Loss: 209.95478194896097, Neurons: 201, Grad norm: 1.2019014855126826\n",
      "Epoch 2203, Loss: 209.95478194896097, Neurons: 201, Grad norm: 1.2019014855126826\n",
      "Epoch 2204, Loss: 209.95345608798797, Neurons: 201, Grad norm: 1.4417588071375338\n",
      "Epoch 2204, Loss: 209.95345608798797, Neurons: 201, Grad norm: 1.4417588071375338\n",
      "Epoch 2205, Loss: 209.95214093486615, Neurons: 201, Grad norm: 1.1712371734732236\n",
      "Epoch 2205, Loss: 209.95214093486615, Neurons: 201, Grad norm: 1.1712371734732236\n",
      "Epoch 2206, Loss: 209.95083452684517, Neurons: 201, Grad norm: 1.3762981011136928\n",
      "Epoch 2206, Loss: 209.95083452684517, Neurons: 201, Grad norm: 1.3762981011136928\n",
      "Epoch 2207, Loss: 209.94954172928632, Neurons: 201, Grad norm: 1.173115305373645\n",
      "Epoch 2207, Loss: 209.94954172928632, Neurons: 201, Grad norm: 1.173115305373645\n",
      "Epoch 2208, Loss: 209.94824885345494, Neurons: 201, Grad norm: 1.2125287151721316\n",
      "Epoch 2208, Loss: 209.94824885345494, Neurons: 201, Grad norm: 1.2125287151721316\n",
      "Epoch 2209, Loss: 209.9469416740783, Neurons: 201, Grad norm: 1.1888330290492681\n",
      "Epoch 2209, Loss: 209.9469416740783, Neurons: 201, Grad norm: 1.1888330290492681\n",
      "Epoch 2210, Loss: 209.94564214771736, Neurons: 201, Grad norm: 1.1377926591379584\n",
      "Epoch 2210, Loss: 209.94564214771736, Neurons: 201, Grad norm: 1.1377926591379584\n",
      "Epoch 2211, Loss: 209.94434987599635, Neurons: 201, Grad norm: 1.2775987254841752\n",
      "Epoch 2211, Loss: 209.94434987599635, Neurons: 201, Grad norm: 1.2775987254841752\n",
      "Epoch 2212, Loss: 209.94305011648174, Neurons: 201, Grad norm: 1.115200903895277\n",
      "Epoch 2212, Loss: 209.94305011648174, Neurons: 201, Grad norm: 1.115200903895277\n",
      "Epoch 2213, Loss: 209.94176443796462, Neurons: 201, Grad norm: 1.26460035080653\n",
      "Epoch 2213, Loss: 209.94176443796462, Neurons: 201, Grad norm: 1.26460035080653\n",
      "Epoch 2214, Loss: 209.9405014607296, Neurons: 201, Grad norm: 1.1994984482015365\n",
      "Epoch 2214, Loss: 209.9405014607296, Neurons: 201, Grad norm: 1.1994984482015365\n",
      "Epoch 2215, Loss: 209.9392390993277, Neurons: 201, Grad norm: 1.1860227179747285\n",
      "Epoch 2215, Loss: 209.9392390993277, Neurons: 201, Grad norm: 1.1860227179747285\n",
      "Epoch 2216, Loss: 209.937958073633, Neurons: 201, Grad norm: 1.0990439638158247\n",
      "Epoch 2216, Loss: 209.937958073633, Neurons: 201, Grad norm: 1.0990439638158247\n",
      "Epoch 2217, Loss: 209.93668033409892, Neurons: 201, Grad norm: 1.2094188667775956\n",
      "Epoch 2217, Loss: 209.93668033409892, Neurons: 201, Grad norm: 1.2094188667775956\n",
      "Epoch 2218, Loss: 209.9353986237942, Neurons: 201, Grad norm: 1.1635639262369184\n",
      "Epoch 2218, Loss: 209.9353986237942, Neurons: 201, Grad norm: 1.1635639262369184\n",
      "Epoch 2219, Loss: 209.93414087093055, Neurons: 201, Grad norm: 1.615032026283431\n",
      "Epoch 2219, Loss: 209.93414087093055, Neurons: 201, Grad norm: 1.615032026283431\n",
      "Epoch 2220, Loss: 209.93289262702905, Neurons: 201, Grad norm: 1.5777508544515344\n",
      "Epoch 2220, Loss: 209.93289262702905, Neurons: 201, Grad norm: 1.5777508544515344\n",
      "Epoch 2221, Loss: 209.93165876633702, Neurons: 201, Grad norm: 2.088398354600127\n",
      "Epoch 2221, Loss: 209.93165876633702, Neurons: 201, Grad norm: 2.088398354600127\n",
      "Epoch 2222, Loss: 209.93043054968416, Neurons: 201, Grad norm: 1.7368303783832348\n",
      "Epoch 2222, Loss: 209.93043054968416, Neurons: 201, Grad norm: 1.7368303783832348\n",
      "Epoch 2223, Loss: 209.929178530895, Neurons: 201, Grad norm: 2.01079801181905\n",
      "Epoch 2223, Loss: 209.929178530895, Neurons: 201, Grad norm: 2.01079801181905\n",
      "Epoch 2224, Loss: 209.92788839956523, Neurons: 201, Grad norm: 1.5449695313195968\n",
      "Epoch 2224, Loss: 209.92788839956523, Neurons: 201, Grad norm: 1.5449695313195968\n",
      "Epoch 2225, Loss: 209.92660470375267, Neurons: 201, Grad norm: 1.6712475660015762\n",
      "Epoch 2225, Loss: 209.92660470375267, Neurons: 201, Grad norm: 1.6712475660015762\n",
      "Epoch 2226, Loss: 209.92533868353402, Neurons: 201, Grad norm: 1.1408879166951904\n",
      "Epoch 2226, Loss: 209.92533868353402, Neurons: 201, Grad norm: 1.1408879166951904\n",
      "Epoch 2227, Loss: 209.9240764181443, Neurons: 201, Grad norm: 1.1652904509081232\n",
      "Epoch 2227, Loss: 209.9240764181443, Neurons: 201, Grad norm: 1.1652904509081232\n",
      "Epoch 2228, Loss: 209.9228121278641, Neurons: 201, Grad norm: 1.4314977410920264\n",
      "Epoch 2228, Loss: 209.9228121278641, Neurons: 201, Grad norm: 1.4314977410920264\n",
      "Epoch 2229, Loss: 209.9215787094892, Neurons: 201, Grad norm: 1.6169936751096283\n",
      "Epoch 2229, Loss: 209.9215787094892, Neurons: 201, Grad norm: 1.6169936751096283\n",
      "Epoch 2230, Loss: 209.92039520403787, Neurons: 201, Grad norm: 2.4102284979699853\n",
      "Epoch 2230, Loss: 209.92039520403787, Neurons: 201, Grad norm: 2.4102284979699853\n",
      "Epoch 2231, Loss: 209.91923789676682, Neurons: 201, Grad norm: 2.080155445184798\n",
      "Epoch 2231, Loss: 209.91923789676682, Neurons: 201, Grad norm: 2.080155445184798\n",
      "Epoch 2232, Loss: 209.91802826371887, Neurons: 201, Grad norm: 2.2644762950341146\n",
      "Epoch 2232, Loss: 209.91802826371887, Neurons: 201, Grad norm: 2.2644762950341146\n",
      "Epoch 2233, Loss: 209.91676794974998, Neurons: 201, Grad norm: 1.4169556719231404\n",
      "Epoch 2233, Loss: 209.91676794974998, Neurons: 201, Grad norm: 1.4169556719231404\n",
      "Epoch 2234, Loss: 209.91547217016827, Neurons: 201, Grad norm: 1.1857013007142554\n",
      "Epoch 2234, Loss: 209.91547217016827, Neurons: 201, Grad norm: 1.1857013007142554\n",
      "Epoch 2235, Loss: 209.91421325245116, Neurons: 201, Grad norm: 1.4419371020399476\n",
      "Epoch 2235, Loss: 209.91421325245116, Neurons: 201, Grad norm: 1.4419371020399476\n",
      "Epoch 2236, Loss: 209.9130290419532, Neurons: 201, Grad norm: 1.5454272539215483\n",
      "Epoch 2236, Loss: 209.9130290419532, Neurons: 201, Grad norm: 1.5454272539215483\n",
      "Epoch 2237, Loss: 209.91189311953943, Neurons: 201, Grad norm: 2.07425411163754\n",
      "Epoch 2237, Loss: 209.91189311953943, Neurons: 201, Grad norm: 2.07425411163754\n",
      "Epoch 2238, Loss: 209.91072560345094, Neurons: 201, Grad norm: 1.5945705324058983\n",
      "Epoch 2238, Loss: 209.91072560345094, Neurons: 201, Grad norm: 1.5945705324058983\n",
      "Epoch 2239, Loss: 209.90950430006683, Neurons: 201, Grad norm: 1.5008037592583077\n",
      "Epoch 2239, Loss: 209.90950430006683, Neurons: 201, Grad norm: 1.5008037592583077\n",
      "Epoch 2240, Loss: 209.90825501578976, Neurons: 201, Grad norm: 1.112854462604392\n",
      "Epoch 2240, Loss: 209.90825501578976, Neurons: 201, Grad norm: 1.112854462604392\n",
      "Epoch 2241, Loss: 209.90704626924142, Neurons: 201, Grad norm: 1.1030792562177918\n",
      "Epoch 2241, Loss: 209.90704626924142, Neurons: 201, Grad norm: 1.1030792562177918\n",
      "Epoch 2242, Loss: 209.90587610330255, Neurons: 201, Grad norm: 1.6033275683653094\n",
      "Epoch 2242, Loss: 209.90587610330255, Neurons: 201, Grad norm: 1.6033275683653094\n",
      "Epoch 2243, Loss: 209.9047092565224, Neurons: 201, Grad norm: 1.4555735057810797\n",
      "Epoch 2243, Loss: 209.9047092565224, Neurons: 201, Grad norm: 1.4555735057810797\n",
      "Epoch 2244, Loss: 209.90355068389718, Neurons: 201, Grad norm: 1.7045238527227986\n",
      "Epoch 2244, Loss: 209.90355068389718, Neurons: 201, Grad norm: 1.7045238527227986\n",
      "Epoch 2245, Loss: 209.90236797122384, Neurons: 201, Grad norm: 1.2941963099149398\n",
      "Epoch 2245, Loss: 209.90236797122384, Neurons: 201, Grad norm: 1.2941963099149398\n",
      "Epoch 2246, Loss: 209.90116659471192, Neurons: 201, Grad norm: 1.2954509995249759\n",
      "Epoch 2246, Loss: 209.90116659471192, Neurons: 201, Grad norm: 1.2954509995249759\n",
      "Epoch 2247, Loss: 209.8999878344968, Neurons: 201, Grad norm: 1.0968017522248408\n",
      "Epoch 2247, Loss: 209.8999878344968, Neurons: 201, Grad norm: 1.0968017522248408\n",
      "Epoch 2248, Loss: 209.89880481786994, Neurons: 201, Grad norm: 1.1153975504312192\n",
      "Epoch 2248, Loss: 209.89880481786994, Neurons: 201, Grad norm: 1.1153975504312192\n",
      "Epoch 2249, Loss: 209.89764731736818, Neurons: 201, Grad norm: 1.6878039220753225\n",
      "Epoch 2249, Loss: 209.89764731736818, Neurons: 201, Grad norm: 1.6878039220753225\n",
      "Epoch 2250, Loss: 209.89650318989786, Neurons: 201, Grad norm: 1.4436346993845461\n",
      "Epoch 2250, Loss: 209.89650318989786, Neurons: 201, Grad norm: 1.4436346993845461\n",
      "Epoch 2251, Loss: 209.89536580141677, Neurons: 201, Grad norm: 1.5946407792779624\n",
      "Epoch 2251, Loss: 209.89536580141677, Neurons: 201, Grad norm: 1.5946407792779624\n",
      "Epoch 2252, Loss: 209.89418376832543, Neurons: 201, Grad norm: 1.1246241077415233\n",
      "Epoch 2252, Loss: 209.89418376832543, Neurons: 201, Grad norm: 1.1246241077415233\n",
      "Epoch 2253, Loss: 209.89298632961533, Neurons: 201, Grad norm: 1.0829607251978475\n",
      "Epoch 2253, Loss: 209.89298632961533, Neurons: 201, Grad norm: 1.0829607251978475\n",
      "Epoch 2254, Loss: 209.89182234496332, Neurons: 201, Grad norm: 1.3704079855976508\n",
      "Epoch 2254, Loss: 209.89182234496332, Neurons: 201, Grad norm: 1.3704079855976508\n",
      "Epoch 2255, Loss: 209.89067151773344, Neurons: 201, Grad norm: 1.302479600457104\n",
      "Epoch 2255, Loss: 209.89067151773344, Neurons: 201, Grad norm: 1.302479600457104\n",
      "Epoch 2256, Loss: 209.8895151533391, Neurons: 201, Grad norm: 1.6581490065268432\n",
      "Epoch 2256, Loss: 209.8895151533391, Neurons: 201, Grad norm: 1.6581490065268432\n",
      "Epoch 2257, Loss: 209.88836850997745, Neurons: 201, Grad norm: 1.234449360693537\n",
      "Epoch 2257, Loss: 209.88836850997745, Neurons: 201, Grad norm: 1.234449360693537\n",
      "Epoch 2258, Loss: 209.88721363597045, Neurons: 201, Grad norm: 1.301025118527317\n",
      "Epoch 2258, Loss: 209.88721363597045, Neurons: 201, Grad norm: 1.301025118527317\n",
      "Epoch 2259, Loss: 209.88603786081313, Neurons: 201, Grad norm: 1.1112380514567668\n",
      "Epoch 2259, Loss: 209.88603786081313, Neurons: 201, Grad norm: 1.1112380514567668\n",
      "Epoch 2260, Loss: 209.88489016656308, Neurons: 201, Grad norm: 1.1179823668497753\n",
      "Epoch 2260, Loss: 209.88489016656308, Neurons: 201, Grad norm: 1.1179823668497753\n",
      "Epoch 2261, Loss: 209.8837390004624, Neurons: 201, Grad norm: 1.4427530275312517\n",
      "Epoch 2261, Loss: 209.8837390004624, Neurons: 201, Grad norm: 1.4427530275312517\n",
      "Epoch 2262, Loss: 209.88261523074777, Neurons: 201, Grad norm: 1.4694706366664738\n",
      "Epoch 2262, Loss: 209.88261523074777, Neurons: 201, Grad norm: 1.4694706366664738\n",
      "Epoch 2263, Loss: 209.88152264660218, Neurons: 201, Grad norm: 2.183694785363902\n",
      "Epoch 2263, Loss: 209.88152264660218, Neurons: 201, Grad norm: 2.183694785363902\n",
      "Epoch 2264, Loss: 209.88044475362645, Neurons: 201, Grad norm: 1.8888267081388992\n",
      "Epoch 2264, Loss: 209.88044475362645, Neurons: 201, Grad norm: 1.8888267081388992\n",
      "Epoch 2265, Loss: 209.8793423328714, Neurons: 201, Grad norm: 2.1153735580462416\n",
      "Epoch 2265, Loss: 209.8793423328714, Neurons: 201, Grad norm: 2.1153735580462416\n",
      "Epoch 2266, Loss: 209.87817684260227, Neurons: 201, Grad norm: 1.3571853631036672\n",
      "Epoch 2266, Loss: 209.87817684260227, Neurons: 201, Grad norm: 1.3571853631036672\n",
      "Epoch 2267, Loss: 209.87697289514145, Neurons: 201, Grad norm: 1.131268079121489\n",
      "Epoch 2267, Loss: 209.87697289514145, Neurons: 201, Grad norm: 1.131268079121489\n",
      "Epoch 2268, Loss: 209.87578273789143, Neurons: 201, Grad norm: 1.2873182180170446\n",
      "Epoch 2268, Loss: 209.87578273789143, Neurons: 201, Grad norm: 1.2873182180170446\n",
      "Epoch 2269, Loss: 209.87464766982282, Neurons: 201, Grad norm: 1.5191239899143292\n",
      "Epoch 2269, Loss: 209.87464766982282, Neurons: 201, Grad norm: 1.5191239899143292\n",
      "Epoch 2270, Loss: 209.87356115627145, Neurons: 201, Grad norm: 2.2939438569518353\n",
      "Epoch 2270, Loss: 209.87356115627145, Neurons: 201, Grad norm: 2.2939438569518353\n",
      "Epoch 2271, Loss: 209.87247074823432, Neurons: 201, Grad norm: 1.9186900739506367\n",
      "Epoch 2271, Loss: 209.87247074823432, Neurons: 201, Grad norm: 1.9186900739506367\n",
      "Epoch 2272, Loss: 209.87131013995216, Neurons: 201, Grad norm: 1.976078268275698\n",
      "Epoch 2272, Loss: 209.87131013995216, Neurons: 201, Grad norm: 1.976078268275698\n",
      "Epoch 2273, Loss: 209.87010183268953, Neurons: 201, Grad norm: 1.1058102510982675\n",
      "Epoch 2273, Loss: 209.87010183268953, Neurons: 201, Grad norm: 1.1058102510982675\n",
      "Epoch 2274, Loss: 209.86889551747146, Neurons: 201, Grad norm: 1.0428174467275886\n",
      "Epoch 2274, Loss: 209.86889551747146, Neurons: 201, Grad norm: 1.0428174467275886\n",
      "Epoch 2275, Loss: 209.86772622200752, Neurons: 201, Grad norm: 1.7397437456009346\n",
      "Epoch 2275, Loss: 209.86772622200752, Neurons: 201, Grad norm: 1.7397437456009346\n",
      "Epoch 2276, Loss: 209.86662084717733, Neurons: 201, Grad norm: 1.8009702086224981\n",
      "Epoch 2276, Loss: 209.86662084717733, Neurons: 201, Grad norm: 1.8009702086224981\n",
      "Epoch 2277, Loss: 209.86554144689504, Neurons: 201, Grad norm: 2.153803736225514\n",
      "Epoch 2277, Loss: 209.86554144689504, Neurons: 201, Grad norm: 2.153803736225514\n",
      "Epoch 2278, Loss: 209.86443655545068, Neurons: 201, Grad norm: 1.4002175823041896\n",
      "Epoch 2278, Loss: 209.86443655545068, Neurons: 201, Grad norm: 1.4002175823041896\n",
      "Epoch 2279, Loss: 209.86328629872904, Neurons: 201, Grad norm: 1.159768897328196\n",
      "Epoch 2279, Loss: 209.86328629872904, Neurons: 201, Grad norm: 1.159768897328196\n",
      "Epoch 2280, Loss: 209.862147477259, Neurons: 201, Grad norm: 1.3152792912708318\n",
      "Epoch 2280, Loss: 209.862147477259, Neurons: 201, Grad norm: 1.3152792912708318\n",
      "Epoch 2281, Loss: 209.86106535902732, Neurons: 201, Grad norm: 1.530459343303302\n",
      "Epoch 2281, Loss: 209.86106535902732, Neurons: 201, Grad norm: 1.530459343303302\n",
      "Epoch 2282, Loss: 209.86001546252365, Neurons: 201, Grad norm: 2.217139317083691\n",
      "Epoch 2282, Loss: 209.86001546252365, Neurons: 201, Grad norm: 2.217139317083691\n",
      "Epoch 2283, Loss: 209.85897361004425, Neurons: 201, Grad norm: 1.734496596540036\n",
      "Epoch 2283, Loss: 209.85897361004425, Neurons: 201, Grad norm: 1.734496596540036\n",
      "Epoch 2284, Loss: 209.85787386920381, Neurons: 201, Grad norm: 1.6884242489415229\n",
      "Epoch 2284, Loss: 209.85787386920381, Neurons: 201, Grad norm: 1.6884242489415229\n",
      "Epoch 2285, Loss: 209.85671771937368, Neurons: 201, Grad norm: 1.0861649178826234\n",
      "Epoch 2285, Loss: 209.85671771937368, Neurons: 201, Grad norm: 1.0861649178826234\n",
      "Epoch 2286, Loss: 209.85557567175022, Neurons: 201, Grad norm: 1.0434343231678838\n",
      "Epoch 2286, Loss: 209.85557567175022, Neurons: 201, Grad norm: 1.0434343231678838\n",
      "Epoch 2287, Loss: 209.8544692539277, Neurons: 201, Grad norm: 1.525895624392385\n",
      "Epoch 2287, Loss: 209.8544692539277, Neurons: 201, Grad norm: 1.525895624392385\n",
      "Epoch 2288, Loss: 209.8533919719694, Neurons: 201, Grad norm: 1.5435702944320022\n",
      "Epoch 2288, Loss: 209.8533919719694, Neurons: 201, Grad norm: 1.5435702944320022\n",
      "Epoch 2289, Loss: 209.85232905592554, Neurons: 201, Grad norm: 2.1109572283675435\n",
      "Epoch 2289, Loss: 209.85232905592554, Neurons: 201, Grad norm: 2.1109572283675435\n",
      "Epoch 2290, Loss: 209.85124252093536, Neurons: 201, Grad norm: 1.7396145666332772\n",
      "Epoch 2290, Loss: 209.85124252093536, Neurons: 201, Grad norm: 1.7396145666332772\n",
      "Epoch 2291, Loss: 209.85015139763192, Neurons: 201, Grad norm: 1.8880175733451814\n",
      "Epoch 2291, Loss: 209.85015139763192, Neurons: 201, Grad norm: 1.8880175733451814\n",
      "Epoch 2292, Loss: 209.8490275790345, Neurons: 201, Grad norm: 1.2590896591541818\n",
      "Epoch 2292, Loss: 209.8490275790345, Neurons: 201, Grad norm: 1.2590896591541818\n",
      "Epoch 2293, Loss: 209.84789078612238, Neurons: 201, Grad norm: 1.1927593919426283\n",
      "Epoch 2293, Loss: 209.84789078612238, Neurons: 201, Grad norm: 1.1927593919426283\n",
      "Epoch 2294, Loss: 209.84678719028244, Neurons: 201, Grad norm: 1.1246787505163913\n",
      "Epoch 2294, Loss: 209.84678719028244, Neurons: 201, Grad norm: 1.1246787505163913\n",
      "Epoch 2295, Loss: 209.84568618895395, Neurons: 201, Grad norm: 1.0786587018284912\n",
      "Epoch 2295, Loss: 209.84568618895395, Neurons: 201, Grad norm: 1.0786587018284912\n",
      "Epoch 2296, Loss: 209.84460276364283, Neurons: 201, Grad norm: 1.4189264466927\n",
      "Epoch 2296, Loss: 209.84460276364283, Neurons: 201, Grad norm: 1.4189264466927\n",
      "Epoch 2297, Loss: 209.84351056502283, Neurons: 201, Grad norm: 1.1971587936083448\n",
      "Epoch 2297, Loss: 209.84351056502283, Neurons: 201, Grad norm: 1.1971587936083448\n",
      "Epoch 2298, Loss: 209.8424134474047, Neurons: 201, Grad norm: 1.3291757181209034\n",
      "Epoch 2298, Loss: 209.8424134474047, Neurons: 201, Grad norm: 1.3291757181209034\n",
      "Epoch 2299, Loss: 209.84131560732473, Neurons: 201, Grad norm: 1.0472855351373427\n",
      "Epoch 2299, Loss: 209.84131560732473, Neurons: 201, Grad norm: 1.0472855351373427\n",
      "Epoch 2300, Loss: 209.840212655809, Neurons: 201, Grad norm: 1.0390434178049\n",
      "Epoch 2300, Loss: 209.840212655809, Neurons: 201, Grad norm: 1.0390434178049\n",
      "Epoch 2301, Loss: 209.8391357327023, Neurons: 201, Grad norm: 1.2694217790974185\n",
      "Epoch 2301, Loss: 209.8391357327023, Neurons: 201, Grad norm: 1.2694217790974185\n",
      "Epoch 2302, Loss: 209.83807483550598, Neurons: 201, Grad norm: 1.0744662790958217\n",
      "Epoch 2302, Loss: 209.83807483550598, Neurons: 201, Grad norm: 1.0744662790958217\n",
      "Epoch 2303, Loss: 209.83700738195566, Neurons: 201, Grad norm: 1.2040257489842154\n",
      "Epoch 2303, Loss: 209.83700738195566, Neurons: 201, Grad norm: 1.2040257489842154\n",
      "Epoch 2304, Loss: 209.83594159429632, Neurons: 201, Grad norm: 1.0360487750343086\n",
      "Epoch 2304, Loss: 209.83594159429632, Neurons: 201, Grad norm: 1.0360487750343086\n",
      "Epoch 2305, Loss: 209.8348827675319, Neurons: 201, Grad norm: 1.0838848216940145\n",
      "Epoch 2305, Loss: 209.8348827675319, Neurons: 201, Grad norm: 1.0838848216940145\n",
      "Epoch 2306, Loss: 209.83382926070428, Neurons: 201, Grad norm: 1.0963475557460696\n",
      "Epoch 2306, Loss: 209.83382926070428, Neurons: 201, Grad norm: 1.0963475557460696\n",
      "Epoch 2307, Loss: 209.83277981642746, Neurons: 201, Grad norm: 1.0532150025154587\n",
      "Epoch 2307, Loss: 209.83277981642746, Neurons: 201, Grad norm: 1.0532150025154587\n",
      "Epoch 2308, Loss: 209.83172854427104, Neurons: 201, Grad norm: 1.2054995741595875\n",
      "Epoch 2308, Loss: 209.83172854427104, Neurons: 201, Grad norm: 1.2054995741595875\n",
      "Epoch 2309, Loss: 209.8306909410744, Neurons: 201, Grad norm: 1.1026185695699873\n",
      "Epoch 2309, Loss: 209.8306909410744, Neurons: 201, Grad norm: 1.1026185695699873\n",
      "Epoch 2310, Loss: 209.82965725351391, Neurons: 201, Grad norm: 1.4329346671136598\n",
      "Epoch 2310, Loss: 209.82965725351391, Neurons: 201, Grad norm: 1.4329346671136598\n",
      "Epoch 2311, Loss: 209.8286164152221, Neurons: 201, Grad norm: 1.2716939349515974\n",
      "Epoch 2311, Loss: 209.8286164152221, Neurons: 201, Grad norm: 1.2716939349515974\n",
      "Epoch 2312, Loss: 209.82759125998058, Neurons: 201, Grad norm: 1.7312045599928154\n",
      "Epoch 2312, Loss: 209.82759125998058, Neurons: 201, Grad norm: 1.7312045599928154\n",
      "Epoch 2313, Loss: 209.8265738460038, Neurons: 201, Grad norm: 1.51291971706482\n",
      "Epoch 2313, Loss: 209.8265738460038, Neurons: 201, Grad norm: 1.51291971706482\n",
      "Epoch 2314, Loss: 209.8255539725461, Neurons: 201, Grad norm: 1.9972093366532597\n",
      "Epoch 2314, Loss: 209.8255539725461, Neurons: 201, Grad norm: 1.9972093366532597\n",
      "Epoch 2315, Loss: 209.8245392308362, Neurons: 201, Grad norm: 1.6292154995481494\n",
      "Epoch 2315, Loss: 209.8245392308362, Neurons: 201, Grad norm: 1.6292154995481494\n",
      "Epoch 2316, Loss: 209.82352445816534, Neurons: 201, Grad norm: 1.8634863131377213\n",
      "Epoch 2316, Loss: 209.82352445816534, Neurons: 201, Grad norm: 1.8634863131377213\n",
      "Epoch 2317, Loss: 209.8224862209291, Neurons: 201, Grad norm: 1.1995330582824142\n",
      "Epoch 2317, Loss: 209.8224862209291, Neurons: 201, Grad norm: 1.1995330582824142\n",
      "Epoch 2318, Loss: 209.8214263214659, Neurons: 201, Grad norm: 1.1025694301884883\n",
      "Epoch 2318, Loss: 209.8214263214659, Neurons: 201, Grad norm: 1.1025694301884883\n",
      "Epoch 2319, Loss: 209.82038149442084, Neurons: 201, Grad norm: 1.1729764782088459\n",
      "Epoch 2319, Loss: 209.82038149442084, Neurons: 201, Grad norm: 1.1729764782088459\n",
      "Epoch 2320, Loss: 209.81937376741075, Neurons: 201, Grad norm: 1.1955016249850678\n",
      "Epoch 2320, Loss: 209.81937376741075, Neurons: 201, Grad norm: 1.1955016249850678\n",
      "Epoch 2321, Loss: 209.8183947304113, Neurons: 201, Grad norm: 1.6229525464110277\n",
      "Epoch 2321, Loss: 209.8183947304113, Neurons: 201, Grad norm: 1.6229525464110277\n",
      "Epoch 2322, Loss: 209.8174105387217, Neurons: 201, Grad norm: 1.2857877071918073\n",
      "Epoch 2322, Loss: 209.8174105387217, Neurons: 201, Grad norm: 1.2857877071918073\n",
      "Epoch 2323, Loss: 209.81640560918999, Neurons: 201, Grad norm: 1.5097360487140352\n",
      "Epoch 2323, Loss: 209.81640560918999, Neurons: 201, Grad norm: 1.5097360487140352\n",
      "Epoch 2324, Loss: 209.81541530137005, Neurons: 201, Grad norm: 1.1227757174069188\n",
      "Epoch 2324, Loss: 209.81541530137005, Neurons: 201, Grad norm: 1.1227757174069188\n",
      "Epoch 2325, Loss: 209.81441435549698, Neurons: 201, Grad norm: 1.191357214584961\n",
      "Epoch 2325, Loss: 209.81441435549698, Neurons: 201, Grad norm: 1.191357214584961\n",
      "Epoch 2326, Loss: 209.8133941468112, Neurons: 201, Grad norm: 0.9811116435622407\n",
      "Epoch 2326, Loss: 209.8133941468112, Neurons: 201, Grad norm: 0.9811116435622407\n",
      "Epoch 2327, Loss: 209.81240861964918, Neurons: 201, Grad norm: 1.01081502472845\n",
      "Epoch 2327, Loss: 209.81240861964918, Neurons: 201, Grad norm: 1.01081502472845\n",
      "Epoch 2328, Loss: 209.81142246977586, Neurons: 201, Grad norm: 0.9678734192015764\n",
      "Epoch 2328, Loss: 209.81142246977586, Neurons: 201, Grad norm: 0.9678734192015764\n",
      "Epoch 2329, Loss: 209.81042788884088, Neurons: 201, Grad norm: 1.0046838921870025\n",
      "Epoch 2329, Loss: 209.81042788884088, Neurons: 201, Grad norm: 1.0046838921870025\n",
      "Epoch 2330, Loss: 209.80945390462585, Neurons: 201, Grad norm: 1.0864307739567896\n",
      "Epoch 2330, Loss: 209.80945390462585, Neurons: 201, Grad norm: 1.0864307739567896\n",
      "Epoch 2331, Loss: 209.80848197100693, Neurons: 201, Grad norm: 1.0522732570715576\n",
      "Epoch 2331, Loss: 209.80848197100693, Neurons: 201, Grad norm: 1.0522732570715576\n",
      "Epoch 2332, Loss: 209.80751511561792, Neurons: 201, Grad norm: 1.4113651132451261\n",
      "Epoch 2332, Loss: 209.80751511561792, Neurons: 201, Grad norm: 1.4113651132451261\n",
      "Epoch 2333, Loss: 209.80655492540333, Neurons: 201, Grad norm: 1.326112516967504\n",
      "Epoch 2333, Loss: 209.80655492540333, Neurons: 201, Grad norm: 1.326112516967504\n",
      "Epoch 2334, Loss: 209.80561642397475, Neurons: 201, Grad norm: 1.7439528087237939\n",
      "Epoch 2334, Loss: 209.80561642397475, Neurons: 201, Grad norm: 1.7439528087237939\n",
      "Epoch 2335, Loss: 209.804673474555, Neurons: 201, Grad norm: 1.4549531852712672\n",
      "Epoch 2335, Loss: 209.804673474555, Neurons: 201, Grad norm: 1.4549531852712672\n",
      "Epoch 2336, Loss: 209.80371241621305, Neurons: 201, Grad norm: 1.682106100792784\n",
      "Epoch 2336, Loss: 209.80371241621305, Neurons: 201, Grad norm: 1.682106100792784\n",
      "Epoch 2337, Loss: 209.8027291720807, Neurons: 201, Grad norm: 1.155775223808664\n",
      "Epoch 2337, Loss: 209.8027291720807, Neurons: 201, Grad norm: 1.155775223808664\n",
      "Epoch 2338, Loss: 209.80173430233842, Neurons: 201, Grad norm: 1.2897105192313885\n",
      "Epoch 2338, Loss: 209.80173430233842, Neurons: 201, Grad norm: 1.2897105192313885\n",
      "Epoch 2339, Loss: 209.80075529589362, Neurons: 201, Grad norm: 1.0398136921109937\n",
      "Epoch 2339, Loss: 209.80075529589362, Neurons: 201, Grad norm: 1.0398136921109937\n",
      "Epoch 2340, Loss: 209.79976641874802, Neurons: 201, Grad norm: 1.0089791694220904\n",
      "Epoch 2340, Loss: 209.79976641874802, Neurons: 201, Grad norm: 1.0089791694220904\n",
      "Epoch 2341, Loss: 209.79879036477158, Neurons: 201, Grad norm: 1.396405006749244\n",
      "Epoch 2341, Loss: 209.79879036477158, Neurons: 201, Grad norm: 1.396405006749244\n",
      "Epoch 2342, Loss: 209.79782491938798, Neurons: 201, Grad norm: 1.5058767569149383\n",
      "Epoch 2342, Loss: 209.79782491938798, Neurons: 201, Grad norm: 1.5058767569149383\n",
      "Epoch 2343, Loss: 209.7968977940944, Neurons: 201, Grad norm: 2.346684645212788\n",
      "Epoch 2343, Loss: 209.7968977940944, Neurons: 201, Grad norm: 2.346684645212788\n",
      "Epoch 2344, Loss: 209.79591575334717, Neurons: 201, Grad norm: 2.177306392556436\n",
      "Epoch 2344, Loss: 209.79591575334717, Neurons: 201, Grad norm: 2.177306392556436\n",
      "Epoch 2345, Loss: 209.79494545046288, Neurons: 201, Grad norm: 2.751135983131485\n",
      "Epoch 2345, Loss: 209.79494545046288, Neurons: 201, Grad norm: 2.751135983131485\n",
      "Epoch 2346, Loss: 209.79389009280334, Neurons: 201, Grad norm: 2.185127567300759\n",
      "Epoch 2346, Loss: 209.79389009280334, Neurons: 201, Grad norm: 2.185127567300759\n",
      "Epoch 2347, Loss: 209.7928177576321, Neurons: 201, Grad norm: 2.336823755663403\n",
      "Epoch 2347, Loss: 209.7928177576321, Neurons: 201, Grad norm: 2.336823755663403\n",
      "Epoch 2348, Loss: 209.79172864655598, Neurons: 201, Grad norm: 1.455265148841226\n",
      "Epoch 2348, Loss: 209.79172864655598, Neurons: 201, Grad norm: 1.455265148841226\n",
      "Epoch 2349, Loss: 209.7906022619661, Neurons: 201, Grad norm: 1.4141594967761546\n",
      "Epoch 2349, Loss: 209.7906022619661, Neurons: 201, Grad norm: 1.4141594967761546\n",
      "Epoch 2350, Loss: 209.78941599825643, Neurons: 201, Grad norm: 1.31291794045215\n",
      "Epoch 2350, Loss: 209.78941599825643, Neurons: 201, Grad norm: 1.31291794045215\n",
      "Epoch 2351, Loss: 209.78821756180434, Neurons: 201, Grad norm: 1.3404397449420524\n",
      "Epoch 2351, Loss: 209.78821756180434, Neurons: 201, Grad norm: 1.3404397449420524\n",
      "Epoch 2352, Loss: 209.78697897356076, Neurons: 201, Grad norm: 2.0179552917104098\n",
      "Epoch 2352, Loss: 209.78697897356076, Neurons: 201, Grad norm: 2.0179552917104098\n",
      "Epoch 2353, Loss: 209.7858708155424, Neurons: 201, Grad norm: 2.007203478612002\n",
      "Epoch 2353, Loss: 209.7858708155424, Neurons: 201, Grad norm: 2.007203478612002\n",
      "Epoch 2354, Loss: 209.78478131314378, Neurons: 201, Grad norm: 2.681472527036894\n",
      "Epoch 2354, Loss: 209.78478131314378, Neurons: 201, Grad norm: 2.681472527036894\n",
      "Epoch 2355, Loss: 209.7838800328757, Neurons: 201, Grad norm: 2.3306686111029467\n",
      "Epoch 2355, Loss: 209.7838800328757, Neurons: 201, Grad norm: 2.3306686111029467\n",
      "Epoch 2356, Loss: 209.78284739098382, Neurons: 201, Grad norm: 2.387188618854832\n",
      "Epoch 2356, Loss: 209.78284739098382, Neurons: 201, Grad norm: 2.387188618854832\n",
      "Epoch 2357, Loss: 209.78166948013492, Neurons: 201, Grad norm: 1.4068626469580847\n",
      "Epoch 2357, Loss: 209.78166948013492, Neurons: 201, Grad norm: 1.4068626469580847\n",
      "Epoch 2358, Loss: 209.78041592377838, Neurons: 201, Grad norm: 1.151288411359719\n",
      "Epoch 2358, Loss: 209.78041592377838, Neurons: 201, Grad norm: 1.151288411359719\n",
      "Epoch 2359, Loss: 209.77924316083534, Neurons: 201, Grad norm: 1.311231192336765\n",
      "Epoch 2359, Loss: 209.77924316083534, Neurons: 201, Grad norm: 1.311231192336765\n",
      "Epoch 2360, Loss: 209.77812649582475, Neurons: 201, Grad norm: 1.2285389332375765\n",
      "Epoch 2360, Loss: 209.77812649582475, Neurons: 201, Grad norm: 1.2285389332375765\n",
      "Epoch 2361, Loss: 209.77702442699623, Neurons: 201, Grad norm: 1.87605611670753\n",
      "Epoch 2361, Loss: 209.77702442699623, Neurons: 201, Grad norm: 1.87605611670753\n",
      "Epoch 2362, Loss: 209.77595087924516, Neurons: 201, Grad norm: 1.6571228115424845\n",
      "Epoch 2362, Loss: 209.77595087924516, Neurons: 201, Grad norm: 1.6571228115424845\n",
      "Epoch 2363, Loss: 209.7749492588498, Neurons: 201, Grad norm: 1.8516433633044602\n",
      "Epoch 2363, Loss: 209.7749492588498, Neurons: 201, Grad norm: 1.8516433633044602\n",
      "Epoch 2364, Loss: 209.77387226039323, Neurons: 201, Grad norm: 1.1667166140128842\n",
      "Epoch 2364, Loss: 209.77387226039323, Neurons: 201, Grad norm: 1.1667166140128842\n",
      "Epoch 2365, Loss: 209.77275531460998, Neurons: 201, Grad norm: 1.1362306018166592\n",
      "Epoch 2365, Loss: 209.77275531460998, Neurons: 201, Grad norm: 1.1362306018166592\n",
      "Epoch 2366, Loss: 209.7716261355781, Neurons: 201, Grad norm: 1.34658698307891\n",
      "Epoch 2366, Loss: 209.7716261355781, Neurons: 201, Grad norm: 1.34658698307891\n",
      "Epoch 2367, Loss: 209.77053106475933, Neurons: 201, Grad norm: 1.413429216014627\n",
      "Epoch 2367, Loss: 209.77053106475933, Neurons: 201, Grad norm: 1.413429216014627\n",
      "Epoch 2368, Loss: 209.7693670354064, Neurons: 201, Grad norm: 2.1089375746299255\n",
      "Epoch 2368, Loss: 209.7693670354064, Neurons: 201, Grad norm: 2.1089375746299255\n",
      "Epoch 2369, Loss: 209.76825712823967, Neurons: 201, Grad norm: 2.2120145524183155\n",
      "Epoch 2369, Loss: 209.76825712823967, Neurons: 201, Grad norm: 2.2120145524183155\n",
      "Epoch 2370, Loss: 209.76725512390308, Neurons: 201, Grad norm: 3.069335844539654\n",
      "Epoch 2370, Loss: 209.76725512390308, Neurons: 201, Grad norm: 3.069335844539654\n",
      "Epoch 2371, Loss: 209.7662599816643, Neurons: 201, Grad norm: 2.6305978204711895\n",
      "Epoch 2371, Loss: 209.7662599816643, Neurons: 201, Grad norm: 2.6305978204711895\n",
      "Epoch 2372, Loss: 209.76540688957854, Neurons: 201, Grad norm: 2.3383204035679435\n",
      "Epoch 2372, Loss: 209.76540688957854, Neurons: 201, Grad norm: 2.3383204035679435\n",
      "Epoch 2373, Loss: 209.76435805947884, Neurons: 201, Grad norm: 1.2131448998918692\n",
      "Epoch 2373, Loss: 209.76435805947884, Neurons: 201, Grad norm: 1.2131448998918692\n",
      "Epoch 2374, Loss: 209.76331441245628, Neurons: 201, Grad norm: 1.0649126777082578\n",
      "Epoch 2374, Loss: 209.76331441245628, Neurons: 201, Grad norm: 1.0649126777082578\n",
      "Epoch 2375, Loss: 209.76233247909957, Neurons: 201, Grad norm: 1.977491527615071\n",
      "Epoch 2375, Loss: 209.76233247909957, Neurons: 201, Grad norm: 1.977491527615071\n",
      "Epoch 2376, Loss: 209.76145854245732, Neurons: 201, Grad norm: 2.556878530890877\n",
      "Epoch 2376, Loss: 209.76145854245732, Neurons: 201, Grad norm: 2.556878530890877\n",
      "Epoch 2377, Loss: 209.76061361103478, Neurons: 201, Grad norm: 3.105224282883578\n",
      "Epoch 2377, Loss: 209.76061361103478, Neurons: 201, Grad norm: 3.105224282883578\n",
      "Epoch 2378, Loss: 209.75970212892003, Neurons: 201, Grad norm: 2.771536584607933\n",
      "Epoch 2378, Loss: 209.75970212892003, Neurons: 201, Grad norm: 2.771536584607933\n",
      "Epoch 2379, Loss: 209.7586425567352, Neurons: 201, Grad norm: 2.3064416702736374\n",
      "Epoch 2379, Loss: 209.7586425567352, Neurons: 201, Grad norm: 2.3064416702736374\n",
      "Epoch 2380, Loss: 209.75748892028733, Neurons: 201, Grad norm: 1.4353313002116912\n",
      "Epoch 2380, Loss: 209.75748892028733, Neurons: 201, Grad norm: 1.4353313002116912\n",
      "Epoch 2381, Loss: 209.7563719480874, Neurons: 201, Grad norm: 1.1048206341900182\n",
      "Epoch 2381, Loss: 209.7563719480874, Neurons: 201, Grad norm: 1.1048206341900182\n",
      "Epoch 2382, Loss: 209.75531233915612, Neurons: 201, Grad norm: 1.300257299881033\n",
      "Epoch 2382, Loss: 209.75531233915612, Neurons: 201, Grad norm: 1.300257299881033\n",
      "Epoch 2383, Loss: 209.75432484623929, Neurons: 201, Grad norm: 1.5071149957225336\n",
      "Epoch 2383, Loss: 209.75432484623929, Neurons: 201, Grad norm: 1.5071149957225336\n",
      "Epoch 2384, Loss: 209.75336821058855, Neurons: 201, Grad norm: 2.12034161285016\n",
      "Epoch 2384, Loss: 209.75336821058855, Neurons: 201, Grad norm: 2.12034161285016\n",
      "Epoch 2385, Loss: 209.75240999843274, Neurons: 201, Grad norm: 1.7726984035363904\n",
      "Epoch 2385, Loss: 209.75240999843274, Neurons: 201, Grad norm: 1.7726984035363904\n",
      "Epoch 2386, Loss: 209.75146077382675, Neurons: 201, Grad norm: 1.8076097626149317\n",
      "Epoch 2386, Loss: 209.75146077382675, Neurons: 201, Grad norm: 1.8076097626149317\n",
      "Epoch 2387, Loss: 209.75050852927654, Neurons: 201, Grad norm: 1.0589710409495463\n",
      "Epoch 2387, Loss: 209.75050852927654, Neurons: 201, Grad norm: 1.0589710409495463\n",
      "Epoch 2388, Loss: 209.74953899319863, Neurons: 201, Grad norm: 1.0327484855708406\n",
      "Epoch 2388, Loss: 209.74953899319863, Neurons: 201, Grad norm: 1.0327484855708406\n",
      "Epoch 2389, Loss: 209.74859628380776, Neurons: 201, Grad norm: 1.6651980760386171\n",
      "Epoch 2389, Loss: 209.74859628380776, Neurons: 201, Grad norm: 1.6651980760386171\n",
      "Epoch 2390, Loss: 209.7476676273861, Neurons: 201, Grad norm: 1.4653525149361282\n",
      "Epoch 2390, Loss: 209.7476676273861, Neurons: 201, Grad norm: 1.4653525149361282\n",
      "Epoch 2391, Loss: 209.74672489948705, Neurons: 201, Grad norm: 1.8858846466866757\n",
      "Epoch 2391, Loss: 209.74672489948705, Neurons: 201, Grad norm: 1.8858846466866757\n",
      "Epoch 2392, Loss: 209.74573089647652, Neurons: 201, Grad norm: 1.3782511392089305\n",
      "Epoch 2392, Loss: 209.74573089647652, Neurons: 201, Grad norm: 1.3782511392089305\n",
      "Epoch 2393, Loss: 209.74471551199596, Neurons: 201, Grad norm: 1.443383071396184\n",
      "Epoch 2393, Loss: 209.74471551199596, Neurons: 201, Grad norm: 1.443383071396184\n",
      "Epoch 2394, Loss: 209.74376113018113, Neurons: 201, Grad norm: 1.025090902042396\n",
      "Epoch 2394, Loss: 209.74376113018113, Neurons: 201, Grad norm: 1.025090902042396\n",
      "Epoch 2395, Loss: 209.74281840476766, Neurons: 201, Grad norm: 0.983122915492228\n",
      "Epoch 2395, Loss: 209.74281840476766, Neurons: 201, Grad norm: 0.983122915492228\n",
      "Epoch 2396, Loss: 209.74191391374208, Neurons: 201, Grad norm: 1.0546363631947997\n",
      "Epoch 2396, Loss: 209.74191391374208, Neurons: 201, Grad norm: 1.0546363631947997\n",
      "Epoch 2397, Loss: 209.7410068799514, Neurons: 201, Grad norm: 1.0068714963761738\n",
      "Epoch 2397, Loss: 209.7410068799514, Neurons: 201, Grad norm: 1.0068714963761738\n",
      "Epoch 2398, Loss: 209.7400862578721, Neurons: 201, Grad norm: 1.0717802531678735\n",
      "Epoch 2398, Loss: 209.7400862578721, Neurons: 201, Grad norm: 1.0717802531678735\n",
      "Epoch 2399, Loss: 209.7391527053466, Neurons: 201, Grad norm: 1.0523331146886037\n",
      "Epoch 2399, Loss: 209.7391527053466, Neurons: 201, Grad norm: 1.0523331146886037\n",
      "Epoch 2400, Loss: 209.7382054338043, Neurons: 201, Grad norm: 0.9936945703685586\n",
      "Epoch 2400, Loss: 209.7382054338043, Neurons: 201, Grad norm: 0.9936945703685586\n",
      "Epoch 2401, Loss: 209.73725909462303, Neurons: 201, Grad norm: 0.9732046035260351\n",
      "Epoch 2401, Loss: 209.73725909462303, Neurons: 201, Grad norm: 0.9732046035260351\n",
      "Epoch 2402, Loss: 209.7363611166854, Neurons: 201, Grad norm: 1.1204787950405548\n",
      "Epoch 2402, Loss: 209.7363611166854, Neurons: 201, Grad norm: 1.1204787950405548\n",
      "Epoch 2403, Loss: 209.73550716111126, Neurons: 201, Grad norm: 1.0383665377020437\n",
      "Epoch 2403, Loss: 209.73550716111126, Neurons: 201, Grad norm: 1.0383665377020437\n",
      "Epoch 2404, Loss: 209.7346157916548, Neurons: 201, Grad norm: 1.0576621276823126\n",
      "Epoch 2404, Loss: 209.7346157916548, Neurons: 201, Grad norm: 1.0576621276823126\n",
      "Epoch 2405, Loss: 209.7337085695327, Neurons: 201, Grad norm: 1.1446255674026737\n",
      "Epoch 2405, Loss: 209.7337085695327, Neurons: 201, Grad norm: 1.1446255674026737\n",
      "Epoch 2406, Loss: 209.73282736293405, Neurons: 201, Grad norm: 1.0462273390424919\n",
      "Epoch 2406, Loss: 209.73282736293405, Neurons: 201, Grad norm: 1.0462273390424919\n",
      "Epoch 2407, Loss: 209.73194319646228, Neurons: 201, Grad norm: 1.09653733896276\n",
      "Epoch 2407, Loss: 209.73194319646228, Neurons: 201, Grad norm: 1.09653733896276\n",
      "Epoch 2408, Loss: 209.73107404330247, Neurons: 201, Grad norm: 0.9486124767581183\n",
      "Epoch 2408, Loss: 209.73107404330247, Neurons: 201, Grad norm: 0.9486124767581183\n",
      "Epoch 2409, Loss: 209.73019666865085, Neurons: 201, Grad norm: 0.9566723341792479\n",
      "Epoch 2409, Loss: 209.73019666865085, Neurons: 201, Grad norm: 0.9566723341792479\n",
      "Epoch 2410, Loss: 209.72931576417787, Neurons: 201, Grad norm: 0.9806534783323332\n",
      "Epoch 2410, Loss: 209.72931576417787, Neurons: 201, Grad norm: 0.9806534783323332\n",
      "Epoch 2411, Loss: 209.72843702097825, Neurons: 201, Grad norm: 1.0276346006179515\n",
      "Epoch 2411, Loss: 209.72843702097825, Neurons: 201, Grad norm: 1.0276346006179515\n",
      "Epoch 2412, Loss: 209.7275723853447, Neurons: 201, Grad norm: 1.088097485204223\n",
      "Epoch 2412, Loss: 209.7275723853447, Neurons: 201, Grad norm: 1.088097485204223\n",
      "Epoch 2413, Loss: 209.72669443339814, Neurons: 201, Grad norm: 0.9326207499562054\n",
      "Epoch 2413, Loss: 209.72669443339814, Neurons: 201, Grad norm: 0.9326207499562054\n",
      "Epoch 2414, Loss: 209.72583134893827, Neurons: 201, Grad norm: 1.2209083733104904\n",
      "Epoch 2414, Loss: 209.72583134893827, Neurons: 201, Grad norm: 1.2209083733104904\n",
      "Epoch 2415, Loss: 209.72498248781892, Neurons: 201, Grad norm: 1.0985458050803842\n",
      "Epoch 2415, Loss: 209.72498248781892, Neurons: 201, Grad norm: 1.0985458050803842\n",
      "Epoch 2416, Loss: 209.72411736391595, Neurons: 201, Grad norm: 1.5510893129305274\n",
      "Epoch 2416, Loss: 209.72411736391595, Neurons: 201, Grad norm: 1.5510893129305274\n",
      "Epoch 2417, Loss: 209.72326345289605, Neurons: 201, Grad norm: 1.3615335668420003\n",
      "Epoch 2417, Loss: 209.72326345289605, Neurons: 201, Grad norm: 1.3615335668420003\n",
      "Epoch 2418, Loss: 209.72240510895162, Neurons: 201, Grad norm: 1.7186161645866807\n",
      "Epoch 2418, Loss: 209.72240510895162, Neurons: 201, Grad norm: 1.7186161645866807\n",
      "Epoch 2419, Loss: 209.7215364262406, Neurons: 201, Grad norm: 1.4407508038561947\n",
      "Epoch 2419, Loss: 209.7215364262406, Neurons: 201, Grad norm: 1.4407508038561947\n",
      "Epoch 2420, Loss: 209.72068248580788, Neurons: 201, Grad norm: 1.7256302792229175\n",
      "Epoch 2420, Loss: 209.72068248580788, Neurons: 201, Grad norm: 1.7256302792229175\n",
      "Epoch 2421, Loss: 209.71981059689728, Neurons: 201, Grad norm: 1.4722603570680695\n",
      "Epoch 2421, Loss: 209.71981059689728, Neurons: 201, Grad norm: 1.4722603570680695\n",
      "Epoch 2422, Loss: 209.71893588708062, Neurons: 201, Grad norm: 1.8027884301082466\n",
      "Epoch 2422, Loss: 209.71893588708062, Neurons: 201, Grad norm: 1.8027884301082466\n",
      "Epoch 2423, Loss: 209.71807582181958, Neurons: 201, Grad norm: 1.474582739770443\n",
      "Epoch 2423, Loss: 209.71807582181958, Neurons: 201, Grad norm: 1.474582739770443\n",
      "Epoch 2424, Loss: 209.7171938140184, Neurons: 201, Grad norm: 1.875358946183178\n",
      "Epoch 2424, Loss: 209.7171938140184, Neurons: 201, Grad norm: 1.875358946183178\n",
      "Epoch 2425, Loss: 209.7163140674342, Neurons: 201, Grad norm: 1.49580905132992\n",
      "Epoch 2425, Loss: 209.7163140674342, Neurons: 201, Grad norm: 1.49580905132992\n",
      "Epoch 2426, Loss: 209.7154391517486, Neurons: 201, Grad norm: 1.7490283082662306\n",
      "Epoch 2426, Loss: 209.7154391517486, Neurons: 201, Grad norm: 1.7490283082662306\n",
      "Epoch 2427, Loss: 209.71453955452438, Neurons: 201, Grad norm: 1.4013828572969245\n",
      "Epoch 2427, Loss: 209.71453955452438, Neurons: 201, Grad norm: 1.4013828572969245\n",
      "Epoch 2428, Loss: 209.713644220142, Neurons: 201, Grad norm: 1.563642064648111\n",
      "Epoch 2428, Loss: 209.713644220142, Neurons: 201, Grad norm: 1.563642064648111\n",
      "Epoch 2429, Loss: 209.71274145284542, Neurons: 201, Grad norm: 1.2728979911426965\n",
      "Epoch 2429, Loss: 209.71274145284542, Neurons: 201, Grad norm: 1.2728979911426965\n",
      "Epoch 2430, Loss: 209.7118230206864, Neurons: 201, Grad norm: 1.63229501425188\n",
      "Epoch 2430, Loss: 209.7118230206864, Neurons: 201, Grad norm: 1.63229501425188\n",
      "Epoch 2431, Loss: 209.7109093960578, Neurons: 201, Grad norm: 1.5543617345727947\n",
      "Epoch 2431, Loss: 209.7109093960578, Neurons: 201, Grad norm: 1.5543617345727947\n",
      "Epoch 2432, Loss: 209.71002110849602, Neurons: 201, Grad norm: 2.107471851660701\n",
      "Epoch 2432, Loss: 209.71002110849602, Neurons: 201, Grad norm: 2.107471851660701\n",
      "Epoch 2433, Loss: 209.70916728329655, Neurons: 201, Grad norm: 1.939553090648181\n",
      "Epoch 2433, Loss: 209.70916728329655, Neurons: 201, Grad norm: 1.939553090648181\n",
      "Epoch 2434, Loss: 209.70835517485833, Neurons: 201, Grad norm: 2.7381290880409557\n",
      "Epoch 2434, Loss: 209.70835517485833, Neurons: 201, Grad norm: 2.7381290880409557\n",
      "Epoch 2435, Loss: 209.7075800613199, Neurons: 201, Grad norm: 2.506370751675555\n",
      "Epoch 2435, Loss: 209.7075800613199, Neurons: 201, Grad norm: 2.506370751675555\n",
      "Epoch 2436, Loss: 209.70675618028284, Neurons: 201, Grad norm: 2.9933693245366393\n",
      "Epoch 2436, Loss: 209.70675618028284, Neurons: 201, Grad norm: 2.9933693245366393\n",
      "Epoch 2437, Loss: 209.7059023277405, Neurons: 201, Grad norm: 2.470121532113873\n",
      "Epoch 2437, Loss: 209.7059023277405, Neurons: 201, Grad norm: 2.470121532113873\n",
      "Epoch 2438, Loss: 209.70496756931678, Neurons: 201, Grad norm: 2.3146867293831055\n",
      "Epoch 2438, Loss: 209.70496756931678, Neurons: 201, Grad norm: 2.3146867293831055\n",
      "Epoch 2439, Loss: 209.7039900146149, Neurons: 201, Grad norm: 1.3935949599952921\n",
      "Epoch 2439, Loss: 209.7039900146149, Neurons: 201, Grad norm: 1.3935949599952921\n",
      "Epoch 2440, Loss: 209.70293818686878, Neurons: 201, Grad norm: 1.1614508019878655\n",
      "Epoch 2440, Loss: 209.70293818686878, Neurons: 201, Grad norm: 1.1614508019878655\n",
      "Epoch 2441, Loss: 209.7018028575849, Neurons: 201, Grad norm: 1.3101714186112705\n",
      "Epoch 2441, Loss: 209.7018028575849, Neurons: 201, Grad norm: 1.3101714186112705\n",
      "Epoch 2442, Loss: 209.70065617975075, Neurons: 201, Grad norm: 1.4942667805511507\n",
      "Epoch 2442, Loss: 209.70065617975075, Neurons: 201, Grad norm: 1.4942667805511507\n",
      "Epoch 2443, Loss: 209.6994823447805, Neurons: 201, Grad norm: 2.336633488995777\n",
      "Epoch 2443, Loss: 209.6994823447805, Neurons: 201, Grad norm: 2.336633488995777\n",
      "Epoch 2444, Loss: 209.69830761220757, Neurons: 201, Grad norm: 2.2654613662751264\n",
      "Epoch 2444, Loss: 209.69830761220757, Neurons: 201, Grad norm: 2.2654613662751264\n",
      "Epoch 2445, Loss: 209.6970939268689, Neurons: 201, Grad norm: 2.9729917559381223\n",
      "Epoch 2445, Loss: 209.6970939268689, Neurons: 201, Grad norm: 2.9729917559381223\n",
      "Epoch 2446, Loss: 209.6958229842009, Neurons: 201, Grad norm: 2.4367923684442796\n",
      "Epoch 2446, Loss: 209.6958229842009, Neurons: 201, Grad norm: 2.4367923684442796\n",
      "Epoch 2447, Loss: 209.694392412491, Neurons: 201, Grad norm: 2.6403259699482233\n",
      "Epoch 2447, Loss: 209.694392412491, Neurons: 201, Grad norm: 2.6403259699482233\n",
      "Epoch 2448, Loss: 209.6929585329543, Neurons: 201, Grad norm: 1.810950451676858\n",
      "Epoch 2448, Loss: 209.6929585329543, Neurons: 201, Grad norm: 1.810950451676858\n",
      "Epoch 2449, Loss: 209.69158309452945, Neurons: 201, Grad norm: 1.5553414738844675\n",
      "Epoch 2449, Loss: 209.69158309452945, Neurons: 201, Grad norm: 1.5553414738844675\n",
      "Epoch 2450, Loss: 209.69019319777274, Neurons: 201, Grad norm: 1.2025606003783977\n",
      "Epoch 2450, Loss: 209.69019319777274, Neurons: 201, Grad norm: 1.2025606003783977\n",
      "Epoch 2451, Loss: 209.6890469710593, Neurons: 201, Grad norm: 1.2724431908399636\n",
      "Epoch 2451, Loss: 209.6890469710593, Neurons: 201, Grad norm: 1.2724431908399636\n",
      "Epoch 2452, Loss: 209.68797472920372, Neurons: 201, Grad norm: 2.076450032505992\n",
      "Epoch 2452, Loss: 209.68797472920372, Neurons: 201, Grad norm: 2.076450032505992\n",
      "Epoch 2453, Loss: 209.6870923215624, Neurons: 201, Grad norm: 2.175091097808646\n",
      "Epoch 2453, Loss: 209.6870923215624, Neurons: 201, Grad norm: 2.175091097808646\n",
      "Epoch 2454, Loss: 209.68613581085114, Neurons: 201, Grad norm: 2.5252548107667456\n",
      "Epoch 2454, Loss: 209.68613581085114, Neurons: 201, Grad norm: 2.5252548107667456\n",
      "Epoch 2455, Loss: 209.685214697549, Neurons: 201, Grad norm: 1.8726227478680508\n",
      "Epoch 2455, Loss: 209.685214697549, Neurons: 201, Grad norm: 1.8726227478680508\n",
      "Epoch 2456, Loss: 209.68440933419922, Neurons: 201, Grad norm: 1.678841581678723\n",
      "Epoch 2456, Loss: 209.68440933419922, Neurons: 201, Grad norm: 1.678841581678723\n",
      "Epoch 2457, Loss: 209.6836159509869, Neurons: 201, Grad norm: 1.3087935523340737\n",
      "Epoch 2457, Loss: 209.6836159509869, Neurons: 201, Grad norm: 1.3087935523340737\n",
      "Epoch 2458, Loss: 209.68272402402593, Neurons: 201, Grad norm: 1.4318896465358852\n",
      "Epoch 2458, Loss: 209.68272402402593, Neurons: 201, Grad norm: 1.4318896465358852\n",
      "Epoch 2459, Loss: 209.68174883508706, Neurons: 201, Grad norm: 2.1549367366645855\n",
      "Epoch 2459, Loss: 209.68174883508706, Neurons: 201, Grad norm: 2.1549367366645855\n",
      "Epoch 2460, Loss: 209.68070956962836, Neurons: 201, Grad norm: 2.048839705809455\n",
      "Epoch 2460, Loss: 209.68070956962836, Neurons: 201, Grad norm: 2.048839705809455\n",
      "Epoch 2461, Loss: 209.6796049770295, Neurons: 201, Grad norm: 2.2914820118537773\n",
      "Epoch 2461, Loss: 209.6796049770295, Neurons: 201, Grad norm: 2.2914820118537773\n",
      "Epoch 2462, Loss: 209.67846691895065, Neurons: 201, Grad norm: 1.822810200288949\n",
      "Epoch 2462, Loss: 209.67846691895065, Neurons: 201, Grad norm: 1.822810200288949\n",
      "Epoch 2463, Loss: 209.6775381496768, Neurons: 201, Grad norm: 1.7637240530538032\n",
      "Epoch 2463, Loss: 209.6775381496768, Neurons: 201, Grad norm: 1.7637240530538032\n",
      "Epoch 2464, Loss: 209.67664417947785, Neurons: 201, Grad norm: 1.2194511584835661\n",
      "Epoch 2464, Loss: 209.67664417947785, Neurons: 201, Grad norm: 1.2194511584835661\n",
      "Epoch 2465, Loss: 209.67572153922347, Neurons: 201, Grad norm: 1.223094040064278\n",
      "Epoch 2465, Loss: 209.67572153922347, Neurons: 201, Grad norm: 1.223094040064278\n",
      "Epoch 2466, Loss: 209.6748314903685, Neurons: 201, Grad norm: 1.2868117146258125\n",
      "Epoch 2466, Loss: 209.6748314903685, Neurons: 201, Grad norm: 1.2868117146258125\n",
      "Epoch 2467, Loss: 209.67394716055298, Neurons: 201, Grad norm: 1.225616594437086\n",
      "Epoch 2467, Loss: 209.67394716055298, Neurons: 201, Grad norm: 1.225616594437086\n",
      "Epoch 2468, Loss: 209.67308831429702, Neurons: 201, Grad norm: 2.0131403866123714\n",
      "Epoch 2468, Loss: 209.67308831429702, Neurons: 201, Grad norm: 2.0131403866123714\n",
      "Epoch 2469, Loss: 209.67226527072725, Neurons: 201, Grad norm: 2.0569282133216524\n",
      "Epoch 2469, Loss: 209.67226527072725, Neurons: 201, Grad norm: 2.0569282133216524\n",
      "Epoch 2470, Loss: 209.671438678877, Neurons: 201, Grad norm: 2.575543780210374\n",
      "Epoch 2470, Loss: 209.671438678877, Neurons: 201, Grad norm: 2.575543780210374\n",
      "Epoch 2471, Loss: 209.67054092089532, Neurons: 201, Grad norm: 2.2239831091386435\n",
      "Epoch 2471, Loss: 209.67054092089532, Neurons: 201, Grad norm: 2.2239831091386435\n",
      "Epoch 2472, Loss: 209.66959170792168, Neurons: 201, Grad norm: 2.5766528460747735\n",
      "Epoch 2472, Loss: 209.66959170792168, Neurons: 201, Grad norm: 2.5766528460747735\n",
      "Epoch 2473, Loss: 209.6686478192151, Neurons: 201, Grad norm: 2.074318995904704\n",
      "Epoch 2473, Loss: 209.6686478192151, Neurons: 201, Grad norm: 2.074318995904704\n",
      "Epoch 2474, Loss: 209.6677269611191, Neurons: 201, Grad norm: 2.412994835323654\n",
      "Epoch 2474, Loss: 209.6677269611191, Neurons: 201, Grad norm: 2.412994835323654\n",
      "Epoch 2475, Loss: 209.6668651735524, Neurons: 201, Grad norm: 1.8800017364005768\n",
      "Epoch 2475, Loss: 209.6668651735524, Neurons: 201, Grad norm: 1.8800017364005768\n",
      "Epoch 2476, Loss: 209.66596613048634, Neurons: 201, Grad norm: 1.794912931618408\n",
      "Epoch 2476, Loss: 209.66596613048634, Neurons: 201, Grad norm: 1.794912931618408\n",
      "Epoch 2477, Loss: 209.66506215868847, Neurons: 201, Grad norm: 1.121961290083222\n",
      "Epoch 2477, Loss: 209.66506215868847, Neurons: 201, Grad norm: 1.121961290083222\n",
      "Epoch 2478, Loss: 209.66414775843973, Neurons: 201, Grad norm: 1.0289269803171126\n",
      "Epoch 2478, Loss: 209.66414775843973, Neurons: 201, Grad norm: 1.0289269803171126\n",
      "Epoch 2479, Loss: 209.66323921476865, Neurons: 201, Grad norm: 1.4973444018979014\n",
      "Epoch 2479, Loss: 209.66323921476865, Neurons: 201, Grad norm: 1.4973444018979014\n",
      "Epoch 2480, Loss: 209.66241236191414, Neurons: 201, Grad norm: 1.7197826026672307\n",
      "Epoch 2480, Loss: 209.66241236191414, Neurons: 201, Grad norm: 1.7197826026672307\n",
      "Epoch 2481, Loss: 209.661611713724, Neurons: 201, Grad norm: 2.4737128396136168\n",
      "Epoch 2481, Loss: 209.661611713724, Neurons: 201, Grad norm: 2.4737128396136168\n",
      "Epoch 2482, Loss: 209.66079395070466, Neurons: 201, Grad norm: 2.2738244766400357\n",
      "Epoch 2482, Loss: 209.66079395070466, Neurons: 201, Grad norm: 2.2738244766400357\n",
      "Epoch 2483, Loss: 209.65994970916566, Neurons: 201, Grad norm: 2.807208068815189\n",
      "Epoch 2483, Loss: 209.65994970916566, Neurons: 201, Grad norm: 2.807208068815189\n",
      "Epoch 2484, Loss: 209.65908799764492, Neurons: 201, Grad norm: 2.439933274445824\n",
      "Epoch 2484, Loss: 209.65908799764492, Neurons: 201, Grad norm: 2.439933274445824\n",
      "Epoch 2485, Loss: 209.65825621469048, Neurons: 201, Grad norm: 2.6850800487348727\n",
      "Epoch 2485, Loss: 209.65825621469048, Neurons: 201, Grad norm: 2.6850800487348727\n",
      "Epoch 2486, Loss: 209.65738892789196, Neurons: 201, Grad norm: 2.015924986120828\n",
      "Epoch 2486, Loss: 209.65738892789196, Neurons: 201, Grad norm: 2.015924986120828\n",
      "Epoch 2487, Loss: 209.65647959654237, Neurons: 201, Grad norm: 2.0731046252395333\n",
      "Epoch 2487, Loss: 209.65647959654237, Neurons: 201, Grad norm: 2.0731046252395333\n",
      "Epoch 2488, Loss: 209.65562512334623, Neurons: 201, Grad norm: 1.499809145898975\n",
      "Epoch 2488, Loss: 209.65562512334623, Neurons: 201, Grad norm: 1.499809145898975\n",
      "Epoch 2489, Loss: 209.65475515675777, Neurons: 201, Grad norm: 1.4782500348440604\n",
      "Epoch 2489, Loss: 209.65475515675777, Neurons: 201, Grad norm: 1.4782500348440604\n",
      "Epoch 2490, Loss: 209.65389528955896, Neurons: 201, Grad norm: 1.110230672390993\n",
      "Epoch 2490, Loss: 209.65389528955896, Neurons: 201, Grad norm: 1.110230672390993\n",
      "Epoch 2491, Loss: 209.6530648328637, Neurons: 201, Grad norm: 1.0584408558051877\n",
      "Epoch 2491, Loss: 209.6530648328637, Neurons: 201, Grad norm: 1.0584408558051877\n",
      "Epoch 2492, Loss: 209.65222879358646, Neurons: 201, Grad norm: 1.529290770245291\n",
      "Epoch 2492, Loss: 209.65222879358646, Neurons: 201, Grad norm: 1.529290770245291\n",
      "Epoch 2493, Loss: 209.651439970686, Neurons: 201, Grad norm: 1.7334484028744868\n",
      "Epoch 2493, Loss: 209.651439970686, Neurons: 201, Grad norm: 1.7334484028744868\n",
      "Epoch 2494, Loss: 209.65071254568855, Neurons: 201, Grad norm: 2.530487239073511\n",
      "Epoch 2494, Loss: 209.65071254568855, Neurons: 201, Grad norm: 2.530487239073511\n",
      "Epoch 2495, Loss: 209.64995483579423, Neurons: 201, Grad norm: 2.4053497402441444\n",
      "Epoch 2495, Loss: 209.64995483579423, Neurons: 201, Grad norm: 2.4053497402441444\n",
      "Epoch 2496, Loss: 209.6491647214672, Neurons: 201, Grad norm: 2.889903729350008\n",
      "Epoch 2496, Loss: 209.6491647214672, Neurons: 201, Grad norm: 2.889903729350008\n",
      "Epoch 2497, Loss: 209.64837188148184, Neurons: 201, Grad norm: 2.4542934279124524\n",
      "Epoch 2497, Loss: 209.64837188148184, Neurons: 201, Grad norm: 2.4542934279124524\n",
      "Epoch 2498, Loss: 209.64754414519265, Neurons: 201, Grad norm: 2.6394829059028444\n",
      "Epoch 2498, Loss: 209.64754414519265, Neurons: 201, Grad norm: 2.6394829059028444\n",
      "Epoch 2499, Loss: 209.64675328496713, Neurons: 201, Grad norm: 1.9686718905566225\n",
      "Epoch 2499, Loss: 209.64675328496713, Neurons: 201, Grad norm: 1.9686718905566225\n",
      "Epoch 2500, Loss: 209.64591044559114, Neurons: 201, Grad norm: 1.910632989588579\n",
      "Epoch 2500, Loss: 209.64591044559114, Neurons: 201, Grad norm: 1.910632989588579\n",
      "Epoch 2501, Loss: 209.64508070397636, Neurons: 201, Grad norm: 1.3514795475354706\n",
      "Epoch 2501, Loss: 209.64508070397636, Neurons: 201, Grad norm: 1.3514795475354706\n",
      "Epoch 2502, Loss: 209.64424578690486, Neurons: 201, Grad norm: 1.4213973663868422\n",
      "Epoch 2502, Loss: 209.64424578690486, Neurons: 201, Grad norm: 1.4213973663868422\n",
      "Epoch 2503, Loss: 209.64341469057794, Neurons: 201, Grad norm: 1.1513002810353319\n",
      "Epoch 2503, Loss: 209.64341469057794, Neurons: 201, Grad norm: 1.1513002810353319\n",
      "Epoch 2504, Loss: 209.64261374995507, Neurons: 201, Grad norm: 1.3150800441995436\n",
      "Epoch 2504, Loss: 209.64261374995507, Neurons: 201, Grad norm: 1.3150800441995436\n",
      "Epoch 2505, Loss: 209.64183261900925, Neurons: 201, Grad norm: 1.0206186486441569\n",
      "Epoch 2505, Loss: 209.64183261900925, Neurons: 201, Grad norm: 1.0206186486441569\n",
      "Epoch 2506, Loss: 209.64105803575237, Neurons: 201, Grad norm: 1.089491920746159\n",
      "Epoch 2506, Loss: 209.64105803575237, Neurons: 201, Grad norm: 1.089491920746159\n",
      "Epoch 2507, Loss: 209.640273082836, Neurons: 201, Grad norm: 0.9570810804946551\n",
      "Epoch 2507, Loss: 209.640273082836, Neurons: 201, Grad norm: 0.9570810804946551\n",
      "Epoch 2508, Loss: 209.63945701893545, Neurons: 201, Grad norm: 1.024481879134282\n",
      "Epoch 2508, Loss: 209.63945701893545, Neurons: 201, Grad norm: 1.024481879134282\n",
      "Epoch 2509, Loss: 209.63867006211453, Neurons: 201, Grad norm: 1.7389922300213374\n",
      "Epoch 2509, Loss: 209.63867006211453, Neurons: 201, Grad norm: 1.7389922300213374\n",
      "Epoch 2510, Loss: 209.63791444091, Neurons: 201, Grad norm: 2.2179382949707183\n",
      "Epoch 2510, Loss: 209.63791444091, Neurons: 201, Grad norm: 2.2179382949707183\n",
      "Epoch 2511, Loss: 209.63721783559853, Neurons: 201, Grad norm: 3.471863984137599\n",
      "Epoch 2511, Loss: 209.63721783559853, Neurons: 201, Grad norm: 3.471863984137599\n",
      "Epoch 2512, Loss: 209.6366258620089, Neurons: 201, Grad norm: 3.7423825363539733\n",
      "Epoch 2512, Loss: 209.6366258620089, Neurons: 201, Grad norm: 3.7423825363539733\n",
      "Epoch 2513, Loss: 209.63598750594628, Neurons: 201, Grad norm: 4.401240385308105\n",
      "Epoch 2513, Loss: 209.63598750594628, Neurons: 201, Grad norm: 4.401240385308105\n",
      "Epoch 2514, Loss: 209.63527047790944, Neurons: 201, Grad norm: 3.5316796263503605\n",
      "Epoch 2514, Loss: 209.63527047790944, Neurons: 201, Grad norm: 3.5316796263503605\n",
      "Epoch 2515, Loss: 209.63438283510942, Neurons: 201, Grad norm: 2.8571035030611824\n",
      "Epoch 2515, Loss: 209.63438283510942, Neurons: 201, Grad norm: 2.8571035030611824\n",
      "Epoch 2516, Loss: 209.6333961735187, Neurons: 201, Grad norm: 1.2607537068904535\n",
      "Epoch 2516, Loss: 209.6333961735187, Neurons: 201, Grad norm: 1.2607537068904535\n",
      "Epoch 2517, Loss: 209.63246149784715, Neurons: 201, Grad norm: 1.1041628412516917\n",
      "Epoch 2517, Loss: 209.63246149784715, Neurons: 201, Grad norm: 1.1041628412516917\n",
      "Epoch 2518, Loss: 209.63167582737626, Neurons: 201, Grad norm: 2.451052810107102\n",
      "Epoch 2518, Loss: 209.63167582737626, Neurons: 201, Grad norm: 2.451052810107102\n",
      "Epoch 2519, Loss: 209.63103115257843, Neurons: 201, Grad norm: 3.069489642425706\n",
      "Epoch 2519, Loss: 209.63103115257843, Neurons: 201, Grad norm: 3.069489642425706\n",
      "Epoch 2520, Loss: 209.6304403669371, Neurons: 201, Grad norm: 3.970160853275617\n",
      "Epoch 2520, Loss: 209.6304403669371, Neurons: 201, Grad norm: 3.970160853275617\n",
      "Epoch 2521, Loss: 209.62981874615417, Neurons: 201, Grad norm: 3.4238403264699477\n",
      "Epoch 2521, Loss: 209.62981874615417, Neurons: 201, Grad norm: 3.4238403264699477\n",
      "Epoch 2522, Loss: 209.6290004694217, Neurons: 201, Grad norm: 3.226898942111502\n",
      "Epoch 2522, Loss: 209.6290004694217, Neurons: 201, Grad norm: 3.226898942111502\n",
      "Epoch 2523, Loss: 209.62813512520165, Neurons: 201, Grad norm: 1.7476574564983536\n",
      "Epoch 2523, Loss: 209.62813512520165, Neurons: 201, Grad norm: 1.7476574564983536\n",
      "Epoch 2524, Loss: 209.62717913028095, Neurons: 201, Grad norm: 1.0262029596929287\n",
      "Epoch 2524, Loss: 209.62717913028095, Neurons: 201, Grad norm: 1.0262029596929287\n",
      "Epoch 2525, Loss: 209.62632577014423, Neurons: 201, Grad norm: 1.7875016881816777\n",
      "Epoch 2525, Loss: 209.62632577014423, Neurons: 201, Grad norm: 1.7875016881816777\n",
      "Epoch 2526, Loss: 209.62563853192643, Neurons: 201, Grad norm: 2.508674829988362\n",
      "Epoch 2526, Loss: 209.62563853192643, Neurons: 201, Grad norm: 2.508674829988362\n",
      "Epoch 2527, Loss: 209.62504673802644, Neurons: 201, Grad norm: 3.4069340887815343\n",
      "Epoch 2527, Loss: 209.62504673802644, Neurons: 201, Grad norm: 3.4069340887815343\n",
      "Epoch 2528, Loss: 209.62442119398003, Neurons: 201, Grad norm: 3.032906900964905\n",
      "Epoch 2528, Loss: 209.62442119398003, Neurons: 201, Grad norm: 3.032906900964905\n",
      "Epoch 2529, Loss: 209.6236565069488, Neurons: 201, Grad norm: 2.970132246086064\n",
      "Epoch 2529, Loss: 209.6236565069488, Neurons: 201, Grad norm: 2.970132246086064\n",
      "Epoch 2530, Loss: 209.62285340727493, Neurons: 201, Grad norm: 1.7296883452489986\n",
      "Epoch 2530, Loss: 209.62285340727493, Neurons: 201, Grad norm: 1.7296883452489986\n",
      "Epoch 2531, Loss: 209.62197664319277, Neurons: 201, Grad norm: 1.1622869038529908\n",
      "Epoch 2531, Loss: 209.62197664319277, Neurons: 201, Grad norm: 1.1622869038529908\n",
      "Epoch 2532, Loss: 209.62116946492227, Neurons: 201, Grad norm: 1.3465305218328336\n",
      "Epoch 2532, Loss: 209.62116946492227, Neurons: 201, Grad norm: 1.3465305218328336\n",
      "Epoch 2533, Loss: 209.62046078142654, Neurons: 201, Grad norm: 1.739556818431088\n",
      "Epoch 2533, Loss: 209.62046078142654, Neurons: 201, Grad norm: 1.739556818431088\n",
      "Epoch 2534, Loss: 209.61981477384796, Neurons: 201, Grad norm: 2.446337565035196\n",
      "Epoch 2534, Loss: 209.61981477384796, Neurons: 201, Grad norm: 2.446337565035196\n",
      "Epoch 2535, Loss: 209.61912478842828, Neurons: 201, Grad norm: 2.313674622393902\n",
      "Epoch 2535, Loss: 209.61912478842828, Neurons: 201, Grad norm: 2.313674622393902\n",
      "Epoch 2536, Loss: 209.61841740437202, Neurons: 201, Grad norm: 2.778077726294984\n",
      "Epoch 2536, Loss: 209.61841740437202, Neurons: 201, Grad norm: 2.778077726294984\n",
      "Epoch 2537, Loss: 209.61773643564518, Neurons: 201, Grad norm: 2.302022720755449\n",
      "Epoch 2537, Loss: 209.61773643564518, Neurons: 201, Grad norm: 2.302022720755449\n",
      "Epoch 2538, Loss: 209.61699724572358, Neurons: 201, Grad norm: 2.0941342687001994\n",
      "Epoch 2538, Loss: 209.61699724572358, Neurons: 201, Grad norm: 2.0941342687001994\n",
      "Epoch 2539, Loss: 209.61620588373674, Neurons: 201, Grad norm: 1.188894262237113\n",
      "Epoch 2539, Loss: 209.61620588373674, Neurons: 201, Grad norm: 1.188894262237113\n",
      "Epoch 2540, Loss: 209.61542643479916, Neurons: 201, Grad norm: 0.935822899427936\n",
      "Epoch 2540, Loss: 209.61542643479916, Neurons: 201, Grad norm: 0.935822899427936\n",
      "Epoch 2541, Loss: 209.6146904280078, Neurons: 201, Grad norm: 1.2500360216153188\n",
      "Epoch 2541, Loss: 209.6146904280078, Neurons: 201, Grad norm: 1.2500360216153188\n",
      "Epoch 2542, Loss: 209.6139810148172, Neurons: 201, Grad norm: 1.5900795264767298\n",
      "Epoch 2542, Loss: 209.6139810148172, Neurons: 201, Grad norm: 1.5900795264767298\n",
      "Epoch 2543, Loss: 209.6133460416288, Neurons: 201, Grad norm: 2.850124517928668\n",
      "Epoch 2543, Loss: 209.6133460416288, Neurons: 201, Grad norm: 2.850124517928668\n",
      "Epoch 2544, Loss: 209.61277287923238, Neurons: 201, Grad norm: 3.114113163487351\n",
      "Epoch 2544, Loss: 209.61277287923238, Neurons: 201, Grad norm: 3.114113163487351\n",
      "Epoch 2545, Loss: 209.61221846905102, Neurons: 201, Grad norm: 3.5987367696166306\n",
      "Epoch 2545, Loss: 209.61221846905102, Neurons: 201, Grad norm: 3.5987367696166306\n",
      "Epoch 2546, Loss: 209.61156193559907, Neurons: 201, Grad norm: 2.734029319781998\n",
      "Epoch 2546, Loss: 209.61156193559907, Neurons: 201, Grad norm: 2.734029319781998\n",
      "Epoch 2547, Loss: 209.61072215016023, Neurons: 201, Grad norm: 2.0938233439824248\n",
      "Epoch 2547, Loss: 209.61072215016023, Neurons: 201, Grad norm: 2.0938233439824248\n",
      "Epoch 2548, Loss: 209.60989589427803, Neurons: 201, Grad norm: 0.9073493643184103\n",
      "Epoch 2548, Loss: 209.60989589427803, Neurons: 201, Grad norm: 0.9073493643184103\n",
      "Epoch 2549, Loss: 209.60909076648292, Neurons: 201, Grad norm: 1.2230004549309954\n",
      "Epoch 2549, Loss: 209.60909076648292, Neurons: 201, Grad norm: 1.2230004549309954\n",
      "Epoch 2550, Loss: 209.60840619907182, Neurons: 201, Grad norm: 2.399298776014759\n",
      "Epoch 2550, Loss: 209.60840619907182, Neurons: 201, Grad norm: 2.399298776014759\n",
      "Epoch 2551, Loss: 209.60778836004656, Neurons: 201, Grad norm: 2.5852523132290934\n",
      "Epoch 2551, Loss: 209.60778836004656, Neurons: 201, Grad norm: 2.5852523132290934\n",
      "Epoch 2552, Loss: 209.6071539064119, Neurons: 201, Grad norm: 3.01295550166063\n",
      "Epoch 2552, Loss: 209.6071539064119, Neurons: 201, Grad norm: 3.01295550166063\n",
      "Epoch 2553, Loss: 209.6064327792047, Neurons: 201, Grad norm: 2.248738134506873\n",
      "Epoch 2553, Loss: 209.6064327792047, Neurons: 201, Grad norm: 2.248738134506873\n",
      "Epoch 2554, Loss: 209.60561529225473, Neurons: 201, Grad norm: 1.996181412090379\n",
      "Epoch 2554, Loss: 209.60561529225473, Neurons: 201, Grad norm: 1.996181412090379\n",
      "Epoch 2555, Loss: 209.60475200495026, Neurons: 201, Grad norm: 1.1280520771581866\n",
      "Epoch 2555, Loss: 209.60475200495026, Neurons: 201, Grad norm: 1.1280520771581866\n",
      "Epoch 2556, Loss: 209.6039056121186, Neurons: 201, Grad norm: 0.9602152265759506\n",
      "Epoch 2556, Loss: 209.6039056121186, Neurons: 201, Grad norm: 0.9602152265759506\n",
      "Epoch 2557, Loss: 209.60314168468736, Neurons: 201, Grad norm: 1.7008100491691398\n",
      "Epoch 2557, Loss: 209.60314168468736, Neurons: 201, Grad norm: 1.7008100491691398\n",
      "Epoch 2558, Loss: 209.6024328640661, Neurons: 201, Grad norm: 2.0940202687122667\n",
      "Epoch 2558, Loss: 209.6024328640661, Neurons: 201, Grad norm: 2.0940202687122667\n",
      "Epoch 2559, Loss: 209.601755949996, Neurons: 201, Grad norm: 2.9184950997173082\n",
      "Epoch 2559, Loss: 209.601755949996, Neurons: 201, Grad norm: 2.9184950997173082\n",
      "Epoch 2560, Loss: 209.60104561658738, Neurons: 201, Grad norm: 2.7186473170896495\n",
      "Epoch 2560, Loss: 209.60104561658738, Neurons: 201, Grad norm: 2.7186473170896495\n",
      "Epoch 2561, Loss: 209.60020954004906, Neurons: 201, Grad norm: 2.742357809186893\n",
      "Epoch 2561, Loss: 209.60020954004906, Neurons: 201, Grad norm: 2.742357809186893\n",
      "Epoch 2562, Loss: 209.5992492295557, Neurons: 201, Grad norm: 1.6550460179726514\n",
      "Epoch 2562, Loss: 209.5992492295557, Neurons: 201, Grad norm: 1.6550460179726514\n",
      "Epoch 2563, Loss: 209.59819262874848, Neurons: 201, Grad norm: 1.203852355792601\n",
      "Epoch 2563, Loss: 209.59819262874848, Neurons: 201, Grad norm: 1.203852355792601\n",
      "Epoch 2564, Loss: 209.5971158716484, Neurons: 201, Grad norm: 1.5298366273252633\n",
      "Epoch 2564, Loss: 209.5971158716484, Neurons: 201, Grad norm: 1.5298366273252633\n",
      "Epoch 2565, Loss: 209.59607557652873, Neurons: 201, Grad norm: 1.8337908197665211\n",
      "Epoch 2565, Loss: 209.59607557652873, Neurons: 201, Grad norm: 1.8337908197665211\n",
      "Epoch 2566, Loss: 209.59500841588272, Neurons: 201, Grad norm: 2.119856500063292\n",
      "Epoch 2566, Loss: 209.59500841588272, Neurons: 201, Grad norm: 2.119856500063292\n",
      "Epoch 2567, Loss: 209.59371518382937, Neurons: 201, Grad norm: 1.4284088665055508\n",
      "Epoch 2567, Loss: 209.59371518382937, Neurons: 201, Grad norm: 1.4284088665055508\n",
      "Epoch 2568, Loss: 209.59233913945633, Neurons: 201, Grad norm: 1.115232570315856\n",
      "Epoch 2568, Loss: 209.59233913945633, Neurons: 201, Grad norm: 1.115232570315856\n",
      "Epoch 2569, Loss: 209.59098601744816, Neurons: 201, Grad norm: 1.2302731673898057\n",
      "Epoch 2569, Loss: 209.59098601744816, Neurons: 201, Grad norm: 1.2302731673898057\n",
      "Epoch 2570, Loss: 209.58994998518975, Neurons: 201, Grad norm: 1.4262872287018211\n",
      "Epoch 2570, Loss: 209.58994998518975, Neurons: 201, Grad norm: 1.4262872287018211\n",
      "Epoch 2571, Loss: 209.58914516918628, Neurons: 201, Grad norm: 2.2022129702192457\n",
      "Epoch 2571, Loss: 209.58914516918628, Neurons: 201, Grad norm: 2.2022129702192457\n",
      "Epoch 2572, Loss: 209.58843478591615, Neurons: 201, Grad norm: 2.0471341313653353\n",
      "Epoch 2572, Loss: 209.58843478591615, Neurons: 201, Grad norm: 2.0471341313653353\n",
      "Epoch 2573, Loss: 209.58785308429094, Neurons: 201, Grad norm: 2.107930577139835\n",
      "Epoch 2573, Loss: 209.58785308429094, Neurons: 201, Grad norm: 2.107930577139835\n",
      "Epoch 2574, Loss: 209.5873307372576, Neurons: 201, Grad norm: 1.3572272838440522\n",
      "Epoch 2574, Loss: 209.5873307372576, Neurons: 201, Grad norm: 1.3572272838440522\n",
      "Epoch 2575, Loss: 209.58666279351453, Neurons: 201, Grad norm: 1.1764926586849234\n",
      "Epoch 2575, Loss: 209.58666279351453, Neurons: 201, Grad norm: 1.1764926586849234\n",
      "Epoch 2576, Loss: 209.58599675757011, Neurons: 201, Grad norm: 1.536875174150694\n",
      "Epoch 2576, Loss: 209.58599675757011, Neurons: 201, Grad norm: 1.536875174150694\n",
      "Epoch 2577, Loss: 209.58531557447574, Neurons: 201, Grad norm: 1.9949245551769175\n",
      "Epoch 2577, Loss: 209.58531557447574, Neurons: 201, Grad norm: 1.9949245551769175\n",
      "Epoch 2578, Loss: 209.58463062461544, Neurons: 201, Grad norm: 2.6638017470651216\n",
      "Epoch 2578, Loss: 209.58463062461544, Neurons: 201, Grad norm: 2.6638017470651216\n",
      "Epoch 2579, Loss: 209.58392438300552, Neurons: 201, Grad norm: 2.396913034812782\n",
      "Epoch 2579, Loss: 209.58392438300552, Neurons: 201, Grad norm: 2.396913034812782\n",
      "Epoch 2580, Loss: 209.58310208543256, Neurons: 201, Grad norm: 2.2680531876418426\n",
      "Epoch 2580, Loss: 209.58310208543256, Neurons: 201, Grad norm: 2.2680531876418426\n",
      "Epoch 2581, Loss: 209.58220833445566, Neurons: 201, Grad norm: 1.3283499163623846\n",
      "Epoch 2581, Loss: 209.58220833445566, Neurons: 201, Grad norm: 1.3283499163623846\n",
      "Epoch 2582, Loss: 209.58125236938702, Neurons: 201, Grad norm: 1.1216486557186505\n",
      "Epoch 2582, Loss: 209.58125236938702, Neurons: 201, Grad norm: 1.1216486557186505\n",
      "Epoch 2583, Loss: 209.58031895811223, Neurons: 201, Grad norm: 1.5345977377515125\n",
      "Epoch 2583, Loss: 209.58031895811223, Neurons: 201, Grad norm: 1.5345977377515125\n",
      "Epoch 2584, Loss: 209.57946098365616, Neurons: 201, Grad norm: 1.5494699677392163\n",
      "Epoch 2584, Loss: 209.57946098365616, Neurons: 201, Grad norm: 1.5494699677392163\n",
      "Epoch 2585, Loss: 209.57882431349128, Neurons: 201, Grad norm: 1.91686961755745\n",
      "Epoch 2585, Loss: 209.57882431349128, Neurons: 201, Grad norm: 1.91686961755745\n",
      "Epoch 2586, Loss: 209.57813789405373, Neurons: 201, Grad norm: 1.3723171094829276\n",
      "Epoch 2586, Loss: 209.57813789405373, Neurons: 201, Grad norm: 1.3723171094829276\n",
      "Epoch 2587, Loss: 209.57743776611534, Neurons: 201, Grad norm: 1.2727459469383549\n",
      "Epoch 2587, Loss: 209.57743776611534, Neurons: 201, Grad norm: 1.2727459469383549\n",
      "Epoch 2588, Loss: 209.57674824916703, Neurons: 201, Grad norm: 0.951596932458419\n",
      "Epoch 2588, Loss: 209.57674824916703, Neurons: 201, Grad norm: 0.951596932458419\n",
      "Epoch 2589, Loss: 209.57606070551552, Neurons: 201, Grad norm: 0.9934596665812809\n",
      "Epoch 2589, Loss: 209.57606070551552, Neurons: 201, Grad norm: 0.9934596665812809\n",
      "Epoch 2590, Loss: 209.5753873648311, Neurons: 201, Grad norm: 0.9370781002704937\n",
      "Epoch 2590, Loss: 209.5753873648311, Neurons: 201, Grad norm: 0.9370781002704937\n",
      "Epoch 2591, Loss: 209.57469149642318, Neurons: 201, Grad norm: 0.9447369699169201\n",
      "Epoch 2591, Loss: 209.57469149642318, Neurons: 201, Grad norm: 0.9447369699169201\n",
      "Epoch 2592, Loss: 209.57396726667676, Neurons: 201, Grad norm: 0.9926954401752467\n",
      "Epoch 2592, Loss: 209.57396726667676, Neurons: 201, Grad norm: 0.9926954401752467\n",
      "Epoch 2593, Loss: 209.57326397596367, Neurons: 201, Grad norm: 0.972989809118161\n",
      "Epoch 2593, Loss: 209.57326397596367, Neurons: 201, Grad norm: 0.972989809118161\n",
      "Epoch 2594, Loss: 209.57255269359214, Neurons: 201, Grad norm: 1.0725879731084418\n",
      "Epoch 2594, Loss: 209.57255269359214, Neurons: 201, Grad norm: 1.0725879731084418\n",
      "Epoch 2595, Loss: 209.5717822303546, Neurons: 201, Grad norm: 1.0049840878804377\n",
      "Epoch 2595, Loss: 209.5717822303546, Neurons: 201, Grad norm: 1.0049840878804377\n",
      "Epoch 2596, Loss: 209.57103433046723, Neurons: 201, Grad norm: 1.3282278502956013\n",
      "Epoch 2596, Loss: 209.57103433046723, Neurons: 201, Grad norm: 1.3282278502956013\n",
      "Epoch 2597, Loss: 209.57027812075032, Neurons: 201, Grad norm: 1.1215554815050266\n",
      "Epoch 2597, Loss: 209.57027812075032, Neurons: 201, Grad norm: 1.1215554815050266\n",
      "Epoch 2598, Loss: 209.5695238056588, Neurons: 201, Grad norm: 1.5082228646267524\n",
      "Epoch 2598, Loss: 209.5695238056588, Neurons: 201, Grad norm: 1.5082228646267524\n",
      "Epoch 2599, Loss: 209.56877235076107, Neurons: 201, Grad norm: 1.4150195186110388\n",
      "Epoch 2599, Loss: 209.56877235076107, Neurons: 201, Grad norm: 1.4150195186110388\n",
      "Epoch 2600, Loss: 209.5680318414441, Neurons: 201, Grad norm: 1.9362037559762173\n",
      "Epoch 2600, Loss: 209.5680318414441, Neurons: 201, Grad norm: 1.9362037559762173\n",
      "Epoch 2601, Loss: 209.56730269399137, Neurons: 201, Grad norm: 1.9256219481216732\n",
      "Epoch 2601, Loss: 209.56730269399137, Neurons: 201, Grad norm: 1.9256219481216732\n",
      "Epoch 2602, Loss: 209.56662486053605, Neurons: 201, Grad norm: 2.1523533628606586\n",
      "Epoch 2602, Loss: 209.56662486053605, Neurons: 201, Grad norm: 2.1523533628606586\n",
      "Epoch 2603, Loss: 209.5659748329079, Neurons: 201, Grad norm: 1.7445370545077523\n",
      "Epoch 2603, Loss: 209.5659748329079, Neurons: 201, Grad norm: 1.7445370545077523\n",
      "Epoch 2604, Loss: 209.56527033722065, Neurons: 201, Grad norm: 1.800883068401144\n",
      "Epoch 2604, Loss: 209.56527033722065, Neurons: 201, Grad norm: 1.800883068401144\n",
      "Epoch 2605, Loss: 209.5644989275626, Neurons: 201, Grad norm: 1.0320164115658863\n",
      "Epoch 2605, Loss: 209.5644989275626, Neurons: 201, Grad norm: 1.0320164115658863\n",
      "Epoch 2606, Loss: 209.56370270552446, Neurons: 201, Grad norm: 1.0554440332179462\n",
      "Epoch 2606, Loss: 209.56370270552446, Neurons: 201, Grad norm: 1.0554440332179462\n",
      "Epoch 2607, Loss: 209.56292182468994, Neurons: 201, Grad norm: 1.2288728542982477\n",
      "Epoch 2607, Loss: 209.56292182468994, Neurons: 201, Grad norm: 1.2288728542982477\n",
      "Epoch 2608, Loss: 209.56221047105203, Neurons: 201, Grad norm: 1.1405980351250444\n",
      "Epoch 2608, Loss: 209.56221047105203, Neurons: 201, Grad norm: 1.1405980351250444\n",
      "Epoch 2609, Loss: 209.56152582015088, Neurons: 201, Grad norm: 1.5691161181099733\n",
      "Epoch 2609, Loss: 209.56152582015088, Neurons: 201, Grad norm: 1.5691161181099733\n",
      "Epoch 2610, Loss: 209.56083668027824, Neurons: 201, Grad norm: 1.4108632596379298\n",
      "Epoch 2610, Loss: 209.56083668027824, Neurons: 201, Grad norm: 1.4108632596379298\n",
      "Epoch 2611, Loss: 209.5601181769474, Neurons: 201, Grad norm: 1.826122686176423\n",
      "Epoch 2611, Loss: 209.5601181769474, Neurons: 201, Grad norm: 1.826122686176423\n",
      "Epoch 2612, Loss: 209.55939004656906, Neurons: 201, Grad norm: 1.7007420778307332\n",
      "Epoch 2612, Loss: 209.55939004656906, Neurons: 201, Grad norm: 1.7007420778307332\n",
      "Epoch 2613, Loss: 209.55864557107375, Neurons: 201, Grad norm: 2.275036156782055\n",
      "Epoch 2613, Loss: 209.55864557107375, Neurons: 201, Grad norm: 2.275036156782055\n",
      "Epoch 2614, Loss: 209.5578947967482, Neurons: 201, Grad norm: 2.381530085625729\n",
      "Epoch 2614, Loss: 209.5578947967482, Neurons: 201, Grad norm: 2.381530085625729\n",
      "Epoch 2615, Loss: 209.55721580764032, Neurons: 201, Grad norm: 3.1036401598007273\n",
      "Epoch 2615, Loss: 209.55721580764032, Neurons: 201, Grad norm: 3.1036401598007273\n",
      "Epoch 2616, Loss: 209.55655883791258, Neurons: 201, Grad norm: 2.996787939041359\n",
      "Epoch 2616, Loss: 209.55655883791258, Neurons: 201, Grad norm: 2.996787939041359\n",
      "Epoch 2617, Loss: 209.5558392443947, Neurons: 201, Grad norm: 3.260595878394138\n",
      "Epoch 2617, Loss: 209.5558392443947, Neurons: 201, Grad norm: 3.260595878394138\n",
      "Epoch 2618, Loss: 209.55507383881067, Neurons: 201, Grad norm: 2.442647333468152\n",
      "Epoch 2618, Loss: 209.55507383881067, Neurons: 201, Grad norm: 2.442647333468152\n",
      "Epoch 2619, Loss: 209.5542081679869, Neurons: 201, Grad norm: 2.2148516286781175\n",
      "Epoch 2619, Loss: 209.5542081679869, Neurons: 201, Grad norm: 2.2148516286781175\n",
      "Epoch 2620, Loss: 209.55332865807648, Neurons: 201, Grad norm: 1.2766559672230569\n",
      "Epoch 2620, Loss: 209.55332865807648, Neurons: 201, Grad norm: 1.2766559672230569\n",
      "Epoch 2621, Loss: 209.55251992270792, Neurons: 201, Grad norm: 1.0474450750681366\n",
      "Epoch 2621, Loss: 209.55251992270792, Neurons: 201, Grad norm: 1.0474450750681366\n",
      "Epoch 2622, Loss: 209.55177280749234, Neurons: 201, Grad norm: 1.2101942712381433\n",
      "Epoch 2622, Loss: 209.55177280749234, Neurons: 201, Grad norm: 1.2101942712381433\n",
      "Epoch 2623, Loss: 209.55104655830735, Neurons: 201, Grad norm: 1.4331202663143865\n",
      "Epoch 2623, Loss: 209.55104655830735, Neurons: 201, Grad norm: 1.4331202663143865\n",
      "Epoch 2624, Loss: 209.55033791536033, Neurons: 201, Grad norm: 2.427303829888632\n",
      "Epoch 2624, Loss: 209.55033791536033, Neurons: 201, Grad norm: 2.427303829888632\n",
      "Epoch 2625, Loss: 209.54964035983122, Neurons: 201, Grad norm: 2.8551072177187873\n",
      "Epoch 2625, Loss: 209.54964035983122, Neurons: 201, Grad norm: 2.8551072177187873\n",
      "Epoch 2626, Loss: 209.54907600806197, Neurons: 201, Grad norm: 3.847835753543793\n",
      "Epoch 2626, Loss: 209.54907600806197, Neurons: 201, Grad norm: 3.847835753543793\n",
      "Epoch 2627, Loss: 209.5484840898792, Neurons: 201, Grad norm: 3.6537896056782824\n",
      "Epoch 2627, Loss: 209.5484840898792, Neurons: 201, Grad norm: 3.6537896056782824\n",
      "Epoch 2628, Loss: 209.5478153497416, Neurons: 201, Grad norm: 3.8440977551642073\n",
      "Epoch 2628, Loss: 209.5478153497416, Neurons: 201, Grad norm: 3.8440977551642073\n",
      "Epoch 2629, Loss: 209.54705691919824, Neurons: 201, Grad norm: 2.6158192390230046\n",
      "Epoch 2629, Loss: 209.54705691919824, Neurons: 201, Grad norm: 2.6158192390230046\n",
      "Epoch 2630, Loss: 209.54620259029144, Neurons: 201, Grad norm: 1.641790199154282\n",
      "Epoch 2630, Loss: 209.54620259029144, Neurons: 201, Grad norm: 1.641790199154282\n",
      "Epoch 2631, Loss: 209.54531869561131, Neurons: 201, Grad norm: 1.213539193283602\n",
      "Epoch 2631, Loss: 209.54531869561131, Neurons: 201, Grad norm: 1.213539193283602\n",
      "Epoch 2632, Loss: 209.54457340079395, Neurons: 201, Grad norm: 2.2705095646778233\n",
      "Epoch 2632, Loss: 209.54457340079395, Neurons: 201, Grad norm: 2.2705095646778233\n",
      "Epoch 2633, Loss: 209.5440069649772, Neurons: 201, Grad norm: 3.9648068528685863\n",
      "Epoch 2633, Loss: 209.5440069649772, Neurons: 201, Grad norm: 3.9648068528685863\n",
      "Epoch 2634, Loss: 209.54360118851758, Neurons: 201, Grad norm: 4.295899839669259\n",
      "Epoch 2634, Loss: 209.54360118851758, Neurons: 201, Grad norm: 4.295899839669259\n",
      "Epoch 2635, Loss: 209.54316827481193, Neurons: 201, Grad norm: 4.797741053321343\n",
      "Epoch 2635, Loss: 209.54316827481193, Neurons: 201, Grad norm: 4.797741053321343\n",
      "Epoch 2636, Loss: 209.5424386657644, Neurons: 201, Grad norm: 3.810278500418339\n",
      "Epoch 2636, Loss: 209.5424386657644, Neurons: 201, Grad norm: 3.810278500418339\n",
      "Epoch 2637, Loss: 209.54158616129715, Neurons: 201, Grad norm: 2.945915392286433\n",
      "Epoch 2637, Loss: 209.54158616129715, Neurons: 201, Grad norm: 2.945915392286433\n",
      "Epoch 2638, Loss: 209.54058477798446, Neurons: 201, Grad norm: 1.1166185899717183\n",
      "Epoch 2638, Loss: 209.54058477798446, Neurons: 201, Grad norm: 1.1166185899717183\n",
      "Epoch 2639, Loss: 209.5397207941382, Neurons: 201, Grad norm: 1.356730454136654\n",
      "Epoch 2639, Loss: 209.5397207941382, Neurons: 201, Grad norm: 1.356730454136654\n",
      "Epoch 2640, Loss: 209.53905630417756, Neurons: 201, Grad norm: 3.0062589625017924\n",
      "Epoch 2640, Loss: 209.53905630417756, Neurons: 201, Grad norm: 3.0062589625017924\n",
      "Epoch 2641, Loss: 209.53858984049378, Neurons: 201, Grad norm: 3.6868259296844905\n",
      "Epoch 2641, Loss: 209.53858984049378, Neurons: 201, Grad norm: 3.6868259296844905\n",
      "Epoch 2642, Loss: 209.53808763242156, Neurons: 201, Grad norm: 4.296201089646825\n",
      "Epoch 2642, Loss: 209.53808763242156, Neurons: 201, Grad norm: 4.296201089646825\n",
      "Epoch 2643, Loss: 209.53745455648965, Neurons: 201, Grad norm: 3.532047660850003\n",
      "Epoch 2643, Loss: 209.53745455648965, Neurons: 201, Grad norm: 3.532047660850003\n",
      "Epoch 2644, Loss: 209.53664732676347, Neurons: 201, Grad norm: 2.672326379191306\n",
      "Epoch 2644, Loss: 209.53664732676347, Neurons: 201, Grad norm: 2.672326379191306\n",
      "Epoch 2645, Loss: 209.53574447527532, Neurons: 201, Grad norm: 1.0062534839310102\n",
      "Epoch 2645, Loss: 209.53574447527532, Neurons: 201, Grad norm: 1.0062534839310102\n",
      "Epoch 2646, Loss: 209.53490107418625, Neurons: 201, Grad norm: 1.3303529172606452\n",
      "Epoch 2646, Loss: 209.53490107418625, Neurons: 201, Grad norm: 1.3303529172606452\n",
      "Epoch 2647, Loss: 209.53423633607227, Neurons: 201, Grad norm: 2.9806464093303444\n",
      "Epoch 2647, Loss: 209.53423633607227, Neurons: 201, Grad norm: 2.9806464093303444\n",
      "Epoch 2648, Loss: 209.5337284952138, Neurons: 201, Grad norm: 3.2519136099446526\n",
      "Epoch 2648, Loss: 209.5337284952138, Neurons: 201, Grad norm: 3.2519136099446526\n",
      "Epoch 2649, Loss: 209.53321849867245, Neurons: 201, Grad norm: 3.563595802819005\n",
      "Epoch 2649, Loss: 209.53321849867245, Neurons: 201, Grad norm: 3.563595802819005\n",
      "Epoch 2650, Loss: 209.53250467646305, Neurons: 201, Grad norm: 2.343167203681212\n",
      "Epoch 2650, Loss: 209.53250467646305, Neurons: 201, Grad norm: 2.343167203681212\n",
      "Epoch 2651, Loss: 209.53173037796685, Neurons: 201, Grad norm: 1.3639959192582753\n",
      "Epoch 2651, Loss: 209.53173037796685, Neurons: 201, Grad norm: 1.3639959192582753\n",
      "Epoch 2652, Loss: 209.53091189278695, Neurons: 201, Grad norm: 1.4419764173939698\n",
      "Epoch 2652, Loss: 209.53091189278695, Neurons: 201, Grad norm: 1.4419764173939698\n",
      "Epoch 2653, Loss: 209.53024181370893, Neurons: 201, Grad norm: 2.3433865731263195\n",
      "Epoch 2653, Loss: 209.53024181370893, Neurons: 201, Grad norm: 2.3433865731263195\n",
      "Epoch 2654, Loss: 209.52971519606095, Neurons: 201, Grad norm: 3.487135157452142\n",
      "Epoch 2654, Loss: 209.52971519606095, Neurons: 201, Grad norm: 3.487135157452142\n",
      "Epoch 2655, Loss: 209.52918451468307, Neurons: 201, Grad norm: 2.982343677115177\n",
      "Epoch 2655, Loss: 209.52918451468307, Neurons: 201, Grad norm: 2.982343677115177\n",
      "Epoch 2656, Loss: 209.5284929597537, Neurons: 201, Grad norm: 2.6086515438792985\n",
      "Epoch 2656, Loss: 209.5284929597537, Neurons: 201, Grad norm: 2.6086515438792985\n",
      "Epoch 2657, Loss: 209.52768856114616, Neurons: 201, Grad norm: 1.109240798294588\n",
      "Epoch 2657, Loss: 209.52768856114616, Neurons: 201, Grad norm: 1.109240798294588\n",
      "Epoch 2658, Loss: 209.52689994840676, Neurons: 201, Grad norm: 1.0277643509866772\n",
      "Epoch 2658, Loss: 209.52689994840676, Neurons: 201, Grad norm: 1.0277643509866772\n",
      "Epoch 2659, Loss: 209.5262330397568, Neurons: 201, Grad norm: 2.1729497830596882\n",
      "Epoch 2659, Loss: 209.5262330397568, Neurons: 201, Grad norm: 2.1729497830596882\n",
      "Epoch 2660, Loss: 209.52565954320286, Neurons: 201, Grad norm: 2.4391247699164462\n",
      "Epoch 2660, Loss: 209.52565954320286, Neurons: 201, Grad norm: 2.4391247699164462\n",
      "Epoch 2661, Loss: 209.52507664861565, Neurons: 201, Grad norm: 3.0726521633815693\n",
      "Epoch 2661, Loss: 209.52507664861565, Neurons: 201, Grad norm: 3.0726521633815693\n",
      "Epoch 2662, Loss: 209.52439827853897, Neurons: 201, Grad norm: 2.457841116546626\n",
      "Epoch 2662, Loss: 209.52439827853897, Neurons: 201, Grad norm: 2.457841116546626\n",
      "Epoch 2663, Loss: 209.52375918983395, Neurons: 201, Grad norm: 2.3730538239975405\n",
      "Epoch 2663, Loss: 209.52375918983395, Neurons: 201, Grad norm: 2.3730538239975405\n",
      "Epoch 2664, Loss: 209.52300335993718, Neurons: 201, Grad norm: 1.320849184115186\n",
      "Epoch 2664, Loss: 209.52300335993718, Neurons: 201, Grad norm: 1.320849184115186\n",
      "Epoch 2665, Loss: 209.52227513737733, Neurons: 201, Grad norm: 0.9962585377591601\n",
      "Epoch 2665, Loss: 209.52227513737733, Neurons: 201, Grad norm: 0.9962585377591601\n",
      "Epoch 2666, Loss: 209.52158214149864, Neurons: 201, Grad norm: 1.2936959719649623\n",
      "Epoch 2666, Loss: 209.52158214149864, Neurons: 201, Grad norm: 1.2936959719649623\n",
      "Epoch 2667, Loss: 209.52095297291459, Neurons: 201, Grad norm: 1.560073177691692\n",
      "Epoch 2667, Loss: 209.52095297291459, Neurons: 201, Grad norm: 1.560073177691692\n",
      "Epoch 2668, Loss: 209.52037166538312, Neurons: 201, Grad norm: 2.5713157930512867\n",
      "Epoch 2668, Loss: 209.52037166538312, Neurons: 201, Grad norm: 2.5713157930512867\n",
      "Epoch 2669, Loss: 209.51980189721903, Neurons: 201, Grad norm: 2.5018779381890806\n",
      "Epoch 2669, Loss: 209.51980189721903, Neurons: 201, Grad norm: 2.5018779381890806\n",
      "Epoch 2670, Loss: 209.51920328145425, Neurons: 201, Grad norm: 2.5856451019235647\n",
      "Epoch 2670, Loss: 209.51920328145425, Neurons: 201, Grad norm: 2.5856451019235647\n",
      "Epoch 2671, Loss: 209.51856432663797, Neurons: 201, Grad norm: 1.877975077615365\n",
      "Epoch 2671, Loss: 209.51856432663797, Neurons: 201, Grad norm: 1.877975077615365\n",
      "Epoch 2672, Loss: 209.51789759991524, Neurons: 201, Grad norm: 1.4023320356094227\n",
      "Epoch 2672, Loss: 209.51789759991524, Neurons: 201, Grad norm: 1.4023320356094227\n",
      "Epoch 2673, Loss: 209.5172238323555, Neurons: 201, Grad norm: 0.8989112702359535\n",
      "Epoch 2673, Loss: 209.5172238323555, Neurons: 201, Grad norm: 0.8989112702359535\n",
      "Epoch 2674, Loss: 209.5165816180938, Neurons: 201, Grad norm: 1.0988744566069912\n",
      "Epoch 2674, Loss: 209.5165816180938, Neurons: 201, Grad norm: 1.0988744566069912\n",
      "Epoch 2675, Loss: 209.5159678249985, Neurons: 201, Grad norm: 1.807007385197805\n",
      "Epoch 2675, Loss: 209.5159678249985, Neurons: 201, Grad norm: 1.807007385197805\n",
      "Epoch 2676, Loss: 209.51538388772568, Neurons: 201, Grad norm: 1.8059875697544199\n",
      "Epoch 2676, Loss: 209.51538388772568, Neurons: 201, Grad norm: 1.8059875697544199\n",
      "Epoch 2677, Loss: 209.51482780747963, Neurons: 201, Grad norm: 2.0720326475157793\n",
      "Epoch 2677, Loss: 209.51482780747963, Neurons: 201, Grad norm: 2.0720326475157793\n",
      "Epoch 2678, Loss: 209.51419042890512, Neurons: 201, Grad norm: 1.5338727298395731\n",
      "Epoch 2678, Loss: 209.51419042890512, Neurons: 201, Grad norm: 1.5338727298395731\n",
      "Epoch 2679, Loss: 209.51353103359787, Neurons: 201, Grad norm: 1.4143348086449543\n",
      "Epoch 2679, Loss: 209.51353103359787, Neurons: 201, Grad norm: 1.4143348086449543\n",
      "Epoch 2680, Loss: 209.51289138237718, Neurons: 201, Grad norm: 0.936565168009234\n",
      "Epoch 2680, Loss: 209.51289138237718, Neurons: 201, Grad norm: 0.936565168009234\n",
      "Epoch 2681, Loss: 209.51226268326084, Neurons: 201, Grad norm: 0.9859833953414473\n",
      "Epoch 2681, Loss: 209.51226268326084, Neurons: 201, Grad norm: 0.9859833953414473\n",
      "Epoch 2682, Loss: 209.5116335394639, Neurons: 201, Grad norm: 0.8716874002189888\n",
      "Epoch 2682, Loss: 209.5116335394639, Neurons: 201, Grad norm: 0.8716874002189888\n",
      "Epoch 2683, Loss: 209.51099489155143, Neurons: 201, Grad norm: 0.8245338350846075\n",
      "Epoch 2683, Loss: 209.51099489155143, Neurons: 201, Grad norm: 0.8245338350846075\n",
      "Epoch 2684, Loss: 209.51036619228802, Neurons: 201, Grad norm: 0.9570704627935419\n",
      "Epoch 2684, Loss: 209.51036619228802, Neurons: 201, Grad norm: 0.9570704627935419\n",
      "Epoch 2685, Loss: 209.50978426460188, Neurons: 201, Grad norm: 0.9339182507858397\n",
      "Epoch 2685, Loss: 209.50978426460188, Neurons: 201, Grad norm: 0.9339182507858397\n",
      "Epoch 2686, Loss: 209.50917336263498, Neurons: 201, Grad norm: 1.088173262343538\n",
      "Epoch 2686, Loss: 209.50917336263498, Neurons: 201, Grad norm: 1.088173262343538\n",
      "Epoch 2687, Loss: 209.50856822561113, Neurons: 201, Grad norm: 0.9807092593938674\n",
      "Epoch 2687, Loss: 209.50856822561113, Neurons: 201, Grad norm: 0.9807092593938674\n",
      "Epoch 2688, Loss: 209.50794951394462, Neurons: 201, Grad norm: 1.3164035602812327\n",
      "Epoch 2688, Loss: 209.50794951394462, Neurons: 201, Grad norm: 1.3164035602812327\n",
      "Epoch 2689, Loss: 209.5073132237349, Neurons: 201, Grad norm: 1.161022711745344\n",
      "Epoch 2689, Loss: 209.5073132237349, Neurons: 201, Grad norm: 1.161022711745344\n",
      "Epoch 2690, Loss: 209.50666810578613, Neurons: 201, Grad norm: 1.5981666692945518\n",
      "Epoch 2690, Loss: 209.50666810578613, Neurons: 201, Grad norm: 1.5981666692945518\n",
      "Epoch 2691, Loss: 209.50602037567756, Neurons: 201, Grad norm: 1.4863767948883415\n",
      "Epoch 2691, Loss: 209.50602037567756, Neurons: 201, Grad norm: 1.4863767948883415\n",
      "Epoch 2692, Loss: 209.50534618587548, Neurons: 201, Grad norm: 1.9651745012190533\n",
      "Epoch 2692, Loss: 209.50534618587548, Neurons: 201, Grad norm: 1.9651745012190533\n",
      "Epoch 2693, Loss: 209.50470995172614, Neurons: 201, Grad norm: 1.8541741003464376\n",
      "Epoch 2693, Loss: 209.50470995172614, Neurons: 201, Grad norm: 1.8541741003464376\n",
      "Epoch 2694, Loss: 209.5040458916412, Neurons: 201, Grad norm: 2.2458119609240392\n",
      "Epoch 2694, Loss: 209.5040458916412, Neurons: 201, Grad norm: 2.2458119609240392\n",
      "Epoch 2695, Loss: 209.50337082245935, Neurons: 201, Grad norm: 1.9601008755959957\n",
      "Epoch 2695, Loss: 209.50337082245935, Neurons: 201, Grad norm: 1.9601008755959957\n",
      "Epoch 2696, Loss: 209.50273778202705, Neurons: 201, Grad norm: 2.1617209139210347\n",
      "Epoch 2696, Loss: 209.50273778202705, Neurons: 201, Grad norm: 2.1617209139210347\n",
      "Epoch 2697, Loss: 209.50211151309725, Neurons: 201, Grad norm: 1.669796824081825\n",
      "Epoch 2697, Loss: 209.50211151309725, Neurons: 201, Grad norm: 1.669796824081825\n",
      "Epoch 2698, Loss: 209.50146045716045, Neurons: 201, Grad norm: 1.627755300707357\n",
      "Epoch 2698, Loss: 209.50146045716045, Neurons: 201, Grad norm: 1.627755300707357\n",
      "Epoch 2699, Loss: 209.500811651709, Neurons: 201, Grad norm: 1.2074514532144245\n",
      "Epoch 2699, Loss: 209.500811651709, Neurons: 201, Grad norm: 1.2074514532144245\n",
      "Epoch 2700, Loss: 209.50013427528816, Neurons: 201, Grad norm: 1.2241746985665396\n",
      "Epoch 2700, Loss: 209.50013427528816, Neurons: 201, Grad norm: 1.2241746985665396\n",
      "Epoch 2701, Loss: 209.4994327673141, Neurons: 201, Grad norm: 0.9721349507198478\n",
      "Epoch 2701, Loss: 209.4994327673141, Neurons: 201, Grad norm: 0.9721349507198478\n",
      "Epoch 2702, Loss: 209.49869701095125, Neurons: 201, Grad norm: 1.1692019373847657\n",
      "Epoch 2702, Loss: 209.49869701095125, Neurons: 201, Grad norm: 1.1692019373847657\n",
      "Epoch 2703, Loss: 209.4979411204642, Neurons: 201, Grad norm: 1.0042904614919985\n",
      "Epoch 2703, Loss: 209.4979411204642, Neurons: 201, Grad norm: 1.0042904614919985\n",
      "Epoch 2704, Loss: 209.4971359363939, Neurons: 201, Grad norm: 1.1473727757146421\n",
      "Epoch 2704, Loss: 209.4971359363939, Neurons: 201, Grad norm: 1.1473727757146421\n",
      "Epoch 2705, Loss: 209.4962738011241, Neurons: 201, Grad norm: 1.0533989663424619\n",
      "Epoch 2705, Loss: 209.4962738011241, Neurons: 201, Grad norm: 1.0533989663424619\n",
      "Epoch 2706, Loss: 209.49537945741486, Neurons: 201, Grad norm: 1.0564133006841137\n",
      "Epoch 2706, Loss: 209.49537945741486, Neurons: 201, Grad norm: 1.0564133006841137\n",
      "Epoch 2707, Loss: 209.49447612653205, Neurons: 201, Grad norm: 1.1682421839994717\n",
      "Epoch 2707, Loss: 209.49447612653205, Neurons: 201, Grad norm: 1.1682421839994717\n",
      "Epoch 2708, Loss: 209.4935223506229, Neurons: 201, Grad norm: 1.2686955335874195\n",
      "Epoch 2708, Loss: 209.4935223506229, Neurons: 201, Grad norm: 1.2686955335874195\n",
      "Epoch 2709, Loss: 209.49254640647777, Neurons: 201, Grad norm: 2.0838542683428485\n",
      "Epoch 2709, Loss: 209.49254640647777, Neurons: 201, Grad norm: 2.0838542683428485\n",
      "Epoch 2710, Loss: 209.49149460227403, Neurons: 201, Grad norm: 2.496692232636212\n",
      "Epoch 2710, Loss: 209.49149460227403, Neurons: 201, Grad norm: 2.496692232636212\n",
      "Epoch 2711, Loss: 209.49044139540933, Neurons: 201, Grad norm: 3.814523114307329\n",
      "Epoch 2711, Loss: 209.49044139540933, Neurons: 201, Grad norm: 3.814523114307329\n",
      "Epoch 2712, Loss: 209.48934866335972, Neurons: 201, Grad norm: 4.163514489520566\n",
      "Epoch 2712, Loss: 209.48934866335972, Neurons: 201, Grad norm: 4.163514489520566\n",
      "Epoch 2713, Loss: 209.48832823898582, Neurons: 201, Grad norm: 4.9369220181901206\n",
      "Epoch 2713, Loss: 209.48832823898582, Neurons: 201, Grad norm: 4.9369220181901206\n",
      "Epoch 2714, Loss: 209.48723889677055, Neurons: 201, Grad norm: 4.255572835203466\n",
      "Epoch 2714, Loss: 209.48723889677055, Neurons: 201, Grad norm: 4.255572835203466\n",
      "Epoch 2715, Loss: 209.48618279264934, Neurons: 201, Grad norm: 3.557814739560116\n",
      "Epoch 2715, Loss: 209.48618279264934, Neurons: 201, Grad norm: 3.557814739560116\n",
      "Epoch 2716, Loss: 209.48499861264688, Neurons: 201, Grad norm: 1.6372401626609259\n",
      "Epoch 2716, Loss: 209.48499861264688, Neurons: 201, Grad norm: 1.6372401626609259\n",
      "Epoch 2717, Loss: 209.4839103765434, Neurons: 201, Grad norm: 1.0864865958107293\n",
      "Epoch 2717, Loss: 209.4839103765434, Neurons: 201, Grad norm: 1.0864865958107293\n",
      "Epoch 2718, Loss: 209.4832008995718, Neurons: 201, Grad norm: 2.637097539569994\n",
      "Epoch 2718, Loss: 209.4832008995718, Neurons: 201, Grad norm: 2.637097539569994\n",
      "Epoch 2719, Loss: 209.4826776803543, Neurons: 201, Grad norm: 3.3548675559609578\n",
      "Epoch 2719, Loss: 209.4826776803543, Neurons: 201, Grad norm: 3.3548675559609578\n",
      "Epoch 2720, Loss: 209.48216184323945, Neurons: 201, Grad norm: 3.3559159367881413\n",
      "Epoch 2720, Loss: 209.48216184323945, Neurons: 201, Grad norm: 3.3559159367881413\n",
      "Epoch 2721, Loss: 209.4816067675734, Neurons: 201, Grad norm: 2.1810796647925854\n",
      "Epoch 2721, Loss: 209.4816067675734, Neurons: 201, Grad norm: 2.1810796647925854\n",
      "Epoch 2722, Loss: 209.48091023607105, Neurons: 201, Grad norm: 1.2129585481718093\n",
      "Epoch 2722, Loss: 209.48091023607105, Neurons: 201, Grad norm: 1.2129585481718093\n",
      "Epoch 2723, Loss: 209.48025563623497, Neurons: 201, Grad norm: 1.8744248106638157\n",
      "Epoch 2723, Loss: 209.48025563623497, Neurons: 201, Grad norm: 1.8744248106638157\n",
      "Epoch 2724, Loss: 209.47973287428346, Neurons: 201, Grad norm: 2.4817669268401192\n",
      "Epoch 2724, Loss: 209.47973287428346, Neurons: 201, Grad norm: 2.4817669268401192\n",
      "Epoch 2725, Loss: 209.47917844983388, Neurons: 201, Grad norm: 2.983154012376978\n",
      "Epoch 2725, Loss: 209.47917844983388, Neurons: 201, Grad norm: 2.983154012376978\n",
      "Epoch 2726, Loss: 209.4785562019262, Neurons: 201, Grad norm: 2.367180196216902\n",
      "Epoch 2726, Loss: 209.4785562019262, Neurons: 201, Grad norm: 2.367180196216902\n",
      "Epoch 2727, Loss: 209.47776857373245, Neurons: 201, Grad norm: 2.0796127835884746\n",
      "Epoch 2727, Loss: 209.47776857373245, Neurons: 201, Grad norm: 2.0796127835884746\n",
      "Epoch 2728, Loss: 209.4769528697685, Neurons: 201, Grad norm: 1.213725506922866\n",
      "Epoch 2728, Loss: 209.4769528697685, Neurons: 201, Grad norm: 1.213725506922866\n",
      "Epoch 2729, Loss: 209.47618554055398, Neurons: 201, Grad norm: 1.0974256164976168\n",
      "Epoch 2729, Loss: 209.47618554055398, Neurons: 201, Grad norm: 1.0974256164976168\n",
      "Epoch 2730, Loss: 209.47540209042248, Neurons: 201, Grad norm: 1.5777118281391755\n",
      "Epoch 2730, Loss: 209.47540209042248, Neurons: 201, Grad norm: 1.5777118281391755\n",
      "Epoch 2731, Loss: 209.47463372143326, Neurons: 201, Grad norm: 1.6027833090197403\n",
      "Epoch 2731, Loss: 209.47463372143326, Neurons: 201, Grad norm: 1.6027833090197403\n",
      "Epoch 2732, Loss: 209.47407805215698, Neurons: 201, Grad norm: 2.1547382895763887\n",
      "Epoch 2732, Loss: 209.47407805215698, Neurons: 201, Grad norm: 2.1547382895763887\n",
      "Epoch 2733, Loss: 209.473558393915, Neurons: 201, Grad norm: 1.577056439180239\n",
      "Epoch 2733, Loss: 209.473558393915, Neurons: 201, Grad norm: 1.577056439180239\n",
      "Epoch 2734, Loss: 209.47291893317123, Neurons: 201, Grad norm: 1.3934125732725522\n",
      "Epoch 2734, Loss: 209.47291893317123, Neurons: 201, Grad norm: 1.3934125732725522\n",
      "Epoch 2735, Loss: 209.47226302417118, Neurons: 201, Grad norm: 0.9884657398148717\n",
      "Epoch 2735, Loss: 209.47226302417118, Neurons: 201, Grad norm: 0.9884657398148717\n",
      "Epoch 2736, Loss: 209.47163584240448, Neurons: 201, Grad norm: 1.0269483616514903\n",
      "Epoch 2736, Loss: 209.47163584240448, Neurons: 201, Grad norm: 1.0269483616514903\n",
      "Epoch 2737, Loss: 209.47100380250268, Neurons: 201, Grad norm: 1.3577492944705398\n",
      "Epoch 2737, Loss: 209.47100380250268, Neurons: 201, Grad norm: 1.3577492944705398\n",
      "Epoch 2738, Loss: 209.4703759939663, Neurons: 201, Grad norm: 1.3489650250243197\n",
      "Epoch 2738, Loss: 209.4703759939663, Neurons: 201, Grad norm: 1.3489650250243197\n",
      "Epoch 2739, Loss: 209.4697849785444, Neurons: 201, Grad norm: 1.7329150152677022\n",
      "Epoch 2739, Loss: 209.4697849785444, Neurons: 201, Grad norm: 1.7329150152677022\n",
      "Epoch 2740, Loss: 209.46921641194535, Neurons: 201, Grad norm: 1.4647756525990387\n",
      "Epoch 2740, Loss: 209.46921641194535, Neurons: 201, Grad norm: 1.4647756525990387\n",
      "Epoch 2741, Loss: 209.46861949955215, Neurons: 201, Grad norm: 1.58310779140409\n",
      "Epoch 2741, Loss: 209.46861949955215, Neurons: 201, Grad norm: 1.58310779140409\n",
      "Epoch 2742, Loss: 209.46799110510074, Neurons: 201, Grad norm: 1.0768729150678886\n",
      "Epoch 2742, Loss: 209.46799110510074, Neurons: 201, Grad norm: 1.0768729150678886\n",
      "Epoch 2743, Loss: 209.46734875903036, Neurons: 201, Grad norm: 1.2251516476703475\n",
      "Epoch 2743, Loss: 209.46734875903036, Neurons: 201, Grad norm: 1.2251516476703475\n",
      "Epoch 2744, Loss: 209.46674846579026, Neurons: 201, Grad norm: 0.8929387091157076\n",
      "Epoch 2744, Loss: 209.46674846579026, Neurons: 201, Grad norm: 0.8929387091157076\n",
      "Epoch 2745, Loss: 209.4661247917684, Neurons: 201, Grad norm: 1.133880829309037\n",
      "Epoch 2745, Loss: 209.4661247917684, Neurons: 201, Grad norm: 1.133880829309037\n",
      "Epoch 2746, Loss: 209.4655329082971, Neurons: 201, Grad norm: 0.9394849868179705\n",
      "Epoch 2746, Loss: 209.4655329082971, Neurons: 201, Grad norm: 0.9394849868179705\n",
      "Epoch 2747, Loss: 209.46494068611466, Neurons: 201, Grad norm: 0.99491359140229\n",
      "Epoch 2747, Loss: 209.46494068611466, Neurons: 201, Grad norm: 0.99491359140229\n",
      "Epoch 2748, Loss: 209.4643294322744, Neurons: 201, Grad norm: 0.8890962958787523\n",
      "Epoch 2748, Loss: 209.4643294322744, Neurons: 201, Grad norm: 0.8890962958787523\n",
      "Epoch 2749, Loss: 209.46370637672777, Neurons: 201, Grad norm: 0.8911270746603656\n",
      "Epoch 2749, Loss: 209.46370637672777, Neurons: 201, Grad norm: 0.8911270746603656\n",
      "Epoch 2750, Loss: 209.463073946744, Neurons: 201, Grad norm: 0.9350335925033448\n",
      "Epoch 2750, Loss: 209.463073946744, Neurons: 201, Grad norm: 0.9350335925033448\n",
      "Epoch 2751, Loss: 209.46243887023735, Neurons: 201, Grad norm: 0.868422959343722\n",
      "Epoch 2751, Loss: 209.46243887023735, Neurons: 201, Grad norm: 0.868422959343722\n",
      "Epoch 2752, Loss: 209.46180793341946, Neurons: 201, Grad norm: 1.1203393843982394\n",
      "Epoch 2752, Loss: 209.46180793341946, Neurons: 201, Grad norm: 1.1203393843982394\n",
      "Epoch 2753, Loss: 209.46121109284402, Neurons: 201, Grad norm: 1.0068278931212904\n",
      "Epoch 2753, Loss: 209.46121109284402, Neurons: 201, Grad norm: 1.0068278931212904\n",
      "Epoch 2754, Loss: 209.4606774010821, Neurons: 201, Grad norm: 1.084411286076275\n",
      "Epoch 2754, Loss: 209.4606774010821, Neurons: 201, Grad norm: 1.084411286076275\n",
      "Epoch 2755, Loss: 209.46011103036935, Neurons: 201, Grad norm: 0.9283140595922867\n",
      "Epoch 2755, Loss: 209.46011103036935, Neurons: 201, Grad norm: 0.9283140595922867\n",
      "Epoch 2756, Loss: 209.45950449113084, Neurons: 201, Grad norm: 1.1213712259921031\n",
      "Epoch 2756, Loss: 209.45950449113084, Neurons: 201, Grad norm: 1.1213712259921031\n",
      "Epoch 2757, Loss: 209.45890226430245, Neurons: 201, Grad norm: 0.9713697373827614\n",
      "Epoch 2757, Loss: 209.45890226430245, Neurons: 201, Grad norm: 0.9713697373827614\n",
      "Epoch 2758, Loss: 209.4583004281339, Neurons: 201, Grad norm: 1.1470397797341654\n",
      "Epoch 2758, Loss: 209.4583004281339, Neurons: 201, Grad norm: 1.1470397797341654\n",
      "Epoch 2759, Loss: 209.45769575019142, Neurons: 201, Grad norm: 0.925206782675545\n",
      "Epoch 2759, Loss: 209.45769575019142, Neurons: 201, Grad norm: 0.925206782675545\n",
      "Epoch 2760, Loss: 209.45708702833164, Neurons: 201, Grad norm: 1.1333178460077244\n",
      "Epoch 2760, Loss: 209.45708702833164, Neurons: 201, Grad norm: 1.1333178460077244\n",
      "Epoch 2761, Loss: 209.45654258807258, Neurons: 201, Grad norm: 0.9970700843587186\n",
      "Epoch 2761, Loss: 209.45654258807258, Neurons: 201, Grad norm: 0.9970700843587186\n",
      "Epoch 2762, Loss: 209.45597962290176, Neurons: 201, Grad norm: 1.040208216097469\n",
      "Epoch 2762, Loss: 209.45597962290176, Neurons: 201, Grad norm: 1.040208216097469\n",
      "Epoch 2763, Loss: 209.45539569999366, Neurons: 201, Grad norm: 0.9922287947203896\n",
      "Epoch 2763, Loss: 209.45539569999366, Neurons: 201, Grad norm: 0.9922287947203896\n",
      "Epoch 2764, Loss: 209.45482688798813, Neurons: 201, Grad norm: 1.357683450537273\n",
      "Epoch 2764, Loss: 209.45482688798813, Neurons: 201, Grad norm: 1.357683450537273\n",
      "Epoch 2765, Loss: 209.45424634213947, Neurons: 201, Grad norm: 1.3447228248792282\n",
      "Epoch 2765, Loss: 209.45424634213947, Neurons: 201, Grad norm: 1.3447228248792282\n",
      "Epoch 2766, Loss: 209.45367239752198, Neurons: 201, Grad norm: 1.7655260727506061\n",
      "Epoch 2766, Loss: 209.45367239752198, Neurons: 201, Grad norm: 1.7655260727506061\n",
      "Epoch 2767, Loss: 209.45312531356845, Neurons: 201, Grad norm: 1.575192685943017\n",
      "Epoch 2767, Loss: 209.45312531356845, Neurons: 201, Grad norm: 1.575192685943017\n",
      "Epoch 2768, Loss: 209.4525597269233, Neurons: 201, Grad norm: 2.0871254432185284\n",
      "Epoch 2768, Loss: 209.4525597269233, Neurons: 201, Grad norm: 2.0871254432185284\n",
      "Epoch 2769, Loss: 209.45200894692667, Neurons: 201, Grad norm: 2.35212207680283\n",
      "Epoch 2769, Loss: 209.45200894692667, Neurons: 201, Grad norm: 2.35212207680283\n",
      "Epoch 2770, Loss: 209.4514795272435, Neurons: 201, Grad norm: 3.450753461207795\n",
      "Epoch 2770, Loss: 209.4514795272435, Neurons: 201, Grad norm: 3.450753461207795\n",
      "Epoch 2771, Loss: 209.45108287231102, Neurons: 201, Grad norm: 4.132855833616244\n",
      "Epoch 2771, Loss: 209.45108287231102, Neurons: 201, Grad norm: 4.132855833616244\n",
      "Epoch 2772, Loss: 209.4507762875429, Neurons: 201, Grad norm: 5.072768802897251\n",
      "Epoch 2772, Loss: 209.4507762875429, Neurons: 201, Grad norm: 5.072768802897251\n",
      "Epoch 2773, Loss: 209.450403817529, Neurons: 201, Grad norm: 4.910167541265872\n",
      "Epoch 2773, Loss: 209.450403817529, Neurons: 201, Grad norm: 4.910167541265872\n",
      "Epoch 2774, Loss: 209.44985952320076, Neurons: 201, Grad norm: 4.818710006831868\n",
      "Epoch 2774, Loss: 209.44985952320076, Neurons: 201, Grad norm: 4.818710006831868\n",
      "Epoch 2775, Loss: 209.44919113791886, Neurons: 201, Grad norm: 3.588216457928493\n",
      "Epoch 2775, Loss: 209.44919113791886, Neurons: 201, Grad norm: 3.588216457928493\n",
      "Epoch 2776, Loss: 209.44847634317924, Neurons: 201, Grad norm: 2.6771425178215904\n",
      "Epoch 2776, Loss: 209.44847634317924, Neurons: 201, Grad norm: 2.6771425178215904\n",
      "Epoch 2777, Loss: 209.44771667285323, Neurons: 201, Grad norm: 1.2433655409099553\n",
      "Epoch 2777, Loss: 209.44771667285323, Neurons: 201, Grad norm: 1.2433655409099553\n",
      "Epoch 2778, Loss: 209.44702002224727, Neurons: 201, Grad norm: 1.04534628157519\n",
      "Epoch 2778, Loss: 209.44702002224727, Neurons: 201, Grad norm: 1.04534628157519\n",
      "Epoch 2779, Loss: 209.44645664588631, Neurons: 201, Grad norm: 2.307455334770571\n",
      "Epoch 2779, Loss: 209.44645664588631, Neurons: 201, Grad norm: 2.307455334770571\n",
      "Epoch 2780, Loss: 209.44601065420724, Neurons: 201, Grad norm: 3.2204374619030425\n",
      "Epoch 2780, Loss: 209.44601065420724, Neurons: 201, Grad norm: 3.2204374619030425\n",
      "Epoch 2781, Loss: 209.44564173304056, Neurons: 201, Grad norm: 4.627460204524894\n",
      "Epoch 2781, Loss: 209.44564173304056, Neurons: 201, Grad norm: 4.627460204524894\n",
      "Epoch 2782, Loss: 209.44534027111686, Neurons: 201, Grad norm: 4.965308323796989\n",
      "Epoch 2782, Loss: 209.44534027111686, Neurons: 201, Grad norm: 4.965308323796989\n",
      "Epoch 2783, Loss: 209.44501003730838, Neurons: 201, Grad norm: 5.51535883922869\n",
      "Epoch 2783, Loss: 209.44501003730838, Neurons: 201, Grad norm: 5.51535883922869\n",
      "Epoch 2784, Loss: 209.44454464123382, Neurons: 201, Grad norm: 4.743930605960859\n",
      "Epoch 2784, Loss: 209.44454464123382, Neurons: 201, Grad norm: 4.743930605960859\n",
      "Epoch 2785, Loss: 209.4438474573614, Neurons: 201, Grad norm: 3.974157777251176\n",
      "Epoch 2785, Loss: 209.4438474573614, Neurons: 201, Grad norm: 3.974157777251176\n",
      "Epoch 2786, Loss: 209.44309928175605, Neurons: 201, Grad norm: 2.36850272063929\n",
      "Epoch 2786, Loss: 209.44309928175605, Neurons: 201, Grad norm: 2.36850272063929\n",
      "Epoch 2787, Loss: 209.44234330250856, Neurons: 201, Grad norm: 1.2094430611484608\n",
      "Epoch 2787, Loss: 209.44234330250856, Neurons: 201, Grad norm: 1.2094430611484608\n",
      "Epoch 2788, Loss: 209.44165009444015, Neurons: 201, Grad norm: 1.2787520694022458\n",
      "Epoch 2788, Loss: 209.44165009444015, Neurons: 201, Grad norm: 1.2787520694022458\n",
      "Epoch 2789, Loss: 209.44113238886365, Neurons: 201, Grad norm: 2.158614601664432\n",
      "Epoch 2789, Loss: 209.44113238886365, Neurons: 201, Grad norm: 2.158614601664432\n",
      "Epoch 2790, Loss: 209.44071599959344, Neurons: 201, Grad norm: 3.326119675275441\n",
      "Epoch 2790, Loss: 209.44071599959344, Neurons: 201, Grad norm: 3.326119675275441\n",
      "Epoch 2791, Loss: 209.4402979517359, Neurons: 201, Grad norm: 3.5847348059074022\n",
      "Epoch 2791, Loss: 209.4402979517359, Neurons: 201, Grad norm: 3.5847348059074022\n",
      "Epoch 2792, Loss: 209.4398883823033, Neurons: 201, Grad norm: 3.9109552484588455\n",
      "Epoch 2792, Loss: 209.4398883823033, Neurons: 201, Grad norm: 3.9109552484588455\n",
      "Epoch 2793, Loss: 209.4393782874901, Neurons: 201, Grad norm: 3.199065577875332\n",
      "Epoch 2793, Loss: 209.4393782874901, Neurons: 201, Grad norm: 3.199065577875332\n",
      "Epoch 2794, Loss: 209.43876668778512, Neurons: 201, Grad norm: 2.251124649106696\n",
      "Epoch 2794, Loss: 209.43876668778512, Neurons: 201, Grad norm: 2.251124649106696\n",
      "Epoch 2795, Loss: 209.43806313701668, Neurons: 201, Grad norm: 0.9675603980666785\n",
      "Epoch 2795, Loss: 209.43806313701668, Neurons: 201, Grad norm: 0.9675603980666785\n",
      "Epoch 2796, Loss: 209.43743482343712, Neurons: 201, Grad norm: 1.2083737096984126\n",
      "Epoch 2796, Loss: 209.43743482343712, Neurons: 201, Grad norm: 1.2083737096984126\n",
      "Epoch 2797, Loss: 209.43693713144665, Neurons: 201, Grad norm: 2.7804226442952777\n",
      "Epoch 2797, Loss: 209.43693713144665, Neurons: 201, Grad norm: 2.7804226442952777\n",
      "Epoch 2798, Loss: 209.4365609672056, Neurons: 201, Grad norm: 3.3817814049465964\n",
      "Epoch 2798, Loss: 209.4365609672056, Neurons: 201, Grad norm: 3.3817814049465964\n",
      "Epoch 2799, Loss: 209.4362185634336, Neurons: 201, Grad norm: 4.23406937992256\n",
      "Epoch 2799, Loss: 209.4362185634336, Neurons: 201, Grad norm: 4.23406937992256\n",
      "Epoch 2800, Loss: 209.43581113441994, Neurons: 201, Grad norm: 3.8580236246202455\n",
      "Epoch 2800, Loss: 209.43581113441994, Neurons: 201, Grad norm: 3.8580236246202455\n",
      "Epoch 2801, Loss: 209.4352683642396, Neurons: 201, Grad norm: 3.1138493259419175\n",
      "Epoch 2801, Loss: 209.4352683642396, Neurons: 201, Grad norm: 3.1138493259419175\n",
      "Epoch 2802, Loss: 209.43458971749115, Neurons: 201, Grad norm: 1.6378337558883154\n",
      "Epoch 2802, Loss: 209.43458971749115, Neurons: 201, Grad norm: 1.6378337558883154\n",
      "Epoch 2803, Loss: 209.43390380513745, Neurons: 201, Grad norm: 0.9096492374281753\n",
      "Epoch 2803, Loss: 209.43390380513745, Neurons: 201, Grad norm: 0.9096492374281753\n",
      "Epoch 2804, Loss: 209.43332277319598, Neurons: 201, Grad norm: 2.045589579628792\n",
      "Epoch 2804, Loss: 209.43332277319598, Neurons: 201, Grad norm: 2.045589579628792\n",
      "Epoch 2805, Loss: 209.43289315855918, Neurons: 201, Grad norm: 2.9931885339779285\n",
      "Epoch 2805, Loss: 209.43289315855918, Neurons: 201, Grad norm: 2.9931885339779285\n",
      "Epoch 2806, Loss: 209.43256459061593, Neurons: 201, Grad norm: 4.286332679336393\n",
      "Epoch 2806, Loss: 209.43256459061593, Neurons: 201, Grad norm: 4.286332679336393\n",
      "Epoch 2807, Loss: 209.4322465361021, Neurons: 201, Grad norm: 4.2777294924172224\n",
      "Epoch 2807, Loss: 209.4322465361021, Neurons: 201, Grad norm: 4.2777294924172224\n",
      "Epoch 2808, Loss: 209.43180502002647, Neurons: 201, Grad norm: 4.444446802538556\n",
      "Epoch 2808, Loss: 209.43180502002647, Neurons: 201, Grad norm: 4.444446802538556\n",
      "Epoch 2809, Loss: 209.4312690069994, Neurons: 201, Grad norm: 3.3587023120175807\n",
      "Epoch 2809, Loss: 209.4312690069994, Neurons: 201, Grad norm: 3.3587023120175807\n",
      "Epoch 2810, Loss: 209.4305888275167, Neurons: 201, Grad norm: 2.2146151695074163\n",
      "Epoch 2810, Loss: 209.4305888275167, Neurons: 201, Grad norm: 2.2146151695074163\n",
      "Epoch 2811, Loss: 209.42990499699127, Neurons: 201, Grad norm: 0.8470352633382734\n",
      "Epoch 2811, Loss: 209.42990499699127, Neurons: 201, Grad norm: 0.8470352633382734\n",
      "Epoch 2812, Loss: 209.4293030634111, Neurons: 201, Grad norm: 1.3617688770974279\n",
      "Epoch 2812, Loss: 209.4293030634111, Neurons: 201, Grad norm: 1.3617688770974279\n",
      "Epoch 2813, Loss: 209.4288302635775, Neurons: 201, Grad norm: 2.775942314237866\n",
      "Epoch 2813, Loss: 209.4288302635775, Neurons: 201, Grad norm: 2.775942314237866\n",
      "Epoch 2814, Loss: 209.428459344783, Neurons: 201, Grad norm: 3.410677844477249\n",
      "Epoch 2814, Loss: 209.428459344783, Neurons: 201, Grad norm: 3.410677844477249\n",
      "Epoch 2815, Loss: 209.42814755157727, Neurons: 201, Grad norm: 3.860261954035082\n",
      "Epoch 2815, Loss: 209.42814755157727, Neurons: 201, Grad norm: 3.860261954035082\n",
      "Epoch 2816, Loss: 209.42763518826646, Neurons: 201, Grad norm: 3.1853306441308\n",
      "Epoch 2816, Loss: 209.42763518826646, Neurons: 201, Grad norm: 3.1853306441308\n",
      "Epoch 2817, Loss: 209.42711506497005, Neurons: 201, Grad norm: 2.544971273293146\n",
      "Epoch 2817, Loss: 209.42711506497005, Neurons: 201, Grad norm: 2.544971273293146\n",
      "Epoch 2818, Loss: 209.42648562011834, Neurons: 201, Grad norm: 0.9794720686457663\n",
      "Epoch 2818, Loss: 209.42648562011834, Neurons: 201, Grad norm: 0.9794720686457663\n",
      "Epoch 2819, Loss: 209.42585707585548, Neurons: 201, Grad norm: 0.9693125656111623\n",
      "Epoch 2819, Loss: 209.42585707585548, Neurons: 201, Grad norm: 0.9693125656111623\n",
      "Epoch 2820, Loss: 209.42535063990633, Neurons: 201, Grad norm: 2.3860523796062987\n",
      "Epoch 2820, Loss: 209.42535063990633, Neurons: 201, Grad norm: 2.3860523796062987\n",
      "Epoch 2821, Loss: 209.42495940572877, Neurons: 201, Grad norm: 3.2180625258295468\n",
      "Epoch 2821, Loss: 209.42495940572877, Neurons: 201, Grad norm: 3.2180625258295468\n",
      "Epoch 2822, Loss: 209.42463590187498, Neurons: 201, Grad norm: 4.149983350402572\n",
      "Epoch 2822, Loss: 209.42463590187498, Neurons: 201, Grad norm: 4.149983350402572\n",
      "Epoch 2823, Loss: 209.42430594167473, Neurons: 201, Grad norm: 3.7584403655551353\n",
      "Epoch 2823, Loss: 209.42430594167473, Neurons: 201, Grad norm: 3.7584403655551353\n",
      "Epoch 2824, Loss: 209.42381089336854, Neurons: 201, Grad norm: 3.181660250012145\n",
      "Epoch 2824, Loss: 209.42381089336854, Neurons: 201, Grad norm: 3.181660250012145\n",
      "Epoch 2825, Loss: 209.42313828463693, Neurons: 201, Grad norm: 1.7011015054455045\n",
      "Epoch 2825, Loss: 209.42313828463693, Neurons: 201, Grad norm: 1.7011015054455045\n",
      "Epoch 2826, Loss: 209.42252223075675, Neurons: 201, Grad norm: 0.885952765811195\n",
      "Epoch 2826, Loss: 209.42252223075675, Neurons: 201, Grad norm: 0.885952765811195\n",
      "Epoch 2827, Loss: 209.42197362155122, Neurons: 201, Grad norm: 1.2905298886853036\n",
      "Epoch 2827, Loss: 209.42197362155122, Neurons: 201, Grad norm: 1.2905298886853036\n",
      "Epoch 2828, Loss: 209.42151039827777, Neurons: 201, Grad norm: 1.6007311419996773\n",
      "Epoch 2828, Loss: 209.42151039827777, Neurons: 201, Grad norm: 1.6007311419996773\n",
      "Epoch 2829, Loss: 209.42108708834832, Neurons: 201, Grad norm: 2.0283137757515095\n",
      "Epoch 2829, Loss: 209.42108708834832, Neurons: 201, Grad norm: 2.0283137757515095\n",
      "Epoch 2830, Loss: 209.4206189753238, Neurons: 201, Grad norm: 1.462293223857533\n",
      "Epoch 2830, Loss: 209.4206189753238, Neurons: 201, Grad norm: 1.462293223857533\n",
      "Epoch 2831, Loss: 209.4201105736875, Neurons: 201, Grad norm: 1.4496703408374252\n",
      "Epoch 2831, Loss: 209.4201105736875, Neurons: 201, Grad norm: 1.4496703408374252\n",
      "Epoch 2832, Loss: 209.4196033206546, Neurons: 201, Grad norm: 0.913621115458108\n",
      "Epoch 2832, Loss: 209.4196033206546, Neurons: 201, Grad norm: 0.913621115458108\n",
      "Epoch 2833, Loss: 209.41909424163867, Neurons: 201, Grad norm: 0.9424509504363799\n",
      "Epoch 2833, Loss: 209.41909424163867, Neurons: 201, Grad norm: 0.9424509504363799\n",
      "Epoch 2834, Loss: 209.41861296189347, Neurons: 201, Grad norm: 0.877833080981114\n",
      "Epoch 2834, Loss: 209.41861296189347, Neurons: 201, Grad norm: 0.877833080981114\n",
      "Epoch 2835, Loss: 209.4181138080861, Neurons: 201, Grad norm: 0.7545377351221194\n",
      "Epoch 2835, Loss: 209.4181138080861, Neurons: 201, Grad norm: 0.7545377351221194\n",
      "Epoch 2836, Loss: 209.41762004069105, Neurons: 201, Grad norm: 0.7797789828726374\n",
      "Epoch 2836, Loss: 209.41762004069105, Neurons: 201, Grad norm: 0.7797789828726374\n",
      "Epoch 2837, Loss: 209.41714057340917, Neurons: 201, Grad norm: 0.7632535271010996\n",
      "Epoch 2837, Loss: 209.41714057340917, Neurons: 201, Grad norm: 0.7632535271010996\n",
      "Epoch 2838, Loss: 209.41664937654213, Neurons: 201, Grad norm: 0.7915752710372521\n",
      "Epoch 2838, Loss: 209.41664937654213, Neurons: 201, Grad norm: 0.7915752710372521\n",
      "Epoch 2839, Loss: 209.41614497700402, Neurons: 201, Grad norm: 1.1091548087397967\n",
      "Epoch 2839, Loss: 209.41614497700402, Neurons: 201, Grad norm: 1.1091548087397967\n",
      "Epoch 2840, Loss: 209.41568311670028, Neurons: 201, Grad norm: 1.0976017825177677\n",
      "Epoch 2840, Loss: 209.41568311670028, Neurons: 201, Grad norm: 1.0976017825177677\n",
      "Epoch 2841, Loss: 209.41520221749542, Neurons: 201, Grad norm: 1.462449315389332\n",
      "Epoch 2841, Loss: 209.41520221749542, Neurons: 201, Grad norm: 1.462449315389332\n",
      "Epoch 2842, Loss: 209.4147421155684, Neurons: 201, Grad norm: 1.3991955149099966\n",
      "Epoch 2842, Loss: 209.4147421155684, Neurons: 201, Grad norm: 1.3991955149099966\n",
      "Epoch 2843, Loss: 209.41428610148614, Neurons: 201, Grad norm: 1.766587926456466\n",
      "Epoch 2843, Loss: 209.41428610148614, Neurons: 201, Grad norm: 1.766587926456466\n",
      "Epoch 2844, Loss: 209.4138101953543, Neurons: 201, Grad norm: 1.9105471866858403\n",
      "Epoch 2844, Loss: 209.4138101953543, Neurons: 201, Grad norm: 1.9105471866858403\n",
      "Epoch 2845, Loss: 209.41337838573327, Neurons: 201, Grad norm: 2.446705658049581\n",
      "Epoch 2845, Loss: 209.41337838573327, Neurons: 201, Grad norm: 2.446705658049581\n",
      "Epoch 2846, Loss: 209.41295707108733, Neurons: 201, Grad norm: 2.6106211586846944\n",
      "Epoch 2846, Loss: 209.41295707108733, Neurons: 201, Grad norm: 2.6106211586846944\n",
      "Epoch 2847, Loss: 209.41254758041393, Neurons: 201, Grad norm: 2.955109419519444\n",
      "Epoch 2847, Loss: 209.41254758041393, Neurons: 201, Grad norm: 2.955109419519444\n",
      "Epoch 2848, Loss: 209.4121317738407, Neurons: 201, Grad norm: 2.6600103743826216\n",
      "Epoch 2848, Loss: 209.4121317738407, Neurons: 201, Grad norm: 2.6600103743826216\n",
      "Epoch 2849, Loss: 209.41165787569545, Neurons: 201, Grad norm: 2.8337615701552896\n",
      "Epoch 2849, Loss: 209.41165787569545, Neurons: 201, Grad norm: 2.8337615701552896\n",
      "Epoch 2850, Loss: 209.4111911790062, Neurons: 201, Grad norm: 2.1710163194072853\n",
      "Epoch 2850, Loss: 209.4111911790062, Neurons: 201, Grad norm: 2.1710163194072853\n",
      "Epoch 2851, Loss: 209.4107121806226, Neurons: 201, Grad norm: 1.8310645849098526\n",
      "Epoch 2851, Loss: 209.4107121806226, Neurons: 201, Grad norm: 1.8310645849098526\n",
      "Epoch 2852, Loss: 209.41017087769845, Neurons: 201, Grad norm: 0.8977118997891677\n",
      "Epoch 2852, Loss: 209.41017087769845, Neurons: 201, Grad norm: 0.8977118997891677\n",
      "Epoch 2853, Loss: 209.4096494932158, Neurons: 201, Grad norm: 0.8183806408755188\n",
      "Epoch 2853, Loss: 209.4096494932158, Neurons: 201, Grad norm: 0.8183806408755188\n",
      "Epoch 2854, Loss: 209.40921386435474, Neurons: 201, Grad norm: 1.3896273365607872\n",
      "Epoch 2854, Loss: 209.40921386435474, Neurons: 201, Grad norm: 1.3896273365607872\n",
      "Epoch 2855, Loss: 209.4087755889827, Neurons: 201, Grad norm: 1.67949061515156\n",
      "Epoch 2855, Loss: 209.4087755889827, Neurons: 201, Grad norm: 1.67949061515156\n",
      "Epoch 2856, Loss: 209.40838133722144, Neurons: 201, Grad norm: 2.193227517515657\n",
      "Epoch 2856, Loss: 209.40838133722144, Neurons: 201, Grad norm: 2.193227517515657\n",
      "Epoch 2857, Loss: 209.40796247388207, Neurons: 201, Grad norm: 2.118580898056034\n",
      "Epoch 2857, Loss: 209.40796247388207, Neurons: 201, Grad norm: 2.118580898056034\n",
      "Epoch 2858, Loss: 209.40749467231294, Neurons: 201, Grad norm: 2.1719593507629105\n",
      "Epoch 2858, Loss: 209.40749467231294, Neurons: 201, Grad norm: 2.1719593507629105\n",
      "Epoch 2859, Loss: 209.40702712142868, Neurons: 201, Grad norm: 1.5124187745425732\n",
      "Epoch 2859, Loss: 209.40702712142868, Neurons: 201, Grad norm: 1.5124187745425732\n",
      "Epoch 2860, Loss: 209.4065453633874, Neurons: 201, Grad norm: 1.3983432640683167\n",
      "Epoch 2860, Loss: 209.4065453633874, Neurons: 201, Grad norm: 1.3983432640683167\n",
      "Epoch 2861, Loss: 209.4060665901197, Neurons: 201, Grad norm: 0.7526094913217571\n",
      "Epoch 2861, Loss: 209.4060665901197, Neurons: 201, Grad norm: 0.7526094913217571\n",
      "Epoch 2862, Loss: 209.4055752897907, Neurons: 201, Grad norm: 0.8573953492664069\n",
      "Epoch 2862, Loss: 209.4055752897907, Neurons: 201, Grad norm: 0.8573953492664069\n",
      "Epoch 2863, Loss: 209.4051420813449, Neurons: 201, Grad norm: 1.707748038304143\n",
      "Epoch 2863, Loss: 209.4051420813449, Neurons: 201, Grad norm: 1.707748038304143\n",
      "Epoch 2864, Loss: 209.4047479049982, Neurons: 201, Grad norm: 2.5310420157959\n",
      "Epoch 2864, Loss: 209.4047479049982, Neurons: 201, Grad norm: 2.5310420157959\n",
      "Epoch 2865, Loss: 209.40440064466003, Neurons: 201, Grad norm: 3.5030771700142487\n",
      "Epoch 2865, Loss: 209.40440064466003, Neurons: 201, Grad norm: 3.5030771700142487\n",
      "Epoch 2866, Loss: 209.40408902157242, Neurons: 201, Grad norm: 3.7845410442415526\n",
      "Epoch 2866, Loss: 209.40408902157242, Neurons: 201, Grad norm: 3.7845410442415526\n",
      "Epoch 2867, Loss: 209.4037554899501, Neurons: 201, Grad norm: 4.253041314810441\n",
      "Epoch 2867, Loss: 209.4037554899501, Neurons: 201, Grad norm: 4.253041314810441\n",
      "Epoch 2868, Loss: 209.40335087241357, Neurons: 201, Grad norm: 3.302230359697164\n",
      "Epoch 2868, Loss: 209.40335087241357, Neurons: 201, Grad norm: 3.302230359697164\n",
      "Epoch 2869, Loss: 209.40278644084145, Neurons: 201, Grad norm: 2.2247337239286837\n",
      "Epoch 2869, Loss: 209.40278644084145, Neurons: 201, Grad norm: 2.2247337239286837\n",
      "Epoch 2870, Loss: 209.4021621411454, Neurons: 201, Grad norm: 0.7266924873373963\n",
      "Epoch 2870, Loss: 209.4021621411454, Neurons: 201, Grad norm: 0.7266924873373963\n",
      "Epoch 2871, Loss: 209.4016256506019, Neurons: 201, Grad norm: 1.660228569523985\n",
      "Epoch 2871, Loss: 209.4016256506019, Neurons: 201, Grad norm: 1.660228569523985\n",
      "Epoch 2872, Loss: 209.40124369439445, Neurons: 201, Grad norm: 3.1151962528597315\n",
      "Epoch 2872, Loss: 209.40124369439445, Neurons: 201, Grad norm: 3.1151962528597315\n",
      "Epoch 2873, Loss: 209.40097250125137, Neurons: 201, Grad norm: 3.277655631582232\n",
      "Epoch 2873, Loss: 209.40097250125137, Neurons: 201, Grad norm: 3.277655631582232\n",
      "Epoch 2874, Loss: 209.40061012344867, Neurons: 201, Grad norm: 3.2148674240707544\n",
      "Epoch 2874, Loss: 209.40061012344867, Neurons: 201, Grad norm: 3.2148674240707544\n",
      "Epoch 2875, Loss: 209.40008771530898, Neurons: 201, Grad norm: 1.9164049777798546\n",
      "Epoch 2875, Loss: 209.40008771530898, Neurons: 201, Grad norm: 1.9164049777798546\n",
      "Epoch 2876, Loss: 209.39950799623128, Neurons: 201, Grad norm: 0.9793791497674583\n",
      "Epoch 2876, Loss: 209.39950799623128, Neurons: 201, Grad norm: 0.9793791497674583\n",
      "Epoch 2877, Loss: 209.3989766842822, Neurons: 201, Grad norm: 1.3537105341198397\n",
      "Epoch 2877, Loss: 209.3989766842822, Neurons: 201, Grad norm: 1.3537105341198397\n",
      "Epoch 2878, Loss: 209.39857025524017, Neurons: 201, Grad norm: 2.4223497020147944\n",
      "Epoch 2878, Loss: 209.39857025524017, Neurons: 201, Grad norm: 2.4223497020147944\n",
      "Epoch 2879, Loss: 209.3982135954085, Neurons: 201, Grad norm: 3.752288228645964\n",
      "Epoch 2879, Loss: 209.3982135954085, Neurons: 201, Grad norm: 3.752288228645964\n",
      "Epoch 2880, Loss: 209.39796467225761, Neurons: 201, Grad norm: 4.04856313483131\n",
      "Epoch 2880, Loss: 209.39796467225761, Neurons: 201, Grad norm: 4.04856313483131\n",
      "Epoch 2881, Loss: 209.39763290431267, Neurons: 201, Grad norm: 4.33363050817432\n",
      "Epoch 2881, Loss: 209.39763290431267, Neurons: 201, Grad norm: 4.33363050817432\n",
      "Epoch 2882, Loss: 209.3971035833906, Neurons: 201, Grad norm: 3.105184745742353\n",
      "Epoch 2882, Loss: 209.3971035833906, Neurons: 201, Grad norm: 3.105184745742353\n",
      "Epoch 2883, Loss: 209.39642071378336, Neurons: 201, Grad norm: 1.9786200169988135\n",
      "Epoch 2883, Loss: 209.39642071378336, Neurons: 201, Grad norm: 1.9786200169988135\n",
      "Epoch 2884, Loss: 209.3957507157638, Neurons: 201, Grad norm: 0.8885012706360109\n",
      "Epoch 2884, Loss: 209.3957507157638, Neurons: 201, Grad norm: 0.8885012706360109\n",
      "Epoch 2885, Loss: 209.39518326358044, Neurons: 201, Grad norm: 1.4978538277230073\n",
      "Epoch 2885, Loss: 209.39518326358044, Neurons: 201, Grad norm: 1.4978538277230073\n",
      "Epoch 2886, Loss: 209.39472359852522, Neurons: 201, Grad norm: 2.6383861676593092\n",
      "Epoch 2886, Loss: 209.39472359852522, Neurons: 201, Grad norm: 2.6383861676593092\n",
      "Epoch 2887, Loss: 209.3943370756755, Neurons: 201, Grad norm: 2.72414143541654\n",
      "Epoch 2887, Loss: 209.3943370756755, Neurons: 201, Grad norm: 2.72414143541654\n",
      "Epoch 2888, Loss: 209.3938611920704, Neurons: 201, Grad norm: 2.9976047646494193\n",
      "Epoch 2888, Loss: 209.3938611920704, Neurons: 201, Grad norm: 2.9976047646494193\n",
      "Epoch 2889, Loss: 209.3932773118514, Neurons: 201, Grad norm: 2.169904941352104\n",
      "Epoch 2889, Loss: 209.3932773118514, Neurons: 201, Grad norm: 2.169904941352104\n",
      "Epoch 2890, Loss: 209.39266336355087, Neurons: 201, Grad norm: 1.797458127650113\n",
      "Epoch 2890, Loss: 209.39266336355087, Neurons: 201, Grad norm: 1.797458127650113\n",
      "Epoch 2891, Loss: 209.39204208632606, Neurons: 201, Grad norm: 0.9368818743132903\n",
      "Epoch 2891, Loss: 209.39204208632606, Neurons: 201, Grad norm: 0.9368818743132903\n",
      "Epoch 2892, Loss: 209.3914340549276, Neurons: 201, Grad norm: 0.7628851575686401\n",
      "Epoch 2892, Loss: 209.3914340549276, Neurons: 201, Grad norm: 0.7628851575686401\n",
      "Epoch 2893, Loss: 209.39088456849282, Neurons: 201, Grad norm: 1.2677101320774766\n",
      "Epoch 2893, Loss: 209.39088456849282, Neurons: 201, Grad norm: 1.2677101320774766\n",
      "Epoch 2894, Loss: 209.39035151854787, Neurons: 201, Grad norm: 1.5249633335714374\n",
      "Epoch 2894, Loss: 209.39035151854787, Neurons: 201, Grad norm: 1.5249633335714374\n",
      "Epoch 2895, Loss: 209.3898295106234, Neurons: 201, Grad norm: 1.7761462259069383\n",
      "Epoch 2895, Loss: 209.3898295106234, Neurons: 201, Grad norm: 1.7761462259069383\n",
      "Epoch 2896, Loss: 209.38929603804985, Neurons: 201, Grad norm: 1.3851639641733786\n",
      "Epoch 2896, Loss: 209.38929603804985, Neurons: 201, Grad norm: 1.3851639641733786\n",
      "Epoch 2897, Loss: 209.38875061422402, Neurons: 201, Grad norm: 1.6378107722200286\n",
      "Epoch 2897, Loss: 209.38875061422402, Neurons: 201, Grad norm: 1.6378107722200286\n",
      "Epoch 2898, Loss: 209.38821979268837, Neurons: 201, Grad norm: 1.0330903804463727\n",
      "Epoch 2898, Loss: 209.38821979268837, Neurons: 201, Grad norm: 1.0330903804463727\n",
      "Epoch 2899, Loss: 209.38763667143678, Neurons: 201, Grad norm: 1.1732132148901036\n",
      "Epoch 2899, Loss: 209.38763667143678, Neurons: 201, Grad norm: 1.1732132148901036\n",
      "Epoch 2900, Loss: 209.387115442965, Neurons: 201, Grad norm: 0.859266207018357\n",
      "Epoch 2900, Loss: 209.387115442965, Neurons: 201, Grad norm: 0.859266207018357\n",
      "Epoch 2901, Loss: 209.386591516342, Neurons: 201, Grad norm: 0.8122865607944394\n",
      "Epoch 2901, Loss: 209.386591516342, Neurons: 201, Grad norm: 0.8122865607944394\n",
      "Epoch 2902, Loss: 209.38608476926495, Neurons: 201, Grad norm: 1.0144666216600493\n",
      "Epoch 2902, Loss: 209.38608476926495, Neurons: 201, Grad norm: 1.0144666216600493\n",
      "Epoch 2903, Loss: 209.38558664656614, Neurons: 201, Grad norm: 1.0314765980390712\n",
      "Epoch 2903, Loss: 209.38558664656614, Neurons: 201, Grad norm: 1.0314765980390712\n",
      "Epoch 2904, Loss: 209.3850845761927, Neurons: 201, Grad norm: 1.2744509930429775\n",
      "Epoch 2904, Loss: 209.3850845761927, Neurons: 201, Grad norm: 1.2744509930429775\n",
      "Epoch 2905, Loss: 209.3845630004696, Neurons: 201, Grad norm: 1.2755662917324926\n",
      "Epoch 2905, Loss: 209.3845630004696, Neurons: 201, Grad norm: 1.2755662917324926\n",
      "Epoch 2906, Loss: 209.38409304002914, Neurons: 201, Grad norm: 1.3771513504792576\n",
      "Epoch 2906, Loss: 209.38409304002914, Neurons: 201, Grad norm: 1.3771513504792576\n",
      "Epoch 2907, Loss: 209.3836077619531, Neurons: 201, Grad norm: 0.981220156037944\n",
      "Epoch 2907, Loss: 209.3836077619531, Neurons: 201, Grad norm: 0.981220156037944\n",
      "Epoch 2908, Loss: 209.3831073896459, Neurons: 201, Grad norm: 1.0797966360162912\n",
      "Epoch 2908, Loss: 209.3831073896459, Neurons: 201, Grad norm: 1.0797966360162912\n",
      "Epoch 2909, Loss: 209.3826257731463, Neurons: 201, Grad norm: 0.7527111848236747\n",
      "Epoch 2909, Loss: 209.3826257731463, Neurons: 201, Grad norm: 0.7527111848236747\n",
      "Epoch 2910, Loss: 209.3821404107905, Neurons: 201, Grad norm: 0.8682434183517589\n",
      "Epoch 2910, Loss: 209.3821404107905, Neurons: 201, Grad norm: 0.8682434183517589\n",
      "Epoch 2911, Loss: 209.3816599904681, Neurons: 201, Grad norm: 0.9163057795771385\n",
      "Epoch 2911, Loss: 209.3816599904681, Neurons: 201, Grad norm: 0.9163057795771385\n",
      "Epoch 2912, Loss: 209.38116421794092, Neurons: 201, Grad norm: 0.8331946902012908\n",
      "Epoch 2912, Loss: 209.38116421794092, Neurons: 201, Grad norm: 0.8331946902012908\n",
      "Epoch 2913, Loss: 209.3806796744595, Neurons: 201, Grad norm: 0.8981246303852648\n",
      "Epoch 2913, Loss: 209.3806796744595, Neurons: 201, Grad norm: 0.8981246303852648\n",
      "Epoch 2914, Loss: 209.38018886100545, Neurons: 201, Grad norm: 0.8209171350023752\n",
      "Epoch 2914, Loss: 209.38018886100545, Neurons: 201, Grad norm: 0.8209171350023752\n",
      "Epoch 2915, Loss: 209.37969223235933, Neurons: 201, Grad norm: 0.9201619074549506\n",
      "Epoch 2915, Loss: 209.37969223235933, Neurons: 201, Grad norm: 0.9201619074549506\n",
      "Epoch 2916, Loss: 209.37917794146813, Neurons: 201, Grad norm: 0.8204224485247738\n",
      "Epoch 2916, Loss: 209.37917794146813, Neurons: 201, Grad norm: 0.8204224485247738\n",
      "Epoch 2917, Loss: 209.3786348290932, Neurons: 201, Grad norm: 0.9145692339890595\n",
      "Epoch 2917, Loss: 209.3786348290932, Neurons: 201, Grad norm: 0.9145692339890595\n",
      "Epoch 2918, Loss: 209.37809479614754, Neurons: 201, Grad norm: 0.8801593756506061\n",
      "Epoch 2918, Loss: 209.37809479614754, Neurons: 201, Grad norm: 0.8801593756506061\n",
      "Epoch 2919, Loss: 209.37755590661155, Neurons: 201, Grad norm: 0.8962737566810145\n",
      "Epoch 2919, Loss: 209.37755590661155, Neurons: 201, Grad norm: 0.8962737566810145\n",
      "Epoch 2920, Loss: 209.37701564336967, Neurons: 201, Grad norm: 1.2638990744276108\n",
      "Epoch 2920, Loss: 209.37701564336967, Neurons: 201, Grad norm: 1.2638990744276108\n",
      "Epoch 2921, Loss: 209.3764896465851, Neurons: 201, Grad norm: 1.4753055546122624\n",
      "Epoch 2921, Loss: 209.3764896465851, Neurons: 201, Grad norm: 1.4753055546122624\n",
      "Epoch 2922, Loss: 209.37606497572952, Neurons: 201, Grad norm: 2.407777782273977\n",
      "Epoch 2922, Loss: 209.37606497572952, Neurons: 201, Grad norm: 2.407777782273977\n",
      "Epoch 2923, Loss: 209.3756579364265, Neurons: 201, Grad norm: 2.8998784020460127\n",
      "Epoch 2923, Loss: 209.3756579364265, Neurons: 201, Grad norm: 2.8998784020460127\n",
      "Epoch 2924, Loss: 209.37522273476395, Neurons: 201, Grad norm: 3.602043251894603\n",
      "Epoch 2924, Loss: 209.37522273476395, Neurons: 201, Grad norm: 3.602043251894603\n",
      "Epoch 2925, Loss: 209.37482782402466, Neurons: 201, Grad norm: 3.367157264275813\n",
      "Epoch 2925, Loss: 209.37482782402466, Neurons: 201, Grad norm: 3.367157264275813\n",
      "Epoch 2926, Loss: 209.37433050576465, Neurons: 201, Grad norm: 3.4318744745751197\n",
      "Epoch 2926, Loss: 209.37433050576465, Neurons: 201, Grad norm: 3.4318744745751197\n",
      "Epoch 2927, Loss: 209.37378645357927, Neurons: 201, Grad norm: 2.578972011243557\n",
      "Epoch 2927, Loss: 209.37378645357927, Neurons: 201, Grad norm: 2.578972011243557\n",
      "Epoch 2928, Loss: 209.37316663476335, Neurons: 201, Grad norm: 2.266849793539779\n",
      "Epoch 2928, Loss: 209.37316663476335, Neurons: 201, Grad norm: 2.266849793539779\n",
      "Epoch 2929, Loss: 209.37258651878213, Neurons: 201, Grad norm: 1.4114769209661664\n",
      "Epoch 2929, Loss: 209.37258651878213, Neurons: 201, Grad norm: 1.4114769209661664\n",
      "Epoch 2930, Loss: 209.37203783687264, Neurons: 201, Grad norm: 1.0060478851368264\n",
      "Epoch 2930, Loss: 209.37203783687264, Neurons: 201, Grad norm: 1.0060478851368264\n",
      "Epoch 2931, Loss: 209.37149489342687, Neurons: 201, Grad norm: 0.7657030471267816\n",
      "Epoch 2931, Loss: 209.37149489342687, Neurons: 201, Grad norm: 0.7657030471267816\n",
      "Epoch 2932, Loss: 209.37098180640854, Neurons: 201, Grad norm: 0.8584305673998057\n",
      "Epoch 2932, Loss: 209.37098180640854, Neurons: 201, Grad norm: 0.8584305673998057\n",
      "Epoch 2933, Loss: 209.37051918825546, Neurons: 201, Grad norm: 1.5751381355290224\n",
      "Epoch 2933, Loss: 209.37051918825546, Neurons: 201, Grad norm: 1.5751381355290224\n",
      "Epoch 2934, Loss: 209.37004183256494, Neurons: 201, Grad norm: 2.385383614497441\n",
      "Epoch 2934, Loss: 209.37004183256494, Neurons: 201, Grad norm: 2.385383614497441\n",
      "Epoch 2935, Loss: 209.36969363921372, Neurons: 201, Grad norm: 3.9068949859470576\n",
      "Epoch 2935, Loss: 209.36969363921372, Neurons: 201, Grad norm: 3.9068949859470576\n",
      "Epoch 2936, Loss: 209.36944535518742, Neurons: 201, Grad norm: 4.705352252750289\n",
      "Epoch 2936, Loss: 209.36944535518742, Neurons: 201, Grad norm: 4.705352252750289\n",
      "Epoch 2937, Loss: 209.36917921001867, Neurons: 201, Grad norm: 5.483307197448406\n",
      "Epoch 2937, Loss: 209.36917921001867, Neurons: 201, Grad norm: 5.483307197448406\n",
      "Epoch 2938, Loss: 209.36883160135048, Neurons: 201, Grad norm: 5.0179124891239475\n",
      "Epoch 2938, Loss: 209.36883160135048, Neurons: 201, Grad norm: 5.0179124891239475\n",
      "Epoch 2939, Loss: 209.36832961600422, Neurons: 201, Grad norm: 4.21935243004257\n",
      "Epoch 2939, Loss: 209.36832961600422, Neurons: 201, Grad norm: 4.21935243004257\n",
      "Epoch 2940, Loss: 209.3675877824054, Neurons: 201, Grad norm: 2.3872727076371145\n",
      "Epoch 2940, Loss: 209.3675877824054, Neurons: 201, Grad norm: 2.3872727076371145\n",
      "Epoch 2941, Loss: 209.36683350373025, Neurons: 201, Grad norm: 1.1145386069869814\n",
      "Epoch 2941, Loss: 209.36683350373025, Neurons: 201, Grad norm: 1.1145386069869814\n",
      "Epoch 2942, Loss: 209.36620946897506, Neurons: 201, Grad norm: 1.437452894414539\n",
      "Epoch 2942, Loss: 209.36620946897506, Neurons: 201, Grad norm: 1.437452894414539\n",
      "Epoch 2943, Loss: 209.3657437276318, Neurons: 201, Grad norm: 2.4621227846584364\n",
      "Epoch 2943, Loss: 209.3657437276318, Neurons: 201, Grad norm: 2.4621227846584364\n",
      "Epoch 2944, Loss: 209.3653954482838, Neurons: 201, Grad norm: 4.22178699796141\n",
      "Epoch 2944, Loss: 209.3653954482838, Neurons: 201, Grad norm: 4.22178699796141\n",
      "Epoch 2945, Loss: 209.36516500666372, Neurons: 201, Grad norm: 4.882189980762437\n",
      "Epoch 2945, Loss: 209.36516500666372, Neurons: 201, Grad norm: 4.882189980762437\n",
      "Epoch 2946, Loss: 209.36493213572015, Neurons: 201, Grad norm: 5.538237896925708\n",
      "Epoch 2946, Loss: 209.36493213572015, Neurons: 201, Grad norm: 5.538237896925708\n",
      "Epoch 2947, Loss: 209.36454810147492, Neurons: 201, Grad norm: 4.891941492124576\n",
      "Epoch 2947, Loss: 209.36454810147492, Neurons: 201, Grad norm: 4.891941492124576\n",
      "Epoch 2948, Loss: 209.3639497412943, Neurons: 201, Grad norm: 4.015636235484514\n",
      "Epoch 2948, Loss: 209.3639497412943, Neurons: 201, Grad norm: 4.015636235484514\n",
      "Epoch 2949, Loss: 209.36324418247636, Neurons: 201, Grad norm: 2.327652950208393\n",
      "Epoch 2949, Loss: 209.36324418247636, Neurons: 201, Grad norm: 2.327652950208393\n",
      "Epoch 2950, Loss: 209.36254146942338, Neurons: 201, Grad norm: 1.0740436326499843\n",
      "Epoch 2950, Loss: 209.36254146942338, Neurons: 201, Grad norm: 1.0740436326499843\n",
      "Epoch 2951, Loss: 209.3619428219069, Neurons: 201, Grad norm: 1.4512392703562642\n",
      "Epoch 2951, Loss: 209.3619428219069, Neurons: 201, Grad norm: 1.4512392703562642\n",
      "Epoch 2952, Loss: 209.36150792064694, Neurons: 201, Grad norm: 2.6920925493345242\n",
      "Epoch 2952, Loss: 209.36150792064694, Neurons: 201, Grad norm: 2.6920925493345242\n",
      "Epoch 2953, Loss: 209.36120336395132, Neurons: 201, Grad norm: 4.239018913945753\n",
      "Epoch 2953, Loss: 209.36120336395132, Neurons: 201, Grad norm: 4.239018913945753\n",
      "Epoch 2954, Loss: 209.36096979141445, Neurons: 201, Grad norm: 4.693485851149831\n",
      "Epoch 2954, Loss: 209.36096979141445, Neurons: 201, Grad norm: 4.693485851149831\n",
      "Epoch 2955, Loss: 209.360710722614, Neurons: 201, Grad norm: 5.237356422041207\n",
      "Epoch 2955, Loss: 209.360710722614, Neurons: 201, Grad norm: 5.237356422041207\n",
      "Epoch 2956, Loss: 209.36036307813902, Neurons: 201, Grad norm: 4.3177861321607045\n",
      "Epoch 2956, Loss: 209.36036307813902, Neurons: 201, Grad norm: 4.3177861321607045\n",
      "Epoch 2957, Loss: 209.3597227365686, Neurons: 201, Grad norm: 3.2337034034952836\n",
      "Epoch 2957, Loss: 209.3597227365686, Neurons: 201, Grad norm: 3.2337034034952836\n",
      "Epoch 2958, Loss: 209.35902256711708, Neurons: 201, Grad norm: 1.6537260778782648\n",
      "Epoch 2958, Loss: 209.35902256711708, Neurons: 201, Grad norm: 1.6537260778782648\n",
      "Epoch 2959, Loss: 209.35838114299486, Neurons: 201, Grad norm: 0.8343254914580441\n",
      "Epoch 2959, Loss: 209.35838114299486, Neurons: 201, Grad norm: 0.8343254914580441\n",
      "Epoch 2960, Loss: 209.35788284901338, Neurons: 201, Grad norm: 2.196008417713076\n",
      "Epoch 2960, Loss: 209.35788284901338, Neurons: 201, Grad norm: 2.196008417713076\n",
      "Epoch 2961, Loss: 209.35753540020303, Neurons: 201, Grad norm: 3.136559974023722\n",
      "Epoch 2961, Loss: 209.35753540020303, Neurons: 201, Grad norm: 3.136559974023722\n",
      "Epoch 2962, Loss: 209.35729672431916, Neurons: 201, Grad norm: 4.363877125919903\n",
      "Epoch 2962, Loss: 209.35729672431916, Neurons: 201, Grad norm: 4.363877125919903\n",
      "Epoch 2963, Loss: 209.35697239880108, Neurons: 201, Grad norm: 4.029198351825557\n",
      "Epoch 2963, Loss: 209.35697239880108, Neurons: 201, Grad norm: 4.029198351825557\n",
      "Epoch 2964, Loss: 209.3565909481166, Neurons: 201, Grad norm: 3.7473895029677635\n",
      "Epoch 2964, Loss: 209.3565909481166, Neurons: 201, Grad norm: 3.7473895029677635\n",
      "Epoch 2965, Loss: 209.3560123753193, Neurons: 201, Grad norm: 2.079058371506136\n",
      "Epoch 2965, Loss: 209.3560123753193, Neurons: 201, Grad norm: 2.079058371506136\n",
      "Epoch 2966, Loss: 209.35537372083562, Neurons: 201, Grad norm: 0.9364409843663862\n",
      "Epoch 2966, Loss: 209.35537372083562, Neurons: 201, Grad norm: 0.9364409843663862\n",
      "Epoch 2967, Loss: 209.35480102726723, Neurons: 201, Grad norm: 1.6159091179883864\n",
      "Epoch 2967, Loss: 209.35480102726723, Neurons: 201, Grad norm: 1.6159091179883864\n",
      "Epoch 2968, Loss: 209.354404410679, Neurons: 201, Grad norm: 2.584416242306289\n",
      "Epoch 2968, Loss: 209.354404410679, Neurons: 201, Grad norm: 2.584416242306289\n",
      "Epoch 2969, Loss: 209.35404219940548, Neurons: 201, Grad norm: 3.7384825855053485\n",
      "Epoch 2969, Loss: 209.35404219940548, Neurons: 201, Grad norm: 3.7384825855053485\n",
      "Epoch 2970, Loss: 209.35374286428535, Neurons: 201, Grad norm: 3.916784991386107\n",
      "Epoch 2970, Loss: 209.35374286428535, Neurons: 201, Grad norm: 3.916784991386107\n",
      "Epoch 2971, Loss: 209.35339608901887, Neurons: 201, Grad norm: 4.321308801519136\n",
      "Epoch 2971, Loss: 209.35339608901887, Neurons: 201, Grad norm: 4.321308801519136\n",
      "Epoch 2972, Loss: 209.3529461713526, Neurons: 201, Grad norm: 3.362130721686373\n",
      "Epoch 2972, Loss: 209.3529461713526, Neurons: 201, Grad norm: 3.362130721686373\n",
      "Epoch 2973, Loss: 209.3523623973455, Neurons: 201, Grad norm: 2.8190285529728305\n",
      "Epoch 2973, Loss: 209.3523623973455, Neurons: 201, Grad norm: 2.8190285529728305\n",
      "Epoch 2974, Loss: 209.3517957453634, Neurons: 201, Grad norm: 1.4612395733481085\n",
      "Epoch 2974, Loss: 209.3517957453634, Neurons: 201, Grad norm: 1.4612395733481085\n",
      "Epoch 2975, Loss: 209.35121075214818, Neurons: 201, Grad norm: 0.8308242039273191\n",
      "Epoch 2975, Loss: 209.35121075214818, Neurons: 201, Grad norm: 0.8308242039273191\n",
      "Epoch 2976, Loss: 209.3506845952159, Neurons: 201, Grad norm: 1.366780257767583\n",
      "Epoch 2976, Loss: 209.3506845952159, Neurons: 201, Grad norm: 1.366780257767583\n",
      "Epoch 2977, Loss: 209.35024393003732, Neurons: 201, Grad norm: 1.9499563751931175\n",
      "Epoch 2977, Loss: 209.35024393003732, Neurons: 201, Grad norm: 1.9499563751931175\n",
      "Epoch 2978, Loss: 209.3498641600232, Neurons: 201, Grad norm: 2.9629353580736546\n",
      "Epoch 2978, Loss: 209.3498641600232, Neurons: 201, Grad norm: 2.9629353580736546\n",
      "Epoch 2979, Loss: 209.3494776693737, Neurons: 201, Grad norm: 3.099897607432059\n",
      "Epoch 2979, Loss: 209.3494776693737, Neurons: 201, Grad norm: 3.099897607432059\n",
      "Epoch 2980, Loss: 209.34906343067126, Neurons: 201, Grad norm: 3.124487994318601\n",
      "Epoch 2980, Loss: 209.34906343067126, Neurons: 201, Grad norm: 3.124487994318601\n",
      "Epoch 2981, Loss: 209.3485922031056, Neurons: 201, Grad norm: 2.2852593388756848\n",
      "Epoch 2981, Loss: 209.3485922031056, Neurons: 201, Grad norm: 2.2852593388756848\n",
      "Epoch 2982, Loss: 209.34804726121774, Neurons: 201, Grad norm: 1.650858585791254\n",
      "Epoch 2982, Loss: 209.34804726121774, Neurons: 201, Grad norm: 1.650858585791254\n",
      "Epoch 2983, Loss: 209.3474747114166, Neurons: 201, Grad norm: 0.8086083372184398\n",
      "Epoch 2983, Loss: 209.3474747114166, Neurons: 201, Grad norm: 0.8086083372184398\n",
      "Epoch 2984, Loss: 209.34694387214347, Neurons: 201, Grad norm: 0.8644138014214845\n",
      "Epoch 2984, Loss: 209.34694387214347, Neurons: 201, Grad norm: 0.8644138014214845\n",
      "Epoch 2985, Loss: 209.34647871139083, Neurons: 201, Grad norm: 1.8400394516570606\n",
      "Epoch 2985, Loss: 209.34647871139083, Neurons: 201, Grad norm: 1.8400394516570606\n",
      "Epoch 2986, Loss: 209.3460699900729, Neurons: 201, Grad norm: 2.2558103850290205\n",
      "Epoch 2986, Loss: 209.3460699900729, Neurons: 201, Grad norm: 2.2558103850290205\n",
      "Epoch 2987, Loss: 209.3456643622751, Neurons: 201, Grad norm: 3.3669292927972543\n",
      "Epoch 2987, Loss: 209.3456643622751, Neurons: 201, Grad norm: 3.3669292927972543\n",
      "Epoch 2988, Loss: 209.34532753077, Neurons: 201, Grad norm: 3.567753444081704\n",
      "Epoch 2988, Loss: 209.34532753077, Neurons: 201, Grad norm: 3.567753444081704\n",
      "Epoch 2989, Loss: 209.3449562026925, Neurons: 201, Grad norm: 3.788722574628408\n",
      "Epoch 2989, Loss: 209.3449562026925, Neurons: 201, Grad norm: 3.788722574628408\n",
      "Epoch 2990, Loss: 209.34452377575553, Neurons: 201, Grad norm: 3.056451727924145\n",
      "Epoch 2990, Loss: 209.34452377575553, Neurons: 201, Grad norm: 3.056451727924145\n",
      "Epoch 2991, Loss: 209.34399475145707, Neurons: 201, Grad norm: 2.302879609584927\n",
      "Epoch 2991, Loss: 209.34399475145707, Neurons: 201, Grad norm: 2.302879609584927\n",
      "Epoch 2992, Loss: 209.34340179566587, Neurons: 201, Grad norm: 1.0143826754083756\n",
      "Epoch 2992, Loss: 209.34340179566587, Neurons: 201, Grad norm: 1.0143826754083756\n",
      "Epoch 2993, Loss: 209.34283816321366, Neurons: 201, Grad norm: 0.9021029971764111\n",
      "Epoch 2993, Loss: 209.34283816321366, Neurons: 201, Grad norm: 0.9021029971764111\n",
      "Epoch 2994, Loss: 209.34238060630113, Neurons: 201, Grad norm: 2.0490096809549887\n",
      "Epoch 2994, Loss: 209.34238060630113, Neurons: 201, Grad norm: 2.0490096809549887\n",
      "Epoch 2995, Loss: 209.34199597842073, Neurons: 201, Grad norm: 2.825122705725289\n",
      "Epoch 2995, Loss: 209.34199597842073, Neurons: 201, Grad norm: 2.825122705725289\n",
      "Epoch 2996, Loss: 209.34167086782531, Neurons: 201, Grad norm: 3.8349020818914004\n",
      "Epoch 2996, Loss: 209.34167086782531, Neurons: 201, Grad norm: 3.8349020818914004\n",
      "Epoch 2997, Loss: 209.34138804680825, Neurons: 201, Grad norm: 4.091419915899373\n",
      "Epoch 2997, Loss: 209.34138804680825, Neurons: 201, Grad norm: 4.091419915899373\n",
      "Epoch 2998, Loss: 209.34105834488992, Neurons: 201, Grad norm: 4.407869998299515\n",
      "Epoch 2998, Loss: 209.34105834488992, Neurons: 201, Grad norm: 4.407869998299515\n",
      "Epoch 2999, Loss: 209.3406386373146, Neurons: 201, Grad norm: 3.422229151474615\n",
      "Epoch 2999, Loss: 209.3406386373146, Neurons: 201, Grad norm: 3.422229151474615\n",
      "Epoch 3000, Loss: 209.3401281559711, Neurons: 201, Grad norm: 2.4457421547496208\n",
      "Epoch 3000, Loss: 209.3401281559711, Neurons: 201, Grad norm: 2.4457421547496208\n",
      "Epoch 3001, Loss: 209.33948589275238, Neurons: 201, Grad norm: 0.9128663145061319\n",
      "Epoch 3001, Loss: 209.33948589275238, Neurons: 201, Grad norm: 0.9128663145061319\n",
      "Epoch 3002, Loss: 209.33897739713524, Neurons: 201, Grad norm: 1.2068960838228275\n",
      "Epoch 3002, Loss: 209.33897739713524, Neurons: 201, Grad norm: 1.2068960838228275\n",
      "Epoch 3003, Loss: 209.33855756745422, Neurons: 201, Grad norm: 2.6273482739383813\n",
      "Epoch 3003, Loss: 209.33855756745422, Neurons: 201, Grad norm: 2.6273482739383813\n",
      "Epoch 3004, Loss: 209.3382190190104, Neurons: 201, Grad norm: 3.3428511508766467\n",
      "Epoch 3004, Loss: 209.3382190190104, Neurons: 201, Grad norm: 3.3428511508766467\n",
      "Epoch 3005, Loss: 209.33793589065462, Neurons: 201, Grad norm: 3.883969946219095\n",
      "Epoch 3005, Loss: 209.33793589065462, Neurons: 201, Grad norm: 3.883969946219095\n",
      "Epoch 3006, Loss: 209.3375870365922, Neurons: 201, Grad norm: 3.4060756184904806\n",
      "Epoch 3006, Loss: 209.3375870365922, Neurons: 201, Grad norm: 3.4060756184904806\n",
      "Epoch 3007, Loss: 209.33713514813556, Neurons: 201, Grad norm: 2.5948394791498814\n",
      "Epoch 3007, Loss: 209.33713514813556, Neurons: 201, Grad norm: 2.5948394791498814\n",
      "Epoch 3008, Loss: 209.33652180182202, Neurons: 201, Grad norm: 1.119112662952967\n",
      "Epoch 3008, Loss: 209.33652180182202, Neurons: 201, Grad norm: 1.119112662952967\n",
      "Epoch 3009, Loss: 209.33600383770525, Neurons: 201, Grad norm: 0.8641307859971198\n",
      "Epoch 3009, Loss: 209.33600383770525, Neurons: 201, Grad norm: 0.8641307859971198\n",
      "Epoch 3010, Loss: 209.33557722947117, Neurons: 201, Grad norm: 2.0092234963002213\n",
      "Epoch 3010, Loss: 209.33557722947117, Neurons: 201, Grad norm: 2.0092234963002213\n",
      "Epoch 3011, Loss: 209.3352293900606, Neurons: 201, Grad norm: 2.7118227919458713\n",
      "Epoch 3011, Loss: 209.3352293900606, Neurons: 201, Grad norm: 2.7118227919458713\n",
      "Epoch 3012, Loss: 209.33493246731828, Neurons: 201, Grad norm: 3.975966402183711\n",
      "Epoch 3012, Loss: 209.33493246731828, Neurons: 201, Grad norm: 3.975966402183711\n",
      "Epoch 3013, Loss: 209.334673090712, Neurons: 201, Grad norm: 4.272744356242641\n",
      "Epoch 3013, Loss: 209.334673090712, Neurons: 201, Grad norm: 4.272744356242641\n",
      "Epoch 3014, Loss: 209.33439002416398, Neurons: 201, Grad norm: 4.685814090962776\n",
      "Epoch 3014, Loss: 209.33439002416398, Neurons: 201, Grad norm: 4.685814090962776\n",
      "Epoch 3015, Loss: 209.33402069353585, Neurons: 201, Grad norm: 4.002416167034514\n",
      "Epoch 3015, Loss: 209.33402069353585, Neurons: 201, Grad norm: 4.002416167034514\n",
      "Epoch 3016, Loss: 209.3335142102191, Neurons: 201, Grad norm: 2.9879270774710416\n",
      "Epoch 3016, Loss: 209.3335142102191, Neurons: 201, Grad norm: 2.9879270774710416\n",
      "Epoch 3017, Loss: 209.33291065649314, Neurons: 201, Grad norm: 1.2942109605669296\n",
      "Epoch 3017, Loss: 209.33291065649314, Neurons: 201, Grad norm: 1.2942109605669296\n",
      "Epoch 3018, Loss: 209.33230802177192, Neurons: 201, Grad norm: 0.7077821017740809\n",
      "Epoch 3018, Loss: 209.33230802177192, Neurons: 201, Grad norm: 0.7077821017740809\n",
      "Epoch 3019, Loss: 209.33190281504318, Neurons: 201, Grad norm: 1.9503771229223403\n",
      "Epoch 3019, Loss: 209.33190281504318, Neurons: 201, Grad norm: 1.9503771229223403\n",
      "Epoch 3020, Loss: 209.33156650243535, Neurons: 201, Grad norm: 2.406258474710732\n",
      "Epoch 3020, Loss: 209.33156650243535, Neurons: 201, Grad norm: 2.406258474710732\n",
      "Epoch 3021, Loss: 209.33123590142213, Neurons: 201, Grad norm: 2.8732330699191557\n",
      "Epoch 3021, Loss: 209.33123590142213, Neurons: 201, Grad norm: 2.8732330699191557\n",
      "Epoch 3022, Loss: 209.33086239177052, Neurons: 201, Grad norm: 2.649592643694004\n",
      "Epoch 3022, Loss: 209.33086239177052, Neurons: 201, Grad norm: 2.649592643694004\n",
      "Epoch 3023, Loss: 209.33044918167434, Neurons: 201, Grad norm: 2.3530013609549165\n",
      "Epoch 3023, Loss: 209.33044918167434, Neurons: 201, Grad norm: 2.3530013609549165\n",
      "Epoch 3024, Loss: 209.3299750037385, Neurons: 201, Grad norm: 1.6133803442697736\n",
      "Epoch 3024, Loss: 209.3299750037385, Neurons: 201, Grad norm: 1.6133803442697736\n",
      "Epoch 3025, Loss: 209.32951726399835, Neurons: 201, Grad norm: 1.2375125777342113\n",
      "Epoch 3025, Loss: 209.32951726399835, Neurons: 201, Grad norm: 1.2375125777342113\n",
      "Epoch 3026, Loss: 209.3290809553219, Neurons: 201, Grad norm: 0.7963482212310169\n",
      "Epoch 3026, Loss: 209.3290809553219, Neurons: 201, Grad norm: 0.7963482212310169\n",
      "Epoch 3027, Loss: 209.32864858467866, Neurons: 201, Grad norm: 1.0628398103504324\n",
      "Epoch 3027, Loss: 209.32864858467866, Neurons: 201, Grad norm: 1.0628398103504324\n",
      "Epoch 3028, Loss: 209.32827837128536, Neurons: 201, Grad norm: 1.9005191629241251\n",
      "Epoch 3028, Loss: 209.32827837128536, Neurons: 201, Grad norm: 1.9005191629241251\n",
      "Epoch 3029, Loss: 209.3279443108938, Neurons: 201, Grad norm: 2.507645422303841\n",
      "Epoch 3029, Loss: 209.3279443108938, Neurons: 201, Grad norm: 2.507645422303841\n",
      "Epoch 3030, Loss: 209.32759993331683, Neurons: 201, Grad norm: 3.678080824061416\n",
      "Epoch 3030, Loss: 209.32759993331683, Neurons: 201, Grad norm: 3.678080824061416\n",
      "Epoch 3031, Loss: 209.32736895639073, Neurons: 201, Grad norm: 4.043293963355853\n",
      "Epoch 3031, Loss: 209.32736895639073, Neurons: 201, Grad norm: 4.043293963355853\n",
      "Epoch 3032, Loss: 209.32712563436647, Neurons: 201, Grad norm: 4.681858686736273\n",
      "Epoch 3032, Loss: 209.32712563436647, Neurons: 201, Grad norm: 4.681858686736273\n",
      "Epoch 3033, Loss: 209.3267612316917, Neurons: 201, Grad norm: 4.03329367308582\n",
      "Epoch 3033, Loss: 209.3267612316917, Neurons: 201, Grad norm: 4.03329367308582\n",
      "Epoch 3034, Loss: 209.3263300935419, Neurons: 201, Grad norm: 3.1426895015938956\n",
      "Epoch 3034, Loss: 209.3263300935419, Neurons: 201, Grad norm: 3.1426895015938956\n",
      "Epoch 3035, Loss: 209.32574535840598, Neurons: 201, Grad norm: 1.3535070516263885\n",
      "Epoch 3035, Loss: 209.32574535840598, Neurons: 201, Grad norm: 1.3535070516263885\n",
      "Epoch 3036, Loss: 209.32514642249242, Neurons: 201, Grad norm: 0.9871095554334172\n",
      "Epoch 3036, Loss: 209.32514642249242, Neurons: 201, Grad norm: 0.9871095554334172\n",
      "Epoch 3037, Loss: 209.3247107086219, Neurons: 201, Grad norm: 2.6294998423482783\n",
      "Epoch 3037, Loss: 209.3247107086219, Neurons: 201, Grad norm: 2.6294998423482783\n",
      "Epoch 3038, Loss: 209.3244530732112, Neurons: 201, Grad norm: 3.314045789103653\n",
      "Epoch 3038, Loss: 209.3244530732112, Neurons: 201, Grad norm: 3.314045789103653\n",
      "Epoch 3039, Loss: 209.32421510180248, Neurons: 201, Grad norm: 3.9678935579025385\n",
      "Epoch 3039, Loss: 209.32421510180248, Neurons: 201, Grad norm: 3.9678935579025385\n",
      "Epoch 3040, Loss: 209.32387232019178, Neurons: 201, Grad norm: 3.593448137473771\n",
      "Epoch 3040, Loss: 209.32387232019178, Neurons: 201, Grad norm: 3.593448137473771\n",
      "Epoch 3041, Loss: 209.32343973581706, Neurons: 201, Grad norm: 3.297146349326955\n",
      "Epoch 3041, Loss: 209.32343973581706, Neurons: 201, Grad norm: 3.297146349326955\n",
      "Epoch 3042, Loss: 209.32296769423695, Neurons: 201, Grad norm: 2.1319380352351014\n",
      "Epoch 3042, Loss: 209.32296769423695, Neurons: 201, Grad norm: 2.1319380352351014\n",
      "Epoch 3043, Loss: 209.32247216277878, Neurons: 201, Grad norm: 1.2955122193741648\n",
      "Epoch 3043, Loss: 209.32247216277878, Neurons: 201, Grad norm: 1.2955122193741648\n",
      "Epoch 3044, Loss: 209.3219734909229, Neurons: 201, Grad norm: 0.8731879033896084\n",
      "Epoch 3044, Loss: 209.3219734909229, Neurons: 201, Grad norm: 0.8731879033896084\n",
      "Epoch 3045, Loss: 209.3215507494082, Neurons: 201, Grad norm: 1.582401628721779\n",
      "Epoch 3045, Loss: 209.3215507494082, Neurons: 201, Grad norm: 1.582401628721779\n",
      "Epoch 3046, Loss: 209.32121964866158, Neurons: 201, Grad norm: 2.7138466565537445\n",
      "Epoch 3046, Loss: 209.32121964866158, Neurons: 201, Grad norm: 2.7138466565537445\n",
      "Epoch 3047, Loss: 209.32091554046926, Neurons: 201, Grad norm: 3.0347382658950255\n",
      "Epoch 3047, Loss: 209.32091554046926, Neurons: 201, Grad norm: 3.0347382658950255\n",
      "Epoch 3048, Loss: 209.32062285606662, Neurons: 201, Grad norm: 3.615396149613265\n",
      "Epoch 3048, Loss: 209.32062285606662, Neurons: 201, Grad norm: 3.615396149613265\n",
      "Epoch 3049, Loss: 209.32028311112998, Neurons: 201, Grad norm: 3.323906887378233\n",
      "Epoch 3049, Loss: 209.32028311112998, Neurons: 201, Grad norm: 3.323906887378233\n",
      "Epoch 3050, Loss: 209.31988270805053, Neurons: 201, Grad norm: 2.8485097969958977\n",
      "Epoch 3050, Loss: 209.31988270805053, Neurons: 201, Grad norm: 2.8485097969958977\n",
      "Epoch 3051, Loss: 209.31939951687642, Neurons: 201, Grad norm: 1.6869779095359054\n",
      "Epoch 3051, Loss: 209.31939951687642, Neurons: 201, Grad norm: 1.6869779095359054\n",
      "Epoch 3052, Loss: 209.31890591915862, Neurons: 201, Grad norm: 0.8542103124145407\n",
      "Epoch 3052, Loss: 209.31890591915862, Neurons: 201, Grad norm: 0.8542103124145407\n",
      "Epoch 3053, Loss: 209.31844745848701, Neurons: 201, Grad norm: 1.3702565903266561\n",
      "Epoch 3053, Loss: 209.31844745848701, Neurons: 201, Grad norm: 1.3702565903266561\n",
      "Epoch 3054, Loss: 209.31806839322883, Neurons: 201, Grad norm: 1.8993292887988014\n",
      "Epoch 3054, Loss: 209.31806839322883, Neurons: 201, Grad norm: 1.8993292887988014\n",
      "Epoch 3055, Loss: 209.31775227469657, Neurons: 201, Grad norm: 2.924932064381998\n",
      "Epoch 3055, Loss: 209.31775227469657, Neurons: 201, Grad norm: 2.924932064381998\n",
      "Epoch 3056, Loss: 209.31741759074333, Neurons: 201, Grad norm: 2.937251863622251\n",
      "Epoch 3056, Loss: 209.31741759074333, Neurons: 201, Grad norm: 2.937251863622251\n",
      "Epoch 3057, Loss: 209.31705604014573, Neurons: 201, Grad norm: 2.9819489228162728\n",
      "Epoch 3057, Loss: 209.31705604014573, Neurons: 201, Grad norm: 2.9819489228162728\n",
      "Epoch 3058, Loss: 209.31663335886233, Neurons: 201, Grad norm: 2.2962181354642044\n",
      "Epoch 3058, Loss: 209.31663335886233, Neurons: 201, Grad norm: 2.2962181354642044\n",
      "Epoch 3059, Loss: 209.31613406272783, Neurons: 201, Grad norm: 1.5601129266998957\n",
      "Epoch 3059, Loss: 209.31613406272783, Neurons: 201, Grad norm: 1.5601129266998957\n",
      "Epoch 3060, Loss: 209.31564945964462, Neurons: 201, Grad norm: 0.7095324954172402\n",
      "Epoch 3060, Loss: 209.31564945964462, Neurons: 201, Grad norm: 0.7095324954172402\n",
      "Epoch 3061, Loss: 209.3151783635874, Neurons: 201, Grad norm: 0.9538265479672727\n",
      "Epoch 3061, Loss: 209.3151783635874, Neurons: 201, Grad norm: 0.9538265479672727\n",
      "Epoch 3062, Loss: 209.31479468947114, Neurons: 201, Grad norm: 2.0686354746506623\n",
      "Epoch 3062, Loss: 209.31479468947114, Neurons: 201, Grad norm: 2.0686354746506623\n",
      "Epoch 3063, Loss: 209.31443383215333, Neurons: 201, Grad norm: 2.6094013226271664\n",
      "Epoch 3063, Loss: 209.31443383215333, Neurons: 201, Grad norm: 2.6094013226271664\n",
      "Epoch 3064, Loss: 209.31406121155723, Neurons: 201, Grad norm: 3.830774921111484\n",
      "Epoch 3064, Loss: 209.31406121155723, Neurons: 201, Grad norm: 3.830774921111484\n",
      "Epoch 3065, Loss: 209.31379738197845, Neurons: 201, Grad norm: 3.975786780228797\n",
      "Epoch 3065, Loss: 209.31379738197845, Neurons: 201, Grad norm: 3.975786780228797\n",
      "Epoch 3066, Loss: 209.31346428545083, Neurons: 201, Grad norm: 4.462468785149067\n",
      "Epoch 3066, Loss: 209.31346428545083, Neurons: 201, Grad norm: 4.462468785149067\n",
      "Epoch 3067, Loss: 209.31307618386032, Neurons: 201, Grad norm: 3.8689571994457554\n",
      "Epoch 3067, Loss: 209.31307618386032, Neurons: 201, Grad norm: 3.8689571994457554\n",
      "Epoch 3068, Loss: 209.31256475074431, Neurons: 201, Grad norm: 3.078685971843888\n",
      "Epoch 3068, Loss: 209.31256475074431, Neurons: 201, Grad norm: 3.078685971843888\n",
      "Epoch 3069, Loss: 209.31200559343642, Neurons: 201, Grad norm: 1.8680908715204443\n",
      "Epoch 3069, Loss: 209.31200559343642, Neurons: 201, Grad norm: 1.8680908715204443\n",
      "Epoch 3070, Loss: 209.31143374935627, Neurons: 201, Grad norm: 1.079502513123527\n",
      "Epoch 3070, Loss: 209.31143374935627, Neurons: 201, Grad norm: 1.079502513123527\n",
      "Epoch 3071, Loss: 209.31093200642826, Neurons: 201, Grad norm: 0.8935724124316268\n",
      "Epoch 3071, Loss: 209.31093200642826, Neurons: 201, Grad norm: 0.8935724124316268\n",
      "Epoch 3072, Loss: 209.31049150014564, Neurons: 201, Grad norm: 1.174327966078539\n",
      "Epoch 3072, Loss: 209.31049150014564, Neurons: 201, Grad norm: 1.174327966078539\n",
      "Epoch 3073, Loss: 209.31007365688274, Neurons: 201, Grad norm: 1.8612280364323832\n",
      "Epoch 3073, Loss: 209.31007365688274, Neurons: 201, Grad norm: 1.8612280364323832\n",
      "Epoch 3074, Loss: 209.3096691604767, Neurons: 201, Grad norm: 1.7701112831906334\n",
      "Epoch 3074, Loss: 209.3096691604767, Neurons: 201, Grad norm: 1.7701112831906334\n",
      "Epoch 3075, Loss: 209.30927391316146, Neurons: 201, Grad norm: 1.9398925733951033\n",
      "Epoch 3075, Loss: 209.30927391316146, Neurons: 201, Grad norm: 1.9398925733951033\n",
      "Epoch 3076, Loss: 209.3088443100989, Neurons: 201, Grad norm: 1.3823038937057996\n",
      "Epoch 3076, Loss: 209.3088443100989, Neurons: 201, Grad norm: 1.3823038937057996\n",
      "Epoch 3077, Loss: 209.30840425595727, Neurons: 201, Grad norm: 1.2569913259188252\n",
      "Epoch 3077, Loss: 209.30840425595727, Neurons: 201, Grad norm: 1.2569913259188252\n",
      "Epoch 3078, Loss: 209.3079383508841, Neurons: 201, Grad norm: 0.9489930643060691\n",
      "Epoch 3078, Loss: 209.3079383508841, Neurons: 201, Grad norm: 0.9489930643060691\n",
      "Epoch 3079, Loss: 209.30749533441067, Neurons: 201, Grad norm: 0.9741383556717006\n",
      "Epoch 3079, Loss: 209.30749533441067, Neurons: 201, Grad norm: 0.9741383556717006\n",
      "Epoch 3080, Loss: 209.3070642700122, Neurons: 201, Grad norm: 0.7265920934174666\n",
      "Epoch 3080, Loss: 209.3070642700122, Neurons: 201, Grad norm: 0.7265920934174666\n",
      "Epoch 3081, Loss: 209.30658537793153, Neurons: 201, Grad norm: 0.7582862690065841\n",
      "Epoch 3081, Loss: 209.30658537793153, Neurons: 201, Grad norm: 0.7582862690065841\n",
      "Epoch 3082, Loss: 209.30613597759586, Neurons: 201, Grad norm: 1.0676359088489022\n",
      "Epoch 3082, Loss: 209.30613597759586, Neurons: 201, Grad norm: 1.0676359088489022\n",
      "Epoch 3083, Loss: 209.30568412090767, Neurons: 201, Grad norm: 1.4760622301008532\n",
      "Epoch 3083, Loss: 209.30568412090767, Neurons: 201, Grad norm: 1.4760622301008532\n",
      "Epoch 3084, Loss: 209.30525216715972, Neurons: 201, Grad norm: 2.1373642190260367\n",
      "Epoch 3084, Loss: 209.30525216715972, Neurons: 201, Grad norm: 2.1373642190260367\n",
      "Epoch 3085, Loss: 209.3048686293347, Neurons: 201, Grad norm: 2.7233972123749344\n",
      "Epoch 3085, Loss: 209.3048686293347, Neurons: 201, Grad norm: 2.7233972123749344\n",
      "Epoch 3086, Loss: 209.30449304486245, Neurons: 201, Grad norm: 3.5452237409742384\n",
      "Epoch 3086, Loss: 209.30449304486245, Neurons: 201, Grad norm: 3.5452237409742384\n",
      "Epoch 3087, Loss: 209.30416200966965, Neurons: 201, Grad norm: 3.826686638366402\n",
      "Epoch 3087, Loss: 209.30416200966965, Neurons: 201, Grad norm: 3.826686638366402\n",
      "Epoch 3088, Loss: 209.3038213946912, Neurons: 201, Grad norm: 4.401044102238645\n",
      "Epoch 3088, Loss: 209.3038213946912, Neurons: 201, Grad norm: 4.401044102238645\n",
      "Epoch 3089, Loss: 209.30344234506023, Neurons: 201, Grad norm: 3.9391418336704622\n",
      "Epoch 3089, Loss: 209.30344234506023, Neurons: 201, Grad norm: 3.9391418336704622\n",
      "Epoch 3090, Loss: 209.30295885247497, Neurons: 201, Grad norm: 3.3275646623000945\n",
      "Epoch 3090, Loss: 209.30295885247497, Neurons: 201, Grad norm: 3.3275646623000945\n",
      "Epoch 3091, Loss: 209.30240284983282, Neurons: 201, Grad norm: 1.8384067437607596\n",
      "Epoch 3091, Loss: 209.30240284983282, Neurons: 201, Grad norm: 1.8384067437607596\n",
      "Epoch 3092, Loss: 209.30185832093827, Neurons: 201, Grad norm: 0.9217287457202459\n",
      "Epoch 3092, Loss: 209.30185832093827, Neurons: 201, Grad norm: 0.9217287457202459\n",
      "Epoch 3093, Loss: 209.30135155095525, Neurons: 201, Grad norm: 1.4769080739336977\n",
      "Epoch 3093, Loss: 209.30135155095525, Neurons: 201, Grad norm: 1.4769080739336977\n",
      "Epoch 3094, Loss: 209.30096273967757, Neurons: 201, Grad norm: 2.1723080945177604\n",
      "Epoch 3094, Loss: 209.30096273967757, Neurons: 201, Grad norm: 2.1723080945177604\n",
      "Epoch 3095, Loss: 209.30064514946412, Neurons: 201, Grad norm: 3.028383151059184\n",
      "Epoch 3095, Loss: 209.30064514946412, Neurons: 201, Grad norm: 3.028383151059184\n",
      "Epoch 3096, Loss: 209.3002646556704, Neurons: 201, Grad norm: 3.0717734040158344\n",
      "Epoch 3096, Loss: 209.3002646556704, Neurons: 201, Grad norm: 3.0717734040158344\n",
      "Epoch 3097, Loss: 209.29987569222348, Neurons: 201, Grad norm: 3.101745006277913\n",
      "Epoch 3097, Loss: 209.29987569222348, Neurons: 201, Grad norm: 3.101745006277913\n",
      "Epoch 3098, Loss: 209.29943244592923, Neurons: 201, Grad norm: 2.2077170561059933\n",
      "Epoch 3098, Loss: 209.29943244592923, Neurons: 201, Grad norm: 2.2077170561059933\n",
      "Epoch 3099, Loss: 209.2989037414024, Neurons: 201, Grad norm: 1.512674187947843\n",
      "Epoch 3099, Loss: 209.2989037414024, Neurons: 201, Grad norm: 1.512674187947843\n",
      "Epoch 3100, Loss: 209.29840151375222, Neurons: 201, Grad norm: 0.7813416377909415\n",
      "Epoch 3100, Loss: 209.29840151375222, Neurons: 201, Grad norm: 0.7813416377909415\n",
      "Epoch 3101, Loss: 209.29791362492725, Neurons: 201, Grad norm: 1.4415885490184268\n",
      "Epoch 3101, Loss: 209.29791362492725, Neurons: 201, Grad norm: 1.4415885490184268\n",
      "Epoch 3102, Loss: 209.29752477436887, Neurons: 201, Grad norm: 2.4650167173276576\n",
      "Epoch 3102, Loss: 209.29752477436887, Neurons: 201, Grad norm: 2.4650167173276576\n",
      "Epoch 3103, Loss: 209.29719288763818, Neurons: 201, Grad norm: 2.9423404183893607\n",
      "Epoch 3103, Loss: 209.29719288763818, Neurons: 201, Grad norm: 2.9423404183893607\n",
      "Epoch 3104, Loss: 209.29686032533226, Neurons: 201, Grad norm: 4.066621620123158\n",
      "Epoch 3104, Loss: 209.29686032533226, Neurons: 201, Grad norm: 4.066621620123158\n",
      "Epoch 3105, Loss: 209.2965663518969, Neurons: 201, Grad norm: 4.223892321587709\n",
      "Epoch 3105, Loss: 209.2965663518969, Neurons: 201, Grad norm: 4.223892321587709\n",
      "Epoch 3106, Loss: 209.29623293721426, Neurons: 201, Grad norm: 4.563457488276175\n",
      "Epoch 3106, Loss: 209.29623293721426, Neurons: 201, Grad norm: 4.563457488276175\n",
      "Epoch 3107, Loss: 209.29581611170894, Neurons: 201, Grad norm: 3.7704191113547734\n",
      "Epoch 3107, Loss: 209.29581611170894, Neurons: 201, Grad norm: 3.7704191113547734\n",
      "Epoch 3108, Loss: 209.29529351106427, Neurons: 201, Grad norm: 2.9117946165469935\n",
      "Epoch 3108, Loss: 209.29529351106427, Neurons: 201, Grad norm: 2.9117946165469935\n",
      "Epoch 3109, Loss: 209.29465874168466, Neurons: 201, Grad norm: 1.044487773425364\n",
      "Epoch 3109, Loss: 209.29465874168466, Neurons: 201, Grad norm: 1.044487773425364\n",
      "Epoch 3110, Loss: 209.29410104257138, Neurons: 201, Grad norm: 1.0403947209356115\n",
      "Epoch 3110, Loss: 209.29410104257138, Neurons: 201, Grad norm: 1.0403947209356115\n",
      "Epoch 3111, Loss: 209.2937024918648, Neurons: 201, Grad norm: 2.5676165930445727\n",
      "Epoch 3111, Loss: 209.2937024918648, Neurons: 201, Grad norm: 2.5676165930445727\n",
      "Epoch 3112, Loss: 209.29334733153402, Neurons: 201, Grad norm: 3.7446823857635767\n",
      "Epoch 3112, Loss: 209.29334733153402, Neurons: 201, Grad norm: 3.7446823857635767\n",
      "Epoch 3113, Loss: 209.29315017575786, Neurons: 201, Grad norm: 4.895030176805855\n",
      "Epoch 3113, Loss: 209.29315017575786, Neurons: 201, Grad norm: 4.895030176805855\n",
      "Epoch 3114, Loss: 209.29289747781576, Neurons: 201, Grad norm: 5.273679663858876\n",
      "Epoch 3114, Loss: 209.29289747781576, Neurons: 201, Grad norm: 5.273679663858876\n",
      "Epoch 3115, Loss: 209.2926047192984, Neurons: 201, Grad norm: 5.416847326639706\n",
      "Epoch 3115, Loss: 209.2926047192984, Neurons: 201, Grad norm: 5.416847326639706\n",
      "Epoch 3116, Loss: 209.29224189641207, Neurons: 201, Grad norm: 4.429407195937409\n",
      "Epoch 3116, Loss: 209.29224189641207, Neurons: 201, Grad norm: 4.429407195937409\n",
      "Epoch 3117, Loss: 209.29163053623944, Neurons: 201, Grad norm: 3.239612347434528\n",
      "Epoch 3117, Loss: 209.29163053623944, Neurons: 201, Grad norm: 3.239612347434528\n",
      "Epoch 3118, Loss: 209.29096650392697, Neurons: 201, Grad norm: 1.1877001315749087\n",
      "Epoch 3118, Loss: 209.29096650392697, Neurons: 201, Grad norm: 1.1877001315749087\n",
      "Epoch 3119, Loss: 209.29036308244343, Neurons: 201, Grad norm: 1.0247725242935186\n",
      "Epoch 3119, Loss: 209.29036308244343, Neurons: 201, Grad norm: 1.0247725242935186\n",
      "Epoch 3120, Loss: 209.28994832235566, Neurons: 201, Grad norm: 2.8297097253444536\n",
      "Epoch 3120, Loss: 209.28994832235566, Neurons: 201, Grad norm: 2.8297097253444536\n",
      "Epoch 3121, Loss: 209.2896677058536, Neurons: 201, Grad norm: 3.5132267423250876\n",
      "Epoch 3121, Loss: 209.2896677058536, Neurons: 201, Grad norm: 3.5132267423250876\n",
      "Epoch 3122, Loss: 209.28940333969834, Neurons: 201, Grad norm: 4.376999827035746\n",
      "Epoch 3122, Loss: 209.28940333969834, Neurons: 201, Grad norm: 4.376999827035746\n",
      "Epoch 3123, Loss: 209.28911631814057, Neurons: 201, Grad norm: 4.002957703076626\n",
      "Epoch 3123, Loss: 209.28911631814057, Neurons: 201, Grad norm: 4.002957703076626\n",
      "Epoch 3124, Loss: 209.28866338188553, Neurons: 201, Grad norm: 3.214239940850326\n",
      "Epoch 3124, Loss: 209.28866338188553, Neurons: 201, Grad norm: 3.214239940850326\n",
      "Epoch 3125, Loss: 209.28810724309074, Neurons: 201, Grad norm: 1.8219518154186491\n",
      "Epoch 3125, Loss: 209.28810724309074, Neurons: 201, Grad norm: 1.8219518154186491\n",
      "Epoch 3126, Loss: 209.28754471477714, Neurons: 201, Grad norm: 0.7488171629065764\n",
      "Epoch 3126, Loss: 209.28754471477714, Neurons: 201, Grad norm: 0.7488171629065764\n",
      "Epoch 3127, Loss: 209.28705255112894, Neurons: 201, Grad norm: 1.5796528487077097\n",
      "Epoch 3127, Loss: 209.28705255112894, Neurons: 201, Grad norm: 1.5796528487077097\n",
      "Epoch 3128, Loss: 209.28669743444786, Neurons: 201, Grad norm: 2.1788282423876595\n",
      "Epoch 3128, Loss: 209.28669743444786, Neurons: 201, Grad norm: 2.1788282423876595\n",
      "Epoch 3129, Loss: 209.28636422919496, Neurons: 201, Grad norm: 3.1779655720622313\n",
      "Epoch 3129, Loss: 209.28636422919496, Neurons: 201, Grad norm: 3.1779655720622313\n",
      "Epoch 3130, Loss: 209.28604087065958, Neurons: 201, Grad norm: 3.0910719448578243\n",
      "Epoch 3130, Loss: 209.28604087065958, Neurons: 201, Grad norm: 3.0910719448578243\n",
      "Epoch 3131, Loss: 209.28567600466053, Neurons: 201, Grad norm: 3.508898684888043\n",
      "Epoch 3131, Loss: 209.28567600466053, Neurons: 201, Grad norm: 3.508898684888043\n",
      "Epoch 3132, Loss: 209.2852919036818, Neurons: 201, Grad norm: 3.0593147617759326\n",
      "Epoch 3132, Loss: 209.2852919036818, Neurons: 201, Grad norm: 3.0593147617759326\n",
      "Epoch 3133, Loss: 209.2848744762714, Neurons: 201, Grad norm: 2.407994066701743\n",
      "Epoch 3133, Loss: 209.2848744762714, Neurons: 201, Grad norm: 2.407994066701743\n",
      "Epoch 3134, Loss: 209.28435605095672, Neurons: 201, Grad norm: 1.4684018462085677\n",
      "Epoch 3134, Loss: 209.28435605095672, Neurons: 201, Grad norm: 1.4684018462085677\n",
      "Epoch 3135, Loss: 209.28392909637685, Neurons: 201, Grad norm: 0.7875181988493987\n",
      "Epoch 3135, Loss: 209.28392909637685, Neurons: 201, Grad norm: 0.7875181988493987\n",
      "Epoch 3136, Loss: 209.28346398243022, Neurons: 201, Grad norm: 1.352603192209487\n",
      "Epoch 3136, Loss: 209.28346398243022, Neurons: 201, Grad norm: 1.352603192209487\n",
      "Epoch 3137, Loss: 209.28308413294656, Neurons: 201, Grad norm: 2.181977002654712\n",
      "Epoch 3137, Loss: 209.28308413294656, Neurons: 201, Grad norm: 2.181977002654712\n",
      "Epoch 3138, Loss: 209.28277055795164, Neurons: 201, Grad norm: 3.250775891916007\n",
      "Epoch 3138, Loss: 209.28277055795164, Neurons: 201, Grad norm: 3.250775891916007\n",
      "Epoch 3139, Loss: 209.28244767119958, Neurons: 201, Grad norm: 3.6382963629489504\n",
      "Epoch 3139, Loss: 209.28244767119958, Neurons: 201, Grad norm: 3.6382963629489504\n",
      "Epoch 3140, Loss: 209.28216143095742, Neurons: 201, Grad norm: 4.05229544655039\n",
      "Epoch 3140, Loss: 209.28216143095742, Neurons: 201, Grad norm: 4.05229544655039\n",
      "Epoch 3141, Loss: 209.28182910101776, Neurons: 201, Grad norm: 3.288510713992737\n",
      "Epoch 3141, Loss: 209.28182910101776, Neurons: 201, Grad norm: 3.288510713992737\n",
      "Epoch 3142, Loss: 209.28132032910057, Neurons: 201, Grad norm: 2.809770832831527\n",
      "Epoch 3142, Loss: 209.28132032910057, Neurons: 201, Grad norm: 2.809770832831527\n",
      "Epoch 3143, Loss: 209.28081925267318, Neurons: 201, Grad norm: 1.4285289707585842\n",
      "Epoch 3143, Loss: 209.28081925267318, Neurons: 201, Grad norm: 1.4285289707585842\n",
      "Epoch 3144, Loss: 209.2803150902726, Neurons: 201, Grad norm: 0.7070697860932547\n",
      "Epoch 3144, Loss: 209.2803150902726, Neurons: 201, Grad norm: 0.7070697860932547\n",
      "Epoch 3145, Loss: 209.27984908881356, Neurons: 201, Grad norm: 1.3721365811135409\n",
      "Epoch 3145, Loss: 209.27984908881356, Neurons: 201, Grad norm: 1.3721365811135409\n",
      "Epoch 3146, Loss: 209.2794647614669, Neurons: 201, Grad norm: 2.0500279138266064\n",
      "Epoch 3146, Loss: 209.2794647614669, Neurons: 201, Grad norm: 2.0500279138266064\n",
      "Epoch 3147, Loss: 209.27911152407222, Neurons: 201, Grad norm: 2.980420433664724\n",
      "Epoch 3147, Loss: 209.27911152407222, Neurons: 201, Grad norm: 2.980420433664724\n",
      "Epoch 3148, Loss: 209.27878600959144, Neurons: 201, Grad norm: 3.1899795107671762\n",
      "Epoch 3148, Loss: 209.27878600959144, Neurons: 201, Grad norm: 3.1899795107671762\n",
      "Epoch 3149, Loss: 209.2784540435254, Neurons: 201, Grad norm: 3.974448998675829\n",
      "Epoch 3149, Loss: 209.2784540435254, Neurons: 201, Grad norm: 3.974448998675829\n",
      "Epoch 3150, Loss: 209.27811763381334, Neurons: 201, Grad norm: 3.8103562740855135\n",
      "Epoch 3150, Loss: 209.27811763381334, Neurons: 201, Grad norm: 3.8103562740855135\n",
      "Epoch 3151, Loss: 209.27774723472925, Neurons: 201, Grad norm: 3.8157474941454677\n",
      "Epoch 3151, Loss: 209.27774723472925, Neurons: 201, Grad norm: 3.8157474941454677\n",
      "Epoch 3152, Loss: 209.27735786224525, Neurons: 201, Grad norm: 2.9932744132002003\n",
      "Epoch 3152, Loss: 209.27735786224525, Neurons: 201, Grad norm: 2.9932744132002003\n",
      "Epoch 3153, Loss: 209.276830700737, Neurons: 201, Grad norm: 2.051060813920434\n",
      "Epoch 3153, Loss: 209.276830700737, Neurons: 201, Grad norm: 2.051060813920434\n",
      "Epoch 3154, Loss: 209.276317466519, Neurons: 201, Grad norm: 0.7991021949388128\n",
      "Epoch 3154, Loss: 209.276317466519, Neurons: 201, Grad norm: 0.7991021949388128\n",
      "Epoch 3155, Loss: 209.2758426398999, Neurons: 201, Grad norm: 1.2111313966844766\n",
      "Epoch 3155, Loss: 209.2758426398999, Neurons: 201, Grad norm: 1.2111313966844766\n",
      "Epoch 3156, Loss: 209.27545496595022, Neurons: 201, Grad norm: 2.609491482019271\n",
      "Epoch 3156, Loss: 209.27545496595022, Neurons: 201, Grad norm: 2.609491482019271\n",
      "Epoch 3157, Loss: 209.27516647830598, Neurons: 201, Grad norm: 3.303755563537173\n",
      "Epoch 3157, Loss: 209.27516647830598, Neurons: 201, Grad norm: 3.303755563537173\n",
      "Epoch 3158, Loss: 209.27490126587517, Neurons: 201, Grad norm: 4.348058184376449\n",
      "Epoch 3158, Loss: 209.27490126587517, Neurons: 201, Grad norm: 4.348058184376449\n",
      "Epoch 3159, Loss: 209.2746633049556, Neurons: 201, Grad norm: 4.2342926035875275\n",
      "Epoch 3159, Loss: 209.2746633049556, Neurons: 201, Grad norm: 4.2342926035875275\n",
      "Epoch 3160, Loss: 209.27429379344392, Neurons: 201, Grad norm: 4.114128543830837\n",
      "Epoch 3160, Loss: 209.27429379344392, Neurons: 201, Grad norm: 4.114128543830837\n",
      "Epoch 3161, Loss: 209.27384538146288, Neurons: 201, Grad norm: 3.029339514025088\n",
      "Epoch 3161, Loss: 209.27384538146288, Neurons: 201, Grad norm: 3.029339514025088\n",
      "Epoch 3162, Loss: 209.2732573637894, Neurons: 201, Grad norm: 1.8473639022510522\n",
      "Epoch 3162, Loss: 209.2732573637894, Neurons: 201, Grad norm: 1.8473639022510522\n",
      "Epoch 3163, Loss: 209.2727460192904, Neurons: 201, Grad norm: 0.6931646071242042\n",
      "Epoch 3163, Loss: 209.2727460192904, Neurons: 201, Grad norm: 0.6931646071242042\n",
      "Epoch 3164, Loss: 209.2722943183898, Neurons: 201, Grad norm: 1.2956692220665955\n",
      "Epoch 3164, Loss: 209.2722943183898, Neurons: 201, Grad norm: 1.2956692220665955\n",
      "Epoch 3165, Loss: 209.27196672162782, Neurons: 201, Grad norm: 2.4995505505224176\n",
      "Epoch 3165, Loss: 209.27196672162782, Neurons: 201, Grad norm: 2.4995505505224176\n",
      "Epoch 3166, Loss: 209.2716375506346, Neurons: 201, Grad norm: 2.907387734358979\n",
      "Epoch 3166, Loss: 209.2716375506346, Neurons: 201, Grad norm: 2.907387734358979\n",
      "Epoch 3167, Loss: 209.27132833738682, Neurons: 201, Grad norm: 3.380046915806579\n",
      "Epoch 3167, Loss: 209.27132833738682, Neurons: 201, Grad norm: 3.380046915806579\n",
      "Epoch 3168, Loss: 209.27101278214838, Neurons: 201, Grad norm: 3.2320851902328656\n",
      "Epoch 3168, Loss: 209.27101278214838, Neurons: 201, Grad norm: 3.2320851902328656\n",
      "Epoch 3169, Loss: 209.27056962289902, Neurons: 201, Grad norm: 3.0500029029934503\n",
      "Epoch 3169, Loss: 209.27056962289902, Neurons: 201, Grad norm: 3.0500029029934503\n",
      "Epoch 3170, Loss: 209.27019300422378, Neurons: 201, Grad norm: 2.0951437801751442\n",
      "Epoch 3170, Loss: 209.27019300422378, Neurons: 201, Grad norm: 2.0951437801751442\n",
      "Epoch 3171, Loss: 209.26973158381654, Neurons: 201, Grad norm: 1.75151018353479\n",
      "Epoch 3171, Loss: 209.26973158381654, Neurons: 201, Grad norm: 1.75151018353479\n",
      "Epoch 3172, Loss: 209.2692673147698, Neurons: 201, Grad norm: 0.9036467833036617\n",
      "Epoch 3172, Loss: 209.2692673147698, Neurons: 201, Grad norm: 0.9036467833036617\n",
      "Epoch 3173, Loss: 209.268835807592, Neurons: 201, Grad norm: 0.7169198318061465\n",
      "Epoch 3173, Loss: 209.268835807592, Neurons: 201, Grad norm: 0.7169198318061465\n",
      "Epoch 3174, Loss: 209.26839827587446, Neurons: 201, Grad norm: 1.3984120769436694\n",
      "Epoch 3174, Loss: 209.26839827587446, Neurons: 201, Grad norm: 1.3984120769436694\n",
      "Epoch 3175, Loss: 209.2680648289734, Neurons: 201, Grad norm: 1.823321204391724\n",
      "Epoch 3175, Loss: 209.2680648289734, Neurons: 201, Grad norm: 1.823321204391724\n",
      "Epoch 3176, Loss: 209.2677343503286, Neurons: 201, Grad norm: 2.4718094115716536\n",
      "Epoch 3176, Loss: 209.2677343503286, Neurons: 201, Grad norm: 2.4718094115716536\n",
      "Epoch 3177, Loss: 209.26738962348594, Neurons: 201, Grad norm: 2.760717576477879\n",
      "Epoch 3177, Loss: 209.26738962348594, Neurons: 201, Grad norm: 2.760717576477879\n",
      "Epoch 3178, Loss: 209.26704966396554, Neurons: 201, Grad norm: 3.558127003019786\n",
      "Epoch 3178, Loss: 209.26704966396554, Neurons: 201, Grad norm: 3.558127003019786\n",
      "Epoch 3179, Loss: 209.26675870963632, Neurons: 201, Grad norm: 3.7149608931799394\n",
      "Epoch 3179, Loss: 209.26675870963632, Neurons: 201, Grad norm: 3.7149608931799394\n",
      "Epoch 3180, Loss: 209.26642513644052, Neurons: 201, Grad norm: 4.292729281804949\n",
      "Epoch 3180, Loss: 209.26642513644052, Neurons: 201, Grad norm: 4.292729281804949\n",
      "Epoch 3181, Loss: 209.2661183471099, Neurons: 201, Grad norm: 3.8940499944019877\n",
      "Epoch 3181, Loss: 209.2661183471099, Neurons: 201, Grad norm: 3.8940499944019877\n",
      "Epoch 3182, Loss: 209.26568861969494, Neurons: 201, Grad norm: 3.219979311806372\n",
      "Epoch 3182, Loss: 209.26568861969494, Neurons: 201, Grad norm: 3.219979311806372\n",
      "Epoch 3183, Loss: 209.2652009753562, Neurons: 201, Grad norm: 1.6505199512056847\n",
      "Epoch 3183, Loss: 209.2652009753562, Neurons: 201, Grad norm: 1.6505199512056847\n",
      "Epoch 3184, Loss: 209.2646697410704, Neurons: 201, Grad norm: 0.6423866519995454\n",
      "Epoch 3184, Loss: 209.2646697410704, Neurons: 201, Grad norm: 0.6423866519995454\n",
      "Epoch 3185, Loss: 209.2642002150372, Neurons: 201, Grad norm: 1.7030019526456528\n",
      "Epoch 3185, Loss: 209.2642002150372, Neurons: 201, Grad norm: 1.7030019526456528\n",
      "Epoch 3186, Loss: 209.26388751184942, Neurons: 201, Grad norm: 2.4939349555342685\n",
      "Epoch 3186, Loss: 209.26388751184942, Neurons: 201, Grad norm: 2.4939349555342685\n",
      "Epoch 3187, Loss: 209.2635928537484, Neurons: 201, Grad norm: 3.315633321901757\n",
      "Epoch 3187, Loss: 209.2635928537484, Neurons: 201, Grad norm: 3.315633321901757\n",
      "Epoch 3188, Loss: 209.26327325463302, Neurons: 201, Grad norm: 3.3987297572408157\n",
      "Epoch 3188, Loss: 209.26327325463302, Neurons: 201, Grad norm: 3.3987297572408157\n",
      "Epoch 3189, Loss: 209.262945390372, Neurons: 201, Grad norm: 3.475242017933873\n",
      "Epoch 3189, Loss: 209.262945390372, Neurons: 201, Grad norm: 3.475242017933873\n",
      "Epoch 3190, Loss: 209.2625735416549, Neurons: 201, Grad norm: 2.862114236904008\n",
      "Epoch 3190, Loss: 209.2625735416549, Neurons: 201, Grad norm: 2.862114236904008\n",
      "Epoch 3191, Loss: 209.26212407150993, Neurons: 201, Grad norm: 2.6515159059922166\n",
      "Epoch 3191, Loss: 209.26212407150993, Neurons: 201, Grad norm: 2.6515159059922166\n",
      "Epoch 3192, Loss: 209.26170608404527, Neurons: 201, Grad norm: 1.9647190327110213\n",
      "Epoch 3192, Loss: 209.26170608404527, Neurons: 201, Grad norm: 1.9647190327110213\n",
      "Epoch 3193, Loss: 209.26125388209354, Neurons: 201, Grad norm: 1.6307159396652706\n",
      "Epoch 3193, Loss: 209.26125388209354, Neurons: 201, Grad norm: 1.6307159396652706\n",
      "Epoch 3194, Loss: 209.26085763081986, Neurons: 201, Grad norm: 0.9635388030031689\n",
      "Epoch 3194, Loss: 209.26085763081986, Neurons: 201, Grad norm: 0.9635388030031689\n",
      "Epoch 3195, Loss: 209.26047998469215, Neurons: 201, Grad norm: 0.7553896392741959\n",
      "Epoch 3195, Loss: 209.26047998469215, Neurons: 201, Grad norm: 0.7553896392741959\n",
      "Epoch 3196, Loss: 209.2600999704785, Neurons: 201, Grad norm: 0.7942302895167686\n",
      "Epoch 3196, Loss: 209.2600999704785, Neurons: 201, Grad norm: 0.7942302895167686\n",
      "Epoch 3197, Loss: 209.25974177521306, Neurons: 201, Grad norm: 0.8813339607102904\n",
      "Epoch 3197, Loss: 209.25974177521306, Neurons: 201, Grad norm: 0.8813339607102904\n",
      "Epoch 3198, Loss: 209.25937718277893, Neurons: 201, Grad norm: 1.3402780979586133\n",
      "Epoch 3198, Loss: 209.25937718277893, Neurons: 201, Grad norm: 1.3402780979586133\n",
      "Epoch 3199, Loss: 209.25902561359356, Neurons: 201, Grad norm: 1.2826953628605513\n",
      "Epoch 3199, Loss: 209.25902561359356, Neurons: 201, Grad norm: 1.2826953628605513\n",
      "Epoch 3200, Loss: 209.25866478032935, Neurons: 201, Grad norm: 1.6829503911937027\n",
      "Epoch 3200, Loss: 209.25866478032935, Neurons: 201, Grad norm: 1.6829503911937027\n",
      "Epoch 3201, Loss: 209.2583239810905, Neurons: 201, Grad norm: 1.7738448699617575\n",
      "Epoch 3201, Loss: 209.2583239810905, Neurons: 201, Grad norm: 1.7738448699617575\n",
      "Epoch 3202, Loss: 209.2579733936016, Neurons: 201, Grad norm: 2.2212281854026985\n",
      "Epoch 3202, Loss: 209.2579733936016, Neurons: 201, Grad norm: 2.2212281854026985\n",
      "Epoch 3203, Loss: 209.25765954195444, Neurons: 201, Grad norm: 2.4534304987487454\n",
      "Epoch 3203, Loss: 209.25765954195444, Neurons: 201, Grad norm: 2.4534304987487454\n",
      "Epoch 3204, Loss: 209.2573439690439, Neurons: 201, Grad norm: 3.2884038800215785\n",
      "Epoch 3204, Loss: 209.2573439690439, Neurons: 201, Grad norm: 3.2884038800215785\n",
      "Epoch 3205, Loss: 209.25707389154533, Neurons: 201, Grad norm: 3.7170756210325377\n",
      "Epoch 3205, Loss: 209.25707389154533, Neurons: 201, Grad norm: 3.7170756210325377\n",
      "Epoch 3206, Loss: 209.25680728005594, Neurons: 201, Grad norm: 4.463324046368545\n",
      "Epoch 3206, Loss: 209.25680728005594, Neurons: 201, Grad norm: 4.463324046368545\n",
      "Epoch 3207, Loss: 209.25659156700027, Neurons: 201, Grad norm: 4.367350436914106\n",
      "Epoch 3207, Loss: 209.25659156700027, Neurons: 201, Grad norm: 4.367350436914106\n",
      "Epoch 3208, Loss: 209.2562487002652, Neurons: 201, Grad norm: 4.254545449052119\n",
      "Epoch 3208, Loss: 209.2562487002652, Neurons: 201, Grad norm: 4.254545449052119\n",
      "Epoch 3209, Loss: 209.2558353578064, Neurons: 201, Grad norm: 3.364689496721338\n",
      "Epoch 3209, Loss: 209.2558353578064, Neurons: 201, Grad norm: 3.364689496721338\n",
      "Epoch 3210, Loss: 209.25538005823844, Neurons: 201, Grad norm: 2.552165696411473\n",
      "Epoch 3210, Loss: 209.25538005823844, Neurons: 201, Grad norm: 2.552165696411473\n",
      "Epoch 3211, Loss: 209.25488615392376, Neurons: 201, Grad norm: 1.3351800384899166\n",
      "Epoch 3211, Loss: 209.25488615392376, Neurons: 201, Grad norm: 1.3351800384899166\n",
      "Epoch 3212, Loss: 209.2544512403202, Neurons: 201, Grad norm: 0.8222450631201872\n",
      "Epoch 3212, Loss: 209.2544512403202, Neurons: 201, Grad norm: 0.8222450631201872\n",
      "Epoch 3213, Loss: 209.25407081138619, Neurons: 201, Grad norm: 0.9406231338909106\n",
      "Epoch 3213, Loss: 209.25407081138619, Neurons: 201, Grad norm: 0.9406231338909106\n",
      "Epoch 3214, Loss: 209.2537284945625, Neurons: 201, Grad norm: 1.4922705540742207\n",
      "Epoch 3214, Loss: 209.2537284945625, Neurons: 201, Grad norm: 1.4922705540742207\n",
      "Epoch 3215, Loss: 209.2534300341486, Neurons: 201, Grad norm: 2.592248734728717\n",
      "Epoch 3215, Loss: 209.2534300341486, Neurons: 201, Grad norm: 2.592248734728717\n",
      "Epoch 3216, Loss: 209.2531512811601, Neurons: 201, Grad norm: 3.196336357445037\n",
      "Epoch 3216, Loss: 209.2531512811601, Neurons: 201, Grad norm: 3.196336357445037\n",
      "Epoch 3217, Loss: 209.25289735128217, Neurons: 201, Grad norm: 4.12823854656196\n",
      "Epoch 3217, Loss: 209.25289735128217, Neurons: 201, Grad norm: 4.12823854656196\n",
      "Epoch 3218, Loss: 209.25269791942844, Neurons: 201, Grad norm: 4.299169127458289\n",
      "Epoch 3218, Loss: 209.25269791942844, Neurons: 201, Grad norm: 4.299169127458289\n",
      "Epoch 3219, Loss: 209.25243469265698, Neurons: 201, Grad norm: 4.357535463902253\n",
      "Epoch 3219, Loss: 209.25243469265698, Neurons: 201, Grad norm: 4.357535463902253\n",
      "Epoch 3220, Loss: 209.25206750481362, Neurons: 201, Grad norm: 3.453022562059662\n",
      "Epoch 3220, Loss: 209.25206750481362, Neurons: 201, Grad norm: 3.453022562059662\n",
      "Epoch 3221, Loss: 209.2516024428193, Neurons: 201, Grad norm: 2.8572893880278083\n",
      "Epoch 3221, Loss: 209.2516024428193, Neurons: 201, Grad norm: 2.8572893880278083\n",
      "Epoch 3222, Loss: 209.25116280942012, Neurons: 201, Grad norm: 1.7068299397792455\n",
      "Epoch 3222, Loss: 209.25116280942012, Neurons: 201, Grad norm: 1.7068299397792455\n",
      "Epoch 3223, Loss: 209.25070484638965, Neurons: 201, Grad norm: 1.1421645081543519\n",
      "Epoch 3223, Loss: 209.25070484638965, Neurons: 201, Grad norm: 1.1421645081543519\n",
      "Epoch 3224, Loss: 209.25032968058855, Neurons: 201, Grad norm: 0.6378146278629212\n",
      "Epoch 3224, Loss: 209.25032968058855, Neurons: 201, Grad norm: 0.6378146278629212\n",
      "Epoch 3225, Loss: 209.2499539838656, Neurons: 201, Grad norm: 1.1256472870232301\n",
      "Epoch 3225, Loss: 209.2499539838656, Neurons: 201, Grad norm: 1.1256472870232301\n",
      "Epoch 3226, Loss: 209.24963912862077, Neurons: 201, Grad norm: 2.2650940491684186\n",
      "Epoch 3226, Loss: 209.24963912862077, Neurons: 201, Grad norm: 2.2650940491684186\n",
      "Epoch 3227, Loss: 209.24937415387475, Neurons: 201, Grad norm: 3.3646167413850283\n",
      "Epoch 3227, Loss: 209.24937415387475, Neurons: 201, Grad norm: 3.3646167413850283\n",
      "Epoch 3228, Loss: 209.2491735668111, Neurons: 201, Grad norm: 4.981840113564249\n",
      "Epoch 3228, Loss: 209.2491735668111, Neurons: 201, Grad norm: 4.981840113564249\n",
      "Epoch 3229, Loss: 209.2491187494642, Neurons: 201, Grad norm: 6.051658374772878\n",
      "Epoch 3229, Loss: 209.2491187494642, Neurons: 201, Grad norm: 6.051658374772878\n",
      "Epoch 3230, Loss: 209.24908725228912, Neurons: 201, Grad norm: 7.42350817925566\n",
      "Epoch 3230, Loss: 209.24908725228912, Neurons: 201, Grad norm: 7.42350817925566\n",
      "Epoch 3231, Loss: 209.24914073811846, Neurons: 201, Grad norm: 7.341420751314082\n",
      "Epoch 3231, Loss: 209.24914073811846, Neurons: 201, Grad norm: 7.341420751314082\n",
      "Epoch 3232, Loss: 209.24884477959432, Neurons: 201, Grad norm: 6.827564679331478\n",
      "Epoch 3232, Loss: 209.24884477959432, Neurons: 201, Grad norm: 6.827564679331478\n",
      "Epoch 3233, Loss: 209.2483344046038, Neurons: 201, Grad norm: 4.738027698221273\n",
      "Epoch 3233, Loss: 209.2483344046038, Neurons: 201, Grad norm: 4.738027698221273\n",
      "Epoch 3234, Loss: 209.24749162011312, Neurons: 201, Grad norm: 2.091672211375831\n",
      "Epoch 3234, Loss: 209.24749162011312, Neurons: 201, Grad norm: 2.091672211375831\n",
      "Epoch 3235, Loss: 209.24673955304985, Neurons: 201, Grad norm: 1.2649724923507772\n",
      "Epoch 3235, Loss: 209.24673955304985, Neurons: 201, Grad norm: 1.2649724923507772\n",
      "Epoch 3236, Loss: 209.24634245525993, Neurons: 201, Grad norm: 3.595036863858022\n",
      "Epoch 3236, Loss: 209.24634245525993, Neurons: 201, Grad norm: 3.595036863858022\n",
      "Epoch 3237, Loss: 209.24631308887825, Neurons: 201, Grad norm: 5.873607853003478\n",
      "Epoch 3237, Loss: 209.24631308887825, Neurons: 201, Grad norm: 5.873607853003478\n",
      "Epoch 3238, Loss: 209.24637577857902, Neurons: 201, Grad norm: 6.582701194477606\n",
      "Epoch 3238, Loss: 209.24637577857902, Neurons: 201, Grad norm: 6.582701194477606\n",
      "Epoch 3239, Loss: 209.24637310609108, Neurons: 201, Grad norm: 6.668219064875131\n",
      "Epoch 3239, Loss: 209.24637310609108, Neurons: 201, Grad norm: 6.668219064875131\n",
      "Epoch 3240, Loss: 209.24600391225565, Neurons: 201, Grad norm: 5.218465915566262\n",
      "Epoch 3240, Loss: 209.24600391225565, Neurons: 201, Grad norm: 5.218465915566262\n",
      "Epoch 3241, Loss: 209.24533365407967, Neurons: 201, Grad norm: 3.30257230210039\n",
      "Epoch 3241, Loss: 209.24533365407967, Neurons: 201, Grad norm: 3.30257230210039\n",
      "Epoch 3242, Loss: 209.24460805245056, Neurons: 201, Grad norm: 0.9467183082800077\n",
      "Epoch 3242, Loss: 209.24460805245056, Neurons: 201, Grad norm: 0.9467183082800077\n",
      "Epoch 3243, Loss: 209.2440780002572, Neurons: 201, Grad norm: 1.6367349283628765\n",
      "Epoch 3243, Loss: 209.2440780002572, Neurons: 201, Grad norm: 1.6367349283628765\n",
      "Epoch 3244, Loss: 209.2437986945466, Neurons: 201, Grad norm: 3.6075977646622124\n",
      "Epoch 3244, Loss: 209.2437986945466, Neurons: 201, Grad norm: 3.6075977646622124\n",
      "Epoch 3245, Loss: 209.24368767765648, Neurons: 201, Grad norm: 4.235429564978509\n",
      "Epoch 3245, Loss: 209.24368767765648, Neurons: 201, Grad norm: 4.235429564978509\n",
      "Epoch 3246, Loss: 209.2435267317373, Neurons: 201, Grad norm: 4.793417021820939\n",
      "Epoch 3246, Loss: 209.2435267317373, Neurons: 201, Grad norm: 4.793417021820939\n",
      "Epoch 3247, Loss: 209.24325467500566, Neurons: 201, Grad norm: 4.070456565659459\n",
      "Epoch 3247, Loss: 209.24325467500566, Neurons: 201, Grad norm: 4.070456565659459\n",
      "Epoch 3248, Loss: 209.2428336978251, Neurons: 201, Grad norm: 3.256283188857666\n",
      "Epoch 3248, Loss: 209.2428336978251, Neurons: 201, Grad norm: 3.256283188857666\n",
      "Epoch 3249, Loss: 209.2423642014186, Neurons: 201, Grad norm: 1.7296244977963322\n",
      "Epoch 3249, Loss: 209.2423642014186, Neurons: 201, Grad norm: 1.7296244977963322\n",
      "Epoch 3250, Loss: 209.24189923032228, Neurons: 201, Grad norm: 0.6680707552973513\n",
      "Epoch 3250, Loss: 209.24189923032228, Neurons: 201, Grad norm: 0.6680707552973513\n",
      "Epoch 3251, Loss: 209.24151013101593, Neurons: 201, Grad norm: 1.4303574303424857\n",
      "Epoch 3251, Loss: 209.24151013101593, Neurons: 201, Grad norm: 1.4303574303424857\n",
      "Epoch 3252, Loss: 209.2412265001793, Neurons: 201, Grad norm: 2.3496138997861094\n",
      "Epoch 3252, Loss: 209.2412265001793, Neurons: 201, Grad norm: 2.3496138997861094\n",
      "Epoch 3253, Loss: 209.2410094108867, Neurons: 201, Grad norm: 3.4145291534364213\n",
      "Epoch 3253, Loss: 209.2410094108867, Neurons: 201, Grad norm: 3.4145291534364213\n",
      "Epoch 3254, Loss: 209.24080571701734, Neurons: 201, Grad norm: 3.606400174664567\n",
      "Epoch 3254, Loss: 209.24080571701734, Neurons: 201, Grad norm: 3.606400174664567\n",
      "Epoch 3255, Loss: 209.24056994173196, Neurons: 201, Grad norm: 3.9680503690688957\n",
      "Epoch 3255, Loss: 209.24056994173196, Neurons: 201, Grad norm: 3.9680503690688957\n",
      "Epoch 3256, Loss: 209.2402357373018, Neurons: 201, Grad norm: 3.279676599929646\n",
      "Epoch 3256, Loss: 209.2402357373018, Neurons: 201, Grad norm: 3.279676599929646\n",
      "Epoch 3257, Loss: 209.23985946881837, Neurons: 201, Grad norm: 2.9664183337803034\n",
      "Epoch 3257, Loss: 209.23985946881837, Neurons: 201, Grad norm: 2.9664183337803034\n",
      "Epoch 3258, Loss: 209.23949213903327, Neurons: 201, Grad norm: 1.9505157692046455\n",
      "Epoch 3258, Loss: 209.23949213903327, Neurons: 201, Grad norm: 1.9505157692046455\n",
      "Epoch 3259, Loss: 209.23911518964604, Neurons: 201, Grad norm: 1.0190220532141356\n",
      "Epoch 3259, Loss: 209.23911518964604, Neurons: 201, Grad norm: 1.0190220532141356\n",
      "Epoch 3260, Loss: 209.23872262828476, Neurons: 201, Grad norm: 0.6982889629210517\n",
      "Epoch 3260, Loss: 209.23872262828476, Neurons: 201, Grad norm: 0.6982889629210517\n",
      "Epoch 3261, Loss: 209.23840007527824, Neurons: 201, Grad norm: 1.5468277911580854\n",
      "Epoch 3261, Loss: 209.23840007527824, Neurons: 201, Grad norm: 1.5468277911580854\n",
      "Epoch 3262, Loss: 209.23812919946718, Neurons: 201, Grad norm: 2.718834777420893\n",
      "Epoch 3262, Loss: 209.23812919946718, Neurons: 201, Grad norm: 2.718834777420893\n",
      "Epoch 3263, Loss: 209.23789904100525, Neurons: 201, Grad norm: 3.2127558908120757\n",
      "Epoch 3263, Loss: 209.23789904100525, Neurons: 201, Grad norm: 3.2127558908120757\n",
      "Epoch 3264, Loss: 209.23771610041825, Neurons: 201, Grad norm: 3.9451230122771768\n",
      "Epoch 3264, Loss: 209.23771610041825, Neurons: 201, Grad norm: 3.9451230122771768\n",
      "Epoch 3265, Loss: 209.2374658366043, Neurons: 201, Grad norm: 3.601654566084652\n",
      "Epoch 3265, Loss: 209.2374658366043, Neurons: 201, Grad norm: 3.601654566084652\n",
      "Epoch 3266, Loss: 209.23714731919307, Neurons: 201, Grad norm: 3.353498267788813\n",
      "Epoch 3266, Loss: 209.23714731919307, Neurons: 201, Grad norm: 3.353498267788813\n",
      "Epoch 3267, Loss: 209.23675966762107, Neurons: 201, Grad norm: 2.3267115260392575\n",
      "Epoch 3267, Loss: 209.23675966762107, Neurons: 201, Grad norm: 2.3267115260392575\n",
      "Epoch 3268, Loss: 209.23634596386827, Neurons: 201, Grad norm: 1.6437168445330903\n",
      "Epoch 3268, Loss: 209.23634596386827, Neurons: 201, Grad norm: 1.6437168445330903\n",
      "Epoch 3269, Loss: 209.23598976323194, Neurons: 201, Grad norm: 0.7445295094272982\n",
      "Epoch 3269, Loss: 209.23598976323194, Neurons: 201, Grad norm: 0.7445295094272982\n",
      "Epoch 3270, Loss: 209.23562330432037, Neurons: 201, Grad norm: 0.6819398284892111\n",
      "Epoch 3270, Loss: 209.23562330432037, Neurons: 201, Grad norm: 0.6819398284892111\n",
      "Epoch 3271, Loss: 209.23533684588767, Neurons: 201, Grad norm: 1.4805222399368199\n",
      "Epoch 3271, Loss: 209.23533684588767, Neurons: 201, Grad norm: 1.4805222399368199\n",
      "Epoch 3272, Loss: 209.23505926533448, Neurons: 201, Grad norm: 1.995913180243768\n",
      "Epoch 3272, Loss: 209.23505926533448, Neurons: 201, Grad norm: 1.995913180243768\n",
      "Epoch 3273, Loss: 209.23478870353372, Neurons: 201, Grad norm: 3.255719319213249\n",
      "Epoch 3273, Loss: 209.23478870353372, Neurons: 201, Grad norm: 3.255719319213249\n",
      "Epoch 3274, Loss: 209.23459099515918, Neurons: 201, Grad norm: 3.710092581246389\n",
      "Epoch 3274, Loss: 209.23459099515918, Neurons: 201, Grad norm: 3.710092581246389\n",
      "Epoch 3275, Loss: 209.2344046616574, Neurons: 201, Grad norm: 4.465944975778053\n",
      "Epoch 3275, Loss: 209.2344046616574, Neurons: 201, Grad norm: 4.465944975778053\n",
      "Epoch 3276, Loss: 209.2342034885521, Neurons: 201, Grad norm: 4.1760827750555425\n",
      "Epoch 3276, Loss: 209.2342034885521, Neurons: 201, Grad norm: 4.1760827750555425\n",
      "Epoch 3277, Loss: 209.23387928571705, Neurons: 201, Grad norm: 3.37087699595647\n",
      "Epoch 3277, Loss: 209.23387928571705, Neurons: 201, Grad norm: 3.37087699595647\n",
      "Epoch 3278, Loss: 209.23339936226972, Neurons: 201, Grad norm: 1.8619561470707877\n",
      "Epoch 3278, Loss: 209.23339936226972, Neurons: 201, Grad norm: 1.8619561470707877\n",
      "Epoch 3279, Loss: 209.23291638526783, Neurons: 201, Grad norm: 0.7675246196921646\n",
      "Epoch 3279, Loss: 209.23291638526783, Neurons: 201, Grad norm: 0.7675246196921646\n",
      "Epoch 3280, Loss: 209.23255741804937, Neurons: 201, Grad norm: 1.7340615780446806\n",
      "Epoch 3280, Loss: 209.23255741804937, Neurons: 201, Grad norm: 1.7340615780446806\n",
      "Epoch 3281, Loss: 209.23225081646564, Neurons: 201, Grad norm: 2.670074861872379\n",
      "Epoch 3281, Loss: 209.23225081646564, Neurons: 201, Grad norm: 2.670074861872379\n",
      "Epoch 3282, Loss: 209.2320468828257, Neurons: 201, Grad norm: 4.000531514481066\n",
      "Epoch 3282, Loss: 209.2320468828257, Neurons: 201, Grad norm: 4.000531514481066\n",
      "Epoch 3283, Loss: 209.23188235394454, Neurons: 201, Grad norm: 4.337733370549549\n",
      "Epoch 3283, Loss: 209.23188235394454, Neurons: 201, Grad norm: 4.337733370549549\n",
      "Epoch 3284, Loss: 209.2316607262345, Neurons: 201, Grad norm: 4.751298599794239\n",
      "Epoch 3284, Loss: 209.2316607262345, Neurons: 201, Grad norm: 4.751298599794239\n",
      "Epoch 3285, Loss: 209.23138141399414, Neurons: 201, Grad norm: 4.104311939723001\n",
      "Epoch 3285, Loss: 209.23138141399414, Neurons: 201, Grad norm: 4.104311939723001\n",
      "Epoch 3286, Loss: 209.23098628621835, Neurons: 201, Grad norm: 3.331059573305952\n",
      "Epoch 3286, Loss: 209.23098628621835, Neurons: 201, Grad norm: 3.331059573305952\n",
      "Epoch 3287, Loss: 209.23051121667206, Neurons: 201, Grad norm: 1.8783138857733794\n",
      "Epoch 3287, Loss: 209.23051121667206, Neurons: 201, Grad norm: 1.8783138857733794\n",
      "Epoch 3288, Loss: 209.23000288632625, Neurons: 201, Grad norm: 0.7972897563259065\n",
      "Epoch 3288, Loss: 209.23000288632625, Neurons: 201, Grad norm: 0.7972897563259065\n",
      "Epoch 3289, Loss: 209.2296084910605, Neurons: 201, Grad norm: 1.2322076951825147\n",
      "Epoch 3289, Loss: 209.2296084910605, Neurons: 201, Grad norm: 1.2322076951825147\n",
      "Epoch 3290, Loss: 209.22930216416123, Neurons: 201, Grad norm: 1.7479769489622725\n",
      "Epoch 3290, Loss: 209.22930216416123, Neurons: 201, Grad norm: 1.7479769489622725\n",
      "Epoch 3291, Loss: 209.2290234760715, Neurons: 201, Grad norm: 2.688969548835021\n",
      "Epoch 3291, Loss: 209.2290234760715, Neurons: 201, Grad norm: 2.688969548835021\n",
      "Epoch 3292, Loss: 209.2287976858897, Neurons: 201, Grad norm: 2.793523022844252\n",
      "Epoch 3292, Loss: 209.2287976858897, Neurons: 201, Grad norm: 2.793523022844252\n",
      "Epoch 3293, Loss: 209.2285378685556, Neurons: 201, Grad norm: 2.9085956463584672\n",
      "Epoch 3293, Loss: 209.2285378685556, Neurons: 201, Grad norm: 2.9085956463584672\n",
      "Epoch 3294, Loss: 209.22823480198707, Neurons: 201, Grad norm: 2.3197225500799017\n",
      "Epoch 3294, Loss: 209.22823480198707, Neurons: 201, Grad norm: 2.3197225500799017\n",
      "Epoch 3295, Loss: 209.2278626914256, Neurons: 201, Grad norm: 1.6390159461053555\n",
      "Epoch 3295, Loss: 209.2278626914256, Neurons: 201, Grad norm: 1.6390159461053555\n",
      "Epoch 3296, Loss: 209.22748007537484, Neurons: 201, Grad norm: 0.8923707173262749\n",
      "Epoch 3296, Loss: 209.22748007537484, Neurons: 201, Grad norm: 0.8923707173262749\n",
      "Epoch 3297, Loss: 209.2270667317524, Neurons: 201, Grad norm: 0.851167587261523\n",
      "Epoch 3297, Loss: 209.2270667317524, Neurons: 201, Grad norm: 0.851167587261523\n",
      "Epoch 3298, Loss: 209.22675671869425, Neurons: 201, Grad norm: 1.5521235871347683\n",
      "Epoch 3298, Loss: 209.22675671869425, Neurons: 201, Grad norm: 1.5521235871347683\n",
      "Epoch 3299, Loss: 209.22642657200333, Neurons: 201, Grad norm: 2.184476727612971\n",
      "Epoch 3299, Loss: 209.22642657200333, Neurons: 201, Grad norm: 2.184476727612971\n",
      "Epoch 3300, Loss: 209.22615214203034, Neurons: 201, Grad norm: 3.0766340028638783\n",
      "Epoch 3300, Loss: 209.22615214203034, Neurons: 201, Grad norm: 3.0766340028638783\n",
      "Epoch 3301, Loss: 209.2259100871201, Neurons: 201, Grad norm: 3.1312109324672046\n",
      "Epoch 3301, Loss: 209.2259100871201, Neurons: 201, Grad norm: 3.1312109324672046\n",
      "Epoch 3302, Loss: 209.22564169152847, Neurons: 201, Grad norm: 3.161302716596172\n",
      "Epoch 3302, Loss: 209.22564169152847, Neurons: 201, Grad norm: 3.161302716596172\n",
      "Epoch 3303, Loss: 209.22527854799677, Neurons: 201, Grad norm: 2.548654995220809\n",
      "Epoch 3303, Loss: 209.22527854799677, Neurons: 201, Grad norm: 2.548654995220809\n",
      "Epoch 3304, Loss: 209.2249269851554, Neurons: 201, Grad norm: 2.3506828248408342\n",
      "Epoch 3304, Loss: 209.2249269851554, Neurons: 201, Grad norm: 2.3506828248408342\n",
      "Epoch 3305, Loss: 209.22457841393387, Neurons: 201, Grad norm: 1.7972011091604676\n",
      "Epoch 3305, Loss: 209.22457841393387, Neurons: 201, Grad norm: 1.7972011091604676\n",
      "Epoch 3306, Loss: 209.22423052611978, Neurons: 201, Grad norm: 1.7933586311529766\n",
      "Epoch 3306, Loss: 209.22423052611978, Neurons: 201, Grad norm: 1.7933586311529766\n",
      "Epoch 3307, Loss: 209.22392785224906, Neurons: 201, Grad norm: 1.6596523645163745\n",
      "Epoch 3307, Loss: 209.22392785224906, Neurons: 201, Grad norm: 1.6596523645163745\n",
      "Epoch 3308, Loss: 209.22361234994995, Neurons: 201, Grad norm: 2.0016255148444935\n",
      "Epoch 3308, Loss: 209.22361234994995, Neurons: 201, Grad norm: 2.0016255148444935\n",
      "Epoch 3309, Loss: 209.22331339686372, Neurons: 201, Grad norm: 2.156160646632276\n",
      "Epoch 3309, Loss: 209.22331339686372, Neurons: 201, Grad norm: 2.156160646632276\n",
      "Epoch 3310, Loss: 209.2230158546372, Neurons: 201, Grad norm: 2.326775142359813\n",
      "Epoch 3310, Loss: 209.2230158546372, Neurons: 201, Grad norm: 2.326775142359813\n",
      "Epoch 3311, Loss: 209.2227059130688, Neurons: 201, Grad norm: 2.304201106155528\n",
      "Epoch 3311, Loss: 209.2227059130688, Neurons: 201, Grad norm: 2.304201106155528\n",
      "Epoch 3312, Loss: 209.22239215849663, Neurons: 201, Grad norm: 2.5277915874275037\n",
      "Epoch 3312, Loss: 209.22239215849663, Neurons: 201, Grad norm: 2.5277915874275037\n",
      "Epoch 3313, Loss: 209.2221269211915, Neurons: 201, Grad norm: 2.296415909424426\n",
      "Epoch 3313, Loss: 209.2221269211915, Neurons: 201, Grad norm: 2.296415909424426\n",
      "Epoch 3314, Loss: 209.22179145920464, Neurons: 201, Grad norm: 2.331335076603434\n",
      "Epoch 3314, Loss: 209.22179145920464, Neurons: 201, Grad norm: 2.331335076603434\n",
      "Epoch 3315, Loss: 209.221504626664, Neurons: 201, Grad norm: 1.7062812491839894\n",
      "Epoch 3315, Loss: 209.221504626664, Neurons: 201, Grad norm: 1.7062812491839894\n",
      "Epoch 3316, Loss: 209.22117263901512, Neurons: 201, Grad norm: 1.9549546306425718\n",
      "Epoch 3316, Loss: 209.22117263901512, Neurons: 201, Grad norm: 1.9549546306425718\n",
      "Epoch 3317, Loss: 209.22083252016557, Neurons: 201, Grad norm: 1.641530979989314\n",
      "Epoch 3317, Loss: 209.22083252016557, Neurons: 201, Grad norm: 1.641530979989314\n",
      "Epoch 3318, Loss: 209.2205565749392, Neurons: 201, Grad norm: 1.8785563085309107\n",
      "Epoch 3318, Loss: 209.2205565749392, Neurons: 201, Grad norm: 1.8785563085309107\n",
      "Epoch 3319, Loss: 209.22022714618745, Neurons: 201, Grad norm: 1.9842312407645888\n",
      "Epoch 3319, Loss: 209.22022714618745, Neurons: 201, Grad norm: 1.9842312407645888\n",
      "Epoch 3320, Loss: 209.21995055324794, Neurons: 201, Grad norm: 2.5339237751312074\n",
      "Epoch 3320, Loss: 209.21995055324794, Neurons: 201, Grad norm: 2.5339237751312074\n",
      "Epoch 3321, Loss: 209.21968055635665, Neurons: 201, Grad norm: 2.9590034225454085\n",
      "Epoch 3321, Loss: 209.21968055635665, Neurons: 201, Grad norm: 2.9590034225454085\n",
      "Epoch 3322, Loss: 209.2194470716993, Neurons: 201, Grad norm: 3.3493704313554344\n",
      "Epoch 3322, Loss: 209.2194470716993, Neurons: 201, Grad norm: 3.3493704313554344\n",
      "Epoch 3323, Loss: 209.21919647602846, Neurons: 201, Grad norm: 3.1265990000710775\n",
      "Epoch 3323, Loss: 209.21919647602846, Neurons: 201, Grad norm: 3.1265990000710775\n",
      "Epoch 3324, Loss: 209.21886066039195, Neurons: 201, Grad norm: 2.6064450367161394\n",
      "Epoch 3324, Loss: 209.21886066039195, Neurons: 201, Grad norm: 2.6064450367161394\n",
      "Epoch 3325, Loss: 209.21852926613084, Neurons: 201, Grad norm: 1.5487389668500025\n",
      "Epoch 3325, Loss: 209.21852926613084, Neurons: 201, Grad norm: 1.5487389668500025\n",
      "Epoch 3326, Loss: 209.21813379024982, Neurons: 201, Grad norm: 0.8258275974131144\n",
      "Epoch 3326, Loss: 209.21813379024982, Neurons: 201, Grad norm: 0.8258275974131144\n",
      "Epoch 3327, Loss: 209.21774562347116, Neurons: 201, Grad norm: 1.2084141018580776\n",
      "Epoch 3327, Loss: 209.21774562347116, Neurons: 201, Grad norm: 1.2084141018580776\n",
      "Epoch 3328, Loss: 209.2174702246322, Neurons: 201, Grad norm: 1.6130220934334585\n",
      "Epoch 3328, Loss: 209.2174702246322, Neurons: 201, Grad norm: 1.6130220934334585\n",
      "Epoch 3329, Loss: 209.21719618875963, Neurons: 201, Grad norm: 2.825123604007706\n",
      "Epoch 3329, Loss: 209.21719618875963, Neurons: 201, Grad norm: 2.825123604007706\n",
      "Epoch 3330, Loss: 209.21699238918208, Neurons: 201, Grad norm: 3.6388010937319466\n",
      "Epoch 3330, Loss: 209.21699238918208, Neurons: 201, Grad norm: 3.6388010937319466\n",
      "Epoch 3331, Loss: 209.21683995028465, Neurons: 201, Grad norm: 4.757115401168147\n",
      "Epoch 3331, Loss: 209.21683995028465, Neurons: 201, Grad norm: 4.757115401168147\n",
      "Epoch 3332, Loss: 209.21671414900803, Neurons: 201, Grad norm: 5.065256981758777\n",
      "Epoch 3332, Loss: 209.21671414900803, Neurons: 201, Grad norm: 5.065256981758777\n",
      "Epoch 3333, Loss: 209.21651848775352, Neurons: 201, Grad norm: 5.2512785668080575\n",
      "Epoch 3333, Loss: 209.21651848775352, Neurons: 201, Grad norm: 5.2512785668080575\n",
      "Epoch 3334, Loss: 209.2162466166724, Neurons: 201, Grad norm: 4.418821931981896\n",
      "Epoch 3334, Loss: 209.2162466166724, Neurons: 201, Grad norm: 4.418821931981896\n",
      "Epoch 3335, Loss: 209.21577650980225, Neurons: 201, Grad norm: 3.2019870960128336\n",
      "Epoch 3335, Loss: 209.21577650980225, Neurons: 201, Grad norm: 3.2019870960128336\n",
      "Epoch 3336, Loss: 209.215322131965, Neurons: 201, Grad norm: 1.5124419174363222\n",
      "Epoch 3336, Loss: 209.215322131965, Neurons: 201, Grad norm: 1.5124419174363222\n",
      "Epoch 3337, Loss: 209.21483769452303, Neurons: 201, Grad norm: 0.8291770186540997\n",
      "Epoch 3337, Loss: 209.21483769452303, Neurons: 201, Grad norm: 0.8291770186540997\n",
      "Epoch 3338, Loss: 209.21447678869768, Neurons: 201, Grad norm: 2.419282743260998\n",
      "Epoch 3338, Loss: 209.21447678869768, Neurons: 201, Grad norm: 2.419282743260998\n",
      "Epoch 3339, Loss: 209.21429113677834, Neurons: 201, Grad norm: 3.361940609118496\n",
      "Epoch 3339, Loss: 209.21429113677834, Neurons: 201, Grad norm: 3.361940609118496\n",
      "Epoch 3340, Loss: 209.21416440989816, Neurons: 201, Grad norm: 4.800805924748071\n",
      "Epoch 3340, Loss: 209.21416440989816, Neurons: 201, Grad norm: 4.800805924748071\n",
      "Epoch 3341, Loss: 209.2140617825054, Neurons: 201, Grad norm: 4.933705912863273\n",
      "Epoch 3341, Loss: 209.2140617825054, Neurons: 201, Grad norm: 4.933705912863273\n",
      "Epoch 3342, Loss: 209.21385396997078, Neurons: 201, Grad norm: 4.920244204541505\n",
      "Epoch 3342, Loss: 209.21385396997078, Neurons: 201, Grad norm: 4.920244204541505\n",
      "Epoch 3343, Loss: 209.21352017729905, Neurons: 201, Grad norm: 4.021534291415681\n",
      "Epoch 3343, Loss: 209.21352017729905, Neurons: 201, Grad norm: 4.021534291415681\n",
      "Epoch 3344, Loss: 209.2130736667318, Neurons: 201, Grad norm: 3.123607172615471\n",
      "Epoch 3344, Loss: 209.2130736667318, Neurons: 201, Grad norm: 3.123607172615471\n",
      "Epoch 3345, Loss: 209.21260837671272, Neurons: 201, Grad norm: 1.7355455094643029\n",
      "Epoch 3345, Loss: 209.21260837671272, Neurons: 201, Grad norm: 1.7355455094643029\n",
      "Epoch 3346, Loss: 209.21221211239074, Neurons: 201, Grad norm: 0.6779558508640816\n",
      "Epoch 3346, Loss: 209.21221211239074, Neurons: 201, Grad norm: 0.6779558508640816\n",
      "Epoch 3347, Loss: 209.21184948677887, Neurons: 201, Grad norm: 1.1898635615254152\n",
      "Epoch 3347, Loss: 209.21184948677887, Neurons: 201, Grad norm: 1.1898635615254152\n",
      "Epoch 3348, Loss: 209.21157822295854, Neurons: 201, Grad norm: 2.266731359564612\n",
      "Epoch 3348, Loss: 209.21157822295854, Neurons: 201, Grad norm: 2.266731359564612\n",
      "Epoch 3349, Loss: 209.21136429248185, Neurons: 201, Grad norm: 3.308334148013556\n",
      "Epoch 3349, Loss: 209.21136429248185, Neurons: 201, Grad norm: 3.308334148013556\n",
      "Epoch 3350, Loss: 209.2111790426622, Neurons: 201, Grad norm: 3.762423929322443\n",
      "Epoch 3350, Loss: 209.2111790426622, Neurons: 201, Grad norm: 3.762423929322443\n",
      "Epoch 3351, Loss: 209.21101481180986, Neurons: 201, Grad norm: 4.465007348799172\n",
      "Epoch 3351, Loss: 209.21101481180986, Neurons: 201, Grad norm: 4.465007348799172\n",
      "Epoch 3352, Loss: 209.2107590195539, Neurons: 201, Grad norm: 4.06066585308579\n",
      "Epoch 3352, Loss: 209.2107590195539, Neurons: 201, Grad norm: 4.06066585308579\n",
      "Epoch 3353, Loss: 209.2104523958177, Neurons: 201, Grad norm: 4.1173516348700225\n",
      "Epoch 3353, Loss: 209.2104523958177, Neurons: 201, Grad norm: 4.1173516348700225\n",
      "Epoch 3354, Loss: 209.21017804609147, Neurons: 201, Grad norm: 3.132779835633858\n",
      "Epoch 3354, Loss: 209.21017804609147, Neurons: 201, Grad norm: 3.132779835633858\n",
      "Epoch 3355, Loss: 209.20975035952873, Neurons: 201, Grad norm: 2.407503837139474\n",
      "Epoch 3355, Loss: 209.20975035952873, Neurons: 201, Grad norm: 2.407503837139474\n",
      "Epoch 3356, Loss: 209.2093624505297, Neurons: 201, Grad norm: 1.2163188097978805\n",
      "Epoch 3356, Loss: 209.2093624505297, Neurons: 201, Grad norm: 1.2163188097978805\n",
      "Epoch 3357, Loss: 209.208985586444, Neurons: 201, Grad norm: 0.6688170547490744\n",
      "Epoch 3357, Loss: 209.208985586444, Neurons: 201, Grad norm: 0.6688170547490744\n",
      "Epoch 3358, Loss: 209.20866264551103, Neurons: 201, Grad norm: 1.5275520786041703\n",
      "Epoch 3358, Loss: 209.20866264551103, Neurons: 201, Grad norm: 1.5275520786041703\n",
      "Epoch 3359, Loss: 209.20843242308734, Neurons: 201, Grad norm: 2.0808198870684365\n",
      "Epoch 3359, Loss: 209.20843242308734, Neurons: 201, Grad norm: 2.0808198870684365\n",
      "Epoch 3360, Loss: 209.20819289911574, Neurons: 201, Grad norm: 3.0487301915085947\n",
      "Epoch 3360, Loss: 209.20819289911574, Neurons: 201, Grad norm: 3.0487301915085947\n",
      "Epoch 3361, Loss: 209.2080002069049, Neurons: 201, Grad norm: 3.606583004637338\n",
      "Epoch 3361, Loss: 209.2080002069049, Neurons: 201, Grad norm: 3.606583004637338\n",
      "Epoch 3362, Loss: 209.2077816075124, Neurons: 201, Grad norm: 4.190069297967017\n",
      "Epoch 3362, Loss: 209.2077816075124, Neurons: 201, Grad norm: 4.190069297967017\n",
      "Epoch 3363, Loss: 209.2075926052962, Neurons: 201, Grad norm: 4.178193923201635\n",
      "Epoch 3363, Loss: 209.2075926052962, Neurons: 201, Grad norm: 4.178193923201635\n",
      "Epoch 3364, Loss: 209.2073383478123, Neurons: 201, Grad norm: 4.177904669629246\n",
      "Epoch 3364, Loss: 209.2073383478123, Neurons: 201, Grad norm: 4.177904669629246\n",
      "Epoch 3365, Loss: 209.2070071282802, Neurons: 201, Grad norm: 3.2085163472090077\n",
      "Epoch 3365, Loss: 209.2070071282802, Neurons: 201, Grad norm: 3.2085163472090077\n",
      "Epoch 3366, Loss: 209.20658134828344, Neurons: 201, Grad norm: 2.285465466729477\n",
      "Epoch 3366, Loss: 209.20658134828344, Neurons: 201, Grad norm: 2.285465466729477\n",
      "Epoch 3367, Loss: 209.20614794994287, Neurons: 201, Grad norm: 0.8712975707326143\n",
      "Epoch 3367, Loss: 209.20614794994287, Neurons: 201, Grad norm: 0.8712975707326143\n",
      "Epoch 3368, Loss: 209.20576224864087, Neurons: 201, Grad norm: 0.8912512547339109\n",
      "Epoch 3368, Loss: 209.20576224864087, Neurons: 201, Grad norm: 0.8912512547339109\n",
      "Epoch 3369, Loss: 209.2054729725793, Neurons: 201, Grad norm: 1.9048303013537529\n",
      "Epoch 3369, Loss: 209.2054729725793, Neurons: 201, Grad norm: 1.9048303013537529\n",
      "Epoch 3370, Loss: 209.2052221583149, Neurons: 201, Grad norm: 2.5677753944671458\n",
      "Epoch 3370, Loss: 209.2052221583149, Neurons: 201, Grad norm: 2.5677753944671458\n",
      "Epoch 3371, Loss: 209.20502632417725, Neurons: 201, Grad norm: 3.279767935842121\n",
      "Epoch 3371, Loss: 209.20502632417725, Neurons: 201, Grad norm: 3.279767935842121\n",
      "Epoch 3372, Loss: 209.2047445912471, Neurons: 201, Grad norm: 3.5366195608493363\n",
      "Epoch 3372, Loss: 209.2047445912471, Neurons: 201, Grad norm: 3.5366195608493363\n",
      "Epoch 3373, Loss: 209.20447074008231, Neurons: 201, Grad norm: 4.062098543909503\n",
      "Epoch 3373, Loss: 209.20447074008231, Neurons: 201, Grad norm: 4.062098543909503\n",
      "Epoch 3374, Loss: 209.20422218223308, Neurons: 201, Grad norm: 3.9020215077345086\n",
      "Epoch 3374, Loss: 209.20422218223308, Neurons: 201, Grad norm: 3.9020215077345086\n",
      "Epoch 3375, Loss: 209.20390629328065, Neurons: 201, Grad norm: 3.9475889293671633\n",
      "Epoch 3375, Loss: 209.20390629328065, Neurons: 201, Grad norm: 3.9475889293671633\n",
      "Epoch 3376, Loss: 209.20365263799724, Neurons: 201, Grad norm: 3.3352961884777605\n",
      "Epoch 3376, Loss: 209.20365263799724, Neurons: 201, Grad norm: 3.3352961884777605\n",
      "Epoch 3377, Loss: 209.20331720739725, Neurons: 201, Grad norm: 2.816741347451073\n",
      "Epoch 3377, Loss: 209.20331720739725, Neurons: 201, Grad norm: 2.816741347451073\n",
      "Epoch 3378, Loss: 209.2029313370046, Neurons: 201, Grad norm: 1.643999268344984\n",
      "Epoch 3378, Loss: 209.2029313370046, Neurons: 201, Grad norm: 1.643999268344984\n",
      "Epoch 3379, Loss: 209.2025610319999, Neurons: 201, Grad norm: 1.0650970646507465\n",
      "Epoch 3379, Loss: 209.2025610319999, Neurons: 201, Grad norm: 1.0650970646507465\n",
      "Epoch 3380, Loss: 209.20224770756462, Neurons: 201, Grad norm: 0.7585352563125817\n",
      "Epoch 3380, Loss: 209.20224770756462, Neurons: 201, Grad norm: 0.7585352563125817\n",
      "Epoch 3381, Loss: 209.20195301910806, Neurons: 201, Grad norm: 1.1312819850513385\n",
      "Epoch 3381, Loss: 209.20195301910806, Neurons: 201, Grad norm: 1.1312819850513385\n",
      "Epoch 3382, Loss: 209.20170868441863, Neurons: 201, Grad norm: 1.9858212553032561\n",
      "Epoch 3382, Loss: 209.20170868441863, Neurons: 201, Grad norm: 1.9858212553032561\n",
      "Epoch 3383, Loss: 209.20144632554025, Neurons: 201, Grad norm: 3.107817206287138\n",
      "Epoch 3383, Loss: 209.20144632554025, Neurons: 201, Grad norm: 3.107817206287138\n",
      "Epoch 3384, Loss: 209.20127371569112, Neurons: 201, Grad norm: 4.645446441472591\n",
      "Epoch 3384, Loss: 209.20127371569112, Neurons: 201, Grad norm: 4.645446441472591\n",
      "Epoch 3385, Loss: 209.2012321398748, Neurons: 201, Grad norm: 5.421768678521751\n",
      "Epoch 3385, Loss: 209.2012321398748, Neurons: 201, Grad norm: 5.421768678521751\n",
      "Epoch 3386, Loss: 209.20114187434197, Neurons: 201, Grad norm: 6.335572335792231\n",
      "Epoch 3386, Loss: 209.20114187434197, Neurons: 201, Grad norm: 6.335572335792231\n",
      "Epoch 3387, Loss: 209.20106153933511, Neurons: 201, Grad norm: 6.065761527582122\n",
      "Epoch 3387, Loss: 209.20106153933511, Neurons: 201, Grad norm: 6.065761527582122\n",
      "Epoch 3388, Loss: 209.20071985250783, Neurons: 201, Grad norm: 5.2379394484284845\n",
      "Epoch 3388, Loss: 209.20071985250783, Neurons: 201, Grad norm: 5.2379394484284845\n",
      "Epoch 3389, Loss: 209.20021801892784, Neurons: 201, Grad norm: 3.328516943098008\n",
      "Epoch 3389, Loss: 209.20021801892784, Neurons: 201, Grad norm: 3.328516943098008\n",
      "Epoch 3390, Loss: 209.19960810299943, Neurons: 201, Grad norm: 1.2444160700642015\n",
      "Epoch 3390, Loss: 209.19960810299943, Neurons: 201, Grad norm: 1.2444160700642015\n",
      "Epoch 3391, Loss: 209.19909561985511, Neurons: 201, Grad norm: 1.563349786129822\n",
      "Epoch 3391, Loss: 209.19909561985511, Neurons: 201, Grad norm: 1.563349786129822\n",
      "Epoch 3392, Loss: 209.19883235220522, Neurons: 201, Grad norm: 3.4444064877989264\n",
      "Epoch 3392, Loss: 209.19883235220522, Neurons: 201, Grad norm: 3.4444064877989264\n",
      "Epoch 3393, Loss: 209.19878382179496, Neurons: 201, Grad norm: 5.186703466333387\n",
      "Epoch 3393, Loss: 209.19878382179496, Neurons: 201, Grad norm: 5.186703466333387\n",
      "Epoch 3394, Loss: 209.19881364151962, Neurons: 201, Grad norm: 5.870664930676745\n",
      "Epoch 3394, Loss: 209.19881364151962, Neurons: 201, Grad norm: 5.870664930676745\n",
      "Epoch 3395, Loss: 209.19873214331074, Neurons: 201, Grad norm: 6.157566319230733\n",
      "Epoch 3395, Loss: 209.19873214331074, Neurons: 201, Grad norm: 6.157566319230733\n",
      "Epoch 3396, Loss: 209.19844131312837, Neurons: 201, Grad norm: 5.250337924844977\n",
      "Epoch 3396, Loss: 209.19844131312837, Neurons: 201, Grad norm: 5.250337924844977\n",
      "Epoch 3397, Loss: 209.1980081180147, Neurons: 201, Grad norm: 4.384334246679944\n",
      "Epoch 3397, Loss: 209.1980081180147, Neurons: 201, Grad norm: 4.384334246679944\n",
      "Epoch 3398, Loss: 209.19750601319237, Neurons: 201, Grad norm: 2.610204397612043\n",
      "Epoch 3398, Loss: 209.19750601319237, Neurons: 201, Grad norm: 2.610204397612043\n",
      "Epoch 3399, Loss: 209.19698549236736, Neurons: 201, Grad norm: 1.3912253507719432\n",
      "Epoch 3399, Loss: 209.19698549236736, Neurons: 201, Grad norm: 1.3912253507719432\n",
      "Epoch 3400, Loss: 209.1965903464573, Neurons: 201, Grad norm: 0.7882552219031205\n",
      "Epoch 3400, Loss: 209.1965903464573, Neurons: 201, Grad norm: 0.7882552219031205\n",
      "Epoch 3401, Loss: 209.19630090634828, Neurons: 201, Grad norm: 1.722012142778704\n",
      "Epoch 3401, Loss: 209.19630090634828, Neurons: 201, Grad norm: 1.722012142778704\n",
      "Epoch 3402, Loss: 209.19608804439582, Neurons: 201, Grad norm: 2.5959897264755365\n",
      "Epoch 3402, Loss: 209.19608804439582, Neurons: 201, Grad norm: 2.5959897264755365\n",
      "Epoch 3403, Loss: 209.19588520325362, Neurons: 201, Grad norm: 2.971008544643833\n",
      "Epoch 3403, Loss: 209.19588520325362, Neurons: 201, Grad norm: 2.971008544643833\n",
      "Epoch 3404, Loss: 209.19564176093468, Neurons: 201, Grad norm: 3.3223020590963803\n",
      "Epoch 3404, Loss: 209.19564176093468, Neurons: 201, Grad norm: 3.3223020590963803\n",
      "Epoch 3405, Loss: 209.1953956453627, Neurons: 201, Grad norm: 3.151802570823937\n",
      "Epoch 3405, Loss: 209.1953956453627, Neurons: 201, Grad norm: 3.151802570823937\n",
      "Epoch 3406, Loss: 209.19510089279308, Neurons: 201, Grad norm: 3.0557424228586187\n",
      "Epoch 3406, Loss: 209.19510089279308, Neurons: 201, Grad norm: 3.0557424228586187\n",
      "Epoch 3407, Loss: 209.19479716749254, Neurons: 201, Grad norm: 2.5251558544397414\n",
      "Epoch 3407, Loss: 209.19479716749254, Neurons: 201, Grad norm: 2.5251558544397414\n",
      "Epoch 3408, Loss: 209.1944382451708, Neurons: 201, Grad norm: 2.167795408744501\n",
      "Epoch 3408, Loss: 209.1944382451708, Neurons: 201, Grad norm: 2.167795408744501\n",
      "Epoch 3409, Loss: 209.1941232714231, Neurons: 201, Grad norm: 1.4544647694529587\n",
      "Epoch 3409, Loss: 209.1941232714231, Neurons: 201, Grad norm: 1.4544647694529587\n",
      "Epoch 3410, Loss: 209.1938101310009, Neurons: 201, Grad norm: 1.3632396808307223\n",
      "Epoch 3410, Loss: 209.1938101310009, Neurons: 201, Grad norm: 1.3632396808307223\n",
      "Epoch 3411, Loss: 209.19352321207697, Neurons: 201, Grad norm: 0.922039114080845\n",
      "Epoch 3411, Loss: 209.19352321207697, Neurons: 201, Grad norm: 0.922039114080845\n",
      "Epoch 3412, Loss: 209.19323897072655, Neurons: 201, Grad norm: 1.1345901774937486\n",
      "Epoch 3412, Loss: 209.19323897072655, Neurons: 201, Grad norm: 1.1345901774937486\n",
      "Epoch 3413, Loss: 209.19294876073616, Neurons: 201, Grad norm: 1.2668369952834504\n",
      "Epoch 3413, Loss: 209.19294876073616, Neurons: 201, Grad norm: 1.2668369952834504\n",
      "Epoch 3414, Loss: 209.19268444219605, Neurons: 201, Grad norm: 1.8677781449981994\n",
      "Epoch 3414, Loss: 209.19268444219605, Neurons: 201, Grad norm: 1.8677781449981994\n",
      "Epoch 3415, Loss: 209.19244049791396, Neurons: 201, Grad norm: 2.0846558926902587\n",
      "Epoch 3415, Loss: 209.19244049791396, Neurons: 201, Grad norm: 2.0846558926902587\n",
      "Epoch 3416, Loss: 209.1921813263503, Neurons: 201, Grad norm: 2.3646708551088866\n",
      "Epoch 3416, Loss: 209.1921813263503, Neurons: 201, Grad norm: 2.3646708551088866\n",
      "Epoch 3417, Loss: 209.19194694011316, Neurons: 201, Grad norm: 2.4808449617025543\n",
      "Epoch 3417, Loss: 209.19194694011316, Neurons: 201, Grad norm: 2.4808449617025543\n",
      "Epoch 3418, Loss: 209.19167963850632, Neurons: 201, Grad norm: 2.7518257711885936\n",
      "Epoch 3418, Loss: 209.19167963850632, Neurons: 201, Grad norm: 2.7518257711885936\n",
      "Epoch 3419, Loss: 209.19144456788507, Neurons: 201, Grad norm: 2.5793148849840004\n",
      "Epoch 3419, Loss: 209.19144456788507, Neurons: 201, Grad norm: 2.5793148849840004\n",
      "Epoch 3420, Loss: 209.19115386194764, Neurons: 201, Grad norm: 2.4093659599724706\n",
      "Epoch 3420, Loss: 209.19115386194764, Neurons: 201, Grad norm: 2.4093659599724706\n",
      "Epoch 3421, Loss: 209.19086097714694, Neurons: 201, Grad norm: 1.7424942955918996\n",
      "Epoch 3421, Loss: 209.19086097714694, Neurons: 201, Grad norm: 1.7424942955918996\n",
      "Epoch 3422, Loss: 209.19052259766067, Neurons: 201, Grad norm: 1.4152292728963707\n",
      "Epoch 3422, Loss: 209.19052259766067, Neurons: 201, Grad norm: 1.4152292728963707\n",
      "Epoch 3423, Loss: 209.19021549806186, Neurons: 201, Grad norm: 0.9226232468315404\n",
      "Epoch 3423, Loss: 209.19021549806186, Neurons: 201, Grad norm: 0.9226232468315404\n",
      "Epoch 3424, Loss: 209.1899240694526, Neurons: 201, Grad norm: 0.9153280349630928\n",
      "Epoch 3424, Loss: 209.1899240694526, Neurons: 201, Grad norm: 0.9153280349630928\n",
      "Epoch 3425, Loss: 209.1896418090477, Neurons: 201, Grad norm: 0.7144799404293204\n",
      "Epoch 3425, Loss: 209.1896418090477, Neurons: 201, Grad norm: 0.7144799404293204\n",
      "Epoch 3426, Loss: 209.18938778175755, Neurons: 201, Grad norm: 0.9518567446678418\n",
      "Epoch 3426, Loss: 209.18938778175755, Neurons: 201, Grad norm: 0.9518567446678418\n",
      "Epoch 3427, Loss: 209.1891230993315, Neurons: 201, Grad norm: 0.9403461431283103\n",
      "Epoch 3427, Loss: 209.1891230993315, Neurons: 201, Grad norm: 0.9403461431283103\n",
      "Epoch 3428, Loss: 209.18885504958672, Neurons: 201, Grad norm: 1.3532818737426753\n",
      "Epoch 3428, Loss: 209.18885504958672, Neurons: 201, Grad norm: 1.3532818737426753\n",
      "Epoch 3429, Loss: 209.18860267195998, Neurons: 201, Grad norm: 1.4537521106715774\n",
      "Epoch 3429, Loss: 209.18860267195998, Neurons: 201, Grad norm: 1.4537521106715774\n",
      "Epoch 3430, Loss: 209.1883372346496, Neurons: 201, Grad norm: 1.759169328909133\n",
      "Epoch 3430, Loss: 209.1883372346496, Neurons: 201, Grad norm: 1.759169328909133\n",
      "Epoch 3431, Loss: 209.1880941469239, Neurons: 201, Grad norm: 1.760118420557476\n",
      "Epoch 3431, Loss: 209.1880941469239, Neurons: 201, Grad norm: 1.760118420557476\n",
      "Epoch 3432, Loss: 209.18782813424295, Neurons: 201, Grad norm: 2.2724166006375133\n",
      "Epoch 3432, Loss: 209.18782813424295, Neurons: 201, Grad norm: 2.2724166006375133\n",
      "Epoch 3433, Loss: 209.18757806713847, Neurons: 201, Grad norm: 2.608028461963481\n",
      "Epoch 3433, Loss: 209.18757806713847, Neurons: 201, Grad norm: 2.608028461963481\n",
      "Epoch 3434, Loss: 209.18737215788647, Neurons: 201, Grad norm: 3.277276794577435\n",
      "Epoch 3434, Loss: 209.18737215788647, Neurons: 201, Grad norm: 3.277276794577435\n",
      "Epoch 3435, Loss: 209.18719762087915, Neurons: 201, Grad norm: 3.3509999617499995\n",
      "Epoch 3435, Loss: 209.18719762087915, Neurons: 201, Grad norm: 3.3509999617499995\n",
      "Epoch 3436, Loss: 209.18694914071983, Neurons: 201, Grad norm: 3.3965746884504635\n",
      "Epoch 3436, Loss: 209.18694914071983, Neurons: 201, Grad norm: 3.3965746884504635\n",
      "Epoch 3437, Loss: 209.18667297034153, Neurons: 201, Grad norm: 2.8221219104817954\n",
      "Epoch 3437, Loss: 209.18667297034153, Neurons: 201, Grad norm: 2.8221219104817954\n",
      "Epoch 3438, Loss: 209.1863285855032, Neurons: 201, Grad norm: 2.3350178365752083\n",
      "Epoch 3438, Loss: 209.1863285855032, Neurons: 201, Grad norm: 2.3350178365752083\n",
      "Epoch 3439, Loss: 209.18600886192306, Neurons: 201, Grad norm: 1.5009419249719917\n",
      "Epoch 3439, Loss: 209.18600886192306, Neurons: 201, Grad norm: 1.5009419249719917\n",
      "Epoch 3440, Loss: 209.18567390178933, Neurons: 201, Grad norm: 1.1201825154168816\n",
      "Epoch 3440, Loss: 209.18567390178933, Neurons: 201, Grad norm: 1.1201825154168816\n",
      "Epoch 3441, Loss: 209.18540321626335, Neurons: 201, Grad norm: 0.7620390042646792\n",
      "Epoch 3441, Loss: 209.18540321626335, Neurons: 201, Grad norm: 0.7620390042646792\n",
      "Epoch 3442, Loss: 209.1851262945272, Neurons: 201, Grad norm: 0.7372890269285394\n",
      "Epoch 3442, Loss: 209.1851262945272, Neurons: 201, Grad norm: 0.7372890269285394\n",
      "Epoch 3443, Loss: 209.1848470927691, Neurons: 201, Grad norm: 0.7065904140376298\n",
      "Epoch 3443, Loss: 209.1848470927691, Neurons: 201, Grad norm: 0.7065904140376298\n",
      "Epoch 3444, Loss: 209.1845756645319, Neurons: 201, Grad norm: 0.5758915348789373\n",
      "Epoch 3444, Loss: 209.1845756645319, Neurons: 201, Grad norm: 0.5758915348789373\n",
      "Epoch 3445, Loss: 209.18430559047303, Neurons: 201, Grad norm: 0.914395121359709\n",
      "Epoch 3445, Loss: 209.18430559047303, Neurons: 201, Grad norm: 0.914395121359709\n",
      "Epoch 3446, Loss: 209.18404008630256, Neurons: 201, Grad norm: 1.1346176687267338\n",
      "Epoch 3446, Loss: 209.18404008630256, Neurons: 201, Grad norm: 1.1346176687267338\n",
      "Epoch 3447, Loss: 209.18378334889928, Neurons: 201, Grad norm: 1.9253582573210268\n",
      "Epoch 3447, Loss: 209.18378334889928, Neurons: 201, Grad norm: 1.9253582573210268\n",
      "Epoch 3448, Loss: 209.18357459455362, Neurons: 201, Grad norm: 2.4660799632995714\n",
      "Epoch 3448, Loss: 209.18357459455362, Neurons: 201, Grad norm: 2.4660799632995714\n",
      "Epoch 3449, Loss: 209.1833874852626, Neurons: 201, Grad norm: 3.221859210108299\n",
      "Epoch 3449, Loss: 209.1833874852626, Neurons: 201, Grad norm: 3.221859210108299\n",
      "Epoch 3450, Loss: 209.18319734812331, Neurons: 201, Grad norm: 3.612007600995017\n",
      "Epoch 3450, Loss: 209.18319734812331, Neurons: 201, Grad norm: 3.612007600995017\n",
      "Epoch 3451, Loss: 209.18300405682854, Neurons: 201, Grad norm: 4.224367272436713\n",
      "Epoch 3451, Loss: 209.18300405682854, Neurons: 201, Grad norm: 4.224367272436713\n",
      "Epoch 3452, Loss: 209.18282629976213, Neurons: 201, Grad norm: 4.395728158245962\n",
      "Epoch 3452, Loss: 209.18282629976213, Neurons: 201, Grad norm: 4.395728158245962\n",
      "Epoch 3453, Loss: 209.18261557061365, Neurons: 201, Grad norm: 4.949872605784021\n",
      "Epoch 3453, Loss: 209.18261557061365, Neurons: 201, Grad norm: 4.949872605784021\n",
      "Epoch 3454, Loss: 209.18244911007577, Neurons: 201, Grad norm: 4.691485435995608\n",
      "Epoch 3454, Loss: 209.18244911007577, Neurons: 201, Grad norm: 4.691485435995608\n",
      "Epoch 3455, Loss: 209.18217580387318, Neurons: 201, Grad norm: 4.045415967745177\n",
      "Epoch 3455, Loss: 209.18217580387318, Neurons: 201, Grad norm: 4.045415967745177\n",
      "Epoch 3456, Loss: 209.18180056907605, Neurons: 201, Grad norm: 2.6860676762461098\n",
      "Epoch 3456, Loss: 209.18180056907605, Neurons: 201, Grad norm: 2.6860676762461098\n",
      "Epoch 3457, Loss: 209.18134627925497, Neurons: 201, Grad norm: 1.403593847441963\n",
      "Epoch 3457, Loss: 209.18134627925497, Neurons: 201, Grad norm: 1.403593847441963\n",
      "Epoch 3458, Loss: 209.18097755826446, Neurons: 201, Grad norm: 0.712183619301334\n",
      "Epoch 3458, Loss: 209.18097755826446, Neurons: 201, Grad norm: 0.712183619301334\n",
      "Epoch 3459, Loss: 209.18068959309934, Neurons: 201, Grad norm: 1.454933134606893\n",
      "Epoch 3459, Loss: 209.18068959309934, Neurons: 201, Grad norm: 1.454933134606893\n",
      "Epoch 3460, Loss: 209.18045693803595, Neurons: 201, Grad norm: 3.3347656661321836\n",
      "Epoch 3460, Loss: 209.18045693803595, Neurons: 201, Grad norm: 3.3347656661321836\n",
      "Epoch 3461, Loss: 209.18036625688572, Neurons: 201, Grad norm: 4.759648920609114\n",
      "Epoch 3461, Loss: 209.18036625688572, Neurons: 201, Grad norm: 4.759648920609114\n",
      "Epoch 3462, Loss: 209.18038787335806, Neurons: 201, Grad norm: 6.7072638122212\n",
      "Epoch 3462, Loss: 209.18038787335806, Neurons: 201, Grad norm: 6.7072638122212\n",
      "Epoch 3463, Loss: 209.180606928356, Neurons: 201, Grad norm: 7.7174802991717835\n",
      "Epoch 3463, Loss: 209.180606928356, Neurons: 201, Grad norm: 7.7174802991717835\n",
      "Epoch 3464, Loss: 209.18067253802502, Neurons: 201, Grad norm: 8.34351945785746\n",
      "Epoch 3464, Loss: 209.18067253802502, Neurons: 201, Grad norm: 8.34351945785746\n",
      "Epoch 3465, Loss: 209.18063789261552, Neurons: 201, Grad norm: 7.58726053972289\n",
      "Epoch 3465, Loss: 209.18063789261552, Neurons: 201, Grad norm: 7.58726053972289\n",
      "Epoch 3466, Loss: 209.18016535284661, Neurons: 201, Grad norm: 5.825537777160759\n",
      "Epoch 3466, Loss: 209.18016535284661, Neurons: 201, Grad norm: 5.825537777160759\n",
      "Epoch 3467, Loss: 209.17943107031542, Neurons: 201, Grad norm: 2.903070234527301\n",
      "Epoch 3467, Loss: 209.17943107031542, Neurons: 201, Grad norm: 2.903070234527301\n",
      "Epoch 3468, Loss: 209.17868434381882, Neurons: 201, Grad norm: 0.7207829679344053\n",
      "Epoch 3468, Loss: 209.17868434381882, Neurons: 201, Grad norm: 0.7207829679344053\n",
      "Epoch 3469, Loss: 209.17821445560386, Neurons: 201, Grad norm: 3.548583184431967\n",
      "Epoch 3469, Loss: 209.17821445560386, Neurons: 201, Grad norm: 3.548583184431967\n",
      "Epoch 3470, Loss: 209.1782679706399, Neurons: 201, Grad norm: 5.461345459523373\n",
      "Epoch 3470, Loss: 209.1782679706399, Neurons: 201, Grad norm: 5.461345459523373\n",
      "Epoch 3471, Loss: 209.1783314544812, Neurons: 201, Grad norm: 6.548244374011553\n",
      "Epoch 3471, Loss: 209.1783314544812, Neurons: 201, Grad norm: 6.548244374011553\n",
      "Epoch 3472, Loss: 209.17831840114465, Neurons: 201, Grad norm: 6.026403810687559\n",
      "Epoch 3472, Loss: 209.17831840114465, Neurons: 201, Grad norm: 6.026403810687559\n",
      "Epoch 3473, Loss: 209.17794026384246, Neurons: 201, Grad norm: 4.91177508245887\n",
      "Epoch 3473, Loss: 209.17794026384246, Neurons: 201, Grad norm: 4.91177508245887\n",
      "Epoch 3474, Loss: 209.1774277991603, Neurons: 201, Grad norm: 2.680268217358781\n",
      "Epoch 3474, Loss: 209.1774277991603, Neurons: 201, Grad norm: 2.680268217358781\n",
      "Epoch 3475, Loss: 209.1768265736817, Neurons: 201, Grad norm: 0.6204947959905548\n",
      "Epoch 3475, Loss: 209.1768265736817, Neurons: 201, Grad norm: 0.6204947959905548\n",
      "Epoch 3476, Loss: 209.17640111755676, Neurons: 201, Grad norm: 2.3551838293187433\n",
      "Epoch 3476, Loss: 209.17640111755676, Neurons: 201, Grad norm: 2.3551838293187433\n",
      "Epoch 3477, Loss: 209.17619113274208, Neurons: 201, Grad norm: 4.018774345478038\n",
      "Epoch 3477, Loss: 209.17619113274208, Neurons: 201, Grad norm: 4.018774345478038\n",
      "Epoch 3478, Loss: 209.17627342556474, Neurons: 201, Grad norm: 5.795136107208143\n",
      "Epoch 3478, Loss: 209.17627342556474, Neurons: 201, Grad norm: 5.795136107208143\n",
      "Epoch 3479, Loss: 209.1762775773475, Neurons: 201, Grad norm: 6.098151407921159\n",
      "Epoch 3479, Loss: 209.1762775773475, Neurons: 201, Grad norm: 6.098151407921159\n",
      "Epoch 3480, Loss: 209.1762514620884, Neurons: 201, Grad norm: 6.057314936019517\n",
      "Epoch 3480, Loss: 209.1762514620884, Neurons: 201, Grad norm: 6.057314936019517\n",
      "Epoch 3481, Loss: 209.17594394374603, Neurons: 201, Grad norm: 4.7051446996532365\n",
      "Epoch 3481, Loss: 209.17594394374603, Neurons: 201, Grad norm: 4.7051446996532365\n",
      "Epoch 3482, Loss: 209.1754102957798, Neurons: 201, Grad norm: 3.0649189353019244\n",
      "Epoch 3482, Loss: 209.1754102957798, Neurons: 201, Grad norm: 3.0649189353019244\n",
      "Epoch 3483, Loss: 209.17488018506302, Neurons: 201, Grad norm: 0.9279779558576139\n",
      "Epoch 3483, Loss: 209.17488018506302, Neurons: 201, Grad norm: 0.9279779558576139\n",
      "Epoch 3484, Loss: 209.17446874128197, Neurons: 201, Grad norm: 1.1697607596501276\n",
      "Epoch 3484, Loss: 209.17446874128197, Neurons: 201, Grad norm: 1.1697607596501276\n",
      "Epoch 3485, Loss: 209.17423654065752, Neurons: 201, Grad norm: 2.6604322815934425\n",
      "Epoch 3485, Loss: 209.17423654065752, Neurons: 201, Grad norm: 2.6604322815934425\n",
      "Epoch 3486, Loss: 209.1741055035394, Neurons: 201, Grad norm: 3.3442468727330423\n",
      "Epoch 3486, Loss: 209.1741055035394, Neurons: 201, Grad norm: 3.3442468727330423\n",
      "Epoch 3487, Loss: 209.17395809950676, Neurons: 201, Grad norm: 3.751654361475439\n",
      "Epoch 3487, Loss: 209.17395809950676, Neurons: 201, Grad norm: 3.751654361475439\n",
      "Epoch 3488, Loss: 209.17377063371688, Neurons: 201, Grad norm: 3.3213823515904437\n",
      "Epoch 3488, Loss: 209.17377063371688, Neurons: 201, Grad norm: 3.3213823515904437\n",
      "Epoch 3489, Loss: 209.17348334383465, Neurons: 201, Grad norm: 2.653315612418484\n",
      "Epoch 3489, Loss: 209.17348334383465, Neurons: 201, Grad norm: 2.653315612418484\n",
      "Epoch 3490, Loss: 209.17314041661632, Neurons: 201, Grad norm: 1.5245313665721898\n",
      "Epoch 3490, Loss: 209.17314041661632, Neurons: 201, Grad norm: 1.5245313665721898\n",
      "Epoch 3491, Loss: 209.17281991154985, Neurons: 201, Grad norm: 0.5159485245610338\n",
      "Epoch 3491, Loss: 209.17281991154985, Neurons: 201, Grad norm: 0.5159485245610338\n",
      "Epoch 3492, Loss: 209.17252771076488, Neurons: 201, Grad norm: 1.2710827891926553\n",
      "Epoch 3492, Loss: 209.17252771076488, Neurons: 201, Grad norm: 1.2710827891926553\n",
      "Epoch 3493, Loss: 209.17231078698936, Neurons: 201, Grad norm: 2.2953550578108732\n",
      "Epoch 3493, Loss: 209.17231078698936, Neurons: 201, Grad norm: 2.2953550578108732\n",
      "Epoch 3494, Loss: 209.17217959650193, Neurons: 201, Grad norm: 3.420545633035771\n",
      "Epoch 3494, Loss: 209.17217959650193, Neurons: 201, Grad norm: 3.420545633035771\n",
      "Epoch 3495, Loss: 209.17201418429056, Neurons: 201, Grad norm: 3.6771225877474336\n",
      "Epoch 3495, Loss: 209.17201418429056, Neurons: 201, Grad norm: 3.6771225877474336\n",
      "Epoch 3496, Loss: 209.17186427565858, Neurons: 201, Grad norm: 4.101854846873889\n",
      "Epoch 3496, Loss: 209.17186427565858, Neurons: 201, Grad norm: 4.101854846873889\n",
      "Epoch 3497, Loss: 209.17164354610284, Neurons: 201, Grad norm: 3.698141260557937\n",
      "Epoch 3497, Loss: 209.17164354610284, Neurons: 201, Grad norm: 3.698141260557937\n",
      "Epoch 3498, Loss: 209.171398972961, Neurons: 201, Grad norm: 3.447501460162293\n",
      "Epoch 3498, Loss: 209.171398972961, Neurons: 201, Grad norm: 3.447501460162293\n",
      "Epoch 3499, Loss: 209.17111727897867, Neurons: 201, Grad norm: 2.428712294184106\n",
      "Epoch 3499, Loss: 209.17111727897867, Neurons: 201, Grad norm: 2.428712294184106\n",
      "Epoch 3500, Loss: 209.1707788250462, Neurons: 201, Grad norm: 1.1953705089964557\n",
      "Epoch 3500, Loss: 209.1707788250462, Neurons: 201, Grad norm: 1.1953705089964557\n",
      "Epoch 3501, Loss: 209.17044521687913, Neurons: 201, Grad norm: 0.78541180950597\n",
      "Epoch 3501, Loss: 209.17044521687913, Neurons: 201, Grad norm: 0.78541180950597\n",
      "Epoch 3502, Loss: 209.1701809026625, Neurons: 201, Grad norm: 2.0685664316086916\n",
      "Epoch 3502, Loss: 209.1701809026625, Neurons: 201, Grad norm: 2.0685664316086916\n",
      "Epoch 3503, Loss: 209.17003393422314, Neurons: 201, Grad norm: 3.5624407968711003\n",
      "Epoch 3503, Loss: 209.17003393422314, Neurons: 201, Grad norm: 3.5624407968711003\n",
      "Epoch 3504, Loss: 209.1699632943853, Neurons: 201, Grad norm: 4.222590193659233\n",
      "Epoch 3504, Loss: 209.1699632943853, Neurons: 201, Grad norm: 4.222590193659233\n",
      "Epoch 3505, Loss: 209.16988310590287, Neurons: 201, Grad norm: 4.502011353345149\n",
      "Epoch 3505, Loss: 209.16988310590287, Neurons: 201, Grad norm: 4.502011353345149\n",
      "Epoch 3506, Loss: 209.16967131891425, Neurons: 201, Grad norm: 3.687262567729294\n",
      "Epoch 3506, Loss: 209.16967131891425, Neurons: 201, Grad norm: 3.687262567729294\n",
      "Epoch 3507, Loss: 209.16932415640812, Neurons: 201, Grad norm: 2.731455152700714\n",
      "Epoch 3507, Loss: 209.16932415640812, Neurons: 201, Grad norm: 2.731455152700714\n",
      "Epoch 3508, Loss: 209.16897503189034, Neurons: 201, Grad norm: 1.3146958727128728\n",
      "Epoch 3508, Loss: 209.16897503189034, Neurons: 201, Grad norm: 1.3146958727128728\n",
      "Epoch 3509, Loss: 209.16861367651967, Neurons: 201, Grad norm: 0.5849639494832582\n",
      "Epoch 3509, Loss: 209.16861367651967, Neurons: 201, Grad norm: 0.5849639494832582\n",
      "Epoch 3510, Loss: 209.16833972817673, Neurons: 201, Grad norm: 1.2588104802481817\n",
      "Epoch 3510, Loss: 209.16833972817673, Neurons: 201, Grad norm: 1.2588104802481817\n",
      "Epoch 3511, Loss: 209.16811473702663, Neurons: 201, Grad norm: 1.9542684258906526\n",
      "Epoch 3511, Loss: 209.16811473702663, Neurons: 201, Grad norm: 1.9542684258906526\n",
      "Epoch 3512, Loss: 209.16795389348218, Neurons: 201, Grad norm: 2.934040298089826\n",
      "Epoch 3512, Loss: 209.16795389348218, Neurons: 201, Grad norm: 2.934040298089826\n",
      "Epoch 3513, Loss: 209.1677996864232, Neurons: 201, Grad norm: 3.4071675729528277\n",
      "Epoch 3513, Loss: 209.1677996864232, Neurons: 201, Grad norm: 3.4071675729528277\n",
      "Epoch 3514, Loss: 209.16762954160484, Neurons: 201, Grad norm: 3.6116890808790103\n",
      "Epoch 3514, Loss: 209.16762954160484, Neurons: 201, Grad norm: 3.6116890808790103\n",
      "Epoch 3515, Loss: 209.16740062991218, Neurons: 201, Grad norm: 3.1449584576957657\n",
      "Epoch 3515, Loss: 209.16740062991218, Neurons: 201, Grad norm: 3.1449584576957657\n",
      "Epoch 3516, Loss: 209.1671124385959, Neurons: 201, Grad norm: 2.5783779905487663\n",
      "Epoch 3516, Loss: 209.1671124385959, Neurons: 201, Grad norm: 2.5783779905487663\n",
      "Epoch 3517, Loss: 209.1667841419725, Neurons: 201, Grad norm: 1.3905262440184798\n",
      "Epoch 3517, Loss: 209.1667841419725, Neurons: 201, Grad norm: 1.3905262440184798\n",
      "Epoch 3518, Loss: 209.16644279753166, Neurons: 201, Grad norm: 0.7690384635584885\n",
      "Epoch 3518, Loss: 209.16644279753166, Neurons: 201, Grad norm: 0.7690384635584885\n",
      "Epoch 3519, Loss: 209.16614523171629, Neurons: 201, Grad norm: 0.6643732147498157\n",
      "Epoch 3519, Loss: 209.16614523171629, Neurons: 201, Grad norm: 0.6643732147498157\n",
      "Epoch 3520, Loss: 209.16590419673363, Neurons: 201, Grad norm: 1.1905621063579683\n",
      "Epoch 3520, Loss: 209.16590419673363, Neurons: 201, Grad norm: 1.1905621063579683\n",
      "Epoch 3521, Loss: 209.16569471844346, Neurons: 201, Grad norm: 2.254271654635747\n",
      "Epoch 3521, Loss: 209.16569471844346, Neurons: 201, Grad norm: 2.254271654635747\n",
      "Epoch 3522, Loss: 209.16549416823023, Neurons: 201, Grad norm: 2.9782524761002946\n",
      "Epoch 3522, Loss: 209.16549416823023, Neurons: 201, Grad norm: 2.9782524761002946\n",
      "Epoch 3523, Loss: 209.1653796584108, Neurons: 201, Grad norm: 3.6379279639157662\n",
      "Epoch 3523, Loss: 209.1653796584108, Neurons: 201, Grad norm: 3.6379279639157662\n",
      "Epoch 3524, Loss: 209.1652425323022, Neurons: 201, Grad norm: 3.4505604953342504\n",
      "Epoch 3524, Loss: 209.1652425323022, Neurons: 201, Grad norm: 3.4505604953342504\n",
      "Epoch 3525, Loss: 209.164991348957, Neurons: 201, Grad norm: 3.30771507596631\n",
      "Epoch 3525, Loss: 209.164991348957, Neurons: 201, Grad norm: 3.30771507596631\n",
      "Epoch 3526, Loss: 209.16469463760876, Neurons: 201, Grad norm: 2.4998311552494052\n",
      "Epoch 3526, Loss: 209.16469463760876, Neurons: 201, Grad norm: 2.4998311552494052\n",
      "Epoch 3527, Loss: 209.1643940013659, Neurons: 201, Grad norm: 2.0573190792280287\n",
      "Epoch 3527, Loss: 209.1643940013659, Neurons: 201, Grad norm: 2.0573190792280287\n",
      "Epoch 3528, Loss: 209.16406691031906, Neurons: 201, Grad norm: 1.3465922377940538\n",
      "Epoch 3528, Loss: 209.16406691031906, Neurons: 201, Grad norm: 1.3465922377940538\n",
      "Epoch 3529, Loss: 209.16381604032466, Neurons: 201, Grad norm: 0.874097166205563\n",
      "Epoch 3529, Loss: 209.16381604032466, Neurons: 201, Grad norm: 0.874097166205563\n",
      "Epoch 3530, Loss: 209.16349727836044, Neurons: 201, Grad norm: 0.6285326187922706\n",
      "Epoch 3530, Loss: 209.16349727836044, Neurons: 201, Grad norm: 0.6285326187922706\n",
      "Epoch 3531, Loss: 209.1632435863125, Neurons: 201, Grad norm: 0.8191064250493414\n",
      "Epoch 3531, Loss: 209.1632435863125, Neurons: 201, Grad norm: 0.8191064250493414\n",
      "Epoch 3532, Loss: 209.16302951125786, Neurons: 201, Grad norm: 0.913838995427274\n",
      "Epoch 3532, Loss: 209.16302951125786, Neurons: 201, Grad norm: 0.913838995427274\n",
      "Epoch 3533, Loss: 209.16277116092095, Neurons: 201, Grad norm: 0.8977178116520571\n",
      "Epoch 3533, Loss: 209.16277116092095, Neurons: 201, Grad norm: 0.8977178116520571\n",
      "Epoch 3534, Loss: 209.16254731846612, Neurons: 201, Grad norm: 1.2479954974776437\n",
      "Epoch 3534, Loss: 209.16254731846612, Neurons: 201, Grad norm: 1.2479954974776437\n",
      "Epoch 3535, Loss: 209.16225841029487, Neurons: 201, Grad norm: 1.4463042249197204\n",
      "Epoch 3535, Loss: 209.16225841029487, Neurons: 201, Grad norm: 1.4463042249197204\n",
      "Epoch 3536, Loss: 209.16202706946996, Neurons: 201, Grad norm: 2.1792998933641514\n",
      "Epoch 3536, Loss: 209.16202706946996, Neurons: 201, Grad norm: 2.1792998933641514\n",
      "Epoch 3537, Loss: 209.16177772793077, Neurons: 201, Grad norm: 2.6422851113245387\n",
      "Epoch 3537, Loss: 209.16177772793077, Neurons: 201, Grad norm: 2.6422851113245387\n",
      "Epoch 3538, Loss: 209.16156463970506, Neurons: 201, Grad norm: 3.512929225146623\n",
      "Epoch 3538, Loss: 209.16156463970506, Neurons: 201, Grad norm: 3.512929225146623\n",
      "Epoch 3539, Loss: 209.16136321645814, Neurons: 201, Grad norm: 3.5818871518527393\n",
      "Epoch 3539, Loss: 209.16136321645814, Neurons: 201, Grad norm: 3.5818871518527393\n",
      "Epoch 3540, Loss: 209.1610707913322, Neurons: 201, Grad norm: 3.9948890091833094\n",
      "Epoch 3540, Loss: 209.1610707913322, Neurons: 201, Grad norm: 3.9948890091833094\n",
      "Epoch 3541, Loss: 209.16078678643532, Neurons: 201, Grad norm: 3.284038475818823\n",
      "Epoch 3541, Loss: 209.16078678643532, Neurons: 201, Grad norm: 3.284038475818823\n",
      "Epoch 3542, Loss: 209.16041816613975, Neurons: 201, Grad norm: 3.1420406127040708\n",
      "Epoch 3542, Loss: 209.16041816613975, Neurons: 201, Grad norm: 3.1420406127040708\n",
      "Epoch 3543, Loss: 209.15998434726762, Neurons: 201, Grad norm: 1.8029611966526908\n",
      "Epoch 3543, Loss: 209.15998434726762, Neurons: 201, Grad norm: 1.8029611966526908\n",
      "Epoch 3544, Loss: 209.1595158928431, Neurons: 201, Grad norm: 1.5382114792012742\n",
      "Epoch 3544, Loss: 209.1595158928431, Neurons: 201, Grad norm: 1.5382114792012742\n",
      "Epoch 3545, Loss: 209.15907967937747, Neurons: 201, Grad norm: 0.8826427422315705\n",
      "Epoch 3545, Loss: 209.15907967937747, Neurons: 201, Grad norm: 0.8826427422315705\n",
      "Epoch 3546, Loss: 209.15872805522454, Neurons: 201, Grad norm: 0.7678560929980208\n",
      "Epoch 3546, Loss: 209.15872805522454, Neurons: 201, Grad norm: 0.7678560929980208\n",
      "Epoch 3547, Loss: 209.15833640984218, Neurons: 201, Grad norm: 0.7663853109485397\n",
      "Epoch 3547, Loss: 209.15833640984218, Neurons: 201, Grad norm: 0.7663853109485397\n",
      "Epoch 3548, Loss: 209.15806486337993, Neurons: 201, Grad norm: 1.0354429627604818\n",
      "Epoch 3548, Loss: 209.15806486337993, Neurons: 201, Grad norm: 1.0354429627604818\n",
      "Epoch 3549, Loss: 209.15781173454712, Neurons: 201, Grad norm: 1.1992461363891922\n",
      "Epoch 3549, Loss: 209.15781173454712, Neurons: 201, Grad norm: 1.1992461363891922\n",
      "Epoch 3550, Loss: 209.15754239343144, Neurons: 201, Grad norm: 1.415148029620322\n",
      "Epoch 3550, Loss: 209.15754239343144, Neurons: 201, Grad norm: 1.415148029620322\n",
      "Epoch 3551, Loss: 209.1573028559703, Neurons: 201, Grad norm: 2.0758290735307656\n",
      "Epoch 3551, Loss: 209.1573028559703, Neurons: 201, Grad norm: 2.0758290735307656\n",
      "Epoch 3552, Loss: 209.1571604955294, Neurons: 201, Grad norm: 2.3571523328182775\n",
      "Epoch 3552, Loss: 209.1571604955294, Neurons: 201, Grad norm: 2.3571523328182775\n",
      "Epoch 3553, Loss: 209.15699284527898, Neurons: 201, Grad norm: 2.6975077455678784\n",
      "Epoch 3553, Loss: 209.15699284527898, Neurons: 201, Grad norm: 2.6975077455678784\n",
      "Epoch 3554, Loss: 209.1567946173542, Neurons: 201, Grad norm: 2.9165644867146465\n",
      "Epoch 3554, Loss: 209.1567946173542, Neurons: 201, Grad norm: 2.9165644867146465\n",
      "Epoch 3555, Loss: 209.15657322144799, Neurons: 201, Grad norm: 2.9133589057477027\n",
      "Epoch 3555, Loss: 209.15657322144799, Neurons: 201, Grad norm: 2.9133589057477027\n",
      "Epoch 3556, Loss: 209.15635744393424, Neurons: 201, Grad norm: 3.136899189058775\n",
      "Epoch 3556, Loss: 209.15635744393424, Neurons: 201, Grad norm: 3.136899189058775\n",
      "Epoch 3557, Loss: 209.1561214865149, Neurons: 201, Grad norm: 3.115654624964647\n",
      "Epoch 3557, Loss: 209.1561214865149, Neurons: 201, Grad norm: 3.115654624964647\n",
      "Epoch 3558, Loss: 209.155891765226, Neurons: 201, Grad norm: 3.126008175988299\n",
      "Epoch 3558, Loss: 209.155891765226, Neurons: 201, Grad norm: 3.126008175988299\n",
      "Epoch 3559, Loss: 209.15559269282707, Neurons: 201, Grad norm: 3.1319073536423296\n",
      "Epoch 3559, Loss: 209.15559269282707, Neurons: 201, Grad norm: 3.1319073536423296\n",
      "Epoch 3560, Loss: 209.15532866798532, Neurons: 201, Grad norm: 2.98901837808381\n",
      "Epoch 3560, Loss: 209.15532866798532, Neurons: 201, Grad norm: 2.98901837808381\n",
      "Epoch 3561, Loss: 209.15505686734804, Neurons: 201, Grad norm: 3.209549062126043\n",
      "Epoch 3561, Loss: 209.15505686734804, Neurons: 201, Grad norm: 3.209549062126043\n",
      "Epoch 3562, Loss: 209.15478804014506, Neurons: 201, Grad norm: 2.985178046943754\n",
      "Epoch 3562, Loss: 209.15478804014506, Neurons: 201, Grad norm: 2.985178046943754\n",
      "Epoch 3563, Loss: 209.1544787606438, Neurons: 201, Grad norm: 3.254974091723284\n",
      "Epoch 3563, Loss: 209.1544787606438, Neurons: 201, Grad norm: 3.254974091723284\n",
      "Epoch 3564, Loss: 209.15426940588722, Neurons: 201, Grad norm: 3.0147605923063643\n",
      "Epoch 3564, Loss: 209.15426940588722, Neurons: 201, Grad norm: 3.0147605923063643\n",
      "Epoch 3565, Loss: 209.15407032931202, Neurons: 201, Grad norm: 3.409289589356235\n",
      "Epoch 3565, Loss: 209.15407032931202, Neurons: 201, Grad norm: 3.409289589356235\n",
      "Epoch 3566, Loss: 209.15383561773484, Neurons: 201, Grad norm: 2.9464753263818957\n",
      "Epoch 3566, Loss: 209.15383561773484, Neurons: 201, Grad norm: 2.9464753263818957\n",
      "Epoch 3567, Loss: 209.15353856260774, Neurons: 201, Grad norm: 2.820646115848713\n",
      "Epoch 3567, Loss: 209.15353856260774, Neurons: 201, Grad norm: 2.820646115848713\n",
      "Epoch 3568, Loss: 209.15325334527242, Neurons: 201, Grad norm: 2.1615811856799123\n",
      "Epoch 3568, Loss: 209.15325334527242, Neurons: 201, Grad norm: 2.1615811856799123\n",
      "Epoch 3569, Loss: 209.15297283463852, Neurons: 201, Grad norm: 1.6610114536396863\n",
      "Epoch 3569, Loss: 209.15297283463852, Neurons: 201, Grad norm: 1.6610114536396863\n",
      "Epoch 3570, Loss: 209.15267633128357, Neurons: 201, Grad norm: 1.0165214957466813\n",
      "Epoch 3570, Loss: 209.15267633128357, Neurons: 201, Grad norm: 1.0165214957466813\n",
      "Epoch 3571, Loss: 209.15237504896598, Neurons: 201, Grad norm: 0.8175490833299653\n",
      "Epoch 3571, Loss: 209.15237504896598, Neurons: 201, Grad norm: 0.8175490833299653\n",
      "Epoch 3572, Loss: 209.15208349896278, Neurons: 201, Grad norm: 0.7224149576844855\n",
      "Epoch 3572, Loss: 209.15208349896278, Neurons: 201, Grad norm: 0.7224149576844855\n",
      "Epoch 3573, Loss: 209.15181218711777, Neurons: 201, Grad norm: 0.9346443764406613\n",
      "Epoch 3573, Loss: 209.15181218711777, Neurons: 201, Grad norm: 0.9346443764406613\n",
      "Epoch 3574, Loss: 209.15154001122886, Neurons: 201, Grad norm: 1.4345009087347824\n",
      "Epoch 3574, Loss: 209.15154001122886, Neurons: 201, Grad norm: 1.4345009087347824\n",
      "Epoch 3575, Loss: 209.1512820201711, Neurons: 201, Grad norm: 1.8314952136066867\n",
      "Epoch 3575, Loss: 209.1512820201711, Neurons: 201, Grad norm: 1.8314952136066867\n",
      "Epoch 3576, Loss: 209.15105050646105, Neurons: 201, Grad norm: 2.1377383659572162\n",
      "Epoch 3576, Loss: 209.15105050646105, Neurons: 201, Grad norm: 2.1377383659572162\n",
      "Epoch 3577, Loss: 209.150817954967, Neurons: 201, Grad norm: 2.1860053854082553\n",
      "Epoch 3577, Loss: 209.150817954967, Neurons: 201, Grad norm: 2.1860053854082553\n",
      "Epoch 3578, Loss: 209.15057444634033, Neurons: 201, Grad norm: 2.6959528327982243\n",
      "Epoch 3578, Loss: 209.15057444634033, Neurons: 201, Grad norm: 2.6959528327982243\n",
      "Epoch 3579, Loss: 209.15036054416294, Neurons: 201, Grad norm: 2.474703804006229\n",
      "Epoch 3579, Loss: 209.15036054416294, Neurons: 201, Grad norm: 2.474703804006229\n",
      "Epoch 3580, Loss: 209.15008195992044, Neurons: 201, Grad norm: 2.663659637998024\n",
      "Epoch 3580, Loss: 209.15008195992044, Neurons: 201, Grad norm: 2.663659637998024\n",
      "Epoch 3581, Loss: 209.14981076582353, Neurons: 201, Grad norm: 2.5811204013549633\n",
      "Epoch 3581, Loss: 209.14981076582353, Neurons: 201, Grad norm: 2.5811204013549633\n",
      "Epoch 3582, Loss: 209.14954150862962, Neurons: 201, Grad norm: 2.788839564745502\n",
      "Epoch 3582, Loss: 209.14954150862962, Neurons: 201, Grad norm: 2.788839564745502\n",
      "Epoch 3583, Loss: 209.1493310788691, Neurons: 201, Grad norm: 3.022497955738209\n",
      "Epoch 3583, Loss: 209.1493310788691, Neurons: 201, Grad norm: 3.022497955738209\n",
      "Epoch 3584, Loss: 209.1491222450857, Neurons: 201, Grad norm: 3.592590732604908\n",
      "Epoch 3584, Loss: 209.1491222450857, Neurons: 201, Grad norm: 3.592590732604908\n",
      "Epoch 3585, Loss: 209.1489319475248, Neurons: 201, Grad norm: 4.089737024456378\n",
      "Epoch 3585, Loss: 209.1489319475248, Neurons: 201, Grad norm: 4.089737024456378\n",
      "Epoch 3586, Loss: 209.1487574952026, Neurons: 201, Grad norm: 4.840711901433208\n",
      "Epoch 3586, Loss: 209.1487574952026, Neurons: 201, Grad norm: 4.840711901433208\n",
      "Epoch 3587, Loss: 209.14868462340272, Neurons: 201, Grad norm: 4.958272297880585\n",
      "Epoch 3587, Loss: 209.14868462340272, Neurons: 201, Grad norm: 4.958272297880585\n",
      "Epoch 3588, Loss: 209.14849603170032, Neurons: 201, Grad norm: 5.322481339313634\n",
      "Epoch 3588, Loss: 209.14849603170032, Neurons: 201, Grad norm: 5.322481339313634\n",
      "Epoch 3589, Loss: 209.14827398988473, Neurons: 201, Grad norm: 4.674415511584026\n",
      "Epoch 3589, Loss: 209.14827398988473, Neurons: 201, Grad norm: 4.674415511584026\n",
      "Epoch 3590, Loss: 209.14793249010808, Neurons: 201, Grad norm: 4.222650863976089\n",
      "Epoch 3590, Loss: 209.14793249010808, Neurons: 201, Grad norm: 4.222650863976089\n",
      "Epoch 3591, Loss: 209.14758799120435, Neurons: 201, Grad norm: 3.0941746111936315\n",
      "Epoch 3591, Loss: 209.14758799120435, Neurons: 201, Grad norm: 3.0941746111936315\n",
      "Epoch 3592, Loss: 209.14721581729134, Neurons: 201, Grad norm: 2.2087565085753593\n",
      "Epoch 3592, Loss: 209.14721581729134, Neurons: 201, Grad norm: 2.2087565085753593\n",
      "Epoch 3593, Loss: 209.14689634758616, Neurons: 201, Grad norm: 1.5355104107816935\n",
      "Epoch 3593, Loss: 209.14689634758616, Neurons: 201, Grad norm: 1.5355104107816935\n",
      "Epoch 3594, Loss: 209.1465913849971, Neurons: 201, Grad norm: 1.0898994831815403\n",
      "Epoch 3594, Loss: 209.1465913849971, Neurons: 201, Grad norm: 1.0898994831815403\n",
      "Epoch 3595, Loss: 209.14634877987618, Neurons: 201, Grad norm: 0.9358667884835224\n",
      "Epoch 3595, Loss: 209.14634877987618, Neurons: 201, Grad norm: 0.9358667884835224\n",
      "Epoch 3596, Loss: 209.14612064903434, Neurons: 201, Grad norm: 0.7087845609829714\n",
      "Epoch 3596, Loss: 209.14612064903434, Neurons: 201, Grad norm: 0.7087845609829714\n",
      "Epoch 3597, Loss: 209.14583147520614, Neurons: 201, Grad norm: 0.7909911253563202\n",
      "Epoch 3597, Loss: 209.14583147520614, Neurons: 201, Grad norm: 0.7909911253563202\n",
      "Epoch 3598, Loss: 209.1456420437516, Neurons: 201, Grad norm: 0.7135846081698796\n",
      "Epoch 3598, Loss: 209.1456420437516, Neurons: 201, Grad norm: 0.7135846081698796\n",
      "Epoch 3599, Loss: 209.14537990356277, Neurons: 201, Grad norm: 0.9768328101512924\n",
      "Epoch 3599, Loss: 209.14537990356277, Neurons: 201, Grad norm: 0.9768328101512924\n",
      "Epoch 3600, Loss: 209.1451163338337, Neurons: 201, Grad norm: 1.0432603608704543\n",
      "Epoch 3600, Loss: 209.1451163338337, Neurons: 201, Grad norm: 1.0432603608704543\n",
      "Epoch 3601, Loss: 209.1449262487379, Neurons: 201, Grad norm: 1.3343624346496663\n",
      "Epoch 3601, Loss: 209.1449262487379, Neurons: 201, Grad norm: 1.3343624346496663\n",
      "Epoch 3602, Loss: 209.1446605898732, Neurons: 201, Grad norm: 1.5128473658676198\n",
      "Epoch 3602, Loss: 209.1446605898732, Neurons: 201, Grad norm: 1.5128473658676198\n",
      "Epoch 3603, Loss: 209.144454849419, Neurons: 201, Grad norm: 1.8946425373952465\n",
      "Epoch 3603, Loss: 209.144454849419, Neurons: 201, Grad norm: 1.8946425373952465\n",
      "Epoch 3604, Loss: 209.14424328609184, Neurons: 201, Grad norm: 2.2966548505105786\n",
      "Epoch 3604, Loss: 209.14424328609184, Neurons: 201, Grad norm: 2.2966548505105786\n",
      "Epoch 3605, Loss: 209.14401343340538, Neurons: 201, Grad norm: 2.9135203705984596\n",
      "Epoch 3605, Loss: 209.14401343340538, Neurons: 201, Grad norm: 2.9135203705984596\n",
      "Epoch 3606, Loss: 209.14386677307093, Neurons: 201, Grad norm: 3.37632980412944\n",
      "Epoch 3606, Loss: 209.14386677307093, Neurons: 201, Grad norm: 3.37632980412944\n",
      "Epoch 3607, Loss: 209.14366844171943, Neurons: 201, Grad norm: 4.364838671869806\n",
      "Epoch 3607, Loss: 209.14366844171943, Neurons: 201, Grad norm: 4.364838671869806\n",
      "Epoch 3608, Loss: 209.14357672566933, Neurons: 201, Grad norm: 5.012865750064613\n",
      "Epoch 3608, Loss: 209.14357672566933, Neurons: 201, Grad norm: 5.012865750064613\n",
      "Epoch 3609, Loss: 209.1435275694156, Neurons: 201, Grad norm: 6.115267259493843\n",
      "Epoch 3609, Loss: 209.1435275694156, Neurons: 201, Grad norm: 6.115267259493843\n",
      "Epoch 3610, Loss: 209.14350120310633, Neurons: 201, Grad norm: 6.619950033694075\n",
      "Epoch 3610, Loss: 209.14350120310633, Neurons: 201, Grad norm: 6.619950033694075\n",
      "Epoch 3611, Loss: 209.1434075203603, Neurons: 201, Grad norm: 6.982507232327253\n",
      "Epoch 3611, Loss: 209.1434075203603, Neurons: 201, Grad norm: 6.982507232327253\n",
      "Epoch 3612, Loss: 209.1432539637043, Neurons: 201, Grad norm: 6.5012168714827165\n",
      "Epoch 3612, Loss: 209.1432539637043, Neurons: 201, Grad norm: 6.5012168714827165\n",
      "Epoch 3613, Loss: 209.1429473442636, Neurons: 201, Grad norm: 5.767702166182454\n",
      "Epoch 3613, Loss: 209.1429473442636, Neurons: 201, Grad norm: 5.767702166182454\n",
      "Epoch 3614, Loss: 209.1424573412386, Neurons: 201, Grad norm: 4.200780835095885\n",
      "Epoch 3614, Loss: 209.1424573412386, Neurons: 201, Grad norm: 4.200780835095885\n",
      "Epoch 3615, Loss: 209.14193711515495, Neurons: 201, Grad norm: 2.8086566752763864\n",
      "Epoch 3615, Loss: 209.14193711515495, Neurons: 201, Grad norm: 2.8086566752763864\n",
      "Epoch 3616, Loss: 209.14151563526673, Neurons: 201, Grad norm: 1.1078955507264296\n",
      "Epoch 3616, Loss: 209.14151563526673, Neurons: 201, Grad norm: 1.1078955507264296\n",
      "Epoch 3617, Loss: 209.14114857843765, Neurons: 201, Grad norm: 0.9323978403820304\n",
      "Epoch 3617, Loss: 209.14114857843765, Neurons: 201, Grad norm: 0.9323978403820304\n",
      "Epoch 3618, Loss: 209.14088473612046, Neurons: 201, Grad norm: 2.4494953596399753\n",
      "Epoch 3618, Loss: 209.14088473612046, Neurons: 201, Grad norm: 2.4494953596399753\n",
      "Epoch 3619, Loss: 209.14074641739006, Neurons: 201, Grad norm: 3.817447438590864\n",
      "Epoch 3619, Loss: 209.14074641739006, Neurons: 201, Grad norm: 3.817447438590864\n",
      "Epoch 3620, Loss: 209.14077090470116, Neurons: 201, Grad norm: 5.4241626231606155\n",
      "Epoch 3620, Loss: 209.14077090470116, Neurons: 201, Grad norm: 5.4241626231606155\n",
      "Epoch 3621, Loss: 209.1407247081881, Neurons: 201, Grad norm: 6.480735359693534\n",
      "Epoch 3621, Loss: 209.1407247081881, Neurons: 201, Grad norm: 6.480735359693534\n",
      "Epoch 3622, Loss: 209.14085600391374, Neurons: 201, Grad norm: 7.312644798984161\n",
      "Epoch 3622, Loss: 209.14085600391374, Neurons: 201, Grad norm: 7.312644798984161\n",
      "Epoch 3623, Loss: 209.140787665734, Neurons: 201, Grad norm: 7.092838789972029\n",
      "Epoch 3623, Loss: 209.140787665734, Neurons: 201, Grad norm: 7.092838789972029\n",
      "Epoch 3624, Loss: 209.14060687893638, Neurons: 201, Grad norm: 6.5480997571070905\n",
      "Epoch 3624, Loss: 209.14060687893638, Neurons: 201, Grad norm: 6.5480997571070905\n",
      "Epoch 3625, Loss: 209.14013423357522, Neurons: 201, Grad norm: 4.7892067697695175\n",
      "Epoch 3625, Loss: 209.14013423357522, Neurons: 201, Grad norm: 4.7892067697695175\n",
      "Epoch 3626, Loss: 209.13954967626358, Neurons: 201, Grad norm: 2.8042075636697397\n",
      "Epoch 3626, Loss: 209.13954967626358, Neurons: 201, Grad norm: 2.8042075636697397\n",
      "Epoch 3627, Loss: 209.13902250396814, Neurons: 201, Grad norm: 0.6166864692382039\n",
      "Epoch 3627, Loss: 209.13902250396814, Neurons: 201, Grad norm: 0.6166864692382039\n",
      "Epoch 3628, Loss: 209.13863827676948, Neurons: 201, Grad norm: 1.9025168454144517\n",
      "Epoch 3628, Loss: 209.13863827676948, Neurons: 201, Grad norm: 1.9025168454144517\n",
      "Epoch 3629, Loss: 209.1384609585145, Neurons: 201, Grad norm: 3.649935707956546\n",
      "Epoch 3629, Loss: 209.1384609585145, Neurons: 201, Grad norm: 3.649935707956546\n",
      "Epoch 3630, Loss: 209.13841919091064, Neurons: 201, Grad norm: 4.657645301458082\n",
      "Epoch 3630, Loss: 209.13841919091064, Neurons: 201, Grad norm: 4.657645301458082\n",
      "Epoch 3631, Loss: 209.13840483525803, Neurons: 201, Grad norm: 5.487933184386589\n",
      "Epoch 3631, Loss: 209.13840483525803, Neurons: 201, Grad norm: 5.487933184386589\n",
      "Epoch 3632, Loss: 209.13830326203805, Neurons: 201, Grad norm: 5.140198566800138\n",
      "Epoch 3632, Loss: 209.13830326203805, Neurons: 201, Grad norm: 5.140198566800138\n",
      "Epoch 3633, Loss: 209.1380148653978, Neurons: 201, Grad norm: 4.671808639167714\n",
      "Epoch 3633, Loss: 209.1380148653978, Neurons: 201, Grad norm: 4.671808639167714\n",
      "Epoch 3634, Loss: 209.13770215529016, Neurons: 201, Grad norm: 3.627673659507398\n",
      "Epoch 3634, Loss: 209.13770215529016, Neurons: 201, Grad norm: 3.627673659507398\n",
      "Epoch 3635, Loss: 209.13730037103633, Neurons: 201, Grad norm: 2.60254735343789\n",
      "Epoch 3635, Loss: 209.13730037103633, Neurons: 201, Grad norm: 2.60254735343789\n",
      "Epoch 3636, Loss: 209.1369476140432, Neurons: 201, Grad norm: 1.416442685447343\n",
      "Epoch 3636, Loss: 209.1369476140432, Neurons: 201, Grad norm: 1.416442685447343\n",
      "Epoch 3637, Loss: 209.1366447690178, Neurons: 201, Grad norm: 0.6277527679114808\n",
      "Epoch 3637, Loss: 209.1366447690178, Neurons: 201, Grad norm: 0.6277527679114808\n",
      "Epoch 3638, Loss: 209.13638930429465, Neurons: 201, Grad norm: 1.2395267863552526\n",
      "Epoch 3638, Loss: 209.13638930429465, Neurons: 201, Grad norm: 1.2395267863552526\n",
      "Epoch 3639, Loss: 209.13617413156146, Neurons: 201, Grad norm: 1.941995137415314\n",
      "Epoch 3639, Loss: 209.13617413156146, Neurons: 201, Grad norm: 1.941995137415314\n",
      "Epoch 3640, Loss: 209.1360076667167, Neurons: 201, Grad norm: 2.8946731393461156\n",
      "Epoch 3640, Loss: 209.1360076667167, Neurons: 201, Grad norm: 2.8946731393461156\n",
      "Epoch 3641, Loss: 209.13586557077645, Neurons: 201, Grad norm: 3.4895315162532894\n",
      "Epoch 3641, Loss: 209.13586557077645, Neurons: 201, Grad norm: 3.4895315162532894\n",
      "Epoch 3642, Loss: 209.13570789161446, Neurons: 201, Grad norm: 3.941398297439907\n",
      "Epoch 3642, Loss: 209.13570789161446, Neurons: 201, Grad norm: 3.941398297439907\n",
      "Epoch 3643, Loss: 209.13558311526424, Neurons: 201, Grad norm: 3.902287218135491\n",
      "Epoch 3643, Loss: 209.13558311526424, Neurons: 201, Grad norm: 3.902287218135491\n",
      "Epoch 3644, Loss: 209.13534604075554, Neurons: 201, Grad norm: 3.578204979293249\n",
      "Epoch 3644, Loss: 209.13534604075554, Neurons: 201, Grad norm: 3.578204979293249\n",
      "Epoch 3645, Loss: 209.1350598839932, Neurons: 201, Grad norm: 2.72234910752844\n",
      "Epoch 3645, Loss: 209.1350598839932, Neurons: 201, Grad norm: 2.72234910752844\n",
      "Epoch 3646, Loss: 209.1347306169513, Neurons: 201, Grad norm: 2.0437311678100247\n",
      "Epoch 3646, Loss: 209.1347306169513, Neurons: 201, Grad norm: 2.0437311678100247\n",
      "Epoch 3647, Loss: 209.13443474942468, Neurons: 201, Grad norm: 1.1842499705480947\n",
      "Epoch 3647, Loss: 209.13443474942468, Neurons: 201, Grad norm: 1.1842499705480947\n",
      "Epoch 3648, Loss: 209.1341983849177, Neurons: 201, Grad norm: 0.9238286121989875\n",
      "Epoch 3648, Loss: 209.1341983849177, Neurons: 201, Grad norm: 0.9238286121989875\n",
      "Epoch 3649, Loss: 209.1339512952613, Neurons: 201, Grad norm: 0.6382110176896517\n",
      "Epoch 3649, Loss: 209.1339512952613, Neurons: 201, Grad norm: 0.6382110176896517\n",
      "Epoch 3650, Loss: 209.13372174651352, Neurons: 201, Grad norm: 0.8194075826723374\n",
      "Epoch 3650, Loss: 209.13372174651352, Neurons: 201, Grad norm: 0.8194075826723374\n",
      "Epoch 3651, Loss: 209.13349802995162, Neurons: 201, Grad norm: 0.9964500405323069\n",
      "Epoch 3651, Loss: 209.13349802995162, Neurons: 201, Grad norm: 0.9964500405323069\n",
      "Epoch 3652, Loss: 209.13328701513345, Neurons: 201, Grad norm: 1.0964381832592542\n",
      "Epoch 3652, Loss: 209.13328701513345, Neurons: 201, Grad norm: 1.0964381832592542\n",
      "Epoch 3653, Loss: 209.13308557406538, Neurons: 201, Grad norm: 1.4228996150783633\n",
      "Epoch 3653, Loss: 209.13308557406538, Neurons: 201, Grad norm: 1.4228996150783633\n",
      "Epoch 3654, Loss: 209.13287930304026, Neurons: 201, Grad norm: 1.4733378488361153\n",
      "Epoch 3654, Loss: 209.13287930304026, Neurons: 201, Grad norm: 1.4733378488361153\n",
      "Epoch 3655, Loss: 209.13267890104515, Neurons: 201, Grad norm: 2.04451890365987\n",
      "Epoch 3655, Loss: 209.13267890104515, Neurons: 201, Grad norm: 2.04451890365987\n",
      "Epoch 3656, Loss: 209.13248703005996, Neurons: 201, Grad norm: 2.2654909520150834\n",
      "Epoch 3656, Loss: 209.13248703005996, Neurons: 201, Grad norm: 2.2654909520150834\n",
      "Epoch 3657, Loss: 209.1322920017756, Neurons: 201, Grad norm: 2.697267528900233\n",
      "Epoch 3657, Loss: 209.1322920017756, Neurons: 201, Grad norm: 2.697267528900233\n",
      "Epoch 3658, Loss: 209.13209993785392, Neurons: 201, Grad norm: 2.952175649642867\n",
      "Epoch 3658, Loss: 209.13209993785392, Neurons: 201, Grad norm: 2.952175649642867\n",
      "Epoch 3659, Loss: 209.1319106386697, Neurons: 201, Grad norm: 3.509108870599597\n",
      "Epoch 3659, Loss: 209.1319106386697, Neurons: 201, Grad norm: 3.509108870599597\n",
      "Epoch 3660, Loss: 209.13177273177604, Neurons: 201, Grad norm: 3.616235806036009\n",
      "Epoch 3660, Loss: 209.13177273177604, Neurons: 201, Grad norm: 3.616235806036009\n",
      "Epoch 3661, Loss: 209.131589610783, Neurons: 201, Grad norm: 3.7428830684691516\n",
      "Epoch 3661, Loss: 209.131589610783, Neurons: 201, Grad norm: 3.7428830684691516\n",
      "Epoch 3662, Loss: 209.13137920578552, Neurons: 201, Grad norm: 3.6076441032878335\n",
      "Epoch 3662, Loss: 209.13137920578552, Neurons: 201, Grad norm: 3.6076441032878335\n",
      "Epoch 3663, Loss: 209.13113427670433, Neurons: 201, Grad norm: 3.932307026418531\n",
      "Epoch 3663, Loss: 209.13113427670433, Neurons: 201, Grad norm: 3.932307026418531\n",
      "Epoch 3664, Loss: 209.1309484530212, Neurons: 201, Grad norm: 3.9882909939900917\n",
      "Epoch 3664, Loss: 209.1309484530212, Neurons: 201, Grad norm: 3.9882909939900917\n",
      "Epoch 3665, Loss: 209.13077798904462, Neurons: 201, Grad norm: 4.329778282423677\n",
      "Epoch 3665, Loss: 209.13077798904462, Neurons: 201, Grad norm: 4.329778282423677\n",
      "Epoch 3666, Loss: 209.130590413737, Neurons: 201, Grad norm: 4.287776319707775\n",
      "Epoch 3666, Loss: 209.130590413737, Neurons: 201, Grad norm: 4.287776319707775\n",
      "Epoch 3667, Loss: 209.13041077540174, Neurons: 201, Grad norm: 4.274313444492215\n",
      "Epoch 3667, Loss: 209.13041077540174, Neurons: 201, Grad norm: 4.274313444492215\n",
      "Epoch 3668, Loss: 209.13017741412804, Neurons: 201, Grad norm: 3.8139773686841685\n",
      "Epoch 3668, Loss: 209.13017741412804, Neurons: 201, Grad norm: 3.8139773686841685\n",
      "Epoch 3669, Loss: 209.12988587236325, Neurons: 201, Grad norm: 3.4702964598706463\n",
      "Epoch 3669, Loss: 209.12988587236325, Neurons: 201, Grad norm: 3.4702964598706463\n",
      "Epoch 3670, Loss: 209.12959853042085, Neurons: 201, Grad norm: 2.742073670751083\n",
      "Epoch 3670, Loss: 209.12959853042085, Neurons: 201, Grad norm: 2.742073670751083\n",
      "Epoch 3671, Loss: 209.12931638898442, Neurons: 201, Grad norm: 2.4495237561344867\n",
      "Epoch 3671, Loss: 209.12931638898442, Neurons: 201, Grad norm: 2.4495237561344867\n",
      "Epoch 3672, Loss: 209.12905424375523, Neurons: 201, Grad norm: 1.8340900551625572\n",
      "Epoch 3672, Loss: 209.12905424375523, Neurons: 201, Grad norm: 1.8340900551625572\n",
      "Epoch 3673, Loss: 209.12883248361382, Neurons: 201, Grad norm: 1.3965477911302164\n",
      "Epoch 3673, Loss: 209.12883248361382, Neurons: 201, Grad norm: 1.3965477911302164\n",
      "Epoch 3674, Loss: 209.12856671900246, Neurons: 201, Grad norm: 0.7793993959934378\n",
      "Epoch 3674, Loss: 209.12856671900246, Neurons: 201, Grad norm: 0.7793993959934378\n",
      "Epoch 3675, Loss: 209.1283175199663, Neurons: 201, Grad norm: 0.6574821258121416\n",
      "Epoch 3675, Loss: 209.1283175199663, Neurons: 201, Grad norm: 0.6574821258121416\n",
      "Epoch 3676, Loss: 209.12808965800926, Neurons: 201, Grad norm: 0.9137747409439858\n",
      "Epoch 3676, Loss: 209.12808965800926, Neurons: 201, Grad norm: 0.9137747409439858\n",
      "Epoch 3677, Loss: 209.12789626687507, Neurons: 201, Grad norm: 1.283906419660582\n",
      "Epoch 3677, Loss: 209.12789626687507, Neurons: 201, Grad norm: 1.283906419660582\n",
      "Epoch 3678, Loss: 209.12772326793916, Neurons: 201, Grad norm: 1.8255268491583148\n",
      "Epoch 3678, Loss: 209.12772326793916, Neurons: 201, Grad norm: 1.8255268491583148\n",
      "Epoch 3679, Loss: 209.12750442283456, Neurons: 201, Grad norm: 2.4034946831785855\n",
      "Epoch 3679, Loss: 209.12750442283456, Neurons: 201, Grad norm: 2.4034946831785855\n",
      "Epoch 3680, Loss: 209.1273591858368, Neurons: 201, Grad norm: 3.456725122463492\n",
      "Epoch 3680, Loss: 209.1273591858368, Neurons: 201, Grad norm: 3.456725122463492\n",
      "Epoch 3681, Loss: 209.12722726652905, Neurons: 201, Grad norm: 4.037386983540236\n",
      "Epoch 3681, Loss: 209.12722726652905, Neurons: 201, Grad norm: 4.037386983540236\n",
      "Epoch 3682, Loss: 209.12711991401247, Neurons: 201, Grad norm: 5.162478903072713\n",
      "Epoch 3682, Loss: 209.12711991401247, Neurons: 201, Grad norm: 5.162478903072713\n",
      "Epoch 3683, Loss: 209.12710550507614, Neurons: 201, Grad norm: 5.690742215650645\n",
      "Epoch 3683, Loss: 209.12710550507614, Neurons: 201, Grad norm: 5.690742215650645\n",
      "Epoch 3684, Loss: 209.12698716618797, Neurons: 201, Grad norm: 6.071221913310719\n",
      "Epoch 3684, Loss: 209.12698716618797, Neurons: 201, Grad norm: 6.071221913310719\n",
      "Epoch 3685, Loss: 209.12687253299168, Neurons: 201, Grad norm: 5.654856049507678\n",
      "Epoch 3685, Loss: 209.12687253299168, Neurons: 201, Grad norm: 5.654856049507678\n",
      "Epoch 3686, Loss: 209.1265477318322, Neurons: 201, Grad norm: 5.123500925541526\n",
      "Epoch 3686, Loss: 209.1265477318322, Neurons: 201, Grad norm: 5.123500925541526\n",
      "Epoch 3687, Loss: 209.12622852038606, Neurons: 201, Grad norm: 3.814647458128591\n",
      "Epoch 3687, Loss: 209.12622852038606, Neurons: 201, Grad norm: 3.814647458128591\n",
      "Epoch 3688, Loss: 209.12577252403622, Neurons: 201, Grad norm: 2.459028959290493\n",
      "Epoch 3688, Loss: 209.12577252403622, Neurons: 201, Grad norm: 2.459028959290493\n",
      "Epoch 3689, Loss: 209.12536361373532, Neurons: 201, Grad norm: 1.070539437666615\n",
      "Epoch 3689, Loss: 209.12536361373532, Neurons: 201, Grad norm: 1.070539437666615\n",
      "Epoch 3690, Loss: 209.12503449529765, Neurons: 201, Grad norm: 0.5923896828965889\n",
      "Epoch 3690, Loss: 209.12503449529765, Neurons: 201, Grad norm: 0.5923896828965889\n",
      "Epoch 3691, Loss: 209.12478894048508, Neurons: 201, Grad norm: 1.6725437566664643\n",
      "Epoch 3691, Loss: 209.12478894048508, Neurons: 201, Grad norm: 1.6725437566664643\n",
      "Epoch 3692, Loss: 209.12458936091886, Neurons: 201, Grad norm: 2.595446922383342\n",
      "Epoch 3692, Loss: 209.12458936091886, Neurons: 201, Grad norm: 2.595446922383342\n",
      "Epoch 3693, Loss: 209.12445155139022, Neurons: 201, Grad norm: 4.066181455550998\n",
      "Epoch 3693, Loss: 209.12445155139022, Neurons: 201, Grad norm: 4.066181455550998\n",
      "Epoch 3694, Loss: 209.12438697794047, Neurons: 201, Grad norm: 5.100457873210847\n",
      "Epoch 3694, Loss: 209.12438697794047, Neurons: 201, Grad norm: 5.100457873210847\n",
      "Epoch 3695, Loss: 209.1243857222684, Neurons: 201, Grad norm: 6.2666802154013705\n",
      "Epoch 3695, Loss: 209.1243857222684, Neurons: 201, Grad norm: 6.2666802154013705\n",
      "Epoch 3696, Loss: 209.12435845000667, Neurons: 201, Grad norm: 6.5591659417870956\n",
      "Epoch 3696, Loss: 209.12435845000667, Neurons: 201, Grad norm: 6.5591659417870956\n",
      "Epoch 3697, Loss: 209.12423925985016, Neurons: 201, Grad norm: 6.654771471265416\n",
      "Epoch 3697, Loss: 209.12423925985016, Neurons: 201, Grad norm: 6.654771471265416\n",
      "Epoch 3698, Loss: 209.1240139626153, Neurons: 201, Grad norm: 5.749047685987172\n",
      "Epoch 3698, Loss: 209.1240139626153, Neurons: 201, Grad norm: 5.749047685987172\n",
      "Epoch 3699, Loss: 209.12356061973534, Neurons: 201, Grad norm: 4.571467596208762\n",
      "Epoch 3699, Loss: 209.12356061973534, Neurons: 201, Grad norm: 4.571467596208762\n",
      "Epoch 3700, Loss: 209.1230697636275, Neurons: 201, Grad norm: 2.7937284928488757\n",
      "Epoch 3700, Loss: 209.1230697636275, Neurons: 201, Grad norm: 2.7937284928488757\n",
      "Epoch 3701, Loss: 209.1225340376329, Neurons: 201, Grad norm: 1.1294748352205048\n",
      "Epoch 3701, Loss: 209.1225340376329, Neurons: 201, Grad norm: 1.1294748352205048\n",
      "Epoch 3702, Loss: 209.12215265445363, Neurons: 201, Grad norm: 1.0243333477081582\n",
      "Epoch 3702, Loss: 209.12215265445363, Neurons: 201, Grad norm: 1.0243333477081582\n",
      "Epoch 3703, Loss: 209.12186880736772, Neurons: 201, Grad norm: 2.185027736379085\n",
      "Epoch 3703, Loss: 209.12186880736772, Neurons: 201, Grad norm: 2.185027736379085\n",
      "Epoch 3704, Loss: 209.1216709701684, Neurons: 201, Grad norm: 3.7187178865125454\n",
      "Epoch 3704, Loss: 209.1216709701684, Neurons: 201, Grad norm: 3.7187178865125454\n",
      "Epoch 3705, Loss: 209.12152504253402, Neurons: 201, Grad norm: 4.3952774932064855\n",
      "Epoch 3705, Loss: 209.12152504253402, Neurons: 201, Grad norm: 4.3952774932064855\n",
      "Epoch 3706, Loss: 209.12137403774904, Neurons: 201, Grad norm: 5.502092826123218\n",
      "Epoch 3706, Loss: 209.12137403774904, Neurons: 201, Grad norm: 5.502092826123218\n",
      "Epoch 3707, Loss: 209.12117248790065, Neurons: 201, Grad norm: 5.654873249622373\n",
      "Epoch 3707, Loss: 209.12117248790065, Neurons: 201, Grad norm: 5.654873249622373\n",
      "Epoch 3708, Loss: 209.12095291996422, Neurons: 201, Grad norm: 5.954533033284941\n",
      "Epoch 3708, Loss: 209.12095291996422, Neurons: 201, Grad norm: 5.954533033284941\n",
      "Epoch 3709, Loss: 209.12061024600087, Neurons: 201, Grad norm: 5.448965840289528\n",
      "Epoch 3709, Loss: 209.12061024600087, Neurons: 201, Grad norm: 5.448965840289528\n",
      "Epoch 3710, Loss: 209.12020423510285, Neurons: 201, Grad norm: 4.8994924756545535\n",
      "Epoch 3710, Loss: 209.12020423510285, Neurons: 201, Grad norm: 4.8994924756545535\n",
      "Epoch 3711, Loss: 209.1197897580187, Neurons: 201, Grad norm: 3.7314176286420064\n",
      "Epoch 3711, Loss: 209.1197897580187, Neurons: 201, Grad norm: 3.7314176286420064\n",
      "Epoch 3712, Loss: 209.1193215079519, Neurons: 201, Grad norm: 2.6761070032986116\n",
      "Epoch 3712, Loss: 209.1193215079519, Neurons: 201, Grad norm: 2.6761070032986116\n",
      "Epoch 3713, Loss: 209.11891793499635, Neurons: 201, Grad norm: 1.2851011928345994\n",
      "Epoch 3713, Loss: 209.11891793499635, Neurons: 201, Grad norm: 1.2851011928345994\n",
      "Epoch 3714, Loss: 209.11854506819108, Neurons: 201, Grad norm: 0.554203419813014\n",
      "Epoch 3714, Loss: 209.11854506819108, Neurons: 201, Grad norm: 0.554203419813014\n",
      "Epoch 3715, Loss: 209.1182600417572, Neurons: 201, Grad norm: 1.51431861589531\n",
      "Epoch 3715, Loss: 209.1182600417572, Neurons: 201, Grad norm: 1.51431861589531\n",
      "Epoch 3716, Loss: 209.11810614578366, Neurons: 201, Grad norm: 2.4212210108426864\n",
      "Epoch 3716, Loss: 209.11810614578366, Neurons: 201, Grad norm: 2.4212210108426864\n",
      "Epoch 3717, Loss: 209.11801863459385, Neurons: 201, Grad norm: 3.771226107012464\n",
      "Epoch 3717, Loss: 209.11801863459385, Neurons: 201, Grad norm: 3.771226107012464\n",
      "Epoch 3718, Loss: 209.11795331458833, Neurons: 201, Grad norm: 4.746444339843133\n",
      "Epoch 3718, Loss: 209.11795331458833, Neurons: 201, Grad norm: 4.746444339843133\n",
      "Epoch 3719, Loss: 209.1179682069514, Neurons: 201, Grad norm: 5.586668497829633\n",
      "Epoch 3719, Loss: 209.1179682069514, Neurons: 201, Grad norm: 5.586668497829633\n",
      "Epoch 3720, Loss: 209.11792108480606, Neurons: 201, Grad norm: 5.861657875537939\n",
      "Epoch 3720, Loss: 209.11792108480606, Neurons: 201, Grad norm: 5.861657875537939\n",
      "Epoch 3721, Loss: 209.1177672471814, Neurons: 201, Grad norm: 5.6416154015569075\n",
      "Epoch 3721, Loss: 209.1177672471814, Neurons: 201, Grad norm: 5.6416154015569075\n",
      "Epoch 3722, Loss: 209.11747553927322, Neurons: 201, Grad norm: 4.861753085894629\n",
      "Epoch 3722, Loss: 209.11747553927322, Neurons: 201, Grad norm: 4.861753085894629\n",
      "Epoch 3723, Loss: 209.11713729915505, Neurons: 201, Grad norm: 4.114558287682616\n",
      "Epoch 3723, Loss: 209.11713729915505, Neurons: 201, Grad norm: 4.114558287682616\n",
      "Epoch 3724, Loss: 209.11676161638687, Neurons: 201, Grad norm: 3.0523565964871406\n",
      "Epoch 3724, Loss: 209.11676161638687, Neurons: 201, Grad norm: 3.0523565964871406\n",
      "Epoch 3725, Loss: 209.11640784945715, Neurons: 201, Grad norm: 2.012626647928257\n",
      "Epoch 3725, Loss: 209.11640784945715, Neurons: 201, Grad norm: 2.012626647928257\n",
      "Epoch 3726, Loss: 209.11604783420364, Neurons: 201, Grad norm: 1.179180482842624\n",
      "Epoch 3726, Loss: 209.11604783420364, Neurons: 201, Grad norm: 1.179180482842624\n",
      "Epoch 3727, Loss: 209.11579463717163, Neurons: 201, Grad norm: 0.7951104927203896\n",
      "Epoch 3727, Loss: 209.11579463717163, Neurons: 201, Grad norm: 0.7951104927203896\n",
      "Epoch 3728, Loss: 209.11552502529088, Neurons: 201, Grad norm: 0.6101826340898928\n",
      "Epoch 3728, Loss: 209.11552502529088, Neurons: 201, Grad norm: 0.6101826340898928\n",
      "Epoch 3729, Loss: 209.11528859720394, Neurons: 201, Grad norm: 0.6258988885805932\n",
      "Epoch 3729, Loss: 209.11528859720394, Neurons: 201, Grad norm: 0.6258988885805932\n",
      "Epoch 3730, Loss: 209.11503935259583, Neurons: 201, Grad norm: 0.9105491655540465\n",
      "Epoch 3730, Loss: 209.11503935259583, Neurons: 201, Grad norm: 0.9105491655540465\n",
      "Epoch 3731, Loss: 209.11480348137883, Neurons: 201, Grad norm: 1.5783058280592717\n",
      "Epoch 3731, Loss: 209.11480348137883, Neurons: 201, Grad norm: 1.5783058280592717\n",
      "Epoch 3732, Loss: 209.11468028975764, Neurons: 201, Grad norm: 2.773855455727958\n",
      "Epoch 3732, Loss: 209.11468028975764, Neurons: 201, Grad norm: 2.773855455727958\n",
      "Epoch 3733, Loss: 209.11457535892976, Neurons: 201, Grad norm: 3.347522463283268\n",
      "Epoch 3733, Loss: 209.11457535892976, Neurons: 201, Grad norm: 3.347522463283268\n",
      "Epoch 3734, Loss: 209.11446544813248, Neurons: 201, Grad norm: 4.477744487512639\n",
      "Epoch 3734, Loss: 209.11446544813248, Neurons: 201, Grad norm: 4.477744487512639\n",
      "Epoch 3735, Loss: 209.1143676716028, Neurons: 201, Grad norm: 4.916358477498477\n",
      "Epoch 3735, Loss: 209.1143676716028, Neurons: 201, Grad norm: 4.916358477498477\n",
      "Epoch 3736, Loss: 209.11427270954732, Neurons: 201, Grad norm: 5.416384651712685\n",
      "Epoch 3736, Loss: 209.11427270954732, Neurons: 201, Grad norm: 5.416384651712685\n",
      "Epoch 3737, Loss: 209.1141505993142, Neurons: 201, Grad norm: 5.040564591345162\n",
      "Epoch 3737, Loss: 209.1141505993142, Neurons: 201, Grad norm: 5.040564591345162\n",
      "Epoch 3738, Loss: 209.11387244929017, Neurons: 201, Grad norm: 4.506886762835782\n",
      "Epoch 3738, Loss: 209.11387244929017, Neurons: 201, Grad norm: 4.506886762835782\n",
      "Epoch 3739, Loss: 209.11353378289658, Neurons: 201, Grad norm: 3.195682311887326\n",
      "Epoch 3739, Loss: 209.11353378289658, Neurons: 201, Grad norm: 3.195682311887326\n",
      "Epoch 3740, Loss: 209.1131305301716, Neurons: 201, Grad norm: 2.1762908529114346\n",
      "Epoch 3740, Loss: 209.1131305301716, Neurons: 201, Grad norm: 2.1762908529114346\n",
      "Epoch 3741, Loss: 209.1127964404483, Neurons: 201, Grad norm: 1.103762000123561\n",
      "Epoch 3741, Loss: 209.1127964404483, Neurons: 201, Grad norm: 1.103762000123561\n",
      "Epoch 3742, Loss: 209.11255926439733, Neurons: 201, Grad norm: 0.5632617176087423\n",
      "Epoch 3742, Loss: 209.11255926439733, Neurons: 201, Grad norm: 0.5632617176087423\n",
      "Epoch 3743, Loss: 209.11232470460348, Neurons: 201, Grad norm: 0.9163382028435778\n",
      "Epoch 3743, Loss: 209.11232470460348, Neurons: 201, Grad norm: 0.9163382028435778\n",
      "Epoch 3744, Loss: 209.11209744630906, Neurons: 201, Grad norm: 1.5538892231124366\n",
      "Epoch 3744, Loss: 209.11209744630906, Neurons: 201, Grad norm: 1.5538892231124366\n",
      "Epoch 3745, Loss: 209.11185739510276, Neurons: 201, Grad norm: 2.3189219678421726\n",
      "Epoch 3745, Loss: 209.11185739510276, Neurons: 201, Grad norm: 2.3189219678421726\n",
      "Epoch 3746, Loss: 209.11163717852716, Neurons: 201, Grad norm: 3.221437654452641\n",
      "Epoch 3746, Loss: 209.11163717852716, Neurons: 201, Grad norm: 3.221437654452641\n",
      "Epoch 3747, Loss: 209.11137637970498, Neurons: 201, Grad norm: 4.316399708008127\n",
      "Epoch 3747, Loss: 209.11137637970498, Neurons: 201, Grad norm: 4.316399708008127\n",
      "Epoch 3748, Loss: 209.1110606216389, Neurons: 201, Grad norm: 5.06091700536165\n",
      "Epoch 3748, Loss: 209.1110606216389, Neurons: 201, Grad norm: 5.06091700536165\n",
      "Epoch 3749, Loss: 209.1107189827657, Neurons: 201, Grad norm: 5.9339170816108675\n",
      "Epoch 3749, Loss: 209.1107189827657, Neurons: 201, Grad norm: 5.9339170816108675\n",
      "Epoch 3750, Loss: 209.11018836750134, Neurons: 201, Grad norm: 5.926152641172122\n",
      "Epoch 3750, Loss: 209.11018836750134, Neurons: 201, Grad norm: 5.926152641172122\n",
      "Epoch 3751, Loss: 209.10949924830834, Neurons: 201, Grad norm: 5.741785417902196\n",
      "Epoch 3751, Loss: 209.10949924830834, Neurons: 201, Grad norm: 5.741785417902196\n",
      "Epoch 3752, Loss: 209.10874812056733, Neurons: 201, Grad norm: 4.526387145291441\n",
      "Epoch 3752, Loss: 209.10874812056733, Neurons: 201, Grad norm: 4.526387145291441\n",
      "Epoch 3753, Loss: 209.10805496364148, Neurons: 201, Grad norm: 3.3071012790288354\n",
      "Epoch 3753, Loss: 209.10805496364148, Neurons: 201, Grad norm: 3.3071012790288354\n",
      "Epoch 3754, Loss: 209.10764942834587, Neurons: 201, Grad norm: 1.5418187312418263\n",
      "Epoch 3754, Loss: 209.10764942834587, Neurons: 201, Grad norm: 1.5418187312418263\n",
      "Epoch 3755, Loss: 209.107359721643, Neurons: 201, Grad norm: 0.5866065184829741\n",
      "Epoch 3755, Loss: 209.107359721643, Neurons: 201, Grad norm: 0.5866065184829741\n",
      "Epoch 3756, Loss: 209.10711030219048, Neurons: 201, Grad norm: 1.774091319584773\n",
      "Epoch 3756, Loss: 209.10711030219048, Neurons: 201, Grad norm: 1.774091319584773\n",
      "Epoch 3757, Loss: 209.10689619716203, Neurons: 201, Grad norm: 3.175696104757043\n",
      "Epoch 3757, Loss: 209.10689619716203, Neurons: 201, Grad norm: 3.175696104757043\n",
      "Epoch 3758, Loss: 209.1067897955082, Neurons: 201, Grad norm: 4.682849124257113\n",
      "Epoch 3758, Loss: 209.1067897955082, Neurons: 201, Grad norm: 4.682849124257113\n",
      "Epoch 3759, Loss: 209.10678436954177, Neurons: 201, Grad norm: 5.547790347032516\n",
      "Epoch 3759, Loss: 209.10678436954177, Neurons: 201, Grad norm: 5.547790347032516\n",
      "Epoch 3760, Loss: 209.10676675041424, Neurons: 201, Grad norm: 6.3489695192481665\n",
      "Epoch 3760, Loss: 209.10676675041424, Neurons: 201, Grad norm: 6.3489695192481665\n",
      "Epoch 3761, Loss: 209.1066642700039, Neurons: 201, Grad norm: 6.133647269661483\n",
      "Epoch 3761, Loss: 209.1066642700039, Neurons: 201, Grad norm: 6.133647269661483\n",
      "Epoch 3762, Loss: 209.10640918119537, Neurons: 201, Grad norm: 5.727640009771512\n",
      "Epoch 3762, Loss: 209.10640918119537, Neurons: 201, Grad norm: 5.727640009771512\n",
      "Epoch 3763, Loss: 209.10609600914947, Neurons: 201, Grad norm: 4.191589000456353\n",
      "Epoch 3763, Loss: 209.10609600914947, Neurons: 201, Grad norm: 4.191589000456353\n",
      "Epoch 3764, Loss: 209.10564363456513, Neurons: 201, Grad norm: 2.629821616515686\n",
      "Epoch 3764, Loss: 209.10564363456513, Neurons: 201, Grad norm: 2.629821616515686\n",
      "Epoch 3765, Loss: 209.1053027403753, Neurons: 201, Grad norm: 0.8561390613022744\n",
      "Epoch 3765, Loss: 209.1053027403753, Neurons: 201, Grad norm: 0.8561390613022744\n",
      "Epoch 3766, Loss: 209.1049835051791, Neurons: 201, Grad norm: 1.5506051286906257\n",
      "Epoch 3766, Loss: 209.1049835051791, Neurons: 201, Grad norm: 1.5506051286906257\n",
      "Epoch 3767, Loss: 209.1047045309051, Neurons: 201, Grad norm: 3.422286517217686\n",
      "Epoch 3767, Loss: 209.1047045309051, Neurons: 201, Grad norm: 3.422286517217686\n",
      "Epoch 3768, Loss: 209.10461712280784, Neurons: 201, Grad norm: 4.852297897342528\n",
      "Epoch 3768, Loss: 209.10461712280784, Neurons: 201, Grad norm: 4.852297897342528\n",
      "Epoch 3769, Loss: 209.10467214601601, Neurons: 201, Grad norm: 5.751890381517114\n",
      "Epoch 3769, Loss: 209.10467214601601, Neurons: 201, Grad norm: 5.751890381517114\n",
      "Epoch 3770, Loss: 209.10465106380306, Neurons: 201, Grad norm: 5.898256795314635\n",
      "Epoch 3770, Loss: 209.10465106380306, Neurons: 201, Grad norm: 5.898256795314635\n",
      "Epoch 3771, Loss: 209.10443195774326, Neurons: 201, Grad norm: 5.407878710479778\n",
      "Epoch 3771, Loss: 209.10443195774326, Neurons: 201, Grad norm: 5.407878710479778\n",
      "Epoch 3772, Loss: 209.10414688658844, Neurons: 201, Grad norm: 4.0335381076927375\n",
      "Epoch 3772, Loss: 209.10414688658844, Neurons: 201, Grad norm: 4.0335381076927375\n",
      "Epoch 3773, Loss: 209.10367209094375, Neurons: 201, Grad norm: 2.536643520294191\n",
      "Epoch 3773, Loss: 209.10367209094375, Neurons: 201, Grad norm: 2.536643520294191\n",
      "Epoch 3774, Loss: 209.10328133489173, Neurons: 201, Grad norm: 0.7091434678237883\n",
      "Epoch 3774, Loss: 209.10328133489173, Neurons: 201, Grad norm: 0.7091434678237883\n",
      "Epoch 3775, Loss: 209.1029475710145, Neurons: 201, Grad norm: 1.2020901632038559\n",
      "Epoch 3775, Loss: 209.1029475710145, Neurons: 201, Grad norm: 1.2020901632038559\n",
      "Epoch 3776, Loss: 209.10274572179875, Neurons: 201, Grad norm: 2.8687891792361886\n",
      "Epoch 3776, Loss: 209.10274572179875, Neurons: 201, Grad norm: 2.8687891792361886\n",
      "Epoch 3777, Loss: 209.1026256435843, Neurons: 201, Grad norm: 3.7064702993706433\n",
      "Epoch 3777, Loss: 209.1026256435843, Neurons: 201, Grad norm: 3.7064702993706433\n",
      "Epoch 3778, Loss: 209.10253226661308, Neurons: 201, Grad norm: 4.6624191295522746\n",
      "Epoch 3778, Loss: 209.10253226661308, Neurons: 201, Grad norm: 4.6624191295522746\n",
      "Epoch 3779, Loss: 209.10243266884717, Neurons: 201, Grad norm: 4.722243905106926\n",
      "Epoch 3779, Loss: 209.10243266884717, Neurons: 201, Grad norm: 4.722243905106926\n",
      "Epoch 3780, Loss: 209.10226484664517, Neurons: 201, Grad norm: 4.3337446719152535\n",
      "Epoch 3780, Loss: 209.10226484664517, Neurons: 201, Grad norm: 4.3337446719152535\n",
      "Epoch 3781, Loss: 209.10194234538838, Neurons: 201, Grad norm: 3.4285666278857883\n",
      "Epoch 3781, Loss: 209.10194234538838, Neurons: 201, Grad norm: 3.4285666278857883\n",
      "Epoch 3782, Loss: 209.1016379457346, Neurons: 201, Grad norm: 2.435319088015255\n",
      "Epoch 3782, Loss: 209.1016379457346, Neurons: 201, Grad norm: 2.435319088015255\n",
      "Epoch 3783, Loss: 209.1012509024438, Neurons: 201, Grad norm: 1.6146963633272802\n",
      "Epoch 3783, Loss: 209.1012509024438, Neurons: 201, Grad norm: 1.6146963633272802\n",
      "Epoch 3784, Loss: 209.10099438657724, Neurons: 201, Grad norm: 1.0628753772104114\n",
      "Epoch 3784, Loss: 209.10099438657724, Neurons: 201, Grad norm: 1.0628753772104114\n",
      "Epoch 3785, Loss: 209.10074353709075, Neurons: 201, Grad norm: 0.6080778468427823\n",
      "Epoch 3785, Loss: 209.10074353709075, Neurons: 201, Grad norm: 0.6080778468427823\n",
      "Epoch 3786, Loss: 209.10052039031586, Neurons: 201, Grad norm: 0.6795882546993443\n",
      "Epoch 3786, Loss: 209.10052039031586, Neurons: 201, Grad norm: 0.6795882546993443\n",
      "Epoch 3787, Loss: 209.10029588485494, Neurons: 201, Grad norm: 0.7331027744132499\n",
      "Epoch 3787, Loss: 209.10029588485494, Neurons: 201, Grad norm: 0.7331027744132499\n",
      "Epoch 3788, Loss: 209.10007663845226, Neurons: 201, Grad norm: 0.6994418416893311\n",
      "Epoch 3788, Loss: 209.10007663845226, Neurons: 201, Grad norm: 0.6994418416893311\n",
      "Epoch 3789, Loss: 209.09984855027918, Neurons: 201, Grad norm: 0.684162880278553\n",
      "Epoch 3789, Loss: 209.09984855027918, Neurons: 201, Grad norm: 0.684162880278553\n",
      "Epoch 3790, Loss: 209.0996000843518, Neurons: 201, Grad norm: 0.6645790792009963\n",
      "Epoch 3790, Loss: 209.0996000843518, Neurons: 201, Grad norm: 0.6645790792009963\n",
      "Epoch 3791, Loss: 209.09936204385872, Neurons: 201, Grad norm: 0.5313688942416898\n",
      "Epoch 3791, Loss: 209.09936204385872, Neurons: 201, Grad norm: 0.5313688942416898\n",
      "Epoch 3792, Loss: 209.09912279722622, Neurons: 201, Grad norm: 0.5245351943555905\n",
      "Epoch 3792, Loss: 209.09912279722622, Neurons: 201, Grad norm: 0.5245351943555905\n",
      "Epoch 3793, Loss: 209.098891873994, Neurons: 201, Grad norm: 0.7287179641084407\n",
      "Epoch 3793, Loss: 209.098891873994, Neurons: 201, Grad norm: 0.7287179641084407\n",
      "Epoch 3794, Loss: 209.09867082174316, Neurons: 201, Grad norm: 0.7899114031988613\n",
      "Epoch 3794, Loss: 209.09867082174316, Neurons: 201, Grad norm: 0.7899114031988613\n",
      "Epoch 3795, Loss: 209.09846706847188, Neurons: 201, Grad norm: 1.1882226675694014\n",
      "Epoch 3795, Loss: 209.09846706847188, Neurons: 201, Grad norm: 1.1882226675694014\n",
      "Epoch 3796, Loss: 209.09826840018414, Neurons: 201, Grad norm: 1.3690805342094376\n",
      "Epoch 3796, Loss: 209.09826840018414, Neurons: 201, Grad norm: 1.3690805342094376\n",
      "Epoch 3797, Loss: 209.09807852901983, Neurons: 201, Grad norm: 1.7247883433029436\n",
      "Epoch 3797, Loss: 209.09807852901983, Neurons: 201, Grad norm: 1.7247883433029436\n",
      "Epoch 3798, Loss: 209.09788497777856, Neurons: 201, Grad norm: 1.6480456550317402\n",
      "Epoch 3798, Loss: 209.09788497777856, Neurons: 201, Grad norm: 1.6480456550317402\n",
      "Epoch 3799, Loss: 209.09769354496612, Neurons: 201, Grad norm: 1.7052015456731189\n",
      "Epoch 3799, Loss: 209.09769354496612, Neurons: 201, Grad norm: 1.7052015456731189\n",
      "Epoch 3800, Loss: 209.09749281401488, Neurons: 201, Grad norm: 1.6916166300303743\n",
      "Epoch 3800, Loss: 209.09749281401488, Neurons: 201, Grad norm: 1.6916166300303743\n",
      "Epoch 3801, Loss: 209.09727451571072, Neurons: 201, Grad norm: 1.7745305858155325\n",
      "Epoch 3801, Loss: 209.09727451571072, Neurons: 201, Grad norm: 1.7745305858155325\n",
      "Epoch 3802, Loss: 209.09704505354657, Neurons: 201, Grad norm: 1.6646445690090912\n",
      "Epoch 3802, Loss: 209.09704505354657, Neurons: 201, Grad norm: 1.6646445690090912\n",
      "Epoch 3803, Loss: 209.09682047684842, Neurons: 201, Grad norm: 2.0406450119040693\n",
      "Epoch 3803, Loss: 209.09682047684842, Neurons: 201, Grad norm: 2.0406450119040693\n",
      "Epoch 3804, Loss: 209.09664546184737, Neurons: 201, Grad norm: 2.1359849510271953\n",
      "Epoch 3804, Loss: 209.09664546184737, Neurons: 201, Grad norm: 2.1359849510271953\n",
      "Epoch 3805, Loss: 209.09645488263445, Neurons: 201, Grad norm: 2.4682339257538617\n",
      "Epoch 3805, Loss: 209.09645488263445, Neurons: 201, Grad norm: 2.4682339257538617\n",
      "Epoch 3806, Loss: 209.09628774114228, Neurons: 201, Grad norm: 2.3364257300577753\n",
      "Epoch 3806, Loss: 209.09628774114228, Neurons: 201, Grad norm: 2.3364257300577753\n",
      "Epoch 3807, Loss: 209.09606084393596, Neurons: 201, Grad norm: 2.4243303914658356\n",
      "Epoch 3807, Loss: 209.09606084393596, Neurons: 201, Grad norm: 2.4243303914658356\n",
      "Epoch 3808, Loss: 209.09584117488117, Neurons: 201, Grad norm: 2.5235807387855367\n",
      "Epoch 3808, Loss: 209.09584117488117, Neurons: 201, Grad norm: 2.5235807387855367\n",
      "Epoch 3809, Loss: 209.0956256432199, Neurons: 201, Grad norm: 3.032144246493873\n",
      "Epoch 3809, Loss: 209.0956256432199, Neurons: 201, Grad norm: 3.032144246493873\n",
      "Epoch 3810, Loss: 209.09547012634164, Neurons: 201, Grad norm: 3.271038556418085\n",
      "Epoch 3810, Loss: 209.09547012634164, Neurons: 201, Grad norm: 3.271038556418085\n",
      "Epoch 3811, Loss: 209.09536293334455, Neurons: 201, Grad norm: 3.803051751532822\n",
      "Epoch 3811, Loss: 209.09536293334455, Neurons: 201, Grad norm: 3.803051751532822\n",
      "Epoch 3812, Loss: 209.0951523944751, Neurons: 201, Grad norm: 3.8968704556509755\n",
      "Epoch 3812, Loss: 209.0951523944751, Neurons: 201, Grad norm: 3.8968704556509755\n",
      "Epoch 3813, Loss: 209.09500341166267, Neurons: 201, Grad norm: 4.127435545141413\n",
      "Epoch 3813, Loss: 209.09500341166267, Neurons: 201, Grad norm: 4.127435545141413\n",
      "Epoch 3814, Loss: 209.09482412859813, Neurons: 201, Grad norm: 4.021782286855485\n",
      "Epoch 3814, Loss: 209.09482412859813, Neurons: 201, Grad norm: 4.021782286855485\n",
      "Epoch 3815, Loss: 209.09461077205114, Neurons: 201, Grad norm: 4.075727981370971\n",
      "Epoch 3815, Loss: 209.09461077205114, Neurons: 201, Grad norm: 4.075727981370971\n",
      "Epoch 3816, Loss: 209.0944097621894, Neurons: 201, Grad norm: 3.8881813228249817\n",
      "Epoch 3816, Loss: 209.0944097621894, Neurons: 201, Grad norm: 3.8881813228249817\n",
      "Epoch 3817, Loss: 209.0941510955303, Neurons: 201, Grad norm: 3.8782135377254217\n",
      "Epoch 3817, Loss: 209.0941510955303, Neurons: 201, Grad norm: 3.8782135377254217\n",
      "Epoch 3818, Loss: 209.09396956817048, Neurons: 201, Grad norm: 3.6267290559493337\n",
      "Epoch 3818, Loss: 209.09396956817048, Neurons: 201, Grad norm: 3.6267290559493337\n",
      "Epoch 3819, Loss: 209.09372901832123, Neurons: 201, Grad norm: 3.6901733188153503\n",
      "Epoch 3819, Loss: 209.09372901832123, Neurons: 201, Grad norm: 3.6901733188153503\n",
      "Epoch 3820, Loss: 209.09349842176042, Neurons: 201, Grad norm: 3.5322924104509994\n",
      "Epoch 3820, Loss: 209.09349842176042, Neurons: 201, Grad norm: 3.5322924104509994\n",
      "Epoch 3821, Loss: 209.0932699015081, Neurons: 201, Grad norm: 3.7208572883275406\n",
      "Epoch 3821, Loss: 209.0932699015081, Neurons: 201, Grad norm: 3.7208572883275406\n",
      "Epoch 3822, Loss: 209.09309271357185, Neurons: 201, Grad norm: 3.504176880116305\n",
      "Epoch 3822, Loss: 209.09309271357185, Neurons: 201, Grad norm: 3.504176880116305\n",
      "Epoch 3823, Loss: 209.0928964947225, Neurons: 201, Grad norm: 3.1803409817879373\n",
      "Epoch 3823, Loss: 209.0928964947225, Neurons: 201, Grad norm: 3.1803409817879373\n",
      "Epoch 3824, Loss: 209.09263122062245, Neurons: 201, Grad norm: 2.535163440758174\n",
      "Epoch 3824, Loss: 209.09263122062245, Neurons: 201, Grad norm: 2.535163440758174\n",
      "Epoch 3825, Loss: 209.09235385799474, Neurons: 201, Grad norm: 2.1468124810862066\n",
      "Epoch 3825, Loss: 209.09235385799474, Neurons: 201, Grad norm: 2.1468124810862066\n",
      "Epoch 3826, Loss: 209.09211143826943, Neurons: 201, Grad norm: 1.5559814764145932\n",
      "Epoch 3826, Loss: 209.09211143826943, Neurons: 201, Grad norm: 1.5559814764145932\n",
      "Epoch 3827, Loss: 209.0918889218882, Neurons: 201, Grad norm: 1.312336150370947\n",
      "Epoch 3827, Loss: 209.0918889218882, Neurons: 201, Grad norm: 1.312336150370947\n",
      "Epoch 3828, Loss: 209.0916539243833, Neurons: 201, Grad norm: 1.019533943482916\n",
      "Epoch 3828, Loss: 209.0916539243833, Neurons: 201, Grad norm: 1.019533943482916\n",
      "Epoch 3829, Loss: 209.09144761110116, Neurons: 201, Grad norm: 1.1476303503752747\n",
      "Epoch 3829, Loss: 209.09144761110116, Neurons: 201, Grad norm: 1.1476303503752747\n",
      "Epoch 3830, Loss: 209.09124563680874, Neurons: 201, Grad norm: 1.250368795341758\n",
      "Epoch 3830, Loss: 209.09124563680874, Neurons: 201, Grad norm: 1.250368795341758\n",
      "Epoch 3831, Loss: 209.09103465162354, Neurons: 201, Grad norm: 1.4660644904012075\n",
      "Epoch 3831, Loss: 209.09103465162354, Neurons: 201, Grad norm: 1.4660644904012075\n",
      "Epoch 3832, Loss: 209.0908485598806, Neurons: 201, Grad norm: 1.6760634054164463\n",
      "Epoch 3832, Loss: 209.0908485598806, Neurons: 201, Grad norm: 1.6760634054164463\n",
      "Epoch 3833, Loss: 209.09066772202564, Neurons: 201, Grad norm: 2.3104710818404786\n",
      "Epoch 3833, Loss: 209.09066772202564, Neurons: 201, Grad norm: 2.3104710818404786\n",
      "Epoch 3834, Loss: 209.09049699536857, Neurons: 201, Grad norm: 2.9126941637411803\n",
      "Epoch 3834, Loss: 209.09049699536857, Neurons: 201, Grad norm: 2.9126941637411803\n",
      "Epoch 3835, Loss: 209.09035662549616, Neurons: 201, Grad norm: 3.967826888062222\n",
      "Epoch 3835, Loss: 209.09035662549616, Neurons: 201, Grad norm: 3.967826888062222\n",
      "Epoch 3836, Loss: 209.09026198471383, Neurons: 201, Grad norm: 4.9581565219452886\n",
      "Epoch 3836, Loss: 209.09026198471383, Neurons: 201, Grad norm: 4.9581565219452886\n",
      "Epoch 3837, Loss: 209.0902571650814, Neurons: 201, Grad norm: 6.23020677301969\n",
      "Epoch 3837, Loss: 209.0902571650814, Neurons: 201, Grad norm: 6.23020677301969\n",
      "Epoch 3838, Loss: 209.09028742905616, Neurons: 201, Grad norm: 6.9715993240103975\n",
      "Epoch 3838, Loss: 209.09028742905616, Neurons: 201, Grad norm: 6.9715993240103975\n",
      "Epoch 3839, Loss: 209.09029361294827, Neurons: 201, Grad norm: 7.4837822902304305\n",
      "Epoch 3839, Loss: 209.09029361294827, Neurons: 201, Grad norm: 7.4837822902304305\n",
      "Epoch 3840, Loss: 209.0902365305117, Neurons: 201, Grad norm: 7.140969975574245\n",
      "Epoch 3840, Loss: 209.0902365305117, Neurons: 201, Grad norm: 7.140969975574245\n",
      "Epoch 3841, Loss: 209.08995295742875, Neurons: 201, Grad norm: 6.600645808663881\n",
      "Epoch 3841, Loss: 209.08995295742875, Neurons: 201, Grad norm: 6.600645808663881\n",
      "Epoch 3842, Loss: 209.08959101005328, Neurons: 201, Grad norm: 5.249557574939382\n",
      "Epoch 3842, Loss: 209.08959101005328, Neurons: 201, Grad norm: 5.249557574939382\n",
      "Epoch 3843, Loss: 209.0891033975042, Neurons: 201, Grad norm: 3.9749412818343193\n",
      "Epoch 3843, Loss: 209.0891033975042, Neurons: 201, Grad norm: 3.9749412818343193\n",
      "Epoch 3844, Loss: 209.0887069658223, Neurons: 201, Grad norm: 2.4575602170661117\n",
      "Epoch 3844, Loss: 209.0887069658223, Neurons: 201, Grad norm: 2.4575602170661117\n",
      "Epoch 3845, Loss: 209.08830168658025, Neurons: 201, Grad norm: 1.0848030932339792\n",
      "Epoch 3845, Loss: 209.08830168658025, Neurons: 201, Grad norm: 1.0848030932339792\n",
      "Epoch 3846, Loss: 209.0880198588359, Neurons: 201, Grad norm: 0.7763939928551349\n",
      "Epoch 3846, Loss: 209.0880198588359, Neurons: 201, Grad norm: 0.7763939928551349\n",
      "Epoch 3847, Loss: 209.08780651557606, Neurons: 201, Grad norm: 1.6300309008903477\n",
      "Epoch 3847, Loss: 209.08780651557606, Neurons: 201, Grad norm: 1.6300309008903477\n",
      "Epoch 3848, Loss: 209.0876524386264, Neurons: 201, Grad norm: 3.094731320973512\n",
      "Epoch 3848, Loss: 209.0876524386264, Neurons: 201, Grad norm: 3.094731320973512\n",
      "Epoch 3849, Loss: 209.087570046918, Neurons: 201, Grad norm: 4.250373440179827\n",
      "Epoch 3849, Loss: 209.087570046918, Neurons: 201, Grad norm: 4.250373440179827\n",
      "Epoch 3850, Loss: 209.08756264685147, Neurons: 201, Grad norm: 5.344590531974343\n",
      "Epoch 3850, Loss: 209.08756264685147, Neurons: 201, Grad norm: 5.344590531974343\n",
      "Epoch 3851, Loss: 209.08752825588178, Neurons: 201, Grad norm: 5.853993001119309\n",
      "Epoch 3851, Loss: 209.08752825588178, Neurons: 201, Grad norm: 5.853993001119309\n",
      "Epoch 3852, Loss: 209.08747801822358, Neurons: 201, Grad norm: 6.1458372720592225\n",
      "Epoch 3852, Loss: 209.08747801822358, Neurons: 201, Grad norm: 6.1458372720592225\n",
      "Epoch 3853, Loss: 209.08730806788017, Neurons: 201, Grad norm: 5.82094552534349\n",
      "Epoch 3853, Loss: 209.08730806788017, Neurons: 201, Grad norm: 5.82094552534349\n",
      "Epoch 3854, Loss: 209.08707178184045, Neurons: 201, Grad norm: 5.190763953348608\n",
      "Epoch 3854, Loss: 209.08707178184045, Neurons: 201, Grad norm: 5.190763953348608\n",
      "Epoch 3855, Loss: 209.0867030016706, Neurons: 201, Grad norm: 3.97764151007094\n",
      "Epoch 3855, Loss: 209.0867030016706, Neurons: 201, Grad norm: 3.97764151007094\n",
      "Epoch 3856, Loss: 209.0863313638639, Neurons: 201, Grad norm: 2.9030383454582362\n",
      "Epoch 3856, Loss: 209.0863313638639, Neurons: 201, Grad norm: 2.9030383454582362\n",
      "Epoch 3857, Loss: 209.08595769850731, Neurons: 201, Grad norm: 1.7810607014190118\n",
      "Epoch 3857, Loss: 209.08595769850731, Neurons: 201, Grad norm: 1.7810607014190118\n",
      "Epoch 3858, Loss: 209.0856969013842, Neurons: 201, Grad norm: 0.9831825274049075\n",
      "Epoch 3858, Loss: 209.0856969013842, Neurons: 201, Grad norm: 0.9831825274049075\n",
      "Epoch 3859, Loss: 209.085466710607, Neurons: 201, Grad norm: 0.5809836499415263\n",
      "Epoch 3859, Loss: 209.085466710607, Neurons: 201, Grad norm: 0.5809836499415263\n",
      "Epoch 3860, Loss: 209.08523939595608, Neurons: 201, Grad norm: 0.9806431291128805\n",
      "Epoch 3860, Loss: 209.08523939595608, Neurons: 201, Grad norm: 0.9806431291128805\n",
      "Epoch 3861, Loss: 209.08507391965418, Neurons: 201, Grad norm: 1.7393363029833524\n",
      "Epoch 3861, Loss: 209.08507391965418, Neurons: 201, Grad norm: 1.7393363029833524\n",
      "Epoch 3862, Loss: 209.08487707489073, Neurons: 201, Grad norm: 2.390840605202898\n",
      "Epoch 3862, Loss: 209.08487707489073, Neurons: 201, Grad norm: 2.390840605202898\n",
      "Epoch 3863, Loss: 209.08476447227216, Neurons: 201, Grad norm: 3.103655035562319\n",
      "Epoch 3863, Loss: 209.08476447227216, Neurons: 201, Grad norm: 3.103655035562319\n",
      "Epoch 3864, Loss: 209.08461677272243, Neurons: 201, Grad norm: 3.6227355535331967\n",
      "Epoch 3864, Loss: 209.08461677272243, Neurons: 201, Grad norm: 3.6227355535331967\n",
      "Epoch 3865, Loss: 209.08449120196136, Neurons: 201, Grad norm: 4.152581431431403\n",
      "Epoch 3865, Loss: 209.08449120196136, Neurons: 201, Grad norm: 4.152581431431403\n",
      "Epoch 3866, Loss: 209.08439936907521, Neurons: 201, Grad norm: 4.500811668080363\n",
      "Epoch 3866, Loss: 209.08439936907521, Neurons: 201, Grad norm: 4.500811668080363\n",
      "Epoch 3867, Loss: 209.0842350297097, Neurons: 201, Grad norm: 4.743821014320409\n",
      "Epoch 3867, Loss: 209.0842350297097, Neurons: 201, Grad norm: 4.743821014320409\n",
      "Epoch 3868, Loss: 209.08409021093652, Neurons: 201, Grad norm: 4.656554094107578\n",
      "Epoch 3868, Loss: 209.08409021093652, Neurons: 201, Grad norm: 4.656554094107578\n",
      "Epoch 3869, Loss: 209.08388865821084, Neurons: 201, Grad norm: 4.697553837286322\n",
      "Epoch 3869, Loss: 209.08388865821084, Neurons: 201, Grad norm: 4.697553837286322\n",
      "Epoch 3870, Loss: 209.08369085563805, Neurons: 201, Grad norm: 4.057719795250296\n",
      "Epoch 3870, Loss: 209.08369085563805, Neurons: 201, Grad norm: 4.057719795250296\n",
      "Epoch 3871, Loss: 209.08341710858818, Neurons: 201, Grad norm: 3.9308666985469096\n",
      "Epoch 3871, Loss: 209.08341710858818, Neurons: 201, Grad norm: 3.9308666985469096\n",
      "Epoch 3872, Loss: 209.0831667210875, Neurons: 201, Grad norm: 3.324534519402344\n",
      "Epoch 3872, Loss: 209.0831667210875, Neurons: 201, Grad norm: 3.324534519402344\n",
      "Epoch 3873, Loss: 209.08289633669014, Neurons: 201, Grad norm: 2.914336862931402\n",
      "Epoch 3873, Loss: 209.08289633669014, Neurons: 201, Grad norm: 2.914336862931402\n",
      "Epoch 3874, Loss: 209.08267077880822, Neurons: 201, Grad norm: 2.6539545063150145\n",
      "Epoch 3874, Loss: 209.08267077880822, Neurons: 201, Grad norm: 2.6539545063150145\n",
      "Epoch 3875, Loss: 209.08245155735887, Neurons: 201, Grad norm: 2.5683140146246224\n",
      "Epoch 3875, Loss: 209.08245155735887, Neurons: 201, Grad norm: 2.5683140146246224\n",
      "Epoch 3876, Loss: 209.08225214974775, Neurons: 201, Grad norm: 2.6711613842795234\n",
      "Epoch 3876, Loss: 209.08225214974775, Neurons: 201, Grad norm: 2.6711613842795234\n",
      "Epoch 3877, Loss: 209.08206822076133, Neurons: 201, Grad norm: 3.085601894018177\n",
      "Epoch 3877, Loss: 209.08206822076133, Neurons: 201, Grad norm: 3.085601894018177\n",
      "Epoch 3878, Loss: 209.08190523299888, Neurons: 201, Grad norm: 3.3359056877955973\n",
      "Epoch 3878, Loss: 209.08190523299888, Neurons: 201, Grad norm: 3.3359056877955973\n",
      "Epoch 3879, Loss: 209.0817856599145, Neurons: 201, Grad norm: 4.2762276964733985\n",
      "Epoch 3879, Loss: 209.0817856599145, Neurons: 201, Grad norm: 4.2762276964733985\n",
      "Epoch 3880, Loss: 209.0816944051925, Neurons: 201, Grad norm: 4.591226641056582\n",
      "Epoch 3880, Loss: 209.0816944051925, Neurons: 201, Grad norm: 4.591226641056582\n",
      "Epoch 3881, Loss: 209.08160302126186, Neurons: 201, Grad norm: 5.248991844752049\n",
      "Epoch 3881, Loss: 209.08160302126186, Neurons: 201, Grad norm: 5.248991844752049\n",
      "Epoch 3882, Loss: 209.08148411826673, Neurons: 201, Grad norm: 5.462248014633749\n",
      "Epoch 3882, Loss: 209.08148411826673, Neurons: 201, Grad norm: 5.462248014633749\n",
      "Epoch 3883, Loss: 209.08134982205152, Neurons: 201, Grad norm: 5.424686374075802\n",
      "Epoch 3883, Loss: 209.08134982205152, Neurons: 201, Grad norm: 5.424686374075802\n",
      "Epoch 3884, Loss: 209.08117295329095, Neurons: 201, Grad norm: 4.930079281622878\n",
      "Epoch 3884, Loss: 209.08117295329095, Neurons: 201, Grad norm: 4.930079281622878\n",
      "Epoch 3885, Loss: 209.08092001008183, Neurons: 201, Grad norm: 4.142678623389425\n",
      "Epoch 3885, Loss: 209.08092001008183, Neurons: 201, Grad norm: 4.142678623389425\n",
      "Epoch 3886, Loss: 209.08057051112266, Neurons: 201, Grad norm: 2.8872524389227547\n",
      "Epoch 3886, Loss: 209.08057051112266, Neurons: 201, Grad norm: 2.8872524389227547\n",
      "Epoch 3887, Loss: 209.0802235592379, Neurons: 201, Grad norm: 1.7563984988681474\n",
      "Epoch 3887, Loss: 209.0802235592379, Neurons: 201, Grad norm: 1.7563984988681474\n",
      "Epoch 3888, Loss: 209.07994930302624, Neurons: 201, Grad norm: 0.7427955319307601\n",
      "Epoch 3888, Loss: 209.07994930302624, Neurons: 201, Grad norm: 0.7427955319307601\n",
      "Epoch 3889, Loss: 209.0797062970459, Neurons: 201, Grad norm: 0.7256091287026681\n",
      "Epoch 3889, Loss: 209.0797062970459, Neurons: 201, Grad norm: 0.7256091287026681\n",
      "Epoch 3890, Loss: 209.07950816957526, Neurons: 201, Grad norm: 1.6637684891850502\n",
      "Epoch 3890, Loss: 209.07950816957526, Neurons: 201, Grad norm: 1.6637684891850502\n",
      "Epoch 3891, Loss: 209.07935477066906, Neurons: 201, Grad norm: 2.4717646053780675\n",
      "Epoch 3891, Loss: 209.07935477066906, Neurons: 201, Grad norm: 2.4717646053780675\n",
      "Epoch 3892, Loss: 209.07923472137733, Neurons: 201, Grad norm: 3.88377766334798\n",
      "Epoch 3892, Loss: 209.07923472137733, Neurons: 201, Grad norm: 3.88377766334798\n",
      "Epoch 3893, Loss: 209.07918685218314, Neurons: 201, Grad norm: 4.913703779365919\n",
      "Epoch 3893, Loss: 209.07918685218314, Neurons: 201, Grad norm: 4.913703779365919\n",
      "Epoch 3894, Loss: 209.07919274238452, Neurons: 201, Grad norm: 5.91053661245915\n",
      "Epoch 3894, Loss: 209.07919274238452, Neurons: 201, Grad norm: 5.91053661245915\n",
      "Epoch 3895, Loss: 209.07918015476295, Neurons: 201, Grad norm: 6.178336982778756\n",
      "Epoch 3895, Loss: 209.07918015476295, Neurons: 201, Grad norm: 6.178336982778756\n",
      "Epoch 3896, Loss: 209.07907784627167, Neurons: 201, Grad norm: 6.034601429376146\n",
      "Epoch 3896, Loss: 209.07907784627167, Neurons: 201, Grad norm: 6.034601429376146\n",
      "Epoch 3897, Loss: 209.07884466386827, Neurons: 201, Grad norm: 5.284375151613801\n",
      "Epoch 3897, Loss: 209.07884466386827, Neurons: 201, Grad norm: 5.284375151613801\n",
      "Epoch 3898, Loss: 209.07852192835557, Neurons: 201, Grad norm: 4.294074416330923\n",
      "Epoch 3898, Loss: 209.07852192835557, Neurons: 201, Grad norm: 4.294074416330923\n",
      "Epoch 3899, Loss: 209.07812972117196, Neurons: 201, Grad norm: 2.9924918484710057\n",
      "Epoch 3899, Loss: 209.07812972117196, Neurons: 201, Grad norm: 2.9924918484710057\n",
      "Epoch 3900, Loss: 209.0777982807309, Neurons: 201, Grad norm: 2.04711353823274\n",
      "Epoch 3900, Loss: 209.0777982807309, Neurons: 201, Grad norm: 2.04711353823274\n",
      "Epoch 3901, Loss: 209.07750062156038, Neurons: 201, Grad norm: 0.9147016123919066\n",
      "Epoch 3901, Loss: 209.07750062156038, Neurons: 201, Grad norm: 0.9147016123919066\n",
      "Epoch 3902, Loss: 209.0772744318288, Neurons: 201, Grad norm: 0.49153716022393024\n",
      "Epoch 3902, Loss: 209.0772744318288, Neurons: 201, Grad norm: 0.49153716022393024\n",
      "Epoch 3903, Loss: 209.0770628474255, Neurons: 201, Grad norm: 1.0790715913828086\n",
      "Epoch 3903, Loss: 209.0770628474255, Neurons: 201, Grad norm: 1.0790715913828086\n",
      "Epoch 3904, Loss: 209.07690703075684, Neurons: 201, Grad norm: 1.8706234382279705\n",
      "Epoch 3904, Loss: 209.07690703075684, Neurons: 201, Grad norm: 1.8706234382279705\n",
      "Epoch 3905, Loss: 209.07674627147588, Neurons: 201, Grad norm: 2.9258549909944165\n",
      "Epoch 3905, Loss: 209.07674627147588, Neurons: 201, Grad norm: 2.9258549909944165\n",
      "Epoch 3906, Loss: 209.07666814320564, Neurons: 201, Grad norm: 3.7532139718737527\n",
      "Epoch 3906, Loss: 209.07666814320564, Neurons: 201, Grad norm: 3.7532139718737527\n",
      "Epoch 3907, Loss: 209.07659237609323, Neurons: 201, Grad norm: 4.870577354476333\n",
      "Epoch 3907, Loss: 209.07659237609323, Neurons: 201, Grad norm: 4.870577354476333\n",
      "Epoch 3908, Loss: 209.0765351135753, Neurons: 201, Grad norm: 5.459930923255107\n",
      "Epoch 3908, Loss: 209.0765351135753, Neurons: 201, Grad norm: 5.459930923255107\n",
      "Epoch 3909, Loss: 209.0765174389409, Neurons: 201, Grad norm: 6.1468003249193215\n",
      "Epoch 3909, Loss: 209.0765174389409, Neurons: 201, Grad norm: 6.1468003249193215\n",
      "Epoch 3910, Loss: 209.0764476333162, Neurons: 201, Grad norm: 5.975010216600503\n",
      "Epoch 3910, Loss: 209.0764476333162, Neurons: 201, Grad norm: 5.975010216600503\n",
      "Epoch 3911, Loss: 209.07626380414277, Neurons: 201, Grad norm: 5.55896217601206\n",
      "Epoch 3911, Loss: 209.07626380414277, Neurons: 201, Grad norm: 5.55896217601206\n",
      "Epoch 3912, Loss: 209.0759789276374, Neurons: 201, Grad norm: 4.597356945966873\n",
      "Epoch 3912, Loss: 209.0759789276374, Neurons: 201, Grad norm: 4.597356945966873\n",
      "Epoch 3913, Loss: 209.07561263710906, Neurons: 201, Grad norm: 3.5809402248573323\n",
      "Epoch 3913, Loss: 209.07561263710906, Neurons: 201, Grad norm: 3.5809402248573323\n",
      "Epoch 3914, Loss: 209.07528773923676, Neurons: 201, Grad norm: 2.368384342516399\n",
      "Epoch 3914, Loss: 209.07528773923676, Neurons: 201, Grad norm: 2.368384342516399\n",
      "Epoch 3915, Loss: 209.07497424108143, Neurons: 201, Grad norm: 1.292903746098225\n",
      "Epoch 3915, Loss: 209.07497424108143, Neurons: 201, Grad norm: 1.292903746098225\n",
      "Epoch 3916, Loss: 209.07471920736603, Neurons: 201, Grad norm: 0.45392473424755586\n",
      "Epoch 3916, Loss: 209.07471920736603, Neurons: 201, Grad norm: 0.45392473424755586\n",
      "Epoch 3917, Loss: 209.0745075389348, Neurons: 201, Grad norm: 1.3698045455528893\n",
      "Epoch 3917, Loss: 209.0745075389348, Neurons: 201, Grad norm: 1.3698045455528893\n",
      "Epoch 3918, Loss: 209.0743587718248, Neurons: 201, Grad norm: 2.9436984259917094\n",
      "Epoch 3918, Loss: 209.0743587718248, Neurons: 201, Grad norm: 2.9436984259917094\n",
      "Epoch 3919, Loss: 209.07428172497177, Neurons: 201, Grad norm: 4.096875102061459\n",
      "Epoch 3919, Loss: 209.07428172497177, Neurons: 201, Grad norm: 4.096875102061459\n",
      "Epoch 3920, Loss: 209.07429417392743, Neurons: 201, Grad norm: 5.351924452364661\n",
      "Epoch 3920, Loss: 209.07429417392743, Neurons: 201, Grad norm: 5.351924452364661\n",
      "Epoch 3921, Loss: 209.07428834769058, Neurons: 201, Grad norm: 5.700101932979209\n",
      "Epoch 3921, Loss: 209.07428834769058, Neurons: 201, Grad norm: 5.700101932979209\n",
      "Epoch 3922, Loss: 209.0742199011609, Neurons: 201, Grad norm: 5.961725919891582\n",
      "Epoch 3922, Loss: 209.0742199011609, Neurons: 201, Grad norm: 5.961725919891582\n",
      "Epoch 3923, Loss: 209.07401865588776, Neurons: 201, Grad norm: 5.4233338863019895\n",
      "Epoch 3923, Loss: 209.07401865588776, Neurons: 201, Grad norm: 5.4233338863019895\n",
      "Epoch 3924, Loss: 209.0737988825332, Neurons: 201, Grad norm: 4.657277594385774\n",
      "Epoch 3924, Loss: 209.0737988825332, Neurons: 201, Grad norm: 4.657277594385774\n",
      "Epoch 3925, Loss: 209.07346513364777, Neurons: 201, Grad norm: 3.46352072785516\n",
      "Epoch 3925, Loss: 209.07346513364777, Neurons: 201, Grad norm: 3.46352072785516\n",
      "Epoch 3926, Loss: 209.07312488178667, Neurons: 201, Grad norm: 2.426666093252052\n",
      "Epoch 3926, Loss: 209.07312488178667, Neurons: 201, Grad norm: 2.426666093252052\n",
      "Epoch 3927, Loss: 209.07281798895104, Neurons: 201, Grad norm: 1.254422676820278\n",
      "Epoch 3927, Loss: 209.07281798895104, Neurons: 201, Grad norm: 1.254422676820278\n",
      "Epoch 3928, Loss: 209.07256440070913, Neurons: 201, Grad norm: 0.599730530494366\n",
      "Epoch 3928, Loss: 209.07256440070913, Neurons: 201, Grad norm: 0.599730530494366\n",
      "Epoch 3929, Loss: 209.07236042834492, Neurons: 201, Grad norm: 0.7440394824274122\n",
      "Epoch 3929, Loss: 209.07236042834492, Neurons: 201, Grad norm: 0.7440394824274122\n",
      "Epoch 3930, Loss: 209.0721872224619, Neurons: 201, Grad norm: 1.1722329637193518\n",
      "Epoch 3930, Loss: 209.0721872224619, Neurons: 201, Grad norm: 1.1722329637193518\n",
      "Epoch 3931, Loss: 209.0720242218427, Neurons: 201, Grad norm: 1.8620166423885975\n",
      "Epoch 3931, Loss: 209.0720242218427, Neurons: 201, Grad norm: 1.8620166423885975\n",
      "Epoch 3932, Loss: 209.0718517209858, Neurons: 201, Grad norm: 2.2729753418431407\n",
      "Epoch 3932, Loss: 209.0718517209858, Neurons: 201, Grad norm: 2.2729753418431407\n",
      "Epoch 3933, Loss: 209.07170134590774, Neurons: 201, Grad norm: 3.032857587914979\n",
      "Epoch 3933, Loss: 209.07170134590774, Neurons: 201, Grad norm: 3.032857587914979\n",
      "Epoch 3934, Loss: 209.07158296308754, Neurons: 201, Grad norm: 3.4184481046821977\n",
      "Epoch 3934, Loss: 209.07158296308754, Neurons: 201, Grad norm: 3.4184481046821977\n",
      "Epoch 3935, Loss: 209.07144772782914, Neurons: 201, Grad norm: 3.972782925519506\n",
      "Epoch 3935, Loss: 209.07144772782914, Neurons: 201, Grad norm: 3.972782925519506\n",
      "Epoch 3936, Loss: 209.07132899408532, Neurons: 201, Grad norm: 4.11829209510335\n",
      "Epoch 3936, Loss: 209.07132899408532, Neurons: 201, Grad norm: 4.11829209510335\n",
      "Epoch 3937, Loss: 209.0711824257642, Neurons: 201, Grad norm: 4.443454456414274\n",
      "Epoch 3937, Loss: 209.0711824257642, Neurons: 201, Grad norm: 4.443454456414274\n",
      "Epoch 3938, Loss: 209.07101520166208, Neurons: 201, Grad norm: 4.286797608332075\n",
      "Epoch 3938, Loss: 209.07101520166208, Neurons: 201, Grad norm: 4.286797608332075\n",
      "Epoch 3939, Loss: 209.0708445813371, Neurons: 201, Grad norm: 4.666219603208472\n",
      "Epoch 3939, Loss: 209.0708445813371, Neurons: 201, Grad norm: 4.666219603208472\n",
      "Epoch 3940, Loss: 209.0706468337632, Neurons: 201, Grad norm: 4.325878845557497\n",
      "Epoch 3940, Loss: 209.0706468337632, Neurons: 201, Grad norm: 4.325878845557497\n",
      "Epoch 3941, Loss: 209.0704529964804, Neurons: 201, Grad norm: 4.389006265834875\n",
      "Epoch 3941, Loss: 209.0704529964804, Neurons: 201, Grad norm: 4.389006265834875\n",
      "Epoch 3942, Loss: 209.07022933882484, Neurons: 201, Grad norm: 3.8075987185141313\n",
      "Epoch 3942, Loss: 209.07022933882484, Neurons: 201, Grad norm: 3.8075987185141313\n",
      "Epoch 3943, Loss: 209.06993632898934, Neurons: 201, Grad norm: 3.538896473162625\n",
      "Epoch 3943, Loss: 209.06993632898934, Neurons: 201, Grad norm: 3.538896473162625\n",
      "Epoch 3944, Loss: 209.06962159028703, Neurons: 201, Grad norm: 2.7739435879314085\n",
      "Epoch 3944, Loss: 209.06962159028703, Neurons: 201, Grad norm: 2.7739435879314085\n",
      "Epoch 3945, Loss: 209.06935454309257, Neurons: 201, Grad norm: 2.664624075916235\n",
      "Epoch 3945, Loss: 209.06935454309257, Neurons: 201, Grad norm: 2.664624075916235\n",
      "Epoch 3946, Loss: 209.06905586113197, Neurons: 201, Grad norm: 2.0846796267420604\n",
      "Epoch 3946, Loss: 209.06905586113197, Neurons: 201, Grad norm: 2.0846796267420604\n",
      "Epoch 3947, Loss: 209.06876114697857, Neurons: 201, Grad norm: 2.3653799808672553\n",
      "Epoch 3947, Loss: 209.06876114697857, Neurons: 201, Grad norm: 2.3653799808672553\n",
      "Epoch 3948, Loss: 209.0685163804313, Neurons: 201, Grad norm: 1.9263228944837851\n",
      "Epoch 3948, Loss: 209.0685163804313, Neurons: 201, Grad norm: 1.9263228944837851\n",
      "Epoch 3949, Loss: 209.06824323880286, Neurons: 201, Grad norm: 1.9675931975625303\n",
      "Epoch 3949, Loss: 209.06824323880286, Neurons: 201, Grad norm: 1.9675931975625303\n",
      "Epoch 3950, Loss: 209.06798571576203, Neurons: 201, Grad norm: 1.9114340129698295\n",
      "Epoch 3950, Loss: 209.06798571576203, Neurons: 201, Grad norm: 1.9114340129698295\n",
      "Epoch 3951, Loss: 209.06776145308797, Neurons: 201, Grad norm: 2.583926493609667\n",
      "Epoch 3951, Loss: 209.06776145308797, Neurons: 201, Grad norm: 2.583926493609667\n",
      "Epoch 3952, Loss: 209.0675778751693, Neurons: 201, Grad norm: 2.884936363141734\n",
      "Epoch 3952, Loss: 209.0675778751693, Neurons: 201, Grad norm: 2.884936363141734\n",
      "Epoch 3953, Loss: 209.06738908947227, Neurons: 201, Grad norm: 4.03030825888285\n",
      "Epoch 3953, Loss: 209.06738908947227, Neurons: 201, Grad norm: 4.03030825888285\n",
      "Epoch 3954, Loss: 209.06713358018723, Neurons: 201, Grad norm: 4.4208733525165576\n",
      "Epoch 3954, Loss: 209.06713358018723, Neurons: 201, Grad norm: 4.4208733525165576\n",
      "Epoch 3955, Loss: 209.06694738637702, Neurons: 201, Grad norm: 5.300425029420618\n",
      "Epoch 3955, Loss: 209.06694738637702, Neurons: 201, Grad norm: 5.300425029420618\n",
      "Epoch 3956, Loss: 209.0666870250686, Neurons: 201, Grad norm: 5.397019924251627\n",
      "Epoch 3956, Loss: 209.0666870250686, Neurons: 201, Grad norm: 5.397019924251627\n",
      "Epoch 3957, Loss: 209.06639485389678, Neurons: 201, Grad norm: 5.710926413617163\n",
      "Epoch 3957, Loss: 209.06639485389678, Neurons: 201, Grad norm: 5.710926413617163\n",
      "Epoch 3958, Loss: 209.066000075428, Neurons: 201, Grad norm: 5.008044440064177\n",
      "Epoch 3958, Loss: 209.066000075428, Neurons: 201, Grad norm: 5.008044440064177\n",
      "Epoch 3959, Loss: 209.06546112928814, Neurons: 201, Grad norm: 4.521048009518362\n",
      "Epoch 3959, Loss: 209.06546112928814, Neurons: 201, Grad norm: 4.521048009518362\n",
      "Epoch 3960, Loss: 209.06502668202415, Neurons: 201, Grad norm: 3.299642868466784\n",
      "Epoch 3960, Loss: 209.06502668202415, Neurons: 201, Grad norm: 3.299642868466784\n",
      "Epoch 3961, Loss: 209.0646137302214, Neurons: 201, Grad norm: 2.20314166086991\n",
      "Epoch 3961, Loss: 209.0646137302214, Neurons: 201, Grad norm: 2.20314166086991\n",
      "Epoch 3962, Loss: 209.06421197568199, Neurons: 201, Grad norm: 0.9978348587503915\n",
      "Epoch 3962, Loss: 209.06421197568199, Neurons: 201, Grad norm: 0.9978348587503915\n",
      "Epoch 3963, Loss: 209.06381721487895, Neurons: 201, Grad norm: 0.6028542832504499\n",
      "Epoch 3963, Loss: 209.06381721487895, Neurons: 201, Grad norm: 0.6028542832504499\n",
      "Epoch 3964, Loss: 209.06352667344575, Neurons: 201, Grad norm: 1.4316958973965126\n",
      "Epoch 3964, Loss: 209.06352667344575, Neurons: 201, Grad norm: 1.4316958973965126\n",
      "Epoch 3965, Loss: 209.06340530363195, Neurons: 201, Grad norm: 2.198139190033793\n",
      "Epoch 3965, Loss: 209.06340530363195, Neurons: 201, Grad norm: 2.198139190033793\n",
      "Epoch 3966, Loss: 209.06328787764517, Neurons: 201, Grad norm: 3.139782164125367\n",
      "Epoch 3966, Loss: 209.06328787764517, Neurons: 201, Grad norm: 3.139782164125367\n",
      "Epoch 3967, Loss: 209.06322128731904, Neurons: 201, Grad norm: 4.2537047414208145\n",
      "Epoch 3967, Loss: 209.06322128731904, Neurons: 201, Grad norm: 4.2537047414208145\n",
      "Epoch 3968, Loss: 209.06315613518737, Neurons: 201, Grad norm: 5.240525792285347\n",
      "Epoch 3968, Loss: 209.06315613518737, Neurons: 201, Grad norm: 5.240525792285347\n",
      "Epoch 3969, Loss: 209.0631318291552, Neurons: 201, Grad norm: 5.911250457345223\n",
      "Epoch 3969, Loss: 209.0631318291552, Neurons: 201, Grad norm: 5.911250457345223\n",
      "Epoch 3970, Loss: 209.06308056956192, Neurons: 201, Grad norm: 6.3318904214686444\n",
      "Epoch 3970, Loss: 209.06308056956192, Neurons: 201, Grad norm: 6.3318904214686444\n",
      "Epoch 3971, Loss: 209.0629605188626, Neurons: 201, Grad norm: 5.516622445196231\n",
      "Epoch 3971, Loss: 209.0629605188626, Neurons: 201, Grad norm: 5.516622445196231\n",
      "Epoch 3972, Loss: 209.06258635178756, Neurons: 201, Grad norm: 4.737650353027473\n",
      "Epoch 3972, Loss: 209.06258635178756, Neurons: 201, Grad norm: 4.737650353027473\n",
      "Epoch 3973, Loss: 209.06219012296876, Neurons: 201, Grad norm: 3.206926661440329\n",
      "Epoch 3973, Loss: 209.06219012296876, Neurons: 201, Grad norm: 3.206926661440329\n",
      "Epoch 3974, Loss: 209.06174701728898, Neurons: 201, Grad norm: 2.1056650905728485\n",
      "Epoch 3974, Loss: 209.06174701728898, Neurons: 201, Grad norm: 2.1056650905728485\n",
      "Epoch 3975, Loss: 209.06141393519027, Neurons: 201, Grad norm: 1.0416728734510496\n",
      "Epoch 3975, Loss: 209.06141393519027, Neurons: 201, Grad norm: 1.0416728734510496\n",
      "Epoch 3976, Loss: 209.06112542910515, Neurons: 201, Grad norm: 0.6811972045555948\n",
      "Epoch 3976, Loss: 209.06112542910515, Neurons: 201, Grad norm: 0.6811972045555948\n",
      "Epoch 3977, Loss: 209.06089575712494, Neurons: 201, Grad norm: 0.9455321376646756\n",
      "Epoch 3977, Loss: 209.06089575712494, Neurons: 201, Grad norm: 0.9455321376646756\n",
      "Epoch 3978, Loss: 209.06064073880233, Neurons: 201, Grad norm: 1.320872674145536\n",
      "Epoch 3978, Loss: 209.06064073880233, Neurons: 201, Grad norm: 1.320872674145536\n",
      "Epoch 3979, Loss: 209.06039229201863, Neurons: 201, Grad norm: 2.3823631427866614\n",
      "Epoch 3979, Loss: 209.06039229201863, Neurons: 201, Grad norm: 2.3823631427866614\n",
      "Epoch 3980, Loss: 209.06018391393746, Neurons: 201, Grad norm: 2.8214300944420305\n",
      "Epoch 3980, Loss: 209.06018391393746, Neurons: 201, Grad norm: 2.8214300944420305\n",
      "Epoch 3981, Loss: 209.05995278212274, Neurons: 201, Grad norm: 3.7992457362109255\n",
      "Epoch 3981, Loss: 209.05995278212274, Neurons: 201, Grad norm: 3.7992457362109255\n",
      "Epoch 3982, Loss: 209.05972612383061, Neurons: 201, Grad norm: 3.998783647229436\n",
      "Epoch 3982, Loss: 209.05972612383061, Neurons: 201, Grad norm: 3.998783647229436\n",
      "Epoch 3983, Loss: 209.05946517174996, Neurons: 201, Grad norm: 4.663407706740613\n",
      "Epoch 3983, Loss: 209.05946517174996, Neurons: 201, Grad norm: 4.663407706740613\n",
      "Epoch 3984, Loss: 209.05926136466485, Neurons: 201, Grad norm: 4.579118395630882\n",
      "Epoch 3984, Loss: 209.05926136466485, Neurons: 201, Grad norm: 4.579118395630882\n",
      "Epoch 3985, Loss: 209.0589625777279, Neurons: 201, Grad norm: 5.028139576414373\n",
      "Epoch 3985, Loss: 209.0589625777279, Neurons: 201, Grad norm: 5.028139576414373\n",
      "Epoch 3986, Loss: 209.05869617662472, Neurons: 201, Grad norm: 4.62953520235738\n",
      "Epoch 3986, Loss: 209.05869617662472, Neurons: 201, Grad norm: 4.62953520235738\n",
      "Epoch 3987, Loss: 209.05831814991018, Neurons: 201, Grad norm: 4.474621474338528\n",
      "Epoch 3987, Loss: 209.05831814991018, Neurons: 201, Grad norm: 4.474621474338528\n",
      "Epoch 3988, Loss: 209.05795253662092, Neurons: 201, Grad norm: 3.5151186517006274\n",
      "Epoch 3988, Loss: 209.05795253662092, Neurons: 201, Grad norm: 3.5151186517006274\n",
      "Epoch 3989, Loss: 209.05750568080296, Neurons: 201, Grad norm: 2.8401046319703376\n",
      "Epoch 3989, Loss: 209.05750568080296, Neurons: 201, Grad norm: 2.8401046319703376\n",
      "Epoch 3990, Loss: 209.0570720539788, Neurons: 201, Grad norm: 1.570362356225573\n",
      "Epoch 3990, Loss: 209.0570720539788, Neurons: 201, Grad norm: 1.570362356225573\n",
      "Epoch 3991, Loss: 209.05661804717613, Neurons: 201, Grad norm: 0.7389518098160001\n",
      "Epoch 3991, Loss: 209.05661804717613, Neurons: 201, Grad norm: 0.7389518098160001\n",
      "Epoch 3992, Loss: 209.05635502191274, Neurons: 201, Grad norm: 1.2897045998941312\n",
      "Epoch 3992, Loss: 209.05635502191274, Neurons: 201, Grad norm: 1.2897045998941312\n",
      "Epoch 3993, Loss: 209.0561171960824, Neurons: 201, Grad norm: 2.1700186036635754\n",
      "Epoch 3993, Loss: 209.0561171960824, Neurons: 201, Grad norm: 2.1700186036635754\n",
      "Epoch 3994, Loss: 209.05592428673881, Neurons: 201, Grad norm: 3.2834008912651447\n",
      "Epoch 3994, Loss: 209.05592428673881, Neurons: 201, Grad norm: 3.2834008912651447\n",
      "Epoch 3995, Loss: 209.0557188838445, Neurons: 201, Grad norm: 4.071525784166081\n",
      "Epoch 3995, Loss: 209.0557188838445, Neurons: 201, Grad norm: 4.071525784166081\n",
      "Epoch 3996, Loss: 209.0555900728304, Neurons: 201, Grad norm: 4.865853193144438\n",
      "Epoch 3996, Loss: 209.0555900728304, Neurons: 201, Grad norm: 4.865853193144438\n",
      "Epoch 3997, Loss: 209.05542783292236, Neurons: 201, Grad norm: 4.84603990343365\n",
      "Epoch 3997, Loss: 209.05542783292236, Neurons: 201, Grad norm: 4.84603990343365\n",
      "Epoch 3998, Loss: 209.05515853733712, Neurons: 201, Grad norm: 4.68931886928671\n",
      "Epoch 3998, Loss: 209.05515853733712, Neurons: 201, Grad norm: 4.68931886928671\n",
      "Epoch 3999, Loss: 209.05475867919282, Neurons: 201, Grad norm: 3.263148377026908\n",
      "Epoch 3999, Loss: 209.05475867919282, Neurons: 201, Grad norm: 3.263148377026908\n",
      "Epoch 4000, Loss: 209.05425008010926, Neurons: 201, Grad norm: 2.2784898042720343\n",
      "Epoch 4000, Loss: 209.05425008010926, Neurons: 201, Grad norm: 2.2784898042720343\n",
      "Epoch 4001, Loss: 209.053712103915, Neurons: 201, Grad norm: 1.1865202722594492\n",
      "Epoch 4001, Loss: 209.053712103915, Neurons: 201, Grad norm: 1.1865202722594492\n",
      "Epoch 4002, Loss: 209.0532847583631, Neurons: 201, Grad norm: 1.1220921036040081\n",
      "Epoch 4002, Loss: 209.0532847583631, Neurons: 201, Grad norm: 1.1220921036040081\n",
      "Epoch 4003, Loss: 209.05288758947205, Neurons: 201, Grad norm: 2.6589073382404123\n",
      "Epoch 4003, Loss: 209.05288758947205, Neurons: 201, Grad norm: 2.6589073382404123\n",
      "Epoch 4004, Loss: 209.0525453961855, Neurons: 201, Grad norm: 3.9526710549240653\n",
      "Epoch 4004, Loss: 209.0525453961855, Neurons: 201, Grad norm: 3.9526710549240653\n",
      "Epoch 4005, Loss: 209.052260603992, Neurons: 201, Grad norm: 5.878965921743018\n",
      "Epoch 4005, Loss: 209.052260603992, Neurons: 201, Grad norm: 5.878965921743018\n",
      "Epoch 4006, Loss: 209.05206060737342, Neurons: 201, Grad norm: 6.452123166136351\n",
      "Epoch 4006, Loss: 209.05206060737342, Neurons: 201, Grad norm: 6.452123166136351\n",
      "Epoch 4007, Loss: 209.0517412075502, Neurons: 201, Grad norm: 6.69038785576818\n",
      "Epoch 4007, Loss: 209.0517412075502, Neurons: 201, Grad norm: 6.69038785576818\n",
      "Epoch 4008, Loss: 209.0512704429421, Neurons: 201, Grad norm: 5.080705734898834\n",
      "Epoch 4008, Loss: 209.0512704429421, Neurons: 201, Grad norm: 5.080705734898834\n",
      "Epoch 4009, Loss: 209.0505092752526, Neurons: 201, Grad norm: 3.1259431174190855\n",
      "Epoch 4009, Loss: 209.0505092752526, Neurons: 201, Grad norm: 3.1259431174190855\n",
      "Epoch 4010, Loss: 209.04963504126042, Neurons: 201, Grad norm: 0.641068166401517\n",
      "Epoch 4010, Loss: 209.04963504126042, Neurons: 201, Grad norm: 0.641068166401517\n",
      "Epoch 4011, Loss: 209.0489730297008, Neurons: 201, Grad norm: 2.6968887042623946\n",
      "Epoch 4011, Loss: 209.0489730297008, Neurons: 201, Grad norm: 2.6968887042623946\n",
      "Epoch 4012, Loss: 209.0488772445984, Neurons: 201, Grad norm: 5.365234610752394\n",
      "Epoch 4012, Loss: 209.0488772445984, Neurons: 201, Grad norm: 5.365234610752394\n",
      "Epoch 4013, Loss: 209.04900793894043, Neurons: 201, Grad norm: 6.750433086128245\n",
      "Epoch 4013, Loss: 209.04900793894043, Neurons: 201, Grad norm: 6.750433086128245\n",
      "Epoch 4014, Loss: 209.04917122357773, Neurons: 201, Grad norm: 8.062376147702949\n",
      "Epoch 4014, Loss: 209.04917122357773, Neurons: 201, Grad norm: 8.062376147702949\n",
      "Epoch 4015, Loss: 209.0492238867261, Neurons: 201, Grad norm: 7.3858847615542755\n",
      "Epoch 4015, Loss: 209.0492238867261, Neurons: 201, Grad norm: 7.3858847615542755\n",
      "Epoch 4016, Loss: 209.04889993224847, Neurons: 201, Grad norm: 6.115165057419979\n",
      "Epoch 4016, Loss: 209.04889993224847, Neurons: 201, Grad norm: 6.115165057419979\n",
      "Epoch 4017, Loss: 209.04829860710893, Neurons: 201, Grad norm: 3.3691821816151886\n",
      "Epoch 4017, Loss: 209.04829860710893, Neurons: 201, Grad norm: 3.3691821816151886\n",
      "Epoch 4018, Loss: 209.04770303642687, Neurons: 201, Grad norm: 0.7684190742356826\n",
      "Epoch 4018, Loss: 209.04770303642687, Neurons: 201, Grad norm: 0.7684190742356826\n",
      "Epoch 4019, Loss: 209.04725424613477, Neurons: 201, Grad norm: 2.958039965743257\n",
      "Epoch 4019, Loss: 209.04725424613477, Neurons: 201, Grad norm: 2.958039965743257\n",
      "Epoch 4020, Loss: 209.0471540158542, Neurons: 201, Grad norm: 5.096641301865956\n",
      "Epoch 4020, Loss: 209.0471540158542, Neurons: 201, Grad norm: 5.096641301865956\n",
      "Epoch 4021, Loss: 209.04729102673687, Neurons: 201, Grad norm: 6.629475479424204\n",
      "Epoch 4021, Loss: 209.04729102673687, Neurons: 201, Grad norm: 6.629475479424204\n",
      "Epoch 4022, Loss: 209.04740367242508, Neurons: 201, Grad norm: 6.955034329896823\n",
      "Epoch 4022, Loss: 209.04740367242508, Neurons: 201, Grad norm: 6.955034329896823\n",
      "Epoch 4023, Loss: 209.0473408705296, Neurons: 201, Grad norm: 6.11821233667033\n",
      "Epoch 4023, Loss: 209.0473408705296, Neurons: 201, Grad norm: 6.11821233667033\n",
      "Epoch 4024, Loss: 209.04701113838584, Neurons: 201, Grad norm: 4.600604444033713\n",
      "Epoch 4024, Loss: 209.04701113838584, Neurons: 201, Grad norm: 4.600604444033713\n",
      "Epoch 4025, Loss: 209.04653256511696, Neurons: 201, Grad norm: 2.4925556007241783\n",
      "Epoch 4025, Loss: 209.04653256511696, Neurons: 201, Grad norm: 2.4925556007241783\n",
      "Epoch 4026, Loss: 209.0460789859048, Neurons: 201, Grad norm: 0.7900096968233662\n",
      "Epoch 4026, Loss: 209.0460789859048, Neurons: 201, Grad norm: 0.7900096968233662\n",
      "Epoch 4027, Loss: 209.04578238052062, Neurons: 201, Grad norm: 2.1709723645585575\n",
      "Epoch 4027, Loss: 209.04578238052062, Neurons: 201, Grad norm: 2.1709723645585575\n",
      "Epoch 4028, Loss: 209.04563552440086, Neurons: 201, Grad norm: 3.6998352204394576\n",
      "Epoch 4028, Loss: 209.04563552440086, Neurons: 201, Grad norm: 3.6998352204394576\n",
      "Epoch 4029, Loss: 209.04560346562596, Neurons: 201, Grad norm: 4.658586913567109\n",
      "Epoch 4029, Loss: 209.04560346562596, Neurons: 201, Grad norm: 4.658586913567109\n",
      "Epoch 4030, Loss: 209.04558446228836, Neurons: 201, Grad norm: 5.015757137323576\n",
      "Epoch 4030, Loss: 209.04558446228836, Neurons: 201, Grad norm: 5.015757137323576\n",
      "Epoch 4031, Loss: 209.04541861950042, Neurons: 201, Grad norm: 4.241954218809584\n",
      "Epoch 4031, Loss: 209.04541861950042, Neurons: 201, Grad norm: 4.241954218809584\n",
      "Epoch 4032, Loss: 209.0451076064, Neurons: 201, Grad norm: 3.3845633244872877\n",
      "Epoch 4032, Loss: 209.0451076064, Neurons: 201, Grad norm: 3.3845633244872877\n",
      "Epoch 4033, Loss: 209.04474184674527, Neurons: 201, Grad norm: 2.1557699019417633\n",
      "Epoch 4033, Loss: 209.04474184674527, Neurons: 201, Grad norm: 2.1557699019417633\n",
      "Epoch 4034, Loss: 209.0444171048668, Neurons: 201, Grad norm: 1.0080108421472176\n",
      "Epoch 4034, Loss: 209.0444171048668, Neurons: 201, Grad norm: 1.0080108421472176\n",
      "Epoch 4035, Loss: 209.0441394451222, Neurons: 201, Grad norm: 0.7980721268958472\n",
      "Epoch 4035, Loss: 209.0441394451222, Neurons: 201, Grad norm: 0.7980721268958472\n",
      "Epoch 4036, Loss: 209.04394616014832, Neurons: 201, Grad norm: 1.4718514235384563\n",
      "Epoch 4036, Loss: 209.04394616014832, Neurons: 201, Grad norm: 1.4718514235384563\n",
      "Epoch 4037, Loss: 209.04374015706605, Neurons: 201, Grad norm: 2.3251909528026093\n",
      "Epoch 4037, Loss: 209.04374015706605, Neurons: 201, Grad norm: 2.3251909528026093\n",
      "Epoch 4038, Loss: 209.043608434064, Neurons: 201, Grad norm: 2.7776462929203047\n",
      "Epoch 4038, Loss: 209.043608434064, Neurons: 201, Grad norm: 2.7776462929203047\n",
      "Epoch 4039, Loss: 209.0434894406861, Neurons: 201, Grad norm: 3.4206941036167104\n",
      "Epoch 4039, Loss: 209.0434894406861, Neurons: 201, Grad norm: 3.4206941036167104\n",
      "Epoch 4040, Loss: 209.04336030198354, Neurons: 201, Grad norm: 3.4188359113147024\n",
      "Epoch 4040, Loss: 209.04336030198354, Neurons: 201, Grad norm: 3.4188359113147024\n",
      "Epoch 4041, Loss: 209.04318996381807, Neurons: 201, Grad norm: 3.413833046424339\n",
      "Epoch 4041, Loss: 209.04318996381807, Neurons: 201, Grad norm: 3.413833046424339\n",
      "Epoch 4042, Loss: 209.04300499399184, Neurons: 201, Grad norm: 2.9177205343982977\n",
      "Epoch 4042, Loss: 209.04300499399184, Neurons: 201, Grad norm: 2.9177205343982977\n",
      "Epoch 4043, Loss: 209.04276087809333, Neurons: 201, Grad norm: 2.2915536593551735\n",
      "Epoch 4043, Loss: 209.04276087809333, Neurons: 201, Grad norm: 2.2915536593551735\n",
      "Epoch 4044, Loss: 209.042512919122, Neurons: 201, Grad norm: 1.4041611387380073\n",
      "Epoch 4044, Loss: 209.042512919122, Neurons: 201, Grad norm: 1.4041611387380073\n",
      "Epoch 4045, Loss: 209.04227442493942, Neurons: 201, Grad norm: 0.9539423032590713\n",
      "Epoch 4045, Loss: 209.04227442493942, Neurons: 201, Grad norm: 0.9539423032590713\n",
      "Epoch 4046, Loss: 209.04207312702187, Neurons: 201, Grad norm: 0.6018271063136015\n",
      "Epoch 4046, Loss: 209.04207312702187, Neurons: 201, Grad norm: 0.6018271063136015\n",
      "Epoch 4047, Loss: 209.0418643329524, Neurons: 201, Grad norm: 0.4536583144816452\n",
      "Epoch 4047, Loss: 209.0418643329524, Neurons: 201, Grad norm: 0.4536583144816452\n",
      "Epoch 4048, Loss: 209.04166322649144, Neurons: 201, Grad norm: 0.6355935958199693\n",
      "Epoch 4048, Loss: 209.04166322649144, Neurons: 201, Grad norm: 0.6355935958199693\n",
      "Epoch 4049, Loss: 209.0414858508609, Neurons: 201, Grad norm: 0.6758714512617177\n",
      "Epoch 4049, Loss: 209.0414858508609, Neurons: 201, Grad norm: 0.6758714512617177\n",
      "Epoch 4050, Loss: 209.04131331515907, Neurons: 201, Grad norm: 0.7096407572052585\n",
      "Epoch 4050, Loss: 209.04131331515907, Neurons: 201, Grad norm: 0.7096407572052585\n",
      "Epoch 4051, Loss: 209.04110814135444, Neurons: 201, Grad norm: 0.8235321945828354\n",
      "Epoch 4051, Loss: 209.04110814135444, Neurons: 201, Grad norm: 0.8235321945828354\n",
      "Epoch 4052, Loss: 209.04091690912705, Neurons: 201, Grad norm: 1.1688566057357714\n",
      "Epoch 4052, Loss: 209.04091690912705, Neurons: 201, Grad norm: 1.1688566057357714\n",
      "Epoch 4053, Loss: 209.04074637041475, Neurons: 201, Grad norm: 1.3185611943653497\n",
      "Epoch 4053, Loss: 209.04074637041475, Neurons: 201, Grad norm: 1.3185611943653497\n",
      "Epoch 4054, Loss: 209.0405801738861, Neurons: 201, Grad norm: 1.713164723475954\n",
      "Epoch 4054, Loss: 209.0405801738861, Neurons: 201, Grad norm: 1.713164723475954\n",
      "Epoch 4055, Loss: 209.04039729997444, Neurons: 201, Grad norm: 2.1002128535770144\n",
      "Epoch 4055, Loss: 209.04039729997444, Neurons: 201, Grad norm: 2.1002128535770144\n",
      "Epoch 4056, Loss: 209.04024726855354, Neurons: 201, Grad norm: 2.585223970052831\n",
      "Epoch 4056, Loss: 209.04024726855354, Neurons: 201, Grad norm: 2.585223970052831\n",
      "Epoch 4057, Loss: 209.040073514923, Neurons: 201, Grad norm: 3.0296505068950275\n",
      "Epoch 4057, Loss: 209.040073514923, Neurons: 201, Grad norm: 3.0296505068950275\n",
      "Epoch 4058, Loss: 209.03995075225845, Neurons: 201, Grad norm: 3.6587776034874615\n",
      "Epoch 4058, Loss: 209.03995075225845, Neurons: 201, Grad norm: 3.6587776034874615\n",
      "Epoch 4059, Loss: 209.03982722173424, Neurons: 201, Grad norm: 4.045858724303243\n",
      "Epoch 4059, Loss: 209.03982722173424, Neurons: 201, Grad norm: 4.045858724303243\n",
      "Epoch 4060, Loss: 209.03972119634702, Neurons: 201, Grad norm: 4.799157062348945\n",
      "Epoch 4060, Loss: 209.03972119634702, Neurons: 201, Grad norm: 4.799157062348945\n",
      "Epoch 4061, Loss: 209.03963968740348, Neurons: 201, Grad norm: 4.9807099260846295\n",
      "Epoch 4061, Loss: 209.03963968740348, Neurons: 201, Grad norm: 4.9807099260846295\n",
      "Epoch 4062, Loss: 209.03949260035165, Neurons: 201, Grad norm: 5.361447535060123\n",
      "Epoch 4062, Loss: 209.03949260035165, Neurons: 201, Grad norm: 5.361447535060123\n",
      "Epoch 4063, Loss: 209.0393635643971, Neurons: 201, Grad norm: 5.45299646326954\n",
      "Epoch 4063, Loss: 209.0393635643971, Neurons: 201, Grad norm: 5.45299646326954\n",
      "Epoch 4064, Loss: 209.03921426201416, Neurons: 201, Grad norm: 5.261407192987333\n",
      "Epoch 4064, Loss: 209.03921426201416, Neurons: 201, Grad norm: 5.261407192987333\n",
      "Epoch 4065, Loss: 209.03899517215032, Neurons: 201, Grad norm: 4.698831383650429\n",
      "Epoch 4065, Loss: 209.03899517215032, Neurons: 201, Grad norm: 4.698831383650429\n",
      "Epoch 4066, Loss: 209.03872800913976, Neurons: 201, Grad norm: 3.665141576486498\n",
      "Epoch 4066, Loss: 209.03872800913976, Neurons: 201, Grad norm: 3.665141576486498\n",
      "Epoch 4067, Loss: 209.03840062320916, Neurons: 201, Grad norm: 2.093387973543228\n",
      "Epoch 4067, Loss: 209.03840062320916, Neurons: 201, Grad norm: 2.093387973543228\n",
      "Epoch 4068, Loss: 209.03809720968766, Neurons: 201, Grad norm: 1.010468495918939\n",
      "Epoch 4068, Loss: 209.03809720968766, Neurons: 201, Grad norm: 1.010468495918939\n",
      "Epoch 4069, Loss: 209.0378252804155, Neurons: 201, Grad norm: 0.7599193358340152\n",
      "Epoch 4069, Loss: 209.0378252804155, Neurons: 201, Grad norm: 0.7599193358340152\n",
      "Epoch 4070, Loss: 209.03762667184643, Neurons: 201, Grad norm: 1.3695156736875764\n",
      "Epoch 4070, Loss: 209.03762667184643, Neurons: 201, Grad norm: 1.3695156736875764\n",
      "Epoch 4071, Loss: 209.03747706816142, Neurons: 201, Grad norm: 2.125048922185076\n",
      "Epoch 4071, Loss: 209.03747706816142, Neurons: 201, Grad norm: 2.125048922185076\n",
      "Epoch 4072, Loss: 209.03732006776337, Neurons: 201, Grad norm: 2.8455504145914943\n",
      "Epoch 4072, Loss: 209.03732006776337, Neurons: 201, Grad norm: 2.8455504145914943\n",
      "Epoch 4073, Loss: 209.03719290402614, Neurons: 201, Grad norm: 3.990073991365768\n",
      "Epoch 4073, Loss: 209.03719290402614, Neurons: 201, Grad norm: 3.990073991365768\n",
      "Epoch 4074, Loss: 209.03717620908645, Neurons: 201, Grad norm: 4.607651400241888\n",
      "Epoch 4074, Loss: 209.03717620908645, Neurons: 201, Grad norm: 4.607651400241888\n",
      "Epoch 4075, Loss: 209.03713441636293, Neurons: 201, Grad norm: 5.346027632023066\n",
      "Epoch 4075, Loss: 209.03713441636293, Neurons: 201, Grad norm: 5.346027632023066\n",
      "Epoch 4076, Loss: 209.0370355086474, Neurons: 201, Grad norm: 5.323929502202858\n",
      "Epoch 4076, Loss: 209.0370355086474, Neurons: 201, Grad norm: 5.323929502202858\n",
      "Epoch 4077, Loss: 209.03685040429247, Neurons: 201, Grad norm: 5.08073193868475\n",
      "Epoch 4077, Loss: 209.03685040429247, Neurons: 201, Grad norm: 5.08073193868475\n",
      "Epoch 4078, Loss: 209.03664787673745, Neurons: 201, Grad norm: 4.671495151943625\n",
      "Epoch 4078, Loss: 209.03664787673745, Neurons: 201, Grad norm: 4.671495151943625\n",
      "Epoch 4079, Loss: 209.03633952339723, Neurons: 201, Grad norm: 4.173932595858502\n",
      "Epoch 4079, Loss: 209.03633952339723, Neurons: 201, Grad norm: 4.173932595858502\n",
      "Epoch 4080, Loss: 209.0361211720176, Neurons: 201, Grad norm: 3.3929935674761507\n",
      "Epoch 4080, Loss: 209.0361211720176, Neurons: 201, Grad norm: 3.3929935674761507\n",
      "Epoch 4081, Loss: 209.035848943213, Neurons: 201, Grad norm: 2.932194316997188\n",
      "Epoch 4081, Loss: 209.035848943213, Neurons: 201, Grad norm: 2.932194316997188\n",
      "Epoch 4082, Loss: 209.03561990354606, Neurons: 201, Grad norm: 2.31531144227513\n",
      "Epoch 4082, Loss: 209.03561990354606, Neurons: 201, Grad norm: 2.31531144227513\n",
      "Epoch 4083, Loss: 209.03537214346414, Neurons: 201, Grad norm: 1.681283107602636\n",
      "Epoch 4083, Loss: 209.03537214346414, Neurons: 201, Grad norm: 1.681283107602636\n",
      "Epoch 4084, Loss: 209.0351661737735, Neurons: 201, Grad norm: 1.0352337538699052\n",
      "Epoch 4084, Loss: 209.0351661737735, Neurons: 201, Grad norm: 1.0352337538699052\n",
      "Epoch 4085, Loss: 209.03494946923212, Neurons: 201, Grad norm: 0.7535099315809292\n",
      "Epoch 4085, Loss: 209.03494946923212, Neurons: 201, Grad norm: 0.7535099315809292\n",
      "Epoch 4086, Loss: 209.03477263000443, Neurons: 201, Grad norm: 0.6204123284010095\n",
      "Epoch 4086, Loss: 209.03477263000443, Neurons: 201, Grad norm: 0.6204123284010095\n",
      "Epoch 4087, Loss: 209.0346044866073, Neurons: 201, Grad norm: 0.47093689292688684\n",
      "Epoch 4087, Loss: 209.0346044866073, Neurons: 201, Grad norm: 0.47093689292688684\n",
      "Epoch 4088, Loss: 209.03440326226342, Neurons: 201, Grad norm: 0.7676801874292373\n",
      "Epoch 4088, Loss: 209.03440326226342, Neurons: 201, Grad norm: 0.7676801874292373\n",
      "Epoch 4089, Loss: 209.0342529868442, Neurons: 201, Grad norm: 0.8961608819177806\n",
      "Epoch 4089, Loss: 209.0342529868442, Neurons: 201, Grad norm: 0.8961608819177806\n",
      "Epoch 4090, Loss: 209.03407608993686, Neurons: 201, Grad norm: 1.249187822329676\n",
      "Epoch 4090, Loss: 209.03407608993686, Neurons: 201, Grad norm: 1.249187822329676\n",
      "Epoch 4091, Loss: 209.03390070387883, Neurons: 201, Grad norm: 1.483616744663205\n",
      "Epoch 4091, Loss: 209.03390070387883, Neurons: 201, Grad norm: 1.483616744663205\n",
      "Epoch 4092, Loss: 209.03373618480828, Neurons: 201, Grad norm: 2.064738157255126\n",
      "Epoch 4092, Loss: 209.03373618480828, Neurons: 201, Grad norm: 2.064738157255126\n",
      "Epoch 4093, Loss: 209.03360898834634, Neurons: 201, Grad norm: 2.875424467738749\n",
      "Epoch 4093, Loss: 209.03360898834634, Neurons: 201, Grad norm: 2.875424467738749\n",
      "Epoch 4094, Loss: 209.03348414310398, Neurons: 201, Grad norm: 3.9985404085090925\n",
      "Epoch 4094, Loss: 209.03348414310398, Neurons: 201, Grad norm: 3.9985404085090925\n",
      "Epoch 4095, Loss: 209.03341938155492, Neurons: 201, Grad norm: 5.213799752549502\n",
      "Epoch 4095, Loss: 209.03341938155492, Neurons: 201, Grad norm: 5.213799752549502\n",
      "Epoch 4096, Loss: 209.0334405188315, Neurons: 201, Grad norm: 6.4889559734049636\n",
      "Epoch 4096, Loss: 209.0334405188315, Neurons: 201, Grad norm: 6.4889559734049636\n",
      "Epoch 4097, Loss: 209.03351188655802, Neurons: 201, Grad norm: 7.30567378103816\n",
      "Epoch 4097, Loss: 209.03351188655802, Neurons: 201, Grad norm: 7.30567378103816\n",
      "Epoch 4098, Loss: 209.03358233239896, Neurons: 201, Grad norm: 8.205904173233494\n",
      "Epoch 4098, Loss: 209.03358233239896, Neurons: 201, Grad norm: 8.205904173233494\n",
      "Epoch 4099, Loss: 209.03362485699947, Neurons: 201, Grad norm: 8.342687919494603\n",
      "Epoch 4099, Loss: 209.03362485699947, Neurons: 201, Grad norm: 8.342687919494603\n",
      "Epoch 4100, Loss: 209.03347417577294, Neurons: 201, Grad norm: 8.062530313733575\n",
      "Epoch 4100, Loss: 209.03347417577294, Neurons: 201, Grad norm: 8.062530313733575\n",
      "Epoch 4101, Loss: 209.0332133133971, Neurons: 201, Grad norm: 6.852826111981317\n",
      "Epoch 4101, Loss: 209.0332133133971, Neurons: 201, Grad norm: 6.852826111981317\n",
      "Epoch 4102, Loss: 209.03279895955743, Neurons: 201, Grad norm: 5.310940796863578\n",
      "Epoch 4102, Loss: 209.03279895955743, Neurons: 201, Grad norm: 5.310940796863578\n",
      "Epoch 4103, Loss: 209.03226819355984, Neurons: 201, Grad norm: 3.1102677051144223\n",
      "Epoch 4103, Loss: 209.03226819355984, Neurons: 201, Grad norm: 3.1102677051144223\n",
      "Epoch 4104, Loss: 209.03181073428547, Neurons: 201, Grad norm: 1.1288357390687822\n",
      "Epoch 4104, Loss: 209.03181073428547, Neurons: 201, Grad norm: 1.1288357390687822\n",
      "Epoch 4105, Loss: 209.03143999971078, Neurons: 201, Grad norm: 1.3497884587037978\n",
      "Epoch 4105, Loss: 209.03143999971078, Neurons: 201, Grad norm: 1.3497884587037978\n",
      "Epoch 4106, Loss: 209.03127715578216, Neurons: 201, Grad norm: 3.366408769928198\n",
      "Epoch 4106, Loss: 209.03127715578216, Neurons: 201, Grad norm: 3.366408769928198\n",
      "Epoch 4107, Loss: 209.0312545706121, Neurons: 201, Grad norm: 5.0746150481388135\n",
      "Epoch 4107, Loss: 209.0312545706121, Neurons: 201, Grad norm: 5.0746150481388135\n",
      "Epoch 4108, Loss: 209.0313256236975, Neurons: 201, Grad norm: 6.381565985595477\n",
      "Epoch 4108, Loss: 209.0313256236975, Neurons: 201, Grad norm: 6.381565985595477\n",
      "Epoch 4109, Loss: 209.03142533405403, Neurons: 201, Grad norm: 7.20029241020074\n",
      "Epoch 4109, Loss: 209.03142533405403, Neurons: 201, Grad norm: 7.20029241020074\n",
      "Epoch 4110, Loss: 209.03141985862027, Neurons: 201, Grad norm: 6.977644037693248\n",
      "Epoch 4110, Loss: 209.03141985862027, Neurons: 201, Grad norm: 6.977644037693248\n",
      "Epoch 4111, Loss: 209.0312317845583, Neurons: 201, Grad norm: 6.254817756265366\n",
      "Epoch 4111, Loss: 209.0312317845583, Neurons: 201, Grad norm: 6.254817756265366\n",
      "Epoch 4112, Loss: 209.03084990920024, Neurons: 201, Grad norm: 4.618403968935476\n",
      "Epoch 4112, Loss: 209.03084990920024, Neurons: 201, Grad norm: 4.618403968935476\n",
      "Epoch 4113, Loss: 209.03041787180507, Neurons: 201, Grad norm: 2.7078603996803885\n",
      "Epoch 4113, Loss: 209.03041787180507, Neurons: 201, Grad norm: 2.7078603996803885\n",
      "Epoch 4114, Loss: 209.02997048200555, Neurons: 201, Grad norm: 0.7181747366522112\n",
      "Epoch 4114, Loss: 209.02997048200555, Neurons: 201, Grad norm: 0.7181747366522112\n",
      "Epoch 4115, Loss: 209.02970345319017, Neurons: 201, Grad norm: 1.950061833646617\n",
      "Epoch 4115, Loss: 209.02970345319017, Neurons: 201, Grad norm: 1.950061833646617\n",
      "Epoch 4116, Loss: 209.0295569925982, Neurons: 201, Grad norm: 4.081557083661752\n",
      "Epoch 4116, Loss: 209.0295569925982, Neurons: 201, Grad norm: 4.081557083661752\n",
      "Epoch 4117, Loss: 209.02963350697885, Neurons: 201, Grad norm: 5.605503747342557\n",
      "Epoch 4117, Loss: 209.02963350697885, Neurons: 201, Grad norm: 5.605503747342557\n",
      "Epoch 4118, Loss: 209.02969705340425, Neurons: 201, Grad norm: 6.542334857482314\n",
      "Epoch 4118, Loss: 209.02969705340425, Neurons: 201, Grad norm: 6.542334857482314\n",
      "Epoch 4119, Loss: 209.02968725526307, Neurons: 201, Grad norm: 6.575604765172876\n",
      "Epoch 4119, Loss: 209.02968725526307, Neurons: 201, Grad norm: 6.575604765172876\n",
      "Epoch 4120, Loss: 209.0295446191847, Neurons: 201, Grad norm: 5.968425713084251\n",
      "Epoch 4120, Loss: 209.0295446191847, Neurons: 201, Grad norm: 5.968425713084251\n",
      "Epoch 4121, Loss: 209.02922794509186, Neurons: 201, Grad norm: 4.603064624261367\n",
      "Epoch 4121, Loss: 209.02922794509186, Neurons: 201, Grad norm: 4.603064624261367\n",
      "Epoch 4122, Loss: 209.02881145681746, Neurons: 201, Grad norm: 2.9251389527783265\n",
      "Epoch 4122, Loss: 209.02881145681746, Neurons: 201, Grad norm: 2.9251389527783265\n",
      "Epoch 4123, Loss: 209.02843073472917, Neurons: 201, Grad norm: 1.0990050305838857\n",
      "Epoch 4123, Loss: 209.02843073472917, Neurons: 201, Grad norm: 1.0990050305838857\n",
      "Epoch 4124, Loss: 209.02814610984444, Neurons: 201, Grad norm: 1.1031039047469486\n",
      "Epoch 4124, Loss: 209.02814610984444, Neurons: 201, Grad norm: 1.1031039047469486\n",
      "Epoch 4125, Loss: 209.02795513413088, Neurons: 201, Grad norm: 2.8492058681199333\n",
      "Epoch 4125, Loss: 209.02795513413088, Neurons: 201, Grad norm: 2.8492058681199333\n",
      "Epoch 4126, Loss: 209.02789406243576, Neurons: 201, Grad norm: 3.990152907373054\n",
      "Epoch 4126, Loss: 209.02789406243576, Neurons: 201, Grad norm: 3.990152907373054\n",
      "Epoch 4127, Loss: 209.02790526789136, Neurons: 201, Grad norm: 4.94804226796781\n",
      "Epoch 4127, Loss: 209.02790526789136, Neurons: 201, Grad norm: 4.94804226796781\n",
      "Epoch 4128, Loss: 209.02784041274987, Neurons: 201, Grad norm: 5.305742039248654\n",
      "Epoch 4128, Loss: 209.02784041274987, Neurons: 201, Grad norm: 5.305742039248654\n",
      "Epoch 4129, Loss: 209.02770496905708, Neurons: 201, Grad norm: 5.255788547025481\n",
      "Epoch 4129, Loss: 209.02770496905708, Neurons: 201, Grad norm: 5.255788547025481\n",
      "Epoch 4130, Loss: 209.02752147923027, Neurons: 201, Grad norm: 4.629376015335815\n",
      "Epoch 4130, Loss: 209.02752147923027, Neurons: 201, Grad norm: 4.629376015335815\n",
      "Epoch 4131, Loss: 209.02729726389168, Neurons: 201, Grad norm: 3.886916144879314\n",
      "Epoch 4131, Loss: 209.02729726389168, Neurons: 201, Grad norm: 3.886916144879314\n",
      "Epoch 4132, Loss: 209.02697966031974, Neurons: 201, Grad norm: 2.79376868092748\n",
      "Epoch 4132, Loss: 209.02697966031974, Neurons: 201, Grad norm: 2.79376868092748\n",
      "Epoch 4133, Loss: 209.0266815825056, Neurons: 201, Grad norm: 2.0127133703899918\n",
      "Epoch 4133, Loss: 209.0266815825056, Neurons: 201, Grad norm: 2.0127133703899918\n",
      "Epoch 4134, Loss: 209.02642877439575, Neurons: 201, Grad norm: 1.428869374375796\n",
      "Epoch 4134, Loss: 209.02642877439575, Neurons: 201, Grad norm: 1.428869374375796\n",
      "Epoch 4135, Loss: 209.02626272043085, Neurons: 201, Grad norm: 1.098207382114253\n",
      "Epoch 4135, Loss: 209.02626272043085, Neurons: 201, Grad norm: 1.098207382114253\n",
      "Epoch 4136, Loss: 209.02608819971636, Neurons: 201, Grad norm: 0.9259490230127826\n",
      "Epoch 4136, Loss: 209.02608819971636, Neurons: 201, Grad norm: 0.9259490230127826\n",
      "Epoch 4137, Loss: 209.02590440537705, Neurons: 201, Grad norm: 0.988182734620593\n",
      "Epoch 4137, Loss: 209.02590440537705, Neurons: 201, Grad norm: 0.988182734620593\n",
      "Epoch 4138, Loss: 209.02572769212762, Neurons: 201, Grad norm: 0.7569110239487573\n",
      "Epoch 4138, Loss: 209.02572769212762, Neurons: 201, Grad norm: 0.7569110239487573\n",
      "Epoch 4139, Loss: 209.02554653869018, Neurons: 201, Grad norm: 0.8311471219775766\n",
      "Epoch 4139, Loss: 209.02554653869018, Neurons: 201, Grad norm: 0.8311471219775766\n",
      "Epoch 4140, Loss: 209.02537094100677, Neurons: 201, Grad norm: 0.8919705285761997\n",
      "Epoch 4140, Loss: 209.02537094100677, Neurons: 201, Grad norm: 0.8919705285761997\n",
      "Epoch 4141, Loss: 209.0252070047168, Neurons: 201, Grad norm: 1.225379177921413\n",
      "Epoch 4141, Loss: 209.0252070047168, Neurons: 201, Grad norm: 1.225379177921413\n",
      "Epoch 4142, Loss: 209.02504335458673, Neurons: 201, Grad norm: 1.795647365376378\n",
      "Epoch 4142, Loss: 209.02504335458673, Neurons: 201, Grad norm: 1.795647365376378\n",
      "Epoch 4143, Loss: 209.02489883459103, Neurons: 201, Grad norm: 2.6144158202776997\n",
      "Epoch 4143, Loss: 209.02489883459103, Neurons: 201, Grad norm: 2.6144158202776997\n",
      "Epoch 4144, Loss: 209.0248232481748, Neurons: 201, Grad norm: 3.5179389566949406\n",
      "Epoch 4144, Loss: 209.0248232481748, Neurons: 201, Grad norm: 3.5179389566949406\n",
      "Epoch 4145, Loss: 209.02474128198605, Neurons: 201, Grad norm: 4.490468015199086\n",
      "Epoch 4145, Loss: 209.02474128198605, Neurons: 201, Grad norm: 4.490468015199086\n",
      "Epoch 4146, Loss: 209.02468820388123, Neurons: 201, Grad norm: 4.8898538396815345\n",
      "Epoch 4146, Loss: 209.02468820388123, Neurons: 201, Grad norm: 4.8898538396815345\n",
      "Epoch 4147, Loss: 209.02459615329215, Neurons: 201, Grad norm: 5.315817101288776\n",
      "Epoch 4147, Loss: 209.02459615329215, Neurons: 201, Grad norm: 5.315817101288776\n",
      "Epoch 4148, Loss: 209.02452024425511, Neurons: 201, Grad norm: 4.968347982979691\n",
      "Epoch 4148, Loss: 209.02452024425511, Neurons: 201, Grad norm: 4.968347982979691\n",
      "Epoch 4149, Loss: 209.02429004147004, Neurons: 201, Grad norm: 4.390947645966362\n",
      "Epoch 4149, Loss: 209.02429004147004, Neurons: 201, Grad norm: 4.390947645966362\n",
      "Epoch 4150, Loss: 209.02401160783612, Neurons: 201, Grad norm: 3.2558944049888106\n",
      "Epoch 4150, Loss: 209.02401160783612, Neurons: 201, Grad norm: 3.2558944049888106\n",
      "Epoch 4151, Loss: 209.02370262379685, Neurons: 201, Grad norm: 2.4336858227072753\n",
      "Epoch 4151, Loss: 209.02370262379685, Neurons: 201, Grad norm: 2.4336858227072753\n",
      "Epoch 4152, Loss: 209.0234273248857, Neurons: 201, Grad norm: 1.8007613715456627\n",
      "Epoch 4152, Loss: 209.0234273248857, Neurons: 201, Grad norm: 1.8007613715456627\n",
      "Epoch 4153, Loss: 209.0232239217009, Neurons: 201, Grad norm: 1.6416196893125319\n",
      "Epoch 4153, Loss: 209.0232239217009, Neurons: 201, Grad norm: 1.6416196893125319\n",
      "Epoch 4154, Loss: 209.0230607371851, Neurons: 201, Grad norm: 1.716838760924275\n",
      "Epoch 4154, Loss: 209.0230607371851, Neurons: 201, Grad norm: 1.716838760924275\n",
      "Epoch 4155, Loss: 209.0228999683489, Neurons: 201, Grad norm: 2.038419223417732\n",
      "Epoch 4155, Loss: 209.0228999683489, Neurons: 201, Grad norm: 2.038419223417732\n",
      "Epoch 4156, Loss: 209.02273722229288, Neurons: 201, Grad norm: 2.5500837866947745\n",
      "Epoch 4156, Loss: 209.02273722229288, Neurons: 201, Grad norm: 2.5500837866947745\n",
      "Epoch 4157, Loss: 209.02261474327207, Neurons: 201, Grad norm: 3.452614589283582\n",
      "Epoch 4157, Loss: 209.02261474327207, Neurons: 201, Grad norm: 3.452614589283582\n",
      "Epoch 4158, Loss: 209.02256683976387, Neurons: 201, Grad norm: 4.089378622021261\n",
      "Epoch 4158, Loss: 209.02256683976387, Neurons: 201, Grad norm: 4.089378622021261\n",
      "Epoch 4159, Loss: 209.02248908233548, Neurons: 201, Grad norm: 5.036928503908639\n",
      "Epoch 4159, Loss: 209.02248908233548, Neurons: 201, Grad norm: 5.036928503908639\n",
      "Epoch 4160, Loss: 209.02244684814352, Neurons: 201, Grad norm: 5.630138941995068\n",
      "Epoch 4160, Loss: 209.02244684814352, Neurons: 201, Grad norm: 5.630138941995068\n",
      "Epoch 4161, Loss: 209.02241464241143, Neurons: 201, Grad norm: 5.984755718726444\n",
      "Epoch 4161, Loss: 209.02241464241143, Neurons: 201, Grad norm: 5.984755718726444\n",
      "Epoch 4162, Loss: 209.02232369842693, Neurons: 201, Grad norm: 5.927153282918557\n",
      "Epoch 4162, Loss: 209.02232369842693, Neurons: 201, Grad norm: 5.927153282918557\n",
      "Epoch 4163, Loss: 209.02217027965975, Neurons: 201, Grad norm: 5.87430238102943\n",
      "Epoch 4163, Loss: 209.02217027965975, Neurons: 201, Grad norm: 5.87430238102943\n",
      "Epoch 4164, Loss: 209.02198268140077, Neurons: 201, Grad norm: 5.339941638068563\n",
      "Epoch 4164, Loss: 209.02198268140077, Neurons: 201, Grad norm: 5.339941638068563\n",
      "Epoch 4165, Loss: 209.02174009662193, Neurons: 201, Grad norm: 4.615519751110939\n",
      "Epoch 4165, Loss: 209.02174009662193, Neurons: 201, Grad norm: 4.615519751110939\n",
      "Epoch 4166, Loss: 209.02141172853507, Neurons: 201, Grad norm: 3.367906746918444\n",
      "Epoch 4166, Loss: 209.02141172853507, Neurons: 201, Grad norm: 3.367906746918444\n",
      "Epoch 4167, Loss: 209.02114005835404, Neurons: 201, Grad norm: 2.291956078632492\n",
      "Epoch 4167, Loss: 209.02114005835404, Neurons: 201, Grad norm: 2.291956078632492\n",
      "Epoch 4168, Loss: 209.02084888505593, Neurons: 201, Grad norm: 1.0912681775395634\n",
      "Epoch 4168, Loss: 209.02084888505593, Neurons: 201, Grad norm: 1.0912681775395634\n",
      "Epoch 4169, Loss: 209.02063858153176, Neurons: 201, Grad norm: 0.7150008993009649\n",
      "Epoch 4169, Loss: 209.02063858153176, Neurons: 201, Grad norm: 0.7150008993009649\n",
      "Epoch 4170, Loss: 209.02046346935455, Neurons: 201, Grad norm: 0.9588650729770347\n",
      "Epoch 4170, Loss: 209.02046346935455, Neurons: 201, Grad norm: 0.9588650729770347\n",
      "Epoch 4171, Loss: 209.0203129514679, Neurons: 201, Grad norm: 1.6637267702837646\n",
      "Epoch 4171, Loss: 209.0203129514679, Neurons: 201, Grad norm: 1.6637267702837646\n",
      "Epoch 4172, Loss: 209.02020134496692, Neurons: 201, Grad norm: 2.497580659665428\n",
      "Epoch 4172, Loss: 209.02020134496692, Neurons: 201, Grad norm: 2.497580659665428\n",
      "Epoch 4173, Loss: 209.02007082015774, Neurons: 201, Grad norm: 3.389990247985936\n",
      "Epoch 4173, Loss: 209.02007082015774, Neurons: 201, Grad norm: 3.389990247985936\n",
      "Epoch 4174, Loss: 209.01997632826257, Neurons: 201, Grad norm: 4.50267073234901\n",
      "Epoch 4174, Loss: 209.01997632826257, Neurons: 201, Grad norm: 4.50267073234901\n",
      "Epoch 4175, Loss: 209.01996570152303, Neurons: 201, Grad norm: 5.16550483794162\n",
      "Epoch 4175, Loss: 209.01996570152303, Neurons: 201, Grad norm: 5.16550483794162\n",
      "Epoch 4176, Loss: 209.01993863596618, Neurons: 201, Grad norm: 6.16734042016084\n",
      "Epoch 4176, Loss: 209.01993863596618, Neurons: 201, Grad norm: 6.16734042016084\n",
      "Epoch 4177, Loss: 209.01994705878425, Neurons: 201, Grad norm: 6.363231275841808\n",
      "Epoch 4177, Loss: 209.01994705878425, Neurons: 201, Grad norm: 6.363231275841808\n",
      "Epoch 4178, Loss: 209.01985718816192, Neurons: 201, Grad norm: 6.583836293676957\n",
      "Epoch 4178, Loss: 209.01985718816192, Neurons: 201, Grad norm: 6.583836293676957\n",
      "Epoch 4179, Loss: 209.01970542081014, Neurons: 201, Grad norm: 5.727275269556238\n",
      "Epoch 4179, Loss: 209.01970542081014, Neurons: 201, Grad norm: 5.727275269556238\n",
      "Epoch 4180, Loss: 209.01937934108597, Neurons: 201, Grad norm: 4.7367500644788025\n",
      "Epoch 4180, Loss: 209.01937934108597, Neurons: 201, Grad norm: 4.7367500644788025\n",
      "Epoch 4181, Loss: 209.01903698897155, Neurons: 201, Grad norm: 3.3166638075576174\n",
      "Epoch 4181, Loss: 209.01903698897155, Neurons: 201, Grad norm: 3.3166638075576174\n",
      "Epoch 4182, Loss: 209.0186771803688, Neurons: 201, Grad norm: 1.8610852052845652\n",
      "Epoch 4182, Loss: 209.0186771803688, Neurons: 201, Grad norm: 1.8610852052845652\n",
      "Epoch 4183, Loss: 209.01841903042413, Neurons: 201, Grad norm: 0.7499032088133685\n",
      "Epoch 4183, Loss: 209.01841903042413, Neurons: 201, Grad norm: 0.7499032088133685\n",
      "Epoch 4184, Loss: 209.01818605850613, Neurons: 201, Grad norm: 0.8897713335329828\n",
      "Epoch 4184, Loss: 209.01818605850613, Neurons: 201, Grad norm: 0.8897713335329828\n",
      "Epoch 4185, Loss: 209.01805127470314, Neurons: 201, Grad norm: 1.7506859410428317\n",
      "Epoch 4185, Loss: 209.01805127470314, Neurons: 201, Grad norm: 1.7506859410428317\n",
      "Epoch 4186, Loss: 209.01792857883817, Neurons: 201, Grad norm: 2.708193713933599\n",
      "Epoch 4186, Loss: 209.01792857883817, Neurons: 201, Grad norm: 2.708193713933599\n",
      "Epoch 4187, Loss: 209.01783923108903, Neurons: 201, Grad norm: 3.7106064787915147\n",
      "Epoch 4187, Loss: 209.01783923108903, Neurons: 201, Grad norm: 3.7106064787915147\n",
      "Epoch 4188, Loss: 209.01776552510452, Neurons: 201, Grad norm: 4.581563261464811\n",
      "Epoch 4188, Loss: 209.01776552510452, Neurons: 201, Grad norm: 4.581563261464811\n",
      "Epoch 4189, Loss: 209.01771514472608, Neurons: 201, Grad norm: 5.345170168134632\n",
      "Epoch 4189, Loss: 209.01771514472608, Neurons: 201, Grad norm: 5.345170168134632\n",
      "Epoch 4190, Loss: 209.01770047293687, Neurons: 201, Grad norm: 5.8364310706994145\n",
      "Epoch 4190, Loss: 209.01770047293687, Neurons: 201, Grad norm: 5.8364310706994145\n",
      "Epoch 4191, Loss: 209.0175966560318, Neurons: 201, Grad norm: 6.416629068061796\n",
      "Epoch 4191, Loss: 209.0175966560318, Neurons: 201, Grad norm: 6.416629068061796\n",
      "Epoch 4192, Loss: 209.01759372554216, Neurons: 201, Grad norm: 6.387673517064363\n",
      "Epoch 4192, Loss: 209.01759372554216, Neurons: 201, Grad norm: 6.387673517064363\n",
      "Epoch 4193, Loss: 209.01746502026097, Neurons: 201, Grad norm: 6.657711180744926\n",
      "Epoch 4193, Loss: 209.01746502026097, Neurons: 201, Grad norm: 6.657711180744926\n",
      "Epoch 4194, Loss: 209.0173449971448, Neurons: 201, Grad norm: 6.075524684131981\n",
      "Epoch 4194, Loss: 209.0173449971448, Neurons: 201, Grad norm: 6.075524684131981\n",
      "Epoch 4195, Loss: 209.01709213872124, Neurons: 201, Grad norm: 5.388971115780449\n",
      "Epoch 4195, Loss: 209.01709213872124, Neurons: 201, Grad norm: 5.388971115780449\n",
      "Epoch 4196, Loss: 209.0168020376722, Neurons: 201, Grad norm: 3.9543690634301485\n",
      "Epoch 4196, Loss: 209.0168020376722, Neurons: 201, Grad norm: 3.9543690634301485\n",
      "Epoch 4197, Loss: 209.01647005339623, Neurons: 201, Grad norm: 2.0259883487348986\n",
      "Epoch 4197, Loss: 209.01647005339623, Neurons: 201, Grad norm: 2.0259883487348986\n",
      "Epoch 4198, Loss: 209.01610549643067, Neurons: 201, Grad norm: 0.6808168200552768\n",
      "Epoch 4198, Loss: 209.01610549643067, Neurons: 201, Grad norm: 0.6808168200552768\n",
      "Epoch 4199, Loss: 209.0158665987776, Neurons: 201, Grad norm: 1.6558853842511987\n",
      "Epoch 4199, Loss: 209.0158665987776, Neurons: 201, Grad norm: 1.6558853842511987\n",
      "Epoch 4200, Loss: 209.0157826794961, Neurons: 201, Grad norm: 3.272240877980197\n",
      "Epoch 4200, Loss: 209.0157826794961, Neurons: 201, Grad norm: 3.272240877980197\n",
      "Epoch 4201, Loss: 209.01572795716484, Neurons: 201, Grad norm: 4.5488013462633745\n",
      "Epoch 4201, Loss: 209.01572795716484, Neurons: 201, Grad norm: 4.5488013462633745\n",
      "Epoch 4202, Loss: 209.0157384932337, Neurons: 201, Grad norm: 5.905516123124524\n",
      "Epoch 4202, Loss: 209.0157384932337, Neurons: 201, Grad norm: 5.905516123124524\n",
      "Epoch 4203, Loss: 209.01584265460212, Neurons: 201, Grad norm: 6.729639869896074\n",
      "Epoch 4203, Loss: 209.01584265460212, Neurons: 201, Grad norm: 6.729639869896074\n",
      "Epoch 4204, Loss: 209.01582150019104, Neurons: 201, Grad norm: 7.264823271472538\n",
      "Epoch 4204, Loss: 209.01582150019104, Neurons: 201, Grad norm: 7.264823271472538\n",
      "Epoch 4205, Loss: 209.01583689087784, Neurons: 201, Grad norm: 6.8564860852529605\n",
      "Epoch 4205, Loss: 209.01583689087784, Neurons: 201, Grad norm: 6.8564860852529605\n",
      "Epoch 4206, Loss: 209.01560852306588, Neurons: 201, Grad norm: 6.373128564722202\n",
      "Epoch 4206, Loss: 209.01560852306588, Neurons: 201, Grad norm: 6.373128564722202\n",
      "Epoch 4207, Loss: 209.01533212520792, Neurons: 201, Grad norm: 5.067988789393762\n",
      "Epoch 4207, Loss: 209.01533212520792, Neurons: 201, Grad norm: 5.067988789393762\n",
      "Epoch 4208, Loss: 209.01495179997772, Neurons: 201, Grad norm: 3.5801527241180118\n",
      "Epoch 4208, Loss: 209.01495179997772, Neurons: 201, Grad norm: 3.5801527241180118\n",
      "Epoch 4209, Loss: 209.01462634183838, Neurons: 201, Grad norm: 2.083053749438467\n",
      "Epoch 4209, Loss: 209.01462634183838, Neurons: 201, Grad norm: 2.083053749438467\n",
      "Epoch 4210, Loss: 209.01431704108307, Neurons: 201, Grad norm: 0.6262325117610327\n",
      "Epoch 4210, Loss: 209.01431704108307, Neurons: 201, Grad norm: 0.6262325117610327\n",
      "Epoch 4211, Loss: 209.0140672422983, Neurons: 201, Grad norm: 1.49941450278118\n",
      "Epoch 4211, Loss: 209.0140672422983, Neurons: 201, Grad norm: 1.49941450278118\n",
      "Epoch 4212, Loss: 209.01396936257757, Neurons: 201, Grad norm: 2.52466293462266\n",
      "Epoch 4212, Loss: 209.01396936257757, Neurons: 201, Grad norm: 2.52466293462266\n",
      "Epoch 4213, Loss: 209.0138646393862, Neurons: 201, Grad norm: 3.847874758140014\n",
      "Epoch 4213, Loss: 209.0138646393862, Neurons: 201, Grad norm: 3.847874758140014\n",
      "Epoch 4214, Loss: 209.0138530659543, Neurons: 201, Grad norm: 4.7712596973621695\n",
      "Epoch 4214, Loss: 209.0138530659543, Neurons: 201, Grad norm: 4.7712596973621695\n",
      "Epoch 4215, Loss: 209.0138252981691, Neurons: 201, Grad norm: 5.561914019628604\n",
      "Epoch 4215, Loss: 209.0138252981691, Neurons: 201, Grad norm: 5.561914019628604\n",
      "Epoch 4216, Loss: 209.01383604242508, Neurons: 201, Grad norm: 5.7860096960622\n",
      "Epoch 4216, Loss: 209.01383604242508, Neurons: 201, Grad norm: 5.7860096960622\n",
      "Epoch 4217, Loss: 209.01371422662118, Neurons: 201, Grad norm: 5.951524007124197\n",
      "Epoch 4217, Loss: 209.01371422662118, Neurons: 201, Grad norm: 5.951524007124197\n",
      "Epoch 4218, Loss: 209.01357277480665, Neurons: 201, Grad norm: 5.328187237461752\n",
      "Epoch 4218, Loss: 209.01357277480665, Neurons: 201, Grad norm: 5.328187237461752\n",
      "Epoch 4219, Loss: 209.01333697327962, Neurons: 201, Grad norm: 4.715252584152598\n",
      "Epoch 4219, Loss: 209.01333697327962, Neurons: 201, Grad norm: 4.715252584152598\n",
      "Epoch 4220, Loss: 209.01308890749158, Neurons: 201, Grad norm: 3.646684560388246\n",
      "Epoch 4220, Loss: 209.01308890749158, Neurons: 201, Grad norm: 3.646684560388246\n",
      "Epoch 4221, Loss: 209.01277353424516, Neurons: 201, Grad norm: 2.544291179423542\n",
      "Epoch 4221, Loss: 209.01277353424516, Neurons: 201, Grad norm: 2.544291179423542\n",
      "Epoch 4222, Loss: 209.01252300059625, Neurons: 201, Grad norm: 1.4246373326362272\n",
      "Epoch 4222, Loss: 209.01252300059625, Neurons: 201, Grad norm: 1.4246373326362272\n",
      "Epoch 4223, Loss: 209.01230612324676, Neurons: 201, Grad norm: 0.5924610350931169\n",
      "Epoch 4223, Loss: 209.01230612324676, Neurons: 201, Grad norm: 0.5924610350931169\n",
      "Epoch 4224, Loss: 209.01213974881477, Neurons: 201, Grad norm: 0.8273534171107879\n",
      "Epoch 4224, Loss: 209.01213974881477, Neurons: 201, Grad norm: 0.8273534171107879\n",
      "Epoch 4225, Loss: 209.01199954569765, Neurons: 201, Grad norm: 1.1465630006590464\n",
      "Epoch 4225, Loss: 209.01199954569765, Neurons: 201, Grad norm: 1.1465630006590464\n",
      "Epoch 4226, Loss: 209.01185893170887, Neurons: 201, Grad norm: 1.6635291526753277\n",
      "Epoch 4226, Loss: 209.01185893170887, Neurons: 201, Grad norm: 1.6635291526753277\n",
      "Epoch 4227, Loss: 209.01174972358012, Neurons: 201, Grad norm: 2.2112912192928755\n",
      "Epoch 4227, Loss: 209.01174972358012, Neurons: 201, Grad norm: 2.2112912192928755\n",
      "Epoch 4228, Loss: 209.01163006299026, Neurons: 201, Grad norm: 2.984826356847389\n",
      "Epoch 4228, Loss: 209.01163006299026, Neurons: 201, Grad norm: 2.984826356847389\n",
      "Epoch 4229, Loss: 209.0115215287272, Neurons: 201, Grad norm: 3.6695140447528805\n",
      "Epoch 4229, Loss: 209.0115215287272, Neurons: 201, Grad norm: 3.6695140447528805\n",
      "Epoch 4230, Loss: 209.0114703893699, Neurons: 201, Grad norm: 4.741069635549165\n",
      "Epoch 4230, Loss: 209.0114703893699, Neurons: 201, Grad norm: 4.741069635549165\n",
      "Epoch 4231, Loss: 209.0114543479782, Neurons: 201, Grad norm: 5.434976434113717\n",
      "Epoch 4231, Loss: 209.0114543479782, Neurons: 201, Grad norm: 5.434976434113717\n",
      "Epoch 4232, Loss: 209.01147362663522, Neurons: 201, Grad norm: 6.387237809207747\n",
      "Epoch 4232, Loss: 209.01147362663522, Neurons: 201, Grad norm: 6.387237809207747\n",
      "Epoch 4233, Loss: 209.0114814338408, Neurons: 201, Grad norm: 6.7686163451645305\n",
      "Epoch 4233, Loss: 209.0114814338408, Neurons: 201, Grad norm: 6.7686163451645305\n",
      "Epoch 4234, Loss: 209.01142972202894, Neurons: 201, Grad norm: 6.880616672153484\n",
      "Epoch 4234, Loss: 209.01142972202894, Neurons: 201, Grad norm: 6.880616672153484\n",
      "Epoch 4235, Loss: 209.01132283404775, Neurons: 201, Grad norm: 6.052018457726838\n",
      "Epoch 4235, Loss: 209.01132283404775, Neurons: 201, Grad norm: 6.052018457726838\n",
      "Epoch 4236, Loss: 209.0110145506018, Neurons: 201, Grad norm: 4.4812857627743865\n",
      "Epoch 4236, Loss: 209.0110145506018, Neurons: 201, Grad norm: 4.4812857627743865\n",
      "Epoch 4237, Loss: 209.01060248151902, Neurons: 201, Grad norm: 2.240922100362231\n",
      "Epoch 4237, Loss: 209.01060248151902, Neurons: 201, Grad norm: 2.240922100362231\n",
      "Epoch 4238, Loss: 209.0101894363555, Neurons: 201, Grad norm: 0.6301765432518774\n",
      "Epoch 4238, Loss: 209.0101894363555, Neurons: 201, Grad norm: 0.6301765432518774\n",
      "Epoch 4239, Loss: 209.00995302146774, Neurons: 201, Grad norm: 2.633278573359369\n",
      "Epoch 4239, Loss: 209.00995302146774, Neurons: 201, Grad norm: 2.633278573359369\n",
      "Epoch 4240, Loss: 209.00990525752653, Neurons: 201, Grad norm: 4.42519595849678\n",
      "Epoch 4240, Loss: 209.00990525752653, Neurons: 201, Grad norm: 4.42519595849678\n",
      "Epoch 4241, Loss: 209.0099953114016, Neurons: 201, Grad norm: 6.120004456314693\n",
      "Epoch 4241, Loss: 209.0099953114016, Neurons: 201, Grad norm: 6.120004456314693\n",
      "Epoch 4242, Loss: 209.01010636514303, Neurons: 201, Grad norm: 6.724383993175334\n",
      "Epoch 4242, Loss: 209.01010636514303, Neurons: 201, Grad norm: 6.724383993175334\n",
      "Epoch 4243, Loss: 209.0101941021288, Neurons: 201, Grad norm: 6.711936159810404\n",
      "Epoch 4243, Loss: 209.0101941021288, Neurons: 201, Grad norm: 6.711936159810404\n",
      "Epoch 4244, Loss: 209.01000792549095, Neurons: 201, Grad norm: 5.796491368486443\n",
      "Epoch 4244, Loss: 209.01000792549095, Neurons: 201, Grad norm: 5.796491368486443\n",
      "Epoch 4245, Loss: 209.00965919362184, Neurons: 201, Grad norm: 4.451662011972408\n",
      "Epoch 4245, Loss: 209.00965919362184, Neurons: 201, Grad norm: 4.451662011972408\n",
      "Epoch 4246, Loss: 209.0092572925411, Neurons: 201, Grad norm: 2.801025246829545\n",
      "Epoch 4246, Loss: 209.0092572925411, Neurons: 201, Grad norm: 2.801025246829545\n",
      "Epoch 4247, Loss: 209.0089314800231, Neurons: 201, Grad norm: 1.5686068171093457\n",
      "Epoch 4247, Loss: 209.0089314800231, Neurons: 201, Grad norm: 1.5686068171093457\n",
      "Epoch 4248, Loss: 209.00870651486701, Neurons: 201, Grad norm: 0.5542823288634926\n",
      "Epoch 4248, Loss: 209.00870651486701, Neurons: 201, Grad norm: 0.5542823288634926\n",
      "Epoch 4249, Loss: 209.00852907529926, Neurons: 201, Grad norm: 1.505294012268649\n",
      "Epoch 4249, Loss: 209.00852907529926, Neurons: 201, Grad norm: 1.505294012268649\n",
      "Epoch 4250, Loss: 209.00842557532638, Neurons: 201, Grad norm: 2.865939052884968\n",
      "Epoch 4250, Loss: 209.00842557532638, Neurons: 201, Grad norm: 2.865939052884968\n",
      "Epoch 4251, Loss: 209.0083553961972, Neurons: 201, Grad norm: 4.079995382722211\n",
      "Epoch 4251, Loss: 209.0083553961972, Neurons: 201, Grad norm: 4.079995382722211\n",
      "Epoch 4252, Loss: 209.00837005670112, Neurons: 201, Grad norm: 5.058789150941033\n",
      "Epoch 4252, Loss: 209.00837005670112, Neurons: 201, Grad norm: 5.058789150941033\n",
      "Epoch 4253, Loss: 209.00838960916826, Neurons: 201, Grad norm: 5.504777789453638\n",
      "Epoch 4253, Loss: 209.00838960916826, Neurons: 201, Grad norm: 5.504777789453638\n",
      "Epoch 4254, Loss: 209.00834009330094, Neurons: 201, Grad norm: 5.533092717727467\n",
      "Epoch 4254, Loss: 209.00834009330094, Neurons: 201, Grad norm: 5.533092717727467\n",
      "Epoch 4255, Loss: 209.00817890803245, Neurons: 201, Grad norm: 4.655101940419991\n",
      "Epoch 4255, Loss: 209.00817890803245, Neurons: 201, Grad norm: 4.655101940419991\n",
      "Epoch 4256, Loss: 209.00790649272074, Neurons: 201, Grad norm: 4.06443921645767\n",
      "Epoch 4256, Loss: 209.00790649272074, Neurons: 201, Grad norm: 4.06443921645767\n",
      "Epoch 4257, Loss: 209.00766012886217, Neurons: 201, Grad norm: 3.0543245984259215\n",
      "Epoch 4257, Loss: 209.00766012886217, Neurons: 201, Grad norm: 3.0543245984259215\n",
      "Epoch 4258, Loss: 209.007417183291, Neurons: 201, Grad norm: 2.1836503642767275\n",
      "Epoch 4258, Loss: 209.007417183291, Neurons: 201, Grad norm: 2.1836503642767275\n",
      "Epoch 4259, Loss: 209.0072363433064, Neurons: 201, Grad norm: 1.3132445505785562\n",
      "Epoch 4259, Loss: 209.0072363433064, Neurons: 201, Grad norm: 1.3132445505785562\n",
      "Epoch 4260, Loss: 209.0070285629513, Neurons: 201, Grad norm: 0.7055514798345557\n",
      "Epoch 4260, Loss: 209.0070285629513, Neurons: 201, Grad norm: 0.7055514798345557\n",
      "Epoch 4261, Loss: 209.00686695338425, Neurons: 201, Grad norm: 0.5519901047662548\n",
      "Epoch 4261, Loss: 209.00686695338425, Neurons: 201, Grad norm: 0.5519901047662548\n",
      "Epoch 4262, Loss: 209.0067118416455, Neurons: 201, Grad norm: 0.9902829048271727\n",
      "Epoch 4262, Loss: 209.0067118416455, Neurons: 201, Grad norm: 0.9902829048271727\n",
      "Epoch 4263, Loss: 209.00655488954283, Neurons: 201, Grad norm: 1.8672780228755808\n",
      "Epoch 4263, Loss: 209.00655488954283, Neurons: 201, Grad norm: 1.8672780228755808\n",
      "Epoch 4264, Loss: 209.00648027960113, Neurons: 201, Grad norm: 2.7499435270533894\n",
      "Epoch 4264, Loss: 209.00648027960113, Neurons: 201, Grad norm: 2.7499435270533894\n",
      "Epoch 4265, Loss: 209.00641030031025, Neurons: 201, Grad norm: 3.9375429117669634\n",
      "Epoch 4265, Loss: 209.00641030031025, Neurons: 201, Grad norm: 3.9375429117669634\n",
      "Epoch 4266, Loss: 209.006367898926, Neurons: 201, Grad norm: 4.8503569086095775\n",
      "Epoch 4266, Loss: 209.006367898926, Neurons: 201, Grad norm: 4.8503569086095775\n",
      "Epoch 4267, Loss: 209.00640218391945, Neurons: 201, Grad norm: 6.098980098933698\n",
      "Epoch 4267, Loss: 209.00640218391945, Neurons: 201, Grad norm: 6.098980098933698\n",
      "Epoch 4268, Loss: 209.00646547537514, Neurons: 201, Grad norm: 6.6412128762714016\n",
      "Epoch 4268, Loss: 209.00646547537514, Neurons: 201, Grad norm: 6.6412128762714016\n",
      "Epoch 4269, Loss: 209.00644324537248, Neurons: 201, Grad norm: 7.105552938656092\n",
      "Epoch 4269, Loss: 209.00644324537248, Neurons: 201, Grad norm: 7.105552938656092\n",
      "Epoch 4270, Loss: 209.00641099713368, Neurons: 201, Grad norm: 6.564347801358116\n",
      "Epoch 4270, Loss: 209.00641099713368, Neurons: 201, Grad norm: 6.564347801358116\n",
      "Epoch 4271, Loss: 209.0062013063638, Neurons: 201, Grad norm: 5.236148209195031\n",
      "Epoch 4271, Loss: 209.0062013063638, Neurons: 201, Grad norm: 5.236148209195031\n",
      "Epoch 4272, Loss: 209.00582389416513, Neurons: 201, Grad norm: 3.364331508833129\n",
      "Epoch 4272, Loss: 209.00582389416513, Neurons: 201, Grad norm: 3.364331508833129\n",
      "Epoch 4273, Loss: 209.0053834592009, Neurons: 201, Grad norm: 1.1064509732745083\n",
      "Epoch 4273, Loss: 209.0053834592009, Neurons: 201, Grad norm: 1.1064509732745083\n",
      "Epoch 4274, Loss: 209.0050929517247, Neurons: 201, Grad norm: 1.4158527940555738\n",
      "Epoch 4274, Loss: 209.0050929517247, Neurons: 201, Grad norm: 1.4158527940555738\n",
      "Epoch 4275, Loss: 209.00496797375172, Neurons: 201, Grad norm: 3.1078493992937184\n",
      "Epoch 4275, Loss: 209.00496797375172, Neurons: 201, Grad norm: 3.1078493992937184\n",
      "Epoch 4276, Loss: 209.00498315540185, Neurons: 201, Grad norm: 5.320422483199296\n",
      "Epoch 4276, Loss: 209.00498315540185, Neurons: 201, Grad norm: 5.320422483199296\n",
      "Epoch 4277, Loss: 209.00505656794178, Neurons: 201, Grad norm: 6.691051982916823\n",
      "Epoch 4277, Loss: 209.00505656794178, Neurons: 201, Grad norm: 6.691051982916823\n",
      "Epoch 4278, Loss: 209.0052429351832, Neurons: 201, Grad norm: 7.791952422056794\n",
      "Epoch 4278, Loss: 209.0052429351832, Neurons: 201, Grad norm: 7.791952422056794\n",
      "Epoch 4279, Loss: 209.00536481392822, Neurons: 201, Grad norm: 7.7364036226436745\n",
      "Epoch 4279, Loss: 209.00536481392822, Neurons: 201, Grad norm: 7.7364036226436745\n",
      "Epoch 4280, Loss: 209.00525875392202, Neurons: 201, Grad norm: 6.806959477318821\n",
      "Epoch 4280, Loss: 209.00525875392202, Neurons: 201, Grad norm: 6.806959477318821\n",
      "Epoch 4281, Loss: 209.00483357104264, Neurons: 201, Grad norm: 4.981544546171294\n",
      "Epoch 4281, Loss: 209.00483357104264, Neurons: 201, Grad norm: 4.981544546171294\n",
      "Epoch 4282, Loss: 209.00436105402653, Neurons: 201, Grad norm: 2.6430128900945116\n",
      "Epoch 4282, Loss: 209.00436105402653, Neurons: 201, Grad norm: 2.6430128900945116\n",
      "Epoch 4283, Loss: 209.00394422419555, Neurons: 201, Grad norm: 0.727641930478877\n",
      "Epoch 4283, Loss: 209.00394422419555, Neurons: 201, Grad norm: 0.727641930478877\n",
      "Epoch 4284, Loss: 209.0036820314772, Neurons: 201, Grad norm: 1.720920183125935\n",
      "Epoch 4284, Loss: 209.0036820314772, Neurons: 201, Grad norm: 1.720920183125935\n",
      "Epoch 4285, Loss: 209.00359229714385, Neurons: 201, Grad norm: 3.678759408196733\n",
      "Epoch 4285, Loss: 209.00359229714385, Neurons: 201, Grad norm: 3.678759408196733\n",
      "Epoch 4286, Loss: 209.00359194161229, Neurons: 201, Grad norm: 4.950018974861032\n",
      "Epoch 4286, Loss: 209.00359194161229, Neurons: 201, Grad norm: 4.950018974861032\n",
      "Epoch 4287, Loss: 209.0036758603027, Neurons: 201, Grad norm: 6.335783509828218\n",
      "Epoch 4287, Loss: 209.0036758603027, Neurons: 201, Grad norm: 6.335783509828218\n",
      "Epoch 4288, Loss: 209.00378150359646, Neurons: 201, Grad norm: 6.675101434332226\n",
      "Epoch 4288, Loss: 209.00378150359646, Neurons: 201, Grad norm: 6.675101434332226\n",
      "Epoch 4289, Loss: 209.00372177956498, Neurons: 201, Grad norm: 6.5951134494361074\n",
      "Epoch 4289, Loss: 209.00372177956498, Neurons: 201, Grad norm: 6.5951134494361074\n",
      "Epoch 4290, Loss: 209.00353340339356, Neurons: 201, Grad norm: 5.431409928283847\n",
      "Epoch 4290, Loss: 209.00353340339356, Neurons: 201, Grad norm: 5.431409928283847\n",
      "Epoch 4291, Loss: 209.00322866054967, Neurons: 201, Grad norm: 3.8593867444993983\n",
      "Epoch 4291, Loss: 209.00322866054967, Neurons: 201, Grad norm: 3.8593867444993983\n",
      "Epoch 4292, Loss: 209.00285562692048, Neurons: 201, Grad norm: 1.9676014062956249\n",
      "Epoch 4292, Loss: 209.00285562692048, Neurons: 201, Grad norm: 1.9676014062956249\n",
      "Epoch 4293, Loss: 209.00250129072944, Neurons: 201, Grad norm: 0.5364251903421121\n",
      "Epoch 4293, Loss: 209.00250129072944, Neurons: 201, Grad norm: 0.5364251903421121\n",
      "Epoch 4294, Loss: 209.0023194310128, Neurons: 201, Grad norm: 1.7892091829262133\n",
      "Epoch 4294, Loss: 209.0023194310128, Neurons: 201, Grad norm: 1.7892091829262133\n",
      "Epoch 4295, Loss: 209.0022495610655, Neurons: 201, Grad norm: 3.1903705248048415\n",
      "Epoch 4295, Loss: 209.0022495610655, Neurons: 201, Grad norm: 3.1903705248048415\n",
      "Epoch 4296, Loss: 209.00222826209972, Neurons: 201, Grad norm: 4.454277384443437\n",
      "Epoch 4296, Loss: 209.00222826209972, Neurons: 201, Grad norm: 4.454277384443437\n",
      "Epoch 4297, Loss: 209.0022218838463, Neurons: 201, Grad norm: 5.033307317296225\n",
      "Epoch 4297, Loss: 209.0022218838463, Neurons: 201, Grad norm: 5.033307317296225\n",
      "Epoch 4298, Loss: 209.00219128211313, Neurons: 201, Grad norm: 5.2775197205396465\n",
      "Epoch 4298, Loss: 209.00219128211313, Neurons: 201, Grad norm: 5.2775197205396465\n",
      "Epoch 4299, Loss: 209.00212512811717, Neurons: 201, Grad norm: 4.605581538991482\n",
      "Epoch 4299, Loss: 209.00212512811717, Neurons: 201, Grad norm: 4.605581538991482\n",
      "Epoch 4300, Loss: 209.00186262757055, Neurons: 201, Grad norm: 3.5465215075028254\n",
      "Epoch 4300, Loss: 209.00186262757055, Neurons: 201, Grad norm: 3.5465215075028254\n",
      "Epoch 4301, Loss: 209.00159674488472, Neurons: 201, Grad norm: 2.1360242331147683\n",
      "Epoch 4301, Loss: 209.00159674488472, Neurons: 201, Grad norm: 2.1360242331147683\n",
      "Epoch 4302, Loss: 209.00133912881307, Neurons: 201, Grad norm: 0.7787493408279463\n",
      "Epoch 4302, Loss: 209.00133912881307, Neurons: 201, Grad norm: 0.7787493408279463\n",
      "Epoch 4303, Loss: 209.0011547163427, Neurons: 201, Grad norm: 0.9919383120012752\n",
      "Epoch 4303, Loss: 209.0011547163427, Neurons: 201, Grad norm: 0.9919383120012752\n",
      "Epoch 4304, Loss: 209.00101664306482, Neurons: 201, Grad norm: 2.0544005269269476\n",
      "Epoch 4304, Loss: 209.00101664306482, Neurons: 201, Grad norm: 2.0544005269269476\n",
      "Epoch 4305, Loss: 209.00093521116932, Neurons: 201, Grad norm: 3.306598319714588\n",
      "Epoch 4305, Loss: 209.00093521116932, Neurons: 201, Grad norm: 3.306598319714588\n",
      "Epoch 4306, Loss: 209.00089989866598, Neurons: 201, Grad norm: 4.287848607477987\n",
      "Epoch 4306, Loss: 209.00089989866598, Neurons: 201, Grad norm: 4.287848607477987\n",
      "Epoch 4307, Loss: 209.00086680832484, Neurons: 201, Grad norm: 5.00047563433439\n",
      "Epoch 4307, Loss: 209.00086680832484, Neurons: 201, Grad norm: 5.00047563433439\n",
      "Epoch 4308, Loss: 209.0008317336944, Neurons: 201, Grad norm: 5.148626962721692\n",
      "Epoch 4308, Loss: 209.0008317336944, Neurons: 201, Grad norm: 5.148626962721692\n",
      "Epoch 4309, Loss: 209.0007182359462, Neurons: 201, Grad norm: 5.092474086018529\n",
      "Epoch 4309, Loss: 209.0007182359462, Neurons: 201, Grad norm: 5.092474086018529\n",
      "Epoch 4310, Loss: 209.0005597932625, Neurons: 201, Grad norm: 4.6074711871814396\n",
      "Epoch 4310, Loss: 209.0005597932625, Neurons: 201, Grad norm: 4.6074711871814396\n",
      "Epoch 4311, Loss: 209.00033561078106, Neurons: 201, Grad norm: 4.392711571501956\n",
      "Epoch 4311, Loss: 209.00033561078106, Neurons: 201, Grad norm: 4.392711571501956\n",
      "Epoch 4312, Loss: 209.00017672706068, Neurons: 201, Grad norm: 3.664115015329288\n",
      "Epoch 4312, Loss: 209.00017672706068, Neurons: 201, Grad norm: 3.664115015329288\n",
      "Epoch 4313, Loss: 208.99994418316658, Neurons: 201, Grad norm: 3.0760164447420597\n",
      "Epoch 4313, Loss: 208.99994418316658, Neurons: 201, Grad norm: 3.0760164447420597\n",
      "Epoch 4314, Loss: 208.99968106487626, Neurons: 201, Grad norm: 2.3087496942083576\n",
      "Epoch 4314, Loss: 208.99968106487626, Neurons: 201, Grad norm: 2.3087496942083576\n",
      "Epoch 4315, Loss: 208.99942304105107, Neurons: 201, Grad norm: 1.681034543745844\n",
      "Epoch 4315, Loss: 208.99942304105107, Neurons: 201, Grad norm: 1.681034543745844\n",
      "Epoch 4316, Loss: 208.9991747043879, Neurons: 201, Grad norm: 1.1699266763994869\n",
      "Epoch 4316, Loss: 208.9991747043879, Neurons: 201, Grad norm: 1.1699266763994869\n",
      "Epoch 4317, Loss: 208.99881415244164, Neurons: 201, Grad norm: 0.807825028454197\n",
      "Epoch 4317, Loss: 208.99881415244164, Neurons: 201, Grad norm: 0.807825028454197\n",
      "Epoch 4318, Loss: 208.9983786835913, Neurons: 201, Grad norm: 0.5562557314403234\n",
      "Epoch 4318, Loss: 208.9983786835913, Neurons: 201, Grad norm: 0.5562557314403234\n",
      "Epoch 4319, Loss: 208.99794510589325, Neurons: 201, Grad norm: 0.6444193611506095\n",
      "Epoch 4319, Loss: 208.99794510589325, Neurons: 201, Grad norm: 0.6444193611506095\n",
      "Epoch 4320, Loss: 208.99753857372596, Neurons: 201, Grad norm: 0.5877474687000512\n",
      "Epoch 4320, Loss: 208.99753857372596, Neurons: 201, Grad norm: 0.5877474687000512\n",
      "Epoch 4321, Loss: 208.9972800945234, Neurons: 201, Grad norm: 0.5730633524467308\n",
      "Epoch 4321, Loss: 208.9972800945234, Neurons: 201, Grad norm: 0.5730633524467308\n",
      "Epoch 4322, Loss: 208.99711135605367, Neurons: 201, Grad norm: 0.6103146724385745\n",
      "Epoch 4322, Loss: 208.99711135605367, Neurons: 201, Grad norm: 0.6103146724385745\n",
      "Epoch 4323, Loss: 208.99693183866071, Neurons: 201, Grad norm: 0.7262513944708032\n",
      "Epoch 4323, Loss: 208.99693183866071, Neurons: 201, Grad norm: 0.7262513944708032\n",
      "Epoch 4324, Loss: 208.9967518316878, Neurons: 201, Grad norm: 0.8800784469929931\n",
      "Epoch 4324, Loss: 208.9967518316878, Neurons: 201, Grad norm: 0.8800784469929931\n",
      "Epoch 4325, Loss: 208.99658290126663, Neurons: 201, Grad norm: 1.2834795996497308\n",
      "Epoch 4325, Loss: 208.99658290126663, Neurons: 201, Grad norm: 1.2834795996497308\n",
      "Epoch 4326, Loss: 208.99643384057026, Neurons: 201, Grad norm: 1.8146549119363464\n",
      "Epoch 4326, Loss: 208.99643384057026, Neurons: 201, Grad norm: 1.8146549119363464\n",
      "Epoch 4327, Loss: 208.99627464921016, Neurons: 201, Grad norm: 2.5711344145387387\n",
      "Epoch 4327, Loss: 208.99627464921016, Neurons: 201, Grad norm: 2.5711344145387387\n",
      "Epoch 4328, Loss: 208.9961085595765, Neurons: 201, Grad norm: 3.4580192378028785\n",
      "Epoch 4328, Loss: 208.9961085595765, Neurons: 201, Grad norm: 3.4580192378028785\n",
      "Epoch 4329, Loss: 208.99599563171233, Neurons: 201, Grad norm: 4.685437539853332\n",
      "Epoch 4329, Loss: 208.99599563171233, Neurons: 201, Grad norm: 4.685437539853332\n",
      "Epoch 4330, Loss: 208.99594718856275, Neurons: 201, Grad norm: 5.589208831297308\n",
      "Epoch 4330, Loss: 208.99594718856275, Neurons: 201, Grad norm: 5.589208831297308\n",
      "Epoch 4331, Loss: 208.99591842495414, Neurons: 201, Grad norm: 6.655865892912104\n",
      "Epoch 4331, Loss: 208.99591842495414, Neurons: 201, Grad norm: 6.655865892912104\n",
      "Epoch 4332, Loss: 208.99593314400005, Neurons: 201, Grad norm: 7.001716175501611\n",
      "Epoch 4332, Loss: 208.99593314400005, Neurons: 201, Grad norm: 7.001716175501611\n",
      "Epoch 4333, Loss: 208.99586659866867, Neurons: 201, Grad norm: 7.060005932810884\n",
      "Epoch 4333, Loss: 208.99586659866867, Neurons: 201, Grad norm: 7.060005932810884\n",
      "Epoch 4334, Loss: 208.99574641595598, Neurons: 201, Grad norm: 6.161341438668844\n",
      "Epoch 4334, Loss: 208.99574641595598, Neurons: 201, Grad norm: 6.161341438668844\n",
      "Epoch 4335, Loss: 208.99548143843109, Neurons: 201, Grad norm: 4.389226124656201\n",
      "Epoch 4335, Loss: 208.99548143843109, Neurons: 201, Grad norm: 4.389226124656201\n",
      "Epoch 4336, Loss: 208.99506593239906, Neurons: 201, Grad norm: 2.195683048044225\n",
      "Epoch 4336, Loss: 208.99506593239906, Neurons: 201, Grad norm: 2.195683048044225\n",
      "Epoch 4337, Loss: 208.9946962521328, Neurons: 201, Grad norm: 0.6863727285769167\n",
      "Epoch 4337, Loss: 208.9946962521328, Neurons: 201, Grad norm: 0.6863727285769167\n",
      "Epoch 4338, Loss: 208.9944929848462, Neurons: 201, Grad norm: 2.7959819274707836\n",
      "Epoch 4338, Loss: 208.9944929848462, Neurons: 201, Grad norm: 2.7959819274707836\n",
      "Epoch 4339, Loss: 208.99447844423105, Neurons: 201, Grad norm: 4.597538852617268\n",
      "Epoch 4339, Loss: 208.99447844423105, Neurons: 201, Grad norm: 4.597538852617268\n",
      "Epoch 4340, Loss: 208.99457501087483, Neurons: 201, Grad norm: 6.1438650861425295\n",
      "Epoch 4340, Loss: 208.99457501087483, Neurons: 201, Grad norm: 6.1438650861425295\n",
      "Epoch 4341, Loss: 208.99467521322677, Neurons: 201, Grad norm: 6.714825854658988\n",
      "Epoch 4341, Loss: 208.99467521322677, Neurons: 201, Grad norm: 6.714825854658988\n",
      "Epoch 4342, Loss: 208.99468864720566, Neurons: 201, Grad norm: 7.153953482628456\n",
      "Epoch 4342, Loss: 208.99468864720566, Neurons: 201, Grad norm: 7.153953482628456\n",
      "Epoch 4343, Loss: 208.99457704918353, Neurons: 201, Grad norm: 6.406965702729611\n",
      "Epoch 4343, Loss: 208.99457704918353, Neurons: 201, Grad norm: 6.406965702729611\n",
      "Epoch 4344, Loss: 208.99436257059372, Neurons: 201, Grad norm: 5.182559322946038\n",
      "Epoch 4344, Loss: 208.99436257059372, Neurons: 201, Grad norm: 5.182559322946038\n",
      "Epoch 4345, Loss: 208.99395989100918, Neurons: 201, Grad norm: 3.4450720765988616\n",
      "Epoch 4345, Loss: 208.99395989100918, Neurons: 201, Grad norm: 3.4450720765988616\n",
      "Epoch 4346, Loss: 208.993547670972, Neurons: 201, Grad norm: 1.58931695792308\n",
      "Epoch 4346, Loss: 208.993547670972, Neurons: 201, Grad norm: 1.58931695792308\n",
      "Epoch 4347, Loss: 208.99326363428932, Neurons: 201, Grad norm: 0.5016047220702538\n",
      "Epoch 4347, Loss: 208.99326363428932, Neurons: 201, Grad norm: 0.5016047220702538\n",
      "Epoch 4348, Loss: 208.99308921610887, Neurons: 201, Grad norm: 2.1511966341540867\n",
      "Epoch 4348, Loss: 208.99308921610887, Neurons: 201, Grad norm: 2.1511966341540867\n",
      "Epoch 4349, Loss: 208.99299645327798, Neurons: 201, Grad norm: 4.049000449755132\n",
      "Epoch 4349, Loss: 208.99299645327798, Neurons: 201, Grad norm: 4.049000449755132\n",
      "Epoch 4350, Loss: 208.993015905905, Neurons: 201, Grad norm: 5.4236062991024\n",
      "Epoch 4350, Loss: 208.993015905905, Neurons: 201, Grad norm: 5.4236062991024\n",
      "Epoch 4351, Loss: 208.99309358229448, Neurons: 201, Grad norm: 6.6190884919736215\n",
      "Epoch 4351, Loss: 208.99309358229448, Neurons: 201, Grad norm: 6.6190884919736215\n",
      "Epoch 4352, Loss: 208.99315788271275, Neurons: 201, Grad norm: 6.585979049512265\n",
      "Epoch 4352, Loss: 208.99315788271275, Neurons: 201, Grad norm: 6.585979049512265\n",
      "Epoch 4353, Loss: 208.9930680254644, Neurons: 201, Grad norm: 6.167315459978154\n",
      "Epoch 4353, Loss: 208.9930680254644, Neurons: 201, Grad norm: 6.167315459978154\n",
      "Epoch 4354, Loss: 208.99278293864663, Neurons: 201, Grad norm: 4.774727366452387\n",
      "Epoch 4354, Loss: 208.99278293864663, Neurons: 201, Grad norm: 4.774727366452387\n",
      "Epoch 4355, Loss: 208.99241926878915, Neurons: 201, Grad norm: 3.113399370030234\n",
      "Epoch 4355, Loss: 208.99241926878915, Neurons: 201, Grad norm: 3.113399370030234\n",
      "Epoch 4356, Loss: 208.99206890274155, Neurons: 201, Grad norm: 1.4720492589267018\n",
      "Epoch 4356, Loss: 208.99206890274155, Neurons: 201, Grad norm: 1.4720492589267018\n",
      "Epoch 4357, Loss: 208.99181369248024, Neurons: 201, Grad norm: 0.5426099754013157\n",
      "Epoch 4357, Loss: 208.99181369248024, Neurons: 201, Grad norm: 0.5426099754013157\n",
      "Epoch 4358, Loss: 208.99167490354623, Neurons: 201, Grad norm: 1.988335020198558\n",
      "Epoch 4358, Loss: 208.99167490354623, Neurons: 201, Grad norm: 1.988335020198558\n",
      "Epoch 4359, Loss: 208.99156603906357, Neurons: 201, Grad norm: 3.1875991314409906\n",
      "Epoch 4359, Loss: 208.99156603906357, Neurons: 201, Grad norm: 3.1875991314409906\n",
      "Epoch 4360, Loss: 208.9915348725005, Neurons: 201, Grad norm: 4.872715603935286\n",
      "Epoch 4360, Loss: 208.9915348725005, Neurons: 201, Grad norm: 4.872715603935286\n",
      "Epoch 4361, Loss: 208.99157768612358, Neurons: 201, Grad norm: 6.003226332260891\n",
      "Epoch 4361, Loss: 208.99157768612358, Neurons: 201, Grad norm: 6.003226332260891\n",
      "Epoch 4362, Loss: 208.99167004322655, Neurons: 201, Grad norm: 6.834926918831923\n",
      "Epoch 4362, Loss: 208.99167004322655, Neurons: 201, Grad norm: 6.834926918831923\n",
      "Epoch 4363, Loss: 208.9917137264045, Neurons: 201, Grad norm: 6.523004242192795\n",
      "Epoch 4363, Loss: 208.9917137264045, Neurons: 201, Grad norm: 6.523004242192795\n",
      "Epoch 4364, Loss: 208.99152895273647, Neurons: 201, Grad norm: 5.377301568187403\n",
      "Epoch 4364, Loss: 208.99152895273647, Neurons: 201, Grad norm: 5.377301568187403\n",
      "Epoch 4365, Loss: 208.99116277055512, Neurons: 201, Grad norm: 3.6537256807500373\n",
      "Epoch 4365, Loss: 208.99116277055512, Neurons: 201, Grad norm: 3.6537256807500373\n",
      "Epoch 4366, Loss: 208.99075685456108, Neurons: 201, Grad norm: 1.647480350585107\n",
      "Epoch 4366, Loss: 208.99075685456108, Neurons: 201, Grad norm: 1.647480350585107\n",
      "Epoch 4367, Loss: 208.99045410041884, Neurons: 201, Grad norm: 0.652099402571299\n",
      "Epoch 4367, Loss: 208.99045410041884, Neurons: 201, Grad norm: 0.652099402571299\n",
      "Epoch 4368, Loss: 208.9902950134887, Neurons: 201, Grad norm: 2.216796420722597\n",
      "Epoch 4368, Loss: 208.9902950134887, Neurons: 201, Grad norm: 2.216796420722597\n",
      "Epoch 4369, Loss: 208.9902166701757, Neurons: 201, Grad norm: 4.015585503625265\n",
      "Epoch 4369, Loss: 208.9902166701757, Neurons: 201, Grad norm: 4.015585503625265\n",
      "Epoch 4370, Loss: 208.99026471302184, Neurons: 201, Grad norm: 5.314977840233593\n",
      "Epoch 4370, Loss: 208.99026471302184, Neurons: 201, Grad norm: 5.314977840233593\n",
      "Epoch 4371, Loss: 208.99033454063942, Neurons: 201, Grad norm: 6.5590623682936435\n",
      "Epoch 4371, Loss: 208.99033454063942, Neurons: 201, Grad norm: 6.5590623682936435\n",
      "Epoch 4372, Loss: 208.99041632565766, Neurons: 201, Grad norm: 6.631366951000653\n",
      "Epoch 4372, Loss: 208.99041632565766, Neurons: 201, Grad norm: 6.631366951000653\n",
      "Epoch 4373, Loss: 208.99035131984823, Neurons: 201, Grad norm: 6.546242802828476\n",
      "Epoch 4373, Loss: 208.99035131984823, Neurons: 201, Grad norm: 6.546242802828476\n",
      "Epoch 4374, Loss: 208.99012915614531, Neurons: 201, Grad norm: 5.542253677720147\n",
      "Epoch 4374, Loss: 208.99012915614531, Neurons: 201, Grad norm: 5.542253677720147\n",
      "Epoch 4375, Loss: 208.98983816310752, Neurons: 201, Grad norm: 4.308629190644973\n",
      "Epoch 4375, Loss: 208.98983816310752, Neurons: 201, Grad norm: 4.308629190644973\n",
      "Epoch 4376, Loss: 208.98952219376488, Neurons: 201, Grad norm: 2.790498420169344\n",
      "Epoch 4376, Loss: 208.98952219376488, Neurons: 201, Grad norm: 2.790498420169344\n",
      "Epoch 4377, Loss: 208.9892341272274, Neurons: 201, Grad norm: 1.210078088707168\n",
      "Epoch 4377, Loss: 208.9892341272274, Neurons: 201, Grad norm: 1.210078088707168\n",
      "Epoch 4378, Loss: 208.98900833195918, Neurons: 201, Grad norm: 0.8509031023239509\n",
      "Epoch 4378, Loss: 208.98900833195918, Neurons: 201, Grad norm: 0.8509031023239509\n",
      "Epoch 4379, Loss: 208.98885265590906, Neurons: 201, Grad norm: 2.2504977988917076\n",
      "Epoch 4379, Loss: 208.98885265590906, Neurons: 201, Grad norm: 2.2504977988917076\n",
      "Epoch 4380, Loss: 208.98880573187125, Neurons: 201, Grad norm: 3.362507985539903\n",
      "Epoch 4380, Loss: 208.98880573187125, Neurons: 201, Grad norm: 3.362507985539903\n",
      "Epoch 4381, Loss: 208.9887705909552, Neurons: 201, Grad norm: 4.286725842752408\n",
      "Epoch 4381, Loss: 208.9887705909552, Neurons: 201, Grad norm: 4.286725842752408\n",
      "Epoch 4382, Loss: 208.9887202002076, Neurons: 201, Grad norm: 5.096531129504096\n",
      "Epoch 4382, Loss: 208.9887202002076, Neurons: 201, Grad norm: 5.096531129504096\n",
      "Epoch 4383, Loss: 208.98867039066812, Neurons: 201, Grad norm: 5.253817761455765\n",
      "Epoch 4383, Loss: 208.98867039066812, Neurons: 201, Grad norm: 5.253817761455765\n",
      "Epoch 4384, Loss: 208.9886269285424, Neurons: 201, Grad norm: 5.761148851569986\n",
      "Epoch 4384, Loss: 208.9886269285424, Neurons: 201, Grad norm: 5.761148851569986\n",
      "Epoch 4385, Loss: 208.98854084429695, Neurons: 201, Grad norm: 5.268737687760443\n",
      "Epoch 4385, Loss: 208.98854084429695, Neurons: 201, Grad norm: 5.268737687760443\n",
      "Epoch 4386, Loss: 208.98835745314867, Neurons: 201, Grad norm: 4.808784869415065\n",
      "Epoch 4386, Loss: 208.98835745314867, Neurons: 201, Grad norm: 4.808784869415065\n",
      "Epoch 4387, Loss: 208.9881443108838, Neurons: 201, Grad norm: 3.7688904324317827\n",
      "Epoch 4387, Loss: 208.9881443108838, Neurons: 201, Grad norm: 3.7688904324317827\n",
      "Epoch 4388, Loss: 208.9878899047689, Neurons: 201, Grad norm: 2.6102737045298587\n",
      "Epoch 4388, Loss: 208.9878899047689, Neurons: 201, Grad norm: 2.6102737045298587\n",
      "Epoch 4389, Loss: 208.98761119755727, Neurons: 201, Grad norm: 1.3525880145301372\n",
      "Epoch 4389, Loss: 208.98761119755727, Neurons: 201, Grad norm: 1.3525880145301372\n",
      "Epoch 4390, Loss: 208.9874137428544, Neurons: 201, Grad norm: 0.6437343151505492\n",
      "Epoch 4390, Loss: 208.9874137428544, Neurons: 201, Grad norm: 0.6437343151505492\n",
      "Epoch 4391, Loss: 208.98729643019257, Neurons: 201, Grad norm: 1.2097418658910188\n",
      "Epoch 4391, Loss: 208.98729643019257, Neurons: 201, Grad norm: 1.2097418658910188\n",
      "Epoch 4392, Loss: 208.98716764194737, Neurons: 201, Grad norm: 2.189928343914218\n",
      "Epoch 4392, Loss: 208.98716764194737, Neurons: 201, Grad norm: 2.189928343914218\n",
      "Epoch 4393, Loss: 208.9870978088498, Neurons: 201, Grad norm: 3.0543257653549083\n",
      "Epoch 4393, Loss: 208.9870978088498, Neurons: 201, Grad norm: 3.0543257653549083\n",
      "Epoch 4394, Loss: 208.98701061762188, Neurons: 201, Grad norm: 3.3487597562768716\n",
      "Epoch 4394, Loss: 208.98701061762188, Neurons: 201, Grad norm: 3.3487597562768716\n",
      "Epoch 4395, Loss: 208.98693029664716, Neurons: 201, Grad norm: 3.894244855332181\n",
      "Epoch 4395, Loss: 208.98693029664716, Neurons: 201, Grad norm: 3.894244855332181\n",
      "Epoch 4396, Loss: 208.98682681253598, Neurons: 201, Grad norm: 3.7730245848883097\n",
      "Epoch 4396, Loss: 208.98682681253598, Neurons: 201, Grad norm: 3.7730245848883097\n",
      "Epoch 4397, Loss: 208.9867052420943, Neurons: 201, Grad norm: 3.8086845176352884\n",
      "Epoch 4397, Loss: 208.9867052420943, Neurons: 201, Grad norm: 3.8086845176352884\n",
      "Epoch 4398, Loss: 208.98658649066422, Neurons: 201, Grad norm: 3.278253073727507\n",
      "Epoch 4398, Loss: 208.98658649066422, Neurons: 201, Grad norm: 3.278253073727507\n",
      "Epoch 4399, Loss: 208.98639025728272, Neurons: 201, Grad norm: 2.70049382206523\n",
      "Epoch 4399, Loss: 208.98639025728272, Neurons: 201, Grad norm: 2.70049382206523\n",
      "Epoch 4400, Loss: 208.98620195540636, Neurons: 201, Grad norm: 2.100827288488209\n",
      "Epoch 4400, Loss: 208.98620195540636, Neurons: 201, Grad norm: 2.100827288488209\n",
      "Epoch 4401, Loss: 208.98602153132995, Neurons: 201, Grad norm: 1.7627771169717652\n",
      "Epoch 4401, Loss: 208.98602153132995, Neurons: 201, Grad norm: 1.7627771169717652\n",
      "Epoch 4402, Loss: 208.98587313285324, Neurons: 201, Grad norm: 1.476655632131129\n",
      "Epoch 4402, Loss: 208.98587313285324, Neurons: 201, Grad norm: 1.476655632131129\n",
      "Epoch 4403, Loss: 208.98573276600635, Neurons: 201, Grad norm: 1.3303462672639519\n",
      "Epoch 4403, Loss: 208.98573276600635, Neurons: 201, Grad norm: 1.3303462672639519\n",
      "Epoch 4404, Loss: 208.98559180696725, Neurons: 201, Grad norm: 1.2308419574572755\n",
      "Epoch 4404, Loss: 208.98559180696725, Neurons: 201, Grad norm: 1.2308419574572755\n",
      "Epoch 4405, Loss: 208.98544573036546, Neurons: 201, Grad norm: 1.0617270294917511\n",
      "Epoch 4405, Loss: 208.98544573036546, Neurons: 201, Grad norm: 1.0617270294917511\n",
      "Epoch 4406, Loss: 208.985341375008, Neurons: 201, Grad norm: 0.6447032719080574\n",
      "Epoch 4406, Loss: 208.985341375008, Neurons: 201, Grad norm: 0.6447032719080574\n",
      "Epoch 4407, Loss: 208.98518836285461, Neurons: 201, Grad norm: 0.647609346528957\n",
      "Epoch 4407, Loss: 208.98518836285461, Neurons: 201, Grad norm: 0.647609346528957\n",
      "Epoch 4408, Loss: 208.98505720849252, Neurons: 201, Grad norm: 0.6313890609178757\n",
      "Epoch 4408, Loss: 208.98505720849252, Neurons: 201, Grad norm: 0.6313890609178757\n",
      "Epoch 4409, Loss: 208.98493853513287, Neurons: 201, Grad norm: 0.59140854403108\n",
      "Epoch 4409, Loss: 208.98493853513287, Neurons: 201, Grad norm: 0.59140854403108\n",
      "Epoch 4410, Loss: 208.98481840542922, Neurons: 201, Grad norm: 0.783302233338479\n",
      "Epoch 4410, Loss: 208.98481840542922, Neurons: 201, Grad norm: 0.783302233338479\n",
      "Epoch 4411, Loss: 208.98467915843412, Neurons: 201, Grad norm: 1.1363504040348895\n",
      "Epoch 4411, Loss: 208.98467915843412, Neurons: 201, Grad norm: 1.1363504040348895\n",
      "Epoch 4412, Loss: 208.98455238137467, Neurons: 201, Grad norm: 1.6493398985135987\n",
      "Epoch 4412, Loss: 208.98455238137467, Neurons: 201, Grad norm: 1.6493398985135987\n",
      "Epoch 4413, Loss: 208.9844684314926, Neurons: 201, Grad norm: 2.3738858434512573\n",
      "Epoch 4413, Loss: 208.9844684314926, Neurons: 201, Grad norm: 2.3738858434512573\n",
      "Epoch 4414, Loss: 208.98438302104623, Neurons: 201, Grad norm: 3.6072669033707716\n",
      "Epoch 4414, Loss: 208.98438302104623, Neurons: 201, Grad norm: 3.6072669033707716\n",
      "Epoch 4415, Loss: 208.9843119757488, Neurons: 201, Grad norm: 4.660424803415242\n",
      "Epoch 4415, Loss: 208.9843119757488, Neurons: 201, Grad norm: 4.660424803415242\n",
      "Epoch 4416, Loss: 208.98436683477166, Neurons: 201, Grad norm: 6.010332025723981\n",
      "Epoch 4416, Loss: 208.98436683477166, Neurons: 201, Grad norm: 6.010332025723981\n",
      "Epoch 4417, Loss: 208.98446783492523, Neurons: 201, Grad norm: 6.89432838682069\n",
      "Epoch 4417, Loss: 208.98446783492523, Neurons: 201, Grad norm: 6.89432838682069\n",
      "Epoch 4418, Loss: 208.98454243701198, Neurons: 201, Grad norm: 7.342147403785246\n",
      "Epoch 4418, Loss: 208.98454243701198, Neurons: 201, Grad norm: 7.342147403785246\n",
      "Epoch 4419, Loss: 208.9845569018629, Neurons: 201, Grad norm: 6.930250133414368\n",
      "Epoch 4419, Loss: 208.9845569018629, Neurons: 201, Grad norm: 6.930250133414368\n",
      "Epoch 4420, Loss: 208.98432359433198, Neurons: 201, Grad norm: 5.738516186415307\n",
      "Epoch 4420, Loss: 208.98432359433198, Neurons: 201, Grad norm: 5.738516186415307\n",
      "Epoch 4421, Loss: 208.98394841278454, Neurons: 201, Grad norm: 3.6569462583929173\n",
      "Epoch 4421, Loss: 208.98394841278454, Neurons: 201, Grad norm: 3.6569462583929173\n",
      "Epoch 4422, Loss: 208.98349930650974, Neurons: 201, Grad norm: 1.5551193332429583\n",
      "Epoch 4422, Loss: 208.98349930650974, Neurons: 201, Grad norm: 1.5551193332429583\n",
      "Epoch 4423, Loss: 208.9831744486931, Neurons: 201, Grad norm: 0.7174924343637544\n",
      "Epoch 4423, Loss: 208.9831744486931, Neurons: 201, Grad norm: 0.7174924343637544\n",
      "Epoch 4424, Loss: 208.98302172354744, Neurons: 201, Grad norm: 2.321787028688349\n",
      "Epoch 4424, Loss: 208.98302172354744, Neurons: 201, Grad norm: 2.321787028688349\n",
      "Epoch 4425, Loss: 208.98298800181243, Neurons: 201, Grad norm: 3.893865944386477\n",
      "Epoch 4425, Loss: 208.98298800181243, Neurons: 201, Grad norm: 3.893865944386477\n",
      "Epoch 4426, Loss: 208.98298709162904, Neurons: 201, Grad norm: 4.960763476565042\n",
      "Epoch 4426, Loss: 208.98298709162904, Neurons: 201, Grad norm: 4.960763476565042\n",
      "Epoch 4427, Loss: 208.9830614478686, Neurons: 201, Grad norm: 6.085553127761194\n",
      "Epoch 4427, Loss: 208.9830614478686, Neurons: 201, Grad norm: 6.085553127761194\n",
      "Epoch 4428, Loss: 208.98305470531105, Neurons: 201, Grad norm: 6.48919987494226\n",
      "Epoch 4428, Loss: 208.98305470531105, Neurons: 201, Grad norm: 6.48919987494226\n",
      "Epoch 4429, Loss: 208.9830845474615, Neurons: 201, Grad norm: 6.770569380929429\n",
      "Epoch 4429, Loss: 208.9830845474615, Neurons: 201, Grad norm: 6.770569380929429\n",
      "Epoch 4430, Loss: 208.98297469999497, Neurons: 201, Grad norm: 6.225573903644583\n",
      "Epoch 4430, Loss: 208.98297469999497, Neurons: 201, Grad norm: 6.225573903644583\n",
      "Epoch 4431, Loss: 208.98276960346107, Neurons: 201, Grad norm: 5.310142544450384\n",
      "Epoch 4431, Loss: 208.98276960346107, Neurons: 201, Grad norm: 5.310142544450384\n",
      "Epoch 4432, Loss: 208.9824793173437, Neurons: 201, Grad norm: 3.607692729068346\n",
      "Epoch 4432, Loss: 208.9824793173437, Neurons: 201, Grad norm: 3.607692729068346\n",
      "Epoch 4433, Loss: 208.98212444489482, Neurons: 201, Grad norm: 1.8349810813830638\n",
      "Epoch 4433, Loss: 208.98212444489482, Neurons: 201, Grad norm: 1.8349810813830638\n",
      "Epoch 4434, Loss: 208.9818079038813, Neurons: 201, Grad norm: 0.5513350678294446\n",
      "Epoch 4434, Loss: 208.9818079038813, Neurons: 201, Grad norm: 0.5513350678294446\n",
      "Epoch 4435, Loss: 208.98163356856728, Neurons: 201, Grad norm: 2.2574902433499453\n",
      "Epoch 4435, Loss: 208.98163356856728, Neurons: 201, Grad norm: 2.2574902433499453\n",
      "Epoch 4436, Loss: 208.98157696757735, Neurons: 201, Grad norm: 4.077052102670191\n",
      "Epoch 4436, Loss: 208.98157696757735, Neurons: 201, Grad norm: 4.077052102670191\n",
      "Epoch 4437, Loss: 208.98164573263233, Neurons: 201, Grad norm: 5.502657088778135\n",
      "Epoch 4437, Loss: 208.98164573263233, Neurons: 201, Grad norm: 5.502657088778135\n",
      "Epoch 4438, Loss: 208.98177575100158, Neurons: 201, Grad norm: 6.704090344767229\n",
      "Epoch 4438, Loss: 208.98177575100158, Neurons: 201, Grad norm: 6.704090344767229\n",
      "Epoch 4439, Loss: 208.98183431069114, Neurons: 201, Grad norm: 7.259610092543056\n",
      "Epoch 4439, Loss: 208.98183431069114, Neurons: 201, Grad norm: 7.259610092543056\n",
      "Epoch 4440, Loss: 208.98185313670564, Neurons: 201, Grad norm: 7.402718332142093\n",
      "Epoch 4440, Loss: 208.98185313670564, Neurons: 201, Grad norm: 7.402718332142093\n",
      "Epoch 4441, Loss: 208.9817795304884, Neurons: 201, Grad norm: 6.50065693519984\n",
      "Epoch 4441, Loss: 208.9817795304884, Neurons: 201, Grad norm: 6.50065693519984\n",
      "Epoch 4442, Loss: 208.98148244282302, Neurons: 201, Grad norm: 5.326644450738116\n",
      "Epoch 4442, Loss: 208.98148244282302, Neurons: 201, Grad norm: 5.326644450738116\n",
      "Epoch 4443, Loss: 208.98111647467522, Neurons: 201, Grad norm: 3.2074666153151448\n",
      "Epoch 4443, Loss: 208.98111647467522, Neurons: 201, Grad norm: 3.2074666153151448\n",
      "Epoch 4444, Loss: 208.98068473902023, Neurons: 201, Grad norm: 1.1516570541050488\n",
      "Epoch 4444, Loss: 208.98068473902023, Neurons: 201, Grad norm: 1.1516570541050488\n",
      "Epoch 4445, Loss: 208.9803956696246, Neurons: 201, Grad norm: 1.3819954216353938\n",
      "Epoch 4445, Loss: 208.9803956696246, Neurons: 201, Grad norm: 1.3819954216353938\n",
      "Epoch 4446, Loss: 208.98026780171415, Neurons: 201, Grad norm: 3.143971235394265\n",
      "Epoch 4446, Loss: 208.98026780171415, Neurons: 201, Grad norm: 3.143971235394265\n",
      "Epoch 4447, Loss: 208.9802849312066, Neurons: 201, Grad norm: 4.985395570319684\n",
      "Epoch 4447, Loss: 208.9802849312066, Neurons: 201, Grad norm: 4.985395570319684\n",
      "Epoch 4448, Loss: 208.98032502782837, Neurons: 201, Grad norm: 6.254877234642564\n",
      "Epoch 4448, Loss: 208.98032502782837, Neurons: 201, Grad norm: 6.254877234642564\n",
      "Epoch 4449, Loss: 208.98048798568962, Neurons: 201, Grad norm: 7.501239553248255\n",
      "Epoch 4449, Loss: 208.98048798568962, Neurons: 201, Grad norm: 7.501239553248255\n",
      "Epoch 4450, Loss: 208.9805918445937, Neurons: 201, Grad norm: 7.496573422663046\n",
      "Epoch 4450, Loss: 208.9805918445937, Neurons: 201, Grad norm: 7.496573422663046\n",
      "Epoch 4451, Loss: 208.98055257736848, Neurons: 201, Grad norm: 6.914427963446457\n",
      "Epoch 4451, Loss: 208.98055257736848, Neurons: 201, Grad norm: 6.914427963446457\n",
      "Epoch 4452, Loss: 208.98025432586434, Neurons: 201, Grad norm: 5.285910525063731\n",
      "Epoch 4452, Loss: 208.98025432586434, Neurons: 201, Grad norm: 5.285910525063731\n",
      "Epoch 4453, Loss: 208.9798295243073, Neurons: 201, Grad norm: 3.1798551034932463\n",
      "Epoch 4453, Loss: 208.9798295243073, Neurons: 201, Grad norm: 3.1798551034932463\n",
      "Epoch 4454, Loss: 208.97938386290048, Neurons: 201, Grad norm: 0.8777430629751578\n",
      "Epoch 4454, Loss: 208.97938386290048, Neurons: 201, Grad norm: 0.8777430629751578\n",
      "Epoch 4455, Loss: 208.97908209013974, Neurons: 201, Grad norm: 1.53341736365672\n",
      "Epoch 4455, Loss: 208.97908209013974, Neurons: 201, Grad norm: 1.53341736365672\n",
      "Epoch 4456, Loss: 208.97899386800876, Neurons: 201, Grad norm: 3.819195349644113\n",
      "Epoch 4456, Loss: 208.97899386800876, Neurons: 201, Grad norm: 3.819195349644113\n",
      "Epoch 4457, Loss: 208.97903552857778, Neurons: 201, Grad norm: 5.331530127252614\n",
      "Epoch 4457, Loss: 208.97903552857778, Neurons: 201, Grad norm: 5.331530127252614\n",
      "Epoch 4458, Loss: 208.9791429120626, Neurons: 201, Grad norm: 6.552262256641066\n",
      "Epoch 4458, Loss: 208.9791429120626, Neurons: 201, Grad norm: 6.552262256641066\n",
      "Epoch 4459, Loss: 208.9792510066461, Neurons: 201, Grad norm: 6.916114435459701\n",
      "Epoch 4459, Loss: 208.9792510066461, Neurons: 201, Grad norm: 6.916114435459701\n",
      "Epoch 4460, Loss: 208.97916162055887, Neurons: 201, Grad norm: 6.574252023132269\n",
      "Epoch 4460, Loss: 208.97916162055887, Neurons: 201, Grad norm: 6.574252023132269\n",
      "Epoch 4461, Loss: 208.9789442438533, Neurons: 201, Grad norm: 5.186539855509502\n",
      "Epoch 4461, Loss: 208.9789442438533, Neurons: 201, Grad norm: 5.186539855509502\n",
      "Epoch 4462, Loss: 208.9785529121238, Neurons: 201, Grad norm: 3.2465160167588265\n",
      "Epoch 4462, Loss: 208.9785529121238, Neurons: 201, Grad norm: 3.2465160167588265\n",
      "Epoch 4463, Loss: 208.97815819484222, Neurons: 201, Grad norm: 1.1564355267878133\n",
      "Epoch 4463, Loss: 208.97815819484222, Neurons: 201, Grad norm: 1.1564355267878133\n",
      "Epoch 4464, Loss: 208.97786516417247, Neurons: 201, Grad norm: 1.1748826669191796\n",
      "Epoch 4464, Loss: 208.97786516417247, Neurons: 201, Grad norm: 1.1748826669191796\n",
      "Epoch 4465, Loss: 208.97772060310936, Neurons: 201, Grad norm: 3.601004681746683\n",
      "Epoch 4465, Loss: 208.97772060310936, Neurons: 201, Grad norm: 3.601004681746683\n",
      "Epoch 4466, Loss: 208.97773972534887, Neurons: 201, Grad norm: 5.408663841648026\n",
      "Epoch 4466, Loss: 208.97773972534887, Neurons: 201, Grad norm: 5.408663841648026\n",
      "Epoch 4467, Loss: 208.9778771452044, Neurons: 201, Grad norm: 7.121978300680536\n",
      "Epoch 4467, Loss: 208.9778771452044, Neurons: 201, Grad norm: 7.121978300680536\n",
      "Epoch 4468, Loss: 208.97809896766717, Neurons: 201, Grad norm: 7.455767872676244\n",
      "Epoch 4468, Loss: 208.97809896766717, Neurons: 201, Grad norm: 7.455767872676244\n",
      "Epoch 4469, Loss: 208.97810509007883, Neurons: 201, Grad norm: 6.547687452936202\n",
      "Epoch 4469, Loss: 208.97810509007883, Neurons: 201, Grad norm: 6.547687452936202\n",
      "Epoch 4470, Loss: 208.97778416785386, Neurons: 201, Grad norm: 4.710802328582005\n",
      "Epoch 4470, Loss: 208.97778416785386, Neurons: 201, Grad norm: 4.710802328582005\n",
      "Epoch 4471, Loss: 208.97730251050484, Neurons: 201, Grad norm: 2.1905582780335293\n",
      "Epoch 4471, Loss: 208.97730251050484, Neurons: 201, Grad norm: 2.1905582780335293\n",
      "Epoch 4472, Loss: 208.97690107315012, Neurons: 201, Grad norm: 0.6047199145039157\n",
      "Epoch 4472, Loss: 208.97690107315012, Neurons: 201, Grad norm: 0.6047199145039157\n",
      "Epoch 4473, Loss: 208.97667867233818, Neurons: 201, Grad norm: 2.2043930275912613\n",
      "Epoch 4473, Loss: 208.97667867233818, Neurons: 201, Grad norm: 2.2043930275912613\n",
      "Epoch 4474, Loss: 208.97664944598813, Neurons: 201, Grad norm: 4.452165680920743\n",
      "Epoch 4474, Loss: 208.97664944598813, Neurons: 201, Grad norm: 4.452165680920743\n",
      "Epoch 4475, Loss: 208.97674604787926, Neurons: 201, Grad norm: 5.773892104308619\n",
      "Epoch 4475, Loss: 208.97674604787926, Neurons: 201, Grad norm: 5.773892104308619\n",
      "Epoch 4476, Loss: 208.97686949848062, Neurons: 201, Grad norm: 6.957633143707074\n",
      "Epoch 4476, Loss: 208.97686949848062, Neurons: 201, Grad norm: 6.957633143707074\n",
      "Epoch 4477, Loss: 208.9769528382846, Neurons: 201, Grad norm: 6.9964194534841795\n",
      "Epoch 4477, Loss: 208.9769528382846, Neurons: 201, Grad norm: 6.9964194534841795\n",
      "Epoch 4478, Loss: 208.97687700097336, Neurons: 201, Grad norm: 6.26744080706853\n",
      "Epoch 4478, Loss: 208.97687700097336, Neurons: 201, Grad norm: 6.26744080706853\n",
      "Epoch 4479, Loss: 208.97660414850665, Neurons: 201, Grad norm: 4.941162506119132\n",
      "Epoch 4479, Loss: 208.97660414850665, Neurons: 201, Grad norm: 4.941162506119132\n",
      "Epoch 4480, Loss: 208.97621853049066, Neurons: 201, Grad norm: 3.1846351232876184\n",
      "Epoch 4480, Loss: 208.97621853049066, Neurons: 201, Grad norm: 3.1846351232876184\n",
      "Epoch 4481, Loss: 208.97587376211814, Neurons: 201, Grad norm: 1.4772420013759093\n",
      "Epoch 4481, Loss: 208.97587376211814, Neurons: 201, Grad norm: 1.4772420013759093\n",
      "Epoch 4482, Loss: 208.97561780347237, Neurons: 201, Grad norm: 0.5665261634988975\n",
      "Epoch 4482, Loss: 208.97561780347237, Neurons: 201, Grad norm: 0.5665261634988975\n",
      "Epoch 4483, Loss: 208.9754735838681, Neurons: 201, Grad norm: 1.9646108623264016\n",
      "Epoch 4483, Loss: 208.9754735838681, Neurons: 201, Grad norm: 1.9646108623264016\n",
      "Epoch 4484, Loss: 208.97538342702472, Neurons: 201, Grad norm: 3.133826753938391\n",
      "Epoch 4484, Loss: 208.97538342702472, Neurons: 201, Grad norm: 3.133826753938391\n",
      "Epoch 4485, Loss: 208.97535742274812, Neurons: 201, Grad norm: 4.405566469878224\n",
      "Epoch 4485, Loss: 208.97535742274812, Neurons: 201, Grad norm: 4.405566469878224\n",
      "Epoch 4486, Loss: 208.97539698690446, Neurons: 201, Grad norm: 5.413435459882409\n",
      "Epoch 4486, Loss: 208.97539698690446, Neurons: 201, Grad norm: 5.413435459882409\n",
      "Epoch 4487, Loss: 208.97541764773385, Neurons: 201, Grad norm: 6.207608798182747\n",
      "Epoch 4487, Loss: 208.97541764773385, Neurons: 201, Grad norm: 6.207608798182747\n",
      "Epoch 4488, Loss: 208.9754398841612, Neurons: 201, Grad norm: 6.405980448893901\n",
      "Epoch 4488, Loss: 208.9754398841612, Neurons: 201, Grad norm: 6.405980448893901\n",
      "Epoch 4489, Loss: 208.9754024875637, Neurons: 201, Grad norm: 6.406178011683956\n",
      "Epoch 4489, Loss: 208.9754024875637, Neurons: 201, Grad norm: 6.406178011683956\n",
      "Epoch 4490, Loss: 208.9752596950309, Neurons: 201, Grad norm: 5.487763455964658\n",
      "Epoch 4490, Loss: 208.9752596950309, Neurons: 201, Grad norm: 5.487763455964658\n",
      "Epoch 4491, Loss: 208.97495962408746, Neurons: 201, Grad norm: 4.038622798818634\n",
      "Epoch 4491, Loss: 208.97495962408746, Neurons: 201, Grad norm: 4.038622798818634\n",
      "Epoch 4492, Loss: 208.9746276087892, Neurons: 201, Grad norm: 2.3715377544842124\n",
      "Epoch 4492, Loss: 208.9746276087892, Neurons: 201, Grad norm: 2.3715377544842124\n",
      "Epoch 4493, Loss: 208.97432798522254, Neurons: 201, Grad norm: 0.7562649350719916\n",
      "Epoch 4493, Loss: 208.97432798522254, Neurons: 201, Grad norm: 0.7562649350719916\n",
      "Epoch 4494, Loss: 208.9741424821377, Neurons: 201, Grad norm: 1.3978235391622382\n",
      "Epoch 4494, Loss: 208.9741424821377, Neurons: 201, Grad norm: 1.3978235391622382\n",
      "Epoch 4495, Loss: 208.97403407367685, Neurons: 201, Grad norm: 2.6836569002792316\n",
      "Epoch 4495, Loss: 208.97403407367685, Neurons: 201, Grad norm: 2.6836569002792316\n",
      "Epoch 4496, Loss: 208.9740160812373, Neurons: 201, Grad norm: 4.567695634936815\n",
      "Epoch 4496, Loss: 208.9740160812373, Neurons: 201, Grad norm: 4.567695634936815\n",
      "Epoch 4497, Loss: 208.97403848716405, Neurons: 201, Grad norm: 5.903528651087055\n",
      "Epoch 4497, Loss: 208.97403848716405, Neurons: 201, Grad norm: 5.903528651087055\n",
      "Epoch 4498, Loss: 208.97420806905276, Neurons: 201, Grad norm: 6.963942799212253\n",
      "Epoch 4498, Loss: 208.97420806905276, Neurons: 201, Grad norm: 6.963942799212253\n",
      "Epoch 4499, Loss: 208.97431290594253, Neurons: 201, Grad norm: 7.254427384533879\n",
      "Epoch 4499, Loss: 208.97431290594253, Neurons: 201, Grad norm: 7.254427384533879\n",
      "Epoch 4500, Loss: 208.97423552905266, Neurons: 201, Grad norm: 6.7727584349948735\n",
      "Epoch 4500, Loss: 208.97423552905266, Neurons: 201, Grad norm: 6.7727584349948735\n",
      "Epoch 4501, Loss: 208.97401596877606, Neurons: 201, Grad norm: 5.462495066513046\n",
      "Epoch 4501, Loss: 208.97401596877606, Neurons: 201, Grad norm: 5.462495066513046\n",
      "Epoch 4502, Loss: 208.97363553103233, Neurons: 201, Grad norm: 3.7419459159367294\n",
      "Epoch 4502, Loss: 208.97363553103233, Neurons: 201, Grad norm: 3.7419459159367294\n",
      "Epoch 4503, Loss: 208.9732943207742, Neurons: 201, Grad norm: 1.6671502795144775\n",
      "Epoch 4503, Loss: 208.9732943207742, Neurons: 201, Grad norm: 1.6671502795144775\n",
      "Epoch 4504, Loss: 208.97298178490257, Neurons: 201, Grad norm: 0.7810966391413852\n",
      "Epoch 4504, Loss: 208.97298178490257, Neurons: 201, Grad norm: 0.7810966391413852\n",
      "Epoch 4505, Loss: 208.97285389977844, Neurons: 201, Grad norm: 2.2675658212081236\n",
      "Epoch 4505, Loss: 208.97285389977844, Neurons: 201, Grad norm: 2.2675658212081236\n",
      "Epoch 4506, Loss: 208.97277467801172, Neurons: 201, Grad norm: 3.8925919984588186\n",
      "Epoch 4506, Loss: 208.97277467801172, Neurons: 201, Grad norm: 3.8925919984588186\n",
      "Epoch 4507, Loss: 208.97283211149187, Neurons: 201, Grad norm: 5.350445987380714\n",
      "Epoch 4507, Loss: 208.97283211149187, Neurons: 201, Grad norm: 5.350445987380714\n",
      "Epoch 4508, Loss: 208.97291518463422, Neurons: 201, Grad norm: 6.066081344756749\n",
      "Epoch 4508, Loss: 208.97291518463422, Neurons: 201, Grad norm: 6.066081344756749\n",
      "Epoch 4509, Loss: 208.97295346125222, Neurons: 201, Grad norm: 6.3853250561905694\n",
      "Epoch 4509, Loss: 208.97295346125222, Neurons: 201, Grad norm: 6.3853250561905694\n",
      "Epoch 4510, Loss: 208.97285869943352, Neurons: 201, Grad norm: 5.7003296241015\n",
      "Epoch 4510, Loss: 208.97285869943352, Neurons: 201, Grad norm: 5.7003296241015\n",
      "Epoch 4511, Loss: 208.97263797117424, Neurons: 201, Grad norm: 4.7077911274584565\n",
      "Epoch 4511, Loss: 208.97263797117424, Neurons: 201, Grad norm: 4.7077911274584565\n",
      "Epoch 4512, Loss: 208.972316906346, Neurons: 201, Grad norm: 3.443791702871366\n",
      "Epoch 4512, Loss: 208.972316906346, Neurons: 201, Grad norm: 3.443791702871366\n",
      "Epoch 4513, Loss: 208.9720395496311, Neurons: 201, Grad norm: 2.2930002068881166\n",
      "Epoch 4513, Loss: 208.9720395496311, Neurons: 201, Grad norm: 2.2930002068881166\n",
      "Epoch 4514, Loss: 208.97183366646337, Neurons: 201, Grad norm: 1.1653685222189714\n",
      "Epoch 4514, Loss: 208.97183366646337, Neurons: 201, Grad norm: 1.1653685222189714\n",
      "Epoch 4515, Loss: 208.97167502170595, Neurons: 201, Grad norm: 0.5906692351603848\n",
      "Epoch 4515, Loss: 208.97167502170595, Neurons: 201, Grad norm: 0.5906692351603848\n",
      "Epoch 4516, Loss: 208.97152157529433, Neurons: 201, Grad norm: 0.7744130482281149\n",
      "Epoch 4516, Loss: 208.97152157529433, Neurons: 201, Grad norm: 0.7744130482281149\n",
      "Epoch 4517, Loss: 208.97142031587936, Neurons: 201, Grad norm: 1.2305124473355689\n",
      "Epoch 4517, Loss: 208.97142031587936, Neurons: 201, Grad norm: 1.2305124473355689\n",
      "Epoch 4518, Loss: 208.97130532852663, Neurons: 201, Grad norm: 1.8357319777857786\n",
      "Epoch 4518, Loss: 208.97130532852663, Neurons: 201, Grad norm: 1.8357319777857786\n",
      "Epoch 4519, Loss: 208.97121378635526, Neurons: 201, Grad norm: 2.494148711883931\n",
      "Epoch 4519, Loss: 208.97121378635526, Neurons: 201, Grad norm: 2.494148711883931\n",
      "Epoch 4520, Loss: 208.97115535343895, Neurons: 201, Grad norm: 3.4881665395465307\n",
      "Epoch 4520, Loss: 208.97115535343895, Neurons: 201, Grad norm: 3.4881665395465307\n",
      "Epoch 4521, Loss: 208.97109775358743, Neurons: 201, Grad norm: 4.111825071562864\n",
      "Epoch 4521, Loss: 208.97109775358743, Neurons: 201, Grad norm: 4.111825071562864\n",
      "Epoch 4522, Loss: 208.97105128734978, Neurons: 201, Grad norm: 5.05449996453876\n",
      "Epoch 4522, Loss: 208.97105128734978, Neurons: 201, Grad norm: 5.05449996453876\n",
      "Epoch 4523, Loss: 208.97105548813363, Neurons: 201, Grad norm: 5.71590874982168\n",
      "Epoch 4523, Loss: 208.97105548813363, Neurons: 201, Grad norm: 5.71590874982168\n",
      "Epoch 4524, Loss: 208.97109295616502, Neurons: 201, Grad norm: 6.331597766471081\n",
      "Epoch 4524, Loss: 208.97109295616502, Neurons: 201, Grad norm: 6.331597766471081\n",
      "Epoch 4525, Loss: 208.97107536239358, Neurons: 201, Grad norm: 6.459473885025183\n",
      "Epoch 4525, Loss: 208.97107536239358, Neurons: 201, Grad norm: 6.459473885025183\n",
      "Epoch 4526, Loss: 208.9710063425824, Neurons: 201, Grad norm: 6.0235558145600505\n",
      "Epoch 4526, Loss: 208.9710063425824, Neurons: 201, Grad norm: 6.0235558145600505\n",
      "Epoch 4527, Loss: 208.97082890482682, Neurons: 201, Grad norm: 4.739704008169203\n",
      "Epoch 4527, Loss: 208.97082890482682, Neurons: 201, Grad norm: 4.739704008169203\n",
      "Epoch 4528, Loss: 208.9705174885526, Neurons: 201, Grad norm: 3.31960775522231\n",
      "Epoch 4528, Loss: 208.9705174885526, Neurons: 201, Grad norm: 3.31960775522231\n",
      "Epoch 4529, Loss: 208.97017312126644, Neurons: 201, Grad norm: 1.7987733374121069\n",
      "Epoch 4529, Loss: 208.97017312126644, Neurons: 201, Grad norm: 1.7987733374121069\n",
      "Epoch 4530, Loss: 208.96994196681305, Neurons: 201, Grad norm: 0.5447754212450943\n",
      "Epoch 4530, Loss: 208.96994196681305, Neurons: 201, Grad norm: 0.5447754212450943\n",
      "Epoch 4531, Loss: 208.96975328890068, Neurons: 201, Grad norm: 1.7819269725189861\n",
      "Epoch 4531, Loss: 208.96975328890068, Neurons: 201, Grad norm: 1.7819269725189861\n",
      "Epoch 4532, Loss: 208.96971242879636, Neurons: 201, Grad norm: 3.3043332541165307\n",
      "Epoch 4532, Loss: 208.96971242879636, Neurons: 201, Grad norm: 3.3043332541165307\n",
      "Epoch 4533, Loss: 208.96974344916157, Neurons: 201, Grad norm: 5.197849689663156\n",
      "Epoch 4533, Loss: 208.96974344916157, Neurons: 201, Grad norm: 5.197849689663156\n",
      "Epoch 4534, Loss: 208.96981135833784, Neurons: 201, Grad norm: 6.486619185773014\n",
      "Epoch 4534, Loss: 208.96981135833784, Neurons: 201, Grad norm: 6.486619185773014\n",
      "Epoch 4535, Loss: 208.96993017049238, Neurons: 201, Grad norm: 7.732170950743263\n",
      "Epoch 4535, Loss: 208.96993017049238, Neurons: 201, Grad norm: 7.732170950743263\n",
      "Epoch 4536, Loss: 208.97017195281578, Neurons: 201, Grad norm: 7.687726609047175\n",
      "Epoch 4536, Loss: 208.97017195281578, Neurons: 201, Grad norm: 7.687726609047175\n",
      "Epoch 4537, Loss: 208.9700938319891, Neurons: 201, Grad norm: 6.784321861264154\n",
      "Epoch 4537, Loss: 208.9700938319891, Neurons: 201, Grad norm: 6.784321861264154\n",
      "Epoch 4538, Loss: 208.96968229024873, Neurons: 201, Grad norm: 4.72820367168559\n",
      "Epoch 4538, Loss: 208.96968229024873, Neurons: 201, Grad norm: 4.72820367168559\n",
      "Epoch 4539, Loss: 208.9692433546212, Neurons: 201, Grad norm: 2.1237879252131546\n",
      "Epoch 4539, Loss: 208.9692433546212, Neurons: 201, Grad norm: 2.1237879252131546\n",
      "Epoch 4540, Loss: 208.9688509080547, Neurons: 201, Grad norm: 0.8365916350619896\n",
      "Epoch 4540, Loss: 208.9688509080547, Neurons: 201, Grad norm: 0.8365916350619896\n",
      "Epoch 4541, Loss: 208.96866541595796, Neurons: 201, Grad norm: 3.3431226947294927\n",
      "Epoch 4541, Loss: 208.96866541595796, Neurons: 201, Grad norm: 3.3431226947294927\n",
      "Epoch 4542, Loss: 208.96871475177804, Neurons: 201, Grad norm: 5.220283939078194\n",
      "Epoch 4542, Loss: 208.96871475177804, Neurons: 201, Grad norm: 5.220283939078194\n",
      "Epoch 4543, Loss: 208.96887363339914, Neurons: 201, Grad norm: 6.235207691946085\n",
      "Epoch 4543, Loss: 208.96887363339914, Neurons: 201, Grad norm: 6.235207691946085\n",
      "Epoch 4544, Loss: 208.96891690012856, Neurons: 201, Grad norm: 6.5807589182030295\n",
      "Epoch 4544, Loss: 208.96891690012856, Neurons: 201, Grad norm: 6.5807589182030295\n",
      "Epoch 4545, Loss: 208.96879619519152, Neurons: 201, Grad norm: 5.864994162547077\n",
      "Epoch 4545, Loss: 208.96879619519152, Neurons: 201, Grad norm: 5.864994162547077\n",
      "Epoch 4546, Loss: 208.9686243185225, Neurons: 201, Grad norm: 5.182790072682129\n",
      "Epoch 4546, Loss: 208.9686243185225, Neurons: 201, Grad norm: 5.182790072682129\n",
      "Epoch 4547, Loss: 208.96834088052563, Neurons: 201, Grad norm: 3.6927937048833774\n",
      "Epoch 4547, Loss: 208.96834088052563, Neurons: 201, Grad norm: 3.6927937048833774\n",
      "Epoch 4548, Loss: 208.96805535651916, Neurons: 201, Grad norm: 2.0962940452277383\n",
      "Epoch 4548, Loss: 208.96805535651916, Neurons: 201, Grad norm: 2.0962940452277383\n",
      "Epoch 4549, Loss: 208.96780687254136, Neurons: 201, Grad norm: 0.5841778278236256\n",
      "Epoch 4549, Loss: 208.96780687254136, Neurons: 201, Grad norm: 0.5841778278236256\n",
      "Epoch 4550, Loss: 208.96762227650024, Neurons: 201, Grad norm: 1.9770359872329817\n",
      "Epoch 4550, Loss: 208.96762227650024, Neurons: 201, Grad norm: 1.9770359872329817\n",
      "Epoch 4551, Loss: 208.9675531583924, Neurons: 201, Grad norm: 3.916421404052887\n",
      "Epoch 4551, Loss: 208.9675531583924, Neurons: 201, Grad norm: 3.916421404052887\n",
      "Epoch 4552, Loss: 208.96761433342502, Neurons: 201, Grad norm: 5.37549515939873\n",
      "Epoch 4552, Loss: 208.96761433342502, Neurons: 201, Grad norm: 5.37549515939873\n",
      "Epoch 4553, Loss: 208.96772400192177, Neurons: 201, Grad norm: 6.072809267341316\n",
      "Epoch 4553, Loss: 208.96772400192177, Neurons: 201, Grad norm: 6.072809267341316\n",
      "Epoch 4554, Loss: 208.9677469794175, Neurons: 201, Grad norm: 5.953165149909961\n",
      "Epoch 4554, Loss: 208.9677469794175, Neurons: 201, Grad norm: 5.953165149909961\n",
      "Epoch 4555, Loss: 208.9676150357023, Neurons: 201, Grad norm: 5.113526348837771\n",
      "Epoch 4555, Loss: 208.9676150357023, Neurons: 201, Grad norm: 5.113526348837771\n",
      "Epoch 4556, Loss: 208.96731763675996, Neurons: 201, Grad norm: 3.778014210392607\n",
      "Epoch 4556, Loss: 208.96731763675996, Neurons: 201, Grad norm: 3.778014210392607\n",
      "Epoch 4557, Loss: 208.96703155151363, Neurons: 201, Grad norm: 2.502568621625379\n",
      "Epoch 4557, Loss: 208.96703155151363, Neurons: 201, Grad norm: 2.502568621625379\n",
      "Epoch 4558, Loss: 208.9668133004077, Neurons: 201, Grad norm: 1.199624459202701\n",
      "Epoch 4558, Loss: 208.9668133004077, Neurons: 201, Grad norm: 1.199624459202701\n",
      "Epoch 4559, Loss: 208.96663273707577, Neurons: 201, Grad norm: 0.5893979450463024\n",
      "Epoch 4559, Loss: 208.96663273707577, Neurons: 201, Grad norm: 0.5893979450463024\n",
      "Epoch 4560, Loss: 208.9664887735958, Neurons: 201, Grad norm: 1.4588002705462837\n",
      "Epoch 4560, Loss: 208.9664887735958, Neurons: 201, Grad norm: 1.4588002705462837\n",
      "Epoch 4561, Loss: 208.96639691516606, Neurons: 201, Grad norm: 2.371432729761783\n",
      "Epoch 4561, Loss: 208.96639691516606, Neurons: 201, Grad norm: 2.371432729761783\n",
      "Epoch 4562, Loss: 208.9663400933798, Neurons: 201, Grad norm: 3.4154324316834876\n",
      "Epoch 4562, Loss: 208.9663400933798, Neurons: 201, Grad norm: 3.4154324316834876\n",
      "Epoch 4563, Loss: 208.96632301833722, Neurons: 201, Grad norm: 4.2225605485594855\n",
      "Epoch 4563, Loss: 208.96632301833722, Neurons: 201, Grad norm: 4.2225605485594855\n",
      "Epoch 4564, Loss: 208.9663251839678, Neurons: 201, Grad norm: 4.7998970457277235\n",
      "Epoch 4564, Loss: 208.9663251839678, Neurons: 201, Grad norm: 4.7998970457277235\n",
      "Epoch 4565, Loss: 208.96628609368454, Neurons: 201, Grad norm: 5.008678060950856\n",
      "Epoch 4565, Loss: 208.96628609368454, Neurons: 201, Grad norm: 5.008678060950856\n",
      "Epoch 4566, Loss: 208.96624255904604, Neurons: 201, Grad norm: 5.066109667370169\n",
      "Epoch 4566, Loss: 208.96624255904604, Neurons: 201, Grad norm: 5.066109667370169\n",
      "Epoch 4567, Loss: 208.96609996415603, Neurons: 201, Grad norm: 4.673702138863743\n",
      "Epoch 4567, Loss: 208.96609996415603, Neurons: 201, Grad norm: 4.673702138863743\n",
      "Epoch 4568, Loss: 208.96592890539483, Neurons: 201, Grad norm: 4.496447009626026\n",
      "Epoch 4568, Loss: 208.96592890539483, Neurons: 201, Grad norm: 4.496447009626026\n",
      "Epoch 4569, Loss: 208.96579308415215, Neurons: 201, Grad norm: 4.02972454777351\n",
      "Epoch 4569, Loss: 208.96579308415215, Neurons: 201, Grad norm: 4.02972454777351\n",
      "Epoch 4570, Loss: 208.96563872856865, Neurons: 201, Grad norm: 3.3187769354070977\n",
      "Epoch 4570, Loss: 208.96563872856865, Neurons: 201, Grad norm: 3.3187769354070977\n",
      "Epoch 4571, Loss: 208.96545589383342, Neurons: 201, Grad norm: 2.5892497482782333\n",
      "Epoch 4571, Loss: 208.96545589383342, Neurons: 201, Grad norm: 2.5892497482782333\n",
      "Epoch 4572, Loss: 208.96526741165613, Neurons: 201, Grad norm: 1.695549019793719\n",
      "Epoch 4572, Loss: 208.96526741165613, Neurons: 201, Grad norm: 1.695549019793719\n",
      "Epoch 4573, Loss: 208.96509533416, Neurons: 201, Grad norm: 1.0598625883824722\n",
      "Epoch 4573, Loss: 208.96509533416, Neurons: 201, Grad norm: 1.0598625883824722\n",
      "Epoch 4574, Loss: 208.96495208857834, Neurons: 201, Grad norm: 0.48779361913742664\n",
      "Epoch 4574, Loss: 208.96495208857834, Neurons: 201, Grad norm: 0.48779361913742664\n",
      "Epoch 4575, Loss: 208.96483299830777, Neurons: 201, Grad norm: 0.641458590557211\n",
      "Epoch 4575, Loss: 208.96483299830777, Neurons: 201, Grad norm: 0.641458590557211\n",
      "Epoch 4576, Loss: 208.96471415567504, Neurons: 201, Grad norm: 1.038256338359542\n",
      "Epoch 4576, Loss: 208.96471415567504, Neurons: 201, Grad norm: 1.038256338359542\n",
      "Epoch 4577, Loss: 208.96461347731477, Neurons: 201, Grad norm: 1.6811925693596772\n",
      "Epoch 4577, Loss: 208.96461347731477, Neurons: 201, Grad norm: 1.6811925693596772\n",
      "Epoch 4578, Loss: 208.96451689533257, Neurons: 201, Grad norm: 2.0529913317802144\n",
      "Epoch 4578, Loss: 208.96451689533257, Neurons: 201, Grad norm: 2.0529913317802144\n",
      "Epoch 4579, Loss: 208.9644661758302, Neurons: 201, Grad norm: 2.7854188974617604\n",
      "Epoch 4579, Loss: 208.9644661758302, Neurons: 201, Grad norm: 2.7854188974617604\n",
      "Epoch 4580, Loss: 208.96436877791132, Neurons: 201, Grad norm: 2.9583449307940173\n",
      "Epoch 4580, Loss: 208.96436877791132, Neurons: 201, Grad norm: 2.9583449307940173\n",
      "Epoch 4581, Loss: 208.9642968967811, Neurons: 201, Grad norm: 3.853713661637772\n",
      "Epoch 4581, Loss: 208.9642968967811, Neurons: 201, Grad norm: 3.853713661637772\n",
      "Epoch 4582, Loss: 208.96425123519165, Neurons: 201, Grad norm: 4.272257350751315\n",
      "Epoch 4582, Loss: 208.96425123519165, Neurons: 201, Grad norm: 4.272257350751315\n",
      "Epoch 4583, Loss: 208.96425395861002, Neurons: 201, Grad norm: 4.789645972750278\n",
      "Epoch 4583, Loss: 208.96425395861002, Neurons: 201, Grad norm: 4.789645972750278\n",
      "Epoch 4584, Loss: 208.9642266778975, Neurons: 201, Grad norm: 5.099031653689443\n",
      "Epoch 4584, Loss: 208.9642266778975, Neurons: 201, Grad norm: 5.099031653689443\n",
      "Epoch 4585, Loss: 208.96413435580598, Neurons: 201, Grad norm: 5.117315693854917\n",
      "Epoch 4585, Loss: 208.96413435580598, Neurons: 201, Grad norm: 5.117315693854917\n",
      "Epoch 4586, Loss: 208.96404711463285, Neurons: 201, Grad norm: 5.044815319060329\n",
      "Epoch 4586, Loss: 208.96404711463285, Neurons: 201, Grad norm: 5.044815319060329\n",
      "Epoch 4587, Loss: 208.96387934891695, Neurons: 201, Grad norm: 4.653743117336465\n",
      "Epoch 4587, Loss: 208.96387934891695, Neurons: 201, Grad norm: 4.653743117336465\n",
      "Epoch 4588, Loss: 208.96372231208207, Neurons: 201, Grad norm: 3.973926491911767\n",
      "Epoch 4588, Loss: 208.96372231208207, Neurons: 201, Grad norm: 3.973926491911767\n",
      "Epoch 4589, Loss: 208.96349492577818, Neurons: 201, Grad norm: 3.157523581850674\n",
      "Epoch 4589, Loss: 208.96349492577818, Neurons: 201, Grad norm: 3.157523581850674\n",
      "Epoch 4590, Loss: 208.9633035029995, Neurons: 201, Grad norm: 1.9511184249835862\n",
      "Epoch 4590, Loss: 208.9633035029995, Neurons: 201, Grad norm: 1.9511184249835862\n",
      "Epoch 4591, Loss: 208.9631066600525, Neurons: 201, Grad norm: 0.9000841443985621\n",
      "Epoch 4591, Loss: 208.9631066600525, Neurons: 201, Grad norm: 0.9000841443985621\n",
      "Epoch 4592, Loss: 208.96290359633645, Neurons: 201, Grad norm: 0.7055010131576227\n",
      "Epoch 4592, Loss: 208.96290359633645, Neurons: 201, Grad norm: 0.7055010131576227\n",
      "Epoch 4593, Loss: 208.96277880918927, Neurons: 201, Grad norm: 1.198438577388009\n",
      "Epoch 4593, Loss: 208.96277880918927, Neurons: 201, Grad norm: 1.198438577388009\n",
      "Epoch 4594, Loss: 208.9626567244899, Neurons: 201, Grad norm: 2.250600309723933\n",
      "Epoch 4594, Loss: 208.9626567244899, Neurons: 201, Grad norm: 2.250600309723933\n",
      "Epoch 4595, Loss: 208.9625700223565, Neurons: 201, Grad norm: 3.2430069169088536\n",
      "Epoch 4595, Loss: 208.9625700223565, Neurons: 201, Grad norm: 3.2430069169088536\n",
      "Epoch 4596, Loss: 208.9625534892904, Neurons: 201, Grad norm: 4.1887348856907884\n",
      "Epoch 4596, Loss: 208.9625534892904, Neurons: 201, Grad norm: 4.1887348856907884\n",
      "Epoch 4597, Loss: 208.96254707369087, Neurons: 201, Grad norm: 5.069596942518544\n",
      "Epoch 4597, Loss: 208.96254707369087, Neurons: 201, Grad norm: 5.069596942518544\n",
      "Epoch 4598, Loss: 208.96252954220597, Neurons: 201, Grad norm: 5.767645799895602\n",
      "Epoch 4598, Loss: 208.96252954220597, Neurons: 201, Grad norm: 5.767645799895602\n",
      "Epoch 4599, Loss: 208.96251953657807, Neurons: 201, Grad norm: 6.2730479656083595\n",
      "Epoch 4599, Loss: 208.96251953657807, Neurons: 201, Grad norm: 6.2730479656083595\n",
      "Epoch 4600, Loss: 208.9624928286367, Neurons: 201, Grad norm: 6.667297549165166\n",
      "Epoch 4600, Loss: 208.9624928286367, Neurons: 201, Grad norm: 6.667297549165166\n",
      "Epoch 4601, Loss: 208.96243311773125, Neurons: 201, Grad norm: 6.472879455492349\n",
      "Epoch 4601, Loss: 208.96243311773125, Neurons: 201, Grad norm: 6.472879455492349\n",
      "Epoch 4602, Loss: 208.96227017699684, Neurons: 201, Grad norm: 6.037301351272325\n",
      "Epoch 4602, Loss: 208.96227017699684, Neurons: 201, Grad norm: 6.037301351272325\n",
      "Epoch 4603, Loss: 208.9620515306546, Neurons: 201, Grad norm: 4.783755736623115\n",
      "Epoch 4603, Loss: 208.9620515306546, Neurons: 201, Grad norm: 4.783755736623115\n",
      "Epoch 4604, Loss: 208.96174077536662, Neurons: 201, Grad norm: 3.5960105353663203\n",
      "Epoch 4604, Loss: 208.96174077536662, Neurons: 201, Grad norm: 3.5960105353663203\n",
      "Epoch 4605, Loss: 208.96143227691937, Neurons: 201, Grad norm: 1.910708281696514\n",
      "Epoch 4605, Loss: 208.96143227691937, Neurons: 201, Grad norm: 1.910708281696514\n",
      "Epoch 4606, Loss: 208.9611708434777, Neurons: 201, Grad norm: 0.5677300330128443\n",
      "Epoch 4606, Loss: 208.9611708434777, Neurons: 201, Grad norm: 0.5677300330128443\n",
      "Epoch 4607, Loss: 208.96100118192527, Neurons: 201, Grad norm: 1.4006065746360166\n",
      "Epoch 4607, Loss: 208.96100118192527, Neurons: 201, Grad norm: 1.4006065746360166\n",
      "Epoch 4608, Loss: 208.96090051279205, Neurons: 201, Grad norm: 2.870529313442711\n",
      "Epoch 4608, Loss: 208.96090051279205, Neurons: 201, Grad norm: 2.870529313442711\n",
      "Epoch 4609, Loss: 208.96085877430798, Neurons: 201, Grad norm: 4.243459264350547\n",
      "Epoch 4609, Loss: 208.96085877430798, Neurons: 201, Grad norm: 4.243459264350547\n",
      "Epoch 4610, Loss: 208.9608866674716, Neurons: 201, Grad norm: 5.33827929059233\n",
      "Epoch 4610, Loss: 208.9608866674716, Neurons: 201, Grad norm: 5.33827929059233\n",
      "Epoch 4611, Loss: 208.96093511886892, Neurons: 201, Grad norm: 6.192749368939643\n",
      "Epoch 4611, Loss: 208.96093511886892, Neurons: 201, Grad norm: 6.192749368939643\n",
      "Epoch 4612, Loss: 208.96097597745293, Neurons: 201, Grad norm: 6.220920680594057\n",
      "Epoch 4612, Loss: 208.96097597745293, Neurons: 201, Grad norm: 6.220920680594057\n",
      "Epoch 4613, Loss: 208.96085550994295, Neurons: 201, Grad norm: 6.2245608831940835\n",
      "Epoch 4613, Loss: 208.96085550994295, Neurons: 201, Grad norm: 6.2245608831940835\n",
      "Epoch 4614, Loss: 208.96070132111396, Neurons: 201, Grad norm: 5.205466617058396\n",
      "Epoch 4614, Loss: 208.96070132111396, Neurons: 201, Grad norm: 5.205466617058396\n",
      "Epoch 4615, Loss: 208.96039155050835, Neurons: 201, Grad norm: 4.4505528287382505\n",
      "Epoch 4615, Loss: 208.96039155050835, Neurons: 201, Grad norm: 4.4505528287382505\n",
      "Epoch 4616, Loss: 208.96012605036864, Neurons: 201, Grad norm: 3.2604746207619897\n",
      "Epoch 4616, Loss: 208.96012605036864, Neurons: 201, Grad norm: 3.2604746207619897\n",
      "Epoch 4617, Loss: 208.95984407820617, Neurons: 201, Grad norm: 2.1033783266351835\n",
      "Epoch 4617, Loss: 208.95984407820617, Neurons: 201, Grad norm: 2.1033783266351835\n",
      "Epoch 4618, Loss: 208.95961880453677, Neurons: 201, Grad norm: 1.1266036406341144\n",
      "Epoch 4618, Loss: 208.95961880453677, Neurons: 201, Grad norm: 1.1266036406341144\n",
      "Epoch 4619, Loss: 208.9594112489, Neurons: 201, Grad norm: 0.5733998746305293\n",
      "Epoch 4619, Loss: 208.9594112489, Neurons: 201, Grad norm: 0.5733998746305293\n",
      "Epoch 4620, Loss: 208.95921719383924, Neurons: 201, Grad norm: 1.0352009115202192\n",
      "Epoch 4620, Loss: 208.95921719383924, Neurons: 201, Grad norm: 1.0352009115202192\n",
      "Epoch 4621, Loss: 208.9590641597837, Neurons: 201, Grad norm: 1.6675828891991296\n",
      "Epoch 4621, Loss: 208.9590641597837, Neurons: 201, Grad norm: 1.6675828891991296\n",
      "Epoch 4622, Loss: 208.95894434916872, Neurons: 201, Grad norm: 2.632347861373167\n",
      "Epoch 4622, Loss: 208.95894434916872, Neurons: 201, Grad norm: 2.632347861373167\n",
      "Epoch 4623, Loss: 208.95880539836006, Neurons: 201, Grad norm: 3.2073983632756633\n",
      "Epoch 4623, Loss: 208.95880539836006, Neurons: 201, Grad norm: 3.2073983632756633\n",
      "Epoch 4624, Loss: 208.95869846165505, Neurons: 201, Grad norm: 4.590720391814573\n",
      "Epoch 4624, Loss: 208.95869846165505, Neurons: 201, Grad norm: 4.590720391814573\n",
      "Epoch 4625, Loss: 208.9586702178863, Neurons: 201, Grad norm: 5.227996864513247\n",
      "Epoch 4625, Loss: 208.9586702178863, Neurons: 201, Grad norm: 5.227996864513247\n",
      "Epoch 4626, Loss: 208.95861334277762, Neurons: 201, Grad norm: 6.3900693389191145\n",
      "Epoch 4626, Loss: 208.95861334277762, Neurons: 201, Grad norm: 6.3900693389191145\n",
      "Epoch 4627, Loss: 208.9586005790361, Neurons: 201, Grad norm: 6.81300300344372\n",
      "Epoch 4627, Loss: 208.9586005790361, Neurons: 201, Grad norm: 6.81300300344372\n",
      "Epoch 4628, Loss: 208.95854473087968, Neurons: 201, Grad norm: 7.345317573093797\n",
      "Epoch 4628, Loss: 208.95854473087968, Neurons: 201, Grad norm: 7.345317573093797\n",
      "Epoch 4629, Loss: 208.95850859645103, Neurons: 201, Grad norm: 7.080765385769977\n",
      "Epoch 4629, Loss: 208.95850859645103, Neurons: 201, Grad norm: 7.080765385769977\n",
      "Epoch 4630, Loss: 208.9583334979367, Neurons: 201, Grad norm: 6.338753551536702\n",
      "Epoch 4630, Loss: 208.9583334979367, Neurons: 201, Grad norm: 6.338753551536702\n",
      "Epoch 4631, Loss: 208.95804572880584, Neurons: 201, Grad norm: 4.7423107928468715\n",
      "Epoch 4631, Loss: 208.95804572880584, Neurons: 201, Grad norm: 4.7423107928468715\n",
      "Epoch 4632, Loss: 208.9575933449888, Neurons: 201, Grad norm: 2.6437295141794768\n",
      "Epoch 4632, Loss: 208.9575933449888, Neurons: 201, Grad norm: 2.6437295141794768\n",
      "Epoch 4633, Loss: 208.95715232569881, Neurons: 201, Grad norm: 0.6067168453172549\n",
      "Epoch 4633, Loss: 208.95715232569881, Neurons: 201, Grad norm: 0.6067168453172549\n",
      "Epoch 4634, Loss: 208.9569208847405, Neurons: 201, Grad norm: 2.4196974058918914\n",
      "Epoch 4634, Loss: 208.9569208847405, Neurons: 201, Grad norm: 2.4196974058918914\n",
      "Epoch 4635, Loss: 208.95683587992283, Neurons: 201, Grad norm: 5.281641955720204\n",
      "Epoch 4635, Loss: 208.95683587992283, Neurons: 201, Grad norm: 5.281641955720204\n",
      "Epoch 4636, Loss: 208.95698484861757, Neurons: 201, Grad norm: 7.537286863549059\n",
      "Epoch 4636, Loss: 208.95698484861757, Neurons: 201, Grad norm: 7.537286863549059\n",
      "Epoch 4637, Loss: 208.95732339024133, Neurons: 201, Grad norm: 9.513139604993636\n",
      "Epoch 4637, Loss: 208.95732339024133, Neurons: 201, Grad norm: 9.513139604993636\n",
      "Epoch 4638, Loss: 208.9576594830233, Neurons: 201, Grad norm: 10.138599423815924\n",
      "Epoch 4638, Loss: 208.9576594830233, Neurons: 201, Grad norm: 10.138599423815924\n",
      "Epoch 4639, Loss: 208.95775732511333, Neurons: 201, Grad norm: 9.887220735379698\n",
      "Epoch 4639, Loss: 208.95775732511333, Neurons: 201, Grad norm: 9.887220735379698\n",
      "Epoch 4640, Loss: 208.95749658923438, Neurons: 201, Grad norm: 7.912765752026154\n",
      "Epoch 4640, Loss: 208.95749658923438, Neurons: 201, Grad norm: 7.912765752026154\n",
      "Epoch 4641, Loss: 208.9567043946226, Neurons: 201, Grad norm: 5.58712252626362\n",
      "Epoch 4641, Loss: 208.9567043946226, Neurons: 201, Grad norm: 5.58712252626362\n",
      "Epoch 4642, Loss: 208.9560457584681, Neurons: 201, Grad norm: 2.097169012275259\n",
      "Epoch 4642, Loss: 208.9560457584681, Neurons: 201, Grad norm: 2.097169012275259\n",
      "Epoch 4643, Loss: 208.95548804932724, Neurons: 201, Grad norm: 1.262207215190048\n",
      "Epoch 4643, Loss: 208.95548804932724, Neurons: 201, Grad norm: 1.262207215190048\n",
      "Epoch 4644, Loss: 208.9552337582604, Neurons: 201, Grad norm: 4.242801367381229\n",
      "Epoch 4644, Loss: 208.9552337582604, Neurons: 201, Grad norm: 4.242801367381229\n",
      "Epoch 4645, Loss: 208.95526145417375, Neurons: 201, Grad norm: 6.097694397617058\n",
      "Epoch 4645, Loss: 208.95526145417375, Neurons: 201, Grad norm: 6.097694397617058\n",
      "Epoch 4646, Loss: 208.95534796499328, Neurons: 201, Grad norm: 7.502702909397496\n",
      "Epoch 4646, Loss: 208.95534796499328, Neurons: 201, Grad norm: 7.502702909397496\n",
      "Epoch 4647, Loss: 208.95547842277733, Neurons: 201, Grad norm: 7.303428210485176\n",
      "Epoch 4647, Loss: 208.95547842277733, Neurons: 201, Grad norm: 7.303428210485176\n",
      "Epoch 4648, Loss: 208.95522622472276, Neurons: 201, Grad norm: 6.344064355788868\n",
      "Epoch 4648, Loss: 208.95522622472276, Neurons: 201, Grad norm: 6.344064355788868\n",
      "Epoch 4649, Loss: 208.95479558119845, Neurons: 201, Grad norm: 4.305669789145293\n",
      "Epoch 4649, Loss: 208.95479558119845, Neurons: 201, Grad norm: 4.305669789145293\n",
      "Epoch 4650, Loss: 208.9542059559554, Neurons: 201, Grad norm: 2.1481710067245943\n",
      "Epoch 4650, Loss: 208.9542059559554, Neurons: 201, Grad norm: 2.1481710067245943\n",
      "Epoch 4651, Loss: 208.95371927585995, Neurons: 201, Grad norm: 1.023169826513846\n",
      "Epoch 4651, Loss: 208.95371927585995, Neurons: 201, Grad norm: 1.023169826513846\n",
      "Epoch 4652, Loss: 208.95340784592537, Neurons: 201, Grad norm: 2.5413531294534684\n",
      "Epoch 4652, Loss: 208.95340784592537, Neurons: 201, Grad norm: 2.5413531294534684\n",
      "Epoch 4653, Loss: 208.95326461153593, Neurons: 201, Grad norm: 4.580078301190217\n",
      "Epoch 4653, Loss: 208.95326461153593, Neurons: 201, Grad norm: 4.580078301190217\n",
      "Epoch 4654, Loss: 208.95320044858627, Neurons: 201, Grad norm: 5.465946103035524\n",
      "Epoch 4654, Loss: 208.95320044858627, Neurons: 201, Grad norm: 5.465946103035524\n",
      "Epoch 4655, Loss: 208.95310937501557, Neurons: 201, Grad norm: 6.221450472772892\n",
      "Epoch 4655, Loss: 208.95310937501557, Neurons: 201, Grad norm: 6.221450472772892\n",
      "Epoch 4656, Loss: 208.95298546658097, Neurons: 201, Grad norm: 5.900554018843783\n",
      "Epoch 4656, Loss: 208.95298546658097, Neurons: 201, Grad norm: 5.900554018843783\n",
      "Epoch 4657, Loss: 208.95269204063115, Neurons: 201, Grad norm: 4.710014238597741\n",
      "Epoch 4657, Loss: 208.95269204063115, Neurons: 201, Grad norm: 4.710014238597741\n",
      "Epoch 4658, Loss: 208.95229349545616, Neurons: 201, Grad norm: 2.8967211164761837\n",
      "Epoch 4658, Loss: 208.95229349545616, Neurons: 201, Grad norm: 2.8967211164761837\n",
      "Epoch 4659, Loss: 208.95186843480974, Neurons: 201, Grad norm: 0.9678747286330722\n",
      "Epoch 4659, Loss: 208.95186843480974, Neurons: 201, Grad norm: 0.9678747286330722\n",
      "Epoch 4660, Loss: 208.9515376491833, Neurons: 201, Grad norm: 1.644688949090859\n",
      "Epoch 4660, Loss: 208.9515376491833, Neurons: 201, Grad norm: 1.644688949090859\n",
      "Epoch 4661, Loss: 208.9513199408887, Neurons: 201, Grad norm: 3.284046689519634\n",
      "Epoch 4661, Loss: 208.9513199408887, Neurons: 201, Grad norm: 3.284046689519634\n",
      "Epoch 4662, Loss: 208.95122985636684, Neurons: 201, Grad norm: 4.95745373921637\n",
      "Epoch 4662, Loss: 208.95122985636684, Neurons: 201, Grad norm: 4.95745373921637\n",
      "Epoch 4663, Loss: 208.95123838368283, Neurons: 201, Grad norm: 6.002267586593981\n",
      "Epoch 4663, Loss: 208.95123838368283, Neurons: 201, Grad norm: 6.002267586593981\n",
      "Epoch 4664, Loss: 208.95132226641567, Neurons: 201, Grad norm: 6.318684552652026\n",
      "Epoch 4664, Loss: 208.95132226641567, Neurons: 201, Grad norm: 6.318684552652026\n",
      "Epoch 4665, Loss: 208.95125837439176, Neurons: 201, Grad norm: 6.018773884376262\n",
      "Epoch 4665, Loss: 208.95125837439176, Neurons: 201, Grad norm: 6.018773884376262\n",
      "Epoch 4666, Loss: 208.95103157836445, Neurons: 201, Grad norm: 4.852934393305805\n",
      "Epoch 4666, Loss: 208.95103157836445, Neurons: 201, Grad norm: 4.852934393305805\n",
      "Epoch 4667, Loss: 208.9507211792701, Neurons: 201, Grad norm: 3.2742497024874244\n",
      "Epoch 4667, Loss: 208.9507211792701, Neurons: 201, Grad norm: 3.2742497024874244\n",
      "Epoch 4668, Loss: 208.95036572978412, Neurons: 201, Grad norm: 1.531706067265187\n",
      "Epoch 4668, Loss: 208.95036572978412, Neurons: 201, Grad norm: 1.531706067265187\n",
      "Epoch 4669, Loss: 208.9500695172674, Neurons: 201, Grad norm: 0.7515652030635072\n",
      "Epoch 4669, Loss: 208.9500695172674, Neurons: 201, Grad norm: 0.7515652030635072\n",
      "Epoch 4670, Loss: 208.94987206012667, Neurons: 201, Grad norm: 2.042364981625943\n",
      "Epoch 4670, Loss: 208.94987206012667, Neurons: 201, Grad norm: 2.042364981625943\n",
      "Epoch 4671, Loss: 208.9497635166115, Neurons: 201, Grad norm: 3.195505339630265\n",
      "Epoch 4671, Loss: 208.9497635166115, Neurons: 201, Grad norm: 3.195505339630265\n",
      "Epoch 4672, Loss: 208.9496837785401, Neurons: 201, Grad norm: 4.3585887035440365\n",
      "Epoch 4672, Loss: 208.9496837785401, Neurons: 201, Grad norm: 4.3585887035440365\n",
      "Epoch 4673, Loss: 208.94967531646364, Neurons: 201, Grad norm: 5.200451802739986\n",
      "Epoch 4673, Loss: 208.94967531646364, Neurons: 201, Grad norm: 5.200451802739986\n",
      "Epoch 4674, Loss: 208.94961556082978, Neurons: 201, Grad norm: 5.5371100637085675\n",
      "Epoch 4674, Loss: 208.94961556082978, Neurons: 201, Grad norm: 5.5371100637085675\n",
      "Epoch 4675, Loss: 208.94953439079117, Neurons: 201, Grad norm: 5.167527603287091\n",
      "Epoch 4675, Loss: 208.94953439079117, Neurons: 201, Grad norm: 5.167527603287091\n",
      "Epoch 4676, Loss: 208.94926924805344, Neurons: 201, Grad norm: 4.37151179935995\n",
      "Epoch 4676, Loss: 208.94926924805344, Neurons: 201, Grad norm: 4.37151179935995\n",
      "Epoch 4677, Loss: 208.94896749474267, Neurons: 201, Grad norm: 3.4211766306249323\n",
      "Epoch 4677, Loss: 208.94896749474267, Neurons: 201, Grad norm: 3.4211766306249323\n",
      "Epoch 4678, Loss: 208.9487047228595, Neurons: 201, Grad norm: 2.2249599514837977\n",
      "Epoch 4678, Loss: 208.9487047228595, Neurons: 201, Grad norm: 2.2249599514837977\n",
      "Epoch 4679, Loss: 208.9484422250326, Neurons: 201, Grad norm: 1.3850174091057377\n",
      "Epoch 4679, Loss: 208.9484422250326, Neurons: 201, Grad norm: 1.3850174091057377\n",
      "Epoch 4680, Loss: 208.94823624752144, Neurons: 201, Grad norm: 0.5871067061226894\n",
      "Epoch 4680, Loss: 208.94823624752144, Neurons: 201, Grad norm: 0.5871067061226894\n",
      "Epoch 4681, Loss: 208.94806711936926, Neurons: 201, Grad norm: 1.3067077567927279\n",
      "Epoch 4681, Loss: 208.94806711936926, Neurons: 201, Grad norm: 1.3067077567927279\n",
      "Epoch 4682, Loss: 208.94790105755973, Neurons: 201, Grad norm: 2.071976562057006\n",
      "Epoch 4682, Loss: 208.94790105755973, Neurons: 201, Grad norm: 2.071976562057006\n",
      "Epoch 4683, Loss: 208.94780726902016, Neurons: 201, Grad norm: 3.0985213448843205\n",
      "Epoch 4683, Loss: 208.94780726902016, Neurons: 201, Grad norm: 3.0985213448843205\n",
      "Epoch 4684, Loss: 208.94770508253382, Neurons: 201, Grad norm: 4.154680072120985\n",
      "Epoch 4684, Loss: 208.94770508253382, Neurons: 201, Grad norm: 4.154680072120985\n",
      "Epoch 4685, Loss: 208.9476631913076, Neurons: 201, Grad norm: 5.166984488414691\n",
      "Epoch 4685, Loss: 208.9476631913076, Neurons: 201, Grad norm: 5.166984488414691\n",
      "Epoch 4686, Loss: 208.94769175508893, Neurons: 201, Grad norm: 6.162626404154274\n",
      "Epoch 4686, Loss: 208.94769175508893, Neurons: 201, Grad norm: 6.162626404154274\n",
      "Epoch 4687, Loss: 208.94771451241292, Neurons: 201, Grad norm: 6.878259585499533\n",
      "Epoch 4687, Loss: 208.94771451241292, Neurons: 201, Grad norm: 6.878259585499533\n",
      "Epoch 4688, Loss: 208.94770569878753, Neurons: 201, Grad norm: 7.21912795843775\n",
      "Epoch 4688, Loss: 208.94770569878753, Neurons: 201, Grad norm: 7.21912795843775\n",
      "Epoch 4689, Loss: 208.94767274494274, Neurons: 201, Grad norm: 7.096161514999636\n",
      "Epoch 4689, Loss: 208.94767274494274, Neurons: 201, Grad norm: 7.096161514999636\n",
      "Epoch 4690, Loss: 208.94749323868396, Neurons: 201, Grad norm: 6.252594233107866\n",
      "Epoch 4690, Loss: 208.94749323868396, Neurons: 201, Grad norm: 6.252594233107866\n",
      "Epoch 4691, Loss: 208.94725272205002, Neurons: 201, Grad norm: 4.81655282607943\n",
      "Epoch 4691, Loss: 208.94725272205002, Neurons: 201, Grad norm: 4.81655282607943\n",
      "Epoch 4692, Loss: 208.94688982906763, Neurons: 201, Grad norm: 3.342047056262629\n",
      "Epoch 4692, Loss: 208.94688982906763, Neurons: 201, Grad norm: 3.342047056262629\n",
      "Epoch 4693, Loss: 208.94654436285265, Neurons: 201, Grad norm: 1.4524943805703399\n",
      "Epoch 4693, Loss: 208.94654436285265, Neurons: 201, Grad norm: 1.4524943805703399\n",
      "Epoch 4694, Loss: 208.94631301008476, Neurons: 201, Grad norm: 0.6639969114284724\n",
      "Epoch 4694, Loss: 208.94631301008476, Neurons: 201, Grad norm: 0.6639969114284724\n",
      "Epoch 4695, Loss: 208.94615610923836, Neurons: 201, Grad norm: 1.7443147483663364\n",
      "Epoch 4695, Loss: 208.94615610923836, Neurons: 201, Grad norm: 1.7443147483663364\n",
      "Epoch 4696, Loss: 208.94605559575706, Neurons: 201, Grad norm: 2.911611397288595\n",
      "Epoch 4696, Loss: 208.94605559575706, Neurons: 201, Grad norm: 2.911611397288595\n",
      "Epoch 4697, Loss: 208.94599058325934, Neurons: 201, Grad norm: 3.785056791484518\n",
      "Epoch 4697, Loss: 208.94599058325934, Neurons: 201, Grad norm: 3.785056791484518\n",
      "Epoch 4698, Loss: 208.94595822461105, Neurons: 201, Grad norm: 4.3099119268465245\n",
      "Epoch 4698, Loss: 208.94595822461105, Neurons: 201, Grad norm: 4.3099119268465245\n",
      "Epoch 4699, Loss: 208.94590077585733, Neurons: 201, Grad norm: 4.819923361954304\n",
      "Epoch 4699, Loss: 208.94590077585733, Neurons: 201, Grad norm: 4.819923361954304\n",
      "Epoch 4700, Loss: 208.94582093671423, Neurons: 201, Grad norm: 4.760899132647199\n",
      "Epoch 4700, Loss: 208.94582093671423, Neurons: 201, Grad norm: 4.760899132647199\n",
      "Epoch 4701, Loss: 208.9457161927988, Neurons: 201, Grad norm: 4.768900264477343\n",
      "Epoch 4701, Loss: 208.9457161927988, Neurons: 201, Grad norm: 4.768900264477343\n",
      "Epoch 4702, Loss: 208.94557335952933, Neurons: 201, Grad norm: 4.444205765678748\n",
      "Epoch 4702, Loss: 208.94557335952933, Neurons: 201, Grad norm: 4.444205765678748\n",
      "Epoch 4703, Loss: 208.94542360407877, Neurons: 201, Grad norm: 4.319007033572526\n",
      "Epoch 4703, Loss: 208.94542360407877, Neurons: 201, Grad norm: 4.319007033572526\n",
      "Epoch 4704, Loss: 208.94527039368387, Neurons: 201, Grad norm: 4.101222001461287\n",
      "Epoch 4704, Loss: 208.94527039368387, Neurons: 201, Grad norm: 4.101222001461287\n",
      "Epoch 4705, Loss: 208.94509744829463, Neurons: 201, Grad norm: 3.5555792924734257\n",
      "Epoch 4705, Loss: 208.94509744829463, Neurons: 201, Grad norm: 3.5555792924734257\n",
      "Epoch 4706, Loss: 208.94493879167342, Neurons: 201, Grad norm: 3.0797453820482956\n",
      "Epoch 4706, Loss: 208.94493879167342, Neurons: 201, Grad norm: 3.0797453820482956\n",
      "Epoch 4707, Loss: 208.94475927383598, Neurons: 201, Grad norm: 2.5862809564605573\n",
      "Epoch 4707, Loss: 208.94475927383598, Neurons: 201, Grad norm: 2.5862809564605573\n",
      "Epoch 4708, Loss: 208.9446083048755, Neurons: 201, Grad norm: 2.3603571438855315\n",
      "Epoch 4708, Loss: 208.9446083048755, Neurons: 201, Grad norm: 2.3603571438855315\n",
      "Epoch 4709, Loss: 208.94444664590802, Neurons: 201, Grad norm: 2.4269851021695468\n",
      "Epoch 4709, Loss: 208.94444664590802, Neurons: 201, Grad norm: 2.4269851021695468\n",
      "Epoch 4710, Loss: 208.94432141752804, Neurons: 201, Grad norm: 2.6930362371319165\n",
      "Epoch 4710, Loss: 208.94432141752804, Neurons: 201, Grad norm: 2.6930362371319165\n",
      "Epoch 4711, Loss: 208.94424748395807, Neurons: 201, Grad norm: 3.335360820605016\n",
      "Epoch 4711, Loss: 208.94424748395807, Neurons: 201, Grad norm: 3.335360820605016\n",
      "Epoch 4712, Loss: 208.94417618764138, Neurons: 201, Grad norm: 3.8859662652544786\n",
      "Epoch 4712, Loss: 208.94417618764138, Neurons: 201, Grad norm: 3.8859662652544786\n",
      "Epoch 4713, Loss: 208.9441275809994, Neurons: 201, Grad norm: 4.927230183891461\n",
      "Epoch 4713, Loss: 208.9441275809994, Neurons: 201, Grad norm: 4.927230183891461\n",
      "Epoch 4714, Loss: 208.94410775665764, Neurons: 201, Grad norm: 5.571082541355112\n",
      "Epoch 4714, Loss: 208.94410775665764, Neurons: 201, Grad norm: 5.571082541355112\n",
      "Epoch 4715, Loss: 208.94409017851544, Neurons: 201, Grad norm: 6.426348769350787\n",
      "Epoch 4715, Loss: 208.94409017851544, Neurons: 201, Grad norm: 6.426348769350787\n",
      "Epoch 4716, Loss: 208.9441123589938, Neurons: 201, Grad norm: 6.9578272735494355\n",
      "Epoch 4716, Loss: 208.9441123589938, Neurons: 201, Grad norm: 6.9578272735494355\n",
      "Epoch 4717, Loss: 208.94410087240263, Neurons: 201, Grad norm: 7.392477768890618\n",
      "Epoch 4717, Loss: 208.94410087240263, Neurons: 201, Grad norm: 7.392477768890618\n",
      "Epoch 4718, Loss: 208.9441379213507, Neurons: 201, Grad norm: 7.237730162768069\n",
      "Epoch 4718, Loss: 208.9441379213507, Neurons: 201, Grad norm: 7.237730162768069\n",
      "Epoch 4719, Loss: 208.94395548517633, Neurons: 201, Grad norm: 6.616054468331739\n",
      "Epoch 4719, Loss: 208.94395548517633, Neurons: 201, Grad norm: 6.616054468331739\n",
      "Epoch 4720, Loss: 208.94378158040894, Neurons: 201, Grad norm: 5.508313265041989\n",
      "Epoch 4720, Loss: 208.94378158040894, Neurons: 201, Grad norm: 5.508313265041989\n",
      "Epoch 4721, Loss: 208.94337393988678, Neurons: 201, Grad norm: 3.813856956087632\n",
      "Epoch 4721, Loss: 208.94337393988678, Neurons: 201, Grad norm: 3.813856956087632\n",
      "Epoch 4722, Loss: 208.9430391154417, Neurons: 201, Grad norm: 1.9427641059758354\n",
      "Epoch 4722, Loss: 208.9430391154417, Neurons: 201, Grad norm: 1.9427641059758354\n",
      "Epoch 4723, Loss: 208.94275165519448, Neurons: 201, Grad norm: 0.5986662629892329\n",
      "Epoch 4723, Loss: 208.94275165519448, Neurons: 201, Grad norm: 0.5986662629892329\n",
      "Epoch 4724, Loss: 208.94258172338937, Neurons: 201, Grad norm: 2.1175849845704455\n",
      "Epoch 4724, Loss: 208.94258172338937, Neurons: 201, Grad norm: 2.1175849845704455\n",
      "Epoch 4725, Loss: 208.9425233234917, Neurons: 201, Grad norm: 3.6774430083596314\n",
      "Epoch 4725, Loss: 208.9425233234917, Neurons: 201, Grad norm: 3.6774430083596314\n",
      "Epoch 4726, Loss: 208.94254432485963, Neurons: 201, Grad norm: 5.264132448720688\n",
      "Epoch 4726, Loss: 208.94254432485963, Neurons: 201, Grad norm: 5.264132448720688\n",
      "Epoch 4727, Loss: 208.94261386227504, Neurons: 201, Grad norm: 6.361460666366739\n",
      "Epoch 4727, Loss: 208.94261386227504, Neurons: 201, Grad norm: 6.361460666366739\n",
      "Epoch 4728, Loss: 208.94272850420705, Neurons: 201, Grad norm: 7.2723801955511345\n",
      "Epoch 4728, Loss: 208.94272850420705, Neurons: 201, Grad norm: 7.2723801955511345\n",
      "Epoch 4729, Loss: 208.94275823225018, Neurons: 201, Grad norm: 7.140774464330629\n",
      "Epoch 4729, Loss: 208.94275823225018, Neurons: 201, Grad norm: 7.140774464330629\n",
      "Epoch 4730, Loss: 208.94266264454538, Neurons: 201, Grad norm: 6.6366420959973125\n",
      "Epoch 4730, Loss: 208.94266264454538, Neurons: 201, Grad norm: 6.6366420959973125\n",
      "Epoch 4731, Loss: 208.94243632471952, Neurons: 201, Grad norm: 5.389872680947217\n",
      "Epoch 4731, Loss: 208.94243632471952, Neurons: 201, Grad norm: 5.389872680947217\n",
      "Epoch 4732, Loss: 208.9420879459962, Neurons: 201, Grad norm: 3.881149273691933\n",
      "Epoch 4732, Loss: 208.9420879459962, Neurons: 201, Grad norm: 3.881149273691933\n",
      "Epoch 4733, Loss: 208.9417637686613, Neurons: 201, Grad norm: 1.9974608856064688\n",
      "Epoch 4733, Loss: 208.9417637686613, Neurons: 201, Grad norm: 1.9974608856064688\n",
      "Epoch 4734, Loss: 208.94148132188045, Neurons: 201, Grad norm: 0.7300746312175893\n",
      "Epoch 4734, Loss: 208.94148132188045, Neurons: 201, Grad norm: 0.7300746312175893\n",
      "Epoch 4735, Loss: 208.94132085596902, Neurons: 201, Grad norm: 2.111592179668475\n",
      "Epoch 4735, Loss: 208.94132085596902, Neurons: 201, Grad norm: 2.111592179668475\n",
      "Epoch 4736, Loss: 208.94122733268043, Neurons: 201, Grad norm: 3.8027098723289123\n",
      "Epoch 4736, Loss: 208.94122733268043, Neurons: 201, Grad norm: 3.8027098723289123\n",
      "Epoch 4737, Loss: 208.9413000605602, Neurons: 201, Grad norm: 5.332545427791539\n",
      "Epoch 4737, Loss: 208.9413000605602, Neurons: 201, Grad norm: 5.332545427791539\n",
      "Epoch 4738, Loss: 208.94135916832215, Neurons: 201, Grad norm: 6.539169529543431\n",
      "Epoch 4738, Loss: 208.94135916832215, Neurons: 201, Grad norm: 6.539169529543431\n",
      "Epoch 4739, Loss: 208.94146837380515, Neurons: 201, Grad norm: 7.464115677014855\n",
      "Epoch 4739, Loss: 208.94146837380515, Neurons: 201, Grad norm: 7.464115677014855\n",
      "Epoch 4740, Loss: 208.94152725996355, Neurons: 201, Grad norm: 7.697672238596715\n",
      "Epoch 4740, Loss: 208.94152725996355, Neurons: 201, Grad norm: 7.697672238596715\n",
      "Epoch 4741, Loss: 208.94151132335895, Neurons: 201, Grad norm: 7.572505294110065\n",
      "Epoch 4741, Loss: 208.94151132335895, Neurons: 201, Grad norm: 7.572505294110065\n",
      "Epoch 4742, Loss: 208.94134635218552, Neurons: 201, Grad norm: 6.7764353899428\n",
      "Epoch 4742, Loss: 208.94134635218552, Neurons: 201, Grad norm: 6.7764353899428\n",
      "Epoch 4743, Loss: 208.94104161817978, Neurons: 201, Grad norm: 5.719825078286578\n",
      "Epoch 4743, Loss: 208.94104161817978, Neurons: 201, Grad norm: 5.719825078286578\n",
      "Epoch 4744, Loss: 208.94076183566125, Neurons: 201, Grad norm: 4.237831669930017\n",
      "Epoch 4744, Loss: 208.94076183566125, Neurons: 201, Grad norm: 4.237831669930017\n",
      "Epoch 4745, Loss: 208.94041673315434, Neurons: 201, Grad norm: 2.44740174834122\n",
      "Epoch 4745, Loss: 208.94041673315434, Neurons: 201, Grad norm: 2.44740174834122\n",
      "Epoch 4746, Loss: 208.94010906766647, Neurons: 201, Grad norm: 0.6430439402697735\n",
      "Epoch 4746, Loss: 208.94010906766647, Neurons: 201, Grad norm: 0.6430439402697735\n",
      "Epoch 4747, Loss: 208.93995249643567, Neurons: 201, Grad norm: 1.6498878433231434\n",
      "Epoch 4747, Loss: 208.93995249643567, Neurons: 201, Grad norm: 1.6498878433231434\n",
      "Epoch 4748, Loss: 208.93985919407055, Neurons: 201, Grad norm: 3.006105016833751\n",
      "Epoch 4748, Loss: 208.93985919407055, Neurons: 201, Grad norm: 3.006105016833751\n",
      "Epoch 4749, Loss: 208.9398240891476, Neurons: 201, Grad norm: 4.058389267787734\n",
      "Epoch 4749, Loss: 208.9398240891476, Neurons: 201, Grad norm: 4.058389267787734\n",
      "Epoch 4750, Loss: 208.93981398706603, Neurons: 201, Grad norm: 4.998951619748136\n",
      "Epoch 4750, Loss: 208.93981398706603, Neurons: 201, Grad norm: 4.998951619748136\n",
      "Epoch 4751, Loss: 208.93981633270292, Neurons: 201, Grad norm: 5.582213546566278\n",
      "Epoch 4751, Loss: 208.93981633270292, Neurons: 201, Grad norm: 5.582213546566278\n",
      "Epoch 4752, Loss: 208.93979803762704, Neurons: 201, Grad norm: 6.237563090215454\n",
      "Epoch 4752, Loss: 208.93979803762704, Neurons: 201, Grad norm: 6.237563090215454\n",
      "Epoch 4753, Loss: 208.93977743394998, Neurons: 201, Grad norm: 6.473912900769068\n",
      "Epoch 4753, Loss: 208.93977743394998, Neurons: 201, Grad norm: 6.473912900769068\n",
      "Epoch 4754, Loss: 208.93969236121117, Neurons: 201, Grad norm: 6.7268016844038705\n",
      "Epoch 4754, Loss: 208.93969236121117, Neurons: 201, Grad norm: 6.7268016844038705\n",
      "Epoch 4755, Loss: 208.93962564817, Neurons: 201, Grad norm: 6.285430314564614\n",
      "Epoch 4755, Loss: 208.93962564817, Neurons: 201, Grad norm: 6.285430314564614\n",
      "Epoch 4756, Loss: 208.93943983163803, Neurons: 201, Grad norm: 5.364112501735456\n",
      "Epoch 4756, Loss: 208.93943983163803, Neurons: 201, Grad norm: 5.364112501735456\n",
      "Epoch 4757, Loss: 208.93922767809514, Neurons: 201, Grad norm: 3.903601109251081\n",
      "Epoch 4757, Loss: 208.93922767809514, Neurons: 201, Grad norm: 3.903601109251081\n",
      "Epoch 4758, Loss: 208.93888352697397, Neurons: 201, Grad norm: 2.3680172425333743\n",
      "Epoch 4758, Loss: 208.93888352697397, Neurons: 201, Grad norm: 2.3680172425333743\n",
      "Epoch 4759, Loss: 208.9386380638318, Neurons: 201, Grad norm: 0.7530386188766132\n",
      "Epoch 4759, Loss: 208.9386380638318, Neurons: 201, Grad norm: 0.7530386188766132\n",
      "Epoch 4760, Loss: 208.9384026150126, Neurons: 201, Grad norm: 1.4669970496932507\n",
      "Epoch 4760, Loss: 208.9384026150126, Neurons: 201, Grad norm: 1.4669970496932507\n",
      "Epoch 4761, Loss: 208.93834834366706, Neurons: 201, Grad norm: 3.079450030790173\n",
      "Epoch 4761, Loss: 208.93834834366706, Neurons: 201, Grad norm: 3.079450030790173\n",
      "Epoch 4762, Loss: 208.9382966169966, Neurons: 201, Grad norm: 4.552021737497397\n",
      "Epoch 4762, Loss: 208.9382966169966, Neurons: 201, Grad norm: 4.552021737497397\n",
      "Epoch 4763, Loss: 208.93839354445663, Neurons: 201, Grad norm: 6.018856081131229\n",
      "Epoch 4763, Loss: 208.93839354445663, Neurons: 201, Grad norm: 6.018856081131229\n",
      "Epoch 4764, Loss: 208.93850062924028, Neurons: 201, Grad norm: 7.112347867893359\n",
      "Epoch 4764, Loss: 208.93850062924028, Neurons: 201, Grad norm: 7.112347867893359\n",
      "Epoch 4765, Loss: 208.93859526727815, Neurons: 201, Grad norm: 7.779628225810601\n",
      "Epoch 4765, Loss: 208.93859526727815, Neurons: 201, Grad norm: 7.779628225810601\n",
      "Epoch 4766, Loss: 208.93864178335167, Neurons: 201, Grad norm: 7.648660602785477\n",
      "Epoch 4766, Loss: 208.93864178335167, Neurons: 201, Grad norm: 7.648660602785477\n",
      "Epoch 4767, Loss: 208.93846991900705, Neurons: 201, Grad norm: 7.1896292423311134\n",
      "Epoch 4767, Loss: 208.93846991900705, Neurons: 201, Grad norm: 7.1896292423311134\n",
      "Epoch 4768, Loss: 208.93826746713037, Neurons: 201, Grad norm: 5.7000541329164705\n",
      "Epoch 4768, Loss: 208.93826746713037, Neurons: 201, Grad norm: 5.7000541329164705\n",
      "Epoch 4769, Loss: 208.93788004340104, Neurons: 201, Grad norm: 3.985495990298589\n",
      "Epoch 4769, Loss: 208.93788004340104, Neurons: 201, Grad norm: 3.985495990298589\n",
      "Epoch 4770, Loss: 208.93753572546166, Neurons: 201, Grad norm: 1.7817748477374076\n",
      "Epoch 4770, Loss: 208.93753572546166, Neurons: 201, Grad norm: 1.7817748477374076\n",
      "Epoch 4771, Loss: 208.9372237558046, Neurons: 201, Grad norm: 0.9427037962336033\n",
      "Epoch 4771, Loss: 208.9372237558046, Neurons: 201, Grad norm: 0.9427037962336033\n",
      "Epoch 4772, Loss: 208.93705782562378, Neurons: 201, Grad norm: 2.8359414377510084\n",
      "Epoch 4772, Loss: 208.93705782562378, Neurons: 201, Grad norm: 2.8359414377510084\n",
      "Epoch 4773, Loss: 208.93706646783988, Neurons: 201, Grad norm: 4.683563430377727\n",
      "Epoch 4773, Loss: 208.93706646783988, Neurons: 201, Grad norm: 4.683563430377727\n",
      "Epoch 4774, Loss: 208.93713647202895, Neurons: 201, Grad norm: 6.504619356558583\n",
      "Epoch 4774, Loss: 208.93713647202895, Neurons: 201, Grad norm: 6.504619356558583\n",
      "Epoch 4775, Loss: 208.93731506289544, Neurons: 201, Grad norm: 7.674475173544098\n",
      "Epoch 4775, Loss: 208.93731506289544, Neurons: 201, Grad norm: 7.674475173544098\n",
      "Epoch 4776, Loss: 208.93748825270916, Neurons: 201, Grad norm: 8.34749864783018\n",
      "Epoch 4776, Loss: 208.93748825270916, Neurons: 201, Grad norm: 8.34749864783018\n",
      "Epoch 4777, Loss: 208.93751123274723, Neurons: 201, Grad norm: 7.82277772090332\n",
      "Epoch 4777, Loss: 208.93751123274723, Neurons: 201, Grad norm: 7.82277772090332\n",
      "Epoch 4778, Loss: 208.93734644840168, Neurons: 201, Grad norm: 6.63049024181946\n",
      "Epoch 4778, Loss: 208.93734644840168, Neurons: 201, Grad norm: 6.63049024181946\n",
      "Epoch 4779, Loss: 208.93696669647264, Neurons: 201, Grad norm: 4.632887948388166\n",
      "Epoch 4779, Loss: 208.93696669647264, Neurons: 201, Grad norm: 4.632887948388166\n",
      "Epoch 4780, Loss: 208.936462241478, Neurons: 201, Grad norm: 2.468675409711552\n",
      "Epoch 4780, Loss: 208.936462241478, Neurons: 201, Grad norm: 2.468675409711552\n",
      "Epoch 4781, Loss: 208.93616349282448, Neurons: 201, Grad norm: 0.5314481308489538\n",
      "Epoch 4781, Loss: 208.93616349282448, Neurons: 201, Grad norm: 0.5314481308489538\n",
      "Epoch 4782, Loss: 208.93592928668244, Neurons: 201, Grad norm: 2.034683619333513\n",
      "Epoch 4782, Loss: 208.93592928668244, Neurons: 201, Grad norm: 2.034683619333513\n",
      "Epoch 4783, Loss: 208.93590638580616, Neurons: 201, Grad norm: 4.009634008801997\n",
      "Epoch 4783, Loss: 208.93590638580616, Neurons: 201, Grad norm: 4.009634008801997\n",
      "Epoch 4784, Loss: 208.93593787520317, Neurons: 201, Grad norm: 5.341918473986681\n",
      "Epoch 4784, Loss: 208.93593787520317, Neurons: 201, Grad norm: 5.341918473986681\n",
      "Epoch 4785, Loss: 208.93603485359756, Neurons: 201, Grad norm: 6.785547640485369\n",
      "Epoch 4785, Loss: 208.93603485359756, Neurons: 201, Grad norm: 6.785547640485369\n",
      "Epoch 4786, Loss: 208.93614137474572, Neurons: 201, Grad norm: 7.589289789514335\n",
      "Epoch 4786, Loss: 208.93614137474572, Neurons: 201, Grad norm: 7.589289789514335\n",
      "Epoch 4787, Loss: 208.93621193752548, Neurons: 201, Grad norm: 7.6668571373896235\n",
      "Epoch 4787, Loss: 208.93621193752548, Neurons: 201, Grad norm: 7.6668571373896235\n",
      "Epoch 4788, Loss: 208.93621218716993, Neurons: 201, Grad norm: 7.0346006881117535\n",
      "Epoch 4788, Loss: 208.93621218716993, Neurons: 201, Grad norm: 7.0346006881117535\n",
      "Epoch 4789, Loss: 208.9359127813612, Neurons: 201, Grad norm: 5.417319678300505\n",
      "Epoch 4789, Loss: 208.9359127813612, Neurons: 201, Grad norm: 5.417319678300505\n",
      "Epoch 4790, Loss: 208.93552911647447, Neurons: 201, Grad norm: 3.3061881768391697\n",
      "Epoch 4790, Loss: 208.93552911647447, Neurons: 201, Grad norm: 3.3061881768391697\n",
      "Epoch 4791, Loss: 208.93510684671028, Neurons: 201, Grad norm: 1.314871455150872\n",
      "Epoch 4791, Loss: 208.93510684671028, Neurons: 201, Grad norm: 1.314871455150872\n",
      "Epoch 4792, Loss: 208.9348803435839, Neurons: 201, Grad norm: 1.2976475450249214\n",
      "Epoch 4792, Loss: 208.9348803435839, Neurons: 201, Grad norm: 1.2976475450249214\n",
      "Epoch 4793, Loss: 208.9347597295177, Neurons: 201, Grad norm: 3.0879431482030846\n",
      "Epoch 4793, Loss: 208.9347597295177, Neurons: 201, Grad norm: 3.0879431482030846\n",
      "Epoch 4794, Loss: 208.93476597820182, Neurons: 201, Grad norm: 5.055464504502561\n",
      "Epoch 4794, Loss: 208.93476597820182, Neurons: 201, Grad norm: 5.055464504502561\n",
      "Epoch 4795, Loss: 208.9348744567527, Neurons: 201, Grad norm: 6.347481678564115\n",
      "Epoch 4795, Loss: 208.9348744567527, Neurons: 201, Grad norm: 6.347481678564115\n",
      "Epoch 4796, Loss: 208.93498941984979, Neurons: 201, Grad norm: 7.180456203854535\n",
      "Epoch 4796, Loss: 208.93498941984979, Neurons: 201, Grad norm: 7.180456203854535\n",
      "Epoch 4797, Loss: 208.93510834897157, Neurons: 201, Grad norm: 7.246619044078221\n",
      "Epoch 4797, Loss: 208.93510834897157, Neurons: 201, Grad norm: 7.246619044078221\n",
      "Epoch 4798, Loss: 208.93498506399354, Neurons: 201, Grad norm: 6.408860622898054\n",
      "Epoch 4798, Loss: 208.93498506399354, Neurons: 201, Grad norm: 6.408860622898054\n",
      "Epoch 4799, Loss: 208.9347148736868, Neurons: 201, Grad norm: 4.961808025539645\n",
      "Epoch 4799, Loss: 208.9347148736868, Neurons: 201, Grad norm: 4.961808025539645\n",
      "Epoch 4800, Loss: 208.9343593045512, Neurons: 201, Grad norm: 3.2444063526741744\n",
      "Epoch 4800, Loss: 208.9343593045512, Neurons: 201, Grad norm: 3.2444063526741744\n",
      "Epoch 4801, Loss: 208.93406506892433, Neurons: 201, Grad norm: 1.2310134629192464\n",
      "Epoch 4801, Loss: 208.93406506892433, Neurons: 201, Grad norm: 1.2310134629192464\n",
      "Epoch 4802, Loss: 208.93380944564097, Neurons: 201, Grad norm: 0.9212468244059137\n",
      "Epoch 4802, Loss: 208.93380944564097, Neurons: 201, Grad norm: 0.9212468244059137\n",
      "Epoch 4803, Loss: 208.93369817631677, Neurons: 201, Grad norm: 2.6645011304888633\n",
      "Epoch 4803, Loss: 208.93369817631677, Neurons: 201, Grad norm: 2.6645011304888633\n",
      "Epoch 4804, Loss: 208.93371890148597, Neurons: 201, Grad norm: 4.112411778029304\n",
      "Epoch 4804, Loss: 208.93371890148597, Neurons: 201, Grad norm: 4.112411778029304\n",
      "Epoch 4805, Loss: 208.93367754198394, Neurons: 201, Grad norm: 5.681689021040187\n",
      "Epoch 4805, Loss: 208.93367754198394, Neurons: 201, Grad norm: 5.681689021040187\n",
      "Epoch 4806, Loss: 208.93385685233324, Neurons: 201, Grad norm: 6.712389915910631\n",
      "Epoch 4806, Loss: 208.93385685233324, Neurons: 201, Grad norm: 6.712389915910631\n",
      "Epoch 4807, Loss: 208.93392655719003, Neurons: 201, Grad norm: 7.3751005844976625\n",
      "Epoch 4807, Loss: 208.93392655719003, Neurons: 201, Grad norm: 7.3751005844976625\n",
      "Epoch 4808, Loss: 208.93393258010192, Neurons: 201, Grad norm: 7.106399188682795\n",
      "Epoch 4808, Loss: 208.93393258010192, Neurons: 201, Grad norm: 7.106399188682795\n",
      "Epoch 4809, Loss: 208.93381651706505, Neurons: 201, Grad norm: 6.237156020636088\n",
      "Epoch 4809, Loss: 208.93381651706505, Neurons: 201, Grad norm: 6.237156020636088\n",
      "Epoch 4810, Loss: 208.93348209088555, Neurons: 201, Grad norm: 4.780510758494747\n",
      "Epoch 4810, Loss: 208.93348209088555, Neurons: 201, Grad norm: 4.780510758494747\n",
      "Epoch 4811, Loss: 208.93317959493257, Neurons: 201, Grad norm: 3.264473768537684\n",
      "Epoch 4811, Loss: 208.93317959493257, Neurons: 201, Grad norm: 3.264473768537684\n",
      "Epoch 4812, Loss: 208.9328699242127, Neurons: 201, Grad norm: 1.700251252575129\n",
      "Epoch 4812, Loss: 208.9328699242127, Neurons: 201, Grad norm: 1.700251252575129\n",
      "Epoch 4813, Loss: 208.93268944668412, Neurons: 201, Grad norm: 0.6520855811039208\n",
      "Epoch 4813, Loss: 208.93268944668412, Neurons: 201, Grad norm: 0.6520855811039208\n",
      "Epoch 4814, Loss: 208.93250169224274, Neurons: 201, Grad norm: 2.146358331178571\n",
      "Epoch 4814, Loss: 208.93250169224274, Neurons: 201, Grad norm: 2.146358331178571\n",
      "Epoch 4815, Loss: 208.93251077475637, Neurons: 201, Grad norm: 2.9575127111611903\n",
      "Epoch 4815, Loss: 208.93251077475637, Neurons: 201, Grad norm: 2.9575127111611903\n",
      "Epoch 4816, Loss: 208.93242100409486, Neurons: 201, Grad norm: 3.885571007243159\n",
      "Epoch 4816, Loss: 208.93242100409486, Neurons: 201, Grad norm: 3.885571007243159\n",
      "Epoch 4817, Loss: 208.93243056850125, Neurons: 201, Grad norm: 3.998597629529712\n",
      "Epoch 4817, Loss: 208.93243056850125, Neurons: 201, Grad norm: 3.998597629529712\n",
      "Epoch 4818, Loss: 208.93235209498147, Neurons: 201, Grad norm: 4.358371849502371\n",
      "Epoch 4818, Loss: 208.93235209498147, Neurons: 201, Grad norm: 4.358371849502371\n",
      "Epoch 4819, Loss: 208.93225051416047, Neurons: 201, Grad norm: 4.35155297184331\n",
      "Epoch 4819, Loss: 208.93225051416047, Neurons: 201, Grad norm: 4.35155297184331\n",
      "Epoch 4820, Loss: 208.93216176173004, Neurons: 201, Grad norm: 4.214369225429037\n",
      "Epoch 4820, Loss: 208.93216176173004, Neurons: 201, Grad norm: 4.214369225429037\n",
      "Epoch 4821, Loss: 208.93201340807244, Neurons: 201, Grad norm: 4.29556106158892\n",
      "Epoch 4821, Loss: 208.93201340807244, Neurons: 201, Grad norm: 4.29556106158892\n",
      "Epoch 4822, Loss: 208.93192199332535, Neurons: 201, Grad norm: 4.50783051658156\n",
      "Epoch 4822, Loss: 208.93192199332535, Neurons: 201, Grad norm: 4.50783051658156\n",
      "Epoch 4823, Loss: 208.9318208458506, Neurons: 201, Grad norm: 4.554234436545701\n",
      "Epoch 4823, Loss: 208.9318208458506, Neurons: 201, Grad norm: 4.554234436545701\n",
      "Epoch 4824, Loss: 208.9317809481141, Neurons: 201, Grad norm: 4.764610508284773\n",
      "Epoch 4824, Loss: 208.9317809481141, Neurons: 201, Grad norm: 4.764610508284773\n",
      "Epoch 4825, Loss: 208.931689648589, Neurons: 201, Grad norm: 4.046294959545403\n",
      "Epoch 4825, Loss: 208.931689648589, Neurons: 201, Grad norm: 4.046294959545403\n",
      "Epoch 4826, Loss: 208.93147524151445, Neurons: 201, Grad norm: 3.3059703546492205\n",
      "Epoch 4826, Loss: 208.93147524151445, Neurons: 201, Grad norm: 3.3059703546492205\n",
      "Epoch 4827, Loss: 208.9312901221882, Neurons: 201, Grad norm: 2.1810692613216287\n",
      "Epoch 4827, Loss: 208.9312901221882, Neurons: 201, Grad norm: 2.1810692613216287\n",
      "Epoch 4828, Loss: 208.9310885673968, Neurons: 201, Grad norm: 0.9402719176452831\n",
      "Epoch 4828, Loss: 208.9310885673968, Neurons: 201, Grad norm: 0.9402719176452831\n",
      "Epoch 4829, Loss: 208.9309423413671, Neurons: 201, Grad norm: 0.8896175020159899\n",
      "Epoch 4829, Loss: 208.9309423413671, Neurons: 201, Grad norm: 0.8896175020159899\n",
      "Epoch 4830, Loss: 208.93082193758073, Neurons: 201, Grad norm: 1.7144184886979215\n",
      "Epoch 4830, Loss: 208.93082193758073, Neurons: 201, Grad norm: 1.7144184886979215\n",
      "Epoch 4831, Loss: 208.93071681960396, Neurons: 201, Grad norm: 2.8737392612581445\n",
      "Epoch 4831, Loss: 208.93071681960396, Neurons: 201, Grad norm: 2.8737392612581445\n",
      "Epoch 4832, Loss: 208.93068614882432, Neurons: 201, Grad norm: 3.956906076994044\n",
      "Epoch 4832, Loss: 208.93068614882432, Neurons: 201, Grad norm: 3.956906076994044\n",
      "Epoch 4833, Loss: 208.93069262531625, Neurons: 201, Grad norm: 5.18657039441117\n",
      "Epoch 4833, Loss: 208.93069262531625, Neurons: 201, Grad norm: 5.18657039441117\n",
      "Epoch 4834, Loss: 208.93076205874414, Neurons: 201, Grad norm: 5.778470562308818\n",
      "Epoch 4834, Loss: 208.93076205874414, Neurons: 201, Grad norm: 5.778470562308818\n",
      "Epoch 4835, Loss: 208.93075136384775, Neurons: 201, Grad norm: 6.243324996379053\n",
      "Epoch 4835, Loss: 208.93075136384775, Neurons: 201, Grad norm: 6.243324996379053\n",
      "Epoch 4836, Loss: 208.93073566948053, Neurons: 201, Grad norm: 6.039829891084758\n",
      "Epoch 4836, Loss: 208.93073566948053, Neurons: 201, Grad norm: 6.039829891084758\n",
      "Epoch 4837, Loss: 208.93056610139817, Neurons: 201, Grad norm: 5.245904414890876\n",
      "Epoch 4837, Loss: 208.93056610139817, Neurons: 201, Grad norm: 5.245904414890876\n",
      "Epoch 4838, Loss: 208.9303825119262, Neurons: 201, Grad norm: 4.2993269543289845\n",
      "Epoch 4838, Loss: 208.9303825119262, Neurons: 201, Grad norm: 4.2993269543289845\n",
      "Epoch 4839, Loss: 208.93011594248796, Neurons: 201, Grad norm: 3.1043851729995557\n",
      "Epoch 4839, Loss: 208.93011594248796, Neurons: 201, Grad norm: 3.1043851729995557\n",
      "Epoch 4840, Loss: 208.9298637108531, Neurons: 201, Grad norm: 1.5778840084493484\n",
      "Epoch 4840, Loss: 208.9298637108531, Neurons: 201, Grad norm: 1.5778840084493484\n",
      "Epoch 4841, Loss: 208.92966278043497, Neurons: 201, Grad norm: 0.828345773952187\n",
      "Epoch 4841, Loss: 208.92966278043497, Neurons: 201, Grad norm: 0.828345773952187\n",
      "Epoch 4842, Loss: 208.92955277253128, Neurons: 201, Grad norm: 0.7919292482329656\n",
      "Epoch 4842, Loss: 208.92955277253128, Neurons: 201, Grad norm: 0.7919292482329656\n",
      "Epoch 4843, Loss: 208.92945550902675, Neurons: 201, Grad norm: 1.4735962598289942\n",
      "Epoch 4843, Loss: 208.92945550902675, Neurons: 201, Grad norm: 1.4735962598289942\n",
      "Epoch 4844, Loss: 208.9293406818814, Neurons: 201, Grad norm: 2.1501805578240156\n",
      "Epoch 4844, Loss: 208.9293406818814, Neurons: 201, Grad norm: 2.1501805578240156\n",
      "Epoch 4845, Loss: 208.92926950593414, Neurons: 201, Grad norm: 3.3614212886684394\n",
      "Epoch 4845, Loss: 208.92926950593414, Neurons: 201, Grad norm: 3.3614212886684394\n",
      "Epoch 4846, Loss: 208.92925968155677, Neurons: 201, Grad norm: 4.58710784482255\n",
      "Epoch 4846, Loss: 208.92925968155677, Neurons: 201, Grad norm: 4.58710784482255\n",
      "Epoch 4847, Loss: 208.92929711443196, Neurons: 201, Grad norm: 5.688337311905163\n",
      "Epoch 4847, Loss: 208.92929711443196, Neurons: 201, Grad norm: 5.688337311905163\n",
      "Epoch 4848, Loss: 208.92938949358663, Neurons: 201, Grad norm: 6.981486326992215\n",
      "Epoch 4848, Loss: 208.92938949358663, Neurons: 201, Grad norm: 6.981486326992215\n",
      "Epoch 4849, Loss: 208.92949439591465, Neurons: 201, Grad norm: 7.56219965152378\n",
      "Epoch 4849, Loss: 208.92949439591465, Neurons: 201, Grad norm: 7.56219965152378\n",
      "Epoch 4850, Loss: 208.92955063998116, Neurons: 201, Grad norm: 7.929794380556386\n",
      "Epoch 4850, Loss: 208.92955063998116, Neurons: 201, Grad norm: 7.929794380556386\n",
      "Epoch 4851, Loss: 208.9295315483882, Neurons: 201, Grad norm: 7.270055594742013\n",
      "Epoch 4851, Loss: 208.9295315483882, Neurons: 201, Grad norm: 7.270055594742013\n",
      "Epoch 4852, Loss: 208.92928055219605, Neurons: 201, Grad norm: 5.893699362763698\n",
      "Epoch 4852, Loss: 208.92928055219605, Neurons: 201, Grad norm: 5.893699362763698\n",
      "Epoch 4853, Loss: 208.9289507023435, Neurons: 201, Grad norm: 3.9178390228528155\n",
      "Epoch 4853, Loss: 208.9289507023435, Neurons: 201, Grad norm: 3.9178390228528155\n",
      "Epoch 4854, Loss: 208.9285570675347, Neurons: 201, Grad norm: 1.640228704594654\n",
      "Epoch 4854, Loss: 208.9285570675347, Neurons: 201, Grad norm: 1.640228704594654\n",
      "Epoch 4855, Loss: 208.92821876114755, Neurons: 201, Grad norm: 0.9194263480144146\n",
      "Epoch 4855, Loss: 208.92821876114755, Neurons: 201, Grad norm: 0.9194263480144146\n",
      "Epoch 4856, Loss: 208.9281014784494, Neurons: 201, Grad norm: 2.9867995964911502\n",
      "Epoch 4856, Loss: 208.9281014784494, Neurons: 201, Grad norm: 2.9867995964911502\n",
      "Epoch 4857, Loss: 208.92814752512214, Neurons: 201, Grad norm: 5.1214582461559655\n",
      "Epoch 4857, Loss: 208.92814752512214, Neurons: 201, Grad norm: 5.1214582461559655\n",
      "Epoch 4858, Loss: 208.9282430207559, Neurons: 201, Grad norm: 6.595235280740854\n",
      "Epoch 4858, Loss: 208.9282430207559, Neurons: 201, Grad norm: 6.595235280740854\n",
      "Epoch 4859, Loss: 208.92847896276848, Neurons: 201, Grad norm: 7.946954243484802\n",
      "Epoch 4859, Loss: 208.92847896276848, Neurons: 201, Grad norm: 7.946954243484802\n",
      "Epoch 4860, Loss: 208.92859292005943, Neurons: 201, Grad norm: 8.415463844055328\n",
      "Epoch 4860, Loss: 208.92859292005943, Neurons: 201, Grad norm: 8.415463844055328\n",
      "Epoch 4861, Loss: 208.92864652680328, Neurons: 201, Grad norm: 8.225119825795536\n",
      "Epoch 4861, Loss: 208.92864652680328, Neurons: 201, Grad norm: 8.225119825795536\n",
      "Epoch 4862, Loss: 208.92847951610597, Neurons: 201, Grad norm: 7.11558693053083\n",
      "Epoch 4862, Loss: 208.92847951610597, Neurons: 201, Grad norm: 7.11558693053083\n",
      "Epoch 4863, Loss: 208.92810898433564, Neurons: 201, Grad norm: 5.363268029613811\n",
      "Epoch 4863, Loss: 208.92810898433564, Neurons: 201, Grad norm: 5.363268029613811\n",
      "Epoch 4864, Loss: 208.92771401138376, Neurons: 201, Grad norm: 2.9942905499042722\n",
      "Epoch 4864, Loss: 208.92771401138376, Neurons: 201, Grad norm: 2.9942905499042722\n",
      "Epoch 4865, Loss: 208.9273271679452, Neurons: 201, Grad norm: 0.7789349204814662\n",
      "Epoch 4865, Loss: 208.9273271679452, Neurons: 201, Grad norm: 0.7789349204814662\n",
      "Epoch 4866, Loss: 208.927106136447, Neurons: 201, Grad norm: 2.138228750752363\n",
      "Epoch 4866, Loss: 208.927106136447, Neurons: 201, Grad norm: 2.138228750752363\n",
      "Epoch 4867, Loss: 208.92708811930405, Neurons: 201, Grad norm: 4.16853383904024\n",
      "Epoch 4867, Loss: 208.92708811930405, Neurons: 201, Grad norm: 4.16853383904024\n",
      "Epoch 4868, Loss: 208.92713578009116, Neurons: 201, Grad norm: 6.156233580869921\n",
      "Epoch 4868, Loss: 208.92713578009116, Neurons: 201, Grad norm: 6.156233580869921\n",
      "Epoch 4869, Loss: 208.92730730823536, Neurons: 201, Grad norm: 7.270295880530079\n",
      "Epoch 4869, Loss: 208.92730730823536, Neurons: 201, Grad norm: 7.270295880530079\n",
      "Epoch 4870, Loss: 208.92746459702227, Neurons: 201, Grad norm: 7.8591291127389695\n",
      "Epoch 4870, Loss: 208.92746459702227, Neurons: 201, Grad norm: 7.8591291127389695\n",
      "Epoch 4871, Loss: 208.9275023673278, Neurons: 201, Grad norm: 7.459938531231433\n",
      "Epoch 4871, Loss: 208.9275023673278, Neurons: 201, Grad norm: 7.459938531231433\n",
      "Epoch 4872, Loss: 208.92730485403885, Neurons: 201, Grad norm: 6.438032705188129\n",
      "Epoch 4872, Loss: 208.92730485403885, Neurons: 201, Grad norm: 6.438032705188129\n",
      "Epoch 4873, Loss: 208.92699357116666, Neurons: 201, Grad norm: 4.81791284570369\n",
      "Epoch 4873, Loss: 208.92699357116666, Neurons: 201, Grad norm: 4.81791284570369\n",
      "Epoch 4874, Loss: 208.9266353545281, Neurons: 201, Grad norm: 3.154519238009331\n",
      "Epoch 4874, Loss: 208.9266353545281, Neurons: 201, Grad norm: 3.154519238009331\n",
      "Epoch 4875, Loss: 208.9263318865394, Neurons: 201, Grad norm: 1.5987226668926378\n",
      "Epoch 4875, Loss: 208.9263318865394, Neurons: 201, Grad norm: 1.5987226668926378\n",
      "Epoch 4876, Loss: 208.92611233854603, Neurons: 201, Grad norm: 0.5320765857022096\n",
      "Epoch 4876, Loss: 208.92611233854603, Neurons: 201, Grad norm: 0.5320765857022096\n",
      "Epoch 4877, Loss: 208.92596861913273, Neurons: 201, Grad norm: 1.5485719901349995\n",
      "Epoch 4877, Loss: 208.92596861913273, Neurons: 201, Grad norm: 1.5485719901349995\n",
      "Epoch 4878, Loss: 208.92589856397785, Neurons: 201, Grad norm: 2.811939642122627\n",
      "Epoch 4878, Loss: 208.92589856397785, Neurons: 201, Grad norm: 2.811939642122627\n",
      "Epoch 4879, Loss: 208.92588232807938, Neurons: 201, Grad norm: 4.37959018053758\n",
      "Epoch 4879, Loss: 208.92588232807938, Neurons: 201, Grad norm: 4.37959018053758\n",
      "Epoch 4880, Loss: 208.92594412830064, Neurons: 201, Grad norm: 5.553638976928457\n",
      "Epoch 4880, Loss: 208.92594412830064, Neurons: 201, Grad norm: 5.553638976928457\n",
      "Epoch 4881, Loss: 208.92599442262886, Neurons: 201, Grad norm: 6.79975847360663\n",
      "Epoch 4881, Loss: 208.92599442262886, Neurons: 201, Grad norm: 6.79975847360663\n",
      "Epoch 4882, Loss: 208.92613760379362, Neurons: 201, Grad norm: 7.432488334006887\n",
      "Epoch 4882, Loss: 208.92613760379362, Neurons: 201, Grad norm: 7.432488334006887\n",
      "Epoch 4883, Loss: 208.92618261329213, Neurons: 201, Grad norm: 7.725468556605902\n",
      "Epoch 4883, Loss: 208.92618261329213, Neurons: 201, Grad norm: 7.725468556605902\n",
      "Epoch 4884, Loss: 208.92615993202043, Neurons: 201, Grad norm: 7.1930688911028255\n",
      "Epoch 4884, Loss: 208.92615993202043, Neurons: 201, Grad norm: 7.1930688911028255\n",
      "Epoch 4885, Loss: 208.92594299190824, Neurons: 201, Grad norm: 6.252267319065858\n",
      "Epoch 4885, Loss: 208.92594299190824, Neurons: 201, Grad norm: 6.252267319065858\n",
      "Epoch 4886, Loss: 208.92564519580674, Neurons: 201, Grad norm: 4.772169280728675\n",
      "Epoch 4886, Loss: 208.92564519580674, Neurons: 201, Grad norm: 4.772169280728675\n",
      "Epoch 4887, Loss: 208.92531754136934, Neurons: 201, Grad norm: 3.136698269257665\n",
      "Epoch 4887, Loss: 208.92531754136934, Neurons: 201, Grad norm: 3.136698269257665\n",
      "Epoch 4888, Loss: 208.92502852550697, Neurons: 201, Grad norm: 1.5832898026011955\n",
      "Epoch 4888, Loss: 208.92502852550697, Neurons: 201, Grad norm: 1.5832898026011955\n",
      "Epoch 4889, Loss: 208.92485286218812, Neurons: 201, Grad norm: 0.7698647104921682\n",
      "Epoch 4889, Loss: 208.92485286218812, Neurons: 201, Grad norm: 0.7698647104921682\n",
      "Epoch 4890, Loss: 208.92472055968875, Neurons: 201, Grad norm: 1.6516849663835782\n",
      "Epoch 4890, Loss: 208.92472055968875, Neurons: 201, Grad norm: 1.6516849663835782\n",
      "Epoch 4891, Loss: 208.92463372258507, Neurons: 201, Grad norm: 2.7098300595610616\n",
      "Epoch 4891, Loss: 208.92463372258507, Neurons: 201, Grad norm: 2.7098300595610616\n",
      "Epoch 4892, Loss: 208.92463309795735, Neurons: 201, Grad norm: 3.8384273074211337\n",
      "Epoch 4892, Loss: 208.92463309795735, Neurons: 201, Grad norm: 3.8384273074211337\n",
      "Epoch 4893, Loss: 208.92462262322036, Neurons: 201, Grad norm: 4.9720542911267085\n",
      "Epoch 4893, Loss: 208.92462262322036, Neurons: 201, Grad norm: 4.9720542911267085\n",
      "Epoch 4894, Loss: 208.9246540096242, Neurons: 201, Grad norm: 5.878958670377778\n",
      "Epoch 4894, Loss: 208.9246540096242, Neurons: 201, Grad norm: 5.878958670377778\n",
      "Epoch 4895, Loss: 208.92470575970154, Neurons: 201, Grad norm: 6.322911221416511\n",
      "Epoch 4895, Loss: 208.92470575970154, Neurons: 201, Grad norm: 6.322911221416511\n",
      "Epoch 4896, Loss: 208.92471256489023, Neurons: 201, Grad norm: 6.45483607684202\n",
      "Epoch 4896, Loss: 208.92471256489023, Neurons: 201, Grad norm: 6.45483607684202\n",
      "Epoch 4897, Loss: 208.9246159046875, Neurons: 201, Grad norm: 6.0355199588932305\n",
      "Epoch 4897, Loss: 208.9246159046875, Neurons: 201, Grad norm: 6.0355199588932305\n",
      "Epoch 4898, Loss: 208.92441923659516, Neurons: 201, Grad norm: 5.4647633968043525\n",
      "Epoch 4898, Loss: 208.92441923659516, Neurons: 201, Grad norm: 5.4647633968043525\n",
      "Epoch 4899, Loss: 208.92425027542336, Neurons: 201, Grad norm: 4.284866689061087\n",
      "Epoch 4899, Loss: 208.92425027542336, Neurons: 201, Grad norm: 4.284866689061087\n",
      "Epoch 4900, Loss: 208.9239960650658, Neurons: 201, Grad norm: 3.2234045958691318\n",
      "Epoch 4900, Loss: 208.9239960650658, Neurons: 201, Grad norm: 3.2234045958691318\n",
      "Epoch 4901, Loss: 208.92379930232605, Neurons: 201, Grad norm: 1.7229144513566146\n",
      "Epoch 4901, Loss: 208.92379930232605, Neurons: 201, Grad norm: 1.7229144513566146\n",
      "Epoch 4902, Loss: 208.92357934818017, Neurons: 201, Grad norm: 0.5536262227056522\n",
      "Epoch 4902, Loss: 208.92357934818017, Neurons: 201, Grad norm: 0.5536262227056522\n",
      "Epoch 4903, Loss: 208.92345041443406, Neurons: 201, Grad norm: 1.3583392222676138\n",
      "Epoch 4903, Loss: 208.92345041443406, Neurons: 201, Grad norm: 1.3583392222676138\n",
      "Epoch 4904, Loss: 208.92336462768432, Neurons: 201, Grad norm: 2.734088158493568\n",
      "Epoch 4904, Loss: 208.92336462768432, Neurons: 201, Grad norm: 2.734088158493568\n",
      "Epoch 4905, Loss: 208.92336323546013, Neurons: 201, Grad norm: 3.9972416332852663\n",
      "Epoch 4905, Loss: 208.92336323546013, Neurons: 201, Grad norm: 3.9972416332852663\n",
      "Epoch 4906, Loss: 208.92341314857438, Neurons: 201, Grad norm: 5.0771164826633655\n",
      "Epoch 4906, Loss: 208.92341314857438, Neurons: 201, Grad norm: 5.0771164826633655\n",
      "Epoch 4907, Loss: 208.92342269217738, Neurons: 201, Grad norm: 6.030961256800588\n",
      "Epoch 4907, Loss: 208.92342269217738, Neurons: 201, Grad norm: 6.030961256800588\n",
      "Epoch 4908, Loss: 208.92346321435892, Neurons: 201, Grad norm: 6.636218677914966\n",
      "Epoch 4908, Loss: 208.92346321435892, Neurons: 201, Grad norm: 6.636218677914966\n",
      "Epoch 4909, Loss: 208.92346090447427, Neurons: 201, Grad norm: 7.30026096162303\n",
      "Epoch 4909, Loss: 208.92346090447427, Neurons: 201, Grad norm: 7.30026096162303\n",
      "Epoch 4910, Loss: 208.9235366551561, Neurons: 201, Grad norm: 7.014490304655705\n",
      "Epoch 4910, Loss: 208.9235366551561, Neurons: 201, Grad norm: 7.014490304655705\n",
      "Epoch 4911, Loss: 208.92341066203218, Neurons: 201, Grad norm: 6.353744019684154\n",
      "Epoch 4911, Loss: 208.92341066203218, Neurons: 201, Grad norm: 6.353744019684154\n",
      "Epoch 4912, Loss: 208.92318081081493, Neurons: 201, Grad norm: 4.625550422737536\n",
      "Epoch 4912, Loss: 208.92318081081493, Neurons: 201, Grad norm: 4.625550422737536\n",
      "Epoch 4913, Loss: 208.92280889885683, Neurons: 201, Grad norm: 2.7541875280633774\n",
      "Epoch 4913, Loss: 208.92280889885683, Neurons: 201, Grad norm: 2.7541875280633774\n",
      "Epoch 4914, Loss: 208.9225101119917, Neurons: 201, Grad norm: 0.7953755448636232\n",
      "Epoch 4914, Loss: 208.9225101119917, Neurons: 201, Grad norm: 0.7953755448636232\n",
      "Epoch 4915, Loss: 208.92229071305525, Neurons: 201, Grad norm: 1.8771178461382159\n",
      "Epoch 4915, Loss: 208.92229071305525, Neurons: 201, Grad norm: 1.8771178461382159\n",
      "Epoch 4916, Loss: 208.92228141664498, Neurons: 201, Grad norm: 3.8556915957046085\n",
      "Epoch 4916, Loss: 208.92228141664498, Neurons: 201, Grad norm: 3.8556915957046085\n",
      "Epoch 4917, Loss: 208.9223341852997, Neurons: 201, Grad norm: 5.558478613990172\n",
      "Epoch 4917, Loss: 208.9223341852997, Neurons: 201, Grad norm: 5.558478613990172\n",
      "Epoch 4918, Loss: 208.92246134492817, Neurons: 201, Grad norm: 7.215371239439362\n",
      "Epoch 4918, Loss: 208.92246134492817, Neurons: 201, Grad norm: 7.215371239439362\n",
      "Epoch 4919, Loss: 208.92264859416974, Neurons: 201, Grad norm: 7.8788027913928556\n",
      "Epoch 4919, Loss: 208.92264859416974, Neurons: 201, Grad norm: 7.8788027913928556\n",
      "Epoch 4920, Loss: 208.92272046148238, Neurons: 201, Grad norm: 7.9507819231131345\n",
      "Epoch 4920, Loss: 208.92272046148238, Neurons: 201, Grad norm: 7.9507819231131345\n",
      "Epoch 4921, Loss: 208.9226872158116, Neurons: 201, Grad norm: 6.785314770899578\n",
      "Epoch 4921, Loss: 208.9226872158116, Neurons: 201, Grad norm: 6.785314770899578\n",
      "Epoch 4922, Loss: 208.92232797979213, Neurons: 201, Grad norm: 5.080190639392773\n",
      "Epoch 4922, Loss: 208.92232797979213, Neurons: 201, Grad norm: 5.080190639392773\n",
      "Epoch 4923, Loss: 208.9219375847149, Neurons: 201, Grad norm: 2.4630391234743474\n",
      "Epoch 4923, Loss: 208.9219375847149, Neurons: 201, Grad norm: 2.4630391234743474\n",
      "Epoch 4924, Loss: 208.9215588295366, Neurons: 201, Grad norm: 0.7612241022336116\n",
      "Epoch 4924, Loss: 208.9215588295366, Neurons: 201, Grad norm: 0.7612241022336116\n",
      "Epoch 4925, Loss: 208.92141192768707, Neurons: 201, Grad norm: 2.631517444683012\n",
      "Epoch 4925, Loss: 208.92141192768707, Neurons: 201, Grad norm: 2.631517444683012\n",
      "Epoch 4926, Loss: 208.92135554046715, Neurons: 201, Grad norm: 4.6553516874322165\n",
      "Epoch 4926, Loss: 208.92135554046715, Neurons: 201, Grad norm: 4.6553516874322165\n",
      "Epoch 4927, Loss: 208.92144745012277, Neurons: 201, Grad norm: 6.289954913940333\n",
      "Epoch 4927, Loss: 208.92144745012277, Neurons: 201, Grad norm: 6.289954913940333\n",
      "Epoch 4928, Loss: 208.92161917014496, Neurons: 201, Grad norm: 7.118235114695009\n",
      "Epoch 4928, Loss: 208.92161917014496, Neurons: 201, Grad norm: 7.118235114695009\n",
      "Epoch 4929, Loss: 208.92170582855033, Neurons: 201, Grad norm: 7.343661885372191\n",
      "Epoch 4929, Loss: 208.92170582855033, Neurons: 201, Grad norm: 7.343661885372191\n",
      "Epoch 4930, Loss: 208.9216524397722, Neurons: 201, Grad norm: 6.69866971470879\n",
      "Epoch 4930, Loss: 208.9216524397722, Neurons: 201, Grad norm: 6.69866971470879\n",
      "Epoch 4931, Loss: 208.92144396925278, Neurons: 201, Grad norm: 5.554851099072258\n",
      "Epoch 4931, Loss: 208.92144396925278, Neurons: 201, Grad norm: 5.554851099072258\n",
      "Epoch 4932, Loss: 208.92110502814066, Neurons: 201, Grad norm: 3.7678105923891936\n",
      "Epoch 4932, Loss: 208.92110502814066, Neurons: 201, Grad norm: 3.7678105923891936\n",
      "Epoch 4933, Loss: 208.92079601428276, Neurons: 201, Grad norm: 2.0127337985043408\n",
      "Epoch 4933, Loss: 208.92079601428276, Neurons: 201, Grad norm: 2.0127337985043408\n",
      "Epoch 4934, Loss: 208.92050892460009, Neurons: 201, Grad norm: 0.6033906895758964\n",
      "Epoch 4934, Loss: 208.92050892460009, Neurons: 201, Grad norm: 0.6033906895758964\n",
      "Epoch 4935, Loss: 208.92038884097855, Neurons: 201, Grad norm: 1.7470514081542334\n",
      "Epoch 4935, Loss: 208.92038884097855, Neurons: 201, Grad norm: 1.7470514081542334\n",
      "Epoch 4936, Loss: 208.92033725455752, Neurons: 201, Grad norm: 3.3738541958896233\n",
      "Epoch 4936, Loss: 208.92033725455752, Neurons: 201, Grad norm: 3.3738541958896233\n",
      "Epoch 4937, Loss: 208.9203319868547, Neurons: 201, Grad norm: 4.2835294903661225\n",
      "Epoch 4937, Loss: 208.9203319868547, Neurons: 201, Grad norm: 4.2835294903661225\n",
      "Epoch 4938, Loss: 208.9203980823774, Neurons: 201, Grad norm: 5.151549836476\n",
      "Epoch 4938, Loss: 208.9203980823774, Neurons: 201, Grad norm: 5.151549836476\n",
      "Epoch 4939, Loss: 208.92039933325455, Neurons: 201, Grad norm: 5.46167332101453\n",
      "Epoch 4939, Loss: 208.92039933325455, Neurons: 201, Grad norm: 5.46167332101453\n",
      "Epoch 4940, Loss: 208.92033474922036, Neurons: 201, Grad norm: 5.416590075624645\n",
      "Epoch 4940, Loss: 208.92033474922036, Neurons: 201, Grad norm: 5.416590075624645\n",
      "Epoch 4941, Loss: 208.92022659784686, Neurons: 201, Grad norm: 4.99182971618366\n",
      "Epoch 4941, Loss: 208.92022659784686, Neurons: 201, Grad norm: 4.99182971618366\n",
      "Epoch 4942, Loss: 208.920054187879, Neurons: 201, Grad norm: 4.524056965207365\n",
      "Epoch 4942, Loss: 208.920054187879, Neurons: 201, Grad norm: 4.524056965207365\n",
      "Epoch 4943, Loss: 208.91993306487115, Neurons: 201, Grad norm: 3.633180454044417\n",
      "Epoch 4943, Loss: 208.91993306487115, Neurons: 201, Grad norm: 3.633180454044417\n",
      "Epoch 4944, Loss: 208.91969921037244, Neurons: 201, Grad norm: 2.7890494663791667\n",
      "Epoch 4944, Loss: 208.91969921037244, Neurons: 201, Grad norm: 2.7890494663791667\n",
      "Epoch 4945, Loss: 208.91951501776603, Neurons: 201, Grad norm: 1.5278625343475787\n",
      "Epoch 4945, Loss: 208.91951501776603, Neurons: 201, Grad norm: 1.5278625343475787\n",
      "Epoch 4946, Loss: 208.91937629622223, Neurons: 201, Grad norm: 0.6520271463288112\n",
      "Epoch 4946, Loss: 208.91937629622223, Neurons: 201, Grad norm: 0.6520271463288112\n",
      "Epoch 4947, Loss: 208.9191969078872, Neurons: 201, Grad norm: 1.1196717023278016\n",
      "Epoch 4947, Loss: 208.9191969078872, Neurons: 201, Grad norm: 1.1196717023278016\n",
      "Epoch 4948, Loss: 208.9191277144673, Neurons: 201, Grad norm: 1.943545713559772\n",
      "Epoch 4948, Loss: 208.9191277144673, Neurons: 201, Grad norm: 1.943545713559772\n",
      "Epoch 4949, Loss: 208.9190542487508, Neurons: 201, Grad norm: 3.0467993723283278\n",
      "Epoch 4949, Loss: 208.9190542487508, Neurons: 201, Grad norm: 3.0467993723283278\n",
      "Epoch 4950, Loss: 208.91898440571057, Neurons: 201, Grad norm: 4.084106305969025\n",
      "Epoch 4950, Loss: 208.91898440571057, Neurons: 201, Grad norm: 4.084106305969025\n",
      "Epoch 4951, Loss: 208.91902793845512, Neurons: 201, Grad norm: 5.687096068767168\n",
      "Epoch 4951, Loss: 208.91902793845512, Neurons: 201, Grad norm: 5.687096068767168\n",
      "Epoch 4952, Loss: 208.91905951321118, Neurons: 201, Grad norm: 6.763095457690587\n",
      "Epoch 4952, Loss: 208.91905951321118, Neurons: 201, Grad norm: 6.763095457690587\n",
      "Epoch 4953, Loss: 208.919194445356, Neurons: 201, Grad norm: 7.6102136946821375\n",
      "Epoch 4953, Loss: 208.919194445356, Neurons: 201, Grad norm: 7.6102136946821375\n",
      "Epoch 4954, Loss: 208.9192784574077, Neurons: 201, Grad norm: 7.3811469063983495\n",
      "Epoch 4954, Loss: 208.9192784574077, Neurons: 201, Grad norm: 7.3811469063983495\n",
      "Epoch 4955, Loss: 208.9191411116038, Neurons: 201, Grad norm: 6.339713627144367\n",
      "Epoch 4955, Loss: 208.9191411116038, Neurons: 201, Grad norm: 6.339713627144367\n",
      "Epoch 4956, Loss: 208.91886327589845, Neurons: 201, Grad norm: 4.664838826439652\n",
      "Epoch 4956, Loss: 208.91886327589845, Neurons: 201, Grad norm: 4.664838826439652\n",
      "Epoch 4957, Loss: 208.91845952730012, Neurons: 201, Grad norm: 2.866562087166048\n",
      "Epoch 4957, Loss: 208.91845952730012, Neurons: 201, Grad norm: 2.866562087166048\n",
      "Epoch 4958, Loss: 208.9181877948459, Neurons: 201, Grad norm: 1.1346409213298683\n",
      "Epoch 4958, Loss: 208.9181877948459, Neurons: 201, Grad norm: 1.1346409213298683\n",
      "Epoch 4959, Loss: 208.9179470613401, Neurons: 201, Grad norm: 1.0097128867311569\n",
      "Epoch 4959, Loss: 208.9179470613401, Neurons: 201, Grad norm: 1.0097128867311569\n",
      "Epoch 4960, Loss: 208.91785631362973, Neurons: 201, Grad norm: 2.536300463571762\n",
      "Epoch 4960, Loss: 208.91785631362973, Neurons: 201, Grad norm: 2.536300463571762\n",
      "Epoch 4961, Loss: 208.9178900854107, Neurons: 201, Grad norm: 3.9731012392065703\n",
      "Epoch 4961, Loss: 208.9178900854107, Neurons: 201, Grad norm: 3.9731012392065703\n",
      "Epoch 4962, Loss: 208.91786094611757, Neurons: 201, Grad norm: 5.581499975473613\n",
      "Epoch 4962, Loss: 208.91786094611757, Neurons: 201, Grad norm: 5.581499975473613\n",
      "Epoch 4963, Loss: 208.9180164941289, Neurons: 201, Grad norm: 6.665461873783176\n",
      "Epoch 4963, Loss: 208.9180164941289, Neurons: 201, Grad norm: 6.665461873783176\n",
      "Epoch 4964, Loss: 208.91810609021272, Neurons: 201, Grad norm: 7.51926961917946\n",
      "Epoch 4964, Loss: 208.91810609021272, Neurons: 201, Grad norm: 7.51926961917946\n",
      "Epoch 4965, Loss: 208.91823846298283, Neurons: 201, Grad norm: 7.562162292849919\n",
      "Epoch 4965, Loss: 208.91823846298283, Neurons: 201, Grad norm: 7.562162292849919\n",
      "Epoch 4966, Loss: 208.91806629676103, Neurons: 201, Grad norm: 6.879762879038284\n",
      "Epoch 4966, Loss: 208.91806629676103, Neurons: 201, Grad norm: 6.879762879038284\n",
      "Epoch 4967, Loss: 208.91791561276372, Neurons: 201, Grad norm: 5.529958904807541\n",
      "Epoch 4967, Loss: 208.91791561276372, Neurons: 201, Grad norm: 5.529958904807541\n",
      "Epoch 4968, Loss: 208.91759317144906, Neurons: 201, Grad norm: 3.5651343597578293\n",
      "Epoch 4968, Loss: 208.91759317144906, Neurons: 201, Grad norm: 3.5651343597578293\n",
      "Epoch 4969, Loss: 208.91718518676288, Neurons: 201, Grad norm: 1.6224098629189008\n",
      "Epoch 4969, Loss: 208.91718518676288, Neurons: 201, Grad norm: 1.6224098629189008\n",
      "Epoch 4970, Loss: 208.91703355801124, Neurons: 201, Grad norm: 1.0871863342237764\n",
      "Epoch 4970, Loss: 208.91703355801124, Neurons: 201, Grad norm: 1.0871863342237764\n",
      "Epoch 4971, Loss: 208.9168407549574, Neurons: 201, Grad norm: 2.7707600423806036\n",
      "Epoch 4971, Loss: 208.9168407549574, Neurons: 201, Grad norm: 2.7707600423806036\n",
      "Epoch 4972, Loss: 208.91686597023946, Neurons: 201, Grad norm: 4.039300051020189\n",
      "Epoch 4972, Loss: 208.91686597023946, Neurons: 201, Grad norm: 4.039300051020189\n",
      "Epoch 4973, Loss: 208.9168619523698, Neurons: 201, Grad norm: 5.549965336229363\n",
      "Epoch 4973, Loss: 208.9168619523698, Neurons: 201, Grad norm: 5.549965336229363\n",
      "Epoch 4974, Loss: 208.91699962067622, Neurons: 201, Grad norm: 6.372584307088477\n",
      "Epoch 4974, Loss: 208.91699962067622, Neurons: 201, Grad norm: 6.372584307088477\n",
      "Epoch 4975, Loss: 208.91707461882828, Neurons: 201, Grad norm: 6.884602703827215\n",
      "Epoch 4975, Loss: 208.91707461882828, Neurons: 201, Grad norm: 6.884602703827215\n",
      "Epoch 4976, Loss: 208.91703365026208, Neurons: 201, Grad norm: 6.856103015590518\n",
      "Epoch 4976, Loss: 208.91703365026208, Neurons: 201, Grad norm: 6.856103015590518\n",
      "Epoch 4977, Loss: 208.91695496195885, Neurons: 201, Grad norm: 6.23449683387726\n",
      "Epoch 4977, Loss: 208.91695496195885, Neurons: 201, Grad norm: 6.23449683387726\n",
      "Epoch 4978, Loss: 208.91671291824807, Neurons: 201, Grad norm: 5.484883926608843\n",
      "Epoch 4978, Loss: 208.91671291824807, Neurons: 201, Grad norm: 5.484883926608843\n",
      "Epoch 4979, Loss: 208.91653780236325, Neurons: 201, Grad norm: 4.495684181934078\n",
      "Epoch 4979, Loss: 208.91653780236325, Neurons: 201, Grad norm: 4.495684181934078\n",
      "Epoch 4980, Loss: 208.91626232651927, Neurons: 201, Grad norm: 3.4394816788513936\n",
      "Epoch 4980, Loss: 208.91626232651927, Neurons: 201, Grad norm: 3.4394816788513936\n",
      "Epoch 4981, Loss: 208.9160402186525, Neurons: 201, Grad norm: 2.4963036945862878\n",
      "Epoch 4981, Loss: 208.9160402186525, Neurons: 201, Grad norm: 2.4963036945862878\n",
      "Epoch 4982, Loss: 208.91589281829957, Neurons: 201, Grad norm: 1.5141394285018603\n",
      "Epoch 4982, Loss: 208.91589281829957, Neurons: 201, Grad norm: 1.5141394285018603\n",
      "Epoch 4983, Loss: 208.9157218110704, Neurons: 201, Grad norm: 1.0946133923666366\n",
      "Epoch 4983, Loss: 208.9157218110704, Neurons: 201, Grad norm: 1.0946133923666366\n",
      "Epoch 4984, Loss: 208.9156025407541, Neurons: 201, Grad norm: 0.6468072873476233\n",
      "Epoch 4984, Loss: 208.9156025407541, Neurons: 201, Grad norm: 0.6468072873476233\n",
      "Epoch 4985, Loss: 208.91550944098333, Neurons: 201, Grad norm: 0.6811557536926273\n",
      "Epoch 4985, Loss: 208.91550944098333, Neurons: 201, Grad norm: 0.6811557536926273\n",
      "Epoch 4986, Loss: 208.91543376852005, Neurons: 201, Grad norm: 0.7284291760693486\n",
      "Epoch 4986, Loss: 208.91543376852005, Neurons: 201, Grad norm: 0.7284291760693486\n",
      "Epoch 4987, Loss: 208.9153142780629, Neurons: 201, Grad norm: 0.6104125738646817\n",
      "Epoch 4987, Loss: 208.9153142780629, Neurons: 201, Grad norm: 0.6104125738646817\n",
      "Epoch 4988, Loss: 208.9152418525615, Neurons: 201, Grad norm: 0.7564609085662181\n",
      "Epoch 4988, Loss: 208.9152418525615, Neurons: 201, Grad norm: 0.7564609085662181\n",
      "Epoch 4989, Loss: 208.91517741320183, Neurons: 201, Grad norm: 0.6239357407617542\n",
      "Epoch 4989, Loss: 208.91517741320183, Neurons: 201, Grad norm: 0.6239357407617542\n",
      "Epoch 4990, Loss: 208.91502999337246, Neurons: 201, Grad norm: 0.705746855328877\n",
      "Epoch 4990, Loss: 208.91502999337246, Neurons: 201, Grad norm: 0.705746855328877\n",
      "Epoch 4991, Loss: 208.91498501569404, Neurons: 201, Grad norm: 0.5675715379476864\n",
      "Epoch 4991, Loss: 208.91498501569404, Neurons: 201, Grad norm: 0.5675715379476864\n",
      "Epoch 4992, Loss: 208.9148431578081, Neurons: 201, Grad norm: 1.0043981610792843\n",
      "Epoch 4992, Loss: 208.9148431578081, Neurons: 201, Grad norm: 1.0043981610792843\n",
      "Epoch 4993, Loss: 208.914783153724, Neurons: 201, Grad norm: 1.2979422706031012\n",
      "Epoch 4993, Loss: 208.914783153724, Neurons: 201, Grad norm: 1.2979422706031012\n",
      "Epoch 4994, Loss: 208.91465853511738, Neurons: 201, Grad norm: 2.120262457179222\n",
      "Epoch 4994, Loss: 208.91465853511738, Neurons: 201, Grad norm: 2.120262457179222\n",
      "Epoch 4995, Loss: 208.91462826616342, Neurons: 201, Grad norm: 3.100710051151235\n",
      "Epoch 4995, Loss: 208.91462826616342, Neurons: 201, Grad norm: 3.100710051151235\n",
      "Epoch 4996, Loss: 208.91463131092829, Neurons: 201, Grad norm: 4.575876680902589\n",
      "Epoch 4996, Loss: 208.91463131092829, Neurons: 201, Grad norm: 4.575876680902589\n",
      "Epoch 4997, Loss: 208.91466236442764, Neurons: 201, Grad norm: 6.040964866959693\n",
      "Epoch 4997, Loss: 208.91466236442764, Neurons: 201, Grad norm: 6.040964866959693\n",
      "Epoch 4998, Loss: 208.91477681928285, Neurons: 201, Grad norm: 7.5880461083894355\n",
      "Epoch 4998, Loss: 208.91477681928285, Neurons: 201, Grad norm: 7.5880461083894355\n",
      "Epoch 4999, Loss: 208.91503847868498, Neurons: 201, Grad norm: 8.586694016451204\n",
      "Epoch 4999, Loss: 208.91503847868498, Neurons: 201, Grad norm: 8.586694016451204\n",
      "Epoch 5000, Loss: 208.9151915964899, Neurons: 201, Grad norm: 9.198495850416245\n",
      "Epoch 5000, Loss: 208.9151915964899, Neurons: 201, Grad norm: 9.198495850416245\n",
      "Epoch 5001, Loss: 208.91527923653013, Neurons: 201, Grad norm: 8.49549340326272\n",
      "Epoch 5001, Loss: 208.91527923653013, Neurons: 201, Grad norm: 8.49549340326272\n",
      "Epoch 5002, Loss: 208.91505187155374, Neurons: 201, Grad norm: 6.8369378149103355\n",
      "Epoch 5002, Loss: 208.91505187155374, Neurons: 201, Grad norm: 6.8369378149103355\n",
      "Epoch 5003, Loss: 208.91458432378587, Neurons: 201, Grad norm: 4.582285917850419\n",
      "Epoch 5003, Loss: 208.91458432378587, Neurons: 201, Grad norm: 4.582285917850419\n",
      "Epoch 5004, Loss: 208.91408329005074, Neurons: 201, Grad norm: 1.5696954053638694\n",
      "Epoch 5004, Loss: 208.91408329005074, Neurons: 201, Grad norm: 1.5696954053638694\n",
      "Epoch 5005, Loss: 208.91371418546447, Neurons: 201, Grad norm: 1.5290171905896544\n",
      "Epoch 5005, Loss: 208.91371418546447, Neurons: 201, Grad norm: 1.5290171905896544\n",
      "Epoch 5006, Loss: 208.91361464161642, Neurons: 201, Grad norm: 3.7336249987769237\n",
      "Epoch 5006, Loss: 208.91361464161642, Neurons: 201, Grad norm: 3.7336249987769237\n",
      "Epoch 5007, Loss: 208.91374368080525, Neurons: 201, Grad norm: 5.931299769933168\n",
      "Epoch 5007, Loss: 208.91374368080525, Neurons: 201, Grad norm: 5.931299769933168\n",
      "Epoch 5008, Loss: 208.91388468810877, Neurons: 201, Grad norm: 7.3681866906196385\n",
      "Epoch 5008, Loss: 208.91388468810877, Neurons: 201, Grad norm: 7.3681866906196385\n",
      "Epoch 5009, Loss: 208.91409373241007, Neurons: 201, Grad norm: 8.108764196777187\n",
      "Epoch 5009, Loss: 208.91409373241007, Neurons: 201, Grad norm: 8.108764196777187\n",
      "Epoch 5010, Loss: 208.9141522397554, Neurons: 201, Grad norm: 7.955005432887605\n",
      "Epoch 5010, Loss: 208.9141522397554, Neurons: 201, Grad norm: 7.955005432887605\n",
      "Epoch 5011, Loss: 208.91404932016832, Neurons: 201, Grad norm: 7.0583283830942625\n",
      "Epoch 5011, Loss: 208.91404932016832, Neurons: 201, Grad norm: 7.0583283830942625\n",
      "Epoch 5012, Loss: 208.91381248568635, Neurons: 201, Grad norm: 5.183277304661487\n",
      "Epoch 5012, Loss: 208.91381248568635, Neurons: 201, Grad norm: 5.183277304661487\n",
      "Epoch 5013, Loss: 208.9133667350733, Neurons: 201, Grad norm: 3.0432998699629588\n",
      "Epoch 5013, Loss: 208.9133667350733, Neurons: 201, Grad norm: 3.0432998699629588\n",
      "Epoch 5014, Loss: 208.91302630017753, Neurons: 201, Grad norm: 0.9232462446840352\n",
      "Epoch 5014, Loss: 208.91302630017753, Neurons: 201, Grad norm: 0.9232462446840352\n",
      "Epoch 5015, Loss: 208.91283572426445, Neurons: 201, Grad norm: 1.8592686649331123\n",
      "Epoch 5015, Loss: 208.91283572426445, Neurons: 201, Grad norm: 1.8592686649331123\n",
      "Epoch 5016, Loss: 208.91274804957825, Neurons: 201, Grad norm: 3.8453119374102815\n",
      "Epoch 5016, Loss: 208.91274804957825, Neurons: 201, Grad norm: 3.8453119374102815\n",
      "Epoch 5017, Loss: 208.91281367220452, Neurons: 201, Grad norm: 5.1999482563841335\n",
      "Epoch 5017, Loss: 208.91281367220452, Neurons: 201, Grad norm: 5.1999482563841335\n",
      "Epoch 5018, Loss: 208.91287365477223, Neurons: 201, Grad norm: 6.383178807421103\n",
      "Epoch 5018, Loss: 208.91287365477223, Neurons: 201, Grad norm: 6.383178807421103\n",
      "Epoch 5019, Loss: 208.9129556635359, Neurons: 201, Grad norm: 6.960658107652504\n",
      "Epoch 5019, Loss: 208.9129556635359, Neurons: 201, Grad norm: 6.960658107652504\n",
      "Epoch 5020, Loss: 208.9129906802727, Neurons: 201, Grad norm: 7.235260131462369\n",
      "Epoch 5020, Loss: 208.9129906802727, Neurons: 201, Grad norm: 7.235260131462369\n",
      "Epoch 5021, Loss: 208.91295852460172, Neurons: 201, Grad norm: 6.762046736072519\n",
      "Epoch 5021, Loss: 208.91295852460172, Neurons: 201, Grad norm: 6.762046736072519\n",
      "Epoch 5022, Loss: 208.9127890726207, Neurons: 201, Grad norm: 6.263023353342815\n",
      "Epoch 5022, Loss: 208.9127890726207, Neurons: 201, Grad norm: 6.263023353342815\n",
      "Epoch 5023, Loss: 208.91260604479294, Neurons: 201, Grad norm: 4.830833884484748\n",
      "Epoch 5023, Loss: 208.91260604479294, Neurons: 201, Grad norm: 4.830833884484748\n",
      "Epoch 5024, Loss: 208.91230476831575, Neurons: 201, Grad norm: 3.3520434963076764\n",
      "Epoch 5024, Loss: 208.91230476831575, Neurons: 201, Grad norm: 3.3520434963076764\n",
      "Epoch 5025, Loss: 208.91204946806917, Neurons: 201, Grad norm: 1.8700447230263681\n",
      "Epoch 5025, Loss: 208.91204946806917, Neurons: 201, Grad norm: 1.8700447230263681\n",
      "Epoch 5026, Loss: 208.91183263842592, Neurons: 201, Grad norm: 0.5970424829594663\n",
      "Epoch 5026, Loss: 208.91183263842592, Neurons: 201, Grad norm: 0.5970424829594663\n",
      "Epoch 5027, Loss: 208.91169278892502, Neurons: 201, Grad norm: 1.594068853226915\n",
      "Epoch 5027, Loss: 208.91169278892502, Neurons: 201, Grad norm: 1.594068853226915\n",
      "Epoch 5028, Loss: 208.91166117321632, Neurons: 201, Grad norm: 2.8092922823889084\n",
      "Epoch 5028, Loss: 208.91166117321632, Neurons: 201, Grad norm: 2.8092922823889084\n",
      "Epoch 5029, Loss: 208.9116436297615, Neurons: 201, Grad norm: 4.331154751430268\n",
      "Epoch 5029, Loss: 208.9116436297615, Neurons: 201, Grad norm: 4.331154751430268\n",
      "Epoch 5030, Loss: 208.9116361752466, Neurons: 201, Grad norm: 5.568808332362996\n",
      "Epoch 5030, Loss: 208.9116361752466, Neurons: 201, Grad norm: 5.568808332362996\n",
      "Epoch 5031, Loss: 208.91173355152966, Neurons: 201, Grad norm: 7.096151455164968\n",
      "Epoch 5031, Loss: 208.91173355152966, Neurons: 201, Grad norm: 7.096151455164968\n",
      "Epoch 5032, Loss: 208.9119502947345, Neurons: 201, Grad norm: 7.962026469929525\n",
      "Epoch 5032, Loss: 208.9119502947345, Neurons: 201, Grad norm: 7.962026469929525\n",
      "Epoch 5033, Loss: 208.9120742518355, Neurons: 201, Grad norm: 8.49002803785048\n",
      "Epoch 5033, Loss: 208.9120742518355, Neurons: 201, Grad norm: 8.49002803785048\n",
      "Epoch 5034, Loss: 208.91209905505033, Neurons: 201, Grad norm: 7.703075469174639\n",
      "Epoch 5034, Loss: 208.91209905505033, Neurons: 201, Grad norm: 7.703075469174639\n",
      "Epoch 5035, Loss: 208.91187716723482, Neurons: 201, Grad norm: 6.32822793236003\n",
      "Epoch 5035, Loss: 208.91187716723482, Neurons: 201, Grad norm: 6.32822793236003\n",
      "Epoch 5036, Loss: 208.91147886837112, Neurons: 201, Grad norm: 4.204250644543604\n",
      "Epoch 5036, Loss: 208.91147886837112, Neurons: 201, Grad norm: 4.204250644543604\n",
      "Epoch 5037, Loss: 208.91105315490694, Neurons: 201, Grad norm: 1.7300481893285786\n",
      "Epoch 5037, Loss: 208.91105315490694, Neurons: 201, Grad norm: 1.7300481893285786\n",
      "Epoch 5038, Loss: 208.91075228073268, Neurons: 201, Grad norm: 0.7436506626142239\n",
      "Epoch 5038, Loss: 208.91075228073268, Neurons: 201, Grad norm: 0.7436506626142239\n",
      "Epoch 5039, Loss: 208.91063739309175, Neurons: 201, Grad norm: 2.7178978076825207\n",
      "Epoch 5039, Loss: 208.91063739309175, Neurons: 201, Grad norm: 2.7178978076825207\n",
      "Epoch 5040, Loss: 208.91061197650433, Neurons: 201, Grad norm: 4.639434665659941\n",
      "Epoch 5040, Loss: 208.91061197650433, Neurons: 201, Grad norm: 4.639434665659941\n",
      "Epoch 5041, Loss: 208.9107217629838, Neurons: 201, Grad norm: 6.008633720580261\n",
      "Epoch 5041, Loss: 208.9107217629838, Neurons: 201, Grad norm: 6.008633720580261\n",
      "Epoch 5042, Loss: 208.91090867083963, Neurons: 201, Grad norm: 7.212227877538036\n",
      "Epoch 5042, Loss: 208.91090867083963, Neurons: 201, Grad norm: 7.212227877538036\n",
      "Epoch 5043, Loss: 208.91098075946283, Neurons: 201, Grad norm: 7.390776549920317\n",
      "Epoch 5043, Loss: 208.91098075946283, Neurons: 201, Grad norm: 7.390776549920317\n",
      "Epoch 5044, Loss: 208.9109910752562, Neurons: 201, Grad norm: 7.243501551286382\n",
      "Epoch 5044, Loss: 208.9109910752562, Neurons: 201, Grad norm: 7.243501551286382\n",
      "Epoch 5045, Loss: 208.9108803881304, Neurons: 201, Grad norm: 6.1438487507747\n",
      "Epoch 5045, Loss: 208.9108803881304, Neurons: 201, Grad norm: 6.1438487507747\n",
      "Epoch 5046, Loss: 208.91055181805734, Neurons: 201, Grad norm: 4.405884938618286\n",
      "Epoch 5046, Loss: 208.91055181805734, Neurons: 201, Grad norm: 4.405884938618286\n",
      "Epoch 5047, Loss: 208.91023021448618, Neurons: 201, Grad norm: 2.5820568920316638\n",
      "Epoch 5047, Loss: 208.91023021448618, Neurons: 201, Grad norm: 2.5820568920316638\n",
      "Epoch 5048, Loss: 208.90991534324908, Neurons: 201, Grad norm: 0.7734722975769356\n",
      "Epoch 5048, Loss: 208.90991534324908, Neurons: 201, Grad norm: 0.7734722975769356\n",
      "Epoch 5049, Loss: 208.9097669971822, Neurons: 201, Grad norm: 1.4584278225847422\n",
      "Epoch 5049, Loss: 208.9097669971822, Neurons: 201, Grad norm: 1.4584278225847422\n",
      "Epoch 5050, Loss: 208.90966854654138, Neurons: 201, Grad norm: 3.1478457800952078\n",
      "Epoch 5050, Loss: 208.90966854654138, Neurons: 201, Grad norm: 3.1478457800952078\n",
      "Epoch 5051, Loss: 208.90972025190518, Neurons: 201, Grad norm: 5.157508532166971\n",
      "Epoch 5051, Loss: 208.90972025190518, Neurons: 201, Grad norm: 5.157508532166971\n",
      "Epoch 5052, Loss: 208.909827725586, Neurons: 201, Grad norm: 6.444676274035986\n",
      "Epoch 5052, Loss: 208.909827725586, Neurons: 201, Grad norm: 6.444676274035986\n",
      "Epoch 5053, Loss: 208.90996809728912, Neurons: 201, Grad norm: 7.659934064548778\n",
      "Epoch 5053, Loss: 208.90996809728912, Neurons: 201, Grad norm: 7.659934064548778\n",
      "Epoch 5054, Loss: 208.91015988007314, Neurons: 201, Grad norm: 7.805671322945554\n",
      "Epoch 5054, Loss: 208.91015988007314, Neurons: 201, Grad norm: 7.805671322945554\n",
      "Epoch 5055, Loss: 208.91014610264355, Neurons: 201, Grad norm: 7.506985380144243\n",
      "Epoch 5055, Loss: 208.91014610264355, Neurons: 201, Grad norm: 7.506985380144243\n",
      "Epoch 5056, Loss: 208.90995942361138, Neurons: 201, Grad norm: 6.43856370142085\n",
      "Epoch 5056, Loss: 208.90995942361138, Neurons: 201, Grad norm: 6.43856370142085\n",
      "Epoch 5057, Loss: 208.90961323464074, Neurons: 201, Grad norm: 4.903897988384167\n",
      "Epoch 5057, Loss: 208.90961323464074, Neurons: 201, Grad norm: 4.903897988384167\n",
      "Epoch 5058, Loss: 208.90928777208327, Neurons: 201, Grad norm: 3.178556602215791\n",
      "Epoch 5058, Loss: 208.90928777208327, Neurons: 201, Grad norm: 3.178556602215791\n",
      "Epoch 5059, Loss: 208.90901482365913, Neurons: 201, Grad norm: 1.255530009801666\n",
      "Epoch 5059, Loss: 208.90901482365913, Neurons: 201, Grad norm: 1.255530009801666\n",
      "Epoch 5060, Loss: 208.90882682722253, Neurons: 201, Grad norm: 0.8402938903747138\n",
      "Epoch 5060, Loss: 208.90882682722253, Neurons: 201, Grad norm: 0.8402938903747138\n",
      "Epoch 5061, Loss: 208.90872843504425, Neurons: 201, Grad norm: 2.3309306752322216\n",
      "Epoch 5061, Loss: 208.90872843504425, Neurons: 201, Grad norm: 2.3309306752322216\n",
      "Epoch 5062, Loss: 208.90868744595127, Neurons: 201, Grad norm: 3.9968556544820615\n",
      "Epoch 5062, Loss: 208.90868744595127, Neurons: 201, Grad norm: 3.9968556544820615\n",
      "Epoch 5063, Loss: 208.90873127287057, Neurons: 201, Grad norm: 5.147692259889566\n",
      "Epoch 5063, Loss: 208.90873127287057, Neurons: 201, Grad norm: 5.147692259889566\n",
      "Epoch 5064, Loss: 208.90881489193168, Neurons: 201, Grad norm: 6.013360043128218\n",
      "Epoch 5064, Loss: 208.90881489193168, Neurons: 201, Grad norm: 6.013360043128218\n",
      "Epoch 5065, Loss: 208.908881090077, Neurons: 201, Grad norm: 6.540344134888173\n",
      "Epoch 5065, Loss: 208.908881090077, Neurons: 201, Grad norm: 6.540344134888173\n",
      "Epoch 5066, Loss: 208.90886116297585, Neurons: 201, Grad norm: 6.662637542375923\n",
      "Epoch 5066, Loss: 208.90886116297585, Neurons: 201, Grad norm: 6.662637542375923\n",
      "Epoch 5067, Loss: 208.9088011818155, Neurons: 201, Grad norm: 5.944484934135079\n",
      "Epoch 5067, Loss: 208.9088011818155, Neurons: 201, Grad norm: 5.944484934135079\n",
      "Epoch 5068, Loss: 208.90865140303322, Neurons: 201, Grad norm: 5.0632750531546025\n",
      "Epoch 5068, Loss: 208.90865140303322, Neurons: 201, Grad norm: 5.0632750531546025\n",
      "Epoch 5069, Loss: 208.9083530613565, Neurons: 201, Grad norm: 3.505956367734194\n",
      "Epoch 5069, Loss: 208.9083530613565, Neurons: 201, Grad norm: 3.505956367734194\n",
      "Epoch 5070, Loss: 208.9080915534063, Neurons: 201, Grad norm: 1.9642104097952007\n",
      "Epoch 5070, Loss: 208.9080915534063, Neurons: 201, Grad norm: 1.9642104097952007\n",
      "Epoch 5071, Loss: 208.90788970987853, Neurons: 201, Grad norm: 0.643229244962763\n",
      "Epoch 5071, Loss: 208.90788970987853, Neurons: 201, Grad norm: 0.643229244962763\n",
      "Epoch 5072, Loss: 208.90774730739716, Neurons: 201, Grad norm: 1.2466711144335905\n",
      "Epoch 5072, Loss: 208.90774730739716, Neurons: 201, Grad norm: 1.2466711144335905\n",
      "Epoch 5073, Loss: 208.9076706418992, Neurons: 201, Grad norm: 2.58909100703039\n",
      "Epoch 5073, Loss: 208.9076706418992, Neurons: 201, Grad norm: 2.58909100703039\n",
      "Epoch 5074, Loss: 208.90766032187383, Neurons: 201, Grad norm: 3.609728974135928\n",
      "Epoch 5074, Loss: 208.90766032187383, Neurons: 201, Grad norm: 3.609728974135928\n",
      "Epoch 5075, Loss: 208.9076910759127, Neurons: 201, Grad norm: 4.953343678469488\n",
      "Epoch 5075, Loss: 208.9076910759127, Neurons: 201, Grad norm: 4.953343678469488\n",
      "Epoch 5076, Loss: 208.90773737571962, Neurons: 201, Grad norm: 5.668897390190241\n",
      "Epoch 5076, Loss: 208.90773737571962, Neurons: 201, Grad norm: 5.668897390190241\n",
      "Epoch 5077, Loss: 208.90777041001496, Neurons: 201, Grad norm: 6.356625674798366\n",
      "Epoch 5077, Loss: 208.90777041001496, Neurons: 201, Grad norm: 6.356625674798366\n",
      "Epoch 5078, Loss: 208.90780847337186, Neurons: 201, Grad norm: 6.531018099353762\n",
      "Epoch 5078, Loss: 208.90780847337186, Neurons: 201, Grad norm: 6.531018099353762\n",
      "Epoch 5079, Loss: 208.90773854279809, Neurons: 201, Grad norm: 6.4882714899054905\n",
      "Epoch 5079, Loss: 208.90773854279809, Neurons: 201, Grad norm: 6.4882714899054905\n",
      "Epoch 5080, Loss: 208.90765695088413, Neurons: 201, Grad norm: 5.894284763043978\n",
      "Epoch 5080, Loss: 208.90765695088413, Neurons: 201, Grad norm: 5.894284763043978\n",
      "Epoch 5081, Loss: 208.90745845486182, Neurons: 201, Grad norm: 5.03879136220995\n",
      "Epoch 5081, Loss: 208.90745845486182, Neurons: 201, Grad norm: 5.03879136220995\n",
      "Epoch 5082, Loss: 208.90723687566765, Neurons: 201, Grad norm: 3.8923975158159188\n",
      "Epoch 5082, Loss: 208.90723687566765, Neurons: 201, Grad norm: 3.8923975158159188\n",
      "Epoch 5083, Loss: 208.9070256243353, Neurons: 201, Grad norm: 2.597358829914889\n",
      "Epoch 5083, Loss: 208.9070256243353, Neurons: 201, Grad norm: 2.597358829914889\n",
      "Epoch 5084, Loss: 208.9068146315651, Neurons: 201, Grad norm: 1.178045904556973\n",
      "Epoch 5084, Loss: 208.9068146315651, Neurons: 201, Grad norm: 1.178045904556973\n",
      "Epoch 5085, Loss: 208.9066652845625, Neurons: 201, Grad norm: 0.6685335805634314\n",
      "Epoch 5085, Loss: 208.9066652845625, Neurons: 201, Grad norm: 0.6685335805634314\n",
      "Epoch 5086, Loss: 208.90652589241083, Neurons: 201, Grad norm: 1.9292347178055809\n",
      "Epoch 5086, Loss: 208.90652589241083, Neurons: 201, Grad norm: 1.9292347178055809\n",
      "Epoch 5087, Loss: 208.9064931764254, Neurons: 201, Grad norm: 3.389641556090131\n",
      "Epoch 5087, Loss: 208.9064931764254, Neurons: 201, Grad norm: 3.389641556090131\n",
      "Epoch 5088, Loss: 208.90653777727402, Neurons: 201, Grad norm: 4.965024628142364\n",
      "Epoch 5088, Loss: 208.90653777727402, Neurons: 201, Grad norm: 4.965024628142364\n",
      "Epoch 5089, Loss: 208.90658603933178, Neurons: 201, Grad norm: 5.877483930732286\n",
      "Epoch 5089, Loss: 208.90658603933178, Neurons: 201, Grad norm: 5.877483930732286\n",
      "Epoch 5090, Loss: 208.9066596788888, Neurons: 201, Grad norm: 6.77832048679902\n",
      "Epoch 5090, Loss: 208.9066596788888, Neurons: 201, Grad norm: 6.77832048679902\n",
      "Epoch 5091, Loss: 208.90667634846574, Neurons: 201, Grad norm: 7.059746323935269\n",
      "Epoch 5091, Loss: 208.90667634846574, Neurons: 201, Grad norm: 7.059746323935269\n",
      "Epoch 5092, Loss: 208.9066283390907, Neurons: 201, Grad norm: 7.192358484472212\n",
      "Epoch 5092, Loss: 208.9066283390907, Neurons: 201, Grad norm: 7.192358484472212\n",
      "Epoch 5093, Loss: 208.90666237345528, Neurons: 201, Grad norm: 6.518389994081746\n",
      "Epoch 5093, Loss: 208.90666237345528, Neurons: 201, Grad norm: 6.518389994081746\n",
      "Epoch 5094, Loss: 208.90642398398705, Neurons: 201, Grad norm: 5.348184992460062\n",
      "Epoch 5094, Loss: 208.90642398398705, Neurons: 201, Grad norm: 5.348184992460062\n",
      "Epoch 5095, Loss: 208.9061462287046, Neurons: 201, Grad norm: 3.74775576629443\n",
      "Epoch 5095, Loss: 208.9061462287046, Neurons: 201, Grad norm: 3.74775576629443\n",
      "Epoch 5096, Loss: 208.905850043353, Neurons: 201, Grad norm: 1.8474095433031494\n",
      "Epoch 5096, Loss: 208.905850043353, Neurons: 201, Grad norm: 1.8474095433031494\n",
      "Epoch 5097, Loss: 208.9055915878582, Neurons: 201, Grad norm: 0.8562628944955903\n",
      "Epoch 5097, Loss: 208.9055915878582, Neurons: 201, Grad norm: 0.8562628944955903\n",
      "Epoch 5098, Loss: 208.90552570537022, Neurons: 201, Grad norm: 1.8359076346357417\n",
      "Epoch 5098, Loss: 208.90552570537022, Neurons: 201, Grad norm: 1.8359076346357417\n",
      "Epoch 5099, Loss: 208.9054161284491, Neurons: 201, Grad norm: 3.689582993599404\n",
      "Epoch 5099, Loss: 208.9054161284491, Neurons: 201, Grad norm: 3.689582993599404\n",
      "Epoch 5100, Loss: 208.90546488647087, Neurons: 201, Grad norm: 5.3964319639769895\n",
      "Epoch 5100, Loss: 208.90546488647087, Neurons: 201, Grad norm: 5.3964319639769895\n",
      "Epoch 5101, Loss: 208.90561722681346, Neurons: 201, Grad norm: 6.979785006892123\n",
      "Epoch 5101, Loss: 208.90561722681346, Neurons: 201, Grad norm: 6.979785006892123\n",
      "Epoch 5102, Loss: 208.9057571382523, Neurons: 201, Grad norm: 7.958688756537915\n",
      "Epoch 5102, Loss: 208.9057571382523, Neurons: 201, Grad norm: 7.958688756537915\n",
      "Epoch 5103, Loss: 208.90594452097963, Neurons: 201, Grad norm: 8.256601966568725\n",
      "Epoch 5103, Loss: 208.90594452097963, Neurons: 201, Grad norm: 8.256601966568725\n",
      "Epoch 5104, Loss: 208.90593421378574, Neurons: 201, Grad norm: 7.691510564238912\n",
      "Epoch 5104, Loss: 208.90593421378574, Neurons: 201, Grad norm: 7.691510564238912\n",
      "Epoch 5105, Loss: 208.90567751353342, Neurons: 201, Grad norm: 6.452568447146581\n",
      "Epoch 5105, Loss: 208.90567751353342, Neurons: 201, Grad norm: 6.452568447146581\n",
      "Epoch 5106, Loss: 208.90537318870213, Neurons: 201, Grad norm: 4.626776053956826\n",
      "Epoch 5106, Loss: 208.90537318870213, Neurons: 201, Grad norm: 4.626776053956826\n",
      "Epoch 5107, Loss: 208.9049671564218, Neurons: 201, Grad norm: 2.7002186789109106\n",
      "Epoch 5107, Loss: 208.9049671564218, Neurons: 201, Grad norm: 2.7002186789109106\n",
      "Epoch 5108, Loss: 208.90467102677405, Neurons: 201, Grad norm: 0.7205842546128093\n",
      "Epoch 5108, Loss: 208.90467102677405, Neurons: 201, Grad norm: 0.7205842546128093\n",
      "Epoch 5109, Loss: 208.90449579822356, Neurons: 201, Grad norm: 1.2697414955985908\n",
      "Epoch 5109, Loss: 208.90449579822356, Neurons: 201, Grad norm: 1.2697414955985908\n",
      "Epoch 5110, Loss: 208.90441734261665, Neurons: 201, Grad norm: 2.91975104820001\n",
      "Epoch 5110, Loss: 208.90441734261665, Neurons: 201, Grad norm: 2.91975104820001\n",
      "Epoch 5111, Loss: 208.9044315701695, Neurons: 201, Grad norm: 4.2211590275064985\n",
      "Epoch 5111, Loss: 208.9044315701695, Neurons: 201, Grad norm: 4.2211590275064985\n",
      "Epoch 5112, Loss: 208.9044779637852, Neurons: 201, Grad norm: 5.591990791161603\n",
      "Epoch 5112, Loss: 208.9044779637852, Neurons: 201, Grad norm: 5.591990791161603\n",
      "Epoch 5113, Loss: 208.90457542193215, Neurons: 201, Grad norm: 6.719991532278082\n",
      "Epoch 5113, Loss: 208.90457542193215, Neurons: 201, Grad norm: 6.719991532278082\n",
      "Epoch 5114, Loss: 208.9047137416166, Neurons: 201, Grad norm: 7.401289903551805\n",
      "Epoch 5114, Loss: 208.9047137416166, Neurons: 201, Grad norm: 7.401289903551805\n",
      "Epoch 5115, Loss: 208.90476517048512, Neurons: 201, Grad norm: 7.65134851517545\n",
      "Epoch 5115, Loss: 208.90476517048512, Neurons: 201, Grad norm: 7.65134851517545\n",
      "Epoch 5116, Loss: 208.90470455047173, Neurons: 201, Grad norm: 7.300907121161536\n",
      "Epoch 5116, Loss: 208.90470455047173, Neurons: 201, Grad norm: 7.300907121161536\n",
      "Epoch 5117, Loss: 208.90458149523914, Neurons: 201, Grad norm: 6.271513384935377\n",
      "Epoch 5117, Loss: 208.90458149523914, Neurons: 201, Grad norm: 6.271513384935377\n",
      "Epoch 5118, Loss: 208.9043045931151, Neurons: 201, Grad norm: 4.903535373429067\n",
      "Epoch 5118, Loss: 208.9043045931151, Neurons: 201, Grad norm: 4.903535373429067\n",
      "Epoch 5119, Loss: 208.9040195359969, Neurons: 201, Grad norm: 2.9887722299969113\n",
      "Epoch 5119, Loss: 208.9040195359969, Neurons: 201, Grad norm: 2.9887722299969113\n",
      "Epoch 5120, Loss: 208.9037026427658, Neurons: 201, Grad norm: 1.6094481593137262\n",
      "Epoch 5120, Loss: 208.9037026427658, Neurons: 201, Grad norm: 1.6094481593137262\n",
      "Epoch 5121, Loss: 208.90356067974773, Neurons: 201, Grad norm: 0.7278444614775473\n",
      "Epoch 5121, Loss: 208.90356067974773, Neurons: 201, Grad norm: 0.7278444614775473\n",
      "Epoch 5122, Loss: 208.9034079476551, Neurons: 201, Grad norm: 1.8991979363808198\n",
      "Epoch 5122, Loss: 208.9034079476551, Neurons: 201, Grad norm: 1.8991979363808198\n",
      "Epoch 5123, Loss: 208.90334223155278, Neurons: 201, Grad norm: 3.4343579041040937\n",
      "Epoch 5123, Loss: 208.90334223155278, Neurons: 201, Grad norm: 3.4343579041040937\n",
      "Epoch 5124, Loss: 208.90338943214027, Neurons: 201, Grad norm: 4.8368441070118084\n",
      "Epoch 5124, Loss: 208.90338943214027, Neurons: 201, Grad norm: 4.8368441070118084\n",
      "Epoch 5125, Loss: 208.903451922383, Neurons: 201, Grad norm: 6.13658483920054\n",
      "Epoch 5125, Loss: 208.903451922383, Neurons: 201, Grad norm: 6.13658483920054\n",
      "Epoch 5126, Loss: 208.90356268848248, Neurons: 201, Grad norm: 7.121915789586752\n",
      "Epoch 5126, Loss: 208.90356268848248, Neurons: 201, Grad norm: 7.121915789586752\n",
      "Epoch 5127, Loss: 208.9036839929479, Neurons: 201, Grad norm: 7.866760386871829\n",
      "Epoch 5127, Loss: 208.9036839929479, Neurons: 201, Grad norm: 7.866760386871829\n",
      "Epoch 5128, Loss: 208.90371849036126, Neurons: 201, Grad norm: 7.722404714668943\n",
      "Epoch 5128, Loss: 208.90371849036126, Neurons: 201, Grad norm: 7.722404714668943\n",
      "Epoch 5129, Loss: 208.9036865431918, Neurons: 201, Grad norm: 6.892524338995076\n",
      "Epoch 5129, Loss: 208.9036865431918, Neurons: 201, Grad norm: 6.892524338995076\n",
      "Epoch 5130, Loss: 208.90340512997292, Neurons: 201, Grad norm: 5.1618208048528675\n",
      "Epoch 5130, Loss: 208.90340512997292, Neurons: 201, Grad norm: 5.1618208048528675\n",
      "Epoch 5131, Loss: 208.9029674507698, Neurons: 201, Grad norm: 3.2986674131593916\n",
      "Epoch 5131, Loss: 208.9029674507698, Neurons: 201, Grad norm: 3.2986674131593916\n",
      "Epoch 5132, Loss: 208.90265665796315, Neurons: 201, Grad norm: 1.1419680109182244\n",
      "Epoch 5132, Loss: 208.90265665796315, Neurons: 201, Grad norm: 1.1419680109182244\n",
      "Epoch 5133, Loss: 208.90248369528413, Neurons: 201, Grad norm: 1.1266696982816513\n",
      "Epoch 5133, Loss: 208.90248369528413, Neurons: 201, Grad norm: 1.1266696982816513\n",
      "Epoch 5134, Loss: 208.90235276996918, Neurons: 201, Grad norm: 2.796849432940319\n",
      "Epoch 5134, Loss: 208.90235276996918, Neurons: 201, Grad norm: 2.796849432940319\n",
      "Epoch 5135, Loss: 208.90236574254433, Neurons: 201, Grad norm: 4.447564512523421\n",
      "Epoch 5135, Loss: 208.90236574254433, Neurons: 201, Grad norm: 4.447564512523421\n",
      "Epoch 5136, Loss: 208.90243599277943, Neurons: 201, Grad norm: 5.8954098293367405\n",
      "Epoch 5136, Loss: 208.90243599277943, Neurons: 201, Grad norm: 5.8954098293367405\n",
      "Epoch 5137, Loss: 208.9025490450467, Neurons: 201, Grad norm: 6.69381471814539\n",
      "Epoch 5137, Loss: 208.9025490450467, Neurons: 201, Grad norm: 6.69381471814539\n",
      "Epoch 5138, Loss: 208.90261024898564, Neurons: 201, Grad norm: 7.545658451591471\n",
      "Epoch 5138, Loss: 208.90261024898564, Neurons: 201, Grad norm: 7.545658451591471\n",
      "Epoch 5139, Loss: 208.9027138058187, Neurons: 201, Grad norm: 7.392517204161184\n",
      "Epoch 5139, Loss: 208.9027138058187, Neurons: 201, Grad norm: 7.392517204161184\n",
      "Epoch 5140, Loss: 208.90258216557015, Neurons: 201, Grad norm: 6.924758844250989\n",
      "Epoch 5140, Loss: 208.90258216557015, Neurons: 201, Grad norm: 6.924758844250989\n",
      "Epoch 5141, Loss: 208.90237480443906, Neurons: 201, Grad norm: 5.7644912924847125\n",
      "Epoch 5141, Loss: 208.90237480443906, Neurons: 201, Grad norm: 5.7644912924847125\n",
      "Epoch 5142, Loss: 208.90204521161925, Neurons: 201, Grad norm: 3.946988189848113\n",
      "Epoch 5142, Loss: 208.90204521161925, Neurons: 201, Grad norm: 3.946988189848113\n",
      "Epoch 5143, Loss: 208.9017861027737, Neurons: 201, Grad norm: 1.8600013781800107\n",
      "Epoch 5143, Loss: 208.9017861027737, Neurons: 201, Grad norm: 1.8600013781800107\n",
      "Epoch 5144, Loss: 208.90149297579583, Neurons: 201, Grad norm: 0.5986450006344064\n",
      "Epoch 5144, Loss: 208.90149297579583, Neurons: 201, Grad norm: 0.5986450006344064\n",
      "Epoch 5145, Loss: 208.9013356454891, Neurons: 201, Grad norm: 2.2436137094345923\n",
      "Epoch 5145, Loss: 208.9013356454891, Neurons: 201, Grad norm: 2.2436137094345923\n",
      "Epoch 5146, Loss: 208.90131952365502, Neurons: 201, Grad norm: 3.7065358269288\n",
      "Epoch 5146, Loss: 208.90131952365502, Neurons: 201, Grad norm: 3.7065358269288\n",
      "Epoch 5147, Loss: 208.9013991117123, Neurons: 201, Grad norm: 5.380414099663395\n",
      "Epoch 5147, Loss: 208.9013991117123, Neurons: 201, Grad norm: 5.380414099663395\n",
      "Epoch 5148, Loss: 208.90148135905537, Neurons: 201, Grad norm: 6.408760276898936\n",
      "Epoch 5148, Loss: 208.90148135905537, Neurons: 201, Grad norm: 6.408760276898936\n",
      "Epoch 5149, Loss: 208.90156341122236, Neurons: 201, Grad norm: 7.075594768313269\n",
      "Epoch 5149, Loss: 208.90156341122236, Neurons: 201, Grad norm: 7.075594768313269\n",
      "Epoch 5150, Loss: 208.90159656560013, Neurons: 201, Grad norm: 7.307802695297422\n",
      "Epoch 5150, Loss: 208.90159656560013, Neurons: 201, Grad norm: 7.307802695297422\n",
      "Epoch 5151, Loss: 208.90155116471172, Neurons: 201, Grad norm: 7.057016600619008\n",
      "Epoch 5151, Loss: 208.90155116471172, Neurons: 201, Grad norm: 7.057016600619008\n",
      "Epoch 5152, Loss: 208.90138970265733, Neurons: 201, Grad norm: 6.3849578766730835\n",
      "Epoch 5152, Loss: 208.90138970265733, Neurons: 201, Grad norm: 6.3849578766730835\n",
      "Epoch 5153, Loss: 208.90117636293343, Neurons: 201, Grad norm: 5.650451299887107\n",
      "Epoch 5153, Loss: 208.90117636293343, Neurons: 201, Grad norm: 5.650451299887107\n",
      "Epoch 5154, Loss: 208.9009873572956, Neurons: 201, Grad norm: 4.425177735707169\n",
      "Epoch 5154, Loss: 208.9009873572956, Neurons: 201, Grad norm: 4.425177735707169\n",
      "Epoch 5155, Loss: 208.9007418552087, Neurons: 201, Grad norm: 3.2846783021561365\n",
      "Epoch 5155, Loss: 208.9007418552087, Neurons: 201, Grad norm: 3.2846783021561365\n",
      "Epoch 5156, Loss: 208.90051855936042, Neurons: 201, Grad norm: 1.6967652798385635\n",
      "Epoch 5156, Loss: 208.90051855936042, Neurons: 201, Grad norm: 1.6967652798385635\n",
      "Epoch 5157, Loss: 208.90030859360542, Neurons: 201, Grad norm: 0.6347015429316983\n",
      "Epoch 5157, Loss: 208.90030859360542, Neurons: 201, Grad norm: 0.6347015429316983\n",
      "Epoch 5158, Loss: 208.9001803771333, Neurons: 201, Grad norm: 1.1827052169228827\n",
      "Epoch 5158, Loss: 208.9001803771333, Neurons: 201, Grad norm: 1.1827052169228827\n",
      "Epoch 5159, Loss: 208.9000784765198, Neurons: 201, Grad norm: 2.304088069179415\n",
      "Epoch 5159, Loss: 208.9000784765198, Neurons: 201, Grad norm: 2.304088069179415\n",
      "Epoch 5160, Loss: 208.90005018920155, Neurons: 201, Grad norm: 3.4501340615208203\n",
      "Epoch 5160, Loss: 208.90005018920155, Neurons: 201, Grad norm: 3.4501340615208203\n",
      "Epoch 5161, Loss: 208.9000333429975, Neurons: 201, Grad norm: 4.20534911819046\n",
      "Epoch 5161, Loss: 208.9000333429975, Neurons: 201, Grad norm: 4.20534911819046\n",
      "Epoch 5162, Loss: 208.9000475076922, Neurons: 201, Grad norm: 5.3589084300614\n",
      "Epoch 5162, Loss: 208.9000475076922, Neurons: 201, Grad norm: 5.3589084300614\n",
      "Epoch 5163, Loss: 208.9000991814781, Neurons: 201, Grad norm: 6.0696559541678505\n",
      "Epoch 5163, Loss: 208.9000991814781, Neurons: 201, Grad norm: 6.0696559541678505\n",
      "Epoch 5164, Loss: 208.9001417540306, Neurons: 201, Grad norm: 6.639223425479048\n",
      "Epoch 5164, Loss: 208.9001417540306, Neurons: 201, Grad norm: 6.639223425479048\n",
      "Epoch 5165, Loss: 208.90014073082796, Neurons: 201, Grad norm: 6.655709203518131\n",
      "Epoch 5165, Loss: 208.90014073082796, Neurons: 201, Grad norm: 6.655709203518131\n",
      "Epoch 5166, Loss: 208.9000521353067, Neurons: 201, Grad norm: 6.1880802692819\n",
      "Epoch 5166, Loss: 208.9000521353067, Neurons: 201, Grad norm: 6.1880802692819\n",
      "Epoch 5167, Loss: 208.89992814567043, Neurons: 201, Grad norm: 4.9596916206623884\n",
      "Epoch 5167, Loss: 208.89992814567043, Neurons: 201, Grad norm: 4.9596916206623884\n",
      "Epoch 5168, Loss: 208.89962790743417, Neurons: 201, Grad norm: 3.596283115056348\n",
      "Epoch 5168, Loss: 208.89962790743417, Neurons: 201, Grad norm: 3.596283115056348\n",
      "Epoch 5169, Loss: 208.89936157601792, Neurons: 201, Grad norm: 1.8852887761597001\n",
      "Epoch 5169, Loss: 208.89936157601792, Neurons: 201, Grad norm: 1.8852887761597001\n",
      "Epoch 5170, Loss: 208.89914748110473, Neurons: 201, Grad norm: 0.7115161038644586\n",
      "Epoch 5170, Loss: 208.89914748110473, Neurons: 201, Grad norm: 0.7115161038644586\n",
      "Epoch 5171, Loss: 208.89900227209333, Neurons: 201, Grad norm: 0.732557630126793\n",
      "Epoch 5171, Loss: 208.89900227209333, Neurons: 201, Grad norm: 0.732557630126793\n",
      "Epoch 5172, Loss: 208.89890926343932, Neurons: 201, Grad norm: 1.6246453336417943\n",
      "Epoch 5172, Loss: 208.89890926343932, Neurons: 201, Grad norm: 1.6246453336417943\n",
      "Epoch 5173, Loss: 208.89884522708525, Neurons: 201, Grad norm: 2.6767171827417084\n",
      "Epoch 5173, Loss: 208.89884522708525, Neurons: 201, Grad norm: 2.6767171827417084\n",
      "Epoch 5174, Loss: 208.89883895079873, Neurons: 201, Grad norm: 3.7874224330442807\n",
      "Epoch 5174, Loss: 208.89883895079873, Neurons: 201, Grad norm: 3.7874224330442807\n",
      "Epoch 5175, Loss: 208.89884276674172, Neurons: 201, Grad norm: 5.0637311301403845\n",
      "Epoch 5175, Loss: 208.89884276674172, Neurons: 201, Grad norm: 5.0637311301403845\n",
      "Epoch 5176, Loss: 208.8989052553117, Neurons: 201, Grad norm: 5.933552012425733\n",
      "Epoch 5176, Loss: 208.8989052553117, Neurons: 201, Grad norm: 5.933552012425733\n",
      "Epoch 5177, Loss: 208.89894242717702, Neurons: 201, Grad norm: 6.914359676377014\n",
      "Epoch 5177, Loss: 208.89894242717702, Neurons: 201, Grad norm: 6.914359676377014\n",
      "Epoch 5178, Loss: 208.89903523527343, Neurons: 201, Grad norm: 7.011201200206037\n",
      "Epoch 5178, Loss: 208.89903523527343, Neurons: 201, Grad norm: 7.011201200206037\n",
      "Epoch 5179, Loss: 208.89902186414818, Neurons: 201, Grad norm: 7.145648728724712\n",
      "Epoch 5179, Loss: 208.89902186414818, Neurons: 201, Grad norm: 7.145648728724712\n",
      "Epoch 5180, Loss: 208.89893460399108, Neurons: 201, Grad norm: 6.440217010659175\n",
      "Epoch 5180, Loss: 208.89893460399108, Neurons: 201, Grad norm: 6.440217010659175\n",
      "Epoch 5181, Loss: 208.8986723501845, Neurons: 201, Grad norm: 5.419823517327513\n",
      "Epoch 5181, Loss: 208.8986723501845, Neurons: 201, Grad norm: 5.419823517327513\n",
      "Epoch 5182, Loss: 208.89846019140725, Neurons: 201, Grad norm: 4.043434544939156\n",
      "Epoch 5182, Loss: 208.89846019140725, Neurons: 201, Grad norm: 4.043434544939156\n",
      "Epoch 5183, Loss: 208.89814679942825, Neurons: 201, Grad norm: 2.2646056244566557\n",
      "Epoch 5183, Loss: 208.89814679942825, Neurons: 201, Grad norm: 2.2646056244566557\n",
      "Epoch 5184, Loss: 208.8979334115419, Neurons: 201, Grad norm: 0.8055565936760974\n",
      "Epoch 5184, Loss: 208.8979334115419, Neurons: 201, Grad norm: 0.8055565936760974\n",
      "Epoch 5185, Loss: 208.89775962807892, Neurons: 201, Grad norm: 0.9424070217447084\n",
      "Epoch 5185, Loss: 208.89775962807892, Neurons: 201, Grad norm: 0.9424070217447084\n",
      "Epoch 5186, Loss: 208.89767143214638, Neurons: 201, Grad norm: 2.3306824892654023\n",
      "Epoch 5186, Loss: 208.89767143214638, Neurons: 201, Grad norm: 2.3306824892654023\n",
      "Epoch 5187, Loss: 208.89764539310272, Neurons: 201, Grad norm: 3.6350948782679184\n",
      "Epoch 5187, Loss: 208.89764539310272, Neurons: 201, Grad norm: 3.6350948782679184\n",
      "Epoch 5188, Loss: 208.8977001009819, Neurons: 201, Grad norm: 5.157498533549008\n",
      "Epoch 5188, Loss: 208.8977001009819, Neurons: 201, Grad norm: 5.157498533549008\n",
      "Epoch 5189, Loss: 208.89774307521404, Neurons: 201, Grad norm: 5.770069620915143\n",
      "Epoch 5189, Loss: 208.89774307521404, Neurons: 201, Grad norm: 5.770069620915143\n",
      "Epoch 5190, Loss: 208.8977625184745, Neurons: 201, Grad norm: 6.3657815267025715\n",
      "Epoch 5190, Loss: 208.8977625184745, Neurons: 201, Grad norm: 6.3657815267025715\n",
      "Epoch 5191, Loss: 208.89777400517923, Neurons: 201, Grad norm: 6.228097711032847\n",
      "Epoch 5191, Loss: 208.89777400517923, Neurons: 201, Grad norm: 6.228097711032847\n",
      "Epoch 5192, Loss: 208.8976662966414, Neurons: 201, Grad norm: 5.872412607797628\n",
      "Epoch 5192, Loss: 208.8976662966414, Neurons: 201, Grad norm: 5.872412607797628\n",
      "Epoch 5193, Loss: 208.89754970991848, Neurons: 201, Grad norm: 5.285179802755033\n",
      "Epoch 5193, Loss: 208.89754970991848, Neurons: 201, Grad norm: 5.285179802755033\n",
      "Epoch 5194, Loss: 208.8972910633808, Neurons: 201, Grad norm: 4.30760829193385\n",
      "Epoch 5194, Loss: 208.8972910633808, Neurons: 201, Grad norm: 4.30760829193385\n",
      "Epoch 5195, Loss: 208.89703786209213, Neurons: 201, Grad norm: 2.976536989423436\n",
      "Epoch 5195, Loss: 208.89703786209213, Neurons: 201, Grad norm: 2.976536989423436\n",
      "Epoch 5196, Loss: 208.89678090758187, Neurons: 201, Grad norm: 1.6497566700973636\n",
      "Epoch 5196, Loss: 208.89678090758187, Neurons: 201, Grad norm: 1.6497566700973636\n",
      "Epoch 5197, Loss: 208.89646732027956, Neurons: 201, Grad norm: 0.6820735660991809\n",
      "Epoch 5197, Loss: 208.89646732027956, Neurons: 201, Grad norm: 0.6820735660991809\n",
      "Epoch 5198, Loss: 208.89622239496143, Neurons: 201, Grad norm: 0.9823606248637053\n",
      "Epoch 5198, Loss: 208.89622239496143, Neurons: 201, Grad norm: 0.9823606248637053\n",
      "Epoch 5199, Loss: 208.89595601349453, Neurons: 201, Grad norm: 1.794410282383404\n",
      "Epoch 5199, Loss: 208.89595601349453, Neurons: 201, Grad norm: 1.794410282383404\n",
      "Epoch 5200, Loss: 208.8959158948776, Neurons: 201, Grad norm: 2.883138917286952\n",
      "Epoch 5200, Loss: 208.8959158948776, Neurons: 201, Grad norm: 2.883138917286952\n",
      "Epoch 5201, Loss: 208.89597382526193, Neurons: 201, Grad norm: 4.018827457309317\n",
      "Epoch 5201, Loss: 208.89597382526193, Neurons: 201, Grad norm: 4.018827457309317\n",
      "Epoch 5202, Loss: 208.8960465711481, Neurons: 201, Grad norm: 4.723798212858459\n",
      "Epoch 5202, Loss: 208.8960465711481, Neurons: 201, Grad norm: 4.723798212858459\n",
      "Epoch 5203, Loss: 208.89609804692762, Neurons: 201, Grad norm: 5.7197265084726\n",
      "Epoch 5203, Loss: 208.89609804692762, Neurons: 201, Grad norm: 5.7197265084726\n",
      "Epoch 5204, Loss: 208.89613114081126, Neurons: 201, Grad norm: 6.485178507570206\n",
      "Epoch 5204, Loss: 208.89613114081126, Neurons: 201, Grad norm: 6.485178507570206\n",
      "Epoch 5205, Loss: 208.89618268190438, Neurons: 201, Grad norm: 7.162180325111502\n",
      "Epoch 5205, Loss: 208.89618268190438, Neurons: 201, Grad norm: 7.162180325111502\n",
      "Epoch 5206, Loss: 208.89627572271164, Neurons: 201, Grad norm: 7.134667164269056\n",
      "Epoch 5206, Loss: 208.89627572271164, Neurons: 201, Grad norm: 7.134667164269056\n",
      "Epoch 5207, Loss: 208.89614841551708, Neurons: 201, Grad norm: 6.802065700349785\n",
      "Epoch 5207, Loss: 208.89614841551708, Neurons: 201, Grad norm: 6.802065700349785\n",
      "Epoch 5208, Loss: 208.89599909273855, Neurons: 201, Grad norm: 5.481270118839991\n",
      "Epoch 5208, Loss: 208.89599909273855, Neurons: 201, Grad norm: 5.481270118839991\n",
      "Epoch 5209, Loss: 208.8956855937379, Neurons: 201, Grad norm: 3.783847770194099\n",
      "Epoch 5209, Loss: 208.8956855937379, Neurons: 201, Grad norm: 3.783847770194099\n",
      "Epoch 5210, Loss: 208.89525370904792, Neurons: 201, Grad norm: 1.8765156240243501\n",
      "Epoch 5210, Loss: 208.89525370904792, Neurons: 201, Grad norm: 1.8765156240243501\n",
      "Epoch 5211, Loss: 208.8949915841822, Neurons: 201, Grad norm: 0.8090787383772147\n",
      "Epoch 5211, Loss: 208.8949915841822, Neurons: 201, Grad norm: 0.8090787383772147\n",
      "Epoch 5212, Loss: 208.89486833397504, Neurons: 201, Grad norm: 2.1374943100968578\n",
      "Epoch 5212, Loss: 208.89486833397504, Neurons: 201, Grad norm: 2.1374943100968578\n",
      "Epoch 5213, Loss: 208.89477123540078, Neurons: 201, Grad norm: 3.894739519069596\n",
      "Epoch 5213, Loss: 208.89477123540078, Neurons: 201, Grad norm: 3.894739519069596\n",
      "Epoch 5214, Loss: 208.89488055355653, Neurons: 201, Grad norm: 5.721155092883082\n",
      "Epoch 5214, Loss: 208.89488055355653, Neurons: 201, Grad norm: 5.721155092883082\n",
      "Epoch 5215, Loss: 208.8950320640763, Neurons: 201, Grad norm: 7.091576592544923\n",
      "Epoch 5215, Loss: 208.8950320640763, Neurons: 201, Grad norm: 7.091576592544923\n",
      "Epoch 5216, Loss: 208.89516845737245, Neurons: 201, Grad norm: 8.328081717818943\n",
      "Epoch 5216, Loss: 208.89516845737245, Neurons: 201, Grad norm: 8.328081717818943\n",
      "Epoch 5217, Loss: 208.89538699721578, Neurons: 201, Grad norm: 8.3384983849258\n",
      "Epoch 5217, Loss: 208.89538699721578, Neurons: 201, Grad norm: 8.3384983849258\n",
      "Epoch 5218, Loss: 208.8952497606013, Neurons: 201, Grad norm: 7.961367399326874\n",
      "Epoch 5218, Loss: 208.8952497606013, Neurons: 201, Grad norm: 7.961367399326874\n",
      "Epoch 5219, Loss: 208.89509455936562, Neurons: 201, Grad norm: 6.414598134666854\n",
      "Epoch 5219, Loss: 208.89509455936562, Neurons: 201, Grad norm: 6.414598134666854\n",
      "Epoch 5220, Loss: 208.89474939679758, Neurons: 201, Grad norm: 4.2929399112644395\n",
      "Epoch 5220, Loss: 208.89474939679758, Neurons: 201, Grad norm: 4.2929399112644395\n",
      "Epoch 5221, Loss: 208.89429001540242, Neurons: 201, Grad norm: 1.575171869900785\n",
      "Epoch 5221, Loss: 208.89429001540242, Neurons: 201, Grad norm: 1.575171869900785\n",
      "Epoch 5222, Loss: 208.8939601746376, Neurons: 201, Grad norm: 1.5350361124567142\n",
      "Epoch 5222, Loss: 208.8939601746376, Neurons: 201, Grad norm: 1.5350361124567142\n",
      "Epoch 5223, Loss: 208.89392457975967, Neurons: 201, Grad norm: 3.735225131826773\n",
      "Epoch 5223, Loss: 208.89392457975967, Neurons: 201, Grad norm: 3.735225131826773\n",
      "Epoch 5224, Loss: 208.89396002848224, Neurons: 201, Grad norm: 5.525519535230822\n",
      "Epoch 5224, Loss: 208.89396002848224, Neurons: 201, Grad norm: 5.525519535230822\n",
      "Epoch 5225, Loss: 208.89405986373387, Neurons: 201, Grad norm: 6.689007465253716\n",
      "Epoch 5225, Loss: 208.89405986373387, Neurons: 201, Grad norm: 6.689007465253716\n",
      "Epoch 5226, Loss: 208.89419193377435, Neurons: 201, Grad norm: 7.1900983169204515\n",
      "Epoch 5226, Loss: 208.89419193377435, Neurons: 201, Grad norm: 7.1900983169204515\n",
      "Epoch 5227, Loss: 208.89420585886654, Neurons: 201, Grad norm: 7.277703159383108\n",
      "Epoch 5227, Loss: 208.89420585886654, Neurons: 201, Grad norm: 7.277703159383108\n",
      "Epoch 5228, Loss: 208.89408173074136, Neurons: 201, Grad norm: 6.507968531265821\n",
      "Epoch 5228, Loss: 208.89408173074136, Neurons: 201, Grad norm: 6.507968531265821\n",
      "Epoch 5229, Loss: 208.89395643866985, Neurons: 201, Grad norm: 5.641645597975392\n",
      "Epoch 5229, Loss: 208.89395643866985, Neurons: 201, Grad norm: 5.641645597975392\n",
      "Epoch 5230, Loss: 208.89367088583214, Neurons: 201, Grad norm: 4.086712613020699\n",
      "Epoch 5230, Loss: 208.89367088583214, Neurons: 201, Grad norm: 4.086712613020699\n",
      "Epoch 5231, Loss: 208.8933491733235, Neurons: 201, Grad norm: 2.428341186293923\n",
      "Epoch 5231, Loss: 208.8933491733235, Neurons: 201, Grad norm: 2.428341186293923\n",
      "Epoch 5232, Loss: 208.89311970319946, Neurons: 201, Grad norm: 0.5503949363293449\n",
      "Epoch 5232, Loss: 208.89311970319946, Neurons: 201, Grad norm: 0.5503949363293449\n",
      "Epoch 5233, Loss: 208.8929124364886, Neurons: 201, Grad norm: 1.772644408780515\n",
      "Epoch 5233, Loss: 208.8929124364886, Neurons: 201, Grad norm: 1.772644408780515\n",
      "Epoch 5234, Loss: 208.89287203846217, Neurons: 201, Grad norm: 3.784708396648386\n",
      "Epoch 5234, Loss: 208.89287203846217, Neurons: 201, Grad norm: 3.784708396648386\n",
      "Epoch 5235, Loss: 208.8929671247396, Neurons: 201, Grad norm: 5.403694152815241\n",
      "Epoch 5235, Loss: 208.8929671247396, Neurons: 201, Grad norm: 5.403694152815241\n",
      "Epoch 5236, Loss: 208.89303645220127, Neurons: 201, Grad norm: 7.128706844221676\n",
      "Epoch 5236, Loss: 208.89303645220127, Neurons: 201, Grad norm: 7.128706844221676\n",
      "Epoch 5237, Loss: 208.89323211819496, Neurons: 201, Grad norm: 8.257044679212584\n",
      "Epoch 5237, Loss: 208.89323211819496, Neurons: 201, Grad norm: 8.257044679212584\n",
      "Epoch 5238, Loss: 208.8934319861103, Neurons: 201, Grad norm: 8.963132216367262\n",
      "Epoch 5238, Loss: 208.8934319861103, Neurons: 201, Grad norm: 8.963132216367262\n",
      "Epoch 5239, Loss: 208.89351413729608, Neurons: 201, Grad norm: 8.826155702546924\n",
      "Epoch 5239, Loss: 208.89351413729608, Neurons: 201, Grad norm: 8.826155702546924\n",
      "Epoch 5240, Loss: 208.89338244607083, Neurons: 201, Grad norm: 7.878588602868752\n",
      "Epoch 5240, Loss: 208.89338244607083, Neurons: 201, Grad norm: 7.878588602868752\n",
      "Epoch 5241, Loss: 208.8931026684131, Neurons: 201, Grad norm: 5.919221797465506\n",
      "Epoch 5241, Loss: 208.8931026684131, Neurons: 201, Grad norm: 5.919221797465506\n",
      "Epoch 5242, Loss: 208.89265606364785, Neurons: 201, Grad norm: 3.72517676009258\n",
      "Epoch 5242, Loss: 208.89265606364785, Neurons: 201, Grad norm: 3.72517676009258\n",
      "Epoch 5243, Loss: 208.89223449775676, Neurons: 201, Grad norm: 1.246689839693863\n",
      "Epoch 5243, Loss: 208.89223449775676, Neurons: 201, Grad norm: 1.246689839693863\n",
      "Epoch 5244, Loss: 208.89201044351609, Neurons: 201, Grad norm: 1.4537032798271543\n",
      "Epoch 5244, Loss: 208.89201044351609, Neurons: 201, Grad norm: 1.4537032798271543\n",
      "Epoch 5245, Loss: 208.89190357954294, Neurons: 201, Grad norm: 3.435599081817936\n",
      "Epoch 5245, Loss: 208.89190357954294, Neurons: 201, Grad norm: 3.435599081817936\n",
      "Epoch 5246, Loss: 208.89195220428192, Neurons: 201, Grad norm: 5.258419784682863\n",
      "Epoch 5246, Loss: 208.89195220428192, Neurons: 201, Grad norm: 5.258419784682863\n",
      "Epoch 5247, Loss: 208.8921309890651, Neurons: 201, Grad norm: 6.810552942370834\n",
      "Epoch 5247, Loss: 208.8921309890651, Neurons: 201, Grad norm: 6.810552942370834\n",
      "Epoch 5248, Loss: 208.89226464474262, Neurons: 201, Grad norm: 7.727635274383292\n",
      "Epoch 5248, Loss: 208.89226464474262, Neurons: 201, Grad norm: 7.727635274383292\n",
      "Epoch 5249, Loss: 208.8923465695835, Neurons: 201, Grad norm: 8.2003220768463\n",
      "Epoch 5249, Loss: 208.8923465695835, Neurons: 201, Grad norm: 8.2003220768463\n",
      "Epoch 5250, Loss: 208.89238198657253, Neurons: 201, Grad norm: 7.653292192297489\n",
      "Epoch 5250, Loss: 208.89238198657253, Neurons: 201, Grad norm: 7.653292192297489\n",
      "Epoch 5251, Loss: 208.8921890066293, Neurons: 201, Grad norm: 6.803249236453068\n",
      "Epoch 5251, Loss: 208.8921890066293, Neurons: 201, Grad norm: 6.803249236453068\n",
      "Epoch 5252, Loss: 208.89192554348253, Neurons: 201, Grad norm: 4.856430000921455\n",
      "Epoch 5252, Loss: 208.89192554348253, Neurons: 201, Grad norm: 4.856430000921455\n",
      "Epoch 5253, Loss: 208.89152808193077, Neurons: 201, Grad norm: 3.1462879106962554\n",
      "Epoch 5253, Loss: 208.89152808193077, Neurons: 201, Grad norm: 3.1462879106962554\n",
      "Epoch 5254, Loss: 208.89120079526128, Neurons: 201, Grad norm: 1.0757713017064805\n",
      "Epoch 5254, Loss: 208.89120079526128, Neurons: 201, Grad norm: 1.0757713017064805\n",
      "Epoch 5255, Loss: 208.89102926835403, Neurons: 201, Grad norm: 1.2448188944154268\n",
      "Epoch 5255, Loss: 208.89102926835403, Neurons: 201, Grad norm: 1.2448188944154268\n",
      "Epoch 5256, Loss: 208.89094282979562, Neurons: 201, Grad norm: 2.709034587804417\n",
      "Epoch 5256, Loss: 208.89094282979562, Neurons: 201, Grad norm: 2.709034587804417\n",
      "Epoch 5257, Loss: 208.89092065428315, Neurons: 201, Grad norm: 4.19412950806309\n",
      "Epoch 5257, Loss: 208.89092065428315, Neurons: 201, Grad norm: 4.19412950806309\n",
      "Epoch 5258, Loss: 208.89094877463555, Neurons: 201, Grad norm: 5.1299537577682095\n",
      "Epoch 5258, Loss: 208.89094877463555, Neurons: 201, Grad norm: 5.1299537577682095\n",
      "Epoch 5259, Loss: 208.89097099596958, Neurons: 201, Grad norm: 5.755168649715181\n",
      "Epoch 5259, Loss: 208.89097099596958, Neurons: 201, Grad norm: 5.755168649715181\n",
      "Epoch 5260, Loss: 208.89099227046296, Neurons: 201, Grad norm: 6.200362587789584\n",
      "Epoch 5260, Loss: 208.89099227046296, Neurons: 201, Grad norm: 6.200362587789584\n",
      "Epoch 5261, Loss: 208.8909272493099, Neurons: 201, Grad norm: 6.076532313642497\n",
      "Epoch 5261, Loss: 208.8909272493099, Neurons: 201, Grad norm: 6.076532313642497\n",
      "Epoch 5262, Loss: 208.8907516575059, Neurons: 201, Grad norm: 6.017775091790933\n",
      "Epoch 5262, Loss: 208.8907516575059, Neurons: 201, Grad norm: 6.017775091790933\n",
      "Epoch 5263, Loss: 208.8906165335336, Neurons: 201, Grad norm: 5.181168065386147\n",
      "Epoch 5263, Loss: 208.8906165335336, Neurons: 201, Grad norm: 5.181168065386147\n",
      "Epoch 5264, Loss: 208.8902413413246, Neurons: 201, Grad norm: 4.296874312730215\n",
      "Epoch 5264, Loss: 208.8902413413246, Neurons: 201, Grad norm: 4.296874312730215\n",
      "Epoch 5265, Loss: 208.8898423173885, Neurons: 201, Grad norm: 3.1303193330666557\n",
      "Epoch 5265, Loss: 208.8898423173885, Neurons: 201, Grad norm: 3.1303193330666557\n",
      "Epoch 5266, Loss: 208.889536861275, Neurons: 201, Grad norm: 2.106476051595701\n",
      "Epoch 5266, Loss: 208.889536861275, Neurons: 201, Grad norm: 2.106476051595701\n",
      "Epoch 5267, Loss: 208.8894638406034, Neurons: 201, Grad norm: 1.227514455664283\n",
      "Epoch 5267, Loss: 208.8894638406034, Neurons: 201, Grad norm: 1.227514455664283\n",
      "Epoch 5268, Loss: 208.88944858919606, Neurons: 201, Grad norm: 0.742005773450485\n",
      "Epoch 5268, Loss: 208.88944858919606, Neurons: 201, Grad norm: 0.742005773450485\n",
      "Epoch 5269, Loss: 208.88940112704702, Neurons: 201, Grad norm: 0.8186748899506414\n",
      "Epoch 5269, Loss: 208.88940112704702, Neurons: 201, Grad norm: 0.8186748899506414\n",
      "Epoch 5270, Loss: 208.88935280436928, Neurons: 201, Grad norm: 1.4573215855987385\n",
      "Epoch 5270, Loss: 208.88935280436928, Neurons: 201, Grad norm: 1.4573215855987385\n",
      "Epoch 5271, Loss: 208.8892807826651, Neurons: 201, Grad norm: 2.285237838667989\n",
      "Epoch 5271, Loss: 208.8892807826651, Neurons: 201, Grad norm: 2.285237838667989\n",
      "Epoch 5272, Loss: 208.8891807016726, Neurons: 201, Grad norm: 3.0246955131076936\n",
      "Epoch 5272, Loss: 208.8891807016726, Neurons: 201, Grad norm: 3.0246955131076936\n",
      "Epoch 5273, Loss: 208.8890777727653, Neurons: 201, Grad norm: 3.8232803250788967\n",
      "Epoch 5273, Loss: 208.8890777727653, Neurons: 201, Grad norm: 3.8232803250788967\n",
      "Epoch 5274, Loss: 208.88898879350486, Neurons: 201, Grad norm: 4.5391388334924185\n",
      "Epoch 5274, Loss: 208.88898879350486, Neurons: 201, Grad norm: 4.5391388334924185\n",
      "Epoch 5275, Loss: 208.88889985376588, Neurons: 201, Grad norm: 5.750595744712391\n",
      "Epoch 5275, Loss: 208.88889985376588, Neurons: 201, Grad norm: 5.750595744712391\n",
      "Epoch 5276, Loss: 208.88883821489753, Neurons: 201, Grad norm: 6.29301987743766\n",
      "Epoch 5276, Loss: 208.88883821489753, Neurons: 201, Grad norm: 6.29301987743766\n",
      "Epoch 5277, Loss: 208.88888838037843, Neurons: 201, Grad norm: 7.238334420012485\n",
      "Epoch 5277, Loss: 208.88888838037843, Neurons: 201, Grad norm: 7.238334420012485\n",
      "Epoch 5278, Loss: 208.8888994705552, Neurons: 201, Grad norm: 7.045958116378481\n",
      "Epoch 5278, Loss: 208.8888994705552, Neurons: 201, Grad norm: 7.045958116378481\n",
      "Epoch 5279, Loss: 208.8888950735879, Neurons: 201, Grad norm: 6.707206605104427\n",
      "Epoch 5279, Loss: 208.8888950735879, Neurons: 201, Grad norm: 6.707206605104427\n",
      "Epoch 5280, Loss: 208.88873551684173, Neurons: 201, Grad norm: 5.648806632015972\n",
      "Epoch 5280, Loss: 208.88873551684173, Neurons: 201, Grad norm: 5.648806632015972\n",
      "Epoch 5281, Loss: 208.88836025479804, Neurons: 201, Grad norm: 4.1982470042627575\n",
      "Epoch 5281, Loss: 208.88836025479804, Neurons: 201, Grad norm: 4.1982470042627575\n",
      "Epoch 5282, Loss: 208.88805686423393, Neurons: 201, Grad norm: 2.6686490399408314\n",
      "Epoch 5282, Loss: 208.88805686423393, Neurons: 201, Grad norm: 2.6686490399408314\n",
      "Epoch 5283, Loss: 208.88778624555786, Neurons: 201, Grad norm: 1.398757120151249\n",
      "Epoch 5283, Loss: 208.88778624555786, Neurons: 201, Grad norm: 1.398757120151249\n",
      "Epoch 5284, Loss: 208.8876506240473, Neurons: 201, Grad norm: 0.6010552385870757\n",
      "Epoch 5284, Loss: 208.8876506240473, Neurons: 201, Grad norm: 0.6010552385870757\n",
      "Epoch 5285, Loss: 208.88753565728211, Neurons: 201, Grad norm: 1.1194412517783847\n",
      "Epoch 5285, Loss: 208.88753565728211, Neurons: 201, Grad norm: 1.1194412517783847\n",
      "Epoch 5286, Loss: 208.88744453657085, Neurons: 201, Grad norm: 2.2476361770184505\n",
      "Epoch 5286, Loss: 208.88744453657085, Neurons: 201, Grad norm: 2.2476361770184505\n",
      "Epoch 5287, Loss: 208.8873729562163, Neurons: 201, Grad norm: 3.100734008481588\n",
      "Epoch 5287, Loss: 208.8873729562163, Neurons: 201, Grad norm: 3.100734008481588\n",
      "Epoch 5288, Loss: 208.88732125018151, Neurons: 201, Grad norm: 4.151035246465799\n",
      "Epoch 5288, Loss: 208.88732125018151, Neurons: 201, Grad norm: 4.151035246465799\n",
      "Epoch 5289, Loss: 208.8873351106117, Neurons: 201, Grad norm: 4.7094443798695345\n",
      "Epoch 5289, Loss: 208.8873351106117, Neurons: 201, Grad norm: 4.7094443798695345\n",
      "Epoch 5290, Loss: 208.88729070266098, Neurons: 201, Grad norm: 5.1694987641926335\n",
      "Epoch 5290, Loss: 208.88729070266098, Neurons: 201, Grad norm: 5.1694987641926335\n",
      "Epoch 5291, Loss: 208.8872787213514, Neurons: 201, Grad norm: 5.302476758483821\n",
      "Epoch 5291, Loss: 208.8872787213514, Neurons: 201, Grad norm: 5.302476758483821\n",
      "Epoch 5292, Loss: 208.88723388411248, Neurons: 201, Grad norm: 5.785990253677688\n",
      "Epoch 5292, Loss: 208.88723388411248, Neurons: 201, Grad norm: 5.785990253677688\n",
      "Epoch 5293, Loss: 208.8871801376235, Neurons: 201, Grad norm: 6.009876667701962\n",
      "Epoch 5293, Loss: 208.8871801376235, Neurons: 201, Grad norm: 6.009876667701962\n",
      "Epoch 5294, Loss: 208.88711192563235, Neurons: 201, Grad norm: 5.992724669568115\n",
      "Epoch 5294, Loss: 208.88711192563235, Neurons: 201, Grad norm: 5.992724669568115\n",
      "Epoch 5295, Loss: 208.88707000453562, Neurons: 201, Grad norm: 5.826290777067419\n",
      "Epoch 5295, Loss: 208.88707000453562, Neurons: 201, Grad norm: 5.826290777067419\n",
      "Epoch 5296, Loss: 208.886909281063, Neurons: 201, Grad norm: 5.192342832315915\n",
      "Epoch 5296, Loss: 208.886909281063, Neurons: 201, Grad norm: 5.192342832315915\n",
      "Epoch 5297, Loss: 208.88676653987378, Neurons: 201, Grad norm: 4.239787286390495\n",
      "Epoch 5297, Loss: 208.88676653987378, Neurons: 201, Grad norm: 4.239787286390495\n",
      "Epoch 5298, Loss: 208.88652084704896, Neurons: 201, Grad norm: 3.5399796428087753\n",
      "Epoch 5298, Loss: 208.88652084704896, Neurons: 201, Grad norm: 3.5399796428087753\n",
      "Epoch 5299, Loss: 208.88632926745683, Neurons: 201, Grad norm: 2.342940094144382\n",
      "Epoch 5299, Loss: 208.88632926745683, Neurons: 201, Grad norm: 2.342940094144382\n",
      "Epoch 5300, Loss: 208.88617363293324, Neurons: 201, Grad norm: 1.927258420322135\n",
      "Epoch 5300, Loss: 208.88617363293324, Neurons: 201, Grad norm: 1.927258420322135\n",
      "Epoch 5301, Loss: 208.88600534459724, Neurons: 201, Grad norm: 1.4247979742294534\n",
      "Epoch 5301, Loss: 208.88600534459724, Neurons: 201, Grad norm: 1.4247979742294534\n",
      "Epoch 5302, Loss: 208.8859242575509, Neurons: 201, Grad norm: 1.3234301847364731\n",
      "Epoch 5302, Loss: 208.8859242575509, Neurons: 201, Grad norm: 1.3234301847364731\n",
      "Epoch 5303, Loss: 208.8858491346338, Neurons: 201, Grad norm: 1.5335525481054801\n",
      "Epoch 5303, Loss: 208.8858491346338, Neurons: 201, Grad norm: 1.5335525481054801\n",
      "Epoch 5304, Loss: 208.88572273749833, Neurons: 201, Grad norm: 1.8942594386095362\n",
      "Epoch 5304, Loss: 208.88572273749833, Neurons: 201, Grad norm: 1.8942594386095362\n",
      "Epoch 5305, Loss: 208.8856613577723, Neurons: 201, Grad norm: 2.3611685538116527\n",
      "Epoch 5305, Loss: 208.8856613577723, Neurons: 201, Grad norm: 2.3611685538116527\n",
      "Epoch 5306, Loss: 208.8856293453357, Neurons: 201, Grad norm: 3.1005304314090014\n",
      "Epoch 5306, Loss: 208.8856293453357, Neurons: 201, Grad norm: 3.1005304314090014\n",
      "Epoch 5307, Loss: 208.88558916358596, Neurons: 201, Grad norm: 3.643214667818578\n",
      "Epoch 5307, Loss: 208.88558916358596, Neurons: 201, Grad norm: 3.643214667818578\n",
      "Epoch 5308, Loss: 208.88555177649246, Neurons: 201, Grad norm: 4.382819094543523\n",
      "Epoch 5308, Loss: 208.88555177649246, Neurons: 201, Grad norm: 4.382819094543523\n",
      "Epoch 5309, Loss: 208.88552627811538, Neurons: 201, Grad norm: 5.025156780963518\n",
      "Epoch 5309, Loss: 208.88552627811538, Neurons: 201, Grad norm: 5.025156780963518\n",
      "Epoch 5310, Loss: 208.88550266690376, Neurons: 201, Grad norm: 5.810395110225552\n",
      "Epoch 5310, Loss: 208.88550266690376, Neurons: 201, Grad norm: 5.810395110225552\n",
      "Epoch 5311, Loss: 208.8855433337732, Neurons: 201, Grad norm: 6.2972649970989965\n",
      "Epoch 5311, Loss: 208.8855433337732, Neurons: 201, Grad norm: 6.2972649970989965\n",
      "Epoch 5312, Loss: 208.88555957377545, Neurons: 201, Grad norm: 6.976977109470954\n",
      "Epoch 5312, Loss: 208.88555957377545, Neurons: 201, Grad norm: 6.976977109470954\n",
      "Epoch 5313, Loss: 208.88555930384155, Neurons: 201, Grad norm: 7.183141836346532\n",
      "Epoch 5313, Loss: 208.88555930384155, Neurons: 201, Grad norm: 7.183141836346532\n",
      "Epoch 5314, Loss: 208.88555037242273, Neurons: 201, Grad norm: 7.443119190041347\n",
      "Epoch 5314, Loss: 208.88555037242273, Neurons: 201, Grad norm: 7.443119190041347\n",
      "Epoch 5315, Loss: 208.88551293329834, Neurons: 201, Grad norm: 7.3098881951614\n",
      "Epoch 5315, Loss: 208.88551293329834, Neurons: 201, Grad norm: 7.3098881951614\n",
      "Epoch 5316, Loss: 208.88537307419958, Neurons: 201, Grad norm: 7.040825508013012\n",
      "Epoch 5316, Loss: 208.88537307419958, Neurons: 201, Grad norm: 7.040825508013012\n",
      "Epoch 5317, Loss: 208.88525586806165, Neurons: 201, Grad norm: 6.357224477561343\n",
      "Epoch 5317, Loss: 208.88525586806165, Neurons: 201, Grad norm: 6.357224477561343\n",
      "Epoch 5318, Loss: 208.88502337251782, Neurons: 201, Grad norm: 5.389041455272118\n",
      "Epoch 5318, Loss: 208.88502337251782, Neurons: 201, Grad norm: 5.389041455272118\n",
      "Epoch 5319, Loss: 208.88482783098695, Neurons: 201, Grad norm: 3.8289088340583004\n",
      "Epoch 5319, Loss: 208.88482783098695, Neurons: 201, Grad norm: 3.8289088340583004\n",
      "Epoch 5320, Loss: 208.88453053308635, Neurons: 201, Grad norm: 2.1613580516162316\n",
      "Epoch 5320, Loss: 208.88453053308635, Neurons: 201, Grad norm: 2.1613580516162316\n",
      "Epoch 5321, Loss: 208.88430067167187, Neurons: 201, Grad norm: 0.5511237267783617\n",
      "Epoch 5321, Loss: 208.88430067167187, Neurons: 201, Grad norm: 0.5511237267783617\n",
      "Epoch 5322, Loss: 208.88414898405924, Neurons: 201, Grad norm: 1.5215045772683213\n",
      "Epoch 5322, Loss: 208.88414898405924, Neurons: 201, Grad norm: 1.5215045772683213\n",
      "Epoch 5323, Loss: 208.88408913301103, Neurons: 201, Grad norm: 2.8649546908605106\n",
      "Epoch 5323, Loss: 208.88408913301103, Neurons: 201, Grad norm: 2.8649546908605106\n",
      "Epoch 5324, Loss: 208.88408273668517, Neurons: 201, Grad norm: 4.321349852245515\n",
      "Epoch 5324, Loss: 208.88408273668517, Neurons: 201, Grad norm: 4.321349852245515\n",
      "Epoch 5325, Loss: 208.88413185406213, Neurons: 201, Grad norm: 5.923694821254047\n",
      "Epoch 5325, Loss: 208.88413185406213, Neurons: 201, Grad norm: 5.923694821254047\n",
      "Epoch 5326, Loss: 208.88427149510898, Neurons: 201, Grad norm: 7.287423298825784\n",
      "Epoch 5326, Loss: 208.88427149510898, Neurons: 201, Grad norm: 7.287423298825784\n",
      "Epoch 5327, Loss: 208.88444593268363, Neurons: 201, Grad norm: 8.526738108671314\n",
      "Epoch 5327, Loss: 208.88444593268363, Neurons: 201, Grad norm: 8.526738108671314\n",
      "Epoch 5328, Loss: 208.88464535341706, Neurons: 201, Grad norm: 8.820422112717878\n",
      "Epoch 5328, Loss: 208.88464535341706, Neurons: 201, Grad norm: 8.820422112717878\n",
      "Epoch 5329, Loss: 208.88466165804033, Neurons: 201, Grad norm: 8.809980471670292\n",
      "Epoch 5329, Loss: 208.88466165804033, Neurons: 201, Grad norm: 8.809980471670292\n",
      "Epoch 5330, Loss: 208.88453466318614, Neurons: 201, Grad norm: 7.68471220191082\n",
      "Epoch 5330, Loss: 208.88453466318614, Neurons: 201, Grad norm: 7.68471220191082\n",
      "Epoch 5331, Loss: 208.88421593928214, Neurons: 201, Grad norm: 6.219022008671953\n",
      "Epoch 5331, Loss: 208.88421593928214, Neurons: 201, Grad norm: 6.219022008671953\n",
      "Epoch 5332, Loss: 208.8838673989414, Neurons: 201, Grad norm: 3.993649056915293\n",
      "Epoch 5332, Loss: 208.8838673989414, Neurons: 201, Grad norm: 3.993649056915293\n",
      "Epoch 5333, Loss: 208.88345401463144, Neurons: 201, Grad norm: 1.5658181075686926\n",
      "Epoch 5333, Loss: 208.88345401463144, Neurons: 201, Grad norm: 1.5658181075686926\n",
      "Epoch 5334, Loss: 208.8831930216523, Neurons: 201, Grad norm: 0.9444641389776128\n",
      "Epoch 5334, Loss: 208.8831930216523, Neurons: 201, Grad norm: 0.9444641389776128\n",
      "Epoch 5335, Loss: 208.8830986249878, Neurons: 201, Grad norm: 2.920295954330635\n",
      "Epoch 5335, Loss: 208.8830986249878, Neurons: 201, Grad norm: 2.920295954330635\n",
      "Epoch 5336, Loss: 208.88310124090455, Neurons: 201, Grad norm: 4.808934317625847\n",
      "Epoch 5336, Loss: 208.88310124090455, Neurons: 201, Grad norm: 4.808934317625847\n",
      "Epoch 5337, Loss: 208.8832124705909, Neurons: 201, Grad norm: 6.721754952814735\n",
      "Epoch 5337, Loss: 208.8832124705909, Neurons: 201, Grad norm: 6.721754952814735\n",
      "Epoch 5338, Loss: 208.88343668613584, Neurons: 201, Grad norm: 8.421221948782524\n",
      "Epoch 5338, Loss: 208.88343668613584, Neurons: 201, Grad norm: 8.421221948782524\n",
      "Epoch 5339, Loss: 208.88371383517068, Neurons: 201, Grad norm: 9.664457465739373\n",
      "Epoch 5339, Loss: 208.88371383517068, Neurons: 201, Grad norm: 9.664457465739373\n",
      "Epoch 5340, Loss: 208.88393471612886, Neurons: 201, Grad norm: 10.2630260988125\n",
      "Epoch 5340, Loss: 208.88393471612886, Neurons: 201, Grad norm: 10.2630260988125\n",
      "Epoch 5341, Loss: 208.88404064819244, Neurons: 201, Grad norm: 9.614119982518424\n",
      "Epoch 5341, Loss: 208.88404064819244, Neurons: 201, Grad norm: 9.614119982518424\n",
      "Epoch 5342, Loss: 208.88378950120057, Neurons: 201, Grad norm: 8.302993807518764\n",
      "Epoch 5342, Loss: 208.88378950120057, Neurons: 201, Grad norm: 8.302993807518764\n",
      "Epoch 5343, Loss: 208.8833766591292, Neurons: 201, Grad norm: 5.853485185108476\n",
      "Epoch 5343, Loss: 208.8833766591292, Neurons: 201, Grad norm: 5.853485185108476\n",
      "Epoch 5344, Loss: 208.882857003914, Neurons: 201, Grad norm: 3.3126713570306943\n",
      "Epoch 5344, Loss: 208.882857003914, Neurons: 201, Grad norm: 3.3126713570306943\n",
      "Epoch 5345, Loss: 208.8824285590924, Neurons: 201, Grad norm: 0.5863410962212295\n",
      "Epoch 5345, Loss: 208.8824285590924, Neurons: 201, Grad norm: 0.5863410962212295\n",
      "Epoch 5346, Loss: 208.88219451774063, Neurons: 201, Grad norm: 2.312076520945025\n",
      "Epoch 5346, Loss: 208.88219451774063, Neurons: 201, Grad norm: 2.312076520945025\n",
      "Epoch 5347, Loss: 208.8821828492306, Neurons: 201, Grad norm: 4.585778861585773\n",
      "Epoch 5347, Loss: 208.8821828492306, Neurons: 201, Grad norm: 4.585778861585773\n",
      "Epoch 5348, Loss: 208.8823014570827, Neurons: 201, Grad norm: 6.304439394452807\n",
      "Epoch 5348, Loss: 208.8823014570827, Neurons: 201, Grad norm: 6.304439394452807\n",
      "Epoch 5349, Loss: 208.88249111215436, Neurons: 201, Grad norm: 7.39281478491357\n",
      "Epoch 5349, Loss: 208.88249111215436, Neurons: 201, Grad norm: 7.39281478491357\n",
      "Epoch 5350, Loss: 208.88264469999172, Neurons: 201, Grad norm: 7.769451254930326\n",
      "Epoch 5350, Loss: 208.88264469999172, Neurons: 201, Grad norm: 7.769451254930326\n",
      "Epoch 5351, Loss: 208.882644520793, Neurons: 201, Grad norm: 7.346276666899315\n",
      "Epoch 5351, Loss: 208.882644520793, Neurons: 201, Grad norm: 7.346276666899315\n",
      "Epoch 5352, Loss: 208.88246654199204, Neurons: 201, Grad norm: 6.602196383492459\n",
      "Epoch 5352, Loss: 208.88246654199204, Neurons: 201, Grad norm: 6.602196383492459\n",
      "Epoch 5353, Loss: 208.8822287602464, Neurons: 201, Grad norm: 5.449303311481334\n",
      "Epoch 5353, Loss: 208.8822287602464, Neurons: 201, Grad norm: 5.449303311481334\n",
      "Epoch 5354, Loss: 208.88194629634498, Neurons: 201, Grad norm: 3.974463406996319\n",
      "Epoch 5354, Loss: 208.88194629634498, Neurons: 201, Grad norm: 3.974463406996319\n",
      "Epoch 5355, Loss: 208.88175213079927, Neurons: 201, Grad norm: 2.611886070130191\n",
      "Epoch 5355, Loss: 208.88175213079927, Neurons: 201, Grad norm: 2.611886070130191\n",
      "Epoch 5356, Loss: 208.8815201758772, Neurons: 201, Grad norm: 0.8698070672672552\n",
      "Epoch 5356, Loss: 208.8815201758772, Neurons: 201, Grad norm: 0.8698070672672552\n",
      "Epoch 5357, Loss: 208.88134232630173, Neurons: 201, Grad norm: 0.8393554363143638\n",
      "Epoch 5357, Loss: 208.88134232630173, Neurons: 201, Grad norm: 0.8393554363143638\n",
      "Epoch 5358, Loss: 208.88126176554215, Neurons: 201, Grad norm: 2.547413795836541\n",
      "Epoch 5358, Loss: 208.88126176554215, Neurons: 201, Grad norm: 2.547413795836541\n",
      "Epoch 5359, Loss: 208.88128149330467, Neurons: 201, Grad norm: 4.007427945227395\n",
      "Epoch 5359, Loss: 208.88128149330467, Neurons: 201, Grad norm: 4.007427945227395\n",
      "Epoch 5360, Loss: 208.88131241315702, Neurons: 201, Grad norm: 5.466210352774467\n",
      "Epoch 5360, Loss: 208.88131241315702, Neurons: 201, Grad norm: 5.466210352774467\n",
      "Epoch 5361, Loss: 208.88140532024858, Neurons: 201, Grad norm: 6.674573635893244\n",
      "Epoch 5361, Loss: 208.88140532024858, Neurons: 201, Grad norm: 6.674573635893244\n",
      "Epoch 5362, Loss: 208.88154171713074, Neurons: 201, Grad norm: 7.714840275510017\n",
      "Epoch 5362, Loss: 208.88154171713074, Neurons: 201, Grad norm: 7.714840275510017\n",
      "Epoch 5363, Loss: 208.88161808404408, Neurons: 201, Grad norm: 8.02818061271944\n",
      "Epoch 5363, Loss: 208.88161808404408, Neurons: 201, Grad norm: 8.02818061271944\n",
      "Epoch 5364, Loss: 208.8817120075964, Neurons: 201, Grad norm: 8.036937970464203\n",
      "Epoch 5364, Loss: 208.8817120075964, Neurons: 201, Grad norm: 8.036937970464203\n",
      "Epoch 5365, Loss: 208.88161919634427, Neurons: 201, Grad norm: 7.461254910186119\n",
      "Epoch 5365, Loss: 208.88161919634427, Neurons: 201, Grad norm: 7.461254910186119\n",
      "Epoch 5366, Loss: 208.88136429032485, Neurons: 201, Grad norm: 6.361283090470659\n",
      "Epoch 5366, Loss: 208.88136429032485, Neurons: 201, Grad norm: 6.361283090470659\n",
      "Epoch 5367, Loss: 208.88113520356447, Neurons: 201, Grad norm: 4.4406311959774065\n",
      "Epoch 5367, Loss: 208.88113520356447, Neurons: 201, Grad norm: 4.4406311959774065\n",
      "Epoch 5368, Loss: 208.88076569458542, Neurons: 201, Grad norm: 2.1360132470652924\n",
      "Epoch 5368, Loss: 208.88076569458542, Neurons: 201, Grad norm: 2.1360132470652924\n",
      "Epoch 5369, Loss: 208.88047133213547, Neurons: 201, Grad norm: 0.6238266144888406\n",
      "Epoch 5369, Loss: 208.88047133213547, Neurons: 201, Grad norm: 0.6238266144888406\n",
      "Epoch 5370, Loss: 208.88034144142162, Neurons: 201, Grad norm: 2.700617161436548\n",
      "Epoch 5370, Loss: 208.88034144142162, Neurons: 201, Grad norm: 2.700617161436548\n",
      "Epoch 5371, Loss: 208.88034733674687, Neurons: 201, Grad norm: 4.54860966043377\n",
      "Epoch 5371, Loss: 208.88034733674687, Neurons: 201, Grad norm: 4.54860966043377\n",
      "Epoch 5372, Loss: 208.88046782954126, Neurons: 201, Grad norm: 6.215307617626325\n",
      "Epoch 5372, Loss: 208.88046782954126, Neurons: 201, Grad norm: 6.215307617626325\n",
      "Epoch 5373, Loss: 208.88062217850717, Neurons: 201, Grad norm: 7.378702229689908\n",
      "Epoch 5373, Loss: 208.88062217850717, Neurons: 201, Grad norm: 7.378702229689908\n",
      "Epoch 5374, Loss: 208.88073117946885, Neurons: 201, Grad norm: 7.979385550466042\n",
      "Epoch 5374, Loss: 208.88073117946885, Neurons: 201, Grad norm: 7.979385550466042\n",
      "Epoch 5375, Loss: 208.88081281804813, Neurons: 201, Grad norm: 7.955455698203769\n",
      "Epoch 5375, Loss: 208.88081281804813, Neurons: 201, Grad norm: 7.955455698203769\n",
      "Epoch 5376, Loss: 208.88071145965176, Neurons: 201, Grad norm: 6.972455049227979\n",
      "Epoch 5376, Loss: 208.88071145965176, Neurons: 201, Grad norm: 6.972455049227979\n",
      "Epoch 5377, Loss: 208.8804516575552, Neurons: 201, Grad norm: 5.845847849567357\n",
      "Epoch 5377, Loss: 208.8804516575552, Neurons: 201, Grad norm: 5.845847849567357\n",
      "Epoch 5378, Loss: 208.88022936355515, Neurons: 201, Grad norm: 4.106290540916772\n",
      "Epoch 5378, Loss: 208.88022936355515, Neurons: 201, Grad norm: 4.106290540916772\n",
      "Epoch 5379, Loss: 208.879864303686, Neurons: 201, Grad norm: 2.2545295171812008\n",
      "Epoch 5379, Loss: 208.879864303686, Neurons: 201, Grad norm: 2.2545295171812008\n",
      "Epoch 5380, Loss: 208.87959801486957, Neurons: 201, Grad norm: 0.7879699575211709\n",
      "Epoch 5380, Loss: 208.87959801486957, Neurons: 201, Grad norm: 0.7879699575211709\n",
      "Epoch 5381, Loss: 208.87949174066878, Neurons: 201, Grad norm: 1.2494913365645086\n",
      "Epoch 5381, Loss: 208.87949174066878, Neurons: 201, Grad norm: 1.2494913365645086\n",
      "Epoch 5382, Loss: 208.87941530785318, Neurons: 201, Grad norm: 2.680039003112112\n",
      "Epoch 5382, Loss: 208.87941530785318, Neurons: 201, Grad norm: 2.680039003112112\n",
      "Epoch 5383, Loss: 208.8794255401116, Neurons: 201, Grad norm: 3.662390262675122\n",
      "Epoch 5383, Loss: 208.8794255401116, Neurons: 201, Grad norm: 3.662390262675122\n",
      "Epoch 5384, Loss: 208.8794430641104, Neurons: 201, Grad norm: 4.632572562589952\n",
      "Epoch 5384, Loss: 208.8794430641104, Neurons: 201, Grad norm: 4.632572562589952\n",
      "Epoch 5385, Loss: 208.87945481654393, Neurons: 201, Grad norm: 5.145132548094316\n",
      "Epoch 5385, Loss: 208.87945481654393, Neurons: 201, Grad norm: 5.145132548094316\n",
      "Epoch 5386, Loss: 208.87947011348808, Neurons: 201, Grad norm: 5.502650833692465\n",
      "Epoch 5386, Loss: 208.87947011348808, Neurons: 201, Grad norm: 5.502650833692465\n",
      "Epoch 5387, Loss: 208.8794051830954, Neurons: 201, Grad norm: 5.8236893268070595\n",
      "Epoch 5387, Loss: 208.8794051830954, Neurons: 201, Grad norm: 5.8236893268070595\n",
      "Epoch 5388, Loss: 208.87937751239372, Neurons: 201, Grad norm: 6.116530011726654\n",
      "Epoch 5388, Loss: 208.87937751239372, Neurons: 201, Grad norm: 6.116530011726654\n",
      "Epoch 5389, Loss: 208.8793899880947, Neurons: 201, Grad norm: 5.943926975816946\n",
      "Epoch 5389, Loss: 208.8793899880947, Neurons: 201, Grad norm: 5.943926975816946\n",
      "Epoch 5390, Loss: 208.87925856022392, Neurons: 201, Grad norm: 5.554873030932487\n",
      "Epoch 5390, Loss: 208.87925856022392, Neurons: 201, Grad norm: 5.554873030932487\n",
      "Epoch 5391, Loss: 208.87911382854554, Neurons: 201, Grad norm: 4.593761086251446\n",
      "Epoch 5391, Loss: 208.87911382854554, Neurons: 201, Grad norm: 4.593761086251446\n",
      "Epoch 5392, Loss: 208.87891465957352, Neurons: 201, Grad norm: 3.550587412665307\n",
      "Epoch 5392, Loss: 208.87891465957352, Neurons: 201, Grad norm: 3.550587412665307\n",
      "Epoch 5393, Loss: 208.87870699621936, Neurons: 201, Grad norm: 2.355805308217211\n",
      "Epoch 5393, Loss: 208.87870699621936, Neurons: 201, Grad norm: 2.355805308217211\n",
      "Epoch 5394, Loss: 208.8785361027141, Neurons: 201, Grad norm: 1.3867642323425204\n",
      "Epoch 5394, Loss: 208.8785361027141, Neurons: 201, Grad norm: 1.3867642323425204\n",
      "Epoch 5395, Loss: 208.87841513785557, Neurons: 201, Grad norm: 0.6098746575981361\n",
      "Epoch 5395, Loss: 208.87841513785557, Neurons: 201, Grad norm: 0.6098746575981361\n",
      "Epoch 5396, Loss: 208.87831578870853, Neurons: 201, Grad norm: 0.6462052213158446\n",
      "Epoch 5396, Loss: 208.87831578870853, Neurons: 201, Grad norm: 0.6462052213158446\n",
      "Epoch 5397, Loss: 208.87823349632478, Neurons: 201, Grad norm: 1.4183151986892484\n",
      "Epoch 5397, Loss: 208.87823349632478, Neurons: 201, Grad norm: 1.4183151986892484\n",
      "Epoch 5398, Loss: 208.87818444490722, Neurons: 201, Grad norm: 2.4626468977298366\n",
      "Epoch 5398, Loss: 208.87818444490722, Neurons: 201, Grad norm: 2.4626468977298366\n",
      "Epoch 5399, Loss: 208.87819286637824, Neurons: 201, Grad norm: 3.993871076785254\n",
      "Epoch 5399, Loss: 208.87819286637824, Neurons: 201, Grad norm: 3.993871076785254\n",
      "Epoch 5400, Loss: 208.87822775642036, Neurons: 201, Grad norm: 5.319995620475469\n",
      "Epoch 5400, Loss: 208.87822775642036, Neurons: 201, Grad norm: 5.319995620475469\n",
      "Epoch 5401, Loss: 208.87832389293962, Neurons: 201, Grad norm: 6.625083111829416\n",
      "Epoch 5401, Loss: 208.87832389293962, Neurons: 201, Grad norm: 6.625083111829416\n",
      "Epoch 5402, Loss: 208.87846792095544, Neurons: 201, Grad norm: 7.546371398291251\n",
      "Epoch 5402, Loss: 208.87846792095544, Neurons: 201, Grad norm: 7.546371398291251\n",
      "Epoch 5403, Loss: 208.8785591006093, Neurons: 201, Grad norm: 8.240304969085631\n",
      "Epoch 5403, Loss: 208.8785591006093, Neurons: 201, Grad norm: 8.240304969085631\n",
      "Epoch 5404, Loss: 208.8786378567247, Neurons: 201, Grad norm: 7.986356133233203\n",
      "Epoch 5404, Loss: 208.8786378567247, Neurons: 201, Grad norm: 7.986356133233203\n",
      "Epoch 5405, Loss: 208.8785626527546, Neurons: 201, Grad norm: 7.382990683042257\n",
      "Epoch 5405, Loss: 208.8785626527546, Neurons: 201, Grad norm: 7.382990683042257\n",
      "Epoch 5406, Loss: 208.87838033399132, Neurons: 201, Grad norm: 5.678046353240144\n",
      "Epoch 5406, Loss: 208.87838033399132, Neurons: 201, Grad norm: 5.678046353240144\n",
      "Epoch 5407, Loss: 208.87794054221246, Neurons: 201, Grad norm: 3.355170005992383\n",
      "Epoch 5407, Loss: 208.87794054221246, Neurons: 201, Grad norm: 3.355170005992383\n",
      "Epoch 5408, Loss: 208.8776033619789, Neurons: 201, Grad norm: 1.039705341395445\n",
      "Epoch 5408, Loss: 208.8776033619789, Neurons: 201, Grad norm: 1.039705341395445\n",
      "Epoch 5409, Loss: 208.8774190773347, Neurons: 201, Grad norm: 2.2062107696509856\n",
      "Epoch 5409, Loss: 208.8774190773347, Neurons: 201, Grad norm: 2.2062107696509856\n",
      "Epoch 5410, Loss: 208.87732398117026, Neurons: 201, Grad norm: 4.63542912598275\n",
      "Epoch 5410, Loss: 208.87732398117026, Neurons: 201, Grad norm: 4.63542912598275\n",
      "Epoch 5411, Loss: 208.8774932427783, Neurons: 201, Grad norm: 6.446700000345545\n",
      "Epoch 5411, Loss: 208.8774932427783, Neurons: 201, Grad norm: 6.446700000345545\n",
      "Epoch 5412, Loss: 208.87769445119713, Neurons: 201, Grad norm: 7.96320569145852\n",
      "Epoch 5412, Loss: 208.87769445119713, Neurons: 201, Grad norm: 7.96320569145852\n",
      "Epoch 5413, Loss: 208.87789052589164, Neurons: 201, Grad norm: 8.50813026867598\n",
      "Epoch 5413, Loss: 208.87789052589164, Neurons: 201, Grad norm: 8.50813026867598\n",
      "Epoch 5414, Loss: 208.8780018776352, Neurons: 201, Grad norm: 8.679425951343987\n",
      "Epoch 5414, Loss: 208.8780018776352, Neurons: 201, Grad norm: 8.679425951343987\n",
      "Epoch 5415, Loss: 208.8779158923817, Neurons: 201, Grad norm: 7.858813948352275\n",
      "Epoch 5415, Loss: 208.8779158923817, Neurons: 201, Grad norm: 7.858813948352275\n",
      "Epoch 5416, Loss: 208.8776607418425, Neurons: 201, Grad norm: 6.660116138556854\n",
      "Epoch 5416, Loss: 208.8776607418425, Neurons: 201, Grad norm: 6.660116138556854\n",
      "Epoch 5417, Loss: 208.8773353293273, Neurons: 201, Grad norm: 4.386790961547424\n",
      "Epoch 5417, Loss: 208.8773353293273, Neurons: 201, Grad norm: 4.386790961547424\n",
      "Epoch 5418, Loss: 208.8769258979493, Neurons: 201, Grad norm: 2.485063339954456\n",
      "Epoch 5418, Loss: 208.8769258979493, Neurons: 201, Grad norm: 2.485063339954456\n",
      "Epoch 5419, Loss: 208.87661137646808, Neurons: 201, Grad norm: 0.7416858800662919\n",
      "Epoch 5419, Loss: 208.87661137646808, Neurons: 201, Grad norm: 0.7416858800662919\n",
      "Epoch 5420, Loss: 208.87646190839837, Neurons: 201, Grad norm: 2.0348026980326814\n",
      "Epoch 5420, Loss: 208.87646190839837, Neurons: 201, Grad norm: 2.0348026980326814\n",
      "Epoch 5421, Loss: 208.8764274884465, Neurons: 201, Grad norm: 3.4253469338606877\n",
      "Epoch 5421, Loss: 208.8764274884465, Neurons: 201, Grad norm: 3.4253469338606877\n",
      "Epoch 5422, Loss: 208.87642931131776, Neurons: 201, Grad norm: 4.836017657698056\n",
      "Epoch 5422, Loss: 208.87642931131776, Neurons: 201, Grad norm: 4.836017657698056\n",
      "Epoch 5423, Loss: 208.87645085012298, Neurons: 201, Grad norm: 6.4352768712001405\n",
      "Epoch 5423, Loss: 208.87645085012298, Neurons: 201, Grad norm: 6.4352768712001405\n",
      "Epoch 5424, Loss: 208.87660272342197, Neurons: 201, Grad norm: 7.175283499150438\n",
      "Epoch 5424, Loss: 208.87660272342197, Neurons: 201, Grad norm: 7.175283499150438\n",
      "Epoch 5425, Loss: 208.87672960159492, Neurons: 201, Grad norm: 7.6322335538348645\n",
      "Epoch 5425, Loss: 208.87672960159492, Neurons: 201, Grad norm: 7.6322335538348645\n",
      "Epoch 5426, Loss: 208.87671593917634, Neurons: 201, Grad norm: 7.1285788041015685\n",
      "Epoch 5426, Loss: 208.87671593917634, Neurons: 201, Grad norm: 7.1285788041015685\n",
      "Epoch 5427, Loss: 208.87653261947213, Neurons: 201, Grad norm: 5.847901733325656\n",
      "Epoch 5427, Loss: 208.87653261947213, Neurons: 201, Grad norm: 5.847901733325656\n",
      "Epoch 5428, Loss: 208.87623292148965, Neurons: 201, Grad norm: 3.8582967210585806\n",
      "Epoch 5428, Loss: 208.87623292148965, Neurons: 201, Grad norm: 3.8582967210585806\n",
      "Epoch 5429, Loss: 208.87587958943368, Neurons: 201, Grad norm: 2.0079077122495925\n",
      "Epoch 5429, Loss: 208.87587958943368, Neurons: 201, Grad norm: 2.0079077122495925\n",
      "Epoch 5430, Loss: 208.87561299187217, Neurons: 201, Grad norm: 0.5345735026602512\n",
      "Epoch 5430, Loss: 208.87561299187217, Neurons: 201, Grad norm: 0.5345735026602512\n",
      "Epoch 5431, Loss: 208.87545091108063, Neurons: 201, Grad norm: 1.8824733972835908\n",
      "Epoch 5431, Loss: 208.87545091108063, Neurons: 201, Grad norm: 1.8824733972835908\n",
      "Epoch 5432, Loss: 208.8754206353888, Neurons: 201, Grad norm: 3.224324221395528\n",
      "Epoch 5432, Loss: 208.8754206353888, Neurons: 201, Grad norm: 3.224324221395528\n",
      "Epoch 5433, Loss: 208.8754803297484, Neurons: 201, Grad norm: 4.674464663690595\n",
      "Epoch 5433, Loss: 208.8754803297484, Neurons: 201, Grad norm: 4.674464663690595\n",
      "Epoch 5434, Loss: 208.87552449960884, Neurons: 201, Grad norm: 6.2340169800958005\n",
      "Epoch 5434, Loss: 208.87552449960884, Neurons: 201, Grad norm: 6.2340169800958005\n",
      "Epoch 5435, Loss: 208.87568317115455, Neurons: 201, Grad norm: 7.570555154242473\n",
      "Epoch 5435, Loss: 208.87568317115455, Neurons: 201, Grad norm: 7.570555154242473\n",
      "Epoch 5436, Loss: 208.87589252901543, Neurons: 201, Grad norm: 8.445769729995602\n",
      "Epoch 5436, Loss: 208.87589252901543, Neurons: 201, Grad norm: 8.445769729995602\n",
      "Epoch 5437, Loss: 208.87602273873452, Neurons: 201, Grad norm: 8.532902289284818\n",
      "Epoch 5437, Loss: 208.87602273873452, Neurons: 201, Grad norm: 8.532902289284818\n",
      "Epoch 5438, Loss: 208.87594750406555, Neurons: 201, Grad norm: 8.08373292016873\n",
      "Epoch 5438, Loss: 208.87594750406555, Neurons: 201, Grad norm: 8.08373292016873\n",
      "Epoch 5439, Loss: 208.87580554220398, Neurons: 201, Grad norm: 6.384045525266187\n",
      "Epoch 5439, Loss: 208.87580554220398, Neurons: 201, Grad norm: 6.384045525266187\n",
      "Epoch 5440, Loss: 208.87537706926986, Neurons: 201, Grad norm: 4.376418761089525\n",
      "Epoch 5440, Loss: 208.87537706926986, Neurons: 201, Grad norm: 4.376418761089525\n",
      "Epoch 5441, Loss: 208.87498083139857, Neurons: 201, Grad norm: 1.7110623464159418\n",
      "Epoch 5441, Loss: 208.87498083139857, Neurons: 201, Grad norm: 1.7110623464159418\n",
      "Epoch 5442, Loss: 208.8746892056065, Neurons: 201, Grad norm: 1.1752412613949046\n",
      "Epoch 5442, Loss: 208.8746892056065, Neurons: 201, Grad norm: 1.1752412613949046\n",
      "Epoch 5443, Loss: 208.87458680017616, Neurons: 201, Grad norm: 3.432720618289725\n",
      "Epoch 5443, Loss: 208.87458680017616, Neurons: 201, Grad norm: 3.432720618289725\n",
      "Epoch 5444, Loss: 208.87463903581107, Neurons: 201, Grad norm: 5.473720356824414\n",
      "Epoch 5444, Loss: 208.87463903581107, Neurons: 201, Grad norm: 5.473720356824414\n",
      "Epoch 5445, Loss: 208.87478744418644, Neurons: 201, Grad norm: 7.35598416840179\n",
      "Epoch 5445, Loss: 208.87478744418644, Neurons: 201, Grad norm: 7.35598416840179\n",
      "Epoch 5446, Loss: 208.8750598854725, Neurons: 201, Grad norm: 8.324945125693183\n",
      "Epoch 5446, Loss: 208.8750598854725, Neurons: 201, Grad norm: 8.324945125693183\n",
      "Epoch 5447, Loss: 208.87522710392014, Neurons: 201, Grad norm: 9.268778585174408\n",
      "Epoch 5447, Loss: 208.87522710392014, Neurons: 201, Grad norm: 9.268778585174408\n",
      "Epoch 5448, Loss: 208.87530793614735, Neurons: 201, Grad norm: 8.71951664432873\n",
      "Epoch 5448, Loss: 208.87530793614735, Neurons: 201, Grad norm: 8.71951664432873\n",
      "Epoch 5449, Loss: 208.8751630006578, Neurons: 201, Grad norm: 7.523457854382881\n",
      "Epoch 5449, Loss: 208.8751630006578, Neurons: 201, Grad norm: 7.523457854382881\n",
      "Epoch 5450, Loss: 208.87478763211945, Neurons: 201, Grad norm: 5.6315168991951845\n",
      "Epoch 5450, Loss: 208.87478763211945, Neurons: 201, Grad norm: 5.6315168991951845\n",
      "Epoch 5451, Loss: 208.874413491632, Neurons: 201, Grad norm: 3.2432960288835475\n",
      "Epoch 5451, Loss: 208.874413491632, Neurons: 201, Grad norm: 3.2432960288835475\n",
      "Epoch 5452, Loss: 208.87402953714044, Neurons: 201, Grad norm: 0.9215374071973268\n",
      "Epoch 5452, Loss: 208.87402953714044, Neurons: 201, Grad norm: 0.9215374071973268\n",
      "Epoch 5453, Loss: 208.87380710080822, Neurons: 201, Grad norm: 1.7055821859357718\n",
      "Epoch 5453, Loss: 208.87380710080822, Neurons: 201, Grad norm: 1.7055821859357718\n",
      "Epoch 5454, Loss: 208.8737912702897, Neurons: 201, Grad norm: 3.5333543348333873\n",
      "Epoch 5454, Loss: 208.8737912702897, Neurons: 201, Grad norm: 3.5333543348333873\n",
      "Epoch 5455, Loss: 208.8737567641908, Neurons: 201, Grad norm: 4.467814633855695\n",
      "Epoch 5455, Loss: 208.8737567641908, Neurons: 201, Grad norm: 4.467814633855695\n",
      "Epoch 5456, Loss: 208.87379045140085, Neurons: 201, Grad norm: 5.5969488979440065\n",
      "Epoch 5456, Loss: 208.87379045140085, Neurons: 201, Grad norm: 5.5969488979440065\n",
      "Epoch 5457, Loss: 208.87385309825157, Neurons: 201, Grad norm: 5.528691995403166\n",
      "Epoch 5457, Loss: 208.87385309825157, Neurons: 201, Grad norm: 5.528691995403166\n",
      "Epoch 5458, Loss: 208.8737761396577, Neurons: 201, Grad norm: 5.053122985083363\n",
      "Epoch 5458, Loss: 208.8737761396577, Neurons: 201, Grad norm: 5.053122985083363\n",
      "Epoch 5459, Loss: 208.8735373221418, Neurons: 201, Grad norm: 3.7059345679465934\n",
      "Epoch 5459, Loss: 208.8735373221418, Neurons: 201, Grad norm: 3.7059345679465934\n",
      "Epoch 5460, Loss: 208.87323215744988, Neurons: 201, Grad norm: 2.7883370600166395\n",
      "Epoch 5460, Loss: 208.87323215744988, Neurons: 201, Grad norm: 2.7883370600166395\n",
      "Epoch 5461, Loss: 208.87300162958485, Neurons: 201, Grad norm: 1.2772245035324252\n",
      "Epoch 5461, Loss: 208.87300162958485, Neurons: 201, Grad norm: 1.2772245035324252\n",
      "Epoch 5462, Loss: 208.8728014435175, Neurons: 201, Grad norm: 1.0411802194555078\n",
      "Epoch 5462, Loss: 208.8728014435175, Neurons: 201, Grad norm: 1.0411802194555078\n",
      "Epoch 5463, Loss: 208.87262507845682, Neurons: 201, Grad norm: 1.5597867388413207\n",
      "Epoch 5463, Loss: 208.87262507845682, Neurons: 201, Grad norm: 1.5597867388413207\n",
      "Epoch 5464, Loss: 208.87251885138912, Neurons: 201, Grad norm: 1.9561369562179665\n",
      "Epoch 5464, Loss: 208.87251885138912, Neurons: 201, Grad norm: 1.9561369562179665\n",
      "Epoch 5465, Loss: 208.8723435746227, Neurons: 201, Grad norm: 2.419148372951147\n",
      "Epoch 5465, Loss: 208.8723435746227, Neurons: 201, Grad norm: 2.419148372951147\n",
      "Epoch 5466, Loss: 208.87212875386922, Neurons: 201, Grad norm: 3.0348936535524755\n",
      "Epoch 5466, Loss: 208.87212875386922, Neurons: 201, Grad norm: 3.0348936535524755\n",
      "Epoch 5467, Loss: 208.8720416460851, Neurons: 201, Grad norm: 3.501630784419739\n",
      "Epoch 5467, Loss: 208.8720416460851, Neurons: 201, Grad norm: 3.501630784419739\n",
      "Epoch 5468, Loss: 208.87204614551277, Neurons: 201, Grad norm: 4.1279763803209395\n",
      "Epoch 5468, Loss: 208.87204614551277, Neurons: 201, Grad norm: 4.1279763803209395\n",
      "Epoch 5469, Loss: 208.8720009287481, Neurons: 201, Grad norm: 5.012584961379737\n",
      "Epoch 5469, Loss: 208.8720009287481, Neurons: 201, Grad norm: 5.012584961379737\n",
      "Epoch 5470, Loss: 208.87204814449476, Neurons: 201, Grad norm: 5.79579794847057\n",
      "Epoch 5470, Loss: 208.87204814449476, Neurons: 201, Grad norm: 5.79579794847057\n",
      "Epoch 5471, Loss: 208.8721021953698, Neurons: 201, Grad norm: 5.933810020648984\n",
      "Epoch 5471, Loss: 208.8721021953698, Neurons: 201, Grad norm: 5.933810020648984\n",
      "Epoch 5472, Loss: 208.87209090177257, Neurons: 201, Grad norm: 5.865562601848125\n",
      "Epoch 5472, Loss: 208.87209090177257, Neurons: 201, Grad norm: 5.865562601848125\n",
      "Epoch 5473, Loss: 208.87200309554302, Neurons: 201, Grad norm: 5.300980981245363\n",
      "Epoch 5473, Loss: 208.87200309554302, Neurons: 201, Grad norm: 5.300980981245363\n",
      "Epoch 5474, Loss: 208.87187603565297, Neurons: 201, Grad norm: 4.241984310784407\n",
      "Epoch 5474, Loss: 208.87187603565297, Neurons: 201, Grad norm: 4.241984310784407\n",
      "Epoch 5475, Loss: 208.87168180860007, Neurons: 201, Grad norm: 3.2965393148574043\n",
      "Epoch 5475, Loss: 208.87168180860007, Neurons: 201, Grad norm: 3.2965393148574043\n",
      "Epoch 5476, Loss: 208.8715040356804, Neurons: 201, Grad norm: 2.048149221168158\n",
      "Epoch 5476, Loss: 208.8715040356804, Neurons: 201, Grad norm: 2.048149221168158\n",
      "Epoch 5477, Loss: 208.87131748975682, Neurons: 201, Grad norm: 0.7100274771530338\n",
      "Epoch 5477, Loss: 208.87131748975682, Neurons: 201, Grad norm: 0.7100274771530338\n",
      "Epoch 5478, Loss: 208.87118198597642, Neurons: 201, Grad norm: 0.8430815490111332\n",
      "Epoch 5478, Loss: 208.87118198597642, Neurons: 201, Grad norm: 0.8430815490111332\n",
      "Epoch 5479, Loss: 208.87113236250875, Neurons: 201, Grad norm: 2.1806922748855353\n",
      "Epoch 5479, Loss: 208.87113236250875, Neurons: 201, Grad norm: 2.1806922748855353\n",
      "Epoch 5480, Loss: 208.8711000832471, Neurons: 201, Grad norm: 3.4329215686506793\n",
      "Epoch 5480, Loss: 208.8711000832471, Neurons: 201, Grad norm: 3.4329215686506793\n",
      "Epoch 5481, Loss: 208.87115930389248, Neurons: 201, Grad norm: 5.089343634280765\n",
      "Epoch 5481, Loss: 208.87115930389248, Neurons: 201, Grad norm: 5.089343634280765\n",
      "Epoch 5482, Loss: 208.87121199794046, Neurons: 201, Grad norm: 6.652697588457508\n",
      "Epoch 5482, Loss: 208.87121199794046, Neurons: 201, Grad norm: 6.652697588457508\n",
      "Epoch 5483, Loss: 208.87139199159068, Neurons: 201, Grad norm: 8.159394627208929\n",
      "Epoch 5483, Loss: 208.87139199159068, Neurons: 201, Grad norm: 8.159394627208929\n",
      "Epoch 5484, Loss: 208.87163427867532, Neurons: 201, Grad norm: 9.06404756837964\n",
      "Epoch 5484, Loss: 208.87163427867532, Neurons: 201, Grad norm: 9.06404756837964\n",
      "Epoch 5485, Loss: 208.87182808621787, Neurons: 201, Grad norm: 9.330423171149251\n",
      "Epoch 5485, Loss: 208.87182808621787, Neurons: 201, Grad norm: 9.330423171149251\n",
      "Epoch 5486, Loss: 208.87169776117287, Neurons: 201, Grad norm: 8.739865908705813\n",
      "Epoch 5486, Loss: 208.87169776117287, Neurons: 201, Grad norm: 8.739865908705813\n",
      "Epoch 5487, Loss: 208.87158035963478, Neurons: 201, Grad norm: 7.033764676998574\n",
      "Epoch 5487, Loss: 208.87158035963478, Neurons: 201, Grad norm: 7.033764676998574\n",
      "Epoch 5488, Loss: 208.87112764226842, Neurons: 201, Grad norm: 4.728126394231256\n",
      "Epoch 5488, Loss: 208.87112764226842, Neurons: 201, Grad norm: 4.728126394231256\n",
      "Epoch 5489, Loss: 208.87064654402496, Neurons: 201, Grad norm: 1.9731957305071908\n",
      "Epoch 5489, Loss: 208.87064654402496, Neurons: 201, Grad norm: 1.9731957305071908\n",
      "Epoch 5490, Loss: 208.87029292908971, Neurons: 201, Grad norm: 1.4275938467628786\n",
      "Epoch 5490, Loss: 208.87029292908971, Neurons: 201, Grad norm: 1.4275938467628786\n",
      "Epoch 5491, Loss: 208.8701487012414, Neurons: 201, Grad norm: 3.671088042852174\n",
      "Epoch 5491, Loss: 208.8701487012414, Neurons: 201, Grad norm: 3.671088042852174\n",
      "Epoch 5492, Loss: 208.87019131427397, Neurons: 201, Grad norm: 6.011850385057478\n",
      "Epoch 5492, Loss: 208.87019131427397, Neurons: 201, Grad norm: 6.011850385057478\n",
      "Epoch 5493, Loss: 208.87045488534488, Neurons: 201, Grad norm: 7.889251776226236\n",
      "Epoch 5493, Loss: 208.87045488534488, Neurons: 201, Grad norm: 7.889251776226236\n",
      "Epoch 5494, Loss: 208.8707059628589, Neurons: 201, Grad norm: 9.111308814627014\n",
      "Epoch 5494, Loss: 208.8707059628589, Neurons: 201, Grad norm: 9.111308814627014\n",
      "Epoch 5495, Loss: 208.87087582651466, Neurons: 201, Grad norm: 9.710831525076161\n",
      "Epoch 5495, Loss: 208.87087582651466, Neurons: 201, Grad norm: 9.710831525076161\n",
      "Epoch 5496, Loss: 208.87095396090172, Neurons: 201, Grad norm: 9.273337591413638\n",
      "Epoch 5496, Loss: 208.87095396090172, Neurons: 201, Grad norm: 9.273337591413638\n",
      "Epoch 5497, Loss: 208.87081295261117, Neurons: 201, Grad norm: 8.331730301046893\n",
      "Epoch 5497, Loss: 208.87081295261117, Neurons: 201, Grad norm: 8.331730301046893\n",
      "Epoch 5498, Loss: 208.87045821241074, Neurons: 201, Grad norm: 6.172901022930419\n",
      "Epoch 5498, Loss: 208.87045821241074, Neurons: 201, Grad norm: 6.172901022930419\n",
      "Epoch 5499, Loss: 208.87005013021204, Neurons: 201, Grad norm: 3.682759091999835\n",
      "Epoch 5499, Loss: 208.87005013021204, Neurons: 201, Grad norm: 3.682759091999835\n",
      "Epoch 5500, Loss: 208.86958510850866, Neurons: 201, Grad norm: 1.063020228268833\n",
      "Epoch 5500, Loss: 208.86958510850866, Neurons: 201, Grad norm: 1.063020228268833\n",
      "Epoch 5501, Loss: 208.86926865023815, Neurons: 201, Grad norm: 2.037546943814179\n",
      "Epoch 5501, Loss: 208.86926865023815, Neurons: 201, Grad norm: 2.037546943814179\n",
      "Epoch 5502, Loss: 208.86925301830078, Neurons: 201, Grad norm: 4.263968124049381\n",
      "Epoch 5502, Loss: 208.86925301830078, Neurons: 201, Grad norm: 4.263968124049381\n",
      "Epoch 5503, Loss: 208.86930296372657, Neurons: 201, Grad norm: 5.827770321662828\n",
      "Epoch 5503, Loss: 208.86930296372657, Neurons: 201, Grad norm: 5.827770321662828\n",
      "Epoch 5504, Loss: 208.8694449253427, Neurons: 201, Grad norm: 7.110756825432966\n",
      "Epoch 5504, Loss: 208.8694449253427, Neurons: 201, Grad norm: 7.110756825432966\n",
      "Epoch 5505, Loss: 208.86956643432808, Neurons: 201, Grad norm: 7.663031296287383\n",
      "Epoch 5505, Loss: 208.86956643432808, Neurons: 201, Grad norm: 7.663031296287383\n",
      "Epoch 5506, Loss: 208.86963090535346, Neurons: 201, Grad norm: 7.703342702150712\n",
      "Epoch 5506, Loss: 208.86963090535346, Neurons: 201, Grad norm: 7.703342702150712\n",
      "Epoch 5507, Loss: 208.86956509937093, Neurons: 201, Grad norm: 6.7945807004045315\n",
      "Epoch 5507, Loss: 208.86956509937093, Neurons: 201, Grad norm: 6.7945807004045315\n",
      "Epoch 5508, Loss: 208.86934254196655, Neurons: 201, Grad norm: 5.504619264928797\n",
      "Epoch 5508, Loss: 208.86934254196655, Neurons: 201, Grad norm: 5.504619264928797\n",
      "Epoch 5509, Loss: 208.86900545463746, Neurons: 201, Grad norm: 3.506324935342134\n",
      "Epoch 5509, Loss: 208.86900545463746, Neurons: 201, Grad norm: 3.506324935342134\n",
      "Epoch 5510, Loss: 208.86864135654233, Neurons: 201, Grad norm: 1.461718823394118\n",
      "Epoch 5510, Loss: 208.86864135654233, Neurons: 201, Grad norm: 1.461718823394118\n",
      "Epoch 5511, Loss: 208.86842236597707, Neurons: 201, Grad norm: 1.2044277884244436\n",
      "Epoch 5511, Loss: 208.86842236597707, Neurons: 201, Grad norm: 1.2044277884244436\n",
      "Epoch 5512, Loss: 208.86830690855697, Neurons: 201, Grad norm: 2.972814804814901\n",
      "Epoch 5512, Loss: 208.86830690855697, Neurons: 201, Grad norm: 2.972814804814901\n",
      "Epoch 5513, Loss: 208.8683253140996, Neurons: 201, Grad norm: 4.737324512564431\n",
      "Epoch 5513, Loss: 208.8683253140996, Neurons: 201, Grad norm: 4.737324512564431\n",
      "Epoch 5514, Loss: 208.8684181693969, Neurons: 201, Grad norm: 6.087438974128304\n",
      "Epoch 5514, Loss: 208.8684181693969, Neurons: 201, Grad norm: 6.087438974128304\n",
      "Epoch 5515, Loss: 208.86851840647552, Neurons: 201, Grad norm: 7.064588441527898\n",
      "Epoch 5515, Loss: 208.86851840647552, Neurons: 201, Grad norm: 7.064588441527898\n",
      "Epoch 5516, Loss: 208.86863193548814, Neurons: 201, Grad norm: 7.497520398923444\n",
      "Epoch 5516, Loss: 208.86863193548814, Neurons: 201, Grad norm: 7.497520398923444\n",
      "Epoch 5517, Loss: 208.86866347752235, Neurons: 201, Grad norm: 7.282087339788915\n",
      "Epoch 5517, Loss: 208.86866347752235, Neurons: 201, Grad norm: 7.282087339788915\n",
      "Epoch 5518, Loss: 208.86851448960863, Neurons: 201, Grad norm: 6.460502731987246\n",
      "Epoch 5518, Loss: 208.86851448960863, Neurons: 201, Grad norm: 6.460502731987246\n",
      "Epoch 5519, Loss: 208.8682620320812, Neurons: 201, Grad norm: 5.095995099510787\n",
      "Epoch 5519, Loss: 208.8682620320812, Neurons: 201, Grad norm: 5.095995099510787\n",
      "Epoch 5520, Loss: 208.86800272972476, Neurons: 201, Grad norm: 3.0887356621983484\n",
      "Epoch 5520, Loss: 208.86800272972476, Neurons: 201, Grad norm: 3.0887356621983484\n",
      "Epoch 5521, Loss: 208.86767431727787, Neurons: 201, Grad norm: 1.197543407567155\n",
      "Epoch 5521, Loss: 208.86767431727787, Neurons: 201, Grad norm: 1.197543407567155\n",
      "Epoch 5522, Loss: 208.86749580426954, Neurons: 201, Grad norm: 1.2505788150019597\n",
      "Epoch 5522, Loss: 208.86749580426954, Neurons: 201, Grad norm: 1.2505788150019597\n",
      "Epoch 5523, Loss: 208.86739643082421, Neurons: 201, Grad norm: 3.0212502693640553\n",
      "Epoch 5523, Loss: 208.86739643082421, Neurons: 201, Grad norm: 3.0212502693640553\n",
      "Epoch 5524, Loss: 208.86743074880258, Neurons: 201, Grad norm: 4.8415357201232565\n",
      "Epoch 5524, Loss: 208.86743074880258, Neurons: 201, Grad norm: 4.8415357201232565\n",
      "Epoch 5525, Loss: 208.86756272346477, Neurons: 201, Grad norm: 6.2491421053187075\n",
      "Epoch 5525, Loss: 208.86756272346477, Neurons: 201, Grad norm: 6.2491421053187075\n",
      "Epoch 5526, Loss: 208.86767372489186, Neurons: 201, Grad norm: 7.468644952195348\n",
      "Epoch 5526, Loss: 208.86767372489186, Neurons: 201, Grad norm: 7.468644952195348\n",
      "Epoch 5527, Loss: 208.86777721799737, Neurons: 201, Grad norm: 8.096804032513925\n",
      "Epoch 5527, Loss: 208.86777721799737, Neurons: 201, Grad norm: 8.096804032513925\n",
      "Epoch 5528, Loss: 208.86786687210457, Neurons: 201, Grad norm: 8.302382158611644\n",
      "Epoch 5528, Loss: 208.86786687210457, Neurons: 201, Grad norm: 8.302382158611644\n",
      "Epoch 5529, Loss: 208.8677805406173, Neurons: 201, Grad norm: 7.376045614187303\n",
      "Epoch 5529, Loss: 208.8677805406173, Neurons: 201, Grad norm: 7.376045614187303\n",
      "Epoch 5530, Loss: 208.8675273892647, Neurons: 201, Grad norm: 6.307600106660223\n",
      "Epoch 5530, Loss: 208.8675273892647, Neurons: 201, Grad norm: 6.307600106660223\n",
      "Epoch 5531, Loss: 208.86731115696517, Neurons: 201, Grad norm: 4.148788875225937\n",
      "Epoch 5531, Loss: 208.86731115696517, Neurons: 201, Grad norm: 4.148788875225937\n",
      "Epoch 5532, Loss: 208.86689250448617, Neurons: 201, Grad norm: 1.7183124422933473\n",
      "Epoch 5532, Loss: 208.86689250448617, Neurons: 201, Grad norm: 1.7183124422933473\n",
      "Epoch 5533, Loss: 208.86661447837727, Neurons: 201, Grad norm: 1.036256959256477\n",
      "Epoch 5533, Loss: 208.86661447837727, Neurons: 201, Grad norm: 1.036256959256477\n",
      "Epoch 5534, Loss: 208.86651726958937, Neurons: 201, Grad norm: 3.2232967721542987\n",
      "Epoch 5534, Loss: 208.86651726958937, Neurons: 201, Grad norm: 3.2232967721542987\n",
      "Epoch 5535, Loss: 208.8665191541091, Neurons: 201, Grad norm: 4.541213239747071\n",
      "Epoch 5535, Loss: 208.8665191541091, Neurons: 201, Grad norm: 4.541213239747071\n",
      "Epoch 5536, Loss: 208.86661084091355, Neurons: 201, Grad norm: 5.857564055648838\n",
      "Epoch 5536, Loss: 208.86661084091355, Neurons: 201, Grad norm: 5.857564055648838\n",
      "Epoch 5537, Loss: 208.86668625540787, Neurons: 201, Grad norm: 6.558795804018806\n",
      "Epoch 5537, Loss: 208.86668625540787, Neurons: 201, Grad norm: 6.558795804018806\n",
      "Epoch 5538, Loss: 208.86667649579292, Neurons: 201, Grad norm: 6.519451120691503\n",
      "Epoch 5538, Loss: 208.86667649579292, Neurons: 201, Grad norm: 6.519451120691503\n",
      "Epoch 5539, Loss: 208.86663913258954, Neurons: 201, Grad norm: 6.557112987670069\n",
      "Epoch 5539, Loss: 208.86663913258954, Neurons: 201, Grad norm: 6.557112987670069\n",
      "Epoch 5540, Loss: 208.86652501453716, Neurons: 201, Grad norm: 5.910132726526048\n",
      "Epoch 5540, Loss: 208.86652501453716, Neurons: 201, Grad norm: 5.910132726526048\n",
      "Epoch 5541, Loss: 208.86637537842606, Neurons: 201, Grad norm: 5.443537908985686\n",
      "Epoch 5541, Loss: 208.86637537842606, Neurons: 201, Grad norm: 5.443537908985686\n",
      "Epoch 5542, Loss: 208.8662273092951, Neurons: 201, Grad norm: 4.23376256088034\n",
      "Epoch 5542, Loss: 208.8662273092951, Neurons: 201, Grad norm: 4.23376256088034\n",
      "Epoch 5543, Loss: 208.86595885699106, Neurons: 201, Grad norm: 2.773675214123175\n",
      "Epoch 5543, Loss: 208.86595885699106, Neurons: 201, Grad norm: 2.773675214123175\n",
      "Epoch 5544, Loss: 208.86575797564703, Neurons: 201, Grad norm: 1.4183385975057485\n",
      "Epoch 5544, Loss: 208.86575797564703, Neurons: 201, Grad norm: 1.4183385975057485\n",
      "Epoch 5545, Loss: 208.86560186594124, Neurons: 201, Grad norm: 0.7971785893692171\n",
      "Epoch 5545, Loss: 208.86560186594124, Neurons: 201, Grad norm: 0.7971785893692171\n",
      "Epoch 5546, Loss: 208.86549463159844, Neurons: 201, Grad norm: 2.073688960484388\n",
      "Epoch 5546, Loss: 208.86549463159844, Neurons: 201, Grad norm: 2.073688960484388\n",
      "Epoch 5547, Loss: 208.86547301718002, Neurons: 201, Grad norm: 3.4129642472173836\n",
      "Epoch 5547, Loss: 208.86547301718002, Neurons: 201, Grad norm: 3.4129642472173836\n",
      "Epoch 5548, Loss: 208.865501447407, Neurons: 201, Grad norm: 4.928316371508385\n",
      "Epoch 5548, Loss: 208.865501447407, Neurons: 201, Grad norm: 4.928316371508385\n",
      "Epoch 5549, Loss: 208.8655399302694, Neurons: 201, Grad norm: 6.181329991413777\n",
      "Epoch 5549, Loss: 208.8655399302694, Neurons: 201, Grad norm: 6.181329991413777\n",
      "Epoch 5550, Loss: 208.86567204294678, Neurons: 201, Grad norm: 7.338073806297709\n",
      "Epoch 5550, Loss: 208.86567204294678, Neurons: 201, Grad norm: 7.338073806297709\n",
      "Epoch 5551, Loss: 208.86581587678052, Neurons: 201, Grad norm: 7.8922726687440665\n",
      "Epoch 5551, Loss: 208.86581587678052, Neurons: 201, Grad norm: 7.8922726687440665\n",
      "Epoch 5552, Loss: 208.86585990717413, Neurons: 201, Grad norm: 7.722916612444091\n",
      "Epoch 5552, Loss: 208.86585990717413, Neurons: 201, Grad norm: 7.722916612444091\n",
      "Epoch 5553, Loss: 208.86575038739122, Neurons: 201, Grad norm: 6.494029758247445\n",
      "Epoch 5553, Loss: 208.86575038739122, Neurons: 201, Grad norm: 6.494029758247445\n",
      "Epoch 5554, Loss: 208.86548478277902, Neurons: 201, Grad norm: 4.678525424569382\n",
      "Epoch 5554, Loss: 208.86548478277902, Neurons: 201, Grad norm: 4.678525424569382\n",
      "Epoch 5555, Loss: 208.8651401431889, Neurons: 201, Grad norm: 2.3244380935484674\n",
      "Epoch 5555, Loss: 208.8651401431889, Neurons: 201, Grad norm: 2.3244380935484674\n",
      "Epoch 5556, Loss: 208.86479654764787, Neurons: 201, Grad norm: 0.45403884121603666\n",
      "Epoch 5556, Loss: 208.86479654764787, Neurons: 201, Grad norm: 0.45403884121603666\n",
      "Epoch 5557, Loss: 208.8646177978788, Neurons: 201, Grad norm: 2.019214918718504\n",
      "Epoch 5557, Loss: 208.8646177978788, Neurons: 201, Grad norm: 2.019214918718504\n",
      "Epoch 5558, Loss: 208.8646239402145, Neurons: 201, Grad norm: 3.8295045505290357\n",
      "Epoch 5558, Loss: 208.8646239402145, Neurons: 201, Grad norm: 3.8295045505290357\n",
      "Epoch 5559, Loss: 208.86472482808603, Neurons: 201, Grad norm: 5.544825445226961\n",
      "Epoch 5559, Loss: 208.86472482808603, Neurons: 201, Grad norm: 5.544825445226961\n",
      "Epoch 5560, Loss: 208.86479370152222, Neurons: 201, Grad norm: 7.03790097557607\n",
      "Epoch 5560, Loss: 208.86479370152222, Neurons: 201, Grad norm: 7.03790097557607\n",
      "Epoch 5561, Loss: 208.8649244186101, Neurons: 201, Grad norm: 8.304721918504233\n",
      "Epoch 5561, Loss: 208.8649244186101, Neurons: 201, Grad norm: 8.304721918504233\n",
      "Epoch 5562, Loss: 208.8650563671394, Neurons: 201, Grad norm: 8.666515927129984\n",
      "Epoch 5562, Loss: 208.8650563671394, Neurons: 201, Grad norm: 8.666515927129984\n",
      "Epoch 5563, Loss: 208.86503399618002, Neurons: 201, Grad norm: 8.623098447162734\n",
      "Epoch 5563, Loss: 208.86503399618002, Neurons: 201, Grad norm: 8.623098447162734\n",
      "Epoch 5564, Loss: 208.86476429127015, Neurons: 201, Grad norm: 7.505763933364808\n",
      "Epoch 5564, Loss: 208.86476429127015, Neurons: 201, Grad norm: 7.505763933364808\n",
      "Epoch 5565, Loss: 208.86436971960705, Neurons: 201, Grad norm: 5.8556284336999\n",
      "Epoch 5565, Loss: 208.86436971960705, Neurons: 201, Grad norm: 5.8556284336999\n",
      "Epoch 5566, Loss: 208.86390832120938, Neurons: 201, Grad norm: 3.6766937895328593\n",
      "Epoch 5566, Loss: 208.86390832120938, Neurons: 201, Grad norm: 3.6766937895328593\n",
      "Epoch 5567, Loss: 208.86347886677922, Neurons: 201, Grad norm: 1.3125424365113114\n",
      "Epoch 5567, Loss: 208.86347886677922, Neurons: 201, Grad norm: 1.3125424365113114\n",
      "Epoch 5568, Loss: 208.86333683316695, Neurons: 201, Grad norm: 1.2582284499011904\n",
      "Epoch 5568, Loss: 208.86333683316695, Neurons: 201, Grad norm: 1.2582284499011904\n",
      "Epoch 5569, Loss: 208.86328508643794, Neurons: 201, Grad norm: 2.9425879882963977\n",
      "Epoch 5569, Loss: 208.86328508643794, Neurons: 201, Grad norm: 2.9425879882963977\n",
      "Epoch 5570, Loss: 208.86327311013645, Neurons: 201, Grad norm: 4.198775748909793\n",
      "Epoch 5570, Loss: 208.86327311013645, Neurons: 201, Grad norm: 4.198775748909793\n",
      "Epoch 5571, Loss: 208.86329071031213, Neurons: 201, Grad norm: 5.271159590084573\n",
      "Epoch 5571, Loss: 208.86329071031213, Neurons: 201, Grad norm: 5.271159590084573\n",
      "Epoch 5572, Loss: 208.86339288442184, Neurons: 201, Grad norm: 6.072506992884658\n",
      "Epoch 5572, Loss: 208.86339288442184, Neurons: 201, Grad norm: 6.072506992884658\n",
      "Epoch 5573, Loss: 208.86337521727899, Neurons: 201, Grad norm: 6.835667760104407\n",
      "Epoch 5573, Loss: 208.86337521727899, Neurons: 201, Grad norm: 6.835667760104407\n",
      "Epoch 5574, Loss: 208.86344629143676, Neurons: 201, Grad norm: 6.914687005219874\n",
      "Epoch 5574, Loss: 208.86344629143676, Neurons: 201, Grad norm: 6.914687005219874\n",
      "Epoch 5575, Loss: 208.86344961375718, Neurons: 201, Grad norm: 6.5290645717554945\n",
      "Epoch 5575, Loss: 208.86344961375718, Neurons: 201, Grad norm: 6.5290645717554945\n",
      "Epoch 5576, Loss: 208.86329151610605, Neurons: 201, Grad norm: 5.772649974865744\n",
      "Epoch 5576, Loss: 208.86329151610605, Neurons: 201, Grad norm: 5.772649974865744\n",
      "Epoch 5577, Loss: 208.86300910629228, Neurons: 201, Grad norm: 4.459558651447865\n",
      "Epoch 5577, Loss: 208.86300910629228, Neurons: 201, Grad norm: 4.459558651447865\n",
      "Epoch 5578, Loss: 208.86278075822122, Neurons: 201, Grad norm: 3.537833604564181\n",
      "Epoch 5578, Loss: 208.86278075822122, Neurons: 201, Grad norm: 3.537833604564181\n",
      "Epoch 5579, Loss: 208.86255951290138, Neurons: 201, Grad norm: 2.167114608757272\n",
      "Epoch 5579, Loss: 208.86255951290138, Neurons: 201, Grad norm: 2.167114608757272\n",
      "Epoch 5580, Loss: 208.8623239789093, Neurons: 201, Grad norm: 1.222103916137779\n",
      "Epoch 5580, Loss: 208.8623239789093, Neurons: 201, Grad norm: 1.222103916137779\n",
      "Epoch 5581, Loss: 208.862236928377, Neurons: 201, Grad norm: 0.850602724837099\n",
      "Epoch 5581, Loss: 208.862236928377, Neurons: 201, Grad norm: 0.850602724837099\n",
      "Epoch 5582, Loss: 208.8621464914396, Neurons: 201, Grad norm: 1.6261222898897882\n",
      "Epoch 5582, Loss: 208.8621464914396, Neurons: 201, Grad norm: 1.6261222898897882\n",
      "Epoch 5583, Loss: 208.86203315826302, Neurons: 201, Grad norm: 2.72970311770859\n",
      "Epoch 5583, Loss: 208.86203315826302, Neurons: 201, Grad norm: 2.72970311770859\n",
      "Epoch 5584, Loss: 208.86197959468987, Neurons: 201, Grad norm: 4.135578705225197\n",
      "Epoch 5584, Loss: 208.86197959468987, Neurons: 201, Grad norm: 4.135578705225197\n",
      "Epoch 5585, Loss: 208.86200339727452, Neurons: 201, Grad norm: 5.482079863681675\n",
      "Epoch 5585, Loss: 208.86200339727452, Neurons: 201, Grad norm: 5.482079863681675\n",
      "Epoch 5586, Loss: 208.8621256106671, Neurons: 201, Grad norm: 6.662900030840787\n",
      "Epoch 5586, Loss: 208.8621256106671, Neurons: 201, Grad norm: 6.662900030840787\n",
      "Epoch 5587, Loss: 208.86221244513615, Neurons: 201, Grad norm: 7.58873540886573\n",
      "Epoch 5587, Loss: 208.86221244513615, Neurons: 201, Grad norm: 7.58873540886573\n",
      "Epoch 5588, Loss: 208.8622910671683, Neurons: 201, Grad norm: 7.716675548270992\n",
      "Epoch 5588, Loss: 208.8622910671683, Neurons: 201, Grad norm: 7.716675548270992\n",
      "Epoch 5589, Loss: 208.86225309916406, Neurons: 201, Grad norm: 7.542243456889689\n",
      "Epoch 5589, Loss: 208.86225309916406, Neurons: 201, Grad norm: 7.542243456889689\n",
      "Epoch 5590, Loss: 208.86217342075295, Neurons: 201, Grad norm: 6.6498820641251974\n",
      "Epoch 5590, Loss: 208.86217342075295, Neurons: 201, Grad norm: 6.6498820641251974\n",
      "Epoch 5591, Loss: 208.86192574073198, Neurons: 201, Grad norm: 5.612042913700565\n",
      "Epoch 5591, Loss: 208.86192574073198, Neurons: 201, Grad norm: 5.612042913700565\n",
      "Epoch 5592, Loss: 208.86163583951537, Neurons: 201, Grad norm: 4.497630611526736\n",
      "Epoch 5592, Loss: 208.86163583951537, Neurons: 201, Grad norm: 4.497630611526736\n",
      "Epoch 5593, Loss: 208.86137075078537, Neurons: 201, Grad norm: 3.558283082677253\n",
      "Epoch 5593, Loss: 208.86137075078537, Neurons: 201, Grad norm: 3.558283082677253\n",
      "Epoch 5594, Loss: 208.8611554594379, Neurons: 201, Grad norm: 2.4613489462647395\n",
      "Epoch 5594, Loss: 208.8611554594379, Neurons: 201, Grad norm: 2.4613489462647395\n",
      "Epoch 5595, Loss: 208.86102247717213, Neurons: 201, Grad norm: 1.4078958389719909\n",
      "Epoch 5595, Loss: 208.86102247717213, Neurons: 201, Grad norm: 1.4078958389719909\n",
      "Epoch 5596, Loss: 208.86087820543912, Neurons: 201, Grad norm: 0.6782503778125912\n",
      "Epoch 5596, Loss: 208.86087820543912, Neurons: 201, Grad norm: 0.6782503778125912\n",
      "Epoch 5597, Loss: 208.86073388529243, Neurons: 201, Grad norm: 1.310440747986975\n",
      "Epoch 5597, Loss: 208.86073388529243, Neurons: 201, Grad norm: 1.310440747986975\n",
      "Epoch 5598, Loss: 208.86066644367318, Neurons: 201, Grad norm: 2.2934993826760035\n",
      "Epoch 5598, Loss: 208.86066644367318, Neurons: 201, Grad norm: 2.2934993826760035\n",
      "Epoch 5599, Loss: 208.86062677759332, Neurons: 201, Grad norm: 3.4975772745870275\n",
      "Epoch 5599, Loss: 208.86062677759332, Neurons: 201, Grad norm: 3.4975772745870275\n",
      "Epoch 5600, Loss: 208.86067252003127, Neurons: 201, Grad norm: 4.819367473663229\n",
      "Epoch 5600, Loss: 208.86067252003127, Neurons: 201, Grad norm: 4.819367473663229\n",
      "Epoch 5601, Loss: 208.86068537251583, Neurons: 201, Grad norm: 5.2537704474436\n",
      "Epoch 5601, Loss: 208.86068537251583, Neurons: 201, Grad norm: 5.2537704474436\n",
      "Epoch 5602, Loss: 208.86075082765998, Neurons: 201, Grad norm: 6.12525430050585\n",
      "Epoch 5602, Loss: 208.86075082765998, Neurons: 201, Grad norm: 6.12525430050585\n",
      "Epoch 5603, Loss: 208.86081552222396, Neurons: 201, Grad norm: 6.054398486338099\n",
      "Epoch 5603, Loss: 208.86081552222396, Neurons: 201, Grad norm: 6.054398486338099\n",
      "Epoch 5604, Loss: 208.86070597902332, Neurons: 201, Grad norm: 6.074383832473213\n",
      "Epoch 5604, Loss: 208.86070597902332, Neurons: 201, Grad norm: 6.074383832473213\n",
      "Epoch 5605, Loss: 208.8605352629699, Neurons: 201, Grad norm: 5.936692531018466\n",
      "Epoch 5605, Loss: 208.8605352629699, Neurons: 201, Grad norm: 5.936692531018466\n",
      "Epoch 5606, Loss: 208.86046503888016, Neurons: 201, Grad norm: 5.3847708555212\n",
      "Epoch 5606, Loss: 208.86046503888016, Neurons: 201, Grad norm: 5.3847708555212\n",
      "Epoch 5607, Loss: 208.86031208058571, Neurons: 201, Grad norm: 4.835768533343645\n",
      "Epoch 5607, Loss: 208.86031208058571, Neurons: 201, Grad norm: 4.835768533343645\n",
      "Epoch 5608, Loss: 208.8600769979554, Neurons: 201, Grad norm: 4.122716977788988\n",
      "Epoch 5608, Loss: 208.8600769979554, Neurons: 201, Grad norm: 4.122716977788988\n",
      "Epoch 5609, Loss: 208.85998014573366, Neurons: 201, Grad norm: 3.7636926781019953\n",
      "Epoch 5609, Loss: 208.85998014573366, Neurons: 201, Grad norm: 3.7636926781019953\n",
      "Epoch 5610, Loss: 208.85982770757155, Neurons: 201, Grad norm: 3.3430215618834773\n",
      "Epoch 5610, Loss: 208.85982770757155, Neurons: 201, Grad norm: 3.3430215618834773\n",
      "Epoch 5611, Loss: 208.85965287428394, Neurons: 201, Grad norm: 3.0038712934718115\n",
      "Epoch 5611, Loss: 208.85965287428394, Neurons: 201, Grad norm: 3.0038712934718115\n",
      "Epoch 5612, Loss: 208.8595630884964, Neurons: 201, Grad norm: 2.4557614239327896\n",
      "Epoch 5612, Loss: 208.8595630884964, Neurons: 201, Grad norm: 2.4557614239327896\n",
      "Epoch 5613, Loss: 208.85946276015568, Neurons: 201, Grad norm: 1.5162425475302623\n",
      "Epoch 5613, Loss: 208.85946276015568, Neurons: 201, Grad norm: 1.5162425475302623\n",
      "Epoch 5614, Loss: 208.85925649103172, Neurons: 201, Grad norm: 0.9888929283004216\n",
      "Epoch 5614, Loss: 208.85925649103172, Neurons: 201, Grad norm: 0.9888929283004216\n",
      "Epoch 5615, Loss: 208.85918984303981, Neurons: 201, Grad norm: 0.7309565047803788\n",
      "Epoch 5615, Loss: 208.85918984303981, Neurons: 201, Grad norm: 0.7309565047803788\n",
      "Epoch 5616, Loss: 208.85909355828042, Neurons: 201, Grad norm: 0.8912420950863741\n",
      "Epoch 5616, Loss: 208.85909355828042, Neurons: 201, Grad norm: 0.8912420950863741\n",
      "Epoch 5617, Loss: 208.85893988641052, Neurons: 201, Grad norm: 2.1200296762348927\n",
      "Epoch 5617, Loss: 208.85893988641052, Neurons: 201, Grad norm: 2.1200296762348927\n",
      "Epoch 5618, Loss: 208.85891907816497, Neurons: 201, Grad norm: 3.5187739265155784\n",
      "Epoch 5618, Loss: 208.85891907816497, Neurons: 201, Grad norm: 3.5187739265155784\n",
      "Epoch 5619, Loss: 208.85896522836833, Neurons: 201, Grad norm: 4.810691440536868\n",
      "Epoch 5619, Loss: 208.85896522836833, Neurons: 201, Grad norm: 4.810691440536868\n",
      "Epoch 5620, Loss: 208.85903487119356, Neurons: 201, Grad norm: 6.507039436906463\n",
      "Epoch 5620, Loss: 208.85903487119356, Neurons: 201, Grad norm: 6.507039436906463\n",
      "Epoch 5621, Loss: 208.85916509257513, Neurons: 201, Grad norm: 7.83809915967919\n",
      "Epoch 5621, Loss: 208.85916509257513, Neurons: 201, Grad norm: 7.83809915967919\n",
      "Epoch 5622, Loss: 208.85936030875, Neurons: 201, Grad norm: 8.7728064306448\n",
      "Epoch 5622, Loss: 208.85936030875, Neurons: 201, Grad norm: 8.7728064306448\n",
      "Epoch 5623, Loss: 208.8593879395028, Neurons: 201, Grad norm: 9.188263344964275\n",
      "Epoch 5623, Loss: 208.8593879395028, Neurons: 201, Grad norm: 9.188263344964275\n",
      "Epoch 5624, Loss: 208.85950161646707, Neurons: 201, Grad norm: 8.451916272786605\n",
      "Epoch 5624, Loss: 208.85950161646707, Neurons: 201, Grad norm: 8.451916272786605\n",
      "Epoch 5625, Loss: 208.85931009240824, Neurons: 201, Grad norm: 7.308591493550625\n",
      "Epoch 5625, Loss: 208.85931009240824, Neurons: 201, Grad norm: 7.308591493550625\n",
      "Epoch 5626, Loss: 208.85891991938195, Neurons: 201, Grad norm: 4.875643707138424\n",
      "Epoch 5626, Loss: 208.85891991938195, Neurons: 201, Grad norm: 4.875643707138424\n",
      "Epoch 5627, Loss: 208.85844972329778, Neurons: 201, Grad norm: 2.4370341907200057\n",
      "Epoch 5627, Loss: 208.85844972329778, Neurons: 201, Grad norm: 2.4370341907200057\n",
      "Epoch 5628, Loss: 208.8580803863545, Neurons: 201, Grad norm: 0.6544490346330512\n",
      "Epoch 5628, Loss: 208.8580803863545, Neurons: 201, Grad norm: 0.6544490346330512\n",
      "Epoch 5629, Loss: 208.85781689628732, Neurons: 201, Grad norm: 3.0781748328672984\n",
      "Epoch 5629, Loss: 208.85781689628732, Neurons: 201, Grad norm: 3.0781748328672984\n",
      "Epoch 5630, Loss: 208.8577464583898, Neurons: 201, Grad norm: 5.268143279221904\n",
      "Epoch 5630, Loss: 208.8577464583898, Neurons: 201, Grad norm: 5.268143279221904\n",
      "Epoch 5631, Loss: 208.85794273795082, Neurons: 201, Grad norm: 7.244402605824686\n",
      "Epoch 5631, Loss: 208.85794273795082, Neurons: 201, Grad norm: 7.244402605824686\n",
      "Epoch 5632, Loss: 208.85815347313667, Neurons: 201, Grad norm: 8.952106483924293\n",
      "Epoch 5632, Loss: 208.85815347313667, Neurons: 201, Grad norm: 8.952106483924293\n",
      "Epoch 5633, Loss: 208.85831748897974, Neurons: 201, Grad norm: 9.728947132804942\n",
      "Epoch 5633, Loss: 208.85831748897974, Neurons: 201, Grad norm: 9.728947132804942\n",
      "Epoch 5634, Loss: 208.8584561100538, Neurons: 201, Grad norm: 10.15995139249143\n",
      "Epoch 5634, Loss: 208.8584561100538, Neurons: 201, Grad norm: 10.15995139249143\n",
      "Epoch 5635, Loss: 208.85842459773409, Neurons: 201, Grad norm: 9.675247257607278\n",
      "Epoch 5635, Loss: 208.85842459773409, Neurons: 201, Grad norm: 9.675247257607278\n",
      "Epoch 5636, Loss: 208.85807726372238, Neurons: 201, Grad norm: 8.131177429517905\n",
      "Epoch 5636, Loss: 208.85807726372238, Neurons: 201, Grad norm: 8.131177429517905\n",
      "Epoch 5637, Loss: 208.85756059499113, Neurons: 201, Grad norm: 5.828307211905921\n",
      "Epoch 5637, Loss: 208.85756059499113, Neurons: 201, Grad norm: 5.828307211905921\n",
      "Epoch 5638, Loss: 208.85694410748908, Neurons: 201, Grad norm: 3.1120620464181914\n",
      "Epoch 5638, Loss: 208.85694410748908, Neurons: 201, Grad norm: 3.1120620464181914\n",
      "Epoch 5639, Loss: 208.85643167391805, Neurons: 201, Grad norm: 0.7770872111882944\n",
      "Epoch 5639, Loss: 208.85643167391805, Neurons: 201, Grad norm: 0.7770872111882944\n",
      "Epoch 5640, Loss: 208.85615647375684, Neurons: 201, Grad norm: 3.1177496635624804\n",
      "Epoch 5640, Loss: 208.85615647375684, Neurons: 201, Grad norm: 3.1177496635624804\n",
      "Epoch 5641, Loss: 208.8561411478712, Neurons: 201, Grad norm: 5.3845039118628675\n",
      "Epoch 5641, Loss: 208.8561411478712, Neurons: 201, Grad norm: 5.3845039118628675\n",
      "Epoch 5642, Loss: 208.85619743194363, Neurons: 201, Grad norm: 7.141959607204747\n",
      "Epoch 5642, Loss: 208.85619743194363, Neurons: 201, Grad norm: 7.141959607204747\n",
      "Epoch 5643, Loss: 208.8563107906726, Neurons: 201, Grad norm: 7.984477736215663\n",
      "Epoch 5643, Loss: 208.8563107906726, Neurons: 201, Grad norm: 7.984477736215663\n",
      "Epoch 5644, Loss: 208.85636516573265, Neurons: 201, Grad norm: 8.040284863626642\n",
      "Epoch 5644, Loss: 208.85636516573265, Neurons: 201, Grad norm: 8.040284863626642\n",
      "Epoch 5645, Loss: 208.85620367221196, Neurons: 201, Grad norm: 7.217529370136916\n",
      "Epoch 5645, Loss: 208.85620367221196, Neurons: 201, Grad norm: 7.217529370136916\n",
      "Epoch 5646, Loss: 208.85586044850038, Neurons: 201, Grad norm: 5.40939368866273\n",
      "Epoch 5646, Loss: 208.85586044850038, Neurons: 201, Grad norm: 5.40939368866273\n",
      "Epoch 5647, Loss: 208.85541218051534, Neurons: 201, Grad norm: 3.3852922440203073\n",
      "Epoch 5647, Loss: 208.85541218051534, Neurons: 201, Grad norm: 3.3852922440203073\n",
      "Epoch 5648, Loss: 208.85508113804832, Neurons: 201, Grad norm: 1.2485732067823208\n",
      "Epoch 5648, Loss: 208.85508113804832, Neurons: 201, Grad norm: 1.2485732067823208\n",
      "Epoch 5649, Loss: 208.85482669819672, Neurons: 201, Grad norm: 1.800583560087775\n",
      "Epoch 5649, Loss: 208.85482669819672, Neurons: 201, Grad norm: 1.800583560087775\n",
      "Epoch 5650, Loss: 208.85462439267388, Neurons: 201, Grad norm: 4.1287802038874535\n",
      "Epoch 5650, Loss: 208.85462439267388, Neurons: 201, Grad norm: 4.1287802038874535\n",
      "Epoch 5651, Loss: 208.85473806921468, Neurons: 201, Grad norm: 6.021454747265962\n",
      "Epoch 5651, Loss: 208.85473806921468, Neurons: 201, Grad norm: 6.021454747265962\n",
      "Epoch 5652, Loss: 208.85489711636666, Neurons: 201, Grad norm: 7.276388022408704\n",
      "Epoch 5652, Loss: 208.85489711636666, Neurons: 201, Grad norm: 7.276388022408704\n",
      "Epoch 5653, Loss: 208.8549160072944, Neurons: 201, Grad norm: 7.682479088969935\n",
      "Epoch 5653, Loss: 208.8549160072944, Neurons: 201, Grad norm: 7.682479088969935\n",
      "Epoch 5654, Loss: 208.854912106987, Neurons: 201, Grad norm: 7.4520039422205775\n",
      "Epoch 5654, Loss: 208.854912106987, Neurons: 201, Grad norm: 7.4520039422205775\n",
      "Epoch 5655, Loss: 208.85475334800003, Neurons: 201, Grad norm: 6.304816207670431\n",
      "Epoch 5655, Loss: 208.85475334800003, Neurons: 201, Grad norm: 6.304816207670431\n",
      "Epoch 5656, Loss: 208.85443171142785, Neurons: 201, Grad norm: 4.8911212477413475\n",
      "Epoch 5656, Loss: 208.85443171142785, Neurons: 201, Grad norm: 4.8911212477413475\n",
      "Epoch 5657, Loss: 208.85407565754412, Neurons: 201, Grad norm: 2.844655566401433\n",
      "Epoch 5657, Loss: 208.85407565754412, Neurons: 201, Grad norm: 2.844655566401433\n",
      "Epoch 5658, Loss: 208.85374008775995, Neurons: 201, Grad norm: 0.971638030403431\n",
      "Epoch 5658, Loss: 208.85374008775995, Neurons: 201, Grad norm: 0.971638030403431\n",
      "Epoch 5659, Loss: 208.85351943310212, Neurons: 201, Grad norm: 1.6374598276395427\n",
      "Epoch 5659, Loss: 208.85351943310212, Neurons: 201, Grad norm: 1.6374598276395427\n",
      "Epoch 5660, Loss: 208.8533875920218, Neurons: 201, Grad norm: 3.5585935276128344\n",
      "Epoch 5660, Loss: 208.8533875920218, Neurons: 201, Grad norm: 3.5585935276128344\n",
      "Epoch 5661, Loss: 208.85338105302927, Neurons: 201, Grad norm: 5.657278305223135\n",
      "Epoch 5661, Loss: 208.85338105302927, Neurons: 201, Grad norm: 5.657278305223135\n",
      "Epoch 5662, Loss: 208.85353619484937, Neurons: 201, Grad norm: 7.2332802138699295\n",
      "Epoch 5662, Loss: 208.85353619484937, Neurons: 201, Grad norm: 7.2332802138699295\n",
      "Epoch 5663, Loss: 208.85370101323596, Neurons: 201, Grad norm: 8.487861840872624\n",
      "Epoch 5663, Loss: 208.85370101323596, Neurons: 201, Grad norm: 8.487861840872624\n",
      "Epoch 5664, Loss: 208.85379522683098, Neurons: 201, Grad norm: 9.074061784697287\n",
      "Epoch 5664, Loss: 208.85379522683098, Neurons: 201, Grad norm: 9.074061784697287\n",
      "Epoch 5665, Loss: 208.8538570193904, Neurons: 201, Grad norm: 8.883221635524777\n",
      "Epoch 5665, Loss: 208.8538570193904, Neurons: 201, Grad norm: 8.883221635524777\n",
      "Epoch 5666, Loss: 208.85375125577744, Neurons: 201, Grad norm: 7.715073740933556\n",
      "Epoch 5666, Loss: 208.85375125577744, Neurons: 201, Grad norm: 7.715073740933556\n",
      "Epoch 5667, Loss: 208.85338132144304, Neurons: 201, Grad norm: 5.853883156897866\n",
      "Epoch 5667, Loss: 208.85338132144304, Neurons: 201, Grad norm: 5.853883156897866\n",
      "Epoch 5668, Loss: 208.85286479754342, Neurons: 201, Grad norm: 3.3110411451069166\n",
      "Epoch 5668, Loss: 208.85286479754342, Neurons: 201, Grad norm: 3.3110411451069166\n",
      "Epoch 5669, Loss: 208.8524301040297, Neurons: 201, Grad norm: 0.8258560218221209\n",
      "Epoch 5669, Loss: 208.8524301040297, Neurons: 201, Grad norm: 0.8258560218221209\n",
      "Epoch 5670, Loss: 208.85219006120124, Neurons: 201, Grad norm: 1.8262497363920482\n",
      "Epoch 5670, Loss: 208.85219006120124, Neurons: 201, Grad norm: 1.8262497363920482\n",
      "Epoch 5671, Loss: 208.85213147228572, Neurons: 201, Grad norm: 3.6590987009842677\n",
      "Epoch 5671, Loss: 208.85213147228572, Neurons: 201, Grad norm: 3.6590987009842677\n",
      "Epoch 5672, Loss: 208.8521247223147, Neurons: 201, Grad norm: 5.162208772868656\n",
      "Epoch 5672, Loss: 208.8521247223147, Neurons: 201, Grad norm: 5.162208772868656\n",
      "Epoch 5673, Loss: 208.8521659594921, Neurons: 201, Grad norm: 6.025952653891533\n",
      "Epoch 5673, Loss: 208.8521659594921, Neurons: 201, Grad norm: 6.025952653891533\n",
      "Epoch 5674, Loss: 208.85218418215294, Neurons: 201, Grad norm: 6.768288676346619\n",
      "Epoch 5674, Loss: 208.85218418215294, Neurons: 201, Grad norm: 6.768288676346619\n",
      "Epoch 5675, Loss: 208.85218602487853, Neurons: 201, Grad norm: 7.170684570697278\n",
      "Epoch 5675, Loss: 208.85218602487853, Neurons: 201, Grad norm: 7.170684570697278\n",
      "Epoch 5676, Loss: 208.85215907921372, Neurons: 201, Grad norm: 7.211636409456065\n",
      "Epoch 5676, Loss: 208.85215907921372, Neurons: 201, Grad norm: 7.211636409456065\n",
      "Epoch 5677, Loss: 208.85203797509328, Neurons: 201, Grad norm: 6.570397128206083\n",
      "Epoch 5677, Loss: 208.85203797509328, Neurons: 201, Grad norm: 6.570397128206083\n",
      "Epoch 5678, Loss: 208.85184482779422, Neurons: 201, Grad norm: 5.800316783002727\n",
      "Epoch 5678, Loss: 208.85184482779422, Neurons: 201, Grad norm: 5.800316783002727\n",
      "Epoch 5679, Loss: 208.851527264542, Neurons: 201, Grad norm: 4.128079838803472\n",
      "Epoch 5679, Loss: 208.851527264542, Neurons: 201, Grad norm: 4.128079838803472\n",
      "Epoch 5680, Loss: 208.8512055446723, Neurons: 201, Grad norm: 2.5542077113391373\n",
      "Epoch 5680, Loss: 208.8512055446723, Neurons: 201, Grad norm: 2.5542077113391373\n",
      "Epoch 5681, Loss: 208.85095628995592, Neurons: 201, Grad norm: 1.0732419174292718\n",
      "Epoch 5681, Loss: 208.85095628995592, Neurons: 201, Grad norm: 1.0732419174292718\n",
      "Epoch 5682, Loss: 208.8507780531629, Neurons: 201, Grad norm: 1.0965448145581744\n",
      "Epoch 5682, Loss: 208.8507780531629, Neurons: 201, Grad norm: 1.0965448145581744\n",
      "Epoch 5683, Loss: 208.85064465212943, Neurons: 201, Grad norm: 2.1710150974543563\n",
      "Epoch 5683, Loss: 208.85064465212943, Neurons: 201, Grad norm: 2.1710150974543563\n",
      "Epoch 5684, Loss: 208.85056326901474, Neurons: 201, Grad norm: 3.244598411812779\n",
      "Epoch 5684, Loss: 208.85056326901474, Neurons: 201, Grad norm: 3.244598411812779\n",
      "Epoch 5685, Loss: 208.8505395850399, Neurons: 201, Grad norm: 4.206632469416946\n",
      "Epoch 5685, Loss: 208.8505395850399, Neurons: 201, Grad norm: 4.206632469416946\n",
      "Epoch 5686, Loss: 208.85048473814865, Neurons: 201, Grad norm: 4.59763294769893\n",
      "Epoch 5686, Loss: 208.85048473814865, Neurons: 201, Grad norm: 4.59763294769893\n",
      "Epoch 5687, Loss: 208.85046519189643, Neurons: 201, Grad norm: 5.293734205949996\n",
      "Epoch 5687, Loss: 208.85046519189643, Neurons: 201, Grad norm: 5.293734205949996\n",
      "Epoch 5688, Loss: 208.85046049498737, Neurons: 201, Grad norm: 5.474580423577887\n",
      "Epoch 5688, Loss: 208.85046049498737, Neurons: 201, Grad norm: 5.474580423577887\n",
      "Epoch 5689, Loss: 208.85036470294574, Neurons: 201, Grad norm: 5.52630309379669\n",
      "Epoch 5689, Loss: 208.85036470294574, Neurons: 201, Grad norm: 5.52630309379669\n",
      "Epoch 5690, Loss: 208.85018747152756, Neurons: 201, Grad norm: 5.588195258960716\n",
      "Epoch 5690, Loss: 208.85018747152756, Neurons: 201, Grad norm: 5.588195258960716\n",
      "Epoch 5691, Loss: 208.85007716780484, Neurons: 201, Grad norm: 5.70486143816277\n",
      "Epoch 5691, Loss: 208.85007716780484, Neurons: 201, Grad norm: 5.70486143816277\n",
      "Epoch 5692, Loss: 208.85000004811937, Neurons: 201, Grad norm: 5.548572353702978\n",
      "Epoch 5692, Loss: 208.85000004811937, Neurons: 201, Grad norm: 5.548572353702978\n",
      "Epoch 5693, Loss: 208.84985920974557, Neurons: 201, Grad norm: 4.95766074507397\n",
      "Epoch 5693, Loss: 208.84985920974557, Neurons: 201, Grad norm: 4.95766074507397\n",
      "Epoch 5694, Loss: 208.84968156168856, Neurons: 201, Grad norm: 4.024284081015752\n",
      "Epoch 5694, Loss: 208.84968156168856, Neurons: 201, Grad norm: 4.024284081015752\n",
      "Epoch 5695, Loss: 208.849467796263, Neurons: 201, Grad norm: 3.0786061833781724\n",
      "Epoch 5695, Loss: 208.849467796263, Neurons: 201, Grad norm: 3.0786061833781724\n",
      "Epoch 5696, Loss: 208.8493098179478, Neurons: 201, Grad norm: 1.983584053724139\n",
      "Epoch 5696, Loss: 208.8493098179478, Neurons: 201, Grad norm: 1.983584053724139\n",
      "Epoch 5697, Loss: 208.84925264334996, Neurons: 201, Grad norm: 1.288209157188646\n",
      "Epoch 5697, Loss: 208.84925264334996, Neurons: 201, Grad norm: 1.288209157188646\n",
      "Epoch 5698, Loss: 208.84904784920357, Neurons: 201, Grad norm: 0.7228794031000699\n",
      "Epoch 5698, Loss: 208.84904784920357, Neurons: 201, Grad norm: 0.7228794031000699\n",
      "Epoch 5699, Loss: 208.84885324428788, Neurons: 201, Grad norm: 1.5794964099027622\n",
      "Epoch 5699, Loss: 208.84885324428788, Neurons: 201, Grad norm: 1.5794964099027622\n",
      "Epoch 5700, Loss: 208.84883597472643, Neurons: 201, Grad norm: 2.3606871819177\n",
      "Epoch 5700, Loss: 208.84883597472643, Neurons: 201, Grad norm: 2.3606871819177\n",
      "Epoch 5701, Loss: 208.8488187635964, Neurons: 201, Grad norm: 3.72495917781891\n",
      "Epoch 5701, Loss: 208.8488187635964, Neurons: 201, Grad norm: 3.72495917781891\n",
      "Epoch 5702, Loss: 208.84871398357248, Neurons: 201, Grad norm: 4.928390671880916\n",
      "Epoch 5702, Loss: 208.84871398357248, Neurons: 201, Grad norm: 4.928390671880916\n",
      "Epoch 5703, Loss: 208.8487741199001, Neurons: 201, Grad norm: 5.695447720852579\n",
      "Epoch 5703, Loss: 208.8487741199001, Neurons: 201, Grad norm: 5.695447720852579\n",
      "Epoch 5704, Loss: 208.84880830950615, Neurons: 201, Grad norm: 6.60386981541779\n",
      "Epoch 5704, Loss: 208.84880830950615, Neurons: 201, Grad norm: 6.60386981541779\n",
      "Epoch 5705, Loss: 208.8488134169956, Neurons: 201, Grad norm: 6.739830593267935\n",
      "Epoch 5705, Loss: 208.8488134169956, Neurons: 201, Grad norm: 6.739830593267935\n",
      "Epoch 5706, Loss: 208.8487729506418, Neurons: 201, Grad norm: 6.936215356763297\n",
      "Epoch 5706, Loss: 208.8487729506418, Neurons: 201, Grad norm: 6.936215356763297\n",
      "Epoch 5707, Loss: 208.84875928244566, Neurons: 201, Grad norm: 6.472780386117416\n",
      "Epoch 5707, Loss: 208.84875928244566, Neurons: 201, Grad norm: 6.472780386117416\n",
      "Epoch 5708, Loss: 208.84858668974366, Neurons: 201, Grad norm: 5.812029779438768\n",
      "Epoch 5708, Loss: 208.84858668974366, Neurons: 201, Grad norm: 5.812029779438768\n",
      "Epoch 5709, Loss: 208.84830616670212, Neurons: 201, Grad norm: 4.756005868063525\n",
      "Epoch 5709, Loss: 208.84830616670212, Neurons: 201, Grad norm: 4.756005868063525\n",
      "Epoch 5710, Loss: 208.84809042226703, Neurons: 201, Grad norm: 3.5949790233842616\n",
      "Epoch 5710, Loss: 208.84809042226703, Neurons: 201, Grad norm: 3.5949790233842616\n",
      "Epoch 5711, Loss: 208.84788378967744, Neurons: 201, Grad norm: 2.213265336218976\n",
      "Epoch 5711, Loss: 208.84788378967744, Neurons: 201, Grad norm: 2.213265336218976\n",
      "Epoch 5712, Loss: 208.84764665860928, Neurons: 201, Grad norm: 1.047136141538787\n",
      "Epoch 5712, Loss: 208.84764665860928, Neurons: 201, Grad norm: 1.047136141538787\n",
      "Epoch 5713, Loss: 208.847478552468, Neurons: 201, Grad norm: 0.8478900349452536\n",
      "Epoch 5713, Loss: 208.847478552468, Neurons: 201, Grad norm: 0.8478900349452536\n",
      "Epoch 5714, Loss: 208.8474313963505, Neurons: 201, Grad norm: 1.4462934512260261\n",
      "Epoch 5714, Loss: 208.8474313963505, Neurons: 201, Grad norm: 1.4462934512260261\n",
      "Epoch 5715, Loss: 208.84736657575473, Neurons: 201, Grad norm: 2.3212654502986427\n",
      "Epoch 5715, Loss: 208.84736657575473, Neurons: 201, Grad norm: 2.3212654502986427\n",
      "Epoch 5716, Loss: 208.84725380210102, Neurons: 201, Grad norm: 3.3008151101170795\n",
      "Epoch 5716, Loss: 208.84725380210102, Neurons: 201, Grad norm: 3.3008151101170795\n",
      "Epoch 5717, Loss: 208.84724805923446, Neurons: 201, Grad norm: 4.796031485343028\n",
      "Epoch 5717, Loss: 208.84724805923446, Neurons: 201, Grad norm: 4.796031485343028\n",
      "Epoch 5718, Loss: 208.84735568938686, Neurons: 201, Grad norm: 6.335465891964976\n",
      "Epoch 5718, Loss: 208.84735568938686, Neurons: 201, Grad norm: 6.335465891964976\n",
      "Epoch 5719, Loss: 208.84742296200125, Neurons: 201, Grad norm: 7.8681766164525495\n",
      "Epoch 5719, Loss: 208.84742296200125, Neurons: 201, Grad norm: 7.8681766164525495\n",
      "Epoch 5720, Loss: 208.84760641627054, Neurons: 201, Grad norm: 8.884977965731885\n",
      "Epoch 5720, Loss: 208.84760641627054, Neurons: 201, Grad norm: 8.884977965731885\n",
      "Epoch 5721, Loss: 208.84777961450195, Neurons: 201, Grad norm: 9.37379530624147\n",
      "Epoch 5721, Loss: 208.84777961450195, Neurons: 201, Grad norm: 9.37379530624147\n",
      "Epoch 5722, Loss: 208.84782535441622, Neurons: 201, Grad norm: 8.747590947556473\n",
      "Epoch 5722, Loss: 208.84782535441622, Neurons: 201, Grad norm: 8.747590947556473\n",
      "Epoch 5723, Loss: 208.84760083646256, Neurons: 201, Grad norm: 7.3369475628805665\n",
      "Epoch 5723, Loss: 208.84760083646256, Neurons: 201, Grad norm: 7.3369475628805665\n",
      "Epoch 5724, Loss: 208.84722683493123, Neurons: 201, Grad norm: 4.7305775349372485\n",
      "Epoch 5724, Loss: 208.84722683493123, Neurons: 201, Grad norm: 4.7305775349372485\n",
      "Epoch 5725, Loss: 208.84674973412928, Neurons: 201, Grad norm: 2.2076805278775242\n",
      "Epoch 5725, Loss: 208.84674973412928, Neurons: 201, Grad norm: 2.2076805278775242\n",
      "Epoch 5726, Loss: 208.84636367136417, Neurons: 201, Grad norm: 0.9066424505675887\n",
      "Epoch 5726, Loss: 208.84636367136417, Neurons: 201, Grad norm: 0.9066424505675887\n",
      "Epoch 5727, Loss: 208.84620993788818, Neurons: 201, Grad norm: 3.5895372533694\n",
      "Epoch 5727, Loss: 208.84620993788818, Neurons: 201, Grad norm: 3.5895372533694\n",
      "Epoch 5728, Loss: 208.84628818747407, Neurons: 201, Grad norm: 5.829050015606864\n",
      "Epoch 5728, Loss: 208.84628818747407, Neurons: 201, Grad norm: 5.829050015606864\n",
      "Epoch 5729, Loss: 208.84648082020263, Neurons: 201, Grad norm: 8.001903257930456\n",
      "Epoch 5729, Loss: 208.84648082020263, Neurons: 201, Grad norm: 8.001903257930456\n",
      "Epoch 5730, Loss: 208.84675362600356, Neurons: 201, Grad norm: 9.348793237246749\n",
      "Epoch 5730, Loss: 208.84675362600356, Neurons: 201, Grad norm: 9.348793237246749\n",
      "Epoch 5731, Loss: 208.84698152370316, Neurons: 201, Grad norm: 9.95722274576781\n",
      "Epoch 5731, Loss: 208.84698152370316, Neurons: 201, Grad norm: 9.95722274576781\n",
      "Epoch 5732, Loss: 208.84706625397732, Neurons: 201, Grad norm: 9.968717353057254\n",
      "Epoch 5732, Loss: 208.84706625397732, Neurons: 201, Grad norm: 9.968717353057254\n",
      "Epoch 5733, Loss: 208.84699414101792, Neurons: 201, Grad norm: 8.837402712857807\n",
      "Epoch 5733, Loss: 208.84699414101792, Neurons: 201, Grad norm: 8.837402712857807\n",
      "Epoch 5734, Loss: 208.84666048474122, Neurons: 201, Grad norm: 7.081294436363793\n",
      "Epoch 5734, Loss: 208.84666048474122, Neurons: 201, Grad norm: 7.081294436363793\n",
      "Epoch 5735, Loss: 208.84617133931587, Neurons: 201, Grad norm: 4.140296773929807\n",
      "Epoch 5735, Loss: 208.84617133931587, Neurons: 201, Grad norm: 4.140296773929807\n",
      "Epoch 5736, Loss: 208.84566431965584, Neurons: 201, Grad norm: 1.3303879509968042\n",
      "Epoch 5736, Loss: 208.84566431965584, Neurons: 201, Grad norm: 1.3303879509968042\n",
      "Epoch 5737, Loss: 208.8453553508864, Neurons: 201, Grad norm: 1.919926107496029\n",
      "Epoch 5737, Loss: 208.8453553508864, Neurons: 201, Grad norm: 1.919926107496029\n",
      "Epoch 5738, Loss: 208.8452619293032, Neurons: 201, Grad norm: 4.4313738506627915\n",
      "Epoch 5738, Loss: 208.8452619293032, Neurons: 201, Grad norm: 4.4313738506627915\n",
      "Epoch 5739, Loss: 208.84537976569771, Neurons: 201, Grad norm: 6.093280804201574\n",
      "Epoch 5739, Loss: 208.84537976569771, Neurons: 201, Grad norm: 6.093280804201574\n",
      "Epoch 5740, Loss: 208.84559542173562, Neurons: 201, Grad norm: 7.159280974869111\n",
      "Epoch 5740, Loss: 208.84559542173562, Neurons: 201, Grad norm: 7.159280974869111\n",
      "Epoch 5741, Loss: 208.84562662591455, Neurons: 201, Grad norm: 7.30804378315427\n",
      "Epoch 5741, Loss: 208.84562662591455, Neurons: 201, Grad norm: 7.30804378315427\n",
      "Epoch 5742, Loss: 208.8455968026423, Neurons: 201, Grad norm: 6.715766245622536\n",
      "Epoch 5742, Loss: 208.8455968026423, Neurons: 201, Grad norm: 6.715766245622536\n",
      "Epoch 5743, Loss: 208.84543941204788, Neurons: 201, Grad norm: 5.4851553196537886\n",
      "Epoch 5743, Loss: 208.84543941204788, Neurons: 201, Grad norm: 5.4851553196537886\n",
      "Epoch 5744, Loss: 208.84510888532074, Neurons: 201, Grad norm: 3.5566792421107634\n",
      "Epoch 5744, Loss: 208.84510888532074, Neurons: 201, Grad norm: 3.5566792421107634\n",
      "Epoch 5745, Loss: 208.84477570635121, Neurons: 201, Grad norm: 1.9832123212329933\n",
      "Epoch 5745, Loss: 208.84477570635121, Neurons: 201, Grad norm: 1.9832123212329933\n",
      "Epoch 5746, Loss: 208.84458424589815, Neurons: 201, Grad norm: 0.5640096751930063\n",
      "Epoch 5746, Loss: 208.84458424589815, Neurons: 201, Grad norm: 0.5640096751930063\n",
      "Epoch 5747, Loss: 208.84441500243867, Neurons: 201, Grad norm: 1.973463158410233\n",
      "Epoch 5747, Loss: 208.84441500243867, Neurons: 201, Grad norm: 1.973463158410233\n",
      "Epoch 5748, Loss: 208.84439950058933, Neurons: 201, Grad norm: 3.6712517557496716\n",
      "Epoch 5748, Loss: 208.84439950058933, Neurons: 201, Grad norm: 3.6712517557496716\n",
      "Epoch 5749, Loss: 208.84443246083757, Neurons: 201, Grad norm: 5.354307384732587\n",
      "Epoch 5749, Loss: 208.84443246083757, Neurons: 201, Grad norm: 5.354307384732587\n",
      "Epoch 5750, Loss: 208.84450442097915, Neurons: 201, Grad norm: 6.123330511415577\n",
      "Epoch 5750, Loss: 208.84450442097915, Neurons: 201, Grad norm: 6.123330511415577\n",
      "Epoch 5751, Loss: 208.84458457683476, Neurons: 201, Grad norm: 6.856475870336652\n",
      "Epoch 5751, Loss: 208.84458457683476, Neurons: 201, Grad norm: 6.856475870336652\n",
      "Epoch 5752, Loss: 208.8446283194379, Neurons: 201, Grad norm: 7.042864754693688\n",
      "Epoch 5752, Loss: 208.8446283194379, Neurons: 201, Grad norm: 7.042864754693688\n",
      "Epoch 5753, Loss: 208.8446107389331, Neurons: 201, Grad norm: 6.4498040093196805\n",
      "Epoch 5753, Loss: 208.8446107389331, Neurons: 201, Grad norm: 6.4498040093196805\n",
      "Epoch 5754, Loss: 208.84442375086954, Neurons: 201, Grad norm: 5.576011818589409\n",
      "Epoch 5754, Loss: 208.84442375086954, Neurons: 201, Grad norm: 5.576011818589409\n",
      "Epoch 5755, Loss: 208.8441346688801, Neurons: 201, Grad norm: 3.5213485831300377\n",
      "Epoch 5755, Loss: 208.8441346688801, Neurons: 201, Grad norm: 3.5213485831300377\n",
      "Epoch 5756, Loss: 208.84381704126085, Neurons: 201, Grad norm: 1.759598685003623\n",
      "Epoch 5756, Loss: 208.84381704126085, Neurons: 201, Grad norm: 1.759598685003623\n",
      "Epoch 5757, Loss: 208.8435839137553, Neurons: 201, Grad norm: 0.8679124988568069\n",
      "Epoch 5757, Loss: 208.8435839137553, Neurons: 201, Grad norm: 0.8679124988568069\n",
      "Epoch 5758, Loss: 208.8434616777839, Neurons: 201, Grad norm: 2.7997850886524485\n",
      "Epoch 5758, Loss: 208.8434616777839, Neurons: 201, Grad norm: 2.7997850886524485\n",
      "Epoch 5759, Loss: 208.84345157688546, Neurons: 201, Grad norm: 4.44698898843905\n",
      "Epoch 5759, Loss: 208.84345157688546, Neurons: 201, Grad norm: 4.44698898843905\n",
      "Epoch 5760, Loss: 208.84353930057142, Neurons: 201, Grad norm: 6.1570193723804145\n",
      "Epoch 5760, Loss: 208.84353930057142, Neurons: 201, Grad norm: 6.1570193723804145\n",
      "Epoch 5761, Loss: 208.8436839398764, Neurons: 201, Grad norm: 7.4167027110307115\n",
      "Epoch 5761, Loss: 208.8436839398764, Neurons: 201, Grad norm: 7.4167027110307115\n",
      "Epoch 5762, Loss: 208.84379320064912, Neurons: 201, Grad norm: 7.961393646459964\n",
      "Epoch 5762, Loss: 208.84379320064912, Neurons: 201, Grad norm: 7.961393646459964\n",
      "Epoch 5763, Loss: 208.84389860662728, Neurons: 201, Grad norm: 8.203557394326952\n",
      "Epoch 5763, Loss: 208.84389860662728, Neurons: 201, Grad norm: 8.203557394326952\n",
      "Epoch 5764, Loss: 208.8438227629553, Neurons: 201, Grad norm: 7.7467622740454\n",
      "Epoch 5764, Loss: 208.8438227629553, Neurons: 201, Grad norm: 7.7467622740454\n",
      "Epoch 5765, Loss: 208.84373910756608, Neurons: 201, Grad norm: 7.21047186294551\n",
      "Epoch 5765, Loss: 208.84373910756608, Neurons: 201, Grad norm: 7.21047186294551\n",
      "Epoch 5766, Loss: 208.84344834157972, Neurons: 201, Grad norm: 6.087613346223034\n",
      "Epoch 5766, Loss: 208.84344834157972, Neurons: 201, Grad norm: 6.087613346223034\n",
      "Epoch 5767, Loss: 208.84312851536004, Neurons: 201, Grad norm: 4.795863632534485\n",
      "Epoch 5767, Loss: 208.84312851536004, Neurons: 201, Grad norm: 4.795863632534485\n",
      "Epoch 5768, Loss: 208.84290122142804, Neurons: 201, Grad norm: 2.8376067874697934\n",
      "Epoch 5768, Loss: 208.84290122142804, Neurons: 201, Grad norm: 2.8376067874697934\n",
      "Epoch 5769, Loss: 208.84272738316704, Neurons: 201, Grad norm: 0.9476431671373431\n",
      "Epoch 5769, Loss: 208.84272738316704, Neurons: 201, Grad norm: 0.9476431671373431\n",
      "Epoch 5770, Loss: 208.84244909945843, Neurons: 201, Grad norm: 1.5989251075174267\n",
      "Epoch 5770, Loss: 208.84244909945843, Neurons: 201, Grad norm: 1.5989251075174267\n",
      "Epoch 5771, Loss: 208.84238075374398, Neurons: 201, Grad norm: 3.380856420694974\n",
      "Epoch 5771, Loss: 208.84238075374398, Neurons: 201, Grad norm: 3.380856420694974\n",
      "Epoch 5772, Loss: 208.84250752350542, Neurons: 201, Grad norm: 4.543809257690439\n",
      "Epoch 5772, Loss: 208.84250752350542, Neurons: 201, Grad norm: 4.543809257690439\n",
      "Epoch 5773, Loss: 208.84239187247525, Neurons: 201, Grad norm: 5.488819848387404\n",
      "Epoch 5773, Loss: 208.84239187247525, Neurons: 201, Grad norm: 5.488819848387404\n",
      "Epoch 5774, Loss: 208.84243396092256, Neurons: 201, Grad norm: 6.557499808431319\n",
      "Epoch 5774, Loss: 208.84243396092256, Neurons: 201, Grad norm: 6.557499808431319\n",
      "Epoch 5775, Loss: 208.84252814726526, Neurons: 201, Grad norm: 7.262554703207688\n",
      "Epoch 5775, Loss: 208.84252814726526, Neurons: 201, Grad norm: 7.262554703207688\n",
      "Epoch 5776, Loss: 208.8426242438675, Neurons: 201, Grad norm: 7.807962816463795\n",
      "Epoch 5776, Loss: 208.8426242438675, Neurons: 201, Grad norm: 7.807962816463795\n",
      "Epoch 5777, Loss: 208.8426254568463, Neurons: 201, Grad norm: 7.989464421479931\n",
      "Epoch 5777, Loss: 208.8426254568463, Neurons: 201, Grad norm: 7.989464421479931\n",
      "Epoch 5778, Loss: 208.8425446094223, Neurons: 201, Grad norm: 7.8837743353987\n",
      "Epoch 5778, Loss: 208.8425446094223, Neurons: 201, Grad norm: 7.8837743353987\n",
      "Epoch 5779, Loss: 208.84240621666416, Neurons: 201, Grad norm: 7.1799249234922895\n",
      "Epoch 5779, Loss: 208.84240621666416, Neurons: 201, Grad norm: 7.1799249234922895\n",
      "Epoch 5780, Loss: 208.84219875606667, Neurons: 201, Grad norm: 6.369773741581678\n",
      "Epoch 5780, Loss: 208.84219875606667, Neurons: 201, Grad norm: 6.369773741581678\n",
      "Epoch 5781, Loss: 208.84198520771457, Neurons: 201, Grad norm: 4.678657331128429\n",
      "Epoch 5781, Loss: 208.84198520771457, Neurons: 201, Grad norm: 4.678657331128429\n",
      "Epoch 5782, Loss: 208.8416192660206, Neurons: 201, Grad norm: 2.773610218636805\n",
      "Epoch 5782, Loss: 208.8416192660206, Neurons: 201, Grad norm: 2.773610218636805\n",
      "Epoch 5783, Loss: 208.84137227222672, Neurons: 201, Grad norm: 0.8650767601381804\n",
      "Epoch 5783, Loss: 208.84137227222672, Neurons: 201, Grad norm: 0.8650767601381804\n",
      "Epoch 5784, Loss: 208.84121199639213, Neurons: 201, Grad norm: 1.9912171603215274\n",
      "Epoch 5784, Loss: 208.84121199639213, Neurons: 201, Grad norm: 1.9912171603215274\n",
      "Epoch 5785, Loss: 208.84111462715714, Neurons: 201, Grad norm: 3.7574804679061917\n",
      "Epoch 5785, Loss: 208.84111462715714, Neurons: 201, Grad norm: 3.7574804679061917\n",
      "Epoch 5786, Loss: 208.841127036066, Neurons: 201, Grad norm: 4.97292201512834\n",
      "Epoch 5786, Loss: 208.841127036066, Neurons: 201, Grad norm: 4.97292201512834\n",
      "Epoch 5787, Loss: 208.8412266316407, Neurons: 201, Grad norm: 6.127086390803922\n",
      "Epoch 5787, Loss: 208.8412266316407, Neurons: 201, Grad norm: 6.127086390803922\n",
      "Epoch 5788, Loss: 208.84124137411493, Neurons: 201, Grad norm: 6.721398587168871\n",
      "Epoch 5788, Loss: 208.84124137411493, Neurons: 201, Grad norm: 6.721398587168871\n",
      "Epoch 5789, Loss: 208.84125191007007, Neurons: 201, Grad norm: 7.2540734344015725\n",
      "Epoch 5789, Loss: 208.84125191007007, Neurons: 201, Grad norm: 7.2540734344015725\n",
      "Epoch 5790, Loss: 208.8413005581794, Neurons: 201, Grad norm: 7.459319175922244\n",
      "Epoch 5790, Loss: 208.8413005581794, Neurons: 201, Grad norm: 7.459319175922244\n",
      "Epoch 5791, Loss: 208.84121225846172, Neurons: 201, Grad norm: 7.2005863063468265\n",
      "Epoch 5791, Loss: 208.84121225846172, Neurons: 201, Grad norm: 7.2005863063468265\n",
      "Epoch 5792, Loss: 208.84108130006194, Neurons: 201, Grad norm: 6.203828708555792\n",
      "Epoch 5792, Loss: 208.84108130006194, Neurons: 201, Grad norm: 6.203828708555792\n",
      "Epoch 5793, Loss: 208.8408494999449, Neurons: 201, Grad norm: 4.971215640926092\n",
      "Epoch 5793, Loss: 208.8408494999449, Neurons: 201, Grad norm: 4.971215640926092\n",
      "Epoch 5794, Loss: 208.84053074185306, Neurons: 201, Grad norm: 2.7536586546341257\n",
      "Epoch 5794, Loss: 208.84053074185306, Neurons: 201, Grad norm: 2.7536586546341257\n",
      "Epoch 5795, Loss: 208.84022893267345, Neurons: 201, Grad norm: 0.9541778860543669\n",
      "Epoch 5795, Loss: 208.84022893267345, Neurons: 201, Grad norm: 0.9541778860543669\n",
      "Epoch 5796, Loss: 208.8400220090651, Neurons: 201, Grad norm: 1.3493792943736536\n",
      "Epoch 5796, Loss: 208.8400220090651, Neurons: 201, Grad norm: 1.3493792943736536\n",
      "Epoch 5797, Loss: 208.83993618775494, Neurons: 201, Grad norm: 2.9447772577681697\n",
      "Epoch 5797, Loss: 208.83993618775494, Neurons: 201, Grad norm: 2.9447772577681697\n",
      "Epoch 5798, Loss: 208.8399095759919, Neurons: 201, Grad norm: 4.560060382977442\n",
      "Epoch 5798, Loss: 208.8399095759919, Neurons: 201, Grad norm: 4.560060382977442\n",
      "Epoch 5799, Loss: 208.8399436004933, Neurons: 201, Grad norm: 5.946274716231957\n",
      "Epoch 5799, Loss: 208.8399436004933, Neurons: 201, Grad norm: 5.946274716231957\n",
      "Epoch 5800, Loss: 208.84005190821344, Neurons: 201, Grad norm: 7.189775046892891\n",
      "Epoch 5800, Loss: 208.84005190821344, Neurons: 201, Grad norm: 7.189775046892891\n",
      "Epoch 5801, Loss: 208.84011753508378, Neurons: 201, Grad norm: 7.793656053861539\n",
      "Epoch 5801, Loss: 208.84011753508378, Neurons: 201, Grad norm: 7.793656053861539\n",
      "Epoch 5802, Loss: 208.8401447778477, Neurons: 201, Grad norm: 8.368448386221562\n",
      "Epoch 5802, Loss: 208.8401447778477, Neurons: 201, Grad norm: 8.368448386221562\n",
      "Epoch 5803, Loss: 208.84007622185945, Neurons: 201, Grad norm: 7.516488762666398\n",
      "Epoch 5803, Loss: 208.84007622185945, Neurons: 201, Grad norm: 7.516488762666398\n",
      "Epoch 5804, Loss: 208.8398302305507, Neurons: 201, Grad norm: 6.779567523986703\n",
      "Epoch 5804, Loss: 208.8398302305507, Neurons: 201, Grad norm: 6.779567523986703\n",
      "Epoch 5805, Loss: 208.83952026806026, Neurons: 201, Grad norm: 4.724651363339785\n",
      "Epoch 5805, Loss: 208.83952026806026, Neurons: 201, Grad norm: 4.724651363339785\n",
      "Epoch 5806, Loss: 208.83915177164647, Neurons: 201, Grad norm: 2.881552569021395\n",
      "Epoch 5806, Loss: 208.83915177164647, Neurons: 201, Grad norm: 2.881552569021395\n",
      "Epoch 5807, Loss: 208.83876095253868, Neurons: 201, Grad norm: 0.8018820321753994\n",
      "Epoch 5807, Loss: 208.83876095253868, Neurons: 201, Grad norm: 0.8018820321753994\n",
      "Epoch 5808, Loss: 208.83848089956524, Neurons: 201, Grad norm: 1.8190861065741204\n",
      "Epoch 5808, Loss: 208.83848089956524, Neurons: 201, Grad norm: 1.8190861065741204\n",
      "Epoch 5809, Loss: 208.83834450232501, Neurons: 201, Grad norm: 3.477034704001095\n",
      "Epoch 5809, Loss: 208.83834450232501, Neurons: 201, Grad norm: 3.477034704001095\n",
      "Epoch 5810, Loss: 208.83833901084182, Neurons: 201, Grad norm: 5.304641122090552\n",
      "Epoch 5810, Loss: 208.83833901084182, Neurons: 201, Grad norm: 5.304641122090552\n",
      "Epoch 5811, Loss: 208.83842330027946, Neurons: 201, Grad norm: 7.438231250738427\n",
      "Epoch 5811, Loss: 208.83842330027946, Neurons: 201, Grad norm: 7.438231250738427\n",
      "Epoch 5812, Loss: 208.83854480596534, Neurons: 201, Grad norm: 8.80168650662602\n",
      "Epoch 5812, Loss: 208.83854480596534, Neurons: 201, Grad norm: 8.80168650662602\n",
      "Epoch 5813, Loss: 208.83866391086517, Neurons: 201, Grad norm: 10.12802704758772\n",
      "Epoch 5813, Loss: 208.83866391086517, Neurons: 201, Grad norm: 10.12802704758772\n",
      "Epoch 5814, Loss: 208.83867738024216, Neurons: 201, Grad norm: 9.951489935716955\n",
      "Epoch 5814, Loss: 208.83867738024216, Neurons: 201, Grad norm: 9.951489935716955\n",
      "Epoch 5815, Loss: 208.83861498278443, Neurons: 201, Grad norm: 9.470573243480567\n",
      "Epoch 5815, Loss: 208.83861498278443, Neurons: 201, Grad norm: 9.470573243480567\n",
      "Epoch 5816, Loss: 208.8381540165073, Neurons: 201, Grad norm: 7.676406848985853\n",
      "Epoch 5816, Loss: 208.8381540165073, Neurons: 201, Grad norm: 7.676406848985853\n",
      "Epoch 5817, Loss: 208.8376128408943, Neurons: 201, Grad norm: 5.868158011443933\n",
      "Epoch 5817, Loss: 208.8376128408943, Neurons: 201, Grad norm: 5.868158011443933\n",
      "Epoch 5818, Loss: 208.83713698637544, Neurons: 201, Grad norm: 3.0967955396857954\n",
      "Epoch 5818, Loss: 208.83713698637544, Neurons: 201, Grad norm: 3.0967955396857954\n",
      "Epoch 5819, Loss: 208.83653623637306, Neurons: 201, Grad norm: 1.119843135038343\n",
      "Epoch 5819, Loss: 208.83653623637306, Neurons: 201, Grad norm: 1.119843135038343\n",
      "Epoch 5820, Loss: 208.8360387906206, Neurons: 201, Grad norm: 2.6384678338295293\n",
      "Epoch 5820, Loss: 208.8360387906206, Neurons: 201, Grad norm: 2.6384678338295293\n",
      "Epoch 5821, Loss: 208.83585754038845, Neurons: 201, Grad norm: 4.4309857308568485\n",
      "Epoch 5821, Loss: 208.83585754038845, Neurons: 201, Grad norm: 4.4309857308568485\n",
      "Epoch 5822, Loss: 208.83582255438287, Neurons: 201, Grad norm: 6.332774567178054\n",
      "Epoch 5822, Loss: 208.83582255438287, Neurons: 201, Grad norm: 6.332774567178054\n",
      "Epoch 5823, Loss: 208.83571094533593, Neurons: 201, Grad norm: 7.560660948665162\n",
      "Epoch 5823, Loss: 208.83571094533593, Neurons: 201, Grad norm: 7.560660948665162\n",
      "Epoch 5824, Loss: 208.83550324271064, Neurons: 201, Grad norm: 8.394610915145678\n",
      "Epoch 5824, Loss: 208.83550324271064, Neurons: 201, Grad norm: 8.394610915145678\n",
      "Epoch 5825, Loss: 208.83551091902612, Neurons: 201, Grad norm: 8.65849617277123\n",
      "Epoch 5825, Loss: 208.83551091902612, Neurons: 201, Grad norm: 8.65849617277123\n",
      "Epoch 5826, Loss: 208.83548250943093, Neurons: 201, Grad norm: 8.169316828180627\n",
      "Epoch 5826, Loss: 208.83548250943093, Neurons: 201, Grad norm: 8.169316828180627\n",
      "Epoch 5827, Loss: 208.83530802928794, Neurons: 201, Grad norm: 6.95749598600166\n",
      "Epoch 5827, Loss: 208.83530802928794, Neurons: 201, Grad norm: 6.95749598600166\n",
      "Epoch 5828, Loss: 208.83499119376702, Neurons: 201, Grad norm: 5.076746759787405\n",
      "Epoch 5828, Loss: 208.83499119376702, Neurons: 201, Grad norm: 5.076746759787405\n",
      "Epoch 5829, Loss: 208.83465701281972, Neurons: 201, Grad norm: 3.137529355596431\n",
      "Epoch 5829, Loss: 208.83465701281972, Neurons: 201, Grad norm: 3.137529355596431\n",
      "Epoch 5830, Loss: 208.8343348427892, Neurons: 201, Grad norm: 1.0812697908153919\n",
      "Epoch 5830, Loss: 208.8343348427892, Neurons: 201, Grad norm: 1.0812697908153919\n",
      "Epoch 5831, Loss: 208.83405747660066, Neurons: 201, Grad norm: 1.2086138434164002\n",
      "Epoch 5831, Loss: 208.83405747660066, Neurons: 201, Grad norm: 1.2086138434164002\n",
      "Epoch 5832, Loss: 208.8339261757763, Neurons: 201, Grad norm: 2.8390254944531925\n",
      "Epoch 5832, Loss: 208.8339261757763, Neurons: 201, Grad norm: 2.8390254944531925\n",
      "Epoch 5833, Loss: 208.83393661985772, Neurons: 201, Grad norm: 4.578193854570303\n",
      "Epoch 5833, Loss: 208.83393661985772, Neurons: 201, Grad norm: 4.578193854570303\n",
      "Epoch 5834, Loss: 208.8340969914219, Neurons: 201, Grad norm: 6.237283427498586\n",
      "Epoch 5834, Loss: 208.8340969914219, Neurons: 201, Grad norm: 6.237283427498586\n",
      "Epoch 5835, Loss: 208.83425308272956, Neurons: 201, Grad norm: 7.814041241634343\n",
      "Epoch 5835, Loss: 208.83425308272956, Neurons: 201, Grad norm: 7.814041241634343\n",
      "Epoch 5836, Loss: 208.83435779108711, Neurons: 201, Grad norm: 9.041261073389338\n",
      "Epoch 5836, Loss: 208.83435779108711, Neurons: 201, Grad norm: 9.041261073389338\n",
      "Epoch 5837, Loss: 208.83458547625656, Neurons: 201, Grad norm: 9.133433293802165\n",
      "Epoch 5837, Loss: 208.83458547625656, Neurons: 201, Grad norm: 9.133433293802165\n",
      "Epoch 5838, Loss: 208.83452498354347, Neurons: 201, Grad norm: 8.625451144703165\n",
      "Epoch 5838, Loss: 208.83452498354347, Neurons: 201, Grad norm: 8.625451144703165\n",
      "Epoch 5839, Loss: 208.83427921359382, Neurons: 201, Grad norm: 6.933976121942184\n",
      "Epoch 5839, Loss: 208.83427921359382, Neurons: 201, Grad norm: 6.933976121942184\n",
      "Epoch 5840, Loss: 208.83396034943306, Neurons: 201, Grad norm: 4.687131714233142\n",
      "Epoch 5840, Loss: 208.83396034943306, Neurons: 201, Grad norm: 4.687131714233142\n",
      "Epoch 5841, Loss: 208.83345811465034, Neurons: 201, Grad norm: 2.1466173314747476\n",
      "Epoch 5841, Loss: 208.83345811465034, Neurons: 201, Grad norm: 2.1466173314747476\n",
      "Epoch 5842, Loss: 208.83304987375402, Neurons: 201, Grad norm: 0.9363820642248347\n",
      "Epoch 5842, Loss: 208.83304987375402, Neurons: 201, Grad norm: 0.9363820642248347\n",
      "Epoch 5843, Loss: 208.8329176436354, Neurons: 201, Grad norm: 2.9957604693361906\n",
      "Epoch 5843, Loss: 208.8329176436354, Neurons: 201, Grad norm: 2.9957604693361906\n",
      "Epoch 5844, Loss: 208.83300019783658, Neurons: 201, Grad norm: 4.988633510016967\n",
      "Epoch 5844, Loss: 208.83300019783658, Neurons: 201, Grad norm: 4.988633510016967\n",
      "Epoch 5845, Loss: 208.83308626999292, Neurons: 201, Grad norm: 6.411473832079665\n",
      "Epoch 5845, Loss: 208.83308626999292, Neurons: 201, Grad norm: 6.411473832079665\n",
      "Epoch 5846, Loss: 208.8331777437179, Neurons: 201, Grad norm: 7.729232261125576\n",
      "Epoch 5846, Loss: 208.8331777437179, Neurons: 201, Grad norm: 7.729232261125576\n",
      "Epoch 5847, Loss: 208.83325977704908, Neurons: 201, Grad norm: 7.821096819157155\n",
      "Epoch 5847, Loss: 208.83325977704908, Neurons: 201, Grad norm: 7.821096819157155\n",
      "Epoch 5848, Loss: 208.83323843879705, Neurons: 201, Grad norm: 7.6099468837160344\n",
      "Epoch 5848, Loss: 208.83323843879705, Neurons: 201, Grad norm: 7.6099468837160344\n",
      "Epoch 5849, Loss: 208.83303053358975, Neurons: 201, Grad norm: 6.698651246709666\n",
      "Epoch 5849, Loss: 208.83303053358975, Neurons: 201, Grad norm: 6.698651246709666\n",
      "Epoch 5850, Loss: 208.83276087803705, Neurons: 201, Grad norm: 5.810437529109275\n",
      "Epoch 5850, Loss: 208.83276087803705, Neurons: 201, Grad norm: 5.810437529109275\n",
      "Epoch 5851, Loss: 208.8325028617783, Neurons: 201, Grad norm: 4.477727846261479\n",
      "Epoch 5851, Loss: 208.8325028617783, Neurons: 201, Grad norm: 4.477727846261479\n",
      "Epoch 5852, Loss: 208.83226980161956, Neurons: 201, Grad norm: 3.220616047734832\n",
      "Epoch 5852, Loss: 208.83226980161956, Neurons: 201, Grad norm: 3.220616047734832\n",
      "Epoch 5853, Loss: 208.83207311301967, Neurons: 201, Grad norm: 1.6932307483367866\n",
      "Epoch 5853, Loss: 208.83207311301967, Neurons: 201, Grad norm: 1.6932307483367866\n",
      "Epoch 5854, Loss: 208.831845352697, Neurons: 201, Grad norm: 0.5223272591785287\n",
      "Epoch 5854, Loss: 208.831845352697, Neurons: 201, Grad norm: 0.5223272591785287\n",
      "Epoch 5855, Loss: 208.83169742405892, Neurons: 201, Grad norm: 0.9849091078971668\n",
      "Epoch 5855, Loss: 208.83169742405892, Neurons: 201, Grad norm: 0.9849091078971668\n",
      "Epoch 5856, Loss: 208.83161348988946, Neurons: 201, Grad norm: 1.9109563514865529\n",
      "Epoch 5856, Loss: 208.83161348988946, Neurons: 201, Grad norm: 1.9109563514865529\n",
      "Epoch 5857, Loss: 208.83154151628102, Neurons: 201, Grad norm: 2.6607504284342105\n",
      "Epoch 5857, Loss: 208.83154151628102, Neurons: 201, Grad norm: 2.6607504284342105\n",
      "Epoch 5858, Loss: 208.83148744699247, Neurons: 201, Grad norm: 3.2343644602432198\n",
      "Epoch 5858, Loss: 208.83148744699247, Neurons: 201, Grad norm: 3.2343644602432198\n",
      "Epoch 5859, Loss: 208.83142281082613, Neurons: 201, Grad norm: 4.067444031734594\n",
      "Epoch 5859, Loss: 208.83142281082613, Neurons: 201, Grad norm: 4.067444031734594\n",
      "Epoch 5860, Loss: 208.831397992872, Neurons: 201, Grad norm: 5.090769738706739\n",
      "Epoch 5860, Loss: 208.831397992872, Neurons: 201, Grad norm: 5.090769738706739\n",
      "Epoch 5861, Loss: 208.83140866022882, Neurons: 201, Grad norm: 5.818987926933269\n",
      "Epoch 5861, Loss: 208.83140866022882, Neurons: 201, Grad norm: 5.818987926933269\n",
      "Epoch 5862, Loss: 208.83147992553435, Neurons: 201, Grad norm: 6.889242771641998\n",
      "Epoch 5862, Loss: 208.83147992553435, Neurons: 201, Grad norm: 6.889242771641998\n",
      "Epoch 5863, Loss: 208.83149680748784, Neurons: 201, Grad norm: 7.273379672553511\n",
      "Epoch 5863, Loss: 208.83149680748784, Neurons: 201, Grad norm: 7.273379672553511\n",
      "Epoch 5864, Loss: 208.83148355596893, Neurons: 201, Grad norm: 7.0159571051162475\n",
      "Epoch 5864, Loss: 208.83148355596893, Neurons: 201, Grad norm: 7.0159571051162475\n",
      "Epoch 5865, Loss: 208.83136738658004, Neurons: 201, Grad norm: 6.238376498581732\n",
      "Epoch 5865, Loss: 208.83136738658004, Neurons: 201, Grad norm: 6.238376498581732\n",
      "Epoch 5866, Loss: 208.83115926018579, Neurons: 201, Grad norm: 4.80386884141599\n",
      "Epoch 5866, Loss: 208.83115926018579, Neurons: 201, Grad norm: 4.80386884141599\n",
      "Epoch 5867, Loss: 208.83085437840944, Neurons: 201, Grad norm: 3.1227386728553084\n",
      "Epoch 5867, Loss: 208.83085437840944, Neurons: 201, Grad norm: 3.1227386728553084\n",
      "Epoch 5868, Loss: 208.83056741726296, Neurons: 201, Grad norm: 1.450080657761493\n",
      "Epoch 5868, Loss: 208.83056741726296, Neurons: 201, Grad norm: 1.450080657761493\n",
      "Epoch 5869, Loss: 208.83036685770165, Neurons: 201, Grad norm: 0.5204557714060118\n",
      "Epoch 5869, Loss: 208.83036685770165, Neurons: 201, Grad norm: 0.5204557714060118\n",
      "Epoch 5870, Loss: 208.830242658758, Neurons: 201, Grad norm: 1.3789653764372058\n",
      "Epoch 5870, Loss: 208.830242658758, Neurons: 201, Grad norm: 1.3789653764372058\n",
      "Epoch 5871, Loss: 208.8301903687586, Neurons: 201, Grad norm: 2.181126108321596\n",
      "Epoch 5871, Loss: 208.8301903687586, Neurons: 201, Grad norm: 2.181126108321596\n",
      "Epoch 5872, Loss: 208.83012326539125, Neurons: 201, Grad norm: 2.9834123813313074\n",
      "Epoch 5872, Loss: 208.83012326539125, Neurons: 201, Grad norm: 2.9834123813313074\n",
      "Epoch 5873, Loss: 208.8300707168016, Neurons: 201, Grad norm: 3.8380178515765926\n",
      "Epoch 5873, Loss: 208.8300707168016, Neurons: 201, Grad norm: 3.8380178515765926\n",
      "Epoch 5874, Loss: 208.83003590226255, Neurons: 201, Grad norm: 4.28681433744531\n",
      "Epoch 5874, Loss: 208.83003590226255, Neurons: 201, Grad norm: 4.28681433744531\n",
      "Epoch 5875, Loss: 208.83003146317705, Neurons: 201, Grad norm: 4.478813149799579\n",
      "Epoch 5875, Loss: 208.83003146317705, Neurons: 201, Grad norm: 4.478813149799579\n",
      "Epoch 5876, Loss: 208.82998724232147, Neurons: 201, Grad norm: 4.756022838107253\n",
      "Epoch 5876, Loss: 208.82998724232147, Neurons: 201, Grad norm: 4.756022838107253\n",
      "Epoch 5877, Loss: 208.82990881029664, Neurons: 201, Grad norm: 4.440722461803131\n",
      "Epoch 5877, Loss: 208.82990881029664, Neurons: 201, Grad norm: 4.440722461803131\n",
      "Epoch 5878, Loss: 208.8297996447104, Neurons: 201, Grad norm: 4.733249126088376\n",
      "Epoch 5878, Loss: 208.8297996447104, Neurons: 201, Grad norm: 4.733249126088376\n",
      "Epoch 5879, Loss: 208.8297197947285, Neurons: 201, Grad norm: 4.685852315550272\n",
      "Epoch 5879, Loss: 208.8297197947285, Neurons: 201, Grad norm: 4.685852315550272\n",
      "Epoch 5880, Loss: 208.82961828094005, Neurons: 201, Grad norm: 4.823872657315218\n",
      "Epoch 5880, Loss: 208.82961828094005, Neurons: 201, Grad norm: 4.823872657315218\n",
      "Epoch 5881, Loss: 208.82955837445743, Neurons: 201, Grad norm: 5.013312098927749\n",
      "Epoch 5881, Loss: 208.82955837445743, Neurons: 201, Grad norm: 5.013312098927749\n",
      "Epoch 5882, Loss: 208.829496888068, Neurons: 201, Grad norm: 4.831287879431068\n",
      "Epoch 5882, Loss: 208.829496888068, Neurons: 201, Grad norm: 4.831287879431068\n",
      "Epoch 5883, Loss: 208.82937514505068, Neurons: 201, Grad norm: 5.030220506488495\n",
      "Epoch 5883, Loss: 208.82937514505068, Neurons: 201, Grad norm: 5.030220506488495\n",
      "Epoch 5884, Loss: 208.8292865567833, Neurons: 201, Grad norm: 5.437111100470199\n",
      "Epoch 5884, Loss: 208.8292865567833, Neurons: 201, Grad norm: 5.437111100470199\n",
      "Epoch 5885, Loss: 208.82924501060924, Neurons: 201, Grad norm: 5.700101836228624\n",
      "Epoch 5885, Loss: 208.82924501060924, Neurons: 201, Grad norm: 5.700101836228624\n",
      "Epoch 5886, Loss: 208.82923535565112, Neurons: 201, Grad norm: 6.006635778123186\n",
      "Epoch 5886, Loss: 208.82923535565112, Neurons: 201, Grad norm: 6.006635778123186\n",
      "Epoch 5887, Loss: 208.8291933526551, Neurons: 201, Grad norm: 5.801137868050899\n",
      "Epoch 5887, Loss: 208.8291933526551, Neurons: 201, Grad norm: 5.801137868050899\n",
      "Epoch 5888, Loss: 208.82914876253082, Neurons: 201, Grad norm: 5.8545076038477\n",
      "Epoch 5888, Loss: 208.82914876253082, Neurons: 201, Grad norm: 5.8545076038477\n",
      "Epoch 5889, Loss: 208.82914376979997, Neurons: 201, Grad norm: 5.492299903406706\n",
      "Epoch 5889, Loss: 208.82914376979997, Neurons: 201, Grad norm: 5.492299903406706\n",
      "Epoch 5890, Loss: 208.82895450163758, Neurons: 201, Grad norm: 5.091729680178953\n",
      "Epoch 5890, Loss: 208.82895450163758, Neurons: 201, Grad norm: 5.091729680178953\n",
      "Epoch 5891, Loss: 208.82874053000916, Neurons: 201, Grad norm: 4.575201099835447\n",
      "Epoch 5891, Loss: 208.82874053000916, Neurons: 201, Grad norm: 4.575201099835447\n",
      "Epoch 5892, Loss: 208.82853468565247, Neurons: 201, Grad norm: 4.191296656781756\n",
      "Epoch 5892, Loss: 208.82853468565247, Neurons: 201, Grad norm: 4.191296656781756\n",
      "Epoch 5893, Loss: 208.8284526231672, Neurons: 201, Grad norm: 3.8966034471010533\n",
      "Epoch 5893, Loss: 208.8284526231672, Neurons: 201, Grad norm: 3.8966034471010533\n",
      "Epoch 5894, Loss: 208.82835765620683, Neurons: 201, Grad norm: 3.6701807213664357\n",
      "Epoch 5894, Loss: 208.82835765620683, Neurons: 201, Grad norm: 3.6701807213664357\n",
      "Epoch 5895, Loss: 208.82823078612034, Neurons: 201, Grad norm: 3.510439917272437\n",
      "Epoch 5895, Loss: 208.82823078612034, Neurons: 201, Grad norm: 3.510439917272437\n",
      "Epoch 5896, Loss: 208.82809734136725, Neurons: 201, Grad norm: 3.3978657095017892\n",
      "Epoch 5896, Loss: 208.82809734136725, Neurons: 201, Grad norm: 3.3978657095017892\n",
      "Epoch 5897, Loss: 208.82799029093889, Neurons: 201, Grad norm: 3.4913043876038015\n",
      "Epoch 5897, Loss: 208.82799029093889, Neurons: 201, Grad norm: 3.4913043876038015\n",
      "Epoch 5898, Loss: 208.82790546908464, Neurons: 201, Grad norm: 3.7832053361315863\n",
      "Epoch 5898, Loss: 208.82790546908464, Neurons: 201, Grad norm: 3.7832053361315863\n",
      "Epoch 5899, Loss: 208.82784948394402, Neurons: 201, Grad norm: 4.144156142870369\n",
      "Epoch 5899, Loss: 208.82784948394402, Neurons: 201, Grad norm: 4.144156142870369\n",
      "Epoch 5900, Loss: 208.82781649912278, Neurons: 201, Grad norm: 5.068161381905614\n",
      "Epoch 5900, Loss: 208.82781649912278, Neurons: 201, Grad norm: 5.068161381905614\n",
      "Epoch 5901, Loss: 208.82781538448015, Neurons: 201, Grad norm: 6.075336026807639\n",
      "Epoch 5901, Loss: 208.82781538448015, Neurons: 201, Grad norm: 6.075336026807639\n",
      "Epoch 5902, Loss: 208.82785999350608, Neurons: 201, Grad norm: 7.440560396929634\n",
      "Epoch 5902, Loss: 208.82785999350608, Neurons: 201, Grad norm: 7.440560396929634\n",
      "Epoch 5903, Loss: 208.82805777820877, Neurons: 201, Grad norm: 8.929724893885862\n",
      "Epoch 5903, Loss: 208.82805777820877, Neurons: 201, Grad norm: 8.929724893885862\n",
      "Epoch 5904, Loss: 208.82835269054544, Neurons: 201, Grad norm: 10.193769560264167\n",
      "Epoch 5904, Loss: 208.82835269054544, Neurons: 201, Grad norm: 10.193769560264167\n",
      "Epoch 5905, Loss: 208.82862606910652, Neurons: 201, Grad norm: 11.14582449776315\n",
      "Epoch 5905, Loss: 208.82862606910652, Neurons: 201, Grad norm: 11.14582449776315\n",
      "Epoch 5906, Loss: 208.82871827912027, Neurons: 201, Grad norm: 10.995546848034587\n",
      "Epoch 5906, Loss: 208.82871827912027, Neurons: 201, Grad norm: 10.995546848034587\n",
      "Epoch 5907, Loss: 208.8285670801727, Neurons: 201, Grad norm: 9.926900130618346\n",
      "Epoch 5907, Loss: 208.8285670801727, Neurons: 201, Grad norm: 9.926900130618346\n",
      "Epoch 5908, Loss: 208.82822986326494, Neurons: 201, Grad norm: 8.012908505033101\n",
      "Epoch 5908, Loss: 208.82822986326494, Neurons: 201, Grad norm: 8.012908505033101\n",
      "Epoch 5909, Loss: 208.82764429321048, Neurons: 201, Grad norm: 4.994068036936431\n",
      "Epoch 5909, Loss: 208.82764429321048, Neurons: 201, Grad norm: 4.994068036936431\n",
      "Epoch 5910, Loss: 208.82708455994637, Neurons: 201, Grad norm: 2.359131016551583\n",
      "Epoch 5910, Loss: 208.82708455994637, Neurons: 201, Grad norm: 2.359131016551583\n",
      "Epoch 5911, Loss: 208.82677187416127, Neurons: 201, Grad norm: 0.7521593648965852\n",
      "Epoch 5911, Loss: 208.82677187416127, Neurons: 201, Grad norm: 0.7521593648965852\n",
      "Epoch 5912, Loss: 208.82660310448432, Neurons: 201, Grad norm: 3.1791020911054164\n",
      "Epoch 5912, Loss: 208.82660310448432, Neurons: 201, Grad norm: 3.1791020911054164\n",
      "Epoch 5913, Loss: 208.82663813122306, Neurons: 201, Grad norm: 5.749548516595986\n",
      "Epoch 5913, Loss: 208.82663813122306, Neurons: 201, Grad norm: 5.749548516595986\n",
      "Epoch 5914, Loss: 208.82682463138752, Neurons: 201, Grad norm: 8.055721195787834\n",
      "Epoch 5914, Loss: 208.82682463138752, Neurons: 201, Grad norm: 8.055721195787834\n",
      "Epoch 5915, Loss: 208.8271309763188, Neurons: 201, Grad norm: 10.013472288429421\n",
      "Epoch 5915, Loss: 208.8271309763188, Neurons: 201, Grad norm: 10.013472288429421\n",
      "Epoch 5916, Loss: 208.8275045395248, Neurons: 201, Grad norm: 10.984108338550476\n",
      "Epoch 5916, Loss: 208.8275045395248, Neurons: 201, Grad norm: 10.984108338550476\n",
      "Epoch 5917, Loss: 208.82776388525073, Neurons: 201, Grad norm: 11.506978294425917\n",
      "Epoch 5917, Loss: 208.82776388525073, Neurons: 201, Grad norm: 11.506978294425917\n",
      "Epoch 5918, Loss: 208.82780359037528, Neurons: 201, Grad norm: 10.954954592720341\n",
      "Epoch 5918, Loss: 208.82780359037528, Neurons: 201, Grad norm: 10.954954592720341\n",
      "Epoch 5919, Loss: 208.82755590203666, Neurons: 201, Grad norm: 9.63765463365507\n",
      "Epoch 5919, Loss: 208.82755590203666, Neurons: 201, Grad norm: 9.63765463365507\n",
      "Epoch 5920, Loss: 208.8272110190684, Neurons: 201, Grad norm: 7.644107454719217\n",
      "Epoch 5920, Loss: 208.8272110190684, Neurons: 201, Grad norm: 7.644107454719217\n",
      "Epoch 5921, Loss: 208.8266597116745, Neurons: 201, Grad norm: 5.111627695865223\n",
      "Epoch 5921, Loss: 208.8266597116745, Neurons: 201, Grad norm: 5.111627695865223\n",
      "Epoch 5922, Loss: 208.82610701560776, Neurons: 201, Grad norm: 2.285925737448393\n",
      "Epoch 5922, Loss: 208.82610701560776, Neurons: 201, Grad norm: 2.285925737448393\n",
      "Epoch 5923, Loss: 208.8257863505736, Neurons: 201, Grad norm: 0.8106555780900174\n",
      "Epoch 5923, Loss: 208.8257863505736, Neurons: 201, Grad norm: 0.8106555780900174\n",
      "Epoch 5924, Loss: 208.82565144292428, Neurons: 201, Grad norm: 3.2870922476934554\n",
      "Epoch 5924, Loss: 208.82565144292428, Neurons: 201, Grad norm: 3.2870922476934554\n",
      "Epoch 5925, Loss: 208.82566746300768, Neurons: 201, Grad norm: 5.79233630868783\n",
      "Epoch 5925, Loss: 208.82566746300768, Neurons: 201, Grad norm: 5.79233630868783\n",
      "Epoch 5926, Loss: 208.8258334238019, Neurons: 201, Grad norm: 7.997556083954607\n",
      "Epoch 5926, Loss: 208.8258334238019, Neurons: 201, Grad norm: 7.997556083954607\n",
      "Epoch 5927, Loss: 208.82615247113335, Neurons: 201, Grad norm: 9.571069131868144\n",
      "Epoch 5927, Loss: 208.82615247113335, Neurons: 201, Grad norm: 9.571069131868144\n",
      "Epoch 5928, Loss: 208.82642478890855, Neurons: 201, Grad norm: 10.527083492467796\n",
      "Epoch 5928, Loss: 208.82642478890855, Neurons: 201, Grad norm: 10.527083492467796\n",
      "Epoch 5929, Loss: 208.82656917257432, Neurons: 201, Grad norm: 10.60351087117507\n",
      "Epoch 5929, Loss: 208.82656917257432, Neurons: 201, Grad norm: 10.60351087117507\n",
      "Epoch 5930, Loss: 208.82656997386533, Neurons: 201, Grad norm: 9.967376221771378\n",
      "Epoch 5930, Loss: 208.82656997386533, Neurons: 201, Grad norm: 9.967376221771378\n",
      "Epoch 5931, Loss: 208.82632127600112, Neurons: 201, Grad norm: 8.453734446980171\n",
      "Epoch 5931, Loss: 208.82632127600112, Neurons: 201, Grad norm: 8.453734446980171\n",
      "Epoch 5932, Loss: 208.82602483086694, Neurons: 201, Grad norm: 6.48667876469228\n",
      "Epoch 5932, Loss: 208.82602483086694, Neurons: 201, Grad norm: 6.48667876469228\n",
      "Epoch 5933, Loss: 208.8255289068418, Neurons: 201, Grad norm: 3.818809859865421\n",
      "Epoch 5933, Loss: 208.8255289068418, Neurons: 201, Grad norm: 3.818809859865421\n",
      "Epoch 5934, Loss: 208.82499686671807, Neurons: 201, Grad norm: 1.3940743970686573\n",
      "Epoch 5934, Loss: 208.82499686671807, Neurons: 201, Grad norm: 1.3940743970686573\n",
      "Epoch 5935, Loss: 208.82480361892564, Neurons: 201, Grad norm: 2.0526970180580255\n",
      "Epoch 5935, Loss: 208.82480361892564, Neurons: 201, Grad norm: 2.0526970180580255\n",
      "Epoch 5936, Loss: 208.82483734976717, Neurons: 201, Grad norm: 4.4542860226489225\n",
      "Epoch 5936, Loss: 208.82483734976717, Neurons: 201, Grad norm: 4.4542860226489225\n",
      "Epoch 5937, Loss: 208.82484199629738, Neurons: 201, Grad norm: 6.470419961331601\n",
      "Epoch 5937, Loss: 208.82484199629738, Neurons: 201, Grad norm: 6.470419961331601\n",
      "Epoch 5938, Loss: 208.82498365446983, Neurons: 201, Grad norm: 7.923648116252101\n",
      "Epoch 5938, Loss: 208.82498365446983, Neurons: 201, Grad norm: 7.923648116252101\n",
      "Epoch 5939, Loss: 208.82517541415984, Neurons: 201, Grad norm: 9.32174331395535\n",
      "Epoch 5939, Loss: 208.82517541415984, Neurons: 201, Grad norm: 9.32174331395535\n",
      "Epoch 5940, Loss: 208.82539508836052, Neurons: 201, Grad norm: 9.45207138421408\n",
      "Epoch 5940, Loss: 208.82539508836052, Neurons: 201, Grad norm: 9.45207138421408\n",
      "Epoch 5941, Loss: 208.8253367399889, Neurons: 201, Grad norm: 9.18106403657992\n",
      "Epoch 5941, Loss: 208.8253367399889, Neurons: 201, Grad norm: 9.18106403657992\n",
      "Epoch 5942, Loss: 208.82523000631036, Neurons: 201, Grad norm: 7.986303999361514\n",
      "Epoch 5942, Loss: 208.82523000631036, Neurons: 201, Grad norm: 7.986303999361514\n",
      "Epoch 5943, Loss: 208.82493716657135, Neurons: 201, Grad norm: 6.1125829023860465\n",
      "Epoch 5943, Loss: 208.82493716657135, Neurons: 201, Grad norm: 6.1125829023860465\n",
      "Epoch 5944, Loss: 208.8244972917327, Neurons: 201, Grad norm: 3.3052816394863695\n",
      "Epoch 5944, Loss: 208.8244972917327, Neurons: 201, Grad norm: 3.3052816394863695\n",
      "Epoch 5945, Loss: 208.82411517496686, Neurons: 201, Grad norm: 0.7863406364674099\n",
      "Epoch 5945, Loss: 208.82411517496686, Neurons: 201, Grad norm: 0.7863406364674099\n",
      "Epoch 5946, Loss: 208.82385083863946, Neurons: 201, Grad norm: 1.9740609033255114\n",
      "Epoch 5946, Loss: 208.82385083863946, Neurons: 201, Grad norm: 1.9740609033255114\n",
      "Epoch 5947, Loss: 208.82378724465087, Neurons: 201, Grad norm: 4.452260602072316\n",
      "Epoch 5947, Loss: 208.82378724465087, Neurons: 201, Grad norm: 4.452260602072316\n",
      "Epoch 5948, Loss: 208.8238716609492, Neurons: 201, Grad norm: 6.258825322019815\n",
      "Epoch 5948, Loss: 208.8238716609492, Neurons: 201, Grad norm: 6.258825322019815\n",
      "Epoch 5949, Loss: 208.82408452039823, Neurons: 201, Grad norm: 8.07367160926318\n",
      "Epoch 5949, Loss: 208.82408452039823, Neurons: 201, Grad norm: 8.07367160926318\n",
      "Epoch 5950, Loss: 208.82428642117165, Neurons: 201, Grad norm: 9.233051500834438\n",
      "Epoch 5950, Loss: 208.82428642117165, Neurons: 201, Grad norm: 9.233051500834438\n",
      "Epoch 5951, Loss: 208.82447424986617, Neurons: 201, Grad norm: 9.486800607755738\n",
      "Epoch 5951, Loss: 208.82447424986617, Neurons: 201, Grad norm: 9.486800607755738\n",
      "Epoch 5952, Loss: 208.82456673365684, Neurons: 201, Grad norm: 9.673491678638166\n",
      "Epoch 5952, Loss: 208.82456673365684, Neurons: 201, Grad norm: 9.673491678638166\n",
      "Epoch 5953, Loss: 208.82446130102576, Neurons: 201, Grad norm: 8.536327500292124\n",
      "Epoch 5953, Loss: 208.82446130102576, Neurons: 201, Grad norm: 8.536327500292124\n",
      "Epoch 5954, Loss: 208.82424567757164, Neurons: 201, Grad norm: 7.208519454115379\n",
      "Epoch 5954, Loss: 208.82424567757164, Neurons: 201, Grad norm: 7.208519454115379\n",
      "Epoch 5955, Loss: 208.82390672201817, Neurons: 201, Grad norm: 4.867103296796676\n",
      "Epoch 5955, Loss: 208.82390672201817, Neurons: 201, Grad norm: 4.867103296796676\n",
      "Epoch 5956, Loss: 208.82339670209268, Neurons: 201, Grad norm: 2.235672160134591\n",
      "Epoch 5956, Loss: 208.82339670209268, Neurons: 201, Grad norm: 2.235672160134591\n",
      "Epoch 5957, Loss: 208.82303237216942, Neurons: 201, Grad norm: 0.9101385914951962\n",
      "Epoch 5957, Loss: 208.82303237216942, Neurons: 201, Grad norm: 0.9101385914951962\n",
      "Epoch 5958, Loss: 208.8229034129454, Neurons: 201, Grad norm: 3.1543499252339195\n",
      "Epoch 5958, Loss: 208.8229034129454, Neurons: 201, Grad norm: 3.1543499252339195\n",
      "Epoch 5959, Loss: 208.8230014995746, Neurons: 201, Grad norm: 4.897074378508919\n",
      "Epoch 5959, Loss: 208.8230014995746, Neurons: 201, Grad norm: 4.897074378508919\n",
      "Epoch 5960, Loss: 208.8231129214046, Neurons: 201, Grad norm: 6.24288508983633\n",
      "Epoch 5960, Loss: 208.8231129214046, Neurons: 201, Grad norm: 6.24288508983633\n",
      "Epoch 5961, Loss: 208.82312292767122, Neurons: 201, Grad norm: 7.0136172006978805\n",
      "Epoch 5961, Loss: 208.82312292767122, Neurons: 201, Grad norm: 7.0136172006978805\n",
      "Epoch 5962, Loss: 208.8231821161364, Neurons: 201, Grad norm: 6.905983510717019\n",
      "Epoch 5962, Loss: 208.8231821161364, Neurons: 201, Grad norm: 6.905983510717019\n",
      "Epoch 5963, Loss: 208.8231280817701, Neurons: 201, Grad norm: 6.319207216764079\n",
      "Epoch 5963, Loss: 208.8231280817701, Neurons: 201, Grad norm: 6.319207216764079\n",
      "Epoch 5964, Loss: 208.82291996522343, Neurons: 201, Grad norm: 4.87258995965545\n",
      "Epoch 5964, Loss: 208.82291996522343, Neurons: 201, Grad norm: 4.87258995965545\n",
      "Epoch 5965, Loss: 208.8226373669452, Neurons: 201, Grad norm: 3.5675775806673604\n",
      "Epoch 5965, Loss: 208.8226373669452, Neurons: 201, Grad norm: 3.5675775806673604\n",
      "Epoch 5966, Loss: 208.82245220766697, Neurons: 201, Grad norm: 2.2532914508735202\n",
      "Epoch 5966, Loss: 208.82245220766697, Neurons: 201, Grad norm: 2.2532914508735202\n",
      "Epoch 5967, Loss: 208.82228612483235, Neurons: 201, Grad norm: 1.158599542093652\n",
      "Epoch 5967, Loss: 208.82228612483235, Neurons: 201, Grad norm: 1.158599542093652\n",
      "Epoch 5968, Loss: 208.8221555434716, Neurons: 201, Grad norm: 0.913773638124674\n",
      "Epoch 5968, Loss: 208.8221555434716, Neurons: 201, Grad norm: 0.913773638124674\n",
      "Epoch 5969, Loss: 208.82207193762042, Neurons: 201, Grad norm: 1.8284216831201896\n",
      "Epoch 5969, Loss: 208.82207193762042, Neurons: 201, Grad norm: 1.8284216831201896\n",
      "Epoch 5970, Loss: 208.82199014656334, Neurons: 201, Grad norm: 2.939024701922347\n",
      "Epoch 5970, Loss: 208.82199014656334, Neurons: 201, Grad norm: 2.939024701922347\n",
      "Epoch 5971, Loss: 208.821947961446, Neurons: 201, Grad norm: 4.283210022965592\n",
      "Epoch 5971, Loss: 208.821947961446, Neurons: 201, Grad norm: 4.283210022965592\n",
      "Epoch 5972, Loss: 208.82203044818422, Neurons: 201, Grad norm: 5.905002949894433\n",
      "Epoch 5972, Loss: 208.82203044818422, Neurons: 201, Grad norm: 5.905002949894433\n",
      "Epoch 5973, Loss: 208.8222390811949, Neurons: 201, Grad norm: 7.3280095713556355\n",
      "Epoch 5973, Loss: 208.8222390811949, Neurons: 201, Grad norm: 7.3280095713556355\n",
      "Epoch 5974, Loss: 208.8224712767109, Neurons: 201, Grad norm: 8.734698812841836\n",
      "Epoch 5974, Loss: 208.8224712767109, Neurons: 201, Grad norm: 8.734698812841836\n",
      "Epoch 5975, Loss: 208.82258957874305, Neurons: 201, Grad norm: 9.458378006493348\n",
      "Epoch 5975, Loss: 208.82258957874305, Neurons: 201, Grad norm: 9.458378006493348\n",
      "Epoch 5976, Loss: 208.8226162383958, Neurons: 201, Grad norm: 9.50174466943455\n",
      "Epoch 5976, Loss: 208.8226162383958, Neurons: 201, Grad norm: 9.50174466943455\n",
      "Epoch 5977, Loss: 208.82263716864145, Neurons: 201, Grad norm: 8.571555409008708\n",
      "Epoch 5977, Loss: 208.82263716864145, Neurons: 201, Grad norm: 8.571555409008708\n",
      "Epoch 5978, Loss: 208.8223563665925, Neurons: 201, Grad norm: 6.4955735490363535\n",
      "Epoch 5978, Loss: 208.8223563665925, Neurons: 201, Grad norm: 6.4955735490363535\n",
      "Epoch 5979, Loss: 208.82187116294102, Neurons: 201, Grad norm: 3.429509043327817\n",
      "Epoch 5979, Loss: 208.82187116294102, Neurons: 201, Grad norm: 3.429509043327817\n",
      "Epoch 5980, Loss: 208.82145852013556, Neurons: 201, Grad norm: 1.1122654422563412\n",
      "Epoch 5980, Loss: 208.82145852013556, Neurons: 201, Grad norm: 1.1122654422563412\n",
      "Epoch 5981, Loss: 208.82130855578208, Neurons: 201, Grad norm: 2.4782548728772777\n",
      "Epoch 5981, Loss: 208.82130855578208, Neurons: 201, Grad norm: 2.4782548728772777\n",
      "Epoch 5982, Loss: 208.8212106965889, Neurons: 201, Grad norm: 4.416020062086184\n",
      "Epoch 5982, Loss: 208.8212106965889, Neurons: 201, Grad norm: 4.416020062086184\n",
      "Epoch 5983, Loss: 208.82120422624672, Neurons: 201, Grad norm: 5.974558758655798\n",
      "Epoch 5983, Loss: 208.82120422624672, Neurons: 201, Grad norm: 5.974558758655798\n",
      "Epoch 5984, Loss: 208.8213479971016, Neurons: 201, Grad norm: 7.062584661083179\n",
      "Epoch 5984, Loss: 208.8213479971016, Neurons: 201, Grad norm: 7.062584661083179\n",
      "Epoch 5985, Loss: 208.82150503403955, Neurons: 201, Grad norm: 7.872086876970709\n",
      "Epoch 5985, Loss: 208.82150503403955, Neurons: 201, Grad norm: 7.872086876970709\n",
      "Epoch 5986, Loss: 208.82155807930152, Neurons: 201, Grad norm: 8.248446552204571\n",
      "Epoch 5986, Loss: 208.82155807930152, Neurons: 201, Grad norm: 8.248446552204571\n",
      "Epoch 5987, Loss: 208.82153183747428, Neurons: 201, Grad norm: 8.293229299944079\n",
      "Epoch 5987, Loss: 208.82153183747428, Neurons: 201, Grad norm: 8.293229299944079\n",
      "Epoch 5988, Loss: 208.82148269782502, Neurons: 201, Grad norm: 7.774266402794324\n",
      "Epoch 5988, Loss: 208.82148269782502, Neurons: 201, Grad norm: 7.774266402794324\n",
      "Epoch 5989, Loss: 208.82122491995682, Neurons: 201, Grad norm: 6.74136291614696\n",
      "Epoch 5989, Loss: 208.82122491995682, Neurons: 201, Grad norm: 6.74136291614696\n",
      "Epoch 5990, Loss: 208.8209458472158, Neurons: 201, Grad norm: 4.737216847783382\n",
      "Epoch 5990, Loss: 208.8209458472158, Neurons: 201, Grad norm: 4.737216847783382\n",
      "Epoch 5991, Loss: 208.82072900010263, Neurons: 201, Grad norm: 2.4212192746264267\n",
      "Epoch 5991, Loss: 208.82072900010263, Neurons: 201, Grad norm: 2.4212192746264267\n",
      "Epoch 5992, Loss: 208.82055942396377, Neurons: 201, Grad norm: 1.5334778433951104\n",
      "Epoch 5992, Loss: 208.82055942396377, Neurons: 201, Grad norm: 1.5334778433951104\n",
      "Epoch 5993, Loss: 208.82032760464344, Neurons: 201, Grad norm: 4.195566383262506\n",
      "Epoch 5993, Loss: 208.82032760464344, Neurons: 201, Grad norm: 4.195566383262506\n",
      "Epoch 5994, Loss: 208.82032828684834, Neurons: 201, Grad norm: 6.5750061223405005\n",
      "Epoch 5994, Loss: 208.82032828684834, Neurons: 201, Grad norm: 6.5750061223405005\n",
      "Epoch 5995, Loss: 208.82073897547806, Neurons: 201, Grad norm: 7.7595179312148055\n",
      "Epoch 5995, Loss: 208.82073897547806, Neurons: 201, Grad norm: 7.7595179312148055\n",
      "Epoch 5996, Loss: 208.8208581608718, Neurons: 201, Grad norm: 8.048825422350182\n",
      "Epoch 5996, Loss: 208.8208581608718, Neurons: 201, Grad norm: 8.048825422350182\n",
      "Epoch 5997, Loss: 208.8206089450988, Neurons: 201, Grad norm: 7.667638774086073\n",
      "Epoch 5997, Loss: 208.8206089450988, Neurons: 201, Grad norm: 7.667638774086073\n",
      "Epoch 5998, Loss: 208.82043153035607, Neurons: 201, Grad norm: 6.826653737255206\n",
      "Epoch 5998, Loss: 208.82043153035607, Neurons: 201, Grad norm: 6.826653737255206\n",
      "Epoch 5999, Loss: 208.82030156788124, Neurons: 201, Grad norm: 6.115047952908108\n",
      "Epoch 5999, Loss: 208.82030156788124, Neurons: 201, Grad norm: 6.115047952908108\n",
      "Epoch 6000, Loss: 208.81989553219344, Neurons: 201, Grad norm: 5.515585357342714\n",
      "Epoch 6000, Loss: 208.81989553219344, Neurons: 201, Grad norm: 5.515585357342714\n",
      "Epoch 6001, Loss: 208.81933160558887, Neurons: 201, Grad norm: 4.850314181563055\n",
      "Epoch 6001, Loss: 208.81933160558887, Neurons: 201, Grad norm: 4.850314181563055\n",
      "Epoch 6002, Loss: 208.81880953893554, Neurons: 201, Grad norm: 4.9695429291020385\n",
      "Epoch 6002, Loss: 208.81880953893554, Neurons: 201, Grad norm: 4.9695429291020385\n",
      "Epoch 6003, Loss: 208.81867277624633, Neurons: 201, Grad norm: 4.140323978951603\n",
      "Epoch 6003, Loss: 208.81867277624633, Neurons: 201, Grad norm: 4.140323978951603\n",
      "Epoch 6004, Loss: 208.8183881504439, Neurons: 201, Grad norm: 3.1148020907331806\n",
      "Epoch 6004, Loss: 208.8183881504439, Neurons: 201, Grad norm: 3.1148020907331806\n",
      "Epoch 6005, Loss: 208.81805273629377, Neurons: 201, Grad norm: 1.7842366327763586\n",
      "Epoch 6005, Loss: 208.81805273629377, Neurons: 201, Grad norm: 1.7842366327763586\n",
      "Epoch 6006, Loss: 208.81743875627777, Neurons: 201, Grad norm: 0.7877309235428781\n",
      "Epoch 6006, Loss: 208.81743875627777, Neurons: 201, Grad norm: 0.7877309235428781\n",
      "Epoch 6007, Loss: 208.81714600110084, Neurons: 201, Grad norm: 1.2456741315720956\n",
      "Epoch 6007, Loss: 208.81714600110084, Neurons: 201, Grad norm: 1.2456741315720956\n",
      "Epoch 6008, Loss: 208.81711946148135, Neurons: 201, Grad norm: 1.6649854501244146\n",
      "Epoch 6008, Loss: 208.81711946148135, Neurons: 201, Grad norm: 1.6649854501244146\n",
      "Epoch 6009, Loss: 208.81692939618705, Neurons: 201, Grad norm: 2.15676969721423\n",
      "Epoch 6009, Loss: 208.81692939618705, Neurons: 201, Grad norm: 2.15676969721423\n",
      "Epoch 6010, Loss: 208.81678239932927, Neurons: 201, Grad norm: 2.99088988595803\n",
      "Epoch 6010, Loss: 208.81678239932927, Neurons: 201, Grad norm: 2.99088988595803\n",
      "Epoch 6011, Loss: 208.8166246412532, Neurons: 201, Grad norm: 3.7930747251543946\n",
      "Epoch 6011, Loss: 208.8166246412532, Neurons: 201, Grad norm: 3.7930747251543946\n",
      "Epoch 6012, Loss: 208.81638733886348, Neurons: 201, Grad norm: 5.050161334601386\n",
      "Epoch 6012, Loss: 208.81638733886348, Neurons: 201, Grad norm: 5.050161334601386\n",
      "Epoch 6013, Loss: 208.81596271480294, Neurons: 201, Grad norm: 5.834304296319872\n",
      "Epoch 6013, Loss: 208.81596271480294, Neurons: 201, Grad norm: 5.834304296319872\n",
      "Epoch 6014, Loss: 208.81538913030303, Neurons: 201, Grad norm: 6.1310252865222985\n",
      "Epoch 6014, Loss: 208.81538913030303, Neurons: 201, Grad norm: 6.1310252865222985\n",
      "Epoch 6015, Loss: 208.81450721578727, Neurons: 201, Grad norm: 6.045796861452352\n",
      "Epoch 6015, Loss: 208.81450721578727, Neurons: 201, Grad norm: 6.045796861452352\n",
      "Epoch 6016, Loss: 208.81329791281124, Neurons: 201, Grad norm: 5.481448168762784\n",
      "Epoch 6016, Loss: 208.81329791281124, Neurons: 201, Grad norm: 5.481448168762784\n",
      "Epoch 6017, Loss: 208.81230323950234, Neurons: 201, Grad norm: 5.168616714792986\n",
      "Epoch 6017, Loss: 208.81230323950234, Neurons: 201, Grad norm: 5.168616714792986\n",
      "Epoch 6018, Loss: 208.81181491851737, Neurons: 201, Grad norm: 5.198952597209654\n",
      "Epoch 6018, Loss: 208.81181491851737, Neurons: 201, Grad norm: 5.198952597209654\n",
      "Epoch 6019, Loss: 208.81184132335045, Neurons: 201, Grad norm: 4.844849821252573\n",
      "Epoch 6019, Loss: 208.81184132335045, Neurons: 201, Grad norm: 4.844849821252573\n",
      "Epoch 6020, Loss: 208.81225357891114, Neurons: 201, Grad norm: 4.970993295115715\n",
      "Epoch 6020, Loss: 208.81225357891114, Neurons: 201, Grad norm: 4.970993295115715\n",
      "Epoch 6021, Loss: 208.81195916317265, Neurons: 201, Grad norm: 3.9202636771079984\n",
      "Epoch 6021, Loss: 208.81195916317265, Neurons: 201, Grad norm: 3.9202636771079984\n",
      "Epoch 6022, Loss: 208.81121923717194, Neurons: 201, Grad norm: 2.908270447778058\n",
      "Epoch 6022, Loss: 208.81121923717194, Neurons: 201, Grad norm: 2.908270447778058\n",
      "Epoch 6023, Loss: 208.81035962419367, Neurons: 201, Grad norm: 1.8180324104912602\n",
      "Epoch 6023, Loss: 208.81035962419367, Neurons: 201, Grad norm: 1.8180324104912602\n",
      "Epoch 6024, Loss: 208.8098037665699, Neurons: 201, Grad norm: 0.6288406198584753\n",
      "Epoch 6024, Loss: 208.8098037665699, Neurons: 201, Grad norm: 0.6288406198584753\n",
      "Epoch 6025, Loss: 208.80971611349625, Neurons: 201, Grad norm: 1.1854303737530554\n",
      "Epoch 6025, Loss: 208.80971611349625, Neurons: 201, Grad norm: 1.1854303737530554\n",
      "Epoch 6026, Loss: 208.80982397391523, Neurons: 201, Grad norm: 2.7483335459776543\n",
      "Epoch 6026, Loss: 208.80982397391523, Neurons: 201, Grad norm: 2.7483335459776543\n",
      "Epoch 6027, Loss: 208.81001285143242, Neurons: 201, Grad norm: 3.950859288623807\n",
      "Epoch 6027, Loss: 208.81001285143242, Neurons: 201, Grad norm: 3.950859288623807\n",
      "Epoch 6028, Loss: 208.81015340103608, Neurons: 201, Grad norm: 5.1242405128992\n",
      "Epoch 6028, Loss: 208.81015340103608, Neurons: 201, Grad norm: 5.1242405128992\n",
      "Epoch 6029, Loss: 208.8099740611136, Neurons: 201, Grad norm: 5.745995478684806\n",
      "Epoch 6029, Loss: 208.8099740611136, Neurons: 201, Grad norm: 5.745995478684806\n",
      "Epoch 6030, Loss: 208.80979739698384, Neurons: 201, Grad norm: 6.51606299500294\n",
      "Epoch 6030, Loss: 208.80979739698384, Neurons: 201, Grad norm: 6.51606299500294\n",
      "Epoch 6031, Loss: 208.80944786207573, Neurons: 201, Grad norm: 7.119369765006545\n",
      "Epoch 6031, Loss: 208.80944786207573, Neurons: 201, Grad norm: 7.119369765006545\n",
      "Epoch 6032, Loss: 208.80950459734063, Neurons: 201, Grad norm: 7.5060248508710545\n",
      "Epoch 6032, Loss: 208.80950459734063, Neurons: 201, Grad norm: 7.5060248508710545\n",
      "Epoch 6033, Loss: 208.8096357070173, Neurons: 201, Grad norm: 7.776945490122869\n",
      "Epoch 6033, Loss: 208.8096357070173, Neurons: 201, Grad norm: 7.776945490122869\n",
      "Epoch 6034, Loss: 208.8096843975835, Neurons: 201, Grad norm: 7.736526082541727\n",
      "Epoch 6034, Loss: 208.8096843975835, Neurons: 201, Grad norm: 7.736526082541727\n",
      "Epoch 6035, Loss: 208.80957982408748, Neurons: 201, Grad norm: 7.240844599797616\n",
      "Epoch 6035, Loss: 208.80957982408748, Neurons: 201, Grad norm: 7.240844599797616\n",
      "Epoch 6036, Loss: 208.80918436799405, Neurons: 201, Grad norm: 6.215501422824854\n",
      "Epoch 6036, Loss: 208.80918436799405, Neurons: 201, Grad norm: 6.215501422824854\n",
      "Epoch 6037, Loss: 208.8086512868023, Neurons: 201, Grad norm: 4.212647149741243\n",
      "Epoch 6037, Loss: 208.8086512868023, Neurons: 201, Grad norm: 4.212647149741243\n",
      "Epoch 6038, Loss: 208.80834489204935, Neurons: 201, Grad norm: 2.692849788508603\n",
      "Epoch 6038, Loss: 208.80834489204935, Neurons: 201, Grad norm: 2.692849788508603\n",
      "Epoch 6039, Loss: 208.80821608760056, Neurons: 201, Grad norm: 0.7570234126956975\n",
      "Epoch 6039, Loss: 208.80821608760056, Neurons: 201, Grad norm: 0.7570234126956975\n",
      "Epoch 6040, Loss: 208.80798949128234, Neurons: 201, Grad norm: 1.7588796127237705\n",
      "Epoch 6040, Loss: 208.80798949128234, Neurons: 201, Grad norm: 1.7588796127237705\n",
      "Epoch 6041, Loss: 208.80783520049266, Neurons: 201, Grad norm: 3.149826492312608\n",
      "Epoch 6041, Loss: 208.80783520049266, Neurons: 201, Grad norm: 3.149826492312608\n",
      "Epoch 6042, Loss: 208.80784612790492, Neurons: 201, Grad norm: 5.003046433778483\n",
      "Epoch 6042, Loss: 208.80784612790492, Neurons: 201, Grad norm: 5.003046433778483\n",
      "Epoch 6043, Loss: 208.80794451721007, Neurons: 201, Grad norm: 6.587641528974991\n",
      "Epoch 6043, Loss: 208.80794451721007, Neurons: 201, Grad norm: 6.587641528974991\n",
      "Epoch 6044, Loss: 208.80804668861043, Neurons: 201, Grad norm: 8.483589477469954\n",
      "Epoch 6044, Loss: 208.80804668861043, Neurons: 201, Grad norm: 8.483589477469954\n",
      "Epoch 6045, Loss: 208.80825605343261, Neurons: 201, Grad norm: 9.829263341844575\n",
      "Epoch 6045, Loss: 208.80825605343261, Neurons: 201, Grad norm: 9.829263341844575\n",
      "Epoch 6046, Loss: 208.8085552766778, Neurons: 201, Grad norm: 10.166765241886882\n",
      "Epoch 6046, Loss: 208.8085552766778, Neurons: 201, Grad norm: 10.166765241886882\n",
      "Epoch 6047, Loss: 208.80860447647026, Neurons: 201, Grad norm: 9.605215981112933\n",
      "Epoch 6047, Loss: 208.80860447647026, Neurons: 201, Grad norm: 9.605215981112933\n",
      "Epoch 6048, Loss: 208.80829305548824, Neurons: 201, Grad norm: 7.645359431124669\n",
      "Epoch 6048, Loss: 208.80829305548824, Neurons: 201, Grad norm: 7.645359431124669\n",
      "Epoch 6049, Loss: 208.80786190839405, Neurons: 201, Grad norm: 5.244418310029648\n",
      "Epoch 6049, Loss: 208.80786190839405, Neurons: 201, Grad norm: 5.244418310029648\n",
      "Epoch 6050, Loss: 208.80754223136657, Neurons: 201, Grad norm: 2.7770377371138957\n",
      "Epoch 6050, Loss: 208.80754223136657, Neurons: 201, Grad norm: 2.7770377371138957\n",
      "Epoch 6051, Loss: 208.80714015388244, Neurons: 201, Grad norm: 0.8065304572419018\n",
      "Epoch 6051, Loss: 208.80714015388244, Neurons: 201, Grad norm: 0.8065304572419018\n",
      "Epoch 6052, Loss: 208.80683944170093, Neurons: 201, Grad norm: 1.8610303623510829\n",
      "Epoch 6052, Loss: 208.80683944170093, Neurons: 201, Grad norm: 1.8610303623510829\n",
      "Epoch 6053, Loss: 208.80678528713526, Neurons: 201, Grad norm: 3.282867619380361\n",
      "Epoch 6053, Loss: 208.80678528713526, Neurons: 201, Grad norm: 3.282867619380361\n",
      "Epoch 6054, Loss: 208.80693322315304, Neurons: 201, Grad norm: 4.849055202334743\n",
      "Epoch 6054, Loss: 208.80693322315304, Neurons: 201, Grad norm: 4.849055202334743\n",
      "Epoch 6055, Loss: 208.80692957018792, Neurons: 201, Grad norm: 6.144012961533836\n",
      "Epoch 6055, Loss: 208.80692957018792, Neurons: 201, Grad norm: 6.144012961533836\n",
      "Epoch 6056, Loss: 208.80691238143493, Neurons: 201, Grad norm: 7.21614313671829\n",
      "Epoch 6056, Loss: 208.80691238143493, Neurons: 201, Grad norm: 7.21614313671829\n",
      "Epoch 6057, Loss: 208.8069625132346, Neurons: 201, Grad norm: 7.8966422926292426\n",
      "Epoch 6057, Loss: 208.8069625132346, Neurons: 201, Grad norm: 7.8966422926292426\n",
      "Epoch 6058, Loss: 208.80703087858367, Neurons: 201, Grad norm: 7.761581597042642\n",
      "Epoch 6058, Loss: 208.80703087858367, Neurons: 201, Grad norm: 7.761581597042642\n",
      "Epoch 6059, Loss: 208.80697887568346, Neurons: 201, Grad norm: 7.033960425125001\n",
      "Epoch 6059, Loss: 208.80697887568346, Neurons: 201, Grad norm: 7.033960425125001\n",
      "Epoch 6060, Loss: 208.8066851240902, Neurons: 201, Grad norm: 6.222596402778604\n",
      "Epoch 6060, Loss: 208.8066851240902, Neurons: 201, Grad norm: 6.222596402778604\n",
      "Epoch 6061, Loss: 208.80653175462578, Neurons: 201, Grad norm: 5.4630861417965235\n",
      "Epoch 6061, Loss: 208.80653175462578, Neurons: 201, Grad norm: 5.4630861417965235\n",
      "Epoch 6062, Loss: 208.8063641548717, Neurons: 201, Grad norm: 4.880859884973339\n",
      "Epoch 6062, Loss: 208.8063641548717, Neurons: 201, Grad norm: 4.880859884973339\n",
      "Epoch 6063, Loss: 208.8061633710636, Neurons: 201, Grad norm: 4.4335678055990675\n",
      "Epoch 6063, Loss: 208.8061633710636, Neurons: 201, Grad norm: 4.4335678055990675\n",
      "Epoch 6064, Loss: 208.80597544864827, Neurons: 201, Grad norm: 4.191911701157921\n",
      "Epoch 6064, Loss: 208.80597544864827, Neurons: 201, Grad norm: 4.191911701157921\n",
      "Epoch 6065, Loss: 208.80585291454585, Neurons: 201, Grad norm: 3.8867544527622635\n",
      "Epoch 6065, Loss: 208.80585291454585, Neurons: 201, Grad norm: 3.8867544527622635\n",
      "Epoch 6066, Loss: 208.8057223339885, Neurons: 201, Grad norm: 3.6078626493996255\n",
      "Epoch 6066, Loss: 208.8057223339885, Neurons: 201, Grad norm: 3.6078626493996255\n",
      "Epoch 6067, Loss: 208.80559057969708, Neurons: 201, Grad norm: 3.4243938581043856\n",
      "Epoch 6067, Loss: 208.80559057969708, Neurons: 201, Grad norm: 3.4243938581043856\n",
      "Epoch 6068, Loss: 208.8054980057061, Neurons: 201, Grad norm: 3.4916028693234753\n",
      "Epoch 6068, Loss: 208.8054980057061, Neurons: 201, Grad norm: 3.4916028693234753\n",
      "Epoch 6069, Loss: 208.80548796221922, Neurons: 201, Grad norm: 3.6028481270115056\n",
      "Epoch 6069, Loss: 208.80548796221922, Neurons: 201, Grad norm: 3.6028481270115056\n",
      "Epoch 6070, Loss: 208.80540122616173, Neurons: 201, Grad norm: 4.072974326186555\n",
      "Epoch 6070, Loss: 208.80540122616173, Neurons: 201, Grad norm: 4.072974326186555\n",
      "Epoch 6071, Loss: 208.80534617719533, Neurons: 201, Grad norm: 4.514985758910317\n",
      "Epoch 6071, Loss: 208.80534617719533, Neurons: 201, Grad norm: 4.514985758910317\n",
      "Epoch 6072, Loss: 208.80533697603977, Neurons: 201, Grad norm: 5.296137778122611\n",
      "Epoch 6072, Loss: 208.80533697603977, Neurons: 201, Grad norm: 5.296137778122611\n",
      "Epoch 6073, Loss: 208.80546261929726, Neurons: 201, Grad norm: 5.612480824082654\n",
      "Epoch 6073, Loss: 208.80546261929726, Neurons: 201, Grad norm: 5.612480824082654\n",
      "Epoch 6074, Loss: 208.80531468209176, Neurons: 201, Grad norm: 5.869540411163396\n",
      "Epoch 6074, Loss: 208.80531468209176, Neurons: 201, Grad norm: 5.869540411163396\n",
      "Epoch 6075, Loss: 208.80528162880591, Neurons: 201, Grad norm: 5.795459137704729\n",
      "Epoch 6075, Loss: 208.80528162880591, Neurons: 201, Grad norm: 5.795459137704729\n",
      "Epoch 6076, Loss: 208.80512250885445, Neurons: 201, Grad norm: 5.803559489763077\n",
      "Epoch 6076, Loss: 208.80512250885445, Neurons: 201, Grad norm: 5.803559489763077\n",
      "Epoch 6077, Loss: 208.8050264210409, Neurons: 201, Grad norm: 5.540564834435557\n",
      "Epoch 6077, Loss: 208.8050264210409, Neurons: 201, Grad norm: 5.540564834435557\n",
      "Epoch 6078, Loss: 208.80492621941102, Neurons: 201, Grad norm: 5.388650252259933\n",
      "Epoch 6078, Loss: 208.80492621941102, Neurons: 201, Grad norm: 5.388650252259933\n",
      "Epoch 6079, Loss: 208.80484065261444, Neurons: 201, Grad norm: 5.343216721757794\n",
      "Epoch 6079, Loss: 208.80484065261444, Neurons: 201, Grad norm: 5.343216721757794\n",
      "Epoch 6080, Loss: 208.80470788656774, Neurons: 201, Grad norm: 5.386327276922342\n",
      "Epoch 6080, Loss: 208.80470788656774, Neurons: 201, Grad norm: 5.386327276922342\n",
      "Epoch 6081, Loss: 208.80463207522763, Neurons: 201, Grad norm: 5.409296078065447\n",
      "Epoch 6081, Loss: 208.80463207522763, Neurons: 201, Grad norm: 5.409296078065447\n",
      "Epoch 6082, Loss: 208.80458901759147, Neurons: 201, Grad norm: 5.731711699888029\n",
      "Epoch 6082, Loss: 208.80458901759147, Neurons: 201, Grad norm: 5.731711699888029\n",
      "Epoch 6083, Loss: 208.80462650505225, Neurons: 201, Grad norm: 6.068058784301392\n",
      "Epoch 6083, Loss: 208.80462650505225, Neurons: 201, Grad norm: 6.068058784301392\n",
      "Epoch 6084, Loss: 208.8046539621042, Neurons: 201, Grad norm: 6.460615217300644\n",
      "Epoch 6084, Loss: 208.8046539621042, Neurons: 201, Grad norm: 6.460615217300644\n",
      "Epoch 6085, Loss: 208.8045252902781, Neurons: 201, Grad norm: 6.812741989216713\n",
      "Epoch 6085, Loss: 208.8045252902781, Neurons: 201, Grad norm: 6.812741989216713\n",
      "Epoch 6086, Loss: 208.80454719108178, Neurons: 201, Grad norm: 7.586662040349091\n",
      "Epoch 6086, Loss: 208.80454719108178, Neurons: 201, Grad norm: 7.586662040349091\n",
      "Epoch 6087, Loss: 208.80459804462265, Neurons: 201, Grad norm: 7.948616566735687\n",
      "Epoch 6087, Loss: 208.80459804462265, Neurons: 201, Grad norm: 7.948616566735687\n",
      "Epoch 6088, Loss: 208.80460902370638, Neurons: 201, Grad norm: 7.983554988544599\n",
      "Epoch 6088, Loss: 208.80460902370638, Neurons: 201, Grad norm: 7.983554988544599\n",
      "Epoch 6089, Loss: 208.80451518940384, Neurons: 201, Grad norm: 7.5611185646893375\n",
      "Epoch 6089, Loss: 208.80451518940384, Neurons: 201, Grad norm: 7.5611185646893375\n",
      "Epoch 6090, Loss: 208.8043645286743, Neurons: 201, Grad norm: 6.664560230751592\n",
      "Epoch 6090, Loss: 208.8043645286743, Neurons: 201, Grad norm: 6.664560230751592\n",
      "Epoch 6091, Loss: 208.8042479254419, Neurons: 201, Grad norm: 5.53245790149765\n",
      "Epoch 6091, Loss: 208.8042479254419, Neurons: 201, Grad norm: 5.53245790149765\n",
      "Epoch 6092, Loss: 208.8041335693454, Neurons: 201, Grad norm: 4.1985149203423004\n",
      "Epoch 6092, Loss: 208.8041335693454, Neurons: 201, Grad norm: 4.1985149203423004\n",
      "Epoch 6093, Loss: 208.80377369001206, Neurons: 201, Grad norm: 2.7931733271657544\n",
      "Epoch 6093, Loss: 208.80377369001206, Neurons: 201, Grad norm: 2.7931733271657544\n",
      "Epoch 6094, Loss: 208.80344477324388, Neurons: 201, Grad norm: 1.8453696281990422\n",
      "Epoch 6094, Loss: 208.80344477324388, Neurons: 201, Grad norm: 1.8453696281990422\n",
      "Epoch 6095, Loss: 208.80334559675453, Neurons: 201, Grad norm: 1.2882571837196477\n",
      "Epoch 6095, Loss: 208.80334559675453, Neurons: 201, Grad norm: 1.2882571837196477\n",
      "Epoch 6096, Loss: 208.80329920575653, Neurons: 201, Grad norm: 1.5324509963378443\n",
      "Epoch 6096, Loss: 208.80329920575653, Neurons: 201, Grad norm: 1.5324509963378443\n",
      "Epoch 6097, Loss: 208.80322369161897, Neurons: 201, Grad norm: 2.6400822500865107\n",
      "Epoch 6097, Loss: 208.80322369161897, Neurons: 201, Grad norm: 2.6400822500865107\n",
      "Epoch 6098, Loss: 208.80314177715036, Neurons: 201, Grad norm: 4.096074536819381\n",
      "Epoch 6098, Loss: 208.80314177715036, Neurons: 201, Grad norm: 4.096074536819381\n",
      "Epoch 6099, Loss: 208.80320466706326, Neurons: 201, Grad norm: 6.49678584831746\n",
      "Epoch 6099, Loss: 208.80320466706326, Neurons: 201, Grad norm: 6.49678584831746\n",
      "Epoch 6100, Loss: 208.80327928393808, Neurons: 201, Grad norm: 8.539314784284208\n",
      "Epoch 6100, Loss: 208.80327928393808, Neurons: 201, Grad norm: 8.539314784284208\n",
      "Epoch 6101, Loss: 208.8036040214811, Neurons: 201, Grad norm: 10.669117334526874\n",
      "Epoch 6101, Loss: 208.8036040214811, Neurons: 201, Grad norm: 10.669117334526874\n",
      "Epoch 6102, Loss: 208.80406464422356, Neurons: 201, Grad norm: 12.353398300711538\n",
      "Epoch 6102, Loss: 208.80406464422356, Neurons: 201, Grad norm: 12.353398300711538\n",
      "Epoch 6103, Loss: 208.80449488898557, Neurons: 201, Grad norm: 13.341944353530165\n",
      "Epoch 6103, Loss: 208.80449488898557, Neurons: 201, Grad norm: 13.341944353530165\n",
      "Epoch 6104, Loss: 208.80489296481625, Neurons: 201, Grad norm: 13.579523933847724\n",
      "Epoch 6104, Loss: 208.80489296481625, Neurons: 201, Grad norm: 13.579523933847724\n",
      "Epoch 6105, Loss: 208.80494940284072, Neurons: 201, Grad norm: 12.786319029266581\n",
      "Epoch 6105, Loss: 208.80494940284072, Neurons: 201, Grad norm: 12.786319029266581\n",
      "Epoch 6106, Loss: 208.8047395040917, Neurons: 201, Grad norm: 10.754211845159888\n",
      "Epoch 6106, Loss: 208.8047395040917, Neurons: 201, Grad norm: 10.754211845159888\n",
      "Epoch 6107, Loss: 208.80398171274496, Neurons: 201, Grad norm: 7.961344959886199\n",
      "Epoch 6107, Loss: 208.80398171274496, Neurons: 201, Grad norm: 7.961344959886199\n",
      "Epoch 6108, Loss: 208.8030881927703, Neurons: 201, Grad norm: 4.4183812135765255\n",
      "Epoch 6108, Loss: 208.8030881927703, Neurons: 201, Grad norm: 4.4183812135765255\n",
      "Epoch 6109, Loss: 208.80253141387138, Neurons: 201, Grad norm: 0.9128068659126818\n",
      "Epoch 6109, Loss: 208.80253141387138, Neurons: 201, Grad norm: 0.9128068659126818\n",
      "Epoch 6110, Loss: 208.80213365795564, Neurons: 201, Grad norm: 3.0358569808814524\n",
      "Epoch 6110, Loss: 208.80213365795564, Neurons: 201, Grad norm: 3.0358569808814524\n",
      "Epoch 6111, Loss: 208.80226738900907, Neurons: 201, Grad norm: 6.083754455709255\n",
      "Epoch 6111, Loss: 208.80226738900907, Neurons: 201, Grad norm: 6.083754455709255\n",
      "Epoch 6112, Loss: 208.80259806046323, Neurons: 201, Grad norm: 8.49532401726775\n",
      "Epoch 6112, Loss: 208.80259806046323, Neurons: 201, Grad norm: 8.49532401726775\n",
      "Epoch 6113, Loss: 208.8029367242646, Neurons: 201, Grad norm: 10.032926631529653\n",
      "Epoch 6113, Loss: 208.8029367242646, Neurons: 201, Grad norm: 10.032926631529653\n",
      "Epoch 6114, Loss: 208.8031459793058, Neurons: 201, Grad norm: 10.920153865838751\n",
      "Epoch 6114, Loss: 208.8031459793058, Neurons: 201, Grad norm: 10.920153865838751\n",
      "Epoch 6115, Loss: 208.8032102123114, Neurons: 201, Grad norm: 10.480321748788876\n",
      "Epoch 6115, Loss: 208.8032102123114, Neurons: 201, Grad norm: 10.480321748788876\n",
      "Epoch 6116, Loss: 208.80304897125313, Neurons: 201, Grad norm: 9.213398810025641\n",
      "Epoch 6116, Loss: 208.80304897125313, Neurons: 201, Grad norm: 9.213398810025641\n",
      "Epoch 6117, Loss: 208.80266387734727, Neurons: 201, Grad norm: 7.073290024593882\n",
      "Epoch 6117, Loss: 208.80266387734727, Neurons: 201, Grad norm: 7.073290024593882\n",
      "Epoch 6118, Loss: 208.80234656135346, Neurons: 201, Grad norm: 4.6422733895296755\n",
      "Epoch 6118, Loss: 208.80234656135346, Neurons: 201, Grad norm: 4.6422733895296755\n",
      "Epoch 6119, Loss: 208.80190722762552, Neurons: 201, Grad norm: 1.9288370734498408\n",
      "Epoch 6119, Loss: 208.80190722762552, Neurons: 201, Grad norm: 1.9288370734498408\n",
      "Epoch 6120, Loss: 208.80156787564218, Neurons: 201, Grad norm: 0.9831683161211806\n",
      "Epoch 6120, Loss: 208.80156787564218, Neurons: 201, Grad norm: 0.9831683161211806\n",
      "Epoch 6121, Loss: 208.80135182263314, Neurons: 201, Grad norm: 3.1118500440543717\n",
      "Epoch 6121, Loss: 208.80135182263314, Neurons: 201, Grad norm: 3.1118500440543717\n",
      "Epoch 6122, Loss: 208.8014043867939, Neurons: 201, Grad norm: 5.107344310828021\n",
      "Epoch 6122, Loss: 208.8014043867939, Neurons: 201, Grad norm: 5.107344310828021\n",
      "Epoch 6123, Loss: 208.80163160047192, Neurons: 201, Grad norm: 6.927198774448485\n",
      "Epoch 6123, Loss: 208.80163160047192, Neurons: 201, Grad norm: 6.927198774448485\n",
      "Epoch 6124, Loss: 208.8017935702601, Neurons: 201, Grad norm: 8.487951976927208\n",
      "Epoch 6124, Loss: 208.8017935702601, Neurons: 201, Grad norm: 8.487951976927208\n",
      "Epoch 6125, Loss: 208.8019537862049, Neurons: 201, Grad norm: 9.907962918828222\n",
      "Epoch 6125, Loss: 208.8019537862049, Neurons: 201, Grad norm: 9.907962918828222\n",
      "Epoch 6126, Loss: 208.80213544305542, Neurons: 201, Grad norm: 10.541794717845539\n",
      "Epoch 6126, Loss: 208.80213544305542, Neurons: 201, Grad norm: 10.541794717845539\n",
      "Epoch 6127, Loss: 208.8022151461113, Neurons: 201, Grad norm: 10.51348516601701\n",
      "Epoch 6127, Loss: 208.8022151461113, Neurons: 201, Grad norm: 10.51348516601701\n",
      "Epoch 6128, Loss: 208.80211294138442, Neurons: 201, Grad norm: 9.328455250453063\n",
      "Epoch 6128, Loss: 208.80211294138442, Neurons: 201, Grad norm: 9.328455250453063\n",
      "Epoch 6129, Loss: 208.80195206880356, Neurons: 201, Grad norm: 7.006754657437874\n",
      "Epoch 6129, Loss: 208.80195206880356, Neurons: 201, Grad norm: 7.006754657437874\n",
      "Epoch 6130, Loss: 208.80152913885698, Neurons: 201, Grad norm: 4.369870878819499\n",
      "Epoch 6130, Loss: 208.80152913885698, Neurons: 201, Grad norm: 4.369870878819499\n",
      "Epoch 6131, Loss: 208.80096914985177, Neurons: 201, Grad norm: 1.7302092569150587\n",
      "Epoch 6131, Loss: 208.80096914985177, Neurons: 201, Grad norm: 1.7302092569150587\n",
      "Epoch 6132, Loss: 208.80064993656393, Neurons: 201, Grad norm: 1.6267796553420029\n",
      "Epoch 6132, Loss: 208.80064993656393, Neurons: 201, Grad norm: 1.6267796553420029\n",
      "Epoch 6133, Loss: 208.80049260216617, Neurons: 201, Grad norm: 4.037210745079084\n",
      "Epoch 6133, Loss: 208.80049260216617, Neurons: 201, Grad norm: 4.037210745079084\n",
      "Epoch 6134, Loss: 208.8006182913605, Neurons: 201, Grad norm: 6.483299826924734\n",
      "Epoch 6134, Loss: 208.8006182913605, Neurons: 201, Grad norm: 6.483299826924734\n",
      "Epoch 6135, Loss: 208.80109209712845, Neurons: 201, Grad norm: 8.31759562548303\n",
      "Epoch 6135, Loss: 208.80109209712845, Neurons: 201, Grad norm: 8.31759562548303\n",
      "Epoch 6136, Loss: 208.80135976056746, Neurons: 201, Grad norm: 9.874878633909194\n",
      "Epoch 6136, Loss: 208.80135976056746, Neurons: 201, Grad norm: 9.874878633909194\n",
      "Epoch 6137, Loss: 208.80139916322992, Neurons: 201, Grad norm: 10.436878114081674\n",
      "Epoch 6137, Loss: 208.80139916322992, Neurons: 201, Grad norm: 10.436878114081674\n",
      "Epoch 6138, Loss: 208.80149100873342, Neurons: 201, Grad norm: 10.114816054500361\n",
      "Epoch 6138, Loss: 208.80149100873342, Neurons: 201, Grad norm: 10.114816054500361\n",
      "Epoch 6139, Loss: 208.80138196026562, Neurons: 201, Grad norm: 8.351657945267947\n",
      "Epoch 6139, Loss: 208.80138196026562, Neurons: 201, Grad norm: 8.351657945267947\n",
      "Epoch 6140, Loss: 208.80094415590645, Neurons: 201, Grad norm: 5.529730050549905\n",
      "Epoch 6140, Loss: 208.80094415590645, Neurons: 201, Grad norm: 5.529730050549905\n",
      "Epoch 6141, Loss: 208.80033676233646, Neurons: 201, Grad norm: 2.4255962677275686\n",
      "Epoch 6141, Loss: 208.80033676233646, Neurons: 201, Grad norm: 2.4255962677275686\n",
      "Epoch 6142, Loss: 208.7999634631831, Neurons: 201, Grad norm: 1.37936905090138\n",
      "Epoch 6142, Loss: 208.7999634631831, Neurons: 201, Grad norm: 1.37936905090138\n",
      "Epoch 6143, Loss: 208.79992672194362, Neurons: 201, Grad norm: 4.027370265179841\n",
      "Epoch 6143, Loss: 208.79992672194362, Neurons: 201, Grad norm: 4.027370265179841\n",
      "Epoch 6144, Loss: 208.80001404931937, Neurons: 201, Grad norm: 5.723560434017079\n",
      "Epoch 6144, Loss: 208.80001404931937, Neurons: 201, Grad norm: 5.723560434017079\n",
      "Epoch 6145, Loss: 208.80005625179814, Neurons: 201, Grad norm: 6.757325625483099\n",
      "Epoch 6145, Loss: 208.80005625179814, Neurons: 201, Grad norm: 6.757325625483099\n",
      "Epoch 6146, Loss: 208.8001541736827, Neurons: 201, Grad norm: 6.864491311031258\n",
      "Epoch 6146, Loss: 208.8001541736827, Neurons: 201, Grad norm: 6.864491311031258\n",
      "Epoch 6147, Loss: 208.80008805750225, Neurons: 201, Grad norm: 5.605661065146098\n",
      "Epoch 6147, Loss: 208.80008805750225, Neurons: 201, Grad norm: 5.605661065146098\n",
      "Epoch 6148, Loss: 208.79987235802162, Neurons: 201, Grad norm: 4.104775192268737\n",
      "Epoch 6148, Loss: 208.79987235802162, Neurons: 201, Grad norm: 4.104775192268737\n",
      "Epoch 6149, Loss: 208.79956776844315, Neurons: 201, Grad norm: 2.318141464526263\n",
      "Epoch 6149, Loss: 208.79956776844315, Neurons: 201, Grad norm: 2.318141464526263\n",
      "Epoch 6150, Loss: 208.79929527361736, Neurons: 201, Grad norm: 0.6233124700419772\n",
      "Epoch 6150, Loss: 208.79929527361736, Neurons: 201, Grad norm: 0.6233124700419772\n",
      "Epoch 6151, Loss: 208.79917966687444, Neurons: 201, Grad norm: 1.585133624165274\n",
      "Epoch 6151, Loss: 208.79917966687444, Neurons: 201, Grad norm: 1.585133624165274\n",
      "Epoch 6152, Loss: 208.79915956039747, Neurons: 201, Grad norm: 3.2371412316759383\n",
      "Epoch 6152, Loss: 208.79915956039747, Neurons: 201, Grad norm: 3.2371412316759383\n",
      "Epoch 6153, Loss: 208.79918555030412, Neurons: 201, Grad norm: 4.2567677961716015\n",
      "Epoch 6153, Loss: 208.79918555030412, Neurons: 201, Grad norm: 4.2567677961716015\n",
      "Epoch 6154, Loss: 208.7992494244621, Neurons: 201, Grad norm: 5.165725711510791\n",
      "Epoch 6154, Loss: 208.7992494244621, Neurons: 201, Grad norm: 5.165725711510791\n",
      "Epoch 6155, Loss: 208.79932874940786, Neurons: 201, Grad norm: 5.907279184136443\n",
      "Epoch 6155, Loss: 208.79932874940786, Neurons: 201, Grad norm: 5.907279184136443\n",
      "Epoch 6156, Loss: 208.79937841596188, Neurons: 201, Grad norm: 6.158308514243042\n",
      "Epoch 6156, Loss: 208.79937841596188, Neurons: 201, Grad norm: 6.158308514243042\n",
      "Epoch 6157, Loss: 208.79934827998116, Neurons: 201, Grad norm: 6.295715395894741\n",
      "Epoch 6157, Loss: 208.79934827998116, Neurons: 201, Grad norm: 6.295715395894741\n",
      "Epoch 6158, Loss: 208.79926092213378, Neurons: 201, Grad norm: 5.927647676081041\n",
      "Epoch 6158, Loss: 208.79926092213378, Neurons: 201, Grad norm: 5.927647676081041\n",
      "Epoch 6159, Loss: 208.79913035685544, Neurons: 201, Grad norm: 4.987690873723003\n",
      "Epoch 6159, Loss: 208.79913035685544, Neurons: 201, Grad norm: 4.987690873723003\n",
      "Epoch 6160, Loss: 208.79893381652016, Neurons: 201, Grad norm: 3.790942491463255\n",
      "Epoch 6160, Loss: 208.79893381652016, Neurons: 201, Grad norm: 3.790942491463255\n",
      "Epoch 6161, Loss: 208.79865233084442, Neurons: 201, Grad norm: 2.2384513520687404\n",
      "Epoch 6161, Loss: 208.79865233084442, Neurons: 201, Grad norm: 2.2384513520687404\n",
      "Epoch 6162, Loss: 208.7984460288301, Neurons: 201, Grad norm: 0.7851183293602799\n",
      "Epoch 6162, Loss: 208.7984460288301, Neurons: 201, Grad norm: 0.7851183293602799\n",
      "Epoch 6163, Loss: 208.79835609635597, Neurons: 201, Grad norm: 1.0536858980066823\n",
      "Epoch 6163, Loss: 208.79835609635597, Neurons: 201, Grad norm: 1.0536858980066823\n",
      "Epoch 6164, Loss: 208.79840436159446, Neurons: 201, Grad norm: 1.4231442298080053\n",
      "Epoch 6164, Loss: 208.79840436159446, Neurons: 201, Grad norm: 1.4231442298080053\n",
      "Epoch 6165, Loss: 208.7982469480671, Neurons: 201, Grad norm: 2.3774901741789725\n",
      "Epoch 6165, Loss: 208.7982469480671, Neurons: 201, Grad norm: 2.3774901741789725\n",
      "Epoch 6166, Loss: 208.7982200933304, Neurons: 201, Grad norm: 3.3982977787260022\n",
      "Epoch 6166, Loss: 208.7982200933304, Neurons: 201, Grad norm: 3.3982977787260022\n",
      "Epoch 6167, Loss: 208.79821048265535, Neurons: 201, Grad norm: 4.382374614142757\n",
      "Epoch 6167, Loss: 208.79821048265535, Neurons: 201, Grad norm: 4.382374614142757\n",
      "Epoch 6168, Loss: 208.7983172213137, Neurons: 201, Grad norm: 5.461943603121493\n",
      "Epoch 6168, Loss: 208.7983172213137, Neurons: 201, Grad norm: 5.461943603121493\n",
      "Epoch 6169, Loss: 208.7984806203865, Neurons: 201, Grad norm: 6.212592276324848\n",
      "Epoch 6169, Loss: 208.7984806203865, Neurons: 201, Grad norm: 6.212592276324848\n",
      "Epoch 6170, Loss: 208.79853128607843, Neurons: 201, Grad norm: 6.562685657017781\n",
      "Epoch 6170, Loss: 208.79853128607843, Neurons: 201, Grad norm: 6.562685657017781\n",
      "Epoch 6171, Loss: 208.79838729489185, Neurons: 201, Grad norm: 6.7008153360616145\n",
      "Epoch 6171, Loss: 208.79838729489185, Neurons: 201, Grad norm: 6.7008153360616145\n",
      "Epoch 6172, Loss: 208.79831289890805, Neurons: 201, Grad norm: 6.0142635940536255\n",
      "Epoch 6172, Loss: 208.79831289890805, Neurons: 201, Grad norm: 6.0142635940536255\n",
      "Epoch 6173, Loss: 208.79818309039902, Neurons: 201, Grad norm: 5.228803366868938\n",
      "Epoch 6173, Loss: 208.79818309039902, Neurons: 201, Grad norm: 5.228803366868938\n",
      "Epoch 6174, Loss: 208.7979493024717, Neurons: 201, Grad norm: 3.9563871629840395\n",
      "Epoch 6174, Loss: 208.7979493024717, Neurons: 201, Grad norm: 3.9563871629840395\n",
      "Epoch 6175, Loss: 208.79775036508636, Neurons: 201, Grad norm: 2.6726680933309983\n",
      "Epoch 6175, Loss: 208.79775036508636, Neurons: 201, Grad norm: 2.6726680933309983\n",
      "Epoch 6176, Loss: 208.79759520532204, Neurons: 201, Grad norm: 1.506357792038541\n",
      "Epoch 6176, Loss: 208.79759520532204, Neurons: 201, Grad norm: 1.506357792038541\n",
      "Epoch 6177, Loss: 208.79748901701524, Neurons: 201, Grad norm: 0.6928975307451744\n",
      "Epoch 6177, Loss: 208.79748901701524, Neurons: 201, Grad norm: 0.6928975307451744\n",
      "Epoch 6178, Loss: 208.79738041552181, Neurons: 201, Grad norm: 0.6083003422063951\n",
      "Epoch 6178, Loss: 208.79738041552181, Neurons: 201, Grad norm: 0.6083003422063951\n",
      "Epoch 6179, Loss: 208.79729373038103, Neurons: 201, Grad norm: 1.2458875126645734\n",
      "Epoch 6179, Loss: 208.79729373038103, Neurons: 201, Grad norm: 1.2458875126645734\n",
      "Epoch 6180, Loss: 208.7972170589235, Neurons: 201, Grad norm: 2.1052646575087905\n",
      "Epoch 6180, Loss: 208.7972170589235, Neurons: 201, Grad norm: 2.1052646575087905\n",
      "Epoch 6181, Loss: 208.79718734451484, Neurons: 201, Grad norm: 2.9629485620388447\n",
      "Epoch 6181, Loss: 208.79718734451484, Neurons: 201, Grad norm: 2.9629485620388447\n",
      "Epoch 6182, Loss: 208.7972157450355, Neurons: 201, Grad norm: 4.143368598215916\n",
      "Epoch 6182, Loss: 208.7972157450355, Neurons: 201, Grad norm: 4.143368598215916\n",
      "Epoch 6183, Loss: 208.79731604946326, Neurons: 201, Grad norm: 4.660890418104501\n",
      "Epoch 6183, Loss: 208.79731604946326, Neurons: 201, Grad norm: 4.660890418104501\n",
      "Epoch 6184, Loss: 208.79735296956514, Neurons: 201, Grad norm: 5.054053642803982\n",
      "Epoch 6184, Loss: 208.79735296956514, Neurons: 201, Grad norm: 5.054053642803982\n",
      "Epoch 6185, Loss: 208.79725020527894, Neurons: 201, Grad norm: 5.180166143285359\n",
      "Epoch 6185, Loss: 208.79725020527894, Neurons: 201, Grad norm: 5.180166143285359\n",
      "Epoch 6186, Loss: 208.79721782511754, Neurons: 201, Grad norm: 5.428491301694141\n",
      "Epoch 6186, Loss: 208.79721782511754, Neurons: 201, Grad norm: 5.428491301694141\n",
      "Epoch 6187, Loss: 208.79746566056374, Neurons: 201, Grad norm: 6.2815697667089\n",
      "Epoch 6187, Loss: 208.79746566056374, Neurons: 201, Grad norm: 6.2815697667089\n",
      "Epoch 6188, Loss: 208.79764967982197, Neurons: 201, Grad norm: 7.31485124483116\n",
      "Epoch 6188, Loss: 208.79764967982197, Neurons: 201, Grad norm: 7.31485124483116\n",
      "Epoch 6189, Loss: 208.79750937056934, Neurons: 201, Grad norm: 8.857112359579112\n",
      "Epoch 6189, Loss: 208.79750937056934, Neurons: 201, Grad norm: 8.857112359579112\n",
      "Epoch 6190, Loss: 208.7974713171456, Neurons: 201, Grad norm: 10.46650919562028\n",
      "Epoch 6190, Loss: 208.7974713171456, Neurons: 201, Grad norm: 10.46650919562028\n",
      "Epoch 6191, Loss: 208.79796385497445, Neurons: 201, Grad norm: 11.011623817579839\n",
      "Epoch 6191, Loss: 208.79796385497445, Neurons: 201, Grad norm: 11.011623817579839\n",
      "Epoch 6192, Loss: 208.79802187491143, Neurons: 201, Grad norm: 10.40897798027418\n",
      "Epoch 6192, Loss: 208.79802187491143, Neurons: 201, Grad norm: 10.40897798027418\n",
      "Epoch 6193, Loss: 208.7977558393793, Neurons: 201, Grad norm: 8.490681549232296\n",
      "Epoch 6193, Loss: 208.7977558393793, Neurons: 201, Grad norm: 8.490681549232296\n",
      "Epoch 6194, Loss: 208.79721952005394, Neurons: 201, Grad norm: 6.134485388759249\n",
      "Epoch 6194, Loss: 208.79721952005394, Neurons: 201, Grad norm: 6.134485388759249\n",
      "Epoch 6195, Loss: 208.79681531727124, Neurons: 201, Grad norm: 3.393133382015336\n",
      "Epoch 6195, Loss: 208.79681531727124, Neurons: 201, Grad norm: 3.393133382015336\n",
      "Epoch 6196, Loss: 208.79647375570232, Neurons: 201, Grad norm: 0.9818148676393441\n",
      "Epoch 6196, Loss: 208.79647375570232, Neurons: 201, Grad norm: 0.9818148676393441\n",
      "Epoch 6197, Loss: 208.79614730804505, Neurons: 201, Grad norm: 2.0237585827309243\n",
      "Epoch 6197, Loss: 208.79614730804505, Neurons: 201, Grad norm: 2.0237585827309243\n",
      "Epoch 6198, Loss: 208.7961124701582, Neurons: 201, Grad norm: 4.196609788327665\n",
      "Epoch 6198, Loss: 208.7961124701582, Neurons: 201, Grad norm: 4.196609788327665\n",
      "Epoch 6199, Loss: 208.7961800027286, Neurons: 201, Grad norm: 6.30027064514675\n",
      "Epoch 6199, Loss: 208.7961800027286, Neurons: 201, Grad norm: 6.30027064514675\n",
      "Epoch 6200, Loss: 208.79647880459626, Neurons: 201, Grad norm: 7.864358146447543\n",
      "Epoch 6200, Loss: 208.79647880459626, Neurons: 201, Grad norm: 7.864358146447543\n",
      "Epoch 6201, Loss: 208.796819728837, Neurons: 201, Grad norm: 9.465295222287992\n",
      "Epoch 6201, Loss: 208.796819728837, Neurons: 201, Grad norm: 9.465295222287992\n",
      "Epoch 6202, Loss: 208.79697454207303, Neurons: 201, Grad norm: 10.554318121057099\n",
      "Epoch 6202, Loss: 208.79697454207303, Neurons: 201, Grad norm: 10.554318121057099\n",
      "Epoch 6203, Loss: 208.79715262455207, Neurons: 201, Grad norm: 10.973867128516213\n",
      "Epoch 6203, Loss: 208.79715262455207, Neurons: 201, Grad norm: 10.973867128516213\n",
      "Epoch 6204, Loss: 208.7971903101492, Neurons: 201, Grad norm: 10.395791374783997\n",
      "Epoch 6204, Loss: 208.7971903101492, Neurons: 201, Grad norm: 10.395791374783997\n",
      "Epoch 6205, Loss: 208.79692515051266, Neurons: 201, Grad norm: 8.586437417811705\n",
      "Epoch 6205, Loss: 208.79692515051266, Neurons: 201, Grad norm: 8.586437417811705\n",
      "Epoch 6206, Loss: 208.79652095746644, Neurons: 201, Grad norm: 6.053988113838518\n",
      "Epoch 6206, Loss: 208.79652095746644, Neurons: 201, Grad norm: 6.053988113838518\n",
      "Epoch 6207, Loss: 208.79599984610473, Neurons: 201, Grad norm: 2.7683965878795758\n",
      "Epoch 6207, Loss: 208.79599984610473, Neurons: 201, Grad norm: 2.7683965878795758\n",
      "Epoch 6208, Loss: 208.795540879065, Neurons: 201, Grad norm: 0.8813565897583691\n",
      "Epoch 6208, Loss: 208.795540879065, Neurons: 201, Grad norm: 0.8813565897583691\n",
      "Epoch 6209, Loss: 208.7953692186015, Neurons: 201, Grad norm: 3.3514229361118777\n",
      "Epoch 6209, Loss: 208.7953692186015, Neurons: 201, Grad norm: 3.3514229361118777\n",
      "Epoch 6210, Loss: 208.7954445676002, Neurons: 201, Grad norm: 5.523071540460009\n",
      "Epoch 6210, Loss: 208.7954445676002, Neurons: 201, Grad norm: 5.523071540460009\n",
      "Epoch 6211, Loss: 208.7955744055108, Neurons: 201, Grad norm: 6.562518785439563\n",
      "Epoch 6211, Loss: 208.7955744055108, Neurons: 201, Grad norm: 6.562518785439563\n",
      "Epoch 6212, Loss: 208.79573654562827, Neurons: 201, Grad norm: 7.524199746220792\n",
      "Epoch 6212, Loss: 208.79573654562827, Neurons: 201, Grad norm: 7.524199746220792\n",
      "Epoch 6213, Loss: 208.79592452472912, Neurons: 201, Grad norm: 8.01652934860304\n",
      "Epoch 6213, Loss: 208.79592452472912, Neurons: 201, Grad norm: 8.01652934860304\n",
      "Epoch 6214, Loss: 208.79587711681103, Neurons: 201, Grad norm: 8.364055443670354\n",
      "Epoch 6214, Loss: 208.79587711681103, Neurons: 201, Grad norm: 8.364055443670354\n",
      "Epoch 6215, Loss: 208.7958673834895, Neurons: 201, Grad norm: 8.32243002464928\n",
      "Epoch 6215, Loss: 208.7958673834895, Neurons: 201, Grad norm: 8.32243002464928\n",
      "Epoch 6216, Loss: 208.7957011682165, Neurons: 201, Grad norm: 7.836008202397527\n",
      "Epoch 6216, Loss: 208.7957011682165, Neurons: 201, Grad norm: 7.836008202397527\n",
      "Epoch 6217, Loss: 208.7955709834318, Neurons: 201, Grad norm: 7.052928828437508\n",
      "Epoch 6217, Loss: 208.7955709834318, Neurons: 201, Grad norm: 7.052928828437508\n",
      "Epoch 6218, Loss: 208.79537352418535, Neurons: 201, Grad norm: 5.880800180626582\n",
      "Epoch 6218, Loss: 208.79537352418535, Neurons: 201, Grad norm: 5.880800180626582\n",
      "Epoch 6219, Loss: 208.79530810688462, Neurons: 201, Grad norm: 4.435163228822583\n",
      "Epoch 6219, Loss: 208.79530810688462, Neurons: 201, Grad norm: 4.435163228822583\n",
      "Epoch 6220, Loss: 208.79505752968342, Neurons: 201, Grad norm: 2.8349846284526485\n",
      "Epoch 6220, Loss: 208.79505752968342, Neurons: 201, Grad norm: 2.8349846284526485\n",
      "Epoch 6221, Loss: 208.79472682038292, Neurons: 201, Grad norm: 1.0780809477257292\n",
      "Epoch 6221, Loss: 208.79472682038292, Neurons: 201, Grad norm: 1.0780809477257292\n",
      "Epoch 6222, Loss: 208.79453689138862, Neurons: 201, Grad norm: 0.8436997477051057\n",
      "Epoch 6222, Loss: 208.79453689138862, Neurons: 201, Grad norm: 0.8436997477051057\n",
      "Epoch 6223, Loss: 208.7944490158407, Neurons: 201, Grad norm: 2.3883497665126248\n",
      "Epoch 6223, Loss: 208.7944490158407, Neurons: 201, Grad norm: 2.3883497665126248\n",
      "Epoch 6224, Loss: 208.79444723159034, Neurons: 201, Grad norm: 3.378408320007574\n",
      "Epoch 6224, Loss: 208.79444723159034, Neurons: 201, Grad norm: 3.378408320007574\n",
      "Epoch 6225, Loss: 208.7944363779335, Neurons: 201, Grad norm: 4.274642289832425\n",
      "Epoch 6225, Loss: 208.7944363779335, Neurons: 201, Grad norm: 4.274642289832425\n",
      "Epoch 6226, Loss: 208.79449576817842, Neurons: 201, Grad norm: 5.010982182452188\n",
      "Epoch 6226, Loss: 208.79449576817842, Neurons: 201, Grad norm: 5.010982182452188\n",
      "Epoch 6227, Loss: 208.79444187414296, Neurons: 201, Grad norm: 5.650793766164259\n",
      "Epoch 6227, Loss: 208.79444187414296, Neurons: 201, Grad norm: 5.650793766164259\n",
      "Epoch 6228, Loss: 208.7944441942901, Neurons: 201, Grad norm: 5.915816530683499\n",
      "Epoch 6228, Loss: 208.7944441942901, Neurons: 201, Grad norm: 5.915816530683499\n",
      "Epoch 6229, Loss: 208.79446844122697, Neurons: 201, Grad norm: 6.1965812161940566\n",
      "Epoch 6229, Loss: 208.79446844122697, Neurons: 201, Grad norm: 6.1965812161940566\n",
      "Epoch 6230, Loss: 208.79439609018056, Neurons: 201, Grad norm: 6.130916218205458\n",
      "Epoch 6230, Loss: 208.79439609018056, Neurons: 201, Grad norm: 6.130916218205458\n",
      "Epoch 6231, Loss: 208.79440810544048, Neurons: 201, Grad norm: 6.069001909819585\n",
      "Epoch 6231, Loss: 208.79440810544048, Neurons: 201, Grad norm: 6.069001909819585\n",
      "Epoch 6232, Loss: 208.7943540427099, Neurons: 201, Grad norm: 5.8523890535578325\n",
      "Epoch 6232, Loss: 208.7943540427099, Neurons: 201, Grad norm: 5.8523890535578325\n",
      "Epoch 6233, Loss: 208.79424866394356, Neurons: 201, Grad norm: 5.46041398562003\n",
      "Epoch 6233, Loss: 208.79424866394356, Neurons: 201, Grad norm: 5.46041398562003\n",
      "Epoch 6234, Loss: 208.7941324128804, Neurons: 201, Grad norm: 4.746088405646345\n",
      "Epoch 6234, Loss: 208.7941324128804, Neurons: 201, Grad norm: 4.746088405646345\n",
      "Epoch 6235, Loss: 208.79390173804322, Neurons: 201, Grad norm: 3.9192447444691068\n",
      "Epoch 6235, Loss: 208.79390173804322, Neurons: 201, Grad norm: 3.9192447444691068\n",
      "Epoch 6236, Loss: 208.79377144463814, Neurons: 201, Grad norm: 2.538172506839821\n",
      "Epoch 6236, Loss: 208.79377144463814, Neurons: 201, Grad norm: 2.538172506839821\n",
      "Epoch 6237, Loss: 208.7936407100424, Neurons: 201, Grad norm: 1.4319382497342832\n",
      "Epoch 6237, Loss: 208.7936407100424, Neurons: 201, Grad norm: 1.4319382497342832\n",
      "Epoch 6238, Loss: 208.79353469018196, Neurons: 201, Grad norm: 1.2157323877197483\n",
      "Epoch 6238, Loss: 208.79353469018196, Neurons: 201, Grad norm: 1.2157323877197483\n",
      "Epoch 6239, Loss: 208.7933829648457, Neurons: 201, Grad norm: 2.5197018121150627\n",
      "Epoch 6239, Loss: 208.7933829648457, Neurons: 201, Grad norm: 2.5197018121150627\n",
      "Epoch 6240, Loss: 208.79338534852806, Neurons: 201, Grad norm: 3.5408398444489775\n",
      "Epoch 6240, Loss: 208.79338534852806, Neurons: 201, Grad norm: 3.5408398444489775\n",
      "Epoch 6241, Loss: 208.79335793940956, Neurons: 201, Grad norm: 4.937150956910543\n",
      "Epoch 6241, Loss: 208.79335793940956, Neurons: 201, Grad norm: 4.937150956910543\n",
      "Epoch 6242, Loss: 208.79342177854642, Neurons: 201, Grad norm: 6.220352977762897\n",
      "Epoch 6242, Loss: 208.79342177854642, Neurons: 201, Grad norm: 6.220352977762897\n",
      "Epoch 6243, Loss: 208.79348394063115, Neurons: 201, Grad norm: 7.418672199162734\n",
      "Epoch 6243, Loss: 208.79348394063115, Neurons: 201, Grad norm: 7.418672199162734\n",
      "Epoch 6244, Loss: 208.79364621751603, Neurons: 201, Grad norm: 8.83075462054254\n",
      "Epoch 6244, Loss: 208.79364621751603, Neurons: 201, Grad norm: 8.83075462054254\n",
      "Epoch 6245, Loss: 208.7940111262787, Neurons: 201, Grad norm: 10.043310936519646\n",
      "Epoch 6245, Loss: 208.7940111262787, Neurons: 201, Grad norm: 10.043310936519646\n",
      "Epoch 6246, Loss: 208.79427672275742, Neurons: 201, Grad norm: 11.204953294152194\n",
      "Epoch 6246, Loss: 208.79427672275742, Neurons: 201, Grad norm: 11.204953294152194\n",
      "Epoch 6247, Loss: 208.79455330949241, Neurons: 201, Grad norm: 11.5713544316895\n",
      "Epoch 6247, Loss: 208.79455330949241, Neurons: 201, Grad norm: 11.5713544316895\n",
      "Epoch 6248, Loss: 208.79455776891902, Neurons: 201, Grad norm: 11.11309372157133\n",
      "Epoch 6248, Loss: 208.79455776891902, Neurons: 201, Grad norm: 11.11309372157133\n",
      "Epoch 6249, Loss: 208.79431633725045, Neurons: 201, Grad norm: 9.667153045086307\n",
      "Epoch 6249, Loss: 208.79431633725045, Neurons: 201, Grad norm: 9.667153045086307\n",
      "Epoch 6250, Loss: 208.79386645418472, Neurons: 201, Grad norm: 7.30248166078736\n",
      "Epoch 6250, Loss: 208.79386645418472, Neurons: 201, Grad norm: 7.30248166078736\n",
      "Epoch 6251, Loss: 208.79335576246862, Neurons: 201, Grad norm: 4.478481232746045\n",
      "Epoch 6251, Loss: 208.79335576246862, Neurons: 201, Grad norm: 4.478481232746045\n",
      "Epoch 6252, Loss: 208.7928624286445, Neurons: 201, Grad norm: 1.342639211846338\n",
      "Epoch 6252, Loss: 208.7928624286445, Neurons: 201, Grad norm: 1.342639211846338\n",
      "Epoch 6253, Loss: 208.79249689465374, Neurons: 201, Grad norm: 2.0793729387926914\n",
      "Epoch 6253, Loss: 208.79249689465374, Neurons: 201, Grad norm: 2.0793729387926914\n",
      "Epoch 6254, Loss: 208.79242258140502, Neurons: 201, Grad norm: 4.772986167376957\n",
      "Epoch 6254, Loss: 208.79242258140502, Neurons: 201, Grad norm: 4.772986167376957\n",
      "Epoch 6255, Loss: 208.79263992175908, Neurons: 201, Grad norm: 7.163393042738668\n",
      "Epoch 6255, Loss: 208.79263992175908, Neurons: 201, Grad norm: 7.163393042738668\n",
      "Epoch 6256, Loss: 208.79298549756822, Neurons: 201, Grad norm: 9.179515658239236\n",
      "Epoch 6256, Loss: 208.79298549756822, Neurons: 201, Grad norm: 9.179515658239236\n",
      "Epoch 6257, Loss: 208.79331848079354, Neurons: 201, Grad norm: 10.413252119707014\n",
      "Epoch 6257, Loss: 208.79331848079354, Neurons: 201, Grad norm: 10.413252119707014\n",
      "Epoch 6258, Loss: 208.79351297410378, Neurons: 201, Grad norm: 10.728889293378932\n",
      "Epoch 6258, Loss: 208.79351297410378, Neurons: 201, Grad norm: 10.728889293378932\n",
      "Epoch 6259, Loss: 208.79353867023403, Neurons: 201, Grad norm: 10.501566377110274\n",
      "Epoch 6259, Loss: 208.79353867023403, Neurons: 201, Grad norm: 10.501566377110274\n",
      "Epoch 6260, Loss: 208.79340843320122, Neurons: 201, Grad norm: 9.039260839264733\n",
      "Epoch 6260, Loss: 208.79340843320122, Neurons: 201, Grad norm: 9.039260839264733\n",
      "Epoch 6261, Loss: 208.7930085246798, Neurons: 201, Grad norm: 6.894158429300881\n",
      "Epoch 6261, Loss: 208.7930085246798, Neurons: 201, Grad norm: 6.894158429300881\n",
      "Epoch 6262, Loss: 208.79246713508, Neurons: 201, Grad norm: 4.21464476376919\n",
      "Epoch 6262, Loss: 208.79246713508, Neurons: 201, Grad norm: 4.21464476376919\n",
      "Epoch 6263, Loss: 208.79208600130218, Neurons: 201, Grad norm: 1.2682752262426642\n",
      "Epoch 6263, Loss: 208.79208600130218, Neurons: 201, Grad norm: 1.2682752262426642\n",
      "Epoch 6264, Loss: 208.79178297490398, Neurons: 201, Grad norm: 1.8302296039127877\n",
      "Epoch 6264, Loss: 208.79178297490398, Neurons: 201, Grad norm: 1.8302296039127877\n",
      "Epoch 6265, Loss: 208.7917510110998, Neurons: 201, Grad norm: 4.26953887170506\n",
      "Epoch 6265, Loss: 208.7917510110998, Neurons: 201, Grad norm: 4.26953887170506\n",
      "Epoch 6266, Loss: 208.7918165659243, Neurons: 201, Grad norm: 6.375861786870346\n",
      "Epoch 6266, Loss: 208.7918165659243, Neurons: 201, Grad norm: 6.375861786870346\n",
      "Epoch 6267, Loss: 208.7920291368946, Neurons: 201, Grad norm: 7.683954638609477\n",
      "Epoch 6267, Loss: 208.7920291368946, Neurons: 201, Grad norm: 7.683954638609477\n",
      "Epoch 6268, Loss: 208.7922018029365, Neurons: 201, Grad norm: 8.248361511177086\n",
      "Epoch 6268, Loss: 208.7922018029365, Neurons: 201, Grad norm: 8.248361511177086\n",
      "Epoch 6269, Loss: 208.7922555594032, Neurons: 201, Grad norm: 7.590408922573348\n",
      "Epoch 6269, Loss: 208.7922555594032, Neurons: 201, Grad norm: 7.590408922573348\n",
      "Epoch 6270, Loss: 208.7921037735881, Neurons: 201, Grad norm: 6.750785622192928\n",
      "Epoch 6270, Loss: 208.7921037735881, Neurons: 201, Grad norm: 6.750785622192928\n",
      "Epoch 6271, Loss: 208.79197101471547, Neurons: 201, Grad norm: 5.486726682450897\n",
      "Epoch 6271, Loss: 208.79197101471547, Neurons: 201, Grad norm: 5.486726682450897\n",
      "Epoch 6272, Loss: 208.79172522345027, Neurons: 201, Grad norm: 4.624603808804804\n",
      "Epoch 6272, Loss: 208.79172522345027, Neurons: 201, Grad norm: 4.624603808804804\n",
      "Epoch 6273, Loss: 208.79168464297126, Neurons: 201, Grad norm: 3.705741250729956\n",
      "Epoch 6273, Loss: 208.79168464297126, Neurons: 201, Grad norm: 3.705741250729956\n",
      "Epoch 6274, Loss: 208.79148683099152, Neurons: 201, Grad norm: 2.785455431050584\n",
      "Epoch 6274, Loss: 208.79148683099152, Neurons: 201, Grad norm: 2.785455431050584\n",
      "Epoch 6275, Loss: 208.7912339381621, Neurons: 201, Grad norm: 2.24190970674029\n",
      "Epoch 6275, Loss: 208.7912339381621, Neurons: 201, Grad norm: 2.24190970674029\n",
      "Epoch 6276, Loss: 208.79117669616303, Neurons: 201, Grad norm: 1.1624302482393891\n",
      "Epoch 6276, Loss: 208.79117669616303, Neurons: 201, Grad norm: 1.1624302482393891\n",
      "Epoch 6277, Loss: 208.79103455717163, Neurons: 201, Grad norm: 0.8384807233033499\n",
      "Epoch 6277, Loss: 208.79103455717163, Neurons: 201, Grad norm: 0.8384807233033499\n",
      "Epoch 6278, Loss: 208.79097032936014, Neurons: 201, Grad norm: 1.434624474474851\n",
      "Epoch 6278, Loss: 208.79097032936014, Neurons: 201, Grad norm: 1.434624474474851\n",
      "Epoch 6279, Loss: 208.7909648873723, Neurons: 201, Grad norm: 2.809791216539338\n",
      "Epoch 6279, Loss: 208.7909648873723, Neurons: 201, Grad norm: 2.809791216539338\n",
      "Epoch 6280, Loss: 208.7909083796917, Neurons: 201, Grad norm: 3.7092259590109147\n",
      "Epoch 6280, Loss: 208.7909083796917, Neurons: 201, Grad norm: 3.7092259590109147\n",
      "Epoch 6281, Loss: 208.7908921561654, Neurons: 201, Grad norm: 4.8806878304437715\n",
      "Epoch 6281, Loss: 208.7908921561654, Neurons: 201, Grad norm: 4.8806878304437715\n",
      "Epoch 6282, Loss: 208.79095817712633, Neurons: 201, Grad norm: 5.616146218609765\n",
      "Epoch 6282, Loss: 208.79095817712633, Neurons: 201, Grad norm: 5.616146218609765\n",
      "Epoch 6283, Loss: 208.79092834648492, Neurons: 201, Grad norm: 5.971715768813208\n",
      "Epoch 6283, Loss: 208.79092834648492, Neurons: 201, Grad norm: 5.971715768813208\n",
      "Epoch 6284, Loss: 208.79101704334116, Neurons: 201, Grad norm: 6.300057539861305\n",
      "Epoch 6284, Loss: 208.79101704334116, Neurons: 201, Grad norm: 6.300057539861305\n",
      "Epoch 6285, Loss: 208.79100468181534, Neurons: 201, Grad norm: 6.327032979533074\n",
      "Epoch 6285, Loss: 208.79100468181534, Neurons: 201, Grad norm: 6.327032979533074\n",
      "Epoch 6286, Loss: 208.79090838207887, Neurons: 201, Grad norm: 6.2547067039351445\n",
      "Epoch 6286, Loss: 208.79090838207887, Neurons: 201, Grad norm: 6.2547067039351445\n",
      "Epoch 6287, Loss: 208.7909516742894, Neurons: 201, Grad norm: 6.12278134132725\n",
      "Epoch 6287, Loss: 208.7909516742894, Neurons: 201, Grad norm: 6.12278134132725\n",
      "Epoch 6288, Loss: 208.79084251166253, Neurons: 201, Grad norm: 5.75141413242316\n",
      "Epoch 6288, Loss: 208.79084251166253, Neurons: 201, Grad norm: 5.75141413242316\n",
      "Epoch 6289, Loss: 208.79066347452004, Neurons: 201, Grad norm: 4.919913056678851\n",
      "Epoch 6289, Loss: 208.79066347452004, Neurons: 201, Grad norm: 4.919913056678851\n",
      "Epoch 6290, Loss: 208.7905250331925, Neurons: 201, Grad norm: 3.3121249314509775\n",
      "Epoch 6290, Loss: 208.7905250331925, Neurons: 201, Grad norm: 3.3121249314509775\n",
      "Epoch 6291, Loss: 208.79027454422143, Neurons: 201, Grad norm: 2.018312961521564\n",
      "Epoch 6291, Loss: 208.79027454422143, Neurons: 201, Grad norm: 2.018312961521564\n",
      "Epoch 6292, Loss: 208.7900723624222, Neurons: 201, Grad norm: 0.9178807919175661\n",
      "Epoch 6292, Loss: 208.7900723624222, Neurons: 201, Grad norm: 0.9178807919175661\n",
      "Epoch 6293, Loss: 208.79005438532533, Neurons: 201, Grad norm: 1.0285379858737638\n",
      "Epoch 6293, Loss: 208.79005438532533, Neurons: 201, Grad norm: 1.0285379858737638\n",
      "Epoch 6294, Loss: 208.78993487909753, Neurons: 201, Grad norm: 1.3731327328014122\n",
      "Epoch 6294, Loss: 208.78993487909753, Neurons: 201, Grad norm: 1.3731327328014122\n",
      "Epoch 6295, Loss: 208.7899080877724, Neurons: 201, Grad norm: 2.3205221762796464\n",
      "Epoch 6295, Loss: 208.7899080877724, Neurons: 201, Grad norm: 2.3205221762796464\n",
      "Epoch 6296, Loss: 208.78990446185287, Neurons: 201, Grad norm: 3.771582645761309\n",
      "Epoch 6296, Loss: 208.78990446185287, Neurons: 201, Grad norm: 3.771582645761309\n",
      "Epoch 6297, Loss: 208.78991822875847, Neurons: 201, Grad norm: 4.815174942233209\n",
      "Epoch 6297, Loss: 208.78991822875847, Neurons: 201, Grad norm: 4.815174942233209\n",
      "Epoch 6298, Loss: 208.78996834566502, Neurons: 201, Grad norm: 6.285382218687414\n",
      "Epoch 6298, Loss: 208.78996834566502, Neurons: 201, Grad norm: 6.285382218687414\n",
      "Epoch 6299, Loss: 208.7900849760685, Neurons: 201, Grad norm: 7.082128218356507\n",
      "Epoch 6299, Loss: 208.7900849760685, Neurons: 201, Grad norm: 7.082128218356507\n",
      "Epoch 6300, Loss: 208.7900926904216, Neurons: 201, Grad norm: 7.53529908817454\n",
      "Epoch 6300, Loss: 208.7900926904216, Neurons: 201, Grad norm: 7.53529908817454\n",
      "Epoch 6301, Loss: 208.79022544973466, Neurons: 201, Grad norm: 7.771923613303948\n",
      "Epoch 6301, Loss: 208.79022544973466, Neurons: 201, Grad norm: 7.771923613303948\n",
      "Epoch 6302, Loss: 208.7901749230534, Neurons: 201, Grad norm: 7.155053697840375\n",
      "Epoch 6302, Loss: 208.7901749230534, Neurons: 201, Grad norm: 7.155053697840375\n",
      "Epoch 6303, Loss: 208.7900330980707, Neurons: 201, Grad norm: 6.1663622638165805\n",
      "Epoch 6303, Loss: 208.7900330980707, Neurons: 201, Grad norm: 6.1663622638165805\n",
      "Epoch 6304, Loss: 208.78981685687623, Neurons: 201, Grad norm: 4.740283178333773\n",
      "Epoch 6304, Loss: 208.78981685687623, Neurons: 201, Grad norm: 4.740283178333773\n",
      "Epoch 6305, Loss: 208.78964840692953, Neurons: 201, Grad norm: 3.0400320240990153\n",
      "Epoch 6305, Loss: 208.78964840692953, Neurons: 201, Grad norm: 3.0400320240990153\n",
      "Epoch 6306, Loss: 208.7895446055533, Neurons: 201, Grad norm: 1.8391051190262329\n",
      "Epoch 6306, Loss: 208.7895446055533, Neurons: 201, Grad norm: 1.8391051190262329\n",
      "Epoch 6307, Loss: 208.78937581405864, Neurons: 201, Grad norm: 1.0428347418555466\n",
      "Epoch 6307, Loss: 208.78937581405864, Neurons: 201, Grad norm: 1.0428347418555466\n",
      "Epoch 6308, Loss: 208.78910844610508, Neurons: 201, Grad norm: 1.3264949980251357\n",
      "Epoch 6308, Loss: 208.78910844610508, Neurons: 201, Grad norm: 1.3264949980251357\n",
      "Epoch 6309, Loss: 208.7890081883381, Neurons: 201, Grad norm: 2.4568950266359053\n",
      "Epoch 6309, Loss: 208.7890081883381, Neurons: 201, Grad norm: 2.4568950266359053\n",
      "Epoch 6310, Loss: 208.7890453806745, Neurons: 201, Grad norm: 4.134364794299534\n",
      "Epoch 6310, Loss: 208.7890453806745, Neurons: 201, Grad norm: 4.134364794299534\n",
      "Epoch 6311, Loss: 208.78916777132852, Neurons: 201, Grad norm: 5.740198572217152\n",
      "Epoch 6311, Loss: 208.78916777132852, Neurons: 201, Grad norm: 5.740198572217152\n",
      "Epoch 6312, Loss: 208.78933749727204, Neurons: 201, Grad norm: 7.826207905458198\n",
      "Epoch 6312, Loss: 208.78933749727204, Neurons: 201, Grad norm: 7.826207905458198\n",
      "Epoch 6313, Loss: 208.78951182967683, Neurons: 201, Grad norm: 9.764034459907691\n",
      "Epoch 6313, Loss: 208.78951182967683, Neurons: 201, Grad norm: 9.764034459907691\n",
      "Epoch 6314, Loss: 208.78989940620477, Neurons: 201, Grad norm: 11.366942197212609\n",
      "Epoch 6314, Loss: 208.78989940620477, Neurons: 201, Grad norm: 11.366942197212609\n",
      "Epoch 6315, Loss: 208.79022096036155, Neurons: 201, Grad norm: 12.534902284506058\n",
      "Epoch 6315, Loss: 208.79022096036155, Neurons: 201, Grad norm: 12.534902284506058\n",
      "Epoch 6316, Loss: 208.79049535660775, Neurons: 201, Grad norm: 12.510684139915229\n",
      "Epoch 6316, Loss: 208.79049535660775, Neurons: 201, Grad norm: 12.510684139915229\n",
      "Epoch 6317, Loss: 208.79051937326957, Neurons: 201, Grad norm: 11.624055738810348\n",
      "Epoch 6317, Loss: 208.79051937326957, Neurons: 201, Grad norm: 11.624055738810348\n",
      "Epoch 6318, Loss: 208.7902018656605, Neurons: 201, Grad norm: 9.652301581069901\n",
      "Epoch 6318, Loss: 208.7902018656605, Neurons: 201, Grad norm: 9.652301581069901\n",
      "Epoch 6319, Loss: 208.78966927917745, Neurons: 201, Grad norm: 6.722910946836454\n",
      "Epoch 6319, Loss: 208.78966927917745, Neurons: 201, Grad norm: 6.722910946836454\n",
      "Epoch 6320, Loss: 208.78905025630996, Neurons: 201, Grad norm: 3.4228312333762285\n",
      "Epoch 6320, Loss: 208.78905025630996, Neurons: 201, Grad norm: 3.4228312333762285\n",
      "Epoch 6321, Loss: 208.78846876657641, Neurons: 201, Grad norm: 0.9138449162787109\n",
      "Epoch 6321, Loss: 208.78846876657641, Neurons: 201, Grad norm: 0.9138449162787109\n",
      "Epoch 6322, Loss: 208.78826515332887, Neurons: 201, Grad norm: 3.644844521946659\n",
      "Epoch 6322, Loss: 208.78826515332887, Neurons: 201, Grad norm: 3.644844521946659\n",
      "Epoch 6323, Loss: 208.78835100073974, Neurons: 201, Grad norm: 6.1910751788503555\n",
      "Epoch 6323, Loss: 208.78835100073974, Neurons: 201, Grad norm: 6.1910751788503555\n",
      "Epoch 6324, Loss: 208.78857031162374, Neurons: 201, Grad norm: 8.262677923137586\n",
      "Epoch 6324, Loss: 208.78857031162374, Neurons: 201, Grad norm: 8.262677923137586\n",
      "Epoch 6325, Loss: 208.78882442843314, Neurons: 201, Grad norm: 9.734635319118619\n",
      "Epoch 6325, Loss: 208.78882442843314, Neurons: 201, Grad norm: 9.734635319118619\n",
      "Epoch 6326, Loss: 208.78912690976352, Neurons: 201, Grad norm: 10.734937230066155\n",
      "Epoch 6326, Loss: 208.78912690976352, Neurons: 201, Grad norm: 10.734937230066155\n",
      "Epoch 6327, Loss: 208.78952118405357, Neurons: 201, Grad norm: 10.740533835530341\n",
      "Epoch 6327, Loss: 208.78952118405357, Neurons: 201, Grad norm: 10.740533835530341\n",
      "Epoch 6328, Loss: 208.7897673845157, Neurons: 201, Grad norm: 10.018972152601457\n",
      "Epoch 6328, Loss: 208.7897673845157, Neurons: 201, Grad norm: 10.018972152601457\n",
      "Epoch 6329, Loss: 208.78930333472988, Neurons: 201, Grad norm: 8.468519853531182\n",
      "Epoch 6329, Loss: 208.78930333472988, Neurons: 201, Grad norm: 8.468519853531182\n",
      "Epoch 6330, Loss: 208.78874732420002, Neurons: 201, Grad norm: 6.052061970021152\n",
      "Epoch 6330, Loss: 208.78874732420002, Neurons: 201, Grad norm: 6.052061970021152\n",
      "Epoch 6331, Loss: 208.78814441711006, Neurons: 201, Grad norm: 3.491490722358613\n",
      "Epoch 6331, Loss: 208.78814441711006, Neurons: 201, Grad norm: 3.491490722358613\n",
      "Epoch 6332, Loss: 208.78784710911177, Neurons: 201, Grad norm: 1.1263699371113778\n",
      "Epoch 6332, Loss: 208.78784710911177, Neurons: 201, Grad norm: 1.1263699371113778\n",
      "Epoch 6333, Loss: 208.78769313476295, Neurons: 201, Grad norm: 2.6826369656588773\n",
      "Epoch 6333, Loss: 208.78769313476295, Neurons: 201, Grad norm: 2.6826369656588773\n",
      "Epoch 6334, Loss: 208.78760698233222, Neurons: 201, Grad norm: 5.192785140780387\n",
      "Epoch 6334, Loss: 208.78760698233222, Neurons: 201, Grad norm: 5.192785140780387\n",
      "Epoch 6335, Loss: 208.78782242261516, Neurons: 201, Grad norm: 7.803613431705085\n",
      "Epoch 6335, Loss: 208.78782242261516, Neurons: 201, Grad norm: 7.803613431705085\n",
      "Epoch 6336, Loss: 208.78811777034954, Neurons: 201, Grad norm: 9.791379705595237\n",
      "Epoch 6336, Loss: 208.78811777034954, Neurons: 201, Grad norm: 9.791379705595237\n",
      "Epoch 6337, Loss: 208.78850661377984, Neurons: 201, Grad norm: 11.152141877370397\n",
      "Epoch 6337, Loss: 208.78850661377984, Neurons: 201, Grad norm: 11.152141877370397\n",
      "Epoch 6338, Loss: 208.78880832047173, Neurons: 201, Grad norm: 11.301334333189361\n",
      "Epoch 6338, Loss: 208.78880832047173, Neurons: 201, Grad norm: 11.301334333189361\n",
      "Epoch 6339, Loss: 208.78873599457225, Neurons: 201, Grad norm: 10.508912854810907\n",
      "Epoch 6339, Loss: 208.78873599457225, Neurons: 201, Grad norm: 10.508912854810907\n",
      "Epoch 6340, Loss: 208.7885128794037, Neurons: 201, Grad norm: 8.368141344323284\n",
      "Epoch 6340, Loss: 208.7885128794037, Neurons: 201, Grad norm: 8.368141344323284\n",
      "Epoch 6341, Loss: 208.78806115265962, Neurons: 201, Grad norm: 5.730750871963303\n",
      "Epoch 6341, Loss: 208.78806115265962, Neurons: 201, Grad norm: 5.730750871963303\n",
      "Epoch 6342, Loss: 208.7875671114361, Neurons: 201, Grad norm: 2.813852518519342\n",
      "Epoch 6342, Loss: 208.7875671114361, Neurons: 201, Grad norm: 2.813852518519342\n",
      "Epoch 6343, Loss: 208.78723362251384, Neurons: 201, Grad norm: 0.7013081250858546\n",
      "Epoch 6343, Loss: 208.78723362251384, Neurons: 201, Grad norm: 0.7013081250858546\n",
      "Epoch 6344, Loss: 208.7869916768631, Neurons: 201, Grad norm: 2.533920003498417\n",
      "Epoch 6344, Loss: 208.7869916768631, Neurons: 201, Grad norm: 2.533920003498417\n",
      "Epoch 6345, Loss: 208.7869627822091, Neurons: 201, Grad norm: 4.916239521568768\n",
      "Epoch 6345, Loss: 208.7869627822091, Neurons: 201, Grad norm: 4.916239521568768\n",
      "Epoch 6346, Loss: 208.78719187111062, Neurons: 201, Grad norm: 6.795474467521957\n",
      "Epoch 6346, Loss: 208.78719187111062, Neurons: 201, Grad norm: 6.795474467521957\n",
      "Epoch 6347, Loss: 208.78743467893975, Neurons: 201, Grad norm: 8.257644788622445\n",
      "Epoch 6347, Loss: 208.78743467893975, Neurons: 201, Grad norm: 8.257644788622445\n",
      "Epoch 6348, Loss: 208.78766310649686, Neurons: 201, Grad norm: 9.36191568492931\n",
      "Epoch 6348, Loss: 208.78766310649686, Neurons: 201, Grad norm: 9.36191568492931\n",
      "Epoch 6349, Loss: 208.787847190596, Neurons: 201, Grad norm: 9.113339246001624\n",
      "Epoch 6349, Loss: 208.787847190596, Neurons: 201, Grad norm: 9.113339246001624\n",
      "Epoch 6350, Loss: 208.78766900413362, Neurons: 201, Grad norm: 8.640481242893697\n",
      "Epoch 6350, Loss: 208.78766900413362, Neurons: 201, Grad norm: 8.640481242893697\n",
      "Epoch 6351, Loss: 208.7873961767998, Neurons: 201, Grad norm: 7.0269733043612215\n",
      "Epoch 6351, Loss: 208.7873961767998, Neurons: 201, Grad norm: 7.0269733043612215\n",
      "Epoch 6352, Loss: 208.78708569393052, Neurons: 201, Grad norm: 5.08372136718232\n",
      "Epoch 6352, Loss: 208.78708569393052, Neurons: 201, Grad norm: 5.08372136718232\n",
      "Epoch 6353, Loss: 208.78662506994817, Neurons: 201, Grad norm: 2.8530856184018267\n",
      "Epoch 6353, Loss: 208.78662506994817, Neurons: 201, Grad norm: 2.8530856184018267\n",
      "Epoch 6354, Loss: 208.78633840963585, Neurons: 201, Grad norm: 0.884315159232923\n",
      "Epoch 6354, Loss: 208.78633840963585, Neurons: 201, Grad norm: 0.884315159232923\n",
      "Epoch 6355, Loss: 208.78620023889877, Neurons: 201, Grad norm: 1.9259693875986148\n",
      "Epoch 6355, Loss: 208.78620023889877, Neurons: 201, Grad norm: 1.9259693875986148\n",
      "Epoch 6356, Loss: 208.7861768291752, Neurons: 201, Grad norm: 3.5828884541729487\n",
      "Epoch 6356, Loss: 208.7861768291752, Neurons: 201, Grad norm: 3.5828884541729487\n",
      "Epoch 6357, Loss: 208.78621718815296, Neurons: 201, Grad norm: 5.030528799710473\n",
      "Epoch 6357, Loss: 208.78621718815296, Neurons: 201, Grad norm: 5.030528799710473\n",
      "Epoch 6358, Loss: 208.7862708016009, Neurons: 201, Grad norm: 5.839860096325305\n",
      "Epoch 6358, Loss: 208.7862708016009, Neurons: 201, Grad norm: 5.839860096325305\n",
      "Epoch 6359, Loss: 208.78633063542244, Neurons: 201, Grad norm: 6.7692920632734594\n",
      "Epoch 6359, Loss: 208.78633063542244, Neurons: 201, Grad norm: 6.7692920632734594\n",
      "Epoch 6360, Loss: 208.78636084160303, Neurons: 201, Grad norm: 6.800732608412481\n",
      "Epoch 6360, Loss: 208.78636084160303, Neurons: 201, Grad norm: 6.800732608412481\n",
      "Epoch 6361, Loss: 208.78634709672974, Neurons: 201, Grad norm: 6.463540702419722\n",
      "Epoch 6361, Loss: 208.78634709672974, Neurons: 201, Grad norm: 6.463540702419722\n",
      "Epoch 6362, Loss: 208.78623114295658, Neurons: 201, Grad norm: 5.323913600217785\n",
      "Epoch 6362, Loss: 208.78623114295658, Neurons: 201, Grad norm: 5.323913600217785\n",
      "Epoch 6363, Loss: 208.78602202005666, Neurons: 201, Grad norm: 3.974130254487074\n",
      "Epoch 6363, Loss: 208.78602202005666, Neurons: 201, Grad norm: 3.974130254487074\n",
      "Epoch 6364, Loss: 208.7857575724684, Neurons: 201, Grad norm: 2.601172012184704\n",
      "Epoch 6364, Loss: 208.7857575724684, Neurons: 201, Grad norm: 2.601172012184704\n",
      "Epoch 6365, Loss: 208.78556112491063, Neurons: 201, Grad norm: 1.2011639674843997\n",
      "Epoch 6365, Loss: 208.78556112491063, Neurons: 201, Grad norm: 1.2011639674843997\n",
      "Epoch 6366, Loss: 208.78536341658958, Neurons: 201, Grad norm: 0.9402880638491392\n",
      "Epoch 6366, Loss: 208.78536341658958, Neurons: 201, Grad norm: 0.9402880638491392\n",
      "Epoch 6367, Loss: 208.78530579097108, Neurons: 201, Grad norm: 2.11319908559172\n",
      "Epoch 6367, Loss: 208.78530579097108, Neurons: 201, Grad norm: 2.11319908559172\n",
      "Epoch 6368, Loss: 208.78526787010267, Neurons: 201, Grad norm: 3.374576759311475\n",
      "Epoch 6368, Loss: 208.78526787010267, Neurons: 201, Grad norm: 3.374576759311475\n",
      "Epoch 6369, Loss: 208.78529513542816, Neurons: 201, Grad norm: 4.6557422958993495\n",
      "Epoch 6369, Loss: 208.78529513542816, Neurons: 201, Grad norm: 4.6557422958993495\n",
      "Epoch 6370, Loss: 208.78534257623588, Neurons: 201, Grad norm: 5.611442299682631\n",
      "Epoch 6370, Loss: 208.78534257623588, Neurons: 201, Grad norm: 5.611442299682631\n",
      "Epoch 6371, Loss: 208.7854256978936, Neurons: 201, Grad norm: 6.440887430404741\n",
      "Epoch 6371, Loss: 208.7854256978936, Neurons: 201, Grad norm: 6.440887430404741\n",
      "Epoch 6372, Loss: 208.7855361856279, Neurons: 201, Grad norm: 6.887173940889345\n",
      "Epoch 6372, Loss: 208.7855361856279, Neurons: 201, Grad norm: 6.887173940889345\n",
      "Epoch 6373, Loss: 208.78554414107174, Neurons: 201, Grad norm: 6.378105387365062\n",
      "Epoch 6373, Loss: 208.78554414107174, Neurons: 201, Grad norm: 6.378105387365062\n",
      "Epoch 6374, Loss: 208.78547785209733, Neurons: 201, Grad norm: 5.879040380726795\n",
      "Epoch 6374, Loss: 208.78547785209733, Neurons: 201, Grad norm: 5.879040380726795\n",
      "Epoch 6375, Loss: 208.78530616281236, Neurons: 201, Grad norm: 4.471597044279838\n",
      "Epoch 6375, Loss: 208.78530616281236, Neurons: 201, Grad norm: 4.471597044279838\n",
      "Epoch 6376, Loss: 208.78499577141054, Neurons: 201, Grad norm: 3.210153599149823\n",
      "Epoch 6376, Loss: 208.78499577141054, Neurons: 201, Grad norm: 3.210153599149823\n",
      "Epoch 6377, Loss: 208.78473921261138, Neurons: 201, Grad norm: 1.959285260806853\n",
      "Epoch 6377, Loss: 208.78473921261138, Neurons: 201, Grad norm: 1.959285260806853\n",
      "Epoch 6378, Loss: 208.78468289241528, Neurons: 201, Grad norm: 1.6021782776137847\n",
      "Epoch 6378, Loss: 208.78468289241528, Neurons: 201, Grad norm: 1.6021782776137847\n",
      "Epoch 6379, Loss: 208.78478124326207, Neurons: 201, Grad norm: 2.455691565269035\n",
      "Epoch 6379, Loss: 208.78478124326207, Neurons: 201, Grad norm: 2.455691565269035\n",
      "Epoch 6380, Loss: 208.78469445433174, Neurons: 201, Grad norm: 4.0772105621312695\n",
      "Epoch 6380, Loss: 208.78469445433174, Neurons: 201, Grad norm: 4.0772105621312695\n",
      "Epoch 6381, Loss: 208.78456762276437, Neurons: 201, Grad norm: 6.30625788226169\n",
      "Epoch 6381, Loss: 208.78456762276437, Neurons: 201, Grad norm: 6.30625788226169\n",
      "Epoch 6382, Loss: 208.78471502957768, Neurons: 201, Grad norm: 8.222882104081176\n",
      "Epoch 6382, Loss: 208.78471502957768, Neurons: 201, Grad norm: 8.222882104081176\n",
      "Epoch 6383, Loss: 208.7851478008854, Neurons: 201, Grad norm: 9.905106177273755\n",
      "Epoch 6383, Loss: 208.7851478008854, Neurons: 201, Grad norm: 9.905106177273755\n",
      "Epoch 6384, Loss: 208.7854774548166, Neurons: 201, Grad norm: 10.06179291335437\n",
      "Epoch 6384, Loss: 208.7854774548166, Neurons: 201, Grad norm: 10.06179291335437\n",
      "Epoch 6385, Loss: 208.78540068791455, Neurons: 201, Grad norm: 9.32986397334047\n",
      "Epoch 6385, Loss: 208.78540068791455, Neurons: 201, Grad norm: 9.32986397334047\n",
      "Epoch 6386, Loss: 208.78510746369642, Neurons: 201, Grad norm: 7.809012291412554\n",
      "Epoch 6386, Loss: 208.78510746369642, Neurons: 201, Grad norm: 7.809012291412554\n",
      "Epoch 6387, Loss: 208.7848279257027, Neurons: 201, Grad norm: 5.6224987987862844\n",
      "Epoch 6387, Loss: 208.7848279257027, Neurons: 201, Grad norm: 5.6224987987862844\n",
      "Epoch 6388, Loss: 208.7845292407037, Neurons: 201, Grad norm: 3.3443559151620805\n",
      "Epoch 6388, Loss: 208.7845292407037, Neurons: 201, Grad norm: 3.3443559151620805\n",
      "Epoch 6389, Loss: 208.78416322158327, Neurons: 201, Grad norm: 1.4943075168301085\n",
      "Epoch 6389, Loss: 208.78416322158327, Neurons: 201, Grad norm: 1.4943075168301085\n",
      "Epoch 6390, Loss: 208.78385275497078, Neurons: 201, Grad norm: 1.7190678158588752\n",
      "Epoch 6390, Loss: 208.78385275497078, Neurons: 201, Grad norm: 1.7190678158588752\n",
      "Epoch 6391, Loss: 208.78359590773832, Neurons: 201, Grad norm: 3.3558237204901693\n",
      "Epoch 6391, Loss: 208.78359590773832, Neurons: 201, Grad norm: 3.3558237204901693\n",
      "Epoch 6392, Loss: 208.78364019624368, Neurons: 201, Grad norm: 5.061226478926109\n",
      "Epoch 6392, Loss: 208.78364019624368, Neurons: 201, Grad norm: 5.061226478926109\n",
      "Epoch 6393, Loss: 208.7839813014789, Neurons: 201, Grad norm: 6.27757081595976\n",
      "Epoch 6393, Loss: 208.7839813014789, Neurons: 201, Grad norm: 6.27757081595976\n",
      "Epoch 6394, Loss: 208.7842064884534, Neurons: 201, Grad norm: 7.650658802511083\n",
      "Epoch 6394, Loss: 208.7842064884534, Neurons: 201, Grad norm: 7.650658802511083\n",
      "Epoch 6395, Loss: 208.78403836139907, Neurons: 201, Grad norm: 8.328644240416294\n",
      "Epoch 6395, Loss: 208.78403836139907, Neurons: 201, Grad norm: 8.328644240416294\n",
      "Epoch 6396, Loss: 208.78402446927066, Neurons: 201, Grad norm: 8.80398074151821\n",
      "Epoch 6396, Loss: 208.78402446927066, Neurons: 201, Grad norm: 8.80398074151821\n",
      "Epoch 6397, Loss: 208.78402896604126, Neurons: 201, Grad norm: 8.126931906017747\n",
      "Epoch 6397, Loss: 208.78402896604126, Neurons: 201, Grad norm: 8.126931906017747\n",
      "Epoch 6398, Loss: 208.78382740599744, Neurons: 201, Grad norm: 6.5047689499976835\n",
      "Epoch 6398, Loss: 208.78382740599744, Neurons: 201, Grad norm: 6.5047689499976835\n",
      "Epoch 6399, Loss: 208.78338782246252, Neurons: 201, Grad norm: 4.24565034726497\n",
      "Epoch 6399, Loss: 208.78338782246252, Neurons: 201, Grad norm: 4.24565034726497\n",
      "Epoch 6400, Loss: 208.78296945564912, Neurons: 201, Grad norm: 2.2929779157379264\n",
      "Epoch 6400, Loss: 208.78296945564912, Neurons: 201, Grad norm: 2.2929779157379264\n",
      "Epoch 6401, Loss: 208.78285678839325, Neurons: 201, Grad norm: 0.8427749176745223\n",
      "Epoch 6401, Loss: 208.78285678839325, Neurons: 201, Grad norm: 0.8427749176745223\n",
      "Epoch 6402, Loss: 208.78264237874993, Neurons: 201, Grad norm: 1.8759793066385293\n",
      "Epoch 6402, Loss: 208.78264237874993, Neurons: 201, Grad norm: 1.8759793066385293\n",
      "Epoch 6403, Loss: 208.7824696815404, Neurons: 201, Grad norm: 3.258649612957503\n",
      "Epoch 6403, Loss: 208.7824696815404, Neurons: 201, Grad norm: 3.258649612957503\n",
      "Epoch 6404, Loss: 208.78250683626115, Neurons: 201, Grad norm: 4.719806421625907\n",
      "Epoch 6404, Loss: 208.78250683626115, Neurons: 201, Grad norm: 4.719806421625907\n",
      "Epoch 6405, Loss: 208.78253185270034, Neurons: 201, Grad norm: 6.26094106483494\n",
      "Epoch 6405, Loss: 208.78253185270034, Neurons: 201, Grad norm: 6.26094106483494\n",
      "Epoch 6406, Loss: 208.78266147825025, Neurons: 201, Grad norm: 7.732932762062834\n",
      "Epoch 6406, Loss: 208.78266147825025, Neurons: 201, Grad norm: 7.732932762062834\n",
      "Epoch 6407, Loss: 208.78295971345085, Neurons: 201, Grad norm: 9.614180746587543\n",
      "Epoch 6407, Loss: 208.78295971345085, Neurons: 201, Grad norm: 9.614180746587543\n",
      "Epoch 6408, Loss: 208.783143352181, Neurons: 201, Grad norm: 10.59905680009871\n",
      "Epoch 6408, Loss: 208.783143352181, Neurons: 201, Grad norm: 10.59905680009871\n",
      "Epoch 6409, Loss: 208.78323064164985, Neurons: 201, Grad norm: 11.437633772217723\n",
      "Epoch 6409, Loss: 208.78323064164985, Neurons: 201, Grad norm: 11.437633772217723\n",
      "Epoch 6410, Loss: 208.78337705614032, Neurons: 201, Grad norm: 10.6164427743405\n",
      "Epoch 6410, Loss: 208.78337705614032, Neurons: 201, Grad norm: 10.6164427743405\n",
      "Epoch 6411, Loss: 208.78322423438453, Neurons: 201, Grad norm: 9.002873204829527\n",
      "Epoch 6411, Loss: 208.78322423438453, Neurons: 201, Grad norm: 9.002873204829527\n",
      "Epoch 6412, Loss: 208.7826559624725, Neurons: 201, Grad norm: 6.147965517564913\n",
      "Epoch 6412, Loss: 208.7826559624725, Neurons: 201, Grad norm: 6.147965517564913\n",
      "Epoch 6413, Loss: 208.78218174096543, Neurons: 201, Grad norm: 3.267785394181953\n",
      "Epoch 6413, Loss: 208.78218174096543, Neurons: 201, Grad norm: 3.267785394181953\n",
      "Epoch 6414, Loss: 208.7816923542567, Neurons: 201, Grad norm: 0.9255053945739454\n",
      "Epoch 6414, Loss: 208.7816923542567, Neurons: 201, Grad norm: 0.9255053945739454\n",
      "Epoch 6415, Loss: 208.78140298445052, Neurons: 201, Grad norm: 2.9925372311012075\n",
      "Epoch 6415, Loss: 208.78140298445052, Neurons: 201, Grad norm: 2.9925372311012075\n",
      "Epoch 6416, Loss: 208.78130706741416, Neurons: 201, Grad norm: 5.148930192946448\n",
      "Epoch 6416, Loss: 208.78130706741416, Neurons: 201, Grad norm: 5.148930192946448\n",
      "Epoch 6417, Loss: 208.7813648265972, Neurons: 201, Grad norm: 6.802511962153147\n",
      "Epoch 6417, Loss: 208.7813648265972, Neurons: 201, Grad norm: 6.802511962153147\n",
      "Epoch 6418, Loss: 208.78159791580532, Neurons: 201, Grad norm: 8.656313138836214\n",
      "Epoch 6418, Loss: 208.78159791580532, Neurons: 201, Grad norm: 8.656313138836214\n",
      "Epoch 6419, Loss: 208.78187659820824, Neurons: 201, Grad norm: 9.630308512601209\n",
      "Epoch 6419, Loss: 208.78187659820824, Neurons: 201, Grad norm: 9.630308512601209\n",
      "Epoch 6420, Loss: 208.7819632779923, Neurons: 201, Grad norm: 10.839865905657746\n",
      "Epoch 6420, Loss: 208.7819632779923, Neurons: 201, Grad norm: 10.839865905657746\n",
      "Epoch 6421, Loss: 208.78177709676308, Neurons: 201, Grad norm: 10.451603307621395\n",
      "Epoch 6421, Loss: 208.78177709676308, Neurons: 201, Grad norm: 10.451603307621395\n",
      "Epoch 6422, Loss: 208.7810602323495, Neurons: 201, Grad norm: 10.006516437012\n",
      "Epoch 6422, Loss: 208.7810602323495, Neurons: 201, Grad norm: 10.006516437012\n",
      "Epoch 6423, Loss: 208.7802885752607, Neurons: 201, Grad norm: 8.099673896430907\n",
      "Epoch 6423, Loss: 208.7802885752607, Neurons: 201, Grad norm: 8.099673896430907\n",
      "Epoch 6424, Loss: 208.7795241915711, Neurons: 201, Grad norm: 6.016344690799397\n",
      "Epoch 6424, Loss: 208.7795241915711, Neurons: 201, Grad norm: 6.016344690799397\n",
      "Epoch 6425, Loss: 208.7790044294889, Neurons: 201, Grad norm: 2.6141944451290446\n",
      "Epoch 6425, Loss: 208.7790044294889, Neurons: 201, Grad norm: 2.6141944451290446\n",
      "Epoch 6426, Loss: 208.77841335594204, Neurons: 201, Grad norm: 1.6750250821328037\n",
      "Epoch 6426, Loss: 208.77841335594204, Neurons: 201, Grad norm: 1.6750250821328037\n",
      "Epoch 6427, Loss: 208.77796870434014, Neurons: 201, Grad norm: 4.78812786519643\n",
      "Epoch 6427, Loss: 208.77796870434014, Neurons: 201, Grad norm: 4.78812786519643\n",
      "Epoch 6428, Loss: 208.77797031966668, Neurons: 201, Grad norm: 7.208292859420024\n",
      "Epoch 6428, Loss: 208.77797031966668, Neurons: 201, Grad norm: 7.208292859420024\n",
      "Epoch 6429, Loss: 208.77821627284712, Neurons: 201, Grad norm: 7.98561019683249\n",
      "Epoch 6429, Loss: 208.77821627284712, Neurons: 201, Grad norm: 7.98561019683249\n",
      "Epoch 6430, Loss: 208.77803070708978, Neurons: 201, Grad norm: 7.090386761467375\n",
      "Epoch 6430, Loss: 208.77803070708978, Neurons: 201, Grad norm: 7.090386761467375\n",
      "Epoch 6431, Loss: 208.7774272814783, Neurons: 201, Grad norm: 5.874592071568493\n",
      "Epoch 6431, Loss: 208.7774272814783, Neurons: 201, Grad norm: 5.874592071568493\n",
      "Epoch 6432, Loss: 208.77700530810387, Neurons: 201, Grad norm: 3.8592497999537807\n",
      "Epoch 6432, Loss: 208.77700530810387, Neurons: 201, Grad norm: 3.8592497999537807\n",
      "Epoch 6433, Loss: 208.77670738839714, Neurons: 201, Grad norm: 2.4272810563523564\n",
      "Epoch 6433, Loss: 208.77670738839714, Neurons: 201, Grad norm: 2.4272810563523564\n",
      "Epoch 6434, Loss: 208.77632434912857, Neurons: 201, Grad norm: 1.0298134381215835\n",
      "Epoch 6434, Loss: 208.77632434912857, Neurons: 201, Grad norm: 1.0298134381215835\n",
      "Epoch 6435, Loss: 208.77590651348862, Neurons: 201, Grad norm: 1.3532546778358672\n",
      "Epoch 6435, Loss: 208.77590651348862, Neurons: 201, Grad norm: 1.3532546778358672\n",
      "Epoch 6436, Loss: 208.77571896714667, Neurons: 201, Grad norm: 2.6365346117132695\n",
      "Epoch 6436, Loss: 208.77571896714667, Neurons: 201, Grad norm: 2.6365346117132695\n",
      "Epoch 6437, Loss: 208.77574240978126, Neurons: 201, Grad norm: 3.6237253151806983\n",
      "Epoch 6437, Loss: 208.77574240978126, Neurons: 201, Grad norm: 3.6237253151806983\n",
      "Epoch 6438, Loss: 208.77579714584485, Neurons: 201, Grad norm: 4.445723577140047\n",
      "Epoch 6438, Loss: 208.77579714584485, Neurons: 201, Grad norm: 4.445723577140047\n",
      "Epoch 6439, Loss: 208.77554190674041, Neurons: 201, Grad norm: 5.1240206729105555\n",
      "Epoch 6439, Loss: 208.77554190674041, Neurons: 201, Grad norm: 5.1240206729105555\n",
      "Epoch 6440, Loss: 208.77531367670335, Neurons: 201, Grad norm: 5.432137615073938\n",
      "Epoch 6440, Loss: 208.77531367670335, Neurons: 201, Grad norm: 5.432137615073938\n",
      "Epoch 6441, Loss: 208.77515499166523, Neurons: 201, Grad norm: 5.355388591837084\n",
      "Epoch 6441, Loss: 208.77515499166523, Neurons: 201, Grad norm: 5.355388591837084\n",
      "Epoch 6442, Loss: 208.77497133461324, Neurons: 201, Grad norm: 4.835795324631437\n",
      "Epoch 6442, Loss: 208.77497133461324, Neurons: 201, Grad norm: 4.835795324631437\n",
      "Epoch 6443, Loss: 208.7746939862468, Neurons: 201, Grad norm: 3.610751551894996\n",
      "Epoch 6443, Loss: 208.7746939862468, Neurons: 201, Grad norm: 3.610751551894996\n",
      "Epoch 6444, Loss: 208.77433064322926, Neurons: 201, Grad norm: 2.3777176287521713\n",
      "Epoch 6444, Loss: 208.77433064322926, Neurons: 201, Grad norm: 2.3777176287521713\n",
      "Epoch 6445, Loss: 208.77415002463266, Neurons: 201, Grad norm: 1.352232288628996\n",
      "Epoch 6445, Loss: 208.77415002463266, Neurons: 201, Grad norm: 1.352232288628996\n",
      "Epoch 6446, Loss: 208.77401973697374, Neurons: 201, Grad norm: 1.1789299983732777\n",
      "Epoch 6446, Loss: 208.77401973697374, Neurons: 201, Grad norm: 1.1789299983732777\n",
      "Epoch 6447, Loss: 208.77378235816684, Neurons: 201, Grad norm: 1.3890351429944638\n",
      "Epoch 6447, Loss: 208.77378235816684, Neurons: 201, Grad norm: 1.3890351429944638\n",
      "Epoch 6448, Loss: 208.77355574380402, Neurons: 201, Grad norm: 1.8349662574786068\n",
      "Epoch 6448, Loss: 208.77355574380402, Neurons: 201, Grad norm: 1.8349662574786068\n",
      "Epoch 6449, Loss: 208.77343748392434, Neurons: 201, Grad norm: 2.5795692220920357\n",
      "Epoch 6449, Loss: 208.77343748392434, Neurons: 201, Grad norm: 2.5795692220920357\n",
      "Epoch 6450, Loss: 208.7734160907003, Neurons: 201, Grad norm: 3.517193933415096\n",
      "Epoch 6450, Loss: 208.7734160907003, Neurons: 201, Grad norm: 3.517193933415096\n",
      "Epoch 6451, Loss: 208.77342605308837, Neurons: 201, Grad norm: 4.808877873154171\n",
      "Epoch 6451, Loss: 208.77342605308837, Neurons: 201, Grad norm: 4.808877873154171\n",
      "Epoch 6452, Loss: 208.773278798496, Neurons: 201, Grad norm: 6.518195820280687\n",
      "Epoch 6452, Loss: 208.773278798496, Neurons: 201, Grad norm: 6.518195820280687\n",
      "Epoch 6453, Loss: 208.77325555633024, Neurons: 201, Grad norm: 8.447415979084557\n",
      "Epoch 6453, Loss: 208.77325555633024, Neurons: 201, Grad norm: 8.447415979084557\n",
      "Epoch 6454, Loss: 208.77340736370445, Neurons: 201, Grad norm: 9.524063103345522\n",
      "Epoch 6454, Loss: 208.77340736370445, Neurons: 201, Grad norm: 9.524063103345522\n",
      "Epoch 6455, Loss: 208.77353823400583, Neurons: 201, Grad norm: 10.68840838072613\n",
      "Epoch 6455, Loss: 208.77353823400583, Neurons: 201, Grad norm: 10.68840838072613\n",
      "Epoch 6456, Loss: 208.77361609380958, Neurons: 201, Grad norm: 10.315081424081944\n",
      "Epoch 6456, Loss: 208.77361609380958, Neurons: 201, Grad norm: 10.315081424081944\n",
      "Epoch 6457, Loss: 208.77351573188477, Neurons: 201, Grad norm: 10.057285466070084\n",
      "Epoch 6457, Loss: 208.77351573188477, Neurons: 201, Grad norm: 10.057285466070084\n",
      "Epoch 6458, Loss: 208.77325826849747, Neurons: 201, Grad norm: 8.393147580085646\n",
      "Epoch 6458, Loss: 208.77325826849747, Neurons: 201, Grad norm: 8.393147580085646\n",
      "Epoch 6459, Loss: 208.77282992288644, Neurons: 201, Grad norm: 7.296598724136759\n",
      "Epoch 6459, Loss: 208.77282992288644, Neurons: 201, Grad norm: 7.296598724136759\n",
      "Epoch 6460, Loss: 208.77227006440532, Neurons: 201, Grad norm: 5.047835238704059\n",
      "Epoch 6460, Loss: 208.77227006440532, Neurons: 201, Grad norm: 5.047835238704059\n",
      "Epoch 6461, Loss: 208.77165140181623, Neurons: 201, Grad norm: 3.4368877645518787\n",
      "Epoch 6461, Loss: 208.77165140181623, Neurons: 201, Grad norm: 3.4368877645518787\n",
      "Epoch 6462, Loss: 208.7712326809241, Neurons: 201, Grad norm: 1.4935495652457365\n",
      "Epoch 6462, Loss: 208.7712326809241, Neurons: 201, Grad norm: 1.4935495652457365\n",
      "Epoch 6463, Loss: 208.77096249373005, Neurons: 201, Grad norm: 1.7471393326755318\n",
      "Epoch 6463, Loss: 208.77096249373005, Neurons: 201, Grad norm: 1.7471393326755318\n",
      "Epoch 6464, Loss: 208.77065225688753, Neurons: 201, Grad norm: 3.909134136673387\n",
      "Epoch 6464, Loss: 208.77065225688753, Neurons: 201, Grad norm: 3.909134136673387\n",
      "Epoch 6465, Loss: 208.77047852537243, Neurons: 201, Grad norm: 5.624396495245001\n",
      "Epoch 6465, Loss: 208.77047852537243, Neurons: 201, Grad norm: 5.624396495245001\n",
      "Epoch 6466, Loss: 208.77047636551941, Neurons: 201, Grad norm: 7.7283915224118\n",
      "Epoch 6466, Loss: 208.77047636551941, Neurons: 201, Grad norm: 7.7283915224118\n",
      "Epoch 6467, Loss: 208.77054292381746, Neurons: 201, Grad norm: 8.945738498348126\n",
      "Epoch 6467, Loss: 208.77054292381746, Neurons: 201, Grad norm: 8.945738498348126\n",
      "Epoch 6468, Loss: 208.77072632249238, Neurons: 201, Grad norm: 10.001246421843764\n",
      "Epoch 6468, Loss: 208.77072632249238, Neurons: 201, Grad norm: 10.001246421843764\n",
      "Epoch 6469, Loss: 208.77083095137618, Neurons: 201, Grad norm: 10.500753005099881\n",
      "Epoch 6469, Loss: 208.77083095137618, Neurons: 201, Grad norm: 10.500753005099881\n",
      "Epoch 6470, Loss: 208.77098382782162, Neurons: 201, Grad norm: 10.85923618692101\n",
      "Epoch 6470, Loss: 208.77098382782162, Neurons: 201, Grad norm: 10.85923618692101\n",
      "Epoch 6471, Loss: 208.7709639193979, Neurons: 201, Grad norm: 11.051604476751589\n",
      "Epoch 6471, Loss: 208.7709639193979, Neurons: 201, Grad norm: 11.051604476751589\n",
      "Epoch 6472, Loss: 208.77069759404668, Neurons: 201, Grad norm: 10.473493562389592\n",
      "Epoch 6472, Loss: 208.77069759404668, Neurons: 201, Grad norm: 10.473493562389592\n",
      "Epoch 6473, Loss: 208.7704097585711, Neurons: 201, Grad norm: 9.036594181283228\n",
      "Epoch 6473, Loss: 208.7704097585711, Neurons: 201, Grad norm: 9.036594181283228\n",
      "Epoch 6474, Loss: 208.77000484157807, Neurons: 201, Grad norm: 7.315830040662945\n",
      "Epoch 6474, Loss: 208.77000484157807, Neurons: 201, Grad norm: 7.315830040662945\n",
      "Epoch 6475, Loss: 208.769556847696, Neurons: 201, Grad norm: 4.855589810336444\n",
      "Epoch 6475, Loss: 208.769556847696, Neurons: 201, Grad norm: 4.855589810336444\n",
      "Epoch 6476, Loss: 208.76910841975112, Neurons: 201, Grad norm: 2.0054666810738326\n",
      "Epoch 6476, Loss: 208.76910841975112, Neurons: 201, Grad norm: 2.0054666810738326\n",
      "Epoch 6477, Loss: 208.76872701602213, Neurons: 201, Grad norm: 0.9847676180349907\n",
      "Epoch 6477, Loss: 208.76872701602213, Neurons: 201, Grad norm: 0.9847676180349907\n",
      "Epoch 6478, Loss: 208.7685971676132, Neurons: 201, Grad norm: 3.0746553185317524\n",
      "Epoch 6478, Loss: 208.7685971676132, Neurons: 201, Grad norm: 3.0746553185317524\n",
      "Epoch 6479, Loss: 208.76858991998174, Neurons: 201, Grad norm: 4.732354053985484\n",
      "Epoch 6479, Loss: 208.76858991998174, Neurons: 201, Grad norm: 4.732354053985484\n",
      "Epoch 6480, Loss: 208.76855850545397, Neurons: 201, Grad norm: 6.1026874200396275\n",
      "Epoch 6480, Loss: 208.76855850545397, Neurons: 201, Grad norm: 6.1026874200396275\n",
      "Epoch 6481, Loss: 208.76858367172053, Neurons: 201, Grad norm: 7.196285715146979\n",
      "Epoch 6481, Loss: 208.76858367172053, Neurons: 201, Grad norm: 7.196285715146979\n",
      "Epoch 6482, Loss: 208.76871450966766, Neurons: 201, Grad norm: 8.09319958523081\n",
      "Epoch 6482, Loss: 208.76871450966766, Neurons: 201, Grad norm: 8.09319958523081\n",
      "Epoch 6483, Loss: 208.76890080438932, Neurons: 201, Grad norm: 8.629702890335603\n",
      "Epoch 6483, Loss: 208.76890080438932, Neurons: 201, Grad norm: 8.629702890335603\n",
      "Epoch 6484, Loss: 208.76887580186352, Neurons: 201, Grad norm: 8.530764863222064\n",
      "Epoch 6484, Loss: 208.76887580186352, Neurons: 201, Grad norm: 8.530764863222064\n",
      "Epoch 6485, Loss: 208.76875812161325, Neurons: 201, Grad norm: 8.226873356723152\n",
      "Epoch 6485, Loss: 208.76875812161325, Neurons: 201, Grad norm: 8.226873356723152\n",
      "Epoch 6486, Loss: 208.76845307986034, Neurons: 201, Grad norm: 7.105082354695799\n",
      "Epoch 6486, Loss: 208.76845307986034, Neurons: 201, Grad norm: 7.105082354695799\n",
      "Epoch 6487, Loss: 208.76808226776893, Neurons: 201, Grad norm: 5.93728381983452\n",
      "Epoch 6487, Loss: 208.76808226776893, Neurons: 201, Grad norm: 5.93728381983452\n",
      "Epoch 6488, Loss: 208.76771904031168, Neurons: 201, Grad norm: 4.7259460088044705\n",
      "Epoch 6488, Loss: 208.76771904031168, Neurons: 201, Grad norm: 4.7259460088044705\n",
      "Epoch 6489, Loss: 208.76745614152935, Neurons: 201, Grad norm: 2.9631611858941724\n",
      "Epoch 6489, Loss: 208.76745614152935, Neurons: 201, Grad norm: 2.9631611858941724\n",
      "Epoch 6490, Loss: 208.76728403210626, Neurons: 201, Grad norm: 1.231118120610887\n",
      "Epoch 6490, Loss: 208.76728403210626, Neurons: 201, Grad norm: 1.231118120610887\n",
      "Epoch 6491, Loss: 208.76706105020142, Neurons: 201, Grad norm: 1.2544317189064833\n",
      "Epoch 6491, Loss: 208.76706105020142, Neurons: 201, Grad norm: 1.2544317189064833\n",
      "Epoch 6492, Loss: 208.76690691915314, Neurons: 201, Grad norm: 3.0805363404811277\n",
      "Epoch 6492, Loss: 208.76690691915314, Neurons: 201, Grad norm: 3.0805363404811277\n",
      "Epoch 6493, Loss: 208.7668571841705, Neurons: 201, Grad norm: 4.480207248729724\n",
      "Epoch 6493, Loss: 208.7668571841705, Neurons: 201, Grad norm: 4.480207248729724\n",
      "Epoch 6494, Loss: 208.7668444374884, Neurons: 201, Grad norm: 5.259727651779714\n",
      "Epoch 6494, Loss: 208.7668444374884, Neurons: 201, Grad norm: 5.259727651779714\n",
      "Epoch 6495, Loss: 208.76687658954103, Neurons: 201, Grad norm: 5.978063238294459\n",
      "Epoch 6495, Loss: 208.76687658954103, Neurons: 201, Grad norm: 5.978063238294459\n",
      "Epoch 6496, Loss: 208.76683443769775, Neurons: 201, Grad norm: 6.361369241698826\n",
      "Epoch 6496, Loss: 208.76683443769775, Neurons: 201, Grad norm: 6.361369241698826\n",
      "Epoch 6497, Loss: 208.7667728206387, Neurons: 201, Grad norm: 6.4536396103632825\n",
      "Epoch 6497, Loss: 208.7667728206387, Neurons: 201, Grad norm: 6.4536396103632825\n",
      "Epoch 6498, Loss: 208.76666552335328, Neurons: 201, Grad norm: 6.809299403704203\n",
      "Epoch 6498, Loss: 208.76666552335328, Neurons: 201, Grad norm: 6.809299403704203\n",
      "Epoch 6499, Loss: 208.76665799887328, Neurons: 201, Grad norm: 6.509181582151347\n",
      "Epoch 6499, Loss: 208.76665799887328, Neurons: 201, Grad norm: 6.509181582151347\n",
      "Epoch 6500, Loss: 208.76649143837463, Neurons: 201, Grad norm: 6.221333446614121\n",
      "Epoch 6500, Loss: 208.76649143837463, Neurons: 201, Grad norm: 6.221333446614121\n",
      "Epoch 6501, Loss: 208.76631214043846, Neurons: 201, Grad norm: 5.21819623927615\n",
      "Epoch 6501, Loss: 208.76631214043846, Neurons: 201, Grad norm: 5.21819623927615\n",
      "Epoch 6502, Loss: 208.76608599221893, Neurons: 201, Grad norm: 4.004302364434521\n",
      "Epoch 6502, Loss: 208.76608599221893, Neurons: 201, Grad norm: 4.004302364434521\n",
      "Epoch 6503, Loss: 208.76578468015938, Neurons: 201, Grad norm: 2.2614267140034157\n",
      "Epoch 6503, Loss: 208.76578468015938, Neurons: 201, Grad norm: 2.2614267140034157\n",
      "Epoch 6504, Loss: 208.76557950140085, Neurons: 201, Grad norm: 1.0527284678345314\n",
      "Epoch 6504, Loss: 208.76557950140085, Neurons: 201, Grad norm: 1.0527284678345314\n",
      "Epoch 6505, Loss: 208.76544963788857, Neurons: 201, Grad norm: 1.5329108118377515\n",
      "Epoch 6505, Loss: 208.76544963788857, Neurons: 201, Grad norm: 1.5329108118377515\n",
      "Epoch 6506, Loss: 208.7654323570552, Neurons: 201, Grad norm: 2.5619029744255184\n",
      "Epoch 6506, Loss: 208.7654323570552, Neurons: 201, Grad norm: 2.5619029744255184\n",
      "Epoch 6507, Loss: 208.7653316969987, Neurons: 201, Grad norm: 2.8383217324256087\n",
      "Epoch 6507, Loss: 208.7653316969987, Neurons: 201, Grad norm: 2.8383217324256087\n",
      "Epoch 6508, Loss: 208.765215595504, Neurons: 201, Grad norm: 3.367661491721363\n",
      "Epoch 6508, Loss: 208.765215595504, Neurons: 201, Grad norm: 3.367661491721363\n",
      "Epoch 6509, Loss: 208.76508545860216, Neurons: 201, Grad norm: 4.366076555052777\n",
      "Epoch 6509, Loss: 208.76508545860216, Neurons: 201, Grad norm: 4.366076555052777\n",
      "Epoch 6510, Loss: 208.76506162574708, Neurons: 201, Grad norm: 4.868033521849803\n",
      "Epoch 6510, Loss: 208.76506162574708, Neurons: 201, Grad norm: 4.868033521849803\n",
      "Epoch 6511, Loss: 208.76511139813027, Neurons: 201, Grad norm: 6.294993273595286\n",
      "Epoch 6511, Loss: 208.76511139813027, Neurons: 201, Grad norm: 6.294993273595286\n",
      "Epoch 6512, Loss: 208.76519159361717, Neurons: 201, Grad norm: 7.300883931947017\n",
      "Epoch 6512, Loss: 208.76519159361717, Neurons: 201, Grad norm: 7.300883931947017\n",
      "Epoch 6513, Loss: 208.7653207735733, Neurons: 201, Grad norm: 8.410112351506438\n",
      "Epoch 6513, Loss: 208.7653207735733, Neurons: 201, Grad norm: 8.410112351506438\n",
      "Epoch 6514, Loss: 208.76543566547528, Neurons: 201, Grad norm: 9.020049672815887\n",
      "Epoch 6514, Loss: 208.76543566547528, Neurons: 201, Grad norm: 9.020049672815887\n",
      "Epoch 6515, Loss: 208.76542689991777, Neurons: 201, Grad norm: 9.413883279111372\n",
      "Epoch 6515, Loss: 208.76542689991777, Neurons: 201, Grad norm: 9.413883279111372\n",
      "Epoch 6516, Loss: 208.76527805058004, Neurons: 201, Grad norm: 9.267172310759925\n",
      "Epoch 6516, Loss: 208.76527805058004, Neurons: 201, Grad norm: 9.267172310759925\n",
      "Epoch 6517, Loss: 208.76518886875667, Neurons: 201, Grad norm: 8.670895316935036\n",
      "Epoch 6517, Loss: 208.76518886875667, Neurons: 201, Grad norm: 8.670895316935036\n",
      "Epoch 6518, Loss: 208.76490966736256, Neurons: 201, Grad norm: 7.54623054266888\n",
      "Epoch 6518, Loss: 208.76490966736256, Neurons: 201, Grad norm: 7.54623054266888\n",
      "Epoch 6519, Loss: 208.76464797780244, Neurons: 201, Grad norm: 5.977088832705699\n",
      "Epoch 6519, Loss: 208.76464797780244, Neurons: 201, Grad norm: 5.977088832705699\n",
      "Epoch 6520, Loss: 208.76428245853683, Neurons: 201, Grad norm: 4.2071879263594605\n",
      "Epoch 6520, Loss: 208.76428245853683, Neurons: 201, Grad norm: 4.2071879263594605\n",
      "Epoch 6521, Loss: 208.7639452299939, Neurons: 201, Grad norm: 2.7381673779106213\n",
      "Epoch 6521, Loss: 208.7639452299939, Neurons: 201, Grad norm: 2.7381673779106213\n",
      "Epoch 6522, Loss: 208.7637074996328, Neurons: 201, Grad norm: 1.6805004087683066\n",
      "Epoch 6522, Loss: 208.7637074996328, Neurons: 201, Grad norm: 1.6805004087683066\n",
      "Epoch 6523, Loss: 208.76363308881946, Neurons: 201, Grad norm: 1.1953432314878207\n",
      "Epoch 6523, Loss: 208.76363308881946, Neurons: 201, Grad norm: 1.1953432314878207\n",
      "Epoch 6524, Loss: 208.76349071312592, Neurons: 201, Grad norm: 1.0111488118548022\n",
      "Epoch 6524, Loss: 208.76349071312592, Neurons: 201, Grad norm: 1.0111488118548022\n",
      "Epoch 6525, Loss: 208.76335687870144, Neurons: 201, Grad norm: 0.7174913244044869\n",
      "Epoch 6525, Loss: 208.76335687870144, Neurons: 201, Grad norm: 0.7174913244044869\n",
      "Epoch 6526, Loss: 208.76321002748674, Neurons: 201, Grad norm: 0.5825824895065862\n",
      "Epoch 6526, Loss: 208.76321002748674, Neurons: 201, Grad norm: 0.5825824895065862\n",
      "Epoch 6527, Loss: 208.76309595195644, Neurons: 201, Grad norm: 0.7270095722264822\n",
      "Epoch 6527, Loss: 208.76309595195644, Neurons: 201, Grad norm: 0.7270095722264822\n",
      "Epoch 6528, Loss: 208.763000561143, Neurons: 201, Grad norm: 0.788203165143961\n",
      "Epoch 6528, Loss: 208.763000561143, Neurons: 201, Grad norm: 0.788203165143961\n",
      "Epoch 6529, Loss: 208.76290201175723, Neurons: 201, Grad norm: 0.7357063791921048\n",
      "Epoch 6529, Loss: 208.76290201175723, Neurons: 201, Grad norm: 0.7357063791921048\n",
      "Epoch 6530, Loss: 208.76279358650734, Neurons: 201, Grad norm: 0.7597593547474797\n",
      "Epoch 6530, Loss: 208.76279358650734, Neurons: 201, Grad norm: 0.7597593547474797\n",
      "Epoch 6531, Loss: 208.76267803125901, Neurons: 201, Grad norm: 1.0678758857332598\n",
      "Epoch 6531, Loss: 208.76267803125901, Neurons: 201, Grad norm: 1.0678758857332598\n",
      "Epoch 6532, Loss: 208.76257832758034, Neurons: 201, Grad norm: 1.8235973045367069\n",
      "Epoch 6532, Loss: 208.76257832758034, Neurons: 201, Grad norm: 1.8235973045367069\n",
      "Epoch 6533, Loss: 208.76242389319847, Neurons: 201, Grad norm: 2.742017863177331\n",
      "Epoch 6533, Loss: 208.76242389319847, Neurons: 201, Grad norm: 2.742017863177331\n",
      "Epoch 6534, Loss: 208.76242281673348, Neurons: 201, Grad norm: 4.19277122498478\n",
      "Epoch 6534, Loss: 208.76242281673348, Neurons: 201, Grad norm: 4.19277122498478\n",
      "Epoch 6535, Loss: 208.76243436863504, Neurons: 201, Grad norm: 5.519003157489167\n",
      "Epoch 6535, Loss: 208.76243436863504, Neurons: 201, Grad norm: 5.519003157489167\n",
      "Epoch 6536, Loss: 208.7625442297229, Neurons: 201, Grad norm: 6.787299138935032\n",
      "Epoch 6536, Loss: 208.7625442297229, Neurons: 201, Grad norm: 6.787299138935032\n",
      "Epoch 6537, Loss: 208.76268112843135, Neurons: 201, Grad norm: 8.573050728448425\n",
      "Epoch 6537, Loss: 208.76268112843135, Neurons: 201, Grad norm: 8.573050728448425\n",
      "Epoch 6538, Loss: 208.7628774737806, Neurons: 201, Grad norm: 10.045674550787247\n",
      "Epoch 6538, Loss: 208.7628774737806, Neurons: 201, Grad norm: 10.045674550787247\n",
      "Epoch 6539, Loss: 208.76307692440582, Neurons: 201, Grad norm: 11.249349056432196\n",
      "Epoch 6539, Loss: 208.76307692440582, Neurons: 201, Grad norm: 11.249349056432196\n",
      "Epoch 6540, Loss: 208.76332528895722, Neurons: 201, Grad norm: 12.435979886551467\n",
      "Epoch 6540, Loss: 208.76332528895722, Neurons: 201, Grad norm: 12.435979886551467\n",
      "Epoch 6541, Loss: 208.76354931576222, Neurons: 201, Grad norm: 13.055469564325941\n",
      "Epoch 6541, Loss: 208.76354931576222, Neurons: 201, Grad norm: 13.055469564325941\n",
      "Epoch 6542, Loss: 208.76364792840363, Neurons: 201, Grad norm: 13.299472786320695\n",
      "Epoch 6542, Loss: 208.76364792840363, Neurons: 201, Grad norm: 13.299472786320695\n",
      "Epoch 6543, Loss: 208.76357557320375, Neurons: 201, Grad norm: 12.952310394575079\n",
      "Epoch 6543, Loss: 208.76357557320375, Neurons: 201, Grad norm: 12.952310394575079\n",
      "Epoch 6544, Loss: 208.76345465832588, Neurons: 201, Grad norm: 12.061378661245161\n",
      "Epoch 6544, Loss: 208.76345465832588, Neurons: 201, Grad norm: 12.061378661245161\n",
      "Epoch 6545, Loss: 208.76315055812066, Neurons: 201, Grad norm: 10.67267813638757\n",
      "Epoch 6545, Loss: 208.76315055812066, Neurons: 201, Grad norm: 10.67267813638757\n",
      "Epoch 6546, Loss: 208.76254895593175, Neurons: 201, Grad norm: 8.502612066260308\n",
      "Epoch 6546, Loss: 208.76254895593175, Neurons: 201, Grad norm: 8.502612066260308\n",
      "Epoch 6547, Loss: 208.76180336719952, Neurons: 201, Grad norm: 5.470783277018585\n",
      "Epoch 6547, Loss: 208.76180336719952, Neurons: 201, Grad norm: 5.470783277018585\n",
      "Epoch 6548, Loss: 208.76117679816545, Neurons: 201, Grad norm: 2.3739054501041066\n",
      "Epoch 6548, Loss: 208.76117679816545, Neurons: 201, Grad norm: 2.3739054501041066\n",
      "Epoch 6549, Loss: 208.7607450769431, Neurons: 201, Grad norm: 1.4696878543815959\n",
      "Epoch 6549, Loss: 208.7607450769431, Neurons: 201, Grad norm: 1.4696878543815959\n",
      "Epoch 6550, Loss: 208.76062527429673, Neurons: 201, Grad norm: 4.410124852870081\n",
      "Epoch 6550, Loss: 208.76062527429673, Neurons: 201, Grad norm: 4.410124852870081\n",
      "Epoch 6551, Loss: 208.76070877313302, Neurons: 201, Grad norm: 7.476657238066192\n",
      "Epoch 6551, Loss: 208.76070877313302, Neurons: 201, Grad norm: 7.476657238066192\n",
      "Epoch 6552, Loss: 208.76093811842344, Neurons: 201, Grad norm: 10.218958244232278\n",
      "Epoch 6552, Loss: 208.76093811842344, Neurons: 201, Grad norm: 10.218958244232278\n",
      "Epoch 6553, Loss: 208.7614311818929, Neurons: 201, Grad norm: 12.806852736627484\n",
      "Epoch 6553, Loss: 208.7614311818929, Neurons: 201, Grad norm: 12.806852736627484\n",
      "Epoch 6554, Loss: 208.7619686104381, Neurons: 201, Grad norm: 14.01511611370606\n",
      "Epoch 6554, Loss: 208.7619686104381, Neurons: 201, Grad norm: 14.01511611370606\n",
      "Epoch 6555, Loss: 208.76235987810406, Neurons: 201, Grad norm: 14.4222289735238\n",
      "Epoch 6555, Loss: 208.76235987810406, Neurons: 201, Grad norm: 14.4222289735238\n",
      "Epoch 6556, Loss: 208.76232406410196, Neurons: 201, Grad norm: 13.447940000788194\n",
      "Epoch 6556, Loss: 208.76232406410196, Neurons: 201, Grad norm: 13.447940000788194\n",
      "Epoch 6557, Loss: 208.76191419931092, Neurons: 201, Grad norm: 11.36956099457978\n",
      "Epoch 6557, Loss: 208.76191419931092, Neurons: 201, Grad norm: 11.36956099457978\n",
      "Epoch 6558, Loss: 208.7610711792392, Neurons: 201, Grad norm: 8.281550956860553\n",
      "Epoch 6558, Loss: 208.7610711792392, Neurons: 201, Grad norm: 8.281550956860553\n",
      "Epoch 6559, Loss: 208.76036430240015, Neurons: 201, Grad norm: 4.555567332383364\n",
      "Epoch 6559, Loss: 208.76036430240015, Neurons: 201, Grad norm: 4.555567332383364\n",
      "Epoch 6560, Loss: 208.75963418354831, Neurons: 201, Grad norm: 0.9954378846403643\n",
      "Epoch 6560, Loss: 208.75963418354831, Neurons: 201, Grad norm: 0.9954378846403643\n",
      "Epoch 6561, Loss: 208.75926517937438, Neurons: 201, Grad norm: 3.1669804704130438\n",
      "Epoch 6561, Loss: 208.75926517937438, Neurons: 201, Grad norm: 3.1669804704130438\n",
      "Epoch 6562, Loss: 208.7591938085155, Neurons: 201, Grad norm: 6.188312727444788\n",
      "Epoch 6562, Loss: 208.7591938085155, Neurons: 201, Grad norm: 6.188312727444788\n",
      "Epoch 6563, Loss: 208.7594070298623, Neurons: 201, Grad norm: 8.374112832409532\n",
      "Epoch 6563, Loss: 208.7594070298623, Neurons: 201, Grad norm: 8.374112832409532\n",
      "Epoch 6564, Loss: 208.7596942887683, Neurons: 201, Grad norm: 10.291459532817674\n",
      "Epoch 6564, Loss: 208.7596942887683, Neurons: 201, Grad norm: 10.291459532817674\n",
      "Epoch 6565, Loss: 208.76000041031975, Neurons: 201, Grad norm: 10.907555158462598\n",
      "Epoch 6565, Loss: 208.76000041031975, Neurons: 201, Grad norm: 10.907555158462598\n",
      "Epoch 6566, Loss: 208.76005088727555, Neurons: 201, Grad norm: 10.691757497757258\n",
      "Epoch 6566, Loss: 208.76005088727555, Neurons: 201, Grad norm: 10.691757497757258\n",
      "Epoch 6567, Loss: 208.75991521967777, Neurons: 201, Grad norm: 9.371955864531726\n",
      "Epoch 6567, Loss: 208.75991521967777, Neurons: 201, Grad norm: 9.371955864531726\n",
      "Epoch 6568, Loss: 208.75961266500153, Neurons: 201, Grad norm: 7.258465976627965\n",
      "Epoch 6568, Loss: 208.75961266500153, Neurons: 201, Grad norm: 7.258465976627965\n",
      "Epoch 6569, Loss: 208.75924464680094, Neurons: 201, Grad norm: 4.826178783047172\n",
      "Epoch 6569, Loss: 208.75924464680094, Neurons: 201, Grad norm: 4.826178783047172\n",
      "Epoch 6570, Loss: 208.7587943164023, Neurons: 201, Grad norm: 2.283856942342571\n",
      "Epoch 6570, Loss: 208.7587943164023, Neurons: 201, Grad norm: 2.283856942342571\n",
      "Epoch 6571, Loss: 208.75823264072082, Neurons: 201, Grad norm: 0.9695776229168899\n",
      "Epoch 6571, Loss: 208.75823264072082, Neurons: 201, Grad norm: 0.9695776229168899\n",
      "Epoch 6572, Loss: 208.75792504646313, Neurons: 201, Grad norm: 3.3651634364629697\n",
      "Epoch 6572, Loss: 208.75792504646313, Neurons: 201, Grad norm: 3.3651634364629697\n",
      "Epoch 6573, Loss: 208.758133304145, Neurons: 201, Grad norm: 5.950024966915541\n",
      "Epoch 6573, Loss: 208.758133304145, Neurons: 201, Grad norm: 5.950024966915541\n",
      "Epoch 6574, Loss: 208.75851720305258, Neurons: 201, Grad norm: 8.502088318691342\n",
      "Epoch 6574, Loss: 208.75851720305258, Neurons: 201, Grad norm: 8.502088318691342\n",
      "Epoch 6575, Loss: 208.75890378897859, Neurons: 201, Grad norm: 10.68432610068128\n",
      "Epoch 6575, Loss: 208.75890378897859, Neurons: 201, Grad norm: 10.68432610068128\n",
      "Epoch 6576, Loss: 208.75911815002553, Neurons: 201, Grad norm: 12.034271257112325\n",
      "Epoch 6576, Loss: 208.75911815002553, Neurons: 201, Grad norm: 12.034271257112325\n",
      "Epoch 6577, Loss: 208.7591672928943, Neurons: 201, Grad norm: 12.445086237457481\n",
      "Epoch 6577, Loss: 208.7591672928943, Neurons: 201, Grad norm: 12.445086237457481\n",
      "Epoch 6578, Loss: 208.75908208072264, Neurons: 201, Grad norm: 11.151973697437464\n",
      "Epoch 6578, Loss: 208.75908208072264, Neurons: 201, Grad norm: 11.151973697437464\n",
      "Epoch 6579, Loss: 208.75868081377885, Neurons: 201, Grad norm: 8.955907033184372\n",
      "Epoch 6579, Loss: 208.75868081377885, Neurons: 201, Grad norm: 8.955907033184372\n",
      "Epoch 6580, Loss: 208.75801509661233, Neurons: 201, Grad norm: 6.104917587311515\n",
      "Epoch 6580, Loss: 208.75801509661233, Neurons: 201, Grad norm: 6.104917587311515\n",
      "Epoch 6581, Loss: 208.75745461504434, Neurons: 201, Grad norm: 2.9952022070096502\n",
      "Epoch 6581, Loss: 208.75745461504434, Neurons: 201, Grad norm: 2.9952022070096502\n",
      "Epoch 6582, Loss: 208.7570328422191, Neurons: 201, Grad norm: 0.659631974442501\n",
      "Epoch 6582, Loss: 208.7570328422191, Neurons: 201, Grad norm: 0.659631974442501\n",
      "Epoch 6583, Loss: 208.7567998349269, Neurons: 201, Grad norm: 2.688001322447982\n",
      "Epoch 6583, Loss: 208.7567998349269, Neurons: 201, Grad norm: 2.688001322447982\n",
      "Epoch 6584, Loss: 208.75682661764984, Neurons: 201, Grad norm: 4.8176509193443655\n",
      "Epoch 6584, Loss: 208.75682661764984, Neurons: 201, Grad norm: 4.8176509193443655\n",
      "Epoch 6585, Loss: 208.75687975612917, Neurons: 201, Grad norm: 6.471733703887594\n",
      "Epoch 6585, Loss: 208.75687975612917, Neurons: 201, Grad norm: 6.471733703887594\n",
      "Epoch 6586, Loss: 208.75707439754632, Neurons: 201, Grad norm: 7.802149435762978\n",
      "Epoch 6586, Loss: 208.75707439754632, Neurons: 201, Grad norm: 7.802149435762978\n",
      "Epoch 6587, Loss: 208.7571824915799, Neurons: 201, Grad norm: 8.36817574843279\n",
      "Epoch 6587, Loss: 208.7571824915799, Neurons: 201, Grad norm: 8.36817574843279\n",
      "Epoch 6588, Loss: 208.7571291142365, Neurons: 201, Grad norm: 8.844085356130485\n",
      "Epoch 6588, Loss: 208.7571291142365, Neurons: 201, Grad norm: 8.844085356130485\n",
      "Epoch 6589, Loss: 208.75707085285794, Neurons: 201, Grad norm: 8.506092917942283\n",
      "Epoch 6589, Loss: 208.75707085285794, Neurons: 201, Grad norm: 8.506092917942283\n",
      "Epoch 6590, Loss: 208.75689282479053, Neurons: 201, Grad norm: 7.797198943069825\n",
      "Epoch 6590, Loss: 208.75689282479053, Neurons: 201, Grad norm: 7.797198943069825\n",
      "Epoch 6591, Loss: 208.75668368092275, Neurons: 201, Grad norm: 6.2169152677947555\n",
      "Epoch 6591, Loss: 208.75668368092275, Neurons: 201, Grad norm: 6.2169152677947555\n",
      "Epoch 6592, Loss: 208.75639154764482, Neurons: 201, Grad norm: 4.218408287785478\n",
      "Epoch 6592, Loss: 208.75639154764482, Neurons: 201, Grad norm: 4.218408287785478\n",
      "Epoch 6593, Loss: 208.75606418928024, Neurons: 201, Grad norm: 2.362368086520629\n",
      "Epoch 6593, Loss: 208.75606418928024, Neurons: 201, Grad norm: 2.362368086520629\n",
      "Epoch 6594, Loss: 208.75590323443737, Neurons: 201, Grad norm: 1.0158941628470126\n",
      "Epoch 6594, Loss: 208.75590323443737, Neurons: 201, Grad norm: 1.0158941628470126\n",
      "Epoch 6595, Loss: 208.75569034900522, Neurons: 201, Grad norm: 1.714167449867595\n",
      "Epoch 6595, Loss: 208.75569034900522, Neurons: 201, Grad norm: 1.714167449867595\n",
      "Epoch 6596, Loss: 208.75549924320617, Neurons: 201, Grad norm: 2.852779874796416\n",
      "Epoch 6596, Loss: 208.75549924320617, Neurons: 201, Grad norm: 2.852779874796416\n",
      "Epoch 6597, Loss: 208.75556155612335, Neurons: 201, Grad norm: 4.23567764360613\n",
      "Epoch 6597, Loss: 208.75556155612335, Neurons: 201, Grad norm: 4.23567764360613\n",
      "Epoch 6598, Loss: 208.7556480540684, Neurons: 201, Grad norm: 5.258637673704716\n",
      "Epoch 6598, Loss: 208.7556480540684, Neurons: 201, Grad norm: 5.258637673704716\n",
      "Epoch 6599, Loss: 208.75560257771608, Neurons: 201, Grad norm: 6.22975897142599\n",
      "Epoch 6599, Loss: 208.75560257771608, Neurons: 201, Grad norm: 6.22975897142599\n",
      "Epoch 6600, Loss: 208.7555684720755, Neurons: 201, Grad norm: 6.782230677619951\n",
      "Epoch 6600, Loss: 208.7555684720755, Neurons: 201, Grad norm: 6.782230677619951\n",
      "Epoch 6601, Loss: 208.75557003717202, Neurons: 201, Grad norm: 7.172056278410788\n",
      "Epoch 6601, Loss: 208.75557003717202, Neurons: 201, Grad norm: 7.172056278410788\n",
      "Epoch 6602, Loss: 208.75544397652283, Neurons: 201, Grad norm: 6.788201909194661\n",
      "Epoch 6602, Loss: 208.75544397652283, Neurons: 201, Grad norm: 6.788201909194661\n",
      "Epoch 6603, Loss: 208.75532327107666, Neurons: 201, Grad norm: 6.219868094131145\n",
      "Epoch 6603, Loss: 208.75532327107666, Neurons: 201, Grad norm: 6.219868094131145\n",
      "Epoch 6604, Loss: 208.7551522125834, Neurons: 201, Grad norm: 5.0759984978860455\n",
      "Epoch 6604, Loss: 208.7551522125834, Neurons: 201, Grad norm: 5.0759984978860455\n",
      "Epoch 6605, Loss: 208.75488103933114, Neurons: 201, Grad norm: 3.4547079552010054\n",
      "Epoch 6605, Loss: 208.75488103933114, Neurons: 201, Grad norm: 3.4547079552010054\n",
      "Epoch 6606, Loss: 208.75467966396775, Neurons: 201, Grad norm: 2.3815484881673346\n",
      "Epoch 6606, Loss: 208.75467966396775, Neurons: 201, Grad norm: 2.3815484881673346\n",
      "Epoch 6607, Loss: 208.75463873585326, Neurons: 201, Grad norm: 1.2741217849970166\n",
      "Epoch 6607, Loss: 208.75463873585326, Neurons: 201, Grad norm: 1.2741217849970166\n",
      "Epoch 6608, Loss: 208.75442716525902, Neurons: 201, Grad norm: 0.74701967930095\n",
      "Epoch 6608, Loss: 208.75442716525902, Neurons: 201, Grad norm: 0.74701967930095\n",
      "Epoch 6609, Loss: 208.75422616860195, Neurons: 201, Grad norm: 1.236405037850197\n",
      "Epoch 6609, Loss: 208.75422616860195, Neurons: 201, Grad norm: 1.236405037850197\n",
      "Epoch 6610, Loss: 208.75417857832716, Neurons: 201, Grad norm: 2.576237019785426\n",
      "Epoch 6610, Loss: 208.75417857832716, Neurons: 201, Grad norm: 2.576237019785426\n",
      "Epoch 6611, Loss: 208.7541176558812, Neurons: 201, Grad norm: 3.7221542499219358\n",
      "Epoch 6611, Loss: 208.7541176558812, Neurons: 201, Grad norm: 3.7221542499219358\n",
      "Epoch 6612, Loss: 208.75424681827678, Neurons: 201, Grad norm: 5.341167806255659\n",
      "Epoch 6612, Loss: 208.75424681827678, Neurons: 201, Grad norm: 5.341167806255659\n",
      "Epoch 6613, Loss: 208.75433823478593, Neurons: 201, Grad norm: 6.916920428093195\n",
      "Epoch 6613, Loss: 208.75433823478593, Neurons: 201, Grad norm: 6.916920428093195\n",
      "Epoch 6614, Loss: 208.75426618903606, Neurons: 201, Grad norm: 8.332836310852473\n",
      "Epoch 6614, Loss: 208.75426618903606, Neurons: 201, Grad norm: 8.332836310852473\n",
      "Epoch 6615, Loss: 208.75445209904106, Neurons: 201, Grad norm: 9.098370814922902\n",
      "Epoch 6615, Loss: 208.75445209904106, Neurons: 201, Grad norm: 9.098370814922902\n",
      "Epoch 6616, Loss: 208.75448647944276, Neurons: 201, Grad norm: 8.592649463091083\n",
      "Epoch 6616, Loss: 208.75448647944276, Neurons: 201, Grad norm: 8.592649463091083\n",
      "Epoch 6617, Loss: 208.75425988969545, Neurons: 201, Grad norm: 7.390149105875308\n",
      "Epoch 6617, Loss: 208.75425988969545, Neurons: 201, Grad norm: 7.390149105875308\n",
      "Epoch 6618, Loss: 208.7540196801362, Neurons: 201, Grad norm: 5.955284349148439\n",
      "Epoch 6618, Loss: 208.7540196801362, Neurons: 201, Grad norm: 5.955284349148439\n",
      "Epoch 6619, Loss: 208.75370848186822, Neurons: 201, Grad norm: 4.094968682930807\n",
      "Epoch 6619, Loss: 208.75370848186822, Neurons: 201, Grad norm: 4.094968682930807\n",
      "Epoch 6620, Loss: 208.75346104665292, Neurons: 201, Grad norm: 2.7967608803762354\n",
      "Epoch 6620, Loss: 208.75346104665292, Neurons: 201, Grad norm: 2.7967608803762354\n",
      "Epoch 6621, Loss: 208.75321115168626, Neurons: 201, Grad norm: 1.4770358044169098\n",
      "Epoch 6621, Loss: 208.75321115168626, Neurons: 201, Grad norm: 1.4770358044169098\n",
      "Epoch 6622, Loss: 208.75299663288135, Neurons: 201, Grad norm: 0.7568068366787652\n",
      "Epoch 6622, Loss: 208.75299663288135, Neurons: 201, Grad norm: 0.7568068366787652\n",
      "Epoch 6623, Loss: 208.7528665431966, Neurons: 201, Grad norm: 0.879930122686326\n",
      "Epoch 6623, Loss: 208.7528665431966, Neurons: 201, Grad norm: 0.879930122686326\n",
      "Epoch 6624, Loss: 208.75283693201067, Neurons: 201, Grad norm: 1.445681782178141\n",
      "Epoch 6624, Loss: 208.75283693201067, Neurons: 201, Grad norm: 1.445681782178141\n",
      "Epoch 6625, Loss: 208.75266416371133, Neurons: 201, Grad norm: 2.705276105793688\n",
      "Epoch 6625, Loss: 208.75266416371133, Neurons: 201, Grad norm: 2.705276105793688\n",
      "Epoch 6626, Loss: 208.75267883973117, Neurons: 201, Grad norm: 3.9063874166096886\n",
      "Epoch 6626, Loss: 208.75267883973117, Neurons: 201, Grad norm: 3.9063874166096886\n",
      "Epoch 6627, Loss: 208.75265931797713, Neurons: 201, Grad norm: 5.204331953900627\n",
      "Epoch 6627, Loss: 208.75265931797713, Neurons: 201, Grad norm: 5.204331953900627\n",
      "Epoch 6628, Loss: 208.75271193117658, Neurons: 201, Grad norm: 5.9330261987606026\n",
      "Epoch 6628, Loss: 208.75271193117658, Neurons: 201, Grad norm: 5.9330261987606026\n",
      "Epoch 6629, Loss: 208.75274104316262, Neurons: 201, Grad norm: 6.4211045788828365\n",
      "Epoch 6629, Loss: 208.75274104316262, Neurons: 201, Grad norm: 6.4211045788828365\n",
      "Epoch 6630, Loss: 208.75268093392756, Neurons: 201, Grad norm: 6.232728908178765\n",
      "Epoch 6630, Loss: 208.75268093392756, Neurons: 201, Grad norm: 6.232728908178765\n",
      "Epoch 6631, Loss: 208.75259893220718, Neurons: 201, Grad norm: 5.879189807884282\n",
      "Epoch 6631, Loss: 208.75259893220718, Neurons: 201, Grad norm: 5.879189807884282\n",
      "Epoch 6632, Loss: 208.75251464839548, Neurons: 201, Grad norm: 5.303186862453663\n",
      "Epoch 6632, Loss: 208.75251464839548, Neurons: 201, Grad norm: 5.303186862453663\n",
      "Epoch 6633, Loss: 208.7524689047807, Neurons: 201, Grad norm: 5.06534043255882\n",
      "Epoch 6633, Loss: 208.7524689047807, Neurons: 201, Grad norm: 5.06534043255882\n",
      "Epoch 6634, Loss: 208.75223294836823, Neurons: 201, Grad norm: 4.7644350739810015\n",
      "Epoch 6634, Loss: 208.75223294836823, Neurons: 201, Grad norm: 4.7644350739810015\n",
      "Epoch 6635, Loss: 208.75204849595073, Neurons: 201, Grad norm: 4.796914176198626\n",
      "Epoch 6635, Loss: 208.75204849595073, Neurons: 201, Grad norm: 4.796914176198626\n",
      "Epoch 6636, Loss: 208.75196897202056, Neurons: 201, Grad norm: 5.209466989665391\n",
      "Epoch 6636, Loss: 208.75196897202056, Neurons: 201, Grad norm: 5.209466989665391\n",
      "Epoch 6637, Loss: 208.75188256282902, Neurons: 201, Grad norm: 5.892801709466796\n",
      "Epoch 6637, Loss: 208.75188256282902, Neurons: 201, Grad norm: 5.892801709466796\n",
      "Epoch 6638, Loss: 208.75186635525284, Neurons: 201, Grad norm: 6.64247462381915\n",
      "Epoch 6638, Loss: 208.75186635525284, Neurons: 201, Grad norm: 6.64247462381915\n",
      "Epoch 6639, Loss: 208.75193695647167, Neurons: 201, Grad norm: 7.178432175696483\n",
      "Epoch 6639, Loss: 208.75193695647167, Neurons: 201, Grad norm: 7.178432175696483\n",
      "Epoch 6640, Loss: 208.75190461901653, Neurons: 201, Grad norm: 7.650091433615333\n",
      "Epoch 6640, Loss: 208.75190461901653, Neurons: 201, Grad norm: 7.650091433615333\n",
      "Epoch 6641, Loss: 208.75186222422147, Neurons: 201, Grad norm: 7.625447757170388\n",
      "Epoch 6641, Loss: 208.75186222422147, Neurons: 201, Grad norm: 7.625447757170388\n",
      "Epoch 6642, Loss: 208.7518348712638, Neurons: 201, Grad norm: 7.5686741944194385\n",
      "Epoch 6642, Loss: 208.7518348712638, Neurons: 201, Grad norm: 7.5686741944194385\n",
      "Epoch 6643, Loss: 208.7518740907119, Neurons: 201, Grad norm: 7.563179541409526\n",
      "Epoch 6643, Loss: 208.7518740907119, Neurons: 201, Grad norm: 7.563179541409526\n",
      "Epoch 6644, Loss: 208.75186002645114, Neurons: 201, Grad norm: 7.1905292408009585\n",
      "Epoch 6644, Loss: 208.75186002645114, Neurons: 201, Grad norm: 7.1905292408009585\n",
      "Epoch 6645, Loss: 208.75177761617027, Neurons: 201, Grad norm: 7.427584926878444\n",
      "Epoch 6645, Loss: 208.75177761617027, Neurons: 201, Grad norm: 7.427584926878444\n",
      "Epoch 6646, Loss: 208.75163025327439, Neurons: 201, Grad norm: 7.139334406889691\n",
      "Epoch 6646, Loss: 208.75163025327439, Neurons: 201, Grad norm: 7.139334406889691\n",
      "Epoch 6647, Loss: 208.75136578023842, Neurons: 201, Grad norm: 7.019909692147403\n",
      "Epoch 6647, Loss: 208.75136578023842, Neurons: 201, Grad norm: 7.019909692147403\n",
      "Epoch 6648, Loss: 208.75112676368238, Neurons: 201, Grad norm: 6.3725969420855195\n",
      "Epoch 6648, Loss: 208.75112676368238, Neurons: 201, Grad norm: 6.3725969420855195\n",
      "Epoch 6649, Loss: 208.7510296666399, Neurons: 201, Grad norm: 5.056006203940739\n",
      "Epoch 6649, Loss: 208.7510296666399, Neurons: 201, Grad norm: 5.056006203940739\n",
      "Epoch 6650, Loss: 208.75070351284324, Neurons: 201, Grad norm: 3.533096569839683\n",
      "Epoch 6650, Loss: 208.75070351284324, Neurons: 201, Grad norm: 3.533096569839683\n",
      "Epoch 6651, Loss: 208.75047445545692, Neurons: 201, Grad norm: 2.170469278517607\n",
      "Epoch 6651, Loss: 208.75047445545692, Neurons: 201, Grad norm: 2.170469278517607\n",
      "Epoch 6652, Loss: 208.7503409481739, Neurons: 201, Grad norm: 1.043674246652077\n",
      "Epoch 6652, Loss: 208.7503409481739, Neurons: 201, Grad norm: 1.043674246652077\n",
      "Epoch 6653, Loss: 208.75024868997582, Neurons: 201, Grad norm: 0.9617183629480311\n",
      "Epoch 6653, Loss: 208.75024868997582, Neurons: 201, Grad norm: 0.9617183629480311\n",
      "Epoch 6654, Loss: 208.75013899612205, Neurons: 201, Grad norm: 1.668919993806711\n",
      "Epoch 6654, Loss: 208.75013899612205, Neurons: 201, Grad norm: 1.668919993806711\n",
      "Epoch 6655, Loss: 208.75008584898842, Neurons: 201, Grad norm: 2.240476390773082\n",
      "Epoch 6655, Loss: 208.75008584898842, Neurons: 201, Grad norm: 2.240476390773082\n",
      "Epoch 6656, Loss: 208.74994339599442, Neurons: 201, Grad norm: 3.335655609126279\n",
      "Epoch 6656, Loss: 208.74994339599442, Neurons: 201, Grad norm: 3.335655609126279\n",
      "Epoch 6657, Loss: 208.75000889073334, Neurons: 201, Grad norm: 4.721331078874885\n",
      "Epoch 6657, Loss: 208.75000889073334, Neurons: 201, Grad norm: 4.721331078874885\n",
      "Epoch 6658, Loss: 208.75017448333946, Neurons: 201, Grad norm: 6.32839558107724\n",
      "Epoch 6658, Loss: 208.75017448333946, Neurons: 201, Grad norm: 6.32839558107724\n",
      "Epoch 6659, Loss: 208.75026954288163, Neurons: 201, Grad norm: 8.237695240725092\n",
      "Epoch 6659, Loss: 208.75026954288163, Neurons: 201, Grad norm: 8.237695240725092\n",
      "Epoch 6660, Loss: 208.75041595628144, Neurons: 201, Grad norm: 10.39900712283206\n",
      "Epoch 6660, Loss: 208.75041595628144, Neurons: 201, Grad norm: 10.39900712283206\n",
      "Epoch 6661, Loss: 208.7507760096631, Neurons: 201, Grad norm: 11.352088343047248\n",
      "Epoch 6661, Loss: 208.7507760096631, Neurons: 201, Grad norm: 11.352088343047248\n",
      "Epoch 6662, Loss: 208.75088339039962, Neurons: 201, Grad norm: 11.011656165236742\n",
      "Epoch 6662, Loss: 208.75088339039962, Neurons: 201, Grad norm: 11.011656165236742\n",
      "Epoch 6663, Loss: 208.7507899410046, Neurons: 201, Grad norm: 9.31393301926515\n",
      "Epoch 6663, Loss: 208.7507899410046, Neurons: 201, Grad norm: 9.31393301926515\n",
      "Epoch 6664, Loss: 208.75032651694383, Neurons: 201, Grad norm: 6.324990637406494\n",
      "Epoch 6664, Loss: 208.75032651694383, Neurons: 201, Grad norm: 6.324990637406494\n",
      "Epoch 6665, Loss: 208.74954491245919, Neurons: 201, Grad norm: 2.968039277209803\n",
      "Epoch 6665, Loss: 208.74954491245919, Neurons: 201, Grad norm: 2.968039277209803\n",
      "Epoch 6666, Loss: 208.7492159563491, Neurons: 201, Grad norm: 2.049505310142648\n",
      "Epoch 6666, Loss: 208.7492159563491, Neurons: 201, Grad norm: 2.049505310142648\n",
      "Epoch 6667, Loss: 208.74929167607726, Neurons: 201, Grad norm: 3.6174610392022157\n",
      "Epoch 6667, Loss: 208.74929167607726, Neurons: 201, Grad norm: 3.6174610392022157\n",
      "Epoch 6668, Loss: 208.7493339188372, Neurons: 201, Grad norm: 4.747245384122704\n",
      "Epoch 6668, Loss: 208.7493339188372, Neurons: 201, Grad norm: 4.747245384122704\n",
      "Epoch 6669, Loss: 208.74909105113548, Neurons: 201, Grad norm: 5.477935336548477\n",
      "Epoch 6669, Loss: 208.74909105113548, Neurons: 201, Grad norm: 5.477935336548477\n",
      "Epoch 6670, Loss: 208.74884812108093, Neurons: 201, Grad norm: 5.75877076756987\n",
      "Epoch 6670, Loss: 208.74884812108093, Neurons: 201, Grad norm: 5.75877076756987\n",
      "Epoch 6671, Loss: 208.7491164001725, Neurons: 201, Grad norm: 6.529128903164896\n",
      "Epoch 6671, Loss: 208.7491164001725, Neurons: 201, Grad norm: 6.529128903164896\n",
      "Epoch 6672, Loss: 208.74948666797548, Neurons: 201, Grad norm: 6.841102773595952\n",
      "Epoch 6672, Loss: 208.74948666797548, Neurons: 201, Grad norm: 6.841102773595952\n",
      "Epoch 6673, Loss: 208.7495049727472, Neurons: 201, Grad norm: 7.32542931088148\n",
      "Epoch 6673, Loss: 208.7495049727472, Neurons: 201, Grad norm: 7.32542931088148\n",
      "Epoch 6674, Loss: 208.74907931473268, Neurons: 201, Grad norm: 7.7648833045451005\n",
      "Epoch 6674, Loss: 208.74907931473268, Neurons: 201, Grad norm: 7.7648833045451005\n",
      "Epoch 6675, Loss: 208.74883051702682, Neurons: 201, Grad norm: 7.7446851490906905\n",
      "Epoch 6675, Loss: 208.74883051702682, Neurons: 201, Grad norm: 7.7446851490906905\n",
      "Epoch 6676, Loss: 208.74885016919765, Neurons: 201, Grad norm: 6.844961027743238\n",
      "Epoch 6676, Loss: 208.74885016919765, Neurons: 201, Grad norm: 6.844961027743238\n",
      "Epoch 6677, Loss: 208.74864916251167, Neurons: 201, Grad norm: 5.167647479139807\n",
      "Epoch 6677, Loss: 208.74864916251167, Neurons: 201, Grad norm: 5.167647479139807\n",
      "Epoch 6678, Loss: 208.74832704954366, Neurons: 201, Grad norm: 2.4985949037539523\n",
      "Epoch 6678, Loss: 208.74832704954366, Neurons: 201, Grad norm: 2.4985949037539523\n",
      "Epoch 6679, Loss: 208.74788620861958, Neurons: 201, Grad norm: 0.9216395209460999\n",
      "Epoch 6679, Loss: 208.74788620861958, Neurons: 201, Grad norm: 0.9216395209460999\n",
      "Epoch 6680, Loss: 208.74778242877233, Neurons: 201, Grad norm: 2.7718517347073335\n",
      "Epoch 6680, Loss: 208.74778242877233, Neurons: 201, Grad norm: 2.7718517347073335\n",
      "Epoch 6681, Loss: 208.74784537000406, Neurons: 201, Grad norm: 4.285589014215296\n",
      "Epoch 6681, Loss: 208.74784537000406, Neurons: 201, Grad norm: 4.285589014215296\n",
      "Epoch 6682, Loss: 208.74784941171774, Neurons: 201, Grad norm: 5.587252352980723\n",
      "Epoch 6682, Loss: 208.74784941171774, Neurons: 201, Grad norm: 5.587252352980723\n",
      "Epoch 6683, Loss: 208.74789921738488, Neurons: 201, Grad norm: 5.8091941168255135\n",
      "Epoch 6683, Loss: 208.74789921738488, Neurons: 201, Grad norm: 5.8091941168255135\n",
      "Epoch 6684, Loss: 208.74784057618507, Neurons: 201, Grad norm: 6.318259329358816\n",
      "Epoch 6684, Loss: 208.74784057618507, Neurons: 201, Grad norm: 6.318259329358816\n",
      "Epoch 6685, Loss: 208.74786239511997, Neurons: 201, Grad norm: 6.6794737125663595\n",
      "Epoch 6685, Loss: 208.74786239511997, Neurons: 201, Grad norm: 6.6794737125663595\n",
      "Epoch 6686, Loss: 208.74797699196992, Neurons: 201, Grad norm: 6.525907371780014\n",
      "Epoch 6686, Loss: 208.74797699196992, Neurons: 201, Grad norm: 6.525907371780014\n",
      "Epoch 6687, Loss: 208.74785682995704, Neurons: 201, Grad norm: 6.370498769696061\n",
      "Epoch 6687, Loss: 208.74785682995704, Neurons: 201, Grad norm: 6.370498769696061\n",
      "Epoch 6688, Loss: 208.74753124122248, Neurons: 201, Grad norm: 6.100529168157368\n",
      "Epoch 6688, Loss: 208.74753124122248, Neurons: 201, Grad norm: 6.100529168157368\n",
      "Epoch 6689, Loss: 208.74738773221554, Neurons: 201, Grad norm: 5.422247903938378\n",
      "Epoch 6689, Loss: 208.74738773221554, Neurons: 201, Grad norm: 5.422247903938378\n",
      "Epoch 6690, Loss: 208.7472725682922, Neurons: 201, Grad norm: 4.437673161302099\n",
      "Epoch 6690, Loss: 208.7472725682922, Neurons: 201, Grad norm: 4.437673161302099\n",
      "Epoch 6691, Loss: 208.74712423840057, Neurons: 201, Grad norm: 2.8285035854302496\n",
      "Epoch 6691, Loss: 208.74712423840057, Neurons: 201, Grad norm: 2.8285035854302496\n",
      "Epoch 6692, Loss: 208.74688129217546, Neurons: 201, Grad norm: 0.8348302654697609\n",
      "Epoch 6692, Loss: 208.74688129217546, Neurons: 201, Grad norm: 0.8348302654697609\n",
      "Epoch 6693, Loss: 208.74661905657976, Neurons: 201, Grad norm: 1.4335107190394614\n",
      "Epoch 6693, Loss: 208.74661905657976, Neurons: 201, Grad norm: 1.4335107190394614\n",
      "Epoch 6694, Loss: 208.74656510832108, Neurons: 201, Grad norm: 3.0987414688605357\n",
      "Epoch 6694, Loss: 208.74656510832108, Neurons: 201, Grad norm: 3.0987414688605357\n",
      "Epoch 6695, Loss: 208.74661699284684, Neurons: 201, Grad norm: 4.405315814935558\n",
      "Epoch 6695, Loss: 208.74661699284684, Neurons: 201, Grad norm: 4.405315814935558\n",
      "Epoch 6696, Loss: 208.74662564808693, Neurons: 201, Grad norm: 5.4516017123123754\n",
      "Epoch 6696, Loss: 208.74662564808693, Neurons: 201, Grad norm: 5.4516017123123754\n",
      "Epoch 6697, Loss: 208.7465731870567, Neurons: 201, Grad norm: 6.279379515622502\n",
      "Epoch 6697, Loss: 208.7465731870567, Neurons: 201, Grad norm: 6.279379515622502\n",
      "Epoch 6698, Loss: 208.74661758109048, Neurons: 201, Grad norm: 6.795251059483987\n",
      "Epoch 6698, Loss: 208.74661758109048, Neurons: 201, Grad norm: 6.795251059483987\n",
      "Epoch 6699, Loss: 208.74660264122545, Neurons: 201, Grad norm: 7.752394987073918\n",
      "Epoch 6699, Loss: 208.74660264122545, Neurons: 201, Grad norm: 7.752394987073918\n",
      "Epoch 6700, Loss: 208.74672388729718, Neurons: 201, Grad norm: 8.186337776193318\n",
      "Epoch 6700, Loss: 208.74672388729718, Neurons: 201, Grad norm: 8.186337776193318\n",
      "Epoch 6701, Loss: 208.74691999374707, Neurons: 201, Grad norm: 9.030176281784\n",
      "Epoch 6701, Loss: 208.74691999374707, Neurons: 201, Grad norm: 9.030176281784\n",
      "Epoch 6702, Loss: 208.74690381579444, Neurons: 201, Grad norm: 9.000674854617387\n",
      "Epoch 6702, Loss: 208.74690381579444, Neurons: 201, Grad norm: 9.000674854617387\n",
      "Epoch 6703, Loss: 208.746870973328, Neurons: 201, Grad norm: 8.772541623933137\n",
      "Epoch 6703, Loss: 208.746870973328, Neurons: 201, Grad norm: 8.772541623933137\n",
      "Epoch 6704, Loss: 208.74677069796604, Neurons: 201, Grad norm: 8.037399466846049\n",
      "Epoch 6704, Loss: 208.74677069796604, Neurons: 201, Grad norm: 8.037399466846049\n",
      "Epoch 6705, Loss: 208.7464695246801, Neurons: 201, Grad norm: 6.5391621387961925\n",
      "Epoch 6705, Loss: 208.7464695246801, Neurons: 201, Grad norm: 6.5391621387961925\n",
      "Epoch 6706, Loss: 208.7459957929511, Neurons: 201, Grad norm: 4.465811679272095\n",
      "Epoch 6706, Loss: 208.7459957929511, Neurons: 201, Grad norm: 4.465811679272095\n",
      "Epoch 6707, Loss: 208.74571618468468, Neurons: 201, Grad norm: 2.0065609162311913\n",
      "Epoch 6707, Loss: 208.74571618468468, Neurons: 201, Grad norm: 2.0065609162311913\n",
      "Epoch 6708, Loss: 208.74540618179864, Neurons: 201, Grad norm: 0.8219222462942415\n",
      "Epoch 6708, Loss: 208.74540618179864, Neurons: 201, Grad norm: 0.8219222462942415\n",
      "Epoch 6709, Loss: 208.74526453444216, Neurons: 201, Grad norm: 2.773765200393997\n",
      "Epoch 6709, Loss: 208.74526453444216, Neurons: 201, Grad norm: 2.773765200393997\n",
      "Epoch 6710, Loss: 208.74528699575845, Neurons: 201, Grad norm: 4.853246083710258\n",
      "Epoch 6710, Loss: 208.74528699575845, Neurons: 201, Grad norm: 4.853246083710258\n",
      "Epoch 6711, Loss: 208.74537769630064, Neurons: 201, Grad norm: 6.885963879645801\n",
      "Epoch 6711, Loss: 208.74537769630064, Neurons: 201, Grad norm: 6.885963879645801\n",
      "Epoch 6712, Loss: 208.745544473116, Neurons: 201, Grad norm: 9.059998819029996\n",
      "Epoch 6712, Loss: 208.745544473116, Neurons: 201, Grad norm: 9.059998819029996\n",
      "Epoch 6713, Loss: 208.74585871045002, Neurons: 201, Grad norm: 10.730792505991117\n",
      "Epoch 6713, Loss: 208.74585871045002, Neurons: 201, Grad norm: 10.730792505991117\n",
      "Epoch 6714, Loss: 208.7462580930304, Neurons: 201, Grad norm: 12.38085778091358\n",
      "Epoch 6714, Loss: 208.7462580930304, Neurons: 201, Grad norm: 12.38085778091358\n",
      "Epoch 6715, Loss: 208.7466124585829, Neurons: 201, Grad norm: 12.946144518452128\n",
      "Epoch 6715, Loss: 208.7466124585829, Neurons: 201, Grad norm: 12.946144518452128\n",
      "Epoch 6716, Loss: 208.74674762247682, Neurons: 201, Grad norm: 12.535442968683764\n",
      "Epoch 6716, Loss: 208.74674762247682, Neurons: 201, Grad norm: 12.535442968683764\n",
      "Epoch 6717, Loss: 208.74653054163292, Neurons: 201, Grad norm: 10.668728184983086\n",
      "Epoch 6717, Loss: 208.74653054163292, Neurons: 201, Grad norm: 10.668728184983086\n",
      "Epoch 6718, Loss: 208.7460619360794, Neurons: 201, Grad norm: 8.152489659511735\n",
      "Epoch 6718, Loss: 208.7460619360794, Neurons: 201, Grad norm: 8.152489659511735\n",
      "Epoch 6719, Loss: 208.74540746540958, Neurons: 201, Grad norm: 4.715130574133766\n",
      "Epoch 6719, Loss: 208.74540746540958, Neurons: 201, Grad norm: 4.715130574133766\n",
      "Epoch 6720, Loss: 208.74481160101007, Neurons: 201, Grad norm: 1.319017690389825\n",
      "Epoch 6720, Loss: 208.74481160101007, Neurons: 201, Grad norm: 1.319017690389825\n",
      "Epoch 6721, Loss: 208.74439462002252, Neurons: 201, Grad norm: 2.1463156023781007\n",
      "Epoch 6721, Loss: 208.74439462002252, Neurons: 201, Grad norm: 2.1463156023781007\n",
      "Epoch 6722, Loss: 208.74428293958366, Neurons: 201, Grad norm: 4.600666347998217\n",
      "Epoch 6722, Loss: 208.74428293958366, Neurons: 201, Grad norm: 4.600666347998217\n",
      "Epoch 6723, Loss: 208.7444839173188, Neurons: 201, Grad norm: 6.424268729937284\n",
      "Epoch 6723, Loss: 208.7444839173188, Neurons: 201, Grad norm: 6.424268729937284\n",
      "Epoch 6724, Loss: 208.7447549387521, Neurons: 201, Grad norm: 7.554527011024398\n",
      "Epoch 6724, Loss: 208.7447549387521, Neurons: 201, Grad norm: 7.554527011024398\n",
      "Epoch 6725, Loss: 208.74492136883737, Neurons: 201, Grad norm: 8.181258046552175\n",
      "Epoch 6725, Loss: 208.74492136883737, Neurons: 201, Grad norm: 8.181258046552175\n",
      "Epoch 6726, Loss: 208.74484929970615, Neurons: 201, Grad norm: 8.07046107288028\n",
      "Epoch 6726, Loss: 208.74484929970615, Neurons: 201, Grad norm: 8.07046107288028\n",
      "Epoch 6727, Loss: 208.74463013821793, Neurons: 201, Grad norm: 7.217353471648708\n",
      "Epoch 6727, Loss: 208.74463013821793, Neurons: 201, Grad norm: 7.217353471648708\n",
      "Epoch 6728, Loss: 208.74438427334496, Neurons: 201, Grad norm: 5.689467767636234\n",
      "Epoch 6728, Loss: 208.74438427334496, Neurons: 201, Grad norm: 5.689467767636234\n",
      "Epoch 6729, Loss: 208.74405724026474, Neurons: 201, Grad norm: 3.933247817610724\n",
      "Epoch 6729, Loss: 208.74405724026474, Neurons: 201, Grad norm: 3.933247817610724\n",
      "Epoch 6730, Loss: 208.74374316435882, Neurons: 201, Grad norm: 2.1751516015777863\n",
      "Epoch 6730, Loss: 208.74374316435882, Neurons: 201, Grad norm: 2.1751516015777863\n",
      "Epoch 6731, Loss: 208.74353080683304, Neurons: 201, Grad norm: 1.0097753369150528\n",
      "Epoch 6731, Loss: 208.74353080683304, Neurons: 201, Grad norm: 1.0097753369150528\n",
      "Epoch 6732, Loss: 208.74341124317522, Neurons: 201, Grad norm: 1.1336091356262805\n",
      "Epoch 6732, Loss: 208.74341124317522, Neurons: 201, Grad norm: 1.1336091356262805\n",
      "Epoch 6733, Loss: 208.74337526528794, Neurons: 201, Grad norm: 1.9204527673492333\n",
      "Epoch 6733, Loss: 208.74337526528794, Neurons: 201, Grad norm: 1.9204527673492333\n",
      "Epoch 6734, Loss: 208.74330201653083, Neurons: 201, Grad norm: 2.775430287627159\n",
      "Epoch 6734, Loss: 208.74330201653083, Neurons: 201, Grad norm: 2.775430287627159\n",
      "Epoch 6735, Loss: 208.74331273303392, Neurons: 201, Grad norm: 3.4698814865500904\n",
      "Epoch 6735, Loss: 208.74331273303392, Neurons: 201, Grad norm: 3.4698814865500904\n",
      "Epoch 6736, Loss: 208.74324411188653, Neurons: 201, Grad norm: 4.097016646845052\n",
      "Epoch 6736, Loss: 208.74324411188653, Neurons: 201, Grad norm: 4.097016646845052\n",
      "Epoch 6737, Loss: 208.74320230640458, Neurons: 201, Grad norm: 4.414425622684965\n",
      "Epoch 6737, Loss: 208.74320230640458, Neurons: 201, Grad norm: 4.414425622684965\n",
      "Epoch 6738, Loss: 208.74315922441338, Neurons: 201, Grad norm: 5.159649963294476\n",
      "Epoch 6738, Loss: 208.74315922441338, Neurons: 201, Grad norm: 5.159649963294476\n",
      "Epoch 6739, Loss: 208.74325505656105, Neurons: 201, Grad norm: 5.659911955000192\n",
      "Epoch 6739, Loss: 208.74325505656105, Neurons: 201, Grad norm: 5.659911955000192\n",
      "Epoch 6740, Loss: 208.74330373435112, Neurons: 201, Grad norm: 6.5967742016642585\n",
      "Epoch 6740, Loss: 208.74330373435112, Neurons: 201, Grad norm: 6.5967742016642585\n",
      "Epoch 6741, Loss: 208.74341343555756, Neurons: 201, Grad norm: 7.518071054795232\n",
      "Epoch 6741, Loss: 208.74341343555756, Neurons: 201, Grad norm: 7.518071054795232\n",
      "Epoch 6742, Loss: 208.7433062347589, Neurons: 201, Grad norm: 8.43711289932595\n",
      "Epoch 6742, Loss: 208.7433062347589, Neurons: 201, Grad norm: 8.43711289932595\n",
      "Epoch 6743, Loss: 208.74327972789922, Neurons: 201, Grad norm: 8.498930607419187\n",
      "Epoch 6743, Loss: 208.74327972789922, Neurons: 201, Grad norm: 8.498930607419187\n",
      "Epoch 6744, Loss: 208.74326294544454, Neurons: 201, Grad norm: 7.982457935038071\n",
      "Epoch 6744, Loss: 208.74326294544454, Neurons: 201, Grad norm: 7.982457935038071\n",
      "Epoch 6745, Loss: 208.74307676149616, Neurons: 201, Grad norm: 6.816758797594394\n",
      "Epoch 6745, Loss: 208.74307676149616, Neurons: 201, Grad norm: 6.816758797594394\n",
      "Epoch 6746, Loss: 208.74276964714753, Neurons: 201, Grad norm: 4.8861574387918765\n",
      "Epoch 6746, Loss: 208.74276964714753, Neurons: 201, Grad norm: 4.8861574387918765\n",
      "Epoch 6747, Loss: 208.74242360002506, Neurons: 201, Grad norm: 3.079429193804373\n",
      "Epoch 6747, Loss: 208.74242360002506, Neurons: 201, Grad norm: 3.079429193804373\n",
      "Epoch 6748, Loss: 208.74215911060878, Neurons: 201, Grad norm: 1.4852417729501473\n",
      "Epoch 6748, Loss: 208.74215911060878, Neurons: 201, Grad norm: 1.4852417729501473\n",
      "Epoch 6749, Loss: 208.74202895813897, Neurons: 201, Grad norm: 1.420151940052754\n",
      "Epoch 6749, Loss: 208.74202895813897, Neurons: 201, Grad norm: 1.420151940052754\n",
      "Epoch 6750, Loss: 208.74194963231236, Neurons: 201, Grad norm: 2.125722792321565\n",
      "Epoch 6750, Loss: 208.74194963231236, Neurons: 201, Grad norm: 2.125722792321565\n",
      "Epoch 6751, Loss: 208.74186955051124, Neurons: 201, Grad norm: 3.0219648766996148\n",
      "Epoch 6751, Loss: 208.74186955051124, Neurons: 201, Grad norm: 3.0219648766996148\n",
      "Epoch 6752, Loss: 208.7418013036199, Neurons: 201, Grad norm: 3.7577406462030374\n",
      "Epoch 6752, Loss: 208.7418013036199, Neurons: 201, Grad norm: 3.7577406462030374\n",
      "Epoch 6753, Loss: 208.74175575224638, Neurons: 201, Grad norm: 4.438217609139272\n",
      "Epoch 6753, Loss: 208.74175575224638, Neurons: 201, Grad norm: 4.438217609139272\n",
      "Epoch 6754, Loss: 208.74170134860822, Neurons: 201, Grad norm: 4.607649015329055\n",
      "Epoch 6754, Loss: 208.74170134860822, Neurons: 201, Grad norm: 4.607649015329055\n",
      "Epoch 6755, Loss: 208.74172752971742, Neurons: 201, Grad norm: 4.999935997800022\n",
      "Epoch 6755, Loss: 208.74172752971742, Neurons: 201, Grad norm: 4.999935997800022\n",
      "Epoch 6756, Loss: 208.74174865352023, Neurons: 201, Grad norm: 5.7095234071797005\n",
      "Epoch 6756, Loss: 208.74174865352023, Neurons: 201, Grad norm: 5.7095234071797005\n",
      "Epoch 6757, Loss: 208.7417730804963, Neurons: 201, Grad norm: 6.4467446735410565\n",
      "Epoch 6757, Loss: 208.7417730804963, Neurons: 201, Grad norm: 6.4467446735410565\n",
      "Epoch 6758, Loss: 208.74188488915033, Neurons: 201, Grad norm: 7.251033644700253\n",
      "Epoch 6758, Loss: 208.74188488915033, Neurons: 201, Grad norm: 7.251033644700253\n",
      "Epoch 6759, Loss: 208.74187505153665, Neurons: 201, Grad norm: 8.73467593641521\n",
      "Epoch 6759, Loss: 208.74187505153665, Neurons: 201, Grad norm: 8.73467593641521\n",
      "Epoch 6760, Loss: 208.7418814753628, Neurons: 201, Grad norm: 9.68146383013296\n",
      "Epoch 6760, Loss: 208.7418814753628, Neurons: 201, Grad norm: 9.68146383013296\n",
      "Epoch 6761, Loss: 208.74201583925336, Neurons: 201, Grad norm: 10.691227910096112\n",
      "Epoch 6761, Loss: 208.74201583925336, Neurons: 201, Grad norm: 10.691227910096112\n",
      "Epoch 6762, Loss: 208.74218941952398, Neurons: 201, Grad norm: 10.770598837559094\n",
      "Epoch 6762, Loss: 208.74218941952398, Neurons: 201, Grad norm: 10.770598837559094\n",
      "Epoch 6763, Loss: 208.74211939405617, Neurons: 201, Grad norm: 9.851433913694057\n",
      "Epoch 6763, Loss: 208.74211939405617, Neurons: 201, Grad norm: 9.851433913694057\n",
      "Epoch 6764, Loss: 208.7419024952701, Neurons: 201, Grad norm: 8.157632699958356\n",
      "Epoch 6764, Loss: 208.7419024952701, Neurons: 201, Grad norm: 8.157632699958356\n",
      "Epoch 6765, Loss: 208.74148833147763, Neurons: 201, Grad norm: 5.92684413533504\n",
      "Epoch 6765, Loss: 208.74148833147763, Neurons: 201, Grad norm: 5.92684413533504\n",
      "Epoch 6766, Loss: 208.74109087124927, Neurons: 201, Grad norm: 3.6481472483233026\n",
      "Epoch 6766, Loss: 208.74109087124927, Neurons: 201, Grad norm: 3.6481472483233026\n",
      "Epoch 6767, Loss: 208.74082402685764, Neurons: 201, Grad norm: 1.4016000556920958\n",
      "Epoch 6767, Loss: 208.74082402685764, Neurons: 201, Grad norm: 1.4016000556920958\n",
      "Epoch 6768, Loss: 208.74049402232689, Neurons: 201, Grad norm: 0.8244938174578176\n",
      "Epoch 6768, Loss: 208.74049402232689, Neurons: 201, Grad norm: 0.8244938174578176\n",
      "Epoch 6769, Loss: 208.74030364896473, Neurons: 201, Grad norm: 2.5261195063153976\n",
      "Epoch 6769, Loss: 208.74030364896473, Neurons: 201, Grad norm: 2.5261195063153976\n",
      "Epoch 6770, Loss: 208.74037199686248, Neurons: 201, Grad norm: 4.451121324130146\n",
      "Epoch 6770, Loss: 208.74037199686248, Neurons: 201, Grad norm: 4.451121324130146\n",
      "Epoch 6771, Loss: 208.74052369093766, Neurons: 201, Grad norm: 6.300171709357256\n",
      "Epoch 6771, Loss: 208.74052369093766, Neurons: 201, Grad norm: 6.300171709357256\n",
      "Epoch 6772, Loss: 208.74071862030578, Neurons: 201, Grad norm: 8.35750864509145\n",
      "Epoch 6772, Loss: 208.74071862030578, Neurons: 201, Grad norm: 8.35750864509145\n",
      "Epoch 6773, Loss: 208.7409475021716, Neurons: 201, Grad norm: 10.03912775893658\n",
      "Epoch 6773, Loss: 208.7409475021716, Neurons: 201, Grad norm: 10.03912775893658\n",
      "Epoch 6774, Loss: 208.74110602288414, Neurons: 201, Grad norm: 11.462614371998846\n",
      "Epoch 6774, Loss: 208.74110602288414, Neurons: 201, Grad norm: 11.462614371998846\n",
      "Epoch 6775, Loss: 208.7412949369262, Neurons: 201, Grad norm: 11.36564132168801\n",
      "Epoch 6775, Loss: 208.7412949369262, Neurons: 201, Grad norm: 11.36564132168801\n",
      "Epoch 6776, Loss: 208.74128936371795, Neurons: 201, Grad norm: 10.627999861579005\n",
      "Epoch 6776, Loss: 208.74128936371795, Neurons: 201, Grad norm: 10.627999861579005\n",
      "Epoch 6777, Loss: 208.7410595996467, Neurons: 201, Grad norm: 8.444330527806471\n",
      "Epoch 6777, Loss: 208.7410595996467, Neurons: 201, Grad norm: 8.444330527806471\n",
      "Epoch 6778, Loss: 208.74046976180855, Neurons: 201, Grad norm: 5.465198066980522\n",
      "Epoch 6778, Loss: 208.74046976180855, Neurons: 201, Grad norm: 5.465198066980522\n",
      "Epoch 6779, Loss: 208.7399525543061, Neurons: 201, Grad norm: 2.7530461634019474\n",
      "Epoch 6779, Loss: 208.7399525543061, Neurons: 201, Grad norm: 2.7530461634019474\n",
      "Epoch 6780, Loss: 208.739805343936, Neurons: 201, Grad norm: 1.5415039774694606\n",
      "Epoch 6780, Loss: 208.739805343936, Neurons: 201, Grad norm: 1.5415039774694606\n",
      "Epoch 6781, Loss: 208.73964763194405, Neurons: 201, Grad norm: 2.7304731354034306\n",
      "Epoch 6781, Loss: 208.73964763194405, Neurons: 201, Grad norm: 2.7304731354034306\n",
      "Epoch 6782, Loss: 208.7394203495906, Neurons: 201, Grad norm: 4.324411282411845\n",
      "Epoch 6782, Loss: 208.7394203495906, Neurons: 201, Grad norm: 4.324411282411845\n",
      "Epoch 6783, Loss: 208.73952346705235, Neurons: 201, Grad norm: 6.020959019763781\n",
      "Epoch 6783, Loss: 208.73952346705235, Neurons: 201, Grad norm: 6.020959019763781\n",
      "Epoch 6784, Loss: 208.73987222494483, Neurons: 201, Grad norm: 7.474802405808819\n",
      "Epoch 6784, Loss: 208.73987222494483, Neurons: 201, Grad norm: 7.474802405808819\n",
      "Epoch 6785, Loss: 208.7401787334349, Neurons: 201, Grad norm: 8.608159471064251\n",
      "Epoch 6785, Loss: 208.7401787334349, Neurons: 201, Grad norm: 8.608159471064251\n",
      "Epoch 6786, Loss: 208.7402488894057, Neurons: 201, Grad norm: 9.105354445800822\n",
      "Epoch 6786, Loss: 208.7402488894057, Neurons: 201, Grad norm: 9.105354445800822\n",
      "Epoch 6787, Loss: 208.7400893739005, Neurons: 201, Grad norm: 9.001176700138625\n",
      "Epoch 6787, Loss: 208.7400893739005, Neurons: 201, Grad norm: 9.001176700138625\n",
      "Epoch 6788, Loss: 208.73981487061508, Neurons: 201, Grad norm: 7.76752071040314\n",
      "Epoch 6788, Loss: 208.73981487061508, Neurons: 201, Grad norm: 7.76752071040314\n",
      "Epoch 6789, Loss: 208.73955160205682, Neurons: 201, Grad norm: 5.747429560413003\n",
      "Epoch 6789, Loss: 208.73955160205682, Neurons: 201, Grad norm: 5.747429560413003\n",
      "Epoch 6790, Loss: 208.73922853168435, Neurons: 201, Grad norm: 3.2141231884903467\n",
      "Epoch 6790, Loss: 208.73922853168435, Neurons: 201, Grad norm: 3.2141231884903467\n",
      "Epoch 6791, Loss: 208.73877011707063, Neurons: 201, Grad norm: 1.0910331314227915\n",
      "Epoch 6791, Loss: 208.73877011707063, Neurons: 201, Grad norm: 1.0910331314227915\n",
      "Epoch 6792, Loss: 208.73866761021222, Neurons: 201, Grad norm: 2.293255966796025\n",
      "Epoch 6792, Loss: 208.73866761021222, Neurons: 201, Grad norm: 2.293255966796025\n",
      "Epoch 6793, Loss: 208.73882131272157, Neurons: 201, Grad norm: 3.5862781478762242\n",
      "Epoch 6793, Loss: 208.73882131272157, Neurons: 201, Grad norm: 3.5862781478762242\n",
      "Epoch 6794, Loss: 208.73871526697812, Neurons: 201, Grad norm: 5.139808721593047\n",
      "Epoch 6794, Loss: 208.73871526697812, Neurons: 201, Grad norm: 5.139808721593047\n",
      "Epoch 6795, Loss: 208.7386477316716, Neurons: 201, Grad norm: 6.4111382050884185\n",
      "Epoch 6795, Loss: 208.7386477316716, Neurons: 201, Grad norm: 6.4111382050884185\n",
      "Epoch 6796, Loss: 208.73884151005922, Neurons: 201, Grad norm: 7.9329858160462745\n",
      "Epoch 6796, Loss: 208.73884151005922, Neurons: 201, Grad norm: 7.9329858160462745\n",
      "Epoch 6797, Loss: 208.7392240033017, Neurons: 201, Grad norm: 8.957879583568673\n",
      "Epoch 6797, Loss: 208.7392240033017, Neurons: 201, Grad norm: 8.957879583568673\n",
      "Epoch 6798, Loss: 208.7394263680957, Neurons: 201, Grad norm: 9.297460968613603\n",
      "Epoch 6798, Loss: 208.7394263680957, Neurons: 201, Grad norm: 9.297460968613603\n",
      "Epoch 6799, Loss: 208.73938295743469, Neurons: 201, Grad norm: 8.839409497958103\n",
      "Epoch 6799, Loss: 208.73938295743469, Neurons: 201, Grad norm: 8.839409497958103\n",
      "Epoch 6800, Loss: 208.7390863636355, Neurons: 201, Grad norm: 7.718208410850551\n",
      "Epoch 6800, Loss: 208.7390863636355, Neurons: 201, Grad norm: 7.718208410850551\n",
      "Epoch 6801, Loss: 208.7387211422018, Neurons: 201, Grad norm: 5.758470765146133\n",
      "Epoch 6801, Loss: 208.7387211422018, Neurons: 201, Grad norm: 5.758470765146133\n",
      "Epoch 6802, Loss: 208.73834959150741, Neurons: 201, Grad norm: 2.978738284248969\n",
      "Epoch 6802, Loss: 208.73834959150741, Neurons: 201, Grad norm: 2.978738284248969\n",
      "Epoch 6803, Loss: 208.73796970168914, Neurons: 201, Grad norm: 0.7133772314426691\n",
      "Epoch 6803, Loss: 208.73796970168914, Neurons: 201, Grad norm: 0.7133772314426691\n",
      "Epoch 6804, Loss: 208.737753718517, Neurons: 201, Grad norm: 3.347972821054481\n",
      "Epoch 6804, Loss: 208.737753718517, Neurons: 201, Grad norm: 3.347972821054481\n",
      "Epoch 6805, Loss: 208.73775815972198, Neurons: 201, Grad norm: 5.7202481358085775\n",
      "Epoch 6805, Loss: 208.73775815972198, Neurons: 201, Grad norm: 5.7202481358085775\n",
      "Epoch 6806, Loss: 208.73798840417427, Neurons: 201, Grad norm: 7.307561492564561\n",
      "Epoch 6806, Loss: 208.73798840417427, Neurons: 201, Grad norm: 7.307561492564561\n",
      "Epoch 6807, Loss: 208.7382321744156, Neurons: 201, Grad norm: 8.127107630484442\n",
      "Epoch 6807, Loss: 208.7382321744156, Neurons: 201, Grad norm: 8.127107630484442\n",
      "Epoch 6808, Loss: 208.73820898233993, Neurons: 201, Grad norm: 8.007844244461566\n",
      "Epoch 6808, Loss: 208.73820898233993, Neurons: 201, Grad norm: 8.007844244461566\n",
      "Epoch 6809, Loss: 208.73806712916726, Neurons: 201, Grad norm: 7.80207647173195\n",
      "Epoch 6809, Loss: 208.73806712916726, Neurons: 201, Grad norm: 7.80207647173195\n",
      "Epoch 6810, Loss: 208.7381283463619, Neurons: 201, Grad norm: 7.238618843193683\n",
      "Epoch 6810, Loss: 208.7381283463619, Neurons: 201, Grad norm: 7.238618843193683\n",
      "Epoch 6811, Loss: 208.7384970518272, Neurons: 201, Grad norm: 6.762953741060891\n",
      "Epoch 6811, Loss: 208.7384970518272, Neurons: 201, Grad norm: 6.762953741060891\n",
      "Epoch 6812, Loss: 208.7383993459164, Neurons: 201, Grad norm: 5.784681776754897\n",
      "Epoch 6812, Loss: 208.7383993459164, Neurons: 201, Grad norm: 5.784681776754897\n",
      "Epoch 6813, Loss: 208.73785264247437, Neurons: 201, Grad norm: 5.196649483370447\n",
      "Epoch 6813, Loss: 208.73785264247437, Neurons: 201, Grad norm: 5.196649483370447\n",
      "Epoch 6814, Loss: 208.737336161928, Neurons: 201, Grad norm: 4.3499918104454895\n",
      "Epoch 6814, Loss: 208.737336161928, Neurons: 201, Grad norm: 4.3499918104454895\n",
      "Epoch 6815, Loss: 208.7372524298665, Neurons: 201, Grad norm: 3.323000000791163\n",
      "Epoch 6815, Loss: 208.7372524298665, Neurons: 201, Grad norm: 3.323000000791163\n",
      "Epoch 6816, Loss: 208.7372154394426, Neurons: 201, Grad norm: 1.6431097530185528\n",
      "Epoch 6816, Loss: 208.7372154394426, Neurons: 201, Grad norm: 1.6431097530185528\n",
      "Epoch 6817, Loss: 208.73697862302154, Neurons: 201, Grad norm: 1.445725145928014\n",
      "Epoch 6817, Loss: 208.73697862302154, Neurons: 201, Grad norm: 1.445725145928014\n",
      "Epoch 6818, Loss: 208.7367652751016, Neurons: 201, Grad norm: 3.047333358999138\n",
      "Epoch 6818, Loss: 208.7367652751016, Neurons: 201, Grad norm: 3.047333358999138\n",
      "Epoch 6819, Loss: 208.73675635420022, Neurons: 201, Grad norm: 4.7558236896628285\n",
      "Epoch 6819, Loss: 208.73675635420022, Neurons: 201, Grad norm: 4.7558236896628285\n",
      "Epoch 6820, Loss: 208.73686479258546, Neurons: 201, Grad norm: 6.02060261655357\n",
      "Epoch 6820, Loss: 208.73686479258546, Neurons: 201, Grad norm: 6.02060261655357\n",
      "Epoch 6821, Loss: 208.73696787033626, Neurons: 201, Grad norm: 6.947363964787145\n",
      "Epoch 6821, Loss: 208.73696787033626, Neurons: 201, Grad norm: 6.947363964787145\n",
      "Epoch 6822, Loss: 208.7369773429126, Neurons: 201, Grad norm: 7.658960422632993\n",
      "Epoch 6822, Loss: 208.7369773429126, Neurons: 201, Grad norm: 7.658960422632993\n",
      "Epoch 6823, Loss: 208.73707129536336, Neurons: 201, Grad norm: 8.141771348754022\n",
      "Epoch 6823, Loss: 208.73707129536336, Neurons: 201, Grad norm: 8.141771348754022\n",
      "Epoch 6824, Loss: 208.73719886506484, Neurons: 201, Grad norm: 8.326848468032514\n",
      "Epoch 6824, Loss: 208.73719886506484, Neurons: 201, Grad norm: 8.326848468032514\n",
      "Epoch 6825, Loss: 208.7372901255519, Neurons: 201, Grad norm: 7.953177534835084\n",
      "Epoch 6825, Loss: 208.7372901255519, Neurons: 201, Grad norm: 7.953177534835084\n",
      "Epoch 6826, Loss: 208.73733150382424, Neurons: 201, Grad norm: 7.504953903656227\n",
      "Epoch 6826, Loss: 208.73733150382424, Neurons: 201, Grad norm: 7.504953903656227\n",
      "Epoch 6827, Loss: 208.73702617915708, Neurons: 201, Grad norm: 6.684130206311447\n",
      "Epoch 6827, Loss: 208.73702617915708, Neurons: 201, Grad norm: 6.684130206311447\n",
      "Epoch 6828, Loss: 208.73672771775338, Neurons: 201, Grad norm: 5.8210120749803105\n",
      "Epoch 6828, Loss: 208.73672771775338, Neurons: 201, Grad norm: 5.8210120749803105\n",
      "Epoch 6829, Loss: 208.73640134754905, Neurons: 201, Grad norm: 4.45296261309244\n",
      "Epoch 6829, Loss: 208.73640134754905, Neurons: 201, Grad norm: 4.45296261309244\n",
      "Epoch 6830, Loss: 208.7361509409218, Neurons: 201, Grad norm: 2.9473965651313865\n",
      "Epoch 6830, Loss: 208.7361509409218, Neurons: 201, Grad norm: 2.9473965651313865\n",
      "Epoch 6831, Loss: 208.73598282101236, Neurons: 201, Grad norm: 1.6315987000208785\n",
      "Epoch 6831, Loss: 208.73598282101236, Neurons: 201, Grad norm: 1.6315987000208785\n",
      "Epoch 6832, Loss: 208.7359433694806, Neurons: 201, Grad norm: 1.6329687584518628\n",
      "Epoch 6832, Loss: 208.7359433694806, Neurons: 201, Grad norm: 1.6329687584518628\n",
      "Epoch 6833, Loss: 208.7358367993908, Neurons: 201, Grad norm: 3.2867982832015445\n",
      "Epoch 6833, Loss: 208.7358367993908, Neurons: 201, Grad norm: 3.2867982832015445\n",
      "Epoch 6834, Loss: 208.7357399791572, Neurons: 201, Grad norm: 5.310952028992678\n",
      "Epoch 6834, Loss: 208.7357399791572, Neurons: 201, Grad norm: 5.310952028992678\n",
      "Epoch 6835, Loss: 208.7358781678426, Neurons: 201, Grad norm: 7.874748150126988\n",
      "Epoch 6835, Loss: 208.7358781678426, Neurons: 201, Grad norm: 7.874748150126988\n",
      "Epoch 6836, Loss: 208.7361447169208, Neurons: 201, Grad norm: 9.44040032153922\n",
      "Epoch 6836, Loss: 208.7361447169208, Neurons: 201, Grad norm: 9.44040032153922\n",
      "Epoch 6837, Loss: 208.73647234443155, Neurons: 201, Grad norm: 10.716567513966776\n",
      "Epoch 6837, Loss: 208.73647234443155, Neurons: 201, Grad norm: 10.716567513966776\n",
      "Epoch 6838, Loss: 208.7366728962262, Neurons: 201, Grad norm: 10.473301378403454\n",
      "Epoch 6838, Loss: 208.7366728962262, Neurons: 201, Grad norm: 10.473301378403454\n",
      "Epoch 6839, Loss: 208.73663375653175, Neurons: 201, Grad norm: 9.512014195406644\n",
      "Epoch 6839, Loss: 208.73663375653175, Neurons: 201, Grad norm: 9.512014195406644\n",
      "Epoch 6840, Loss: 208.73641003697236, Neurons: 201, Grad norm: 7.993936119889455\n",
      "Epoch 6840, Loss: 208.73641003697236, Neurons: 201, Grad norm: 7.993936119889455\n",
      "Epoch 6841, Loss: 208.73623586461972, Neurons: 201, Grad norm: 6.058685060953871\n",
      "Epoch 6841, Loss: 208.73623586461972, Neurons: 201, Grad norm: 6.058685060953871\n",
      "Epoch 6842, Loss: 208.7357769400965, Neurons: 201, Grad norm: 4.070108212707986\n",
      "Epoch 6842, Loss: 208.7357769400965, Neurons: 201, Grad norm: 4.070108212707986\n",
      "Epoch 6843, Loss: 208.73522990890532, Neurons: 201, Grad norm: 2.3348431130055984\n",
      "Epoch 6843, Loss: 208.73522990890532, Neurons: 201, Grad norm: 2.3348431130055984\n",
      "Epoch 6844, Loss: 208.73512166247724, Neurons: 201, Grad norm: 0.9604362142828361\n",
      "Epoch 6844, Loss: 208.73512166247724, Neurons: 201, Grad norm: 0.9604362142828361\n",
      "Epoch 6845, Loss: 208.73506056816652, Neurons: 201, Grad norm: 1.6966156082137565\n",
      "Epoch 6845, Loss: 208.73506056816652, Neurons: 201, Grad norm: 1.6966156082137565\n",
      "Epoch 6846, Loss: 208.73496682737678, Neurons: 201, Grad norm: 3.0107813970414465\n",
      "Epoch 6846, Loss: 208.73496682737678, Neurons: 201, Grad norm: 3.0107813970414465\n",
      "Epoch 6847, Loss: 208.73485120146333, Neurons: 201, Grad norm: 4.043733076252862\n",
      "Epoch 6847, Loss: 208.73485120146333, Neurons: 201, Grad norm: 4.043733076252862\n",
      "Epoch 6848, Loss: 208.7349726713829, Neurons: 201, Grad norm: 4.412268455041493\n",
      "Epoch 6848, Loss: 208.7349726713829, Neurons: 201, Grad norm: 4.412268455041493\n",
      "Epoch 6849, Loss: 208.73491957260774, Neurons: 201, Grad norm: 4.302049633420777\n",
      "Epoch 6849, Loss: 208.73491957260774, Neurons: 201, Grad norm: 4.302049633420777\n",
      "Epoch 6850, Loss: 208.73471528790992, Neurons: 201, Grad norm: 4.189609621275681\n",
      "Epoch 6850, Loss: 208.73471528790992, Neurons: 201, Grad norm: 4.189609621275681\n",
      "Epoch 6851, Loss: 208.73470319522653, Neurons: 201, Grad norm: 3.534058345078261\n",
      "Epoch 6851, Loss: 208.73470319522653, Neurons: 201, Grad norm: 3.534058345078261\n",
      "Epoch 6852, Loss: 208.73462578000425, Neurons: 201, Grad norm: 3.314673762272904\n",
      "Epoch 6852, Loss: 208.73462578000425, Neurons: 201, Grad norm: 3.314673762272904\n",
      "Epoch 6853, Loss: 208.734453005424, Neurons: 201, Grad norm: 2.774976038873614\n",
      "Epoch 6853, Loss: 208.734453005424, Neurons: 201, Grad norm: 2.774976038873614\n",
      "Epoch 6854, Loss: 208.73439285962615, Neurons: 201, Grad norm: 2.6116016741273733\n",
      "Epoch 6854, Loss: 208.73439285962615, Neurons: 201, Grad norm: 2.6116016741273733\n",
      "Epoch 6855, Loss: 208.73430460102907, Neurons: 201, Grad norm: 2.5654704765646708\n",
      "Epoch 6855, Loss: 208.73430460102907, Neurons: 201, Grad norm: 2.5654704765646708\n",
      "Epoch 6856, Loss: 208.73417237983884, Neurons: 201, Grad norm: 2.6911355487073023\n",
      "Epoch 6856, Loss: 208.73417237983884, Neurons: 201, Grad norm: 2.6911355487073023\n",
      "Epoch 6857, Loss: 208.73411382776834, Neurons: 201, Grad norm: 2.9820299690986\n",
      "Epoch 6857, Loss: 208.73411382776834, Neurons: 201, Grad norm: 2.9820299690986\n",
      "Epoch 6858, Loss: 208.7340948410096, Neurons: 201, Grad norm: 3.2886770373996725\n",
      "Epoch 6858, Loss: 208.7340948410096, Neurons: 201, Grad norm: 3.2886770373996725\n",
      "Epoch 6859, Loss: 208.73407159897508, Neurons: 201, Grad norm: 3.3993918164932384\n",
      "Epoch 6859, Loss: 208.73407159897508, Neurons: 201, Grad norm: 3.3993918164932384\n",
      "Epoch 6860, Loss: 208.73396959503455, Neurons: 201, Grad norm: 3.5422581497202352\n",
      "Epoch 6860, Loss: 208.73396959503455, Neurons: 201, Grad norm: 3.5422581497202352\n",
      "Epoch 6861, Loss: 208.73390507545648, Neurons: 201, Grad norm: 3.7370749250787973\n",
      "Epoch 6861, Loss: 208.73390507545648, Neurons: 201, Grad norm: 3.7370749250787973\n",
      "Epoch 6862, Loss: 208.7339963684683, Neurons: 201, Grad norm: 4.051850815255297\n",
      "Epoch 6862, Loss: 208.7339963684683, Neurons: 201, Grad norm: 4.051850815255297\n",
      "Epoch 6863, Loss: 208.73396503268418, Neurons: 201, Grad norm: 4.2397467108031295\n",
      "Epoch 6863, Loss: 208.73396503268418, Neurons: 201, Grad norm: 4.2397467108031295\n",
      "Epoch 6864, Loss: 208.73386337652195, Neurons: 201, Grad norm: 4.857939957144427\n",
      "Epoch 6864, Loss: 208.73386337652195, Neurons: 201, Grad norm: 4.857939957144427\n",
      "Epoch 6865, Loss: 208.73377328857597, Neurons: 201, Grad norm: 5.104164751725662\n",
      "Epoch 6865, Loss: 208.73377328857597, Neurons: 201, Grad norm: 5.104164751725662\n",
      "Epoch 6866, Loss: 208.7336862183885, Neurons: 201, Grad norm: 5.717203549244281\n",
      "Epoch 6866, Loss: 208.7336862183885, Neurons: 201, Grad norm: 5.717203549244281\n",
      "Epoch 6867, Loss: 208.73372216524874, Neurons: 201, Grad norm: 5.945239321909447\n",
      "Epoch 6867, Loss: 208.73372216524874, Neurons: 201, Grad norm: 5.945239321909447\n",
      "Epoch 6868, Loss: 208.7336867821532, Neurons: 201, Grad norm: 6.296215939601687\n",
      "Epoch 6868, Loss: 208.7336867821532, Neurons: 201, Grad norm: 6.296215939601687\n",
      "Epoch 6869, Loss: 208.73363568632348, Neurons: 201, Grad norm: 6.479961346722357\n",
      "Epoch 6869, Loss: 208.73363568632348, Neurons: 201, Grad norm: 6.479961346722357\n",
      "Epoch 6870, Loss: 208.73367655595771, Neurons: 201, Grad norm: 6.9578824944184365\n",
      "Epoch 6870, Loss: 208.73367655595771, Neurons: 201, Grad norm: 6.9578824944184365\n",
      "Epoch 6871, Loss: 208.7337946447394, Neurons: 201, Grad norm: 7.318368493449986\n",
      "Epoch 6871, Loss: 208.7337946447394, Neurons: 201, Grad norm: 7.318368493449986\n",
      "Epoch 6872, Loss: 208.7338483418019, Neurons: 201, Grad norm: 7.709108663686037\n",
      "Epoch 6872, Loss: 208.7338483418019, Neurons: 201, Grad norm: 7.709108663686037\n",
      "Epoch 6873, Loss: 208.73376942040863, Neurons: 201, Grad norm: 8.10767315366699\n",
      "Epoch 6873, Loss: 208.73376942040863, Neurons: 201, Grad norm: 8.10767315366699\n",
      "Epoch 6874, Loss: 208.73363659773236, Neurons: 201, Grad norm: 8.60585155115738\n",
      "Epoch 6874, Loss: 208.73363659773236, Neurons: 201, Grad norm: 8.60585155115738\n",
      "Epoch 6875, Loss: 208.73362101369605, Neurons: 201, Grad norm: 8.816345333361031\n",
      "Epoch 6875, Loss: 208.73362101369605, Neurons: 201, Grad norm: 8.816345333361031\n",
      "Epoch 6876, Loss: 208.73361321702805, Neurons: 201, Grad norm: 8.926040554076238\n",
      "Epoch 6876, Loss: 208.73361321702805, Neurons: 201, Grad norm: 8.926040554076238\n",
      "Epoch 6877, Loss: 208.7334966159263, Neurons: 201, Grad norm: 7.960553906034853\n",
      "Epoch 6877, Loss: 208.7334966159263, Neurons: 201, Grad norm: 7.960553906034853\n",
      "Epoch 6878, Loss: 208.73333847658563, Neurons: 201, Grad norm: 7.121069002082629\n",
      "Epoch 6878, Loss: 208.73333847658563, Neurons: 201, Grad norm: 7.121069002082629\n",
      "Epoch 6879, Loss: 208.73315576278358, Neurons: 201, Grad norm: 6.142147975430917\n",
      "Epoch 6879, Loss: 208.73315576278358, Neurons: 201, Grad norm: 6.142147975430917\n",
      "Epoch 6880, Loss: 208.73298266830597, Neurons: 201, Grad norm: 5.159348260655127\n",
      "Epoch 6880, Loss: 208.73298266830597, Neurons: 201, Grad norm: 5.159348260655127\n",
      "Epoch 6881, Loss: 208.73278320335962, Neurons: 201, Grad norm: 4.450885537997545\n",
      "Epoch 6881, Loss: 208.73278320335962, Neurons: 201, Grad norm: 4.450885537997545\n",
      "Epoch 6882, Loss: 208.73249256513893, Neurons: 201, Grad norm: 4.014825758805567\n",
      "Epoch 6882, Loss: 208.73249256513893, Neurons: 201, Grad norm: 4.014825758805567\n",
      "Epoch 6883, Loss: 208.73241082668068, Neurons: 201, Grad norm: 3.5403239731906204\n",
      "Epoch 6883, Loss: 208.73241082668068, Neurons: 201, Grad norm: 3.5403239731906204\n",
      "Epoch 6884, Loss: 208.73239935656295, Neurons: 201, Grad norm: 3.0076002262723396\n",
      "Epoch 6884, Loss: 208.73239935656295, Neurons: 201, Grad norm: 3.0076002262723396\n",
      "Epoch 6885, Loss: 208.7321983456537, Neurons: 201, Grad norm: 1.897187199788908\n",
      "Epoch 6885, Loss: 208.7321983456537, Neurons: 201, Grad norm: 1.897187199788908\n",
      "Epoch 6886, Loss: 208.73211404072364, Neurons: 201, Grad norm: 1.1709126794791755\n",
      "Epoch 6886, Loss: 208.73211404072364, Neurons: 201, Grad norm: 1.1709126794791755\n",
      "Epoch 6887, Loss: 208.732024146083, Neurons: 201, Grad norm: 0.6658134372656894\n",
      "Epoch 6887, Loss: 208.732024146083, Neurons: 201, Grad norm: 0.6658134372656894\n",
      "Epoch 6888, Loss: 208.731914504777, Neurons: 201, Grad norm: 0.9069633934872966\n",
      "Epoch 6888, Loss: 208.731914504777, Neurons: 201, Grad norm: 0.9069633934872966\n",
      "Epoch 6889, Loss: 208.7318257583559, Neurons: 201, Grad norm: 1.1314186736994867\n",
      "Epoch 6889, Loss: 208.7318257583559, Neurons: 201, Grad norm: 1.1314186736994867\n",
      "Epoch 6890, Loss: 208.731772508666, Neurons: 201, Grad norm: 1.2843311926075394\n",
      "Epoch 6890, Loss: 208.731772508666, Neurons: 201, Grad norm: 1.2843311926075394\n",
      "Epoch 6891, Loss: 208.73163768010042, Neurons: 201, Grad norm: 1.7017559733709013\n",
      "Epoch 6891, Loss: 208.73163768010042, Neurons: 201, Grad norm: 1.7017559733709013\n",
      "Epoch 6892, Loss: 208.73163756747994, Neurons: 201, Grad norm: 2.098005243466542\n",
      "Epoch 6892, Loss: 208.73163756747994, Neurons: 201, Grad norm: 2.098005243466542\n",
      "Epoch 6893, Loss: 208.73168064613026, Neurons: 201, Grad norm: 3.3560503034734275\n",
      "Epoch 6893, Loss: 208.73168064613026, Neurons: 201, Grad norm: 3.3560503034734275\n",
      "Epoch 6894, Loss: 208.731652507463, Neurons: 201, Grad norm: 4.245891148392464\n",
      "Epoch 6894, Loss: 208.731652507463, Neurons: 201, Grad norm: 4.245891148392464\n",
      "Epoch 6895, Loss: 208.7315882146461, Neurons: 201, Grad norm: 6.107335911089262\n",
      "Epoch 6895, Loss: 208.7315882146461, Neurons: 201, Grad norm: 6.107335911089262\n",
      "Epoch 6896, Loss: 208.73171137141426, Neurons: 201, Grad norm: 8.083606165057978\n",
      "Epoch 6896, Loss: 208.73171137141426, Neurons: 201, Grad norm: 8.083606165057978\n",
      "Epoch 6897, Loss: 208.73196124442296, Neurons: 201, Grad norm: 10.024862451258594\n",
      "Epoch 6897, Loss: 208.73196124442296, Neurons: 201, Grad norm: 10.024862451258594\n",
      "Epoch 6898, Loss: 208.73230131063218, Neurons: 201, Grad norm: 11.691235709924195\n",
      "Epoch 6898, Loss: 208.73230131063218, Neurons: 201, Grad norm: 11.691235709924195\n",
      "Epoch 6899, Loss: 208.73270582891874, Neurons: 201, Grad norm: 12.975481127530612\n",
      "Epoch 6899, Loss: 208.73270582891874, Neurons: 201, Grad norm: 12.975481127530612\n",
      "Epoch 6900, Loss: 208.73305528627697, Neurons: 201, Grad norm: 13.349224812898507\n",
      "Epoch 6900, Loss: 208.73305528627697, Neurons: 201, Grad norm: 13.349224812898507\n",
      "Epoch 6901, Loss: 208.73327041249183, Neurons: 201, Grad norm: 13.383741892208585\n",
      "Epoch 6901, Loss: 208.73327041249183, Neurons: 201, Grad norm: 13.383741892208585\n",
      "Epoch 6902, Loss: 208.73337693366284, Neurons: 201, Grad norm: 12.69524299401877\n",
      "Epoch 6902, Loss: 208.73337693366284, Neurons: 201, Grad norm: 12.69524299401877\n",
      "Epoch 6903, Loss: 208.73313739315682, Neurons: 201, Grad norm: 11.548864239467322\n",
      "Epoch 6903, Loss: 208.73313739315682, Neurons: 201, Grad norm: 11.548864239467322\n",
      "Epoch 6904, Loss: 208.73256775323253, Neurons: 201, Grad norm: 10.030555586089944\n",
      "Epoch 6904, Loss: 208.73256775323253, Neurons: 201, Grad norm: 10.030555586089944\n",
      "Epoch 6905, Loss: 208.73191538153455, Neurons: 201, Grad norm: 8.384896952370639\n",
      "Epoch 6905, Loss: 208.73191538153455, Neurons: 201, Grad norm: 8.384896952370639\n",
      "Epoch 6906, Loss: 208.7314376425645, Neurons: 201, Grad norm: 6.2553775407889445\n",
      "Epoch 6906, Loss: 208.7314376425645, Neurons: 201, Grad norm: 6.2553775407889445\n",
      "Epoch 6907, Loss: 208.73099221496662, Neurons: 201, Grad norm: 3.9421566988700443\n",
      "Epoch 6907, Loss: 208.73099221496662, Neurons: 201, Grad norm: 3.9421566988700443\n",
      "Epoch 6908, Loss: 208.7305818052744, Neurons: 201, Grad norm: 1.3829434160179581\n",
      "Epoch 6908, Loss: 208.7305818052744, Neurons: 201, Grad norm: 1.3829434160179581\n",
      "Epoch 6909, Loss: 208.73040841592382, Neurons: 201, Grad norm: 2.1636679166001325\n",
      "Epoch 6909, Loss: 208.73040841592382, Neurons: 201, Grad norm: 2.1636679166001325\n",
      "Epoch 6910, Loss: 208.7304561963598, Neurons: 201, Grad norm: 5.066723127769335\n",
      "Epoch 6910, Loss: 208.7304561963598, Neurons: 201, Grad norm: 5.066723127769335\n",
      "Epoch 6911, Loss: 208.73064859641525, Neurons: 201, Grad norm: 7.422236042845515\n",
      "Epoch 6911, Loss: 208.73064859641525, Neurons: 201, Grad norm: 7.422236042845515\n",
      "Epoch 6912, Loss: 208.73091224294086, Neurons: 201, Grad norm: 9.850976100809701\n",
      "Epoch 6912, Loss: 208.73091224294086, Neurons: 201, Grad norm: 9.850976100809701\n",
      "Epoch 6913, Loss: 208.73124320765604, Neurons: 201, Grad norm: 11.507201028867325\n",
      "Epoch 6913, Loss: 208.73124320765604, Neurons: 201, Grad norm: 11.507201028867325\n",
      "Epoch 6914, Loss: 208.7316467714992, Neurons: 201, Grad norm: 12.815516552373001\n",
      "Epoch 6914, Loss: 208.7316467714992, Neurons: 201, Grad norm: 12.815516552373001\n",
      "Epoch 6915, Loss: 208.73180224439827, Neurons: 201, Grad norm: 12.504456773426398\n",
      "Epoch 6915, Loss: 208.73180224439827, Neurons: 201, Grad norm: 12.504456773426398\n",
      "Epoch 6916, Loss: 208.73174459093136, Neurons: 201, Grad norm: 11.54863524694725\n",
      "Epoch 6916, Loss: 208.73174459093136, Neurons: 201, Grad norm: 11.54863524694725\n",
      "Epoch 6917, Loss: 208.731305037771, Neurons: 201, Grad norm: 9.360186591811905\n",
      "Epoch 6917, Loss: 208.731305037771, Neurons: 201, Grad norm: 9.360186591811905\n",
      "Epoch 6918, Loss: 208.73076892601293, Neurons: 201, Grad norm: 6.437042725542391\n",
      "Epoch 6918, Loss: 208.73076892601293, Neurons: 201, Grad norm: 6.437042725542391\n",
      "Epoch 6919, Loss: 208.73013800267987, Neurons: 201, Grad norm: 3.2832172392767967\n",
      "Epoch 6919, Loss: 208.73013800267987, Neurons: 201, Grad norm: 3.2832172392767967\n",
      "Epoch 6920, Loss: 208.7297993987812, Neurons: 201, Grad norm: 1.3486288166133031\n",
      "Epoch 6920, Loss: 208.7297993987812, Neurons: 201, Grad norm: 1.3486288166133031\n",
      "Epoch 6921, Loss: 208.7296141915142, Neurons: 201, Grad norm: 2.755958856938209\n",
      "Epoch 6921, Loss: 208.7296141915142, Neurons: 201, Grad norm: 2.755958856938209\n",
      "Epoch 6922, Loss: 208.7296007639411, Neurons: 201, Grad norm: 4.090084852253683\n",
      "Epoch 6922, Loss: 208.7296007639411, Neurons: 201, Grad norm: 4.090084852253683\n",
      "Epoch 6923, Loss: 208.72961825944648, Neurons: 201, Grad norm: 4.990352101814423\n",
      "Epoch 6923, Loss: 208.72961825944648, Neurons: 201, Grad norm: 4.990352101814423\n",
      "Epoch 6924, Loss: 208.72955937437854, Neurons: 201, Grad norm: 5.7019659739113795\n",
      "Epoch 6924, Loss: 208.72955937437854, Neurons: 201, Grad norm: 5.7019659739113795\n",
      "Epoch 6925, Loss: 208.7296031536052, Neurons: 201, Grad norm: 6.766340683327393\n",
      "Epoch 6925, Loss: 208.7296031536052, Neurons: 201, Grad norm: 6.766340683327393\n",
      "Epoch 6926, Loss: 208.72989592985442, Neurons: 201, Grad norm: 7.829650431643478\n",
      "Epoch 6926, Loss: 208.72989592985442, Neurons: 201, Grad norm: 7.829650431643478\n",
      "Epoch 6927, Loss: 208.73015867375597, Neurons: 201, Grad norm: 9.18765056507497\n",
      "Epoch 6927, Loss: 208.73015867375597, Neurons: 201, Grad norm: 9.18765056507497\n",
      "Epoch 6928, Loss: 208.73030210738534, Neurons: 201, Grad norm: 10.530699293576642\n",
      "Epoch 6928, Loss: 208.73030210738534, Neurons: 201, Grad norm: 10.530699293576642\n",
      "Epoch 6929, Loss: 208.73027147278611, Neurons: 201, Grad norm: 11.91318761361724\n",
      "Epoch 6929, Loss: 208.73027147278611, Neurons: 201, Grad norm: 11.91318761361724\n",
      "Epoch 6930, Loss: 208.73035313624322, Neurons: 201, Grad norm: 11.802896552496184\n",
      "Epoch 6930, Loss: 208.73035313624322, Neurons: 201, Grad norm: 11.802896552496184\n",
      "Epoch 6931, Loss: 208.73023784187257, Neurons: 201, Grad norm: 11.494139992483206\n",
      "Epoch 6931, Loss: 208.73023784187257, Neurons: 201, Grad norm: 11.494139992483206\n",
      "Epoch 6932, Loss: 208.72990588418747, Neurons: 201, Grad norm: 9.157487408714006\n",
      "Epoch 6932, Loss: 208.72990588418747, Neurons: 201, Grad norm: 9.157487408714006\n",
      "Epoch 6933, Loss: 208.72934194982545, Neurons: 201, Grad norm: 6.92130034058537\n",
      "Epoch 6933, Loss: 208.72934194982545, Neurons: 201, Grad norm: 6.92130034058537\n",
      "Epoch 6934, Loss: 208.7287295723184, Neurons: 201, Grad norm: 3.816171904434689\n",
      "Epoch 6934, Loss: 208.7287295723184, Neurons: 201, Grad norm: 3.816171904434689\n",
      "Epoch 6935, Loss: 208.7282813737317, Neurons: 201, Grad norm: 1.6369827701407451\n",
      "Epoch 6935, Loss: 208.7282813737317, Neurons: 201, Grad norm: 1.6369827701407451\n",
      "Epoch 6936, Loss: 208.72805573859137, Neurons: 201, Grad norm: 2.0278817617168636\n",
      "Epoch 6936, Loss: 208.72805573859137, Neurons: 201, Grad norm: 2.0278817617168636\n",
      "Epoch 6937, Loss: 208.72791527444417, Neurons: 201, Grad norm: 3.6581194511673374\n",
      "Epoch 6937, Loss: 208.72791527444417, Neurons: 201, Grad norm: 3.6581194511673374\n",
      "Epoch 6938, Loss: 208.72783512852556, Neurons: 201, Grad norm: 5.699371078140819\n",
      "Epoch 6938, Loss: 208.72783512852556, Neurons: 201, Grad norm: 5.699371078140819\n",
      "Epoch 6939, Loss: 208.72796160729357, Neurons: 201, Grad norm: 7.192384774581948\n",
      "Epoch 6939, Loss: 208.72796160729357, Neurons: 201, Grad norm: 7.192384774581948\n",
      "Epoch 6940, Loss: 208.72806957509476, Neurons: 201, Grad norm: 9.016276454403508\n",
      "Epoch 6940, Loss: 208.72806957509476, Neurons: 201, Grad norm: 9.016276454403508\n",
      "Epoch 6941, Loss: 208.7282532718337, Neurons: 201, Grad norm: 10.181520386170419\n",
      "Epoch 6941, Loss: 208.7282532718337, Neurons: 201, Grad norm: 10.181520386170419\n",
      "Epoch 6942, Loss: 208.72847263436387, Neurons: 201, Grad norm: 11.70255511890797\n",
      "Epoch 6942, Loss: 208.72847263436387, Neurons: 201, Grad norm: 11.70255511890797\n",
      "Epoch 6943, Loss: 208.7285817581701, Neurons: 201, Grad norm: 11.919576283510606\n",
      "Epoch 6943, Loss: 208.7285817581701, Neurons: 201, Grad norm: 11.919576283510606\n",
      "Epoch 6944, Loss: 208.72849900913704, Neurons: 201, Grad norm: 11.884760122670885\n",
      "Epoch 6944, Loss: 208.72849900913704, Neurons: 201, Grad norm: 11.884760122670885\n",
      "Epoch 6945, Loss: 208.72816588645523, Neurons: 201, Grad norm: 10.337257059769303\n",
      "Epoch 6945, Loss: 208.72816588645523, Neurons: 201, Grad norm: 10.337257059769303\n",
      "Epoch 6946, Loss: 208.72766175655738, Neurons: 201, Grad norm: 8.285069589843792\n",
      "Epoch 6946, Loss: 208.72766175655738, Neurons: 201, Grad norm: 8.285069589843792\n",
      "Epoch 6947, Loss: 208.72695106681854, Neurons: 201, Grad norm: 4.8858391606565545\n",
      "Epoch 6947, Loss: 208.72695106681854, Neurons: 201, Grad norm: 4.8858391606565545\n",
      "Epoch 6948, Loss: 208.72629089383133, Neurons: 201, Grad norm: 2.4652338056390652\n",
      "Epoch 6948, Loss: 208.72629089383133, Neurons: 201, Grad norm: 2.4652338056390652\n",
      "Epoch 6949, Loss: 208.72583561447922, Neurons: 201, Grad norm: 1.5830853165849808\n",
      "Epoch 6949, Loss: 208.72583561447922, Neurons: 201, Grad norm: 1.5830853165849808\n",
      "Epoch 6950, Loss: 208.72552730306268, Neurons: 201, Grad norm: 3.50998386501597\n",
      "Epoch 6950, Loss: 208.72552730306268, Neurons: 201, Grad norm: 3.50998386501597\n",
      "Epoch 6951, Loss: 208.72542691121913, Neurons: 201, Grad norm: 5.568519400909983\n",
      "Epoch 6951, Loss: 208.72542691121913, Neurons: 201, Grad norm: 5.568519400909983\n",
      "Epoch 6952, Loss: 208.72542873701943, Neurons: 201, Grad norm: 7.18901642986998\n",
      "Epoch 6952, Loss: 208.72542873701943, Neurons: 201, Grad norm: 7.18901642986998\n",
      "Epoch 6953, Loss: 208.7254845578926, Neurons: 201, Grad norm: 9.16860405838197\n",
      "Epoch 6953, Loss: 208.7254845578926, Neurons: 201, Grad norm: 9.16860405838197\n",
      "Epoch 6954, Loss: 208.72576989862682, Neurons: 201, Grad norm: 10.137416915752414\n",
      "Epoch 6954, Loss: 208.72576989862682, Neurons: 201, Grad norm: 10.137416915752414\n",
      "Epoch 6955, Loss: 208.72586765308904, Neurons: 201, Grad norm: 11.734920648572114\n",
      "Epoch 6955, Loss: 208.72586765308904, Neurons: 201, Grad norm: 11.734920648572114\n",
      "Epoch 6956, Loss: 208.72573872301385, Neurons: 201, Grad norm: 11.924170652323959\n",
      "Epoch 6956, Loss: 208.72573872301385, Neurons: 201, Grad norm: 11.924170652323959\n",
      "Epoch 6957, Loss: 208.72545850749725, Neurons: 201, Grad norm: 12.061090601379476\n",
      "Epoch 6957, Loss: 208.72545850749725, Neurons: 201, Grad norm: 12.061090601379476\n",
      "Epoch 6958, Loss: 208.7250851228183, Neurons: 201, Grad norm: 10.331192728240397\n",
      "Epoch 6958, Loss: 208.7250851228183, Neurons: 201, Grad norm: 10.331192728240397\n",
      "Epoch 6959, Loss: 208.7244142773929, Neurons: 201, Grad norm: 8.899957268977149\n",
      "Epoch 6959, Loss: 208.7244142773929, Neurons: 201, Grad norm: 8.899957268977149\n",
      "Epoch 6960, Loss: 208.7237094987217, Neurons: 201, Grad norm: 5.805567858960503\n",
      "Epoch 6960, Loss: 208.7237094987217, Neurons: 201, Grad norm: 5.805567858960503\n",
      "Epoch 6961, Loss: 208.72298876613198, Neurons: 201, Grad norm: 3.50822979521909\n",
      "Epoch 6961, Loss: 208.72298876613198, Neurons: 201, Grad norm: 3.50822979521909\n",
      "Epoch 6962, Loss: 208.722375866454, Neurons: 201, Grad norm: 1.0004805820840041\n",
      "Epoch 6962, Loss: 208.722375866454, Neurons: 201, Grad norm: 1.0004805820840041\n",
      "Epoch 6963, Loss: 208.72193666211683, Neurons: 201, Grad norm: 2.208811652578761\n",
      "Epoch 6963, Loss: 208.72193666211683, Neurons: 201, Grad norm: 2.208811652578761\n",
      "Epoch 6964, Loss: 208.72174828424195, Neurons: 201, Grad norm: 4.900367107371626\n",
      "Epoch 6964, Loss: 208.72174828424195, Neurons: 201, Grad norm: 4.900367107371626\n",
      "Epoch 6965, Loss: 208.72187408893708, Neurons: 201, Grad norm: 6.968553966031277\n",
      "Epoch 6965, Loss: 208.72187408893708, Neurons: 201, Grad norm: 6.968553966031277\n",
      "Epoch 6966, Loss: 208.7221169720163, Neurons: 201, Grad norm: 8.395592121868724\n",
      "Epoch 6966, Loss: 208.7221169720163, Neurons: 201, Grad norm: 8.395592121868724\n",
      "Epoch 6967, Loss: 208.722483204643, Neurons: 201, Grad norm: 9.388818949239683\n",
      "Epoch 6967, Loss: 208.722483204643, Neurons: 201, Grad norm: 9.388818949239683\n",
      "Epoch 6968, Loss: 208.7226742175852, Neurons: 201, Grad norm: 9.29751633559736\n",
      "Epoch 6968, Loss: 208.7226742175852, Neurons: 201, Grad norm: 9.29751633559736\n",
      "Epoch 6969, Loss: 208.72261919525806, Neurons: 201, Grad norm: 8.905539665558095\n",
      "Epoch 6969, Loss: 208.72261919525806, Neurons: 201, Grad norm: 8.905539665558095\n",
      "Epoch 6970, Loss: 208.7223309800248, Neurons: 201, Grad norm: 7.599427888547706\n",
      "Epoch 6970, Loss: 208.7223309800248, Neurons: 201, Grad norm: 7.599427888547706\n",
      "Epoch 6971, Loss: 208.72190551123228, Neurons: 201, Grad norm: 5.907157843563695\n",
      "Epoch 6971, Loss: 208.72190551123228, Neurons: 201, Grad norm: 5.907157843563695\n",
      "Epoch 6972, Loss: 208.72149097335168, Neurons: 201, Grad norm: 3.9190852203127506\n",
      "Epoch 6972, Loss: 208.72149097335168, Neurons: 201, Grad norm: 3.9190852203127506\n",
      "Epoch 6973, Loss: 208.72117407903767, Neurons: 201, Grad norm: 1.9063812160143407\n",
      "Epoch 6973, Loss: 208.72117407903767, Neurons: 201, Grad norm: 1.9063812160143407\n",
      "Epoch 6974, Loss: 208.720985394592, Neurons: 201, Grad norm: 0.9063240559748005\n",
      "Epoch 6974, Loss: 208.720985394592, Neurons: 201, Grad norm: 0.9063240559748005\n",
      "Epoch 6975, Loss: 208.72087179876573, Neurons: 201, Grad norm: 2.308181196120129\n",
      "Epoch 6975, Loss: 208.72087179876573, Neurons: 201, Grad norm: 2.308181196120129\n",
      "Epoch 6976, Loss: 208.7208918570675, Neurons: 201, Grad norm: 3.3315598316282458\n",
      "Epoch 6976, Loss: 208.7208918570675, Neurons: 201, Grad norm: 3.3315598316282458\n",
      "Epoch 6977, Loss: 208.72083870321123, Neurons: 201, Grad norm: 4.272760583083026\n",
      "Epoch 6977, Loss: 208.72083870321123, Neurons: 201, Grad norm: 4.272760583083026\n",
      "Epoch 6978, Loss: 208.72080654038953, Neurons: 201, Grad norm: 5.356419632419181\n",
      "Epoch 6978, Loss: 208.72080654038953, Neurons: 201, Grad norm: 5.356419632419181\n",
      "Epoch 6979, Loss: 208.72089655540788, Neurons: 201, Grad norm: 5.582757946983157\n",
      "Epoch 6979, Loss: 208.72089655540788, Neurons: 201, Grad norm: 5.582757946983157\n",
      "Epoch 6980, Loss: 208.72096041764252, Neurons: 201, Grad norm: 6.5772264853473255\n",
      "Epoch 6980, Loss: 208.72096041764252, Neurons: 201, Grad norm: 6.5772264853473255\n",
      "Epoch 6981, Loss: 208.72095139424985, Neurons: 201, Grad norm: 6.770043101467121\n",
      "Epoch 6981, Loss: 208.72095139424985, Neurons: 201, Grad norm: 6.770043101467121\n",
      "Epoch 6982, Loss: 208.72095962040962, Neurons: 201, Grad norm: 7.353351285141926\n",
      "Epoch 6982, Loss: 208.72095962040962, Neurons: 201, Grad norm: 7.353351285141926\n",
      "Epoch 6983, Loss: 208.72089015143868, Neurons: 201, Grad norm: 7.42968479860115\n",
      "Epoch 6983, Loss: 208.72089015143868, Neurons: 201, Grad norm: 7.42968479860115\n",
      "Epoch 6984, Loss: 208.72071329573524, Neurons: 201, Grad norm: 7.403394658323802\n",
      "Epoch 6984, Loss: 208.72071329573524, Neurons: 201, Grad norm: 7.403394658323802\n",
      "Epoch 6985, Loss: 208.72062735326764, Neurons: 201, Grad norm: 6.31969722871724\n",
      "Epoch 6985, Loss: 208.72062735326764, Neurons: 201, Grad norm: 6.31969722871724\n",
      "Epoch 6986, Loss: 208.72035894692613, Neurons: 201, Grad norm: 5.096799000302088\n",
      "Epoch 6986, Loss: 208.72035894692613, Neurons: 201, Grad norm: 5.096799000302088\n",
      "Epoch 6987, Loss: 208.72010920434445, Neurons: 201, Grad norm: 3.756457863260115\n",
      "Epoch 6987, Loss: 208.72010920434445, Neurons: 201, Grad norm: 3.756457863260115\n",
      "Epoch 6988, Loss: 208.71990875461574, Neurons: 201, Grad norm: 2.5040719969774266\n",
      "Epoch 6988, Loss: 208.71990875461574, Neurons: 201, Grad norm: 2.5040719969774266\n",
      "Epoch 6989, Loss: 208.7198063397634, Neurons: 201, Grad norm: 1.7976209675625825\n",
      "Epoch 6989, Loss: 208.7198063397634, Neurons: 201, Grad norm: 1.7976209675625825\n",
      "Epoch 6990, Loss: 208.71974029801194, Neurons: 201, Grad norm: 1.6282484586474903\n",
      "Epoch 6990, Loss: 208.71974029801194, Neurons: 201, Grad norm: 1.6282484586474903\n",
      "Epoch 6991, Loss: 208.71967304381633, Neurons: 201, Grad norm: 1.542314018384157\n",
      "Epoch 6991, Loss: 208.71967304381633, Neurons: 201, Grad norm: 1.542314018384157\n",
      "Epoch 6992, Loss: 208.71960744399544, Neurons: 201, Grad norm: 1.2545248465037135\n",
      "Epoch 6992, Loss: 208.71960744399544, Neurons: 201, Grad norm: 1.2545248465037135\n",
      "Epoch 6993, Loss: 208.71950326050796, Neurons: 201, Grad norm: 1.7779118513897096\n",
      "Epoch 6993, Loss: 208.71950326050796, Neurons: 201, Grad norm: 1.7779118513897096\n",
      "Epoch 6994, Loss: 208.71938376209, Neurons: 201, Grad norm: 2.0386948263278484\n",
      "Epoch 6994, Loss: 208.71938376209, Neurons: 201, Grad norm: 2.0386948263278484\n",
      "Epoch 6995, Loss: 208.71933748555554, Neurons: 201, Grad norm: 2.750221586018084\n",
      "Epoch 6995, Loss: 208.71933748555554, Neurons: 201, Grad norm: 2.750221586018084\n",
      "Epoch 6996, Loss: 208.71927763873498, Neurons: 201, Grad norm: 2.8238791729301527\n",
      "Epoch 6996, Loss: 208.71927763873498, Neurons: 201, Grad norm: 2.8238791729301527\n",
      "Epoch 6997, Loss: 208.71926548863, Neurons: 201, Grad norm: 2.5882676955473167\n",
      "Epoch 6997, Loss: 208.71926548863, Neurons: 201, Grad norm: 2.5882676955473167\n",
      "Epoch 6998, Loss: 208.719226557397, Neurons: 201, Grad norm: 1.9291654276937469\n",
      "Epoch 6998, Loss: 208.719226557397, Neurons: 201, Grad norm: 1.9291654276937469\n",
      "Epoch 6999, Loss: 208.71899905548457, Neurons: 201, Grad norm: 1.3860521150591847\n",
      "Epoch 6999, Loss: 208.71899905548457, Neurons: 201, Grad norm: 1.3860521150591847\n",
      "Epoch 7000, Loss: 208.71889375432872, Neurons: 201, Grad norm: 0.9056761493901484\n",
      "Epoch 7000, Loss: 208.71889375432872, Neurons: 201, Grad norm: 0.9056761493901484\n",
      "Epoch 7001, Loss: 208.71880323642893, Neurons: 201, Grad norm: 1.0177605239488978\n",
      "Epoch 7001, Loss: 208.71880323642893, Neurons: 201, Grad norm: 1.0177605239488978\n",
      "Epoch 7002, Loss: 208.71875985224477, Neurons: 201, Grad norm: 0.9218093978334746\n",
      "Epoch 7002, Loss: 208.71875985224477, Neurons: 201, Grad norm: 0.9218093978334746\n",
      "Epoch 7003, Loss: 208.7186891937761, Neurons: 201, Grad norm: 1.221817667273758\n",
      "Epoch 7003, Loss: 208.7186891937761, Neurons: 201, Grad norm: 1.221817667273758\n",
      "Epoch 7004, Loss: 208.71859279516158, Neurons: 201, Grad norm: 1.4005298330715914\n",
      "Epoch 7004, Loss: 208.71859279516158, Neurons: 201, Grad norm: 1.4005298330715914\n",
      "Epoch 7005, Loss: 208.7184969456038, Neurons: 201, Grad norm: 1.5572654234083172\n",
      "Epoch 7005, Loss: 208.7184969456038, Neurons: 201, Grad norm: 1.5572654234083172\n",
      "Epoch 7006, Loss: 208.71842766519936, Neurons: 201, Grad norm: 2.201171887491537\n",
      "Epoch 7006, Loss: 208.71842766519936, Neurons: 201, Grad norm: 2.201171887491537\n",
      "Epoch 7007, Loss: 208.71839855508807, Neurons: 201, Grad norm: 2.9606408123720573\n",
      "Epoch 7007, Loss: 208.71839855508807, Neurons: 201, Grad norm: 2.9606408123720573\n",
      "Epoch 7008, Loss: 208.7183856847829, Neurons: 201, Grad norm: 3.9717425100950514\n",
      "Epoch 7008, Loss: 208.7183856847829, Neurons: 201, Grad norm: 3.9717425100950514\n",
      "Epoch 7009, Loss: 208.7183393766854, Neurons: 201, Grad norm: 5.386095890563973\n",
      "Epoch 7009, Loss: 208.7183393766854, Neurons: 201, Grad norm: 5.386095890563973\n",
      "Epoch 7010, Loss: 208.71839155853607, Neurons: 201, Grad norm: 7.050063831250215\n",
      "Epoch 7010, Loss: 208.71839155853607, Neurons: 201, Grad norm: 7.050063831250215\n",
      "Epoch 7011, Loss: 208.7185713329516, Neurons: 201, Grad norm: 8.690219315270236\n",
      "Epoch 7011, Loss: 208.7185713329516, Neurons: 201, Grad norm: 8.690219315270236\n",
      "Epoch 7012, Loss: 208.7187542594043, Neurons: 201, Grad norm: 10.21161588802731\n",
      "Epoch 7012, Loss: 208.7187542594043, Neurons: 201, Grad norm: 10.21161588802731\n",
      "Epoch 7013, Loss: 208.71912918984245, Neurons: 201, Grad norm: 11.863338576131431\n",
      "Epoch 7013, Loss: 208.71912918984245, Neurons: 201, Grad norm: 11.863338576131431\n",
      "Epoch 7014, Loss: 208.71937910790547, Neurons: 201, Grad norm: 12.747192137722884\n",
      "Epoch 7014, Loss: 208.71937910790547, Neurons: 201, Grad norm: 12.747192137722884\n",
      "Epoch 7015, Loss: 208.71961371899042, Neurons: 201, Grad norm: 13.349369666511853\n",
      "Epoch 7015, Loss: 208.71961371899042, Neurons: 201, Grad norm: 13.349369666511853\n",
      "Epoch 7016, Loss: 208.71979205404054, Neurons: 201, Grad norm: 13.577133723828121\n",
      "Epoch 7016, Loss: 208.71979205404054, Neurons: 201, Grad norm: 13.577133723828121\n",
      "Epoch 7017, Loss: 208.7198545121885, Neurons: 201, Grad norm: 12.93252553496912\n",
      "Epoch 7017, Loss: 208.7198545121885, Neurons: 201, Grad norm: 12.93252553496912\n",
      "Epoch 7018, Loss: 208.71967155412423, Neurons: 201, Grad norm: 11.663248407577719\n",
      "Epoch 7018, Loss: 208.71967155412423, Neurons: 201, Grad norm: 11.663248407577719\n",
      "Epoch 7019, Loss: 208.71945982179216, Neurons: 201, Grad norm: 9.802457959297689\n",
      "Epoch 7019, Loss: 208.71945982179216, Neurons: 201, Grad norm: 9.802457959297689\n",
      "Epoch 7020, Loss: 208.71891006176355, Neurons: 201, Grad norm: 7.433543577442476\n",
      "Epoch 7020, Loss: 208.71891006176355, Neurons: 201, Grad norm: 7.433543577442476\n",
      "Epoch 7021, Loss: 208.7181035258754, Neurons: 201, Grad norm: 4.308830269303939\n",
      "Epoch 7021, Loss: 208.7181035258754, Neurons: 201, Grad norm: 4.308830269303939\n",
      "Epoch 7022, Loss: 208.7175351656112, Neurons: 201, Grad norm: 1.6465513728776184\n",
      "Epoch 7022, Loss: 208.7175351656112, Neurons: 201, Grad norm: 1.6465513728776184\n",
      "Epoch 7023, Loss: 208.71725367164674, Neurons: 201, Grad norm: 1.8225683726477542\n",
      "Epoch 7023, Loss: 208.71725367164674, Neurons: 201, Grad norm: 1.8225683726477542\n",
      "Epoch 7024, Loss: 208.71713590998567, Neurons: 201, Grad norm: 4.731093135622648\n",
      "Epoch 7024, Loss: 208.71713590998567, Neurons: 201, Grad norm: 4.731093135622648\n",
      "Epoch 7025, Loss: 208.71729800799065, Neurons: 201, Grad norm: 7.515566410866038\n",
      "Epoch 7025, Loss: 208.71729800799065, Neurons: 201, Grad norm: 7.515566410866038\n",
      "Epoch 7026, Loss: 208.71766960689354, Neurons: 201, Grad norm: 10.293324282532602\n",
      "Epoch 7026, Loss: 208.71766960689354, Neurons: 201, Grad norm: 10.293324282532602\n",
      "Epoch 7027, Loss: 208.71812822868537, Neurons: 201, Grad norm: 12.651569743889736\n",
      "Epoch 7027, Loss: 208.71812822868537, Neurons: 201, Grad norm: 12.651569743889736\n",
      "Epoch 7028, Loss: 208.71867372548328, Neurons: 201, Grad norm: 14.28924137845617\n",
      "Epoch 7028, Loss: 208.71867372548328, Neurons: 201, Grad norm: 14.28924137845617\n",
      "Epoch 7029, Loss: 208.71900278546266, Neurons: 201, Grad norm: 14.723485440439536\n",
      "Epoch 7029, Loss: 208.71900278546266, Neurons: 201, Grad norm: 14.723485440439536\n",
      "Epoch 7030, Loss: 208.71922985669602, Neurons: 201, Grad norm: 14.246746582427889\n",
      "Epoch 7030, Loss: 208.71922985669602, Neurons: 201, Grad norm: 14.246746582427889\n",
      "Epoch 7031, Loss: 208.7191612006261, Neurons: 201, Grad norm: 12.612968498201695\n",
      "Epoch 7031, Loss: 208.7191612006261, Neurons: 201, Grad norm: 12.612968498201695\n",
      "Epoch 7032, Loss: 208.71865723735925, Neurons: 201, Grad norm: 9.695201241421142\n",
      "Epoch 7032, Loss: 208.71865723735925, Neurons: 201, Grad norm: 9.695201241421142\n",
      "Epoch 7033, Loss: 208.7178840853534, Neurons: 201, Grad norm: 6.743924304821334\n",
      "Epoch 7033, Loss: 208.7178840853534, Neurons: 201, Grad norm: 6.743924304821334\n",
      "Epoch 7034, Loss: 208.71711019474535, Neurons: 201, Grad norm: 3.1721755142602417\n",
      "Epoch 7034, Loss: 208.71711019474535, Neurons: 201, Grad norm: 3.1721755142602417\n",
      "Epoch 7035, Loss: 208.71654558605383, Neurons: 201, Grad norm: 0.6495346529718267\n",
      "Epoch 7035, Loss: 208.71654558605383, Neurons: 201, Grad norm: 0.6495346529718267\n",
      "Epoch 7036, Loss: 208.71627769914863, Neurons: 201, Grad norm: 3.1720670936356745\n",
      "Epoch 7036, Loss: 208.71627769914863, Neurons: 201, Grad norm: 3.1720670936356745\n",
      "Epoch 7037, Loss: 208.7163265877772, Neurons: 201, Grad norm: 5.9586524068961175\n",
      "Epoch 7037, Loss: 208.7163265877772, Neurons: 201, Grad norm: 5.9586524068961175\n",
      "Epoch 7038, Loss: 208.7166876238794, Neurons: 201, Grad norm: 7.94941775918113\n",
      "Epoch 7038, Loss: 208.7166876238794, Neurons: 201, Grad norm: 7.94941775918113\n",
      "Epoch 7039, Loss: 208.71702067558624, Neurons: 201, Grad norm: 9.843319230510122\n",
      "Epoch 7039, Loss: 208.71702067558624, Neurons: 201, Grad norm: 9.843319230510122\n",
      "Epoch 7040, Loss: 208.71749838141733, Neurons: 201, Grad norm: 11.136550646066606\n",
      "Epoch 7040, Loss: 208.71749838141733, Neurons: 201, Grad norm: 11.136550646066606\n",
      "Epoch 7041, Loss: 208.71765396168138, Neurons: 201, Grad norm: 11.893960379113867\n",
      "Epoch 7041, Loss: 208.71765396168138, Neurons: 201, Grad norm: 11.893960379113867\n",
      "Epoch 7042, Loss: 208.71768806222093, Neurons: 201, Grad norm: 11.946177569443595\n",
      "Epoch 7042, Loss: 208.71768806222093, Neurons: 201, Grad norm: 11.946177569443595\n",
      "Epoch 7043, Loss: 208.71752534881685, Neurons: 201, Grad norm: 10.876280083610991\n",
      "Epoch 7043, Loss: 208.71752534881685, Neurons: 201, Grad norm: 10.876280083610991\n",
      "Epoch 7044, Loss: 208.71713114678485, Neurons: 201, Grad norm: 8.901091120906921\n",
      "Epoch 7044, Loss: 208.71713114678485, Neurons: 201, Grad norm: 8.901091120906921\n",
      "Epoch 7045, Loss: 208.71652633428172, Neurons: 201, Grad norm: 5.962501928776004\n",
      "Epoch 7045, Loss: 208.71652633428172, Neurons: 201, Grad norm: 5.962501928776004\n",
      "Epoch 7046, Loss: 208.71599276855568, Neurons: 201, Grad norm: 2.835269727081247\n",
      "Epoch 7046, Loss: 208.71599276855568, Neurons: 201, Grad norm: 2.835269727081247\n",
      "Epoch 7047, Loss: 208.71560411479385, Neurons: 201, Grad norm: 1.3945193803599691\n",
      "Epoch 7047, Loss: 208.71560411479385, Neurons: 201, Grad norm: 1.3945193803599691\n",
      "Epoch 7048, Loss: 208.7154506193732, Neurons: 201, Grad norm: 4.433069315151107\n",
      "Epoch 7048, Loss: 208.7154506193732, Neurons: 201, Grad norm: 4.433069315151107\n",
      "Epoch 7049, Loss: 208.71556765927937, Neurons: 201, Grad norm: 7.197764351704795\n",
      "Epoch 7049, Loss: 208.71556765927937, Neurons: 201, Grad norm: 7.197764351704795\n",
      "Epoch 7050, Loss: 208.71586206280458, Neurons: 201, Grad norm: 9.644709290112589\n",
      "Epoch 7050, Loss: 208.71586206280458, Neurons: 201, Grad norm: 9.644709290112589\n",
      "Epoch 7051, Loss: 208.71620445663083, Neurons: 201, Grad norm: 11.08170935489213\n",
      "Epoch 7051, Loss: 208.71620445663083, Neurons: 201, Grad norm: 11.08170935489213\n",
      "Epoch 7052, Loss: 208.71651197726524, Neurons: 201, Grad norm: 11.63333873798195\n",
      "Epoch 7052, Loss: 208.71651197726524, Neurons: 201, Grad norm: 11.63333873798195\n",
      "Epoch 7053, Loss: 208.7166636207527, Neurons: 201, Grad norm: 11.122439552053761\n",
      "Epoch 7053, Loss: 208.7166636207527, Neurons: 201, Grad norm: 11.122439552053761\n",
      "Epoch 7054, Loss: 208.71648047120422, Neurons: 201, Grad norm: 9.664593637682934\n",
      "Epoch 7054, Loss: 208.71648047120422, Neurons: 201, Grad norm: 9.664593637682934\n",
      "Epoch 7055, Loss: 208.71614677543218, Neurons: 201, Grad norm: 7.720933069184763\n",
      "Epoch 7055, Loss: 208.71614677543218, Neurons: 201, Grad norm: 7.720933069184763\n",
      "Epoch 7056, Loss: 208.71584695186397, Neurons: 201, Grad norm: 5.675373381896875\n",
      "Epoch 7056, Loss: 208.71584695186397, Neurons: 201, Grad norm: 5.675373381896875\n",
      "Epoch 7057, Loss: 208.71544300802785, Neurons: 201, Grad norm: 3.625486784418696\n",
      "Epoch 7057, Loss: 208.71544300802785, Neurons: 201, Grad norm: 3.625486784418696\n",
      "Epoch 7058, Loss: 208.71494831348787, Neurons: 201, Grad norm: 1.721678103779916\n",
      "Epoch 7058, Loss: 208.71494831348787, Neurons: 201, Grad norm: 1.721678103779916\n",
      "Epoch 7059, Loss: 208.71467176075555, Neurons: 201, Grad norm: 1.025718745974717\n",
      "Epoch 7059, Loss: 208.71467176075555, Neurons: 201, Grad norm: 1.025718745974717\n",
      "Epoch 7060, Loss: 208.71468932902192, Neurons: 201, Grad norm: 2.2554516423107027\n",
      "Epoch 7060, Loss: 208.71468932902192, Neurons: 201, Grad norm: 2.2554516423107027\n",
      "Epoch 7061, Loss: 208.71472689626066, Neurons: 201, Grad norm: 4.03278914963523\n",
      "Epoch 7061, Loss: 208.71472689626066, Neurons: 201, Grad norm: 4.03278914963523\n",
      "Epoch 7062, Loss: 208.71472268771652, Neurons: 201, Grad norm: 5.855475292172982\n",
      "Epoch 7062, Loss: 208.71472268771652, Neurons: 201, Grad norm: 5.855475292172982\n",
      "Epoch 7063, Loss: 208.71490038762985, Neurons: 201, Grad norm: 7.678441981337469\n",
      "Epoch 7063, Loss: 208.71490038762985, Neurons: 201, Grad norm: 7.678441981337469\n",
      "Epoch 7064, Loss: 208.71500396611253, Neurons: 201, Grad norm: 9.203648053776972\n",
      "Epoch 7064, Loss: 208.71500396611253, Neurons: 201, Grad norm: 9.203648053776972\n",
      "Epoch 7065, Loss: 208.71516107611046, Neurons: 201, Grad norm: 9.806778584908907\n",
      "Epoch 7065, Loss: 208.71516107611046, Neurons: 201, Grad norm: 9.806778584908907\n",
      "Epoch 7066, Loss: 208.71527034579086, Neurons: 201, Grad norm: 10.20199738785146\n",
      "Epoch 7066, Loss: 208.71527034579086, Neurons: 201, Grad norm: 10.20199738785146\n",
      "Epoch 7067, Loss: 208.71522323265026, Neurons: 201, Grad norm: 9.581825635089261\n",
      "Epoch 7067, Loss: 208.71522323265026, Neurons: 201, Grad norm: 9.581825635089261\n",
      "Epoch 7068, Loss: 208.71503369061173, Neurons: 201, Grad norm: 8.119824548491358\n",
      "Epoch 7068, Loss: 208.71503369061173, Neurons: 201, Grad norm: 8.119824548491358\n",
      "Epoch 7069, Loss: 208.71477929252933, Neurons: 201, Grad norm: 6.185956043886062\n",
      "Epoch 7069, Loss: 208.71477929252933, Neurons: 201, Grad norm: 6.185956043886062\n",
      "Epoch 7070, Loss: 208.71443930563794, Neurons: 201, Grad norm: 4.317432790227987\n",
      "Epoch 7070, Loss: 208.71443930563794, Neurons: 201, Grad norm: 4.317432790227987\n",
      "Epoch 7071, Loss: 208.71417595363457, Neurons: 201, Grad norm: 2.567055971029881\n",
      "Epoch 7071, Loss: 208.71417595363457, Neurons: 201, Grad norm: 2.567055971029881\n",
      "Epoch 7072, Loss: 208.71402970391605, Neurons: 201, Grad norm: 1.415127050970931\n",
      "Epoch 7072, Loss: 208.71402970391605, Neurons: 201, Grad norm: 1.415127050970931\n",
      "Epoch 7073, Loss: 208.7138307851265, Neurons: 201, Grad norm: 0.8041358098622681\n",
      "Epoch 7073, Loss: 208.7138307851265, Neurons: 201, Grad norm: 0.8041358098622681\n",
      "Epoch 7074, Loss: 208.7136862109568, Neurons: 201, Grad norm: 1.3001477333729876\n",
      "Epoch 7074, Loss: 208.7136862109568, Neurons: 201, Grad norm: 1.3001477333729876\n",
      "Epoch 7075, Loss: 208.7136179826317, Neurons: 201, Grad norm: 1.8373584057097951\n",
      "Epoch 7075, Loss: 208.7136179826317, Neurons: 201, Grad norm: 1.8373584057097951\n",
      "Epoch 7076, Loss: 208.7135477710462, Neurons: 201, Grad norm: 2.4813288447172934\n",
      "Epoch 7076, Loss: 208.7135477710462, Neurons: 201, Grad norm: 2.4813288447172934\n",
      "Epoch 7077, Loss: 208.7136044302658, Neurons: 201, Grad norm: 3.906459786845469\n",
      "Epoch 7077, Loss: 208.7136044302658, Neurons: 201, Grad norm: 3.906459786845469\n",
      "Epoch 7078, Loss: 208.71366997036964, Neurons: 201, Grad norm: 4.654974083285369\n",
      "Epoch 7078, Loss: 208.71366997036964, Neurons: 201, Grad norm: 4.654974083285369\n",
      "Epoch 7079, Loss: 208.71366729410016, Neurons: 201, Grad norm: 6.077273249545945\n",
      "Epoch 7079, Loss: 208.71366729410016, Neurons: 201, Grad norm: 6.077273249545945\n",
      "Epoch 7080, Loss: 208.7137230317979, Neurons: 201, Grad norm: 7.1821110422007255\n",
      "Epoch 7080, Loss: 208.7137230317979, Neurons: 201, Grad norm: 7.1821110422007255\n",
      "Epoch 7081, Loss: 208.71378223101866, Neurons: 201, Grad norm: 7.785105828252235\n",
      "Epoch 7081, Loss: 208.71378223101866, Neurons: 201, Grad norm: 7.785105828252235\n",
      "Epoch 7082, Loss: 208.71376156787733, Neurons: 201, Grad norm: 8.571175502499385\n",
      "Epoch 7082, Loss: 208.71376156787733, Neurons: 201, Grad norm: 8.571175502499385\n",
      "Epoch 7083, Loss: 208.71378778687102, Neurons: 201, Grad norm: 8.896739576602416\n",
      "Epoch 7083, Loss: 208.71378778687102, Neurons: 201, Grad norm: 8.896739576602416\n",
      "Epoch 7084, Loss: 208.7137973654866, Neurons: 201, Grad norm: 8.840545426925887\n",
      "Epoch 7084, Loss: 208.7137973654866, Neurons: 201, Grad norm: 8.840545426925887\n",
      "Epoch 7085, Loss: 208.71384739659663, Neurons: 201, Grad norm: 8.904112201433032\n",
      "Epoch 7085, Loss: 208.71384739659663, Neurons: 201, Grad norm: 8.904112201433032\n",
      "Epoch 7086, Loss: 208.71380568443374, Neurons: 201, Grad norm: 8.788071599858574\n",
      "Epoch 7086, Loss: 208.71380568443374, Neurons: 201, Grad norm: 8.788071599858574\n",
      "Epoch 7087, Loss: 208.71378544114717, Neurons: 201, Grad norm: 8.876099369547026\n",
      "Epoch 7087, Loss: 208.71378544114717, Neurons: 201, Grad norm: 8.876099369547026\n",
      "Epoch 7088, Loss: 208.71365503359613, Neurons: 201, Grad norm: 9.003439946835874\n",
      "Epoch 7088, Loss: 208.71365503359613, Neurons: 201, Grad norm: 9.003439946835874\n",
      "Epoch 7089, Loss: 208.7135879314488, Neurons: 201, Grad norm: 9.135986939673714\n",
      "Epoch 7089, Loss: 208.7135879314488, Neurons: 201, Grad norm: 9.135986939673714\n",
      "Epoch 7090, Loss: 208.7134931141254, Neurons: 201, Grad norm: 9.111526296443625\n",
      "Epoch 7090, Loss: 208.7134931141254, Neurons: 201, Grad norm: 9.111526296443625\n",
      "Epoch 7091, Loss: 208.7134185627822, Neurons: 201, Grad norm: 8.852295314406575\n",
      "Epoch 7091, Loss: 208.7134185627822, Neurons: 201, Grad norm: 8.852295314406575\n",
      "Epoch 7092, Loss: 208.7133736115613, Neurons: 201, Grad norm: 8.236622300858317\n",
      "Epoch 7092, Loss: 208.7133736115613, Neurons: 201, Grad norm: 8.236622300858317\n",
      "Epoch 7093, Loss: 208.71315443522306, Neurons: 201, Grad norm: 7.5828534193737\n",
      "Epoch 7093, Loss: 208.71315443522306, Neurons: 201, Grad norm: 7.5828534193737\n",
      "Epoch 7094, Loss: 208.71293458815893, Neurons: 201, Grad norm: 6.9459296149639265\n",
      "Epoch 7094, Loss: 208.71293458815893, Neurons: 201, Grad norm: 6.9459296149639265\n",
      "Epoch 7095, Loss: 208.71283742241405, Neurons: 201, Grad norm: 6.067443787735643\n",
      "Epoch 7095, Loss: 208.71283742241405, Neurons: 201, Grad norm: 6.067443787735643\n",
      "Epoch 7096, Loss: 208.71260412704942, Neurons: 201, Grad norm: 4.97745160304481\n",
      "Epoch 7096, Loss: 208.71260412704942, Neurons: 201, Grad norm: 4.97745160304481\n",
      "Epoch 7097, Loss: 208.71241229663772, Neurons: 201, Grad norm: 4.09557700844958\n",
      "Epoch 7097, Loss: 208.71241229663772, Neurons: 201, Grad norm: 4.09557700844958\n",
      "Epoch 7098, Loss: 208.71224342956725, Neurons: 201, Grad norm: 3.000653565197562\n",
      "Epoch 7098, Loss: 208.71224342956725, Neurons: 201, Grad norm: 3.000653565197562\n",
      "Epoch 7099, Loss: 208.7120412692959, Neurons: 201, Grad norm: 2.056955683841121\n",
      "Epoch 7099, Loss: 208.7120412692959, Neurons: 201, Grad norm: 2.056955683841121\n",
      "Epoch 7100, Loss: 208.71193943803033, Neurons: 201, Grad norm: 1.1482784038775586\n",
      "Epoch 7100, Loss: 208.71193943803033, Neurons: 201, Grad norm: 1.1482784038775586\n",
      "Epoch 7101, Loss: 208.71184069417168, Neurons: 201, Grad norm: 0.8361753964378148\n",
      "Epoch 7101, Loss: 208.71184069417168, Neurons: 201, Grad norm: 0.8361753964378148\n",
      "Epoch 7102, Loss: 208.71177900877944, Neurons: 201, Grad norm: 1.2953888211621476\n",
      "Epoch 7102, Loss: 208.71177900877944, Neurons: 201, Grad norm: 1.2953888211621476\n",
      "Epoch 7103, Loss: 208.71171915253242, Neurons: 201, Grad norm: 2.062751166667513\n",
      "Epoch 7103, Loss: 208.71171915253242, Neurons: 201, Grad norm: 2.062751166667513\n",
      "Epoch 7104, Loss: 208.7116846201328, Neurons: 201, Grad norm: 2.939870089015131\n",
      "Epoch 7104, Loss: 208.7116846201328, Neurons: 201, Grad norm: 2.939870089015131\n",
      "Epoch 7105, Loss: 208.71169708342194, Neurons: 201, Grad norm: 4.081158088237936\n",
      "Epoch 7105, Loss: 208.71169708342194, Neurons: 201, Grad norm: 4.081158088237936\n",
      "Epoch 7106, Loss: 208.71173799716286, Neurons: 201, Grad norm: 5.2626696885224105\n",
      "Epoch 7106, Loss: 208.71173799716286, Neurons: 201, Grad norm: 5.2626696885224105\n",
      "Epoch 7107, Loss: 208.7117761571042, Neurons: 201, Grad norm: 6.393738972135066\n",
      "Epoch 7107, Loss: 208.7117761571042, Neurons: 201, Grad norm: 6.393738972135066\n",
      "Epoch 7108, Loss: 208.71187034329034, Neurons: 201, Grad norm: 7.853505809931729\n",
      "Epoch 7108, Loss: 208.71187034329034, Neurons: 201, Grad norm: 7.853505809931729\n",
      "Epoch 7109, Loss: 208.71202025934906, Neurons: 201, Grad norm: 9.405977590167781\n",
      "Epoch 7109, Loss: 208.71202025934906, Neurons: 201, Grad norm: 9.405977590167781\n",
      "Epoch 7110, Loss: 208.71224238783228, Neurons: 201, Grad norm: 10.87499998471523\n",
      "Epoch 7110, Loss: 208.71224238783228, Neurons: 201, Grad norm: 10.87499998471523\n",
      "Epoch 7111, Loss: 208.71268717984867, Neurons: 201, Grad norm: 12.138256075548162\n",
      "Epoch 7111, Loss: 208.71268717984867, Neurons: 201, Grad norm: 12.138256075548162\n",
      "Epoch 7112, Loss: 208.71300441514478, Neurons: 201, Grad norm: 13.5110043663254\n",
      "Epoch 7112, Loss: 208.71300441514478, Neurons: 201, Grad norm: 13.5110043663254\n",
      "Epoch 7113, Loss: 208.71338025748517, Neurons: 201, Grad norm: 14.10190279357678\n",
      "Epoch 7113, Loss: 208.71338025748517, Neurons: 201, Grad norm: 14.10190279357678\n",
      "Epoch 7114, Loss: 208.7135034467986, Neurons: 201, Grad norm: 13.827515233245665\n",
      "Epoch 7114, Loss: 208.7135034467986, Neurons: 201, Grad norm: 13.827515233245665\n",
      "Epoch 7115, Loss: 208.71333442354447, Neurons: 201, Grad norm: 12.630620025887376\n",
      "Epoch 7115, Loss: 208.71333442354447, Neurons: 201, Grad norm: 12.630620025887376\n",
      "Epoch 7116, Loss: 208.71268717202378, Neurons: 201, Grad norm: 10.13869878913666\n",
      "Epoch 7116, Loss: 208.71268717202378, Neurons: 201, Grad norm: 10.13869878913666\n",
      "Epoch 7117, Loss: 208.7120233452836, Neurons: 201, Grad norm: 6.543006899689457\n",
      "Epoch 7117, Loss: 208.7120233452836, Neurons: 201, Grad norm: 6.543006899689457\n",
      "Epoch 7118, Loss: 208.71130165271288, Neurons: 201, Grad norm: 3.221253208323283\n",
      "Epoch 7118, Loss: 208.71130165271288, Neurons: 201, Grad norm: 3.221253208323283\n",
      "Epoch 7119, Loss: 208.7108886592625, Neurons: 201, Grad norm: 1.3151011835257562\n",
      "Epoch 7119, Loss: 208.7108886592625, Neurons: 201, Grad norm: 1.3151011835257562\n",
      "Epoch 7120, Loss: 208.71078129828507, Neurons: 201, Grad norm: 3.1743709983009163\n",
      "Epoch 7120, Loss: 208.71078129828507, Neurons: 201, Grad norm: 3.1743709983009163\n",
      "Epoch 7121, Loss: 208.71080304883216, Neurons: 201, Grad norm: 4.981783013711333\n",
      "Epoch 7121, Loss: 208.71080304883216, Neurons: 201, Grad norm: 4.981783013711333\n",
      "Epoch 7122, Loss: 208.71084173299485, Neurons: 201, Grad norm: 6.146136247949433\n",
      "Epoch 7122, Loss: 208.71084173299485, Neurons: 201, Grad norm: 6.146136247949433\n",
      "Epoch 7123, Loss: 208.7108839622084, Neurons: 201, Grad norm: 6.898804354098406\n",
      "Epoch 7123, Loss: 208.7108839622084, Neurons: 201, Grad norm: 6.898804354098406\n",
      "Epoch 7124, Loss: 208.71092385027836, Neurons: 201, Grad norm: 7.495744714705891\n",
      "Epoch 7124, Loss: 208.71092385027836, Neurons: 201, Grad norm: 7.495744714705891\n",
      "Epoch 7125, Loss: 208.71111409124254, Neurons: 201, Grad norm: 7.560393618594904\n",
      "Epoch 7125, Loss: 208.71111409124254, Neurons: 201, Grad norm: 7.560393618594904\n",
      "Epoch 7126, Loss: 208.71120224958977, Neurons: 201, Grad norm: 7.9611380211025\n",
      "Epoch 7126, Loss: 208.71120224958977, Neurons: 201, Grad norm: 7.9611380211025\n",
      "Epoch 7127, Loss: 208.7112042164369, Neurons: 201, Grad norm: 8.082701881372893\n",
      "Epoch 7127, Loss: 208.7112042164369, Neurons: 201, Grad norm: 8.082701881372893\n",
      "Epoch 7128, Loss: 208.71114821138013, Neurons: 201, Grad norm: 7.96498934205744\n",
      "Epoch 7128, Loss: 208.71114821138013, Neurons: 201, Grad norm: 7.96498934205744\n",
      "Epoch 7129, Loss: 208.71096925942783, Neurons: 201, Grad norm: 8.406616534735761\n",
      "Epoch 7129, Loss: 208.71096925942783, Neurons: 201, Grad norm: 8.406616534735761\n",
      "Epoch 7130, Loss: 208.71075821714533, Neurons: 201, Grad norm: 8.089579930595995\n",
      "Epoch 7130, Loss: 208.71075821714533, Neurons: 201, Grad norm: 8.089579930595995\n",
      "Epoch 7131, Loss: 208.7106135714885, Neurons: 201, Grad norm: 7.214425369333287\n",
      "Epoch 7131, Loss: 208.7106135714885, Neurons: 201, Grad norm: 7.214425369333287\n",
      "Epoch 7132, Loss: 208.71042526274803, Neurons: 201, Grad norm: 5.327365590244962\n",
      "Epoch 7132, Loss: 208.71042526274803, Neurons: 201, Grad norm: 5.327365590244962\n",
      "Epoch 7133, Loss: 208.7101255503083, Neurons: 201, Grad norm: 3.5696479076525054\n",
      "Epoch 7133, Loss: 208.7101255503083, Neurons: 201, Grad norm: 3.5696479076525054\n",
      "Epoch 7134, Loss: 208.70986677537567, Neurons: 201, Grad norm: 1.9033184724359942\n",
      "Epoch 7134, Loss: 208.70986677537567, Neurons: 201, Grad norm: 1.9033184724359942\n",
      "Epoch 7135, Loss: 208.7097155515488, Neurons: 201, Grad norm: 0.9217605228976575\n",
      "Epoch 7135, Loss: 208.7097155515488, Neurons: 201, Grad norm: 0.9217605228976575\n",
      "Epoch 7136, Loss: 208.7096560412534, Neurons: 201, Grad norm: 1.3112624507011421\n",
      "Epoch 7136, Loss: 208.7096560412534, Neurons: 201, Grad norm: 1.3112624507011421\n",
      "Epoch 7137, Loss: 208.70961088591432, Neurons: 201, Grad norm: 2.1292148573934186\n",
      "Epoch 7137, Loss: 208.70961088591432, Neurons: 201, Grad norm: 2.1292148573934186\n",
      "Epoch 7138, Loss: 208.70957263664482, Neurons: 201, Grad norm: 2.750505038749323\n",
      "Epoch 7138, Loss: 208.70957263664482, Neurons: 201, Grad norm: 2.750505038749323\n",
      "Epoch 7139, Loss: 208.70953926788476, Neurons: 201, Grad norm: 2.636733602881929\n",
      "Epoch 7139, Loss: 208.70953926788476, Neurons: 201, Grad norm: 2.636733602881929\n",
      "Epoch 7140, Loss: 208.70942973253608, Neurons: 201, Grad norm: 2.91931989490754\n",
      "Epoch 7140, Loss: 208.70942973253608, Neurons: 201, Grad norm: 2.91931989490754\n",
      "Epoch 7141, Loss: 208.7093993690859, Neurons: 201, Grad norm: 2.954144668834656\n",
      "Epoch 7141, Loss: 208.7093993690859, Neurons: 201, Grad norm: 2.954144668834656\n",
      "Epoch 7142, Loss: 208.70934734838508, Neurons: 201, Grad norm: 3.112861318648022\n",
      "Epoch 7142, Loss: 208.70934734838508, Neurons: 201, Grad norm: 3.112861318648022\n",
      "Epoch 7143, Loss: 208.70927871376867, Neurons: 201, Grad norm: 3.27639746782609\n",
      "Epoch 7143, Loss: 208.70927871376867, Neurons: 201, Grad norm: 3.27639746782609\n",
      "Epoch 7144, Loss: 208.70921779670968, Neurons: 201, Grad norm: 3.796507000031307\n",
      "Epoch 7144, Loss: 208.70921779670968, Neurons: 201, Grad norm: 3.796507000031307\n",
      "Epoch 7145, Loss: 208.70924413765, Neurons: 201, Grad norm: 4.63432943146616\n",
      "Epoch 7145, Loss: 208.70924413765, Neurons: 201, Grad norm: 4.63432943146616\n",
      "Epoch 7146, Loss: 208.70936433341862, Neurons: 201, Grad norm: 5.938129885908191\n",
      "Epoch 7146, Loss: 208.70936433341862, Neurons: 201, Grad norm: 5.938129885908191\n",
      "Epoch 7147, Loss: 208.7094400000037, Neurons: 201, Grad norm: 7.6865316709100995\n",
      "Epoch 7147, Loss: 208.7094400000037, Neurons: 201, Grad norm: 7.6865316709100995\n",
      "Epoch 7148, Loss: 208.7095589691231, Neurons: 201, Grad norm: 9.5095880169783\n",
      "Epoch 7148, Loss: 208.7095589691231, Neurons: 201, Grad norm: 9.5095880169783\n",
      "Epoch 7149, Loss: 208.7098255871158, Neurons: 201, Grad norm: 11.087597738115827\n",
      "Epoch 7149, Loss: 208.7098255871158, Neurons: 201, Grad norm: 11.087597738115827\n",
      "Epoch 7150, Loss: 208.7100795723885, Neurons: 201, Grad norm: 12.286745780894046\n",
      "Epoch 7150, Loss: 208.7100795723885, Neurons: 201, Grad norm: 12.286745780894046\n",
      "Epoch 7151, Loss: 208.71035617816267, Neurons: 201, Grad norm: 12.259059279127538\n",
      "Epoch 7151, Loss: 208.71035617816267, Neurons: 201, Grad norm: 12.259059279127538\n",
      "Epoch 7152, Loss: 208.71039823882947, Neurons: 201, Grad norm: 11.515046322535017\n",
      "Epoch 7152, Loss: 208.71039823882947, Neurons: 201, Grad norm: 11.515046322535017\n",
      "Epoch 7153, Loss: 208.71031611114563, Neurons: 201, Grad norm: 9.886394876663777\n",
      "Epoch 7153, Loss: 208.71031611114563, Neurons: 201, Grad norm: 9.886394876663777\n",
      "Epoch 7154, Loss: 208.71000282153958, Neurons: 201, Grad norm: 7.811652337248217\n",
      "Epoch 7154, Loss: 208.71000282153958, Neurons: 201, Grad norm: 7.811652337248217\n",
      "Epoch 7155, Loss: 208.70965429171181, Neurons: 201, Grad norm: 5.666440475083602\n",
      "Epoch 7155, Loss: 208.70965429171181, Neurons: 201, Grad norm: 5.666440475083602\n",
      "Epoch 7156, Loss: 208.70904833776137, Neurons: 201, Grad norm: 3.5748385236990416\n",
      "Epoch 7156, Loss: 208.70904833776137, Neurons: 201, Grad norm: 3.5748385236990416\n",
      "Epoch 7157, Loss: 208.7086426057895, Neurons: 201, Grad norm: 1.5028218103172863\n",
      "Epoch 7157, Loss: 208.7086426057895, Neurons: 201, Grad norm: 1.5028218103172863\n",
      "Epoch 7158, Loss: 208.70835837661392, Neurons: 201, Grad norm: 1.0271085380474374\n",
      "Epoch 7158, Loss: 208.70835837661392, Neurons: 201, Grad norm: 1.0271085380474374\n",
      "Epoch 7159, Loss: 208.70831356435994, Neurons: 201, Grad norm: 2.993153492040748\n",
      "Epoch 7159, Loss: 208.70831356435994, Neurons: 201, Grad norm: 2.993153492040748\n",
      "Epoch 7160, Loss: 208.70842038265235, Neurons: 201, Grad norm: 4.999626418455264\n",
      "Epoch 7160, Loss: 208.70842038265235, Neurons: 201, Grad norm: 4.999626418455264\n",
      "Epoch 7161, Loss: 208.70866474850595, Neurons: 201, Grad norm: 7.400257844922913\n",
      "Epoch 7161, Loss: 208.70866474850595, Neurons: 201, Grad norm: 7.400257844922913\n",
      "Epoch 7162, Loss: 208.70895685944228, Neurons: 201, Grad norm: 9.855815468907089\n",
      "Epoch 7162, Loss: 208.70895685944228, Neurons: 201, Grad norm: 9.855815468907089\n",
      "Epoch 7163, Loss: 208.7092694446312, Neurons: 201, Grad norm: 12.299630004405072\n",
      "Epoch 7163, Loss: 208.7092694446312, Neurons: 201, Grad norm: 12.299630004405072\n",
      "Epoch 7164, Loss: 208.70959960644853, Neurons: 201, Grad norm: 13.711029532085306\n",
      "Epoch 7164, Loss: 208.70959960644853, Neurons: 201, Grad norm: 13.711029532085306\n",
      "Epoch 7165, Loss: 208.70992907945893, Neurons: 201, Grad norm: 13.7039491671381\n",
      "Epoch 7165, Loss: 208.70992907945893, Neurons: 201, Grad norm: 13.7039491671381\n",
      "Epoch 7166, Loss: 208.70994842103732, Neurons: 201, Grad norm: 12.113954228635418\n",
      "Epoch 7166, Loss: 208.70994842103732, Neurons: 201, Grad norm: 12.113954228635418\n",
      "Epoch 7167, Loss: 208.70937940184837, Neurons: 201, Grad norm: 9.102666107188119\n",
      "Epoch 7167, Loss: 208.70937940184837, Neurons: 201, Grad norm: 9.102666107188119\n",
      "Epoch 7168, Loss: 208.70865214553635, Neurons: 201, Grad norm: 4.9799911406039215\n",
      "Epoch 7168, Loss: 208.70865214553635, Neurons: 201, Grad norm: 4.9799911406039215\n",
      "Epoch 7169, Loss: 208.70800494976206, Neurons: 201, Grad norm: 1.3804519818913772\n",
      "Epoch 7169, Loss: 208.70800494976206, Neurons: 201, Grad norm: 1.3804519818913772\n",
      "Epoch 7170, Loss: 208.70773558187028, Neurons: 201, Grad norm: 2.902701660795224\n",
      "Epoch 7170, Loss: 208.70773558187028, Neurons: 201, Grad norm: 2.902701660795224\n",
      "Epoch 7171, Loss: 208.70759296770873, Neurons: 201, Grad norm: 6.088557097781192\n",
      "Epoch 7171, Loss: 208.70759296770873, Neurons: 201, Grad norm: 6.088557097781192\n",
      "Epoch 7172, Loss: 208.70789950385503, Neurons: 201, Grad norm: 8.457454869253334\n",
      "Epoch 7172, Loss: 208.70789950385503, Neurons: 201, Grad norm: 8.457454869253334\n",
      "Epoch 7173, Loss: 208.7082056868348, Neurons: 201, Grad norm: 9.946682007602474\n",
      "Epoch 7173, Loss: 208.7082056868348, Neurons: 201, Grad norm: 9.946682007602474\n",
      "Epoch 7174, Loss: 208.70853137857156, Neurons: 201, Grad norm: 10.784795203967493\n",
      "Epoch 7174, Loss: 208.70853137857156, Neurons: 201, Grad norm: 10.784795203967493\n",
      "Epoch 7175, Loss: 208.7087934863526, Neurons: 201, Grad norm: 10.355692036949549\n",
      "Epoch 7175, Loss: 208.7087934863526, Neurons: 201, Grad norm: 10.355692036949549\n",
      "Epoch 7176, Loss: 208.70886478245018, Neurons: 201, Grad norm: 9.717206567221425\n",
      "Epoch 7176, Loss: 208.70886478245018, Neurons: 201, Grad norm: 9.717206567221425\n",
      "Epoch 7177, Loss: 208.70871553546777, Neurons: 201, Grad norm: 8.42624075398055\n",
      "Epoch 7177, Loss: 208.70871553546777, Neurons: 201, Grad norm: 8.42624075398055\n",
      "Epoch 7178, Loss: 208.7082359844368, Neurons: 201, Grad norm: 6.638361575206124\n",
      "Epoch 7178, Loss: 208.7082359844368, Neurons: 201, Grad norm: 6.638361575206124\n",
      "Epoch 7179, Loss: 208.70761822603012, Neurons: 201, Grad norm: 4.473044966957188\n",
      "Epoch 7179, Loss: 208.70761822603012, Neurons: 201, Grad norm: 4.473044966957188\n",
      "Epoch 7180, Loss: 208.70721133480095, Neurons: 201, Grad norm: 2.077753039390854\n",
      "Epoch 7180, Loss: 208.70721133480095, Neurons: 201, Grad norm: 2.077753039390854\n",
      "Epoch 7181, Loss: 208.70698840966665, Neurons: 201, Grad norm: 1.090423429192369\n",
      "Epoch 7181, Loss: 208.70698840966665, Neurons: 201, Grad norm: 1.090423429192369\n",
      "Epoch 7182, Loss: 208.70693315668794, Neurons: 201, Grad norm: 2.822685310339701\n",
      "Epoch 7182, Loss: 208.70693315668794, Neurons: 201, Grad norm: 2.822685310339701\n",
      "Epoch 7183, Loss: 208.70700103874955, Neurons: 201, Grad norm: 4.5524403757327265\n",
      "Epoch 7183, Loss: 208.70700103874955, Neurons: 201, Grad norm: 4.5524403757327265\n",
      "Epoch 7184, Loss: 208.70703002136543, Neurons: 201, Grad norm: 5.870444955043088\n",
      "Epoch 7184, Loss: 208.70703002136543, Neurons: 201, Grad norm: 5.870444955043088\n",
      "Epoch 7185, Loss: 208.707060242838, Neurons: 201, Grad norm: 6.833609319065937\n",
      "Epoch 7185, Loss: 208.707060242838, Neurons: 201, Grad norm: 6.833609319065937\n",
      "Epoch 7186, Loss: 208.7070936378076, Neurons: 201, Grad norm: 7.017795800274807\n",
      "Epoch 7186, Loss: 208.7070936378076, Neurons: 201, Grad norm: 7.017795800274807\n",
      "Epoch 7187, Loss: 208.70705718766936, Neurons: 201, Grad norm: 6.510711416022946\n",
      "Epoch 7187, Loss: 208.70705718766936, Neurons: 201, Grad norm: 6.510711416022946\n",
      "Epoch 7188, Loss: 208.70697872827043, Neurons: 201, Grad norm: 5.303228073161072\n",
      "Epoch 7188, Loss: 208.70697872827043, Neurons: 201, Grad norm: 5.303228073161072\n",
      "Epoch 7189, Loss: 208.7067268874921, Neurons: 201, Grad norm: 4.155678995837945\n",
      "Epoch 7189, Loss: 208.7067268874921, Neurons: 201, Grad norm: 4.155678995837945\n",
      "Epoch 7190, Loss: 208.70655892381788, Neurons: 201, Grad norm: 2.9122326594363943\n",
      "Epoch 7190, Loss: 208.70655892381788, Neurons: 201, Grad norm: 2.9122326594363943\n",
      "Epoch 7191, Loss: 208.7064093637931, Neurons: 201, Grad norm: 2.120952920033386\n",
      "Epoch 7191, Loss: 208.7064093637931, Neurons: 201, Grad norm: 2.120952920033386\n",
      "Epoch 7192, Loss: 208.706315126606, Neurons: 201, Grad norm: 1.676098483234006\n",
      "Epoch 7192, Loss: 208.706315126606, Neurons: 201, Grad norm: 1.676098483234006\n",
      "Epoch 7193, Loss: 208.70622249778205, Neurons: 201, Grad norm: 1.4003513129472616\n",
      "Epoch 7193, Loss: 208.70622249778205, Neurons: 201, Grad norm: 1.4003513129472616\n",
      "Epoch 7194, Loss: 208.7061499306611, Neurons: 201, Grad norm: 1.1255808809914651\n",
      "Epoch 7194, Loss: 208.7061499306611, Neurons: 201, Grad norm: 1.1255808809914651\n",
      "Epoch 7195, Loss: 208.70612026246633, Neurons: 201, Grad norm: 1.357037893724033\n",
      "Epoch 7195, Loss: 208.70612026246633, Neurons: 201, Grad norm: 1.357037893724033\n",
      "Epoch 7196, Loss: 208.7060149388061, Neurons: 201, Grad norm: 1.25673239022741\n",
      "Epoch 7196, Loss: 208.7060149388061, Neurons: 201, Grad norm: 1.25673239022741\n",
      "Epoch 7197, Loss: 208.70599322267873, Neurons: 201, Grad norm: 1.7724166782442328\n",
      "Epoch 7197, Loss: 208.70599322267873, Neurons: 201, Grad norm: 1.7724166782442328\n",
      "Epoch 7198, Loss: 208.70597382937456, Neurons: 201, Grad norm: 2.909103846967643\n",
      "Epoch 7198, Loss: 208.70597382937456, Neurons: 201, Grad norm: 2.909103846967643\n",
      "Epoch 7199, Loss: 208.70594018307543, Neurons: 201, Grad norm: 4.312855452103421\n",
      "Epoch 7199, Loss: 208.70594018307543, Neurons: 201, Grad norm: 4.312855452103421\n",
      "Epoch 7200, Loss: 208.7059803573092, Neurons: 201, Grad norm: 5.856055975886596\n",
      "Epoch 7200, Loss: 208.7059803573092, Neurons: 201, Grad norm: 5.856055975886596\n",
      "Epoch 7201, Loss: 208.70610927635903, Neurons: 201, Grad norm: 7.634901144766191\n",
      "Epoch 7201, Loss: 208.70610927635903, Neurons: 201, Grad norm: 7.634901144766191\n",
      "Epoch 7202, Loss: 208.7063082368795, Neurons: 201, Grad norm: 8.810594013964895\n",
      "Epoch 7202, Loss: 208.7063082368795, Neurons: 201, Grad norm: 8.810594013964895\n",
      "Epoch 7203, Loss: 208.70661797362487, Neurons: 201, Grad norm: 10.10816693947456\n",
      "Epoch 7203, Loss: 208.70661797362487, Neurons: 201, Grad norm: 10.10816693947456\n",
      "Epoch 7204, Loss: 208.70700873423996, Neurons: 201, Grad norm: 10.903732106552932\n",
      "Epoch 7204, Loss: 208.70700873423996, Neurons: 201, Grad norm: 10.903732106552932\n",
      "Epoch 7205, Loss: 208.70721451691688, Neurons: 201, Grad norm: 11.340763236901509\n",
      "Epoch 7205, Loss: 208.70721451691688, Neurons: 201, Grad norm: 11.340763236901509\n",
      "Epoch 7206, Loss: 208.70706390771898, Neurons: 201, Grad norm: 10.855371375584207\n",
      "Epoch 7206, Loss: 208.70706390771898, Neurons: 201, Grad norm: 10.855371375584207\n",
      "Epoch 7207, Loss: 208.70690343490685, Neurons: 201, Grad norm: 9.36024535303581\n",
      "Epoch 7207, Loss: 208.70690343490685, Neurons: 201, Grad norm: 9.36024535303581\n",
      "Epoch 7208, Loss: 208.70647791626823, Neurons: 201, Grad norm: 7.193971114569067\n",
      "Epoch 7208, Loss: 208.70647791626823, Neurons: 201, Grad norm: 7.193971114569067\n",
      "Epoch 7209, Loss: 208.70583800130782, Neurons: 201, Grad norm: 4.086519127024144\n",
      "Epoch 7209, Loss: 208.70583800130782, Neurons: 201, Grad norm: 4.086519127024144\n",
      "Epoch 7210, Loss: 208.70546786611183, Neurons: 201, Grad norm: 1.001438544001079\n",
      "Epoch 7210, Loss: 208.70546786611183, Neurons: 201, Grad norm: 1.001438544001079\n",
      "Epoch 7211, Loss: 208.7052459296483, Neurons: 201, Grad norm: 2.0985408111852846\n",
      "Epoch 7211, Loss: 208.7052459296483, Neurons: 201, Grad norm: 2.0985408111852846\n",
      "Epoch 7212, Loss: 208.7052081802818, Neurons: 201, Grad norm: 4.62780733664303\n",
      "Epoch 7212, Loss: 208.7052081802818, Neurons: 201, Grad norm: 4.62780733664303\n",
      "Epoch 7213, Loss: 208.70528842713875, Neurons: 201, Grad norm: 5.864641720851444\n",
      "Epoch 7213, Loss: 208.70528842713875, Neurons: 201, Grad norm: 5.864641720851444\n",
      "Epoch 7214, Loss: 208.70539440454644, Neurons: 201, Grad norm: 6.8868094727082525\n",
      "Epoch 7214, Loss: 208.70539440454644, Neurons: 201, Grad norm: 6.8868094727082525\n",
      "Epoch 7215, Loss: 208.70543503493386, Neurons: 201, Grad norm: 7.10440925606295\n",
      "Epoch 7215, Loss: 208.70543503493386, Neurons: 201, Grad norm: 7.10440925606295\n",
      "Epoch 7216, Loss: 208.70547872955146, Neurons: 201, Grad norm: 7.436338904168592\n",
      "Epoch 7216, Loss: 208.70547872955146, Neurons: 201, Grad norm: 7.436338904168592\n",
      "Epoch 7217, Loss: 208.70550655995785, Neurons: 201, Grad norm: 7.395233286915833\n",
      "Epoch 7217, Loss: 208.70550655995785, Neurons: 201, Grad norm: 7.395233286915833\n",
      "Epoch 7218, Loss: 208.70546724156628, Neurons: 201, Grad norm: 7.315205684876468\n",
      "Epoch 7218, Loss: 208.70546724156628, Neurons: 201, Grad norm: 7.315205684876468\n",
      "Epoch 7219, Loss: 208.70530672220593, Neurons: 201, Grad norm: 6.934277316821545\n",
      "Epoch 7219, Loss: 208.70530672220593, Neurons: 201, Grad norm: 6.934277316821545\n",
      "Epoch 7220, Loss: 208.70519147619473, Neurons: 201, Grad norm: 6.466519032884279\n",
      "Epoch 7220, Loss: 208.70519147619473, Neurons: 201, Grad norm: 6.466519032884279\n",
      "Epoch 7221, Loss: 208.7049992308731, Neurons: 201, Grad norm: 5.798148493783595\n",
      "Epoch 7221, Loss: 208.7049992308731, Neurons: 201, Grad norm: 5.798148493783595\n",
      "Epoch 7222, Loss: 208.7048977978125, Neurons: 201, Grad norm: 4.679556319485072\n",
      "Epoch 7222, Loss: 208.7048977978125, Neurons: 201, Grad norm: 4.679556319485072\n",
      "Epoch 7223, Loss: 208.7047137495353, Neurons: 201, Grad norm: 3.489321462923578\n",
      "Epoch 7223, Loss: 208.7047137495353, Neurons: 201, Grad norm: 3.489321462923578\n",
      "Epoch 7224, Loss: 208.70449513979685, Neurons: 201, Grad norm: 2.428266393601936\n",
      "Epoch 7224, Loss: 208.70449513979685, Neurons: 201, Grad norm: 2.428266393601936\n",
      "Epoch 7225, Loss: 208.70440883006052, Neurons: 201, Grad norm: 1.8507257623790312\n",
      "Epoch 7225, Loss: 208.70440883006052, Neurons: 201, Grad norm: 1.8507257623790312\n",
      "Epoch 7226, Loss: 208.70440833529076, Neurons: 201, Grad norm: 2.284799613699796\n",
      "Epoch 7226, Loss: 208.70440833529076, Neurons: 201, Grad norm: 2.284799613699796\n",
      "Epoch 7227, Loss: 208.70453124564446, Neurons: 201, Grad norm: 2.3121570701402936\n",
      "Epoch 7227, Loss: 208.70453124564446, Neurons: 201, Grad norm: 2.3121570701402936\n",
      "Epoch 7228, Loss: 208.70443663430984, Neurons: 201, Grad norm: 3.5321541245585215\n",
      "Epoch 7228, Loss: 208.70443663430984, Neurons: 201, Grad norm: 3.5321541245585215\n",
      "Epoch 7229, Loss: 208.70427218717836, Neurons: 201, Grad norm: 5.140564622212375\n",
      "Epoch 7229, Loss: 208.70427218717836, Neurons: 201, Grad norm: 5.140564622212375\n",
      "Epoch 7230, Loss: 208.7043774632217, Neurons: 201, Grad norm: 7.134645656060934\n",
      "Epoch 7230, Loss: 208.7043774632217, Neurons: 201, Grad norm: 7.134645656060934\n",
      "Epoch 7231, Loss: 208.70452507028745, Neurons: 201, Grad norm: 8.92677209149078\n",
      "Epoch 7231, Loss: 208.70452507028745, Neurons: 201, Grad norm: 8.92677209149078\n",
      "Epoch 7232, Loss: 208.70475369355546, Neurons: 201, Grad norm: 10.514830752009843\n",
      "Epoch 7232, Loss: 208.70475369355546, Neurons: 201, Grad norm: 10.514830752009843\n",
      "Epoch 7233, Loss: 208.70496105981172, Neurons: 201, Grad norm: 11.221414010350323\n",
      "Epoch 7233, Loss: 208.70496105981172, Neurons: 201, Grad norm: 11.221414010350323\n",
      "Epoch 7234, Loss: 208.70512804462308, Neurons: 201, Grad norm: 11.261699184340054\n",
      "Epoch 7234, Loss: 208.70512804462308, Neurons: 201, Grad norm: 11.261699184340054\n",
      "Epoch 7235, Loss: 208.70502701772668, Neurons: 201, Grad norm: 10.116377673438603\n",
      "Epoch 7235, Loss: 208.70502701772668, Neurons: 201, Grad norm: 10.116377673438603\n",
      "Epoch 7236, Loss: 208.70485558276528, Neurons: 201, Grad norm: 8.568474026898473\n",
      "Epoch 7236, Loss: 208.70485558276528, Neurons: 201, Grad norm: 8.568474026898473\n",
      "Epoch 7237, Loss: 208.70467063797966, Neurons: 201, Grad norm: 7.0251997941971\n",
      "Epoch 7237, Loss: 208.70467063797966, Neurons: 201, Grad norm: 7.0251997941971\n",
      "Epoch 7238, Loss: 208.70461205255725, Neurons: 201, Grad norm: 5.749471232828411\n",
      "Epoch 7238, Loss: 208.70461205255725, Neurons: 201, Grad norm: 5.749471232828411\n",
      "Epoch 7239, Loss: 208.70434820208172, Neurons: 201, Grad norm: 4.514406791468732\n",
      "Epoch 7239, Loss: 208.70434820208172, Neurons: 201, Grad norm: 4.514406791468732\n",
      "Epoch 7240, Loss: 208.70380487869087, Neurons: 201, Grad norm: 3.8310610295325676\n",
      "Epoch 7240, Loss: 208.70380487869087, Neurons: 201, Grad norm: 3.8310610295325676\n",
      "Epoch 7241, Loss: 208.7034837596965, Neurons: 201, Grad norm: 3.6250907562688015\n",
      "Epoch 7241, Loss: 208.7034837596965, Neurons: 201, Grad norm: 3.6250907562688015\n",
      "Epoch 7242, Loss: 208.70343382526318, Neurons: 201, Grad norm: 3.43590702053293\n",
      "Epoch 7242, Loss: 208.70343382526318, Neurons: 201, Grad norm: 3.43590702053293\n",
      "Epoch 7243, Loss: 208.70341134072063, Neurons: 201, Grad norm: 2.8545247833825034\n",
      "Epoch 7243, Loss: 208.70341134072063, Neurons: 201, Grad norm: 2.8545247833825034\n",
      "Epoch 7244, Loss: 208.70335977747246, Neurons: 201, Grad norm: 1.6936845139431556\n",
      "Epoch 7244, Loss: 208.70335977747246, Neurons: 201, Grad norm: 1.6936845139431556\n",
      "Epoch 7245, Loss: 208.70319163445984, Neurons: 201, Grad norm: 0.737408093677547\n",
      "Epoch 7245, Loss: 208.70319163445984, Neurons: 201, Grad norm: 0.737408093677547\n",
      "Epoch 7246, Loss: 208.70300370424061, Neurons: 201, Grad norm: 1.951489134470117\n",
      "Epoch 7246, Loss: 208.70300370424061, Neurons: 201, Grad norm: 1.951489134470117\n",
      "Epoch 7247, Loss: 208.7029764870479, Neurons: 201, Grad norm: 3.4731574174538937\n",
      "Epoch 7247, Loss: 208.7029764870479, Neurons: 201, Grad norm: 3.4731574174538937\n",
      "Epoch 7248, Loss: 208.70317773342666, Neurons: 201, Grad norm: 4.6199471677390544\n",
      "Epoch 7248, Loss: 208.70317773342666, Neurons: 201, Grad norm: 4.6199471677390544\n",
      "Epoch 7249, Loss: 208.70321262425287, Neurons: 201, Grad norm: 5.042549665187815\n",
      "Epoch 7249, Loss: 208.70321262425287, Neurons: 201, Grad norm: 5.042549665187815\n",
      "Epoch 7250, Loss: 208.70308115946358, Neurons: 201, Grad norm: 5.3897986604537875\n",
      "Epoch 7250, Loss: 208.70308115946358, Neurons: 201, Grad norm: 5.3897986604537875\n",
      "Epoch 7251, Loss: 208.70309737394913, Neurons: 201, Grad norm: 6.310919251734397\n",
      "Epoch 7251, Loss: 208.70309737394913, Neurons: 201, Grad norm: 6.310919251734397\n",
      "Epoch 7252, Loss: 208.7031940640402, Neurons: 201, Grad norm: 6.980687114878834\n",
      "Epoch 7252, Loss: 208.7031940640402, Neurons: 201, Grad norm: 6.980687114878834\n",
      "Epoch 7253, Loss: 208.7034685307074, Neurons: 201, Grad norm: 7.682768062683304\n",
      "Epoch 7253, Loss: 208.7034685307074, Neurons: 201, Grad norm: 7.682768062683304\n",
      "Epoch 7254, Loss: 208.70365185877526, Neurons: 201, Grad norm: 8.367604731766212\n",
      "Epoch 7254, Loss: 208.70365185877526, Neurons: 201, Grad norm: 8.367604731766212\n",
      "Epoch 7255, Loss: 208.70352577857483, Neurons: 201, Grad norm: 8.978023088073554\n",
      "Epoch 7255, Loss: 208.70352577857483, Neurons: 201, Grad norm: 8.978023088073554\n",
      "Epoch 7256, Loss: 208.70331153070612, Neurons: 201, Grad norm: 9.710409712489325\n",
      "Epoch 7256, Loss: 208.70331153070612, Neurons: 201, Grad norm: 9.710409712489325\n",
      "Epoch 7257, Loss: 208.70319941985818, Neurons: 201, Grad norm: 9.850659945036204\n",
      "Epoch 7257, Loss: 208.70319941985818, Neurons: 201, Grad norm: 9.850659945036204\n",
      "Epoch 7258, Loss: 208.70310416617428, Neurons: 201, Grad norm: 9.16696275276772\n",
      "Epoch 7258, Loss: 208.70310416617428, Neurons: 201, Grad norm: 9.16696275276772\n",
      "Epoch 7259, Loss: 208.70287706763992, Neurons: 201, Grad norm: 7.925785510120102\n",
      "Epoch 7259, Loss: 208.70287706763992, Neurons: 201, Grad norm: 7.925785510120102\n",
      "Epoch 7260, Loss: 208.70251315800712, Neurons: 201, Grad norm: 5.643829904953264\n",
      "Epoch 7260, Loss: 208.70251315800712, Neurons: 201, Grad norm: 5.643829904953264\n",
      "Epoch 7261, Loss: 208.70213246306076, Neurons: 201, Grad norm: 3.7840259814316783\n",
      "Epoch 7261, Loss: 208.70213246306076, Neurons: 201, Grad norm: 3.7840259814316783\n",
      "Epoch 7262, Loss: 208.70189943962205, Neurons: 201, Grad norm: 2.5066368353268955\n",
      "Epoch 7262, Loss: 208.70189943962205, Neurons: 201, Grad norm: 2.5066368353268955\n",
      "Epoch 7263, Loss: 208.7019056279836, Neurons: 201, Grad norm: 2.3569542614403085\n",
      "Epoch 7263, Loss: 208.7019056279836, Neurons: 201, Grad norm: 2.3569542614403085\n",
      "Epoch 7264, Loss: 208.7019235271416, Neurons: 201, Grad norm: 2.39039555355018\n",
      "Epoch 7264, Loss: 208.7019235271416, Neurons: 201, Grad norm: 2.39039555355018\n",
      "Epoch 7265, Loss: 208.70175881471084, Neurons: 201, Grad norm: 1.8197170980138122\n",
      "Epoch 7265, Loss: 208.70175881471084, Neurons: 201, Grad norm: 1.8197170980138122\n",
      "Epoch 7266, Loss: 208.7014980784967, Neurons: 201, Grad norm: 1.0622891191838637\n",
      "Epoch 7266, Loss: 208.7014980784967, Neurons: 201, Grad norm: 1.0622891191838637\n",
      "Epoch 7267, Loss: 208.7012044405003, Neurons: 201, Grad norm: 2.1619387443990137\n",
      "Epoch 7267, Loss: 208.7012044405003, Neurons: 201, Grad norm: 2.1619387443990137\n",
      "Epoch 7268, Loss: 208.701150954098, Neurons: 201, Grad norm: 3.264995808423984\n",
      "Epoch 7268, Loss: 208.701150954098, Neurons: 201, Grad norm: 3.264995808423984\n",
      "Epoch 7269, Loss: 208.70134201406108, Neurons: 201, Grad norm: 3.993105628959993\n",
      "Epoch 7269, Loss: 208.70134201406108, Neurons: 201, Grad norm: 3.993105628959993\n",
      "Epoch 7270, Loss: 208.70148097693013, Neurons: 201, Grad norm: 3.7334569855685804\n",
      "Epoch 7270, Loss: 208.70148097693013, Neurons: 201, Grad norm: 3.7334569855685804\n",
      "Epoch 7271, Loss: 208.70127096501125, Neurons: 201, Grad norm: 2.4722312937970714\n",
      "Epoch 7271, Loss: 208.70127096501125, Neurons: 201, Grad norm: 2.4722312937970714\n",
      "Epoch 7272, Loss: 208.70086696796335, Neurons: 201, Grad norm: 2.040979950095516\n",
      "Epoch 7272, Loss: 208.70086696796335, Neurons: 201, Grad norm: 2.040979950095516\n",
      "Epoch 7273, Loss: 208.7006610725013, Neurons: 201, Grad norm: 2.635771020267019\n",
      "Epoch 7273, Loss: 208.7006610725013, Neurons: 201, Grad norm: 2.635771020267019\n",
      "Epoch 7274, Loss: 208.7008080684849, Neurons: 201, Grad norm: 3.294497915516817\n",
      "Epoch 7274, Loss: 208.7008080684849, Neurons: 201, Grad norm: 3.294497915516817\n",
      "Epoch 7275, Loss: 208.70095220448312, Neurons: 201, Grad norm: 4.857832292374799\n",
      "Epoch 7275, Loss: 208.70095220448312, Neurons: 201, Grad norm: 4.857832292374799\n",
      "Epoch 7276, Loss: 208.7007923808653, Neurons: 201, Grad norm: 6.4898467285038715\n",
      "Epoch 7276, Loss: 208.7007923808653, Neurons: 201, Grad norm: 6.4898467285038715\n",
      "Epoch 7277, Loss: 208.70079011326675, Neurons: 201, Grad norm: 8.919933174831964\n",
      "Epoch 7277, Loss: 208.70079011326675, Neurons: 201, Grad norm: 8.919933174831964\n",
      "Epoch 7278, Loss: 208.7010094308738, Neurons: 201, Grad norm: 11.007724689397337\n",
      "Epoch 7278, Loss: 208.7010094308738, Neurons: 201, Grad norm: 11.007724689397337\n",
      "Epoch 7279, Loss: 208.70142094670547, Neurons: 201, Grad norm: 12.303874088433178\n",
      "Epoch 7279, Loss: 208.70142094670547, Neurons: 201, Grad norm: 12.303874088433178\n",
      "Epoch 7280, Loss: 208.70173988209027, Neurons: 201, Grad norm: 12.876817479078287\n",
      "Epoch 7280, Loss: 208.70173988209027, Neurons: 201, Grad norm: 12.876817479078287\n",
      "Epoch 7281, Loss: 208.7017585923624, Neurons: 201, Grad norm: 12.224767977628327\n",
      "Epoch 7281, Loss: 208.7017585923624, Neurons: 201, Grad norm: 12.224767977628327\n",
      "Epoch 7282, Loss: 208.70155639232956, Neurons: 201, Grad norm: 11.42280103864754\n",
      "Epoch 7282, Loss: 208.70155639232956, Neurons: 201, Grad norm: 11.42280103864754\n",
      "Epoch 7283, Loss: 208.70162190949722, Neurons: 201, Grad norm: 9.916525862256618\n",
      "Epoch 7283, Loss: 208.70162190949722, Neurons: 201, Grad norm: 9.916525862256618\n",
      "Epoch 7284, Loss: 208.7014329982795, Neurons: 201, Grad norm: 8.192533039465363\n",
      "Epoch 7284, Loss: 208.7014329982795, Neurons: 201, Grad norm: 8.192533039465363\n",
      "Epoch 7285, Loss: 208.7008954696843, Neurons: 201, Grad norm: 6.846983960499691\n",
      "Epoch 7285, Loss: 208.7008954696843, Neurons: 201, Grad norm: 6.846983960499691\n",
      "Epoch 7286, Loss: 208.700264734888, Neurons: 201, Grad norm: 4.9844714583679615\n",
      "Epoch 7286, Loss: 208.700264734888, Neurons: 201, Grad norm: 4.9844714583679615\n",
      "Epoch 7287, Loss: 208.6997255869921, Neurons: 201, Grad norm: 3.7545231877943563\n",
      "Epoch 7287, Loss: 208.6997255869921, Neurons: 201, Grad norm: 3.7545231877943563\n",
      "Epoch 7288, Loss: 208.699495882076, Neurons: 201, Grad norm: 2.9048493210506123\n",
      "Epoch 7288, Loss: 208.699495882076, Neurons: 201, Grad norm: 2.9048493210506123\n",
      "Epoch 7289, Loss: 208.69947228768777, Neurons: 201, Grad norm: 1.9743652816325499\n",
      "Epoch 7289, Loss: 208.69947228768777, Neurons: 201, Grad norm: 1.9743652816325499\n",
      "Epoch 7290, Loss: 208.69939219706268, Neurons: 201, Grad norm: 1.269220661197673\n",
      "Epoch 7290, Loss: 208.69939219706268, Neurons: 201, Grad norm: 1.269220661197673\n",
      "Epoch 7291, Loss: 208.69922708464205, Neurons: 201, Grad norm: 1.6576917351656588\n",
      "Epoch 7291, Loss: 208.69922708464205, Neurons: 201, Grad norm: 1.6576917351656588\n",
      "Epoch 7292, Loss: 208.69907573929103, Neurons: 201, Grad norm: 3.321696692057306\n",
      "Epoch 7292, Loss: 208.69907573929103, Neurons: 201, Grad norm: 3.321696692057306\n",
      "Epoch 7293, Loss: 208.6990683767307, Neurons: 201, Grad norm: 4.644833936527074\n",
      "Epoch 7293, Loss: 208.6990683767307, Neurons: 201, Grad norm: 4.644833936527074\n",
      "Epoch 7294, Loss: 208.69926151053915, Neurons: 201, Grad norm: 5.455833825687461\n",
      "Epoch 7294, Loss: 208.69926151053915, Neurons: 201, Grad norm: 5.455833825687461\n",
      "Epoch 7295, Loss: 208.69928946115058, Neurons: 201, Grad norm: 6.087722775391165\n",
      "Epoch 7295, Loss: 208.69928946115058, Neurons: 201, Grad norm: 6.087722775391165\n",
      "Epoch 7296, Loss: 208.69923313665737, Neurons: 201, Grad norm: 6.334276671524604\n",
      "Epoch 7296, Loss: 208.69923313665737, Neurons: 201, Grad norm: 6.334276671524604\n",
      "Epoch 7297, Loss: 208.6990352751972, Neurons: 201, Grad norm: 6.067214842347468\n",
      "Epoch 7297, Loss: 208.6990352751972, Neurons: 201, Grad norm: 6.067214842347468\n",
      "Epoch 7298, Loss: 208.6989935573773, Neurons: 201, Grad norm: 6.11060593983306\n",
      "Epoch 7298, Loss: 208.6989935573773, Neurons: 201, Grad norm: 6.11060593983306\n",
      "Epoch 7299, Loss: 208.69902584347543, Neurons: 201, Grad norm: 6.167266093823079\n",
      "Epoch 7299, Loss: 208.69902584347543, Neurons: 201, Grad norm: 6.167266093823079\n",
      "Epoch 7300, Loss: 208.69905368036186, Neurons: 201, Grad norm: 6.208472240445798\n",
      "Epoch 7300, Loss: 208.69905368036186, Neurons: 201, Grad norm: 6.208472240445798\n",
      "Epoch 7301, Loss: 208.69913257978402, Neurons: 201, Grad norm: 6.2052209061373755\n",
      "Epoch 7301, Loss: 208.69913257978402, Neurons: 201, Grad norm: 6.2052209061373755\n",
      "Epoch 7302, Loss: 208.6989867629998, Neurons: 201, Grad norm: 6.666880432134398\n",
      "Epoch 7302, Loss: 208.6989867629998, Neurons: 201, Grad norm: 6.666880432134398\n",
      "Epoch 7303, Loss: 208.6987924572765, Neurons: 201, Grad norm: 7.442768965080319\n",
      "Epoch 7303, Loss: 208.6987924572765, Neurons: 201, Grad norm: 7.442768965080319\n",
      "Epoch 7304, Loss: 208.69874604620568, Neurons: 201, Grad norm: 8.495000100583512\n",
      "Epoch 7304, Loss: 208.69874604620568, Neurons: 201, Grad norm: 8.495000100583512\n",
      "Epoch 7305, Loss: 208.69880766948907, Neurons: 201, Grad norm: 9.317937871350253\n",
      "Epoch 7305, Loss: 208.69880766948907, Neurons: 201, Grad norm: 9.317937871350253\n",
      "Epoch 7306, Loss: 208.69900427454758, Neurons: 201, Grad norm: 9.7438333592793\n",
      "Epoch 7306, Loss: 208.69900427454758, Neurons: 201, Grad norm: 9.7438333592793\n",
      "Epoch 7307, Loss: 208.69895204650933, Neurons: 201, Grad norm: 8.902353214653722\n",
      "Epoch 7307, Loss: 208.69895204650933, Neurons: 201, Grad norm: 8.902353214653722\n",
      "Epoch 7308, Loss: 208.69877200949065, Neurons: 201, Grad norm: 7.698743166556521\n",
      "Epoch 7308, Loss: 208.69877200949065, Neurons: 201, Grad norm: 7.698743166556521\n",
      "Epoch 7309, Loss: 208.69852272186588, Neurons: 201, Grad norm: 6.288518285132174\n",
      "Epoch 7309, Loss: 208.69852272186588, Neurons: 201, Grad norm: 6.288518285132174\n",
      "Epoch 7310, Loss: 208.69832624756089, Neurons: 201, Grad norm: 4.845804300739617\n",
      "Epoch 7310, Loss: 208.69832624756089, Neurons: 201, Grad norm: 4.845804300739617\n",
      "Epoch 7311, Loss: 208.69828200428262, Neurons: 201, Grad norm: 3.6955125144477377\n",
      "Epoch 7311, Loss: 208.69828200428262, Neurons: 201, Grad norm: 3.6955125144477377\n",
      "Epoch 7312, Loss: 208.69807556050506, Neurons: 201, Grad norm: 2.774978299673909\n",
      "Epoch 7312, Loss: 208.69807556050506, Neurons: 201, Grad norm: 2.774978299673909\n",
      "Epoch 7313, Loss: 208.69773335056962, Neurons: 201, Grad norm: 2.271855610805796\n",
      "Epoch 7313, Loss: 208.69773335056962, Neurons: 201, Grad norm: 2.271855610805796\n",
      "Epoch 7314, Loss: 208.6975463188416, Neurons: 201, Grad norm: 2.0601182800216136\n",
      "Epoch 7314, Loss: 208.6975463188416, Neurons: 201, Grad norm: 2.0601182800216136\n",
      "Epoch 7315, Loss: 208.6974785845373, Neurons: 201, Grad norm: 1.9176328689525752\n",
      "Epoch 7315, Loss: 208.6974785845373, Neurons: 201, Grad norm: 1.9176328689525752\n",
      "Epoch 7316, Loss: 208.697449701285, Neurons: 201, Grad norm: 1.9151237549763476\n",
      "Epoch 7316, Loss: 208.697449701285, Neurons: 201, Grad norm: 1.9151237549763476\n",
      "Epoch 7317, Loss: 208.69740306665594, Neurons: 201, Grad norm: 1.1233717246841834\n",
      "Epoch 7317, Loss: 208.69740306665594, Neurons: 201, Grad norm: 1.1233717246841834\n",
      "Epoch 7318, Loss: 208.69725334725234, Neurons: 201, Grad norm: 0.6033481008139066\n",
      "Epoch 7318, Loss: 208.69725334725234, Neurons: 201, Grad norm: 0.6033481008139066\n",
      "Epoch 7319, Loss: 208.69710615312331, Neurons: 201, Grad norm: 0.8174962958486615\n",
      "Epoch 7319, Loss: 208.69710615312331, Neurons: 201, Grad norm: 0.8174962958486615\n",
      "Epoch 7320, Loss: 208.6970526937044, Neurons: 201, Grad norm: 1.7598759787059235\n",
      "Epoch 7320, Loss: 208.6970526937044, Neurons: 201, Grad norm: 1.7598759787059235\n",
      "Epoch 7321, Loss: 208.69706204176094, Neurons: 201, Grad norm: 1.9291502771472075\n",
      "Epoch 7321, Loss: 208.69706204176094, Neurons: 201, Grad norm: 1.9291502771472075\n",
      "Epoch 7322, Loss: 208.69697049729697, Neurons: 201, Grad norm: 1.9078730958059142\n",
      "Epoch 7322, Loss: 208.69697049729697, Neurons: 201, Grad norm: 1.9078730958059142\n",
      "Epoch 7323, Loss: 208.6968403335769, Neurons: 201, Grad norm: 2.4782227122953735\n",
      "Epoch 7323, Loss: 208.6968403335769, Neurons: 201, Grad norm: 2.4782227122953735\n",
      "Epoch 7324, Loss: 208.696792939151, Neurons: 201, Grad norm: 2.8209088962256486\n",
      "Epoch 7324, Loss: 208.696792939151, Neurons: 201, Grad norm: 2.8209088962256486\n",
      "Epoch 7325, Loss: 208.6967435911431, Neurons: 201, Grad norm: 4.0415447952545405\n",
      "Epoch 7325, Loss: 208.6967435911431, Neurons: 201, Grad norm: 4.0415447952545405\n",
      "Epoch 7326, Loss: 208.69675717773194, Neurons: 201, Grad norm: 5.265849034583585\n",
      "Epoch 7326, Loss: 208.69675717773194, Neurons: 201, Grad norm: 5.265849034583585\n",
      "Epoch 7327, Loss: 208.69682151944534, Neurons: 201, Grad norm: 6.662914062751056\n",
      "Epoch 7327, Loss: 208.69682151944534, Neurons: 201, Grad norm: 6.662914062751056\n",
      "Epoch 7328, Loss: 208.69693384024345, Neurons: 201, Grad norm: 8.816612550240583\n",
      "Epoch 7328, Loss: 208.69693384024345, Neurons: 201, Grad norm: 8.816612550240583\n",
      "Epoch 7329, Loss: 208.69718670662547, Neurons: 201, Grad norm: 11.160505738983037\n",
      "Epoch 7329, Loss: 208.69718670662547, Neurons: 201, Grad norm: 11.160505738983037\n",
      "Epoch 7330, Loss: 208.69763977713782, Neurons: 201, Grad norm: 13.245101275055882\n",
      "Epoch 7330, Loss: 208.69763977713782, Neurons: 201, Grad norm: 13.245101275055882\n",
      "Epoch 7331, Loss: 208.69824956259353, Neurons: 201, Grad norm: 15.499743396290887\n",
      "Epoch 7331, Loss: 208.69824956259353, Neurons: 201, Grad norm: 15.499743396290887\n",
      "Epoch 7332, Loss: 208.69897503683063, Neurons: 201, Grad norm: 17.067667901905768\n",
      "Epoch 7332, Loss: 208.69897503683063, Neurons: 201, Grad norm: 17.067667901905768\n",
      "Epoch 7333, Loss: 208.69989909036167, Neurons: 201, Grad norm: 18.18793749976638\n",
      "Epoch 7333, Loss: 208.69989909036167, Neurons: 201, Grad norm: 18.18793749976638\n",
      "Epoch 7334, Loss: 208.70066049531042, Neurons: 201, Grad norm: 18.27482886651938\n",
      "Epoch 7334, Loss: 208.70066049531042, Neurons: 201, Grad norm: 18.27482886651938\n",
      "Epoch 7335, Loss: 208.7004968645694, Neurons: 201, Grad norm: 17.40585558798071\n",
      "Epoch 7335, Loss: 208.7004968645694, Neurons: 201, Grad norm: 17.40585558798071\n",
      "Epoch 7336, Loss: 208.69967715425568, Neurons: 201, Grad norm: 14.932231496922165\n",
      "Epoch 7336, Loss: 208.69967715425568, Neurons: 201, Grad norm: 14.932231496922165\n",
      "Epoch 7337, Loss: 208.69849188542045, Neurons: 201, Grad norm: 10.740766296641738\n",
      "Epoch 7337, Loss: 208.69849188542045, Neurons: 201, Grad norm: 10.740766296641738\n",
      "Epoch 7338, Loss: 208.6972295970524, Neurons: 201, Grad norm: 5.785477060846483\n",
      "Epoch 7338, Loss: 208.6972295970524, Neurons: 201, Grad norm: 5.785477060846483\n",
      "Epoch 7339, Loss: 208.6961976781777, Neurons: 201, Grad norm: 0.6181583923850942\n",
      "Epoch 7339, Loss: 208.6961976781777, Neurons: 201, Grad norm: 0.6181583923850942\n",
      "Epoch 7340, Loss: 208.6957981108497, Neurons: 201, Grad norm: 5.123030768460191\n",
      "Epoch 7340, Loss: 208.6957981108497, Neurons: 201, Grad norm: 5.123030768460191\n",
      "Epoch 7341, Loss: 208.69594089357037, Neurons: 201, Grad norm: 9.252278747380531\n",
      "Epoch 7341, Loss: 208.69594089357037, Neurons: 201, Grad norm: 9.252278747380531\n",
      "Epoch 7342, Loss: 208.69650494256953, Neurons: 201, Grad norm: 12.364328262289407\n",
      "Epoch 7342, Loss: 208.69650494256953, Neurons: 201, Grad norm: 12.364328262289407\n",
      "Epoch 7343, Loss: 208.6971560541909, Neurons: 201, Grad norm: 13.413445268763825\n",
      "Epoch 7343, Loss: 208.6971560541909, Neurons: 201, Grad norm: 13.413445268763825\n",
      "Epoch 7344, Loss: 208.69748080032474, Neurons: 201, Grad norm: 12.889251467730132\n",
      "Epoch 7344, Loss: 208.69748080032474, Neurons: 201, Grad norm: 12.889251467730132\n",
      "Epoch 7345, Loss: 208.69732484559873, Neurons: 201, Grad norm: 10.98657116497213\n",
      "Epoch 7345, Loss: 208.69732484559873, Neurons: 201, Grad norm: 10.98657116497213\n",
      "Epoch 7346, Loss: 208.69685613218797, Neurons: 201, Grad norm: 8.482966403943509\n",
      "Epoch 7346, Loss: 208.69685613218797, Neurons: 201, Grad norm: 8.482966403943509\n",
      "Epoch 7347, Loss: 208.69619446692585, Neurons: 201, Grad norm: 5.57157801642849\n",
      "Epoch 7347, Loss: 208.69619446692585, Neurons: 201, Grad norm: 5.57157801642849\n",
      "Epoch 7348, Loss: 208.6957223715544, Neurons: 201, Grad norm: 2.650978477256783\n",
      "Epoch 7348, Loss: 208.6957223715544, Neurons: 201, Grad norm: 2.650978477256783\n",
      "Epoch 7349, Loss: 208.69529246684252, Neurons: 201, Grad norm: 0.5667862281609727\n",
      "Epoch 7349, Loss: 208.69529246684252, Neurons: 201, Grad norm: 0.5667862281609727\n",
      "Epoch 7350, Loss: 208.69507178689454, Neurons: 201, Grad norm: 3.0669045827324544\n",
      "Epoch 7350, Loss: 208.69507178689454, Neurons: 201, Grad norm: 3.0669045827324544\n",
      "Epoch 7351, Loss: 208.69523796139904, Neurons: 201, Grad norm: 5.324454552263892\n",
      "Epoch 7351, Loss: 208.69523796139904, Neurons: 201, Grad norm: 5.324454552263892\n",
      "Epoch 7352, Loss: 208.69551052522058, Neurons: 201, Grad norm: 7.6512289803093765\n",
      "Epoch 7352, Loss: 208.69551052522058, Neurons: 201, Grad norm: 7.6512289803093765\n",
      "Epoch 7353, Loss: 208.6957303009855, Neurons: 201, Grad norm: 9.869534942585616\n",
      "Epoch 7353, Loss: 208.6957303009855, Neurons: 201, Grad norm: 9.869534942585616\n",
      "Epoch 7354, Loss: 208.69593569647424, Neurons: 201, Grad norm: 11.557415178096946\n",
      "Epoch 7354, Loss: 208.69593569647424, Neurons: 201, Grad norm: 11.557415178096946\n",
      "Epoch 7355, Loss: 208.69618474022545, Neurons: 201, Grad norm: 12.689810602931708\n",
      "Epoch 7355, Loss: 208.69618474022545, Neurons: 201, Grad norm: 12.689810602931708\n",
      "Epoch 7356, Loss: 208.6963723458233, Neurons: 201, Grad norm: 12.080516887754971\n",
      "Epoch 7356, Loss: 208.6963723458233, Neurons: 201, Grad norm: 12.080516887754971\n",
      "Epoch 7357, Loss: 208.69626196811035, Neurons: 201, Grad norm: 10.242890528686456\n",
      "Epoch 7357, Loss: 208.69626196811035, Neurons: 201, Grad norm: 10.242890528686456\n",
      "Epoch 7358, Loss: 208.69575294917135, Neurons: 201, Grad norm: 6.9235510635393585\n",
      "Epoch 7358, Loss: 208.69575294917135, Neurons: 201, Grad norm: 6.9235510635393585\n",
      "Epoch 7359, Loss: 208.69512206211112, Neurons: 201, Grad norm: 3.2357751431040147\n",
      "Epoch 7359, Loss: 208.69512206211112, Neurons: 201, Grad norm: 3.2357751431040147\n",
      "Epoch 7360, Loss: 208.6947383327195, Neurons: 201, Grad norm: 1.6548493668262285\n",
      "Epoch 7360, Loss: 208.6947383327195, Neurons: 201, Grad norm: 1.6548493668262285\n",
      "Epoch 7361, Loss: 208.69451559353004, Neurons: 201, Grad norm: 3.3592846532127423\n",
      "Epoch 7361, Loss: 208.69451559353004, Neurons: 201, Grad norm: 3.3592846532127423\n",
      "Epoch 7362, Loss: 208.6944957120082, Neurons: 201, Grad norm: 4.954265963077416\n",
      "Epoch 7362, Loss: 208.6944957120082, Neurons: 201, Grad norm: 4.954265963077416\n",
      "Epoch 7363, Loss: 208.69452979178465, Neurons: 201, Grad norm: 5.772071277739705\n",
      "Epoch 7363, Loss: 208.69452979178465, Neurons: 201, Grad norm: 5.772071277739705\n",
      "Epoch 7364, Loss: 208.69463497877678, Neurons: 201, Grad norm: 6.50829697700525\n",
      "Epoch 7364, Loss: 208.69463497877678, Neurons: 201, Grad norm: 6.50829697700525\n",
      "Epoch 7365, Loss: 208.69471442728218, Neurons: 201, Grad norm: 7.1452537529778555\n",
      "Epoch 7365, Loss: 208.69471442728218, Neurons: 201, Grad norm: 7.1452537529778555\n",
      "Epoch 7366, Loss: 208.6947904670144, Neurons: 201, Grad norm: 7.766481526230608\n",
      "Epoch 7366, Loss: 208.6947904670144, Neurons: 201, Grad norm: 7.766481526230608\n",
      "Epoch 7367, Loss: 208.6946489179335, Neurons: 201, Grad norm: 8.01598915747533\n",
      "Epoch 7367, Loss: 208.6946489179335, Neurons: 201, Grad norm: 8.01598915747533\n",
      "Epoch 7368, Loss: 208.69457631343, Neurons: 201, Grad norm: 8.390213317995496\n",
      "Epoch 7368, Loss: 208.69457631343, Neurons: 201, Grad norm: 8.390213317995496\n",
      "Epoch 7369, Loss: 208.69456021715888, Neurons: 201, Grad norm: 8.375093339478427\n",
      "Epoch 7369, Loss: 208.69456021715888, Neurons: 201, Grad norm: 8.375093339478427\n",
      "Epoch 7370, Loss: 208.69447628219697, Neurons: 201, Grad norm: 7.737058509666615\n",
      "Epoch 7370, Loss: 208.69447628219697, Neurons: 201, Grad norm: 7.737058509666615\n",
      "Epoch 7371, Loss: 208.69434184986082, Neurons: 201, Grad norm: 6.980155863132565\n",
      "Epoch 7371, Loss: 208.69434184986082, Neurons: 201, Grad norm: 6.980155863132565\n",
      "Epoch 7372, Loss: 208.69415104620208, Neurons: 201, Grad norm: 5.636564605160463\n",
      "Epoch 7372, Loss: 208.69415104620208, Neurons: 201, Grad norm: 5.636564605160463\n",
      "Epoch 7373, Loss: 208.69389436093388, Neurons: 201, Grad norm: 4.065201639618669\n",
      "Epoch 7373, Loss: 208.69389436093388, Neurons: 201, Grad norm: 4.065201639618669\n",
      "Epoch 7374, Loss: 208.69377221634636, Neurons: 201, Grad norm: 2.954151283367128\n",
      "Epoch 7374, Loss: 208.69377221634636, Neurons: 201, Grad norm: 2.954151283367128\n",
      "Epoch 7375, Loss: 208.6937144876586, Neurons: 201, Grad norm: 1.9417950794589516\n",
      "Epoch 7375, Loss: 208.6937144876586, Neurons: 201, Grad norm: 1.9417950794589516\n",
      "Epoch 7376, Loss: 208.6936245487541, Neurons: 201, Grad norm: 1.1776503409687398\n",
      "Epoch 7376, Loss: 208.6936245487541, Neurons: 201, Grad norm: 1.1776503409687398\n",
      "Epoch 7377, Loss: 208.6934187865476, Neurons: 201, Grad norm: 0.5710123325903598\n",
      "Epoch 7377, Loss: 208.6934187865476, Neurons: 201, Grad norm: 0.5710123325903598\n",
      "Epoch 7378, Loss: 208.6932139275697, Neurons: 201, Grad norm: 1.2281636410183676\n",
      "Epoch 7378, Loss: 208.6932139275697, Neurons: 201, Grad norm: 1.2281636410183676\n",
      "Epoch 7379, Loss: 208.69322364694145, Neurons: 201, Grad norm: 2.2475195254264606\n",
      "Epoch 7379, Loss: 208.69322364694145, Neurons: 201, Grad norm: 2.2475195254264606\n",
      "Epoch 7380, Loss: 208.69326262237672, Neurons: 201, Grad norm: 3.455473711860069\n",
      "Epoch 7380, Loss: 208.69326262237672, Neurons: 201, Grad norm: 3.455473711860069\n",
      "Epoch 7381, Loss: 208.69330679637795, Neurons: 201, Grad norm: 5.679609954110634\n",
      "Epoch 7381, Loss: 208.69330679637795, Neurons: 201, Grad norm: 5.679609954110634\n",
      "Epoch 7382, Loss: 208.69337829453437, Neurons: 201, Grad norm: 8.28076187761948\n",
      "Epoch 7382, Loss: 208.69337829453437, Neurons: 201, Grad norm: 8.28076187761948\n",
      "Epoch 7383, Loss: 208.69375935074925, Neurons: 201, Grad norm: 11.31869268981595\n",
      "Epoch 7383, Loss: 208.69375935074925, Neurons: 201, Grad norm: 11.31869268981595\n",
      "Epoch 7384, Loss: 208.69426619919662, Neurons: 201, Grad norm: 13.112501644234644\n",
      "Epoch 7384, Loss: 208.69426619919662, Neurons: 201, Grad norm: 13.112501644234644\n",
      "Epoch 7385, Loss: 208.69483231843833, Neurons: 201, Grad norm: 13.948788816261885\n",
      "Epoch 7385, Loss: 208.69483231843833, Neurons: 201, Grad norm: 13.948788816261885\n",
      "Epoch 7386, Loss: 208.69489429507018, Neurons: 201, Grad norm: 12.742815993565882\n",
      "Epoch 7386, Loss: 208.69489429507018, Neurons: 201, Grad norm: 12.742815993565882\n",
      "Epoch 7387, Loss: 208.69456759185655, Neurons: 201, Grad norm: 9.847480596178245\n",
      "Epoch 7387, Loss: 208.69456759185655, Neurons: 201, Grad norm: 9.847480596178245\n",
      "Epoch 7388, Loss: 208.69387904836495, Neurons: 201, Grad norm: 6.608120260468983\n",
      "Epoch 7388, Loss: 208.69387904836495, Neurons: 201, Grad norm: 6.608120260468983\n",
      "Epoch 7389, Loss: 208.6932114298976, Neurons: 201, Grad norm: 2.990844594163799\n",
      "Epoch 7389, Loss: 208.6932114298976, Neurons: 201, Grad norm: 2.990844594163799\n",
      "Epoch 7390, Loss: 208.69279075270381, Neurons: 201, Grad norm: 1.3718863184367038\n",
      "Epoch 7390, Loss: 208.69279075270381, Neurons: 201, Grad norm: 1.3718863184367038\n",
      "Epoch 7391, Loss: 208.69255409529427, Neurons: 201, Grad norm: 3.7179154341472396\n",
      "Epoch 7391, Loss: 208.69255409529427, Neurons: 201, Grad norm: 3.7179154341472396\n",
      "Epoch 7392, Loss: 208.6925019134143, Neurons: 201, Grad norm: 6.054692741868974\n",
      "Epoch 7392, Loss: 208.6925019134143, Neurons: 201, Grad norm: 6.054692741868974\n",
      "Epoch 7393, Loss: 208.69282309649552, Neurons: 201, Grad norm: 8.364004118667188\n",
      "Epoch 7393, Loss: 208.69282309649552, Neurons: 201, Grad norm: 8.364004118667188\n",
      "Epoch 7394, Loss: 208.69337523902686, Neurons: 201, Grad norm: 10.394511418466543\n",
      "Epoch 7394, Loss: 208.69337523902686, Neurons: 201, Grad norm: 10.394511418466543\n",
      "Epoch 7395, Loss: 208.69394407666383, Neurons: 201, Grad norm: 11.370835316853977\n",
      "Epoch 7395, Loss: 208.69394407666383, Neurons: 201, Grad norm: 11.370835316853977\n",
      "Epoch 7396, Loss: 208.69401225272478, Neurons: 201, Grad norm: 11.610295528463876\n",
      "Epoch 7396, Loss: 208.69401225272478, Neurons: 201, Grad norm: 11.610295528463876\n",
      "Epoch 7397, Loss: 208.69356129947258, Neurons: 201, Grad norm: 10.266993971386794\n",
      "Epoch 7397, Loss: 208.69356129947258, Neurons: 201, Grad norm: 10.266993971386794\n",
      "Epoch 7398, Loss: 208.69314442982926, Neurons: 201, Grad norm: 7.617985684732003\n",
      "Epoch 7398, Loss: 208.69314442982926, Neurons: 201, Grad norm: 7.617985684732003\n",
      "Epoch 7399, Loss: 208.69259769102882, Neurons: 201, Grad norm: 4.311624663007714\n",
      "Epoch 7399, Loss: 208.69259769102882, Neurons: 201, Grad norm: 4.311624663007714\n",
      "Epoch 7400, Loss: 208.69205294834612, Neurons: 201, Grad norm: 0.7029831487722804\n",
      "Epoch 7400, Loss: 208.69205294834612, Neurons: 201, Grad norm: 0.7029831487722804\n",
      "Epoch 7401, Loss: 208.69183208612287, Neurons: 201, Grad norm: 2.9485712375189546\n",
      "Epoch 7401, Loss: 208.69183208612287, Neurons: 201, Grad norm: 2.9485712375189546\n",
      "Epoch 7402, Loss: 208.6918750772045, Neurons: 201, Grad norm: 5.3529048502593195\n",
      "Epoch 7402, Loss: 208.6918750772045, Neurons: 201, Grad norm: 5.3529048502593195\n",
      "Epoch 7403, Loss: 208.6920113070413, Neurons: 201, Grad norm: 7.458468041808857\n",
      "Epoch 7403, Loss: 208.6920113070413, Neurons: 201, Grad norm: 7.458468041808857\n",
      "Epoch 7404, Loss: 208.69214293439148, Neurons: 201, Grad norm: 8.056973712660586\n",
      "Epoch 7404, Loss: 208.69214293439148, Neurons: 201, Grad norm: 8.056973712660586\n",
      "Epoch 7405, Loss: 208.69218968514264, Neurons: 201, Grad norm: 8.21782048442871\n",
      "Epoch 7405, Loss: 208.69218968514264, Neurons: 201, Grad norm: 8.21782048442871\n",
      "Epoch 7406, Loss: 208.69219658661575, Neurons: 201, Grad norm: 7.429350360603848\n",
      "Epoch 7406, Loss: 208.69219658661575, Neurons: 201, Grad norm: 7.429350360603848\n",
      "Epoch 7407, Loss: 208.69202157558087, Neurons: 201, Grad norm: 6.276419570598208\n",
      "Epoch 7407, Loss: 208.69202157558087, Neurons: 201, Grad norm: 6.276419570598208\n",
      "Epoch 7408, Loss: 208.69196847325267, Neurons: 201, Grad norm: 5.115980701730343\n",
      "Epoch 7408, Loss: 208.69196847325267, Neurons: 201, Grad norm: 5.115980701730343\n",
      "Epoch 7409, Loss: 208.6919717226903, Neurons: 201, Grad norm: 3.822222971443481\n",
      "Epoch 7409, Loss: 208.6919717226903, Neurons: 201, Grad norm: 3.822222971443481\n",
      "Epoch 7410, Loss: 208.69180524843537, Neurons: 201, Grad norm: 2.4260398737444486\n",
      "Epoch 7410, Loss: 208.69180524843537, Neurons: 201, Grad norm: 2.4260398737444486\n",
      "Epoch 7411, Loss: 208.6914355004657, Neurons: 201, Grad norm: 0.7773280718664664\n",
      "Epoch 7411, Loss: 208.6914355004657, Neurons: 201, Grad norm: 0.7773280718664664\n",
      "Epoch 7412, Loss: 208.69111688928024, Neurons: 201, Grad norm: 1.547722785003992\n",
      "Epoch 7412, Loss: 208.69111688928024, Neurons: 201, Grad norm: 1.547722785003992\n",
      "Epoch 7413, Loss: 208.69105286775627, Neurons: 201, Grad norm: 3.1247689203942826\n",
      "Epoch 7413, Loss: 208.69105286775627, Neurons: 201, Grad norm: 3.1247689203942826\n",
      "Epoch 7414, Loss: 208.69136865387037, Neurons: 201, Grad norm: 5.25229108805753\n",
      "Epoch 7414, Loss: 208.69136865387037, Neurons: 201, Grad norm: 5.25229108805753\n",
      "Epoch 7415, Loss: 208.69168711584263, Neurons: 201, Grad norm: 7.342576622593747\n",
      "Epoch 7415, Loss: 208.69168711584263, Neurons: 201, Grad norm: 7.342576622593747\n",
      "Epoch 7416, Loss: 208.691852611727, Neurons: 201, Grad norm: 10.124702671183183\n",
      "Epoch 7416, Loss: 208.691852611727, Neurons: 201, Grad norm: 10.124702671183183\n",
      "Epoch 7417, Loss: 208.69213118410744, Neurons: 201, Grad norm: 13.062814725482328\n",
      "Epoch 7417, Loss: 208.69213118410744, Neurons: 201, Grad norm: 13.062814725482328\n",
      "Epoch 7418, Loss: 208.69261406818, Neurons: 201, Grad norm: 15.31185952287971\n",
      "Epoch 7418, Loss: 208.69261406818, Neurons: 201, Grad norm: 15.31185952287971\n",
      "Epoch 7419, Loss: 208.6931013182573, Neurons: 201, Grad norm: 14.995843182546155\n",
      "Epoch 7419, Loss: 208.6931013182573, Neurons: 201, Grad norm: 14.995843182546155\n",
      "Epoch 7420, Loss: 208.6931285539511, Neurons: 201, Grad norm: 13.002998956072636\n",
      "Epoch 7420, Loss: 208.6931285539511, Neurons: 201, Grad norm: 13.002998956072636\n",
      "Epoch 7421, Loss: 208.6923932854064, Neurons: 201, Grad norm: 8.435615284760802\n",
      "Epoch 7421, Loss: 208.6923932854064, Neurons: 201, Grad norm: 8.435615284760802\n",
      "Epoch 7422, Loss: 208.6913975287259, Neurons: 201, Grad norm: 3.208838573592231\n",
      "Epoch 7422, Loss: 208.6913975287259, Neurons: 201, Grad norm: 3.208838573592231\n",
      "Epoch 7423, Loss: 208.69071619253677, Neurons: 201, Grad norm: 2.3430608911286828\n",
      "Epoch 7423, Loss: 208.69071619253677, Neurons: 201, Grad norm: 2.3430608911286828\n",
      "Epoch 7424, Loss: 208.69059056727843, Neurons: 201, Grad norm: 6.035283941456952\n",
      "Epoch 7424, Loss: 208.69059056727843, Neurons: 201, Grad norm: 6.035283941456952\n",
      "Epoch 7425, Loss: 208.69081062389893, Neurons: 201, Grad norm: 8.107127646955007\n",
      "Epoch 7425, Loss: 208.69081062389893, Neurons: 201, Grad norm: 8.107127646955007\n",
      "Epoch 7426, Loss: 208.69104841443627, Neurons: 201, Grad norm: 8.6348730104708\n",
      "Epoch 7426, Loss: 208.69104841443627, Neurons: 201, Grad norm: 8.6348730104708\n",
      "Epoch 7427, Loss: 208.69111590736614, Neurons: 201, Grad norm: 7.650188277756264\n",
      "Epoch 7427, Loss: 208.69111590736614, Neurons: 201, Grad norm: 7.650188277756264\n",
      "Epoch 7428, Loss: 208.6910070825675, Neurons: 201, Grad norm: 5.658278543574386\n",
      "Epoch 7428, Loss: 208.6910070825675, Neurons: 201, Grad norm: 5.658278543574386\n",
      "Epoch 7429, Loss: 208.69068333238488, Neurons: 201, Grad norm: 3.322688668672539\n",
      "Epoch 7429, Loss: 208.69068333238488, Neurons: 201, Grad norm: 3.322688668672539\n",
      "Epoch 7430, Loss: 208.69026415278122, Neurons: 201, Grad norm: 1.0930194853778035\n",
      "Epoch 7430, Loss: 208.69026415278122, Neurons: 201, Grad norm: 1.0930194853778035\n",
      "Epoch 7431, Loss: 208.6899884374614, Neurons: 201, Grad norm: 1.235737945687966\n",
      "Epoch 7431, Loss: 208.6899884374614, Neurons: 201, Grad norm: 1.235737945687966\n",
      "Epoch 7432, Loss: 208.68988916338864, Neurons: 201, Grad norm: 2.708477119788757\n",
      "Epoch 7432, Loss: 208.68988916338864, Neurons: 201, Grad norm: 2.708477119788757\n",
      "Epoch 7433, Loss: 208.68991067335136, Neurons: 201, Grad norm: 4.293968773407853\n",
      "Epoch 7433, Loss: 208.68991067335136, Neurons: 201, Grad norm: 4.293968773407853\n",
      "Epoch 7434, Loss: 208.69008351601437, Neurons: 201, Grad norm: 5.212304012638018\n",
      "Epoch 7434, Loss: 208.69008351601437, Neurons: 201, Grad norm: 5.212304012638018\n",
      "Epoch 7435, Loss: 208.69029722230613, Neurons: 201, Grad norm: 6.0185775177347764\n",
      "Epoch 7435, Loss: 208.69029722230613, Neurons: 201, Grad norm: 6.0185775177347764\n",
      "Epoch 7436, Loss: 208.69019880091, Neurons: 201, Grad norm: 6.709097175604451\n",
      "Epoch 7436, Loss: 208.69019880091, Neurons: 201, Grad norm: 6.709097175604451\n",
      "Epoch 7437, Loss: 208.6900217279354, Neurons: 201, Grad norm: 6.805347817415321\n",
      "Epoch 7437, Loss: 208.6900217279354, Neurons: 201, Grad norm: 6.805347817415321\n",
      "Epoch 7438, Loss: 208.68995571411293, Neurons: 201, Grad norm: 7.046703503005544\n",
      "Epoch 7438, Loss: 208.68995571411293, Neurons: 201, Grad norm: 7.046703503005544\n",
      "Epoch 7439, Loss: 208.68987723366607, Neurons: 201, Grad norm: 6.336481427546675\n",
      "Epoch 7439, Loss: 208.68987723366607, Neurons: 201, Grad norm: 6.336481427546675\n",
      "Epoch 7440, Loss: 208.68978610106382, Neurons: 201, Grad norm: 5.280958691336416\n",
      "Epoch 7440, Loss: 208.68978610106382, Neurons: 201, Grad norm: 5.280958691336416\n",
      "Epoch 7441, Loss: 208.68959795212822, Neurons: 201, Grad norm: 3.5514464659445957\n",
      "Epoch 7441, Loss: 208.68959795212822, Neurons: 201, Grad norm: 3.5514464659445957\n",
      "Epoch 7442, Loss: 208.68940559272446, Neurons: 201, Grad norm: 2.504303630570989\n",
      "Epoch 7442, Loss: 208.68940559272446, Neurons: 201, Grad norm: 2.504303630570989\n",
      "Epoch 7443, Loss: 208.68928904818085, Neurons: 201, Grad norm: 1.7447497705145352\n",
      "Epoch 7443, Loss: 208.68928904818085, Neurons: 201, Grad norm: 1.7447497705145352\n",
      "Epoch 7444, Loss: 208.68912007388397, Neurons: 201, Grad norm: 1.4262951064812184\n",
      "Epoch 7444, Loss: 208.68912007388397, Neurons: 201, Grad norm: 1.4262951064812184\n",
      "Epoch 7445, Loss: 208.68912000100104, Neurons: 201, Grad norm: 1.548033781554447\n",
      "Epoch 7445, Loss: 208.68912000100104, Neurons: 201, Grad norm: 1.548033781554447\n",
      "Epoch 7446, Loss: 208.6890837481778, Neurons: 201, Grad norm: 1.7799924492988557\n",
      "Epoch 7446, Loss: 208.6890837481778, Neurons: 201, Grad norm: 1.7799924492988557\n",
      "Epoch 7447, Loss: 208.68896227176484, Neurons: 201, Grad norm: 2.516723360844298\n",
      "Epoch 7447, Loss: 208.68896227176484, Neurons: 201, Grad norm: 2.516723360844298\n",
      "Epoch 7448, Loss: 208.68892341089622, Neurons: 201, Grad norm: 3.783039305261398\n",
      "Epoch 7448, Loss: 208.68892341089622, Neurons: 201, Grad norm: 3.783039305261398\n",
      "Epoch 7449, Loss: 208.68894003707535, Neurons: 201, Grad norm: 5.29842688598368\n",
      "Epoch 7449, Loss: 208.68894003707535, Neurons: 201, Grad norm: 5.29842688598368\n",
      "Epoch 7450, Loss: 208.68904111790314, Neurons: 201, Grad norm: 6.908298157733269\n",
      "Epoch 7450, Loss: 208.68904111790314, Neurons: 201, Grad norm: 6.908298157733269\n",
      "Epoch 7451, Loss: 208.6892370041615, Neurons: 201, Grad norm: 8.332636766445182\n",
      "Epoch 7451, Loss: 208.6892370041615, Neurons: 201, Grad norm: 8.332636766445182\n",
      "Epoch 7452, Loss: 208.6894200260485, Neurons: 201, Grad norm: 9.350057999330128\n",
      "Epoch 7452, Loss: 208.6894200260485, Neurons: 201, Grad norm: 9.350057999330128\n",
      "Epoch 7453, Loss: 208.68944907292945, Neurons: 201, Grad norm: 9.842650680295367\n",
      "Epoch 7453, Loss: 208.68944907292945, Neurons: 201, Grad norm: 9.842650680295367\n",
      "Epoch 7454, Loss: 208.6895464098294, Neurons: 201, Grad norm: 9.890917426002229\n",
      "Epoch 7454, Loss: 208.6895464098294, Neurons: 201, Grad norm: 9.890917426002229\n",
      "Epoch 7455, Loss: 208.6894024887967, Neurons: 201, Grad norm: 9.544917738079166\n",
      "Epoch 7455, Loss: 208.6894024887967, Neurons: 201, Grad norm: 9.544917738079166\n",
      "Epoch 7456, Loss: 208.6892259804836, Neurons: 201, Grad norm: 8.514093871011095\n",
      "Epoch 7456, Loss: 208.6892259804836, Neurons: 201, Grad norm: 8.514093871011095\n",
      "Epoch 7457, Loss: 208.6889785455353, Neurons: 201, Grad norm: 6.6727292629311155\n",
      "Epoch 7457, Loss: 208.6889785455353, Neurons: 201, Grad norm: 6.6727292629311155\n",
      "Epoch 7458, Loss: 208.68853607814324, Neurons: 201, Grad norm: 4.2708880093915464\n",
      "Epoch 7458, Loss: 208.68853607814324, Neurons: 201, Grad norm: 4.2708880093915464\n",
      "Epoch 7459, Loss: 208.68820586218857, Neurons: 201, Grad norm: 1.4624465932045083\n",
      "Epoch 7459, Loss: 208.68820586218857, Neurons: 201, Grad norm: 1.4624465932045083\n",
      "Epoch 7460, Loss: 208.6879928908368, Neurons: 201, Grad norm: 1.6881412576294337\n",
      "Epoch 7460, Loss: 208.6879928908368, Neurons: 201, Grad norm: 1.6881412576294337\n",
      "Epoch 7461, Loss: 208.6878530035745, Neurons: 201, Grad norm: 4.032107271549787\n",
      "Epoch 7461, Loss: 208.6878530035745, Neurons: 201, Grad norm: 4.032107271549787\n",
      "Epoch 7462, Loss: 208.68798973349698, Neurons: 201, Grad norm: 5.918850656644472\n",
      "Epoch 7462, Loss: 208.68798973349698, Neurons: 201, Grad norm: 5.918850656644472\n",
      "Epoch 7463, Loss: 208.68814707320254, Neurons: 201, Grad norm: 7.579843779570269\n",
      "Epoch 7463, Loss: 208.68814707320254, Neurons: 201, Grad norm: 7.579843779570269\n",
      "Epoch 7464, Loss: 208.68823343908494, Neurons: 201, Grad norm: 8.201971466966052\n",
      "Epoch 7464, Loss: 208.68823343908494, Neurons: 201, Grad norm: 8.201971466966052\n",
      "Epoch 7465, Loss: 208.68852032842045, Neurons: 201, Grad norm: 9.171922035799692\n",
      "Epoch 7465, Loss: 208.68852032842045, Neurons: 201, Grad norm: 9.171922035799692\n",
      "Epoch 7466, Loss: 208.68861973265996, Neurons: 201, Grad norm: 9.395802289573947\n",
      "Epoch 7466, Loss: 208.68861973265996, Neurons: 201, Grad norm: 9.395802289573947\n",
      "Epoch 7467, Loss: 208.68849890254484, Neurons: 201, Grad norm: 9.112224548103745\n",
      "Epoch 7467, Loss: 208.68849890254484, Neurons: 201, Grad norm: 9.112224548103745\n",
      "Epoch 7468, Loss: 208.68846327803791, Neurons: 201, Grad norm: 8.493480259900581\n",
      "Epoch 7468, Loss: 208.68846327803791, Neurons: 201, Grad norm: 8.493480259900581\n",
      "Epoch 7469, Loss: 208.68829680491487, Neurons: 201, Grad norm: 7.299987923709829\n",
      "Epoch 7469, Loss: 208.68829680491487, Neurons: 201, Grad norm: 7.299987923709829\n",
      "Epoch 7470, Loss: 208.68798247143, Neurons: 201, Grad norm: 5.759504615056721\n",
      "Epoch 7470, Loss: 208.68798247143, Neurons: 201, Grad norm: 5.759504615056721\n",
      "Epoch 7471, Loss: 208.6876279641267, Neurons: 201, Grad norm: 3.7372526833562185\n",
      "Epoch 7471, Loss: 208.6876279641267, Neurons: 201, Grad norm: 3.7372526833562185\n",
      "Epoch 7472, Loss: 208.68737932271813, Neurons: 201, Grad norm: 1.6830917912181866\n",
      "Epoch 7472, Loss: 208.68737932271813, Neurons: 201, Grad norm: 1.6830917912181866\n",
      "Epoch 7473, Loss: 208.6871446180761, Neurons: 201, Grad norm: 0.7816954659869056\n",
      "Epoch 7473, Loss: 208.6871446180761, Neurons: 201, Grad norm: 0.7816954659869056\n",
      "Epoch 7474, Loss: 208.6870522345361, Neurons: 201, Grad norm: 2.7399896307685485\n",
      "Epoch 7474, Loss: 208.6870522345361, Neurons: 201, Grad norm: 2.7399896307685485\n",
      "Epoch 7475, Loss: 208.68704912751704, Neurons: 201, Grad norm: 4.368537905375321\n",
      "Epoch 7475, Loss: 208.68704912751704, Neurons: 201, Grad norm: 4.368537905375321\n",
      "Epoch 7476, Loss: 208.68708427536615, Neurons: 201, Grad norm: 6.4206476234740855\n",
      "Epoch 7476, Loss: 208.68708427536615, Neurons: 201, Grad norm: 6.4206476234740855\n",
      "Epoch 7477, Loss: 208.68728231377457, Neurons: 201, Grad norm: 8.026484624762157\n",
      "Epoch 7477, Loss: 208.68728231377457, Neurons: 201, Grad norm: 8.026484624762157\n",
      "Epoch 7478, Loss: 208.687524527257, Neurons: 201, Grad norm: 9.943949726186485\n",
      "Epoch 7478, Loss: 208.687524527257, Neurons: 201, Grad norm: 9.943949726186485\n",
      "Epoch 7479, Loss: 208.6878679731064, Neurons: 201, Grad norm: 11.757849454089886\n",
      "Epoch 7479, Loss: 208.6878679731064, Neurons: 201, Grad norm: 11.757849454089886\n",
      "Epoch 7480, Loss: 208.6883297105686, Neurons: 201, Grad norm: 13.703967436317637\n",
      "Epoch 7480, Loss: 208.6883297105686, Neurons: 201, Grad norm: 13.703967436317637\n",
      "Epoch 7481, Loss: 208.688839051659, Neurons: 201, Grad norm: 14.876978887477005\n",
      "Epoch 7481, Loss: 208.688839051659, Neurons: 201, Grad norm: 14.876978887477005\n",
      "Epoch 7482, Loss: 208.68913607545582, Neurons: 201, Grad norm: 15.086198486932048\n",
      "Epoch 7482, Loss: 208.68913607545582, Neurons: 201, Grad norm: 15.086198486932048\n",
      "Epoch 7483, Loss: 208.68911330848752, Neurons: 201, Grad norm: 14.037198947651051\n",
      "Epoch 7483, Loss: 208.68911330848752, Neurons: 201, Grad norm: 14.037198947651051\n",
      "Epoch 7484, Loss: 208.688862389394, Neurons: 201, Grad norm: 11.356590486718018\n",
      "Epoch 7484, Loss: 208.688862389394, Neurons: 201, Grad norm: 11.356590486718018\n",
      "Epoch 7485, Loss: 208.6881019559804, Neurons: 201, Grad norm: 7.380209989763313\n",
      "Epoch 7485, Loss: 208.6881019559804, Neurons: 201, Grad norm: 7.380209989763313\n",
      "Epoch 7486, Loss: 208.68716906229986, Neurons: 201, Grad norm: 3.019791971067711\n",
      "Epoch 7486, Loss: 208.68716906229986, Neurons: 201, Grad norm: 3.019791971067711\n",
      "Epoch 7487, Loss: 208.6864867430246, Neurons: 201, Grad norm: 2.0695371582325692\n",
      "Epoch 7487, Loss: 208.6864867430246, Neurons: 201, Grad norm: 2.0695371582325692\n",
      "Epoch 7488, Loss: 208.6863154700285, Neurons: 201, Grad norm: 5.015807067128424\n",
      "Epoch 7488, Loss: 208.6863154700285, Neurons: 201, Grad norm: 5.015807067128424\n",
      "Epoch 7489, Loss: 208.68643726837965, Neurons: 201, Grad norm: 7.190089315839319\n",
      "Epoch 7489, Loss: 208.68643726837965, Neurons: 201, Grad norm: 7.190089315839319\n",
      "Epoch 7490, Loss: 208.6866487142746, Neurons: 201, Grad norm: 8.338562603254122\n",
      "Epoch 7490, Loss: 208.6866487142746, Neurons: 201, Grad norm: 8.338562603254122\n",
      "Epoch 7491, Loss: 208.68700755234659, Neurons: 201, Grad norm: 8.85741527703717\n",
      "Epoch 7491, Loss: 208.68700755234659, Neurons: 201, Grad norm: 8.85741527703717\n",
      "Epoch 7492, Loss: 208.68734103066245, Neurons: 201, Grad norm: 8.547548177277116\n",
      "Epoch 7492, Loss: 208.68734103066245, Neurons: 201, Grad norm: 8.547548177277116\n",
      "Epoch 7493, Loss: 208.68728605286728, Neurons: 201, Grad norm: 7.488314464358247\n",
      "Epoch 7493, Loss: 208.68728605286728, Neurons: 201, Grad norm: 7.488314464358247\n",
      "Epoch 7494, Loss: 208.68680331576036, Neurons: 201, Grad norm: 6.018749973092673\n",
      "Epoch 7494, Loss: 208.68680331576036, Neurons: 201, Grad norm: 6.018749973092673\n",
      "Epoch 7495, Loss: 208.68619629897796, Neurons: 201, Grad norm: 4.500261911700407\n",
      "Epoch 7495, Loss: 208.68619629897796, Neurons: 201, Grad norm: 4.500261911700407\n",
      "Epoch 7496, Loss: 208.68581897275527, Neurons: 201, Grad norm: 2.766636233898071\n",
      "Epoch 7496, Loss: 208.68581897275527, Neurons: 201, Grad norm: 2.766636233898071\n",
      "Epoch 7497, Loss: 208.6857310102345, Neurons: 201, Grad norm: 1.7726179368702633\n",
      "Epoch 7497, Loss: 208.6857310102345, Neurons: 201, Grad norm: 1.7726179368702633\n",
      "Epoch 7498, Loss: 208.68575372255435, Neurons: 201, Grad norm: 3.1183949503137485\n",
      "Epoch 7498, Loss: 208.68575372255435, Neurons: 201, Grad norm: 3.1183949503137485\n",
      "Epoch 7499, Loss: 208.68573907183938, Neurons: 201, Grad norm: 5.654221979648393\n",
      "Epoch 7499, Loss: 208.68573907183938, Neurons: 201, Grad norm: 5.654221979648393\n",
      "Epoch 7500, Loss: 208.68580893556606, Neurons: 201, Grad norm: 8.130128884761973\n",
      "Epoch 7500, Loss: 208.68580893556606, Neurons: 201, Grad norm: 8.130128884761973\n",
      "Epoch 7501, Loss: 208.68605857896515, Neurons: 201, Grad norm: 9.960456684842143\n",
      "Epoch 7501, Loss: 208.68605857896515, Neurons: 201, Grad norm: 9.960456684842143\n",
      "Epoch 7502, Loss: 208.68633863117836, Neurons: 201, Grad norm: 10.575992773809416\n",
      "Epoch 7502, Loss: 208.68633863117836, Neurons: 201, Grad norm: 10.575992773809416\n",
      "Epoch 7503, Loss: 208.68644467541876, Neurons: 201, Grad norm: 9.848751563155945\n",
      "Epoch 7503, Loss: 208.68644467541876, Neurons: 201, Grad norm: 9.848751563155945\n",
      "Epoch 7504, Loss: 208.68621718222565, Neurons: 201, Grad norm: 8.176351275706628\n",
      "Epoch 7504, Loss: 208.68621718222565, Neurons: 201, Grad norm: 8.176351275706628\n",
      "Epoch 7505, Loss: 208.68587988822475, Neurons: 201, Grad norm: 5.467790703934865\n",
      "Epoch 7505, Loss: 208.68587988822475, Neurons: 201, Grad norm: 5.467790703934865\n",
      "Epoch 7506, Loss: 208.68542463584348, Neurons: 201, Grad norm: 2.84594555092566\n",
      "Epoch 7506, Loss: 208.68542463584348, Neurons: 201, Grad norm: 2.84594555092566\n",
      "Epoch 7507, Loss: 208.68510568108644, Neurons: 201, Grad norm: 1.3431163017533263\n",
      "Epoch 7507, Loss: 208.68510568108644, Neurons: 201, Grad norm: 1.3431163017533263\n",
      "Epoch 7508, Loss: 208.68501781372163, Neurons: 201, Grad norm: 2.1780810398996318\n",
      "Epoch 7508, Loss: 208.68501781372163, Neurons: 201, Grad norm: 2.1780810398996318\n",
      "Epoch 7509, Loss: 208.68496748805111, Neurons: 201, Grad norm: 3.4494194243264054\n",
      "Epoch 7509, Loss: 208.68496748805111, Neurons: 201, Grad norm: 3.4494194243264054\n",
      "Epoch 7510, Loss: 208.68487777093927, Neurons: 201, Grad norm: 4.388471190867351\n",
      "Epoch 7510, Loss: 208.68487777093927, Neurons: 201, Grad norm: 4.388471190867351\n",
      "Epoch 7511, Loss: 208.68492653748604, Neurons: 201, Grad norm: 5.5222075390378\n",
      "Epoch 7511, Loss: 208.68492653748604, Neurons: 201, Grad norm: 5.5222075390378\n",
      "Epoch 7512, Loss: 208.68502054168718, Neurons: 201, Grad norm: 6.62304112169667\n",
      "Epoch 7512, Loss: 208.68502054168718, Neurons: 201, Grad norm: 6.62304112169667\n",
      "Epoch 7513, Loss: 208.6852071882335, Neurons: 201, Grad norm: 7.702957465047768\n",
      "Epoch 7513, Loss: 208.6852071882335, Neurons: 201, Grad norm: 7.702957465047768\n",
      "Epoch 7514, Loss: 208.68529849574182, Neurons: 201, Grad norm: 8.417395849187695\n",
      "Epoch 7514, Loss: 208.68529849574182, Neurons: 201, Grad norm: 8.417395849187695\n",
      "Epoch 7515, Loss: 208.6852842358822, Neurons: 201, Grad norm: 8.613964255714464\n",
      "Epoch 7515, Loss: 208.6852842358822, Neurons: 201, Grad norm: 8.613964255714464\n",
      "Epoch 7516, Loss: 208.6852134328434, Neurons: 201, Grad norm: 8.52351020450342\n",
      "Epoch 7516, Loss: 208.6852134328434, Neurons: 201, Grad norm: 8.52351020450342\n",
      "Epoch 7517, Loss: 208.68517223005261, Neurons: 201, Grad norm: 7.915368684960016\n",
      "Epoch 7517, Loss: 208.68517223005261, Neurons: 201, Grad norm: 7.915368684960016\n",
      "Epoch 7518, Loss: 208.68507785652355, Neurons: 201, Grad norm: 6.803091988785033\n",
      "Epoch 7518, Loss: 208.68507785652355, Neurons: 201, Grad norm: 6.803091988785033\n",
      "Epoch 7519, Loss: 208.6848827224993, Neurons: 201, Grad norm: 5.22132443950757\n",
      "Epoch 7519, Loss: 208.6848827224993, Neurons: 201, Grad norm: 5.22132443950757\n",
      "Epoch 7520, Loss: 208.6846002763001, Neurons: 201, Grad norm: 3.5171016642282664\n",
      "Epoch 7520, Loss: 208.6846002763001, Neurons: 201, Grad norm: 3.5171016642282664\n",
      "Epoch 7521, Loss: 208.68426050444336, Neurons: 201, Grad norm: 2.344590540711109\n",
      "Epoch 7521, Loss: 208.68426050444336, Neurons: 201, Grad norm: 2.344590540711109\n",
      "Epoch 7522, Loss: 208.6841126814032, Neurons: 201, Grad norm: 0.9086081022013267\n",
      "Epoch 7522, Loss: 208.6841126814032, Neurons: 201, Grad norm: 0.9086081022013267\n",
      "Epoch 7523, Loss: 208.6840113541361, Neurons: 201, Grad norm: 0.6810887493397693\n",
      "Epoch 7523, Loss: 208.6840113541361, Neurons: 201, Grad norm: 0.6810887493397693\n",
      "Epoch 7524, Loss: 208.68394681405366, Neurons: 201, Grad norm: 1.5269673332935347\n",
      "Epoch 7524, Loss: 208.68394681405366, Neurons: 201, Grad norm: 1.5269673332935347\n",
      "Epoch 7525, Loss: 208.68382906223033, Neurons: 201, Grad norm: 2.763822645430093\n",
      "Epoch 7525, Loss: 208.68382906223033, Neurons: 201, Grad norm: 2.763822645430093\n",
      "Epoch 7526, Loss: 208.683899393176, Neurons: 201, Grad norm: 4.196111668139983\n",
      "Epoch 7526, Loss: 208.683899393176, Neurons: 201, Grad norm: 4.196111668139983\n",
      "Epoch 7527, Loss: 208.6839509518596, Neurons: 201, Grad norm: 5.039324534173728\n",
      "Epoch 7527, Loss: 208.6839509518596, Neurons: 201, Grad norm: 5.039324534173728\n",
      "Epoch 7528, Loss: 208.683927314295, Neurons: 201, Grad norm: 6.323124231616847\n",
      "Epoch 7528, Loss: 208.683927314295, Neurons: 201, Grad norm: 6.323124231616847\n",
      "Epoch 7529, Loss: 208.68394965824692, Neurons: 201, Grad norm: 7.387486472524327\n",
      "Epoch 7529, Loss: 208.68394965824692, Neurons: 201, Grad norm: 7.387486472524327\n",
      "Epoch 7530, Loss: 208.6841216102836, Neurons: 201, Grad norm: 7.965238556439921\n",
      "Epoch 7530, Loss: 208.6841216102836, Neurons: 201, Grad norm: 7.965238556439921\n",
      "Epoch 7531, Loss: 208.68419977653946, Neurons: 201, Grad norm: 8.479052939610348\n",
      "Epoch 7531, Loss: 208.68419977653946, Neurons: 201, Grad norm: 8.479052939610348\n",
      "Epoch 7532, Loss: 208.68418178280885, Neurons: 201, Grad norm: 8.661706259801917\n",
      "Epoch 7532, Loss: 208.68418178280885, Neurons: 201, Grad norm: 8.661706259801917\n",
      "Epoch 7533, Loss: 208.6840837005726, Neurons: 201, Grad norm: 8.645616640475899\n",
      "Epoch 7533, Loss: 208.6840837005726, Neurons: 201, Grad norm: 8.645616640475899\n",
      "Epoch 7534, Loss: 208.6842336210035, Neurons: 201, Grad norm: 8.868796722148348\n",
      "Epoch 7534, Loss: 208.6842336210035, Neurons: 201, Grad norm: 8.868796722148348\n",
      "Epoch 7535, Loss: 208.68428420752107, Neurons: 201, Grad norm: 8.947063203643683\n",
      "Epoch 7535, Loss: 208.68428420752107, Neurons: 201, Grad norm: 8.947063203643683\n",
      "Epoch 7536, Loss: 208.68423120486824, Neurons: 201, Grad norm: 8.695919469860963\n",
      "Epoch 7536, Loss: 208.68423120486824, Neurons: 201, Grad norm: 8.695919469860963\n",
      "Epoch 7537, Loss: 208.68406390167405, Neurons: 201, Grad norm: 8.097615545163414\n",
      "Epoch 7537, Loss: 208.68406390167405, Neurons: 201, Grad norm: 8.097615545163414\n",
      "Epoch 7538, Loss: 208.68394475911936, Neurons: 201, Grad norm: 7.293163078832526\n",
      "Epoch 7538, Loss: 208.68394475911936, Neurons: 201, Grad norm: 7.293163078832526\n",
      "Epoch 7539, Loss: 208.6836077780798, Neurons: 201, Grad norm: 5.751699848874461\n",
      "Epoch 7539, Loss: 208.6836077780798, Neurons: 201, Grad norm: 5.751699848874461\n",
      "Epoch 7540, Loss: 208.68326569240577, Neurons: 201, Grad norm: 3.761870683091796\n",
      "Epoch 7540, Loss: 208.68326569240577, Neurons: 201, Grad norm: 3.761870683091796\n",
      "Epoch 7541, Loss: 208.68299197318368, Neurons: 201, Grad norm: 1.6485152690803668\n",
      "Epoch 7541, Loss: 208.68299197318368, Neurons: 201, Grad norm: 1.6485152690803668\n",
      "Epoch 7542, Loss: 208.68282948887088, Neurons: 201, Grad norm: 1.3117467832667649\n",
      "Epoch 7542, Loss: 208.68282948887088, Neurons: 201, Grad norm: 1.3117467832667649\n",
      "Epoch 7543, Loss: 208.68271199038793, Neurons: 201, Grad norm: 3.60571417025871\n",
      "Epoch 7543, Loss: 208.68271199038793, Neurons: 201, Grad norm: 3.60571417025871\n",
      "Epoch 7544, Loss: 208.68279269181463, Neurons: 201, Grad norm: 5.909257345870918\n",
      "Epoch 7544, Loss: 208.68279269181463, Neurons: 201, Grad norm: 5.909257345870918\n",
      "Epoch 7545, Loss: 208.68296617733606, Neurons: 201, Grad norm: 8.498444529518668\n",
      "Epoch 7545, Loss: 208.68296617733606, Neurons: 201, Grad norm: 8.498444529518668\n",
      "Epoch 7546, Loss: 208.68322748327554, Neurons: 201, Grad norm: 10.195119308871666\n",
      "Epoch 7546, Loss: 208.68322748327554, Neurons: 201, Grad norm: 10.195119308871666\n",
      "Epoch 7547, Loss: 208.68362194319573, Neurons: 201, Grad norm: 11.460874136558997\n",
      "Epoch 7547, Loss: 208.68362194319573, Neurons: 201, Grad norm: 11.460874136558997\n",
      "Epoch 7548, Loss: 208.683869495092, Neurons: 201, Grad norm: 11.084205028427565\n",
      "Epoch 7548, Loss: 208.683869495092, Neurons: 201, Grad norm: 11.084205028427565\n",
      "Epoch 7549, Loss: 208.68377264762708, Neurons: 201, Grad norm: 9.698447672822441\n",
      "Epoch 7549, Loss: 208.68377264762708, Neurons: 201, Grad norm: 9.698447672822441\n",
      "Epoch 7550, Loss: 208.6834359848428, Neurons: 201, Grad norm: 7.758004942689053\n",
      "Epoch 7550, Loss: 208.6834359848428, Neurons: 201, Grad norm: 7.758004942689053\n",
      "Epoch 7551, Loss: 208.6829262394416, Neurons: 201, Grad norm: 6.841417877191872\n",
      "Epoch 7551, Loss: 208.6829262394416, Neurons: 201, Grad norm: 6.841417877191872\n",
      "Epoch 7552, Loss: 208.68449287637367, Neurons: 201, Grad norm: 8.525022582920473\n",
      "Epoch 7552, Loss: 208.68449287637367, Neurons: 201, Grad norm: 8.525022582920473\n",
      "Epoch 7553, Loss: 208.68794452499054, Neurons: 201, Grad norm: 11.335286319197268\n",
      "Epoch 7553, Loss: 208.68794452499054, Neurons: 201, Grad norm: 11.335286319197268\n",
      "Epoch 7554, Loss: 208.69228815707757, Neurons: 201, Grad norm: 14.694297682249045\n",
      "Epoch 7554, Loss: 208.69228815707757, Neurons: 201, Grad norm: 14.694297682249045\n",
      "Epoch 7555, Loss: 208.69752078855487, Neurons: 201, Grad norm: 15.61454366859033\n",
      "Epoch 7555, Loss: 208.69752078855487, Neurons: 201, Grad norm: 15.61454366859033\n",
      "Epoch 7556, Loss: 208.6924469687118, Neurons: 201, Grad norm: 18.14186956047865\n",
      "Epoch 7556, Loss: 208.6924469687118, Neurons: 201, Grad norm: 18.14186956047865\n",
      "Epoch 7557, Loss: 208.68577001119326, Neurons: 201, Grad norm: 23.573793260561143\n",
      "Epoch 7557, Loss: 208.68577001119326, Neurons: 201, Grad norm: 23.573793260561143\n",
      "Epoch 7558, Loss: 208.69067282245572, Neurons: 201, Grad norm: 22.66443146177315\n",
      "Epoch 7558, Loss: 208.69067282245572, Neurons: 201, Grad norm: 22.66443146177315\n",
      "Epoch 7559, Loss: 208.69144174288675, Neurons: 201, Grad norm: 16.019475082984144\n",
      "Epoch 7559, Loss: 208.69144174288675, Neurons: 201, Grad norm: 16.019475082984144\n",
      "Epoch 7560, Loss: 208.68554837441116, Neurons: 201, Grad norm: 9.774717887102133\n",
      "Epoch 7560, Loss: 208.68554837441116, Neurons: 201, Grad norm: 9.774717887102133\n",
      "Epoch 7561, Loss: 208.687038389336, Neurons: 201, Grad norm: 5.694402807857771\n",
      "Epoch 7561, Loss: 208.687038389336, Neurons: 201, Grad norm: 5.694402807857771\n",
      "Epoch 7562, Loss: 208.6855152528893, Neurons: 201, Grad norm: 4.168765902297291\n",
      "Epoch 7562, Loss: 208.6855152528893, Neurons: 201, Grad norm: 4.168765902297291\n",
      "Epoch 7563, Loss: 208.68252507213617, Neurons: 201, Grad norm: 9.593357036264694\n",
      "Epoch 7563, Loss: 208.68252507213617, Neurons: 201, Grad norm: 9.593357036264694\n",
      "Epoch 7564, Loss: 208.68609107886994, Neurons: 201, Grad norm: 11.560514719537354\n",
      "Epoch 7564, Loss: 208.68609107886994, Neurons: 201, Grad norm: 11.560514719537354\n",
      "Epoch 7565, Loss: 208.68498443346905, Neurons: 201, Grad norm: 13.03974042081958\n",
      "Epoch 7565, Loss: 208.68498443346905, Neurons: 201, Grad norm: 13.03974042081958\n",
      "Epoch 7566, Loss: 208.68349672366946, Neurons: 201, Grad norm: 12.835012020823301\n",
      "Epoch 7566, Loss: 208.68349672366946, Neurons: 201, Grad norm: 12.835012020823301\n",
      "Epoch 7567, Loss: 208.68518839689668, Neurons: 201, Grad norm: 7.510475380090902\n",
      "Epoch 7567, Loss: 208.68518839689668, Neurons: 201, Grad norm: 7.510475380090902\n",
      "Epoch 7568, Loss: 208.68224200044045, Neurons: 201, Grad norm: 3.06329209557075\n",
      "Epoch 7568, Loss: 208.68224200044045, Neurons: 201, Grad norm: 3.06329209557075\n",
      "Epoch 7569, Loss: 208.68197900147013, Neurons: 201, Grad norm: 6.573354129921636\n",
      "Epoch 7569, Loss: 208.68197900147013, Neurons: 201, Grad norm: 6.573354129921636\n",
      "Epoch 7570, Loss: 208.68314963693803, Neurons: 201, Grad norm: 7.638209795114801\n",
      "Epoch 7570, Loss: 208.68314963693803, Neurons: 201, Grad norm: 7.638209795114801\n",
      "Epoch 7571, Loss: 208.6815073852306, Neurons: 201, Grad norm: 9.301337382390974\n",
      "Epoch 7571, Loss: 208.6815073852306, Neurons: 201, Grad norm: 9.301337382390974\n",
      "Epoch 7572, Loss: 208.6825642216991, Neurons: 201, Grad norm: 9.352195918887576\n",
      "Epoch 7572, Loss: 208.6825642216991, Neurons: 201, Grad norm: 9.352195918887576\n",
      "Epoch 7573, Loss: 208.68256289374986, Neurons: 201, Grad norm: 8.590117047452216\n",
      "Epoch 7573, Loss: 208.68256289374986, Neurons: 201, Grad norm: 8.590117047452216\n",
      "Epoch 7574, Loss: 208.6809637403325, Neurons: 201, Grad norm: 6.897436922962696\n",
      "Epoch 7574, Loss: 208.6809637403325, Neurons: 201, Grad norm: 6.897436922962696\n",
      "Epoch 7575, Loss: 208.68147022146488, Neurons: 201, Grad norm: 3.1075626788735464\n",
      "Epoch 7575, Loss: 208.68147022146488, Neurons: 201, Grad norm: 3.1075626788735464\n",
      "Epoch 7576, Loss: 208.68040195431016, Neurons: 201, Grad norm: 2.7144446864416487\n",
      "Epoch 7576, Loss: 208.68040195431016, Neurons: 201, Grad norm: 2.7144446864416487\n",
      "Epoch 7577, Loss: 208.6799718172733, Neurons: 201, Grad norm: 6.606576108936311\n",
      "Epoch 7577, Loss: 208.6799718172733, Neurons: 201, Grad norm: 6.606576108936311\n",
      "Epoch 7578, Loss: 208.68058640343295, Neurons: 201, Grad norm: 6.956766648935307\n",
      "Epoch 7578, Loss: 208.68058640343295, Neurons: 201, Grad norm: 6.956766648935307\n",
      "Epoch 7579, Loss: 208.6800947864538, Neurons: 201, Grad norm: 6.626487662060511\n",
      "Epoch 7579, Loss: 208.6800947864538, Neurons: 201, Grad norm: 6.626487662060511\n",
      "Epoch 7580, Loss: 208.68016318102798, Neurons: 201, Grad norm: 5.7069798846565645\n",
      "Epoch 7580, Loss: 208.68016318102798, Neurons: 201, Grad norm: 5.7069798846565645\n",
      "Epoch 7581, Loss: 208.680126849868, Neurons: 201, Grad norm: 3.9390428755360567\n",
      "Epoch 7581, Loss: 208.680126849868, Neurons: 201, Grad norm: 3.9390428755360567\n",
      "Epoch 7582, Loss: 208.67926642613102, Neurons: 201, Grad norm: 2.7467000800107955\n",
      "Epoch 7582, Loss: 208.67926642613102, Neurons: 201, Grad norm: 2.7467000800107955\n",
      "Epoch 7583, Loss: 208.6792569072663, Neurons: 201, Grad norm: 1.829419465572285\n",
      "Epoch 7583, Loss: 208.6792569072663, Neurons: 201, Grad norm: 1.829419465572285\n",
      "Epoch 7584, Loss: 208.67915650717615, Neurons: 201, Grad norm: 3.70909640194585\n",
      "Epoch 7584, Loss: 208.67915650717615, Neurons: 201, Grad norm: 3.70909640194585\n",
      "Epoch 7585, Loss: 208.67893760591642, Neurons: 201, Grad norm: 6.250669425221085\n",
      "Epoch 7585, Loss: 208.67893760591642, Neurons: 201, Grad norm: 6.250669425221085\n",
      "Epoch 7586, Loss: 208.67929861323776, Neurons: 201, Grad norm: 7.109787251117565\n",
      "Epoch 7586, Loss: 208.67929861323776, Neurons: 201, Grad norm: 7.109787251117565\n",
      "Epoch 7587, Loss: 208.6791888439683, Neurons: 201, Grad norm: 7.080893414662476\n",
      "Epoch 7587, Loss: 208.6791888439683, Neurons: 201, Grad norm: 7.080893414662476\n",
      "Epoch 7588, Loss: 208.67904020150513, Neurons: 201, Grad norm: 6.145137457786025\n",
      "Epoch 7588, Loss: 208.67904020150513, Neurons: 201, Grad norm: 6.145137457786025\n",
      "Epoch 7589, Loss: 208.67902821147325, Neurons: 201, Grad norm: 4.8682117137883445\n",
      "Epoch 7589, Loss: 208.67902821147325, Neurons: 201, Grad norm: 4.8682117137883445\n",
      "Epoch 7590, Loss: 208.67858002368948, Neurons: 201, Grad norm: 3.3736305900289296\n",
      "Epoch 7590, Loss: 208.67858002368948, Neurons: 201, Grad norm: 3.3736305900289296\n",
      "Epoch 7591, Loss: 208.67829319581594, Neurons: 201, Grad norm: 1.8183061229578454\n",
      "Epoch 7591, Loss: 208.67829319581594, Neurons: 201, Grad norm: 1.8183061229578454\n",
      "Epoch 7592, Loss: 208.67828372848973, Neurons: 201, Grad norm: 1.3118263890527186\n",
      "Epoch 7592, Loss: 208.67828372848973, Neurons: 201, Grad norm: 1.3118263890527186\n",
      "Epoch 7593, Loss: 208.67806956346993, Neurons: 201, Grad norm: 3.757924657121322\n",
      "Epoch 7593, Loss: 208.67806956346993, Neurons: 201, Grad norm: 3.757924657121322\n",
      "Epoch 7594, Loss: 208.67811185268909, Neurons: 201, Grad norm: 5.511640172292772\n",
      "Epoch 7594, Loss: 208.67811185268909, Neurons: 201, Grad norm: 5.511640172292772\n",
      "Epoch 7595, Loss: 208.6782570109971, Neurons: 201, Grad norm: 6.284948403634259\n",
      "Epoch 7595, Loss: 208.6782570109971, Neurons: 201, Grad norm: 6.284948403634259\n",
      "Epoch 7596, Loss: 208.67826860513168, Neurons: 201, Grad norm: 6.740537428804781\n",
      "Epoch 7596, Loss: 208.67826860513168, Neurons: 201, Grad norm: 6.740537428804781\n",
      "Epoch 7597, Loss: 208.67828232376561, Neurons: 201, Grad norm: 6.326205985644593\n",
      "Epoch 7597, Loss: 208.67828232376561, Neurons: 201, Grad norm: 6.326205985644593\n",
      "Epoch 7598, Loss: 208.6781832536405, Neurons: 201, Grad norm: 5.6778665878207795\n",
      "Epoch 7598, Loss: 208.6781832536405, Neurons: 201, Grad norm: 5.6778665878207795\n",
      "Epoch 7599, Loss: 208.67781713333747, Neurons: 201, Grad norm: 4.828204837425568\n",
      "Epoch 7599, Loss: 208.67781713333747, Neurons: 201, Grad norm: 4.828204837425568\n",
      "Epoch 7600, Loss: 208.6777253721947, Neurons: 201, Grad norm: 3.364294262277803\n",
      "Epoch 7600, Loss: 208.6777253721947, Neurons: 201, Grad norm: 3.364294262277803\n",
      "Epoch 7601, Loss: 208.6775485273565, Neurons: 201, Grad norm: 1.1980168718830118\n",
      "Epoch 7601, Loss: 208.6775485273565, Neurons: 201, Grad norm: 1.1980168718830118\n",
      "Epoch 7602, Loss: 208.67731898993028, Neurons: 201, Grad norm: 1.3695499769429311\n",
      "Epoch 7602, Loss: 208.67731898993028, Neurons: 201, Grad norm: 1.3695499769429311\n",
      "Epoch 7603, Loss: 208.6772872161701, Neurons: 201, Grad norm: 2.2979982600480944\n",
      "Epoch 7603, Loss: 208.6772872161701, Neurons: 201, Grad norm: 2.2979982600480944\n",
      "Epoch 7604, Loss: 208.67725404798097, Neurons: 201, Grad norm: 3.0132781735820267\n",
      "Epoch 7604, Loss: 208.67725404798097, Neurons: 201, Grad norm: 3.0132781735820267\n",
      "Epoch 7605, Loss: 208.67722969495435, Neurons: 201, Grad norm: 3.7433070105653385\n",
      "Epoch 7605, Loss: 208.67722969495435, Neurons: 201, Grad norm: 3.7433070105653385\n",
      "Epoch 7606, Loss: 208.67731323027348, Neurons: 201, Grad norm: 4.021398189456976\n",
      "Epoch 7606, Loss: 208.67731323027348, Neurons: 201, Grad norm: 4.021398189456976\n",
      "Epoch 7607, Loss: 208.67714687285226, Neurons: 201, Grad norm: 4.691735238184404\n",
      "Epoch 7607, Loss: 208.67714687285226, Neurons: 201, Grad norm: 4.691735238184404\n",
      "Epoch 7608, Loss: 208.67706381128997, Neurons: 201, Grad norm: 5.439293351087531\n",
      "Epoch 7608, Loss: 208.67706381128997, Neurons: 201, Grad norm: 5.439293351087531\n",
      "Epoch 7609, Loss: 208.6771461984581, Neurons: 201, Grad norm: 5.401218406087851\n",
      "Epoch 7609, Loss: 208.6771461984581, Neurons: 201, Grad norm: 5.401218406087851\n",
      "Epoch 7610, Loss: 208.6770026196807, Neurons: 201, Grad norm: 4.955154215694181\n",
      "Epoch 7610, Loss: 208.6770026196807, Neurons: 201, Grad norm: 4.955154215694181\n",
      "Epoch 7611, Loss: 208.67696073596207, Neurons: 201, Grad norm: 4.384780721490794\n",
      "Epoch 7611, Loss: 208.67696073596207, Neurons: 201, Grad norm: 4.384780721490794\n",
      "Epoch 7612, Loss: 208.67692070375713, Neurons: 201, Grad norm: 3.7763411636256166\n",
      "Epoch 7612, Loss: 208.67692070375713, Neurons: 201, Grad norm: 3.7763411636256166\n",
      "Epoch 7613, Loss: 208.6766922355122, Neurons: 201, Grad norm: 3.4681780836017975\n",
      "Epoch 7613, Loss: 208.6766922355122, Neurons: 201, Grad norm: 3.4681780836017975\n",
      "Epoch 7614, Loss: 208.67655182710632, Neurons: 201, Grad norm: 3.234186555733498\n",
      "Epoch 7614, Loss: 208.67655182710632, Neurons: 201, Grad norm: 3.234186555733498\n",
      "Epoch 7615, Loss: 208.67653406042783, Neurons: 201, Grad norm: 2.6916740032134197\n",
      "Epoch 7615, Loss: 208.67653406042783, Neurons: 201, Grad norm: 2.6916740032134197\n",
      "Epoch 7616, Loss: 208.67637988263863, Neurons: 201, Grad norm: 2.1590435692460277\n",
      "Epoch 7616, Loss: 208.67637988263863, Neurons: 201, Grad norm: 2.1590435692460277\n",
      "Epoch 7617, Loss: 208.67630896713837, Neurons: 201, Grad norm: 1.8433700266638853\n",
      "Epoch 7617, Loss: 208.67630896713837, Neurons: 201, Grad norm: 1.8433700266638853\n",
      "Epoch 7618, Loss: 208.67623141576036, Neurons: 201, Grad norm: 1.4866713648014\n",
      "Epoch 7618, Loss: 208.67623141576036, Neurons: 201, Grad norm: 1.4866713648014\n",
      "Epoch 7619, Loss: 208.67610172745674, Neurons: 201, Grad norm: 1.4923878373478994\n",
      "Epoch 7619, Loss: 208.67610172745674, Neurons: 201, Grad norm: 1.4923878373478994\n",
      "Epoch 7620, Loss: 208.67603828800796, Neurons: 201, Grad norm: 1.4331455625688432\n",
      "Epoch 7620, Loss: 208.67603828800796, Neurons: 201, Grad norm: 1.4331455625688432\n",
      "Epoch 7621, Loss: 208.67595687218918, Neurons: 201, Grad norm: 1.5456509206678122\n",
      "Epoch 7621, Loss: 208.67595687218918, Neurons: 201, Grad norm: 1.5456509206678122\n",
      "Epoch 7622, Loss: 208.6759043426379, Neurons: 201, Grad norm: 1.739365952646886\n",
      "Epoch 7622, Loss: 208.6759043426379, Neurons: 201, Grad norm: 1.739365952646886\n",
      "Epoch 7623, Loss: 208.67582656380182, Neurons: 201, Grad norm: 1.9205688894301456\n",
      "Epoch 7623, Loss: 208.67582656380182, Neurons: 201, Grad norm: 1.9205688894301456\n",
      "Epoch 7624, Loss: 208.67575042950858, Neurons: 201, Grad norm: 2.3589260576839965\n",
      "Epoch 7624, Loss: 208.67575042950858, Neurons: 201, Grad norm: 2.3589260576839965\n",
      "Epoch 7625, Loss: 208.67572892461914, Neurons: 201, Grad norm: 2.9184807123388223\n",
      "Epoch 7625, Loss: 208.67572892461914, Neurons: 201, Grad norm: 2.9184807123388223\n",
      "Epoch 7626, Loss: 208.6756741143177, Neurons: 201, Grad norm: 3.4674133515909\n",
      "Epoch 7626, Loss: 208.6756741143177, Neurons: 201, Grad norm: 3.4674133515909\n",
      "Epoch 7627, Loss: 208.67564198521774, Neurons: 201, Grad norm: 4.1383578338669995\n",
      "Epoch 7627, Loss: 208.67564198521774, Neurons: 201, Grad norm: 4.1383578338669995\n",
      "Epoch 7628, Loss: 208.67560375678548, Neurons: 201, Grad norm: 4.749871041729088\n",
      "Epoch 7628, Loss: 208.67560375678548, Neurons: 201, Grad norm: 4.749871041729088\n",
      "Epoch 7629, Loss: 208.67562463242433, Neurons: 201, Grad norm: 5.722115092659329\n",
      "Epoch 7629, Loss: 208.67562463242433, Neurons: 201, Grad norm: 5.722115092659329\n",
      "Epoch 7630, Loss: 208.67565663277625, Neurons: 201, Grad norm: 6.394231722181325\n",
      "Epoch 7630, Loss: 208.67565663277625, Neurons: 201, Grad norm: 6.394231722181325\n",
      "Epoch 7631, Loss: 208.67569252498456, Neurons: 201, Grad norm: 7.136850586153449\n",
      "Epoch 7631, Loss: 208.67569252498456, Neurons: 201, Grad norm: 7.136850586153449\n",
      "Epoch 7632, Loss: 208.67575133203886, Neurons: 201, Grad norm: 7.598718676369161\n",
      "Epoch 7632, Loss: 208.67575133203886, Neurons: 201, Grad norm: 7.598718676369161\n",
      "Epoch 7633, Loss: 208.67575807825273, Neurons: 201, Grad norm: 7.5582665729048015\n",
      "Epoch 7633, Loss: 208.67575807825273, Neurons: 201, Grad norm: 7.5582665729048015\n",
      "Epoch 7634, Loss: 208.6756819789249, Neurons: 201, Grad norm: 7.100828167365142\n",
      "Epoch 7634, Loss: 208.6756819789249, Neurons: 201, Grad norm: 7.100828167365142\n",
      "Epoch 7635, Loss: 208.6755795929815, Neurons: 201, Grad norm: 6.040913363796382\n",
      "Epoch 7635, Loss: 208.6755795929815, Neurons: 201, Grad norm: 6.040913363796382\n",
      "Epoch 7636, Loss: 208.67538513401394, Neurons: 201, Grad norm: 4.185140523868115\n",
      "Epoch 7636, Loss: 208.67538513401394, Neurons: 201, Grad norm: 4.185140523868115\n",
      "Epoch 7637, Loss: 208.67509056387246, Neurons: 201, Grad norm: 1.8886210289807503\n",
      "Epoch 7637, Loss: 208.67509056387246, Neurons: 201, Grad norm: 1.8886210289807503\n",
      "Epoch 7638, Loss: 208.6748755556817, Neurons: 201, Grad norm: 0.827922285398864\n",
      "Epoch 7638, Loss: 208.6748755556817, Neurons: 201, Grad norm: 0.827922285398864\n",
      "Epoch 7639, Loss: 208.67477114477325, Neurons: 201, Grad norm: 2.6073450510578002\n",
      "Epoch 7639, Loss: 208.67477114477325, Neurons: 201, Grad norm: 2.6073450510578002\n",
      "Epoch 7640, Loss: 208.67477910440604, Neurons: 201, Grad norm: 4.314449869679859\n",
      "Epoch 7640, Loss: 208.67477910440604, Neurons: 201, Grad norm: 4.314449869679859\n",
      "Epoch 7641, Loss: 208.6748461254105, Neurons: 201, Grad norm: 5.56556839999271\n",
      "Epoch 7641, Loss: 208.6748461254105, Neurons: 201, Grad norm: 5.56556839999271\n",
      "Epoch 7642, Loss: 208.67489475952866, Neurons: 201, Grad norm: 6.529801618600449\n",
      "Epoch 7642, Loss: 208.67489475952866, Neurons: 201, Grad norm: 6.529801618600449\n",
      "Epoch 7643, Loss: 208.67485036447877, Neurons: 201, Grad norm: 6.666850362100722\n",
      "Epoch 7643, Loss: 208.67485036447877, Neurons: 201, Grad norm: 6.666850362100722\n",
      "Epoch 7644, Loss: 208.6747172376918, Neurons: 201, Grad norm: 6.717287508626186\n",
      "Epoch 7644, Loss: 208.6747172376918, Neurons: 201, Grad norm: 6.717287508626186\n",
      "Epoch 7645, Loss: 208.6745752445242, Neurons: 201, Grad norm: 6.5803722912131555\n",
      "Epoch 7645, Loss: 208.6745752445242, Neurons: 201, Grad norm: 6.5803722912131555\n",
      "Epoch 7646, Loss: 208.67446520092895, Neurons: 201, Grad norm: 6.2324692052691555\n",
      "Epoch 7646, Loss: 208.67446520092895, Neurons: 201, Grad norm: 6.2324692052691555\n",
      "Epoch 7647, Loss: 208.6743512529458, Neurons: 201, Grad norm: 5.415009579066556\n",
      "Epoch 7647, Loss: 208.6743512529458, Neurons: 201, Grad norm: 5.415009579066556\n",
      "Epoch 7648, Loss: 208.67410934754037, Neurons: 201, Grad norm: 4.6146781458454305\n",
      "Epoch 7648, Loss: 208.67410934754037, Neurons: 201, Grad norm: 4.6146781458454305\n",
      "Epoch 7649, Loss: 208.6738349074833, Neurons: 201, Grad norm: 3.6155523890810644\n",
      "Epoch 7649, Loss: 208.6738349074833, Neurons: 201, Grad norm: 3.6155523890810644\n",
      "Epoch 7650, Loss: 208.67365495771514, Neurons: 201, Grad norm: 2.487168676710735\n",
      "Epoch 7650, Loss: 208.67365495771514, Neurons: 201, Grad norm: 2.487168676710735\n",
      "Epoch 7651, Loss: 208.67341330696163, Neurons: 201, Grad norm: 1.516189256930426\n",
      "Epoch 7651, Loss: 208.67341330696163, Neurons: 201, Grad norm: 1.516189256930426\n",
      "Epoch 7652, Loss: 208.6732800286084, Neurons: 201, Grad norm: 0.7010231325188221\n",
      "Epoch 7652, Loss: 208.6732800286084, Neurons: 201, Grad norm: 0.7010231325188221\n",
      "Epoch 7653, Loss: 208.6731805401182, Neurons: 201, Grad norm: 0.6891112371892086\n",
      "Epoch 7653, Loss: 208.6731805401182, Neurons: 201, Grad norm: 0.6891112371892086\n",
      "Epoch 7654, Loss: 208.6730299756926, Neurons: 201, Grad norm: 1.1885783069148386\n",
      "Epoch 7654, Loss: 208.6730299756926, Neurons: 201, Grad norm: 1.1885783069148386\n",
      "Epoch 7655, Loss: 208.67297559113743, Neurons: 201, Grad norm: 1.9906801669416643\n",
      "Epoch 7655, Loss: 208.67297559113743, Neurons: 201, Grad norm: 1.9906801669416643\n",
      "Epoch 7656, Loss: 208.67293074009956, Neurons: 201, Grad norm: 2.625288006594347\n",
      "Epoch 7656, Loss: 208.67293074009956, Neurons: 201, Grad norm: 2.625288006594347\n",
      "Epoch 7657, Loss: 208.67285583702434, Neurons: 201, Grad norm: 3.675335252700441\n",
      "Epoch 7657, Loss: 208.67285583702434, Neurons: 201, Grad norm: 3.675335252700441\n",
      "Epoch 7658, Loss: 208.6728509591698, Neurons: 201, Grad norm: 4.606952871978972\n",
      "Epoch 7658, Loss: 208.6728509591698, Neurons: 201, Grad norm: 4.606952871978972\n",
      "Epoch 7659, Loss: 208.672837302101, Neurons: 201, Grad norm: 6.229368118127124\n",
      "Epoch 7659, Loss: 208.672837302101, Neurons: 201, Grad norm: 6.229368118127124\n",
      "Epoch 7660, Loss: 208.67287866680803, Neurons: 201, Grad norm: 7.146644973343217\n",
      "Epoch 7660, Loss: 208.67287866680803, Neurons: 201, Grad norm: 7.146644973343217\n",
      "Epoch 7661, Loss: 208.67294767116803, Neurons: 201, Grad norm: 8.406523420518424\n",
      "Epoch 7661, Loss: 208.67294767116803, Neurons: 201, Grad norm: 8.406523420518424\n",
      "Epoch 7662, Loss: 208.67292860266534, Neurons: 201, Grad norm: 9.41981176627655\n",
      "Epoch 7662, Loss: 208.67292860266534, Neurons: 201, Grad norm: 9.41981176627655\n",
      "Epoch 7663, Loss: 208.6729110964831, Neurons: 201, Grad norm: 9.982174366394187\n",
      "Epoch 7663, Loss: 208.6729110964831, Neurons: 201, Grad norm: 9.982174366394187\n",
      "Epoch 7664, Loss: 208.6727377995977, Neurons: 201, Grad norm: 10.367521866917109\n",
      "Epoch 7664, Loss: 208.6727377995977, Neurons: 201, Grad norm: 10.367521866917109\n",
      "Epoch 7665, Loss: 208.67259176298097, Neurons: 201, Grad norm: 9.973465857550384\n",
      "Epoch 7665, Loss: 208.67259176298097, Neurons: 201, Grad norm: 9.973465857550384\n",
      "Epoch 7666, Loss: 208.67231609812725, Neurons: 201, Grad norm: 9.64664800489362\n",
      "Epoch 7666, Loss: 208.67231609812725, Neurons: 201, Grad norm: 9.64664800489362\n",
      "Epoch 7667, Loss: 208.67201275950225, Neurons: 201, Grad norm: 8.994173421628789\n",
      "Epoch 7667, Loss: 208.67201275950225, Neurons: 201, Grad norm: 8.994173421628789\n",
      "Epoch 7668, Loss: 208.67162838394634, Neurons: 201, Grad norm: 7.884045952218246\n",
      "Epoch 7668, Loss: 208.67162838394634, Neurons: 201, Grad norm: 7.884045952218246\n",
      "Epoch 7669, Loss: 208.67121486997036, Neurons: 201, Grad norm: 6.877209364886038\n",
      "Epoch 7669, Loss: 208.67121486997036, Neurons: 201, Grad norm: 6.877209364886038\n",
      "Epoch 7670, Loss: 208.670804705046, Neurons: 201, Grad norm: 5.758248354924447\n",
      "Epoch 7670, Loss: 208.670804705046, Neurons: 201, Grad norm: 5.758248354924447\n",
      "Epoch 7671, Loss: 208.67046350277124, Neurons: 201, Grad norm: 4.718093294890071\n",
      "Epoch 7671, Loss: 208.67046350277124, Neurons: 201, Grad norm: 4.718093294890071\n",
      "Epoch 7672, Loss: 208.67010068497154, Neurons: 201, Grad norm: 3.427193403095122\n",
      "Epoch 7672, Loss: 208.67010068497154, Neurons: 201, Grad norm: 3.427193403095122\n",
      "Epoch 7673, Loss: 208.66980734998788, Neurons: 201, Grad norm: 2.364265011538482\n",
      "Epoch 7673, Loss: 208.66980734998788, Neurons: 201, Grad norm: 2.364265011538482\n",
      "Epoch 7674, Loss: 208.66951328544084, Neurons: 201, Grad norm: 1.0519650985361406\n",
      "Epoch 7674, Loss: 208.66951328544084, Neurons: 201, Grad norm: 1.0519650985361406\n",
      "Epoch 7675, Loss: 208.66927288827233, Neurons: 201, Grad norm: 0.7682583266884323\n",
      "Epoch 7675, Loss: 208.66927288827233, Neurons: 201, Grad norm: 0.7682583266884323\n",
      "Epoch 7676, Loss: 208.66909483419263, Neurons: 201, Grad norm: 0.9427125351077469\n",
      "Epoch 7676, Loss: 208.66909483419263, Neurons: 201, Grad norm: 0.9427125351077469\n",
      "Epoch 7677, Loss: 208.66887099408297, Neurons: 201, Grad norm: 1.5528769251964003\n",
      "Epoch 7677, Loss: 208.66887099408297, Neurons: 201, Grad norm: 1.5528769251964003\n",
      "Epoch 7678, Loss: 208.66873714836456, Neurons: 201, Grad norm: 2.376749093710813\n",
      "Epoch 7678, Loss: 208.66873714836456, Neurons: 201, Grad norm: 2.376749093710813\n",
      "Epoch 7679, Loss: 208.66858035831854, Neurons: 201, Grad norm: 3.28311277877925\n",
      "Epoch 7679, Loss: 208.66858035831854, Neurons: 201, Grad norm: 3.28311277877925\n",
      "Epoch 7680, Loss: 208.66842370333703, Neurons: 201, Grad norm: 4.3933011933295925\n",
      "Epoch 7680, Loss: 208.66842370333703, Neurons: 201, Grad norm: 4.3933011933295925\n",
      "Epoch 7681, Loss: 208.66837480121083, Neurons: 201, Grad norm: 5.46476659203513\n",
      "Epoch 7681, Loss: 208.66837480121083, Neurons: 201, Grad norm: 5.46476659203513\n",
      "Epoch 7682, Loss: 208.66830929661882, Neurons: 201, Grad norm: 6.783698947475712\n",
      "Epoch 7682, Loss: 208.66830929661882, Neurons: 201, Grad norm: 6.783698947475712\n",
      "Epoch 7683, Loss: 208.66820816226755, Neurons: 201, Grad norm: 7.81815442182629\n",
      "Epoch 7683, Loss: 208.66820816226755, Neurons: 201, Grad norm: 7.81815442182629\n",
      "Epoch 7684, Loss: 208.6682653381428, Neurons: 201, Grad norm: 8.818672416466669\n",
      "Epoch 7684, Loss: 208.6682653381428, Neurons: 201, Grad norm: 8.818672416466669\n",
      "Epoch 7685, Loss: 208.66825703001572, Neurons: 201, Grad norm: 9.573817647541093\n",
      "Epoch 7685, Loss: 208.66825703001572, Neurons: 201, Grad norm: 9.573817647541093\n",
      "Epoch 7686, Loss: 208.66825991611947, Neurons: 201, Grad norm: 10.235600580312488\n",
      "Epoch 7686, Loss: 208.66825991611947, Neurons: 201, Grad norm: 10.235600580312488\n",
      "Epoch 7687, Loss: 208.66834097003166, Neurons: 201, Grad norm: 10.867673018247785\n",
      "Epoch 7687, Loss: 208.66834097003166, Neurons: 201, Grad norm: 10.867673018247785\n",
      "Epoch 7688, Loss: 208.66828866166375, Neurons: 201, Grad norm: 11.666021101140958\n",
      "Epoch 7688, Loss: 208.66828866166375, Neurons: 201, Grad norm: 11.666021101140958\n",
      "Epoch 7689, Loss: 208.66821947963516, Neurons: 201, Grad norm: 12.560622923029065\n",
      "Epoch 7689, Loss: 208.66821947963516, Neurons: 201, Grad norm: 12.560622923029065\n",
      "Epoch 7690, Loss: 208.66831570336532, Neurons: 201, Grad norm: 12.772530257068752\n",
      "Epoch 7690, Loss: 208.66831570336532, Neurons: 201, Grad norm: 12.772530257068752\n",
      "Epoch 7691, Loss: 208.66823364713906, Neurons: 201, Grad norm: 11.765271767540026\n",
      "Epoch 7691, Loss: 208.66823364713906, Neurons: 201, Grad norm: 11.765271767540026\n",
      "Epoch 7692, Loss: 208.66788690448107, Neurons: 201, Grad norm: 9.835968609115598\n",
      "Epoch 7692, Loss: 208.66788690448107, Neurons: 201, Grad norm: 9.835968609115598\n",
      "Epoch 7693, Loss: 208.66731150605213, Neurons: 201, Grad norm: 7.12112068579518\n",
      "Epoch 7693, Loss: 208.66731150605213, Neurons: 201, Grad norm: 7.12112068579518\n",
      "Epoch 7694, Loss: 208.66661890635947, Neurons: 201, Grad norm: 4.057639763370346\n",
      "Epoch 7694, Loss: 208.66661890635947, Neurons: 201, Grad norm: 4.057639763370346\n",
      "Epoch 7695, Loss: 208.66610877806636, Neurons: 201, Grad norm: 1.1238158243641057\n",
      "Epoch 7695, Loss: 208.66610877806636, Neurons: 201, Grad norm: 1.1238158243641057\n",
      "Epoch 7696, Loss: 208.66577880712657, Neurons: 201, Grad norm: 1.8159880442669354\n",
      "Epoch 7696, Loss: 208.66577880712657, Neurons: 201, Grad norm: 1.8159880442669354\n",
      "Epoch 7697, Loss: 208.66566600520696, Neurons: 201, Grad norm: 3.861737589230585\n",
      "Epoch 7697, Loss: 208.66566600520696, Neurons: 201, Grad norm: 3.861737589230585\n",
      "Epoch 7698, Loss: 208.66562168292316, Neurons: 201, Grad norm: 5.298231995899647\n",
      "Epoch 7698, Loss: 208.66562168292316, Neurons: 201, Grad norm: 5.298231995899647\n",
      "Epoch 7699, Loss: 208.6656351157424, Neurons: 201, Grad norm: 6.322714462111469\n",
      "Epoch 7699, Loss: 208.6656351157424, Neurons: 201, Grad norm: 6.322714462111469\n",
      "Epoch 7700, Loss: 208.66566714395927, Neurons: 201, Grad norm: 6.780035056303119\n",
      "Epoch 7700, Loss: 208.66566714395927, Neurons: 201, Grad norm: 6.780035056303119\n",
      "Epoch 7701, Loss: 208.66560073498044, Neurons: 201, Grad norm: 7.404959184508324\n",
      "Epoch 7701, Loss: 208.66560073498044, Neurons: 201, Grad norm: 7.404959184508324\n",
      "Epoch 7702, Loss: 208.66542665222053, Neurons: 201, Grad norm: 7.867436397281023\n",
      "Epoch 7702, Loss: 208.66542665222053, Neurons: 201, Grad norm: 7.867436397281023\n",
      "Epoch 7703, Loss: 208.6653777630636, Neurons: 201, Grad norm: 8.062783201047422\n",
      "Epoch 7703, Loss: 208.6653777630636, Neurons: 201, Grad norm: 8.062783201047422\n",
      "Epoch 7704, Loss: 208.66527427170954, Neurons: 201, Grad norm: 8.18908804978263\n",
      "Epoch 7704, Loss: 208.66527427170954, Neurons: 201, Grad norm: 8.18908804978263\n",
      "Epoch 7705, Loss: 208.66507830066604, Neurons: 201, Grad norm: 7.702867813281519\n",
      "Epoch 7705, Loss: 208.66507830066604, Neurons: 201, Grad norm: 7.702867813281519\n",
      "Epoch 7706, Loss: 208.66492107643074, Neurons: 201, Grad norm: 7.536829603624589\n",
      "Epoch 7706, Loss: 208.66492107643074, Neurons: 201, Grad norm: 7.536829603624589\n",
      "Epoch 7707, Loss: 208.66473757699623, Neurons: 201, Grad norm: 7.633387559692054\n",
      "Epoch 7707, Loss: 208.66473757699623, Neurons: 201, Grad norm: 7.633387559692054\n",
      "Epoch 7708, Loss: 208.66450887071403, Neurons: 201, Grad norm: 8.1294078360728\n",
      "Epoch 7708, Loss: 208.66450887071403, Neurons: 201, Grad norm: 8.1294078360728\n",
      "Epoch 7709, Loss: 208.66442180317384, Neurons: 201, Grad norm: 8.674062801494777\n",
      "Epoch 7709, Loss: 208.66442180317384, Neurons: 201, Grad norm: 8.674062801494777\n",
      "Epoch 7710, Loss: 208.66434360089414, Neurons: 201, Grad norm: 8.109981841567823\n",
      "Epoch 7710, Loss: 208.66434360089414, Neurons: 201, Grad norm: 8.109981841567823\n",
      "Epoch 7711, Loss: 208.6641221361805, Neurons: 201, Grad norm: 7.201764177069021\n",
      "Epoch 7711, Loss: 208.6641221361805, Neurons: 201, Grad norm: 7.201764177069021\n",
      "Epoch 7712, Loss: 208.6638104915133, Neurons: 201, Grad norm: 6.020668876016675\n",
      "Epoch 7712, Loss: 208.6638104915133, Neurons: 201, Grad norm: 6.020668876016675\n",
      "Epoch 7713, Loss: 208.6634729973056, Neurons: 201, Grad norm: 5.032370808984211\n",
      "Epoch 7713, Loss: 208.6634729973056, Neurons: 201, Grad norm: 5.032370808984211\n",
      "Epoch 7714, Loss: 208.6632083299164, Neurons: 201, Grad norm: 4.789152745281307\n",
      "Epoch 7714, Loss: 208.6632083299164, Neurons: 201, Grad norm: 4.789152745281307\n",
      "Epoch 7715, Loss: 208.6630433653505, Neurons: 201, Grad norm: 4.445832832355528\n",
      "Epoch 7715, Loss: 208.6630433653505, Neurons: 201, Grad norm: 4.445832832355528\n",
      "Epoch 7716, Loss: 208.6628808614254, Neurons: 201, Grad norm: 4.089406687469471\n",
      "Epoch 7716, Loss: 208.6628808614254, Neurons: 201, Grad norm: 4.089406687469471\n",
      "Epoch 7717, Loss: 208.66279045734768, Neurons: 201, Grad norm: 3.5311966496534457\n",
      "Epoch 7717, Loss: 208.66279045734768, Neurons: 201, Grad norm: 3.5311966496534457\n",
      "Epoch 7718, Loss: 208.6625820705394, Neurons: 201, Grad norm: 2.740688275651909\n",
      "Epoch 7718, Loss: 208.6625820705394, Neurons: 201, Grad norm: 2.740688275651909\n",
      "Epoch 7719, Loss: 208.66242223828766, Neurons: 201, Grad norm: 2.7467259650530775\n",
      "Epoch 7719, Loss: 208.66242223828766, Neurons: 201, Grad norm: 2.7467259650530775\n",
      "Epoch 7720, Loss: 208.6623243239112, Neurons: 201, Grad norm: 2.742001048875197\n",
      "Epoch 7720, Loss: 208.6623243239112, Neurons: 201, Grad norm: 2.742001048875197\n",
      "Epoch 7721, Loss: 208.66221492837857, Neurons: 201, Grad norm: 3.02850274402672\n",
      "Epoch 7721, Loss: 208.66221492837857, Neurons: 201, Grad norm: 3.02850274402672\n",
      "Epoch 7722, Loss: 208.6621199643123, Neurons: 201, Grad norm: 3.489371479205769\n",
      "Epoch 7722, Loss: 208.6621199643123, Neurons: 201, Grad norm: 3.489371479205769\n",
      "Epoch 7723, Loss: 208.66201460956879, Neurons: 201, Grad norm: 4.058935515825931\n",
      "Epoch 7723, Loss: 208.66201460956879, Neurons: 201, Grad norm: 4.058935515825931\n",
      "Epoch 7724, Loss: 208.6619283839257, Neurons: 201, Grad norm: 4.849465400035039\n",
      "Epoch 7724, Loss: 208.6619283839257, Neurons: 201, Grad norm: 4.849465400035039\n",
      "Epoch 7725, Loss: 208.66192550171692, Neurons: 201, Grad norm: 5.849700506491883\n",
      "Epoch 7725, Loss: 208.66192550171692, Neurons: 201, Grad norm: 5.849700506491883\n",
      "Epoch 7726, Loss: 208.661951185311, Neurons: 201, Grad norm: 7.312015985945588\n",
      "Epoch 7726, Loss: 208.661951185311, Neurons: 201, Grad norm: 7.312015985945588\n",
      "Epoch 7727, Loss: 208.66201017584595, Neurons: 201, Grad norm: 9.133943290669897\n",
      "Epoch 7727, Loss: 208.66201017584595, Neurons: 201, Grad norm: 9.133943290669897\n",
      "Epoch 7728, Loss: 208.6621253298395, Neurons: 201, Grad norm: 10.921454930399829\n",
      "Epoch 7728, Loss: 208.6621253298395, Neurons: 201, Grad norm: 10.921454930399829\n",
      "Epoch 7729, Loss: 208.66247574736028, Neurons: 201, Grad norm: 13.500455559782182\n",
      "Epoch 7729, Loss: 208.66247574736028, Neurons: 201, Grad norm: 13.500455559782182\n",
      "Epoch 7730, Loss: 208.66292730157195, Neurons: 201, Grad norm: 15.256224974206154\n",
      "Epoch 7730, Loss: 208.66292730157195, Neurons: 201, Grad norm: 15.256224974206154\n",
      "Epoch 7731, Loss: 208.6635734556047, Neurons: 201, Grad norm: 16.644491703910003\n",
      "Epoch 7731, Loss: 208.6635734556047, Neurons: 201, Grad norm: 16.644491703910003\n",
      "Epoch 7732, Loss: 208.66390289251427, Neurons: 201, Grad norm: 16.707239906926787\n",
      "Epoch 7732, Loss: 208.66390289251427, Neurons: 201, Grad norm: 16.707239906926787\n",
      "Epoch 7733, Loss: 208.66392416412452, Neurons: 201, Grad norm: 15.400654929685624\n",
      "Epoch 7733, Loss: 208.66392416412452, Neurons: 201, Grad norm: 15.400654929685624\n",
      "Epoch 7734, Loss: 208.6633962307386, Neurons: 201, Grad norm: 12.547534464373816\n",
      "Epoch 7734, Loss: 208.6633962307386, Neurons: 201, Grad norm: 12.547534464373816\n",
      "Epoch 7735, Loss: 208.662357090178, Neurons: 201, Grad norm: 8.326271584866502\n",
      "Epoch 7735, Loss: 208.662357090178, Neurons: 201, Grad norm: 8.326271584866502\n",
      "Epoch 7736, Loss: 208.66132769941163, Neurons: 201, Grad norm: 3.8059512111499467\n",
      "Epoch 7736, Loss: 208.66132769941163, Neurons: 201, Grad norm: 3.8059512111499467\n",
      "Epoch 7737, Loss: 208.66063062297917, Neurons: 201, Grad norm: 1.226324124878486\n",
      "Epoch 7737, Loss: 208.66063062297917, Neurons: 201, Grad norm: 1.226324124878486\n",
      "Epoch 7738, Loss: 208.6603254795859, Neurons: 201, Grad norm: 5.358560141588659\n",
      "Epoch 7738, Loss: 208.6603254795859, Neurons: 201, Grad norm: 5.358560141588659\n",
      "Epoch 7739, Loss: 208.66052627007505, Neurons: 201, Grad norm: 8.579392800954523\n",
      "Epoch 7739, Loss: 208.66052627007505, Neurons: 201, Grad norm: 8.579392800954523\n",
      "Epoch 7740, Loss: 208.6609343382591, Neurons: 201, Grad norm: 11.021099988059813\n",
      "Epoch 7740, Loss: 208.6609343382591, Neurons: 201, Grad norm: 11.021099988059813\n",
      "Epoch 7741, Loss: 208.66124531609177, Neurons: 201, Grad norm: 12.723434826524088\n",
      "Epoch 7741, Loss: 208.66124531609177, Neurons: 201, Grad norm: 12.723434826524088\n",
      "Epoch 7742, Loss: 208.66173520894645, Neurons: 201, Grad norm: 13.131195198991897\n",
      "Epoch 7742, Loss: 208.66173520894645, Neurons: 201, Grad norm: 13.131195198991897\n",
      "Epoch 7743, Loss: 208.6618148586987, Neurons: 201, Grad norm: 12.324158791370762\n",
      "Epoch 7743, Loss: 208.6618148586987, Neurons: 201, Grad norm: 12.324158791370762\n",
      "Epoch 7744, Loss: 208.66142438795308, Neurons: 201, Grad norm: 10.093766018046267\n",
      "Epoch 7744, Loss: 208.66142438795308, Neurons: 201, Grad norm: 10.093766018046267\n",
      "Epoch 7745, Loss: 208.66076519539456, Neurons: 201, Grad norm: 6.505881075093757\n",
      "Epoch 7745, Loss: 208.66076519539456, Neurons: 201, Grad norm: 6.505881075093757\n",
      "Epoch 7746, Loss: 208.66003379403557, Neurons: 201, Grad norm: 2.4220577042916327\n",
      "Epoch 7746, Loss: 208.66003379403557, Neurons: 201, Grad norm: 2.4220577042916327\n",
      "Epoch 7747, Loss: 208.65955453584024, Neurons: 201, Grad norm: 1.5882323882732263\n",
      "Epoch 7747, Loss: 208.65955453584024, Neurons: 201, Grad norm: 1.5882323882732263\n",
      "Epoch 7748, Loss: 208.65945255049087, Neurons: 201, Grad norm: 4.810375497470757\n",
      "Epoch 7748, Loss: 208.65945255049087, Neurons: 201, Grad norm: 4.810375497470757\n",
      "Epoch 7749, Loss: 208.65957554774147, Neurons: 201, Grad norm: 7.08192026147837\n",
      "Epoch 7749, Loss: 208.65957554774147, Neurons: 201, Grad norm: 7.08192026147837\n",
      "Epoch 7750, Loss: 208.65976473661277, Neurons: 201, Grad norm: 8.018424518325618\n",
      "Epoch 7750, Loss: 208.65976473661277, Neurons: 201, Grad norm: 8.018424518325618\n",
      "Epoch 7751, Loss: 208.6599321851107, Neurons: 201, Grad norm: 8.891124467739237\n",
      "Epoch 7751, Loss: 208.6599321851107, Neurons: 201, Grad norm: 8.891124467739237\n",
      "Epoch 7752, Loss: 208.6599259427015, Neurons: 201, Grad norm: 8.311656921571913\n",
      "Epoch 7752, Loss: 208.6599259427015, Neurons: 201, Grad norm: 8.311656921571913\n",
      "Epoch 7753, Loss: 208.65975557674432, Neurons: 201, Grad norm: 7.231967943292976\n",
      "Epoch 7753, Loss: 208.65975557674432, Neurons: 201, Grad norm: 7.231967943292976\n",
      "Epoch 7754, Loss: 208.65944488946235, Neurons: 201, Grad norm: 5.444683695102691\n",
      "Epoch 7754, Loss: 208.65944488946235, Neurons: 201, Grad norm: 5.444683695102691\n",
      "Epoch 7755, Loss: 208.65912449761012, Neurons: 201, Grad norm: 2.9407631115658304\n",
      "Epoch 7755, Loss: 208.65912449761012, Neurons: 201, Grad norm: 2.9407631115658304\n",
      "Epoch 7756, Loss: 208.65880370661012, Neurons: 201, Grad norm: 0.4353608800463842\n",
      "Epoch 7756, Loss: 208.65880370661012, Neurons: 201, Grad norm: 0.4353608800463842\n",
      "Epoch 7757, Loss: 208.65862876615654, Neurons: 201, Grad norm: 2.7061461588789077\n",
      "Epoch 7757, Loss: 208.65862876615654, Neurons: 201, Grad norm: 2.7061461588789077\n",
      "Epoch 7758, Loss: 208.65862961769872, Neurons: 201, Grad norm: 4.659758939697854\n",
      "Epoch 7758, Loss: 208.65862961769872, Neurons: 201, Grad norm: 4.659758939697854\n",
      "Epoch 7759, Loss: 208.65868368252654, Neurons: 201, Grad norm: 6.4825788029526\n",
      "Epoch 7759, Loss: 208.65868368252654, Neurons: 201, Grad norm: 6.4825788029526\n",
      "Epoch 7760, Loss: 208.65878651701038, Neurons: 201, Grad norm: 7.8818174267230106\n",
      "Epoch 7760, Loss: 208.65878651701038, Neurons: 201, Grad norm: 7.8818174267230106\n",
      "Epoch 7761, Loss: 208.65887998976822, Neurons: 201, Grad norm: 9.061035269683924\n",
      "Epoch 7761, Loss: 208.65887998976822, Neurons: 201, Grad norm: 9.061035269683924\n",
      "Epoch 7762, Loss: 208.6591127932342, Neurons: 201, Grad norm: 10.266370988444857\n",
      "Epoch 7762, Loss: 208.6591127932342, Neurons: 201, Grad norm: 10.266370988444857\n",
      "Epoch 7763, Loss: 208.65929418711036, Neurons: 201, Grad norm: 9.839802474595865\n",
      "Epoch 7763, Loss: 208.65929418711036, Neurons: 201, Grad norm: 9.839802474595865\n",
      "Epoch 7764, Loss: 208.6592669129834, Neurons: 201, Grad norm: 8.787112538897524\n",
      "Epoch 7764, Loss: 208.6592669129834, Neurons: 201, Grad norm: 8.787112538897524\n",
      "Epoch 7765, Loss: 208.6588442015348, Neurons: 201, Grad norm: 6.797140516689467\n",
      "Epoch 7765, Loss: 208.6588442015348, Neurons: 201, Grad norm: 6.797140516689467\n",
      "Epoch 7766, Loss: 208.65841852083713, Neurons: 201, Grad norm: 3.6045370926691223\n",
      "Epoch 7766, Loss: 208.65841852083713, Neurons: 201, Grad norm: 3.6045370926691223\n",
      "Epoch 7767, Loss: 208.6579872958274, Neurons: 201, Grad norm: 0.6714636924723484\n",
      "Epoch 7767, Loss: 208.6579872958274, Neurons: 201, Grad norm: 0.6714636924723484\n",
      "Epoch 7768, Loss: 208.6577456167125, Neurons: 201, Grad norm: 2.936393942747786\n",
      "Epoch 7768, Loss: 208.6577456167125, Neurons: 201, Grad norm: 2.936393942747786\n",
      "Epoch 7769, Loss: 208.65773064841164, Neurons: 201, Grad norm: 5.9326367973405425\n",
      "Epoch 7769, Loss: 208.65773064841164, Neurons: 201, Grad norm: 5.9326367973405425\n",
      "Epoch 7770, Loss: 208.65788101651796, Neurons: 201, Grad norm: 8.6366426683672\n",
      "Epoch 7770, Loss: 208.65788101651796, Neurons: 201, Grad norm: 8.6366426683672\n",
      "Epoch 7771, Loss: 208.65820102105255, Neurons: 201, Grad norm: 11.164871639143428\n",
      "Epoch 7771, Loss: 208.65820102105255, Neurons: 201, Grad norm: 11.164871639143428\n",
      "Epoch 7772, Loss: 208.6586107879077, Neurons: 201, Grad norm: 12.86821440650597\n",
      "Epoch 7772, Loss: 208.6586107879077, Neurons: 201, Grad norm: 12.86821440650597\n",
      "Epoch 7773, Loss: 208.65916508726806, Neurons: 201, Grad norm: 13.693564227465851\n",
      "Epoch 7773, Loss: 208.65916508726806, Neurons: 201, Grad norm: 13.693564227465851\n",
      "Epoch 7774, Loss: 208.65925844826165, Neurons: 201, Grad norm: 12.896730348727914\n",
      "Epoch 7774, Loss: 208.65925844826165, Neurons: 201, Grad norm: 12.896730348727914\n",
      "Epoch 7775, Loss: 208.65897018610497, Neurons: 201, Grad norm: 11.274125859100145\n",
      "Epoch 7775, Loss: 208.65897018610497, Neurons: 201, Grad norm: 11.274125859100145\n",
      "Epoch 7776, Loss: 208.65838140861044, Neurons: 201, Grad norm: 8.95187397011773\n",
      "Epoch 7776, Loss: 208.65838140861044, Neurons: 201, Grad norm: 8.95187397011773\n",
      "Epoch 7777, Loss: 208.6577342866388, Neurons: 201, Grad norm: 5.967418638787901\n",
      "Epoch 7777, Loss: 208.6577342866388, Neurons: 201, Grad norm: 5.967418638787901\n",
      "Epoch 7778, Loss: 208.6572315191806, Neurons: 201, Grad norm: 2.9228077447821903\n",
      "Epoch 7778, Loss: 208.6572315191806, Neurons: 201, Grad norm: 2.9228077447821903\n",
      "Epoch 7779, Loss: 208.65686218788645, Neurons: 201, Grad norm: 0.7448121871168324\n",
      "Epoch 7779, Loss: 208.65686218788645, Neurons: 201, Grad norm: 0.7448121871168324\n",
      "Epoch 7780, Loss: 208.65669624435242, Neurons: 201, Grad norm: 3.324863529521581\n",
      "Epoch 7780, Loss: 208.65669624435242, Neurons: 201, Grad norm: 3.324863529521581\n",
      "Epoch 7781, Loss: 208.65673717590087, Neurons: 201, Grad norm: 5.679081337329463\n",
      "Epoch 7781, Loss: 208.65673717590087, Neurons: 201, Grad norm: 5.679081337329463\n",
      "Epoch 7782, Loss: 208.65688731816766, Neurons: 201, Grad norm: 7.184101076842754\n",
      "Epoch 7782, Loss: 208.65688731816766, Neurons: 201, Grad norm: 7.184101076842754\n",
      "Epoch 7783, Loss: 208.6569961324675, Neurons: 201, Grad norm: 7.60907368880639\n",
      "Epoch 7783, Loss: 208.6569961324675, Neurons: 201, Grad norm: 7.60907368880639\n",
      "Epoch 7784, Loss: 208.65698914257217, Neurons: 201, Grad norm: 7.403502300756298\n",
      "Epoch 7784, Loss: 208.65698914257217, Neurons: 201, Grad norm: 7.403502300756298\n",
      "Epoch 7785, Loss: 208.65685144422386, Neurons: 201, Grad norm: 6.23066620435703\n",
      "Epoch 7785, Loss: 208.65685144422386, Neurons: 201, Grad norm: 6.23066620435703\n",
      "Epoch 7786, Loss: 208.65667310744854, Neurons: 201, Grad norm: 5.000134758604925\n",
      "Epoch 7786, Loss: 208.65667310744854, Neurons: 201, Grad norm: 5.000134758604925\n",
      "Epoch 7787, Loss: 208.65641712495744, Neurons: 201, Grad norm: 3.7179423048739215\n",
      "Epoch 7787, Loss: 208.65641712495744, Neurons: 201, Grad norm: 3.7179423048739215\n",
      "Epoch 7788, Loss: 208.65616827759467, Neurons: 201, Grad norm: 2.2625772244095517\n",
      "Epoch 7788, Loss: 208.65616827759467, Neurons: 201, Grad norm: 2.2625772244095517\n",
      "Epoch 7789, Loss: 208.65603652070283, Neurons: 201, Grad norm: 1.2923308073644988\n",
      "Epoch 7789, Loss: 208.65603652070283, Neurons: 201, Grad norm: 1.2923308073644988\n",
      "Epoch 7790, Loss: 208.6559463703482, Neurons: 201, Grad norm: 1.209077267409152\n",
      "Epoch 7790, Loss: 208.6559463703482, Neurons: 201, Grad norm: 1.209077267409152\n",
      "Epoch 7791, Loss: 208.6558747106977, Neurons: 201, Grad norm: 2.5607507075726543\n",
      "Epoch 7791, Loss: 208.6558747106977, Neurons: 201, Grad norm: 2.5607507075726543\n",
      "Epoch 7792, Loss: 208.65576589883668, Neurons: 201, Grad norm: 3.645108621008149\n",
      "Epoch 7792, Loss: 208.65576589883668, Neurons: 201, Grad norm: 3.645108621008149\n",
      "Epoch 7793, Loss: 208.65574659632767, Neurons: 201, Grad norm: 4.636567702481018\n",
      "Epoch 7793, Loss: 208.65574659632767, Neurons: 201, Grad norm: 4.636567702481018\n",
      "Epoch 7794, Loss: 208.6558003776654, Neurons: 201, Grad norm: 5.374142093173993\n",
      "Epoch 7794, Loss: 208.6558003776654, Neurons: 201, Grad norm: 5.374142093173993\n",
      "Epoch 7795, Loss: 208.65577220857014, Neurons: 201, Grad norm: 5.522270011739878\n",
      "Epoch 7795, Loss: 208.65577220857014, Neurons: 201, Grad norm: 5.522270011739878\n",
      "Epoch 7796, Loss: 208.65572053211693, Neurons: 201, Grad norm: 5.208963795325894\n",
      "Epoch 7796, Loss: 208.65572053211693, Neurons: 201, Grad norm: 5.208963795325894\n",
      "Epoch 7797, Loss: 208.65572004803727, Neurons: 201, Grad norm: 4.866508417904155\n",
      "Epoch 7797, Loss: 208.65572004803727, Neurons: 201, Grad norm: 4.866508417904155\n",
      "Epoch 7798, Loss: 208.6555447385241, Neurons: 201, Grad norm: 4.134538743634715\n",
      "Epoch 7798, Loss: 208.6555447385241, Neurons: 201, Grad norm: 4.134538743634715\n",
      "Epoch 7799, Loss: 208.65545163104355, Neurons: 201, Grad norm: 3.3430405976113384\n",
      "Epoch 7799, Loss: 208.65545163104355, Neurons: 201, Grad norm: 3.3430405976113384\n",
      "Epoch 7800, Loss: 208.65526339306558, Neurons: 201, Grad norm: 2.74584707148398\n",
      "Epoch 7800, Loss: 208.65526339306558, Neurons: 201, Grad norm: 2.74584707148398\n",
      "Epoch 7801, Loss: 208.65506572985993, Neurons: 201, Grad norm: 1.677172414169074\n",
      "Epoch 7801, Loss: 208.65506572985993, Neurons: 201, Grad norm: 1.677172414169074\n",
      "Epoch 7802, Loss: 208.65500360936394, Neurons: 201, Grad norm: 0.6540250229229462\n",
      "Epoch 7802, Loss: 208.65500360936394, Neurons: 201, Grad norm: 0.6540250229229462\n",
      "Epoch 7803, Loss: 208.65486922152976, Neurons: 201, Grad norm: 1.1799155476159062\n",
      "Epoch 7803, Loss: 208.65486922152976, Neurons: 201, Grad norm: 1.1799155476159062\n",
      "Epoch 7804, Loss: 208.65476059948216, Neurons: 201, Grad norm: 2.2987426478046453\n",
      "Epoch 7804, Loss: 208.65476059948216, Neurons: 201, Grad norm: 2.2987426478046453\n",
      "Epoch 7805, Loss: 208.65480450750053, Neurons: 201, Grad norm: 2.934855371544697\n",
      "Epoch 7805, Loss: 208.65480450750053, Neurons: 201, Grad norm: 2.934855371544697\n",
      "Epoch 7806, Loss: 208.65475664114942, Neurons: 201, Grad norm: 3.2904127430805885\n",
      "Epoch 7806, Loss: 208.65475664114942, Neurons: 201, Grad norm: 3.2904127430805885\n",
      "Epoch 7807, Loss: 208.65461722801706, Neurons: 201, Grad norm: 3.380742045401352\n",
      "Epoch 7807, Loss: 208.65461722801706, Neurons: 201, Grad norm: 3.380742045401352\n",
      "Epoch 7808, Loss: 208.65463655791248, Neurons: 201, Grad norm: 3.9790506994949477\n",
      "Epoch 7808, Loss: 208.65463655791248, Neurons: 201, Grad norm: 3.9790506994949477\n",
      "Epoch 7809, Loss: 208.65458149559453, Neurons: 201, Grad norm: 4.7025346504004535\n",
      "Epoch 7809, Loss: 208.65458149559453, Neurons: 201, Grad norm: 4.7025346504004535\n",
      "Epoch 7810, Loss: 208.65451759884232, Neurons: 201, Grad norm: 5.6090635509443345\n",
      "Epoch 7810, Loss: 208.65451759884232, Neurons: 201, Grad norm: 5.6090635509443345\n",
      "Epoch 7811, Loss: 208.65454775791196, Neurons: 201, Grad norm: 6.124050981325721\n",
      "Epoch 7811, Loss: 208.65454775791196, Neurons: 201, Grad norm: 6.124050981325721\n",
      "Epoch 7812, Loss: 208.65452445413183, Neurons: 201, Grad norm: 6.4303397429166\n",
      "Epoch 7812, Loss: 208.65452445413183, Neurons: 201, Grad norm: 6.4303397429166\n",
      "Epoch 7813, Loss: 208.6544982591548, Neurons: 201, Grad norm: 6.325171933515218\n",
      "Epoch 7813, Loss: 208.6544982591548, Neurons: 201, Grad norm: 6.325171933515218\n",
      "Epoch 7814, Loss: 208.6544068924449, Neurons: 201, Grad norm: 6.227934910131087\n",
      "Epoch 7814, Loss: 208.6544068924449, Neurons: 201, Grad norm: 6.227934910131087\n",
      "Epoch 7815, Loss: 208.65435915495127, Neurons: 201, Grad norm: 6.281880420459132\n",
      "Epoch 7815, Loss: 208.65435915495127, Neurons: 201, Grad norm: 6.281880420459132\n",
      "Epoch 7816, Loss: 208.6543603884221, Neurons: 201, Grad norm: 6.39398151709429\n",
      "Epoch 7816, Loss: 208.6543603884221, Neurons: 201, Grad norm: 6.39398151709429\n",
      "Epoch 7817, Loss: 208.65422704797322, Neurons: 201, Grad norm: 6.7272428969874305\n",
      "Epoch 7817, Loss: 208.65422704797322, Neurons: 201, Grad norm: 6.7272428969874305\n",
      "Epoch 7818, Loss: 208.65416939898918, Neurons: 201, Grad norm: 7.176266545157419\n",
      "Epoch 7818, Loss: 208.65416939898918, Neurons: 201, Grad norm: 7.176266545157419\n",
      "Epoch 7819, Loss: 208.65413987751512, Neurons: 201, Grad norm: 7.103482364110953\n",
      "Epoch 7819, Loss: 208.65413987751512, Neurons: 201, Grad norm: 7.103482364110953\n",
      "Epoch 7820, Loss: 208.65407708201678, Neurons: 201, Grad norm: 6.8656130444877395\n",
      "Epoch 7820, Loss: 208.65407708201678, Neurons: 201, Grad norm: 6.8656130444877395\n",
      "Epoch 7821, Loss: 208.65396462862861, Neurons: 201, Grad norm: 6.471599250785792\n",
      "Epoch 7821, Loss: 208.65396462862861, Neurons: 201, Grad norm: 6.471599250785792\n",
      "Epoch 7822, Loss: 208.65387014782166, Neurons: 201, Grad norm: 6.052263346309309\n",
      "Epoch 7822, Loss: 208.65387014782166, Neurons: 201, Grad norm: 6.052263346309309\n",
      "Epoch 7823, Loss: 208.65376275843613, Neurons: 201, Grad norm: 5.371409863793031\n",
      "Epoch 7823, Loss: 208.65376275843613, Neurons: 201, Grad norm: 5.371409863793031\n",
      "Epoch 7824, Loss: 208.6536330501049, Neurons: 201, Grad norm: 4.617499888188382\n",
      "Epoch 7824, Loss: 208.6536330501049, Neurons: 201, Grad norm: 4.617499888188382\n",
      "Epoch 7825, Loss: 208.6534058393631, Neurons: 201, Grad norm: 3.9538794191683095\n",
      "Epoch 7825, Loss: 208.6534058393631, Neurons: 201, Grad norm: 3.9538794191683095\n",
      "Epoch 7826, Loss: 208.6532548592949, Neurons: 201, Grad norm: 3.3543937340994936\n",
      "Epoch 7826, Loss: 208.6532548592949, Neurons: 201, Grad norm: 3.3543937340994936\n",
      "Epoch 7827, Loss: 208.65314507644567, Neurons: 201, Grad norm: 2.4700222738197475\n",
      "Epoch 7827, Loss: 208.65314507644567, Neurons: 201, Grad norm: 2.4700222738197475\n",
      "Epoch 7828, Loss: 208.65301518620797, Neurons: 201, Grad norm: 1.445461726491051\n",
      "Epoch 7828, Loss: 208.65301518620797, Neurons: 201, Grad norm: 1.445461726491051\n",
      "Epoch 7829, Loss: 208.65293663508447, Neurons: 201, Grad norm: 0.5774887595761906\n",
      "Epoch 7829, Loss: 208.65293663508447, Neurons: 201, Grad norm: 0.5774887595761906\n",
      "Epoch 7830, Loss: 208.65279876195285, Neurons: 201, Grad norm: 1.955529131347805\n",
      "Epoch 7830, Loss: 208.65279876195285, Neurons: 201, Grad norm: 1.955529131347805\n",
      "Epoch 7831, Loss: 208.65278707562211, Neurons: 201, Grad norm: 3.230879217384055\n",
      "Epoch 7831, Loss: 208.65278707562211, Neurons: 201, Grad norm: 3.230879217384055\n",
      "Epoch 7832, Loss: 208.65283573132973, Neurons: 201, Grad norm: 4.156553359079678\n",
      "Epoch 7832, Loss: 208.65283573132973, Neurons: 201, Grad norm: 4.156553359079678\n",
      "Epoch 7833, Loss: 208.6527761715198, Neurons: 201, Grad norm: 5.074216096156217\n",
      "Epoch 7833, Loss: 208.6527761715198, Neurons: 201, Grad norm: 5.074216096156217\n",
      "Epoch 7834, Loss: 208.65278547437802, Neurons: 201, Grad norm: 5.980685247695085\n",
      "Epoch 7834, Loss: 208.65278547437802, Neurons: 201, Grad norm: 5.980685247695085\n",
      "Epoch 7835, Loss: 208.65285612452996, Neurons: 201, Grad norm: 7.088955682471004\n",
      "Epoch 7835, Loss: 208.65285612452996, Neurons: 201, Grad norm: 7.088955682471004\n",
      "Epoch 7836, Loss: 208.65294319110657, Neurons: 201, Grad norm: 8.157616243851779\n",
      "Epoch 7836, Loss: 208.65294319110657, Neurons: 201, Grad norm: 8.157616243851779\n",
      "Epoch 7837, Loss: 208.65304262551808, Neurons: 201, Grad norm: 9.320822823816853\n",
      "Epoch 7837, Loss: 208.65304262551808, Neurons: 201, Grad norm: 9.320822823816853\n",
      "Epoch 7838, Loss: 208.65312541998082, Neurons: 201, Grad norm: 10.163043674056285\n",
      "Epoch 7838, Loss: 208.65312541998082, Neurons: 201, Grad norm: 10.163043674056285\n",
      "Epoch 7839, Loss: 208.65327172270653, Neurons: 201, Grad norm: 10.570016348619882\n",
      "Epoch 7839, Loss: 208.65327172270653, Neurons: 201, Grad norm: 10.570016348619882\n",
      "Epoch 7840, Loss: 208.6532812405051, Neurons: 201, Grad norm: 10.113786434512608\n",
      "Epoch 7840, Loss: 208.6532812405051, Neurons: 201, Grad norm: 10.113786434512608\n",
      "Epoch 7841, Loss: 208.6531585138856, Neurons: 201, Grad norm: 9.367260474781933\n",
      "Epoch 7841, Loss: 208.6531585138856, Neurons: 201, Grad norm: 9.367260474781933\n",
      "Epoch 7842, Loss: 208.6529076559455, Neurons: 201, Grad norm: 7.998017794948775\n",
      "Epoch 7842, Loss: 208.6529076559455, Neurons: 201, Grad norm: 7.998017794948775\n",
      "Epoch 7843, Loss: 208.6526154419144, Neurons: 201, Grad norm: 6.593608166896434\n",
      "Epoch 7843, Loss: 208.6526154419144, Neurons: 201, Grad norm: 6.593608166896434\n",
      "Epoch 7844, Loss: 208.6522954484917, Neurons: 201, Grad norm: 5.088414952812643\n",
      "Epoch 7844, Loss: 208.6522954484917, Neurons: 201, Grad norm: 5.088414952812643\n",
      "Epoch 7845, Loss: 208.65203886109066, Neurons: 201, Grad norm: 3.8992871623606855\n",
      "Epoch 7845, Loss: 208.65203886109066, Neurons: 201, Grad norm: 3.8992871623606855\n",
      "Epoch 7846, Loss: 208.65187556032194, Neurons: 201, Grad norm: 2.4635292370052047\n",
      "Epoch 7846, Loss: 208.65187556032194, Neurons: 201, Grad norm: 2.4635292370052047\n",
      "Epoch 7847, Loss: 208.65166424355004, Neurons: 201, Grad norm: 1.1882067833950105\n",
      "Epoch 7847, Loss: 208.65166424355004, Neurons: 201, Grad norm: 1.1882067833950105\n",
      "Epoch 7848, Loss: 208.65149446169548, Neurons: 201, Grad norm: 0.7679739679393512\n",
      "Epoch 7848, Loss: 208.65149446169548, Neurons: 201, Grad norm: 0.7679739679393512\n",
      "Epoch 7849, Loss: 208.65146795729302, Neurons: 201, Grad norm: 1.6668092360476572\n",
      "Epoch 7849, Loss: 208.65146795729302, Neurons: 201, Grad norm: 1.6668092360476572\n",
      "Epoch 7850, Loss: 208.65137747280403, Neurons: 201, Grad norm: 3.167009661933196\n",
      "Epoch 7850, Loss: 208.65137747280403, Neurons: 201, Grad norm: 3.167009661933196\n",
      "Epoch 7851, Loss: 208.65136672868255, Neurons: 201, Grad norm: 3.9278062327277836\n",
      "Epoch 7851, Loss: 208.65136672868255, Neurons: 201, Grad norm: 3.9278062327277836\n",
      "Epoch 7852, Loss: 208.65134902761272, Neurons: 201, Grad norm: 4.841055590686247\n",
      "Epoch 7852, Loss: 208.65134902761272, Neurons: 201, Grad norm: 4.841055590686247\n",
      "Epoch 7853, Loss: 208.6513605848114, Neurons: 201, Grad norm: 5.547995879030542\n",
      "Epoch 7853, Loss: 208.6513605848114, Neurons: 201, Grad norm: 5.547995879030542\n",
      "Epoch 7854, Loss: 208.65135029041727, Neurons: 201, Grad norm: 6.220139112108083\n",
      "Epoch 7854, Loss: 208.65135029041727, Neurons: 201, Grad norm: 6.220139112108083\n",
      "Epoch 7855, Loss: 208.65136269361352, Neurons: 201, Grad norm: 6.410624340166723\n",
      "Epoch 7855, Loss: 208.65136269361352, Neurons: 201, Grad norm: 6.410624340166723\n",
      "Epoch 7856, Loss: 208.65132398789, Neurons: 201, Grad norm: 7.247631851200901\n",
      "Epoch 7856, Loss: 208.65132398789, Neurons: 201, Grad norm: 7.247631851200901\n",
      "Epoch 7857, Loss: 208.65137036350538, Neurons: 201, Grad norm: 7.895795899240848\n",
      "Epoch 7857, Loss: 208.65137036350538, Neurons: 201, Grad norm: 7.895795899240848\n",
      "Epoch 7858, Loss: 208.65152190933514, Neurons: 201, Grad norm: 9.01886338698327\n",
      "Epoch 7858, Loss: 208.65152190933514, Neurons: 201, Grad norm: 9.01886338698327\n",
      "Epoch 7859, Loss: 208.65158155607685, Neurons: 201, Grad norm: 10.235451045174324\n",
      "Epoch 7859, Loss: 208.65158155607685, Neurons: 201, Grad norm: 10.235451045174324\n",
      "Epoch 7860, Loss: 208.65178158307708, Neurons: 201, Grad norm: 11.565965723294847\n",
      "Epoch 7860, Loss: 208.65178158307708, Neurons: 201, Grad norm: 11.565965723294847\n",
      "Epoch 7861, Loss: 208.65196125423336, Neurons: 201, Grad norm: 12.395655103436154\n",
      "Epoch 7861, Loss: 208.65196125423336, Neurons: 201, Grad norm: 12.395655103436154\n",
      "Epoch 7862, Loss: 208.65210373846153, Neurons: 201, Grad norm: 12.848648193691908\n",
      "Epoch 7862, Loss: 208.65210373846153, Neurons: 201, Grad norm: 12.848648193691908\n",
      "Epoch 7863, Loss: 208.6521102755425, Neurons: 201, Grad norm: 12.400607489665619\n",
      "Epoch 7863, Loss: 208.6521102755425, Neurons: 201, Grad norm: 12.400607489665619\n",
      "Epoch 7864, Loss: 208.65195259958824, Neurons: 201, Grad norm: 11.460466031720886\n",
      "Epoch 7864, Loss: 208.65195259958824, Neurons: 201, Grad norm: 11.460466031720886\n",
      "Epoch 7865, Loss: 208.65162883028984, Neurons: 201, Grad norm: 10.171568045776509\n",
      "Epoch 7865, Loss: 208.65162883028984, Neurons: 201, Grad norm: 10.171568045776509\n",
      "Epoch 7866, Loss: 208.65137697592834, Neurons: 201, Grad norm: 9.27567896521126\n",
      "Epoch 7866, Loss: 208.65137697592834, Neurons: 201, Grad norm: 9.27567896521126\n",
      "Epoch 7867, Loss: 208.65107911703888, Neurons: 201, Grad norm: 8.129134326738559\n",
      "Epoch 7867, Loss: 208.65107911703888, Neurons: 201, Grad norm: 8.129134326738559\n",
      "Epoch 7868, Loss: 208.6508239218216, Neurons: 201, Grad norm: 8.115447868018538\n",
      "Epoch 7868, Loss: 208.6508239218216, Neurons: 201, Grad norm: 8.115447868018538\n",
      "Epoch 7869, Loss: 208.6505343820402, Neurons: 201, Grad norm: 8.085112715542769\n",
      "Epoch 7869, Loss: 208.6505343820402, Neurons: 201, Grad norm: 8.085112715542769\n",
      "Epoch 7870, Loss: 208.65048337873017, Neurons: 201, Grad norm: 8.188594754967825\n",
      "Epoch 7870, Loss: 208.65048337873017, Neurons: 201, Grad norm: 8.188594754967825\n",
      "Epoch 7871, Loss: 208.6505474964106, Neurons: 201, Grad norm: 7.768335612914642\n",
      "Epoch 7871, Loss: 208.6505474964106, Neurons: 201, Grad norm: 7.768335612914642\n",
      "Epoch 7872, Loss: 208.65033215251077, Neurons: 201, Grad norm: 6.931424246904526\n",
      "Epoch 7872, Loss: 208.65033215251077, Neurons: 201, Grad norm: 6.931424246904526\n",
      "Epoch 7873, Loss: 208.6500835671193, Neurons: 201, Grad norm: 5.226135065491776\n",
      "Epoch 7873, Loss: 208.6500835671193, Neurons: 201, Grad norm: 5.226135065491776\n",
      "Epoch 7874, Loss: 208.64985310997105, Neurons: 201, Grad norm: 4.000937863763647\n",
      "Epoch 7874, Loss: 208.64985310997105, Neurons: 201, Grad norm: 4.000937863763647\n",
      "Epoch 7875, Loss: 208.6496740010067, Neurons: 201, Grad norm: 2.9810231757618277\n",
      "Epoch 7875, Loss: 208.6496740010067, Neurons: 201, Grad norm: 2.9810231757618277\n",
      "Epoch 7876, Loss: 208.64951027999322, Neurons: 201, Grad norm: 2.3410416118991795\n",
      "Epoch 7876, Loss: 208.64951027999322, Neurons: 201, Grad norm: 2.3410416118991795\n",
      "Epoch 7877, Loss: 208.64933520805099, Neurons: 201, Grad norm: 1.3144037152120933\n",
      "Epoch 7877, Loss: 208.64933520805099, Neurons: 201, Grad norm: 1.3144037152120933\n",
      "Epoch 7878, Loss: 208.64918168192563, Neurons: 201, Grad norm: 1.3100983921805267\n",
      "Epoch 7878, Loss: 208.64918168192563, Neurons: 201, Grad norm: 1.3100983921805267\n",
      "Epoch 7879, Loss: 208.64915205611013, Neurons: 201, Grad norm: 1.1150747997511272\n",
      "Epoch 7879, Loss: 208.64915205611013, Neurons: 201, Grad norm: 1.1150747997511272\n",
      "Epoch 7880, Loss: 208.64907041980473, Neurons: 201, Grad norm: 0.9132822030430423\n",
      "Epoch 7880, Loss: 208.64907041980473, Neurons: 201, Grad norm: 0.9132822030430423\n",
      "Epoch 7881, Loss: 208.6489912659123, Neurons: 201, Grad norm: 0.5810146414799537\n",
      "Epoch 7881, Loss: 208.6489912659123, Neurons: 201, Grad norm: 0.5810146414799537\n",
      "Epoch 7882, Loss: 208.64886566121373, Neurons: 201, Grad norm: 0.7869748762781557\n",
      "Epoch 7882, Loss: 208.64886566121373, Neurons: 201, Grad norm: 0.7869748762781557\n",
      "Epoch 7883, Loss: 208.6487994166387, Neurons: 201, Grad norm: 1.4541641435917922\n",
      "Epoch 7883, Loss: 208.6487994166387, Neurons: 201, Grad norm: 1.4541641435917922\n",
      "Epoch 7884, Loss: 208.64878663476097, Neurons: 201, Grad norm: 1.683984851862563\n",
      "Epoch 7884, Loss: 208.64878663476097, Neurons: 201, Grad norm: 1.683984851862563\n",
      "Epoch 7885, Loss: 208.64870721342643, Neurons: 201, Grad norm: 1.7851862847723121\n",
      "Epoch 7885, Loss: 208.64870721342643, Neurons: 201, Grad norm: 1.7851862847723121\n",
      "Epoch 7886, Loss: 208.64862082325703, Neurons: 201, Grad norm: 1.9079622403863432\n",
      "Epoch 7886, Loss: 208.64862082325703, Neurons: 201, Grad norm: 1.9079622403863432\n",
      "Epoch 7887, Loss: 208.64858437402145, Neurons: 201, Grad norm: 3.0449194463590548\n",
      "Epoch 7887, Loss: 208.64858437402145, Neurons: 201, Grad norm: 3.0449194463590548\n",
      "Epoch 7888, Loss: 208.6485818325412, Neurons: 201, Grad norm: 4.5016213698974505\n",
      "Epoch 7888, Loss: 208.6485818325412, Neurons: 201, Grad norm: 4.5016213698974505\n",
      "Epoch 7889, Loss: 208.64872548920326, Neurons: 201, Grad norm: 6.8739423331689835\n",
      "Epoch 7889, Loss: 208.64872548920326, Neurons: 201, Grad norm: 6.8739423331689835\n",
      "Epoch 7890, Loss: 208.64886189252633, Neurons: 201, Grad norm: 9.34636444713857\n",
      "Epoch 7890, Loss: 208.64886189252633, Neurons: 201, Grad norm: 9.34636444713857\n",
      "Epoch 7891, Loss: 208.649123532221, Neurons: 201, Grad norm: 11.879428868977254\n",
      "Epoch 7891, Loss: 208.649123532221, Neurons: 201, Grad norm: 11.879428868977254\n",
      "Epoch 7892, Loss: 208.64961512099896, Neurons: 201, Grad norm: 13.97474070037599\n",
      "Epoch 7892, Loss: 208.64961512099896, Neurons: 201, Grad norm: 13.97474070037599\n",
      "Epoch 7893, Loss: 208.65018066191465, Neurons: 201, Grad norm: 16.312273181077458\n",
      "Epoch 7893, Loss: 208.65018066191465, Neurons: 201, Grad norm: 16.312273181077458\n",
      "Epoch 7894, Loss: 208.6505408835822, Neurons: 201, Grad norm: 18.267112090097882\n",
      "Epoch 7894, Loss: 208.6505408835822, Neurons: 201, Grad norm: 18.267112090097882\n",
      "Epoch 7895, Loss: 208.65145907231133, Neurons: 201, Grad norm: 20.101687349249133\n",
      "Epoch 7895, Loss: 208.65145907231133, Neurons: 201, Grad norm: 20.101687349249133\n",
      "Epoch 7896, Loss: 208.65241895380112, Neurons: 201, Grad norm: 20.979702808365335\n",
      "Epoch 7896, Loss: 208.65241895380112, Neurons: 201, Grad norm: 20.979702808365335\n",
      "Epoch 7897, Loss: 208.6530474306256, Neurons: 201, Grad norm: 20.622525180126583\n",
      "Epoch 7897, Loss: 208.6530474306256, Neurons: 201, Grad norm: 20.622525180126583\n",
      "Epoch 7898, Loss: 208.6527043712426, Neurons: 201, Grad norm: 18.610571986921457\n",
      "Epoch 7898, Loss: 208.6527043712426, Neurons: 201, Grad norm: 18.610571986921457\n",
      "Epoch 7899, Loss: 208.65152743773933, Neurons: 201, Grad norm: 15.263347299149787\n",
      "Epoch 7899, Loss: 208.65152743773933, Neurons: 201, Grad norm: 15.263347299149787\n",
      "Epoch 7900, Loss: 208.6500708138695, Neurons: 201, Grad norm: 10.302162767321994\n",
      "Epoch 7900, Loss: 208.6500708138695, Neurons: 201, Grad norm: 10.302162767321994\n",
      "Epoch 7901, Loss: 208.64865731382866, Neurons: 201, Grad norm: 4.229498666755805\n",
      "Epoch 7901, Loss: 208.64865731382866, Neurons: 201, Grad norm: 4.229498666755805\n",
      "Epoch 7902, Loss: 208.64765921658721, Neurons: 201, Grad norm: 2.369629461680914\n",
      "Epoch 7902, Loss: 208.64765921658721, Neurons: 201, Grad norm: 2.369629461680914\n",
      "Epoch 7903, Loss: 208.64746334758576, Neurons: 201, Grad norm: 7.775185448152594\n",
      "Epoch 7903, Loss: 208.64746334758576, Neurons: 201, Grad norm: 7.775185448152594\n",
      "Epoch 7904, Loss: 208.6479966596926, Neurons: 201, Grad norm: 12.138457917453431\n",
      "Epoch 7904, Loss: 208.6479966596926, Neurons: 201, Grad norm: 12.138457917453431\n",
      "Epoch 7905, Loss: 208.6486993277285, Neurons: 201, Grad norm: 14.107789721246046\n",
      "Epoch 7905, Loss: 208.6486993277285, Neurons: 201, Grad norm: 14.107789721246046\n",
      "Epoch 7906, Loss: 208.6492963635159, Neurons: 201, Grad norm: 14.542767044639655\n",
      "Epoch 7906, Loss: 208.6492963635159, Neurons: 201, Grad norm: 14.542767044639655\n",
      "Epoch 7907, Loss: 208.6493659531173, Neurons: 201, Grad norm: 12.983476297497251\n",
      "Epoch 7907, Loss: 208.6493659531173, Neurons: 201, Grad norm: 12.983476297497251\n",
      "Epoch 7908, Loss: 208.6489728154597, Neurons: 201, Grad norm: 10.102787760561407\n",
      "Epoch 7908, Loss: 208.6489728154597, Neurons: 201, Grad norm: 10.102787760561407\n",
      "Epoch 7909, Loss: 208.64810574026922, Neurons: 201, Grad norm: 5.9319887284795225\n",
      "Epoch 7909, Loss: 208.64810574026922, Neurons: 201, Grad norm: 5.9319887284795225\n",
      "Epoch 7910, Loss: 208.64726886178704, Neurons: 201, Grad norm: 2.0795928980138516\n",
      "Epoch 7910, Loss: 208.64726886178704, Neurons: 201, Grad norm: 2.0795928980138516\n",
      "Epoch 7911, Loss: 208.64677032501382, Neurons: 201, Grad norm: 2.2269408463691667\n",
      "Epoch 7911, Loss: 208.64677032501382, Neurons: 201, Grad norm: 2.2269408463691667\n",
      "Epoch 7912, Loss: 208.6466849951539, Neurons: 201, Grad norm: 5.246002333847261\n",
      "Epoch 7912, Loss: 208.6466849951539, Neurons: 201, Grad norm: 5.246002333847261\n",
      "Epoch 7913, Loss: 208.64691709743656, Neurons: 201, Grad norm: 8.091365164401747\n",
      "Epoch 7913, Loss: 208.64691709743656, Neurons: 201, Grad norm: 8.091365164401747\n",
      "Epoch 7914, Loss: 208.64722607104758, Neurons: 201, Grad norm: 9.589738947186403\n",
      "Epoch 7914, Loss: 208.64722607104758, Neurons: 201, Grad norm: 9.589738947186403\n",
      "Epoch 7915, Loss: 208.64749016833784, Neurons: 201, Grad norm: 11.342262402335038\n",
      "Epoch 7915, Loss: 208.64749016833784, Neurons: 201, Grad norm: 11.342262402335038\n",
      "Epoch 7916, Loss: 208.64755976055275, Neurons: 201, Grad norm: 12.252837595762548\n",
      "Epoch 7916, Loss: 208.64755976055275, Neurons: 201, Grad norm: 12.252837595762548\n",
      "Epoch 7917, Loss: 208.6477462004602, Neurons: 201, Grad norm: 12.174652348306205\n",
      "Epoch 7917, Loss: 208.6477462004602, Neurons: 201, Grad norm: 12.174652348306205\n",
      "Epoch 7918, Loss: 208.64770688284608, Neurons: 201, Grad norm: 10.618161110489815\n",
      "Epoch 7918, Loss: 208.64770688284608, Neurons: 201, Grad norm: 10.618161110489815\n",
      "Epoch 7919, Loss: 208.64723385961025, Neurons: 201, Grad norm: 7.928158316601793\n",
      "Epoch 7919, Loss: 208.64723385961025, Neurons: 201, Grad norm: 7.928158316601793\n",
      "Epoch 7920, Loss: 208.64658227754086, Neurons: 201, Grad norm: 4.071872059254965\n",
      "Epoch 7920, Loss: 208.64658227754086, Neurons: 201, Grad norm: 4.071872059254965\n",
      "Epoch 7921, Loss: 208.64610104941042, Neurons: 201, Grad norm: 1.6722130650741864\n",
      "Epoch 7921, Loss: 208.64610104941042, Neurons: 201, Grad norm: 1.6722130650741864\n",
      "Epoch 7922, Loss: 208.6458435994777, Neurons: 201, Grad norm: 2.9928047033256457\n",
      "Epoch 7922, Loss: 208.6458435994777, Neurons: 201, Grad norm: 2.9928047033256457\n",
      "Epoch 7923, Loss: 208.64580508230935, Neurons: 201, Grad norm: 4.857301594316146\n",
      "Epoch 7923, Loss: 208.64580508230935, Neurons: 201, Grad norm: 4.857301594316146\n",
      "Epoch 7924, Loss: 208.64583541314343, Neurons: 201, Grad norm: 6.35196944543866\n",
      "Epoch 7924, Loss: 208.64583541314343, Neurons: 201, Grad norm: 6.35196944543866\n",
      "Epoch 7925, Loss: 208.6458037307861, Neurons: 201, Grad norm: 6.713219962716714\n",
      "Epoch 7925, Loss: 208.6458037307861, Neurons: 201, Grad norm: 6.713219962716714\n",
      "Epoch 7926, Loss: 208.6458586383924, Neurons: 201, Grad norm: 7.797303518065862\n",
      "Epoch 7926, Loss: 208.6458586383924, Neurons: 201, Grad norm: 7.797303518065862\n",
      "Epoch 7927, Loss: 208.64594020373445, Neurons: 201, Grad norm: 8.24399511384651\n",
      "Epoch 7927, Loss: 208.64594020373445, Neurons: 201, Grad norm: 8.24399511384651\n",
      "Epoch 7928, Loss: 208.64611796302955, Neurons: 201, Grad norm: 8.924101204145858\n",
      "Epoch 7928, Loss: 208.64611796302955, Neurons: 201, Grad norm: 8.924101204145858\n",
      "Epoch 7929, Loss: 208.6461288026508, Neurons: 201, Grad norm: 9.228743935077233\n",
      "Epoch 7929, Loss: 208.6461288026508, Neurons: 201, Grad norm: 9.228743935077233\n",
      "Epoch 7930, Loss: 208.64602522442905, Neurons: 201, Grad norm: 8.741692828980444\n",
      "Epoch 7930, Loss: 208.64602522442905, Neurons: 201, Grad norm: 8.741692828980444\n",
      "Epoch 7931, Loss: 208.64580549924213, Neurons: 201, Grad norm: 7.742145382998832\n",
      "Epoch 7931, Loss: 208.64580549924213, Neurons: 201, Grad norm: 7.742145382998832\n",
      "Epoch 7932, Loss: 208.64554307935117, Neurons: 201, Grad norm: 6.011794042354904\n",
      "Epoch 7932, Loss: 208.64554307935117, Neurons: 201, Grad norm: 6.011794042354904\n",
      "Epoch 7933, Loss: 208.6452289397593, Neurons: 201, Grad norm: 4.181292632068458\n",
      "Epoch 7933, Loss: 208.6452289397593, Neurons: 201, Grad norm: 4.181292632068458\n",
      "Epoch 7934, Loss: 208.6449587000917, Neurons: 201, Grad norm: 1.7601386927560463\n",
      "Epoch 7934, Loss: 208.6449587000917, Neurons: 201, Grad norm: 1.7601386927560463\n",
      "Epoch 7935, Loss: 208.64472589188668, Neurons: 201, Grad norm: 1.0595851490920685\n",
      "Epoch 7935, Loss: 208.64472589188668, Neurons: 201, Grad norm: 1.0595851490920685\n",
      "Epoch 7936, Loss: 208.64465511764, Neurons: 201, Grad norm: 2.436704894687346\n",
      "Epoch 7936, Loss: 208.64465511764, Neurons: 201, Grad norm: 2.436704894687346\n",
      "Epoch 7937, Loss: 208.64462998669305, Neurons: 201, Grad norm: 3.3183079063478496\n",
      "Epoch 7937, Loss: 208.64462998669305, Neurons: 201, Grad norm: 3.3183079063478496\n",
      "Epoch 7938, Loss: 208.64464098289577, Neurons: 201, Grad norm: 3.850554840008491\n",
      "Epoch 7938, Loss: 208.64464098289577, Neurons: 201, Grad norm: 3.850554840008491\n",
      "Epoch 7939, Loss: 208.6446047414506, Neurons: 201, Grad norm: 3.9687502598100015\n",
      "Epoch 7939, Loss: 208.6446047414506, Neurons: 201, Grad norm: 3.9687502598100015\n",
      "Epoch 7940, Loss: 208.64458013040567, Neurons: 201, Grad norm: 4.085667418865984\n",
      "Epoch 7940, Loss: 208.64458013040567, Neurons: 201, Grad norm: 4.085667418865984\n",
      "Epoch 7941, Loss: 208.6445976669267, Neurons: 201, Grad norm: 4.370524492845573\n",
      "Epoch 7941, Loss: 208.6445976669267, Neurons: 201, Grad norm: 4.370524492845573\n",
      "Epoch 7942, Loss: 208.6446111299912, Neurons: 201, Grad norm: 4.792714838564777\n",
      "Epoch 7942, Loss: 208.6446111299912, Neurons: 201, Grad norm: 4.792714838564777\n",
      "Epoch 7943, Loss: 208.6444567173993, Neurons: 201, Grad norm: 5.092067927986285\n",
      "Epoch 7943, Loss: 208.6444567173993, Neurons: 201, Grad norm: 5.092067927986285\n",
      "Epoch 7944, Loss: 208.64431150705212, Neurons: 201, Grad norm: 5.2632294054337905\n",
      "Epoch 7944, Loss: 208.64431150705212, Neurons: 201, Grad norm: 5.2632294054337905\n",
      "Epoch 7945, Loss: 208.64426380008743, Neurons: 201, Grad norm: 4.487549605321865\n",
      "Epoch 7945, Loss: 208.64426380008743, Neurons: 201, Grad norm: 4.487549605321865\n",
      "Epoch 7946, Loss: 208.64413174941026, Neurons: 201, Grad norm: 3.5317893836085883\n",
      "Epoch 7946, Loss: 208.64413174941026, Neurons: 201, Grad norm: 3.5317893836085883\n",
      "Epoch 7947, Loss: 208.64397173686487, Neurons: 201, Grad norm: 1.6286775953074306\n",
      "Epoch 7947, Loss: 208.64397173686487, Neurons: 201, Grad norm: 1.6286775953074306\n",
      "Epoch 7948, Loss: 208.64379012649704, Neurons: 201, Grad norm: 0.8624303015835897\n",
      "Epoch 7948, Loss: 208.64379012649704, Neurons: 201, Grad norm: 0.8624303015835897\n",
      "Epoch 7949, Loss: 208.6437034484855, Neurons: 201, Grad norm: 1.7854831161332823\n",
      "Epoch 7949, Loss: 208.6437034484855, Neurons: 201, Grad norm: 1.7854831161332823\n",
      "Epoch 7950, Loss: 208.64367356169709, Neurons: 201, Grad norm: 2.772356914984045\n",
      "Epoch 7950, Loss: 208.64367356169709, Neurons: 201, Grad norm: 2.772356914984045\n",
      "Epoch 7951, Loss: 208.64357655956033, Neurons: 201, Grad norm: 3.1361580024150353\n",
      "Epoch 7951, Loss: 208.64357655956033, Neurons: 201, Grad norm: 3.1361580024150353\n",
      "Epoch 7952, Loss: 208.64353843975678, Neurons: 201, Grad norm: 5.105865448983104\n",
      "Epoch 7952, Loss: 208.64353843975678, Neurons: 201, Grad norm: 5.105865448983104\n",
      "Epoch 7953, Loss: 208.64374912396008, Neurons: 201, Grad norm: 7.632204529721082\n",
      "Epoch 7953, Loss: 208.64374912396008, Neurons: 201, Grad norm: 7.632204529721082\n",
      "Epoch 7954, Loss: 208.6441121741045, Neurons: 201, Grad norm: 10.726768868383102\n",
      "Epoch 7954, Loss: 208.6441121741045, Neurons: 201, Grad norm: 10.726768868383102\n",
      "Epoch 7955, Loss: 208.64465113947077, Neurons: 201, Grad norm: 13.108976958636012\n",
      "Epoch 7955, Loss: 208.64465113947077, Neurons: 201, Grad norm: 13.108976958636012\n",
      "Epoch 7956, Loss: 208.64519183258523, Neurons: 201, Grad norm: 15.369052341429102\n",
      "Epoch 7956, Loss: 208.64519183258523, Neurons: 201, Grad norm: 15.369052341429102\n",
      "Epoch 7957, Loss: 208.64554896120174, Neurons: 201, Grad norm: 15.385371001362808\n",
      "Epoch 7957, Loss: 208.64554896120174, Neurons: 201, Grad norm: 15.385371001362808\n",
      "Epoch 7958, Loss: 208.645608531312, Neurons: 201, Grad norm: 14.63126291440476\n",
      "Epoch 7958, Loss: 208.645608531312, Neurons: 201, Grad norm: 14.63126291440476\n",
      "Epoch 7959, Loss: 208.645204946927, Neurons: 201, Grad norm: 12.711800555112411\n",
      "Epoch 7959, Loss: 208.645204946927, Neurons: 201, Grad norm: 12.711800555112411\n",
      "Epoch 7960, Loss: 208.64464614493187, Neurons: 201, Grad norm: 9.356370929225186\n",
      "Epoch 7960, Loss: 208.64464614493187, Neurons: 201, Grad norm: 9.356370929225186\n",
      "Epoch 7961, Loss: 208.6438215335252, Neurons: 201, Grad norm: 5.561839539828192\n",
      "Epoch 7961, Loss: 208.6438215335252, Neurons: 201, Grad norm: 5.561839539828192\n",
      "Epoch 7962, Loss: 208.64314147783185, Neurons: 201, Grad norm: 1.804650103591264\n",
      "Epoch 7962, Loss: 208.64314147783185, Neurons: 201, Grad norm: 1.804650103591264\n",
      "Epoch 7963, Loss: 208.6427934398946, Neurons: 201, Grad norm: 2.302124947767915\n",
      "Epoch 7963, Loss: 208.6427934398946, Neurons: 201, Grad norm: 2.302124947767915\n",
      "Epoch 7964, Loss: 208.6427160951818, Neurons: 201, Grad norm: 5.039083693956087\n",
      "Epoch 7964, Loss: 208.6427160951818, Neurons: 201, Grad norm: 5.039083693956087\n",
      "Epoch 7965, Loss: 208.64286452045488, Neurons: 201, Grad norm: 6.807230789053777\n",
      "Epoch 7965, Loss: 208.64286452045488, Neurons: 201, Grad norm: 6.807230789053777\n",
      "Epoch 7966, Loss: 208.64297521908495, Neurons: 201, Grad norm: 8.25562993189218\n",
      "Epoch 7966, Loss: 208.64297521908495, Neurons: 201, Grad norm: 8.25562993189218\n",
      "Epoch 7967, Loss: 208.64316150888916, Neurons: 201, Grad norm: 9.111687233160094\n",
      "Epoch 7967, Loss: 208.64316150888916, Neurons: 201, Grad norm: 9.111687233160094\n",
      "Epoch 7968, Loss: 208.64330208605824, Neurons: 201, Grad norm: 9.365825731393562\n",
      "Epoch 7968, Loss: 208.64330208605824, Neurons: 201, Grad norm: 9.365825731393562\n",
      "Epoch 7969, Loss: 208.6433627918848, Neurons: 201, Grad norm: 9.545056223559971\n",
      "Epoch 7969, Loss: 208.6433627918848, Neurons: 201, Grad norm: 9.545056223559971\n",
      "Epoch 7970, Loss: 208.6431835243569, Neurons: 201, Grad norm: 9.491491732217716\n",
      "Epoch 7970, Loss: 208.6431835243569, Neurons: 201, Grad norm: 9.491491732217716\n",
      "Epoch 7971, Loss: 208.64295086220127, Neurons: 201, Grad norm: 9.477175334084745\n",
      "Epoch 7971, Loss: 208.64295086220127, Neurons: 201, Grad norm: 9.477175334084745\n",
      "Epoch 7972, Loss: 208.6425681293746, Neurons: 201, Grad norm: 8.5576792456099\n",
      "Epoch 7972, Loss: 208.6425681293746, Neurons: 201, Grad norm: 8.5576792456099\n",
      "Epoch 7973, Loss: 208.64232091803046, Neurons: 201, Grad norm: 7.797363582927352\n",
      "Epoch 7973, Loss: 208.64232091803046, Neurons: 201, Grad norm: 7.797363582927352\n",
      "Epoch 7974, Loss: 208.64196134015415, Neurons: 201, Grad norm: 6.51987419988041\n",
      "Epoch 7974, Loss: 208.64196134015415, Neurons: 201, Grad norm: 6.51987419988041\n",
      "Epoch 7975, Loss: 208.64164790870618, Neurons: 201, Grad norm: 4.861333243393983\n",
      "Epoch 7975, Loss: 208.64164790870618, Neurons: 201, Grad norm: 4.861333243393983\n",
      "Epoch 7976, Loss: 208.64135422553002, Neurons: 201, Grad norm: 3.0744604193914378\n",
      "Epoch 7976, Loss: 208.64135422553002, Neurons: 201, Grad norm: 3.0744604193914378\n",
      "Epoch 7977, Loss: 208.64100748791864, Neurons: 201, Grad norm: 1.533343789901442\n",
      "Epoch 7977, Loss: 208.64100748791864, Neurons: 201, Grad norm: 1.533343789901442\n",
      "Epoch 7978, Loss: 208.6407660736113, Neurons: 201, Grad norm: 1.1075732735488513\n",
      "Epoch 7978, Loss: 208.6407660736113, Neurons: 201, Grad norm: 1.1075732735488513\n",
      "Epoch 7979, Loss: 208.64061004030717, Neurons: 201, Grad norm: 2.685447902032268\n",
      "Epoch 7979, Loss: 208.64061004030717, Neurons: 201, Grad norm: 2.685447902032268\n",
      "Epoch 7980, Loss: 208.6405346945664, Neurons: 201, Grad norm: 4.724838418594973\n",
      "Epoch 7980, Loss: 208.6405346945664, Neurons: 201, Grad norm: 4.724838418594973\n",
      "Epoch 7981, Loss: 208.64061402504424, Neurons: 201, Grad norm: 6.533534359195386\n",
      "Epoch 7981, Loss: 208.64061402504424, Neurons: 201, Grad norm: 6.533534359195386\n",
      "Epoch 7982, Loss: 208.6406830502546, Neurons: 201, Grad norm: 7.886453013550038\n",
      "Epoch 7982, Loss: 208.6406830502546, Neurons: 201, Grad norm: 7.886453013550038\n",
      "Epoch 7983, Loss: 208.64075125873117, Neurons: 201, Grad norm: 8.45215293073461\n",
      "Epoch 7983, Loss: 208.64075125873117, Neurons: 201, Grad norm: 8.45215293073461\n",
      "Epoch 7984, Loss: 208.64079335136887, Neurons: 201, Grad norm: 9.56378670025315\n",
      "Epoch 7984, Loss: 208.64079335136887, Neurons: 201, Grad norm: 9.56378670025315\n",
      "Epoch 7985, Loss: 208.6408496233365, Neurons: 201, Grad norm: 10.176973359479044\n",
      "Epoch 7985, Loss: 208.6408496233365, Neurons: 201, Grad norm: 10.176973359479044\n",
      "Epoch 7986, Loss: 208.6409994266256, Neurons: 201, Grad norm: 10.39963581471264\n",
      "Epoch 7986, Loss: 208.6409994266256, Neurons: 201, Grad norm: 10.39963581471264\n",
      "Epoch 7987, Loss: 208.6409316840944, Neurons: 201, Grad norm: 10.310428735378414\n",
      "Epoch 7987, Loss: 208.6409316840944, Neurons: 201, Grad norm: 10.310428735378414\n",
      "Epoch 7988, Loss: 208.64082686847306, Neurons: 201, Grad norm: 10.216873466546899\n",
      "Epoch 7988, Loss: 208.64082686847306, Neurons: 201, Grad norm: 10.216873466546899\n",
      "Epoch 7989, Loss: 208.64063149292076, Neurons: 201, Grad norm: 10.051774819494456\n",
      "Epoch 7989, Loss: 208.64063149292076, Neurons: 201, Grad norm: 10.051774819494456\n",
      "Epoch 7990, Loss: 208.6406037466613, Neurons: 201, Grad norm: 9.794796142325609\n",
      "Epoch 7990, Loss: 208.6406037466613, Neurons: 201, Grad norm: 9.794796142325609\n",
      "Epoch 7991, Loss: 208.64047951078672, Neurons: 201, Grad norm: 9.11685181659831\n",
      "Epoch 7991, Loss: 208.64047951078672, Neurons: 201, Grad norm: 9.11685181659831\n",
      "Epoch 7992, Loss: 208.64022562670544, Neurons: 201, Grad norm: 7.664462401793721\n",
      "Epoch 7992, Loss: 208.64022562670544, Neurons: 201, Grad norm: 7.664462401793721\n",
      "Epoch 7993, Loss: 208.6398743205856, Neurons: 201, Grad norm: 6.068385340521286\n",
      "Epoch 7993, Loss: 208.6398743205856, Neurons: 201, Grad norm: 6.068385340521286\n",
      "Epoch 7994, Loss: 208.6395444162535, Neurons: 201, Grad norm: 4.280410290796694\n",
      "Epoch 7994, Loss: 208.6395444162535, Neurons: 201, Grad norm: 4.280410290796694\n",
      "Epoch 7995, Loss: 208.63923147423088, Neurons: 201, Grad norm: 2.5327762857574463\n",
      "Epoch 7995, Loss: 208.63923147423088, Neurons: 201, Grad norm: 2.5327762857574463\n",
      "Epoch 7996, Loss: 208.63900917602638, Neurons: 201, Grad norm: 1.028376989788784\n",
      "Epoch 7996, Loss: 208.63900917602638, Neurons: 201, Grad norm: 1.028376989788784\n",
      "Epoch 7997, Loss: 208.6388861027063, Neurons: 201, Grad norm: 1.396126800736598\n",
      "Epoch 7997, Loss: 208.6388861027063, Neurons: 201, Grad norm: 1.396126800736598\n",
      "Epoch 7998, Loss: 208.6388147654554, Neurons: 201, Grad norm: 3.1474294195287964\n",
      "Epoch 7998, Loss: 208.6388147654554, Neurons: 201, Grad norm: 3.1474294195287964\n",
      "Epoch 7999, Loss: 208.63879574824242, Neurons: 201, Grad norm: 5.071347625434401\n",
      "Epoch 7999, Loss: 208.63879574824242, Neurons: 201, Grad norm: 5.071347625434401\n",
      "Epoch 8000, Loss: 208.63889643316725, Neurons: 201, Grad norm: 6.9667664427733555\n",
      "Epoch 8000, Loss: 208.63889643316725, Neurons: 201, Grad norm: 6.9667664427733555\n",
      "Epoch 8001, Loss: 208.63898739948814, Neurons: 201, Grad norm: 8.655651933263096\n",
      "Epoch 8001, Loss: 208.63898739948814, Neurons: 201, Grad norm: 8.655651933263096\n",
      "Epoch 8002, Loss: 208.639121161343, Neurons: 201, Grad norm: 9.726129193975124\n",
      "Epoch 8002, Loss: 208.639121161343, Neurons: 201, Grad norm: 9.726129193975124\n",
      "Epoch 8003, Loss: 208.63927318713846, Neurons: 201, Grad norm: 10.976848553263622\n",
      "Epoch 8003, Loss: 208.63927318713846, Neurons: 201, Grad norm: 10.976848553263622\n",
      "Epoch 8004, Loss: 208.63936218622032, Neurons: 201, Grad norm: 12.364767283032654\n",
      "Epoch 8004, Loss: 208.63936218622032, Neurons: 201, Grad norm: 12.364767283032654\n",
      "Epoch 8005, Loss: 208.63985736111206, Neurons: 201, Grad norm: 13.427684804164052\n",
      "Epoch 8005, Loss: 208.63985736111206, Neurons: 201, Grad norm: 13.427684804164052\n",
      "Epoch 8006, Loss: 208.6402035173215, Neurons: 201, Grad norm: 13.558895484953522\n",
      "Epoch 8006, Loss: 208.6402035173215, Neurons: 201, Grad norm: 13.558895484953522\n",
      "Epoch 8007, Loss: 208.6402442615358, Neurons: 201, Grad norm: 12.92928302946414\n",
      "Epoch 8007, Loss: 208.6402442615358, Neurons: 201, Grad norm: 12.92928302946414\n",
      "Epoch 8008, Loss: 208.64009858736335, Neurons: 201, Grad norm: 11.244472258978986\n",
      "Epoch 8008, Loss: 208.64009858736335, Neurons: 201, Grad norm: 11.244472258978986\n",
      "Epoch 8009, Loss: 208.6395996345932, Neurons: 201, Grad norm: 9.588496737168963\n",
      "Epoch 8009, Loss: 208.6395996345932, Neurons: 201, Grad norm: 9.588496737168963\n",
      "Epoch 8010, Loss: 208.63886678844185, Neurons: 201, Grad norm: 7.639286918651232\n",
      "Epoch 8010, Loss: 208.63886678844185, Neurons: 201, Grad norm: 7.639286918651232\n",
      "Epoch 8011, Loss: 208.63832553900792, Neurons: 201, Grad norm: 5.31283133373678\n",
      "Epoch 8011, Loss: 208.63832553900792, Neurons: 201, Grad norm: 5.31283133373678\n",
      "Epoch 8012, Loss: 208.6380176487401, Neurons: 201, Grad norm: 2.813473156259425\n",
      "Epoch 8012, Loss: 208.6380176487401, Neurons: 201, Grad norm: 2.813473156259425\n",
      "Epoch 8013, Loss: 208.63770507735475, Neurons: 201, Grad norm: 0.7536607394353912\n",
      "Epoch 8013, Loss: 208.63770507735475, Neurons: 201, Grad norm: 0.7536607394353912\n",
      "Epoch 8014, Loss: 208.63748756509708, Neurons: 201, Grad norm: 2.1487704693993237\n",
      "Epoch 8014, Loss: 208.63748756509708, Neurons: 201, Grad norm: 2.1487704693993237\n",
      "Epoch 8015, Loss: 208.63752483877934, Neurons: 201, Grad norm: 3.9308901093699724\n",
      "Epoch 8015, Loss: 208.63752483877934, Neurons: 201, Grad norm: 3.9308901093699724\n",
      "Epoch 8016, Loss: 208.6375588217733, Neurons: 201, Grad norm: 4.705840540059507\n",
      "Epoch 8016, Loss: 208.6375588217733, Neurons: 201, Grad norm: 4.705840540059507\n",
      "Epoch 8017, Loss: 208.6375333333186, Neurons: 201, Grad norm: 5.386495861737684\n",
      "Epoch 8017, Loss: 208.6375333333186, Neurons: 201, Grad norm: 5.386495861737684\n",
      "Epoch 8018, Loss: 208.63748004569604, Neurons: 201, Grad norm: 5.545000097325462\n",
      "Epoch 8018, Loss: 208.63748004569604, Neurons: 201, Grad norm: 5.545000097325462\n",
      "Epoch 8019, Loss: 208.63739352907547, Neurons: 201, Grad norm: 5.669236765237161\n",
      "Epoch 8019, Loss: 208.63739352907547, Neurons: 201, Grad norm: 5.669236765237161\n",
      "Epoch 8020, Loss: 208.6373581944877, Neurons: 201, Grad norm: 6.46054104871643\n",
      "Epoch 8020, Loss: 208.6373581944877, Neurons: 201, Grad norm: 6.46054104871643\n",
      "Epoch 8021, Loss: 208.63735495346916, Neurons: 201, Grad norm: 7.465978053304464\n",
      "Epoch 8021, Loss: 208.63735495346916, Neurons: 201, Grad norm: 7.465978053304464\n",
      "Epoch 8022, Loss: 208.6375307230444, Neurons: 201, Grad norm: 8.992319511620728\n",
      "Epoch 8022, Loss: 208.6375307230444, Neurons: 201, Grad norm: 8.992319511620728\n",
      "Epoch 8023, Loss: 208.63783372053234, Neurons: 201, Grad norm: 10.31324960929122\n",
      "Epoch 8023, Loss: 208.63783372053234, Neurons: 201, Grad norm: 10.31324960929122\n",
      "Epoch 8024, Loss: 208.63820227393376, Neurons: 201, Grad norm: 11.530797169137061\n",
      "Epoch 8024, Loss: 208.63820227393376, Neurons: 201, Grad norm: 11.530797169137061\n",
      "Epoch 8025, Loss: 208.6382302888385, Neurons: 201, Grad norm: 12.308660654374458\n",
      "Epoch 8025, Loss: 208.6382302888385, Neurons: 201, Grad norm: 12.308660654374458\n",
      "Epoch 8026, Loss: 208.63833384526254, Neurons: 201, Grad norm: 13.377849193691437\n",
      "Epoch 8026, Loss: 208.63833384526254, Neurons: 201, Grad norm: 13.377849193691437\n",
      "Epoch 8027, Loss: 208.63835451969658, Neurons: 201, Grad norm: 13.768220037572386\n",
      "Epoch 8027, Loss: 208.63835451969658, Neurons: 201, Grad norm: 13.768220037572386\n",
      "Epoch 8028, Loss: 208.63847317326633, Neurons: 201, Grad norm: 13.124830369690194\n",
      "Epoch 8028, Loss: 208.63847317326633, Neurons: 201, Grad norm: 13.124830369690194\n",
      "Epoch 8029, Loss: 208.63815363354448, Neurons: 201, Grad norm: 11.017641012874167\n",
      "Epoch 8029, Loss: 208.63815363354448, Neurons: 201, Grad norm: 11.017641012874167\n",
      "Epoch 8030, Loss: 208.63757190739494, Neurons: 201, Grad norm: 7.8856787742901275\n",
      "Epoch 8030, Loss: 208.63757190739494, Neurons: 201, Grad norm: 7.8856787742901275\n",
      "Epoch 8031, Loss: 208.63688324257245, Neurons: 201, Grad norm: 4.358028170744883\n",
      "Epoch 8031, Loss: 208.63688324257245, Neurons: 201, Grad norm: 4.358028170744883\n",
      "Epoch 8032, Loss: 208.63649018200192, Neurons: 201, Grad norm: 2.131591159842392\n",
      "Epoch 8032, Loss: 208.63649018200192, Neurons: 201, Grad norm: 2.131591159842392\n",
      "Epoch 8033, Loss: 208.63633272711755, Neurons: 201, Grad norm: 2.446426988084362\n",
      "Epoch 8033, Loss: 208.63633272711755, Neurons: 201, Grad norm: 2.446426988084362\n",
      "Epoch 8034, Loss: 208.6362067513147, Neurons: 201, Grad norm: 4.1891336505280945\n",
      "Epoch 8034, Loss: 208.6362067513147, Neurons: 201, Grad norm: 4.1891336505280945\n",
      "Epoch 8035, Loss: 208.6361070803566, Neurons: 201, Grad norm: 5.944856723409862\n",
      "Epoch 8035, Loss: 208.6361070803566, Neurons: 201, Grad norm: 5.944856723409862\n",
      "Epoch 8036, Loss: 208.63622297680885, Neurons: 201, Grad norm: 7.192027260334321\n",
      "Epoch 8036, Loss: 208.63622297680885, Neurons: 201, Grad norm: 7.192027260334321\n",
      "Epoch 8037, Loss: 208.6364536551611, Neurons: 201, Grad norm: 8.501712247712613\n",
      "Epoch 8037, Loss: 208.6364536551611, Neurons: 201, Grad norm: 8.501712247712613\n",
      "Epoch 8038, Loss: 208.63666553738761, Neurons: 201, Grad norm: 9.41243288071582\n",
      "Epoch 8038, Loss: 208.63666553738761, Neurons: 201, Grad norm: 9.41243288071582\n",
      "Epoch 8039, Loss: 208.6368650299933, Neurons: 201, Grad norm: 9.884115363175592\n",
      "Epoch 8039, Loss: 208.6368650299933, Neurons: 201, Grad norm: 9.884115363175592\n",
      "Epoch 8040, Loss: 208.63675247819683, Neurons: 201, Grad norm: 10.12943212144472\n",
      "Epoch 8040, Loss: 208.63675247819683, Neurons: 201, Grad norm: 10.12943212144472\n",
      "Epoch 8041, Loss: 208.63670728107525, Neurons: 201, Grad norm: 10.449594229236276\n",
      "Epoch 8041, Loss: 208.63670728107525, Neurons: 201, Grad norm: 10.449594229236276\n",
      "Epoch 8042, Loss: 208.6365713971337, Neurons: 201, Grad norm: 10.725756487031916\n",
      "Epoch 8042, Loss: 208.6365713971337, Neurons: 201, Grad norm: 10.725756487031916\n",
      "Epoch 8043, Loss: 208.63655598363715, Neurons: 201, Grad norm: 10.323842225072934\n",
      "Epoch 8043, Loss: 208.63655598363715, Neurons: 201, Grad norm: 10.323842225072934\n",
      "Epoch 8044, Loss: 208.6365338520535, Neurons: 201, Grad norm: 9.16784940746528\n",
      "Epoch 8044, Loss: 208.6365338520535, Neurons: 201, Grad norm: 9.16784940746528\n",
      "Epoch 8045, Loss: 208.63619997930414, Neurons: 201, Grad norm: 6.989714025071077\n",
      "Epoch 8045, Loss: 208.63619997930414, Neurons: 201, Grad norm: 6.989714025071077\n",
      "Epoch 8046, Loss: 208.6357327236033, Neurons: 201, Grad norm: 4.531723021427294\n",
      "Epoch 8046, Loss: 208.6357327236033, Neurons: 201, Grad norm: 4.531723021427294\n",
      "Epoch 8047, Loss: 208.63552235944627, Neurons: 201, Grad norm: 2.645242315928394\n",
      "Epoch 8047, Loss: 208.63552235944627, Neurons: 201, Grad norm: 2.645242315928394\n",
      "Epoch 8048, Loss: 208.63532599857487, Neurons: 201, Grad norm: 1.1373602343727736\n",
      "Epoch 8048, Loss: 208.63532599857487, Neurons: 201, Grad norm: 1.1373602343727736\n",
      "Epoch 8049, Loss: 208.63500879405746, Neurons: 201, Grad norm: 1.3238024572838218\n",
      "Epoch 8049, Loss: 208.63500879405746, Neurons: 201, Grad norm: 1.3238024572838218\n",
      "Epoch 8050, Loss: 208.63497322675667, Neurons: 201, Grad norm: 1.0045530584891331\n",
      "Epoch 8050, Loss: 208.63497322675667, Neurons: 201, Grad norm: 1.0045530584891331\n",
      "Epoch 8051, Loss: 208.6349145933168, Neurons: 201, Grad norm: 0.6871919675010189\n",
      "Epoch 8051, Loss: 208.6349145933168, Neurons: 201, Grad norm: 0.6871919675010189\n",
      "Epoch 8052, Loss: 208.63480864524132, Neurons: 201, Grad norm: 0.5593980752281672\n",
      "Epoch 8052, Loss: 208.63480864524132, Neurons: 201, Grad norm: 0.5593980752281672\n",
      "Epoch 8053, Loss: 208.63464670337814, Neurons: 201, Grad norm: 0.9815479509403574\n",
      "Epoch 8053, Loss: 208.63464670337814, Neurons: 201, Grad norm: 0.9815479509403574\n",
      "Epoch 8054, Loss: 208.634651171231, Neurons: 201, Grad norm: 1.3217962257063571\n",
      "Epoch 8054, Loss: 208.634651171231, Neurons: 201, Grad norm: 1.3217962257063571\n",
      "Epoch 8055, Loss: 208.6345917107699, Neurons: 201, Grad norm: 1.5162727301547192\n",
      "Epoch 8055, Loss: 208.6345917107699, Neurons: 201, Grad norm: 1.5162727301547192\n",
      "Epoch 8056, Loss: 208.63445539939073, Neurons: 201, Grad norm: 2.258866369594516\n",
      "Epoch 8056, Loss: 208.63445539939073, Neurons: 201, Grad norm: 2.258866369594516\n",
      "Epoch 8057, Loss: 208.63442484556415, Neurons: 201, Grad norm: 2.754393653464918\n",
      "Epoch 8057, Loss: 208.63442484556415, Neurons: 201, Grad norm: 2.754393653464918\n",
      "Epoch 8058, Loss: 208.6343995994575, Neurons: 201, Grad norm: 2.897226786926737\n",
      "Epoch 8058, Loss: 208.6343995994575, Neurons: 201, Grad norm: 2.897226786926737\n",
      "Epoch 8059, Loss: 208.6343068673436, Neurons: 201, Grad norm: 3.0821206572283355\n",
      "Epoch 8059, Loss: 208.6343068673436, Neurons: 201, Grad norm: 3.0821206572283355\n",
      "Epoch 8060, Loss: 208.63424608638184, Neurons: 201, Grad norm: 2.84395279468628\n",
      "Epoch 8060, Loss: 208.63424608638184, Neurons: 201, Grad norm: 2.84395279468628\n",
      "Epoch 8061, Loss: 208.6341782881752, Neurons: 201, Grad norm: 2.820889489493209\n",
      "Epoch 8061, Loss: 208.6341782881752, Neurons: 201, Grad norm: 2.820889489493209\n",
      "Epoch 8062, Loss: 208.63403225069274, Neurons: 201, Grad norm: 3.107893997847316\n",
      "Epoch 8062, Loss: 208.63403225069274, Neurons: 201, Grad norm: 3.107893997847316\n",
      "Epoch 8063, Loss: 208.63397984361325, Neurons: 201, Grad norm: 3.737122549777731\n",
      "Epoch 8063, Loss: 208.63397984361325, Neurons: 201, Grad norm: 3.737122549777731\n",
      "Epoch 8064, Loss: 208.6339642774432, Neurons: 201, Grad norm: 3.9078302271803005\n",
      "Epoch 8064, Loss: 208.6339642774432, Neurons: 201, Grad norm: 3.9078302271803005\n",
      "Epoch 8065, Loss: 208.63388744530883, Neurons: 201, Grad norm: 4.691581330623363\n",
      "Epoch 8065, Loss: 208.63388744530883, Neurons: 201, Grad norm: 4.691581330623363\n",
      "Epoch 8066, Loss: 208.63390007034744, Neurons: 201, Grad norm: 5.431903969662271\n",
      "Epoch 8066, Loss: 208.63390007034744, Neurons: 201, Grad norm: 5.431903969662271\n",
      "Epoch 8067, Loss: 208.6338826475186, Neurons: 201, Grad norm: 6.19641480795987\n",
      "Epoch 8067, Loss: 208.6338826475186, Neurons: 201, Grad norm: 6.19641480795987\n",
      "Epoch 8068, Loss: 208.63386396449005, Neurons: 201, Grad norm: 7.267770681372844\n",
      "Epoch 8068, Loss: 208.63386396449005, Neurons: 201, Grad norm: 7.267770681372844\n",
      "Epoch 8069, Loss: 208.6339763486117, Neurons: 201, Grad norm: 9.462425380164666\n",
      "Epoch 8069, Loss: 208.6339763486117, Neurons: 201, Grad norm: 9.462425380164666\n",
      "Epoch 8070, Loss: 208.63432269535951, Neurons: 201, Grad norm: 12.191205603525066\n",
      "Epoch 8070, Loss: 208.63432269535951, Neurons: 201, Grad norm: 12.191205603525066\n",
      "Epoch 8071, Loss: 208.6350802539696, Neurons: 201, Grad norm: 14.784547743188318\n",
      "Epoch 8071, Loss: 208.6350802539696, Neurons: 201, Grad norm: 14.784547743188318\n",
      "Epoch 8072, Loss: 208.63587605985177, Neurons: 201, Grad norm: 16.533568158585698\n",
      "Epoch 8072, Loss: 208.63587605985177, Neurons: 201, Grad norm: 16.533568158585698\n",
      "Epoch 8073, Loss: 208.6363928928389, Neurons: 201, Grad norm: 17.205153259487492\n",
      "Epoch 8073, Loss: 208.6363928928389, Neurons: 201, Grad norm: 17.205153259487492\n",
      "Epoch 8074, Loss: 208.6367032705178, Neurons: 201, Grad norm: 16.74947173952148\n",
      "Epoch 8074, Loss: 208.6367032705178, Neurons: 201, Grad norm: 16.74947173952148\n",
      "Epoch 8075, Loss: 208.63636623058, Neurons: 201, Grad norm: 15.366715480313355\n",
      "Epoch 8075, Loss: 208.63636623058, Neurons: 201, Grad norm: 15.366715480313355\n",
      "Epoch 8076, Loss: 208.63563510953793, Neurons: 201, Grad norm: 12.99375697430424\n",
      "Epoch 8076, Loss: 208.63563510953793, Neurons: 201, Grad norm: 12.99375697430424\n",
      "Epoch 8077, Loss: 208.63487098433455, Neurons: 201, Grad norm: 9.934360324621935\n",
      "Epoch 8077, Loss: 208.63487098433455, Neurons: 201, Grad norm: 9.934360324621935\n",
      "Epoch 8078, Loss: 208.63389091248197, Neurons: 201, Grad norm: 5.939862037723427\n",
      "Epoch 8078, Loss: 208.63389091248197, Neurons: 201, Grad norm: 5.939862037723427\n",
      "Epoch 8079, Loss: 208.6330872320135, Neurons: 201, Grad norm: 2.2461917323173743\n",
      "Epoch 8079, Loss: 208.6330872320135, Neurons: 201, Grad norm: 2.2461917323173743\n",
      "Epoch 8080, Loss: 208.63268583730385, Neurons: 201, Grad norm: 2.9459255210033897\n",
      "Epoch 8080, Loss: 208.63268583730385, Neurons: 201, Grad norm: 2.9459255210033897\n",
      "Epoch 8081, Loss: 208.63257427339744, Neurons: 201, Grad norm: 6.774150309227419\n",
      "Epoch 8081, Loss: 208.63257427339744, Neurons: 201, Grad norm: 6.774150309227419\n",
      "Epoch 8082, Loss: 208.63283186638253, Neurons: 201, Grad norm: 9.865780536953126\n",
      "Epoch 8082, Loss: 208.63283186638253, Neurons: 201, Grad norm: 9.865780536953126\n",
      "Epoch 8083, Loss: 208.63325574924278, Neurons: 201, Grad norm: 12.26967120249531\n",
      "Epoch 8083, Loss: 208.63325574924278, Neurons: 201, Grad norm: 12.26967120249531\n",
      "Epoch 8084, Loss: 208.63361056142782, Neurons: 201, Grad norm: 13.147331920193054\n",
      "Epoch 8084, Loss: 208.63361056142782, Neurons: 201, Grad norm: 13.147331920193054\n",
      "Epoch 8085, Loss: 208.6338596643071, Neurons: 201, Grad norm: 12.884917409776925\n",
      "Epoch 8085, Loss: 208.6338596643071, Neurons: 201, Grad norm: 12.884917409776925\n",
      "Epoch 8086, Loss: 208.63379917198586, Neurons: 201, Grad norm: 12.057575227899429\n",
      "Epoch 8086, Loss: 208.63379917198586, Neurons: 201, Grad norm: 12.057575227899429\n",
      "Epoch 8087, Loss: 208.6332807653393, Neurons: 201, Grad norm: 10.66971848808273\n",
      "Epoch 8087, Loss: 208.6332807653393, Neurons: 201, Grad norm: 10.66971848808273\n",
      "Epoch 8088, Loss: 208.63283067799625, Neurons: 201, Grad norm: 8.77246117939419\n",
      "Epoch 8088, Loss: 208.63283067799625, Neurons: 201, Grad norm: 8.77246117939419\n",
      "Epoch 8089, Loss: 208.6323107401422, Neurons: 201, Grad norm: 6.604430736248614\n",
      "Epoch 8089, Loss: 208.6323107401422, Neurons: 201, Grad norm: 6.604430736248614\n",
      "Epoch 8090, Loss: 208.6318030342161, Neurons: 201, Grad norm: 4.148521300698464\n",
      "Epoch 8090, Loss: 208.6318030342161, Neurons: 201, Grad norm: 4.148521300698464\n",
      "Epoch 8091, Loss: 208.63151299159244, Neurons: 201, Grad norm: 1.6125646437931325\n",
      "Epoch 8091, Loss: 208.63151299159244, Neurons: 201, Grad norm: 1.6125646437931325\n",
      "Epoch 8092, Loss: 208.63131668218938, Neurons: 201, Grad norm: 1.0160317377150276\n",
      "Epoch 8092, Loss: 208.63131668218938, Neurons: 201, Grad norm: 1.0160317377150276\n",
      "Epoch 8093, Loss: 208.6311108629453, Neurons: 201, Grad norm: 2.4297463406591233\n",
      "Epoch 8093, Loss: 208.6311108629453, Neurons: 201, Grad norm: 2.4297463406591233\n",
      "Epoch 8094, Loss: 208.63095335067266, Neurons: 201, Grad norm: 3.5711385411563445\n",
      "Epoch 8094, Loss: 208.63095335067266, Neurons: 201, Grad norm: 3.5711385411563445\n",
      "Epoch 8095, Loss: 208.63103274248084, Neurons: 201, Grad norm: 5.399997866972803\n",
      "Epoch 8095, Loss: 208.63103274248084, Neurons: 201, Grad norm: 5.399997866972803\n",
      "Epoch 8096, Loss: 208.6310927349941, Neurons: 201, Grad norm: 7.623981069413821\n",
      "Epoch 8096, Loss: 208.6310927349941, Neurons: 201, Grad norm: 7.623981069413821\n",
      "Epoch 8097, Loss: 208.6313828055029, Neurons: 201, Grad norm: 9.930013525621247\n",
      "Epoch 8097, Loss: 208.6313828055029, Neurons: 201, Grad norm: 9.930013525621247\n",
      "Epoch 8098, Loss: 208.63194504270638, Neurons: 201, Grad norm: 12.041657701393671\n",
      "Epoch 8098, Loss: 208.63194504270638, Neurons: 201, Grad norm: 12.041657701393671\n",
      "Epoch 8099, Loss: 208.63231054533222, Neurons: 201, Grad norm: 13.402264120537923\n",
      "Epoch 8099, Loss: 208.63231054533222, Neurons: 201, Grad norm: 13.402264120537923\n",
      "Epoch 8100, Loss: 208.63225156304557, Neurons: 201, Grad norm: 13.726447311664616\n",
      "Epoch 8100, Loss: 208.63225156304557, Neurons: 201, Grad norm: 13.726447311664616\n",
      "Epoch 8101, Loss: 208.63229062211636, Neurons: 201, Grad norm: 12.95281244824614\n",
      "Epoch 8101, Loss: 208.63229062211636, Neurons: 201, Grad norm: 12.95281244824614\n",
      "Epoch 8102, Loss: 208.63205334692728, Neurons: 201, Grad norm: 10.369360918758167\n",
      "Epoch 8102, Loss: 208.63205334692728, Neurons: 201, Grad norm: 10.369360918758167\n",
      "Epoch 8103, Loss: 208.63119776257724, Neurons: 201, Grad norm: 6.454491089827562\n",
      "Epoch 8103, Loss: 208.63119776257724, Neurons: 201, Grad norm: 6.454491089827562\n",
      "Epoch 8104, Loss: 208.63037420595242, Neurons: 201, Grad norm: 2.7527406399107868\n",
      "Epoch 8104, Loss: 208.63037420595242, Neurons: 201, Grad norm: 2.7527406399107868\n",
      "Epoch 8105, Loss: 208.6299708053985, Neurons: 201, Grad norm: 1.1034436593658588\n",
      "Epoch 8105, Loss: 208.6299708053985, Neurons: 201, Grad norm: 1.1034436593658588\n",
      "Epoch 8106, Loss: 208.62979124263757, Neurons: 201, Grad norm: 2.116767276735518\n",
      "Epoch 8106, Loss: 208.62979124263757, Neurons: 201, Grad norm: 2.116767276735518\n",
      "Epoch 8107, Loss: 208.62971804525787, Neurons: 201, Grad norm: 2.9020718956117046\n",
      "Epoch 8107, Loss: 208.62971804525787, Neurons: 201, Grad norm: 2.9020718956117046\n",
      "Epoch 8108, Loss: 208.62961472922402, Neurons: 201, Grad norm: 3.6253031519933865\n",
      "Epoch 8108, Loss: 208.62961472922402, Neurons: 201, Grad norm: 3.6253031519933865\n",
      "Epoch 8109, Loss: 208.62953158634258, Neurons: 201, Grad norm: 4.031391210784817\n",
      "Epoch 8109, Loss: 208.62953158634258, Neurons: 201, Grad norm: 4.031391210784817\n",
      "Epoch 8110, Loss: 208.62954875317863, Neurons: 201, Grad norm: 4.034537697084652\n",
      "Epoch 8110, Loss: 208.62954875317863, Neurons: 201, Grad norm: 4.034537697084652\n",
      "Epoch 8111, Loss: 208.62945366294343, Neurons: 201, Grad norm: 3.1770837943565122\n",
      "Epoch 8111, Loss: 208.62945366294343, Neurons: 201, Grad norm: 3.1770837943565122\n",
      "Epoch 8112, Loss: 208.62920373514393, Neurons: 201, Grad norm: 1.9534392141083663\n",
      "Epoch 8112, Loss: 208.62920373514393, Neurons: 201, Grad norm: 1.9534392141083663\n",
      "Epoch 8113, Loss: 208.62900320509843, Neurons: 201, Grad norm: 0.9853781134186326\n",
      "Epoch 8113, Loss: 208.62900320509843, Neurons: 201, Grad norm: 0.9853781134186326\n",
      "Epoch 8114, Loss: 208.62888444147976, Neurons: 201, Grad norm: 2.190035327498471\n",
      "Epoch 8114, Loss: 208.62888444147976, Neurons: 201, Grad norm: 2.190035327498471\n",
      "Epoch 8115, Loss: 208.62883454561668, Neurons: 201, Grad norm: 4.432571659570363\n",
      "Epoch 8115, Loss: 208.62883454561668, Neurons: 201, Grad norm: 4.432571659570363\n",
      "Epoch 8116, Loss: 208.62897018031407, Neurons: 201, Grad norm: 5.030049562977643\n",
      "Epoch 8116, Loss: 208.62897018031407, Neurons: 201, Grad norm: 5.030049562977643\n",
      "Epoch 8117, Loss: 208.62890233471794, Neurons: 201, Grad norm: 4.322586699666053\n",
      "Epoch 8117, Loss: 208.62890233471794, Neurons: 201, Grad norm: 4.322586699666053\n",
      "Epoch 8118, Loss: 208.6286661879949, Neurons: 201, Grad norm: 2.224375893103015\n",
      "Epoch 8118, Loss: 208.6286661879949, Neurons: 201, Grad norm: 2.224375893103015\n",
      "Epoch 8119, Loss: 208.62848743994255, Neurons: 201, Grad norm: 0.8384434055413582\n",
      "Epoch 8119, Loss: 208.62848743994255, Neurons: 201, Grad norm: 0.8384434055413582\n",
      "Epoch 8120, Loss: 208.628322685106, Neurons: 201, Grad norm: 2.8376129043247755\n",
      "Epoch 8120, Loss: 208.628322685106, Neurons: 201, Grad norm: 2.8376129043247755\n",
      "Epoch 8121, Loss: 208.6283581829277, Neurons: 201, Grad norm: 4.906908644243307\n",
      "Epoch 8121, Loss: 208.6283581829277, Neurons: 201, Grad norm: 4.906908644243307\n",
      "Epoch 8122, Loss: 208.62840565036754, Neurons: 201, Grad norm: 6.404286489071265\n",
      "Epoch 8122, Loss: 208.62840565036754, Neurons: 201, Grad norm: 6.404286489071265\n",
      "Epoch 8123, Loss: 208.62848679878738, Neurons: 201, Grad norm: 6.565232825374078\n",
      "Epoch 8123, Loss: 208.62848679878738, Neurons: 201, Grad norm: 6.565232825374078\n",
      "Epoch 8124, Loss: 208.628595334105, Neurons: 201, Grad norm: 4.683059225877406\n",
      "Epoch 8124, Loss: 208.628595334105, Neurons: 201, Grad norm: 4.683059225877406\n",
      "Epoch 8125, Loss: 208.62832543187338, Neurons: 201, Grad norm: 1.5768569390022988\n",
      "Epoch 8125, Loss: 208.62832543187338, Neurons: 201, Grad norm: 1.5768569390022988\n",
      "Epoch 8126, Loss: 208.62787782434364, Neurons: 201, Grad norm: 3.7029017822786274\n",
      "Epoch 8126, Loss: 208.62787782434364, Neurons: 201, Grad norm: 3.7029017822786274\n",
      "Epoch 8127, Loss: 208.62786217754112, Neurons: 201, Grad norm: 8.067625282157515\n",
      "Epoch 8127, Loss: 208.62786217754112, Neurons: 201, Grad norm: 8.067625282157515\n",
      "Epoch 8128, Loss: 208.62841037346658, Neurons: 201, Grad norm: 12.077261373280594\n",
      "Epoch 8128, Loss: 208.62841037346658, Neurons: 201, Grad norm: 12.077261373280594\n",
      "Epoch 8129, Loss: 208.62914341689256, Neurons: 201, Grad norm: 14.93289455999084\n",
      "Epoch 8129, Loss: 208.62914341689256, Neurons: 201, Grad norm: 14.93289455999084\n",
      "Epoch 8130, Loss: 208.6300175868634, Neurons: 201, Grad norm: 16.843460383256073\n",
      "Epoch 8130, Loss: 208.6300175868634, Neurons: 201, Grad norm: 16.843460383256073\n",
      "Epoch 8131, Loss: 208.63054420216307, Neurons: 201, Grad norm: 17.318693631156627\n",
      "Epoch 8131, Loss: 208.63054420216307, Neurons: 201, Grad norm: 17.318693631156627\n",
      "Epoch 8132, Loss: 208.63073062770553, Neurons: 201, Grad norm: 16.65790643451348\n",
      "Epoch 8132, Loss: 208.63073062770553, Neurons: 201, Grad norm: 16.65790643451348\n",
      "Epoch 8133, Loss: 208.63033131570455, Neurons: 201, Grad norm: 14.680634354143017\n",
      "Epoch 8133, Loss: 208.63033131570455, Neurons: 201, Grad norm: 14.680634354143017\n",
      "Epoch 8134, Loss: 208.629726178089, Neurons: 201, Grad norm: 11.408399594280864\n",
      "Epoch 8134, Loss: 208.629726178089, Neurons: 201, Grad norm: 11.408399594280864\n",
      "Epoch 8135, Loss: 208.62874000586834, Neurons: 201, Grad norm: 7.945352598334023\n",
      "Epoch 8135, Loss: 208.62874000586834, Neurons: 201, Grad norm: 7.945352598334023\n",
      "Epoch 8136, Loss: 208.62774035941408, Neurons: 201, Grad norm: 3.7384701608070925\n",
      "Epoch 8136, Loss: 208.62774035941408, Neurons: 201, Grad norm: 3.7384701608070925\n",
      "Epoch 8137, Loss: 208.62718471228678, Neurons: 201, Grad norm: 0.8728015790213851\n",
      "Epoch 8137, Loss: 208.62718471228678, Neurons: 201, Grad norm: 0.8728015790213851\n",
      "Epoch 8138, Loss: 208.6269005407699, Neurons: 201, Grad norm: 3.859021329802405\n",
      "Epoch 8138, Loss: 208.6269005407699, Neurons: 201, Grad norm: 3.859021329802405\n",
      "Epoch 8139, Loss: 208.62684204619333, Neurons: 201, Grad norm: 6.499853086630629\n",
      "Epoch 8139, Loss: 208.62684204619333, Neurons: 201, Grad norm: 6.499853086630629\n",
      "Epoch 8140, Loss: 208.6271751151362, Neurons: 201, Grad norm: 8.339521387751814\n",
      "Epoch 8140, Loss: 208.6271751151362, Neurons: 201, Grad norm: 8.339521387751814\n",
      "Epoch 8141, Loss: 208.6274319461065, Neurons: 201, Grad norm: 9.328965918900279\n",
      "Epoch 8141, Loss: 208.6274319461065, Neurons: 201, Grad norm: 9.328965918900279\n",
      "Epoch 8142, Loss: 208.6274765550382, Neurons: 201, Grad norm: 9.262404740495509\n",
      "Epoch 8142, Loss: 208.6274765550382, Neurons: 201, Grad norm: 9.262404740495509\n",
      "Epoch 8143, Loss: 208.627337478839, Neurons: 201, Grad norm: 8.35331928135096\n",
      "Epoch 8143, Loss: 208.627337478839, Neurons: 201, Grad norm: 8.35331928135096\n",
      "Epoch 8144, Loss: 208.62701712523724, Neurons: 201, Grad norm: 6.305862676469275\n",
      "Epoch 8144, Loss: 208.62701712523724, Neurons: 201, Grad norm: 6.305862676469275\n",
      "Epoch 8145, Loss: 208.62657292519555, Neurons: 201, Grad norm: 4.081756184361745\n",
      "Epoch 8145, Loss: 208.62657292519555, Neurons: 201, Grad norm: 4.081756184361745\n",
      "Epoch 8146, Loss: 208.62627882140325, Neurons: 201, Grad norm: 1.7320149636248543\n",
      "Epoch 8146, Loss: 208.62627882140325, Neurons: 201, Grad norm: 1.7320149636248543\n",
      "Epoch 8147, Loss: 208.62606759476674, Neurons: 201, Grad norm: 1.531816622828545\n",
      "Epoch 8147, Loss: 208.62606759476674, Neurons: 201, Grad norm: 1.531816622828545\n",
      "Epoch 8148, Loss: 208.62590415706603, Neurons: 201, Grad norm: 3.6535708617037277\n",
      "Epoch 8148, Loss: 208.62590415706603, Neurons: 201, Grad norm: 3.6535708617037277\n",
      "Epoch 8149, Loss: 208.62594033929878, Neurons: 201, Grad norm: 6.088935359523163\n",
      "Epoch 8149, Loss: 208.62594033929878, Neurons: 201, Grad norm: 6.088935359523163\n",
      "Epoch 8150, Loss: 208.62609263244318, Neurons: 201, Grad norm: 8.92800103616609\n",
      "Epoch 8150, Loss: 208.62609263244318, Neurons: 201, Grad norm: 8.92800103616609\n",
      "Epoch 8151, Loss: 208.62638506497868, Neurons: 201, Grad norm: 11.209758973662048\n",
      "Epoch 8151, Loss: 208.62638506497868, Neurons: 201, Grad norm: 11.209758973662048\n",
      "Epoch 8152, Loss: 208.6268933625473, Neurons: 201, Grad norm: 12.236731257785271\n",
      "Epoch 8152, Loss: 208.6268933625473, Neurons: 201, Grad norm: 12.236731257785271\n",
      "Epoch 8153, Loss: 208.62713072402397, Neurons: 201, Grad norm: 12.085842612450776\n",
      "Epoch 8153, Loss: 208.62713072402397, Neurons: 201, Grad norm: 12.085842612450776\n",
      "Epoch 8154, Loss: 208.62703627591125, Neurons: 201, Grad norm: 10.586880762665368\n",
      "Epoch 8154, Loss: 208.62703627591125, Neurons: 201, Grad norm: 10.586880762665368\n",
      "Epoch 8155, Loss: 208.62676073058051, Neurons: 201, Grad norm: 9.051458119954784\n",
      "Epoch 8155, Loss: 208.62676073058051, Neurons: 201, Grad norm: 9.051458119954784\n",
      "Epoch 8156, Loss: 208.62629754548882, Neurons: 201, Grad norm: 7.817852337669026\n",
      "Epoch 8156, Loss: 208.62629754548882, Neurons: 201, Grad norm: 7.817852337669026\n",
      "Epoch 8157, Loss: 208.6258347918091, Neurons: 201, Grad norm: 7.092211960685234\n",
      "Epoch 8157, Loss: 208.6258347918091, Neurons: 201, Grad norm: 7.092211960685234\n",
      "Epoch 8158, Loss: 208.6255723055487, Neurons: 201, Grad norm: 6.231223999977577\n",
      "Epoch 8158, Loss: 208.6255723055487, Neurons: 201, Grad norm: 6.231223999977577\n",
      "Epoch 8159, Loss: 208.62544809327173, Neurons: 201, Grad norm: 5.597056943948251\n",
      "Epoch 8159, Loss: 208.62544809327173, Neurons: 201, Grad norm: 5.597056943948251\n",
      "Epoch 8160, Loss: 208.62519412585746, Neurons: 201, Grad norm: 4.059323042711475\n",
      "Epoch 8160, Loss: 208.62519412585746, Neurons: 201, Grad norm: 4.059323042711475\n",
      "Epoch 8161, Loss: 208.6248793384585, Neurons: 201, Grad norm: 2.4615791212778104\n",
      "Epoch 8161, Loss: 208.6248793384585, Neurons: 201, Grad norm: 2.4615791212778104\n",
      "Epoch 8162, Loss: 208.62470549397983, Neurons: 201, Grad norm: 0.9603769089520195\n",
      "Epoch 8162, Loss: 208.62470549397983, Neurons: 201, Grad norm: 0.9603769089520195\n",
      "Epoch 8163, Loss: 208.62461736825455, Neurons: 201, Grad norm: 1.2691313851482513\n",
      "Epoch 8163, Loss: 208.62461736825455, Neurons: 201, Grad norm: 1.2691313851482513\n",
      "Epoch 8164, Loss: 208.62447416694772, Neurons: 201, Grad norm: 2.6100897052595724\n",
      "Epoch 8164, Loss: 208.62447416694772, Neurons: 201, Grad norm: 2.6100897052595724\n",
      "Epoch 8165, Loss: 208.62432981295083, Neurons: 201, Grad norm: 3.81776802206485\n",
      "Epoch 8165, Loss: 208.62432981295083, Neurons: 201, Grad norm: 3.81776802206485\n",
      "Epoch 8166, Loss: 208.62438886099233, Neurons: 201, Grad norm: 5.026832299576186\n",
      "Epoch 8166, Loss: 208.62438886099233, Neurons: 201, Grad norm: 5.026832299576186\n",
      "Epoch 8167, Loss: 208.62437253383126, Neurons: 201, Grad norm: 5.768402798408219\n",
      "Epoch 8167, Loss: 208.62437253383126, Neurons: 201, Grad norm: 5.768402798408219\n",
      "Epoch 8168, Loss: 208.62433829979463, Neurons: 201, Grad norm: 6.132354831965844\n",
      "Epoch 8168, Loss: 208.62433829979463, Neurons: 201, Grad norm: 6.132354831965844\n",
      "Epoch 8169, Loss: 208.6242430108756, Neurons: 201, Grad norm: 6.114885230726136\n",
      "Epoch 8169, Loss: 208.6242430108756, Neurons: 201, Grad norm: 6.114885230726136\n",
      "Epoch 8170, Loss: 208.6242207244581, Neurons: 201, Grad norm: 5.571604987226084\n",
      "Epoch 8170, Loss: 208.6242207244581, Neurons: 201, Grad norm: 5.571604987226084\n",
      "Epoch 8171, Loss: 208.6241035313704, Neurons: 201, Grad norm: 4.947308851638079\n",
      "Epoch 8171, Loss: 208.6241035313704, Neurons: 201, Grad norm: 4.947308851638079\n",
      "Epoch 8172, Loss: 208.62385923514375, Neurons: 201, Grad norm: 4.064584487308009\n",
      "Epoch 8172, Loss: 208.62385923514375, Neurons: 201, Grad norm: 4.064584487308009\n",
      "Epoch 8173, Loss: 208.62367034436744, Neurons: 201, Grad norm: 3.1508150103823365\n",
      "Epoch 8173, Loss: 208.62367034436744, Neurons: 201, Grad norm: 3.1508150103823365\n",
      "Epoch 8174, Loss: 208.6234381359148, Neurons: 201, Grad norm: 2.739898695089134\n",
      "Epoch 8174, Loss: 208.6234381359148, Neurons: 201, Grad norm: 2.739898695089134\n",
      "Epoch 8175, Loss: 208.62328547233955, Neurons: 201, Grad norm: 2.364094244975882\n",
      "Epoch 8175, Loss: 208.62328547233955, Neurons: 201, Grad norm: 2.364094244975882\n",
      "Epoch 8176, Loss: 208.6232213680395, Neurons: 201, Grad norm: 2.8498735155449566\n",
      "Epoch 8176, Loss: 208.6232213680395, Neurons: 201, Grad norm: 2.8498735155449566\n",
      "Epoch 8177, Loss: 208.6230940689184, Neurons: 201, Grad norm: 2.8664030185709386\n",
      "Epoch 8177, Loss: 208.6230940689184, Neurons: 201, Grad norm: 2.8664030185709386\n",
      "Epoch 8178, Loss: 208.62293571221537, Neurons: 201, Grad norm: 3.2983628762164967\n",
      "Epoch 8178, Loss: 208.62293571221537, Neurons: 201, Grad norm: 3.2983628762164967\n",
      "Epoch 8179, Loss: 208.62290870652336, Neurons: 201, Grad norm: 3.724292995743123\n",
      "Epoch 8179, Loss: 208.62290870652336, Neurons: 201, Grad norm: 3.724292995743123\n",
      "Epoch 8180, Loss: 208.6228245689098, Neurons: 201, Grad norm: 4.257854612769124\n",
      "Epoch 8180, Loss: 208.6228245689098, Neurons: 201, Grad norm: 4.257854612769124\n",
      "Epoch 8181, Loss: 208.62270905036974, Neurons: 201, Grad norm: 5.148129143645527\n",
      "Epoch 8181, Loss: 208.62270905036974, Neurons: 201, Grad norm: 5.148129143645527\n",
      "Epoch 8182, Loss: 208.62268974519446, Neurons: 201, Grad norm: 6.5280091444832244\n",
      "Epoch 8182, Loss: 208.62268974519446, Neurons: 201, Grad norm: 6.5280091444832244\n",
      "Epoch 8183, Loss: 208.62269814955022, Neurons: 201, Grad norm: 8.193138771125643\n",
      "Epoch 8183, Loss: 208.62269814955022, Neurons: 201, Grad norm: 8.193138771125643\n",
      "Epoch 8184, Loss: 208.62288346377602, Neurons: 201, Grad norm: 9.634575042955738\n",
      "Epoch 8184, Loss: 208.62288346377602, Neurons: 201, Grad norm: 9.634575042955738\n",
      "Epoch 8185, Loss: 208.62307212550093, Neurons: 201, Grad norm: 11.054546892472555\n",
      "Epoch 8185, Loss: 208.62307212550093, Neurons: 201, Grad norm: 11.054546892472555\n",
      "Epoch 8186, Loss: 208.62341739871286, Neurons: 201, Grad norm: 12.379797796240423\n",
      "Epoch 8186, Loss: 208.62341739871286, Neurons: 201, Grad norm: 12.379797796240423\n",
      "Epoch 8187, Loss: 208.6236907212198, Neurons: 201, Grad norm: 13.307433648533097\n",
      "Epoch 8187, Loss: 208.6236907212198, Neurons: 201, Grad norm: 13.307433648533097\n",
      "Epoch 8188, Loss: 208.62401512784015, Neurons: 201, Grad norm: 14.247883006249912\n",
      "Epoch 8188, Loss: 208.62401512784015, Neurons: 201, Grad norm: 14.247883006249912\n",
      "Epoch 8189, Loss: 208.62430183457147, Neurons: 201, Grad norm: 14.656416788557026\n",
      "Epoch 8189, Loss: 208.62430183457147, Neurons: 201, Grad norm: 14.656416788557026\n",
      "Epoch 8190, Loss: 208.62451865842294, Neurons: 201, Grad norm: 14.569567968825037\n",
      "Epoch 8190, Loss: 208.62451865842294, Neurons: 201, Grad norm: 14.569567968825037\n",
      "Epoch 8191, Loss: 208.62456103743054, Neurons: 201, Grad norm: 13.69802062701497\n",
      "Epoch 8191, Loss: 208.62456103743054, Neurons: 201, Grad norm: 13.69802062701497\n",
      "Epoch 8192, Loss: 208.62412811896522, Neurons: 201, Grad norm: 12.61715499367846\n",
      "Epoch 8192, Loss: 208.62412811896522, Neurons: 201, Grad norm: 12.61715499367846\n",
      "Epoch 8193, Loss: 208.62357608264062, Neurons: 201, Grad norm: 10.550413409642095\n",
      "Epoch 8193, Loss: 208.62357608264062, Neurons: 201, Grad norm: 10.550413409642095\n",
      "Epoch 8194, Loss: 208.622750392206, Neurons: 201, Grad norm: 8.189839284174681\n",
      "Epoch 8194, Loss: 208.622750392206, Neurons: 201, Grad norm: 8.189839284174681\n",
      "Epoch 8195, Loss: 208.62202455197576, Neurons: 201, Grad norm: 5.702811740588625\n",
      "Epoch 8195, Loss: 208.62202455197576, Neurons: 201, Grad norm: 5.702811740588625\n",
      "Epoch 8196, Loss: 208.62143534136766, Neurons: 201, Grad norm: 3.1345634420172637\n",
      "Epoch 8196, Loss: 208.62143534136766, Neurons: 201, Grad norm: 3.1345634420172637\n",
      "Epoch 8197, Loss: 208.62102678143856, Neurons: 201, Grad norm: 0.9365512895857185\n",
      "Epoch 8197, Loss: 208.62102678143856, Neurons: 201, Grad norm: 0.9365512895857185\n",
      "Epoch 8198, Loss: 208.62083290010526, Neurons: 201, Grad norm: 1.3057540221539534\n",
      "Epoch 8198, Loss: 208.62083290010526, Neurons: 201, Grad norm: 1.3057540221539534\n",
      "Epoch 8199, Loss: 208.6207540452304, Neurons: 201, Grad norm: 3.638610715560018\n",
      "Epoch 8199, Loss: 208.6207540452304, Neurons: 201, Grad norm: 3.638610715560018\n",
      "Epoch 8200, Loss: 208.62075768619943, Neurons: 201, Grad norm: 5.5958802228324585\n",
      "Epoch 8200, Loss: 208.62075768619943, Neurons: 201, Grad norm: 5.5958802228324585\n",
      "Epoch 8201, Loss: 208.6208431368448, Neurons: 201, Grad norm: 7.986053549682742\n",
      "Epoch 8201, Loss: 208.6208431368448, Neurons: 201, Grad norm: 7.986053549682742\n",
      "Epoch 8202, Loss: 208.6209816081921, Neurons: 201, Grad norm: 10.715853544142771\n",
      "Epoch 8202, Loss: 208.6209816081921, Neurons: 201, Grad norm: 10.715853544142771\n",
      "Epoch 8203, Loss: 208.6215010522152, Neurons: 201, Grad norm: 12.113693761957828\n",
      "Epoch 8203, Loss: 208.6215010522152, Neurons: 201, Grad norm: 12.113693761957828\n",
      "Epoch 8204, Loss: 208.62184092402867, Neurons: 201, Grad norm: 12.389865264374022\n",
      "Epoch 8204, Loss: 208.62184092402867, Neurons: 201, Grad norm: 12.389865264374022\n",
      "Epoch 8205, Loss: 208.62184367819393, Neurons: 201, Grad norm: 11.389056564370414\n",
      "Epoch 8205, Loss: 208.62184367819393, Neurons: 201, Grad norm: 11.389056564370414\n",
      "Epoch 8206, Loss: 208.6216111964064, Neurons: 201, Grad norm: 9.77198007136299\n",
      "Epoch 8206, Loss: 208.6216111964064, Neurons: 201, Grad norm: 9.77198007136299\n",
      "Epoch 8207, Loss: 208.62127055307312, Neurons: 201, Grad norm: 8.562399586052148\n",
      "Epoch 8207, Loss: 208.62127055307312, Neurons: 201, Grad norm: 8.562399586052148\n",
      "Epoch 8208, Loss: 208.62081250670008, Neurons: 201, Grad norm: 8.089087810032671\n",
      "Epoch 8208, Loss: 208.62081250670008, Neurons: 201, Grad norm: 8.089087810032671\n",
      "Epoch 8209, Loss: 208.62059381313065, Neurons: 201, Grad norm: 7.818767587149444\n",
      "Epoch 8209, Loss: 208.62059381313065, Neurons: 201, Grad norm: 7.818767587149444\n",
      "Epoch 8210, Loss: 208.62035323963102, Neurons: 201, Grad norm: 7.221247776814332\n",
      "Epoch 8210, Loss: 208.62035323963102, Neurons: 201, Grad norm: 7.221247776814332\n",
      "Epoch 8211, Loss: 208.62005182644089, Neurons: 201, Grad norm: 6.824155226350069\n",
      "Epoch 8211, Loss: 208.62005182644089, Neurons: 201, Grad norm: 6.824155226350069\n",
      "Epoch 8212, Loss: 208.61993196230065, Neurons: 201, Grad norm: 5.744766090181104\n",
      "Epoch 8212, Loss: 208.61993196230065, Neurons: 201, Grad norm: 5.744766090181104\n",
      "Epoch 8213, Loss: 208.6196780493596, Neurons: 201, Grad norm: 4.71174806406719\n",
      "Epoch 8213, Loss: 208.6196780493596, Neurons: 201, Grad norm: 4.71174806406719\n",
      "Epoch 8214, Loss: 208.6195040562803, Neurons: 201, Grad norm: 3.8369918619580643\n",
      "Epoch 8214, Loss: 208.6195040562803, Neurons: 201, Grad norm: 3.8369918619580643\n",
      "Epoch 8215, Loss: 208.6193773938205, Neurons: 201, Grad norm: 3.675981805440401\n",
      "Epoch 8215, Loss: 208.6193773938205, Neurons: 201, Grad norm: 3.675981805440401\n",
      "Epoch 8216, Loss: 208.61929000534585, Neurons: 201, Grad norm: 3.918917577402737\n",
      "Epoch 8216, Loss: 208.61929000534585, Neurons: 201, Grad norm: 3.918917577402737\n",
      "Epoch 8217, Loss: 208.619123351298, Neurons: 201, Grad norm: 4.73077883928481\n",
      "Epoch 8217, Loss: 208.619123351298, Neurons: 201, Grad norm: 4.73077883928481\n",
      "Epoch 8218, Loss: 208.61911300360632, Neurons: 201, Grad norm: 5.163820462220557\n",
      "Epoch 8218, Loss: 208.61911300360632, Neurons: 201, Grad norm: 5.163820462220557\n",
      "Epoch 8219, Loss: 208.61901407357453, Neurons: 201, Grad norm: 5.4812739834685\n",
      "Epoch 8219, Loss: 208.61901407357453, Neurons: 201, Grad norm: 5.4812739834685\n",
      "Epoch 8220, Loss: 208.6189951120909, Neurons: 201, Grad norm: 5.151218383701464\n",
      "Epoch 8220, Loss: 208.6189951120909, Neurons: 201, Grad norm: 5.151218383701464\n",
      "Epoch 8221, Loss: 208.61893338015844, Neurons: 201, Grad norm: 4.572919459409678\n",
      "Epoch 8221, Loss: 208.61893338015844, Neurons: 201, Grad norm: 4.572919459409678\n",
      "Epoch 8222, Loss: 208.618762668152, Neurons: 201, Grad norm: 3.573628270408017\n",
      "Epoch 8222, Loss: 208.618762668152, Neurons: 201, Grad norm: 3.573628270408017\n",
      "Epoch 8223, Loss: 208.61860507293716, Neurons: 201, Grad norm: 1.8568160565670468\n",
      "Epoch 8223, Loss: 208.61860507293716, Neurons: 201, Grad norm: 1.8568160565670468\n",
      "Epoch 8224, Loss: 208.61840411236764, Neurons: 201, Grad norm: 0.9554359089918713\n",
      "Epoch 8224, Loss: 208.61840411236764, Neurons: 201, Grad norm: 0.9554359089918713\n",
      "Epoch 8225, Loss: 208.61820978152707, Neurons: 201, Grad norm: 3.229214774819957\n",
      "Epoch 8225, Loss: 208.61820978152707, Neurons: 201, Grad norm: 3.229214774819957\n",
      "Epoch 8226, Loss: 208.61821619715028, Neurons: 201, Grad norm: 5.828885070184978\n",
      "Epoch 8226, Loss: 208.61821619715028, Neurons: 201, Grad norm: 5.828885070184978\n",
      "Epoch 8227, Loss: 208.61838113564286, Neurons: 201, Grad norm: 7.728557371288038\n",
      "Epoch 8227, Loss: 208.61838113564286, Neurons: 201, Grad norm: 7.728557371288038\n",
      "Epoch 8228, Loss: 208.61854281455646, Neurons: 201, Grad norm: 9.620627725226491\n",
      "Epoch 8228, Loss: 208.61854281455646, Neurons: 201, Grad norm: 9.620627725226491\n",
      "Epoch 8229, Loss: 208.61869421280304, Neurons: 201, Grad norm: 11.17756559652945\n",
      "Epoch 8229, Loss: 208.61869421280304, Neurons: 201, Grad norm: 11.17756559652945\n",
      "Epoch 8230, Loss: 208.6190120271196, Neurons: 201, Grad norm: 12.609573442064905\n",
      "Epoch 8230, Loss: 208.6190120271196, Neurons: 201, Grad norm: 12.609573442064905\n",
      "Epoch 8231, Loss: 208.61927967764802, Neurons: 201, Grad norm: 13.51711252830405\n",
      "Epoch 8231, Loss: 208.61927967764802, Neurons: 201, Grad norm: 13.51711252830405\n",
      "Epoch 8232, Loss: 208.61969459271614, Neurons: 201, Grad norm: 13.88994722058921\n",
      "Epoch 8232, Loss: 208.61969459271614, Neurons: 201, Grad norm: 13.88994722058921\n",
      "Epoch 8233, Loss: 208.6201107535763, Neurons: 201, Grad norm: 13.498622884782609\n",
      "Epoch 8233, Loss: 208.6201107535763, Neurons: 201, Grad norm: 13.498622884782609\n",
      "Epoch 8234, Loss: 208.62041250594194, Neurons: 201, Grad norm: 13.44528814314338\n",
      "Epoch 8234, Loss: 208.62041250594194, Neurons: 201, Grad norm: 13.44528814314338\n",
      "Epoch 8235, Loss: 208.62037604782876, Neurons: 201, Grad norm: 13.034118096053152\n",
      "Epoch 8235, Loss: 208.62037604782876, Neurons: 201, Grad norm: 13.034118096053152\n",
      "Epoch 8236, Loss: 208.6201406797585, Neurons: 201, Grad norm: 12.587248725448182\n",
      "Epoch 8236, Loss: 208.6201406797585, Neurons: 201, Grad norm: 12.587248725448182\n",
      "Epoch 8237, Loss: 208.61941138862016, Neurons: 201, Grad norm: 11.464979800562556\n",
      "Epoch 8237, Loss: 208.61941138862016, Neurons: 201, Grad norm: 11.464979800562556\n",
      "Epoch 8238, Loss: 208.61866618338533, Neurons: 201, Grad norm: 9.606667801304788\n",
      "Epoch 8238, Loss: 208.61866618338533, Neurons: 201, Grad norm: 9.606667801304788\n",
      "Epoch 8239, Loss: 208.6179566413993, Neurons: 201, Grad norm: 6.8682352804076805\n",
      "Epoch 8239, Loss: 208.6179566413993, Neurons: 201, Grad norm: 6.8682352804076805\n",
      "Epoch 8240, Loss: 208.61751372434273, Neurons: 201, Grad norm: 3.7237873641867534\n",
      "Epoch 8240, Loss: 208.61751372434273, Neurons: 201, Grad norm: 3.7237873641867534\n",
      "Epoch 8241, Loss: 208.61717198210624, Neurons: 201, Grad norm: 1.1736170333338207\n",
      "Epoch 8241, Loss: 208.61717198210624, Neurons: 201, Grad norm: 1.1736170333338207\n",
      "Epoch 8242, Loss: 208.61688138846893, Neurons: 201, Grad norm: 3.2890315502747436\n",
      "Epoch 8242, Loss: 208.61688138846893, Neurons: 201, Grad norm: 3.2890315502747436\n",
      "Epoch 8243, Loss: 208.61690406958152, Neurons: 201, Grad norm: 6.644885573201134\n",
      "Epoch 8243, Loss: 208.61690406958152, Neurons: 201, Grad norm: 6.644885573201134\n",
      "Epoch 8244, Loss: 208.61704363303437, Neurons: 201, Grad norm: 9.557980372914264\n",
      "Epoch 8244, Loss: 208.61704363303437, Neurons: 201, Grad norm: 9.557980372914264\n",
      "Epoch 8245, Loss: 208.61752327372037, Neurons: 201, Grad norm: 11.858105590144772\n",
      "Epoch 8245, Loss: 208.61752327372037, Neurons: 201, Grad norm: 11.858105590144772\n",
      "Epoch 8246, Loss: 208.6179576854374, Neurons: 201, Grad norm: 12.47061201122127\n",
      "Epoch 8246, Loss: 208.6179576854374, Neurons: 201, Grad norm: 12.47061201122127\n",
      "Epoch 8247, Loss: 208.61800423778973, Neurons: 201, Grad norm: 12.188958544974005\n",
      "Epoch 8247, Loss: 208.61800423778973, Neurons: 201, Grad norm: 12.188958544974005\n",
      "Epoch 8248, Loss: 208.61800079178983, Neurons: 201, Grad norm: 11.111297331977205\n",
      "Epoch 8248, Loss: 208.61800079178983, Neurons: 201, Grad norm: 11.111297331977205\n",
      "Epoch 8249, Loss: 208.61810784044457, Neurons: 201, Grad norm: 10.01704894404553\n",
      "Epoch 8249, Loss: 208.61810784044457, Neurons: 201, Grad norm: 10.01704894404553\n",
      "Epoch 8250, Loss: 208.61798472229444, Neurons: 201, Grad norm: 9.043078115097662\n",
      "Epoch 8250, Loss: 208.61798472229444, Neurons: 201, Grad norm: 9.043078115097662\n",
      "Epoch 8251, Loss: 208.61764057430344, Neurons: 201, Grad norm: 8.562505777915877\n",
      "Epoch 8251, Loss: 208.61764057430344, Neurons: 201, Grad norm: 8.562505777915877\n",
      "Epoch 8252, Loss: 208.6170824650319, Neurons: 201, Grad norm: 8.217544212041696\n",
      "Epoch 8252, Loss: 208.6170824650319, Neurons: 201, Grad norm: 8.217544212041696\n",
      "Epoch 8253, Loss: 208.616665689346, Neurons: 201, Grad norm: 7.896814307663646\n",
      "Epoch 8253, Loss: 208.616665689346, Neurons: 201, Grad norm: 7.896814307663646\n",
      "Epoch 8254, Loss: 208.61639564394227, Neurons: 201, Grad norm: 7.190878096209466\n",
      "Epoch 8254, Loss: 208.61639564394227, Neurons: 201, Grad norm: 7.190878096209466\n",
      "Epoch 8255, Loss: 208.6162856412051, Neurons: 201, Grad norm: 5.453919486223988\n",
      "Epoch 8255, Loss: 208.6162856412051, Neurons: 201, Grad norm: 5.453919486223988\n",
      "Epoch 8256, Loss: 208.6160669603039, Neurons: 201, Grad norm: 3.231030425038873\n",
      "Epoch 8256, Loss: 208.6160669603039, Neurons: 201, Grad norm: 3.231030425038873\n",
      "Epoch 8257, Loss: 208.61566463700527, Neurons: 201, Grad norm: 0.8810682087800946\n",
      "Epoch 8257, Loss: 208.61566463700527, Neurons: 201, Grad norm: 0.8810682087800946\n",
      "Epoch 8258, Loss: 208.61542825899713, Neurons: 201, Grad norm: 2.569268425067539\n",
      "Epoch 8258, Loss: 208.61542825899713, Neurons: 201, Grad norm: 2.569268425067539\n",
      "Epoch 8259, Loss: 208.61533653385845, Neurons: 201, Grad norm: 5.244149357414643\n",
      "Epoch 8259, Loss: 208.61533653385845, Neurons: 201, Grad norm: 5.244149357414643\n",
      "Epoch 8260, Loss: 208.61550863413026, Neurons: 201, Grad norm: 7.336166800740899\n",
      "Epoch 8260, Loss: 208.61550863413026, Neurons: 201, Grad norm: 7.336166800740899\n",
      "Epoch 8261, Loss: 208.61561659344915, Neurons: 201, Grad norm: 8.416830155864728\n",
      "Epoch 8261, Loss: 208.61561659344915, Neurons: 201, Grad norm: 8.416830155864728\n",
      "Epoch 8262, Loss: 208.61576111317842, Neurons: 201, Grad norm: 8.69264273221866\n",
      "Epoch 8262, Loss: 208.61576111317842, Neurons: 201, Grad norm: 8.69264273221866\n",
      "Epoch 8263, Loss: 208.61564062754852, Neurons: 201, Grad norm: 8.324531739804518\n",
      "Epoch 8263, Loss: 208.61564062754852, Neurons: 201, Grad norm: 8.324531739804518\n",
      "Epoch 8264, Loss: 208.61556582972162, Neurons: 201, Grad norm: 8.485911897184247\n",
      "Epoch 8264, Loss: 208.61556582972162, Neurons: 201, Grad norm: 8.485911897184247\n",
      "Epoch 8265, Loss: 208.615745058179, Neurons: 201, Grad norm: 9.279978722997912\n",
      "Epoch 8265, Loss: 208.615745058179, Neurons: 201, Grad norm: 9.279978722997912\n",
      "Epoch 8266, Loss: 208.61577954635095, Neurons: 201, Grad norm: 10.001346840934213\n",
      "Epoch 8266, Loss: 208.61577954635095, Neurons: 201, Grad norm: 10.001346840934213\n",
      "Epoch 8267, Loss: 208.61583366158013, Neurons: 201, Grad norm: 10.487368757035817\n",
      "Epoch 8267, Loss: 208.61583366158013, Neurons: 201, Grad norm: 10.487368757035817\n",
      "Epoch 8268, Loss: 208.6157213812494, Neurons: 201, Grad norm: 10.50246492946111\n",
      "Epoch 8268, Loss: 208.6157213812494, Neurons: 201, Grad norm: 10.50246492946111\n",
      "Epoch 8269, Loss: 208.61541202262825, Neurons: 201, Grad norm: 9.71392414514379\n",
      "Epoch 8269, Loss: 208.61541202262825, Neurons: 201, Grad norm: 9.71392414514379\n",
      "Epoch 8270, Loss: 208.61517635039712, Neurons: 201, Grad norm: 8.801824887496572\n",
      "Epoch 8270, Loss: 208.61517635039712, Neurons: 201, Grad norm: 8.801824887496572\n",
      "Epoch 8271, Loss: 208.61493521861084, Neurons: 201, Grad norm: 7.703646996482819\n",
      "Epoch 8271, Loss: 208.61493521861084, Neurons: 201, Grad norm: 7.703646996482819\n",
      "Epoch 8272, Loss: 208.61463308451505, Neurons: 201, Grad norm: 5.81641946988363\n",
      "Epoch 8272, Loss: 208.61463308451505, Neurons: 201, Grad norm: 5.81641946988363\n",
      "Epoch 8273, Loss: 208.6143894552608, Neurons: 201, Grad norm: 3.863243183033717\n",
      "Epoch 8273, Loss: 208.6143894552608, Neurons: 201, Grad norm: 3.863243183033717\n",
      "Epoch 8274, Loss: 208.61419860868924, Neurons: 201, Grad norm: 2.549105316377807\n",
      "Epoch 8274, Loss: 208.61419860868924, Neurons: 201, Grad norm: 2.549105316377807\n",
      "Epoch 8275, Loss: 208.61402546627008, Neurons: 201, Grad norm: 1.2570906998638136\n",
      "Epoch 8275, Loss: 208.61402546627008, Neurons: 201, Grad norm: 1.2570906998638136\n",
      "Epoch 8276, Loss: 208.61382352533127, Neurons: 201, Grad norm: 1.5845438876705549\n",
      "Epoch 8276, Loss: 208.61382352533127, Neurons: 201, Grad norm: 1.5845438876705549\n",
      "Epoch 8277, Loss: 208.61372691922517, Neurons: 201, Grad norm: 2.6185200855735307\n",
      "Epoch 8277, Loss: 208.61372691922517, Neurons: 201, Grad norm: 2.6185200855735307\n",
      "Epoch 8278, Loss: 208.61364198251988, Neurons: 201, Grad norm: 4.916750985555895\n",
      "Epoch 8278, Loss: 208.61364198251988, Neurons: 201, Grad norm: 4.916750985555895\n",
      "Epoch 8279, Loss: 208.61375277991846, Neurons: 201, Grad norm: 7.118624238676719\n",
      "Epoch 8279, Loss: 208.61375277991846, Neurons: 201, Grad norm: 7.118624238676719\n",
      "Epoch 8280, Loss: 208.61397503574676, Neurons: 201, Grad norm: 8.845065815172847\n",
      "Epoch 8280, Loss: 208.61397503574676, Neurons: 201, Grad norm: 8.845065815172847\n",
      "Epoch 8281, Loss: 208.61435424617844, Neurons: 201, Grad norm: 10.587632287926501\n",
      "Epoch 8281, Loss: 208.61435424617844, Neurons: 201, Grad norm: 10.587632287926501\n",
      "Epoch 8282, Loss: 208.61454595816926, Neurons: 201, Grad norm: 11.472733865959624\n",
      "Epoch 8282, Loss: 208.61454595816926, Neurons: 201, Grad norm: 11.472733865959624\n",
      "Epoch 8283, Loss: 208.61446479575113, Neurons: 201, Grad norm: 11.695022196004256\n",
      "Epoch 8283, Loss: 208.61446479575113, Neurons: 201, Grad norm: 11.695022196004256\n",
      "Epoch 8284, Loss: 208.61454190769012, Neurons: 201, Grad norm: 11.038107350932838\n",
      "Epoch 8284, Loss: 208.61454190769012, Neurons: 201, Grad norm: 11.038107350932838\n",
      "Epoch 8285, Loss: 208.61414246194389, Neurons: 201, Grad norm: 9.008516219035574\n",
      "Epoch 8285, Loss: 208.61414246194389, Neurons: 201, Grad norm: 9.008516219035574\n",
      "Epoch 8286, Loss: 208.61347815429832, Neurons: 201, Grad norm: 4.90736412220828\n",
      "Epoch 8286, Loss: 208.61347815429832, Neurons: 201, Grad norm: 4.90736412220828\n",
      "Epoch 8287, Loss: 208.61299953629572, Neurons: 201, Grad norm: 0.8064055017169522\n",
      "Epoch 8287, Loss: 208.61299953629572, Neurons: 201, Grad norm: 0.8064055017169522\n",
      "Epoch 8288, Loss: 208.61246732020868, Neurons: 201, Grad norm: 5.338417411854035\n",
      "Epoch 8288, Loss: 208.61246732020868, Neurons: 201, Grad norm: 5.338417411854035\n",
      "Epoch 8289, Loss: 208.6125798640364, Neurons: 201, Grad norm: 9.754277892195638\n",
      "Epoch 8289, Loss: 208.6125798640364, Neurons: 201, Grad norm: 9.754277892195638\n",
      "Epoch 8290, Loss: 208.61311991766692, Neurons: 201, Grad norm: 11.898759705402014\n",
      "Epoch 8290, Loss: 208.61311991766692, Neurons: 201, Grad norm: 11.898759705402014\n",
      "Epoch 8291, Loss: 208.6136177712828, Neurons: 201, Grad norm: 12.53723836959799\n",
      "Epoch 8291, Loss: 208.6136177712828, Neurons: 201, Grad norm: 12.53723836959799\n",
      "Epoch 8292, Loss: 208.61368549993233, Neurons: 201, Grad norm: 11.97834862390839\n",
      "Epoch 8292, Loss: 208.61368549993233, Neurons: 201, Grad norm: 11.97834862390839\n",
      "Epoch 8293, Loss: 208.61350961610063, Neurons: 201, Grad norm: 11.035573134771202\n",
      "Epoch 8293, Loss: 208.61350961610063, Neurons: 201, Grad norm: 11.035573134771202\n",
      "Epoch 8294, Loss: 208.61349098272396, Neurons: 201, Grad norm: 9.377634037773186\n",
      "Epoch 8294, Loss: 208.61349098272396, Neurons: 201, Grad norm: 9.377634037773186\n",
      "Epoch 8295, Loss: 208.6133021516995, Neurons: 201, Grad norm: 8.022089232601026\n",
      "Epoch 8295, Loss: 208.6133021516995, Neurons: 201, Grad norm: 8.022089232601026\n",
      "Epoch 8296, Loss: 208.61275907643196, Neurons: 201, Grad norm: 7.2514803807699995\n",
      "Epoch 8296, Loss: 208.61275907643196, Neurons: 201, Grad norm: 7.2514803807699995\n",
      "Epoch 8297, Loss: 208.61248195739603, Neurons: 201, Grad norm: 6.3375950896486595\n",
      "Epoch 8297, Loss: 208.61248195739603, Neurons: 201, Grad norm: 6.3375950896486595\n",
      "Epoch 8298, Loss: 208.61225917978783, Neurons: 201, Grad norm: 6.042420670211855\n",
      "Epoch 8298, Loss: 208.61225917978783, Neurons: 201, Grad norm: 6.042420670211855\n",
      "Epoch 8299, Loss: 208.61198450561596, Neurons: 201, Grad norm: 5.282935349772628\n",
      "Epoch 8299, Loss: 208.61198450561596, Neurons: 201, Grad norm: 5.282935349772628\n",
      "Epoch 8300, Loss: 208.6117391106862, Neurons: 201, Grad norm: 4.106387267154795\n",
      "Epoch 8300, Loss: 208.6117391106862, Neurons: 201, Grad norm: 4.106387267154795\n",
      "Epoch 8301, Loss: 208.61164494526506, Neurons: 201, Grad norm: 2.5717023107438384\n",
      "Epoch 8301, Loss: 208.61164494526506, Neurons: 201, Grad norm: 2.5717023107438384\n",
      "Epoch 8302, Loss: 208.61145164022508, Neurons: 201, Grad norm: 1.1078115781465623\n",
      "Epoch 8302, Loss: 208.61145164022508, Neurons: 201, Grad norm: 1.1078115781465623\n",
      "Epoch 8303, Loss: 208.6112572209834, Neurons: 201, Grad norm: 1.7643648266129335\n",
      "Epoch 8303, Loss: 208.6112572209834, Neurons: 201, Grad norm: 1.7643648266129335\n",
      "Epoch 8304, Loss: 208.61128917261811, Neurons: 201, Grad norm: 3.124378718996189\n",
      "Epoch 8304, Loss: 208.61128917261811, Neurons: 201, Grad norm: 3.124378718996189\n",
      "Epoch 8305, Loss: 208.61129157611794, Neurons: 201, Grad norm: 4.6189615551175764\n",
      "Epoch 8305, Loss: 208.61129157611794, Neurons: 201, Grad norm: 4.6189615551175764\n",
      "Epoch 8306, Loss: 208.61125183489938, Neurons: 201, Grad norm: 5.362938441704103\n",
      "Epoch 8306, Loss: 208.61125183489938, Neurons: 201, Grad norm: 5.362938441704103\n",
      "Epoch 8307, Loss: 208.61119636081082, Neurons: 201, Grad norm: 6.412447327372377\n",
      "Epoch 8307, Loss: 208.61119636081082, Neurons: 201, Grad norm: 6.412447327372377\n",
      "Epoch 8308, Loss: 208.61129760609373, Neurons: 201, Grad norm: 7.374672668755115\n",
      "Epoch 8308, Loss: 208.61129760609373, Neurons: 201, Grad norm: 7.374672668755115\n",
      "Epoch 8309, Loss: 208.6113454302709, Neurons: 201, Grad norm: 7.626018128001257\n",
      "Epoch 8309, Loss: 208.6113454302709, Neurons: 201, Grad norm: 7.626018128001257\n",
      "Epoch 8310, Loss: 208.6111982110779, Neurons: 201, Grad norm: 7.178230504071529\n",
      "Epoch 8310, Loss: 208.6111982110779, Neurons: 201, Grad norm: 7.178230504071529\n",
      "Epoch 8311, Loss: 208.6111004770276, Neurons: 201, Grad norm: 6.07212924991043\n",
      "Epoch 8311, Loss: 208.6111004770276, Neurons: 201, Grad norm: 6.07212924991043\n",
      "Epoch 8312, Loss: 208.6108910184545, Neurons: 201, Grad norm: 4.263124091236317\n",
      "Epoch 8312, Loss: 208.6108910184545, Neurons: 201, Grad norm: 4.263124091236317\n",
      "Epoch 8313, Loss: 208.61064038378814, Neurons: 201, Grad norm: 2.913443578102557\n",
      "Epoch 8313, Loss: 208.61064038378814, Neurons: 201, Grad norm: 2.913443578102557\n",
      "Epoch 8314, Loss: 208.6105636491626, Neurons: 201, Grad norm: 2.293769056890727\n",
      "Epoch 8314, Loss: 208.6105636491626, Neurons: 201, Grad norm: 2.293769056890727\n",
      "Epoch 8315, Loss: 208.61047113615547, Neurons: 201, Grad norm: 1.6240955091837124\n",
      "Epoch 8315, Loss: 208.61047113615547, Neurons: 201, Grad norm: 1.6240955091837124\n",
      "Epoch 8316, Loss: 208.61024106443745, Neurons: 201, Grad norm: 1.2783967328035182\n",
      "Epoch 8316, Loss: 208.61024106443745, Neurons: 201, Grad norm: 1.2783967328035182\n",
      "Epoch 8317, Loss: 208.61009229953638, Neurons: 201, Grad norm: 1.24499106579914\n",
      "Epoch 8317, Loss: 208.61009229953638, Neurons: 201, Grad norm: 1.24499106579914\n",
      "Epoch 8318, Loss: 208.6099630700965, Neurons: 201, Grad norm: 1.6872324395113976\n",
      "Epoch 8318, Loss: 208.6099630700965, Neurons: 201, Grad norm: 1.6872324395113976\n",
      "Epoch 8319, Loss: 208.60987683411867, Neurons: 201, Grad norm: 2.723169160115572\n",
      "Epoch 8319, Loss: 208.60987683411867, Neurons: 201, Grad norm: 2.723169160115572\n",
      "Epoch 8320, Loss: 208.60982915938754, Neurons: 201, Grad norm: 3.5498241338960574\n",
      "Epoch 8320, Loss: 208.60982915938754, Neurons: 201, Grad norm: 3.5498241338960574\n",
      "Epoch 8321, Loss: 208.60977621752502, Neurons: 201, Grad norm: 3.9165629214722486\n",
      "Epoch 8321, Loss: 208.60977621752502, Neurons: 201, Grad norm: 3.9165629214722486\n",
      "Epoch 8322, Loss: 208.6097191899715, Neurons: 201, Grad norm: 4.090407498178013\n",
      "Epoch 8322, Loss: 208.6097191899715, Neurons: 201, Grad norm: 4.090407498178013\n",
      "Epoch 8323, Loss: 208.60970920092316, Neurons: 201, Grad norm: 3.983385899150248\n",
      "Epoch 8323, Loss: 208.60970920092316, Neurons: 201, Grad norm: 3.983385899150248\n",
      "Epoch 8324, Loss: 208.60961295842247, Neurons: 201, Grad norm: 4.362059362575705\n",
      "Epoch 8324, Loss: 208.60961295842247, Neurons: 201, Grad norm: 4.362059362575705\n",
      "Epoch 8325, Loss: 208.60956199276765, Neurons: 201, Grad norm: 5.114485711348861\n",
      "Epoch 8325, Loss: 208.60956199276765, Neurons: 201, Grad norm: 5.114485711348861\n",
      "Epoch 8326, Loss: 208.60960738032432, Neurons: 201, Grad norm: 7.151862393697088\n",
      "Epoch 8326, Loss: 208.60960738032432, Neurons: 201, Grad norm: 7.151862393697088\n",
      "Epoch 8327, Loss: 208.609969828778, Neurons: 201, Grad norm: 9.31394157945074\n",
      "Epoch 8327, Loss: 208.609969828778, Neurons: 201, Grad norm: 9.31394157945074\n",
      "Epoch 8328, Loss: 208.61052245808608, Neurons: 201, Grad norm: 11.06471190049452\n",
      "Epoch 8328, Loss: 208.61052245808608, Neurons: 201, Grad norm: 11.06471190049452\n",
      "Epoch 8329, Loss: 208.6108366680585, Neurons: 201, Grad norm: 12.991358115503468\n",
      "Epoch 8329, Loss: 208.6108366680585, Neurons: 201, Grad norm: 12.991358115503468\n",
      "Epoch 8330, Loss: 208.61094973894166, Neurons: 201, Grad norm: 14.662326679949206\n",
      "Epoch 8330, Loss: 208.61094973894166, Neurons: 201, Grad norm: 14.662326679949206\n",
      "Epoch 8331, Loss: 208.611366784898, Neurons: 201, Grad norm: 16.05670161835924\n",
      "Epoch 8331, Loss: 208.611366784898, Neurons: 201, Grad norm: 16.05670161835924\n",
      "Epoch 8332, Loss: 208.61173055384262, Neurons: 201, Grad norm: 16.73083066155604\n",
      "Epoch 8332, Loss: 208.61173055384262, Neurons: 201, Grad norm: 16.73083066155604\n",
      "Epoch 8333, Loss: 208.61185729504044, Neurons: 201, Grad norm: 17.26214674212612\n",
      "Epoch 8333, Loss: 208.61185729504044, Neurons: 201, Grad norm: 17.26214674212612\n",
      "Epoch 8334, Loss: 208.61161734686385, Neurons: 201, Grad norm: 16.370275253653976\n",
      "Epoch 8334, Loss: 208.61161734686385, Neurons: 201, Grad norm: 16.370275253653976\n",
      "Epoch 8335, Loss: 208.61157256579673, Neurons: 201, Grad norm: 14.821060812889845\n",
      "Epoch 8335, Loss: 208.61157256579673, Neurons: 201, Grad norm: 14.821060812889845\n",
      "Epoch 8336, Loss: 208.6109802584656, Neurons: 201, Grad norm: 11.925555403988403\n",
      "Epoch 8336, Loss: 208.6109802584656, Neurons: 201, Grad norm: 11.925555403988403\n",
      "Epoch 8337, Loss: 208.61019600062923, Neurons: 201, Grad norm: 8.183672306482551\n",
      "Epoch 8337, Loss: 208.61019600062923, Neurons: 201, Grad norm: 8.183672306482551\n",
      "Epoch 8338, Loss: 208.60941149586174, Neurons: 201, Grad norm: 4.532688608689984\n",
      "Epoch 8338, Loss: 208.60941149586174, Neurons: 201, Grad norm: 4.532688608689984\n",
      "Epoch 8339, Loss: 208.60881787309816, Neurons: 201, Grad norm: 1.8112343096686958\n",
      "Epoch 8339, Loss: 208.60881787309816, Neurons: 201, Grad norm: 1.8112343096686958\n",
      "Epoch 8340, Loss: 208.6085541291104, Neurons: 201, Grad norm: 2.086454427894774\n",
      "Epoch 8340, Loss: 208.6085541291104, Neurons: 201, Grad norm: 2.086454427894774\n",
      "Epoch 8341, Loss: 208.60841300441353, Neurons: 201, Grad norm: 3.8195266395421594\n",
      "Epoch 8341, Loss: 208.60841300441353, Neurons: 201, Grad norm: 3.8195266395421594\n",
      "Epoch 8342, Loss: 208.60831766459472, Neurons: 201, Grad norm: 5.181415785328101\n",
      "Epoch 8342, Loss: 208.60831766459472, Neurons: 201, Grad norm: 5.181415785328101\n",
      "Epoch 8343, Loss: 208.6084512387955, Neurons: 201, Grad norm: 6.042534025693658\n",
      "Epoch 8343, Loss: 208.6084512387955, Neurons: 201, Grad norm: 6.042534025693658\n",
      "Epoch 8344, Loss: 208.60862283821743, Neurons: 201, Grad norm: 6.702281129694669\n",
      "Epoch 8344, Loss: 208.60862283821743, Neurons: 201, Grad norm: 6.702281129694669\n",
      "Epoch 8345, Loss: 208.60864577347755, Neurons: 201, Grad norm: 7.162424143191269\n",
      "Epoch 8345, Loss: 208.60864577347755, Neurons: 201, Grad norm: 7.162424143191269\n",
      "Epoch 8346, Loss: 208.6085386691243, Neurons: 201, Grad norm: 7.730931856437124\n",
      "Epoch 8346, Loss: 208.6085386691243, Neurons: 201, Grad norm: 7.730931856437124\n",
      "Epoch 8347, Loss: 208.6085854621373, Neurons: 201, Grad norm: 8.40486191485788\n",
      "Epoch 8347, Loss: 208.6085854621373, Neurons: 201, Grad norm: 8.40486191485788\n",
      "Epoch 8348, Loss: 208.6086304602172, Neurons: 201, Grad norm: 8.86307420797802\n",
      "Epoch 8348, Loss: 208.6086304602172, Neurons: 201, Grad norm: 8.86307420797802\n",
      "Epoch 8349, Loss: 208.60854039275708, Neurons: 201, Grad norm: 8.990959147193179\n",
      "Epoch 8349, Loss: 208.60854039275708, Neurons: 201, Grad norm: 8.990959147193179\n",
      "Epoch 8350, Loss: 208.60846576111192, Neurons: 201, Grad norm: 8.609357203138288\n",
      "Epoch 8350, Loss: 208.60846576111192, Neurons: 201, Grad norm: 8.609357203138288\n",
      "Epoch 8351, Loss: 208.60832395388766, Neurons: 201, Grad norm: 7.416960194127619\n",
      "Epoch 8351, Loss: 208.60832395388766, Neurons: 201, Grad norm: 7.416960194127619\n",
      "Epoch 8352, Loss: 208.6079403911453, Neurons: 201, Grad norm: 6.102375314444199\n",
      "Epoch 8352, Loss: 208.6079403911453, Neurons: 201, Grad norm: 6.102375314444199\n",
      "Epoch 8353, Loss: 208.60769718066797, Neurons: 201, Grad norm: 4.57184940331242\n",
      "Epoch 8353, Loss: 208.60769718066797, Neurons: 201, Grad norm: 4.57184940331242\n",
      "Epoch 8354, Loss: 208.60757165073684, Neurons: 201, Grad norm: 3.413314436307022\n",
      "Epoch 8354, Loss: 208.60757165073684, Neurons: 201, Grad norm: 3.413314436307022\n",
      "Epoch 8355, Loss: 208.6073503856717, Neurons: 201, Grad norm: 2.49989660567537\n",
      "Epoch 8355, Loss: 208.6073503856717, Neurons: 201, Grad norm: 2.49989660567537\n",
      "Epoch 8356, Loss: 208.60723202920005, Neurons: 201, Grad norm: 2.0659926743077963\n",
      "Epoch 8356, Loss: 208.60723202920005, Neurons: 201, Grad norm: 2.0659926743077963\n",
      "Epoch 8357, Loss: 208.60722557080925, Neurons: 201, Grad norm: 2.3988142948685636\n",
      "Epoch 8357, Loss: 208.60722557080925, Neurons: 201, Grad norm: 2.3988142948685636\n",
      "Epoch 8358, Loss: 208.6071486137777, Neurons: 201, Grad norm: 3.4444717027693548\n",
      "Epoch 8358, Loss: 208.6071486137777, Neurons: 201, Grad norm: 3.4444717027693548\n",
      "Epoch 8359, Loss: 208.60712614289497, Neurons: 201, Grad norm: 5.4327549168004765\n",
      "Epoch 8359, Loss: 208.60712614289497, Neurons: 201, Grad norm: 5.4327549168004765\n",
      "Epoch 8360, Loss: 208.60723834779435, Neurons: 201, Grad norm: 7.890910386342743\n",
      "Epoch 8360, Loss: 208.60723834779435, Neurons: 201, Grad norm: 7.890910386342743\n",
      "Epoch 8361, Loss: 208.6074361435206, Neurons: 201, Grad norm: 9.950108474216638\n",
      "Epoch 8361, Loss: 208.6074361435206, Neurons: 201, Grad norm: 9.950108474216638\n",
      "Epoch 8362, Loss: 208.60772290472008, Neurons: 201, Grad norm: 12.156489321705315\n",
      "Epoch 8362, Loss: 208.60772290472008, Neurons: 201, Grad norm: 12.156489321705315\n",
      "Epoch 8363, Loss: 208.6078977832676, Neurons: 201, Grad norm: 13.82694799430389\n",
      "Epoch 8363, Loss: 208.6078977832676, Neurons: 201, Grad norm: 13.82694799430389\n",
      "Epoch 8364, Loss: 208.60843390595642, Neurons: 201, Grad norm: 14.699688029883045\n",
      "Epoch 8364, Loss: 208.60843390595642, Neurons: 201, Grad norm: 14.699688029883045\n",
      "Epoch 8365, Loss: 208.60863549798017, Neurons: 201, Grad norm: 13.922475533499338\n",
      "Epoch 8365, Loss: 208.60863549798017, Neurons: 201, Grad norm: 13.922475533499338\n",
      "Epoch 8366, Loss: 208.6084700094404, Neurons: 201, Grad norm: 12.196502486513854\n",
      "Epoch 8366, Loss: 208.6084700094404, Neurons: 201, Grad norm: 12.196502486513854\n",
      "Epoch 8367, Loss: 208.60824200688126, Neurons: 201, Grad norm: 9.960934840945423\n",
      "Epoch 8367, Loss: 208.60824200688126, Neurons: 201, Grad norm: 9.960934840945423\n",
      "Epoch 8368, Loss: 208.60821835814087, Neurons: 201, Grad norm: 8.233133439373507\n",
      "Epoch 8368, Loss: 208.60821835814087, Neurons: 201, Grad norm: 8.233133439373507\n",
      "Epoch 8369, Loss: 208.60814660977817, Neurons: 201, Grad norm: 6.5313673170437\n",
      "Epoch 8369, Loss: 208.60814660977817, Neurons: 201, Grad norm: 6.5313673170437\n",
      "Epoch 8370, Loss: 208.6074720435327, Neurons: 201, Grad norm: 5.374826674478658\n",
      "Epoch 8370, Loss: 208.6074720435327, Neurons: 201, Grad norm: 5.374826674478658\n",
      "Epoch 8371, Loss: 208.60671653949134, Neurons: 201, Grad norm: 4.782458972385752\n",
      "Epoch 8371, Loss: 208.60671653949134, Neurons: 201, Grad norm: 4.782458972385752\n",
      "Epoch 8372, Loss: 208.60626281818787, Neurons: 201, Grad norm: 4.798812613712487\n",
      "Epoch 8372, Loss: 208.60626281818787, Neurons: 201, Grad norm: 4.798812613712487\n",
      "Epoch 8373, Loss: 208.60624640967063, Neurons: 201, Grad norm: 4.794712700980996\n",
      "Epoch 8373, Loss: 208.60624640967063, Neurons: 201, Grad norm: 4.794712700980996\n",
      "Epoch 8374, Loss: 208.60636363088204, Neurons: 201, Grad norm: 4.158299361862701\n",
      "Epoch 8374, Loss: 208.60636363088204, Neurons: 201, Grad norm: 4.158299361862701\n",
      "Epoch 8375, Loss: 208.60631087160286, Neurons: 201, Grad norm: 2.7054376058978495\n",
      "Epoch 8375, Loss: 208.60631087160286, Neurons: 201, Grad norm: 2.7054376058978495\n",
      "Epoch 8376, Loss: 208.60591770083698, Neurons: 201, Grad norm: 1.06570147424645\n",
      "Epoch 8376, Loss: 208.60591770083698, Neurons: 201, Grad norm: 1.06570147424645\n",
      "Epoch 8377, Loss: 208.60568892093482, Neurons: 201, Grad norm: 2.086627931005423\n",
      "Epoch 8377, Loss: 208.60568892093482, Neurons: 201, Grad norm: 2.086627931005423\n",
      "Epoch 8378, Loss: 208.6056100366724, Neurons: 201, Grad norm: 3.8512777461797993\n",
      "Epoch 8378, Loss: 208.6056100366724, Neurons: 201, Grad norm: 3.8512777461797993\n",
      "Epoch 8379, Loss: 208.6055973456675, Neurons: 201, Grad norm: 6.063639986173495\n",
      "Epoch 8379, Loss: 208.6055973456675, Neurons: 201, Grad norm: 6.063639986173495\n",
      "Epoch 8380, Loss: 208.60574076431672, Neurons: 201, Grad norm: 8.184657351304017\n",
      "Epoch 8380, Loss: 208.60574076431672, Neurons: 201, Grad norm: 8.184657351304017\n",
      "Epoch 8381, Loss: 208.6060386380902, Neurons: 201, Grad norm: 9.97273964273225\n",
      "Epoch 8381, Loss: 208.6060386380902, Neurons: 201, Grad norm: 9.97273964273225\n",
      "Epoch 8382, Loss: 208.60631447364327, Neurons: 201, Grad norm: 10.861825894987442\n",
      "Epoch 8382, Loss: 208.60631447364327, Neurons: 201, Grad norm: 10.861825894987442\n",
      "Epoch 8383, Loss: 208.606562812152, Neurons: 201, Grad norm: 11.004649382477917\n",
      "Epoch 8383, Loss: 208.606562812152, Neurons: 201, Grad norm: 11.004649382477917\n",
      "Epoch 8384, Loss: 208.60704358185635, Neurons: 201, Grad norm: 10.906422553123637\n",
      "Epoch 8384, Loss: 208.60704358185635, Neurons: 201, Grad norm: 10.906422553123637\n",
      "Epoch 8385, Loss: 208.60731341558827, Neurons: 201, Grad norm: 10.779376879144468\n",
      "Epoch 8385, Loss: 208.60731341558827, Neurons: 201, Grad norm: 10.779376879144468\n",
      "Epoch 8386, Loss: 208.60731323181435, Neurons: 201, Grad norm: 9.780539820363261\n",
      "Epoch 8386, Loss: 208.60731323181435, Neurons: 201, Grad norm: 9.780539820363261\n",
      "Epoch 8387, Loss: 208.60671962559982, Neurons: 201, Grad norm: 7.387887451707284\n",
      "Epoch 8387, Loss: 208.60671962559982, Neurons: 201, Grad norm: 7.387887451707284\n",
      "Epoch 8388, Loss: 208.6056568740597, Neurons: 201, Grad norm: 3.8771164623972885\n",
      "Epoch 8388, Loss: 208.6056568740597, Neurons: 201, Grad norm: 3.8771164623972885\n",
      "Epoch 8389, Loss: 208.60496096219697, Neurons: 201, Grad norm: 1.7991951737489005\n",
      "Epoch 8389, Loss: 208.60496096219697, Neurons: 201, Grad norm: 1.7991951737489005\n",
      "Epoch 8390, Loss: 208.60504931958508, Neurons: 201, Grad norm: 4.468217296862121\n",
      "Epoch 8390, Loss: 208.60504931958508, Neurons: 201, Grad norm: 4.468217296862121\n",
      "Epoch 8391, Loss: 208.60531594370931, Neurons: 201, Grad norm: 7.1772267772908265\n",
      "Epoch 8391, Loss: 208.60531594370931, Neurons: 201, Grad norm: 7.1772267772908265\n",
      "Epoch 8392, Loss: 208.6054207944773, Neurons: 201, Grad norm: 8.78100976591769\n",
      "Epoch 8392, Loss: 208.6054207944773, Neurons: 201, Grad norm: 8.78100976591769\n",
      "Epoch 8393, Loss: 208.60553175408162, Neurons: 201, Grad norm: 9.714221021504777\n",
      "Epoch 8393, Loss: 208.60553175408162, Neurons: 201, Grad norm: 9.714221021504777\n",
      "Epoch 8394, Loss: 208.60549413252605, Neurons: 201, Grad norm: 9.653260622578312\n",
      "Epoch 8394, Loss: 208.60549413252605, Neurons: 201, Grad norm: 9.653260622578312\n",
      "Epoch 8395, Loss: 208.605334837332, Neurons: 201, Grad norm: 8.544998778373948\n",
      "Epoch 8395, Loss: 208.605334837332, Neurons: 201, Grad norm: 8.544998778373948\n",
      "Epoch 8396, Loss: 208.6050713236181, Neurons: 201, Grad norm: 6.264165584510196\n",
      "Epoch 8396, Loss: 208.6050713236181, Neurons: 201, Grad norm: 6.264165584510196\n",
      "Epoch 8397, Loss: 208.6047107836881, Neurons: 201, Grad norm: 3.3284749877607744\n",
      "Epoch 8397, Loss: 208.6047107836881, Neurons: 201, Grad norm: 3.3284749877607744\n",
      "Epoch 8398, Loss: 208.60442646639925, Neurons: 201, Grad norm: 1.2871768450608017\n",
      "Epoch 8398, Loss: 208.60442646639925, Neurons: 201, Grad norm: 1.2871768450608017\n",
      "Epoch 8399, Loss: 208.60420211353403, Neurons: 201, Grad norm: 3.4869163164455363\n",
      "Epoch 8399, Loss: 208.60420211353403, Neurons: 201, Grad norm: 3.4869163164455363\n",
      "Epoch 8400, Loss: 208.60432258080934, Neurons: 201, Grad norm: 5.133576147239207\n",
      "Epoch 8400, Loss: 208.60432258080934, Neurons: 201, Grad norm: 5.133576147239207\n",
      "Epoch 8401, Loss: 208.60441310768863, Neurons: 201, Grad norm: 6.339173444410751\n",
      "Epoch 8401, Loss: 208.60441310768863, Neurons: 201, Grad norm: 6.339173444410751\n",
      "Epoch 8402, Loss: 208.6043339735498, Neurons: 201, Grad norm: 7.289148149102277\n",
      "Epoch 8402, Loss: 208.6043339735498, Neurons: 201, Grad norm: 7.289148149102277\n",
      "Epoch 8403, Loss: 208.60437386885587, Neurons: 201, Grad norm: 7.439052104805222\n",
      "Epoch 8403, Loss: 208.60437386885587, Neurons: 201, Grad norm: 7.439052104805222\n",
      "Epoch 8404, Loss: 208.60455057349418, Neurons: 201, Grad norm: 6.610240021052263\n",
      "Epoch 8404, Loss: 208.60455057349418, Neurons: 201, Grad norm: 6.610240021052263\n",
      "Epoch 8405, Loss: 208.60442055751895, Neurons: 201, Grad norm: 5.7180985283385874\n",
      "Epoch 8405, Loss: 208.60442055751895, Neurons: 201, Grad norm: 5.7180985283385874\n",
      "Epoch 8406, Loss: 208.6040837776641, Neurons: 201, Grad norm: 4.7686284135245\n",
      "Epoch 8406, Loss: 208.6040837776641, Neurons: 201, Grad norm: 4.7686284135245\n",
      "Epoch 8407, Loss: 208.60388231383416, Neurons: 201, Grad norm: 4.187591983836511\n",
      "Epoch 8407, Loss: 208.60388231383416, Neurons: 201, Grad norm: 4.187591983836511\n",
      "Epoch 8408, Loss: 208.60380290937366, Neurons: 201, Grad norm: 4.3017347134535395\n",
      "Epoch 8408, Loss: 208.60380290937366, Neurons: 201, Grad norm: 4.3017347134535395\n",
      "Epoch 8409, Loss: 208.6037422628418, Neurons: 201, Grad norm: 4.002861987012569\n",
      "Epoch 8409, Loss: 208.6037422628418, Neurons: 201, Grad norm: 4.002861987012569\n",
      "Epoch 8410, Loss: 208.60362888552868, Neurons: 201, Grad norm: 3.170553739200984\n",
      "Epoch 8410, Loss: 208.60362888552868, Neurons: 201, Grad norm: 3.170553739200984\n",
      "Epoch 8411, Loss: 208.60347951817658, Neurons: 201, Grad norm: 2.5604626223090876\n",
      "Epoch 8411, Loss: 208.60347951817658, Neurons: 201, Grad norm: 2.5604626223090876\n",
      "Epoch 8412, Loss: 208.60334238673883, Neurons: 201, Grad norm: 2.1122945076967152\n",
      "Epoch 8412, Loss: 208.60334238673883, Neurons: 201, Grad norm: 2.1122945076967152\n",
      "Epoch 8413, Loss: 208.60328424026687, Neurons: 201, Grad norm: 1.7426103066817649\n",
      "Epoch 8413, Loss: 208.60328424026687, Neurons: 201, Grad norm: 1.7426103066817649\n",
      "Epoch 8414, Loss: 208.6032011648614, Neurons: 201, Grad norm: 1.159652876889157\n",
      "Epoch 8414, Loss: 208.6032011648614, Neurons: 201, Grad norm: 1.159652876889157\n",
      "Epoch 8415, Loss: 208.60309448139336, Neurons: 201, Grad norm: 1.1708080835640655\n",
      "Epoch 8415, Loss: 208.60309448139336, Neurons: 201, Grad norm: 1.1708080835640655\n",
      "Epoch 8416, Loss: 208.6031048722213, Neurons: 201, Grad norm: 1.5474272245885379\n",
      "Epoch 8416, Loss: 208.6031048722213, Neurons: 201, Grad norm: 1.5474272245885379\n",
      "Epoch 8417, Loss: 208.6030764023509, Neurons: 201, Grad norm: 2.7968241594303844\n",
      "Epoch 8417, Loss: 208.6030764023509, Neurons: 201, Grad norm: 2.7968241594303844\n",
      "Epoch 8418, Loss: 208.60299643946442, Neurons: 201, Grad norm: 4.030975401639921\n",
      "Epoch 8418, Loss: 208.60299643946442, Neurons: 201, Grad norm: 4.030975401639921\n",
      "Epoch 8419, Loss: 208.6029810203071, Neurons: 201, Grad norm: 5.350283848632684\n",
      "Epoch 8419, Loss: 208.6029810203071, Neurons: 201, Grad norm: 5.350283848632684\n",
      "Epoch 8420, Loss: 208.60306151810875, Neurons: 201, Grad norm: 7.225677994189353\n",
      "Epoch 8420, Loss: 208.60306151810875, Neurons: 201, Grad norm: 7.225677994189353\n",
      "Epoch 8421, Loss: 208.60312213254267, Neurons: 201, Grad norm: 9.12994533684377\n",
      "Epoch 8421, Loss: 208.60312213254267, Neurons: 201, Grad norm: 9.12994533684377\n",
      "Epoch 8422, Loss: 208.60343814166131, Neurons: 201, Grad norm: 11.259760366743553\n",
      "Epoch 8422, Loss: 208.60343814166131, Neurons: 201, Grad norm: 11.259760366743553\n",
      "Epoch 8423, Loss: 208.6037584761151, Neurons: 201, Grad norm: 12.517157718319002\n",
      "Epoch 8423, Loss: 208.6037584761151, Neurons: 201, Grad norm: 12.517157718319002\n",
      "Epoch 8424, Loss: 208.60401946747302, Neurons: 201, Grad norm: 12.776239364073858\n",
      "Epoch 8424, Loss: 208.60401946747302, Neurons: 201, Grad norm: 12.776239364073858\n",
      "Epoch 8425, Loss: 208.60415761955926, Neurons: 201, Grad norm: 12.349837653835595\n",
      "Epoch 8425, Loss: 208.60415761955926, Neurons: 201, Grad norm: 12.349837653835595\n",
      "Epoch 8426, Loss: 208.6040207431737, Neurons: 201, Grad norm: 11.464186111903238\n",
      "Epoch 8426, Loss: 208.6040207431737, Neurons: 201, Grad norm: 11.464186111903238\n",
      "Epoch 8427, Loss: 208.60372642761482, Neurons: 201, Grad norm: 10.339111394342636\n",
      "Epoch 8427, Loss: 208.60372642761482, Neurons: 201, Grad norm: 10.339111394342636\n",
      "Epoch 8428, Loss: 208.6035853239242, Neurons: 201, Grad norm: 8.763781567860297\n",
      "Epoch 8428, Loss: 208.6035853239242, Neurons: 201, Grad norm: 8.763781567860297\n",
      "Epoch 8429, Loss: 208.60320891979333, Neurons: 201, Grad norm: 7.568834529517514\n",
      "Epoch 8429, Loss: 208.60320891979333, Neurons: 201, Grad norm: 7.568834529517514\n",
      "Epoch 8430, Loss: 208.60268551368736, Neurons: 201, Grad norm: 6.3782534392338865\n",
      "Epoch 8430, Loss: 208.60268551368736, Neurons: 201, Grad norm: 6.3782534392338865\n",
      "Epoch 8431, Loss: 208.60237814764665, Neurons: 201, Grad norm: 5.200598422801386\n",
      "Epoch 8431, Loss: 208.60237814764665, Neurons: 201, Grad norm: 5.200598422801386\n",
      "Epoch 8432, Loss: 208.6022032454564, Neurons: 201, Grad norm: 4.82025239277569\n",
      "Epoch 8432, Loss: 208.6022032454564, Neurons: 201, Grad norm: 4.82025239277569\n",
      "Epoch 8433, Loss: 208.60196034773477, Neurons: 201, Grad norm: 4.823963377194811\n",
      "Epoch 8433, Loss: 208.60196034773477, Neurons: 201, Grad norm: 4.823963377194811\n",
      "Epoch 8434, Loss: 208.60196789299138, Neurons: 201, Grad norm: 5.229472478004057\n",
      "Epoch 8434, Loss: 208.60196789299138, Neurons: 201, Grad norm: 5.229472478004057\n",
      "Epoch 8435, Loss: 208.60197722155442, Neurons: 201, Grad norm: 6.131465064164528\n",
      "Epoch 8435, Loss: 208.60197722155442, Neurons: 201, Grad norm: 6.131465064164528\n",
      "Epoch 8436, Loss: 208.60192497354683, Neurons: 201, Grad norm: 7.868529915909414\n",
      "Epoch 8436, Loss: 208.60192497354683, Neurons: 201, Grad norm: 7.868529915909414\n",
      "Epoch 8437, Loss: 208.602161259144, Neurons: 201, Grad norm: 10.295554380161684\n",
      "Epoch 8437, Loss: 208.602161259144, Neurons: 201, Grad norm: 10.295554380161684\n",
      "Epoch 8438, Loss: 208.60279165827797, Neurons: 201, Grad norm: 13.14337645800834\n",
      "Epoch 8438, Loss: 208.60279165827797, Neurons: 201, Grad norm: 13.14337645800834\n",
      "Epoch 8439, Loss: 208.6034097275229, Neurons: 201, Grad norm: 15.40692139114975\n",
      "Epoch 8439, Loss: 208.6034097275229, Neurons: 201, Grad norm: 15.40692139114975\n",
      "Epoch 8440, Loss: 208.60406495377805, Neurons: 201, Grad norm: 16.793751674267245\n",
      "Epoch 8440, Loss: 208.60406495377805, Neurons: 201, Grad norm: 16.793751674267245\n",
      "Epoch 8441, Loss: 208.60449071113283, Neurons: 201, Grad norm: 17.401886559568158\n",
      "Epoch 8441, Loss: 208.60449071113283, Neurons: 201, Grad norm: 17.401886559568158\n",
      "Epoch 8442, Loss: 208.60456638620735, Neurons: 201, Grad norm: 17.609777724883337\n",
      "Epoch 8442, Loss: 208.60456638620735, Neurons: 201, Grad norm: 17.609777724883337\n",
      "Epoch 8443, Loss: 208.604344837636, Neurons: 201, Grad norm: 17.59778587256436\n",
      "Epoch 8443, Loss: 208.604344837636, Neurons: 201, Grad norm: 17.59778587256436\n",
      "Epoch 8444, Loss: 208.6042603682029, Neurons: 201, Grad norm: 16.47615104929449\n",
      "Epoch 8444, Loss: 208.6042603682029, Neurons: 201, Grad norm: 16.47615104929449\n",
      "Epoch 8445, Loss: 208.60374493995178, Neurons: 201, Grad norm: 13.869604653739017\n",
      "Epoch 8445, Loss: 208.60374493995178, Neurons: 201, Grad norm: 13.869604653739017\n",
      "Epoch 8446, Loss: 208.60299490541223, Neurons: 201, Grad norm: 10.622475734815751\n",
      "Epoch 8446, Loss: 208.60299490541223, Neurons: 201, Grad norm: 10.622475734815751\n",
      "Epoch 8447, Loss: 208.6021388898307, Neurons: 201, Grad norm: 6.537720473372291\n",
      "Epoch 8447, Loss: 208.6021388898307, Neurons: 201, Grad norm: 6.537720473372291\n",
      "Epoch 8448, Loss: 208.60150528244785, Neurons: 201, Grad norm: 3.2756921145364575\n",
      "Epoch 8448, Loss: 208.60150528244785, Neurons: 201, Grad norm: 3.2756921145364575\n",
      "Epoch 8449, Loss: 208.60102895903879, Neurons: 201, Grad norm: 2.402058720842926\n",
      "Epoch 8449, Loss: 208.60102895903879, Neurons: 201, Grad norm: 2.402058720842926\n",
      "Epoch 8450, Loss: 208.60088878466377, Neurons: 201, Grad norm: 3.909107401453163\n",
      "Epoch 8450, Loss: 208.60088878466377, Neurons: 201, Grad norm: 3.909107401453163\n",
      "Epoch 8451, Loss: 208.60078178561037, Neurons: 201, Grad norm: 5.487537039963982\n",
      "Epoch 8451, Loss: 208.60078178561037, Neurons: 201, Grad norm: 5.487537039963982\n",
      "Epoch 8452, Loss: 208.6007902843683, Neurons: 201, Grad norm: 6.968307890558965\n",
      "Epoch 8452, Loss: 208.6007902843683, Neurons: 201, Grad norm: 6.968307890558965\n",
      "Epoch 8453, Loss: 208.60082893910104, Neurons: 201, Grad norm: 8.171690750840346\n",
      "Epoch 8453, Loss: 208.60082893910104, Neurons: 201, Grad norm: 8.171690750840346\n",
      "Epoch 8454, Loss: 208.60104171755353, Neurons: 201, Grad norm: 9.567937323864864\n",
      "Epoch 8454, Loss: 208.60104171755353, Neurons: 201, Grad norm: 9.567937323864864\n",
      "Epoch 8455, Loss: 208.60144753765832, Neurons: 201, Grad norm: 10.490726184876333\n",
      "Epoch 8455, Loss: 208.60144753765832, Neurons: 201, Grad norm: 10.490726184876333\n",
      "Epoch 8456, Loss: 208.60210044015534, Neurons: 201, Grad norm: 11.137090888613644\n",
      "Epoch 8456, Loss: 208.60210044015534, Neurons: 201, Grad norm: 11.137090888613644\n",
      "Epoch 8457, Loss: 208.60220600057716, Neurons: 201, Grad norm: 11.083222291856082\n",
      "Epoch 8457, Loss: 208.60220600057716, Neurons: 201, Grad norm: 11.083222291856082\n",
      "Epoch 8458, Loss: 208.60185936385065, Neurons: 201, Grad norm: 10.765364005694405\n",
      "Epoch 8458, Loss: 208.60185936385065, Neurons: 201, Grad norm: 10.765364005694405\n",
      "Epoch 8459, Loss: 208.60121922780218, Neurons: 201, Grad norm: 10.409660602136356\n",
      "Epoch 8459, Loss: 208.60121922780218, Neurons: 201, Grad norm: 10.409660602136356\n",
      "Epoch 8460, Loss: 208.60082127300495, Neurons: 201, Grad norm: 10.14913670348385\n",
      "Epoch 8460, Loss: 208.60082127300495, Neurons: 201, Grad norm: 10.14913670348385\n",
      "Epoch 8461, Loss: 208.6006842242784, Neurons: 201, Grad norm: 9.163152708561503\n",
      "Epoch 8461, Loss: 208.6006842242784, Neurons: 201, Grad norm: 9.163152708561503\n",
      "Epoch 8462, Loss: 208.60051759013382, Neurons: 201, Grad norm: 7.154506381483533\n",
      "Epoch 8462, Loss: 208.60051759013382, Neurons: 201, Grad norm: 7.154506381483533\n",
      "Epoch 8463, Loss: 208.60012061688758, Neurons: 201, Grad norm: 4.3448669203562105\n",
      "Epoch 8463, Loss: 208.60012061688758, Neurons: 201, Grad norm: 4.3448669203562105\n",
      "Epoch 8464, Loss: 208.59965933680016, Neurons: 201, Grad norm: 1.1009194123400605\n",
      "Epoch 8464, Loss: 208.59965933680016, Neurons: 201, Grad norm: 1.1009194123400605\n",
      "Epoch 8465, Loss: 208.5994097700244, Neurons: 201, Grad norm: 2.453571846026556\n",
      "Epoch 8465, Loss: 208.5994097700244, Neurons: 201, Grad norm: 2.453571846026556\n",
      "Epoch 8466, Loss: 208.59942379870222, Neurons: 201, Grad norm: 4.36930515968284\n",
      "Epoch 8466, Loss: 208.59942379870222, Neurons: 201, Grad norm: 4.36930515968284\n",
      "Epoch 8467, Loss: 208.59947314580566, Neurons: 201, Grad norm: 6.1596058271964065\n",
      "Epoch 8467, Loss: 208.59947314580566, Neurons: 201, Grad norm: 6.1596058271964065\n",
      "Epoch 8468, Loss: 208.59947911774967, Neurons: 201, Grad norm: 7.0108720251461305\n",
      "Epoch 8468, Loss: 208.59947911774967, Neurons: 201, Grad norm: 7.0108720251461305\n",
      "Epoch 8469, Loss: 208.59958578230885, Neurons: 201, Grad norm: 7.32920153690207\n",
      "Epoch 8469, Loss: 208.59958578230885, Neurons: 201, Grad norm: 7.32920153690207\n",
      "Epoch 8470, Loss: 208.59971185448563, Neurons: 201, Grad norm: 8.427896638869827\n",
      "Epoch 8470, Loss: 208.59971185448563, Neurons: 201, Grad norm: 8.427896638869827\n",
      "Epoch 8471, Loss: 208.60008347995824, Neurons: 201, Grad norm: 9.286785052532181\n",
      "Epoch 8471, Loss: 208.60008347995824, Neurons: 201, Grad norm: 9.286785052532181\n",
      "Epoch 8472, Loss: 208.6003126523958, Neurons: 201, Grad norm: 9.972358426836463\n",
      "Epoch 8472, Loss: 208.6003126523958, Neurons: 201, Grad norm: 9.972358426836463\n",
      "Epoch 8473, Loss: 208.60054549393152, Neurons: 201, Grad norm: 10.454180177185204\n",
      "Epoch 8473, Loss: 208.60054549393152, Neurons: 201, Grad norm: 10.454180177185204\n",
      "Epoch 8474, Loss: 208.60032644928484, Neurons: 201, Grad norm: 9.785435940760346\n",
      "Epoch 8474, Loss: 208.60032644928484, Neurons: 201, Grad norm: 9.785435940760346\n",
      "Epoch 8475, Loss: 208.60000618832757, Neurons: 201, Grad norm: 8.017774692510141\n",
      "Epoch 8475, Loss: 208.60000618832757, Neurons: 201, Grad norm: 8.017774692510141\n",
      "Epoch 8476, Loss: 208.59925195977814, Neurons: 201, Grad norm: 5.632404729351893\n",
      "Epoch 8476, Loss: 208.59925195977814, Neurons: 201, Grad norm: 5.632404729351893\n",
      "Epoch 8477, Loss: 208.59896559851896, Neurons: 201, Grad norm: 2.7971915262497076\n",
      "Epoch 8477, Loss: 208.59896559851896, Neurons: 201, Grad norm: 2.7971915262497076\n",
      "Epoch 8478, Loss: 208.59882230972957, Neurons: 201, Grad norm: 2.2889615286623743\n",
      "Epoch 8478, Loss: 208.59882230972957, Neurons: 201, Grad norm: 2.2889615286623743\n",
      "Epoch 8479, Loss: 208.59875501263107, Neurons: 201, Grad norm: 4.3636016204454755\n",
      "Epoch 8479, Loss: 208.59875501263107, Neurons: 201, Grad norm: 4.3636016204454755\n",
      "Epoch 8480, Loss: 208.59878265343826, Neurons: 201, Grad norm: 6.213597126500201\n",
      "Epoch 8480, Loss: 208.59878265343826, Neurons: 201, Grad norm: 6.213597126500201\n",
      "Epoch 8481, Loss: 208.5987980598437, Neurons: 201, Grad norm: 6.279607376549707\n",
      "Epoch 8481, Loss: 208.5987980598437, Neurons: 201, Grad norm: 6.279607376549707\n",
      "Epoch 8482, Loss: 208.59871513323884, Neurons: 201, Grad norm: 4.657503434698348\n",
      "Epoch 8482, Loss: 208.59871513323884, Neurons: 201, Grad norm: 4.657503434698348\n",
      "Epoch 8483, Loss: 208.59841663189218, Neurons: 201, Grad norm: 2.2357862096116072\n",
      "Epoch 8483, Loss: 208.59841663189218, Neurons: 201, Grad norm: 2.2357862096116072\n",
      "Epoch 8484, Loss: 208.59821505607468, Neurons: 201, Grad norm: 0.8524017772970734\n",
      "Epoch 8484, Loss: 208.59821505607468, Neurons: 201, Grad norm: 0.8524017772970734\n",
      "Epoch 8485, Loss: 208.59811421699342, Neurons: 201, Grad norm: 2.7593606763546097\n",
      "Epoch 8485, Loss: 208.59811421699342, Neurons: 201, Grad norm: 2.7593606763546097\n",
      "Epoch 8486, Loss: 208.5980936360542, Neurons: 201, Grad norm: 4.268704823060813\n",
      "Epoch 8486, Loss: 208.5980936360542, Neurons: 201, Grad norm: 4.268704823060813\n",
      "Epoch 8487, Loss: 208.598124244988, Neurons: 201, Grad norm: 4.045189907549014\n",
      "Epoch 8487, Loss: 208.598124244988, Neurons: 201, Grad norm: 4.045189907549014\n",
      "Epoch 8488, Loss: 208.59804665700952, Neurons: 201, Grad norm: 3.1859848351208453\n",
      "Epoch 8488, Loss: 208.59804665700952, Neurons: 201, Grad norm: 3.1859848351208453\n",
      "Epoch 8489, Loss: 208.59789591776578, Neurons: 201, Grad norm: 1.5288478499776386\n",
      "Epoch 8489, Loss: 208.59789591776578, Neurons: 201, Grad norm: 1.5288478499776386\n",
      "Epoch 8490, Loss: 208.5977787368518, Neurons: 201, Grad norm: 1.6543324855855102\n",
      "Epoch 8490, Loss: 208.5977787368518, Neurons: 201, Grad norm: 1.6543324855855102\n",
      "Epoch 8491, Loss: 208.5976939943512, Neurons: 201, Grad norm: 2.375599254030923\n",
      "Epoch 8491, Loss: 208.5976939943512, Neurons: 201, Grad norm: 2.375599254030923\n",
      "Epoch 8492, Loss: 208.5976825017006, Neurons: 201, Grad norm: 2.4032588446918095\n",
      "Epoch 8492, Loss: 208.5976825017006, Neurons: 201, Grad norm: 2.4032588446918095\n",
      "Epoch 8493, Loss: 208.5974798437619, Neurons: 201, Grad norm: 1.7052497931492945\n",
      "Epoch 8493, Loss: 208.5974798437619, Neurons: 201, Grad norm: 1.7052497931492945\n",
      "Epoch 8494, Loss: 208.5972416296907, Neurons: 201, Grad norm: 1.2113864031616728\n",
      "Epoch 8494, Loss: 208.5972416296907, Neurons: 201, Grad norm: 1.2113864031616728\n",
      "Epoch 8495, Loss: 208.59718851254846, Neurons: 201, Grad norm: 1.7077251623321643\n",
      "Epoch 8495, Loss: 208.59718851254846, Neurons: 201, Grad norm: 1.7077251623321643\n",
      "Epoch 8496, Loss: 208.59714885411745, Neurons: 201, Grad norm: 1.7931397333131684\n",
      "Epoch 8496, Loss: 208.59714885411745, Neurons: 201, Grad norm: 1.7931397333131684\n",
      "Epoch 8497, Loss: 208.59708765602073, Neurons: 201, Grad norm: 1.427888173394167\n",
      "Epoch 8497, Loss: 208.59708765602073, Neurons: 201, Grad norm: 1.427888173394167\n",
      "Epoch 8498, Loss: 208.59690797921937, Neurons: 201, Grad norm: 0.9192230558083392\n",
      "Epoch 8498, Loss: 208.59690797921937, Neurons: 201, Grad norm: 0.9192230558083392\n",
      "Epoch 8499, Loss: 208.59662347123555, Neurons: 201, Grad norm: 1.2803153016607753\n",
      "Epoch 8499, Loss: 208.59662347123555, Neurons: 201, Grad norm: 1.2803153016607753\n",
      "Epoch 8500, Loss: 208.5964970863269, Neurons: 201, Grad norm: 1.782421533026302\n",
      "Epoch 8500, Loss: 208.5964970863269, Neurons: 201, Grad norm: 1.782421533026302\n",
      "Epoch 8501, Loss: 208.5964348520669, Neurons: 201, Grad norm: 1.975909886466013\n",
      "Epoch 8501, Loss: 208.5964348520669, Neurons: 201, Grad norm: 1.975909886466013\n",
      "Epoch 8502, Loss: 208.5965199652634, Neurons: 201, Grad norm: 1.599299485237789\n",
      "Epoch 8502, Loss: 208.5965199652634, Neurons: 201, Grad norm: 1.599299485237789\n",
      "Epoch 8503, Loss: 208.5964354665581, Neurons: 201, Grad norm: 2.172840384535876\n",
      "Epoch 8503, Loss: 208.5964354665581, Neurons: 201, Grad norm: 2.172840384535876\n",
      "Epoch 8504, Loss: 208.5962431512899, Neurons: 201, Grad norm: 3.371868830873957\n",
      "Epoch 8504, Loss: 208.5962431512899, Neurons: 201, Grad norm: 3.371868830873957\n",
      "Epoch 8505, Loss: 208.59631172194878, Neurons: 201, Grad norm: 3.7148907426162046\n",
      "Epoch 8505, Loss: 208.59631172194878, Neurons: 201, Grad norm: 3.7148907426162046\n",
      "Epoch 8506, Loss: 208.59630410859734, Neurons: 201, Grad norm: 3.1099890655049194\n",
      "Epoch 8506, Loss: 208.59630410859734, Neurons: 201, Grad norm: 3.1099890655049194\n",
      "Epoch 8507, Loss: 208.59619721446805, Neurons: 201, Grad norm: 1.459075163418696\n",
      "Epoch 8507, Loss: 208.59619721446805, Neurons: 201, Grad norm: 1.459075163418696\n",
      "Epoch 8508, Loss: 208.5960457985453, Neurons: 201, Grad norm: 1.2084379075832323\n",
      "Epoch 8508, Loss: 208.5960457985453, Neurons: 201, Grad norm: 1.2084379075832323\n",
      "Epoch 8509, Loss: 208.59580888853367, Neurons: 201, Grad norm: 2.7529472698202864\n",
      "Epoch 8509, Loss: 208.59580888853367, Neurons: 201, Grad norm: 2.7529472698202864\n",
      "Epoch 8510, Loss: 208.5958248441525, Neurons: 201, Grad norm: 4.004537820663089\n",
      "Epoch 8510, Loss: 208.5958248441525, Neurons: 201, Grad norm: 4.004537820663089\n",
      "Epoch 8511, Loss: 208.595820097642, Neurons: 201, Grad norm: 4.2679748194485585\n",
      "Epoch 8511, Loss: 208.595820097642, Neurons: 201, Grad norm: 4.2679748194485585\n",
      "Epoch 8512, Loss: 208.59568085121606, Neurons: 201, Grad norm: 3.5331403124266036\n",
      "Epoch 8512, Loss: 208.59568085121606, Neurons: 201, Grad norm: 3.5331403124266036\n",
      "Epoch 8513, Loss: 208.59556609251405, Neurons: 201, Grad norm: 2.4869393898228314\n",
      "Epoch 8513, Loss: 208.59556609251405, Neurons: 201, Grad norm: 2.4869393898228314\n",
      "Epoch 8514, Loss: 208.59545166737573, Neurons: 201, Grad norm: 1.1616526237348679\n",
      "Epoch 8514, Loss: 208.59545166737573, Neurons: 201, Grad norm: 1.1616526237348679\n",
      "Epoch 8515, Loss: 208.5953726196274, Neurons: 201, Grad norm: 1.1356752133161547\n",
      "Epoch 8515, Loss: 208.5953726196274, Neurons: 201, Grad norm: 1.1356752133161547\n",
      "Epoch 8516, Loss: 208.5952832037635, Neurons: 201, Grad norm: 1.9074611745772363\n",
      "Epoch 8516, Loss: 208.5952832037635, Neurons: 201, Grad norm: 1.9074611745772363\n",
      "Epoch 8517, Loss: 208.59527246197297, Neurons: 201, Grad norm: 2.005088736539133\n",
      "Epoch 8517, Loss: 208.59527246197297, Neurons: 201, Grad norm: 2.005088736539133\n",
      "Epoch 8518, Loss: 208.59519270886184, Neurons: 201, Grad norm: 1.8571196639844683\n",
      "Epoch 8518, Loss: 208.59519270886184, Neurons: 201, Grad norm: 1.8571196639844683\n",
      "Epoch 8519, Loss: 208.5950744614438, Neurons: 201, Grad norm: 1.617315382762473\n",
      "Epoch 8519, Loss: 208.5950744614438, Neurons: 201, Grad norm: 1.617315382762473\n",
      "Epoch 8520, Loss: 208.59500472569812, Neurons: 201, Grad norm: 0.8616342265939722\n",
      "Epoch 8520, Loss: 208.59500472569812, Neurons: 201, Grad norm: 0.8616342265939722\n",
      "Epoch 8521, Loss: 208.5948892924598, Neurons: 201, Grad norm: 0.6320776162444144\n",
      "Epoch 8521, Loss: 208.5948892924598, Neurons: 201, Grad norm: 0.6320776162444144\n",
      "Epoch 8522, Loss: 208.59481546649803, Neurons: 201, Grad norm: 1.1187625257420244\n",
      "Epoch 8522, Loss: 208.59481546649803, Neurons: 201, Grad norm: 1.1187625257420244\n",
      "Epoch 8523, Loss: 208.5947504357601, Neurons: 201, Grad norm: 1.7783828415868008\n",
      "Epoch 8523, Loss: 208.5947504357601, Neurons: 201, Grad norm: 1.7783828415868008\n",
      "Epoch 8524, Loss: 208.5946936475724, Neurons: 201, Grad norm: 2.265465767654003\n",
      "Epoch 8524, Loss: 208.5946936475724, Neurons: 201, Grad norm: 2.265465767654003\n",
      "Epoch 8525, Loss: 208.5946679665651, Neurons: 201, Grad norm: 2.5067968319044955\n",
      "Epoch 8525, Loss: 208.5946679665651, Neurons: 201, Grad norm: 2.5067968319044955\n",
      "Epoch 8526, Loss: 208.5946229170861, Neurons: 201, Grad norm: 2.9928239590154733\n",
      "Epoch 8526, Loss: 208.5946229170861, Neurons: 201, Grad norm: 2.9928239590154733\n",
      "Epoch 8527, Loss: 208.5945697502962, Neurons: 201, Grad norm: 3.3166889281651777\n",
      "Epoch 8527, Loss: 208.5945697502962, Neurons: 201, Grad norm: 3.3166889281651777\n",
      "Epoch 8528, Loss: 208.5946393765159, Neurons: 201, Grad norm: 3.3639496247054073\n",
      "Epoch 8528, Loss: 208.5946393765159, Neurons: 201, Grad norm: 3.3639496247054073\n",
      "Epoch 8529, Loss: 208.5946008825796, Neurons: 201, Grad norm: 3.8850619323595974\n",
      "Epoch 8529, Loss: 208.5946008825796, Neurons: 201, Grad norm: 3.8850619323595974\n",
      "Epoch 8530, Loss: 208.59458952128625, Neurons: 201, Grad norm: 4.086646173043329\n",
      "Epoch 8530, Loss: 208.59458952128625, Neurons: 201, Grad norm: 4.086646173043329\n",
      "Epoch 8531, Loss: 208.59456310943946, Neurons: 201, Grad norm: 4.092795892684974\n",
      "Epoch 8531, Loss: 208.59456310943946, Neurons: 201, Grad norm: 4.092795892684974\n",
      "Epoch 8532, Loss: 208.59440587894608, Neurons: 201, Grad norm: 3.962278202155691\n",
      "Epoch 8532, Loss: 208.59440587894608, Neurons: 201, Grad norm: 3.962278202155691\n",
      "Epoch 8533, Loss: 208.59417121661622, Neurons: 201, Grad norm: 3.5198733743917225\n",
      "Epoch 8533, Loss: 208.59417121661622, Neurons: 201, Grad norm: 3.5198733743917225\n",
      "Epoch 8534, Loss: 208.59406338761247, Neurons: 201, Grad norm: 2.4155392910552145\n",
      "Epoch 8534, Loss: 208.59406338761247, Neurons: 201, Grad norm: 2.4155392910552145\n",
      "Epoch 8535, Loss: 208.59395538595814, Neurons: 201, Grad norm: 1.220562889701056\n",
      "Epoch 8535, Loss: 208.59395538595814, Neurons: 201, Grad norm: 1.220562889701056\n",
      "Epoch 8536, Loss: 208.59385670905942, Neurons: 201, Grad norm: 1.128411001623063\n",
      "Epoch 8536, Loss: 208.59385670905942, Neurons: 201, Grad norm: 1.128411001623063\n",
      "Epoch 8537, Loss: 208.59376988116378, Neurons: 201, Grad norm: 2.5611824200750086\n",
      "Epoch 8537, Loss: 208.59376988116378, Neurons: 201, Grad norm: 2.5611824200750086\n",
      "Epoch 8538, Loss: 208.59371556155295, Neurons: 201, Grad norm: 3.5456765829199326\n",
      "Epoch 8538, Loss: 208.59371556155295, Neurons: 201, Grad norm: 3.5456765829199326\n",
      "Epoch 8539, Loss: 208.5936925005281, Neurons: 201, Grad norm: 3.802338330750186\n",
      "Epoch 8539, Loss: 208.5936925005281, Neurons: 201, Grad norm: 3.802338330750186\n",
      "Epoch 8540, Loss: 208.59371301030586, Neurons: 201, Grad norm: 3.761037276141823\n",
      "Epoch 8540, Loss: 208.59371301030586, Neurons: 201, Grad norm: 3.761037276141823\n",
      "Epoch 8541, Loss: 208.59358480233803, Neurons: 201, Grad norm: 2.809765135952461\n",
      "Epoch 8541, Loss: 208.59358480233803, Neurons: 201, Grad norm: 2.809765135952461\n",
      "Epoch 8542, Loss: 208.5934840359491, Neurons: 201, Grad norm: 1.5178851313359145\n",
      "Epoch 8542, Loss: 208.5934840359491, Neurons: 201, Grad norm: 1.5178851313359145\n",
      "Epoch 8543, Loss: 208.59337047000614, Neurons: 201, Grad norm: 0.9199023723981675\n",
      "Epoch 8543, Loss: 208.59337047000614, Neurons: 201, Grad norm: 0.9199023723981675\n",
      "Epoch 8544, Loss: 208.59328053367219, Neurons: 201, Grad norm: 1.4894717813160983\n",
      "Epoch 8544, Loss: 208.59328053367219, Neurons: 201, Grad norm: 1.4894717813160983\n",
      "Epoch 8545, Loss: 208.59328441722587, Neurons: 201, Grad norm: 1.6871516325094549\n",
      "Epoch 8545, Loss: 208.59328441722587, Neurons: 201, Grad norm: 1.6871516325094549\n",
      "Epoch 8546, Loss: 208.59317802445318, Neurons: 201, Grad norm: 1.6015414134420476\n",
      "Epoch 8546, Loss: 208.59317802445318, Neurons: 201, Grad norm: 1.6015414134420476\n",
      "Epoch 8547, Loss: 208.59308574445524, Neurons: 201, Grad norm: 1.415108798986634\n",
      "Epoch 8547, Loss: 208.59308574445524, Neurons: 201, Grad norm: 1.415108798986634\n",
      "Epoch 8548, Loss: 208.59305519920125, Neurons: 201, Grad norm: 1.6616017964515906\n",
      "Epoch 8548, Loss: 208.59305519920125, Neurons: 201, Grad norm: 1.6616017964515906\n",
      "Epoch 8549, Loss: 208.5929945568225, Neurons: 201, Grad norm: 1.9882399678512022\n",
      "Epoch 8549, Loss: 208.5929945568225, Neurons: 201, Grad norm: 1.9882399678512022\n",
      "Epoch 8550, Loss: 208.59296909035348, Neurons: 201, Grad norm: 2.105880126391821\n",
      "Epoch 8550, Loss: 208.59296909035348, Neurons: 201, Grad norm: 2.105880126391821\n",
      "Epoch 8551, Loss: 208.59297542592728, Neurons: 201, Grad norm: 2.8788179852417013\n",
      "Epoch 8551, Loss: 208.59297542592728, Neurons: 201, Grad norm: 2.8788179852417013\n",
      "Epoch 8552, Loss: 208.59285123339694, Neurons: 201, Grad norm: 3.1625455871112513\n",
      "Epoch 8552, Loss: 208.59285123339694, Neurons: 201, Grad norm: 3.1625455871112513\n",
      "Epoch 8553, Loss: 208.59278471054444, Neurons: 201, Grad norm: 3.5169359592167995\n",
      "Epoch 8553, Loss: 208.59278471054444, Neurons: 201, Grad norm: 3.5169359592167995\n",
      "Epoch 8554, Loss: 208.5927124818704, Neurons: 201, Grad norm: 3.532588444779988\n",
      "Epoch 8554, Loss: 208.5927124818704, Neurons: 201, Grad norm: 3.532588444779988\n",
      "Epoch 8555, Loss: 208.59260479839173, Neurons: 201, Grad norm: 2.9603658103487103\n",
      "Epoch 8555, Loss: 208.59260479839173, Neurons: 201, Grad norm: 2.9603658103487103\n",
      "Epoch 8556, Loss: 208.59247952618333, Neurons: 201, Grad norm: 2.3333441369772485\n",
      "Epoch 8556, Loss: 208.59247952618333, Neurons: 201, Grad norm: 2.3333441369772485\n",
      "Epoch 8557, Loss: 208.5923789335652, Neurons: 201, Grad norm: 1.5973270889164324\n",
      "Epoch 8557, Loss: 208.5923789335652, Neurons: 201, Grad norm: 1.5973270889164324\n",
      "Epoch 8558, Loss: 208.5923746228793, Neurons: 201, Grad norm: 1.2350861856271067\n",
      "Epoch 8558, Loss: 208.5923746228793, Neurons: 201, Grad norm: 1.2350861856271067\n",
      "Epoch 8559, Loss: 208.59232332278125, Neurons: 201, Grad norm: 2.634633015727549\n",
      "Epoch 8559, Loss: 208.59232332278125, Neurons: 201, Grad norm: 2.634633015727549\n",
      "Epoch 8560, Loss: 208.59219637211817, Neurons: 201, Grad norm: 3.8667573836144786\n",
      "Epoch 8560, Loss: 208.59219637211817, Neurons: 201, Grad norm: 3.8667573836144786\n",
      "Epoch 8561, Loss: 208.59232185033912, Neurons: 201, Grad norm: 5.059902629759601\n",
      "Epoch 8561, Loss: 208.59232185033912, Neurons: 201, Grad norm: 5.059902629759601\n",
      "Epoch 8562, Loss: 208.59237396586425, Neurons: 201, Grad norm: 6.1400353447383464\n",
      "Epoch 8562, Loss: 208.59237396586425, Neurons: 201, Grad norm: 6.1400353447383464\n",
      "Epoch 8563, Loss: 208.59234532954093, Neurons: 201, Grad norm: 6.668352828900714\n",
      "Epoch 8563, Loss: 208.59234532954093, Neurons: 201, Grad norm: 6.668352828900714\n",
      "Epoch 8564, Loss: 208.59247154727285, Neurons: 201, Grad norm: 7.199323237205146\n",
      "Epoch 8564, Loss: 208.59247154727285, Neurons: 201, Grad norm: 7.199323237205146\n",
      "Epoch 8565, Loss: 208.5925475555703, Neurons: 201, Grad norm: 7.3232260275497\n",
      "Epoch 8565, Loss: 208.5925475555703, Neurons: 201, Grad norm: 7.3232260275497\n",
      "Epoch 8566, Loss: 208.5924901124689, Neurons: 201, Grad norm: 7.000463853645103\n",
      "Epoch 8566, Loss: 208.5924901124689, Neurons: 201, Grad norm: 7.000463853645103\n",
      "Epoch 8567, Loss: 208.59226402434265, Neurons: 201, Grad norm: 6.037713310239462\n",
      "Epoch 8567, Loss: 208.59226402434265, Neurons: 201, Grad norm: 6.037713310239462\n",
      "Epoch 8568, Loss: 208.59213089648495, Neurons: 201, Grad norm: 4.95988329969797\n",
      "Epoch 8568, Loss: 208.59213089648495, Neurons: 201, Grad norm: 4.95988329969797\n",
      "Epoch 8569, Loss: 208.59190701283177, Neurons: 201, Grad norm: 3.648001695565255\n",
      "Epoch 8569, Loss: 208.59190701283177, Neurons: 201, Grad norm: 3.648001695565255\n",
      "Epoch 8570, Loss: 208.59164540401693, Neurons: 201, Grad norm: 2.0441608484253586\n",
      "Epoch 8570, Loss: 208.59164540401693, Neurons: 201, Grad norm: 2.0441608484253586\n",
      "Epoch 8571, Loss: 208.5914700819526, Neurons: 201, Grad norm: 0.9133730851220562\n",
      "Epoch 8571, Loss: 208.5914700819526, Neurons: 201, Grad norm: 0.9133730851220562\n",
      "Epoch 8572, Loss: 208.5913132967044, Neurons: 201, Grad norm: 0.7946631057656718\n",
      "Epoch 8572, Loss: 208.5913132967044, Neurons: 201, Grad norm: 0.7946631057656718\n",
      "Epoch 8573, Loss: 208.5911788176243, Neurons: 201, Grad norm: 1.3499904686390118\n",
      "Epoch 8573, Loss: 208.5911788176243, Neurons: 201, Grad norm: 1.3499904686390118\n",
      "Epoch 8574, Loss: 208.59113936964224, Neurons: 201, Grad norm: 1.913835724070043\n",
      "Epoch 8574, Loss: 208.59113936964224, Neurons: 201, Grad norm: 1.913835724070043\n",
      "Epoch 8575, Loss: 208.59116069389466, Neurons: 201, Grad norm: 2.460757335377118\n",
      "Epoch 8575, Loss: 208.59116069389466, Neurons: 201, Grad norm: 2.460757335377118\n",
      "Epoch 8576, Loss: 208.5911477597606, Neurons: 201, Grad norm: 2.9353823451201437\n",
      "Epoch 8576, Loss: 208.5911477597606, Neurons: 201, Grad norm: 2.9353823451201437\n",
      "Epoch 8577, Loss: 208.59114321361335, Neurons: 201, Grad norm: 3.653810715658698\n",
      "Epoch 8577, Loss: 208.59114321361335, Neurons: 201, Grad norm: 3.653810715658698\n",
      "Epoch 8578, Loss: 208.5911696970224, Neurons: 201, Grad norm: 4.127060288822554\n",
      "Epoch 8578, Loss: 208.5911696970224, Neurons: 201, Grad norm: 4.127060288822554\n",
      "Epoch 8579, Loss: 208.59121287873174, Neurons: 201, Grad norm: 5.098114139810814\n",
      "Epoch 8579, Loss: 208.59121287873174, Neurons: 201, Grad norm: 5.098114139810814\n",
      "Epoch 8580, Loss: 208.5912917791455, Neurons: 201, Grad norm: 6.019482265897981\n",
      "Epoch 8580, Loss: 208.5912917791455, Neurons: 201, Grad norm: 6.019482265897981\n",
      "Epoch 8581, Loss: 208.5914649572773, Neurons: 201, Grad norm: 6.8638834967592\n",
      "Epoch 8581, Loss: 208.5914649572773, Neurons: 201, Grad norm: 6.8638834967592\n",
      "Epoch 8582, Loss: 208.5915170061964, Neurons: 201, Grad norm: 7.875011042358854\n",
      "Epoch 8582, Loss: 208.5915170061964, Neurons: 201, Grad norm: 7.875011042358854\n",
      "Epoch 8583, Loss: 208.59155767251247, Neurons: 201, Grad norm: 8.700808799668636\n",
      "Epoch 8583, Loss: 208.59155767251247, Neurons: 201, Grad norm: 8.700808799668636\n",
      "Epoch 8584, Loss: 208.59152804483764, Neurons: 201, Grad norm: 9.506338480832822\n",
      "Epoch 8584, Loss: 208.59152804483764, Neurons: 201, Grad norm: 9.506338480832822\n",
      "Epoch 8585, Loss: 208.59154544259277, Neurons: 201, Grad norm: 9.845029710399682\n",
      "Epoch 8585, Loss: 208.59154544259277, Neurons: 201, Grad norm: 9.845029710399682\n",
      "Epoch 8586, Loss: 208.59154101564653, Neurons: 201, Grad norm: 9.863203907046598\n",
      "Epoch 8586, Loss: 208.59154101564653, Neurons: 201, Grad norm: 9.863203907046598\n",
      "Epoch 8587, Loss: 208.59150548761437, Neurons: 201, Grad norm: 9.59131827415805\n",
      "Epoch 8587, Loss: 208.59150548761437, Neurons: 201, Grad norm: 9.59131827415805\n",
      "Epoch 8588, Loss: 208.59146495468877, Neurons: 201, Grad norm: 8.836000358693651\n",
      "Epoch 8588, Loss: 208.59146495468877, Neurons: 201, Grad norm: 8.836000358693651\n",
      "Epoch 8589, Loss: 208.59132871483345, Neurons: 201, Grad norm: 7.663929871035157\n",
      "Epoch 8589, Loss: 208.59132871483345, Neurons: 201, Grad norm: 7.663929871035157\n",
      "Epoch 8590, Loss: 208.59115924027734, Neurons: 201, Grad norm: 6.28947653604576\n",
      "Epoch 8590, Loss: 208.59115924027734, Neurons: 201, Grad norm: 6.28947653604576\n",
      "Epoch 8591, Loss: 208.5908520150255, Neurons: 201, Grad norm: 5.329328910020739\n",
      "Epoch 8591, Loss: 208.5908520150255, Neurons: 201, Grad norm: 5.329328910020739\n",
      "Epoch 8592, Loss: 208.5905442506459, Neurons: 201, Grad norm: 4.374694267666763\n",
      "Epoch 8592, Loss: 208.5905442506459, Neurons: 201, Grad norm: 4.374694267666763\n",
      "Epoch 8593, Loss: 208.5903286687645, Neurons: 201, Grad norm: 3.6193285359676666\n",
      "Epoch 8593, Loss: 208.5903286687645, Neurons: 201, Grad norm: 3.6193285359676666\n",
      "Epoch 8594, Loss: 208.59005251054475, Neurons: 201, Grad norm: 3.1206347887376418\n",
      "Epoch 8594, Loss: 208.59005251054475, Neurons: 201, Grad norm: 3.1206347887376418\n",
      "Epoch 8595, Loss: 208.58976548548318, Neurons: 201, Grad norm: 2.8034075164982135\n",
      "Epoch 8595, Loss: 208.58976548548318, Neurons: 201, Grad norm: 2.8034075164982135\n",
      "Epoch 8596, Loss: 208.58970818991943, Neurons: 201, Grad norm: 2.1981077453524316\n",
      "Epoch 8596, Loss: 208.58970818991943, Neurons: 201, Grad norm: 2.1981077453524316\n",
      "Epoch 8597, Loss: 208.58970776907623, Neurons: 201, Grad norm: 1.975214522424733\n",
      "Epoch 8597, Loss: 208.58970776907623, Neurons: 201, Grad norm: 1.975214522424733\n",
      "Epoch 8598, Loss: 208.5895869187557, Neurons: 201, Grad norm: 2.1949074448835475\n",
      "Epoch 8598, Loss: 208.5895869187557, Neurons: 201, Grad norm: 2.1949074448835475\n",
      "Epoch 8599, Loss: 208.58960330042717, Neurons: 201, Grad norm: 3.445845807236287\n",
      "Epoch 8599, Loss: 208.58960330042717, Neurons: 201, Grad norm: 3.445845807236287\n",
      "Epoch 8600, Loss: 208.58964370767754, Neurons: 201, Grad norm: 5.191562429022818\n",
      "Epoch 8600, Loss: 208.58964370767754, Neurons: 201, Grad norm: 5.191562429022818\n",
      "Epoch 8601, Loss: 208.58967565167617, Neurons: 201, Grad norm: 6.796181786212121\n",
      "Epoch 8601, Loss: 208.58967565167617, Neurons: 201, Grad norm: 6.796181786212121\n",
      "Epoch 8602, Loss: 208.5896609142209, Neurons: 201, Grad norm: 8.007837923550854\n",
      "Epoch 8602, Loss: 208.5896609142209, Neurons: 201, Grad norm: 8.007837923550854\n",
      "Epoch 8603, Loss: 208.58980705727976, Neurons: 201, Grad norm: 8.263685147416886\n",
      "Epoch 8603, Loss: 208.58980705727976, Neurons: 201, Grad norm: 8.263685147416886\n",
      "Epoch 8604, Loss: 208.58980923116226, Neurons: 201, Grad norm: 7.4887917060648554\n",
      "Epoch 8604, Loss: 208.58980923116226, Neurons: 201, Grad norm: 7.4887917060648554\n",
      "Epoch 8605, Loss: 208.58956941486625, Neurons: 201, Grad norm: 6.162136667931525\n",
      "Epoch 8605, Loss: 208.58956941486625, Neurons: 201, Grad norm: 6.162136667931525\n",
      "Epoch 8606, Loss: 208.58928055051751, Neurons: 201, Grad norm: 4.377520219063746\n",
      "Epoch 8606, Loss: 208.58928055051751, Neurons: 201, Grad norm: 4.377520219063746\n",
      "Epoch 8607, Loss: 208.5891250350331, Neurons: 201, Grad norm: 3.149972163350065\n",
      "Epoch 8607, Loss: 208.5891250350331, Neurons: 201, Grad norm: 3.149972163350065\n",
      "Epoch 8608, Loss: 208.5890205358439, Neurons: 201, Grad norm: 2.2338402323812083\n",
      "Epoch 8608, Loss: 208.5890205358439, Neurons: 201, Grad norm: 2.2338402323812083\n",
      "Epoch 8609, Loss: 208.5888509839701, Neurons: 201, Grad norm: 1.305667870425781\n",
      "Epoch 8609, Loss: 208.5888509839701, Neurons: 201, Grad norm: 1.305667870425781\n",
      "Epoch 8610, Loss: 208.58865159471748, Neurons: 201, Grad norm: 0.9410321187471102\n",
      "Epoch 8610, Loss: 208.58865159471748, Neurons: 201, Grad norm: 0.9410321187471102\n",
      "Epoch 8611, Loss: 208.58859188066734, Neurons: 201, Grad norm: 0.6479799975511388\n",
      "Epoch 8611, Loss: 208.58859188066734, Neurons: 201, Grad norm: 0.6479799975511388\n",
      "Epoch 8612, Loss: 208.58852522238865, Neurons: 201, Grad norm: 0.6636987362687079\n",
      "Epoch 8612, Loss: 208.58852522238865, Neurons: 201, Grad norm: 0.6636987362687079\n",
      "Epoch 8613, Loss: 208.58847938321657, Neurons: 201, Grad norm: 0.8628302743878704\n",
      "Epoch 8613, Loss: 208.58847938321657, Neurons: 201, Grad norm: 0.8628302743878704\n",
      "Epoch 8614, Loss: 208.588406115415, Neurons: 201, Grad norm: 1.3743277252139283\n",
      "Epoch 8614, Loss: 208.588406115415, Neurons: 201, Grad norm: 1.3743277252139283\n",
      "Epoch 8615, Loss: 208.5882823798346, Neurons: 201, Grad norm: 1.9495450902636455\n",
      "Epoch 8615, Loss: 208.5882823798346, Neurons: 201, Grad norm: 1.9495450902636455\n",
      "Epoch 8616, Loss: 208.58825533693962, Neurons: 201, Grad norm: 2.3592362956644757\n",
      "Epoch 8616, Loss: 208.58825533693962, Neurons: 201, Grad norm: 2.3592362956644757\n",
      "Epoch 8617, Loss: 208.58820963633877, Neurons: 201, Grad norm: 2.4851393669115236\n",
      "Epoch 8617, Loss: 208.58820963633877, Neurons: 201, Grad norm: 2.4851393669115236\n",
      "Epoch 8618, Loss: 208.5881085015465, Neurons: 201, Grad norm: 2.650788499290492\n",
      "Epoch 8618, Loss: 208.5881085015465, Neurons: 201, Grad norm: 2.650788499290492\n",
      "Epoch 8619, Loss: 208.58806888563393, Neurons: 201, Grad norm: 2.886899413641653\n",
      "Epoch 8619, Loss: 208.58806888563393, Neurons: 201, Grad norm: 2.886899413641653\n",
      "Epoch 8620, Loss: 208.58800198471764, Neurons: 201, Grad norm: 2.8035652484921716\n",
      "Epoch 8620, Loss: 208.58800198471764, Neurons: 201, Grad norm: 2.8035652484921716\n",
      "Epoch 8621, Loss: 208.58792375586717, Neurons: 201, Grad norm: 3.1903672121624833\n",
      "Epoch 8621, Loss: 208.58792375586717, Neurons: 201, Grad norm: 3.1903672121624833\n",
      "Epoch 8622, Loss: 208.5878980753914, Neurons: 201, Grad norm: 3.4837249737730027\n",
      "Epoch 8622, Loss: 208.5878980753914, Neurons: 201, Grad norm: 3.4837249737730027\n",
      "Epoch 8623, Loss: 208.58783894612662, Neurons: 201, Grad norm: 4.114348571551224\n",
      "Epoch 8623, Loss: 208.58783894612662, Neurons: 201, Grad norm: 4.114348571551224\n",
      "Epoch 8624, Loss: 208.5878561284389, Neurons: 201, Grad norm: 4.822993347597416\n",
      "Epoch 8624, Loss: 208.5878561284389, Neurons: 201, Grad norm: 4.822993347597416\n",
      "Epoch 8625, Loss: 208.58793310600672, Neurons: 201, Grad norm: 6.170990756119766\n",
      "Epoch 8625, Loss: 208.58793310600672, Neurons: 201, Grad norm: 6.170990756119766\n",
      "Epoch 8626, Loss: 208.5880731705764, Neurons: 201, Grad norm: 7.623587807951252\n",
      "Epoch 8626, Loss: 208.5880731705764, Neurons: 201, Grad norm: 7.623587807951252\n",
      "Epoch 8627, Loss: 208.58828954658642, Neurons: 201, Grad norm: 9.070200680224948\n",
      "Epoch 8627, Loss: 208.58828954658642, Neurons: 201, Grad norm: 9.070200680224948\n",
      "Epoch 8628, Loss: 208.58852423019638, Neurons: 201, Grad norm: 10.845861809141347\n",
      "Epoch 8628, Loss: 208.58852423019638, Neurons: 201, Grad norm: 10.845861809141347\n",
      "Epoch 8629, Loss: 208.58883110284253, Neurons: 201, Grad norm: 12.160485602223728\n",
      "Epoch 8629, Loss: 208.58883110284253, Neurons: 201, Grad norm: 12.160485602223728\n",
      "Epoch 8630, Loss: 208.58917725122535, Neurons: 201, Grad norm: 13.034234615860044\n",
      "Epoch 8630, Loss: 208.58917725122535, Neurons: 201, Grad norm: 13.034234615860044\n",
      "Epoch 8631, Loss: 208.5894073015429, Neurons: 201, Grad norm: 13.847430864852127\n",
      "Epoch 8631, Loss: 208.5894073015429, Neurons: 201, Grad norm: 13.847430864852127\n",
      "Epoch 8632, Loss: 208.58949089251237, Neurons: 201, Grad norm: 13.97854850564444\n",
      "Epoch 8632, Loss: 208.58949089251237, Neurons: 201, Grad norm: 13.97854850564444\n",
      "Epoch 8633, Loss: 208.58954857297104, Neurons: 201, Grad norm: 13.466989607685067\n",
      "Epoch 8633, Loss: 208.58954857297104, Neurons: 201, Grad norm: 13.466989607685067\n",
      "Epoch 8634, Loss: 208.58949048515487, Neurons: 201, Grad norm: 12.703486870623886\n",
      "Epoch 8634, Loss: 208.58949048515487, Neurons: 201, Grad norm: 12.703486870623886\n",
      "Epoch 8635, Loss: 208.58908632230805, Neurons: 201, Grad norm: 11.295925281330673\n",
      "Epoch 8635, Loss: 208.58908632230805, Neurons: 201, Grad norm: 11.295925281330673\n",
      "Epoch 8636, Loss: 208.58852898139733, Neurons: 201, Grad norm: 9.20793172863452\n",
      "Epoch 8636, Loss: 208.58852898139733, Neurons: 201, Grad norm: 9.20793172863452\n",
      "Epoch 8637, Loss: 208.58791156536148, Neurons: 201, Grad norm: 7.2058644283379065\n",
      "Epoch 8637, Loss: 208.58791156536148, Neurons: 201, Grad norm: 7.2058644283379065\n",
      "Epoch 8638, Loss: 208.58733113089983, Neurons: 201, Grad norm: 4.634561608853319\n",
      "Epoch 8638, Loss: 208.58733113089983, Neurons: 201, Grad norm: 4.634561608853319\n",
      "Epoch 8639, Loss: 208.58686835934432, Neurons: 201, Grad norm: 1.8675359461097596\n",
      "Epoch 8639, Loss: 208.58686835934432, Neurons: 201, Grad norm: 1.8675359461097596\n",
      "Epoch 8640, Loss: 208.58658052058453, Neurons: 201, Grad norm: 1.146016176974514\n",
      "Epoch 8640, Loss: 208.58658052058453, Neurons: 201, Grad norm: 1.146016176974514\n",
      "Epoch 8641, Loss: 208.5864995661581, Neurons: 201, Grad norm: 3.724719523952176\n",
      "Epoch 8641, Loss: 208.5864995661581, Neurons: 201, Grad norm: 3.724719523952176\n",
      "Epoch 8642, Loss: 208.5864994561005, Neurons: 201, Grad norm: 5.937217387951668\n",
      "Epoch 8642, Loss: 208.5864994561005, Neurons: 201, Grad norm: 5.937217387951668\n",
      "Epoch 8643, Loss: 208.58677505188942, Neurons: 201, Grad norm: 7.83657008702486\n",
      "Epoch 8643, Loss: 208.58677505188942, Neurons: 201, Grad norm: 7.83657008702486\n",
      "Epoch 8644, Loss: 208.58703758835335, Neurons: 201, Grad norm: 9.669945981398431\n",
      "Epoch 8644, Loss: 208.58703758835335, Neurons: 201, Grad norm: 9.669945981398431\n",
      "Epoch 8645, Loss: 208.58733422881593, Neurons: 201, Grad norm: 10.749633736039788\n",
      "Epoch 8645, Loss: 208.58733422881593, Neurons: 201, Grad norm: 10.749633736039788\n",
      "Epoch 8646, Loss: 208.58772091073578, Neurons: 201, Grad norm: 11.479364971133625\n",
      "Epoch 8646, Loss: 208.58772091073578, Neurons: 201, Grad norm: 11.479364971133625\n",
      "Epoch 8647, Loss: 208.587840866238, Neurons: 201, Grad norm: 11.395926394557963\n",
      "Epoch 8647, Loss: 208.587840866238, Neurons: 201, Grad norm: 11.395926394557963\n",
      "Epoch 8648, Loss: 208.58765782253553, Neurons: 201, Grad norm: 10.977052219331297\n",
      "Epoch 8648, Loss: 208.58765782253553, Neurons: 201, Grad norm: 10.977052219331297\n",
      "Epoch 8649, Loss: 208.58772214701324, Neurons: 201, Grad norm: 9.659316296979\n",
      "Epoch 8649, Loss: 208.58772214701324, Neurons: 201, Grad norm: 9.659316296979\n",
      "Epoch 8650, Loss: 208.58739218779914, Neurons: 201, Grad norm: 8.34073223556335\n",
      "Epoch 8650, Loss: 208.58739218779914, Neurons: 201, Grad norm: 8.34073223556335\n",
      "Epoch 8651, Loss: 208.5868150726242, Neurons: 201, Grad norm: 6.428840187688894\n",
      "Epoch 8651, Loss: 208.5868150726242, Neurons: 201, Grad norm: 6.428840187688894\n",
      "Epoch 8652, Loss: 208.5865188286103, Neurons: 201, Grad norm: 4.386623495887994\n",
      "Epoch 8652, Loss: 208.5865188286103, Neurons: 201, Grad norm: 4.386623495887994\n",
      "Epoch 8653, Loss: 208.58618886627013, Neurons: 201, Grad norm: 2.5045767800160355\n",
      "Epoch 8653, Loss: 208.58618886627013, Neurons: 201, Grad norm: 2.5045767800160355\n",
      "Epoch 8654, Loss: 208.58575072582815, Neurons: 201, Grad norm: 0.9904327626665377\n",
      "Epoch 8654, Loss: 208.58575072582815, Neurons: 201, Grad norm: 0.9904327626665377\n",
      "Epoch 8655, Loss: 208.5855085738729, Neurons: 201, Grad norm: 1.2225955383921132\n",
      "Epoch 8655, Loss: 208.5855085738729, Neurons: 201, Grad norm: 1.2225955383921132\n",
      "Epoch 8656, Loss: 208.5855399525029, Neurons: 201, Grad norm: 2.242834035042043\n",
      "Epoch 8656, Loss: 208.5855399525029, Neurons: 201, Grad norm: 2.242834035042043\n",
      "Epoch 8657, Loss: 208.5854681040773, Neurons: 201, Grad norm: 3.045135709379064\n",
      "Epoch 8657, Loss: 208.5854681040773, Neurons: 201, Grad norm: 3.045135709379064\n",
      "Epoch 8658, Loss: 208.58541438077432, Neurons: 201, Grad norm: 4.1606391275544725\n",
      "Epoch 8658, Loss: 208.58541438077432, Neurons: 201, Grad norm: 4.1606391275544725\n",
      "Epoch 8659, Loss: 208.58545250615265, Neurons: 201, Grad norm: 4.744556665411847\n",
      "Epoch 8659, Loss: 208.58545250615265, Neurons: 201, Grad norm: 4.744556665411847\n",
      "Epoch 8660, Loss: 208.58540526519027, Neurons: 201, Grad norm: 4.8556131060262615\n",
      "Epoch 8660, Loss: 208.58540526519027, Neurons: 201, Grad norm: 4.8556131060262615\n",
      "Epoch 8661, Loss: 208.58540151252362, Neurons: 201, Grad norm: 4.979888871096872\n",
      "Epoch 8661, Loss: 208.58540151252362, Neurons: 201, Grad norm: 4.979888871096872\n",
      "Epoch 8662, Loss: 208.58530337642014, Neurons: 201, Grad norm: 4.597704589509734\n",
      "Epoch 8662, Loss: 208.58530337642014, Neurons: 201, Grad norm: 4.597704589509734\n",
      "Epoch 8663, Loss: 208.58527502956971, Neurons: 201, Grad norm: 3.9923805159997077\n",
      "Epoch 8663, Loss: 208.58527502956971, Neurons: 201, Grad norm: 3.9923805159997077\n",
      "Epoch 8664, Loss: 208.58517822596158, Neurons: 201, Grad norm: 3.6618764724334496\n",
      "Epoch 8664, Loss: 208.58517822596158, Neurons: 201, Grad norm: 3.6618764724334496\n",
      "Epoch 8665, Loss: 208.58510584633726, Neurons: 201, Grad norm: 3.458573132561121\n",
      "Epoch 8665, Loss: 208.58510584633726, Neurons: 201, Grad norm: 3.458573132561121\n",
      "Epoch 8666, Loss: 208.58501626678506, Neurons: 201, Grad norm: 3.370801931681704\n",
      "Epoch 8666, Loss: 208.58501626678506, Neurons: 201, Grad norm: 3.370801931681704\n",
      "Epoch 8667, Loss: 208.58495056033874, Neurons: 201, Grad norm: 3.568655299220529\n",
      "Epoch 8667, Loss: 208.58495056033874, Neurons: 201, Grad norm: 3.568655299220529\n",
      "Epoch 8668, Loss: 208.58487617466665, Neurons: 201, Grad norm: 3.6866479695163012\n",
      "Epoch 8668, Loss: 208.58487617466665, Neurons: 201, Grad norm: 3.6866479695163012\n",
      "Epoch 8669, Loss: 208.58486698856842, Neurons: 201, Grad norm: 4.268882341270809\n",
      "Epoch 8669, Loss: 208.58486698856842, Neurons: 201, Grad norm: 4.268882341270809\n",
      "Epoch 8670, Loss: 208.5848097967491, Neurons: 201, Grad norm: 4.710707891063967\n",
      "Epoch 8670, Loss: 208.5848097967491, Neurons: 201, Grad norm: 4.710707891063967\n",
      "Epoch 8671, Loss: 208.5846961407902, Neurons: 201, Grad norm: 5.421866291794545\n",
      "Epoch 8671, Loss: 208.5846961407902, Neurons: 201, Grad norm: 5.421866291794545\n",
      "Epoch 8672, Loss: 208.584766124057, Neurons: 201, Grad norm: 5.594410898086174\n",
      "Epoch 8672, Loss: 208.584766124057, Neurons: 201, Grad norm: 5.594410898086174\n",
      "Epoch 8673, Loss: 208.5847398566577, Neurons: 201, Grad norm: 6.02971650357272\n",
      "Epoch 8673, Loss: 208.5847398566577, Neurons: 201, Grad norm: 6.02971650357272\n",
      "Epoch 8674, Loss: 208.5846797527995, Neurons: 201, Grad norm: 6.5219454769855\n",
      "Epoch 8674, Loss: 208.5846797527995, Neurons: 201, Grad norm: 6.5219454769855\n",
      "Epoch 8675, Loss: 208.58479123774316, Neurons: 201, Grad norm: 6.668327285646595\n",
      "Epoch 8675, Loss: 208.58479123774316, Neurons: 201, Grad norm: 6.668327285646595\n",
      "Epoch 8676, Loss: 208.5848832622534, Neurons: 201, Grad norm: 7.42229489706066\n",
      "Epoch 8676, Loss: 208.5848832622534, Neurons: 201, Grad norm: 7.42229489706066\n",
      "Epoch 8677, Loss: 208.5848732332473, Neurons: 201, Grad norm: 7.811440987043069\n",
      "Epoch 8677, Loss: 208.5848732332473, Neurons: 201, Grad norm: 7.811440987043069\n",
      "Epoch 8678, Loss: 208.58491316202068, Neurons: 201, Grad norm: 8.377236483660344\n",
      "Epoch 8678, Loss: 208.58491316202068, Neurons: 201, Grad norm: 8.377236483660344\n",
      "Epoch 8679, Loss: 208.58496029266658, Neurons: 201, Grad norm: 9.211215232024447\n",
      "Epoch 8679, Loss: 208.58496029266658, Neurons: 201, Grad norm: 9.211215232024447\n",
      "Epoch 8680, Loss: 208.58492988393488, Neurons: 201, Grad norm: 9.540371171504527\n",
      "Epoch 8680, Loss: 208.58492988393488, Neurons: 201, Grad norm: 9.540371171504527\n",
      "Epoch 8681, Loss: 208.5848606714213, Neurons: 201, Grad norm: 9.913710862877977\n",
      "Epoch 8681, Loss: 208.5848606714213, Neurons: 201, Grad norm: 9.913710862877977\n",
      "Epoch 8682, Loss: 208.58487942602235, Neurons: 201, Grad norm: 9.981753206018375\n",
      "Epoch 8682, Loss: 208.58487942602235, Neurons: 201, Grad norm: 9.981753206018375\n",
      "Epoch 8683, Loss: 208.58485480410042, Neurons: 201, Grad norm: 9.554573685463932\n",
      "Epoch 8683, Loss: 208.58485480410042, Neurons: 201, Grad norm: 9.554573685463932\n",
      "Epoch 8684, Loss: 208.58485971904267, Neurons: 201, Grad norm: 8.939976425203104\n",
      "Epoch 8684, Loss: 208.58485971904267, Neurons: 201, Grad norm: 8.939976425203104\n",
      "Epoch 8685, Loss: 208.58480989811065, Neurons: 201, Grad norm: 8.179102965483194\n",
      "Epoch 8685, Loss: 208.58480989811065, Neurons: 201, Grad norm: 8.179102965483194\n",
      "Epoch 8686, Loss: 208.58464390480748, Neurons: 201, Grad norm: 6.891959807477061\n",
      "Epoch 8686, Loss: 208.58464390480748, Neurons: 201, Grad norm: 6.891959807477061\n",
      "Epoch 8687, Loss: 208.58441660426118, Neurons: 201, Grad norm: 5.878055278445272\n",
      "Epoch 8687, Loss: 208.58441660426118, Neurons: 201, Grad norm: 5.878055278445272\n",
      "Epoch 8688, Loss: 208.584020030972, Neurons: 201, Grad norm: 4.90188602660236\n",
      "Epoch 8688, Loss: 208.584020030972, Neurons: 201, Grad norm: 4.90188602660236\n",
      "Epoch 8689, Loss: 208.58357435491956, Neurons: 201, Grad norm: 4.059582774215317\n",
      "Epoch 8689, Loss: 208.58357435491956, Neurons: 201, Grad norm: 4.059582774215317\n",
      "Epoch 8690, Loss: 208.5833205780558, Neurons: 201, Grad norm: 3.260186069351436\n",
      "Epoch 8690, Loss: 208.5833205780558, Neurons: 201, Grad norm: 3.260186069351436\n",
      "Epoch 8691, Loss: 208.5831801585464, Neurons: 201, Grad norm: 2.7172261868980367\n",
      "Epoch 8691, Loss: 208.5831801585464, Neurons: 201, Grad norm: 2.7172261868980367\n",
      "Epoch 8692, Loss: 208.58306015761346, Neurons: 201, Grad norm: 2.159159579645324\n",
      "Epoch 8692, Loss: 208.58306015761346, Neurons: 201, Grad norm: 2.159159579645324\n",
      "Epoch 8693, Loss: 208.5830089187799, Neurons: 201, Grad norm: 1.6180334025059449\n",
      "Epoch 8693, Loss: 208.5830089187799, Neurons: 201, Grad norm: 1.6180334025059449\n",
      "Epoch 8694, Loss: 208.58286809293995, Neurons: 201, Grad norm: 1.3473312693616177\n",
      "Epoch 8694, Loss: 208.58286809293995, Neurons: 201, Grad norm: 1.3473312693616177\n",
      "Epoch 8695, Loss: 208.5828990016568, Neurons: 201, Grad norm: 1.0556839516361798\n",
      "Epoch 8695, Loss: 208.5828990016568, Neurons: 201, Grad norm: 1.0556839516361798\n",
      "Epoch 8696, Loss: 208.58281340966252, Neurons: 201, Grad norm: 1.9476533063560204\n",
      "Epoch 8696, Loss: 208.58281340966252, Neurons: 201, Grad norm: 1.9476533063560204\n",
      "Epoch 8697, Loss: 208.5827342005524, Neurons: 201, Grad norm: 2.9009252648729023\n",
      "Epoch 8697, Loss: 208.5827342005524, Neurons: 201, Grad norm: 2.9009252648729023\n",
      "Epoch 8698, Loss: 208.5827211227916, Neurons: 201, Grad norm: 3.9470134930770344\n",
      "Epoch 8698, Loss: 208.5827211227916, Neurons: 201, Grad norm: 3.9470134930770344\n",
      "Epoch 8699, Loss: 208.58272463700425, Neurons: 201, Grad norm: 4.917924564382974\n",
      "Epoch 8699, Loss: 208.58272463700425, Neurons: 201, Grad norm: 4.917924564382974\n",
      "Epoch 8700, Loss: 208.58264070238687, Neurons: 201, Grad norm: 5.7229202549782245\n",
      "Epoch 8700, Loss: 208.58264070238687, Neurons: 201, Grad norm: 5.7229202549782245\n",
      "Epoch 8701, Loss: 208.58266225502638, Neurons: 201, Grad norm: 6.303057893274662\n",
      "Epoch 8701, Loss: 208.58266225502638, Neurons: 201, Grad norm: 6.303057893274662\n",
      "Epoch 8702, Loss: 208.58274966504257, Neurons: 201, Grad norm: 7.246691571008251\n",
      "Epoch 8702, Loss: 208.58274966504257, Neurons: 201, Grad norm: 7.246691571008251\n",
      "Epoch 8703, Loss: 208.58281537141252, Neurons: 201, Grad norm: 8.454276124282565\n",
      "Epoch 8703, Loss: 208.58281537141252, Neurons: 201, Grad norm: 8.454276124282565\n",
      "Epoch 8704, Loss: 208.5830852128212, Neurons: 201, Grad norm: 9.873131581584628\n",
      "Epoch 8704, Loss: 208.5830852128212, Neurons: 201, Grad norm: 9.873131581584628\n",
      "Epoch 8705, Loss: 208.5835359733345, Neurons: 201, Grad norm: 11.618418332881753\n",
      "Epoch 8705, Loss: 208.5835359733345, Neurons: 201, Grad norm: 11.618418332881753\n",
      "Epoch 8706, Loss: 208.58426191389825, Neurons: 201, Grad norm: 13.552898584036626\n",
      "Epoch 8706, Loss: 208.58426191389825, Neurons: 201, Grad norm: 13.552898584036626\n",
      "Epoch 8707, Loss: 208.58491560746566, Neurons: 201, Grad norm: 15.358757876064644\n",
      "Epoch 8707, Loss: 208.58491560746566, Neurons: 201, Grad norm: 15.358757876064644\n",
      "Epoch 8708, Loss: 208.58541765372055, Neurons: 201, Grad norm: 16.953275051157455\n",
      "Epoch 8708, Loss: 208.58541765372055, Neurons: 201, Grad norm: 16.953275051157455\n",
      "Epoch 8709, Loss: 208.58570958288988, Neurons: 201, Grad norm: 17.54538135599363\n",
      "Epoch 8709, Loss: 208.58570958288988, Neurons: 201, Grad norm: 17.54538135599363\n",
      "Epoch 8710, Loss: 208.58555448294044, Neurons: 201, Grad norm: 17.63306068965672\n",
      "Epoch 8710, Loss: 208.58555448294044, Neurons: 201, Grad norm: 17.63306068965672\n",
      "Epoch 8711, Loss: 208.58535303700273, Neurons: 201, Grad norm: 16.209287691028752\n",
      "Epoch 8711, Loss: 208.58535303700273, Neurons: 201, Grad norm: 16.209287691028752\n",
      "Epoch 8712, Loss: 208.58463457955565, Neurons: 201, Grad norm: 13.46467905682983\n",
      "Epoch 8712, Loss: 208.58463457955565, Neurons: 201, Grad norm: 13.46467905682983\n",
      "Epoch 8713, Loss: 208.58365360229072, Neurons: 201, Grad norm: 9.948447470361549\n",
      "Epoch 8713, Loss: 208.58365360229072, Neurons: 201, Grad norm: 9.948447470361549\n",
      "Epoch 8714, Loss: 208.58260839265122, Neurons: 201, Grad norm: 5.687587144767329\n",
      "Epoch 8714, Loss: 208.58260839265122, Neurons: 201, Grad norm: 5.687587144767329\n",
      "Epoch 8715, Loss: 208.5818892931578, Neurons: 201, Grad norm: 1.9917330250899499\n",
      "Epoch 8715, Loss: 208.5818892931578, Neurons: 201, Grad norm: 1.9917330250899499\n",
      "Epoch 8716, Loss: 208.58142561714868, Neurons: 201, Grad norm: 1.812627165525936\n",
      "Epoch 8716, Loss: 208.58142561714868, Neurons: 201, Grad norm: 1.812627165525936\n",
      "Epoch 8717, Loss: 208.58125649782562, Neurons: 201, Grad norm: 4.631373817087421\n",
      "Epoch 8717, Loss: 208.58125649782562, Neurons: 201, Grad norm: 4.631373817087421\n",
      "Epoch 8718, Loss: 208.5813901122222, Neurons: 201, Grad norm: 7.005228367754307\n",
      "Epoch 8718, Loss: 208.5813901122222, Neurons: 201, Grad norm: 7.005228367754307\n",
      "Epoch 8719, Loss: 208.58173421153938, Neurons: 201, Grad norm: 9.113099205541175\n",
      "Epoch 8719, Loss: 208.58173421153938, Neurons: 201, Grad norm: 9.113099205541175\n",
      "Epoch 8720, Loss: 208.58222820051034, Neurons: 201, Grad norm: 10.727231949965098\n",
      "Epoch 8720, Loss: 208.58222820051034, Neurons: 201, Grad norm: 10.727231949965098\n",
      "Epoch 8721, Loss: 208.58264600876413, Neurons: 201, Grad norm: 12.131094985145394\n",
      "Epoch 8721, Loss: 208.58264600876413, Neurons: 201, Grad norm: 12.131094985145394\n",
      "Epoch 8722, Loss: 208.5827696532546, Neurons: 201, Grad norm: 12.475819107200369\n",
      "Epoch 8722, Loss: 208.5827696532546, Neurons: 201, Grad norm: 12.475819107200369\n",
      "Epoch 8723, Loss: 208.58276396968967, Neurons: 201, Grad norm: 12.008610299800326\n",
      "Epoch 8723, Loss: 208.58276396968967, Neurons: 201, Grad norm: 12.008610299800326\n",
      "Epoch 8724, Loss: 208.58249093317684, Neurons: 201, Grad norm: 10.408184942999375\n",
      "Epoch 8724, Loss: 208.58249093317684, Neurons: 201, Grad norm: 10.408184942999375\n",
      "Epoch 8725, Loss: 208.58190796075607, Neurons: 201, Grad norm: 7.548285894476164\n",
      "Epoch 8725, Loss: 208.58190796075607, Neurons: 201, Grad norm: 7.548285894476164\n",
      "Epoch 8726, Loss: 208.58127102146332, Neurons: 201, Grad norm: 4.346598803812023\n",
      "Epoch 8726, Loss: 208.58127102146332, Neurons: 201, Grad norm: 4.346598803812023\n",
      "Epoch 8727, Loss: 208.5808047791199, Neurons: 201, Grad norm: 1.2747262762847902\n",
      "Epoch 8727, Loss: 208.5808047791199, Neurons: 201, Grad norm: 1.2747262762847902\n",
      "Epoch 8728, Loss: 208.5805044244909, Neurons: 201, Grad norm: 2.2395565168868803\n",
      "Epoch 8728, Loss: 208.5805044244909, Neurons: 201, Grad norm: 2.2395565168868803\n",
      "Epoch 8729, Loss: 208.58041984745327, Neurons: 201, Grad norm: 4.7144513022542425\n",
      "Epoch 8729, Loss: 208.58041984745327, Neurons: 201, Grad norm: 4.7144513022542425\n",
      "Epoch 8730, Loss: 208.58058353974454, Neurons: 201, Grad norm: 6.787880779916839\n",
      "Epoch 8730, Loss: 208.58058353974454, Neurons: 201, Grad norm: 6.787880779916839\n",
      "Epoch 8731, Loss: 208.58075596503156, Neurons: 201, Grad norm: 8.080999992360029\n",
      "Epoch 8731, Loss: 208.58075596503156, Neurons: 201, Grad norm: 8.080999992360029\n",
      "Epoch 8732, Loss: 208.58091542783376, Neurons: 201, Grad norm: 8.646120820071689\n",
      "Epoch 8732, Loss: 208.58091542783376, Neurons: 201, Grad norm: 8.646120820071689\n",
      "Epoch 8733, Loss: 208.580949392296, Neurons: 201, Grad norm: 8.537769831980434\n",
      "Epoch 8733, Loss: 208.580949392296, Neurons: 201, Grad norm: 8.537769831980434\n",
      "Epoch 8734, Loss: 208.58085264322406, Neurons: 201, Grad norm: 8.005343611995688\n",
      "Epoch 8734, Loss: 208.58085264322406, Neurons: 201, Grad norm: 8.005343611995688\n",
      "Epoch 8735, Loss: 208.58086616263657, Neurons: 201, Grad norm: 7.258438025767769\n",
      "Epoch 8735, Loss: 208.58086616263657, Neurons: 201, Grad norm: 7.258438025767769\n",
      "Epoch 8736, Loss: 208.58081496003072, Neurons: 201, Grad norm: 6.138716137296603\n",
      "Epoch 8736, Loss: 208.58081496003072, Neurons: 201, Grad norm: 6.138716137296603\n",
      "Epoch 8737, Loss: 208.58060518341165, Neurons: 201, Grad norm: 5.1284151657744035\n",
      "Epoch 8737, Loss: 208.58060518341165, Neurons: 201, Grad norm: 5.1284151657744035\n",
      "Epoch 8738, Loss: 208.58037662986484, Neurons: 201, Grad norm: 4.260227119414837\n",
      "Epoch 8738, Loss: 208.58037662986484, Neurons: 201, Grad norm: 4.260227119414837\n",
      "Epoch 8739, Loss: 208.58005693290002, Neurons: 201, Grad norm: 3.2487670280040146\n",
      "Epoch 8739, Loss: 208.58005693290002, Neurons: 201, Grad norm: 3.2487670280040146\n",
      "Epoch 8740, Loss: 208.5798110014222, Neurons: 201, Grad norm: 2.603252968365303\n",
      "Epoch 8740, Loss: 208.5798110014222, Neurons: 201, Grad norm: 2.603252968365303\n",
      "Epoch 8741, Loss: 208.57964875286896, Neurons: 201, Grad norm: 2.050917649283561\n",
      "Epoch 8741, Loss: 208.57964875286896, Neurons: 201, Grad norm: 2.050917649283561\n",
      "Epoch 8742, Loss: 208.57949552258572, Neurons: 201, Grad norm: 1.665737618758137\n",
      "Epoch 8742, Loss: 208.57949552258572, Neurons: 201, Grad norm: 1.665737618758137\n",
      "Epoch 8743, Loss: 208.5793978867859, Neurons: 201, Grad norm: 0.9460301029012087\n",
      "Epoch 8743, Loss: 208.5793978867859, Neurons: 201, Grad norm: 0.9460301029012087\n",
      "Epoch 8744, Loss: 208.57936047430152, Neurons: 201, Grad norm: 0.8136571852814087\n",
      "Epoch 8744, Loss: 208.57936047430152, Neurons: 201, Grad norm: 0.8136571852814087\n",
      "Epoch 8745, Loss: 208.57928711549417, Neurons: 201, Grad norm: 0.8869507524127779\n",
      "Epoch 8745, Loss: 208.57928711549417, Neurons: 201, Grad norm: 0.8869507524127779\n",
      "Epoch 8746, Loss: 208.5792131115872, Neurons: 201, Grad norm: 1.509381936343412\n",
      "Epoch 8746, Loss: 208.5792131115872, Neurons: 201, Grad norm: 1.509381936343412\n",
      "Epoch 8747, Loss: 208.5791054422944, Neurons: 201, Grad norm: 1.8875383177770988\n",
      "Epoch 8747, Loss: 208.5791054422944, Neurons: 201, Grad norm: 1.8875383177770988\n",
      "Epoch 8748, Loss: 208.57908625549064, Neurons: 201, Grad norm: 2.2596886423972564\n",
      "Epoch 8748, Loss: 208.57908625549064, Neurons: 201, Grad norm: 2.2596886423972564\n",
      "Epoch 8749, Loss: 208.57904352076778, Neurons: 201, Grad norm: 2.0852071217095656\n",
      "Epoch 8749, Loss: 208.57904352076778, Neurons: 201, Grad norm: 2.0852071217095656\n",
      "Epoch 8750, Loss: 208.57896853472505, Neurons: 201, Grad norm: 1.5141618836140525\n",
      "Epoch 8750, Loss: 208.57896853472505, Neurons: 201, Grad norm: 1.5141618836140525\n",
      "Epoch 8751, Loss: 208.57886492037042, Neurons: 201, Grad norm: 1.0801215355725342\n",
      "Epoch 8751, Loss: 208.57886492037042, Neurons: 201, Grad norm: 1.0801215355725342\n",
      "Epoch 8752, Loss: 208.5788170232078, Neurons: 201, Grad norm: 0.9058682201916604\n",
      "Epoch 8752, Loss: 208.5788170232078, Neurons: 201, Grad norm: 0.9058682201916604\n",
      "Epoch 8753, Loss: 208.57873144564803, Neurons: 201, Grad norm: 1.1169479000627671\n",
      "Epoch 8753, Loss: 208.57873144564803, Neurons: 201, Grad norm: 1.1169479000627671\n",
      "Epoch 8754, Loss: 208.57871069923402, Neurons: 201, Grad norm: 0.9972675491152527\n",
      "Epoch 8754, Loss: 208.57871069923402, Neurons: 201, Grad norm: 0.9972675491152527\n",
      "Epoch 8755, Loss: 208.57859410933338, Neurons: 201, Grad norm: 0.8492219252042621\n",
      "Epoch 8755, Loss: 208.57859410933338, Neurons: 201, Grad norm: 0.8492219252042621\n",
      "Epoch 8756, Loss: 208.5785395460318, Neurons: 201, Grad norm: 0.9890908365977154\n",
      "Epoch 8756, Loss: 208.5785395460318, Neurons: 201, Grad norm: 0.9890908365977154\n",
      "Epoch 8757, Loss: 208.5784988805463, Neurons: 201, Grad norm: 1.537209629202025\n",
      "Epoch 8757, Loss: 208.5784988805463, Neurons: 201, Grad norm: 1.537209629202025\n",
      "Epoch 8758, Loss: 208.57842823231803, Neurons: 201, Grad norm: 2.431827518540295\n",
      "Epoch 8758, Loss: 208.57842823231803, Neurons: 201, Grad norm: 2.431827518540295\n",
      "Epoch 8759, Loss: 208.57857063072817, Neurons: 201, Grad norm: 2.9332783520606123\n",
      "Epoch 8759, Loss: 208.57857063072817, Neurons: 201, Grad norm: 2.9332783520606123\n",
      "Epoch 8760, Loss: 208.57858673584818, Neurons: 201, Grad norm: 4.096151644377613\n",
      "Epoch 8760, Loss: 208.57858673584818, Neurons: 201, Grad norm: 4.096151644377613\n",
      "Epoch 8761, Loss: 208.5784999157535, Neurons: 201, Grad norm: 5.611820174002944\n",
      "Epoch 8761, Loss: 208.5784999157535, Neurons: 201, Grad norm: 5.611820174002944\n",
      "Epoch 8762, Loss: 208.5785058015506, Neurons: 201, Grad norm: 7.143002292515251\n",
      "Epoch 8762, Loss: 208.5785058015506, Neurons: 201, Grad norm: 7.143002292515251\n",
      "Epoch 8763, Loss: 208.5786328637222, Neurons: 201, Grad norm: 8.748956732964318\n",
      "Epoch 8763, Loss: 208.5786328637222, Neurons: 201, Grad norm: 8.748956732964318\n",
      "Epoch 8764, Loss: 208.57878267649735, Neurons: 201, Grad norm: 9.932696931959299\n",
      "Epoch 8764, Loss: 208.57878267649735, Neurons: 201, Grad norm: 9.932696931959299\n",
      "Epoch 8765, Loss: 208.57902270253902, Neurons: 201, Grad norm: 10.577955381055721\n",
      "Epoch 8765, Loss: 208.57902270253902, Neurons: 201, Grad norm: 10.577955381055721\n",
      "Epoch 8766, Loss: 208.5791442757447, Neurons: 201, Grad norm: 11.113139677548183\n",
      "Epoch 8766, Loss: 208.5791442757447, Neurons: 201, Grad norm: 11.113139677548183\n",
      "Epoch 8767, Loss: 208.57921257326225, Neurons: 201, Grad norm: 10.80786146767454\n",
      "Epoch 8767, Loss: 208.57921257326225, Neurons: 201, Grad norm: 10.80786146767454\n",
      "Epoch 8768, Loss: 208.57917788663477, Neurons: 201, Grad norm: 10.178613879268942\n",
      "Epoch 8768, Loss: 208.57917788663477, Neurons: 201, Grad norm: 10.178613879268942\n",
      "Epoch 8769, Loss: 208.57910525091205, Neurons: 201, Grad norm: 9.217261877127468\n",
      "Epoch 8769, Loss: 208.57910525091205, Neurons: 201, Grad norm: 9.217261877127468\n",
      "Epoch 8770, Loss: 208.57891875860722, Neurons: 201, Grad norm: 8.152999119035009\n",
      "Epoch 8770, Loss: 208.57891875860722, Neurons: 201, Grad norm: 8.152999119035009\n",
      "Epoch 8771, Loss: 208.57866624210266, Neurons: 201, Grad norm: 7.220280958177555\n",
      "Epoch 8771, Loss: 208.57866624210266, Neurons: 201, Grad norm: 7.220280958177555\n",
      "Epoch 8772, Loss: 208.57837654770526, Neurons: 201, Grad norm: 6.415622886197737\n",
      "Epoch 8772, Loss: 208.57837654770526, Neurons: 201, Grad norm: 6.415622886197737\n",
      "Epoch 8773, Loss: 208.57809684482416, Neurons: 201, Grad norm: 5.875767863749046\n",
      "Epoch 8773, Loss: 208.57809684482416, Neurons: 201, Grad norm: 5.875767863749046\n",
      "Epoch 8774, Loss: 208.57787398248715, Neurons: 201, Grad norm: 5.344651827643152\n",
      "Epoch 8774, Loss: 208.57787398248715, Neurons: 201, Grad norm: 5.344651827643152\n",
      "Epoch 8775, Loss: 208.57760969304894, Neurons: 201, Grad norm: 4.667024315426204\n",
      "Epoch 8775, Loss: 208.57760969304894, Neurons: 201, Grad norm: 4.667024315426204\n",
      "Epoch 8776, Loss: 208.57741738844658, Neurons: 201, Grad norm: 3.8439831975702377\n",
      "Epoch 8776, Loss: 208.57741738844658, Neurons: 201, Grad norm: 3.8439831975702377\n",
      "Epoch 8777, Loss: 208.57730830638172, Neurons: 201, Grad norm: 2.602020345372017\n",
      "Epoch 8777, Loss: 208.57730830638172, Neurons: 201, Grad norm: 2.602020345372017\n",
      "Epoch 8778, Loss: 208.57714551386016, Neurons: 201, Grad norm: 1.413022147826236\n",
      "Epoch 8778, Loss: 208.57714551386016, Neurons: 201, Grad norm: 1.413022147826236\n",
      "Epoch 8779, Loss: 208.57702392853037, Neurons: 201, Grad norm: 0.5971992658037256\n",
      "Epoch 8779, Loss: 208.57702392853037, Neurons: 201, Grad norm: 0.5971992658037256\n",
      "Epoch 8780, Loss: 208.5769106161728, Neurons: 201, Grad norm: 1.6067138752940637\n",
      "Epoch 8780, Loss: 208.5769106161728, Neurons: 201, Grad norm: 1.6067138752940637\n",
      "Epoch 8781, Loss: 208.57683390181137, Neurons: 201, Grad norm: 2.787938665194636\n",
      "Epoch 8781, Loss: 208.57683390181137, Neurons: 201, Grad norm: 2.787938665194636\n",
      "Epoch 8782, Loss: 208.57686991785422, Neurons: 201, Grad norm: 3.720104994749866\n",
      "Epoch 8782, Loss: 208.57686991785422, Neurons: 201, Grad norm: 3.720104994749866\n",
      "Epoch 8783, Loss: 208.57690490887, Neurons: 201, Grad norm: 4.287244988388559\n",
      "Epoch 8783, Loss: 208.57690490887, Neurons: 201, Grad norm: 4.287244988388559\n",
      "Epoch 8784, Loss: 208.5768485282922, Neurons: 201, Grad norm: 4.718619979867188\n",
      "Epoch 8784, Loss: 208.5768485282922, Neurons: 201, Grad norm: 4.718619979867188\n",
      "Epoch 8785, Loss: 208.57680028432466, Neurons: 201, Grad norm: 4.380346469110213\n",
      "Epoch 8785, Loss: 208.57680028432466, Neurons: 201, Grad norm: 4.380346469110213\n",
      "Epoch 8786, Loss: 208.57668371208769, Neurons: 201, Grad norm: 4.3099163586704865\n",
      "Epoch 8786, Loss: 208.57668371208769, Neurons: 201, Grad norm: 4.3099163586704865\n",
      "Epoch 8787, Loss: 208.57661249938857, Neurons: 201, Grad norm: 4.619829465663798\n",
      "Epoch 8787, Loss: 208.57661249938857, Neurons: 201, Grad norm: 4.619829465663798\n",
      "Epoch 8788, Loss: 208.5766895695445, Neurons: 201, Grad norm: 4.979766295095555\n",
      "Epoch 8788, Loss: 208.5766895695445, Neurons: 201, Grad norm: 4.979766295095555\n",
      "Epoch 8789, Loss: 208.57691268162895, Neurons: 201, Grad norm: 6.044104959587387\n",
      "Epoch 8789, Loss: 208.57691268162895, Neurons: 201, Grad norm: 6.044104959587387\n",
      "Epoch 8790, Loss: 208.57710616926522, Neurons: 201, Grad norm: 6.975567590891412\n",
      "Epoch 8790, Loss: 208.57710616926522, Neurons: 201, Grad norm: 6.975567590891412\n",
      "Epoch 8791, Loss: 208.57731119575334, Neurons: 201, Grad norm: 8.408788433344627\n",
      "Epoch 8791, Loss: 208.57731119575334, Neurons: 201, Grad norm: 8.408788433344627\n",
      "Epoch 8792, Loss: 208.5774319060081, Neurons: 201, Grad norm: 10.436728478236443\n",
      "Epoch 8792, Loss: 208.5774319060081, Neurons: 201, Grad norm: 10.436728478236443\n",
      "Epoch 8793, Loss: 208.57745794579358, Neurons: 201, Grad norm: 12.563436038141223\n",
      "Epoch 8793, Loss: 208.57745794579358, Neurons: 201, Grad norm: 12.563436038141223\n",
      "Epoch 8794, Loss: 208.57784234823401, Neurons: 201, Grad norm: 14.93054190084511\n",
      "Epoch 8794, Loss: 208.57784234823401, Neurons: 201, Grad norm: 14.93054190084511\n",
      "Epoch 8795, Loss: 208.57830024743248, Neurons: 201, Grad norm: 16.679339083292746\n",
      "Epoch 8795, Loss: 208.57830024743248, Neurons: 201, Grad norm: 16.679339083292746\n",
      "Epoch 8796, Loss: 208.5787651994884, Neurons: 201, Grad norm: 17.404293786723155\n",
      "Epoch 8796, Loss: 208.5787651994884, Neurons: 201, Grad norm: 17.404293786723155\n",
      "Epoch 8797, Loss: 208.57899002508537, Neurons: 201, Grad norm: 17.46420225100452\n",
      "Epoch 8797, Loss: 208.57899002508537, Neurons: 201, Grad norm: 17.46420225100452\n",
      "Epoch 8798, Loss: 208.579145395194, Neurons: 201, Grad norm: 16.188170191431144\n",
      "Epoch 8798, Loss: 208.579145395194, Neurons: 201, Grad norm: 16.188170191431144\n",
      "Epoch 8799, Loss: 208.57889792399254, Neurons: 201, Grad norm: 14.011661923578474\n",
      "Epoch 8799, Loss: 208.57889792399254, Neurons: 201, Grad norm: 14.011661923578474\n",
      "Epoch 8800, Loss: 208.57823698768203, Neurons: 201, Grad norm: 11.038928582679903\n",
      "Epoch 8800, Loss: 208.57823698768203, Neurons: 201, Grad norm: 11.038928582679903\n",
      "Epoch 8801, Loss: 208.57740903575882, Neurons: 201, Grad norm: 7.585430753266997\n",
      "Epoch 8801, Loss: 208.57740903575882, Neurons: 201, Grad norm: 7.585430753266997\n",
      "Epoch 8802, Loss: 208.5766089818702, Neurons: 201, Grad norm: 4.495651279262023\n",
      "Epoch 8802, Loss: 208.5766089818702, Neurons: 201, Grad norm: 4.495651279262023\n",
      "Epoch 8803, Loss: 208.57575828601057, Neurons: 201, Grad norm: 1.4729364216544876\n",
      "Epoch 8803, Loss: 208.57575828601057, Neurons: 201, Grad norm: 1.4729364216544876\n",
      "Epoch 8804, Loss: 208.57542749132125, Neurons: 201, Grad norm: 1.9430287820381384\n",
      "Epoch 8804, Loss: 208.57542749132125, Neurons: 201, Grad norm: 1.9430287820381384\n",
      "Epoch 8805, Loss: 208.57536897051864, Neurons: 201, Grad norm: 3.923007349523028\n",
      "Epoch 8805, Loss: 208.57536897051864, Neurons: 201, Grad norm: 3.923007349523028\n",
      "Epoch 8806, Loss: 208.57542617312507, Neurons: 201, Grad norm: 6.004640168332012\n",
      "Epoch 8806, Loss: 208.57542617312507, Neurons: 201, Grad norm: 6.004640168332012\n",
      "Epoch 8807, Loss: 208.575630036911, Neurons: 201, Grad norm: 7.5021427810482555\n",
      "Epoch 8807, Loss: 208.575630036911, Neurons: 201, Grad norm: 7.5021427810482555\n",
      "Epoch 8808, Loss: 208.57587211360692, Neurons: 201, Grad norm: 8.343724045129854\n",
      "Epoch 8808, Loss: 208.57587211360692, Neurons: 201, Grad norm: 8.343724045129854\n",
      "Epoch 8809, Loss: 208.57589356932863, Neurons: 201, Grad norm: 9.086316967164588\n",
      "Epoch 8809, Loss: 208.57589356932863, Neurons: 201, Grad norm: 9.086316967164588\n",
      "Epoch 8810, Loss: 208.57570584578147, Neurons: 201, Grad norm: 8.591970589115245\n",
      "Epoch 8810, Loss: 208.57570584578147, Neurons: 201, Grad norm: 8.591970589115245\n",
      "Epoch 8811, Loss: 208.5756813732814, Neurons: 201, Grad norm: 7.841106826312559\n",
      "Epoch 8811, Loss: 208.5756813732814, Neurons: 201, Grad norm: 7.841106826312559\n",
      "Epoch 8812, Loss: 208.5753982743068, Neurons: 201, Grad norm: 6.335870272471558\n",
      "Epoch 8812, Loss: 208.5753982743068, Neurons: 201, Grad norm: 6.335870272471558\n",
      "Epoch 8813, Loss: 208.57493256257575, Neurons: 201, Grad norm: 4.60916177568648\n",
      "Epoch 8813, Loss: 208.57493256257575, Neurons: 201, Grad norm: 4.60916177568648\n",
      "Epoch 8814, Loss: 208.5743862991144, Neurons: 201, Grad norm: 2.6162873269957374\n",
      "Epoch 8814, Loss: 208.5743862991144, Neurons: 201, Grad norm: 2.6162873269957374\n",
      "Epoch 8815, Loss: 208.57415337254258, Neurons: 201, Grad norm: 0.9322922286586985\n",
      "Epoch 8815, Loss: 208.57415337254258, Neurons: 201, Grad norm: 0.9322922286586985\n",
      "Epoch 8816, Loss: 208.573964789803, Neurons: 201, Grad norm: 1.1904869029847396\n",
      "Epoch 8816, Loss: 208.573964789803, Neurons: 201, Grad norm: 1.1904869029847396\n",
      "Epoch 8817, Loss: 208.57394191738433, Neurons: 201, Grad norm: 3.0025045662412126\n",
      "Epoch 8817, Loss: 208.57394191738433, Neurons: 201, Grad norm: 3.0025045662412126\n",
      "Epoch 8818, Loss: 208.57396817446264, Neurons: 201, Grad norm: 3.8989699513171296\n",
      "Epoch 8818, Loss: 208.57396817446264, Neurons: 201, Grad norm: 3.8989699513171296\n",
      "Epoch 8819, Loss: 208.57400636624757, Neurons: 201, Grad norm: 4.78618125999993\n",
      "Epoch 8819, Loss: 208.57400636624757, Neurons: 201, Grad norm: 4.78618125999993\n",
      "Epoch 8820, Loss: 208.57396210915468, Neurons: 201, Grad norm: 5.18248315914724\n",
      "Epoch 8820, Loss: 208.57396210915468, Neurons: 201, Grad norm: 5.18248315914724\n",
      "Epoch 8821, Loss: 208.57391268281728, Neurons: 201, Grad norm: 5.302403243886124\n",
      "Epoch 8821, Loss: 208.57391268281728, Neurons: 201, Grad norm: 5.302403243886124\n",
      "Epoch 8822, Loss: 208.57386843069284, Neurons: 201, Grad norm: 5.243882018359018\n",
      "Epoch 8822, Loss: 208.57386843069284, Neurons: 201, Grad norm: 5.243882018359018\n",
      "Epoch 8823, Loss: 208.57381869062615, Neurons: 201, Grad norm: 5.235081798217155\n",
      "Epoch 8823, Loss: 208.57381869062615, Neurons: 201, Grad norm: 5.235081798217155\n",
      "Epoch 8824, Loss: 208.57378915465745, Neurons: 201, Grad norm: 5.339495441859153\n",
      "Epoch 8824, Loss: 208.57378915465745, Neurons: 201, Grad norm: 5.339495441859153\n",
      "Epoch 8825, Loss: 208.573676607062, Neurons: 201, Grad norm: 5.116887542431647\n",
      "Epoch 8825, Loss: 208.573676607062, Neurons: 201, Grad norm: 5.116887542431647\n",
      "Epoch 8826, Loss: 208.57354405736095, Neurons: 201, Grad norm: 5.2281711807816755\n",
      "Epoch 8826, Loss: 208.57354405736095, Neurons: 201, Grad norm: 5.2281711807816755\n",
      "Epoch 8827, Loss: 208.57343150666657, Neurons: 201, Grad norm: 4.740909246922675\n",
      "Epoch 8827, Loss: 208.57343150666657, Neurons: 201, Grad norm: 4.740909246922675\n",
      "Epoch 8828, Loss: 208.57325677553422, Neurons: 201, Grad norm: 4.169649350553668\n",
      "Epoch 8828, Loss: 208.57325677553422, Neurons: 201, Grad norm: 4.169649350553668\n",
      "Epoch 8829, Loss: 208.57317412349119, Neurons: 201, Grad norm: 3.2781854815133307\n",
      "Epoch 8829, Loss: 208.57317412349119, Neurons: 201, Grad norm: 3.2781854815133307\n",
      "Epoch 8830, Loss: 208.57303499172036, Neurons: 201, Grad norm: 2.000375302828056\n",
      "Epoch 8830, Loss: 208.57303499172036, Neurons: 201, Grad norm: 2.000375302828056\n",
      "Epoch 8831, Loss: 208.57282888980865, Neurons: 201, Grad norm: 1.2838715196851023\n",
      "Epoch 8831, Loss: 208.57282888980865, Neurons: 201, Grad norm: 1.2838715196851023\n",
      "Epoch 8832, Loss: 208.57277223445365, Neurons: 201, Grad norm: 0.5365736394420481\n",
      "Epoch 8832, Loss: 208.57277223445365, Neurons: 201, Grad norm: 0.5365736394420481\n",
      "Epoch 8833, Loss: 208.57264699956966, Neurons: 201, Grad norm: 1.2241744188381554\n",
      "Epoch 8833, Loss: 208.57264699956966, Neurons: 201, Grad norm: 1.2241744188381554\n",
      "Epoch 8834, Loss: 208.57256344915504, Neurons: 201, Grad norm: 1.6198607127315325\n",
      "Epoch 8834, Loss: 208.57256344915504, Neurons: 201, Grad norm: 1.6198607127315325\n",
      "Epoch 8835, Loss: 208.5725561161077, Neurons: 201, Grad norm: 2.15375746482805\n",
      "Epoch 8835, Loss: 208.5725561161077, Neurons: 201, Grad norm: 2.15375746482805\n",
      "Epoch 8836, Loss: 208.57246095493264, Neurons: 201, Grad norm: 2.5268817183547787\n",
      "Epoch 8836, Loss: 208.57246095493264, Neurons: 201, Grad norm: 2.5268817183547787\n",
      "Epoch 8837, Loss: 208.57243359460534, Neurons: 201, Grad norm: 2.7632348572940555\n",
      "Epoch 8837, Loss: 208.57243359460534, Neurons: 201, Grad norm: 2.7632348572940555\n",
      "Epoch 8838, Loss: 208.572402947245, Neurons: 201, Grad norm: 3.1233434449833926\n",
      "Epoch 8838, Loss: 208.572402947245, Neurons: 201, Grad norm: 3.1233434449833926\n",
      "Epoch 8839, Loss: 208.57231328085365, Neurons: 201, Grad norm: 3.349554471999181\n",
      "Epoch 8839, Loss: 208.57231328085365, Neurons: 201, Grad norm: 3.349554471999181\n",
      "Epoch 8840, Loss: 208.57227211437424, Neurons: 201, Grad norm: 3.7199664168151965\n",
      "Epoch 8840, Loss: 208.57227211437424, Neurons: 201, Grad norm: 3.7199664168151965\n",
      "Epoch 8841, Loss: 208.5722571448869, Neurons: 201, Grad norm: 3.952080889631056\n",
      "Epoch 8841, Loss: 208.5722571448869, Neurons: 201, Grad norm: 3.952080889631056\n",
      "Epoch 8842, Loss: 208.57215704324608, Neurons: 201, Grad norm: 4.241779359893295\n",
      "Epoch 8842, Loss: 208.57215704324608, Neurons: 201, Grad norm: 4.241779359893295\n",
      "Epoch 8843, Loss: 208.57204004444185, Neurons: 201, Grad norm: 4.546045641781376\n",
      "Epoch 8843, Loss: 208.57204004444185, Neurons: 201, Grad norm: 4.546045641781376\n",
      "Epoch 8844, Loss: 208.5720053389979, Neurons: 201, Grad norm: 4.5442362608351905\n",
      "Epoch 8844, Loss: 208.5720053389979, Neurons: 201, Grad norm: 4.5442362608351905\n",
      "Epoch 8845, Loss: 208.5719206053273, Neurons: 201, Grad norm: 4.677758765753484\n",
      "Epoch 8845, Loss: 208.5719206053273, Neurons: 201, Grad norm: 4.677758765753484\n",
      "Epoch 8846, Loss: 208.57185394858794, Neurons: 201, Grad norm: 4.7167294665802775\n",
      "Epoch 8846, Loss: 208.57185394858794, Neurons: 201, Grad norm: 4.7167294665802775\n",
      "Epoch 8847, Loss: 208.57180068691835, Neurons: 201, Grad norm: 5.0325290687853075\n",
      "Epoch 8847, Loss: 208.57180068691835, Neurons: 201, Grad norm: 5.0325290687853075\n",
      "Epoch 8848, Loss: 208.57179519318717, Neurons: 201, Grad norm: 5.486717856538158\n",
      "Epoch 8848, Loss: 208.57179519318717, Neurons: 201, Grad norm: 5.486717856538158\n",
      "Epoch 8849, Loss: 208.571856173455, Neurons: 201, Grad norm: 6.303561497370537\n",
      "Epoch 8849, Loss: 208.571856173455, Neurons: 201, Grad norm: 6.303561497370537\n",
      "Epoch 8850, Loss: 208.5719669643664, Neurons: 201, Grad norm: 7.510589217787422\n",
      "Epoch 8850, Loss: 208.5719669643664, Neurons: 201, Grad norm: 7.510589217787422\n",
      "Epoch 8851, Loss: 208.5723731914811, Neurons: 201, Grad norm: 8.750659331264675\n",
      "Epoch 8851, Loss: 208.5723731914811, Neurons: 201, Grad norm: 8.750659331264675\n",
      "Epoch 8852, Loss: 208.57260866656495, Neurons: 201, Grad norm: 10.38838752816725\n",
      "Epoch 8852, Loss: 208.57260866656495, Neurons: 201, Grad norm: 10.38838752816725\n",
      "Epoch 8853, Loss: 208.5726959148568, Neurons: 201, Grad norm: 12.424875643281458\n",
      "Epoch 8853, Loss: 208.5726959148568, Neurons: 201, Grad norm: 12.424875643281458\n",
      "Epoch 8854, Loss: 208.57303897377568, Neurons: 201, Grad norm: 14.308973396171629\n",
      "Epoch 8854, Loss: 208.57303897377568, Neurons: 201, Grad norm: 14.308973396171629\n",
      "Epoch 8855, Loss: 208.57341908592133, Neurons: 201, Grad norm: 16.202005840538497\n",
      "Epoch 8855, Loss: 208.57341908592133, Neurons: 201, Grad norm: 16.202005840538497\n",
      "Epoch 8856, Loss: 208.57361423749643, Neurons: 201, Grad norm: 17.062861997618135\n",
      "Epoch 8856, Loss: 208.57361423749643, Neurons: 201, Grad norm: 17.062861997618135\n",
      "Epoch 8857, Loss: 208.5739025791755, Neurons: 201, Grad norm: 17.659186785091702\n",
      "Epoch 8857, Loss: 208.5739025791755, Neurons: 201, Grad norm: 17.659186785091702\n",
      "Epoch 8858, Loss: 208.5739344138741, Neurons: 201, Grad norm: 16.992072787699378\n",
      "Epoch 8858, Loss: 208.5739344138741, Neurons: 201, Grad norm: 16.992072787699378\n",
      "Epoch 8859, Loss: 208.57372063140477, Neurons: 201, Grad norm: 15.373425423379627\n",
      "Epoch 8859, Loss: 208.57372063140477, Neurons: 201, Grad norm: 15.373425423379627\n",
      "Epoch 8860, Loss: 208.57331200468926, Neurons: 201, Grad norm: 13.246091490538884\n",
      "Epoch 8860, Loss: 208.57331200468926, Neurons: 201, Grad norm: 13.246091490538884\n",
      "Epoch 8861, Loss: 208.57268559021236, Neurons: 201, Grad norm: 10.65118061964655\n",
      "Epoch 8861, Loss: 208.57268559021236, Neurons: 201, Grad norm: 10.65118061964655\n",
      "Epoch 8862, Loss: 208.57181558017479, Neurons: 201, Grad norm: 7.808871991591127\n",
      "Epoch 8862, Loss: 208.57181558017479, Neurons: 201, Grad norm: 7.808871991591127\n",
      "Epoch 8863, Loss: 208.57110450332664, Neurons: 201, Grad norm: 5.0322375589577\n",
      "Epoch 8863, Loss: 208.57110450332664, Neurons: 201, Grad norm: 5.0322375589577\n",
      "Epoch 8864, Loss: 208.57030516552436, Neurons: 201, Grad norm: 2.650065512047668\n",
      "Epoch 8864, Loss: 208.57030516552436, Neurons: 201, Grad norm: 2.650065512047668\n",
      "Epoch 8865, Loss: 208.56951490984773, Neurons: 201, Grad norm: 0.9729744537676086\n",
      "Epoch 8865, Loss: 208.56951490984773, Neurons: 201, Grad norm: 0.9729744537676086\n",
      "Epoch 8866, Loss: 208.56933017979608, Neurons: 201, Grad norm: 2.2560856658494424\n",
      "Epoch 8866, Loss: 208.56933017979608, Neurons: 201, Grad norm: 2.2560856658494424\n",
      "Epoch 8867, Loss: 208.56933215147302, Neurons: 201, Grad norm: 4.14054507833041\n",
      "Epoch 8867, Loss: 208.56933215147302, Neurons: 201, Grad norm: 4.14054507833041\n",
      "Epoch 8868, Loss: 208.56924507363723, Neurons: 201, Grad norm: 6.231620748201607\n",
      "Epoch 8868, Loss: 208.56924507363723, Neurons: 201, Grad norm: 6.231620748201607\n",
      "Epoch 8869, Loss: 208.5692885800673, Neurons: 201, Grad norm: 8.285658149058744\n",
      "Epoch 8869, Loss: 208.5692885800673, Neurons: 201, Grad norm: 8.285658149058744\n",
      "Epoch 8870, Loss: 208.56960714941513, Neurons: 201, Grad norm: 10.053147118636959\n",
      "Epoch 8870, Loss: 208.56960714941513, Neurons: 201, Grad norm: 10.053147118636959\n",
      "Epoch 8871, Loss: 208.56972096784546, Neurons: 201, Grad norm: 11.115497334450524\n",
      "Epoch 8871, Loss: 208.56972096784546, Neurons: 201, Grad norm: 11.115497334450524\n",
      "Epoch 8872, Loss: 208.56967123427987, Neurons: 201, Grad norm: 11.473306725726335\n",
      "Epoch 8872, Loss: 208.56967123427987, Neurons: 201, Grad norm: 11.473306725726335\n",
      "Epoch 8873, Loss: 208.5695845134256, Neurons: 201, Grad norm: 10.375928606654309\n",
      "Epoch 8873, Loss: 208.5695845134256, Neurons: 201, Grad norm: 10.375928606654309\n",
      "Epoch 8874, Loss: 208.56912512014122, Neurons: 201, Grad norm: 8.241141877955805\n",
      "Epoch 8874, Loss: 208.56912512014122, Neurons: 201, Grad norm: 8.241141877955805\n",
      "Epoch 8875, Loss: 208.56844100468118, Neurons: 201, Grad norm: 5.328377872085532\n",
      "Epoch 8875, Loss: 208.56844100468118, Neurons: 201, Grad norm: 5.328377872085532\n",
      "Epoch 8876, Loss: 208.56789823160958, Neurons: 201, Grad norm: 2.3118974624690027\n",
      "Epoch 8876, Loss: 208.56789823160958, Neurons: 201, Grad norm: 2.3118974624690027\n",
      "Epoch 8877, Loss: 208.56750285118022, Neurons: 201, Grad norm: 1.1568891889017183\n",
      "Epoch 8877, Loss: 208.56750285118022, Neurons: 201, Grad norm: 1.1568891889017183\n",
      "Epoch 8878, Loss: 208.5672050523548, Neurons: 201, Grad norm: 3.818926965813114\n",
      "Epoch 8878, Loss: 208.5672050523548, Neurons: 201, Grad norm: 3.818926965813114\n",
      "Epoch 8879, Loss: 208.5672612868776, Neurons: 201, Grad norm: 5.899462197665406\n",
      "Epoch 8879, Loss: 208.5672612868776, Neurons: 201, Grad norm: 5.899462197665406\n",
      "Epoch 8880, Loss: 208.56735902931905, Neurons: 201, Grad norm: 7.635413558126434\n",
      "Epoch 8880, Loss: 208.56735902931905, Neurons: 201, Grad norm: 7.635413558126434\n",
      "Epoch 8881, Loss: 208.56752139609605, Neurons: 201, Grad norm: 8.266725779680451\n",
      "Epoch 8881, Loss: 208.56752139609605, Neurons: 201, Grad norm: 8.266725779680451\n",
      "Epoch 8882, Loss: 208.56768287478914, Neurons: 201, Grad norm: 8.774763462624405\n",
      "Epoch 8882, Loss: 208.56768287478914, Neurons: 201, Grad norm: 8.774763462624405\n",
      "Epoch 8883, Loss: 208.56770762174446, Neurons: 201, Grad norm: 8.721253788384544\n",
      "Epoch 8883, Loss: 208.56770762174446, Neurons: 201, Grad norm: 8.721253788384544\n",
      "Epoch 8884, Loss: 208.56768752617154, Neurons: 201, Grad norm: 8.419926165067865\n",
      "Epoch 8884, Loss: 208.56768752617154, Neurons: 201, Grad norm: 8.419926165067865\n",
      "Epoch 8885, Loss: 208.56770785588563, Neurons: 201, Grad norm: 8.152770382210782\n",
      "Epoch 8885, Loss: 208.56770785588563, Neurons: 201, Grad norm: 8.152770382210782\n",
      "Epoch 8886, Loss: 208.567726116727, Neurons: 201, Grad norm: 7.661723450127461\n",
      "Epoch 8886, Loss: 208.567726116727, Neurons: 201, Grad norm: 7.661723450127461\n",
      "Epoch 8887, Loss: 208.56753952937478, Neurons: 201, Grad norm: 7.161854460556441\n",
      "Epoch 8887, Loss: 208.56753952937478, Neurons: 201, Grad norm: 7.161854460556441\n",
      "Epoch 8888, Loss: 208.56730409448159, Neurons: 201, Grad norm: 6.723858226358694\n",
      "Epoch 8888, Loss: 208.56730409448159, Neurons: 201, Grad norm: 6.723858226358694\n",
      "Epoch 8889, Loss: 208.56692492596665, Neurons: 201, Grad norm: 6.1724933132354005\n",
      "Epoch 8889, Loss: 208.56692492596665, Neurons: 201, Grad norm: 6.1724933132354005\n",
      "Epoch 8890, Loss: 208.5667385437042, Neurons: 201, Grad norm: 5.704091664905502\n",
      "Epoch 8890, Loss: 208.5667385437042, Neurons: 201, Grad norm: 5.704091664905502\n",
      "Epoch 8891, Loss: 208.56656941276478, Neurons: 201, Grad norm: 4.982626743346822\n",
      "Epoch 8891, Loss: 208.56656941276478, Neurons: 201, Grad norm: 4.982626743346822\n",
      "Epoch 8892, Loss: 208.5663508805925, Neurons: 201, Grad norm: 4.379287398465908\n",
      "Epoch 8892, Loss: 208.5663508805925, Neurons: 201, Grad norm: 4.379287398465908\n",
      "Epoch 8893, Loss: 208.56615689818128, Neurons: 201, Grad norm: 3.7568895979893875\n",
      "Epoch 8893, Loss: 208.56615689818128, Neurons: 201, Grad norm: 3.7568895979893875\n",
      "Epoch 8894, Loss: 208.5660490074556, Neurons: 201, Grad norm: 2.8197830741440333\n",
      "Epoch 8894, Loss: 208.5660490074556, Neurons: 201, Grad norm: 2.8197830741440333\n",
      "Epoch 8895, Loss: 208.56597884434424, Neurons: 201, Grad norm: 2.2258210667821077\n",
      "Epoch 8895, Loss: 208.56597884434424, Neurons: 201, Grad norm: 2.2258210667821077\n",
      "Epoch 8896, Loss: 208.5658433729831, Neurons: 201, Grad norm: 1.761557877549006\n",
      "Epoch 8896, Loss: 208.5658433729831, Neurons: 201, Grad norm: 1.761557877549006\n",
      "Epoch 8897, Loss: 208.56571280940483, Neurons: 201, Grad norm: 1.387239866727847\n",
      "Epoch 8897, Loss: 208.56571280940483, Neurons: 201, Grad norm: 1.387239866727847\n",
      "Epoch 8898, Loss: 208.56563648170152, Neurons: 201, Grad norm: 1.1652848990003366\n",
      "Epoch 8898, Loss: 208.56563648170152, Neurons: 201, Grad norm: 1.1652848990003366\n",
      "Epoch 8899, Loss: 208.56555103646312, Neurons: 201, Grad norm: 1.1124178681503927\n",
      "Epoch 8899, Loss: 208.56555103646312, Neurons: 201, Grad norm: 1.1124178681503927\n",
      "Epoch 8900, Loss: 208.56544869850694, Neurons: 201, Grad norm: 1.3582294325930542\n",
      "Epoch 8900, Loss: 208.56544869850694, Neurons: 201, Grad norm: 1.3582294325930542\n",
      "Epoch 8901, Loss: 208.5653524433108, Neurons: 201, Grad norm: 1.8578402267325573\n",
      "Epoch 8901, Loss: 208.5653524433108, Neurons: 201, Grad norm: 1.8578402267325573\n",
      "Epoch 8902, Loss: 208.56530106139778, Neurons: 201, Grad norm: 2.578258393521444\n",
      "Epoch 8902, Loss: 208.56530106139778, Neurons: 201, Grad norm: 2.578258393521444\n",
      "Epoch 8903, Loss: 208.56534564643852, Neurons: 201, Grad norm: 3.630837806329293\n",
      "Epoch 8903, Loss: 208.56534564643852, Neurons: 201, Grad norm: 3.630837806329293\n",
      "Epoch 8904, Loss: 208.565442840096, Neurons: 201, Grad norm: 4.76116129972553\n",
      "Epoch 8904, Loss: 208.565442840096, Neurons: 201, Grad norm: 4.76116129972553\n",
      "Epoch 8905, Loss: 208.5656066370229, Neurons: 201, Grad norm: 6.397203316188562\n",
      "Epoch 8905, Loss: 208.5656066370229, Neurons: 201, Grad norm: 6.397203316188562\n",
      "Epoch 8906, Loss: 208.56565429574314, Neurons: 201, Grad norm: 8.168978262461005\n",
      "Epoch 8906, Loss: 208.56565429574314, Neurons: 201, Grad norm: 8.168978262461005\n",
      "Epoch 8907, Loss: 208.56586849220986, Neurons: 201, Grad norm: 9.86475521627162\n",
      "Epoch 8907, Loss: 208.56586849220986, Neurons: 201, Grad norm: 9.86475521627162\n",
      "Epoch 8908, Loss: 208.56614049586048, Neurons: 201, Grad norm: 11.994786621259037\n",
      "Epoch 8908, Loss: 208.56614049586048, Neurons: 201, Grad norm: 11.994786621259037\n",
      "Epoch 8909, Loss: 208.56654463044023, Neurons: 201, Grad norm: 13.606063322667643\n",
      "Epoch 8909, Loss: 208.56654463044023, Neurons: 201, Grad norm: 13.606063322667643\n",
      "Epoch 8910, Loss: 208.56689852778703, Neurons: 201, Grad norm: 15.05497034475731\n",
      "Epoch 8910, Loss: 208.56689852778703, Neurons: 201, Grad norm: 15.05497034475731\n",
      "Epoch 8911, Loss: 208.56720302500267, Neurons: 201, Grad norm: 15.850119204189774\n",
      "Epoch 8911, Loss: 208.56720302500267, Neurons: 201, Grad norm: 15.850119204189774\n",
      "Epoch 8912, Loss: 208.56728392450924, Neurons: 201, Grad norm: 15.811356852079127\n",
      "Epoch 8912, Loss: 208.56728392450924, Neurons: 201, Grad norm: 15.811356852079127\n",
      "Epoch 8913, Loss: 208.5673486097441, Neurons: 201, Grad norm: 14.79278721577992\n",
      "Epoch 8913, Loss: 208.5673486097441, Neurons: 201, Grad norm: 14.79278721577992\n",
      "Epoch 8914, Loss: 208.56705017085145, Neurons: 201, Grad norm: 13.174294277912606\n",
      "Epoch 8914, Loss: 208.56705017085145, Neurons: 201, Grad norm: 13.174294277912606\n",
      "Epoch 8915, Loss: 208.5665431979199, Neurons: 201, Grad norm: 10.761579119759254\n",
      "Epoch 8915, Loss: 208.5665431979199, Neurons: 201, Grad norm: 10.761579119759254\n",
      "Epoch 8916, Loss: 208.56590970889482, Neurons: 201, Grad norm: 7.802849667802779\n",
      "Epoch 8916, Loss: 208.56590970889482, Neurons: 201, Grad norm: 7.802849667802779\n",
      "Epoch 8917, Loss: 208.56518508285455, Neurons: 201, Grad norm: 4.920463369126787\n",
      "Epoch 8917, Loss: 208.56518508285455, Neurons: 201, Grad norm: 4.920463369126787\n",
      "Epoch 8918, Loss: 208.5644398972612, Neurons: 201, Grad norm: 2.289493841360346\n",
      "Epoch 8918, Loss: 208.5644398972612, Neurons: 201, Grad norm: 2.289493841360346\n",
      "Epoch 8919, Loss: 208.56415359976182, Neurons: 201, Grad norm: 1.1397369487870885\n",
      "Epoch 8919, Loss: 208.56415359976182, Neurons: 201, Grad norm: 1.1397369487870885\n",
      "Epoch 8920, Loss: 208.56401362218546, Neurons: 201, Grad norm: 3.2718472927933795\n",
      "Epoch 8920, Loss: 208.56401362218546, Neurons: 201, Grad norm: 3.2718472927933795\n",
      "Epoch 8921, Loss: 208.56398889242462, Neurons: 201, Grad norm: 5.2628410251561\n",
      "Epoch 8921, Loss: 208.56398889242462, Neurons: 201, Grad norm: 5.2628410251561\n",
      "Epoch 8922, Loss: 208.5641367846337, Neurons: 201, Grad norm: 7.062515566800788\n",
      "Epoch 8922, Loss: 208.5641367846337, Neurons: 201, Grad norm: 7.062515566800788\n",
      "Epoch 8923, Loss: 208.5643999243437, Neurons: 201, Grad norm: 8.141492099453117\n",
      "Epoch 8923, Loss: 208.5643999243437, Neurons: 201, Grad norm: 8.141492099453117\n",
      "Epoch 8924, Loss: 208.5645282061149, Neurons: 201, Grad norm: 8.784321940007128\n",
      "Epoch 8924, Loss: 208.5645282061149, Neurons: 201, Grad norm: 8.784321940007128\n",
      "Epoch 8925, Loss: 208.56452879265993, Neurons: 201, Grad norm: 9.08064402025409\n",
      "Epoch 8925, Loss: 208.56452879265993, Neurons: 201, Grad norm: 9.08064402025409\n",
      "Epoch 8926, Loss: 208.56442621785192, Neurons: 201, Grad norm: 8.638755258123284\n",
      "Epoch 8926, Loss: 208.56442621785192, Neurons: 201, Grad norm: 8.638755258123284\n",
      "Epoch 8927, Loss: 208.56420206477148, Neurons: 201, Grad norm: 7.677851096959562\n",
      "Epoch 8927, Loss: 208.56420206477148, Neurons: 201, Grad norm: 7.677851096959562\n",
      "Epoch 8928, Loss: 208.56394171644538, Neurons: 201, Grad norm: 6.186169532325955\n",
      "Epoch 8928, Loss: 208.56394171644538, Neurons: 201, Grad norm: 6.186169532325955\n",
      "Epoch 8929, Loss: 208.56366638643493, Neurons: 201, Grad norm: 4.309090840095394\n",
      "Epoch 8929, Loss: 208.56366638643493, Neurons: 201, Grad norm: 4.309090840095394\n",
      "Epoch 8930, Loss: 208.56337968389607, Neurons: 201, Grad norm: 2.515433992182204\n",
      "Epoch 8930, Loss: 208.56337968389607, Neurons: 201, Grad norm: 2.515433992182204\n",
      "Epoch 8931, Loss: 208.5632287750705, Neurons: 201, Grad norm: 1.4692891457203638\n",
      "Epoch 8931, Loss: 208.5632287750705, Neurons: 201, Grad norm: 1.4692891457203638\n",
      "Epoch 8932, Loss: 208.5631117099488, Neurons: 201, Grad norm: 1.6266982882810106\n",
      "Epoch 8932, Loss: 208.5631117099488, Neurons: 201, Grad norm: 1.6266982882810106\n",
      "Epoch 8933, Loss: 208.56305752711458, Neurons: 201, Grad norm: 2.000354232622484\n",
      "Epoch 8933, Loss: 208.56305752711458, Neurons: 201, Grad norm: 2.000354232622484\n",
      "Epoch 8934, Loss: 208.56297924038833, Neurons: 201, Grad norm: 2.184285465477616\n",
      "Epoch 8934, Loss: 208.56297924038833, Neurons: 201, Grad norm: 2.184285465477616\n",
      "Epoch 8935, Loss: 208.56288363516407, Neurons: 201, Grad norm: 2.1770988629661314\n",
      "Epoch 8935, Loss: 208.56288363516407, Neurons: 201, Grad norm: 2.1770988629661314\n",
      "Epoch 8936, Loss: 208.56277881258382, Neurons: 201, Grad norm: 1.8007134341306474\n",
      "Epoch 8936, Loss: 208.56277881258382, Neurons: 201, Grad norm: 1.8007134341306474\n",
      "Epoch 8937, Loss: 208.56266107879182, Neurons: 201, Grad norm: 1.1978380333987224\n",
      "Epoch 8937, Loss: 208.56266107879182, Neurons: 201, Grad norm: 1.1978380333987224\n",
      "Epoch 8938, Loss: 208.56257078777364, Neurons: 201, Grad norm: 0.9369204746006679\n",
      "Epoch 8938, Loss: 208.56257078777364, Neurons: 201, Grad norm: 0.9369204746006679\n",
      "Epoch 8939, Loss: 208.56246311807632, Neurons: 201, Grad norm: 1.1381625355844724\n",
      "Epoch 8939, Loss: 208.56246311807632, Neurons: 201, Grad norm: 1.1381625355844724\n",
      "Epoch 8940, Loss: 208.5624538977807, Neurons: 201, Grad norm: 1.6866951939669916\n",
      "Epoch 8940, Loss: 208.5624538977807, Neurons: 201, Grad norm: 1.6866951939669916\n",
      "Epoch 8941, Loss: 208.5624799123365, Neurons: 201, Grad norm: 1.9784127604580584\n",
      "Epoch 8941, Loss: 208.5624799123365, Neurons: 201, Grad norm: 1.9784127604580584\n",
      "Epoch 8942, Loss: 208.5624932958109, Neurons: 201, Grad norm: 1.9717300217248899\n",
      "Epoch 8942, Loss: 208.5624932958109, Neurons: 201, Grad norm: 1.9717300217248899\n",
      "Epoch 8943, Loss: 208.5624031410006, Neurons: 201, Grad norm: 2.196875911366438\n",
      "Epoch 8943, Loss: 208.5624031410006, Neurons: 201, Grad norm: 2.196875911366438\n",
      "Epoch 8944, Loss: 208.56231090988877, Neurons: 201, Grad norm: 2.9125331082519708\n",
      "Epoch 8944, Loss: 208.56231090988877, Neurons: 201, Grad norm: 2.9125331082519708\n",
      "Epoch 8945, Loss: 208.562237677322, Neurons: 201, Grad norm: 4.137565505075994\n",
      "Epoch 8945, Loss: 208.562237677322, Neurons: 201, Grad norm: 4.137565505075994\n",
      "Epoch 8946, Loss: 208.56219713627823, Neurons: 201, Grad norm: 5.478162064465567\n",
      "Epoch 8946, Loss: 208.56219713627823, Neurons: 201, Grad norm: 5.478162064465567\n",
      "Epoch 8947, Loss: 208.56219574363595, Neurons: 201, Grad norm: 6.538084374292351\n",
      "Epoch 8947, Loss: 208.56219574363595, Neurons: 201, Grad norm: 6.538084374292351\n",
      "Epoch 8948, Loss: 208.5622841512156, Neurons: 201, Grad norm: 7.87980113249558\n",
      "Epoch 8948, Loss: 208.5622841512156, Neurons: 201, Grad norm: 7.87980113249558\n",
      "Epoch 8949, Loss: 208.56238881830518, Neurons: 201, Grad norm: 9.267524155545036\n",
      "Epoch 8949, Loss: 208.56238881830518, Neurons: 201, Grad norm: 9.267524155545036\n",
      "Epoch 8950, Loss: 208.56256461180985, Neurons: 201, Grad norm: 10.308267078317124\n",
      "Epoch 8950, Loss: 208.56256461180985, Neurons: 201, Grad norm: 10.308267078317124\n",
      "Epoch 8951, Loss: 208.56282373128403, Neurons: 201, Grad norm: 11.327155712460216\n",
      "Epoch 8951, Loss: 208.56282373128403, Neurons: 201, Grad norm: 11.327155712460216\n",
      "Epoch 8952, Loss: 208.56309335439568, Neurons: 201, Grad norm: 12.102039437591028\n",
      "Epoch 8952, Loss: 208.56309335439568, Neurons: 201, Grad norm: 12.102039437591028\n",
      "Epoch 8953, Loss: 208.5635169917204, Neurons: 201, Grad norm: 12.55068565885658\n",
      "Epoch 8953, Loss: 208.5635169917204, Neurons: 201, Grad norm: 12.55068565885658\n",
      "Epoch 8954, Loss: 208.56403248413002, Neurons: 201, Grad norm: 12.973659215853615\n",
      "Epoch 8954, Loss: 208.56403248413002, Neurons: 201, Grad norm: 12.973659215853615\n",
      "Epoch 8955, Loss: 208.56434944144678, Neurons: 201, Grad norm: 13.274596785351648\n",
      "Epoch 8955, Loss: 208.56434944144678, Neurons: 201, Grad norm: 13.274596785351648\n",
      "Epoch 8956, Loss: 208.5643883260121, Neurons: 201, Grad norm: 13.169707157096001\n",
      "Epoch 8956, Loss: 208.5643883260121, Neurons: 201, Grad norm: 13.169707157096001\n",
      "Epoch 8957, Loss: 208.56388328573976, Neurons: 201, Grad norm: 12.58880329453706\n",
      "Epoch 8957, Loss: 208.56388328573976, Neurons: 201, Grad norm: 12.58880329453706\n",
      "Epoch 8958, Loss: 208.56319789155236, Neurons: 201, Grad norm: 11.670947491560652\n",
      "Epoch 8958, Loss: 208.56319789155236, Neurons: 201, Grad norm: 11.670947491560652\n",
      "Epoch 8959, Loss: 208.56254569215832, Neurons: 201, Grad norm: 10.020119945886306\n",
      "Epoch 8959, Loss: 208.56254569215832, Neurons: 201, Grad norm: 10.020119945886306\n",
      "Epoch 8960, Loss: 208.56203237469688, Neurons: 201, Grad norm: 7.437784027193702\n",
      "Epoch 8960, Loss: 208.56203237469688, Neurons: 201, Grad norm: 7.437784027193702\n",
      "Epoch 8961, Loss: 208.56149525879115, Neurons: 201, Grad norm: 4.419333303689232\n",
      "Epoch 8961, Loss: 208.56149525879115, Neurons: 201, Grad norm: 4.419333303689232\n",
      "Epoch 8962, Loss: 208.56104961348626, Neurons: 201, Grad norm: 1.8853336556172744\n",
      "Epoch 8962, Loss: 208.56104961348626, Neurons: 201, Grad norm: 1.8853336556172744\n",
      "Epoch 8963, Loss: 208.5608760396369, Neurons: 201, Grad norm: 3.9102923899034696\n",
      "Epoch 8963, Loss: 208.5608760396369, Neurons: 201, Grad norm: 3.9102923899034696\n",
      "Epoch 8964, Loss: 208.56100603870775, Neurons: 201, Grad norm: 7.282204119519083\n",
      "Epoch 8964, Loss: 208.56100603870775, Neurons: 201, Grad norm: 7.282204119519083\n",
      "Epoch 8965, Loss: 208.56134051469712, Neurons: 201, Grad norm: 10.635816042034563\n",
      "Epoch 8965, Loss: 208.56134051469712, Neurons: 201, Grad norm: 10.635816042034563\n",
      "Epoch 8966, Loss: 208.56182522515795, Neurons: 201, Grad norm: 13.165431425340486\n",
      "Epoch 8966, Loss: 208.56182522515795, Neurons: 201, Grad norm: 13.165431425340486\n",
      "Epoch 8967, Loss: 208.56243513697274, Neurons: 201, Grad norm: 14.889930910144708\n",
      "Epoch 8967, Loss: 208.56243513697274, Neurons: 201, Grad norm: 14.889930910144708\n",
      "Epoch 8968, Loss: 208.5629080696546, Neurons: 201, Grad norm: 15.500871633438143\n",
      "Epoch 8968, Loss: 208.5629080696546, Neurons: 201, Grad norm: 15.500871633438143\n",
      "Epoch 8969, Loss: 208.56308289623144, Neurons: 201, Grad norm: 14.71423762138329\n",
      "Epoch 8969, Loss: 208.56308289623144, Neurons: 201, Grad norm: 14.71423762138329\n",
      "Epoch 8970, Loss: 208.56298688131776, Neurons: 201, Grad norm: 13.0709648847322\n",
      "Epoch 8970, Loss: 208.56298688131776, Neurons: 201, Grad norm: 13.0709648847322\n",
      "Epoch 8971, Loss: 208.56251598168365, Neurons: 201, Grad norm: 10.83048298100863\n",
      "Epoch 8971, Loss: 208.56251598168365, Neurons: 201, Grad norm: 10.83048298100863\n",
      "Epoch 8972, Loss: 208.56189279653688, Neurons: 201, Grad norm: 7.772421020970124\n",
      "Epoch 8972, Loss: 208.56189279653688, Neurons: 201, Grad norm: 7.772421020970124\n",
      "Epoch 8973, Loss: 208.56110389288975, Neurons: 201, Grad norm: 4.816004591206111\n",
      "Epoch 8973, Loss: 208.56110389288975, Neurons: 201, Grad norm: 4.816004591206111\n",
      "Epoch 8974, Loss: 208.56037658338605, Neurons: 201, Grad norm: 2.1965274719164363\n",
      "Epoch 8974, Loss: 208.56037658338605, Neurons: 201, Grad norm: 2.1965274719164363\n",
      "Epoch 8975, Loss: 208.55997435315575, Neurons: 201, Grad norm: 1.496339352897809\n",
      "Epoch 8975, Loss: 208.55997435315575, Neurons: 201, Grad norm: 1.496339352897809\n",
      "Epoch 8976, Loss: 208.55974529683252, Neurons: 201, Grad norm: 3.5241373118447332\n",
      "Epoch 8976, Loss: 208.55974529683252, Neurons: 201, Grad norm: 3.5241373118447332\n",
      "Epoch 8977, Loss: 208.55975115651626, Neurons: 201, Grad norm: 4.930255020282278\n",
      "Epoch 8977, Loss: 208.55975115651626, Neurons: 201, Grad norm: 4.930255020282278\n",
      "Epoch 8978, Loss: 208.55978872393425, Neurons: 201, Grad norm: 6.098560246402287\n",
      "Epoch 8978, Loss: 208.55978872393425, Neurons: 201, Grad norm: 6.098560246402287\n",
      "Epoch 8979, Loss: 208.55979196078636, Neurons: 201, Grad norm: 6.773704940913341\n",
      "Epoch 8979, Loss: 208.55979196078636, Neurons: 201, Grad norm: 6.773704940913341\n",
      "Epoch 8980, Loss: 208.5598895034427, Neurons: 201, Grad norm: 6.7127502868231455\n",
      "Epoch 8980, Loss: 208.5598895034427, Neurons: 201, Grad norm: 6.7127502868231455\n",
      "Epoch 8981, Loss: 208.55982374352857, Neurons: 201, Grad norm: 6.523069100390749\n",
      "Epoch 8981, Loss: 208.55982374352857, Neurons: 201, Grad norm: 6.523069100390749\n",
      "Epoch 8982, Loss: 208.5597250409255, Neurons: 201, Grad norm: 6.354107945003894\n",
      "Epoch 8982, Loss: 208.5597250409255, Neurons: 201, Grad norm: 6.354107945003894\n",
      "Epoch 8983, Loss: 208.55966886507423, Neurons: 201, Grad norm: 5.811041782467937\n",
      "Epoch 8983, Loss: 208.55966886507423, Neurons: 201, Grad norm: 5.811041782467937\n",
      "Epoch 8984, Loss: 208.5595267510051, Neurons: 201, Grad norm: 5.275058880836014\n",
      "Epoch 8984, Loss: 208.5595267510051, Neurons: 201, Grad norm: 5.275058880836014\n",
      "Epoch 8985, Loss: 208.55930519029923, Neurons: 201, Grad norm: 4.799854010196939\n",
      "Epoch 8985, Loss: 208.55930519029923, Neurons: 201, Grad norm: 4.799854010196939\n",
      "Epoch 8986, Loss: 208.55902683632186, Neurons: 201, Grad norm: 4.476204840564612\n",
      "Epoch 8986, Loss: 208.55902683632186, Neurons: 201, Grad norm: 4.476204840564612\n",
      "Epoch 8987, Loss: 208.55882286869564, Neurons: 201, Grad norm: 3.962725023013814\n",
      "Epoch 8987, Loss: 208.55882286869564, Neurons: 201, Grad norm: 3.962725023013814\n",
      "Epoch 8988, Loss: 208.5586482309257, Neurons: 201, Grad norm: 3.3680709864427416\n",
      "Epoch 8988, Loss: 208.5586482309257, Neurons: 201, Grad norm: 3.3680709864427416\n",
      "Epoch 8989, Loss: 208.55852163597206, Neurons: 201, Grad norm: 3.1624807789603624\n",
      "Epoch 8989, Loss: 208.55852163597206, Neurons: 201, Grad norm: 3.1624807789603624\n",
      "Epoch 8990, Loss: 208.5584502056144, Neurons: 201, Grad norm: 2.719205829780088\n",
      "Epoch 8990, Loss: 208.5584502056144, Neurons: 201, Grad norm: 2.719205829780088\n",
      "Epoch 8991, Loss: 208.55835261440322, Neurons: 201, Grad norm: 2.689863267760753\n",
      "Epoch 8991, Loss: 208.55835261440322, Neurons: 201, Grad norm: 2.689863267760753\n",
      "Epoch 8992, Loss: 208.55834495156816, Neurons: 201, Grad norm: 2.745133228323627\n",
      "Epoch 8992, Loss: 208.55834495156816, Neurons: 201, Grad norm: 2.745133228323627\n",
      "Epoch 8993, Loss: 208.55831203266501, Neurons: 201, Grad norm: 2.8585470156121175\n",
      "Epoch 8993, Loss: 208.55831203266501, Neurons: 201, Grad norm: 2.8585470156121175\n",
      "Epoch 8994, Loss: 208.55823696214932, Neurons: 201, Grad norm: 3.5058764334527286\n",
      "Epoch 8994, Loss: 208.55823696214932, Neurons: 201, Grad norm: 3.5058764334527286\n",
      "Epoch 8995, Loss: 208.5581989585862, Neurons: 201, Grad norm: 3.7299918211347447\n",
      "Epoch 8995, Loss: 208.5581989585862, Neurons: 201, Grad norm: 3.7299918211347447\n",
      "Epoch 8996, Loss: 208.55808749826653, Neurons: 201, Grad norm: 4.487779449899934\n",
      "Epoch 8996, Loss: 208.55808749826653, Neurons: 201, Grad norm: 4.487779449899934\n",
      "Epoch 8997, Loss: 208.55803144479097, Neurons: 201, Grad norm: 5.200916053334291\n",
      "Epoch 8997, Loss: 208.55803144479097, Neurons: 201, Grad norm: 5.200916053334291\n",
      "Epoch 8998, Loss: 208.558032835292, Neurons: 201, Grad norm: 5.672844898804958\n",
      "Epoch 8998, Loss: 208.558032835292, Neurons: 201, Grad norm: 5.672844898804958\n",
      "Epoch 8999, Loss: 208.55800851508442, Neurons: 201, Grad norm: 6.386852672086967\n",
      "Epoch 8999, Loss: 208.55800851508442, Neurons: 201, Grad norm: 6.386852672086967\n",
      "Epoch 9000, Loss: 208.55799153747304, Neurons: 201, Grad norm: 6.9604749403202835\n",
      "Epoch 9000, Loss: 208.55799153747304, Neurons: 201, Grad norm: 6.9604749403202835\n",
      "Epoch 9001, Loss: 208.55804555761895, Neurons: 201, Grad norm: 7.268308012226226\n",
      "Epoch 9001, Loss: 208.55804555761895, Neurons: 201, Grad norm: 7.268308012226226\n",
      "Epoch 9002, Loss: 208.55800828892532, Neurons: 201, Grad norm: 7.66052957363626\n",
      "Epoch 9002, Loss: 208.55800828892532, Neurons: 201, Grad norm: 7.66052957363626\n",
      "Epoch 9003, Loss: 208.55798956787896, Neurons: 201, Grad norm: 7.736865883714466\n",
      "Epoch 9003, Loss: 208.55798956787896, Neurons: 201, Grad norm: 7.736865883714466\n",
      "Epoch 9004, Loss: 208.55804869900635, Neurons: 201, Grad norm: 7.35144768364802\n",
      "Epoch 9004, Loss: 208.55804869900635, Neurons: 201, Grad norm: 7.35144768364802\n",
      "Epoch 9005, Loss: 208.5580025611454, Neurons: 201, Grad norm: 7.2770324288210775\n",
      "Epoch 9005, Loss: 208.5580025611454, Neurons: 201, Grad norm: 7.2770324288210775\n",
      "Epoch 9006, Loss: 208.55779761736886, Neurons: 201, Grad norm: 7.1561642894755915\n",
      "Epoch 9006, Loss: 208.55779761736886, Neurons: 201, Grad norm: 7.1561642894755915\n",
      "Epoch 9007, Loss: 208.5576931182851, Neurons: 201, Grad norm: 6.6350022392268935\n",
      "Epoch 9007, Loss: 208.5576931182851, Neurons: 201, Grad norm: 6.6350022392268935\n",
      "Epoch 9008, Loss: 208.55749425629853, Neurons: 201, Grad norm: 6.240205353533468\n",
      "Epoch 9008, Loss: 208.55749425629853, Neurons: 201, Grad norm: 6.240205353533468\n",
      "Epoch 9009, Loss: 208.55732647490936, Neurons: 201, Grad norm: 5.695859444743417\n",
      "Epoch 9009, Loss: 208.55732647490936, Neurons: 201, Grad norm: 5.695859444743417\n",
      "Epoch 9010, Loss: 208.55722825075833, Neurons: 201, Grad norm: 5.009214235635469\n",
      "Epoch 9010, Loss: 208.55722825075833, Neurons: 201, Grad norm: 5.009214235635469\n",
      "Epoch 9011, Loss: 208.55709347209648, Neurons: 201, Grad norm: 4.218844936570148\n",
      "Epoch 9011, Loss: 208.55709347209648, Neurons: 201, Grad norm: 4.218844936570148\n",
      "Epoch 9012, Loss: 208.55692776499544, Neurons: 201, Grad norm: 3.601134031186323\n",
      "Epoch 9012, Loss: 208.55692776499544, Neurons: 201, Grad norm: 3.601134031186323\n",
      "Epoch 9013, Loss: 208.5568401663263, Neurons: 201, Grad norm: 2.702758265584941\n",
      "Epoch 9013, Loss: 208.5568401663263, Neurons: 201, Grad norm: 2.702758265584941\n",
      "Epoch 9014, Loss: 208.55677128870792, Neurons: 201, Grad norm: 2.0737148546025512\n",
      "Epoch 9014, Loss: 208.55677128870792, Neurons: 201, Grad norm: 2.0737148546025512\n",
      "Epoch 9015, Loss: 208.5566381420897, Neurons: 201, Grad norm: 2.0675968337630106\n",
      "Epoch 9015, Loss: 208.5566381420897, Neurons: 201, Grad norm: 2.0675968337630106\n",
      "Epoch 9016, Loss: 208.55650821337701, Neurons: 201, Grad norm: 1.7966655046096327\n",
      "Epoch 9016, Loss: 208.55650821337701, Neurons: 201, Grad norm: 1.7966655046096327\n",
      "Epoch 9017, Loss: 208.556421931707, Neurons: 201, Grad norm: 2.0038215867285545\n",
      "Epoch 9017, Loss: 208.556421931707, Neurons: 201, Grad norm: 2.0038215867285545\n",
      "Epoch 9018, Loss: 208.5563318323192, Neurons: 201, Grad norm: 2.6360761740943404\n",
      "Epoch 9018, Loss: 208.5563318323192, Neurons: 201, Grad norm: 2.6360761740943404\n",
      "Epoch 9019, Loss: 208.55625491031336, Neurons: 201, Grad norm: 3.0870881764872093\n",
      "Epoch 9019, Loss: 208.55625491031336, Neurons: 201, Grad norm: 3.0870881764872093\n",
      "Epoch 9020, Loss: 208.55623094073115, Neurons: 201, Grad norm: 3.5385166350446084\n",
      "Epoch 9020, Loss: 208.55623094073115, Neurons: 201, Grad norm: 3.5385166350446084\n",
      "Epoch 9021, Loss: 208.5562571092606, Neurons: 201, Grad norm: 3.4702063330439326\n",
      "Epoch 9021, Loss: 208.5562571092606, Neurons: 201, Grad norm: 3.4702063330439326\n",
      "Epoch 9022, Loss: 208.55613012041653, Neurons: 201, Grad norm: 3.2575679411899423\n",
      "Epoch 9022, Loss: 208.55613012041653, Neurons: 201, Grad norm: 3.2575679411899423\n",
      "Epoch 9023, Loss: 208.55597096589554, Neurons: 201, Grad norm: 2.600234412793701\n",
      "Epoch 9023, Loss: 208.55597096589554, Neurons: 201, Grad norm: 2.600234412793701\n",
      "Epoch 9024, Loss: 208.5559036923806, Neurons: 201, Grad norm: 2.197509381479819\n",
      "Epoch 9024, Loss: 208.5559036923806, Neurons: 201, Grad norm: 2.197509381479819\n",
      "Epoch 9025, Loss: 208.55580047589328, Neurons: 201, Grad norm: 2.3056345349630383\n",
      "Epoch 9025, Loss: 208.55580047589328, Neurons: 201, Grad norm: 2.3056345349630383\n",
      "Epoch 9026, Loss: 208.5557863865867, Neurons: 201, Grad norm: 1.8399024612214978\n",
      "Epoch 9026, Loss: 208.5557863865867, Neurons: 201, Grad norm: 1.8399024612214978\n",
      "Epoch 9027, Loss: 208.55571694369544, Neurons: 201, Grad norm: 2.1583578760747257\n",
      "Epoch 9027, Loss: 208.55571694369544, Neurons: 201, Grad norm: 2.1583578760747257\n",
      "Epoch 9028, Loss: 208.55564719448856, Neurons: 201, Grad norm: 2.861829763473023\n",
      "Epoch 9028, Loss: 208.55564719448856, Neurons: 201, Grad norm: 2.861829763473023\n",
      "Epoch 9029, Loss: 208.55558894034874, Neurons: 201, Grad norm: 3.3595281580025027\n",
      "Epoch 9029, Loss: 208.55558894034874, Neurons: 201, Grad norm: 3.3595281580025027\n",
      "Epoch 9030, Loss: 208.55549400776692, Neurons: 201, Grad norm: 4.4949317386601795\n",
      "Epoch 9030, Loss: 208.55549400776692, Neurons: 201, Grad norm: 4.4949317386601795\n",
      "Epoch 9031, Loss: 208.55550079472465, Neurons: 201, Grad norm: 5.1393474432457085\n",
      "Epoch 9031, Loss: 208.55550079472465, Neurons: 201, Grad norm: 5.1393474432457085\n",
      "Epoch 9032, Loss: 208.555515405597, Neurons: 201, Grad norm: 5.926425481319582\n",
      "Epoch 9032, Loss: 208.555515405597, Neurons: 201, Grad norm: 5.926425481319582\n",
      "Epoch 9033, Loss: 208.55550523317336, Neurons: 201, Grad norm: 6.4950860604647165\n",
      "Epoch 9033, Loss: 208.55550523317336, Neurons: 201, Grad norm: 6.4950860604647165\n",
      "Epoch 9034, Loss: 208.5555594057209, Neurons: 201, Grad norm: 7.293048384695035\n",
      "Epoch 9034, Loss: 208.5555594057209, Neurons: 201, Grad norm: 7.293048384695035\n",
      "Epoch 9035, Loss: 208.55562890355816, Neurons: 201, Grad norm: 8.340423589271028\n",
      "Epoch 9035, Loss: 208.55562890355816, Neurons: 201, Grad norm: 8.340423589271028\n",
      "Epoch 9036, Loss: 208.55581142155015, Neurons: 201, Grad norm: 9.679483101050392\n",
      "Epoch 9036, Loss: 208.55581142155015, Neurons: 201, Grad norm: 9.679483101050392\n",
      "Epoch 9037, Loss: 208.5562130087042, Neurons: 201, Grad norm: 11.324411948844263\n",
      "Epoch 9037, Loss: 208.5562130087042, Neurons: 201, Grad norm: 11.324411948844263\n",
      "Epoch 9038, Loss: 208.55680295116113, Neurons: 201, Grad norm: 13.08195215698028\n",
      "Epoch 9038, Loss: 208.55680295116113, Neurons: 201, Grad norm: 13.08195215698028\n",
      "Epoch 9039, Loss: 208.55719107637856, Neurons: 201, Grad norm: 14.871293548855569\n",
      "Epoch 9039, Loss: 208.55719107637856, Neurons: 201, Grad norm: 14.871293548855569\n",
      "Epoch 9040, Loss: 208.55765382069234, Neurons: 201, Grad norm: 16.85968281643806\n",
      "Epoch 9040, Loss: 208.55765382069234, Neurons: 201, Grad norm: 16.85968281643806\n",
      "Epoch 9041, Loss: 208.55811103299982, Neurons: 201, Grad norm: 18.38168941296873\n",
      "Epoch 9041, Loss: 208.55811103299982, Neurons: 201, Grad norm: 18.38168941296873\n",
      "Epoch 9042, Loss: 208.55844412500394, Neurons: 201, Grad norm: 19.298174122156492\n",
      "Epoch 9042, Loss: 208.55844412500394, Neurons: 201, Grad norm: 19.298174122156492\n",
      "Epoch 9043, Loss: 208.5586437041958, Neurons: 201, Grad norm: 19.394277498057704\n",
      "Epoch 9043, Loss: 208.5586437041958, Neurons: 201, Grad norm: 19.394277498057704\n",
      "Epoch 9044, Loss: 208.55846560676383, Neurons: 201, Grad norm: 18.47845210451905\n",
      "Epoch 9044, Loss: 208.55846560676383, Neurons: 201, Grad norm: 18.47845210451905\n",
      "Epoch 9045, Loss: 208.55815586801896, Neurons: 201, Grad norm: 16.4105516744276\n",
      "Epoch 9045, Loss: 208.55815586801896, Neurons: 201, Grad norm: 16.4105516744276\n",
      "Epoch 9046, Loss: 208.55741409285554, Neurons: 201, Grad norm: 13.174854436915558\n",
      "Epoch 9046, Loss: 208.55741409285554, Neurons: 201, Grad norm: 13.174854436915558\n",
      "Epoch 9047, Loss: 208.5563445104926, Neurons: 201, Grad norm: 9.188729809275305\n",
      "Epoch 9047, Loss: 208.5563445104926, Neurons: 201, Grad norm: 9.188729809275305\n",
      "Epoch 9048, Loss: 208.55529780794987, Neurons: 201, Grad norm: 5.103696391013867\n",
      "Epoch 9048, Loss: 208.55529780794987, Neurons: 201, Grad norm: 5.103696391013867\n",
      "Epoch 9049, Loss: 208.55461549561576, Neurons: 201, Grad norm: 2.263625846453775\n",
      "Epoch 9049, Loss: 208.55461549561576, Neurons: 201, Grad norm: 2.263625846453775\n",
      "Epoch 9050, Loss: 208.55415715722862, Neurons: 201, Grad norm: 2.844004724009778\n",
      "Epoch 9050, Loss: 208.55415715722862, Neurons: 201, Grad norm: 2.844004724009778\n",
      "Epoch 9051, Loss: 208.55403126903943, Neurons: 201, Grad norm: 4.9019106748307015\n",
      "Epoch 9051, Loss: 208.55403126903943, Neurons: 201, Grad norm: 4.9019106748307015\n",
      "Epoch 9052, Loss: 208.55402176800706, Neurons: 201, Grad norm: 6.533755468215566\n",
      "Epoch 9052, Loss: 208.55402176800706, Neurons: 201, Grad norm: 6.533755468215566\n",
      "Epoch 9053, Loss: 208.55417639940057, Neurons: 201, Grad norm: 7.539691511012507\n",
      "Epoch 9053, Loss: 208.55417639940057, Neurons: 201, Grad norm: 7.539691511012507\n",
      "Epoch 9054, Loss: 208.55431304442925, Neurons: 201, Grad norm: 7.971929880105628\n",
      "Epoch 9054, Loss: 208.55431304442925, Neurons: 201, Grad norm: 7.971929880105628\n",
      "Epoch 9055, Loss: 208.5544428317442, Neurons: 201, Grad norm: 8.246536002972205\n",
      "Epoch 9055, Loss: 208.5544428317442, Neurons: 201, Grad norm: 8.246536002972205\n",
      "Epoch 9056, Loss: 208.55462491651895, Neurons: 201, Grad norm: 7.9961564016941\n",
      "Epoch 9056, Loss: 208.55462491651895, Neurons: 201, Grad norm: 7.9961564016941\n",
      "Epoch 9057, Loss: 208.55456963456191, Neurons: 201, Grad norm: 7.675689158138119\n",
      "Epoch 9057, Loss: 208.55456963456191, Neurons: 201, Grad norm: 7.675689158138119\n",
      "Epoch 9058, Loss: 208.55442173442316, Neurons: 201, Grad norm: 7.023827934344176\n",
      "Epoch 9058, Loss: 208.55442173442316, Neurons: 201, Grad norm: 7.023827934344176\n",
      "Epoch 9059, Loss: 208.55409200754775, Neurons: 201, Grad norm: 6.453155800977042\n",
      "Epoch 9059, Loss: 208.55409200754775, Neurons: 201, Grad norm: 6.453155800977042\n",
      "Epoch 9060, Loss: 208.55370215939323, Neurons: 201, Grad norm: 5.344399597458002\n",
      "Epoch 9060, Loss: 208.55370215939323, Neurons: 201, Grad norm: 5.344399597458002\n",
      "Epoch 9061, Loss: 208.5534286022837, Neurons: 201, Grad norm: 3.9566276205473763\n",
      "Epoch 9061, Loss: 208.5534286022837, Neurons: 201, Grad norm: 3.9566276205473763\n",
      "Epoch 9062, Loss: 208.55322233516847, Neurons: 201, Grad norm: 2.542132894669532\n",
      "Epoch 9062, Loss: 208.55322233516847, Neurons: 201, Grad norm: 2.542132894669532\n",
      "Epoch 9063, Loss: 208.55304970036255, Neurons: 201, Grad norm: 0.9701570924640546\n",
      "Epoch 9063, Loss: 208.55304970036255, Neurons: 201, Grad norm: 0.9701570924640546\n",
      "Epoch 9064, Loss: 208.55291558958717, Neurons: 201, Grad norm: 1.7507208804396517\n",
      "Epoch 9064, Loss: 208.55291558958717, Neurons: 201, Grad norm: 1.7507208804396517\n",
      "Epoch 9065, Loss: 208.5528928040655, Neurons: 201, Grad norm: 3.4871859535084413\n",
      "Epoch 9065, Loss: 208.5528928040655, Neurons: 201, Grad norm: 3.4871859535084413\n",
      "Epoch 9066, Loss: 208.55300481723413, Neurons: 201, Grad norm: 5.262641888163394\n",
      "Epoch 9066, Loss: 208.55300481723413, Neurons: 201, Grad norm: 5.262641888163394\n",
      "Epoch 9067, Loss: 208.55324107361898, Neurons: 201, Grad norm: 7.105587189705048\n",
      "Epoch 9067, Loss: 208.55324107361898, Neurons: 201, Grad norm: 7.105587189705048\n",
      "Epoch 9068, Loss: 208.5534246366567, Neurons: 201, Grad norm: 9.106111531469159\n",
      "Epoch 9068, Loss: 208.5534246366567, Neurons: 201, Grad norm: 9.106111531469159\n",
      "Epoch 9069, Loss: 208.5536939272765, Neurons: 201, Grad norm: 10.66352037999991\n",
      "Epoch 9069, Loss: 208.5536939272765, Neurons: 201, Grad norm: 10.66352037999991\n",
      "Epoch 9070, Loss: 208.55392583405944, Neurons: 201, Grad norm: 12.088612089532157\n",
      "Epoch 9070, Loss: 208.55392583405944, Neurons: 201, Grad norm: 12.088612089532157\n",
      "Epoch 9071, Loss: 208.5541921687074, Neurons: 201, Grad norm: 12.716250450373208\n",
      "Epoch 9071, Loss: 208.5541921687074, Neurons: 201, Grad norm: 12.716250450373208\n",
      "Epoch 9072, Loss: 208.5541955693315, Neurons: 201, Grad norm: 12.918228757843778\n",
      "Epoch 9072, Loss: 208.5541955693315, Neurons: 201, Grad norm: 12.918228757843778\n",
      "Epoch 9073, Loss: 208.55414404259488, Neurons: 201, Grad norm: 12.408664882280322\n",
      "Epoch 9073, Loss: 208.55414404259488, Neurons: 201, Grad norm: 12.408664882280322\n",
      "Epoch 9074, Loss: 208.55395438229598, Neurons: 201, Grad norm: 10.987971248295189\n",
      "Epoch 9074, Loss: 208.55395438229598, Neurons: 201, Grad norm: 10.987971248295189\n",
      "Epoch 9075, Loss: 208.55359791153114, Neurons: 201, Grad norm: 9.02887975085504\n",
      "Epoch 9075, Loss: 208.55359791153114, Neurons: 201, Grad norm: 9.02887975085504\n",
      "Epoch 9076, Loss: 208.55314632843292, Neurons: 201, Grad norm: 6.591180467449982\n",
      "Epoch 9076, Loss: 208.55314632843292, Neurons: 201, Grad norm: 6.591180467449982\n",
      "Epoch 9077, Loss: 208.55268755145616, Neurons: 201, Grad norm: 4.068529332816335\n",
      "Epoch 9077, Loss: 208.55268755145616, Neurons: 201, Grad norm: 4.068529332816335\n",
      "Epoch 9078, Loss: 208.5522742513395, Neurons: 201, Grad norm: 1.959444784666521\n",
      "Epoch 9078, Loss: 208.5522742513395, Neurons: 201, Grad norm: 1.959444784666521\n",
      "Epoch 9079, Loss: 208.55195280011262, Neurons: 201, Grad norm: 0.9247023766098889\n",
      "Epoch 9079, Loss: 208.55195280011262, Neurons: 201, Grad norm: 0.9247023766098889\n",
      "Epoch 9080, Loss: 208.55181272703248, Neurons: 201, Grad norm: 2.349307641531673\n",
      "Epoch 9080, Loss: 208.55181272703248, Neurons: 201, Grad norm: 2.349307641531673\n",
      "Epoch 9081, Loss: 208.5517469579084, Neurons: 201, Grad norm: 3.6626018417970485\n",
      "Epoch 9081, Loss: 208.5517469579084, Neurons: 201, Grad norm: 3.6626018417970485\n",
      "Epoch 9082, Loss: 208.5518238351149, Neurons: 201, Grad norm: 4.860298148267758\n",
      "Epoch 9082, Loss: 208.5518238351149, Neurons: 201, Grad norm: 4.860298148267758\n",
      "Epoch 9083, Loss: 208.55198291361734, Neurons: 201, Grad norm: 5.999841691662798\n",
      "Epoch 9083, Loss: 208.55198291361734, Neurons: 201, Grad norm: 5.999841691662798\n",
      "Epoch 9084, Loss: 208.55203412775333, Neurons: 201, Grad norm: 6.67629372076969\n",
      "Epoch 9084, Loss: 208.55203412775333, Neurons: 201, Grad norm: 6.67629372076969\n",
      "Epoch 9085, Loss: 208.55213529425393, Neurons: 201, Grad norm: 7.159195159614757\n",
      "Epoch 9085, Loss: 208.55213529425393, Neurons: 201, Grad norm: 7.159195159614757\n",
      "Epoch 9086, Loss: 208.55200683449723, Neurons: 201, Grad norm: 7.334765459965902\n",
      "Epoch 9086, Loss: 208.55200683449723, Neurons: 201, Grad norm: 7.334765459965902\n",
      "Epoch 9087, Loss: 208.55180089496284, Neurons: 201, Grad norm: 7.022409430492842\n",
      "Epoch 9087, Loss: 208.55180089496284, Neurons: 201, Grad norm: 7.022409430492842\n",
      "Epoch 9088, Loss: 208.55171318193155, Neurons: 201, Grad norm: 6.526957163045701\n",
      "Epoch 9088, Loss: 208.55171318193155, Neurons: 201, Grad norm: 6.526957163045701\n",
      "Epoch 9089, Loss: 208.55155072219566, Neurons: 201, Grad norm: 5.408209024587867\n",
      "Epoch 9089, Loss: 208.55155072219566, Neurons: 201, Grad norm: 5.408209024587867\n",
      "Epoch 9090, Loss: 208.55132554152573, Neurons: 201, Grad norm: 4.209626817758907\n",
      "Epoch 9090, Loss: 208.55132554152573, Neurons: 201, Grad norm: 4.209626817758907\n",
      "Epoch 9091, Loss: 208.5511546658482, Neurons: 201, Grad norm: 2.8762965701395506\n",
      "Epoch 9091, Loss: 208.5511546658482, Neurons: 201, Grad norm: 2.8762965701395506\n",
      "Epoch 9092, Loss: 208.55096349527417, Neurons: 201, Grad norm: 1.9060844614354777\n",
      "Epoch 9092, Loss: 208.55096349527417, Neurons: 201, Grad norm: 1.9060844614354777\n",
      "Epoch 9093, Loss: 208.55083072349893, Neurons: 201, Grad norm: 1.3868814266487075\n",
      "Epoch 9093, Loss: 208.55083072349893, Neurons: 201, Grad norm: 1.3868814266487075\n",
      "Epoch 9094, Loss: 208.550754592032, Neurons: 201, Grad norm: 1.0653908259418978\n",
      "Epoch 9094, Loss: 208.550754592032, Neurons: 201, Grad norm: 1.0653908259418978\n",
      "Epoch 9095, Loss: 208.55063938130868, Neurons: 201, Grad norm: 1.464105423647051\n",
      "Epoch 9095, Loss: 208.55063938130868, Neurons: 201, Grad norm: 1.464105423647051\n",
      "Epoch 9096, Loss: 208.55052399919103, Neurons: 201, Grad norm: 2.633919202627438\n",
      "Epoch 9096, Loss: 208.55052399919103, Neurons: 201, Grad norm: 2.633919202627438\n",
      "Epoch 9097, Loss: 208.55052997472941, Neurons: 201, Grad norm: 3.8760161188818647\n",
      "Epoch 9097, Loss: 208.55052997472941, Neurons: 201, Grad norm: 3.8760161188818647\n",
      "Epoch 9098, Loss: 208.55053264607716, Neurons: 201, Grad norm: 5.475777591527139\n",
      "Epoch 9098, Loss: 208.55053264607716, Neurons: 201, Grad norm: 5.475777591527139\n",
      "Epoch 9099, Loss: 208.55071708082002, Neurons: 201, Grad norm: 6.893416608975973\n",
      "Epoch 9099, Loss: 208.55071708082002, Neurons: 201, Grad norm: 6.893416608975973\n",
      "Epoch 9100, Loss: 208.55086159018455, Neurons: 201, Grad norm: 8.877099920554011\n",
      "Epoch 9100, Loss: 208.55086159018455, Neurons: 201, Grad norm: 8.877099920554011\n",
      "Epoch 9101, Loss: 208.55101874766885, Neurons: 201, Grad norm: 10.568739692230716\n",
      "Epoch 9101, Loss: 208.55101874766885, Neurons: 201, Grad norm: 10.568739692230716\n",
      "Epoch 9102, Loss: 208.551311986932, Neurons: 201, Grad norm: 11.994478249314394\n",
      "Epoch 9102, Loss: 208.551311986932, Neurons: 201, Grad norm: 11.994478249314394\n",
      "Epoch 9103, Loss: 208.5515444374123, Neurons: 201, Grad norm: 12.92227030188133\n",
      "Epoch 9103, Loss: 208.5515444374123, Neurons: 201, Grad norm: 12.92227030188133\n",
      "Epoch 9104, Loss: 208.55161064824975, Neurons: 201, Grad norm: 13.122685025800466\n",
      "Epoch 9104, Loss: 208.55161064824975, Neurons: 201, Grad norm: 13.122685025800466\n",
      "Epoch 9105, Loss: 208.55168809631118, Neurons: 201, Grad norm: 12.61519225524349\n",
      "Epoch 9105, Loss: 208.55168809631118, Neurons: 201, Grad norm: 12.61519225524349\n",
      "Epoch 9106, Loss: 208.55146960692718, Neurons: 201, Grad norm: 11.19766815532138\n",
      "Epoch 9106, Loss: 208.55146960692718, Neurons: 201, Grad norm: 11.19766815532138\n",
      "Epoch 9107, Loss: 208.5509612121273, Neurons: 201, Grad norm: 9.066713663029807\n",
      "Epoch 9107, Loss: 208.5509612121273, Neurons: 201, Grad norm: 9.066713663029807\n",
      "Epoch 9108, Loss: 208.5505176180303, Neurons: 201, Grad norm: 6.247158586680654\n",
      "Epoch 9108, Loss: 208.5505176180303, Neurons: 201, Grad norm: 6.247158586680654\n",
      "Epoch 9109, Loss: 208.5500659450872, Neurons: 201, Grad norm: 3.759247027752509\n",
      "Epoch 9109, Loss: 208.5500659450872, Neurons: 201, Grad norm: 3.759247027752509\n",
      "Epoch 9110, Loss: 208.5496242565206, Neurons: 201, Grad norm: 1.5821459678811016\n",
      "Epoch 9110, Loss: 208.5496242565206, Neurons: 201, Grad norm: 1.5821459678811016\n",
      "Epoch 9111, Loss: 208.54941732287293, Neurons: 201, Grad norm: 1.398092673060341\n",
      "Epoch 9111, Loss: 208.54941732287293, Neurons: 201, Grad norm: 1.398092673060341\n",
      "Epoch 9112, Loss: 208.549388864972, Neurons: 201, Grad norm: 2.7071471202832886\n",
      "Epoch 9112, Loss: 208.549388864972, Neurons: 201, Grad norm: 2.7071471202832886\n",
      "Epoch 9113, Loss: 208.549308228667, Neurons: 201, Grad norm: 3.7392088386239153\n",
      "Epoch 9113, Loss: 208.549308228667, Neurons: 201, Grad norm: 3.7392088386239153\n",
      "Epoch 9114, Loss: 208.54923781925194, Neurons: 201, Grad norm: 4.713614784701849\n",
      "Epoch 9114, Loss: 208.54923781925194, Neurons: 201, Grad norm: 4.713614784701849\n",
      "Epoch 9115, Loss: 208.54932460329297, Neurons: 201, Grad norm: 5.645547048726634\n",
      "Epoch 9115, Loss: 208.54932460329297, Neurons: 201, Grad norm: 5.645547048726634\n",
      "Epoch 9116, Loss: 208.54942728564401, Neurons: 201, Grad norm: 6.343325438959778\n",
      "Epoch 9116, Loss: 208.54942728564401, Neurons: 201, Grad norm: 6.343325438959778\n",
      "Epoch 9117, Loss: 208.5494305407531, Neurons: 201, Grad norm: 7.277935257006078\n",
      "Epoch 9117, Loss: 208.5494305407531, Neurons: 201, Grad norm: 7.277935257006078\n",
      "Epoch 9118, Loss: 208.54946587676946, Neurons: 201, Grad norm: 8.024143981849555\n",
      "Epoch 9118, Loss: 208.54946587676946, Neurons: 201, Grad norm: 8.024143981849555\n",
      "Epoch 9119, Loss: 208.5495224362499, Neurons: 201, Grad norm: 8.907493920714222\n",
      "Epoch 9119, Loss: 208.5495224362499, Neurons: 201, Grad norm: 8.907493920714222\n",
      "Epoch 9120, Loss: 208.54952951707654, Neurons: 201, Grad norm: 9.150298861731901\n",
      "Epoch 9120, Loss: 208.54952951707654, Neurons: 201, Grad norm: 9.150298861731901\n",
      "Epoch 9121, Loss: 208.54945129977875, Neurons: 201, Grad norm: 9.135633693894565\n",
      "Epoch 9121, Loss: 208.54945129977875, Neurons: 201, Grad norm: 9.135633693894565\n",
      "Epoch 9122, Loss: 208.5493357183368, Neurons: 201, Grad norm: 8.791198883496353\n",
      "Epoch 9122, Loss: 208.5493357183368, Neurons: 201, Grad norm: 8.791198883496353\n",
      "Epoch 9123, Loss: 208.5493139300766, Neurons: 201, Grad norm: 8.143930098458855\n",
      "Epoch 9123, Loss: 208.5493139300766, Neurons: 201, Grad norm: 8.143930098458855\n",
      "Epoch 9124, Loss: 208.54914026523423, Neurons: 201, Grad norm: 7.475208737462866\n",
      "Epoch 9124, Loss: 208.54914026523423, Neurons: 201, Grad norm: 7.475208737462866\n",
      "Epoch 9125, Loss: 208.548982966179, Neurons: 201, Grad norm: 6.916171765984926\n",
      "Epoch 9125, Loss: 208.548982966179, Neurons: 201, Grad norm: 6.916171765984926\n",
      "Epoch 9126, Loss: 208.54896608541864, Neurons: 201, Grad norm: 6.221423495694512\n",
      "Epoch 9126, Loss: 208.54896608541864, Neurons: 201, Grad norm: 6.221423495694512\n",
      "Epoch 9127, Loss: 208.54872961200942, Neurons: 201, Grad norm: 5.513066349901395\n",
      "Epoch 9127, Loss: 208.54872961200942, Neurons: 201, Grad norm: 5.513066349901395\n",
      "Epoch 9128, Loss: 208.54845137425676, Neurons: 201, Grad norm: 5.213715426344135\n",
      "Epoch 9128, Loss: 208.54845137425676, Neurons: 201, Grad norm: 5.213715426344135\n",
      "Epoch 9129, Loss: 208.54830770137391, Neurons: 201, Grad norm: 4.902126884844051\n",
      "Epoch 9129, Loss: 208.54830770137391, Neurons: 201, Grad norm: 4.902126884844051\n",
      "Epoch 9130, Loss: 208.54812074461796, Neurons: 201, Grad norm: 4.689440116721365\n",
      "Epoch 9130, Loss: 208.54812074461796, Neurons: 201, Grad norm: 4.689440116721365\n",
      "Epoch 9131, Loss: 208.54793823221422, Neurons: 201, Grad norm: 4.326387076163689\n",
      "Epoch 9131, Loss: 208.54793823221422, Neurons: 201, Grad norm: 4.326387076163689\n",
      "Epoch 9132, Loss: 208.5478883030201, Neurons: 201, Grad norm: 4.0437024556534995\n",
      "Epoch 9132, Loss: 208.5478883030201, Neurons: 201, Grad norm: 4.0437024556534995\n",
      "Epoch 9133, Loss: 208.54776175129564, Neurons: 201, Grad norm: 3.821650592567426\n",
      "Epoch 9133, Loss: 208.54776175129564, Neurons: 201, Grad norm: 3.821650592567426\n",
      "Epoch 9134, Loss: 208.54764701263593, Neurons: 201, Grad norm: 3.7252906184231516\n",
      "Epoch 9134, Loss: 208.54764701263593, Neurons: 201, Grad norm: 3.7252906184231516\n",
      "Epoch 9135, Loss: 208.54760906931622, Neurons: 201, Grad norm: 3.9558924889662497\n",
      "Epoch 9135, Loss: 208.54760906931622, Neurons: 201, Grad norm: 3.9558924889662497\n",
      "Epoch 9136, Loss: 208.54750441913274, Neurons: 201, Grad norm: 4.450491743926912\n",
      "Epoch 9136, Loss: 208.54750441913274, Neurons: 201, Grad norm: 4.450491743926912\n",
      "Epoch 9137, Loss: 208.54750399759232, Neurons: 201, Grad norm: 5.374963328652308\n",
      "Epoch 9137, Loss: 208.54750399759232, Neurons: 201, Grad norm: 5.374963328652308\n",
      "Epoch 9138, Loss: 208.54754728537233, Neurons: 201, Grad norm: 6.487006039425098\n",
      "Epoch 9138, Loss: 208.54754728537233, Neurons: 201, Grad norm: 6.487006039425098\n",
      "Epoch 9139, Loss: 208.54755754298088, Neurons: 201, Grad norm: 7.923276274566367\n",
      "Epoch 9139, Loss: 208.54755754298088, Neurons: 201, Grad norm: 7.923276274566367\n",
      "Epoch 9140, Loss: 208.5476247735621, Neurons: 201, Grad norm: 9.217126529309308\n",
      "Epoch 9140, Loss: 208.5476247735621, Neurons: 201, Grad norm: 9.217126529309308\n",
      "Epoch 9141, Loss: 208.54769698117283, Neurons: 201, Grad norm: 10.407542837800415\n",
      "Epoch 9141, Loss: 208.54769698117283, Neurons: 201, Grad norm: 10.407542837800415\n",
      "Epoch 9142, Loss: 208.5478418718931, Neurons: 201, Grad norm: 11.091267158489158\n",
      "Epoch 9142, Loss: 208.5478418718931, Neurons: 201, Grad norm: 11.091267158489158\n",
      "Epoch 9143, Loss: 208.54797010289127, Neurons: 201, Grad norm: 11.394883707176454\n",
      "Epoch 9143, Loss: 208.54797010289127, Neurons: 201, Grad norm: 11.394883707176454\n",
      "Epoch 9144, Loss: 208.54803516641022, Neurons: 201, Grad norm: 11.659898922711868\n",
      "Epoch 9144, Loss: 208.54803516641022, Neurons: 201, Grad norm: 11.659898922711868\n",
      "Epoch 9145, Loss: 208.5482693048606, Neurons: 201, Grad norm: 11.77922610224539\n",
      "Epoch 9145, Loss: 208.5482693048606, Neurons: 201, Grad norm: 11.77922610224539\n",
      "Epoch 9146, Loss: 208.54847422739687, Neurons: 201, Grad norm: 11.723057369268348\n",
      "Epoch 9146, Loss: 208.54847422739687, Neurons: 201, Grad norm: 11.723057369268348\n",
      "Epoch 9147, Loss: 208.54834674956237, Neurons: 201, Grad norm: 11.178313157317602\n",
      "Epoch 9147, Loss: 208.54834674956237, Neurons: 201, Grad norm: 11.178313157317602\n",
      "Epoch 9148, Loss: 208.54804593263054, Neurons: 201, Grad norm: 10.440654386775952\n",
      "Epoch 9148, Loss: 208.54804593263054, Neurons: 201, Grad norm: 10.440654386775952\n",
      "Epoch 9149, Loss: 208.54765199952672, Neurons: 201, Grad norm: 9.5181384721763\n",
      "Epoch 9149, Loss: 208.54765199952672, Neurons: 201, Grad norm: 9.5181384721763\n",
      "Epoch 9150, Loss: 208.54722349025894, Neurons: 201, Grad norm: 8.076358963738514\n",
      "Epoch 9150, Loss: 208.54722349025894, Neurons: 201, Grad norm: 8.076358963738514\n",
      "Epoch 9151, Loss: 208.54676048956114, Neurons: 201, Grad norm: 6.846563040320669\n",
      "Epoch 9151, Loss: 208.54676048956114, Neurons: 201, Grad norm: 6.846563040320669\n",
      "Epoch 9152, Loss: 208.5464805823522, Neurons: 201, Grad norm: 5.079798982374657\n",
      "Epoch 9152, Loss: 208.5464805823522, Neurons: 201, Grad norm: 5.079798982374657\n",
      "Epoch 9153, Loss: 208.54623910830009, Neurons: 201, Grad norm: 3.045913381951425\n",
      "Epoch 9153, Loss: 208.54623910830009, Neurons: 201, Grad norm: 3.045913381951425\n",
      "Epoch 9154, Loss: 208.5459960245948, Neurons: 201, Grad norm: 1.2599848652546402\n",
      "Epoch 9154, Loss: 208.5459960245948, Neurons: 201, Grad norm: 1.2599848652546402\n",
      "Epoch 9155, Loss: 208.54582081839982, Neurons: 201, Grad norm: 1.4892227114102106\n",
      "Epoch 9155, Loss: 208.54582081839982, Neurons: 201, Grad norm: 1.4892227114102106\n",
      "Epoch 9156, Loss: 208.5457436893335, Neurons: 201, Grad norm: 3.7889908743735408\n",
      "Epoch 9156, Loss: 208.5457436893335, Neurons: 201, Grad norm: 3.7889908743735408\n",
      "Epoch 9157, Loss: 208.5458350133073, Neurons: 201, Grad norm: 5.8833768306661804\n",
      "Epoch 9157, Loss: 208.5458350133073, Neurons: 201, Grad norm: 5.8833768306661804\n",
      "Epoch 9158, Loss: 208.5459268938491, Neurons: 201, Grad norm: 7.859086276380764\n",
      "Epoch 9158, Loss: 208.5459268938491, Neurons: 201, Grad norm: 7.859086276380764\n",
      "Epoch 9159, Loss: 208.54610198683042, Neurons: 201, Grad norm: 9.297373449488175\n",
      "Epoch 9159, Loss: 208.54610198683042, Neurons: 201, Grad norm: 9.297373449488175\n",
      "Epoch 9160, Loss: 208.54626439895156, Neurons: 201, Grad norm: 10.437452489816254\n",
      "Epoch 9160, Loss: 208.54626439895156, Neurons: 201, Grad norm: 10.437452489816254\n",
      "Epoch 9161, Loss: 208.54649048282536, Neurons: 201, Grad norm: 11.398509382718649\n",
      "Epoch 9161, Loss: 208.54649048282536, Neurons: 201, Grad norm: 11.398509382718649\n",
      "Epoch 9162, Loss: 208.5467534363283, Neurons: 201, Grad norm: 12.533014952951655\n",
      "Epoch 9162, Loss: 208.5467534363283, Neurons: 201, Grad norm: 12.533014952951655\n",
      "Epoch 9163, Loss: 208.54722871845132, Neurons: 201, Grad norm: 13.325825671985074\n",
      "Epoch 9163, Loss: 208.54722871845132, Neurons: 201, Grad norm: 13.325825671985074\n",
      "Epoch 9164, Loss: 208.5477581357941, Neurons: 201, Grad norm: 13.962671032817294\n",
      "Epoch 9164, Loss: 208.5477581357941, Neurons: 201, Grad norm: 13.962671032817294\n",
      "Epoch 9165, Loss: 208.54834088957602, Neurons: 201, Grad norm: 14.559439161287242\n",
      "Epoch 9165, Loss: 208.54834088957602, Neurons: 201, Grad norm: 14.559439161287242\n",
      "Epoch 9166, Loss: 208.5483690307262, Neurons: 201, Grad norm: 14.498063273992896\n",
      "Epoch 9166, Loss: 208.5483690307262, Neurons: 201, Grad norm: 14.498063273992896\n",
      "Epoch 9167, Loss: 208.5480913462658, Neurons: 201, Grad norm: 14.179742349218328\n",
      "Epoch 9167, Loss: 208.5480913462658, Neurons: 201, Grad norm: 14.179742349218328\n",
      "Epoch 9168, Loss: 208.54743184879914, Neurons: 201, Grad norm: 13.31174257133142\n",
      "Epoch 9168, Loss: 208.54743184879914, Neurons: 201, Grad norm: 13.31174257133142\n",
      "Epoch 9169, Loss: 208.54677495038925, Neurons: 201, Grad norm: 11.557165985685717\n",
      "Epoch 9169, Loss: 208.54677495038925, Neurons: 201, Grad norm: 11.557165985685717\n",
      "Epoch 9170, Loss: 208.54617094331005, Neurons: 201, Grad norm: 9.112479168661437\n",
      "Epoch 9170, Loss: 208.54617094331005, Neurons: 201, Grad norm: 9.112479168661437\n",
      "Epoch 9171, Loss: 208.54552827202522, Neurons: 201, Grad norm: 5.7490977553989\n",
      "Epoch 9171, Loss: 208.54552827202522, Neurons: 201, Grad norm: 5.7490977553989\n",
      "Epoch 9172, Loss: 208.54496382204545, Neurons: 201, Grad norm: 2.5142925466268737\n",
      "Epoch 9172, Loss: 208.54496382204545, Neurons: 201, Grad norm: 2.5142925466268737\n",
      "Epoch 9173, Loss: 208.54455402024422, Neurons: 201, Grad norm: 1.0627825729166875\n",
      "Epoch 9173, Loss: 208.54455402024422, Neurons: 201, Grad norm: 1.0627825729166875\n",
      "Epoch 9174, Loss: 208.54445018918358, Neurons: 201, Grad norm: 3.9593516956513226\n",
      "Epoch 9174, Loss: 208.54445018918358, Neurons: 201, Grad norm: 3.9593516956513226\n",
      "Epoch 9175, Loss: 208.5445133084121, Neurons: 201, Grad norm: 6.37613891501449\n",
      "Epoch 9175, Loss: 208.5445133084121, Neurons: 201, Grad norm: 6.37613891501449\n",
      "Epoch 9176, Loss: 208.54469433179054, Neurons: 201, Grad norm: 8.400953760577764\n",
      "Epoch 9176, Loss: 208.54469433179054, Neurons: 201, Grad norm: 8.400953760577764\n",
      "Epoch 9177, Loss: 208.54494053001542, Neurons: 201, Grad norm: 9.840512912230144\n",
      "Epoch 9177, Loss: 208.54494053001542, Neurons: 201, Grad norm: 9.840512912230144\n",
      "Epoch 9178, Loss: 208.54514410689129, Neurons: 201, Grad norm: 10.520668749506541\n",
      "Epoch 9178, Loss: 208.54514410689129, Neurons: 201, Grad norm: 10.520668749506541\n",
      "Epoch 9179, Loss: 208.5453580807626, Neurons: 201, Grad norm: 11.025791838782157\n",
      "Epoch 9179, Loss: 208.5453580807626, Neurons: 201, Grad norm: 11.025791838782157\n",
      "Epoch 9180, Loss: 208.5456196029499, Neurons: 201, Grad norm: 11.112824233059122\n",
      "Epoch 9180, Loss: 208.5456196029499, Neurons: 201, Grad norm: 11.112824233059122\n",
      "Epoch 9181, Loss: 208.54565170593736, Neurons: 201, Grad norm: 10.822666458666538\n",
      "Epoch 9181, Loss: 208.54565170593736, Neurons: 201, Grad norm: 10.822666458666538\n",
      "Epoch 9182, Loss: 208.54551818142585, Neurons: 201, Grad norm: 10.14677689937888\n",
      "Epoch 9182, Loss: 208.54551818142585, Neurons: 201, Grad norm: 10.14677689937888\n",
      "Epoch 9183, Loss: 208.54533916846881, Neurons: 201, Grad norm: 8.98674337676315\n",
      "Epoch 9183, Loss: 208.54533916846881, Neurons: 201, Grad norm: 8.98674337676315\n",
      "Epoch 9184, Loss: 208.54488054159972, Neurons: 201, Grad norm: 7.732354171789835\n",
      "Epoch 9184, Loss: 208.54488054159972, Neurons: 201, Grad norm: 7.732354171789835\n",
      "Epoch 9185, Loss: 208.54432094266113, Neurons: 201, Grad norm: 6.129588348777719\n",
      "Epoch 9185, Loss: 208.54432094266113, Neurons: 201, Grad norm: 6.129588348777719\n",
      "Epoch 9186, Loss: 208.54403265788883, Neurons: 201, Grad norm: 4.132369208132615\n",
      "Epoch 9186, Loss: 208.54403265788883, Neurons: 201, Grad norm: 4.132369208132615\n",
      "Epoch 9187, Loss: 208.54376863832104, Neurons: 201, Grad norm: 2.1691061452686964\n",
      "Epoch 9187, Loss: 208.54376863832104, Neurons: 201, Grad norm: 2.1691061452686964\n",
      "Epoch 9188, Loss: 208.54356766940984, Neurons: 201, Grad norm: 1.4354238621252011\n",
      "Epoch 9188, Loss: 208.54356766940984, Neurons: 201, Grad norm: 1.4354238621252011\n",
      "Epoch 9189, Loss: 208.5434840397795, Neurons: 201, Grad norm: 3.655871057796765\n",
      "Epoch 9189, Loss: 208.5434840397795, Neurons: 201, Grad norm: 3.655871057796765\n",
      "Epoch 9190, Loss: 208.54348852222276, Neurons: 201, Grad norm: 5.757806341479528\n",
      "Epoch 9190, Loss: 208.54348852222276, Neurons: 201, Grad norm: 5.757806341479528\n",
      "Epoch 9191, Loss: 208.54365624474303, Neurons: 201, Grad norm: 7.61379026463645\n",
      "Epoch 9191, Loss: 208.54365624474303, Neurons: 201, Grad norm: 7.61379026463645\n",
      "Epoch 9192, Loss: 208.54382643352147, Neurons: 201, Grad norm: 8.920015230855501\n",
      "Epoch 9192, Loss: 208.54382643352147, Neurons: 201, Grad norm: 8.920015230855501\n",
      "Epoch 9193, Loss: 208.54397349861114, Neurons: 201, Grad norm: 9.600571108939432\n",
      "Epoch 9193, Loss: 208.54397349861114, Neurons: 201, Grad norm: 9.600571108939432\n",
      "Epoch 9194, Loss: 208.54402465088066, Neurons: 201, Grad norm: 9.472679689640858\n",
      "Epoch 9194, Loss: 208.54402465088066, Neurons: 201, Grad norm: 9.472679689640858\n",
      "Epoch 9195, Loss: 208.5438585312722, Neurons: 201, Grad norm: 8.90898302645001\n",
      "Epoch 9195, Loss: 208.5438585312722, Neurons: 201, Grad norm: 8.90898302645001\n",
      "Epoch 9196, Loss: 208.54380703677197, Neurons: 201, Grad norm: 8.283438066249321\n",
      "Epoch 9196, Loss: 208.54380703677197, Neurons: 201, Grad norm: 8.283438066249321\n",
      "Epoch 9197, Loss: 208.54381699574137, Neurons: 201, Grad norm: 7.446019563787108\n",
      "Epoch 9197, Loss: 208.54381699574137, Neurons: 201, Grad norm: 7.446019563787108\n",
      "Epoch 9198, Loss: 208.5437810203811, Neurons: 201, Grad norm: 6.703074785706581\n",
      "Epoch 9198, Loss: 208.5437810203811, Neurons: 201, Grad norm: 6.703074785706581\n",
      "Epoch 9199, Loss: 208.54376596660435, Neurons: 201, Grad norm: 5.8948102509992255\n",
      "Epoch 9199, Loss: 208.54376596660435, Neurons: 201, Grad norm: 5.8948102509992255\n",
      "Epoch 9200, Loss: 208.5434310993538, Neurons: 201, Grad norm: 5.064352206323546\n",
      "Epoch 9200, Loss: 208.5434310993538, Neurons: 201, Grad norm: 5.064352206323546\n",
      "Epoch 9201, Loss: 208.54303277056394, Neurons: 201, Grad norm: 4.544984505351347\n",
      "Epoch 9201, Loss: 208.54303277056394, Neurons: 201, Grad norm: 4.544984505351347\n",
      "Epoch 9202, Loss: 208.54275046799953, Neurons: 201, Grad norm: 3.9558806457285427\n",
      "Epoch 9202, Loss: 208.54275046799953, Neurons: 201, Grad norm: 3.9558806457285427\n",
      "Epoch 9203, Loss: 208.5425391091082, Neurons: 201, Grad norm: 3.7374317173304497\n",
      "Epoch 9203, Loss: 208.5425391091082, Neurons: 201, Grad norm: 3.7374317173304497\n",
      "Epoch 9204, Loss: 208.54249003399914, Neurons: 201, Grad norm: 3.388287911545705\n",
      "Epoch 9204, Loss: 208.54249003399914, Neurons: 201, Grad norm: 3.388287911545705\n",
      "Epoch 9205, Loss: 208.54253634623453, Neurons: 201, Grad norm: 2.935774627753497\n",
      "Epoch 9205, Loss: 208.54253634623453, Neurons: 201, Grad norm: 2.935774627753497\n",
      "Epoch 9206, Loss: 208.54244211788438, Neurons: 201, Grad norm: 2.2641414808475906\n",
      "Epoch 9206, Loss: 208.54244211788438, Neurons: 201, Grad norm: 2.2641414808475906\n",
      "Epoch 9207, Loss: 208.54230787410026, Neurons: 201, Grad norm: 1.1898841844248036\n",
      "Epoch 9207, Loss: 208.54230787410026, Neurons: 201, Grad norm: 1.1898841844248036\n",
      "Epoch 9208, Loss: 208.54210470839914, Neurons: 201, Grad norm: 1.6800022836278279\n",
      "Epoch 9208, Loss: 208.54210470839914, Neurons: 201, Grad norm: 1.6800022836278279\n",
      "Epoch 9209, Loss: 208.54195267796288, Neurons: 201, Grad norm: 3.178948967300986\n",
      "Epoch 9209, Loss: 208.54195267796288, Neurons: 201, Grad norm: 3.178948967300986\n",
      "Epoch 9210, Loss: 208.54200834775062, Neurons: 201, Grad norm: 4.30077208999346\n",
      "Epoch 9210, Loss: 208.54200834775062, Neurons: 201, Grad norm: 4.30077208999346\n",
      "Epoch 9211, Loss: 208.54213376619614, Neurons: 201, Grad norm: 4.541612674383011\n",
      "Epoch 9211, Loss: 208.54213376619614, Neurons: 201, Grad norm: 4.541612674383011\n",
      "Epoch 9212, Loss: 208.54215251006707, Neurons: 201, Grad norm: 4.272853619939687\n",
      "Epoch 9212, Loss: 208.54215251006707, Neurons: 201, Grad norm: 4.272853619939687\n",
      "Epoch 9213, Loss: 208.54198472154533, Neurons: 201, Grad norm: 3.8236731246241598\n",
      "Epoch 9213, Loss: 208.54198472154533, Neurons: 201, Grad norm: 3.8236731246241598\n",
      "Epoch 9214, Loss: 208.54174976530845, Neurons: 201, Grad norm: 3.2162726730390645\n",
      "Epoch 9214, Loss: 208.54174976530845, Neurons: 201, Grad norm: 3.2162726730390645\n",
      "Epoch 9215, Loss: 208.5417259773084, Neurons: 201, Grad norm: 3.6760184229926045\n",
      "Epoch 9215, Loss: 208.5417259773084, Neurons: 201, Grad norm: 3.6760184229926045\n",
      "Epoch 9216, Loss: 208.54179415000732, Neurons: 201, Grad norm: 4.354088132121643\n",
      "Epoch 9216, Loss: 208.54179415000732, Neurons: 201, Grad norm: 4.354088132121643\n",
      "Epoch 9217, Loss: 208.54195459016216, Neurons: 201, Grad norm: 4.925143621799676\n",
      "Epoch 9217, Loss: 208.54195459016216, Neurons: 201, Grad norm: 4.925143621799676\n",
      "Epoch 9218, Loss: 208.5420411180781, Neurons: 201, Grad norm: 6.070903135379897\n",
      "Epoch 9218, Loss: 208.5420411180781, Neurons: 201, Grad norm: 6.070903135379897\n",
      "Epoch 9219, Loss: 208.54190700843859, Neurons: 201, Grad norm: 7.56505210150239\n",
      "Epoch 9219, Loss: 208.54190700843859, Neurons: 201, Grad norm: 7.56505210150239\n",
      "Epoch 9220, Loss: 208.54189081554017, Neurons: 201, Grad norm: 8.965293445536743\n",
      "Epoch 9220, Loss: 208.54189081554017, Neurons: 201, Grad norm: 8.965293445536743\n",
      "Epoch 9221, Loss: 208.54195759520476, Neurons: 201, Grad norm: 10.162727867809219\n",
      "Epoch 9221, Loss: 208.54195759520476, Neurons: 201, Grad norm: 10.162727867809219\n",
      "Epoch 9222, Loss: 208.54211566925034, Neurons: 201, Grad norm: 10.635448416778106\n",
      "Epoch 9222, Loss: 208.54211566925034, Neurons: 201, Grad norm: 10.635448416778106\n",
      "Epoch 9223, Loss: 208.54221128469558, Neurons: 201, Grad norm: 10.368563154603336\n",
      "Epoch 9223, Loss: 208.54221128469558, Neurons: 201, Grad norm: 10.368563154603336\n",
      "Epoch 9224, Loss: 208.54204992568313, Neurons: 201, Grad norm: 9.769720614899896\n",
      "Epoch 9224, Loss: 208.54204992568313, Neurons: 201, Grad norm: 9.769720614899896\n",
      "Epoch 9225, Loss: 208.5418830341496, Neurons: 201, Grad norm: 8.567112758982322\n",
      "Epoch 9225, Loss: 208.5418830341496, Neurons: 201, Grad norm: 8.567112758982322\n",
      "Epoch 9226, Loss: 208.54172424496403, Neurons: 201, Grad norm: 7.191508712346171\n",
      "Epoch 9226, Loss: 208.54172424496403, Neurons: 201, Grad norm: 7.191508712346171\n",
      "Epoch 9227, Loss: 208.54149180516976, Neurons: 201, Grad norm: 5.8868431969431185\n",
      "Epoch 9227, Loss: 208.54149180516976, Neurons: 201, Grad norm: 5.8868431969431185\n",
      "Epoch 9228, Loss: 208.54128908925668, Neurons: 201, Grad norm: 4.831202280889295\n",
      "Epoch 9228, Loss: 208.54128908925668, Neurons: 201, Grad norm: 4.831202280889295\n",
      "Epoch 9229, Loss: 208.54107669614876, Neurons: 201, Grad norm: 3.793036779941439\n",
      "Epoch 9229, Loss: 208.54107669614876, Neurons: 201, Grad norm: 3.793036779941439\n",
      "Epoch 9230, Loss: 208.54076755971687, Neurons: 201, Grad norm: 2.7603787455322846\n",
      "Epoch 9230, Loss: 208.54076755971687, Neurons: 201, Grad norm: 2.7603787455322846\n",
      "Epoch 9231, Loss: 208.54053192368522, Neurons: 201, Grad norm: 2.2749581274959856\n",
      "Epoch 9231, Loss: 208.54053192368522, Neurons: 201, Grad norm: 2.2749581274959856\n",
      "Epoch 9232, Loss: 208.54044571795114, Neurons: 201, Grad norm: 1.6455665247544604\n",
      "Epoch 9232, Loss: 208.54044571795114, Neurons: 201, Grad norm: 1.6455665247544604\n",
      "Epoch 9233, Loss: 208.54033434507411, Neurons: 201, Grad norm: 1.7094716097695672\n",
      "Epoch 9233, Loss: 208.54033434507411, Neurons: 201, Grad norm: 1.7094716097695672\n",
      "Epoch 9234, Loss: 208.5402618419136, Neurons: 201, Grad norm: 1.49127829575958\n",
      "Epoch 9234, Loss: 208.5402618419136, Neurons: 201, Grad norm: 1.49127829575958\n",
      "Epoch 9235, Loss: 208.5402056818168, Neurons: 201, Grad norm: 1.1340874776094607\n",
      "Epoch 9235, Loss: 208.5402056818168, Neurons: 201, Grad norm: 1.1340874776094607\n",
      "Epoch 9236, Loss: 208.54016803074484, Neurons: 201, Grad norm: 0.9150969128094255\n",
      "Epoch 9236, Loss: 208.54016803074484, Neurons: 201, Grad norm: 0.9150969128094255\n",
      "Epoch 9237, Loss: 208.54003990035255, Neurons: 201, Grad norm: 0.8333038174036104\n",
      "Epoch 9237, Loss: 208.54003990035255, Neurons: 201, Grad norm: 0.8333038174036104\n",
      "Epoch 9238, Loss: 208.53996854845136, Neurons: 201, Grad norm: 1.355907648212897\n",
      "Epoch 9238, Loss: 208.53996854845136, Neurons: 201, Grad norm: 1.355907648212897\n",
      "Epoch 9239, Loss: 208.5398955322654, Neurons: 201, Grad norm: 1.955441769399402\n",
      "Epoch 9239, Loss: 208.5398955322654, Neurons: 201, Grad norm: 1.955441769399402\n",
      "Epoch 9240, Loss: 208.53988654642822, Neurons: 201, Grad norm: 2.016711924571778\n",
      "Epoch 9240, Loss: 208.53988654642822, Neurons: 201, Grad norm: 2.016711924571778\n",
      "Epoch 9241, Loss: 208.53988728569595, Neurons: 201, Grad norm: 2.2787316521397636\n",
      "Epoch 9241, Loss: 208.53988728569595, Neurons: 201, Grad norm: 2.2787316521397636\n",
      "Epoch 9242, Loss: 208.53978019566102, Neurons: 201, Grad norm: 2.187833434288867\n",
      "Epoch 9242, Loss: 208.53978019566102, Neurons: 201, Grad norm: 2.187833434288867\n",
      "Epoch 9243, Loss: 208.53975113416698, Neurons: 201, Grad norm: 1.4599859223565153\n",
      "Epoch 9243, Loss: 208.53975113416698, Neurons: 201, Grad norm: 1.4599859223565153\n",
      "Epoch 9244, Loss: 208.53961901485653, Neurons: 201, Grad norm: 1.2853354703700954\n",
      "Epoch 9244, Loss: 208.53961901485653, Neurons: 201, Grad norm: 1.2853354703700954\n",
      "Epoch 9245, Loss: 208.53954403986666, Neurons: 201, Grad norm: 1.1105905333070138\n",
      "Epoch 9245, Loss: 208.53954403986666, Neurons: 201, Grad norm: 1.1105905333070138\n",
      "Epoch 9246, Loss: 208.53947085508477, Neurons: 201, Grad norm: 1.475422767178693\n",
      "Epoch 9246, Loss: 208.53947085508477, Neurons: 201, Grad norm: 1.475422767178693\n",
      "Epoch 9247, Loss: 208.5393938516745, Neurons: 201, Grad norm: 1.6172395141446687\n",
      "Epoch 9247, Loss: 208.5393938516745, Neurons: 201, Grad norm: 1.6172395141446687\n",
      "Epoch 9248, Loss: 208.53937085833763, Neurons: 201, Grad norm: 1.8855546019466263\n",
      "Epoch 9248, Loss: 208.53937085833763, Neurons: 201, Grad norm: 1.8855546019466263\n",
      "Epoch 9249, Loss: 208.53930069132466, Neurons: 201, Grad norm: 2.262827312805296\n",
      "Epoch 9249, Loss: 208.53930069132466, Neurons: 201, Grad norm: 2.262827312805296\n",
      "Epoch 9250, Loss: 208.5391876178516, Neurons: 201, Grad norm: 2.7761815708016853\n",
      "Epoch 9250, Loss: 208.5391876178516, Neurons: 201, Grad norm: 2.7761815708016853\n",
      "Epoch 9251, Loss: 208.53916977386586, Neurons: 201, Grad norm: 3.874282401233027\n",
      "Epoch 9251, Loss: 208.53916977386586, Neurons: 201, Grad norm: 3.874282401233027\n",
      "Epoch 9252, Loss: 208.5391453556313, Neurons: 201, Grad norm: 4.543280936276628\n",
      "Epoch 9252, Loss: 208.5391453556313, Neurons: 201, Grad norm: 4.543280936276628\n",
      "Epoch 9253, Loss: 208.53915968286157, Neurons: 201, Grad norm: 5.2935127031449865\n",
      "Epoch 9253, Loss: 208.53915968286157, Neurons: 201, Grad norm: 5.2935127031449865\n",
      "Epoch 9254, Loss: 208.53916255519846, Neurons: 201, Grad norm: 6.3837510950032454\n",
      "Epoch 9254, Loss: 208.53916255519846, Neurons: 201, Grad norm: 6.3837510950032454\n",
      "Epoch 9255, Loss: 208.5391586505072, Neurons: 201, Grad norm: 7.46960852996791\n",
      "Epoch 9255, Loss: 208.5391586505072, Neurons: 201, Grad norm: 7.46960852996791\n",
      "Epoch 9256, Loss: 208.53927882963598, Neurons: 201, Grad norm: 8.667214467062015\n",
      "Epoch 9256, Loss: 208.53927882963598, Neurons: 201, Grad norm: 8.667214467062015\n",
      "Epoch 9257, Loss: 208.53938603710534, Neurons: 201, Grad norm: 9.915750638412286\n",
      "Epoch 9257, Loss: 208.53938603710534, Neurons: 201, Grad norm: 9.915750638412286\n",
      "Epoch 9258, Loss: 208.5396527518016, Neurons: 201, Grad norm: 11.370261179513053\n",
      "Epoch 9258, Loss: 208.5396527518016, Neurons: 201, Grad norm: 11.370261179513053\n",
      "Epoch 9259, Loss: 208.54001739587346, Neurons: 201, Grad norm: 13.081912448842894\n",
      "Epoch 9259, Loss: 208.54001739587346, Neurons: 201, Grad norm: 13.081912448842894\n",
      "Epoch 9260, Loss: 208.54038270921455, Neurons: 201, Grad norm: 15.001069773517402\n",
      "Epoch 9260, Loss: 208.54038270921455, Neurons: 201, Grad norm: 15.001069773517402\n",
      "Epoch 9261, Loss: 208.54109181551274, Neurons: 201, Grad norm: 16.871470696538506\n",
      "Epoch 9261, Loss: 208.54109181551274, Neurons: 201, Grad norm: 16.871470696538506\n",
      "Epoch 9262, Loss: 208.5417549666112, Neurons: 201, Grad norm: 18.894667508337864\n",
      "Epoch 9262, Loss: 208.5417549666112, Neurons: 201, Grad norm: 18.894667508337864\n",
      "Epoch 9263, Loss: 208.54238887864517, Neurons: 201, Grad norm: 20.390638623566844\n",
      "Epoch 9263, Loss: 208.54238887864517, Neurons: 201, Grad norm: 20.390638623566844\n",
      "Epoch 9264, Loss: 208.54311384993585, Neurons: 201, Grad norm: 21.399086318060515\n",
      "Epoch 9264, Loss: 208.54311384993585, Neurons: 201, Grad norm: 21.399086318060515\n",
      "Epoch 9265, Loss: 208.54352810013464, Neurons: 201, Grad norm: 21.662868988266816\n",
      "Epoch 9265, Loss: 208.54352810013464, Neurons: 201, Grad norm: 21.662868988266816\n",
      "Epoch 9266, Loss: 208.54329231211227, Neurons: 201, Grad norm: 20.41592811116638\n",
      "Epoch 9266, Loss: 208.54329231211227, Neurons: 201, Grad norm: 20.41592811116638\n",
      "Epoch 9267, Loss: 208.5426662929577, Neurons: 201, Grad norm: 17.659186718236715\n",
      "Epoch 9267, Loss: 208.5426662929577, Neurons: 201, Grad norm: 17.659186718236715\n",
      "Epoch 9268, Loss: 208.5415111654399, Neurons: 201, Grad norm: 13.548880302366584\n",
      "Epoch 9268, Loss: 208.5415111654399, Neurons: 201, Grad norm: 13.548880302366584\n",
      "Epoch 9269, Loss: 208.54002569292754, Neurons: 201, Grad norm: 8.258659717864147\n",
      "Epoch 9269, Loss: 208.54002569292754, Neurons: 201, Grad norm: 8.258659717864147\n",
      "Epoch 9270, Loss: 208.53869454850914, Neurons: 201, Grad norm: 2.9165469795578627\n",
      "Epoch 9270, Loss: 208.53869454850914, Neurons: 201, Grad norm: 2.9165469795578627\n",
      "Epoch 9271, Loss: 208.53792237595715, Neurons: 201, Grad norm: 2.720804530872385\n",
      "Epoch 9271, Loss: 208.53792237595715, Neurons: 201, Grad norm: 2.720804530872385\n",
      "Epoch 9272, Loss: 208.5378316213468, Neurons: 201, Grad norm: 6.201349939508246\n",
      "Epoch 9272, Loss: 208.5378316213468, Neurons: 201, Grad norm: 6.201349939508246\n",
      "Epoch 9273, Loss: 208.53803202379956, Neurons: 201, Grad norm: 8.917415764629668\n",
      "Epoch 9273, Loss: 208.53803202379956, Neurons: 201, Grad norm: 8.917415764629668\n",
      "Epoch 9274, Loss: 208.53833013441056, Neurons: 201, Grad norm: 10.381815759266972\n",
      "Epoch 9274, Loss: 208.53833013441056, Neurons: 201, Grad norm: 10.381815759266972\n",
      "Epoch 9275, Loss: 208.53883251238793, Neurons: 201, Grad norm: 11.606364697342256\n",
      "Epoch 9275, Loss: 208.53883251238793, Neurons: 201, Grad norm: 11.606364697342256\n",
      "Epoch 9276, Loss: 208.539325499617, Neurons: 201, Grad norm: 12.025770124416487\n",
      "Epoch 9276, Loss: 208.539325499617, Neurons: 201, Grad norm: 12.025770124416487\n",
      "Epoch 9277, Loss: 208.53944221670318, Neurons: 201, Grad norm: 11.867289198313937\n",
      "Epoch 9277, Loss: 208.53944221670318, Neurons: 201, Grad norm: 11.867289198313937\n",
      "Epoch 9278, Loss: 208.5394695392006, Neurons: 201, Grad norm: 11.239417616296372\n",
      "Epoch 9278, Loss: 208.5394695392006, Neurons: 201, Grad norm: 11.239417616296372\n",
      "Epoch 9279, Loss: 208.53917721755272, Neurons: 201, Grad norm: 9.924119937495638\n",
      "Epoch 9279, Loss: 208.53917721755272, Neurons: 201, Grad norm: 9.924119937495638\n",
      "Epoch 9280, Loss: 208.5385964099896, Neurons: 201, Grad norm: 8.261838403343205\n",
      "Epoch 9280, Loss: 208.5385964099896, Neurons: 201, Grad norm: 8.261838403343205\n",
      "Epoch 9281, Loss: 208.53796714116947, Neurons: 201, Grad norm: 6.2004927867608695\n",
      "Epoch 9281, Loss: 208.53796714116947, Neurons: 201, Grad norm: 6.2004927867608695\n",
      "Epoch 9282, Loss: 208.53740517922424, Neurons: 201, Grad norm: 4.168173736686679\n",
      "Epoch 9282, Loss: 208.53740517922424, Neurons: 201, Grad norm: 4.168173736686679\n",
      "Epoch 9283, Loss: 208.5370532918227, Neurons: 201, Grad norm: 2.3539875686321605\n",
      "Epoch 9283, Loss: 208.5370532918227, Neurons: 201, Grad norm: 2.3539875686321605\n",
      "Epoch 9284, Loss: 208.53692408790104, Neurons: 201, Grad norm: 2.5304528586297046\n",
      "Epoch 9284, Loss: 208.53692408790104, Neurons: 201, Grad norm: 2.5304528586297046\n",
      "Epoch 9285, Loss: 208.5370504129034, Neurons: 201, Grad norm: 4.131854132867789\n",
      "Epoch 9285, Loss: 208.5370504129034, Neurons: 201, Grad norm: 4.131854132867789\n",
      "Epoch 9286, Loss: 208.53714803594016, Neurons: 201, Grad norm: 6.373084933334375\n",
      "Epoch 9286, Loss: 208.53714803594016, Neurons: 201, Grad norm: 6.373084933334375\n",
      "Epoch 9287, Loss: 208.53730665802823, Neurons: 201, Grad norm: 8.3274432483093\n",
      "Epoch 9287, Loss: 208.53730665802823, Neurons: 201, Grad norm: 8.3274432483093\n",
      "Epoch 9288, Loss: 208.5373740114757, Neurons: 201, Grad norm: 9.345004023625192\n",
      "Epoch 9288, Loss: 208.5373740114757, Neurons: 201, Grad norm: 9.345004023625192\n",
      "Epoch 9289, Loss: 208.53740073660293, Neurons: 201, Grad norm: 9.613201359578387\n",
      "Epoch 9289, Loss: 208.53740073660293, Neurons: 201, Grad norm: 9.613201359578387\n",
      "Epoch 9290, Loss: 208.53740446954976, Neurons: 201, Grad norm: 9.110568808776232\n",
      "Epoch 9290, Loss: 208.53740446954976, Neurons: 201, Grad norm: 9.110568808776232\n",
      "Epoch 9291, Loss: 208.5372085261989, Neurons: 201, Grad norm: 7.553410097500536\n",
      "Epoch 9291, Loss: 208.5372085261989, Neurons: 201, Grad norm: 7.553410097500536\n",
      "Epoch 9292, Loss: 208.53691053693208, Neurons: 201, Grad norm: 6.143201505941921\n",
      "Epoch 9292, Loss: 208.53691053693208, Neurons: 201, Grad norm: 6.143201505941921\n",
      "Epoch 9293, Loss: 208.53672834938385, Neurons: 201, Grad norm: 4.72835493502055\n",
      "Epoch 9293, Loss: 208.53672834938385, Neurons: 201, Grad norm: 4.72835493502055\n",
      "Epoch 9294, Loss: 208.53650976349832, Neurons: 201, Grad norm: 3.3221689952821563\n",
      "Epoch 9294, Loss: 208.53650976349832, Neurons: 201, Grad norm: 3.3221689952821563\n",
      "Epoch 9295, Loss: 208.53627128747766, Neurons: 201, Grad norm: 2.175282745772546\n",
      "Epoch 9295, Loss: 208.53627128747766, Neurons: 201, Grad norm: 2.175282745772546\n",
      "Epoch 9296, Loss: 208.53603930631905, Neurons: 201, Grad norm: 1.1391298660041056\n",
      "Epoch 9296, Loss: 208.53603930631905, Neurons: 201, Grad norm: 1.1391298660041056\n",
      "Epoch 9297, Loss: 208.5358283592485, Neurons: 201, Grad norm: 1.0536658213613874\n",
      "Epoch 9297, Loss: 208.5358283592485, Neurons: 201, Grad norm: 1.0536658213613874\n",
      "Epoch 9298, Loss: 208.53575003304022, Neurons: 201, Grad norm: 1.7303545116884174\n",
      "Epoch 9298, Loss: 208.53575003304022, Neurons: 201, Grad norm: 1.7303545116884174\n",
      "Epoch 9299, Loss: 208.5358493885952, Neurons: 201, Grad norm: 2.7845003106493653\n",
      "Epoch 9299, Loss: 208.5358493885952, Neurons: 201, Grad norm: 2.7845003106493653\n",
      "Epoch 9300, Loss: 208.53587764964362, Neurons: 201, Grad norm: 4.091883383784744\n",
      "Epoch 9300, Loss: 208.53587764964362, Neurons: 201, Grad norm: 4.091883383784744\n",
      "Epoch 9301, Loss: 208.53593696044297, Neurons: 201, Grad norm: 5.727401882192075\n",
      "Epoch 9301, Loss: 208.53593696044297, Neurons: 201, Grad norm: 5.727401882192075\n",
      "Epoch 9302, Loss: 208.5358898176829, Neurons: 201, Grad norm: 7.533093142405123\n",
      "Epoch 9302, Loss: 208.5358898176829, Neurons: 201, Grad norm: 7.533093142405123\n",
      "Epoch 9303, Loss: 208.53593231318445, Neurons: 201, Grad norm: 8.989298821775805\n",
      "Epoch 9303, Loss: 208.53593231318445, Neurons: 201, Grad norm: 8.989298821775805\n",
      "Epoch 9304, Loss: 208.53616297956216, Neurons: 201, Grad norm: 9.9947416348462\n",
      "Epoch 9304, Loss: 208.53616297956216, Neurons: 201, Grad norm: 9.9947416348462\n",
      "Epoch 9305, Loss: 208.53624489514516, Neurons: 201, Grad norm: 10.436038178236581\n",
      "Epoch 9305, Loss: 208.53624489514516, Neurons: 201, Grad norm: 10.436038178236581\n",
      "Epoch 9306, Loss: 208.53614727833573, Neurons: 201, Grad norm: 9.811253294000702\n",
      "Epoch 9306, Loss: 208.53614727833573, Neurons: 201, Grad norm: 9.811253294000702\n",
      "Epoch 9307, Loss: 208.53601549862552, Neurons: 201, Grad norm: 8.572944224216155\n",
      "Epoch 9307, Loss: 208.53601549862552, Neurons: 201, Grad norm: 8.572944224216155\n",
      "Epoch 9308, Loss: 208.53575134121482, Neurons: 201, Grad norm: 6.831275615489119\n",
      "Epoch 9308, Loss: 208.53575134121482, Neurons: 201, Grad norm: 6.831275615489119\n",
      "Epoch 9309, Loss: 208.535358578322, Neurons: 201, Grad norm: 4.639108336933571\n",
      "Epoch 9309, Loss: 208.535358578322, Neurons: 201, Grad norm: 4.639108336933571\n",
      "Epoch 9310, Loss: 208.53508097988149, Neurons: 201, Grad norm: 2.4519869192195904\n",
      "Epoch 9310, Loss: 208.53508097988149, Neurons: 201, Grad norm: 2.4519869192195904\n",
      "Epoch 9311, Loss: 208.5348707010603, Neurons: 201, Grad norm: 1.3766036956787826\n",
      "Epoch 9311, Loss: 208.5348707010603, Neurons: 201, Grad norm: 1.3766036956787826\n",
      "Epoch 9312, Loss: 208.53473654935112, Neurons: 201, Grad norm: 2.136971814448768\n",
      "Epoch 9312, Loss: 208.53473654935112, Neurons: 201, Grad norm: 2.136971814448768\n",
      "Epoch 9313, Loss: 208.53466284185112, Neurons: 201, Grad norm: 3.032441411191373\n",
      "Epoch 9313, Loss: 208.53466284185112, Neurons: 201, Grad norm: 3.032441411191373\n",
      "Epoch 9314, Loss: 208.5346370694262, Neurons: 201, Grad norm: 3.872234713719596\n",
      "Epoch 9314, Loss: 208.5346370694262, Neurons: 201, Grad norm: 3.872234713719596\n",
      "Epoch 9315, Loss: 208.53456520865768, Neurons: 201, Grad norm: 4.62431549190608\n",
      "Epoch 9315, Loss: 208.53456520865768, Neurons: 201, Grad norm: 4.62431549190608\n",
      "Epoch 9316, Loss: 208.53458073241592, Neurons: 201, Grad norm: 5.608063786892615\n",
      "Epoch 9316, Loss: 208.53458073241592, Neurons: 201, Grad norm: 5.608063786892615\n",
      "Epoch 9317, Loss: 208.5346852277225, Neurons: 201, Grad norm: 6.375559370348632\n",
      "Epoch 9317, Loss: 208.5346852277225, Neurons: 201, Grad norm: 6.375559370348632\n",
      "Epoch 9318, Loss: 208.53483144025842, Neurons: 201, Grad norm: 7.166943283342096\n",
      "Epoch 9318, Loss: 208.53483144025842, Neurons: 201, Grad norm: 7.166943283342096\n",
      "Epoch 9319, Loss: 208.5348903217792, Neurons: 201, Grad norm: 7.779590048144446\n",
      "Epoch 9319, Loss: 208.5348903217792, Neurons: 201, Grad norm: 7.779590048144446\n",
      "Epoch 9320, Loss: 208.53482807970394, Neurons: 201, Grad norm: 8.120341698642134\n",
      "Epoch 9320, Loss: 208.53482807970394, Neurons: 201, Grad norm: 8.120341698642134\n",
      "Epoch 9321, Loss: 208.53474590259074, Neurons: 201, Grad norm: 8.072528698929363\n",
      "Epoch 9321, Loss: 208.53474590259074, Neurons: 201, Grad norm: 8.072528698929363\n",
      "Epoch 9322, Loss: 208.53457259479256, Neurons: 201, Grad norm: 7.756201088382288\n",
      "Epoch 9322, Loss: 208.53457259479256, Neurons: 201, Grad norm: 7.756201088382288\n",
      "Epoch 9323, Loss: 208.53447163885346, Neurons: 201, Grad norm: 6.90399372045964\n",
      "Epoch 9323, Loss: 208.53447163885346, Neurons: 201, Grad norm: 6.90399372045964\n",
      "Epoch 9324, Loss: 208.5342687902941, Neurons: 201, Grad norm: 5.574787379543056\n",
      "Epoch 9324, Loss: 208.5342687902941, Neurons: 201, Grad norm: 5.574787379543056\n",
      "Epoch 9325, Loss: 208.5340243881247, Neurons: 201, Grad norm: 3.9030722385674275\n",
      "Epoch 9325, Loss: 208.5340243881247, Neurons: 201, Grad norm: 3.9030722385674275\n",
      "Epoch 9326, Loss: 208.53377465911416, Neurons: 201, Grad norm: 1.972732964558481\n",
      "Epoch 9326, Loss: 208.53377465911416, Neurons: 201, Grad norm: 1.972732964558481\n",
      "Epoch 9327, Loss: 208.53357956106856, Neurons: 201, Grad norm: 1.14542538939152\n",
      "Epoch 9327, Loss: 208.53357956106856, Neurons: 201, Grad norm: 1.14542538939152\n",
      "Epoch 9328, Loss: 208.53352808214265, Neurons: 201, Grad norm: 1.959478521057593\n",
      "Epoch 9328, Loss: 208.53352808214265, Neurons: 201, Grad norm: 1.959478521057593\n",
      "Epoch 9329, Loss: 208.53351218213075, Neurons: 201, Grad norm: 2.878986164708052\n",
      "Epoch 9329, Loss: 208.53351218213075, Neurons: 201, Grad norm: 2.878986164708052\n",
      "Epoch 9330, Loss: 208.53344122807286, Neurons: 201, Grad norm: 3.738660934892597\n",
      "Epoch 9330, Loss: 208.53344122807286, Neurons: 201, Grad norm: 3.738660934892597\n",
      "Epoch 9331, Loss: 208.53343204752505, Neurons: 201, Grad norm: 4.25393712766794\n",
      "Epoch 9331, Loss: 208.53343204752505, Neurons: 201, Grad norm: 4.25393712766794\n",
      "Epoch 9332, Loss: 208.53334033659732, Neurons: 201, Grad norm: 4.220217184654907\n",
      "Epoch 9332, Loss: 208.53334033659732, Neurons: 201, Grad norm: 4.220217184654907\n",
      "Epoch 9333, Loss: 208.5333225805528, Neurons: 201, Grad norm: 4.994682264035308\n",
      "Epoch 9333, Loss: 208.5333225805528, Neurons: 201, Grad norm: 4.994682264035308\n",
      "Epoch 9334, Loss: 208.53337548764765, Neurons: 201, Grad norm: 5.468365837690525\n",
      "Epoch 9334, Loss: 208.53337548764765, Neurons: 201, Grad norm: 5.468365837690525\n",
      "Epoch 9335, Loss: 208.53338062709537, Neurons: 201, Grad norm: 6.308641835288942\n",
      "Epoch 9335, Loss: 208.53338062709537, Neurons: 201, Grad norm: 6.308641835288942\n",
      "Epoch 9336, Loss: 208.53346135763874, Neurons: 201, Grad norm: 7.317281390216396\n",
      "Epoch 9336, Loss: 208.53346135763874, Neurons: 201, Grad norm: 7.317281390216396\n",
      "Epoch 9337, Loss: 208.5335208675579, Neurons: 201, Grad norm: 8.099891504695071\n",
      "Epoch 9337, Loss: 208.5335208675579, Neurons: 201, Grad norm: 8.099891504695071\n",
      "Epoch 9338, Loss: 208.53358452470917, Neurons: 201, Grad norm: 8.843062019568045\n",
      "Epoch 9338, Loss: 208.53358452470917, Neurons: 201, Grad norm: 8.843062019568045\n",
      "Epoch 9339, Loss: 208.53366532748615, Neurons: 201, Grad norm: 8.906888421620213\n",
      "Epoch 9339, Loss: 208.53366532748615, Neurons: 201, Grad norm: 8.906888421620213\n",
      "Epoch 9340, Loss: 208.53365119352546, Neurons: 201, Grad norm: 8.983541965753497\n",
      "Epoch 9340, Loss: 208.53365119352546, Neurons: 201, Grad norm: 8.983541965753497\n",
      "Epoch 9341, Loss: 208.53353722500924, Neurons: 201, Grad norm: 8.839430224009906\n",
      "Epoch 9341, Loss: 208.53353722500924, Neurons: 201, Grad norm: 8.839430224009906\n",
      "Epoch 9342, Loss: 208.53343038800796, Neurons: 201, Grad norm: 8.025680712626277\n",
      "Epoch 9342, Loss: 208.53343038800796, Neurons: 201, Grad norm: 8.025680712626277\n",
      "Epoch 9343, Loss: 208.5333210173015, Neurons: 201, Grad norm: 7.610605425016852\n",
      "Epoch 9343, Loss: 208.5333210173015, Neurons: 201, Grad norm: 7.610605425016852\n",
      "Epoch 9344, Loss: 208.5332025194558, Neurons: 201, Grad norm: 7.082192451917077\n",
      "Epoch 9344, Loss: 208.5332025194558, Neurons: 201, Grad norm: 7.082192451917077\n",
      "Epoch 9345, Loss: 208.53300412216112, Neurons: 201, Grad norm: 6.427111059402334\n",
      "Epoch 9345, Loss: 208.53300412216112, Neurons: 201, Grad norm: 6.427111059402334\n",
      "Epoch 9346, Loss: 208.53284610763856, Neurons: 201, Grad norm: 6.037031464166967\n",
      "Epoch 9346, Loss: 208.53284610763856, Neurons: 201, Grad norm: 6.037031464166967\n",
      "Epoch 9347, Loss: 208.53279731725473, Neurons: 201, Grad norm: 5.450716244293796\n",
      "Epoch 9347, Loss: 208.53279731725473, Neurons: 201, Grad norm: 5.450716244293796\n",
      "Epoch 9348, Loss: 208.5326074780033, Neurons: 201, Grad norm: 5.21878283466248\n",
      "Epoch 9348, Loss: 208.5326074780033, Neurons: 201, Grad norm: 5.21878283466248\n",
      "Epoch 9349, Loss: 208.53250803597803, Neurons: 201, Grad norm: 5.547275843360054\n",
      "Epoch 9349, Loss: 208.53250803597803, Neurons: 201, Grad norm: 5.547275843360054\n",
      "Epoch 9350, Loss: 208.53235383900048, Neurons: 201, Grad norm: 5.630793851762838\n",
      "Epoch 9350, Loss: 208.53235383900048, Neurons: 201, Grad norm: 5.630793851762838\n",
      "Epoch 9351, Loss: 208.53232292997635, Neurons: 201, Grad norm: 6.128716887101136\n",
      "Epoch 9351, Loss: 208.53232292997635, Neurons: 201, Grad norm: 6.128716887101136\n",
      "Epoch 9352, Loss: 208.53233051966168, Neurons: 201, Grad norm: 6.883806652308727\n",
      "Epoch 9352, Loss: 208.53233051966168, Neurons: 201, Grad norm: 6.883806652308727\n",
      "Epoch 9353, Loss: 208.53236436901796, Neurons: 201, Grad norm: 7.849964804713967\n",
      "Epoch 9353, Loss: 208.53236436901796, Neurons: 201, Grad norm: 7.849964804713967\n",
      "Epoch 9354, Loss: 208.53258630131597, Neurons: 201, Grad norm: 8.85966973566618\n",
      "Epoch 9354, Loss: 208.53258630131597, Neurons: 201, Grad norm: 8.85966973566618\n",
      "Epoch 9355, Loss: 208.5328226377196, Neurons: 201, Grad norm: 10.30990604617339\n",
      "Epoch 9355, Loss: 208.5328226377196, Neurons: 201, Grad norm: 10.30990604617339\n",
      "Epoch 9356, Loss: 208.53303564642113, Neurons: 201, Grad norm: 11.356862052514755\n",
      "Epoch 9356, Loss: 208.53303564642113, Neurons: 201, Grad norm: 11.356862052514755\n",
      "Epoch 9357, Loss: 208.53330903564247, Neurons: 201, Grad norm: 12.211810135839292\n",
      "Epoch 9357, Loss: 208.53330903564247, Neurons: 201, Grad norm: 12.211810135839292\n",
      "Epoch 9358, Loss: 208.53342530159065, Neurons: 201, Grad norm: 12.832255875467045\n",
      "Epoch 9358, Loss: 208.53342530159065, Neurons: 201, Grad norm: 12.832255875467045\n",
      "Epoch 9359, Loss: 208.53346397880506, Neurons: 201, Grad norm: 13.277843296918281\n",
      "Epoch 9359, Loss: 208.53346397880506, Neurons: 201, Grad norm: 13.277843296918281\n",
      "Epoch 9360, Loss: 208.53347476365212, Neurons: 201, Grad norm: 12.89868878500629\n",
      "Epoch 9360, Loss: 208.53347476365212, Neurons: 201, Grad norm: 12.89868878500629\n",
      "Epoch 9361, Loss: 208.53321326376744, Neurons: 201, Grad norm: 12.09136432029929\n",
      "Epoch 9361, Loss: 208.53321326376744, Neurons: 201, Grad norm: 12.09136432029929\n",
      "Epoch 9362, Loss: 208.53294871829243, Neurons: 201, Grad norm: 11.060723874246236\n",
      "Epoch 9362, Loss: 208.53294871829243, Neurons: 201, Grad norm: 11.060723874246236\n",
      "Epoch 9363, Loss: 208.53251886337873, Neurons: 201, Grad norm: 9.37869249416\n",
      "Epoch 9363, Loss: 208.53251886337873, Neurons: 201, Grad norm: 9.37869249416\n",
      "Epoch 9364, Loss: 208.53207140420747, Neurons: 201, Grad norm: 7.309306092197445\n",
      "Epoch 9364, Loss: 208.53207140420747, Neurons: 201, Grad norm: 7.309306092197445\n",
      "Epoch 9365, Loss: 208.5316451822293, Neurons: 201, Grad norm: 4.913647163907394\n",
      "Epoch 9365, Loss: 208.5316451822293, Neurons: 201, Grad norm: 4.913647163907394\n",
      "Epoch 9366, Loss: 208.5312270792736, Neurons: 201, Grad norm: 2.7454158076180395\n",
      "Epoch 9366, Loss: 208.5312270792736, Neurons: 201, Grad norm: 2.7454158076180395\n",
      "Epoch 9367, Loss: 208.53094461365086, Neurons: 201, Grad norm: 1.4308976351435994\n",
      "Epoch 9367, Loss: 208.53094461365086, Neurons: 201, Grad norm: 1.4308976351435994\n",
      "Epoch 9368, Loss: 208.53083091239927, Neurons: 201, Grad norm: 1.8807840016759336\n",
      "Epoch 9368, Loss: 208.53083091239927, Neurons: 201, Grad norm: 1.8807840016759336\n",
      "Epoch 9369, Loss: 208.53072178017462, Neurons: 201, Grad norm: 2.7527463526591744\n",
      "Epoch 9369, Loss: 208.53072178017462, Neurons: 201, Grad norm: 2.7527463526591744\n",
      "Epoch 9370, Loss: 208.5306722852904, Neurons: 201, Grad norm: 4.009669952529224\n",
      "Epoch 9370, Loss: 208.5306722852904, Neurons: 201, Grad norm: 4.009669952529224\n",
      "Epoch 9371, Loss: 208.53063646823264, Neurons: 201, Grad norm: 4.609659992855939\n",
      "Epoch 9371, Loss: 208.53063646823264, Neurons: 201, Grad norm: 4.609659992855939\n",
      "Epoch 9372, Loss: 208.53063735450002, Neurons: 201, Grad norm: 5.305806398680255\n",
      "Epoch 9372, Loss: 208.53063735450002, Neurons: 201, Grad norm: 5.305806398680255\n",
      "Epoch 9373, Loss: 208.53067985788982, Neurons: 201, Grad norm: 6.128092025443394\n",
      "Epoch 9373, Loss: 208.53067985788982, Neurons: 201, Grad norm: 6.128092025443394\n",
      "Epoch 9374, Loss: 208.5307451536409, Neurons: 201, Grad norm: 6.671388325999133\n",
      "Epoch 9374, Loss: 208.5307451536409, Neurons: 201, Grad norm: 6.671388325999133\n",
      "Epoch 9375, Loss: 208.53082726794815, Neurons: 201, Grad norm: 7.131858800370266\n",
      "Epoch 9375, Loss: 208.53082726794815, Neurons: 201, Grad norm: 7.131858800370266\n",
      "Epoch 9376, Loss: 208.53094769332117, Neurons: 201, Grad norm: 7.728033495618005\n",
      "Epoch 9376, Loss: 208.53094769332117, Neurons: 201, Grad norm: 7.728033495618005\n",
      "Epoch 9377, Loss: 208.53120842878423, Neurons: 201, Grad norm: 8.26605284041064\n",
      "Epoch 9377, Loss: 208.53120842878423, Neurons: 201, Grad norm: 8.26605284041064\n",
      "Epoch 9378, Loss: 208.53137606561089, Neurons: 201, Grad norm: 9.12245538848964\n",
      "Epoch 9378, Loss: 208.53137606561089, Neurons: 201, Grad norm: 9.12245538848964\n",
      "Epoch 9379, Loss: 208.53125589813794, Neurons: 201, Grad norm: 9.564258639912174\n",
      "Epoch 9379, Loss: 208.53125589813794, Neurons: 201, Grad norm: 9.564258639912174\n",
      "Epoch 9380, Loss: 208.5311345522452, Neurons: 201, Grad norm: 10.219725375694676\n",
      "Epoch 9380, Loss: 208.5311345522452, Neurons: 201, Grad norm: 10.219725375694676\n",
      "Epoch 9381, Loss: 208.53104172917966, Neurons: 201, Grad norm: 10.17832078252738\n",
      "Epoch 9381, Loss: 208.53104172917966, Neurons: 201, Grad norm: 10.17832078252738\n",
      "Epoch 9382, Loss: 208.53101773456916, Neurons: 201, Grad norm: 9.868372918955078\n",
      "Epoch 9382, Loss: 208.53101773456916, Neurons: 201, Grad norm: 9.868372918955078\n",
      "Epoch 9383, Loss: 208.53080986514584, Neurons: 201, Grad norm: 9.2272176556976\n",
      "Epoch 9383, Loss: 208.53080986514584, Neurons: 201, Grad norm: 9.2272176556976\n",
      "Epoch 9384, Loss: 208.5305653469882, Neurons: 201, Grad norm: 8.138932684882512\n",
      "Epoch 9384, Loss: 208.5305653469882, Neurons: 201, Grad norm: 8.138932684882512\n",
      "Epoch 9385, Loss: 208.53032925464643, Neurons: 201, Grad norm: 6.393960564398107\n",
      "Epoch 9385, Loss: 208.53032925464643, Neurons: 201, Grad norm: 6.393960564398107\n",
      "Epoch 9386, Loss: 208.5300963789399, Neurons: 201, Grad norm: 5.123426311792335\n",
      "Epoch 9386, Loss: 208.5300963789399, Neurons: 201, Grad norm: 5.123426311792335\n",
      "Epoch 9387, Loss: 208.52982746984654, Neurons: 201, Grad norm: 3.72303966714095\n",
      "Epoch 9387, Loss: 208.52982746984654, Neurons: 201, Grad norm: 3.72303966714095\n",
      "Epoch 9388, Loss: 208.5296115277623, Neurons: 201, Grad norm: 2.9531028605511604\n",
      "Epoch 9388, Loss: 208.5296115277623, Neurons: 201, Grad norm: 2.9531028605511604\n",
      "Epoch 9389, Loss: 208.52958513770886, Neurons: 201, Grad norm: 1.9430195337952905\n",
      "Epoch 9389, Loss: 208.52958513770886, Neurons: 201, Grad norm: 1.9430195337952905\n",
      "Epoch 9390, Loss: 208.5293182211412, Neurons: 201, Grad norm: 1.184435240571799\n",
      "Epoch 9390, Loss: 208.5293182211412, Neurons: 201, Grad norm: 1.184435240571799\n",
      "Epoch 9391, Loss: 208.5289942705285, Neurons: 201, Grad norm: 0.8994915425038109\n",
      "Epoch 9391, Loss: 208.5289942705285, Neurons: 201, Grad norm: 0.8994915425038109\n",
      "Epoch 9392, Loss: 208.52877429639076, Neurons: 201, Grad norm: 1.9358192634402909\n",
      "Epoch 9392, Loss: 208.52877429639076, Neurons: 201, Grad norm: 1.9358192634402909\n",
      "Epoch 9393, Loss: 208.52877020062843, Neurons: 201, Grad norm: 2.667051486720818\n",
      "Epoch 9393, Loss: 208.52877020062843, Neurons: 201, Grad norm: 2.667051486720818\n",
      "Epoch 9394, Loss: 208.52885164048826, Neurons: 201, Grad norm: 2.7135939640903173\n",
      "Epoch 9394, Loss: 208.52885164048826, Neurons: 201, Grad norm: 2.7135939640903173\n",
      "Epoch 9395, Loss: 208.52882893061584, Neurons: 201, Grad norm: 3.572452023511727\n",
      "Epoch 9395, Loss: 208.52882893061584, Neurons: 201, Grad norm: 3.572452023511727\n",
      "Epoch 9396, Loss: 208.5285999586706, Neurons: 201, Grad norm: 4.783088269644951\n",
      "Epoch 9396, Loss: 208.5285999586706, Neurons: 201, Grad norm: 4.783088269644951\n",
      "Epoch 9397, Loss: 208.52855306250925, Neurons: 201, Grad norm: 6.58202074439783\n",
      "Epoch 9397, Loss: 208.52855306250925, Neurons: 201, Grad norm: 6.58202074439783\n",
      "Epoch 9398, Loss: 208.528632152381, Neurons: 201, Grad norm: 8.040733154389912\n",
      "Epoch 9398, Loss: 208.528632152381, Neurons: 201, Grad norm: 8.040733154389912\n",
      "Epoch 9399, Loss: 208.52869459489057, Neurons: 201, Grad norm: 8.964195528639689\n",
      "Epoch 9399, Loss: 208.52869459489057, Neurons: 201, Grad norm: 8.964195528639689\n",
      "Epoch 9400, Loss: 208.52868906336977, Neurons: 201, Grad norm: 8.913162748788283\n",
      "Epoch 9400, Loss: 208.52868906336977, Neurons: 201, Grad norm: 8.913162748788283\n",
      "Epoch 9401, Loss: 208.52865442962283, Neurons: 201, Grad norm: 9.214752935974147\n",
      "Epoch 9401, Loss: 208.52865442962283, Neurons: 201, Grad norm: 9.214752935974147\n",
      "Epoch 9402, Loss: 208.5285355180008, Neurons: 201, Grad norm: 8.64739492078916\n",
      "Epoch 9402, Loss: 208.5285355180008, Neurons: 201, Grad norm: 8.64739492078916\n",
      "Epoch 9403, Loss: 208.52842386183647, Neurons: 201, Grad norm: 8.431626387783037\n",
      "Epoch 9403, Loss: 208.52842386183647, Neurons: 201, Grad norm: 8.431626387783037\n",
      "Epoch 9404, Loss: 208.52844613568817, Neurons: 201, Grad norm: 8.621852392854722\n",
      "Epoch 9404, Loss: 208.52844613568817, Neurons: 201, Grad norm: 8.621852392854722\n",
      "Epoch 9405, Loss: 208.52865691329032, Neurons: 201, Grad norm: 8.998819251214245\n",
      "Epoch 9405, Loss: 208.52865691329032, Neurons: 201, Grad norm: 8.998819251214245\n",
      "Epoch 9406, Loss: 208.52880506727334, Neurons: 201, Grad norm: 9.590563876504255\n",
      "Epoch 9406, Loss: 208.52880506727334, Neurons: 201, Grad norm: 9.590563876504255\n",
      "Epoch 9407, Loss: 208.5287980424743, Neurons: 201, Grad norm: 10.362416691608493\n",
      "Epoch 9407, Loss: 208.5287980424743, Neurons: 201, Grad norm: 10.362416691608493\n",
      "Epoch 9408, Loss: 208.5286550861389, Neurons: 201, Grad norm: 11.394041323876035\n",
      "Epoch 9408, Loss: 208.5286550861389, Neurons: 201, Grad norm: 11.394041323876035\n",
      "Epoch 9409, Loss: 208.52864446311764, Neurons: 201, Grad norm: 12.26880745280005\n",
      "Epoch 9409, Loss: 208.52864446311764, Neurons: 201, Grad norm: 12.26880745280005\n",
      "Epoch 9410, Loss: 208.52864476572992, Neurons: 201, Grad norm: 12.832478116239358\n",
      "Epoch 9410, Loss: 208.52864476572992, Neurons: 201, Grad norm: 12.832478116239358\n",
      "Epoch 9411, Loss: 208.5286665730018, Neurons: 201, Grad norm: 12.970552586402652\n",
      "Epoch 9411, Loss: 208.5286665730018, Neurons: 201, Grad norm: 12.970552586402652\n",
      "Epoch 9412, Loss: 208.5285388124647, Neurons: 201, Grad norm: 12.17168553321297\n",
      "Epoch 9412, Loss: 208.5285388124647, Neurons: 201, Grad norm: 12.17168553321297\n",
      "Epoch 9413, Loss: 208.52834787984304, Neurons: 201, Grad norm: 10.931129681695584\n",
      "Epoch 9413, Loss: 208.52834787984304, Neurons: 201, Grad norm: 10.931129681695584\n",
      "Epoch 9414, Loss: 208.52804148682714, Neurons: 201, Grad norm: 9.508113801731959\n",
      "Epoch 9414, Loss: 208.52804148682714, Neurons: 201, Grad norm: 9.508113801731959\n",
      "Epoch 9415, Loss: 208.52768535932026, Neurons: 201, Grad norm: 7.90806966693403\n",
      "Epoch 9415, Loss: 208.52768535932026, Neurons: 201, Grad norm: 7.90806966693403\n",
      "Epoch 9416, Loss: 208.52742827618127, Neurons: 201, Grad norm: 5.8347411203426445\n",
      "Epoch 9416, Loss: 208.52742827618127, Neurons: 201, Grad norm: 5.8347411203426445\n",
      "Epoch 9417, Loss: 208.5271537840315, Neurons: 201, Grad norm: 4.6642377309647705\n",
      "Epoch 9417, Loss: 208.5271537840315, Neurons: 201, Grad norm: 4.6642377309647705\n",
      "Epoch 9418, Loss: 208.52690739186684, Neurons: 201, Grad norm: 3.394345966545558\n",
      "Epoch 9418, Loss: 208.52690739186684, Neurons: 201, Grad norm: 3.394345966545558\n",
      "Epoch 9419, Loss: 208.52660051409765, Neurons: 201, Grad norm: 2.111548686332973\n",
      "Epoch 9419, Loss: 208.52660051409765, Neurons: 201, Grad norm: 2.111548686332973\n",
      "Epoch 9420, Loss: 208.52640188470068, Neurons: 201, Grad norm: 1.500459164525882\n",
      "Epoch 9420, Loss: 208.52640188470068, Neurons: 201, Grad norm: 1.500459164525882\n",
      "Epoch 9421, Loss: 208.52625781610277, Neurons: 201, Grad norm: 0.9307833179529527\n",
      "Epoch 9421, Loss: 208.52625781610277, Neurons: 201, Grad norm: 0.9307833179529527\n",
      "Epoch 9422, Loss: 208.5261200230152, Neurons: 201, Grad norm: 0.6057345145222086\n",
      "Epoch 9422, Loss: 208.5261200230152, Neurons: 201, Grad norm: 0.6057345145222086\n",
      "Epoch 9423, Loss: 208.52604891623508, Neurons: 201, Grad norm: 1.1278412043285138\n",
      "Epoch 9423, Loss: 208.52604891623508, Neurons: 201, Grad norm: 1.1278412043285138\n",
      "Epoch 9424, Loss: 208.52600020843659, Neurons: 201, Grad norm: 1.7621150709311217\n",
      "Epoch 9424, Loss: 208.52600020843659, Neurons: 201, Grad norm: 1.7621150709311217\n",
      "Epoch 9425, Loss: 208.52596203440564, Neurons: 201, Grad norm: 2.9316536891015383\n",
      "Epoch 9425, Loss: 208.52596203440564, Neurons: 201, Grad norm: 2.9316536891015383\n",
      "Epoch 9426, Loss: 208.5259551250165, Neurons: 201, Grad norm: 4.364741479602344\n",
      "Epoch 9426, Loss: 208.5259551250165, Neurons: 201, Grad norm: 4.364741479602344\n",
      "Epoch 9427, Loss: 208.52595569566208, Neurons: 201, Grad norm: 5.534152328397185\n",
      "Epoch 9427, Loss: 208.52595569566208, Neurons: 201, Grad norm: 5.534152328397185\n",
      "Epoch 9428, Loss: 208.52610783562653, Neurons: 201, Grad norm: 7.059192495009876\n",
      "Epoch 9428, Loss: 208.52610783562653, Neurons: 201, Grad norm: 7.059192495009876\n",
      "Epoch 9429, Loss: 208.52622802723968, Neurons: 201, Grad norm: 8.663902388799242\n",
      "Epoch 9429, Loss: 208.52622802723968, Neurons: 201, Grad norm: 8.663902388799242\n",
      "Epoch 9430, Loss: 208.52633870128702, Neurons: 201, Grad norm: 9.999546413064857\n",
      "Epoch 9430, Loss: 208.52633870128702, Neurons: 201, Grad norm: 9.999546413064857\n",
      "Epoch 9431, Loss: 208.52656189943932, Neurons: 201, Grad norm: 10.677652677282394\n",
      "Epoch 9431, Loss: 208.52656189943932, Neurons: 201, Grad norm: 10.677652677282394\n",
      "Epoch 9432, Loss: 208.5266479447893, Neurons: 201, Grad norm: 11.24138360549152\n",
      "Epoch 9432, Loss: 208.5266479447893, Neurons: 201, Grad norm: 11.24138360549152\n",
      "Epoch 9433, Loss: 208.52663146954353, Neurons: 201, Grad norm: 11.073070591723265\n",
      "Epoch 9433, Loss: 208.52663146954353, Neurons: 201, Grad norm: 11.073070591723265\n",
      "Epoch 9434, Loss: 208.52656444574203, Neurons: 201, Grad norm: 10.230300428459943\n",
      "Epoch 9434, Loss: 208.52656444574203, Neurons: 201, Grad norm: 10.230300428459943\n",
      "Epoch 9435, Loss: 208.5263302833168, Neurons: 201, Grad norm: 9.405349104987359\n",
      "Epoch 9435, Loss: 208.5263302833168, Neurons: 201, Grad norm: 9.405349104987359\n",
      "Epoch 9436, Loss: 208.526114653947, Neurons: 201, Grad norm: 8.404113428590989\n",
      "Epoch 9436, Loss: 208.526114653947, Neurons: 201, Grad norm: 8.404113428590989\n",
      "Epoch 9437, Loss: 208.52578441970184, Neurons: 201, Grad norm: 6.961249031869406\n",
      "Epoch 9437, Loss: 208.52578441970184, Neurons: 201, Grad norm: 6.961249031869406\n",
      "Epoch 9438, Loss: 208.52546108870555, Neurons: 201, Grad norm: 5.507747531529611\n",
      "Epoch 9438, Loss: 208.52546108870555, Neurons: 201, Grad norm: 5.507747531529611\n",
      "Epoch 9439, Loss: 208.5251717333844, Neurons: 201, Grad norm: 4.172942781006547\n",
      "Epoch 9439, Loss: 208.5251717333844, Neurons: 201, Grad norm: 4.172942781006547\n",
      "Epoch 9440, Loss: 208.5250002628382, Neurons: 201, Grad norm: 2.881496214389393\n",
      "Epoch 9440, Loss: 208.5250002628382, Neurons: 201, Grad norm: 2.881496214389393\n",
      "Epoch 9441, Loss: 208.52483204931522, Neurons: 201, Grad norm: 1.7523644517632844\n",
      "Epoch 9441, Loss: 208.52483204931522, Neurons: 201, Grad norm: 1.7523644517632844\n",
      "Epoch 9442, Loss: 208.52471610760156, Neurons: 201, Grad norm: 1.251689434157302\n",
      "Epoch 9442, Loss: 208.52471610760156, Neurons: 201, Grad norm: 1.251689434157302\n",
      "Epoch 9443, Loss: 208.52461703070466, Neurons: 201, Grad norm: 0.8695168272329876\n",
      "Epoch 9443, Loss: 208.52461703070466, Neurons: 201, Grad norm: 0.8695168272329876\n",
      "Epoch 9444, Loss: 208.5244889866565, Neurons: 201, Grad norm: 1.6668531025925792\n",
      "Epoch 9444, Loss: 208.5244889866565, Neurons: 201, Grad norm: 1.6668531025925792\n",
      "Epoch 9445, Loss: 208.52453788639679, Neurons: 201, Grad norm: 2.2672599169958465\n",
      "Epoch 9445, Loss: 208.52453788639679, Neurons: 201, Grad norm: 2.2672599169958465\n",
      "Epoch 9446, Loss: 208.5245091455817, Neurons: 201, Grad norm: 3.5579307223932592\n",
      "Epoch 9446, Loss: 208.5245091455817, Neurons: 201, Grad norm: 3.5579307223932592\n",
      "Epoch 9447, Loss: 208.5245199895459, Neurons: 201, Grad norm: 4.996000242539312\n",
      "Epoch 9447, Loss: 208.5245199895459, Neurons: 201, Grad norm: 4.996000242539312\n",
      "Epoch 9448, Loss: 208.5245608722081, Neurons: 201, Grad norm: 6.620212613001049\n",
      "Epoch 9448, Loss: 208.5245608722081, Neurons: 201, Grad norm: 6.620212613001049\n",
      "Epoch 9449, Loss: 208.52466534358604, Neurons: 201, Grad norm: 8.450646954622625\n",
      "Epoch 9449, Loss: 208.52466534358604, Neurons: 201, Grad norm: 8.450646954622625\n",
      "Epoch 9450, Loss: 208.52491210737145, Neurons: 201, Grad norm: 10.276898595252934\n",
      "Epoch 9450, Loss: 208.52491210737145, Neurons: 201, Grad norm: 10.276898595252934\n",
      "Epoch 9451, Loss: 208.52533308473846, Neurons: 201, Grad norm: 12.319890724301661\n",
      "Epoch 9451, Loss: 208.52533308473846, Neurons: 201, Grad norm: 12.319890724301661\n",
      "Epoch 9452, Loss: 208.52583122738645, Neurons: 201, Grad norm: 14.214007708785745\n",
      "Epoch 9452, Loss: 208.52583122738645, Neurons: 201, Grad norm: 14.214007708785745\n",
      "Epoch 9453, Loss: 208.52642466933645, Neurons: 201, Grad norm: 15.790077856034369\n",
      "Epoch 9453, Loss: 208.52642466933645, Neurons: 201, Grad norm: 15.790077856034369\n",
      "Epoch 9454, Loss: 208.52704627583122, Neurons: 201, Grad norm: 16.984900937381642\n",
      "Epoch 9454, Loss: 208.52704627583122, Neurons: 201, Grad norm: 16.984900937381642\n",
      "Epoch 9455, Loss: 208.52737685839253, Neurons: 201, Grad norm: 17.64453903717948\n",
      "Epoch 9455, Loss: 208.52737685839253, Neurons: 201, Grad norm: 17.64453903717948\n",
      "Epoch 9456, Loss: 208.52731083526425, Neurons: 201, Grad norm: 17.229559835489113\n",
      "Epoch 9456, Loss: 208.52731083526425, Neurons: 201, Grad norm: 17.229559835489113\n",
      "Epoch 9457, Loss: 208.5269068712678, Neurons: 201, Grad norm: 16.03577449295864\n",
      "Epoch 9457, Loss: 208.5269068712678, Neurons: 201, Grad norm: 16.03577449295864\n",
      "Epoch 9458, Loss: 208.52630629338765, Neurons: 201, Grad norm: 13.430065389029794\n",
      "Epoch 9458, Loss: 208.52630629338765, Neurons: 201, Grad norm: 13.430065389029794\n",
      "Epoch 9459, Loss: 208.52539496116592, Neurons: 201, Grad norm: 9.840465457386195\n",
      "Epoch 9459, Loss: 208.52539496116592, Neurons: 201, Grad norm: 9.840465457386195\n",
      "Epoch 9460, Loss: 208.5245060978869, Neurons: 201, Grad norm: 5.806665990895625\n",
      "Epoch 9460, Loss: 208.5245060978869, Neurons: 201, Grad norm: 5.806665990895625\n",
      "Epoch 9461, Loss: 208.52373709280883, Neurons: 201, Grad norm: 2.003252148513441\n",
      "Epoch 9461, Loss: 208.52373709280883, Neurons: 201, Grad norm: 2.003252148513441\n",
      "Epoch 9462, Loss: 208.52332714889698, Neurons: 201, Grad norm: 2.430458993180685\n",
      "Epoch 9462, Loss: 208.52332714889698, Neurons: 201, Grad norm: 2.430458993180685\n",
      "Epoch 9463, Loss: 208.52328199683166, Neurons: 201, Grad norm: 5.3689247200135854\n",
      "Epoch 9463, Loss: 208.52328199683166, Neurons: 201, Grad norm: 5.3689247200135854\n",
      "Epoch 9464, Loss: 208.52338608814728, Neurons: 201, Grad norm: 7.2677389192056765\n",
      "Epoch 9464, Loss: 208.52338608814728, Neurons: 201, Grad norm: 7.2677389192056765\n",
      "Epoch 9465, Loss: 208.52358853304833, Neurons: 201, Grad norm: 8.985267223759635\n",
      "Epoch 9465, Loss: 208.52358853304833, Neurons: 201, Grad norm: 8.985267223759635\n",
      "Epoch 9466, Loss: 208.5238551405838, Neurons: 201, Grad norm: 10.254900478280113\n",
      "Epoch 9466, Loss: 208.5238551405838, Neurons: 201, Grad norm: 10.254900478280113\n",
      "Epoch 9467, Loss: 208.52410941489555, Neurons: 201, Grad norm: 10.848044825812158\n",
      "Epoch 9467, Loss: 208.52410941489555, Neurons: 201, Grad norm: 10.848044825812158\n",
      "Epoch 9468, Loss: 208.52440345053208, Neurons: 201, Grad norm: 11.180731117141098\n",
      "Epoch 9468, Loss: 208.52440345053208, Neurons: 201, Grad norm: 11.180731117141098\n",
      "Epoch 9469, Loss: 208.52453376907235, Neurons: 201, Grad norm: 11.294210581027984\n",
      "Epoch 9469, Loss: 208.52453376907235, Neurons: 201, Grad norm: 11.294210581027984\n",
      "Epoch 9470, Loss: 208.52435795704423, Neurons: 201, Grad norm: 10.80591056763098\n",
      "Epoch 9470, Loss: 208.52435795704423, Neurons: 201, Grad norm: 10.80591056763098\n",
      "Epoch 9471, Loss: 208.524231652536, Neurons: 201, Grad norm: 9.83891764260465\n",
      "Epoch 9471, Loss: 208.524231652536, Neurons: 201, Grad norm: 9.83891764260465\n",
      "Epoch 9472, Loss: 208.5238461479645, Neurons: 201, Grad norm: 8.222783657346815\n",
      "Epoch 9472, Loss: 208.5238461479645, Neurons: 201, Grad norm: 8.222783657346815\n",
      "Epoch 9473, Loss: 208.52326090868374, Neurons: 201, Grad norm: 6.291140297866192\n",
      "Epoch 9473, Loss: 208.52326090868374, Neurons: 201, Grad norm: 6.291140297866192\n",
      "Epoch 9474, Loss: 208.5228791423265, Neurons: 201, Grad norm: 4.188013381311366\n",
      "Epoch 9474, Loss: 208.5228791423265, Neurons: 201, Grad norm: 4.188013381311366\n",
      "Epoch 9475, Loss: 208.52259757559662, Neurons: 201, Grad norm: 1.8827282204754927\n",
      "Epoch 9475, Loss: 208.52259757559662, Neurons: 201, Grad norm: 1.8827282204754927\n",
      "Epoch 9476, Loss: 208.5223349820131, Neurons: 201, Grad norm: 0.7609497399524877\n",
      "Epoch 9476, Loss: 208.5223349820131, Neurons: 201, Grad norm: 0.7609497399524877\n",
      "Epoch 9477, Loss: 208.52222183705143, Neurons: 201, Grad norm: 2.1950222321500803\n",
      "Epoch 9477, Loss: 208.52222183705143, Neurons: 201, Grad norm: 2.1950222321500803\n",
      "Epoch 9478, Loss: 208.52220989321015, Neurons: 201, Grad norm: 3.3084137031772594\n",
      "Epoch 9478, Loss: 208.52220989321015, Neurons: 201, Grad norm: 3.3084137031772594\n",
      "Epoch 9479, Loss: 208.52221276061815, Neurons: 201, Grad norm: 4.613813270422611\n",
      "Epoch 9479, Loss: 208.52221276061815, Neurons: 201, Grad norm: 4.613813270422611\n",
      "Epoch 9480, Loss: 208.5222605251271, Neurons: 201, Grad norm: 5.772995755040836\n",
      "Epoch 9480, Loss: 208.5222605251271, Neurons: 201, Grad norm: 5.772995755040836\n",
      "Epoch 9481, Loss: 208.52235815252206, Neurons: 201, Grad norm: 6.315150437171933\n",
      "Epoch 9481, Loss: 208.52235815252206, Neurons: 201, Grad norm: 6.315150437171933\n",
      "Epoch 9482, Loss: 208.52239469572584, Neurons: 201, Grad norm: 6.819750041648723\n",
      "Epoch 9482, Loss: 208.52239469572584, Neurons: 201, Grad norm: 6.819750041648723\n",
      "Epoch 9483, Loss: 208.52242164801697, Neurons: 201, Grad norm: 6.874956576675418\n",
      "Epoch 9483, Loss: 208.52242164801697, Neurons: 201, Grad norm: 6.874956576675418\n",
      "Epoch 9484, Loss: 208.5225786847665, Neurons: 201, Grad norm: 6.734597423808054\n",
      "Epoch 9484, Loss: 208.5225786847665, Neurons: 201, Grad norm: 6.734597423808054\n",
      "Epoch 9485, Loss: 208.52248697837123, Neurons: 201, Grad norm: 6.861240186100017\n",
      "Epoch 9485, Loss: 208.52248697837123, Neurons: 201, Grad norm: 6.861240186100017\n",
      "Epoch 9486, Loss: 208.52220218085708, Neurons: 201, Grad norm: 6.840201796104916\n",
      "Epoch 9486, Loss: 208.52220218085708, Neurons: 201, Grad norm: 6.840201796104916\n",
      "Epoch 9487, Loss: 208.5221459698558, Neurons: 201, Grad norm: 6.791599583630373\n",
      "Epoch 9487, Loss: 208.5221459698558, Neurons: 201, Grad norm: 6.791599583630373\n",
      "Epoch 9488, Loss: 208.5219311091825, Neurons: 201, Grad norm: 6.301754193730425\n",
      "Epoch 9488, Loss: 208.5219311091825, Neurons: 201, Grad norm: 6.301754193730425\n",
      "Epoch 9489, Loss: 208.5217311026851, Neurons: 201, Grad norm: 5.3807972980970975\n",
      "Epoch 9489, Loss: 208.5217311026851, Neurons: 201, Grad norm: 5.3807972980970975\n",
      "Epoch 9490, Loss: 208.5216399524083, Neurons: 201, Grad norm: 4.23879279482519\n",
      "Epoch 9490, Loss: 208.5216399524083, Neurons: 201, Grad norm: 4.23879279482519\n",
      "Epoch 9491, Loss: 208.5214532297779, Neurons: 201, Grad norm: 2.589761542063615\n",
      "Epoch 9491, Loss: 208.5214532297779, Neurons: 201, Grad norm: 2.589761542063615\n",
      "Epoch 9492, Loss: 208.52122263362153, Neurons: 201, Grad norm: 1.3353782814194894\n",
      "Epoch 9492, Loss: 208.52122263362153, Neurons: 201, Grad norm: 1.3353782814194894\n",
      "Epoch 9493, Loss: 208.5211873011349, Neurons: 201, Grad norm: 1.1239795039194815\n",
      "Epoch 9493, Loss: 208.5211873011349, Neurons: 201, Grad norm: 1.1239795039194815\n",
      "Epoch 9494, Loss: 208.52106735628746, Neurons: 201, Grad norm: 1.47201294108582\n",
      "Epoch 9494, Loss: 208.52106735628746, Neurons: 201, Grad norm: 1.47201294108582\n",
      "Epoch 9495, Loss: 208.52095794800422, Neurons: 201, Grad norm: 2.161560742910875\n",
      "Epoch 9495, Loss: 208.52095794800422, Neurons: 201, Grad norm: 2.161560742910875\n",
      "Epoch 9496, Loss: 208.52097498434722, Neurons: 201, Grad norm: 2.98212188315677\n",
      "Epoch 9496, Loss: 208.52097498434722, Neurons: 201, Grad norm: 2.98212188315677\n",
      "Epoch 9497, Loss: 208.520921940968, Neurons: 201, Grad norm: 3.267515316434927\n",
      "Epoch 9497, Loss: 208.520921940968, Neurons: 201, Grad norm: 3.267515316434927\n",
      "Epoch 9498, Loss: 208.5207893151396, Neurons: 201, Grad norm: 3.809140636527417\n",
      "Epoch 9498, Loss: 208.5207893151396, Neurons: 201, Grad norm: 3.809140636527417\n",
      "Epoch 9499, Loss: 208.52082558283058, Neurons: 201, Grad norm: 4.6300005867365135\n",
      "Epoch 9499, Loss: 208.52082558283058, Neurons: 201, Grad norm: 4.6300005867365135\n",
      "Epoch 9500, Loss: 208.52078643537368, Neurons: 201, Grad norm: 5.382951391989614\n",
      "Epoch 9500, Loss: 208.52078643537368, Neurons: 201, Grad norm: 5.382951391989614\n",
      "Epoch 9501, Loss: 208.52080310214012, Neurons: 201, Grad norm: 6.483033122507759\n",
      "Epoch 9501, Loss: 208.52080310214012, Neurons: 201, Grad norm: 6.483033122507759\n",
      "Epoch 9502, Loss: 208.5209736169517, Neurons: 201, Grad norm: 7.902506681936195\n",
      "Epoch 9502, Loss: 208.5209736169517, Neurons: 201, Grad norm: 7.902506681936195\n",
      "Epoch 9503, Loss: 208.52110724446214, Neurons: 201, Grad norm: 9.160358943987625\n",
      "Epoch 9503, Loss: 208.52110724446214, Neurons: 201, Grad norm: 9.160358943987625\n",
      "Epoch 9504, Loss: 208.5213622234472, Neurons: 201, Grad norm: 10.49380473393288\n",
      "Epoch 9504, Loss: 208.5213622234472, Neurons: 201, Grad norm: 10.49380473393288\n",
      "Epoch 9505, Loss: 208.5216528888803, Neurons: 201, Grad norm: 11.791661448604456\n",
      "Epoch 9505, Loss: 208.5216528888803, Neurons: 201, Grad norm: 11.791661448604456\n",
      "Epoch 9506, Loss: 208.52187881194428, Neurons: 201, Grad norm: 12.975873285101054\n",
      "Epoch 9506, Loss: 208.52187881194428, Neurons: 201, Grad norm: 12.975873285101054\n",
      "Epoch 9507, Loss: 208.52206369644688, Neurons: 201, Grad norm: 13.600071669668889\n",
      "Epoch 9507, Loss: 208.52206369644688, Neurons: 201, Grad norm: 13.600071669668889\n",
      "Epoch 9508, Loss: 208.52217045887298, Neurons: 201, Grad norm: 13.922725559080368\n",
      "Epoch 9508, Loss: 208.52217045887298, Neurons: 201, Grad norm: 13.922725559080368\n",
      "Epoch 9509, Loss: 208.52212616055084, Neurons: 201, Grad norm: 13.6303747130522\n",
      "Epoch 9509, Loss: 208.52212616055084, Neurons: 201, Grad norm: 13.6303747130522\n",
      "Epoch 9510, Loss: 208.5220978562544, Neurons: 201, Grad norm: 12.972812120725564\n",
      "Epoch 9510, Loss: 208.5220978562544, Neurons: 201, Grad norm: 12.972812120725564\n",
      "Epoch 9511, Loss: 208.52181720483009, Neurons: 201, Grad norm: 11.49345882359906\n",
      "Epoch 9511, Loss: 208.52181720483009, Neurons: 201, Grad norm: 11.49345882359906\n",
      "Epoch 9512, Loss: 208.52126895660828, Neurons: 201, Grad norm: 9.532291194234672\n",
      "Epoch 9512, Loss: 208.52126895660828, Neurons: 201, Grad norm: 9.532291194234672\n",
      "Epoch 9513, Loss: 208.52084729958239, Neurons: 201, Grad norm: 7.338963809112557\n",
      "Epoch 9513, Loss: 208.52084729958239, Neurons: 201, Grad norm: 7.338963809112557\n",
      "Epoch 9514, Loss: 208.52032279772195, Neurons: 201, Grad norm: 4.301103043366754\n",
      "Epoch 9514, Loss: 208.52032279772195, Neurons: 201, Grad norm: 4.301103043366754\n",
      "Epoch 9515, Loss: 208.5197623500096, Neurons: 201, Grad norm: 1.7081642390036764\n",
      "Epoch 9515, Loss: 208.5197623500096, Neurons: 201, Grad norm: 1.7081642390036764\n",
      "Epoch 9516, Loss: 208.51952332361253, Neurons: 201, Grad norm: 1.395749196878826\n",
      "Epoch 9516, Loss: 208.51952332361253, Neurons: 201, Grad norm: 1.395749196878826\n",
      "Epoch 9517, Loss: 208.5194513414055, Neurons: 201, Grad norm: 3.4782436294720065\n",
      "Epoch 9517, Loss: 208.5194513414055, Neurons: 201, Grad norm: 3.4782436294720065\n",
      "Epoch 9518, Loss: 208.51945473357796, Neurons: 201, Grad norm: 5.232901182074615\n",
      "Epoch 9518, Loss: 208.51945473357796, Neurons: 201, Grad norm: 5.232901182074615\n",
      "Epoch 9519, Loss: 208.5195984658251, Neurons: 201, Grad norm: 7.102286602217449\n",
      "Epoch 9519, Loss: 208.5195984658251, Neurons: 201, Grad norm: 7.102286602217449\n",
      "Epoch 9520, Loss: 208.51973711754735, Neurons: 201, Grad norm: 8.303496063918743\n",
      "Epoch 9520, Loss: 208.51973711754735, Neurons: 201, Grad norm: 8.303496063918743\n",
      "Epoch 9521, Loss: 208.51991878614652, Neurons: 201, Grad norm: 9.40992517539179\n",
      "Epoch 9521, Loss: 208.51991878614652, Neurons: 201, Grad norm: 9.40992517539179\n",
      "Epoch 9522, Loss: 208.52007815473183, Neurons: 201, Grad norm: 10.107139512154196\n",
      "Epoch 9522, Loss: 208.52007815473183, Neurons: 201, Grad norm: 10.107139512154196\n",
      "Epoch 9523, Loss: 208.52018562580582, Neurons: 201, Grad norm: 10.569142128161673\n",
      "Epoch 9523, Loss: 208.52018562580582, Neurons: 201, Grad norm: 10.569142128161673\n",
      "Epoch 9524, Loss: 208.52033521611435, Neurons: 201, Grad norm: 10.604945297485278\n",
      "Epoch 9524, Loss: 208.52033521611435, Neurons: 201, Grad norm: 10.604945297485278\n",
      "Epoch 9525, Loss: 208.52037453942557, Neurons: 201, Grad norm: 10.430083256205084\n",
      "Epoch 9525, Loss: 208.52037453942557, Neurons: 201, Grad norm: 10.430083256205084\n",
      "Epoch 9526, Loss: 208.52033777448386, Neurons: 201, Grad norm: 10.122957728862273\n",
      "Epoch 9526, Loss: 208.52033777448386, Neurons: 201, Grad norm: 10.122957728862273\n",
      "Epoch 9527, Loss: 208.5202845465429, Neurons: 201, Grad norm: 9.337632416891683\n",
      "Epoch 9527, Loss: 208.5202845465429, Neurons: 201, Grad norm: 9.337632416891683\n",
      "Epoch 9528, Loss: 208.52006340485664, Neurons: 201, Grad norm: 8.424521482999104\n",
      "Epoch 9528, Loss: 208.52006340485664, Neurons: 201, Grad norm: 8.424521482999104\n",
      "Epoch 9529, Loss: 208.5197005959366, Neurons: 201, Grad norm: 7.2228798271817025\n",
      "Epoch 9529, Loss: 208.5197005959366, Neurons: 201, Grad norm: 7.2228798271817025\n",
      "Epoch 9530, Loss: 208.5192485353367, Neurons: 201, Grad norm: 5.868573400275473\n",
      "Epoch 9530, Loss: 208.5192485353367, Neurons: 201, Grad norm: 5.868573400275473\n",
      "Epoch 9531, Loss: 208.51892444932255, Neurons: 201, Grad norm: 4.769473465329083\n",
      "Epoch 9531, Loss: 208.51892444932255, Neurons: 201, Grad norm: 4.769473465329083\n",
      "Epoch 9532, Loss: 208.51861049412713, Neurons: 201, Grad norm: 3.905656095832781\n",
      "Epoch 9532, Loss: 208.51861049412713, Neurons: 201, Grad norm: 3.905656095832781\n",
      "Epoch 9533, Loss: 208.5184005491908, Neurons: 201, Grad norm: 2.8436393464996286\n",
      "Epoch 9533, Loss: 208.5184005491908, Neurons: 201, Grad norm: 2.8436393464996286\n",
      "Epoch 9534, Loss: 208.51827953310868, Neurons: 201, Grad norm: 1.7584367062546604\n",
      "Epoch 9534, Loss: 208.51827953310868, Neurons: 201, Grad norm: 1.7584367062546604\n",
      "Epoch 9535, Loss: 208.51814172195122, Neurons: 201, Grad norm: 0.9585692395521451\n",
      "Epoch 9535, Loss: 208.51814172195122, Neurons: 201, Grad norm: 0.9585692395521451\n",
      "Epoch 9536, Loss: 208.51807014873094, Neurons: 201, Grad norm: 0.7479201255755336\n",
      "Epoch 9536, Loss: 208.51807014873094, Neurons: 201, Grad norm: 0.7479201255755336\n",
      "Epoch 9537, Loss: 208.51801193907482, Neurons: 201, Grad norm: 0.9779108147777046\n",
      "Epoch 9537, Loss: 208.51801193907482, Neurons: 201, Grad norm: 0.9779108147777046\n",
      "Epoch 9538, Loss: 208.51791105786012, Neurons: 201, Grad norm: 1.8716173118484376\n",
      "Epoch 9538, Loss: 208.51791105786012, Neurons: 201, Grad norm: 1.8716173118484376\n",
      "Epoch 9539, Loss: 208.51788407614671, Neurons: 201, Grad norm: 2.454876250246878\n",
      "Epoch 9539, Loss: 208.51788407614671, Neurons: 201, Grad norm: 2.454876250246878\n",
      "Epoch 9540, Loss: 208.517822448868, Neurons: 201, Grad norm: 2.8539943407239003\n",
      "Epoch 9540, Loss: 208.517822448868, Neurons: 201, Grad norm: 2.8539943407239003\n",
      "Epoch 9541, Loss: 208.51778127257836, Neurons: 201, Grad norm: 3.5088490536156036\n",
      "Epoch 9541, Loss: 208.51778127257836, Neurons: 201, Grad norm: 3.5088490536156036\n",
      "Epoch 9542, Loss: 208.51771638616677, Neurons: 201, Grad norm: 3.6328330493726506\n",
      "Epoch 9542, Loss: 208.51771638616677, Neurons: 201, Grad norm: 3.6328330493726506\n",
      "Epoch 9543, Loss: 208.51765377394005, Neurons: 201, Grad norm: 3.7987150226818454\n",
      "Epoch 9543, Loss: 208.51765377394005, Neurons: 201, Grad norm: 3.7987150226818454\n",
      "Epoch 9544, Loss: 208.51756020531204, Neurons: 201, Grad norm: 4.167804847908823\n",
      "Epoch 9544, Loss: 208.51756020531204, Neurons: 201, Grad norm: 4.167804847908823\n",
      "Epoch 9545, Loss: 208.51751909372453, Neurons: 201, Grad norm: 4.45145924675219\n",
      "Epoch 9545, Loss: 208.51751909372453, Neurons: 201, Grad norm: 4.45145924675219\n",
      "Epoch 9546, Loss: 208.51746184568992, Neurons: 201, Grad norm: 4.615205275459701\n",
      "Epoch 9546, Loss: 208.51746184568992, Neurons: 201, Grad norm: 4.615205275459701\n",
      "Epoch 9547, Loss: 208.51736473093032, Neurons: 201, Grad norm: 4.444392353623007\n",
      "Epoch 9547, Loss: 208.51736473093032, Neurons: 201, Grad norm: 4.444392353623007\n",
      "Epoch 9548, Loss: 208.51730016561737, Neurons: 201, Grad norm: 4.658169715357646\n",
      "Epoch 9548, Loss: 208.51730016561737, Neurons: 201, Grad norm: 4.658169715357646\n",
      "Epoch 9549, Loss: 208.51726779451764, Neurons: 201, Grad norm: 4.707973489165044\n",
      "Epoch 9549, Loss: 208.51726779451764, Neurons: 201, Grad norm: 4.707973489165044\n",
      "Epoch 9550, Loss: 208.51722554470336, Neurons: 201, Grad norm: 5.053395831286245\n",
      "Epoch 9550, Loss: 208.51722554470336, Neurons: 201, Grad norm: 5.053395831286245\n",
      "Epoch 9551, Loss: 208.51724720462272, Neurons: 201, Grad norm: 5.605118443380035\n",
      "Epoch 9551, Loss: 208.51724720462272, Neurons: 201, Grad norm: 5.605118443380035\n",
      "Epoch 9552, Loss: 208.51730960846643, Neurons: 201, Grad norm: 6.309171780880765\n",
      "Epoch 9552, Loss: 208.51730960846643, Neurons: 201, Grad norm: 6.309171780880765\n",
      "Epoch 9553, Loss: 208.51751508805015, Neurons: 201, Grad norm: 7.0118840046748225\n",
      "Epoch 9553, Loss: 208.51751508805015, Neurons: 201, Grad norm: 7.0118840046748225\n",
      "Epoch 9554, Loss: 208.5176457521824, Neurons: 201, Grad norm: 8.108622861854366\n",
      "Epoch 9554, Loss: 208.5176457521824, Neurons: 201, Grad norm: 8.108622861854366\n",
      "Epoch 9555, Loss: 208.51768684492646, Neurons: 201, Grad norm: 9.495053070293372\n",
      "Epoch 9555, Loss: 208.51768684492646, Neurons: 201, Grad norm: 9.495053070293372\n",
      "Epoch 9556, Loss: 208.51782764726607, Neurons: 201, Grad norm: 10.803822298698048\n",
      "Epoch 9556, Loss: 208.51782764726607, Neurons: 201, Grad norm: 10.803822298698048\n",
      "Epoch 9557, Loss: 208.51790550759628, Neurons: 201, Grad norm: 12.116827569878645\n",
      "Epoch 9557, Loss: 208.51790550759628, Neurons: 201, Grad norm: 12.116827569878645\n",
      "Epoch 9558, Loss: 208.5180397023127, Neurons: 201, Grad norm: 13.159577763629748\n",
      "Epoch 9558, Loss: 208.5180397023127, Neurons: 201, Grad norm: 13.159577763629748\n",
      "Epoch 9559, Loss: 208.5180879129786, Neurons: 201, Grad norm: 13.87968685629619\n",
      "Epoch 9559, Loss: 208.5180879129786, Neurons: 201, Grad norm: 13.87968685629619\n",
      "Epoch 9560, Loss: 208.51815982047322, Neurons: 201, Grad norm: 13.981405803710327\n",
      "Epoch 9560, Loss: 208.51815982047322, Neurons: 201, Grad norm: 13.981405803710327\n",
      "Epoch 9561, Loss: 208.51817850109146, Neurons: 201, Grad norm: 13.287225456705704\n",
      "Epoch 9561, Loss: 208.51817850109146, Neurons: 201, Grad norm: 13.287225456705704\n",
      "Epoch 9562, Loss: 208.51788552529436, Neurons: 201, Grad norm: 12.244694485818991\n",
      "Epoch 9562, Loss: 208.51788552529436, Neurons: 201, Grad norm: 12.244694485818991\n",
      "Epoch 9563, Loss: 208.51751010413446, Neurons: 201, Grad norm: 10.645935287686894\n",
      "Epoch 9563, Loss: 208.51751010413446, Neurons: 201, Grad norm: 10.645935287686894\n",
      "Epoch 9564, Loss: 208.51709158761673, Neurons: 201, Grad norm: 8.309371491970962\n",
      "Epoch 9564, Loss: 208.51709158761673, Neurons: 201, Grad norm: 8.309371491970962\n",
      "Epoch 9565, Loss: 208.51650127685136, Neurons: 201, Grad norm: 6.400219912156202\n",
      "Epoch 9565, Loss: 208.51650127685136, Neurons: 201, Grad norm: 6.400219912156202\n",
      "Epoch 9566, Loss: 208.51584960507037, Neurons: 201, Grad norm: 3.9052616175558703\n",
      "Epoch 9566, Loss: 208.51584960507037, Neurons: 201, Grad norm: 3.9052616175558703\n",
      "Epoch 9567, Loss: 208.5153893720802, Neurons: 201, Grad norm: 1.3400010601740184\n",
      "Epoch 9567, Loss: 208.5153893720802, Neurons: 201, Grad norm: 1.3400010601740184\n",
      "Epoch 9568, Loss: 208.51516484184498, Neurons: 201, Grad norm: 1.8688271688599212\n",
      "Epoch 9568, Loss: 208.51516484184498, Neurons: 201, Grad norm: 1.8688271688599212\n",
      "Epoch 9569, Loss: 208.51509676456445, Neurons: 201, Grad norm: 4.160360067431366\n",
      "Epoch 9569, Loss: 208.51509676456445, Neurons: 201, Grad norm: 4.160360067431366\n",
      "Epoch 9570, Loss: 208.51514030277932, Neurons: 201, Grad norm: 6.604092878609833\n",
      "Epoch 9570, Loss: 208.51514030277932, Neurons: 201, Grad norm: 6.604092878609833\n",
      "Epoch 9571, Loss: 208.51546331974387, Neurons: 201, Grad norm: 9.076617907176082\n",
      "Epoch 9571, Loss: 208.51546331974387, Neurons: 201, Grad norm: 9.076617907176082\n",
      "Epoch 9572, Loss: 208.516059327911, Neurons: 201, Grad norm: 10.931162946644045\n",
      "Epoch 9572, Loss: 208.516059327911, Neurons: 201, Grad norm: 10.931162946644045\n",
      "Epoch 9573, Loss: 208.5164609824491, Neurons: 201, Grad norm: 12.901301171968912\n",
      "Epoch 9573, Loss: 208.5164609824491, Neurons: 201, Grad norm: 12.901301171968912\n",
      "Epoch 9574, Loss: 208.51681566746228, Neurons: 201, Grad norm: 14.064225529907846\n",
      "Epoch 9574, Loss: 208.51681566746228, Neurons: 201, Grad norm: 14.064225529907846\n",
      "Epoch 9575, Loss: 208.51714612940748, Neurons: 201, Grad norm: 14.736788405140913\n",
      "Epoch 9575, Loss: 208.51714612940748, Neurons: 201, Grad norm: 14.736788405140913\n",
      "Epoch 9576, Loss: 208.51704229871785, Neurons: 201, Grad norm: 14.13518291357378\n",
      "Epoch 9576, Loss: 208.51704229871785, Neurons: 201, Grad norm: 14.13518291357378\n",
      "Epoch 9577, Loss: 208.51671412975045, Neurons: 201, Grad norm: 12.939438895529122\n",
      "Epoch 9577, Loss: 208.51671412975045, Neurons: 201, Grad norm: 12.939438895529122\n",
      "Epoch 9578, Loss: 208.51638997677338, Neurons: 201, Grad norm: 11.008865933509192\n",
      "Epoch 9578, Loss: 208.51638997677338, Neurons: 201, Grad norm: 11.008865933509192\n",
      "Epoch 9579, Loss: 208.51582077213845, Neurons: 201, Grad norm: 8.408195283491038\n",
      "Epoch 9579, Loss: 208.51582077213845, Neurons: 201, Grad norm: 8.408195283491038\n",
      "Epoch 9580, Loss: 208.5151589973045, Neurons: 201, Grad norm: 6.034032899867115\n",
      "Epoch 9580, Loss: 208.5151589973045, Neurons: 201, Grad norm: 6.034032899867115\n",
      "Epoch 9581, Loss: 208.51472645488565, Neurons: 201, Grad norm: 3.2986391368402423\n",
      "Epoch 9581, Loss: 208.51472645488565, Neurons: 201, Grad norm: 3.2986391368402423\n",
      "Epoch 9582, Loss: 208.5143563827948, Neurons: 201, Grad norm: 1.0439662374892182\n",
      "Epoch 9582, Loss: 208.5143563827948, Neurons: 201, Grad norm: 1.0439662374892182\n",
      "Epoch 9583, Loss: 208.51408660631944, Neurons: 201, Grad norm: 1.9534475217006868\n",
      "Epoch 9583, Loss: 208.51408660631944, Neurons: 201, Grad norm: 1.9534475217006868\n",
      "Epoch 9584, Loss: 208.51408362584024, Neurons: 201, Grad norm: 4.435232831414089\n",
      "Epoch 9584, Loss: 208.51408362584024, Neurons: 201, Grad norm: 4.435232831414089\n",
      "Epoch 9585, Loss: 208.51418087667574, Neurons: 201, Grad norm: 6.502533069448129\n",
      "Epoch 9585, Loss: 208.51418087667574, Neurons: 201, Grad norm: 6.502533069448129\n",
      "Epoch 9586, Loss: 208.51447482233644, Neurons: 201, Grad norm: 8.89328911988527\n",
      "Epoch 9586, Loss: 208.51447482233644, Neurons: 201, Grad norm: 8.89328911988527\n",
      "Epoch 9587, Loss: 208.5147542016, Neurons: 201, Grad norm: 10.737985967201494\n",
      "Epoch 9587, Loss: 208.5147542016, Neurons: 201, Grad norm: 10.737985967201494\n",
      "Epoch 9588, Loss: 208.51489948562633, Neurons: 201, Grad norm: 12.454106447390144\n",
      "Epoch 9588, Loss: 208.51489948562633, Neurons: 201, Grad norm: 12.454106447390144\n",
      "Epoch 9589, Loss: 208.5152579918599, Neurons: 201, Grad norm: 13.083891983267819\n",
      "Epoch 9589, Loss: 208.5152579918599, Neurons: 201, Grad norm: 13.083891983267819\n",
      "Epoch 9590, Loss: 208.51544983940965, Neurons: 201, Grad norm: 13.004254121578498\n",
      "Epoch 9590, Loss: 208.51544983940965, Neurons: 201, Grad norm: 13.004254121578498\n",
      "Epoch 9591, Loss: 208.51526848159213, Neurons: 201, Grad norm: 11.97833364373686\n",
      "Epoch 9591, Loss: 208.51526848159213, Neurons: 201, Grad norm: 11.97833364373686\n",
      "Epoch 9592, Loss: 208.51486103624984, Neurons: 201, Grad norm: 10.15568077061865\n",
      "Epoch 9592, Loss: 208.51486103624984, Neurons: 201, Grad norm: 10.15568077061865\n",
      "Epoch 9593, Loss: 208.51450888745504, Neurons: 201, Grad norm: 8.180976524727962\n",
      "Epoch 9593, Loss: 208.51450888745504, Neurons: 201, Grad norm: 8.180976524727962\n",
      "Epoch 9594, Loss: 208.51411141277154, Neurons: 201, Grad norm: 5.745598365153565\n",
      "Epoch 9594, Loss: 208.51411141277154, Neurons: 201, Grad norm: 5.745598365153565\n",
      "Epoch 9595, Loss: 208.51356998655064, Neurons: 201, Grad norm: 3.381727143548161\n",
      "Epoch 9595, Loss: 208.51356998655064, Neurons: 201, Grad norm: 3.381727143548161\n",
      "Epoch 9596, Loss: 208.51321604996707, Neurons: 201, Grad norm: 0.9078465786062991\n",
      "Epoch 9596, Loss: 208.51321604996707, Neurons: 201, Grad norm: 0.9078465786062991\n",
      "Epoch 9597, Loss: 208.51305207347662, Neurons: 201, Grad norm: 1.8103293289945253\n",
      "Epoch 9597, Loss: 208.51305207347662, Neurons: 201, Grad norm: 1.8103293289945253\n",
      "Epoch 9598, Loss: 208.51301526421258, Neurons: 201, Grad norm: 3.6074971849947604\n",
      "Epoch 9598, Loss: 208.51301526421258, Neurons: 201, Grad norm: 3.6074971849947604\n",
      "Epoch 9599, Loss: 208.5129842888376, Neurons: 201, Grad norm: 5.094751240550418\n",
      "Epoch 9599, Loss: 208.5129842888376, Neurons: 201, Grad norm: 5.094751240550418\n",
      "Epoch 9600, Loss: 208.51308447454187, Neurons: 201, Grad norm: 6.336901866497979\n",
      "Epoch 9600, Loss: 208.51308447454187, Neurons: 201, Grad norm: 6.336901866497979\n",
      "Epoch 9601, Loss: 208.513224638734, Neurons: 201, Grad norm: 7.387325812531421\n",
      "Epoch 9601, Loss: 208.513224638734, Neurons: 201, Grad norm: 7.387325812531421\n",
      "Epoch 9602, Loss: 208.51331512777725, Neurons: 201, Grad norm: 7.906560789304604\n",
      "Epoch 9602, Loss: 208.51331512777725, Neurons: 201, Grad norm: 7.906560789304604\n",
      "Epoch 9603, Loss: 208.51338128033876, Neurons: 201, Grad norm: 8.348789283135329\n",
      "Epoch 9603, Loss: 208.51338128033876, Neurons: 201, Grad norm: 8.348789283135329\n",
      "Epoch 9604, Loss: 208.51335120738824, Neurons: 201, Grad norm: 8.346647581985938\n",
      "Epoch 9604, Loss: 208.51335120738824, Neurons: 201, Grad norm: 8.346647581985938\n",
      "Epoch 9605, Loss: 208.51340301770634, Neurons: 201, Grad norm: 8.837140482590883\n",
      "Epoch 9605, Loss: 208.51340301770634, Neurons: 201, Grad norm: 8.837140482590883\n",
      "Epoch 9606, Loss: 208.51342477674865, Neurons: 201, Grad norm: 8.772401811784961\n",
      "Epoch 9606, Loss: 208.51342477674865, Neurons: 201, Grad norm: 8.772401811784961\n",
      "Epoch 9607, Loss: 208.5132826567232, Neurons: 201, Grad norm: 8.495358110674953\n",
      "Epoch 9607, Loss: 208.5132826567232, Neurons: 201, Grad norm: 8.495358110674953\n",
      "Epoch 9608, Loss: 208.51327822762346, Neurons: 201, Grad norm: 8.609967331938991\n",
      "Epoch 9608, Loss: 208.51327822762346, Neurons: 201, Grad norm: 8.609967331938991\n",
      "Epoch 9609, Loss: 208.5132152036031, Neurons: 201, Grad norm: 8.37018548174863\n",
      "Epoch 9609, Loss: 208.5132152036031, Neurons: 201, Grad norm: 8.37018548174863\n",
      "Epoch 9610, Loss: 208.5131311051893, Neurons: 201, Grad norm: 7.857368830359515\n",
      "Epoch 9610, Loss: 208.5131311051893, Neurons: 201, Grad norm: 7.857368830359515\n",
      "Epoch 9611, Loss: 208.5128270443269, Neurons: 201, Grad norm: 6.930896542836322\n",
      "Epoch 9611, Loss: 208.5128270443269, Neurons: 201, Grad norm: 6.930896542836322\n",
      "Epoch 9612, Loss: 208.5125578116423, Neurons: 201, Grad norm: 6.21026840048562\n",
      "Epoch 9612, Loss: 208.5125578116423, Neurons: 201, Grad norm: 6.21026840048562\n",
      "Epoch 9613, Loss: 208.51238668375015, Neurons: 201, Grad norm: 5.469111856085208\n",
      "Epoch 9613, Loss: 208.51238668375015, Neurons: 201, Grad norm: 5.469111856085208\n",
      "Epoch 9614, Loss: 208.51215587294823, Neurons: 201, Grad norm: 4.363102801707252\n",
      "Epoch 9614, Loss: 208.51215587294823, Neurons: 201, Grad norm: 4.363102801707252\n",
      "Epoch 9615, Loss: 208.51195021581196, Neurons: 201, Grad norm: 3.640380007247557\n",
      "Epoch 9615, Loss: 208.51195021581196, Neurons: 201, Grad norm: 3.640380007247557\n",
      "Epoch 9616, Loss: 208.51180910685218, Neurons: 201, Grad norm: 2.955622537662536\n",
      "Epoch 9616, Loss: 208.51180910685218, Neurons: 201, Grad norm: 2.955622537662536\n",
      "Epoch 9617, Loss: 208.5117205108184, Neurons: 201, Grad norm: 2.2936088067603655\n",
      "Epoch 9617, Loss: 208.5117205108184, Neurons: 201, Grad norm: 2.2936088067603655\n",
      "Epoch 9618, Loss: 208.5115884225039, Neurons: 201, Grad norm: 2.072896148720389\n",
      "Epoch 9618, Loss: 208.5115884225039, Neurons: 201, Grad norm: 2.072896148720389\n",
      "Epoch 9619, Loss: 208.511444965248, Neurons: 201, Grad norm: 1.922796402930786\n",
      "Epoch 9619, Loss: 208.511444965248, Neurons: 201, Grad norm: 1.922796402930786\n",
      "Epoch 9620, Loss: 208.51138094471642, Neurons: 201, Grad norm: 1.9583786509254142\n",
      "Epoch 9620, Loss: 208.51138094471642, Neurons: 201, Grad norm: 1.9583786509254142\n",
      "Epoch 9621, Loss: 208.51128525724198, Neurons: 201, Grad norm: 1.9786436076317475\n",
      "Epoch 9621, Loss: 208.51128525724198, Neurons: 201, Grad norm: 1.9786436076317475\n",
      "Epoch 9622, Loss: 208.51128994329702, Neurons: 201, Grad norm: 1.7419878185192788\n",
      "Epoch 9622, Loss: 208.51128994329702, Neurons: 201, Grad norm: 1.7419878185192788\n",
      "Epoch 9623, Loss: 208.5112103263968, Neurons: 201, Grad norm: 1.7223919769604674\n",
      "Epoch 9623, Loss: 208.5112103263968, Neurons: 201, Grad norm: 1.7223919769604674\n",
      "Epoch 9624, Loss: 208.5110866837491, Neurons: 201, Grad norm: 1.853216950369356\n",
      "Epoch 9624, Loss: 208.5110866837491, Neurons: 201, Grad norm: 1.853216950369356\n",
      "Epoch 9625, Loss: 208.5110245129351, Neurons: 201, Grad norm: 1.6822938753462473\n",
      "Epoch 9625, Loss: 208.5110245129351, Neurons: 201, Grad norm: 1.6822938753462473\n",
      "Epoch 9626, Loss: 208.5109830712938, Neurons: 201, Grad norm: 2.3028662077223996\n",
      "Epoch 9626, Loss: 208.5109830712938, Neurons: 201, Grad norm: 2.3028662077223996\n",
      "Epoch 9627, Loss: 208.51095830417626, Neurons: 201, Grad norm: 2.8112398919892962\n",
      "Epoch 9627, Loss: 208.51095830417626, Neurons: 201, Grad norm: 2.8112398919892962\n",
      "Epoch 9628, Loss: 208.51089316879367, Neurons: 201, Grad norm: 3.343122969428538\n",
      "Epoch 9628, Loss: 208.51089316879367, Neurons: 201, Grad norm: 3.343122969428538\n",
      "Epoch 9629, Loss: 208.51083044073616, Neurons: 201, Grad norm: 4.443502774012466\n",
      "Epoch 9629, Loss: 208.51083044073616, Neurons: 201, Grad norm: 4.443502774012466\n",
      "Epoch 9630, Loss: 208.51094897431767, Neurons: 201, Grad norm: 5.318864563432598\n",
      "Epoch 9630, Loss: 208.51094897431767, Neurons: 201, Grad norm: 5.318864563432598\n",
      "Epoch 9631, Loss: 208.51099324365532, Neurons: 201, Grad norm: 7.367198427647922\n",
      "Epoch 9631, Loss: 208.51099324365532, Neurons: 201, Grad norm: 7.367198427647922\n",
      "Epoch 9632, Loss: 208.51107888373886, Neurons: 201, Grad norm: 8.925629898428852\n",
      "Epoch 9632, Loss: 208.51107888373886, Neurons: 201, Grad norm: 8.925629898428852\n",
      "Epoch 9633, Loss: 208.5113817238709, Neurons: 201, Grad norm: 10.645613904562797\n",
      "Epoch 9633, Loss: 208.5113817238709, Neurons: 201, Grad norm: 10.645613904562797\n",
      "Epoch 9634, Loss: 208.5116872390836, Neurons: 201, Grad norm: 12.464146058827925\n",
      "Epoch 9634, Loss: 208.5116872390836, Neurons: 201, Grad norm: 12.464146058827925\n",
      "Epoch 9635, Loss: 208.51203221106854, Neurons: 201, Grad norm: 13.671124677758991\n",
      "Epoch 9635, Loss: 208.51203221106854, Neurons: 201, Grad norm: 13.671124677758991\n",
      "Epoch 9636, Loss: 208.51247944859662, Neurons: 201, Grad norm: 14.880555753422632\n",
      "Epoch 9636, Loss: 208.51247944859662, Neurons: 201, Grad norm: 14.880555753422632\n",
      "Epoch 9637, Loss: 208.51278425730928, Neurons: 201, Grad norm: 15.634233965653204\n",
      "Epoch 9637, Loss: 208.51278425730928, Neurons: 201, Grad norm: 15.634233965653204\n",
      "Epoch 9638, Loss: 208.51299522495827, Neurons: 201, Grad norm: 15.363096596165029\n",
      "Epoch 9638, Loss: 208.51299522495827, Neurons: 201, Grad norm: 15.363096596165029\n",
      "Epoch 9639, Loss: 208.51299876873455, Neurons: 201, Grad norm: 14.475322374022687\n",
      "Epoch 9639, Loss: 208.51299876873455, Neurons: 201, Grad norm: 14.475322374022687\n",
      "Epoch 9640, Loss: 208.51248119453638, Neurons: 201, Grad norm: 13.319952319164326\n",
      "Epoch 9640, Loss: 208.51248119453638, Neurons: 201, Grad norm: 13.319952319164326\n",
      "Epoch 9641, Loss: 208.5120636690725, Neurons: 201, Grad norm: 11.355509353140224\n",
      "Epoch 9641, Loss: 208.5120636690725, Neurons: 201, Grad norm: 11.355509353140224\n",
      "Epoch 9642, Loss: 208.5115554178904, Neurons: 201, Grad norm: 9.196322615046512\n",
      "Epoch 9642, Loss: 208.5115554178904, Neurons: 201, Grad norm: 9.196322615046512\n",
      "Epoch 9643, Loss: 208.5109642863536, Neurons: 201, Grad norm: 6.590869354407339\n",
      "Epoch 9643, Loss: 208.5109642863536, Neurons: 201, Grad norm: 6.590869354407339\n",
      "Epoch 9644, Loss: 208.51046131976025, Neurons: 201, Grad norm: 4.189575018478436\n",
      "Epoch 9644, Loss: 208.51046131976025, Neurons: 201, Grad norm: 4.189575018478436\n",
      "Epoch 9645, Loss: 208.51004526515965, Neurons: 201, Grad norm: 1.8711025060170339\n",
      "Epoch 9645, Loss: 208.51004526515965, Neurons: 201, Grad norm: 1.8711025060170339\n",
      "Epoch 9646, Loss: 208.50964048738288, Neurons: 201, Grad norm: 0.8424842974391894\n",
      "Epoch 9646, Loss: 208.50964048738288, Neurons: 201, Grad norm: 0.8424842974391894\n",
      "Epoch 9647, Loss: 208.5096019453956, Neurons: 201, Grad norm: 1.4355566665115795\n",
      "Epoch 9647, Loss: 208.5096019453956, Neurons: 201, Grad norm: 1.4355566665115795\n",
      "Epoch 9648, Loss: 208.50957621021018, Neurons: 201, Grad norm: 3.0745236505761704\n",
      "Epoch 9648, Loss: 208.50957621021018, Neurons: 201, Grad norm: 3.0745236505761704\n",
      "Epoch 9649, Loss: 208.50950596677148, Neurons: 201, Grad norm: 4.319220876329927\n",
      "Epoch 9649, Loss: 208.50950596677148, Neurons: 201, Grad norm: 4.319220876329927\n",
      "Epoch 9650, Loss: 208.5095968123243, Neurons: 201, Grad norm: 5.938795736284052\n",
      "Epoch 9650, Loss: 208.5095968123243, Neurons: 201, Grad norm: 5.938795736284052\n",
      "Epoch 9651, Loss: 208.50977917848866, Neurons: 201, Grad norm: 7.5948677214360565\n",
      "Epoch 9651, Loss: 208.50977917848866, Neurons: 201, Grad norm: 7.5948677214360565\n",
      "Epoch 9652, Loss: 208.50998050422868, Neurons: 201, Grad norm: 9.047957437039061\n",
      "Epoch 9652, Loss: 208.50998050422868, Neurons: 201, Grad norm: 9.047957437039061\n",
      "Epoch 9653, Loss: 208.5101444203712, Neurons: 201, Grad norm: 9.802484565372525\n",
      "Epoch 9653, Loss: 208.5101444203712, Neurons: 201, Grad norm: 9.802484565372525\n",
      "Epoch 9654, Loss: 208.5102627366248, Neurons: 201, Grad norm: 10.419667940556597\n",
      "Epoch 9654, Loss: 208.5102627366248, Neurons: 201, Grad norm: 10.419667940556597\n",
      "Epoch 9655, Loss: 208.51032766969735, Neurons: 201, Grad norm: 10.616422313748723\n",
      "Epoch 9655, Loss: 208.51032766969735, Neurons: 201, Grad norm: 10.616422313748723\n",
      "Epoch 9656, Loss: 208.51019787989637, Neurons: 201, Grad norm: 10.361639006996548\n",
      "Epoch 9656, Loss: 208.51019787989637, Neurons: 201, Grad norm: 10.361639006996548\n",
      "Epoch 9657, Loss: 208.5100173959822, Neurons: 201, Grad norm: 9.648593762461172\n",
      "Epoch 9657, Loss: 208.5100173959822, Neurons: 201, Grad norm: 9.648593762461172\n",
      "Epoch 9658, Loss: 208.509952477699, Neurons: 201, Grad norm: 8.704067644752918\n",
      "Epoch 9658, Loss: 208.509952477699, Neurons: 201, Grad norm: 8.704067644752918\n",
      "Epoch 9659, Loss: 208.50980438336083, Neurons: 201, Grad norm: 7.678550150585248\n",
      "Epoch 9659, Loss: 208.50980438336083, Neurons: 201, Grad norm: 7.678550150585248\n",
      "Epoch 9660, Loss: 208.50940940875603, Neurons: 201, Grad norm: 6.13075632634876\n",
      "Epoch 9660, Loss: 208.50940940875603, Neurons: 201, Grad norm: 6.13075632634876\n",
      "Epoch 9661, Loss: 208.50902375188858, Neurons: 201, Grad norm: 4.84692509193535\n",
      "Epoch 9661, Loss: 208.50902375188858, Neurons: 201, Grad norm: 4.84692509193535\n",
      "Epoch 9662, Loss: 208.5087517790665, Neurons: 201, Grad norm: 3.4781393738906017\n",
      "Epoch 9662, Loss: 208.5087517790665, Neurons: 201, Grad norm: 3.4781393738906017\n",
      "Epoch 9663, Loss: 208.50855814647826, Neurons: 201, Grad norm: 2.415435529971479\n",
      "Epoch 9663, Loss: 208.50855814647826, Neurons: 201, Grad norm: 2.415435529971479\n",
      "Epoch 9664, Loss: 208.50838685541214, Neurons: 201, Grad norm: 1.3951525876748512\n",
      "Epoch 9664, Loss: 208.50838685541214, Neurons: 201, Grad norm: 1.3951525876748512\n",
      "Epoch 9665, Loss: 208.50823626467857, Neurons: 201, Grad norm: 0.8703307060318317\n",
      "Epoch 9665, Loss: 208.50823626467857, Neurons: 201, Grad norm: 0.8703307060318317\n",
      "Epoch 9666, Loss: 208.50820915879532, Neurons: 201, Grad norm: 0.5913737760375796\n",
      "Epoch 9666, Loss: 208.50820915879532, Neurons: 201, Grad norm: 0.5913737760375796\n",
      "Epoch 9667, Loss: 208.5081025005746, Neurons: 201, Grad norm: 0.9029121904048606\n",
      "Epoch 9667, Loss: 208.5081025005746, Neurons: 201, Grad norm: 0.9029121904048606\n",
      "Epoch 9668, Loss: 208.50801015352548, Neurons: 201, Grad norm: 1.6582692696836194\n",
      "Epoch 9668, Loss: 208.50801015352548, Neurons: 201, Grad norm: 1.6582692696836194\n",
      "Epoch 9669, Loss: 208.50794705330887, Neurons: 201, Grad norm: 2.486711025932346\n",
      "Epoch 9669, Loss: 208.50794705330887, Neurons: 201, Grad norm: 2.486711025932346\n",
      "Epoch 9670, Loss: 208.5079610074115, Neurons: 201, Grad norm: 2.915948792106714\n",
      "Epoch 9670, Loss: 208.5079610074115, Neurons: 201, Grad norm: 2.915948792106714\n",
      "Epoch 9671, Loss: 208.50790058948843, Neurons: 201, Grad norm: 3.7135877841269904\n",
      "Epoch 9671, Loss: 208.50790058948843, Neurons: 201, Grad norm: 3.7135877841269904\n",
      "Epoch 9672, Loss: 208.50784091121972, Neurons: 201, Grad norm: 4.525301754970706\n",
      "Epoch 9672, Loss: 208.50784091121972, Neurons: 201, Grad norm: 4.525301754970706\n",
      "Epoch 9673, Loss: 208.50788482811924, Neurons: 201, Grad norm: 5.456114535373454\n",
      "Epoch 9673, Loss: 208.50788482811924, Neurons: 201, Grad norm: 5.456114535373454\n",
      "Epoch 9674, Loss: 208.50785889384647, Neurons: 201, Grad norm: 6.4663859589817\n",
      "Epoch 9674, Loss: 208.50785889384647, Neurons: 201, Grad norm: 6.4663859589817\n",
      "Epoch 9675, Loss: 208.507872718142, Neurons: 201, Grad norm: 7.62187539794488\n",
      "Epoch 9675, Loss: 208.507872718142, Neurons: 201, Grad norm: 7.62187539794488\n",
      "Epoch 9676, Loss: 208.50804137862477, Neurons: 201, Grad norm: 8.536535574493465\n",
      "Epoch 9676, Loss: 208.50804137862477, Neurons: 201, Grad norm: 8.536535574493465\n",
      "Epoch 9677, Loss: 208.50817919457177, Neurons: 201, Grad norm: 9.20765356224291\n",
      "Epoch 9677, Loss: 208.50817919457177, Neurons: 201, Grad norm: 9.20765356224291\n",
      "Epoch 9678, Loss: 208.5082405666311, Neurons: 201, Grad norm: 9.438357050041525\n",
      "Epoch 9678, Loss: 208.5082405666311, Neurons: 201, Grad norm: 9.438357050041525\n",
      "Epoch 9679, Loss: 208.50835870628208, Neurons: 201, Grad norm: 9.233193740379225\n",
      "Epoch 9679, Loss: 208.50835870628208, Neurons: 201, Grad norm: 9.233193740379225\n",
      "Epoch 9680, Loss: 208.50837901319497, Neurons: 201, Grad norm: 9.540348250172563\n",
      "Epoch 9680, Loss: 208.50837901319497, Neurons: 201, Grad norm: 9.540348250172563\n",
      "Epoch 9681, Loss: 208.50831807996934, Neurons: 201, Grad norm: 9.667817214331762\n",
      "Epoch 9681, Loss: 208.50831807996934, Neurons: 201, Grad norm: 9.667817214331762\n",
      "Epoch 9682, Loss: 208.50844587720337, Neurons: 201, Grad norm: 9.743788854451862\n",
      "Epoch 9682, Loss: 208.50844587720337, Neurons: 201, Grad norm: 9.743788854451862\n",
      "Epoch 9683, Loss: 208.50848784707566, Neurons: 201, Grad norm: 10.649377621725893\n",
      "Epoch 9683, Loss: 208.50848784707566, Neurons: 201, Grad norm: 10.649377621725893\n",
      "Epoch 9684, Loss: 208.5082844278383, Neurons: 201, Grad norm: 10.986026293190937\n",
      "Epoch 9684, Loss: 208.5082844278383, Neurons: 201, Grad norm: 10.986026293190937\n",
      "Epoch 9685, Loss: 208.5081818045341, Neurons: 201, Grad norm: 11.237397616584756\n",
      "Epoch 9685, Loss: 208.5081818045341, Neurons: 201, Grad norm: 11.237397616584756\n",
      "Epoch 9686, Loss: 208.50815400451197, Neurons: 201, Grad norm: 11.347757106659405\n",
      "Epoch 9686, Loss: 208.50815400451197, Neurons: 201, Grad norm: 11.347757106659405\n",
      "Epoch 9687, Loss: 208.507980239837, Neurons: 201, Grad norm: 10.027715527908077\n",
      "Epoch 9687, Loss: 208.507980239837, Neurons: 201, Grad norm: 10.027715527908077\n",
      "Epoch 9688, Loss: 208.50768622495954, Neurons: 201, Grad norm: 8.339249556092179\n",
      "Epoch 9688, Loss: 208.50768622495954, Neurons: 201, Grad norm: 8.339249556092179\n",
      "Epoch 9689, Loss: 208.50737482994626, Neurons: 201, Grad norm: 6.687509165181605\n",
      "Epoch 9689, Loss: 208.50737482994626, Neurons: 201, Grad norm: 6.687509165181605\n",
      "Epoch 9690, Loss: 208.50704464620304, Neurons: 201, Grad norm: 5.096591899067532\n",
      "Epoch 9690, Loss: 208.50704464620304, Neurons: 201, Grad norm: 5.096591899067532\n",
      "Epoch 9691, Loss: 208.50681439019894, Neurons: 201, Grad norm: 3.395940974144322\n",
      "Epoch 9691, Loss: 208.50681439019894, Neurons: 201, Grad norm: 3.395940974144322\n",
      "Epoch 9692, Loss: 208.50667765516022, Neurons: 201, Grad norm: 2.3452700079932653\n",
      "Epoch 9692, Loss: 208.50667765516022, Neurons: 201, Grad norm: 2.3452700079932653\n",
      "Epoch 9693, Loss: 208.50646488545928, Neurons: 201, Grad norm: 1.6569952970123187\n",
      "Epoch 9693, Loss: 208.50646488545928, Neurons: 201, Grad norm: 1.6569952970123187\n",
      "Epoch 9694, Loss: 208.50634112908588, Neurons: 201, Grad norm: 0.8282244011939718\n",
      "Epoch 9694, Loss: 208.50634112908588, Neurons: 201, Grad norm: 0.8282244011939718\n",
      "Epoch 9695, Loss: 208.50616618696625, Neurons: 201, Grad norm: 0.5230190990558021\n",
      "Epoch 9695, Loss: 208.50616618696625, Neurons: 201, Grad norm: 0.5230190990558021\n",
      "Epoch 9696, Loss: 208.5060614554009, Neurons: 201, Grad norm: 1.1068754031167762\n",
      "Epoch 9696, Loss: 208.5060614554009, Neurons: 201, Grad norm: 1.1068754031167762\n",
      "Epoch 9697, Loss: 208.50606609380088, Neurons: 201, Grad norm: 1.8246678031080819\n",
      "Epoch 9697, Loss: 208.50606609380088, Neurons: 201, Grad norm: 1.8246678031080819\n",
      "Epoch 9698, Loss: 208.50596594793413, Neurons: 201, Grad norm: 2.634323593805113\n",
      "Epoch 9698, Loss: 208.50596594793413, Neurons: 201, Grad norm: 2.634323593805113\n",
      "Epoch 9699, Loss: 208.5059893920353, Neurons: 201, Grad norm: 3.6594055840533413\n",
      "Epoch 9699, Loss: 208.5059893920353, Neurons: 201, Grad norm: 3.6594055840533413\n",
      "Epoch 9700, Loss: 208.50607472925535, Neurons: 201, Grad norm: 4.983664383675324\n",
      "Epoch 9700, Loss: 208.50607472925535, Neurons: 201, Grad norm: 4.983664383675324\n",
      "Epoch 9701, Loss: 208.5060838059589, Neurons: 201, Grad norm: 6.219395559591705\n",
      "Epoch 9701, Loss: 208.5060838059589, Neurons: 201, Grad norm: 6.219395559591705\n",
      "Epoch 9702, Loss: 208.50617574019623, Neurons: 201, Grad norm: 7.5801639252453645\n",
      "Epoch 9702, Loss: 208.50617574019623, Neurons: 201, Grad norm: 7.5801639252453645\n",
      "Epoch 9703, Loss: 208.50627267044655, Neurons: 201, Grad norm: 8.85237154676099\n",
      "Epoch 9703, Loss: 208.50627267044655, Neurons: 201, Grad norm: 8.85237154676099\n",
      "Epoch 9704, Loss: 208.50638767888034, Neurons: 201, Grad norm: 10.647022100492208\n",
      "Epoch 9704, Loss: 208.50638767888034, Neurons: 201, Grad norm: 10.647022100492208\n",
      "Epoch 9705, Loss: 208.50664958536652, Neurons: 201, Grad norm: 11.49533841546608\n",
      "Epoch 9705, Loss: 208.50664958536652, Neurons: 201, Grad norm: 11.49533841546608\n",
      "Epoch 9706, Loss: 208.50690676070138, Neurons: 201, Grad norm: 12.56123604848805\n",
      "Epoch 9706, Loss: 208.50690676070138, Neurons: 201, Grad norm: 12.56123604848805\n",
      "Epoch 9707, Loss: 208.5071072479879, Neurons: 201, Grad norm: 13.757997606289093\n",
      "Epoch 9707, Loss: 208.5071072479879, Neurons: 201, Grad norm: 13.757997606289093\n",
      "Epoch 9708, Loss: 208.5074437001589, Neurons: 201, Grad norm: 13.94759019476531\n",
      "Epoch 9708, Loss: 208.5074437001589, Neurons: 201, Grad norm: 13.94759019476531\n",
      "Epoch 9709, Loss: 208.50755262071308, Neurons: 201, Grad norm: 14.033453694605944\n",
      "Epoch 9709, Loss: 208.50755262071308, Neurons: 201, Grad norm: 14.033453694605944\n",
      "Epoch 9710, Loss: 208.50739963282993, Neurons: 201, Grad norm: 13.497982274475754\n",
      "Epoch 9710, Loss: 208.50739963282993, Neurons: 201, Grad norm: 13.497982274475754\n",
      "Epoch 9711, Loss: 208.50732403257547, Neurons: 201, Grad norm: 12.30712369043119\n",
      "Epoch 9711, Loss: 208.50732403257547, Neurons: 201, Grad norm: 12.30712369043119\n",
      "Epoch 9712, Loss: 208.50679378277238, Neurons: 201, Grad norm: 10.213259031550756\n",
      "Epoch 9712, Loss: 208.50679378277238, Neurons: 201, Grad norm: 10.213259031550756\n",
      "Epoch 9713, Loss: 208.50606357371277, Neurons: 201, Grad norm: 7.562593388538284\n",
      "Epoch 9713, Loss: 208.50606357371277, Neurons: 201, Grad norm: 7.562593388538284\n",
      "Epoch 9714, Loss: 208.5055688661267, Neurons: 201, Grad norm: 4.693824270917958\n",
      "Epoch 9714, Loss: 208.5055688661267, Neurons: 201, Grad norm: 4.693824270917958\n",
      "Epoch 9715, Loss: 208.50511996330982, Neurons: 201, Grad norm: 2.0278302352153292\n",
      "Epoch 9715, Loss: 208.50511996330982, Neurons: 201, Grad norm: 2.0278302352153292\n",
      "Epoch 9716, Loss: 208.50472074347314, Neurons: 201, Grad norm: 0.9584555915212466\n",
      "Epoch 9716, Loss: 208.50472074347314, Neurons: 201, Grad norm: 0.9584555915212466\n",
      "Epoch 9717, Loss: 208.50466019264084, Neurons: 201, Grad norm: 2.4242586202883274\n",
      "Epoch 9717, Loss: 208.50466019264084, Neurons: 201, Grad norm: 2.4242586202883274\n",
      "Epoch 9718, Loss: 208.50464135946538, Neurons: 201, Grad norm: 4.146061933317184\n",
      "Epoch 9718, Loss: 208.50464135946538, Neurons: 201, Grad norm: 4.146061933317184\n",
      "Epoch 9719, Loss: 208.50468026590806, Neurons: 201, Grad norm: 5.976138805274155\n",
      "Epoch 9719, Loss: 208.50468026590806, Neurons: 201, Grad norm: 5.976138805274155\n",
      "Epoch 9720, Loss: 208.50479881643128, Neurons: 201, Grad norm: 7.015016327241374\n",
      "Epoch 9720, Loss: 208.50479881643128, Neurons: 201, Grad norm: 7.015016327241374\n",
      "Epoch 9721, Loss: 208.50484142506593, Neurons: 201, Grad norm: 7.893111137004368\n",
      "Epoch 9721, Loss: 208.50484142506593, Neurons: 201, Grad norm: 7.893111137004368\n",
      "Epoch 9722, Loss: 208.5049350151824, Neurons: 201, Grad norm: 8.37266910577239\n",
      "Epoch 9722, Loss: 208.5049350151824, Neurons: 201, Grad norm: 8.37266910577239\n",
      "Epoch 9723, Loss: 208.505065903387, Neurons: 201, Grad norm: 8.987574445398636\n",
      "Epoch 9723, Loss: 208.505065903387, Neurons: 201, Grad norm: 8.987574445398636\n",
      "Epoch 9724, Loss: 208.50504107930269, Neurons: 201, Grad norm: 8.866963859502553\n",
      "Epoch 9724, Loss: 208.50504107930269, Neurons: 201, Grad norm: 8.866963859502553\n",
      "Epoch 9725, Loss: 208.5050089595865, Neurons: 201, Grad norm: 8.737889725840468\n",
      "Epoch 9725, Loss: 208.5050089595865, Neurons: 201, Grad norm: 8.737889725840468\n",
      "Epoch 9726, Loss: 208.50495395572162, Neurons: 201, Grad norm: 8.764079721042283\n",
      "Epoch 9726, Loss: 208.50495395572162, Neurons: 201, Grad norm: 8.764079721042283\n",
      "Epoch 9727, Loss: 208.50480986007656, Neurons: 201, Grad norm: 8.235627186917553\n",
      "Epoch 9727, Loss: 208.50480986007656, Neurons: 201, Grad norm: 8.235627186917553\n",
      "Epoch 9728, Loss: 208.50474249576357, Neurons: 201, Grad norm: 7.680515773328534\n",
      "Epoch 9728, Loss: 208.50474249576357, Neurons: 201, Grad norm: 7.680515773328534\n",
      "Epoch 9729, Loss: 208.50466543291898, Neurons: 201, Grad norm: 6.964359568344794\n",
      "Epoch 9729, Loss: 208.50466543291898, Neurons: 201, Grad norm: 6.964359568344794\n",
      "Epoch 9730, Loss: 208.50436115978263, Neurons: 201, Grad norm: 6.245283829592383\n",
      "Epoch 9730, Loss: 208.50436115978263, Neurons: 201, Grad norm: 6.245283829592383\n",
      "Epoch 9731, Loss: 208.50417027996778, Neurons: 201, Grad norm: 5.38635830756569\n",
      "Epoch 9731, Loss: 208.50417027996778, Neurons: 201, Grad norm: 5.38635830756569\n",
      "Epoch 9732, Loss: 208.50394893339393, Neurons: 201, Grad norm: 4.701899209810048\n",
      "Epoch 9732, Loss: 208.50394893339393, Neurons: 201, Grad norm: 4.701899209810048\n",
      "Epoch 9733, Loss: 208.50365501568936, Neurons: 201, Grad norm: 3.907547380570144\n",
      "Epoch 9733, Loss: 208.50365501568936, Neurons: 201, Grad norm: 3.907547380570144\n",
      "Epoch 9734, Loss: 208.50365998034573, Neurons: 201, Grad norm: 3.2648085662336466\n",
      "Epoch 9734, Loss: 208.50365998034573, Neurons: 201, Grad norm: 3.2648085662336466\n",
      "Epoch 9735, Loss: 208.50359608669638, Neurons: 201, Grad norm: 2.9609253478965964\n",
      "Epoch 9735, Loss: 208.50359608669638, Neurons: 201, Grad norm: 2.9609253478965964\n",
      "Epoch 9736, Loss: 208.50338097276924, Neurons: 201, Grad norm: 2.7179978702679253\n",
      "Epoch 9736, Loss: 208.50338097276924, Neurons: 201, Grad norm: 2.7179978702679253\n",
      "Epoch 9737, Loss: 208.5032674483162, Neurons: 201, Grad norm: 2.3928574523198294\n",
      "Epoch 9737, Loss: 208.5032674483162, Neurons: 201, Grad norm: 2.3928574523198294\n",
      "Epoch 9738, Loss: 208.5032708517103, Neurons: 201, Grad norm: 2.1800004862749063\n",
      "Epoch 9738, Loss: 208.5032708517103, Neurons: 201, Grad norm: 2.1800004862749063\n",
      "Epoch 9739, Loss: 208.50311339469056, Neurons: 201, Grad norm: 2.7352341575008796\n",
      "Epoch 9739, Loss: 208.50311339469056, Neurons: 201, Grad norm: 2.7352341575008796\n",
      "Epoch 9740, Loss: 208.5029937465961, Neurons: 201, Grad norm: 2.9966397388930868\n",
      "Epoch 9740, Loss: 208.5029937465961, Neurons: 201, Grad norm: 2.9966397388930868\n",
      "Epoch 9741, Loss: 208.50296341688988, Neurons: 201, Grad norm: 3.7496938669398157\n",
      "Epoch 9741, Loss: 208.50296341688988, Neurons: 201, Grad norm: 3.7496938669398157\n",
      "Epoch 9742, Loss: 208.502887038948, Neurons: 201, Grad norm: 4.558844875496494\n",
      "Epoch 9742, Loss: 208.502887038948, Neurons: 201, Grad norm: 4.558844875496494\n",
      "Epoch 9743, Loss: 208.50281894193765, Neurons: 201, Grad norm: 5.646329235478195\n",
      "Epoch 9743, Loss: 208.50281894193765, Neurons: 201, Grad norm: 5.646329235478195\n",
      "Epoch 9744, Loss: 208.50280197548668, Neurons: 201, Grad norm: 7.162827838646281\n",
      "Epoch 9744, Loss: 208.50280197548668, Neurons: 201, Grad norm: 7.162827838646281\n",
      "Epoch 9745, Loss: 208.50305028579575, Neurons: 201, Grad norm: 8.527847239814756\n",
      "Epoch 9745, Loss: 208.50305028579575, Neurons: 201, Grad norm: 8.527847239814756\n",
      "Epoch 9746, Loss: 208.50335108505735, Neurons: 201, Grad norm: 10.090435901199964\n",
      "Epoch 9746, Loss: 208.50335108505735, Neurons: 201, Grad norm: 10.090435901199964\n",
      "Epoch 9747, Loss: 208.50372896148957, Neurons: 201, Grad norm: 11.969800119179224\n",
      "Epoch 9747, Loss: 208.50372896148957, Neurons: 201, Grad norm: 11.969800119179224\n",
      "Epoch 9748, Loss: 208.50405214510877, Neurons: 201, Grad norm: 13.338626350565184\n",
      "Epoch 9748, Loss: 208.50405214510877, Neurons: 201, Grad norm: 13.338626350565184\n",
      "Epoch 9749, Loss: 208.50443776756822, Neurons: 201, Grad norm: 14.341821106012103\n",
      "Epoch 9749, Loss: 208.50443776756822, Neurons: 201, Grad norm: 14.341821106012103\n",
      "Epoch 9750, Loss: 208.50469657448662, Neurons: 201, Grad norm: 15.370926560667986\n",
      "Epoch 9750, Loss: 208.50469657448662, Neurons: 201, Grad norm: 15.370926560667986\n",
      "Epoch 9751, Loss: 208.50509753966935, Neurons: 201, Grad norm: 15.657012702859467\n",
      "Epoch 9751, Loss: 208.50509753966935, Neurons: 201, Grad norm: 15.657012702859467\n",
      "Epoch 9752, Loss: 208.5051795023603, Neurons: 201, Grad norm: 15.44551886269247\n",
      "Epoch 9752, Loss: 208.5051795023603, Neurons: 201, Grad norm: 15.44551886269247\n",
      "Epoch 9753, Loss: 208.505116138723, Neurons: 201, Grad norm: 14.968051833283448\n",
      "Epoch 9753, Loss: 208.505116138723, Neurons: 201, Grad norm: 14.968051833283448\n",
      "Epoch 9754, Loss: 208.50481752450233, Neurons: 201, Grad norm: 13.891627447846155\n",
      "Epoch 9754, Loss: 208.50481752450233, Neurons: 201, Grad norm: 13.891627447846155\n",
      "Epoch 9755, Loss: 208.50432818223427, Neurons: 201, Grad norm: 12.722295560416564\n",
      "Epoch 9755, Loss: 208.50432818223427, Neurons: 201, Grad norm: 12.722295560416564\n",
      "Epoch 9756, Loss: 208.50377549003372, Neurons: 201, Grad norm: 10.866301143880197\n",
      "Epoch 9756, Loss: 208.50377549003372, Neurons: 201, Grad norm: 10.866301143880197\n",
      "Epoch 9757, Loss: 208.50309151467178, Neurons: 201, Grad norm: 8.405622517598045\n",
      "Epoch 9757, Loss: 208.50309151467178, Neurons: 201, Grad norm: 8.405622517598045\n",
      "Epoch 9758, Loss: 208.50252097976812, Neurons: 201, Grad norm: 6.300181569454242\n",
      "Epoch 9758, Loss: 208.50252097976812, Neurons: 201, Grad norm: 6.300181569454242\n",
      "Epoch 9759, Loss: 208.50203803863647, Neurons: 201, Grad norm: 4.219268596627502\n",
      "Epoch 9759, Loss: 208.50203803863647, Neurons: 201, Grad norm: 4.219268596627502\n",
      "Epoch 9760, Loss: 208.50169769457207, Neurons: 201, Grad norm: 2.1150974065884456\n",
      "Epoch 9760, Loss: 208.50169769457207, Neurons: 201, Grad norm: 2.1150974065884456\n",
      "Epoch 9761, Loss: 208.50147767290102, Neurons: 201, Grad norm: 0.8225908519359693\n",
      "Epoch 9761, Loss: 208.50147767290102, Neurons: 201, Grad norm: 0.8225908519359693\n",
      "Epoch 9762, Loss: 208.5012748226972, Neurons: 201, Grad norm: 1.7610582756637534\n",
      "Epoch 9762, Loss: 208.5012748226972, Neurons: 201, Grad norm: 1.7610582756637534\n",
      "Epoch 9763, Loss: 208.50119125108475, Neurons: 201, Grad norm: 2.9263437581322345\n",
      "Epoch 9763, Loss: 208.50119125108475, Neurons: 201, Grad norm: 2.9263437581322345\n",
      "Epoch 9764, Loss: 208.5011844741381, Neurons: 201, Grad norm: 3.9611311550110093\n",
      "Epoch 9764, Loss: 208.5011844741381, Neurons: 201, Grad norm: 3.9611311550110093\n",
      "Epoch 9765, Loss: 208.5012221280786, Neurons: 201, Grad norm: 5.136832832779857\n",
      "Epoch 9765, Loss: 208.5012221280786, Neurons: 201, Grad norm: 5.136832832779857\n",
      "Epoch 9766, Loss: 208.5012303579699, Neurons: 201, Grad norm: 6.082469744384247\n",
      "Epoch 9766, Loss: 208.5012303579699, Neurons: 201, Grad norm: 6.082469744384247\n",
      "Epoch 9767, Loss: 208.5012692884321, Neurons: 201, Grad norm: 7.116287483492753\n",
      "Epoch 9767, Loss: 208.5012692884321, Neurons: 201, Grad norm: 7.116287483492753\n",
      "Epoch 9768, Loss: 208.5014285871879, Neurons: 201, Grad norm: 8.093640539141422\n",
      "Epoch 9768, Loss: 208.5014285871879, Neurons: 201, Grad norm: 8.093640539141422\n",
      "Epoch 9769, Loss: 208.5015848408654, Neurons: 201, Grad norm: 9.065190983181985\n",
      "Epoch 9769, Loss: 208.5015848408654, Neurons: 201, Grad norm: 9.065190983181985\n",
      "Epoch 9770, Loss: 208.50170611668253, Neurons: 201, Grad norm: 9.728490360831401\n",
      "Epoch 9770, Loss: 208.50170611668253, Neurons: 201, Grad norm: 9.728490360831401\n",
      "Epoch 9771, Loss: 208.5017603359863, Neurons: 201, Grad norm: 10.105830736250638\n",
      "Epoch 9771, Loss: 208.5017603359863, Neurons: 201, Grad norm: 10.105830736250638\n",
      "Epoch 9772, Loss: 208.50186833196554, Neurons: 201, Grad norm: 10.357022814867042\n",
      "Epoch 9772, Loss: 208.50186833196554, Neurons: 201, Grad norm: 10.357022814867042\n",
      "Epoch 9773, Loss: 208.50185499529294, Neurons: 201, Grad norm: 9.966289602231498\n",
      "Epoch 9773, Loss: 208.50185499529294, Neurons: 201, Grad norm: 9.966289602231498\n",
      "Epoch 9774, Loss: 208.50175800752137, Neurons: 201, Grad norm: 9.422422933802208\n",
      "Epoch 9774, Loss: 208.50175800752137, Neurons: 201, Grad norm: 9.422422933802208\n",
      "Epoch 9775, Loss: 208.50155842296647, Neurons: 201, Grad norm: 8.610788987358262\n",
      "Epoch 9775, Loss: 208.50155842296647, Neurons: 201, Grad norm: 8.610788987358262\n",
      "Epoch 9776, Loss: 208.50125538432076, Neurons: 201, Grad norm: 7.383499361231751\n",
      "Epoch 9776, Loss: 208.50125538432076, Neurons: 201, Grad norm: 7.383499361231751\n",
      "Epoch 9777, Loss: 208.50090304507438, Neurons: 201, Grad norm: 6.035190498884202\n",
      "Epoch 9777, Loss: 208.50090304507438, Neurons: 201, Grad norm: 6.035190498884202\n",
      "Epoch 9778, Loss: 208.50064197804573, Neurons: 201, Grad norm: 4.803192547598742\n",
      "Epoch 9778, Loss: 208.50064197804573, Neurons: 201, Grad norm: 4.803192547598742\n",
      "Epoch 9779, Loss: 208.50034771923225, Neurons: 201, Grad norm: 3.861650423704575\n",
      "Epoch 9779, Loss: 208.50034771923225, Neurons: 201, Grad norm: 3.861650423704575\n",
      "Epoch 9780, Loss: 208.5001228837539, Neurons: 201, Grad norm: 2.6942202995776423\n",
      "Epoch 9780, Loss: 208.5001228837539, Neurons: 201, Grad norm: 2.6942202995776423\n",
      "Epoch 9781, Loss: 208.50001749096916, Neurons: 201, Grad norm: 2.2756274125351106\n",
      "Epoch 9781, Loss: 208.50001749096916, Neurons: 201, Grad norm: 2.2756274125351106\n",
      "Epoch 9782, Loss: 208.499897806662, Neurons: 201, Grad norm: 2.0737548962706347\n",
      "Epoch 9782, Loss: 208.499897806662, Neurons: 201, Grad norm: 2.0737548962706347\n",
      "Epoch 9783, Loss: 208.4999989226714, Neurons: 201, Grad norm: 2.3756717533221323\n",
      "Epoch 9783, Loss: 208.4999989226714, Neurons: 201, Grad norm: 2.3756717533221323\n",
      "Epoch 9784, Loss: 208.49995410104242, Neurons: 201, Grad norm: 3.283252355347644\n",
      "Epoch 9784, Loss: 208.49995410104242, Neurons: 201, Grad norm: 3.283252355347644\n",
      "Epoch 9785, Loss: 208.49980277239564, Neurons: 201, Grad norm: 5.135060723914908\n",
      "Epoch 9785, Loss: 208.49980277239564, Neurons: 201, Grad norm: 5.135060723914908\n",
      "Epoch 9786, Loss: 208.4998676414779, Neurons: 201, Grad norm: 7.125410756480609\n",
      "Epoch 9786, Loss: 208.4998676414779, Neurons: 201, Grad norm: 7.125410756480609\n",
      "Epoch 9787, Loss: 208.49997312406097, Neurons: 201, Grad norm: 8.942110048901629\n",
      "Epoch 9787, Loss: 208.49997312406097, Neurons: 201, Grad norm: 8.942110048901629\n",
      "Epoch 9788, Loss: 208.50013098359588, Neurons: 201, Grad norm: 9.946296235938279\n",
      "Epoch 9788, Loss: 208.50013098359588, Neurons: 201, Grad norm: 9.946296235938279\n",
      "Epoch 9789, Loss: 208.50030642474076, Neurons: 201, Grad norm: 10.50146679142818\n",
      "Epoch 9789, Loss: 208.50030642474076, Neurons: 201, Grad norm: 10.50146679142818\n",
      "Epoch 9790, Loss: 208.50029184338052, Neurons: 201, Grad norm: 10.525819659600929\n",
      "Epoch 9790, Loss: 208.50029184338052, Neurons: 201, Grad norm: 10.525819659600929\n",
      "Epoch 9791, Loss: 208.50029794674194, Neurons: 201, Grad norm: 10.478198019442473\n",
      "Epoch 9791, Loss: 208.50029794674194, Neurons: 201, Grad norm: 10.478198019442473\n",
      "Epoch 9792, Loss: 208.50031887020768, Neurons: 201, Grad norm: 10.44814482292148\n",
      "Epoch 9792, Loss: 208.50031887020768, Neurons: 201, Grad norm: 10.44814482292148\n",
      "Epoch 9793, Loss: 208.50048838740304, Neurons: 201, Grad norm: 10.30675326232529\n",
      "Epoch 9793, Loss: 208.50048838740304, Neurons: 201, Grad norm: 10.30675326232529\n",
      "Epoch 9794, Loss: 208.5006371771318, Neurons: 201, Grad norm: 10.579491054190163\n",
      "Epoch 9794, Loss: 208.5006371771318, Neurons: 201, Grad norm: 10.579491054190163\n",
      "Epoch 9795, Loss: 208.5008503770145, Neurons: 201, Grad norm: 10.433107263649996\n",
      "Epoch 9795, Loss: 208.5008503770145, Neurons: 201, Grad norm: 10.433107263649996\n",
      "Epoch 9796, Loss: 208.500738577337, Neurons: 201, Grad norm: 10.740731331637956\n",
      "Epoch 9796, Loss: 208.500738577337, Neurons: 201, Grad norm: 10.740731331637956\n",
      "Epoch 9797, Loss: 208.50050821731332, Neurons: 201, Grad norm: 11.175387274509209\n",
      "Epoch 9797, Loss: 208.50050821731332, Neurons: 201, Grad norm: 11.175387274509209\n",
      "Epoch 9798, Loss: 208.5003564550894, Neurons: 201, Grad norm: 11.113528581797954\n",
      "Epoch 9798, Loss: 208.5003564550894, Neurons: 201, Grad norm: 11.113528581797954\n",
      "Epoch 9799, Loss: 208.5000323680928, Neurons: 201, Grad norm: 11.147638016244464\n",
      "Epoch 9799, Loss: 208.5000323680928, Neurons: 201, Grad norm: 11.147638016244464\n",
      "Epoch 9800, Loss: 208.49976590805585, Neurons: 201, Grad norm: 10.540815665046466\n",
      "Epoch 9800, Loss: 208.49976590805585, Neurons: 201, Grad norm: 10.540815665046466\n",
      "Epoch 9801, Loss: 208.49949826856675, Neurons: 201, Grad norm: 9.486750570057085\n",
      "Epoch 9801, Loss: 208.49949826856675, Neurons: 201, Grad norm: 9.486750570057085\n",
      "Epoch 9802, Loss: 208.4991663152527, Neurons: 201, Grad norm: 7.950736254849062\n",
      "Epoch 9802, Loss: 208.4991663152527, Neurons: 201, Grad norm: 7.950736254849062\n",
      "Epoch 9803, Loss: 208.4988628823332, Neurons: 201, Grad norm: 5.9742050176991945\n",
      "Epoch 9803, Loss: 208.4988628823332, Neurons: 201, Grad norm: 5.9742050176991945\n",
      "Epoch 9804, Loss: 208.49851792835392, Neurons: 201, Grad norm: 4.405477801730003\n",
      "Epoch 9804, Loss: 208.49851792835392, Neurons: 201, Grad norm: 4.405477801730003\n",
      "Epoch 9805, Loss: 208.4982784303325, Neurons: 201, Grad norm: 2.998318318160363\n",
      "Epoch 9805, Loss: 208.4982784303325, Neurons: 201, Grad norm: 2.998318318160363\n",
      "Epoch 9806, Loss: 208.4982694440809, Neurons: 201, Grad norm: 2.6456756649788113\n",
      "Epoch 9806, Loss: 208.4982694440809, Neurons: 201, Grad norm: 2.6456756649788113\n",
      "Epoch 9807, Loss: 208.4982242519185, Neurons: 201, Grad norm: 2.320082764719431\n",
      "Epoch 9807, Loss: 208.4982242519185, Neurons: 201, Grad norm: 2.320082764719431\n",
      "Epoch 9808, Loss: 208.49810839655046, Neurons: 201, Grad norm: 2.0403794382171205\n",
      "Epoch 9808, Loss: 208.49810839655046, Neurons: 201, Grad norm: 2.0403794382171205\n",
      "Epoch 9809, Loss: 208.49798183984325, Neurons: 201, Grad norm: 1.559075833132559\n",
      "Epoch 9809, Loss: 208.49798183984325, Neurons: 201, Grad norm: 1.559075833132559\n",
      "Epoch 9810, Loss: 208.49782895383984, Neurons: 201, Grad norm: 1.567629575442477\n",
      "Epoch 9810, Loss: 208.49782895383984, Neurons: 201, Grad norm: 1.567629575442477\n",
      "Epoch 9811, Loss: 208.49767277504685, Neurons: 201, Grad norm: 2.141617158327488\n",
      "Epoch 9811, Loss: 208.49767277504685, Neurons: 201, Grad norm: 2.141617158327488\n",
      "Epoch 9812, Loss: 208.49764976223878, Neurons: 201, Grad norm: 2.539994081937536\n",
      "Epoch 9812, Loss: 208.49764976223878, Neurons: 201, Grad norm: 2.539994081937536\n",
      "Epoch 9813, Loss: 208.4976522092261, Neurons: 201, Grad norm: 2.9462553111963716\n",
      "Epoch 9813, Loss: 208.4976522092261, Neurons: 201, Grad norm: 2.9462553111963716\n",
      "Epoch 9814, Loss: 208.49775767257233, Neurons: 201, Grad norm: 2.982696393390009\n",
      "Epoch 9814, Loss: 208.49775767257233, Neurons: 201, Grad norm: 2.982696393390009\n",
      "Epoch 9815, Loss: 208.4978044338639, Neurons: 201, Grad norm: 2.714856039225874\n",
      "Epoch 9815, Loss: 208.4978044338639, Neurons: 201, Grad norm: 2.714856039225874\n",
      "Epoch 9816, Loss: 208.4977638069362, Neurons: 201, Grad norm: 2.5593084564097053\n",
      "Epoch 9816, Loss: 208.4977638069362, Neurons: 201, Grad norm: 2.5593084564097053\n",
      "Epoch 9817, Loss: 208.49750182311524, Neurons: 201, Grad norm: 3.6809652250741283\n",
      "Epoch 9817, Loss: 208.49750182311524, Neurons: 201, Grad norm: 3.6809652250741283\n",
      "Epoch 9818, Loss: 208.49735271492858, Neurons: 201, Grad norm: 5.612141066366994\n",
      "Epoch 9818, Loss: 208.49735271492858, Neurons: 201, Grad norm: 5.612141066366994\n",
      "Epoch 9819, Loss: 208.49743556639962, Neurons: 201, Grad norm: 7.450849592666216\n",
      "Epoch 9819, Loss: 208.49743556639962, Neurons: 201, Grad norm: 7.450849592666216\n",
      "Epoch 9820, Loss: 208.49756465473283, Neurons: 201, Grad norm: 9.39326239390032\n",
      "Epoch 9820, Loss: 208.49756465473283, Neurons: 201, Grad norm: 9.39326239390032\n",
      "Epoch 9821, Loss: 208.49777967970203, Neurons: 201, Grad norm: 10.276855371591152\n",
      "Epoch 9821, Loss: 208.49777967970203, Neurons: 201, Grad norm: 10.276855371591152\n",
      "Epoch 9822, Loss: 208.49795502033294, Neurons: 201, Grad norm: 11.131507788966287\n",
      "Epoch 9822, Loss: 208.49795502033294, Neurons: 201, Grad norm: 11.131507788966287\n",
      "Epoch 9823, Loss: 208.4980990999985, Neurons: 201, Grad norm: 11.523830070592311\n",
      "Epoch 9823, Loss: 208.4980990999985, Neurons: 201, Grad norm: 11.523830070592311\n",
      "Epoch 9824, Loss: 208.49817903087072, Neurons: 201, Grad norm: 11.436631451823203\n",
      "Epoch 9824, Loss: 208.49817903087072, Neurons: 201, Grad norm: 11.436631451823203\n",
      "Epoch 9825, Loss: 208.49830930076598, Neurons: 201, Grad norm: 11.614440596717404\n",
      "Epoch 9825, Loss: 208.49830930076598, Neurons: 201, Grad norm: 11.614440596717404\n",
      "Epoch 9826, Loss: 208.4984525457847, Neurons: 201, Grad norm: 11.412862470089294\n",
      "Epoch 9826, Loss: 208.4984525457847, Neurons: 201, Grad norm: 11.412862470089294\n",
      "Epoch 9827, Loss: 208.49856670873655, Neurons: 201, Grad norm: 11.796640984145656\n",
      "Epoch 9827, Loss: 208.49856670873655, Neurons: 201, Grad norm: 11.796640984145656\n",
      "Epoch 9828, Loss: 208.4986087945546, Neurons: 201, Grad norm: 11.900780087832578\n",
      "Epoch 9828, Loss: 208.4986087945546, Neurons: 201, Grad norm: 11.900780087832578\n",
      "Epoch 9829, Loss: 208.49844168339493, Neurons: 201, Grad norm: 11.91529888921161\n",
      "Epoch 9829, Loss: 208.49844168339493, Neurons: 201, Grad norm: 11.91529888921161\n",
      "Epoch 9830, Loss: 208.49817367777905, Neurons: 201, Grad norm: 11.867688036584747\n",
      "Epoch 9830, Loss: 208.49817367777905, Neurons: 201, Grad norm: 11.867688036584747\n",
      "Epoch 9831, Loss: 208.4978596078583, Neurons: 201, Grad norm: 11.110128250756663\n",
      "Epoch 9831, Loss: 208.4978596078583, Neurons: 201, Grad norm: 11.110128250756663\n",
      "Epoch 9832, Loss: 208.49761779248115, Neurons: 201, Grad norm: 10.140900412350216\n",
      "Epoch 9832, Loss: 208.49761779248115, Neurons: 201, Grad norm: 10.140900412350216\n",
      "Epoch 9833, Loss: 208.4973644260446, Neurons: 201, Grad norm: 8.614003032126124\n",
      "Epoch 9833, Loss: 208.4973644260446, Neurons: 201, Grad norm: 8.614003032126124\n",
      "Epoch 9834, Loss: 208.49707352828605, Neurons: 201, Grad norm: 7.265428414364548\n",
      "Epoch 9834, Loss: 208.49707352828605, Neurons: 201, Grad norm: 7.265428414364548\n",
      "Epoch 9835, Loss: 208.49681600041097, Neurons: 201, Grad norm: 5.658688200338382\n",
      "Epoch 9835, Loss: 208.49681600041097, Neurons: 201, Grad norm: 5.658688200338382\n",
      "Epoch 9836, Loss: 208.4964324004941, Neurons: 201, Grad norm: 4.0925793133958654\n",
      "Epoch 9836, Loss: 208.4964324004941, Neurons: 201, Grad norm: 4.0925793133958654\n",
      "Epoch 9837, Loss: 208.4961398457671, Neurons: 201, Grad norm: 3.0110969823665394\n",
      "Epoch 9837, Loss: 208.4961398457671, Neurons: 201, Grad norm: 3.0110969823665394\n",
      "Epoch 9838, Loss: 208.49591085301122, Neurons: 201, Grad norm: 1.632388792018158\n",
      "Epoch 9838, Loss: 208.49591085301122, Neurons: 201, Grad norm: 1.632388792018158\n",
      "Epoch 9839, Loss: 208.4957529502612, Neurons: 201, Grad norm: 0.8936790360556887\n",
      "Epoch 9839, Loss: 208.4957529502612, Neurons: 201, Grad norm: 0.8936790360556887\n",
      "Epoch 9840, Loss: 208.49566491065255, Neurons: 201, Grad norm: 0.7739784543629716\n",
      "Epoch 9840, Loss: 208.49566491065255, Neurons: 201, Grad norm: 0.7739784543629716\n",
      "Epoch 9841, Loss: 208.4955586719057, Neurons: 201, Grad norm: 1.5506635228531689\n",
      "Epoch 9841, Loss: 208.4955586719057, Neurons: 201, Grad norm: 1.5506635228531689\n",
      "Epoch 9842, Loss: 208.49554744492372, Neurons: 201, Grad norm: 2.8627900571646903\n",
      "Epoch 9842, Loss: 208.49554744492372, Neurons: 201, Grad norm: 2.8627900571646903\n",
      "Epoch 9843, Loss: 208.49560329630063, Neurons: 201, Grad norm: 4.464791836164817\n",
      "Epoch 9843, Loss: 208.49560329630063, Neurons: 201, Grad norm: 4.464791836164817\n",
      "Epoch 9844, Loss: 208.4957131708275, Neurons: 201, Grad norm: 5.897538247148146\n",
      "Epoch 9844, Loss: 208.4957131708275, Neurons: 201, Grad norm: 5.897538247148146\n",
      "Epoch 9845, Loss: 208.49581131837013, Neurons: 201, Grad norm: 8.120322624335094\n",
      "Epoch 9845, Loss: 208.49581131837013, Neurons: 201, Grad norm: 8.120322624335094\n",
      "Epoch 9846, Loss: 208.496017252183, Neurons: 201, Grad norm: 10.161159160084475\n",
      "Epoch 9846, Loss: 208.496017252183, Neurons: 201, Grad norm: 10.161159160084475\n",
      "Epoch 9847, Loss: 208.49629821664544, Neurons: 201, Grad norm: 12.341507068277723\n",
      "Epoch 9847, Loss: 208.49629821664544, Neurons: 201, Grad norm: 12.341507068277723\n",
      "Epoch 9848, Loss: 208.4967608830113, Neurons: 201, Grad norm: 13.924090468785476\n",
      "Epoch 9848, Loss: 208.4967608830113, Neurons: 201, Grad norm: 13.924090468785476\n",
      "Epoch 9849, Loss: 208.49723089526597, Neurons: 201, Grad norm: 15.070684564044818\n",
      "Epoch 9849, Loss: 208.49723089526597, Neurons: 201, Grad norm: 15.070684564044818\n",
      "Epoch 9850, Loss: 208.4975778018868, Neurons: 201, Grad norm: 15.4940248653435\n",
      "Epoch 9850, Loss: 208.4975778018868, Neurons: 201, Grad norm: 15.4940248653435\n",
      "Epoch 9851, Loss: 208.49774267080468, Neurons: 201, Grad norm: 14.637858664743245\n",
      "Epoch 9851, Loss: 208.49774267080468, Neurons: 201, Grad norm: 14.637858664743245\n",
      "Epoch 9852, Loss: 208.49746503423745, Neurons: 201, Grad norm: 13.30698089645116\n",
      "Epoch 9852, Loss: 208.49746503423745, Neurons: 201, Grad norm: 13.30698089645116\n",
      "Epoch 9853, Loss: 208.4969160963366, Neurons: 201, Grad norm: 11.199611876944562\n",
      "Epoch 9853, Loss: 208.4969160963366, Neurons: 201, Grad norm: 11.199611876944562\n",
      "Epoch 9854, Loss: 208.49628272714006, Neurons: 201, Grad norm: 8.501403819309372\n",
      "Epoch 9854, Loss: 208.49628272714006, Neurons: 201, Grad norm: 8.501403819309372\n",
      "Epoch 9855, Loss: 208.4954286719748, Neurons: 201, Grad norm: 5.878727030369285\n",
      "Epoch 9855, Loss: 208.4954286719748, Neurons: 201, Grad norm: 5.878727030369285\n",
      "Epoch 9856, Loss: 208.49470444182404, Neurons: 201, Grad norm: 3.3869286255776325\n",
      "Epoch 9856, Loss: 208.49470444182404, Neurons: 201, Grad norm: 3.3869286255776325\n",
      "Epoch 9857, Loss: 208.49442235973152, Neurons: 201, Grad norm: 1.5125793855204634\n",
      "Epoch 9857, Loss: 208.49442235973152, Neurons: 201, Grad norm: 1.5125793855204634\n",
      "Epoch 9858, Loss: 208.49428376370773, Neurons: 201, Grad norm: 2.4457571660568815\n",
      "Epoch 9858, Loss: 208.49428376370773, Neurons: 201, Grad norm: 2.4457571660568815\n",
      "Epoch 9859, Loss: 208.49427240817596, Neurons: 201, Grad norm: 4.943049767961979\n",
      "Epoch 9859, Loss: 208.49427240817596, Neurons: 201, Grad norm: 4.943049767961979\n",
      "Epoch 9860, Loss: 208.49443872983238, Neurons: 201, Grad norm: 7.55154969701071\n",
      "Epoch 9860, Loss: 208.49443872983238, Neurons: 201, Grad norm: 7.55154969701071\n",
      "Epoch 9861, Loss: 208.49469105101883, Neurons: 201, Grad norm: 10.25348585669537\n",
      "Epoch 9861, Loss: 208.49469105101883, Neurons: 201, Grad norm: 10.25348585669537\n",
      "Epoch 9862, Loss: 208.4950219822332, Neurons: 201, Grad norm: 12.51222170308587\n",
      "Epoch 9862, Loss: 208.4950219822332, Neurons: 201, Grad norm: 12.51222170308587\n",
      "Epoch 9863, Loss: 208.4953334129543, Neurons: 201, Grad norm: 13.172674299419205\n",
      "Epoch 9863, Loss: 208.4953334129543, Neurons: 201, Grad norm: 13.172674299419205\n",
      "Epoch 9864, Loss: 208.49556412894913, Neurons: 201, Grad norm: 13.725079257523225\n",
      "Epoch 9864, Loss: 208.49556412894913, Neurons: 201, Grad norm: 13.725079257523225\n",
      "Epoch 9865, Loss: 208.49555985801922, Neurons: 201, Grad norm: 12.752786982952664\n",
      "Epoch 9865, Loss: 208.49555985801922, Neurons: 201, Grad norm: 12.752786982952664\n",
      "Epoch 9866, Loss: 208.49541047617404, Neurons: 201, Grad norm: 11.51799943750656\n",
      "Epoch 9866, Loss: 208.49541047617404, Neurons: 201, Grad norm: 11.51799943750656\n",
      "Epoch 9867, Loss: 208.4952099240528, Neurons: 201, Grad norm: 10.190852999892135\n",
      "Epoch 9867, Loss: 208.4952099240528, Neurons: 201, Grad norm: 10.190852999892135\n",
      "Epoch 9868, Loss: 208.49491752987885, Neurons: 201, Grad norm: 8.725930027424745\n",
      "Epoch 9868, Loss: 208.49491752987885, Neurons: 201, Grad norm: 8.725930027424745\n",
      "Epoch 9869, Loss: 208.49455140664628, Neurons: 201, Grad norm: 7.288917564529941\n",
      "Epoch 9869, Loss: 208.49455140664628, Neurons: 201, Grad norm: 7.288917564529941\n",
      "Epoch 9870, Loss: 208.49424544231866, Neurons: 201, Grad norm: 5.441880118321303\n",
      "Epoch 9870, Loss: 208.49424544231866, Neurons: 201, Grad norm: 5.441880118321303\n",
      "Epoch 9871, Loss: 208.4938156011832, Neurons: 201, Grad norm: 4.028072129108693\n",
      "Epoch 9871, Loss: 208.4938156011832, Neurons: 201, Grad norm: 4.028072129108693\n",
      "Epoch 9872, Loss: 208.49340547155253, Neurons: 201, Grad norm: 2.59120894791481\n",
      "Epoch 9872, Loss: 208.49340547155253, Neurons: 201, Grad norm: 2.59120894791481\n",
      "Epoch 9873, Loss: 208.4932401129032, Neurons: 201, Grad norm: 1.454375484503184\n",
      "Epoch 9873, Loss: 208.4932401129032, Neurons: 201, Grad norm: 1.454375484503184\n",
      "Epoch 9874, Loss: 208.4931795400631, Neurons: 201, Grad norm: 2.01717964192232\n",
      "Epoch 9874, Loss: 208.4931795400631, Neurons: 201, Grad norm: 2.01717964192232\n",
      "Epoch 9875, Loss: 208.49323314909196, Neurons: 201, Grad norm: 3.6689227980687287\n",
      "Epoch 9875, Loss: 208.49323314909196, Neurons: 201, Grad norm: 3.6689227980687287\n",
      "Epoch 9876, Loss: 208.49326953515026, Neurons: 201, Grad norm: 5.883361410599847\n",
      "Epoch 9876, Loss: 208.49326953515026, Neurons: 201, Grad norm: 5.883361410599847\n",
      "Epoch 9877, Loss: 208.4933103727149, Neurons: 201, Grad norm: 8.193486847179313\n",
      "Epoch 9877, Loss: 208.4933103727149, Neurons: 201, Grad norm: 8.193486847179313\n",
      "Epoch 9878, Loss: 208.49352389051083, Neurons: 201, Grad norm: 9.99878424205474\n",
      "Epoch 9878, Loss: 208.49352389051083, Neurons: 201, Grad norm: 9.99878424205474\n",
      "Epoch 9879, Loss: 208.49382532551581, Neurons: 201, Grad norm: 11.35864541824778\n",
      "Epoch 9879, Loss: 208.49382532551581, Neurons: 201, Grad norm: 11.35864541824778\n",
      "Epoch 9880, Loss: 208.49399568009292, Neurons: 201, Grad norm: 11.739634095739754\n",
      "Epoch 9880, Loss: 208.49399568009292, Neurons: 201, Grad norm: 11.739634095739754\n",
      "Epoch 9881, Loss: 208.49394281884224, Neurons: 201, Grad norm: 10.930361186013034\n",
      "Epoch 9881, Loss: 208.49394281884224, Neurons: 201, Grad norm: 10.930361186013034\n",
      "Epoch 9882, Loss: 208.49379182901407, Neurons: 201, Grad norm: 9.542913853861885\n",
      "Epoch 9882, Loss: 208.49379182901407, Neurons: 201, Grad norm: 9.542913853861885\n",
      "Epoch 9883, Loss: 208.49355388988013, Neurons: 201, Grad norm: 7.75043068235268\n",
      "Epoch 9883, Loss: 208.49355388988013, Neurons: 201, Grad norm: 7.75043068235268\n",
      "Epoch 9884, Loss: 208.49320396336608, Neurons: 201, Grad norm: 5.7770353930089575\n",
      "Epoch 9884, Loss: 208.49320396336608, Neurons: 201, Grad norm: 5.7770353930089575\n",
      "Epoch 9885, Loss: 208.49296499902394, Neurons: 201, Grad norm: 3.9910284397134483\n",
      "Epoch 9885, Loss: 208.49296499902394, Neurons: 201, Grad norm: 3.9910284397134483\n",
      "Epoch 9886, Loss: 208.4926564840979, Neurons: 201, Grad norm: 2.704705122081954\n",
      "Epoch 9886, Loss: 208.4926564840979, Neurons: 201, Grad norm: 2.704705122081954\n",
      "Epoch 9887, Loss: 208.4923709116526, Neurons: 201, Grad norm: 1.8300442668330634\n",
      "Epoch 9887, Loss: 208.4923709116526, Neurons: 201, Grad norm: 1.8300442668330634\n",
      "Epoch 9888, Loss: 208.49221788410935, Neurons: 201, Grad norm: 1.6296523250309283\n",
      "Epoch 9888, Loss: 208.49221788410935, Neurons: 201, Grad norm: 1.6296523250309283\n",
      "Epoch 9889, Loss: 208.49214826815125, Neurons: 201, Grad norm: 1.9018656178566864\n",
      "Epoch 9889, Loss: 208.49214826815125, Neurons: 201, Grad norm: 1.9018656178566864\n",
      "Epoch 9890, Loss: 208.4921010051947, Neurons: 201, Grad norm: 2.243687543904024\n",
      "Epoch 9890, Loss: 208.4921010051947, Neurons: 201, Grad norm: 2.243687543904024\n",
      "Epoch 9891, Loss: 208.49217323261826, Neurons: 201, Grad norm: 2.9688005661253762\n",
      "Epoch 9891, Loss: 208.49217323261826, Neurons: 201, Grad norm: 2.9688005661253762\n",
      "Epoch 9892, Loss: 208.4922123818242, Neurons: 201, Grad norm: 4.53538877395698\n",
      "Epoch 9892, Loss: 208.4922123818242, Neurons: 201, Grad norm: 4.53538877395698\n",
      "Epoch 9893, Loss: 208.49219667403312, Neurons: 201, Grad norm: 6.0382552405625525\n",
      "Epoch 9893, Loss: 208.49219667403312, Neurons: 201, Grad norm: 6.0382552405625525\n",
      "Epoch 9894, Loss: 208.49219911886215, Neurons: 201, Grad norm: 8.523286531595893\n",
      "Epoch 9894, Loss: 208.49219911886215, Neurons: 201, Grad norm: 8.523286531595893\n",
      "Epoch 9895, Loss: 208.492294709056, Neurons: 201, Grad norm: 10.056785742940923\n",
      "Epoch 9895, Loss: 208.492294709056, Neurons: 201, Grad norm: 10.056785742940923\n",
      "Epoch 9896, Loss: 208.4925003587774, Neurons: 201, Grad norm: 11.383471277803478\n",
      "Epoch 9896, Loss: 208.4925003587774, Neurons: 201, Grad norm: 11.383471277803478\n",
      "Epoch 9897, Loss: 208.49265736914867, Neurons: 201, Grad norm: 11.527055015358581\n",
      "Epoch 9897, Loss: 208.49265736914867, Neurons: 201, Grad norm: 11.527055015358581\n",
      "Epoch 9898, Loss: 208.4926714304907, Neurons: 201, Grad norm: 11.612795894586823\n",
      "Epoch 9898, Loss: 208.4926714304907, Neurons: 201, Grad norm: 11.612795894586823\n",
      "Epoch 9899, Loss: 208.4925972950194, Neurons: 201, Grad norm: 10.502937733154782\n",
      "Epoch 9899, Loss: 208.4925972950194, Neurons: 201, Grad norm: 10.502937733154782\n",
      "Epoch 9900, Loss: 208.49238365335503, Neurons: 201, Grad norm: 9.357208942953468\n",
      "Epoch 9900, Loss: 208.49238365335503, Neurons: 201, Grad norm: 9.357208942953468\n",
      "Epoch 9901, Loss: 208.4920882477118, Neurons: 201, Grad norm: 7.780136216524822\n",
      "Epoch 9901, Loss: 208.4920882477118, Neurons: 201, Grad norm: 7.780136216524822\n",
      "Epoch 9902, Loss: 208.49172287828313, Neurons: 201, Grad norm: 6.4583508087165304\n",
      "Epoch 9902, Loss: 208.49172287828313, Neurons: 201, Grad norm: 6.4583508087165304\n",
      "Epoch 9903, Loss: 208.49137940074962, Neurons: 201, Grad norm: 5.005109607944939\n",
      "Epoch 9903, Loss: 208.49137940074962, Neurons: 201, Grad norm: 5.005109607944939\n",
      "Epoch 9904, Loss: 208.4910498066043, Neurons: 201, Grad norm: 3.990154928773481\n",
      "Epoch 9904, Loss: 208.4910498066043, Neurons: 201, Grad norm: 3.990154928773481\n",
      "Epoch 9905, Loss: 208.49071689930383, Neurons: 201, Grad norm: 2.694849521704006\n",
      "Epoch 9905, Loss: 208.49071689930383, Neurons: 201, Grad norm: 2.694849521704006\n",
      "Epoch 9906, Loss: 208.49038751426414, Neurons: 201, Grad norm: 2.728190782438935\n",
      "Epoch 9906, Loss: 208.49038751426414, Neurons: 201, Grad norm: 2.728190782438935\n",
      "Epoch 9907, Loss: 208.49017268516647, Neurons: 201, Grad norm: 1.7081164309683228\n",
      "Epoch 9907, Loss: 208.49017268516647, Neurons: 201, Grad norm: 1.7081164309683228\n",
      "Epoch 9908, Loss: 208.489976286884, Neurons: 201, Grad norm: 1.6055129294869324\n",
      "Epoch 9908, Loss: 208.489976286884, Neurons: 201, Grad norm: 1.6055129294869324\n",
      "Epoch 9909, Loss: 208.4898264410769, Neurons: 201, Grad norm: 1.8922774052601037\n",
      "Epoch 9909, Loss: 208.4898264410769, Neurons: 201, Grad norm: 1.8922774052601037\n",
      "Epoch 9910, Loss: 208.4897622554416, Neurons: 201, Grad norm: 1.8151205357888767\n",
      "Epoch 9910, Loss: 208.4897622554416, Neurons: 201, Grad norm: 1.8151205357888767\n",
      "Epoch 9911, Loss: 208.48968133739618, Neurons: 201, Grad norm: 1.857933121547193\n",
      "Epoch 9911, Loss: 208.48968133739618, Neurons: 201, Grad norm: 1.857933121547193\n",
      "Epoch 9912, Loss: 208.4896352625795, Neurons: 201, Grad norm: 1.4943526976017407\n",
      "Epoch 9912, Loss: 208.4896352625795, Neurons: 201, Grad norm: 1.4943526976017407\n",
      "Epoch 9913, Loss: 208.48963041348, Neurons: 201, Grad norm: 1.0675269749170544\n",
      "Epoch 9913, Loss: 208.48963041348, Neurons: 201, Grad norm: 1.0675269749170544\n",
      "Epoch 9914, Loss: 208.4895124631955, Neurons: 201, Grad norm: 1.0392416291452766\n",
      "Epoch 9914, Loss: 208.4895124631955, Neurons: 201, Grad norm: 1.0392416291452766\n",
      "Epoch 9915, Loss: 208.48948042446958, Neurons: 201, Grad norm: 1.4305036657735897\n",
      "Epoch 9915, Loss: 208.48948042446958, Neurons: 201, Grad norm: 1.4305036657735897\n",
      "Epoch 9916, Loss: 208.48943394825437, Neurons: 201, Grad norm: 2.4717028511010373\n",
      "Epoch 9916, Loss: 208.48943394825437, Neurons: 201, Grad norm: 2.4717028511010373\n",
      "Epoch 9917, Loss: 208.4894684889708, Neurons: 201, Grad norm: 3.1803223981427116\n",
      "Epoch 9917, Loss: 208.4894684889708, Neurons: 201, Grad norm: 3.1803223981427116\n",
      "Epoch 9918, Loss: 208.48946130386196, Neurons: 201, Grad norm: 3.8754119461857464\n",
      "Epoch 9918, Loss: 208.48946130386196, Neurons: 201, Grad norm: 3.8754119461857464\n",
      "Epoch 9919, Loss: 208.48946718575246, Neurons: 201, Grad norm: 3.6596530779844656\n",
      "Epoch 9919, Loss: 208.48946718575246, Neurons: 201, Grad norm: 3.6596530779844656\n",
      "Epoch 9920, Loss: 208.4894149787759, Neurons: 201, Grad norm: 3.854796608210781\n",
      "Epoch 9920, Loss: 208.4894149787759, Neurons: 201, Grad norm: 3.854796608210781\n",
      "Epoch 9921, Loss: 208.48925483565873, Neurons: 201, Grad norm: 3.709089906070471\n",
      "Epoch 9921, Loss: 208.48925483565873, Neurons: 201, Grad norm: 3.709089906070471\n",
      "Epoch 9922, Loss: 208.48915540060926, Neurons: 201, Grad norm: 3.507873073457452\n",
      "Epoch 9922, Loss: 208.48915540060926, Neurons: 201, Grad norm: 3.507873073457452\n",
      "Epoch 9923, Loss: 208.48903209376354, Neurons: 201, Grad norm: 3.626953801375489\n",
      "Epoch 9923, Loss: 208.48903209376354, Neurons: 201, Grad norm: 3.626953801375489\n",
      "Epoch 9924, Loss: 208.48892513627362, Neurons: 201, Grad norm: 4.09957148970691\n",
      "Epoch 9924, Loss: 208.48892513627362, Neurons: 201, Grad norm: 4.09957148970691\n",
      "Epoch 9925, Loss: 208.48899564627052, Neurons: 201, Grad norm: 5.401265264390952\n",
      "Epoch 9925, Loss: 208.48899564627052, Neurons: 201, Grad norm: 5.401265264390952\n",
      "Epoch 9926, Loss: 208.4890842059452, Neurons: 201, Grad norm: 6.556837681428335\n",
      "Epoch 9926, Loss: 208.4890842059452, Neurons: 201, Grad norm: 6.556837681428335\n",
      "Epoch 9927, Loss: 208.4892673501114, Neurons: 201, Grad norm: 8.295606131536893\n",
      "Epoch 9927, Loss: 208.4892673501114, Neurons: 201, Grad norm: 8.295606131536893\n",
      "Epoch 9928, Loss: 208.48947647091802, Neurons: 201, Grad norm: 10.653133639259504\n",
      "Epoch 9928, Loss: 208.48947647091802, Neurons: 201, Grad norm: 10.653133639259504\n",
      "Epoch 9929, Loss: 208.4898562097293, Neurons: 201, Grad norm: 12.594620367124286\n",
      "Epoch 9929, Loss: 208.4898562097293, Neurons: 201, Grad norm: 12.594620367124286\n",
      "Epoch 9930, Loss: 208.4902706905936, Neurons: 201, Grad norm: 14.177585201636104\n",
      "Epoch 9930, Loss: 208.4902706905936, Neurons: 201, Grad norm: 14.177585201636104\n",
      "Epoch 9931, Loss: 208.49061285036916, Neurons: 201, Grad norm: 15.675640591329978\n",
      "Epoch 9931, Loss: 208.49061285036916, Neurons: 201, Grad norm: 15.675640591329978\n",
      "Epoch 9932, Loss: 208.49082140535256, Neurons: 201, Grad norm: 15.875279311285853\n",
      "Epoch 9932, Loss: 208.49082140535256, Neurons: 201, Grad norm: 15.875279311285853\n",
      "Epoch 9933, Loss: 208.4908726201464, Neurons: 201, Grad norm: 15.14369976909139\n",
      "Epoch 9933, Loss: 208.4908726201464, Neurons: 201, Grad norm: 15.14369976909139\n",
      "Epoch 9934, Loss: 208.49070904920984, Neurons: 201, Grad norm: 13.980261156454334\n",
      "Epoch 9934, Loss: 208.49070904920984, Neurons: 201, Grad norm: 13.980261156454334\n",
      "Epoch 9935, Loss: 208.49024037343213, Neurons: 201, Grad norm: 12.388527630162974\n",
      "Epoch 9935, Loss: 208.49024037343213, Neurons: 201, Grad norm: 12.388527630162974\n",
      "Epoch 9936, Loss: 208.4897831617669, Neurons: 201, Grad norm: 9.900321611911965\n",
      "Epoch 9936, Loss: 208.4897831617669, Neurons: 201, Grad norm: 9.900321611911965\n",
      "Epoch 9937, Loss: 208.48924444289582, Neurons: 201, Grad norm: 8.304146626906963\n",
      "Epoch 9937, Loss: 208.48924444289582, Neurons: 201, Grad norm: 8.304146626906963\n",
      "Epoch 9938, Loss: 208.48857813535244, Neurons: 201, Grad norm: 6.269323487920162\n",
      "Epoch 9938, Loss: 208.48857813535244, Neurons: 201, Grad norm: 6.269323487920162\n",
      "Epoch 9939, Loss: 208.4882940381354, Neurons: 201, Grad norm: 4.586682590700158\n",
      "Epoch 9939, Loss: 208.4882940381354, Neurons: 201, Grad norm: 4.586682590700158\n",
      "Epoch 9940, Loss: 208.48803758671104, Neurons: 201, Grad norm: 3.2544376487562126\n",
      "Epoch 9940, Loss: 208.48803758671104, Neurons: 201, Grad norm: 3.2544376487562126\n",
      "Epoch 9941, Loss: 208.48772239934448, Neurons: 201, Grad norm: 1.9359346871393577\n",
      "Epoch 9941, Loss: 208.48772239934448, Neurons: 201, Grad norm: 1.9359346871393577\n",
      "Epoch 9942, Loss: 208.48768652219334, Neurons: 201, Grad norm: 1.5154189615402223\n",
      "Epoch 9942, Loss: 208.48768652219334, Neurons: 201, Grad norm: 1.5154189615402223\n",
      "Epoch 9943, Loss: 208.4876505027555, Neurons: 201, Grad norm: 1.0267761434062084\n",
      "Epoch 9943, Loss: 208.4876505027555, Neurons: 201, Grad norm: 1.0267761434062084\n",
      "Epoch 9944, Loss: 208.48752073179, Neurons: 201, Grad norm: 0.9850422724513616\n",
      "Epoch 9944, Loss: 208.48752073179, Neurons: 201, Grad norm: 0.9850422724513616\n",
      "Epoch 9945, Loss: 208.48734594221605, Neurons: 201, Grad norm: 1.0071798624208643\n",
      "Epoch 9945, Loss: 208.48734594221605, Neurons: 201, Grad norm: 1.0071798624208643\n",
      "Epoch 9946, Loss: 208.48737787975418, Neurons: 201, Grad norm: 0.9274401078324217\n",
      "Epoch 9946, Loss: 208.48737787975418, Neurons: 201, Grad norm: 0.9274401078324217\n",
      "Epoch 9947, Loss: 208.48736978514023, Neurons: 201, Grad norm: 0.9887969338840762\n",
      "Epoch 9947, Loss: 208.48736978514023, Neurons: 201, Grad norm: 0.9887969338840762\n",
      "Epoch 9948, Loss: 208.48722452458344, Neurons: 201, Grad norm: 1.1788368026214893\n",
      "Epoch 9948, Loss: 208.48722452458344, Neurons: 201, Grad norm: 1.1788368026214893\n",
      "Epoch 9949, Loss: 208.4870785260064, Neurons: 201, Grad norm: 1.6285230217813969\n",
      "Epoch 9949, Loss: 208.4870785260064, Neurons: 201, Grad norm: 1.6285230217813969\n",
      "Epoch 9950, Loss: 208.48702947240173, Neurons: 201, Grad norm: 2.4291770095611804\n",
      "Epoch 9950, Loss: 208.48702947240173, Neurons: 201, Grad norm: 2.4291770095611804\n",
      "Epoch 9951, Loss: 208.48698955763822, Neurons: 201, Grad norm: 3.020238530320473\n",
      "Epoch 9951, Loss: 208.48698955763822, Neurons: 201, Grad norm: 3.020238530320473\n",
      "Epoch 9952, Loss: 208.4869876960479, Neurons: 201, Grad norm: 4.1621507071862665\n",
      "Epoch 9952, Loss: 208.4869876960479, Neurons: 201, Grad norm: 4.1621507071862665\n",
      "Epoch 9953, Loss: 208.4869447008453, Neurons: 201, Grad norm: 5.343502960656402\n",
      "Epoch 9953, Loss: 208.4869447008453, Neurons: 201, Grad norm: 5.343502960656402\n",
      "Epoch 9954, Loss: 208.48696492326607, Neurons: 201, Grad norm: 6.097023940945239\n",
      "Epoch 9954, Loss: 208.48696492326607, Neurons: 201, Grad norm: 6.097023940945239\n",
      "Epoch 9955, Loss: 208.48702592192154, Neurons: 201, Grad norm: 7.145256958835718\n",
      "Epoch 9955, Loss: 208.48702592192154, Neurons: 201, Grad norm: 7.145256958835718\n",
      "Epoch 9956, Loss: 208.48705128249443, Neurons: 201, Grad norm: 8.743328650014696\n",
      "Epoch 9956, Loss: 208.48705128249443, Neurons: 201, Grad norm: 8.743328650014696\n",
      "Epoch 9957, Loss: 208.48716731714006, Neurons: 201, Grad norm: 9.609181180556613\n",
      "Epoch 9957, Loss: 208.48716731714006, Neurons: 201, Grad norm: 9.609181180556613\n",
      "Epoch 9958, Loss: 208.48733591442632, Neurons: 201, Grad norm: 10.597111806981049\n",
      "Epoch 9958, Loss: 208.48733591442632, Neurons: 201, Grad norm: 10.597111806981049\n",
      "Epoch 9959, Loss: 208.487580907104, Neurons: 201, Grad norm: 11.759087710685293\n",
      "Epoch 9959, Loss: 208.487580907104, Neurons: 201, Grad norm: 11.759087710685293\n",
      "Epoch 9960, Loss: 208.48789445094644, Neurons: 201, Grad norm: 12.656209507705553\n",
      "Epoch 9960, Loss: 208.48789445094644, Neurons: 201, Grad norm: 12.656209507705553\n",
      "Epoch 9961, Loss: 208.48829079756973, Neurons: 201, Grad norm: 13.340407211725543\n",
      "Epoch 9961, Loss: 208.48829079756973, Neurons: 201, Grad norm: 13.340407211725543\n",
      "Epoch 9962, Loss: 208.48857849123283, Neurons: 201, Grad norm: 13.676307826125504\n",
      "Epoch 9962, Loss: 208.48857849123283, Neurons: 201, Grad norm: 13.676307826125504\n",
      "Epoch 9963, Loss: 208.48885308927922, Neurons: 201, Grad norm: 14.112445505482615\n",
      "Epoch 9963, Loss: 208.48885308927922, Neurons: 201, Grad norm: 14.112445505482615\n",
      "Epoch 9964, Loss: 208.4889369187938, Neurons: 201, Grad norm: 14.329905584428793\n",
      "Epoch 9964, Loss: 208.4889369187938, Neurons: 201, Grad norm: 14.329905584428793\n",
      "Epoch 9965, Loss: 208.48877988617474, Neurons: 201, Grad norm: 14.032817112421448\n",
      "Epoch 9965, Loss: 208.48877988617474, Neurons: 201, Grad norm: 14.032817112421448\n",
      "Epoch 9966, Loss: 208.4884560481456, Neurons: 201, Grad norm: 13.799454010584645\n",
      "Epoch 9966, Loss: 208.4884560481456, Neurons: 201, Grad norm: 13.799454010584645\n",
      "Epoch 9967, Loss: 208.488023717099, Neurons: 201, Grad norm: 13.257193140419911\n",
      "Epoch 9967, Loss: 208.488023717099, Neurons: 201, Grad norm: 13.257193140419911\n",
      "Epoch 9968, Loss: 208.48758533684503, Neurons: 201, Grad norm: 11.665303577454683\n",
      "Epoch 9968, Loss: 208.48758533684503, Neurons: 201, Grad norm: 11.665303577454683\n",
      "Epoch 9969, Loss: 208.48706847066774, Neurons: 201, Grad norm: 9.441249310389372\n",
      "Epoch 9969, Loss: 208.48706847066774, Neurons: 201, Grad norm: 9.441249310389372\n",
      "Epoch 9970, Loss: 208.48649622494247, Neurons: 201, Grad norm: 6.2668836998642545\n",
      "Epoch 9970, Loss: 208.48649622494247, Neurons: 201, Grad norm: 6.2668836998642545\n",
      "Epoch 9971, Loss: 208.48595640075058, Neurons: 201, Grad norm: 3.3453422521485043\n",
      "Epoch 9971, Loss: 208.48595640075058, Neurons: 201, Grad norm: 3.3453422521485043\n",
      "Epoch 9972, Loss: 208.48559692624727, Neurons: 201, Grad norm: 1.0170435978740346\n",
      "Epoch 9972, Loss: 208.48559692624727, Neurons: 201, Grad norm: 1.0170435978740346\n",
      "Epoch 9973, Loss: 208.4854175430355, Neurons: 201, Grad norm: 2.965366934994364\n",
      "Epoch 9973, Loss: 208.4854175430355, Neurons: 201, Grad norm: 2.965366934994364\n",
      "Epoch 9974, Loss: 208.48541871824494, Neurons: 201, Grad norm: 4.613873580259816\n",
      "Epoch 9974, Loss: 208.48541871824494, Neurons: 201, Grad norm: 4.613873580259816\n",
      "Epoch 9975, Loss: 208.48547446929064, Neurons: 201, Grad norm: 6.540845004288356\n",
      "Epoch 9975, Loss: 208.48547446929064, Neurons: 201, Grad norm: 6.540845004288356\n",
      "Epoch 9976, Loss: 208.48563951928665, Neurons: 201, Grad norm: 7.937883181643939\n",
      "Epoch 9976, Loss: 208.48563951928665, Neurons: 201, Grad norm: 7.937883181643939\n",
      "Epoch 9977, Loss: 208.4857357045248, Neurons: 201, Grad norm: 8.532404118835844\n",
      "Epoch 9977, Loss: 208.4857357045248, Neurons: 201, Grad norm: 8.532404118835844\n",
      "Epoch 9978, Loss: 208.48578210122182, Neurons: 201, Grad norm: 8.601850873877003\n",
      "Epoch 9978, Loss: 208.48578210122182, Neurons: 201, Grad norm: 8.601850873877003\n",
      "Epoch 9979, Loss: 208.48579603828057, Neurons: 201, Grad norm: 8.728301319453035\n",
      "Epoch 9979, Loss: 208.48579603828057, Neurons: 201, Grad norm: 8.728301319453035\n",
      "Epoch 9980, Loss: 208.48587700623997, Neurons: 201, Grad norm: 9.149963659106636\n",
      "Epoch 9980, Loss: 208.48587700623997, Neurons: 201, Grad norm: 9.149963659106636\n",
      "Epoch 9981, Loss: 208.48622498233033, Neurons: 201, Grad norm: 9.833106637780137\n",
      "Epoch 9981, Loss: 208.48622498233033, Neurons: 201, Grad norm: 9.833106637780137\n",
      "Epoch 9982, Loss: 208.48662610135668, Neurons: 201, Grad norm: 10.629782908109943\n",
      "Epoch 9982, Loss: 208.48662610135668, Neurons: 201, Grad norm: 10.629782908109943\n",
      "Epoch 9983, Loss: 208.48697198603, Neurons: 201, Grad norm: 11.704679140833539\n",
      "Epoch 9983, Loss: 208.48697198603, Neurons: 201, Grad norm: 11.704679140833539\n",
      "Epoch 9984, Loss: 208.48692196575004, Neurons: 201, Grad norm: 12.418977986460922\n",
      "Epoch 9984, Loss: 208.48692196575004, Neurons: 201, Grad norm: 12.418977986460922\n",
      "Epoch 9985, Loss: 208.48662469303034, Neurons: 201, Grad norm: 12.830134315764683\n",
      "Epoch 9985, Loss: 208.48662469303034, Neurons: 201, Grad norm: 12.830134315764683\n",
      "Epoch 9986, Loss: 208.4863478514831, Neurons: 201, Grad norm: 12.731658168956686\n",
      "Epoch 9986, Loss: 208.4863478514831, Neurons: 201, Grad norm: 12.731658168956686\n",
      "Epoch 9987, Loss: 208.48620634009126, Neurons: 201, Grad norm: 11.693508259210724\n",
      "Epoch 9987, Loss: 208.48620634009126, Neurons: 201, Grad norm: 11.693508259210724\n",
      "Epoch 9988, Loss: 208.48577832416214, Neurons: 201, Grad norm: 10.02357038597946\n",
      "Epoch 9988, Loss: 208.48577832416214, Neurons: 201, Grad norm: 10.02357038597946\n",
      "Epoch 9989, Loss: 208.48527999481485, Neurons: 201, Grad norm: 7.205693529936604\n",
      "Epoch 9989, Loss: 208.48527999481485, Neurons: 201, Grad norm: 7.205693529936604\n",
      "Epoch 9990, Loss: 208.4848219581603, Neurons: 201, Grad norm: 4.664814454073889\n",
      "Epoch 9990, Loss: 208.4848219581603, Neurons: 201, Grad norm: 4.664814454073889\n",
      "Epoch 9991, Loss: 208.4844492478512, Neurons: 201, Grad norm: 2.212107679605955\n",
      "Epoch 9991, Loss: 208.4844492478512, Neurons: 201, Grad norm: 2.212107679605955\n",
      "Epoch 9992, Loss: 208.48424992260234, Neurons: 201, Grad norm: 2.6980757630929677\n",
      "Epoch 9992, Loss: 208.48424992260234, Neurons: 201, Grad norm: 2.6980757630929677\n",
      "Epoch 9993, Loss: 208.4843180288807, Neurons: 201, Grad norm: 4.258943410867129\n",
      "Epoch 9993, Loss: 208.4843180288807, Neurons: 201, Grad norm: 4.258943410867129\n",
      "Epoch 9994, Loss: 208.4845538314213, Neurons: 201, Grad norm: 5.281659449654719\n",
      "Epoch 9994, Loss: 208.4845538314213, Neurons: 201, Grad norm: 5.281659449654719\n",
      "Epoch 9995, Loss: 208.48446813980087, Neurons: 201, Grad norm: 5.2874424472137385\n",
      "Epoch 9995, Loss: 208.48446813980087, Neurons: 201, Grad norm: 5.2874424472137385\n",
      "Epoch 9996, Loss: 208.48423366762603, Neurons: 201, Grad norm: 5.827634425471901\n",
      "Epoch 9996, Loss: 208.48423366762603, Neurons: 201, Grad norm: 5.827634425471901\n",
      "Epoch 9997, Loss: 208.48414687497757, Neurons: 201, Grad norm: 6.271514255018506\n",
      "Epoch 9997, Loss: 208.48414687497757, Neurons: 201, Grad norm: 6.271514255018506\n",
      "Epoch 9998, Loss: 208.48414083815462, Neurons: 201, Grad norm: 7.36103561762552\n",
      "Epoch 9998, Loss: 208.48414083815462, Neurons: 201, Grad norm: 7.36103561762552\n",
      "Epoch 9999, Loss: 208.4843220518496, Neurons: 201, Grad norm: 8.41401394389421\n",
      "Epoch 9999, Loss: 208.4843220518496, Neurons: 201, Grad norm: 8.41401394389421\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    loss, mlp, opt_state = train_step(mlp, x, y, opt_state, opt.update)\n",
    "    _, grads  = compute_loss(mlp, x, y)\n",
    "    grad_norm_val = grad_norm(grads)\n",
    "    key, add_key, sub_key = jax.random.split(key,3)\n",
    "    n_neurons = sum(mlp.get_shape())\n",
    "    logging.info(f\"Epoch {epoch :03d}, Loss: {loss.item()}, Neurons: {n_neurons}, Grad norm: {grad_norm_val}\")\n",
    "    wandb.log({\"loss\": loss.item(), \"neurons\": n_neurons})\n",
    "    Loss_history.append(loss)\n",
    "    Node_history.append(n_neurons)\n",
    "    grad_norm_history.append(grad_norm_val)\n",
    "        \n",
    "    if loss < threshold or grad_norm_val < 1e-6:\n",
    "        # if loss is below threshold, stop training\n",
    "        logging.info(f\"Threshold reached, stopping training at epoch {epoch}\")\n",
    "        wandb.log({\"threshold reached\": epoch})\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f\"{out_folder}/neurons.txt\", Node_history)\n",
    "np.savetxt(f\"{out_folder}/loss.txt\", Loss_history)\n",
    "np.savetxt(f\"{out_folder}/grad_norm.txt\", grad_norm_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/UAAAI7CAYAAACtLruJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOz9eZQcx5UfCv+quwFwQwOaXX5seuyxOX5s6DvvvE/v+BDy92x/ok2Q53nsocdqfeOxh5AEcRaLmAUYz0L2jCHNjEbASAK1jQhK1C40JUESJQENiRIpSmyQAhdRQEPcwAUFElywdFejgV6qMr8/MiPzxr03sjKrsrqrG/HToQpdlRl5IzLixt2jEoZhCA8PDw8PDw8PDw8PDw8PjyWHnsUmwMPDw8PDw8PDw8PDw8PDozV4pd7Dw8PDw8PDw8PDw8PDY4nCK/UeHh4eHh4eHh4eHh4eHksUXqn38PDw8PDw8PDw8PDw8Fii8Eq9h4eHh4eHh4eHh4eHh8cShVfqPTw8PDw8PDw8PDw8PDyWKLxS7+Hh4eHh4eHh4eHh4eGxROGVeg8PDw8PDw8PDw8PDw+PJQqv1Ht4eHh4eHgsGYyPj2N0dHSxyfDw8PDw8OgaeKXew8PD4wJBrVbD2NjYYpPh4dEyhoeHcfjwYQwODmLjxo2LTY6Hh4eHh0dXoG+xCfDw8PDoBEZGRjA6Opoose94xzuwdevWXPfWajW8+c1vRq1Ww8DAAAYGBrBz50709/cDAHbt2oWxsTEcPnwYtVoN/f39WLduHQYGBrBt27bMts29hi7TvsHk5CQA4PLLL8dNN92EwcHBwn13YWRkBCMjI7jnnntKa3M5wiiLd9555yJT0jqWQx84du3ahYmJCQwNDSVraHx8vNQ14rFwoHwUANasWYOBgQGsXr0aADA1NQUAqFarCV985zvfiU2bNi0OwSViOa5PDw+PRUbo4eHhsYzxvve9L7zxxhvDN77xjbnv2b17d3jjjTeGV155ZeZ1t956a3jllVeGDzzwQEt0XXnlleHhw4fV3x944IHwjW98Y/iud72rcNsuvPnNb858pkeEN7/5zYXmy2Lgfe97X+bvS6EPRUHX2uHDh8Mbb7wxnJyc7Mizmo1v3mu6Ad1Op+GjWXxp37594Rvf+Mbw1ltvXUDKWseFuD49PDwWFz783sPDY1lj7dq1GBoaKhR6XqvVEm9RFsw1a9asaYkuAIn3n2P9+vX41Kc+hf3792P79u2F2+cYHx/HVVddBQDYu3dv2+0tZ9xzzz04ePDgYpORiWq1mvn7UuhDEZj+rlu3DgAwODiIO++807l+ynpeu9d0A7qdzjy8dsOGDdi5cycmJiY6T1AJuNDWp4eHx+LDK/UeHh7LHuvXr0d/fz92797d9Npqtdo14byDg4MYHBzEHXfcgVqt1lZbe/fuxXve8x709/fjrrvuKolCj8XCkSNHFpuEBYVRkjqlxHPkGd+l8g6WCp3NsH79+sUmITeWy5h7eHgsHXil3sPDY9mjv78fb3nLW7B///6myvHY2FhXCY+XX345ALRd4G5qaioZB18wb2ljbGys672vSxl5xnepvIOlQmde0Poj3YrlNuYeHh5LA16p9/DwuCDw1re+FQCwb9++RaakGEyxqHaE2bGxMWzYsAFAOg7+SLCliWq1is2bNy82GcsWecZ3qbyDpUJnFrgR1qQtdSuWw5h7eHgsTfjq9x4eHhcEBgYGMDg4iJGREQwNDanXdJuXHgAOHz6M/v7+tlICRkdHk6r8ptr+yMiIs1K/EUxrtRomJydx8OBBjI6O4tChQwAiQ8PAwICoQl3GfUCUbzo6OopqtYpDhw7h+uuvT4wS5vrdu3fjiiuuQK1Ww8TEBK6//nprjIaHhy2P2dDQkNXf7du344477gAQRXLs3LkT69evx8aNG1GtVlGtVvHkk08m19dqNdx4442o1WrJb+Pj40nEw6FDhzAwMJCcsGAqs5t/r1+/PrNq98jISNL/arWqjpM50WHNmjWo1WrWkW60fVcf+Jg3G8Nmfa5Wq1i9enXuUyVaoWFsbAy7du1Kqp/TPhepHF7W+Oa5puh8zksfxfj4OEZGRjAwMJDkmb/pTW9K+FfeuWKQ51200q928fGPf9yaX0NDQ7jhhhuSOXnw4MEkJYPSV3T95pnLZY35UlmfHh4eSwyLXanPw8PDo5O4/fbbk3/v3r07vPLKK8Njx46p1+7evTv597ve9a6m1e+bVbBvRlcWLZTeVqrrU/BKzObZ+/bty7zPVKXevXu3oPNd73pX+Ou//utq9fF27nvjG98Y7tu3LxnTN77xjeGNN96YXLNv3z7rb9oufdf0e22cjx075hxb81410Erd/N43v/nN4fve977wgQceUH+j84vi9ttvF+Pxvve9L3zzm9+sXm/mRRay+lB0DPP0uSiK0vDAAw807bMLnRjfPNfkmc+t0qetIW3e5aGzlfmQp195kcVHXad/mHs0PpLFu1udy2WPebevTw8Pj6UHH37v4eFxweC6664DgFwF8xYLtVoN4+PjGB4exsjICO688862ogdGR0dx/fXXW9+ZSIWRkZHMe41XaN26dSL8/7bbbkO1WsWOHTtKv48WK/zUpz6VeNiNJ27nzp3i3ttuuw0jIyOiVsBtt92GgYEBDA8PW9+Pjo5iz5496ti+6U1vEt8ZmOu1qI5rr70Wd911F6rVqvht/fr16njXajXcfvvtIi1k69atqFarTd+RC64+tDKGzfq8f//+QrS1QkOr6NT45kGz+dwKfdVqFcPDw9iyZYsoGrh7927s2rWrEI2tvIs8/WoXtVoNu3btwvHjx9Xf3/CGNzjvbWf9anO57DHPorEb1qeHh8fShFfqPTw8Lhj09/dj/fr1avX30dHRROlfSGzfvt367+Mf/zgOHz6MoaEhp9JZBGNjYyJ034zD2NhYZuFAc1SfK/T/ne98J0ZGRkRRqHbuq9VqVp8HBwcTw8Dw8HBykoGGa6+9VijvQBSmbcK4gSiM1qRjtArtXhMqa45doxgYGMgsnqW9h4GBARw7dqxlGjW0OoaAu89Fi4K1Q0OrWKjxpWg2n1uhb3h4GAMDAypfMPU3iqCVd1GkX0Vw6623YuPGjdi4cSNuvPFG1fBXForM5bLHPAvdsD49PDyWJrxS7+HhcUHBdWb95OTkgh2XRXHTTTdh69at1n9DQ0OlHKtXq9WcgrbJfW2ncKChsahXtdl9Lpqb1Tx4wxvekOSq8va2bduGHTt2YGxsDHv37m079zdLgSny7vr7+3Hw4MHM/Oky0eoYAuVVHm+HhqJY6PHVkDVuRek7fPgwrrrqKvW3O++8s1CdAaA75oPBu9/97qQPe/bswT333FNq+xRFaC97zLPQTe/Dw8NjacEXyvPw8LigsGHDhuTMeiM8ZSm/ZcAUMipDUS+Cffv2YWxsLFPpzioc2AxmzIp6O5vdpxlXTNG5LMMLLZjF3+fQ0BAeeOABbNy4EQcPHixErwYTjVAmRkdHMTY2hoGBAfT39yfF4cpCu2NYRp/bpaEddHp8XchrLGxGX61WQ61WK60CfLvvotNG0IGBAVx99dUdaTvvXC57zLPQDevTw8Nj6cIr9R4eHhccrrvuOitXdd++fS0rtnlw+PDhRRG4xsfHM71IN998M/bv31+68tRJZKULmN9c17zhDW/AgQMHsGPHjlLzf9vFyMgIduzYgS1btlh0tZKrmwftjOFSpGGhx7co8tJnFDpTeb0sdMN8cCErd34h0Kkxz0I3vw8PD4/uhQ+/9/DwuOCQt1BcWahWqwse2p8nMsAU0Gv1zHoTAlpU8G7lPtOXLOHaeDa1fo+Pj6O/vx+f+tSnkqOnugGjo6MYHh7Gzp072zIsmaPFstDuGJaBhaZhIcc3zzXt0jcwMOAsHlfkmZQ/LOZ8aIayj8hrBWWOeRaWwvvw8PDoXnil3sPD44KDKeo0MjKC8fFxtbBZmTBnGy8k8hT+M6kIrRo3HnjgAQDFBcxW7xscHMSRI0cy2+3v7xdjXavVsHfv3qRWwZYtW7B58+auKCB1++23J4ULOWj49djYWFN680SDtDqGZWIhaVjo8S0akVOUvvXr1ydh2hrGx8dzeXFpMcvFng+tIMtImjU+raDsMc/CUn0fHh4eiw+v1Ht4eFyQGBoawvj4OPbu3dtRr8f4+HjpQmYe5I0OuO6661CtVpsKrRruuusuvOMd73AKmK3e58K73/3uzIr9Bw4cwLvf/W7x/Y4dO7B169bk702bNmFwcBCbN28u9PxOoFqtqkalarWKWq2WVNemfTbjRr/L+75bHcMysZA0dGp823kH7dBnjlVzpQ7s3bu3EJ3dMB9aQZaCfPjw4VKfVfaYZ2Gpvg8PD4/Fh1fqPTw8ljX27dunhlqbUFdXAaQ8RxWZa1wFt8bGxnDjjTeqyqsJsexEsa5du3bl9kIbD2GWt14TMjdu3Ih169ZZynK79zUbi8HBQWzbtg033nij+G14eBhvectbrHDdWq2Gm2++WW1r586dGB8fx/bt28VvreatZl0/MTGh/v6Wt7xFHafR0VFs2bIleY+07sH69esxMDCQeXKBqw9Fx7AZWsntbYWGVt9Jp8Y3zzV51nZR+vr7+7Fz507cfvvtwmg2OjqapNTkpbOVd1E2z2rGRzWYaCver5GRkSRCqWgkjmtulT3m9FnduD49PDyWJiphGIaLTYSHh4dH2di1a5d1Fvrg4CA+9alPWd6S4eHhxAtjsH37dhw5ciSpGD84OIjLL78c73nPe5Lrdu3aZVWVHxgYwMDAAFavXo2pqSlMTk4mnjbTxp49ewAgyec+fPhwUnX/qquuwk033dR2xMDY2BiGh4etPpvnarj55ptx4MCBhM7169fjqquuShTu0dFRbN68GU8++SRGR0cxOTlpVfJ35QAXva9arWJ4eDgZEzPmW7duVQ0iJsLCnAs/MTGBN73pTVYI8w033JC8A3NsGO/7/v37k3G6+uqrcdNNN2Hz5s0WHddddx02bdqEWq1m/WbOrd62bZtK/9VXX42tW7difHwcO3bsUNs0MPOJnk9tjl7cvHkzVq9ejbe+9a1W/8wzr7rqKqxduxZDQ0Po7+8XdGrPyzuGrfY5L1qloeh6KXN8KVzXFJ3PrdK3a9curF69GldccQWAVJnkyNOXPO+iaL+awfTbtNff349169YlR1A2Q7Vaxfbt2zEwMGCNwfj4ODZv3mzN1zLmchljvpTWp4eHx9KCV+o9PDw8PFRQ5Xwh7vPw8PDw8PDw8CgOH37v4eHh4eHh4eHh4eHh4bFE4ZV6Dw8PDw8PDw8PDw8PD48lCq/Ue3h4eHioaLUgVieK/3l4eHh4eHh4eOjwOfUeHh4eHha0Ikvr1q1rWryq1fs8PDw8PDw8PDxah1fqPTw8PDw8PDw8PDw8PDyWKHz4vYeHh4eHh4eHh4eHh4fHEkXfYhPQ7Th9+jR++MMf4vLLL8eqVasWmxwPDw8PDw8PDw8PDw+PZY7Z2VkcP34c/+pf/Sv8zM/8TOa1Xqlvgh/+8IfYunXrYpPh4eHh4eHh4eHh4eHhcYFh+/bt+LVf+7XMa7xS3wSXX345gGgwf+VXfmWRqfHw8PDw8PDw8PDw8PBY7jh69Ci2bt2a6KNZ8Ep9E5iQ+1/5lV/B4ODgIlPj4eHh4eHh4eHh4eHhcaEgTwq4L5Tn4eHh4eHh4eHh4eHh4bFE4ZV6Dw8PDw8PDw8PDw8PD48lCq/Ue3h4eHh4eHh4eHh4eHgsUXil3sPDw8PDw8PDw8PDw8NjicIr9R4eHh4eHh4eHh4eHh4eSxReqffw8PDw8PDw8PDw8PDwWKLwSr2Hh4eHh4eHh4eHh4eHxxKFV+o9PDw8PDw8PDw8PDw8PJYo+habgAsBYRgm/3l4eCxvVCqV5D8PDw8PDw8PDw+PTsMr9R1CGIaYnJxErVbD9PT0YpPj4eGxwLj00kvR39+PNWvWeAXfw8PDw8PDw8OjY/BKfQcQhiFOnDiBc+fO4Wd+5mfwi7/4i+jr80Pt4XGhoF6vY3p6GidPnsS5c+fw+te/3iv2Hh4eHh4eHh4eHYHXNDuAyclJnDt3Dr/8y7/slXkPjwsQvb29WLVqFfr7+/H8889jcnISa9euXWyyPDw8PDw8PDw8liF8obwOoFar4Wd+5me8Qu/hcYGjr68Pr3vd61Cr1RabFA8PDw8PDw8Pj2UKr9SXjDAMMT09jUsvvXSxSfHw8OgCXHbZZZienvaFMj08PDw8PDw8PDoCr9SXDCO4ey+9h4cHkPICr9R7eHh4eHh4eHh0Al6pLxlecPfw8NDgeYOHh4eHh4eHh0cn4JV6Dw8PDw8PDw8PD49cmJqewXy9sdhkeHh4EHil3sPDw8PDw8PDw8MjF675nY/iP2/55GKT4eHhQeCVeg8PDw8PDw8PDw+P3Hjl1NRik+Dh4UHgq7l5dBWuueYaTE5OYmBgAJdffnny/YEDBwAA69atw+rVqwEAx48fR7VaBQDs2bMHAwMDC0+wh4eHh4eHh4eHh4fHIsIr9R5dhWq1ip07d2LDhg3W9xs3bsTY2BjuvPNO6/vx8XHceOONqFary0apHx8fx+DgYNvXLBa6mTYPDw8PDw8PDw+P5QYffu/RNajVarj22muFQg8Aq1evRn9/v/h+cHAQW7ZsQa1WWwgSFwR79+4t5ZrFQjfT5uHh4eHh4eHh4bHc4JV6j67B5OQkrr/++sL3XXfddZicnOwARYsDk1LQ7jWLhW6mzcPDw8PDw8PDw2O5wSv1Hl2DWq3WUgh9f3//svHUj4yMlHLNYqGbafPw8PDw8PDw8PBYjvBKvUfXoL+/v+W8+OWQwz0+Po4dO3a0fc1ioZtp8/Dw8PDw8PDw8Fiu8IXyPLoGrSr01WoVO3bsQLVaxVve8hbcdNNNGBkZwcTEBKamprBt2zZUq1Vs3rwZ1WoV69atswruDQ8PY2xsDNVqFQcPHhS5+7t27Uq+O3bsGN70pjdh/fr1uemr1WoYGRlJ2hgfH8emTZus/o6OjmLv3r1Ys2YNDhw4gJtvvjn57bbbbst9De2nayyK0EUxOjqKQ4cOYe3atZiYmMAVV1yBoaGh3LRRjIyMoFarJc+u1WrYtGlT8nuRfmj41V/9VQwODuLqq6/GFVdckXxv3uWePXsy7/fw8PDw8PDw8PBYKqiEYRguNhHdjPHxcdxwww3Ys2dPLm9wo9HAU089hSuvvBK9vb3O6z53+334/ncOl0nqouBf/7t1+K13/puOP+fmm2/GgQMHcPDgQec1GzduxMDAAAYGBrBp0yaMjIxgeHgYTz75pHUNAFFFf3R0FJs3bxZK/Q033IAtW7ZYSvwNN9yAoaGhRKFthu3bt2Pr1q3J39VqNZlTXIEeHh7GxMSEqggXuSbPWBSlC4ClTFerVYyOjlrKeB7abr75Zlx//fVWQUTj5efvJU8/NJh+UIyNjWHjxo2513JZyMsTPDw8PDw8lgL+5X97PwDgoc/+0SJT4uGxvFFED/Xh9x7LBgMDA9i3b1+iLA4NDQkjwFVXXeW8l2P79u1Ys2aN8Mpv2bIld5j5+Pg4Dhw4YBWPGxgYwLp167Br165cbbSCZmNRhK7R0VHs27dPeMfHx8cL59CPjIxgampKnHAwODiIgYEBbN++vVA/NNRqNWFwqdVq2Lx5M7Zs2bIsUjU8PDw8PDw8PDw8DHz4/SLht975bxbEw32hYc2aNZaCrh2Dp0G77o477sCWLVvE9+vWrUOtVst9Hnu1WhWF/K666iocOXIkF22totlY5KVrx44duO6660T71Wq18KkDO3bsUMcUADZs2ICNGzfipptusmgt+k4nJyeFkeaWW25JvP0eHh4eHh4eHh4eywleqfdYVmg1L5/DeLAnJiYwOjrqvKaZUj84OGh5lqvVKqrVKo4cOdLxY/iyxqIIXdVqVW1r06ZNhZRkY0Rw0bVu3ToAwOHDh63oiKLv1ITrG4yOjmL//v245557CrXj4eHh4eHhYcNn7Xp4dCe8Uu+xrLB69epS2jFK/fXXX68q7s1yunlbJqR9/fr1WL9+Pa666iocOHCgFFpdaDYWeegy45A34qHZ84DI856F8fFxS6lv553WajXceuut2LJlS2kGHw8PDw8PjwsVXqf38OhO+Jx6Dw9AhKEbBbBdb7opcLF+/Xps27YNGzZsKKwguyIFil7TCl1mHPj4FIGhrdmYmu/LVL43b94swu7Hx8dLa9/Dw8PDw+NCQgiv1Xt4dCO8Uu/hAaloDgwMoL+/P1MBzKPo7tixA+vWrROF4Si03Hb+ezPkuaZVugYGBnDo0KFC7Wu0GWXdRav5vqxCdiMjIxgbG8POnTut78fGxkpp38PDw8PD40KD99R7eHQnvFLvcUFh7dq1qqf4gQceEN9t2bLFWd19dHQ0lxd/bGxMrbhPi9HRgnOrV6/G8ePHrWu55zrPNWXStWXLFuzfv181PIyOjlpKejPatmzZ4owqGB0dxdDQUCme+lqthuHhYWzbtk20V9QA4uHh4eHh4RHDa/UeHl0Jr9R7LAlMTU21FQJusGHDBqHUVatVrF27Nvm3wdDQEK666qrkjHZ6vVZhXcP69etFNfnx8XEMDQ0lz6KF6K6//nqLhtHRUXGkXp5ryqRrw4YNuPbaa3HLLbdY19dqNTEOzWgzYfDcWDI6OorDhw87K+MXxebNm7F+/XpxtF21WsXhw4dLeYaHh4eHh8eFBqrS+6J5Hh7dg0roV2QmTO7xnj17coUFNxoNPPXUU7jyyivR29u7ABQuX4yNjWH37t2YmppKQqYHBwdx+eWX4w1veEOiIFarVWzfvj0p8Hb11VfjTW96k1DoDEZHRzE2NobBwcGkaNvg4CCuueYaDAwM4Nprr8XWrVuT60dGRnDs2DGsXbs2UWCzwtYparVacqa9mT/r1q3D4OAghoeHMTExgeuvv95qb2RkJDkub82aNeqzXNfkHYt26KLV5YvQxq8xY2pA896LvlOK0dFRbN68Ge94xztwxRVXJP09dOgQ9u/fj8HBQezZs6dpO2XB8wQPDw8Pj+WCufk6/j9vuw0A8MCdm9HX5/c1D49OoYge6pX6JvBKvYeHRzvwPMHDw8PDY7lgZm4e//rtHwIAfP8T78JFK1csMkUeHssXRfRQH37v4eHh4eHh4eHh4dEcxBVYbwSLR4eHh4cFr9R7eHh4eHh4eHh4eDQFje998zs/gu8+9NTiEePh4ZHAK/UeHh4eHh4eHh4eHk3Bz6n/1DceWiRKPDw8KLxS7+Hh4eHh4eHh4eHRFLwS1wpfKM/DoyvglXoPDw8PDw8PDw8Pj6bgnnqv1Ht4dAe8Uu/h4eHh4eHh4eHh0RzMU7/SK/UeHl0Br9R7eHh4eHh4eHh4eDRFwOLv/Tn1Hh7dAa/Ue3h4eHh4eHh4eHg0RciU+pUrvFLv4dEN8Eq9h4eHh4eHx4Jg8sw05ubqi02Gh4dHq/CF8jyWEO7Y+W2M3ffEYpOxIPBKvYeHh4eHh8eC4Kahj+Jj2/cuNhkeHh4tgun0Xqn36Gp86TMP4J5v/nixyVgQeKXew8PDw8PDY0Fw5tRZTJyeXmwyPDw8WgQPv/dKvUe3Iwi4KWp5wiv1Hh4eHh4eHguGC0XA8vBYjpDn1HtVwqM7YQxQ3BC1XOFXooeHh4eHh8eCwSv1Hh5LF/yc+pUr+haJEg+PbBhl/kLZc7xS7+Hh4eHh4dFxXGheEw+P5Qgffr/88OD9T6L6/MnFJqNjuFD2HK/Ue3h4eHh4eHQcF5rXxMNjOcKH3y8vhGGId28dwRfu+P5ik4L7vn0YE6fPltaemasXyp7jV6KHh4eHh4fHgiG8QAQsD4/lCO+pX14IghD1emPRjxp9+aUz+Ns/+xK++eWHy2vURIddIHuOT4Tx6Brs2rULY2NjGBsbAwAcPHgQ/f39Te8bHR3F5s2b0d/fj6uvvhpvfetbsX79+qTNQ4cOYf/+/QCA9evXY/Xq1di6dSsGBgZy03Lttddav09NTWH16tXWs5YqhoeHMTY2hmq1iieffHKxyfHw8FimSLwmSywU8pUTE9j2x7vxR3/5H/Erv/r6xSbHw2NRwVdvb4/3Dy5pdIniOzcbGRXKNC4s1T2nVXil3qNrsGnTJmzatAnbt2/HHXfcgZGREWzatKnpfZOTkwCAd77zneJ68/c111yDyclJ3HnnnYVoueaaa9Df34/bbrtNXDM+Po7NmzfjqquuUn9fKti2bVtiGKGo1Wq44YYbMDQ0lOs9uDA+Po7BwUH1t7Ke4eHhsQTQJcJjUbxw9FU88+QJPPPECa/Ue3gsreXrkRPdEqJe5v5gijoutT2nVXjzmkfXYe3atRgaGsLIyEjTa6vVauJxz/Lq9/f3Z3rms+5zYXBwEDt37sT+/fuxa9euwm13E1oZm7zYu3dvx9r28PBYOjDOkqVWtOhCy8v08MgCX7+8Gr7H0kK38OVOFlJd7L4tFLxS79GV2LBhA6rVKsbHxzOvGxsbW9Tw98HBQQwMDOD2229fNBo6hf7+ftxzzz1te9Cr1WrHn+Hh4dH9MML/UlOOfdV+D48UfBX4ZbG0kfDlRrDIlEQoc3+40AyyXqn36EqsX78e/f39lpc3DMOuFKoGBgZQq9VQq9UWm5SuQ55oCw8PjwsLSzUU8kIRDD2WL7755YPY+dd3t9UGX79dKJZ5FEC35J13JGJgiaZ8tQqv1Ht0Ld7ylrfgrrvuSv5+7sVTOHo8PUdzfHy8K4rUVatV9Pf35yrqdyFhfHwcO3bsWGwyPDw8ugSp16Q7PEJFsVTp9vAwGLv3p/jevkNtteHD7ZcnFl3x7cCRp0t9zykKXyjPo2vx1re+FXfccUcSYj/LKmIePnwYQ0NDi0RdhGq1imq1ine84x25rt28eTOq1Squu+46bNmyJfFkT0xMYGpqClu2bEmMA/T6t7zlLbjpppswMjKSXLtt2zar/V27diX3Hjt2DG9605tUo8fo6CgOHTqEK664AgCwZs0aNad+48aNSc0CrcCgaWft2rWYmJjAFVdckbyP0dFR7N27F2vWrMGBAwdw8803J/fRooLNnjEyMoJarZb0q1arWaH6dIyuvvpq3HbbbcmY1mo1HDp0CO95z3sKGVx+9Vd/FYODg7j66quTMQLS8d2zZ0/utjw8PAiW6Dn14QXm7fFYvgjD9uexdKT6dbGkYfhyl3jqy1TAwyW657QKr9QvEu746gHc89BTi01G27jmX16Jd/z61R1pe2BgAAMDA9i9e7eqnK5Zs6btZ9TrDdTrAS66aEXhe2u1GjZv3oxrr70WW7dubXr9wMAA9uzZg40bN+Lw4cMYGxuzFNTR0VG8+c1vxp49e5K+m+unpqaS0wBGRkYwPDxsKfU33HADtmzZYo2TqSpPDR/Dw8PJkX4G1WoV27dvF/TeeeeduPnmmzE1NSV+Gx4eBgCLhmq1il27dmHTpk3YsGEDNmzYgOHhYUxMTDhPB8h6xs0334zrr7/eon98fBwbN25MDAB0jAAkzzfYvn07Nm/enPvUAyCqk8AVd3Pkn1foPTxaR7cUZCqK5ZaX2ag30OvPFr8gESJsW3njnvoltpw9GBK+vMj8rZOV6pfantMqfPi9R1djaGgoOWPe4OSrtdIK5J18tYbjz5/MXPBGWTX/bd++HcPDw7jllluwZcuWwsfZmRz8DRs2WN9v2LABV199tThabmBgAPv27UuuHxoawsGDB5Pft2/fjjVr1ojx2LJlixX+PjY2hn379gkDxMDAAK6//nonrRyjo6PYt2+fiBQYHx9vKYdee8bIyAimpqbEGJnChNwIcdVVV+HAgQPi+je84Q0YGxvLTUutVhPRH8Z4s2XLFufRfMsdT73wKjYOfx5jY+UZIufm6vj8rvtw6jVp0PFY3lhyyvEyKpT3nW/+GL/x//071CbPLTYpHouATnjql8O6uJDRLd7sThpPF7tvCwXvqV8kvOPXr+6Yh3s5YWhoCDt27MDo6Cj+8ZX/BwBgdnYe1Wq1FKU+CMKmoT4DAwOlV2d3HSF300034YYbbhBnu/MQeRpOfscdd2DLli2irXXr1qFWqyVtDQ8P47rrrlOfWyQ8fceOHWo71WoVk5OTudtp9gytT0Bk/Ni4cSNuuukmQTcfV/M3DeHPwuTkpGjjlltu6cgcWEr46098B0889wr+9D1fwTc+fzPWvO7Sttt8+shL+Mw/3IvVay7Gr73lX5ZApUe3Y6lWkV9OnvqXjp3CuelZnDl1Fv1rLllscjwWGmH7nnoebb/0V4UH0AV8uQP7w1Ldc1qFV+o9uhr9/f1Yv349RkZG8Ce3/h8AgLNTU6WE3gNId6MQqE3lU/w6CaNQHj582FLqXUYAc1zcxMQERkdHndcMDg4mn+3C5MBzbNq0qRTFt1qtolarOfu8bt06ANEYUcOOdn3R92nSHgxGR0exf/9+3HPPPYXaWW7o7akk/z5/fq4Upb4RH5/TqF8YBWw8UixV5Xip0k1hetDokuOrPBYWpXjqvRq/LBE0uuO9+iPtWodX6j26HiY3++zZKVx22Wo88uhB/OZv/ZdSnxEiCk834d2LBaOEjo+PW9+vXr1avd4o9ddff72qsD/55JPWde3CtNNJ44d5RjPDDT/9oDRDT4xarYZbb70VW7ZsWdQ50Q3o7Y0ytUKUl+92oVnQPZZuwblO5nouNJJQ2y4R4D0WFuZo4DAMUalUmt+ggCtInocvbSQ8oUsK5XViPi0H3p0HPqfeo+thcpy/ve8bANCh8+BDpwd6IWH6ltejbuhtFvZeVr9oOHurcEUU8Ge4+mS+7/S72rx5swi758aWCwW9RvirlLfxm2YaXrm44LDYwmNRdMs5zmXgQjviyUNHO55LX/x+eaFrCuV15Ei77jBYLBS8Uu+xJHDttdfih/ffi7Nnp/D61/+jEltOF3qRgmqdwuHDhwGkIebNMDAwgP7+/kxl0yjgAwMDpSilAwMDOHSo9XNum0UNGGXddZ35vpNF60ZGRjA2NoadO3da33fDHFkM9PTEW0WlxI3fe+ovOCyU8Dhzfq7cBjsQYbD/64/iyE/KiaAqBO+p90Cbc5nxbB+Ov7TRCcX3i5+8H1vfmf/UIYueMveHLjFYLBS8Uu/RdZiYmBDfvfWtb8WzzzyFr4x8Hv/v//P/Kv2Z4+PjpYWo54HLC22O7yuisNLz7jlGR0eTZ23ZssWplBZR9rds2YL9+/er3vrR0VFrHFevXo3jx49b1+TxsG/ZssXp0R8dHcXQ0FDHPPW1Wi05MpA/YyHnSDfBhN8DldKs6Ek5iwtks/VYmCrL939nHDf867/Fyy+eKb3tMun+0Hu/hS99+oeltVcUDe+pX5JotxZCGQqct8MuM3RA8f3pT6o4/ONjxcjoRKE8XFjOA6/Ue3Qd+BF2ALB+/XpcetllAOSGYpTLrJDwWq2m/h4CeOboU3jb296mKomu+9pFrVYTCvbo6CiOHDkivMPNMDQ0hKuuuio5O97AVKM3/dqwYQOuuuoq7Nq1S1xnPO9aX7kBYsOGDbj22mtxyy23iD7x6vHXX3+9pQiPjo6qpxbwZ5iQd26sGB0dxeHDh0Vl/KmpKdVQYvpTpCr/5s2bsX79enG0XbVaTSIpLjSYQnlhpTzF5kILi/NAIjx2Uql/5cQEGo2g1KMSOxGy3mgEqM83SmsvL5K++EJ5Sw6fu/1evO3Xb2trHpYRLePPqV+eKFOpD8PiPKYTRe0utDQ/XyjPo2uwa9cujIyMoFqt4pprrsHQ0JCVz/zvN/wHXHv9r4GGzA8PDyeK1u23345Dhw7hpptuSjzdu3btwtjYWKJY3nzzzVi7di2AKCLg2Wefx9NPR8XkaDG6Xbt24dChQ9Z9b3jDG0o71sxUWTfe6Gq1iomJCavKerVaxfbt23HgwIGEhje96U1C2QSA2267DSMjI9i+fTvWrl2bKNb8WnPdrl27LOX7rW99K/bv348bbrgBQ0NDGBoawi233IIDBw6gVqvh5ptvxtatW5N7TDvDw8NWxXj+vMHBQWzZsgXDw8MYHBzEmjVrkiJ7tVot8xl33nmn1SeDPXv2qGNk2njrW9+K9evXW2O3efNmXHfddU3f3+joKMbGxvCOd7wjMSjUajUcOnQI+/fvv2DPqe/tSe2/5RXKK7c9j+7HQnpNyqzu3pECf2UcLdbKY+N3cKEIucsJ1edP4uUXz6BeD7ByZWs+uTK8oebW//v//BXc/+hRH36/xGHeXyf4URAEafpeMzo6GMl1oXjqvVLv0TVodiTab7/9dwDYNVm2bdvWVpsvHjuF6bMz+KdX/hL6+nqt+zoNfnya9vttt92Wuz1N2S9ynamUb9Ds2e0+r7+/v+1nZI3R1q1bc9FHsWHDBjEOHkBPT/mF8rAAodge+XDkJ1VcfsXPon/twpxb3llDjskZL1Gpjz/LFHojT9YizH1fKG/JohRDaAneUEPHJRetsP72WJroSPQONYQWtD91olDeheI88OH3HksPF8ba9PBoiiAIcP7cbMef00POqS97c7xQLOjdivPnZvHH7/gkvvjJ+zv+rIU4MzgJtyzZqw6UHZ4aLqpi7QvlLT2YddOWl72E4xnN85Mj8fxUKgWPPHgUm37jw6hNnFvQ53YiFc60VIQPP/zkcTRW9pQrEyzAntNN8Eq9x5JDR5bmhbHePZYZPvWR7+K3f20nGvXO5ub2mUJ5lUppG+5CKHhLCdNTMzj02AsL/ty52TqCRoBzZztvHOpEISTXMzqRM152eOpizH0zPmWmJ3gsEEp8d20VygNT6pcAps/OYH6+vthkZOKpIy/i2HOv4eWXyi/ymQdlGy2BYnz4Q18bw9Q/W90ROi4U54FX6j2WHi6Qxenh0QyvvVLD5JlpzHe44JbJqS+1UJ4Jk/ZhwACAr37xQWx5xydx+mR5Bd7yIPWoLMB7WEBDTrk59fFnyUUiF0Ox9ufUL10EJSgoZYRamzaMUr8Ucupv/u+78IFtX19sMjKxEKeD6A+2n19KkwV5PX12qeH3HWizm7Fkc+qHh4exadMmNSd5dHQUhw4dwhVXXIFarYb+/v7c+b8e3Y9OLM2F2JS0wne0qJ+HR1EslHJAw+9LUwZ8oTwLJo3ifNlnrDfDIgiSHfWadKSCcrljtGjCO322D79feihjbpfhuYzvNdvCUvCznD45hVMnzy42GdnogHKd67Gd4EdJm/nkBdrlTvT/QvHUL0mlfnx8HCMjI2oxs127dmFiYsIqkmWqdDcrquZxAWMB1nvRwnceHs2wUCHsSfVaf6Rdx7BYpwEs5HMXQpkNCwqT+RpF3GbJqSeLGAK/mJ76l188g+9/+zD+y2+/KXdlbA+SU19Ckbu2CuXFn9Nxys5SUJiCIOz6YxwXy9hnnlb2kXZAfuMhdax1xrjQ/XO0DCxJbsrPrjaoVqu4/fbbRdXroaEhjI2NiXPBPTwujGXusXzRufxhir7e8gvl+SPtbCyaQNcJJdj1rPizk89K0gnq5T+jtLnaBXmei5lTf8+3foxPfvgeHH/h1KLRsBRRxpGQ5RxpF937wPeOtNzGQiMMw643PizantiBvadoel2nPPUXmpyx5JT6kZERZyj97t27sW7dOvW39evXY/fu3Z0kzWOBUG5lzHiDK69FjyWOyTPTC57X3C4WzlNfZqG8C8uCnhcLH3oZfS7IueULcLxQJ+ZV2ec4F/VilYluCL83BpdOGF6WM8y6KcPL3k4bwQKs47IRnTbR7fQu7p5YbspS9NnKvlImHTOz81EtoC436JSFJaXUV6tVDAwMoL+/X/39wIEDznO/BwYGklxmj6WNjizNC2O9e+TA5JlzmDyzsEfKtIoFC79PCiKV/yyfPxdh8c7TXUBP/QLN1+gZXVwoLx7zBSlOyJ9thO1FDL9fiIiN5YhS1k8ZfIbduhT4bRh2P52LdSJMwt864TDL26ZVKK88vvCf/uedmPzf1ywpA1Q7WFJK/ejoKNavX+/8vVqtYvXq1epv/f39qNVqqNVqnSIPwNI64sOD4sJY8N2Ms1MzePXlicUmA2H8v7LRCd6wUKHTvb1pTn3ZFcDL3mxffXkSb/332/HIg0dLbbfTMONQ6vnqeZ67CF7jBSmUV2J/yl5ni3qcYxdEyPgondZQ5ri1daSdUOrbJGYBEAZh1yt2i3X8WkeimxI+nDP8nv67A+/pQjEgLhmlfnR0tGkF+yyFfc2aNQCAycnJUuniMIJ7vd7d52F62OhuVn9hYGryHCZOT3eHoFciCYYXdEapjz47PWa9psxxpTylM/UYlkv7KycmMHF6Gi88+2qp7XYai537lyVI1ucbOPVa+ykpC1kor9Eo/5jHsukuWgvj3Ex5JyM06p09BjMLaWjuhSFol4ETJ2t47vw0QrSbDx99tmP0SozeIfu7i7EUwu+Xk6e+KK/v1JF2nWyzG7EklHqjrLvC7inWrl2bq61OoVKp4NJLL8X09HRHn3MhoyNGzAtjvS8RLP7LKHOOnT17FqtWXYSXXzxTXqMGSX6sLhyfm57F7//mP+Dg2NNtPaaXVKguvVhY2ZutUeqWWL5uK0Wwnj/6atvGi7DJHAKAT3/se9j4n3Zibna+zWfZz+wEOiIYl013C8aNg+PH8G83fRhfv+9QGY9eXCG3CwoFLjWMPvBTPDMzjWBVT5vV79sf+256bdNTM3jvX3wZx184mXndUiiUtxA1R7LQCZ6QN83HH2lXDpaEUj8yMoINGzYsNhm50d/fj9OnT3tv/QWKs1MzeOHoq94L0Sq6gveWQ0S9XseZM2fw4H1H8Ttv/Rjq8+V6x9LcVJ3eV16awDNPnsATh4639RxzTn1YaqG86LPsAjbdcFxYK2hF2dp+6x7s+KuvlfLcrIiJyYlpzM7MY2amPaX+W2NHMPu6lQsitJbJf8s/pz76LDJHf/jYswCAu79/uL1nL2ANBReCxJDUFcx+ScDM57DdY0VLMOqYOWRizxZTX3rmyRO4d/RQ03SrMGxtvj325HFs+/jogtSgMNQtvAJavjGhaEHOjh1pZ9q/QDz1XX9O/djYWCGFfmJiIvP3PN7+drFmzRqcO3cOzz//PF73utfhsssuQ19f1w911yMM400tLC+0MgwDhGGARtBAo1GOjevc9AxmZmYxNzuPlas6997r9TpOHD+DX/iltVh10YqOPWeh0IjfRb3RQO8iavZhECAIgrbmWL1ex9mzZ3HmzBlccsklOHZ0AjPn51CvN9C3ole95+SrNfzDjn246Y834Od/cU0+WpNQY13gSAT4NhUc6qkvvVBehwrvLWYhsJbQgpdmZmau/XO+c+SLl+Xd/ciXHwBefzEuebKTp0t0ID/UfJZcT6KIQSsxrLVJw2JW3k+JiGlYamt0EZEqPe0ZVss4Fi9dEK03URbyGMiMl74VA/LvvOcuAMCvv/n/hTf8s3/UEo15YXjWYoXfd6K4aO42O+ypv1DC77te06xWq5nF8fLC5NKb3PpOolKp4PWvfz0mJydRq9Xw6qtLK7ezW/HyySh1oi8A5uvl1EY4c+os5ubqmG1MYoVD2SqKs1MzmD47g7nGpFOBKwNzs/M4c3oapycuxsWXrOrYcxYKk2emMTMzjzqmEgF2MXDqtSk0GgHqaC9V59JLL8XP/dzPYc2aNbmUoiOPV/GD7x7Bv3rzVfg3174h30OatFta3nol/SzNU98B7wCwDDz1BcY3DNsXVpJojwwlL0+IfqFnLkD4famRUh2qBVBEsTYlOcqKbFlMhTo1Rl4YgnYZSF57m576Mgx0fA4uamhzjrVZRlHWChZAJlmgwrfysR0whLYRjdMJr/qFEn7f1Ur9rl27cOjQIYyPj1vfG2/88PAwBgYGMDg4iKGhIaxfvx7ValVt69ixY5nH4ZWNSqWCtWvXYu3atYmV8EKZVJ3CO9/3IQDAL9VC7L7r5lLa/It3fRaHHzuGv79jI/7ZleVYYT97+7348mfG8ME7345/8s9/qZQ2NTz20LPY8Rdfw+/80QZcd4OuBH7hE9/H7Pl5bPwf13SMjrLwd7d8BWP3PYHPfvMP0b/2kkWjY/Nf78KJ42dw13f/pKX7K5VK8l+K5pt10MLG2lRYKUtIIM2XHoLcIb645HLqWxA8y9hXclV2D+1r20UQRHR39ESIDhh1ypv7xdelOVaybRqaRPcsBBaitsJyQ+Kpr7THz8tQcNP3Zrz+LTfVNhKjZKZSH1/TBqEL4WhYrGKpHVmPBT31YQdkDArvqe8CbNq0Sf1+fHwc+/fvx7Zt26xz6devX499+/ap95Tl8W8FUsBfunj15Un8zZ/ehc1/8Wv4J//8Fxf02XOxkD43F6C3txwPeH0+wPxcA2FQKa3NoIGozbC8NjWEiJ7TaLjH44HvPYGZc3N4x+ZrO0ZHWTDvAujsuDXD/FwDszPzpdKQJ+TVbORFNtZmIW5lCQllCZR2o53x1CdKyxLbxFPhNP/4hmEJglgOz10nPKudU+qjz054nUqvJ1GARjNW7RrBuiH8vpOGl+WKhJejHJ7Z1jzqItaahqxnhN8H7e81CyHDJ+lyi2QlKTdlqZiTgubUd6RQHjq353QTlkShvLzYsGEDxsfH1Qr3Bw4cWFLF9roVzz71Mn566DieOvLiotEQlLijdMRbyDyuL790Bm+/4UN44nB7xcrkc6KPTOWlhPDchcJCnbnelA6U78XK07dWQuCabZxlhdWZ+0NUSswrjtsuu1Be/LnkFIYWIzXa7WeeOdKKwaHpczvMl8otlBd9lu6pL0BjklNfUmRGN9ScWCp7U1GcPzdb/mknZqgqlVIU8rY89bytxdTyc/Gv9vfB3oVICVwkT30nTqMoyjM77alvN21lqWBJKvUmP56H2g8MDGDLli3YsWOH9f2uXbtw3XXXLZqnfjliMUP3OrEuy2SiAVPgqs+fxPEXTuLZp14u7RlAPsEwDMOuEN4AYOy+J3D6pLtAVic8bK3AnGe70BtcS2GRxrDTZD2WpuCWuDF2ylvXrHhgGXj6py/h+99urwo5RytRFa0Wf9Kem/ke2siPdKFj3qgOzKuyPfW5DLIMRqlvNwIlNXotvqd+uZ4Qc8fO7+B3/38fK9ewRKKlygidLyOEP/275abaRq5CeTm8+c2wIJ76DtXuaPpc81nqMaDFxrzT1e/bXTdLBV0dfs8xNjaG0dFRjI2NAQB27NiBdevWYWhoCIODgwCikP3R0VFs374dV1xxReK137Zt26LRvZywWExHo6HMtsr11EcfidDUIWU1l6KI7mBkE6fP4n/98Rfxlt/+V3j7zf9OvaYMa3opIOPa21vSRp5j3eQJI5TN5vPUt60ImMlWaqE81nbJ6KSn/oufuB8PH3gG//rfryutzZZ4Udi+cpZn3SWRGkS5PX3yLH7251e3/twOrfM0qqD89ksrFNjCqRQmp76s9eJz6juHqdp5nJuejVPjyvGdleXJLGN9iNe2iO8xTzX/MtLQFsJTv1jrojOF8qLP3PuTNb/L501hpRK3u3ipnQuBJaXUr1+/Ppe3fcOGDT7UvkNolsO7EOiEAt6R8zmDQP279Oc08dQvupIMYHa2DiCq2O9EHo/hAiIIShTITJuZ3lDz3CKe2ux2S8up70RoXIcMhIbWTiot8/MN1OfLOVbToNVCeWUVQcxzpJ0Z0x/98GkM/8HnsfPTm/Av1l3e0iM7xZc6Wiiv5Jz6IsJ7peRCeYua5tSByI9uQmIE60RdhwKG1VOv1TA/38Av/aPXyXbamMvJOfW232JxkPCmLKW+fedN20eH5sBiO806U6Aub6G89NmNThg1fPi9h4eCThW3Kk5COW114kxjppx1ujBRJu1hdyjJeTbVxd7QBB1tvK9HHjyKw4+9INvM8oa2Imw1uUczKM2cn0OjXkwhTUM/2zsj2aYt/uxUobxOzvsOGMtaqTEQhvb41ecbOHPqbMHn5pnv9vydOB09o+izEpQY8cHRCaNOGRXDtfaK8JjeWKk4dXIK58/NtvFsFH522egG50AnUXq6BkPed/d3t+zBX/3RF+0vWzAec3RThEWRejXtrN+eBSywtuAyEDEylre/m324eHsd0S86uOd0E7xSv4zx4rFT2Pk338DsTIZ3tCASgWkxlfoOFMrrSEg/C1ktvSBYzs2sG6qAJzltOaq/L3aeZRkC50f+7lvY9cFvk0ZNm1kGmNaNGs6NUxHg3/XfbscH3n13ofaTdYLylIHOrYvos5NKSxCWf0xpHkVv/PFjqE2cS++Bvb4//bHv4cb/uDM7IkY8N/rMNrjFn5yntTjG4QJ4TTphqC1N2GyBxxhP/flzszj6ZOv1WbqhIKnZw7thb+oEOnnud5FCedNTMzhbm1HbaS8v30HbIkDj9/vvfgxHnzyR/J2ktnW5Ule28bDoc/m/22oz/syfU5+iE3whCr/v7vdfBrxSv4xx4PtPYO9XHsYzhLm1i1ZyActGqeuyA6GaPPyzcwXBos9mYWfdkFMf5FDgzC+Lb01t37gwP1fH/Hw9bZEJ0sdfOIn3/M+7MFU7n1zDjUD5KXVvnKnwnP5+8tUaXntlMvczLJoqJQpGnfLUx+ikcaiV4webN4rMNs9Nz2LLpjvxxU/eb91D+crEmWnMnJ/DTAFDbt40HoCmFEXftzzGJUZ8CHQgUqNsA1QrtS7S6N9yxq4rcuq7YG/qBMoozCbaNENVoOBXCLfhMe8cmp+vi8iu5N6EZ+VqqiPgvKlRb+AD276OL392TFzTXsX/zneylWitMp8LlGm4LGb4pfOxI/33nnqPpY6OFr9YZp76MpmIM/y+Q2HGzXJhuyLEMYcQV0bYexkow9MbhKF1P58Dj/3oWfzgnnE8deQlck3x/je7RxOeW6mzYG/6JRcLK9tTX4JRpukzSpgjss1sfj03V0fQCHBueta6J2DvNqKreN+zT2awr2m7enkHPfWd3KNKi1JJ2ivuqQ/RZt86MHeL01C+0ttNCDohe5mCcMjPM4NAHnlZdH382e99Bn/9p19itMh/LTaoNz4MQ8zPpUb1RiNsu2jwguiDifFhYdeFVXm+NMNl3F7evpDHdiKnfiGiw7oBXqlfxki8KfUSGcQihQcpJJTbZkeO8rDN2GWPWR7FImTK5WIhT+GgbsmzLCU8NbS94zzCRXtGK97AZmOWeoxsA0NRnkCPUyp7Yyx9fi7APMoTeVIUpiXXGnG9S+t6w/NbMgw1P9KOK/GtjnEnQyE7YtQp2/hLvVI5xzDJ6W1zDaZ1ZBbfU98Ne1MnEObY7wq3aZoqcjRXqEWDFKPtlZcm8MpLE1oTXQGZ7gjrbwB4x1+PYPJf9LcV1r0QXt5OGIOKovS6IbmjSuS9paJSWbaRQRReqV/G6ETunFmgC332uRWaU6qnvgMWdaZUJMaVDo1ZU099F4Qc5VJYu2BDI2S0VODFIAhCXdnKKJ7YUsXkJmPmMh4U5QkJTZ0olFe2p94ooGUaM+VDoo9OGAMd46HND/4u2/GgNzsak7bf9hiXdGbwc0+/gl0f3K/O51JTqgoqQk3bI83kVWxp9e0yjiNb1Lo4y9xT3yneBiDKqc+rKIUy/a7o+w9DyU9k+P1izqXoM5G3lNo8x14+A/R0v1LX0XmT+eD0n+WdblOsPR9+Xw68Ur+c0QFruGlpoS3sVvhvme0m7ZfXamJtjcco9dKWrLzkqdwfyvC7xUAeb2DQhkLSCbQjcLrCohOhQulrKwamZqGUyXplBoaiY0xbL2vT79RpB6lRpoOe+g7k1GupEvbvuoGGCucpf87f9zxGR57m0W5UTVmhkPfuP4Qvf3YMJ46fIY0b2jrwbkozaFFjXl5PffyPSvu8CQCCThq9mtEQf9J3VPREjjLw3b2P42///EsdMyx2+tjGptdBzpWi+eVRMU7WhvKcRYPgTW5Zox1lcUH6uEiODZsflcTjCkYEWYbODnTfh997LHl0xBq+SBZ2zoxL24QXwOPWiaI55DHZBa7QHYwsT2GxRbNSOwhpZ9x4LqMreoPOidr52Sjvr0j4fbONU+lLiLC4Ut+BTb/ThfI6Oe/bzinPaLOZp77BajXYESEt0JWHB4r522b/S4r4SIpjqcaxDpxT34k8/Zxt9vSkR2qVsWbKihybPDONG//jThwcezr/TewdHXvuNfz6v/5bPPajZ0uhKS8evP9J3Lf/cBJxMjdXx+HHXmh7bib53R2pfp/faBcGtnH52weewNFLGoXOug8DmcJn5p+ZkV3hqWc0aJEIba2bBehjMyN9p58LlB+NlLtQHjGbdCSqtZPFWbsIXqlfxtCs4WEY4pUTEy1P7mbepI6B0FtkQ8rbbJmhiFzZ7tiYGcG6SfG5so/eagW5csWYxX2x0Iq3U7TBhCm3NyH6fPbFU/jQPQ/j/OsvasnL2qxQHjcwFB3jzmz62Upsu+0uRKG8TnjqXe9fVVbZ+m4lSiGPICmUlIICm0BJXhNXnQGgu2vJWF6pnG1WyDnZpRTKK6kvL780gRPHT+OZJ/KfssP51isnJjA7M4+XqqdKoakwHfGa+v7+w/jjd3yyUF+yGu5ItAjy88wwtA24t350L2Z7gcZFvQXCohVvP2w+sJjihatejcYD2+HXC9HH2XpU3G+h5ev5eiOVe0qORmrFuNopebUbHFydhlfqlzGS3CIi3Hx990P47//PB/D9bx9urc0cimQnwJ/WCtM7f24WE2em7XY64KmXhVs6M2a5PPUd8Bi0giKe+sXOsyxDKQx4+H38aSzQyd/xM549fhIAMLd2ZbFNtcnGqYaBhm166lvYcF85MYE/uelTePFYKrSbVjp2pF0Hw4s7sa54vrrzd0WBbef4zDzHlPJUn3ZTZcKecgS31NjQXhpLM5TPm8h6yht+b3Lq2ywy2KkjVosZI+33lqynBU/rs+fKuenoTPfpqRnnPXkQNFnLrYAWK80dOh86aCjiGFH2i25yeHKjZJZcVEaByU7hvoefxpeeehZza1YseB2k//aeL2LyV/sBlLgfFzX8kssaHRhrH37vseShWcoe+sFTAIDHHmoxzG2RFC9rA6pUWlKQ//6vvoY/etsnWMPRRyeqWAdMgSs//L658No9inL0mVV8LlWmF5nxluHJCvUCZjyn3lyThNYWrNCa21PPFMHChfLov1sYl6eOvITHH34OTx5+URDXuXzWko7eC2VhwazIkzAMseuD+zH++LHCz3G1CTi80qbSOxNoW/HUZ/JULii3O8YlVSLOOtKx3DPCyzUUWJ76vIXyYhYRoj3BO92PyupLCwYexpe4sahTOPbca3j5xTMpGayoGl8LM+fn8O4/GcHTP30JRdDZ6vfFCuVp8ytE/vcfQs5RqeAu4p7NjFRZa7WdsO5O69n3P3IUADC3ZsWCe+rrjQDojRhM2Z76vGNO51RHxtpXv/dY6tCEtd6+6JW37GEpuQpwXliMpsXKyZMT5zBxmnnqO9AfLnx3YoMH8hkLOlWkrxkefeioOE+bfmrIc81CoAxPVhDwQnnp9/Rv403urfSQa4so9U02TkX5CsOw+JF2hKaWeIdCZ6eLSZUVfr/zr7+BP/8fn7W/zIjwqU2cw5c/O4bvfuvxQs9Jwmsd4xGoY8jvaUXBaj7fXcdGtRXNUmL4vbZmyjQOJqNbssALtGB8qJQjeJeWntKCEZRHfnQqeoBj25bdeP+2ryd/8+dzOo6/cAo//O6RYvUCII0VrcKab+TfufPhFYMkgEIKjtZGaLObxQ2/5/Mvgzd18zn1fX3lnG7RLkpLMYo/i6R5GHTCuOc99R7LAHKj7O2NXnm9xUqzmudvQRDa/2xFuMo6ymshwu9LH7MML1V6jU3TQuD4CyfxZ7/3GYx+7ZHku0Ln1C9y9ftcnsumbbBCeYG9Frk3mRbBakUZaVr93iquFhaei3T61FvKkYvpUA0dnSkgWZbS8vwzr+CFZ15N/j43M4daI8p91MYxLWhX8PnNwu+1EGUexpysoSKGofieXBE/No2tpjiEPSUVylO8xJ1UEDvhqc+73m3vfht9K3l8kmiRAnOBr/2FShM7Nz2rGpvTk2oiNDifbtFA1A5vu/0D+/HHb/9k8neiRxcMv1fHtIBhSNSHocTA5geLASFvZaQTtacsdraPvXF6TbjIBd3KjuAJc1e/J7JBJ8baH2nnsdShCbdte+oXyKIun0v+aNHiFobaeavRZ6mWQa6cdkhZzaMULUTRMI7z5+YAAOem5wQd2YqDfc2rJybwse17MXN+znlPJ9G2p17ZpMQ59fHfxtgW/VZEIcveOLVQdG0d5H0O0NrRU6kSmN770xdfQ9DXgZC4NgVxjiCwj4374/d/DeM4j8bKHvVdtWrEa+bZ0I7R40p8K+s9V10RbjxoQmtTVMrhSZmF8jpw6kvZp64A+RU/+73no2Pm/ByOv3BSfXTZBooiCixXlgOFT3UCkZKbPkPUZHAa5IvRVYan/tmnX8bRp15O/qbV73MbnB30h0Uq6IfyWq50LaaqlPKiIP50j32n8+LbQZ+RAVqMRC0Lpa3BgnyGXtWR7rdZi2SpwCv1yxgaczPKQ8tKvfFCLfDisJhxi7kx6tEsHTBShMx6zRW60p6TQ4BftMgKtHDMFDNCPfSDp/C13Q/hCZqHvQDgoaEttRGGzDuOuE1WobcuPfWlnlOv/M4rIud7Tnp/vYW1whXdV05NYeShI5j6p5eVPjfL9tTzCJ9Hf3ocABCsqKh8o9WIk7yF8gJtXSX3Rt+30vfsNJ74GjOn2zQWlnWCSbLHaV65kow6M3Pz+NTYIcyt7iutTdpKEa8rgEJG7S984n78ztBHcf6c5p0ub30ALebUM4NSp/cpyZcN7dzYyiJfihroMtJCirTBjbER8ss/ibEk7l9PhdRuyeupV45A5aHuiwpuRM3ggSUEuHQMvUSp78iRbjlR9uk2uflCSP9Z/mCXeWpWN8Mr9csZyubdtlJvPhdaqWePa8WzHkIJv09k1PL6wwVr83f5HknzHHe7ixFZoTHzXOH3vMK2cgb1gqAFz5NogglkYMIrN3KY0Dt6Ta7nNNs4HV7jwgon+XdrSn30aeicmZuPvu/Tvd3tIDGilTRvgiB0vJOKyodaTrdpopCnHmiplLRV/d7MoVxRNDzMvzsK5Wm5x2W9/0NPn8ArtWmcG7i09CJSQBFPVvF7pmrnMT/fwMz5efLs6LP0nPoCBo+AzdNOnOuuPjcILYXJnVPPjA2F+WXz/S4Prer9RWoqsL1sRV+qOBY70s6+ltiXkmsWC5wXZfLANhS7Tnv5E099AaNNJ1Aej4vba6Ev3lPfOrxSv4yReFfIJtYTM44gZ/7b80dfxSdu+44SnrbQ4fdEkC0QOma3EW+UShhjqccfMQElDDo7ZnnC74tuZEEQ4MUWzwxWwzGZZybrPtf4LRSK5gvX5xv409/7NMbu/WnyXRC4PPW6N4F66lsROpp76lmEQGEvMnlWKwY1Jmit6O1N2+vQ+y3TE+nKS9XmZishu7XpGRydnsr0JmgKBp9XrYXfQ7TrvKaN51goqdhbWr9AW2vlvP++3tYMbpkgzeSuDk33rbyeWqY0U5QVOdaap57x+AUyPvNoPVnrJPo+Mci3GLVVRkRjGIaqAS9E/vfP5ZvemO8W8VqGgRLZxe9dRK1eRCvF3ztrCbT4ThbKU7+YHuUicytfa0XSPIjRshP9X+S0hoWCV+qXMbQiL4mnPufkvnf0J7jr0z/ES9XTzjYXAhaTa5XpaeGrWvsFMT01g1Ov1chjuKDQmTHLU9k+FVKKPfu+/Yfxtv90G557+pXidClKMQ+zVO9jxo9W8xnbRVEL88SZaTz20LN47OCzaRuwNybXnDDvxS6U10IYq9O7a497y/nepC+teOp5fl1vX2s1BHI9ignm7SJouNMV9CPtzPPz9+sDn7sPT5ydwuzPrmpa/Z6nUkTf2fU7Wsmpt9qRF1nPbscLA6BQsa/MdhQeUfaJH1SpL7uIFJCfzuSWSqVwHr59fbkKdKpEtW5IWjBPfWhHUMk1ZY9Xq0UvyzBIR4ZhKasUPaee0pN66gsei8c99fZwLW4UfjKXDDHudxZVQG9x3ndY0U6i9RazSntJxlag+B4ROv5dFsIS+9bN8Er9MoYm3BYNvzeMUp7jWowxzs7MY6p2vtA9FNZSbDGMhm/Qk1PnMVFpWL+1gve/++t6lVpuOe6Q8pIKIAH+5KZPYd9XHxEXFS1i9OhTxxEiOgawOF2K8mGEtkxPffx+mPdt4U9aKCb0pnm9dn+1+5NCecm9sae+0pqnvpkniY9psn4X+Eg7XqW8Qn8r8H6PPvUyPvnhe7LHqOTw68DhqXcdkdNKdMzLpyKjYNDn5m3q0ZhMcGonvxlwK5iykFmbY1xSKKS69hhfbBd9LRaxzIIV+ZKTTso7846dpiy3a5BxoRVDUsDWyoJ46pV9qRHY8k2qIMZ/t2gEbSunnq25tFCenvYDAHd+5B489iNiXGZt9JkIqYJGtWaF8hYTIfg4Rd/r4feth7aX3eP7vzOO3/vNj2F2JkqNaSciaG52vpz9rkRvdlGnjGXoLIUCBn9OvcdSw/TUTOJRB6TnEyBKfc4K1iLHLIfHVcNvXf9+/Ma/fW+hezQ6ALR+pF38aTboLR/4Ol5YWUf94t62Fntt4pyt/DIvbFElMS+48jw7M4/HH34Ohx59npNSqH+Hj57Alx5+AvNrVrQkGGvGpDzRCsn7aSM/uEzkjWbRhC/u3XB5zLmxjF6T79mIn+1S6uPfk5MYiht5AFugmW+nUF4S1pqiiMD83W89jpE7f4DXXp7MeFbxdrPgMtBEz3Ir9UXmbSpsuwtYZXqluQe9yJF2NFfb+Ww4ntPa2iwrxDT7nPpy+EYvTRUp+Ri4qM28fIb+O+c9aspGuUYv5ODtjlvS6vc5jL5lICqUJ8fCVeuk1WixMnhQMjasiB+ll2Judh67P/kD7P/6o4QOe3yNp75Q+H0oI5X4rQsdLj4/Xxe0cBm1/PD7cvv400NVHH3yZZw5dRYALZTnNtq4sPnGO/CBd3+9bZrCEvPOC+9F9LLSjKeknXaiNJYQvFK/jPAP7x/Fu/777cnfacGodGL3FTzSzrWpFV34tcniHl+bDvJHq4yZCTM/efolALF3rE2Luu4J4YJByRsfE6zV/NIWcgKn4yPkgr5KLoZcff4k/vbPv4TpqZnomYrQmKsaMA/xLSEvsRWkxp+ia4QZvsKQ/Ju16RBEgIKCrbI+a8TAJGmLvm/1DHVKc7H72XNbNGLkLZ4YVoApBKV5g9V56xCAWqnkTYXtZkfaNTRew3KAW8mpp+24Lio1p77E8HuLjhaUzCz0kVSR0pROOuZ5Bc0WomW4R5yivJoTcXuFBGamPCsRF51AEIR6WpSZi4xPtZI699QLr+LZcKbt/ORAvLt47TmUkzxRGX19qfEw/xwybSjXm/0tV0vl4N7RQ/jP/+a9OH1yKiaBG2Ki69Twe3L9YoPzrj6aU19w3rzy0gReeWmifaI6EPqfl2dSQ2dpRl8qZyxmWsMCwiv1ywhna+dxtnY+XQwKM+5JPPUFQ4sdluyFgsipb2Fxcmbfa/KYK/rRVHkRBCxPj41Zp/IFeWg1rxofXYP4muKhkWFPvmNvHn3oKO7bfxhPP3EibiD6oGOq5QPL58afzGuzWIXycnvQ+Boh9MpCULpS1EoRrOg++zlj9z2B//LmvxO1EBKjCjHyFNk06cbcynE7LsMH/S5XOznTOGZ+4SK8uAbY98CRwrRq7dHxoqkSGh9sxYtNzyhulkoRaAos4/mt59S7ng372a0ahwwKHKlFcf93xrHn82PJ39mKTDl7FE0VKTs0Fcg//zVltOk9mekJ5falpeKMCyxXRJ56Ofay1gkL5S4wV3//vV/GqZ4G5lf3tXU0mauIn4tHZPIHU6C0r3mhvJOv1qxITs3gIp6/gIryieOnMTszj1OvTcXPtmnKjJQq6Imuz5NxKLmLXB7Nswe42yq2nzvbKTNEPes9uC+P/o2SlHp+FHaXGHQ6Ca/ULyNwxUnzEPe26KkXOfUtWtRbXVS2p741zzpXvigTbTf3zWaEujJatsBiWk82fU3AbcEDkugHPfms+a4Cd6qnPkup5+0oRoqy8fjDz+GJw8dtOgoqBeJ4JktgZ0qQOP9Y3lMkMoELMKdejXKzjcCTGn5kmH+xY8/Sf9fbUeqV8PtWjAvN0jjql/QBAJ49XvwEh49t34sHvmefZEA/k6KGrur3xlte4D1a4fdNlHrLAJQo2/ZvrSrbZj4effIEjj71sni2iD5qdR+otHbv10cewu47fyjoomPWLm1PHXkRv3X9+1F9/mTUHvmt7CJSQH4B3hJ6W0wNog2VxVdbkQm4bLJQhfIiA52SiiD26hwKogPn4xxp9BRTkP7s9z6Dz3783pQ2h0OF/zv9LvpsZBjTmymO02dncOOvfRBf/OQP0nYh5wvPqV9IXYkXMXQZjFX+W0DWm6838Ie37k7+Lr2OAJtbfW2cCBMVVSyBvjIL5cWf+QvlMQW8lEgu8m/vqfdYcmCKQsLkiVe+aKE8YVHPE0adgaIFuhI6WGhOKwwsEbZjGujxLu0s9jDgR89En50Pv2cCkSKAtFKwJ2Hqvfms2sLwY9op6D3jocOal6ls7Pzrb+Af/n6UEVJMMZLCV/pbomyJNAjWtxYEdnqbmAPOwk/EeNCiUt9KOkRWZEIrnvpmaRxhrHfTUwXyIAgCfG33Q/je6E9Ic/aY9vZQT70iXLdgjKKhly6hSlsP7vddgM8q8/X9/+vr+MA2maPJ51lbhfJa2EOCILCVFi06Kf5slbYXjr6G116ZTJR6Ovk746nPyWfIi8q7BlVPvWmjxb1YElZc8V2wPZI/N9CPtEsjmWK6MgzlzdDq8aTjPz6Gn/6kmvwt1rb5oUDaD5ffkur30L2W56ZnMT/fwMSZaWcb9LvFAF/z6R7YPPweBWTHb94/jh+9SCLeSu5zwkPj/vT2RvMmbMGjzI1VrSLsKZ/HtRQFW5Zxgbbhj7TzWGpIci7r7iIvPfGxGbmtZzwErM3jcGiBk0Jg5LZUKI8JEn3keJd2PPWRlVSx/rMCN50rlBdY7Wvv1vXso0+ewH+9/u/x/DNy8wpzehqEZyy056FNq7s9V0hmOyGMzTA/V8fc7LxOR87NXwgZVvi9LWiEjqOS6JMKbTzcA84FO4fSZ12T70HJv1oLv3c/s5DBqaCQ3dtbbItTC4sxxcjwUHf1e1jX50Ga6+p+/7xSN31YnuOcXNAUzJmZOczEtTXoNTz3uKggadSdVo+040ULs+putMo3XIaS6LvyhULXPHn84efwF+/6bMKfWknRyUpXKS38Pv4sNN5s3mrGmU7AnSqnGxe4kg9EBel+7zc/hvv2H1KfYYx+RZ0FQcicA4zvJHuIY+1oRn3O//voOfVZhgGlDcsIFH9XSdjBwilLIvrQwQM1mafIsWZnz83a95bcRS4X9rYZfl/Kei4zRN0YV1qJRCpJAbfetQ+/91hycIQhWeH3RXPqRZsQbRbB/Fy+qvsuOgC0fBwSH4/kXFC0J+C4CrVwL3nHjrTjVV81A4Ojfy88+xpOvlJLvVKEzrAnn5AlvS7R35pHLYup8lBaLUe9bIShFKq1cMPsNowiJfsolWu+jqQhpsg8Sdphc4znYWoe7iKeOstT30b1+3YL5eXJvQ1DJNpjb1FPvcIz+dy1PHEZRopWPPVZvE0LK+fvP1Gwiij15N+psclR/NORe5wX7QiuQMTH1PDiEgvlhcw4Z1Wq74RS75gnjz50FA+PPYOX4wJYrRgXsqK3ygu/j9srwk8MfQtcKI8rP9IgzehS+MHE6WkcffJlkbZl0NOqXBHaBitZKA/iN/t2udfzdKXUkeEwSCp0JzxBiYYhpC8YpNHNHqdMHlggrLuPGYQ7FX4v9uEWFFp+VGPzRzuuLSlE/fsPP4PnV4fOoo46UeXTYRkKejrDv7sNXqlfRsgTipnk1Oc80k5YPdsJqUHrnnrLS9FiDnzi1akbq3Xr1UYpeIijyB9uU8h0QXjqFa8VV+pkI1DuifvRW8llZXUVgdNyFzOZqlOg6pz3JgxDp4epeKE8RUFnSnyDraPUU0/GvxUlt2HPuQZTSDSjShHPWmmF8pT+FvJm5TD00D5SATsfnfFzMo4ASwrlOULIW1nvCS8CnLwtK7dW8JoWvKb8GVlpPOl8LsbTzNi1EmIKSOFVM1Zxg1lRcD5qCYYlh6YC7jHMTOtx9G3m/BzOEw+jGj7e4rtzIZkLLRnnbIVsITz1mrG5wfacJNpRiSBoVtejhxbgLcjbtDo0XPaKQsgVL7RCK18LzY7OTGQkSgehL23XvreTSv2B7z+BkTvTHH8z7q5IyGayRt53Qk+9oM8pC+m6YRFBLaQmhWF+3jQ3V8dv/4cP4u67HpLtlJTL/ic778ZsX1TbJrccxXLqS1HqqVxVsMbFUoVX6pcRuOdWC8UseqSdS8Bp1evcqqfeelqLVrx0c7KV+natgs4iUg6vLBAdO/b2G27DIweeAQA8Of4ixh8/1tLzE2Va3dSzhSUtnSIR3IuG32d46vMo9TzHTAu1DsMQR35SLS2MKlJedAElr/LKhTwr/N4haCRzUfXuF1HI7Hukkhf93n6hvOZKSPb9ho78CkoWHVkC2xd+8BMEqyLhtbeoUq8ItTythYb06556Q0sBT30TD5rVrvLehPGoxSgMmsaRrQhKvpHrWeYfLXpNgiBgvCr+3opekO+w2DPcfetMoTyHUdGxrwBuAf6v/viL+It3fc7ZBm2n7HSwQuOdrBG+d3VO6NZ4B48OCzldigGk2QkcvZXsSJ4s+jSDMN8znAq5ZmxgfW52dKY6N5TvkluTJjr33r755YP4/K7vSxpd0RQZfLKIQ4gWrusERBRNjvWd1VZeeeXc2Rm8cmICzz3zqvyx0nrakjonc0Z7RveTf5cUfh/SadzT3tHVSwVeqV9GkFXIEf+dTuTihfIcDLRFK//8fGtKPQ/Nae1IO1vYozn17QgTQvnkSi0THADg5ZfO4PgLp/D0T18CAHz4776FD77n7qbP4vnfQMqE1cJyitBLoc2RNPy+Uij8nvc3qyCR3g5TSBUF6+67foQ/eNsduP327zWlKw/CUNl08kQV0Mu5p17xpIbsWpchpMhzo3ZtWuVctN+FrZy3tnk3wuL3yWKKzQWY2uQ5PGOOSUzaiT5dY3Ts5TM4VE2FlYI6fZMQ1thTT6rfZ53dXKz6PVXqHQY4YSxUxrAFhVZLFwmCkIXb6vO18BwqaDDkCLinPsNo2Xr4PR9n+Vu72PnlH+Ds5ZdktilzquV74jh98ixOnzzrbCNqJ/osrVZJC0YCzuu1KKeyoRlrpOGYzXMlFUtN+SBIooOaKJD86DhXbR5uGA6hj5NmTOT8spkjQ0s/Utf6AnrqQ0d0BV/fuVKDCsh65vi/hI5Ohd830vdqUDRipUj4fZbRslVl+i/e9Vn89q99MPnbimbL66mnk6jFQqqiTSpn9HpPvccSg6germ0+8WIrXP2eMZ5Ww+RaDb+3FKVKPmVTgPXFKhrTBgPhyqczVDXDCj8/W8fsjFTYKfbf/Rh+49/+XVKZVoQwZoQKugQ4tTCY0Q968jFkLjhqlbFzRXgwAUTzrDx95CWc+0cX45M/fBxPvaBYmosilJth6u3MZ4ASHhXNq90kmqGVM6hpO9yb7KrvQCUH6n36wLu/jo+/n50CYD2H9KmVjZHRaRkxHP39zD/ciz/YeAfm5lKe0cw4xKvd91SKht8r64G936QQFpAtGBdQctLzo92ChytU2P4u/rvlkw1SJUszyom12aqnvo3w+8ijyec71bwRf9eip170rbW1mYWxwy+g3r8iek6T960ZC53RHAE7si3Dq1xWOpg250bu/AEe+sFTTe8Re1jJ0QPWM7XIL/Zc7plXc/05T2XoacIfAOD5Z17Bf73u7/Gx+OQVTRF1e+r1Z6f1MNyReomi6uIzytrRIxzsGzpZgCwIeXFD2xDkSuWg1yQoIOutYOH3HdLp2z4RxtybV2FVeaZBi3z54bFn8Epc+wMALloVHSkb9jSR+QjoVaV56mkT3lPvsdSQKpe2ImEJ4QU97SKku6AXk6Pl8Hu2GFsL3bT7QguhuNobufMHeOKQXhAnuVd40OLvcxSwoxtRM0H85RfPYHZ2HhOnzrLnZERRKFECFJowkYx1byXXmeSpd9OtWLxWm0bQ5LgUHgqZbHbknksvW4X5NSsBAMdfnWhKW1PaIQXJXPn/2vUKvVKJt9emdqRdKwVvkrB2h3dPzWUn/f7xwefw+MPPOZ9DSWrpKDI+z3L099z0LObn6pgnSn1W8SgA6GOu+YJ18lTBmK9vyxOX4THjPOvFY6cwPTWj0009aI6+uaphU9rk0Yk5QIVJosxoHj8eplzUU5+m9rTJw7PqdzQZg6eOvIgnx1900+gwjAFtHOGXAVebriJu9DcObozhBoqz52bx7LmzxQpYNYE23p+9/T5888sHm97Di4t2NPyeKKA8gipNC9LfvVox3yFD9TaL5EFUoBYAvvmlg+y5VHFm3zVV+iRdfE/tpSd3ZBkG6oqi2ZBrrJmBowyEYUQX74tMb1T2Up5a56hHoIGH35fdR1eqXNFn8Tn7yIFncOvNn3M60DI99SUVk1u1IlLqI099C3ympCPt7Jz6Eo/x7GJ4pX4ZgW9AXOmj3+X21DPvv2CgCg4+8LTTSk8F9EKgj2vZs273pZdUnNbaO39uFp/88D345lfcwgmgWfu5YCA3bOlRDQXDoR4p2o4UQOx+ZYXfCdoTeuQ9AHC+SfSA3QZXWNM2//Yr96N2Zb+TjmePn8SLKxoIIT2RlLZLLl2V/HtFCTlvPI+RIq/QK+tOyPfcrO5AnnzZTBqcnnpOW3pPg3n0Mg191CvcyibNDV/UuOBay5qg28Sjx4+wK6jT68I1G9MekjOrRS3oIc8h/sdvfRy3f2C/+ty0gFVzA1wadSEF7mRetVCJnLYdhKGqHHDjbktRG0Du1B4O4b1Wxzr6dI3Bzvd8Ax9499fdz8iYq51QXpz8xxQEY6Hg0W9634LAUWwt/vzoXT/Ek9NTmPn5VeUVblVkiqARZPMJJqu4vIdUAW+bzEBZL8wY6uLLqrLt9NRn19wAgFUXrbDa0vgaT01IHuc60o47YMg9Yi47DZJcYZZ7mUWL+a2TSj0bG3nCi77nAfpelZdWUSivCNE5IFPSUhRRrB/8yfOY61+R3PPwgWfwoweexslXapnPVddVSYXyVq0knnpHe3NzdXzyw/fg1RMThrCUxpKK2lltVCqYy1sgfAnDK/XLCNyyn5VbVC8aWlzgPNlbbv4chv/g8+pvrebUW4JVy0faRZ9p+H2T/DJWUdzdrr4RckWKMhgRRhxKIfSj2/fij97+SUJPYNMT2t9r+cBNw2QV7z7d9Gbm5sQtoglnCCN7ZoYg/66/+wpOrwgwvzqtlioiTwBcctlFyb9XrCiu1Ncmzwmhx+mpL5gLxhVrwH6/9Deeq5kntFZ/uE2DEBTY3LMEHjLfgiDMFHYsY0ALAhw3MFpeZqfXUfIvTdik4OH3RZEn77aXVLfOEowbzCB3bnoWU1PnAQBf++KDePsNtyUpHmn1ezdv47RZKRvMoNZyTn3CY5hyGH/y/M9Ww6Vbz6m311grxUFnZ+etVKdGI0Bt8lx6v8MTSH8rionTZ53pPM0K5Wkh9ObfL790xupLwCIsuAL06ump6O8VPc458sSh43jh2fypTdoew+lw3pPxHl85MYENb/wrfPWLD+amJQt0XclirCwSMSPKjtPMYVW/d/Cpi2KlPmlTWbcu41LoOnXDYUyk7aaGAZ3PuKLuOG2GA1TsPzsC0QdmRJdpe+m9Mvy+jSPtSvfUR5/tFsr7gx1fxbnLLxHvMytFB9AL3roiOIrCKPXISJV95okTGLnzB3jg3p9Gz6aPbbF49ejXHsHBB55O/uYtnFdqUi03eKV+GUFYLOPvVStzXk+92GyLKTwc9VaVerbgW8rHZJsDPdJOYzw8RNAFZx6zw0sbtR2BChdcyHrh6Gt44WgqXLk2eSEYKcK4M6RXE4DJtedzRFZIi7NNl3Wtg1FPxccwUQ+eVrn50stST/3KvmJK/bnpWfzWde/Hlz79gEWPy9tY1FOv5tQzLxtX8hslhd9zA5QrQsAOTbQVoSyeUPQIuonTZ/Hg/U8KOtX8Qefc1OmM2smezwaVSkElP3kvipKYFMrrEb9pUHPS4+8+tmMfjr9wCqdem4rbTEN2XW1mR13Y37WeU58qkBpPcBmPgGiOjf/4WGYtiuRZBXItrft5VJLiSU3pcc8rSvfnbr8P//3/+UCiHLsUvaw2szBzfg5D/247/ufvflrSAvde2sy4MDdXxzt/4yP41Ee/a32vzrv45l4r5UyfI+/9iy/jI3+3N0fPYNFFeY4Weabdw+mj4/tUnCLx8b931/ooAs14JYwL5nceUZURucPRSwyLdL+jxpeVTKnnY2g9RzOEagoZDK2agcueQ646QgkddWXuKxGfyW8d9NTz/bXBxwV8nCjNNl2uqv8axMkpJXcxi5+3It/WmcHTtQdkOuZKymW3PPUO/mb2iXrdfo8RHa3l9n/g3XfjlpvT0z94GzNeqfdYShCLWVHgiwp9ySbHzwRttVAezY8t0Ia1aeRkzAe+/wSef+aV5G9Oe2+TMLm8Y+WqZZBHMEifK5V6HnroyvVsCCXY2h2i7xyMlW+UtB0AmCmg1HPFsUjoWx9JheBGCvpuVhFhqKinfvrsDGZn53HytTQsLYT0KKXvPd+mIqrf07F0rJtMr2uBzYwLcsIQYp6rVb+ndAbZYa6alysLX/3ig/jLP/wCziT1H3ThGcjy/Mv5zI0V01Mz+NRHv4vaxDnRLlA8/F5bQ1yoTAphuSJ8FKEp8bqyviYCjfk6R/i95tmRqT4F+LOm7HDlMGS/s78B4NCjL+CP3v4JHCDGHPGoJPy30lLUljBsBvJ9JfzHoVRGBqz0+tOvTeH8uTmcPz8Xt5VGK5Dmkns1jD9+DN+460fqb9NnI4PloUdfkD9m5F3LI6/S3xqNICquOjufzH0g4gNZ+d8Wn3Xwt9mZ+WQs8oAbeFyh9OymhF5AKrAAsPZnL8tNQx5k5as769KE9jwDsg1JQGr0o/zhwfufxK//33+D4y+cBCDThFSDPNubLR6R5am3+mn/lkwilwzFFM3AtV/YGmhHq4on86vO5gobF022EDJIAYdQ6dXu5QMASGcI0JrxcLZiz9Us/ud8RpsnQZm+mJz6rKLWLmdYdF9rYyDAmsjjpFrq8Er9cgIT4PXNNceGS69ONhbdsl0Uc7Egd8+3HsfQNdtxNg5HbU4I+Xelksso8d6/+Ao+8/F70yaYl6/ZkXbNLPIGXGDn55Yb4u0CapKh8T5FIYzKPY5ia1q6QJ50CX4PZa4zczly6tm8S8ZB2VRcm39alVfOW1cuHy+KVpRO851WyyB6bk7DF3sPeqE8e+6JMMcWN3RnGGuikLB5Ru7lHvC8Row8XhnjlZqJlYPEUKJ4gFzNaaHwvL+PP/I8vviJ+/HIg0fjC+w2KgXZlH4ahP1MmlMfBAGqz5/Exv+0Mzl+LzMvn61xkwZFQ2tdRhMe+cM9t/S3ls+pJ/wiswI2E/6BVHk1n/rD0n/mMRhycB6nRkE1Wb88KioxiLHwXjVH12H8+urnD+Aj79ur/sZzcymyUsm4UscVLPWUEdY3PhbNotPMczTe3Qw8B5zTQSM4wuQefe8EgJUmhLckaB5c/lxhfNXmF9uXvvbFB7Hjr76a/E499eaaV146g0YjSPKc+TxRI1+EQSF7j9D4pcvBAOieUN5fizdoMkLCDlqTB/NA7JVcpuH7r2LsTFAg/J53qeweJmPNDbtoTb6eM3u9MpfMiUn0e9eRdtqzJ89M4wuf+H6yn7tgInEvWhU7X3oq7qg6h3EGQBt1s2xwWaWVPWepwSv1ywguL512tJgL01MzOH1yKm2TK1ah/X1RGE/9sWdfRW3ynHWmbha41bSeQ+iYm6tjbpYch8WYHRVw9FA0e7Nw0uYIk+MW/SwhWQu/D4PsM5m5AJJVQ8EdiqooINRTn8Ob5qJLO0bPRYc5PoYKm5pw/tMXX2tKT146DbGCJmXdZEEYaGhTYt0ww03ifaDtFfGyxvc4C+XZNFIGwHPVszbRPOHy1vViw3YLiw2HuCRot9qNFYckhM8xTwuG32trSBTKo6HyQYhjz76Gl6qn8ZyJCmLvhPaBj11q5DD0ug1f3FhoC69MKSkSfm8pC+k8sk9NienlPK6ujFNmGkeK2RaON3V6hamhLv50GkfC7GJyqVCsCJuAuk7m6w24UlgyU0AyCkllGReCIPWO8nVs1Udh40Oj05xV95W9KAvOnGfSxm1/+038wcY7xD3ZBQ/LVaPsaCMeIWDzRzHP1aKR0efHduzDd77x4+T3XuV0DBERx7qmGrBdnkxHaLKW9pbsxYxnuKrAi/4qPIZ/DwCOKVwKOF9JjXCM56l1ACRhuY9YcxheSgMzVjQz2jRDPZ52fN6MP34MQ9e8D48+dDR+rJwnCRxz68EfPIVPf/R7GP/xsWwa4n049dRnGw8BOg/JvHVUzQ/D0HmCjIakK3FfZ+Z9+L3HUgL32oEvmuaMacdffRVb33knbdRqo2hOPodR6g2NeQv2cbLn89wXsrw+xvy1zde6Hfb1LohwPD5GimAgjSWRQMiVJ624njgGyBGZoQn9oo+KEkDH2lg2H3nwKF59eVJvw0FXEeMCrf7N+2PaffSnVXzuBz9Jn6u25IaqsIXy/abrJt0caSEt0S73jlvCIxOmuEeVrVVOH8ex517Di9VTok8i79BxVJQt8NiKTV5lTDPWiOsTYVI3LtgVxbMbUQvlOaI5RE59QUFME3ga7P2milFUsIrzWS0812Ug5J76XEfaacYyxp8LVaUnl9Jx1I6wysypD/V34EIrSr143w5jCQDBTw240srT1kREhJXr6dgrFEU2+S3LWEaE1ycOH7fqUMiIrxSNRkN/B4F+Ykqy57HisC5vbSsnXIgIK9LG8edP4vgLlG/Fn2I92/t1CGBudV8untMMeqSc/VyXUqumNDhoSot1VsSaSA2/9rir1e8dRjyXN1U18rDnJ3c5+Axvw/YeU37Abyy6G+eHMEyw8RfrxGG4BowxIx+t/KoO6fRqzYQiBoSLY6/4fI/NC03fjePM1G/JMr665paR25ulTBl5OymUl1EQVTNOJ3DMz6998UEM/fvtmKrli/A166xilPpZ76n3WEIQwgkTpKMvs9uoTZ7HJMnRc3khc3nrNI9GzBQMjXnDRPnz6o3mSr1LwDHPtM6pz7HBGXzpMz/Ew2PPOK8TCkxoM1t6T/Jp6KAbcsMOgW04hInU22GHVWlhaI/96Fns+MuvCgHWCvMn983W65ibq+PWmz+Hz++6Dxo02qO/JdN2bVZ2KoTuqT/DGHlRy7mrOrAoppO8v+i5X/r0A/it696Pc9N6WHGyiao59WzdcI+q5l3I6Ndf/8+78P7/lR7H5ZxrLFrH1GdwGXqCsEn1e8f8cCFga03kRVJh0cGU1PBiYaSwBRTeUtECTmrIP1t3vb3kHOqG9Jhqhs9mnnrLCxdf+9ork/jz3/8MXjx2ympDOzqRewBbPU+de0xdyg4PiQWyFVtOL5CmYmXhrk//MPEwUXpcx1vVGwFenj6HsGL3h/dRfTc5DNdNz/fW7snqYE/ap0999Lv44HvuTttk4ezc0KQZioIgsHOfmYGU5tTzNhN6C3vqY5riuZzs7Wzdap5enlpgR1yEmPmFVTg3cCk++w29XgGdU6dPTmHnX99thRq7rnXl0CfFcXnRMcW4zpUV018eyRP9xp7Dhj19rnxOI5C8TVOUMsPvWX9dp0/IiCoy5+qSD7v+LhN8HxDGLEazfZIMm8dFCrA53lERzGWEe4sIF0U+1O75yz/8Ar5Fjln++bWXAgDmmafevC8RxZdl+O1pYrRsIq8nnvqV1FPv7gugR0SFjjSJ116pYX6ubtURyYJ5RiV+RiuG5KUGr9QvI5glIJhfASt3GNjebeGFVDbfqdp5/OHb7hChOZoX3uTcZHlzdcLsBT4/n31flicpEXCIIpm5wTGl79Mfuxd33/VQeh33HvHoBvP8jFxHTSDmgpDMl4b1XOm1TGk29/zp734a3/nmj/HUkRdtWpVK10DEBOvzDTQagTOfKuDCh9is5LUc5sz5UAlZNH+vWmXnWGrC9Q+/dwRf/OT96jO4Im1oFRs/mycnX6thdnYeZx3WYVeoufYdF0SSjTdLECE4f26OGReYQMM2cC7IOoW0IPucevpLLkXZIRyqRXGaPNQyPghvoFsIjX4vptxqRhJuSLAKYYWhiEpIFGvVU2/To60RM5+ePvISHnnwKI48XgUA7HvsacyuXaF7djjvKZRTL5Ud4SV0ejTze+r51zM5BKw7P/JdfPNLqQDr4g3m77u/fxgPvPoqZn7hIoteiw5wT72thLpSzgA494pAUWTTB2asK5JTPzerp4vxdwtExgvNkGAibrgh2VzbS1LOaN+tvhRU6t1rnc6rUN+LuXHZMgADjYsjnv/ssZPisXv3PIyN/3Fnojg9/vDz2LvnERx+TClICGB2voGwJ+2j9Rna7zrdyw39bjnCwHgzTSRPiCz+x/iU5mV37StN8o218Hux77q8/XzdO4zA/PGObb0UuArRSgO5W+5JkNHv8R8fy1b4C/Zx8sw0fuPfvhffvvsxvTkuJ5HfXHJSEIR48P4n8dhDzybfmTXdMAVcHUZmk6rmMkoBcB6XqNXJ0GDSYleaIsY9Faf+IR2G5LnOIrT56DBIlkzcVp49Z6nDK/XLCE6Bp0CeGhd4kk2NV9MmC/X4Cydx5PEqxh9nSr3iiUnC7xtyE8uki5HdLGxfNRow2nuJcK5ZLTUl0LSpGwt0AUUVchwbNq0VwJmerJnAmDdTrumgcUZdmzhvXUJzzyxP/XwjZaQuRUEIAnE7TEGgNHKkBhbiiWRjdBErnESPCDLY+5WHMXLnDxxkKkJwGLWvhqEa+pvMVS6gaoYYISxyYUvzumrPYl5G7kEVwjKjk3aTG5Ayw4Qz5pKLTusZyTxTlAjozxZRB+Q7vsbS0EvWtmKomJudxysnJlS6s7wnqVJvH1kl3r9Ctys9IOVjcnx5ZM69h5/D+X90SdKOFokjDAyOPlafP6kaWKSyrCtq3Mti3eMqjMRezlwOAStoBBavbzAexxWsF146DQCoX9zrpIWnmrgNBXJ8XMJmQpfCIzPzY3tsY4I2Z1xHGLrC77P60kfC7130hmH2cXTyelh0JPyS7mWhg2+Jdcx4klHCFXqOPvkyTrx4BlNxalSz6L+3vWc3Jv/FGus5ItLHZWzQjOtcqY/lHeqp595zF5/KKtDJ00FchYLVKCNNDorb0HmuaUvhDUo6DsLov0566nkfZMoEex90L1XC7zUZ5JtfPog/evsncNenfiie62qrGU6fPIvZmXmcOH5a/Z3LSTYf1p+lzsfkRnst8fXoSjkBbL6gjU/C35op9Uzmp+kOL1VPY9cH92M+5vvSgERudBiuzLX503aj6ysx2XkKPy91eKV+GcEViqop6c42HAJPQzAEKexyLxTNvzHFgsx33LPYDFwgnG8Sfs+Vneg7W9hoxshcG6KoMBzozEl4uTLDiCGeJTb1JhZq7r3UNuQVsWKchC85FF2D2XqDMFLHRsMFgSzjgmOzWpHk1FeEgJUck8KU+vPnZORAEIYZdCqKiGJwkePaxDqcyBJM+IKMXuBWaX7ednSPe5VGVck1+h1CKB37hq4ImuuzlA9b4HBell5PnmnRyU6EAOAUMNWQXPOdQ7nnfEIbyzs/8l288798RA2NFEUvAzlevabwmfHaMiWcG7nsdm16xJF25NqscHZRfyMjB5hj/MfH8I7//CH86IdPx7fQdgI1OiF5n2w8VeXYIeDzr5uFQqpGOKY8c6V1RZ+ttKqe+kDPqU8Lcdl8wqr/4PIgmfB/VUnO6CM7wlNNNVENTIG6ZwiFh827NOXMHX5f1FOv1SChn6YPWvi9a2+LG0YYr7Uwo+CZK8yY4+REGpbvSlfiY6qm0jjWmHFYWEY/xq80T7223ui/udIXsvuTdoQRSPLN5DNnbQg1xUd5vstYXwb43uGSc3QjpcI7lbEzJ5c8+qNn0+eya+YLenkTucExNmkkrdyr64570jY1g3HcDBsfoeQra83MWNcRdCl/y5a7kxoxhpaetL0ffu8IvvzZMTz71CtWm9xJZe7TU0yyDXccSQtxW/MtnOqx1OCV+mUEl8VS83S5wDd0qbDbmzD9N2eW83MpA+iLw3HMxpfl2dDpsv9utjj1cHbTVvSP3t7i4fdmA7byGB0btghVtYQyJtRkeF2E59qh9Lo8+/S3NWsjT99kLODwDZG2C8RKfROlVioA8d9qaLk+/3qt6ve2UJ2kS7Aj7DSlPisfVOurFnkixrWZp54rAdp7ZhtutpXevUbDgNeJsO+RgqCuCABK+H2GIhiGYXI8nCsHntMJSKOF0/upeXeZgE3bFfnGyjjS3ykmz0xj5vwc5mal1Z4LWtbcjWnssSJ8SBg0U9A1oZrzyKz6F1outUHkqSXthPa8ylLKjEHP1E555sQpNFb1JM+izxPKDU+xocKlogBZSBkhgCgKKAt6ZA3jNUJpNWk8FXEvpZNG5/CokmxPvUvYzOIRGeulYs/lrGKq1tolSrJqhGe813z2kTQn2keL2rDFnHq2D2mRQCGbpzKkmr3rmOX3KScIuBTQPAqmPB7N5t089ULz1PPnGIcFLcDL52laGDXF7Mx8poFGKOnOwr76GgWkAgzoyi030NhFNHXDP+9PK8g6Kk2sTyHX2jRr/U6mj2P9XnRRVGyORv9xWXm2YJE1bU5TJO/c7Bvkt0ag80Zu0KD3JZ9CfmF7pLY+zT8cp3G4HHccqUyRzlUuP0mZQK4JV6G8vBED3Khp0MmIkm6BV+qXEQSTSBQHMpGbzOkQsAQefkxK8gxFCXJVdgbS8OrEU88WeHMkknJ8XxOBUMkVl6G18feuSrBM8KBtWN8xRlsXwoXCiJMNmwnJSj0Dfi0Px3QV/bEsn/E9/bFSbwR73RuajsFcvaEWPqLgtKdzJJ8gARBPPaRQwosJGmhWYxOenhXObW9m7k2Sh1M3N2rIjYQbw4Q3V/GqZBXKiypT0/Vsb7ZZIbtBEFpfWF6hMMwUhsMwTKz5meHE5HrAHX4vvJ8Z7ytQFEcufHODkoF2pJH5TvOqiqJMlucs+q6XF8Ji61BTatJCWfYz0+r3hAbWp3yeejcfcfXR3POhbz6IqV9ZnTzT7rMt3AvvmMavHPPXfGvyG+eapVApht9UcdSNRX3cU+8Iv49+040nku+QNpyF8mzB2XpexnIJeyrWXFYNWIqRthEEKj8TfWF9pUUeo+/18Wknp16btwGZ/ydO1nB4ZgpBX8V5OggQzRdjnOkj+0P6WPs5yWeTUKKQ0sOV+IRefX7R50onBvfUV4TRID0RJ713ZmY+00AjlPQmletVBT6JEEtIyzZOaXPOKpSX/MumrQUc+UkVv/5//42zFoJYB8n7ZrxIUwLja3sq8shcilWKUs8FjqKeeu4U4HAZSovcE/07VK8RvJIZqnlUDBCtNz3sPZ+8nuWp5224nFQA3CkmeemYt/dV45C4AHR6r9QvJ7jzIOWG1LSNJgtP9ygwgXVe8dS3WCgvITv+rNcDTJyZxuMPP5fZD61iqyp4aZbvxBsViuu0/jeCAPvHfoqxmYn4GB626WjKCTeWZIT5SQ+BrXDIXDNYvwNA/5qLAUSnHNCLNNoAYK7RSDbPhkMIF+9fGE8InY75Z1e/Z4KQsunR3ymylBo98sK0FYB/2WBz36Uoceu5esqBeY5D8RPKtwPCU2/uYfNJFRQCW+UVBbaynos0RC9ARMNnP36vdbyedT1ba5n5c65KzJpXwulZc70bRTBIQvjkfJYKHxFqjdeHhdcKo48iNGmpGUAazaR69TO8I2EYWkInF9ozc+ozPEgRH6HKGHt/ibQm+XfWEWy0DZPf2CynPvP0A1HAL/pc0Zcejenso8Nwk3i3WZt0nF1hy1nRPJnrqmJHJIVhur6zjuqixhe1kr/D6NHLop1c9BYpMJnyNj5vJd9vBCE+vPt+nArmcf4XLpLeQ66gxGttRa/iqRfKi1x3Lsh0JS4z2es1T+0Is5Z7KqnhREYiSP43c35ORghAvn96j6GBphC5Ik6sdhPDQAV17R2zfUqLOrMuNH+1oS299vIkgiDEqyccR+bGnyL6hL+zjKinXqXOAcVFF68EYEcMcANx3qPw0mdn700uJxOQOoZEmw0595LjRpkDzhU5o6aDmr428dQ3i6zlp91YdSUcfFZzQAD66Sh5Iwa0fRVwy5/LCV6pX0Zwb0iahdXRhosBZCioznA0suEYYavlQnm0MAuA+UaAkTt/gD/93U9j+uyMvD6+Tg+/N98RxpPlKaSeIsULQcf9noeeiujrX+H0mtB/C+VEtdSzazSlvRHK51Ere9wu99RzgSx+cvKvuUbz8PuEBocCS+l0eaFp9Xsxfx1MP0uA1n5TlZmMNZLlec1ql75n7onioWZp/QtyT+ge50Zgp36IfEMhCBIBx+HdNfdlKh90roUhjr9wCp+7/T7cu+8nmddzgYUrvkCsKGnrzzxP8UrIdAN9jmR5o7Lyn7U1JGiMvQkuj6p+bFoY3xoJmYnhk44v4xeqkCXqI9hCe9a7bDBaeLuWYtFkTdsGT7v/f/77n8EH3i2PXzTh93O566JQI4NjrJlSn4bfa3w9pj3x7Bo+YwukmlESrpzTLCN11qareLK44C68rDHNWSlbsp5L9EmNp7Rtqy9BKIzhLoOu+Z3Soe0XtiJRSfrOjUXiOLaY3B5IpZ6v49x1eip0bHX+kXrUzbMUgzw30M1r1e/1/Z3eO3N+3rpOGPH582K+89NDVfyHq9+NvXsetujgdVtoP5sZj9N5bPiJbNdqJ2E7GXO8CdL3qM8xIQdlGN14ilnu8PuLtfB7+5qsWjcaRHFEDs5TmZNGbVMxYrtCzMVRdo6wd0KK8yi5vDIgjzyLPPV8z9bp4siqedPMuJBEVfCueKXeYylBVL5OmIY+kc0GcsfOb+PZp1+OvmMFvIRgzTyCABWK+CaXMmlToI0Xyivqqa8km04D58/NIQhCzJyPGPHE6bP4+PtHcXbqvGr5lh7k+GtSnM16JhP26HeqotEIiKeoIjws1vnBuQwwnBlyAcTeBDILa8W/XXLJKgBpPm2zcK65eprn2awAnTPX31KM0vtePTGB0yenANhhs84oERFarSllbgFBM/RoXiXxW5O5yt+lrRSxucaUr0yvigJX7rtQDNRojdDa5KSn3r0WQ8Q59WGUy2021bm5nIJYsgakgkKjM6w2NC8Z4z+icBAXxJR3ZmjX5whXUMh7Yd8ZY4Qr/UTz1Ce5zSYdKRGCtOfYn1YfAruyARfaDf0vv3QGf/mHX8A3vvQj59jBaicQfCXugf2cJG1F54MA8MiDRzH6tUfFM0z4vVYXZeL0Wdxx27cxfXZG5WfNjtrjhfKyjHvO8FQ+dy3iXUaWeB5qhiLxDfmNerJcHkiFrzQCGSFizUUu0Mff0xNfouukQhCGdvj9pz/2Pbz9P3+4qeKW8iA5v+i576tWEAOuI+IiogWpNqYZ/biyojxXRUUbY1u+4XuXZpDnc0urfi8VLEkb9dSbftB3qZ1kUg9CHHwgKnT51S8+GLfN5YP0elXRV+uY6HOQX59E3di3tYQsuSWiRd8rVc98w04f4ulfrlQvNfxe0JFPVuV0N/fUG+LS35zF9TQZI/lnZCB0jRfPsbeUd/PPHt1A08zwYpAeWW3aI0ZLJkcJGYFxynnVU2/27ux3YeQSHlnmPfUeSwtGoBPewUBehEgAOfHiGXzpMw/g3n2H4mt1oSCtBGw/AyAWZcaIKAMwhdCSQnnKsTeZXQttxjffkErsIw8exZ7PH8BPHnlB92K4vJguT2GWcO6ooL6CCCyJEG2en2Ec0BTOBhN4uGLEvXsyxE95R/FN3FNvvc+k0RDzOTz1riJA6qZLiL518+fxvuE9AEjOpBp+Lzc963uNFkKrCanLzJ/XciaTfttChOuZLiEj/tJqk88t2pOsjYcK3IeeeQnHLwlt4dg1x+NnadEbRoDMzKkn7yCAPMYNAP7iXZ/FnR+5x3quKG6k0OU+fcKm0/Qh+uQCni4YZJ65m3H8mBZ+L9ZVxR5THoVABXM+R3riIp315HiflIYGa4/TGRpaFOWbGxgeP/gcHrz/SXz4vd/Ca6/ULFo0wbER8EJ5pi+w6M96Ny7lj78b7bqDDzyDL336ARx+7JgcV0q78EJFn729zcPvhREm0P/WFBtnzmmGYpK1rtBTUZRS/ukwvjC6dWOiPe/4kXa8bW3Mq8+fxInjp53GxpSH2sqoVh8mCAKsNKeYkDOs1Wg2xrvEc9lzXPnx4r6MPUbsh0qbTk/9HFPqafvCiJ/eN3N+XhroKZ9W1lXQCJKURte8tfiDouhrEWFZjgO1sJr5uw1lyYyNW2G05zA/iYnvnZrHm16jrceVqyKl3jiIonvs67S1vecLB/DJD9+jUs3pFb/zPRJyjol7tCgYh1HDZbRUnVUmhN9hYG8WrWiQKNvK3BOfwqBmt6VFciV6Q7Pwe7Ovij0n87ZlAa/ULyMIC10iiNGNMr2+Xm8kG4IoaNVEwNGPZ2OWa+LFS460m2vVUx89o5JsAAE50qaRfGfa5Pk7tO88CiGiRxEaMrxRekGjECtJTqdLoaH38E+6sYnQxAylnfY569xT811tknnqlf5UghBzQUCUC4dXlgv4ifFBEUbIv89OzWAqzu3vo9Xv2bi5hGJX6Cjtz/67H8Nv/Nv34vTJqSbh98pGxjw/zpx60V/avC148Ar5qvKYsfM0GmnkxOb37cH0SmBujUz10DZKEZoojEXu54bkH0Goz9cjj1fxxKHjdpu8eKIyN1191t6XM3pFiUwA7DWXfKfwBvIA6xrN65M+o2J71JgAHz0/UH/ri/lEWtAnvafO+YbDeGW9S+bt4fMBoCeP2B4b3m6mcsg9H6rCzQUpmzbxPYGZT416QzUEyRQkm64VCR+pWPdSuBQ67lFSzxRv5qnPiB7SYHnqGZ/JNtDJI+3suar3kSqcVh8NPYQnuKJ/lA6S9sh+oe2b9QArNU89N1jbzaq8STggFF6qQknxckWgZO2PIqeehd/TozpFuiHp3Mz5ORGpZf2tGIsbYejkIca40swQoRtKYNGpyRB0DOIHl+Opb1KzJp+nnp3wojhwtL0mSYey5C9Gh8JL7h09hHu++WOVbl6T56XqaTx/9NX0AsOrlbGmstNTR15M5pYWtZPIGHHfuMGdp4xmFcqjnnW77/nkdb3wq80/mqX2mn9keeqbKvVzLGIg2bbamKhLBF6pX1ZgG5C6UdpCqhBonJucvfA0DxbfJOii5GHReS1/6f1WF61c1iSnjm7uTLiljQgFwHWknUKjCPcFrDGkOZ2cWWnKLR9n1bshvFK6MuvKPYvotTe3s7UZ629rk4g/K/E7Pz8zJ2izns02kdSYFHkcrPB7+kwy/1YQD5I0YugKW3b4ffTbqycmMD/fwJlTZ1XvYjqfFQGBeYOb5tQrwrVIJWDKdl4DE+2faaOSJgqK99tg88q0a+Xumw2YzZfXXpnElz7zgOoNqIS2N46GwVF+wsdVrD3Yc0JVMLXICocw7vISa5WwzbPU0xOI8BsEga2gM8XcKCWClzmEM9oXfhqIJtA5w4l7jFIn+YlIn1Loz8zVJx5gSkO6pu2/tZQi/g5MzRPOw7VpnvJXOa5aBAHniSuYpz5f+D0fb/ae6b3NqoarPCn9tzCMEk8996C59mYgUurkGpD7lDSCmH7oR/5Zz3CMT2b/LJlClxFWrYg99ZWK7INysgeApF6D/VzXe2wiU9Dwe4chnPehofWFzXOjSNDT90QEVcKXU8zN1kWVefX4W3JT0AgSHsJlKv5v2j+KesaYNg2/zxERlRdpSHW+VC5uROcRi67oggjZxxfbX3I6lXVfD9Tvo+vtebnxP+3ETW/5iHimZkAx0VrPPvUy3vXfbk8iaXWnGnmmEsHqkk/sQnnxp8tomXNtqdFvwsDIjKdcVomb0E5Hyas3GAM2f69eqfdYUhCeh1AugDAEgh5g/tI+NOqpVZ3ntklrmv23FibHmUF9Xlo9k8XWhEk0GgG2vvNOfPvux6LrE1Nb3DYRuLUwI1ffo+9C64vmR9opG7qjWBmtviyENTW6gQnJGeGs4l0QWoNGYAnVYWgrcCHbALlyqUUjmNzX6TjPzJnHJPpCBYHAItQ6hz5IQ8nTPMSKEITS1A8uqDQXrqnA1yx1gtMuhEXH5u0SOkwfabs8DUIzwGSdA089qTSUlh/zo0ZrsHchlJd43nzob7+JO3Z+G9/88kHy4PQzqn4v53RA3qdQyPh6ZF3UNlthGNDa5QILb0PNR4/b0PKfmUJre9CYoMv4hqj8S+ji86s3Cb+XhfL4cVLC812poMEL5bH3rdfVsOlTr2mETKFwKYfpuLtSDAwmz8RRQXEn0zxc+c7pupVKW5bSGq+JPIXgHO3KyCqF31UqTVI6lDoN5OVy71OoGTGFkm/vERGtzYweXIBn/M0Vfk/bYMZyZ1oFU0CzjOFBwD31+vwC7LVsxmD/1x9Njj4z/U2U2pye+hAVRdFgewsbFzVaiM0Prkhkvlu2xmwDvP03N2QCsad+he2pl1FZyjq2+qTxXD5f7DbT6/T7WkFm5BRSmvOkxwQB3+NYvx1Kq6roc3lD20sagdvZ0SxtT8he8p1Pxc6Xs1Pn4+fJ+RqQNU2dKC7+lpmm4vDUu1LBONIj7dK26wFz5PFTRtjeZaJxVU99zogobiwvo/bDUoFX6pcRBJNI/g6ti6avuBTT//hSPH3sVbFInNZvoYxIQVuE39Mji8xCja3ZjcC9OAFg5twcfvLI8/jJo89Ht8eXVQh9adiW2dRTOjIVOK4AEO/Li8dO4QPv/rp9zIwSeufK813RJ0PvuAJH28nyBnOllhsUuDBlV4nmodY2Q088NprxgxlQtHBKCte8A2AVdAJgRUUEQSAYOj1HtqmnPkMo4YIeVRKywsu44Mzb0OA6elBr12XEsTzoGUIpVZyNUm/Vb+AbNp0joSOnnhmtTFjnw3EhJtrHiFaItWf6ms5xe16lc0QKi80ELW1N5OkvoI9llqeerxltzSbjVbGNLFrIuwjzNe/OCORKobwGu1bMu4rhcZRW+zm6gYHxdtZuCHtNau1qCgY3DnGld+LMdHyP3Q3V403WnFgjgeyLq54Lv85+MBsjx/tToz8qeptZNWIobUbYTA1yUsFM+I7Yf9hadgjJtN9ZUQf0uuRvxTBAw3fDMMRPD1XtOUl5Zj09ElEz+DQaIVYaT32PMtaKs4B+/5H37cWXPvNA/LtNp0sOEVAL5dn8w5UCQWnhiqx5t+oRuNwrydYu/9t6D8r+12gECZ9Oig8zA6PquQ9luxSS58r5EH1rywgZduim4Ht2M5p4eoxtuObGTpvOiMcpe41Kl/23tv83gsA537T9IGqX8WptTjCZQhgcHdG31BDtrNXRxNgw34aHPFk3yr1yDbC1z+ZUJh0ZRW4BxVMff/hCeR5LCk5vCrN+Ny6JNtUztfOK4qQLJ1xhy1Uoj3rqTTuMIbssf6KADl/wDVnlk0YdZCrJqoU3+vdDP3wKo197FE8/cUJu+HCPsXnuCiVfMCFdaUeEE2cJ1Px9WoKALK6jb26srYw+Jm05lICkbe6NsJ5rKx/Uu0kVIsv7yeYT927TPgtaXNbgQHq2tPdvKcEkFJi2ycG9YXa1f5t2Pvc0Y0KW14P2w44KscdK99TzPGxNCQ3wy//sFwAAh398LKUp/r9K7AlIixulYxLl+3MrvD2uWvi9q8+aQM3nRlODiyaI5bT2U0MQkM6D9P1WrHWX5R3na6OXCeSaMcllhAp7Korwygy5GYKiK7LK1AHJalf3GjPlmCmK3FOfzAVlmtPxylJaXYocn0aZdTf4+nZ46q216Syq6p4D9HKzJ5p0o7CH9pnvY7qRwfxbpFqwdZzZlyaF8iw6yDs58pMq/uDGO/Cnv/vp9B7LIKkrk3TMjVIfVtJCeVpKiDZ36/MNsmbcvD4TFbrG7HHgxlfNUMAL7hoIRULZy3g6knmGNe517mVneySiOWuUem6cSu6x5AOljYy5qimkWtRj+neTMc9AM4XRpRSm74T0O7R3Fs1orhoAc9Dvcga49x6df5sK+zL8XsoNXE7WeKzFiwNpDJXpkfbc5u9OPx/eGMKzlfpEEVf2EHfak91m4qmvN/Cx7Xtxy82fI3TY40FhGU9NTj2/xiv1HksJkklE37s2uT7rjFx7oYsw2izlk1kcDbSc+gZjyE0ZuQjNiT7rpJCSOKc2SAOY1fxp5qmn+e805JAzR5suTdAKsLLP5AsqCpwWRszGjJ8PTOl1vYuIRlYYpxFYHE2z9tNBUHO02AbvrE6bsTlxJSHssQW4pG/JJaQyMVc+uMAev4P7vn0Yr70yaV3LlT2rzoLy7lyhyLT/rXnqbdpFmovyLl0yqQmPN33rJd6+JPLFYQ039Kmeevp+gjBJhTg3PUuOqEn7EVL6xdqzheVGw/YiafmD9J3PnJ8TQpBdFyNu1zFHpFIHgTRs163wAdG7EmsKxFDjqH6vGdO4MGbeXVrQRwp0aaSILfSbMMsshV2nJVuYMmcK215CxvdVY6Z7zgHAZOypz5NyQderDCO157LdX/3ZWYYblzHCFZ0GAGFfj7qf5g4LjRW/HlJMzaVACsMv7Vcgc2ep57Vp6lClgon/vV/wdHW+k/liCpv+5JHncey512I67XHQ3hPdN82RdjRCjhvcaR/o/Q2iRMmaM3KeaIj2+yDhp/Qel+Fc89SLnHpWzAyVVL7idTKajVkW34naS6vfzyshz5EMpKxR+lxlnLgyGbqut9mRc8/Kg2YKo4unucZSM8xTYvVUy+bfacV0G40wQ4YNkmsoktN4zNzK8G7z+cn3eYvOeD3x8RKyEGuLd12rOi8KPTqQ1OmhU4XL/q71au6JHzFXb+Brux9Kjm6k9xg6Jk6fVWWKpPp90ra+PyxHeKV+GUHkzxlLvqIoAlGV1qT6PVvgziIbymLVCoQBqQATE2Nd24xJiKJvzMtDPQKGkdDjLoRlHHRzsNuyzpOljEYzYHDBiwnASaG8ngoRWNJ7RfgwF2q0Z7F7VC+syKGzFQFXyGBWNELSVj37XQklgdzeaNjChSXoUCu3pSixzUhRJMz3Z06dxd/+2ZfwtfisXlE8kcwj7i3n3hL2lXjH1HP1zBMnyO/ps6igqNHOc/zUHEvHxsPfFQ2/d53bbQkKTDnUlSVbWUxSaMLYuRdGbfKTJ7gBRMwrJhyHTCo0wsjbfv027Prgt617LU89Xzeiv2zuZqRaNAvhayhrKrqG0x1fr3nMzDiwNZwUudK8IoIX2dEuYU8FjUaAH/z4KM7/wkVxn+znZHp/HAZFnk4QtRuPFXt/fI1b7TM+kYbf2/dqApaVQsXWnWYsE/zY0Z71nbKerTb43kF5Qm++I+0mTp/Fni8csKr4A9KTRfPK3QZ1jd/LtA+9wCHnzTYvdp5UoNARBCEpzgmcOXVWuSe01pw0+gWJ0dAYkaxnxPTUGwHe9Q/fIP2xw/qt8ckwVn3nGz/GqycmrD6ayCbNMJXyZZtPaQZ5Ke/YyjUtqsiLIPJj17iXXTdgwbrGeOr1Aq0ypJ830lDmsTRqyDHi9AOhuibyQkvlUmlqsE9HxCU3zEbXyOdRaPKP4CWOvcQ846Xqady6+fPJyULcgWVwbnrOPCi+zs2reVSZ7qlPNyTaf55C0mBz0RUBOT+vGbvdRksKLZ2s7khjFGsiptM47vSc+nRcXn15EkP/bjs++J67xTNTTz3nb3Z/liO8Ur+MwCesrtim1/f29IhNVSof+u+AVEj4QtGOZ+MhQebv6bMz+NiOfTj1Ws1qSyiK8Z+0UJTmLeS/0TbEJkmLt2meIrbhav0w96Q59fqYccGaWyutyALuQRJKmL152WHKTRSSmJZEIVHmiBHfzG/uQnn8GfaYWBsmGxduuLBCydlmzhEEAWZno1C22VnbSyLz73Ie+Qc5ZrzNRx98Fr//X/8Bjz74rPW7+bcIgyTP4pbjdB6ltJh+f37XffgOOS6HH+1lFcoTBggpxAWhLuhlCUX2PA9RCaMxap7nqAsWmqJk2m/UA5x6bQqvvTxptxEoa8KhDHDZUq1+zww/FHzuavURrPcdKqdO0DF2GEeTfFjNy8aFnoZdDdusofd9/j7M/tyqJBc++jHud12Z4w7DT9puRVUwPvPNH+HozwL1VT1E4JVzxOXBNJ56voo1PYDWWhGCraVY2fOKryveXvpMQnfdnrNCmVYMUGGf4xxnJrB+/9uH8fG/H8XTPz1hG8mUsFAu/Lv4nzVHoO1/Nv+n37ly6rmQbq99OS7ansLTwDT+QdeIte86ZIg5Wo8npp+/HxGpx34/9doUdvzVV3H3l35kd9rUpFCMb0LRUgxgLnknDb+36bb6rxjFqMEZiN6nvoeQa8IAFX48YWi//6x9SKOfXpeGrcvf+L8R2rQVRRY/BiD3Gq6kMn5L/9ZqAzTLq06USXadtu4bQeqY2P6Xe/CjHz6FL37i/oSW6NO+73zsqRc1MywZwH5mVt0Iaiul8gfnYyYioFl0WztV5+vaviOiqrgRjvGm+Lp5RX+gxoWJ05FRMSmmTfnsvFyLpp2PvO9buO7/+l+Yi2XH5Qav1C8jCIscYwzWl4g2j5TxsE3MUUSIosGYB2d6qheKCbdmgR95vIqvffFBPDz2jNqmYUQVsum6vbJ6nqvwYhk2Qou3EQ9QMn5U0eaCFtvoejVFyxLY2SbPBCO6sQkPPdsEOOMM2HM05QJCaWXCBnmOaaDO5giHyBcnvzUYHfzsXj0VQt/A+JYakNA3Lhw22IbaCMJU4VGEdU0JSqJY2Fydqp23PnnY48naNOqrYi8683iItal40Mz4f+Yf7sWOv/wqjr9w0vre3Jfm1GspC9Ea+Pj9P8bMz61Kn6UpNVwZ0OYrmRNhKAUx4VXkwmEy9m7BTUQOKOtPerHZHFE2cY5EMMgQXiJabQOHUGjjImciTFw1ptnvp5d56jVFwBJ66AUVVqFYCWPWPG28qr4wlvXAOkrOtHPXt38c0XppnxrqKOYeF2KnTbip/X2mp54YbTVPpGvv4U3yPcltsLJ5P6WPthmF37v3QrOm5mIFb77esBpQ3zfjVS6jPN9H+JpSPZTC6GWPhzB6ZBixRFqMspYbDT2nnobeJr9WKuI98ug2Spfb+MKVhOhvo2TPz9oGAmMU4/slfa4ocKpG69lEJgXrzPdkXaZpUfJd0shCc43KQ8izuPGY0hq1yQ0witE6Q7k1BhytToP9UGcTmXj0oaP4xl0/Sp4FuD31rvQ2596p9dt8xQxJIr0MUZFm1qxFp/VdXP8gCIJE9pub5WfK2+N2fnrWal+VR0J7vmTVjbAcIoH7VKhkDnJ5jnU0q0Bd4HLsGLqV8Pu4+L3gb3Lvjv5OPPWEDt7/Rr2BVRetsJ5t59QzpT4VX3D3SDTvTp88m9mXpQqv1C8juELt1HxpRItJbKrNrGlMsbCeyze5OXmknQidixdrPQmhdygJ1ByJ+Ei7RLFgR9qI0DM+HlJw4JtugyhAqvdcFbTIdSS0UaPFeU49FR4cBheXh5Ue3yU89YqASr0qWpoCp9mVU8/niKVINGw6aAQDnX8JQ1Y89a7UgSBL0EvO7k3fqxAOQrst/qWIomBtuoTpv/j0d3D2V1Zbv4XJ78z4wBQirZ/7vvqIPUbxfUn4PfmNKkXz9QYmzs1gxoRoB/q64IYpW3gkmzhZgqmXkK1bZwEqNx9JhGwufGSsP1lgku3ehn4tD5IYa+Zm53Hb33wDr8QhukK4pqHE7N0lRdM4nQpP4GtEKPUZESJcyKd1KaK/K8JYpCnfrhzk5PdKxQpzNvSaI8hAwqU1j7fLAJymu1hfI0SIg2NP4wPbvq6sKZpelcFrk3UklRb1XkVZ4uMh05zIPb36OdeCfhJdRd9BeiJMyu9S44Fj79X4PYmWUXOuucHCYfRqsFBbtQ1Cj6awC2ODYjixjHx0LrP17Dr5gx5/6jTgMl6a5h+zNuN5nlVYUKvRwKNhzPN6kvoYsSIBwx/S4w8zo3mUcdWMKzyygCvlvD82H9efyyHoUNZ51A57doaBQMOezx/AHbd9x3qmO6fefr5MzST0N0LxN7/G0PrR7Xvxe//1H6xnAKknXfASzYhF+PqKuAAkz+fm42za5/uGzqvZ+uUGDUZnSOaOO4XWXmv8zek59VIGnJ6aEe89DZmnc7WJgYJHr8Rt1sk+Yoyk1MEiDH/kC54Kox2jqoX3Lwd4pX4ZQSzm+HsrdMzKdWlIYYQzGtOGxniYYsot91ahPBbG7xSC2CbPF7yx4lFlUfMoqCGAGQKvFKRD8R39t6t4E7UIZwmSQjlh7Ua32UJKlleSh7lzD7mqTBElT83RYr85zygV42qPiRY6bPojoyYgBKFk/jImHpDQN2GUYqG11NupKl8Zir4suqdvkrQdQ67IN2bCVdAwBZvS5/LNilfLNffR8HvhhVW8KmHAwjwV+nlONRduK6H9Dl1hgVzgFn8z2qiBRlbMl+tHKGSK0QqQnkh6b70e4J5vPY5vfeVh/Pnvf1bQ5fI6Uk+cxScy+AoPTefHUVnvn+XxciMljcxI6QiSuw3tUbsK7xGGENqO9NQndUKI55GHXKvjw59rHkNe7y3v+hxGv/4oThw/Y7XVILwpFeTk3OVedv7+gyDAqddqGLrmfXjw/iftY7+aKYeK0OsOv7f5Di1YSZ+ZGnGUex17oTavaEoGV3ZNvwFNAbJp5+tDjWSgdGjjR9trsCMRmcFEeMhF9IhunDHeUOu5zLDI0xey6vaIiBQmZ2hGe76Gzd8r+NFySrvyXdq8PCtlzeWp55NdGGQUI5iaPmE3Qn7Xj820L9PX3anXpvDev/hykk7JMT/fIF5d93sC6Bxma8ux/9rjwBW3dP2+eOw0Xqqetp4BpIXsDFZMxOHyynhRJXPlqlipn+Pz0e5XGrkE9XfaJ5d8rr4LXriVe7dzzEUgu4BsUjPkzDSG/t378M0vH7SuUw2wimyt9ZFNKeudmFB5auilvxsZySAxrCh8JOmnV+o9uh1mukrhLZAXAWjUQ6vaO/1deocVazEL8ZPMgSwa1q70sDJrHt/Ak3aif9Ub1FNv96HBwlWdeb1UweGhSZa3SgpLrvD71PpQyRTyXR4UGt7kipLQ8qW5kBKNmxSeBC2KEigUI8s6qgi0Gd6gSLggF8epDnzDS5wgZNzE5hM30Xs+ttoSpZ5bpetCuA7EeGrCl+apksYj/Zm0naivdC2CXWvPG8tTKwRvKfQEQVooiZ51reauJu0wIU0bByYspkK3ITu0crjrLEXBpTim9i1ZTNB8L0NUbRqsdvk6cikDmgJGwu9XrIwEsZdfPCOuF8W01DXkPkIIUIwtTIDTBAvN0McjGyzjX09FjHNWRWUtOidthwvFxFPvSCmSPNwec5fwaHtW4pBVy8Ntz3suKD75/Kt46RdWoLGyR+VLpr2XX5rA5MQ5HHvuNduLnMxd/TlqrmtvRVEUKG9mhSOZcjVnoteSr8ixbry/GQq55amPBfmAvbdmfaHP4v0AqFKQzmFVyWNrhDoRtFB51djMDULxR89cSgNXUkSutQjv1ZUqU5xQjWRj6WjWXsafG7efVKFXjrQT/ErlR3LvzjLGGVp4Wzxiwlb83P2xaGHvnxf0S9rLUJYA4PBjL+De0UP4ySMviGdE9MkovWbh93xdaH3i+54Yo4o9b7R9w4TPCwOhonxTmWAFmwdpLRC7oSQSILTnkZ0aYdrnc1zOaXteyOhLrpC7HAzmH6qnnsk8E6enMT/fwMlXbaNNEjVL55nCAwBlzfNnhso7oXyEjNcrJybYfsKM5ZJVuU9zWuLwSv0ygsuy77KAUk8U/+ShTmrejyNkzYBWv28mjPMjX1z5N4lXmFokeRuBIyeNKRrWWPBxoDmditWcexgMHVkKPL3PFUqveeolEzbvgjyrIcMJmwlgEWNkvxN6jUfNVn4j+mbOz2H67IzVpqoY13VPvVQoU0FIWnJZu2TD45uc8CATgU9TEtPxcVun+cbKlZip83MIY05qFXWzPJv2vJGKIf2CCSKKUBcEgV39XhFkZSX4ULx/2W6TYnohrHD/hkh94XzDKBNsDlHShMeb8wj3Ws4Ka6VtUBg+Va83sGbtJcm/aTvRv3mhPPbs2EAl1m6o3OOY03WtUF6iNOj8jIbBA4jC8RmvaCjrXQh5XJiKo2R4wc0VmvGI3Cb6yJV6h9BG+2zCK6nwSMeMR18FjQAfHvkBGisqmP3ZVU7DQRCkgjuPvHAp8TxCKGkzCIFKBbVzs6IvLt7A15NIt6CRS3zPEwohGbuAK3GB9d5cIemCJzDZQI2GIHtyVqSD+U4Lv7flC2VOsvWctpn2XfB0M9cdx2o6PfUVeXSjyKFXjFciKii+35xkkXpozbuV6SquaDY78sVV/Z7zafc64/u/Jr+Z608cP43P3X6vLr8obUS0xF00f8MG34c5TD0nasylRxPv/Ou7ceixF6yH8X1BLQbLjGiNunRE0PWu7RucZl4w2OoHWffGQJzyMpuvGKQ59fHvSj0frvALx1Qo3wUANfxeyAZMhk3mRExmXXlnsmimzRuS6xRPfSO0xyGV+ZmRjr8nQkZaCFnuDwDwyksT1vxPC+XZfMSKVPZKvUfXgytBiiVMhEY7Qpl4WHRWeLK2UQG2FyoxMLDnybw9LmjZi7FC2uGCsaXYKUyaGzlUJko2bspsRFixIsByD6TZtMZfO4XGyh6rP65QJOoFksxZ3yTMb7JQntzA6RsKSR+1UwIM6CZn/r1ty+4kZNnl+TO/iePLwhDcu58KQvI7V/EkWhHZFUrboIJyhmClnUHLNx+XxflD33sYtX/eb/cDiJUvNveUDSwSPGi/GB2KBzRoUE+9nFcNtgZMfzThRQqDUpCNiKY0OeYmm2eq97rBYxGid8yFc/6+oq+YgJAx96LrlPdKhEgjiJEHWHRaa4opzkYJdkUl0GfJMPHoM0/4PU+lsYxFgBoVpL5bUTzNHjNzNCLnIytJ+L12HKQMDbXbFRFLoRwn44mhdHNl0YqeCgJGl84jGo3AikbTIi+EYVkIvREq8dGek2elUs/Xgyu6iVdlDgGx97lrFNiCslCmVQOOLXzz8eECvBaBYUXQKLzBmu8N+0g7bc6pRkPHmNNweJenTxj1FcOKhXiPefSJKqZ++VJxIov1DGUP/cDeAzj3+ouTvxNPPX+3FbnWNCWS791uTz29Jzun2GU8seSi+Pp79x/CZz9+H449a0eyCEOaxmNNXxVjGgCn953KfWl0XXTtmVNnsXfPI/j+tw+TvihGJm1fDGXdGCE3kHWeyGzqeJNFCrl2DP1RPwOsXOkIv2fz7zw7p15LL3TVYhApapAGQl6fiRu3hPHV3G72pEaARx86io+/f5QYobm8rvP6RFG2eIIuN8n6VLDuVY2+iUHefq8TZ6atZ87NSWM5pQHw4fceSwCuUFRXobxGgxQac3iSODOhDchiVfYCtwpRMKskVybTBa9vzMmCJUo19xbSjUK3wnMm4hbwuDdRF06kAEz5dxCGePKFV/HoKycx9U8vS76jz+YKKw+x1q7VLJvUI2X+HvvJ8zj3ixdZ4dI8RA9sTCiN6Vinvxlr+umTZ8k5xWyMuIBCp4UpxkU2Q4AMdaWihInpClujIXPqAzYn0nSOUFGs0rZc3hC7TbYZ0Y21t2L9BsAulsjWIhfqrPBqvhGpYfI0p74i6OfCs6FNDSenNCvKlKQpvUYcJ+UwQGX1F6jERjRd8LXCPk27jE9pXht6HQVVuLjAJQxjCh+h1YazChOZNjS6zYTnxbXUe3gkR49d/Z4WykPoHnfO24UXrUc70s721GsGtmbhlKmhx/4+S2gLmEFFHPPVCBMPqVX9X3iiQ0tZtzz1/Ignblhm/eiJaTt3XlHqGT+ja5b2M/NEGP6Zxa9CGbJt7R3KHOJtmOuCIMBjP3oWc3P1zCJ3sgCtzu+1aAg7ckHyWGd0BLnOyes5nXyesxxho8T/yYe+icYlfZhfvULIGVl7xJnpGcy9bmWq1MfrwygSmTUDFKNYEIRi3NVCeXScw+zq95z/p+uDXGN4eDwn6/WGYmyW79LQbD8cOPrkCRz4/hPx883+4CquK41eSToM21NcclsQhJg+P4ddDx/G+V8wJ7yw/SvQnQq0Pbe8aNOspd1Q3rJipW3ccSm+3FPPHWj02UKZVmSiNHKzYs0lyd/se7khtBI3Od9o4M9+7zPY8/kDaa0TVjPEZbCoK556l07hdNzF99F1ZE6woE5BEblCxs9V/Z5ibs4r9R5dDq4YpoxBLjAAVk4yF2SaWtMgFzZf4HahPPNMW4Byhi06FjztrDy6gwhS1KvBGIBQJAldlgCobM78zHpRQZcpBclGGJ8pa/pdPVVD0OfOp6TfcSFPizTQPPN/85nvYu5nV9kV5Rm9wloMe46YtpNxIt6bVNlnmyTbIK3NyoT4ZhgoGqzfaZXWkD7OMmTwsC8tukGuD/tdRd+l/eZRJHyOaqGF1gZuhUWb32V/uTeB7z+aktFohFjRR8Pv7fcrIiRgv2NAbvrJfdYaD8U1ISSfEIoin89CWCSExEqZK/JHDb8X/ZVrmn7/zS8fxBOHjlvtNdhxY7Q9c28QKM9m45PwNkU4kyHB9jX6kXb28zj/inLqmaDKhPZ0bsq16xLI+CkE5hqTK6p5NK32yLpVlQHJwhPMsfBKTdHhymJfLz3SUTFigPEILgg28WRpfQVS/kQhI1fST3o5r8psjtiyvdv63stPyOC8SvfU8zXE+tJoYPzxKv70dz+NB773U4dCntKh7Yn2OOjeXYsP0+tDux6AK/c/DEPBhyWv19+noDMOi1/RS2tF2O9a47k86idpN9ZCRMivllqhGQsaMl1Q5Tt8PDJ4lzyaUs5lba/UDC5a/629JYza+tRHv4ftw1+N73XvkfyZ5jmuE5Dk2krnyssno5zu2Z8zJ7xIWU8q58zwFvITX5i8Qb4PggBf+MT3ceL4aTEnk/B7zsvi56xaFR3BxnPqixhg9ehbSqOMaHFFroh6AsbIQ95ZbeKcRQ8/5tdVI0aVIRwRj1oUCe0rAMzyQnmKIYY+M0lryzAk0/Tg5QSv1C8jyGIzKSN3ead5yB/PUwuTa+WmIIrxcKudFX7PBBQH4+FeUJcAGhBLdZ1bD5ml2x3OJjcp6nHM8iiY59lCEN8cAqxcYYf3BkGImdl53PXYE6j9s9XSM6oVylMUtrgDTlqs6IwecrQOY7Z6NIdpP207pS9NdRAh34pAJryhrFCemZuasC3ChBnTD4J0DrqUS+o5FuGsbDO0+k7pYMKPVrgu7S+ZUz0VQrv9Dvk7zzrSjletNfQmSg3tN+kjF2bEOKtzWqaQEPLTOZHwiVgQY0YvcWQjnROBlu8fWO+KjoNp+/sPP4OnfxaoX9QrjA1alIhpq9EI8OH3fgtf/eKB5FlAxDe4kpKpKHFPPex5pRrbWF941E0arijfP1UILAG+Ij31WqSGkxbL0EUu6DFH2tl9Tjz1SjoJoESwuOYQM8rZYeky2oq/Cz7/V1JjgxapEYflZ7Vp2qLjI45STO7R97kkhBeSD3Fja3qkXQpex0DwMo1nhHLf0NpI5oPC/03b01NRbZRz0zOizagPhB7VEMrooPsFM1jQUw0AJEYNkcaW/IHk2RpPt+nUZQbBp+Nn9mlGUdO3DONVQlqyD0cficHG3FupiHWfGh8ZH2brpZm8ws9jT74jbViG1Ax+QNcBVxBd/efzKAyjCuSmSrlp03VMHfXKO5V2Z/REug5XsfQpGU0SCGKlp16Ov+gcovd6/IVT+PRHv4fv7n2cyX6pUp/yMvs5F10cK/Ws+n1WqodLMdecP8Z5w/cPERHgeKeV+Pp50vZkrNTLdFmbNxloyjSXY2U0X2jfw9YMQCO50nkjHSOEzyZrMe6bsj14pd6j6yEXb/pbEg5lKWhSMROMRlj15PNk7l+EeSWnnm+8dXGeuP07P0uTLs7UemhXHOaCg/Q+upUx6/ma4CqswG7GEgSkcrT5rhGk7yAueGWFZ2rhS0KpVwTrBgvHpMy2RxGsTV+J0JR8z5VKJqSlz7Pp0KIquGIE5qk392leBaEY8vCsjEiT1NCTzl9R2VjZeGxF36wnxwbbxFNvhMXp83M4vyqiWjuzm88BOrejvzUBM7SOtOP958pE+l36Nw/pM/Tz8EVCVFoYiY8zS5vhfEQUriR0hPF3woPA5tUXRh8BAMytXaEICHJNmGeZOZgcOUU89VSZOMvO3XXNy5QZ2dXiuTHK6j9TeM1j5rUjzrjQyXhR2EOUWP53hqCohSfT8TLzlb//lYqnHllCGzeOKIYdQ1tvPIeTI4vIWuOGAW5QXtGnzH/afgUI6raxKCu83H0Otj22QRDifbd+BR98z90JbbxNOi8144X1vnkdA8bnNT4Tch4ayFQwqy1lPpjvqcCe7annIf96KoE1xjxtgilZxuDMFVLNOCeM3Hz/D3RexD3sYXytlb7EjK9p1E0KXneF0yNSaSryGqenno07N2BxBIG9Z/NGI4O9pFUYBkDHi68Pnn5EmQUf04jP8tNQXMfgailQ0gts8ytt/00MjqRPMizbhlZILg+/agRh8o7n5xt2OkIjwMqVdvV7Ph9XxEfe8XPq1fXNDIiu6AVOJ+ULYhw15wCVCRL+lhoojKeeOzI4bzJ8XD3SLszuSyNj7zaYm7GLD8r9QYmahS3jcbrmvFLv0e1wWeii76JJTq1w0UapK0Uub4Fm0dQ8fgDzSghBVd94Xb+r4XguRqOEYIH/DaagK/SpR1NxQYr9zY0JlUoFFJGFHe57FIWRewh1pVTPwwMij4GqtJINVau7kFR9JRszzaHmlnONOQvFAbBCrRPalTHgxgxt8xEWZGHokYoRn9u8/5Qu+ukMNaf3UMEn9mz+5cf24tQvrMT8Jb26d6vBlDYumDjmRFr9XjvSTq/6q4VFS0897Y8Ubq0xcB1px37n60/bbEUbTJi7OA5fhOoBk2vCjIMrfaJet4XnidPTtnAtQol1vprlCeGGT/Od+T4NV3Tfw3mRyQvtjVN6UJFpPIlybq1FqfTY+aZ6VfAVfX3JczWhkveb1hmgzzW/U8OsOdvZnDNsne/OFR1r70ojVUKlyjgA1P7FGszO120FQlF8aXQLQPmsS9gM8N29P8G+rz6Cubm6fYRbcpQmfQ/pveJ9V+w5aug042jaoJ8RjdJ4xMcnK5Q6oacRWMK/xnfsQnl0HBhfjungKWp8fCxKjHfRWnehGPMwDAWv4YbDxPja1FMf8ct0/si+aAY6rlxznqOdU8+9wmqhSb5eiMHc/M1uQRAGgmfw9cJrpVBaozbs8WkwfsAjWyyDNftH9H4aCR9P94doTE69VsPZqfMWfZzOJPyev2fH+lSP5GPvWlS/d6REqLKAYgCjRgu+Zo2sx6vf86r5aU49rH7YirBNi8vJBtjvlCq7KS/i64btX3zPDJGcCjM5MZ1cR9vgTrCeWBZJT3Mh7bF9N2+ak3WkHfPUR/Uf7Gvp3a7CoGFIamDMeqXeo8uRbEhqqL1khA22odN7eE6mWUxnZ+edIWqcyaqVpx0h2+mC1wUZHhIehkr4PbU4M+WFK5pRG+l3POw/UrTk+GXn0NsMssGEINO+bSxoCOEMsBmaq5CTraDr3h4AVhg4t6Bypci6hs0nwN4oRMivYvjhoeXJ8WXcuJRl2RXz2fwurdFcmdSKZCVKFRNGo5bpu2BzQgtHZdA89Y8+Eedyr+whY0bu4cpG2DyvvdEIVE99WkjG3uRCGCFNCi/CMKUosryvTi+ZmBOaoUfm1NM5IaIOTPhirNSHPZJ2d4pGmEYDKV4kOh4Tp6eld1gR6u31m74rVWhSjDiUP2XlIDbIXLaFk6iYZFL9vUcxfEGZV4yXCoNbT6xgsve/agVRnhVFV+aAh0w5iJ8LGyHCpGK0UeqtfSGDjwQBiYKqyPlpcH5u3g6/14wRfK/hf3MDFGnj8GMv6PybzE8rEstRKE9TKsQxb/SeMLtujIwycRvnNK+p3Reyr0IZP7ZmuLKTld5jUkd4/5OoLLMHhcQBwd6bZlSi1wlPd8wv7UKj9tpQFS1GOzeUi7Ws1LLRZI8gUNKAMoxiGi31eoMpNY7QefZc65O/f6bwqSHfyd9QFV7z3W9u+Hv85rV/L9qixieRRsn6rZ0KoUV0SKMrvaJC3jHdM5V5DRvWaTt1VpiSPDepfs/3VzNPeAE75Ug7sPnCU/9UT705WYivC24U4TVqzJ/JZ4h+o9SfOWfdQ3kFbdP4rjSHWZgYLkOrLR7hxqGG3xP9RDixlPkuUr4QJqdVeE+9R9dDhBESJmG+o+H3QUMJXxYKZMpETpys4e7nXsC5/+3iqE1mteP54VoOFt+YpfKlWyQJi0ja4/n/1KMgct+ZQmS3CZgtkXrqNcG1YY2fokgz4VzzHAqvhLahMMs9QDYBTVEIpKfGIFQKttF2xPXJ13IDoQoS36z0PF79SBlpdKFjkl5n9dduxuozF+yksahJOK9D2LI+2ZpQPfVUuYjTK9Tq4Sx8OUtxaATKnAjCdCclYdNpFWmeLy09YK4QbR4Bkv6IpB+mn5pBjbapPUOkZMTP5QKLucK0eXGi1FcUw498f0m7jrBObu2fnZlndOqGMu4hcBogYfMTeo+5RFXyFCOeJryuiOt1hOTc+kxFjwuKzChpPJicd67QlGeFn7rC+jWFAgDCIA1JTTz1JG2G82yLXzmMWoLXEOFbKq3shAyWsuOMECIPefTBo9Ya0QpJqWs5+aqSw9hgxo/ugjLMnefU81DqqAl7gBpsfHib9PmawYeOi/lOKPl0z9QMeswIzw2uph2hUHBez/mzg0+bIxDV9I2svYw7B0IuIzGjH4mgkdEf9v7OeXuWMc60R9/F/FxDMZ6ktKpGCvMblcGYfOCSFwSfDamnvaHukabYGf3emn+sUB6fs/wYYW64jr6TDpyQSY/CUy/4FRsrMidoBCDtG60N4Dqnns8TsPlr7bsJLfaeRWvy8Mi7ZEz4fGR6gev4xCS1Lgyx5nUOT70j1SXZz+oy8iyhi/VXROaZi814k/k8N2OnZ2l1J1TZJmkjpdPU0vCeeo+uB8/DsZWWWKmnih8VSB0edMogTKXR+TUrrfapV862uNtCCG1XeOodgoym5BraUyMGs4xqucNM0ODjk1r9U6aheS248DU/30DQk7ZrMUzYG6/ptxVWBEees2WJtRm6CQt+4IWXUL+4N7le8xACAHrSo9W4NTNltLbAEF0bfVhzhliMXe8ylwKXIYC6vL1pA+Y6SoNrXtGNmz2TNGn69dJrk5i/tM+6V8vBM/dYc4i0AyDxbK7oU3KS2Tunx/5xL5xW8ZZapsNYuadzixuYwtigoCl5fOw1Y2Aq4OjrU3pXYP0uhFjYCMNQCD/8/V9kiiL1EOMIE5w4uCfSor0ulSkxFnzM4Z7fqjFV9dSTexRezYspcp5haFvZRz2NUnHmaR3SSMWiOYxHhSl2K/tolXkmgEHyRjluvI+mjdQwkXrqdcOsMPw1HOH3sNEgHqKGwgOiZzmEYIcxIgjCJNx0cuKcUKZ5mzaf4RTGvJQaBsy9jDcHbI7w/Yl7e9Xim6IvDSsCSTN+W7IBnU+KMsKNL9yQwr39pl8uuYEK46L+j+DL/D3a9CcwhfJ6SaG85Bp9fzTtW31NSDQ8SFnrDvnKmhMKzz09OY251X32PXTsYc/leXYcIY8aVCN52L6iRQxYxjvL8C84eOo4IsUSXefU06gp7ql3GWmo7GHoE0aqILRprts80E4h0g1vTgNhYBuI+fozbcyzUHFuCOWKsJa2yKMfXVExtoEsMiJlnQoF2Pt9GCqGkRC4+OJIxp84PW3R7CpKaQjRIs+AaH9q5kAURl8qJ7M6BdJgLYtWW00mryD11PtCeR5dD2nZT39LPGtUeGiQIznYPdybHTS0om82k+BVRO1wrZQOKsC7GI9gRDyMJkwF3XQz0DcnHr6q5zApjLCZtTwI8P6R+1H7F2sQxGdFSyuxDaHUV2wmq+b7M4YeBCF++tzL+OnJMzj7Ty5L7guUjQmAXR2b0aIWORQKhKSFbmrCmETuFfnTSaE8YigIQgRQxppvQtomy6zQIj+PKBxCoFHe79vevRvT//hSBD2kr2xjpYXzrKHqSa8FEIcz2556mUpgDAxsjHiIHNh7UOYWzWUOmNHChFZbSh+LkjHP0MLv+bMabJy58YSns9hjzwUtO5dbC+cG7PB7Z5V9RWHgSj2lXRboIn3kConKA6QHoqmnXruH0gx77LgAE8Y8YwUJv1cNuYo3A2DKN+1wpRIfhUXXZoCeHlolXDfS8PZV/pV0IP4I05z6GR5+L/iZrF9ie+pJowSRMJkafbPoluNjz6m0QGeIntiQ1mgEtkKuKSTqWMRtK9Xfgzqf/1LoDyDnWWbYu6KAA3ZOvfTuS4OpOp8oXQ3umVei9zgf5wpSoOX52qHPAOX1tgzTYHKJiKiK+U2zIxHVND5KZzwhQvK7oTXti70utXxtUcsgCPCXn/oOzg1cisYKkrJl7ZE2rXNzddvgIPi4bEM4WhT5TY3MAHuF8W10z02joXRjqzbn+Dn1PNpMGA/ZuJnfsk40se4n78bpEIG97qnhwT6pKJU5k+r3bD/jBVCzws9dSr0VHRBIYy8dT8NHpAHeMfdCOh7RV2dOu3Lq2VqLr08KPXN5JshKC7DXCE25MRBH2vH9oRGCG+RomwZhCB9+77F0kCjOimXfMI55K3xcOU6EC5tEsJDHszFmFXLFSVcUqWLLhSCh5CeCMu9rKDbthPEoCpuuJKftiWJJwsMiGWKjEWLs0PPR9yuNYEA2PpL7S8fEsrBX9I1L89TTMUmKV9F2GW2mkJadc8vHxX4uQOZNMp/S32ihPLnJKgILEy60cFNn7rKD6dPr0o3LnvOaB1l6/khb8fUmKiHs67Hu1du0N1WacwwgCb+3cn81JZcJT/RZlDZn+kCFjAcZM66wacIjAKHE8+fwZ9N71LSUIBQCY77oDftdJnMzfscXxQpgSNIYRB4+4xPcu2LRzD31XCAU46XwVWpIyVB4Le8IWXd61BCs5wiPTExrmlNfEWOW0m+Phd1uKMdLrMXQmme8yj4g37GoreISsBBiFQu/d9Wr4EelBY0gqbgMR66/6WMzpZUrFc5CeYnsG6IS81YuXGrRS+qeSL4LQ35ySbbQa27nBqhcBp2M8XHtk3Tf0X7PUgR5WgBPWQthr6GUDnIBjFLA+K95T02OtOORXsaQ0teTGoW0/ZG/O+pIAICgElrvTn+3ulxjzQnx/kOcnIzPB++rqGuOp1/MzzWsNrgyq7WhFcpzR0zAUmK1tUzD6HlxNoM6P7qSyoJ1u9Cgq3AjVY4lv88Ov7fuJ4opvUIztJq27LHSjWh8T+LGQm7oUaO5GI0uGYAPAJ2zblmayQCso2GYXjOZKPX2XHGtRU22NvdzQ39a8FAfb0tOnuWF8rijTp/vTEQCkBrDffi9R9dDnq8rN3U7zE8plCcWb7oQxfEh3LPR4NVTyebNBBteeEN46PkmaLwliWBFhTG+GSihUU0UldRqmn5mCWu0nYgwozTB/o4LFAFrFzZc4crmXkODUXCS+4KQeVyJEabiEPqJR0R7V9RCzemLrPE2A9eewcPcTd+k55LQRSzGUd/ybbKAVDbTeSZrF7giGwAgIMKUK/SMF1ozHtPe2ItnPJtJmGcPeQ4VHgPes4qwyJv+0r4nTdDwe0sAT1uMvNuBLrxYCiUTcKgAwuYOYBt56G+ZUUNK+H0jCIUAY24ybVg59cLbYfMJ03k6R3hVaRGyrBiXsuYIAMuQqQk0Is8WtgdKvQfpOzRjI3MUyXFOFTJmQumi71YqP6KWA1NcrGgrUstAjUZw1VZRFApD6gpWKI8KjZzv8Pmf5IBa54zH+8RcaqSjHnk1vJwJqG5lOp1rFWpIa9hzym5TDy2nQ8HnZbpX2/OA71cip56Nj7ZXmfHpPZeGs7qUOm1v1vfRtC880oOvMS58J9X/OQ/iSmMYisgiLquYe4TBUfEW00gPk2PP+yLC77lBwhjTEqVUWess8k6L1BIRJJReV3QMm8vz8zz8PsTJyWmSnif3UPOaXLU7tL+Tvof2P8Iw7WudGHJ4+L2pgE+jLrhX32mEE4ZkRWEn78O0z+eb5gxS+2m+C9PvTX/qdSWnXvBo/s7N99l/k0cKZTqr9gIQ8Tuxtzhk6+gaMoLJ1pnyDlHJn8lVPELKZcCN+HmgtqEZ1KLv038bOmjUJF+bWdGtWvj9cvXU9zW/ZPFRq9UwMjKCiYkJAMDU1BQAYNOmTRgYGBDXj46O4tChQ7jiiitQq9XQ39+PoaGhhSR5cSAWVvqTmeR1LrQKT5e9QSUeNx6qCamIC0GDMI/5XqB+US/6ZhqWEKMV4wEgrXhsX9bC711eHi2slg8QD43iRaR4XyltQKpoqDlelBamNAkrPTNQ2LSlTNmEf1p9ZJv6yhW9OD87j7AnDfumfbI8htaGbTNCyxDEDShknFzWZOt9VGxFC9CUK95fm+lXCM00tJaOlVZJl1vwqYjD50w+Tz3vWzQHent7onHqqSTvwfyebLAZQp2lpNG+WYI/eV+m8ixpR/PUh1zgidt95sVTmFvdh5VT9WidK4psdJscrzCM3qVVk4EYt1zFeShMOLkw7DHlpqcS26B75DXceLBich7za1cKpYU+u16XJ08k3l/TD0Uh4+s1GXMWFmyNE/kueg/275byzRRnnuts1lCi1Pa4c93lnGf8hAqSsSeep37Ynnr33kJ5qItPUiLDMEyK8PHq93zsNYWzJyB0MaWsEvNZ+v45jzTrRQisnJ/Z1CM6TkynK80VJm1kzP1EqVX2AJkGQGggdKp08P0gZOMTf9app56PjzjZoklBsbj/3BBmG/xsvhvl28pQ8bCX7W9BaCl1NGSaR+AIowjj7Smfrlh/WwMEqShExkrSTk+F7aHKeAhDg723mvsshYTxdtUQpHjq+dr/ww/djfP/5DKs+emkSpsWfs8VI5N6Q/vHO1CJGraOpKN7Jm2zNnkea3/mMtuQlMic9pF23NjDFTUtgol/pxpihZKr83nRdmCngAg+KWQ9pgAzOU4o33aIR9If+skdN0Fo+2UpH+COPM7fTBs9igEtdfYwGYjJVbxWgzp2bF8RkTaJYYD1nTQyyzz1MhIpX12EMEyPtJtfpp76rlfqa7UaPv7xj2Pr1q3W97t27cINN9yAPXv2WIr9rl27MDExYV0/MjKC4eFhbNu2bcHoXgykwomyuShModEIEPTojEbzWgjhRvGWuRjqq//bKgCrsObIpCXE8Nwc7h0VHrgYYahZXFNGlOmpV6zyfGOWlV8VgZ16t+MQd4vKivQScOtzCIiNVD5H8ZgoFmrO5Fb1merYcmNJ2gvtcTY08bYT+pRK4lmhV3zsTX8zPRUhm1eKt9fQ5bJky4IufOPWDT1rLrsIk2dnorDHWbY5cqGxwYoRxePc19ODOTQST71JlXB5hLhRgz6LjgOfe2mVZTIeyTpXaHOEqP3Vp78DDFyKlUcmnV7WMIStAAqFwjY4ZEcNKeH3oazvkQoK9nwISaE8p+Enadees3Se1+uSL/T0ZPENqeQFinJhRytpglT2mkn5GrmGCydUwSJKPVfsNM8rXSNScJVRTcZoZBekU+YIpcHaB+x7EnUtTMdFht/b85fzTcozQisiKn5GaO5jIbNs3mZGRAmJMO0P3XvoGNd50Va2J7gMv9zLTp9vGYbCMDLQmURm0hfexqnJacz87EqsOjUnlUmytoKM8aHjkuW5TfvSPEqO6SGCNzcaIdBjJ6xT/mDuEeHjZP+nn+b3nkoUaRJWomf09chCefTNiJBetu8mx/GJtSzfpTjdB/Y4aoZAAJHBgRn5on/bf8/N1ZNIHNPm+TgPOex1ROqx+aXtDxWFl9F2Ej6L1JBeJ9XvI699et/UZOypJ8ohr41AlWFNBgscfCaEzY8B3ZtPjQJqv8U7SteflVPPHRNcqWdKLFfU6RokP0ffGf7lkG+S9jn/JutNHAGotcEMdYYOmR7L1prYq91rwIxB0IQujjAMUalERxAaBZw+R/TDGge5T5n7l7unvuvD7/ft24f9+/ejVqtZ3w8NDaFWq2HXrl3Jd9VqFbfffrswAAwNDWFsbAxjY2MLQvNioKnwqQgq1GMurNwNZeHxhco9qkJZY9wCkXJBGaLIP2IbmLC4kd9Tr6wiSHHhRNkcrA1csUzyzYHSZdo1eeumyJTLWmuex0OmeFizGhLNxkSEMMZ0000mCIiHuKdC2rCfJTydoEJFyP5OFSFtQ3SNkVQcpDfQVkZsOhJrsGLIoMdQUWNB4jUg81vSJQWp162OjmsMetMQeBl6RqzFdD+KlYu+XlPLgOfUk5x79mw+Rta7VDzE1vw04fdEKNdTQfQQNQMzP7Uw+zSs3dxL2qk37PfZCFMBRhMmNWEkoJ448yzJXwBYSixXwJJmkyZCu4ATizrJiiqRHmebLkMbF9ytNcboNPdwwdI2aqXPT56hCEnmndACdlzRo39znqqF3zcaUsFMrrGeQ++RnhfNsCF15HQcZlj4veaZ5+8iWUuOWhXpfYRHcKMHncfckN2Q79v0k64zHm5O29LWnMa7tRB+UasBtrFKGnDsNv7uM9/DzC9ejLm1K5yKirUXB0xx5nuz8OSyNaf0JcrZd/NdE/0hi5uF5ue4vzK6K1UG7f2fe+jN9z3JXh09o5cUWuR7rLlfRIvQ9cTD71XljPEpZZ7ysH4ash46omO4rDU/V2fzgdDZS2u9SD5DDeAiYsIRzcb5URjanvY09cEuRjpVO2+1Rd+jUBiZ4qZ66unsM8cjEroCUf0+3TvseaI9x+oiS1eVNT7o+6jPN6x1w/sMSMU5k1erThnNGRCK8RQyPTeyKYqveCfcU0+cbs10D0MXN7KJGgOKfLdipa2Ap8+VNZFUOsx3RD4w694r9YuENWvWYHJyEpOTk9b3/f394trdu3dj3bp1ajvr16/H7t27O0JjNyDL4wA4vEhBIJSitA17cWqKhwiZZ0qCCDUEEKzssRiB8AZwZV+JOjB/y2JdZKNg48G9PnwsUoU5HTttPLjQv5JWoGYMMmTXm3wuLsBrOXhWOLMQUkJFKZIekVX0HGvHxkHfb4rQ+giYUCaEfm4J5koPF+ICKQhbG3GoM31CeNK2JQBkvC8ZyaB7AdZcFin1YV+P0+NDlU8u5DUaIXordlVu6+gkTfFjtEeeJGpkkXOvQZT2xJNK1wSbDxFt2aGJxqOjpUJwY1UjSAVPeoRR9JuMxBGKDRPGojBo3cCX5QHjgrvwEDTcIZN1rcgZF7apUS4xIJBrAjnntCgbERrI3oO1+oQioCnfQUJH2FOBpiyIdcWFS87Tk1Bwe+4l1zgKiolQTGakE/yWyFnmOh5+32AKhlYor2EZefj7T9cBraotjJoKz2iweSiMEYEt9HL+GLVF1iFTtoQiItYcV17ImCdDKBVsPu9ePhWlKUapRHJ+RPTZ60MzfFLDr/ZeuSEp23gqa6xw5VlEvMXXcIODkCGYEYSnTSURInEqUh8ptJj2JX0mP7lF0Nkb89xkn9R4nU5TdugwnR96dAw36nBZy+JbVi2M9Bo+fjy6i+4x/Bn2PAotowuVEfj6qE2cs/amRj09PYKfWKPJNNEn3dMJFYYP0PHn+yAZG7q/2/siX/Dx9yExXDSkp56+w9mZeRGdwdsXMid9JFv73KEQfac4A0iUhHSc2fw/6lPKU9J6VVoha77W9Heknd7Ej0pN9x+bPsFnwzBJ/0ir36dzRcgDylyVbaa0+UJ5i4QNGzbg4MGDInd+fHwcQKSsGxw4cEDNsQeAgYEBHDhwoHOELjI05qsq6RbDk3lqyW+8qrgiWApvGRfmlPC8ID6ixRXO4w5XMx1N+0tDvOi1Wmi1Ft6obXDUQKCNqS1Yhmkxup6K2GRQscfAhIlyT73mPdUUGOpNUMPvA/vdrlqRGhzUQkDEo8q9/BQ8p14q5GyzsASjhrQEB9wzrws1zirU5DrrnStCjnPjbtibv3nmpRdF57MGfRXp8WG1G1SvUxAk0qMRMmhBMy3qQM8NtN8loCiGGV5WUYzOeKOUNW4Q9mTMx+T/5L3q+soQdHm4o7mHewF4G/QZ0uss5x4ABCHLqedzl42pCM8WY64YrQzPUgQaLUJKU3pVXkQNUvRVVWwPIW1fhKxr1zTh6a4UIxONFNGYfi32CmG0kPeYfhr6tEJ59HI13JIpglH/bdDweyGANriHXO5nUZtsPhIDoYj+EEKvTEmzx6EiIwZcSmoYOj312hpc0UcLdNp7CF1b1CPfLDpCjeJh+yT3zHPPvQzN5ceQkWvInsf3KMGXHZEWAZsbxrja26MZW9l6Z3uG8NRrDgq2v1Ma1D1SSVuklfm16BiqjJm+ZnvqZf/Mv7L2UE2GjBsSNNHwezMWPMWpNnnOqQzzI+1ckSF29Xu2/4qxlAYikboV6kZIzk3CgO0lfA8kD56dnXcq0+7we5vXWsYP5z7KZICQ1tVxGMdd/N30MwzFO+EGMqrsawaRLFlNRiLpfJYq4Cb8nh5hLJ00sl+qM9Ao9d5T313YsWMH1q9fjw0bNiTfVatVrF69Wr2+v78ftVpNhPEvF2jCp7VxOJQ6utBUw4ClsNvPFMqXY2FZ96zoiZUPxsC51Y4v+PgzzeFSQq1p1AFn0lrf6IYR2r/J/EGbDnONCa02Cru9hVQsAQc9xqOSfhUm/8efLwVWy8DChjZSWOwNOBVa0hxkl3JlPc9Qr/zGNzMqtLqUHpmSII/wsZRchyAkFRBWuZk8t84UDZ4awb2YfCOPjhJiBZn4e1C84ZYgUpGF8lyCcFZOvZqXTTdT9Ug7e84ntJFnCI+EiehgAmZEr30vPX84Cr+36c2ss1CXyqRdKM+eR1woN88w99F7SIvR96GdKmIpcSL8XoafqlELzDCKkNHN+kU/0/6wdi1FgF6nzw/uQVdDdAvmpBo6uWGWG+Bm5+o4fHYSjZU9CX10XOQ+wPej9H2acWlWKE9LjWgwHmL1n/Ak2l9pTJH7psuYmJwGwue6ohBYYaI8SowpVmK82JyxFMEwIiiswHp32visUM5hN6jEKTt1GsnAlToWHRFyPq2sB+3d85BhtkWCe6r5fg1E74TXA+IhwmKf5EoEeZGNRpCk7TvXD5svwmgfe8AFn6K8jr1Ll3LG+UwvrcyvROGEUM5jZ+s2ubZH33eEp54bvtm7ouNvvZ4waisNuSeeelYlfqp2XpEfomuN99Xie8raojVHLF4bFwTmc1go/twIw/hvlhPBLgbo3jvm5upSIefyTJiOkfa8MLD3Lnqv+beQG+rSyMyjYHmxPbEXK8/j3n9LTtbekUVXxd7fxX6h81nL6KsUyuP8TvAZiC3HGo/lWihvySn11WoV27dvx8DAAO68807rtyyFfc2aNQAgwviXC9TNlnkDAVsxaFCPuaYIkzYaimdQFaz5phCjxzCYlT2WoCXDFdmGzKrwJ/0NJKOhYT1ZFk2NaQuLOs8V0savIYvRacp28oy46Ae35GdVeKVjkYwJE5wSwZALIGbMeux3kT6LCCSUTqGE2xZprnByqy69myvPMGPAQmltLyxw6OmX8NIVqzC7dgUxSJAOx33MNOSAbT4ZoZR8TgSxUMWt8XR8+DE2yZF1Ifk7TI+CpIXybCHCFios7wzSuSDyHYnxgPeJC9cmBE7zwqf0V6x84YQ2GONT6im0xqUu6zlkeRhk2HccwcIEieRdMMEmaoN7IQid5B+yuFH6YO5FUkOH2Zhbz4C9fjVPCKczHZ+0Db5G0siX1NDJ17tQsJR5xRVIzWPEvUNSiZdRQd/6wThempvB9BWX2nQ65p7bE5MKejynvpnXmKdGpIZsvkex8HLehuIhd6b9mOsYP7SUfHHqhox8sPlhLJw3JJ9xKqVhzPNDPj72mkw89aTmQPJYYwhssCMfeZtWGpgrciVtV6sPYI+xPZ/C+Ll1Eplh7V3JOoZ11Bs1FiTr26V4cKNSxaQZxV9XKvY6IM/gMoDYd4kirIYeC0NDyqes/rK53kdq9dAIvaTdEOIezg8uMUeA0kJ55mYgrd1BZC9Rc0kzzjFaSJMJLan81rDW7bnpWdtTL5TjwN6zFTmOKoOWrFLR+KI0EPF0QR4VxJVu6txoWHsJm+cO3sL5Hy8up8lmACxDFo+GMvQLT73i3Xd5yA2dqVxl5kVojQEdZ3n6ETf06QYKLSWPytrxAFmwIgY4fxNrM1QNUJYzMJ47Zk4vV09911e/N6DH2q1duxZXXHGFet3atWubtrMc0XSzDeTCsQRpZlEX1kVFYRUbFVvglOn1NEIEfYg89Yqi5LIMir4k3SCKg1o1ldBR15m26h1rZoFkDJEWo9O8ELQiLXokI6abrPM5jEEFQlGW748KxXbOLe2z9DIkNJF/0N94HjIV4PlmaPojjARCWJRpC2M/fhYAMPuzqxAcO88IS+mnArvuMaNzwqZBT3FIaYj627DuAYiipiqnIQL6dyMgnnp90+NCBT+nXlTRNc+2h0N4yK3f43x/LnxRJPOEGf4AMh9DeW+9LqNEMgtDBQFJcE37U2FtS+GEzEPNoAh77gGI8yDj+3nuPxM41fBsa05lz2+zFnSvq62AZhodzVA7lGRUmGHEOss6vYx7+Hm0jj6HZLRCGKYvKwTQa4xIcUFI/r7CQK41TptpTHqViADKeHhvX+qD4F5Fd/h9YO0PQmnVDFjMiMZDwe3jGwPhQaafWiqYDD+X6yf6nu2FtL9giiAzWDSCkBSCkzUHKjCGQDvaKTv8mr/X6I/J8zOYuGoNLj5xXvWgybnea/V/Yuocjlxax8pfugiXvDwj5o8ZA1fqjOD1bNyS302ECDdwWtXv5dpNnhlIzyhVPFS5K+QKTPT39MwsaleuxsUnzlv80rRDi/gl68c0XqlER9rxd2PNhwYuXrUC52bnWfV7us9z/srWnMMomNDCxsGgTgqn1tm8FOe7s/lCf+cpBZribBmIYhmshxyvoPI4vq64A0cx3prvqYGYG6/k3mHPS9eeqHq3zTGvjJ+EXAZgRNIxEsqzMge0EH4TeUHbpDIPjXjjfJhHPJq+REaOJjI+M+TRSBlpHJRRJVa/FAdT1Pf0PSxXpX7JeOr7+/uxadMmbN26FZs2bUKtVsMNN9ywbJX0ouAK/AsnTuPR3vOoX9wbfycnuWWlD0KbgSuec2FhV4REznStGxBZjeliSgQKtsBTrztflml/Rd4PLU7EBSlNQaftgfXXkSvEBZaV1AvbUMKh6EaoVCCPlADyHM0iqxk8aBsmn98x9q7wOypwUu952gd7czD/tr2yKTNNFBr+DNjg3mAtvHiFKfJH83h5pAiZb0IhExZlTWClbbGNJfaUUKWeW8u5kBEqRpsgCNHXm6ZoqLSyduizANuIkLTLlRozHmQ9WznHFVsANW1QpDn1dFzM2NuwlXoWfk8EKdVTr4Xf0/mn8BXe/7mA8Q3FeABEPIIqLVyAtN+DFm5rr1X+jICPl+LdA4CPf+9RTP2y8WwrChkbC7tvWs0Fsu6gp9dEQnl6Dy9MJNJHIBVfzmtQAVaujH0BvebUhfjZCc9m46rQFj0vHYc6X6+q19jmO9zIZT0jTK9rONaEJphbNCg8M7quYd2j1/JI36EUou32BO9mfbHqcIRR30JAGHF5WO2K3nRv4usj8dTz9cGFeQevp+Nz7HQkg53/xYuEDCDfG4v8qACvnDkLAJj7mVVWuxQ0vDtpJ0yfQcfNGbJsrVN6JGglNRgwuSHLQIGKHXmg8jpRKC/6e/LcDMK+HjQu6lWjo5z5/sl+Ldc6510XW556MqZsOKgzRPbXHo+0DbYXM/5OvcPCkJqh1NP50mBOEt3gSEiqSJ6thd8bOSXlszKCR+mitb82SN0AQwvvR4PJ0KY9bmBLjMHkWcl+7lDQzXeapz41PjJ5RZUtyXMNfaHcnywnTJbeELjGTh5pZ3n7hcUX9jsS80gaMa256jDy07QVXyivy2AU+82bN1vfT0xMZN6nVc1fDuCM7CvffRyoRBut+U5cF9AQIUdl2xjCU0+9Q0SY45EACX3EM2cpSi4ru+N7Q0SIlOGlAqFrc9JD6Xk4m9UGM2JoxbqiEEdTjM4ubMLvAxDn1Ov5senYSNqkksM2sx4p5DYajfQarVCSOi72GFMmn/aZbcqsojRXaoTiyyzQ2j0AEmOJiW6gZFnhcA6FjXv+pDWeR5XYm5GZr/NzGXOV022ONTRzNPayJFWW4w8ZucA2NF79nilNgFQWwAQatQga+46vcZNTz40HgBEo0+/r7P1ZY0/D9ZS1xj0MRhjjUSrJmqRCXkK7PSZuaz+ru5AhUGoKuXMsDO2BVD41Y9FLZ6bQuKQv7T/oNfbY0neY0Cl4hv3uNeOn7E/cbiIohba1hnlUkjFg15gCnLTPlCbuadWMqIiNITK/lfBfLuwzZYn2OYncMDyCXEdTuUSUhaKkCo8aW0cNJuBq/JunTNF7uVIbcIHVYVwwt1WMAsD7wvhfH/X2hnZfTE69CHfmY56hRJj7klDx+IQNy9iihHDbU7mS8npzDVf8EdHfYPNSRPKw9ZkYVrjXjlXjdhbKawTWGHO5wlyfyg4yUsf0g/OpZIgqrA5L3B8afm+lDyTsTVHA6XgFQarU80g9tq9bZ8Zbe7kuN9F7E3qEYh79XWfRUNxTz2UmWmRPix7NSmMy84/LoNIg6jYQmedoCEPYewk3zAq5J52PNOxbjV5TZCDN0M3lWu1IO/EcYaRka1huHfI5jD9ROV3TG6QcbOsa/Br7HZh9ivRbicTk8nmWzGwZw+Lf5uKK+ssNS1apB6LK92NjY6hWq02vNbn0Jrd+uYELJ5ShR9/Fi4MuhJCGCMmNxbqPe3XIRuE6Bs7FHK1CKUqVfa0/wrNHnqV56oXAowmZlKkaRuKoMUAF1qSdILQEGr7ho2IzxySnnhnNebVg+jz6b5cXC/G7cBsyCG3WhheKDRCA2Ci4sNgQG6I9JiF7hgw3zTa6oAISAZF6tzmC0K6Yrs29hmP+aps/QOadUernFaWeKKw8/E8o7CEVUCsJTcI7kaG0JUpJhgJqrrOt3+THiva+2XtOjj6Sz+aCEV3D9bqtLNN3wRUS019VgHFs+pqnV+Yl2vPbOt/aOqfeFiB5m3yOnD57DvOXpco460p0rFqWosgNNtD5pGXkCO3+akfPcWOCxjed7dI1wWiT3limpFQquGhln7iHtu8yovJJRD31PMxUE7RFfrcmxCVKa3qdpbTSe+p2jQVXXZfkltDur0aX4DucLytCdECM6+aaLGNM4qkXCrjNl63we7bn9VTS1AladZwrKjyPmit9ANBXIeHOipDPU614/1kmjjVv6TFbrrDtRIZgyoxloNeUDMLrRd0WyHXH+28MMqKgo8JjBW1mLSqFAoMgsDz1NFKtEqZ0CgXcoiPERSbajXjqQyBtg0UYaEYuTQbi42TGxoAq5nJONUQ9Fpd8IY5pDPg+E4BOpiQajfMvzUDE91JlzxPOjSCwjt2zC/5JA7Bc9/r+ZtrT9mthmOKGHDGvlbQUEdXmlt8MXcJA0eB/SzmVti0dDnb0hqSD9IWseeuZ3IiSIUOqKV9h9J+hgxb7XU7oeqX+mmuuwfDwsPqbqXRvlPr169c7Ffxjx45hYGBg2XrqbU9ZiItXRUdzmTes5vIy65mq+FpKglyo4hpKkyLQouJQlBSFibYjNhHlWivvRyxwRQCk14R2W1ouJL0uaifdwLXQ64gmNmYNZRyZsMJpk7mw3FOvVH0l9Icg7wqcfm1cYtJC+3tAWt5FUUI21lqoNVfqxYYGpMfAEe+2KphZYX6UTrmhZXrpuPW8UkEIoJ4xV7lynuZq2jSGZI4AUS7Xsfp5BD2pwcL27tjzP3n/YhMjg2G8rGSuBOwCYYCJx8goQGn1/vQuOR/NOqHn1NvHHNL+qMe8NTRl0vZKUMFChNGS9oSXLsPDR8MGDW1CIGdj/IFvPojpKy5F0FtRQ/rUuawYZOy+yudaxiGz7gxvVvmKrRymhgByjZjj3IDa3OCmGWDAutQsnJLzFdpPXuzMMphxoY6tV+tdsQiNSmJAI0or75uIbmI0JMydjT0TcHmud0QfmSvCcGSPg+qRZHQmbVnzxF7L3BC4oleGcBuYNd8I7FDa7EgVbsCN7jMKqEp7k/dI89mtfom54jYEJ5F6iUE+VQpTGqzeW/tWSGoOgPef8y3OU7kCFNjvW0QNcB7CT0yJ6e5JPPXM4JBMc0XxcvAdmlNve/vNtTo/aDQCfPH7j6P2K5fJNpW1bFAX4ff2vsyNM3T9WJ56bmTl3nC+B8Zjue/xZ3D+51cl99jRSOYISVuxtY3OoTU+5l9BwGv42P2QIevkd8J7VPkzsNe2+U4owowH8vegFqRj+wivs5KIPITdZRkMqQwo3pFi+A7jvvAIKBcdaf+5EY+NN7nBJa8LZyCJcGmQiOHlhK5W6mu1GqrVqjOk3ijw5mz69evX4/jx485r6Zn2yw5sgl+8ylRlT72D0Rc2I6EbuibgJNbculQkhRWaLNzob7IJEFJVRYlZEUVYZPw3tdyLTd0SCNPnaWG2bChSQTpwCzgAhDU8EQyUc+pD0r/0GumV5Zsc7YtFU8KcmXDn8tQTt6UmWIuiaJqVFZK5WhZqRQnMGvvEy2iFaCo59X2plwmIN/C0xzGd2aGjSR8hmT5/V5rRAxVHqkigtymMNizM07ikvnH/OI41ZnFu4JKERm7o4cf+RP2154T2nqz5yTatIAgw/sKrmOtfYfV5JT3BIeTznj07/rCOtFOFf5v2ZnnaNPfdXGMuUXMBQ5su95FmLEWjYQsn9lyVa75u5oUVwprewxWQqHgTaZMpU7xvhi5rLob2mKnepgZb3/w9QSpL/KhIp3co4O+BrQlmqOCebWHYYmurQt4R5ffUEyc8vvVGZmi4DC9Px4B6dIVxSeGzqSKme3IyUziUyDNrLLiRM/bEciXj2InTOHvFJQj6WJGzMB6/itw3+Bq0wu9Z37Twe6GYMEHaFR2RHA0HZf40WGSXZqAK2XziKQoAgsDdX+6R5PySR7aJ3Gt6bJz1TLY/BjLcma/3oBHY0ZAKLQCEp54rUYmhhBY5NCEaAALSdtp32gYx8BJZTTMeUqcIl2/u+8lzCFb1RoqZxU/scXBFwHCDb53lomcpwzJyQEa9WP2Jx2rsqSpmf/6iZFyapnLwdhXjLRDvURnV7zONLIqMZxkSmHxtnid4a8Nej5osKQzebAybefuFpz7rhAIm/6meehjjjU2XiAIR8gwbTx4tkCFTZBmSeSTDckNXK/X9/f249tprcdttt6m/HzhwAIODg4lSv2HDBoyPj6vF8w4cOGCdab/cwCf4RSb8nmze0XXkHu6pqMt/26GacmMU1yhKIoce0mwzIB6yx0Vjak2k4YPJ9cJbAOtvgG1wiQeSCmP2hk7pNO3wjZMLbNKTK5mXrtRLpS6JJhCeeikYOHOMmCDMFV1AUYwoM60rgh5jznyD5O8uOjvczZDDSuppo/1JrjF0hbaibXthWZ0FxUijjY9NR0UtlJd4gurKpsr6S59r1uJsXCiSnvMtLO6WlV9RapkCGsa/U3rqzJgSBCH+YfRHOHf5JdYzVtK6EC5FJ/k/hb66OxRRFWCU/kpPXED4Sjrvaf8BwnscvCYMYQtiXIAUhhK9j/axkDZfkDn1ujBn7uR8giv5ppiTJdwG9gWC1iDA8y+dxuTPr0zqQbijUXSebr7j7yEznx9SSONRNc4ihhneRi2yhvOdgCiD3BiVGgOJ0qooT/xv3r8wlJ4sHrqrCexWNA/bR2zDb0WmY9QDfGj3D1C/bAXO/8JF0ggdhlEBUWZYC9nelIZwU8OAGZ5KMm6WIYWNuRWVwA2hDcIbCO2ZFfQVIxftR3RNYPU1+lDqsAil3uYFLuUw6SsxtrpCorP2VK34KFfOeMgzj25Ej4ygCoIAfUqhvIhU8h6zaCXrNuy10y/S8Pu0X9EnM1BQ4x0zIlnDGdrjRhV5TWkXxtvAvpcqjFlRHxrfbHBDJr8GDhkli18l8oZtILaNVdkFIpsZ6eUcrVhHy2kOl4DXRAHsiAC2DhK6LDplG1S21vpK+6ZFiJo2SFfEfgbAKaMnjrsMAyM38oqoU4dxAUj5sQ+/XyRs3boVw8PDQlHfvn07AGDnzp3JdwMDA9iyZQt27NhhXbtr1y5cd911y9pTzxmEUerNG9YU2SgclTJUW2iKPlMhy1r8tKK6Jcyll6jh96ionvpUmY4/MzYs0w9X7pDIkaIKIXSmmmxwlhJI+6IoVnQz6JGCNlCxBK3EE8aET0tYUXOnQkxOnce5n10ZK/DMeKAKBoT+is7kZO4mt+zG4xvaDJ1vZqINvlnxd6cJ7Iz51oWXWdmcmfWWe48NfVpfXcqX9YweV/h93KbqLdfeQyo8AsBFK1Ml2tkOG2NzXdouM5ZUKmKsrXxY9jftT1qUsGIpMdE1cq3Qe82/hRGKeQtk+L1sT8wr2P3WPLOpsY3TmfIkM5fCMLRC7jTPpDOHlNRLsAyjoTKvHG0AAHri+S8EIfc8EpEsFcZr42Jbf/z3X8XM6j7MrV3poMUW8oRQqBTt0guk6nPBiiwI5XMthIrwaB1nJdenKxoEgIiU6iHXOT3RwgMl57pau4JVv9cMA5Zyz+eHYkixcvuDIFG6rSir5P/sZ5l7+N60wvLUmzaiT+Nd//+z96+xti3ZeRg2quba+9z37SabTVHkbUkmRVJNAk6ECA7bThA4gdmUDTgwIlFBYECK1TASIDQCUXn8iBl1fgQIOz8SOHDEB+jIttwkTcuRDLNNWYKsx21RtEjx0d18k923yX4/zrmPc87ea87Kj6ox6hvfGHPuQ6ZJXm7uAs7Za641Z71m1ajx+MYY5/W3YKlPaKiIhHe90fpnC1t0JeH1FN1CmpDSFs5RVqQ0WIfap9TNRIXbitkj4J41KmiPLKO9XyT4a1+oT0alSq58WyBQnhOUHO2hd0Frw5TJ0A9EFk1DxuSf9owymEEHxzVjl8y2EZ7NeyxY6s/rbsaF6Mp2HFejgXJm1r/z7pPzlced7VP0qT9a10GBTAopEYkKZWyMU9olaLU1s9TDnKSW+qAYAXpk6yVa8wOdRp6feW3hufPnCrpEzjYydA6fDUfzfZOBCvYCyQ23rbzp89SroP5X/+pfFRGRV1991XLV/52/83eCj/x73vMe+cAHPiDf/d3fLe94xztMGfDe9773d73vv5uFmfnT4uHLmYa8p1KJghB+1qcYRth9yLMDa4eZw+j311masCiYz3pgu7f5d2rcOH1ZYqmHcU8/XxiPjTNnBPY0pZMxiAIuPqeT8NuB37etyf/rh/6BPHrbPdlK9i4yP7EdSz20GxQXKBi5Z31fw8HKdeI1af+lFGcd6vdEZciZCC4fHtrPzDqv/dT+ab+OhILs/TaK/8DWlsCg6rvBa2BM1FJ/7zIq3Nz2DFaReYBif7O1tmsVgwjYIirk92vzvV0SoW6Le0Xb0nI+r4GBmYib+Hyw1GsAybB+x+dM2Nr8nDhEARSGWmI2A44PwTBdpxSpwITgPBKtCXBrXselBKRNXP+DkTJalLj1AK1Vpt1II+SPz/b3pNe5gHkEz2wSGWd2TdpIAaxCPo8RGSwRcdDblIYHRjOhEeOWAm47e5bIzPpv/dd7EmViWOsH9DtVDod3HV3fLp5OgtzZ+pMIvz9vUsG3fXN+2TFQXp+fPje6I0LMAUplxVbpDOKaKgaCknPe34qn29aOnyIHRe7jSyz1Jsx4mrBtPjBaCHBX8r0dIb2bkKdAqox142M6xef7QFGwQkbfnSrx+4U4gTwg5PaUcRy3oLk/bs1mVtfej+KEqvB+iFfScUYhfgsIE1bMW/yBRFCOYySegPjcFCmYoZES5SeXbROP+qJ9H/YOuR3MeugFSKTVeh9b6llhFsYLSBmnvN3pZxqvqkWF0Z6yj/fzmoyt3wfvNTNcZePnd080MijPbuDXbWwwP621qUC9JeVNL9SLdBj+X/7Lf/mJ73/3u999q6H2WcGly5aS/t2OVh3AGplQ5KO9w+Fbim26jz54VdaLumu1GA/0+orINVvLWnMMLP61eqbKrf/emlQmeDsa3j2LVSYkToEtWlyzfs2DM7HUs1VLffloWlJlCmn/77/2qH+vPpYHloc+Fwyli0xLgMnu+JKxH7K3EGWuDvsHgta3LrDukvXKlnonCI2/W/NzhwL4GQ5fG5sTNMiClig9pJSdlHbN/sZgdDh+EpLVUq8pwSACNS8cVnr08e7PM95nc7AS2mH1a5E11eZTnzLuvq2V3BJYCacTuWfN42M0VbqQwO4t9SRI6thojbCy4Ppq5qZlK05YEzg/iWCkfcKZWddNPvXqa7JeVFmuE4TRsNQH661TDnXLIQbVcrRXiMYNIWVmPBn3rIRYCoqQqCzYVo4MHWHtDFtc127B+tCjV+X89BIUAdqXwOm16LqAcOUjpo7Xi86JtmHw8m0/7gbXkZ15TkkHyhBXR7Jm/FlEjDgpAiPCpsnFMuJcJFb20oaSic6N0w4d9oJh/1tB2a9IrJvRTKywTfYl+cNH2pAokoKyEfYh7OPgbqBCfJb9RqZwLyJJfBFGuiiax4/vaGxZkL/AN2gfiX/wxoA470YfC6AIpE1oskhYu0fKuL283ToukT6PJ0gv6AwLi1/3mbBkbYF1PvADiX82p8zFczYEhw1jhE5kKCJSMGqfPALF02M+S3wmldE3dkPMBN8dFGFXcDJa0ffB2mN0XqBNcS9FRcA+3cwUGJlLiVdQbLDnIqKKx6ZuEXyOZ0Ga3VgOxp6nUvbXOpY5sL6HWPlyohStv9/Lmx5+f1eerNyo9Ur8GrfVH5QOfp/ltUdN7bAO33/1ofz4pz8jr/7x54M1BhkY7A5a6vU+tH7qd+l4gDcJhzow+EeMVKZN1JziKMRkROKXPvE5SHEFfmvaDsOK2apFTGATz5wx6kCkv9tavNUFW2kJY+hggBhsBw/fgEaIa4THcJPGlNcew02bREErrFcKFMfzYYfsRtpyWr/NHXA35BPPDoGyF9RxrlW23CDj24SYq9FxjBatYztEb7DgKlEg60H92IJKDCgyZbAmEIa6ezjag75PIjuMGjGxLBxgsTWB6yqDEdKe0Pv6bzsKqUaW+mtvqQ+WoEShISL7wabIYraum/zQP/tFefWPPx/qEJHpKoN93JhqJAwsv8uExnEcFV7jIUZBUCZIUOpk0dqj5b7JP/3Ix+Uz67W89see61ZVXs+8Xseze/603PeQGmvHskVbrQutUCfXwUJbf4YVVLw3ae3TtT0n8T0xakzv3WjOLVAoB2js/6U+9SHmgF6WuI8zpUcGKfZ0KHctCYYCRnIFJZEfv6Nbxb9HLa3595IK9Ybyi+/xOlESc6wDEb+3WSBki672g6/93mblI9GpYanfmyOElE8eKKEXfA6zkn+DNUR1OKUXneVWanFjzdwjtJzPqz3L+yNY7mnsGB0/wL4TxZ7vB7kIiITgmNp3jgHT6D27MbXZnvYNBVvr25ESktZJds4yT7dt0XWF32lwW4R1YAipQ+VPC+MMCoeE9jokUlCuZudZjLOTGdqwH0e0Oh1Htp+5I82vXTYe3YZyJ9TfknJoDZB9C7A7KBMLOhYvFAyGgJmi8Mzoi4Pfn909yDyw343WwcRLvxfBlDabjYuJUtTq+QNbZAgAexrI0Z/3/5MPy+vveNbGGy0bvs4Uns3vJvEFZ2jRQumJ2Hp2BL9rgkodXid+Xtw9zX+vfQ2WemYeiDEIKYySZ4KlPliZo0aZYfwcqT5opHl+MismdGMvUJ4dTmx1Ugas4bW3CPWxHTOCbEVPffCSdRTiELh2imMQpM7xYP869NWvabsJHj+f/bwzBFnryFxdMmGyEQOTClsZk4rMRcLsdp96YO7BUn8OKe3ifjbXBAiUx4rRXZcHIWZFxIKWsbUgYzz3UU+DEdWLsc40f3wB+L1b82wpyZivRLGR0TC8Xs8ghEpuHXNWJRMsEsYNFDgR8sl0JRMG+z2Wsg0E1fB+OahbhghJlBqHSk71uQVlU3r2YL9XjiexyWkZcTdAqNuILvN57eeySVM0C6DqrFnLDuDjGBzFsknjp4gEesHC98p0mDri+IohPEa3kP2I5QFBRcK9zsdsUxKUWnN/dXw8Nj53032J9arCVBUQ2o5+z/ExuI6KdHu+/yZx72QWUxxvf3RY+2GLeih1TnNa9ecHsXThOYt0TsFImX8IqeFQIUDzz7RJhIwmFCivu0xFJVpMbUln3o5A2Br51LOSKdCyeR2RhxnvGM8OPzeEekF+0wny4u45QkakCjTxayv0Hcaezm+mcIVAguzG2J/B+Yh7sfvx+73mXBqS9d9ronM1qfe2lTuh/paUm60BYyPhd8Q4HqWpEvGHpDJRC+Sz2RKmOiNW12ypJ8ZLRALywJvVvQbSLA1oHeEDL2ESvEBWht/ePlPJxVkhdiPbwyEznsmEXG7nR/7+z8kX3/nisMI3i4bbx5nBzg6CyJS5PlprFh27BQi6F1r0zXJWhBggBsabuj64KQkCHGuguc0+HiD6Tb/z7wWJfMidHgKpRChbHzvcVPOUdo4J3vz7ZQYhU0hlPsmN6skE3KiZdtUEBMyZ9ysqitDyDAxmpgEX6c8iE8eKniAI0t5k4TIc+htBDWFuM2FrbbNfNiawMGAEXVwjVxQj4UiA20Col+phsHZPYtXgcWEx5QDtuyDoJYynqycIJZs8pbEaRp8DaoYVIesmTLC3rdG+yZhNXkeb3LucnnzcN30mMo9JxGjo21EqJmbMdQ7smza/e2LLX0IDMksWK7CYlvV7dP0nglIy54yYOllKTwn7VJokir8Iq7U1AzDx+F78+XkUKI/RaxNSDvVxPxhCncadwfXk25lwc46fkiF5yCq+5WdDt+iSErxt8pufvi//4PXPW8rPDLlzhKjSa6cY3vx93EepJaIGYM+1wudym7I99+3gfAjKlFmNO8+OAoWyFdxVh+sCBHVW+J7PK6XE5UB6lC6N+biw54kuuvM7BhAW6TQbz5osLgqPSdtCHiAomYJCLBprsI2bePZM0X2TMSS4XSRr+LNvPLTMO2iEsPO9+bWV8evO5YX7kJwZDlkDilvf79m+iMT5JISfQ1HSel/pHc40qnnq7ttU7oT6W1KCNWBPIHfarBYYFPzMddwEJc/bvRlajQJY6j8LG9ag1zI3fRZs70iAs/FRv/BgZDhUFsk/wKHomSwa6xGKQkTM7eFv/eOP9N/uVWkNgx5JsDK3HTiu73+v99fLldz/Ey/KVrP3N8bepu+eiM9LHXzqg4Y0CrVRobIFAU7oXaA1u4lfA/Y9we8ZKs9Bng7h94l2vu3C73OGXccS9iIKnhLXUqZ0claShEnlw7tl8HuGIpLlRSHvjArh/vfv+7UpeohWxDXh+xDmnjXoLebqNtROIpAEX3r9zIyYeHqDlnqRmF6TBceLZWYqyCw4rZGyIWHeXKmawszf4+oUsXdj9aJQgoG9RAypMzOeTEv9ls3ZjmXOAjseCAeN2lbL6sXpBM8kCmGnyOjvqTVSRoMwwArSlNbC1Oq+MqUOjBkZ8cOozhTXhcdvkP6V64hn6C6keeOVr2vfj9UQIlmQu/HfnkLExmqCYXS/mu4JwKBzikdS4GaCiIhXcl1T8MnUokkT4PgKsghraS3OewiUZ0rA+B7DeZIIsB/59U/JJmIpP/saFLgHXBpGPXG/0zksnnbNM3bUYXF2iC/TS85+AG2zFTso00lR1Pth1Vq/ZqrWnGcQERcYWSvSOgrt4y7IT97M/3ZDfncXLPNmpYrrY+Hr4aLCZ0IQluPcjRrcn23zeerZ7ca9w7NHqMSzOTlnmRYnPMvunm/cd7zHz/d/86lPyatfN9zDkF+zP15BxGcmKvFTJBOfZxQMc56jfs1nhrf5ewyM6oMPRjrLbZQxRHb5um3lTqi/JeUITtRkMnKOaLNQ5OAscZM5gjGYjci8JdetOawWa/4ckUj84YIlS8RZ6if8fh7mRwJcv1ch+PPAbA0YQGIqg6Zb4oHE2nIbv5Ydf8EMfj+f6fOMOYeD64Ba6lnb3PyaEBH5XB1zdVmD1WjPL5kP4SB8sVBDB2Q6B8xck+Ab/SxREFTGyB/OZ0YUBMUBHSLJ+2X0Bgt9Vtf4m+XwbnwdBKfkmcB4bOFzsID5R0IU6UyhZN0YlsAoLPG6jwy2iHePYGsMjpk15tZ3Wr/r6tNroqInHb/u2xv2aNt8Grso1M/rLPq95YuuiYAuImvL/THnNdEtVR4Sw51atm9QFjAj+vS9IVgD/P7+o8fy6h97VrZTCfPIii6RHuGa58CPgeHSSd+SNZOtV753BQtQyCmfBGOM8HugPRgIDi1/ASpOa06Y2dyEpQKGxGapq9Aie6TkM5ccYlBPVYNpAhOs7bYmTUpAETEyycaW0Bw9kNeg9CBa787hHfg9fHe9Jvmj2SLnaCwLj1lqWH828/h0f6Oggf3De7TNnhJvfrWumzz71OW8vqhRUFibyEHftR6m//PZ5IytkY/CdhsEytNJKYOfiog54kVAgvcot07jW1HlofYxCtEm/IeUdqPqsX6ZFhk8Owi/fFZsQchCJU0U+Ik32ZgGwO81WW+ia9KvpSMXKn3nrXml3XowjsAnBRqZ82c4mG6p5/3o+2lX48N1EsQ0o3Gu32Gv+TnAYMGzzklTc57Xf3c+x7nYC3qIClnXJlvqSV5xvGzCd4i0G5Xwt6HcCfW3pbR8g4iIg+odWpk4uixv1oR5uxFanBCN6wOf+tSvETXXcL6xpd4JXXQYP746y7aAq4ASRGMCvVAerDjMnNv48flIIALBC0Ku98tjItOGxnZxlnqG8JdBXFmwmn3jdyky/KcD05II9SQsB6usG28Sz4BaZitkZs1HJkz9+RqtAQ6CdmSpj350fPjNg9vavdFSn6A9nOIrMvVZ25mfrVsToLzSyOZR0ZVHJee+2OVJIdp+nWTWAV4PXHeW0q7R3vQMzMan7eGayOF6Lf0uQwBgX1VJU4clFN9vBl08mU99DuVkqHlmKXFF3R5umGNWEDL9CVDM1iz6vVrqt3WTn/jUZ2R9+iSPvuKeE+btOehfSd14EqUUMldpGsQcjRTmTkhxgcrdc3wX3O+obJjvHxElzkc3tOeVxyLMbEa680Qp7UDBHMfhpqFbfOnsVfh9sNTrvyTuxq4wnUD40/nJ3BMOLJr2ruC7x+T2FK2LGT2cX0xEDBz0ozAtNuv31pygZlZiJyzGc9gjqAhhdpGs66AE29nvWK/2Uf9SfJCZ3WBnrWMsD2in8ftnegF1NMimwgoVRrIwXbrUyOAcKE/3WRHvXC9e+O5nA54V0aeeg67uWbiZPosQLRLqo8ZnoPWWWupdnZlA2J/D+E3B2OHmziNWYrybBOWa9XOHPlq/N9rPWTuHymFc47pe/Lpnfh2RGH1tZntLwjPchwfrWTbN1IJnIvB3c6wt9P2azu405g72rY1viD+9beVOqL8lJYNRa2lAkD00OhIm/MwCacZYhuibLFico6aUfX+xrZxZJyFAN6cTrrw/PBOy973/v5EH3/CCCfZ26OltqrVGq87R5q8Zo8kMsE9NZoHIDhiDVAhYPfye/YfU7+4otVxQOBhkX8I99pUysesml8MKmGqLN54DX6dXKOwFCvN9c2st8UMWEWlbFC5x/CEdDPZrZ374/Z3JB9utsx1hzL6znOTA5JE1wfzYmdFNNNv/3o/9E7n/jS+O76KwFS31vH9nnfUE+wBRPRu/PxRq5n6JfpEkkB/tZ1IEabtBmAxWrsgs7wpMbd7nhPphqb8cPuCcspAFummpLykyg/fzzT710RKZKWExpV2styQKV4x+P8dzUktamTEUHLqF6RMLoVt8V2gh17OFYf7R99WPsYhXzIr4bASZj+QalA3Ur+w7eP+5T308N8NaTfY4Fq2/QER6s1QiekD7mGAWrsnqtJRJ76dwBkwvubFlY0E6xLTdAuVtPlAe7yfvJrWDboLvrs6rcHaAo1RrTTxdminewhQlCrj5W3clREHDK6xC4FVWigX0UBQIM/fCmxA0Jlxsvm9oqWcBEBUfrcz88E6pA3WJjLVwICROpc74QutAnmeLgua94VbTlhLoc58mkuglxrPxRoH10Hh0Pq/mgqj347289zz98mvR3BITWDfzXDdldciec+lRWWFIyr7MNc7RN+aTDUVBPAzvcVJ+RWNFPJvd70jfYW04hUTCr3s0hYTfb+KjvvDgDfmQPJTX/thzab+y74Jy4drTTHYjfBIUwp2l/q68eQsxQI4BrglRlyj8Zto0LE4wTPwvs+ds05f5XCrUq9IhFQIyP8RocZrB9jwjuq6b/NQv/Ub/7TStWK0NKNvomIvQGXx02IJOTH4iwPE4el8opR1bZVdup49zBsrTlHb+AOB36aBZpQSFjPr7eyWPZ0CwTxcXU6gPByLNUxC0kkN1D26oA8KDHwUSN4bmD6wzpSvbZXKt3+J+D/WXmArJBXBLhLyg9edDL4n2nCnH4j7a5LOvPvTtUJfZGsACG85HGfmI3dwbhNm/myzzBDLuZ/a9hb4xY6LP8vveMgaGmFcUJqeAuof4GL+zUD/WiAr13voX4cUmXNUyguLRPGwSmDksgW7UaN3PgocFZRmumaHE40Bfqvhr5lPffP+VEdtTQmR0JFEeRbhlRgPcLX1uva1x1D/bvwImOYOz8v4NAUeB1mSW6IwGZAze2mZP/Vh1TZHFaPT74nKZCmY7i5I89nE7uYwwbmzgy2yClEhnlCn685MoLKalXt0TYNyJVY8VaTchu67PvBZiarUj5EdbYgYOkT5l1zRH8V1OQQP/6vy4NsP+ydb58Viy+EBBSdr8vGVxOThAoesbIADd2qa2M0ul9QMQZKwYQks9x7ZZt2aWesz+MYdfpJRivso4B8hvsPB7JFAzEtDDtpu88qkvyP2vf17WexrojWgRnuM7rhzxrNlxK9Ev7CzzaewcvUr2ORsusHBe+jR1KCm6o4DuYzyIRERKNr9YGDXWx0l7epyRp8EzYD/2UGZM4li2eOPRVb/3HvAh9AzzoSEQMCn5uAJH75HX25F5bku5E+pvSQlCkhBxU0JFzBdDoexzZqnHw1eSQ07o8JQpJEBYFSMSquX1lnpv6bDxJBYyLGeAUoZDEvsEQaRwp0+L6WTGMk233V/jYZAJeRHdkAiCySHGeekVfm+WXldFCQFpMuHalSQ/7oqHGR7u6yancbjn/tM4lmMLiKbwYV/NKNQS/B4OCg3it20+32zwqV/311A4yJ/AUq9zYUI9WyTBqtKvowAnQkxshXeXWNbsPmSuk/5LGXtgKVMg4f0K82FpzxxKIk+NmJnNIqrHM18bMQW/fPW6RdxlhUoj5lJofJlCUlfDTRBGaf7wN0v9QJ44n3q2ngCN0EBRKYR8h040SZRFQ8F2DMnWIIbAfCTKUixo2VZLPSolNKq4yL4SoqhrzwHt1bVn10O4WJlJDoo8YLpa/8dC4vXjYyaZaXpULkSlS2uTBmcWORamfvXjn5UvfuML8vht92As0G+J71QZQ1V8bkDfgpIsUXLq3sV+2JpPgtzph/PRHqRzhjObzPnBSNbRdYr9guP+8HvweovpLY/qwL7Ne6LLg4jI1RUqbTOLpKcXOB9RORtdRjIBMRgObuR36LxrrCSL/M25Zelo4f3retPjYfwf6GVQlEO/ULhpsw6/7qKy/fIUA4XquERECmQ/svHQurmiNKLBbQA6Gq38Xhj8G//g56Sdqjx8+1P9eairCSkelpIq0TYSllkgND7IFGDjvub5jSOUV5aqz/chQw7O6yaDL9p4j+frBFGVWCKykvdaZs2mQHnj/Ly4XGxsGFQ0D0Kd00h9Rt3a0rHod3St+1/lBsfvZXxWJjdIO1TC34ZyJ9TfkuIsrixIYfoqeGbbWKD0ObkP04eoZSQIY0RUEp8V/Q6JxNT85YxnIDxUJ1pmjwTaBj48rfmKjqJphnEk8LzOpOI9nohmkW65fzqnJ8xL35pUtdQnFgS1uiNMn9EN/J6yoH2ZhaP3r/v0n05L0LSnlnk6IDNizVGVhebNCTF1h0A3P3fsc+nntYWDO1sjrol6jCrJmLw1wDwTiyK+u8Uz8dqBsI8Cwxn3xEc/80V58A0vyOMvv7S2sV03f+yGIqgs8OPlY7H3x9ONyCTN65/40MfkN9crefVrn7Pfef8GRssp2LwFrn/ufx/WNoVYVHYBr4PMl36+GEqqK2LMAtpFL83qw2vwJvg9W+qT6Pdcb2oxz5gx+B36sQH8HgNsKm11sH7Xv5IoRCNNc24cqnAj8siCb6jHxh6Zx/49CcOgOKhLjUot8e/fWeoBEs8oBR9MbZMP/eonRUTkkQn1GeqALfXDknWh59mMMZHHG4jzwFBSm2NwRbKsJMrAH8CYg88uSckzTz0Gh03QEXidCI4inmaeRwR9Zbyjm1McPLuo4btHkdFZ6hmVRPBeHdv8LmP44QumyyXeE5TpSZ56ttR32h5pAk7DSvW6MzRxvygiEeFHLmzRZ3vUYV/1D4cxRc6bGRfU/QjPijEFAYK/Ekru2ilj1tBvVgLtWuq3TZ4aCCtFIzFPiudkXWoKv28tSWmXIBb5kArpUQmBcIRyyRGs+Dsxo5JY6jnOCBrvlCYQ/8HIB8cLyzi/khPepbRTJJIqLUGBmLnSBd4kQeceumeRMj/0Y8gNWOcTp1FtEs6A21buhPpbUsJhuyNsxwNnXoegJJLXYW22zMK6o7kedL/J1Jo7IsH+cDdoJHkDXx/416zENGibrUHqNvZR3LHk2tirRIZlx3rknttoVksyZ+smF6cZoGZbOVBerGPbmry2naU8rdYiLyjvMlPUfxGYWxAw61JlWWoIZJP6WdLcBz/kLYGqhXUEDJa14/vfYa77SinWUB9ZdY3pIfRGyNSAlvpMu77GcURLPSosYgC2Jolw6NZwZApERD72ufsiIvL4rffcmLAvVpYJX3QM5NZEGiiHkNEjxtM+h+CJXiBVa8/cey3QJ4bpo+V5WgShjbbJL370M/Ibb63yuqWgSqyg4pkv/XxxL8LvM8ucMbFL7ibRl/sOreE0UCIGY2XmmXudzQf/jt9kDPe2bbIo4cWAW3vKggyWHBQZ3re21Lqzf6MgkzKP8NzV42MmWft9cVqChSGHfwABAABJREFU+0HIkJH5jJNQyv3etibPP933jqDQkCkPoARmk9Jy3aTk7M/sWP0wLgsJuugnzpBnFsjV4t/89MiK83OOc77SWtH5VYGpdwsEAFAu12WsjR1lnY6PUShRkShBMGAhwbtuDF4C2nEw2xL3eu+b79e6bvLz9+/L+ZkJEb4RicfniiQCDAlwa9uPfq91irhHAt+QusBs82UzhF8knm/B/QjPhsUL0a31NaRuHKh9YUHdK2OOA8xxHnveF/cGz4jBQLE4NNqphv0nohbwtnvNdU6e0/fHw+8zd5Cct967nwVhVj5EhMGkZ4rPS+luotzRNrDdmcaY0BNkqUe0RcaHMApWJPJRAXmWutjmdZjrXDDC+ee9EgTW/ebX220rd0L9LSmsUfZ5jFFg8/d5S0W0WrWC95NVh5j3LnyxhTFaoZhIdObBa9ddv5ghbBIO12v2x6Rx6jAawO/7PZN5Yh/FoKXHkghjmXCW+lwnjACWdcU8xb0O678kFsPB+P30+rp87o8MAWcnqJH1TQVDaldkEFM6cGotspy6UL+x8scxgokVktcirbvoTsCKGGXYfeF1HqPfHylp9uD30EApwSLk8ugGBpXmuUSfPn2f8xrh99L/ZYoex6BH4aAVkVMZ5Bwi5HPfzK0Dc5knir5Ffe7XKMjqfTYnoLkP7YpMRgzuD1YyepfOUp8gSFoT+eTnHoiIyPn5i1HvXHtoO0LmS+nEvRFULsLvWegbF+rCZDyCMrcM6UZkThJno9xMN0QkBJvj/bAS8mRrwHCrpf68KS9uCIHeZ79fsV4MOGZ9w47R+i1kwRNRxEfv77Lkvq96I46RfVT3mOTlNCxwiQJ1MqhTCOHo27ONGAvimacvfJ0gYKLbDxaDp14kiiJ+15nAKl6Jt21bFBaN/s33zu5G0S8bKgiCLMyPWeqzOfd0Wts4neo8s6GddVim61JlSYIoZgI7n38O/QI3s8UXC57/+jzzEDgZe0ohLA8fX8svvPpAXvujz42+UzwcEXcW2vjwnpal/Dr25w9rf7M3P7qKLoSzXa+QIaUfW5/H3/WQ54GxgJJ3DKz3pRZPbEVdIWdF1w5+vwY+88innjPvWOA+O+M8bfVotJoq0ThVHNL1AvGHggtRo/gsNyghGYHg6iIr8l5AzkMlJO4lfZ9Bke9pnEetltAPkf5qnaX+WpWWECwZFHoRBRPrDDEF+DoxRDJ9n8rTRKhPlHQhToGyWKRQv23lTqi/JSXzJ7HfJGeqNjpwGM73D37qV+T+n3hRrp+bvoJW1KpD9d60eUUinIeJhPZtjgWJhN7n6wwMIY3LAr4AVLfNXS5NGKnQUiu29cIC5c3vzkzMSqYZzXJDR8bAfI446nZmpQX3CquDFCHhUN8RLkQ8k6Z11aXKcqohRQ0zaWyRy6yQvG5uhrFTGjD905pjqpDIt9YCAx+EJMfAWKWzDrBkqHDiLPWJ5TagWfhdlZIcglnAvf39PN+du2VGOs+gidLX4sVprqv+Xa68msKYn6fJDM4vI/z+hjQ6idW2u4/Q/qPn3ZppiV9ehioo3gKsayQPlJf4XKvwPgLlbckaxJGw8M1Q+xmLwz/Dih9OL5bFKnGvpSWM1LrJUiA12qjvVdnADckLO8GdYI00Hq/rEgU3RD0tY70hPHgqKL0ihxWzGZy1SXed4Db1jDM/WKDzu2gegkb3COJuqKmvZiPhj31ObwroFggiW0zJH1dEPPpl1He1k6e+lJiOTcSvGXsHm09pFugyIqZg3S47lnoVRGop5iZxpFwV2bHaRXbFzStb6tkSGGhQEhDS7TnJ+Jtk/ugenbs9tzfmsdK+NX+OdkUr9sMj6IpIOEcY/cTrzhR+bEGl/cB8k10hykocG8Ey/YDfz/lG3kwkutlgPznALftiz8B9xfpshfitouk2qX+I3tF6tQ/LUnMF/7jP+dRfn9M6RCSgNlM3jRuUXW2LCILdtJV6LiftcKo9q7/Gc0V5YYe+IZe1qOyLPD+zDNFSn2WjgAdEAk80lacRfp8FGjQeH+rkmxhBcRvKnVB/S0rqX6glORhE/IEuQgT0vMnf+8lfERGRx29JfHQl0Y7VSVTMp06JHVD+zFKPPjpa92wnblj+wgVZSixul0PDq/m5HSPdZDCix9GEXfNPktJOcqY5MMCZUF+npd5p+9F/WAsEQpztJgqGbZuvQa3fieAQBK5hqVefeq/ljlaGX/nCfXn81ktDAzBTw5pyPtAa+cbF8Uxmcm/9ikRI5pFmfLqnQCkFGHaI/g9rNRxoN70HiYxIFybpngNLfYAajy8NPpcyPH3tXSwzmrG2Y/MACqOT7ZOcwUbmIARK25lbvD9YB7aYZojH7pjwLQ+2kxVvqR/v815MaRf9UOccF8mFja2RAgKzNmSZDUbaOGkY/yK3Jrn5IItUcGFILI0OBjmUCb/8ymfko89u8vpLz457Ii3yUGBCH5GwUzQX9Ib3TEXlCbMsJDbqXUt9YqX6e7/yitx/54tSLpZA47UNLtvmI1Y7K3pw0Wk7MFlfJ9OmozSJqGzZiwXQhM6ehGZuLc4ep/jTZ04XS1AKsSCrSo91g5gDvG852BfM+XJaJk9B0NZ1a1KXYu5a0aUFBlGIsQ60LQoXfey5YmXOxw2W0rDnivezTt3icgFRRAzZxEobtnpm96xtkx/5mV+UB1/3vNW5C5lu/d01GlPIhoF1JIFX7TmKLh8MAaSJY/fIkiSqX1e/5/C9iYhcPb527XMKRH+mwztpTS6X6ZaI/RDxCCEREVl8fAYcV+Av9ZETKKvobTO/we5CIVCeQxzclFIxQXS1LFDePu8lQmd+0o8zuZj0+YvjzJAWLq0x0R4/tohgDDEwMjoLZ632Awtb6tnlVt9zVYNEQrszxfdtK3dC/S0ph0HtBHKd0j0cKMg+r5t82fMdyt0uVEjwzB0LqJ6Zm5Y+3ki6oU1QAkKOQYGwn7jBixxb6jN/eNXwqlDvhOAh1DsiQUxUQDpklu6WMJrMeBPxbtwX6fPhLPV4CEHGAKx35cONBWXxzEEjJg/H2IUO6M+6Sa3gU+8ELn+YPbq6ln/08U/Kw696Wq6//F7UQA/47mGaI0ksKwnxPYLWipDlDwUcbZPqEhnrSq2z4CpyQi01MiFsuUnfQ2Su3ThWsgAXGr/4Z5pZ4uCGIpCeMT6jc2hZFIApCjRha85Sz4dtnwdm/ncYStlTUFDfGlvWIgPv9prsWOolFlT4GYNykVtV3brH/cHCxvizteaIUeo2kllMmxcEUujl4Rweozua+P3dRqC/z37xdREROT87aC8rarfJSF5cLCljhIxlyRQXoNxdTgC/JzmtT11kHrMxr+dNPvypz/Xn7tXoFsJWOoOXCwkJ+4ERmWnX78I7H8+oUsai34/zbA81ZkKucCnk25xHWTcXHf2OEVPjGUUyHCr64TtnqV+nsJYx71rn6VRhX876NGJ3rXUoMaJVFAfRxL+fNurINrJPWbpP60XEIxskzx5xCL8vmaI8us6l/I7Qmsr2mOMbRD79+kNpl8qbkCJNzyNlARL4fbDirs27RYRAeb0EqznT8fG5BEv9XCecqn4Pfq/74/GjiGRRQYx96lkYNIW+Io2YD0KhtSr83teQprRThdgwXIjAXOn8b23Xp57PwK7892ek6wPxxawo1PbcORsUrtEfPlOgY3Foxp2Uf9q2Fo6BtVKwQ62zgksf71/erzdlc8m+Y16MgzzqnkJUJaJbikRFTVxfv//LnVB/S8qhBgq0zp6B52AenrF46/NP9/syQViUyMAXdW5EY1hJU9818wmchwPl8YGFQo9EIfDq8Tm/X9RS39uqGvUbGJQy/metNU5qgN+bpV7cM2w9vQl6t2upR596YAJcpG+rg3KfnzSVS7ynuGvfXz7M8KAwy8ua5amXUIdIV6CwBlukhKiuaRaFhBFi5rqJ7FrhRJhhSSDhyft1jDNEv1chsDOLuSJM2/HjOIZ5KtTar8XcsmRlR1gMAadgP5uvoM4d+F2jNUbh9hV8oRly3r/3h3pEb0A/kGlPLMpzTeTzmkW/b5vMYJLWJ9iz0D4K7hwo7xrS5GSQb/RBRgFNFSitecXd2Y01iTsC+9kLAm46hH0VkekrJSpxeX6kEu0dATfDnPG6gv3arbGJ+wi0U+uIs4FCSJ3K3YzBGk1Nq++4h2G6fB7Zs8NKzHQl2xON3+lBxHgRTzOa6DmA38Qz7kyw0CAoyRSEsz7imSgiASWmNCPsd/I31vWi1sbMgqb7A5F0K+wvfY8Xl0tiGZy0fg9+38Z7KXWeF6xgv8la5t7J3H7H8HsW6jePHroJft/Ht38G8Tms9Uw3E1TQYT+6IPjoyy6dIOqEehY0sA4XYX/SaVZ0Z7FsnBJb6ZU0N6cxUKjQNbQp8K706x34Pc4dBzhzlvqxB/eg3UEY1OvMuCFk3V2SdyZRgYx7EuH3LJi2kmdS4TryccTYPKwMzpS/cf/5M4GzWjDfxKkc3VmsaVqZrxpnGsPcs2xVNhYBl72EDz7KMT/H5oaSwO89IordZfX2EyiSw3lwA+25DeVOqL8l5Ul9cr1lWXYtndvW5JmnO+y+nXZ8dGnTaNAvER8gqW1NUJ2bQZqnMO8ZJ6tjfC4igucS15mNf1unL5bUBJrTWogEGxj8zFJPVtjAsJBV1pgz6vsh/H4EuIpCLlxTlG2N1B0tbDPa/27KHhEXZVzLUrtP/U3wXGSeSq1hjnQOgqbczVuJ40007iIxCA+Wq+CS4evjcVjzarWH4Im7lnr37koQklKf+mCp37wlU6aSBplvrDeF3h0pGMzSPK+1//MsLZbep5QitZbgZ2xWogALpH2wI0htJw0MOOuca2JvXr0mXqSvUU6l5NfIvPfx4wi/n4HyxvvV4Guk6PGxLBK/xxZh4lYOLPXS2qGlnjNEBIsU0RFWlihqytP7HN2AFTsYtyrlhPsP10mqv1YTRi+he3qte4thuiyA23OnEiyR1oaXQWTd9l108NxRNwGOkh6CtMqcswvqt8FCH5OlXgXh07JvhaazN4e06gT4fthYVCAfSo8MyeDO0VEHWurRYtmRUEQjG/4+zmxoRiOJL7XMQHnk+x2gueme4Rkqh4Hyrq5YSCClWIjRcryuG6Gl2lKCMC4SkYlsxGhN5G/9gw/Joz/0tLz+hzVLByP8kneNynY9j0Tl+WJtzfHFTA74XkIE/fF3z9qpdTZaMMhHFpHB10X4Pc49Z4dgN5ttawbt5jz2EbZN75nPVlxLO8H9usI05z8Qfp+VLJOKjZmVE7t8QuR5NnZJUyUSIeJ+/nNflMdvHe6wSJubttPGVPSxs7LLCdMjToxrt3XFT9vm+TR96nP4/URljbEnfHBQLiRGGyaMiHBy/aCUdtWC2Pr7s6CkhmZKFAO3pdwJ9belZIwjXq9+8+s9W2IRExEfTXdPsNjYQgMbHOC7fGixZQOFAjs0di1mOlx/jQKcSGTezEIF+bldIb8fJrpBI1xVUzq/y4PiJAwLW3PHO1Dr6Hqe+aWVabZ6zcLKgiK0cxGFaR2Ts9RTQEEXIIaooVrqOc9s0FATNDe8O7WS8PvlvnIwOegUshBZmqNqhwAeuqR84EMVlV7AyJwPFFAiiRDACprEv4xhniHtHdSDWmctM6q6uGcOIW3qy40mFskVO21rUsq0WmDfNLPikR9kiKKNwmbmV1wioxV97sjVp0Ul47qxhaAXpA1R2z8CIZ4iZNkrWmjd2h+iE2jprbHfaCW0dxt89Yc/pZtTFr432qNJsExiajakg1ZvpKsPr8+yXtRuqWdlGq3fOvZ49Pln601ioR6XGWxdJNJwy+p5yjKAqOJAmdrRxOaDWzEayxQYF1GobyevHJ2Q/inYikB06MylA6zjXXG0pUrTkLnDKU5uVuJ1RnuzsQSFu3haPYX6SWswRsjFxRL8cdHqqfEBRMhSP87AUovUU3STeBJLfbT09eIUuDdZ6tt+SsgmyXwGuuyf2U41RKnHvs/YEbSfpMmD1x/33+7lLolu9IlrFQvkFg9hnYpf9h3fy8zCc89uH0LvylUgk+7rXXUXfr9vqUclq1p9b4J24/1YIk/ajE7sWfMzZdWMFQGB8ozfAINU4sqlbbTWvPL/yJo9+OIK8W94v7YtruGf/vzn5eFXPT37TefRCjRAZO4TFfLdPiBhGA412bZtKluvvVImQ2uK4HkW+bkbLfWJEcos76Y89QG27ew2nqLfv8BexKHhOkXZ47aVO6H+lpTMiq4FrThOKdcoJdiBv2FsowSig1Ax1Fzv+cagTz1DbNmS69E8JRAAZgiZ4bkHed/1OxPgmo6fFRyNrmdRgsiQq5uCN+0x+SITToz1zGBzm41dhJh88ieVU41Eki15dVgZHSOgc8+MSYfZngaTfwy1nhfqbxuJdZa+zN8TINtrC2ePiMhVItRfnPwh0MdEAhszMMCsWMC5UsCfLCqgQj8l10Dz2PaEr+n3NftTgQmwYgLMLI3voevCkFO01DtrdL+n1CK11tBOSfIDR/j9vk+9uoYwy86RfjNLfRAeEut2tkYy2O6E3/ffDBp9oGxyc9Hgux0FhirbMhRVa80EgUzxdZNbRxB8CBWUKl1bS9EN+IyIyI/+2sfk1T/+/K5w6COAR+VgqzMt1F4AsSLF+n9xEferPQP91CBZW6YslJyOMITVkDca9BNQCSIi13gGLMXViRH1RSLCQMfhEUJzXZsrAkMMWKFMY5s55r1AvqdcPalAnq07bRKUepnS45T45aNQqAoKEaH1P33ql6p56vm8IH7A7XWvsCxwq6P1B77CvR2yJt7g09y/8wfmtpKCh846DKa3YABeqKW1Zq5/zYRMUnTAE6eLGgQ8U55oz0hYVVeIf/gbn5Q3hsCXZ20YKCz4zq87psHQz2Cp176I+z2LxcA+9VePEvg95kB3GW38e2OLr0PYEcKPlR9Is5m2OPj9TvwBkdxSf3F5srkzof6cW7NN+TPcO2fq2D3f/5wHbeN6I5owkUcjRgH7oaPSMuEjrG5AHSh9e1KFBadb7fdw9PuD8338NeSR9sNil3g3p7rU8A61n34PTLlhyh53PvV35fdJCVEw9QCG77ZNiOEhzb9jLHJNNt/DUJyuFfXPsaV+A0uPErFfffCqpdLjvqA/ppYAMyIBXbV7GDXVMeiJpX4Pnt07kcCoWZNf+hy7exI4bsoYqFBfS+hL1p/cUs9tNxBYo6ICNdTsJ1erWuqTQHlOgFvdM3vMJWugg1CTCKjB0idecz4DMCYwPxI8mPlajVlpItKkijgfOj0ENtZSJ9Zid51ZTBILCsPPUPjQ/msxaGhYRwfXBsd2tzhIrsic5yJFqgo1NqYWGEr9HF0yoB8cEX6Hgcm0/3jtUCUt0gCnxIAP1wn8nhmWbpWe9MwUWMpnCL6nWX8T3w8XrTlBpaCLhgtGGJignH5r410h559hpQ67OYT4JlzvKA91D18kiACyYJYkpZ0ith5/2aW8dql9S5hHZbB2hHr2Gb9w6KVEqYNnhK7T5seoZ89C8T4mMw5ML1ijsc4AvycltY/KPOmMKXESyOcZGGPeT30+myGoSqLYRSFCofF+enxa0Ax+LzIZZxXq99Km+YBi0NetQ4brUixQHiu9GMLOfIUKn2GOXNo/ttRHYY/dE7CNTFnF92Ck8G3ZUdCRsMb9aq3JhQW91b7Ru6nztK2mTPF1YEyhYmPoWWk0reTHXn1Nrt56abSLZzALxsYuhw6ZlCj8Jh85pXrUE9576mI3pZ3ul8ec3701Z6l3ioXzFNyw/TEVUdmNihcK7mfjagfw+6WGdY28EK4ZPVcsMOXWnGEmUyYuFED6xDwfKFEOFd0av8qO5jbu8fTsilGxSHsSwxSOkenyZZKnHvu1F1eix8PYR1x0BUV2PvixBDcAVNDCfnaIgUwzA2O7g9/flTdtORT6MKcpad73/H5aozzfpxlB375bN5+KC1KrLbsba8f6qZb68fenPv95ef0dz846yHdIa1wSqDXWo/WfKh2sYKktQ6pnZmz3gJPJuHq/V9LkCwkeanWn+WAtrhOEayTuIv79tlI8rOpUh+9mbBut0CFLgGqoScCUIpannpEX5/Mmb1zMu3ENhXRXraUuCLmFLY43I8+ouWetdLTUU32tx1JooOBwhgkHv8cgMbkQlylKGA3BjEipkFMaGLbMjWU+lEStLbkWPvRlzGIDJq0RI9EtuiMIGim/pjDQI+SXEUfj0FLvxqvMCK2JNaY5xBLh90mcicQKKFJS64r6cKoV/0RC3nKqREOV8fB0VOHGab9r4oebWffOm+B+CwKGJAI7C+OkLFIFq1M4bNsxHfE1ynaxBKsi90WtY27ea5HtvMnDP/S0vPJUX5M5gzWYxz34PUGDL3UvJOms+j3x/bPQaoq/i6WvoVWvx3pIAqppPyu5oe3BU6/JZ1jXCp6JXJB2sUCq6SjZtSAo1oAJDsqkQnRWFQOsPIL5YcEElVoLKDywGYMVl5nSjiN4c79St6GE2Pv4Kf0ZhS/z2tloradKQqKfR0YMs9RT33kv21janJsTWepDdHuQGpeLZReFowpne//nbcQ+qa6vNQlQyO/fzjeXp97v9bCvhXkEnf85gHv3Tkn0+wG/vxcD5SkvsAfttv1qAmOkyfNa98n8XeuES2mbxLWByiq2xLCFYxRnqR/rHq3ZWfT7E4yjteO4KiFKP56xA1nGQWy17zpfRlf0mvLUsxtiN5j1z6dgIYdsVYmlfjcDRNoPprORB4xCPdFZjIcDzyMiisem5SJR4t6WcifU35KyR3ztegd+72E0HCkT/YWLI7ZdODmw1MPGYsYx91Meh2CiTc4gzPqFMYQHPvXIUDaE30OnODBO8AsOTHS0OGY+d56BK4HZwnbxQJjw+840x7ztZBHEd7NEoa9ZX6ZQ12hep4Z63IZ8ei1DqPcpZz7yic/Kp75skYd/6KleB1q2NIiW+JJpoPkQiDBmGkwybg5qF/JeC7XZRF77I8/K61/zjMyUP8pQFl/nKSqgRMRBNLUdvnbfoIJNRErGgEE9S+JTn1ma0AIsIpauxj2z+vt7/xmxAPD7JWryC+yfWoucTiPOwg0M9Bx+9XtPx9vIJYOFjQx+H1ASudb9KvGD1EB5XphCePEe/JgZL3H7xNHMWgJjgQK7CyJHExLhxDe9/4jM4LV3PkAJZWW7yHzXvetTKVFxgWO0unCMNNbdQHkktKqlfi3xrODAn5OB98GmmEaYUiez1FOdJtQTszmRZzFPPQbk3IPfNxCuTJhOzpGh/wK0zBRE0C3qGH7f3PwEeDMw3yxgNVhPinToP8Aeab2vdamdfiSKY1bPBsQY7ju9tfj1EN5jcN24AfkT0AAl0FhvuS8JyiDZyzYn855gUEj2lJZ6UcPZrc/M2ycNLqU46/KsI3f74jODEY3xXeX9aCLmLhYs9bRu2BeaferXrbnAZe69kYU7pGRrfMbl82SdltxSb7Ei6jyfM0s9FgzcpjGodD2ymyIrfxgmb6gwPCuIdrm9eNJYPL5PjDwy97KLqBSxlHYpAB9ihhC6jeMeBEs9BdcVmXQGeVwrjP7SrT++MwUFKRcMdbVUM0ZsVVza6kBHRkEFxW0rd0L9LSkTejKISiB2g1CRj2imFd275jpDZG9MZYTEipiYYP0EiwBbNns/PZEoMi8zAU7rtM/E/PV+NU+0SWvNULtg9azxkAx9Z6h1Ui/21SEX9JYR/b5RcKVDi9tSEuapBEu9WrGuXrhwlgnun0gnnNMPdfblC288EhGxvNcojKmlniHL25bB35pnDhOl1Pw59k8EGeOcuQ7ogK3JdlGlueA4Nj29zgMFlEhk0DML69GasFRquhbJgpYJ9arM8MoCDxdVtw1oKGUWWXiclnrwqXdbvPevyUhblayJI6E+KArgAD+qg11QupX1INiOE7SBwdyBSve1jfD7Kqi0a3v1N7JuubHWSP8AQXHkU8+01wUblPj+m4i0xJqP91yT4qTXG/eSMgWr0pFEOMCbO0MLNxQJ78Yr7tTa2NeSMm0xLoq31J/KEIq1H4kim4VWPuNYgXpN8NTgs5uk9ZoR4r3fKqM/tH1UFPWxROuQUy7trBnth8sHLVPA/pnPfV7uf/3zsiyJMkZUMTaqHGMJUanP+/3QTAJXL16ILJO+YCu6T9VdKyhBNzjbtN6QSo5VvJHis+WPhfpDBI0QakHE7Uv9IiATE0Ua7+Vz8m4XnWxAerC7ihazsgfFR4yHsK4bKF/hTLm3BAG904dJzPh8s/HpWU1xHBr0XQSMSKU4offynsLvZ9u2xxJLvcHWQWDMAqYirbQx8bhLCRZg7LMp+tgCPvjLUqbLSL9PqymuPi1XV2cppTgFMNMVzqqBLpYipOgjRc+RC8lGe1z5urPRhDyI55kMdS5lpy6PPaXlHvweAtb1+YxIk5WUcB5VyAH7tB/inmHlwnSlmrFfHnzji/ILz5ytn9iPIpP/R9njtpU7of6WlAA9WT1BX4lQ9c+cMmPfUhItfVFARUs9EuGVGJRrsmxwUJEgsCYQUC2XO0K900CD1WJzsGOhZ3zQGIbfu0Oy5gG/okWdhLFEgx7guA5ZMBjTA6skW6ztQMYHStKXtcnn27W88TXPyPnZE1jqE0a/9gOPNenKsBgCYouHhnOdGBA5TtcVGSxmwlog+lwQWitC0Wlp3vHgabi2XT8KaIfnYbSL4MjiLCTvG5ULlV0URNz49+H3maUW/YF35pDg92fu/7rJF9pZfvn5TWSJAckw0Jpaic60f4NAimuz5r790SoRA18Fi3egE5nVwZdrgt9rWVSIN4TEEpkTGEuB5YLvDsdeskj/kihsdI5pT4hg3BG/QQJEmZRFdUCfb0QaJEzNvWFZPNdcKcUZLjL/9kwps/dqLAbGsODpGuMYL9qP86iI1zfGGZiR6skF4ZwLg9MSmCjlxucJv9+ojuNAeTpwZuhnKe5MZMWhiEwrcZvzoyghte7/4oMH0k5Vyli77PaByCydnxCbhpUc5ML0S1+4L2989TPy0fY4uCz1z30P1VpmoDxQWDrXG1GewaMjgrEAitJDpvV5oDxU7CdKwh0BvXc2o5/xnGLosWWlafOem+sBS72l1vTtIH1Qfdi6bubm4JB7l1mgXAwi1+z/M2ZqAH7mdKqpwMNIhFqL6/+9pwb8PrHUG6/2aOw5oI97Ke3mfiX3BhlrJ6DR/Hmm43JjIIVP25qct00ev/XC+C0sHN1fy9XVWZal2jjUJa2POQaX0zGLiHz+/hvyxlc+JeUCUiFOqbr389BSHzNL6DMi+4HyfHwbNpa45g+j32fKBh8fwNdpGRD0PCPFcOZeyYgoDrh4DYoSbHMFZc7ePktTmN6ScifU35KCvqD9Oid2uMZVE6ia/2CpT4ghljX4mHWhYL1X5fEy22ALUiA0RCTCIUiMGdLYPfgdH+hT4wx1SmfOi5TcUo+W3QzOxoJ+YSap7Ea+xsEYk5hEWG+msYV2xDP5TRKGJIlA6hAPI0fpCvMyfST1psmZ6OHFWtqTEkqLig7vqXpmXBEWLMBNSz30NUE47IlrDMfKA+WRn/fq0R8YJFD7KhIVUJyKxcG3mMkY37EyJbgoYBAs7J8grJPf73Ecgq508u2GnLQSGZ512+TX6pWcq8gbT8fUiEorRIrB7zl4YITTkhIDhOXOoJYQKC9TDPg89S0RwBI3HSostGhRX0oMtpMxJ7OPXljOxipLCfnmEdbrLPXUT4YX87qKwcS8Qmn61c47bhJkzIox2ILr0gKzxUoMi3bNVqYMaeOsJsXa22Me2YVKm70GphfbXMHaY5bInSjpJ/I5TQMnWXoxTxOMcbZgVMRsXntBOFrqI41ABEGw5ArS82bKBQyK5bOf7GQHAAXDnqCyh2SQ0YfXr7uV9fU2rbG4erfW12qtdQioEMDvIkmRKJkiHGgz3XtBqShtztNAeblA1PuZzQ8JjEw/w/5BZKJ/twU6znwUu/ahT30ZQQ65II3oSp3RdhmxT5zAt4T91seHa7k3GoI6jjmrS6JcgPFZ3WXui34eLCHujPme31P4fV9DF5dTgXU6Ld3SztDus59fDt6X+dTj7+EZGSgvcrX85ddfkzf+0NPyiXq235wxAkoFV4tlqU4xv9TOJ0W3Hk/zP/CTvyRXX35PPvtssbpSRffO2bJxWs/xd93y/WtuATecI2VWBVmEhkC+h1ak88zGYgMqga74gLI5ek9LCEga5rQGZaHrR1Ipog5uW7kT6m9JCfB71vQbQfCM8bZB5FE+fFCDLpGAbuTr3WrfrK9+7fPyofLQ6gzw+8T66QToEMUb+tVE8CR50hzHurm1pszy6/3LJgNk4wjC+A3QVIb0FWVOaXwMMbv21mAOLMfa/yb+elrquW1iUpDoaa5bERMw8dm6VBN0vKV+KJEGJXFWWYq4rozEuu3AyqxNgj6Ovj8p0WcLmkhUptghUsS9J5wPEYDWXsY6+1hgvBLXbj/b6Ltg6ZzvSmHJQahnhvPAiqwVpRYi61cb44uCMTJpDDkPlvrTMvZv8j71mtcmKlQaKHpugN/f5A/uIHxz0bliFoPhU6/lZBay/pzlaCf4b/CZLb4fyMDru931wwXXCqfUAvj9KbNsPIHyqC6RBrCFyo0Hy+jvlbSgDAsuRUpHwnlDa+DAd1HPn6vH3vdWnzGmebR73aKFWCS39nA5k2U1KE9Cyqy5Vk2op7OWrXKB7qjCPVPQjYLBY8OZWbxS0yz10A+nVEsyTPTzG7/LpXoWAthSP/tUDMYc/LC34ZpD8UIuEoWFyM5eT3sX4btH7nftgKcI7yDA7/cs7HCGCgo0CqNe54/jT4YiwJZaBZp6iiisfr7PCkuZ/FhN4PdZ+r2sXVQmiXgaOzMoEP2jc7KWYakvnWaexnnQWrRaXxKvdnl56ijKDWID/BYs9d1ociDkj6I8KirlOADdw7X36XGZv4FM6so9QHnVZfZ703V/qhEqThD1F57qaUFePU1hHM8AVcJjvAHHj3PaYn1um3tNJFFacpysLdlpY7wLWftREOaU0Xh/v/bn2TXTWdcPr/zksmupDynt/HO8jzJj4J1P/V150xa0MImQ9psFtlHsQCKGhiFuvY4dLR9bphNGmwnHTdbPaKnHdprbnSbQPd73qcfDeIPfvfxWKKUdWbkITSAyCPGBtUwkCnSZpf4QvjTgiDEyr6+DYdRrAneNCAGGwY8D2w5BgAUqk0YC3GKG2wTqRilTFDYYLPVD0WGtZZBFsDIzO8qWerb8iUTFSLBiqgWCUAVHdYbxliJr40Mi8W3HgybEHegWzI0UPZlCDd8vur7YmJL3LSSkOncJIbpRyRogINQXn+YwC0Zm/SBBF33dUFDagxpqHWwlC+0kwgBfz0B5DL+PecszpR1b3ZoIMTizT2UZqITN95tdKyIiYNKiix0lba5QnP3ILPVZFg2nlFUGfny1SrQqihRvqa+JpV72lDJQC9JwihqfCW64ZvTvEaLL6idiwb6drAhM4zSYVO8ri4HyjhFC+/B7369srSPUdiLr/PxYXUPpFxAizlI7v8/6YVY68rnmx0Ik99b3UK3FlIK6/9XFhRXG7J7n6IXvnsF3WRFua2cnlS77undL/bx2grPIRH7YZZJaFs4pFyRMK9TxJXuB3419HGlgmR64yPU3BMpbTx4hZ2MEodFiKrClHvhI9OPXT9NSP/ui3T+d6hBo8wwjJow9nr+r8sUC8a58lhCPGubSXQa3RPfMqDYEZU1oK5ZCn1Q5IdJpuPrhm1CPlnpaF0oDnlLFpSlo4J2DgL6tm4u1tKjbTJXIW8H492KGmHuIjtUZXfxoL4jnQTQT0t4zjS09NxPFgBaN/4OrDcuJaNEl83sHrnJoCELyfXlnqb8rb/by+VcfyuO3XMzIj4lgLELbZVwwJCYVJBhKnsHREgtSdhAyTJpzWN7ku59p3K6IOfP+mHnwPdaGYz84aj8zSaX0tE3MoBz66UkyH2CVdfB7Z6nnOQQrLMGurB9URxOvyFBYf8NnCIJe6yQPtVbzM3ZKGCLeaGFnS72Np7UwvmHSnvVsvu+pv/RYCJc7kEz0beVI/6ZcGVYGx1i2ucaOIlv38d5gKSi5MsUua25V0f6YdY+VOuma3meO++9ZHAlG52w2duvbrBJTKktR+P045C2X8IEbT2HrP/T1KBNHpgzDdWjre0fdr33TcnHphfqLEf3+Zz77eXn4lU/N4Edwj2P8d5j2TKkV4o6cN7l+7iS/fH4DGLrm9lKA9aaoCz8fOPTcpz6ng1w24PJSP+Kg3CT3oFSQ2YdX7gVCQlgn0hF9/MhnfM8SHeNusEUt7tW4pIqvg4UWjuWh4zyA36PwEhRBeq6MNaJ7EH37vVCfICxYGZNPT1BiciA1VgYE5XfrbSsMGaPwX1A+aa0o0KmWoLJGe2yl4/eo/WYFVq4U298LrDgvNUndKB4CLBLpafYdG0O8pb4GhA0rZFmo15R2FuAyyzpTBh9kylSvGJpz0j+rkjNAmpWP1DO7TKPIclpkOVXIS+/PTD2nNfr9xeWpx4rYmgWci/B7VrpFPmdes+XZGxp0llVYtjGhognqZFcFLYjyqrU6RIrGOLD1ePJnoo0D6aVFss/Xo655Vuw7nhQUFthO5urq24jCsJY9uryRewW/o4xXO5OykAMaOndI2vOqLOCUdi76PRkFZj9cVUBH7nzq78qbvPzjj3xMHv7hZ2S9VJ96OpDMTyiWABEyqNMNFrcEWsoHdBdQ6VAzOF6eji7PP829HowVaX9PQHiwT0FoMiIyGZX1zIQemYLNR3gm32AbGzG3mTBO8qPNWRoNO1OeYDCX8YfOtsDEBHihCfHNqlGBXO9blnmYKcxMxAu2MXIxoztm35WRbFuTT772ujx+8WKO1/d21yKCY9bCRD6zmPG7whgTDRjLaenrwv7M0bpjqT/qp7Z1IHzPwHHNaZMDRJuZGRbQybLE7ahAOgWi0U4SGAwPwJUQDgi/r6VbV87nVba1zVzClEPaB3H0FmRjtNhSnygbDq3mJIAVuveShfhLttR3y9Qv3L8vj7/83gycFyzQa6h/Xbec6awRSivS5+P6hQv5zevHM1eweMZjD36vCBIMCicSLY0WzwL7TtZL3PN6LeKVUFn/3XWiuNAx+mvGNM3CwnHmh7qdo1IgQP4TSzKXecblTG9Ef0RUiZY9S/2en3LIZAFzZnWcMks9WdQs+r0y8NXtlxlIMAoJxuTuQBl43V0H1IG454L//9bpXRmBVdd1k+vrVbalDKVwgupwNDNXcmqxYF2MuKDrbaNAeSxYi0guOOf9KqZIdV1N3KRIGZEgioJyAF9BpvQUT7uHS71s62aW4W1t9k67Mr0lArn6OsM54/LU+/SLuF7s3LBzsw0lb+9Mk74OT6cl5KVnYezKfOpnlP66FFvHWWwVTgVnYwoKc38m6Ny5ZyQqfCbtnYoBq5o2PgZZXU7V5t9Z6kMqOVonFBwyOxNZAYlopV4HCsJjz0OaS5HoThMCLFP8Cj1f8BmGvTP8ftuaXD+zyOfb9exng4rkhoB9FGBY17F+w779HFcjDSYs2dkVUQh38Pu78qYtf/itz4uIyNXlOPDRqlyjZRcLL3C2lPRKxAmjUkaqNbbQsJCwboGoarncEZSO/DNLezKGEDc8CskupR1qvkvC0KHlmPL+zpQvfkxHfnmTMfAHUeaT5DT5wRI2BTidixAdPQjKnLecmAdnqe/zbEHRStdIq9bZwUsPUu2Zpd4EkmLt/P1PfkoefvUz/R6dd+hLaoXeZfS8Dy5DMtWPm+H32zYWEzB03ES01B/A7yW6X4gkih73/ik1jc4RC/U4rxrEiOFmN8AI+xz670IwTJhnttTrd/i5+9Rvsm5b3HsJdLwsqkCJfdu1eIukAjZHQs4UKlpYqA/R7wnCejrV1N8wxibpaxzzE2vJcrjrfp88Pyp15hpcSZmkYzMF5A0+wTWJvN9aizSdhPx+37yFaVymqGREQEpLg286MljsUx8Z0pss9U38GmEB3NLAsdDKqZZWPx8oyKHriUhknDOEEL6DI/j99fksW90PaIX11OLrUf/nC40DouuIBZ4k6F/oB0Ftr4Kl3kserDhSNxp1zdm2Tf7ur74iD77hBZHLgR7BBgtbIL0ihYu57O0oH05ALz3SjtERhVLrRSRi5sK4Hx/Drx+cp4wuO8V+8TQ1EzTc/ilzLdfSfeqzfc21sBuQFFJAnachY8YYGc/SeCffUExBsCwdfm9GG/KhtzMUlGDnYfWtGJ/lSS31EpWHGVJrJdrZNv8coxq4Tk5ph2eHxjQIlvodZaHRAHoXat12CvXghx6RJFlAYXzGBPIEwdrHGvlRLZzm06f19Wf1o7c/Jb/0+A3XB90DKBfs5anHgH17ylOMO4Jlj64yH+1cvnbiiN2GcifU35Ly0tvfIiIiDwe9CRDfTGhR5mSHGY95WvetsFoy2OWeUJ8FFuI6mihj6Q9YLbrBHz/yzIhjeBIrXwpF5sjmjvC3QCBSBiVYtfD3Mixszf2o84yWTnfIbFs69yLTYrhS34IQTIRTqgRffQetk6kB7Z+LEU8n1LMChuMwgFAzYaPzmUx4apKgNVKY2EBrhMMnh2QGPzpCYljjMpdYjKi/j17JoMlRQcE+yWL+sgXaNR+8JVrqFW6Zrem9a85tr58yv3S0WvDeqyDU11Jc8MToxhODG+nadFaJsTadDywhizIfYdf3RAGBhYV4FPK7/69PC7XtRr+PCqhtbflYNVUPLYlVlUnaFlpc9B52hUqtrsQYogKx1iBwaZ5xLS6VI9YN6J1MeZQF7WSXohDxO2Ow6Py5YosQB4+DfvV+uCY7bbX6PWuYCRQineltdSc1Gik9mNlk5cOlQcOfMPq9HgNF5Dee7jmW28lb4bEf+o3uQX0PqvTQTCRpdgAB2pQIPuanf2OgPD8LTEf1fMM89b/2hQe9/YuY0s71S+t0ubP9vWyp59R7OMcsuIVC5yNDuRHtV2pJU+1NlB3RabjNWSVFTICzAlx4o8Cp1jew1M/sB5uUIrIQ7SqUtUFkCoHBB5uiwG+tWb52C3iG4zUrdtNpsrpOp8XxDHwO67VIVzqqEC8iZuGOKe1YGKR5SRRXNmbtMxlAmrTA2+G5P+MG5KcJ+9RbVqBhqa+nGtA70VJPfIPRx9lm8IdnBRoqmcYfc3XZCSiZxiGBa9zdy46FHGPPiIy9WLzih93JQnBsRCrU3ECmJSgoWKhXBGlw4/V14tj2kFm3odwJ9bekPP/0PSlXmzys40B3qcUAXpw8y8ErUku9sNWZ0lCIOKuzlhBEyQnkkQlK2yXYW5FpcWdtMPvUWw5LZQhVCAYCOf3LfLvn61Xe+Kqn5fq5U9TSm0/6McPLyghnuVNCvG7y8CvuyS8+et36Nv1a80BUEX7PFuNo7QjWfiToBV00+uGixLLJ9KkXyfIwz+Lh98Xd063QXqhdLpapSYeqQqpEJPqB0YtCgEg8BHZdMkCTzD6HIRp0gN97pj9TYB25Evi4AxNCuW2bbHVaxh1KRAOwhb0XmTjXD8d8a99ovyZIC4TnKUMpZTJiq8LvmYHJLPWJm4D2jQPlvfFVT8v9d74IVth5fxNOi6PWLJr/xLoi4gPllRIjSJ81EJHszzH2dfq++7Fm1r3tvMPQJUxQhN8rkqMFYu7z1JcBWZ+/MzMrtQSBqsmxpZ4tj0WUPvkxBcjxus887irhVGDSQHBWQQvjFTm2RLMwqArKX/j8F+X+N74o989n1yb2G9c/FkZnZOnVtrUrq774DS/IL7/+atqGiMjr98YZpFlECEGRIQbOND8npVnjXQQFcyKUamELeBZDJHPF6O9+XmtqylprEpVdlZFe8Mro1BNb6ncyEGxbk6u2GZ9wTvbt8fkY4fdRsQjxcE5RWNESrejkOoMKKHXr4729+nNG65002CsGMyHJ8TyjkqC0af23Wok/kKmQwFJrsfW4DPi9FlZypcKwuWqN7Dpkqefo99Hg49fS+Qng91m8BaQXU3Gh1fjn7z0FPvWWpx4C/mXw+wOfehE435p2G4Klmk89IwpAGUF9Z4NZhkTS8yzQBOWt2UXpVO38zlB1FsA0Ua5fnVd5+JVPmWXHZd2xfug1K2T9WC4vOXONp+3WL+TPm7hDYZ4Hd5b6u/ImLW1rsjxe5dGQjILgkMGCx99AeNL0F8ycD8sPw4gCsYoRl/UqgyuKxKj7wXcfNmeA3xGjNYMsec4MrSWZf5mIyKOrs1y99VKuXrgQTdXj58MfpE0iI+VcB8acZYqQ6+cv5NNXj+wZx1i3JBVVsNTDj0wkoS+WE7dE6JWuGa3bB8qbPvVoqWdXCRZgsd5C1yIiy+UCEYPnCZWtoz1Nbsxjmit6+CBq8wSNBzlYErHOx4/P8uht96Q+c2H9wvFmQl+wJgTlEPjUWz2bPPjGF+XHH94P7UwIO7UTBPRMMBjjVEt9SGm3TeUKoAis7QR+r3A8zqJxSvwgte8+I0JJcvJucvXWnvanLSVHBaU5xWHAUIJPPUEoQwTpZA2KzDUUferHWKlP6xoRBuu6OcYFrXB6z3kE0yvkL1hEBe/4TIijAjEztJ0I4cwsmH4fBqQJr2eqVySBeQa6F5W7V6SEY8WszuMEOjHtiQpFVv5ixGQRkY++9pqIiPzmww4d5XE0FDBJU6Dv3MZBUfxF+l5/7fGVyFLk5x88sLnolVtnZ7czS56I0Qh0i9J+nS46Da0q1G/KA8T3xIoBY+DvHWcQ0Uj2Zu1UupnQoevrdab6Wje5GOfItmgUf39/iP2RIGT0fXL8lAi/79dta/IrbxF58Mef9/2EtX0YaJSvExeuJpPex3gJ+lxilQT6t6Cpe9wfXedg/7RBg0f/FX7vDAwp7eIsLP2Pj//Q5BdefSCPX7zYzVPvLPVtVDTqOp0WtyemT70XTkXE8rtbWjI9S4alnt1lMqUp9mfOnX8/IkCzZSrIQ6A8q6OEtRJQP2EcMyCkZiOIgZu9MjFTps/1WOwMENmHrHtLfbOx9Xa99fqC+GKbI1ImY2FrtgYFjC4SHcHj5nsoKLSvn3+myOMvvycfedTprdsTFvhZeVrfIaZFiPgQgUB6WepIN2XxzLkT6u/Km7Y0aY7R9FDMGyz1JNRnfrxN4iGXaf6zwFstYxxlP/p92PAU9MVZeXassmjpQmZGa+FAeFJieiPUambW8g6T93Ww31r2u02HCuTrJoi9ZgRECEYEzLiS0pXztSYQPo6466BXwAjodwtCrYdGWsSnD4yCY2Ss9TBSptO7htTcup0y7HQfWWGDvyxrqV1QoLEmykAPDNhoky6w8UGu8R9+9bNfkEdvf0ruf/VTvU53SJawH1rxy6yJ+IOmep/kMrQJOmeP1epG0OrgLy2Zy4LQNQQ+Gs9ySruAxnHrqE1LvUz4vfpFsvIkC4pjyIT5zeiHh/TlPtl+PbPSMaaYnCVGuwdL/YDf43xel5bC7zk2iQY5yhRHRfeho6PR/9XeP7T1qS++Kq+/41n5uXWgd1SJdyBMOfJco/vAtlF60eItqbOP9DcR4u1etYQyyimJrULkyMoevNLB78ElyWh4YjUFmc2VzC1LROSp4Z/+cKwlTg3qLORUp/bb2sjSwNG4sQ/sny4iZsniAJwrWL/QBaaPxbtaXI89HSziiaVWyyXRSLaOLcONjUtQtpUucGtU9taa3FuGQLFEdx5GLgVFEs0d03L2/TfhRePDpD7Mo2re2/gFxiESpYVAXVSIWjdZ71X5zKNHo19e6dcFfzgj1SVn/H4qxUW/1/20t+eKiKPBZql/AhQl8msq4PiAZ5v88huvyetf9bSsS05zdSy9O23A77sQupyqyzLCWWkyS73Fvan+LJmIjH0FcVg7dP42eEdYtubXAyMu9+LraEGUl8YR0NhBqswKtMzQa4o4iPOKdKZJXOMR/ZTtkzLayZVfwaU2IKhA8CXh2eJknP05cj6DsUgS3lOKuU5dDX7GubrSntiNXZIoh/pYkzmV+F6L/QeW+oSm/X4vd0L9LSkNfNX6QYKCEzCSibkzCMJ7QUkSSzV/l8EXE75xtPsEwcdMQNWBMuEhq2xg3mJqJxFxEDcMPNPr9MKIMucp/N5VG4PteL9PCorWmjH1WM7n1fU3S6XDlnqvS1BFyPyqM3XN0X5MAYUCuaarsQO6dIKeBspDBr/mlr+NBBI8EOoCEGDoXID1I3NN64n9ZYNmN/Fr61pcr+gKih5sw9Lx9DbWkyoojpiMMawnYmLHZRn7N7F02iNm7ZFQz7wuTpmm719ovQTf580H6+E1jpFpPfx+gzQxXnBKmePm1y+nGQp05LwFC5+D34eo0f7mo0B53bripZwraSn8PlVArRsEQEqEQqoDBbAmaoX1sp2+l9fbENAQfi8iZ0Y/0bqqukag7daigJHGgKC5C0qpZI/4aMaZgomgkFDY4p2lWEW0Ff+d/WxWeRDqLz1sW2nC5WCBXh/w+z0LuQisfWU2Sai32ACEPOPCPvVYypLQFRVWRj+mUD8YeAqK+FgRV8mZt0vfbrDUXwzlOPc5E/TX8+qUwJeKPkjoifUL6yTYN5bTxSKllJgWd5xJuwx+Mud4RyOFfKG9bq40Cb/z6tc+L3/nY79hfefaXV8w24l0f3hcrI21LQI0AvqG/aq1C1p4trO7i++bGBINrZuo4PvcsuZ1KI+ge6LOQHndUh/h93adCMP6HruCeHGR8UWioj66GQJ9E78e7VwHhYj2nVFhxlOU+TsrQPQWn9KuuP23Hyhv/0wUkfH+aL8aPzqMFqyQTfhCIdpkAaSz1Kh0FrtJEh9TSa8NNZXC76HfTfxeW5u7JwYk3Q9yGlKHMt01NESUIzyPFC31dz71d+VNW/ZgUiKTkRahM5kIAOdcZeGDU1uFYCySCfUtEDAt7EupheH3R4Rn3yqrmtHFmGbto4g4hlerYz9WPfBKrWGsQdmgc3AACVVGwUdtLtNSPwofpj3LANY6rQj6GFrqiyR9SwRO53OUWepdSrt6M/y+lmBh6u0MS70qT3AdjSi7rhS2wuWChJYQPOnSM9eBQRhCgh0soGxQwUBT9VgbF+rXNtYqxQvQEi1CrKAoQUhG95I6rB7R/QDe3Q4cPYuY7a7bZBv02Uy7jdyjT5sTA+VN+H30qT8lVjJDDSWMvbN43wTfTizeDdEcVP/lU/uB8hQyOaoRkY6QyNyGziwcqKX+CCJJ5A/3u1rUHRc0YPvuGdrvNyqPFnHWbRGRtbXI1CX7ir8KdI+UmyIR+hizKlDQIqB3CuvUEq10i+uHLccgYCbWHqszt1wt4/7Xr6/Tfh+lyUMBpg6GV8TTR5FJl6yfiWJIi1ptI6wYAuWhpXYIQ05RZEoP8XXoO2jZ/Nzgq06WehSYeA1dX6/yK49fN5eGS43Wb1ZoP8dHmU54zheDAM/zXdvEfu/FCkGF5SH8nvdgFccDmDI9MWL0Qc12YlCwee5e1EqW+oRPEy9wF3r/dYnulRkywZAGbXRMpt+2riF7fk8hSfWWAj71S3UKuiN01HIasHVF8Y1AvBws8/r6LK3Ae83OK+hfRs9C9PtG8VtSRS3Ot//t3lM8jmJnYHdJq9P9k2DvFqcoKNwIZTTOlfNTi8jgw9bgKgfpgmkI7A+fxclS3sO60vx+U6U93l9BYWF9H+eZISPG+kYkUlOEx3gmBiRFg5OfcObxcV21Muc0Q4chkqFoYzvzcVvKnVB/S8pN/oVH8HuGtOVQncgARut1Jlhswe/aIDA7wcdww7cSrZIK9xKZsEH2x8SotBgoT2QqH5gBNCuOIRVUqBcj2jiEQBAyYYw0hail9ww6+CQRsmDdmotu7+B4Te+JihDuXIgcS/NqGle0IoyyDJ83kS4sl0RAb+DmIZJoytXSBY1O31/ZDZTXhAg0lckADKK/w+it6yZXL1xIu1fHgejrcVA0Osj34Guc5zswFcw8MuNRi7Oy2LwGyOC0oKvVyO/mqFDJUn5h0X3g2qF1xMGhGPppkMk1+tQvCeKnmBWJ90CPGzFTuGVrlRjM4Je3H3eBo90j86nR70XEIoif23DHYOXDSsKB9L6l8HtJXJSKV1hoMDEzMut+RhooYKkv2qYyK7PuzK3FWdnbk0W/nzzeZNKwIk/P2xi3Z9IcikIkCAhIwytk1hDZt9IxYiA7j26iEY/OZ1kva1DCPBrznWXv2KsThfoFGGC1GtcdZjO11KtCVd9vQCrpM82lGtV88NhPo7sk1R+ljVIrKkN+X726kodf+VQXVJpfB9ovEvNEROTj14/klTe668iiih9cT3Z7SXgGv2ewr3XpAfhMgUvpSzOXH+0nFthqeT/oOg16WRL6mcVUwbMMlSsiclqGpV6VBHofvTvuixICjAeCZ9cubzKEG0WEXQPiIRogvPIVzxAfE6X/rjnbtQShni31JDAupxrSWn70/Eju/4kX5XrMTOBzmqczK/ENIsm51/z8uHGW+d2TnSXVkH/btpml3sYcULARSdKYzow+PHjjkbz2zz0nP/HaF3odHOOKLdFQpqU+Dz7aO8902bdfi6fLdennJiNrWbYw3hq3iq3vNuYjCuAwtHQsOj/GI5yK3P8TL8qHH9wfdUaXvT1jYB0xHe586u/Km7Y4n8zCDN6xdWBPSx8hlBl0x9cVmLktBnmzdiFQ3uO3Xsp6MRjqYO2iQ77EOnZ96k9L2k8O+ieS+R8NYTOF3uVRvBm5kEFEHaxLhZyiTwwFAjy2bS0oRlgxEK1WkRnN+jYt9YDmUKHeDqfirGnXV+dJWPFQXUqABfe+sAAHBNz5LoKAklhR5vIu7u5Li37vhQBlEPT6jatreeNrnpGHL144+P08yL2lr7l1NsYbIqyStTgRtpwwQoqvIgMhoAyXogYoivK2Aiy+encEa5vnLFh7b46BsW7NQRF5HRUQKCrA79d1s/XBlvrgOoDzrH0d8Ps01UyiXBDJIvnuQ/gCIwYCmVq7RCQwd4Hx55R2AzFQSzGLzU39Rkv9zHE8f2/ima92mnvT4lKwerZ4f9JKCkQRCVGf2W8Yx41lc2cLuxippR7rKXGfJO4i2NeMEebYDDFdKAlYSCOK/6D791ee3eTVr3veUEgcEyTECHFrla3bYKlH+njNDPzBOTr6bsGhkuj3Iv5cxQCmRdD6N/vdrxMaSvuOx8KK/Z/b3pDHX35PHj+zDHriaS+vMSkoMBc33rMJ9XA7WX/NtQg7V2Z7y9LPopinPs8WYWNvrDgu8czE60r9KmSph/FraZIgeaSktNxSj9U61uiYG0kK8XOqWG3jt1orCa7RfU1kCDn6Zojnubg4pehOXwvyCL0Dpc5dcTotjq6yTzbuFxbqu6J1kcePFH7f6fUnWr/+1OPHYwxEA4KbBZ67zT1TjKYz/D4SJm/A8bsF4ffLMuMIrOctWLcZeab3snvNqq5xba6th8MV4fW9eB94nivy7rLK61/9tKzjzT26Osurf+xZ+Ynf/FRQehRVFuVybxiL0riIrF3dvg8uOWX2T5v3AniSzQcKw+0tyN1T/ftfGgFI8+CsetW6kn1cLYumULyD39+VN2lhoW8lwYmtsFguCb48rU5+txMdigJ7SYQECqqBRQn3F6+v5OFXPS2v/dHnRrsJs57WMA/xx49zTX0W9E9/b8SsrgF+P4X6EMVaEuaM22GLefEHujEGiVWBo9JHwYAON0eNORiZth1Torhr88UUkeZ9qlRLK9KF5QwOpxpnu9a+MvzeQckBfg+dIcS617oS1mz6cnt4FvtgXSvyYghSmS+ndoJiUc2DZM9X0/qt77aE77S4S/KxnJb62LfJJx7ndRVRS+a07oU6eiej4g6FwGQdTehnGdaVrjTrEYs7g8PQ2AD5S/wHt9YzaVzYusJ1BJB9tUYWkfVMay+jM6O/6M+pwYx0LMi8sFAY+qltgHRksMulJvs/ieexdmSOyGDIkdke/12jJemiznVVsA6hPeMF9gztEaPf09qEKo1fRJcM8c/YHicLN6eWisxjsTkogAISSZBjpxyyyooQjBHCjI3t3/GDwdxxPpY4Z866TTQBfep1TYnESOzRUj/qQ7I3btFtz9Zd3KfOBabOeBBhfo7QLhQf4HLHp15Z3nLK0EHT+psVRh1okCxWEkbLva9QXZJEpjDIea8DrWelElvkQIk+x8KCsReiVqa5iWJ/BkGc7UQ+aj5zsrg1g+4T2oLrldZcBhK1pgaUVmJw8CnQhgGF4ghhHes5KuKm//Q8r5SOnk4efn/kU4/uKlqP+muLzPf49FhE96+v+jwEZQ3SougOis9Y9PutOd4nfSaxnAvtlT6O4pTZipzR8qQp7Tx6ra938lKJrl2oKB1/r99yKdcvXspPfuLTIiLyxvks69Mn+elPfFbOz52SOmilFVpbMBYVhLOsQpgU0AR0IzUFYj/1D9Fwt8Ha9H1BRJRIslZHCa5TxGdwLIqFXE5uS7kT6m9Jac3LOj7VVp4CS7dPlhdYJAqtnIu4W6+PDkIVSIlRWoo8fPtT5gf+eDAS7SKm85nw+8kBOUu9HuKJUN9kx4dJmW29LF2Dt5dCRK3JEf7LBDFazNN8695APH2S4NoJ2y1GGGbFgKdYObO1bQ0OqG5BsGkFAq/jrHroFrVuTp/ROjTUh0oMbFemQOi04BgoT2Zf2O/S+1myxcwzD3uW+jMoaZwv6Hj/DgbNbexY6m9U9JR87bnr1a9FZJ6sXmRCimcCXGXwkRmH4AYjEvx9MeBmEZ33+RxmRCgOcjzSWA13gu2iyOfqCD6W7T06wNlSnyn2omILrfmJhQ/KBVnqRSZt6FZ2PQqVqWZbZi8ZEmU0L5XS4omMFF4Z3HhUn0WpF/HvZbuY+wzTMvkOREQE+9RvjdZEAn0WEKCQ6dXZaLyeRwkMVXh//hmF/4r4dJkigBwj95kbkSnbBsqWfP/avaocOVCGq9Jrz7p9Iku9MvOcRopzl8+5gfc1+nG2bBf7dKXSHqx0xumTaaC8OTRXIlrPx5gop7pzpuwH65r3jLFtydgIYaJxZ3Zhs7XD72NKO58yLFNocddcr0uiBGFL/daC0jb6BntFqgivMR+L6HJ5MhbcKXXIBSpDCAVFcuB5+n0z4KA/QydtoHVoxiGoZ5TltLh9jMIvt6Ep7WxMi89xr/feG9P7+UfdUu+Cvyb8Bu4Tjn5f4PsPfeZzcv+dL0q9HIIdrQ9EKfAbCgH/0PhxA/xefwuoCDwDlDYFxdS8LsO6bbF4iN5dKToG/N8bp8IdqKsQIR6UrT6tcfVCPSosoPkQUb8WUFr2Dzl/E/cotqPF+D0iO9fkspbxGfpBzxxWuN6G8iUR6n/4h3/4S1HNXfn/o0ShD61jk4hkLClbFNJAecIEVHPOsqCbQGBo3zx8+1Py+G335D/62z8lIiJrSGnHjFWE0VjfOTIm5AV99Z97Tl4pXcObwbmFDqaQQkT7MTTy7KN8E/xeRAJM1jMGsiPAbY4pYPi9EiyZtYSSCX3xADQJdlxPS0oRTmkHPvVX536YBWugv9b2zVKv3++5McDXMTBgC+PRoe/B/IKfpbajEM+EIXDCNdZJEH8tMTBawjySNBKFXIB16lpkIYmZGYLfa+5iNx6yCK4J881C6rbNSMCKvMBgPGwlwowImrP3fF7l8Vvvya+sj2Q7eUbCgnZSV9TfmxUws18Y5CnOyZxHrdDXf0l56UWmANAF8jL6YdW5a2uD1iqul+7bmikwiG6AsD3zQdP7D8FCN/d7Gs2bLPWcWqht2+563ZVc9SeiR/abMaAeoePpAPWlNa9/Ykb4ckfJfAP8HhVfPAy2GuqJc5NPdOYjbXQHmM0y4MMike5kQQP7AKC+8Vn3Y3STmdfOpx7mzlQFKtzzHiOhFQta6jX4noiYWwArcKfA1CJkfEeod+naYL1H2DegOppX4qoQZRbdkz//ZzraCHlPC67rhC5Dx9yZYQp52qeZjy7D71FRxFZIVqhZX844R9itksDvc8Ubz7NIVJxhGwF+XzyPYO2DpR4RN7znHPz+lAjDSVwNnW8V6ncDAo4jJfWpD4HyRH7qM5/rF89cpPTMRWPnvUIK4goBhTVQnhbkPV7/mmfkR3/tY65PIjMDkHftKDFNaGLd3nM307P+TIKuT31I1n4qtUaf+gV86o8U8NKEAJXN9StNfT0PU/dbgN/vWOq3xJXQGwP9ezqd4r65DeVLItS/733vk9dee+1LUdVd+e0WYhxDpHolxvgMMSe6OZcEIpSmfGk+2FiTxBf2HC31Wj76yS/0dg5yHIcgIjK1zCJT2FLCjELBdq/K40FZUvg9wp0EhXoV4NY51pWUEyWxhIr4YEI72v8ItSZLPVvYtkQpQQKbp+oRwsiaepFOYNt8BCz1/atlyX1Gt3WTZWhx+d06Tbn+JUu9Ey4hci8OITBYK2pdmejnzEMMlDcY1KGMWFt2GI176JS8SKDkOF5j8pp/L10e8mNhhYVaakubGveggMnaJRgrl4h2IMZPIoLH62hi3IwYKG8GsVEGZ8aImKgCfMbvvdm3HigvUZ4gAwPr/XymOeI5gd9cjuTBqJjgksDvW5zO3q8EXttE5JFsUpaaoDB2FJ8qly2JcrCQEkckWAhtGlSAC/Q5+upvQgK5xHWGg9N3xPOeCQwcKC8GnCMlFCAC2FK/l40lCKl0vTWKVwKFLZHqcxrcx4Jv8j5zHwLlmYJrlasXL6Re5FbjqAwux5b6UiatauRTD0J9gN8n8HI+e7To/LTWPIRYaW71geK8wER8gtatAhKfXc2PLQrPMeq6lrp462Hwqc9cByXSaTtvgU5nQjz2ISjkxZ9lzpVA/wTlgArL/bvLJRdQuKzb3F/h/Z8IIcQLdTTsg3j2cg1uDJ43LDM1GZTgU19Kb6/E6PdPP3vPPXtBwUpdoDw4S0Qg20xmjIGCQm0Tf05ahhdCOeE+WVTpTON080m/3SOf+iNLPfKj1y9cyOcePgrjqCP3uxZ+N2mfjKbmQv3VuPc6WcN8vYeCZWWrxqK5vlplvVelovK1QJ1mUBp9q8Uq1nfBPP6TujmJ4DryLyYoPej8y+D3dz71O+X+/fvyb/wb/4Z88IMf/FJUd1d+G8XBZEuMhH0U5XEy0t5SHYPN+MM7tXY6i00SMVZE6kjN8ekvvCalFDlz4A2GCG1MvKZUH3JWooKiTGKSwu/bqGlUdz53YWTmRJ3zmY0jS8Xm54MzBpQRJRXGYn7LE4Z4PrN1L0mnFxg4349MAxvTweA9FHehNecbttAhXE8qwMVDgvtkh6oKrJguBoN1oTLk4DAPmvN7DL+na7bejDWVRbI32aVMoWOrIr/2qc/3Ovb8YyUq0+ZY5thQQNPfvVWg2Jpw7WBgH/FWyTEkarf4dSaBN0mEmCEIwI0Y2FHEWwlrLdNFQybDfXZwvCKeV/bxAJTRWgf8PlOeTGSCB8W76PcS5wQnZTkttp4t0v0pg98fl2BlFZH1mUV+ur0hV88sgXHO6QZYadSnfgjO2mO21JtCakdQ6t/BIzW68XD0e/f+E9lemzhirPUTW6OPrEoifr3WSqmwAG0lAtGPSdCjHUBuLH4szBie1dK87e+zwAQj5ypJSruxvr74VJM3vvoZ+eyzY20nqJMxoFnz+KyW+jDnLlDeVOygNa1RtViF7aFxA5OLS7B+OcEEhXoQIoy2H1j6eLzWP0LJsd9rSH8IdS2Lt4yeCJU1DRRsHc+FH1RWBf7GKQi9y5YGrMT9VJdlrh+kDwkST5fABcHvpyjky5pZ6pUGJyit7Nr55auQRTwfPh6QPlCHnVeQp345Lc6y+8wzl67OS4LfOyswu+CQpV7LnuLFzl/sr9IvPedNWTlLHTFhuDhlNhETB78nxAEHl8tixPA4Si0ejVpKUIaL5K5T8yvfR40fxEIrK39iWuYZIDgGyuvXj6/O8urXPi8ff1sW/4aRtVGBKJK4JMEzrJBlFElVpSO9tizLSMi4Moohfu7g93l56aWX5Ed+5EfkxRdflO/7vu+TH/7hH76z3P8uFyZLMcqxHsaRgO2lvziC3xfxmmv90sF5VbvNhqhx/fkHbwy/Fsrry6k7iPBkPvV8bcRMCTnDGddpYVCi88Xzldz/Ey/KZ+Qa7ukMcrC4iSQIhOIjRcuxpd4FjivEKGE7wZ+4BBggH+IBrm6+vPPGle5hNIdLaUdBcJZaTSDx7QKBJ8Y5E0g6s6kXMD4/nB0f8l721oCWNEYCK6SImcQ19vht9+Sv/LX/WralJGlTSGHBFiFJLJ2JdbAN00etJcDksO++r7jHa7AuB2aFD1di9ESUAYqMuz2C/rylxDUR/PaIjrjxytyfWw9caD6xHB1XhYfJ+UTFJVki0W8bLSrqVmK56euMfs880j5dhX2jQgbHhxjK1fC+tylVlVpjQCrZccmRhEHCPcMW0GDxLBGWnCihmJa0hhkRfNTwbI0w0kDbYebRPlWG3ubZWLhdIolesU3NMBRYI7HHAGNE40FoZWbJ+9RDfInR5uPx8/mARlofRyPXmd859bPSHpwoExWe/d9Zx80p/0SImbfBe2Ucwu9DjbR3goI2mM+Ku+azC9c8IsZEMpRh/y1z3xERKc3vc0enE1ckHJML5jUe9EL9tJg75WPm5jXmYFluZsFZwYDvXy3k7v6degL8vmBKO78/WlH+gOoguoRvj+H3Tz196frKvujeX9ufJWapD5Z5UkJTBwHQAJZ6/068pX5x71V/2Rx/6NvA6PeYDlWvXXA5UlBa3xh+r/zNPBrCMzEN3KR3vIrUUu+F1iJsHPHBE0nZWkqIe4A+9Ztm6iBFQVAUg4FEy975hkUfn0pdkfVelWUogVlVkLmW7bkcKe9yG4X608233Fz+9t/+2yIi8s53vlPe+c53yquvvir/5X/5X8qrr74q73znO+VbvuVbvhTN3JWDcnQg9aAaXmDDkuV2F4maQefXXYawSQxK8Ic/x3twcy1LlfN1bv2c7XhfWQ1sJzIDFGnfZ5TyTUTq9EFl2OmKmsFevtA6Ef3E+bFUAcZUrek0/ht96ktucWYI326eT72WJieG8AY44ZzUpv3gAy/ReqMQsxr8vv89nYqNtTNT3jIVLPWS+7TpPBm03Amjujb9sZT6z+5wKyEf7o6Qv66byIUMaPKa5HGfAi3mAm51CDJlaJihq6awkGFB1yVjd5Qg1LOCpo+3X6UZAmSHSWXemAr6wlOnrGQBpYyxGZ9wT1fHYHvIpDI45/Mqcpr3heA8iLwZja1bk/tf/5z8s/a6PM39QoULjIUDCSGDYsyRytsQmEkt9ksCv4+lWSXK6NrXYzw6+WXknPd9Siz1583qLItXwHVYelQOZIG+fD/Isqj0KSgLSPBPLIuKh7B1QHSSI06LHDOPbZwDQv3TUkseMXqeR7rG5rswxV9rVlkIOAmF/TAz4blJ4v/eklge1E8RL2w2pefQLywm+Dky0O9VC1t0C1j14xQiirhgVrD0+9+E/k+lpWqV+l9zY1uKbBdgRVVheMR+yAKDBth/plwEwxpb6kmmDy4/NnDpQnsGv9fyuPU1oD722E+sxxagEnaZe6EIKJuXeb/LXFOKiHjkSz1hJpe5aZyim/iZE9OdhEaLgKGjEQ2mvWPtJHU4hNyoYi9QngZvY2uK0j9F8/no94sXzC9PIyNIRAOkFu4kHV5UTOV87qRNmVFhCL7F0zURGTnmm2xLwhvxXhnlHgfK4yj+u0qn+b2D35c6lIeLay+zPM+GxKHAuI9X51WqJO6wB+5F45b5mX3qx9gCPTtv0+VGlA77tcbrMY3twvL3qFLp/9VbL+XhVz0tH/jHHxlzvI/wVdfCBssa0ZeKcLqN0e+/JEI9l+eff17+7J/9syIi8uEPf1i+//u/X1544QX5tm/7Nnnuued+J5r8A19usgY6ZhN5IyG/n2dP8usDZXEEv5dhlQ6QoMT39+jQr6cqV7vRgcUYzyPCczpV00z6QFt1CmZsxVLrf5sEUSOrcvAny1MfYLRwgA+CgYJHKR56bIR4m/V2xmBIIKpZJqLI/qgyb82L8ivYN0ne57rZOdMELPVqRWANNFplB9R622YdyvhYH0dXAgycLfUq1O8In8oIVWQEoZxOPT2ZKSP2LPVmVe99WrM1ge8PftN+nK+7YkALuha01mY+ZHu288VF2hCW2KLq50SZ3MOo3NLXCI4y+NSXOO9cgpCKwvOcBheUbc+fV2Ro8jV4IpwsPt+zV+wYc3nepJ2qPJYWhXpRi+ARg9ffn6r7uqw9R45MpAr3Ofy+T4QtA1psWyaQaQ8UEaXvVOnIniVD+nx24dsz5nsMXYW1KKLrarRH6KzWojgacmbDGuF7vcW3M/Dsu2/9ZeXuOaPh+BWovYI/bb5/XasF6MioamtNWvHratY5FuTaRJayYxEvhwKYDHo9mU0KIqXIjzafF8kC5bH4PT+diQbbM7AHZwDTjkZhqPys3dO3dhAfQJEMr37d89KWMukJjB0Vfvp35bOpzMqNfhByYNvaXG8JeiikPyRFYpYHXETk4Vfck7/xS78mzz2zyNUVuebsIdvgzAnKq8RSbyg7Gz8YT5YSg5FKVHwjrP3JrOz+XHVoqeqtqa7DdIl++eb2pCntLhZirPL+sAGiw+/7zSyoX947dR/soTi4KWo8KwREWIEoYa05xXXxMQ6Uhh8ZlerCLpK9ONQX8SUXnJqPIepJoLw95IiISD0pEq1O5EPxEPXCil7xud15BVydV3lKPO3B1Nb60JHLmsHcbaxj71Fj0VVsm5OvddIzqXIBDSpQTDEy8tJ/4IO/0PsR5AZG+FK8ADfMO5/633Z55zvfKc8//7x8z/d8j/ypP/Wn5Lu+67vufO9/B0rwN02gxXsFg+Q8ets9+clPfkZEcsuuq3NtQYjnABjr1kI9rt+XmaWeiYT36w0atywwCQcFoy7MoGjNBKlGh++Mfq/MHc0HBC+a7cB7QMZTn9mmIkQZ9DMdlDHAVWIhIZjfXmAvK8qUuP5ToDz0fWzitbR8eA0BLvqGRU25CSSD+YiKoGPhU8QzQmVKNCLSA/p5f7zcco/Iiw6/jwftPIfmGmvwQveEramw0DvnaFDhtpcSTO+ZgfJQ6+yVco0PLOqvPsPCV1wj85B3eWSJofNCqMDnEvwiNU+9tVUi3ejjo712BDVEhhoEl91I7tCOlg4NHRZ6ttQXyPUtRyXGOsC2OLWUdiGgLtbV+S2yL3iTHL6ufXW1A8MZ1oOwMnPCbbleXbjNuEoQDlWQIQUUPOaj35dECcWQavhtj4bz9dG7YQGcAwqq5U8D0l0ZzfXzk1oCdxjnYKk/kXCdKXXEC+h237j3aswjuyhhv5yytYBPvd5vQrTvr1ofe3PEOKtldOyDz736sI8ZLc7gNoOuVXtZSaz/+oz2gyA3Tk5jt5HWnNzPPvXLaenKpiry+Cue6vVfVL/OiwQ6lxWll3X0KXU3pH3oUs2h6xGe39leaHM8oSQHoRPODGXR/wVBC9YTlsxS/1pb5f43PC9vxBwGYxg5D4jKIa2ru+jNPXHv3kWaqlIk8alfPHTf0KO8hhN+SgQVMfEFG3+RzElZfDo5RB45XgBa4UB5e+4wIhj08wB+X6vrgym64Z1jxgftSvaMlsfnc3flwzOhliSz1IHBjJX21b8zLS5Qnkw+ymbthvU8+et5Pz6ic1gf9zn81d/4nCxLDefBbylQXi1xTm9J+R2x1IuIfOQjH5H3v//98kM/9EMiIvKv/Cv/irz3ve+Vb/mWb5EPf/jD8n3f933y4osvyp/5M3/md6oLf6BKtOT61TwDnIhpyZXpuMBAFGXWdTOUfAsR8oMG7rwFRslpSk81WuBWzyAe+dRrRE4tF0xEM8i3eA2lt9RPYrFtzeB3bKkPQoV+P2BpIkUsfReMuwFjUAcH34niYvO+naOlfg81wcwZ9s8+FLBWwO3r1mQgvibcTuZ79tHvIWXTcyf55MUqL1C070pCvptH6KsTWCtcI/PHmt0ts9SX0c/B6A3EJTLbrXCKwmLQ5Kik2mfg9cuuPZ/1G7NYvC88rlF2HeA4FHaPyI7VxVtZRMQJgiKSRr/nec+sYqnvswreyuCAZbGWPGLx+V6VL1xf9TVwADU01CsxY0cRwnWvddoF7gHc93UTRFGimw5ahtT6YLm4awJhzV4DKg5ACEY6wvOZjW3bNltCdSmynWPU9gxqKTIFa7Y0ttkl65dIVNJk0Y+PSq+3r1+11Kfw+4P3FxjQ5pVQzDyi//tr73hGfu5Tn837FoTWzQAPe5b6MhhORofNOm4+J6xOF/gLI8YrHdP9s2+l43K1rrJIPK/SuBZF5De/4iQf+tTn7BqaT89VRV1w4ZgDr3z2vlZifxCSrDVw/BcU0qcQP39160kShj9DdcDPXZkcIcHXJ9/IFcLvcc3S/ilKmos4lFWn5Z6HQleaeXZP8cX51Nui4T2nSrz+3YkCdKYIPKrDlOOXVX5meSRvffTI18EV2tmEdLhL4194qklbqvzqw9dDm6EyPSMF3+GgWKWfBR5CfwpoFnWVzIThzFJ/FDC3STxHAt1275WJpxiPxtN+tEdPF4sh87Io/trOo7fdk499vu+jzM0Nn+nvpv9jFIWIhAj52kcO3KilNQmCbykluEmhK4zewwaz7VTkwde/ID/+kY91oZ55s8TltjUxhSC6Mlrf06DNtEdHUX5O99RrbzyWtyeIgewMas2/ay0aw+HOp36nfNd3fZf8lb/yV0Sk56x///vfLx/60IfkhRdekL/0l/6SfPu3f7s8//zzdj/63n/f932fvPvd75av+Zqv+VJ05Q9swc2ZplHZy9Mq0TKiJC4G60mICmuhOU0YwphED1DcXDcRCc1r7Q9G+7iXDomEK1ZQOCZJBX/1KafxanqoiFwYHw4EtixYEQv1OocW2IU0jBz9PoXAohCJl3vMhaCVpcx5hkcWsIhU0Ky//o5n5XVZ5cWFLPUk5G+tdQbVBBJVnuwf1GkZ492DmiH0VQRS2j13ktff8ax8/PXOsHRf10XUNzDLeatz5w4iVIScRx3ad0UhjOskdqKD9Ev27mQubztUcZAlS9/WpgKpKASyuGd2/bCxntUzsg4hMj6jlaGoRbt4Yey1r31e/t4nPinfuAyf+iH8T/cKrUAVOyjEthhI6DwFX1VKNhE3j1nmBUyVp1ZvERLqKU+9FG/9xGa4ZNGtTUCo1eWTnpZaX9v5vM2Tt8wggF3Y1bGRUiNY6qmQsD0t9f4erjeijUpYMFpHLUVW8dYfppVZX8J5JJ7HQ9oi4s+j83MX8snX3gjD7YpKgHGLtoHrSmwswVJPSl/r9xHkmplN8qU1JRELviF/8v4aOg+3miMaab77tcj1RZHPvP7Q3TsD5s165/6QoaDxY1Ehqlxv0i6qfPQzX/RjGWcZwllFEgRbIqk315F5JnZa1wKtS1FIMPboi60RTWZBmlWX6etudNqE1nnm6WuxewIvM3ksC/oKQn1JAseKZOiPA0v9zvZ2GTOUhl5UWYvIa9fXhygWrRdRBAHJEwywRW+10mTSDzuv6nTV2IPfW79HgLOrIdRnkdW1sAvO7BLR/FQL4ktAAuKWL0W2de3CX5m8017QXJGB+hrnXDco+HGoMvnR25+S/+jln5O3CCFYJSpptjO1V8hSf6qRxvIzVOpSxaJSj3bOGUQdNHdYjcarun6u04b/5w//Q/kfPPvWsNbQUq8Zr/g9YWniXQv6ump7t4fo9yIiclFFHvk7GS3WxwayAo1N3+FtK18Sof5Hf/RH5eMf/7i8/PLL0lqTd73rXfIDP/ADNwbIe/755+Uv/sW/KN///d8v/9a/9W99KbryB7Y0khyYkcbI5sgIiZBQD4xw8GfySj4HR9PvHMMqEbLGfp71BhiN5rXegJnA84d9sWb6Mi+gplYdIogKv9fWHfx+azF3tAr9rROPRgIc+nlbuxBspw5e5Ez1hjRjxORo/7HvKVUX/643hkk1WDHVa+GLAMNRfB5mq5vh9ySwGjSX4PccRGtaP6HTRNpd4EcaKkfSVYbg6oUOk/ulz31RROaamJZDYhAS6LRrsIict1XQqf4Mih+3JuDxPp/NFFpsuRIRWBORmVLlGD5j1n/d0KwIEJnuBW5eqV6Ci27bJm3RfdAGgwMCBfu30pqoNVoDGMYq2n+4RouX7YFlPjSVGLNmnhOvDJsWExHvPoKB8tbLKj//wiZf++nPSSjJlkp9c4sy9UU2h6gooZ9zrKNfdTCVwapKa9MCMnphFeHEWaRfphuBqUvScnLxQhjtX9rj1n9eA7TfnNWEIasa7Z47kpE4EBhdcCu6zazq4/fH1weWeusKpZrSJqmfIiNwaO2xPRziSKJS58jdaJ5X+C4xonRzaSVdsXeeDm0o/nNioJb6er3JelHlNz//wFXGdGoq/tlSD/0w5UIUau225NwKllM4DypkqhCBtUMCD8Lvy2mBAGp6IsZ2ES3TShMCR0VLvejenoifGaNkzlvmOqdtXRD9bHnX6PzT91/gDz1khFZs/tbkDHXuBCV5nup0LnrUNuepv3fvFAT302mRq8dnqafMF91b+Xf7AYWVw43XE5ydBbW81rBa6onfgMjyjIZUhcT5vAa3RFN0wyMaVBr75I0hZaJomrZXnI94WYrPLCVe+ZUhNnu/oB06m1l5wUUNZvW63/D4+jzGxsJ05ssuLmOKKzVHr+FYesDYcftA0jn3wYubjYFHlnoNzHgHv98pDx48kJ/92Z9NrfJPUl544YUvRTf+QJcgoCQwwnGnBRXRolCo/sxMWRSg44lgmabeOs1nUCCvpTg4qIi4A3rW6wnRbyfI0gYCuUjs+wqRzuuwys4gMJNhGQ3OsWE/E2oY3gMwmSqMme/esGayJv98Xl09W/MQRhQMjxjD0SEROyT2YaClYGRbkdqEDt0arArlVGXbztaLHvQLGH5CfBgjAT1soHDy0aBdS94fcOeQ1TLhWv0ZDZ6DEZDXdUuUNKA8QSZHdRtBYJ37ylAI9l6KzUAbDbBA68Y5bjSEAKzxVopF1Mayl/ZJK+aAz+xTj766+tM2LP/6GZEW0kTKQaA8EZnBeKA/R5Z6LdfnVZRwtOzQB8iqdjjN5oCvD8Z7cnnqy/iuyvXzXUHzD3/lN1z/Uj4HmbPkhlKiAC9CihNVpJgiQAPlaRNKa3YC2gWlzxTS8lgNfgBBwGQ8tQ4kqaOWqUfqtcU9rs+vLoBmRB85+WEnpZ21vyNgMArBMYYMlSfL3yNNo8qMIfZbSFEi+3Ua+mOZAT85pdZsg+YcUDbmq76jxLU2BOaF97UTvOd68fPjn+XsAGda5/yejUfAjBNainvU29DhvSWoXOcGNh+ZtJhpvZSBuLny9VyDoLGcaq6Mw04WOqeaog6nPwfCnUvCE1TNfuEimGbojzlhNSCEMsLi6XRQ6pBA7s//+TGz9ht8fQ8BRB1xPFLT6Pf9V05ph/B7jZKPcU0444WhAKqkvtuoQNUvAnqP9wKMMQ0gVhRN6uNSOGUV1bmclt6/x0nAv0TRvT11kuWhz8bgFZzdCo/koMkwQuirPtVEMbDJdvD+6skHk+tnc3PKcj4PcmXrvCeLAdGReYMHXCKkvRRPw1ulLDGs5LD/Zr+5Xd43IjuuhCb2NLdP1BjIMZJuQ/mSCPUvvfSSpbX7rZT3ve998mM/9mPyrd/6rV+KbvyBLkd+u6XMwydjVtXKsG0awAkYC9hc7M8UfL2LRwi0QHj0Pt920PwRIXKbU+uBzamHQxNAHRCVZ/j6zHsN41sVBj/6MZQcWhVDV60FmHp8D2ipL6Pj24rwe23Ha+FDnnoKZqLf4TCfJFBeJmxpRHbNQ2xjEEy3UwLEXQfQ4cYqoAillBnjI8EXGZ8mLQpChfLUl3wOrBscPGkoqRR5phruuScGg+aMiZgRoRHvMA8sfzSjT/0cD153yWeOn6HIxkSYpT6PXXpOnvGoEHqgzHdR8Es3rBiksAeenvO1CFuWBT6XAI0rHHCOhe+i7fh5W0GoFwo4NwMDygzcxUoqY55RYpjtuTz15lO/SE4R90vqKqKMVy2SGOqDi0Nn4KZ1b0IgZ9DOlSzGTDMyocTvGX0Pc39K4YCExdBJE0kSx8aWegwoZrSSLfXYf31/O0qozmDFdFaz25G4qdiKCy0LBKaFfcYfjVzLOGep21oS8Vy7gwg3dd9AK53OyLrROWpz5c8k/IYttuc1mbsdBZSrA/qMkepZCLi8vHBjs2Wlwrv2XRUGoCjF99pgLLFH2i9YtOZzMr9idzv8WXkVu665ZdRZ6muyf2h82C9FwzAP5fLLm3ISzu5lKLOIrKRub62PMROSMoqEikFDc6FQf8PzIolPvcC7CPQjqQeUC7iOZvR7H7C2w+/J5QloMAe3VWHw/je+KP/xP/1IarDg/uwqa+ZAveA79lVpY/4qB2bsf2b8CaA/cJZUGAfyHpmlfn128UI90Zlai2xXW6Cz67rOIzFJv7ZCv9NQPKcqmPWtlNKRhka2Sti/biuaMO15q6AIdb7/s849S30rxaFTVZG3AyJK93iWxjGLwo88YwVtgY6NFYi3oXxJhPrfrlD+L/6L/6I8ePBA/u1/+9/+UnTjD3Thg6MdCNtIAK+fO8ln7r/uAo2Z8WZrjgDcZKlvwsydCuQDOppI9VlgMKc9HNFJnZgXLPUQzONXf4Nq84dQfxwEOOgDB4pbhw/2cLe6WatXChx243rzB8O6zbRnmaVec2c6ZlMy+D0dZnsFHgt+y8A5ljKJs80LWeozAW67QvhhdYy1MkUbvX9klrYCyEm2IkEJqZPEup77WS7VtDPn0T6mtFvXzSkgRDTASzKvKtRXFctmYVi0MlozcA2gKpLxa1EAYAqtLZ55tGca+BRXiiJdi7nL7DE8dak+BoZ4S5H2myP1YhvBogI5tK2ehJmcSJN+7XLMcuodAZggDJKVQc1p5r0w6FLaGfx+9p2zh9wIg4WNbrxIVWbFzwkqfoxGljlPaMWeypUpFJfKMFO8E/qWmMJZBxGyopBPfSYQ6Lzz/i1lzlvw1QfEll6zkGkf2Z+W6IymqQtWOuowZvOIlnrP6nCaOa3zOFCev9tnA1HBJvHvhsCIIh75wsUJzfCqkflEtyj/d3Ywe49ppPpRME1Xb9//rpe6LvVa45D4QgIjlRl4ETuvT2ZKfB/wsi5dOXp+pvf5dFpCH84g1Few1MugmFPxML+/KZI6GjGmpR5oW51+zzgqVuKusKZCLI8mqZC+OcXqRA+ExvQJ/amNk6UwHfZPhJgsO5wF0j/tqtZVA/z+wiz3Ex3Vr4NQf1rkGp69/+ixvCWMqoT3zHFjUoUIG0Dwx0HD5rExeBZ4R1ksjXmWcIT4EiOzs4tF8XRG0W2scFvXNiW0JcZr8PE+4vsqCYpuW7fpPVgkpEvmQHl1KW4prAm/fgZXOQsWyew6PqaunhikGZW+xatxJyIQ9sCgAa4fjLxcPT9XYP30rCG3M6Xdl0So/87v/M7f1nPf8i3fcqPf/V158oIRV32+zmbQYuZVX3/Hs/K+v/mP5A8BM55CAOlQUKtGSGmHAsAy/OE3T3hwM5ZM80dw3XVrFNV6flZr4XrZ+/9jP/ur8hZsgzXS45mZ0g4YQGJa2d/UM66TMfDCgAoHRaQ0zwCLOEv9kghwSxrlNFpdgsXQMXTAEMKayHKlWi1KWKEh9hmNQX384VRrcYKyzSO//2GlMIEoYzDou752/ftC5UOliMh1qdNSv6pQP5QWKkh5/dOwEGEf/PupS5XWKDfqk8AXzQpfZANFD45BP2R7pCXvzqod0ifPWUGBDcboLpdia80sclt8f9q2VzqU4AstIh56Oh46tNSPr12Qm6oKqNlW/32fHolQ3t5EADMrUQKV3pHhXeHUYqwsUWWhSuN655nQECsxdBvC7wcHhG5Ms96o9HGBzDI0B1nqmV4HXVHg9sUzjg59VKz2mEKVxkj0qkBbuyntmAaECrporzRkUx/KRHtgQmvRupq7tn6DNqcJI4RIAIW0SEp/OvKMhEES6tNsMNqv5Ozt/ZjXCwSrxJKL0LMRDKZr6QnHr5cXgMmFftgYTDlO358TZQ3V7QkTCWLE8M9sN+MeE/570X386O1PyeMvvyc/+WufSFK6+dSjZYH9w5scXi1Htvf8T3FrIYPfl1qkabvwaOSjpoJyIffDxhdlPqOFBTgWmhrXM0oWHBj7dSMBLKT4H1K91nVaPPz+EuD3uj+O4PdpQDRCcQSa4M5fWizjmQyiXnQM1VuJdd5SJfr4y6iv1KDg+h0nFpV2MxWiP7vc+1qKoxttoOxYGYyF/dA5pZ3SNzpWodvxfH/U1sivo4BuyAcYum302fcVDYZ1IvFw/DYOm1NQ1CWIRg/pT7IaoNwwlDG3Mfp9jvW8K7/vyqGlfqzmI+suMot6KIQDnGCIWaA8B9Ud2sXpmh6F2NRSf/YHJQao6TQCiPMgPA5GV2cjnrkdbZ5qnqpIiala6slx3VkPdzioNk47pWNs+W0NUtoxjG70LWgPiwTr7h40jIvqJptIzJXaPBzTxS5ozUUHz3zFQqC8WpyQgBBNbUPbtT64QWlFkdHZEmumFs55q3EWFKp9rcI87ZGjNHGuDRU+Ej8/i35f6F67BuXDELx34ffNC83YPuetF/H7k5m0UmqYL16ytVZb63oP8P1mxXeKm4CSIavq4tcjCyR2H9Eix8CcljR9D1rqQ70ksBbxc4LQUGUIsO8qGM7r3KbJqIP+XH8wE177M6rAAEFAp0mtNMDQcZ53Dx9mrjauJf+7/8gW6hAjIKEjTpkGMnMFupTl4sb+r6iZbDB3EmmLpbMi5V1K41B4OlC4sE/9XtRs9n/mgIVYMEf8a2WV//S//mcpnDrEMchcOEZh4WL2Y7UfZlrJ4/nhOliJi0WVHi4VoiAtoDNRv+dI11CHjWVnyWooSyT7pYhj8PU+LXUpnW4NJf4vfuJzQzj0jeAZWmqNKWB1z2K/2FIv8b0xjB8Vp+az3GuzdnL0R/8urpdsbXj6fxP8fq+6BorUwuMPEOm8Kh3LNohxLdOn3nzNR7mAQHkaC0RpbjcSzEYuLk/p3jksQH94v2NJIfowL25Nj48rBsqjOpfT4pQVbFCI/t/7ioZef2KpL8RvLhF+fxRDpPeTeQIOYNrX/HQ9aE4AZ2WriMh18+cinym1+n5q0L+gPGX4/cbPzH5gLAZrZynhxWTueMbzNT9Hmq2EIfq3odwJ9bekcJqhLBJyiFQLi3xqTed3+4Lk+H2NOegzC82EX8d+lyRQnovQXKMFGRlbYwihmvPTp8jgQDerpp5BIirxOJ2MNTDjWh98jwgJZM6d8mGcJAjhm9A7FD4i8e799+83vJudz3gRGPogFDVXLxL0pdYIteaUdsUHOQqWenNzaLb2cEUaKddm4MDKrL2zn8UdnHawjkeu1bpg/Fz/4NLMFA8lLQgBG/3pbcx2mkyGIFhP8D4V2EvfE1lKML1K89TvKAJ6sKJ5j3ukRmGSD8EKTKgJ/tBOENgauWSURKi3NgZjwLBBUuxkSqm65P7yHKM4DYwDzxRgUJalmlLGQ6XzgsI6dsQFDfTLIax/E4jAp773O9JIVVjofMRYJcRgxq5NBAz8zqoJ178nYIqbeCG+FHEuRS0T9phpq16J2scBtJHh95eJxS4rDp1EcEsWWskSndUhIiElJSo6A29eizH0n2jX8r6/9neHpZ7r4DPSo2MadIt91q1fGV0+kOVAi0xjaWOdzfu2JdnHRFf2+sUCeH9Gz9PILDdYM0O6tN9qqcLKOZFBd1VwHArc5arf89kHb6R+vtec0u4G32tN2de7P877RPlimVyMjsGwF08ftPiz2ivPWWjaO+ZcQL697Ac6FlxQoFhZmXZhP7O6Ehrj3I+a53OWE+Wav1gC/B4t9YzOOaLHWX+Qz93bChh53p+tYz0Xn5lDp+MoKjy6cmUGhTCOZK1xnnrrQ5tryyl2+UwUVjLFGShEsFx2htEvzu6RGczY2s/oCQ4WORWQM0ZM4K3Zqg6pMetoW7tiLg3YbKIASt0p4RqnAxXJt82v/k6ovyXFBcrLmDWZWjqm5yITkupgv0R4EIbYxu9RMOT8sJsdVEZ4nFBeg1bYWapJi2ePg4C2nLwPU4NVbQIQjQWtYyH4lD6TRfbHepOz1ZhzssoORF9HLjQV6jOBpkZ/TzoEBBnrPSafCxFfkWGpt+fHPO8I9TVh/IIVopLbR/PafWOE4G05vslJZOLWc5aOZ/YtQuCQubiiSOJarZ9nGP9gVnhd5gy7RyFk8nOj9Y97k9M+Vcjvbs8XZjD1Gdd937eSZEggRr+AwG3CJLDiarXnFGxWXS0BvWB7Dw7kzCq6hc5BWWpUuCjUEASCaAGjtDhoRVqqh91LtxrdtG1Cv5OAZfau6g2CgNaxbbZASqE0Q6MuXO84h+aeoT/CnsEzoPHP/ZaoCDlQDmqHfACn2ZcCdIkZo6i44JR28969lHYml2TMtTKK8FtzyCN/+yX5jKeWelJGiCidHeMlgoAZQXRpBn9a2Yk3QO3iRsBlrjeg8o0ttTuyR5ifLC5JO1V58A0vyF/7uz/lvuf5UboeU7QepLTbe287iqRlKE07gizuMxG1jBYpY8985sHrQYhS9yorS4RgZ7IsIxFdAEDdlyTU+7HB3kChPnFN0XeTWqcTvmLW0eCsORDuszqQjh9Z93fLDEY5WUEfKA95BIRvZz71qCC+HPB7XjIBMcA8GiMhw7Cy86e4BbBtDfaS0rPo7qelR/mfCmJ3JpYS+AQWrmv1LniTH/VDdIIvocCaNI8sTF5nrdEN4Mjar/VYnYmlnsfCqDJzbbX6koVIdLYUUqKAQeX8zCL/7S9+PKIfyNdfJKKq2BiIigJNaSfyBLGyfp+VO6H+lpTmTnBkvGZAiSNtddB8FX8oo7W0QH2eCSoRdrluE/bFTLBIbqnHTVbFtHhT/ixmszMI8C7xb/D/qHLZg9/7SuwwoAN9r3RmDOY4YWC2DVLaLVGAUx/NWK9vK1Pa4P3ZRQq/14uyb6lv4hlYK9UT1lJKgLiLJEI9W4PpXRVeiuMQtLmkk5sZhFK6sBkZAv9FsAZnawKeC35cZTJK7AvvLPXjby1FBA70Cieo3WNCsT8FnWCgz7QZYZYDHfU580o87lAFpAWuz3AAo6KOhPpTYKiJaWYXDWWeqF2XXzi1SmzGCM/vPNONMRGs7qLMZF8j21Lkk+crWbet9x3m0o1jRyDBoEvg5TPGxsFE+2eOu+AEoZrDKL2yLIHf28TNvqlCUWDcPIDA+AT4fc7slzbdR0xJJfOzW0ekiFXkBZ8n9rnmaUm1II3K+qW/rWtmGxZ59LZ78tFPf7HXReuP39ZGTGBuiR7jQqZ3fHc6xU6yBcnebfPrFwunb0TGebpF+b3G+5b7nAXWUhj7yx/6qHuOYw5YWtBgqR9qQDgrp/jp67CxOSXR/F4t8hy8C8tC8VMeXZ0DDRLh6Pd1V5GAXYvK1/mbCVrbvlBv8TGwzhJpCyofFxaSshWM77/twO+hGlcHtM3+/75doTry4rIojb5MxekiHJWcfepPB5Z6NhpkEc5dKUBbM236uGeXdooaHdDtcI4T6RwWjn6/LLPf19uWxh5yl+AO0n/WGE/zOihgyR9eZFjZDyz1nC7a3KCgHCGoND889j/GYiiynmEsiw+WXJJnuB8hUB6Uh1/xlPwHP/rfBkVJ6raLLooFeIZsbGXyLrctWN6dUH9LCgtTc7PP7+YijwSwXURIn4cIeQFVf8H8qZwSqBr8flxnhIfgPE0mXLp3sQzrtsB3/vnO5OTMqNHq5vtlRLTlyoY+fl9HZkGHP47h7fBtH/m8HyBTcJ6W+tnwsuS5MxnCx1H13RyCoIxpRc6Zb2ebj690uGlKu6u3XspP/fonkkjnNB01oircoarwe0IdzI7PviJ3WIqHeTI6IUTSvVhyCwi1GbIBUNAYvr+SEgO11Ly2LRBVEVsUHFOgIgM81mLGePAB757ZYZxLYqm39a3fw/ua3Y8TgIo67F8Gv9/o3XRXl7h5D+HkAX6v11Gg4Gvn/gKkxQJsfcU9+fnHr8l/8Df/iWMaI1Pbwpxiv0WAMbYtSMGMxl+G37dCzziLSzEBTOC7CLMsrk4RVfKosHqDcGDPuCGkY2ZhB4WyvWCYfp524PcwB4j40EB5bD1zfbK+zt880mb041Tk0dufkv/Lf/x33fOssNXPjswO5jNGmB5zX4sxzvpYJVcwkeiaENEccdKDEhdod4bwSgsc1E1k+M/uNknt+w7sWepjatj5XvcEcwU/cBfm2uE0W9MaXJfoBlY4EnaJAiwrX6d2cc6lZenRfqKlXr8L9VC7zDRIRBSpm1eRJ4ffI38XhUZSTqVnmFc4HgZ23StAlzDo8nw3Ucmr1lCllXqNEHYRgN9Dt3icnW56AbPBWap95MJpW8cArE7cW/aeyXKMFXB8Fv18/dxJ/sOf/nn53BuPvOGKeYNTce9I+WQby0CsuDOQFEZNVDk8aXHYT4wYKEkdhM5kupxa6mnNn2mvscAeeZMqZAsk6z6QripyvW4j/gK8+wTh62OXdAW2Q0TA/YjuvMlY9/ut3An1t6Tswu9LCQdSYPJFZoArLcUf4F27qD+VwLCa5p83+LrZQZAdhCWxfro89brhGxIvT9gzn7q94Dwi6mM3fXSf9HwLFnQbjjt+rd8CAt10E5952U9J+q/gTzwqc8wUvl/4Li/zuWD9FGSYk+j3ajGrRf763/+ZJOCLvy57UOvW3x9CvI9KKX1uC7xzPMC49Oj3sy8Xl6cb0Bu95Jb6yADYez5RSp0EvYKwante+zkORI4e3u9p4TlsP/P7Qp/6LPp9cNGYQx39qU4pJzIh93izU9ThIV8SppSYq0JxF+w+mAPXAZEu1LPCZVjvUEkVmGXOw10QGtqFAX3++//zf+wD5VEXdwWSg4A+UiS47OAzle+HcbAlcSVmxJS0LNCZEO/77IS3XQEjUcJxKXNt1lqkISMtc7+voBxq1I7FdwCNoQNmAIPlgzN5gZn7xT+mVvWdkt8X95BTRtA+QrcBW5YUtI3nQgTWCJzX3A3uZBbXIig9HM0ZdMjVgdkhSto03ot16nrcaI1xhhh8xvnOw9jYncOQUGO/xjRb8/NitB7GGqx2xRsGlrKLbANOwgSNFLk3PqoAM63lKGggTUJBkc5u859uLlp8v3lqO7CvLnVe1j+sAh+Gpn0d7u6IVNqx9nv4fZNSIfr9Kaa95YwjaKnHsyQLlBetscRvlBJiYFhPYe0pUsadrap7KYpY1PXd3Diz4qLfn2ae+m0Yxt64vvZ9DcYPH2em1OL8vzMa2moeEwndssJsJTx9Fkdpz8aS5Ycv1S2pnn6W46dkrpJoJV+8coERUZ6X6Xv3SSz1PKeOZ2z+/Xe33b5Wb1sE/Duh/paUQJSVCYSdwPnPcZNsp3hQ8L2O8RyfMd0VWyGK+tSPPVOTDZ5p/hA6J3DIF31UD9inFvkvfvwjO3AnZSziWExzP75MI47boOaz55VhOswYQZ566cxKJsBZoLwEfl93A+X56z0fQf3c8GKn/w18eyezMX/nef30F17zz4dpL/EwhINEp9lFyIcueii5q9gFdOHf9ZBdL6o8/Ip78t/+/Cuj73ssay/B13VXwzzec61hrbKvc8aQKUxeU4I5hRst0CwjAguwm2SLOlnjQXDWBa2NFVD0DcYkMHcwT61Na9pS5G9/+pPyT3/lN9z9G015rRwob9wX4PfuoQRaH30OI1SaLHxws2rmyxjvum4ORcHgv1DP+DCh0/N9Ti1JCfvQjbXMeviVCK3tEHA0Y0yxFBC+3T3FzXEMQHjwHvQ7ZeAVRdDmeFJLPTDSvf81MI8ui0LpFr6tijz4o8/Kz/zKJ6x/2n7TBrHzeKUuOqwc25ELUku90B7SNZXQnevnTvKRj34qwO9jejVPV1oy52k/QEnPMTUswOreWZ3UJ8VDincf5PkZRTNhxEB5fV+6LH50bnJn1JWu4D2teSRX80/rUFNBgyDCUpK4PKTMyNLRBp/6ZC8EZFag0z5GCQtSKqzpNyFPveS6nqNAebyaHO1CoT5Li4dHyc5ecQKw1dFMULJ3s0SEnMHvTQjG6PcjUNlS5P/zt/+pvHF17fqQ7SXmSS0IMx+8cGNIqevovneHsuj+kNUB5Uc1Iu2ltBOJPC0a1vR3jvHkXLDGww4hV32aRuVXlMz2o4hoYqkBMcDbPUPF8FjdMwm/vro4WqQ8Gnywq2KplLZ6GC0IjSpFLFVrmOOEvwsGRQp26Cz1oDy+s9TflTdl8VasqVFH5olzQ2PZxkrQKhrdpUxTrxMZVn/IhVQdWwsMKW5d1ri1EiNfr0h4SjHG8eotF/K3fvznZcuCJduZNYg37O6FA5PsMIA2F8q4nun4TA5Biy5MzFFxc9acgOS0mJgSBBhPttSHNBzQl8wK1UqSzkS8lQc1v0UkQOk+/NFP0/Me9pil9FImpo9N379ncuKC9AxHIaLPt6vW/+rLLuXxVzwl/7v/x98MUL4mkUlzbg5FdhUH+lxcq9nYxr3wbh18uaDCDfcbtUtMapZ2ZwPGP1OE7PmRmgJhAWFRf2KfevGaeFNEXVS5bk0+ff911+xGjdVkTYhIYGD8iUs349ptzZiT4HeOgqMxnL3e02kJMREKrm9aiK1JWGjcpu7p8O6wSsFAeQnlNZoIdKNkCgsdphdKgkGteVrDwwjZKgIdSfpIiiv042yOCQbEVmKp91YTaHIwWOvTJzk/tcj//t/7L6j5hKAl40cmbi5Dz6RqSdPKBXquyt/I3L/+jmflO973N4Klnv2AG6//UlKIdugH9WVatlpQJOyiE4pvQ88dnv/40Fx/+vh5CKLsOrVC1GqRwYTT2ceCGNJYLxOXIGSZhW10eDnVMMdZzmpOi7vne+zI1Y6CFstMYZrcA+/a7blEEaLlRGPZHOGZe927NXpjQIA4u+aAhwAUQaBVbX85YlGBzVz3QJg8Za4RpIDIfOrPz57kH/zsr8uvfeaLnjc8CCKode/ud91iMHeppV4v8UyVfV4ALfQiXjjk7DpZn0W6QOqFzcmPliagFGjhHiwczI+Xa7Bms/sgjxPownqvygd/8ZUQkI5j92gQW/vd8a/A89N7i8owxIyWsH9YuVCSQHlBER5QCMX9fudTf1fe1CUIU4kwua6dYc8Yno1hncRYVLI6a2H4PQpsCrNxQg22IYMwuw1OMKPiN2eRKPhk/jU2D8l3DBEKjLI+R3WurBRJznXH4BcBTerkZszHNoEQpdHvxTO2TlDOeHBk5Ynp5f63SUldRgBpEqCBv0BCfTisUBiZEwGKjsEwZgz1eKZovSXWsSc81cWnPGkt8ccDKBpHMtbBbO4wit0rBPvEdcRr2zOP411RTAHcU8pV7TGUWZ56J9BxX4GJC/IPMCsziJt2g8TA4qGIN+VIVnbcGJzMnUQS6zWUCKclvz3tV2Kpx7Hpfetllc/cfz2kxUGmh33oh3w82xsF3RXYYhbGooxiaqkv1k8RIQYyutvsBdZy6TTduprfOwZpy4WddLBa7/g4rfCjHZnzZHFC9B4nyNbD1EnKGCNUHOMO7AobMLbJxNF6htvxfW9tZ8COgVVobmzX6jShXvd4DedZQL+gtVPrC1b34t4J1lFJkbDnluS7WpxPvc5/DNA3/u5MDxvTOD0fPpTV0UTXaXfBMCWA0lxeO/S8Rr/HEhS4JU+LK0J7UNy0B2t+hoQwfidFVOUojDBnuk5bogTy2372Degfx1Tgt4+0Kyh1xndPAuHP6nCB8mS6TIh0lCHD7z/zyfsiIvIn/4Wv7X0HC3cQ2kF5I6JzzNd4ewn73X6DT/OMTsbpzr2537fzFurukO3Z//1xiH95zK+wm+IQaoPyFGlRLW5Ndx5wm+uNYlOJ6NqCmcjGT3tN3+WrX/u8/I0f/4hct43qKGFsRznnK8+FxPeqdMTNd8HfWkBtZPG5fArA6urkvqPr1J2l/q68SYsX+pw1ZXyvMBlj8vFAS6LQu1Ix6NvOIccb/ol86n273aLsfep1c3KaKu3/UVoYlJmsW0tx2rkU0kqMSB+rV2owg9Tb8acyhiZsdE9GvOsyLaPIKIWDO5Pikv4XuI7peACOVYaFBIj8afEH9KOrs+9DEADyiOusKUcSymInvl/tXSlesORmp5+l/84paaqEOToTBEyVGkX8mpiWejpYlgrKFc8tuudbH1stwycZFD2TMfeC4lFKu5lTt7m4A+GwDUyq/pmMwHxfc02HgJEEA8S6WKBg7wu21DMTldGiFtZyZBy4X6XEayld5//q1z0vf+nf/y+CFalC8B3eT44ZgM2EfsI25/jqHd3o9x5FzOb5MBQUWpjRlUJTQ9jvkwo5oV6S/ULrCIVFrk3g2pSygxnLcsGHPe7csIps5wln1THZ59L9G7Ht89OLn5u942lqQ3bfmRZkvvfg964Un8Oa6b6IREs9Rb+PlvoYTM0JUDoWEe8Pv86bT4sfW8vGkVzPc3RXlrPn9hSv3iqPFrYojaYICyEXNfdL/yYw49LPhO1U5MHDx3l6KyocZCwEO1SlGtI9clnMes8xSDzkxKd71A9+HtRNqBe21KNyMVM4iKBwG9e4SL5fmkiexUTfNxoCxI+9wB5zeerHef1lb3tORET+uT/+leHd/C/e8z+Sd/9P/6T8b/4P/2ofbxYoLxmviEQ/6gTmzi5mE8E097czrEB7OM5wjrnI6Xqme2Fe+xTHQZB1OhecMlXm+g3GLxorC58rBtcLu0miNbtQR6SvlSPUJ/P0Kb9OriHrOZ7Vrg6Oys+GO2xynFEpAoTeI5//68pC/by/Lnc+9XflTV5cOidg1pDBC1HVS/LZ/UXGSxxzo02ZfzgIKPMZin6fhChl66eUQrBoCCRVxoZnq2jiU8cCtGNykdFqOQyeI62KgIUdDmx/7cdeZE+50khbPp9blsWlCNG+aGAdvX9aSCID0nYudF69cgUYx80fbcHaLbFfWAoofuaX0afNW539AwXn3Yg857me72u9rPLgjceB6LPFANX09h5oP7hsAIIH/viODyMIAsdMEi51Y/jHaYUCHENUS76YQtRakWgBcn1DKwbUgxV0v7PRN9kvLkjXzLlHNw0BFidQdK8lyBOGRLoTN/ZhBaFGb/XZOSgwTok8TND2LzOYYhBmAbEwl473mQ3vKmGasO+T8fR0VdvvS7/k73IPmdPiR+c7WWa72H8RooNwP3+BrgFN/Nmiz3iXImIES4TG6zjPT1X5sZ/8peg/C+fCXk55HLQF02RhHeYa29BxO1IZ5t3TxEwQTuH3dK5yG8E6xnBU7P+4cNYv8qlPZefxu/epztK45o9ae/Q7N7WetyAUMPw+zEdrbh9r0RgVjVEd40x48PUvyHf99b8jlRS2AalXGO0XlVfwU7gnYVPCumHEjPZzvicwPpDCAwN6hpSgTpkxK0ZIM8PvueBI8f1j9puJrISHkr3vriAGSxMxF6Xnnn9aREReeMsz4Rz+7/8Pv0H+t/+nf10u712IiDhLd4gpxL7oSUo25rFCMFiiCyLoGsTjA/6QzlIfVNIanP1X5QRa6nFPUT95HFkGIESwRP67pPscEShBF54gGzKFxkZCuXvmJhRCpTTWFBg3o5lsHJESs7JMZVsBSz3MB8Wv6XVgPyhttcz3cPXihfxf/5O/Z8qUO6H+rrw5S7P/HKwXtX4zqF1kpI0RHN+Fg7NUp4XW+s0KNQiuo42VLB16kCBjnQTeCAcy+tghYVKhOqPWjlCK6xgH79LnGxErLcHiZvM3brX7nNztIkXjWaN+zFlKuz1L/UZjQK2ma0CIiQDuflrqYZwwFm+pb2Femf9v1C5CrxzKQNfiqC/4h/MByAdH4UB586dXv+55+Tf/yl8PRJ8hmThULZxaCtfZXvR6DmrIAk6eEUHcPWhdYIZ4L1VSjE7stnw61jQgFzzjLPXM5EE9HLBHZI6z0V5YqYZSaphnkURQ4/FidwtnxChhTkqRFOKNa4WDJyLtYesWr23rNzBRKndOX0p/rzFNzFTS2u7tw9i4wH4I6cyUvJX5GZVFrjlYE9qWMcV7kqurt+8ptXy5eC1A44OwUWNmDb3l6q335Ef+4c8FmKfveCx4Vum9JrS2/KxBBXImtHJ6VWeZlPzdhJR2HP0+nE2oUB7PZO8cK6U9eCJhKLXMJmRknsUsMceSKlK4FI2VIM4NJJy9VFjI1TWmkbVR+SAS/b9Z8IiWejYMRMVyNj/BUpqcAbaXE8G6gVKvyOSpmPxZELaWKM6JfvlnxvcZ/B77gZXAe2HDBtbBGWncmtJ5WSbflFmVWzIeLicQhhcWhqlU8qOupDAQEI4nTzbnXz8ExJoUGPf4ywhLUKLY16W4/ov0tRgUPKzc5UuO7UJnQMhwIpIr/gRcKit7ok8jgutHUpwwTL9F99gSzmbm30Kmhr4Z/Fh8K17RiXWO9xeUDcl8MOw/hd9Lj+HwC698xtJ03vnU35U3ZfFWq+qYRP3F4Pd4GNgzvr4IdRLJLPUB0k2bt8Pv9UDVH7AhvzMZzlNEtaaTNpjFs0BfmSE3TV8+VtTOZf1yPp3j4Y0t9fYYHv4Q6VyyA2VCKVMlxzIDjcyDafqla4sh6KE71CWWAul4oF0Uzhwz1aI1oilxHQ0E/WaJgqSmjEFGO8u5rhfAEnmGBAXLjLnmg5IQIK3EteD6UYhxShimoPmuiaXe+jifN//JoV1GhRszfHvw+zPj2kWieYGVdEoDxNdpWQZqsYOtQjXhsIT1GJUOO8y/KQf9gT2ZY9/uUV5fkZjiDevQLz1UWu+bdUXYbt3rvWMGUIk3YxCUpJ+8X3zf9xQ2eHPmkoOMVGBuuM8t7g+8XEmoP1SuaL3attHDqdjQZxTlguvetUOZV1iRygGZnGtYBr+nqSxFfPyWbDwX831r8CVXpR6CiIiCQHlZMWujvj+21HMfSoxtkmWA6ZXOrxzDyoHyso7RGuBga9nZg3Wuah0j4YTpUh5wUM++rGP7Cixz3aBI2IXuXel9BKSe7MPvoysSnBG0rtPo93v57qFObacO4TFmDDjKU9+E17Y+o83tZuuxceDDs21OI4Z1ZEpjvijwvicixiMSLi5PIiLyr/3P/lTat+XUM9T83/6rfywPr699m7S+hGhCP+PnF8CKRLLV5p/gIlemMtpiwLhH2S+8jqGWAL9fTotZ72ecGeoQCcKcFs7WPa7Rnb3hvxSHBA23LNQuziX06UhxmdIHGpsr1fOmxT7BI4mVndNtFl9BklovoW9IM9RS32bIb1XaNrhH5PZZ6k+/1x24K1+agkJfWYBZLyLnre+H9bwvCPLGM8ahNVFsjx4WyLgpk7gwpGZU2Q8w7UvUIWW+wCEdDfk1Zpp7JhJTII+cBfpCWx9ix6IQaMKNZ4iQuWVr8rRqzaqnkAv91Y9LHcqXuDWL9sW1E/vuiBsMn/sfnoPAK73PkVFaTosoRxLhqln03xh5GPsX4fdFSunfVhhj1Lq6RgJzlFrqqQQfNYiwLlICs8xrtSx1jK3MtV3g3nHtBDI7iIshXqyd1tI1wRZDu93+i2drgQM/1jkfaqv2ZWeyij/0hRjKprUxM4B9b5uYmMVM5B5zTONH2lXG/2hNYii5WukdI8M+hmyph0L6gskk2vouEWrO/R4PTWWg0o041/ou9+D31mW1EPom/DpDYb3M3d6ELFI1UcKFns1vlc6ydazJFJoM/RDWb3PVBeFqh2mV0V7sF7GLpvhkJQVQIqAJrQ3Ln9vPMJ2DScaUdpny19Jyjessf3LGwLofdsZexrhRMHFtwF7aUztgzQhrvwl+31r3Y92DeGv7qqzJ4r+EPa7tsVJofJ1l6nFrZZRH23rI4EtRA8Yy+8nQel0/9k7nPYt4Wi6zy9avgJgR/557/nagj1oMvdifiJZ64kvGWTsF8iIBOk9lD6nnz/bxM+wHXweMZdRYlmp0WN+5ezWt74f/6p/+lZ2edUv94694SkREfvPzr7o+TEluXLKivEJnjScFQRjqKvDMBjQbBuXH6Qfsgm5OGgXuA+Pvz3zsU/KRz37eD5L3TBE6iCLiwMYluWIX6QocR86okCJa3Ffz2u+1A16YeR5mvEpc952vWuA8a4fR700hC+OLwZBraMcTEG880H4sfI5rAyLm3nHbAuXdCfW3pLTNa6TOTYWNIk02KTIttXSu9Y+00RZlgMehYkJC9cRRD5vskFP4fbTUe8LNTA/CdzRImAtQRf3P0ltY/8ZzGBF+QoSKzRf3y+VgV5gOw9cLMZY4jEEMY65whOPGdmst4INLXQAVfBaQx3fAXzbZQVUAocMUKSISfNrMeuN4UniXJVGilCkgsUZax4Wt6CHQv5zvHP2j+hoo7tCvC0HjgxV2jlW/96kTfeq2jIEPlvqljPzNNbhSpGiCoSja4JotpewvqyW1qMLcBeYR6kafart5jCeN+Iz7QAh+r98zU0TfG/PAftuK8mhxjc+hxbXs/Pppb9l4OYKuEi4SSm0s8D6Da4mzmOF9QId4/+4oNo4t9WW2J+3QnzevA/fSDPKI8dULLJY9+D33B9tmqG2Ds0XvmUJTorit3oruxmH30P6tVdpAlvXncvqG5G9bm1Nm6PjtEaJnjO4xX88m5lrhaWJGr5Po99xPet/o4mTV4Z4r7udxJk63JkbzbCrkcLtUenaI5uhGqlAQtNQfF3arEKXfMIRAI2wLgctfa06h5TNb+PE8Wlf3RUg1KsRDiATFstEnqCfErcgU5jsw/lHZXCJDoOnHNgrTSg/7e2CfetyO1X0/1worZBr1Yw+pl0e/n3V4JQbSbLG2DX6/Naky6PueQjgpON4rNd4gnaUzHBcPn/EYNyYgc+yMqzMNYXU/iQjzh7OOFeiVBe8t0VL/j3/p4/L61bXe6OrYKyzTF3wHEt+N3oQp8/R8wuw13GQU0FHxO8fu1wW3Sx2hKlP4/Q0Gs6D4LERHHC3snwsrYJOxpfyAJM8ojzb6cQe/vytvyuLWc61mtUAY7ly8eiDtMwIBfl9mwD187MhSr9qyo2jvTERCnnqZBFYZ1rA5GSYIbdi84OEAhF7Hxv1CKqmP6vzFXLeTE1fbilnzWWiSTsCK5FBr9Pd36aoGE2DjM/hy0ncsIIQE6CDeJuSD1EZ6KijbtrnUU+yHhxY5fLILG9MvKvAccIZVZHDhxnVjtIa4hcgCNwfscQ1pnWGdJYcRrlWC9Ne6n//YXfP6h2tmwHJmMRG+ZK4JO3fpMM5g0uNBuw7we+H3w6n+mBlsfo5ojtmCbtuRGGgOdOXHGeH3nVkW/x361KfvjwPlFbuvtUaMMTLi83v0j6+lHPe7xWd4rPxWs0CJKOwEBSSMV9nTCnBjERIOHOKjROVKic9oO1NI8V2wtYZMIVlRVoJUWwXKtPF5A4par2DhMjvhYJ9xGqURTWB4OdJoVECaUkPr4TUkoLg8UDDr/SsoqEQi7QoHj9B6NMVfuG3ez/M16H8QsPnB8YDS+igp+M/BVUzEv3v60YT8TA/h9pnf3HjrG2efhaUscR+6wFsVhGI6g3B+TODJXKDGXxdDiAfn1tLct06wcJb6wTdBQTrk+CxQ9GcGFK4DlQtafLDFEp/hQudFKRPhGBRde3VQWU6LbZbHgR/lm/ksGTB4e1GJe6PSE+VVYb+5M5n2jut5EScQdpLWeY7PPNXkH/6zX53p0Fpzil7tA9fn3hUbB5AvwH2BykOkOck+mcgxqJf4FXf26SEqrEDzz2RCOysb6AbirWPbUVlWXCBVR5X53HNjc1UkgXObM3ZaBpHxrMV4umWW+juh/pYUB7+v0boikhzAjuElK9ZCas2SwJiKh6M1iUE1tq2BP1hyCiUMwHlb3TVGtZ6HJWguAyM1Lzi6eB+rTyuUBSZBDaXO5UowWpsGJFzE8GKkc9en1oLVQGQwfTfA5C0a/kEJ1h6ZDIljCrBfEJXXD2z8vjWnad+o73nE9WN3A4YKRj/L/p1LaVf0Bxgb9yWJsCr0Tryl3gdjG93xkcoZzlZryOww09/NxYHMYhNvNWILfLZHepR6Foj01bY5H76imK7MGL3J4HKgPPfA+MwpuXpdfm9oYUt9iLBO72DPKsG0yUfoHZBnkurXjZAmTBbYQpJApbUg5BuVfkjLdv2SR7EAmyGVJHZi3IvzwUwgM2NcBe11D7/3Vd0Iv7dlW6xKJ+wUpGlAZze4h+lWmX7EWh4/6tati6dOMG5kYmc9bOl0/bQ50GB8vdfpumJLPQeDXXz7FgvgiNQGn3rfRuud823SXs4YVCkSItdj3+aNe2dBGf/jO4pBa6MCbe7rNP823mtns+/XkaIrWz/4vH4OKUxhDh+eb4DfC8flQYtufnYzXU77Dv1ixQqOo9db0mjrXeEw90KOhvDvrgkI5AUQajZ/zXUE9ywu3jWLfk/vQEsWDwF5E1TsJTr4UH7ox35KXv7pX5PTqUpRof76jMMNn/m85b3l48bkfah18g7Zms8yNDQZaElAPpUiIrXIZy42+Uv/9/98CvXbZnyVtR1IYOx3JuQiMiCUQBt7PzdQMgUW4Ah+D/x+QG/BE+GdUiONw24sjHiMgVNRmW6ou9WtWmXy4BmKm1FY6UZzXIeiAIwOVwNRcXFvnDn1dvrU3wn1t6Q4Xyy11IsMq1b/bPD7ncMmWD4LCQCZgGo+PYmlfjBFBs3cgeh7uI0/0EWKTzVWIvFiGCWOJWN4OOfnbvTh8bWyLTMl3Oxrv80fqNpPN59woMQ0aEi8pgCHjHaTyeRhgKt938jIKObChWf6UBBkhuOs1hu9P4GEZ3mv93IEi4iiQWcVKNS0ed3AYmZnIizEld3UDgS27DBrdL2XKxb7WhfyJcbf+PmWWeq9VWVPwZSmHoOBOCYA9/0OI2v1gqLukJFNhCoTRuPtvo1K8QDGAwHRwQc2dMRB+tpM+cMxFthCwHuQkUkhFRbuY+CT8RZnGWGmiV/56B4HqMwIsBOck70r9nsUJlQYUuQGI0DQitWYgduRWN17Hswtx8RwgafsngE/L64yn25ORL7yq14UEZE//s4/3KvILDFKf9HyqLeND6UAY6gQTthSbq7ZxewiCa5JdMeg0pLTWvU2MI/nLLaMa2Nmg5gWx2w9FIENnvrUt2R+ZkPc1UI+9cI3hMKWelZQTEUa1XVQp0hxfTBLYBNHx/AcYdr6xrW31Kcpskhha0YOOnMz1xoWeEUmD6Xv4ZRZ80ELU0THQ+u6KCx47JcQuX8+kvEMBb7fc4HCOvA6DYima2hrRAthLLZOJZxDSK+ODA3//g//I3n/f/WTspwWKaMbj8Z73B1HZtEung/aU8Roqt8CyMdKa1ckBl3UOkIMm1Lk2eefskuLpdGm0WpXkOdlEGhd/xsyJREP4ARh7Sfw5xlKzhUgd16BdsALFwlKOk4n6W4vpCToh7ngBGC/1MCEsUssUB48Fi31+zy/Xk8XCj9vTz97qYMVkTtL/V15k5a2NTu5TFiQcYiMzRIDvcFGo82cRb6dyuJ42GTp2WRYGCPhjcQVr/lARmHTtw9M5Q4jkQbn3U1ph4c4FGbOicN09GaHaarwMyMXsC0Uml21TcQLbEJtR2IsAgcyanX1EC2z7SZjfUBnmMBvW+vwOWUEqO9OiQEfWPD1GlZiEvgcKtNiNid3HvBazs0T5h4oz1fGa8RBNBNG0A8k7hEU6hYLlFfCvTrCZQiRZt0nrbh+h/WMLwOT0R0atIvA0MwvLUhj4TUC93AAqYwtc1YzUjpk6bRE5l4qQDew/mkgiWuiQP3aZqaEwz2hgg/Wy93qVoWcucAx2bgkeZf28jJFSEnX9kZCfWrJpDWxt6+Uzjrl0hBqEJ11aKlHOrKjXEFr8JQ9Yd7xGurNUptKiekGLW/1xeLGYI9gvAMX0yEuNhXG0+wV+D4SS72rx52HMtZUDJQX0DvCNI4XM7aZKFL2lMpwltgeROHX9mDyLC1NZbZt6yeCK/e3pxDb6dsonBkjPYdpvRvqjhZKzfaZ3lfECOfD6zMh72jOpYT1ZwgqpuFKp+pUNqSZE0bRdLQ3BRqUcW6xQIe53kVETnVJntW+Qbuwthl+H5Ro4UfiOyQqj0P0+4QBKqU6d8ruEwlGln2ZXtZ1lfN560i/HUt9k0SQhYEFBQjwFnEZz/0YYppAV+e4/Z7Fs0R/+po/+rbZl5Na6ltUDNA7Z3oeWV5P0wN/S89kASWrxEB5Jd2Pk77r2B0SiuaYxV1+xTHonT+rTa/ltie8U6XdAYmpCr+xPzlQXtzyoV8c/f6l8f6+6qUvn23L7fOp/30TKO97v/d75Ytf/KJ8+MMflvv378u3fdu3yXve85703g984APysz/7s/KOd7xDHjx4IC+88IJ8+7d/++9yj393i1vwS5WtrcNqMzftcfR7f23wHNSKDkYXHzNINwlZ/RnxlvpEiA38TMnyh8+Udq4ePfwCczbHopGBPRPgBbjM+oX13wSjRcEErWVYKfrKWpTdpF1kZsPcTO46HEbItHgL+vyc9h+6uW3NCboc86oL9XUKK9lhZh/LaBuYpcwi1ei5Mg8nZRT5kM186h+fV38IZhYQHUdrsgivMziMgHHei7OgfdWya6nXaRB8t16p4+vEO+ZziN4wJg4ZmuTwbtgOzDOmtEMFgzVAh6XzxbT1NvcyQ99cL+rsB5Zdf3/3pTUaY2AUFSQn4+zuEWBqRvNBHx/gidA/6NNk8stk6gX3R16Jrtfgh0sMn/1NBDb7CMIHljJoPLIltRIEEmiEoZ56pfs+9cmQ0DrV75nM5x5iRStV6yT2UWSinxqleap1MqQjPiu1qX8KKP6mwgJusMI54xlp0c+BTYo00RRRq4uCHeuUwWxaqwnklSH+KKD3avng7P9sa9S57qzf0J/MUh996gcctR7sOyp1ob3LSkijywdKiqx+mE7PC8ybV1bQQD3BZekGxIwTIoiuo/w0adI+tP7IiIFCaa0apHhUZAKwVxRxoDxsC2P1YEq7SQMOXl6yVPMo5/3vum2yiB9LwQuR3YCXTxIo77x2mPqyVClj/T8yxAWei7ghidYNxZ/1vID7mMT3ISIi6jJQiLaOj2trciGk/CudV8bzs4jINQh/CL83BVTC38729sdl7TIS1vEFc+DOUq+K+z34PXfE1icgLk2gbvL0M5dxL4Xr+UUMdI2oohHTS4i2g7JhqVVk3Si70VDJ45RlmWtwvSZD5YxJ8/zarO8itw9+//tCqP/u7/5u+XN/7s/JSy+9JCIir7zyivyFv/AX5Ed/9EflP/vP/jN3rwr/f/kv/2X77gd/8Afl3/13/11573vf+7va79/NwtBhtNTrL2fNU683MtGA0tP9rP4Abj1Vhffp6YxU6p9auiB5CL8nbSLnqbfNiQIKMVfMnBWInJwVjsh95OsqMvlEDpSXBbTBkjIsZVghHAPviWQ4kMc7nLQ+8V3Hsa3A5Cn/WI5z7OoYMSgauzWs29C0lz4PzEyioI1rjPPUY7sbSvV8D/zkA+X1fxu0/Zi0rZWh1Xw4iRcCu1CYrAl+N1glXAefeif0dqFkge/8PXPO9uI7oPCFgmDBORvXTTyTiiiR/mFu6tSnnsoM7AXve/wNAgX9HvLJkkJo1ypBNOLs1uWYN7Kmu1y3PGb97OhEsiiS4i31/W8txRROpvyjqmbshv19x5xzTEME97c2g1ciw1OrrPi+SbFXYNH4SOWJhS5hHHWdsVK2JPQjT2k39hYsXP3ZziRWmCHT2ba5nmhdlTL5u601cxe7CcEkklj+qtiGVWYVA2ZV1Z7gY6wooNzQXEqtu4qU/YcioywC627L1GZKU8ZfPBeiDmDU7EuH3zMM2d+PwQlr7VkXQoA5oi2pX3+bJL/fAxUoQcBxE31wXUyUD1pC9PtEMWXhhJL1vQ5+x7Ie8FihSdetNoegmVxK2/Gp1zMUaCm6/SgqzLlf7JUpJ6WB8rSOdWuCmIHWIL0qKJ8wRbENlJoKXWitW7TXTU6nxXzqHz7WqPEwbtpbIa0bwgvLRL0ttCecq+K2iSzR0CKyP3ceDk5nkExlDBtC9IGjVJDBNZNgchmCM1NMaT9FphLJN8QNz48Ofg9zcG8gqKx+ejAMi2k9RdxNlYeBb9J1NW710zO+y/YJXdDZrrR70tn+6frseZ7bJtS/6eH3H/jAB+RP/+k/bQK9iMhLL70kP/ADPyAf+tCH5Lu/+7vt+1deeUW+53u+xwn0IiLf/u3fLi+//LK8/PLLv2v9/t0uX//OPyxf8fYXRYSEDTis1vMBM1H8AWVME0j1R/D7qjuRDlu0sOYpneJY2MfFMetFnFAy/yKRTDR32GTh6Pf8YXRMae1o73w9GFASvDJY11E09Gmp9weRiBekg4+U+U9lPsm+nSnAzedz3zJxfcCDayGGdd2aQ0VE2FlC/IsXNvyPXJoxdm1c67oKjCtR/kcs1HP+X2hY6+F1hpp4Fk5teDtCPgtb3mLJSq3+N8wHKlJYG87BJrlf9AwzgtzOvKa+iJ9XDA6X9fnmiMf+ZRsjAZYn/D6tgS3PY78rY6wFGTG1ijmhvvh2UgE66boLNgoCSX9X+3XwOsv2OyJZtV7tP/dDRFIrXVDIFmCSSnGQdWdlz9YI1MGjmbSFBGfd4w1pBvbPK2axz8ZgsWsE7DVk+BAubf3W+ygNlQjPtXoy98I+47he1PrfyBJdihf2mKndU27j7zPomTbmb98VTLTfGfza9rFvs9A7ctB3d0PsawiUl4yrWzS1xux8j/XrvrWUduMRl2KSLPWZ2sJ+J+EvInD29wrSznlOZci95vqVnWVOqC9iiiruG+6FNEtLQneclT1T/FKZgXLncz4ugx/jed38WFqMb2+R+8niX+CZrCjKbN02N97XHl65vqYIDLpGIQ1jgqTC4xjnDG4YaWou1LOCuFvBM0v9edssrsTMuOTrbNyvzIIuY423nTMeLOJ+n0x6nim39nhtdOPCbBxcByvtebayuBHxd/oO+aaBvuAUgj0LRPHP7NBqHRvzh+uZUSX9r/G4txR+/6YX6l9++WX5pm/6pvD9Sy+9JN/0Td8kP/RDP2Tfvf/975dv/uZvTut517veJe9///t/x/r5e13+pX/5nfId/8d/TUT8BsAIoesGVhERx+CwYMzR70sBhhDa7blvo+ZXP+eWeuQcIlOMDDwLAXj46qbMNrwrTHfqbKMzE1HrPh+cQuZ1SGk3GKmEmWGC6hhgZaQz5ALC77n/ILBkwaqya6wjpHZJmJbr69WuWTu6bV3TbgfiEaMFtTL8Huc5i/7ulsd4xvu4DXA/3Pd4XZPAMnmnTMmFgfIKuWTou3cMvK+wC4XF9dN+S+Y4uI08wT3arrlOwNeT6craLrhc0v5j24eB8hLYps7LtjXzi87qDe/BhNgdhcPoJ79LU6hhH2BxdV8+EFrGq7l8aoLRIkRv36KH92eWkVK8tQPrtOdtnR344TITusMfBWUhM2jal0GLnaUePmjcNxU6ogtN8e1A45wOzM2LfVcjvS3FMW3QjNHUwJCCj30DrngK9VMoUcUfR9j3g3fyTf+J4sZUOjdFYO23NsTWEsbm6XeSdQOFygWg1GGDwkNUhwtWSYq/bQMkAy0ovaqlkNJjDOtoLd6U0k4AQdBkKGZoPLyn8Omi3/TDre+noc5tnuYcKv0SX+twPb5j2Px035hQ5syrxvEhDc9u3AO+z3gmoIIGz508+r02j3Rn0rXgD5+OOU5CyEcOzzEdcOpuWDTr6k99FCb39Lt6dq1b6/zDKK8/uoo3H6xHzXKE9CwYjOjRskQFckoTeL8Riq8IGTwUyo0ufO597O+BPcXSkWIX2XNEJfhsLNROgkTLzjSvpPF1KO/rxkJn8x7/qu3w+sSxWAyZ1mACRK6vfIaLkPmAt004cyL8Xm/gM+cuUN7vcvnRH/1R+Y7v+I70t2/+5m+WBw8eyIMHD0RE5IMf/KCz6GN56aWX5IMf/ODvWD/fDCUw70PzpmR4XYnq7my0fl30rLUbMthcEC6pUtTspjB3fkZ8+iotqJG138fqDZExb9AeuvvbAYKAqlCNHltl3bCAaWruHjigh1VrL/q9EV5QKrjx1aihVgVNyJ+LzARbDEPnRa6vZmThEDRlaxT9njuGH+cchXUDBdH3IvQu2lyHPkJrrOtqZUt9ZPS0u/qXYXMIw0qX857yqLVohYc11sY9HEPBUHfZoUjthHSKo85eT/GoxNHPvX2XCROpMmF0xAXpo7pWWhPGBCjTnDAJvess1EcmFNtEhkr9rVGAn4e4PtJrRoXDRtVmezzrA64FCz4oZdLMZK30Mfa/tu8SZo3XZGrd0zaapHtIlUs+OGpUxPQ+QSR7WCN6R0zJiJZ5vzb9mpmK2xBjocy4KDpa7ZO91yAcz88otE6hflzLZGgtwj7Ok9suzdOa6oMvzQ0JSAZm7nn6l5IGzuPxzzazQHn5/basCgfKGx/HXy/w+32M+2tF1EE2P9UPsLIVORnahLg2a+tIABfRvT/9bW1caIGklHaHggWvnUIvKqHZSAJ5/0xEDe6b8ZdoKvarn2VjfUrxaxAEFlWuFIl56nu7MtqY/d/gvdk7HgM7gt9PWp9b6nGvMqol4yFcDAU6u/fQFLrH13WTe09d2DNqqTflVPM1tOy9YpMpTzruAd9INmZkfA+XkG2mlNxSb/RL5G1f+cJufWzs4rqtX7LDF+C+xH1i6M0nsNRDcfwJ6iVKkQt3ZjZ6x6yYY1rPfbBP0Pj8bNHvV48MqfzuiTY18b9nc6prddLRceaoUD+23p2l/ne57AnpWF54oW+mV155RZ5//vnde1ABcBuLblTcsLWAxYhT2h3QtTKIFh4KeX7iycxxnXpbFPyxIepHIQuq/m16a3FWe/17o5UWm2DC84S74HztBauo9SwEoYqw0T6WNg70yBigQoLfExKnySP4HxmaqbWXkvn2+vkVAUt9i+9r3ZqzTvt2xH2Pn9qoLw0uhCeKCfG4fou1jVbZUuigpEOYDwHslLbJWvb1TDEnhA9WelegOGBmMfPpZYVLpYj5OF7uNwc55H7JOOQK3jP5SP8M/yAixluGw5Hh9/6+bdsi84+Pk7WALXEZAxOY9lpkvQafeqfYmMyLD5QmopYlLRkq5LCE/e2D7LAik3nrmQZL/R4P/HB3FF/2bkcJaJem1rL5zDIYGqYbosJ+a7bP9gPlRdrE0PoAtVfBjPbmnAMvqIkAQ1W9NRYD5RndgX4VsFYbmqfFiNXNvTv/gjj4ko+RMdt2gkPxQnzQa7JAyfcUsNTDd1lBgTyNUG3n6/zMiiO8xJzyCXkKe5/dE8JNBQ0FJeUBsuj63Icpf+XvKrjRhH54gpFPJ61ZaNPH6IhnahHYywF1yP2afXCCCQnGWo586l12CeXdmj+/s7b5Ny1HblTjy1kfKcBEJA2Ul1mIRURee/hYfuD/++Py2huPTahetyb/0v/4nRZF/rWHj3tbsM8XsOSHeBVjU1qciALniNJgGhbGTzp8Z7QPMMp/FihPRmBPXQ//8Qf+knzDN321r5PbgPr9eadKks4X7rvY+XUhMt3ylvIEPvVQcB+4uBhEv1i30dJ+HV3TeQXf9X5U6wPO95d9xfNy7+np3x8UsDw26ncpiEzSeeu/qcuXKZNumaX+TR8ojwPhYXn55Zed0H8ksL/44osiInL//n1TAty2YppMJ9RPxs0CvQGzAA8Tk1+I0Pn8sloMjpZsXi0mkKRWjPhdlpN7Bpebm9DuSi31+AU3uXP/ITOGlvqd+nYIF/7UU5p1fWf2nIPsFf+hwPzvpXLh4HYZ0sLdU/xtqLXk97WuwyfuGiuH/kJ92i9N4VRkrsubggs1uhZmSEdD+Cz7foV5cILleIai32MwtgxeGbXQgKoghiHzywzwe+5iYvHXdlYL9gO3w+921cY9ZTKime++taF9yWjCKAgXnmPofzNLPZY9wZnTOt6khDsDEiOD+HVhaaPnPGRybc2PjzJ2hUB39i7HmMUHLKwswPLzYzJU8MmC3MFrM/qG7+VEglWm9IlR3ItFdRatTvc5CiUrCjJ6LzOOs5+7ysyxHwuOEcsQZDL0wAxaJG4MIU7AWGO2P2B71TFnGzDiqdBCi7MsVWSAAJo+Y9tgriknxIjIW77sWfnCaw/nXGC/M/0W/r7UvvZBdkFBpGm/SnHvxAXxFK8M3LbNqts7d1CZgPd5Sy3NeS3SVjoT8VLnRwD9IcXPeVgOk8BnsSCYNisixoG++T1yG2W/D5l7miE9dgT2Am1mmR+08PpOSZ+u0wvqT3or1I0wa4bfR3bJKf24DpG2o4CBz7jm4bzgQHklO5BE5J/83Efl//2f/iN5xx96q/zJP/E1ItL5h+dfeFq+7G3Py69/9r48vjrLU9CHbdsiwg4LhzBBnmaHBmsMA5El5fNMyUwPKr9R4PZrQPJxxP+nn7lnAjDThNCxHUnYn+f8OJzVsIbNtavGFK5SSBkG/apAqDxd8IaWLLOGa6KWyM8RHWcEh51xwO9wkNvTUofidip9WR7ZU4ZqJd1VBAI+6pmz+thY57tAeW+O8qEPfUheeeUV+c7v/E73/Vve8pbD526zpV6hXKjVQ6vumeH3WIo/K3sUX0yqArcCc3d0yKHfrbuHCvcq05wh/Ezrc0KeY6xuIDRkFdpVSNC1+dSTT2Pmz1V5PhEyNRQUaUo7YOI5J7M7zHaCoGWWXBV6pqV+1qNFCe/5el+o74fuvgCH9WnfS61j/bU09kDaV7hHkQutYcCq4oT/3jc6OJaSvM8xN+TrrO2hQiP39fbXNj+J9YSDDLrv3NjyOtkSr+8u7EiTU8vsIh14e362uOcnpDOW1Odu/OXgRzwetybKZBYb38rKE6yjAmSugPBVBMbvA6qp/zO+U44BEd10cvrkkC0QLJQVR6yg0u8wQjG34/xwJdKS07K4RyIzPq3uSAM4z7e5aKBABeOBRUntwPsLiiuYlwJ94QLvZ3TZ6jVlTZTq/RpePK2d0e8n7DRkSaH+8/uv7KMLaSK0HQcLLZmym/Yqnz00HXmQUz+2amObax1TKWZuUVoCjZFZVyO0k+8EjF+7dUOgvFrJx3q8whBI0FUqgm4zhvJufu1PBV3nQvaEExFJ4xi4+6EfIR6OIm5AQJw+y3ONOWVDy+k0xwFAJQcq5FUwLlKcUFzog5sPgHmzewBa1cP2G33q/tfgwrRE3sPxAw5BN9fMOmIoYVengmj+8Hi48T2+Pk/4PVjsRRI//q3JskxtF++d4GYpRM/oN5Fh1DK+J0FKhYOoD2/VGD6DVpXiz5I/+a6vk3/9f/4v2PU6UvZppXvrj9tyBdaI/+DHhy4byFsHPjRFrBJ9FxbqSxTquRI+q/d+G3s6VEFniqma4F2W4hXyIWgiNZuntGsp72LvcVzf+dS/Scq/8+/8O/IX/+JflHe/+92/11150xRb6JbPEyMWi6yc0g6fFWKiDOpkN1hBaHG3wkZ/Yfx8o6Wevs7h95MR+MqveournyG+4WDTL/YgruFDXlSjt+tbin2iNhxkagxqwnFz4r2nbEDtJwtZEX7f572UeaguaE7yU+MgZjyGAI/jkvBymOt4MhL7E83jtyBGxFyjlbz3358chc3gyUHOigAk7rZk3PnFB4s/nLAEn3pBZVDvxK4ChvorJfoFos6BteH7whe9bOxv1u64dlkOaJ9vWzuE36MiBJlzjuZ/oG4UKUXOlrmDAlDJZAI2B5mUwBiwz2agPTt0Iw2UJ3vvKn5llvpEENASrDTj74KMWUMECjJ5MB9D4FgxeFqBeR6Mqj4S4Pfqq44MvrazQ/dsrzXobzZGRDmM3ycU0j/DjJZZ6kHQmnX1NhXN5cbD+97RxazOLgYbqqh5QbgIrSlSPhxaj8QzzXsZB1SBUUSVCEXWKeMGWtMjRXMdOjar3FAHmDHCzQ+fWYkCw42lToHJ7Qe6J3lUFPnBVt9JH8Z3Y104IYn2caHfj95BFnPA3HfIpx73srlsHShFUNmgCqAe+wPedClOYYFzxufBJAXeTYbbbjIXdmZcsTrAqDNd/2CfwyPeM00Xl8h23iIiYXz+1Odete9RkLdAeSTcc3yHlS31TEcKrWnYS9ONy683zDax62LGZZwl4ubc7/sXv/w5+Tf/V/+yXa9b88YmXBdJ/f5a30Vzyq09lzQX78S5JPI7n595b3r4PQv18z5WvPBYik7Ozthcs8DAZS43cz307xGdlyKHb7jmoI6MDjPF8p1P/e99+Y7v+A5517veFVLXiYh88YtfPHz2tkLvRZA5GV80v2kC5BULEVDdRJnWEC2uR5prLVMguSnX5KgTrBIo1OsB/JYve5ae8Rs+aO65OCVAbl1qCbFSn2v2hbdzFOo17T4xW0iI0zgENZ/n/mcerpgve4xi1BlPrgklbf4Zd/D039SnnvOfi3QCX09IhN3PooptbL2qpT5hRqGDVoEycVI8c92zLMDhQ1UwTMwiMbt2tN9t1ql9Lz5QXsoc0ZrwPrheYRFgyG6PEAMm+/XoR/apH1WOp2GdlPjegoICX1JYn/7ZJjFIId7HwROZoSk0Dm38EDZZWJmC+czBUj8ohCFRIEOCCrKoIFwDlJADM4kvbl+Pe9r8jnOys6VOS7DU476jPeTeVWvB5zZZMn3NlPll1bmwW6cVx6XtcgKmbyBT0jJtSWO4ZC9U18oa52eF94rl6urslV0nht+X+ZwJBc0xhiJRGMTCAud8Z83WGEftl+KDNoahZmcP0QyzHtG+XGw+5zzrGvMp3nwD6zaV6hxIcFrqdU2wMpjoGxRW1oW9rYqC8T0jRkQElAtxDyHcnu9BZF44h9g9jxh+O0O47xL3YCl93gtoBlixhpb6trERIz/TlP5gW/r9OoJG4r50fbNh6bv0cYQ41SBOR1D6mgGhGF/luu3objL/7meisaNv+tz/8v/8n8hvfua+iEzB6XzewELvhXszbI9me8pcWCdA03QMUvx5N9eSp1f2VJ1nQEqbJFMoYyaNSUXR4PHw8bWDbaPygihqbHLvfG796ZI8g2sQlbgYL4AF9wYM/OlUPT+K1n5dF01P1Aa/NeITY7+Oijv/7btZWRafyymg9Zk93pErh2uXMQnqvSZL/W3zqf99J9T/4A/+oLzlLW+R9773vb+l5+7f78RGfetvYzEmBZksoGPKjKTbg2kQMwVwTxbQ5shqFQKVcHMkqCgRdjAjIHih/8UT5kKHgatcgkwPjPQ+4Wgy52/PEmp8gRKrhKD0n70iJFOmzHHMD/NVguaezqnMUr8QY7g4bXj/rIzB9fW+7/K6bjH/e0JMcbwYTG43wjqOHw6vAtdeYIv+iq35NZApEPT3zYR6//uaMM6s/XXd1neVaNczJVeepUHcWkxh8E4hI/6Z8Z3Nmfbl4OC1uDzw3X5aR9Lk075at2RNuMaxn9MKMBnDuF5L+KIAykgt9UMzD3N20+EcvI9onjKFhoi4eAMzpV2BSO/xnWFarPnuoiDA/oYBQqmCEv1uT9n7nouIFUMmYJRJe7QrGwmYQcmDfVGDPNM9DTjXVMHA8zraSpRyV4PBauLXHtIhkfmOFxvTfCcGUafsB64hiUJ9h98XJzzZmgKllbMmi0czbenZc1Aq0O4gm3qaqe+tFN93du1BtMx0wUNXvN5xn9IuoY8Z2uhgPLWWoKhBJYvIRFhk81LGXEsRUyKzwrWwHk4kBHELdZNUnyKh9NZajI6bpZ7uqTD/nLkmo5ciEgR275fuM3mEvpliba4DTMvGZzzOB9MH3CemTGqzDTe5QMYdpB/h2ODigryTlp/95U+IyLR+ntfNkErq/qnn7NY2+SNf+3b5mj/y5aPuJgXh9+L3Vg9Oh6iHST+ZD3L3YHwG2XlnRK9YiVaKt9Q/enxtvtkinTc627j8+gzj4PZohacxnuCj7vEmc12WEvk1tKGd6IxGw5SHqHtL/TlY6m9Cu8Ga1/rG9yW5B/m9PaV4H4vf06kg4H4u06fe2pL0gTuf+t/D8oEPfEAePHiwK9C/613vkldeeSX97WMf+5i89NJLfzAs9QBjw0NjPU+GNC24KRL4vdWJTCkdctnpnVkZ9+C+qJXuTHOb7QzNY7rhmbAwU+kIJB/aeV888Z8+VcycTx9IfaA5X6H+zOwLWip6O0AI8d3xAQ3j4TqsHSbsbTL0pizZG6+QTz3V3TXpRz718eOegikbn/bfjg1jEv3BE96nRMsCC0PYrsHvwXIhBSC/rQUmQT/vwfFD8LYkVVGEL8c29rJIpCntQj/6ey5U8Y6Bgu7hvs397OGW/ul1a4d5onE9FykSYaw7FdO8W5TtAoyCQF+LD7aj93Ffj4T4PSYB38kGPzFjj8xbhpA6JYJA1DPAe2iwH0p3XthTBBZJ6HOZdc4I32LKMscUUx4tJziOj2y9177iWs/2tI01U5qBsIPlfPZ5igsFytPbq8iA1ZbhotO8sOEUKP5aIyqniqUh4LMg3GGhgPChOkPWjVICzWBLc1CSAIJA/bKR/jFt2VoLgQQ5BoHo3mu91ykLwNsh+NSXMEfTHQVotXtvvh8u9aboPtZ1lATKK1GBu4b58/1ihh/dLlggroIoFr3Hj9spIxMDBTZsYwNlATTXaQi4kh3xRKYYL4XcZCZtxn5ndeB+wXnLYyAlQxLYH6rEaf43fD8f/9QXRcTD7xVlZcK8wtSbyF/9wf+1vH24U67r5gwOnIJ0zsf8zvigyXG4Pru5U0TGzjixrGd25fIPPXx87ZB967aFWE/WR9J+7Bk1jBYnin3UU7nz6MCnHus+LdWdT4g0OTrfNzoz2YUpKtT8pRocmkxhE1GUWXo+JqG9nU5Hq81VVvwcYzrttHPj8g5+/3tUXn75Zbl//7685z3vcd9/6EMfsuB373rXu+TjH/94+vwrr7wi73rXu37H+/l7WZjh6Z+RABxY6oWIyDiQsqjYKVHJ0jWNZ2KgKM9sOAa1YL7YSod8k0xWC4SEBVtlTpQ5u8liSuPV3zjPOwtALugNKx6QyX9S+L0/p+ZtdT/X8ZK8hzqYUXsPmSZ4FEfgAoHfCGqdk1Z81A7RBu9BhYFk3lFTXPR58YHyamF7cTx8hFKgZAGN3GFWq9PYptpyalW1x0X2/Y2xOAtqy5ELez71hrLYeaaN70rSdsgFP8aNPqBs/XOKO7DwRCjs5oMbRTEVh+G18m26vtyUx3cq1MCCqOtqrBGDAkvsp4jIuZFGvohntgiOzeu0lOKYekZE4MPY/HoD/L7BBa87C7Yl4pWnUKwf9C4xqnodY1W20+YdLIBYQqDHRusKYkI4NE4yRi0+hSTT12PCzj71RhzLZNQ7jdhtfsdSj3Q2nk+W67jlXeQ8zrm07H8PftnUpinUy4TfW1yLZA+KJEgGUjT3dGQIv4915JZ6JM72n7WhMGWlOyw0mYtGkAyUHkyYs4tDgso5epshfSnskTRFnBuTdyGZgl4SSR3q309pB32GteAs9e58U37IZ4RxdeqcwVq3lHYShTc8x7hfTjl74MKRlUmH5/vC1GMy+o/v5zeGUK9olvN5mxb6MQanFGtiFu51ay4WTgh+O/aCzkFx7yzSPHvGxixOOPaV87mG6TEjv/EwWOrbhN8DZL0Ur3Q5LKygcI3OixkTCQxgS03IJ0D2l2UoIEcbKExvyfrRcRGcMQyl7CspeheKaZKd8WFUxq4t/dcS9nzhPcFnN3dBm3AxB/J+rneW+t/9ooL7t3/7t4ffXn75ZbO+v/vd73ZCPpYPfvCDtz6ongv4U/x3TXKLuRU+jK2u5Fb4PLXb+4eEEg28Z/aLgt6AdnsJh3xxB7jrETEfSGgMxrbD8U1awz/4Sw74F7TtNO8ueBm8h0Of+uTdab/QFSLm1C1urFgMnqyHxgHU2qCliQCxkaX+QKa3gwnv18NoaouJMWoe4aCMog4xDRakXQn+spIsE3gHVtPoby2OuOsvIViNq0771oJ13Cl+aD3HIDHzvbLfvXZ71y+wsdWtBGY8aLeT98ZrDZvZg4uK6JrAfSp+nmD8qLALKRnd9i1hrmfgtMjUYqA09BHn198ZlH1GIGN4rH4ZQgz0m/evyyUOjNmkfxF+HyPyj7pcX8Cyl/m6L+oGIH7fGt0A+oPIqiJRCNb3TzQC1yYLDObrmrSNxefJ9r+hQGQN4rUhCIbACwps7Yf6v/dHY/vxfftxOHeaOuerufuJ7lC/UXHlxqIfKzKvoFwT8Km3QHlTcdQM5h7jLPR6KeaAjm2KN7I694RQRaRvyVniz+rqaWYixE74/ewXnptILzL6IAktCP7e8FouRjrAvT7nCi/YG4KCP/VT5v5Zkkjq7jyBdel+Keiv7e9hxB/yc+gmw+8u4zP4ulQPq87fP38516H+HoOP+cde+fQXRYQC5ZEvPQqKW2t2L6e0C2c68KQukCWOOy5BK6YISPg8NgD4TBpxah6RT/0ZLfVQ2cXJC9NaPx14/XsaZ6CHpriCs2Uox7uhI45LS4Tf58qTgG5rzQ2eUQdBOURzye6U3K/MUp8e3uO7XSRYeKaMOufXsa/j3LhlQv2bPk/9hz70IXnf+94n7373u+UHf/AH3W8PHjyQl19+2az3L730knznd36nvO9973MQ/e/93u+Vb/u2b7v9lnrQ7IqIt66UcmipD9HDh7+hMU24EUErqj5mmWVTN16W0i7NZ6zPN2Xgiqxn7d+osSTWqrBX/RcMIzyyou+WMnxvamKp34HENh2PeOhqa4MBNiGXiSQdprMLepMdOHyIn5II8xZBeQdp4MZo8PsYQHDdNm9N4Trg4Cml38Cacmx3z+ro4fdA9BGSSc999R/5cnnwi5+Atp7sndpHFur3hBN8Rj+3KATVSsxsi/DlzJKTWjoLBPtJnimlmHBYBOawzN/xmVKKLKA8ERE5LXNPu3aEIiGHNdHk3lImLp2K17Ud+NSTsO0O7eJ9SgMSZ1yHIE706urF4ubtqacu5MW3PiufXa96uzD2VRoJ1l7o6L79PiiaZ3bjur0pDZa2YXU07UtJfi/2/1JGPxrdA+9bLSIoTKwyBQJmuPKUjCToozA8OpChT/QzprQLAmOyXWM8ihbGVgVT2sEIM6VCsNT7PYpPOF9PWHtc7Sa8Vks6lvkzQqnHXNkYYywEqV1hcwSRFREpJ3/OoF++8uFoqc8KCztpcCqif5hRp4z/XAsGv+fGRNACroqUyTPMNlIFrvtuPndxWmSVdVcZyzneay2g4Oo8UIZamm6A47vF12ODgHYQUWS7tmjsjyXQKFUUmFVShXxA5mVuZZmlNbh0lGPhLS08RF1Dthab0RYtr3zyiyIClvoVot+P9leIw9DatHCjG4leu+5Yf4oYydHvSM9lBhAwEmUIPx6rlhXcDLKnHj6+doiDPZ/607LIeTvn7YV1LIM2jo8sPBttTuaoZJboAv2osq6zH8gDHkHU14F+0+MloA5oEbufbY/3+6rWMp7R7FyNHuY1JSLRUk9tFUJm6jBmDJxIlnVP37aUdm96of7P//k/b8J7Vr71W7/VXb/nPe+RD3zgA/Ld3/3d8o53vMOs9u/9LQbW+/1YGHIn4hngo0B567q5H9CfKxyEwFj2qPTH6Zqy6PeZdVsvkXg16YQImenYBPktVl9nfVL4PX5XRZhKrmsX6qNVk+ZdlSlAZdDC2sfSnMY16zszyChnBp9kaydacaYl00O4M+7wKE9995++AX4PB28fz/zJLEz6fhMBoIJFodN+IOIHEttXfc2XyflU5Od//dOj3Sq8nvd8BnvDJQ2UF5UWcFm91QnvQYbMukz7KEDPW/7+ROa7y1A2xhxTvVqyFE1BCVF2FA6Clvroi9utK4sJ9U0kFeh6vwSYYy9M7qXv0TpxXSHcvGxTAGvucI6MwTPP3ZN3/vMvyc+MYE6biHz9N3+1fPanf212UMa7WyMjgZHLSy1A8+I7mRaFEi31UILRMRHIjxQ0JiC7PcTCtzgBwzFbrt3ZjusrzguOUZfMUqUHJGp5/utxwamwuBAL768W6gPMg0WINytiS/cJF3MxI3roEAfiFS8p9NlrrqgRod9hDWn946+Hzjejf1vxc5etI33nC/EAdg4VCCTYxMPhrRK+Pp7DUmvw08bzG/u1S7d2LGlp6shRLi6JbaWAYCs11WX1/uUSglWiUN+/WWgi8Ew6cp3DL6qUnu5QulIGdxtmpsB3yWeGF8hxPnh8UwEZ4gHAfsFAoun+u2HLFPHBKJ0xZ5TXHz4WEQyUtzpLPP4VUUv+FK6+/CtfkF//zGfHuMTPL9CwWnTf+LmyPYydhjE/iU+9uio2PrygPHx87QJmYvT7rc1gpRenKtdXdCZSezadLV/vPA6HYAWFcTlwDT+dqpwfz3qcG6Vz7fHPaRwapUV76Im9Uks8660RU+T135GnDWR0fOmMgUhniO7MsY0bE0XB5b0L+ef/e39Mvum/847DMfx+K296of4nfuInfsvPvPvd7771UPus7B2c/QMGm4r3BW1V0Tqjpd4LWiIiGHF53scWGjxvEH7vmq3FBAS0Jm5NmZyEkGSMFHzJ0bn5mZSGkuq31BEg6cJHH8WxOHoz+l5ERFpzAu20zETGwPvU+98RBjcVtL7zwQoPVjHOw5v5Qp0xRHhiEXCMPSktEHGgzKQJtdvsqwpBWdqsUqbGtcDhXUSctSIouJm5Zs19YhnElVdrcXvApq/4Z7ANZBC4fmauRUCJoYxIggbI4h0UaDdFhdBarrVbmu33yTa7/vH4sV2Hxjnwqe9+kOkGHNX5sVlV7Fcc9mB+eJuAaj9s3eqsfMKOsktkRFd2sMMtpDUU0XW52rjQTQRdQJjmbcCF+rgjjJBB+unpX4U9UsYzV3YzWOLgmWhZFNeO5eJ2zxB9E//M8drUvoDAVrplK0QOR3glunEEGu7PGFbslPFOTqQ0QNQOxt3I3j8z04jA6G0UV689Bxa7oNRiweMGoaFUCZZ6LUYzhlAvpQucpXhrWuXAlCK7Sg+jlaZMoH0HJSinMjSFeydDYV8n0y+6FqgOXDs6ZSBX2z2N6AP+ruXpZy/lm/6775B/9iufCPecTlUeUz+Rx2BFei3qzgP+2XR2OMhv8OGGdYJ9LR55MJWRxZRPNmfat12hvsxMLSW+O5fSjt4/ZovArAsHS1Rq8esaacO2NfLN98/qazP4/dogpV3fn6g8b9tUAKxbk//Jv/rPyz/9D/5O/415Q0fPfOP/P/b+NWazLDsPw9be57zfpaq6qvrePT3dPTfOrdnDITnkcIYXkTQpDUWZFnUJ5UiUZJtjJbINOLDkCIlMAYwdGJYS24FhJ2QQIHAMUEIQKP4jIvmRXxEDSLkgjKQAtoyYQ8nWzZoZSTPTVd97dn7svfZ61rPWOdUDJOL0p9pA91fv+56z73tdn7W28rjmhx/4ta7BUam1jjCDZW5WfuMb5Knf4J76bdvmGnb4vR/HPIXhIPi9xTJ3MNyUcf4Svgwv+neEP3sUHFczHYGlDJm2kUzkXyD13YzHOvcNn2M6C6eF91XpctMe/L7zh0gz1OmYzU5rTf6d/8UfTn55b5f3REz90/LuClt6RbzwdEYoCu3y83lLD2snhCJ4LJA+KPw+E1i1cDI9Ec6u7PuLVmwH190jXixskGA1hSAVzkgxTX3/1Xt2T6d1Wrr34fc4RxRTz56fhnBWTwTnO8yYYN32kvqo8cApbGM+Zkx9crVWf6eYp74lXim6vswpFqW4b6zrFtwePX1equtwYy/09kQ82r69y2u2bY0y5PtNEW5IEPGfS5HzTTJ2Etqae8X21W6iPDhsDqnQMkeYxafvMc6MqanHS6ueQir10yMiPFxNhV02VIlwLLTvNGcs5uumZqdmP9t4TrxnICh59k8UFEqJc5Al/ckgfFtrTllAQQzbdEqe+yzOmJZBYcP6i+1nVUhxHRj4x4rOnrEoNbImQp/WGQyz81hmQlmMXZfWAjJBBWlMlFfomaVWUSWPr5DEcrpY5ROfep2+jfVmHjk1oM7kVizxjRLgvLUMYdO+Q4ObPu0MBbyngpDr+y0Sz7LB+dusQyTJFwDjRcNaFrZUpqde6+jfq1G+lJj8K1bCn5NnXJs+k38WgjcT+LGxAZ+HcU2v3QGtb03kmfvXab/XmbTT023uD54vlRcmtL76pGMh7rdF1BkXhPUr355X5805K67ueW51r6MxEW8ZoLZcojzmQ9O4TIahg/WvlPuGb4dAdEapXgHTfj4GTz0ay89bc46DrbVZ37Ztbizs4dXzWko8AwHhxN+LseI0sRvSxkWSqxojL8Gkwuez5Q7YwNB9WheHFBHZJU/JWPLNhTKe89SbJmvjGp/ZiI+OHafU0+46b4bgXWpxBiRtYh/hAQlZBeVZfXE4F0adR7x7eurRoeZ4IDU9p6LtPsO3aNyW8lSpv0XFEepJoO2rqVwnrCFscGAGfMAQujdjuxPvr9aYxdTvJrwA5avD71UJMEL1BFnDrINapcZOChE7eD50g4XptU6izQw9wO/1/RaF5D4WagOXrVIdAsqLWBxvSJTH7cyvhzAOfVvqztwXkZsbi7sK99RTUrQx6NFXrySyYiQJmiP11INgp8qIXRlm+4iXbGstxJ3uXT+XlVo9/F4bOMzsmq6VCrEaryvhmaj42zPpdYNYRyY4T2t4/9+EUs/ffT2lFFmX4hhjgN8nirK+i2Vr3lMf95RJTAX2LXvqj6Cf2E819KBgsAeVDntk816iG4B+4gvBYwaoC0S7sIKdCteC9C/ud3drQ/OGT66n9ymy7AVDTWA+TDksbu9prL43DMn8HefA3VjCOSH0Y6aYjK/0KiURmSEkGdLmvPU7q/1g4d9TOeS4c584MSBAjkpGh8bWqo5eT0vOng4H3SyHUFsR3CdE33Ue5xAtsZdDiHAAsdgasGJoAvKTE+XxGdw1oMPv86pNidB7EQlX2vU/YCQZ/yhj/AZz398r29aCgcYZTsGAhXWK+MzhvV9Au8F4s8AcM+8u8uT9xVnq7bPxmSI+nGk3UV61nCrTOAClbWYdDSjCBGXU68w6XcI7vU6SA1xCWS9Laj/Vw3tz3kLsufPUtwZX3nkjqwKfAg0sZojRwn30hgibxyP4vW3H6sIMsle2rblxIS+5OZunfl1Nhg2Nza8b/D+XpXGjrECv9sIwtb4pJRYfxrVkuQtarOdmQDaqDBmPjfb0PN6o0/tV5jsZ9fS826qMaFy/N3lG2cCuchgaCqKT6qlS/7R8ixefuEickNgK3FMv8fD2mHo4FMoUSxcIY9KiXhFat2flVouIJPBTocPsiID9e1kiHC87nI1e3IjwFPbUB0FZQglM47TM8AUWLFkoFOmCFyojCPsz4p3MWfFz735XBlfQU+/HErKjJ+PNlGkt/lq3+Ltk2Wlbi0hN7TpYiDmWPwsD8EKYt9i6K0+YmTSGBdK8LJ7os3VeSnEJfFjJST4cKuxzvRNP52RQSQblbE9gNvgQT9t0rCj0+0fCfhdg0OLXIhocMDlcPCsdahiyFKX/9vBa6tuOoIXPju4MY1++v4+8DgjP1mcz+P1MckhexlKK24Ms/DqjFsznjKlPcmgE+D3UqcKNoyMZKmghI+bkA2ZYUoVCpcm90B42QqZXbol2ARTIsQX5HKy7wmMUsNCj9/CFe97oELyX2gd/I8qh0spf7Hj/O52FvrW2zztImAz7mOlMPYipZ2NMiQqniBlTXFmoDhiT5RzYN3hhh+Yei6RGGpyqUiFkqYy9Gsbv57jvyc4EPaxd9/pQcNw59qUjbrAJe4I9kqeR72FCl+kMojzRUR5ds0H0kZd3+ixkKDs2kjlDmu4ptw5elpmKVjAmeq91QKnBZHB4ivKYEtZ/n+Dueft1Lc9wlRtvf5F+lh/fWMZ776nPPjf7t1Pqm9tvAkPb41e6HvNsEf/JlHqVH01+tqSSSoN5kKzU4zidp35Zgnd7RlKogdv/vCNL22dTyIv3bs964fmi/L7zXqY1IhAnX0rYFzfn8zzbtaphiHgvvpLY2qa8y3RW6My3JtKaG4sbe8HwLm+BSJN6CpybImEN+bq+21KeKvW3qCATEBGyeME9pSmR4ph6Ew4YDoSQGoOSxwOrh5mzP4tgfDEVx6DByglWvMBF6OOjd3y20QyuiK9mSYOYSKzrYp569qDTvDCUsM8PQKYotp2JXOg3yFj9q4OY+gQW2L0XUE+CENDPCinzewcewfVFwSr0FTfh+I6g5VnCp6XUCUetokRf2xtcqcTOb83HFjZiNoze8GJ1b+wGjF4ZA4rzNdpokRFXUKhmEzDeImIKMu2b/k/fLlvx/dh0Lcr05KAiuAeLxflgIXUXfk8s47y1AL/fs3/3mHpg4JIzoCZC3k4vjIZzAUZH5wVlYbM1t0e2rdn9371yEcEz5M+1y0JdS/Cqe8UL5m+e96gI8JV2nBzTKSktF17YsGcZ0HUPmmGWDRc09CA4pkr97Ftsn2la91SN7gPsnEdxprX4bT/1nfKFn/4u6F/x9c+xa/t+Xz3Jy4zPBCTLVDCF6owkIDMOHhZ4fhpSNDyDjMUVlD6f4Tzx1M/5IToEv/WzmRuD8aXs6kVfp52LDQwUpUj09k8FdeRfmAYouF2l9M+Kbut9tXHxWrJxTvd1gXam8rIwgiwiYWaiPDSM7oQKzrChAx6q40aFB/mpvyLU2lmnIc36pi9P6HzJUWpWH53RacTgGxTi+vPVilrY+394i8UY3w1mv9+88sveeISt49zMpIRTVjTehDJo/04H5v44A4iiPgL1medtfKzdUy+gBOeGC39PvfYXcw+d1sV3yPU6KairFpkHoYDME1B0tA7ZyTYjfi8oJ/oz7N++gfwPdZx3t+bQLxHiZ00N+U3QUDplk6b9Gu8inQ20x9MmNFCIiAuX9aFv2sUMHXawDu/h8lSpv0XFC+8kBBXxEC54r5Yiy+qve8os2fi8FlY28uz3SpxtuzkPBLyDiUzWJR747HCyEvDo0Y2jwtOTuEOhU/mvimDHlhP2nWHknpMUYY+zxGR9LfnONxk82z7+D4m9lTUI61mSLF2rOPCje+pFOmLBhuDv2x3yjuuXQ40UP08ZYsDNGzACES+whz2weUEv8AT1Ju48gFBS/Dkol9TX7N99bH7tRDiJWEthtHvojbwO67vN/f55xSRC02C2s4e9IItCnG97CzciUN+hLKAU43nufdt5icr0kOvjjeiRS/rj62ShMQiYNHaGNGNOgFLi1VfoxMiMIpnBjSGAzrsnOgZQNngtxe89/FzHNWf4Xn85GnXKqHAqQzQHIkSPGngBK7RDmfedpx4Uk+A1OW9B2VlXozUqqcR8AR5JdpQozwRDv9fd9ZODdXpIv8DvtObCNELc+k7P9OwC/hvekeTsFzGFE85gHlM/xsYGqWq3RWznzRvHQyVCdeTPGG2XmWdG91gQkwkN4cdP6wB0zDkZqB8p/H72QeYaivQY+9TYBvuHFUQ+2x5+zwYYcb/NtRSP5JnGyOKVqNRTX/xaOuNJStdsrvYSopXinzuitgvl/uA583wyyhdn8GL3K+2a+83dU7+1aUzPFH4+izqWmLx5J2wJ9kKFs+Ar9O9orghGUWHZGnnqN7y6b5v7fl0jGo8PvhkPe1fMaQRJQOH1DH7fY+p9UVqk5wJpk8t+n3j7tdyMW7Gmpz4o9cl8QkF5bqHwM+VVZrRG/uDrUZXG5sbLYtinVZ1YwgbZyHNuY3mq1N+iEpMoNR87A9eiICFe1yqvf+AF+f5/6pOhzlqKP8QNLeyYMZaFLSRWzfdv1FtLiddbQ1PLYtbFo8PJ5fEj76mfQmfzn+fvmaJEV6ItiwmYIQMzISREIiNyEL7x6p6Cxh5CE+AhG/JOO8yQF2Bk+k4mkOg7Ll4u6d9nvv/b7HkdiFpccby4EXgOtB/Tw2tMrtIe8dBqqzKL7Q5JzxzviWPhmPvt5hyfd69xpf1/RYBPk0XZQUPRiNPMYFEc1BPrhobmekYhwcetifMyiriIiVkfJqgRkZArAYWiIw/P+eyTJ/bN7ecIvcNt0I8RMhs8LNCQqwO3EyMeUDBA704QcmiPnJuHggaBh2CwfS58u1g2EOpxnaYi8M3A73Fs4NoICt2goxjLGGLqi+XiwHaar6b3R/tPc5AZIWdXapkEn+/vRrrgIMQ0jK15gb4n0Io5LjgRqPGyQm3s8whGTDAd1rwNs9/bfr/dYOmfIqBkwu+OThbI07D4dUP690RP/TRAeV5kkOMyrlJTF1dCD8ffLKEjDg5pOyJjkO6sE+khvl+Ovsush8+TnbOY/6c1nxTVKS/Eh04rh8FFhbXSmqjRc/aTeDd+t2eMzJA8zFOKiDOSxvAs+3x2sptva9usznj+YK3ebaK8xFOPyjBee5uNHr3Y5/M2Y+b1M9JczIbfc57gunoDHcpBLMMFT33CV0oB1GJSCoz/fGM+567sEq0Pnnp/pZ2u9UzcuLNPsuJkabR9jyrUUCAiLhxsjiOVvarj9+j8wXwd3E8No1C+y7fdBB5Ln/tljk2iM64PriPRhqEf5bug1Xcjx1TqqSGenykPuHxA/h3N23HbylOl/hYVhNq3QRBSmA0dsHVZZFkX+R5U2BzTK+70sqe+tOj97Rby/kwGv5+x+hyjA164dTBo/a/ThuilrWuVZ1+45/rkYqmmMEpKn/4zVa7JOnoyZrAQB1mKJcGZDJkMLOaxAkNI6qm3viyFhQLrq7uzHUpADVT1GNi87sLvpbiMrjgvCiO7unMxv3NXBQVDibWvpbIwveOpxzrSJGh7ChtBqffirtNSKasvCFSzDWlBmdZfAuw1UeBYWMq8Vwx95aSAIa5ZxAmlpSQGpZCgrRv7NgFBvvi12YXfU/vnrclnf/Cj83N2fY+NrWfPnaEpLQq6vI+0EhSwOMbTre0BWkOz3SOkOUuWs5JBBpVkM2L+/wh+j/0VPiNlKimTnqeoILAEtahAZSELMbGUL6lRKigpgGDovfaewtZkKTG7cf+V9tHZe766sA/PE2oC177/U42/Mr/nsperJHhv5zND2Gz7/b77zJW88Mp9gQc8byElkzclGg9W2h/zLJcdiDUW8tQ3UO71+e28Hc7P9//oJ0RE5OJ0oIgYi/MJ3EadOsdch0sCN48v1s/5U/Zv6uGkqFBDynfxUfZk10LneBglnaee7/RuYobYnPTMtbMY74ig0va5HVQu++fi4fdBwbRzM5U13Q+wlxDtkSu2+Rmri8/S7+DaNfHUt8176uEc82fn4W6U46TpUKJswaiQQBcmo/YywEykCGXSBTG6OR1gbX8P8pV2Gj60bU0urk4i0o1K2IZ1xnXXFbeHm71gBmPPP4rsKNqtTVmpzxfIa4lekPen173U2vk3XNenLxwlBi3oqUdZboytgqCNBtnQj0lH6pDNG/0M4TIOOahX2iU3GDyF3z8t3+olUxJOAGE8A1QOt/dp7R60DI6iiuRUrAUO/iQ6LSio62Lx8AYRAg9bjdmjte/BWyTkqWei3EQ++JGXQ99nYZ2+APFpVN9sx1t015PBKBliWmpxxoj+jO/j9PTr162lCgzcAJdCBTWT/WR4sgPh036UmqAGonKh7SCjwjEoc0LrNNLVrK/97/542Gsi0iQT9HgfqQCJha8r403eQzJk93cpAL+HPeEYVuBYZjzLvBv6TPhulOBRbRI8EJgUB98x98U4M8AQ97ywuDZmUBt9ISEVvUbtQKnftk2ef8mUmi0IjH5vblunFQEmPY2B3rNGVThFR5tiIUffyRJKba3NvcyZmLUPDD9GCCsalhZCN3jlwSbdkEqR3cbs97YOXRgjz27i/dO4e1WsJyx+jKMWWjfdM1iP+P2+Zp7VgCIQe4bOeIDuCp7fPPu9h97m1w1mic6yvBuZsPz+N58XEZHTUDgnmgmVfO0319kbE17CO3cv5Xf/7Pdbv0W8MXHQ88K0Q6JyshdaICKHZ3BWJnn41QRbQCBqlhz2/rN3ez/2PPUwN1o3ygy4Vy2WuLixOeWj4L/9mmEIVhZT764+mxXgfI75WD38nvPhzPBCojHIR30+nPFdcpMF0i2E2+vc6JVssx1S9AP83tEda455BM4FQva5zqNbTETg7JMMoQqdFqSZWT0dUo+eenveyQ/Sx2V32ifwe2gDjXLcLh+JyR7dupbDs+P2NcLvS56YN2S/B/j9Z3+oG7r1HPzwF96O7ba+B0Bv7/1AHp84b/B8Ykz98y88IyIi9+5eavVu7K012FtWYVOPtT8Gs443P/ySPHP/2uD3dG79vPi+Vvdvf/Z0rIHOSuyH0mZFnbGMgPRsXZYpMyId4XLzFH7/tHyrlyx5CxKAqdQTBz2ti7svVJ8XkQmTx3q9p76/w5DuLOsxw+9L8Rk5ue+rU+rHe7UGQnI+89VUvh7nJYC/83H8uCP01BXh93E+MBeANLy+rUs6LpnY7Nfx8cvuhY6eeg9FW0kwqBWUvMm8JAgyWib8noizxrdidvw94tzboL1ICotIFEDdXhMV9AAm3rhVK428rmzcePz4RtIBSxdaSvFEnpXNrOA+CgYLyDqsfWclcAoR8L1T/FozwVDrTc74FGQLzBk8w8n3ymgH81nUMvwULLhXn2CJFVMOewiJ8pAWjTYX8J6FfA/D+IV1oKAwE1thE6AYIRqJl1v7qnuZr1BiYxMLQKXYXHRFOfHUaz/ZE4JGPOgXexzxmaLjyLy0cL6DgKvPQHgLnveizzRDnoCNaMxBn6M0pn48WYtXIAKSoAEqQ+hmAjbK0VpsbGQmRafB17vx71Refu1ZETGlHr0/2uk2DA7eUND/V/CAQD8RXiz0SOgH/YZbecJq9eyJne09FMisizz1bPSQkmT0pqLK2kpn0BmFS3Hw+zOtqb5zcVp9vyY9GQ80X6+OVT+4pFnQx9O6yLZ5I4f2de5rKOtSU6UXaWOp0cCFdA7pge5lTECn7SDlwwR82l7gieJpSMxcD/OB10GKL9sGYT8UNpMaPKX5NaUyDQN6HWH1hjPOPcNVITT9huD2jx770EgMs9m2Tc4N5Yvm5s2U34jI4BtYsuTHE3Wqn4NhAHge5p/Izv0W76lX+rVtTU5j/6tS/wZc14l6JhtXez8JOSLwggCkX4wu1FLkwcM7IiLzrxp6O79HOcrk0yZPCGscRvhlqbLUKueWJMqDj9GDXty/Q6JTSODnDPIsFwzauC4VxuLrtrNonXL5ApJ9ehvLU6X+FpWMaVj8TZnwIDyHpYzYdUoiNeus5J0gL4jqWRxj5u8nNsJj/Vqk1hqvnwMujkxOvQw9IUgUrLK+zzo18+4OH+MkUtwPER+LFWCotYTYSVOk4H0qrORpXakwJTIZXCuJp2GnHVXqozCZcOOCSrtn/KfBSB7vCLDoLRaRNKY+XAVIglEp1XsGxQu9JujlyXmw/QfP3ZU79y5dR/euW1oHJG87Rw9EY/6KdWTC2Rxb9NSHO8jZ6y4SYtsL/F8k9/aGuZ+KoL7t75DuQmtxmeCXxWdrRs8aZjvO4PfOa0bnGbu/DAEbUQJ8ltO4czcTFiPcFV+v5Pu4bV93G31VunLetujxE6A71c+FgIGJBUQR2TV+WMw0waslKvVBaS8+70ikK+apt7b1POlf3XsDDty6Ecd7clw3LL6baPYsTWb2e5Qi+BxkMfWZoaxfZ+Wht8FQK9GLqLRsGnUa7hZq46y3l3jDQGooA7fzYYLOHYTb7N+gva7X0Jyb3wNPvV0H2FJeEngT7B8LNzH4fcYLdRwzpl70WaJJsEX38vQw7NgM6zXUowPw8HujOZkDwhn9Rge60uDbvVgXZ9COYWLAY2Bc3lOP9EW/26HlMDjksc4gD+PHOViI7qAzwiXXS2gwnw+t126xEGl4pV3qsaY6xhiXpQrm5GBEW5aAbO+e+ncek6ceE+VtzSXV42t79wx5IhIQi4XWtP/T77GILrR3Ns0/Md9zzeWJ8jZAHIy+q1LvEApF/2dXAc9R7yA4nUyP6Aswfun4HY0sNu69WxI87D3ytG3bem6mOuD37hkQLHAcIvMWkfm5DC+7vjKNvoqC2TfIP//SfalLlZdeeSCaUd+hMAyOJIjuPEyU9/RKu6flW71kFnwXOwOeeosXrVO4dB638ZfhjSIieL92UFqVMQzmKwLZn6F/L7/60CXJ0OKEnOCpbyOGy4/xvG1yZmKIxISEXKfhUJt3Rsz4jEPXvkDyjeANTxRkFhQx+ZAaQjIFDd9hphOSFooKbdBuSARUoydv1BPgpyLO64RtpfB77dwYC4rTAR1B9YlgEhntK3uF/Nq0pl4mP90XpyVCMluT08Xq6sIyGUKz5GMmnLcgFGBM2vxJmU+LwmJ2J7nzdALD88mj/DNskMkS5SHstejaYmdK6WcWxlSr9yzpuWrJ+jlYHAuUAGGftgTH5MlL1posawK/n88sgSa4UqPw5ryq+0mz5TxCNFTQ2jZOxtb/8PnO4PdFYt+9Uo/7dnSd0RwjHMHRVsy0vQ2PitpnGirN43mkzyTIK2GY+Utml/o1hF4Ao7NJcOki5i2Z7xSYJ217GnfFvLGjIe+pd1WFJFl8U0GjsaHCWdxcx3210Pk2pTXyJRSCMwhnFHoTGKdjQ52PlOQ3IYNUdpWiIbPsrdTLOuoxbz9UNSb8SVc4mac+N3rEnAQI6fZ8+WKcsUL7AhFwTuCnce2FamS0Hs1+jBhb14VCFxgdFtdUSnEoMvSMinRlJSACpsdx0IziFSQP889lD8y7I+LDMeZ8JE6NLLyAaZdIcdeNJTvI6qAkh3Uh+D0bv6my87bJY4CiI419TEr9DRhWewjOfkw9XscYwoeKP0uOjeqUVDpvO/u61h5WglsserC3cKUd3lOv48BQr6z0ev25RIOShe0gjUW5GPaF0oCJtGnz1RmiRedRhK869P1rgy7XWif83mmNRdz6ByM1GlFUVkVaRnxykquwx3vdFxfrcAb6fpYC8izOD3Qv4zm3sTxV6m9RQWarQqCLqU+EqrWaFe8GrxrROqv3hIj47JsCz/XKxzMJ/N5Z8k+LzMzOeNhAWsY4fU2slcFNFbqpxPBHfuJT8tZ3vmFVgnCLfdSasbrrq5EIrnjPLvYlz6DrmRtn6M4U+KP4LpHEczMVGhJCE8GgAIOanryd/k6mWfaz3ytk9fFNLsBGw4/+Y4wpUXyDR4gMEOplmgobhhxAPdN7Awzl5pygN1DQByTJMhRnFD4Mvtf/dmFSkLe6fbMfU598x5/BXB9DMrzgkeZhKHqONCmOhLXA94qY13wKf6Wme2Iy8lHYUyqCytIipRb5oR9/y36EjvQ2FXIXBXlXPyg2eH0Nerx0LXxSMwgxoqIhGqjUZ4w9QHTBa43ehAi/t5ewDkMZkeFzKPVYfOx7G2uZeFjm5xri5RFG2vuaGwix8HQxFJx5Sa/DP1J2jA7sNcE+agkCvcTElyLRqFVKNITxgGa4BSEmgpAMU4Rn6CjWs22UMIueU+OpP33WxcxTj1m/WUkVyWiEVWt1aBvgqT9vEFcfz4d6TPkarrB3xPbX3h3XCj+OSVE9fcfuY/ig97BZmbR+a4F/ONRG8c/3B+PtEbUUMEjLMLZ6FJ07y8OvGBFxPs7XeLUNW+1z4qdzFjZyo4KehQlpcVfacR3OqYPKW7IOulaai0M99dUbirGeLn9wfwyafnND8PsbD79HCHvMft/7BE7Y2fcEGOHWtqP8YkggjtsSERc/D7Wj9hJS4seIMfXn8+z7udk41sRTP5XrsddIDw48wN4qo06QrUdMfd/Hun5lvqE8EpO8spyBRq/cU98dZkvt2e9PF54P2LueVvaxwL8LnJNRFu5HU94a+UN/Xm/uaf4c6L+bl0U9yiqv87aVp0r9LSqZ0rqX5RKFT4UaZgJuLdHTizDMHm8YoaWYdbYLEp6hdjhPDUTA4jN9RnGN1c08z2oZVSZ/dX0hz9y/tjpJqS80Rx5imh+J5bREIXAUMzQU95011qKBQnLhDIem/cYMut0yjkImMaosZnBaum283QNMzEyKwe8bCWkKv2f4nJgQLKB8ISpiiPRhvDH+M/HC1ugx61Ntz10MwW3bTBDatp5nIVNCRUTqOjzXyuBKkS0Z+0wepDBOsCFnmf3D2FQAFkmujdPxGEdyIRnTiJXUC++ostkElU3PqF2SplJGVnJ4RvcJCZSlIqNuIXZRxAw9HdLf5Md+x6dtCND3dem/23313qDWn2HDh39AhWOcg6pGDfF7JBVQWptn/IYSM2l9bBibCItaSLCM9Vu/ozeFvWgW7wvr794bihMaRgLtqU80Fmm4xRymkJAnEtbBwi/sO6aNaTLIBdtpUgERYApgImCdCSm2cUx9rL83bblZRGyucdugEUckMyZG+liGIRLr3IOnhn4CHTOWHHnzbugU7Os0Y/qB1Bbof/Hhc5MWJ/Wa4Dzmh+DPpvxYNzdA6eDcXKyMwir2N9A9mcrH7Cdme8d6T0sIo9HknGW2442QCNePxqy4pqUUR4d8wl4/HmuHrggtxfGHzAjIKxBi6pUOiVdOokHMjLMBZeScK5jUMMo8Sqv1vEy5aakOZYaItmwfocLL8PtHJD88IqUeacCr739WREQePLw7WrOhhTwIPC9FCJ0Un6FtDWcWQ8763PIo+xit7+js2CDpZwq/p36/O6MdymIoF49/gpw3PfVtPtbDuJ4Ev0/G2Qb8Xudu2zb59u/8APTL1kVvvPLrAs6tovmdupzIiJeonVi5udlcHRvNWhpWIcfeeAz1uE3lqVJ/iwpCJbXMTL+C8W+mKCxDSWb4vR4a5+WbzAaF0+Y9bqoELXXWkXnqJ5Fo2iP7XnuBmWpbk5kdnPnIOShw3uLLMWqRiAKDG3W8885jN5HIHGNCmxoYiL/aKfd8ZbGRDZ5ZiAmZNRYFIz+vDJutlTwRYnOfeWLOg1EV8fMymVMaU9+C8pERlj1P/RRiaw2CUAGukV15UsoIjWBBj9Ab1lfti32vgqa/0s7eWareZdyG1y2eM1Y2QpxuS+KB2VMvEq8xlHHC5nmlzd9UqW3zeVRydXys1NWgLFIM6Jxgb3jL0CXqbVnXRaS1XQv4unSBvK51GgNZoJ4ICtibDIN0KJhCXqSDRHkqoKiBauM4bhJq5/kA4RphsDwX6D1Ab4nOMwtra629fdgjDkq+qZLvjS+zM9JpcSHam3nlPZIooQk0WXw2RRJPPcbdK82anvQCe7M/P/lL3EKybZtHirXEaye5Jxq30CaDT5RIr49ixjlBoc/KHKbC+tW8x+76zoWsp3Xy3XntnxsHnMWE98zfSvQ8lybpVajTI554r/EsIFyXiwq5e0YPVn7Qg9zpjtV1qaFPtC9wEv1tCsXxZ4wVxoKoLBtr1+pnzC48z/QkGIUmbffF8/s4V7khDc6peG9yKZnThc6cKtfqcEFjokNE+L44+D2jUBZI/Gi6uKuD953F1Nuewnll+H2IVW6bZb/fjhPlobLbjaz27MPnujJ/d+TGMZm0uD2ofxbiCzEpG0H06R9OqVdUi0QZS2TE1IMi/zgYJwb8fsxlQDhqnzKlHtuCteIQJJHc2ONveCjzbKH9OFN8s3GeJ/y+19E99evsRwHZZCaLhCpwCXwemi7ZZMaF2RkoakBROWXbmjz7/D23ZpN2gzxkqKcM4fvUU/+0fIuXLPFWgOqIuDiyZanzEGTCuGWHtQPnhDsmNEVEk/k4YY6scpp4QxNeVKyvn/cwnjYswyFR3kiSpkSd4zHnWBNINCsW+szXvvaOa8Mxebqup1aCg0HfM0KsXXgS/J69p5M5w+MaL2t9815Gh2wwGcF5TBbYCx5+b+2sezH1Y62WWh2OLN6Nnig1DGEsJAiNvrLC1ol3GXUsYJTaJvzwTOiNbhsAgVITH7Z8HVSgefbFZ+Q0kjqi5bv/YzCSBuMd5d3A72ezCFFDT2fTTLMgtCUx9aWIhQbgHlFmO/o/nxeI5wYmX5K+lgrz3qKnS8QMPeoVC7k5dH+tdXjqqzPQYGGFoiN+cF+Rt0V4/bxgbePpRoxts738RPg9vDsan9UvJRoXfZiCebsU8hzqBRppbXk4ooVW9H2GsZAiZLCZ5xj6O75GWHxXDEjIo7HM7PeOBvhEeQrDzvJTmPBouRuOhGS9iWAaVBoJXURHMb4WIf6SKIM6p8ETLdpHSL442gphA21HMCSlfmsip4sFvJ0y55xLV/yAdlNYVym58p3mYhmPnSimPkvoyEV/55j6GYLHhkaoz2gyedRXcyZgnYbEo5Agtyd8Is3gqW9NtuaVz9PFIhenxZ8FRQU5+sVIF/CoF6MYOb8f+y7hGXyW+f52y9MAz9CyxBwzZX48g/IWE34B3aH1X6qFVbnY6cyYFM6Y1lEsdEDgXALPwbJtbcbU39C1oZwo78Z5uL0hb0LYJ3JEbA6CHFQJJRTlDaY7J9qjFrZkMqu2x4Xh94hAOG8Rfn9D8PvZ71qEmcDeLTlaVjA6bwlt0uuiVbZWgxLycUbB9n/GcWr+CoXfo2y9ggwpovzfv8/5gjAx3hw/tCWiY/H1qNzZw816Py6vL4zemT9v1yDLdT4px8h7tTxV6m9RyZg3KqDoMZ9y6hDmOWkU3i3vPH8onKqiBFZzs8wnsZTY11onXFf7pHXiM1qmYEWERMSuEzFLN8FuQPnGz/NnnK9DuLbWEwUnJvzsTcmz38fvCo2/FvPCZLFGXQDFOgk6xwYHsTVlr+yyLnStW2SANwC19v3eialXo0SL70SPaEwuFITa5om+Wm5b0yRoqrBtssFe/fbvfFMuryxxHirPaZw6KCxdKd7bq31wDK1XD8meZwoFTBR0eX17E0X/lfa1VkPFqIcIr5ZbV4q7LuoB98YCb9yy/eNQAGts3+D3dShjpNRDGyIiZbE6I4y1OmVzQgnn0eU94hUwfz2P1duvwupJmU7T8JNchSm5YGzjiZ4RLf7qLDtbc6zsEcvybLBgOoWuA9rDCgZ5RS3churdMYCIZJ765pV6AY+Qoz9o3PVIi6OETBpTb5Dq3FM/FQ4nrEUhzvVzKU6ojZ56PR+2zzNIf3/Wj5XDBDTsh+8L73PueRwrGcFTL8UJqLMPmTFY+xSQDL6NDHXAybym0kBhIyFRXvW3DTjle3rqfZ/R1ovngecHrs5256yfY42pNwPQa28+L/cf3OnrRjw0O5fz98KolW5Iy+D3npbFM9ca0Knq+z0N1p4Mu4Lyi9bZHywzc32R3NBjRh2vqC5LnY6BzNHRn+FzrUYdo1soi+F+rzU3Mswr7W7ODubM4XuoDCt95nY4sWUtiaxbvLyYnR2Whe7duxoPK63Wj0XO22a0Xmy+kD6hg+Mx5ApA+L0+7xGODegj3bneaByt9w+fya96NuNulkgw8HsXlrFPl9XwrblbVMl3dHe8dFoXL+u35AxU4O9oZCsC18/Fs6EyhiEGtuHEUSSUl2eNH5gr52n2+6flPVcw4Zl6dtCrPq/sAmVjH34/6kwU1izufKVY4DzO0StsynDxELu4XsggjsQrCIRDAJwCDVl8UcHNihOs4ApAp5ApEWwtFXIQzu7aYkLs5j5jzjb+6YVHAZ4NEqTkMMx/5i4AHNf01FNfl7X662rgGY4N40y9bHBOY0F3DB0m+OYZg6dxKEnosq7qqZfhvcEkaNvcE5//kU/IPciz0D31RUrrDGteszLnpP+9uTnPu1F1uLhX2cqP/WMmsrAQ66dwtBvRC/jMNNpAXab4mSEEGfq6Li4mskjP7nxu/oy4uLSpEHrre6aI6p7Q83qTMUsw/LnM67RN+jPW4GklD1jxipV6O5nW8OxfnBbLvQH31Pvs9yaciHjBuP8MBo4aY2RTT/2A/xZpspKXkI0HIrmxzN0vnXjC+VYFjueupQwYcpnWDqTP+Kz135AaWu/pRErnkRfZCVj+/HYS59/dtn6dFYbPuNAI6heeO80J07/vfiBGX5Vq2d81i78ZrmEPFYCrar/ngP1EnQYyxXnqhxDsIMxYJ+5dUk7YU49Jar2AHs/gzP2xMz9sHvE8YxhsOfu90hwyhtuyI03xY9F76llBzQyHWoNDADSzzuHevBiKQ5MGiJttQoT59oXpONAh0J4NPHWwScx4bzIU0PsEsu4SWkrMxs6hM3x62FOP13v67PexMK2a/VjUYFXczSDeUEIyw5R1Rj+qoTlFOBY5amDbZnH0Z4o9P4Lfc7LMeV4xd4Ko7OjROQy3X081JAhmWSnLP6HzsN1w9vv+9+JkBq9jT/0mpVgbiEhwclL1se4ivLdi3oIV96MqrbC/NJxIw8FMyW+DFlmdTbxcxW21pkq9KdOaDZ896paU0stwOFZ09hXxRrbZjRLl3CljjDq2TREExqfm2awoD1idcZ8mFuBbUJ4q9beo+INgSo+IuEy1HcLeyzrg9yLkYQNF3Cxfo070ng3mGRKFAcR2a/qMZ+i19DYfPHdXrq8167x2IHrI2oB3RoEwenkcdFOV1gx+T/PmYEk4nqXuMvTcW0afySvt0A1UJh0igcPgmqCMSS4YTgNoJS+tGEpi9k2ZOSr1QoLfjA1TBS56UPHu0BR5saM4YM4Dtuw649AUSH0dtZaZ2VwFvXPzeRYY2ldhPWeeAii6x27OfV+hcuUU7alsw1qOtfWoknj/LN/pbX2ZrwRti+8h7v8GiHbx3mGRrjy6/VnAcg/KoTufsDaYYClT5GZMvXrAzyjAtCBwYoLMILDMdTEB03mUSyIsQx12Q0JUXBTNwXkXeGyM6EGDzoyPL7mnnsNt7P5cCWgOVp50bmAw04uIAgv3jeNE+XYOXW9UJpYJiy+jOhYco8VJ48S1sFdYWma4yg0uTIP1akTMi5IhPk50XZPSSE6myR71IuD5S+D3PfnS6HcRT3cgT4NTME9Lcl/1EDbREDTqXMD4oBOEy70mcOAYh53D7+f8cN4D4iFzfuCZicI6+/CEh8/dExGRO3cufZ1oNJrd82t6QXslM2r73BiepgGq3xtSTusIo7FzrKEbFtLnx+/Ch2oNtFONog2+SxPlOdmE+DsnykuMpNFAk58525cgizhvaqTBWhWj33Tvd9q1zUc9DyUjphpGpqfeG4bcLTEJP3DZ7yErvIjB71me6PU2p8jHcBk8h8Svi99PGnLmjhvRyiz8T+s6j5BOPbxTXgaDMELq3wFjhSJHMVeHhiMsGvY3ykL7Vb+bpQURwIcUtr6jkFbU6ciZjxmSZNRZE4dZoUOoSvq2bbIUg9+3cdaKEoBi/eKrJlN5Dp7QdeyjiPKdFp3r6Qwk46kq7ZZ8T/lBm3PI9e5dM/heL0+V+ltUIoFtlrCnFovLEjtMygjZM6LPOmF/nN+VGHavB4VRb4FEL6IWO5yb3Ll7KVdXJ3imTIFwVjm4YQp7HcwAhaIzU0ohBcIJ0vZvR+hJMFQDxvSMTc9FEueLwljLYf2799Tr76rAaFWVvS5jLTNlzBH4JA4fvIbaj7ouzqLMsEcR9NR7xmNKQnx3Ko40B1MAhb0Y4Pfw2aDVmOnVFG5U2Ob1TADdQ0NPXWxew53tzfbqo8dnWZZqRion2IPCxh5W9W7AHPn7jhvsI/vD2eXRoq5z1Osv4RmdG06Ut6yLExS619BfpzYT5c3P6J2O/cHymOY6xA8C0xcZBhUU2qGsy0Lv6FWCdtaCoQus/2a49MJTvyFBJjS6C27eM/TRt15zY2fh2nnqSxFyvLu6MlQCn/csGV2WyMsl4GPD0JIZ7caegTlbaqV9xuvqx8IGNxEJ8Ptpr3C01NMFFxpxBL9v3ii3EazdDENjbCCIur4nvEYNf1NJmDHjYLimPA947jYZgqEoZxp9qQN+j2FrCgtFAzLSGUcW4UeJytU0LpAamAm9bExCBRWTJKpQ74X3oRxP+P3Y72OupzFHx0H8T0vGL8Ld0W6vowHIGzCcIQXaOI28HCGHTlOIcHWeeYbfs+FYeY6TForvGxuztF4snPujUDuelxWeilmHSIIQkrJrWIIG3DtIc6bilCDdsN1796/mOyJmWNEbkvRtZwgt0chwhnjz85k92l35VaPPXvb7dTEHg555NKorjzPDJXvqF6fc9fd8X8PVxLCvfaiCzPlV1F5rljdAxIcVKOpV96MIGr4rdskjDqhf1r4/bwF+38Q5gNTwjeGC7GSx/YvP+dtoOpy+80nVAxSFUHUfFkBRrQe3WY1/I4LAyfIFk0EmnnowOCJigNGe+m/ICWl1khEt0xFuQ3mq1N+i4jJJju9UEEOLNW7vBZQihFUZ3N0LsyIxtrLXEwVL9LB2uuiZqRKJrYESof8Dpt2JrlqNvbAu4i31IjK9trNMQpZxw5zBcakQchAF7z6HLu53Wrs9s0WqmWYxhv5OwUCFc8FsyEYMnadekRnA5KeHAOtNlMJlqRaiIV5xvDh5pZ7vw91VErRvLTIrTp7UmZH9XooIOrdYuNU61DON2e9vzl6AVxjZ7J821PIwCB27eup1PzcRu6cZXmOFrUhUlFghDnuC+vLc8/fMGzaFdp8zQQ1dWk8pYoktx9en1cdEFlFPiBd2sXsWA+sTTS3J2bc9MeZ+i3QEvQNVY+qbzaXNCcf+Rct+FurA3uA+Tn8utq1nNK6lr9fM7FtsrCIxcVR2hVCWgAz3v4O0ksI1+7QYbdY5CsbRAspwA5oBylKGksJn+jkyOjLPlRNq/Fg4vEbE7h7Xvmhm9yk4JWfce7yxNd+extPO8JnGuRn6vxfy1LP3B4U4Laq4cZzr5tYyKtOzbfihwFp2hdFDa7uHz3iEhRaJZAZZpMMhvKFkOVSiwIvjZqUuGHVTo4d5H/Ezn+uo/NCcQX8uT7n3dzbb/PWdSrd4RAXfkaFoDJlB5+a8mWfUnUmkp8BjnAKAvHD+KQ7xEHMdxBDEadROZABt3kI8XHOzzDwEo2C/9nIXcDlxvwB+v8EhyTzW73/zhfGOyi7aD39tJibTzSwM5/NmMfXnc5r9Pksgh0bWdalwXv0VbbXEELMi0VNvXnBd++plpcQBMhqQDWRhlg9LKcNTnycAVFrW4eZ1jNuUepTxMAGvluCpF5B9Wkv3RfDUq8xe1EEGEyV+/c3Y4xVf3Us35w2cfzY2RhGdlmVeL6kFWZPyKubnrjSlv/5rS5Rn8Hu8AYPRD3O6NjNUcJ1PPfVPy7d8Ya+eiL9zNIupt0R43pMZEuXpD42IYac4jujPOGX11G8iGvc0+1rNaocJLwTaMsIzFKrWgqdOBOH3JvC5sUDYARf0yooYs/mRn/iU3LlrsMPjO8m94DSF6N71Xi8r8CD4+Q5BvZWu76rRMMHKWLintsb5mnGoUIdIh9/P+Lfmrbbr9NQr0+U6vdKt/TZ2ERU4jimui2e6KoDZPkLLs423ApFnWJ9BrX22U4RCM6PR8cx+IvweGU7BvhMjVg8QrqeD6ItcXpzc+PmZ66tTWLuQRZr/LebFwDoZOWGxpiV9xoRwr2Tnnno/12dOCjT7MZRY9NAlgimmhVYAAQAASURBVC9m5ccwHn0mIH6KKah7cLuLCSW0+EtNaITJFUXi3nXGN4D35/cJ9z8Y9qSV7cHvsf4Y2uOFvhDfvETjgr/SKCqHitRwwmUwrkRhiaHd3I6Iz7lQRCaNF/GIrShgdY8eGuHQk6L/YoVc94Mz6nTLmxtLLeapX6ENEaWhENtavDDqki2Njq+1GyD5WsSbsw9FKYNHFiluLrTzTsmYHlIQ1MlYykouz89pQrhxrkt4ztP23FPP4Qq6GTIUFivldpVuc3U6ozbtFax3Timcd11H9dTXAvG12zYNGCIdpYIKsOoa+IyOJSoanl8bomz82EQ4i/7l5cl7YGltjefSYkJhmDka5/DasYwG7yE1lHd19MPOVaMzZI3ahbXD86H7ot/6UoJy9Ph8nnt27556nd/drPEIvx90cyJNpxHOjJ1M47pSHxVILysRPZuGH5kG4P6Fbdt16QiAtvE99QC/n/l8EH6PSn1z86dhpVrwXLz86kNR9Oo0kGGYDkDetA6jGyPAqqAcWbyDpewjqDAsRw0UmDiPQ/FOp8WhQXpfgLfputm0EhoX+kGH4waUekXfYMit0VkZnvoGc6SqCusNLPXdjvJUqb9FxSkAg3+sJ4XSVafc6qNLLZNpuGzDk8CXCQGdjIKEuyLRQ4OZ7fHOey3KTJWQ+5i7UUfiIcsSxWjfJ0yLFLjzFNajEKp90aL9eO2N52S9sHE6+D176hMPAStjmpwpv8ueiylUPGcOKjgMJR4BMerUP7UGYbJW37Yys3oQU2/3rWrCEhPSLi7W4QmbXU89qrxHTitlSKaxsFCbXYllifIUvruX0K/RHMB61piMCiUuhNxpv9z8tKjgsfDY58x/vrgcyaRwjYm579bhBFNx/2ZFfFlXgt+Tsjz2kVPqS870M7QLz7VLCgTPTSW2RO+EjD7VUpxgwF7zKJR7o8xesp11rcPD16bH4HzWDLqaC8AEyt73QQNBcJiCVbK/saNzrHjOaI/cHUZDFz7jjKPROPjEfdbaNAw0eJXzEGRoByx2Nm2Po3cSab4z5rFXE/kAKCZZJmK80q4jx6KReSWl1WKV1XAw+iH+HJVS5vpa4q02f0eYtiKitCDd0YIIN1Ra+HaQYmTSjEWoCCONJe/2DKXpn9x4uZhSTx5y4iGINJntUi6MPbRT8PIV+5LhrRdj/xgaQhlSvtf5vM45B+KoBlwRhQRbGBEnyuu0vYXPDOdno+DQgtxeX+DfqipkBjpMEpYn4GPvcqzD2kA5A89uCcYAfISvPF1WM9Zi25nMc6b1nmu3+Bw8DE3nLOLvPPLx5fi7KvEczqf12h5cLL5ex8RoBW8fc308XWhMPfBBWhNMxOzmZBgq1JGEe1uRgedtc3zOZ/H3GeNFTCk1GchkiK21GXbHsvRrrz9na64yfeX96PmAKvFqtEV6H9A2IqlcJeJvPEL4vSbO4214cVp9TH3zNHPG+oMzAcMCzKgajb54w85SAX7vUGllPmPABqiTZJen2e+flvdE2VOkSjVPRWdsZf6u77jrRJynPvf+o9vgSKm3c0UKSwEYDXmgHHROhhDXEmYpXfjoSTOW+bTL5D+ZgyfiWpywBt4SB9dGb1qAu3qPskjiqcc50/d2oP5m1MiT7XDfnTJGnly9Jk4JfK+HkqJVW0MMwXCC346y/NyLz8izz911grVIJyy1Dk/13COsOBD8jbyOKvy7LNRD6JreG0B8eE89CShbElMvlLuBGJCWbp03oT8zxmRZy4Nhh9ZblXosjKAoOu65J/z69v6DsuUUgV5OlCgPvRrunvpkT6hXYvYp2bMhpp4S5fHYymJrGtABpfRYXhrv7LvwvO5lv7flRKj0trV+j+9iysD0VFHM9TRiguCA2e9TGKye96GgVegIG0SuRx4RDe0pyTMBZUPQ+qVGw8/K+w7iavur1vcpFNJQAoqmFtr3TS4vfYZzgfOnn7O1kUQxUe/WfJ+RY9ov9tRPo7P2KlHAa3HKh13ZpWMv0wOsY3YxqIPwFEd3DOF2c3O28KQQ9tPrmAZKGDMbbdlIMg100sxYWmlwotPFBguYH0cPdH4ibWckA2acnnMhYDCBdeS9y3H406MGfUZ+gMOa929rE2rAXWwfn89t0rHz8Kq6UJS5b/1npss1zM9QEMGLyx7d3ndPlwJEn9Z2O28QOue6FOq0MzmS+sGDWWzw7HTSr5iw1T8vYrLJtnmDFKKl1PMrQvd7lxI8nqjg3py3FH7PTgIRmfHb3QBWgpHBZNLI46R4VONpXEPrwh0qIWMo2a/lThHZzi3sif6OzYXP6k/GiU0zxpM8UiFhnbRpUMIbB1CWUCRmxkenItz8vkaIeu87hZg0f/b27qlHA6vm3Jk5Q1QWVfmudadayOQPa/JtH3/fpIFttBcSA0s0LogYAkr3BiMzJyqymaEES2YLe3pP/dPynighC7vehQ2HfMjOIiLzupI9z4hTovUdytIqjTK5N5ECsFF3x/woalkM9/pi38lDMLPf04GfGTpH/azAGZwx3+7s0RtDCjHHMqz8IWtqYvjghFEMiy8tVw69Nd3HsqkA659jT73+Dgxw9qXMLjirtiogi4fS4XqtAMXCz6Uq01DPrwl8eH1JjwXbEYSUqRbYmOMz9oGQq6MO8NQ3M+woBBwzXbtrDpc6czVk8HsWPjU+ry5VXn71getEkajsTsFDK2oiFxdeOLy8IG+o+D3hkQv974mULXpdNJbTZb8/LeQVI0G9mTHAxmz71cG/k5ARZbgzpt4p9SIoUIuIxdSLV+r1HC1LlR//p7+z9529ziSY1SKWQ2A2CNKBDKj0EIwwS/bNnmeSzlg2F11JC1PhYK8iYlcPjvOOs3diiL5IgPrP1A+lTKMmliy2v5JyoOEGMj+L9X1HwQhKPQqGo1xe9RtL0N+R9c9uQSFPGxSFse/dU6+P3x2Z2P3tLIAWSAzIE35P662Gl4fP3XWIIDaeoidLh2chOTKQZj5GWOnO3/u7/0CaFHnm/vVEBM0xiV/7l156MMY+fh+82XkkWzR8wrDhKjmYn4SGun148p56pRXsqV9H3WkOElKWL0AhEIn8T4T2+sGc67d4U48m61LnwXnzRpe6VNEkmjjiLJ9MhlpBHu8MoKroJsrzBvG7PO9qTHRrSaeOY9kXNHJP+pejpT78sVf6HFHoUAi9gnFrwVsERIAHjUrWkZNFz7kzjpdy6KkP8PtxPjQ/Byr1/TN6hf15dUhTpPlixv05ptPi5Q8ZeykxXOvkml+pOPi9MyzpXGxtKuo8jgm/B7qLvMbRgCGXIxrEOZBK3AMsa4t4PqDnYGtN7ty7lBdfuu9phnhZGK8axefwBosJv289LKojHTv6Sam6wvOx4F59+OwdQzyOs5Sic8qxpx7ROawjFBFHZ9Nkgfrbtslf/9LflX/09Udym8pTpf6WlSA4qMetFBCSfMIfJSwesm4EfibdGGU9PdnrnHnqkRcp07P4IzicQ9FA4ubg93Tgt80ITSlRINR/I/yePSZzbBBv6bJZK9EFeOsci3qLtD6oU2P7suSCDuIHjGvGRpH3tA6h0ifk8YSTDQUuJ0KB7+C56+vL+b3mXSjNCx0zaQp5b6ZFukSlm+OBWRgxqGiZfcdHDBrZP2tsaxf0BpNdEPGBXibymG2cKM+k4aVQBtrmLczTcLBt0qT1+El9cAjdS/GMVpVrN94Ln2iMPZ2s7EwDVnLO2EBmcyY2ZyiIkOEg3CdOwq6L5wSFKTNEBfg9eDAa/MP2NdQRvBJdubr/8I4brz1e9scr/i5jo3F9/c4jyU8pRZZSkrwLXqidgrHblFZ/aiQcv0+FvXSCpgocx32KeDq3BqXY1kEFFhFxMbR7IRp8RZt10Xu15kNQOH6+VPLUN39ns46VjZnoAbfsxtGIwEJaD6Ey+nt9r2fmfu3N5/vvJKwZjYjjWau/p17X+zTO32uvP98NzECs9o2Jg1apx27E1uoZm95tTFhWRJ597q553eEHPJfPP39vTJtXyN07xP9Ueb734FpERF5+5YHrc/TUi4f+iHlNzWBLnvrx+9Xdi9kv8VUgaK/3i0IJ2ICL9Y5hOQPmRAehQrUsc122bRvnqU4jPip2r33gBXnuhXvhvLBTwNE9+LO6M1nHs7k3VcfXp3UoVtRO99SLX0s6BAwzV8WJn+OzIyLyyU+/Mcfj6gR0g0eiQd+rKvV+/TH8qA6ZTMeCnWFFLsDvkyzxWUy9SJcv1lomTxcBZI0iTdVgDgbj08Xq6NNUvp38QYnyCD2JPHxDWkXyYR0y5s1AX4j4K+1QHtX1mLxGM8TrfixZTL3nw2Xyt0JedqANIAdiromLi1Xu3r2EPdAXUsNHOipGZn14hlFmNVSMwu97O48f3fS2i3rQvYEnog7gamAxWtKAh/Oci/iY+qVYuOVe9nsXTjO/d1XKP/r6I/lDP/+fyP/qz/9f5DaVp0r9LSsBaj0OVVnKTJRS4P/LJJCcXM7i0F2m0YbQOk/sBJ7BK7NMSPHWb43rRRjNqNgLsPr/pony/Jg1HnOpBk07hN/D/PR+2b9RwPdX1MC95tSB1FtGn9ckpt4J8+Ch0vgqJc6zD0U94uK+y+LEUJjiXAK1+Lm4e2cIa2t1grRLfLT6K2hmluqtTYXFxV6XDnFGds9eXmaqmRcFCXR2z/UyoOWc5OkRK2zDk29jq7Mu89J5ZXH2c7F4sgaKrQnLLYwtg8FfaWK8UTTbMd6awMo3ORMACu73Bf6bQ0FOp9Urk/O6n30PuEuUN7dES++pf9fw+2lAADoA9SzA9NlLM4Xl4s+WQsljMjZbzXXptEZDS3Rv8l4OQi1BmodMNcbg9ypfzziRLHNfjJhfOPOqTO176iMdiTH10RNnif7svARPvRPyPA3EOUAlhff45dWpC49ar1B/m8DZQk999Prr3c46J3xbxcyKTQaX4FUXWH+lEdPw5w19U1Ac8zHhvcV7x2byPaAPHFOvNGIqxqOfr3/wRRERuffM9YTeaqkUXqWGAEwCiPOnPfBx+J2GzJsbpqGUx2K8uIinb3vwe0ayXA8+4VbO8dHYr43OECKXvGLslevMOIfGyZtzH4d6dNUYjjH3GnYz+9kijfWhaHYmWBnRvth3/r57NfCgYoXtbOdt8gvMdYHFrlrUvmkdnidmWj3e746VrwshxnSkIIsZ/B6MCWMetM7uqe+/zxC9MZ+cKO/R431PvSq/JzIczXdvzrN9fU8h6OFKO3gPeZqIKvnkqRdJeRzLyjruLpuKNyytFop3cz7L1TAMPnYJ/3A/sjMEaMCYv615A5e76nEa5QAFgvxo1IX7TeVE9Ko74xYZ530iWphD7FPVhMTb2Od9/+ta67nC6ySLeH7WEWPxikl9GmPquTx2ifIgDEDP5vhfETE0gCAPtP9r+do3Hsnjm7N8/Z3Hob33cnmq1N+ywkIVCudnFHgnIauDidJ9u+N8KQTMKQnsdW5e2Ly4WKKnvvmzqnGemigvXvkGMfKDeCn8uZBwhdlvFXXg4fc+UR4XvBscY+kc/LOCIhlQCTV6YZyckFy9QdbZ6bVubSoCwavAzKxFJSfesR09EeypV0hrh99nBNeSKUXv5jYVQkfQh0CKBJy9vAwl93BzG9vYPoI0H+Msa4kC6A31kyGCda6nwu9RRPA3NWiivL3EUb0+YF5D+fXe0Xhl0eWVV/KLSPTAq4ChfZke4NnVoOSywLOslfZa9WMYwgVa5r0ii2sYzxAnAfKJ8sydMvUkVQ5b3Ltd/8D7iulu9MTw4/eIbRKMf1ZPPdbBXiOGH7OXEUfuPYvxKql517cK1IlCkXnqWWnn2O4Q+rOQ1x2eQSNeZvhx7ZDX+MTzXqJ3vxuL8H537n9znhmfcM63PxFbaIQD+quGI1am0BDoaQTkjan9X6z4mNJgXnftXylZneL2lPLF81Dql1qCd/v7f+TjU8Fgr7sa1Od8Lh754OK9vb4x/wYv+5y//vs8H6BIaN2zH7MOf+b4PFwNpf7ROzdYle/QKHqlnfYjjUt3oUZ+j+Ke0v+7mHqF3xdDGeLVazc3WwpdDug3gLjbOZWUFlbI9YGG/Gl87gStN0f0/3xuXjaLUwZ0Z6z/4G2FXsrg9OjJ7HXo+Cp45Y3uYhWR/vk5m6iUsSbIS9XYjQU99SJecZ/Z75NEefpZ6TPmgEKkKRv7pamy7eUpNYiZLORzi4SYetorSEtwrsrYczc3m1wO4xUaMtLs92D4RnlUaUgBuu6SGCsN2PreKq052txEOqoS6GCt6jWHpHa0Z1CGzRKBioDzTtAJJ3Iz76kvXV4uvT68hjAfy5BD1FAiPrS3jQEhndUyc5WUkeRWk94megM6mBC5xePTvbinF7xXy1Ol/pYVPgw1jakHgXexjNMbK7Ei8qFve8ULBQLegIQxiMiE+6C1rCssaIEcEP3pZVch2JgrWvHsbHoud3laHFMfr+6GEoiQMNI809Sr2pQg6nQuqIiQYO3gYKNET70SSM8gtKhwplduaZsZfIlLBpue84WevCkQ+no1C3ddDrLfnywTau+bKstNFM7L914vxHgLKQXqkjABhL0oeUZkKWbWUWi89psT+mWKpggolqKWXXEbgYXeUkqIuZ6mYXpelVVWrjkxnsbUz2dIYJtMH96JTMyvkzL0WW9rsgzvgpbTCaGKKggUC6sRQ6O4e+rFK20xoVY0oOiNCEVMqPXweey75veI6JopeEncE9intrG6qB4+E1o7Aqa6a4Z6v73Sp6PmUIU+Lz5UhGnivNKMzq83lI16wfDq6lwg63S3djjYpPY1xLGPfk4PevUKeZE4r1J8X2cmdqAZ3M7F5eoNd/xM8/ToSMDatk1uzm3ugUZGZmeQIcOfX/E2aXqBOXJoHlbqB52ZRm+HJDBF3Id0lCk493ucu7DJ2e9bG4bPAoignbVTQ5DdFgMK53hmeuNGJZMu09gwoaP4JZnj0vLERHnj8+V1V+rf+frjWcdcUiEjMCEGsph6ZxynPeGNc+N5OHPns4ff9yvurPqb83koIjp/eMb2eYw+k3rqVUZp/kxh2JC+Voufj230F/POxJh6MshovciXkv6KGO2aSBbc++H5aLTudewkCl2rk29MRohKvoi/s13EK/mq/F6suZPg5mabiizSa0xUO2kRMMYT5Y05nZYgk4TwJ7pdgI0ZWdLV07pMB8bN+Tx5+CMwTmieKKSZk9esi7uaV2mInQWfn8oMRsYrkQe04TFD2VDpxgaIgWCoAb7iDKEo86FhC+bufNY1Enn1/c/K6x98ccx3cdeQSvPoTKXdmATT8ws1zUcervRNrzPU2wnCrVlD9rJwrDaurY5GCzWEZefpvVyeKvW3rHRvgBUPowXhBH5XxQEVYbUmPvv8PbNCq8B68p7KIp5Ba1IgEbO+iTQnsC7F7hffmmWgxuOce0Q9U748rQ5+rx4X9BBj0r/eKa/BZdZbTrzmvflRiOZ5d4p0i9mAtT/6GEJ+y1wzvrddE/JBS8ECGz9XVuCKhwGrBxk9SUzm9rLfT5hZETJqdCWNk2ihsHT//rWbEzZasLcju4Mcr5jBfjEkfM9Tr8Ko99T70pWrGrz/1rGI3ugChDcgXY/EYlo0Nh+zXUeBUyu0vuBnkebmlK3fIn1vYcjIOpA0Il0w6ArQTqI86F8Rb9DSpFyPd5QlfFeaKY19P2quCfRSlyFkJPB7HV/1c7SdLZmcSO51WEZMNcI5lwqees5+T7GtLmncFNpZQffn2xQBT2cqCZ7uWfFj+y0//laqcGDJEmEpfeZkclgH75G4/hRTXyJK42LEse7C76m/e/chi3jvVhnCKqKGVFlmpaZKofWnTot51TlpGwqKHVnmPYM6qOz+ZEV/aILZdVX4vQ/p6HtZBWsKRwqeQ0MpzH6QMK5j0n01FfJwHZk3DDB1w6Xcq+OGPPUXV/28f+NrjwwGDt1DJfWS4PeceBHbEREXX6vIPC2O1oNioWfwPKC4iEB7fNMNKYXmL+Mx2G4Z7WHfVFHGFBp4phziQteH9mmW/Z6L5tPA64SDFxHmXCSu3cqIoWVJPfu4Vkb/vPNjzpnezT765Zw/JWa/f+exhzM7pV4T5ZE8obxE4fcV6i2l71c07BkysncywO9Py4i9tn4w7ViYZtMatoRe6R7URHlTqQdDRmum+BpyxHIRbaPbOo7ucVbZlM5FtTxRtocztY3h95avqsI5sISrVodPYGo1IiIAIfyPb87z3NSlyHMvPDP26jCwQa9cWMHYz8YHODmmzjWi7EqYv1prCHPqHVf5Ist+X9yevzgt5v3nM/YeL0+V+ltWnBdMQKisRrTx0FgWXw9ZRyGK4/qUAE8K0Dwz4WuWVLF3fVMi0Jrz1KPFLUCEWmJNPC1GvIBI4lgaMSt/3D0MfiElcEJvwePBioZePZcpMDpHGboBhUc0JkyLay0EzdXM5lCHeEGaIXwoOGKyIG+xVnih95xg4Rg4S2hlgnBrRtDNM+UFAFy7e/evXBu8b/rek1ActHZRhU2FR5+FmgXUybeHYqkMzskljeaU4mVTYxPNl4POjjoRfl+ayNWVKvUwNhQca/SyzL1HyqK9XwKTWlJoIoyhqWEmnoPuqbcx4B25Fyc/10oD0APq4I8qdCyxHREVjsXFUy+0N7ugbmNT4V4Lxm0zGumGPD9q+OF7ulXA0mFnV092oQYUdBKmJxRSlR/17iUCuRnxPDT46voiCPXh2qtE8L+eWelROQRPfYmQQxWc98bT4fmoPfe7oDHMig0d/WzBR4S3k4ClSQxNWfZZtueVRjV6UZ0yCAOqsP5OmKeY3ZnLwcHvod/mNHY8QPdqj6lfKERnKJ8HCWcrJbA0HiA2n/N32E/WDbtLmlAnuD9cThyYHy261oxkMANuf/ZiGCG//rV3HJKhV+f37onh9xxWIuKSCTJv8F5S5aF1tqeeUE0Idh5Gfcw2jkqVP4O4F2JCU5E8+/1MXDfmz/h0Bb5iygi2cx7hAN5Y8aSzPcaLMoN4XmPrr7TNIyLWJfPU+3OJ+XH0HSyak0TXEtF87wZ+j0nkHu0kytNwjT34fSkAv0cnwpgeVurX0zpy+pgyzDSOb1bh8ECPLOoPTVj/QOhkSr1IXw/Md4KJe7WfDx7eMfi9k0H9/qxDES9jDyNtzvhALf6aX6aRIubtD0ZLpEdkcEeD2Qw5HXQalX7vuELUgSYvbGNO2ZDX5r/1azb+qEGe5bv/5u/8A2lF5M7dS4fQIPDoLBen1dV5m8pTpf6WlVq8V90YkhdatGAW3/O5BS+GQctMYV0ps63WM/sABKALWiZczuerMWSMpURGH++oHgo0fHexLg7u1HWURqgDPxcs4KRQNBJwpsJLVs5ebw0MO8Lvo3cXvQaY/R4FAyfAFvC6TEblBekAHV5AkZh7wl+Vl12txWRu3YmpR5gZX0G1VIS0emViAaXICaCkoGZEv0AH2VPPAntcT8tKbszcC9v6O47dKfWJpSFc6agCOdQbrrQjpT54S9kwIMk+Es+ULi/W1FPP8HvzAA6hvPq77NvZzqxTREDguDj5PcFeidNayTtrtGi0kngl+jniTOXabqU5Oo8EVDpeU+rYu1K9YrgY/H4mKGMIq3rMlnhf9EJKjCV9LK4OlCIdXRQzJqiRg5XdpZIXviVIHHqmiBmLnHLozvaTPYuKovGeZd/2xQXB7yUzbgEfAIMLC1iaW0WF0zYySGOYj9Z/hOaRBjdkwPnOYO6PAX6JMbu7nvpChqKqCbO26UHCq5d6v30ehw1QYqxQnmgfVvyd5GUdz1TqCJk05x/oUHPf27/XCb/3Zy566vu+evzoRhiZVvySujuusY1ZyGjvBHzxaAV/jvuH88gmb9nvfaK8G/D46sQVnQ/ncY8hLp13Kb/3t9Hgd/h9ofMkdOa28yaMCGNdm/lK5qlnj+OJUUZMH041rJWIn2vMj+PGOff64vjA9My3/szRlXYipNSP3yymvr+rBu+bm7PB7+HMY+LlCUmfdKdF+P3FEmkT0Qod9zPj5oiz9lOXecqtgNpSeWPA7xWOz7kBbsA40cdpV10ua5V796/lfe9/zq6024mpVzQn0o1AU8lYpQ6zSVNL3EdoZLObJnwIDF5ph3vx5nyea9ARrWxcjvLo7FehmwVQ5kD+MOowGcOMViiL6Rq+/wP9VpSXX33Y21ClXnc+8daL0+KSF96mcrtG87RMoVgl3AUst62Zpwrjb4pYorws3nBaRUfRg1aAyQWl3lndZxfcM907oh6acYjBm4mWP1R8jNmMpBkgfKh3eNuaCRYKb07iy7lfHF87PfVDqi+SCdbeG1Lm8/AMxRTqM0oIffZ7P0dzzkoSu17YWKIKyXhnQa+sMgWfBGUm9QJPBAvnJ2LCDn4/hCu8quXy6tSTGIIxCAVwvO7FEASUURj6bGPyBqLJZMHrhkx2T8mfipSIMBJFxCvK4boqXP8uB8Y8C2NdnCBNCph6VBu9g32oo/4hWUDuiSl5uHc++sn3ee9eG0mEoMun0xK8FLUUB9H/2j/8xvy3U+rRU683InDCuellX9yeMKGjmkFlXUz5WiLSxpAyhhxwsNYb76lXaIBDc9TqaJgay0KivJ2Y0mXW5dfdzSkhcSak3tEZEirJEMAGulKiFyGc5cUbbKSJXI/YZxe7WI7rVcOV9v3Bs3fnOPfeOV12b5hThskw6PlA9L6KdH6ybf3qK0Rbnc+bJYKbmep9G2zkQT6h3y61OoVzKtxIMyokUpRCwmavuI9nzJcacjeF3/f5YyQT53HAMq8KGwXRWnM+iQ5Pdj4+nwgdk4YBER2SthNTvRNGo3U+/+IzIiLyE7/zu0e/wAsqfn/wdYd3RpI9RKo5gV9sXdvoo0ifb6P1BiXfhndzwu/HmPT3m6n0o6KhHkLYP3ADASa09AYHpVvFfafnTkNG8JmleF52vjmb4T+KIGE+et9sf2BuCwTMMPyeHQ5z7xP5wo1n3v423xGxs7Su1Rm+EUFTxHvuRUyp1/FkMfWG/NPPdrtOrZQDhc7nzOWhlQ4et9CYGCnItEP79/L7nhURkd/4L/+bPibdD5uMeGxQIsFT//hmIHSW6hLl9bkcSBGKj9c+qcFOFVBcNzZ0ixTHR2cuAJIN8fpqDV/IPPWlmSG7Ccjn4unyaTVZ3MPvlU73CjRsyqH/dCw439VD5/G8DhI7EQnaXe3DY4Lfc/6bD33sVXn2+XtydXkSvCHKxuYNFpendcotGZLlvVyeKvW3rOAhQWi5CkpaTJCuM4GLEhf0fKoQvY34pSLmqXeeKiJEZu0dX5LysQwicbPZNWGliKwXa2e8zaBkziMADFQt95YZuZOlJp3QcNKgPSiis1rTfez6Gb2LMSO3QTF1zGz84zg1HYvB70dfN/QMeOuzMoHZ/yZB8FsWP+9oQTUlhbKhLz62t7fl+78Lv5/ClFf+7ty7Sr142lcUuPSJkCgvGIfAojy+U3ihy5Rbi3lhSUCdnl8yDHEMFq7TSooTJ04rIuF+cRU4rVbbg/r5dEH3fAuPX29VsDIZvvM20TtkLFnYU3+xhPNZqldk/uFXvjHHiCIbGjT02qobSAKEn0+rz4Zr+9qmBGPCUfniO4oPPfVo/MviIFcPQZ17hK+020Fi1EEjpwtY4t7U8/Ht3/nmmCczQqggpdBBfmfC76sXPA7DL0ZZlirsQb+cnnr0dJEAWPwewTnCOUZDZZb9HuH3rNihl7OvjVYWBSz0NCskFQ2zjBzTwvtWjETMtWL4vSmt4Kmv6KknYwQYEjnsZ2sI9Y4hOjekmLjbQBa+yaX/G3PAsOFTnzc4sJ7BfO9maB+sp9dBXvUlD2HSV9744IvB+8sGKzX4qfL4+psvCBfmbajt2jRxqKAfwwLrpskKdT4QkYbJd494jLZvdMfoU0h6OXksPAP0lB0bKnvYmfLtZrl6+PyXkq8d87dZJyGwsG5rNzdqThliyFm6PzbIdYEJmE9k5L0aDpo8pl6Vtd7mhN8/Bi8w8Q5d52//9JuTRkzDw8kng535PlzyZw536c9/+OOviIjI937+29wcYX4WnF81MJzP55nMlOH3apzIQoW2JlOa1nGiU8ChVZUGqPzcCG2oYwOapfTMJ+xjx06CoCK6jDD/CnUoCsEM8CMUphzvX+V/JquBTrDTj86XYv4TLSjjN/Hn2dMnr3+cVoupZ2P1e708VepvWal1BzJZKWZQf59ClLhkc/sx9Q1i6qEdJEoFs87ac0hQ74540TNY7YoUOZ2WaZBg6GEfX3FKgLtGSBWpATtCbzK+6zzdibFBBD31ZsCYgkFgnDF+2kNCgXAU/x3DKDXeqM+pF1iXwrCzsZaJ9XkyuyWiEzgb9vTUg1BR6GJbvoLGCWTFCLyWe3cvXRyetus89cQEunfDK18uznL8Dwm0MtmJTKg7XliwtGtfpJhigpbwIiT0EHM2wcnWiveEImA4AV8mTM1EY4XWe8xXKeKyGVsv9T2on6zyOmanTCJUcQgKrCy/8NIzsw4Mvcm8ceGe+vl5EZdnIpmrZfHokAmvpTvj1VPPCmqjmHof/2x0wnlohrAfQjSm9T8K2xmsPIPSX12f5u/aXxk7IWZfJqWejDocl9vHRX2rUfBXBMjZCUn+XIWzty5AV2Od+j2W7jGrdPWUzclLrzzMjXI0jovTMoV9FRbbQGusrNRT391ZLeO8gedJ+5156DBTfSUF0wubMGg9h2pgbRZT37Pf000QeG1eoez3pHDNKx1Hyc7y9BqPvzOvxY5SpwJ+CC9KvL02P8XVudCZnEoCrQPujouTNzbMnDLwjDM0CRrCi1Oo9CnHy0T5Zw13WM/fkVbA/BXudzLH05gPz5eE581xzDp2zlAbt38kRkct0Zg41h+eY8UrJrljeiEJUsOvFctJ7IDQeZ9Kve6D0R/dF6oEKtz+euRg8J56z5c5Ud7jAb9HIwIbXq6uL4Ic1Hka0NaTwu9tnHvw++tx+8+nvutNnZ7x117Wfaxw+9a6p95dDys+z0wlurKMfbJtbTpvloFwPITfS5cLe1JbMwA45AjsfUM2gLEr8C+jI3Z7SW4w0r5rHY8htKW1ESZVbR4mWm0huls9dL4I7tc8fFUNdSzj81x1/WVz51WEDbK9rEvva7jC8ZaUp0r9LSvsdUQvkGVDrsB8fBZfjbFnCGAbREUEoNt6GFq0utvB8sKklrvXl4HglVq697JonVTHQBKgFW9ZkKnXCWdqrU1B4oMffVlERD7ysVe9p3vOGRJ6721cEgIamG9GNPeE8R2lFS2OXvGFOhxBQ0XAnpnxwDA2FmxqYWtnElNPhG4v+70OaQqso9y5dzUgYJZlDeG5GYKAPfWKANC+oyUXFdYsRCEomiT0vvNOz9B7eblGoUckMP9MKfDGM9gTwyuDSQ3LPG9QT7E178+w1714C3OLAhe3zYKL9tchMyCmfnoAiVn+6BfeDu30+q2tyxND4/xcn1aDwV1crM6TMOuDNVekDdYxPWawb3h8uI9cLK4bP+3XZD2DpwrG7I5D83tZJMYlozF17m9QSNHzYUYNPzfcBtNZ7WumbPv++/Puxg+0FBP2BU899aU0W1M0FmM7b37oxTmeJsUZXOaxLsNrAjS8lJ4P4GZrMWFfZcOX8QM7j8MPpmdu11OPxgiYr2T8OldcJ4atYYhOjEtPPPVrrqRiP5iPslLPqAPOuZGdF3wf67DPTOsZnm0Gjb0rD1VGYEi/U+p3eKGIP8eCc179Oy5pVk2SKM59HvlO/xzPT1c2ahjXNISQxx8VHluf6AGchn9/9GYJdGfIac3JUH7eTjvyynw+Qfv0uuP6bztx+WYY6p9dorxiyqPKCKrET0/945vpiWf4vSr5J5coL0dWWZtCjiaR08Ua9h87cHbpPit3Sk8ALYL7uJ97sQSZMOd2draggBofsbz9SkMKJOJ3iJBiDqPxqpMBZmgQ8RY0Wgc+It6rj/B73JSo1CP69ua8DQfToAGUz0KNDqxgqyxj/CKnTYyIQ8edJtvTsoDcrKEGeJ51fmYHJPLM/DaB9265XaN5WoJlf95TX8ad0eIZw7qY0j4TFZVIVDA5yrzPGhgYx9Sz8qGxSVruXl94QbMqtB8yhNNY9Dn9QmHRLotlsURbyqw0PvSZB9fvWsDhxEMTftsi42SPus6bewaE/F78XPuYehAWSGGbFvNiRJghTr5vwCBRsEHBYDUBRvyjsyicMkAyRZmGV1DuPUPw+8l4bD4yQ4hngl7xN/iuTIvySgRaGXeE33th+ytf/ppIKdPbqG3oPzgkgz33gv1pzQlCRcdSLDGSKa7V2hj93rsSbDJFVDiWSLJXZ1GPoS8Rfr/G80nroQo7n5YsUR5f9Wde9n4zxcfeek3uP7xj8cDkqbc9Uae37kzQOEsmty+gSCLEab9YaUPl2Axq1g9Xf6IYMVSeM4hPpQDoBt9trfsWDa/eC5F4pRP4vYeft5hpnIQn5+1WQQc89T2EY1QHjQf4/UUXaF0yTFK4XV4UCAfQdjWWfxqGivGjbduCFzl46qtXfJ3hAPYVrpXSBO/h3TP6FGdM1G+n93Lb+t3agw7x9Y7s3W6k1DNKLBg16Syj0iiCsetWR5wvQhvA+zofmZI369SwAPbUY33YSUm8/3Rm1ciL/XGIC6T1eo7XheijOM8fK4N8zrXvbs6Rd4OiM2/dQP5Kjgs7y5CzYT6aGB8nfcqZbHarTh8vIVyQd0/jCXnZZ5vRU1/0B22XvP0r8XK8qQifU01TaZ7uRfXUX+mVrU1ClvgTyRPKb84jadwuvRJQdDHOfN2B38Mze576vXwUegd8Kd5T3xM8b3JzPo98A9FT/3gHfq+ytCZErkWkbT5XDnrLJ3JpM1SgXlmKewPHpsqzuwaO+QisLYb/7Rn7UBa7gdwnXdbenMzv+JmTTf1cFfHG5SM6ewO0eg9+r0kBM4SvoyOL78dTT/3T8i1dCigSzttdAM5UTCDVGNyZhT5YFzU2GKBOCmEGTuaEURa8gahquXd96ZnreAeVhuywYd/Xpd+//RhhlFMgjJn8NRlPzHRu/9690o4EAf9+ApNNrPTcFgptqpj1+KQx1h0DC4ZCoJDiBCMYzwyF0K1AQuw6Y+r3yQFfV+Y99UX41Xv3rmSpltBEx4OepqCcJczcKLNJepj0hO96VhRCUDTP3pvwla98XZp0wcNnP7YxzbHveupb+E7GL6X6tWLPWu/7WJcdmLTOFyr2vJa97T0ByPaWM+KcFsi9UKYRw+9xL9jZXJiwjsmNtL8ifo8o8gT3cnV9t/XrN1tYHQhhnUmA2BjUvHKAR9vQEbRHdsMpaOzwuQ7l3GKbyWOmQiplkI7C6aiz5gob95PPyMpxt0tyhWHw+BEtBYOSTtcJY+phjid8UZgetxDWEbz5JEQ7mKebh+qMhaV2z1hrUTn0CjcbKPA5ox17SquLd3dCbw6/V2EZ+7ltYp76GiGdZ/BuY/6B/h0hsUrCe4tfp8kbxj+C0YOMTVP4Jsy1o28UBsDefs7kn8Xp93UZ7yfokQnX1S+aX0fmoXsCfvTgeo/kIWpJDWs7CmPT/xWgCfA72kGR5zlFYr7m99wP/ugnZw4GnDMsmTGxf4V70783E+XtoIzmeSGjjj8PHH7hjdwL7UOXKK8YGk/rmZ76odSLxHAM5h0h07rbqxLoCu+lleD36rnf9FJ4iWvCuVRSL+8YI3vqH990+qRXWc52IVyon1+PvDH5s00jaHfkADKEeUARd34X23j9HfG0Y8pAEIfONxtlCF6UH5dKZ4nO1sy1NWRtdMio0Z7PH+sWzO80k7+TCQZ/QARcKouhp94drDbnB+kI9+M2ladK/S0rtXjB1oRLiGlE4aSO2F89nNV79dAix3Uqd6nCEGD2FhZRz7QW9tTX2Y/5+OwjKjAVBH+L0QHo5hzLJpwAqAIh0lLEMwxWAg1+L+EZLSw0mjgJ/S5+zhjC5+Laih/frFeZgotTBi8wCBc6QlaU9Tmn1EDCrgbPYDkRvNhZcaEPulZ3n7mSZYnX3KE3MHjqWeAixQcFW0egce6rh56xQDrh919/JFJELi9PQbnSNub8LN4LwJ4sHc8sAIezPtua8js4rgyuN/d/A4Fbu9y8px6Fes0B0a+0s3ovLhYnbCiTTxVdPHvEhNX70ppntopyOa3LuPLGGKuIjFsWeh0YGoBJ/s4j0VVQ6kno0TFrcSEaAm2EfRXXc35OhGuRqJD4vBScbE/7bfWwd0//bbB3Cf0MZzfQHr+W1l9ol3JV3Dw+O6VV+29nM86xDEUXv2WPbZYTIPPUQ7PTMKAePG17L0Y8oxFOMATtZRpMl+gRF/Fx+oVoSLansOPqVdcr7fYMf+FKu6152lz9fB3RPxGjSwXWDQt7+5UXOzt2k+ANzIweYSxwzWUwhBbjyxd0Z7i+Ewzd9DsSXXdTAvJDmp9u1M/jbZmmzbHSOvFZKMXuqXfoMeLdaATz3D/O6ed+y8eDcsYnLBjn6rtA2RGEPKKYYrJVfi47Y9hBPg8++dyTE+WJmFI/26TEu6fAw0juIUMM08UT7bnT6clX2qlhm6/LVH6bJsobnnkNI1gppt6No8RwkCIjUR7KCK3N5Hj9nNi4MA6/d8r6XYrMfeGcO2O9pgxUknMA+ylFNxE9433XEVXiE2yDoaC3kdRBxoX5sZg8heeJofLskNLftuGpd3Rm1unlj2xst6k8VepvWcH7PEUw/iZCgUVsg7fWvUyZIsmxRlOIBGce0lgmAJmi2BPlZcaDxDPEBF2FtQErngLh+G1rHn4/k/GNZ1oTBwFGlswxiu4O99KVKH8nufeW43hm/U2A0HgChR7IUjz8Psxja7P/3ktihJ09OwyB5TkUsbg8IQUEy5E3kz1bIt1T3yF7w6rfvGDHoQXaV/Ym7Xpviu0BjkHDPRHi5sbnz3z+IyLSQzIyhIIX/KJQISIutCC9SoqYkYj3tKaCL3y1DCEA+F7aV+/9TxIQriTwXKwBWcB7wnlv5v7y7XLMna4JGlBUicE1m2ic5o1OyMxvNrg2R0TclXY4b2D88xA++54VrmDUSmCvWO7evYprtSdc01U7E2XRvFBTa3HeQO2Xo6PF7yFpBtPEvvJZzSC4+N3jR+cwng5ftXbZOKhP83u7sfoS6YzZlAGhNKCQmJcBPWMRfp9Ac2k/aIcLPoNKa4g7J5isRKNmGYrwNCgD/F5z0WR7aiacrfGWjTzxG80f9wNovQhkmYffGe3DEG6dn+mVo/AU3j9q5IqeelCYxGhcTybGc9zfc/e0u7HmAn4f0+jHGs9xrR6a6+g27w2J8+N4DLDoaZRD2SbIReaRNOcJ0DLsi84ZKsSk1odbdRZFN/BkAN3h7Pch3EDS9cdtlWXMHx0cw/YyoFPqRSCmfhjMZ0y9eeovL7xSf6K8DZcnf31aQFO48BhABureoOz3PQFunAs/7ngdoDPmwYtnQCOUWiw3wJLD73t9jLzxN03p3ttAPrT1gjpof6561VwZxhqKJdf5mrd7BCMJ8szinH3aCMsRrBfMm3lapwvo2Uce54wohJRgo7Aa/+tS50KlSW6Rli8WftQGf8Qk3biGk44s3hDz9J76p+VburB10q6ph8MEShgmytsOYuq5jVHprJFhb/pMUx5kKCgREbl353KHSDS5vncpH/nYq6HdmYBsfGTok3o6FA7Gd7iKKv3jbvX5HgjxIb7Mwe9tzrCwAmfPQxukWIt4YVOFvg5X1n55gnZ+HIVxKQZVcwKLMmQgrK0UYwCokJDhQkRi9nsSOBz8PlHQNaaeER463swQkinP+IhPemL9wClhCOteorwf+LG35HSxyCXA7xutDY49s+zy9VRY+NygAO3GTIJi8ELiWWuWJReTJ+EVOP6d0f8Q97cGODYrqaxw4rj1K/S+VBBGcK71rlwcmzNcgGKzwDPnc3Oey2lHpH72tkEQa10B655DaIPWb8+7IhLP9+sfeEHCsRPvUYn3RXshX/+N8MbZb6DRuUIm7jvua/TwRVqEfb15fJMIioAcgH5y+EhqiNO+Jfs3N8pZw9p/B68sJcB0XZ20ls6og2PeoaNZ3Hnw1GOdIPRqNco3/VVXICiSp15RC41oRoTa7vXDBHYdXzo/JZ8f9tS6+aHwlAC/Z+O4jgXrAxU189Rn13NGAT/ulQp8lxEXMpQCC79L5i+DtCP9SXg3jnmPbuG+6/uJ+C6dBUZuZSXculET2Us8T2SEUCYfKAIPEV8+uduewX7sOdrbmCivgMKrV5xyTL2IV3ZFolffwe+LN4jwmvm5HXvj5K//vbhc53zObOyBxw1esxliJ6NXOObT2pXKmcV/Xbz8yAZ28ipXpSdDzlN5FI1IrEyXIi6MYIH8Mlqc0Xy2A+3yeQQ6speHhteA49BVb7BM/nPzu37Muuk84libyDR4dfSMzH9z8lB2uIhYTL2/uWT8Nc1+jG1x8u9TT/3T8i1dpjW4SCfeU6uf/+vEZDyP3oLzOYmpL17A4Vg4rS96wobVbscidn11So0H6tW7//BOsBjr+EwYSSyhJSpw5ykgiCjcafareYXVPCwxy3sb/8e4f4bi4XjwISY06r3X/k+DRINniMnc3ETYbBGz8qJi5fqSGQJQ8Z2QbhSIjutwSr2gl6X/494zV45wFvGMhzMV9zYSz5UT2E24LkCgPbQ298KykjDDTXDvksCIdXjjkWboRgGdzkQwjvn+6FBCwinez3Ps9D4Kdgt5B2je18RTH4VusqqvkTVMpW80fnliT33/N871tm3TUGXwQK/8GDLFLPQ9+Q7A70GpKTQ+P5bmFDuRCGveM/xgn7K5cUoMC4gzJ4ZCHv2Z0nOKyr71IT/ve1cR4VecbK3To9j/BQ70o0eg1KugmFxpV+DM6ePzPYBKzjkpvm027noUhc4bh3v1fZTdsjHb2FN8YQ4KdDpTlsL8EP9yCIPZNiCExnVN2M/McIBXtnaDu5jix4JzopAbbbI+4N/U6MF7qBL8Xsucn0rn4fiKu8mrYSy4LhenVXhJVI7IEGZYp0inD2miPDaClL6WG+wrr0QRdLfp3oM6cOxwJtCYH+hWsyRnc2y8TkRPg6ODxi8S6U7m2CjV7/+ZoHPv5o7iFSsct9WRG+wbjM8ZzgAKrvkvRAw1YjH1ZvS9DPB7nyjPGYjDmSZlEOYWb2Ryse3ouddxVAp3WTzKQddo7tHhRCjirzjunvqB5CRP/SWNI02U15psDc7EgK/3rkaDhvKeJuLD7Zy4Ag6ikiAbHM80I2+p6CchQ+jO/u3vjWc1QR0YMCaPS87ALp2d/KEbCPSppdaAbuQzLiLzmkDOBWBz4OmIS+ydyMzv5fJUqb9lpYKy4QRe0OQxczNa6W9GHCsLTQbFNKIhMjy/Ig5OqXUiBCcrEc4zCOrIDIoKuyfE1t9uJSUvZSmBwaFgpUTVCZJrJBLsqQdde8SxeiLpLJISGTZ7xrQ/jhCXrhRMZYSgtTePz4EAeU9ChM0GwbBF4WcKMNA5bucoGRcqK9ouZpV3fQUFLsCGabwVKbF4r+GeoMeQLt4DmLtAmVFgAs2Pn71wKnRMJSWEZETFAKHgWHYNaGJ1QF6iILSJeAXcx2H2zlSao4uLJYy5w0nxDOf7tf8d9ZAAM+kIKDo9gY3SolEPnWdEMehPlmF3Nj774PZmQ3oksy3PxOnaQ2L8WVwylrkuReYZYiPIiRA+5ukb/1MhDva/ZQu2IfKeCQbURGljwTEqdqSkbpbfRIXidc0NKAiZ1/rd3FB/WWhjFMWoDIxyeYZovt8c64zKoP3uFHCYoyf1MyjXrt8AESK+iWE+C+1rEUucuBDN0Gei4IzCpv1u4/J/2QO6h2TIksPqU+tCBj1a472EYqygI/x+Dw2B/XA09mQ8tSsxbf4baafLUVF4rPlZ8OM+DnFQxX86JQoqKTQekHFYyult+8/BsE8v8Zzde+a6e1xFnFEH32OEUOAvOu/Uv8yRYf3oDbz4ygMREXnf68+5efXX1Bocfw3we4yp9/tUDQB6W8QFGYj9uTjmk73tJMTsQFYSEVnH8xhTj+cvy89yWv2Vz+u6uPk74ThKlIvVGNYz95s8WlbdYwlaT89Nse9mv1SmAxofefn+lcvTCSjK3orrq6sjOTdb6/oGnhPz1HMdUSayj8ZrMCRvWaISz2MTEcvdg+dD/za/9sH7v6OjvFfLU6X+lpXAOBPhvAoIbiA437wbT31SZynRe+LgmiAIYwmZasUfzkl4iBCYMMJxP0Mg1OvoSNDWfva4desHEuX5zmSSlpV+CudMnEjAd3Okn0tcBw+ZGmEQmxHvpXrjwc3jc4BW49xHCzetDQjr3puNMfWFuzn7h8V76iPsf6k1KKDIsGrJPGZ+PfWue1980pMQL037dw9+n2ZTna9ZCIS+w4qElJjJOo4VPgNDwaZCTDIzdIHM1WA8wDjLleD3pgj0/cqxqP1KO+hcoqSiQhHPff8bMxb371Eh24YAg2cE5xY9zbgW5/PmaI8ToA8US7yeRzu+JmEdx576eHa5zd7f6O26YRjsFKibgx/iWKdxlITOAJtUYxGOheOMyVuic+H2mUT61BPlWbvanxaUWaLhSAeKF4Bd0lXgS84jVDm+sY/5hrx/s40dpXX20UFJjUY4xY2E9+DJgjoxJKfL0KPO1Yf9sOEvZtgfygDmu1n83heJ559pExqBRbLbAaLRgz3k/FwGW88MfC6hWO3ricYGfePi5I1oOBb0guKZ+vxv+bjxp4VQHeOZdeEr7VjgT2QXR5db4NVsWNG5wds/WBm3OdKznCS021kHNyfEZSO/lEjrxNc74fe6No5etMlzGanhQw7ZMNT7cXXd4fOYhK5JoZj6MpGQFxNSH2PqdxPljWfxdw474PPpeMDgiwF+jyEgTtZN5s7dgiFzwxFqu/eN9iBfj4bnkWkbjqNp/Pigi9PAS+u7FEv+PMefyJK4vzLDXkBUAV81Gm+HrSvT4upYSLlWXWMbqDpLDgv9IJmCDS3ReOrh92ugTcxjBsLVyXO5p14rjYbk26UG367RPC2dkAxh+40PvghWPbT2e0+mCePnwOCZEIpEolKKBOY6hRTN6ikSmRpbMatZMR2D1jHIIBggjISs+wXjHD3R7sKceqpyT91KkCxlPnjfqWMyaiVNBINZ0KABArzOlf6tQ1Caiv7iifHN4zMQxTLhA8b4gWlgX6uH0wkpNek99UF4JyUAId8lYTSFFABSSNiKq3OA3/3wj7+VKmxSwAuXCOypx+xsMXD9c7wGycXUUx3BA1SKaA5AVmay76aHluIaFlIu2LJdi7jkSihc9fqKq9NZ1JUxZnf4BlhzoizVMreZPqNtisREefq+j6kf8HvYmyU5szY2qyMobKLGBuv37/vnfhDmzGfyTedEEgHlCfD7MowrWByKAObChAs4U/DOJGk7CtuTaC/TmgBJHueUkTRMj3heTxeL8/Ro+7r19O2A4Dk4eyyMz7qK0fAsa3yn4Xped1ATyWentxgpizyN9npQBsULtA00V60m9WTRZxFSGGoNeThs70djTLr+k3/0z9l98G4NFkbuAImGvchIBVZ8RTCTf+e77EHWvutd3lh0zht9p+XZ5+7Ns4Hwe1RygnG1RnhzMIr4boRnAvJnzAtmv0eWi89kjhE0gPq+VGGDPFvOw60bxQwyzngC9Z6YvyUIrN6u1+pR5on0r9dvzhDv2HE32lQz1vENOQi/71dmCnymK+0o+300zvjPbKTk7PeIFLQwAnH7QceEMfXqSRc58NQj/V2rk404i7+70g7O83mgpTSm3q608+dCjZiYy64mvEWK0Q6WI5i3I8Qfx4ttr3SrSmooKBrGaPRtViQJXUnWNcDvm8qNxsecPFdIFht16Bo6wwmdL/349J76p+U9VTCx1psfehEOJh4EVCqN2cy7NR0EEBgjMHDXpiSwywkt9cQFC1sPi0DCCzjws47mPYKZl1YkXl9m2e8Bfg+EOEsaw3WoZVXbeRIcLAgKxNALfa8EH2Mu1+q9PzePzFNvSru4foVYeGLIGfx+JspzQovv/8LK6OLXlT1/HJKh7aNSk3rqoZmLy9Psk0Krtf9OKQgCe7aePpxChSAv0Od7Ndtnpdge0e/muwT3wvoW2MvhvaBY15nkaPZlCg1D4KC9mCVXWlbPCC8ukiunEoEYmauIKYz6GMPv9dnzeRt7bCTSaV7IxYSMHQpn40VPPY6lwLvYz1fe99Dtb2f40XOUZM3eS24ksiNc1znjEymSefsxMVrvr8C5Q099jmQJnu5EqcOlYyiheQ+/Ofq0gLDqPPUk2O559UQkeBEXoEezLg2P2Om/0kE2zOLv7szQ+XUGKB3P4hUKjkvmPeXXAaDgMA8hDn2NxgkR793mkBa8uQPpYjrWAvsJKnmSp34BhXNysLEX3RoQDc0grucQUw/GRljVy9OaGqMq7ifZX4NSCgb6zrKSQhXoZfoZrTORLvN+UgaDiCqjL4XqgTpUkZj1JnyJlI3oqY9nNBg10YAgiBDyYT9aVFFjpMZRorwQbkHz6u+pF/lT/+IX5LNvvym//yc/4+rBRHnsgOFrYS8u8ptUehtZyI1fk5WU+iyBKPIXhILbDRVxv0ATs9+e7lPWfULNhUTOQT7rhmBMflfoHRG7FekEYSpISHEP9vNLCBa+jULrqP5MGn2LoQNBBhr0dts2d21eQX4Oc8dn7erq5PqJ8HtbpyT0MUH42hXGuTwniA6jNWRa9V4v65MfeVreS6UWiKlnQaLYQ7bBPWw2QnXoczNCg4lUWBlx3rdSRLOu+74S0RhMn7NpOgJf94V1hm6e0MsuwOAae+r3YZNOKRzChhNAtE+BgeRjZVllCtLDIuk99Z4oPsaY+vkHYZQl/l6iksceNUu8AvM8KvhP//0vylf+wTfCeFDYRkHpk9/xhvw///p/FQwHMwHKFGITBEjwuvs94q+0037EZFOZQMqJD8/OU+/nTL/HsYZQkWKQL4bMzWeICWL7uhMcDJjaraUzzokSwbO3945TBEb/Vw+HPV2c5DEsTWmR4WZeQhVC9dtLht+POm/O50kDWoPzN5l+me0yBFnrDvk9lMmT0NMt9dbHBpMzaRx5SFkwiInBEm+XKhpFJLvGksN2WBmzdo0uLvRMLaTU0Wdd6yPFH4Wh+V5QXGL/TrBH8IyiAC8C+3dMp/OY1Yg8UWMgevSEzi97Ymox+htixlOlNQplSDv4mcivSIBFJXecu6AI07xHYb//23vqvbC5LFXqNO6ZZ9j1c0cRNK+4N8Af1cGe4Wn0qFHI7f2ha0E3GwvvXRGjz5y0TN8pxaDaIiI+Rt3TB8x+j3vlSGmviQKQ9oPXuvo9XgSQNrh3gOcjfexXsUI7zTsl9FU0FEF11hf2so823DWAge6odzzJfg/e3dag/8Sb9/K8TKM1Pl/oSrtS5MOvvyD/s3/9d8uv/9d/39WD8PtlJCfbu9WC4ffuBieWQas/F6U1OZ0Wu5qX30lkoZmEVjwCBQ0gLZhC9LpG4KUrw+9xHMk1cInjYAPZmGWeSTdak+u7l/L6hx7avtF/NBobzxftxfsPrsFYLtORxPSN5QoRT2sUZXDWMA/H3/3tNTYWq+N7f+CjdGwAfq/9WI5ptRpq3LWECb3D8xevtIv8471cnnrqb1kpIIgVFApxg4spbSsc3pubc5q8p0wC6oW+BszJv2Pt1qUmpNHqdv8umHgDvHQ7ykYGvy+lhHh4hFqrN7wAQcygaNPyN+/B7IoVM3SR5tEMOr9EJyKD0b9e8JwMs/kYXJHhqaeKcY3vXF3YWkFnzAijtlU/91lGdf355eeekY+++aJ7XvuLfdA10qRtrFzrWNHYk9657RAl3mPm2tO+E5MtNYdWT0/9qkq+vz/aNdEkCOw47cr8UED1ns/mBA/ts4jI3XtXIiLyyU+90ftHSpE3dA3oHSSysRZsvDjNmXd3JU/96VTJGx2V1An9xHGTIH9BdwtPOqLX0VVTBnDt8f/eQ+zvuq+40NCHLORGq/SxuKPehKYttL5YvGJq84FxqdyPE3m3XKK8WZf3Rqr3BMOiyhPWUvuP/WOPCj8TPPWDvmLbK62D9nF6T8ZQOcadY0ZRUUNvWF1o/lDAIkVMCuRFSRJ/4X5/9oX7UYgbuHD9mtc/Q5bh3v/uz34onffR8VEnGxcI0km8Bz1OeqYwnwQae3AuQj9oqKgcGerL+vHs8/fSfBB4tJ6U6doMoahoR8ULodTByK30hL7j3/XfeOuC7RVvnCzF009W4lMEGZ2FzLhciiF5fNgQPQNnjfcgr92CXsv5l3gqGxNFIc72LBo5ROw83sC1flg+8fbrPm5aPHpDJMl+P+pAozWOZTurjCJ0Bvx4EH5/FHuO49Ax+DWKe4XXbF0Xl6Su00U9b5EP4B73iASjiZwkVMfBnnoPv2ejklce9xJyFqC5jgeUOgz7nbdpCAryxiLeWJXlxMCl+egnX9tBY8ncZ3xVcAhRmmukia1hfWGOnQGN7qlH1EEriHJhGZ/prB8byvyZMYcNslly1ttUnir1t6zUUiDmyQRrjH9DgoBwrptzh9EEoZEIaOYNjhZzIzBalkG4X33hfv9MXh30DCFB3IPwd4sbH3AJnno78DKVJIPft9RTn2VLH4974WF47oNgIDtzZgOZfZ5zpuOHdcL3bm5uIsGCZ+7QNYG9foqpbF4g6fNkzHDC+lmJD9Z8b7XVds8WOEuKhLcm67VwXCdb5LHvjYRI7deRF47h9qp8uazU00iFfYE66NottcCj8SyMhYXHUZ/GQF7fvQjtFCGGPrwJptI3eTwyC08GSOP1aI3OKSsJIqdTfqXdnjFP95oqwvoUZ/rVPX8+n6eAJCLz6sAnGemQFs3rNbkPlefIn702XPUBzeGUAX9PfbyX2+8nfUcKKuB+zU97HjOltYSGcLHP88xFIdnRvuRffGaymHqm6R/48EshHGhdbU/gepjiNoQ9DdWZ7fv9uxQWam3NNYSJFcqFQqFqsZj6AC+n9f6ez30kIDWANM454sSme/RLROTBs3fd87jm+jV74Rg1NjNrY8Z43suwLx2ybZTXXn8+rBOv0YnQMv0Zm4/v+MwHdzxXNo9o2Nff8kR5O1d/jbl5NGgTezN1fLXmNFzEr2tZLJcDdnuhhJesoDMig6G72nfHLzhR3gDkqUOgVgnGTE6Wi3QLja08p3uGfewvllL8HGk9KFsw3cFzf3V1kve9/lxikPQe470rPX1WeOs73q7E/AoLe+pXl5zPP7t3k4p+3jVkDtq6rNUbuEqkr5yUdfIrt6+r6CpquBCeG0a9rYs3kIfkscTr2NDPYaqV1lx5gCWkM3pakAnBGrHRI8jn2EZBuWcfol5LVKY7akNmvzjWfz+kzz573j32G/IuCs/isUwHS5b4GAts1jA2jol4j5en8PtbVmqtIEiQUCrx0KP18pxcaecIRBFBgRktmU6xKKiQV5HSiePdq5P8J//jn5WXnntm9I8ZsiewsxtTgW4Dot0/7l01xl52DEdQD0NvuycoKVSHSITfmzASoXWZR8UpxeD5NRilzD7Nea5wT31iLHj8yOD3mtkcGf/11UUiOCTKQ/Fzz/fSYr+0BIsz/gwMBQ0oR9nv2dMpEr1fLGybYOL7fuSdmUo934hwAL9nlhDuOx5niXM1zDORrB2eN2wjS5Sn9ajguG1NHjx3R7785a/Jy68+7HMhfk/POQNhU+URZoTrWmVBkVxDSqqf+4UEd2W22l6E39vZQQREj7H3a9/71hyDRSVeadEcGtAxFozSe2nhnb5+BrFlhezE8HtaE5Gh4OJcUD9Wim1dp4Bj/cH9j8q4C2M6EILYq5u9o/vLw+/9O7/rv/05eWdknZ5K/SnLxB7DhSJUF2ln7Nvs81J9fL4qlBkNr/EGEzdemhM2oPbvrdcrC5fJmdlV8gvnaSizX164X9J1wCRcAe1EnkN9Tstb3/GG/OW/+us6ovF/5OfewzmFaTofTMttLNqPePZLMpaJeBvziddslVLk8bxzfAkygs7xpCeEhkIPdMEXxejZuiwO+l0TAZ/PCydrdcimIQdwbLsU5E15+ALWw1BlfTSirjwy5yimXtftScbXcFtPRrtKrMMhagJSadBgMFpj2JePqffnCMv1QUx9hN9TgrnNCRj7Bmfohz8LQAOVvkIfu6Gvfz8RKLqv0aJEY2TEAV+rzIYFVh5ZJphbC4x1YazSadAGZyZDveD5D04IaheNg63Beuq4uK+1SN2q/zxk6W60h7NWoe87skk2Pz77vRmpgtMi+Zx56q0tQCLI00R5T8t7rNRCsCkSHEUGwxj/9pDXFg5NFo8pMoS5yYS1LhNQTJiDuqTIR15/Ue7fvRrvMYErDuKXZpAGorcs/oqMWhh+HxU4FUacxRaGpwRwJsqDuPwpfAeLK81Ri4w0QCBJmFOFxt1HSkLJy68+DEo71nHn8gS/G9FmTwP3lxksPBra6P/eh8edm+29vQzIIt3ww4y5VrtWS5/3XrgMksmxX2SACIkPGRYLDHBHQOE2JiPZPLM42hN19neEcyTtBK9dURG+ybPP35PXP/DCuLuYMtYewNGxz1ruPXMdhcUgTNSwZ1lpONHdwvr9DXnZp3BI+1CEvJW1zt/2st9n8dH6uSdTRL9DL5iQTPvvBbPcU9X7VGZdDbw2nEfD7qm3sA4eKwpbbt/p7wdjw4LLEowxUD9+h4mS2NskIrKeVjIAq8DX3HcnniucV/FzwrlVzMhEApY7W+NqT43PXrygHj01ku53FJgxRlPfiYld+d047xmfwM985ZNIzH6PFYW9L3yW/d4WsTOk3cfQMaQbbmzjo8kA3lTD9DxTCkSigUIdmTokhd8rP4n9IMg+C/i676rP9q1UkKHPEWbMiKoEfi+JYsG8ulhOhMxgryF3aGRzj6hRl+Uo2qdcrQtD0bmQsouyFIlXaXI4jLaNdHEhT30wapLcJMBvpRSD30MbvV4/ILynnuOYuU3v4Y55coK3NjnzDn7vZN8CDqEy+5p56kuBmHrgsbMNCi1hBZFD0vya+rqQdu0r9Rbn37Pk256bY28+3K/LQLj39o2taLlFuYpDcoIyrbJJa9NJxrInozG7kZqMpzrupU6HCNI9dqhk3n6R4pGXxers8zNouqMj8ZzclvJUqb9lpdSSWlj7F+MPxG4GSxh/LvFKHBG1FHqBD5kcwi5n84GJMUP2V1MgI8Hx6edwHdIgBk+C328Av2emrQyFPfUefg/tEhHC+cFxm4ddf9ffQLCqUejB+ftX/sRPekOIeIJ0fXVKFGUyMAzJenFCfqLUhno8Ic0MMiJC+Rz2lRYmziJdkNr1whUB5rMPE9v11KsHdcbUn+fzmaXWWefXyFiK+IRB/A4rBtPbtJdQTbI9MZAlW3N5IFRBmuOF7u8nDttnjNo/zrob94DW1f8yZFJfP5NCrtf36O+DD/d24KojPIsaU8/npjDcvPobE/z1YyYYsBFqSfbI/JwwfBeXqiEscIYmDHZk/nc0U4VKmPdafQZ+bSsT6Ox33yf9juk3/tXxMh1mofiEmdin4hjvqb++6mEjH//29/d2SEjjc4KeMW9wMeEx3FMP03JKlVZx3+3GjKNweUAjsgRruO/2cgEwnXGflc7QPfVap45dm9V5C6ijoAh6nshXgWlb+ViNZxWrIhrKSCkwJc97NDdaz8eP1VO/xn6owpQY3US8olFg3yFaJxhwwzqSsb36M1qElOvxTjBeSpnGV+SxnF9kxtQjnXK0jMenL/v1uHN1muOzBoDutAb0z68VG+R5PrRtj7jyRoiAhqnKy6ODRUQolwKO0ddzCUo9n3M0DrKBk+cu5I2BdW+wizhRHnvq8TwhbZ1nlPaTu799FI415xBQf099Qmec/AbyEKw38+EOc289wTM+j3NS/flhGZ73vBlwRXwCYqNDvJeCDDTk1fO4IjoLdfF8d78f06El0o0vc355b+TILnTczXkY69KaIqu0zsWFgtw2T/1T+P0tK93LbIcUD4B5B02oCleCEYF1ybtKkYfP3h3tiNzoM+PvUovcnL0AUwbxKQorx76yV0K8EGSGAXunK3pifU+YASfKQ++xeoEsyU0VpI6zHze+Dla2g2eDxoZ9/uSn3piKKCodOmfW9w79KqVY7D7U++DhHS/ktc4sdbzXlzGmXojA6zxkiu+sV6L1EhWdAL8XEwTShCUi45q3feYl4j1XOCda5pVY5WD/MkObHjOf/T67AsXfUw9jp2trVJHYwAA15+BsffcCj663V+oddBwEQjmb17KNseNeaRjvGM6vr0/HOZshIU2RJfwM7wH0Joj0q6vcnEyFvLnzez5vfc/Ntc+RBbivgqcexrfvzR7KwNwjY+xhX3m6sRdTqvXjXzc/8BreU+89v/mcohdHwY+MTAnGM4l96etvL332B79tvmsvJnf7TqV1nKPTCkYXO6N8T716w+7cvQztZEgD85pgXK+tc7wukmDtIPyz8VjbZMOPtdJLdmXbEf0uBdFNVnOBfgdPfRiHp4dZfghMTpiNLUNqVPhNJOa16H/FfZcZ5Z0AT4oK52ng6xrVc+pRZXDn+GmZ3+F81CIQK99298701BdvnFmXOiH+OoZMwNfCN2VYP4p2odcR4PcGhUc+Vug9ZzQKezChy7yW4+P/9s/88/I3/85Xdtey0TtYT0TOeGOe9ttdP0h7d8+o6e7+hnmc8PsmUQGFOrHeDLbuf/P1sPMi8N8CP44SE+XBvm9eNlBlWQRlzr5GNzpXTXhn9HwR0JfT6m/G4UR5h84Q3BNzj8nOvqGYehbAxBtx2Li1i4opQJeLieicgHipVTbxe0hRJNvWkXkGv+/yC99mFAwFhc68PrcYYo9D5Vw7ooYCL8952V7mbVdG76Kh4DaVp0r9LSu17GWC9IcJ4VxO+agMafcH8dX3Pzefa0OD8Vl3NUnWOFjL/oHJBE0THIBw1UGVRVzc9bou3tpP0E2G36tgcbPBtXGkfBm0mmLqN7OWs7CVKaiO8Z4MjtjKUMbEE+eZxZMSCR15mESaXF2f5Ot/77GIiFxeRKX+xZfuyyP/ymB40cuIwkOmTNm/97Mln7fmPEBYcDxLSYScxFiSJayS4pWCsH8DhLWvee9T4kGbl2lbQw6unAjsRSw5y5QvWFikPaJ1iZihiZUNrGcaekbcmr6Le5znyClFxc5NgCzz2tTi9qL2p+mGEXtH3+Q4SGbgqORLiUYBNUplwnFPlBdRQowg8EbHOdxhTLQ5j3BrFEAZfur3oP71HltcL5szNRhan1AQAk99tgYs0JUcReJoOQk59+5d9zEE2KffI5xHAmPEUTjkeVBvWHbG2aOHdCEkyoM1j/k6gHZmnmiao6C0tjZoBAhxNBaGaUdjxHy6bykyJi6L9/6HLP6DRuXXwInVwWeO6D2/Y0J9nB/Mfo3fBUPvqE+/XRO48xNDCUpEMKinfsLvhzww56PindgHBqCq3sPm9vq6LlI1F8Tox9KoDh47np/kqrlai5Tm5weNnmqM51Jgj/A5nvWyfDM+z1CKUfHzD+7K8w/uesWbnnHGdmiOPfUO/aPnuZiRZPYX53UvUd7MGeMVZLzl0tF8ii1nBI4ZSvyzC5+dA/lCJNnTY9o4v4QZ663vBeZA6zjveurna7OwEyGEFdCVdu4c8f6UeGaDPF4UrScupn6pZYQVxDmKjo3ktg9Yzzbgm7UYMpKTtNZSBHHd2l7bWs//UyIyIl03OntoQFaCgjI5h9iyDKx7GUP8mI9Jaz4xLuU/yc7ve7ncLhPF0yK14v3Z47spnPfPbKUPwnhQtq1+/ad6EPsz1rbWMWlGlUlJmTlmVkyD+IGnnpQlFCiZeGUC4YwNE1OIJgEkBqEZx0P2e7TeIpFsiTIqntll1tXJXCYBqpNIqsBVSRj1Fur+j8urC/nGyDp8fXkKxoU3P/hiYCRCyoIJBsb5o1JPirKrM8Km+R2t0/ZKDcSULbso6CEMVscgkhDoQopG7YxqrmeAxWKoiFd8tUT4du/XmT31us/F9jOOvffXh3NUmsc5vlmHzLve8Xwh4MNb1HOBh9txsZdCDBaYIhp6TNDtnw+vIYKzeT57KL2jN+CtRGaukH04+vNdN16C9Pns2tY3Po+rEyr9PgxXrInSUDEaCvPF9eP5B8ckCRxmTFIPSEngiVn4UqBXTnDSMeCeSDz1pOygZyZbp4mMGedHf8kUWey/0b46EQlIw7PQlj0vInp1cE5SVAQ8z/eIZ8LmUR/wsDneQ/3MDJ83kCPG6OHoF845QLmtDhyrH7uOzZ1BHK/WAbw+OKR1LAmSwStrdo5xLM3xi+ip5zO31OoQb6FN1QlAWSnF9zN6cP2cs4Eo5HWhdXv43F3/jCLkFl0PMhpCwXCVqUCqLYJlAqRbeXXuXCBP8co+XQvGSj2tvfYTr7RzCUglMWpOT70tgvW9+ER58B6uxWllT715tLN8FEHZqzR3QSaNk+gMXDQXs16k2cqf9u6pp3wiIsOwRLLTQuPeG4fKljgOnNd0rB1WK0167HpGA3m/deXZ0809hACjOHZpQmYY4LnTMwDvHHnq0cCGeTQ6/N7WKeTJKPzZ9AbkdRN+v7VBO/o7bIhJjZ7v4fJUqb9lBb1401KbWKImcUvu2z2yik5PKwj85xuDvsx3pgIwthgQJOzr7E/tMBqXtGRaBqDfQCj6HaHRK6vFYINKnGUqzlNBCp7eXv8NKYE6pXp10SSukhBNgt6ZAOxjoXWusF0zHiiMl4XP0Z/xv6vrk3zjne6pv7pcI4EqTLRaYDauTp0HqsYpCcUsutovHc+2mXfFJ9Hy447KZxNOrOLmtfge6mMrecwqMTSOp51X2p3Ng4TeRGxbC19XpQndNthX/E6I3dQ9SzH1Pku5P6/TSj889d5rDJ56VlgSJuWh9eJiTfW9I6+hO7/j74k99bSn0NDThfPxO1r8QRlKPTQ0lqDo0mdAeHv49YHQGD31EcLq58Irxgj54/pDVnWYW51nvAt+bw77kMp8Dr5MDUM4hk9/5oO0N6OisriYehW+/TsiPsyA5wU9nPrb3LMLGFwKGAkotCXzgM9tA4oOtpkJ+M74S/DyQmNjJbYUcbzHwfqB97CXMiRwKmWG/TjFT4VLSLpV6a/2axo1Z3eMBmgds2uk8Gt3M/6PSJZggKz+nZDJv+qVnohPLvLosV5p172V2Rwj1HcPcYNKaJECeyUm9Du6lYUTROo7Otbr6wt5+7s+EOSS+w/vmEKKiocipZq2Z0qq9nHmAqA95RwOJa4TzlPvO9B6nTBJZJyDmHozDHhUhRq6Zx0H4UfaJ0vkuJ/s0O8Z8tQvRu9YYWQlK0fO+HFle9rB75HG1xJCJvoc9OJyRVSv5BJYJPfUwx5k9NoRCkmgP0jjMn7emjj4/VIKyWtFXnvpgbzy/DPykddfCLQonkXrQ+YsYUN1plyXWgC9Y+fdlPrEMFCIH7oz388WyuS4b7ROz5c8whflDHXStCY9jwTwxphs7/aUp0r9LSteKOh/UZns35vEm3rYChOAKDQiMf/G1x7174AgsLUsKyH+qxTvDSgGgbP+kcWNYFusjIlYDJgpSXbgOQ6UrYkzLn/r/rRPf88Hian4JGDjK29JRWXMfwXelXGFGCXF2V2L8efq2jz1VxcxUV4R9srJ8HB44XvukUnsXTXO08Be9iImjPT4aZnP4fsCzwVopEhEJjgHG2Z8956+KOjt72dLlBezUu8JKHGfKbTWBE/3jgoQSX0cn7oH9e7vjL3eYpKcKfTS+JZCnluqW/8dFHZg/Og1dCEZeqbH53C3MDzrPPVbc4YuVobQmMCChNiUWr10JhCiPPMuALw3u6ee1xdLdqVd74OJ1wXoU1dEYZ7gvYUFTf2+mDdQPfWclTp6rGKfOIxl0hUYwwc+8nJEN8w5639PJ/TUx3a0qGcYw1dsfIlSOvdSnX5dRlu5e+prEt9Nik7w2gWf5xDuZp3RUxW9yJ7HsDGpcJ2Lp/khv8tYl5tp/IghD+5KO/rbx1DCGhhMt392nkFaP67j6Aac3TMlFmPtUQfsQS7yaMDv9apLRvzVEnPT4O/eaKkP2Z6ON51EKO5R4kb1wk8FKtlPRUQePnsXPPXA94hOOAVRfRfzNzZaeNSZPsOF0RxzLmafxe33k8s5Ec/GrAMoOTty4u0ftOcKOGyW6hLEBnoN/XJoqGqKe0BYpnk1fPveCRENJCIEvxd4pyDdsTUz/kS3OrjRe63+RJ76CL/36LW9xKFhXIBS8SiGvtqtGcxdZJwdXKZS5KXnnpH//b/3RfnMJ98IRpFj/m/f67d5ri1aI+FEoKpEKz97gmwC/TDZWBF6KhPU4Lhjh1QpJs853UNlh5Z46snxc5vK7RrN0xKEAhFgFMiEwGrFBPMI+jSFMWjn0VAqURkwa5nAu55ZMJHoMJr9GMQiQyDDvhMBzAwUDCPriTP0nWiRRGrJcfn37l35vjeRi4uVFNRG6xDHGz31Ix9AuIeXBSM/h1fXF/LOo+Gpv4ie+s6Q6ZiDsONhWPZIFsuLQhA2g4px98qWUMfkwdBu9MImV9lkkk+x+Xs3GZGxCr7SDvfZrqd+JywAM/337/WJNoQ6GNui/fUhIU4pgvpFTHjZ9NoYOL+6TSoLcpXnrM0x4Ngybwx7+qYyQP3Sv5go7whCeT5v3qPOewfpUnJ+ex+8QoHPcD9734FWJXQiu/YQf8d50XbM6jWuEKraB1ICYd8uJ/PueY8XwBUhROLIQ6UTF5QFp5RAf7GeSu/QuUqh4Em9Kyn1bq6E6a8p6D1RXje4rKtZ61ZKNJV5OBmazrS1Jvtq/ijJ3iyZ52r/M97yMj1lxDfTvBuFEuURHUa6kiI7cJ2Ixuh7FxDDG/i98B7y6znpNPW9FN9XNkSqV91nv5eZxE49pgvtBadYNF5HlBlyJFK40i7jjwdKlNbN+4jlkg7JV4cC0GPOEq/0BWSSrn+3gCCqzpBm/ecydbzJJyUYT/A9zPgePdr2PV4/+G7h91ZobWaivObqYWcI1otx81mSySWBVNs4jj9r8YnyGNXor31DAyrKnKXY3rM9aG0ETz3lDrig5LG8X/foe4M9yTS0VJM1bF+Ag6hJ2OfRu+0daG49p1bveSY7JUJYYzHZGvMF4D5jXr/ncEEjhffUH+snOl/u1iyVYybKtrnkexmtvk3lqVJ/ywpD70TGptWvNVnM+LwSgWcBNctEKuIVID3FCNs1hbzMZ5gOL5XbkfRwSmFiMvq+I0jNz4nXUoUR9dRn8PvMi4c3CogYo3/uhWfk2z75vmiwIOLd60YFztejjGzTjMI7cXmT942vO/y+G1UuL09CaEO31loeP7oJXopFifuBwLHAs+wd06GdtxYEE+wwMlUn5LaokLJlPYtxCxBlEkjdlYyS3SfurcU2Hi+gRMhX9NTr+/eeuZaHz90lBl5HXX4/ZcyFQzI69K45g4iNNzsDce1Q2CglGm28wEMCpa4nQFJFvIeH243QcRSixRg4wL7DvbYo9EC8HZ+tzDBVoJGVFd+SwOV3aIxg3Rj+Ufx87SlSC8Gj8Qxhcr35HhwJnlP9J373oW97xSMLQOl04ztQYkXyRHns3Rax86PhKy43QyZwAQpG1wbvjQ/XknKOF/g93/+5UUeA7rFRh2lENj+mTBeqeNTJxmCCdIY8Cyjgw95H+ot/995hgxueQTbUzrGw0WN4ftEbdmT04MRp+nxrPumbeurVYxpzH+TrNvtJY+MSbrHIzvGBcYLbzfaTSFfqMSnpPBe61x2NSYx6LSqeHXXGaxnHaPKFuD7a755Gnjg5HO253jbtuydcaRdj0WF/LmU3UR62fVr9VW/o0U6TTC44V9/c1YWzTTROlDjuUmTKR0gDnae+gFIfWti7p764310/ySPMRhceBvmURB1wipIJazrr8p89P/Lt8PzN0NJqht2MnsUbCPyaRPg97cfsfKJMMF5eIKZ+pXb7O57nlCKpM3DKDluja/Ii8vI2ladK/S0re4oUemEVjqTPo4LGAuouoyCBHdt2BKDGd2dfi2+nFCNeLskNvNYhQuPAPwF+n3ru67innhQne4fuIaVkeyx43HvmKgqNAJfz47V/NxDkuW9K4U4X64Hnpv/18PvMU0+CTdN7xA0Kp3O3javIcHyu/+Bl3INOns/b7JtTNuBZESPGrv4jeGWRGXNVQCCN8e7H8PuFPfU4P/pea/5MLAz5Gh704Knv//jE2++X08mvxSfeHvd6M/z+4GyhsIh7loXlI2X6hZfui4iP9SsSr7RDBQK9hg2eQQacMcZDYyAoWUFpU2GThTmQRrQfS8nqtXnxinf/G6/niZDvCAuM3uGpxNAeZKG+C48mHOF4fHKtsRcg629Gr7SckgRk13cu/HzAPO3VEzyYbXjqef2hju/53Ed6HwL83tOB0H+3p9vMRIwK5ZMMLMGzGtqkwctYA7E2kNgEJYE+l2pt8L5w3m2oM7teFcmbT9oGtAv2kLaR9UuvHjSDS3/mgryToc8JnbXnte/H4QmWOA1u1Skl3FfOnnqkF4EPFQnrPOlDhaSoSOszSLD7nCFy/OBx7yPvnaU1uXvvap5bpIusYNvVWWXuPTQ87xkfp1yWCAm8D4p0mqbGE5ZX+MrHLOQrU/hwd3L4UVAYBeeg+kR5RIt1jKf1m/DUk+IWPPUZL8E9PvYKXwlo2dhtvXHNtUp3q0Mtjufp+LVkSryH33saEL3bAgU99drVBH1azRONCqtPfhj3uf07QbiAHKv1LICgynjxkWGljxWQESIBrRJzJQCdxVj76j310bgQ6zxTiO1sQBB+b7TbGZH2COR7tDxV6m9Z4YOmf5uAQHoAveNEFMEqCsxlr22MrZzMKVF0+cAHGM3k8uOhNhS/mvc9EA0iREXKhPaVhLjPcZGwJoLQQyV6ND5mnImyhs88fkdDFpRI23V8z9y/lmfuX8vHPvm+QEhdO03k6uo0haksUV4h4emlVx7IZ3/wo06Z17rPqDgmhG7GGZLAikxi29r8jRkJ/tW1OhLSgpcEmKw+xQmrnHdL4vrqeuqcuVsWEoFI2wgCezHo2bd/5xvauBsj1vGhb3tljFu9XhZrO/tOc4WJnza4VeDYaOEV1MurU/97AZ76Gs9vpjwF4U7nSUpy9rKrBfO1nA+qVX73LJrCP4XlAwW1Vt0jHV2A8+jWc10ky6CLfbU5kDknaBdFIWYlo48TmlTIGzRngT2i70xPfTBK+jn+wX/qrdEX60cpJcyzCHnQMwWD1tZ56pP1f/2DL4oIKPUQw+jaYcQCnK3pqV8XUCiPaTjOQWpQdmOxfdV53KiD4t+ZJma5S8IcGEK195vWKiicgQ7BXeazX/Fe8t2wACMObi4c/Fp5054ySftmL4yN+657aa7fOE8bonhKmXvj+vLk+mMGMmhfxKHK8ByjooHGwE6Hce0l7J2jrN9sjJt8KvBMf/XkfH4qAkaLZru6tjAePz7Lu8FX2mHJDA4uyV1x4on3DNO+Dl5QMAxxQk58J5UhQJZEYw7LdHMPLllMvdXh+WuUORlhedTHl9/3UEQ4pj7mUxDYD2hYuAHUHBqrstwHHIp3OvE99fGaV32c5Tc3TuA3Xg7xtzGhHMXhZlgiPSMv+2x3nOvWOmoO6TL1NSKRoD2g0xwuYv/eN+AWRSg06UntJh/LjAcl1OENM4YO6/3xiNzMAHubylOl/paVSsSwf1cdAcAfY0z5sVWUBX8RmdRven/R2ugYuT88KaQZYhAnnIcI1BSsEvj9keVevQNba5NBI9Qnq0MFmpsdT702f9SPSdThu0cjY71TPMowONQid+9eOuFX32do3NX1hf37Il5pV8T35f6DaycITyZci8uumlkv8bc9JeaMGVqdgBXrECHDDsdxAUOMsV/9h1yY3oeFT/g9IELY+4X9tDbgtzFezX/wsbfe78bEewTrVsFmI8t7NjfYd7wqcM87ou944bl/cPB7iTH16A1Bb1GjZ3QseejL/mdUpFhowfHuefvVN8TQUWynoE5PZ5gVsCgYQJ3FPnvvJwqzJrRHT30J+13rwFCDAL+v++dKpJ9d64v1NdtnUbneV/JF1NDh+5whANhTf+SJ8kLbMCwTvJKFfzTkaP2s8PJ4g+IL4xSJCjgb/tI8MtRvzZPh6A7RrniW/We+xxnrQOPH7EeN64RGIW2XDRA+Sas92+yrMRbrG9NQD78nnlIUqeQ9hf/h/+D3ym//gU/K93/6Q7Me/PskwzeeNbAXOGSeZ+dF2KjEIX1OxpC4tmG+sK5BN+x58mjDWZtz/G489URbXJ2k5JXCV475846KrNBv2Da2i1er8VqXkig5xZTCHt+97yHWuk6UK2Nd6ky4yDyb76nPkjcHmRTp4sM7s82jcTjDNdBiQ2FWZ3yEOAsbB43rYl0m/WL5TPMEGCoyhqTZ84MHSOTnOOdIC62b8WapPcN3H47fi7q/1nVxZ+3IMFCq3784dqQzGerA9SM5g553RQU8C69UwwwibadSP+H3OrYl7LfbVG7XaJ6WQPxElNB6qJwJVU+whBFzYsEfCwoo8/ASw8ie733shzPz1NtTzSkfK1uDS3WC3V5SjbZh0rEIBcNucqI89sJmXvjf8wc+nxtCYM4wOZb+rYN4432kLLQw8b6+Y0r99eXp0MqO/ZzQQejbtrV5bU8i50yBMlXYlEFuBsnILKA8f3OvJTH17DEz4Rq9Nz7zuBOeZTBqp9D5K+2cd5EEQHuHGYvfE+zVTWM1ad6zmHoTsm38+t3NGdAlNEeMMMgMSlcHMfWatMrgpDYdWfLEUoYyduA94WR0zODncxxTT4oQC8t8T7PbI4vhdovYGrICxpDJkMSr2BpPgV6EPGaobCa3QehcLX6OfN6R/hsq9U8ysGKftDEPMaZzJcfGkvld5qmP2zeB30f6hMocJl9s0iY6I1NsZ9/Y6EO09hBJBtOQKb76TkAYhDNlz/rxyawzeOqD8En7lBWgJI/Brsdc/xBbxb2XGdyd0cdtExjLQfiJiITrL/3ZLvPvJz74svypP/KFuUfYQ8/rFPoJdcnYK6ULKyISbzrhOc6VBuv7M/ev5f6DO8k+T/aP9FwcTg7RxzimHp7ZmkCW/ZyWWf9im9ynWkadkzeYfKJ0mN9FGoP91MJQ5LD2yTqh8tU0l0wTR6+1fyJDNsN8DxhTz3TuCQbivo7YhrjP+iTC7wVouIiA48nmhqe/1o6kmkaUsZY4HYieE+nhL4hO4HHoO/p5j57MRHlJCEkRzyNE0Ngo8zOWo1wTbn5xbOCpj3SYDGYl0m39rLe5ICJY+7jndNNzXiTuzyP4veoDKJ9noUzLYjQ9XpOXn//3anmq1N+ywjFkIqAQDV6JDH2tXinKktFkHptU6atGmNgr4YP69XmCBJXilN1p+YO2ajUmn94/zUyfhPVSilOa+WoQFnBUqTdPvdZtUHTtv5bXXn8+WKL7szB4gNzqX/XU9+vLtM8s5IkrV9cn+/fFmljqo0CP/UUmd96J257tV2TK8D0w/fN5c8KiPUN/E4GjEKQLDTilFs6EJSLD6+pyMwgxAe+FDeuJzArHhMailbxwBeCnMAZGbzCEUPsj4u98tr5TPbB/EQHh3/F7byHLttbl4PfihV3tK3qe9V1MlGfjKU9OUkl0Jct+rwx8CqNLotBNYbmlzziva2FIogpVXlDia4kyZYDXYmbkHjTUIxuIztT4Pn+PgpbLIHygfO4hQLwy2f+i90jrwn6wd+J0ijH1mUFhpUR5bh4TmhJCW1KY57GXjmmt50cl1Y5KKXDmnuSppzMD68le72k0IWN4Go4C/XGC9ZxLvEYwrpMiy/CdeRUr9OMoFMwb2yJvmH3fUZbZaKj1T2Mb0XUszCv53Ar3ExUWF1Pf//2kqykzAz3+/unv+aCsp2WeETaocFHI7twaO4oT8sMG3t19T31cJzcvItRHNJTbPGbGSKyDjRdzrWDvduWWaF9YbzjTSz2E36usk3nq53zRWUnzswR+G2VFHvfFyjH1nv+iMsty3pyLmsHvec+Bp/60gjE87kftS28zmdfCfYjtsXFI63Qw92Qs+G92zGF+j5kob7VQxnhjzHHGeAe/x/FxP9y6En8dsQAV0HgxtC0z6lo/XCgd0mPy1PP+uk3lqVJ/y8ouAXDPIPPw3rHMEuaIEbyn5Q/+kR9xbXdLqmdg3Df6KbHigZIAz6GFlQXCqNRz9vtOINogHNqHI0PAXrZyVrqPLM12PU4kHvqaWszPW/OZzt1axDquri7kv/t7v19ERN5833OjTuwL1REEb2M827Y5zxoXi4nLsrj2z9vW0jlhQYYT9enzewIpM3Ej+j4bLXvEuE5GXnhvmDH8Faz+a8LQcHbQs+7GmJzFmEk6MheH7Bj/7sYSv/dEupB/xDi1XJAXIySQgrlGDzQiEXFdQzZcEjCDICEk1MK+t3a9IuSE5R1PPTLxWiGeD9ecPHw9uaKnG8F7R+cvo6EWU5946vU8NL3+ySvpmCDu3OCuX5wzpIFasUSl1t1VTSiZDDWCCBAteKVddn71X0fw++/4ng+693BPxOz3dh5CMkFcq1qTc+Hp2bQXELmZsl2NSgDTrz3v9kQYiJ835pMc0sHKEa73VK4gyScad10/SFC2MyTzeUYwxH6Ie0f/OWloTVAHsG4s9GLoyDGU3PO9hZ7Z2+ulgA+gFPnEB1+RN199Vl55/n4QxqMyiMaZyF+w3cwg/9wLz7hxoud67onZtcgPp1OC1t/lAtG1k1gyA427p76YEr5WDjfIHQ2pF3fuYzbQRyVH5Sat6wh+r5+VJqJCq/IDx2NjvL2I+PBNyc5r5C0i8Uo737fm3mNjhn631Jr5n+SLv+tz8l2f8GF2Ih71xUk/OW8R98kp7PqnJsZBGrvW6fgRj2WHnoXPxdrGKxs51EUNHvZ5H/1k8+f3FjscvOyFbQF/IDkjS6rIOoYZf63qSjH1zHNuU1mf/MjT8l4qntiN72qV7eYsevSdF4Ph9yVTrj2B1e+1fODDL/W6JjMBJofnhc5OPJx+HAHiNxSLN199Tl594b585PUX5df+s78JdVRXx1KLzy4+xrKhgkIEj5mcWuuzRCX6Ps6L9iNT6DKLIApk3lMf3+G1ERFZT4v84Z/6rPzhn/qsG6foFShSgtI750o8NGxr6qmPMVr4TtwT1q+t5VfasbKRCUqRgZlAUmp1XpDLi1WWpcppZQGA4tqozgw+PD3947mLi9UxySy+jI1Fbiz0V8eHc5jB79nwgQrrBlcF+vX0eyRDUYh4Tz0Lw0VE7ty7DMrc9E7re9XWipUY9nb3e2tZWRMoY4yLV0r2hB7txbMvPBPWGzPoopcAFTBG36w7Agob0/CcOwdVsfGE/QDnQfeZ0l00Fui/N9wLQQiKZ5e3zNXFCb6wMbt3jgw/LU+U52jA+PdpYaXe1vg7VamHerCunu8geuoPDXu1hLXYMx7h/sS90z2DNhQ2/C2EKnF0tpa5+dbTInXDfWvvcDJNhc1m49BygpwpmJgt7Yf+oTXC5HBPmp9ZWjI/OBa+ao9ex9sBxP9xhQ1jjFxiRWMaLpY66E4/Yz/0XR+WH/quD4exccLPsK6kRAjTaXhPy0c++orNw6BNTIMMyg3jHFVsrSeKzZ0UNA8H8oCnO5B8Fq60q8GwSu+y3FHsOUcbBy1rLVOG1Thie2zb2rRIsJyg8pbeGrSuVR49Prs4ZlQARYYMesArIiKD9vT4JyaNLOLlS97z2blQWRCvtNMnfu6nPyc/99Ofm+9quYBEeSHcE8+QeAMcj0v3Ft/uwnOBPMAZ3HeMK/rv4N0GWqkFkUOc56DWImXDOuL5tbG0/BnqR0C0FQnhWVmukmjURVqeo6wwtG9d6kRK9jpvl2/7qVJ/y4qHCxoBO+sd5MogQLkLMbl71jTJBT7nWRRP3OZzLWEAB4TaJZ+Bd2ot8v6XH8qf/3d/TkRE/spf/68O6mDlqxNDvB5MlJgk7er81FJCojxjcn4OrF0Y54TfR+LhLMelK9Zbs2eD0IJMIbEo974VGejYaOXeUVqWWp2XfS+MQ3/bY06zUfECP88TMzyDXdE8zn+Ly0D9cz/9Ofnx7/uYg4xpm+/GU38zst9nifIu6BaBJYmXZcgijilTvoTm9ZzEJGde4omAaA3OF3qj2EMevRwifE+9T5T3fT/0Mbn3zHXi6eGzV937KAwGbwD3Q8TNsya0qwCv6389g55VjH/88G99S/7qf/G3oB1k4uLiXb3SYvV2+D0pYCTksFENPbaz3ZrXj4YGXWf8TevV98+UfRnbyAyqvN8vL31oRX8399rpv5kWr+5Kuxre0X9O+P1NEj5CtMUJYLVLbJwoj6G3rGCiIGhV+X0129U9TXRxDWeCPLqlUAiPrd9UNltX6suj0U+qM6M70ZOlCzj6hfB7mnvrp18npNtKhzmG2htTI9/t76OhsZDRaxFU4jLlx4zlnnbyc65f8NDLrz50hpYCHTKlXhyd5TqCbJIoDf53X0dQssXPv+7FzJuIzy601hqHvdtXPBJUgtG7DieE/g5OmACRXuK5xXFqLZg0DNs7t5audwGPKxt6Y/8H/H5BXnV2invMR0FwaOZpLPeUEoyoIhxTf3ydIaMF5u/FQr1mfpZk/1vfDWUQFWFPg3mflGJ1T4BZQjcyB5HKivw9t639Dc4SYyZjrGrYFZgfT9825H+F5Q7IEaPt0Fyx3FhLDB0SEQe/z+gqo1NwedyZr2V2pq7eUIAlk3Xfy+WpUn/LCjMSkb5pHzWQdQocmjQT6bEAqHXOZw6EOQeJ5L6Gdvw40lhnUoyPMp3nWamHNxz6dERElQBiYrWjv9p3Fvj699ZvVchRUVtqT0KzbVuIiRWJQspeCXNQ456IVuQyYP+dCWdrjoJnEJJJ0Ma6sU9sNCi09xq9Y16e6jKbv/rCfXn1hfujPzB29t7QevJtBs5aXnr9p4vFnY/gKUiEyWyM3qLs28+y33PoQyWGlRrUkvGywUXEe+ql+Heuxw0Kmad2esygfyIQs12rnM9b6Ct7LQTpyHzQ3x/b9yqMF9YOjSB76+vQHGL7MCTKC0Jk4u0NypbRorJ5o0H0HtgcqsKu3TpKlMcG1pBsMNlXtRbnqdff1oXWks4Vx9T7pG3i3u3D1no1fMSMYrNtWMc5L3NPiYffK/3hWHQSFnl/4DzouGYbJKyhUSfSZ3Gfg2F7i/N2Oi0ij7VOMhYmeTcktAmIILo7GXm168c8M/aqjm3epV7jvGfz41Bz4ulM8HYBf4jKj63fvJ4tM1iTgopt/OgXPhVkla3Ze5ZFnuqkPXmEygpKlPg1zYwN2N4zd6/k7vWlqzPrCyuhvZ4EcUL0L81bwzykSKRpBeokBce/G2mXiJf5/Jlqod/aXcyLcD6A3/+9r/wjEeloNxGjF0utkyaxkW2pxSVd5bMVjDM78oa7RYN4tLrdkYZmynqtBr9H1Jd7jmip9t2FpYidZXcVMNEdPpsLycE9+XOksRgaVyQaHjwdSXICEV0REVnWZbaVJi+k+j2/tzbwBghexxAapL/3jT77a4areMaPZH4nd+j3w5Cs++PitMg7BwaR93p5qtTfspIpEuxlEgFCmDDCCCUV9xn/igCTBILJQmPBDmlbLh4+Wv44nhDbwv7Od8rBARdlTt3CaTG6oHBliuZQImYyqzlWa1P7i31nppX1vT/r+9499XlcemBUOyV4CGhedVz9szGcs8bUb5FJ+HcYHufHxgKDiO23qDQNQnt5kre/+wPy//r//C1Xz5GCbJ992zEBoz2rnsYzKNUuqWMbXu3xTmZc4TWIynDsF3tGbhL4fdhTLLzQ3tN6PXPN98ilu9IuCv69Lzo+G/NMsCkNxlfmvKy1o0JYgA4ehuLn0ART8A6AB2n+NvqGV/oFY6AunwoGw1M2BZQaPfVorUdlwIRQWmMhOgRrEzzBYvt211Nfa6CRwaAYzlmZ9c++L/4GEP0lCPgkbPIZ8l5jryz2eny9E36fZN+e+xj3Yu08qExP/Wj3IEmbthc90dZvpBELxdTavoqeKhYMFxqrN4a0OUfWb28Yym7IcAI88jPtl4upT/gqnpmExkzYL8870/+MZyB/Ai+qQs6PFNbM4J4BWHnv4X66uj6RDCEutEFEAuKC64ie+CzGPqOfzIOImY3y7/yrPyWXp1UeD1TXhOwCGkjf97Q+tp0pUuwRx76YXlIcDtwpPGTg3ENscDsYUrEufi5URsKCaJBSywjllJl0OSu/9fs+Nuo37zwmykMkY7wBI0F5sWzozknsA56P+R7Isrmn3pIV8/j9czSfoLRn4RCW6yKB34/PUx4dYytlIOAqyd+wDv6qQx4/zVdQpvFhMU+9jik4FKq0Skg1Pr9P8NQHZwiMv4w+GH/I93jqYCk8NqhTx7NU+e5PvC7/yu/7IfmBT39I/k9/+T93ddym8lSpv2WFN7hIJyoz2coQeL2XCd6v1cWhZ14o/Z7bNCYCxCvnl/3zgSK8J4zsEVTtO/4cve4lEu1SQOGKniAlsjOmvtKziTDGRBQTqYTxuHUYKAIIDzBhL1o+U6kn6cvhWgHDmQn6ttwAMZkT9YMJq8C+o69gT3pl+c7dS3n47F0p/6Wfm0n0lyqtnX1lNCat/0gAmFfa3URPvW7W04XB7xmS3v+dQ9yPPFOsFJ2TmORsbTxjtfZxfH68eWIdF1NfS7iOrv/1Cm33WpjbQvfE6688lDtXF9CXc5jnNH6QaQIkldJ2nUENzuYZk0fu1Nsz6M5fvLHA7YHkmpzxuwqhwVBTDbUgsjnhNxPm9L2boQj87t//OTe3mfElZCFPru/TvmDfXdk532wsYKHZIQ+S/TsRANMoFo1SbKhDGt5/6wwIrzFcl8Xt8SwTe4ZgwTbn/sGEgUWcYMh78UkJOr3xeij1J8gOTXWu7A2jOQ7J5ZqkKIRgpGYFC9aTw7pSgzvS6vl9czLACnxzJV5VYR7T+Ur2Cj6HvzGdYr60DaWhLLpXsM/2HP47eCBpP2b09WifY2tvvPKsiIj8zb/9FREROZ+VuphDQCQzkvlrV7UNc1J4foNlriHseYZZo1zn9tjieRUrN9OYlOw7NAhlSj3SkwZ2Sl733/4Dn5RvvPNYPv8dH3R9wuRk4WwkXuHDz0HekFB47XUiUNHmvusabQfhBVo3lr2EqWwk5XGLCOwJcc8W6UbQwBPBkHcUU7/rmRdvOHCe+sUbt9kxBQCNIJtg/hdDOJjBXWlqMFojTdR9vZTZr3irSEa7sV9AZ+dzXZ6+ujzJH/jJz8zx4Tu3qTxV6m9ZyayWlWGpRFCd5ydY9UhIUAU4ETZ9IhRiYElMffC47Qjr2vfSolIfPVDwOVzvNZjk1iyGCebDPPW+/qXGmPojgQWTcvh6oWKy9quQeN6aS+R3JIDslSPUwFH/LVGehEzF/R0TIllhfZLhJ4xjR+lgBIh+XNcqTc5I+8OY9N/B6g+flZg/huzdkxmNxy7gakBVYo68/9z3zNDDxoz5Lu5Pei/LXcDjLXReoyGr//We+ij86ru+ne4tmEl8xu//03/tp5N1jEJA8HZj/SiTQV189rT+bduC91nnwpQacbBdhIy7PbBmQqT22wvGuD91LopIz1I8hRDKrg+eKDXeXIy49yzOEhXkQnPI9Kv3RdwzWPQZFvA9raUEYtNLJPvvjB8xGRW3H+YMxqMGlzJCLr7j294nv/fHPy2ffftN+ct/9dd9fSSAcvgS728/ZoB+Vlwf63OqNASFUy1O9p731JNiskbhc28vj43qr3PMaEaNCpY+f//elTy8dzXq9r8tsGd5vmbdYPRCA5wmEkXjddYHzuT/rqDkbg/Gc6wFE95y150uVyCkQeK6Bi8fPId1MTqCC6KF3Ph2+KHKOqxIRU99bGvuA5azYC31tewaRXzH6IVv1984EnlXUDyxDlJ6eb7+1B/5gvvsPPVgMEL6w9nI+ewcKoOS728Rkj+ap0fseNHvFlbqMVse9C9rB+Ve9z20uWecaPCdjlHOTaJx3ObA9eFItq47/L6UPrjSTQjLSmGHrDyjUp/G1OtY1OgVw9pCvi6W+5of81pjwj4+856OwF6G+UCDL88X07f3enmq1N+ysueVJef0rseB44LYyneosIGgaoqSWbeZ9h55SzJlSySzSB4c8BpDB/pcNIr70eej0jCV7Sdkvz/yDrM1HIu34krIfs+KTGa0CXXCIxynOwXdRHl5/Bhi6ZN2cH13vbACAomD35PwEBRJ7bvfe2g5Tu+aEQnjC1dkwbPhSrsEBn1xuYY4PWaSubLtx+AFk/4Xr+4RYTQD1UNnM/PU1uKTfMVkPP3fFxd0pZ2DTVP71dpxxsAKa0H9D0lwWPCqUYCZeSVgr7NypaWBQW9PWNZ8EDoWJ6DAO3yHcq+3zGexDdyvm95TP37H2Nw9JVEVdqYXGP5y3s7zuyNlM6MB7GXQX0L2e/dOLgjzs6nhNghHEW6K7zv6peuxLvLM3Sv5Y3/wR8MYmGZjaEM6fqARddX11yRrNhdeuUuQRpXrlNDv9bQfc9r76REE3IajM02kLnFse0Iv1isi8m988bfJ19957N4JHns2FBA9KjD2SmcbjQy8Vdj4JiLy4Nk7wgX5hY7HfovXN9ahM5dJX+ItLP58JMoL86WE9x0ZG1KnyPhODfs/+oVPuffYyLusi7zxwRfk7988dm3zOmRt7RlYcYwOrQH7ZeZY4PNiBN6eK/6d2V7SZp9Hq7ttoOk+QR5B5AfGmOM6ndbFh2LylXZSknMB/dtp2ytrXf5E77kL9YI54+z3jFQJnvodYwWjb6YSPeuxujQJHe6ps0T5JTfUtbAOR3TEjVUsaW2H3ysdYLmi7iJGtD2G34ub73jWXL/w/EB4Vsx+n4Rq0O/zTOj3zcs7Wq/VcbyH32vlduEOnpbUqjetj0VEg2RRyThSWEJMXSokErOsURgZL7tPlYiGa6Zm915GYZQFBfyZFQsV5jZIlIeEJxM+VGFVK/2eZ4UVLZTfGNIrIvL6B14Yz0JfS0cRbM3HL+vv+FdE5M0PvihZCRbU4gk81oNxeA0gzhmhW6sJAH5L8J7x4+7P+N94rjOBHY0FywkTwxzsgXIMreVEec4bPDbaxeUaFNhDow2PIekXQoFd3xOBEtc8O2eIonj47F0Xn4hx6L292G6RvF42StSxH6f8luyJurMnODkPKlJdtoHfcC8U3/dUqQ3rq/UIGS/HGlJfWKlHwYCNODgXGIqAdCMmfrLP5x2Ej52HfCzzM65tQnv3vEZMn0I25ITzHykUPD+zfTBSZV6ZWYX+TQSslQThYJilPewEelDcXCx28TwOeQ9m3FfB2iuY8UyL9ER5xlMjOoOFzWhg9muF3jA+g/3fCUR4PHDvzqW8+Oy9+Ry+iwqa+wxCbqn9rLERS5FJyOeCYglKnjby/PPPCJcj2h5ycMDZrwv0k+pk/hDCaIj25fD7/DPXb9/1v3r15Hd99sPufeYH73v/s/KBj7zsx0uKan8/NJXw/f69QectJImNlXsIDTamrqg0MZ1IaIwU3EMC4YvNzXdWMvg9e+LvXF0cyqAcqhQdTXkfQl4nkFMyI7TWjei0/t5xvYhG4P3X6wbHDbxaQE7UKc148ZEDjfs/PwcamsuARcSMlusy+UJ3BgnV4cfGMp/ygok6kBIMaSFEaXxuWBfkQOHrDmOerOLkQTSw4RrGBNtP3j/v1fKe8NR/9atflT/5J/+kvP322/LFL35x97lf+ZVfkV/7tV+TN954Q7761a/K/fv35Wd+5mf+Mfb0N7/sZRz3mTJllzGw55KJSpb0jQVUtFi6uB86O5XqYGE19TAcELMQY0Zj0TZaMwWuCxO+LuynhiOcQQnsz7Awti/AZYrVv/zf/0n3vva1tWax7WLEPSPmdwb8kgsLS0yc/V/0GDZZqD1XL7zjFVZmKnFOgtBA/UiVnAJMITEQcN36jmcCUfBZapnJj3B/657oMNv+ncbgHylfLJgX+ot9jtepRI85K2bYLtf7Qz/+1uHey+LFVGiqpVBSRkZvVM8Ykz0xY/wSgZoNjCxcTtg3zA0rbGkCRtpX2RkEHWEm/9ISYh9hzoK3C+Z8o6zPuIfD/hifg1JPc82etkNFMDmbvJ/m2Tv01EcFI30noftrEI68d5rftySU+32OHm/qK+175hsF1w7DqsCQ5trABHXJWJGGFE0k1sY99dCWm58spGNnHL1/PbeACbve297HlijUiRIV6A6Nac7PamidHmIUnzF6hwiy2AfzsPW/z794P+lXRIO5sdFnVGTM6E5tH9D6ruT7z7xXsA42FolEIwI+Nw37Cc9CxYLPgUhXhnW8l3cu5PHNjXz6Mx/abatSX+3s47Vj0ajR6/Dvshy1LIswzWd6V2uR7WzJgbEupINPKmmiPOLJd68vgucU1+0E50774OTAbNGEzkrT82S/sZwX3rEG6aNfX0SrHYUjZbk9pqdeeSElLuzvJmtc4tj2xs5nOA2Da52GuZA1liNxymn+aqnOeTTHR/woyGos47f+rO3x40R5HC6MPOeIT2bn5raUb2ml/ud//ufly1/+srz99tvyq7/6q/L222/vPvtLv/RL8uUvf1n++B//4/O7P/tn/6z8/M//vPzCL/zCP47ufksUJhoiMpVFMVe9CbzVC9LBElbjQRTx3sKQSb2gBW6/r+zZ4DjbGaPjEnQcKEWVrYfRo6qfGyj1ewxO60BPPRP0zAvB3ia+eqg/L+49VQS2Jg5+fySc703tHpHD95UAo/d3a03WA+aGfQkCWSY8wXf3nrly4w3w/zmPOA7or8byJhl3meHHhFV+DL0P4xzUiAhZ4XovtT4HY0OyDsfejnxeM4ux1bOTeAfqvbg8JcYwCe9g0W+Wpcp2cw71okcUvdN8ZRj2v8sHB4JEMeMSC4XuDPBYsufCeHXDdW96GXvkt37u49KayCsv3Jf6n/3N+c6awO95X5rXa1a9m/0+QLFBIJp0Iwh4/q/+242NYt8z7zHWd94sxIn37Z7SKiLy8Dn1+Po6maaJSIDfc6gWPovnpFSZ7OcIChk9QhXqk9gvWIeyVJGb/v3pwm6wYK/6xWlNkAx5nb1v/d8rxJwGQ1GNifJ4nhh+3404/nmuwxn2WoSj+3f93rXzMvoIa9dDjEqgw5ZDBM4aNYmx/srfn3/hXuwXjY3PLSsNWteRAXfPoDfrPPgcDHXJeco99eMsn/OY+hDihnse+q2PPHz+nvzDv/Vl+aEffyu0Fc4e9QfpXTCkLvwuVTH+gfSJ6ZwpYUUjmVw7LpFcokxyUSPRUiso+P6du9cXtO9juNShkrojCfEZRARpzAuU8Oz5G9c7xqZnxYUYeNRR/97mlA3P+lnh90Euq/6aV7sV03cqozfzt3chR/Tx+Jh6dhY0Mi6E88yyTUF5z9OoPhaQI4O8bPSXeeVCIV/YKp4P1D0i3/J13KbyLa3UozL+i7/4i7vPfelLX5Jf/MVflL/0l/6S+/5nfuZn5Md+7MfkL/7Fvyif//zn///Wz2+lwgdR/26tzXu40UIYBensTt8o3GVMDImXJc2Q8Bz3T3/jdubhFFAsDpSiDH7vHi9GkC3WVRIG5+ustcxs6Wzlz3hvgIsR48R6UKiqReKVdiR4PEkAif3fif+msdZaZNs2aCfWi+vrprVIyiCRcP6+f+4H0/HsfdZ/Tyaz7gt6IXabFfDs9ymwgKcer64ar+x76rP1PVir8Td6OveZbZznEt4pPH5m4BnDKv63I2HXX5sT60KIISuBbOiZii5dBIzn70l19H7CUFCpK2UG9BUR+fgHXpaPf+BlNzZtxynTJWb/5jUsZcSSzvNOAuLO/tiD32fKNnvqQ5Z6UtKw3suLVb72jcchzCNTqNBY1uuV9FnXzvjAifK8Adi/h0Is7uQQl39wthag4RldwTlaQKm/vFxFPXPslXNGO1aiRIXN0Z+ljjD9Juu6iMD84hx2RWkf4cYKKPcjM9gEj6TsncF8z4Y9B/N+Gp56vtJM6Z1LlMd8m3i1iMjzLybw+wPkB/PqUotUMLTujZd/iwZcmvMDxW3u++QsuDbHmnMI3i6d1v4wLduhCa6tPX6Y9F0dAdiGSPTmsjd0Wc2BwnunJkqjcwwoHYTfjooq8CvcN86e0TtXF/Os2jVudLaID5QnrJmIV/6keVmA74NnVMmux0RE7JYYmu8ajUpcN5/viWgl+L2Tz5PY/xAeSR/3bmPBurunvsg0tq513mpz9/oiyE2M2gvOr4RWTdRIwu8yOlKaDPi9jHGCUZfXKKnD0QSo+ggddtuU+luBO/jlX/5l+fZv//b0t89//vPyy7/8y/+Ye/SbV5zHCA6Bv8bNCGEG+QyJ8hJCdXhVDFrLFA6ZwO85wZc3Jtj3Zh9vQciJWVOxr5z93giAWpuLEjWoC/upHgXzuMkcI479SJHO4ECmQNkzpXTFum0twMEy4XyP8YQ5oL7puHz9dffasFkXxBszLJoNQVi3yPCcwbixXezzXr1eqac9EAQ7tuT6/cvzoc+3lin1KiCRwI7L8K6ExTgnvT9eQcH3snnO6nUW8yU3OGBh5cj2YNwbfI0NF/RGODqRMFs+e1xvmhMjEWjY8IP0Zw8YymFJIZmijp1ijLFu56HCd2hPoVAdEuUR/UT69Nzz996VQQ7b1e/0doOt+asSs7O4cObiQL9zqKSI9/ZiO76tiNhSSaOkdfi54z3AyqEngRiiYz9cXp2kJPMgInKxLmGMe4ml0Gu8nha5HMrwxcXi6WwS0oGnJXiymveGMV3mfszxHpznOdW0nkZDAX4/jB48P+YNszpDDhMcy3juhZcy+H3eD/1tz3lQq/HkoKyQjMCJyVhWyYymwWBHRsK9cdycvdEB1yw34hMvG98zegfLXq4ZQzGM76XTME5m5sdF8w48zXnkXV9j392ZBDpYoM69okaidVmmgs8KliqSiDTBZej8eP9c7Do3EsXX8daETx4ZWvhZDC3Qv5kHeO6TwvB7O7MTfp/JAI4eRqda1u/AR9z+hP5VET3h67rId33idfkP/sTvkR/49IfCHoi5iny/Qg4DHEcquwAtp7qmTLIUYVk1oDqYf1RfaXZrlk8U/IRN/B4r39Ke+ndbfvVXf3VXqX/99dflL/yFv/CPuUe/eSUjVB1+759BRcQfXhIkw+GNDNqSa9jhm5BmcQ27vh56P5GpHSXKO6qDFTgY9ySiAnE/B8IHX2mXefLsnejFEdkRgIF419Lj/c8uztn/5cR/WeE5Sb3BZGVeao+VK0PuO4JaL9VnjpVE+Az9oPEG2F/xz+lYWbjORoxzf+fyFIi+70eEojGqZIVYV84GrXVmymamlPMzwWKc7XlYcxermZy9aHSLSdu4xDXI93Lfj947HerCvhKdYK+aflb4fYHf9J1Aixz0MKM9hc5GC89kn9lDzuvN5y0oV+O7Z+5cysNnroOCp+9aQsbRboBX2nuf/t4PufEyooDPCO6ly2E0+8ajm/EbrWX1c7bU2N/g2U0UlZAoL1XqYT1xzQYtZ9ri8wqwkSqJqWfBUP8N9V5cnbzxxtHjJXrRHDlDSP/4ofXY3p/9yc/IZ99+U+5dX7o1ZK8xQ7Izj3d2XziHaLl923IBNPMIur+Thtr50Gs7OYdEvBXFJ8zS+vR3VTavry9CvxgNsWeM088b0b+sHHkHe7+8kZRz6mA/Ko0Zn/Ft9r/bxjKA1ldzvsR8eLyg990fKZCMepn1iO0Tpo8z5IbHSUwWPd8cGpidfYSV1yIevfUErX4aiSDhGfPAu9cX89mbsyp1Vu9p9WfHwbZl366w0DMoH2YJObVuV2lrof4C84jtBE998b93eQbqkZjPZyE6kCFn8a9IV1qPck2xjIBGwFJG2Etrsq49ROJ73nrDPaf1teY/h/NMfSjYVuZlx/NJ/Oijb74kr730QF578aH83+tvjLnwdWkd2GqpuN/t+8NcRgf05r1YboVS/6UvfUk+97nPpb/dv39fvvrVr87Eebe9+ENjDBuz3xcR+ekf/ZR87M2XnLCt7xx5CzhOSJ/BthdQnDAKjY9OIDwFfwNlE6/SOLgSjDPMMpFFSy1aRlnJyZQmvtKOBZU4loRhICFWK6JjCH3M5/O2L5iRQJuV6ImOfQnGgjLg92vZj93cUb5qiQqciCek+nhQHNm7IPk8+jhLYmCo1F/7TLoRvbEP8da0E3h11e6VdgfKVmboyerhz0Fp24mF8wpZhjyI6+1K8b/tZait4+xpDRwLic/GbN+UpFJsbed9zwS/X2t1m5oVoewMYKKcZenGy5KkzT4yBro41Z3s9+btKlNYKaXI/+bf+ll5cO9avvqPvhHqriXJxUG04MggUwsphnx24FlV6t8ZSj0LUUzT3k29mXHo8PaGKZ8hTbN568vdjqGQ5M1CFIR6jxHlhPwL67nc8URzv1B5zeaHPfUvPfeMvPTcM26+7Gx7GhVyTOBZHMYNNu5wVv4nwWzdGGjd9NG5rssiIpuUNpR6N36qCyHDwVMPdInoOhbmp/HWCr93aqO1aFFpZA/tUQ6CLMmWG2NCpzMldSrjm1fGnQEk47G8HrMeTxOytqZiTvNsnnqvbGN/mJ7Pdsb3PRGsr3/KI9QPfWb2o8aEoUdlXS2mftIQGrd66vu6nwNPOy0UU0/yFe6r/9Zv/U75v/21L/V2kM601pVo4HEZbzEDP/SR12ki+jxNXNmBQGcpQ44EJ9Pi1y6ck4Rv4PPctv47dR4Ub4g/SiZXa/HOtSBHJUo9zEdmLELnot3M0aQuRb7v7Q/I/+5/8i+M/jKqyvMH56kHHeAopp757m0qt0Kp/+pXv7r724MHD0RE5Ctf+co/GUo9CUT6FxXjUvqh+b63PzDesffRojqFpqTO1HqYxBbB7SfBQ8MGiNRyWnwMV1ToyGqHY0mUgkL9QsLGME/9rpYiNxtZUoOASQJLQjScfaH637oC1787ny22PQjcSBQlL0ee3D2jRN8jMhlYLqQBPM5BFtnII/M5bteE2BxSy1DIqbCt+4QXx4eZdOf+pWdZYDFUSS/rsoAiGz1oleqMhgo/t9j/B3evRUTkuQd33DyIiHzuhz6e1hPaecK5yQwBrh5IQoPPZIaepkr9TlIknxOCmK2TiyAkR4AowHh6HfYOKxTpGQABb1lVqT82/IhYaJLuERbUzcikfcEem9fulRc6T/kHXzOlHsOe9mLq08RB5dhAM88I0VsRkauLk4iYUr8Hq87q3Qv1yejxs/f7vv3Qa8/3dxMYo+1/oL9HwiNnvmb6q/1hZYUQVpO/tJ5AshSLGd8Tgk1XgXmuRepG9L3FsIFJ55K8G1nSNlzr556/64VaooOZwpmNw71bd/5qP9c6N7DG1HMYyMLexxKFdVSqnnlwR776jXdCn7BfZuz3PJHplArhmcF0foYlYM98DOE7iCWWuJ+y9vC5mSiPziHv2akg77RzFFM/ZS+OP0hodBZu4OrlvY37QP896x2fE36H4+s8YfyguZcPist+vwe/vz65sbEx+7T67PfBaQL//td+9kfs+6BkegNgditQobnq3/kxKfpq4TOzA7/36Bes2Po+PfWJAuvpcBxz1klGUGUyQSUjOobnYB+0PkRoLMWHSS21hHV97fXngry5168sNwTWnf3VPgbandDIJyXYvk3lVij1IiIPHz48/P1I8b9NxQlr4HVCxfgwTg0U4dQLnR0sFraACWwgwGsGdGuXFfKc8Dw+32gV4QDGOB/6TMp18NSXKHxkidXYUx+FQt8n7OWSeHJYmUVB+7y1Wd+R9yxTsrgvEX4OBB3GXKsmyhP3PRbLqO3h5yeKeZsCSInj3VMgw++kVOHtCEf8rN956+e70l4NVv/xuQ0pZT3Fe8tDxtVsTkkeQKFBFb03Xn1W/kd/9LfLd3z0tdC37/2Bj7p6Yqx23ANReYgxZlwK1N8/05zD535Mhnc6ZZZ7wgdBYYsJJAo/ZU995lFIERG8flOpK7tCZoQn5nuEIZVB8C+93++8c+PqS2MpSwnePT5/3rPIqKnjRHkrxpCrp/6xKvVE0w6EYoZgZ14Vff7hM9fyH/+bf0De9+KD+ExCU5yyOuYuKPUYF7zw/i2RJuwoS9iXy8tV1qXKaV2tfSiZRxrHmhnQ1lOeJFDXIXi2oBQSrK/vXI62xL0bE5f5ejRhK5Y9oTfsuaXMRIIXF6vUWsO99LxfKvEy/U7n7c69S/mHjx+HPrl+ZKEFXp8YBlwfV4z9mG0Tn+H9x3KJCv09+ayvY9LphHdlbe4nyotJ//B3piWcn8e3RXUgUwEEXRFJQ1VwPHvnBm9u4HdOQ7HbM6xJ8SGVezLI7JN6sZc6eWCA32tMPebsgXp7uAChYKCKPU+rU+RGTie3ZkkIXTAQJmPU63CfBL9nWbkykhTojNKWNz/80mjTxobNs9ea27I++98yZEMtg18OuhyMljQWht8HZB5t6B/+bXZbWYZe7OOPHd5DcjHPFhnzQ89mxrJDFMIT9vB7rdwapf5p6YWFwv63Tvh9iTKBP1BAmLKDmCV9y+JEKzGwe/euAyHig5UyxlpcPgC2uLFCU6lf7ndgZpqBu0gBAuqZvX6XWkoT4Qf7yIJpeIaYCLZzcz5Hj3piod1jqNx25nHLCGW/EkvHFevNkBgiEq4/4fnE71iwyhRJHIP31Jf8Tlb4fA0x9Rmq5ChEQ3mWv6d+R+jPYt33FEGoR0Tkt37u4679WU8ydhZ8+Z0Ie38y/H566hktQYoFz0tq6EGkCQuCRDdYOOZxLQF+TyiLTDCA/X14FVZQ6vM9sicY2wYWEWny6B2vyLg9BnVMYyCduyw+sNC+CkIinxV492IIhdNTvxMrrd+lyjgrzTv76KNvvmRjzWga7B/OVyFikNys7ogiqKF/u7kgMMfA1Un+xd/9efn7X/1a/y2BkOO7e57AGVMvLSj1tmf83e767ziOfZ6wx0+Y1r3zjahAhxAm/pvstdPlKn/on/5euTmf/VgC39kzYNpZ3hOK2Qjl5iNRcJoxB6iExupo/RrXjTz3Oobt3IDOjaqJtybN0Vi9gY6T5nIdjOL7Zjz1u4YsoEdK+0vRrPE771Z7R6Sfv3BW9TfOKVKUDlVXxxzrExQivPaNUSBa7l53A5ehBjwNWNfFrVEwdidhYVk7HpH1hLDEJKeQFuVfM7QAciZ5eh3lYg5TNIdCL299xxvjXZj/g37qy1G2Jo84nZNeh6eLR576Wosj4moww9/5HJxOi9wMA0jqZcc1MDIb1nMvV4j+m+nTvFHA1UlKPaE5b1O5NUr9l7/85cPf/0mA3otEz4/+3WZ82hY2cVBySLB4ElGZ0C2wSCpR+frXH4mIyIsv72fH5Xaxza7Ug2WYCEfIYg0/R08nxE8D9JeF5GAYSBTpPaabjeUo+z0q1fpOA0TCnoDWv5O0IEMoJd5moHPDf7dtmLN3odbAnEhhdXMktnbWV5q3HWE2eN9AuNaYXJa8Cq1PnDuYm4QJsKW/x9Tr2DQmkNcX2oe6XJ9xD+yED6yJImr15CEp7J3ZU0jwHSyWT4KYJa2B3wPHd2Tz2eM9gd4hFY7NU2918bnJcjVEQZ4EsSfE4oqAV4jq3PVy0vuPgqc+p12PHp/z+jI6Woh+Ee0Rehf3bYTf+/Ec00Wud5/uc0E0Dutk3lNf5kEJdwYf0HA0DPC+LNCO+11ELi9PEw2T9X/Pi9r/HRUhaebF5DoyiD+vZR+HV/pxLLwv2KirfXiUKfU7ezV6H62u02mRH/++j0Edvl/4NzNgaj9vzpvsbI1gOD5C0ZVapGz7fIPbFxF5cO86yhDJu5qAbY93Zwg616bSLTLQYSI0l/fnCTTlhowDWPZ4VxlKFRoE0DB4Pm8RncPnGB0DehapPfbUB4NfUJTDEFzBJMHZjR8iIneuTu57NlT3RHlAZ4JCueepB/6zVjmdFm+IcTQxR6xkY1T4PSdAXmpxV9ay4TbIDUUCT2TZgT31GQ8UabtGa20/QxBMmlxEypYYW4kXO/g90+kS838stciZ99GeQg5/vhn4PTtYUIaw3rbd0N+9vfNeLrdGqd8rX/nKV0TEYutve9nzqrfpmY5EKni7idCnSj0J1v03I26TSZxWkZsb+fDHXw195XbZS6d1K4S/CBOzhEiU/ICLdOFLP1sMU0ySFeCficAessUeKFamQIh7Bv8uS+4R2b1zVvYtjCyYHRsTbBxPgt8jIcSmT+uSMg32QmbtoyDux0mfsa7gdWNm4j0C/kwkdxuTAP/hj75iAvsa90S2z7Cv2bnh++mzvmfCIBsseDy8x0uhvsG//5d/6vfJ/+P//TdmtuE972BgnroWBzcihNj+4s8NZjFXoahQHel1Zk+gPc4oh/1jGkdnZQ8arIJN2J9Tuu5/Hz3ySr2DacN5D2E7cwzRa6X7qpRu2HPKpdiZyIxme4nyUk89KVR8teERQosLelX43KPBDGPTj6CQLNC7DPE7ii/3W0Tk4sqLNntw1Ux5dvQb13XHU79n+DvyZO3Rtz0UgpZvpJ76/Bybc9Wfj0rX2OIzMVFkNAhh/27O0UlgY8zXTUS8l248s7GyIeEYu3ce3LuSr8F8OJmhtUD/eZ+kBrsDRZv74HgZoo9obY339e/ZOIBlF92gtHMYCf/AT35GPjjyWmgtwctOdZqBqgW0Fiv1c2+TnOMq5u+TcnnqaIrTajH1fIPG9YTfW1tOIX9CojxWJuf3YAj47s9+WBZAKDCqM8gnzvDo69cQGIyl17+cmR37x+gdRA4oYiYgBoiOZAivXpcfOxu3dtE2pScFLLIlOUM8/XLw+xTxyH16goOwlLlGiOTag99nCLVIV/OY+njrUI4auQ3lVij1n//85+VLX/pS+tuv//qvy+uvv/5PjKc+E4KdcN6OCQIq9Zl1lqG5/X1mXqY4PfPsHfl7X/+GfPQJSn2pO0pv9YlZgqee42tIEGXFQn9WZyFCnGd2Zag/WIWDEBiFr0iIo4Vaf1dh/PJiJbi6FwQyr/MeOWKB4DiZlRHKs3rquSEeR2FjSU0FFCfwB0FqPLMrqHupLsukb59zoSv3EB3vERGRF196YHtijhnnkO+b9edkymGJoscF652CLDD03HjGzJTGX/14tbz9kffJ2x95X+jTnmfPzevudVrGHEO/dpQzFWDmsOFMxXME48roUbE4Wr9HfF/3lDoOuTGlxbfpprhFT/2eJyTE1LPylgiBtRQ5txb2Ju8z3FPxSjvysNE+So1wIPBiH3l8WBjW7+qrFvuKBpejhKkhhKrGe4pZKeN2Rfa9TgwBzgx/KIzOr9t+2ADnTMnqjHNOnvod+sdnLlXqiSfZO3SutZ+hBrxSi+oiiDf39+ZmC/LE7hhJOdkzhDtecnCOH9y7nvu912myyXbGa2FzOpf1KyFx0WjBtKEW2ZofSx+H/8wxxzk9Zf6Hf5s8Hjkzfu6n7banNt/1823j9/1uwObReCNiRmw20LGB1xrO6YKWP/RT3yvf/+kPycVp3YXfs8f7SQaxoKTu0Cb8/nShuTWANqWyshq+dLLintj31LNHnA1kxVVWiv02rzkMctle9nvo0BNCEpda3N7z+6OYjMXwezYEQBPMqzM5aqlVbuo2n8c50Tpnt4rNN99whQiO/tmv256T48hQsNItA7ep3Bqlfu8u+i996Uvy+c9//h9zj37zSgZLqkSQn33+nnsnWtz2mV4aHx4EAatDrz9JrWeYIOldQI2zer4ZTz0KjIpcqCLB88UMg+OARCJxDYLpgdDc3+9//5kfflve99IDef9LD3MmE+KyUAnMCRILXpcnO+bZWrm+kcCCJUNiiCTw+5L1lfsWPeDYbmBuSOgPGJh7lwQW/Y77yl7IznvLHJuOGevIlM0jpZiZyvw+UdqcckV95/GuNRpUMst+VvaEz7gnSvfuZGcYFTj3fYwh1vo4UR7uCZxXNtJxv7XvU0jZia3EfmLdOFYt6nWN59w/xzH1TGdiP2lvJIYIT3dbuld7Hf55EZF//nd+Vv6vf+1L8i/9zA+48VqehAO6SPH3bDzgsbhxJ8/gX7enShxz75ufA7d/SzQy7yplyVman0cTfP1czuOqnKtmOh9tyZGnPleEonEiMeDQ+vC+dBB1afKNEc6GhZ9lFBl/nxXm08HYIEWamPd7nuVtC2EJ1i9xY/N7JRpGjdyMfyQKFXvq/86X/yHUYe3dnKNxKjM6idje6ONMxrHDb9AYuW37dDxbSzfO5LtouBKRJvL40Tm8I21fIcS6pm+ktd2+Rfi939PRyBK7g+XNV5+TN199TkRgPfYM3HAGeKvu8VjXt5360vd3eLh+p0aA/p3vzIypH7yCw2+W2o25Ofw+3/MzCSOtWXaDE49fJJGjAjILf0t42kGiPJSHhigQ8v2ggXOGiNQSaTXR6KiAt7Cee+Fh/d+cSLDkckowJOf8/zaU/DS8x8oXvvAF+St/5a+kGe5/9Vd/Vb7whS/8JvTqN6dk3kFLHNF/e/EVCkUIijAzQ6w/EVjpwHZBrD93Q/DTvb4GhXxHmA6fKSt5UOCQAIBH+epuh3y98NJ9sFrHsQVjw7tQ4Jhh7F2LJtKvNvttn/u4I3BYXxDQ3DOSFiZ+Tqmf/fZ7Q99p43/HClwCv3dz5Pvh2/V9C0IsCXbs4UzHSxPB9+EWapOV3kDYgYmt2dpVtp77PmeKwq6nPpkjPE+ZIYjPzZ7Qyc9yeeKVdrgnJM5zf9bqCHNEZ0/fV0/9hz/2Smif+87xciISziN7mPszvp97CB/tv3oqLZP5vqf76vokv/Of/T6aBz9WbpPPxNz/BzQPx4Zjyoxmr7/8rPyn/94X5SOvv+h+47vds3r3FMx3s484IZOvz/jAbL+14PFm5cvPZbz2jQXwIDCii2aUkPhyZ89rvWzklJZkvycawSgPjtnNjG3BkFJ8HRxTf5Qob4837fFSLCaIk1eM9k/w1B/F1O+MTd8PdCxTsg+Ul3t3Lr1jgM4008sw19TPrD2sh8e1xw+DATtTRHeY9+6+HN8/prAfEbuedy9PiDPO6gvjn3weTnQ9I9cZwpq+CaVoIc92+H3HU4/thFsBxNPQrL7+vKdDe44XfeeEZ52qn1fa0RV9jNiJBjtCHAjC7/lmBd+v+Q4bWSR/jnNrpbJlKTKz30v01GeyF44tuz1gL4wpM3Qjv583KqThWSwj+rGwgSegShLvP97kdNvKe2pEe8nwXn/9dfljf+yPyZ/5M3/Gff9Lv/RL8hM/8RP/RHnqMyVhQYLcRF58yYcisOfviIAGyy22k1gkZ6xQxiyRwCUCPdaZvdN/R+IVodVBgRufP/htXaH4Hb/ne6LSB/XvestYyNkhViJwbzVUfGSlx74cCWZ77JS94ZeJ1Xkv+cjMvZBUjoIGK6xsge19jkrWvoCVz+fcg4t5rUPf6DMTbJ4P9o4HxgnsambvPVTqd9YIqlWrPhfHVHSOoB4ca+Zd5kR52J9Qf2ib1mBnz821Szzhy86eCN5gQBSoAPPZ7/+oq3+pxRsYaW3Ss1bMeFDwSjsWCneERFXi1VMZIKyJIPGd3/MhefFlbxj1Y8376f9mUEJruxT9e1DHgUB9RMO5XjZ+5UrYu0CaJPsn86LHTMR0Xt04ahTq9vbp0Xwo3Qte9Zx+s3dTpO16skzxIaGe6nwiKkf2lX0tqVJPtHWPNx3Nz3nuf5oX4on8+/kopj6DH8/fomG0OAIfr9LjOph2Z15O14893nJgDNT68PtggKlPOqfeyIBth/GF9dcXRIo0efw4eupVIeL8FUL9mPD7s8XUc3szhwzJjv457VQCpTgoa8K/sOCeC0p9oJ9x3bl4FJSvp1+FFtdsjvsi59ciMjO6r2wAobkK+65y0jtrT+vMeLGXASJdyE5L8IhnxtdSjL5lnnqSFfHfiKByY94547nx1Hg33rgd4fdMI9GQF3MOzM/4/c41qrfRU/8tDb//pV/6Jfm1X/s1+Y3f+A356le/Kn/uz/05+dKXviQPHz6Un/mZn5G33nprPvvFL35RfuVXfkX+9J/+0/LGG29Mr/0v/MIv/GZ1/zelZMTOQ/hEnn/pmcN3+IDW4g+RSLS69+9iHQq1zRg/Ewt8JLPK9ef2LZSBudbEU08M7kozr5aSztdSj6/0yQTszGvZ/0b45d5Y9owHmXAR6jkgpLuCH3gsy07daG3F31fy1NvzcTx7RoU9yOgci4tx823x3c17wuTe+nKsYyn2DDNuG7+4z1jvFJgcU9kRPJK95Rl6siecABkh6nhEjuD3+4YjYni1iJyflP3+OFfB6jz1HmqIClf01ENbc36w/Rr6LRINXnt0ZKKY1FM/7+0W+hvXAQsbMPi5kFgzowmoDO8YoPDvnrdPZN9rp3U62kvPBo+z7O+jtP9o3E3oOGe/D7HogS/ktMNg5ePhg/lAD532zffZz7N5kEY5yEWzUv+ZH2o7jhc9wZucrZuIyDe+/s146nXssxP9c6Iub3wHezY/LoN8XHcuRwJ9ZrA8lygrcNXcVpb3gWUU9twdzfERTz0zzB3ac3xZ/87nfP+ycfAYAt0pMuD3B556pi2zI2MvF3v+4rTIpz76PvnUt/UbItSouZv9viYD9P98YuFEeX/+3/25VGFcazRU784L9JFLZjD1BvO4dyZi4bSKSJ/rIG/sxdTv5Os48m5ru9P7D/1Q/p86lbBLCTKJ6X2mF9RapG2WhJoV3z0j+hxLWqeXceNZ8XQjeOolrifz0yM6UkoJ512SsbEh5jaVb2ml/otf/OI39fwXvvCFf6Kg9llxwhPHA48/pxNlBt4RkvNDFL3OGQNYJrE6hzrsPbSQ7yUEgfeyRHmUBI4NA0ggkFncENywFKuLr/Bx/CwIlIkAR0Q0QNgkFx4ypn9kod4rR88y8WVBQK+Ny9bLxU+jUk+J8tJ9s6M4MhQyMBJl4gcK29dHfLMiEvYMFzmsOCZ4KaXMkIWry/53CWEefo+4MZBXQOTIUw/1iK8neL/pXPZ6k0R5CbPNypMUnD3Byn9n++hJZ0A/nkmpL25f+br9vorjKwXmRZ99gpCj/cXvz+SpD/vTCQ5J/YnBLtv/7JFdkvGhYJKNP6WNVFYWhGi/eqOjp09HCC0uubdG5tjsHNva7AlYe6Fde0nt5jkJaxQ3gD4Tk3IliIli89P2p9jWlJOLJeeUeVE0qtJ+2KHhmad+F8rP53j+HueHr7kM52D2O87Xntd5z2io/97zult9DVrWtnwbuVGJ6H1YF2sTP+N3XPr3pgDhs+Ha2519kClBeTvxr+7DR4mnXstecszQVOsG2l/6N37f/EpjuqdSr3PICcWwrp0wvb3Ce+vVFzxiFOHre7l2eG/3+t4FbUpkWuZX+Hc5LSJjqrn2n/zBt+Qv/J//mvyuH/0U9ZvoGO1DRqIJ7Hmdf1z3SrQAx8GKL9/2wUmZvdHSvt8UbXGQCHQXfg9DSZOrlhJodPDUD5ld6U9CmnbPs9bLBgxGWRWRkJyVQyVuU/mWVuqflm++8AYXgY1bipl1d965vFh3mWBap6AXBJjc+P0opv4o4UUWg5PdlY2CA1s1OeGKu1brxisWAu8GokFwn6x/sd24DhlED0sqGLCCmijPXDKhnNu4OC1yWhe5e33p+ri1NmSp5F1gyk5hXfNkLlk2cndPrOwLfsGb4q4r8337+js9edSdy1Na51QGayTkzrKr34nIw2eu5U//9/4ZeetDr4x+76/dnjLsY8r3BA88R/qd7THv7Y3vhHhOIcPeIfw+t4AHpUT/ZIYeEGjYmOA89WA8ifGDY7xlP1zG99MMcSiw1OR6tb3CBk/1VO4LxsfnztGuAyMer+Ge9/bYS7Lfj/nsNykI9b7trL/EPc9j9f2zfTXrQMMxZyLegZ7vXr2487cdzIf+NHNkkMLDnudZpyZzzOL0xzMr0ZUMneBiPQ/GcERDpIm7K5r7wbyJQ5oQNc2F4fcBFbHTT/xur1/7HjZfhykbpsQG2nYAM2b6Hvez72+qaKQjGc+okpcoa84RQEitNJ547zztGGi0ZJ56e3cHsUEGqmwPqaH1tPo6QsgXdKck/Tsqc75288sgL9n/Dfvn+sbtpRnftS+MCvPjXodSn43xe956Q/7i//pfnXOT3VePdWXKsfZlGpWT7PdHY8Ux/8t/4ieDoy7jK7X0qx5tf/QtrY4cRlDZXEVewed3zwHIIS5+LDK/S7bk7pi9g6U6ItFv3qpjRKMcGpL3232vlqdK/S0rRx6Y3XeAUn/oteflr/0X//V4X8L7ehjWVJgDJjdeYQEeCzN59sDxM/nnI0EqXruhnxVBgIw5Cnz78CcTQPJ2OUkStqV1c8mEaBawl3cBezSG7OcTryQ6rYv8R//D3yuvvfhw9LnXOz02B+vF4+N7ZGfilcQ6vDeuEE/OzyV1aVFP/dWlhlI8gbm6tYn3q2oDP/RdHw5j7//mHAL614/JGT52PPVujjivQCL4cv9rjdn7s76lbS/5XAfBgZS1rP8p/B4/uyvtPErm4x94Wd545Vl57sGd6D3Bz6GfNf0sInJ959L187xxiIZ/xxLl7SgETzCmZYaUbO3CbRaJ4auWeI3beMCP92BxOaM9KjbsuQnKQCpM5tJPFh6AyuXM1aHPyH6WZe3z3x0Zzd/68KvpeIO3ThVwSLbEReHFnCNjz/Ncuc6kMC8Mdbo9sRP/vdOPDLItIvKhj76y2489w2nqZaWyUfbtPeUyhZLvKVU7dfXvvKLRr7T165mFWn2NkAqpwrGjTPG+MZ4UzyCX7Cy/8eqz8sydS3nfiw/kP/+Nv2u/781dIkfstRPOeCkiTeRy8Lis7LU7jU+nRW5uzvL2d74Z3uWM7tHLrHPk+/1N6PTBox1+B/oRDOcHxo4nZdPXOkVob0ATnFB0PVWRb0gGFhn1WZvP3b8jf/B3fI/88Gc+Mur2xqXMyCviDQaMaEWF3/HEZC9lfCBFgNXiwuhKKd3AM37fS2Cao7HYCRf5Ga7jnnFZ+6GhLRm5PURVkQHI9Qv7t2NIfuqpf1q+5UsWY4aH4LU3no8vweZHT30GdVIGqLDk/p0n/KqM1FIC1NY1ywd8h+lj2VPyFyCG+JtLqrEg3EmV1/77v/A7PycfeeMFV0dqKHiSAiRKaCLT8ffvSii5Z8+3h/BDFo75XSRYF+si7zw+uzbwznL9XoXfJ11fhvWcyFOftb/ntdnzTLE3kmFbWE5r34vve/EB9VMrGf1PBIJCwnb/PQw9gZUl490RpkTeXfZ7EzJtzNiXbC7WGmPq2UO4V/aSwvE4VK7J5gWZdvDEoVC14JV2Pn7wC9//CfnC93/C1af9ywyKPE/ZlV137r1bpd7v+91rsHDPxGlwJYtJ17595I0X5KNvvigfe/OlZLw2jir73r3geU1KOF8HyKI9T/i7gQuniirQKr5BIc1uTML+X/nr3aj81odf8fXSmNgjOg0HqSda91zu8WPBWcewvQsPEvc/xnD3OQkeJvHnp3/OjTEiIvcf3JF/+9/+g6Ef+2Py8za932lMfTscC9P0d+N1fjdKrSoaOOfOG0xVP//wjoiI0YuDsBc2oO0Zh56E6tnr+/e9/QH5P/xHf1RqLfLXQanXJ7k/WZ6dvXY4X8TpcpW1VvmD/50f2e0jX63I875erFLOZ/nu7/tIeFeRiwq/j6ionOZ8M5567d8eL3w38PuMfu1n049rdmegf+5cXfg1ZSMGZL9/0hhLKfIv/cwPhnYztNQGLmm8NWh66mFvhrmHfmbGXu6T9cd42vns92UDZTp66v0ewH/vxenznO/Je1hXrWUaFdPQqXmeaY0y+bzaeNH7v+up/yb273ulPFXqb1lxikRi2Xrt9ajU/42//RUREbl/93I87+FEmeCZZ1Qny2QtAL+PfT2MU95huPz50DvCcF5M1nXjPfV/+Ke+19oIglZsP8ShkpCTzdmTBCFvxfTfhfhIOVAU9V1UvE9rV+qfIJxvB9nv8Uoa9kI7xpOOx/d/78qwPYHryFP/e37sO+Tvf/Vr8s9+4bvcO0GYo33d/21rbYaeZG1or2Zw/F0vC7Xp6kWGSfXs3lFb989NbHefaUXFLxdGRLqidKaEhNiXWr2h4+piDddNTQFmOzD0USKhzHjShYW4zzG3wZ27pNSfvbDAkG/25LJn8t0ouPZ7NOJpH1976aH8x//mz87v3TV8uF8PkoZlShIXjqnnd7PxsBc283Rx8dcI0v6BDMk4+zFRnt9vn/nk6/I3/vZX5Ld8N3m+Am3w7W4HGE5ObsV7hscx6eH0/j85Tj+Es/DfZD75t73M/iIil1erPHj2buhHNJjqGH0/jyCuMft9vn+ysewpPSFxYE1+K0XO429aD333/IO78n/8n/9RuXPlQzOwbwu1t4868GPj+nw3ct6d8qe6M2eujrQZ4Fn+3W1r8uDBdbr+WmJCMd/383nbpRkWU8+IkcgLsHwzSv23f/hV+f2//bvlBwEBhwXbDF7tg720N6bM4PPxD7ws//6//rvk0x97zSXYZUMIe62/mRKVeZhTYKHrusCNMOfwbOqoSuXN2IclGXuG4NgAiRBi6ktcezQ8++tmCZ2wI3vteur/v+29eZAc133n+cus6hPd1Y2bOBoXSRxsgDQpgCSat0hRAKmLoEyQlGmLI1EUdQCWhpQclgWNMbS1FrG2KXlti+AuGVrHLuEYczZmJ0jQI+01VlNeOTyeoVo7Ho81GjbksXxIQPMEurtq/6h6me/4vZcvszLr6u8nAoHqqsyXLzPf9TufQ3tqKnX1sUmtR2yMkJLvGRn11Xr2EhDqewxee2YKDjLX7tlMTxLRL3/kduUYbvEoyhzs7zO+O3DdLgpCoo1rxhvXDaghOycLsaFqP2DdTxl3PGNrKK2uuoU1EuqFsoETLLSBKClZl/63Huesu8ImXVe+n2hgTSEo6lpnIqK+BNc3Raivud9XGAaKxl7f0s5I0EgUHa9PyjZLQNQG5XuyjL995RJ94p7rpXraJhapLOOeQlqsiiREjnvX6sWWrwkMRHavCvUZqeXoz5lVXJVCM3mUpwBqLAL1di8mx0YRF86b8ZyK+71Uj1XLR9RFvJRMMcpnwbQx+Zn1lUtKGfriRo6tj+618VkX6qs12w4JQquvJcozlExKLY16yxjJpYi/16jO2jGylYYTnnyEer0PCs8pblzlwo7kv+vf2dqvObfIArNRx1rNsb1Q/f/PPnAL3XfgHbR1w0qlrrGyS3sOjeKEBwgbM76o5UyIFA/cvcYeMlz8sSCqjyXrtSiRn0e0cdByb6pSh3/f+nVt87dYOAfMPcXu99rYaVE++IwxuoJCV+LXf4uPjcuU7pkpt7JsMPqseiaq7diW9NK1vrH1KM6jSiZgPhsKG493aXhZkHh39q0D9TrqCgHx/cJiVRF0ZRYWhVJTzX6vW/9rgZo8MoVMT4MDfXTkvpsS6y8nO4t+0+coj/bHGhXCgK7ds4WIiN5YvGAtv9QnK/kcN8Vg20qxFIZE0jwkezjqBgVZscjdazoDET8+hEFsqQ+YLe30MB5RL1GWc1eoaMwTv4v/ZSU2RWVVvdzv1fZsM5bF+aGkMizbqKZJ9NgtQKjvMTh3SM7NSGbbxlX0nW98xnSVEROuJrASqZZ6cfyW9Svo4buvi6+VMIkZLs3M4KFPQkYWS0cH1weeQLqGvq2WTKDdN7dwtcYtavclH5MUU88NnrqWUnVptlnqzWP7+lS3Oh1xj073e0mBoljqy2Y8db0eDit0VJa4X/44w92sRuQtVGmF6xYs+XpJizabNZuk6ujCvXyI3UXQLhTJSii5XEW4ZQQnNTMwf936b5ZFoEVonJ83hXq5bcvHrxpfFrUlInVLO7elPqa/T90qUR9PDG+eIIhKWKZb6jVLgP4eFy3ux7xi06i2Ar+lHX+sbbwWC2euXcqCkA1WkAiZZ6Zdt/63qTzyWThH9QvNcUK2mtgWWOK5Dfb3RQK9XA+rxbXx/0L0js2VoWGp1wRtxSsljMt0LTZjwUeNQzYStTHXsFrqA/s5trftssTJ/y/WTE8bQZURKurXVxVn3LycJKBy1mxOsBZ9RFakJAuypqLAluxPV+py86RNglMP8Zu7XV4XNoVcoL9LMT4tVp0KWiJS3NeVMkT/WFyk/j5+yW9kv7e8O2U9xhhZmkGOczaMJno9mPUGh/DA454dKyyLNqTkwEl3j1bhMwyoKmlEVPd71aNVVVqb7SZMaLPc+G4q7xvCtOgnVkt9/HyVRHnM9axrCsYyrljqxf0bdyKVra2x2ecjrfnlHCvGnMN4bfYKEOp7DLl/c4lJbPMCN3Bw8TuiUw72mzH1OtyEq1xTGXj4+FlddtKvZU5k6vVtFvVoX1BmtW1bRMqfxXmcVVaf6HRXWPka3HXlzy5By+5+bw7G/dpkbTtnsbFPfWVs2DwmjMtVrNClkrpgFYv0kuN+tEWC9XdtUggoWXNuWlvr3/cxHhPcZMO5ZLncEG3WlaxC0c/s2Eh/99PXqb+vzLY9uV+59vR1XZfI9CAxlHrKuTXeUi+NMfI0v3p8hP7up6/Hx4X2RHkycrsa6C9b+0wYmnugB2FQn8ZrNcb93hRoSqUw6ps1LVGeaamX3kOSUokTii2Nlk84Wr+KrYzovlPWQc57wC2Kzb7p336DQG4/cX0jDyC5bkZ8o58Xkc2tXRZaiIgVwGOhvj4OGq7h2nOOhClpH2edKKmWpkSM3486ZughPMo9aeOQz7wi11f5X7P+i9MihS1zNwtVNc+FTYHiG0rG3iMz7srHGIoUIlq/aQVbtn4NzmJvvOOoT1HjmvX/1Szp/HU4Lzrld0eOFd07rf6ZvxBnTSWqt8MkAToppK1Ws7sb69nvdSFePCN9F5c8hXp53NGLNfq85xwnPPC4eiprRa18OUQo7S2awrw0R0o7EvZJYYvxPvXxO2Rjxrm+lLCW1BWXsmIk9m6qmQlMGQWC3B4470zdA87wEmDGszAI6ELVoTxlFEqym73+HqM5pxYreU1joDk/9goQ6nsMueHriWKI/AZhfeHHTWhcTL0Ol6hEuY624FQFcrMjE5mTob4A1euqD/imYMHUvXGMsG6HTL1cWngdTrmS9DwMqw8zwNos9Wz8fUKMmDwQrlg9Svf8wvXGMaoAF1MuqZb6eOEsr2JIuQ9zD2Xtd/1/WYnQ53cvepsYbbhtcvFmSr9hnqttocTdC1dnG1xM8l3vvJzuauyBmzihh4HZJzyUCVx9be67ggvMdkryOXI9xitD9A9n34iPk/apd+2IIX/jEurrQoCog9RHAiKqmYnyrty5kSrLBuizD9yi1N2w1GtWVk6xmfReY0+R5HHXZVExPmu7I7jGcn0BJ47nrRvaQp5bLFnuucwsjlhLvZKQSc+yrLY/HaM/GwJxY7xuJG/de60Zsxu73/P9WFV8S0kdXYtN0W90RYEuzAXm/enXtyVmtHmqKPXQnk+UbE+rj0tB4Zsoz+XpYdTLcm/yObIwL36vVeOM3Hfc9Q62bEFS2fW/tTnUGKfj8mwKu6T34BqnOUWa1VJvmf9c5wh0l2L+XfFrBjEm91my30f3oO3ikqdMJCtj9GfsVhC5x8F54scWbgyM7jMScJOVKeY1VU9F2RiyEMbqzXI5FowXta2f160ek5TucdmcwpWrnrJOtCTfDMJAUXYbifJcfSsMSB5JhDxg1E8fC7VxVnwXKWQZIoWSNuawCkZpzpE9Be1b2uXYgDsECPU9hsulSP/dWoZzAI1dJJPK5Dqw8ntjQq/W6gNnkgCj34v8t97BRxtbWukLVD3+kre81v8XyXhYa6mxcDOKMeqYNBE5Y5QC9Xtb3bm6EcVudfML/OApJqKFhSotG+xnBWf5Wetlc/Xi2p11sWBZAHGa+Z27N7L3EF+Ld6EeGxlU/uauW68bI9RblCxcHbn3ba1rQvtRJnTLIs3oI/K7sPl9k7SAt9Vfa1+cUC9r5nXrr3y+4n7vUKjJ38mKQ7l+os66d46cd0G31FeWDdK/+f1PqteSyohi6kV8tEUAIOKFIvUe/Dxz5GP1a+n9abFaM11zXUI9k9eiHiLBHKsL80z7tbUjVikWCXNh9L1sfdUXWOJ+7dvm8Z430Xsn9Yv9N+00yogs9boVl+lTcnx3tWp3WRfH6HHHuicFNx4ayiNNAOYVPJZ6WGJOo+ckBIeq3cVV39JOV/RkUzboCun4N04ZKI6r1mo0vnwZhWFA4ytG+JsW1+AW/Pqz1NuLZY4hqof8cCSvZczPhiLE55lZ1iv1z+6RJ+4npPzPCYU29Jh6I55Zt9TnKBTF85G5o4tNUSbXkYMbiwXyV3q/i9zva/Z+Z0NXUsoJ79S2Vo7KrkY5XepfHP/EQdazhlUyMxVUE7DW/zfaVhAnsiZKlyivbjCLjxWeoEmebopXjNQPffapD7R6cGsn3lLPG2r0dWyvAKG+x1AWYtEC1e0Gb5ShL/IYgU3e0s4mN8gxMPZFbRBtQcRpBJX61sz660lJ3r5Q38d200XLlTJ1K5fTBbhxzDJHhl19QHFrixuKEPmZMcdx1l/d6stZxG3159zvbUK9eIeLi7yrmlyePumWS5o7flnV9iv3EQ32vKug/jzjhVhcj12XT7D1i+up3r9415WGUC+/KqHsKGn3Y5bJKwqIiHR3ex+hSxALAO5FHpHcBqR6lUyrRpKraHSuNlkaCzm53BrR/AWz7cj9Qb9d0xNH7Xus9UTW/veVlfYqHy0rAfXFSlAzhXqOUineR922T73Nxc9ZLvP8rO62yruKzzP7Ts1MwOWohs3qzy4AtTAM3W20Xn/bdVRBon5s/MzE5RakmEndIiTqa8+wrf5vs7TqLqwyC0aiPE1Y0eYqUXZsqTdXneKYsjbP6v2qFFk/GQ8hyzN3Wfd19HdtEyZFG+fmPN1TJRpDdWGeVVC4x65Qmjf0e5EVKLFXB9Ho2JBXvCvXVm2WepuiWH73ayxKBFUgT/pde1ba9eTfjHL0cxi3fhtmAknz/koJZUTZ7y3vOygFykCcFIqUhqjNleItzqzK/5RznCtsjsjsM9wY5YupZBN9KqQwUC31NS3Xi7wbh1iGcJn+kxTGnAKRG/OirV4tW9oFgd63JG8K6d0LZZjpJUm0b3ITXblzo1EvTqHKjbO8RT7kn0XIW+p193ui+lxgUyR3MxDqewx22xiPhYGMsb8roy0e6EsXU++KIRPKQs49TS/b6n7fOO7Mj88SEdHEuuVR+fJ54jjh7sNVXTyj4cE+4z6slmTHcxULSdm7gXse3IDnsijp8W3R94xmU4QSXJi3WOob73yhWnNYhOJy5QG9LAlH8vXZ7a4CtSybV4j+XMMwjF5Wf7972NLLfuPN80QUZ01WYtK1RT4Rr9XlJqvo3sTkqysmfPqaZhHT4YRJNXGNva76Z/M4zbITvV/1eoJ5h/s9K6ArbTW23PvsPEFUH2NkS4K+KDYWywHVHxgTU88xMjxAyxr7Fhvux6536bu4ZvqzDudGGWhCfRgGRIvm83JZyWxx/dwixtrnFKWMzYpujn/rVlaosmyAhgb6ooWh/B5Zq0kpdFxDX5TyQpq+TamMGO91hSOnpJWf/6LLUh8JIRZFUOM4kX+GGyMnt11E796/k/Zetkm7J1LKEnVj66HNFbYwmuGRQaKzr9OHH7nFKCNKlGcRDKN+wLTtxLAA7dx6HSUFVnSv9f9rtRrVPC2kvJIhVP7X68y5IQtWjfNCvS0kJv5SPlY9zqY4Yu8n4Otav5+Ecaek93mzjCTLur5PveElI/fdWnJ5aZDntygbvEWZ7h9Tbz6DCObZRteT79OnIXLX1BUSYaC0k75SieZJXY+xXiBkthtV2cfUgVUyqX8HQaAoW7kQzTAI2HFLN+wIeUAfo4MgoN/5pQ/G5XFCfcLzDbX+XD/HnAfEMeJ7OXSKWyuHQZCo5OpGINT3GJwGk3PxdOFyI47c7weS3e+5DmxcKwiIWeMZE6KtHH2Qm20I9aalXj1+obFnKzfYi2OGGwt+uQo2a6zruQqXz6GEZ8Zqji0LNCIPS710rLDU22KXokXson3rHNmKY7j2S6dwMfWiyKGG90OkMNGEJ5sLuGh3V13D73HL1VOcO/fm20QkWeqlupe1fXn1egv0CYhVQOnvymPBo7vq6rDxbAnClqII8LBiiPquGh+h4cH+uO9o53KJ8mQrnLhWpSFQl7RnGlnqI+HLXfeB/jK9ed7cdkjcl/68ZSX/wGDc12z85j/9AI0O19tEJNRbxj4f4UoQL67j75IUn0KYFOexi7LoPu0Jz/Q62KwYyrHaIjT+m5RzXdeRf//IXdfS/Xe8I8q0HYahst1cWldImwCu9wfdGi+zuKh6Ytj6rP6+F6R664hHqbvf67sfiLmSU66PjQ7R8U/cYdwrN//Z2pAt7l1vN4uNdrNx0yqjDN393hYG4MpirWMqTJixjKlvtVajmmcsM1sfrf1G2xZq9dL/JiJavdxiqU+4X1d/5ccQ93jAKfGTnoc1DIMRymwIwY5LmKh7ENW/dxaXCnks0b25Ys8+avzvngMFriSc/Dtr/FaWfkt1F7KXi9o29fG3r1wylIZJ9bR5YBnncII407bE9rK2nQxYBbO4F+l7MdZzWy/b6sV6NHJb2jE5akI5vE97FtF4J4Ub2RTJrvVRtwKhvsdQLI7RgBb/nkrQ4ATJRmGKpd4yqHJWKK6+tVrNOF63ztjqH0829ePWrhylH/3dOZrcdlGjHG1hEcaLNVuHFoPB0AATU29Z9LiEenGM4n5vGUCjczRlBRvnarHUc5O5mKxtlvqQEcB15HuWjymXQiV+qcwNwo0Tbr92B60aX0a7tl6k1jVaaPFtT7yTkdF4j2Ib+uL69TeEpX5IKbNeV3URQ8Q/19gVTdRLup5l8eajQOPelXJdRkuf5HqoKhySFzyibY2PDtG/+b1HjIWdgE2UF21HFtCq8RH6rUfvou2bV9fLVZ6zfU9eW90H+stW65a8wIwUdVX3AkXnkonV0edIUPZ4l8mWBf9FPOcpEoSBNo6rba7KjJc6nAdF/Zkxx2pKiDT3bLtXkY9EnBtb6msW9/vQnvjTEA61czVlEfdchDLTFkZjE4RFvT/+2XebdW4cE7nfWwThwX7ViqV/5spM04ZsMeJ6eMK84/lE7veB2h71vBV6G5Gvb9yLIUyY9xlowkEYBJGl3gdXhnDzXtS5lLOGr/Zxv2ful3tP0TNjFSH8/bjWXknjTtmmkJTnkAR3YzP7vXbfQUCxmJs+iZwLWaiP3O/1LUa5dZDHOMi1eWUONxSHppehL273+7isvnJIFxbUstl37Fhr2OrH1Z8bH8RcsmrNqOVeAnbcCkNVpdxncb83ymPem3zsvQ/eYL0XXbmg58wQZYpLyEkAWff70J7HpZuBUN9jcBpMbr9wnzI4bTEvoCbXxWrpCWP3e/mI2AVYK5PphLLG7fFP3kl//v+doWsv39Iox7JYW6haJ4O3ztfj8oca98gtbqNySf2bvcfGgDKQkFyQe87GgMwoPnR0qwpRHPNkT5Tnv4CXra5EjVisBdm9NvYgEEm+xNsdHOijqSu2Wq9lTjz172Ohi62aei/aQmCu4X4/psXUB4GpxZbP1wlDKcxAroi+iEsh1EeZaS2/c26uSdplPaGMDd1qSaS64OmLhetu2WWUoQtJ8rtVFSVy9nu7cCE/iIH+sqGFlz/rwosru3cSkaVSF+64xW3CBVjX9yTBRzp2w+oxxQtHX+ALgccZ8sOEdYQhH0Oo10G3NLuu5dPWw1CL3UxpqdeVGsYYISlq5frLxJZ69R6trtpRW62XOc5YcOOYeXWe1Z9nJNR7CCL6uJ9kWVXrrl+flOsuOjwZdPd7mweDzRXWdS+udYTuLReEQZwgzGetwozf+j3Ez5C/J5mVFXMrV70uvoJXpAiOpgz1PvnrqP/LhyXvuqGOO1FZssdNwjONst+L9ie1lVIYmInychTq33PDJK1ZPkKD/X1Rf9Xn8rjPx+e5BDOX0YV7p5z7fdpb1Nud6P8DfeVobUlUn2uN9U+Ckl7falD/XcApdU3vz/j4a2/Ywd5LEKgu6iWpL6vbGqtjkD0/ipQcm3k3m7etNs7hYurlHD264im6hpz9nmkjyyvDNO5hJOo2INT3GJz2kXNNc+FyPRW/5bGlnV4fRRjRtOxERL/0+CFrGeJaK8eW0buujQco3dVOtvzaJoO33hZCvek2aS4o1e85xIAiu99zBlRuEe3yCLC538d1jL/rS7TU+7yreNGgaJxLJSXhS1nenz6s7xNrm3d1i0AUn67dbxQf5SGy6c9KLGb1mPq+comdGMqWysoLUE7R41pMJdXVaoVz3Je1TA9h0ufacjk7LttA93/0RmsZroSTRLEiKAhioTRpASNb9+vlqcfpfUQWHNNS1epkc2nWP3PoMdZ63WU4pcF//0/vUo+JxrD6/z4KLq6thKFtAViv77Khgcb//ca5NurhU+a2inr9FxbcMfWXblpNm9et4M8PdWGFHxPnF1yJ8hqWem3LrkAfdzSBzLlTQ+NYW0Z98fhc7vc6rnArq7I1eh7E3lvsdWBXpgmFp3j3Vvd77d6c96IdqxgXpHL1sbRGxCbM4uDd73lrs82TQca29asiXDO36xynmD6emD+Cff/sKfHvljHL16pNZMbU68JjTUpWnGeSPKJ6QrV9k/XcEotVtS+7PKfclnpTQclheHOINUyNUkv1Je3Z3XnDJC2vDNO2jSvp3/3HM9Fx+q5BRB7Kh6gtSb871pLsuSnmtLp3l1lGKQjZt69vGcoRhAHRYs17jOMVd6GhrCNSldlKyBfjHfZ7X7hHyXPVK0Co7zGUiYOJd0xjqeddnepl+nQGn1j++jHmvtXsXut9fHN1udHYLA8Li9VIg6rz5tv1ON4hJvu9bUHptprVf5Ovx02InLXcWEwp7zdpMRX/nrSlnY+7mRw7qrhWl0OaX+QXLEmCaDQIG1YUtS6x9YYtRivTXEQRSUK9WIxrVojos9VSH0j1jdE14NHfHosezn1Uv6btOjrC5VkV5LJZMfQ6DQ72Oa28SdmFo7i4IIhie3mXSPV+OeVJ/VxTeJmP4gPTS/WGpd4ioOl15GCz9Sa0f12ZIaOPYZH7vWvMYWPqza2i5Drc9I6L6fe/cA9dsX2Dcr0kuG0VZYIgUGJHuQWWnEzJKN8izMfl1/+PBXezLhvXjhO98l9pYu24UqYoKlIia+9sMdpqimn7YhzR8nJE/aTxu6wAF55LNkHE1nbq276ypyQKc3r/4LYnPP7IHfTcH/85vf+WPWoZulAf9XefuV19HuyWrZpCKAzq+9T7ylLcWG8kDNSuHyniPdu3XneuD6ljvXpsGs8XWziI6xyBTQDWxwAXoi2z4TthvR2K7W5Tyrqp0Lcc9jE0cXDtlSMKO2gUJZsQBj3ys6jXVMeD8dEhuuP6y+rlSXXtK4fGXJ4U2sEK5I61pHNNyfQZ81549/sg5J+7vnsGRykMaHGRrwfriWvZtpJzyx+QkpLK6aM49/uVY8usdexmINT3GJw23CdeWinDotmWf9P3kHaVo5eh1jeIKsVrJD3KcCwqjQlOWPUWk93v9WRuSr0cmmOdKPu9nCgvSaDRPAC461gtyszXYtKyCvWy0MIeEV+7bnWNv9djxVhh2bqIafyf8FyrKdzvQ8bLg4hopJHATVxLtsokZZQX98IJ1qH2rnwt6nIdbYfKX8fP3zz4ha89TEON9qpayF2Tq7nYVuuW3Cj0nTJs56tCphq/K2MsXOUqaAtrfXwSMdVXXrONr6wDPU5df5dpYlvTbGmnX8d1jDjCR2dhj6m3v6dyuRRtPUSULETI5ycpNaMsyxb3e9f5+sLcJnAKoZVbGH7inhvo0k2r6eB1lynn2vZjjz/bFVAinCr26FIXn6I9ysrc2HPJ1h4YL4+GZStJ8aePD0b/iNzvzXLWrxmjz/7cLdHfpoBI2t/8eK/ei14Puc681xc1FBi1mp9SNHZx198bo9zQ6qWXvmPLGvt1mNwmyu+KO7j82ebdxV/HNYckjjuah5Br/WZDKP8pakuqQFerykK93/iQhQU9pt71XDwU10l11ftw9IJqROs28h5ENuStUo36SPXoK/la6s3fk5Rq+taY9e/s7cI1P9l3NrLPJc53YowL7jbOyQJyuJZ8RplRZsv1XgpAqO8xOO2bKnDx7mUytq1g5O9sE7lSF59BIwyIyBRsuMWubVwOQ1fmZG0hqKwf+HOEUC+EcHWhp57LWfJ02H3qucFLFsaMbQWZd2nZSzU6RrpE5H7vYam3PcstG1bQirFh2rRuuXMyUuPwTAFHRrd8G8K9sE46tpYyy1QXtwI9K7vchuXn62pL3ERis4xkSUqpw/U97tiV48uM4/TPOtz4wNWNyL7A1vf9tp1flseURhPkrRJaGZYJX35P4nkIoWXzVvvi3IYQlG2x1T4KmqhuqRSS7ndAJFsYg0ZdfRLl8Ys67jpWzxTPey6F9j3miUh1hST3gs9Vjyibufbexe+Li/Yt7ZYN9dMHbrlcqgO/sDT6zqJaB5lLN62iX//Ue+jq3ZuU64oyzs/XE0squVQSFr1ce9AtW9Zz9HeujUdxojyPuVu7F31sk5+x1WXdiPE31yZ1oVztJ/VEeTW7dpm5DpdYUu/LtnshIvq3/9MRZ3tP6svKfvKGpd68f18FjaHccVDW5lp2/ZbQpyOhnhljwrDuZVIX6hcLFeqN3Sr0d8isczl8LMdEUohM455qwlZfq9G6jctT1d3pOaqs30rG2jJpXci1Xa6fsC7r2jiqh8dxrF89RutWjzHl8nOJl5I6VOuhrDOYanD3IitOeO8z9TvOUt+rQKjvMVTB2LSi2RZwahn8gofIP0ZJv65dqOMnQ1abaBMsXIKYJsz7aHhFTP3wAGOp1xY1PppgccxgQqI8bgJ3LUSSEuXJz2uisU3ZxJpx9hwfTebOLWvpha89TEEQ0NsX5pXfFAGOEZZtj8cazqAJz1FysAwx9bdds52++af/icZH1Oz3fYyl3tU/wsAyaVkUPD5CEecmLZPUJ9hzPNq4fO0kL5d6mXwZ+yY30X/4q7+hzevMhY/sNcRp0FmrsXYhZe2iLW70fikUVj4KRxu6h0wWaxf3XK3jHxN/r6NbFn3c70eXDdJl29bSnkvXRd8FlnHSldTIBz1xpvF7ENB8Q6i/7T1XeJUpY/OO0ucpV6I8a5mG0jQ+JqmtBkFAt16z3VrP843dImRlrq8ijXO7tj1i2xyn/53p+WjX5hbSdquken026WdA2jgTSF5Zvu2Pj/uNxmFtLuHG8H5LaJ9eX/0+9Gvqv+/Ysoa2b15jfJ+0Xon/jj8n7anNKRP1MpPGLmH0iZWc6hhWrVbrQn11MeeIepU0MfU+iuuktiT6qChLdoZauZrPDG9jYu04/e0/vsb/KFWjrxx6zRHyOVzGd9f8zfULVoFpKePpL92rGAJlDxvulCQjjl4GkTaWMFJ9XGb83QPv2WdVwOtlcn/3MhDqewzVYlr/rGjVPRa8ZpIoqXwP4Y871q6ZDqlGZjIidoKyXHrV8hFaNc7Hx0RjBLOwSMx+34hR5oRtI6u+a2KJ3O/dOwZwA3WoxXr6vEvOe+Ced11JwwN99K5rd/LneCw46mXyi1KbpZ5zA7Ndlytf/B7tOerR/PTtmB7/5J30q4/cYWR752L/XcoNZW9UTti2LIRdcJO0ek2z7SX1QV+XTV1jruPjcr77knX0W4/e5SyfiBd02WetfcV5yYiy9WcTbWnWxAQe7UagC5CK8jGhDMaaZGv/kVXR6z01Fpwe2cHLpZCe+dUPGd+xuQ9sAobnWO/ylCJqvJvz9XczsdnMbpxcvu5tpfaZKKRKbMvm5UWmWTVZpam/MCTXUxwrkpJy27/6KqGVullannXLNq3t6nHKLoyM+lpZfjlI1HqpIU5xebq7eq1W90bx7cW6i7CeoV8PM+JCLZKvEX/mzgosn5/6lcPsnJnkmcUqd1IqE11GGRsiTE9YqnXF1qKIqT+fXJ9mEOu5bRtX1uuhC6Seiuuk/iYYMiz1dYKau3yOzz5wi7SFp1Yfqd595ZKxOwmH4vkRtY/Q+M64lkXZxY11tuejK7vElnG6h41xDec6ih/HbffCWerfe+Pu+BymrvJ4cOsdsYfWUgBCfY+hCq2ma6yPUG9YT1MubuJjpYHHJrQERDXPwcG2WP/9L9xjdUXXEyCl0VqLgZ5LNuJaDBp1aJwvW+p93awMS73HYopbtIRhQO+7eY+1jsq78rGG65pQi7JB347KVo5uFdafa7Q9icdCTHe/D4JAycjPJ2hpnOOy1IdSHDfTJgwLopcgICQTyyKPWdwnW+qZ8hm45GBK3VTVt/OaSfXwTRblUhbJn4cH+9VY5SCQYoabsdSrAgjnOpy4uGasFXbB2d9Sr7uGpn0lDx3ab7HUuz1+kkhKlKe8mwyCgDjF8OKxKRi9hFZ+jrMJXj7WbT0x2wXhfq8I9erYpMO5FyeF8+gKYNeOKfL3LsQp+vzDWd1tz8YcF+U6yBY/uY/XBfo0Scf1BJCGVdciEKZR/iUJ1zYXd6tSMkHJx3nmJdU3KeeE/J0N4b3GbZtZCoN6TH05rAv1zpKa484bJqlarUWeMLoSzsdThMhPyCSK12aRV4tYb2TYSSUIAsULUKmP1jZCre2z5zjWn0T291AKA7Ytckmo0ylwzXBZvRynUK/XIyE/wOjwAF26aTXtvvgitjxRzkAfvx3v/pt4Q1avAqG+xyixifKkATCTpV4632efrujY+DyrVTkMiRhL/TImk7dtkTkyPGCtg2G1SLFQ4xKPGbFdHgsEcYy8pR2HGtcuzlX/9tG6Z7FUKmEQPgO8Q/hKk/2eXXgEZnIhEQ/qs7ge6C/TzXsvof1XbGF/52LufdzvbclZbC7bPkJR4j71jEdA0vvxXfAkuv4rgoXzknz5WgwckTYWMe/S5TYnfz7+iTuURJFhGMRtxLIrhA/xM25ck8x3maT0crlQ69jyP8jo4TQ++9Rz3HYNvxexPf7Tr9xyyZ0oLwylRHkZGpLueWNTogmyuJdzfSvtorduvYrPiyz1cvb7hLGBt66aYw53LzZlhz72+q0BeIVf/NzMvm2rF68wEf8zifKqtYal3q+t6DkddMWJLQdDVq9Dbi5T6pow19nKYOuYSqi3rE1SGGXEOi3aNlOrW7Vai3MoZB9mEymXQrrrnXIOjMYlUxqaksJdBPq2k2KHjp17NlrPyYI+d/t4HMhnpDG0qZ6F5rPw8aTV2bFlDZ2de8uou0Dfr56vl6ONM/dSLpfoD37tAXt5jfP7GY8oWz17GQj1PYYsc7PbJXkteNQYliwaPf1Y18QvHO3kiVFMHMrgkKFv6q7QWSz13MSql+szKNq20OPqI8rTvS3k69i8E6IyEmtkubbP8Q7hS66XvmWdrRwjXlob+OdTxEsHQUC/cfR99t81ayyRvBC0lx8Elu2JRPvVFTEebSJJ6aGGflCjjmn6oP/kqlNK2SZ0FOVCtKWdeX3bOfW/+eO3bVipHBcGklCfQvGoY7goau9U/8yRJqaeUwAY5YVqXWopY46TSLIaJ1G31Dt+zzh/CGJhRS1PH4P1410Yrtic4JlCGBKMLhuk0UZCzrcbMfX9sgUpYZxxeYbYXnd8DinnBlobFvg8H114+OHf/ISIiDavW9H4Xi7P7144JZdpqReJ8sh70JGth/J1Y6FWtSxm6TdJFnPd2yCpDG5bR7nsaA5JoWy3elVIpyUpvIw1haJcCmmxVqNSoz23UlgyFXrxb67xPin8TyDWelGIU+PwG2+9LFN9rfXR5zd5eeuxBmAFcktH0RVmhichozhM4uG7r6OPHZoSBRq/R+son/ksQZHqiyhHEeoZBeJSAUJ9j8F1VHkASBIEiZjOz2j7fLC5ZMtsWb+CFhpbEXFjsyo8pcdcpJuDnM7+y7fQy//hh7RuVcU4znDti55Rcl1sWYLj+kj1tl1Hm2Q5ajV/V/Xoeik1m65DbLGTruvqwlv0zBv/pRHqk2Bd6Bufyw4r77KhAcl7gynPMWla6yLqYJvQmXqnigV1WjHcrt8+lmYXnCdEkiuofhnfOgRBPu73cduwh+0kPYsy81ztlnp3CIRcjli8iVCUvBbVdo8fv+cYBoFT4FDDsLIv2mxuxZks0RZXdZvw5vusnz52L42P1hNyRu73/UyiPNt46FjoJlr3LYmj9EV/Fk8Gwe37dyrXInLswqJb6i39XVdm12o1qlZrXvUUdeE8gAzhgbT6pBlHE/q/qvRzvycil+eiVmdmnrHWUR9LAr+6y8SJ8swQnzCsu98L1/K8lIo+uObWpJA5ouR1qzC4REaEhpeNzY0+O2o9fBSe8recd5LLC8zluu8Tz8/WR2ub8jPyCicL1dwuSYr+5PrU/5eVpz5Kj14FQn2PwbnzcG6wLowtYZgyiYj+4NceoNfeeNtejocA+uVPvzeKEeUmrbTJinSck4GlvN84+j6ae+NtWl4ZNq6rW1o4C09WuEXkQH+ZxkeHaM2KEaMutncZJXlJUSXVBTL5eKdlkUmUZ7dUmteva5jV78Ue1M0IbPE11Xcof3YtJH/tk3dSH2OlSJM0USdJqAuZiTdNW3Nv9+Nuu2kWgxyqpd7Per2oJRhS6uC4VhjGifKacb83rVzcIspdhm45rX9nO9bDXVFrV2mzgydhXUx6tmM9dtMoP+A/+2Lbdz2SXbRrp8llob9vxTvFMu+5EJZsojj7PecWmpRjwWVhSzonSbnol3NAbZeXbVtL3//Bj2lnYy93H+WyXh/uusOD/YZCuVojWlhc9Fbg6u1vfHSIRocHpPWPKsSIQ1N5HSb0f5+x0sdj0niHlFyuXi+XISNJuBW/R2sIpfyAFqtVGuprfg5Oiz6m+nrRJIW7CIY09/v5Rf9wvzToxfnkO+CMDz7r4lDrF7rAnUVpKSMStvbJnpkeayDdOyfJC8YXLndJ/QKZi+xKINT3GNxgp1jqPQYpm2uiXtalm9yZjP21+eoENjzIJ5TLpHGLFn6N63ks1Ab6y7S6f0Sro3q+HkedxwJbudfIchzSv/zNjxiTjviNI97+zR+feD9fuC3tbJUJo2zj8Xcrx5bRyrF69lvxHBYKsNTLwl8oPW8bF0+siv9gJiK9LQjhy1kXbaGpw25pl2Yx2oT7vWpB874ke360pV3CYkRsSxdfmC/PuFYQK358LcwcPvG3Sf2Dy1WQFOLgeqWxpVH/3lkNb5K2JEs8v+Te0i6LGzt3vi6k2PpDmqR25rZI/DvLkuBPeI4MMG6hacIxkpRvhreBQ6irH5/8fLasX0FTV2ylq3dvIiKik1+8lxaqVVZxafNu0o/l6n/s4QOKIi8M61bihcWq91g/Mjyg5NU5cv+N9OH3XW16CljGaR+SXIQVnbhtLPdQyBvZ71MI5Hr9uLZm63/X7NlMf/rKf43WGUJg0700q9XY/T5Ln8iKre/rdTTO88x+PzCgWuoXIiNCvvdoKNi8BFrzXn08WOseLLLCTL2Oj0LBRbSFbNm0kCft5mKbT7PsqCDm/YF+3v2+lWEinQCE+h6DW9Cmdb/XF5pZFzfq9mvJbkyiQy8b6uevl6VvNuQqXRg3ynbAaeENa0gOE1xJs1gIhgfj56Eu9vLTItssVNnKMt3v0yxiv/HPPxQnrml8n8ce5AI91lK+jq8nAOfZoAvoUcZ+VznM/St1VWLumGt7ls+RmChPucX0bYJTJiZZ+ITbY1SGhwVM/BYnykvfRsZHh+jsa2/RcGPscbllJ/UPNi46of27lC+6pTF39/uErTGTeO9Nu53tQ37P2cI4eAuTzYKdKqZe61OqVYykz9mftewWqmfI19G9EOqfG3/YhEVtTkrKfu/TP4YH+5WtKsvlEpVJWrx7zEOuPiTYdNFy/W6oWqvR4mLVux9/5Rffp3hDDPb30eCK2DAQh/40rpAwJ3EkCR4+CjzFUm9x67YpFfVruMrXFQKKYtjyrn770UP09oV5pl7qudVaTcoH0EKh3qKYIXKvg7gErRx6/iQxl6Tdzi4Jl1dRUkiO/NlHEA6D2OOxXr7u0cNfwxchTPcx+9i73e+1PBpMPow0iDCnPka5QJSfR1u3AKG+x+DGIN8BUOBKqJEq9iallrna2It82VCsdW82NkZ3VfXV8MpwE7YtE3Mz+CRNURcG+U04zca9ysj1cm1/Uv/dfH6jywbjupA6yebpfs/HYfqVHzATot7GFqv8XrUy+oLTuA6npU9jqXe8S/GcZSWacq7cJjJMtsq4UzLvk2tnuqXeV+MeBnFMvSsvgo3/8Uv30Z/8xQ9o19a1St2yLK4jBYbPgs3DkqTHBGcJr3HRrPv9A3fuc/7erHulLqwmWYAz7VPPJcDMOO/pKBYkzSXcqJfDEmmb/0z3cv1//hrN4BMG5upDrnJr1XSWejnkwVVXox4pHkNSG/ZR+nHeF7ZjOAVu4nsTtxWNF42/PQwZYRgoxgNOHV0KA7owX42E+lZaQF1eFu68MX5tz3C/z9GIIOMU6n2U64zy0XZndYu4KTBHXqZNelAJ70nZ/V48L9c6qq5skO9b/S0tYpcRW0w93O9BV8N1Ch+XbRl9IMzqpqMIoB6W+jfeukBE8XZ2ehlZ5hDhAc26V/om4mG0oi53sKz4eETIl7EOnBlibpt1tZbhssonKSmSLNXCHc4nfCSJSEhg2rWv0oBV9Gj34uF97/185GPSeGi4+uut+y6l9V+6lyYt+78q1/a+YgznVZK0sB1pKPSi0B55bvZwsySKBbY0bFw7Tve++yqpPP2dSvVIeBhprPs+i069POEam5cFIs+tMfnyk5+DC9tWbZHQkkFo1S3mrKtyk8oIQT8T65kUP8uPL3z5NitmM+EJSahzu81Srym+Pd5LGNQt9QspLPWJZSY8H68yGMFK/T15/vRZD+nKJR9Fv+06LgVRElXG/T4IAqpWq5E1v4UyvRla4imQJvU3gdinXpR/IdpCN9+b1NuczxyxIIWnrBqvhyUq78VSRyNRnnNdn76vCcVHHyNMu9pqGKrhWs1mv+cSksL9HvQMXGeSJ/GkDOxEpvVIj6vyRU3Ql3xeJNRLlsNm95vUt3+yaQhdsLHBgVpGHgNHam2/5Zl6yJIGpSYHVhl5kRdlArdtaae5wRq/N36INOc5eCcIC3qJif33F+rlz40/tLbgY6lPimtXYsotljcXrgV8uVyiPZest9etSYWaUo8S0/+YDnjF9vX0pYcP0DV7Npt1cJSvbLGVQxykvjhJ436fZks7Paabr4s4pv638D7KT+h2W1qbxcdC6cK2v7Iu7MfHe1jqDddw9Xu93Gas22z2e5sSzyG0JCn+TOUiseflIahwXk46sUXQ7Z2gnBME0bjpYwjwwXC/zyDUqztZcAdIHxMU1ESOHEPaHMLlVLERK0/UemQRcETyYvnoMKwnMYzc71soLLkEUp8t7ZLuW4T7ibIWckzMK6NX1ceQIyzRB6/bFSkIfXJN1bcaNd99M2thpV5CqC8xMfUJ3hM2D4Vs7vecpV72PE1dZFcDob7H4DpFWqHcWDwxFre0dUljqR9WhHp5tvS+dERV25olyzYech2Em5bIjD82MmSU6+L0//DxKCuycZ2Ui1/bM82yj7Vi3fQ87b4DV9H2zWuM7zlhOSleLCkOMdacNz/JxlYIOfa/sfD0fGacW7w+afrE1Cfdj/xc9Lg/H5oRRrJYiWz4Jo8LgoDuuP4y5W/X8dxxuYRoOKxdSY8iSv7o4f3iZdkQY5dwv8+wZaULn1jOpsq3WGW8z9ct9ZwFsmHhJUop1Et9Ngz0WM/mlBGCAXmfeov1PLqmS4lkbUO8Et4mvOYZwuQqrxSFOJBSH2e5QbxIzxJGw5fJt5+sYUysN6SH0o/bbcVWDjcvJj0//X1zHhLe80E0xKh9oFqtUqmx7sgjjMOXKFwmpfeBHrJjY7CRKE/MefM5rjdk9Lbj834/8M49NDLcr8yLZQ9jV7kUKsojw9NJeYbp7zN2v5dzhvgoqbVY/wxKJ5nz88wuI4rYsLSkegj1PQYr1EsdxUe4diUlSeV+r0z8yee9+baw1Esx9SkmNY6aZtXKci/ydYVgtWvrWvqjE/+ENqwZM8oVfOEj7zJihIUygL2OVJ+BgT7rcYKkCSfN4/KJ7dL5xQ/dzH6vTDiRpd59XauhuvF7ntnvF6ti8c+0Bc9nxsW06RYyn+z3SZOg3PZWRq53+bjfJ56bo4qbu0+f+7C56emoCrHm24gRl6y8b/dzKTNeCbZxN2nfcq4O8ZjmrIY3SZm4myXL2KKc71AyC4IwIFps9GuPuUbEDw/JO61oi81mF72fuvcG+sb//v/ShjXj0Xf6VnE6nGUxUfGpKygc87d8fDPISmDb89Zdpb3efSAnvMzHUm/zuknnfu9ehwQB/1k9Rh4P3O+f33nIXcdoHhIHNr4IM7TjGjN31b0oalQqB8r1WoErHMqlcItC7RLuWw8VyTOHj4w+d/jknRoZGqAP3HK58t36xrqzXgZ/rU8evl6Zd/TcG80qLUWiPCWHkkffChzK0yxzzoWGkUzeZUTpo0tLpodQ32uwWuSUwrWuyVMH0BQCRUplQhxTHy+0fBKCuHC53/taZeVzBvtj96eNa8fjujFFve/mPanqKg+sg/3JXdNmycjifm9zO81CSd63NMEqwmmNZeJEefm5w4mEjGmy9LvQF2DiWabKfm8rW/pBbPOXpo4u18Qkmg194Ujr0uyrxW/WxVsntvCkqwcR75XQZwl78nEPLWmKsThRXv5Ct/J9EZb6LEK9bolmrN1hENBi9Dm5za9ePkK/80sfjPZdJ6q/c5tnSBZB+IE79xlJBJMEXD73i3uM3Ll1Le3aupYu2bRKKZsTDF3XToOP+318r/6J1cIgoLcblre8kpTpz3xkuK7QsSUI5Uiydvt4FKnrIfcziwR0j3Jv37+D/vjlv6SLVlWU41hXdc92zCXjLIUhVas1CqO1XOukJVc4lHvbVqEk8b1O/cD5gmLqXX0xjUC7df2K+DzLe7h576XqtR3tIsu4LJ5RP5N1Psl7wjYnZMmHIzx71DCn/Ncu3QKE+h6DTeIix9RnsNRnTpTHCE0u3njrPBE5st9nGGBrmhtZs4nybDkJ8rB+yHUTiVtcWN+lUGSkmHTzFOpVS33SItYUgGTE1/OL+VnquSRASfXQ4ayPpvt9VfneRikMrG1bro+YtNLMe3lZ6nMTIFMuMFULmP14H3fgNNhcWes/us+N23z8nRzvxx7rYakXx+SfKK9gob5JS/3Ksbp304qGl1NSTKhvToV9k5uUv4OATyxFlN/i3jsciQl9sdVg24aV9OzxD5nX4BTZmuIiK1yeGeOYBOWCrdzIApizUC9ue2LtcnrmV++nizeu8i9DHguZ3/3y4cSf7TsG8HWuf8efc/yRO+hzv3BrtJuJa+zynQ/0dZM4t1qrsfknioZT5Alc/T2tsj621BcUU6//nUJZLCOvQ31PSxoX0jLPud9HWwi6FS22beyyONnF7vfSM8lxPdttQKjvMbiBoeQxAXNlcJNwOqE+/uzTsXZuWUt/feYf48zX2nnNbGkXMhOR70DmsxjJZaEklTHk435vs9RnCLmVLbrN3orcxqJJ0VJmktBfd9WK9y/PY5JdZIX6wFlPo15kThrx4rv+/41XXUJX7dxIHz2031lWGIb2ZDdcf04h1TcjjKgCdeZiFNIqj9TFst9xubgX69ZReXGdqKQxQw1slnqv7PdRFRrKoprZfpshKdFZsygLrAx1nrx4Hb3wOw/HniqiXhZBKmv4hR5T36wliyPeOtPS35n2ECvz0gkmUdPNoMj2vQaRfUyuNITMscb/Pu01CILcXZ/FeCk/h8u28Tt+uOoVlcfUy0cgS+V+n8KaGgSBsg1s5H3PuvB7ut9zifKCekx95H/WQlnJ5a3iFiCDxGNkRPnzCw1vkZxj6nXvvSyhETpnX3vL6zhbbgmibOPyfQeuov/nz/+aHv7gddF3PvPZ8tEherPhlasfm+UZxInyJEt9ghKul4FQ32MkCeI+E2V/X5nCIGBdwNMlykvXQT/34Vvptmt30NQVW6Xr+S3qbeju96rm26/ANMkFm0Fx8x/wcb+3JMqj9FJ9s9Y0GSVRHmfplK/rca1QWujlE1Nvd7/3VRypSeTq/4t3Jv4fGuyj3/vCPYllhWFgf1XM96kSPDWxKFH7Rz5TY1rhS+mvjrYi99FctuxyWDWSBDzOw8ku1JtJ9XTixXn972ibzgIs6cr3BXhnZC1TCPRyGXK1cxHqQ/v+yXklzEoSMri2s25Vhf7jf/lxlJE78Rr64r1Jixx7DdlQYLmXyYsvov/1yz9Pmxuuwn5jPdF8we73mcponDvQV+L7fwqlH1GydwNrZfesvstS7xtyyPnfh2FQF0ozeAI2i2sd4Yyp98x+r5dVlKVe3p6OSF1HpO2aT3/pXnrqX0zTlTs3eh1vJtKMf8syvm3buIpe+t1HtGskJ8r7Z48cjIw09Xo0Nz9cSLDULzWpHkJ9j8ENcD6xXDJDg3301c/fTVs3rDB+S2MdKjkGYo7BgT5FoCdq3lKvu5HJg5ev9SWtRTEr8kDk436faKlPce08Y8cUS33ClnZc0hbjmCCIJsM8FteLoizp+cUWEr8yuK2Gbrt6By0b6qfdl6xLVR+XSyy3U0Kaia+ZdinHt+VlsJBfc9qYete9FJX9Xk86llQP+Xcft1fxvWuxrfchLolVM9hdgfMXAPOJ5zYtr3l4aoSBI9azVe73THvbsLqeFOvHP3nN8xqqIKMIDi201AdBQNskF3dfa3b+7vdubzEfxDggWwOVa3h6FAlszywqR/yXoQ3qnhpZ4rZr2q5B9euHVK3V4rk4nzyGXnCeC3G97PcUJS21HPPHv/sI60lUVPb7BW2b22ZC3PZcsp6+9ksf9D5eF+bzULbqiHWkaz05MjRANGTWK2s9Nl20nP72H1+jtStGcyuzm4FQ32MkuSf5DlJ6vGFcln8HybJ1jI4ihGcYX/Xs91ksOj6DQh4LbfnZDnhY6vOccLK0ERvclna2dxdbyO0obos57FPPbWkXtQ/PMrjJeGiwj965b3vq+oRhaJ3Qf3LuTSKKs3WnqiQ1p6xRk1TmMzGm1crLY8fwoF3Rlbc1MhbMzXokVptZkNvwstRrSoLc3e8tnTM367QiVORXnk3gyarUCcOAbAnR8g51SPJckushdlj5b39/zusarizvRVjqfduJr3I82powL/f7XCz19f/7LLkx5KJ97jMpUR4XQ+6d70V7/3Kf833/VW3dVP9cnzvnFxYpDAJ68BO3epWVB6VSSKVSqCRDi35rYp/6sdEh5e84pl6EgOQrEK5bWU9m+E8+cI1Rr7wVCDqGF4iyts53XEijoMiS80Hm8U/dSf/3n/1nete1O9gyEVMPuhpu8FJc5ZoUirLsU9/MZNp0TH1VNVtnGUBiK7/9+DyMZ4r7vVf2e/5dZImpV1yFLQsXX8qcUG+z1DOLWJ283WAj93vmAflOAG+dn48+N9un6m6//G/CpWzPpbH1v+aRVV8uOyvqQjVzMQppBSW53YwMD1qPyyJkuNAFgTRWDfGrlydCZNlwLEw1xcJl2y6iv/jLHylW0Gaw1TO/dy4pDHOQ6kURdlf5bBUPg8AqROXvfs/XcWiwny5aOUpbpOzWYku8Rc9+L6rKzb95CcpqmZ7CZkrPnLws9ZxyI2sZAxZLPZdjxYWv+71iKfcV6l1jV8p2rOdjqFarNL9Qpf6+Er3z4OWOM/OlXArpxGfeT5vXLTd+c7UrTgHoQpRV1JZ2Q4N99J1vfIZd9+QlWNvQt0ssRNkndrrIuO1ulj46NjJk7DSltImlJdNDqO818kiU5yw/QzxvM4vDpmPqSbPUK66I6QZ6m+udfJ1mSJ8oz/Yu02fHlp9zX46Kn6R92H1i2X0SDKWBswTVUsYs7NiyhkqlkL78qfc079kQ2N3vD153Gb3x1gW644bL4rqmKbuZmPoCpPq07qTyZUeHBxzH5Su46Isu5fYTqm0kTnQc72PZiMbRxt8f/+B1tG9yE12zZ7O7Ip5YXYFzW+jFn/NYuHILdVlwy2qZqYwMUkVSHKV1qfaBs8DKlEshPf+bH1H67QZpT2qva+jhCU1awlzXIPLbUcf32oGyVsnHvzua25q4dfHebLkx0nogWUMWQn3cSacsIDLHlEwxy8wkUwoDqtaIFhYWrbsAFYkemilI2j5N/j8J8XzEcqAI67ntfXjnO8jIYH+ZSmEQraHUvED5XDvt89avnZvHQJY23yNAqO8xuAEuT9fqNB0krZaUo9kMxLrVOou7k7iubVsqonjP2yt3bEhdR/06RPbFg0ySpT4Naqbu5oYFecGyevkIjY0M2jNsJyxy9d/y2afedF8Wj8y3fd++fye98+rtuSgZXO73YRjQPbdfqXyXJtSjKUt9AXFpafuf/FxGltmF+mZd+IzyNGuGz8L41z/9Hvrmd/4yztIeefjY7zMpG7pSh8YxA/1l6wI3C7Zr57XQazYRkq08zorZzLv/2uc/qHhIFeEa67OFoX6ti1aOWo60XEN7PkXch/zsvS31Hu9efix5WeqFANrM3BEr9pPd732UBzaFRR7bjun9I8hQRpWJqQ+CoGGpX6S+nC3YzeD0cvIIb1KPV4/L21KvI3b3qdWKt9Q/+P5r6Oa9l0b5moqw1Ivn1Ur3e7ZMObRgiZnqIdT3GGz2e9nS2aQVNov1t5kBQ7HUZzhfz36fZQAR+41z8VyCwf4+eul3H6ERhzUxibTxc7YJR79nH+SJsVlLvbwY+/R9N9JH7rrWYalPJ9gVlf0+yzPLMztzKlknhdKmmUlS2eYwcykqzcS6jQz1W39TLHw5Zr/nxg1bvW+9ejvdenWcUyFyrXe0k5JuVWWIrHY+Fc9A0dnv1eSkzZfHCTyBx7NOYq0mPNvi65tBLDbThCGUyyX6vV/+WVq9YsTvGg4X7rwW71lCE7xi6qVWnpdAdfPeS+gnc2/QZVvTbWMnE4XgJSW4I79+U7YoQvR3lsWK6cyg772lXeOapPaBxWo9UV47LPU2fAwC3qEL2nF5b2lnu+ZirVa4RXnNilFaIyWTK2SryyyW+kKMB1L5S0umh1DfayTG1LdQwxp31uy9qtm9NPWEL1kGEJGB3OV+T0Q0riVdSUtaISfPScBnT21f5IVPuRRG+xVzcNYk85h8F3qLi4ylPsOOAXlRCoNU2uQ0oR7NWOYUuSMvq60S+56uzFFHTH0p5zbiXFx7liFOcY25PotO8ZjyEix1bG0kr/Elb+GYS8Aq+k+eu3gUYUGKcjWkLO+qXRPex4p+K7tfC2tgXot3Gd/+ljYxZl5rldXLR+jhu69LPtBBkvu9PCj4dJuSzVKveQZlcSPWQ4eyJHzkst+LceLCwmLTa4Q88XG/986fZFjqi18R1N9XrbDx3UYRLuo+W9rplAoYZ5VxDkI96GaShPqiM2zKJMVT+9BsBu5dW9cSEdHeRjb/LAu18419MH2S1zVD2gVpnlk98xTq0yzGYkul/Zi8XTKrjKU+sk20Qa172zU7Unl4pAmvaKrvKdbpbGXcf/AdNDjAuzSnrZvL/T5vwXHX1ovo6t2bo+0JsygXxb262qzPojOOqW+tUJ9f+XI7yk+oV9uSuFZ+91JIojxGuZw3wrVbSVjasAYWIaT4WjN97rmIRHl5IOpucztP64FkuzeRpLaZuGe9f4wMxeNm2ph6LgfK+QsLHfVufNzvfe9bX4O1Yr0chgHRYr5GGu/rMp+bIctOE0WH+SGmHnQ13MAvD0x5bAnmS+z+1UwZzbluHpjaRZvXraDtm9c0ypAHMr9ncWG+ngnVFVOfB3kJ6bHrnD9KG2lywk4zEbr2n9WPSVu2DeF+z1rq2zD+f/q+G1MdX21RTH0eE+PR+29S/m4mvtqVKC/vuOG1K0fpa5+/O/pbrmq/p9JL3Ksr4ZePZSOP3CQubJ7gOWzoUS8/5wVWNGYw3+Vp7VJdOPO1IOXpUaBz0cpR+sQ919PNey+JvhPWwCKElJLnmsLnnvP2ysqLNInymhHq91yyjj597410895L62VR+r6jz6mKUtXXUs/0fnH9C/OLNOSx5W6rcAv16cZO/bhWtMEixq401yXK01Iv7iVF9vsC60FU3LzZqXROzwS5wE2c7bLUZ9mzUkfV7qcvJwgCumxbHEuXJTmIr/t9s+Q1oGWJD1eElma3tEuhOCp5tJE8c0IQxVtDlRShvvHMmi69BaSx1OfU9/KaF+Uul9YVWLY46RQtDMjP0XccEGOtq836uN/7ZNFvBpsHQJqEjC7yXrS5QqnyfPfNhIrYiC1Zxc3DQRDQL7z3auU7YQ0sQpngban3ePdFJMrLE1ssedrwHFs77e8r08/duTf6O4s1NZ5Tzbr5rv9qCZb6UYfXVKtxPZdySiWaPj61xFLPhFq0gmLCi9J756bdEccH1cN3adF5oyZoisREeS2cKPMQ6kvKpNZ0lTK56V5ouN+7EuXlQd4umWkeu5oor8mY+jSWeh93rZytsCL7vbKlXXSpzp8C0sTUN2epV4LqM5cj08wEPuiwDslFFSG4yPX2HQfE43O635eSF0FZXBrTUHSTbzYvilEeswiOEpkVEFMfBHla6ttrlev4mPoOdb8X+5bbksjKt7Zt48rE8nzvLcvuP1w8vqCZmHrRdi7ML3RUTL1z5xAm/4YLM/t98f2U27O+FRQhTGeZq/KeH4zrd8GaLk86Z9QEuZCcKK91g3EulnpFA57fgpDIX0AUMfXdYqmPyTawNttG0kyE0XUdp+StlBLbDl4ysTr6rlbNy9m4eNIYUJvap16J58xcjIJrwel7Lvtbwd5ImYT6RqNuNqY+8OgjzWB7rjkZ6nO3CPX3lalUCml4MN4NIc66nN+7DwsQhLMkksrlugV4MgiyWkE5FKG+haGCScRCvTvBHRHRtXu2JJbn692Qpe9w4TrDg32pyli9vL7TwthInPxXnHp+vrNi6l39c/8VW+md+y6lLetX+JXVBvf7tBn6875untfOMr4V7X6PmHrQ1XALNHWf79Y1cLFtTzOdSk2y1HSVMiX/EjH1A10i1Gdxm1UT5TU3kaVRCvi4nslzdh6T7Kfvu5Fu2XcpXblzY/RdtE99ixfbWWjVPvVFTrZ5P2dFWVe4+71f+xa5D5rPfl+0pd4i1OcUVZ/3AmtosI+ePnYvbVgzFn1XhCU62iavgDj9dlnqSwW0Id/+5pUor02hgkksLNTzsNjc70UfXzm2jAYH+hLL881DkCXuOdoCUzp+2dAAvfn2vHcZX3zo3fRH3/r3dOjWy+PrR5b67sl+v2vrWvrykfd6l6W30dZsadf4v62W+ry3tEsRU19Awr4gwzq/V4BQ36PIC081CVrrBuN4S5XsZShWsRx6p+xR7DuQ7b5kHf1ff/af6cqdG5q+vgthDWiWLEnfFPfHf+l4AAAdJklEQVT7JpUXaRbBsTeH/Zi8XTL7+8rGFlFxTH3nzwDDjf3aZaHGRjOTZBbXT98y83aRl/tyEYsjedzwtdQvLjYEAceYKxSfPokiC0uUZ/uhCEt9Tvcg50khisePPJXWRShTsuxTn891i1GmEfkv4H2u3anu9wuL9bnZVqdyuUT/4sSDtKKyzKs8f/f7+LNvOxxuKBWGJOXCyPAA/f1PX6f5Rb81xsrxZfSxu6eU7+Qxu5PeTZ7o/bK1ifJaPCZIzSnvnCFphrciEvap99P5a7o8gVDfg/wvv/7ztGJsOPq7CE2YDz5J0JLYd9mm6HMeNc+SKO9DB/fS5Zeup8svXZ9DDeyI2P1miePD/c/J01Kf5n37ZPZuRU6ILM+sXUxdvpU+/sHr6N37dyYe25z7ff4PI7ZK5PselQRbBSyO5DY46Kn0WoiEeg9LvaPOt1+7gwb6SrRsqN96TBb2XjZBf/b9WaqMDLK/52WpVxMuFtPBIvfyAra0y7MfZFn05oG4hSKEFF83eZ8Fu5oor3OswfMNS73LQj2xdrl3eVnc733jja+9fAud+Mz76Zo9m6PvxNjxxlsXvOuoI/fdTrLU54neL1ubKK/wS6nXLWBczqK0LELpq3oh5FJk1wChvge5eGKV8ne7YkryiKkfG41juvJYYmZJDhKGAV2xvVgrPVFsgd24dtx53Nc+fzddcFn1M1idFaG+pXkX/C2VRAVqztu5p11KwjCgB99/jfexzVwnj3Jkslid/9VvP0SDCdbxTsx+L4R6l6tt7H5vL+fay7fQtZdv8bpmGp783N302htvK7HpRVBqgVK5yER5+cbU56988KHIbbO8LfUpY+pbGSqYhLBw2/apT4u3+32GcIS+coluuOpi5buRxtri9TezC/VLwlIvPeMgaI0RjAuXaAXqrgh5CfXpxxl1nZFXGID0HmGpB71Gu+OEm1UqnPqND9OL3/4+bfVMduJbl06K2SMi2rxuBf3Wo3fRrq1rncddvXuz8/cs8mnYJi18ZKl3HNMKl8zomRVSevtopu8p1umcdn6IhRr/eq1dOepdrv45NzIkylv0sNTH2e9bPxaVSyEtrwwnH9gkRYRx6Ih3UkRMfZ7tqd2J8orwYvGOqU+bKK+DLPULDSW6LaY+Lb7zmDwGN7M3/LLGdqBvvHU+cxly3+pZS30b1odC6Gz1ejSLF0gSPolfdeRhIa/pISygzG4BQv0SoB0LRiKian1N2/RCbsv6FfTIz16fQ40o05Z2rWTqiq1Nl7F+dYWIiNaurHifI7eRrFmHT3zm/XTmx2dTnbN5/XK6Zd+ltN9hiVRivwpzvze38OkF8tp5Iq/tHMOCLIZFK+vCDM8ijsO1L4AH+ssUBO7t+tpFXtnv5fdRlNfYioZyIs/xIXJZz7HORW9PaKMIBYXAf5/65GPatf1uEsL9Pq86ZXG/H2rCo2ZkuHn3e2WHnB4V6otOuMrx07k3iaie96CVqAlMc/JAyaC03Loh3gIy7zCARqG5lNktdN5KAuROHq41X/jo7RmyqteP7yTZOe/tlTqRj//s9bRx7Ti976Y93ufIbcQ3u7eO7vLnw2B/H/13CdlpZUVM4Zb6JTYBuMgiyCbRzJZ2PuUSFeO2K5fv2z8WPASBkaEB+q1H76JLN622HtMusuyiwaFaYorpX8Lj4MKFfPKSEMXWyGpe2g0qNmGd87oFJuPy7W8+j1FxN+8goV6E0uRloS75eiFIj3bII6u+DWGpf+v8fOYyVG++znk3eaLuvtCaPirGl50JHpp5I7fl3N3vUygJbrt6Bz1+8o9zub5ej3pdltaaDkL9EiCPhdT7btqd+pxqY+/vvFx78qCIpBydxrKhfjr87qtSnaMkwekgt0cizXpTkNdJjuv2nkHut3lt5+iTGK6ZcokKstRnyH7vkyiPiGj/5c175xRBXl1CVaTmVKjG8ko998rcG2/nVuZFDU+nc6/nV2ZsyWqtUFRZNkj/cPaNYhLl5ThfqInyOkdwTNqnPi1lT0WI6n6fXaj/8Puuph+c+Qf6zM/dkrmMsAXK9U4gDAKq1motd4dPCrvMm03rlkef83O/T2+pHxrso6P330R/+cMf51IHIi20oDeX+VYg1IPCEBrIThKei9ibs9foNNe6ViTKq3VgW22Ggf4ynW/Sailr73O31Hez+33aRHldugC+eGM94erdt17RVDlhC9zvhaU+TwF84qLx3MoSCC+P/haPsRvWjtMPfvSPhZTtban3UBN17JZ2UUx9Tu73nooQJa9JEyE6YyND9OTn7s58PpGWTLfD1gh5EoQB0WKt5eP2xRtXJh+UI9s2xAm187LUb1gzRquXL4vmDl/uP/iOXK4vUDL791ymJDcQ6kFhRHt/d5Cg1A73qm6j01zr5MzWRbWlTmyrzfCvv/oxeq1Jq2WRMfWjOccPFp0oL0uyt6S9rTuddasq9K2vf7LprfSKyG6sI2Lq5127gqRk4qLlyQel5P0376E1K0Zpw5qx3Mt2sWF1/Xr/8NPXcy/bV4k2NjJEy0eH6IPv+hnrMYpQ30HzUBxT39pEebIFtRlLfR4sFaG+FAa0uNi6xHXLR4forfPz3ruq5IU8rue17lmzYpT+9VcfzqWsZlDWAL2xpPMGQj0ojE6MU5ar0ssTUzP0lTtrWBDjc5HC0d7LNtH/8d2/or2XTRR2jVZSWTZIlWX8/uO+qNnv81lQiq0YZde/PIi3ysu12IgsigJf9/tOJo/kTa0IeSoii/+mAoT6NStG6f03++c6yYt1jeSpf/sPc7mX7WvRLJdCOv27jziP6dTdaaIt7XJSNPg+s7zc7/NA3nu8ExQu2zevph//42u5lxsZEVq0peK/evKhtof/5ZU/pVOA+z0ABSBi6jvJIC539r2XbWpjTTqXjrXUFygcHbr1crpy18Zctk3sFYpIlPejxu4IeQtM8daIxQw2WcrtBaE+D1phNVkxlr9Qv2p8We5ltot1jfwAP33trdzLzlP47lz3+3wT5Xnfm9RfBjvIUt8J2w1+45//XK5JLAVh5BnYmvbXagu9zN23XkF/9K1/T+MjQ22rQxGEBeQD6haW1t2CllLtQJdmuS7bN3dexulOoNM8GMQAXeQiLwgC2rahtTFtnU5QQEz9q3/7UyIqwFLfqGtRSTmz7PgT7VPfYf2p1QSKx0cxS44iLPVBEFB/X4mGm9hKrFMQlvoiyNOiKS8VOkFwFCws5p0oL72lvt3tUHW/b7/CJQiCXLebFIj77NZcKGl49OffSUfvvym3+b1TUPpNk+Fj3UZvvUnQUUTJxzrIVD802Efv2DVB11+5raOUDZ1Epwn1wkraSe6YS4EitN3Cer35onw9IopOcJilfFjq68jtSGytlTfLR4uxNH3z9z/ZE+6bW9avoNXLl9H9B/fmXna+2e/lpKid8+DXrx6jH/7NT2hspLmQJkEW9/tmEuXlgSLUd5DCJW/EM18K43YYBj0n0BOpuVvaHbbSanrvbYKOIUo+1kGZKkphSL/7yz/b7mp0NJ0QLycjrK+dVq9epwj3++t+Zit9+y/+C23LOdPv+oYlUljH8yaLAvCB9+yjv/jLH9GdN0wWUKPuoRVxwf19ZfrY3VO0Y8uaXMvtlQVvf1+5sARWeSacDTrMxVvw248dom/96X/KbftJ70R5GXbdKIpQianvnHeTN6INIpFy99KpuTlaQW/MWCCRgf5yy7fMiNzvMTh2Fa3ebikJ0XyW2uDcboqwEn350++l1986n0sCNpnrr7yYnv6X38m1TJkslvrrf2Ybfecbn1nyHkFF70wg+MgHri2sbGAnz/YddmhM/bpVFfq5O/PzcvB2v5e35mrzOLJU9qkXLv1Lwf2+V+kk7+BWA6F+ifB/nvxUy/fgFjlMlnD/6ko6zv1+CbnDdRJFWIkG+suFWD935myh1cmqmGz3QrwTaPW8A7qXTt3SLm98BcZO6jlLZUu72FLfu+2v11nKcw6E+iVCOwaoXtv7e6nQaa51rch+D0xKBSTKK4ogCOh3fumD9OZbF4opv5BSlwZL2WoC0iEvFXp5Ye67JuokL8dShyXKK4rSEkqU16t0Ur9pNZ29UgNdjXC/7+XJuRfptFiypZS4ppMoIvt9keybxBaVnQiEeuCLur802k0nrZ1UL4rOUvznSWREgKW+axFr2KJ2W+lklt4dg5ZRqyKmvhvptMUULPXtIeygJE3tRuxTDdIj+u9Sy0Lc63zp4QN05sdncy2z0+aedtNJz0POKN7LCvZon/oO2n0BpEP0m8ElOOcs7ZUaKJR73n0l/dt/9wM6et9N7a4K6GKETqiX4/g6kQBWs5glfvvNEC7hBVYvc8f1l+VeZq97dfz6p95DP/xvP/E+vpMs9aUlElMvlBedtPsCSIfoNrDUA5AjE2uX0//2Wx9tdzVAl/PT194iIqKtG1q7ewMAgvWrx+hTh2+ga/ZsaXdVuo6FxjaDsNSDJP7q1b8nIqLLL13f5poUw63XbE91fAfJ9Ipit5eF+vmFRSIiGh8dbHNNQFYuXKi/w6WoSO5dHxoAQE/ww7+pWzZ2bV3b5pqApcwD79lH2zevbnc1uo63L8wT0dK0moB07Nhc38XiyH03trkmnUEneUjJlvpe3png3Ot1I8LKsWVtrgnIiphzuiEXUN4svTsGAHQlEOoB6D7ePr9ARLDUg2Q+de8NdM/tV9KW9SvaXZWOYKC/TE9+7hBtumh5u6uyZPapvzBft/JCqO9e3r5Qn3Mg1AMAliy/+KGb6e3z8+2uhpVLJmAlBaDbEGPKUnSFBOkYHuyHQK9xbYeE/IRLxP1esHIcQn23Es05/UtvzulJof706dP0yiuv0KZNm2hubo4qlQodPny43dUCoKO578BV7a4Cy7O/ej/93U9fX5JaVwC6nbcioR79F4BuRc5+v3HtePsq0iJWjA23uwogI8JSvxRDvnrujk+ePElnz56lxx57LPru1KlTdOzYMTp+/HgbawYAyMKubRfRrnZXAgCQCSHUw/0egO7lHbsm6NA7L6d7D1xFI0MD7a5O4cD9vns5L4T6JahI7qk7np2dpaeeeoq++93vKt8fPnyYbrvtNpqenqapqak21Q4AALqLj3/wOtqwZqzd1QBdDNzvAeh+VowN0+cfvK3d1WgZsNR3L7GlfunNOT2V7eK5556j3bt3s79NTU3Rc8891+IaAQBA9/Lg+6+h2/fvbHc1QBfzs++6koiI3ncTPzcDAECnMT461O4qgIwcvK7u25l2C8leoKcs9S+//LJVqJ+YmKAXX3yxxTUCAAAAli7XX7mN/vR//my7qwEAAN6Uwp6yeS4pDl63i258x8VLIkxEp6eE+tnZWdq/fz/7W6VSobm5uShxHgAAAAAAAAAQEf3Brz0Q7XMOupMgCJakQE/UY0L93Nyc9bexsXpc6Llz5yDUAwAAAAAAACIu3YStc0H30nP+JePj487fXYI/AAAAAAAAAADQTfScUA8AAAAAAAAAACwVek6oP3v2rPN3uN4DAAAAAAAAAOgVek6ot3Hu3DkiimPrAQAAAAAAAACAbqenhPqpqSmanZ1lf3v11VdpYmIClnoAAAAAAAAAAD1Dzwn1Z86cYX+bnZ2lqampFtcIAAAAAAAAAAAojp4S6g8cOEAzMzNshvuXX36ZDhw40IZaAQAAAAAAAAAAxdBTQv3ExAQ9+uijdOLECeX7kydP0sGDB2GpBwAAAAAAAADQU5TbXYG8eeihh+j06dP0xBNP0KZNmyKr/fHjx9tcMwAAAAAAAAAAIF96Tqgnqrvhw9UeAAAAAAAAAECv01Pu9wAAAAAAAAAAwFICQj0AAAAAAAAAANClQKgHAAAAAAAAAAC6FAj1AAAAAAAAAABAlwKhHgAAAAAAAAAA6FIg1AMAAAAAAAAAAF0KhHoAAAAAAAAAAKBLgVAPAAAAAAAAAAB0KeV2V6DTOX/+PBER/fVf/3WbawIAAAAAAAAAYCkg5E8hj7qAUJ/AmTNniIjosccea3NNAAAAAAAAAAAsJc6cOUNXXXWV85igVqvVWlSfruQnP/kJ/cmf/Alt3LiRBgYG2l0dAAAAAAAAAAA9zvnz5+nMmTN0/fXX04oVK5zHQqgHAAAAAAAAAAC6FCTKAwAAAAAAAAAAuhQI9QAAAAAAAAAAQJcCoR4AAAAAAAAAAOhSINQDAAAAAAAAAABdCoR6AAAAAAAAAACgS4FQDwAAAAAAAAAAdCkQ6gEAAAAAAAAAgC4FQj0AAAAAAAAAANClQKgHAAAAAAAAAAC6lHK7KwCa5/Tp0/TKK6/Qpk2baG5ujiqVCh0+fLjd1QI9zsmTJ+ns2bP0/e9/n86dO0cHDx6khx56iD02TRtFewZFcezYMXrooYdoYmLC+A1tFLSL06dP0wsvvEDj4+M0OjpKREQPP/wwVSoV4zi0UdAOTp06Ra+++ioREb322ms0OjrKtlEitFNQHHNzc/Qrv/IrtGfPHut6k6i4Ntjp7TWo1Wq1dlcCZEcIVo899lj03alTp2hmZoaOHz/expqBXuaJJ56ge++9NxKOZmdn6cEHH6RKpULPP/+8cmyaNor2DIpiZmaGDh06RN/85jcNoR5tFLSLI0eO0MTEhNKejh07RkSktCe0UdAujh07RocPH6bJycnou9nZWTp69Cg9++yzimCPdgqK4NixY3T27Fnas2cPPfXUU/Sxj33MKtQX1Qa7or3WQNfy6quv1vbu3cv+duutt9a+/e1vt7hGYCnw4osv1r73ve8Z37/66qu17du3177yla8o3/m2UbRnUCRf/OIXa9u3b6+9+uqryvdoo6BdfOUrX6l9+tOfNr6/6667MI6CjuDb3/527bnnnmN/e/HFF2tPPfVU9DfaKWgFe/fuVdqdTFFtsFvaK2Lqu5jnnnuOdu/ezf42NTVFzz33XItrBJYC09PTisZeMDExQZOTk/SHf/iH0Xdp2ijaMyiKU6dOWV3k0EZBO5ibm6Onn35asfoInn/+eeV7tFHQLmZmZmhsbIz9bXJykl555ZXob7RT0G6KaoPd0l4h1HcxL7/8MhsbSlQXsF5++eUW1wgsBV588UU6cuQI+9vu3btpbm6O5ubmiChdG0V7BkUwOztLExMTbOwnEdooaA9f//rXqVKpWNuTDNooaBeVSoVOnDgRzeky09PTtGfPnuhvtFPQbopqg93SXiHUdzGzs7NRUh2dSqWiCFcA5IXPIlQIUGnaKNozKILTp0/T1NSU9Xe0UdAOXn755cjyMzc3R6dPn6aZmRn2WLRR0C4OHjxI586do0OHDtH09HT0vWizclwz2iloN0W1wW5prxDquxhXAxLuUufOnWtVdcAS4fnnn6evfvWr7G/T09OK0J+mjaI9g7w5ffp0YmZatFHQDmZmZmh0dJSmp6dpenqapqamqFKp0JEjRxThiQhtFLSPSqVCzz77LJ07d44efPBBOnbsGE1PT9OLL75IzzzzjHIs2iloN0W1wW5prxDqu5zx8XHn752gOQJLg5mZGZqdnaVHH31U+T5NG0V7Bnkh2orN7V4GbRS0i7m5OTpw4EDkiv/444/T0aNHDas92ihoF5OTk/Stb32LJiYm6NSpU3T06FGrxx7aKWg3RbXBbmivEOoBALlw9OhR+uhHP0oHDhxod1UAoFOnTqEtgo7m5ZdfNtpopVKh/fv304kTJ9pUKwBUZmdn6etf/zo9//zzkXX+wQcfpJMnT7a5ZgAAGQj1Xc7Zs2edv/tYqQBoliNHjtDU1BSbyTlNG0V7BnkwPT2dSqBHGwXtwJZNec+ePYYLPtooaAezs7P0xBNP0GOPPUaVSoWmpqboW9/6Fh0+fJhOnDhBTzzxhHI82iloN0W1wW5orxDqexQR22HbigSAvDh16hSNj4/T8ePHU52Xpo2iPYM0iIz3zYI2CoqiUqlYEy8JZmdnE8tBGwVFcvToUXr88ceV7yqVCh0/fpyOHz9OTz/9tJfbMdopaDdFtcFOaq/ldlcAZGdqaso66b/66qvObZwAyIPTp0/T3NycVaBP00bRnkEenDx5kl555RUjJllo2Y8dO0YTExM0OTlJhw8fRhsFbWH37t302muvOY8Ri0S0UdAOkvKSHD58mE6dOkXf+973aGpqCu0UtJ2i2mC3tFcI9V3M1NQUvfjii+xvs7Ozzm2cAGiW6elpOnfunLKlDVE9YZ4Y4NK0UbRnkAd6exTMzMzQSy+9RMePH1es+GijoB1MTU3RU089xf529uxZqlQqyoISbRR0Irt3747GU7RT0G6KaoPd0l7hft/FHDhwgGZmZljXJy4BDwB5Idodt13Y9PR0tBhN00bRnkE7QBsF7eDw4cM0NzfH7k3/0ksv0cc+9rHob7RR0A7EPO4KA5FDndBOQbspqg12S3uFUN/FTExM0KOPPmpkyT158iQdPHiwYzRHoLeYmZmhEydO0Llz5+jUqVPKv5MnTyoJntK0UbRnUCQi7k1foKKNgnYg4pK/+MUvKt+fPHmSKpWK4nGCNgraxZNPPklHjx41xs25uTk6cuSIEnqHdgpahS1pXVFtsFvaa1Cr1WrtrgRojtOnT9Mrr7xCmzZtirRINhdUAJpl3759zsQ47373u+mrX/2q8l2aNor2DPJkenqaTp8+TdPT0zQ7O0uTk5O0e/duOnz4ME1OTkbHoY2CdnD69Gl64YUXaHx8nM6ePUt79uzJpd2hjYK8mJubo69//etRDgiR4PHhhx9m44jRTkHeiFw5Z86coZmZmWjrz/HxcWMuJyquDXZ6e4VQDwAAAAAAAAAAdClwvwcAAAAAAAAAALoUCPUAAAAAAAAAAECXAqEeAAAAAAAAAADoUiDUAwAAAAAAAAAAXQqEegAAAAAAAAAAoEuBUA8AAAAAAAAAAHQpEOoBAAAAAAAAAIAuBUI9AAAAAAAAAADQpUCoBwAAAAAAAAAAuhQI9QAAAAAAAAAAQJcCoR4AAAAAAAAAAOhSINQDAAAAAAAAAABdCoR6AAAAAAAAAACgS4FQDwAAAAAAAAAAdCkQ6gEAAAAAAAAAgC4FQj0AAAAAAAAAANClQKgHAAAAQNMcO3aMbrvtNtqxYwft2LGDjh07pvz+xBNPRL/t27ePpqen21RTAAAAoLcIarVard2VAAAAAEBvcOTIEXrppZfom9/8Jk1MTETfz87O0m233UbPPPMMTU1NtbGGAAAAQG8BoR4AAAAAuXLbbbfRxMQEPfPMM9F3J0+epKmpKZqcnGxjzQAAAIDeA+73AAAAAMiVZ555hqanp+nkyZNERDQzM0MTExMQ6AEAAIACgFAPAAAAgFyZmJig48eP04kTJ2h6eppeeOEFOnDgQLurBQAAAPQkcL8HAAAAQCGI+Prvfve7VKlU2l0dAAAAoCeBpR4AAAAAhbBnzx6qVCp04sSJdlcFAAAA6Fkg1AMAAAAgd2ZmZqhSqdCzzz5Lp06dotOnT7e7SgAAAEBPAqEeAAAAALkyNzdHL7zwAh0+fJgmJyfp0UcfpaNHj9Ls7Gy7qwYAAAD0HIipBwAAAECuHDt2jI4fP658d+jQISIiev7559tRJQAAAKBngaUeAAAAALkwNzdHR44cYX978sknaWZmhp544okW1woAAADobWCpBwAAAEDTHDp0iGZnZ2lubo4qlQp997vfVX4XmfCJiCYnJ2n//v302GOPtaOqAAAAQE8BoR4AAAAAAAAAAOhS4H4PAAAAAAAAAAB0KRDqAQAAAAAAAACALgVCPQAAAAAAAAAA0KVAqAcAAAAAAAAAALoUCPUAAAAAAAAAAECXAqEeAAAAAAAAAADoUiDUAwAAAAAAAAAAXQqEegAAAAAAAAAAoEuBUA8AAAAAAAAAAHQpEOoBAAAAAAAAAIAuBUI9AAAAAAAAAADQpUCoBwAAAAAAAAAAuhQI9QAAAAAAAAAAQJcCoR4AAAAAAAAAAOhS/n8FeHdnnNtWBgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "y_pred = jax.vmap(mlp)(x_test)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(y_test, label=\"True attractor z\")\n",
    "plt.plot(y_pred, label=\"MLP prediction z\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"MLP Approximation of attractor Function\")\n",
    "plt.savefig(f\"{fig_folder}/attractor_approximation.png\")\n",
    "wandb.log({\"attractor approximation\": wandb.Image(plt, caption=\"attractor approximation\")})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Update_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_adjacency_matrix = mlp.adjacency_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f\"{out_folder}/final_adjacency_matrix.txt\", final_adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(final_adjacency_matrix, cmap=plt.cm.viridis)\n",
    "plt.colorbar()\n",
    "plt.title(\"Final adjacency matrix\")\n",
    "plt.savefig(f\"{fig_folder}/final_adjacency_matrix.png\")\n",
    "wandb.log({\"final adjacency matrix\": wandb.Image(plt, caption=\"final adjacency matrix\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_matrices = np.split(final_adjacency_matrix, np.cumsum(mlp.get_shape())[:-1])[:-1]\n",
    "\n",
    "fig, axs = plt.subplots(1, len(sub_matrices), figsize=(20, 5))\n",
    "\n",
    "for i, (sub_matrix, ax) in enumerate(zip(sub_matrices, axs), start=1):\n",
    "    weights = sub_matrix.flatten()\n",
    "    weights = weights[weights != 0]\n",
    "    ax.hist(weights, bins=\"auto\", density=False, alpha=0.6, color='g')\n",
    "    ax.set_xlabel('Weights')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'Layer {i}-Layer {i+1} ')\n",
    "\n",
    "# Display the figure with its subplots\n",
    "plt.suptitle('Final Weight Distribution (excluding zero weights)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss', color=color)\n",
    "ax1.plot(np.arange(0,len(Loss_history)), Loss_history, \".\", color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.set_yscale(\"log\")\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Number of Nodes', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(np.arange(0,len(Node_history)), Node_history, \".\", color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax3 = ax1.twinx()  # instantiate a third axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:green'\n",
    "ax3.set_ylabel('Gradient Norm', color=color)  # we already handled the x-label with ax1\n",
    "ax3.plot(np.arange(0,len(grad_norm_history)), grad_norm_history, \".\", color=color)\n",
    "ax3.tick_params(axis='y', labelcolor=color)\n",
    "ax3.set_yscale(\"log\")\n",
    "\n",
    "plt.suptitle(\"Homogenous Neural Network with Loss strategic Node Addition and Removal\")\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(f\"{fig_folder}/loss_curve.png\")\n",
    "wandb.log({\"loss and nodes\": wandb.Image(plt, caption=\"loss and nodes\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G, neuron_labels, neuron_importances = mlp.visualize_graph()\n",
    "# fig = mlp_plot(G, neuron_labels, neuron_importances)\n",
    "# plt.savefig(f\"{fig_folder}/final_graph.png\")\n",
    "# wandb.log({\"final neural network\": wandb.Image(plt, caption=\"final neural network\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
