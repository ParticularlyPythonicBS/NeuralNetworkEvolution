# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/01_neuron.ipynb.

# %% auto 0
__all__ = ['Neuron']

# %% ../nbs/01_neuron.ipynb 3
import jax
import jax.numpy as jnp
import equinox as eqx

# %% ../nbs/01_neuron.ipynb 4
class Neuron(eqx.Module):
    """
    A simple neuron with a weight vector, bias, and activation function.
    """
    weight: jax.Array
    bias: jax.Array
    activation: callable

    def __init__(self, in_features, activation=jax.nn.relu, key=None):
        if key is None:
            key = jax.random.PRNGKey(0)
            key, _ = jax.random.split(key)
        w_key, b_key = jax.random.split(key)
        self.weight = jax.random.normal(w_key, (in_features,))
        self.bias = jax.random.normal(b_key, ())

        self.activation = activation

    def __call__(self, x):
        return self.activation(jnp.dot(self.weight, x) + self.bias)
    
    def importance(self):
        """
        Returns the importance of the neuron. This is the L2 norm of the weight vector.
        """
        return jnp.linalg.norm(self.weight)/jnp.sqrt(self.weight.size)
