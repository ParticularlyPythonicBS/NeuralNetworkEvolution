{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test loss based strategy for Polynomial prediction with a heterogenous MLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### env management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: \"WANDB_NOTEBOOK_NAME\"=\"19_hetero_poly_test_strat.ipynb\"\n",
      "env: WANDB_SILENT=True\n",
      "env: XLA_PYTHON_CLIENT_MEM_FRACTION=0.3\n"
     ]
    }
   ],
   "source": [
    "%env \"WANDB_NOTEBOOK_NAME\" \"19_hetero_poly_test_strat.ipynb\"\n",
    "%env WANDB_SILENT=True\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "# %env XLA_PYTHON_CLIENT_MEM_FRACTION=0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "import optax\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.style as mplstyle\n",
    "import seaborn as sns\n",
    "\n",
    "from NeuralNetworkEvolution.config import MLPConfig\n",
    "from NeuralNetworkEvolution.activations import sin\n",
    "from NeuralNetworkEvolution.mlp import CustomMLP, mlp_plot\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "sns.set_theme(context='paper', style='white', palette='vlag', font='serif',\n",
    "            font_scale=2, color_codes=True, rc={'text.usetex' : True})\n",
    "mplstyle.use('fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidpointNormalize(Normalize):\n",
    "    \"\"\"\n",
    "    Normalize and shift the colormap to center 0\n",
    "    \"\"\"\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        result, is_scalar = self.process_value(value)\n",
    "        (vmin, vmax, midpoint) = self.vmin, self.vmax, self.midpoint\n",
    "        if vmin is None or vmax is None:\n",
    "            vmin, vmax = np.min(value), np.max(value)\n",
    "        if midpoint is None:\n",
    "            midpoint = (vmin + vmax) / 2\n",
    "        result = np.ma.masked_array(np.interp(value, [vmin, midpoint, vmax], [0, 0.5, 1]))\n",
    "        if is_scalar:\n",
    "            result = np.atleast_1d(result)[0]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 11:31:35.212248: W external/xla/xla/service/gpu/nvptx_compiler.cc:760] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.4.131). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "input_size = 1\n",
    "hidden_sizes = [5, 5] \n",
    "output_size = 1\n",
    "initial_activation_list = [jax.nn.tanh, jax.nn.relu]\n",
    "activation_list = [jax.nn.tanh, jax.nn.relu]\n",
    "bias = False\n",
    "num_epochs = 25000\n",
    "intervene_every = 50\n",
    "seed = 0\n",
    "key = jax.random.PRNGKey(seed)\n",
    "threshold = 1e-4\n",
    "grad_norm_threshold = 1e-3\n",
    "n_samples = 20000\n",
    "test_size = 0.2\n",
    "learning_rate = 3e-4\n",
    "\n",
    "act_string = \"_\".join([act.__name__ for act in initial_activation_list])\n",
    "\n",
    "config = MLPConfig(input_size=input_size,\n",
    "                output_size=output_size,\n",
    "                hidden_sizes=hidden_sizes,\n",
    "                initial_activation_list=initial_activation_list,\n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.__dict__.update({'n_samples': n_samples,\n",
    "                        'learning_rate': learning_rate,\n",
    "                        'num_epochs': num_epochs,\n",
    "                        'intervene_every': intervene_every,\n",
    "                        'threshold': threshold,\n",
    "                        'activation_list': activation_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jax.config.update(\"jax_enable_x64\", True)\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "Description = f\"Hetero_{act_string}_poly_test_strat__no_bias_{hidden_sizes[0]}_{hidden_sizes[1]}_{num_epochs}_{intervene_every}_{threshold}_{seed}\"\n",
    "fig_folder = f\"../figures/{Description}\"\n",
    "out_folder = f\"../output/{Description}\"\n",
    "os.makedirs(fig_folder, exist_ok=True)\n",
    "os.makedirs(out_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# devices: 4\n",
      "Description: Hetero_tanh_relu_poly_test_strat__no_bias_5_5_25000_50_0.0001_0\n",
      "jax backend: gpu\n",
      "jax devices: [cuda(id=0), cuda(id=1), cuda(id=2), cuda(id=3)]\n"
     ]
    }
   ],
   "source": [
    "print(f\"# devices: {jax.local_device_count()}\")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, filename=f\"{out_folder}/info.log\", filemode=\"w\")\n",
    "console = logging.StreamHandler(sys.stdout)\n",
    "console.setLevel(logging.INFO)\n",
    "logging.getLogger(\"\").addHandler(console)\n",
    "logging.info(f\"Description: {Description}\")\n",
    "logging.info(f\"jax backend: {jax.lib.xla_bridge.get_backend().platform}\")\n",
    "logging.info(f\"jax devices: {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=\"neural-network-evolution\", name=Description, config=config.__dict__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly(x):\n",
    "    \"\"\"\n",
    "    7th degree polynomial to predict\n",
    "    \"\"\"\n",
    "    return (x - 3)*(x - 2)*(x - 1)*x*(x + 1)*(x + 2)*(x + 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.linspace(-3, 3, n_samples).reshape(-1, 1)\n",
    "y = poly(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'Data')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_train, y_train, \"k.\", alpha=0.2, label=f\"train:{len(x_train)}\")\n",
    "plt.plot(x_test, y_test, \"r.\", alpha = 0.2, label=f\"test:{len(x_test)}\")\n",
    "plt.legend()\n",
    "plt.suptitle(\"Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training and eval scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_optimizer_state(mlp, optimizer):\n",
    "    \"\"\"\n",
    "    Optimizer initialization that filters for float arrays in the jax pytrees\n",
    "    \"\"\"\n",
    "    return optimizer.init(eqx.filter(mlp, eqx.is_inexact_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_value_and_grad()\n",
    "def compute_loss(mlp, x, y):\n",
    "    pred = jax.vmap(mlp)(x)\n",
    "    return jnp.mean((pred - y) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit()\n",
    "def train_step(mlp, x, y, opt_state, opt_update):\n",
    "    loss, grads = compute_loss(mlp, x, y)\n",
    "    updates, opt_state = opt_update(grads, opt_state)\n",
    "    mlp = eqx.apply_updates(mlp, updates)\n",
    "    return loss, mlp, opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit()\n",
    "def test_step(mlp, x, y):\n",
    "    return compute_loss(mlp, x, y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_norm(grads):\n",
    "    return jnp.sqrt(sum(jnp.sum(jnp.square(p)) for p in jax.tree_util.tree_leaves(grads)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initializing MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = CustomMLP(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G, neuron_labels, neuron_importances = mlp.visualize_graph()\n",
    "fig = mlp_plot(G, neuron_labels, neuron_importances)\n",
    "plt.suptitle(\"Initial neural network\")\n",
    "plt.savefig(f\"{fig_folder}/initial_graph.png\")\n",
    "wandb.log({\"initial neural network\": wandb.Image(plt, caption=\"initial neural network\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_adjacency_matrix = mlp.adjacency_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_wt = np.max(np.abs(initial_adjacency_matrix))\n",
    "norm = MidpointNormalize(vmin=-max_wt, vmax=max_wt, midpoint=0)\n",
    "cmap = plt.get_cmap('coolwarm')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "cax = ax.matshow(initial_adjacency_matrix, cmap=cmap, norm=norm)\n",
    "cbar = fig.colorbar(cax, ticks=[-max_wt,\n",
    "                                -max_wt/2, \n",
    "                                0,\n",
    "                                max_wt/2,\n",
    "                                max_wt])\n",
    "\n",
    "# plt.colorbar()\n",
    "plt.title(\"Initial adjacency matrix\")\n",
    "plt.savefig(f\"{fig_folder}/initial_adjacency_matrix.png\")\n",
    "wandb.log({\"initial adjacency matrix\": wandb.Image(plt, caption=\"initial adjacency matrix\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initializing optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optax.adabelief(learning_rate=learning_rate)\n",
    "opt_state = initialize_optimizer_state(mlp, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "node_history = []\n",
    "grad_norm_history = []\n",
    "graph_history = []\n",
    "update_history = []\n",
    "\n",
    "test_loss = np.inf # initialize test loss to infinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000, Loss: 1521.5067138671875, Neurons: 11, Grad norm: 3.391e+01\n",
      "Epoch 001, Loss: 1521.463134765625, Neurons: 11, Grad norm: 3.391e+01\n",
      "Epoch 002, Loss: 1521.4171142578125, Neurons: 11, Grad norm: 3.392e+01\n",
      "Epoch 003, Loss: 1521.3687744140625, Neurons: 11, Grad norm: 3.393e+01\n",
      "Epoch 004, Loss: 1521.318359375, Neurons: 11, Grad norm: 3.394e+01\n",
      "Epoch 005, Loss: 1521.2655029296875, Neurons: 11, Grad norm: 3.394e+01\n",
      "Epoch 006, Loss: 1521.2103271484375, Neurons: 11, Grad norm: 3.395e+01\n",
      "Epoch 007, Loss: 1521.1529541015625, Neurons: 11, Grad norm: 3.397e+01\n",
      "Epoch 008, Loss: 1521.09326171875, Neurons: 11, Grad norm: 3.398e+01\n",
      "Epoch 009, Loss: 1521.0313720703125, Neurons: 11, Grad norm: 3.399e+01\n",
      "Epoch 010, Loss: 1520.967041015625, Neurons: 11, Grad norm: 3.400e+01\n",
      "Epoch 011, Loss: 1520.9005126953125, Neurons: 11, Grad norm: 3.402e+01\n",
      "Epoch 012, Loss: 1520.831787109375, Neurons: 11, Grad norm: 3.403e+01\n",
      "Epoch 013, Loss: 1520.7607421875, Neurons: 11, Grad norm: 3.405e+01\n",
      "Epoch 014, Loss: 1520.6876220703125, Neurons: 11, Grad norm: 3.407e+01\n",
      "Epoch 015, Loss: 1520.612060546875, Neurons: 11, Grad norm: 3.409e+01\n",
      "Epoch 016, Loss: 1520.534423828125, Neurons: 11, Grad norm: 3.411e+01\n",
      "Epoch 017, Loss: 1520.4547119140625, Neurons: 11, Grad norm: 3.413e+01\n",
      "Epoch 018, Loss: 1520.372802734375, Neurons: 11, Grad norm: 3.415e+01\n",
      "Epoch 019, Loss: 1520.288818359375, Neurons: 11, Grad norm: 3.418e+01\n",
      "Epoch 020, Loss: 1520.2027587890625, Neurons: 11, Grad norm: 3.421e+01\n",
      "Epoch 021, Loss: 1520.114501953125, Neurons: 11, Grad norm: 3.424e+01\n",
      "Epoch 022, Loss: 1520.0244140625, Neurons: 11, Grad norm: 3.427e+01\n",
      "Epoch 023, Loss: 1519.9320068359375, Neurons: 11, Grad norm: 3.430e+01\n",
      "Epoch 024, Loss: 1519.837890625, Neurons: 11, Grad norm: 3.434e+01\n",
      "Epoch 025, Loss: 1519.7415771484375, Neurons: 11, Grad norm: 3.438e+01\n",
      "Epoch 026, Loss: 1519.643310546875, Neurons: 11, Grad norm: 3.442e+01\n",
      "Epoch 027, Loss: 1519.543212890625, Neurons: 11, Grad norm: 3.447e+01\n",
      "Epoch 028, Loss: 1519.44091796875, Neurons: 11, Grad norm: 3.451e+01\n",
      "Epoch 029, Loss: 1519.336669921875, Neurons: 11, Grad norm: 3.456e+01\n",
      "Epoch 030, Loss: 1519.2305908203125, Neurons: 11, Grad norm: 3.462e+01\n",
      "Epoch 031, Loss: 1519.12255859375, Neurons: 11, Grad norm: 3.467e+01\n",
      "Epoch 032, Loss: 1519.0125732421875, Neurons: 11, Grad norm: 3.473e+01\n",
      "Epoch 033, Loss: 1518.900390625, Neurons: 11, Grad norm: 3.480e+01\n",
      "Epoch 034, Loss: 1518.7864990234375, Neurons: 11, Grad norm: 3.487e+01\n",
      "Epoch 035, Loss: 1518.67041015625, Neurons: 11, Grad norm: 3.494e+01\n",
      "Epoch 036, Loss: 1518.552490234375, Neurons: 11, Grad norm: 3.501e+01\n",
      "Epoch 037, Loss: 1518.432373046875, Neurons: 11, Grad norm: 3.509e+01\n",
      "Epoch 038, Loss: 1518.310302734375, Neurons: 11, Grad norm: 3.517e+01\n",
      "Epoch 039, Loss: 1518.18603515625, Neurons: 11, Grad norm: 3.526e+01\n",
      "Epoch 040, Loss: 1518.0599365234375, Neurons: 11, Grad norm: 3.535e+01\n",
      "Epoch 041, Loss: 1517.9315185546875, Neurons: 11, Grad norm: 3.544e+01\n",
      "Epoch 042, Loss: 1517.8009033203125, Neurons: 11, Grad norm: 3.554e+01\n",
      "Epoch 043, Loss: 1517.668212890625, Neurons: 11, Grad norm: 3.564e+01\n",
      "Epoch 044, Loss: 1517.5333251953125, Neurons: 11, Grad norm: 3.575e+01\n",
      "Epoch 045, Loss: 1517.3961181640625, Neurons: 11, Grad norm: 3.586e+01\n",
      "Epoch 046, Loss: 1517.2567138671875, Neurons: 11, Grad norm: 3.598e+01\n",
      "Epoch 047, Loss: 1517.1148681640625, Neurons: 11, Grad norm: 3.610e+01\n",
      "Epoch 048, Loss: 1516.970703125, Neurons: 11, Grad norm: 3.622e+01\n",
      "Epoch 049, Loss: 1516.823974609375, Neurons: 11, Grad norm: 3.635e+01\n",
      "Epoch 049, Test loss: 1541.182861328125\n",
      "Epoch 050, Loss: 1516.6748046875, Neurons: 11, Grad norm: 3.649e+01\n",
      "Epoch 051, Loss: 1516.52294921875, Neurons: 11, Grad norm: 3.663e+01\n",
      "Epoch 052, Loss: 1516.36865234375, Neurons: 11, Grad norm: 3.677e+01\n",
      "Epoch 053, Loss: 1516.2117919921875, Neurons: 11, Grad norm: 3.692e+01\n",
      "Epoch 054, Loss: 1516.052001953125, Neurons: 11, Grad norm: 3.708e+01\n",
      "Epoch 055, Loss: 1515.889404296875, Neurons: 11, Grad norm: 3.724e+01\n",
      "Epoch 056, Loss: 1515.724365234375, Neurons: 11, Grad norm: 3.740e+01\n",
      "Epoch 057, Loss: 1515.5560302734375, Neurons: 11, Grad norm: 3.757e+01\n",
      "Epoch 058, Loss: 1515.3848876953125, Neurons: 11, Grad norm: 3.775e+01\n",
      "Epoch 059, Loss: 1515.2105712890625, Neurons: 11, Grad norm: 3.793e+01\n",
      "Epoch 060, Loss: 1515.0333251953125, Neurons: 11, Grad norm: 3.812e+01\n",
      "Epoch 061, Loss: 1514.852783203125, Neurons: 11, Grad norm: 3.831e+01\n",
      "Epoch 062, Loss: 1514.6690673828125, Neurons: 11, Grad norm: 3.850e+01\n",
      "Epoch 063, Loss: 1514.4820556640625, Neurons: 11, Grad norm: 3.871e+01\n",
      "Epoch 064, Loss: 1514.29150390625, Neurons: 11, Grad norm: 3.891e+01\n",
      "Epoch 065, Loss: 1514.0975341796875, Neurons: 11, Grad norm: 3.913e+01\n",
      "Epoch 066, Loss: 1513.9000244140625, Neurons: 11, Grad norm: 3.934e+01\n",
      "Epoch 067, Loss: 1513.6988525390625, Neurons: 11, Grad norm: 3.957e+01\n",
      "Epoch 068, Loss: 1513.494140625, Neurons: 11, Grad norm: 3.979e+01\n",
      "Epoch 069, Loss: 1513.2855224609375, Neurons: 11, Grad norm: 3.949e+01\n",
      "Epoch 070, Loss: 1513.0743408203125, Neurons: 11, Grad norm: 3.941e+01\n",
      "Epoch 071, Loss: 1512.86669921875, Neurons: 11, Grad norm: 3.966e+01\n",
      "Epoch 072, Loss: 1512.6593017578125, Neurons: 11, Grad norm: 3.993e+01\n",
      "Epoch 073, Loss: 1512.4493408203125, Neurons: 11, Grad norm: 4.019e+01\n",
      "Epoch 074, Loss: 1512.235107421875, Neurons: 11, Grad norm: 4.045e+01\n",
      "Epoch 075, Loss: 1512.0167236328125, Neurons: 11, Grad norm: 4.072e+01\n",
      "Epoch 076, Loss: 1511.793701171875, Neurons: 11, Grad norm: 4.098e+01\n",
      "Epoch 077, Loss: 1511.566162109375, Neurons: 11, Grad norm: 4.126e+01\n",
      "Epoch 078, Loss: 1511.333984375, Neurons: 11, Grad norm: 4.154e+01\n",
      "Epoch 079, Loss: 1511.097412109375, Neurons: 11, Grad norm: 4.182e+01\n",
      "Epoch 080, Loss: 1510.855712890625, Neurons: 11, Grad norm: 4.211e+01\n",
      "Epoch 081, Loss: 1510.609619140625, Neurons: 11, Grad norm: 4.241e+01\n",
      "Epoch 082, Loss: 1510.3585205078125, Neurons: 11, Grad norm: 4.271e+01\n",
      "Epoch 083, Loss: 1510.102783203125, Neurons: 11, Grad norm: 4.301e+01\n",
      "Epoch 084, Loss: 1509.8419189453125, Neurons: 11, Grad norm: 4.332e+01\n",
      "Epoch 085, Loss: 1509.576171875, Neurons: 11, Grad norm: 4.363e+01\n",
      "Epoch 086, Loss: 1509.30517578125, Neurons: 11, Grad norm: 4.395e+01\n",
      "Epoch 087, Loss: 1509.029052734375, Neurons: 11, Grad norm: 4.427e+01\n",
      "Epoch 088, Loss: 1508.747802734375, Neurons: 11, Grad norm: 4.460e+01\n",
      "Epoch 089, Loss: 1508.4613037109375, Neurons: 11, Grad norm: 4.493e+01\n",
      "Epoch 090, Loss: 1508.1693115234375, Neurons: 11, Grad norm: 4.526e+01\n",
      "Epoch 091, Loss: 1507.871826171875, Neurons: 11, Grad norm: 4.560e+01\n",
      "Epoch 092, Loss: 1507.569091796875, Neurons: 11, Grad norm: 4.594e+01\n",
      "Epoch 093, Loss: 1507.2606201171875, Neurons: 11, Grad norm: 4.628e+01\n",
      "Epoch 094, Loss: 1506.9466552734375, Neurons: 11, Grad norm: 4.663e+01\n",
      "Epoch 095, Loss: 1506.626953125, Neurons: 11, Grad norm: 4.698e+01\n",
      "Epoch 096, Loss: 1506.301513671875, Neurons: 11, Grad norm: 4.734e+01\n",
      "Epoch 097, Loss: 1505.97021484375, Neurons: 11, Grad norm: 4.770e+01\n",
      "Epoch 098, Loss: 1505.6329345703125, Neurons: 11, Grad norm: 4.806e+01\n",
      "Epoch 099, Loss: 1505.289794921875, Neurons: 11, Grad norm: 4.842e+01\n",
      "Epoch 099, Test loss: 1529.4622802734375\n",
      "Epoch 100, Loss: 1504.9407958984375, Neurons: 11, Grad norm: 4.879e+01\n",
      "Epoch 101, Loss: 1504.5855712890625, Neurons: 11, Grad norm: 4.916e+01\n",
      "Epoch 102, Loss: 1504.224365234375, Neurons: 11, Grad norm: 4.953e+01\n",
      "Epoch 103, Loss: 1503.85693359375, Neurons: 11, Grad norm: 4.991e+01\n",
      "Epoch 104, Loss: 1503.4833984375, Neurons: 11, Grad norm: 5.029e+01\n",
      "Epoch 105, Loss: 1503.103515625, Neurons: 11, Grad norm: 5.067e+01\n",
      "Epoch 106, Loss: 1502.7174072265625, Neurons: 11, Grad norm: 5.105e+01\n",
      "Epoch 107, Loss: 1502.32470703125, Neurons: 11, Grad norm: 5.144e+01\n",
      "Epoch 108, Loss: 1501.925537109375, Neurons: 11, Grad norm: 5.183e+01\n",
      "Epoch 109, Loss: 1501.5201416015625, Neurons: 11, Grad norm: 5.222e+01\n",
      "Epoch 110, Loss: 1501.108154296875, Neurons: 11, Grad norm: 5.262e+01\n",
      "Epoch 111, Loss: 1500.689453125, Neurons: 11, Grad norm: 5.302e+01\n",
      "Epoch 112, Loss: 1500.26416015625, Neurons: 11, Grad norm: 5.342e+01\n",
      "Epoch 113, Loss: 1499.83203125, Neurons: 11, Grad norm: 5.383e+01\n",
      "Epoch 114, Loss: 1499.393310546875, Neurons: 11, Grad norm: 5.423e+01\n",
      "Epoch 115, Loss: 1498.94775390625, Neurons: 11, Grad norm: 5.464e+01\n",
      "Epoch 116, Loss: 1498.495361328125, Neurons: 11, Grad norm: 5.506e+01\n",
      "Epoch 117, Loss: 1498.0360107421875, Neurons: 11, Grad norm: 5.547e+01\n",
      "Epoch 118, Loss: 1497.5693359375, Neurons: 11, Grad norm: 6.186e+01\n",
      "Epoch 119, Loss: 1497.0919189453125, Neurons: 11, Grad norm: 6.148e+01\n",
      "Epoch 120, Loss: 1496.6005859375, Neurons: 11, Grad norm: 6.114e+01\n",
      "Epoch 121, Loss: 1496.1021728515625, Neurons: 11, Grad norm: 6.120e+01\n",
      "Epoch 122, Loss: 1495.5960693359375, Neurons: 11, Grad norm: 6.150e+01\n",
      "Epoch 123, Loss: 1495.0811767578125, Neurons: 11, Grad norm: 6.193e+01\n",
      "Epoch 124, Loss: 1494.5570068359375, Neurons: 11, Grad norm: 6.240e+01\n",
      "Epoch 125, Loss: 1494.0230712890625, Neurons: 11, Grad norm: 6.287e+01\n",
      "Epoch 126, Loss: 1493.4794921875, Neurons: 11, Grad norm: 6.327e+01\n",
      "Epoch 127, Loss: 1492.9261474609375, Neurons: 11, Grad norm: 6.364e+01\n",
      "Epoch 128, Loss: 1492.363525390625, Neurons: 11, Grad norm: 6.402e+01\n",
      "Epoch 129, Loss: 1491.7921142578125, Neurons: 11, Grad norm: 6.440e+01\n",
      "Epoch 130, Loss: 1491.211181640625, Neurons: 11, Grad norm: 6.479e+01\n",
      "Epoch 131, Loss: 1490.621337890625, Neurons: 11, Grad norm: 6.518e+01\n",
      "Epoch 132, Loss: 1490.022216796875, Neurons: 11, Grad norm: 6.559e+01\n",
      "Epoch 133, Loss: 1489.4139404296875, Neurons: 11, Grad norm: 6.599e+01\n",
      "Epoch 134, Loss: 1488.7965087890625, Neurons: 11, Grad norm: 6.641e+01\n",
      "Epoch 135, Loss: 1488.169921875, Neurons: 11, Grad norm: 6.683e+01\n",
      "Epoch 136, Loss: 1487.5338134765625, Neurons: 11, Grad norm: 6.725e+01\n",
      "Epoch 137, Loss: 1486.888671875, Neurons: 11, Grad norm: 6.768e+01\n",
      "Epoch 138, Loss: 1486.2340087890625, Neurons: 11, Grad norm: 6.812e+01\n",
      "Epoch 139, Loss: 1485.5697021484375, Neurons: 11, Grad norm: 6.856e+01\n",
      "Epoch 140, Loss: 1484.8961181640625, Neurons: 11, Grad norm: 6.900e+01\n",
      "Epoch 141, Loss: 1484.2130126953125, Neurons: 11, Grad norm: 6.945e+01\n",
      "Epoch 142, Loss: 1483.52001953125, Neurons: 11, Grad norm: 6.990e+01\n",
      "Epoch 143, Loss: 1482.8175048828125, Neurons: 11, Grad norm: 7.036e+01\n",
      "Epoch 144, Loss: 1482.10498046875, Neurons: 11, Grad norm: 7.083e+01\n",
      "Epoch 145, Loss: 1481.3826904296875, Neurons: 11, Grad norm: 7.129e+01\n",
      "Epoch 146, Loss: 1480.650146484375, Neurons: 11, Grad norm: 7.177e+01\n",
      "Epoch 147, Loss: 1479.90771484375, Neurons: 11, Grad norm: 7.225e+01\n",
      "Epoch 148, Loss: 1479.155029296875, Neurons: 11, Grad norm: 7.273e+01\n",
      "Epoch 149, Loss: 1478.39208984375, Neurons: 11, Grad norm: 7.322e+01\n",
      "Epoch 149, Test loss: 1502.180419921875\n",
      "Epoch 150, Loss: 1477.61865234375, Neurons: 11, Grad norm: 7.371e+01\n",
      "Epoch 151, Loss: 1476.834716796875, Neurons: 11, Grad norm: 7.421e+01\n",
      "Epoch 152, Loss: 1476.0401611328125, Neurons: 11, Grad norm: 7.471e+01\n",
      "Epoch 153, Loss: 1475.2349853515625, Neurons: 11, Grad norm: 7.522e+01\n",
      "Epoch 154, Loss: 1474.4188232421875, Neurons: 11, Grad norm: 7.573e+01\n",
      "Epoch 155, Loss: 1473.5916748046875, Neurons: 11, Grad norm: 7.625e+01\n",
      "Epoch 156, Loss: 1472.75341796875, Neurons: 11, Grad norm: 7.677e+01\n",
      "Epoch 157, Loss: 1471.9039306640625, Neurons: 11, Grad norm: 7.729e+01\n",
      "Epoch 158, Loss: 1471.043212890625, Neurons: 11, Grad norm: 7.782e+01\n",
      "Epoch 159, Loss: 1470.1710205078125, Neurons: 11, Grad norm: 7.835e+01\n",
      "Epoch 160, Loss: 1469.287109375, Neurons: 11, Grad norm: 7.889e+01\n",
      "Epoch 161, Loss: 1468.391845703125, Neurons: 11, Grad norm: 7.944e+01\n",
      "Epoch 162, Loss: 1467.484619140625, Neurons: 11, Grad norm: 7.998e+01\n",
      "Epoch 163, Loss: 1466.5653076171875, Neurons: 11, Grad norm: 8.054e+01\n",
      "Epoch 164, Loss: 1465.6341552734375, Neurons: 11, Grad norm: 8.109e+01\n",
      "Epoch 165, Loss: 1464.6907958984375, Neurons: 11, Grad norm: 8.165e+01\n",
      "Epoch 166, Loss: 1463.735107421875, Neurons: 11, Grad norm: 8.221e+01\n",
      "Epoch 167, Loss: 1462.7669677734375, Neurons: 11, Grad norm: 8.278e+01\n",
      "Epoch 168, Loss: 1461.786376953125, Neurons: 11, Grad norm: 8.335e+01\n",
      "Epoch 169, Loss: 1460.7930908203125, Neurons: 11, Grad norm: 8.393e+01\n",
      "Epoch 170, Loss: 1459.7867431640625, Neurons: 11, Grad norm: 8.451e+01\n",
      "Epoch 171, Loss: 1458.767822265625, Neurons: 11, Grad norm: 8.509e+01\n",
      "Epoch 172, Loss: 1457.7357177734375, Neurons: 11, Grad norm: 8.568e+01\n",
      "Epoch 173, Loss: 1456.6904296875, Neurons: 11, Grad norm: 8.627e+01\n",
      "Epoch 174, Loss: 1455.6322021484375, Neurons: 11, Grad norm: 8.687e+01\n",
      "Epoch 175, Loss: 1454.5601806640625, Neurons: 11, Grad norm: 8.746e+01\n",
      "Epoch 176, Loss: 1453.474609375, Neurons: 11, Grad norm: 8.807e+01\n",
      "Epoch 177, Loss: 1452.3756103515625, Neurons: 11, Grad norm: 8.867e+01\n",
      "Epoch 178, Loss: 1451.2628173828125, Neurons: 11, Grad norm: 8.928e+01\n",
      "Epoch 179, Loss: 1450.1361083984375, Neurons: 11, Grad norm: 8.989e+01\n",
      "Epoch 180, Loss: 1448.9954833984375, Neurons: 11, Grad norm: 9.050e+01\n",
      "Epoch 181, Loss: 1447.840576171875, Neurons: 11, Grad norm: 9.112e+01\n",
      "Epoch 182, Loss: 1446.6715087890625, Neurons: 11, Grad norm: 9.174e+01\n",
      "Epoch 183, Loss: 1445.4881591796875, Neurons: 11, Grad norm: 9.236e+01\n",
      "Epoch 184, Loss: 1444.2904052734375, Neurons: 11, Grad norm: 9.298e+01\n",
      "Epoch 185, Loss: 1443.077880859375, Neurons: 11, Grad norm: 9.361e+01\n",
      "Epoch 186, Loss: 1441.8507080078125, Neurons: 11, Grad norm: 9.424e+01\n",
      "Epoch 187, Loss: 1440.6090087890625, Neurons: 11, Grad norm: 9.487e+01\n",
      "Epoch 188, Loss: 1439.3521728515625, Neurons: 11, Grad norm: 9.550e+01\n",
      "Epoch 189, Loss: 1438.080322265625, Neurons: 11, Grad norm: 9.613e+01\n",
      "Epoch 190, Loss: 1436.7933349609375, Neurons: 11, Grad norm: 9.677e+01\n",
      "Epoch 191, Loss: 1435.4913330078125, Neurons: 11, Grad norm: 9.741e+01\n",
      "Epoch 192, Loss: 1434.1737060546875, Neurons: 11, Grad norm: 9.804e+01\n",
      "Epoch 193, Loss: 1432.8409423828125, Neurons: 11, Grad norm: 9.868e+01\n",
      "Epoch 194, Loss: 1431.4925537109375, Neurons: 11, Grad norm: 9.932e+01\n",
      "Epoch 195, Loss: 1430.128662109375, Neurons: 11, Grad norm: 9.996e+01\n",
      "Epoch 196, Loss: 1428.7490234375, Neurons: 11, Grad norm: 1.006e+02\n",
      "Epoch 197, Loss: 1427.353515625, Neurons: 11, Grad norm: 1.012e+02\n",
      "Epoch 198, Loss: 1425.9422607421875, Neurons: 11, Grad norm: 1.019e+02\n",
      "Epoch 199, Loss: 1424.5150146484375, Neurons: 11, Grad norm: 1.025e+02\n",
      "Epoch 199, Test loss: 1447.6998291015625\n",
      "Epoch 200, Loss: 1423.07177734375, Neurons: 11, Grad norm: 1.032e+02\n",
      "Epoch 201, Loss: 1421.6123046875, Neurons: 11, Grad norm: 1.038e+02\n",
      "Epoch 202, Loss: 1420.13671875, Neurons: 11, Grad norm: 1.044e+02\n",
      "Epoch 203, Loss: 1418.64501953125, Neurons: 11, Grad norm: 1.051e+02\n",
      "Epoch 204, Loss: 1417.136962890625, Neurons: 11, Grad norm: 1.057e+02\n",
      "Epoch 205, Loss: 1415.6124267578125, Neurons: 11, Grad norm: 1.064e+02\n",
      "Epoch 206, Loss: 1414.0716552734375, Neurons: 11, Grad norm: 1.070e+02\n",
      "Epoch 207, Loss: 1412.5142822265625, Neurons: 11, Grad norm: 1.076e+02\n",
      "Epoch 208, Loss: 1410.9403076171875, Neurons: 11, Grad norm: 1.082e+02\n",
      "Epoch 209, Loss: 1409.3499755859375, Neurons: 11, Grad norm: 1.089e+02\n",
      "Epoch 210, Loss: 1407.742919921875, Neurons: 11, Grad norm: 1.095e+02\n",
      "Epoch 211, Loss: 1406.119140625, Neurons: 11, Grad norm: 1.101e+02\n",
      "Epoch 212, Loss: 1404.4788818359375, Neurons: 11, Grad norm: 1.107e+02\n",
      "Epoch 213, Loss: 1402.822021484375, Neurons: 11, Grad norm: 1.113e+02\n",
      "Epoch 214, Loss: 1401.148193359375, Neurons: 11, Grad norm: 1.119e+02\n",
      "Epoch 215, Loss: 1399.457763671875, Neurons: 11, Grad norm: 1.125e+02\n",
      "Epoch 216, Loss: 1397.750732421875, Neurons: 11, Grad norm: 1.131e+02\n",
      "Epoch 217, Loss: 1396.0269775390625, Neurons: 11, Grad norm: 1.137e+02\n",
      "Epoch 218, Loss: 1394.28662109375, Neurons: 11, Grad norm: 1.143e+02\n",
      "Epoch 219, Loss: 1392.529541015625, Neurons: 11, Grad norm: 1.149e+02\n",
      "Epoch 220, Loss: 1390.755615234375, Neurons: 11, Grad norm: 1.154e+02\n",
      "Epoch 221, Loss: 1388.96533203125, Neurons: 11, Grad norm: 1.160e+02\n",
      "Epoch 222, Loss: 1387.1585693359375, Neurons: 11, Grad norm: 1.165e+02\n",
      "Epoch 223, Loss: 1385.335205078125, Neurons: 11, Grad norm: 1.171e+02\n",
      "Epoch 224, Loss: 1383.4954833984375, Neurons: 11, Grad norm: 1.176e+02\n",
      "Epoch 225, Loss: 1381.6395263671875, Neurons: 11, Grad norm: 1.181e+02\n",
      "Epoch 226, Loss: 1379.7672119140625, Neurons: 11, Grad norm: 1.186e+02\n",
      "Epoch 227, Loss: 1377.87890625, Neurons: 11, Grad norm: 1.191e+02\n",
      "Epoch 228, Loss: 1375.974365234375, Neurons: 11, Grad norm: 1.196e+02\n",
      "Epoch 229, Loss: 1374.0538330078125, Neurons: 11, Grad norm: 1.201e+02\n",
      "Epoch 230, Loss: 1372.1177978515625, Neurons: 11, Grad norm: 1.206e+02\n",
      "Epoch 231, Loss: 1370.1661376953125, Neurons: 11, Grad norm: 1.210e+02\n",
      "Epoch 232, Loss: 1368.19873046875, Neurons: 11, Grad norm: 1.215e+02\n",
      "Epoch 233, Loss: 1366.21630859375, Neurons: 11, Grad norm: 1.219e+02\n",
      "Epoch 234, Loss: 1364.21875, Neurons: 11, Grad norm: 1.223e+02\n",
      "Epoch 235, Loss: 1362.2064208984375, Neurons: 11, Grad norm: 1.227e+02\n",
      "Epoch 236, Loss: 1360.17919921875, Neurons: 11, Grad norm: 1.231e+02\n",
      "Epoch 237, Loss: 1358.1375732421875, Neurons: 11, Grad norm: 1.234e+02\n",
      "Epoch 238, Loss: 1356.08203125, Neurons: 11, Grad norm: 1.238e+02\n",
      "Epoch 239, Loss: 1354.0125732421875, Neurons: 11, Grad norm: 1.241e+02\n",
      "Epoch 240, Loss: 1351.9295654296875, Neurons: 11, Grad norm: 1.244e+02\n",
      "Epoch 241, Loss: 1349.8331298828125, Neurons: 11, Grad norm: 1.247e+02\n",
      "Epoch 242, Loss: 1347.7239990234375, Neurons: 11, Grad norm: 1.250e+02\n",
      "Epoch 243, Loss: 1345.6024169921875, Neurons: 11, Grad norm: 1.252e+02\n",
      "Epoch 244, Loss: 1343.4686279296875, Neurons: 11, Grad norm: 1.254e+02\n",
      "Epoch 245, Loss: 1341.3231201171875, Neurons: 11, Grad norm: 1.256e+02\n",
      "Epoch 246, Loss: 1339.1666259765625, Neurons: 11, Grad norm: 1.258e+02\n",
      "Epoch 247, Loss: 1336.9991455078125, Neurons: 11, Grad norm: 1.259e+02\n",
      "Epoch 248, Loss: 1334.821533203125, Neurons: 11, Grad norm: 1.261e+02\n",
      "Epoch 249, Loss: 1332.6341552734375, Neurons: 11, Grad norm: 1.262e+02\n",
      "Epoch 249, Test loss: 1355.1090087890625\n",
      "Epoch 250, Loss: 1330.437744140625, Neurons: 11, Grad norm: 1.262e+02\n",
      "Epoch 251, Loss: 1328.23291015625, Neurons: 11, Grad norm: 1.263e+02\n",
      "Epoch 252, Loss: 1326.02001953125, Neurons: 11, Grad norm: 1.263e+02\n",
      "Epoch 253, Loss: 1323.800048828125, Neurons: 11, Grad norm: 1.263e+02\n",
      "Epoch 254, Loss: 1321.5736083984375, Neurons: 11, Grad norm: 1.262e+02\n",
      "Epoch 255, Loss: 1319.341552734375, Neurons: 11, Grad norm: 1.261e+02\n",
      "Epoch 256, Loss: 1317.1044921875, Neurons: 11, Grad norm: 1.260e+02\n",
      "Epoch 257, Loss: 1314.863525390625, Neurons: 11, Grad norm: 1.258e+02\n",
      "Epoch 258, Loss: 1312.619384765625, Neurons: 11, Grad norm: 1.257e+02\n",
      "Epoch 259, Loss: 1310.3731689453125, Neurons: 11, Grad norm: 1.254e+02\n",
      "Epoch 260, Loss: 1308.1256103515625, Neurons: 11, Grad norm: 1.252e+02\n",
      "Epoch 261, Loss: 1305.878173828125, Neurons: 11, Grad norm: 1.249e+02\n",
      "Epoch 262, Loss: 1303.6317138671875, Neurons: 11, Grad norm: 1.245e+02\n",
      "Epoch 263, Loss: 1301.38720703125, Neurons: 11, Grad norm: 1.241e+02\n",
      "Epoch 264, Loss: 1299.146240234375, Neurons: 11, Grad norm: 1.237e+02\n",
      "Epoch 265, Loss: 1296.909912109375, Neurons: 11, Grad norm: 1.232e+02\n",
      "Epoch 266, Loss: 1294.6795654296875, Neurons: 11, Grad norm: 1.227e+02\n",
      "Epoch 267, Loss: 1292.45654296875, Neurons: 11, Grad norm: 1.222e+02\n",
      "Epoch 268, Loss: 1290.2423095703125, Neurons: 11, Grad norm: 1.216e+02\n",
      "Epoch 269, Loss: 1288.0384521484375, Neurons: 11, Grad norm: 1.209e+02\n",
      "Epoch 270, Loss: 1285.8463134765625, Neurons: 11, Grad norm: 1.203e+02\n",
      "Epoch 271, Loss: 1283.667724609375, Neurons: 11, Grad norm: 1.195e+02\n",
      "Epoch 272, Loss: 1281.504150390625, Neurons: 11, Grad norm: 1.187e+02\n",
      "Epoch 273, Loss: 1279.357421875, Neurons: 11, Grad norm: 1.179e+02\n",
      "Epoch 274, Loss: 1277.2291259765625, Neurons: 11, Grad norm: 1.170e+02\n",
      "Epoch 275, Loss: 1275.12109375, Neurons: 11, Grad norm: 1.161e+02\n",
      "Epoch 276, Loss: 1273.0350341796875, Neurons: 11, Grad norm: 1.152e+02\n",
      "Epoch 277, Loss: 1270.9727783203125, Neurons: 11, Grad norm: 1.142e+02\n",
      "Epoch 278, Loss: 1268.93603515625, Neurons: 11, Grad norm: 1.131e+02\n",
      "Epoch 279, Loss: 1266.9267578125, Neurons: 11, Grad norm: 1.120e+02\n",
      "Epoch 280, Loss: 1264.9466552734375, Neurons: 11, Grad norm: 1.109e+02\n",
      "Epoch 281, Loss: 1262.997314453125, Neurons: 11, Grad norm: 1.097e+02\n",
      "Epoch 282, Loss: 1261.080810546875, Neurons: 11, Grad norm: 1.084e+02\n",
      "Epoch 283, Loss: 1259.1982421875, Neurons: 11, Grad norm: 1.072e+02\n",
      "Epoch 284, Loss: 1257.3515625, Neurons: 11, Grad norm: 1.059e+02\n",
      "Epoch 285, Loss: 1255.5421142578125, Neurons: 11, Grad norm: 1.045e+02\n",
      "Epoch 286, Loss: 1253.7711181640625, Neurons: 11, Grad norm: 1.031e+02\n",
      "Epoch 287, Loss: 1252.040283203125, Neurons: 11, Grad norm: 1.017e+02\n",
      "Epoch 288, Loss: 1250.3502197265625, Neurons: 11, Grad norm: 1.003e+02\n",
      "Epoch 289, Loss: 1248.702392578125, Neurons: 11, Grad norm: 9.881e+01\n",
      "Epoch 290, Loss: 1247.09716796875, Neurons: 11, Grad norm: 9.732e+01\n",
      "Epoch 291, Loss: 1245.5357666015625, Neurons: 11, Grad norm: 9.580e+01\n",
      "Epoch 292, Loss: 1244.018310546875, Neurons: 11, Grad norm: 9.426e+01\n",
      "Epoch 293, Loss: 1242.54541015625, Neurons: 11, Grad norm: 9.271e+01\n",
      "Epoch 294, Loss: 1241.1173095703125, Neurons: 11, Grad norm: 9.114e+01\n",
      "Epoch 295, Loss: 1239.734130859375, Neurons: 11, Grad norm: 8.955e+01\n",
      "Epoch 296, Loss: 1238.3955078125, Neurons: 11, Grad norm: 8.796e+01\n",
      "Epoch 297, Loss: 1237.1014404296875, Neurons: 11, Grad norm: 8.636e+01\n",
      "Epoch 298, Loss: 1235.8516845703125, Neurons: 11, Grad norm: 8.476e+01\n",
      "Epoch 299, Loss: 1234.645263671875, Neurons: 11, Grad norm: 8.315e+01\n",
      "Epoch 299, Test loss: 1257.6962890625\n",
      "Epoch 300, Loss: 1233.4820556640625, Neurons: 11, Grad norm: 8.155e+01\n",
      "Epoch 301, Loss: 1232.3609619140625, Neurons: 11, Grad norm: 7.995e+01\n",
      "Epoch 302, Loss: 1231.2813720703125, Neurons: 11, Grad norm: 7.836e+01\n",
      "Epoch 303, Loss: 1230.2421875, Neurons: 11, Grad norm: 7.677e+01\n",
      "Epoch 304, Loss: 1229.2423095703125, Neurons: 11, Grad norm: 7.520e+01\n",
      "Epoch 305, Loss: 1228.281005859375, Neurons: 11, Grad norm: 7.363e+01\n",
      "Epoch 306, Loss: 1227.3570556640625, Neurons: 11, Grad norm: 7.208e+01\n",
      "Epoch 307, Loss: 1226.468994140625, Neurons: 11, Grad norm: 7.055e+01\n",
      "Epoch 308, Loss: 1225.615966796875, Neurons: 11, Grad norm: 6.904e+01\n",
      "Epoch 309, Loss: 1224.79638671875, Neurons: 11, Grad norm: 6.754e+01\n",
      "Epoch 310, Loss: 1224.0093994140625, Neurons: 11, Grad norm: 6.606e+01\n",
      "Epoch 311, Loss: 1223.25341796875, Neurons: 11, Grad norm: 6.461e+01\n",
      "Epoch 312, Loss: 1222.527587890625, Neurons: 11, Grad norm: 6.318e+01\n",
      "Epoch 313, Loss: 1221.830322265625, Neurons: 11, Grad norm: 6.177e+01\n",
      "Epoch 314, Loss: 1221.16064453125, Neurons: 11, Grad norm: 6.039e+01\n",
      "Epoch 315, Loss: 1220.5172119140625, Neurons: 11, Grad norm: 5.903e+01\n",
      "Epoch 316, Loss: 1219.89892578125, Neurons: 11, Grad norm: 5.771e+01\n",
      "Epoch 317, Loss: 1219.3045654296875, Neurons: 11, Grad norm: 5.640e+01\n",
      "Epoch 318, Loss: 1218.73291015625, Neurons: 11, Grad norm: 5.513e+01\n",
      "Epoch 319, Loss: 1218.1832275390625, Neurons: 11, Grad norm: 5.389e+01\n",
      "Epoch 320, Loss: 1217.6541748046875, Neurons: 11, Grad norm: 5.267e+01\n",
      "Epoch 321, Loss: 1217.144775390625, Neurons: 11, Grad norm: 5.148e+01\n",
      "Epoch 322, Loss: 1216.6539306640625, Neurons: 11, Grad norm: 5.033e+01\n",
      "Epoch 323, Loss: 1216.1810302734375, Neurons: 11, Grad norm: 4.920e+01\n",
      "Epoch 324, Loss: 1215.724853515625, Neurons: 11, Grad norm: 4.810e+01\n",
      "Epoch 325, Loss: 1215.2845458984375, Neurons: 11, Grad norm: 4.704e+01\n",
      "Epoch 326, Loss: 1214.859619140625, Neurons: 11, Grad norm: 4.600e+01\n",
      "Epoch 327, Loss: 1214.4486083984375, Neurons: 11, Grad norm: 4.500e+01\n",
      "Epoch 328, Loss: 1214.0513916015625, Neurons: 11, Grad norm: 4.402e+01\n",
      "Epoch 329, Loss: 1213.6666259765625, Neurons: 11, Grad norm: 4.308e+01\n",
      "Epoch 330, Loss: 1213.294189453125, Neurons: 11, Grad norm: 4.216e+01\n",
      "Epoch 331, Loss: 1212.9329833984375, Neurons: 11, Grad norm: 4.127e+01\n",
      "Epoch 332, Loss: 1212.58251953125, Neurons: 11, Grad norm: 4.042e+01\n",
      "Epoch 333, Loss: 1212.2420654296875, Neurons: 11, Grad norm: 3.959e+01\n",
      "Epoch 334, Loss: 1211.9111328125, Neurons: 11, Grad norm: 3.879e+01\n",
      "Epoch 335, Loss: 1211.58935546875, Neurons: 11, Grad norm: 3.803e+01\n",
      "Epoch 336, Loss: 1211.2760009765625, Neurons: 11, Grad norm: 3.728e+01\n",
      "Epoch 337, Loss: 1210.970458984375, Neurons: 11, Grad norm: 3.657e+01\n",
      "Epoch 338, Loss: 1210.672607421875, Neurons: 11, Grad norm: 3.588e+01\n",
      "Epoch 339, Loss: 1210.381591796875, Neurons: 11, Grad norm: 3.522e+01\n",
      "Epoch 340, Loss: 1210.09716796875, Neurons: 11, Grad norm: 3.459e+01\n",
      "Epoch 341, Loss: 1209.8189697265625, Neurons: 11, Grad norm: 3.398e+01\n",
      "Epoch 342, Loss: 1209.546630859375, Neurons: 11, Grad norm: 3.340e+01\n",
      "Epoch 343, Loss: 1209.27978515625, Neurons: 11, Grad norm: 3.284e+01\n",
      "Epoch 344, Loss: 1209.0179443359375, Neurons: 11, Grad norm: 3.230e+01\n",
      "Epoch 345, Loss: 1208.7611083984375, Neurons: 11, Grad norm: 3.179e+01\n",
      "Epoch 346, Loss: 1208.5086669921875, Neurons: 11, Grad norm: 3.129e+01\n",
      "Epoch 347, Loss: 1208.2606201171875, Neurons: 11, Grad norm: 3.082e+01\n",
      "Epoch 348, Loss: 1208.016357421875, Neurons: 11, Grad norm: 3.037e+01\n",
      "Epoch 349, Loss: 1207.77587890625, Neurons: 11, Grad norm: 2.994e+01\n",
      "Epoch 349, Test loss: 1231.021728515625\n",
      "Epoch 350, Loss: 1207.5389404296875, Neurons: 11, Grad norm: 2.953e+01\n",
      "Epoch 351, Loss: 1207.305419921875, Neurons: 11, Grad norm: 2.913e+01\n",
      "Epoch 352, Loss: 1207.074951171875, Neurons: 11, Grad norm: 2.875e+01\n",
      "Epoch 353, Loss: 1206.8475341796875, Neurons: 11, Grad norm: 2.839e+01\n",
      "Epoch 354, Loss: 1206.622802734375, Neurons: 11, Grad norm: 2.804e+01\n",
      "Epoch 355, Loss: 1206.4007568359375, Neurons: 11, Grad norm: 2.771e+01\n",
      "Epoch 356, Loss: 1206.181396484375, Neurons: 11, Grad norm: 2.739e+01\n",
      "Epoch 357, Loss: 1205.964111328125, Neurons: 11, Grad norm: 2.709e+01\n",
      "Epoch 358, Loss: 1205.7493896484375, Neurons: 11, Grad norm: 2.680e+01\n",
      "Epoch 359, Loss: 1205.5367431640625, Neurons: 11, Grad norm: 2.651e+01\n",
      "Epoch 360, Loss: 1205.326416015625, Neurons: 11, Grad norm: 2.624e+01\n",
      "Epoch 361, Loss: 1205.117919921875, Neurons: 11, Grad norm: 2.598e+01\n",
      "Epoch 362, Loss: 1204.91162109375, Neurons: 11, Grad norm: 2.573e+01\n",
      "Epoch 363, Loss: 1204.7071533203125, Neurons: 11, Grad norm: 2.549e+01\n",
      "Epoch 364, Loss: 1204.5047607421875, Neurons: 11, Grad norm: 2.526e+01\n",
      "Epoch 365, Loss: 1204.30419921875, Neurons: 11, Grad norm: 2.503e+01\n",
      "Epoch 366, Loss: 1204.1053466796875, Neurons: 11, Grad norm: 2.481e+01\n",
      "Epoch 367, Loss: 1203.90869140625, Neurons: 11, Grad norm: 2.460e+01\n",
      "Epoch 368, Loss: 1203.7137451171875, Neurons: 11, Grad norm: 2.440e+01\n",
      "Epoch 369, Loss: 1203.5206298828125, Neurons: 11, Grad norm: 2.420e+01\n",
      "Epoch 370, Loss: 1203.329345703125, Neurons: 11, Grad norm: 2.401e+01\n",
      "Epoch 371, Loss: 1203.1400146484375, Neurons: 11, Grad norm: 2.382e+01\n",
      "Epoch 372, Loss: 1202.9525146484375, Neurons: 11, Grad norm: 2.364e+01\n",
      "Epoch 373, Loss: 1202.7669677734375, Neurons: 11, Grad norm: 2.347e+01\n",
      "Epoch 374, Loss: 1202.5833740234375, Neurons: 11, Grad norm: 2.330e+01\n",
      "Epoch 375, Loss: 1202.401611328125, Neurons: 11, Grad norm: 2.313e+01\n",
      "Epoch 376, Loss: 1202.2215576171875, Neurons: 11, Grad norm: 2.297e+01\n",
      "Epoch 377, Loss: 1202.0435791015625, Neurons: 11, Grad norm: 2.282e+01\n",
      "Epoch 378, Loss: 1201.8673095703125, Neurons: 11, Grad norm: 2.267e+01\n",
      "Epoch 379, Loss: 1201.6927490234375, Neurons: 11, Grad norm: 2.252e+01\n",
      "Epoch 380, Loss: 1201.5201416015625, Neurons: 11, Grad norm: 2.239e+01\n",
      "Epoch 381, Loss: 1201.349365234375, Neurons: 11, Grad norm: 2.225e+01\n",
      "Epoch 382, Loss: 1201.18017578125, Neurons: 11, Grad norm: 2.212e+01\n",
      "Epoch 383, Loss: 1201.0125732421875, Neurons: 11, Grad norm: 2.200e+01\n",
      "Epoch 384, Loss: 1200.8465576171875, Neurons: 11, Grad norm: 2.187e+01\n",
      "Epoch 385, Loss: 1200.68212890625, Neurons: 11, Grad norm: 2.176e+01\n",
      "Epoch 386, Loss: 1200.5191650390625, Neurons: 11, Grad norm: 2.165e+01\n",
      "Epoch 387, Loss: 1200.3575439453125, Neurons: 11, Grad norm: 2.154e+01\n",
      "Epoch 388, Loss: 1200.197265625, Neurons: 11, Grad norm: 2.144e+01\n",
      "Epoch 389, Loss: 1200.0380859375, Neurons: 11, Grad norm: 2.134e+01\n",
      "Epoch 390, Loss: 1199.880126953125, Neurons: 11, Grad norm: 2.124e+01\n",
      "Epoch 391, Loss: 1199.72314453125, Neurons: 11, Grad norm: 2.115e+01\n",
      "Epoch 392, Loss: 1199.567138671875, Neurons: 11, Grad norm: 2.106e+01\n",
      "Epoch 393, Loss: 1199.412109375, Neurons: 11, Grad norm: 2.098e+01\n",
      "Epoch 394, Loss: 1199.2578125, Neurons: 11, Grad norm: 2.090e+01\n",
      "Epoch 395, Loss: 1199.1043701171875, Neurons: 11, Grad norm: 2.082e+01\n",
      "Epoch 396, Loss: 1198.951416015625, Neurons: 11, Grad norm: 2.075e+01\n",
      "Epoch 397, Loss: 1198.7991943359375, Neurons: 11, Grad norm: 2.068e+01\n",
      "Epoch 398, Loss: 1198.6475830078125, Neurons: 11, Grad norm: 2.061e+01\n",
      "Epoch 399, Loss: 1198.496337890625, Neurons: 11, Grad norm: 2.054e+01\n",
      "Epoch 399, Test loss: 1221.521728515625\n",
      "Epoch 400, Loss: 1198.3455810546875, Neurons: 11, Grad norm: 2.047e+01\n",
      "Epoch 401, Loss: 1198.1951904296875, Neurons: 11, Grad norm: 2.041e+01\n",
      "Epoch 402, Loss: 1198.045166015625, Neurons: 11, Grad norm: 2.035e+01\n",
      "Epoch 403, Loss: 1197.8955078125, Neurons: 11, Grad norm: 2.028e+01\n",
      "Epoch 404, Loss: 1197.7462158203125, Neurons: 11, Grad norm: 2.022e+01\n",
      "Epoch 405, Loss: 1197.596923828125, Neurons: 11, Grad norm: 2.016e+01\n",
      "Epoch 406, Loss: 1197.4481201171875, Neurons: 11, Grad norm: 2.010e+01\n",
      "Epoch 407, Loss: 1197.29931640625, Neurons: 11, Grad norm: 2.004e+01\n",
      "Epoch 408, Loss: 1197.1510009765625, Neurons: 11, Grad norm: 1.998e+01\n",
      "Epoch 409, Loss: 1197.0028076171875, Neurons: 11, Grad norm: 1.993e+01\n",
      "Epoch 410, Loss: 1196.8546142578125, Neurons: 11, Grad norm: 1.987e+01\n",
      "Epoch 411, Loss: 1196.706787109375, Neurons: 11, Grad norm: 1.981e+01\n",
      "Epoch 412, Loss: 1196.559326171875, Neurons: 11, Grad norm: 1.975e+01\n",
      "Epoch 413, Loss: 1196.4119873046875, Neurons: 11, Grad norm: 1.969e+01\n",
      "Epoch 414, Loss: 1196.264892578125, Neurons: 11, Grad norm: 1.963e+01\n",
      "Epoch 415, Loss: 1196.117919921875, Neurons: 11, Grad norm: 1.957e+01\n",
      "Epoch 416, Loss: 1195.9713134765625, Neurons: 11, Grad norm: 1.951e+01\n",
      "Epoch 417, Loss: 1195.8250732421875, Neurons: 11, Grad norm: 1.945e+01\n",
      "Epoch 418, Loss: 1195.6790771484375, Neurons: 11, Grad norm: 1.939e+01\n",
      "Epoch 419, Loss: 1195.5333251953125, Neurons: 11, Grad norm: 1.934e+01\n",
      "Epoch 420, Loss: 1195.3880615234375, Neurons: 11, Grad norm: 1.928e+01\n",
      "Epoch 421, Loss: 1195.242919921875, Neurons: 11, Grad norm: 1.923e+01\n",
      "Epoch 422, Loss: 1195.09814453125, Neurons: 11, Grad norm: 1.917e+01\n",
      "Epoch 423, Loss: 1194.953857421875, Neurons: 11, Grad norm: 1.912e+01\n",
      "Epoch 424, Loss: 1194.809814453125, Neurons: 11, Grad norm: 1.908e+01\n",
      "Epoch 425, Loss: 1194.6661376953125, Neurons: 11, Grad norm: 1.903e+01\n",
      "Epoch 426, Loss: 1194.5228271484375, Neurons: 11, Grad norm: 1.899e+01\n",
      "Epoch 427, Loss: 1194.379638671875, Neurons: 11, Grad norm: 1.895e+01\n",
      "Epoch 428, Loss: 1194.23681640625, Neurons: 11, Grad norm: 1.892e+01\n",
      "Epoch 429, Loss: 1194.0941162109375, Neurons: 11, Grad norm: 1.888e+01\n",
      "Epoch 430, Loss: 1193.9517822265625, Neurons: 11, Grad norm: 1.886e+01\n",
      "Epoch 431, Loss: 1193.8095703125, Neurons: 11, Grad norm: 1.883e+01\n",
      "Epoch 432, Loss: 1193.667236328125, Neurons: 11, Grad norm: 1.881e+01\n",
      "Epoch 433, Loss: 1193.525146484375, Neurons: 11, Grad norm: 1.880e+01\n",
      "Epoch 434, Loss: 1193.3829345703125, Neurons: 11, Grad norm: 1.878e+01\n",
      "Epoch 435, Loss: 1193.24072265625, Neurons: 11, Grad norm: 1.877e+01\n",
      "Epoch 436, Loss: 1193.0985107421875, Neurons: 11, Grad norm: 1.877e+01\n",
      "Epoch 437, Loss: 1192.9560546875, Neurons: 11, Grad norm: 1.876e+01\n",
      "Epoch 438, Loss: 1192.8133544921875, Neurons: 11, Grad norm: 1.876e+01\n",
      "Epoch 439, Loss: 1192.67041015625, Neurons: 11, Grad norm: 1.876e+01\n",
      "Epoch 440, Loss: 1192.5272216796875, Neurons: 11, Grad norm: 1.877e+01\n",
      "Epoch 441, Loss: 1192.3834228515625, Neurons: 11, Grad norm: 1.878e+01\n",
      "Epoch 442, Loss: 1192.2393798828125, Neurons: 11, Grad norm: 1.878e+01\n",
      "Epoch 443, Loss: 1192.0947265625, Neurons: 11, Grad norm: 1.879e+01\n",
      "Epoch 444, Loss: 1191.9498291015625, Neurons: 11, Grad norm: 1.881e+01\n",
      "Epoch 445, Loss: 1191.8040771484375, Neurons: 11, Grad norm: 1.882e+01\n",
      "Epoch 446, Loss: 1191.657958984375, Neurons: 11, Grad norm: 1.884e+01\n",
      "Epoch 447, Loss: 1191.51123046875, Neurons: 11, Grad norm: 1.885e+01\n",
      "Epoch 448, Loss: 1191.36376953125, Neurons: 11, Grad norm: 1.887e+01\n",
      "Epoch 449, Loss: 1191.215576171875, Neurons: 11, Grad norm: 1.889e+01\n",
      "Epoch 449, Test loss: 1214.028076171875\n",
      "Epoch 450, Loss: 1191.066650390625, Neurons: 11, Grad norm: 1.891e+01\n",
      "Epoch 451, Loss: 1190.9171142578125, Neurons: 11, Grad norm: 1.893e+01\n",
      "Epoch 452, Loss: 1190.7669677734375, Neurons: 11, Grad norm: 1.895e+01\n",
      "Epoch 453, Loss: 1190.6158447265625, Neurons: 11, Grad norm: 1.897e+01\n",
      "Epoch 454, Loss: 1190.4639892578125, Neurons: 11, Grad norm: 1.899e+01\n",
      "Epoch 455, Loss: 1190.3114013671875, Neurons: 11, Grad norm: 1.902e+01\n",
      "Epoch 456, Loss: 1190.157958984375, Neurons: 11, Grad norm: 1.904e+01\n",
      "Epoch 457, Loss: 1190.0037841796875, Neurons: 11, Grad norm: 1.906e+01\n",
      "Epoch 458, Loss: 1189.8487548828125, Neurons: 11, Grad norm: 1.909e+01\n",
      "Epoch 459, Loss: 1189.6927490234375, Neurons: 11, Grad norm: 1.911e+01\n",
      "Epoch 460, Loss: 1189.5361328125, Neurons: 11, Grad norm: 1.913e+01\n",
      "Epoch 461, Loss: 1189.3785400390625, Neurons: 11, Grad norm: 1.915e+01\n",
      "Epoch 462, Loss: 1189.22021484375, Neurons: 11, Grad norm: 1.917e+01\n",
      "Epoch 463, Loss: 1189.0609130859375, Neurons: 11, Grad norm: 1.919e+01\n",
      "Epoch 464, Loss: 1188.90087890625, Neurons: 11, Grad norm: 1.921e+01\n",
      "Epoch 465, Loss: 1188.7401123046875, Neurons: 11, Grad norm: 1.923e+01\n",
      "Epoch 466, Loss: 1188.57861328125, Neurons: 11, Grad norm: 1.924e+01\n",
      "Epoch 467, Loss: 1188.4161376953125, Neurons: 11, Grad norm: 1.925e+01\n",
      "Epoch 468, Loss: 1188.2529296875, Neurons: 11, Grad norm: 1.926e+01\n",
      "Epoch 469, Loss: 1188.089111328125, Neurons: 11, Grad norm: 1.927e+01\n",
      "Epoch 470, Loss: 1187.9248046875, Neurons: 11, Grad norm: 1.927e+01\n",
      "Epoch 471, Loss: 1187.759521484375, Neurons: 11, Grad norm: 1.927e+01\n",
      "Epoch 472, Loss: 1187.593994140625, Neurons: 11, Grad norm: 1.926e+01\n",
      "Epoch 473, Loss: 1187.4278564453125, Neurons: 11, Grad norm: 1.925e+01\n",
      "Epoch 474, Loss: 1187.2613525390625, Neurons: 11, Grad norm: 1.923e+01\n",
      "Epoch 475, Loss: 1187.0946044921875, Neurons: 11, Grad norm: 1.921e+01\n",
      "Epoch 476, Loss: 1186.9276123046875, Neurons: 11, Grad norm: 1.918e+01\n",
      "Epoch 477, Loss: 1186.7606201171875, Neurons: 11, Grad norm: 1.915e+01\n",
      "Epoch 478, Loss: 1186.5936279296875, Neurons: 11, Grad norm: 1.911e+01\n",
      "Epoch 479, Loss: 1186.4268798828125, Neurons: 11, Grad norm: 1.906e+01\n",
      "Epoch 480, Loss: 1186.2606201171875, Neurons: 11, Grad norm: 1.901e+01\n",
      "Epoch 481, Loss: 1186.09521484375, Neurons: 11, Grad norm: 1.895e+01\n",
      "Epoch 482, Loss: 1185.930419921875, Neurons: 11, Grad norm: 1.888e+01\n",
      "Epoch 483, Loss: 1185.766845703125, Neurons: 11, Grad norm: 1.881e+01\n",
      "Epoch 484, Loss: 1185.604736328125, Neurons: 11, Grad norm: 1.874e+01\n",
      "Epoch 485, Loss: 1185.4442138671875, Neurons: 11, Grad norm: 1.866e+01\n",
      "Epoch 486, Loss: 1185.2855224609375, Neurons: 11, Grad norm: 1.857e+01\n",
      "Epoch 487, Loss: 1185.1290283203125, Neurons: 11, Grad norm: 1.849e+01\n",
      "Epoch 488, Loss: 1184.9747314453125, Neurons: 11, Grad norm: 1.841e+01\n",
      "Epoch 489, Loss: 1184.822998046875, Neurons: 11, Grad norm: 1.833e+01\n",
      "Epoch 490, Loss: 1184.673828125, Neurons: 11, Grad norm: 1.825e+01\n",
      "Epoch 491, Loss: 1184.52734375, Neurons: 11, Grad norm: 1.818e+01\n",
      "Epoch 492, Loss: 1184.383544921875, Neurons: 11, Grad norm: 1.810e+01\n",
      "Epoch 493, Loss: 1184.2423095703125, Neurons: 11, Grad norm: 1.804e+01\n",
      "Epoch 494, Loss: 1184.1036376953125, Neurons: 11, Grad norm: 1.797e+01\n",
      "Epoch 495, Loss: 1183.9674072265625, Neurons: 11, Grad norm: 1.790e+01\n",
      "Epoch 496, Loss: 1183.833251953125, Neurons: 11, Grad norm: 1.783e+01\n",
      "Epoch 497, Loss: 1183.701171875, Neurons: 11, Grad norm: 1.777e+01\n",
      "Epoch 498, Loss: 1183.5709228515625, Neurons: 11, Grad norm: 1.770e+01\n",
      "Epoch 499, Loss: 1183.4423828125, Neurons: 11, Grad norm: 1.764e+01\n",
      "Epoch 499, Test loss: 1206.1287841796875\n",
      "Epoch 500, Loss: 1183.315185546875, Neurons: 11, Grad norm: 1.759e+01\n",
      "Epoch 501, Loss: 1183.189208984375, Neurons: 11, Grad norm: 1.754e+01\n",
      "Epoch 502, Loss: 1183.0643310546875, Neurons: 11, Grad norm: 1.750e+01\n",
      "Epoch 503, Loss: 1182.93994140625, Neurons: 11, Grad norm: 1.747e+01\n",
      "Epoch 504, Loss: 1182.81640625, Neurons: 11, Grad norm: 1.745e+01\n",
      "Epoch 505, Loss: 1182.693115234375, Neurons: 11, Grad norm: 1.743e+01\n",
      "Epoch 506, Loss: 1182.5701904296875, Neurons: 11, Grad norm: 1.742e+01\n",
      "Epoch 507, Loss: 1182.4473876953125, Neurons: 11, Grad norm: 1.741e+01\n",
      "Epoch 508, Loss: 1182.324462890625, Neurons: 11, Grad norm: 1.740e+01\n",
      "Epoch 509, Loss: 1182.201416015625, Neurons: 11, Grad norm: 1.739e+01\n",
      "Epoch 510, Loss: 1182.0780029296875, Neurons: 11, Grad norm: 1.740e+01\n",
      "Epoch 511, Loss: 1181.9542236328125, Neurons: 11, Grad norm: 1.741e+01\n",
      "Epoch 512, Loss: 1181.8299560546875, Neurons: 11, Grad norm: 1.743e+01\n",
      "Epoch 513, Loss: 1181.704833984375, Neurons: 11, Grad norm: 1.746e+01\n",
      "Epoch 514, Loss: 1181.5792236328125, Neurons: 11, Grad norm: 1.750e+01\n",
      "Epoch 515, Loss: 1181.4525146484375, Neurons: 11, Grad norm: 1.755e+01\n",
      "Epoch 516, Loss: 1181.324951171875, Neurons: 11, Grad norm: 1.761e+01\n",
      "Epoch 517, Loss: 1181.1964111328125, Neurons: 11, Grad norm: 1.767e+01\n",
      "Epoch 518, Loss: 1181.0665283203125, Neurons: 11, Grad norm: 1.775e+01\n",
      "Epoch 519, Loss: 1180.9354248046875, Neurons: 11, Grad norm: 1.783e+01\n",
      "Epoch 520, Loss: 1180.802978515625, Neurons: 11, Grad norm: 1.792e+01\n",
      "Epoch 521, Loss: 1180.6689453125, Neurons: 11, Grad norm: 1.802e+01\n",
      "Epoch 522, Loss: 1180.5333251953125, Neurons: 11, Grad norm: 1.813e+01\n",
      "Epoch 523, Loss: 1180.39599609375, Neurons: 11, Grad norm: 1.826e+01\n",
      "Epoch 524, Loss: 1180.2567138671875, Neurons: 11, Grad norm: 1.839e+01\n",
      "Epoch 525, Loss: 1180.1156005859375, Neurons: 11, Grad norm: 1.854e+01\n",
      "Epoch 526, Loss: 1179.97216796875, Neurons: 11, Grad norm: 1.870e+01\n",
      "Epoch 527, Loss: 1179.8267822265625, Neurons: 11, Grad norm: 1.887e+01\n",
      "Epoch 528, Loss: 1179.678955078125, Neurons: 11, Grad norm: 1.905e+01\n",
      "Epoch 529, Loss: 1179.5286865234375, Neurons: 11, Grad norm: 1.924e+01\n",
      "Epoch 530, Loss: 1179.3758544921875, Neurons: 11, Grad norm: 1.945e+01\n",
      "Epoch 531, Loss: 1179.2203369140625, Neurons: 11, Grad norm: 1.967e+01\n",
      "Epoch 532, Loss: 1179.0618896484375, Neurons: 11, Grad norm: 1.990e+01\n",
      "Epoch 533, Loss: 1178.9005126953125, Neurons: 11, Grad norm: 2.014e+01\n",
      "Epoch 534, Loss: 1178.736083984375, Neurons: 11, Grad norm: 2.040e+01\n",
      "Epoch 535, Loss: 1178.568359375, Neurons: 11, Grad norm: 2.067e+01\n",
      "Epoch 536, Loss: 1178.3974609375, Neurons: 11, Grad norm: 2.095e+01\n",
      "Epoch 537, Loss: 1178.2230224609375, Neurons: 11, Grad norm: 2.124e+01\n",
      "Epoch 538, Loss: 1178.0447998046875, Neurons: 11, Grad norm: 2.155e+01\n",
      "Epoch 539, Loss: 1177.8629150390625, Neurons: 11, Grad norm: 2.186e+01\n",
      "Epoch 540, Loss: 1177.6773681640625, Neurons: 11, Grad norm: 2.218e+01\n",
      "Epoch 541, Loss: 1177.4879150390625, Neurons: 11, Grad norm: 2.250e+01\n",
      "Epoch 542, Loss: 1177.2943115234375, Neurons: 11, Grad norm: 2.284e+01\n",
      "Epoch 543, Loss: 1177.0965576171875, Neurons: 11, Grad norm: 2.317e+01\n",
      "Epoch 544, Loss: 1176.8948974609375, Neurons: 11, Grad norm: 2.350e+01\n",
      "Epoch 545, Loss: 1176.68896484375, Neurons: 11, Grad norm: 2.383e+01\n",
      "Epoch 546, Loss: 1176.478515625, Neurons: 11, Grad norm: 2.415e+01\n",
      "Epoch 547, Loss: 1176.26416015625, Neurons: 11, Grad norm: 2.445e+01\n",
      "Epoch 548, Loss: 1176.0455322265625, Neurons: 11, Grad norm: 2.475e+01\n",
      "Epoch 549, Loss: 1175.822998046875, Neurons: 11, Grad norm: 2.501e+01\n",
      "Epoch 549, Test loss: 1198.1947021484375\n",
      "Epoch 550, Loss: 1175.5963134765625, Neurons: 11, Grad norm: 2.525e+01\n",
      "Epoch 551, Loss: 1175.36572265625, Neurons: 11, Grad norm: 2.545e+01\n",
      "Epoch 552, Loss: 1175.1317138671875, Neurons: 11, Grad norm: 2.562e+01\n",
      "Epoch 553, Loss: 1174.89453125, Neurons: 11, Grad norm: 2.573e+01\n",
      "Epoch 554, Loss: 1174.654541015625, Neurons: 11, Grad norm: 2.578e+01\n",
      "Epoch 555, Loss: 1174.412109375, Neurons: 11, Grad norm: 2.577e+01\n",
      "Epoch 556, Loss: 1174.168212890625, Neurons: 11, Grad norm: 2.569e+01\n",
      "Epoch 557, Loss: 1173.92333984375, Neurons: 11, Grad norm: 2.553e+01\n",
      "Epoch 558, Loss: 1173.6787109375, Neurons: 11, Grad norm: 2.529e+01\n",
      "Epoch 559, Loss: 1173.4349365234375, Neurons: 11, Grad norm: 2.497e+01\n",
      "Epoch 560, Loss: 1173.1937255859375, Neurons: 11, Grad norm: 2.458e+01\n",
      "Epoch 561, Loss: 1172.9559326171875, Neurons: 11, Grad norm: 2.413e+01\n",
      "Epoch 562, Loss: 1172.7237548828125, Neurons: 11, Grad norm: 2.363e+01\n",
      "Epoch 563, Loss: 1172.4984130859375, Neurons: 11, Grad norm: 2.310e+01\n",
      "Epoch 564, Loss: 1172.281005859375, Neurons: 11, Grad norm: 2.258e+01\n",
      "Epoch 565, Loss: 1172.0731201171875, Neurons: 11, Grad norm: 2.207e+01\n",
      "Epoch 566, Loss: 1171.8751220703125, Neurons: 11, Grad norm: 2.161e+01\n",
      "Epoch 567, Loss: 1171.6876220703125, Neurons: 11, Grad norm: 2.121e+01\n",
      "Epoch 568, Loss: 1171.510009765625, Neurons: 11, Grad norm: 2.086e+01\n",
      "Epoch 569, Loss: 1171.3414306640625, Neurons: 11, Grad norm: 2.057e+01\n",
      "Epoch 570, Loss: 1171.1810302734375, Neurons: 11, Grad norm: 2.032e+01\n",
      "Epoch 571, Loss: 1171.0269775390625, Neurons: 11, Grad norm: 2.011e+01\n",
      "Epoch 572, Loss: 1170.87841796875, Neurons: 11, Grad norm: 1.992e+01\n",
      "Epoch 573, Loss: 1170.734375, Neurons: 11, Grad norm: 1.975e+01\n",
      "Epoch 574, Loss: 1170.59375, Neurons: 11, Grad norm: 1.958e+01\n",
      "Epoch 575, Loss: 1170.455810546875, Neurons: 11, Grad norm: 1.942e+01\n",
      "Epoch 576, Loss: 1170.320068359375, Neurons: 11, Grad norm: 1.927e+01\n",
      "Epoch 577, Loss: 1170.1861572265625, Neurons: 11, Grad norm: 1.912e+01\n",
      "Epoch 578, Loss: 1170.0535888671875, Neurons: 11, Grad norm: 1.898e+01\n",
      "Epoch 579, Loss: 1169.922119140625, Neurons: 11, Grad norm: 1.884e+01\n",
      "Epoch 580, Loss: 1169.7918701171875, Neurons: 11, Grad norm: 1.872e+01\n",
      "Epoch 581, Loss: 1169.66259765625, Neurons: 11, Grad norm: 1.860e+01\n",
      "Epoch 582, Loss: 1169.533935546875, Neurons: 11, Grad norm: 1.850e+01\n",
      "Epoch 583, Loss: 1169.406005859375, Neurons: 11, Grad norm: 1.841e+01\n",
      "Epoch 584, Loss: 1169.278564453125, Neurons: 11, Grad norm: 1.834e+01\n",
      "Epoch 585, Loss: 1169.1517333984375, Neurons: 11, Grad norm: 1.827e+01\n",
      "Epoch 586, Loss: 1169.0252685546875, Neurons: 11, Grad norm: 1.821e+01\n",
      "Epoch 587, Loss: 1168.899169921875, Neurons: 11, Grad norm: 1.816e+01\n",
      "Epoch 588, Loss: 1168.7733154296875, Neurons: 11, Grad norm: 1.811e+01\n",
      "Epoch 589, Loss: 1168.6475830078125, Neurons: 11, Grad norm: 1.807e+01\n",
      "Epoch 590, Loss: 1168.52197265625, Neurons: 11, Grad norm: 1.803e+01\n",
      "Epoch 591, Loss: 1168.3966064453125, Neurons: 11, Grad norm: 1.800e+01\n",
      "Epoch 592, Loss: 1168.2711181640625, Neurons: 11, Grad norm: 1.797e+01\n",
      "Epoch 593, Loss: 1168.145751953125, Neurons: 11, Grad norm: 1.793e+01\n",
      "Epoch 594, Loss: 1168.0203857421875, Neurons: 11, Grad norm: 1.790e+01\n",
      "Epoch 595, Loss: 1167.89501953125, Neurons: 11, Grad norm: 1.787e+01\n",
      "Epoch 596, Loss: 1167.769775390625, Neurons: 11, Grad norm: 1.784e+01\n",
      "Epoch 597, Loss: 1167.64453125, Neurons: 11, Grad norm: 1.781e+01\n",
      "Epoch 598, Loss: 1167.5191650390625, Neurons: 11, Grad norm: 1.778e+01\n",
      "Epoch 599, Loss: 1167.3941650390625, Neurons: 11, Grad norm: 1.775e+01\n",
      "Epoch 599, Test loss: 1189.63330078125\n",
      "Epoch 600, Loss: 1167.2691650390625, Neurons: 11, Grad norm: 1.773e+01\n",
      "Epoch 601, Loss: 1167.1441650390625, Neurons: 11, Grad norm: 1.770e+01\n",
      "Epoch 602, Loss: 1167.0194091796875, Neurons: 11, Grad norm: 1.768e+01\n",
      "Epoch 603, Loss: 1166.89453125, Neurons: 11, Grad norm: 1.766e+01\n",
      "Epoch 604, Loss: 1166.769775390625, Neurons: 11, Grad norm: 1.764e+01\n",
      "Epoch 605, Loss: 1166.6453857421875, Neurons: 11, Grad norm: 1.762e+01\n",
      "Epoch 606, Loss: 1166.520751953125, Neurons: 11, Grad norm: 1.761e+01\n",
      "Epoch 607, Loss: 1166.3963623046875, Neurons: 11, Grad norm: 1.759e+01\n",
      "Epoch 608, Loss: 1166.27197265625, Neurons: 11, Grad norm: 1.758e+01\n",
      "Epoch 609, Loss: 1166.1478271484375, Neurons: 11, Grad norm: 1.756e+01\n",
      "Epoch 610, Loss: 1166.0234375, Neurons: 11, Grad norm: 1.755e+01\n",
      "Epoch 611, Loss: 1165.899169921875, Neurons: 11, Grad norm: 1.753e+01\n",
      "Epoch 612, Loss: 1165.7750244140625, Neurons: 11, Grad norm: 1.752e+01\n",
      "Epoch 613, Loss: 1165.65087890625, Neurons: 11, Grad norm: 1.751e+01\n",
      "Epoch 614, Loss: 1165.526611328125, Neurons: 11, Grad norm: 1.749e+01\n",
      "Epoch 615, Loss: 1165.402587890625, Neurons: 11, Grad norm: 1.748e+01\n",
      "Epoch 616, Loss: 1165.2783203125, Neurons: 11, Grad norm: 1.747e+01\n",
      "Epoch 617, Loss: 1165.1541748046875, Neurons: 11, Grad norm: 1.745e+01\n",
      "Epoch 618, Loss: 1165.030029296875, Neurons: 11, Grad norm: 1.744e+01\n",
      "Epoch 619, Loss: 1164.90576171875, Neurons: 11, Grad norm: 1.742e+01\n",
      "Epoch 620, Loss: 1164.7816162109375, Neurons: 11, Grad norm: 1.741e+01\n",
      "Epoch 621, Loss: 1164.6573486328125, Neurons: 11, Grad norm: 1.740e+01\n",
      "Epoch 622, Loss: 1164.533203125, Neurons: 11, Grad norm: 1.739e+01\n",
      "Epoch 623, Loss: 1164.4088134765625, Neurons: 11, Grad norm: 1.737e+01\n",
      "Epoch 624, Loss: 1164.28466796875, Neurons: 11, Grad norm: 1.736e+01\n",
      "Epoch 625, Loss: 1164.160400390625, Neurons: 11, Grad norm: 1.735e+01\n",
      "Epoch 626, Loss: 1164.0361328125, Neurons: 11, Grad norm: 1.734e+01\n",
      "Epoch 627, Loss: 1163.9117431640625, Neurons: 11, Grad norm: 1.733e+01\n",
      "Epoch 628, Loss: 1163.7874755859375, Neurons: 11, Grad norm: 1.732e+01\n",
      "Epoch 629, Loss: 1163.6632080078125, Neurons: 11, Grad norm: 1.732e+01\n",
      "Epoch 630, Loss: 1163.538818359375, Neurons: 11, Grad norm: 1.731e+01\n",
      "Epoch 631, Loss: 1163.4144287109375, Neurons: 11, Grad norm: 1.730e+01\n",
      "Epoch 632, Loss: 1163.2899169921875, Neurons: 11, Grad norm: 1.729e+01\n",
      "Epoch 633, Loss: 1163.16552734375, Neurons: 11, Grad norm: 1.728e+01\n",
      "Epoch 634, Loss: 1163.041015625, Neurons: 11, Grad norm: 1.728e+01\n",
      "Epoch 635, Loss: 1162.9166259765625, Neurons: 11, Grad norm: 1.727e+01\n",
      "Epoch 636, Loss: 1162.7919921875, Neurons: 11, Grad norm: 1.726e+01\n",
      "Epoch 637, Loss: 1162.6673583984375, Neurons: 11, Grad norm: 1.726e+01\n",
      "Epoch 638, Loss: 1162.542724609375, Neurons: 11, Grad norm: 1.725e+01\n",
      "Epoch 639, Loss: 1162.41796875, Neurons: 11, Grad norm: 1.724e+01\n",
      "Epoch 640, Loss: 1162.2933349609375, Neurons: 11, Grad norm: 1.723e+01\n",
      "Epoch 641, Loss: 1162.1685791015625, Neurons: 11, Grad norm: 1.723e+01\n",
      "Epoch 642, Loss: 1162.0438232421875, Neurons: 11, Grad norm: 1.722e+01\n",
      "Epoch 643, Loss: 1161.9189453125, Neurons: 11, Grad norm: 1.721e+01\n",
      "Epoch 644, Loss: 1161.794189453125, Neurons: 11, Grad norm: 1.721e+01\n",
      "Epoch 645, Loss: 1161.6693115234375, Neurons: 11, Grad norm: 1.720e+01\n",
      "Epoch 646, Loss: 1161.5443115234375, Neurons: 11, Grad norm: 1.720e+01\n",
      "Epoch 647, Loss: 1161.4193115234375, Neurons: 11, Grad norm: 1.719e+01\n",
      "Epoch 648, Loss: 1161.2943115234375, Neurons: 11, Grad norm: 1.718e+01\n",
      "Epoch 649, Loss: 1161.1693115234375, Neurons: 11, Grad norm: 1.718e+01\n",
      "Epoch 649, Test loss: 1183.1680908203125\n",
      "Epoch 650, Loss: 1161.0440673828125, Neurons: 11, Grad norm: 1.717e+01\n",
      "Epoch 651, Loss: 1160.9189453125, Neurons: 11, Grad norm: 1.716e+01\n",
      "Epoch 652, Loss: 1160.7938232421875, Neurons: 11, Grad norm: 1.716e+01\n",
      "Epoch 653, Loss: 1160.6685791015625, Neurons: 11, Grad norm: 1.715e+01\n",
      "Epoch 654, Loss: 1160.543212890625, Neurons: 11, Grad norm: 1.715e+01\n",
      "Epoch 655, Loss: 1160.4178466796875, Neurons: 11, Grad norm: 1.714e+01\n",
      "Epoch 656, Loss: 1160.2926025390625, Neurons: 11, Grad norm: 1.713e+01\n",
      "Epoch 657, Loss: 1160.1671142578125, Neurons: 11, Grad norm: 1.713e+01\n",
      "Epoch 658, Loss: 1160.0416259765625, Neurons: 11, Grad norm: 1.712e+01\n",
      "Epoch 659, Loss: 1159.9161376953125, Neurons: 11, Grad norm: 1.712e+01\n",
      "Epoch 660, Loss: 1159.79052734375, Neurons: 11, Grad norm: 1.711e+01\n",
      "Epoch 661, Loss: 1159.6649169921875, Neurons: 11, Grad norm: 1.710e+01\n",
      "Epoch 662, Loss: 1159.5394287109375, Neurons: 11, Grad norm: 1.710e+01\n",
      "Epoch 663, Loss: 1159.41357421875, Neurons: 11, Grad norm: 1.709e+01\n",
      "Epoch 664, Loss: 1159.2879638671875, Neurons: 11, Grad norm: 1.709e+01\n",
      "Epoch 665, Loss: 1159.1622314453125, Neurons: 11, Grad norm: 1.708e+01\n",
      "Epoch 666, Loss: 1159.036376953125, Neurons: 11, Grad norm: 1.708e+01\n",
      "Epoch 667, Loss: 1158.9105224609375, Neurons: 11, Grad norm: 1.707e+01\n",
      "Epoch 668, Loss: 1158.7845458984375, Neurons: 11, Grad norm: 1.706e+01\n",
      "Epoch 669, Loss: 1158.6588134765625, Neurons: 11, Grad norm: 1.706e+01\n",
      "Epoch 670, Loss: 1158.53271484375, Neurons: 11, Grad norm: 1.705e+01\n",
      "Epoch 671, Loss: 1158.40673828125, Neurons: 11, Grad norm: 1.705e+01\n",
      "Epoch 672, Loss: 1158.2806396484375, Neurons: 11, Grad norm: 1.704e+01\n",
      "Epoch 673, Loss: 1158.154541015625, Neurons: 11, Grad norm: 1.704e+01\n",
      "Epoch 674, Loss: 1158.0283203125, Neurons: 11, Grad norm: 1.703e+01\n",
      "Epoch 675, Loss: 1157.9022216796875, Neurons: 11, Grad norm: 1.702e+01\n",
      "Epoch 676, Loss: 1157.7760009765625, Neurons: 11, Grad norm: 1.702e+01\n",
      "Epoch 677, Loss: 1157.6497802734375, Neurons: 11, Grad norm: 1.701e+01\n",
      "Epoch 678, Loss: 1157.5234375, Neurons: 11, Grad norm: 1.701e+01\n",
      "Epoch 679, Loss: 1157.39697265625, Neurons: 11, Grad norm: 1.700e+01\n",
      "Epoch 680, Loss: 1157.270751953125, Neurons: 11, Grad norm: 1.700e+01\n",
      "Epoch 681, Loss: 1157.1441650390625, Neurons: 11, Grad norm: 1.699e+01\n",
      "Epoch 682, Loss: 1157.017822265625, Neurons: 11, Grad norm: 1.699e+01\n",
      "Epoch 683, Loss: 1156.8912353515625, Neurons: 11, Grad norm: 1.698e+01\n",
      "Epoch 684, Loss: 1156.7647705078125, Neurons: 11, Grad norm: 1.697e+01\n",
      "Epoch 685, Loss: 1156.6380615234375, Neurons: 11, Grad norm: 1.697e+01\n",
      "Epoch 686, Loss: 1156.511474609375, Neurons: 11, Grad norm: 1.696e+01\n",
      "Epoch 687, Loss: 1156.384765625, Neurons: 11, Grad norm: 1.696e+01\n",
      "Epoch 688, Loss: 1156.258056640625, Neurons: 11, Grad norm: 1.695e+01\n",
      "Epoch 689, Loss: 1156.1312255859375, Neurons: 11, Grad norm: 1.695e+01\n",
      "Epoch 690, Loss: 1156.0045166015625, Neurons: 11, Grad norm: 1.694e+01\n",
      "Epoch 691, Loss: 1155.877685546875, Neurons: 11, Grad norm: 1.693e+01\n",
      "Epoch 692, Loss: 1155.750732421875, Neurons: 11, Grad norm: 1.693e+01\n",
      "Epoch 693, Loss: 1155.6240234375, Neurons: 11, Grad norm: 1.692e+01\n",
      "Epoch 694, Loss: 1155.496826171875, Neurons: 11, Grad norm: 1.692e+01\n",
      "Epoch 695, Loss: 1155.3699951171875, Neurons: 11, Grad norm: 1.691e+01\n",
      "Epoch 696, Loss: 1155.242919921875, Neurons: 11, Grad norm: 1.691e+01\n",
      "Epoch 697, Loss: 1155.11572265625, Neurons: 11, Grad norm: 1.690e+01\n",
      "Epoch 698, Loss: 1154.98876953125, Neurons: 11, Grad norm: 1.689e+01\n",
      "Epoch 699, Loss: 1154.861572265625, Neurons: 11, Grad norm: 1.689e+01\n",
      "Epoch 699, Test loss: 1176.6239013671875\n",
      "Epoch 700, Loss: 1154.734375, Neurons: 11, Grad norm: 1.688e+01\n",
      "Epoch 701, Loss: 1154.607177734375, Neurons: 11, Grad norm: 1.688e+01\n",
      "Epoch 702, Loss: 1154.47998046875, Neurons: 11, Grad norm: 1.687e+01\n",
      "Epoch 703, Loss: 1154.3526611328125, Neurons: 11, Grad norm: 1.687e+01\n",
      "Epoch 704, Loss: 1154.225341796875, Neurons: 11, Grad norm: 1.686e+01\n",
      "Epoch 705, Loss: 1154.0980224609375, Neurons: 11, Grad norm: 1.685e+01\n",
      "Epoch 706, Loss: 1153.970458984375, Neurons: 11, Grad norm: 1.685e+01\n",
      "Epoch 707, Loss: 1153.843017578125, Neurons: 11, Grad norm: 1.684e+01\n",
      "Epoch 708, Loss: 1153.715576171875, Neurons: 11, Grad norm: 1.684e+01\n",
      "Epoch 709, Loss: 1153.588134765625, Neurons: 11, Grad norm: 1.683e+01\n",
      "Epoch 710, Loss: 1153.46044921875, Neurons: 11, Grad norm: 1.683e+01\n",
      "Epoch 711, Loss: 1153.3330078125, Neurons: 11, Grad norm: 1.682e+01\n",
      "Epoch 712, Loss: 1153.205322265625, Neurons: 11, Grad norm: 1.682e+01\n",
      "Epoch 713, Loss: 1153.07763671875, Neurons: 11, Grad norm: 1.681e+01\n",
      "Epoch 714, Loss: 1152.949951171875, Neurons: 11, Grad norm: 1.680e+01\n",
      "Epoch 715, Loss: 1152.822265625, Neurons: 11, Grad norm: 1.680e+01\n",
      "Epoch 716, Loss: 1152.694580078125, Neurons: 11, Grad norm: 1.679e+01\n",
      "Epoch 717, Loss: 1152.566650390625, Neurons: 11, Grad norm: 1.679e+01\n",
      "Epoch 718, Loss: 1152.43896484375, Neurons: 11, Grad norm: 1.678e+01\n",
      "Epoch 719, Loss: 1152.3109130859375, Neurons: 11, Grad norm: 1.678e+01\n",
      "Epoch 720, Loss: 1152.1832275390625, Neurons: 11, Grad norm: 1.677e+01\n",
      "Epoch 721, Loss: 1152.05517578125, Neurons: 11, Grad norm: 1.676e+01\n",
      "Epoch 722, Loss: 1151.9271240234375, Neurons: 11, Grad norm: 1.676e+01\n",
      "Epoch 723, Loss: 1151.7991943359375, Neurons: 11, Grad norm: 1.675e+01\n",
      "Epoch 724, Loss: 1151.6712646484375, Neurons: 11, Grad norm: 1.675e+01\n",
      "Epoch 725, Loss: 1151.543212890625, Neurons: 11, Grad norm: 1.674e+01\n",
      "Epoch 726, Loss: 1151.4150390625, Neurons: 11, Grad norm: 1.673e+01\n",
      "Epoch 727, Loss: 1151.2869873046875, Neurons: 11, Grad norm: 1.673e+01\n",
      "Epoch 728, Loss: 1151.1588134765625, Neurons: 11, Grad norm: 1.672e+01\n",
      "Epoch 729, Loss: 1151.030517578125, Neurons: 11, Grad norm: 1.672e+01\n",
      "Epoch 730, Loss: 1150.90234375, Neurons: 11, Grad norm: 1.671e+01\n",
      "Epoch 731, Loss: 1150.7740478515625, Neurons: 11, Grad norm: 1.671e+01\n",
      "Epoch 732, Loss: 1150.6458740234375, Neurons: 11, Grad norm: 1.670e+01\n",
      "Epoch 733, Loss: 1150.517578125, Neurons: 11, Grad norm: 1.669e+01\n",
      "Epoch 734, Loss: 1150.38916015625, Neurons: 11, Grad norm: 1.669e+01\n",
      "Epoch 735, Loss: 1150.2607421875, Neurons: 11, Grad norm: 1.668e+01\n",
      "Epoch 736, Loss: 1150.13232421875, Neurons: 11, Grad norm: 1.668e+01\n",
      "Epoch 737, Loss: 1150.0040283203125, Neurons: 11, Grad norm: 1.667e+01\n",
      "Epoch 738, Loss: 1149.8756103515625, Neurons: 11, Grad norm: 1.667e+01\n",
      "Epoch 739, Loss: 1149.7469482421875, Neurons: 11, Grad norm: 1.666e+01\n",
      "Epoch 740, Loss: 1149.6185302734375, Neurons: 11, Grad norm: 1.665e+01\n",
      "Epoch 741, Loss: 1149.489990234375, Neurons: 11, Grad norm: 1.665e+01\n",
      "Epoch 742, Loss: 1149.361328125, Neurons: 11, Grad norm: 1.664e+01\n",
      "Epoch 743, Loss: 1149.2327880859375, Neurons: 11, Grad norm: 1.664e+01\n",
      "Epoch 744, Loss: 1149.1041259765625, Neurons: 11, Grad norm: 1.663e+01\n",
      "Epoch 745, Loss: 1148.9754638671875, Neurons: 11, Grad norm: 1.662e+01\n",
      "Epoch 746, Loss: 1148.8468017578125, Neurons: 11, Grad norm: 1.662e+01\n",
      "Epoch 747, Loss: 1148.718017578125, Neurons: 11, Grad norm: 1.661e+01\n",
      "Epoch 748, Loss: 1148.58935546875, Neurons: 11, Grad norm: 1.661e+01\n",
      "Epoch 749, Loss: 1148.4605712890625, Neurons: 11, Grad norm: 1.660e+01\n",
      "Epoch 749, Test loss: 1169.9840087890625\n",
      "Epoch 750, Loss: 1148.331787109375, Neurons: 11, Grad norm: 1.659e+01\n",
      "Epoch 751, Loss: 1148.2030029296875, Neurons: 11, Grad norm: 1.659e+01\n",
      "Epoch 752, Loss: 1148.0740966796875, Neurons: 11, Grad norm: 1.658e+01\n",
      "Epoch 753, Loss: 1147.9451904296875, Neurons: 11, Grad norm: 1.658e+01\n",
      "Epoch 754, Loss: 1147.81640625, Neurons: 11, Grad norm: 1.657e+01\n",
      "Epoch 755, Loss: 1147.6873779296875, Neurons: 11, Grad norm: 1.656e+01\n",
      "Epoch 756, Loss: 1147.558349609375, Neurons: 11, Grad norm: 1.656e+01\n",
      "Epoch 757, Loss: 1147.4295654296875, Neurons: 11, Grad norm: 1.655e+01\n",
      "Epoch 758, Loss: 1147.3004150390625, Neurons: 11, Grad norm: 1.655e+01\n",
      "Epoch 759, Loss: 1147.1715087890625, Neurons: 11, Grad norm: 1.654e+01\n",
      "Epoch 760, Loss: 1147.0423583984375, Neurons: 11, Grad norm: 1.654e+01\n",
      "Epoch 761, Loss: 1146.913330078125, Neurons: 11, Grad norm: 1.653e+01\n",
      "Epoch 762, Loss: 1146.7843017578125, Neurons: 11, Grad norm: 1.652e+01\n",
      "Epoch 763, Loss: 1146.6551513671875, Neurons: 11, Grad norm: 1.652e+01\n",
      "Epoch 764, Loss: 1146.5260009765625, Neurons: 11, Grad norm: 1.651e+01\n",
      "Epoch 765, Loss: 1146.3968505859375, Neurons: 11, Grad norm: 1.650e+01\n",
      "Epoch 766, Loss: 1146.2677001953125, Neurons: 11, Grad norm: 1.650e+01\n",
      "Epoch 767, Loss: 1146.138427734375, Neurons: 11, Grad norm: 1.649e+01\n",
      "Epoch 768, Loss: 1146.00927734375, Neurons: 11, Grad norm: 1.649e+01\n",
      "Epoch 769, Loss: 1145.8800048828125, Neurons: 11, Grad norm: 1.648e+01\n",
      "Epoch 770, Loss: 1145.7506103515625, Neurons: 11, Grad norm: 1.647e+01\n",
      "Epoch 771, Loss: 1145.621337890625, Neurons: 11, Grad norm: 1.647e+01\n",
      "Epoch 772, Loss: 1145.4920654296875, Neurons: 11, Grad norm: 1.646e+01\n",
      "Epoch 773, Loss: 1145.36279296875, Neurons: 11, Grad norm: 1.646e+01\n",
      "Epoch 774, Loss: 1145.2333984375, Neurons: 11, Grad norm: 1.645e+01\n",
      "Epoch 775, Loss: 1145.10400390625, Neurons: 11, Grad norm: 1.644e+01\n",
      "Epoch 776, Loss: 1144.974609375, Neurons: 11, Grad norm: 1.644e+01\n",
      "Epoch 777, Loss: 1144.84521484375, Neurons: 11, Grad norm: 1.643e+01\n",
      "Epoch 778, Loss: 1144.7156982421875, Neurons: 11, Grad norm: 1.643e+01\n",
      "Epoch 779, Loss: 1144.586181640625, Neurons: 11, Grad norm: 1.642e+01\n",
      "Epoch 780, Loss: 1144.4566650390625, Neurons: 11, Grad norm: 1.641e+01\n",
      "Epoch 781, Loss: 1144.3271484375, Neurons: 11, Grad norm: 1.641e+01\n",
      "Epoch 782, Loss: 1144.1976318359375, Neurons: 11, Grad norm: 1.640e+01\n",
      "Epoch 783, Loss: 1144.068115234375, Neurons: 11, Grad norm: 1.640e+01\n",
      "Epoch 784, Loss: 1143.9385986328125, Neurons: 11, Grad norm: 1.639e+01\n",
      "Epoch 785, Loss: 1143.8089599609375, Neurons: 11, Grad norm: 1.638e+01\n",
      "Epoch 786, Loss: 1143.6793212890625, Neurons: 11, Grad norm: 1.638e+01\n",
      "Epoch 787, Loss: 1143.5498046875, Neurons: 11, Grad norm: 1.637e+01\n",
      "Epoch 788, Loss: 1143.420166015625, Neurons: 11, Grad norm: 1.636e+01\n",
      "Epoch 789, Loss: 1143.29052734375, Neurons: 11, Grad norm: 1.636e+01\n",
      "Epoch 790, Loss: 1143.1607666015625, Neurons: 11, Grad norm: 1.635e+01\n",
      "Epoch 791, Loss: 1143.0311279296875, Neurons: 11, Grad norm: 1.635e+01\n",
      "Epoch 792, Loss: 1142.9014892578125, Neurons: 11, Grad norm: 1.634e+01\n",
      "Epoch 793, Loss: 1142.771728515625, Neurons: 11, Grad norm: 1.633e+01\n",
      "Epoch 794, Loss: 1142.6419677734375, Neurons: 11, Grad norm: 1.633e+01\n",
      "Epoch 795, Loss: 1142.51220703125, Neurons: 11, Grad norm: 1.632e+01\n",
      "Epoch 796, Loss: 1142.3824462890625, Neurons: 11, Grad norm: 1.632e+01\n",
      "Epoch 797, Loss: 1142.252685546875, Neurons: 11, Grad norm: 1.631e+01\n",
      "Epoch 798, Loss: 1142.1229248046875, Neurons: 11, Grad norm: 1.630e+01\n",
      "Epoch 799, Loss: 1141.9931640625, Neurons: 11, Grad norm: 1.630e+01\n",
      "Epoch 799, Test loss: 1163.2740478515625\n",
      "Epoch 800, Loss: 1141.8634033203125, Neurons: 11, Grad norm: 1.629e+01\n",
      "Epoch 801, Loss: 1141.7333984375, Neurons: 11, Grad norm: 1.628e+01\n",
      "Epoch 802, Loss: 1141.603515625, Neurons: 11, Grad norm: 1.628e+01\n",
      "Epoch 803, Loss: 1141.4736328125, Neurons: 11, Grad norm: 1.627e+01\n",
      "Epoch 804, Loss: 1141.34375, Neurons: 11, Grad norm: 1.626e+01\n",
      "Epoch 805, Loss: 1141.2138671875, Neurons: 11, Grad norm: 1.626e+01\n",
      "Epoch 806, Loss: 1141.083984375, Neurons: 11, Grad norm: 1.625e+01\n",
      "Epoch 807, Loss: 1140.9541015625, Neurons: 11, Grad norm: 1.625e+01\n",
      "Epoch 808, Loss: 1140.8240966796875, Neurons: 11, Grad norm: 1.624e+01\n",
      "Epoch 809, Loss: 1140.6942138671875, Neurons: 11, Grad norm: 1.623e+01\n",
      "Epoch 810, Loss: 1140.564208984375, Neurons: 11, Grad norm: 1.623e+01\n",
      "Epoch 811, Loss: 1140.434326171875, Neurons: 11, Grad norm: 1.622e+01\n",
      "Epoch 812, Loss: 1140.30419921875, Neurons: 11, Grad norm: 1.621e+01\n",
      "Epoch 813, Loss: 1140.1741943359375, Neurons: 11, Grad norm: 1.621e+01\n",
      "Epoch 814, Loss: 1140.0443115234375, Neurons: 11, Grad norm: 1.620e+01\n",
      "Epoch 815, Loss: 1139.9141845703125, Neurons: 11, Grad norm: 1.620e+01\n",
      "Epoch 816, Loss: 1139.7841796875, Neurons: 11, Grad norm: 1.619e+01\n",
      "Epoch 817, Loss: 1139.6541748046875, Neurons: 11, Grad norm: 1.618e+01\n",
      "Epoch 818, Loss: 1139.52392578125, Neurons: 11, Grad norm: 1.618e+01\n",
      "Epoch 819, Loss: 1139.39404296875, Neurons: 11, Grad norm: 1.617e+01\n",
      "Epoch 820, Loss: 1139.263916015625, Neurons: 11, Grad norm: 1.616e+01\n",
      "Epoch 821, Loss: 1139.1337890625, Neurons: 11, Grad norm: 1.616e+01\n",
      "Epoch 822, Loss: 1139.0037841796875, Neurons: 11, Grad norm: 1.615e+01\n",
      "Epoch 823, Loss: 1138.87353515625, Neurons: 11, Grad norm: 1.614e+01\n",
      "Epoch 824, Loss: 1138.7435302734375, Neurons: 11, Grad norm: 1.614e+01\n",
      "Epoch 825, Loss: 1138.6134033203125, Neurons: 11, Grad norm: 1.613e+01\n",
      "Epoch 826, Loss: 1138.4832763671875, Neurons: 11, Grad norm: 1.613e+01\n",
      "Epoch 827, Loss: 1138.3531494140625, Neurons: 11, Grad norm: 1.612e+01\n",
      "Epoch 828, Loss: 1138.222900390625, Neurons: 11, Grad norm: 1.611e+01\n",
      "Epoch 829, Loss: 1138.0927734375, Neurons: 11, Grad norm: 1.611e+01\n",
      "Epoch 830, Loss: 1137.9625244140625, Neurons: 11, Grad norm: 1.610e+01\n",
      "Epoch 831, Loss: 1137.8323974609375, Neurons: 11, Grad norm: 1.609e+01\n",
      "Epoch 832, Loss: 1137.7022705078125, Neurons: 11, Grad norm: 1.609e+01\n",
      "Epoch 833, Loss: 1137.572021484375, Neurons: 11, Grad norm: 1.608e+01\n",
      "Epoch 834, Loss: 1137.44189453125, Neurons: 11, Grad norm: 1.607e+01\n",
      "Epoch 835, Loss: 1137.3115234375, Neurons: 11, Grad norm: 1.607e+01\n",
      "Epoch 836, Loss: 1137.181396484375, Neurons: 11, Grad norm: 1.606e+01\n",
      "Epoch 837, Loss: 1137.0511474609375, Neurons: 11, Grad norm: 1.605e+01\n",
      "Epoch 838, Loss: 1136.9210205078125, Neurons: 11, Grad norm: 1.605e+01\n",
      "Epoch 839, Loss: 1136.790771484375, Neurons: 11, Grad norm: 1.604e+01\n",
      "Epoch 840, Loss: 1136.6605224609375, Neurons: 11, Grad norm: 1.603e+01\n",
      "Epoch 841, Loss: 1136.5302734375, Neurons: 11, Grad norm: 1.603e+01\n",
      "Epoch 842, Loss: 1136.4000244140625, Neurons: 11, Grad norm: 1.602e+01\n",
      "Epoch 843, Loss: 1136.269775390625, Neurons: 11, Grad norm: 1.601e+01\n",
      "Epoch 844, Loss: 1136.1395263671875, Neurons: 11, Grad norm: 1.601e+01\n",
      "Epoch 845, Loss: 1136.00927734375, Neurons: 11, Grad norm: 1.600e+01\n",
      "Epoch 846, Loss: 1135.8790283203125, Neurons: 11, Grad norm: 1.600e+01\n",
      "Epoch 847, Loss: 1135.748779296875, Neurons: 11, Grad norm: 1.599e+01\n",
      "Epoch 848, Loss: 1135.6185302734375, Neurons: 11, Grad norm: 1.598e+01\n",
      "Epoch 849, Loss: 1135.4881591796875, Neurons: 11, Grad norm: 1.598e+01\n",
      "Epoch 849, Test loss: 1156.5233154296875\n",
      "Epoch 850, Loss: 1135.35791015625, Neurons: 11, Grad norm: 1.597e+01\n",
      "Epoch 851, Loss: 1135.2275390625, Neurons: 11, Grad norm: 1.596e+01\n",
      "Epoch 852, Loss: 1135.097412109375, Neurons: 11, Grad norm: 1.596e+01\n",
      "Epoch 853, Loss: 1134.967041015625, Neurons: 11, Grad norm: 1.595e+01\n",
      "Epoch 854, Loss: 1134.8367919921875, Neurons: 11, Grad norm: 1.594e+01\n",
      "Epoch 855, Loss: 1134.7064208984375, Neurons: 11, Grad norm: 1.594e+01\n",
      "Epoch 856, Loss: 1134.576171875, Neurons: 11, Grad norm: 1.593e+01\n",
      "Epoch 857, Loss: 1134.44580078125, Neurons: 11, Grad norm: 1.592e+01\n",
      "Epoch 858, Loss: 1134.3155517578125, Neurons: 11, Grad norm: 1.592e+01\n",
      "Epoch 859, Loss: 1134.185302734375, Neurons: 11, Grad norm: 1.591e+01\n",
      "Epoch 860, Loss: 1134.054931640625, Neurons: 11, Grad norm: 1.590e+01\n",
      "Epoch 861, Loss: 1133.924560546875, Neurons: 11, Grad norm: 1.590e+01\n",
      "Epoch 862, Loss: 1133.7943115234375, Neurons: 11, Grad norm: 1.589e+01\n",
      "Epoch 863, Loss: 1133.6640625, Neurons: 11, Grad norm: 1.588e+01\n",
      "Epoch 864, Loss: 1133.53369140625, Neurons: 11, Grad norm: 1.588e+01\n",
      "Epoch 865, Loss: 1133.4033203125, Neurons: 11, Grad norm: 1.587e+01\n",
      "Epoch 866, Loss: 1133.273193359375, Neurons: 11, Grad norm: 1.586e+01\n",
      "Epoch 867, Loss: 1133.142822265625, Neurons: 11, Grad norm: 1.586e+01\n",
      "Epoch 868, Loss: 1133.0125732421875, Neurons: 11, Grad norm: 1.585e+01\n",
      "Epoch 869, Loss: 1132.8822021484375, Neurons: 11, Grad norm: 1.584e+01\n",
      "Epoch 870, Loss: 1132.7518310546875, Neurons: 11, Grad norm: 1.584e+01\n",
      "Epoch 871, Loss: 1132.62158203125, Neurons: 11, Grad norm: 1.583e+01\n",
      "Epoch 872, Loss: 1132.4912109375, Neurons: 11, Grad norm: 1.582e+01\n",
      "Epoch 873, Loss: 1132.3609619140625, Neurons: 11, Grad norm: 1.582e+01\n",
      "Epoch 874, Loss: 1132.230712890625, Neurons: 11, Grad norm: 1.581e+01\n",
      "Epoch 875, Loss: 1132.100341796875, Neurons: 11, Grad norm: 1.580e+01\n",
      "Epoch 876, Loss: 1131.9700927734375, Neurons: 11, Grad norm: 1.580e+01\n",
      "Epoch 877, Loss: 1131.83984375, Neurons: 11, Grad norm: 1.579e+01\n",
      "Epoch 878, Loss: 1131.7095947265625, Neurons: 11, Grad norm: 1.578e+01\n",
      "Epoch 879, Loss: 1131.5792236328125, Neurons: 11, Grad norm: 1.578e+01\n",
      "Epoch 880, Loss: 1131.448974609375, Neurons: 11, Grad norm: 1.577e+01\n",
      "Epoch 881, Loss: 1131.3187255859375, Neurons: 11, Grad norm: 1.576e+01\n",
      "Epoch 882, Loss: 1131.1883544921875, Neurons: 11, Grad norm: 1.576e+01\n",
      "Epoch 883, Loss: 1131.05810546875, Neurons: 11, Grad norm: 1.575e+01\n",
      "Epoch 884, Loss: 1130.927734375, Neurons: 11, Grad norm: 1.574e+01\n",
      "Epoch 885, Loss: 1130.797607421875, Neurons: 11, Grad norm: 1.573e+01\n",
      "Epoch 886, Loss: 1130.6673583984375, Neurons: 11, Grad norm: 1.573e+01\n",
      "Epoch 887, Loss: 1130.5369873046875, Neurons: 11, Grad norm: 1.572e+01\n",
      "Epoch 888, Loss: 1130.40673828125, Neurons: 11, Grad norm: 1.571e+01\n",
      "Epoch 889, Loss: 1130.276611328125, Neurons: 11, Grad norm: 1.571e+01\n",
      "Epoch 890, Loss: 1130.146240234375, Neurons: 11, Grad norm: 1.570e+01\n",
      "Epoch 891, Loss: 1130.01611328125, Neurons: 11, Grad norm: 1.569e+01\n",
      "Epoch 892, Loss: 1129.8858642578125, Neurons: 11, Grad norm: 1.569e+01\n",
      "Epoch 893, Loss: 1129.755615234375, Neurons: 11, Grad norm: 1.568e+01\n",
      "Epoch 894, Loss: 1129.6253662109375, Neurons: 11, Grad norm: 1.567e+01\n",
      "Epoch 895, Loss: 1129.4951171875, Neurons: 11, Grad norm: 1.567e+01\n",
      "Epoch 896, Loss: 1129.364990234375, Neurons: 11, Grad norm: 1.566e+01\n",
      "Epoch 897, Loss: 1129.2347412109375, Neurons: 11, Grad norm: 1.565e+01\n",
      "Epoch 898, Loss: 1129.1046142578125, Neurons: 11, Grad norm: 1.565e+01\n",
      "Epoch 899, Loss: 1128.974365234375, Neurons: 11, Grad norm: 1.564e+01\n",
      "Epoch 899, Test loss: 1149.760986328125\n",
      "Epoch 900, Loss: 1128.8441162109375, Neurons: 11, Grad norm: 1.563e+01\n",
      "Epoch 901, Loss: 1128.714111328125, Neurons: 11, Grad norm: 1.563e+01\n",
      "Epoch 902, Loss: 1128.583984375, Neurons: 11, Grad norm: 1.562e+01\n",
      "Epoch 903, Loss: 1128.4537353515625, Neurons: 11, Grad norm: 1.561e+01\n",
      "Epoch 904, Loss: 1128.3236083984375, Neurons: 11, Grad norm: 1.561e+01\n",
      "Epoch 905, Loss: 1128.193603515625, Neurons: 11, Grad norm: 1.560e+01\n",
      "Epoch 906, Loss: 1128.0633544921875, Neurons: 11, Grad norm: 1.559e+01\n",
      "Epoch 907, Loss: 1127.9332275390625, Neurons: 11, Grad norm: 1.558e+01\n",
      "Epoch 908, Loss: 1127.80322265625, Neurons: 11, Grad norm: 1.558e+01\n",
      "Epoch 909, Loss: 1127.6729736328125, Neurons: 11, Grad norm: 1.557e+01\n",
      "Epoch 910, Loss: 1127.54296875, Neurons: 11, Grad norm: 1.556e+01\n",
      "Epoch 911, Loss: 1127.412841796875, Neurons: 11, Grad norm: 1.556e+01\n",
      "Epoch 912, Loss: 1127.28271484375, Neurons: 11, Grad norm: 1.555e+01\n",
      "Epoch 913, Loss: 1127.15283203125, Neurons: 11, Grad norm: 1.554e+01\n",
      "Epoch 914, Loss: 1127.022705078125, Neurons: 11, Grad norm: 1.554e+01\n",
      "Epoch 915, Loss: 1126.892578125, Neurons: 11, Grad norm: 1.553e+01\n",
      "Epoch 916, Loss: 1126.7625732421875, Neurons: 11, Grad norm: 1.552e+01\n",
      "Epoch 917, Loss: 1126.632568359375, Neurons: 11, Grad norm: 1.552e+01\n",
      "Epoch 918, Loss: 1126.5025634765625, Neurons: 11, Grad norm: 1.551e+01\n",
      "Epoch 919, Loss: 1126.37255859375, Neurons: 11, Grad norm: 1.550e+01\n",
      "Epoch 920, Loss: 1126.2425537109375, Neurons: 11, Grad norm: 1.549e+01\n",
      "Epoch 921, Loss: 1126.112548828125, Neurons: 11, Grad norm: 1.549e+01\n",
      "Epoch 922, Loss: 1125.982666015625, Neurons: 11, Grad norm: 1.548e+01\n",
      "Epoch 923, Loss: 1125.852783203125, Neurons: 11, Grad norm: 1.547e+01\n",
      "Epoch 924, Loss: 1125.7227783203125, Neurons: 11, Grad norm: 1.547e+01\n",
      "Epoch 925, Loss: 1125.5928955078125, Neurons: 11, Grad norm: 1.546e+01\n",
      "Epoch 926, Loss: 1125.462890625, Neurons: 11, Grad norm: 1.545e+01\n",
      "Epoch 927, Loss: 1125.3330078125, Neurons: 11, Grad norm: 1.545e+01\n",
      "Epoch 928, Loss: 1125.203125, Neurons: 11, Grad norm: 1.544e+01\n",
      "Epoch 929, Loss: 1125.0733642578125, Neurons: 11, Grad norm: 1.543e+01\n",
      "Epoch 930, Loss: 1124.943359375, Neurons: 11, Grad norm: 1.542e+01\n",
      "Epoch 931, Loss: 1124.8135986328125, Neurons: 11, Grad norm: 1.542e+01\n",
      "Epoch 932, Loss: 1124.6837158203125, Neurons: 11, Grad norm: 1.541e+01\n",
      "Epoch 933, Loss: 1124.553955078125, Neurons: 11, Grad norm: 1.540e+01\n",
      "Epoch 934, Loss: 1124.4241943359375, Neurons: 11, Grad norm: 1.540e+01\n",
      "Epoch 935, Loss: 1124.2943115234375, Neurons: 11, Grad norm: 1.539e+01\n",
      "Epoch 936, Loss: 1124.16455078125, Neurons: 11, Grad norm: 1.538e+01\n",
      "Epoch 937, Loss: 1124.034912109375, Neurons: 11, Grad norm: 1.538e+01\n",
      "Epoch 938, Loss: 1123.905029296875, Neurons: 11, Grad norm: 1.537e+01\n",
      "Epoch 939, Loss: 1123.775390625, Neurons: 11, Grad norm: 1.536e+01\n",
      "Epoch 940, Loss: 1123.6456298828125, Neurons: 11, Grad norm: 1.535e+01\n",
      "Epoch 941, Loss: 1123.5159912109375, Neurons: 11, Grad norm: 1.535e+01\n",
      "Epoch 942, Loss: 1123.38623046875, Neurons: 11, Grad norm: 1.534e+01\n",
      "Epoch 943, Loss: 1123.256591796875, Neurons: 11, Grad norm: 1.533e+01\n",
      "Epoch 944, Loss: 1123.126953125, Neurons: 11, Grad norm: 1.533e+01\n",
      "Epoch 945, Loss: 1122.997314453125, Neurons: 11, Grad norm: 1.532e+01\n",
      "Epoch 946, Loss: 1122.8675537109375, Neurons: 11, Grad norm: 1.531e+01\n",
      "Epoch 947, Loss: 1122.7381591796875, Neurons: 11, Grad norm: 1.531e+01\n",
      "Epoch 948, Loss: 1122.6085205078125, Neurons: 11, Grad norm: 1.531e+01\n",
      "Epoch 949, Loss: 1122.47900390625, Neurons: 11, Grad norm: 1.530e+01\n",
      "Epoch 949, Test loss: 1143.0150146484375\n",
      "Epoch 950, Loss: 1122.349365234375, Neurons: 11, Grad norm: 1.530e+01\n",
      "Epoch 951, Loss: 1122.2198486328125, Neurons: 11, Grad norm: 1.529e+01\n",
      "Epoch 952, Loss: 1122.09033203125, Neurons: 11, Grad norm: 1.528e+01\n",
      "Epoch 953, Loss: 1121.9608154296875, Neurons: 11, Grad norm: 1.526e+01\n",
      "Epoch 954, Loss: 1121.8314208984375, Neurons: 11, Grad norm: 1.526e+01\n",
      "Epoch 955, Loss: 1121.701904296875, Neurons: 11, Grad norm: 1.525e+01\n",
      "Epoch 956, Loss: 1121.5723876953125, Neurons: 11, Grad norm: 1.525e+01\n",
      "Epoch 957, Loss: 1121.443115234375, Neurons: 11, Grad norm: 1.524e+01\n",
      "Epoch 958, Loss: 1121.3135986328125, Neurons: 11, Grad norm: 1.523e+01\n",
      "Epoch 959, Loss: 1121.184326171875, Neurons: 11, Grad norm: 1.522e+01\n",
      "Epoch 960, Loss: 1121.054931640625, Neurons: 11, Grad norm: 1.521e+01\n",
      "Epoch 961, Loss: 1120.925537109375, Neurons: 11, Grad norm: 1.521e+01\n",
      "Epoch 962, Loss: 1120.7962646484375, Neurons: 11, Grad norm: 1.520e+01\n",
      "Epoch 963, Loss: 1120.6669921875, Neurons: 11, Grad norm: 1.520e+01\n",
      "Epoch 964, Loss: 1120.5377197265625, Neurons: 11, Grad norm: 1.519e+01\n",
      "Epoch 965, Loss: 1120.4083251953125, Neurons: 11, Grad norm: 1.518e+01\n",
      "Epoch 966, Loss: 1120.2791748046875, Neurons: 11, Grad norm: 1.517e+01\n",
      "Epoch 967, Loss: 1120.14990234375, Neurons: 11, Grad norm: 1.516e+01\n",
      "Epoch 968, Loss: 1120.020751953125, Neurons: 11, Grad norm: 1.515e+01\n",
      "Epoch 969, Loss: 1119.8916015625, Neurons: 11, Grad norm: 1.515e+01\n",
      "Epoch 970, Loss: 1119.7623291015625, Neurons: 11, Grad norm: 1.514e+01\n",
      "Epoch 971, Loss: 1119.6331787109375, Neurons: 11, Grad norm: 1.514e+01\n",
      "Epoch 972, Loss: 1119.5040283203125, Neurons: 11, Grad norm: 1.513e+01\n",
      "Epoch 973, Loss: 1119.375, Neurons: 11, Grad norm: 1.512e+01\n",
      "Epoch 974, Loss: 1119.2459716796875, Neurons: 11, Grad norm: 1.511e+01\n",
      "Epoch 975, Loss: 1119.116943359375, Neurons: 11, Grad norm: 1.511e+01\n",
      "Epoch 976, Loss: 1118.9879150390625, Neurons: 11, Grad norm: 1.510e+01\n",
      "Epoch 977, Loss: 1118.8587646484375, Neurons: 11, Grad norm: 1.509e+01\n",
      "Epoch 978, Loss: 1118.7298583984375, Neurons: 11, Grad norm: 1.508e+01\n",
      "Epoch 979, Loss: 1118.6009521484375, Neurons: 11, Grad norm: 1.508e+01\n",
      "Epoch 980, Loss: 1118.471923828125, Neurons: 11, Grad norm: 1.507e+01\n",
      "Epoch 981, Loss: 1118.343017578125, Neurons: 11, Grad norm: 1.506e+01\n",
      "Epoch 982, Loss: 1118.214111328125, Neurons: 11, Grad norm: 1.506e+01\n",
      "Epoch 983, Loss: 1118.0853271484375, Neurons: 11, Grad norm: 1.505e+01\n",
      "Epoch 984, Loss: 1117.9564208984375, Neurons: 11, Grad norm: 1.504e+01\n",
      "Epoch 985, Loss: 1117.8275146484375, Neurons: 11, Grad norm: 1.504e+01\n",
      "Epoch 986, Loss: 1117.6988525390625, Neurons: 11, Grad norm: 1.503e+01\n",
      "Epoch 987, Loss: 1117.5699462890625, Neurons: 11, Grad norm: 1.502e+01\n",
      "Epoch 988, Loss: 1117.44140625, Neurons: 11, Grad norm: 1.502e+01\n",
      "Epoch 989, Loss: 1117.3126220703125, Neurons: 11, Grad norm: 1.501e+01\n",
      "Epoch 990, Loss: 1117.1837158203125, Neurons: 11, Grad norm: 1.500e+01\n",
      "Epoch 991, Loss: 1117.0552978515625, Neurons: 11, Grad norm: 1.499e+01\n",
      "Epoch 992, Loss: 1116.926513671875, Neurons: 11, Grad norm: 1.498e+01\n",
      "Epoch 993, Loss: 1116.7979736328125, Neurons: 11, Grad norm: 1.498e+01\n",
      "Epoch 994, Loss: 1116.6693115234375, Neurons: 11, Grad norm: 1.497e+01\n",
      "Epoch 995, Loss: 1116.540771484375, Neurons: 11, Grad norm: 1.496e+01\n",
      "Epoch 996, Loss: 1116.4122314453125, Neurons: 11, Grad norm: 1.496e+01\n",
      "Epoch 997, Loss: 1116.2838134765625, Neurons: 11, Grad norm: 1.495e+01\n",
      "Epoch 998, Loss: 1116.1551513671875, Neurons: 11, Grad norm: 1.494e+01\n",
      "Epoch 999, Loss: 1116.0267333984375, Neurons: 11, Grad norm: 1.494e+01\n",
      "Epoch 999, Test loss: 1136.3115234375\n",
      "Epoch 1000, Loss: 1115.8983154296875, Neurons: 11, Grad norm: 1.493e+01\n",
      "Epoch 1001, Loss: 1115.77001953125, Neurons: 11, Grad norm: 1.493e+01\n",
      "Epoch 1002, Loss: 1115.6416015625, Neurons: 11, Grad norm: 1.492e+01\n",
      "Epoch 1003, Loss: 1115.51318359375, Neurons: 11, Grad norm: 1.491e+01\n",
      "Epoch 1004, Loss: 1115.384765625, Neurons: 11, Grad norm: 1.490e+01\n",
      "Epoch 1005, Loss: 1115.2564697265625, Neurons: 11, Grad norm: 1.489e+01\n",
      "Epoch 1006, Loss: 1115.1282958984375, Neurons: 11, Grad norm: 1.488e+01\n",
      "Epoch 1007, Loss: 1115.0, Neurons: 11, Grad norm: 1.487e+01\n",
      "Epoch 1008, Loss: 1114.871826171875, Neurons: 11, Grad norm: 1.487e+01\n",
      "Epoch 1009, Loss: 1114.7435302734375, Neurons: 11, Grad norm: 1.486e+01\n",
      "Epoch 1010, Loss: 1114.6153564453125, Neurons: 11, Grad norm: 1.485e+01\n",
      "Epoch 1011, Loss: 1114.4873046875, Neurons: 11, Grad norm: 1.484e+01\n",
      "Epoch 1012, Loss: 1114.359130859375, Neurons: 11, Grad norm: 1.484e+01\n",
      "Epoch 1013, Loss: 1114.2310791015625, Neurons: 11, Grad norm: 1.483e+01\n",
      "Epoch 1014, Loss: 1114.10302734375, Neurons: 11, Grad norm: 1.483e+01\n",
      "Epoch 1015, Loss: 1113.9749755859375, Neurons: 11, Grad norm: 1.482e+01\n",
      "Epoch 1016, Loss: 1113.8470458984375, Neurons: 11, Grad norm: 1.482e+01\n",
      "Epoch 1017, Loss: 1113.718994140625, Neurons: 11, Grad norm: 1.482e+01\n",
      "Epoch 1018, Loss: 1113.5911865234375, Neurons: 11, Grad norm: 1.481e+01\n",
      "Epoch 1019, Loss: 1113.463134765625, Neurons: 11, Grad norm: 1.480e+01\n",
      "Epoch 1020, Loss: 1113.3353271484375, Neurons: 11, Grad norm: 1.479e+01\n",
      "Epoch 1021, Loss: 1113.20751953125, Neurons: 11, Grad norm: 1.478e+01\n",
      "Epoch 1022, Loss: 1113.0797119140625, Neurons: 11, Grad norm: 1.477e+01\n",
      "Epoch 1023, Loss: 1112.9520263671875, Neurons: 11, Grad norm: 1.476e+01\n",
      "Epoch 1024, Loss: 1112.82421875, Neurons: 11, Grad norm: 1.475e+01\n",
      "Epoch 1025, Loss: 1112.6964111328125, Neurons: 11, Grad norm: 1.474e+01\n",
      "Epoch 1026, Loss: 1112.5687255859375, Neurons: 11, Grad norm: 1.473e+01\n",
      "Epoch 1027, Loss: 1112.4410400390625, Neurons: 11, Grad norm: 1.473e+01\n",
      "Epoch 1028, Loss: 1112.3133544921875, Neurons: 11, Grad norm: 1.472e+01\n",
      "Epoch 1029, Loss: 1112.1859130859375, Neurons: 11, Grad norm: 1.471e+01\n",
      "Epoch 1030, Loss: 1112.0582275390625, Neurons: 11, Grad norm: 1.471e+01\n",
      "Epoch 1031, Loss: 1111.9307861328125, Neurons: 11, Grad norm: 1.470e+01\n",
      "Epoch 1032, Loss: 1111.80322265625, Neurons: 11, Grad norm: 1.470e+01\n",
      "Epoch 1033, Loss: 1111.6759033203125, Neurons: 11, Grad norm: 1.470e+01\n",
      "Epoch 1034, Loss: 1111.54833984375, Neurons: 11, Grad norm: 1.470e+01\n",
      "Epoch 1035, Loss: 1111.4210205078125, Neurons: 11, Grad norm: 1.469e+01\n",
      "Epoch 1036, Loss: 1111.2935791015625, Neurons: 11, Grad norm: 1.467e+01\n",
      "Epoch 1037, Loss: 1111.1661376953125, Neurons: 11, Grad norm: 1.466e+01\n",
      "Epoch 1038, Loss: 1111.0389404296875, Neurons: 11, Grad norm: 1.465e+01\n",
      "Epoch 1039, Loss: 1110.91162109375, Neurons: 11, Grad norm: 1.464e+01\n",
      "Epoch 1040, Loss: 1110.784423828125, Neurons: 11, Grad norm: 1.463e+01\n",
      "Epoch 1041, Loss: 1110.6572265625, Neurons: 11, Grad norm: 1.462e+01\n",
      "Epoch 1042, Loss: 1110.530029296875, Neurons: 11, Grad norm: 1.461e+01\n",
      "Epoch 1043, Loss: 1110.4029541015625, Neurons: 11, Grad norm: 1.461e+01\n",
      "Epoch 1044, Loss: 1110.2757568359375, Neurons: 11, Grad norm: 1.460e+01\n",
      "Epoch 1045, Loss: 1110.148681640625, Neurons: 11, Grad norm: 1.460e+01\n",
      "Epoch 1046, Loss: 1110.0216064453125, Neurons: 11, Grad norm: 1.460e+01\n",
      "Epoch 1047, Loss: 1109.89453125, Neurons: 11, Grad norm: 1.460e+01\n",
      "Epoch 1048, Loss: 1109.7677001953125, Neurons: 11, Grad norm: 1.460e+01\n",
      "Epoch 1049, Loss: 1109.6407470703125, Neurons: 11, Grad norm: 1.458e+01\n",
      "Epoch 1049, Test loss: 1129.673828125\n",
      "Epoch 1050, Loss: 1109.513916015625, Neurons: 11, Grad norm: 1.456e+01\n",
      "Epoch 1051, Loss: 1109.386962890625, Neurons: 11, Grad norm: 1.455e+01\n",
      "Epoch 1052, Loss: 1109.2601318359375, Neurons: 11, Grad norm: 1.454e+01\n",
      "Epoch 1053, Loss: 1109.1334228515625, Neurons: 11, Grad norm: 1.453e+01\n",
      "Epoch 1054, Loss: 1109.0067138671875, Neurons: 11, Grad norm: 1.453e+01\n",
      "Epoch 1055, Loss: 1108.8798828125, Neurons: 11, Grad norm: 1.453e+01\n",
      "Epoch 1056, Loss: 1108.753173828125, Neurons: 11, Grad norm: 1.454e+01\n",
      "Epoch 1057, Loss: 1108.6265869140625, Neurons: 11, Grad norm: 1.454e+01\n",
      "Epoch 1058, Loss: 1108.5, Neurons: 11, Grad norm: 1.450e+01\n",
      "Epoch 1059, Loss: 1108.3734130859375, Neurons: 11, Grad norm: 1.449e+01\n",
      "Epoch 1060, Loss: 1108.246826171875, Neurons: 11, Grad norm: 1.451e+01\n",
      "Epoch 1061, Loss: 1108.1202392578125, Neurons: 11, Grad norm: 1.453e+01\n",
      "Epoch 1062, Loss: 1107.9937744140625, Neurons: 11, Grad norm: 1.451e+01\n",
      "Epoch 1063, Loss: 1107.867431640625, Neurons: 11, Grad norm: 1.446e+01\n",
      "Epoch 1064, Loss: 1107.740966796875, Neurons: 11, Grad norm: 1.466e+01\n",
      "Epoch 1065, Loss: 1107.6146240234375, Neurons: 11, Grad norm: 1.444e+01\n",
      "Epoch 1066, Loss: 1107.4884033203125, Neurons: 11, Grad norm: 1.443e+01\n",
      "Epoch 1067, Loss: 1107.3621826171875, Neurons: 11, Grad norm: 1.443e+01\n",
      "Epoch 1068, Loss: 1107.2359619140625, Neurons: 11, Grad norm: 1.442e+01\n",
      "Epoch 1069, Loss: 1107.109619140625, Neurons: 11, Grad norm: 1.441e+01\n",
      "Epoch 1070, Loss: 1106.9835205078125, Neurons: 11, Grad norm: 1.441e+01\n",
      "Epoch 1071, Loss: 1106.857421875, Neurons: 11, Grad norm: 1.440e+01\n",
      "Epoch 1072, Loss: 1106.731201171875, Neurons: 11, Grad norm: 1.439e+01\n",
      "Epoch 1073, Loss: 1106.605224609375, Neurons: 11, Grad norm: 1.438e+01\n",
      "Epoch 1074, Loss: 1106.4791259765625, Neurons: 11, Grad norm: 1.438e+01\n",
      "Epoch 1075, Loss: 1106.3531494140625, Neurons: 11, Grad norm: 1.437e+01\n",
      "Epoch 1076, Loss: 1106.227294921875, Neurons: 11, Grad norm: 1.436e+01\n",
      "Epoch 1077, Loss: 1106.101318359375, Neurons: 11, Grad norm: 1.435e+01\n",
      "Epoch 1078, Loss: 1105.975341796875, Neurons: 11, Grad norm: 1.435e+01\n",
      "Epoch 1079, Loss: 1105.849609375, Neurons: 11, Grad norm: 1.434e+01\n",
      "Epoch 1080, Loss: 1105.7237548828125, Neurons: 11, Grad norm: 1.433e+01\n",
      "Epoch 1081, Loss: 1105.5980224609375, Neurons: 11, Grad norm: 1.432e+01\n",
      "Epoch 1082, Loss: 1105.472412109375, Neurons: 11, Grad norm: 1.431e+01\n",
      "Epoch 1083, Loss: 1105.3468017578125, Neurons: 11, Grad norm: 1.431e+01\n",
      "Epoch 1084, Loss: 1105.220947265625, Neurons: 11, Grad norm: 1.430e+01\n",
      "Epoch 1085, Loss: 1105.0953369140625, Neurons: 11, Grad norm: 1.429e+01\n",
      "Epoch 1086, Loss: 1104.9698486328125, Neurons: 11, Grad norm: 1.428e+01\n",
      "Epoch 1087, Loss: 1104.8443603515625, Neurons: 11, Grad norm: 1.428e+01\n",
      "Epoch 1088, Loss: 1104.7188720703125, Neurons: 11, Grad norm: 1.427e+01\n",
      "Epoch 1089, Loss: 1104.593505859375, Neurons: 11, Grad norm: 1.426e+01\n",
      "Epoch 1090, Loss: 1104.468017578125, Neurons: 11, Grad norm: 1.425e+01\n",
      "Epoch 1091, Loss: 1104.3427734375, Neurons: 11, Grad norm: 1.425e+01\n",
      "Epoch 1092, Loss: 1104.2174072265625, Neurons: 11, Grad norm: 1.424e+01\n",
      "Epoch 1093, Loss: 1104.0921630859375, Neurons: 11, Grad norm: 1.423e+01\n",
      "Epoch 1094, Loss: 1103.9669189453125, Neurons: 11, Grad norm: 1.422e+01\n",
      "Epoch 1095, Loss: 1103.841796875, Neurons: 11, Grad norm: 1.422e+01\n",
      "Epoch 1096, Loss: 1103.716552734375, Neurons: 11, Grad norm: 1.421e+01\n",
      "Epoch 1097, Loss: 1103.5914306640625, Neurons: 11, Grad norm: 1.420e+01\n",
      "Epoch 1098, Loss: 1103.4664306640625, Neurons: 11, Grad norm: 1.419e+01\n",
      "Epoch 1099, Loss: 1103.3414306640625, Neurons: 11, Grad norm: 1.419e+01\n",
      "Epoch 1099, Test loss: 1123.1231689453125\n",
      "Epoch 1100, Loss: 1103.2164306640625, Neurons: 11, Grad norm: 1.418e+01\n",
      "Epoch 1101, Loss: 1103.091552734375, Neurons: 11, Grad norm: 1.417e+01\n",
      "Epoch 1102, Loss: 1102.966552734375, Neurons: 11, Grad norm: 1.416e+01\n",
      "Epoch 1103, Loss: 1102.841796875, Neurons: 11, Grad norm: 1.416e+01\n",
      "Epoch 1104, Loss: 1102.7169189453125, Neurons: 11, Grad norm: 1.415e+01\n",
      "Epoch 1105, Loss: 1102.5921630859375, Neurons: 11, Grad norm: 1.414e+01\n",
      "Epoch 1106, Loss: 1102.4674072265625, Neurons: 11, Grad norm: 1.413e+01\n",
      "Epoch 1107, Loss: 1102.3426513671875, Neurons: 11, Grad norm: 1.413e+01\n",
      "Epoch 1108, Loss: 1102.2181396484375, Neurons: 11, Grad norm: 1.412e+01\n",
      "Epoch 1109, Loss: 1102.093505859375, Neurons: 11, Grad norm: 1.411e+01\n",
      "Epoch 1110, Loss: 1101.968994140625, Neurons: 11, Grad norm: 1.410e+01\n",
      "Epoch 1111, Loss: 1101.8443603515625, Neurons: 11, Grad norm: 1.410e+01\n",
      "Epoch 1112, Loss: 1101.719970703125, Neurons: 11, Grad norm: 1.409e+01\n",
      "Epoch 1113, Loss: 1101.595458984375, Neurons: 11, Grad norm: 1.408e+01\n",
      "Epoch 1114, Loss: 1101.47119140625, Neurons: 11, Grad norm: 1.407e+01\n",
      "Epoch 1115, Loss: 1101.3468017578125, Neurons: 11, Grad norm: 1.407e+01\n",
      "Epoch 1116, Loss: 1101.2225341796875, Neurons: 11, Grad norm: 1.406e+01\n",
      "Epoch 1117, Loss: 1101.0982666015625, Neurons: 11, Grad norm: 1.405e+01\n",
      "Epoch 1118, Loss: 1100.97412109375, Neurons: 11, Grad norm: 1.404e+01\n",
      "Epoch 1119, Loss: 1100.8497314453125, Neurons: 11, Grad norm: 1.404e+01\n",
      "Epoch 1120, Loss: 1100.725830078125, Neurons: 11, Grad norm: 1.403e+01\n",
      "Epoch 1121, Loss: 1100.601806640625, Neurons: 11, Grad norm: 1.402e+01\n",
      "Epoch 1122, Loss: 1100.477783203125, Neurons: 11, Grad norm: 1.401e+01\n",
      "Epoch 1123, Loss: 1100.3536376953125, Neurons: 11, Grad norm: 1.401e+01\n",
      "Epoch 1124, Loss: 1100.229736328125, Neurons: 11, Grad norm: 1.400e+01\n",
      "Epoch 1125, Loss: 1100.1058349609375, Neurons: 11, Grad norm: 1.399e+01\n",
      "Epoch 1126, Loss: 1099.98193359375, Neurons: 11, Grad norm: 1.398e+01\n",
      "Epoch 1127, Loss: 1099.858154296875, Neurons: 11, Grad norm: 1.397e+01\n",
      "Epoch 1128, Loss: 1099.734375, Neurons: 11, Grad norm: 1.397e+01\n",
      "Epoch 1129, Loss: 1099.6107177734375, Neurons: 11, Grad norm: 1.396e+01\n",
      "Epoch 1130, Loss: 1099.487060546875, Neurons: 11, Grad norm: 1.395e+01\n",
      "Epoch 1131, Loss: 1099.363525390625, Neurons: 11, Grad norm: 1.394e+01\n",
      "Epoch 1132, Loss: 1099.239990234375, Neurons: 11, Grad norm: 1.394e+01\n",
      "Epoch 1133, Loss: 1099.1163330078125, Neurons: 11, Grad norm: 1.393e+01\n",
      "Epoch 1134, Loss: 1098.992919921875, Neurons: 11, Grad norm: 1.392e+01\n",
      "Epoch 1135, Loss: 1098.869384765625, Neurons: 11, Grad norm: 1.391e+01\n",
      "Epoch 1136, Loss: 1098.7459716796875, Neurons: 11, Grad norm: 1.391e+01\n",
      "Epoch 1137, Loss: 1098.6226806640625, Neurons: 11, Grad norm: 1.390e+01\n",
      "Epoch 1138, Loss: 1098.4993896484375, Neurons: 11, Grad norm: 1.389e+01\n",
      "Epoch 1139, Loss: 1098.376220703125, Neurons: 11, Grad norm: 1.388e+01\n",
      "Epoch 1140, Loss: 1098.2529296875, Neurons: 11, Grad norm: 1.388e+01\n",
      "Epoch 1141, Loss: 1098.1297607421875, Neurons: 11, Grad norm: 1.387e+01\n",
      "Epoch 1142, Loss: 1098.0067138671875, Neurons: 11, Grad norm: 1.386e+01\n",
      "Epoch 1143, Loss: 1097.883544921875, Neurons: 11, Grad norm: 1.385e+01\n",
      "Epoch 1144, Loss: 1097.7606201171875, Neurons: 11, Grad norm: 1.385e+01\n",
      "Epoch 1145, Loss: 1097.6375732421875, Neurons: 11, Grad norm: 1.384e+01\n",
      "Epoch 1146, Loss: 1097.5146484375, Neurons: 11, Grad norm: 1.383e+01\n",
      "Epoch 1147, Loss: 1097.3917236328125, Neurons: 11, Grad norm: 1.382e+01\n",
      "Epoch 1148, Loss: 1097.2689208984375, Neurons: 11, Grad norm: 1.382e+01\n",
      "Epoch 1149, Loss: 1097.1461181640625, Neurons: 11, Grad norm: 1.381e+01\n",
      "Epoch 1149, Test loss: 1116.6781005859375\n",
      "Epoch 1150, Loss: 1097.0235595703125, Neurons: 11, Grad norm: 1.380e+01\n",
      "Epoch 1151, Loss: 1096.9007568359375, Neurons: 11, Grad norm: 1.379e+01\n",
      "Epoch 1152, Loss: 1096.7781982421875, Neurons: 11, Grad norm: 1.378e+01\n",
      "Epoch 1153, Loss: 1096.655517578125, Neurons: 11, Grad norm: 1.378e+01\n",
      "Epoch 1154, Loss: 1096.5330810546875, Neurons: 11, Grad norm: 1.377e+01\n",
      "Epoch 1155, Loss: 1096.4105224609375, Neurons: 11, Grad norm: 1.376e+01\n",
      "Epoch 1156, Loss: 1096.2882080078125, Neurons: 11, Grad norm: 1.375e+01\n",
      "Epoch 1157, Loss: 1096.165771484375, Neurons: 11, Grad norm: 1.375e+01\n",
      "Epoch 1158, Loss: 1096.0433349609375, Neurons: 11, Grad norm: 1.374e+01\n",
      "Epoch 1159, Loss: 1095.921142578125, Neurons: 11, Grad norm: 1.373e+01\n",
      "Epoch 1160, Loss: 1095.7989501953125, Neurons: 11, Grad norm: 1.372e+01\n",
      "Epoch 1161, Loss: 1095.6767578125, Neurons: 11, Grad norm: 1.372e+01\n",
      "Epoch 1162, Loss: 1095.554443359375, Neurons: 11, Grad norm: 1.371e+01\n",
      "Epoch 1163, Loss: 1095.432373046875, Neurons: 11, Grad norm: 1.370e+01\n",
      "Epoch 1164, Loss: 1095.3104248046875, Neurons: 11, Grad norm: 1.369e+01\n",
      "Epoch 1165, Loss: 1095.1883544921875, Neurons: 11, Grad norm: 1.369e+01\n",
      "Epoch 1166, Loss: 1095.0665283203125, Neurons: 11, Grad norm: 1.368e+01\n",
      "Epoch 1167, Loss: 1094.944580078125, Neurons: 11, Grad norm: 1.367e+01\n",
      "Epoch 1168, Loss: 1094.82275390625, Neurons: 11, Grad norm: 1.366e+01\n",
      "Epoch 1169, Loss: 1094.700927734375, Neurons: 11, Grad norm: 1.366e+01\n",
      "Epoch 1170, Loss: 1094.5792236328125, Neurons: 11, Grad norm: 1.365e+01\n",
      "Epoch 1171, Loss: 1094.4573974609375, Neurons: 11, Grad norm: 1.364e+01\n",
      "Epoch 1172, Loss: 1094.3358154296875, Neurons: 11, Grad norm: 1.363e+01\n",
      "Epoch 1173, Loss: 1094.214111328125, Neurons: 11, Grad norm: 1.362e+01\n",
      "Epoch 1174, Loss: 1094.0926513671875, Neurons: 11, Grad norm: 1.362e+01\n",
      "Epoch 1175, Loss: 1093.97119140625, Neurons: 11, Grad norm: 1.361e+01\n",
      "Epoch 1176, Loss: 1093.8497314453125, Neurons: 11, Grad norm: 1.360e+01\n",
      "Epoch 1177, Loss: 1093.7283935546875, Neurons: 11, Grad norm: 1.359e+01\n",
      "Epoch 1178, Loss: 1093.60693359375, Neurons: 11, Grad norm: 1.359e+01\n",
      "Epoch 1179, Loss: 1093.4857177734375, Neurons: 11, Grad norm: 1.358e+01\n",
      "Epoch 1180, Loss: 1093.3646240234375, Neurons: 11, Grad norm: 1.357e+01\n",
      "Epoch 1181, Loss: 1093.2431640625, Neurons: 11, Grad norm: 1.356e+01\n",
      "Epoch 1182, Loss: 1093.1221923828125, Neurons: 11, Grad norm: 1.356e+01\n",
      "Epoch 1183, Loss: 1093.0009765625, Neurons: 11, Grad norm: 1.355e+01\n",
      "Epoch 1184, Loss: 1092.8800048828125, Neurons: 11, Grad norm: 1.354e+01\n",
      "Epoch 1185, Loss: 1092.759033203125, Neurons: 11, Grad norm: 1.353e+01\n",
      "Epoch 1186, Loss: 1092.63818359375, Neurons: 11, Grad norm: 1.353e+01\n",
      "Epoch 1187, Loss: 1092.5172119140625, Neurons: 11, Grad norm: 1.352e+01\n",
      "Epoch 1188, Loss: 1092.3963623046875, Neurons: 11, Grad norm: 1.351e+01\n",
      "Epoch 1189, Loss: 1092.275634765625, Neurons: 11, Grad norm: 1.350e+01\n",
      "Epoch 1190, Loss: 1092.155029296875, Neurons: 11, Grad norm: 1.349e+01\n",
      "Epoch 1191, Loss: 1092.0341796875, Neurons: 11, Grad norm: 1.349e+01\n",
      "Epoch 1192, Loss: 1091.91357421875, Neurons: 11, Grad norm: 1.348e+01\n",
      "Epoch 1193, Loss: 1091.7930908203125, Neurons: 11, Grad norm: 1.347e+01\n",
      "Epoch 1194, Loss: 1091.672607421875, Neurons: 11, Grad norm: 1.346e+01\n",
      "Epoch 1195, Loss: 1091.5521240234375, Neurons: 11, Grad norm: 1.346e+01\n",
      "Epoch 1196, Loss: 1091.431640625, Neurons: 11, Grad norm: 1.345e+01\n",
      "Epoch 1197, Loss: 1091.3114013671875, Neurons: 11, Grad norm: 1.344e+01\n",
      "Epoch 1198, Loss: 1091.19091796875, Neurons: 11, Grad norm: 1.343e+01\n",
      "Epoch 1199, Loss: 1091.07080078125, Neurons: 11, Grad norm: 1.343e+01\n",
      "Epoch 1199, Test loss: 1110.354248046875\n",
      "Epoch 1200, Loss: 1090.9505615234375, Neurons: 11, Grad norm: 1.342e+01\n",
      "Epoch 1201, Loss: 1090.830322265625, Neurons: 11, Grad norm: 1.341e+01\n",
      "Epoch 1202, Loss: 1090.7103271484375, Neurons: 11, Grad norm: 1.340e+01\n",
      "Epoch 1203, Loss: 1090.59033203125, Neurons: 11, Grad norm: 1.340e+01\n",
      "Epoch 1204, Loss: 1090.4703369140625, Neurons: 11, Grad norm: 1.339e+01\n",
      "Epoch 1205, Loss: 1090.350341796875, Neurons: 11, Grad norm: 1.338e+01\n",
      "Epoch 1206, Loss: 1090.23046875, Neurons: 11, Grad norm: 1.337e+01\n",
      "Epoch 1207, Loss: 1090.1107177734375, Neurons: 11, Grad norm: 1.337e+01\n",
      "Epoch 1208, Loss: 1089.990966796875, Neurons: 11, Grad norm: 1.336e+01\n",
      "Epoch 1209, Loss: 1089.8712158203125, Neurons: 11, Grad norm: 1.335e+01\n",
      "Epoch 1210, Loss: 1089.7515869140625, Neurons: 11, Grad norm: 1.334e+01\n",
      "Epoch 1211, Loss: 1089.6319580078125, Neurons: 11, Grad norm: 1.333e+01\n",
      "Epoch 1212, Loss: 1089.5123291015625, Neurons: 11, Grad norm: 1.333e+01\n",
      "Epoch 1213, Loss: 1089.392822265625, Neurons: 11, Grad norm: 1.332e+01\n",
      "Epoch 1214, Loss: 1089.2733154296875, Neurons: 11, Grad norm: 1.331e+01\n",
      "Epoch 1215, Loss: 1089.154052734375, Neurons: 11, Grad norm: 1.330e+01\n",
      "Epoch 1216, Loss: 1089.03466796875, Neurons: 11, Grad norm: 1.330e+01\n",
      "Epoch 1217, Loss: 1088.9154052734375, Neurons: 11, Grad norm: 1.329e+01\n",
      "Epoch 1218, Loss: 1088.796142578125, Neurons: 11, Grad norm: 1.328e+01\n",
      "Epoch 1219, Loss: 1088.6771240234375, Neurons: 11, Grad norm: 1.327e+01\n",
      "Epoch 1220, Loss: 1088.5579833984375, Neurons: 11, Grad norm: 1.327e+01\n",
      "Epoch 1221, Loss: 1088.438720703125, Neurons: 11, Grad norm: 1.326e+01\n",
      "Epoch 1222, Loss: 1088.31982421875, Neurons: 11, Grad norm: 1.325e+01\n",
      "Epoch 1223, Loss: 1088.200927734375, Neurons: 11, Grad norm: 1.324e+01\n",
      "Epoch 1224, Loss: 1088.08203125, Neurons: 11, Grad norm: 1.324e+01\n",
      "Epoch 1225, Loss: 1087.963134765625, Neurons: 11, Grad norm: 1.323e+01\n",
      "Epoch 1226, Loss: 1087.844482421875, Neurons: 11, Grad norm: 1.322e+01\n",
      "Epoch 1227, Loss: 1087.7257080078125, Neurons: 11, Grad norm: 1.321e+01\n",
      "Epoch 1228, Loss: 1087.60693359375, Neurons: 11, Grad norm: 1.320e+01\n",
      "Epoch 1229, Loss: 1087.4884033203125, Neurons: 11, Grad norm: 1.320e+01\n",
      "Epoch 1230, Loss: 1087.3697509765625, Neurons: 11, Grad norm: 1.319e+01\n",
      "Epoch 1231, Loss: 1087.251220703125, Neurons: 11, Grad norm: 1.318e+01\n",
      "Epoch 1232, Loss: 1087.1328125, Neurons: 11, Grad norm: 1.317e+01\n",
      "Epoch 1233, Loss: 1087.014404296875, Neurons: 11, Grad norm: 1.317e+01\n",
      "Epoch 1234, Loss: 1086.8961181640625, Neurons: 11, Grad norm: 1.316e+01\n",
      "Epoch 1235, Loss: 1086.77783203125, Neurons: 11, Grad norm: 1.315e+01\n",
      "Epoch 1236, Loss: 1086.6595458984375, Neurons: 11, Grad norm: 1.314e+01\n",
      "Epoch 1237, Loss: 1086.5413818359375, Neurons: 11, Grad norm: 1.314e+01\n",
      "Epoch 1238, Loss: 1086.42333984375, Neurons: 11, Grad norm: 1.313e+01\n",
      "Epoch 1239, Loss: 1086.3052978515625, Neurons: 11, Grad norm: 1.312e+01\n",
      "Epoch 1240, Loss: 1086.1871337890625, Neurons: 11, Grad norm: 1.311e+01\n",
      "Epoch 1241, Loss: 1086.0693359375, Neurons: 11, Grad norm: 1.311e+01\n",
      "Epoch 1242, Loss: 1085.951416015625, Neurons: 11, Grad norm: 1.310e+01\n",
      "Epoch 1243, Loss: 1085.8336181640625, Neurons: 11, Grad norm: 1.309e+01\n",
      "Epoch 1244, Loss: 1085.7158203125, Neurons: 11, Grad norm: 1.308e+01\n",
      "Epoch 1245, Loss: 1085.5980224609375, Neurons: 11, Grad norm: 1.308e+01\n",
      "Epoch 1246, Loss: 1085.4803466796875, Neurons: 11, Grad norm: 1.307e+01\n",
      "Epoch 1247, Loss: 1085.3629150390625, Neurons: 11, Grad norm: 1.306e+01\n",
      "Epoch 1248, Loss: 1085.2452392578125, Neurons: 11, Grad norm: 1.305e+01\n",
      "Epoch 1249, Loss: 1085.1278076171875, Neurons: 11, Grad norm: 1.304e+01\n",
      "Epoch 1249, Test loss: 1104.1654052734375\n",
      "Epoch 1250, Loss: 1085.0103759765625, Neurons: 11, Grad norm: 1.304e+01\n",
      "Epoch 1251, Loss: 1084.8929443359375, Neurons: 11, Grad norm: 1.303e+01\n",
      "Epoch 1252, Loss: 1084.775634765625, Neurons: 11, Grad norm: 1.302e+01\n",
      "Epoch 1253, Loss: 1084.6583251953125, Neurons: 11, Grad norm: 1.301e+01\n",
      "Epoch 1254, Loss: 1084.5411376953125, Neurons: 11, Grad norm: 1.301e+01\n",
      "Epoch 1255, Loss: 1084.4239501953125, Neurons: 11, Grad norm: 1.300e+01\n",
      "Epoch 1256, Loss: 1084.3070068359375, Neurons: 11, Grad norm: 1.299e+01\n",
      "Epoch 1257, Loss: 1084.18994140625, Neurons: 11, Grad norm: 1.298e+01\n",
      "Epoch 1258, Loss: 1084.072998046875, Neurons: 11, Grad norm: 1.298e+01\n",
      "Epoch 1259, Loss: 1083.9561767578125, Neurons: 11, Grad norm: 1.297e+01\n",
      "Epoch 1260, Loss: 1083.8392333984375, Neurons: 11, Grad norm: 1.296e+01\n",
      "Epoch 1261, Loss: 1083.722412109375, Neurons: 11, Grad norm: 1.295e+01\n",
      "Epoch 1262, Loss: 1083.605712890625, Neurons: 11, Grad norm: 1.295e+01\n",
      "Epoch 1263, Loss: 1083.489013671875, Neurons: 11, Grad norm: 1.294e+01\n",
      "Epoch 1264, Loss: 1083.372314453125, Neurons: 11, Grad norm: 1.293e+01\n",
      "Epoch 1265, Loss: 1083.2557373046875, Neurons: 11, Grad norm: 1.292e+01\n",
      "Epoch 1266, Loss: 1083.1392822265625, Neurons: 11, Grad norm: 1.292e+01\n",
      "Epoch 1267, Loss: 1083.0228271484375, Neurons: 11, Grad norm: 1.291e+01\n",
      "Epoch 1268, Loss: 1082.906494140625, Neurons: 11, Grad norm: 1.290e+01\n",
      "Epoch 1269, Loss: 1082.7901611328125, Neurons: 11, Grad norm: 1.289e+01\n",
      "Epoch 1270, Loss: 1082.673828125, Neurons: 11, Grad norm: 1.288e+01\n",
      "Epoch 1271, Loss: 1082.5576171875, Neurons: 11, Grad norm: 1.288e+01\n",
      "Epoch 1272, Loss: 1082.4415283203125, Neurons: 11, Grad norm: 1.287e+01\n",
      "Epoch 1273, Loss: 1082.3253173828125, Neurons: 11, Grad norm: 1.286e+01\n",
      "Epoch 1274, Loss: 1082.2093505859375, Neurons: 11, Grad norm: 1.285e+01\n",
      "Epoch 1275, Loss: 1082.0933837890625, Neurons: 11, Grad norm: 1.285e+01\n",
      "Epoch 1276, Loss: 1081.9774169921875, Neurons: 11, Grad norm: 1.284e+01\n",
      "Epoch 1277, Loss: 1081.861572265625, Neurons: 11, Grad norm: 1.283e+01\n",
      "Epoch 1278, Loss: 1081.7457275390625, Neurons: 11, Grad norm: 1.282e+01\n",
      "Epoch 1279, Loss: 1081.630126953125, Neurons: 11, Grad norm: 1.282e+01\n",
      "Epoch 1280, Loss: 1081.514404296875, Neurons: 11, Grad norm: 1.281e+01\n",
      "Epoch 1281, Loss: 1081.3988037109375, Neurons: 11, Grad norm: 1.280e+01\n",
      "Epoch 1282, Loss: 1081.2833251953125, Neurons: 11, Grad norm: 1.279e+01\n",
      "Epoch 1283, Loss: 1081.167724609375, Neurons: 11, Grad norm: 1.279e+01\n",
      "Epoch 1284, Loss: 1081.05224609375, Neurons: 11, Grad norm: 1.278e+01\n",
      "Epoch 1285, Loss: 1080.93701171875, Neurons: 11, Grad norm: 1.277e+01\n",
      "Epoch 1286, Loss: 1080.821533203125, Neurons: 11, Grad norm: 1.276e+01\n",
      "Epoch 1287, Loss: 1080.7064208984375, Neurons: 11, Grad norm: 1.276e+01\n",
      "Epoch 1288, Loss: 1080.5911865234375, Neurons: 11, Grad norm: 1.275e+01\n",
      "Epoch 1289, Loss: 1080.4759521484375, Neurons: 11, Grad norm: 1.274e+01\n",
      "Epoch 1290, Loss: 1080.36083984375, Neurons: 11, Grad norm: 1.273e+01\n",
      "Epoch 1291, Loss: 1080.2459716796875, Neurons: 11, Grad norm: 1.273e+01\n",
      "Epoch 1292, Loss: 1080.1309814453125, Neurons: 11, Grad norm: 1.272e+01\n",
      "Epoch 1293, Loss: 1080.01611328125, Neurons: 11, Grad norm: 1.271e+01\n",
      "Epoch 1294, Loss: 1079.901123046875, Neurons: 11, Grad norm: 1.270e+01\n",
      "Epoch 1295, Loss: 1079.786376953125, Neurons: 11, Grad norm: 1.269e+01\n",
      "Epoch 1296, Loss: 1079.671630859375, Neurons: 11, Grad norm: 1.269e+01\n",
      "Epoch 1297, Loss: 1079.5570068359375, Neurons: 11, Grad norm: 1.268e+01\n",
      "Epoch 1298, Loss: 1079.4423828125, Neurons: 11, Grad norm: 1.267e+01\n",
      "Epoch 1299, Loss: 1079.327880859375, Neurons: 11, Grad norm: 1.266e+01\n",
      "Epoch 1299, Test loss: 1098.1224365234375\n",
      "Epoch 1300, Loss: 1079.21337890625, Neurons: 11, Grad norm: 1.266e+01\n",
      "Epoch 1301, Loss: 1079.0989990234375, Neurons: 11, Grad norm: 1.265e+01\n",
      "Epoch 1302, Loss: 1078.984619140625, Neurons: 11, Grad norm: 1.264e+01\n",
      "Epoch 1303, Loss: 1078.870361328125, Neurons: 11, Grad norm: 1.263e+01\n",
      "Epoch 1304, Loss: 1078.7562255859375, Neurons: 11, Grad norm: 1.263e+01\n",
      "Epoch 1305, Loss: 1078.6419677734375, Neurons: 11, Grad norm: 1.262e+01\n",
      "Epoch 1306, Loss: 1078.52783203125, Neurons: 11, Grad norm: 1.261e+01\n",
      "Epoch 1307, Loss: 1078.413818359375, Neurons: 11, Grad norm: 1.260e+01\n",
      "Epoch 1308, Loss: 1078.2998046875, Neurons: 11, Grad norm: 1.260e+01\n",
      "Epoch 1309, Loss: 1078.185791015625, Neurons: 11, Grad norm: 1.259e+01\n",
      "Epoch 1310, Loss: 1078.072021484375, Neurons: 11, Grad norm: 1.258e+01\n",
      "Epoch 1311, Loss: 1077.9581298828125, Neurons: 11, Grad norm: 1.257e+01\n",
      "Epoch 1312, Loss: 1077.8443603515625, Neurons: 11, Grad norm: 1.257e+01\n",
      "Epoch 1313, Loss: 1077.730712890625, Neurons: 11, Grad norm: 1.256e+01\n",
      "Epoch 1314, Loss: 1077.6170654296875, Neurons: 11, Grad norm: 1.255e+01\n",
      "Epoch 1315, Loss: 1077.5035400390625, Neurons: 11, Grad norm: 1.254e+01\n",
      "Epoch 1316, Loss: 1077.3900146484375, Neurons: 11, Grad norm: 1.254e+01\n",
      "Epoch 1317, Loss: 1077.276611328125, Neurons: 11, Grad norm: 1.253e+01\n",
      "Epoch 1318, Loss: 1077.1632080078125, Neurons: 11, Grad norm: 1.252e+01\n",
      "Epoch 1319, Loss: 1077.0499267578125, Neurons: 11, Grad norm: 1.251e+01\n",
      "Epoch 1320, Loss: 1076.9366455078125, Neurons: 11, Grad norm: 1.251e+01\n",
      "Epoch 1321, Loss: 1076.823486328125, Neurons: 11, Grad norm: 1.250e+01\n",
      "Epoch 1322, Loss: 1076.7103271484375, Neurons: 11, Grad norm: 1.249e+01\n",
      "Epoch 1323, Loss: 1076.5972900390625, Neurons: 11, Grad norm: 1.248e+01\n",
      "Epoch 1324, Loss: 1076.4842529296875, Neurons: 11, Grad norm: 1.248e+01\n",
      "Epoch 1325, Loss: 1076.3712158203125, Neurons: 11, Grad norm: 1.247e+01\n",
      "Epoch 1326, Loss: 1076.2584228515625, Neurons: 11, Grad norm: 1.246e+01\n",
      "Epoch 1327, Loss: 1076.1456298828125, Neurons: 11, Grad norm: 1.245e+01\n",
      "Epoch 1328, Loss: 1076.03271484375, Neurons: 11, Grad norm: 1.245e+01\n",
      "Epoch 1329, Loss: 1075.920166015625, Neurons: 11, Grad norm: 1.244e+01\n",
      "Epoch 1330, Loss: 1075.8074951171875, Neurons: 11, Grad norm: 1.243e+01\n",
      "Epoch 1331, Loss: 1075.6949462890625, Neurons: 11, Grad norm: 1.242e+01\n",
      "Epoch 1332, Loss: 1075.5823974609375, Neurons: 11, Grad norm: 1.241e+01\n",
      "Epoch 1333, Loss: 1075.469970703125, Neurons: 11, Grad norm: 1.241e+01\n",
      "Epoch 1334, Loss: 1075.3575439453125, Neurons: 11, Grad norm: 1.240e+01\n",
      "Epoch 1335, Loss: 1075.2451171875, Neurons: 11, Grad norm: 1.239e+01\n",
      "Epoch 1336, Loss: 1075.1329345703125, Neurons: 11, Grad norm: 1.238e+01\n",
      "Epoch 1337, Loss: 1075.0208740234375, Neurons: 11, Grad norm: 1.238e+01\n",
      "Epoch 1338, Loss: 1074.9085693359375, Neurons: 11, Grad norm: 1.237e+01\n",
      "Epoch 1339, Loss: 1074.796630859375, Neurons: 11, Grad norm: 1.236e+01\n",
      "Epoch 1340, Loss: 1074.6845703125, Neurons: 11, Grad norm: 1.235e+01\n",
      "Epoch 1341, Loss: 1074.5726318359375, Neurons: 11, Grad norm: 1.235e+01\n",
      "Epoch 1342, Loss: 1074.4608154296875, Neurons: 11, Grad norm: 1.234e+01\n",
      "Epoch 1343, Loss: 1074.3489990234375, Neurons: 11, Grad norm: 1.233e+01\n",
      "Epoch 1344, Loss: 1074.2371826171875, Neurons: 11, Grad norm: 1.232e+01\n",
      "Epoch 1345, Loss: 1074.1253662109375, Neurons: 11, Grad norm: 1.232e+01\n",
      "Epoch 1346, Loss: 1074.013916015625, Neurons: 11, Grad norm: 1.231e+01\n",
      "Epoch 1347, Loss: 1073.9022216796875, Neurons: 11, Grad norm: 1.230e+01\n",
      "Epoch 1348, Loss: 1073.790771484375, Neurons: 11, Grad norm: 1.229e+01\n",
      "Epoch 1349, Loss: 1073.6793212890625, Neurons: 11, Grad norm: 1.229e+01\n",
      "Epoch 1349, Test loss: 1092.2340087890625\n",
      "Epoch 1350, Loss: 1073.5679931640625, Neurons: 11, Grad norm: 1.228e+01\n",
      "Epoch 1351, Loss: 1073.45654296875, Neurons: 11, Grad norm: 1.227e+01\n",
      "Epoch 1352, Loss: 1073.3453369140625, Neurons: 11, Grad norm: 1.226e+01\n",
      "Epoch 1353, Loss: 1073.234130859375, Neurons: 11, Grad norm: 1.226e+01\n",
      "Epoch 1354, Loss: 1073.1229248046875, Neurons: 11, Grad norm: 1.225e+01\n",
      "Epoch 1355, Loss: 1073.011962890625, Neurons: 11, Grad norm: 1.224e+01\n",
      "Epoch 1356, Loss: 1072.9010009765625, Neurons: 11, Grad norm: 1.223e+01\n",
      "Epoch 1357, Loss: 1072.7899169921875, Neurons: 11, Grad norm: 1.223e+01\n",
      "Epoch 1358, Loss: 1072.67919921875, Neurons: 11, Grad norm: 1.222e+01\n",
      "Epoch 1359, Loss: 1072.568359375, Neurons: 11, Grad norm: 1.221e+01\n",
      "Epoch 1360, Loss: 1072.45751953125, Neurons: 11, Grad norm: 1.220e+01\n",
      "Epoch 1361, Loss: 1072.346923828125, Neurons: 11, Grad norm: 1.220e+01\n",
      "Epoch 1362, Loss: 1072.236328125, Neurons: 11, Grad norm: 1.219e+01\n",
      "Epoch 1363, Loss: 1072.125732421875, Neurons: 11, Grad norm: 1.218e+01\n",
      "Epoch 1364, Loss: 1072.0152587890625, Neurons: 11, Grad norm: 1.217e+01\n",
      "Epoch 1365, Loss: 1071.90478515625, Neurons: 11, Grad norm: 1.217e+01\n",
      "Epoch 1366, Loss: 1071.79443359375, Neurons: 11, Grad norm: 1.216e+01\n",
      "Epoch 1367, Loss: 1071.6842041015625, Neurons: 11, Grad norm: 1.215e+01\n",
      "Epoch 1368, Loss: 1071.5738525390625, Neurons: 11, Grad norm: 1.214e+01\n",
      "Epoch 1369, Loss: 1071.4637451171875, Neurons: 11, Grad norm: 1.214e+01\n",
      "Epoch 1370, Loss: 1071.353515625, Neurons: 11, Grad norm: 1.213e+01\n",
      "Epoch 1371, Loss: 1071.24365234375, Neurons: 11, Grad norm: 1.212e+01\n",
      "Epoch 1372, Loss: 1071.133544921875, Neurons: 11, Grad norm: 1.211e+01\n",
      "Epoch 1373, Loss: 1071.0238037109375, Neurons: 11, Grad norm: 1.211e+01\n",
      "Epoch 1374, Loss: 1070.913818359375, Neurons: 11, Grad norm: 1.210e+01\n",
      "Epoch 1375, Loss: 1070.803955078125, Neurons: 11, Grad norm: 1.209e+01\n",
      "Epoch 1376, Loss: 1070.6943359375, Neurons: 11, Grad norm: 1.209e+01\n",
      "Epoch 1377, Loss: 1070.584716796875, Neurons: 11, Grad norm: 1.208e+01\n",
      "Epoch 1378, Loss: 1070.47509765625, Neurons: 11, Grad norm: 1.207e+01\n",
      "Epoch 1379, Loss: 1070.3656005859375, Neurons: 11, Grad norm: 1.206e+01\n",
      "Epoch 1380, Loss: 1070.256103515625, Neurons: 11, Grad norm: 1.206e+01\n",
      "Epoch 1381, Loss: 1070.146728515625, Neurons: 11, Grad norm: 1.205e+01\n",
      "Epoch 1382, Loss: 1070.037353515625, Neurons: 11, Grad norm: 1.204e+01\n",
      "Epoch 1383, Loss: 1069.9281005859375, Neurons: 11, Grad norm: 1.203e+01\n",
      "Epoch 1384, Loss: 1069.8189697265625, Neurons: 11, Grad norm: 1.203e+01\n",
      "Epoch 1385, Loss: 1069.709716796875, Neurons: 11, Grad norm: 1.202e+01\n",
      "Epoch 1386, Loss: 1069.6007080078125, Neurons: 11, Grad norm: 1.201e+01\n",
      "Epoch 1387, Loss: 1069.4915771484375, Neurons: 11, Grad norm: 1.200e+01\n",
      "Epoch 1388, Loss: 1069.3826904296875, Neurons: 11, Grad norm: 1.200e+01\n",
      "Epoch 1389, Loss: 1069.2738037109375, Neurons: 11, Grad norm: 1.199e+01\n",
      "Epoch 1390, Loss: 1069.1649169921875, Neurons: 11, Grad norm: 1.198e+01\n",
      "Epoch 1391, Loss: 1069.05615234375, Neurons: 11, Grad norm: 1.197e+01\n",
      "Epoch 1392, Loss: 1068.9476318359375, Neurons: 11, Grad norm: 1.197e+01\n",
      "Epoch 1393, Loss: 1068.8388671875, Neurons: 11, Grad norm: 1.196e+01\n",
      "Epoch 1394, Loss: 1068.730224609375, Neurons: 11, Grad norm: 1.195e+01\n",
      "Epoch 1395, Loss: 1068.621826171875, Neurons: 11, Grad norm: 1.194e+01\n",
      "Epoch 1396, Loss: 1068.513427734375, Neurons: 11, Grad norm: 1.194e+01\n",
      "Epoch 1397, Loss: 1068.405029296875, Neurons: 11, Grad norm: 1.193e+01\n",
      "Epoch 1398, Loss: 1068.2967529296875, Neurons: 11, Grad norm: 1.192e+01\n",
      "Epoch 1399, Loss: 1068.1884765625, Neurons: 11, Grad norm: 1.191e+01\n",
      "Epoch 1399, Test loss: 1086.5072021484375\n",
      "Epoch 1400, Loss: 1068.080322265625, Neurons: 11, Grad norm: 1.191e+01\n",
      "Epoch 1401, Loss: 1067.97216796875, Neurons: 11, Grad norm: 1.190e+01\n",
      "Epoch 1402, Loss: 1067.8641357421875, Neurons: 11, Grad norm: 1.189e+01\n",
      "Epoch 1403, Loss: 1067.7562255859375, Neurons: 11, Grad norm: 1.188e+01\n",
      "Epoch 1404, Loss: 1067.6483154296875, Neurons: 11, Grad norm: 1.188e+01\n",
      "Epoch 1405, Loss: 1067.54052734375, Neurons: 11, Grad norm: 1.187e+01\n",
      "Epoch 1406, Loss: 1067.4326171875, Neurons: 11, Grad norm: 1.186e+01\n",
      "Epoch 1407, Loss: 1067.3248291015625, Neurons: 11, Grad norm: 1.185e+01\n",
      "Epoch 1408, Loss: 1067.21728515625, Neurons: 11, Grad norm: 1.185e+01\n",
      "Epoch 1409, Loss: 1067.109619140625, Neurons: 11, Grad norm: 1.184e+01\n",
      "Epoch 1410, Loss: 1067.002197265625, Neurons: 11, Grad norm: 1.183e+01\n",
      "Epoch 1411, Loss: 1066.8946533203125, Neurons: 11, Grad norm: 1.183e+01\n",
      "Epoch 1412, Loss: 1066.7872314453125, Neurons: 11, Grad norm: 1.182e+01\n",
      "Epoch 1413, Loss: 1066.679931640625, Neurons: 11, Grad norm: 1.181e+01\n",
      "Epoch 1414, Loss: 1066.5726318359375, Neurons: 11, Grad norm: 1.180e+01\n",
      "Epoch 1415, Loss: 1066.465576171875, Neurons: 11, Grad norm: 1.180e+01\n",
      "Epoch 1416, Loss: 1066.3583984375, Neurons: 11, Grad norm: 1.179e+01\n",
      "Epoch 1417, Loss: 1066.2513427734375, Neurons: 11, Grad norm: 1.178e+01\n",
      "Epoch 1418, Loss: 1066.1444091796875, Neurons: 11, Grad norm: 1.177e+01\n",
      "Epoch 1419, Loss: 1066.037353515625, Neurons: 11, Grad norm: 1.177e+01\n",
      "Epoch 1420, Loss: 1065.9305419921875, Neurons: 11, Grad norm: 1.176e+01\n",
      "Epoch 1421, Loss: 1065.82373046875, Neurons: 11, Grad norm: 1.175e+01\n",
      "Epoch 1422, Loss: 1065.7169189453125, Neurons: 11, Grad norm: 1.174e+01\n",
      "Epoch 1423, Loss: 1065.6102294921875, Neurons: 11, Grad norm: 1.174e+01\n",
      "Epoch 1424, Loss: 1065.503662109375, Neurons: 11, Grad norm: 1.173e+01\n",
      "Epoch 1425, Loss: 1065.397216796875, Neurons: 11, Grad norm: 1.172e+01\n",
      "Epoch 1426, Loss: 1065.29052734375, Neurons: 11, Grad norm: 1.171e+01\n",
      "Epoch 1427, Loss: 1065.184326171875, Neurons: 11, Grad norm: 1.171e+01\n",
      "Epoch 1428, Loss: 1065.077880859375, Neurons: 11, Grad norm: 1.170e+01\n",
      "Epoch 1429, Loss: 1064.9716796875, Neurons: 11, Grad norm: 1.169e+01\n",
      "Epoch 1430, Loss: 1064.8653564453125, Neurons: 11, Grad norm: 1.169e+01\n",
      "Epoch 1431, Loss: 1064.75927734375, Neurons: 11, Grad norm: 1.168e+01\n",
      "Epoch 1432, Loss: 1064.6531982421875, Neurons: 11, Grad norm: 1.167e+01\n",
      "Epoch 1433, Loss: 1064.547119140625, Neurons: 11, Grad norm: 1.166e+01\n",
      "Epoch 1434, Loss: 1064.4412841796875, Neurons: 11, Grad norm: 1.166e+01\n",
      "Epoch 1435, Loss: 1064.3353271484375, Neurons: 11, Grad norm: 1.165e+01\n",
      "Epoch 1436, Loss: 1064.2296142578125, Neurons: 11, Grad norm: 1.164e+01\n",
      "Epoch 1437, Loss: 1064.123779296875, Neurons: 11, Grad norm: 1.163e+01\n",
      "Epoch 1438, Loss: 1064.01806640625, Neurons: 11, Grad norm: 1.163e+01\n",
      "Epoch 1439, Loss: 1063.912353515625, Neurons: 11, Grad norm: 1.162e+01\n",
      "Epoch 1440, Loss: 1063.8070068359375, Neurons: 11, Grad norm: 1.161e+01\n",
      "Epoch 1441, Loss: 1063.701416015625, Neurons: 11, Grad norm: 1.160e+01\n",
      "Epoch 1442, Loss: 1063.595947265625, Neurons: 11, Grad norm: 1.160e+01\n",
      "Epoch 1443, Loss: 1063.4906005859375, Neurons: 11, Grad norm: 1.159e+01\n",
      "Epoch 1444, Loss: 1063.3853759765625, Neurons: 11, Grad norm: 1.158e+01\n",
      "Epoch 1445, Loss: 1063.2801513671875, Neurons: 11, Grad norm: 1.158e+01\n",
      "Epoch 1446, Loss: 1063.1749267578125, Neurons: 11, Grad norm: 1.157e+01\n",
      "Epoch 1447, Loss: 1063.06982421875, Neurons: 11, Grad norm: 1.156e+01\n",
      "Epoch 1448, Loss: 1062.9647216796875, Neurons: 11, Grad norm: 1.155e+01\n",
      "Epoch 1449, Loss: 1062.85986328125, Neurons: 11, Grad norm: 1.155e+01\n",
      "Epoch 1449, Test loss: 1080.9464111328125\n",
      "Epoch 1450, Loss: 1062.7550048828125, Neurons: 11, Grad norm: 1.154e+01\n",
      "Epoch 1451, Loss: 1062.650146484375, Neurons: 11, Grad norm: 1.153e+01\n",
      "Epoch 1452, Loss: 1062.54541015625, Neurons: 11, Grad norm: 1.152e+01\n",
      "Epoch 1453, Loss: 1062.440673828125, Neurons: 11, Grad norm: 1.152e+01\n",
      "Epoch 1454, Loss: 1062.3359375, Neurons: 11, Grad norm: 1.151e+01\n",
      "Epoch 1455, Loss: 1062.2315673828125, Neurons: 11, Grad norm: 1.150e+01\n",
      "Epoch 1456, Loss: 1062.126953125, Neurons: 11, Grad norm: 1.150e+01\n",
      "Epoch 1457, Loss: 1062.0225830078125, Neurons: 11, Grad norm: 1.149e+01\n",
      "Epoch 1458, Loss: 1061.918212890625, Neurons: 11, Grad norm: 1.148e+01\n",
      "Epoch 1459, Loss: 1061.81396484375, Neurons: 11, Grad norm: 1.147e+01\n",
      "Epoch 1460, Loss: 1061.709716796875, Neurons: 11, Grad norm: 1.147e+01\n",
      "Epoch 1461, Loss: 1061.60546875, Neurons: 11, Grad norm: 1.146e+01\n",
      "Epoch 1462, Loss: 1061.5013427734375, Neurons: 11, Grad norm: 1.145e+01\n",
      "Epoch 1463, Loss: 1061.3973388671875, Neurons: 11, Grad norm: 1.144e+01\n",
      "Epoch 1464, Loss: 1061.2933349609375, Neurons: 11, Grad norm: 1.144e+01\n",
      "Epoch 1465, Loss: 1061.1895751953125, Neurons: 11, Grad norm: 1.143e+01\n",
      "Epoch 1466, Loss: 1061.085693359375, Neurons: 11, Grad norm: 1.142e+01\n",
      "Epoch 1467, Loss: 1060.98193359375, Neurons: 11, Grad norm: 1.142e+01\n",
      "Epoch 1468, Loss: 1060.878173828125, Neurons: 11, Grad norm: 1.141e+01\n",
      "Epoch 1469, Loss: 1060.7745361328125, Neurons: 11, Grad norm: 1.140e+01\n",
      "Epoch 1470, Loss: 1060.6710205078125, Neurons: 11, Grad norm: 1.139e+01\n",
      "Epoch 1471, Loss: 1060.567626953125, Neurons: 11, Grad norm: 1.139e+01\n",
      "Epoch 1472, Loss: 1060.4639892578125, Neurons: 11, Grad norm: 1.138e+01\n",
      "Epoch 1473, Loss: 1060.3607177734375, Neurons: 11, Grad norm: 1.137e+01\n",
      "Epoch 1474, Loss: 1060.25732421875, Neurons: 11, Grad norm: 1.136e+01\n",
      "Epoch 1475, Loss: 1060.1541748046875, Neurons: 11, Grad norm: 1.136e+01\n",
      "Epoch 1476, Loss: 1060.051025390625, Neurons: 11, Grad norm: 1.135e+01\n",
      "Epoch 1477, Loss: 1059.9478759765625, Neurons: 11, Grad norm: 1.134e+01\n",
      "Epoch 1478, Loss: 1059.8447265625, Neurons: 11, Grad norm: 1.134e+01\n",
      "Epoch 1479, Loss: 1059.7418212890625, Neurons: 11, Grad norm: 1.133e+01\n",
      "Epoch 1480, Loss: 1059.638916015625, Neurons: 11, Grad norm: 1.132e+01\n",
      "Epoch 1481, Loss: 1059.5361328125, Neurons: 11, Grad norm: 1.131e+01\n",
      "Epoch 1482, Loss: 1059.4332275390625, Neurons: 11, Grad norm: 1.131e+01\n",
      "Epoch 1483, Loss: 1059.3306884765625, Neurons: 11, Grad norm: 1.130e+01\n",
      "Epoch 1484, Loss: 1059.22802734375, Neurons: 11, Grad norm: 1.129e+01\n",
      "Epoch 1485, Loss: 1059.1253662109375, Neurons: 11, Grad norm: 1.129e+01\n",
      "Epoch 1486, Loss: 1059.02294921875, Neurons: 11, Grad norm: 1.128e+01\n",
      "Epoch 1487, Loss: 1058.9205322265625, Neurons: 11, Grad norm: 1.127e+01\n",
      "Epoch 1488, Loss: 1058.818115234375, Neurons: 11, Grad norm: 1.126e+01\n",
      "Epoch 1489, Loss: 1058.7158203125, Neurons: 11, Grad norm: 1.126e+01\n",
      "Epoch 1490, Loss: 1058.613525390625, Neurons: 11, Grad norm: 1.125e+01\n",
      "Epoch 1491, Loss: 1058.5113525390625, Neurons: 11, Grad norm: 1.124e+01\n",
      "Epoch 1492, Loss: 1058.409423828125, Neurons: 11, Grad norm: 1.124e+01\n",
      "Epoch 1493, Loss: 1058.3072509765625, Neurons: 11, Grad norm: 1.123e+01\n",
      "Epoch 1494, Loss: 1058.205322265625, Neurons: 11, Grad norm: 1.122e+01\n",
      "Epoch 1495, Loss: 1058.1033935546875, Neurons: 11, Grad norm: 1.121e+01\n",
      "Epoch 1496, Loss: 1058.0015869140625, Neurons: 11, Grad norm: 1.121e+01\n",
      "Epoch 1497, Loss: 1057.8997802734375, Neurons: 11, Grad norm: 1.120e+01\n",
      "Epoch 1498, Loss: 1057.7979736328125, Neurons: 11, Grad norm: 1.119e+01\n",
      "Epoch 1499, Loss: 1057.6964111328125, Neurons: 11, Grad norm: 1.118e+01\n",
      "Epoch 1499, Test loss: 1075.5550537109375\n",
      "Epoch 1500, Loss: 1057.5948486328125, Neurons: 11, Grad norm: 1.118e+01\n",
      "Epoch 1501, Loss: 1057.4932861328125, Neurons: 11, Grad norm: 1.117e+01\n",
      "Epoch 1502, Loss: 1057.391845703125, Neurons: 11, Grad norm: 1.116e+01\n",
      "Epoch 1503, Loss: 1057.29052734375, Neurons: 11, Grad norm: 1.116e+01\n",
      "Epoch 1504, Loss: 1057.189208984375, Neurons: 11, Grad norm: 1.115e+01\n",
      "Epoch 1505, Loss: 1057.0880126953125, Neurons: 11, Grad norm: 1.114e+01\n",
      "Epoch 1506, Loss: 1056.98681640625, Neurons: 11, Grad norm: 1.113e+01\n",
      "Epoch 1507, Loss: 1056.8856201171875, Neurons: 11, Grad norm: 1.113e+01\n",
      "Epoch 1508, Loss: 1056.78466796875, Neurons: 11, Grad norm: 1.112e+01\n",
      "Epoch 1509, Loss: 1056.6837158203125, Neurons: 11, Grad norm: 1.111e+01\n",
      "Epoch 1510, Loss: 1056.582763671875, Neurons: 11, Grad norm: 1.111e+01\n",
      "Epoch 1511, Loss: 1056.48193359375, Neurons: 11, Grad norm: 1.110e+01\n",
      "Epoch 1512, Loss: 1056.3812255859375, Neurons: 11, Grad norm: 1.109e+01\n",
      "Epoch 1513, Loss: 1056.2803955078125, Neurons: 11, Grad norm: 1.108e+01\n",
      "Epoch 1514, Loss: 1056.1798095703125, Neurons: 11, Grad norm: 1.108e+01\n",
      "Epoch 1515, Loss: 1056.0792236328125, Neurons: 11, Grad norm: 1.107e+01\n",
      "Epoch 1516, Loss: 1055.9786376953125, Neurons: 11, Grad norm: 1.106e+01\n",
      "Epoch 1517, Loss: 1055.8782958984375, Neurons: 11, Grad norm: 1.106e+01\n",
      "Epoch 1518, Loss: 1055.7779541015625, Neurons: 11, Grad norm: 1.105e+01\n",
      "Epoch 1519, Loss: 1055.6776123046875, Neurons: 11, Grad norm: 1.104e+01\n",
      "Epoch 1520, Loss: 1055.577392578125, Neurons: 11, Grad norm: 1.104e+01\n",
      "Epoch 1521, Loss: 1055.4771728515625, Neurons: 11, Grad norm: 1.103e+01\n",
      "Epoch 1522, Loss: 1055.3770751953125, Neurons: 11, Grad norm: 1.102e+01\n",
      "Epoch 1523, Loss: 1055.277099609375, Neurons: 11, Grad norm: 1.101e+01\n",
      "Epoch 1524, Loss: 1055.1771240234375, Neurons: 11, Grad norm: 1.101e+01\n",
      "Epoch 1525, Loss: 1055.0771484375, Neurons: 11, Grad norm: 1.100e+01\n",
      "Epoch 1526, Loss: 1054.9774169921875, Neurons: 11, Grad norm: 1.099e+01\n",
      "Epoch 1527, Loss: 1054.8775634765625, Neurons: 11, Grad norm: 1.099e+01\n",
      "Epoch 1528, Loss: 1054.77783203125, Neurons: 11, Grad norm: 1.098e+01\n",
      "Epoch 1529, Loss: 1054.67822265625, Neurons: 11, Grad norm: 1.097e+01\n",
      "Epoch 1530, Loss: 1054.57861328125, Neurons: 11, Grad norm: 1.096e+01\n",
      "Epoch 1531, Loss: 1054.4791259765625, Neurons: 11, Grad norm: 1.096e+01\n",
      "Epoch 1532, Loss: 1054.379638671875, Neurons: 11, Grad norm: 1.095e+01\n",
      "Epoch 1533, Loss: 1054.2802734375, Neurons: 11, Grad norm: 1.094e+01\n",
      "Epoch 1534, Loss: 1054.1810302734375, Neurons: 11, Grad norm: 1.094e+01\n",
      "Epoch 1535, Loss: 1054.081787109375, Neurons: 11, Grad norm: 1.093e+01\n",
      "Epoch 1536, Loss: 1053.9825439453125, Neurons: 11, Grad norm: 1.092e+01\n",
      "Epoch 1537, Loss: 1053.8834228515625, Neurons: 11, Grad norm: 1.091e+01\n",
      "Epoch 1538, Loss: 1053.784423828125, Neurons: 11, Grad norm: 1.091e+01\n",
      "Epoch 1539, Loss: 1053.6854248046875, Neurons: 11, Grad norm: 1.090e+01\n",
      "Epoch 1540, Loss: 1053.5865478515625, Neurons: 11, Grad norm: 1.089e+01\n",
      "Epoch 1541, Loss: 1053.48779296875, Neurons: 11, Grad norm: 1.089e+01\n",
      "Epoch 1542, Loss: 1053.388916015625, Neurons: 11, Grad norm: 1.088e+01\n",
      "Epoch 1543, Loss: 1053.290283203125, Neurons: 11, Grad norm: 1.087e+01\n",
      "Epoch 1544, Loss: 1053.1915283203125, Neurons: 11, Grad norm: 1.087e+01\n",
      "Epoch 1545, Loss: 1053.093017578125, Neurons: 11, Grad norm: 1.086e+01\n",
      "Epoch 1546, Loss: 1052.99462890625, Neurons: 11, Grad norm: 1.085e+01\n",
      "Epoch 1547, Loss: 1052.8961181640625, Neurons: 11, Grad norm: 1.084e+01\n",
      "Epoch 1548, Loss: 1052.7977294921875, Neurons: 11, Grad norm: 1.084e+01\n",
      "Epoch 1549, Loss: 1052.699462890625, Neurons: 11, Grad norm: 1.083e+01\n",
      "Epoch 1549, Test loss: 1070.3348388671875\n",
      "Epoch 1550, Loss: 1052.6011962890625, Neurons: 11, Grad norm: 1.082e+01\n",
      "Epoch 1551, Loss: 1052.5029296875, Neurons: 11, Grad norm: 1.082e+01\n",
      "Epoch 1552, Loss: 1052.405029296875, Neurons: 11, Grad norm: 1.081e+01\n",
      "Epoch 1553, Loss: 1052.306884765625, Neurons: 11, Grad norm: 1.080e+01\n",
      "Epoch 1554, Loss: 1052.208984375, Neurons: 11, Grad norm: 1.080e+01\n",
      "Epoch 1555, Loss: 1052.111083984375, Neurons: 11, Grad norm: 1.079e+01\n",
      "Epoch 1556, Loss: 1052.01318359375, Neurons: 11, Grad norm: 1.078e+01\n",
      "Epoch 1557, Loss: 1051.91552734375, Neurons: 11, Grad norm: 1.077e+01\n",
      "Epoch 1558, Loss: 1051.8177490234375, Neurons: 11, Grad norm: 1.077e+01\n",
      "Epoch 1559, Loss: 1051.7200927734375, Neurons: 11, Grad norm: 1.076e+01\n",
      "Epoch 1560, Loss: 1051.62255859375, Neurons: 11, Grad norm: 1.075e+01\n",
      "Epoch 1561, Loss: 1051.5250244140625, Neurons: 11, Grad norm: 1.075e+01\n",
      "Epoch 1562, Loss: 1051.4276123046875, Neurons: 11, Grad norm: 1.074e+01\n",
      "Epoch 1563, Loss: 1051.3302001953125, Neurons: 11, Grad norm: 1.073e+01\n",
      "Epoch 1564, Loss: 1051.2330322265625, Neurons: 11, Grad norm: 1.073e+01\n",
      "Epoch 1565, Loss: 1051.1356201171875, Neurons: 11, Grad norm: 1.072e+01\n",
      "Epoch 1566, Loss: 1051.03857421875, Neurons: 11, Grad norm: 1.071e+01\n",
      "Epoch 1567, Loss: 1050.94140625, Neurons: 11, Grad norm: 1.070e+01\n",
      "Epoch 1568, Loss: 1050.8443603515625, Neurons: 11, Grad norm: 1.070e+01\n",
      "Epoch 1569, Loss: 1050.747314453125, Neurons: 11, Grad norm: 1.069e+01\n",
      "Epoch 1570, Loss: 1050.6505126953125, Neurons: 11, Grad norm: 1.068e+01\n",
      "Epoch 1571, Loss: 1050.5537109375, Neurons: 11, Grad norm: 1.068e+01\n",
      "Epoch 1572, Loss: 1050.4569091796875, Neurons: 11, Grad norm: 1.067e+01\n",
      "Epoch 1573, Loss: 1050.3602294921875, Neurons: 11, Grad norm: 1.066e+01\n",
      "Epoch 1574, Loss: 1050.2635498046875, Neurons: 11, Grad norm: 1.066e+01\n",
      "Epoch 1575, Loss: 1050.1669921875, Neurons: 11, Grad norm: 1.065e+01\n",
      "Epoch 1576, Loss: 1050.0704345703125, Neurons: 11, Grad norm: 1.064e+01\n",
      "Epoch 1577, Loss: 1049.97412109375, Neurons: 11, Grad norm: 1.064e+01\n",
      "Epoch 1578, Loss: 1049.877685546875, Neurons: 11, Grad norm: 1.063e+01\n",
      "Epoch 1579, Loss: 1049.7813720703125, Neurons: 11, Grad norm: 1.062e+01\n",
      "Epoch 1580, Loss: 1049.6851806640625, Neurons: 11, Grad norm: 1.061e+01\n",
      "Epoch 1581, Loss: 1049.5889892578125, Neurons: 11, Grad norm: 1.095e+01\n",
      "Epoch 1582, Loss: 1049.492919921875, Neurons: 11, Grad norm: 1.377e+01\n",
      "Epoch 1583, Loss: 1049.3983154296875, Neurons: 11, Grad norm: 1.060e+01\n",
      "Epoch 1584, Loss: 1049.301025390625, Neurons: 11, Grad norm: 1.060e+01\n",
      "Epoch 1585, Loss: 1049.2052001953125, Neurons: 11, Grad norm: 1.060e+01\n",
      "Epoch 1586, Loss: 1049.1094970703125, Neurons: 11, Grad norm: 1.061e+01\n",
      "Epoch 1587, Loss: 1049.0137939453125, Neurons: 11, Grad norm: 1.061e+01\n",
      "Epoch 1588, Loss: 1048.918212890625, Neurons: 11, Grad norm: 1.060e+01\n",
      "Epoch 1589, Loss: 1048.8226318359375, Neurons: 11, Grad norm: 1.059e+01\n",
      "Epoch 1590, Loss: 1048.72705078125, Neurons: 11, Grad norm: 1.058e+01\n",
      "Epoch 1591, Loss: 1048.63134765625, Neurons: 11, Grad norm: 1.056e+01\n",
      "Epoch 1592, Loss: 1048.5360107421875, Neurons: 11, Grad norm: 1.054e+01\n",
      "Epoch 1593, Loss: 1048.4404296875, Neurons: 11, Grad norm: 1.053e+01\n",
      "Epoch 1594, Loss: 1048.344970703125, Neurons: 11, Grad norm: 1.052e+01\n",
      "Epoch 1595, Loss: 1048.249755859375, Neurons: 11, Grad norm: 1.051e+01\n",
      "Epoch 1596, Loss: 1048.154541015625, Neurons: 11, Grad norm: 1.051e+01\n",
      "Epoch 1597, Loss: 1048.0594482421875, Neurons: 11, Grad norm: 1.050e+01\n",
      "Epoch 1598, Loss: 1047.964599609375, Neurons: 11, Grad norm: 1.050e+01\n",
      "Epoch 1599, Loss: 1047.86962890625, Neurons: 11, Grad norm: 1.050e+01\n",
      "Epoch 1599, Test loss: 1065.2862548828125\n",
      "Epoch 1600, Loss: 1047.7747802734375, Neurons: 11, Grad norm: 1.049e+01\n",
      "Epoch 1601, Loss: 1047.679931640625, Neurons: 11, Grad norm: 1.048e+01\n",
      "Epoch 1602, Loss: 1047.585205078125, Neurons: 11, Grad norm: 1.047e+01\n",
      "Epoch 1603, Loss: 1047.4903564453125, Neurons: 11, Grad norm: 1.046e+01\n",
      "Epoch 1604, Loss: 1047.395751953125, Neurons: 11, Grad norm: 1.045e+01\n",
      "Epoch 1605, Loss: 1047.3011474609375, Neurons: 11, Grad norm: 1.044e+01\n",
      "Epoch 1606, Loss: 1047.20654296875, Neurons: 11, Grad norm: 1.044e+01\n",
      "Epoch 1607, Loss: 1047.1121826171875, Neurons: 11, Grad norm: 1.043e+01\n",
      "Epoch 1608, Loss: 1047.017822265625, Neurons: 11, Grad norm: 1.042e+01\n",
      "Epoch 1609, Loss: 1046.923583984375, Neurons: 11, Grad norm: 1.042e+01\n",
      "Epoch 1610, Loss: 1046.8292236328125, Neurons: 11, Grad norm: 1.041e+01\n",
      "Epoch 1611, Loss: 1046.735107421875, Neurons: 11, Grad norm: 1.041e+01\n",
      "Epoch 1612, Loss: 1046.6409912109375, Neurons: 11, Grad norm: 1.040e+01\n",
      "Epoch 1613, Loss: 1046.5469970703125, Neurons: 11, Grad norm: 1.039e+01\n",
      "Epoch 1614, Loss: 1046.4530029296875, Neurons: 11, Grad norm: 1.038e+01\n",
      "Epoch 1615, Loss: 1046.359130859375, Neurons: 11, Grad norm: 1.038e+01\n",
      "Epoch 1616, Loss: 1046.26513671875, Neurons: 11, Grad norm: 1.037e+01\n",
      "Epoch 1617, Loss: 1046.17138671875, Neurons: 11, Grad norm: 1.036e+01\n",
      "Epoch 1618, Loss: 1046.0777587890625, Neurons: 11, Grad norm: 1.035e+01\n",
      "Epoch 1619, Loss: 1045.9840087890625, Neurons: 11, Grad norm: 1.035e+01\n",
      "Epoch 1620, Loss: 1045.8905029296875, Neurons: 11, Grad norm: 1.034e+01\n",
      "Epoch 1621, Loss: 1045.7969970703125, Neurons: 11, Grad norm: 1.033e+01\n",
      "Epoch 1622, Loss: 1045.70361328125, Neurons: 11, Grad norm: 1.033e+01\n",
      "Epoch 1623, Loss: 1045.6102294921875, Neurons: 11, Grad norm: 1.032e+01\n",
      "Epoch 1624, Loss: 1045.5167236328125, Neurons: 11, Grad norm: 1.031e+01\n",
      "Epoch 1625, Loss: 1045.423583984375, Neurons: 11, Grad norm: 1.031e+01\n",
      "Epoch 1626, Loss: 1045.3304443359375, Neurons: 11, Grad norm: 1.030e+01\n",
      "Epoch 1627, Loss: 1045.2373046875, Neurons: 11, Grad norm: 1.029e+01\n",
      "Epoch 1628, Loss: 1045.1441650390625, Neurons: 11, Grad norm: 1.029e+01\n",
      "Epoch 1629, Loss: 1045.05126953125, Neurons: 11, Grad norm: 1.028e+01\n",
      "Epoch 1630, Loss: 1044.9583740234375, Neurons: 11, Grad norm: 1.027e+01\n",
      "Epoch 1631, Loss: 1044.865478515625, Neurons: 11, Grad norm: 1.027e+01\n",
      "Epoch 1632, Loss: 1044.772705078125, Neurons: 11, Grad norm: 1.026e+01\n",
      "Epoch 1633, Loss: 1044.679931640625, Neurons: 11, Grad norm: 1.025e+01\n",
      "Epoch 1634, Loss: 1044.58740234375, Neurons: 11, Grad norm: 1.025e+01\n",
      "Epoch 1635, Loss: 1044.4947509765625, Neurons: 11, Grad norm: 1.024e+01\n",
      "Epoch 1636, Loss: 1044.4022216796875, Neurons: 11, Grad norm: 1.108e+01\n",
      "Epoch 1637, Loss: 1044.3096923828125, Neurons: 11, Grad norm: 1.329e+01\n",
      "Epoch 1638, Loss: 1044.2196044921875, Neurons: 11, Grad norm: 1.066e+01\n",
      "Epoch 1639, Loss: 1044.125, Neurons: 11, Grad norm: 1.023e+01\n",
      "Epoch 1640, Loss: 1044.032958984375, Neurons: 11, Grad norm: 1.024e+01\n",
      "Epoch 1641, Loss: 1043.94091796875, Neurons: 11, Grad norm: 1.025e+01\n",
      "Epoch 1642, Loss: 1043.84912109375, Neurons: 11, Grad norm: 1.026e+01\n",
      "Epoch 1643, Loss: 1043.7572021484375, Neurons: 11, Grad norm: 1.026e+01\n",
      "Epoch 1644, Loss: 1043.665283203125, Neurons: 11, Grad norm: 1.025e+01\n",
      "Epoch 1645, Loss: 1043.5732421875, Neurons: 11, Grad norm: 1.023e+01\n",
      "Epoch 1646, Loss: 1043.4813232421875, Neurons: 11, Grad norm: 1.021e+01\n",
      "Epoch 1647, Loss: 1043.389404296875, Neurons: 11, Grad norm: 1.019e+01\n",
      "Epoch 1648, Loss: 1043.2974853515625, Neurons: 11, Grad norm: 1.017e+01\n",
      "Epoch 1649, Loss: 1043.20556640625, Neurons: 11, Grad norm: 1.015e+01\n",
      "Epoch 1649, Test loss: 1060.4083251953125\n",
      "Epoch 1650, Loss: 1043.114013671875, Neurons: 11, Grad norm: 1.014e+01\n",
      "Epoch 1651, Loss: 1043.0224609375, Neurons: 11, Grad norm: 1.013e+01\n",
      "Epoch 1652, Loss: 1042.9310302734375, Neurons: 11, Grad norm: 1.013e+01\n",
      "Epoch 1653, Loss: 1042.8397216796875, Neurons: 11, Grad norm: 1.013e+01\n",
      "Epoch 1654, Loss: 1042.7484130859375, Neurons: 11, Grad norm: 1.013e+01\n",
      "Epoch 1655, Loss: 1042.6572265625, Neurons: 11, Grad norm: 1.012e+01\n",
      "Epoch 1656, Loss: 1042.5660400390625, Neurons: 11, Grad norm: 1.012e+01\n",
      "Epoch 1657, Loss: 1042.4747314453125, Neurons: 11, Grad norm: 1.011e+01\n",
      "Epoch 1658, Loss: 1042.3837890625, Neurons: 11, Grad norm: 1.010e+01\n",
      "Epoch 1659, Loss: 1042.292724609375, Neurons: 11, Grad norm: 1.009e+01\n",
      "Epoch 1660, Loss: 1042.2017822265625, Neurons: 11, Grad norm: 1.008e+01\n",
      "Epoch 1661, Loss: 1042.1107177734375, Neurons: 11, Grad norm: 1.007e+01\n",
      "Epoch 1662, Loss: 1042.02001953125, Neurons: 11, Grad norm: 1.006e+01\n",
      "Epoch 1663, Loss: 1041.9293212890625, Neurons: 11, Grad norm: 1.005e+01\n",
      "Epoch 1664, Loss: 1041.838623046875, Neurons: 11, Grad norm: 1.005e+01\n",
      "Epoch 1665, Loss: 1041.7479248046875, Neurons: 11, Grad norm: 1.004e+01\n",
      "Epoch 1666, Loss: 1041.6573486328125, Neurons: 11, Grad norm: 1.004e+01\n",
      "Epoch 1667, Loss: 1041.5670166015625, Neurons: 11, Grad norm: 1.003e+01\n",
      "Epoch 1668, Loss: 1041.4764404296875, Neurons: 11, Grad norm: 1.002e+01\n",
      "Epoch 1669, Loss: 1041.38623046875, Neurons: 11, Grad norm: 1.002e+01\n",
      "Epoch 1670, Loss: 1041.2958984375, Neurons: 11, Grad norm: 1.001e+01\n",
      "Epoch 1671, Loss: 1041.20556640625, Neurons: 11, Grad norm: 1.000e+01\n",
      "Epoch 1672, Loss: 1041.1153564453125, Neurons: 11, Grad norm: 9.995e+00\n",
      "Epoch 1673, Loss: 1041.025390625, Neurons: 11, Grad norm: 9.988e+00\n",
      "Epoch 1674, Loss: 1040.9354248046875, Neurons: 11, Grad norm: 9.981e+00\n",
      "Epoch 1675, Loss: 1040.8453369140625, Neurons: 11, Grad norm: 9.974e+00\n",
      "Epoch 1676, Loss: 1040.7554931640625, Neurons: 11, Grad norm: 9.967e+00\n",
      "Epoch 1677, Loss: 1040.6656494140625, Neurons: 11, Grad norm: 9.960e+00\n",
      "Epoch 1678, Loss: 1040.5758056640625, Neurons: 11, Grad norm: 9.954e+00\n",
      "Epoch 1679, Loss: 1040.4862060546875, Neurons: 11, Grad norm: 9.948e+00\n",
      "Epoch 1680, Loss: 1040.3966064453125, Neurons: 11, Grad norm: 9.942e+00\n",
      "Epoch 1681, Loss: 1040.3070068359375, Neurons: 11, Grad norm: 9.935e+00\n",
      "Epoch 1682, Loss: 1040.2174072265625, Neurons: 11, Grad norm: 9.928e+00\n",
      "Epoch 1683, Loss: 1040.1279296875, Neurons: 11, Grad norm: 9.921e+00\n",
      "Epoch 1684, Loss: 1040.0386962890625, Neurons: 11, Grad norm: 9.915e+00\n",
      "Epoch 1685, Loss: 1039.9493408203125, Neurons: 11, Grad norm: 9.908e+00\n",
      "Epoch 1686, Loss: 1039.8599853515625, Neurons: 11, Grad norm: 9.901e+00\n",
      "Epoch 1687, Loss: 1039.7708740234375, Neurons: 11, Grad norm: 9.894e+00\n",
      "Epoch 1688, Loss: 1039.6817626953125, Neurons: 11, Grad norm: 9.888e+00\n",
      "Epoch 1689, Loss: 1039.5927734375, Neurons: 11, Grad norm: 9.882e+00\n",
      "Epoch 1690, Loss: 1039.5037841796875, Neurons: 11, Grad norm: 9.875e+00\n",
      "Epoch 1691, Loss: 1039.414794921875, Neurons: 11, Grad norm: 9.869e+00\n",
      "Epoch 1692, Loss: 1039.325927734375, Neurons: 11, Grad norm: 9.862e+00\n",
      "Epoch 1693, Loss: 1039.2371826171875, Neurons: 11, Grad norm: 9.856e+00\n",
      "Epoch 1694, Loss: 1039.1483154296875, Neurons: 11, Grad norm: 9.849e+00\n",
      "Epoch 1695, Loss: 1039.059814453125, Neurons: 11, Grad norm: 9.843e+00\n",
      "Epoch 1696, Loss: 1038.97119140625, Neurons: 11, Grad norm: 9.836e+00\n",
      "Epoch 1697, Loss: 1038.882568359375, Neurons: 11, Grad norm: 9.829e+00\n",
      "Epoch 1698, Loss: 1038.794189453125, Neurons: 11, Grad norm: 9.823e+00\n",
      "Epoch 1699, Loss: 1038.705810546875, Neurons: 11, Grad norm: 9.816e+00\n",
      "Epoch 1699, Test loss: 1055.69970703125\n",
      "Epoch 1700, Loss: 1038.617431640625, Neurons: 11, Grad norm: 9.810e+00\n",
      "Epoch 1701, Loss: 1038.5291748046875, Neurons: 11, Grad norm: 9.803e+00\n",
      "Epoch 1702, Loss: 1038.44091796875, Neurons: 11, Grad norm: 1.009e+01\n",
      "Epoch 1703, Loss: 1038.3526611328125, Neurons: 11, Grad norm: 1.277e+01\n",
      "Epoch 1704, Loss: 1038.2659912109375, Neurons: 11, Grad norm: 9.784e+00\n",
      "Epoch 1705, Loss: 1038.1766357421875, Neurons: 11, Grad norm: 9.785e+00\n",
      "Epoch 1706, Loss: 1038.0888671875, Neurons: 11, Grad norm: 9.790e+00\n",
      "Epoch 1707, Loss: 1038.0009765625, Neurons: 11, Grad norm: 9.795e+00\n",
      "Epoch 1708, Loss: 1037.913330078125, Neurons: 11, Grad norm: 9.796e+00\n",
      "Epoch 1709, Loss: 1037.82568359375, Neurons: 11, Grad norm: 9.791e+00\n",
      "Epoch 1710, Loss: 1037.7379150390625, Neurons: 11, Grad norm: 9.783e+00\n",
      "Epoch 1711, Loss: 1037.650390625, Neurons: 11, Grad norm: 9.770e+00\n",
      "Epoch 1712, Loss: 1037.562744140625, Neurons: 11, Grad norm: 9.755e+00\n",
      "Epoch 1713, Loss: 1037.4752197265625, Neurons: 11, Grad norm: 9.740e+00\n",
      "Epoch 1714, Loss: 1037.3876953125, Neurons: 11, Grad norm: 9.726e+00\n",
      "Epoch 1715, Loss: 1037.3001708984375, Neurons: 11, Grad norm: 9.714e+00\n",
      "Epoch 1716, Loss: 1037.2127685546875, Neurons: 11, Grad norm: 9.706e+00\n",
      "Epoch 1717, Loss: 1037.1256103515625, Neurons: 11, Grad norm: 9.701e+00\n",
      "Epoch 1718, Loss: 1037.0384521484375, Neurons: 11, Grad norm: 9.697e+00\n",
      "Epoch 1719, Loss: 1036.951416015625, Neurons: 11, Grad norm: 9.693e+00\n",
      "Epoch 1720, Loss: 1036.8643798828125, Neurons: 11, Grad norm: 9.689e+00\n",
      "Epoch 1721, Loss: 1036.77734375, Neurons: 11, Grad norm: 9.684e+00\n",
      "Epoch 1722, Loss: 1036.6904296875, Neurons: 11, Grad norm: 9.678e+00\n",
      "Epoch 1723, Loss: 1036.6036376953125, Neurons: 11, Grad norm: 9.671e+00\n",
      "Epoch 1724, Loss: 1036.5167236328125, Neurons: 11, Grad norm: 9.662e+00\n",
      "Epoch 1725, Loss: 1036.4300537109375, Neurons: 11, Grad norm: 9.653e+00\n",
      "Epoch 1726, Loss: 1036.3433837890625, Neurons: 11, Grad norm: 9.644e+00\n",
      "Epoch 1727, Loss: 1036.2567138671875, Neurons: 11, Grad norm: 9.636e+00\n",
      "Epoch 1728, Loss: 1036.170166015625, Neurons: 11, Grad norm: 9.629e+00\n",
      "Epoch 1729, Loss: 1036.083740234375, Neurons: 11, Grad norm: 9.623e+00\n",
      "Epoch 1730, Loss: 1035.997314453125, Neurons: 11, Grad norm: 9.617e+00\n",
      "Epoch 1731, Loss: 1035.9110107421875, Neurons: 11, Grad norm: 9.611e+00\n",
      "Epoch 1732, Loss: 1035.82470703125, Neurons: 11, Grad norm: 9.606e+00\n",
      "Epoch 1733, Loss: 1035.738525390625, Neurons: 11, Grad norm: 9.600e+00\n",
      "Epoch 1734, Loss: 1035.6522216796875, Neurons: 11, Grad norm: 9.594e+00\n",
      "Epoch 1735, Loss: 1035.566162109375, Neurons: 11, Grad norm: 9.587e+00\n",
      "Epoch 1736, Loss: 1035.480224609375, Neurons: 11, Grad norm: 9.580e+00\n",
      "Epoch 1737, Loss: 1035.394287109375, Neurons: 11, Grad norm: 9.574e+00\n",
      "Epoch 1738, Loss: 1035.308349609375, Neurons: 11, Grad norm: 9.567e+00\n",
      "Epoch 1739, Loss: 1035.2225341796875, Neurons: 11, Grad norm: 9.560e+00\n",
      "Epoch 1740, Loss: 1035.13671875, Neurons: 11, Grad norm: 9.553e+00\n",
      "Epoch 1741, Loss: 1035.051025390625, Neurons: 11, Grad norm: 9.546e+00\n",
      "Epoch 1742, Loss: 1034.96533203125, Neurons: 11, Grad norm: 9.540e+00\n",
      "Epoch 1743, Loss: 1034.8797607421875, Neurons: 11, Grad norm: 9.534e+00\n",
      "Epoch 1744, Loss: 1034.79443359375, Neurons: 11, Grad norm: 9.528e+00\n",
      "Epoch 1745, Loss: 1034.708740234375, Neurons: 11, Grad norm: 9.521e+00\n",
      "Epoch 1746, Loss: 1034.6234130859375, Neurons: 11, Grad norm: 9.515e+00\n",
      "Epoch 1747, Loss: 1034.5382080078125, Neurons: 11, Grad norm: 9.509e+00\n",
      "Epoch 1748, Loss: 1034.452880859375, Neurons: 11, Grad norm: 9.502e+00\n",
      "Epoch 1749, Loss: 1034.3675537109375, Neurons: 11, Grad norm: 9.496e+00\n",
      "Epoch 1749, Test loss: 1051.15771484375\n",
      "Epoch 1750, Loss: 1034.2825927734375, Neurons: 11, Grad norm: 9.489e+00\n",
      "Epoch 1751, Loss: 1034.197509765625, Neurons: 11, Grad norm: 9.483e+00\n",
      "Epoch 1752, Loss: 1034.1124267578125, Neurons: 11, Grad norm: 9.477e+00\n",
      "Epoch 1753, Loss: 1034.0274658203125, Neurons: 11, Grad norm: 9.470e+00\n",
      "Epoch 1754, Loss: 1033.942626953125, Neurons: 11, Grad norm: 9.464e+00\n",
      "Epoch 1755, Loss: 1033.8577880859375, Neurons: 11, Grad norm: 9.458e+00\n",
      "Epoch 1756, Loss: 1033.7730712890625, Neurons: 11, Grad norm: 9.452e+00\n",
      "Epoch 1757, Loss: 1033.6883544921875, Neurons: 11, Grad norm: 9.445e+00\n",
      "Epoch 1758, Loss: 1033.603759765625, Neurons: 11, Grad norm: 9.439e+00\n",
      "Epoch 1759, Loss: 1033.5191650390625, Neurons: 11, Grad norm: 9.433e+00\n",
      "Epoch 1760, Loss: 1033.4345703125, Neurons: 11, Grad norm: 9.426e+00\n",
      "Epoch 1761, Loss: 1033.3502197265625, Neurons: 11, Grad norm: 9.420e+00\n",
      "Epoch 1762, Loss: 1033.265869140625, Neurons: 11, Grad norm: 1.053e+01\n",
      "Epoch 1763, Loss: 1033.1815185546875, Neurons: 11, Grad norm: 1.233e+01\n",
      "Epoch 1764, Loss: 1033.099609375, Neurons: 11, Grad norm: 1.222e+01\n",
      "Epoch 1765, Loss: 1033.0137939453125, Neurons: 11, Grad norm: 9.411e+00\n",
      "Epoch 1766, Loss: 1032.92919921875, Neurons: 11, Grad norm: 9.438e+00\n",
      "Epoch 1767, Loss: 1032.845458984375, Neurons: 11, Grad norm: 9.477e+00\n",
      "Epoch 1768, Loss: 1032.76171875, Neurons: 11, Grad norm: 9.510e+00\n",
      "Epoch 1769, Loss: 1032.67822265625, Neurons: 11, Grad norm: 9.520e+00\n",
      "Epoch 1770, Loss: 1032.5946044921875, Neurons: 11, Grad norm: 9.518e+00\n",
      "Epoch 1771, Loss: 1032.5107421875, Neurons: 11, Grad norm: 9.496e+00\n",
      "Epoch 1772, Loss: 1032.427001953125, Neurons: 11, Grad norm: 9.465e+00\n",
      "Epoch 1773, Loss: 1032.343017578125, Neurons: 11, Grad norm: 9.428e+00\n",
      "Epoch 1774, Loss: 1032.259033203125, Neurons: 11, Grad norm: 9.386e+00\n",
      "Epoch 1775, Loss: 1032.17529296875, Neurons: 11, Grad norm: 9.354e+00\n",
      "Epoch 1776, Loss: 1032.091552734375, Neurons: 11, Grad norm: 9.332e+00\n",
      "Epoch 1777, Loss: 1032.0079345703125, Neurons: 11, Grad norm: 9.322e+00\n",
      "Epoch 1778, Loss: 1031.924560546875, Neurons: 11, Grad norm: 9.321e+00\n",
      "Epoch 1779, Loss: 1031.8414306640625, Neurons: 11, Grad norm: 9.321e+00\n",
      "Epoch 1780, Loss: 1031.7581787109375, Neurons: 11, Grad norm: 9.325e+00\n",
      "Epoch 1781, Loss: 1031.6751708984375, Neurons: 11, Grad norm: 9.328e+00\n",
      "Epoch 1782, Loss: 1031.592041015625, Neurons: 11, Grad norm: 9.328e+00\n",
      "Epoch 1783, Loss: 1031.509033203125, Neurons: 11, Grad norm: 9.323e+00\n",
      "Epoch 1784, Loss: 1031.426025390625, Neurons: 11, Grad norm: 9.312e+00\n",
      "Epoch 1785, Loss: 1031.343017578125, Neurons: 11, Grad norm: 9.298e+00\n",
      "Epoch 1786, Loss: 1031.2601318359375, Neurons: 11, Grad norm: 9.284e+00\n",
      "Epoch 1787, Loss: 1031.17724609375, Neurons: 11, Grad norm: 9.270e+00\n",
      "Epoch 1788, Loss: 1031.094482421875, Neurons: 11, Grad norm: 9.258e+00\n",
      "Epoch 1789, Loss: 1031.01171875, Neurons: 11, Grad norm: 9.247e+00\n",
      "Epoch 1790, Loss: 1030.9290771484375, Neurons: 11, Grad norm: 9.239e+00\n",
      "Epoch 1791, Loss: 1030.8465576171875, Neurons: 11, Grad norm: 9.234e+00\n",
      "Epoch 1792, Loss: 1030.7640380859375, Neurons: 11, Grad norm: 9.231e+00\n",
      "Epoch 1793, Loss: 1030.6815185546875, Neurons: 11, Grad norm: 9.229e+00\n",
      "Epoch 1794, Loss: 1030.5992431640625, Neurons: 11, Grad norm: 9.224e+00\n",
      "Epoch 1795, Loss: 1030.5169677734375, Neurons: 11, Grad norm: 9.219e+00\n",
      "Epoch 1796, Loss: 1030.434814453125, Neurons: 11, Grad norm: 9.213e+00\n",
      "Epoch 1797, Loss: 1030.3525390625, Neurons: 11, Grad norm: 9.207e+00\n",
      "Epoch 1798, Loss: 1030.2703857421875, Neurons: 11, Grad norm: 9.199e+00\n",
      "Epoch 1799, Loss: 1030.1883544921875, Neurons: 11, Grad norm: 9.190e+00\n",
      "Epoch 1799, Test loss: 1046.7794189453125\n",
      "Epoch 1800, Loss: 1030.1063232421875, Neurons: 11, Grad norm: 9.181e+00\n",
      "Epoch 1801, Loss: 1030.0244140625, Neurons: 11, Grad norm: 9.173e+00\n",
      "Epoch 1802, Loss: 1029.9425048828125, Neurons: 11, Grad norm: 9.166e+00\n",
      "Epoch 1803, Loss: 1029.8607177734375, Neurons: 11, Grad norm: 9.160e+00\n",
      "Epoch 1804, Loss: 1029.7789306640625, Neurons: 11, Grad norm: 9.154e+00\n",
      "Epoch 1805, Loss: 1029.697265625, Neurons: 11, Grad norm: 9.148e+00\n",
      "Epoch 1806, Loss: 1029.6156005859375, Neurons: 11, Grad norm: 9.143e+00\n",
      "Epoch 1807, Loss: 1029.533935546875, Neurons: 11, Grad norm: 9.138e+00\n",
      "Epoch 1808, Loss: 1029.4525146484375, Neurons: 11, Grad norm: 9.132e+00\n",
      "Epoch 1809, Loss: 1029.3712158203125, Neurons: 11, Grad norm: 9.125e+00\n",
      "Epoch 1810, Loss: 1029.289794921875, Neurons: 11, Grad norm: 9.119e+00\n",
      "Epoch 1811, Loss: 1029.20849609375, Neurons: 11, Grad norm: 9.112e+00\n",
      "Epoch 1812, Loss: 1029.127197265625, Neurons: 11, Grad norm: 9.106e+00\n",
      "Epoch 1813, Loss: 1029.0460205078125, Neurons: 11, Grad norm: 9.099e+00\n",
      "Epoch 1814, Loss: 1028.9647216796875, Neurons: 11, Grad norm: 9.093e+00\n",
      "Epoch 1815, Loss: 1028.8837890625, Neurons: 11, Grad norm: 9.086e+00\n",
      "Epoch 1816, Loss: 1028.802734375, Neurons: 11, Grad norm: 9.080e+00\n",
      "Epoch 1817, Loss: 1028.721923828125, Neurons: 11, Grad norm: 9.075e+00\n",
      "Epoch 1818, Loss: 1028.6409912109375, Neurons: 11, Grad norm: 9.069e+00\n",
      "Epoch 1819, Loss: 1028.56005859375, Neurons: 11, Grad norm: 9.063e+00\n",
      "Epoch 1820, Loss: 1028.4793701171875, Neurons: 11, Grad norm: 9.057e+00\n",
      "Epoch 1821, Loss: 1028.3985595703125, Neurons: 11, Grad norm: 9.051e+00\n",
      "Epoch 1822, Loss: 1028.3179931640625, Neurons: 11, Grad norm: 9.045e+00\n",
      "Epoch 1823, Loss: 1028.2374267578125, Neurons: 11, Grad norm: 9.038e+00\n",
      "Epoch 1824, Loss: 1028.1568603515625, Neurons: 11, Grad norm: 9.032e+00\n",
      "Epoch 1825, Loss: 1028.076416015625, Neurons: 11, Grad norm: 9.026e+00\n",
      "Epoch 1826, Loss: 1027.99609375, Neurons: 11, Grad norm: 9.020e+00\n",
      "Epoch 1827, Loss: 1027.9156494140625, Neurons: 11, Grad norm: 9.014e+00\n",
      "Epoch 1828, Loss: 1027.8353271484375, Neurons: 11, Grad norm: 9.008e+00\n",
      "Epoch 1829, Loss: 1027.755126953125, Neurons: 11, Grad norm: 9.001e+00\n",
      "Epoch 1830, Loss: 1027.6749267578125, Neurons: 11, Grad norm: 8.996e+00\n",
      "Epoch 1831, Loss: 1027.594970703125, Neurons: 11, Grad norm: 8.990e+00\n",
      "Epoch 1832, Loss: 1027.514892578125, Neurons: 11, Grad norm: 8.984e+00\n",
      "Epoch 1833, Loss: 1027.4349365234375, Neurons: 11, Grad norm: 8.978e+00\n",
      "Epoch 1834, Loss: 1027.35498046875, Neurons: 11, Grad norm: 8.972e+00\n",
      "Epoch 1835, Loss: 1027.275146484375, Neurons: 11, Grad norm: 8.966e+00\n",
      "Epoch 1836, Loss: 1027.1954345703125, Neurons: 11, Grad norm: 8.960e+00\n",
      "Epoch 1837, Loss: 1027.11572265625, Neurons: 11, Grad norm: 8.954e+00\n",
      "Epoch 1838, Loss: 1027.0360107421875, Neurons: 11, Grad norm: 8.947e+00\n",
      "Epoch 1839, Loss: 1026.9564208984375, Neurons: 11, Grad norm: 8.941e+00\n",
      "Epoch 1840, Loss: 1026.8768310546875, Neurons: 11, Grad norm: 8.936e+00\n",
      "Epoch 1841, Loss: 1026.79736328125, Neurons: 11, Grad norm: 8.929e+00\n",
      "Epoch 1842, Loss: 1026.718017578125, Neurons: 11, Grad norm: 8.923e+00\n",
      "Epoch 1843, Loss: 1026.6385498046875, Neurons: 11, Grad norm: 8.917e+00\n",
      "Epoch 1844, Loss: 1026.559326171875, Neurons: 11, Grad norm: 8.912e+00\n",
      "Epoch 1845, Loss: 1026.47998046875, Neurons: 11, Grad norm: 8.906e+00\n",
      "Epoch 1846, Loss: 1026.40087890625, Neurons: 11, Grad norm: 8.900e+00\n",
      "Epoch 1847, Loss: 1026.32177734375, Neurons: 11, Grad norm: 8.894e+00\n",
      "Epoch 1848, Loss: 1026.2425537109375, Neurons: 11, Grad norm: 8.888e+00\n",
      "Epoch 1849, Loss: 1026.163818359375, Neurons: 11, Grad norm: 8.882e+00\n",
      "Epoch 1849, Test loss: 1042.5609130859375\n",
      "Epoch 1850, Loss: 1026.084716796875, Neurons: 11, Grad norm: 8.876e+00\n",
      "Epoch 1851, Loss: 1026.005859375, Neurons: 11, Grad norm: 8.870e+00\n",
      "Epoch 1852, Loss: 1025.927001953125, Neurons: 11, Grad norm: 8.864e+00\n",
      "Epoch 1853, Loss: 1025.8482666015625, Neurons: 11, Grad norm: 8.858e+00\n",
      "Epoch 1854, Loss: 1025.76953125, Neurons: 11, Grad norm: 8.852e+00\n",
      "Epoch 1855, Loss: 1025.69091796875, Neurons: 11, Grad norm: 8.846e+00\n",
      "Epoch 1856, Loss: 1025.6124267578125, Neurons: 11, Grad norm: 8.840e+00\n",
      "Epoch 1857, Loss: 1025.5338134765625, Neurons: 11, Grad norm: 8.834e+00\n",
      "Epoch 1858, Loss: 1025.455322265625, Neurons: 11, Grad norm: 8.828e+00\n",
      "Epoch 1859, Loss: 1025.3770751953125, Neurons: 11, Grad norm: 8.822e+00\n",
      "Epoch 1860, Loss: 1025.2987060546875, Neurons: 11, Grad norm: 8.816e+00\n",
      "Epoch 1861, Loss: 1025.2203369140625, Neurons: 11, Grad norm: 8.811e+00\n",
      "Epoch 1862, Loss: 1025.1422119140625, Neurons: 11, Grad norm: 8.805e+00\n",
      "Epoch 1863, Loss: 1025.06396484375, Neurons: 11, Grad norm: 8.799e+00\n",
      "Epoch 1864, Loss: 1024.98583984375, Neurons: 11, Grad norm: 8.793e+00\n",
      "Epoch 1865, Loss: 1024.9078369140625, Neurons: 11, Grad norm: 8.787e+00\n",
      "Epoch 1866, Loss: 1024.8299560546875, Neurons: 11, Grad norm: 8.781e+00\n",
      "Epoch 1867, Loss: 1024.751953125, Neurons: 11, Grad norm: 8.775e+00\n",
      "Epoch 1868, Loss: 1024.6741943359375, Neurons: 11, Grad norm: 8.769e+00\n",
      "Epoch 1869, Loss: 1024.5963134765625, Neurons: 11, Grad norm: 8.763e+00\n",
      "Epoch 1870, Loss: 1024.5185546875, Neurons: 11, Grad norm: 8.757e+00\n",
      "Epoch 1871, Loss: 1024.44091796875, Neurons: 11, Grad norm: 8.752e+00\n",
      "Epoch 1872, Loss: 1024.36328125, Neurons: 11, Grad norm: 8.746e+00\n",
      "Epoch 1873, Loss: 1024.2857666015625, Neurons: 11, Grad norm: 8.740e+00\n",
      "Epoch 1874, Loss: 1024.2081298828125, Neurons: 11, Grad norm: 8.734e+00\n",
      "Epoch 1875, Loss: 1024.1307373046875, Neurons: 11, Grad norm: 8.728e+00\n",
      "Epoch 1876, Loss: 1024.0533447265625, Neurons: 11, Grad norm: 8.722e+00\n",
      "Epoch 1877, Loss: 1023.97607421875, Neurons: 11, Grad norm: 8.716e+00\n",
      "Epoch 1878, Loss: 1023.8988037109375, Neurons: 11, Grad norm: 8.711e+00\n",
      "Epoch 1879, Loss: 1023.8216552734375, Neurons: 11, Grad norm: 8.705e+00\n",
      "Epoch 1880, Loss: 1023.7444458007812, Neurons: 11, Grad norm: 8.699e+00\n",
      "Epoch 1881, Loss: 1023.6673583984375, Neurons: 11, Grad norm: 8.693e+00\n",
      "Epoch 1882, Loss: 1023.5903930664062, Neurons: 11, Grad norm: 8.687e+00\n",
      "Epoch 1883, Loss: 1023.5133666992188, Neurons: 11, Grad norm: 8.683e+00\n",
      "Epoch 1884, Loss: 1023.4365844726562, Neurons: 11, Grad norm: 8.745e+00\n",
      "Epoch 1885, Loss: 1023.3595581054688, Neurons: 11, Grad norm: 1.132e+01\n",
      "Epoch 1886, Loss: 1023.283203125, Neurons: 11, Grad norm: 8.669e+00\n",
      "Epoch 1887, Loss: 1023.2061767578125, Neurons: 11, Grad norm: 8.678e+00\n",
      "Epoch 1888, Loss: 1023.1296997070312, Neurons: 11, Grad norm: 8.693e+00\n",
      "Epoch 1889, Loss: 1023.0531616210938, Neurons: 11, Grad norm: 8.703e+00\n",
      "Epoch 1890, Loss: 1022.9767456054688, Neurons: 11, Grad norm: 8.704e+00\n",
      "Epoch 1891, Loss: 1022.900390625, Neurons: 11, Grad norm: 8.699e+00\n",
      "Epoch 1892, Loss: 1022.823974609375, Neurons: 11, Grad norm: 8.687e+00\n",
      "Epoch 1893, Loss: 1022.7474975585938, Neurons: 11, Grad norm: 8.669e+00\n",
      "Epoch 1894, Loss: 1022.6710815429688, Neurons: 11, Grad norm: 8.647e+00\n",
      "Epoch 1895, Loss: 1022.5947875976562, Neurons: 11, Grad norm: 8.627e+00\n",
      "Epoch 1896, Loss: 1022.5183715820312, Neurons: 11, Grad norm: 8.612e+00\n",
      "Epoch 1897, Loss: 1022.4421997070312, Neurons: 11, Grad norm: 8.603e+00\n",
      "Epoch 1898, Loss: 1022.3660888671875, Neurons: 11, Grad norm: 8.595e+00\n",
      "Epoch 1899, Loss: 1022.2899780273438, Neurons: 11, Grad norm: 8.592e+00\n",
      "Epoch 1899, Test loss: 1038.49853515625\n",
      "Epoch 1900, Loss: 1022.2141723632812, Neurons: 11, Grad norm: 8.591e+00\n",
      "Epoch 1901, Loss: 1022.1382446289062, Neurons: 11, Grad norm: 8.591e+00\n",
      "Epoch 1902, Loss: 1022.0625, Neurons: 11, Grad norm: 8.588e+00\n",
      "Epoch 1903, Loss: 1021.9867553710938, Neurons: 11, Grad norm: 8.583e+00\n",
      "Epoch 1904, Loss: 1021.9109497070312, Neurons: 11, Grad norm: 8.576e+00\n",
      "Epoch 1905, Loss: 1021.8353881835938, Neurons: 11, Grad norm: 8.567e+00\n",
      "Epoch 1906, Loss: 1021.7597045898438, Neurons: 11, Grad norm: 8.558e+00\n",
      "Epoch 1907, Loss: 1021.6842041015625, Neurons: 11, Grad norm: 8.548e+00\n",
      "Epoch 1908, Loss: 1021.6085815429688, Neurons: 11, Grad norm: 8.539e+00\n",
      "Epoch 1909, Loss: 1021.5330810546875, Neurons: 11, Grad norm: 8.532e+00\n",
      "Epoch 1910, Loss: 1021.457763671875, Neurons: 11, Grad norm: 8.526e+00\n",
      "Epoch 1911, Loss: 1021.3823852539062, Neurons: 11, Grad norm: 8.520e+00\n",
      "Epoch 1912, Loss: 1021.3071899414062, Neurons: 11, Grad norm: 8.516e+00\n",
      "Epoch 1913, Loss: 1021.2319946289062, Neurons: 11, Grad norm: 8.512e+00\n",
      "Epoch 1914, Loss: 1021.1567993164062, Neurons: 11, Grad norm: 8.508e+00\n",
      "Epoch 1915, Loss: 1021.081787109375, Neurons: 11, Grad norm: 8.502e+00\n",
      "Epoch 1916, Loss: 1021.0067749023438, Neurons: 11, Grad norm: 8.496e+00\n",
      "Epoch 1917, Loss: 1020.9317626953125, Neurons: 11, Grad norm: 8.490e+00\n",
      "Epoch 1918, Loss: 1020.8567504882812, Neurons: 11, Grad norm: 8.483e+00\n",
      "Epoch 1919, Loss: 1020.781982421875, Neurons: 11, Grad norm: 8.476e+00\n",
      "Epoch 1920, Loss: 1020.7071533203125, Neurons: 11, Grad norm: 8.469e+00\n",
      "Epoch 1921, Loss: 1020.6323852539062, Neurons: 11, Grad norm: 8.463e+00\n",
      "Epoch 1922, Loss: 1020.5578002929688, Neurons: 11, Grad norm: 8.457e+00\n",
      "Epoch 1923, Loss: 1020.483154296875, Neurons: 11, Grad norm: 8.451e+00\n",
      "Epoch 1924, Loss: 1020.4085693359375, Neurons: 11, Grad norm: 8.446e+00\n",
      "Epoch 1925, Loss: 1020.3340454101562, Neurons: 11, Grad norm: 8.441e+00\n",
      "Epoch 1926, Loss: 1020.2595825195312, Neurons: 11, Grad norm: 8.435e+00\n",
      "Epoch 1927, Loss: 1020.1851806640625, Neurons: 11, Grad norm: 8.430e+00\n",
      "Epoch 1928, Loss: 1020.1109008789062, Neurons: 11, Grad norm: 8.424e+00\n",
      "Epoch 1929, Loss: 1020.0365600585938, Neurons: 11, Grad norm: 8.418e+00\n",
      "Epoch 1930, Loss: 1019.96240234375, Neurons: 11, Grad norm: 8.413e+00\n",
      "Epoch 1931, Loss: 1019.88818359375, Neurons: 11, Grad norm: 8.407e+00\n",
      "Epoch 1932, Loss: 1019.8141479492188, Neurons: 11, Grad norm: 8.401e+00\n",
      "Epoch 1933, Loss: 1019.739990234375, Neurons: 11, Grad norm: 8.395e+00\n",
      "Epoch 1934, Loss: 1019.6660766601562, Neurons: 11, Grad norm: 8.389e+00\n",
      "Epoch 1935, Loss: 1019.5921630859375, Neurons: 11, Grad norm: 8.384e+00\n",
      "Epoch 1936, Loss: 1019.5182495117188, Neurons: 11, Grad norm: 8.378e+00\n",
      "Epoch 1937, Loss: 1019.4443969726562, Neurons: 11, Grad norm: 8.372e+00\n",
      "Epoch 1938, Loss: 1019.3706665039062, Neurons: 11, Grad norm: 8.367e+00\n",
      "Epoch 1939, Loss: 1019.2969970703125, Neurons: 11, Grad norm: 8.361e+00\n",
      "Epoch 1940, Loss: 1019.223388671875, Neurons: 11, Grad norm: 8.356e+00\n",
      "Epoch 1941, Loss: 1019.1497802734375, Neurons: 11, Grad norm: 8.350e+00\n",
      "Epoch 1942, Loss: 1019.076171875, Neurons: 11, Grad norm: 8.344e+00\n",
      "Epoch 1943, Loss: 1019.0027465820312, Neurons: 11, Grad norm: 8.339e+00\n",
      "Epoch 1944, Loss: 1018.9293823242188, Neurons: 11, Grad norm: 8.333e+00\n",
      "Epoch 1945, Loss: 1018.85595703125, Neurons: 11, Grad norm: 8.327e+00\n",
      "Epoch 1946, Loss: 1018.7826538085938, Neurons: 11, Grad norm: 8.322e+00\n",
      "Epoch 1947, Loss: 1018.7093505859375, Neurons: 11, Grad norm: 8.316e+00\n",
      "Epoch 1948, Loss: 1018.6361694335938, Neurons: 11, Grad norm: 8.311e+00\n",
      "Epoch 1949, Loss: 1018.5630493164062, Neurons: 11, Grad norm: 8.305e+00\n",
      "Epoch 1949, Test loss: 1034.587646484375\n",
      "Epoch 1950, Loss: 1018.489990234375, Neurons: 11, Grad norm: 8.299e+00\n",
      "Epoch 1951, Loss: 1018.4170532226562, Neurons: 11, Grad norm: 8.294e+00\n",
      "Epoch 1952, Loss: 1018.343994140625, Neurons: 11, Grad norm: 8.288e+00\n",
      "Epoch 1953, Loss: 1018.2711791992188, Neurons: 11, Grad norm: 8.283e+00\n",
      "Epoch 1954, Loss: 1018.1983642578125, Neurons: 11, Grad norm: 8.277e+00\n",
      "Epoch 1955, Loss: 1018.12548828125, Neurons: 11, Grad norm: 8.271e+00\n",
      "Epoch 1956, Loss: 1018.0527954101562, Neurons: 11, Grad norm: 8.266e+00\n",
      "Epoch 1957, Loss: 1017.9801635742188, Neurons: 11, Grad norm: 8.260e+00\n",
      "Epoch 1958, Loss: 1017.907470703125, Neurons: 11, Grad norm: 8.255e+00\n",
      "Epoch 1959, Loss: 1017.8349609375, Neurons: 11, Grad norm: 8.249e+00\n",
      "Epoch 1960, Loss: 1017.7623901367188, Neurons: 11, Grad norm: 8.244e+00\n",
      "Epoch 1961, Loss: 1017.6900024414062, Neurons: 11, Grad norm: 8.238e+00\n",
      "Epoch 1962, Loss: 1017.6175537109375, Neurons: 11, Grad norm: 8.233e+00\n",
      "Epoch 1963, Loss: 1017.545166015625, Neurons: 11, Grad norm: 8.227e+00\n",
      "Epoch 1964, Loss: 1017.4729614257812, Neurons: 11, Grad norm: 8.222e+00\n",
      "Epoch 1965, Loss: 1017.4007568359375, Neurons: 11, Grad norm: 8.216e+00\n",
      "Epoch 1966, Loss: 1017.3285522460938, Neurons: 11, Grad norm: 8.211e+00\n",
      "Epoch 1967, Loss: 1017.2564697265625, Neurons: 11, Grad norm: 9.583e+00\n",
      "Epoch 1968, Loss: 1017.1843872070312, Neurons: 11, Grad norm: 1.088e+01\n",
      "Epoch 1969, Loss: 1017.1143798828125, Neurons: 11, Grad norm: 1.078e+01\n",
      "Epoch 1970, Loss: 1017.0415649414062, Neurons: 11, Grad norm: 8.203e+00\n",
      "Epoch 1971, Loss: 1016.9686889648438, Neurons: 11, Grad norm: 8.226e+00\n",
      "Epoch 1972, Loss: 1016.8970947265625, Neurons: 11, Grad norm: 8.271e+00\n",
      "Epoch 1973, Loss: 1016.8255615234375, Neurons: 11, Grad norm: 8.291e+00\n",
      "Epoch 1974, Loss: 1016.754150390625, Neurons: 11, Grad norm: 8.311e+00\n",
      "Epoch 1975, Loss: 1016.6825561523438, Neurons: 11, Grad norm: 8.307e+00\n",
      "Epoch 1976, Loss: 1016.611083984375, Neurons: 11, Grad norm: 8.294e+00\n",
      "Epoch 1977, Loss: 1016.5393676757812, Neurons: 11, Grad norm: 8.253e+00\n",
      "Epoch 1978, Loss: 1016.4676513671875, Neurons: 11, Grad norm: 8.217e+00\n",
      "Epoch 1979, Loss: 1016.3960571289062, Neurons: 11, Grad norm: 8.180e+00\n",
      "Epoch 1980, Loss: 1016.324462890625, Neurons: 11, Grad norm: 8.157e+00\n",
      "Epoch 1981, Loss: 1016.2529907226562, Neurons: 11, Grad norm: 8.132e+00\n",
      "Epoch 1982, Loss: 1016.1817016601562, Neurons: 11, Grad norm: 8.124e+00\n",
      "Epoch 1983, Loss: 1016.1103515625, Neurons: 11, Grad norm: 8.124e+00\n",
      "Epoch 1984, Loss: 1016.0392456054688, Neurons: 11, Grad norm: 8.132e+00\n",
      "Epoch 1985, Loss: 1015.9682006835938, Neurons: 11, Grad norm: 8.134e+00\n",
      "Epoch 1986, Loss: 1015.8972778320312, Neurons: 11, Grad norm: 8.137e+00\n",
      "Epoch 1987, Loss: 1015.8263549804688, Neurons: 11, Grad norm: 8.134e+00\n",
      "Epoch 1988, Loss: 1015.75537109375, Neurons: 11, Grad norm: 8.130e+00\n",
      "Epoch 1989, Loss: 1015.6845703125, Neurons: 11, Grad norm: 8.116e+00\n",
      "Epoch 1990, Loss: 1015.6136474609375, Neurons: 11, Grad norm: 8.103e+00\n",
      "Epoch 1991, Loss: 1015.5428466796875, Neurons: 11, Grad norm: 8.088e+00\n",
      "Epoch 1992, Loss: 1015.4719848632812, Neurons: 11, Grad norm: 8.077e+00\n",
      "Epoch 1993, Loss: 1015.4013671875, Neurons: 11, Grad norm: 8.065e+00\n",
      "Epoch 1994, Loss: 1015.3307495117188, Neurons: 11, Grad norm: 8.057e+00\n",
      "Epoch 1995, Loss: 1015.2601928710938, Neurons: 11, Grad norm: 8.053e+00\n",
      "Epoch 1996, Loss: 1015.189697265625, Neurons: 11, Grad norm: 8.052e+00\n",
      "Epoch 1997, Loss: 1015.1192626953125, Neurons: 11, Grad norm: 8.048e+00\n",
      "Epoch 1998, Loss: 1015.0488891601562, Neurons: 11, Grad norm: 8.045e+00\n",
      "Epoch 1999, Loss: 1014.9785766601562, Neurons: 11, Grad norm: 8.041e+00\n",
      "Epoch 1999, Test loss: 1030.8240966796875\n",
      "Epoch 2000, Loss: 1014.9083862304688, Neurons: 11, Grad norm: 8.038e+00\n",
      "Epoch 2001, Loss: 1014.8380737304688, Neurons: 11, Grad norm: 8.030e+00\n",
      "Epoch 2002, Loss: 1014.7678833007812, Neurons: 11, Grad norm: 8.022e+00\n",
      "Epoch 2003, Loss: 1014.69775390625, Neurons: 11, Grad norm: 8.014e+00\n",
      "Epoch 2004, Loss: 1014.627685546875, Neurons: 11, Grad norm: 8.007e+00\n",
      "Epoch 2005, Loss: 1014.5576782226562, Neurons: 11, Grad norm: 7.999e+00\n",
      "Epoch 2006, Loss: 1014.48779296875, Neurons: 11, Grad norm: 7.993e+00\n",
      "Epoch 2007, Loss: 1014.4177856445312, Neurons: 11, Grad norm: 7.987e+00\n",
      "Epoch 2008, Loss: 1014.3479614257812, Neurons: 11, Grad norm: 7.983e+00\n",
      "Epoch 2009, Loss: 1014.2781982421875, Neurons: 11, Grad norm: 7.978e+00\n",
      "Epoch 2010, Loss: 1014.2085571289062, Neurons: 11, Grad norm: 7.973e+00\n",
      "Epoch 2011, Loss: 1014.1387939453125, Neurons: 11, Grad norm: 7.969e+00\n",
      "Epoch 2012, Loss: 1014.0691528320312, Neurons: 11, Grad norm: 7.964e+00\n",
      "Epoch 2013, Loss: 1013.9996948242188, Neurons: 11, Grad norm: 7.958e+00\n",
      "Epoch 2014, Loss: 1013.93017578125, Neurons: 11, Grad norm: 7.952e+00\n",
      "Epoch 2015, Loss: 1013.8607788085938, Neurons: 11, Grad norm: 7.946e+00\n",
      "Epoch 2016, Loss: 1013.7911987304688, Neurons: 11, Grad norm: 7.940e+00\n",
      "Epoch 2017, Loss: 1013.7219848632812, Neurons: 11, Grad norm: 7.934e+00\n",
      "Epoch 2018, Loss: 1013.652587890625, Neurons: 11, Grad norm: 7.928e+00\n",
      "Epoch 2019, Loss: 1013.5833740234375, Neurons: 11, Grad norm: 7.923e+00\n",
      "Epoch 2020, Loss: 1013.51416015625, Neurons: 11, Grad norm: 7.918e+00\n",
      "Epoch 2021, Loss: 1013.445068359375, Neurons: 11, Grad norm: 7.913e+00\n",
      "Epoch 2022, Loss: 1013.3759765625, Neurons: 11, Grad norm: 7.908e+00\n",
      "Epoch 2023, Loss: 1013.3069458007812, Neurons: 11, Grad norm: 7.903e+00\n",
      "Epoch 2024, Loss: 1013.2380981445312, Neurons: 11, Grad norm: 7.898e+00\n",
      "Epoch 2025, Loss: 1013.169189453125, Neurons: 11, Grad norm: 7.892e+00\n",
      "Epoch 2026, Loss: 1013.1002807617188, Neurons: 11, Grad norm: 7.887e+00\n",
      "Epoch 2027, Loss: 1013.0313720703125, Neurons: 11, Grad norm: 7.881e+00\n",
      "Epoch 2028, Loss: 1012.9627685546875, Neurons: 11, Grad norm: 7.876e+00\n",
      "Epoch 2029, Loss: 1012.8939819335938, Neurons: 11, Grad norm: 7.870e+00\n",
      "Epoch 2030, Loss: 1012.8253784179688, Neurons: 11, Grad norm: 7.865e+00\n",
      "Epoch 2031, Loss: 1012.7567749023438, Neurons: 11, Grad norm: 7.860e+00\n",
      "Epoch 2032, Loss: 1012.6881713867188, Neurons: 11, Grad norm: 7.854e+00\n",
      "Epoch 2033, Loss: 1012.6197509765625, Neurons: 11, Grad norm: 7.849e+00\n",
      "Epoch 2034, Loss: 1012.5513916015625, Neurons: 11, Grad norm: 7.844e+00\n",
      "Epoch 2035, Loss: 1012.4829711914062, Neurons: 11, Grad norm: 7.839e+00\n",
      "Epoch 2036, Loss: 1012.41455078125, Neurons: 11, Grad norm: 7.833e+00\n",
      "Epoch 2037, Loss: 1012.3463745117188, Neurons: 11, Grad norm: 7.828e+00\n",
      "Epoch 2038, Loss: 1012.2781982421875, Neurons: 11, Grad norm: 7.823e+00\n",
      "Epoch 2039, Loss: 1012.2099609375, Neurons: 11, Grad norm: 7.817e+00\n",
      "Epoch 2040, Loss: 1012.141845703125, Neurons: 11, Grad norm: 7.812e+00\n",
      "Epoch 2041, Loss: 1012.0738525390625, Neurons: 11, Grad norm: 7.807e+00\n",
      "Epoch 2042, Loss: 1012.0057983398438, Neurons: 11, Grad norm: 7.802e+00\n",
      "Epoch 2043, Loss: 1011.9378662109375, Neurons: 11, Grad norm: 7.796e+00\n",
      "Epoch 2044, Loss: 1011.8699951171875, Neurons: 11, Grad norm: 7.791e+00\n",
      "Epoch 2045, Loss: 1011.8021850585938, Neurons: 11, Grad norm: 7.786e+00\n",
      "Epoch 2046, Loss: 1011.734375, Neurons: 11, Grad norm: 7.781e+00\n",
      "Epoch 2047, Loss: 1011.6666870117188, Neurons: 11, Grad norm: 7.775e+00\n",
      "Epoch 2048, Loss: 1011.5989990234375, Neurons: 11, Grad norm: 7.770e+00\n",
      "Epoch 2049, Loss: 1011.5313720703125, Neurons: 11, Grad norm: 7.765e+00\n",
      "Epoch 2049, Test loss: 1027.2030029296875\n",
      "Epoch 2050, Loss: 1011.4637451171875, Neurons: 11, Grad norm: 7.760e+00\n",
      "Epoch 2051, Loss: 1011.3963012695312, Neurons: 11, Grad norm: 7.755e+00\n",
      "Epoch 2052, Loss: 1011.3287963867188, Neurons: 11, Grad norm: 7.749e+00\n",
      "Epoch 2053, Loss: 1011.2613525390625, Neurons: 11, Grad norm: 7.744e+00\n",
      "Epoch 2054, Loss: 1011.1939697265625, Neurons: 11, Grad norm: 7.739e+00\n",
      "Epoch 2055, Loss: 1011.1266479492188, Neurons: 11, Grad norm: 7.734e+00\n",
      "Epoch 2056, Loss: 1011.0595703125, Neurons: 11, Grad norm: 7.728e+00\n",
      "Epoch 2057, Loss: 1010.9922485351562, Neurons: 11, Grad norm: 7.723e+00\n",
      "Epoch 2058, Loss: 1010.9251708984375, Neurons: 11, Grad norm: 7.718e+00\n",
      "Epoch 2059, Loss: 1010.8579711914062, Neurons: 11, Grad norm: 7.713e+00\n",
      "Epoch 2060, Loss: 1010.7909545898438, Neurons: 11, Grad norm: 7.708e+00\n",
      "Epoch 2061, Loss: 1010.7239990234375, Neurons: 11, Grad norm: 7.703e+00\n",
      "Epoch 2062, Loss: 1010.6571044921875, Neurons: 11, Grad norm: 7.697e+00\n",
      "Epoch 2063, Loss: 1010.5901489257812, Neurons: 11, Grad norm: 7.692e+00\n",
      "Epoch 2064, Loss: 1010.5233764648438, Neurons: 11, Grad norm: 7.687e+00\n",
      "Epoch 2065, Loss: 1010.4564819335938, Neurons: 11, Grad norm: 7.682e+00\n",
      "Epoch 2066, Loss: 1010.3897705078125, Neurons: 11, Grad norm: 7.677e+00\n",
      "Epoch 2067, Loss: 1010.3231811523438, Neurons: 11, Grad norm: 7.672e+00\n",
      "Epoch 2068, Loss: 1010.256591796875, Neurons: 11, Grad norm: 7.666e+00\n",
      "Epoch 2069, Loss: 1010.1900024414062, Neurons: 11, Grad norm: 7.661e+00\n",
      "Epoch 2070, Loss: 1010.1233520507812, Neurons: 11, Grad norm: 7.656e+00\n",
      "Epoch 2071, Loss: 1010.0569458007812, Neurons: 11, Grad norm: 7.651e+00\n",
      "Epoch 2072, Loss: 1009.9906005859375, Neurons: 11, Grad norm: 7.646e+00\n",
      "Epoch 2073, Loss: 1009.9242553710938, Neurons: 11, Grad norm: 7.641e+00\n",
      "Epoch 2074, Loss: 1009.8578491210938, Neurons: 11, Grad norm: 7.636e+00\n",
      "Epoch 2075, Loss: 1009.7915649414062, Neurons: 11, Grad norm: 7.630e+00\n",
      "Epoch 2076, Loss: 1009.7254028320312, Neurons: 11, Grad norm: 7.625e+00\n",
      "Epoch 2077, Loss: 1009.6591796875, Neurons: 11, Grad norm: 7.620e+00\n",
      "Epoch 2078, Loss: 1009.5932006835938, Neurons: 11, Grad norm: 7.615e+00\n",
      "Epoch 2079, Loss: 1009.5271606445312, Neurons: 11, Grad norm: 7.610e+00\n",
      "Epoch 2080, Loss: 1009.461181640625, Neurons: 11, Grad norm: 7.605e+00\n",
      "Epoch 2081, Loss: 1009.3952026367188, Neurons: 11, Grad norm: 7.600e+00\n",
      "Epoch 2082, Loss: 1009.3292846679688, Neurons: 11, Grad norm: 7.595e+00\n",
      "Epoch 2083, Loss: 1009.2634887695312, Neurons: 11, Grad norm: 7.590e+00\n",
      "Epoch 2084, Loss: 1009.1976928710938, Neurons: 11, Grad norm: 7.584e+00\n",
      "Epoch 2085, Loss: 1009.1319580078125, Neurons: 11, Grad norm: 7.579e+00\n",
      "Epoch 2086, Loss: 1009.0662841796875, Neurons: 11, Grad norm: 7.574e+00\n",
      "Epoch 2087, Loss: 1009.0005493164062, Neurons: 11, Grad norm: 7.569e+00\n",
      "Epoch 2088, Loss: 1008.93505859375, Neurons: 11, Grad norm: 7.564e+00\n",
      "Epoch 2089, Loss: 1008.8695678710938, Neurons: 11, Grad norm: 7.559e+00\n",
      "Epoch 2090, Loss: 1008.803955078125, Neurons: 11, Grad norm: 7.554e+00\n",
      "Epoch 2091, Loss: 1008.7385864257812, Neurons: 11, Grad norm: 7.549e+00\n",
      "Epoch 2092, Loss: 1008.6731567382812, Neurons: 11, Grad norm: 7.544e+00\n",
      "Epoch 2093, Loss: 1008.6078491210938, Neurons: 11, Grad norm: 7.539e+00\n",
      "Epoch 2094, Loss: 1008.5426635742188, Neurons: 11, Grad norm: 7.534e+00\n",
      "Epoch 2095, Loss: 1008.4773559570312, Neurons: 11, Grad norm: 7.529e+00\n",
      "Epoch 2096, Loss: 1008.4121704101562, Neurons: 11, Grad norm: 7.524e+00\n",
      "Epoch 2097, Loss: 1008.3470458984375, Neurons: 11, Grad norm: 7.518e+00\n",
      "Epoch 2098, Loss: 1008.2821044921875, Neurons: 11, Grad norm: 7.515e+00\n",
      "Epoch 2099, Loss: 1008.2171020507812, Neurons: 11, Grad norm: 7.509e+00\n",
      "Epoch 2099, Test loss: 1023.719482421875\n",
      "Epoch 2100, Loss: 1008.152099609375, Neurons: 11, Grad norm: 8.891e+00\n",
      "Epoch 2101, Loss: 1008.087158203125, Neurons: 11, Grad norm: 1.004e+01\n",
      "Epoch 2102, Loss: 1008.0240478515625, Neurons: 11, Grad norm: 9.937e+00\n",
      "Epoch 2103, Loss: 1007.9583740234375, Neurons: 11, Grad norm: 7.502e+00\n",
      "Epoch 2104, Loss: 1007.8927612304688, Neurons: 11, Grad norm: 7.540e+00\n",
      "Epoch 2105, Loss: 1007.8282470703125, Neurons: 11, Grad norm: 7.567e+00\n",
      "Epoch 2106, Loss: 1007.7639770507812, Neurons: 11, Grad norm: 7.604e+00\n",
      "Epoch 2107, Loss: 1007.699462890625, Neurons: 11, Grad norm: 7.615e+00\n",
      "Epoch 2108, Loss: 1007.6351928710938, Neurons: 11, Grad norm: 7.622e+00\n",
      "Epoch 2109, Loss: 1007.570556640625, Neurons: 11, Grad norm: 7.589e+00\n",
      "Epoch 2110, Loss: 1007.506103515625, Neurons: 11, Grad norm: 7.556e+00\n",
      "Epoch 2111, Loss: 1007.4414672851562, Neurons: 11, Grad norm: 7.523e+00\n",
      "Epoch 2112, Loss: 1007.376953125, Neurons: 11, Grad norm: 7.482e+00\n",
      "Epoch 2113, Loss: 1007.3125610351562, Neurons: 11, Grad norm: 7.453e+00\n",
      "Epoch 2114, Loss: 1007.2481689453125, Neurons: 11, Grad norm: 7.435e+00\n",
      "Epoch 2115, Loss: 1007.1837768554688, Neurons: 11, Grad norm: 7.437e+00\n",
      "Epoch 2116, Loss: 1007.1196899414062, Neurons: 11, Grad norm: 7.432e+00\n",
      "Epoch 2117, Loss: 1007.0556030273438, Neurons: 11, Grad norm: 7.440e+00\n",
      "Epoch 2118, Loss: 1006.9915771484375, Neurons: 11, Grad norm: 7.448e+00\n",
      "Epoch 2119, Loss: 1006.9276733398438, Neurons: 11, Grad norm: 7.449e+00\n",
      "Epoch 2120, Loss: 1006.86376953125, Neurons: 11, Grad norm: 7.446e+00\n",
      "Epoch 2121, Loss: 1006.7998657226562, Neurons: 11, Grad norm: 7.436e+00\n",
      "Epoch 2122, Loss: 1006.736083984375, Neurons: 11, Grad norm: 7.427e+00\n",
      "Epoch 2123, Loss: 1006.6723022460938, Neurons: 11, Grad norm: 7.409e+00\n",
      "Epoch 2124, Loss: 1006.6084594726562, Neurons: 11, Grad norm: 7.395e+00\n",
      "Epoch 2125, Loss: 1006.544677734375, Neurons: 11, Grad norm: 7.385e+00\n",
      "Epoch 2126, Loss: 1006.4810791015625, Neurons: 11, Grad norm: 7.375e+00\n",
      "Epoch 2127, Loss: 1006.4173583984375, Neurons: 11, Grad norm: 7.369e+00\n",
      "Epoch 2128, Loss: 1006.3538818359375, Neurons: 11, Grad norm: 7.366e+00\n",
      "Epoch 2129, Loss: 1006.2903442382812, Neurons: 11, Grad norm: 7.367e+00\n",
      "Epoch 2130, Loss: 1006.2268676757812, Neurons: 11, Grad norm: 7.362e+00\n",
      "Epoch 2131, Loss: 1006.16357421875, Neurons: 11, Grad norm: 7.360e+00\n",
      "Epoch 2132, Loss: 1006.1002807617188, Neurons: 11, Grad norm: 7.358e+00\n",
      "Epoch 2133, Loss: 1006.0369873046875, Neurons: 11, Grad norm: 7.351e+00\n",
      "Epoch 2134, Loss: 1005.9736938476562, Neurons: 11, Grad norm: 7.343e+00\n",
      "Epoch 2135, Loss: 1005.9104614257812, Neurons: 11, Grad norm: 7.336e+00\n",
      "Epoch 2136, Loss: 1005.8472900390625, Neurons: 11, Grad norm: 7.329e+00\n",
      "Epoch 2137, Loss: 1005.7843017578125, Neurons: 11, Grad norm: 7.321e+00\n",
      "Epoch 2138, Loss: 1005.72119140625, Neurons: 11, Grad norm: 7.315e+00\n",
      "Epoch 2139, Loss: 1005.658203125, Neurons: 11, Grad norm: 7.311e+00\n",
      "Epoch 2140, Loss: 1005.5951538085938, Neurons: 11, Grad norm: 7.305e+00\n",
      "Epoch 2141, Loss: 1005.5323486328125, Neurons: 11, Grad norm: 7.301e+00\n",
      "Epoch 2142, Loss: 1005.4693603515625, Neurons: 11, Grad norm: 7.298e+00\n",
      "Epoch 2143, Loss: 1005.4066772460938, Neurons: 11, Grad norm: 7.293e+00\n",
      "Epoch 2144, Loss: 1005.343994140625, Neurons: 11, Grad norm: 7.288e+00\n",
      "Epoch 2145, Loss: 1005.28125, Neurons: 11, Grad norm: 7.283e+00\n",
      "Epoch 2146, Loss: 1005.2185668945312, Neurons: 11, Grad norm: 7.279e+00\n",
      "Epoch 2147, Loss: 1005.1559448242188, Neurons: 11, Grad norm: 7.272e+00\n",
      "Epoch 2148, Loss: 1005.0933837890625, Neurons: 11, Grad norm: 7.266e+00\n",
      "Epoch 2149, Loss: 1005.0309448242188, Neurons: 11, Grad norm: 7.262e+00\n",
      "Epoch 2149, Test loss: 1020.3687744140625\n",
      "Epoch 2150, Loss: 1004.9684448242188, Neurons: 11, Grad norm: 7.256e+00\n",
      "Epoch 2151, Loss: 1004.9059448242188, Neurons: 11, Grad norm: 7.251e+00\n",
      "Epoch 2152, Loss: 1004.8436889648438, Neurons: 11, Grad norm: 7.247e+00\n",
      "Epoch 2153, Loss: 1004.7813720703125, Neurons: 11, Grad norm: 7.242e+00\n",
      "Epoch 2154, Loss: 1004.7191772460938, Neurons: 11, Grad norm: 7.237e+00\n",
      "Epoch 2155, Loss: 1004.656982421875, Neurons: 11, Grad norm: 7.233e+00\n",
      "Epoch 2156, Loss: 1004.5947875976562, Neurons: 11, Grad norm: 7.228e+00\n",
      "Epoch 2157, Loss: 1004.5327758789062, Neurons: 11, Grad norm: 7.223e+00\n",
      "Epoch 2158, Loss: 1004.470703125, Neurons: 11, Grad norm: 7.218e+00\n",
      "Epoch 2159, Loss: 1004.4085693359375, Neurons: 11, Grad norm: 7.213e+00\n",
      "Epoch 2160, Loss: 1004.3468017578125, Neurons: 11, Grad norm: 7.208e+00\n",
      "Epoch 2161, Loss: 1004.2847900390625, Neurons: 11, Grad norm: 7.203e+00\n",
      "Epoch 2162, Loss: 1004.2229614257812, Neurons: 11, Grad norm: 7.198e+00\n",
      "Epoch 2163, Loss: 1004.1611938476562, Neurons: 11, Grad norm: 7.193e+00\n",
      "Epoch 2164, Loss: 1004.099365234375, Neurons: 11, Grad norm: 7.188e+00\n",
      "Epoch 2165, Loss: 1004.03759765625, Neurons: 11, Grad norm: 7.184e+00\n",
      "Epoch 2166, Loss: 1003.9759521484375, Neurons: 11, Grad norm: 7.179e+00\n",
      "Epoch 2167, Loss: 1003.9142456054688, Neurons: 11, Grad norm: 7.174e+00\n",
      "Epoch 2168, Loss: 1003.852783203125, Neurons: 11, Grad norm: 7.169e+00\n",
      "Epoch 2169, Loss: 1003.7911987304688, Neurons: 11, Grad norm: 7.165e+00\n",
      "Epoch 2170, Loss: 1003.7297973632812, Neurons: 11, Grad norm: 7.160e+00\n",
      "Epoch 2171, Loss: 1003.6683959960938, Neurons: 11, Grad norm: 7.155e+00\n",
      "Epoch 2172, Loss: 1003.6069946289062, Neurons: 11, Grad norm: 7.150e+00\n",
      "Epoch 2173, Loss: 1003.545654296875, Neurons: 11, Grad norm: 7.145e+00\n",
      "Epoch 2174, Loss: 1003.484375, Neurons: 11, Grad norm: 7.140e+00\n",
      "Epoch 2175, Loss: 1003.4231567382812, Neurons: 11, Grad norm: 7.136e+00\n",
      "Epoch 2176, Loss: 1003.3619995117188, Neurons: 11, Grad norm: 7.131e+00\n",
      "Epoch 2177, Loss: 1003.30078125, Neurons: 11, Grad norm: 7.126e+00\n",
      "Epoch 2178, Loss: 1003.23974609375, Neurons: 11, Grad norm: 7.121e+00\n",
      "Epoch 2179, Loss: 1003.1785888671875, Neurons: 11, Grad norm: 7.117e+00\n",
      "Epoch 2180, Loss: 1003.1177978515625, Neurons: 11, Grad norm: 7.112e+00\n",
      "Epoch 2181, Loss: 1003.0567626953125, Neurons: 11, Grad norm: 7.107e+00\n",
      "Epoch 2182, Loss: 1002.995849609375, Neurons: 11, Grad norm: 7.102e+00\n",
      "Epoch 2183, Loss: 1002.9349975585938, Neurons: 11, Grad norm: 7.097e+00\n",
      "Epoch 2184, Loss: 1002.8741455078125, Neurons: 11, Grad norm: 7.093e+00\n",
      "Epoch 2185, Loss: 1002.8134765625, Neurons: 11, Grad norm: 7.088e+00\n",
      "Epoch 2186, Loss: 1002.7527465820312, Neurons: 11, Grad norm: 7.083e+00\n",
      "Epoch 2187, Loss: 1002.6921997070312, Neurons: 11, Grad norm: 7.078e+00\n",
      "Epoch 2188, Loss: 1002.631591796875, Neurons: 11, Grad norm: 7.074e+00\n",
      "Epoch 2189, Loss: 1002.5709838867188, Neurons: 11, Grad norm: 7.069e+00\n",
      "Epoch 2190, Loss: 1002.510498046875, Neurons: 11, Grad norm: 7.064e+00\n",
      "Epoch 2191, Loss: 1002.449951171875, Neurons: 11, Grad norm: 7.059e+00\n",
      "Epoch 2192, Loss: 1002.3895874023438, Neurons: 11, Grad norm: 7.055e+00\n",
      "Epoch 2193, Loss: 1002.3292846679688, Neurons: 11, Grad norm: 7.050e+00\n",
      "Epoch 2194, Loss: 1002.2688598632812, Neurons: 11, Grad norm: 7.045e+00\n",
      "Epoch 2195, Loss: 1002.2085571289062, Neurons: 11, Grad norm: 7.041e+00\n",
      "Epoch 2196, Loss: 1002.1483764648438, Neurons: 11, Grad norm: 7.036e+00\n",
      "Epoch 2197, Loss: 1002.0881958007812, Neurons: 11, Grad norm: 7.031e+00\n",
      "Epoch 2198, Loss: 1002.0281982421875, Neurons: 11, Grad norm: 7.026e+00\n",
      "Epoch 2199, Loss: 1001.9679565429688, Neurons: 11, Grad norm: 7.022e+00\n",
      "Epoch 2199, Test loss: 1017.1460571289062\n",
      "Epoch 2200, Loss: 1001.907958984375, Neurons: 11, Grad norm: 7.017e+00\n",
      "Epoch 2201, Loss: 1001.8480834960938, Neurons: 11, Grad norm: 7.012e+00\n",
      "Epoch 2202, Loss: 1001.7880859375, Neurons: 11, Grad norm: 7.008e+00\n",
      "Epoch 2203, Loss: 1001.7281494140625, Neurons: 11, Grad norm: 7.003e+00\n",
      "Epoch 2204, Loss: 1001.6683959960938, Neurons: 11, Grad norm: 6.998e+00\n",
      "Epoch 2205, Loss: 1001.6085815429688, Neurons: 11, Grad norm: 6.994e+00\n",
      "Epoch 2206, Loss: 1001.5488891601562, Neurons: 11, Grad norm: 6.989e+00\n",
      "Epoch 2207, Loss: 1001.4891967773438, Neurons: 11, Grad norm: 6.984e+00\n",
      "Epoch 2208, Loss: 1001.4293823242188, Neurons: 11, Grad norm: 6.980e+00\n",
      "Epoch 2209, Loss: 1001.3697509765625, Neurons: 11, Grad norm: 6.975e+00\n",
      "Epoch 2210, Loss: 1001.310302734375, Neurons: 11, Grad norm: 6.970e+00\n",
      "Epoch 2211, Loss: 1001.2507934570312, Neurons: 11, Grad norm: 6.966e+00\n",
      "Epoch 2212, Loss: 1001.1913452148438, Neurons: 11, Grad norm: 6.961e+00\n",
      "Epoch 2213, Loss: 1001.1318969726562, Neurons: 11, Grad norm: 6.956e+00\n",
      "Epoch 2214, Loss: 1001.0724487304688, Neurons: 11, Grad norm: 6.952e+00\n",
      "Epoch 2215, Loss: 1001.01318359375, Neurons: 11, Grad norm: 6.947e+00\n",
      "Epoch 2216, Loss: 1000.9539794921875, Neurons: 11, Grad norm: 6.942e+00\n",
      "Epoch 2217, Loss: 1000.8946533203125, Neurons: 11, Grad norm: 6.938e+00\n",
      "Epoch 2218, Loss: 1000.83544921875, Neurons: 11, Grad norm: 6.933e+00\n",
      "Epoch 2219, Loss: 1000.7763671875, Neurons: 11, Grad norm: 6.928e+00\n",
      "Epoch 2220, Loss: 1000.7173461914062, Neurons: 11, Grad norm: 6.924e+00\n",
      "Epoch 2221, Loss: 1000.658203125, Neurons: 11, Grad norm: 6.919e+00\n",
      "Epoch 2222, Loss: 1000.5993041992188, Neurons: 11, Grad norm: 6.915e+00\n",
      "Epoch 2223, Loss: 1000.540283203125, Neurons: 11, Grad norm: 6.910e+00\n",
      "Epoch 2224, Loss: 1000.4813842773438, Neurons: 11, Grad norm: 6.905e+00\n",
      "Epoch 2225, Loss: 1000.4224853515625, Neurons: 11, Grad norm: 6.901e+00\n",
      "Epoch 2226, Loss: 1000.36376953125, Neurons: 11, Grad norm: 6.896e+00\n",
      "Epoch 2227, Loss: 1000.3049926757812, Neurons: 11, Grad norm: 6.892e+00\n",
      "Epoch 2228, Loss: 1000.2461547851562, Neurons: 11, Grad norm: 6.887e+00\n",
      "Epoch 2229, Loss: 1000.1875610351562, Neurons: 11, Grad norm: 6.882e+00\n",
      "Epoch 2230, Loss: 1000.1288452148438, Neurons: 11, Grad norm: 6.878e+00\n",
      "Epoch 2231, Loss: 1000.0702514648438, Neurons: 11, Grad norm: 6.873e+00\n",
      "Epoch 2232, Loss: 1000.0117797851562, Neurons: 11, Grad norm: 6.869e+00\n",
      "Epoch 2233, Loss: 999.953369140625, Neurons: 11, Grad norm: 6.864e+00\n",
      "Epoch 2234, Loss: 999.8949584960938, Neurons: 11, Grad norm: 6.859e+00\n",
      "Epoch 2235, Loss: 999.8363647460938, Neurons: 11, Grad norm: 6.855e+00\n",
      "Epoch 2236, Loss: 999.7781982421875, Neurons: 11, Grad norm: 6.850e+00\n",
      "Epoch 2237, Loss: 999.7197875976562, Neurons: 11, Grad norm: 6.846e+00\n",
      "Epoch 2238, Loss: 999.6615600585938, Neurons: 11, Grad norm: 6.841e+00\n",
      "Epoch 2239, Loss: 999.6033935546875, Neurons: 11, Grad norm: 6.837e+00\n",
      "Epoch 2240, Loss: 999.545166015625, Neurons: 11, Grad norm: 6.832e+00\n",
      "Epoch 2241, Loss: 999.487060546875, Neurons: 11, Grad norm: 6.828e+00\n",
      "Epoch 2242, Loss: 999.428955078125, Neurons: 11, Grad norm: 7.820e+00\n",
      "Epoch 2243, Loss: 999.3709716796875, Neurons: 11, Grad norm: 9.196e+00\n",
      "Epoch 2244, Loss: 999.3141479492188, Neurons: 11, Grad norm: 9.080e+00\n",
      "Epoch 2245, Loss: 999.25537109375, Neurons: 11, Grad norm: 6.825e+00\n",
      "Epoch 2246, Loss: 999.1972045898438, Neurons: 11, Grad norm: 6.885e+00\n",
      "Epoch 2247, Loss: 999.1395874023438, Neurons: 11, Grad norm: 6.923e+00\n",
      "Epoch 2248, Loss: 999.0820922851562, Neurons: 11, Grad norm: 6.953e+00\n",
      "Epoch 2249, Loss: 999.0245971679688, Neurons: 11, Grad norm: 6.983e+00\n",
      "Epoch 2249, Test loss: 1014.0469360351562\n",
      "Epoch 2250, Loss: 998.9669799804688, Neurons: 11, Grad norm: 6.965e+00\n",
      "Epoch 2251, Loss: 998.9093017578125, Neurons: 11, Grad norm: 6.929e+00\n",
      "Epoch 2252, Loss: 998.8515625, Neurons: 11, Grad norm: 6.896e+00\n",
      "Epoch 2253, Loss: 998.7937622070312, Neurons: 11, Grad norm: 6.841e+00\n",
      "Epoch 2254, Loss: 998.7359619140625, Neurons: 11, Grad norm: 6.799e+00\n",
      "Epoch 2255, Loss: 998.6783447265625, Neurons: 11, Grad norm: 6.780e+00\n",
      "Epoch 2256, Loss: 998.6207885742188, Neurons: 11, Grad norm: 6.762e+00\n",
      "Epoch 2257, Loss: 998.5633544921875, Neurons: 11, Grad norm: 6.762e+00\n",
      "Epoch 2258, Loss: 998.506103515625, Neurons: 11, Grad norm: 6.774e+00\n",
      "Epoch 2259, Loss: 998.4487915039062, Neurons: 11, Grad norm: 6.783e+00\n",
      "Epoch 2260, Loss: 998.3916625976562, Neurons: 11, Grad norm: 6.789e+00\n",
      "Epoch 2261, Loss: 998.3345947265625, Neurons: 11, Grad norm: 6.791e+00\n",
      "Epoch 2262, Loss: 998.2774047851562, Neurons: 11, Grad norm: 6.784e+00\n",
      "Epoch 2263, Loss: 998.2201538085938, Neurons: 11, Grad norm: 6.770e+00\n",
      "Epoch 2264, Loss: 998.1630859375, Neurons: 11, Grad norm: 6.754e+00\n",
      "Epoch 2265, Loss: 998.10595703125, Neurons: 11, Grad norm: 6.737e+00\n",
      "Epoch 2266, Loss: 998.0489501953125, Neurons: 11, Grad norm: 6.724e+00\n",
      "Epoch 2267, Loss: 997.9920043945312, Neurons: 11, Grad norm: 6.713e+00\n",
      "Epoch 2268, Loss: 997.9351806640625, Neurons: 11, Grad norm: 6.706e+00\n",
      "Epoch 2269, Loss: 997.878173828125, Neurons: 11, Grad norm: 6.706e+00\n",
      "Epoch 2270, Loss: 997.8213500976562, Neurons: 11, Grad norm: 6.704e+00\n",
      "Epoch 2271, Loss: 997.7647705078125, Neurons: 11, Grad norm: 6.703e+00\n",
      "Epoch 2272, Loss: 997.7080688476562, Neurons: 11, Grad norm: 6.705e+00\n",
      "Epoch 2273, Loss: 997.6513671875, Neurons: 11, Grad norm: 6.699e+00\n",
      "Epoch 2274, Loss: 997.5947875976562, Neurons: 11, Grad norm: 6.693e+00\n",
      "Epoch 2275, Loss: 997.5381469726562, Neurons: 11, Grad norm: 6.688e+00\n",
      "Epoch 2276, Loss: 997.4815673828125, Neurons: 11, Grad norm: 6.678e+00\n",
      "Epoch 2277, Loss: 997.4251708984375, Neurons: 11, Grad norm: 6.670e+00\n",
      "Epoch 2278, Loss: 997.36865234375, Neurons: 11, Grad norm: 6.665e+00\n",
      "Epoch 2279, Loss: 997.3121948242188, Neurons: 11, Grad norm: 6.657e+00\n",
      "Epoch 2280, Loss: 997.2557983398438, Neurons: 11, Grad norm: 6.652e+00\n",
      "Epoch 2281, Loss: 997.1995849609375, Neurons: 11, Grad norm: 6.650e+00\n",
      "Epoch 2282, Loss: 997.1432495117188, Neurons: 11, Grad norm: 6.645e+00\n",
      "Epoch 2283, Loss: 997.0870971679688, Neurons: 11, Grad norm: 6.643e+00\n",
      "Epoch 2284, Loss: 997.0309448242188, Neurons: 11, Grad norm: 6.639e+00\n",
      "Epoch 2285, Loss: 996.9747924804688, Neurons: 11, Grad norm: 6.634e+00\n",
      "Epoch 2286, Loss: 996.9185791015625, Neurons: 11, Grad norm: 6.630e+00\n",
      "Epoch 2287, Loss: 996.862548828125, Neurons: 11, Grad norm: 6.625e+00\n",
      "Epoch 2288, Loss: 996.8065795898438, Neurons: 11, Grad norm: 6.619e+00\n",
      "Epoch 2289, Loss: 996.7505493164062, Neurons: 11, Grad norm: 6.614e+00\n",
      "Epoch 2290, Loss: 996.6947631835938, Neurons: 11, Grad norm: 6.609e+00\n",
      "Epoch 2291, Loss: 996.6387939453125, Neurons: 11, Grad norm: 6.604e+00\n",
      "Epoch 2292, Loss: 996.5829467773438, Neurons: 11, Grad norm: 6.600e+00\n",
      "Epoch 2293, Loss: 996.5271606445312, Neurons: 11, Grad norm: 6.595e+00\n",
      "Epoch 2294, Loss: 996.4714965820312, Neurons: 11, Grad norm: 6.591e+00\n",
      "Epoch 2295, Loss: 996.415771484375, Neurons: 11, Grad norm: 6.588e+00\n",
      "Epoch 2296, Loss: 996.3601684570312, Neurons: 11, Grad norm: 6.583e+00\n",
      "Epoch 2297, Loss: 996.3045654296875, Neurons: 11, Grad norm: 6.579e+00\n",
      "Epoch 2298, Loss: 996.2489624023438, Neurons: 11, Grad norm: 6.575e+00\n",
      "Epoch 2299, Loss: 996.1934814453125, Neurons: 11, Grad norm: 6.569e+00\n",
      "Epoch 2299, Test loss: 1011.065185546875\n",
      "Epoch 2300, Loss: 996.1380004882812, Neurons: 11, Grad norm: 6.565e+00\n",
      "Epoch 2301, Loss: 996.0825805664062, Neurons: 11, Grad norm: 6.560e+00\n",
      "Epoch 2302, Loss: 996.0271606445312, Neurons: 11, Grad norm: 6.556e+00\n",
      "Epoch 2303, Loss: 995.9718017578125, Neurons: 11, Grad norm: 6.552e+00\n",
      "Epoch 2304, Loss: 995.91650390625, Neurons: 11, Grad norm: 6.547e+00\n",
      "Epoch 2305, Loss: 995.8611450195312, Neurons: 11, Grad norm: 6.543e+00\n",
      "Epoch 2306, Loss: 995.8059692382812, Neurons: 11, Grad norm: 6.539e+00\n",
      "Epoch 2307, Loss: 995.7507934570312, Neurons: 11, Grad norm: 6.534e+00\n",
      "Epoch 2308, Loss: 995.69580078125, Neurons: 11, Grad norm: 6.530e+00\n",
      "Epoch 2309, Loss: 995.6406860351562, Neurons: 11, Grad norm: 6.526e+00\n",
      "Epoch 2310, Loss: 995.58544921875, Neurons: 11, Grad norm: 6.521e+00\n",
      "Epoch 2311, Loss: 995.5305786132812, Neurons: 11, Grad norm: 6.517e+00\n",
      "Epoch 2312, Loss: 995.4755859375, Neurons: 11, Grad norm: 6.512e+00\n",
      "Epoch 2313, Loss: 995.4207763671875, Neurons: 11, Grad norm: 6.508e+00\n",
      "Epoch 2314, Loss: 995.3658447265625, Neurons: 11, Grad norm: 6.504e+00\n",
      "Epoch 2315, Loss: 995.3109741210938, Neurons: 11, Grad norm: 6.499e+00\n",
      "Epoch 2316, Loss: 995.2561645507812, Neurons: 11, Grad norm: 6.495e+00\n",
      "Epoch 2317, Loss: 995.2014770507812, Neurons: 11, Grad norm: 6.491e+00\n",
      "Epoch 2318, Loss: 995.1467895507812, Neurons: 11, Grad norm: 6.486e+00\n",
      "Epoch 2319, Loss: 995.0921630859375, Neurons: 11, Grad norm: 6.482e+00\n",
      "Epoch 2320, Loss: 995.03759765625, Neurons: 11, Grad norm: 6.478e+00\n",
      "Epoch 2321, Loss: 994.9829711914062, Neurons: 11, Grad norm: 6.474e+00\n",
      "Epoch 2322, Loss: 994.928466796875, Neurons: 11, Grad norm: 6.469e+00\n",
      "Epoch 2323, Loss: 994.8739624023438, Neurons: 11, Grad norm: 6.465e+00\n",
      "Epoch 2324, Loss: 994.819580078125, Neurons: 11, Grad norm: 6.461e+00\n",
      "Epoch 2325, Loss: 994.7651977539062, Neurons: 11, Grad norm: 6.456e+00\n",
      "Epoch 2326, Loss: 994.7107543945312, Neurons: 11, Grad norm: 6.452e+00\n",
      "Epoch 2327, Loss: 994.6563720703125, Neurons: 11, Grad norm: 6.448e+00\n",
      "Epoch 2328, Loss: 994.6021728515625, Neurons: 11, Grad norm: 6.443e+00\n",
      "Epoch 2329, Loss: 994.5479736328125, Neurons: 11, Grad norm: 6.439e+00\n",
      "Epoch 2330, Loss: 994.4937744140625, Neurons: 11, Grad norm: 6.435e+00\n",
      "Epoch 2331, Loss: 994.4395751953125, Neurons: 11, Grad norm: 6.431e+00\n",
      "Epoch 2332, Loss: 994.3855590820312, Neurons: 11, Grad norm: 6.426e+00\n",
      "Epoch 2333, Loss: 994.3316040039062, Neurons: 11, Grad norm: 6.422e+00\n",
      "Epoch 2334, Loss: 994.2774658203125, Neurons: 11, Grad norm: 6.418e+00\n",
      "Epoch 2335, Loss: 994.2235717773438, Neurons: 11, Grad norm: 6.414e+00\n",
      "Epoch 2336, Loss: 994.1695556640625, Neurons: 11, Grad norm: 6.409e+00\n",
      "Epoch 2337, Loss: 994.1157836914062, Neurons: 11, Grad norm: 6.405e+00\n",
      "Epoch 2338, Loss: 994.0618896484375, Neurons: 11, Grad norm: 6.401e+00\n",
      "Epoch 2339, Loss: 994.008056640625, Neurons: 11, Grad norm: 6.397e+00\n",
      "Epoch 2340, Loss: 993.954345703125, Neurons: 11, Grad norm: 6.392e+00\n",
      "Epoch 2341, Loss: 993.9006958007812, Neurons: 11, Grad norm: 6.388e+00\n",
      "Epoch 2342, Loss: 993.8469848632812, Neurons: 11, Grad norm: 6.384e+00\n",
      "Epoch 2343, Loss: 993.7932739257812, Neurons: 11, Grad norm: 6.380e+00\n",
      "Epoch 2344, Loss: 993.73974609375, Neurons: 11, Grad norm: 6.375e+00\n",
      "Epoch 2345, Loss: 993.6861572265625, Neurons: 11, Grad norm: 6.371e+00\n",
      "Epoch 2346, Loss: 993.6326904296875, Neurons: 11, Grad norm: 6.367e+00\n",
      "Epoch 2347, Loss: 993.5791625976562, Neurons: 11, Grad norm: 6.363e+00\n",
      "Epoch 2348, Loss: 993.5257568359375, Neurons: 11, Grad norm: 6.359e+00\n",
      "Epoch 2349, Loss: 993.4723510742188, Neurons: 11, Grad norm: 6.354e+00\n",
      "Epoch 2349, Test loss: 1008.1975708007812\n",
      "Epoch 2350, Loss: 993.4190673828125, Neurons: 11, Grad norm: 6.350e+00\n",
      "Epoch 2351, Loss: 993.3657836914062, Neurons: 11, Grad norm: 6.346e+00\n",
      "Epoch 2352, Loss: 993.3125, Neurons: 11, Grad norm: 6.342e+00\n",
      "Epoch 2353, Loss: 993.2593994140625, Neurons: 11, Grad norm: 6.337e+00\n",
      "Epoch 2354, Loss: 993.2060546875, Neurons: 11, Grad norm: 6.333e+00\n",
      "Epoch 2355, Loss: 993.153076171875, Neurons: 11, Grad norm: 6.329e+00\n",
      "Epoch 2356, Loss: 993.0999755859375, Neurons: 11, Grad norm: 6.325e+00\n",
      "Epoch 2357, Loss: 993.046875, Neurons: 11, Grad norm: 6.321e+00\n",
      "Epoch 2358, Loss: 992.993896484375, Neurons: 11, Grad norm: 6.317e+00\n",
      "Epoch 2359, Loss: 992.9409790039062, Neurons: 11, Grad norm: 6.312e+00\n",
      "Epoch 2360, Loss: 992.8880004882812, Neurons: 11, Grad norm: 6.308e+00\n",
      "Epoch 2361, Loss: 992.835205078125, Neurons: 11, Grad norm: 6.304e+00\n",
      "Epoch 2362, Loss: 992.7821655273438, Neurons: 11, Grad norm: 6.300e+00\n",
      "Epoch 2363, Loss: 992.7295532226562, Neurons: 11, Grad norm: 6.296e+00\n",
      "Epoch 2364, Loss: 992.6767578125, Neurons: 11, Grad norm: 6.292e+00\n",
      "Epoch 2365, Loss: 992.6239624023438, Neurons: 11, Grad norm: 6.287e+00\n",
      "Epoch 2366, Loss: 992.5713500976562, Neurons: 11, Grad norm: 6.283e+00\n",
      "Epoch 2367, Loss: 992.518798828125, Neurons: 11, Grad norm: 6.279e+00\n",
      "Epoch 2368, Loss: 992.4661865234375, Neurons: 11, Grad norm: 6.275e+00\n",
      "Epoch 2369, Loss: 992.41357421875, Neurons: 11, Grad norm: 6.271e+00\n",
      "Epoch 2370, Loss: 992.3611450195312, Neurons: 11, Grad norm: 6.267e+00\n",
      "Epoch 2371, Loss: 992.30859375, Neurons: 11, Grad norm: 6.262e+00\n",
      "Epoch 2372, Loss: 992.2561645507812, Neurons: 11, Grad norm: 6.258e+00\n",
      "Epoch 2373, Loss: 992.2037963867188, Neurons: 11, Grad norm: 6.254e+00\n",
      "Epoch 2374, Loss: 992.1515502929688, Neurons: 11, Grad norm: 6.250e+00\n",
      "Epoch 2375, Loss: 992.0991821289062, Neurons: 11, Grad norm: 6.246e+00\n",
      "Epoch 2376, Loss: 992.0469970703125, Neurons: 11, Grad norm: 6.242e+00\n",
      "Epoch 2377, Loss: 991.9947509765625, Neurons: 11, Grad norm: 6.238e+00\n",
      "Epoch 2378, Loss: 991.9425659179688, Neurons: 11, Grad norm: 6.233e+00\n",
      "Epoch 2379, Loss: 991.890380859375, Neurons: 11, Grad norm: 6.229e+00\n",
      "Epoch 2380, Loss: 991.83837890625, Neurons: 11, Grad norm: 6.225e+00\n",
      "Epoch 2381, Loss: 991.7861938476562, Neurons: 11, Grad norm: 6.221e+00\n",
      "Epoch 2382, Loss: 991.7342529296875, Neurons: 11, Grad norm: 6.217e+00\n",
      "Epoch 2383, Loss: 991.6821899414062, Neurons: 11, Grad norm: 6.213e+00\n",
      "Epoch 2384, Loss: 991.63037109375, Neurons: 11, Grad norm: 6.209e+00\n",
      "Epoch 2385, Loss: 991.578369140625, Neurons: 11, Grad norm: 6.205e+00\n",
      "Epoch 2386, Loss: 991.5265502929688, Neurons: 11, Grad norm: 6.201e+00\n",
      "Epoch 2387, Loss: 991.4747924804688, Neurons: 11, Grad norm: 6.196e+00\n",
      "Epoch 2388, Loss: 991.4229736328125, Neurons: 11, Grad norm: 6.192e+00\n",
      "Epoch 2389, Loss: 991.3712768554688, Neurons: 11, Grad norm: 6.188e+00\n",
      "Epoch 2390, Loss: 991.319580078125, Neurons: 11, Grad norm: 6.184e+00\n",
      "Epoch 2391, Loss: 991.2680053710938, Neurons: 11, Grad norm: 6.180e+00\n",
      "Epoch 2392, Loss: 991.2163696289062, Neurons: 11, Grad norm: 6.176e+00\n",
      "Epoch 2393, Loss: 991.164794921875, Neurons: 11, Grad norm: 6.172e+00\n",
      "Epoch 2394, Loss: 991.1131591796875, Neurons: 11, Grad norm: 6.168e+00\n",
      "Epoch 2395, Loss: 991.061767578125, Neurons: 11, Grad norm: 6.164e+00\n",
      "Epoch 2396, Loss: 991.0103759765625, Neurons: 11, Grad norm: 6.160e+00\n",
      "Epoch 2397, Loss: 990.9588623046875, Neurons: 11, Grad norm: 6.156e+00\n",
      "Epoch 2398, Loss: 990.9075927734375, Neurons: 11, Grad norm: 6.152e+00\n",
      "Epoch 2399, Loss: 990.8562622070312, Neurons: 11, Grad norm: 6.148e+00\n",
      "Epoch 2399, Test loss: 1005.43896484375\n",
      "Epoch 2400, Loss: 990.8049926757812, Neurons: 11, Grad norm: 6.144e+00\n",
      "Epoch 2401, Loss: 990.753662109375, Neurons: 11, Grad norm: 6.139e+00\n",
      "Epoch 2402, Loss: 990.7024536132812, Neurons: 11, Grad norm: 6.136e+00\n",
      "Epoch 2403, Loss: 990.6513671875, Neurons: 11, Grad norm: 6.131e+00\n",
      "Epoch 2404, Loss: 990.6001586914062, Neurons: 11, Grad norm: 6.127e+00\n",
      "Epoch 2405, Loss: 990.5491943359375, Neurons: 11, Grad norm: 6.123e+00\n",
      "Epoch 2406, Loss: 990.4979858398438, Neurons: 11, Grad norm: 6.119e+00\n",
      "Epoch 2407, Loss: 990.4470825195312, Neurons: 11, Grad norm: 6.115e+00\n",
      "Epoch 2408, Loss: 990.3961791992188, Neurons: 11, Grad norm: 6.111e+00\n",
      "Epoch 2409, Loss: 990.3451538085938, Neurons: 11, Grad norm: 6.107e+00\n",
      "Epoch 2410, Loss: 990.2943725585938, Neurons: 11, Grad norm: 6.934e+00\n",
      "Epoch 2411, Loss: 990.2433471679688, Neurons: 11, Grad norm: 8.325e+00\n",
      "Epoch 2412, Loss: 990.1937866210938, Neurons: 11, Grad norm: 8.217e+00\n",
      "Epoch 2413, Loss: 990.14208984375, Neurons: 11, Grad norm: 6.163e+00\n",
      "Epoch 2414, Loss: 990.0911865234375, Neurons: 11, Grad norm: 6.201e+00\n",
      "Epoch 2415, Loss: 990.040771484375, Neurons: 11, Grad norm: 6.272e+00\n",
      "Epoch 2416, Loss: 989.990478515625, Neurons: 11, Grad norm: 6.297e+00\n",
      "Epoch 2417, Loss: 989.9400024414062, Neurons: 11, Grad norm: 6.324e+00\n",
      "Epoch 2418, Loss: 989.8895874023438, Neurons: 11, Grad norm: 6.282e+00\n",
      "Epoch 2419, Loss: 989.8389892578125, Neurons: 11, Grad norm: 6.251e+00\n",
      "Epoch 2420, Loss: 989.7883911132812, Neurons: 11, Grad norm: 6.173e+00\n",
      "Epoch 2421, Loss: 989.7376708984375, Neurons: 11, Grad norm: 6.125e+00\n",
      "Epoch 2422, Loss: 989.6870727539062, Neurons: 11, Grad norm: 6.075e+00\n",
      "Epoch 2423, Loss: 989.636474609375, Neurons: 11, Grad norm: 6.053e+00\n",
      "Epoch 2424, Loss: 989.586181640625, Neurons: 11, Grad norm: 6.051e+00\n",
      "Epoch 2425, Loss: 989.535888671875, Neurons: 11, Grad norm: 6.061e+00\n",
      "Epoch 2426, Loss: 989.4856567382812, Neurons: 11, Grad norm: 6.083e+00\n",
      "Epoch 2427, Loss: 989.4354858398438, Neurons: 11, Grad norm: 6.096e+00\n",
      "Epoch 2428, Loss: 989.3853759765625, Neurons: 11, Grad norm: 6.112e+00\n",
      "Epoch 2429, Loss: 989.3353881835938, Neurons: 11, Grad norm: 6.107e+00\n",
      "Epoch 2430, Loss: 989.28515625, Neurons: 11, Grad norm: 6.110e+00\n",
      "Epoch 2431, Loss: 989.2351684570312, Neurons: 11, Grad norm: 6.087e+00\n",
      "Epoch 2432, Loss: 989.18505859375, Neurons: 11, Grad norm: 6.089e+00\n",
      "Epoch 2433, Loss: 989.1349487304688, Neurons: 11, Grad norm: 6.065e+00\n",
      "Epoch 2434, Loss: 989.0850830078125, Neurons: 11, Grad norm: 6.082e+00\n",
      "Epoch 2435, Loss: 989.03515625, Neurons: 11, Grad norm: 6.072e+00\n",
      "Epoch 2436, Loss: 988.9852905273438, Neurons: 11, Grad norm: 6.113e+00\n",
      "Epoch 2437, Loss: 988.9353637695312, Neurons: 11, Grad norm: 6.122e+00\n",
      "Epoch 2438, Loss: 988.8858032226562, Neurons: 11, Grad norm: 6.193e+00\n",
      "Epoch 2439, Loss: 988.8359985351562, Neurons: 11, Grad norm: 6.222e+00\n",
      "Epoch 2440, Loss: 988.786376953125, Neurons: 11, Grad norm: 6.344e+00\n",
      "Epoch 2441, Loss: 988.736572265625, Neurons: 11, Grad norm: 6.403e+00\n",
      "Epoch 2442, Loss: 988.6869506835938, Neurons: 11, Grad norm: 6.599e+00\n",
      "Epoch 2443, Loss: 988.6373901367188, Neurons: 11, Grad norm: 6.692e+00\n",
      "Epoch 2444, Loss: 988.587890625, Neurons: 11, Grad norm: 6.938e+00\n",
      "Epoch 2445, Loss: 988.5383911132812, Neurons: 11, Grad norm: 6.993e+00\n",
      "Epoch 2446, Loss: 988.4888916015625, Neurons: 11, Grad norm: 7.120e+00\n",
      "Epoch 2447, Loss: 988.4393920898438, Neurons: 11, Grad norm: 6.945e+00\n",
      "Epoch 2448, Loss: 988.3900756835938, Neurons: 11, Grad norm: 6.760e+00\n",
      "Epoch 2449, Loss: 988.3406982421875, Neurons: 11, Grad norm: 6.364e+00\n",
      "Epoch 2449, Test loss: 1002.7876586914062\n",
      "Epoch 2450, Loss: 988.2913818359375, Neurons: 11, Grad norm: 6.099e+00\n",
      "Epoch 2451, Loss: 988.2420043945312, Neurons: 11, Grad norm: 5.947e+00\n",
      "Epoch 2452, Loss: 988.1927490234375, Neurons: 11, Grad norm: 5.990e+00\n",
      "Epoch 2453, Loss: 988.1435546875, Neurons: 11, Grad norm: 6.178e+00\n",
      "Epoch 2454, Loss: 988.0943603515625, Neurons: 11, Grad norm: 6.298e+00\n",
      "Epoch 2455, Loss: 988.0453491210938, Neurons: 11, Grad norm: 6.427e+00\n",
      "Epoch 2456, Loss: 987.9961547851562, Neurons: 11, Grad norm: 6.335e+00\n",
      "Epoch 2457, Loss: 987.9472045898438, Neurons: 11, Grad norm: 6.249e+00\n",
      "Epoch 2458, Loss: 987.898193359375, Neurons: 11, Grad norm: 6.047e+00\n",
      "Epoch 2459, Loss: 987.8491821289062, Neurons: 11, Grad norm: 5.948e+00\n",
      "Epoch 2460, Loss: 987.8001708984375, Neurons: 11, Grad norm: 5.909e+00\n",
      "Epoch 2461, Loss: 987.7514038085938, Neurons: 11, Grad norm: 5.944e+00\n",
      "Epoch 2462, Loss: 987.7024536132812, Neurons: 11, Grad norm: 6.046e+00\n",
      "Epoch 2463, Loss: 987.6536865234375, Neurons: 11, Grad norm: 6.081e+00\n",
      "Epoch 2464, Loss: 987.6048583984375, Neurons: 11, Grad norm: 6.141e+00\n",
      "Epoch 2465, Loss: 987.55615234375, Neurons: 11, Grad norm: 6.076e+00\n",
      "Epoch 2466, Loss: 987.5074462890625, Neurons: 11, Grad norm: 6.046e+00\n",
      "Epoch 2467, Loss: 987.4588012695312, Neurons: 11, Grad norm: 5.945e+00\n",
      "Epoch 2468, Loss: 987.41015625, Neurons: 11, Grad norm: 5.905e+00\n",
      "Epoch 2469, Loss: 987.361572265625, Neurons: 11, Grad norm: 5.871e+00\n",
      "Epoch 2470, Loss: 987.31298828125, Neurons: 11, Grad norm: 5.872e+00\n",
      "Epoch 2471, Loss: 987.2644653320312, Neurons: 11, Grad norm: 5.907e+00\n",
      "Epoch 2472, Loss: 987.2160034179688, Neurons: 11, Grad norm: 5.919e+00\n",
      "Epoch 2473, Loss: 987.1676025390625, Neurons: 11, Grad norm: 5.965e+00\n",
      "Epoch 2474, Loss: 987.1192016601562, Neurons: 11, Grad norm: 5.951e+00\n",
      "Epoch 2475, Loss: 987.07080078125, Neurons: 11, Grad norm: 5.972e+00\n",
      "Epoch 2476, Loss: 987.0224609375, Neurons: 11, Grad norm: 5.930e+00\n",
      "Epoch 2477, Loss: 986.9741821289062, Neurons: 11, Grad norm: 5.927e+00\n",
      "Epoch 2478, Loss: 986.9259643554688, Neurons: 11, Grad norm: 5.880e+00\n",
      "Epoch 2479, Loss: 986.877685546875, Neurons: 11, Grad norm: 5.870e+00\n",
      "Epoch 2480, Loss: 986.82958984375, Neurons: 11, Grad norm: 5.838e+00\n",
      "Epoch 2481, Loss: 986.7813720703125, Neurons: 11, Grad norm: 5.832e+00\n",
      "Epoch 2482, Loss: 986.733154296875, Neurons: 11, Grad norm: 5.821e+00\n",
      "Epoch 2483, Loss: 986.6851806640625, Neurons: 11, Grad norm: 5.817e+00\n",
      "Epoch 2484, Loss: 986.6371459960938, Neurons: 11, Grad norm: 5.822e+00\n",
      "Epoch 2485, Loss: 986.5891723632812, Neurons: 11, Grad norm: 5.818e+00\n",
      "Epoch 2486, Loss: 986.5411987304688, Neurons: 11, Grad norm: 5.832e+00\n",
      "Epoch 2487, Loss: 986.4932861328125, Neurons: 11, Grad norm: 5.826e+00\n",
      "Epoch 2488, Loss: 986.4454956054688, Neurons: 11, Grad norm: 5.848e+00\n",
      "Epoch 2489, Loss: 986.3975830078125, Neurons: 11, Grad norm: 5.841e+00\n",
      "Epoch 2490, Loss: 986.3497924804688, Neurons: 11, Grad norm: 5.874e+00\n",
      "Epoch 2491, Loss: 986.3020629882812, Neurons: 11, Grad norm: 5.869e+00\n",
      "Epoch 2492, Loss: 986.2542724609375, Neurons: 11, Grad norm: 5.920e+00\n",
      "Epoch 2493, Loss: 986.2066650390625, Neurons: 11, Grad norm: 5.927e+00\n",
      "Epoch 2494, Loss: 986.1589965820312, Neurons: 11, Grad norm: 6.013e+00\n",
      "Epoch 2495, Loss: 986.1113891601562, Neurons: 11, Grad norm: 6.049e+00\n",
      "Epoch 2496, Loss: 986.0637817382812, Neurons: 11, Grad norm: 6.198e+00\n",
      "Epoch 2497, Loss: 986.0161743164062, Neurons: 11, Grad norm: 6.286e+00\n",
      "Epoch 2498, Loss: 985.96875, Neurons: 11, Grad norm: 6.530e+00\n",
      "Epoch 2499, Loss: 985.9212036132812, Neurons: 11, Grad norm: 6.674e+00\n",
      "Epoch 2499, Test loss: 1000.2349853515625\n",
      "Epoch 2500, Loss: 985.873779296875, Neurons: 11, Grad norm: 6.978e+00\n",
      "Epoch 2501, Loss: 985.8264770507812, Neurons: 11, Grad norm: 7.064e+00\n",
      "Epoch 2502, Loss: 985.7791748046875, Neurons: 11, Grad norm: 7.209e+00\n",
      "Epoch 2503, Loss: 985.7317504882812, Neurons: 11, Grad norm: 6.967e+00\n",
      "Epoch 2504, Loss: 985.6844482421875, Neurons: 11, Grad norm: 6.705e+00\n",
      "Epoch 2505, Loss: 985.6371459960938, Neurons: 11, Grad norm: 6.183e+00\n",
      "Epoch 2506, Loss: 985.5899658203125, Neurons: 11, Grad norm: 5.863e+00\n",
      "Epoch 2507, Loss: 985.5427856445312, Neurons: 11, Grad norm: 5.729e+00\n",
      "Epoch 2508, Loss: 985.49560546875, Neurons: 11, Grad norm: 5.837e+00\n",
      "Epoch 2509, Loss: 985.4485473632812, Neurons: 11, Grad norm: 6.112e+00\n",
      "Epoch 2510, Loss: 985.4014892578125, Neurons: 11, Grad norm: 6.249e+00\n",
      "Epoch 2511, Loss: 985.3544921875, Neurons: 11, Grad norm: 6.364e+00\n",
      "Epoch 2512, Loss: 985.307373046875, Neurons: 11, Grad norm: 6.194e+00\n",
      "Epoch 2513, Loss: 985.260498046875, Neurons: 11, Grad norm: 6.037e+00\n",
      "Epoch 2514, Loss: 985.2135620117188, Neurons: 11, Grad norm: 5.792e+00\n",
      "Epoch 2515, Loss: 985.1666870117188, Neurons: 11, Grad norm: 5.705e+00\n",
      "Epoch 2516, Loss: 985.1197509765625, Neurons: 11, Grad norm: 5.732e+00\n",
      "Epoch 2517, Loss: 985.072998046875, Neurons: 11, Grad norm: 5.811e+00\n",
      "Epoch 2518, Loss: 985.0262451171875, Neurons: 11, Grad norm: 5.956e+00\n",
      "Epoch 2519, Loss: 984.9794921875, Neurons: 11, Grad norm: 5.963e+00\n",
      "Epoch 2520, Loss: 984.9328002929688, Neurons: 11, Grad norm: 5.985e+00\n",
      "Epoch 2521, Loss: 984.8861694335938, Neurons: 11, Grad norm: 5.860e+00\n",
      "Epoch 2522, Loss: 984.8394775390625, Neurons: 11, Grad norm: 5.789e+00\n",
      "Epoch 2523, Loss: 984.7928466796875, Neurons: 11, Grad norm: 5.688e+00\n",
      "Epoch 2524, Loss: 984.7463989257812, Neurons: 11, Grad norm: 5.664e+00\n",
      "Epoch 2525, Loss: 984.6997680664062, Neurons: 11, Grad norm: 5.685e+00\n",
      "Epoch 2526, Loss: 984.6532592773438, Neurons: 11, Grad norm: 5.711e+00\n",
      "Epoch 2527, Loss: 984.6067504882812, Neurons: 11, Grad norm: 5.781e+00\n",
      "Epoch 2528, Loss: 984.5603637695312, Neurons: 11, Grad norm: 5.777e+00\n",
      "Epoch 2529, Loss: 984.5140991210938, Neurons: 11, Grad norm: 5.811e+00\n",
      "Epoch 2530, Loss: 984.4676513671875, Neurons: 11, Grad norm: 5.755e+00\n",
      "Epoch 2531, Loss: 984.42138671875, Neurons: 11, Grad norm: 5.745e+00\n",
      "Epoch 2532, Loss: 984.3751831054688, Neurons: 11, Grad norm: 5.680e+00\n",
      "Epoch 2533, Loss: 984.3289794921875, Neurons: 11, Grad norm: 5.661e+00\n",
      "Epoch 2534, Loss: 984.2826538085938, Neurons: 11, Grad norm: 5.629e+00\n",
      "Epoch 2535, Loss: 984.2364501953125, Neurons: 11, Grad norm: 5.623e+00\n",
      "Epoch 2536, Loss: 984.1903686523438, Neurons: 11, Grad norm: 5.629e+00\n",
      "Epoch 2537, Loss: 984.1443481445312, Neurons: 11, Grad norm: 5.629e+00\n",
      "Epoch 2538, Loss: 984.098388671875, Neurons: 11, Grad norm: 5.655e+00\n",
      "Epoch 2539, Loss: 984.0521850585938, Neurons: 11, Grad norm: 5.649e+00\n",
      "Epoch 2540, Loss: 984.0061645507812, Neurons: 11, Grad norm: 5.680e+00\n",
      "Epoch 2541, Loss: 983.9602661132812, Neurons: 11, Grad norm: 5.664e+00\n",
      "Epoch 2542, Loss: 983.9143676757812, Neurons: 11, Grad norm: 5.692e+00\n",
      "Epoch 2543, Loss: 983.8684692382812, Neurons: 11, Grad norm: 5.669e+00\n",
      "Epoch 2544, Loss: 983.8226928710938, Neurons: 11, Grad norm: 5.695e+00\n",
      "Epoch 2545, Loss: 983.7767944335938, Neurons: 11, Grad norm: 5.668e+00\n",
      "Epoch 2546, Loss: 983.73095703125, Neurons: 11, Grad norm: 5.695e+00\n",
      "Epoch 2547, Loss: 983.6853637695312, Neurons: 11, Grad norm: 5.668e+00\n",
      "Epoch 2548, Loss: 983.6396484375, Neurons: 11, Grad norm: 5.700e+00\n",
      "Epoch 2549, Loss: 983.593994140625, Neurons: 11, Grad norm: 5.678e+00\n",
      "Epoch 2549, Test loss: 997.77490234375\n",
      "Epoch 2550, Loss: 983.5482788085938, Neurons: 11, Grad norm: 5.720e+00\n",
      "Epoch 2551, Loss: 983.5027465820312, Neurons: 11, Grad norm: 5.705e+00\n",
      "Epoch 2552, Loss: 983.4571533203125, Neurons: 11, Grad norm: 5.768e+00\n",
      "Epoch 2553, Loss: 983.4115600585938, Neurons: 11, Grad norm: 5.768e+00\n",
      "Epoch 2554, Loss: 983.3661499023438, Neurons: 11, Grad norm: 5.866e+00\n",
      "Epoch 2555, Loss: 983.3206787109375, Neurons: 11, Grad norm: 5.894e+00\n",
      "Epoch 2556, Loss: 983.2752685546875, Neurons: 11, Grad norm: 6.052e+00\n",
      "Epoch 2557, Loss: 983.2298583984375, Neurons: 11, Grad norm: 6.124e+00\n",
      "Epoch 2558, Loss: 983.1845703125, Neurons: 11, Grad norm: 6.360e+00\n",
      "Epoch 2559, Loss: 983.1392822265625, Neurons: 11, Grad norm: 6.473e+00\n",
      "Epoch 2560, Loss: 983.093994140625, Neurons: 11, Grad norm: 6.754e+00\n",
      "Epoch 2561, Loss: 983.0487670898438, Neurons: 11, Grad norm: 6.814e+00\n",
      "Epoch 2562, Loss: 983.0036010742188, Neurons: 11, Grad norm: 6.971e+00\n",
      "Epoch 2563, Loss: 982.95849609375, Neurons: 11, Grad norm: 6.777e+00\n",
      "Epoch 2564, Loss: 982.9131469726562, Neurons: 11, Grad norm: 6.610e+00\n",
      "Epoch 2565, Loss: 982.8681640625, Neurons: 11, Grad norm: 6.143e+00\n",
      "Epoch 2566, Loss: 982.822998046875, Neurons: 11, Grad norm: 5.821e+00\n",
      "Epoch 2567, Loss: 982.7779541015625, Neurons: 11, Grad norm: 5.542e+00\n",
      "Epoch 2568, Loss: 982.7328491210938, Neurons: 11, Grad norm: 5.511e+00\n",
      "Epoch 2569, Loss: 982.68798828125, Neurons: 11, Grad norm: 5.668e+00\n",
      "Epoch 2570, Loss: 982.64306640625, Neurons: 11, Grad norm: 5.824e+00\n",
      "Epoch 2571, Loss: 982.5982055664062, Neurons: 11, Grad norm: 6.046e+00\n",
      "Epoch 2572, Loss: 982.5532836914062, Neurons: 11, Grad norm: 6.045e+00\n",
      "Epoch 2573, Loss: 982.5083618164062, Neurons: 11, Grad norm: 6.058e+00\n",
      "Epoch 2574, Loss: 982.4637451171875, Neurons: 11, Grad norm: 5.848e+00\n",
      "Epoch 2575, Loss: 982.4189453125, Neurons: 11, Grad norm: 5.717e+00\n",
      "Epoch 2576, Loss: 982.3741455078125, Neurons: 11, Grad norm: 5.532e+00\n",
      "Epoch 2577, Loss: 982.3294677734375, Neurons: 11, Grad norm: 5.477e+00\n",
      "Epoch 2578, Loss: 982.2847900390625, Neurons: 11, Grad norm: 5.495e+00\n",
      "Epoch 2579, Loss: 982.2401733398438, Neurons: 11, Grad norm: 5.544e+00\n",
      "Epoch 2580, Loss: 982.195556640625, Neurons: 11, Grad norm: 5.662e+00\n",
      "Epoch 2581, Loss: 982.1510620117188, Neurons: 11, Grad norm: 5.684e+00\n",
      "Epoch 2582, Loss: 982.1064453125, Neurons: 11, Grad norm: 5.754e+00\n",
      "Epoch 2583, Loss: 982.0620727539062, Neurons: 11, Grad norm: 5.688e+00\n",
      "Epoch 2584, Loss: 982.017578125, Neurons: 11, Grad norm: 5.678e+00\n",
      "Epoch 2585, Loss: 981.9732666015625, Neurons: 11, Grad norm: 5.568e+00\n",
      "Epoch 2586, Loss: 981.9287719726562, Neurons: 11, Grad norm: 5.530e+00\n",
      "Epoch 2587, Loss: 981.8844604492188, Neurons: 11, Grad norm: 5.456e+00\n",
      "Epoch 2588, Loss: 981.840087890625, Neurons: 11, Grad norm: 5.439e+00\n",
      "Epoch 2589, Loss: 981.7957763671875, Neurons: 11, Grad norm: 5.433e+00\n",
      "Epoch 2590, Loss: 981.7515869140625, Neurons: 11, Grad norm: 5.437e+00\n",
      "Epoch 2591, Loss: 981.7073974609375, Neurons: 11, Grad norm: 5.476e+00\n",
      "Epoch 2592, Loss: 981.6631469726562, Neurons: 11, Grad norm: 5.479e+00\n",
      "Epoch 2593, Loss: 981.6189575195312, Neurons: 11, Grad norm: 5.530e+00\n",
      "Epoch 2594, Loss: 981.574951171875, Neurons: 11, Grad norm: 5.519e+00\n",
      "Epoch 2595, Loss: 981.53076171875, Neurons: 11, Grad norm: 5.566e+00\n",
      "Epoch 2596, Loss: 981.4867553710938, Neurons: 11, Grad norm: 5.539e+00\n",
      "Epoch 2597, Loss: 981.4427490234375, Neurons: 11, Grad norm: 5.579e+00\n",
      "Epoch 2598, Loss: 981.3988037109375, Neurons: 11, Grad norm: 5.689e+00\n",
      "Epoch 2599, Loss: 981.3548583984375, Neurons: 11, Grad norm: 7.517e+00\n",
      "Epoch 2599, Test loss: 995.4068603515625\n",
      "Epoch 2600, Loss: 981.311279296875, Neurons: 11, Grad norm: 5.554e+00\n",
      "Epoch 2601, Loss: 981.26708984375, Neurons: 11, Grad norm: 5.594e+00\n",
      "Epoch 2602, Loss: 981.2232666015625, Neurons: 11, Grad norm: 5.555e+00\n",
      "Epoch 2603, Loss: 981.1795654296875, Neurons: 11, Grad norm: 5.579e+00\n",
      "Epoch 2604, Loss: 981.1358032226562, Neurons: 11, Grad norm: 5.530e+00\n",
      "Epoch 2605, Loss: 981.0921020507812, Neurons: 11, Grad norm: 5.537e+00\n",
      "Epoch 2606, Loss: 981.0484619140625, Neurons: 11, Grad norm: 5.481e+00\n",
      "Epoch 2607, Loss: 981.0046997070312, Neurons: 11, Grad norm: 5.478e+00\n",
      "Epoch 2608, Loss: 980.9609985351562, Neurons: 11, Grad norm: 5.425e+00\n",
      "Epoch 2609, Loss: 980.9173583984375, Neurons: 11, Grad norm: 5.421e+00\n",
      "Epoch 2610, Loss: 980.873779296875, Neurons: 11, Grad norm: 5.382e+00\n",
      "Epoch 2611, Loss: 980.8302001953125, Neurons: 11, Grad norm: 5.382e+00\n",
      "Epoch 2612, Loss: 980.7868041992188, Neurons: 11, Grad norm: 5.359e+00\n",
      "Epoch 2613, Loss: 980.7431640625, Neurons: 11, Grad norm: 5.365e+00\n",
      "Epoch 2614, Loss: 980.6997680664062, Neurons: 11, Grad norm: 5.352e+00\n",
      "Epoch 2615, Loss: 980.6563720703125, Neurons: 11, Grad norm: 5.360e+00\n",
      "Epoch 2616, Loss: 980.6129760742188, Neurons: 11, Grad norm: 5.349e+00\n",
      "Epoch 2617, Loss: 980.5697021484375, Neurons: 11, Grad norm: 5.358e+00\n",
      "Epoch 2618, Loss: 980.5263671875, Neurons: 11, Grad norm: 5.345e+00\n",
      "Epoch 2619, Loss: 980.4830932617188, Neurons: 11, Grad norm: 5.356e+00\n",
      "Epoch 2620, Loss: 980.4398803710938, Neurons: 11, Grad norm: 5.342e+00\n",
      "Epoch 2621, Loss: 980.3966674804688, Neurons: 11, Grad norm: 5.361e+00\n",
      "Epoch 2622, Loss: 980.3534545898438, Neurons: 11, Grad norm: 5.353e+00\n",
      "Epoch 2623, Loss: 980.3103637695312, Neurons: 11, Grad norm: 5.396e+00\n",
      "Epoch 2624, Loss: 980.2672729492188, Neurons: 11, Grad norm: 5.408e+00\n",
      "Epoch 2625, Loss: 980.2241821289062, Neurons: 11, Grad norm: 5.514e+00\n",
      "Epoch 2626, Loss: 980.1810913085938, Neurons: 11, Grad norm: 5.594e+00\n",
      "Epoch 2627, Loss: 980.13818359375, Neurons: 11, Grad norm: 5.866e+00\n",
      "Epoch 2628, Loss: 980.0951538085938, Neurons: 11, Grad norm: 6.147e+00\n",
      "Epoch 2629, Loss: 980.05224609375, Neurons: 11, Grad norm: 6.799e+00\n",
      "Epoch 2630, Loss: 980.0093994140625, Neurons: 11, Grad norm: 7.482e+00\n",
      "Epoch 2631, Loss: 979.966552734375, Neurons: 11, Grad norm: 8.605e+00\n",
      "Epoch 2632, Loss: 979.9237670898438, Neurons: 11, Grad norm: 9.354e+00\n",
      "Epoch 2633, Loss: 979.8811645507812, Neurons: 11, Grad norm: 9.875e+00\n",
      "Epoch 2634, Loss: 979.83837890625, Neurons: 11, Grad norm: 8.927e+00\n",
      "Epoch 2635, Loss: 979.7955932617188, Neurons: 11, Grad norm: 7.226e+00\n",
      "Epoch 2636, Loss: 979.7525634765625, Neurons: 11, Grad norm: 5.408e+00\n",
      "Epoch 2637, Loss: 979.7097778320312, Neurons: 11, Grad norm: 5.673e+00\n",
      "Epoch 2638, Loss: 979.6671752929688, Neurons: 11, Grad norm: 7.181e+00\n",
      "Epoch 2639, Loss: 979.6246948242188, Neurons: 11, Grad norm: 7.707e+00\n",
      "Epoch 2640, Loss: 979.5821533203125, Neurons: 11, Grad norm: 7.181e+00\n",
      "Epoch 2641, Loss: 979.53955078125, Neurons: 11, Grad norm: 5.715e+00\n",
      "Epoch 2642, Loss: 979.4969482421875, Neurons: 11, Grad norm: 5.279e+00\n",
      "Epoch 2643, Loss: 979.454345703125, Neurons: 11, Grad norm: 6.176e+00\n",
      "Epoch 2644, Loss: 979.4119873046875, Neurons: 11, Grad norm: 6.730e+00\n",
      "Epoch 2645, Loss: 979.3695678710938, Neurons: 11, Grad norm: 6.553e+00\n",
      "Epoch 2646, Loss: 979.3271484375, Neurons: 11, Grad norm: 5.567e+00\n",
      "Epoch 2647, Loss: 979.2847900390625, Neurons: 11, Grad norm: 5.238e+00\n",
      "Epoch 2648, Loss: 979.2423706054688, Neurons: 11, Grad norm: 5.798e+00\n",
      "Epoch 2649, Loss: 979.2001953125, Neurons: 11, Grad norm: 6.155e+00\n",
      "Epoch 2649, Test loss: 993.1334228515625\n",
      "Epoch 2650, Loss: 979.157958984375, Neurons: 11, Grad norm: 6.056e+00\n",
      "Epoch 2651, Loss: 979.1156616210938, Neurons: 11, Grad norm: 5.410e+00\n",
      "Epoch 2652, Loss: 979.0735473632812, Neurons: 11, Grad norm: 5.218e+00\n",
      "Epoch 2653, Loss: 979.0313720703125, Neurons: 11, Grad norm: 5.578e+00\n",
      "Epoch 2654, Loss: 978.9891967773438, Neurons: 11, Grad norm: 5.787e+00\n",
      "Epoch 2655, Loss: 978.9472045898438, Neurons: 11, Grad norm: 5.737e+00\n",
      "Epoch 2656, Loss: 978.9050903320312, Neurons: 11, Grad norm: 5.317e+00\n",
      "Epoch 2657, Loss: 978.8629760742188, Neurons: 11, Grad norm: 5.197e+00\n",
      "Epoch 2658, Loss: 978.8209838867188, Neurons: 11, Grad norm: 5.417e+00\n",
      "Epoch 2659, Loss: 978.7789916992188, Neurons: 11, Grad norm: 5.540e+00\n",
      "Epoch 2660, Loss: 978.737060546875, Neurons: 11, Grad norm: 5.543e+00\n",
      "Epoch 2661, Loss: 978.6951904296875, Neurons: 11, Grad norm: 5.271e+00\n",
      "Epoch 2662, Loss: 978.6532592773438, Neurons: 11, Grad norm: 5.179e+00\n",
      "Epoch 2663, Loss: 978.6113891601562, Neurons: 11, Grad norm: 5.290e+00\n",
      "Epoch 2664, Loss: 978.5697021484375, Neurons: 11, Grad norm: 5.373e+00\n",
      "Epoch 2665, Loss: 978.5278930664062, Neurons: 11, Grad norm: 5.418e+00\n",
      "Epoch 2666, Loss: 978.4861450195312, Neurons: 11, Grad norm: 5.248e+00\n",
      "Epoch 2667, Loss: 978.4443969726562, Neurons: 11, Grad norm: 5.172e+00\n",
      "Epoch 2668, Loss: 978.4027709960938, Neurons: 11, Grad norm: 5.199e+00\n",
      "Epoch 2669, Loss: 978.361083984375, Neurons: 11, Grad norm: 5.250e+00\n",
      "Epoch 2670, Loss: 978.3193969726562, Neurons: 11, Grad norm: 5.323e+00\n",
      "Epoch 2671, Loss: 978.2778930664062, Neurons: 11, Grad norm: 5.230e+00\n",
      "Epoch 2672, Loss: 978.2362670898438, Neurons: 11, Grad norm: 5.180e+00\n",
      "Epoch 2673, Loss: 978.1947631835938, Neurons: 11, Grad norm: 5.146e+00\n",
      "Epoch 2674, Loss: 978.1532592773438, Neurons: 11, Grad norm: 5.166e+00\n",
      "Epoch 2675, Loss: 978.1117553710938, Neurons: 11, Grad norm: 5.234e+00\n",
      "Epoch 2676, Loss: 978.0703735351562, Neurons: 11, Grad norm: 5.200e+00\n",
      "Epoch 2677, Loss: 978.0289916992188, Neurons: 11, Grad norm: 5.189e+00\n",
      "Epoch 2678, Loss: 977.987548828125, Neurons: 11, Grad norm: 5.130e+00\n",
      "Epoch 2679, Loss: 977.9461669921875, Neurons: 11, Grad norm: 5.122e+00\n",
      "Epoch 2680, Loss: 977.9049682617188, Neurons: 11, Grad norm: 5.153e+00\n",
      "Epoch 2681, Loss: 977.86376953125, Neurons: 11, Grad norm: 5.151e+00\n",
      "Epoch 2682, Loss: 977.8225708007812, Neurons: 11, Grad norm: 5.175e+00\n",
      "Epoch 2683, Loss: 977.78125, Neurons: 11, Grad norm: 5.130e+00\n",
      "Epoch 2684, Loss: 977.7400512695312, Neurons: 11, Grad norm: 5.120e+00\n",
      "Epoch 2685, Loss: 977.6988525390625, Neurons: 11, Grad norm: 5.104e+00\n",
      "Epoch 2686, Loss: 977.6577758789062, Neurons: 11, Grad norm: 5.103e+00\n",
      "Epoch 2687, Loss: 977.61669921875, Neurons: 11, Grad norm: 5.127e+00\n",
      "Epoch 2688, Loss: 977.57568359375, Neurons: 11, Grad norm: 5.113e+00\n",
      "Epoch 2689, Loss: 977.5345458984375, Neurons: 11, Grad norm: 5.123e+00\n",
      "Epoch 2690, Loss: 977.4935913085938, Neurons: 11, Grad norm: 5.093e+00\n",
      "Epoch 2691, Loss: 977.4526977539062, Neurons: 11, Grad norm: 5.089e+00\n",
      "Epoch 2692, Loss: 977.4118041992188, Neurons: 11, Grad norm: 5.081e+00\n",
      "Epoch 2693, Loss: 977.370849609375, Neurons: 11, Grad norm: 5.078e+00\n",
      "Epoch 2694, Loss: 977.3299560546875, Neurons: 11, Grad norm: 5.091e+00\n",
      "Epoch 2695, Loss: 977.2891845703125, Neurons: 11, Grad norm: 5.079e+00\n",
      "Epoch 2696, Loss: 977.2483520507812, Neurons: 11, Grad norm: 5.089e+00\n",
      "Epoch 2697, Loss: 977.2075805664062, Neurons: 11, Grad norm: 5.068e+00\n",
      "Epoch 2698, Loss: 977.166748046875, Neurons: 11, Grad norm: 5.069e+00\n",
      "Epoch 2699, Loss: 977.1260986328125, Neurons: 11, Grad norm: 5.057e+00\n",
      "Epoch 2699, Test loss: 990.9366455078125\n",
      "Epoch 2700, Loss: 977.0853881835938, Neurons: 11, Grad norm: 5.054e+00\n",
      "Epoch 2701, Loss: 977.0447998046875, Neurons: 11, Grad norm: 5.056e+00\n",
      "Epoch 2702, Loss: 977.004150390625, Neurons: 11, Grad norm: 5.049e+00\n",
      "Epoch 2703, Loss: 976.9635620117188, Neurons: 11, Grad norm: 6.382e+00\n",
      "Epoch 2704, Loss: 976.9229736328125, Neurons: 11, Grad norm: 7.019e+00\n",
      "Epoch 2705, Loss: 976.8831787109375, Neurons: 11, Grad norm: 6.979e+00\n",
      "Epoch 2706, Loss: 976.8423461914062, Neurons: 11, Grad norm: 5.038e+00\n",
      "Epoch 2707, Loss: 976.8014526367188, Neurons: 11, Grad norm: 5.053e+00\n",
      "Epoch 2708, Loss: 976.7610473632812, Neurons: 11, Grad norm: 5.069e+00\n",
      "Epoch 2709, Loss: 976.7207641601562, Neurons: 11, Grad norm: 5.088e+00\n",
      "Epoch 2710, Loss: 976.6803588867188, Neurons: 11, Grad norm: 5.106e+00\n",
      "Epoch 2711, Loss: 976.6401977539062, Neurons: 11, Grad norm: 5.106e+00\n",
      "Epoch 2712, Loss: 976.5999755859375, Neurons: 11, Grad norm: 5.108e+00\n",
      "Epoch 2713, Loss: 976.5595703125, Neurons: 11, Grad norm: 5.088e+00\n",
      "Epoch 2714, Loss: 976.519287109375, Neurons: 11, Grad norm: 5.074e+00\n",
      "Epoch 2715, Loss: 976.47900390625, Neurons: 11, Grad norm: 5.046e+00\n",
      "Epoch 2716, Loss: 976.4387817382812, Neurons: 11, Grad norm: 5.028e+00\n",
      "Epoch 2717, Loss: 976.3985595703125, Neurons: 11, Grad norm: 5.010e+00\n",
      "Epoch 2718, Loss: 976.3583984375, Neurons: 11, Grad norm: 4.999e+00\n",
      "Epoch 2719, Loss: 976.3181762695312, Neurons: 11, Grad norm: 4.995e+00\n",
      "Epoch 2720, Loss: 976.2781982421875, Neurons: 11, Grad norm: 4.991e+00\n",
      "Epoch 2721, Loss: 976.2381591796875, Neurons: 11, Grad norm: 4.997e+00\n",
      "Epoch 2722, Loss: 976.1980590820312, Neurons: 11, Grad norm: 4.995e+00\n",
      "Epoch 2723, Loss: 976.158203125, Neurons: 11, Grad norm: 5.002e+00\n",
      "Epoch 2724, Loss: 976.1181640625, Neurons: 11, Grad norm: 4.997e+00\n",
      "Epoch 2725, Loss: 976.078369140625, Neurons: 11, Grad norm: 5.000e+00\n",
      "Epoch 2726, Loss: 976.0383911132812, Neurons: 11, Grad norm: 4.990e+00\n",
      "Epoch 2727, Loss: 975.9985961914062, Neurons: 11, Grad norm: 4.988e+00\n",
      "Epoch 2728, Loss: 975.9588012695312, Neurons: 11, Grad norm: 4.976e+00\n",
      "Epoch 2729, Loss: 975.9189453125, Neurons: 11, Grad norm: 4.971e+00\n",
      "Epoch 2730, Loss: 975.879150390625, Neurons: 11, Grad norm: 4.962e+00\n",
      "Epoch 2731, Loss: 975.83935546875, Neurons: 11, Grad norm: 4.958e+00\n",
      "Epoch 2732, Loss: 975.7996826171875, Neurons: 11, Grad norm: 4.952e+00\n",
      "Epoch 2733, Loss: 975.7599487304688, Neurons: 11, Grad norm: 4.949e+00\n",
      "Epoch 2734, Loss: 975.7203979492188, Neurons: 11, Grad norm: 4.946e+00\n",
      "Epoch 2735, Loss: 975.6806640625, Neurons: 11, Grad norm: 4.945e+00\n",
      "Epoch 2736, Loss: 975.6410522460938, Neurons: 11, Grad norm: 4.943e+00\n",
      "Epoch 2737, Loss: 975.6015625, Neurons: 11, Grad norm: 4.940e+00\n",
      "Epoch 2738, Loss: 975.5620727539062, Neurons: 11, Grad norm: 4.939e+00\n",
      "Epoch 2739, Loss: 975.5224609375, Neurons: 11, Grad norm: 4.934e+00\n",
      "Epoch 2740, Loss: 975.4829711914062, Neurons: 11, Grad norm: 4.932e+00\n",
      "Epoch 2741, Loss: 975.443603515625, Neurons: 11, Grad norm: 4.927e+00\n",
      "Epoch 2742, Loss: 975.4041748046875, Neurons: 11, Grad norm: 4.925e+00\n",
      "Epoch 2743, Loss: 975.36474609375, Neurons: 11, Grad norm: 4.918e+00\n",
      "Epoch 2744, Loss: 975.3255004882812, Neurons: 11, Grad norm: 4.918e+00\n",
      "Epoch 2745, Loss: 975.2861938476562, Neurons: 11, Grad norm: 4.911e+00\n",
      "Epoch 2746, Loss: 975.2467651367188, Neurons: 11, Grad norm: 4.915e+00\n",
      "Epoch 2747, Loss: 975.2075805664062, Neurons: 11, Grad norm: 4.906e+00\n",
      "Epoch 2748, Loss: 975.1682739257812, Neurons: 11, Grad norm: 4.917e+00\n",
      "Epoch 2749, Loss: 975.129150390625, Neurons: 11, Grad norm: 4.909e+00\n",
      "Epoch 2749, Test loss: 988.8239135742188\n",
      "Epoch 2750, Loss: 975.0899658203125, Neurons: 11, Grad norm: 4.936e+00\n",
      "Epoch 2751, Loss: 975.05078125, Neurons: 11, Grad norm: 4.935e+00\n",
      "Epoch 2752, Loss: 975.0116577148438, Neurons: 11, Grad norm: 5.007e+00\n",
      "Epoch 2753, Loss: 974.9725952148438, Neurons: 11, Grad norm: 5.048e+00\n",
      "Epoch 2754, Loss: 974.93359375, Neurons: 11, Grad norm: 5.260e+00\n",
      "Epoch 2755, Loss: 974.8945922851562, Neurons: 11, Grad norm: 5.482e+00\n",
      "Epoch 2756, Loss: 974.8555908203125, Neurons: 11, Grad norm: 6.114e+00\n",
      "Epoch 2757, Loss: 974.8165893554688, Neurons: 11, Grad norm: 6.903e+00\n",
      "Epoch 2758, Loss: 974.7776489257812, Neurons: 11, Grad norm: 8.454e+00\n",
      "Epoch 2759, Loss: 974.7388916015625, Neurons: 11, Grad norm: 1.013e+01\n",
      "Epoch 2760, Loss: 974.7001953125, Neurons: 11, Grad norm: 1.220e+01\n",
      "Epoch 2761, Loss: 974.6615600585938, Neurons: 11, Grad norm: 1.280e+01\n",
      "Epoch 2762, Loss: 974.622802734375, Neurons: 11, Grad norm: 1.159e+01\n",
      "Epoch 2763, Loss: 974.5838623046875, Neurons: 11, Grad norm: 7.514e+00\n",
      "Epoch 2764, Loss: 974.5447998046875, Neurons: 11, Grad norm: 4.854e+00\n",
      "Epoch 2765, Loss: 974.5057983398438, Neurons: 11, Grad norm: 7.575e+00\n",
      "Epoch 2766, Loss: 974.46728515625, Neurons: 11, Grad norm: 9.641e+00\n",
      "Epoch 2767, Loss: 974.4287719726562, Neurons: 11, Grad norm: 9.047e+00\n",
      "Epoch 2768, Loss: 974.3899536132812, Neurons: 11, Grad norm: 5.833e+00\n",
      "Epoch 2769, Loss: 974.3511962890625, Neurons: 11, Grad norm: 5.176e+00\n",
      "Epoch 2770, Loss: 974.3125610351562, Neurons: 11, Grad norm: 7.656e+00\n",
      "Epoch 2771, Loss: 974.274169921875, Neurons: 11, Grad norm: 8.060e+00\n",
      "Epoch 2772, Loss: 974.2356567382812, Neurons: 11, Grad norm: 6.356e+00\n",
      "Epoch 2773, Loss: 974.1969604492188, Neurons: 11, Grad norm: 4.842e+00\n",
      "Epoch 2774, Loss: 974.1583862304688, Neurons: 11, Grad norm: 6.221e+00\n",
      "Epoch 2775, Loss: 974.1201782226562, Neurons: 11, Grad norm: 7.315e+00\n",
      "Epoch 2776, Loss: 974.081787109375, Neurons: 11, Grad norm: 6.057e+00\n",
      "Epoch 2777, Loss: 974.0432739257812, Neurons: 11, Grad norm: 4.837e+00\n",
      "Epoch 2778, Loss: 974.0048828125, Neurons: 11, Grad norm: 5.671e+00\n",
      "Epoch 2779, Loss: 973.966552734375, Neurons: 11, Grad norm: 6.401e+00\n",
      "Epoch 2780, Loss: 973.9284057617188, Neurons: 11, Grad norm: 5.930e+00\n",
      "Epoch 2781, Loss: 973.8899536132812, Neurons: 11, Grad norm: 4.837e+00\n",
      "Epoch 2782, Loss: 973.8517456054688, Neurons: 11, Grad norm: 5.177e+00\n",
      "Epoch 2783, Loss: 973.8134765625, Neurons: 11, Grad norm: 5.992e+00\n",
      "Epoch 2784, Loss: 973.775390625, Neurons: 11, Grad norm: 5.561e+00\n",
      "Epoch 2785, Loss: 973.7371826171875, Neurons: 11, Grad norm: 4.896e+00\n",
      "Epoch 2786, Loss: 973.6990966796875, Neurons: 11, Grad norm: 5.017e+00\n",
      "Epoch 2787, Loss: 973.6609497070312, Neurons: 11, Grad norm: 5.459e+00\n",
      "Epoch 2788, Loss: 973.6228637695312, Neurons: 11, Grad norm: 5.476e+00\n",
      "Epoch 2789, Loss: 973.5847778320312, Neurons: 11, Grad norm: 4.869e+00\n",
      "Epoch 2790, Loss: 973.5467529296875, Neurons: 11, Grad norm: 4.825e+00\n",
      "Epoch 2791, Loss: 973.5087890625, Neurons: 11, Grad norm: 5.262e+00\n",
      "Epoch 2792, Loss: 973.4707641601562, Neurons: 11, Grad norm: 5.208e+00\n",
      "Epoch 2793, Loss: 973.4328002929688, Neurons: 11, Grad norm: 4.937e+00\n",
      "Epoch 2794, Loss: 973.3949584960938, Neurons: 11, Grad norm: 4.779e+00\n",
      "Epoch 2795, Loss: 973.357177734375, Neurons: 11, Grad norm: 4.963e+00\n",
      "Epoch 2796, Loss: 973.3191528320312, Neurons: 11, Grad norm: 5.151e+00\n",
      "Epoch 2797, Loss: 973.281494140625, Neurons: 11, Grad norm: 4.890e+00\n",
      "Epoch 2798, Loss: 973.24365234375, Neurons: 11, Grad norm: 4.753e+00\n",
      "Epoch 2799, Loss: 973.2058715820312, Neurons: 11, Grad norm: 4.869e+00\n",
      "Epoch 2799, Test loss: 986.7866821289062\n",
      "Epoch 2800, Loss: 973.1681518554688, Neurons: 11, Grad norm: 4.943e+00\n",
      "Epoch 2801, Loss: 973.1304931640625, Neurons: 11, Grad norm: 4.939e+00\n",
      "Epoch 2802, Loss: 973.0927734375, Neurons: 11, Grad norm: 4.750e+00\n",
      "Epoch 2803, Loss: 973.05517578125, Neurons: 11, Grad norm: 4.745e+00\n",
      "Epoch 2804, Loss: 973.0174560546875, Neurons: 11, Grad norm: 4.882e+00\n",
      "Epoch 2805, Loss: 972.9798583984375, Neurons: 11, Grad norm: 4.847e+00\n",
      "Epoch 2806, Loss: 972.9423828125, Neurons: 11, Grad norm: 4.799e+00\n",
      "Epoch 2807, Loss: 972.90478515625, Neurons: 11, Grad norm: 4.722e+00\n",
      "Epoch 2808, Loss: 972.8671875, Neurons: 11, Grad norm: 4.749e+00\n",
      "Epoch 2809, Loss: 972.8297729492188, Neurons: 11, Grad norm: 4.837e+00\n",
      "Epoch 2810, Loss: 972.7923583984375, Neurons: 11, Grad norm: 4.768e+00\n",
      "Epoch 2811, Loss: 972.7548828125, Neurons: 11, Grad norm: 4.734e+00\n",
      "Epoch 2812, Loss: 972.7174682617188, Neurons: 11, Grad norm: 4.716e+00\n",
      "Epoch 2813, Loss: 972.68017578125, Neurons: 11, Grad norm: 4.733e+00\n",
      "Epoch 2814, Loss: 972.6427612304688, Neurons: 11, Grad norm: 4.783e+00\n",
      "Epoch 2815, Loss: 972.6055908203125, Neurons: 11, Grad norm: 4.722e+00\n",
      "Epoch 2816, Loss: 972.5681762695312, Neurons: 11, Grad norm: 4.704e+00\n",
      "Epoch 2817, Loss: 972.5308837890625, Neurons: 11, Grad norm: 4.704e+00\n",
      "Epoch 2818, Loss: 972.4937744140625, Neurons: 11, Grad norm: 4.708e+00\n",
      "Epoch 2819, Loss: 972.4566040039062, Neurons: 11, Grad norm: 4.740e+00\n",
      "Epoch 2820, Loss: 972.4193725585938, Neurons: 11, Grad norm: 4.694e+00\n",
      "Epoch 2821, Loss: 972.3822021484375, Neurons: 11, Grad norm: 4.685e+00\n",
      "Epoch 2822, Loss: 972.344970703125, Neurons: 11, Grad norm: 4.686e+00\n",
      "Epoch 2823, Loss: 972.3079833984375, Neurons: 11, Grad norm: 4.684e+00\n",
      "Epoch 2824, Loss: 972.2708740234375, Neurons: 11, Grad norm: 4.707e+00\n",
      "Epoch 2825, Loss: 972.23388671875, Neurons: 11, Grad norm: 4.674e+00\n",
      "Epoch 2826, Loss: 972.19677734375, Neurons: 11, Grad norm: 4.671e+00\n",
      "Epoch 2827, Loss: 972.1598510742188, Neurons: 11, Grad norm: 4.667e+00\n",
      "Epoch 2828, Loss: 972.1228637695312, Neurons: 11, Grad norm: 4.663e+00\n",
      "Epoch 2829, Loss: 972.0859985351562, Neurons: 11, Grad norm: 4.681e+00\n",
      "Epoch 2830, Loss: 972.049072265625, Neurons: 11, Grad norm: 4.658e+00\n",
      "Epoch 2831, Loss: 972.0121459960938, Neurons: 11, Grad norm: 4.658e+00\n",
      "Epoch 2832, Loss: 971.9754028320312, Neurons: 11, Grad norm: 4.648e+00\n",
      "Epoch 2833, Loss: 971.9385986328125, Neurons: 11, Grad norm: 4.644e+00\n",
      "Epoch 2834, Loss: 971.9017944335938, Neurons: 11, Grad norm: 4.657e+00\n",
      "Epoch 2835, Loss: 971.864990234375, Neurons: 11, Grad norm: 4.641e+00\n",
      "Epoch 2836, Loss: 971.8281860351562, Neurons: 11, Grad norm: 4.646e+00\n",
      "Epoch 2837, Loss: 971.7915649414062, Neurons: 11, Grad norm: 4.632e+00\n",
      "Epoch 2838, Loss: 971.7548828125, Neurons: 11, Grad norm: 4.629e+00\n",
      "Epoch 2839, Loss: 971.7182006835938, Neurons: 11, Grad norm: 4.634e+00\n",
      "Epoch 2840, Loss: 971.6815795898438, Neurons: 11, Grad norm: 4.625e+00\n",
      "Epoch 2841, Loss: 971.6449584960938, Neurons: 11, Grad norm: 4.631e+00\n",
      "Epoch 2842, Loss: 971.6083984375, Neurons: 11, Grad norm: 4.618e+00\n",
      "Epoch 2843, Loss: 971.57177734375, Neurons: 11, Grad norm: 4.618e+00\n",
      "Epoch 2844, Loss: 971.5352783203125, Neurons: 11, Grad norm: 4.614e+00\n",
      "Epoch 2845, Loss: 971.498779296875, Neurons: 11, Grad norm: 4.609e+00\n",
      "Epoch 2846, Loss: 971.46240234375, Neurons: 11, Grad norm: 4.613e+00\n",
      "Epoch 2847, Loss: 971.4259033203125, Neurons: 11, Grad norm: 4.603e+00\n",
      "Epoch 2848, Loss: 971.3894653320312, Neurons: 11, Grad norm: 4.606e+00\n",
      "Epoch 2849, Loss: 971.3530883789062, Neurons: 11, Grad norm: 4.597e+00\n",
      "Epoch 2849, Test loss: 984.8253784179688\n",
      "Epoch 2850, Loss: 971.316650390625, Neurons: 11, Grad norm: 4.596e+00\n",
      "Epoch 2851, Loss: 971.2803955078125, Neurons: 11, Grad norm: 4.594e+00\n",
      "Epoch 2852, Loss: 971.2440795898438, Neurons: 11, Grad norm: 4.588e+00\n",
      "Epoch 2853, Loss: 971.2078857421875, Neurons: 11, Grad norm: 4.591e+00\n",
      "Epoch 2854, Loss: 971.1715698242188, Neurons: 11, Grad norm: 4.583e+00\n",
      "Epoch 2855, Loss: 971.1353759765625, Neurons: 11, Grad norm: 4.584e+00\n",
      "Epoch 2856, Loss: 971.0991821289062, Neurons: 11, Grad norm: 4.577e+00\n",
      "Epoch 2857, Loss: 971.06298828125, Neurons: 11, Grad norm: 4.576e+00\n",
      "Epoch 2858, Loss: 971.02685546875, Neurons: 11, Grad norm: 4.573e+00\n",
      "Epoch 2859, Loss: 970.9907836914062, Neurons: 11, Grad norm: 4.568e+00\n",
      "Epoch 2860, Loss: 970.9546508789062, Neurons: 11, Grad norm: 4.569e+00\n",
      "Epoch 2861, Loss: 970.9185791015625, Neurons: 11, Grad norm: 4.562e+00\n",
      "Epoch 2862, Loss: 970.882568359375, Neurons: 11, Grad norm: 4.564e+00\n",
      "Epoch 2863, Loss: 970.8465576171875, Neurons: 11, Grad norm: 4.557e+00\n",
      "Epoch 2864, Loss: 970.810546875, Neurons: 11, Grad norm: 4.556e+00\n",
      "Epoch 2865, Loss: 970.7745971679688, Neurons: 11, Grad norm: 4.552e+00\n",
      "Epoch 2866, Loss: 970.7386474609375, Neurons: 11, Grad norm: 4.549e+00\n",
      "Epoch 2867, Loss: 970.7027587890625, Neurons: 11, Grad norm: 4.547e+00\n",
      "Epoch 2868, Loss: 970.6668701171875, Neurons: 11, Grad norm: 4.543e+00\n",
      "Epoch 2869, Loss: 970.6309814453125, Neurons: 11, Grad norm: 4.542e+00\n",
      "Epoch 2870, Loss: 970.5951538085938, Neurons: 11, Grad norm: 4.537e+00\n",
      "Epoch 2871, Loss: 970.5593872070312, Neurons: 11, Grad norm: 4.537e+00\n",
      "Epoch 2872, Loss: 970.5235595703125, Neurons: 11, Grad norm: 4.531e+00\n",
      "Epoch 2873, Loss: 970.4878540039062, Neurons: 11, Grad norm: 4.531e+00\n",
      "Epoch 2874, Loss: 970.4521484375, Neurons: 11, Grad norm: 4.526e+00\n",
      "Epoch 2875, Loss: 970.4163818359375, Neurons: 11, Grad norm: 4.524e+00\n",
      "Epoch 2876, Loss: 970.3807983398438, Neurons: 11, Grad norm: 4.520e+00\n",
      "Epoch 2877, Loss: 970.3451538085938, Neurons: 11, Grad norm: 4.518e+00\n",
      "Epoch 2878, Loss: 970.3095703125, Neurons: 11, Grad norm: 4.515e+00\n",
      "Epoch 2879, Loss: 970.2739868164062, Neurons: 11, Grad norm: 4.512e+00\n",
      "Epoch 2880, Loss: 970.2384033203125, Neurons: 11, Grad norm: 4.510e+00\n",
      "Epoch 2881, Loss: 970.2027587890625, Neurons: 11, Grad norm: 4.506e+00\n",
      "Epoch 2882, Loss: 970.1673583984375, Neurons: 11, Grad norm: 4.505e+00\n",
      "Epoch 2883, Loss: 970.1317749023438, Neurons: 11, Grad norm: 5.698e+00\n",
      "Epoch 2884, Loss: 970.0963745117188, Neurons: 11, Grad norm: 6.333e+00\n",
      "Epoch 2885, Loss: 970.0615844726562, Neurons: 11, Grad norm: 6.292e+00\n",
      "Epoch 2886, Loss: 970.02587890625, Neurons: 11, Grad norm: 4.494e+00\n",
      "Epoch 2887, Loss: 969.9901733398438, Neurons: 11, Grad norm: 4.505e+00\n",
      "Epoch 2888, Loss: 969.9548950195312, Neurons: 11, Grad norm: 4.517e+00\n",
      "Epoch 2889, Loss: 969.9195556640625, Neurons: 11, Grad norm: 4.534e+00\n",
      "Epoch 2890, Loss: 969.8843994140625, Neurons: 11, Grad norm: 4.542e+00\n",
      "Epoch 2891, Loss: 969.8490600585938, Neurons: 11, Grad norm: 4.550e+00\n",
      "Epoch 2892, Loss: 969.8137817382812, Neurons: 11, Grad norm: 4.545e+00\n",
      "Epoch 2893, Loss: 969.778564453125, Neurons: 11, Grad norm: 4.541e+00\n",
      "Epoch 2894, Loss: 969.7433471679688, Neurons: 11, Grad norm: 4.524e+00\n",
      "Epoch 2895, Loss: 969.708251953125, Neurons: 11, Grad norm: 4.513e+00\n",
      "Epoch 2896, Loss: 969.6729736328125, Neurons: 11, Grad norm: 4.492e+00\n",
      "Epoch 2897, Loss: 969.6378784179688, Neurons: 11, Grad norm: 4.482e+00\n",
      "Epoch 2898, Loss: 969.602783203125, Neurons: 11, Grad norm: 4.465e+00\n",
      "Epoch 2899, Loss: 969.5676879882812, Neurons: 11, Grad norm: 4.464e+00\n",
      "Epoch 2899, Test loss: 982.9332885742188\n",
      "Epoch 2900, Loss: 969.5325927734375, Neurons: 11, Grad norm: 4.453e+00\n",
      "Epoch 2901, Loss: 969.49755859375, Neurons: 11, Grad norm: 4.463e+00\n",
      "Epoch 2902, Loss: 969.4625854492188, Neurons: 11, Grad norm: 4.454e+00\n",
      "Epoch 2903, Loss: 969.4275512695312, Neurons: 11, Grad norm: 4.475e+00\n",
      "Epoch 2904, Loss: 969.3927001953125, Neurons: 11, Grad norm: 4.465e+00\n",
      "Epoch 2905, Loss: 969.3577880859375, Neurons: 11, Grad norm: 4.500e+00\n",
      "Epoch 2906, Loss: 969.3228759765625, Neurons: 11, Grad norm: 4.490e+00\n",
      "Epoch 2907, Loss: 969.2880859375, Neurons: 11, Grad norm: 4.558e+00\n",
      "Epoch 2908, Loss: 969.253173828125, Neurons: 11, Grad norm: 4.570e+00\n",
      "Epoch 2909, Loss: 969.2183837890625, Neurons: 11, Grad norm: 4.727e+00\n",
      "Epoch 2910, Loss: 969.18359375, Neurons: 11, Grad norm: 4.831e+00\n",
      "Epoch 2911, Loss: 969.1488647460938, Neurons: 11, Grad norm: 5.231e+00\n",
      "Epoch 2912, Loss: 969.1141967773438, Neurons: 11, Grad norm: 5.631e+00\n",
      "Epoch 2913, Loss: 969.079345703125, Neurons: 11, Grad norm: 6.600e+00\n",
      "Epoch 2914, Loss: 969.0447998046875, Neurons: 11, Grad norm: 7.661e+00\n",
      "Epoch 2915, Loss: 969.0101928710938, Neurons: 11, Grad norm: 9.505e+00\n",
      "Epoch 2916, Loss: 968.9756469726562, Neurons: 11, Grad norm: 1.119e+01\n",
      "Epoch 2917, Loss: 968.941162109375, Neurons: 11, Grad norm: 1.303e+01\n",
      "Epoch 2918, Loss: 968.9067993164062, Neurons: 11, Grad norm: 1.310e+01\n",
      "Epoch 2919, Loss: 968.8722534179688, Neurons: 11, Grad norm: 1.149e+01\n",
      "Epoch 2920, Loss: 968.8375854492188, Neurons: 11, Grad norm: 7.310e+00\n",
      "Epoch 2921, Loss: 968.8027954101562, Neurons: 11, Grad norm: 4.406e+00\n",
      "Epoch 2922, Loss: 968.7681884765625, Neurons: 11, Grad norm: 6.861e+00\n",
      "Epoch 2923, Loss: 968.7337646484375, Neurons: 11, Grad norm: 9.313e+00\n",
      "Epoch 2924, Loss: 968.699462890625, Neurons: 11, Grad norm: 9.660e+00\n",
      "Epoch 2925, Loss: 968.6651000976562, Neurons: 11, Grad norm: 7.013e+00\n",
      "Epoch 2926, Loss: 968.6304931640625, Neurons: 11, Grad norm: 4.490e+00\n",
      "Epoch 2927, Loss: 968.595947265625, Neurons: 11, Grad norm: 5.821e+00\n",
      "Epoch 2928, Loss: 968.561767578125, Neurons: 11, Grad norm: 7.678e+00\n",
      "Epoch 2929, Loss: 968.527587890625, Neurons: 11, Grad norm: 7.831e+00\n",
      "Epoch 2930, Loss: 968.4932861328125, Neurons: 11, Grad norm: 5.663e+00\n",
      "Epoch 2931, Loss: 968.458984375, Neurons: 11, Grad norm: 4.367e+00\n",
      "Epoch 2932, Loss: 968.424560546875, Neurons: 11, Grad norm: 5.766e+00\n",
      "Epoch 2933, Loss: 968.390380859375, Neurons: 11, Grad norm: 6.736e+00\n",
      "Epoch 2934, Loss: 968.3562622070312, Neurons: 11, Grad norm: 6.384e+00\n",
      "Epoch 2935, Loss: 968.3222045898438, Neurons: 11, Grad norm: 4.738e+00\n",
      "Epoch 2936, Loss: 968.2879638671875, Neurons: 11, Grad norm: 4.478e+00\n",
      "Epoch 2937, Loss: 968.2537841796875, Neurons: 11, Grad norm: 5.668e+00\n",
      "Epoch 2938, Loss: 968.2197875976562, Neurons: 11, Grad norm: 5.941e+00\n",
      "Epoch 2939, Loss: 968.185791015625, Neurons: 11, Grad norm: 5.362e+00\n",
      "Epoch 2940, Loss: 968.1517944335938, Neurons: 11, Grad norm: 4.383e+00\n",
      "Epoch 2941, Loss: 968.11767578125, Neurons: 11, Grad norm: 4.604e+00\n",
      "Epoch 2942, Loss: 968.0838012695312, Neurons: 11, Grad norm: 5.418e+00\n",
      "Epoch 2943, Loss: 968.0498046875, Neurons: 11, Grad norm: 5.289e+00\n",
      "Epoch 2944, Loss: 968.0157470703125, Neurons: 11, Grad norm: 4.779e+00\n",
      "Epoch 2945, Loss: 967.9819946289062, Neurons: 11, Grad norm: 4.331e+00\n",
      "Epoch 2946, Loss: 967.947998046875, Neurons: 11, Grad norm: 4.617e+00\n",
      "Epoch 2947, Loss: 967.9141845703125, Neurons: 11, Grad norm: 5.102e+00\n",
      "Epoch 2948, Loss: 967.88037109375, Neurons: 11, Grad norm: 4.858e+00\n",
      "Epoch 2949, Loss: 967.8464965820312, Neurons: 11, Grad norm: 4.512e+00\n",
      "Epoch 2949, Test loss: 981.1077880859375\n",
      "Epoch 2950, Loss: 967.8128051757812, Neurons: 11, Grad norm: 4.337e+00\n",
      "Epoch 2951, Loss: 967.7789916992188, Neurons: 11, Grad norm: 4.542e+00\n",
      "Epoch 2952, Loss: 967.7451782226562, Neurons: 11, Grad norm: 4.835e+00\n",
      "Epoch 2953, Loss: 967.7115478515625, Neurons: 11, Grad norm: 4.609e+00\n",
      "Epoch 2954, Loss: 967.6777954101562, Neurons: 11, Grad norm: 4.408e+00\n",
      "Epoch 2955, Loss: 967.6441650390625, Neurons: 11, Grad norm: 4.325e+00\n",
      "Epoch 2956, Loss: 967.6104736328125, Neurons: 11, Grad norm: 4.444e+00\n",
      "Epoch 2957, Loss: 967.5769653320312, Neurons: 11, Grad norm: 4.636e+00\n",
      "Epoch 2958, Loss: 967.5433959960938, Neurons: 11, Grad norm: 4.479e+00\n",
      "Epoch 2959, Loss: 967.509765625, Neurons: 11, Grad norm: 4.367e+00\n",
      "Epoch 2960, Loss: 967.4761962890625, Neurons: 11, Grad norm: 4.299e+00\n",
      "Epoch 2961, Loss: 967.4427490234375, Neurons: 11, Grad norm: 4.357e+00\n",
      "Epoch 2962, Loss: 967.4091796875, Neurons: 11, Grad norm: 4.498e+00\n",
      "Epoch 2963, Loss: 967.3757934570312, Neurons: 11, Grad norm: 4.403e+00\n",
      "Epoch 2964, Loss: 967.34228515625, Neurons: 11, Grad norm: 4.353e+00\n",
      "Epoch 2965, Loss: 967.3088989257812, Neurons: 11, Grad norm: 4.276e+00\n",
      "Epoch 2966, Loss: 967.2754516601562, Neurons: 11, Grad norm: 4.294e+00\n",
      "Epoch 2967, Loss: 967.2420654296875, Neurons: 11, Grad norm: 4.393e+00\n",
      "Epoch 2968, Loss: 967.2088012695312, Neurons: 11, Grad norm: 4.350e+00\n",
      "Epoch 2969, Loss: 967.1754760742188, Neurons: 11, Grad norm: 4.345e+00\n",
      "Epoch 2970, Loss: 967.14208984375, Neurons: 11, Grad norm: 4.265e+00\n",
      "Epoch 2971, Loss: 967.1087646484375, Neurons: 11, Grad norm: 4.260e+00\n",
      "Epoch 2972, Loss: 967.0755615234375, Neurons: 11, Grad norm: 4.312e+00\n",
      "Epoch 2973, Loss: 967.0423583984375, Neurons: 11, Grad norm: 4.300e+00\n",
      "Epoch 2974, Loss: 967.0091552734375, Neurons: 11, Grad norm: 4.329e+00\n",
      "Epoch 2975, Loss: 966.9759521484375, Neurons: 11, Grad norm: 4.263e+00\n",
      "Epoch 2976, Loss: 966.94287109375, Neurons: 11, Grad norm: 4.253e+00\n",
      "Epoch 2977, Loss: 966.9097900390625, Neurons: 11, Grad norm: 4.256e+00\n",
      "Epoch 2978, Loss: 966.8765869140625, Neurons: 11, Grad norm: 4.254e+00\n",
      "Epoch 2979, Loss: 966.8435668945312, Neurons: 11, Grad norm: 4.293e+00\n",
      "Epoch 2980, Loss: 966.8104858398438, Neurons: 11, Grad norm: 4.256e+00\n",
      "Epoch 2981, Loss: 966.7774047851562, Neurons: 11, Grad norm: 4.261e+00\n",
      "Epoch 2982, Loss: 966.744384765625, Neurons: 11, Grad norm: 4.231e+00\n",
      "Epoch 2983, Loss: 966.7113647460938, Neurons: 11, Grad norm: 4.228e+00\n",
      "Epoch 2984, Loss: 966.678466796875, Neurons: 11, Grad norm: 4.245e+00\n",
      "Epoch 2985, Loss: 966.6455688476562, Neurons: 11, Grad norm: 4.233e+00\n",
      "Epoch 2986, Loss: 966.612548828125, Neurons: 11, Grad norm: 4.254e+00\n",
      "Epoch 2987, Loss: 966.5797729492188, Neurons: 11, Grad norm: 4.224e+00\n",
      "Epoch 2988, Loss: 966.5467529296875, Neurons: 11, Grad norm: 4.227e+00\n",
      "Epoch 2989, Loss: 966.5139770507812, Neurons: 11, Grad norm: 4.213e+00\n",
      "Epoch 2990, Loss: 966.481201171875, Neurons: 11, Grad norm: 4.210e+00\n",
      "Epoch 2991, Loss: 966.4483642578125, Neurons: 11, Grad norm: 4.221e+00\n",
      "Epoch 2992, Loss: 966.4155883789062, Neurons: 11, Grad norm: 4.208e+00\n",
      "Epoch 2993, Loss: 966.3828735351562, Neurons: 11, Grad norm: 4.223e+00\n",
      "Epoch 2994, Loss: 966.3501586914062, Neurons: 11, Grad norm: 4.202e+00\n",
      "Epoch 2995, Loss: 966.3173828125, Neurons: 11, Grad norm: 4.207e+00\n",
      "Epoch 2996, Loss: 966.2847900390625, Neurons: 11, Grad norm: 4.194e+00\n",
      "Epoch 2997, Loss: 966.2520751953125, Neurons: 11, Grad norm: 4.192e+00\n",
      "Epoch 2998, Loss: 966.219482421875, Neurons: 11, Grad norm: 4.195e+00\n",
      "Epoch 2999, Loss: 966.1868896484375, Neurons: 11, Grad norm: 4.187e+00\n",
      "Epoch 2999, Test loss: 979.3488159179688\n",
      "Epoch 3000, Loss: 966.154296875, Neurons: 11, Grad norm: 4.197e+00\n",
      "Epoch 3001, Loss: 966.1217041015625, Neurons: 11, Grad norm: 4.182e+00\n",
      "Epoch 3002, Loss: 966.0891723632812, Neurons: 11, Grad norm: 4.189e+00\n",
      "Epoch 3003, Loss: 966.0567016601562, Neurons: 11, Grad norm: 4.176e+00\n",
      "Epoch 3004, Loss: 966.024169921875, Neurons: 11, Grad norm: 4.178e+00\n",
      "Epoch 3005, Loss: 965.9917602539062, Neurons: 11, Grad norm: 4.172e+00\n",
      "Epoch 3006, Loss: 965.9592895507812, Neurons: 11, Grad norm: 4.169e+00\n",
      "Epoch 3007, Loss: 965.9268798828125, Neurons: 11, Grad norm: 4.170e+00\n",
      "Epoch 3008, Loss: 965.8944702148438, Neurons: 11, Grad norm: 4.163e+00\n",
      "Epoch 3009, Loss: 965.862060546875, Neurons: 11, Grad norm: 4.169e+00\n",
      "Epoch 3010, Loss: 965.8297729492188, Neurons: 11, Grad norm: 4.158e+00\n",
      "Epoch 3011, Loss: 965.79736328125, Neurons: 11, Grad norm: 4.164e+00\n",
      "Epoch 3012, Loss: 965.7650756835938, Neurons: 11, Grad norm: 4.153e+00\n",
      "Epoch 3013, Loss: 965.7327880859375, Neurons: 11, Grad norm: 4.157e+00\n",
      "Epoch 3014, Loss: 965.7005615234375, Neurons: 11, Grad norm: 4.148e+00\n",
      "Epoch 3015, Loss: 965.6682739257812, Neurons: 11, Grad norm: 4.149e+00\n",
      "Epoch 3016, Loss: 965.6360473632812, Neurons: 11, Grad norm: 4.143e+00\n",
      "Epoch 3017, Loss: 965.6038818359375, Neurons: 11, Grad norm: 4.141e+00\n",
      "Epoch 3018, Loss: 965.57177734375, Neurons: 11, Grad norm: 4.139e+00\n",
      "Epoch 3019, Loss: 965.5396728515625, Neurons: 11, Grad norm: 4.135e+00\n",
      "Epoch 3020, Loss: 965.5074462890625, Neurons: 11, Grad norm: 4.136e+00\n",
      "Epoch 3021, Loss: 965.4754028320312, Neurons: 11, Grad norm: 4.130e+00\n",
      "Epoch 3022, Loss: 965.4432983398438, Neurons: 11, Grad norm: 4.132e+00\n",
      "Epoch 3023, Loss: 965.411376953125, Neurons: 11, Grad norm: 4.125e+00\n",
      "Epoch 3024, Loss: 965.3792724609375, Neurons: 11, Grad norm: 4.128e+00\n",
      "Epoch 3025, Loss: 965.34716796875, Neurons: 11, Grad norm: 4.119e+00\n",
      "Epoch 3026, Loss: 965.3152465820312, Neurons: 11, Grad norm: 4.124e+00\n",
      "Epoch 3027, Loss: 965.2833862304688, Neurons: 11, Grad norm: 4.114e+00\n",
      "Epoch 3028, Loss: 965.2514038085938, Neurons: 11, Grad norm: 4.120e+00\n",
      "Epoch 3029, Loss: 965.219482421875, Neurons: 11, Grad norm: 4.110e+00\n",
      "Epoch 3030, Loss: 965.1875610351562, Neurons: 11, Grad norm: 4.117e+00\n",
      "Epoch 3031, Loss: 965.15576171875, Neurons: 11, Grad norm: 4.105e+00\n",
      "Epoch 3032, Loss: 965.1239013671875, Neurons: 11, Grad norm: 4.115e+00\n",
      "Epoch 3033, Loss: 965.0919799804688, Neurons: 11, Grad norm: 4.102e+00\n",
      "Epoch 3034, Loss: 965.0601806640625, Neurons: 11, Grad norm: 4.118e+00\n",
      "Epoch 3035, Loss: 965.0283813476562, Neurons: 11, Grad norm: 4.102e+00\n",
      "Epoch 3036, Loss: 964.9967041015625, Neurons: 11, Grad norm: 4.129e+00\n",
      "Epoch 3037, Loss: 964.9649658203125, Neurons: 11, Grad norm: 4.113e+00\n",
      "Epoch 3038, Loss: 964.9331665039062, Neurons: 11, Grad norm: 4.162e+00\n",
      "Epoch 3039, Loss: 964.9015502929688, Neurons: 11, Grad norm: 4.153e+00\n",
      "Epoch 3040, Loss: 964.8699951171875, Neurons: 11, Grad norm: 4.255e+00\n",
      "Epoch 3041, Loss: 964.8382568359375, Neurons: 11, Grad norm: 4.281e+00\n",
      "Epoch 3042, Loss: 964.8067016601562, Neurons: 11, Grad norm: 4.512e+00\n",
      "Epoch 3043, Loss: 964.7750854492188, Neurons: 11, Grad norm: 4.670e+00\n",
      "Epoch 3044, Loss: 964.7434692382812, Neurons: 11, Grad norm: 5.215e+00\n",
      "Epoch 3045, Loss: 964.7119750976562, Neurons: 11, Grad norm: 5.747e+00\n",
      "Epoch 3046, Loss: 964.6803588867188, Neurons: 11, Grad norm: 6.945e+00\n",
      "Epoch 3047, Loss: 964.6489868164062, Neurons: 11, Grad norm: 8.213e+00\n",
      "Epoch 3048, Loss: 964.6175537109375, Neurons: 11, Grad norm: 1.032e+01\n",
      "Epoch 3049, Loss: 964.5863037109375, Neurons: 11, Grad norm: 1.220e+01\n",
      "Epoch 3049, Test loss: 977.6597900390625\n",
      "Epoch 3050, Loss: 964.5550537109375, Neurons: 11, Grad norm: 1.424e+01\n",
      "Epoch 3051, Loss: 964.5238037109375, Neurons: 11, Grad norm: 1.439e+01\n",
      "Epoch 3052, Loss: 964.4924926757812, Neurons: 11, Grad norm: 1.277e+01\n",
      "Epoch 3053, Loss: 964.4608764648438, Neurons: 11, Grad norm: 8.185e+00\n",
      "Epoch 3054, Loss: 964.42919921875, Neurons: 11, Grad norm: 4.207e+00\n",
      "Epoch 3055, Loss: 964.397705078125, Neurons: 11, Grad norm: 6.468e+00\n",
      "Epoch 3056, Loss: 964.3665771484375, Neurons: 11, Grad norm: 9.593e+00\n",
      "Epoch 3057, Loss: 964.3353881835938, Neurons: 11, Grad norm: 1.059e+01\n",
      "Epoch 3058, Loss: 964.30419921875, Neurons: 11, Grad norm: 8.140e+00\n",
      "Epoch 3059, Loss: 964.2727661132812, Neurons: 11, Grad norm: 4.765e+00\n",
      "Epoch 3060, Loss: 964.2413940429688, Neurons: 11, Grad norm: 4.960e+00\n",
      "Epoch 3061, Loss: 964.2102661132812, Neurons: 11, Grad norm: 7.483e+00\n",
      "Epoch 3062, Loss: 964.17919921875, Neurons: 11, Grad norm: 8.543e+00\n",
      "Epoch 3063, Loss: 964.1480712890625, Neurons: 11, Grad norm: 6.670e+00\n",
      "Epoch 3064, Loss: 964.1168823242188, Neurons: 11, Grad norm: 4.381e+00\n",
      "Epoch 3065, Loss: 964.085693359375, Neurons: 11, Grad norm: 4.809e+00\n",
      "Epoch 3066, Loss: 964.0545654296875, Neurons: 11, Grad norm: 6.494e+00\n",
      "Epoch 3067, Loss: 964.023681640625, Neurons: 11, Grad norm: 7.049e+00\n",
      "Epoch 3068, Loss: 963.99267578125, Neurons: 11, Grad norm: 5.453e+00\n",
      "Epoch 3069, Loss: 963.9615478515625, Neurons: 11, Grad norm: 4.081e+00\n",
      "Epoch 3070, Loss: 963.9304809570312, Neurons: 11, Grad norm: 4.781e+00\n",
      "Epoch 3071, Loss: 963.8995971679688, Neurons: 11, Grad norm: 5.801e+00\n",
      "Epoch 3072, Loss: 963.86865234375, Neurons: 11, Grad norm: 5.966e+00\n",
      "Epoch 3073, Loss: 963.837646484375, Neurons: 11, Grad norm: 4.687e+00\n",
      "Epoch 3074, Loss: 963.8067626953125, Neurons: 11, Grad norm: 4.000e+00\n",
      "Epoch 3075, Loss: 963.77587890625, Neurons: 11, Grad norm: 4.676e+00\n",
      "Epoch 3076, Loss: 963.7449951171875, Neurons: 11, Grad norm: 5.223e+00\n",
      "Epoch 3077, Loss: 963.7142944335938, Neurons: 11, Grad norm: 5.228e+00\n",
      "Epoch 3078, Loss: 963.683349609375, Neurons: 11, Grad norm: 4.315e+00\n",
      "Epoch 3079, Loss: 963.652587890625, Neurons: 11, Grad norm: 3.987e+00\n",
      "Epoch 3080, Loss: 963.6217651367188, Neurons: 11, Grad norm: 7.059e+00\n",
      "Epoch 3081, Loss: 963.591064453125, Neurons: 11, Grad norm: 6.289e+00\n",
      "Epoch 3082, Loss: 963.5609741210938, Neurons: 11, Grad norm: 6.322e+00\n",
      "Epoch 3083, Loss: 963.5303955078125, Neurons: 11, Grad norm: 5.766e+00\n",
      "Epoch 3084, Loss: 963.499267578125, Neurons: 11, Grad norm: 3.979e+00\n",
      "Epoch 3085, Loss: 963.46826171875, Neurons: 11, Grad norm: 4.349e+00\n",
      "Epoch 3086, Loss: 963.4376831054688, Neurons: 11, Grad norm: 4.516e+00\n",
      "Epoch 3087, Loss: 963.4071044921875, Neurons: 11, Grad norm: 4.509e+00\n",
      "Epoch 3088, Loss: 963.3765869140625, Neurons: 11, Grad norm: 4.121e+00\n",
      "Epoch 3089, Loss: 963.345947265625, Neurons: 11, Grad norm: 4.047e+00\n",
      "Epoch 3090, Loss: 963.3154907226562, Neurons: 11, Grad norm: 4.281e+00\n",
      "Epoch 3091, Loss: 963.2849731445312, Neurons: 11, Grad norm: 4.346e+00\n",
      "Epoch 3092, Loss: 963.2544555664062, Neurons: 11, Grad norm: 4.367e+00\n",
      "Epoch 3093, Loss: 963.2239990234375, Neurons: 11, Grad norm: 4.085e+00\n",
      "Epoch 3094, Loss: 963.1934814453125, Neurons: 11, Grad norm: 4.008e+00\n",
      "Epoch 3095, Loss: 963.1629638671875, Neurons: 11, Grad norm: 4.117e+00\n",
      "Epoch 3096, Loss: 963.132568359375, Neurons: 11, Grad norm: 4.149e+00\n",
      "Epoch 3097, Loss: 963.1021728515625, Neurons: 11, Grad norm: 4.194e+00\n",
      "Epoch 3098, Loss: 963.0716552734375, Neurons: 11, Grad norm: 4.007e+00\n",
      "Epoch 3099, Loss: 963.041259765625, Neurons: 11, Grad norm: 3.949e+00\n",
      "Epoch 3099, Test loss: 976.0103149414062\n",
      "Epoch 3100, Loss: 963.010986328125, Neurons: 11, Grad norm: 3.986e+00\n",
      "Epoch 3101, Loss: 962.9806518554688, Neurons: 11, Grad norm: 4.014e+00\n",
      "Epoch 3102, Loss: 962.9503784179688, Neurons: 11, Grad norm: 4.102e+00\n",
      "Epoch 3103, Loss: 962.9201049804688, Neurons: 11, Grad norm: 3.991e+00\n",
      "Epoch 3104, Loss: 962.8897705078125, Neurons: 11, Grad norm: 3.965e+00\n",
      "Epoch 3105, Loss: 962.8595581054688, Neurons: 11, Grad norm: 3.942e+00\n",
      "Epoch 3106, Loss: 962.829345703125, Neurons: 11, Grad norm: 3.956e+00\n",
      "Epoch 3107, Loss: 962.7992553710938, Neurons: 11, Grad norm: 4.034e+00\n",
      "Epoch 3108, Loss: 962.7691040039062, Neurons: 11, Grad norm: 3.982e+00\n",
      "Epoch 3109, Loss: 962.7388916015625, Neurons: 11, Grad norm: 3.984e+00\n",
      "Epoch 3110, Loss: 962.7088012695312, Neurons: 11, Grad norm: 3.924e+00\n",
      "Epoch 3111, Loss: 962.6785888671875, Neurons: 11, Grad norm: 3.918e+00\n",
      "Epoch 3112, Loss: 962.6485595703125, Neurons: 11, Grad norm: 3.954e+00\n",
      "Epoch 3113, Loss: 962.6185913085938, Neurons: 11, Grad norm: 3.935e+00\n",
      "Epoch 3114, Loss: 962.5885009765625, Neurons: 11, Grad norm: 3.967e+00\n",
      "Epoch 3115, Loss: 962.558349609375, Neurons: 11, Grad norm: 3.912e+00\n",
      "Epoch 3116, Loss: 962.5285034179688, Neurons: 11, Grad norm: 3.910e+00\n",
      "Epoch 3117, Loss: 962.4984741210938, Neurons: 11, Grad norm: 3.898e+00\n",
      "Epoch 3118, Loss: 962.4685668945312, Neurons: 11, Grad norm: 3.895e+00\n",
      "Epoch 3119, Loss: 962.4385986328125, Neurons: 11, Grad norm: 3.926e+00\n",
      "Epoch 3120, Loss: 962.40869140625, Neurons: 11, Grad norm: 3.901e+00\n",
      "Epoch 3121, Loss: 962.3787841796875, Neurons: 11, Grad norm: 3.918e+00\n",
      "Epoch 3122, Loss: 962.348876953125, Neurons: 11, Grad norm: 3.886e+00\n",
      "Epoch 3123, Loss: 962.319091796875, Neurons: 11, Grad norm: 3.887e+00\n",
      "Epoch 3124, Loss: 962.2892456054688, Neurons: 11, Grad norm: 3.886e+00\n",
      "Epoch 3125, Loss: 962.2594604492188, Neurons: 11, Grad norm: 3.879e+00\n",
      "Epoch 3126, Loss: 962.2296752929688, Neurons: 11, Grad norm: 3.899e+00\n",
      "Epoch 3127, Loss: 962.1998901367188, Neurons: 11, Grad norm: 3.877e+00\n",
      "Epoch 3128, Loss: 962.1701049804688, Neurons: 11, Grad norm: 3.891e+00\n",
      "Epoch 3129, Loss: 962.140380859375, Neurons: 11, Grad norm: 3.867e+00\n",
      "Epoch 3130, Loss: 962.1106567382812, Neurons: 11, Grad norm: 3.870e+00\n",
      "Epoch 3131, Loss: 962.0809936523438, Neurons: 11, Grad norm: 3.864e+00\n",
      "Epoch 3132, Loss: 962.0513916015625, Neurons: 11, Grad norm: 3.859e+00\n",
      "Epoch 3133, Loss: 962.0217895507812, Neurons: 11, Grad norm: 3.868e+00\n",
      "Epoch 3134, Loss: 961.9921875, Neurons: 11, Grad norm: 3.855e+00\n",
      "Epoch 3135, Loss: 961.9624633789062, Neurons: 11, Grad norm: 3.867e+00\n",
      "Epoch 3136, Loss: 961.9329833984375, Neurons: 11, Grad norm: 3.850e+00\n",
      "Epoch 3137, Loss: 961.9033813476562, Neurons: 11, Grad norm: 3.856e+00\n",
      "Epoch 3138, Loss: 961.873779296875, Neurons: 11, Grad norm: 3.845e+00\n",
      "Epoch 3139, Loss: 961.8443603515625, Neurons: 11, Grad norm: 3.845e+00\n",
      "Epoch 3140, Loss: 961.8147583007812, Neurons: 11, Grad norm: 3.843e+00\n",
      "Epoch 3141, Loss: 961.785400390625, Neurons: 11, Grad norm: 3.838e+00\n",
      "Epoch 3142, Loss: 961.755859375, Neurons: 11, Grad norm: 3.844e+00\n",
      "Epoch 3143, Loss: 961.7263793945312, Neurons: 11, Grad norm: 3.833e+00\n",
      "Epoch 3144, Loss: 961.6970825195312, Neurons: 11, Grad norm: 3.841e+00\n",
      "Epoch 3145, Loss: 961.6676025390625, Neurons: 11, Grad norm: 3.828e+00\n",
      "Epoch 3146, Loss: 961.6383056640625, Neurons: 11, Grad norm: 3.834e+00\n",
      "Epoch 3147, Loss: 961.6089477539062, Neurons: 11, Grad norm: 3.823e+00\n",
      "Epoch 3148, Loss: 961.57958984375, Neurons: 11, Grad norm: 3.826e+00\n",
      "Epoch 3149, Loss: 961.55029296875, Neurons: 11, Grad norm: 3.819e+00\n",
      "Epoch 3149, Test loss: 974.4271850585938\n",
      "Epoch 3150, Loss: 961.52099609375, Neurons: 11, Grad norm: 3.819e+00\n",
      "Epoch 3151, Loss: 961.49169921875, Neurons: 11, Grad norm: 3.816e+00\n",
      "Epoch 3152, Loss: 961.4624633789062, Neurons: 11, Grad norm: 3.812e+00\n",
      "Epoch 3153, Loss: 961.4331665039062, Neurons: 11, Grad norm: 3.814e+00\n",
      "Epoch 3154, Loss: 961.4039916992188, Neurons: 11, Grad norm: 3.807e+00\n",
      "Epoch 3155, Loss: 961.3748779296875, Neurons: 11, Grad norm: 3.811e+00\n",
      "Epoch 3156, Loss: 961.345703125, Neurons: 11, Grad norm: 3.803e+00\n",
      "Epoch 3157, Loss: 961.3165893554688, Neurons: 11, Grad norm: 3.807e+00\n",
      "Epoch 3158, Loss: 961.287353515625, Neurons: 11, Grad norm: 3.798e+00\n",
      "Epoch 3159, Loss: 961.2583618164062, Neurons: 11, Grad norm: 3.803e+00\n",
      "Epoch 3160, Loss: 961.2291870117188, Neurons: 11, Grad norm: 3.793e+00\n",
      "Epoch 3161, Loss: 961.2000732421875, Neurons: 11, Grad norm: 3.799e+00\n",
      "Epoch 3162, Loss: 961.1712036132812, Neurons: 11, Grad norm: 3.789e+00\n",
      "Epoch 3163, Loss: 961.14208984375, Neurons: 11, Grad norm: 3.795e+00\n",
      "Epoch 3164, Loss: 961.1130981445312, Neurons: 11, Grad norm: 3.784e+00\n",
      "Epoch 3165, Loss: 961.0840454101562, Neurons: 11, Grad norm: 3.792e+00\n",
      "Epoch 3166, Loss: 961.05517578125, Neurons: 11, Grad norm: 3.780e+00\n",
      "Epoch 3167, Loss: 961.0261840820312, Neurons: 11, Grad norm: 3.789e+00\n",
      "Epoch 3168, Loss: 960.9971923828125, Neurons: 11, Grad norm: 3.776e+00\n",
      "Epoch 3169, Loss: 960.9683837890625, Neurons: 11, Grad norm: 3.790e+00\n",
      "Epoch 3170, Loss: 960.939453125, Neurons: 11, Grad norm: 3.774e+00\n",
      "Epoch 3171, Loss: 960.9105834960938, Neurons: 11, Grad norm: 3.795e+00\n",
      "Epoch 3172, Loss: 960.8817749023438, Neurons: 11, Grad norm: 3.777e+00\n",
      "Epoch 3173, Loss: 960.8529663085938, Neurons: 11, Grad norm: 3.812e+00\n",
      "Epoch 3174, Loss: 960.8241577148438, Neurons: 11, Grad norm: 3.793e+00\n",
      "Epoch 3175, Loss: 960.7953491210938, Neurons: 11, Grad norm: 3.860e+00\n",
      "Epoch 3176, Loss: 960.7666015625, Neurons: 11, Grad norm: 3.851e+00\n",
      "Epoch 3177, Loss: 960.73779296875, Neurons: 11, Grad norm: 3.990e+00\n",
      "Epoch 3178, Loss: 960.7091674804688, Neurons: 11, Grad norm: 4.033e+00\n",
      "Epoch 3179, Loss: 960.6804809570312, Neurons: 11, Grad norm: 4.347e+00\n",
      "Epoch 3180, Loss: 960.6517944335938, Neurons: 11, Grad norm: 4.573e+00\n",
      "Epoch 3181, Loss: 960.6231689453125, Neurons: 11, Grad norm: 5.291e+00\n",
      "Epoch 3182, Loss: 960.594482421875, Neurons: 11, Grad norm: 5.997e+00\n",
      "Epoch 3183, Loss: 960.5659790039062, Neurons: 11, Grad norm: 7.495e+00\n",
      "Epoch 3184, Loss: 960.537353515625, Neurons: 11, Grad norm: 9.081e+00\n",
      "Epoch 3185, Loss: 960.5088500976562, Neurons: 11, Grad norm: 1.162e+01\n",
      "Epoch 3186, Loss: 960.48046875, Neurons: 11, Grad norm: 1.390e+01\n",
      "Epoch 3187, Loss: 960.4520874023438, Neurons: 11, Grad norm: 1.630e+01\n",
      "Epoch 3188, Loss: 960.4237670898438, Neurons: 11, Grad norm: 1.650e+01\n",
      "Epoch 3189, Loss: 960.3953857421875, Neurons: 11, Grad norm: 1.449e+01\n",
      "Epoch 3190, Loss: 960.36669921875, Neurons: 11, Grad norm: 8.957e+00\n",
      "Epoch 3191, Loss: 960.3377685546875, Neurons: 11, Grad norm: 3.889e+00\n",
      "Epoch 3192, Loss: 960.3092041015625, Neurons: 11, Grad norm: 7.113e+00\n",
      "Epoch 3193, Loss: 960.28076171875, Neurons: 11, Grad norm: 1.090e+01\n",
      "Epoch 3194, Loss: 960.252685546875, Neurons: 11, Grad norm: 1.192e+01\n",
      "Epoch 3195, Loss: 960.224365234375, Neurons: 11, Grad norm: 8.807e+00\n",
      "Epoch 3196, Loss: 960.19580078125, Neurons: 11, Grad norm: 4.505e+00\n",
      "Epoch 3197, Loss: 960.1671752929688, Neurons: 11, Grad norm: 5.262e+00\n",
      "Epoch 3198, Loss: 960.1389770507812, Neurons: 11, Grad norm: 8.424e+00\n",
      "Epoch 3199, Loss: 960.1107788085938, Neurons: 11, Grad norm: 9.448e+00\n",
      "Epoch 3199, Test loss: 972.8914184570312\n",
      "Epoch 3200, Loss: 960.0825805664062, Neurons: 11, Grad norm: 6.920e+00\n",
      "Epoch 3201, Loss: 960.05419921875, Neurons: 11, Grad norm: 3.988e+00\n",
      "Epoch 3202, Loss: 960.0257568359375, Neurons: 11, Grad norm: 5.120e+00\n",
      "Epoch 3203, Loss: 959.99755859375, Neurons: 11, Grad norm: 7.202e+00\n",
      "Epoch 3204, Loss: 959.969482421875, Neurons: 11, Grad norm: 7.560e+00\n",
      "Epoch 3205, Loss: 959.9412841796875, Neurons: 11, Grad norm: 5.332e+00\n",
      "Epoch 3206, Loss: 959.9130859375, Neurons: 11, Grad norm: 3.699e+00\n",
      "Epoch 3207, Loss: 959.8848876953125, Neurons: 11, Grad norm: 5.099e+00\n",
      "Epoch 3208, Loss: 959.8567504882812, Neurons: 11, Grad norm: 6.267e+00\n",
      "Epoch 3209, Loss: 959.8287963867188, Neurons: 11, Grad norm: 6.136e+00\n",
      "Epoch 3210, Loss: 959.8005981445312, Neurons: 11, Grad norm: 4.344e+00\n",
      "Epoch 3211, Loss: 959.7724609375, Neurons: 11, Grad norm: 3.709e+00\n",
      "Epoch 3212, Loss: 959.744384765625, Neurons: 11, Grad norm: 4.932e+00\n",
      "Epoch 3213, Loss: 959.7163696289062, Neurons: 11, Grad norm: 5.458e+00\n",
      "Epoch 3214, Loss: 959.6883544921875, Neurons: 11, Grad norm: 5.150e+00\n",
      "Epoch 3215, Loss: 959.660400390625, Neurons: 11, Grad norm: 3.905e+00\n",
      "Epoch 3216, Loss: 959.6323852539062, Neurons: 11, Grad norm: 3.747e+00\n",
      "Epoch 3217, Loss: 959.6043701171875, Neurons: 11, Grad norm: 4.634e+00\n",
      "Epoch 3218, Loss: 959.5765991210938, Neurons: 11, Grad norm: 4.833e+00\n",
      "Epoch 3219, Loss: 959.548583984375, Neurons: 11, Grad norm: 4.555e+00\n",
      "Epoch 3220, Loss: 959.5206909179688, Neurons: 11, Grad norm: 3.749e+00\n",
      "Epoch 3221, Loss: 959.4927978515625, Neurons: 11, Grad norm: 3.725e+00\n",
      "Epoch 3222, Loss: 959.4649658203125, Neurons: 11, Grad norm: 4.326e+00\n",
      "Epoch 3223, Loss: 959.4371948242188, Neurons: 11, Grad norm: 4.388e+00\n",
      "Epoch 3224, Loss: 959.4093627929688, Neurons: 11, Grad norm: 4.232e+00\n",
      "Epoch 3225, Loss: 959.381591796875, Neurons: 11, Grad norm: 3.702e+00\n",
      "Epoch 3226, Loss: 959.353759765625, Neurons: 11, Grad norm: 3.676e+00\n",
      "Epoch 3227, Loss: 959.3259887695312, Neurons: 11, Grad norm: 4.055e+00\n",
      "Epoch 3228, Loss: 959.2981567382812, Neurons: 11, Grad norm: 4.097e+00\n",
      "Epoch 3229, Loss: 959.2705688476562, Neurons: 11, Grad norm: 4.057e+00\n",
      "Epoch 3230, Loss: 959.2427978515625, Neurons: 11, Grad norm: 3.693e+00\n",
      "Epoch 3231, Loss: 959.215087890625, Neurons: 11, Grad norm: 3.637e+00\n",
      "Epoch 3232, Loss: 959.1873779296875, Neurons: 11, Grad norm: 3.847e+00\n",
      "Epoch 3233, Loss: 959.1598510742188, Neurons: 11, Grad norm: 3.892e+00\n",
      "Epoch 3234, Loss: 959.1322021484375, Neurons: 11, Grad norm: 3.949e+00\n",
      "Epoch 3235, Loss: 959.1045532226562, Neurons: 11, Grad norm: 3.699e+00\n",
      "Epoch 3236, Loss: 959.0769653320312, Neurons: 11, Grad norm: 3.631e+00\n",
      "Epoch 3237, Loss: 959.0493774414062, Neurons: 11, Grad norm: 3.700e+00\n",
      "Epoch 3238, Loss: 959.0217895507812, Neurons: 11, Grad norm: 3.743e+00\n",
      "Epoch 3239, Loss: 958.9942626953125, Neurons: 11, Grad norm: 3.851e+00\n",
      "Epoch 3240, Loss: 958.966796875, Neurons: 11, Grad norm: 3.701e+00\n",
      "Epoch 3241, Loss: 958.9392700195312, Neurons: 11, Grad norm: 3.657e+00\n",
      "Epoch 3242, Loss: 958.9118041992188, Neurons: 11, Grad norm: 3.621e+00\n",
      "Epoch 3243, Loss: 958.88427734375, Neurons: 11, Grad norm: 3.640e+00\n",
      "Epoch 3244, Loss: 958.8569946289062, Neurons: 11, Grad norm: 3.746e+00\n",
      "Epoch 3245, Loss: 958.8294677734375, Neurons: 11, Grad norm: 3.680e+00\n",
      "Epoch 3246, Loss: 958.8021850585938, Neurons: 11, Grad norm: 3.687e+00\n",
      "Epoch 3247, Loss: 958.7747802734375, Neurons: 11, Grad norm: 3.603e+00\n",
      "Epoch 3248, Loss: 958.7473754882812, Neurons: 11, Grad norm: 3.598e+00\n",
      "Epoch 3249, Loss: 958.719970703125, Neurons: 11, Grad norm: 3.645e+00\n",
      "Epoch 3249, Test loss: 971.4193725585938\n",
      "Epoch 3250, Loss: 958.6926879882812, Neurons: 11, Grad norm: 3.631e+00\n",
      "Epoch 3251, Loss: 958.6654052734375, Neurons: 11, Grad norm: 3.680e+00\n",
      "Epoch 3252, Loss: 958.63818359375, Neurons: 11, Grad norm: 3.611e+00\n",
      "Epoch 3253, Loss: 958.6107788085938, Neurons: 11, Grad norm: 3.611e+00\n",
      "Epoch 3254, Loss: 958.5835571289062, Neurons: 11, Grad norm: 3.587e+00\n",
      "Epoch 3255, Loss: 958.556396484375, Neurons: 11, Grad norm: 3.585e+00\n",
      "Epoch 3256, Loss: 958.5291748046875, Neurons: 11, Grad norm: 3.626e+00\n",
      "Epoch 3257, Loss: 958.501953125, Neurons: 11, Grad norm: 3.598e+00\n",
      "Epoch 3258, Loss: 958.4747924804688, Neurons: 11, Grad norm: 3.626e+00\n",
      "Epoch 3259, Loss: 958.4475708007812, Neurons: 11, Grad norm: 3.580e+00\n",
      "Epoch 3260, Loss: 958.4203491210938, Neurons: 11, Grad norm: 3.583e+00\n",
      "Epoch 3261, Loss: 958.3933715820312, Neurons: 11, Grad norm: 3.574e+00\n",
      "Epoch 3262, Loss: 958.3661499023438, Neurons: 11, Grad norm: 3.568e+00\n",
      "Epoch 3263, Loss: 958.3391723632812, Neurons: 11, Grad norm: 3.594e+00\n",
      "Epoch 3264, Loss: 958.3121948242188, Neurons: 11, Grad norm: 3.571e+00\n",
      "Epoch 3265, Loss: 958.2850952148438, Neurons: 11, Grad norm: 3.593e+00\n",
      "Epoch 3266, Loss: 958.258056640625, Neurons: 11, Grad norm: 3.562e+00\n",
      "Epoch 3267, Loss: 958.2310791015625, Neurons: 11, Grad norm: 3.569e+00\n",
      "Epoch 3268, Loss: 958.2039794921875, Neurons: 11, Grad norm: 3.556e+00\n",
      "Epoch 3269, Loss: 958.177001953125, Neurons: 11, Grad norm: 3.553e+00\n",
      "Epoch 3270, Loss: 958.1500854492188, Neurons: 11, Grad norm: 3.564e+00\n",
      "Epoch 3271, Loss: 958.1231689453125, Neurons: 11, Grad norm: 3.550e+00\n",
      "Epoch 3272, Loss: 958.09619140625, Neurons: 11, Grad norm: 3.568e+00\n",
      "Epoch 3273, Loss: 958.0693969726562, Neurons: 11, Grad norm: 3.546e+00\n",
      "Epoch 3274, Loss: 958.04248046875, Neurons: 11, Grad norm: 3.558e+00\n",
      "Epoch 3275, Loss: 958.0155639648438, Neurons: 11, Grad norm: 3.540e+00\n",
      "Epoch 3276, Loss: 957.98876953125, Neurons: 11, Grad norm: 3.543e+00\n",
      "Epoch 3277, Loss: 957.9619750976562, Neurons: 11, Grad norm: 3.538e+00\n",
      "Epoch 3278, Loss: 957.9351806640625, Neurons: 11, Grad norm: 3.534e+00\n",
      "Epoch 3279, Loss: 957.9083862304688, Neurons: 11, Grad norm: 3.540e+00\n",
      "Epoch 3280, Loss: 957.881591796875, Neurons: 11, Grad norm: 3.529e+00\n",
      "Epoch 3281, Loss: 957.8547973632812, Neurons: 11, Grad norm: 3.540e+00\n",
      "Epoch 3282, Loss: 957.8280639648438, Neurons: 11, Grad norm: 3.526e+00\n",
      "Epoch 3283, Loss: 957.8013916015625, Neurons: 11, Grad norm: 3.536e+00\n",
      "Epoch 3284, Loss: 957.7745971679688, Neurons: 11, Grad norm: 3.521e+00\n",
      "Epoch 3285, Loss: 957.7479858398438, Neurons: 11, Grad norm: 3.528e+00\n",
      "Epoch 3286, Loss: 957.7212524414062, Neurons: 11, Grad norm: 3.517e+00\n",
      "Epoch 3287, Loss: 957.6947631835938, Neurons: 11, Grad norm: 3.519e+00\n",
      "Epoch 3288, Loss: 957.6680908203125, Neurons: 11, Grad norm: 3.514e+00\n",
      "Epoch 3289, Loss: 957.641357421875, Neurons: 11, Grad norm: 3.512e+00\n",
      "Epoch 3290, Loss: 957.614990234375, Neurons: 11, Grad norm: 3.512e+00\n",
      "Epoch 3291, Loss: 957.58837890625, Neurons: 11, Grad norm: 3.507e+00\n",
      "Epoch 3292, Loss: 957.561767578125, Neurons: 11, Grad norm: 3.511e+00\n",
      "Epoch 3293, Loss: 957.5352783203125, Neurons: 11, Grad norm: 3.502e+00\n",
      "Epoch 3294, Loss: 957.5086669921875, Neurons: 11, Grad norm: 3.508e+00\n",
      "Epoch 3295, Loss: 957.482177734375, Neurons: 11, Grad norm: 3.498e+00\n",
      "Epoch 3296, Loss: 957.4557495117188, Neurons: 11, Grad norm: 3.505e+00\n",
      "Epoch 3297, Loss: 957.4292602539062, Neurons: 11, Grad norm: 3.494e+00\n",
      "Epoch 3298, Loss: 957.4027709960938, Neurons: 11, Grad norm: 3.502e+00\n",
      "Epoch 3299, Loss: 957.3764038085938, Neurons: 11, Grad norm: 3.490e+00\n",
      "Epoch 3299, Test loss: 969.9911499023438\n",
      "Epoch 3300, Loss: 957.349853515625, Neurons: 11, Grad norm: 3.498e+00\n",
      "Epoch 3301, Loss: 957.3235473632812, Neurons: 11, Grad norm: 3.486e+00\n",
      "Epoch 3302, Loss: 957.2971801757812, Neurons: 11, Grad norm: 3.495e+00\n",
      "Epoch 3303, Loss: 957.270751953125, Neurons: 11, Grad norm: 3.482e+00\n",
      "Epoch 3304, Loss: 957.244384765625, Neurons: 11, Grad norm: 3.494e+00\n",
      "Epoch 3305, Loss: 957.2182006835938, Neurons: 11, Grad norm: 3.479e+00\n",
      "Epoch 3306, Loss: 957.19189453125, Neurons: 11, Grad norm: 3.496e+00\n",
      "Epoch 3307, Loss: 957.1655883789062, Neurons: 11, Grad norm: 3.477e+00\n",
      "Epoch 3308, Loss: 957.139404296875, Neurons: 11, Grad norm: 3.503e+00\n",
      "Epoch 3309, Loss: 957.1130981445312, Neurons: 11, Grad norm: 3.481e+00\n",
      "Epoch 3310, Loss: 957.0868530273438, Neurons: 11, Grad norm: 3.523e+00\n",
      "Epoch 3311, Loss: 957.0606689453125, Neurons: 11, Grad norm: 3.500e+00\n",
      "Epoch 3312, Loss: 957.0343627929688, Neurons: 11, Grad norm: 3.576e+00\n",
      "Epoch 3313, Loss: 957.00830078125, Neurons: 11, Grad norm: 3.562e+00\n",
      "Epoch 3314, Loss: 956.9820556640625, Neurons: 11, Grad norm: 3.715e+00\n",
      "Epoch 3315, Loss: 956.9559936523438, Neurons: 11, Grad norm: 3.751e+00\n",
      "Epoch 3316, Loss: 956.9297485351562, Neurons: 11, Grad norm: 4.081e+00\n",
      "Epoch 3317, Loss: 956.9037475585938, Neurons: 11, Grad norm: 4.292e+00\n",
      "Epoch 3318, Loss: 956.8775634765625, Neurons: 11, Grad norm: 5.015e+00\n",
      "Epoch 3319, Loss: 956.8515625, Neurons: 11, Grad norm: 5.682e+00\n",
      "Epoch 3320, Loss: 956.8255615234375, Neurons: 11, Grad norm: 7.156e+00\n",
      "Epoch 3321, Loss: 956.799560546875, Neurons: 11, Grad norm: 8.692e+00\n",
      "Epoch 3322, Loss: 956.773681640625, Neurons: 11, Grad norm: 1.126e+01\n",
      "Epoch 3323, Loss: 956.747802734375, Neurons: 11, Grad norm: 1.378e+01\n",
      "Epoch 3324, Loss: 956.7219848632812, Neurons: 11, Grad norm: 1.687e+01\n",
      "Epoch 3325, Loss: 956.6963500976562, Neurons: 11, Grad norm: 1.840e+01\n",
      "Epoch 3326, Loss: 956.6705932617188, Neurons: 11, Grad norm: 1.819e+01\n",
      "Epoch 3327, Loss: 956.6445922851562, Neurons: 11, Grad norm: 1.389e+01\n",
      "Epoch 3328, Loss: 956.6182861328125, Neurons: 11, Grad norm: 7.468e+00\n",
      "Epoch 3329, Loss: 956.5919799804688, Neurons: 11, Grad norm: 3.952e+00\n",
      "Epoch 3330, Loss: 956.5659790039062, Neurons: 11, Grad norm: 9.270e+00\n",
      "Epoch 3331, Loss: 956.5404052734375, Neurons: 11, Grad norm: 1.307e+01\n",
      "Epoch 3332, Loss: 956.5146484375, Neurons: 11, Grad norm: 1.223e+01\n",
      "Epoch 3333, Loss: 956.4888916015625, Neurons: 11, Grad norm: 8.198e+00\n",
      "Epoch 3334, Loss: 956.4627685546875, Neurons: 11, Grad norm: 3.447e+00\n",
      "Epoch 3335, Loss: 956.4368896484375, Neurons: 11, Grad norm: 6.519e+00\n",
      "Epoch 3336, Loss: 956.4111938476562, Neurons: 11, Grad norm: 1.006e+01\n",
      "Epoch 3337, Loss: 956.3855590820312, Neurons: 11, Grad norm: 9.585e+00\n",
      "Epoch 3338, Loss: 956.3598022460938, Neurons: 11, Grad norm: 6.585e+00\n",
      "Epoch 3339, Loss: 956.333984375, Neurons: 11, Grad norm: 3.410e+00\n",
      "Epoch 3340, Loss: 956.3081665039062, Neurons: 11, Grad norm: 5.800e+00\n",
      "Epoch 3341, Loss: 956.2825927734375, Neurons: 11, Grad norm: 8.278e+00\n",
      "Epoch 3342, Loss: 956.2569580078125, Neurons: 11, Grad norm: 7.483e+00\n",
      "Epoch 3343, Loss: 956.2313842773438, Neurons: 11, Grad norm: 5.045e+00\n",
      "Epoch 3344, Loss: 956.20556640625, Neurons: 11, Grad norm: 3.510e+00\n",
      "Epoch 3345, Loss: 956.1798706054688, Neurons: 11, Grad norm: 5.409e+00\n",
      "Epoch 3346, Loss: 956.1543579101562, Neurons: 11, Grad norm: 6.940e+00\n",
      "Epoch 3347, Loss: 956.12890625, Neurons: 11, Grad norm: 5.901e+00\n",
      "Epoch 3348, Loss: 956.1031494140625, Neurons: 11, Grad norm: 4.118e+00\n",
      "Epoch 3349, Loss: 956.0776977539062, Neurons: 11, Grad norm: 3.647e+00\n",
      "Epoch 3349, Test loss: 968.60888671875\n",
      "Epoch 3350, Loss: 956.0521850585938, Neurons: 11, Grad norm: 4.964e+00\n",
      "Epoch 3351, Loss: 956.0266723632812, Neurons: 11, Grad norm: 5.874e+00\n",
      "Epoch 3352, Loss: 956.0011596679688, Neurons: 11, Grad norm: 4.867e+00\n",
      "Epoch 3353, Loss: 955.9756469726562, Neurons: 11, Grad norm: 3.690e+00\n",
      "Epoch 3354, Loss: 955.9501953125, Neurons: 11, Grad norm: 3.655e+00\n",
      "Epoch 3355, Loss: 955.9248046875, Neurons: 11, Grad norm: 4.500e+00\n",
      "Epoch 3356, Loss: 955.8993530273438, Neurons: 11, Grad norm: 5.068e+00\n",
      "Epoch 3357, Loss: 955.8739624023438, Neurons: 11, Grad norm: 4.261e+00\n",
      "Epoch 3358, Loss: 955.8485717773438, Neurons: 11, Grad norm: 3.542e+00\n",
      "Epoch 3359, Loss: 955.8231811523438, Neurons: 11, Grad norm: 3.571e+00\n",
      "Epoch 3360, Loss: 955.7977905273438, Neurons: 11, Grad norm: 4.076e+00\n",
      "Epoch 3361, Loss: 955.7723999023438, Neurons: 11, Grad norm: 4.504e+00\n",
      "Epoch 3362, Loss: 955.7471923828125, Neurons: 11, Grad norm: 3.941e+00\n",
      "Epoch 3363, Loss: 955.7218627929688, Neurons: 11, Grad norm: 3.503e+00\n",
      "Epoch 3364, Loss: 955.6964721679688, Neurons: 11, Grad norm: 3.454e+00\n",
      "Epoch 3365, Loss: 955.6712036132812, Neurons: 11, Grad norm: 3.745e+00\n",
      "Epoch 3366, Loss: 955.64599609375, Neurons: 11, Grad norm: 4.106e+00\n",
      "Epoch 3367, Loss: 955.6207885742188, Neurons: 11, Grad norm: 3.767e+00\n",
      "Epoch 3368, Loss: 955.5955810546875, Neurons: 11, Grad norm: 3.516e+00\n",
      "Epoch 3369, Loss: 955.5703735351562, Neurons: 11, Grad norm: 3.369e+00\n",
      "Epoch 3370, Loss: 955.545166015625, Neurons: 11, Grad norm: 3.505e+00\n",
      "Epoch 3371, Loss: 955.5199584960938, Neurons: 11, Grad norm: 3.811e+00\n",
      "Epoch 3372, Loss: 955.4947509765625, Neurons: 11, Grad norm: 3.646e+00\n",
      "Epoch 3373, Loss: 955.4696655273438, Neurons: 11, Grad norm: 3.543e+00\n",
      "Epoch 3374, Loss: 955.444580078125, Neurons: 11, Grad norm: 3.339e+00\n",
      "Epoch 3375, Loss: 955.4193725585938, Neurons: 11, Grad norm: 5.743e+00\n",
      "Epoch 3376, Loss: 955.3943481445312, Neurons: 11, Grad norm: 5.053e+00\n",
      "Epoch 3377, Loss: 955.3695678710938, Neurons: 11, Grad norm: 5.010e+00\n",
      "Epoch 3378, Loss: 955.3446655273438, Neurons: 11, Grad norm: 4.974e+00\n",
      "Epoch 3379, Loss: 955.3193969726562, Neurons: 11, Grad norm: 3.346e+00\n",
      "Epoch 3380, Loss: 955.294189453125, Neurons: 11, Grad norm: 3.336e+00\n",
      "Epoch 3381, Loss: 955.2691650390625, Neurons: 11, Grad norm: 3.437e+00\n",
      "Epoch 3382, Loss: 955.2442016601562, Neurons: 11, Grad norm: 3.450e+00\n",
      "Epoch 3383, Loss: 955.2191772460938, Neurons: 11, Grad norm: 3.532e+00\n",
      "Epoch 3384, Loss: 955.1943969726562, Neurons: 11, Grad norm: 3.418e+00\n",
      "Epoch 3385, Loss: 955.1694946289062, Neurons: 11, Grad norm: 3.405e+00\n",
      "Epoch 3386, Loss: 955.1445922851562, Neurons: 11, Grad norm: 3.393e+00\n",
      "Epoch 3387, Loss: 955.1196899414062, Neurons: 11, Grad norm: 3.396e+00\n",
      "Epoch 3388, Loss: 955.0947875976562, Neurons: 11, Grad norm: 3.474e+00\n",
      "Epoch 3389, Loss: 955.0698852539062, Neurons: 11, Grad norm: 3.408e+00\n",
      "Epoch 3390, Loss: 955.0449829101562, Neurons: 11, Grad norm: 3.417e+00\n",
      "Epoch 3391, Loss: 955.0200805664062, Neurons: 11, Grad norm: 3.341e+00\n",
      "Epoch 3392, Loss: 954.9953002929688, Neurons: 11, Grad norm: 3.329e+00\n",
      "Epoch 3393, Loss: 954.9703979492188, Neurons: 11, Grad norm: 3.349e+00\n",
      "Epoch 3394, Loss: 954.945556640625, Neurons: 11, Grad norm: 3.328e+00\n",
      "Epoch 3395, Loss: 954.9208984375, Neurons: 11, Grad norm: 3.372e+00\n",
      "Epoch 3396, Loss: 954.8960571289062, Neurons: 11, Grad norm: 3.313e+00\n",
      "Epoch 3397, Loss: 954.8712768554688, Neurons: 11, Grad norm: 3.324e+00\n",
      "Epoch 3398, Loss: 954.8465576171875, Neurons: 11, Grad norm: 3.292e+00\n",
      "Epoch 3399, Loss: 954.8218994140625, Neurons: 11, Grad norm: 3.291e+00\n",
      "Epoch 3399, Test loss: 967.273681640625\n",
      "Epoch 3400, Loss: 954.7971801757812, Neurons: 11, Grad norm: 3.316e+00\n",
      "Epoch 3401, Loss: 954.7725830078125, Neurons: 11, Grad norm: 3.298e+00\n",
      "Epoch 3402, Loss: 954.7478637695312, Neurons: 11, Grad norm: 3.332e+00\n",
      "Epoch 3403, Loss: 954.7232666015625, Neurons: 11, Grad norm: 3.295e+00\n",
      "Epoch 3404, Loss: 954.6985473632812, Neurons: 11, Grad norm: 3.310e+00\n",
      "Epoch 3405, Loss: 954.674072265625, Neurons: 11, Grad norm: 3.287e+00\n",
      "Epoch 3406, Loss: 954.6494750976562, Neurons: 11, Grad norm: 3.286e+00\n",
      "Epoch 3407, Loss: 954.6248779296875, Neurons: 11, Grad norm: 3.296e+00\n",
      "Epoch 3408, Loss: 954.6002807617188, Neurons: 11, Grad norm: 3.281e+00\n",
      "Epoch 3409, Loss: 954.5758056640625, Neurons: 11, Grad norm: 3.304e+00\n",
      "Epoch 3410, Loss: 954.55126953125, Neurons: 11, Grad norm: 3.276e+00\n",
      "Epoch 3411, Loss: 954.5267944335938, Neurons: 11, Grad norm: 3.292e+00\n",
      "Epoch 3412, Loss: 954.502197265625, Neurons: 11, Grad norm: 3.267e+00\n",
      "Epoch 3413, Loss: 954.477783203125, Neurons: 11, Grad norm: 3.272e+00\n",
      "Epoch 3414, Loss: 954.4532470703125, Neurons: 11, Grad norm: 3.264e+00\n",
      "Epoch 3415, Loss: 954.4288940429688, Neurons: 11, Grad norm: 3.260e+00\n",
      "Epoch 3416, Loss: 954.4043579101562, Neurons: 11, Grad norm: 3.269e+00\n",
      "Epoch 3417, Loss: 954.3800048828125, Neurons: 11, Grad norm: 3.255e+00\n",
      "Epoch 3418, Loss: 954.3555908203125, Neurons: 11, Grad norm: 3.271e+00\n",
      "Epoch 3419, Loss: 954.3311767578125, Neurons: 11, Grad norm: 3.252e+00\n",
      "Epoch 3420, Loss: 954.3067626953125, Neurons: 11, Grad norm: 3.265e+00\n",
      "Epoch 3421, Loss: 954.2825927734375, Neurons: 11, Grad norm: 3.248e+00\n",
      "Epoch 3422, Loss: 954.2581787109375, Neurons: 11, Grad norm: 3.255e+00\n",
      "Epoch 3423, Loss: 954.23388671875, Neurons: 11, Grad norm: 3.246e+00\n",
      "Epoch 3424, Loss: 954.2095947265625, Neurons: 11, Grad norm: 3.246e+00\n",
      "Epoch 3425, Loss: 954.1853637695312, Neurons: 11, Grad norm: 3.245e+00\n",
      "Epoch 3426, Loss: 954.1609497070312, Neurons: 11, Grad norm: 3.240e+00\n",
      "Epoch 3427, Loss: 954.1367797851562, Neurons: 11, Grad norm: 3.245e+00\n",
      "Epoch 3428, Loss: 954.112548828125, Neurons: 11, Grad norm: 3.235e+00\n",
      "Epoch 3429, Loss: 954.08837890625, Neurons: 11, Grad norm: 3.244e+00\n",
      "Epoch 3430, Loss: 954.0640869140625, Neurons: 11, Grad norm: 3.231e+00\n",
      "Epoch 3431, Loss: 954.0398559570312, Neurons: 11, Grad norm: 3.240e+00\n",
      "Epoch 3432, Loss: 954.0157470703125, Neurons: 11, Grad norm: 3.227e+00\n",
      "Epoch 3433, Loss: 953.9915771484375, Neurons: 11, Grad norm: 3.234e+00\n",
      "Epoch 3434, Loss: 953.9673461914062, Neurons: 11, Grad norm: 3.223e+00\n",
      "Epoch 3435, Loss: 953.943359375, Neurons: 11, Grad norm: 3.229e+00\n",
      "Epoch 3436, Loss: 953.919189453125, Neurons: 11, Grad norm: 3.219e+00\n",
      "Epoch 3437, Loss: 953.8952026367188, Neurons: 11, Grad norm: 3.223e+00\n",
      "Epoch 3438, Loss: 953.8709716796875, Neurons: 11, Grad norm: 3.216e+00\n",
      "Epoch 3439, Loss: 953.8469848632812, Neurons: 11, Grad norm: 3.218e+00\n",
      "Epoch 3440, Loss: 953.822998046875, Neurons: 11, Grad norm: 3.213e+00\n",
      "Epoch 3441, Loss: 953.7989501953125, Neurons: 11, Grad norm: 3.214e+00\n",
      "Epoch 3442, Loss: 953.7749633789062, Neurons: 11, Grad norm: 3.210e+00\n",
      "Epoch 3443, Loss: 953.7509765625, Neurons: 11, Grad norm: 3.209e+00\n",
      "Epoch 3444, Loss: 953.7269897460938, Neurons: 11, Grad norm: 3.207e+00\n",
      "Epoch 3445, Loss: 953.7030029296875, Neurons: 11, Grad norm: 3.205e+00\n",
      "Epoch 3446, Loss: 953.678955078125, Neurons: 11, Grad norm: 3.203e+00\n",
      "Epoch 3447, Loss: 953.6551513671875, Neurons: 11, Grad norm: 3.201e+00\n",
      "Epoch 3448, Loss: 953.6311645507812, Neurons: 11, Grad norm: 3.200e+00\n",
      "Epoch 3449, Loss: 953.607177734375, Neurons: 11, Grad norm: 3.197e+00\n",
      "Epoch 3449, Test loss: 965.9805297851562\n",
      "Epoch 3450, Loss: 953.5833740234375, Neurons: 11, Grad norm: 3.197e+00\n",
      "Epoch 3451, Loss: 953.5595703125, Neurons: 11, Grad norm: 3.192e+00\n",
      "Epoch 3452, Loss: 953.5357055664062, Neurons: 11, Grad norm: 3.194e+00\n",
      "Epoch 3453, Loss: 953.5119018554688, Neurons: 11, Grad norm: 3.188e+00\n",
      "Epoch 3454, Loss: 953.4879760742188, Neurons: 11, Grad norm: 3.192e+00\n",
      "Epoch 3455, Loss: 953.4641723632812, Neurons: 11, Grad norm: 3.184e+00\n",
      "Epoch 3456, Loss: 953.4403686523438, Neurons: 11, Grad norm: 3.191e+00\n",
      "Epoch 3457, Loss: 953.4165649414062, Neurons: 11, Grad norm: 3.180e+00\n",
      "Epoch 3458, Loss: 953.3928833007812, Neurons: 11, Grad norm: 3.194e+00\n",
      "Epoch 3459, Loss: 953.3692016601562, Neurons: 11, Grad norm: 3.178e+00\n",
      "Epoch 3460, Loss: 953.3453979492188, Neurons: 11, Grad norm: 3.207e+00\n",
      "Epoch 3461, Loss: 953.3216552734375, Neurons: 11, Grad norm: 3.187e+00\n",
      "Epoch 3462, Loss: 953.2979736328125, Neurons: 11, Grad norm: 3.252e+00\n",
      "Epoch 3463, Loss: 953.2742919921875, Neurons: 11, Grad norm: 3.240e+00\n",
      "Epoch 3464, Loss: 953.2505493164062, Neurons: 11, Grad norm: 3.399e+00\n",
      "Epoch 3465, Loss: 953.2269897460938, Neurons: 11, Grad norm: 3.457e+00\n",
      "Epoch 3466, Loss: 953.203369140625, Neurons: 11, Grad norm: 3.874e+00\n",
      "Epoch 3467, Loss: 953.1797485351562, Neurons: 11, Grad norm: 4.228e+00\n",
      "Epoch 3468, Loss: 953.1560668945312, Neurons: 11, Grad norm: 5.296e+00\n",
      "Epoch 3469, Loss: 953.132568359375, Neurons: 11, Grad norm: 6.487e+00\n",
      "Epoch 3470, Loss: 953.1089477539062, Neurons: 11, Grad norm: 8.879e+00\n",
      "Epoch 3471, Loss: 953.0855712890625, Neurons: 11, Grad norm: 1.172e+01\n",
      "Epoch 3472, Loss: 953.0621948242188, Neurons: 11, Grad norm: 1.615e+01\n",
      "Epoch 3473, Loss: 953.0390014648438, Neurons: 11, Grad norm: 2.076e+01\n",
      "Epoch 3474, Loss: 953.015869140625, Neurons: 11, Grad norm: 2.544e+01\n",
      "Epoch 3475, Loss: 952.9928588867188, Neurons: 11, Grad norm: 2.608e+01\n",
      "Epoch 3476, Loss: 952.969482421875, Neurons: 11, Grad norm: 2.128e+01\n",
      "Epoch 3477, Loss: 952.9453735351562, Neurons: 11, Grad norm: 9.584e+00\n",
      "Epoch 3478, Loss: 952.9212036132812, Neurons: 11, Grad norm: 5.465e+00\n",
      "Epoch 3479, Loss: 952.8975830078125, Neurons: 11, Grad norm: 1.589e+01\n",
      "Epoch 3480, Loss: 952.8746948242188, Neurons: 11, Grad norm: 1.894e+01\n",
      "Epoch 3481, Loss: 952.8515625, Neurons: 11, Grad norm: 1.415e+01\n",
      "Epoch 3482, Loss: 952.8276977539062, Neurons: 11, Grad norm: 3.892e+00\n",
      "Epoch 3483, Loss: 952.8038940429688, Neurons: 11, Grad norm: 9.245e+00\n",
      "Epoch 3484, Loss: 952.7807006835938, Neurons: 11, Grad norm: 1.514e+01\n",
      "Epoch 3485, Loss: 952.7577514648438, Neurons: 11, Grad norm: 1.260e+01\n",
      "Epoch 3486, Loss: 952.7341918945312, Neurons: 11, Grad norm: 5.039e+00\n",
      "Epoch 3487, Loss: 952.7105712890625, Neurons: 11, Grad norm: 6.944e+00\n",
      "Epoch 3488, Loss: 952.6873779296875, Neurons: 11, Grad norm: 1.183e+01\n",
      "Epoch 3489, Loss: 952.6642456054688, Neurons: 11, Grad norm: 1.090e+01\n",
      "Epoch 3490, Loss: 952.6409912109375, Neurons: 11, Grad norm: 4.439e+00\n",
      "Epoch 3491, Loss: 952.6174926757812, Neurons: 11, Grad norm: 5.593e+00\n",
      "Epoch 3492, Loss: 952.5942993164062, Neurons: 11, Grad norm: 1.008e+01\n",
      "Epoch 3493, Loss: 952.5711669921875, Neurons: 11, Grad norm: 8.676e+00\n",
      "Epoch 3494, Loss: 952.5479736328125, Neurons: 11, Grad norm: 4.079e+00\n",
      "Epoch 3495, Loss: 952.524658203125, Neurons: 11, Grad norm: 5.313e+00\n",
      "Epoch 3496, Loss: 952.50146484375, Neurons: 11, Grad norm: 8.197e+00\n",
      "Epoch 3497, Loss: 952.4783935546875, Neurons: 11, Grad norm: 7.426e+00\n",
      "Epoch 3498, Loss: 952.4552612304688, Neurons: 11, Grad norm: 3.475e+00\n",
      "Epoch 3499, Loss: 952.4320678710938, Neurons: 11, Grad norm: 4.643e+00\n",
      "Epoch 3499, Test loss: 964.7315063476562\n",
      "Epoch 3500, Loss: 952.4089965820312, Neurons: 11, Grad norm: 7.258e+00\n",
      "Epoch 3501, Loss: 952.385986328125, Neurons: 11, Grad norm: 5.943e+00\n",
      "Epoch 3502, Loss: 952.36279296875, Neurons: 11, Grad norm: 3.390e+00\n",
      "Epoch 3503, Loss: 952.339599609375, Neurons: 11, Grad norm: 4.498e+00\n",
      "Epoch 3504, Loss: 952.3165893554688, Neurons: 11, Grad norm: 5.955e+00\n",
      "Epoch 3505, Loss: 952.2935791015625, Neurons: 11, Grad norm: 5.368e+00\n",
      "Epoch 3506, Loss: 952.2705688476562, Neurons: 11, Grad norm: 3.186e+00\n",
      "Epoch 3507, Loss: 952.2474975585938, Neurons: 11, Grad norm: 3.905e+00\n",
      "Epoch 3508, Loss: 952.2245483398438, Neurons: 11, Grad norm: 5.419e+00\n",
      "Epoch 3509, Loss: 952.2015991210938, Neurons: 11, Grad norm: 4.524e+00\n",
      "Epoch 3510, Loss: 952.1785888671875, Neurons: 11, Grad norm: 3.244e+00\n",
      "Epoch 3511, Loss: 952.1555786132812, Neurons: 11, Grad norm: 3.767e+00\n",
      "Epoch 3512, Loss: 952.1326904296875, Neurons: 11, Grad norm: 4.520e+00\n",
      "Epoch 3513, Loss: 952.1098022460938, Neurons: 11, Grad norm: 4.360e+00\n",
      "Epoch 3514, Loss: 952.0868530273438, Neurons: 11, Grad norm: 3.156e+00\n",
      "Epoch 3515, Loss: 952.06396484375, Neurons: 11, Grad norm: 3.337e+00\n",
      "Epoch 3516, Loss: 952.0411987304688, Neurons: 11, Grad norm: 4.252e+00\n",
      "Epoch 3517, Loss: 952.0182495117188, Neurons: 11, Grad norm: 3.865e+00\n",
      "Epoch 3518, Loss: 951.995361328125, Neurons: 11, Grad norm: 3.266e+00\n",
      "Epoch 3519, Loss: 951.9725952148438, Neurons: 11, Grad norm: 3.262e+00\n",
      "Epoch 3520, Loss: 951.9497680664062, Neurons: 11, Grad norm: 3.663e+00\n",
      "Epoch 3521, Loss: 951.927001953125, Neurons: 11, Grad norm: 3.852e+00\n",
      "Epoch 3522, Loss: 951.9041748046875, Neurons: 11, Grad norm: 3.194e+00\n",
      "Epoch 3523, Loss: 951.88134765625, Neurons: 11, Grad norm: 3.075e+00\n",
      "Epoch 3524, Loss: 951.8585815429688, Neurons: 11, Grad norm: 3.534e+00\n",
      "Epoch 3525, Loss: 951.8359985351562, Neurons: 11, Grad norm: 3.494e+00\n",
      "Epoch 3526, Loss: 951.8131713867188, Neurons: 11, Grad norm: 3.328e+00\n",
      "Epoch 3527, Loss: 951.7904052734375, Neurons: 11, Grad norm: 3.059e+00\n",
      "Epoch 3528, Loss: 951.7677612304688, Neurons: 11, Grad norm: 3.190e+00\n",
      "Epoch 3529, Loss: 951.7450561523438, Neurons: 11, Grad norm: 3.484e+00\n",
      "Epoch 3530, Loss: 951.7223510742188, Neurons: 11, Grad norm: 3.218e+00\n",
      "Epoch 3531, Loss: 951.6997680664062, Neurons: 11, Grad norm: 3.087e+00\n",
      "Epoch 3532, Loss: 951.6771850585938, Neurons: 11, Grad norm: 3.137e+00\n",
      "Epoch 3533, Loss: 951.6544799804688, Neurons: 11, Grad norm: 3.203e+00\n",
      "Epoch 3534, Loss: 951.6318969726562, Neurons: 11, Grad norm: 3.306e+00\n",
      "Epoch 3535, Loss: 951.609375, Neurons: 11, Grad norm: 3.072e+00\n",
      "Epoch 3536, Loss: 951.5867919921875, Neurons: 11, Grad norm: 3.038e+00\n",
      "Epoch 3537, Loss: 951.5641479492188, Neurons: 11, Grad norm: 3.172e+00\n",
      "Epoch 3538, Loss: 951.5416870117188, Neurons: 11, Grad norm: 3.143e+00\n",
      "Epoch 3539, Loss: 951.5189819335938, Neurons: 11, Grad norm: 3.165e+00\n",
      "Epoch 3540, Loss: 951.49658203125, Neurons: 11, Grad norm: 3.031e+00\n",
      "Epoch 3541, Loss: 951.4739990234375, Neurons: 11, Grad norm: 3.036e+00\n",
      "Epoch 3542, Loss: 951.4515991210938, Neurons: 11, Grad norm: 3.153e+00\n",
      "Epoch 3543, Loss: 951.4290771484375, Neurons: 11, Grad norm: 3.083e+00\n",
      "Epoch 3544, Loss: 951.4065551757812, Neurons: 11, Grad norm: 3.087e+00\n",
      "Epoch 3545, Loss: 951.3841552734375, Neurons: 11, Grad norm: 3.025e+00\n",
      "Epoch 3546, Loss: 951.3617553710938, Neurons: 11, Grad norm: 3.030e+00\n",
      "Epoch 3547, Loss: 951.3392944335938, Neurons: 11, Grad norm: 3.114e+00\n",
      "Epoch 3548, Loss: 951.31689453125, Neurons: 11, Grad norm: 3.044e+00\n",
      "Epoch 3549, Loss: 951.2944946289062, Neurons: 11, Grad norm: 3.049e+00\n",
      "Epoch 3549, Test loss: 963.5170288085938\n",
      "Epoch 3550, Loss: 951.2721557617188, Neurons: 11, Grad norm: 3.021e+00\n",
      "Epoch 3551, Loss: 951.249755859375, Neurons: 11, Grad norm: 3.018e+00\n",
      "Epoch 3552, Loss: 951.2274780273438, Neurons: 11, Grad norm: 3.077e+00\n",
      "Epoch 3553, Loss: 951.2052001953125, Neurons: 11, Grad norm: 3.020e+00\n",
      "Epoch 3554, Loss: 951.1828002929688, Neurons: 11, Grad norm: 3.028e+00\n",
      "Epoch 3555, Loss: 951.160400390625, Neurons: 11, Grad norm: 3.012e+00\n",
      "Epoch 3556, Loss: 951.13818359375, Neurons: 11, Grad norm: 3.005e+00\n",
      "Epoch 3557, Loss: 951.1159057617188, Neurons: 11, Grad norm: 3.048e+00\n",
      "Epoch 3558, Loss: 951.0936889648438, Neurons: 11, Grad norm: 3.005e+00\n",
      "Epoch 3559, Loss: 951.0713500976562, Neurons: 11, Grad norm: 3.016e+00\n",
      "Epoch 3560, Loss: 951.0491943359375, Neurons: 11, Grad norm: 3.001e+00\n",
      "Epoch 3561, Loss: 951.02685546875, Neurons: 11, Grad norm: 2.995e+00\n",
      "Epoch 3562, Loss: 951.0047607421875, Neurons: 11, Grad norm: 3.025e+00\n",
      "Epoch 3563, Loss: 950.9826049804688, Neurons: 11, Grad norm: 2.993e+00\n",
      "Epoch 3564, Loss: 950.9603881835938, Neurons: 11, Grad norm: 3.007e+00\n",
      "Epoch 3565, Loss: 950.9381713867188, Neurons: 11, Grad norm: 2.990e+00\n",
      "Epoch 3566, Loss: 950.9159545898438, Neurons: 11, Grad norm: 2.986e+00\n",
      "Epoch 3567, Loss: 950.8938598632812, Neurons: 11, Grad norm: 3.005e+00\n",
      "Epoch 3568, Loss: 950.8717651367188, Neurons: 11, Grad norm: 2.983e+00\n",
      "Epoch 3569, Loss: 950.8496704101562, Neurons: 11, Grad norm: 2.998e+00\n",
      "Epoch 3570, Loss: 950.8275756835938, Neurons: 11, Grad norm: 2.980e+00\n",
      "Epoch 3571, Loss: 950.8056030273438, Neurons: 11, Grad norm: 2.979e+00\n",
      "Epoch 3572, Loss: 950.7835693359375, Neurons: 11, Grad norm: 2.988e+00\n",
      "Epoch 3573, Loss: 950.7613525390625, Neurons: 11, Grad norm: 2.974e+00\n",
      "Epoch 3574, Loss: 950.7393798828125, Neurons: 11, Grad norm: 2.988e+00\n",
      "Epoch 3575, Loss: 950.7173461914062, Neurons: 11, Grad norm: 2.971e+00\n",
      "Epoch 3576, Loss: 950.6953735351562, Neurons: 11, Grad norm: 2.974e+00\n",
      "Epoch 3577, Loss: 950.6734008789062, Neurons: 11, Grad norm: 2.974e+00\n",
      "Epoch 3578, Loss: 950.6513671875, Neurons: 11, Grad norm: 2.966e+00\n",
      "Epoch 3579, Loss: 950.62939453125, Neurons: 11, Grad norm: 2.977e+00\n",
      "Epoch 3580, Loss: 950.6074829101562, Neurons: 11, Grad norm: 2.962e+00\n",
      "Epoch 3581, Loss: 950.5855712890625, Neurons: 11, Grad norm: 2.969e+00\n",
      "Epoch 3582, Loss: 950.5635986328125, Neurons: 11, Grad norm: 2.961e+00\n",
      "Epoch 3583, Loss: 950.5416870117188, Neurons: 11, Grad norm: 2.959e+00\n",
      "Epoch 3584, Loss: 950.519775390625, Neurons: 11, Grad norm: 2.964e+00\n",
      "Epoch 3585, Loss: 950.4979858398438, Neurons: 11, Grad norm: 2.954e+00\n",
      "Epoch 3586, Loss: 950.4759521484375, Neurons: 11, Grad norm: 2.962e+00\n",
      "Epoch 3587, Loss: 950.4541625976562, Neurons: 11, Grad norm: 2.951e+00\n",
      "Epoch 3588, Loss: 950.432373046875, Neurons: 11, Grad norm: 2.954e+00\n",
      "Epoch 3589, Loss: 950.4104614257812, Neurons: 11, Grad norm: 2.951e+00\n",
      "Epoch 3590, Loss: 950.3887939453125, Neurons: 11, Grad norm: 2.947e+00\n",
      "Epoch 3591, Loss: 950.3670043945312, Neurons: 11, Grad norm: 2.951e+00\n",
      "Epoch 3592, Loss: 950.3451538085938, Neurons: 11, Grad norm: 2.942e+00\n",
      "Epoch 3593, Loss: 950.3233642578125, Neurons: 11, Grad norm: 2.948e+00\n",
      "Epoch 3594, Loss: 950.3015747070312, Neurons: 11, Grad norm: 2.940e+00\n",
      "Epoch 3595, Loss: 950.2798461914062, Neurons: 11, Grad norm: 2.942e+00\n",
      "Epoch 3596, Loss: 950.2581787109375, Neurons: 11, Grad norm: 2.939e+00\n",
      "Epoch 3597, Loss: 950.2364501953125, Neurons: 11, Grad norm: 2.936e+00\n",
      "Epoch 3598, Loss: 950.2147827148438, Neurons: 11, Grad norm: 2.938e+00\n",
      "Epoch 3599, Loss: 950.1930541992188, Neurons: 11, Grad norm: 2.931e+00\n",
      "Epoch 3599, Test loss: 962.3436279296875\n",
      "Epoch 3600, Loss: 950.17138671875, Neurons: 11, Grad norm: 2.935e+00\n",
      "Epoch 3601, Loss: 950.149658203125, Neurons: 11, Grad norm: 2.928e+00\n",
      "Epoch 3602, Loss: 950.1279907226562, Neurons: 11, Grad norm: 2.930e+00\n",
      "Epoch 3603, Loss: 950.1065063476562, Neurons: 11, Grad norm: 2.926e+00\n",
      "Epoch 3604, Loss: 950.0848999023438, Neurons: 11, Grad norm: 2.925e+00\n",
      "Epoch 3605, Loss: 950.0632934570312, Neurons: 11, Grad norm: 2.924e+00\n",
      "Epoch 3606, Loss: 950.0415649414062, Neurons: 11, Grad norm: 2.920e+00\n",
      "Epoch 3607, Loss: 950.0200805664062, Neurons: 11, Grad norm: 2.922e+00\n",
      "Epoch 3608, Loss: 949.9984741210938, Neurons: 11, Grad norm: 2.917e+00\n",
      "Epoch 3609, Loss: 949.9769897460938, Neurons: 11, Grad norm: 2.919e+00\n",
      "Epoch 3610, Loss: 949.9555053710938, Neurons: 11, Grad norm: 2.914e+00\n",
      "Epoch 3611, Loss: 949.9339599609375, Neurons: 11, Grad norm: 2.915e+00\n",
      "Epoch 3612, Loss: 949.912353515625, Neurons: 11, Grad norm: 2.911e+00\n",
      "Epoch 3613, Loss: 949.8909912109375, Neurons: 11, Grad norm: 2.910e+00\n",
      "Epoch 3614, Loss: 949.869384765625, Neurons: 11, Grad norm: 2.909e+00\n",
      "Epoch 3615, Loss: 949.8479614257812, Neurons: 11, Grad norm: 2.906e+00\n",
      "Epoch 3616, Loss: 949.8265991210938, Neurons: 11, Grad norm: 2.906e+00\n",
      "Epoch 3617, Loss: 949.8050537109375, Neurons: 11, Grad norm: 2.902e+00\n",
      "Epoch 3618, Loss: 949.78369140625, Neurons: 11, Grad norm: 2.904e+00\n",
      "Epoch 3619, Loss: 949.7621459960938, Neurons: 11, Grad norm: 2.899e+00\n",
      "Epoch 3620, Loss: 949.7409057617188, Neurons: 11, Grad norm: 2.900e+00\n",
      "Epoch 3621, Loss: 949.7193603515625, Neurons: 11, Grad norm: 2.896e+00\n",
      "Epoch 3622, Loss: 949.6980590820312, Neurons: 11, Grad norm: 2.896e+00\n",
      "Epoch 3623, Loss: 949.6766967773438, Neurons: 11, Grad norm: 2.893e+00\n",
      "Epoch 3624, Loss: 949.6553955078125, Neurons: 11, Grad norm: 2.892e+00\n",
      "Epoch 3625, Loss: 949.6339721679688, Neurons: 11, Grad norm: 2.890e+00\n",
      "Epoch 3626, Loss: 949.61279296875, Neurons: 11, Grad norm: 2.889e+00\n",
      "Epoch 3627, Loss: 949.5914916992188, Neurons: 11, Grad norm: 2.887e+00\n",
      "Epoch 3628, Loss: 949.570068359375, Neurons: 11, Grad norm: 2.885e+00\n",
      "Epoch 3629, Loss: 949.5488891601562, Neurons: 11, Grad norm: 2.884e+00\n",
      "Epoch 3630, Loss: 949.527587890625, Neurons: 11, Grad norm: 2.881e+00\n",
      "Epoch 3631, Loss: 949.50634765625, Neurons: 11, Grad norm: 2.881e+00\n",
      "Epoch 3632, Loss: 949.4850463867188, Neurons: 11, Grad norm: 2.878e+00\n",
      "Epoch 3633, Loss: 949.4638061523438, Neurons: 11, Grad norm: 2.878e+00\n",
      "Epoch 3634, Loss: 949.4426879882812, Neurons: 11, Grad norm: 2.875e+00\n",
      "Epoch 3635, Loss: 949.4214477539062, Neurons: 11, Grad norm: 2.874e+00\n",
      "Epoch 3636, Loss: 949.4002685546875, Neurons: 11, Grad norm: 2.871e+00\n",
      "Epoch 3637, Loss: 949.379150390625, Neurons: 11, Grad norm: 2.871e+00\n",
      "Epoch 3638, Loss: 949.3579711914062, Neurons: 11, Grad norm: 2.868e+00\n",
      "Epoch 3639, Loss: 949.3368530273438, Neurons: 11, Grad norm: 2.868e+00\n",
      "Epoch 3640, Loss: 949.315673828125, Neurons: 11, Grad norm: 2.865e+00\n",
      "Epoch 3641, Loss: 949.2945556640625, Neurons: 11, Grad norm: 2.865e+00\n",
      "Epoch 3642, Loss: 949.2734985351562, Neurons: 11, Grad norm: 2.861e+00\n",
      "Epoch 3643, Loss: 949.2523803710938, Neurons: 11, Grad norm: 2.862e+00\n",
      "Epoch 3644, Loss: 949.2312622070312, Neurons: 11, Grad norm: 2.857e+00\n",
      "Epoch 3645, Loss: 949.210205078125, Neurons: 11, Grad norm: 2.860e+00\n",
      "Epoch 3646, Loss: 949.1891479492188, Neurons: 11, Grad norm: 2.853e+00\n",
      "Epoch 3647, Loss: 949.1681518554688, Neurons: 11, Grad norm: 2.859e+00\n",
      "Epoch 3648, Loss: 949.1471557617188, Neurons: 11, Grad norm: 2.849e+00\n",
      "Epoch 3649, Loss: 949.1261596679688, Neurons: 11, Grad norm: 2.859e+00\n",
      "Epoch 3649, Test loss: 961.2061767578125\n",
      "Epoch 3650, Loss: 949.1051635742188, Neurons: 11, Grad norm: 2.846e+00\n",
      "Epoch 3651, Loss: 949.0841674804688, Neurons: 11, Grad norm: 2.863e+00\n",
      "Epoch 3652, Loss: 949.0631713867188, Neurons: 11, Grad norm: 2.844e+00\n",
      "Epoch 3653, Loss: 949.0421752929688, Neurons: 11, Grad norm: 2.876e+00\n",
      "Epoch 3654, Loss: 949.0213012695312, Neurons: 11, Grad norm: 2.851e+00\n",
      "Epoch 3655, Loss: 949.0003662109375, Neurons: 11, Grad norm: 2.914e+00\n",
      "Epoch 3656, Loss: 948.9793701171875, Neurons: 11, Grad norm: 2.889e+00\n",
      "Epoch 3657, Loss: 948.9585571289062, Neurons: 11, Grad norm: 3.028e+00\n",
      "Epoch 3658, Loss: 948.9375610351562, Neurons: 11, Grad norm: 3.042e+00\n",
      "Epoch 3659, Loss: 948.916748046875, Neurons: 11, Grad norm: 3.372e+00\n",
      "Epoch 3660, Loss: 948.8958740234375, Neurons: 11, Grad norm: 3.566e+00\n",
      "Epoch 3661, Loss: 948.8750610351562, Neurons: 11, Grad norm: 4.357e+00\n",
      "Epoch 3662, Loss: 948.8541870117188, Neurons: 11, Grad norm: 5.103e+00\n",
      "Epoch 3663, Loss: 948.8333740234375, Neurons: 11, Grad norm: 6.844e+00\n",
      "Epoch 3664, Loss: 948.8126831054688, Neurons: 11, Grad norm: 8.793e+00\n",
      "Epoch 3665, Loss: 948.7919921875, Neurons: 11, Grad norm: 1.221e+01\n",
      "Epoch 3666, Loss: 948.7713012695312, Neurons: 11, Grad norm: 1.615e+01\n",
      "Epoch 3667, Loss: 948.7507934570312, Neurons: 11, Grad norm: 2.165e+01\n",
      "Epoch 3668, Loss: 948.73046875, Neurons: 11, Grad norm: 2.653e+01\n",
      "Epoch 3669, Loss: 948.710205078125, Neurons: 11, Grad norm: 2.990e+01\n",
      "Epoch 3670, Loss: 948.6897583007812, Neurons: 11, Grad norm: 2.697e+01\n",
      "Epoch 3671, Loss: 948.6687622070312, Neurons: 11, Grad norm: 1.768e+01\n",
      "Epoch 3672, Loss: 948.6471557617188, Neurons: 11, Grad norm: 3.701e+00\n",
      "Epoch 3673, Loss: 948.6259765625, Neurons: 11, Grad norm: 1.170e+01\n",
      "Epoch 3674, Loss: 948.60546875, Neurons: 11, Grad norm: 2.043e+01\n",
      "Epoch 3675, Loss: 948.5853881835938, Neurons: 11, Grad norm: 1.982e+01\n",
      "Epoch 3676, Loss: 948.564697265625, Neurons: 11, Grad norm: 1.153e+01\n",
      "Epoch 3677, Loss: 948.54345703125, Neurons: 11, Grad norm: 3.473e+00\n",
      "Epoch 3678, Loss: 948.522705078125, Neurons: 11, Grad norm: 1.283e+01\n",
      "Epoch 3679, Loss: 948.5022583007812, Neurons: 11, Grad norm: 1.686e+01\n",
      "Epoch 3680, Loss: 948.4819946289062, Neurons: 11, Grad norm: 1.199e+01\n",
      "Epoch 3681, Loss: 948.4610595703125, Neurons: 11, Grad norm: 3.402e+00\n",
      "Epoch 3682, Loss: 948.4402465820312, Neurons: 11, Grad norm: 8.881e+00\n",
      "Epoch 3683, Loss: 948.4197998046875, Neurons: 11, Grad norm: 1.316e+01\n",
      "Epoch 3684, Loss: 948.3993530273438, Neurons: 11, Grad norm: 1.119e+01\n",
      "Epoch 3685, Loss: 948.3787841796875, Neurons: 11, Grad norm: 3.900e+00\n",
      "Epoch 3686, Loss: 948.358154296875, Neurons: 11, Grad norm: 6.137e+00\n",
      "Epoch 3687, Loss: 948.3375854492188, Neurons: 11, Grad norm: 1.087e+01\n",
      "Epoch 3688, Loss: 948.3172607421875, Neurons: 11, Grad norm: 9.369e+00\n",
      "Epoch 3689, Loss: 948.2967529296875, Neurons: 11, Grad norm: 4.314e+00\n",
      "Epoch 3690, Loss: 948.2761840820312, Neurons: 11, Grad norm: 4.969e+00\n",
      "Epoch 3691, Loss: 948.2555541992188, Neurons: 11, Grad norm: 8.500e+00\n",
      "Epoch 3692, Loss: 948.2352905273438, Neurons: 11, Grad norm: 8.343e+00\n",
      "Epoch 3693, Loss: 948.2149047851562, Neurons: 11, Grad norm: 4.021e+00\n",
      "Epoch 3694, Loss: 948.1943969726562, Neurons: 11, Grad norm: 3.753e+00\n",
      "Epoch 3695, Loss: 948.1739501953125, Neurons: 11, Grad norm: 7.218e+00\n",
      "Epoch 3696, Loss: 948.153564453125, Neurons: 11, Grad norm: 6.873e+00\n",
      "Epoch 3697, Loss: 948.1333618164062, Neurons: 11, Grad norm: 4.216e+00\n",
      "Epoch 3698, Loss: 948.11279296875, Neurons: 11, Grad norm: 3.334e+00\n",
      "Epoch 3699, Loss: 948.0923461914062, Neurons: 11, Grad norm: 5.605e+00\n",
      "Epoch 3699, Test loss: 960.1070556640625\n",
      "Epoch 3700, Loss: 948.0722045898438, Neurons: 11, Grad norm: 6.245e+00\n",
      "Epoch 3701, Loss: 948.0517578125, Neurons: 11, Grad norm: 3.916e+00\n",
      "Epoch 3702, Loss: 948.031494140625, Neurons: 11, Grad norm: 2.838e+00\n",
      "Epoch 3703, Loss: 948.0111694335938, Neurons: 11, Grad norm: 4.838e+00\n",
      "Epoch 3704, Loss: 947.9909057617188, Neurons: 11, Grad norm: 5.157e+00\n",
      "Epoch 3705, Loss: 947.9705810546875, Neurons: 11, Grad norm: 4.122e+00\n",
      "Epoch 3706, Loss: 947.9502563476562, Neurons: 11, Grad norm: 2.767e+00\n",
      "Epoch 3707, Loss: 947.9299926757812, Neurons: 11, Grad norm: 4.204e+00\n",
      "Epoch 3708, Loss: 947.9097900390625, Neurons: 11, Grad norm: 5.647e+00\n",
      "Epoch 3709, Loss: 947.8896484375, Neurons: 11, Grad norm: 4.818e+00\n",
      "Epoch 3710, Loss: 947.869384765625, Neurons: 11, Grad norm: 2.840e+00\n",
      "Epoch 3711, Loss: 947.8491821289062, Neurons: 11, Grad norm: 3.327e+00\n",
      "Epoch 3712, Loss: 947.8289794921875, Neurons: 11, Grad norm: 3.876e+00\n",
      "Epoch 3713, Loss: 947.8087768554688, Neurons: 11, Grad norm: 3.885e+00\n",
      "Epoch 3714, Loss: 947.7886962890625, Neurons: 11, Grad norm: 2.894e+00\n",
      "Epoch 3715, Loss: 947.7683715820312, Neurons: 11, Grad norm: 2.842e+00\n",
      "Epoch 3716, Loss: 947.748291015625, Neurons: 11, Grad norm: 3.598e+00\n",
      "Epoch 3717, Loss: 947.7281494140625, Neurons: 11, Grad norm: 3.490e+00\n",
      "Epoch 3718, Loss: 947.7080688476562, Neurons: 11, Grad norm: 3.169e+00\n",
      "Epoch 3719, Loss: 947.68798828125, Neurons: 11, Grad norm: 2.773e+00\n",
      "Epoch 3720, Loss: 947.6678466796875, Neurons: 11, Grad norm: 3.009e+00\n",
      "Epoch 3721, Loss: 947.6477661132812, Neurons: 11, Grad norm: 3.447e+00\n",
      "Epoch 3722, Loss: 947.6277465820312, Neurons: 11, Grad norm: 3.074e+00\n",
      "Epoch 3723, Loss: 947.607666015625, Neurons: 11, Grad norm: 2.830e+00\n",
      "Epoch 3724, Loss: 947.5875854492188, Neurons: 11, Grad norm: 2.855e+00\n",
      "Epoch 3725, Loss: 947.5675659179688, Neurons: 11, Grad norm: 2.998e+00\n",
      "Epoch 3726, Loss: 947.5475463867188, Neurons: 11, Grad norm: 3.190e+00\n",
      "Epoch 3727, Loss: 947.527587890625, Neurons: 11, Grad norm: 2.830e+00\n",
      "Epoch 3728, Loss: 947.507568359375, Neurons: 11, Grad norm: 2.733e+00\n",
      "Epoch 3729, Loss: 947.487548828125, Neurons: 11, Grad norm: 2.888e+00\n",
      "Epoch 3730, Loss: 947.4675903320312, Neurons: 11, Grad norm: 2.910e+00\n",
      "Epoch 3731, Loss: 947.4475708007812, Neurons: 11, Grad norm: 2.986e+00\n",
      "Epoch 3732, Loss: 947.4277954101562, Neurons: 11, Grad norm: 2.740e+00\n",
      "Epoch 3733, Loss: 947.4077758789062, Neurons: 11, Grad norm: 2.716e+00\n",
      "Epoch 3734, Loss: 947.3878784179688, Neurons: 11, Grad norm: 2.865e+00\n",
      "Epoch 3735, Loss: 947.3678588867188, Neurons: 11, Grad norm: 2.826e+00\n",
      "Epoch 3736, Loss: 947.3479614257812, Neurons: 11, Grad norm: 2.871e+00\n",
      "Epoch 3737, Loss: 947.3281860351562, Neurons: 11, Grad norm: 2.715e+00\n",
      "Epoch 3738, Loss: 947.3082885742188, Neurons: 11, Grad norm: 2.711e+00\n",
      "Epoch 3739, Loss: 947.2883911132812, Neurons: 11, Grad norm: 2.824e+00\n",
      "Epoch 3740, Loss: 947.2685546875, Neurons: 11, Grad norm: 2.770e+00\n",
      "Epoch 3741, Loss: 947.248779296875, Neurons: 11, Grad norm: 2.808e+00\n",
      "Epoch 3742, Loss: 947.22900390625, Neurons: 11, Grad norm: 2.705e+00\n",
      "Epoch 3743, Loss: 947.2091674804688, Neurons: 11, Grad norm: 2.703e+00\n",
      "Epoch 3744, Loss: 947.1893920898438, Neurons: 11, Grad norm: 2.780e+00\n",
      "Epoch 3745, Loss: 947.1695556640625, Neurons: 11, Grad norm: 2.732e+00\n",
      "Epoch 3746, Loss: 947.1497802734375, Neurons: 11, Grad norm: 2.772e+00\n",
      "Epoch 3747, Loss: 947.1300659179688, Neurons: 11, Grad norm: 2.696e+00\n",
      "Epoch 3748, Loss: 947.1102905273438, Neurons: 11, Grad norm: 2.694e+00\n",
      "Epoch 3749, Loss: 947.090576171875, Neurons: 11, Grad norm: 2.743e+00\n",
      "Epoch 3749, Test loss: 959.0348510742188\n",
      "Epoch 3750, Loss: 947.0708618164062, Neurons: 11, Grad norm: 2.707e+00\n",
      "Epoch 3751, Loss: 947.0510864257812, Neurons: 11, Grad norm: 2.747e+00\n",
      "Epoch 3752, Loss: 947.0313720703125, Neurons: 11, Grad norm: 2.688e+00\n",
      "Epoch 3753, Loss: 947.0117797851562, Neurons: 11, Grad norm: 2.689e+00\n",
      "Epoch 3754, Loss: 946.9920043945312, Neurons: 11, Grad norm: 2.712e+00\n",
      "Epoch 3755, Loss: 946.9723510742188, Neurons: 11, Grad norm: 2.689e+00\n",
      "Epoch 3756, Loss: 946.9526977539062, Neurons: 11, Grad norm: 2.729e+00\n",
      "Epoch 3757, Loss: 946.93310546875, Neurons: 11, Grad norm: 2.681e+00\n",
      "Epoch 3758, Loss: 946.9134521484375, Neurons: 11, Grad norm: 2.689e+00\n",
      "Epoch 3759, Loss: 946.893798828125, Neurons: 11, Grad norm: 2.689e+00\n",
      "Epoch 3760, Loss: 946.874267578125, Neurons: 11, Grad norm: 2.676e+00\n",
      "Epoch 3761, Loss: 946.8546752929688, Neurons: 11, Grad norm: 2.708e+00\n",
      "Epoch 3762, Loss: 946.8350830078125, Neurons: 11, Grad norm: 2.673e+00\n",
      "Epoch 3763, Loss: 946.8155517578125, Neurons: 11, Grad norm: 2.688e+00\n",
      "Epoch 3764, Loss: 946.7959594726562, Neurons: 11, Grad norm: 2.673e+00\n",
      "Epoch 3765, Loss: 946.7763671875, Neurons: 11, Grad norm: 2.668e+00\n",
      "Epoch 3766, Loss: 946.7568969726562, Neurons: 11, Grad norm: 2.687e+00\n",
      "Epoch 3767, Loss: 946.7373657226562, Neurons: 11, Grad norm: 2.665e+00\n",
      "Epoch 3768, Loss: 946.7177734375, Neurons: 11, Grad norm: 2.684e+00\n",
      "Epoch 3769, Loss: 946.6983642578125, Neurons: 11, Grad norm: 2.662e+00\n",
      "Epoch 3770, Loss: 946.6788940429688, Neurons: 11, Grad norm: 2.666e+00\n",
      "Epoch 3771, Loss: 946.6593627929688, Neurons: 11, Grad norm: 2.668e+00\n",
      "Epoch 3772, Loss: 946.6399536132812, Neurons: 11, Grad norm: 2.657e+00\n",
      "Epoch 3773, Loss: 946.62060546875, Neurons: 11, Grad norm: 2.673e+00\n",
      "Epoch 3774, Loss: 946.60107421875, Neurons: 11, Grad norm: 2.654e+00\n",
      "Epoch 3775, Loss: 946.5816040039062, Neurons: 11, Grad norm: 2.664e+00\n",
      "Epoch 3776, Loss: 946.5621948242188, Neurons: 11, Grad norm: 2.654e+00\n",
      "Epoch 3777, Loss: 946.5427856445312, Neurons: 11, Grad norm: 2.653e+00\n",
      "Epoch 3778, Loss: 946.5233764648438, Neurons: 11, Grad norm: 2.659e+00\n",
      "Epoch 3779, Loss: 946.5040893554688, Neurons: 11, Grad norm: 2.647e+00\n",
      "Epoch 3780, Loss: 946.4848022460938, Neurons: 11, Grad norm: 2.659e+00\n",
      "Epoch 3781, Loss: 946.4653930664062, Neurons: 11, Grad norm: 2.644e+00\n",
      "Epoch 3782, Loss: 946.4459838867188, Neurons: 11, Grad norm: 2.651e+00\n",
      "Epoch 3783, Loss: 946.4266967773438, Neurons: 11, Grad norm: 2.644e+00\n",
      "Epoch 3784, Loss: 946.4073486328125, Neurons: 11, Grad norm: 2.643e+00\n",
      "Epoch 3785, Loss: 946.3880004882812, Neurons: 11, Grad norm: 2.646e+00\n",
      "Epoch 3786, Loss: 946.3687744140625, Neurons: 11, Grad norm: 2.638e+00\n",
      "Epoch 3787, Loss: 946.3494873046875, Neurons: 11, Grad norm: 2.645e+00\n",
      "Epoch 3788, Loss: 946.3302001953125, Neurons: 11, Grad norm: 2.635e+00\n",
      "Epoch 3789, Loss: 946.3109741210938, Neurons: 11, Grad norm: 2.640e+00\n",
      "Epoch 3790, Loss: 946.2916870117188, Neurons: 11, Grad norm: 2.634e+00\n",
      "Epoch 3791, Loss: 946.2723999023438, Neurons: 11, Grad norm: 2.634e+00\n",
      "Epoch 3792, Loss: 946.2532958984375, Neurons: 11, Grad norm: 2.633e+00\n",
      "Epoch 3793, Loss: 946.2340698242188, Neurons: 11, Grad norm: 2.628e+00\n",
      "Epoch 3794, Loss: 946.2149047851562, Neurons: 11, Grad norm: 2.633e+00\n",
      "Epoch 3795, Loss: 946.195556640625, Neurons: 11, Grad norm: 2.625e+00\n",
      "Epoch 3796, Loss: 946.1764526367188, Neurons: 11, Grad norm: 2.630e+00\n",
      "Epoch 3797, Loss: 946.1573486328125, Neurons: 11, Grad norm: 2.622e+00\n",
      "Epoch 3798, Loss: 946.13818359375, Neurons: 11, Grad norm: 2.625e+00\n",
      "Epoch 3799, Loss: 946.1189575195312, Neurons: 11, Grad norm: 2.621e+00\n",
      "Epoch 3799, Test loss: 957.9984130859375\n",
      "Epoch 3800, Loss: 946.099853515625, Neurons: 11, Grad norm: 2.620e+00\n",
      "Epoch 3801, Loss: 946.0807495117188, Neurons: 11, Grad norm: 2.619e+00\n",
      "Epoch 3802, Loss: 946.061767578125, Neurons: 11, Grad norm: 2.616e+00\n",
      "Epoch 3803, Loss: 946.0426635742188, Neurons: 11, Grad norm: 2.618e+00\n",
      "Epoch 3804, Loss: 946.0235595703125, Neurons: 11, Grad norm: 2.613e+00\n",
      "Epoch 3805, Loss: 946.00439453125, Neurons: 11, Grad norm: 2.615e+00\n",
      "Epoch 3806, Loss: 945.9853515625, Neurons: 11, Grad norm: 2.610e+00\n",
      "Epoch 3807, Loss: 945.9663696289062, Neurons: 11, Grad norm: 2.611e+00\n",
      "Epoch 3808, Loss: 945.947265625, Neurons: 11, Grad norm: 2.608e+00\n",
      "Epoch 3809, Loss: 945.9282836914062, Neurons: 11, Grad norm: 2.608e+00\n",
      "Epoch 3810, Loss: 945.9093017578125, Neurons: 11, Grad norm: 2.606e+00\n",
      "Epoch 3811, Loss: 945.8902587890625, Neurons: 11, Grad norm: 2.604e+00\n",
      "Epoch 3812, Loss: 945.8712768554688, Neurons: 11, Grad norm: 2.603e+00\n",
      "Epoch 3813, Loss: 945.852294921875, Neurons: 11, Grad norm: 2.601e+00\n",
      "Epoch 3814, Loss: 945.833251953125, Neurons: 11, Grad norm: 2.601e+00\n",
      "Epoch 3815, Loss: 945.8143920898438, Neurons: 11, Grad norm: 2.597e+00\n",
      "Epoch 3816, Loss: 945.7953491210938, Neurons: 11, Grad norm: 2.598e+00\n",
      "Epoch 3817, Loss: 945.7765502929688, Neurons: 11, Grad norm: 2.594e+00\n",
      "Epoch 3818, Loss: 945.757568359375, Neurons: 11, Grad norm: 2.595e+00\n",
      "Epoch 3819, Loss: 945.7386474609375, Neurons: 11, Grad norm: 2.592e+00\n",
      "Epoch 3820, Loss: 945.7197875976562, Neurons: 11, Grad norm: 2.592e+00\n",
      "Epoch 3821, Loss: 945.7008666992188, Neurons: 11, Grad norm: 2.589e+00\n",
      "Epoch 3822, Loss: 945.6819458007812, Neurons: 11, Grad norm: 2.589e+00\n",
      "Epoch 3823, Loss: 945.6631469726562, Neurons: 11, Grad norm: 2.586e+00\n",
      "Epoch 3824, Loss: 945.644287109375, Neurons: 11, Grad norm: 2.586e+00\n",
      "Epoch 3825, Loss: 945.62548828125, Neurons: 11, Grad norm: 2.583e+00\n",
      "Epoch 3826, Loss: 945.606689453125, Neurons: 11, Grad norm: 2.583e+00\n",
      "Epoch 3827, Loss: 945.5877685546875, Neurons: 11, Grad norm: 2.581e+00\n",
      "Epoch 3828, Loss: 945.5689697265625, Neurons: 11, Grad norm: 2.580e+00\n",
      "Epoch 3829, Loss: 945.5501708984375, Neurons: 11, Grad norm: 2.578e+00\n",
      "Epoch 3830, Loss: 945.5313720703125, Neurons: 11, Grad norm: 2.577e+00\n",
      "Epoch 3831, Loss: 945.5126953125, Neurons: 11, Grad norm: 2.575e+00\n",
      "Epoch 3832, Loss: 945.4939575195312, Neurons: 11, Grad norm: 2.574e+00\n",
      "Epoch 3833, Loss: 945.4751586914062, Neurons: 11, Grad norm: 2.572e+00\n",
      "Epoch 3834, Loss: 945.4563598632812, Neurons: 11, Grad norm: 2.571e+00\n",
      "Epoch 3835, Loss: 945.4376831054688, Neurons: 11, Grad norm: 2.570e+00\n",
      "Epoch 3836, Loss: 945.4190063476562, Neurons: 11, Grad norm: 2.568e+00\n",
      "Epoch 3837, Loss: 945.400390625, Neurons: 11, Grad norm: 2.567e+00\n",
      "Epoch 3838, Loss: 945.381591796875, Neurons: 11, Grad norm: 2.565e+00\n",
      "Epoch 3839, Loss: 945.3628540039062, Neurons: 11, Grad norm: 2.564e+00\n",
      "Epoch 3840, Loss: 945.3442993164062, Neurons: 11, Grad norm: 2.562e+00\n",
      "Epoch 3841, Loss: 945.3255615234375, Neurons: 11, Grad norm: 2.562e+00\n",
      "Epoch 3842, Loss: 945.3069458007812, Neurons: 11, Grad norm: 2.558e+00\n",
      "Epoch 3843, Loss: 945.2882690429688, Neurons: 11, Grad norm: 2.560e+00\n",
      "Epoch 3844, Loss: 945.2696533203125, Neurons: 11, Grad norm: 2.554e+00\n",
      "Epoch 3845, Loss: 945.2510986328125, Neurons: 11, Grad norm: 2.560e+00\n",
      "Epoch 3846, Loss: 945.2324829101562, Neurons: 11, Grad norm: 2.550e+00\n",
      "Epoch 3847, Loss: 945.2138671875, Neurons: 11, Grad norm: 2.561e+00\n",
      "Epoch 3848, Loss: 945.1951904296875, Neurons: 11, Grad norm: 2.547e+00\n",
      "Epoch 3849, Loss: 945.1767578125, Neurons: 11, Grad norm: 2.570e+00\n",
      "Epoch 3849, Test loss: 956.992431640625\n",
      "Epoch 3850, Loss: 945.158203125, Neurons: 11, Grad norm: 2.547e+00\n",
      "Epoch 3851, Loss: 945.1395874023438, Neurons: 11, Grad norm: 2.597e+00\n",
      "Epoch 3852, Loss: 945.12109375, Neurons: 11, Grad norm: 2.569e+00\n",
      "Epoch 3853, Loss: 945.1026000976562, Neurons: 11, Grad norm: 2.687e+00\n",
      "Epoch 3854, Loss: 945.0841064453125, Neurons: 11, Grad norm: 2.684e+00\n",
      "Epoch 3855, Loss: 945.0655517578125, Neurons: 11, Grad norm: 2.987e+00\n",
      "Epoch 3856, Loss: 945.0470581054688, Neurons: 11, Grad norm: 3.152e+00\n",
      "Epoch 3857, Loss: 945.028564453125, Neurons: 11, Grad norm: 3.938e+00\n",
      "Epoch 3858, Loss: 945.0101928710938, Neurons: 11, Grad norm: 4.692e+00\n",
      "Epoch 3859, Loss: 944.9917602539062, Neurons: 11, Grad norm: 6.534e+00\n",
      "Epoch 3860, Loss: 944.9732055664062, Neurons: 11, Grad norm: 8.678e+00\n",
      "Epoch 3861, Loss: 944.9549560546875, Neurons: 11, Grad norm: 1.255e+01\n",
      "Epoch 3862, Loss: 944.9365844726562, Neurons: 11, Grad norm: 1.732e+01\n",
      "Epoch 3863, Loss: 944.91845703125, Neurons: 11, Grad norm: 2.437e+01\n",
      "Epoch 3864, Loss: 944.9005737304688, Neurons: 11, Grad norm: 3.170e+01\n",
      "Epoch 3865, Loss: 944.8829956054688, Neurons: 11, Grad norm: 3.813e+01\n",
      "Epoch 3866, Loss: 944.8653564453125, Neurons: 11, Grad norm: 3.709e+01\n",
      "Epoch 3867, Loss: 944.8469848632812, Neurons: 11, Grad norm: 2.625e+01\n",
      "Epoch 3868, Loss: 944.8272705078125, Neurons: 11, Grad norm: 6.236e+00\n",
      "Epoch 3869, Loss: 944.8078002929688, Neurons: 11, Grad norm: 1.453e+01\n",
      "Epoch 3870, Loss: 944.789794921875, Neurons: 11, Grad norm: 2.711e+01\n",
      "Epoch 3871, Loss: 944.7723999023438, Neurons: 11, Grad norm: 2.548e+01\n",
      "Epoch 3872, Loss: 944.7539672851562, Neurons: 11, Grad norm: 1.205e+01\n",
      "Epoch 3873, Loss: 944.7348022460938, Neurons: 11, Grad norm: 7.651e+00\n",
      "Epoch 3874, Loss: 944.7162475585938, Neurons: 11, Grad norm: 2.011e+01\n",
      "Epoch 3875, Loss: 944.6986694335938, Neurons: 11, Grad norm: 2.113e+01\n",
      "Epoch 3876, Loss: 944.6803588867188, Neurons: 11, Grad norm: 9.584e+00\n",
      "Epoch 3877, Loss: 944.6615600585938, Neurons: 11, Grad norm: 6.631e+00\n",
      "Epoch 3878, Loss: 944.6432495117188, Neurons: 11, Grad norm: 1.721e+01\n",
      "Epoch 3879, Loss: 944.6253662109375, Neurons: 11, Grad norm: 1.611e+01\n",
      "Epoch 3880, Loss: 944.607177734375, Neurons: 11, Grad norm: 6.335e+00\n",
      "Epoch 3881, Loss: 944.5885620117188, Neurons: 11, Grad norm: 7.934e+00\n",
      "Epoch 3882, Loss: 944.5703735351562, Neurons: 11, Grad norm: 1.449e+01\n",
      "Epoch 3883, Loss: 944.552490234375, Neurons: 11, Grad norm: 1.225e+01\n",
      "Epoch 3884, Loss: 944.5341796875, Neurons: 11, Grad norm: 3.067e+00\n",
      "Epoch 3885, Loss: 944.5157470703125, Neurons: 11, Grad norm: 8.384e+00\n",
      "Epoch 3886, Loss: 944.4976806640625, Neurons: 11, Grad norm: 1.257e+01\n",
      "Epoch 3887, Loss: 944.4796752929688, Neurons: 11, Grad norm: 8.144e+00\n",
      "Epoch 3888, Loss: 944.4614868164062, Neurons: 11, Grad norm: 2.590e+00\n",
      "Epoch 3889, Loss: 944.4431762695312, Neurons: 11, Grad norm: 8.868e+00\n",
      "Epoch 3890, Loss: 944.42529296875, Neurons: 11, Grad norm: 9.799e+00\n",
      "Epoch 3891, Loss: 944.4071044921875, Neurons: 11, Grad norm: 5.517e+00\n",
      "Epoch 3892, Loss: 944.3889770507812, Neurons: 11, Grad norm: 3.850e+00\n",
      "Epoch 3893, Loss: 944.3707885742188, Neurons: 11, Grad norm: 7.962e+00\n",
      "Epoch 3894, Loss: 944.3529052734375, Neurons: 11, Grad norm: 7.911e+00\n",
      "Epoch 3895, Loss: 944.3347778320312, Neurons: 11, Grad norm: 3.265e+00\n",
      "Epoch 3896, Loss: 944.316650390625, Neurons: 11, Grad norm: 4.296e+00\n",
      "Epoch 3897, Loss: 944.2987060546875, Neurons: 11, Grad norm: 7.385e+00\n",
      "Epoch 3898, Loss: 944.2807006835938, Neurons: 11, Grad norm: 5.666e+00\n",
      "Epoch 3899, Loss: 944.2626953125, Neurons: 11, Grad norm: 2.613e+00\n",
      "Epoch 3899, Test loss: 956.0159912109375\n",
      "Epoch 3900, Loss: 944.2445678710938, Neurons: 11, Grad norm: 4.829e+00\n",
      "Epoch 3901, Loss: 944.2265625, Neurons: 11, Grad norm: 5.980e+00\n",
      "Epoch 3902, Loss: 944.2086791992188, Neurons: 11, Grad norm: 4.584e+00\n",
      "Epoch 3903, Loss: 944.190673828125, Neurons: 11, Grad norm: 2.532e+00\n",
      "Epoch 3904, Loss: 944.1726684570312, Neurons: 11, Grad norm: 4.361e+00\n",
      "Epoch 3905, Loss: 944.15478515625, Neurons: 11, Grad norm: 5.340e+00\n",
      "Epoch 3906, Loss: 944.1367797851562, Neurons: 11, Grad norm: 3.377e+00\n",
      "Epoch 3907, Loss: 944.118896484375, Neurons: 11, Grad norm: 2.561e+00\n",
      "Epoch 3908, Loss: 944.1009521484375, Neurons: 11, Grad norm: 4.336e+00\n",
      "Epoch 3909, Loss: 944.0829467773438, Neurons: 11, Grad norm: 4.226e+00\n",
      "Epoch 3910, Loss: 944.065185546875, Neurons: 11, Grad norm: 3.098e+00\n",
      "Epoch 3911, Loss: 944.0473022460938, Neurons: 11, Grad norm: 2.755e+00\n",
      "Epoch 3912, Loss: 944.0293579101562, Neurons: 11, Grad norm: 3.665e+00\n",
      "Epoch 3913, Loss: 944.0115966796875, Neurons: 11, Grad norm: 3.934e+00\n",
      "Epoch 3914, Loss: 943.99365234375, Neurons: 11, Grad norm: 2.657e+00\n",
      "Epoch 3915, Loss: 943.9758911132812, Neurons: 11, Grad norm: 2.592e+00\n",
      "Epoch 3916, Loss: 943.9579467773438, Neurons: 11, Grad norm: 3.582e+00\n",
      "Epoch 3917, Loss: 943.940185546875, Neurons: 11, Grad norm: 3.253e+00\n",
      "Epoch 3918, Loss: 943.92236328125, Neurons: 11, Grad norm: 2.685e+00\n",
      "Epoch 3919, Loss: 943.9046020507812, Neurons: 11, Grad norm: 2.668e+00\n",
      "Epoch 3920, Loss: 943.8867797851562, Neurons: 11, Grad norm: 3.043e+00\n",
      "Epoch 3921, Loss: 943.8689575195312, Neurons: 11, Grad norm: 3.215e+00\n",
      "Epoch 3922, Loss: 943.8511962890625, Neurons: 11, Grad norm: 2.515e+00\n",
      "Epoch 3923, Loss: 943.83349609375, Neurons: 11, Grad norm: 2.492e+00\n",
      "Epoch 3924, Loss: 943.815673828125, Neurons: 11, Grad norm: 3.027e+00\n",
      "Epoch 3925, Loss: 943.7979736328125, Neurons: 11, Grad norm: 2.815e+00\n",
      "Epoch 3926, Loss: 943.7801513671875, Neurons: 11, Grad norm: 2.600e+00\n",
      "Epoch 3927, Loss: 943.7625732421875, Neurons: 11, Grad norm: 2.518e+00\n",
      "Epoch 3928, Loss: 943.7447509765625, Neurons: 11, Grad norm: 2.666e+00\n",
      "Epoch 3929, Loss: 943.7271728515625, Neurons: 11, Grad norm: 2.871e+00\n",
      "Epoch 3930, Loss: 943.70947265625, Neurons: 11, Grad norm: 2.491e+00\n",
      "Epoch 3931, Loss: 943.6917724609375, Neurons: 11, Grad norm: 2.434e+00\n",
      "Epoch 3932, Loss: 943.6741943359375, Neurons: 11, Grad norm: 2.682e+00\n",
      "Epoch 3933, Loss: 943.656494140625, Neurons: 11, Grad norm: 2.605e+00\n",
      "Epoch 3934, Loss: 943.6387939453125, Neurons: 11, Grad norm: 2.588e+00\n",
      "Epoch 3935, Loss: 943.6211547851562, Neurons: 11, Grad norm: 2.436e+00\n",
      "Epoch 3936, Loss: 943.6035766601562, Neurons: 11, Grad norm: 2.473e+00\n",
      "Epoch 3937, Loss: 943.5859985351562, Neurons: 11, Grad norm: 2.660e+00\n",
      "Epoch 3938, Loss: 943.5682983398438, Neurons: 11, Grad norm: 2.478e+00\n",
      "Epoch 3939, Loss: 943.55078125, Neurons: 11, Grad norm: 2.447e+00\n",
      "Epoch 3940, Loss: 943.533203125, Neurons: 11, Grad norm: 2.489e+00\n",
      "Epoch 3941, Loss: 943.5155639648438, Neurons: 11, Grad norm: 2.478e+00\n",
      "Epoch 3942, Loss: 943.498046875, Neurons: 11, Grad norm: 2.561e+00\n",
      "Epoch 3943, Loss: 943.4805908203125, Neurons: 11, Grad norm: 2.421e+00\n",
      "Epoch 3944, Loss: 943.4629516601562, Neurons: 11, Grad norm: 2.416e+00\n",
      "Epoch 3945, Loss: 943.4453735351562, Neurons: 11, Grad norm: 2.509e+00\n",
      "Epoch 3946, Loss: 943.427978515625, Neurons: 11, Grad norm: 2.447e+00\n",
      "Epoch 3947, Loss: 943.410400390625, Neurons: 11, Grad norm: 2.479e+00\n",
      "Epoch 3948, Loss: 943.3930053710938, Neurons: 11, Grad norm: 2.415e+00\n",
      "Epoch 3949, Loss: 943.3753662109375, Neurons: 11, Grad norm: 2.412e+00\n",
      "Epoch 3949, Test loss: 955.0689697265625\n",
      "Epoch 3950, Loss: 943.3578491210938, Neurons: 11, Grad norm: 2.492e+00\n",
      "Epoch 3951, Loss: 943.3404541015625, Neurons: 11, Grad norm: 2.419e+00\n",
      "Epoch 3952, Loss: 943.322998046875, Neurons: 11, Grad norm: 2.435e+00\n",
      "Epoch 3953, Loss: 943.3056030273438, Neurons: 11, Grad norm: 2.419e+00\n",
      "Epoch 3954, Loss: 943.2880859375, Neurons: 11, Grad norm: 2.406e+00\n",
      "Epoch 3955, Loss: 943.270751953125, Neurons: 11, Grad norm: 2.464e+00\n",
      "Epoch 3956, Loss: 943.2532958984375, Neurons: 11, Grad norm: 2.403e+00\n",
      "Epoch 3957, Loss: 943.2359008789062, Neurons: 11, Grad norm: 2.413e+00\n",
      "Epoch 3958, Loss: 943.218505859375, Neurons: 11, Grad norm: 2.418e+00\n",
      "Epoch 3959, Loss: 943.201171875, Neurons: 11, Grad norm: 2.398e+00\n",
      "Epoch 3960, Loss: 943.1837768554688, Neurons: 11, Grad norm: 2.439e+00\n",
      "Epoch 3961, Loss: 943.1663818359375, Neurons: 11, Grad norm: 2.394e+00\n",
      "Epoch 3962, Loss: 943.1489868164062, Neurons: 11, Grad norm: 2.401e+00\n",
      "Epoch 3963, Loss: 943.1316528320312, Neurons: 11, Grad norm: 2.411e+00\n",
      "Epoch 3964, Loss: 943.1143798828125, Neurons: 11, Grad norm: 2.390e+00\n",
      "Epoch 3965, Loss: 943.0970458984375, Neurons: 11, Grad norm: 2.421e+00\n",
      "Epoch 3966, Loss: 943.0796508789062, Neurons: 11, Grad norm: 2.388e+00\n",
      "Epoch 3967, Loss: 943.0623779296875, Neurons: 11, Grad norm: 2.393e+00\n",
      "Epoch 3968, Loss: 943.0451049804688, Neurons: 11, Grad norm: 2.402e+00\n",
      "Epoch 3969, Loss: 943.0277709960938, Neurons: 11, Grad norm: 2.383e+00\n",
      "Epoch 3970, Loss: 943.0105590820312, Neurons: 11, Grad norm: 2.407e+00\n",
      "Epoch 3971, Loss: 942.9933471679688, Neurons: 11, Grad norm: 2.382e+00\n",
      "Epoch 3972, Loss: 942.9759521484375, Neurons: 11, Grad norm: 2.386e+00\n",
      "Epoch 3973, Loss: 942.9588012695312, Neurons: 11, Grad norm: 2.393e+00\n",
      "Epoch 3974, Loss: 942.9415893554688, Neurons: 11, Grad norm: 2.377e+00\n",
      "Epoch 3975, Loss: 942.9242553710938, Neurons: 11, Grad norm: 2.396e+00\n",
      "Epoch 3976, Loss: 942.9071044921875, Neurons: 11, Grad norm: 2.376e+00\n",
      "Epoch 3977, Loss: 942.8899536132812, Neurons: 11, Grad norm: 2.381e+00\n",
      "Epoch 3978, Loss: 942.8726806640625, Neurons: 11, Grad norm: 2.382e+00\n",
      "Epoch 3979, Loss: 942.8555908203125, Neurons: 11, Grad norm: 2.372e+00\n",
      "Epoch 3980, Loss: 942.83837890625, Neurons: 11, Grad norm: 2.385e+00\n",
      "Epoch 3981, Loss: 942.8211669921875, Neurons: 11, Grad norm: 2.370e+00\n",
      "Epoch 3982, Loss: 942.803955078125, Neurons: 11, Grad norm: 2.376e+00\n",
      "Epoch 3983, Loss: 942.786865234375, Neurons: 11, Grad norm: 2.373e+00\n",
      "Epoch 3984, Loss: 942.769775390625, Neurons: 11, Grad norm: 2.367e+00\n",
      "Epoch 3985, Loss: 942.752685546875, Neurons: 11, Grad norm: 2.376e+00\n",
      "Epoch 3986, Loss: 942.735595703125, Neurons: 11, Grad norm: 2.364e+00\n",
      "Epoch 3987, Loss: 942.718505859375, Neurons: 11, Grad norm: 2.370e+00\n",
      "Epoch 3988, Loss: 942.7013549804688, Neurons: 11, Grad norm: 2.365e+00\n",
      "Epoch 3989, Loss: 942.6842651367188, Neurons: 11, Grad norm: 2.362e+00\n",
      "Epoch 3990, Loss: 942.6671752929688, Neurons: 11, Grad norm: 2.367e+00\n",
      "Epoch 3991, Loss: 942.6500854492188, Neurons: 11, Grad norm: 2.358e+00\n",
      "Epoch 3992, Loss: 942.633056640625, Neurons: 11, Grad norm: 2.364e+00\n",
      "Epoch 3993, Loss: 942.615966796875, Neurons: 11, Grad norm: 2.357e+00\n",
      "Epoch 3994, Loss: 942.5989990234375, Neurons: 11, Grad norm: 2.357e+00\n",
      "Epoch 3995, Loss: 942.5819702148438, Neurons: 11, Grad norm: 2.358e+00\n",
      "Epoch 3996, Loss: 942.5650024414062, Neurons: 11, Grad norm: 2.352e+00\n",
      "Epoch 3997, Loss: 942.5479736328125, Neurons: 11, Grad norm: 2.357e+00\n",
      "Epoch 3998, Loss: 942.531005859375, Neurons: 11, Grad norm: 2.350e+00\n",
      "Epoch 3999, Loss: 942.5139770507812, Neurons: 11, Grad norm: 2.352e+00\n",
      "Epoch 3999, Test loss: 954.1484375\n",
      "Epoch 4000, Loss: 942.4970703125, Neurons: 11, Grad norm: 2.350e+00\n",
      "Epoch 4001, Loss: 942.4801025390625, Neurons: 11, Grad norm: 2.347e+00\n",
      "Epoch 4002, Loss: 942.4631958007812, Neurons: 11, Grad norm: 3.565e+00\n",
      "Epoch 4003, Loss: 942.4461669921875, Neurons: 11, Grad norm: 2.346e+00\n",
      "Epoch 4004, Loss: 942.4292602539062, Neurons: 11, Grad norm: 2.344e+00\n",
      "Epoch 4005, Loss: 942.412353515625, Neurons: 11, Grad norm: 2.350e+00\n",
      "Epoch 4006, Loss: 942.3954467773438, Neurons: 11, Grad norm: 2.344e+00\n",
      "Epoch 4007, Loss: 942.3786010742188, Neurons: 11, Grad norm: 2.352e+00\n",
      "Epoch 4008, Loss: 942.361572265625, Neurons: 11, Grad norm: 2.346e+00\n",
      "Epoch 4009, Loss: 942.3447875976562, Neurons: 11, Grad norm: 2.349e+00\n",
      "Epoch 4010, Loss: 942.327880859375, Neurons: 11, Grad norm: 2.348e+00\n",
      "Epoch 4011, Loss: 942.3109741210938, Neurons: 11, Grad norm: 2.345e+00\n",
      "Epoch 4012, Loss: 942.294189453125, Neurons: 11, Grad norm: 2.348e+00\n",
      "Epoch 4013, Loss: 942.2774047851562, Neurons: 11, Grad norm: 2.340e+00\n",
      "Epoch 4014, Loss: 942.260498046875, Neurons: 11, Grad norm: 2.344e+00\n",
      "Epoch 4015, Loss: 942.2435913085938, Neurons: 11, Grad norm: 2.337e+00\n",
      "Epoch 4016, Loss: 942.226806640625, Neurons: 11, Grad norm: 2.337e+00\n",
      "Epoch 4017, Loss: 942.2099609375, Neurons: 11, Grad norm: 2.334e+00\n",
      "Epoch 4018, Loss: 942.1931762695312, Neurons: 11, Grad norm: 2.330e+00\n",
      "Epoch 4019, Loss: 942.1763916015625, Neurons: 11, Grad norm: 2.331e+00\n",
      "Epoch 4020, Loss: 942.1595458984375, Neurons: 11, Grad norm: 2.325e+00\n",
      "Epoch 4021, Loss: 942.1428833007812, Neurons: 11, Grad norm: 2.327e+00\n",
      "Epoch 4022, Loss: 942.1261596679688, Neurons: 11, Grad norm: 2.321e+00\n",
      "Epoch 4023, Loss: 942.109375, Neurons: 11, Grad norm: 2.322e+00\n",
      "Epoch 4024, Loss: 942.0925903320312, Neurons: 11, Grad norm: 2.319e+00\n",
      "Epoch 4025, Loss: 942.0759887695312, Neurons: 11, Grad norm: 2.317e+00\n",
      "Epoch 4026, Loss: 942.0592041015625, Neurons: 11, Grad norm: 2.318e+00\n",
      "Epoch 4027, Loss: 942.04248046875, Neurons: 11, Grad norm: 2.314e+00\n",
      "Epoch 4028, Loss: 942.0257568359375, Neurons: 11, Grad norm: 2.316e+00\n",
      "Epoch 4029, Loss: 942.0091552734375, Neurons: 11, Grad norm: 2.312e+00\n",
      "Epoch 4030, Loss: 941.9923706054688, Neurons: 11, Grad norm: 2.313e+00\n",
      "Epoch 4031, Loss: 941.9757690429688, Neurons: 11, Grad norm: 2.310e+00\n",
      "Epoch 4032, Loss: 941.9591674804688, Neurons: 11, Grad norm: 2.310e+00\n",
      "Epoch 4033, Loss: 941.9425048828125, Neurons: 11, Grad norm: 2.308e+00\n",
      "Epoch 4034, Loss: 941.92578125, Neurons: 11, Grad norm: 2.307e+00\n",
      "Epoch 4035, Loss: 941.9091796875, Neurons: 11, Grad norm: 2.307e+00\n",
      "Epoch 4036, Loss: 941.892578125, Neurons: 11, Grad norm: 2.304e+00\n",
      "Epoch 4037, Loss: 941.8759765625, Neurons: 11, Grad norm: 2.304e+00\n",
      "Epoch 4038, Loss: 941.859375, Neurons: 11, Grad norm: 2.302e+00\n",
      "Epoch 4039, Loss: 941.8427734375, Neurons: 11, Grad norm: 2.301e+00\n",
      "Epoch 4040, Loss: 941.826171875, Neurons: 11, Grad norm: 2.300e+00\n",
      "Epoch 4041, Loss: 941.8095703125, Neurons: 11, Grad norm: 2.298e+00\n",
      "Epoch 4042, Loss: 941.79296875, Neurons: 11, Grad norm: 2.297e+00\n",
      "Epoch 4043, Loss: 941.7764892578125, Neurons: 11, Grad norm: 2.295e+00\n",
      "Epoch 4044, Loss: 941.7599487304688, Neurons: 11, Grad norm: 2.295e+00\n",
      "Epoch 4045, Loss: 941.7434692382812, Neurons: 11, Grad norm: 2.292e+00\n",
      "Epoch 4046, Loss: 941.7269897460938, Neurons: 11, Grad norm: 2.292e+00\n",
      "Epoch 4047, Loss: 941.7103881835938, Neurons: 11, Grad norm: 2.290e+00\n",
      "Epoch 4048, Loss: 941.6939697265625, Neurons: 11, Grad norm: 2.290e+00\n",
      "Epoch 4049, Loss: 941.6773681640625, Neurons: 11, Grad norm: 2.287e+00\n",
      "Epoch 4049, Test loss: 953.2542724609375\n",
      "Epoch 4050, Loss: 941.660888671875, Neurons: 11, Grad norm: 2.288e+00\n",
      "Epoch 4051, Loss: 941.6443481445312, Neurons: 11, Grad norm: 2.284e+00\n",
      "Epoch 4052, Loss: 941.6279907226562, Neurons: 11, Grad norm: 2.285e+00\n",
      "Epoch 4053, Loss: 941.6114501953125, Neurons: 11, Grad norm: 2.282e+00\n",
      "Epoch 4054, Loss: 941.5950927734375, Neurons: 11, Grad norm: 2.283e+00\n",
      "Epoch 4055, Loss: 941.5785522460938, Neurons: 11, Grad norm: 2.279e+00\n",
      "Epoch 4056, Loss: 941.5621948242188, Neurons: 11, Grad norm: 2.281e+00\n",
      "Epoch 4057, Loss: 941.5457763671875, Neurons: 11, Grad norm: 2.276e+00\n",
      "Epoch 4058, Loss: 941.5293579101562, Neurons: 11, Grad norm: 2.279e+00\n",
      "Epoch 4059, Loss: 941.5130004882812, Neurons: 11, Grad norm: 2.274e+00\n",
      "Epoch 4060, Loss: 941.49658203125, Neurons: 11, Grad norm: 2.277e+00\n",
      "Epoch 4061, Loss: 941.4801635742188, Neurons: 11, Grad norm: 2.271e+00\n",
      "Epoch 4062, Loss: 941.4638061523438, Neurons: 11, Grad norm: 2.275e+00\n",
      "Epoch 4063, Loss: 941.4473876953125, Neurons: 11, Grad norm: 2.268e+00\n",
      "Epoch 4064, Loss: 941.4310913085938, Neurons: 11, Grad norm: 2.274e+00\n",
      "Epoch 4065, Loss: 941.414794921875, Neurons: 11, Grad norm: 2.264e+00\n",
      "Epoch 4066, Loss: 941.3983764648438, Neurons: 11, Grad norm: 2.274e+00\n",
      "Epoch 4067, Loss: 941.382080078125, Neurons: 11, Grad norm: 2.261e+00\n",
      "Epoch 4068, Loss: 941.3657836914062, Neurons: 11, Grad norm: 2.275e+00\n",
      "Epoch 4069, Loss: 941.349365234375, Neurons: 11, Grad norm: 2.258e+00\n",
      "Epoch 4070, Loss: 941.3331909179688, Neurons: 11, Grad norm: 2.281e+00\n",
      "Epoch 4071, Loss: 941.3167724609375, Neurons: 11, Grad norm: 2.256e+00\n",
      "Epoch 4072, Loss: 941.3005981445312, Neurons: 11, Grad norm: 2.295e+00\n",
      "Epoch 4073, Loss: 941.2843017578125, Neurons: 11, Grad norm: 2.261e+00\n",
      "Epoch 4074, Loss: 941.2680053710938, Neurons: 11, Grad norm: 2.331e+00\n",
      "Epoch 4075, Loss: 941.2517700195312, Neurons: 11, Grad norm: 2.289e+00\n",
      "Epoch 4076, Loss: 941.235595703125, Neurons: 11, Grad norm: 2.427e+00\n",
      "Epoch 4077, Loss: 941.2193603515625, Neurons: 11, Grad norm: 2.400e+00\n",
      "Epoch 4078, Loss: 941.2030639648438, Neurons: 11, Grad norm: 2.694e+00\n",
      "Epoch 4079, Loss: 941.1869506835938, Neurons: 11, Grad norm: 2.772e+00\n",
      "Epoch 4080, Loss: 941.1707763671875, Neurons: 11, Grad norm: 3.406e+00\n",
      "Epoch 4081, Loss: 941.1544799804688, Neurons: 11, Grad norm: 3.834e+00\n",
      "Epoch 4082, Loss: 941.1383666992188, Neurons: 11, Grad norm: 5.133e+00\n",
      "Epoch 4083, Loss: 941.1221923828125, Neurons: 11, Grad norm: 6.370e+00\n",
      "Epoch 4084, Loss: 941.10595703125, Neurons: 11, Grad norm: 8.874e+00\n",
      "Epoch 4085, Loss: 941.0899047851562, Neurons: 11, Grad norm: 1.168e+01\n",
      "Epoch 4086, Loss: 941.0737915039062, Neurons: 11, Grad norm: 1.627e+01\n",
      "Epoch 4087, Loss: 941.057861328125, Neurons: 11, Grad norm: 2.157e+01\n",
      "Epoch 4088, Loss: 941.0420532226562, Neurons: 11, Grad norm: 2.872e+01\n",
      "Epoch 4089, Loss: 941.0264892578125, Neurons: 11, Grad norm: 3.515e+01\n",
      "Epoch 4090, Loss: 941.0110473632812, Neurons: 11, Grad norm: 3.957e+01\n",
      "Epoch 4091, Loss: 940.995361328125, Neurons: 11, Grad norm: 3.625e+01\n",
      "Epoch 4092, Loss: 940.97900390625, Neurons: 11, Grad norm: 2.465e+01\n",
      "Epoch 4093, Loss: 940.9617919921875, Neurons: 11, Grad norm: 5.839e+00\n",
      "Epoch 4094, Loss: 940.9448852539062, Neurons: 11, Grad norm: 1.317e+01\n",
      "Epoch 4095, Loss: 940.928955078125, Neurons: 11, Grad norm: 2.580e+01\n",
      "Epoch 4096, Loss: 940.91357421875, Neurons: 11, Grad norm: 2.700e+01\n",
      "Epoch 4097, Loss: 940.897705078125, Neurons: 11, Grad norm: 1.780e+01\n",
      "Epoch 4098, Loss: 940.881103515625, Neurons: 11, Grad norm: 2.472e+00\n",
      "Epoch 4099, Loss: 940.8645629882812, Neurons: 11, Grad norm: 1.394e+01\n",
      "Epoch 4099, Test loss: 952.3933715820312\n",
      "Epoch 4100, Loss: 940.8487548828125, Neurons: 11, Grad norm: 2.173e+01\n",
      "Epoch 4101, Loss: 940.833251953125, Neurons: 11, Grad norm: 1.821e+01\n",
      "Epoch 4102, Loss: 940.8170776367188, Neurons: 11, Grad norm: 7.294e+00\n",
      "Epoch 4103, Loss: 940.8005981445312, Neurons: 11, Grad norm: 7.476e+00\n",
      "Epoch 4104, Loss: 940.7845458984375, Neurons: 11, Grad norm: 1.584e+01\n",
      "Epoch 4105, Loss: 940.7689819335938, Neurons: 11, Grad norm: 1.652e+01\n",
      "Epoch 4106, Loss: 940.7529907226562, Neurons: 11, Grad norm: 8.460e+00\n",
      "Epoch 4107, Loss: 940.7367553710938, Neurons: 11, Grad norm: 3.517e+00\n",
      "Epoch 4108, Loss: 940.7207641601562, Neurons: 11, Grad norm: 1.198e+01\n",
      "Epoch 4109, Loss: 940.7049560546875, Neurons: 11, Grad norm: 1.357e+01\n",
      "Epoch 4110, Loss: 940.6891479492188, Neurons: 11, Grad norm: 8.912e+00\n",
      "Epoch 4111, Loss: 940.6731567382812, Neurons: 11, Grad norm: 2.313e+00\n",
      "Epoch 4112, Loss: 940.6571044921875, Neurons: 11, Grad norm: 8.398e+00\n",
      "Epoch 4113, Loss: 940.641357421875, Neurons: 11, Grad norm: 1.153e+01\n",
      "Epoch 4114, Loss: 940.62548828125, Neurons: 11, Grad norm: 8.087e+00\n",
      "Epoch 4115, Loss: 940.6095581054688, Neurons: 11, Grad norm: 2.544e+00\n",
      "Epoch 4116, Loss: 940.5935668945312, Neurons: 11, Grad norm: 6.285e+00\n",
      "Epoch 4117, Loss: 940.5777587890625, Neurons: 11, Grad norm: 9.006e+00\n",
      "Epoch 4118, Loss: 940.5619506835938, Neurons: 11, Grad norm: 7.815e+00\n",
      "Epoch 4119, Loss: 940.5460815429688, Neurons: 11, Grad norm: 2.968e+00\n",
      "Epoch 4120, Loss: 940.5301513671875, Neurons: 11, Grad norm: 4.019e+00\n",
      "Epoch 4121, Loss: 940.514404296875, Neurons: 11, Grad norm: 7.462e+00\n",
      "Epoch 4122, Loss: 940.4985961914062, Neurons: 11, Grad norm: 6.715e+00\n",
      "Epoch 4123, Loss: 940.4827880859375, Neurons: 11, Grad norm: 3.824e+00\n",
      "Epoch 4124, Loss: 940.4669799804688, Neurons: 11, Grad norm: 2.939e+00\n",
      "Epoch 4125, Loss: 940.451171875, Neurons: 11, Grad norm: 5.403e+00\n",
      "Epoch 4126, Loss: 940.4353637695312, Neurons: 11, Grad norm: 6.256e+00\n",
      "Epoch 4127, Loss: 940.4195556640625, Neurons: 11, Grad norm: 3.889e+00\n",
      "Epoch 4128, Loss: 940.4037475585938, Neurons: 11, Grad norm: 2.190e+00\n",
      "Epoch 4129, Loss: 940.3880004882812, Neurons: 11, Grad norm: 4.261e+00\n",
      "Epoch 4130, Loss: 940.3722534179688, Neurons: 11, Grad norm: 5.013e+00\n",
      "Epoch 4131, Loss: 940.3565673828125, Neurons: 11, Grad norm: 4.359e+00\n",
      "Epoch 4132, Loss: 940.3408813476562, Neurons: 11, Grad norm: 2.296e+00\n",
      "Epoch 4133, Loss: 940.3251953125, Neurons: 11, Grad norm: 2.799e+00\n",
      "Epoch 4134, Loss: 940.3093872070312, Neurons: 11, Grad norm: 4.381e+00\n",
      "Epoch 4135, Loss: 940.2937622070312, Neurons: 11, Grad norm: 3.923e+00\n",
      "Epoch 4136, Loss: 940.278076171875, Neurons: 11, Grad norm: 2.910e+00\n",
      "Epoch 4137, Loss: 940.2623901367188, Neurons: 11, Grad norm: 2.312e+00\n",
      "Epoch 4138, Loss: 940.24658203125, Neurons: 11, Grad norm: 3.124e+00\n",
      "Epoch 4139, Loss: 940.23095703125, Neurons: 11, Grad norm: 3.859e+00\n",
      "Epoch 4140, Loss: 940.2153930664062, Neurons: 11, Grad norm: 2.963e+00\n",
      "Epoch 4141, Loss: 940.1997680664062, Neurons: 11, Grad norm: 2.281e+00\n",
      "Epoch 4142, Loss: 940.1839599609375, Neurons: 11, Grad norm: 2.596e+00\n",
      "Epoch 4143, Loss: 940.1683959960938, Neurons: 11, Grad norm: 3.015e+00\n",
      "Epoch 4144, Loss: 940.1527709960938, Neurons: 11, Grad norm: 3.263e+00\n",
      "Epoch 4145, Loss: 940.1371459960938, Neurons: 11, Grad norm: 2.423e+00\n",
      "Epoch 4146, Loss: 940.12158203125, Neurons: 11, Grad norm: 2.167e+00\n",
      "Epoch 4147, Loss: 940.10595703125, Neurons: 11, Grad norm: 2.662e+00\n",
      "Epoch 4148, Loss: 940.0903930664062, Neurons: 11, Grad norm: 2.761e+00\n",
      "Epoch 4149, Loss: 940.0748901367188, Neurons: 11, Grad norm: 2.809e+00\n",
      "Epoch 4149, Test loss: 951.539794921875\n",
      "Epoch 4150, Loss: 940.0592651367188, Neurons: 11, Grad norm: 2.222e+00\n",
      "Epoch 4151, Loss: 940.043701171875, Neurons: 11, Grad norm: 2.172e+00\n",
      "Epoch 4152, Loss: 940.0281982421875, Neurons: 11, Grad norm: 2.585e+00\n",
      "Epoch 4153, Loss: 940.0125732421875, Neurons: 11, Grad norm: 2.529e+00\n",
      "Epoch 4154, Loss: 939.9971923828125, Neurons: 11, Grad norm: 2.544e+00\n",
      "Epoch 4155, Loss: 939.9815673828125, Neurons: 11, Grad norm: 2.168e+00\n",
      "Epoch 4156, Loss: 939.966064453125, Neurons: 11, Grad norm: 2.169e+00\n",
      "Epoch 4157, Loss: 939.9505615234375, Neurons: 11, Grad norm: 2.466e+00\n",
      "Epoch 4158, Loss: 939.93505859375, Neurons: 11, Grad norm: 2.369e+00\n",
      "Epoch 4159, Loss: 939.9195556640625, Neurons: 11, Grad norm: 2.400e+00\n",
      "Epoch 4160, Loss: 939.904052734375, Neurons: 11, Grad norm: 2.154e+00\n",
      "Epoch 4161, Loss: 939.8885498046875, Neurons: 11, Grad norm: 2.155e+00\n",
      "Epoch 4162, Loss: 939.8731689453125, Neurons: 11, Grad norm: 2.361e+00\n",
      "Epoch 4163, Loss: 939.8577880859375, Neurons: 11, Grad norm: 2.272e+00\n",
      "Epoch 4164, Loss: 939.84228515625, Neurons: 11, Grad norm: 2.328e+00\n",
      "Epoch 4165, Loss: 939.8267822265625, Neurons: 11, Grad norm: 2.147e+00\n",
      "Epoch 4166, Loss: 939.8114013671875, Neurons: 11, Grad norm: 2.144e+00\n",
      "Epoch 4167, Loss: 939.7959594726562, Neurons: 11, Grad norm: 2.272e+00\n",
      "Epoch 4168, Loss: 939.7805786132812, Neurons: 11, Grad norm: 2.207e+00\n",
      "Epoch 4169, Loss: 939.7651977539062, Neurons: 11, Grad norm: 2.282e+00\n",
      "Epoch 4170, Loss: 939.749755859375, Neurons: 11, Grad norm: 2.144e+00\n",
      "Epoch 4171, Loss: 939.734375, Neurons: 11, Grad norm: 2.142e+00\n",
      "Epoch 4172, Loss: 939.718994140625, Neurons: 11, Grad norm: 2.205e+00\n",
      "Epoch 4173, Loss: 939.7035522460938, Neurons: 11, Grad norm: 2.165e+00\n",
      "Epoch 4174, Loss: 939.6882934570312, Neurons: 11, Grad norm: 2.248e+00\n",
      "Epoch 4175, Loss: 939.6729736328125, Neurons: 11, Grad norm: 2.141e+00\n",
      "Epoch 4176, Loss: 939.6575927734375, Neurons: 11, Grad norm: 2.151e+00\n",
      "Epoch 4177, Loss: 939.6422729492188, Neurons: 11, Grad norm: 2.159e+00\n",
      "Epoch 4178, Loss: 939.626953125, Neurons: 11, Grad norm: 2.137e+00\n",
      "Epoch 4179, Loss: 939.6116943359375, Neurons: 11, Grad norm: 2.210e+00\n",
      "Epoch 4180, Loss: 939.5963745117188, Neurons: 11, Grad norm: 2.135e+00\n",
      "Epoch 4181, Loss: 939.5809936523438, Neurons: 11, Grad norm: 2.161e+00\n",
      "Epoch 4182, Loss: 939.5657958984375, Neurons: 11, Grad norm: 2.132e+00\n",
      "Epoch 4183, Loss: 939.5503540039062, Neurons: 11, Grad norm: 2.125e+00\n",
      "Epoch 4184, Loss: 939.53515625, Neurons: 11, Grad norm: 2.172e+00\n",
      "Epoch 4185, Loss: 939.5199584960938, Neurons: 11, Grad norm: 2.126e+00\n",
      "Epoch 4186, Loss: 939.5045776367188, Neurons: 11, Grad norm: 2.165e+00\n",
      "Epoch 4187, Loss: 939.4893798828125, Neurons: 11, Grad norm: 2.120e+00\n",
      "Epoch 4188, Loss: 939.4741821289062, Neurons: 11, Grad norm: 2.127e+00\n",
      "Epoch 4189, Loss: 939.458984375, Neurons: 11, Grad norm: 2.139e+00\n",
      "Epoch 4190, Loss: 939.4437866210938, Neurons: 11, Grad norm: 2.117e+00\n",
      "Epoch 4191, Loss: 939.428466796875, Neurons: 11, Grad norm: 2.155e+00\n",
      "Epoch 4192, Loss: 939.4133911132812, Neurons: 11, Grad norm: 2.115e+00\n",
      "Epoch 4193, Loss: 939.398193359375, Neurons: 11, Grad norm: 2.135e+00\n",
      "Epoch 4194, Loss: 939.3829956054688, Neurons: 11, Grad norm: 2.117e+00\n",
      "Epoch 4195, Loss: 939.3677978515625, Neurons: 11, Grad norm: 2.114e+00\n",
      "Epoch 4196, Loss: 939.3526000976562, Neurons: 11, Grad norm: 2.132e+00\n",
      "Epoch 4197, Loss: 939.33740234375, Neurons: 11, Grad norm: 2.109e+00\n",
      "Epoch 4198, Loss: 939.3223876953125, Neurons: 11, Grad norm: 2.134e+00\n",
      "Epoch 4199, Loss: 939.3071899414062, Neurons: 11, Grad norm: 2.107e+00\n",
      "Epoch 4199, Test loss: 950.7195434570312\n",
      "Epoch 4200, Loss: 939.2919921875, Neurons: 11, Grad norm: 2.119e+00\n",
      "Epoch 4201, Loss: 939.2767944335938, Neurons: 11, Grad norm: 2.111e+00\n",
      "Epoch 4202, Loss: 939.2616577148438, Neurons: 11, Grad norm: 2.106e+00\n",
      "Epoch 4203, Loss: 939.24658203125, Neurons: 11, Grad norm: 2.120e+00\n",
      "Epoch 4204, Loss: 939.2315063476562, Neurons: 11, Grad norm: 2.102e+00\n",
      "Epoch 4205, Loss: 939.2163696289062, Neurons: 11, Grad norm: 2.120e+00\n",
      "Epoch 4206, Loss: 939.2013549804688, Neurons: 11, Grad norm: 2.100e+00\n",
      "Epoch 4207, Loss: 939.186279296875, Neurons: 11, Grad norm: 2.110e+00\n",
      "Epoch 4208, Loss: 939.1712036132812, Neurons: 11, Grad norm: 2.103e+00\n",
      "Epoch 4209, Loss: 939.1560668945312, Neurons: 11, Grad norm: 2.101e+00\n",
      "Epoch 4210, Loss: 939.1410522460938, Neurons: 11, Grad norm: 2.108e+00\n",
      "Epoch 4211, Loss: 939.1259765625, Neurons: 11, Grad norm: 2.095e+00\n",
      "Epoch 4212, Loss: 939.1109619140625, Neurons: 11, Grad norm: 2.109e+00\n",
      "Epoch 4213, Loss: 939.095947265625, Neurons: 11, Grad norm: 2.093e+00\n",
      "Epoch 4214, Loss: 939.0809936523438, Neurons: 11, Grad norm: 2.103e+00\n",
      "Epoch 4215, Loss: 939.0659790039062, Neurons: 11, Grad norm: 2.093e+00\n",
      "Epoch 4216, Loss: 939.0509643554688, Neurons: 11, Grad norm: 2.095e+00\n",
      "Epoch 4217, Loss: 939.035888671875, Neurons: 11, Grad norm: 2.096e+00\n",
      "Epoch 4218, Loss: 939.02099609375, Neurons: 11, Grad norm: 2.089e+00\n",
      "Epoch 4219, Loss: 939.0059814453125, Neurons: 11, Grad norm: 2.097e+00\n",
      "Epoch 4220, Loss: 938.990966796875, Neurons: 11, Grad norm: 2.086e+00\n",
      "Epoch 4221, Loss: 938.97607421875, Neurons: 11, Grad norm: 2.096e+00\n",
      "Epoch 4222, Loss: 938.961181640625, Neurons: 11, Grad norm: 2.084e+00\n",
      "Epoch 4223, Loss: 938.9461669921875, Neurons: 11, Grad norm: 2.091e+00\n",
      "Epoch 4224, Loss: 938.9312744140625, Neurons: 11, Grad norm: 2.084e+00\n",
      "Epoch 4225, Loss: 938.9163818359375, Neurons: 11, Grad norm: 2.086e+00\n",
      "Epoch 4226, Loss: 938.9013671875, Neurons: 11, Grad norm: 2.084e+00\n",
      "Epoch 4227, Loss: 938.886474609375, Neurons: 11, Grad norm: 2.082e+00\n",
      "Epoch 4228, Loss: 938.87158203125, Neurons: 11, Grad norm: 2.083e+00\n",
      "Epoch 4229, Loss: 938.856689453125, Neurons: 11, Grad norm: 2.376e+00\n",
      "Epoch 4230, Loss: 938.841796875, Neurons: 11, Grad norm: 2.084e+00\n",
      "Epoch 4231, Loss: 938.826904296875, Neurons: 11, Grad norm: 2.074e+00\n",
      "Epoch 4232, Loss: 938.8119506835938, Neurons: 11, Grad norm: 2.085e+00\n",
      "Epoch 4233, Loss: 938.7971801757812, Neurons: 11, Grad norm: 2.072e+00\n",
      "Epoch 4234, Loss: 938.7823486328125, Neurons: 11, Grad norm: 2.083e+00\n",
      "Epoch 4235, Loss: 938.7674560546875, Neurons: 11, Grad norm: 2.071e+00\n",
      "Epoch 4236, Loss: 938.752685546875, Neurons: 11, Grad norm: 2.080e+00\n",
      "Epoch 4237, Loss: 938.73779296875, Neurons: 11, Grad norm: 2.070e+00\n",
      "Epoch 4238, Loss: 938.7229614257812, Neurons: 11, Grad norm: 2.077e+00\n",
      "Epoch 4239, Loss: 938.708251953125, Neurons: 11, Grad norm: 2.069e+00\n",
      "Epoch 4240, Loss: 938.693359375, Neurons: 11, Grad norm: 2.072e+00\n",
      "Epoch 4241, Loss: 938.6785888671875, Neurons: 11, Grad norm: 2.068e+00\n",
      "Epoch 4242, Loss: 938.6637573242188, Neurons: 11, Grad norm: 2.068e+00\n",
      "Epoch 4243, Loss: 938.6490478515625, Neurons: 11, Grad norm: 2.067e+00\n",
      "Epoch 4244, Loss: 938.6341552734375, Neurons: 11, Grad norm: 2.063e+00\n",
      "Epoch 4245, Loss: 938.6194458007812, Neurons: 11, Grad norm: 2.066e+00\n",
      "Epoch 4246, Loss: 938.6047973632812, Neurons: 11, Grad norm: 2.060e+00\n",
      "Epoch 4247, Loss: 938.5899658203125, Neurons: 11, Grad norm: 2.065e+00\n",
      "Epoch 4248, Loss: 938.5752563476562, Neurons: 11, Grad norm: 2.056e+00\n",
      "Epoch 4249, Loss: 938.560546875, Neurons: 11, Grad norm: 2.065e+00\n",
      "Epoch 4249, Test loss: 949.9205932617188\n",
      "Epoch 4250, Loss: 938.5457763671875, Neurons: 11, Grad norm: 2.053e+00\n",
      "Epoch 4251, Loss: 938.5310668945312, Neurons: 11, Grad norm: 2.064e+00\n",
      "Epoch 4252, Loss: 938.516357421875, Neurons: 11, Grad norm: 2.050e+00\n",
      "Epoch 4253, Loss: 938.5016479492188, Neurons: 11, Grad norm: 2.064e+00\n",
      "Epoch 4254, Loss: 938.4869995117188, Neurons: 11, Grad norm: 2.047e+00\n",
      "Epoch 4255, Loss: 938.4723510742188, Neurons: 11, Grad norm: 2.066e+00\n",
      "Epoch 4256, Loss: 938.4577026367188, Neurons: 11, Grad norm: 2.044e+00\n",
      "Epoch 4257, Loss: 938.4429931640625, Neurons: 11, Grad norm: 2.070e+00\n",
      "Epoch 4258, Loss: 938.4282836914062, Neurons: 11, Grad norm: 2.042e+00\n",
      "Epoch 4259, Loss: 938.41357421875, Neurons: 11, Grad norm: 2.079e+00\n",
      "Epoch 4260, Loss: 938.3989868164062, Neurons: 11, Grad norm: 2.042e+00\n",
      "Epoch 4261, Loss: 938.3843994140625, Neurons: 11, Grad norm: 2.097e+00\n",
      "Epoch 4262, Loss: 938.3697509765625, Neurons: 11, Grad norm: 2.051e+00\n",
      "Epoch 4263, Loss: 938.3551635742188, Neurons: 11, Grad norm: 2.139e+00\n",
      "Epoch 4264, Loss: 938.340576171875, Neurons: 11, Grad norm: 2.083e+00\n",
      "Epoch 4265, Loss: 938.3259887695312, Neurons: 11, Grad norm: 2.236e+00\n",
      "Epoch 4266, Loss: 938.3114013671875, Neurons: 11, Grad norm: 2.184e+00\n",
      "Epoch 4267, Loss: 938.2967529296875, Neurons: 11, Grad norm: 2.464e+00\n",
      "Epoch 4268, Loss: 938.2821655273438, Neurons: 11, Grad norm: 2.473e+00\n",
      "Epoch 4269, Loss: 938.267578125, Neurons: 11, Grad norm: 2.997e+00\n",
      "Epoch 4270, Loss: 938.2530517578125, Neurons: 11, Grad norm: 3.214e+00\n",
      "Epoch 4271, Loss: 938.2385864257812, Neurons: 11, Grad norm: 4.174e+00\n",
      "Epoch 4272, Loss: 938.2239990234375, Neurons: 11, Grad norm: 4.877e+00\n",
      "Epoch 4273, Loss: 938.2093505859375, Neurons: 11, Grad norm: 6.593e+00\n",
      "Epoch 4274, Loss: 938.1949462890625, Neurons: 11, Grad norm: 8.238e+00\n",
      "Epoch 4275, Loss: 938.1803588867188, Neurons: 11, Grad norm: 1.126e+01\n",
      "Epoch 4276, Loss: 938.1659545898438, Neurons: 11, Grad norm: 1.455e+01\n",
      "Epoch 4277, Loss: 938.1516723632812, Neurons: 11, Grad norm: 1.964e+01\n",
      "Epoch 4278, Loss: 938.1373901367188, Neurons: 11, Grad norm: 2.519e+01\n",
      "Epoch 4279, Loss: 938.1231689453125, Neurons: 11, Grad norm: 3.217e+01\n",
      "Epoch 4280, Loss: 938.1091918945312, Neurons: 11, Grad norm: 3.763e+01\n",
      "Epoch 4281, Loss: 938.0953979492188, Neurons: 11, Grad norm: 4.040e+01\n",
      "Epoch 4282, Loss: 938.0811767578125, Neurons: 11, Grad norm: 3.550e+01\n",
      "Epoch 4283, Loss: 938.066162109375, Neurons: 11, Grad norm: 2.348e+01\n",
      "Epoch 4284, Loss: 938.05078125, Neurons: 11, Grad norm: 5.524e+00\n",
      "Epoch 4285, Loss: 938.0357055664062, Neurons: 11, Grad norm: 1.226e+01\n",
      "Epoch 4286, Loss: 938.0213623046875, Neurons: 11, Grad norm: 2.477e+01\n",
      "Epoch 4287, Loss: 938.007568359375, Neurons: 11, Grad norm: 2.762e+01\n",
      "Epoch 4288, Loss: 937.9933471679688, Neurons: 11, Grad norm: 2.136e+01\n",
      "Epoch 4289, Loss: 937.9785766601562, Neurons: 11, Grad norm: 7.418e+00\n",
      "Epoch 4290, Loss: 937.9636840820312, Neurons: 11, Grad norm: 7.934e+00\n",
      "Epoch 4291, Loss: 937.9491577148438, Neurons: 11, Grad norm: 1.887e+01\n",
      "Epoch 4292, Loss: 937.935302734375, Neurons: 11, Grad norm: 2.092e+01\n",
      "Epoch 4293, Loss: 937.9209594726562, Neurons: 11, Grad norm: 1.521e+01\n",
      "Epoch 4294, Loss: 937.90625, Neurons: 11, Grad norm: 3.616e+00\n",
      "Epoch 4295, Loss: 937.8916625976562, Neurons: 11, Grad norm: 8.649e+00\n",
      "Epoch 4296, Loss: 937.8773803710938, Neurons: 11, Grad norm: 1.605e+01\n",
      "Epoch 4297, Loss: 937.8634033203125, Neurons: 11, Grad norm: 1.555e+01\n",
      "Epoch 4298, Loss: 937.8489990234375, Neurons: 11, Grad norm: 9.317e+00\n",
      "Epoch 4299, Loss: 937.8343505859375, Neurons: 11, Grad norm: 2.275e+00\n",
      "Epoch 4299, Test loss: 949.1429443359375\n",
      "Epoch 4300, Loss: 937.820068359375, Neurons: 11, Grad norm: 9.404e+00\n",
      "Epoch 4301, Loss: 937.8057861328125, Neurons: 11, Grad norm: 1.340e+01\n",
      "Epoch 4302, Loss: 937.7916870117188, Neurons: 11, Grad norm: 1.080e+01\n",
      "Epoch 4303, Loss: 937.7772827148438, Neurons: 11, Grad norm: 4.831e+00\n",
      "Epoch 4304, Loss: 937.7628784179688, Neurons: 11, Grad norm: 4.260e+00\n",
      "Epoch 4305, Loss: 937.7485961914062, Neurons: 11, Grad norm: 9.072e+00\n",
      "Epoch 4306, Loss: 937.734375, Neurons: 11, Grad norm: 1.056e+01\n",
      "Epoch 4307, Loss: 937.7201538085938, Neurons: 11, Grad norm: 6.998e+00\n",
      "Epoch 4308, Loss: 937.7057495117188, Neurons: 11, Grad norm: 2.335e+00\n",
      "Epoch 4309, Loss: 937.6915893554688, Neurons: 11, Grad norm: 5.255e+00\n",
      "Epoch 4310, Loss: 937.6773681640625, Neurons: 11, Grad norm: 7.949e+00\n",
      "Epoch 4311, Loss: 937.6630859375, Neurons: 11, Grad norm: 7.961e+00\n",
      "Epoch 4312, Loss: 937.6488647460938, Neurons: 11, Grad norm: 4.366e+00\n",
      "Epoch 4313, Loss: 937.6345825195312, Neurons: 11, Grad norm: 2.043e+00\n",
      "Epoch 4314, Loss: 937.620361328125, Neurons: 11, Grad norm: 5.287e+00\n",
      "Epoch 4315, Loss: 937.606201171875, Neurons: 11, Grad norm: 6.540e+00\n",
      "Epoch 4316, Loss: 937.5919799804688, Neurons: 11, Grad norm: 5.938e+00\n",
      "Epoch 4317, Loss: 937.577880859375, Neurons: 11, Grad norm: 2.911e+00\n",
      "Epoch 4318, Loss: 937.5636596679688, Neurons: 11, Grad norm: 2.308e+00\n",
      "Epoch 4319, Loss: 937.5494995117188, Neurons: 11, Grad norm: 4.785e+00\n",
      "Epoch 4320, Loss: 937.5352783203125, Neurons: 11, Grad norm: 5.264e+00\n",
      "Epoch 4321, Loss: 937.5211791992188, Neurons: 11, Grad norm: 4.560e+00\n",
      "Epoch 4322, Loss: 937.5069580078125, Neurons: 11, Grad norm: 2.306e+00\n",
      "Epoch 4323, Loss: 937.4927978515625, Neurons: 11, Grad norm: 2.328e+00\n",
      "Epoch 4324, Loss: 937.4786987304688, Neurons: 11, Grad norm: 4.124e+00\n",
      "Epoch 4325, Loss: 937.464599609375, Neurons: 11, Grad norm: 4.247e+00\n",
      "Epoch 4326, Loss: 937.4505615234375, Neurons: 11, Grad norm: 3.725e+00\n",
      "Epoch 4327, Loss: 937.4364013671875, Neurons: 11, Grad norm: 2.128e+00\n",
      "Epoch 4328, Loss: 937.4223022460938, Neurons: 11, Grad norm: 2.189e+00\n",
      "Epoch 4329, Loss: 937.408203125, Neurons: 11, Grad norm: 3.464e+00\n",
      "Epoch 4330, Loss: 937.3941650390625, Neurons: 11, Grad norm: 3.503e+00\n",
      "Epoch 4331, Loss: 937.3800048828125, Neurons: 11, Grad norm: 3.239e+00\n",
      "Epoch 4332, Loss: 937.365966796875, Neurons: 11, Grad norm: 2.098e+00\n",
      "Epoch 4333, Loss: 937.3518676757812, Neurons: 11, Grad norm: 2.031e+00\n",
      "Epoch 4334, Loss: 937.3377685546875, Neurons: 11, Grad norm: 2.897e+00\n",
      "Epoch 4335, Loss: 937.3237915039062, Neurons: 11, Grad norm: 2.954e+00\n",
      "Epoch 4336, Loss: 937.3097534179688, Neurons: 11, Grad norm: 2.950e+00\n",
      "Epoch 4337, Loss: 937.2957763671875, Neurons: 11, Grad norm: 2.123e+00\n",
      "Epoch 4338, Loss: 937.2816772460938, Neurons: 11, Grad norm: 1.959e+00\n",
      "Epoch 4339, Loss: 937.2677001953125, Neurons: 11, Grad norm: 6.485e+00\n",
      "Epoch 4340, Loss: 937.253662109375, Neurons: 11, Grad norm: 3.556e+00\n",
      "Epoch 4341, Loss: 937.23974609375, Neurons: 11, Grad norm: 3.766e+00\n",
      "Epoch 4342, Loss: 937.2259521484375, Neurons: 11, Grad norm: 3.329e+00\n",
      "Epoch 4343, Loss: 937.2119750976562, Neurons: 11, Grad norm: 3.176e+00\n",
      "Epoch 4344, Loss: 937.197998046875, Neurons: 11, Grad norm: 3.191e+00\n",
      "Epoch 4345, Loss: 937.1837768554688, Neurons: 11, Grad norm: 2.236e+00\n",
      "Epoch 4346, Loss: 937.1697998046875, Neurons: 11, Grad norm: 2.563e+00\n",
      "Epoch 4347, Loss: 937.15576171875, Neurons: 11, Grad norm: 2.221e+00\n",
      "Epoch 4348, Loss: 937.1419067382812, Neurons: 11, Grad norm: 2.134e+00\n",
      "Epoch 4349, Loss: 937.1278686523438, Neurons: 11, Grad norm: 1.989e+00\n",
      "Epoch 4349, Test loss: 948.3870239257812\n",
      "Epoch 4350, Loss: 937.1139526367188, Neurons: 11, Grad norm: 2.041e+00\n",
      "Epoch 4351, Loss: 937.10009765625, Neurons: 11, Grad norm: 2.341e+00\n",
      "Epoch 4352, Loss: 937.086181640625, Neurons: 11, Grad norm: 2.187e+00\n",
      "Epoch 4353, Loss: 937.072265625, Neurons: 11, Grad norm: 2.243e+00\n",
      "Epoch 4354, Loss: 937.058349609375, Neurons: 11, Grad norm: 2.003e+00\n",
      "Epoch 4355, Loss: 937.0443725585938, Neurons: 11, Grad norm: 1.992e+00\n",
      "Epoch 4356, Loss: 937.0305786132812, Neurons: 11, Grad norm: 2.116e+00\n",
      "Epoch 4357, Loss: 937.0166625976562, Neurons: 11, Grad norm: 2.075e+00\n",
      "Epoch 4358, Loss: 937.0027465820312, Neurons: 11, Grad norm: 2.215e+00\n",
      "Epoch 4359, Loss: 936.9889526367188, Neurons: 11, Grad norm: 2.025e+00\n",
      "Epoch 4360, Loss: 936.97509765625, Neurons: 11, Grad norm: 2.032e+00\n",
      "Epoch 4361, Loss: 936.961181640625, Neurons: 11, Grad norm: 1.976e+00\n",
      "Epoch 4362, Loss: 936.9473876953125, Neurons: 11, Grad norm: 1.965e+00\n",
      "Epoch 4363, Loss: 936.9334716796875, Neurons: 11, Grad norm: 2.089e+00\n",
      "Epoch 4364, Loss: 936.919677734375, Neurons: 11, Grad norm: 1.994e+00\n",
      "Epoch 4365, Loss: 936.9058837890625, Neurons: 11, Grad norm: 2.069e+00\n",
      "Epoch 4366, Loss: 936.89208984375, Neurons: 11, Grad norm: 1.944e+00\n",
      "Epoch 4367, Loss: 936.878173828125, Neurons: 11, Grad norm: 1.953e+00\n",
      "Epoch 4368, Loss: 936.864501953125, Neurons: 11, Grad norm: 1.959e+00\n",
      "Epoch 4369, Loss: 936.8506469726562, Neurons: 11, Grad norm: 1.935e+00\n",
      "Epoch 4370, Loss: 936.8368530273438, Neurons: 11, Grad norm: 2.023e+00\n",
      "Epoch 4371, Loss: 936.8230590820312, Neurons: 11, Grad norm: 1.942e+00\n",
      "Epoch 4372, Loss: 936.8092651367188, Neurons: 11, Grad norm: 1.998e+00\n",
      "Epoch 4373, Loss: 936.7955932617188, Neurons: 11, Grad norm: 1.923e+00\n",
      "Epoch 4374, Loss: 936.7817993164062, Neurons: 11, Grad norm: 1.936e+00\n",
      "Epoch 4375, Loss: 936.7680053710938, Neurons: 11, Grad norm: 1.944e+00\n",
      "Epoch 4376, Loss: 936.7542724609375, Neurons: 11, Grad norm: 1.922e+00\n",
      "Epoch 4377, Loss: 936.7406005859375, Neurons: 11, Grad norm: 1.983e+00\n",
      "Epoch 4378, Loss: 936.726806640625, Neurons: 11, Grad norm: 1.926e+00\n",
      "Epoch 4379, Loss: 936.7131958007812, Neurons: 11, Grad norm: 1.976e+00\n",
      "Epoch 4380, Loss: 936.6994018554688, Neurons: 11, Grad norm: 1.919e+00\n",
      "Epoch 4381, Loss: 936.6856689453125, Neurons: 11, Grad norm: 1.940e+00\n",
      "Epoch 4382, Loss: 936.6719970703125, Neurons: 11, Grad norm: 1.925e+00\n",
      "Epoch 4383, Loss: 936.6583862304688, Neurons: 11, Grad norm: 1.918e+00\n",
      "Epoch 4384, Loss: 936.6445922851562, Neurons: 11, Grad norm: 1.946e+00\n",
      "Epoch 4385, Loss: 936.6309814453125, Neurons: 11, Grad norm: 1.914e+00\n",
      "Epoch 4386, Loss: 936.6172485351562, Neurons: 11, Grad norm: 1.954e+00\n",
      "Epoch 4387, Loss: 936.6035766601562, Neurons: 11, Grad norm: 1.911e+00\n",
      "Epoch 4388, Loss: 936.5899658203125, Neurons: 11, Grad norm: 1.940e+00\n",
      "Epoch 4389, Loss: 936.5763549804688, Neurons: 11, Grad norm: 1.910e+00\n",
      "Epoch 4390, Loss: 936.5628051757812, Neurons: 11, Grad norm: 1.920e+00\n",
      "Epoch 4391, Loss: 936.549072265625, Neurons: 11, Grad norm: 1.917e+00\n",
      "Epoch 4392, Loss: 936.535400390625, Neurons: 11, Grad norm: 1.908e+00\n",
      "Epoch 4393, Loss: 936.5217895507812, Neurons: 11, Grad norm: 1.928e+00\n",
      "Epoch 4394, Loss: 936.5081787109375, Neurons: 11, Grad norm: 1.903e+00\n",
      "Epoch 4395, Loss: 936.4945678710938, Neurons: 11, Grad norm: 1.931e+00\n",
      "Epoch 4396, Loss: 936.48095703125, Neurons: 11, Grad norm: 1.901e+00\n",
      "Epoch 4397, Loss: 936.4674682617188, Neurons: 11, Grad norm: 1.925e+00\n",
      "Epoch 4398, Loss: 936.453857421875, Neurons: 11, Grad norm: 1.900e+00\n",
      "Epoch 4399, Loss: 936.4402465820312, Neurons: 11, Grad norm: 1.914e+00\n",
      "Epoch 4399, Test loss: 947.6506958007812\n",
      "Epoch 4400, Loss: 936.4267578125, Neurons: 11, Grad norm: 1.901e+00\n",
      "Epoch 4401, Loss: 936.4131469726562, Neurons: 11, Grad norm: 1.904e+00\n",
      "Epoch 4402, Loss: 936.3995971679688, Neurons: 11, Grad norm: 1.905e+00\n",
      "Epoch 4403, Loss: 936.3860473632812, Neurons: 11, Grad norm: 1.898e+00\n",
      "Epoch 4404, Loss: 936.37255859375, Neurons: 11, Grad norm: 1.908e+00\n",
      "Epoch 4405, Loss: 936.3589477539062, Neurons: 11, Grad norm: 1.894e+00\n",
      "Epoch 4406, Loss: 936.3453979492188, Neurons: 11, Grad norm: 1.910e+00\n",
      "Epoch 4407, Loss: 936.3319702148438, Neurons: 11, Grad norm: 1.891e+00\n",
      "Epoch 4408, Loss: 936.3184814453125, Neurons: 11, Grad norm: 1.908e+00\n",
      "Epoch 4409, Loss: 936.3049926757812, Neurons: 11, Grad norm: 1.890e+00\n",
      "Epoch 4410, Loss: 936.2913818359375, Neurons: 11, Grad norm: 1.904e+00\n",
      "Epoch 4411, Loss: 936.2779541015625, Neurons: 11, Grad norm: 1.889e+00\n",
      "Epoch 4412, Loss: 936.2645874023438, Neurons: 11, Grad norm: 1.899e+00\n",
      "Epoch 4413, Loss: 936.2510986328125, Neurons: 11, Grad norm: 1.888e+00\n",
      "Epoch 4414, Loss: 936.237548828125, Neurons: 11, Grad norm: 1.895e+00\n",
      "Epoch 4415, Loss: 936.2240600585938, Neurons: 11, Grad norm: 1.887e+00\n",
      "Epoch 4416, Loss: 936.210693359375, Neurons: 11, Grad norm: 1.893e+00\n",
      "Epoch 4417, Loss: 936.1972045898438, Neurons: 11, Grad norm: 1.885e+00\n",
      "Epoch 4418, Loss: 936.1837768554688, Neurons: 11, Grad norm: 1.890e+00\n",
      "Epoch 4419, Loss: 936.1703491210938, Neurons: 11, Grad norm: 1.883e+00\n",
      "Epoch 4420, Loss: 936.156982421875, Neurons: 11, Grad norm: 1.888e+00\n",
      "Epoch 4421, Loss: 936.1434936523438, Neurons: 11, Grad norm: 1.881e+00\n",
      "Epoch 4422, Loss: 936.1301879882812, Neurons: 11, Grad norm: 1.885e+00\n",
      "Epoch 4423, Loss: 936.1167602539062, Neurons: 11, Grad norm: 1.880e+00\n",
      "Epoch 4424, Loss: 936.1033935546875, Neurons: 11, Grad norm: 1.883e+00\n",
      "Epoch 4425, Loss: 936.0899658203125, Neurons: 11, Grad norm: 1.878e+00\n",
      "Epoch 4426, Loss: 936.0765991210938, Neurons: 11, Grad norm: 1.882e+00\n",
      "Epoch 4427, Loss: 936.0631713867188, Neurons: 11, Grad norm: 1.876e+00\n",
      "Epoch 4428, Loss: 936.0498046875, Neurons: 11, Grad norm: 1.880e+00\n",
      "Epoch 4429, Loss: 936.0365600585938, Neurons: 11, Grad norm: 1.873e+00\n",
      "Epoch 4430, Loss: 936.023193359375, Neurons: 11, Grad norm: 1.879e+00\n",
      "Epoch 4431, Loss: 936.009765625, Neurons: 11, Grad norm: 1.871e+00\n",
      "Epoch 4432, Loss: 935.9964599609375, Neurons: 11, Grad norm: 1.878e+00\n",
      "Epoch 4433, Loss: 935.9830932617188, Neurons: 11, Grad norm: 1.868e+00\n",
      "Epoch 4434, Loss: 935.9698486328125, Neurons: 11, Grad norm: 1.878e+00\n",
      "Epoch 4435, Loss: 935.9566040039062, Neurons: 11, Grad norm: 1.865e+00\n",
      "Epoch 4436, Loss: 935.9431762695312, Neurons: 11, Grad norm: 1.879e+00\n",
      "Epoch 4437, Loss: 935.9298706054688, Neurons: 11, Grad norm: 1.861e+00\n",
      "Epoch 4438, Loss: 935.9165649414062, Neurons: 11, Grad norm: 1.884e+00\n",
      "Epoch 4439, Loss: 935.9033813476562, Neurons: 11, Grad norm: 1.858e+00\n",
      "Epoch 4440, Loss: 935.8900756835938, Neurons: 11, Grad norm: 1.899e+00\n",
      "Epoch 4441, Loss: 935.8767700195312, Neurons: 11, Grad norm: 1.861e+00\n",
      "Epoch 4442, Loss: 935.8634643554688, Neurons: 11, Grad norm: 1.937e+00\n",
      "Epoch 4443, Loss: 935.8501586914062, Neurons: 11, Grad norm: 1.886e+00\n",
      "Epoch 4444, Loss: 935.8369750976562, Neurons: 11, Grad norm: 2.038e+00\n",
      "Epoch 4445, Loss: 935.8237915039062, Neurons: 11, Grad norm: 1.994e+00\n",
      "Epoch 4446, Loss: 935.8104858398438, Neurons: 11, Grad norm: 2.315e+00\n",
      "Epoch 4447, Loss: 935.7973022460938, Neurons: 11, Grad norm: 2.370e+00\n",
      "Epoch 4448, Loss: 935.7840576171875, Neurons: 11, Grad norm: 3.044e+00\n",
      "Epoch 4449, Loss: 935.7708740234375, Neurons: 11, Grad norm: 3.450e+00\n",
      "Epoch 4449, Test loss: 946.935302734375\n",
      "Epoch 4450, Loss: 935.7576904296875, Neurons: 11, Grad norm: 4.789e+00\n",
      "Epoch 4451, Loss: 935.744384765625, Neurons: 11, Grad norm: 6.012e+00\n",
      "Epoch 4452, Loss: 935.7312622070312, Neurons: 11, Grad norm: 8.576e+00\n",
      "Epoch 4453, Loss: 935.7180786132812, Neurons: 11, Grad norm: 1.144e+01\n",
      "Epoch 4454, Loss: 935.7049560546875, Neurons: 11, Grad norm: 1.629e+01\n",
      "Epoch 4455, Loss: 935.6919555664062, Neurons: 11, Grad norm: 2.214e+01\n",
      "Epoch 4456, Loss: 935.67919921875, Neurons: 11, Grad norm: 3.063e+01\n",
      "Epoch 4457, Loss: 935.6663818359375, Neurons: 11, Grad norm: 3.990e+01\n",
      "Epoch 4458, Loss: 935.654052734375, Neurons: 11, Grad norm: 4.938e+01\n",
      "Epoch 4459, Loss: 935.6419067382812, Neurons: 11, Grad norm: 5.269e+01\n",
      "Epoch 4460, Loss: 935.629150390625, Neurons: 11, Grad norm: 4.582e+01\n",
      "Epoch 4461, Loss: 935.6151733398438, Neurons: 11, Grad norm: 2.509e+01\n",
      "Epoch 4462, Loss: 935.6004638671875, Neurons: 11, Grad norm: 2.443e+00\n",
      "Epoch 4463, Loss: 935.5865478515625, Neurons: 11, Grad norm: 2.590e+01\n",
      "Epoch 4464, Loss: 935.5742797851562, Neurons: 11, Grad norm: 3.715e+01\n",
      "Epoch 4465, Loss: 935.5619506835938, Neurons: 11, Grad norm: 3.276e+01\n",
      "Epoch 4466, Loss: 935.548583984375, Neurons: 11, Grad norm: 1.360e+01\n",
      "Epoch 4467, Loss: 935.5343627929688, Neurons: 11, Grad norm: 9.723e+00\n",
      "Epoch 4468, Loss: 935.5211791992188, Neurons: 11, Grad norm: 2.648e+01\n",
      "Epoch 4469, Loss: 935.5087890625, Neurons: 11, Grad norm: 2.823e+01\n",
      "Epoch 4470, Loss: 935.4959716796875, Neurons: 11, Grad norm: 1.644e+01\n",
      "Epoch 4471, Loss: 935.482177734375, Neurons: 11, Grad norm: 3.945e+00\n",
      "Epoch 4472, Loss: 935.46875, Neurons: 11, Grad norm: 1.890e+01\n",
      "Epoch 4473, Loss: 935.4561767578125, Neurons: 11, Grad norm: 2.359e+01\n",
      "Epoch 4474, Loss: 935.443359375, Neurons: 11, Grad norm: 1.464e+01\n",
      "Epoch 4475, Loss: 935.4300537109375, Neurons: 11, Grad norm: 1.973e+00\n",
      "Epoch 4476, Loss: 935.416748046875, Neurons: 11, Grad norm: 1.487e+01\n",
      "Epoch 4477, Loss: 935.4039916992188, Neurons: 11, Grad norm: 1.883e+01\n",
      "Epoch 4478, Loss: 935.3911743164062, Neurons: 11, Grad norm: 1.285e+01\n",
      "Epoch 4479, Loss: 935.3778686523438, Neurons: 11, Grad norm: 1.858e+00\n",
      "Epoch 4480, Loss: 935.3646850585938, Neurons: 11, Grad norm: 1.143e+01\n",
      "Epoch 4481, Loss: 935.3519897460938, Neurons: 11, Grad norm: 1.573e+01\n",
      "Epoch 4482, Loss: 935.3390502929688, Neurons: 11, Grad norm: 1.036e+01\n",
      "Epoch 4483, Loss: 935.3258666992188, Neurons: 11, Grad norm: 1.857e+00\n",
      "Epoch 4484, Loss: 935.3128051757812, Neurons: 11, Grad norm: 9.559e+00\n",
      "Epoch 4485, Loss: 935.2999877929688, Neurons: 11, Grad norm: 1.247e+01\n",
      "Epoch 4486, Loss: 935.2870483398438, Neurons: 11, Grad norm: 9.062e+00\n",
      "Epoch 4487, Loss: 935.2740478515625, Neurons: 11, Grad norm: 1.828e+00\n",
      "Epoch 4488, Loss: 935.260986328125, Neurons: 11, Grad norm: 7.279e+00\n",
      "Epoch 4489, Loss: 935.2481689453125, Neurons: 11, Grad norm: 1.058e+01\n",
      "Epoch 4490, Loss: 935.2352905273438, Neurons: 11, Grad norm: 7.344e+00\n",
      "Epoch 4491, Loss: 935.2223510742188, Neurons: 11, Grad norm: 2.051e+00\n",
      "Epoch 4492, Loss: 935.2092895507812, Neurons: 11, Grad norm: 6.075e+00\n",
      "Epoch 4493, Loss: 935.1964721679688, Neurons: 11, Grad norm: 8.279e+00\n",
      "Epoch 4494, Loss: 935.18359375, Neurons: 11, Grad norm: 6.754e+00\n",
      "Epoch 4495, Loss: 935.170654296875, Neurons: 11, Grad norm: 2.034e+00\n",
      "Epoch 4496, Loss: 935.1577758789062, Neurons: 11, Grad norm: 4.310e+00\n",
      "Epoch 4497, Loss: 935.1448974609375, Neurons: 11, Grad norm: 7.117e+00\n",
      "Epoch 4498, Loss: 935.1319580078125, Neurons: 11, Grad norm: 5.587e+00\n",
      "Epoch 4499, Loss: 935.1192016601562, Neurons: 11, Grad norm: 2.512e+00\n",
      "Epoch 4499, Test loss: 946.234619140625\n",
      "Epoch 4500, Loss: 935.106201171875, Neurons: 11, Grad norm: 3.514e+00\n",
      "Epoch 4501, Loss: 935.0933837890625, Neurons: 11, Grad norm: 5.394e+00\n",
      "Epoch 4502, Loss: 935.08056640625, Neurons: 11, Grad norm: 5.340e+00\n",
      "Epoch 4503, Loss: 935.0677490234375, Neurons: 11, Grad norm: 2.492e+00\n",
      "Epoch 4504, Loss: 935.0548706054688, Neurons: 11, Grad norm: 2.302e+00\n",
      "Epoch 4505, Loss: 935.0420532226562, Neurons: 11, Grad norm: 4.613e+00\n",
      "Epoch 4506, Loss: 935.029296875, Neurons: 11, Grad norm: 4.368e+00\n",
      "Epoch 4507, Loss: 935.016357421875, Neurons: 11, Grad norm: 3.025e+00\n",
      "Epoch 4508, Loss: 935.0036010742188, Neurons: 11, Grad norm: 1.977e+00\n",
      "Epoch 4509, Loss: 934.9907836914062, Neurons: 11, Grad norm: 3.238e+00\n",
      "Epoch 4510, Loss: 934.9779663085938, Neurons: 11, Grad norm: 4.144e+00\n",
      "Epoch 4511, Loss: 934.9652709960938, Neurons: 11, Grad norm: 2.834e+00\n",
      "Epoch 4512, Loss: 934.9525756835938, Neurons: 11, Grad norm: 1.843e+00\n",
      "Epoch 4513, Loss: 934.939697265625, Neurons: 11, Grad norm: 2.716e+00\n",
      "Epoch 4514, Loss: 934.927001953125, Neurons: 11, Grad norm: 3.175e+00\n",
      "Epoch 4515, Loss: 934.9141845703125, Neurons: 11, Grad norm: 3.158e+00\n",
      "Epoch 4516, Loss: 934.9013671875, Neurons: 11, Grad norm: 1.916e+00\n",
      "Epoch 4517, Loss: 934.888671875, Neurons: 11, Grad norm: 1.910e+00\n",
      "Epoch 4518, Loss: 934.8759765625, Neurons: 11, Grad norm: 2.890e+00\n",
      "Epoch 4519, Loss: 934.8631591796875, Neurons: 11, Grad norm: 2.685e+00\n",
      "Epoch 4520, Loss: 934.8504028320312, Neurons: 11, Grad norm: 2.352e+00\n",
      "Epoch 4521, Loss: 934.8377685546875, Neurons: 11, Grad norm: 1.801e+00\n",
      "Epoch 4522, Loss: 934.824951171875, Neurons: 11, Grad norm: 2.082e+00\n",
      "Epoch 4523, Loss: 934.812255859375, Neurons: 11, Grad norm: 2.697e+00\n",
      "Epoch 4524, Loss: 934.799560546875, Neurons: 11, Grad norm: 2.213e+00\n",
      "Epoch 4525, Loss: 934.7869873046875, Neurons: 11, Grad norm: 1.947e+00\n",
      "Epoch 4526, Loss: 934.7742919921875, Neurons: 11, Grad norm: 1.912e+00\n",
      "Epoch 4527, Loss: 934.7615966796875, Neurons: 11, Grad norm: 2.075e+00\n",
      "Epoch 4528, Loss: 934.7489624023438, Neurons: 11, Grad norm: 2.409e+00\n",
      "Epoch 4529, Loss: 934.7362670898438, Neurons: 11, Grad norm: 1.936e+00\n",
      "Epoch 4530, Loss: 934.7235717773438, Neurons: 11, Grad norm: 1.810e+00\n",
      "Epoch 4531, Loss: 934.7108764648438, Neurons: 11, Grad norm: 1.964e+00\n",
      "Epoch 4532, Loss: 934.6983032226562, Neurons: 11, Grad norm: 1.988e+00\n",
      "Epoch 4533, Loss: 934.685546875, Neurons: 11, Grad norm: 2.180e+00\n",
      "Epoch 4534, Loss: 934.6729736328125, Neurons: 11, Grad norm: 1.818e+00\n",
      "Epoch 4535, Loss: 934.660400390625, Neurons: 11, Grad norm: 1.777e+00\n",
      "Epoch 4536, Loss: 934.6477661132812, Neurons: 11, Grad norm: 1.948e+00\n",
      "Epoch 4537, Loss: 934.6351928710938, Neurons: 11, Grad norm: 1.900e+00\n",
      "Epoch 4538, Loss: 934.62255859375, Neurons: 11, Grad norm: 2.030e+00\n",
      "Epoch 4539, Loss: 934.6099853515625, Neurons: 11, Grad norm: 1.779e+00\n",
      "Epoch 4540, Loss: 934.5973510742188, Neurons: 11, Grad norm: 1.768e+00\n",
      "Epoch 4541, Loss: 934.5847778320312, Neurons: 11, Grad norm: 1.905e+00\n",
      "Epoch 4542, Loss: 934.5722045898438, Neurons: 11, Grad norm: 1.836e+00\n",
      "Epoch 4543, Loss: 934.5596923828125, Neurons: 11, Grad norm: 1.943e+00\n",
      "Epoch 4544, Loss: 934.5469970703125, Neurons: 11, Grad norm: 1.766e+00\n",
      "Epoch 4545, Loss: 934.5344848632812, Neurons: 11, Grad norm: 1.766e+00\n",
      "Epoch 4546, Loss: 934.5218505859375, Neurons: 11, Grad norm: 1.857e+00\n",
      "Epoch 4547, Loss: 934.5093994140625, Neurons: 11, Grad norm: 1.794e+00\n",
      "Epoch 4548, Loss: 934.4968872070312, Neurons: 11, Grad norm: 1.889e+00\n",
      "Epoch 4549, Loss: 934.4842529296875, Neurons: 11, Grad norm: 1.759e+00\n",
      "Epoch 4549, Test loss: 945.55517578125\n",
      "Epoch 4550, Loss: 934.4718017578125, Neurons: 11, Grad norm: 1.766e+00\n",
      "Epoch 4551, Loss: 934.4592895507812, Neurons: 11, Grad norm: 1.818e+00\n",
      "Epoch 4552, Loss: 934.44677734375, Neurons: 11, Grad norm: 1.768e+00\n",
      "Epoch 4553, Loss: 934.4342041015625, Neurons: 11, Grad norm: 1.855e+00\n",
      "Epoch 4554, Loss: 934.4217529296875, Neurons: 11, Grad norm: 1.754e+00\n",
      "Epoch 4555, Loss: 934.4091796875, Neurons: 11, Grad norm: 1.770e+00\n",
      "Epoch 4556, Loss: 934.3966674804688, Neurons: 11, Grad norm: 1.786e+00\n",
      "Epoch 4557, Loss: 934.3841552734375, Neurons: 11, Grad norm: 1.753e+00\n",
      "Epoch 4558, Loss: 934.3717651367188, Neurons: 11, Grad norm: 1.826e+00\n",
      "Epoch 4559, Loss: 934.3592529296875, Neurons: 11, Grad norm: 1.750e+00\n",
      "Epoch 4560, Loss: 934.3468017578125, Neurons: 11, Grad norm: 1.775e+00\n",
      "Epoch 4561, Loss: 934.3343505859375, Neurons: 11, Grad norm: 1.763e+00\n",
      "Epoch 4562, Loss: 934.3218994140625, Neurons: 11, Grad norm: 1.746e+00\n",
      "Epoch 4563, Loss: 934.3094482421875, Neurons: 11, Grad norm: 1.801e+00\n",
      "Epoch 4564, Loss: 934.2969970703125, Neurons: 11, Grad norm: 1.745e+00\n",
      "Epoch 4565, Loss: 934.2845458984375, Neurons: 11, Grad norm: 1.780e+00\n",
      "Epoch 4566, Loss: 934.2721557617188, Neurons: 11, Grad norm: 1.748e+00\n",
      "Epoch 4567, Loss: 934.259765625, Neurons: 11, Grad norm: 1.745e+00\n",
      "Epoch 4568, Loss: 934.2473754882812, Neurons: 11, Grad norm: 1.777e+00\n",
      "Epoch 4569, Loss: 934.2349853515625, Neurons: 11, Grad norm: 1.740e+00\n",
      "Epoch 4570, Loss: 934.2225952148438, Neurons: 11, Grad norm: 1.778e+00\n",
      "Epoch 4571, Loss: 934.210205078125, Neurons: 11, Grad norm: 1.740e+00\n",
      "Epoch 4572, Loss: 934.19775390625, Neurons: 11, Grad norm: 1.750e+00\n",
      "Epoch 4573, Loss: 934.1853637695312, Neurons: 11, Grad norm: 1.755e+00\n",
      "Epoch 4574, Loss: 934.1729736328125, Neurons: 11, Grad norm: 1.736e+00\n",
      "Epoch 4575, Loss: 934.1607055664062, Neurons: 11, Grad norm: 1.768e+00\n",
      "Epoch 4576, Loss: 934.1482543945312, Neurons: 11, Grad norm: 1.734e+00\n",
      "Epoch 4577, Loss: 934.1358642578125, Neurons: 11, Grad norm: 1.755e+00\n",
      "Epoch 4578, Loss: 934.1235961914062, Neurons: 11, Grad norm: 1.739e+00\n",
      "Epoch 4579, Loss: 934.1112670898438, Neurons: 11, Grad norm: 1.738e+00\n",
      "Epoch 4580, Loss: 934.098876953125, Neurons: 11, Grad norm: 1.751e+00\n",
      "Epoch 4581, Loss: 934.0865478515625, Neurons: 11, Grad norm: 1.731e+00\n",
      "Epoch 4582, Loss: 934.0742797851562, Neurons: 11, Grad norm: 1.753e+00\n",
      "Epoch 4583, Loss: 934.0619506835938, Neurons: 11, Grad norm: 1.731e+00\n",
      "Epoch 4584, Loss: 934.0496826171875, Neurons: 11, Grad norm: 1.741e+00\n",
      "Epoch 4585, Loss: 934.037353515625, Neurons: 11, Grad norm: 1.736e+00\n",
      "Epoch 4586, Loss: 934.0249633789062, Neurons: 11, Grad norm: 1.731e+00\n",
      "Epoch 4587, Loss: 934.0127563476562, Neurons: 11, Grad norm: 1.742e+00\n",
      "Epoch 4588, Loss: 934.0003662109375, Neurons: 11, Grad norm: 1.727e+00\n",
      "Epoch 4589, Loss: 933.9881591796875, Neurons: 11, Grad norm: 1.741e+00\n",
      "Epoch 4590, Loss: 933.9758911132812, Neurons: 11, Grad norm: 1.727e+00\n",
      "Epoch 4591, Loss: 933.9635620117188, Neurons: 11, Grad norm: 1.733e+00\n",
      "Epoch 4592, Loss: 933.9513549804688, Neurons: 11, Grad norm: 1.731e+00\n",
      "Epoch 4593, Loss: 933.9390869140625, Neurons: 11, Grad norm: 1.726e+00\n",
      "Epoch 4594, Loss: 933.9268798828125, Neurons: 11, Grad norm: 1.734e+00\n",
      "Epoch 4595, Loss: 933.91455078125, Neurons: 11, Grad norm: 1.722e+00\n",
      "Epoch 4596, Loss: 933.9024047851562, Neurons: 11, Grad norm: 1.732e+00\n",
      "Epoch 4597, Loss: 933.8901977539062, Neurons: 11, Grad norm: 1.722e+00\n",
      "Epoch 4598, Loss: 933.8779907226562, Neurons: 11, Grad norm: 1.727e+00\n",
      "Epoch 4599, Loss: 933.8656616210938, Neurons: 11, Grad norm: 1.723e+00\n",
      "Epoch 4599, Test loss: 944.8920288085938\n",
      "Epoch 4600, Loss: 933.8534545898438, Neurons: 11, Grad norm: 1.721e+00\n",
      "Epoch 4601, Loss: 933.8412475585938, Neurons: 11, Grad norm: 1.724e+00\n",
      "Epoch 4602, Loss: 933.8291015625, Neurons: 11, Grad norm: 1.718e+00\n",
      "Epoch 4603, Loss: 933.81689453125, Neurons: 11, Grad norm: 1.723e+00\n",
      "Epoch 4604, Loss: 933.8047485351562, Neurons: 11, Grad norm: 1.717e+00\n",
      "Epoch 4605, Loss: 933.7926025390625, Neurons: 11, Grad norm: 1.719e+00\n",
      "Epoch 4606, Loss: 933.7803955078125, Neurons: 11, Grad norm: 1.717e+00\n",
      "Epoch 4607, Loss: 933.7681884765625, Neurons: 11, Grad norm: 1.715e+00\n",
      "Epoch 4608, Loss: 933.756103515625, Neurons: 11, Grad norm: 1.718e+00\n",
      "Epoch 4609, Loss: 933.7439575195312, Neurons: 11, Grad norm: 1.712e+00\n",
      "Epoch 4610, Loss: 933.7317504882812, Neurons: 11, Grad norm: 1.717e+00\n",
      "Epoch 4611, Loss: 933.7196044921875, Neurons: 11, Grad norm: 1.710e+00\n",
      "Epoch 4612, Loss: 933.7074584960938, Neurons: 11, Grad norm: 1.716e+00\n",
      "Epoch 4613, Loss: 933.6953735351562, Neurons: 11, Grad norm: 1.708e+00\n",
      "Epoch 4614, Loss: 933.6831665039062, Neurons: 11, Grad norm: 1.713e+00\n",
      "Epoch 4615, Loss: 933.6710815429688, Neurons: 11, Grad norm: 1.708e+00\n",
      "Epoch 4616, Loss: 933.6589965820312, Neurons: 11, Grad norm: 1.710e+00\n",
      "Epoch 4617, Loss: 933.6468505859375, Neurons: 11, Grad norm: 1.707e+00\n",
      "Epoch 4618, Loss: 933.634765625, Neurons: 11, Grad norm: 1.707e+00\n",
      "Epoch 4619, Loss: 933.622802734375, Neurons: 11, Grad norm: 1.707e+00\n",
      "Epoch 4620, Loss: 933.610595703125, Neurons: 11, Grad norm: 1.704e+00\n",
      "Epoch 4621, Loss: 933.5985717773438, Neurons: 11, Grad norm: 1.706e+00\n",
      "Epoch 4622, Loss: 933.5864868164062, Neurons: 11, Grad norm: 1.701e+00\n",
      "Epoch 4623, Loss: 933.5744018554688, Neurons: 11, Grad norm: 1.705e+00\n",
      "Epoch 4624, Loss: 933.5623779296875, Neurons: 11, Grad norm: 1.699e+00\n",
      "Epoch 4625, Loss: 933.55029296875, Neurons: 11, Grad norm: 1.704e+00\n",
      "Epoch 4626, Loss: 933.5381469726562, Neurons: 11, Grad norm: 1.697e+00\n",
      "Epoch 4627, Loss: 933.5261840820312, Neurons: 11, Grad norm: 1.701e+00\n",
      "Epoch 4628, Loss: 933.51416015625, Neurons: 11, Grad norm: 1.697e+00\n",
      "Epoch 4629, Loss: 933.502197265625, Neurons: 11, Grad norm: 1.698e+00\n",
      "Epoch 4630, Loss: 933.4900512695312, Neurons: 11, Grad norm: 1.696e+00\n",
      "Epoch 4631, Loss: 933.4780883789062, Neurons: 11, Grad norm: 1.695e+00\n",
      "Epoch 4632, Loss: 933.466064453125, Neurons: 11, Grad norm: 1.695e+00\n",
      "Epoch 4633, Loss: 933.4541015625, Neurons: 11, Grad norm: 1.693e+00\n",
      "Epoch 4634, Loss: 933.4420776367188, Neurons: 11, Grad norm: 1.694e+00\n",
      "Epoch 4635, Loss: 933.4300537109375, Neurons: 11, Grad norm: 1.691e+00\n",
      "Epoch 4636, Loss: 933.4180908203125, Neurons: 11, Grad norm: 1.692e+00\n",
      "Epoch 4637, Loss: 933.406005859375, Neurons: 11, Grad norm: 1.689e+00\n",
      "Epoch 4638, Loss: 933.3941650390625, Neurons: 11, Grad norm: 1.690e+00\n",
      "Epoch 4639, Loss: 933.3822021484375, Neurons: 11, Grad norm: 1.688e+00\n",
      "Epoch 4640, Loss: 933.3701782226562, Neurons: 11, Grad norm: 1.688e+00\n",
      "Epoch 4641, Loss: 933.358154296875, Neurons: 11, Grad norm: 1.687e+00\n",
      "Epoch 4642, Loss: 933.3462524414062, Neurons: 11, Grad norm: 1.685e+00\n",
      "Epoch 4643, Loss: 933.3343505859375, Neurons: 11, Grad norm: 1.686e+00\n",
      "Epoch 4644, Loss: 933.3223876953125, Neurons: 11, Grad norm: 1.683e+00\n",
      "Epoch 4645, Loss: 933.3103637695312, Neurons: 11, Grad norm: 1.685e+00\n",
      "Epoch 4646, Loss: 933.2984619140625, Neurons: 11, Grad norm: 1.680e+00\n",
      "Epoch 4647, Loss: 933.2865600585938, Neurons: 11, Grad norm: 1.685e+00\n",
      "Epoch 4648, Loss: 933.2747802734375, Neurons: 11, Grad norm: 1.677e+00\n",
      "Epoch 4649, Loss: 933.2627563476562, Neurons: 11, Grad norm: 1.685e+00\n",
      "Epoch 4649, Test loss: 944.2455444335938\n",
      "Epoch 4650, Loss: 933.2509765625, Neurons: 11, Grad norm: 1.674e+00\n",
      "Epoch 4651, Loss: 933.2389526367188, Neurons: 11, Grad norm: 1.687e+00\n",
      "Epoch 4652, Loss: 933.2271728515625, Neurons: 11, Grad norm: 1.671e+00\n",
      "Epoch 4653, Loss: 933.2151489257812, Neurons: 11, Grad norm: 1.690e+00\n",
      "Epoch 4654, Loss: 933.2032470703125, Neurons: 11, Grad norm: 1.667e+00\n",
      "Epoch 4655, Loss: 933.1914672851562, Neurons: 11, Grad norm: 1.699e+00\n",
      "Epoch 4656, Loss: 933.1795654296875, Neurons: 11, Grad norm: 1.665e+00\n",
      "Epoch 4657, Loss: 933.1676635742188, Neurons: 11, Grad norm: 1.719e+00\n",
      "Epoch 4658, Loss: 933.1558837890625, Neurons: 11, Grad norm: 1.670e+00\n",
      "Epoch 4659, Loss: 933.1439819335938, Neurons: 11, Grad norm: 1.767e+00\n",
      "Epoch 4660, Loss: 933.1322631835938, Neurons: 11, Grad norm: 1.703e+00\n",
      "Epoch 4661, Loss: 933.120361328125, Neurons: 11, Grad norm: 1.891e+00\n",
      "Epoch 4662, Loss: 933.1085815429688, Neurons: 11, Grad norm: 1.837e+00\n",
      "Epoch 4663, Loss: 933.0966796875, Neurons: 11, Grad norm: 2.215e+00\n",
      "Epoch 4664, Loss: 933.0848999023438, Neurons: 11, Grad norm: 2.276e+00\n",
      "Epoch 4665, Loss: 933.0730590820312, Neurons: 11, Grad norm: 3.020e+00\n",
      "Epoch 4666, Loss: 933.061279296875, Neurons: 11, Grad norm: 3.443e+00\n",
      "Epoch 4667, Loss: 933.0494995117188, Neurons: 11, Grad norm: 4.840e+00\n",
      "Epoch 4668, Loss: 933.0376586914062, Neurons: 11, Grad norm: 6.069e+00\n",
      "Epoch 4669, Loss: 933.02587890625, Neurons: 11, Grad norm: 8.653e+00\n",
      "Epoch 4670, Loss: 933.0140991210938, Neurons: 11, Grad norm: 1.148e+01\n",
      "Epoch 4671, Loss: 933.0025024414062, Neurons: 11, Grad norm: 1.629e+01\n",
      "Epoch 4672, Loss: 932.9907836914062, Neurons: 11, Grad norm: 2.208e+01\n",
      "Epoch 4673, Loss: 932.979248046875, Neurons: 11, Grad norm: 3.063e+01\n",
      "Epoch 4674, Loss: 932.9679565429688, Neurons: 11, Grad norm: 4.037e+01\n",
      "Epoch 4675, Loss: 932.9569702148438, Neurons: 11, Grad norm: 5.149e+01\n",
      "Epoch 4676, Loss: 932.9461669921875, Neurons: 11, Grad norm: 5.840e+01\n",
      "Epoch 4677, Loss: 932.9353637695312, Neurons: 11, Grad norm: 5.673e+01\n",
      "Epoch 4678, Loss: 932.9232788085938, Neurons: 11, Grad norm: 3.990e+01\n",
      "Epoch 4679, Loss: 932.9099731445312, Neurons: 11, Grad norm: 1.279e+01\n",
      "Epoch 4680, Loss: 932.8967895507812, Neurons: 11, Grad norm: 1.720e+01\n",
      "Epoch 4681, Loss: 932.8851928710938, Neurons: 11, Grad norm: 3.706e+01\n",
      "Epoch 4682, Loss: 932.8745727539062, Neurons: 11, Grad norm: 4.161e+01\n",
      "Epoch 4683, Loss: 932.86328125, Neurons: 11, Grad norm: 2.768e+01\n",
      "Epoch 4684, Loss: 932.8505859375, Neurons: 11, Grad norm: 3.764e+00\n",
      "Epoch 4685, Loss: 932.8381958007812, Neurons: 11, Grad norm: 2.072e+01\n",
      "Epoch 4686, Loss: 932.8267822265625, Neurons: 11, Grad norm: 3.214e+01\n",
      "Epoch 4687, Loss: 932.8157958984375, Neurons: 11, Grad norm: 2.791e+01\n",
      "Epoch 4688, Loss: 932.8037719726562, Neurons: 11, Grad norm: 9.666e+00\n",
      "Epoch 4689, Loss: 932.79150390625, Neurons: 11, Grad norm: 1.113e+01\n",
      "Epoch 4690, Loss: 932.77978515625, Neurons: 11, Grad norm: 2.480e+01\n",
      "Epoch 4691, Loss: 932.768798828125, Neurons: 11, Grad norm: 2.381e+01\n",
      "Epoch 4692, Loss: 932.7569580078125, Neurons: 11, Grad norm: 1.138e+01\n",
      "Epoch 4693, Loss: 932.7449951171875, Neurons: 11, Grad norm: 6.796e+00\n",
      "Epoch 4694, Loss: 932.733154296875, Neurons: 11, Grad norm: 1.865e+01\n",
      "Epoch 4695, Loss: 932.7219848632812, Neurons: 11, Grad norm: 2.032e+01\n",
      "Epoch 4696, Loss: 932.7103881835938, Neurons: 11, Grad norm: 1.047e+01\n",
      "Epoch 4697, Loss: 932.6983642578125, Neurons: 11, Grad norm: 3.788e+00\n",
      "Epoch 4698, Loss: 932.6867065429688, Neurons: 11, Grad norm: 1.481e+01\n",
      "Epoch 4699, Loss: 932.67529296875, Neurons: 11, Grad norm: 1.642e+01\n",
      "Epoch 4699, Test loss: 943.6234741210938\n",
      "Epoch 4700, Loss: 932.6637573242188, Neurons: 11, Grad norm: 9.948e+00\n",
      "Epoch 4701, Loss: 932.6519775390625, Neurons: 11, Grad norm: 2.618e+00\n",
      "Epoch 4702, Loss: 932.640380859375, Neurons: 11, Grad norm: 1.106e+01\n",
      "Epoch 4703, Loss: 932.6287841796875, Neurons: 11, Grad norm: 1.393e+01\n",
      "Epoch 4704, Loss: 932.6172485351562, Neurons: 11, Grad norm: 8.563e+00\n",
      "Epoch 4705, Loss: 932.6056518554688, Neurons: 11, Grad norm: 1.647e+00\n",
      "Epoch 4706, Loss: 932.5940551757812, Neurons: 11, Grad norm: 8.782e+00\n",
      "Epoch 4707, Loss: 932.5825805664062, Neurons: 11, Grad norm: 1.106e+01\n",
      "Epoch 4708, Loss: 932.5709838867188, Neurons: 11, Grad norm: 8.146e+00\n",
      "Epoch 4709, Loss: 932.5594482421875, Neurons: 11, Grad norm: 1.677e+00\n",
      "Epoch 4710, Loss: 932.5477905273438, Neurons: 11, Grad norm: 6.105e+00\n",
      "Epoch 4711, Loss: 932.536376953125, Neurons: 11, Grad norm: 9.388e+00\n",
      "Epoch 4712, Loss: 932.5247802734375, Neurons: 11, Grad norm: 6.983e+00\n",
      "Epoch 4713, Loss: 932.5133056640625, Neurons: 11, Grad norm: 2.415e+00\n",
      "Epoch 4714, Loss: 932.5017700195312, Neurons: 11, Grad norm: 4.618e+00\n",
      "Epoch 4715, Loss: 932.4901733398438, Neurons: 11, Grad norm: 7.146e+00\n",
      "Epoch 4716, Loss: 932.478759765625, Neurons: 11, Grad norm: 6.706e+00\n",
      "Epoch 4717, Loss: 932.46728515625, Neurons: 11, Grad norm: 2.679e+00\n",
      "Epoch 4718, Loss: 932.4557495117188, Neurons: 11, Grad norm: 2.705e+00\n",
      "Epoch 4719, Loss: 932.4441528320312, Neurons: 11, Grad norm: 5.907e+00\n",
      "Epoch 4720, Loss: 932.4326782226562, Neurons: 11, Grad norm: 5.569e+00\n",
      "Epoch 4721, Loss: 932.4212646484375, Neurons: 11, Grad norm: 3.506e+00\n",
      "Epoch 4722, Loss: 932.4097900390625, Neurons: 11, Grad norm: 1.958e+00\n",
      "Epoch 4723, Loss: 932.3983764648438, Neurons: 11, Grad norm: 4.016e+00\n",
      "Epoch 4724, Loss: 932.3869018554688, Neurons: 11, Grad norm: 5.180e+00\n",
      "Epoch 4725, Loss: 932.3753662109375, Neurons: 11, Grad norm: 3.403e+00\n",
      "Epoch 4726, Loss: 932.3638916015625, Neurons: 11, Grad norm: 1.694e+00\n",
      "Epoch 4727, Loss: 932.3524780273438, Neurons: 11, Grad norm: 3.087e+00\n",
      "Epoch 4728, Loss: 932.3410034179688, Neurons: 11, Grad norm: 3.908e+00\n",
      "Epoch 4729, Loss: 932.3296508789062, Neurons: 11, Grad norm: 3.805e+00\n",
      "Epoch 4730, Loss: 932.3181762695312, Neurons: 11, Grad norm: 1.916e+00\n",
      "Epoch 4731, Loss: 932.3067626953125, Neurons: 11, Grad norm: 1.834e+00\n",
      "Epoch 4732, Loss: 932.2953491210938, Neurons: 11, Grad norm: 3.349e+00\n",
      "Epoch 4733, Loss: 932.2839965820312, Neurons: 11, Grad norm: 3.191e+00\n",
      "Epoch 4734, Loss: 932.2725830078125, Neurons: 11, Grad norm: 2.613e+00\n",
      "Epoch 4735, Loss: 932.2611694335938, Neurons: 11, Grad norm: 1.611e+00\n",
      "Epoch 4736, Loss: 932.249755859375, Neurons: 11, Grad norm: 2.141e+00\n",
      "Epoch 4737, Loss: 932.2384033203125, Neurons: 11, Grad norm: 3.071e+00\n",
      "Epoch 4738, Loss: 932.22705078125, Neurons: 11, Grad norm: 2.456e+00\n",
      "Epoch 4739, Loss: 932.215576171875, Neurons: 11, Grad norm: 1.931e+00\n",
      "Epoch 4740, Loss: 932.2044067382812, Neurons: 11, Grad norm: 1.780e+00\n",
      "Epoch 4741, Loss: 932.1929931640625, Neurons: 11, Grad norm: 2.143e+00\n",
      "Epoch 4742, Loss: 932.1815795898438, Neurons: 11, Grad norm: 2.653e+00\n",
      "Epoch 4743, Loss: 932.170166015625, Neurons: 11, Grad norm: 1.969e+00\n",
      "Epoch 4744, Loss: 932.1587524414062, Neurons: 11, Grad norm: 1.675e+00\n",
      "Epoch 4745, Loss: 932.1475830078125, Neurons: 11, Grad norm: 1.867e+00\n",
      "Epoch 4746, Loss: 932.1361694335938, Neurons: 11, Grad norm: 2.005e+00\n",
      "Epoch 4747, Loss: 932.1248779296875, Neurons: 11, Grad norm: 2.293e+00\n",
      "Epoch 4748, Loss: 932.1134643554688, Neurons: 11, Grad norm: 1.730e+00\n",
      "Epoch 4749, Loss: 932.1021728515625, Neurons: 11, Grad norm: 1.608e+00\n",
      "Epoch 4749, Test loss: 943.0006713867188\n",
      "Epoch 4750, Loss: 932.0908813476562, Neurons: 11, Grad norm: 1.854e+00\n",
      "Epoch 4751, Loss: 932.07958984375, Neurons: 11, Grad norm: 1.853e+00\n",
      "Epoch 4752, Loss: 932.0682983398438, Neurons: 11, Grad norm: 2.051e+00\n",
      "Epoch 4753, Loss: 932.0570068359375, Neurons: 11, Grad norm: 1.639e+00\n",
      "Epoch 4754, Loss: 932.0457763671875, Neurons: 11, Grad norm: 1.594e+00\n",
      "Epoch 4755, Loss: 932.0343627929688, Neurons: 11, Grad norm: 1.788e+00\n",
      "Epoch 4756, Loss: 932.023193359375, Neurons: 11, Grad norm: 1.736e+00\n",
      "Epoch 4757, Loss: 932.0119018554688, Neurons: 11, Grad norm: 1.899e+00\n",
      "Epoch 4758, Loss: 932.0005493164062, Neurons: 11, Grad norm: 1.605e+00\n",
      "Epoch 4759, Loss: 931.9893798828125, Neurons: 11, Grad norm: 1.592e+00\n",
      "Epoch 4760, Loss: 931.9779663085938, Neurons: 11, Grad norm: 1.719e+00\n",
      "Epoch 4761, Loss: 931.966796875, Neurons: 11, Grad norm: 1.657e+00\n",
      "Epoch 4762, Loss: 931.95556640625, Neurons: 11, Grad norm: 1.806e+00\n",
      "Epoch 4763, Loss: 931.9443969726562, Neurons: 11, Grad norm: 1.592e+00\n",
      "Epoch 4764, Loss: 931.93310546875, Neurons: 11, Grad norm: 1.596e+00\n",
      "Epoch 4765, Loss: 931.921875, Neurons: 11, Grad norm: 1.659e+00\n",
      "Epoch 4766, Loss: 931.9105834960938, Neurons: 11, Grad norm: 1.608e+00\n",
      "Epoch 4767, Loss: 931.8993530273438, Neurons: 11, Grad norm: 1.742e+00\n",
      "Epoch 4768, Loss: 931.88818359375, Neurons: 11, Grad norm: 1.585e+00\n",
      "Epoch 4769, Loss: 931.876953125, Neurons: 11, Grad norm: 1.606e+00\n",
      "Epoch 4770, Loss: 931.8657836914062, Neurons: 11, Grad norm: 1.614e+00\n",
      "Epoch 4771, Loss: 931.8545532226562, Neurons: 11, Grad norm: 1.580e+00\n",
      "Epoch 4772, Loss: 931.8433837890625, Neurons: 11, Grad norm: 1.692e+00\n",
      "Epoch 4773, Loss: 931.8321533203125, Neurons: 11, Grad norm: 1.579e+00\n",
      "Epoch 4774, Loss: 931.8211059570312, Neurons: 11, Grad norm: 1.619e+00\n",
      "Epoch 4775, Loss: 931.8098754882812, Neurons: 11, Grad norm: 1.584e+00\n",
      "Epoch 4776, Loss: 931.7987670898438, Neurons: 11, Grad norm: 1.568e+00\n",
      "Epoch 4777, Loss: 931.78759765625, Neurons: 11, Grad norm: 1.647e+00\n",
      "Epoch 4778, Loss: 931.7763671875, Neurons: 11, Grad norm: 1.571e+00\n",
      "Epoch 4779, Loss: 931.7652587890625, Neurons: 11, Grad norm: 1.625e+00\n",
      "Epoch 4780, Loss: 931.7539672851562, Neurons: 11, Grad norm: 1.569e+00\n",
      "Epoch 4781, Loss: 931.7429809570312, Neurons: 11, Grad norm: 1.571e+00\n",
      "Epoch 4782, Loss: 931.7318725585938, Neurons: 11, Grad norm: 1.608e+00\n",
      "Epoch 4783, Loss: 931.7207641601562, Neurons: 11, Grad norm: 1.563e+00\n",
      "Epoch 4784, Loss: 931.7095947265625, Neurons: 11, Grad norm: 1.619e+00\n",
      "Epoch 4785, Loss: 931.698486328125, Neurons: 11, Grad norm: 1.562e+00\n",
      "Epoch 4786, Loss: 931.687255859375, Neurons: 11, Grad norm: 1.582e+00\n",
      "Epoch 4787, Loss: 931.6761474609375, Neurons: 11, Grad norm: 1.579e+00\n",
      "Epoch 4788, Loss: 931.6651611328125, Neurons: 11, Grad norm: 1.561e+00\n",
      "Epoch 4789, Loss: 931.6539916992188, Neurons: 11, Grad norm: 1.602e+00\n",
      "Epoch 4790, Loss: 931.6430053710938, Neurons: 11, Grad norm: 1.558e+00\n",
      "Epoch 4791, Loss: 931.6317749023438, Neurons: 11, Grad norm: 1.592e+00\n",
      "Epoch 4792, Loss: 931.6207885742188, Neurons: 11, Grad norm: 1.562e+00\n",
      "Epoch 4793, Loss: 931.6098022460938, Neurons: 11, Grad norm: 1.566e+00\n",
      "Epoch 4794, Loss: 931.5985717773438, Neurons: 11, Grad norm: 1.578e+00\n",
      "Epoch 4795, Loss: 931.5875854492188, Neurons: 11, Grad norm: 1.556e+00\n",
      "Epoch 4796, Loss: 931.5765991210938, Neurons: 11, Grad norm: 1.587e+00\n",
      "Epoch 4797, Loss: 931.5654907226562, Neurons: 11, Grad norm: 1.554e+00\n",
      "Epoch 4798, Loss: 931.5543823242188, Neurons: 11, Grad norm: 1.575e+00\n",
      "Epoch 4799, Loss: 931.5433959960938, Neurons: 11, Grad norm: 1.560e+00\n",
      "Epoch 4799, Test loss: 942.4011840820312\n",
      "Epoch 4800, Loss: 931.5323486328125, Neurons: 11, Grad norm: 1.559e+00\n",
      "Epoch 4801, Loss: 931.5213623046875, Neurons: 11, Grad norm: 1.572e+00\n",
      "Epoch 4802, Loss: 931.51025390625, Neurons: 11, Grad norm: 1.552e+00\n",
      "Epoch 4803, Loss: 931.4992065429688, Neurons: 11, Grad norm: 1.573e+00\n",
      "Epoch 4804, Loss: 931.4881591796875, Neurons: 11, Grad norm: 1.552e+00\n",
      "Epoch 4805, Loss: 931.4771728515625, Neurons: 11, Grad norm: 1.563e+00\n",
      "Epoch 4806, Loss: 931.4661865234375, Neurons: 11, Grad norm: 1.557e+00\n",
      "Epoch 4807, Loss: 931.4552001953125, Neurons: 11, Grad norm: 1.554e+00\n",
      "Epoch 4808, Loss: 931.4441528320312, Neurons: 11, Grad norm: 1.562e+00\n",
      "Epoch 4809, Loss: 931.4331665039062, Neurons: 11, Grad norm: 1.549e+00\n",
      "Epoch 4810, Loss: 931.4221801757812, Neurons: 11, Grad norm: 1.563e+00\n",
      "Epoch 4811, Loss: 931.4112548828125, Neurons: 11, Grad norm: 1.548e+00\n",
      "Epoch 4812, Loss: 931.4002685546875, Neurons: 11, Grad norm: 1.559e+00\n",
      "Epoch 4813, Loss: 931.389404296875, Neurons: 11, Grad norm: 1.549e+00\n",
      "Epoch 4814, Loss: 931.3783569335938, Neurons: 11, Grad norm: 1.552e+00\n",
      "Epoch 4815, Loss: 931.3673706054688, Neurons: 11, Grad norm: 1.553e+00\n",
      "Epoch 4816, Loss: 931.3563842773438, Neurons: 11, Grad norm: 1.546e+00\n",
      "Epoch 4817, Loss: 931.3455810546875, Neurons: 11, Grad norm: 1.554e+00\n",
      "Epoch 4818, Loss: 931.3345947265625, Neurons: 11, Grad norm: 1.544e+00\n",
      "Epoch 4819, Loss: 931.3236694335938, Neurons: 11, Grad norm: 1.551e+00\n",
      "Epoch 4820, Loss: 931.3126831054688, Neurons: 11, Grad norm: 1.545e+00\n",
      "Epoch 4821, Loss: 931.3017578125, Neurons: 11, Grad norm: 1.547e+00\n",
      "Epoch 4822, Loss: 931.290771484375, Neurons: 11, Grad norm: 1.546e+00\n",
      "Epoch 4823, Loss: 931.2799682617188, Neurons: 11, Grad norm: 1.543e+00\n",
      "Epoch 4824, Loss: 931.2689819335938, Neurons: 11, Grad norm: 1.546e+00\n",
      "Epoch 4825, Loss: 931.2581787109375, Neurons: 11, Grad norm: 1.541e+00\n",
      "Epoch 4826, Loss: 931.2471923828125, Neurons: 11, Grad norm: 1.544e+00\n",
      "Epoch 4827, Loss: 931.2363891601562, Neurons: 11, Grad norm: 1.540e+00\n",
      "Epoch 4828, Loss: 931.2254638671875, Neurons: 11, Grad norm: 1.541e+00\n",
      "Epoch 4829, Loss: 931.214599609375, Neurons: 11, Grad norm: 1.540e+00\n",
      "Epoch 4830, Loss: 931.2036743164062, Neurons: 11, Grad norm: 1.538e+00\n",
      "Epoch 4831, Loss: 931.19287109375, Neurons: 11, Grad norm: 1.539e+00\n",
      "Epoch 4832, Loss: 931.1820068359375, Neurons: 11, Grad norm: 1.536e+00\n",
      "Epoch 4833, Loss: 931.1712036132812, Neurons: 11, Grad norm: 1.538e+00\n",
      "Epoch 4834, Loss: 931.1602783203125, Neurons: 11, Grad norm: 1.535e+00\n",
      "Epoch 4835, Loss: 931.1494750976562, Neurons: 11, Grad norm: 1.536e+00\n",
      "Epoch 4836, Loss: 931.1385498046875, Neurons: 11, Grad norm: 1.533e+00\n",
      "Epoch 4837, Loss: 931.1277465820312, Neurons: 11, Grad norm: 1.534e+00\n",
      "Epoch 4838, Loss: 931.1170043945312, Neurons: 11, Grad norm: 1.532e+00\n",
      "Epoch 4839, Loss: 931.1060791015625, Neurons: 11, Grad norm: 1.532e+00\n",
      "Epoch 4840, Loss: 931.0952758789062, Neurons: 11, Grad norm: 1.531e+00\n",
      "Epoch 4841, Loss: 931.0843505859375, Neurons: 11, Grad norm: 1.531e+00\n",
      "Epoch 4842, Loss: 931.0735473632812, Neurons: 11, Grad norm: 1.529e+00\n",
      "Epoch 4843, Loss: 931.0628051757812, Neurons: 11, Grad norm: 1.530e+00\n",
      "Epoch 4844, Loss: 931.052001953125, Neurons: 11, Grad norm: 1.527e+00\n",
      "Epoch 4845, Loss: 931.0411987304688, Neurons: 11, Grad norm: 1.528e+00\n",
      "Epoch 4846, Loss: 931.0303955078125, Neurons: 11, Grad norm: 1.526e+00\n",
      "Epoch 4847, Loss: 931.0196533203125, Neurons: 11, Grad norm: 1.527e+00\n",
      "Epoch 4848, Loss: 931.0087890625, Neurons: 11, Grad norm: 1.524e+00\n",
      "Epoch 4849, Loss: 930.998046875, Neurons: 11, Grad norm: 1.525e+00\n",
      "Epoch 4849, Test loss: 941.8160400390625\n",
      "Epoch 4850, Loss: 930.9873657226562, Neurons: 11, Grad norm: 1.523e+00\n",
      "Epoch 4851, Loss: 930.9765625, Neurons: 11, Grad norm: 1.523e+00\n",
      "Epoch 4852, Loss: 930.9657592773438, Neurons: 11, Grad norm: 1.522e+00\n",
      "Epoch 4853, Loss: 930.9549560546875, Neurons: 11, Grad norm: 1.521e+00\n",
      "Epoch 4854, Loss: 930.9442749023438, Neurons: 11, Grad norm: 1.521e+00\n",
      "Epoch 4855, Loss: 930.93359375, Neurons: 11, Grad norm: 1.519e+00\n",
      "Epoch 4856, Loss: 930.9228515625, Neurons: 11, Grad norm: 1.520e+00\n",
      "Epoch 4857, Loss: 930.9120483398438, Neurons: 11, Grad norm: 1.516e+00\n",
      "Epoch 4858, Loss: 930.9013671875, Neurons: 11, Grad norm: 1.520e+00\n",
      "Epoch 4859, Loss: 930.8905639648438, Neurons: 11, Grad norm: 1.514e+00\n",
      "Epoch 4860, Loss: 930.8800048828125, Neurons: 11, Grad norm: 1.519e+00\n",
      "Epoch 4861, Loss: 930.8692016601562, Neurons: 11, Grad norm: 1.512e+00\n",
      "Epoch 4862, Loss: 930.8583984375, Neurons: 11, Grad norm: 1.518e+00\n",
      "Epoch 4863, Loss: 930.8477783203125, Neurons: 11, Grad norm: 1.510e+00\n",
      "Epoch 4864, Loss: 930.837158203125, Neurons: 11, Grad norm: 1.518e+00\n",
      "Epoch 4865, Loss: 930.8263549804688, Neurons: 11, Grad norm: 1.507e+00\n",
      "Epoch 4866, Loss: 930.815673828125, Neurons: 11, Grad norm: 1.519e+00\n",
      "Epoch 4867, Loss: 930.8049926757812, Neurons: 11, Grad norm: 1.504e+00\n",
      "Epoch 4868, Loss: 930.7943725585938, Neurons: 11, Grad norm: 1.521e+00\n",
      "Epoch 4869, Loss: 930.7837524414062, Neurons: 11, Grad norm: 1.500e+00\n",
      "Epoch 4870, Loss: 930.77294921875, Neurons: 11, Grad norm: 1.527e+00\n",
      "Epoch 4871, Loss: 930.7623901367188, Neurons: 11, Grad norm: 1.497e+00\n",
      "Epoch 4872, Loss: 930.7516479492188, Neurons: 11, Grad norm: 1.540e+00\n",
      "Epoch 4873, Loss: 930.740966796875, Neurons: 11, Grad norm: 1.495e+00\n",
      "Epoch 4874, Loss: 930.7303466796875, Neurons: 11, Grad norm: 1.570e+00\n",
      "Epoch 4875, Loss: 930.7197875976562, Neurons: 11, Grad norm: 1.506e+00\n",
      "Epoch 4876, Loss: 930.7091674804688, Neurons: 11, Grad norm: 1.641e+00\n",
      "Epoch 4877, Loss: 930.698486328125, Neurons: 11, Grad norm: 1.563e+00\n",
      "Epoch 4878, Loss: 930.6878662109375, Neurons: 11, Grad norm: 1.820e+00\n",
      "Epoch 4879, Loss: 930.67724609375, Neurons: 11, Grad norm: 1.773e+00\n",
      "Epoch 4880, Loss: 930.6666870117188, Neurons: 11, Grad norm: 2.270e+00\n",
      "Epoch 4881, Loss: 930.656005859375, Neurons: 11, Grad norm: 2.394e+00\n",
      "Epoch 4882, Loss: 930.6453857421875, Neurons: 11, Grad norm: 3.321e+00\n",
      "Epoch 4883, Loss: 930.6348876953125, Neurons: 11, Grad norm: 3.903e+00\n",
      "Epoch 4884, Loss: 930.6242065429688, Neurons: 11, Grad norm: 5.577e+00\n",
      "Epoch 4885, Loss: 930.6136474609375, Neurons: 11, Grad norm: 7.120e+00\n",
      "Epoch 4886, Loss: 930.6030883789062, Neurons: 11, Grad norm: 1.017e+01\n",
      "Epoch 4887, Loss: 930.5926513671875, Neurons: 11, Grad norm: 1.360e+01\n",
      "Epoch 4888, Loss: 930.5820922851562, Neurons: 11, Grad norm: 1.925e+01\n",
      "Epoch 4889, Loss: 930.57177734375, Neurons: 11, Grad norm: 2.612e+01\n",
      "Epoch 4890, Loss: 930.5614624023438, Neurons: 11, Grad norm: 3.607e+01\n",
      "Epoch 4891, Loss: 930.5513916015625, Neurons: 11, Grad norm: 4.733e+01\n",
      "Epoch 4892, Loss: 930.5416870117188, Neurons: 11, Grad norm: 5.966e+01\n",
      "Epoch 4893, Loss: 930.5322875976562, Neurons: 11, Grad norm: 6.657e+01\n",
      "Epoch 4894, Loss: 930.5225830078125, Neurons: 11, Grad norm: 6.284e+01\n",
      "Epoch 4895, Loss: 930.5115966796875, Neurons: 11, Grad norm: 4.203e+01\n",
      "Epoch 4896, Loss: 930.4992065429688, Neurons: 11, Grad norm: 1.055e+01\n",
      "Epoch 4897, Loss: 930.487060546875, Neurons: 11, Grad norm: 2.259e+01\n",
      "Epoch 4898, Loss: 930.4768676757812, Neurons: 11, Grad norm: 4.338e+01\n",
      "Epoch 4899, Loss: 930.4676513671875, Neurons: 11, Grad norm: 4.631e+01\n",
      "Epoch 4899, Test loss: 941.2255249023438\n",
      "Epoch 4900, Loss: 930.4573974609375, Neurons: 11, Grad norm: 2.888e+01\n",
      "Epoch 4901, Loss: 930.4456787109375, Neurons: 11, Grad norm: 1.758e+00\n",
      "Epoch 4902, Loss: 930.4345703125, Neurons: 11, Grad norm: 2.533e+01\n",
      "Epoch 4903, Loss: 930.424560546875, Neurons: 11, Grad norm: 3.662e+01\n",
      "Epoch 4904, Loss: 930.4146728515625, Neurons: 11, Grad norm: 3.020e+01\n",
      "Epoch 4905, Loss: 930.4038696289062, Neurons: 11, Grad norm: 8.869e+00\n",
      "Epoch 4906, Loss: 930.3927001953125, Neurons: 11, Grad norm: 1.420e+01\n",
      "Epoch 4907, Loss: 930.3822021484375, Neurons: 11, Grad norm: 2.850e+01\n",
      "Epoch 4908, Loss: 930.3723754882812, Neurons: 11, Grad norm: 2.620e+01\n",
      "Epoch 4909, Loss: 930.3617553710938, Neurons: 11, Grad norm: 1.141e+01\n",
      "Epoch 4910, Loss: 930.3507690429688, Neurons: 11, Grad norm: 8.792e+00\n",
      "Epoch 4911, Loss: 930.3403930664062, Neurons: 11, Grad norm: 2.153e+01\n",
      "Epoch 4912, Loss: 930.3302001953125, Neurons: 11, Grad norm: 2.251e+01\n",
      "Epoch 4913, Loss: 930.3197631835938, Neurons: 11, Grad norm: 1.088e+01\n",
      "Epoch 4914, Loss: 930.30908203125, Neurons: 11, Grad norm: 4.965e+00\n",
      "Epoch 4915, Loss: 930.298583984375, Neurons: 11, Grad norm: 1.704e+01\n",
      "Epoch 4916, Loss: 930.2882690429688, Neurons: 11, Grad norm: 1.831e+01\n",
      "Epoch 4917, Loss: 930.2779541015625, Neurons: 11, Grad norm: 1.058e+01\n",
      "Epoch 4918, Loss: 930.2672729492188, Neurons: 11, Grad norm: 3.216e+00\n",
      "Epoch 4919, Loss: 930.2567749023438, Neurons: 11, Grad norm: 1.272e+01\n",
      "Epoch 4920, Loss: 930.24658203125, Neurons: 11, Grad norm: 1.555e+01\n",
      "Epoch 4921, Loss: 930.2362060546875, Neurons: 11, Grad norm: 9.274e+00\n",
      "Epoch 4922, Loss: 930.2257690429688, Neurons: 11, Grad norm: 1.610e+00\n",
      "Epoch 4923, Loss: 930.2151489257812, Neurons: 11, Grad norm: 9.999e+00\n",
      "Epoch 4924, Loss: 930.2049560546875, Neurons: 11, Grad norm: 1.238e+01\n",
      "Epoch 4925, Loss: 930.194580078125, Neurons: 11, Grad norm: 8.899e+00\n",
      "Epoch 4926, Loss: 930.1842041015625, Neurons: 11, Grad norm: 1.487e+00\n",
      "Epoch 4927, Loss: 930.1737670898438, Neurons: 11, Grad norm: 6.919e+00\n",
      "Epoch 4928, Loss: 930.1633911132812, Neurons: 11, Grad norm: 1.048e+01\n",
      "Epoch 4929, Loss: 930.1531982421875, Neurons: 11, Grad norm: 7.716e+00\n",
      "Epoch 4930, Loss: 930.1427612304688, Neurons: 11, Grad norm: 2.390e+00\n",
      "Epoch 4931, Loss: 930.1323852539062, Neurons: 11, Grad norm: 5.112e+00\n",
      "Epoch 4932, Loss: 930.1219482421875, Neurons: 11, Grad norm: 7.978e+00\n",
      "Epoch 4933, Loss: 930.1116943359375, Neurons: 11, Grad norm: 7.408e+00\n",
      "Epoch 4934, Loss: 930.1013793945312, Neurons: 11, Grad norm: 2.794e+00\n",
      "Epoch 4935, Loss: 930.0910034179688, Neurons: 11, Grad norm: 2.866e+00\n",
      "Epoch 4936, Loss: 930.0806884765625, Neurons: 11, Grad norm: 6.529e+00\n",
      "Epoch 4937, Loss: 930.0703735351562, Neurons: 11, Grad norm: 6.181e+00\n",
      "Epoch 4938, Loss: 930.0599975585938, Neurons: 11, Grad norm: 3.780e+00\n",
      "Epoch 4939, Loss: 930.0498046875, Neurons: 11, Grad norm: 1.886e+00\n",
      "Epoch 4940, Loss: 930.0393676757812, Neurons: 11, Grad norm: 4.380e+00\n",
      "Epoch 4941, Loss: 930.029052734375, Neurons: 11, Grad norm: 5.695e+00\n",
      "Epoch 4942, Loss: 930.018798828125, Neurons: 11, Grad norm: 3.702e+00\n",
      "Epoch 4943, Loss: 930.0084838867188, Neurons: 11, Grad norm: 1.572e+00\n",
      "Epoch 4944, Loss: 929.9981689453125, Neurons: 11, Grad norm: 3.246e+00\n",
      "Epoch 4945, Loss: 929.9879760742188, Neurons: 11, Grad norm: 4.254e+00\n",
      "Epoch 4946, Loss: 929.977783203125, Neurons: 11, Grad norm: 4.128e+00\n",
      "Epoch 4947, Loss: 929.9673461914062, Neurons: 11, Grad norm: 1.898e+00\n",
      "Epoch 4948, Loss: 929.9571533203125, Neurons: 11, Grad norm: 1.737e+00\n",
      "Epoch 4949, Loss: 929.9468994140625, Neurons: 11, Grad norm: 3.554e+00\n",
      "Epoch 4949, Test loss: 940.6860961914062\n",
      "Epoch 4950, Loss: 929.9365844726562, Neurons: 11, Grad norm: 3.431e+00\n",
      "Epoch 4951, Loss: 929.9263916015625, Neurons: 11, Grad norm: 2.734e+00\n",
      "Epoch 4952, Loss: 929.9161987304688, Neurons: 11, Grad norm: 1.446e+00\n",
      "Epoch 4953, Loss: 929.9058837890625, Neurons: 11, Grad norm: 2.134e+00\n",
      "Epoch 4954, Loss: 929.8955688476562, Neurons: 11, Grad norm: 3.243e+00\n",
      "Epoch 4955, Loss: 929.8853759765625, Neurons: 11, Grad norm: 2.563e+00\n",
      "Epoch 4956, Loss: 929.8751831054688, Neurons: 11, Grad norm: 1.894e+00\n",
      "Epoch 4957, Loss: 929.864990234375, Neurons: 11, Grad norm: 1.655e+00\n",
      "Epoch 4958, Loss: 929.8547973632812, Neurons: 11, Grad norm: 2.147e+00\n",
      "Epoch 4959, Loss: 929.8446044921875, Neurons: 11, Grad norm: 2.759e+00\n",
      "Epoch 4960, Loss: 929.8343505859375, Neurons: 11, Grad norm: 1.958e+00\n",
      "Epoch 4961, Loss: 929.8241577148438, Neurons: 11, Grad norm: 1.550e+00\n",
      "Epoch 4962, Loss: 929.81396484375, Neurons: 11, Grad norm: 1.773e+00\n",
      "Epoch 4963, Loss: 929.8037719726562, Neurons: 11, Grad norm: 1.982e+00\n",
      "Epoch 4964, Loss: 929.7935791015625, Neurons: 11, Grad norm: 2.330e+00\n",
      "Epoch 4965, Loss: 929.7833862304688, Neurons: 11, Grad norm: 1.638e+00\n",
      "Epoch 4966, Loss: 929.773193359375, Neurons: 11, Grad norm: 1.456e+00\n",
      "Epoch 4967, Loss: 929.7630004882812, Neurons: 11, Grad norm: 1.762e+00\n",
      "Epoch 4968, Loss: 929.7528686523438, Neurons: 11, Grad norm: 1.791e+00\n",
      "Epoch 4969, Loss: 929.7427978515625, Neurons: 11, Grad norm: 2.027e+00\n",
      "Epoch 4970, Loss: 929.7326049804688, Neurons: 11, Grad norm: 1.507e+00\n",
      "Epoch 4971, Loss: 929.7223510742188, Neurons: 11, Grad norm: 1.436e+00\n",
      "Epoch 4972, Loss: 929.7122802734375, Neurons: 11, Grad norm: 1.687e+00\n",
      "Epoch 4973, Loss: 929.7020874023438, Neurons: 11, Grad norm: 1.642e+00\n",
      "Epoch 4974, Loss: 929.6919555664062, Neurons: 11, Grad norm: 1.840e+00\n",
      "Epoch 4975, Loss: 929.6817626953125, Neurons: 11, Grad norm: 1.461e+00\n",
      "Epoch 4976, Loss: 929.6716918945312, Neurons: 11, Grad norm: 1.435e+00\n",
      "Epoch 4977, Loss: 929.6615600585938, Neurons: 11, Grad norm: 1.599e+00\n",
      "Epoch 4978, Loss: 929.6514892578125, Neurons: 11, Grad norm: 1.533e+00\n",
      "Epoch 4979, Loss: 929.641357421875, Neurons: 11, Grad norm: 1.718e+00\n",
      "Epoch 4980, Loss: 929.6312866210938, Neurons: 11, Grad norm: 1.443e+00\n",
      "Epoch 4981, Loss: 929.6211547851562, Neurons: 11, Grad norm: 1.442e+00\n",
      "Epoch 4982, Loss: 929.611083984375, Neurons: 11, Grad norm: 1.524e+00\n",
      "Epoch 4983, Loss: 929.6009521484375, Neurons: 11, Grad norm: 1.467e+00\n",
      "Epoch 4984, Loss: 929.5908813476562, Neurons: 11, Grad norm: 1.637e+00\n",
      "Epoch 4985, Loss: 929.5807495117188, Neurons: 11, Grad norm: 1.433e+00\n",
      "Epoch 4986, Loss: 929.5706787109375, Neurons: 11, Grad norm: 1.454e+00\n",
      "Epoch 4987, Loss: 929.560546875, Neurons: 11, Grad norm: 2.385e+00\n",
      "Epoch 4988, Loss: 929.5505981445312, Neurons: 11, Grad norm: 1.426e+00\n",
      "Epoch 4989, Loss: 929.5404663085938, Neurons: 11, Grad norm: 1.560e+00\n",
      "Epoch 4990, Loss: 929.5303955078125, Neurons: 11, Grad norm: 1.422e+00\n",
      "Epoch 4991, Loss: 929.5203857421875, Neurons: 11, Grad norm: 1.465e+00\n",
      "Epoch 4992, Loss: 929.51025390625, Neurons: 11, Grad norm: 1.436e+00\n",
      "Epoch 4993, Loss: 929.5003051757812, Neurons: 11, Grad norm: 1.413e+00\n",
      "Epoch 4994, Loss: 929.4901733398438, Neurons: 11, Grad norm: 1.515e+00\n",
      "Epoch 4995, Loss: 929.4801635742188, Neurons: 11, Grad norm: 1.417e+00\n",
      "Epoch 4996, Loss: 929.4700927734375, Neurons: 11, Grad norm: 1.476e+00\n",
      "Epoch 4997, Loss: 929.460205078125, Neurons: 11, Grad norm: 1.419e+00\n",
      "Epoch 4998, Loss: 929.4500732421875, Neurons: 11, Grad norm: 1.415e+00\n",
      "Epoch 4999, Loss: 929.4400024414062, Neurons: 11, Grad norm: 1.473e+00\n",
      "Epoch 4999, Test loss: 940.1431884765625\n",
      "Epoch 5000, Loss: 929.4299926757812, Neurons: 11, Grad norm: 1.411e+00\n",
      "Epoch 5001, Loss: 929.4199829101562, Neurons: 11, Grad norm: 1.480e+00\n",
      "Epoch 5002, Loss: 929.4099731445312, Neurons: 11, Grad norm: 1.408e+00\n",
      "Epoch 5003, Loss: 929.3999633789062, Neurons: 11, Grad norm: 1.429e+00\n",
      "Epoch 5004, Loss: 929.3900756835938, Neurons: 11, Grad norm: 1.433e+00\n",
      "Epoch 5005, Loss: 929.3800048828125, Neurons: 11, Grad norm: 1.406e+00\n",
      "Epoch 5006, Loss: 929.3699951171875, Neurons: 11, Grad norm: 1.459e+00\n",
      "Epoch 5007, Loss: 929.3599853515625, Neurons: 11, Grad norm: 1.403e+00\n",
      "Epoch 5008, Loss: 929.35009765625, Neurons: 11, Grad norm: 1.440e+00\n",
      "Epoch 5009, Loss: 929.3401489257812, Neurons: 11, Grad norm: 1.410e+00\n",
      "Epoch 5010, Loss: 929.3302001953125, Neurons: 11, Grad norm: 1.411e+00\n",
      "Epoch 5011, Loss: 929.3201904296875, Neurons: 11, Grad norm: 1.432e+00\n",
      "Epoch 5012, Loss: 929.3101806640625, Neurons: 11, Grad norm: 1.400e+00\n",
      "Epoch 5013, Loss: 929.30029296875, Neurons: 11, Grad norm: 1.440e+00\n",
      "Epoch 5014, Loss: 929.2904052734375, Neurons: 11, Grad norm: 1.399e+00\n",
      "Epoch 5015, Loss: 929.2803955078125, Neurons: 11, Grad norm: 1.423e+00\n",
      "Epoch 5016, Loss: 929.2703857421875, Neurons: 11, Grad norm: 1.408e+00\n",
      "Epoch 5017, Loss: 929.260498046875, Neurons: 11, Grad norm: 1.403e+00\n",
      "Epoch 5018, Loss: 929.2505493164062, Neurons: 11, Grad norm: 1.424e+00\n",
      "Epoch 5019, Loss: 929.2406005859375, Neurons: 11, Grad norm: 1.396e+00\n",
      "Epoch 5020, Loss: 929.2307739257812, Neurons: 11, Grad norm: 1.427e+00\n",
      "Epoch 5021, Loss: 929.2207641601562, Neurons: 11, Grad norm: 1.396e+00\n",
      "Epoch 5022, Loss: 929.2108764648438, Neurons: 11, Grad norm: 1.415e+00\n",
      "Epoch 5023, Loss: 929.2009887695312, Neurons: 11, Grad norm: 1.403e+00\n",
      "Epoch 5024, Loss: 929.1911010742188, Neurons: 11, Grad norm: 1.401e+00\n",
      "Epoch 5025, Loss: 929.18115234375, Neurons: 11, Grad norm: 1.413e+00\n",
      "Epoch 5026, Loss: 929.17138671875, Neurons: 11, Grad norm: 1.394e+00\n",
      "Epoch 5027, Loss: 929.161376953125, Neurons: 11, Grad norm: 1.415e+00\n",
      "Epoch 5028, Loss: 929.1515502929688, Neurons: 11, Grad norm: 1.393e+00\n",
      "Epoch 5029, Loss: 929.1416015625, Neurons: 11, Grad norm: 1.408e+00\n",
      "Epoch 5030, Loss: 929.1317749023438, Neurons: 11, Grad norm: 1.397e+00\n",
      "Epoch 5031, Loss: 929.1218872070312, Neurons: 11, Grad norm: 1.398e+00\n",
      "Epoch 5032, Loss: 929.1119995117188, Neurons: 11, Grad norm: 1.403e+00\n",
      "Epoch 5033, Loss: 929.1021728515625, Neurons: 11, Grad norm: 1.393e+00\n",
      "Epoch 5034, Loss: 929.0923461914062, Neurons: 11, Grad norm: 1.405e+00\n",
      "Epoch 5035, Loss: 929.0824584960938, Neurons: 11, Grad norm: 1.391e+00\n",
      "Epoch 5036, Loss: 929.0725708007812, Neurons: 11, Grad norm: 1.403e+00\n",
      "Epoch 5037, Loss: 929.0628051757812, Neurons: 11, Grad norm: 1.391e+00\n",
      "Epoch 5038, Loss: 929.0528564453125, Neurons: 11, Grad norm: 1.398e+00\n",
      "Epoch 5039, Loss: 929.0431518554688, Neurons: 11, Grad norm: 1.393e+00\n",
      "Epoch 5040, Loss: 929.0332641601562, Neurons: 11, Grad norm: 1.393e+00\n",
      "Epoch 5041, Loss: 929.0234985351562, Neurons: 11, Grad norm: 1.394e+00\n",
      "Epoch 5042, Loss: 929.0135498046875, Neurons: 11, Grad norm: 1.389e+00\n",
      "Epoch 5043, Loss: 929.0037841796875, Neurons: 11, Grad norm: 1.395e+00\n",
      "Epoch 5044, Loss: 928.9940795898438, Neurons: 11, Grad norm: 1.387e+00\n",
      "Epoch 5045, Loss: 928.9841918945312, Neurons: 11, Grad norm: 1.393e+00\n",
      "Epoch 5046, Loss: 928.974365234375, Neurons: 11, Grad norm: 1.386e+00\n",
      "Epoch 5047, Loss: 928.964599609375, Neurons: 11, Grad norm: 1.391e+00\n",
      "Epoch 5048, Loss: 928.9548950195312, Neurons: 11, Grad norm: 1.386e+00\n",
      "Epoch 5049, Loss: 928.945068359375, Neurons: 11, Grad norm: 1.388e+00\n",
      "Epoch 5049, Test loss: 939.611572265625\n",
      "Epoch 5050, Loss: 928.935302734375, Neurons: 11, Grad norm: 1.387e+00\n",
      "Epoch 5051, Loss: 928.9255981445312, Neurons: 11, Grad norm: 1.384e+00\n",
      "Epoch 5052, Loss: 928.9156494140625, Neurons: 11, Grad norm: 1.388e+00\n",
      "Epoch 5053, Loss: 928.906005859375, Neurons: 11, Grad norm: 1.381e+00\n",
      "Epoch 5054, Loss: 928.8961791992188, Neurons: 11, Grad norm: 1.387e+00\n",
      "Epoch 5055, Loss: 928.8863525390625, Neurons: 11, Grad norm: 1.379e+00\n",
      "Epoch 5056, Loss: 928.8766479492188, Neurons: 11, Grad norm: 1.386e+00\n",
      "Epoch 5057, Loss: 928.8668823242188, Neurons: 11, Grad norm: 1.378e+00\n",
      "Epoch 5058, Loss: 928.857177734375, Neurons: 11, Grad norm: 1.384e+00\n",
      "Epoch 5059, Loss: 928.8473510742188, Neurons: 11, Grad norm: 1.377e+00\n",
      "Epoch 5060, Loss: 928.8375854492188, Neurons: 11, Grad norm: 1.381e+00\n",
      "Epoch 5061, Loss: 928.8280029296875, Neurons: 11, Grad norm: 1.378e+00\n",
      "Epoch 5062, Loss: 928.8182983398438, Neurons: 11, Grad norm: 1.378e+00\n",
      "Epoch 5063, Loss: 928.8084716796875, Neurons: 11, Grad norm: 1.378e+00\n",
      "Epoch 5064, Loss: 928.7987670898438, Neurons: 11, Grad norm: 1.375e+00\n",
      "Epoch 5065, Loss: 928.7890625, Neurons: 11, Grad norm: 1.378e+00\n",
      "Epoch 5066, Loss: 928.7793579101562, Neurons: 11, Grad norm: 1.373e+00\n",
      "Epoch 5067, Loss: 928.7696533203125, Neurons: 11, Grad norm: 1.377e+00\n",
      "Epoch 5068, Loss: 928.7599487304688, Neurons: 11, Grad norm: 1.371e+00\n",
      "Epoch 5069, Loss: 928.7503051757812, Neurons: 11, Grad norm: 1.378e+00\n",
      "Epoch 5070, Loss: 928.7406005859375, Neurons: 11, Grad norm: 1.368e+00\n",
      "Epoch 5071, Loss: 928.7308959960938, Neurons: 11, Grad norm: 1.378e+00\n",
      "Epoch 5072, Loss: 928.72119140625, Neurons: 11, Grad norm: 1.366e+00\n",
      "Epoch 5073, Loss: 928.7115478515625, Neurons: 11, Grad norm: 1.377e+00\n",
      "Epoch 5074, Loss: 928.7017822265625, Neurons: 11, Grad norm: 1.365e+00\n",
      "Epoch 5075, Loss: 928.6921997070312, Neurons: 11, Grad norm: 1.376e+00\n",
      "Epoch 5076, Loss: 928.6825561523438, Neurons: 11, Grad norm: 1.362e+00\n",
      "Epoch 5077, Loss: 928.6727905273438, Neurons: 11, Grad norm: 1.377e+00\n",
      "Epoch 5078, Loss: 928.6632690429688, Neurons: 11, Grad norm: 1.360e+00\n",
      "Epoch 5079, Loss: 928.653564453125, Neurons: 11, Grad norm: 1.377e+00\n",
      "Epoch 5080, Loss: 928.6439819335938, Neurons: 11, Grad norm: 1.358e+00\n",
      "Epoch 5081, Loss: 928.63427734375, Neurons: 11, Grad norm: 1.379e+00\n",
      "Epoch 5082, Loss: 928.6246948242188, Neurons: 11, Grad norm: 1.354e+00\n",
      "Epoch 5083, Loss: 928.614990234375, Neurons: 11, Grad norm: 1.383e+00\n",
      "Epoch 5084, Loss: 928.6053466796875, Neurons: 11, Grad norm: 1.351e+00\n",
      "Epoch 5085, Loss: 928.5957641601562, Neurons: 11, Grad norm: 1.393e+00\n",
      "Epoch 5086, Loss: 928.586181640625, Neurons: 11, Grad norm: 1.348e+00\n",
      "Epoch 5087, Loss: 928.5765991210938, Neurons: 11, Grad norm: 1.410e+00\n",
      "Epoch 5088, Loss: 928.56689453125, Neurons: 11, Grad norm: 1.349e+00\n",
      "Epoch 5089, Loss: 928.5572509765625, Neurons: 11, Grad norm: 1.445e+00\n",
      "Epoch 5090, Loss: 928.5476684570312, Neurons: 11, Grad norm: 1.364e+00\n",
      "Epoch 5091, Loss: 928.5380859375, Neurons: 11, Grad norm: 1.518e+00\n",
      "Epoch 5092, Loss: 928.528564453125, Neurons: 11, Grad norm: 1.418e+00\n",
      "Epoch 5093, Loss: 928.5188598632812, Neurons: 11, Grad norm: 1.676e+00\n",
      "Epoch 5094, Loss: 928.5093994140625, Neurons: 11, Grad norm: 1.586e+00\n",
      "Epoch 5095, Loss: 928.499755859375, Neurons: 11, Grad norm: 2.031e+00\n",
      "Epoch 5096, Loss: 928.4901733398438, Neurons: 11, Grad norm: 2.041e+00\n",
      "Epoch 5097, Loss: 928.4805908203125, Neurons: 11, Grad norm: 2.790e+00\n",
      "Epoch 5098, Loss: 928.4710693359375, Neurons: 11, Grad norm: 3.079e+00\n",
      "Epoch 5099, Loss: 928.4615478515625, Neurons: 11, Grad norm: 4.321e+00\n",
      "Epoch 5099, Test loss: 939.0903930664062\n",
      "Epoch 5100, Loss: 928.4519653320312, Neurons: 11, Grad norm: 5.199e+00\n",
      "Epoch 5101, Loss: 928.4423828125, Neurons: 11, Grad norm: 7.293e+00\n",
      "Epoch 5102, Loss: 928.4328002929688, Neurons: 11, Grad norm: 9.298e+00\n",
      "Epoch 5103, Loss: 928.4234008789062, Neurons: 11, Grad norm: 1.295e+01\n",
      "Epoch 5104, Loss: 928.4138793945312, Neurons: 11, Grad norm: 1.704e+01\n",
      "Epoch 5105, Loss: 928.4044799804688, Neurons: 11, Grad norm: 2.349e+01\n",
      "Epoch 5106, Loss: 928.3950805664062, Neurons: 11, Grad norm: 3.112e+01\n",
      "Epoch 5107, Loss: 928.385986328125, Neurons: 11, Grad norm: 4.167e+01\n",
      "Epoch 5108, Loss: 928.376953125, Neurons: 11, Grad norm: 5.292e+01\n",
      "Epoch 5109, Loss: 928.3683471679688, Neurons: 11, Grad norm: 6.426e+01\n",
      "Epoch 5110, Loss: 928.35986328125, Neurons: 11, Grad norm: 6.905e+01\n",
      "Epoch 5111, Loss: 928.3509521484375, Neurons: 11, Grad norm: 6.306e+01\n",
      "Epoch 5112, Loss: 928.3407592773438, Neurons: 11, Grad norm: 4.130e+01\n",
      "Epoch 5113, Loss: 928.3294677734375, Neurons: 11, Grad norm: 1.048e+01\n",
      "Epoch 5114, Loss: 928.3187866210938, Neurons: 11, Grad norm: 2.160e+01\n",
      "Epoch 5115, Loss: 928.3095703125, Neurons: 11, Grad norm: 4.270e+01\n",
      "Epoch 5116, Loss: 928.3010864257812, Neurons: 11, Grad norm: 4.813e+01\n",
      "Epoch 5117, Loss: 928.2919921875, Neurons: 11, Grad norm: 3.468e+01\n",
      "Epoch 5118, Loss: 928.2816772460938, Neurons: 11, Grad norm: 9.731e+00\n",
      "Epoch 5119, Loss: 928.2713623046875, Neurons: 11, Grad norm: 1.753e+01\n",
      "Epoch 5120, Loss: 928.261962890625, Neurons: 11, Grad norm: 3.413e+01\n",
      "Epoch 5121, Loss: 928.253173828125, Neurons: 11, Grad norm: 3.582e+01\n",
      "Epoch 5122, Loss: 928.243896484375, Neurons: 11, Grad norm: 2.121e+01\n",
      "Epoch 5123, Loss: 928.2337646484375, Neurons: 11, Grad norm: 1.406e+00\n",
      "Epoch 5124, Loss: 928.2239990234375, Neurons: 11, Grad norm: 2.061e+01\n",
      "Epoch 5125, Loss: 928.2149047851562, Neurons: 11, Grad norm: 2.885e+01\n",
      "Epoch 5126, Loss: 928.2057495117188, Neurons: 11, Grad norm: 2.415e+01\n",
      "Epoch 5127, Loss: 928.1961669921875, Neurons: 11, Grad norm: 8.304e+00\n",
      "Epoch 5128, Loss: 928.1864013671875, Neurons: 11, Grad norm: 9.286e+00\n",
      "Epoch 5129, Loss: 928.1768798828125, Neurons: 11, Grad norm: 2.143e+01\n",
      "Epoch 5130, Loss: 928.1677856445312, Neurons: 11, Grad norm: 2.192e+01\n",
      "Epoch 5131, Loss: 928.1583862304688, Neurons: 11, Grad norm: 1.309e+01\n",
      "Epoch 5132, Loss: 928.1488037109375, Neurons: 11, Grad norm: 2.194e+00\n",
      "Epoch 5133, Loss: 928.13916015625, Neurons: 11, Grad norm: 1.354e+01\n",
      "Epoch 5134, Loss: 928.1300048828125, Neurons: 11, Grad norm: 1.869e+01\n",
      "Epoch 5135, Loss: 928.1206665039062, Neurons: 11, Grad norm: 1.404e+01\n",
      "Epoch 5136, Loss: 928.1112060546875, Neurons: 11, Grad norm: 4.298e+00\n",
      "Epoch 5137, Loss: 928.1016845703125, Neurons: 11, Grad norm: 7.534e+00\n",
      "Epoch 5138, Loss: 928.09228515625, Neurons: 11, Grad norm: 1.376e+01\n",
      "Epoch 5139, Loss: 928.0829467773438, Neurons: 11, Grad norm: 1.392e+01\n",
      "Epoch 5140, Loss: 928.0735473632812, Neurons: 11, Grad norm: 7.111e+00\n",
      "Epoch 5141, Loss: 928.0641479492188, Neurons: 11, Grad norm: 2.081e+00\n",
      "Epoch 5142, Loss: 928.0547485351562, Neurons: 11, Grad norm: 9.495e+00\n",
      "Epoch 5143, Loss: 928.0453491210938, Neurons: 11, Grad norm: 1.153e+01\n",
      "Epoch 5144, Loss: 928.0361938476562, Neurons: 11, Grad norm: 9.074e+00\n",
      "Epoch 5145, Loss: 928.0267944335938, Neurons: 11, Grad norm: 2.401e+00\n",
      "Epoch 5146, Loss: 928.0172729492188, Neurons: 11, Grad norm: 4.598e+00\n",
      "Epoch 5147, Loss: 928.0079956054688, Neurons: 11, Grad norm: 9.095e+00\n",
      "Epoch 5148, Loss: 927.998779296875, Neurons: 11, Grad norm: 8.600e+00\n",
      "Epoch 5149, Loss: 927.9893798828125, Neurons: 11, Grad norm: 5.272e+00\n",
      "Epoch 5149, Test loss: 938.5826416015625\n",
      "Epoch 5150, Loss: 927.97998046875, Neurons: 11, Grad norm: 1.577e+00\n",
      "Epoch 5151, Loss: 927.9705810546875, Neurons: 11, Grad norm: 5.315e+00\n",
      "Epoch 5152, Loss: 927.9613037109375, Neurons: 11, Grad norm: 7.689e+00\n",
      "Epoch 5153, Loss: 927.9519653320312, Neurons: 11, Grad norm: 5.960e+00\n",
      "Epoch 5154, Loss: 927.9426879882812, Neurons: 11, Grad norm: 2.876e+00\n",
      "Epoch 5155, Loss: 927.933349609375, Neurons: 11, Grad norm: 2.548e+00\n",
      "Epoch 5156, Loss: 927.924072265625, Neurons: 11, Grad norm: 4.995e+00\n",
      "Epoch 5157, Loss: 927.914794921875, Neurons: 11, Grad norm: 6.110e+00\n",
      "Epoch 5158, Loss: 927.9055786132812, Neurons: 11, Grad norm: 4.062e+00\n",
      "Epoch 5159, Loss: 927.8961791992188, Neurons: 11, Grad norm: 1.721e+00\n",
      "Epoch 5160, Loss: 927.8867797851562, Neurons: 11, Grad norm: 2.835e+00\n",
      "Epoch 5161, Loss: 927.8775634765625, Neurons: 11, Grad norm: 4.263e+00\n",
      "Epoch 5162, Loss: 927.8683471679688, Neurons: 11, Grad norm: 4.789e+00\n",
      "Epoch 5163, Loss: 927.8590698242188, Neurons: 11, Grad norm: 2.868e+00\n",
      "Epoch 5164, Loss: 927.8497924804688, Neurons: 11, Grad norm: 1.385e+00\n",
      "Epoch 5165, Loss: 927.840576171875, Neurons: 11, Grad norm: 2.669e+00\n",
      "Epoch 5166, Loss: 927.8311767578125, Neurons: 11, Grad norm: 3.480e+00\n",
      "Epoch 5167, Loss: 927.8219604492188, Neurons: 11, Grad norm: 3.799e+00\n",
      "Epoch 5168, Loss: 927.8126831054688, Neurons: 11, Grad norm: 2.225e+00\n",
      "Epoch 5169, Loss: 927.803466796875, Neurons: 11, Grad norm: 1.329e+00\n",
      "Epoch 5170, Loss: 927.794189453125, Neurons: 11, Grad norm: 2.320e+00\n",
      "Epoch 5171, Loss: 927.7849731445312, Neurons: 11, Grad norm: 2.798e+00\n",
      "Epoch 5172, Loss: 927.7757568359375, Neurons: 11, Grad norm: 3.123e+00\n",
      "Epoch 5173, Loss: 927.7666015625, Neurons: 11, Grad norm: 1.911e+00\n",
      "Epoch 5174, Loss: 927.7573852539062, Neurons: 11, Grad norm: 1.346e+00\n",
      "Epoch 5175, Loss: 927.7479858398438, Neurons: 11, Grad norm: 1.937e+00\n",
      "Epoch 5176, Loss: 927.73876953125, Neurons: 11, Grad norm: 2.240e+00\n",
      "Epoch 5177, Loss: 927.7295532226562, Neurons: 11, Grad norm: 2.641e+00\n",
      "Epoch 5178, Loss: 927.720458984375, Neurons: 11, Grad norm: 1.766e+00\n",
      "Epoch 5179, Loss: 927.7113037109375, Neurons: 11, Grad norm: 1.406e+00\n",
      "Epoch 5180, Loss: 927.7019653320312, Neurons: 11, Grad norm: 1.606e+00\n",
      "Epoch 5181, Loss: 927.6927490234375, Neurons: 11, Grad norm: 1.802e+00\n",
      "Epoch 5182, Loss: 927.68359375, Neurons: 11, Grad norm: 2.276e+00\n",
      "Epoch 5183, Loss: 927.6744995117188, Neurons: 11, Grad norm: 1.678e+00\n",
      "Epoch 5184, Loss: 927.6651611328125, Neurons: 11, Grad norm: 1.497e+00\n",
      "Epoch 5185, Loss: 927.6560668945312, Neurons: 11, Grad norm: 1.384e+00\n",
      "Epoch 5186, Loss: 927.6467895507812, Neurons: 11, Grad norm: 1.488e+00\n",
      "Epoch 5187, Loss: 927.6377563476562, Neurons: 11, Grad norm: 1.968e+00\n",
      "Epoch 5188, Loss: 927.6286010742188, Neurons: 11, Grad norm: 1.603e+00\n",
      "Epoch 5189, Loss: 927.619384765625, Neurons: 11, Grad norm: 1.593e+00\n",
      "Epoch 5190, Loss: 927.6101684570312, Neurons: 11, Grad norm: 1.288e+00\n",
      "Epoch 5191, Loss: 927.60107421875, Neurons: 11, Grad norm: 1.309e+00\n",
      "Epoch 5192, Loss: 927.5918579101562, Neurons: 11, Grad norm: 1.674e+00\n",
      "Epoch 5193, Loss: 927.582763671875, Neurons: 11, Grad norm: 1.487e+00\n",
      "Epoch 5194, Loss: 927.5735473632812, Neurons: 11, Grad norm: 1.628e+00\n",
      "Epoch 5195, Loss: 927.564453125, Neurons: 11, Grad norm: 1.296e+00\n",
      "Epoch 5196, Loss: 927.5552978515625, Neurons: 11, Grad norm: 1.292e+00\n",
      "Epoch 5197, Loss: 927.5462036132812, Neurons: 11, Grad norm: 1.433e+00\n",
      "Epoch 5198, Loss: 927.5369873046875, Neurons: 11, Grad norm: 1.362e+00\n",
      "Epoch 5199, Loss: 927.5279541015625, Neurons: 11, Grad norm: 1.585e+00\n",
      "Epoch 5199, Test loss: 938.0885620117188\n",
      "Epoch 5200, Loss: 927.518798828125, Neurons: 11, Grad norm: 1.328e+00\n",
      "Epoch 5201, Loss: 927.509765625, Neurons: 11, Grad norm: 1.374e+00\n",
      "Epoch 5202, Loss: 927.5005493164062, Neurons: 11, Grad norm: 1.300e+00\n",
      "Epoch 5203, Loss: 927.491455078125, Neurons: 11, Grad norm: 1.280e+00\n",
      "Epoch 5204, Loss: 927.4823608398438, Neurons: 11, Grad norm: 1.462e+00\n",
      "Epoch 5205, Loss: 927.4732666015625, Neurons: 11, Grad norm: 1.318e+00\n",
      "Epoch 5206, Loss: 927.4641723632812, Neurons: 11, Grad norm: 1.439e+00\n",
      "Epoch 5207, Loss: 927.455078125, Neurons: 11, Grad norm: 1.275e+00\n",
      "Epoch 5208, Loss: 927.4459838867188, Neurons: 11, Grad norm: 1.297e+00\n",
      "Epoch 5209, Loss: 927.4369506835938, Neurons: 11, Grad norm: 1.330e+00\n",
      "Epoch 5210, Loss: 927.4277954101562, Neurons: 11, Grad norm: 1.278e+00\n",
      "Epoch 5211, Loss: 927.4187622070312, Neurons: 11, Grad norm: 1.410e+00\n",
      "Epoch 5212, Loss: 927.40966796875, Neurons: 11, Grad norm: 1.281e+00\n",
      "Epoch 5213, Loss: 927.4005737304688, Neurons: 11, Grad norm: 1.358e+00\n",
      "Epoch 5214, Loss: 927.3916015625, Neurons: 11, Grad norm: 1.272e+00\n",
      "Epoch 5215, Loss: 927.3824462890625, Neurons: 11, Grad norm: 1.280e+00\n",
      "Epoch 5216, Loss: 927.3733520507812, Neurons: 11, Grad norm: 1.325e+00\n",
      "Epoch 5217, Loss: 927.3643798828125, Neurons: 11, Grad norm: 1.268e+00\n",
      "Epoch 5218, Loss: 927.3553466796875, Neurons: 11, Grad norm: 1.361e+00\n",
      "Epoch 5219, Loss: 927.3462524414062, Neurons: 11, Grad norm: 1.267e+00\n",
      "Epoch 5220, Loss: 927.3372802734375, Neurons: 11, Grad norm: 1.324e+00\n",
      "Epoch 5221, Loss: 927.3281860351562, Neurons: 11, Grad norm: 1.271e+00\n",
      "Epoch 5222, Loss: 927.3191528320312, Neurons: 11, Grad norm: 1.277e+00\n",
      "Epoch 5223, Loss: 927.3101806640625, Neurons: 11, Grad norm: 1.305e+00\n",
      "Epoch 5224, Loss: 927.3011474609375, Neurons: 11, Grad norm: 1.263e+00\n",
      "Epoch 5225, Loss: 927.2921752929688, Neurons: 11, Grad norm: 1.330e+00\n",
      "Epoch 5226, Loss: 927.283203125, Neurons: 11, Grad norm: 1.262e+00\n",
      "Epoch 5227, Loss: 927.274169921875, Neurons: 11, Grad norm: 1.311e+00\n",
      "Epoch 5228, Loss: 927.2651977539062, Neurons: 11, Grad norm: 1.267e+00\n",
      "Epoch 5229, Loss: 927.256103515625, Neurons: 11, Grad norm: 1.278e+00\n",
      "Epoch 5230, Loss: 927.2470703125, Neurons: 11, Grad norm: 1.287e+00\n",
      "Epoch 5231, Loss: 927.2380981445312, Neurons: 11, Grad norm: 1.263e+00\n",
      "Epoch 5232, Loss: 927.2290649414062, Neurons: 11, Grad norm: 1.304e+00\n",
      "Epoch 5233, Loss: 927.2200927734375, Neurons: 11, Grad norm: 1.259e+00\n",
      "Epoch 5234, Loss: 927.211181640625, Neurons: 11, Grad norm: 1.302e+00\n",
      "Epoch 5235, Loss: 927.2021484375, Neurons: 11, Grad norm: 1.261e+00\n",
      "Epoch 5236, Loss: 927.1931762695312, Neurons: 11, Grad norm: 1.284e+00\n",
      "Epoch 5237, Loss: 927.1842041015625, Neurons: 11, Grad norm: 1.269e+00\n",
      "Epoch 5238, Loss: 927.1751708984375, Neurons: 11, Grad norm: 1.268e+00\n",
      "Epoch 5239, Loss: 927.1663818359375, Neurons: 11, Grad norm: 1.281e+00\n",
      "Epoch 5240, Loss: 927.1573486328125, Neurons: 11, Grad norm: 1.260e+00\n",
      "Epoch 5241, Loss: 927.1483764648438, Neurons: 11, Grad norm: 1.286e+00\n",
      "Epoch 5242, Loss: 927.1394653320312, Neurons: 11, Grad norm: 1.258e+00\n",
      "Epoch 5243, Loss: 927.1304931640625, Neurons: 11, Grad norm: 1.283e+00\n",
      "Epoch 5244, Loss: 927.12158203125, Neurons: 11, Grad norm: 1.259e+00\n",
      "Epoch 5245, Loss: 927.1126708984375, Neurons: 11, Grad norm: 1.274e+00\n",
      "Epoch 5246, Loss: 927.1036987304688, Neurons: 11, Grad norm: 1.264e+00\n",
      "Epoch 5247, Loss: 927.0947875976562, Neurons: 11, Grad norm: 1.264e+00\n",
      "Epoch 5248, Loss: 927.0857543945312, Neurons: 11, Grad norm: 1.271e+00\n",
      "Epoch 5249, Loss: 927.0769653320312, Neurons: 11, Grad norm: 1.257e+00\n",
      "Epoch 5249, Test loss: 937.6041870117188\n",
      "Epoch 5250, Loss: 927.0679931640625, Neurons: 11, Grad norm: 1.276e+00\n",
      "Epoch 5251, Loss: 927.05908203125, Neurons: 11, Grad norm: 1.253e+00\n",
      "Epoch 5252, Loss: 927.0501708984375, Neurons: 11, Grad norm: 1.277e+00\n",
      "Epoch 5253, Loss: 927.041259765625, Neurons: 11, Grad norm: 1.253e+00\n",
      "Epoch 5254, Loss: 927.0323486328125, Neurons: 11, Grad norm: 1.273e+00\n",
      "Epoch 5255, Loss: 927.0234985351562, Neurons: 11, Grad norm: 1.254e+00\n",
      "Epoch 5256, Loss: 927.0145874023438, Neurons: 11, Grad norm: 1.265e+00\n",
      "Epoch 5257, Loss: 927.0057983398438, Neurons: 11, Grad norm: 1.258e+00\n",
      "Epoch 5258, Loss: 926.9967651367188, Neurons: 11, Grad norm: 1.257e+00\n",
      "Epoch 5259, Loss: 926.9879760742188, Neurons: 11, Grad norm: 1.263e+00\n",
      "Epoch 5260, Loss: 926.97900390625, Neurons: 11, Grad norm: 1.252e+00\n",
      "Epoch 5261, Loss: 926.9701538085938, Neurons: 11, Grad norm: 1.265e+00\n",
      "Epoch 5262, Loss: 926.9613647460938, Neurons: 11, Grad norm: 1.250e+00\n",
      "Epoch 5263, Loss: 926.952392578125, Neurons: 11, Grad norm: 1.264e+00\n",
      "Epoch 5264, Loss: 926.943603515625, Neurons: 11, Grad norm: 1.249e+00\n",
      "Epoch 5265, Loss: 926.9347534179688, Neurons: 11, Grad norm: 2.127e+00\n",
      "Epoch 5266, Loss: 926.9259033203125, Neurons: 11, Grad norm: 1.252e+00\n",
      "Epoch 5267, Loss: 926.9169921875, Neurons: 11, Grad norm: 1.253e+00\n",
      "Epoch 5268, Loss: 926.908203125, Neurons: 11, Grad norm: 1.257e+00\n",
      "Epoch 5269, Loss: 926.8993530273438, Neurons: 11, Grad norm: 1.248e+00\n",
      "Epoch 5270, Loss: 926.8905639648438, Neurons: 11, Grad norm: 1.262e+00\n",
      "Epoch 5271, Loss: 926.881591796875, Neurons: 11, Grad norm: 1.245e+00\n",
      "Epoch 5272, Loss: 926.872802734375, Neurons: 11, Grad norm: 1.265e+00\n",
      "Epoch 5273, Loss: 926.8639526367188, Neurons: 11, Grad norm: 1.243e+00\n",
      "Epoch 5274, Loss: 926.8551635742188, Neurons: 11, Grad norm: 1.267e+00\n",
      "Epoch 5275, Loss: 926.8463745117188, Neurons: 11, Grad norm: 1.241e+00\n",
      "Epoch 5276, Loss: 926.8375854492188, Neurons: 11, Grad norm: 1.268e+00\n",
      "Epoch 5277, Loss: 926.8287963867188, Neurons: 11, Grad norm: 1.239e+00\n",
      "Epoch 5278, Loss: 926.8199462890625, Neurons: 11, Grad norm: 1.269e+00\n",
      "Epoch 5279, Loss: 926.8111572265625, Neurons: 11, Grad norm: 1.237e+00\n",
      "Epoch 5280, Loss: 926.8023681640625, Neurons: 11, Grad norm: 1.271e+00\n",
      "Epoch 5281, Loss: 926.7935791015625, Neurons: 11, Grad norm: 1.234e+00\n",
      "Epoch 5282, Loss: 926.7847900390625, Neurons: 11, Grad norm: 1.276e+00\n",
      "Epoch 5283, Loss: 926.7760009765625, Neurons: 11, Grad norm: 1.231e+00\n",
      "Epoch 5284, Loss: 926.7671508789062, Neurons: 11, Grad norm: 1.288e+00\n",
      "Epoch 5285, Loss: 926.7583618164062, Neurons: 11, Grad norm: 1.229e+00\n",
      "Epoch 5286, Loss: 926.7495727539062, Neurons: 11, Grad norm: 1.314e+00\n",
      "Epoch 5287, Loss: 926.7407836914062, Neurons: 11, Grad norm: 1.234e+00\n",
      "Epoch 5288, Loss: 926.732177734375, Neurons: 11, Grad norm: 1.366e+00\n",
      "Epoch 5289, Loss: 926.723388671875, Neurons: 11, Grad norm: 1.263e+00\n",
      "Epoch 5290, Loss: 926.714599609375, Neurons: 11, Grad norm: 1.476e+00\n",
      "Epoch 5291, Loss: 926.7058715820312, Neurons: 11, Grad norm: 1.360e+00\n",
      "Epoch 5292, Loss: 926.6970825195312, Neurons: 11, Grad norm: 1.716e+00\n",
      "Epoch 5293, Loss: 926.6883544921875, Neurons: 11, Grad norm: 1.645e+00\n",
      "Epoch 5294, Loss: 926.6795654296875, Neurons: 11, Grad norm: 2.238e+00\n",
      "Epoch 5295, Loss: 926.6707763671875, Neurons: 11, Grad norm: 2.340e+00\n",
      "Epoch 5296, Loss: 926.6620483398438, Neurons: 11, Grad norm: 3.303e+00\n",
      "Epoch 5297, Loss: 926.6533813476562, Neurons: 11, Grad norm: 3.797e+00\n",
      "Epoch 5298, Loss: 926.6445922851562, Neurons: 11, Grad norm: 5.367e+00\n",
      "Epoch 5299, Loss: 926.635986328125, Neurons: 11, Grad norm: 6.631e+00\n",
      "Epoch 5299, Test loss: 937.1329345703125\n",
      "Epoch 5300, Loss: 926.627197265625, Neurons: 11, Grad norm: 9.280e+00\n",
      "Epoch 5301, Loss: 926.6185913085938, Neurons: 11, Grad norm: 1.199e+01\n",
      "Epoch 5302, Loss: 926.60986328125, Neurons: 11, Grad norm: 1.663e+01\n",
      "Epoch 5303, Loss: 926.6013793945312, Neurons: 11, Grad norm: 2.202e+01\n",
      "Epoch 5304, Loss: 926.5927734375, Neurons: 11, Grad norm: 3.015e+01\n",
      "Epoch 5305, Loss: 926.5842895507812, Neurons: 11, Grad norm: 3.978e+01\n",
      "Epoch 5306, Loss: 926.5760498046875, Neurons: 11, Grad norm: 5.241e+01\n",
      "Epoch 5307, Loss: 926.5681762695312, Neurons: 11, Grad norm: 6.491e+01\n",
      "Epoch 5308, Loss: 926.560546875, Neurons: 11, Grad norm: 7.522e+01\n",
      "Epoch 5309, Loss: 926.5528564453125, Neurons: 11, Grad norm: 7.501e+01\n",
      "Epoch 5310, Loss: 926.544189453125, Neurons: 11, Grad norm: 6.052e+01\n",
      "Epoch 5311, Loss: 926.5341796875, Neurons: 11, Grad norm: 3.008e+01\n",
      "Epoch 5312, Loss: 926.5235595703125, Neurons: 11, Grad norm: 5.750e+00\n",
      "Epoch 5313, Loss: 926.5142822265625, Neurons: 11, Grad norm: 3.691e+01\n",
      "Epoch 5314, Loss: 926.506591796875, Neurons: 11, Grad norm: 5.237e+01\n",
      "Epoch 5315, Loss: 926.4989624023438, Neurons: 11, Grad norm: 4.887e+01\n",
      "Epoch 5316, Loss: 926.489990234375, Neurons: 11, Grad norm: 2.658e+01\n",
      "Epoch 5317, Loss: 926.4801635742188, Neurons: 11, Grad norm: 3.551e+00\n",
      "Epoch 5318, Loss: 926.4710693359375, Neurons: 11, Grad norm: 2.971e+01\n",
      "Epoch 5319, Loss: 926.4629516601562, Neurons: 11, Grad norm: 4.065e+01\n",
      "Epoch 5320, Loss: 926.4549560546875, Neurons: 11, Grad norm: 3.442e+01\n",
      "Epoch 5321, Loss: 926.4459838867188, Neurons: 11, Grad norm: 1.317e+01\n",
      "Epoch 5322, Loss: 926.4365844726562, Neurons: 11, Grad norm: 1.103e+01\n",
      "Epoch 5323, Loss: 926.427978515625, Neurons: 11, Grad norm: 2.870e+01\n",
      "Epoch 5324, Loss: 926.4197998046875, Neurons: 11, Grad norm: 3.125e+01\n",
      "Epoch 5325, Loss: 926.411376953125, Neurons: 11, Grad norm: 2.032e+01\n",
      "Epoch 5326, Loss: 926.4022827148438, Neurons: 11, Grad norm: 1.313e+00\n",
      "Epoch 5327, Loss: 926.3933715820312, Neurons: 11, Grad norm: 1.685e+01\n",
      "Epoch 5328, Loss: 926.3849487304688, Neurons: 11, Grad norm: 2.559e+01\n",
      "Epoch 5329, Loss: 926.3765869140625, Neurons: 11, Grad norm: 2.109e+01\n",
      "Epoch 5330, Loss: 926.3679809570312, Neurons: 11, Grad norm: 8.238e+00\n",
      "Epoch 5331, Loss: 926.3590698242188, Neurons: 11, Grad norm: 8.114e+00\n",
      "Epoch 5332, Loss: 926.3504638671875, Neurons: 11, Grad norm: 1.818e+01\n",
      "Epoch 5333, Loss: 926.3421020507812, Neurons: 11, Grad norm: 1.982e+01\n",
      "Epoch 5334, Loss: 926.3335571289062, Neurons: 11, Grad norm: 1.153e+01\n",
      "Epoch 5335, Loss: 926.3247680664062, Neurons: 11, Grad norm: 1.303e+00\n",
      "Epoch 5336, Loss: 926.316162109375, Neurons: 11, Grad norm: 1.187e+01\n",
      "Epoch 5337, Loss: 926.3075561523438, Neurons: 11, Grad norm: 1.597e+01\n",
      "Epoch 5338, Loss: 926.2991943359375, Neurons: 11, Grad norm: 1.325e+01\n",
      "Epoch 5339, Loss: 926.2905883789062, Neurons: 11, Grad norm: 4.207e+00\n",
      "Epoch 5340, Loss: 926.2818603515625, Neurons: 11, Grad norm: 5.389e+00\n",
      "Epoch 5341, Loss: 926.2733764648438, Neurons: 11, Grad norm: 1.213e+01\n",
      "Epoch 5342, Loss: 926.2647705078125, Neurons: 11, Grad norm: 1.214e+01\n",
      "Epoch 5343, Loss: 926.25634765625, Neurons: 11, Grad norm: 7.629e+00\n",
      "Epoch 5344, Loss: 926.2476806640625, Neurons: 11, Grad norm: 1.356e+00\n",
      "Epoch 5345, Loss: 926.2391967773438, Neurons: 11, Grad norm: 7.075e+00\n",
      "Epoch 5346, Loss: 926.2305908203125, Neurons: 11, Grad norm: 1.048e+01\n",
      "Epoch 5347, Loss: 926.2221069335938, Neurons: 11, Grad norm: 8.353e+00\n",
      "Epoch 5348, Loss: 926.2135620117188, Neurons: 11, Grad norm: 3.741e+00\n",
      "Epoch 5349, Loss: 926.2049560546875, Neurons: 11, Grad norm: 3.213e+00\n",
      "Epoch 5349, Test loss: 936.66552734375\n",
      "Epoch 5350, Loss: 926.1963500976562, Neurons: 11, Grad norm: 6.940e+00\n",
      "Epoch 5351, Loss: 926.18798828125, Neurons: 11, Grad norm: 8.305e+00\n",
      "Epoch 5352, Loss: 926.1795043945312, Neurons: 11, Grad norm: 5.387e+00\n",
      "Epoch 5353, Loss: 926.1709594726562, Neurons: 11, Grad norm: 1.675e+00\n",
      "Epoch 5354, Loss: 926.1624755859375, Neurons: 11, Grad norm: 3.930e+00\n",
      "Epoch 5355, Loss: 926.1539916992188, Neurons: 11, Grad norm: 6.013e+00\n",
      "Epoch 5356, Loss: 926.1454467773438, Neurons: 11, Grad norm: 6.311e+00\n",
      "Epoch 5357, Loss: 926.136962890625, Neurons: 11, Grad norm: 3.436e+00\n",
      "Epoch 5358, Loss: 926.1286010742188, Neurons: 11, Grad norm: 1.187e+00\n",
      "Epoch 5359, Loss: 926.1199951171875, Neurons: 11, Grad norm: 3.837e+00\n",
      "Epoch 5360, Loss: 926.111572265625, Neurons: 11, Grad norm: 4.897e+00\n",
      "Epoch 5361, Loss: 926.1029663085938, Neurons: 11, Grad norm: 4.818e+00\n",
      "Epoch 5362, Loss: 926.0946044921875, Neurons: 11, Grad norm: 2.340e+00\n",
      "Epoch 5363, Loss: 926.0860595703125, Neurons: 11, Grad norm: 1.242e+00\n",
      "Epoch 5364, Loss: 926.0775756835938, Neurons: 11, Grad norm: 3.373e+00\n",
      "Epoch 5365, Loss: 926.0691528320312, Neurons: 11, Grad norm: 3.900e+00\n",
      "Epoch 5366, Loss: 926.0606689453125, Neurons: 11, Grad norm: 3.784e+00\n",
      "Epoch 5367, Loss: 926.0521850585938, Neurons: 11, Grad norm: 1.829e+00\n",
      "Epoch 5368, Loss: 926.0437622070312, Neurons: 11, Grad norm: 1.228e+00\n",
      "Epoch 5369, Loss: 926.035400390625, Neurons: 11, Grad norm: 2.800e+00\n",
      "Epoch 5370, Loss: 926.02685546875, Neurons: 11, Grad norm: 3.080e+00\n",
      "Epoch 5371, Loss: 926.0184936523438, Neurons: 11, Grad norm: 3.109e+00\n",
      "Epoch 5372, Loss: 926.0099487304688, Neurons: 11, Grad norm: 1.622e+00\n",
      "Epoch 5373, Loss: 926.0015869140625, Neurons: 11, Grad norm: 1.182e+00\n",
      "Epoch 5374, Loss: 925.9931640625, Neurons: 11, Grad norm: 2.255e+00\n",
      "Epoch 5375, Loss: 925.9848022460938, Neurons: 11, Grad norm: 2.448e+00\n",
      "Epoch 5376, Loss: 925.9763793945312, Neurons: 11, Grad norm: 2.659e+00\n",
      "Epoch 5377, Loss: 925.9678955078125, Neurons: 11, Grad norm: 1.565e+00\n",
      "Epoch 5378, Loss: 925.9593505859375, Neurons: 11, Grad norm: 1.199e+00\n",
      "Epoch 5379, Loss: 925.9510498046875, Neurons: 11, Grad norm: 1.771e+00\n",
      "Epoch 5380, Loss: 925.9425659179688, Neurons: 11, Grad norm: 1.933e+00\n",
      "Epoch 5381, Loss: 925.9342041015625, Neurons: 11, Grad norm: 2.322e+00\n",
      "Epoch 5382, Loss: 925.92578125, Neurons: 11, Grad norm: 1.550e+00\n",
      "Epoch 5383, Loss: 925.91748046875, Neurons: 11, Grad norm: 1.304e+00\n",
      "Epoch 5384, Loss: 925.9090576171875, Neurons: 11, Grad norm: 1.406e+00\n",
      "Epoch 5385, Loss: 925.9006958007812, Neurons: 11, Grad norm: 1.529e+00\n",
      "Epoch 5386, Loss: 925.8921508789062, Neurons: 11, Grad norm: 2.012e+00\n",
      "Epoch 5387, Loss: 925.8838500976562, Neurons: 11, Grad norm: 1.515e+00\n",
      "Epoch 5388, Loss: 925.87548828125, Neurons: 11, Grad norm: 1.437e+00\n",
      "Epoch 5389, Loss: 925.8671875, Neurons: 11, Grad norm: 1.206e+00\n",
      "Epoch 5390, Loss: 925.8587646484375, Neurons: 11, Grad norm: 1.254e+00\n",
      "Epoch 5391, Loss: 925.8504028320312, Neurons: 11, Grad norm: 1.703e+00\n",
      "Epoch 5392, Loss: 925.8421020507812, Neurons: 11, Grad norm: 1.428e+00\n",
      "Epoch 5393, Loss: 925.8336791992188, Neurons: 11, Grad norm: 1.529e+00\n",
      "Epoch 5394, Loss: 925.8252563476562, Neurons: 11, Grad norm: 1.170e+00\n",
      "Epoch 5395, Loss: 925.8169555664062, Neurons: 11, Grad norm: 1.167e+00\n",
      "Epoch 5396, Loss: 925.80859375, Neurons: 11, Grad norm: 1.416e+00\n",
      "Epoch 5397, Loss: 925.8003540039062, Neurons: 11, Grad norm: 1.300e+00\n",
      "Epoch 5398, Loss: 925.7919921875, Neurons: 11, Grad norm: 1.531e+00\n",
      "Epoch 5399, Loss: 925.7835693359375, Neurons: 11, Grad norm: 1.213e+00\n",
      "Epoch 5399, Test loss: 936.2137451171875\n",
      "Epoch 5400, Loss: 925.7752685546875, Neurons: 11, Grad norm: 1.244e+00\n",
      "Epoch 5401, Loss: 925.7669677734375, Neurons: 11, Grad norm: 1.214e+00\n",
      "Epoch 5402, Loss: 925.7586059570312, Neurons: 11, Grad norm: 1.179e+00\n",
      "Epoch 5403, Loss: 925.7503051757812, Neurons: 11, Grad norm: 1.404e+00\n",
      "Epoch 5404, Loss: 925.7420043945312, Neurons: 11, Grad norm: 1.215e+00\n",
      "Epoch 5405, Loss: 925.7337036132812, Neurons: 11, Grad norm: 1.334e+00\n",
      "Epoch 5406, Loss: 925.7254028320312, Neurons: 11, Grad norm: 1.160e+00\n",
      "Epoch 5407, Loss: 925.7171020507812, Neurons: 11, Grad norm: 1.173e+00\n",
      "Epoch 5408, Loss: 925.7088012695312, Neurons: 11, Grad norm: 1.251e+00\n",
      "Epoch 5409, Loss: 925.7003784179688, Neurons: 11, Grad norm: 1.173e+00\n",
      "Epoch 5410, Loss: 925.6920776367188, Neurons: 11, Grad norm: 1.328e+00\n",
      "Epoch 5411, Loss: 925.6838989257812, Neurons: 11, Grad norm: 1.168e+00\n",
      "Epoch 5412, Loss: 925.6755981445312, Neurons: 11, Grad norm: 1.242e+00\n",
      "Epoch 5413, Loss: 925.6672973632812, Neurons: 11, Grad norm: 1.166e+00\n",
      "Epoch 5414, Loss: 925.6589965820312, Neurons: 11, Grad norm: 1.161e+00\n",
      "Epoch 5415, Loss: 925.6507568359375, Neurons: 11, Grad norm: 1.237e+00\n",
      "Epoch 5416, Loss: 925.6423950195312, Neurons: 11, Grad norm: 1.158e+00\n",
      "Epoch 5417, Loss: 925.6341552734375, Neurons: 11, Grad norm: 1.264e+00\n",
      "Epoch 5418, Loss: 925.6258544921875, Neurons: 11, Grad norm: 1.154e+00\n",
      "Epoch 5419, Loss: 925.6175537109375, Neurons: 11, Grad norm: 1.209e+00\n",
      "Epoch 5420, Loss: 925.609375, Neurons: 11, Grad norm: 1.166e+00\n",
      "Epoch 5421, Loss: 925.6011962890625, Neurons: 11, Grad norm: 1.160e+00\n",
      "Epoch 5422, Loss: 925.5928955078125, Neurons: 11, Grad norm: 1.210e+00\n",
      "Epoch 5423, Loss: 925.5845947265625, Neurons: 11, Grad norm: 1.151e+00\n",
      "Epoch 5424, Loss: 925.5763549804688, Neurons: 11, Grad norm: 1.225e+00\n",
      "Epoch 5425, Loss: 925.5680541992188, Neurons: 11, Grad norm: 1.150e+00\n",
      "Epoch 5426, Loss: 925.5598754882812, Neurons: 11, Grad norm: 1.199e+00\n",
      "Epoch 5427, Loss: 925.5516967773438, Neurons: 11, Grad norm: 1.159e+00\n",
      "Epoch 5428, Loss: 925.5433959960938, Neurons: 11, Grad norm: 1.166e+00\n",
      "Epoch 5429, Loss: 925.53515625, Neurons: 11, Grad norm: 1.181e+00\n",
      "Epoch 5430, Loss: 925.52685546875, Neurons: 11, Grad norm: 1.152e+00\n",
      "Epoch 5431, Loss: 925.5186767578125, Neurons: 11, Grad norm: 1.195e+00\n",
      "Epoch 5432, Loss: 925.510498046875, Neurons: 11, Grad norm: 1.150e+00\n",
      "Epoch 5433, Loss: 925.502197265625, Neurons: 11, Grad norm: 1.187e+00\n",
      "Epoch 5434, Loss: 925.4940795898438, Neurons: 11, Grad norm: 1.154e+00\n",
      "Epoch 5435, Loss: 925.4859008789062, Neurons: 11, Grad norm: 1.170e+00\n",
      "Epoch 5436, Loss: 925.4776611328125, Neurons: 11, Grad norm: 1.165e+00\n",
      "Epoch 5437, Loss: 925.4693603515625, Neurons: 11, Grad norm: 1.155e+00\n",
      "Epoch 5438, Loss: 925.4613037109375, Neurons: 11, Grad norm: 1.177e+00\n",
      "Epoch 5439, Loss: 925.4530639648438, Neurons: 11, Grad norm: 1.149e+00\n",
      "Epoch 5440, Loss: 925.4448852539062, Neurons: 11, Grad norm: 1.180e+00\n",
      "Epoch 5441, Loss: 925.4367065429688, Neurons: 11, Grad norm: 1.149e+00\n",
      "Epoch 5442, Loss: 925.4285888671875, Neurons: 11, Grad norm: 1.173e+00\n",
      "Epoch 5443, Loss: 925.4203491210938, Neurons: 11, Grad norm: 1.152e+00\n",
      "Epoch 5444, Loss: 925.4121704101562, Neurons: 11, Grad norm: 1.162e+00\n",
      "Epoch 5445, Loss: 925.4039916992188, Neurons: 11, Grad norm: 1.160e+00\n",
      "Epoch 5446, Loss: 925.395751953125, Neurons: 11, Grad norm: 1.153e+00\n",
      "Epoch 5447, Loss: 925.3876953125, Neurons: 11, Grad norm: 1.167e+00\n",
      "Epoch 5448, Loss: 925.37939453125, Neurons: 11, Grad norm: 1.147e+00\n",
      "Epoch 5449, Loss: 925.3713989257812, Neurons: 11, Grad norm: 1.170e+00\n",
      "Epoch 5449, Test loss: 935.77001953125\n",
      "Epoch 5450, Loss: 925.3631591796875, Neurons: 11, Grad norm: 1.145e+00\n",
      "Epoch 5451, Loss: 925.35498046875, Neurons: 11, Grad norm: 1.168e+00\n",
      "Epoch 5452, Loss: 925.3468017578125, Neurons: 11, Grad norm: 1.145e+00\n",
      "Epoch 5453, Loss: 925.3388061523438, Neurons: 11, Grad norm: 1.163e+00\n",
      "Epoch 5454, Loss: 925.33056640625, Neurons: 11, Grad norm: 1.148e+00\n",
      "Epoch 5455, Loss: 925.3223876953125, Neurons: 11, Grad norm: 1.157e+00\n",
      "Epoch 5456, Loss: 925.3143920898438, Neurons: 11, Grad norm: 1.151e+00\n",
      "Epoch 5457, Loss: 925.30615234375, Neurons: 11, Grad norm: 1.150e+00\n",
      "Epoch 5458, Loss: 925.298095703125, Neurons: 11, Grad norm: 1.154e+00\n",
      "Epoch 5459, Loss: 925.2899780273438, Neurons: 11, Grad norm: 1.146e+00\n",
      "Epoch 5460, Loss: 925.2817993164062, Neurons: 11, Grad norm: 1.155e+00\n",
      "Epoch 5461, Loss: 925.273681640625, Neurons: 11, Grad norm: 1.144e+00\n",
      "Epoch 5462, Loss: 925.2655639648438, Neurons: 11, Grad norm: 1.154e+00\n",
      "Epoch 5463, Loss: 925.2573852539062, Neurons: 11, Grad norm: 1.144e+00\n",
      "Epoch 5464, Loss: 925.2493896484375, Neurons: 11, Grad norm: 1.151e+00\n",
      "Epoch 5465, Loss: 925.2413940429688, Neurons: 11, Grad norm: 1.145e+00\n",
      "Epoch 5466, Loss: 925.233154296875, Neurons: 11, Grad norm: 1.148e+00\n",
      "Epoch 5467, Loss: 925.22509765625, Neurons: 11, Grad norm: 1.146e+00\n",
      "Epoch 5468, Loss: 925.2169799804688, Neurons: 11, Grad norm: 1.144e+00\n",
      "Epoch 5469, Loss: 925.2088623046875, Neurons: 11, Grad norm: 1.148e+00\n",
      "Epoch 5470, Loss: 925.2008056640625, Neurons: 11, Grad norm: 1.140e+00\n",
      "Epoch 5471, Loss: 925.1927490234375, Neurons: 11, Grad norm: 1.149e+00\n",
      "Epoch 5472, Loss: 925.1846923828125, Neurons: 11, Grad norm: 1.138e+00\n",
      "Epoch 5473, Loss: 925.1765747070312, Neurons: 11, Grad norm: 1.149e+00\n",
      "Epoch 5474, Loss: 925.16845703125, Neurons: 11, Grad norm: 1.136e+00\n",
      "Epoch 5475, Loss: 925.160400390625, Neurons: 11, Grad norm: 1.150e+00\n",
      "Epoch 5476, Loss: 925.1524047851562, Neurons: 11, Grad norm: 1.134e+00\n",
      "Epoch 5477, Loss: 925.1443481445312, Neurons: 11, Grad norm: 1.150e+00\n",
      "Epoch 5478, Loss: 925.1362915039062, Neurons: 11, Grad norm: 1.132e+00\n",
      "Epoch 5479, Loss: 925.128173828125, Neurons: 11, Grad norm: 1.152e+00\n",
      "Epoch 5480, Loss: 925.1201782226562, Neurons: 11, Grad norm: 1.128e+00\n",
      "Epoch 5481, Loss: 925.1121826171875, Neurons: 11, Grad norm: 1.157e+00\n",
      "Epoch 5482, Loss: 925.1041870117188, Neurons: 11, Grad norm: 1.124e+00\n",
      "Epoch 5483, Loss: 925.095947265625, Neurons: 11, Grad norm: 1.163e+00\n",
      "Epoch 5484, Loss: 925.0879516601562, Neurons: 11, Grad norm: 1.121e+00\n",
      "Epoch 5485, Loss: 925.0799560546875, Neurons: 11, Grad norm: 1.176e+00\n",
      "Epoch 5486, Loss: 925.0719604492188, Neurons: 11, Grad norm: 1.117e+00\n",
      "Epoch 5487, Loss: 925.06396484375, Neurons: 11, Grad norm: 1.200e+00\n",
      "Epoch 5488, Loss: 925.0558471679688, Neurons: 11, Grad norm: 1.120e+00\n",
      "Epoch 5489, Loss: 925.0478515625, Neurons: 11, Grad norm: 1.245e+00\n",
      "Epoch 5490, Loss: 925.039794921875, Neurons: 11, Grad norm: 1.140e+00\n",
      "Epoch 5491, Loss: 925.0317993164062, Neurons: 11, Grad norm: 1.344e+00\n",
      "Epoch 5492, Loss: 925.0238037109375, Neurons: 11, Grad norm: 1.221e+00\n",
      "Epoch 5493, Loss: 925.0157470703125, Neurons: 11, Grad norm: 1.563e+00\n",
      "Epoch 5494, Loss: 925.0077514648438, Neurons: 11, Grad norm: 1.464e+00\n",
      "Epoch 5495, Loss: 924.9998779296875, Neurons: 11, Grad norm: 2.025e+00\n",
      "Epoch 5496, Loss: 924.9918823242188, Neurons: 11, Grad norm: 2.065e+00\n",
      "Epoch 5497, Loss: 924.98388671875, Neurons: 11, Grad norm: 2.957e+00\n",
      "Epoch 5498, Loss: 924.9758911132812, Neurons: 11, Grad norm: 3.337e+00\n",
      "Epoch 5499, Loss: 924.9679565429688, Neurons: 11, Grad norm: 4.768e+00\n",
      "Epoch 5499, Test loss: 935.334228515625\n",
      "Epoch 5500, Loss: 924.9599609375, Neurons: 11, Grad norm: 5.827e+00\n",
      "Epoch 5501, Loss: 924.9519653320312, Neurons: 11, Grad norm: 8.221e+00\n",
      "Epoch 5502, Loss: 924.9439697265625, Neurons: 11, Grad norm: 1.058e+01\n",
      "Epoch 5503, Loss: 924.9360961914062, Neurons: 11, Grad norm: 1.476e+01\n",
      "Epoch 5504, Loss: 924.9281616210938, Neurons: 11, Grad norm: 1.956e+01\n",
      "Epoch 5505, Loss: 924.9203491210938, Neurons: 11, Grad norm: 2.703e+01\n",
      "Epoch 5506, Loss: 924.91259765625, Neurons: 11, Grad norm: 3.605e+01\n",
      "Epoch 5507, Loss: 924.9049682617188, Neurons: 11, Grad norm: 4.860e+01\n",
      "Epoch 5508, Loss: 924.897705078125, Neurons: 11, Grad norm: 6.255e+01\n",
      "Epoch 5509, Loss: 924.8907470703125, Neurons: 11, Grad norm: 7.739e+01\n",
      "Epoch 5510, Loss: 924.8841552734375, Neurons: 11, Grad norm: 8.586e+01\n",
      "Epoch 5511, Loss: 924.8770751953125, Neurons: 11, Grad norm: 8.212e+01\n",
      "Epoch 5512, Loss: 924.86865234375, Neurons: 11, Grad norm: 5.874e+01\n",
      "Epoch 5513, Loss: 924.8587646484375, Neurons: 11, Grad norm: 2.159e+01\n",
      "Epoch 5514, Loss: 924.848876953125, Neurons: 11, Grad norm: 1.970e+01\n",
      "Epoch 5515, Loss: 924.8407592773438, Neurons: 11, Grad norm: 4.965e+01\n",
      "Epoch 5516, Loss: 924.8343505859375, Neurons: 11, Grad norm: 6.075e+01\n",
      "Epoch 5517, Loss: 924.8271484375, Neurons: 11, Grad norm: 4.776e+01\n",
      "Epoch 5518, Loss: 924.818359375, Neurons: 11, Grad norm: 1.799e+01\n",
      "Epoch 5519, Loss: 924.8092041015625, Neurons: 11, Grad norm: 1.697e+01\n",
      "Epoch 5520, Loss: 924.80126953125, Neurons: 11, Grad norm: 4.068e+01\n",
      "Epoch 5521, Loss: 924.7942504882812, Neurons: 11, Grad norm: 4.590e+01\n",
      "Epoch 5522, Loss: 924.7865600585938, Neurons: 11, Grad norm: 2.989e+01\n",
      "Epoch 5523, Loss: 924.7779541015625, Neurons: 11, Grad norm: 3.227e+00\n",
      "Epoch 5524, Loss: 924.7695922851562, Neurons: 11, Grad norm: 2.339e+01\n",
      "Epoch 5525, Loss: 924.761962890625, Neurons: 11, Grad norm: 3.587e+01\n",
      "Epoch 5526, Loss: 924.7545776367188, Neurons: 11, Grad norm: 3.161e+01\n",
      "Epoch 5527, Loss: 924.7464599609375, Neurons: 11, Grad norm: 1.245e+01\n",
      "Epoch 5528, Loss: 924.7381591796875, Neurons: 11, Grad norm: 9.988e+00\n",
      "Epoch 5529, Loss: 924.7301635742188, Neurons: 11, Grad norm: 2.621e+01\n",
      "Epoch 5530, Loss: 924.72265625, Neurons: 11, Grad norm: 2.791e+01\n",
      "Epoch 5531, Loss: 924.7149047851562, Neurons: 11, Grad norm: 1.718e+01\n",
      "Epoch 5532, Loss: 924.7066650390625, Neurons: 11, Grad norm: 1.809e+00\n",
      "Epoch 5533, Loss: 924.6985473632812, Neurons: 11, Grad norm: 1.672e+01\n",
      "Epoch 5534, Loss: 924.6909790039062, Neurons: 11, Grad norm: 2.345e+01\n",
      "Epoch 5535, Loss: 924.6832885742188, Neurons: 11, Grad norm: 1.774e+01\n",
      "Epoch 5536, Loss: 924.67529296875, Neurons: 11, Grad norm: 5.124e+00\n",
      "Epoch 5537, Loss: 924.6672973632812, Neurons: 11, Grad norm: 9.606e+00\n",
      "Epoch 5538, Loss: 924.6594848632812, Neurons: 11, Grad norm: 1.749e+01\n",
      "Epoch 5539, Loss: 924.6517944335938, Neurons: 11, Grad norm: 1.726e+01\n",
      "Epoch 5540, Loss: 924.6439819335938, Neurons: 11, Grad norm: 8.311e+00\n",
      "Epoch 5541, Loss: 924.635986328125, Neurons: 11, Grad norm: 3.089e+00\n",
      "Epoch 5542, Loss: 924.6280517578125, Neurons: 11, Grad norm: 1.244e+01\n",
      "Epoch 5543, Loss: 924.620361328125, Neurons: 11, Grad norm: 1.450e+01\n",
      "Epoch 5544, Loss: 924.612548828125, Neurons: 11, Grad norm: 1.059e+01\n",
      "Epoch 5545, Loss: 924.6046752929688, Neurons: 11, Grad norm: 1.773e+00\n",
      "Epoch 5546, Loss: 924.5968017578125, Neurons: 11, Grad norm: 6.769e+00\n",
      "Epoch 5547, Loss: 924.5889892578125, Neurons: 11, Grad norm: 1.178e+01\n",
      "Epoch 5548, Loss: 924.581298828125, Neurons: 11, Grad norm: 1.033e+01\n",
      "Epoch 5549, Loss: 924.5733642578125, Neurons: 11, Grad norm: 5.258e+00\n",
      "Epoch 5549, Test loss: 934.9095458984375\n",
      "Epoch 5550, Loss: 924.5655517578125, Neurons: 11, Grad norm: 2.745e+00\n",
      "Epoch 5551, Loss: 924.5578002929688, Neurons: 11, Grad norm: 7.618e+00\n",
      "Epoch 5552, Loss: 924.550048828125, Neurons: 11, Grad norm: 9.626e+00\n",
      "Epoch 5553, Loss: 924.5421752929688, Neurons: 11, Grad norm: 6.534e+00\n",
      "Epoch 5554, Loss: 924.5344848632812, Neurons: 11, Grad norm: 1.971e+00\n",
      "Epoch 5555, Loss: 924.5265502929688, Neurons: 11, Grad norm: 4.312e+00\n",
      "Epoch 5556, Loss: 924.5188598632812, Neurons: 11, Grad norm: 6.944e+00\n",
      "Epoch 5557, Loss: 924.5110473632812, Neurons: 11, Grad norm: 7.402e+00\n",
      "Epoch 5558, Loss: 924.5033569335938, Neurons: 11, Grad norm: 3.801e+00\n",
      "Epoch 5559, Loss: 924.4954833984375, Neurons: 11, Grad norm: 1.116e+00\n",
      "Epoch 5560, Loss: 924.48779296875, Neurons: 11, Grad norm: 4.593e+00\n",
      "Epoch 5561, Loss: 924.47998046875, Neurons: 11, Grad norm: 5.736e+00\n",
      "Epoch 5562, Loss: 924.47216796875, Neurons: 11, Grad norm: 5.291e+00\n",
      "Epoch 5563, Loss: 924.4644775390625, Neurons: 11, Grad norm: 2.176e+00\n",
      "Epoch 5564, Loss: 924.4566650390625, Neurons: 11, Grad norm: 1.501e+00\n",
      "Epoch 5565, Loss: 924.448974609375, Neurons: 11, Grad norm: 4.203e+00\n",
      "Epoch 5566, Loss: 924.441162109375, Neurons: 11, Grad norm: 4.522e+00\n",
      "Epoch 5567, Loss: 924.4334716796875, Neurons: 11, Grad norm: 3.902e+00\n",
      "Epoch 5568, Loss: 924.4256591796875, Neurons: 11, Grad norm: 1.429e+00\n",
      "Epoch 5569, Loss: 924.41796875, Neurons: 11, Grad norm: 1.606e+00\n",
      "Epoch 5570, Loss: 924.41015625, Neurons: 11, Grad norm: 3.596e+00\n",
      "Epoch 5571, Loss: 924.402587890625, Neurons: 11, Grad norm: 3.544e+00\n",
      "Epoch 5572, Loss: 924.394775390625, Neurons: 11, Grad norm: 3.043e+00\n",
      "Epoch 5573, Loss: 924.3870849609375, Neurons: 11, Grad norm: 1.197e+00\n",
      "Epoch 5574, Loss: 924.3792724609375, Neurons: 11, Grad norm: 1.454e+00\n",
      "Epoch 5575, Loss: 924.37158203125, Neurons: 11, Grad norm: 2.964e+00\n",
      "Epoch 5576, Loss: 924.3639526367188, Neurons: 11, Grad norm: 2.799e+00\n",
      "Epoch 5577, Loss: 924.356201171875, Neurons: 11, Grad norm: 2.524e+00\n",
      "Epoch 5578, Loss: 924.3484497070312, Neurons: 11, Grad norm: 1.154e+00\n",
      "Epoch 5579, Loss: 924.3407592773438, Neurons: 11, Grad norm: 1.242e+00\n",
      "Epoch 5580, Loss: 924.3330688476562, Neurons: 11, Grad norm: 2.385e+00\n",
      "Epoch 5581, Loss: 924.3252563476562, Neurons: 11, Grad norm: 2.244e+00\n",
      "Epoch 5582, Loss: 924.3176879882812, Neurons: 11, Grad norm: 2.215e+00\n",
      "Epoch 5583, Loss: 924.3099975585938, Neurons: 11, Grad norm: 1.168e+00\n",
      "Epoch 5584, Loss: 924.3023071289062, Neurons: 11, Grad norm: 1.097e+00\n",
      "Epoch 5585, Loss: 924.2945556640625, Neurons: 11, Grad norm: 1.905e+00\n",
      "Epoch 5586, Loss: 924.286865234375, Neurons: 11, Grad norm: 1.828e+00\n",
      "Epoch 5587, Loss: 924.2791748046875, Neurons: 11, Grad norm: 2.012e+00\n",
      "Epoch 5588, Loss: 924.2716064453125, Neurons: 11, Grad norm: 1.213e+00\n",
      "Epoch 5589, Loss: 924.2637939453125, Neurons: 11, Grad norm: 1.079e+00\n",
      "Epoch 5590, Loss: 924.2561645507812, Neurons: 11, Grad norm: 1.503e+00\n",
      "Epoch 5591, Loss: 924.2485961914062, Neurons: 11, Grad norm: 1.487e+00\n",
      "Epoch 5592, Loss: 924.2407836914062, Neurons: 11, Grad norm: 1.826e+00\n",
      "Epoch 5593, Loss: 924.233154296875, Neurons: 11, Grad norm: 1.246e+00\n",
      "Epoch 5594, Loss: 924.2254638671875, Neurons: 11, Grad norm: 1.170e+00\n",
      "Epoch 5595, Loss: 924.2178955078125, Neurons: 11, Grad norm: 1.220e+00\n",
      "Epoch 5596, Loss: 924.210205078125, Neurons: 11, Grad norm: 1.224e+00\n",
      "Epoch 5597, Loss: 924.2025756835938, Neurons: 11, Grad norm: 1.618e+00\n",
      "Epoch 5598, Loss: 924.1949462890625, Neurons: 11, Grad norm: 1.238e+00\n",
      "Epoch 5599, Loss: 924.187255859375, Neurons: 11, Grad norm: 1.278e+00\n",
      "Epoch 5599, Test loss: 934.4959106445312\n",
      "Epoch 5600, Loss: 924.1796875, Neurons: 11, Grad norm: 1.084e+00\n",
      "Epoch 5601, Loss: 924.1719970703125, Neurons: 11, Grad norm: 1.080e+00\n",
      "Epoch 5602, Loss: 924.1643676757812, Neurons: 11, Grad norm: 1.399e+00\n",
      "Epoch 5603, Loss: 924.1567993164062, Neurons: 11, Grad norm: 1.185e+00\n",
      "Epoch 5604, Loss: 924.149169921875, Neurons: 11, Grad norm: 1.344e+00\n",
      "Epoch 5605, Loss: 924.1414794921875, Neurons: 11, Grad norm: 1.065e+00\n",
      "Epoch 5606, Loss: 924.1338500976562, Neurons: 11, Grad norm: 1.079e+00\n",
      "Epoch 5607, Loss: 924.1262817382812, Neurons: 11, Grad norm: 1.194e+00\n",
      "Epoch 5608, Loss: 924.1185913085938, Neurons: 11, Grad norm: 1.100e+00\n",
      "Epoch 5609, Loss: 924.111083984375, Neurons: 11, Grad norm: 1.313e+00\n",
      "Epoch 5610, Loss: 924.1033935546875, Neurons: 11, Grad norm: 1.085e+00\n",
      "Epoch 5611, Loss: 924.0957641601562, Neurons: 11, Grad norm: 1.159e+00\n",
      "Epoch 5612, Loss: 924.0881958007812, Neurons: 11, Grad norm: 1.081e+00\n",
      "Epoch 5613, Loss: 924.08056640625, Neurons: 11, Grad norm: 1.059e+00\n",
      "Epoch 5614, Loss: 924.072998046875, Neurons: 11, Grad norm: 1.212e+00\n",
      "Epoch 5615, Loss: 924.0653686523438, Neurons: 11, Grad norm: 1.078e+00\n",
      "Epoch 5616, Loss: 924.0578002929688, Neurons: 11, Grad norm: 1.216e+00\n",
      "Epoch 5617, Loss: 924.0501708984375, Neurons: 11, Grad norm: 1.059e+00\n",
      "Epoch 5618, Loss: 924.0426025390625, Neurons: 11, Grad norm: 1.102e+00\n",
      "Epoch 5619, Loss: 924.0350952148438, Neurons: 11, Grad norm: 1.099e+00\n",
      "Epoch 5620, Loss: 924.0274658203125, Neurons: 11, Grad norm: 1.058e+00\n",
      "Epoch 5621, Loss: 924.0199584960938, Neurons: 11, Grad norm: 1.177e+00\n",
      "Epoch 5622, Loss: 924.0123901367188, Neurons: 11, Grad norm: 1.061e+00\n",
      "Epoch 5623, Loss: 924.0047607421875, Neurons: 11, Grad norm: 1.157e+00\n",
      "Epoch 5624, Loss: 923.9971923828125, Neurons: 11, Grad norm: 1.060e+00\n",
      "Epoch 5625, Loss: 923.9896850585938, Neurons: 11, Grad norm: 1.087e+00\n",
      "Epoch 5626, Loss: 923.9820556640625, Neurons: 11, Grad norm: 1.099e+00\n",
      "Epoch 5627, Loss: 923.9745483398438, Neurons: 11, Grad norm: 1.058e+00\n",
      "Epoch 5628, Loss: 923.9669799804688, Neurons: 11, Grad norm: 1.142e+00\n",
      "Epoch 5629, Loss: 923.9593505859375, Neurons: 11, Grad norm: 1.058e+00\n",
      "Epoch 5630, Loss: 923.951904296875, Neurons: 11, Grad norm: 1.128e+00\n",
      "Epoch 5631, Loss: 923.9443969726562, Neurons: 11, Grad norm: 1.064e+00\n",
      "Epoch 5632, Loss: 923.936767578125, Neurons: 11, Grad norm: 1.087e+00\n",
      "Epoch 5633, Loss: 923.9292602539062, Neurons: 11, Grad norm: 1.089e+00\n",
      "Epoch 5634, Loss: 923.9216918945312, Neurons: 11, Grad norm: 1.066e+00\n",
      "Epoch 5635, Loss: 923.9141845703125, Neurons: 11, Grad norm: 1.115e+00\n",
      "Epoch 5636, Loss: 923.9065551757812, Neurons: 11, Grad norm: 1.063e+00\n",
      "Epoch 5637, Loss: 923.899169921875, Neurons: 11, Grad norm: 1.115e+00\n",
      "Epoch 5638, Loss: 923.8916015625, Neurons: 11, Grad norm: 1.068e+00\n",
      "Epoch 5639, Loss: 923.8840942382812, Neurons: 11, Grad norm: 1.096e+00\n",
      "Epoch 5640, Loss: 923.87646484375, Neurons: 11, Grad norm: 1.083e+00\n",
      "Epoch 5641, Loss: 923.8689575195312, Neurons: 11, Grad norm: 1.079e+00\n",
      "Epoch 5642, Loss: 923.861572265625, Neurons: 11, Grad norm: 1.105e+00\n",
      "Epoch 5643, Loss: 923.85400390625, Neurons: 11, Grad norm: 1.074e+00\n",
      "Epoch 5644, Loss: 923.8464965820312, Neurons: 11, Grad norm: 1.115e+00\n",
      "Epoch 5645, Loss: 923.8388671875, Neurons: 11, Grad norm: 1.078e+00\n",
      "Epoch 5646, Loss: 923.8313598632812, Neurons: 11, Grad norm: 1.111e+00\n",
      "Epoch 5647, Loss: 923.8238525390625, Neurons: 11, Grad norm: 1.088e+00\n",
      "Epoch 5648, Loss: 923.81640625, Neurons: 11, Grad norm: 1.101e+00\n",
      "Epoch 5649, Loss: 923.8087768554688, Neurons: 11, Grad norm: 1.106e+00\n",
      "Epoch 5649, Test loss: 934.0892944335938\n",
      "Epoch 5650, Loss: 923.8013916015625, Neurons: 11, Grad norm: 1.097e+00\n",
      "Epoch 5651, Loss: 923.7938842773438, Neurons: 11, Grad norm: 1.122e+00\n",
      "Epoch 5652, Loss: 923.786376953125, Neurons: 11, Grad norm: 1.101e+00\n",
      "Epoch 5653, Loss: 923.7788696289062, Neurons: 11, Grad norm: 1.133e+00\n",
      "Epoch 5654, Loss: 923.7713623046875, Neurons: 11, Grad norm: 1.112e+00\n",
      "Epoch 5655, Loss: 923.7637939453125, Neurons: 11, Grad norm: 1.140e+00\n",
      "Epoch 5656, Loss: 923.75634765625, Neurons: 11, Grad norm: 1.127e+00\n",
      "Epoch 5657, Loss: 923.748779296875, Neurons: 11, Grad norm: 1.146e+00\n",
      "Epoch 5658, Loss: 923.7413940429688, Neurons: 11, Grad norm: 1.148e+00\n",
      "Epoch 5659, Loss: 923.7337646484375, Neurons: 11, Grad norm: 1.156e+00\n",
      "Epoch 5660, Loss: 923.7262573242188, Neurons: 11, Grad norm: 1.173e+00\n",
      "Epoch 5661, Loss: 923.71875, Neurons: 11, Grad norm: 1.174e+00\n",
      "Epoch 5662, Loss: 923.7113037109375, Neurons: 11, Grad norm: 1.200e+00\n",
      "Epoch 5663, Loss: 923.7037963867188, Neurons: 11, Grad norm: 1.200e+00\n",
      "Epoch 5664, Loss: 923.6961669921875, Neurons: 11, Grad norm: 1.233e+00\n",
      "Epoch 5665, Loss: 923.6886596679688, Neurons: 11, Grad norm: 1.236e+00\n",
      "Epoch 5666, Loss: 923.68115234375, Neurons: 11, Grad norm: 1.268e+00\n",
      "Epoch 5667, Loss: 923.6734619140625, Neurons: 11, Grad norm: 1.283e+00\n",
      "Epoch 5668, Loss: 923.6659545898438, Neurons: 11, Grad norm: 1.316e+00\n",
      "Epoch 5669, Loss: 923.6583862304688, Neurons: 11, Grad norm: 1.343e+00\n",
      "Epoch 5670, Loss: 923.6507568359375, Neurons: 11, Grad norm: 1.379e+00\n",
      "Epoch 5671, Loss: 923.6431884765625, Neurons: 11, Grad norm: 1.420e+00\n",
      "Epoch 5672, Loss: 923.635498046875, Neurons: 11, Grad norm: 1.461e+00\n",
      "Epoch 5673, Loss: 923.6277465820312, Neurons: 11, Grad norm: 1.519e+00\n",
      "Epoch 5674, Loss: 923.6200561523438, Neurons: 11, Grad norm: 1.569e+00\n",
      "Epoch 5675, Loss: 923.6123657226562, Neurons: 11, Grad norm: 1.646e+00\n",
      "Epoch 5676, Loss: 923.6045532226562, Neurons: 11, Grad norm: 1.710e+00\n",
      "Epoch 5677, Loss: 923.5968017578125, Neurons: 11, Grad norm: 1.809e+00\n",
      "Epoch 5678, Loss: 923.5888671875, Neurons: 11, Grad norm: 1.897e+00\n",
      "Epoch 5679, Loss: 923.5807495117188, Neurons: 11, Grad norm: 2.020e+00\n",
      "Epoch 5680, Loss: 923.57275390625, Neurons: 11, Grad norm: 2.142e+00\n",
      "Epoch 5681, Loss: 923.5645751953125, Neurons: 11, Grad norm: 2.298e+00\n",
      "Epoch 5682, Loss: 923.55615234375, Neurons: 11, Grad norm: 2.464e+00\n",
      "Epoch 5683, Loss: 923.5476684570312, Neurons: 11, Grad norm: 2.666e+00\n",
      "Epoch 5684, Loss: 923.5390014648438, Neurons: 11, Grad norm: 2.892e+00\n",
      "Epoch 5685, Loss: 923.5299682617188, Neurons: 11, Grad norm: 3.157e+00\n",
      "Epoch 5686, Loss: 923.520751953125, Neurons: 11, Grad norm: 3.462e+00\n",
      "Epoch 5687, Loss: 923.5110473632812, Neurons: 11, Grad norm: 3.819e+00\n",
      "Epoch 5688, Loss: 923.5008544921875, Neurons: 11, Grad norm: 4.236e+00\n",
      "Epoch 5689, Loss: 923.4901733398438, Neurons: 11, Grad norm: 4.724e+00\n",
      "Epoch 5690, Loss: 923.4786987304688, Neurons: 11, Grad norm: 5.302e+00\n",
      "Epoch 5691, Loss: 923.466064453125, Neurons: 11, Grad norm: 5.983e+00\n",
      "Epoch 5692, Loss: 923.4522705078125, Neurons: 11, Grad norm: 6.801e+00\n",
      "Epoch 5693, Loss: 923.4367065429688, Neurons: 11, Grad norm: 7.775e+00\n",
      "Epoch 5694, Loss: 923.4188842773438, Neurons: 11, Grad norm: 8.987e+00\n",
      "Epoch 5695, Loss: 923.39794921875, Neurons: 11, Grad norm: 1.039e+01\n",
      "Epoch 5696, Loss: 923.3729858398438, Neurons: 11, Grad norm: 1.215e+01\n",
      "Epoch 5697, Loss: 923.3425903320312, Neurons: 11, Grad norm: 1.432e+01\n",
      "Epoch 5698, Loss: 923.3043823242188, Neurons: 11, Grad norm: 1.700e+01\n",
      "Epoch 5699, Loss: 923.2554931640625, Neurons: 11, Grad norm: 2.036e+01\n",
      "Epoch 5699, Test loss: 933.4902954101562\n",
      "Epoch 5700, Loss: 923.1917724609375, Neurons: 11, Grad norm: 2.449e+01\n",
      "Epoch 5701, Loss: 923.1077880859375, Neurons: 11, Grad norm: 2.977e+01\n",
      "Epoch 5702, Loss: 922.995361328125, Neurons: 11, Grad norm: 3.644e+01\n",
      "Epoch 5703, Loss: 922.8450927734375, Neurons: 11, Grad norm: 4.463e+01\n",
      "Epoch 5704, Loss: 922.6452026367188, Neurons: 11, Grad norm: 5.453e+01\n",
      "Epoch 5705, Loss: 922.383056640625, Neurons: 11, Grad norm: 6.636e+01\n",
      "Epoch 5706, Loss: 922.0477905273438, Neurons: 11, Grad norm: 8.009e+01\n",
      "Epoch 5707, Loss: 921.6295776367188, Neurons: 11, Grad norm: 9.557e+01\n",
      "Epoch 5708, Loss: 921.1207885742188, Neurons: 11, Grad norm: 1.125e+02\n",
      "Epoch 5709, Loss: 920.514404296875, Neurons: 11, Grad norm: 1.303e+02\n",
      "Epoch 5710, Loss: 919.802001953125, Neurons: 11, Grad norm: 1.483e+02\n",
      "Epoch 5711, Loss: 918.972900390625, Neurons: 11, Grad norm: 1.666e+02\n",
      "Epoch 5712, Loss: 918.0161743164062, Neurons: 11, Grad norm: 1.837e+02\n",
      "Epoch 5713, Loss: 916.9197998046875, Neurons: 11, Grad norm: 2.005e+02\n",
      "Epoch 5714, Loss: 915.6756591796875, Neurons: 11, Grad norm: 2.172e+02\n",
      "Epoch 5715, Loss: 914.2765502929688, Neurons: 11, Grad norm: 2.337e+02\n",
      "Epoch 5716, Loss: 912.716552734375, Neurons: 11, Grad norm: 2.498e+02\n",
      "Epoch 5717, Loss: 910.9921875, Neurons: 11, Grad norm: 2.654e+02\n",
      "Epoch 5718, Loss: 909.1024780273438, Neurons: 11, Grad norm: 2.798e+02\n",
      "Epoch 5719, Loss: 907.0494995117188, Neurons: 11, Grad norm: 2.928e+02\n",
      "Epoch 5720, Loss: 904.8372802734375, Neurons: 11, Grad norm: 3.038e+02\n",
      "Epoch 5721, Loss: 902.4718017578125, Neurons: 11, Grad norm: 3.125e+02\n",
      "Epoch 5722, Loss: 899.9605712890625, Neurons: 11, Grad norm: 3.188e+02\n",
      "Epoch 5723, Loss: 897.3142700195312, Neurons: 11, Grad norm: 3.226e+02\n",
      "Epoch 5724, Loss: 894.5462036132812, Neurons: 11, Grad norm: 3.242e+02\n",
      "Epoch 5725, Loss: 891.6727905273438, Neurons: 11, Grad norm: 3.237e+02\n",
      "Epoch 5726, Loss: 888.7130737304688, Neurons: 11, Grad norm: 3.212e+02\n",
      "Epoch 5727, Loss: 885.6878051757812, Neurons: 11, Grad norm: 3.168e+02\n",
      "Epoch 5728, Loss: 882.6197509765625, Neurons: 11, Grad norm: 3.106e+02\n",
      "Epoch 5729, Loss: 879.533203125, Neurons: 11, Grad norm: 3.027e+02\n",
      "Epoch 5730, Loss: 876.4535522460938, Neurons: 11, Grad norm: 2.932e+02\n",
      "Epoch 5731, Loss: 873.4061889648438, Neurons: 11, Grad norm: 2.824e+02\n",
      "Epoch 5732, Loss: 870.41650390625, Neurons: 11, Grad norm: 2.704e+02\n",
      "Epoch 5733, Loss: 867.5086669921875, Neurons: 11, Grad norm: 2.576e+02\n",
      "Epoch 5734, Loss: 864.70556640625, Neurons: 11, Grad norm: 2.443e+02\n",
      "Epoch 5735, Loss: 862.0269775390625, Neurons: 11, Grad norm: 2.308e+02\n",
      "Epoch 5736, Loss: 859.4898071289062, Neurons: 11, Grad norm: 2.174e+02\n",
      "Epoch 5737, Loss: 857.1056518554688, Neurons: 11, Grad norm: 2.042e+02\n",
      "Epoch 5738, Loss: 854.8827514648438, Neurons: 11, Grad norm: 1.915e+02\n",
      "Epoch 5739, Loss: 852.8245849609375, Neurons: 11, Grad norm: 1.792e+02\n",
      "Epoch 5740, Loss: 850.9303588867188, Neurons: 11, Grad norm: 1.676e+02\n",
      "Epoch 5741, Loss: 849.1964721679688, Neurons: 11, Grad norm: 1.566e+02\n",
      "Epoch 5742, Loss: 847.616455078125, Neurons: 11, Grad norm: 1.463e+02\n",
      "Epoch 5743, Loss: 846.1821899414062, Neurons: 11, Grad norm: 1.367e+02\n",
      "Epoch 5744, Loss: 844.8836059570312, Neurons: 11, Grad norm: 1.277e+02\n",
      "Epoch 5745, Loss: 843.71044921875, Neurons: 11, Grad norm: 1.194e+02\n",
      "Epoch 5746, Loss: 842.6524047851562, Neurons: 11, Grad norm: 1.118e+02\n",
      "Epoch 5747, Loss: 841.6990966796875, Neurons: 11, Grad norm: 1.048e+02\n",
      "Epoch 5748, Loss: 840.8403930664062, Neurons: 11, Grad norm: 9.826e+01\n",
      "Epoch 5749, Loss: 840.0670776367188, Neurons: 11, Grad norm: 9.227e+01\n",
      "Epoch 5749, Test loss: 849.2918090820312\n",
      "Epoch 5750, Loss: 839.37060546875, Neurons: 11, Grad norm: 8.675e+01\n",
      "Epoch 5751, Loss: 838.7430419921875, Neurons: 11, Grad norm: 8.164e+01\n",
      "Epoch 5752, Loss: 838.177001953125, Neurons: 11, Grad norm: 7.692e+01\n",
      "Epoch 5753, Loss: 837.6659545898438, Neurons: 11, Grad norm: 7.255e+01\n",
      "Epoch 5754, Loss: 837.2040405273438, Neurons: 11, Grad norm: 6.851e+01\n",
      "Epoch 5755, Loss: 836.785888671875, Neurons: 11, Grad norm: 6.476e+01\n",
      "Epoch 5756, Loss: 836.4066772460938, Neurons: 11, Grad norm: 6.129e+01\n",
      "Epoch 5757, Loss: 836.0623168945312, Neurons: 11, Grad norm: 5.806e+01\n",
      "Epoch 5758, Loss: 835.7489013671875, Neurons: 11, Grad norm: 5.506e+01\n",
      "Epoch 5759, Loss: 835.4632568359375, Neurons: 11, Grad norm: 5.227e+01\n",
      "Epoch 5760, Loss: 835.2023315429688, Neurons: 11, Grad norm: 4.965e+01\n",
      "Epoch 5761, Loss: 834.96337890625, Neurons: 11, Grad norm: 4.720e+01\n",
      "Epoch 5762, Loss: 834.7442626953125, Neurons: 11, Grad norm: 4.491e+01\n",
      "Epoch 5763, Loss: 834.5428466796875, Neurons: 11, Grad norm: 4.277e+01\n",
      "Epoch 5764, Loss: 834.3572998046875, Neurons: 11, Grad norm: 4.040e+01\n",
      "Epoch 5765, Loss: 834.1863403320312, Neurons: 11, Grad norm: 3.850e+01\n",
      "Epoch 5766, Loss: 834.028564453125, Neurons: 11, Grad norm: 3.674e+01\n",
      "Epoch 5767, Loss: 833.8824462890625, Neurons: 11, Grad norm: 3.509e+01\n",
      "Epoch 5768, Loss: 833.7464599609375, Neurons: 11, Grad norm: 3.353e+01\n",
      "Epoch 5769, Loss: 833.6197509765625, Neurons: 11, Grad norm: 3.206e+01\n",
      "Epoch 5770, Loss: 833.50146484375, Neurons: 11, Grad norm: 3.068e+01\n",
      "Epoch 5771, Loss: 833.3906860351562, Neurons: 11, Grad norm: 2.937e+01\n",
      "Epoch 5772, Loss: 833.2866821289062, Neurons: 11, Grad norm: 2.815e+01\n",
      "Epoch 5773, Loss: 833.188720703125, Neurons: 11, Grad norm: 2.701e+01\n",
      "Epoch 5774, Loss: 833.0963745117188, Neurons: 11, Grad norm: 2.590e+01\n",
      "Epoch 5775, Loss: 833.0089721679688, Neurons: 11, Grad norm: 2.487e+01\n",
      "Epoch 5776, Loss: 832.9260864257812, Neurons: 11, Grad norm: 2.390e+01\n",
      "Epoch 5777, Loss: 832.8473510742188, Neurons: 11, Grad norm: 2.298e+01\n",
      "Epoch 5778, Loss: 832.7723999023438, Neurons: 11, Grad norm: 2.211e+01\n",
      "Epoch 5779, Loss: 832.70068359375, Neurons: 11, Grad norm: 2.128e+01\n",
      "Epoch 5780, Loss: 832.632080078125, Neurons: 11, Grad norm: 2.051e+01\n",
      "Epoch 5781, Loss: 832.566162109375, Neurons: 11, Grad norm: 1.976e+01\n",
      "Epoch 5782, Loss: 832.5029296875, Neurons: 11, Grad norm: 1.906e+01\n",
      "Epoch 5783, Loss: 832.4419555664062, Neurons: 11, Grad norm: 1.840e+01\n",
      "Epoch 5784, Loss: 832.383056640625, Neurons: 11, Grad norm: 1.776e+01\n",
      "Epoch 5785, Loss: 832.3261108398438, Neurons: 11, Grad norm: 1.716e+01\n",
      "Epoch 5786, Loss: 832.2709350585938, Neurons: 11, Grad norm: 1.659e+01\n",
      "Epoch 5787, Loss: 832.2174072265625, Neurons: 11, Grad norm: 1.604e+01\n",
      "Epoch 5788, Loss: 832.165283203125, Neurons: 11, Grad norm: 1.552e+01\n",
      "Epoch 5789, Loss: 832.114501953125, Neurons: 11, Grad norm: 1.503e+01\n",
      "Epoch 5790, Loss: 832.0650024414062, Neurons: 11, Grad norm: 1.456e+01\n",
      "Epoch 5791, Loss: 832.0166015625, Neurons: 11, Grad norm: 1.410e+01\n",
      "Epoch 5792, Loss: 831.9691772460938, Neurons: 11, Grad norm: 1.367e+01\n",
      "Epoch 5793, Loss: 831.9227905273438, Neurons: 11, Grad norm: 1.326e+01\n",
      "Epoch 5794, Loss: 831.8772583007812, Neurons: 11, Grad norm: 1.286e+01\n",
      "Epoch 5795, Loss: 831.8325805664062, Neurons: 11, Grad norm: 1.248e+01\n",
      "Epoch 5796, Loss: 831.7886962890625, Neurons: 11, Grad norm: 1.212e+01\n",
      "Epoch 5797, Loss: 831.745361328125, Neurons: 11, Grad norm: 1.177e+01\n",
      "Epoch 5798, Loss: 831.7027587890625, Neurons: 11, Grad norm: 1.144e+01\n",
      "Epoch 5799, Loss: 831.6607666015625, Neurons: 11, Grad norm: 1.112e+01\n",
      "Epoch 5799, Test loss: 841.1567993164062\n",
      "Epoch 5800, Loss: 831.6193237304688, Neurons: 11, Grad norm: 1.080e+01\n",
      "Epoch 5801, Loss: 831.578369140625, Neurons: 11, Grad norm: 1.051e+01\n",
      "Epoch 5802, Loss: 831.5379028320312, Neurons: 11, Grad norm: 1.022e+01\n",
      "Epoch 5803, Loss: 831.497802734375, Neurons: 11, Grad norm: 9.942e+00\n",
      "Epoch 5804, Loss: 831.458251953125, Neurons: 11, Grad norm: 9.675e+00\n",
      "Epoch 5805, Loss: 831.4190063476562, Neurons: 11, Grad norm: 9.422e+00\n",
      "Epoch 5806, Loss: 831.3800659179688, Neurons: 11, Grad norm: 9.175e+00\n",
      "Epoch 5807, Loss: 831.341552734375, Neurons: 11, Grad norm: 8.935e+00\n",
      "Epoch 5808, Loss: 831.3032836914062, Neurons: 11, Grad norm: 8.708e+00\n",
      "Epoch 5809, Loss: 831.2653198242188, Neurons: 11, Grad norm: 8.485e+00\n",
      "Epoch 5810, Loss: 831.2276000976562, Neurons: 11, Grad norm: 8.267e+00\n",
      "Epoch 5811, Loss: 831.1902465820312, Neurons: 11, Grad norm: 8.061e+00\n",
      "Epoch 5812, Loss: 831.1530151367188, Neurons: 11, Grad norm: 7.863e+00\n",
      "Epoch 5813, Loss: 831.1160888671875, Neurons: 11, Grad norm: 7.669e+00\n",
      "Epoch 5814, Loss: 831.0792846679688, Neurons: 11, Grad norm: 7.485e+00\n",
      "Epoch 5815, Loss: 831.042724609375, Neurons: 11, Grad norm: 7.309e+00\n",
      "Epoch 5816, Loss: 831.00634765625, Neurons: 11, Grad norm: 7.134e+00\n",
      "Epoch 5817, Loss: 830.9701538085938, Neurons: 11, Grad norm: 6.967e+00\n",
      "Epoch 5818, Loss: 830.93408203125, Neurons: 11, Grad norm: 6.807e+00\n",
      "Epoch 5819, Loss: 830.898193359375, Neurons: 11, Grad norm: 6.649e+00\n",
      "Epoch 5820, Loss: 830.8623657226562, Neurons: 11, Grad norm: 6.500e+00\n",
      "Epoch 5821, Loss: 830.8268432617188, Neurons: 11, Grad norm: 6.357e+00\n",
      "Epoch 5822, Loss: 830.7913208007812, Neurons: 11, Grad norm: 6.218e+00\n",
      "Epoch 5823, Loss: 830.7559814453125, Neurons: 11, Grad norm: 6.084e+00\n",
      "Epoch 5824, Loss: 830.720703125, Neurons: 11, Grad norm: 5.957e+00\n",
      "Epoch 5825, Loss: 830.685546875, Neurons: 11, Grad norm: 5.832e+00\n",
      "Epoch 5826, Loss: 830.6504516601562, Neurons: 11, Grad norm: 5.711e+00\n",
      "Epoch 5827, Loss: 830.6155395507812, Neurons: 11, Grad norm: 5.597e+00\n",
      "Epoch 5828, Loss: 830.5806884765625, Neurons: 11, Grad norm: 5.486e+00\n",
      "Epoch 5829, Loss: 830.5458984375, Neurons: 11, Grad norm: 5.379e+00\n",
      "Epoch 5830, Loss: 830.5111083984375, Neurons: 11, Grad norm: 5.278e+00\n",
      "Epoch 5831, Loss: 830.4765014648438, Neurons: 11, Grad norm: 5.181e+00\n",
      "Epoch 5832, Loss: 830.4419555664062, Neurons: 11, Grad norm: 5.086e+00\n",
      "Epoch 5833, Loss: 830.4073486328125, Neurons: 11, Grad norm: 4.997e+00\n",
      "Epoch 5834, Loss: 830.3729858398438, Neurons: 11, Grad norm: 4.911e+00\n",
      "Epoch 5835, Loss: 830.3385620117188, Neurons: 11, Grad norm: 4.826e+00\n",
      "Epoch 5836, Loss: 830.30419921875, Neurons: 11, Grad norm: 4.747e+00\n",
      "Epoch 5837, Loss: 830.2699584960938, Neurons: 11, Grad norm: 4.672e+00\n",
      "Epoch 5838, Loss: 830.2356567382812, Neurons: 11, Grad norm: 4.599e+00\n",
      "Epoch 5839, Loss: 830.2015380859375, Neurons: 11, Grad norm: 4.530e+00\n",
      "Epoch 5840, Loss: 830.1673583984375, Neurons: 11, Grad norm: 4.465e+00\n",
      "Epoch 5841, Loss: 830.1332397460938, Neurons: 11, Grad norm: 4.402e+00\n",
      "Epoch 5842, Loss: 830.0991821289062, Neurons: 11, Grad norm: 4.342e+00\n",
      "Epoch 5843, Loss: 830.0650024414062, Neurons: 11, Grad norm: 4.284e+00\n",
      "Epoch 5844, Loss: 830.0310668945312, Neurons: 11, Grad norm: 4.230e+00\n",
      "Epoch 5845, Loss: 829.9970703125, Neurons: 11, Grad norm: 4.178e+00\n",
      "Epoch 5846, Loss: 829.9630737304688, Neurons: 11, Grad norm: 4.129e+00\n",
      "Epoch 5847, Loss: 829.9291381835938, Neurons: 11, Grad norm: 4.084e+00\n",
      "Epoch 5848, Loss: 829.895263671875, Neurons: 11, Grad norm: 4.040e+00\n",
      "Epoch 5849, Loss: 829.8612060546875, Neurons: 11, Grad norm: 3.999e+00\n",
      "Epoch 5849, Test loss: 839.2936401367188\n",
      "Epoch 5850, Loss: 829.827392578125, Neurons: 11, Grad norm: 3.960e+00\n",
      "Epoch 5851, Loss: 829.7935791015625, Neurons: 11, Grad norm: 3.923e+00\n",
      "Epoch 5852, Loss: 829.759765625, Neurons: 11, Grad norm: 3.887e+00\n",
      "Epoch 5853, Loss: 829.7258911132812, Neurons: 11, Grad norm: 3.855e+00\n",
      "Epoch 5854, Loss: 829.6920166015625, Neurons: 11, Grad norm: 3.824e+00\n",
      "Epoch 5855, Loss: 829.6582641601562, Neurons: 11, Grad norm: 3.796e+00\n",
      "Epoch 5856, Loss: 829.6244506835938, Neurons: 11, Grad norm: 3.770e+00\n",
      "Epoch 5857, Loss: 829.5906982421875, Neurons: 11, Grad norm: 3.745e+00\n",
      "Epoch 5858, Loss: 829.556884765625, Neurons: 11, Grad norm: 3.722e+00\n",
      "Epoch 5859, Loss: 829.5230712890625, Neurons: 11, Grad norm: 3.700e+00\n",
      "Epoch 5860, Loss: 829.4892578125, Neurons: 11, Grad norm: 3.680e+00\n",
      "Epoch 5861, Loss: 829.45556640625, Neurons: 11, Grad norm: 3.661e+00\n",
      "Epoch 5862, Loss: 829.4217529296875, Neurons: 11, Grad norm: 3.644e+00\n",
      "Epoch 5863, Loss: 829.3880004882812, Neurons: 11, Grad norm: 3.629e+00\n",
      "Epoch 5864, Loss: 829.354248046875, Neurons: 11, Grad norm: 3.615e+00\n",
      "Epoch 5865, Loss: 829.3204956054688, Neurons: 11, Grad norm: 3.602e+00\n",
      "Epoch 5866, Loss: 829.2866821289062, Neurons: 11, Grad norm: 3.590e+00\n",
      "Epoch 5867, Loss: 829.2529296875, Neurons: 11, Grad norm: 3.579e+00\n",
      "Epoch 5868, Loss: 829.2191772460938, Neurons: 11, Grad norm: 3.570e+00\n",
      "Epoch 5869, Loss: 829.1853637695312, Neurons: 11, Grad norm: 3.561e+00\n",
      "Epoch 5870, Loss: 829.151611328125, Neurons: 11, Grad norm: 3.553e+00\n",
      "Epoch 5871, Loss: 829.1178588867188, Neurons: 11, Grad norm: 3.547e+00\n",
      "Epoch 5872, Loss: 829.0841064453125, Neurons: 11, Grad norm: 3.542e+00\n",
      "Epoch 5873, Loss: 829.0502319335938, Neurons: 11, Grad norm: 3.536e+00\n",
      "Epoch 5874, Loss: 829.0164794921875, Neurons: 11, Grad norm: 3.533e+00\n",
      "Epoch 5875, Loss: 828.982666015625, Neurons: 11, Grad norm: 3.529e+00\n",
      "Epoch 5876, Loss: 828.9488525390625, Neurons: 11, Grad norm: 3.526e+00\n",
      "Epoch 5877, Loss: 828.9149780273438, Neurons: 11, Grad norm: 3.524e+00\n",
      "Epoch 5878, Loss: 828.8811645507812, Neurons: 11, Grad norm: 3.523e+00\n",
      "Epoch 5879, Loss: 828.8473510742188, Neurons: 11, Grad norm: 3.522e+00\n",
      "Epoch 5880, Loss: 828.8134765625, Neurons: 11, Grad norm: 3.522e+00\n",
      "Epoch 5881, Loss: 828.7796630859375, Neurons: 11, Grad norm: 3.522e+00\n",
      "Epoch 5882, Loss: 828.7457885742188, Neurons: 11, Grad norm: 3.523e+00\n",
      "Epoch 5883, Loss: 828.7118530273438, Neurons: 11, Grad norm: 3.524e+00\n",
      "Epoch 5884, Loss: 828.677978515625, Neurons: 11, Grad norm: 3.526e+00\n",
      "Epoch 5885, Loss: 828.6441040039062, Neurons: 11, Grad norm: 3.528e+00\n",
      "Epoch 5886, Loss: 828.6101684570312, Neurons: 11, Grad norm: 3.530e+00\n",
      "Epoch 5887, Loss: 828.576171875, Neurons: 11, Grad norm: 3.533e+00\n",
      "Epoch 5888, Loss: 828.5422973632812, Neurons: 11, Grad norm: 3.536e+00\n",
      "Epoch 5889, Loss: 828.50830078125, Neurons: 11, Grad norm: 3.539e+00\n",
      "Epoch 5890, Loss: 828.4743041992188, Neurons: 11, Grad norm: 3.543e+00\n",
      "Epoch 5891, Loss: 828.4403686523438, Neurons: 11, Grad norm: 3.547e+00\n",
      "Epoch 5892, Loss: 828.40625, Neurons: 11, Grad norm: 3.551e+00\n",
      "Epoch 5893, Loss: 828.3722534179688, Neurons: 11, Grad norm: 3.555e+00\n",
      "Epoch 5894, Loss: 828.3382568359375, Neurons: 11, Grad norm: 3.559e+00\n",
      "Epoch 5895, Loss: 828.30419921875, Neurons: 11, Grad norm: 3.564e+00\n",
      "Epoch 5896, Loss: 828.2700805664062, Neurons: 11, Grad norm: 3.569e+00\n",
      "Epoch 5897, Loss: 828.2359619140625, Neurons: 11, Grad norm: 3.573e+00\n",
      "Epoch 5898, Loss: 828.201904296875, Neurons: 11, Grad norm: 3.579e+00\n",
      "Epoch 5899, Loss: 828.167724609375, Neurons: 11, Grad norm: 3.584e+00\n",
      "Epoch 5899, Test loss: 837.5465698242188\n",
      "Epoch 5900, Loss: 828.1336059570312, Neurons: 11, Grad norm: 3.589e+00\n",
      "Epoch 5901, Loss: 828.0994262695312, Neurons: 11, Grad norm: 3.594e+00\n",
      "Epoch 5902, Loss: 828.065185546875, Neurons: 11, Grad norm: 3.600e+00\n",
      "Epoch 5903, Loss: 828.0310668945312, Neurons: 11, Grad norm: 3.605e+00\n",
      "Epoch 5904, Loss: 827.9967651367188, Neurons: 11, Grad norm: 3.611e+00\n",
      "Epoch 5905, Loss: 827.9625854492188, Neurons: 11, Grad norm: 3.616e+00\n",
      "Epoch 5906, Loss: 827.9282836914062, Neurons: 11, Grad norm: 3.622e+00\n",
      "Epoch 5907, Loss: 827.8939819335938, Neurons: 11, Grad norm: 3.628e+00\n",
      "Epoch 5908, Loss: 827.8596801757812, Neurons: 11, Grad norm: 3.633e+00\n",
      "Epoch 5909, Loss: 827.8253784179688, Neurons: 11, Grad norm: 3.639e+00\n",
      "Epoch 5910, Loss: 827.791015625, Neurons: 11, Grad norm: 3.644e+00\n",
      "Epoch 5911, Loss: 827.756591796875, Neurons: 11, Grad norm: 3.650e+00\n",
      "Epoch 5912, Loss: 827.7222290039062, Neurons: 11, Grad norm: 3.656e+00\n",
      "Epoch 5913, Loss: 827.6878051757812, Neurons: 11, Grad norm: 3.662e+00\n",
      "Epoch 5914, Loss: 827.6533813476562, Neurons: 11, Grad norm: 3.667e+00\n",
      "Epoch 5915, Loss: 827.618896484375, Neurons: 11, Grad norm: 3.673e+00\n",
      "Epoch 5916, Loss: 827.5844116210938, Neurons: 11, Grad norm: 3.679e+00\n",
      "Epoch 5917, Loss: 827.5498657226562, Neurons: 11, Grad norm: 3.684e+00\n",
      "Epoch 5918, Loss: 827.515380859375, Neurons: 11, Grad norm: 3.689e+00\n",
      "Epoch 5919, Loss: 827.4808349609375, Neurons: 11, Grad norm: 3.695e+00\n",
      "Epoch 5920, Loss: 827.4462280273438, Neurons: 11, Grad norm: 3.701e+00\n",
      "Epoch 5921, Loss: 827.41162109375, Neurons: 11, Grad norm: 3.706e+00\n",
      "Epoch 5922, Loss: 827.376953125, Neurons: 11, Grad norm: 3.712e+00\n",
      "Epoch 5923, Loss: 827.34228515625, Neurons: 11, Grad norm: 3.717e+00\n",
      "Epoch 5924, Loss: 827.3076171875, Neurons: 11, Grad norm: 3.722e+00\n",
      "Epoch 5925, Loss: 827.27294921875, Neurons: 11, Grad norm: 3.728e+00\n",
      "Epoch 5926, Loss: 827.23828125, Neurons: 11, Grad norm: 3.733e+00\n",
      "Epoch 5927, Loss: 827.2034912109375, Neurons: 11, Grad norm: 3.738e+00\n",
      "Epoch 5928, Loss: 827.168701171875, Neurons: 11, Grad norm: 3.744e+00\n",
      "Epoch 5929, Loss: 827.1338500976562, Neurons: 11, Grad norm: 3.748e+00\n",
      "Epoch 5930, Loss: 827.0989990234375, Neurons: 11, Grad norm: 3.754e+00\n",
      "Epoch 5931, Loss: 827.064208984375, Neurons: 11, Grad norm: 3.758e+00\n",
      "Epoch 5932, Loss: 827.0293579101562, Neurons: 11, Grad norm: 3.763e+00\n",
      "Epoch 5933, Loss: 826.994384765625, Neurons: 11, Grad norm: 3.769e+00\n",
      "Epoch 5934, Loss: 826.95947265625, Neurons: 11, Grad norm: 3.773e+00\n",
      "Epoch 5935, Loss: 826.9244995117188, Neurons: 11, Grad norm: 3.778e+00\n",
      "Epoch 5936, Loss: 826.8895263671875, Neurons: 11, Grad norm: 3.783e+00\n",
      "Epoch 5937, Loss: 826.8544921875, Neurons: 11, Grad norm: 3.787e+00\n",
      "Epoch 5938, Loss: 826.8194580078125, Neurons: 11, Grad norm: 3.791e+00\n",
      "Epoch 5939, Loss: 826.7843627929688, Neurons: 11, Grad norm: 3.796e+00\n",
      "Epoch 5940, Loss: 826.749267578125, Neurons: 11, Grad norm: 3.800e+00\n",
      "Epoch 5941, Loss: 826.7141723632812, Neurons: 11, Grad norm: 3.805e+00\n",
      "Epoch 5942, Loss: 826.678955078125, Neurons: 11, Grad norm: 3.809e+00\n",
      "Epoch 5943, Loss: 826.643798828125, Neurons: 11, Grad norm: 3.813e+00\n",
      "Epoch 5944, Loss: 826.6085815429688, Neurons: 11, Grad norm: 3.817e+00\n",
      "Epoch 5945, Loss: 826.5733032226562, Neurons: 11, Grad norm: 3.822e+00\n",
      "Epoch 5946, Loss: 826.5380249023438, Neurons: 11, Grad norm: 3.826e+00\n",
      "Epoch 5947, Loss: 826.5028076171875, Neurons: 11, Grad norm: 3.829e+00\n",
      "Epoch 5948, Loss: 826.4674072265625, Neurons: 11, Grad norm: 3.834e+00\n",
      "Epoch 5949, Loss: 826.4320678710938, Neurons: 11, Grad norm: 3.838e+00\n",
      "Epoch 5949, Test loss: 835.7568969726562\n",
      "Epoch 5950, Loss: 826.3966674804688, Neurons: 11, Grad norm: 3.841e+00\n",
      "Epoch 5951, Loss: 826.3612670898438, Neurons: 11, Grad norm: 3.845e+00\n",
      "Epoch 5952, Loss: 826.3258056640625, Neurons: 11, Grad norm: 3.849e+00\n",
      "Epoch 5953, Loss: 826.290283203125, Neurons: 11, Grad norm: 3.852e+00\n",
      "Epoch 5954, Loss: 826.2547607421875, Neurons: 11, Grad norm: 3.856e+00\n",
      "Epoch 5955, Loss: 826.2192993164062, Neurons: 11, Grad norm: 3.859e+00\n",
      "Epoch 5956, Loss: 826.1837158203125, Neurons: 11, Grad norm: 3.863e+00\n",
      "Epoch 5957, Loss: 826.1480712890625, Neurons: 11, Grad norm: 3.866e+00\n",
      "Epoch 5958, Loss: 826.1124877929688, Neurons: 11, Grad norm: 3.869e+00\n",
      "Epoch 5959, Loss: 826.0767822265625, Neurons: 11, Grad norm: 3.873e+00\n",
      "Epoch 5960, Loss: 826.0410766601562, Neurons: 11, Grad norm: 3.876e+00\n",
      "Epoch 5961, Loss: 826.00537109375, Neurons: 11, Grad norm: 3.879e+00\n",
      "Epoch 5962, Loss: 825.9696044921875, Neurons: 11, Grad norm: 3.883e+00\n",
      "Epoch 5963, Loss: 825.933837890625, Neurons: 11, Grad norm: 3.886e+00\n",
      "Epoch 5964, Loss: 825.8980102539062, Neurons: 11, Grad norm: 3.888e+00\n",
      "Epoch 5965, Loss: 825.8621826171875, Neurons: 11, Grad norm: 3.892e+00\n",
      "Epoch 5966, Loss: 825.8262939453125, Neurons: 11, Grad norm: 3.895e+00\n",
      "Epoch 5967, Loss: 825.7904052734375, Neurons: 11, Grad norm: 3.897e+00\n",
      "Epoch 5968, Loss: 825.75439453125, Neurons: 11, Grad norm: 3.900e+00\n",
      "Epoch 5969, Loss: 825.7184448242188, Neurons: 11, Grad norm: 3.903e+00\n",
      "Epoch 5970, Loss: 825.682373046875, Neurons: 11, Grad norm: 3.906e+00\n",
      "Epoch 5971, Loss: 825.6463012695312, Neurons: 11, Grad norm: 3.908e+00\n",
      "Epoch 5972, Loss: 825.6102905273438, Neurons: 11, Grad norm: 3.911e+00\n",
      "Epoch 5973, Loss: 825.5741577148438, Neurons: 11, Grad norm: 3.914e+00\n",
      "Epoch 5974, Loss: 825.5380249023438, Neurons: 11, Grad norm: 3.916e+00\n",
      "Epoch 5975, Loss: 825.5018310546875, Neurons: 11, Grad norm: 3.919e+00\n",
      "Epoch 5976, Loss: 825.4656372070312, Neurons: 11, Grad norm: 3.921e+00\n",
      "Epoch 5977, Loss: 825.4293212890625, Neurons: 11, Grad norm: 3.924e+00\n",
      "Epoch 5978, Loss: 825.39306640625, Neurons: 11, Grad norm: 3.926e+00\n",
      "Epoch 5979, Loss: 825.3567504882812, Neurons: 11, Grad norm: 3.929e+00\n",
      "Epoch 5980, Loss: 825.3203735351562, Neurons: 11, Grad norm: 3.931e+00\n",
      "Epoch 5981, Loss: 825.2839965820312, Neurons: 11, Grad norm: 3.933e+00\n",
      "Epoch 5982, Loss: 825.24755859375, Neurons: 11, Grad norm: 3.936e+00\n",
      "Epoch 5983, Loss: 825.2111206054688, Neurons: 11, Grad norm: 3.937e+00\n",
      "Epoch 5984, Loss: 825.1746215820312, Neurons: 11, Grad norm: 3.939e+00\n",
      "Epoch 5985, Loss: 825.13818359375, Neurons: 11, Grad norm: 3.942e+00\n",
      "Epoch 5986, Loss: 825.1015014648438, Neurons: 11, Grad norm: 3.944e+00\n",
      "Epoch 5987, Loss: 825.0650024414062, Neurons: 11, Grad norm: 3.946e+00\n",
      "Epoch 5988, Loss: 825.0282592773438, Neurons: 11, Grad norm: 3.948e+00\n",
      "Epoch 5989, Loss: 824.9916381835938, Neurons: 11, Grad norm: 3.950e+00\n",
      "Epoch 5990, Loss: 824.9549560546875, Neurons: 11, Grad norm: 3.952e+00\n",
      "Epoch 5991, Loss: 824.9181518554688, Neurons: 11, Grad norm: 3.955e+00\n",
      "Epoch 5992, Loss: 824.8814697265625, Neurons: 11, Grad norm: 3.956e+00\n",
      "Epoch 5993, Loss: 824.8446655273438, Neurons: 11, Grad norm: 3.958e+00\n",
      "Epoch 5994, Loss: 824.8078002929688, Neurons: 11, Grad norm: 3.961e+00\n",
      "Epoch 5995, Loss: 824.7709350585938, Neurons: 11, Grad norm: 3.961e+00\n",
      "Epoch 5996, Loss: 824.7340087890625, Neurons: 11, Grad norm: 3.964e+00\n",
      "Epoch 5997, Loss: 824.6970825195312, Neurons: 11, Grad norm: 3.966e+00\n",
      "Epoch 5998, Loss: 824.6600341796875, Neurons: 11, Grad norm: 3.967e+00\n",
      "Epoch 5999, Loss: 824.6229858398438, Neurons: 11, Grad norm: 3.969e+00\n",
      "Epoch 5999, Test loss: 833.8887939453125\n",
      "Epoch 6000, Loss: 824.5859985351562, Neurons: 11, Grad norm: 3.971e+00\n",
      "Epoch 6001, Loss: 824.5488891601562, Neurons: 11, Grad norm: 3.973e+00\n",
      "Epoch 6002, Loss: 824.51171875, Neurons: 11, Grad norm: 3.975e+00\n",
      "Epoch 6003, Loss: 824.474609375, Neurons: 11, Grad norm: 3.976e+00\n",
      "Epoch 6004, Loss: 824.437255859375, Neurons: 11, Grad norm: 3.978e+00\n",
      "Epoch 6005, Loss: 824.4000854492188, Neurons: 11, Grad norm: 3.980e+00\n",
      "Epoch 6006, Loss: 824.36279296875, Neurons: 11, Grad norm: 3.981e+00\n",
      "Epoch 6007, Loss: 824.3255004882812, Neurons: 11, Grad norm: 3.983e+00\n",
      "Epoch 6008, Loss: 824.2881469726562, Neurons: 11, Grad norm: 3.985e+00\n",
      "Epoch 6009, Loss: 824.250732421875, Neurons: 11, Grad norm: 3.986e+00\n",
      "Epoch 6010, Loss: 824.2132568359375, Neurons: 11, Grad norm: 3.987e+00\n",
      "Epoch 6011, Loss: 824.17578125, Neurons: 11, Grad norm: 3.990e+00\n",
      "Epoch 6012, Loss: 824.1383056640625, Neurons: 11, Grad norm: 3.991e+00\n",
      "Epoch 6013, Loss: 824.1007080078125, Neurons: 11, Grad norm: 3.992e+00\n",
      "Epoch 6014, Loss: 824.0631103515625, Neurons: 11, Grad norm: 3.995e+00\n",
      "Epoch 6015, Loss: 824.0254516601562, Neurons: 11, Grad norm: 3.996e+00\n",
      "Epoch 6016, Loss: 823.98779296875, Neurons: 11, Grad norm: 3.997e+00\n",
      "Epoch 6017, Loss: 823.9500122070312, Neurons: 11, Grad norm: 3.999e+00\n",
      "Epoch 6018, Loss: 823.912353515625, Neurons: 11, Grad norm: 4.000e+00\n",
      "Epoch 6019, Loss: 823.87451171875, Neurons: 11, Grad norm: 4.002e+00\n",
      "Epoch 6020, Loss: 823.836669921875, Neurons: 11, Grad norm: 4.004e+00\n",
      "Epoch 6021, Loss: 823.7988891601562, Neurons: 11, Grad norm: 4.005e+00\n",
      "Epoch 6022, Loss: 823.760986328125, Neurons: 11, Grad norm: 4.007e+00\n",
      "Epoch 6023, Loss: 823.7229614257812, Neurons: 11, Grad norm: 4.008e+00\n",
      "Epoch 6024, Loss: 823.6849975585938, Neurons: 11, Grad norm: 4.009e+00\n",
      "Epoch 6025, Loss: 823.64697265625, Neurons: 11, Grad norm: 4.011e+00\n",
      "Epoch 6026, Loss: 823.60888671875, Neurons: 11, Grad norm: 4.013e+00\n",
      "Epoch 6027, Loss: 823.57080078125, Neurons: 11, Grad norm: 4.014e+00\n",
      "Epoch 6028, Loss: 823.5325927734375, Neurons: 11, Grad norm: 4.016e+00\n",
      "Epoch 6029, Loss: 823.4945068359375, Neurons: 11, Grad norm: 4.017e+00\n",
      "Epoch 6030, Loss: 823.4561767578125, Neurons: 11, Grad norm: 4.019e+00\n",
      "Epoch 6031, Loss: 823.4179077148438, Neurons: 11, Grad norm: 4.021e+00\n",
      "Epoch 6032, Loss: 823.3795776367188, Neurons: 11, Grad norm: 4.021e+00\n",
      "Epoch 6033, Loss: 823.34130859375, Neurons: 11, Grad norm: 4.024e+00\n",
      "Epoch 6034, Loss: 823.3028564453125, Neurons: 11, Grad norm: 4.025e+00\n",
      "Epoch 6035, Loss: 823.2644653320312, Neurons: 11, Grad norm: 4.026e+00\n",
      "Epoch 6036, Loss: 823.2259521484375, Neurons: 11, Grad norm: 4.029e+00\n",
      "Epoch 6037, Loss: 823.1875, Neurons: 11, Grad norm: 4.029e+00\n",
      "Epoch 6038, Loss: 823.14892578125, Neurons: 11, Grad norm: 4.031e+00\n",
      "Epoch 6039, Loss: 823.1102905273438, Neurons: 11, Grad norm: 4.033e+00\n",
      "Epoch 6040, Loss: 823.0716552734375, Neurons: 11, Grad norm: 4.034e+00\n",
      "Epoch 6041, Loss: 823.032958984375, Neurons: 11, Grad norm: 4.037e+00\n",
      "Epoch 6042, Loss: 822.9942016601562, Neurons: 11, Grad norm: 4.037e+00\n",
      "Epoch 6043, Loss: 822.9555053710938, Neurons: 11, Grad norm: 4.039e+00\n",
      "Epoch 6044, Loss: 822.9166870117188, Neurons: 11, Grad norm: 4.041e+00\n",
      "Epoch 6045, Loss: 822.8778076171875, Neurons: 11, Grad norm: 4.042e+00\n",
      "Epoch 6046, Loss: 822.8388671875, Neurons: 11, Grad norm: 4.044e+00\n",
      "Epoch 6047, Loss: 822.7999267578125, Neurons: 11, Grad norm: 4.046e+00\n",
      "Epoch 6048, Loss: 822.760986328125, Neurons: 11, Grad norm: 4.047e+00\n",
      "Epoch 6049, Loss: 822.7219848632812, Neurons: 11, Grad norm: 4.049e+00\n",
      "Epoch 6049, Test loss: 831.921142578125\n",
      "Epoch 6050, Loss: 822.682861328125, Neurons: 11, Grad norm: 4.050e+00\n",
      "Epoch 6051, Loss: 822.643798828125, Neurons: 11, Grad norm: 4.052e+00\n",
      "Epoch 6052, Loss: 822.6046752929688, Neurons: 11, Grad norm: 4.054e+00\n",
      "Epoch 6053, Loss: 822.5654907226562, Neurons: 11, Grad norm: 4.055e+00\n",
      "Epoch 6054, Loss: 822.5261840820312, Neurons: 11, Grad norm: 4.057e+00\n",
      "Epoch 6055, Loss: 822.4869995117188, Neurons: 11, Grad norm: 4.059e+00\n",
      "Epoch 6056, Loss: 822.4475708007812, Neurons: 11, Grad norm: 4.061e+00\n",
      "Epoch 6057, Loss: 822.408203125, Neurons: 11, Grad norm: 4.063e+00\n",
      "Epoch 6058, Loss: 822.368896484375, Neurons: 11, Grad norm: 4.064e+00\n",
      "Epoch 6059, Loss: 822.3294067382812, Neurons: 11, Grad norm: 4.067e+00\n",
      "Epoch 6060, Loss: 822.2898559570312, Neurons: 11, Grad norm: 4.068e+00\n",
      "Epoch 6061, Loss: 822.2503662109375, Neurons: 11, Grad norm: 4.070e+00\n",
      "Epoch 6062, Loss: 822.210693359375, Neurons: 11, Grad norm: 4.073e+00\n",
      "Epoch 6063, Loss: 822.1710815429688, Neurons: 11, Grad norm: 4.073e+00\n",
      "Epoch 6064, Loss: 822.1314086914062, Neurons: 11, Grad norm: 4.076e+00\n",
      "Epoch 6065, Loss: 822.0916748046875, Neurons: 11, Grad norm: 4.078e+00\n",
      "Epoch 6066, Loss: 822.0519409179688, Neurons: 11, Grad norm: 4.079e+00\n",
      "Epoch 6067, Loss: 822.01220703125, Neurons: 11, Grad norm: 4.083e+00\n",
      "Epoch 6068, Loss: 821.9722900390625, Neurons: 11, Grad norm: 4.083e+00\n",
      "Epoch 6069, Loss: 821.932373046875, Neurons: 11, Grad norm: 4.086e+00\n",
      "Epoch 6070, Loss: 821.8924560546875, Neurons: 11, Grad norm: 4.088e+00\n",
      "Epoch 6071, Loss: 821.8524780273438, Neurons: 11, Grad norm: 4.089e+00\n",
      "Epoch 6072, Loss: 821.8124389648438, Neurons: 11, Grad norm: 4.093e+00\n",
      "Epoch 6073, Loss: 821.7723999023438, Neurons: 11, Grad norm: 4.094e+00\n",
      "Epoch 6074, Loss: 821.732177734375, Neurons: 11, Grad norm: 4.096e+00\n",
      "Epoch 6075, Loss: 821.6920166015625, Neurons: 11, Grad norm: 4.099e+00\n",
      "Epoch 6076, Loss: 821.6517944335938, Neurons: 11, Grad norm: 4.101e+00\n",
      "Epoch 6077, Loss: 821.611572265625, Neurons: 11, Grad norm: 4.103e+00\n",
      "Epoch 6078, Loss: 821.5712890625, Neurons: 11, Grad norm: 4.105e+00\n",
      "Epoch 6079, Loss: 821.5308837890625, Neurons: 11, Grad norm: 4.108e+00\n",
      "Epoch 6080, Loss: 821.490478515625, Neurons: 11, Grad norm: 4.110e+00\n",
      "Epoch 6081, Loss: 821.4500732421875, Neurons: 11, Grad norm: 4.112e+00\n",
      "Epoch 6082, Loss: 821.4096069335938, Neurons: 11, Grad norm: 4.115e+00\n",
      "Epoch 6083, Loss: 821.3690795898438, Neurons: 11, Grad norm: 4.117e+00\n",
      "Epoch 6084, Loss: 821.3284301757812, Neurons: 11, Grad norm: 4.120e+00\n",
      "Epoch 6085, Loss: 821.287841796875, Neurons: 11, Grad norm: 4.123e+00\n",
      "Epoch 6086, Loss: 821.2471923828125, Neurons: 11, Grad norm: 4.124e+00\n",
      "Epoch 6087, Loss: 821.2064208984375, Neurons: 11, Grad norm: 4.128e+00\n",
      "Epoch 6088, Loss: 821.1656494140625, Neurons: 11, Grad norm: 4.130e+00\n",
      "Epoch 6089, Loss: 821.1248168945312, Neurons: 11, Grad norm: 4.133e+00\n",
      "Epoch 6090, Loss: 821.083984375, Neurons: 11, Grad norm: 4.136e+00\n",
      "Epoch 6091, Loss: 821.0430297851562, Neurons: 11, Grad norm: 4.138e+00\n",
      "Epoch 6092, Loss: 821.0020751953125, Neurons: 11, Grad norm: 4.141e+00\n",
      "Epoch 6093, Loss: 820.9611206054688, Neurons: 11, Grad norm: 4.608e+00\n",
      "Epoch 6094, Loss: 820.9199829101562, Neurons: 11, Grad norm: 4.120e+00\n",
      "Epoch 6095, Loss: 820.8789672851562, Neurons: 11, Grad norm: 4.764e+00\n",
      "Epoch 6096, Loss: 820.837890625, Neurons: 11, Grad norm: 4.583e+00\n",
      "Epoch 6097, Loss: 820.7967529296875, Neurons: 11, Grad norm: 4.404e+00\n",
      "Epoch 6098, Loss: 820.7555541992188, Neurons: 11, Grad norm: 3.918e+00\n",
      "Epoch 6099, Loss: 820.71435546875, Neurons: 11, Grad norm: 4.011e+00\n",
      "Epoch 6099, Test loss: 829.8379516601562\n",
      "Epoch 6100, Loss: 820.6729736328125, Neurons: 11, Grad norm: 4.482e+00\n",
      "Epoch 6101, Loss: 820.6316528320312, Neurons: 11, Grad norm: 4.350e+00\n",
      "Epoch 6102, Loss: 820.5901489257812, Neurons: 11, Grad norm: 4.218e+00\n",
      "Epoch 6103, Loss: 820.5487060546875, Neurons: 11, Grad norm: 3.925e+00\n",
      "Epoch 6104, Loss: 820.5072021484375, Neurons: 11, Grad norm: 3.967e+00\n",
      "Epoch 6105, Loss: 820.465576171875, Neurons: 11, Grad norm: 4.871e+00\n",
      "Epoch 6106, Loss: 820.424072265625, Neurons: 11, Grad norm: 4.953e+00\n",
      "Epoch 6107, Loss: 820.3825073242188, Neurons: 11, Grad norm: 5.076e+00\n",
      "Epoch 6108, Loss: 820.3408203125, Neurons: 11, Grad norm: 4.559e+00\n",
      "Epoch 6109, Loss: 820.299072265625, Neurons: 11, Grad norm: 4.383e+00\n",
      "Epoch 6110, Loss: 820.2572631835938, Neurons: 11, Grad norm: 4.621e+00\n",
      "Epoch 6111, Loss: 820.2154541015625, Neurons: 11, Grad norm: 4.717e+00\n",
      "Epoch 6112, Loss: 820.173583984375, Neurons: 11, Grad norm: 4.989e+00\n",
      "Epoch 6113, Loss: 820.1316528320312, Neurons: 11, Grad norm: 4.568e+00\n",
      "Epoch 6114, Loss: 820.0896606445312, Neurons: 11, Grad norm: 4.468e+00\n",
      "Epoch 6115, Loss: 820.047607421875, Neurons: 11, Grad norm: 3.984e+00\n",
      "Epoch 6116, Loss: 820.00537109375, Neurons: 11, Grad norm: 3.982e+00\n",
      "Epoch 6117, Loss: 819.9632568359375, Neurons: 11, Grad norm: 4.020e+00\n",
      "Epoch 6118, Loss: 819.9210815429688, Neurons: 11, Grad norm: 4.006e+00\n",
      "Epoch 6119, Loss: 819.87890625, Neurons: 11, Grad norm: 4.031e+00\n",
      "Epoch 6120, Loss: 819.8366088867188, Neurons: 11, Grad norm: 4.021e+00\n",
      "Epoch 6121, Loss: 819.794189453125, Neurons: 11, Grad norm: 4.011e+00\n",
      "Epoch 6122, Loss: 819.7518920898438, Neurons: 11, Grad norm: 4.029e+00\n",
      "Epoch 6123, Loss: 819.7093505859375, Neurons: 11, Grad norm: 4.574e+00\n",
      "Epoch 6124, Loss: 819.6669921875, Neurons: 11, Grad norm: 4.611e+00\n",
      "Epoch 6125, Loss: 819.6244506835938, Neurons: 11, Grad norm: 4.873e+00\n",
      "Epoch 6126, Loss: 819.5819091796875, Neurons: 11, Grad norm: 4.720e+00\n",
      "Epoch 6127, Loss: 819.5392456054688, Neurons: 11, Grad norm: 7.863e+00\n",
      "Epoch 6128, Loss: 819.4965209960938, Neurons: 11, Grad norm: 6.915e+00\n",
      "Epoch 6129, Loss: 819.4537353515625, Neurons: 11, Grad norm: 9.603e+00\n",
      "Epoch 6130, Loss: 819.4110107421875, Neurons: 11, Grad norm: 9.907e+00\n",
      "Epoch 6131, Loss: 819.3681640625, Neurons: 11, Grad norm: 8.775e+00\n",
      "Epoch 6132, Loss: 819.3253173828125, Neurons: 11, Grad norm: 5.349e+00\n",
      "Epoch 6133, Loss: 819.2824096679688, Neurons: 11, Grad norm: 4.068e+00\n",
      "Epoch 6134, Loss: 819.2393798828125, Neurons: 11, Grad norm: 5.751e+00\n",
      "Epoch 6135, Loss: 819.1963500976562, Neurons: 11, Grad norm: 7.376e+00\n",
      "Epoch 6136, Loss: 819.1532592773438, Neurons: 11, Grad norm: 8.092e+00\n",
      "Epoch 6137, Loss: 819.110107421875, Neurons: 11, Grad norm: 7.002e+00\n",
      "Epoch 6138, Loss: 819.06689453125, Neurons: 11, Grad norm: 5.678e+00\n",
      "Epoch 6139, Loss: 819.0235595703125, Neurons: 11, Grad norm: 4.128e+00\n",
      "Epoch 6140, Loss: 818.9802856445312, Neurons: 11, Grad norm: 4.452e+00\n",
      "Epoch 6141, Loss: 818.9368896484375, Neurons: 11, Grad norm: 5.947e+00\n",
      "Epoch 6142, Loss: 818.8934936523438, Neurons: 11, Grad norm: 6.389e+00\n",
      "Epoch 6143, Loss: 818.8500366210938, Neurons: 11, Grad norm: 6.447e+00\n",
      "Epoch 6144, Loss: 818.8065185546875, Neurons: 11, Grad norm: 5.372e+00\n",
      "Epoch 6145, Loss: 818.762939453125, Neurons: 11, Grad norm: 4.665e+00\n",
      "Epoch 6146, Loss: 818.7192993164062, Neurons: 11, Grad norm: 1.150e+01\n",
      "Epoch 6147, Loss: 818.6756591796875, Neurons: 11, Grad norm: 1.435e+01\n",
      "Epoch 6148, Loss: 818.6319580078125, Neurons: 11, Grad norm: 2.336e+01\n",
      "Epoch 6149, Loss: 818.5885009765625, Neurons: 11, Grad norm: 2.728e+01\n",
      "Epoch 6149, Test loss: 827.6415405273438\n",
      "Epoch 6150, Loss: 818.5448608398438, Neurons: 11, Grad norm: 2.543e+01\n",
      "Epoch 6151, Loss: 818.5008544921875, Neurons: 11, Grad norm: 1.729e+01\n",
      "Epoch 6152, Loss: 818.456787109375, Neurons: 11, Grad norm: 8.464e+00\n",
      "Epoch 6153, Loss: 818.4126586914062, Neurons: 11, Grad norm: 6.231e+00\n",
      "Epoch 6154, Loss: 818.36865234375, Neurons: 11, Grad norm: 1.386e+01\n",
      "Epoch 6155, Loss: 818.32470703125, Neurons: 11, Grad norm: 1.894e+01\n",
      "Epoch 6156, Loss: 818.2805786132812, Neurons: 11, Grad norm: 1.952e+01\n",
      "Epoch 6157, Loss: 818.2364501953125, Neurons: 11, Grad norm: 1.632e+01\n",
      "Epoch 6158, Loss: 818.1920776367188, Neurons: 11, Grad norm: 9.246e+00\n",
      "Epoch 6159, Loss: 818.147705078125, Neurons: 11, Grad norm: 4.418e+00\n",
      "Epoch 6160, Loss: 818.1033935546875, Neurons: 11, Grad norm: 8.278e+00\n",
      "Epoch 6161, Loss: 818.0589599609375, Neurons: 11, Grad norm: 1.258e+01\n",
      "Epoch 6162, Loss: 818.0145263671875, Neurons: 11, Grad norm: 1.478e+01\n",
      "Epoch 6163, Loss: 817.9700317382812, Neurons: 11, Grad norm: 1.355e+01\n",
      "Epoch 6164, Loss: 817.9254760742188, Neurons: 11, Grad norm: 1.042e+01\n",
      "Epoch 6165, Loss: 817.8807983398438, Neurons: 11, Grad norm: 5.544e+00\n",
      "Epoch 6166, Loss: 817.8360595703125, Neurons: 11, Grad norm: 4.582e+00\n",
      "Epoch 6167, Loss: 817.7913208007812, Neurons: 11, Grad norm: 8.102e+00\n",
      "Epoch 6168, Loss: 817.74658203125, Neurons: 11, Grad norm: 1.024e+01\n",
      "Epoch 6169, Loss: 817.7017822265625, Neurons: 11, Grad norm: 1.122e+01\n",
      "Epoch 6170, Loss: 817.6568603515625, Neurons: 11, Grad norm: 9.755e+00\n",
      "Epoch 6171, Loss: 817.6118774414062, Neurons: 11, Grad norm: 7.634e+00\n",
      "Epoch 6172, Loss: 817.5667724609375, Neurons: 11, Grad norm: 4.802e+00\n",
      "Epoch 6173, Loss: 817.5216674804688, Neurons: 11, Grad norm: 4.667e+00\n",
      "Epoch 6174, Loss: 817.4765625, Neurons: 11, Grad norm: 6.810e+00\n",
      "Epoch 6175, Loss: 817.4314575195312, Neurons: 11, Grad norm: 7.957e+00\n",
      "Epoch 6176, Loss: 817.3861083984375, Neurons: 11, Grad norm: 8.756e+00\n",
      "Epoch 6177, Loss: 817.3408203125, Neurons: 11, Grad norm: 7.801e+00\n",
      "Epoch 6178, Loss: 817.2954711914062, Neurons: 11, Grad norm: 6.763e+00\n",
      "Epoch 6179, Loss: 817.2500610351562, Neurons: 11, Grad norm: 4.966e+00\n",
      "Epoch 6180, Loss: 817.20458984375, Neurons: 11, Grad norm: 1.161e+01\n",
      "Epoch 6181, Loss: 817.1589965820312, Neurons: 11, Grad norm: 1.163e+01\n",
      "Epoch 6182, Loss: 817.1134643554688, Neurons: 11, Grad norm: 1.917e+01\n",
      "Epoch 6183, Loss: 817.0680541992188, Neurons: 11, Grad norm: 2.358e+01\n",
      "Epoch 6184, Loss: 817.0223999023438, Neurons: 11, Grad norm: 2.416e+01\n",
      "Epoch 6185, Loss: 816.9766235351562, Neurons: 11, Grad norm: 1.937e+01\n",
      "Epoch 6186, Loss: 816.9306640625, Neurons: 11, Grad norm: 1.399e+01\n",
      "Epoch 6187, Loss: 816.8847045898438, Neurons: 11, Grad norm: 5.978e+00\n",
      "Epoch 6188, Loss: 816.838623046875, Neurons: 11, Grad norm: 6.116e+00\n",
      "Epoch 6189, Loss: 816.7926025390625, Neurons: 11, Grad norm: 1.179e+01\n",
      "Epoch 6190, Loss: 816.7466430664062, Neurons: 11, Grad norm: 1.578e+01\n",
      "Epoch 6191, Loss: 816.7005615234375, Neurons: 11, Grad norm: 1.754e+01\n",
      "Epoch 6192, Loss: 816.6544189453125, Neurons: 11, Grad norm: 1.514e+01\n",
      "Epoch 6193, Loss: 816.608154296875, Neurons: 11, Grad norm: 1.245e+01\n",
      "Epoch 6194, Loss: 816.561767578125, Neurons: 11, Grad norm: 7.051e+00\n",
      "Epoch 6195, Loss: 816.515380859375, Neurons: 11, Grad norm: 4.624e+00\n",
      "Epoch 6196, Loss: 816.468994140625, Neurons: 11, Grad norm: 7.120e+00\n",
      "Epoch 6197, Loss: 816.4224853515625, Neurons: 11, Grad norm: 1.014e+01\n",
      "Epoch 6198, Loss: 816.3758544921875, Neurons: 11, Grad norm: 1.250e+01\n",
      "Epoch 6199, Loss: 816.329345703125, Neurons: 11, Grad norm: 1.186e+01\n",
      "Epoch 6199, Test loss: 825.2734375\n",
      "Epoch 6200, Loss: 816.2826538085938, Neurons: 11, Grad norm: 1.126e+01\n",
      "Epoch 6201, Loss: 816.2359008789062, Neurons: 11, Grad norm: 8.099e+00\n",
      "Epoch 6202, Loss: 816.1890869140625, Neurons: 11, Grad norm: 5.860e+00\n",
      "Epoch 6203, Loss: 816.1421508789062, Neurons: 11, Grad norm: 4.792e+00\n",
      "Epoch 6204, Loss: 816.09521484375, Neurons: 11, Grad norm: 5.929e+00\n",
      "Epoch 6205, Loss: 816.0482788085938, Neurons: 11, Grad norm: 8.129e+00\n",
      "Epoch 6206, Loss: 816.001220703125, Neurons: 11, Grad norm: 8.666e+00\n",
      "Epoch 6207, Loss: 815.9541015625, Neurons: 11, Grad norm: 9.641e+00\n",
      "Epoch 6208, Loss: 815.9068603515625, Neurons: 11, Grad norm: 8.456e+00\n",
      "Epoch 6209, Loss: 815.8595581054688, Neurons: 11, Grad norm: 7.666e+00\n",
      "Epoch 6210, Loss: 815.812255859375, Neurons: 11, Grad norm: 6.001e+00\n",
      "Epoch 6211, Loss: 815.7648315429688, Neurons: 11, Grad norm: 5.192e+00\n",
      "Epoch 6212, Loss: 815.7173461914062, Neurons: 11, Grad norm: 5.067e+00\n",
      "Epoch 6213, Loss: 815.6697998046875, Neurons: 11, Grad norm: 5.458e+00\n",
      "Epoch 6214, Loss: 815.6221923828125, Neurons: 11, Grad norm: 6.691e+00\n",
      "Epoch 6215, Loss: 815.5745239257812, Neurons: 11, Grad norm: 6.851e+00\n",
      "Epoch 6216, Loss: 815.5267333984375, Neurons: 11, Grad norm: 7.490e+00\n",
      "Epoch 6217, Loss: 815.4789428710938, Neurons: 11, Grad norm: 7.030e+00\n",
      "Epoch 6218, Loss: 815.4310913085938, Neurons: 11, Grad norm: 6.987e+00\n",
      "Epoch 6219, Loss: 815.383056640625, Neurons: 11, Grad norm: 6.037e+00\n",
      "Epoch 6220, Loss: 815.3349609375, Neurons: 11, Grad norm: 5.852e+00\n",
      "Epoch 6221, Loss: 815.286865234375, Neurons: 11, Grad norm: 5.201e+00\n",
      "Epoch 6222, Loss: 815.2387084960938, Neurons: 11, Grad norm: 5.147e+00\n",
      "Epoch 6223, Loss: 815.1903686523438, Neurons: 11, Grad norm: 5.278e+00\n",
      "Epoch 6224, Loss: 815.14208984375, Neurons: 11, Grad norm: 5.391e+00\n",
      "Epoch 6225, Loss: 815.0936889648438, Neurons: 11, Grad norm: 5.910e+00\n",
      "Epoch 6226, Loss: 815.045166015625, Neurons: 11, Grad norm: 5.857e+00\n",
      "Epoch 6227, Loss: 814.99658203125, Neurons: 11, Grad norm: 6.408e+00\n",
      "Epoch 6228, Loss: 814.9478759765625, Neurons: 11, Grad norm: 6.102e+00\n",
      "Epoch 6229, Loss: 814.899169921875, Neurons: 11, Grad norm: 6.457e+00\n",
      "Epoch 6230, Loss: 814.8504028320312, Neurons: 11, Grad norm: 6.066e+00\n",
      "Epoch 6231, Loss: 814.801513671875, Neurons: 11, Grad norm: 6.255e+00\n",
      "Epoch 6232, Loss: 814.7525634765625, Neurons: 11, Grad norm: 5.828e+00\n",
      "Epoch 6233, Loss: 814.7034912109375, Neurons: 11, Grad norm: 5.991e+00\n",
      "Epoch 6234, Loss: 814.6543579101562, Neurons: 11, Grad norm: 5.597e+00\n",
      "Epoch 6235, Loss: 814.6051635742188, Neurons: 11, Grad norm: 5.728e+00\n",
      "Epoch 6236, Loss: 814.555908203125, Neurons: 11, Grad norm: 5.468e+00\n",
      "Epoch 6237, Loss: 814.5064697265625, Neurons: 11, Grad norm: 5.553e+00\n",
      "Epoch 6238, Loss: 814.4570922851562, Neurons: 11, Grad norm: 5.419e+00\n",
      "Epoch 6239, Loss: 814.4075317382812, Neurons: 11, Grad norm: 5.486e+00\n",
      "Epoch 6240, Loss: 814.35791015625, Neurons: 11, Grad norm: 5.433e+00\n",
      "Epoch 6241, Loss: 814.3082885742188, Neurons: 11, Grad norm: 5.470e+00\n",
      "Epoch 6242, Loss: 814.2584838867188, Neurons: 11, Grad norm: 5.479e+00\n",
      "Epoch 6243, Loss: 814.2085571289062, Neurons: 11, Grad norm: 5.481e+00\n",
      "Epoch 6244, Loss: 814.15869140625, Neurons: 11, Grad norm: 5.537e+00\n",
      "Epoch 6245, Loss: 814.1085815429688, Neurons: 11, Grad norm: 5.514e+00\n",
      "Epoch 6246, Loss: 814.0584106445312, Neurons: 11, Grad norm: 5.618e+00\n",
      "Epoch 6247, Loss: 814.0082397460938, Neurons: 11, Grad norm: 5.563e+00\n",
      "Epoch 6248, Loss: 813.9579467773438, Neurons: 11, Grad norm: 5.722e+00\n",
      "Epoch 6249, Loss: 813.9075317382812, Neurons: 11, Grad norm: 5.642e+00\n",
      "Epoch 6249, Test loss: 822.730224609375\n",
      "Epoch 6250, Loss: 813.8570556640625, Neurons: 11, Grad norm: 5.876e+00\n",
      "Epoch 6251, Loss: 813.8064575195312, Neurons: 11, Grad norm: 5.791e+00\n",
      "Epoch 6252, Loss: 813.7557983398438, Neurons: 11, Grad norm: 6.168e+00\n",
      "Epoch 6253, Loss: 813.705078125, Neurons: 11, Grad norm: 6.100e+00\n",
      "Epoch 6254, Loss: 813.6541748046875, Neurons: 11, Grad norm: 6.760e+00\n",
      "Epoch 6255, Loss: 813.603271484375, Neurons: 11, Grad norm: 6.827e+00\n",
      "Epoch 6256, Loss: 813.5523071289062, Neurons: 11, Grad norm: 7.991e+00\n",
      "Epoch 6257, Loss: 813.5010986328125, Neurons: 11, Grad norm: 8.515e+00\n",
      "Epoch 6258, Loss: 813.4498901367188, Neurons: 11, Grad norm: 1.059e+01\n",
      "Epoch 6259, Loss: 813.3985595703125, Neurons: 11, Grad norm: 1.211e+01\n",
      "Epoch 6260, Loss: 813.34716796875, Neurons: 11, Grad norm: 1.578e+01\n",
      "Epoch 6261, Loss: 813.2957153320312, Neurons: 11, Grad norm: 1.916e+01\n",
      "Epoch 6262, Loss: 813.2442016601562, Neurons: 11, Grad norm: 2.537e+01\n",
      "Epoch 6263, Loss: 813.1926879882812, Neurons: 11, Grad norm: 3.174e+01\n",
      "Epoch 6264, Loss: 813.1411743164062, Neurons: 11, Grad norm: 4.137e+01\n",
      "Epoch 6265, Loss: 813.0897216796875, Neurons: 11, Grad norm: 5.075e+01\n",
      "Epoch 6266, Loss: 813.038330078125, Neurons: 11, Grad norm: 6.157e+01\n",
      "Epoch 6267, Loss: 812.987060546875, Neurons: 11, Grad norm: 6.720e+01\n",
      "Epoch 6268, Loss: 812.9356079101562, Neurons: 11, Grad norm: 6.668e+01\n",
      "Epoch 6269, Loss: 812.8834228515625, Neurons: 11, Grad norm: 5.264e+01\n",
      "Epoch 6270, Loss: 812.8302612304688, Neurons: 11, Grad norm: 2.982e+01\n",
      "Epoch 6271, Loss: 812.7769775390625, Neurons: 11, Grad norm: 6.073e+00\n",
      "Epoch 6272, Loss: 812.7241821289062, Neurons: 11, Grad norm: 2.667e+01\n",
      "Epoch 6273, Loss: 812.6723022460938, Neurons: 11, Grad norm: 4.379e+01\n",
      "Epoch 6274, Loss: 812.62060546875, Neurons: 11, Grad norm: 4.586e+01\n",
      "Epoch 6275, Loss: 812.5682983398438, Neurons: 11, Grad norm: 3.573e+01\n",
      "Epoch 6276, Loss: 812.5151977539062, Neurons: 11, Grad norm: 1.439e+01\n",
      "Epoch 6277, Loss: 812.4618530273438, Neurons: 11, Grad norm: 1.149e+01\n",
      "Epoch 6278, Loss: 812.4090576171875, Neurons: 11, Grad norm: 2.918e+01\n",
      "Epoch 6279, Loss: 812.356689453125, Neurons: 11, Grad norm: 3.513e+01\n",
      "Epoch 6280, Loss: 812.303955078125, Neurons: 11, Grad norm: 3.048e+01\n",
      "Epoch 6281, Loss: 812.2507934570312, Neurons: 11, Grad norm: 1.503e+01\n",
      "Epoch 6282, Loss: 812.1972045898438, Neurons: 11, Grad norm: 7.671e+00\n",
      "Epoch 6283, Loss: 812.1438598632812, Neurons: 11, Grad norm: 2.146e+01\n",
      "Epoch 6284, Loss: 812.0907592773438, Neurons: 11, Grad norm: 2.706e+01\n",
      "Epoch 6285, Loss: 812.03759765625, Neurons: 11, Grad norm: 2.480e+01\n",
      "Epoch 6286, Loss: 811.9839477539062, Neurons: 11, Grad norm: 1.340e+01\n",
      "Epoch 6287, Loss: 811.9300537109375, Neurons: 11, Grad norm: 6.873e+00\n",
      "Epoch 6288, Loss: 811.8762817382812, Neurons: 11, Grad norm: 1.654e+01\n",
      "Epoch 6289, Loss: 811.822509765625, Neurons: 11, Grad norm: 2.113e+01\n",
      "Epoch 6290, Loss: 811.7686767578125, Neurons: 11, Grad norm: 2.030e+01\n",
      "Epoch 6291, Loss: 811.714599609375, Neurons: 11, Grad norm: 1.193e+01\n",
      "Epoch 6292, Loss: 811.6602783203125, Neurons: 11, Grad norm: 6.745e+00\n",
      "Epoch 6293, Loss: 811.60595703125, Neurons: 11, Grad norm: 1.291e+01\n",
      "Epoch 6294, Loss: 811.5516967773438, Neurons: 11, Grad norm: 1.665e+01\n",
      "Epoch 6295, Loss: 811.4972534179688, Neurons: 11, Grad norm: 1.695e+01\n",
      "Epoch 6296, Loss: 811.442626953125, Neurons: 11, Grad norm: 1.110e+01\n",
      "Epoch 6297, Loss: 811.3878173828125, Neurons: 11, Grad norm: 7.022e+00\n",
      "Epoch 6298, Loss: 811.3330078125, Neurons: 11, Grad norm: 1.010e+01\n",
      "Epoch 6299, Loss: 811.278076171875, Neurons: 11, Grad norm: 1.311e+01\n",
      "Epoch 6299, Test loss: 819.9712524414062\n",
      "Epoch 6300, Loss: 811.2230834960938, Neurons: 11, Grad norm: 1.444e+01\n",
      "Epoch 6301, Loss: 811.1679077148438, Neurons: 11, Grad norm: 1.071e+01\n",
      "Epoch 6302, Loss: 811.1126098632812, Neurons: 11, Grad norm: 7.690e+00\n",
      "Epoch 6303, Loss: 811.0572509765625, Neurons: 11, Grad norm: 8.070e+00\n",
      "Epoch 6304, Loss: 811.001708984375, Neurons: 11, Grad norm: 1.024e+01\n",
      "Epoch 6305, Loss: 810.9461669921875, Neurons: 11, Grad norm: 1.235e+01\n",
      "Epoch 6306, Loss: 810.8904418945312, Neurons: 11, Grad norm: 1.034e+01\n",
      "Epoch 6307, Loss: 810.8345947265625, Neurons: 11, Grad norm: 8.551e+00\n",
      "Epoch 6308, Loss: 810.7786254882812, Neurons: 11, Grad norm: 7.126e+00\n",
      "Epoch 6309, Loss: 810.7225952148438, Neurons: 11, Grad norm: 8.125e+00\n",
      "Epoch 6310, Loss: 810.6664428710938, Neurons: 11, Grad norm: 1.034e+01\n",
      "Epoch 6311, Loss: 810.6101684570312, Neurons: 11, Grad norm: 9.684e+00\n",
      "Epoch 6312, Loss: 810.5537719726562, Neurons: 11, Grad norm: 9.225e+00\n",
      "Epoch 6313, Loss: 810.4972534179688, Neurons: 11, Grad norm: 7.302e+00\n",
      "Epoch 6314, Loss: 810.440673828125, Neurons: 11, Grad norm: 7.167e+00\n",
      "Epoch 6315, Loss: 810.3839111328125, Neurons: 11, Grad norm: 8.486e+00\n",
      "Epoch 6316, Loss: 810.3270874023438, Neurons: 11, Grad norm: 8.644e+00\n",
      "Epoch 6317, Loss: 810.2702026367188, Neurons: 11, Grad norm: 9.280e+00\n",
      "Epoch 6318, Loss: 810.2130737304688, Neurons: 11, Grad norm: 7.875e+00\n",
      "Epoch 6319, Loss: 810.156005859375, Neurons: 11, Grad norm: 7.495e+00\n",
      "Epoch 6320, Loss: 810.0986938476562, Neurons: 11, Grad norm: 7.335e+00\n",
      "Epoch 6321, Loss: 810.041259765625, Neurons: 11, Grad norm: 7.547e+00\n",
      "Epoch 6322, Loss: 809.9837646484375, Neurons: 11, Grad norm: 8.544e+00\n",
      "Epoch 6323, Loss: 809.9262084960938, Neurons: 11, Grad norm: 7.999e+00\n",
      "Epoch 6324, Loss: 809.8684692382812, Neurons: 11, Grad norm: 8.168e+00\n",
      "Epoch 6325, Loss: 809.8106689453125, Neurons: 11, Grad norm: 7.299e+00\n",
      "Epoch 6326, Loss: 809.7528076171875, Neurons: 11, Grad norm: 7.246e+00\n",
      "Epoch 6327, Loss: 809.6947021484375, Neurons: 11, Grad norm: 7.543e+00\n",
      "Epoch 6328, Loss: 809.6365966796875, Neurons: 11, Grad norm: 7.502e+00\n",
      "Epoch 6329, Loss: 809.578369140625, Neurons: 11, Grad norm: 8.126e+00\n",
      "Epoch 6330, Loss: 809.52001953125, Neurons: 11, Grad norm: 7.571e+00\n",
      "Epoch 6331, Loss: 809.4616088867188, Neurons: 11, Grad norm: 7.751e+00\n",
      "Epoch 6332, Loss: 809.4030151367188, Neurons: 11, Grad norm: 7.249e+00\n",
      "Epoch 6333, Loss: 809.3443603515625, Neurons: 11, Grad norm: 7.259e+00\n",
      "Epoch 6334, Loss: 809.2855834960938, Neurons: 11, Grad norm: 7.451e+00\n",
      "Epoch 6335, Loss: 809.226806640625, Neurons: 11, Grad norm: 7.337e+00\n",
      "Epoch 6336, Loss: 809.1679077148438, Neurons: 11, Grad norm: 7.782e+00\n",
      "Epoch 6337, Loss: 809.1088256835938, Neurons: 11, Grad norm: 7.389e+00\n",
      "Epoch 6338, Loss: 809.0496826171875, Neurons: 11, Grad norm: 7.637e+00\n",
      "Epoch 6339, Loss: 808.990478515625, Neurons: 11, Grad norm: 7.252e+00\n",
      "Epoch 6340, Loss: 808.93115234375, Neurons: 11, Grad norm: 7.318e+00\n",
      "Epoch 6341, Loss: 808.8717651367188, Neurons: 11, Grad norm: 7.298e+00\n",
      "Epoch 6342, Loss: 808.812255859375, Neurons: 11, Grad norm: 7.233e+00\n",
      "Epoch 6343, Loss: 808.752685546875, Neurons: 11, Grad norm: 7.504e+00\n",
      "Epoch 6344, Loss: 808.6930541992188, Neurons: 11, Grad norm: 7.272e+00\n",
      "Epoch 6345, Loss: 808.63330078125, Neurons: 11, Grad norm: 7.560e+00\n",
      "Epoch 6346, Loss: 808.573486328125, Neurons: 11, Grad norm: 7.244e+00\n",
      "Epoch 6347, Loss: 808.5135498046875, Neurons: 11, Grad norm: 7.421e+00\n",
      "Epoch 6348, Loss: 808.4535522460938, Neurons: 11, Grad norm: 7.204e+00\n",
      "Epoch 6349, Loss: 808.3934936523438, Neurons: 11, Grad norm: 7.259e+00\n",
      "Epoch 6349, Test loss: 816.9183349609375\n",
      "Epoch 6350, Loss: 808.3333129882812, Neurons: 11, Grad norm: 7.248e+00\n",
      "Epoch 6351, Loss: 808.2730712890625, Neurons: 11, Grad norm: 7.187e+00\n",
      "Epoch 6352, Loss: 808.2127075195312, Neurons: 11, Grad norm: 7.340e+00\n",
      "Epoch 6353, Loss: 808.1524047851562, Neurons: 11, Grad norm: 7.174e+00\n",
      "Epoch 6354, Loss: 808.0919799804688, Neurons: 11, Grad norm: 7.390e+00\n",
      "Epoch 6355, Loss: 808.0314331054688, Neurons: 11, Grad norm: 7.161e+00\n",
      "Epoch 6356, Loss: 807.9708862304688, Neurons: 11, Grad norm: 7.362e+00\n",
      "Epoch 6357, Loss: 807.9102172851562, Neurons: 11, Grad norm: 7.136e+00\n",
      "Epoch 6358, Loss: 807.849609375, Neurons: 11, Grad norm: 7.284e+00\n",
      "Epoch 6359, Loss: 807.7887573242188, Neurons: 11, Grad norm: 7.116e+00\n",
      "Epoch 6360, Loss: 807.7279663085938, Neurons: 11, Grad norm: 7.199e+00\n",
      "Epoch 6361, Loss: 807.6670532226562, Neurons: 11, Grad norm: 7.113e+00\n",
      "Epoch 6362, Loss: 807.606201171875, Neurons: 11, Grad norm: 7.127e+00\n",
      "Epoch 6363, Loss: 807.5452880859375, Neurons: 11, Grad norm: 7.125e+00\n",
      "Epoch 6364, Loss: 807.4842529296875, Neurons: 11, Grad norm: 7.074e+00\n",
      "Epoch 6365, Loss: 807.4232177734375, Neurons: 11, Grad norm: 7.141e+00\n",
      "Epoch 6366, Loss: 807.362060546875, Neurons: 11, Grad norm: 7.034e+00\n",
      "Epoch 6367, Loss: 807.3009643554688, Neurons: 11, Grad norm: 7.154e+00\n",
      "Epoch 6368, Loss: 807.2398071289062, Neurons: 11, Grad norm: 7.001e+00\n",
      "Epoch 6369, Loss: 807.1786499023438, Neurons: 11, Grad norm: 7.162e+00\n",
      "Epoch 6370, Loss: 807.1173706054688, Neurons: 11, Grad norm: 6.970e+00\n",
      "Epoch 6371, Loss: 807.05615234375, Neurons: 11, Grad norm: 7.175e+00\n",
      "Epoch 6372, Loss: 806.994873046875, Neurons: 11, Grad norm: 6.942e+00\n",
      "Epoch 6373, Loss: 806.93359375, Neurons: 11, Grad norm: 7.209e+00\n",
      "Epoch 6374, Loss: 806.8722534179688, Neurons: 11, Grad norm: 6.924e+00\n",
      "Epoch 6375, Loss: 806.8109741210938, Neurons: 11, Grad norm: 7.286e+00\n",
      "Epoch 6376, Loss: 806.7495727539062, Neurons: 11, Grad norm: 6.936e+00\n",
      "Epoch 6377, Loss: 806.6882934570312, Neurons: 11, Grad norm: 7.461e+00\n",
      "Epoch 6378, Loss: 806.6268920898438, Neurons: 11, Grad norm: 7.036e+00\n",
      "Epoch 6379, Loss: 806.5655517578125, Neurons: 11, Grad norm: 7.853e+00\n",
      "Epoch 6380, Loss: 806.504150390625, Neurons: 11, Grad norm: 7.384e+00\n",
      "Epoch 6381, Loss: 806.4428100585938, Neurons: 11, Grad norm: 8.736e+00\n",
      "Epoch 6382, Loss: 806.3815307617188, Neurons: 11, Grad norm: 8.396e+00\n",
      "Epoch 6383, Loss: 806.3201904296875, Neurons: 11, Grad norm: 1.069e+01\n",
      "Epoch 6384, Loss: 806.2589721679688, Neurons: 11, Grad norm: 1.097e+01\n",
      "Epoch 6385, Loss: 806.1976318359375, Neurons: 11, Grad norm: 1.486e+01\n",
      "Epoch 6386, Loss: 806.1364135742188, Neurons: 11, Grad norm: 1.669e+01\n",
      "Epoch 6387, Loss: 806.0752563476562, Neurons: 11, Grad norm: 2.315e+01\n",
      "Epoch 6388, Loss: 806.01416015625, Neurons: 11, Grad norm: 2.794e+01\n",
      "Epoch 6389, Loss: 805.9532470703125, Neurons: 11, Grad norm: 3.837e+01\n",
      "Epoch 6390, Loss: 805.892578125, Neurons: 11, Grad norm: 4.752e+01\n",
      "Epoch 6391, Loss: 805.8320922851562, Neurons: 11, Grad norm: 6.220e+01\n",
      "Epoch 6392, Loss: 805.7721557617188, Neurons: 11, Grad norm: 7.286e+01\n",
      "Epoch 6393, Loss: 805.7125854492188, Neurons: 11, Grad norm: 8.289e+01\n",
      "Epoch 6394, Loss: 805.6531372070312, Neurons: 11, Grad norm: 7.780e+01\n",
      "Epoch 6395, Loss: 805.5932006835938, Neurons: 11, Grad norm: 6.142e+01\n",
      "Epoch 6396, Loss: 805.532470703125, Neurons: 11, Grad norm: 2.768e+01\n",
      "Epoch 6397, Loss: 805.4718017578125, Neurons: 11, Grad norm: 1.027e+01\n",
      "Epoch 6398, Loss: 805.4125366210938, Neurons: 11, Grad norm: 4.107e+01\n",
      "Epoch 6399, Loss: 805.3543701171875, Neurons: 11, Grad norm: 5.512e+01\n",
      "Epoch 6399, Test loss: 813.7420654296875\n",
      "Epoch 6400, Loss: 805.2965087890625, Neurons: 11, Grad norm: 5.443e+01\n",
      "Epoch 6401, Loss: 805.23779296875, Neurons: 11, Grad norm: 3.226e+01\n",
      "Epoch 6402, Loss: 805.1785278320312, Neurons: 11, Grad norm: 7.498e+00\n",
      "Epoch 6403, Loss: 805.1197509765625, Neurons: 11, Grad norm: 2.700e+01\n",
      "Epoch 6404, Loss: 805.06201171875, Neurons: 11, Grad norm: 4.092e+01\n",
      "Epoch 6405, Loss: 805.0045776367188, Neurons: 11, Grad norm: 4.249e+01\n",
      "Epoch 6406, Loss: 804.9467163085938, Neurons: 11, Grad norm: 2.498e+01\n",
      "Epoch 6407, Loss: 804.8885498046875, Neurons: 11, Grad norm: 6.812e+00\n",
      "Epoch 6408, Loss: 804.8306274414062, Neurons: 11, Grad norm: 2.278e+01\n",
      "Epoch 6409, Loss: 804.7733764648438, Neurons: 11, Grad norm: 3.233e+01\n",
      "Epoch 6410, Loss: 804.7163696289062, Neurons: 11, Grad norm: 3.266e+01\n",
      "Epoch 6411, Loss: 804.6591796875, Neurons: 11, Grad norm: 1.749e+01\n",
      "Epoch 6412, Loss: 804.601806640625, Neurons: 11, Grad norm: 6.380e+00\n",
      "Epoch 6413, Loss: 804.544677734375, Neurons: 11, Grad norm: 2.036e+01\n",
      "Epoch 6414, Loss: 804.488037109375, Neurons: 11, Grad norm: 2.588e+01\n",
      "Epoch 6415, Loss: 804.4315795898438, Neurons: 11, Grad norm: 2.508e+01\n",
      "Epoch 6416, Loss: 804.3748779296875, Neurons: 11, Grad norm: 1.221e+01\n",
      "Epoch 6417, Loss: 804.3182983398438, Neurons: 11, Grad norm: 6.670e+00\n",
      "Epoch 6418, Loss: 804.2619018554688, Neurons: 11, Grad norm: 1.779e+01\n",
      "Epoch 6419, Loss: 804.2057495117188, Neurons: 11, Grad norm: 2.060e+01\n",
      "Epoch 6420, Loss: 804.1498413085938, Neurons: 11, Grad norm: 1.960e+01\n",
      "Epoch 6421, Loss: 804.09375, Neurons: 11, Grad norm: 9.313e+00\n",
      "Epoch 6422, Loss: 804.0379638671875, Neurons: 11, Grad norm: 6.578e+00\n",
      "Epoch 6423, Loss: 803.982177734375, Neurons: 11, Grad norm: 1.498e+01\n",
      "Epoch 6424, Loss: 803.9267578125, Neurons: 11, Grad norm: 1.634e+01\n",
      "Epoch 6425, Loss: 803.8713989257812, Neurons: 11, Grad norm: 1.596e+01\n",
      "Epoch 6426, Loss: 803.8161010742188, Neurons: 11, Grad norm: 8.087e+00\n",
      "Epoch 6427, Loss: 803.7608642578125, Neurons: 11, Grad norm: 6.148e+00\n",
      "Epoch 6428, Loss: 803.7058715820312, Neurons: 11, Grad norm: 1.216e+01\n",
      "Epoch 6429, Loss: 803.6510620117188, Neurons: 11, Grad norm: 1.297e+01\n",
      "Epoch 6430, Loss: 803.5963745117188, Neurons: 11, Grad norm: 1.362e+01\n",
      "Epoch 6431, Loss: 803.5418090820312, Neurons: 11, Grad norm: 7.711e+00\n",
      "Epoch 6432, Loss: 803.4873657226562, Neurons: 11, Grad norm: 5.914e+00\n",
      "Epoch 6433, Loss: 803.43310546875, Neurons: 11, Grad norm: 9.506e+00\n",
      "Epoch 6434, Loss: 803.37890625, Neurons: 11, Grad norm: 1.025e+01\n",
      "Epoch 6435, Loss: 803.324951171875, Neurons: 11, Grad norm: 1.194e+01\n",
      "Epoch 6436, Loss: 803.2711181640625, Neurons: 11, Grad norm: 7.683e+00\n",
      "Epoch 6437, Loss: 803.2174682617188, Neurons: 11, Grad norm: 6.284e+00\n",
      "Epoch 6438, Loss: 803.1639404296875, Neurons: 11, Grad norm: 7.261e+00\n",
      "Epoch 6439, Loss: 803.110595703125, Neurons: 11, Grad norm: 7.929e+00\n",
      "Epoch 6440, Loss: 803.057373046875, Neurons: 11, Grad norm: 1.039e+01\n",
      "Epoch 6441, Loss: 803.0042724609375, Neurons: 11, Grad norm: 7.628e+00\n",
      "Epoch 6442, Loss: 802.9513549804688, Neurons: 11, Grad norm: 7.100e+00\n",
      "Epoch 6443, Loss: 802.8985595703125, Neurons: 11, Grad norm: 5.825e+00\n",
      "Epoch 6444, Loss: 802.8460083007812, Neurons: 11, Grad norm: 6.119e+00\n",
      "Epoch 6445, Loss: 802.7935791015625, Neurons: 11, Grad norm: 8.624e+00\n",
      "Epoch 6446, Loss: 802.7413330078125, Neurons: 11, Grad norm: 7.180e+00\n",
      "Epoch 6447, Loss: 802.6892700195312, Neurons: 11, Grad norm: 7.776e+00\n",
      "Epoch 6448, Loss: 802.6372680664062, Neurons: 11, Grad norm: 5.566e+00\n",
      "Epoch 6449, Loss: 802.5855102539062, Neurons: 11, Grad norm: 5.493e+00\n",
      "Epoch 6449, Test loss: 810.800537109375\n",
      "Epoch 6450, Loss: 802.533935546875, Neurons: 11, Grad norm: 6.708e+00\n",
      "Epoch 6451, Loss: 802.4824829101562, Neurons: 11, Grad norm: 6.192e+00\n",
      "Epoch 6452, Loss: 802.43115234375, Neurons: 11, Grad norm: 7.644e+00\n",
      "Epoch 6453, Loss: 802.3800659179688, Neurons: 11, Grad norm: 5.856e+00\n",
      "Epoch 6454, Loss: 802.3291015625, Neurons: 11, Grad norm: 6.134e+00\n",
      "Epoch 6455, Loss: 802.2783813476562, Neurons: 11, Grad norm: 5.439e+00\n",
      "Epoch 6456, Loss: 802.227783203125, Neurons: 11, Grad norm: 5.579e+00\n",
      "Epoch 6457, Loss: 802.1773071289062, Neurons: 11, Grad norm: 1.180e+01\n",
      "Epoch 6458, Loss: 802.12646484375, Neurons: 11, Grad norm: 1.429e+01\n",
      "Epoch 6459, Loss: 802.0764770507812, Neurons: 11, Grad norm: 1.805e+01\n",
      "Epoch 6460, Loss: 802.0265502929688, Neurons: 11, Grad norm: 1.416e+01\n",
      "Epoch 6461, Loss: 801.9769287109375, Neurons: 11, Grad norm: 1.171e+01\n",
      "Epoch 6462, Loss: 801.9273071289062, Neurons: 11, Grad norm: 5.689e+00\n",
      "Epoch 6463, Loss: 801.8779907226562, Neurons: 11, Grad norm: 5.571e+00\n",
      "Epoch 6464, Loss: 801.828857421875, Neurons: 11, Grad norm: 1.067e+01\n",
      "Epoch 6465, Loss: 801.7799072265625, Neurons: 11, Grad norm: 1.118e+01\n",
      "Epoch 6466, Loss: 801.7310180664062, Neurons: 11, Grad norm: 1.379e+01\n",
      "Epoch 6467, Loss: 801.682373046875, Neurons: 11, Grad norm: 1.038e+01\n",
      "Epoch 6468, Loss: 801.6339111328125, Neurons: 11, Grad norm: 9.353e+00\n",
      "Epoch 6469, Loss: 801.5855712890625, Neurons: 11, Grad norm: 5.319e+00\n",
      "Epoch 6470, Loss: 801.5374145507812, Neurons: 11, Grad norm: 5.116e+00\n",
      "Epoch 6471, Loss: 801.489501953125, Neurons: 11, Grad norm: 8.131e+00\n",
      "Epoch 6472, Loss: 801.441650390625, Neurons: 11, Grad norm: 8.133e+00\n",
      "Epoch 6473, Loss: 801.3941040039062, Neurons: 11, Grad norm: 1.075e+01\n",
      "Epoch 6474, Loss: 801.3465576171875, Neurons: 11, Grad norm: 8.491e+00\n",
      "Epoch 6475, Loss: 801.2993774414062, Neurons: 11, Grad norm: 8.886e+00\n",
      "Epoch 6476, Loss: 801.2522583007812, Neurons: 11, Grad norm: 5.667e+00\n",
      "Epoch 6477, Loss: 801.2052612304688, Neurons: 11, Grad norm: 5.454e+00\n",
      "Epoch 6478, Loss: 801.1585083007812, Neurons: 11, Grad norm: 5.591e+00\n",
      "Epoch 6479, Loss: 801.1118774414062, Neurons: 11, Grad norm: 5.528e+00\n",
      "Epoch 6480, Loss: 801.0654907226562, Neurons: 11, Grad norm: 7.902e+00\n",
      "Epoch 6481, Loss: 801.0192260742188, Neurons: 11, Grad norm: 6.804e+00\n",
      "Epoch 6482, Loss: 800.9730834960938, Neurons: 11, Grad norm: 8.394e+00\n",
      "Epoch 6483, Loss: 800.9271850585938, Neurons: 11, Grad norm: 6.203e+00\n",
      "Epoch 6484, Loss: 800.8814086914062, Neurons: 11, Grad norm: 6.896e+00\n",
      "Epoch 6485, Loss: 800.8357543945312, Neurons: 11, Grad norm: 4.945e+00\n",
      "Epoch 6486, Loss: 800.7904052734375, Neurons: 11, Grad norm: 5.109e+00\n",
      "Epoch 6487, Loss: 800.7451171875, Neurons: 11, Grad norm: 5.269e+00\n",
      "Epoch 6488, Loss: 800.699951171875, Neurons: 11, Grad norm: 1.080e+01\n",
      "Epoch 6489, Loss: 800.6552734375, Neurons: 11, Grad norm: 3.187e+01\n",
      "Epoch 6490, Loss: 800.6107177734375, Neurons: 11, Grad norm: 5.024e+01\n",
      "Epoch 6491, Loss: 800.5670776367188, Neurons: 11, Grad norm: 6.679e+01\n",
      "Epoch 6492, Loss: 800.5236206054688, Neurons: 11, Grad norm: 6.748e+01\n",
      "Epoch 6493, Loss: 800.4799194335938, Neurons: 11, Grad norm: 5.903e+01\n",
      "Epoch 6494, Loss: 800.4356689453125, Neurons: 11, Grad norm: 3.527e+01\n",
      "Epoch 6495, Loss: 800.3914794921875, Neurons: 11, Grad norm: 9.508e+00\n",
      "Epoch 6496, Loss: 800.3477783203125, Neurons: 11, Grad norm: 2.263e+01\n",
      "Epoch 6497, Loss: 800.3050537109375, Neurons: 11, Grad norm: 3.944e+01\n",
      "Epoch 6498, Loss: 800.2630004882812, Neurons: 11, Grad norm: 4.940e+01\n",
      "Epoch 6499, Loss: 800.220703125, Neurons: 11, Grad norm: 4.113e+01\n",
      "Epoch 6499, Test loss: 808.3545532226562\n",
      "Epoch 6500, Loss: 800.1781005859375, Neurons: 11, Grad norm: 2.548e+01\n",
      "Epoch 6501, Loss: 800.1353759765625, Neurons: 11, Grad norm: 4.571e+00\n",
      "Epoch 6502, Loss: 800.0932006835938, Neurons: 11, Grad norm: 1.910e+01\n",
      "Epoch 6503, Loss: 800.0515747070312, Neurons: 11, Grad norm: 3.468e+01\n",
      "Epoch 6504, Loss: 800.01025390625, Neurons: 11, Grad norm: 3.423e+01\n",
      "Epoch 6505, Loss: 799.9688110351562, Neurons: 11, Grad norm: 2.794e+01\n",
      "Epoch 6506, Loss: 799.92724609375, Neurons: 11, Grad norm: 1.067e+01\n",
      "Epoch 6507, Loss: 799.8858642578125, Neurons: 11, Grad norm: 7.519e+00\n",
      "Epoch 6508, Loss: 799.8447875976562, Neurons: 11, Grad norm: 2.234e+01\n",
      "Epoch 6509, Loss: 799.8040771484375, Neurons: 11, Grad norm: 2.600e+01\n",
      "Epoch 6510, Loss: 799.7634887695312, Neurons: 11, Grad norm: 2.588e+01\n",
      "Epoch 6511, Loss: 799.722900390625, Neurons: 11, Grad norm: 1.400e+01\n",
      "Epoch 6512, Loss: 799.6822509765625, Neurons: 11, Grad norm: 4.928e+00\n",
      "Epoch 6513, Loss: 799.6419067382812, Neurons: 11, Grad norm: 1.286e+01\n",
      "Epoch 6514, Loss: 799.6017456054688, Neurons: 11, Grad norm: 1.836e+01\n",
      "Epoch 6515, Loss: 799.561767578125, Neurons: 11, Grad norm: 2.185e+01\n",
      "Epoch 6516, Loss: 799.5219116210938, Neurons: 11, Grad norm: 1.490e+01\n",
      "Epoch 6517, Loss: 799.4820556640625, Neurons: 11, Grad norm: 8.903e+00\n",
      "Epoch 6518, Loss: 799.4423217773438, Neurons: 11, Grad norm: 6.235e+00\n",
      "Epoch 6519, Loss: 799.4027709960938, Neurons: 11, Grad norm: 1.123e+01\n",
      "Epoch 6520, Loss: 799.3634643554688, Neurons: 11, Grad norm: 1.690e+01\n",
      "Epoch 6521, Loss: 799.32421875, Neurons: 11, Grad norm: 1.410e+01\n",
      "Epoch 6522, Loss: 799.2850952148438, Neurons: 11, Grad norm: 1.164e+01\n",
      "Epoch 6523, Loss: 799.2460327148438, Neurons: 11, Grad norm: 4.509e+00\n",
      "Epoch 6524, Loss: 799.2070922851562, Neurons: 11, Grad norm: 5.434e+00\n",
      "Epoch 6525, Loss: 799.1682739257812, Neurons: 11, Grad norm: 1.155e+01\n",
      "Epoch 6526, Loss: 799.1296997070312, Neurons: 11, Grad norm: 1.151e+01\n",
      "Epoch 6527, Loss: 799.0911865234375, Neurons: 11, Grad norm: 1.225e+01\n",
      "Epoch 6528, Loss: 799.0527954101562, Neurons: 11, Grad norm: 6.878e+00\n",
      "Epoch 6529, Loss: 799.014404296875, Neurons: 11, Grad norm: 4.865e+00\n",
      "Epoch 6530, Loss: 798.9761962890625, Neurons: 11, Grad norm: 6.464e+00\n",
      "Epoch 6531, Loss: 798.9380493164062, Neurons: 11, Grad norm: 7.557e+00\n",
      "Epoch 6532, Loss: 798.9002075195312, Neurons: 11, Grad norm: 1.071e+01\n",
      "Epoch 6533, Loss: 798.8623046875, Neurons: 11, Grad norm: 1.241e+01\n",
      "Epoch 6534, Loss: 798.8245849609375, Neurons: 11, Grad norm: 2.228e+01\n",
      "Epoch 6535, Loss: 798.787109375, Neurons: 11, Grad norm: 2.594e+01\n",
      "Epoch 6536, Loss: 798.749755859375, Neurons: 11, Grad norm: 2.765e+01\n",
      "Epoch 6537, Loss: 798.7123413085938, Neurons: 11, Grad norm: 1.840e+01\n",
      "Epoch 6538, Loss: 798.6749877929688, Neurons: 11, Grad norm: 9.442e+00\n",
      "Epoch 6539, Loss: 798.6376953125, Neurons: 11, Grad norm: 6.665e+00\n",
      "Epoch 6540, Loss: 798.6007080078125, Neurons: 11, Grad norm: 1.361e+01\n",
      "Epoch 6541, Loss: 798.5638427734375, Neurons: 11, Grad norm: 2.119e+01\n",
      "Epoch 6542, Loss: 798.527099609375, Neurons: 11, Grad norm: 1.888e+01\n",
      "Epoch 6543, Loss: 798.4903564453125, Neurons: 11, Grad norm: 1.670e+01\n",
      "Epoch 6544, Loss: 798.4536743164062, Neurons: 11, Grad norm: 7.604e+00\n",
      "Epoch 6545, Loss: 798.4171752929688, Neurons: 11, Grad norm: 4.047e+00\n",
      "Epoch 6546, Loss: 798.3807373046875, Neurons: 11, Grad norm: 1.069e+01\n",
      "Epoch 6547, Loss: 798.344482421875, Neurons: 11, Grad norm: 1.312e+01\n",
      "Epoch 6548, Loss: 798.308349609375, Neurons: 11, Grad norm: 1.923e+01\n",
      "Epoch 6549, Loss: 798.2722778320312, Neurons: 11, Grad norm: 6.740e+01\n",
      "Epoch 6549, Test loss: 806.3267211914062\n",
      "Epoch 6550, Loss: 798.2384643554688, Neurons: 11, Grad norm: 1.714e+02\n",
      "Epoch 6551, Loss: 798.2138061523438, Neurons: 11, Grad norm: 2.382e+02\n",
      "Epoch 6552, Loss: 798.1941528320312, Neurons: 11, Grad norm: 1.691e+02\n",
      "Epoch 6553, Loss: 798.1449584960938, Neurons: 11, Grad norm: 4.015e+01\n",
      "Epoch 6554, Loss: 798.0995483398438, Neurons: 11, Grad norm: 1.850e+02\n",
      "Epoch 6555, Loss: 798.081787109375, Neurons: 11, Grad norm: 1.139e+02\n",
      "Epoch 6556, Loss: 798.0394897460938, Neurons: 11, Grad norm: 8.042e+01\n",
      "Epoch 6557, Loss: 798.00390625, Neurons: 11, Grad norm: 1.559e+02\n",
      "Epoch 6558, Loss: 797.98046875, Neurons: 11, Grad norm: 3.345e+01\n",
      "Epoch 6559, Loss: 797.9373168945312, Neurons: 11, Grad norm: 1.270e+02\n",
      "Epoch 6560, Loss: 797.912353515625, Neurons: 11, Grad norm: 9.525e+01\n",
      "Epoch 6561, Loss: 797.8779296875, Neurons: 11, Grad norm: 5.834e+01\n",
      "Epoch 6562, Loss: 797.84375, Neurons: 11, Grad norm: 1.170e+02\n",
      "Epoch 6563, Loss: 797.8173217773438, Neurons: 11, Grad norm: 7.212e+00\n",
      "Epoch 6564, Loss: 797.7796630859375, Neurons: 11, Grad norm: 1.017e+02\n",
      "Epoch 6565, Loss: 797.7534790039062, Neurons: 11, Grad norm: 5.576e+01\n",
      "Epoch 6566, Loss: 797.7188720703125, Neurons: 11, Grad norm: 7.099e+01\n",
      "Epoch 6567, Loss: 797.6889038085938, Neurons: 11, Grad norm: 7.604e+01\n",
      "Epoch 6568, Loss: 797.6587524414062, Neurons: 11, Grad norm: 2.666e+01\n",
      "Epoch 6569, Loss: 797.6256103515625, Neurons: 11, Grad norm: 8.229e+01\n",
      "Epoch 6570, Loss: 797.59765625, Neurons: 11, Grad norm: 9.994e+00\n",
      "Epoch 6571, Loss: 797.5640869140625, Neurons: 11, Grad norm: 6.939e+01\n",
      "Epoch 6572, Loss: 797.5357666015625, Neurons: 11, Grad norm: 3.847e+01\n",
      "Epoch 6573, Loss: 797.503662109375, Neurons: 11, Grad norm: 5.047e+01\n",
      "Epoch 6574, Loss: 797.4737548828125, Neurons: 11, Grad norm: 5.025e+01\n",
      "Epoch 6575, Loss: 797.4436645507812, Neurons: 11, Grad norm: 2.156e+01\n",
      "Epoch 6576, Loss: 797.4124145507812, Neurons: 11, Grad norm: 5.701e+01\n",
      "Epoch 6577, Loss: 797.3834228515625, Neurons: 11, Grad norm: 4.165e+00\n",
      "Epoch 6578, Loss: 797.351806640625, Neurons: 11, Grad norm: 5.157e+01\n",
      "Epoch 6579, Loss: 797.3228759765625, Neurons: 11, Grad norm: 3.128e+01\n",
      "Epoch 6580, Loss: 797.2921752929688, Neurons: 11, Grad norm: 3.315e+01\n",
      "Epoch 6581, Loss: 797.26220703125, Neurons: 11, Grad norm: 3.671e+01\n",
      "Epoch 6582, Loss: 797.2326049804688, Neurons: 11, Grad norm: 1.020e+01\n",
      "Epoch 6583, Loss: 797.2020874023438, Neurons: 11, Grad norm: 3.647e+01\n",
      "Epoch 6584, Loss: 797.1727294921875, Neurons: 11, Grad norm: 3.841e+01\n",
      "Epoch 6585, Loss: 797.14306640625, Neurons: 11, Grad norm: 4.365e+01\n",
      "Epoch 6586, Loss: 797.1134643554688, Neurons: 11, Grad norm: 9.311e+00\n",
      "Epoch 6587, Loss: 797.083251953125, Neurons: 11, Grad norm: 3.317e+01\n",
      "Epoch 6588, Loss: 797.05419921875, Neurons: 11, Grad norm: 2.530e+01\n",
      "Epoch 6589, Loss: 797.0242309570312, Neurons: 11, Grad norm: 2.483e+01\n",
      "Epoch 6590, Loss: 796.9947509765625, Neurons: 11, Grad norm: 2.909e+01\n",
      "Epoch 6591, Loss: 796.9654541015625, Neurons: 11, Grad norm: 1.410e+01\n",
      "Epoch 6592, Loss: 796.9356689453125, Neurons: 11, Grad norm: 2.993e+01\n",
      "Epoch 6593, Loss: 796.906494140625, Neurons: 11, Grad norm: 8.172e+00\n",
      "Epoch 6594, Loss: 796.876708984375, Neurons: 11, Grad norm: 6.515e+01\n",
      "Epoch 6595, Loss: 796.8485717773438, Neurons: 11, Grad norm: 8.644e+01\n",
      "Epoch 6596, Loss: 796.8214721679688, Neurons: 11, Grad norm: 4.845e+00\n",
      "Epoch 6597, Loss: 796.7891845703125, Neurons: 11, Grad norm: 7.106e+01\n",
      "Epoch 6598, Loss: 796.762451171875, Neurons: 11, Grad norm: 2.783e+01\n",
      "Epoch 6599, Loss: 796.7313232421875, Neurons: 11, Grad norm: 5.527e+01\n",
      "Epoch 6599, Test loss: 804.7081298828125\n",
      "Epoch 6600, Loss: 796.7034912109375, Neurons: 11, Grad norm: 4.518e+01\n",
      "Epoch 6601, Loss: 796.6739501953125, Neurons: 11, Grad norm: 3.452e+01\n",
      "Epoch 6602, Loss: 796.6446533203125, Neurons: 11, Grad norm: 5.464e+01\n",
      "Epoch 6603, Loss: 796.616455078125, Neurons: 11, Grad norm: 1.779e+01\n",
      "Epoch 6604, Loss: 796.5865478515625, Neurons: 11, Grad norm: 4.914e+01\n",
      "Epoch 6605, Loss: 796.558837890625, Neurons: 11, Grad norm: 6.995e+00\n",
      "Epoch 6606, Loss: 796.52880859375, Neurons: 11, Grad norm: 4.519e+01\n",
      "Epoch 6607, Loss: 796.5010375976562, Neurons: 11, Grad norm: 1.997e+01\n",
      "Epoch 6608, Loss: 796.4715576171875, Neurons: 11, Grad norm: 3.278e+01\n",
      "Epoch 6609, Loss: 796.4432983398438, Neurons: 11, Grad norm: 2.760e+01\n",
      "Epoch 6610, Loss: 796.4144287109375, Neurons: 11, Grad norm: 2.572e+01\n",
      "Epoch 6611, Loss: 796.3857421875, Neurons: 11, Grad norm: 7.382e+01\n",
      "Epoch 6612, Loss: 796.3585815429688, Neurons: 11, Grad norm: 7.832e+01\n",
      "Epoch 6613, Loss: 796.3311767578125, Neurons: 11, Grad norm: 1.158e+01\n",
      "Epoch 6614, Loss: 796.3003540039062, Neurons: 11, Grad norm: 6.709e+01\n",
      "Epoch 6615, Loss: 796.2741088867188, Neurons: 11, Grad norm: 1.676e+01\n",
      "Epoch 6616, Loss: 796.2437744140625, Neurons: 11, Grad norm: 5.604e+01\n",
      "Epoch 6617, Loss: 796.2169799804688, Neurons: 11, Grad norm: 3.309e+01\n",
      "Epoch 6618, Loss: 796.1878051757812, Neurons: 11, Grad norm: 4.108e+01\n",
      "Epoch 6619, Loss: 796.1598510742188, Neurons: 11, Grad norm: 4.383e+01\n",
      "Epoch 6620, Loss: 796.1316528320312, Neurons: 11, Grad norm: 2.851e+01\n",
      "Epoch 6621, Loss: 796.1031494140625, Neurons: 11, Grad norm: 4.207e+01\n",
      "Epoch 6622, Loss: 796.07568359375, Neurons: 11, Grad norm: 8.306e+00\n",
      "Epoch 6623, Loss: 796.0467529296875, Neurons: 11, Grad norm: 4.342e+01\n",
      "Epoch 6624, Loss: 796.0194702148438, Neurons: 11, Grad norm: 6.243e+00\n",
      "Epoch 6625, Loss: 795.9906616210938, Neurons: 11, Grad norm: 3.589e+01\n",
      "Epoch 6626, Loss: 795.96337890625, Neurons: 11, Grad norm: 1.329e+01\n",
      "Epoch 6627, Loss: 795.9348754882812, Neurons: 11, Grad norm: 3.235e+01\n",
      "Epoch 6628, Loss: 795.9072875976562, Neurons: 11, Grad norm: 4.678e+01\n",
      "Epoch 6629, Loss: 795.8795776367188, Neurons: 11, Grad norm: 3.909e+01\n",
      "Epoch 6630, Loss: 795.8518676757812, Neurons: 11, Grad norm: 1.146e+01\n",
      "Epoch 6631, Loss: 795.8236083984375, Neurons: 11, Grad norm: 3.989e+01\n",
      "Epoch 6632, Loss: 795.7963256835938, Neurons: 11, Grad norm: 1.935e+01\n",
      "Epoch 6633, Loss: 795.7682495117188, Neurons: 11, Grad norm: 2.506e+01\n",
      "Epoch 6634, Loss: 795.7407836914062, Neurons: 11, Grad norm: 2.442e+01\n",
      "Epoch 6635, Loss: 795.7131958007812, Neurons: 11, Grad norm: 1.484e+01\n",
      "Epoch 6636, Loss: 795.6853637695312, Neurons: 11, Grad norm: 2.846e+01\n",
      "Epoch 6637, Loss: 795.657958984375, Neurons: 11, Grad norm: 9.245e+00\n",
      "Epoch 6638, Loss: 795.630126953125, Neurons: 11, Grad norm: 2.353e+01\n",
      "Epoch 6639, Loss: 795.6029052734375, Neurons: 11, Grad norm: 4.895e+00\n",
      "Epoch 6640, Loss: 795.5750732421875, Neurons: 11, Grad norm: 2.317e+01\n",
      "Epoch 6641, Loss: 795.5477905273438, Neurons: 11, Grad norm: 1.414e+01\n",
      "Epoch 6642, Loss: 795.5202026367188, Neurons: 11, Grad norm: 1.606e+01\n",
      "Epoch 6643, Loss: 795.4927368164062, Neurons: 11, Grad norm: 3.081e+01\n",
      "Epoch 6644, Loss: 795.4656982421875, Neurons: 11, Grad norm: 3.807e+00\n",
      "Epoch 6645, Loss: 795.4379272460938, Neurons: 11, Grad norm: 4.020e+01\n",
      "Epoch 6646, Loss: 795.4109497070312, Neurons: 11, Grad norm: 4.870e+01\n",
      "Epoch 6647, Loss: 795.3843383789062, Neurons: 11, Grad norm: 9.737e+00\n",
      "Epoch 6648, Loss: 795.3560791015625, Neurons: 11, Grad norm: 4.320e+01\n",
      "Epoch 6649, Loss: 795.3297119140625, Neurons: 11, Grad norm: 7.929e+00\n",
      "Epoch 6649, Test loss: 803.3011474609375\n",
      "Epoch 6650, Loss: 795.3017578125, Neurons: 11, Grad norm: 3.774e+01\n",
      "Epoch 6651, Loss: 795.2750854492188, Neurons: 11, Grad norm: 1.662e+01\n",
      "Epoch 6652, Loss: 795.2474975585938, Neurons: 11, Grad norm: 3.229e+01\n",
      "Epoch 6653, Loss: 795.220703125, Neurons: 11, Grad norm: 3.642e+01\n",
      "Epoch 6654, Loss: 795.193603515625, Neurons: 11, Grad norm: 1.850e+01\n",
      "Epoch 6655, Loss: 795.1661376953125, Neurons: 11, Grad norm: 4.200e+01\n",
      "Epoch 6656, Loss: 795.1395874023438, Neurons: 11, Grad norm: 1.415e+01\n",
      "Epoch 6657, Loss: 795.112060546875, Neurons: 11, Grad norm: 2.915e+01\n",
      "Epoch 6658, Loss: 795.0853881835938, Neurons: 11, Grad norm: 2.872e+01\n",
      "Epoch 6659, Loss: 795.0581665039062, Neurons: 11, Grad norm: 5.216e+00\n",
      "Epoch 6660, Loss: 795.0310668945312, Neurons: 11, Grad norm: 1.476e+01\n",
      "Epoch 6661, Loss: 795.0042114257812, Neurons: 11, Grad norm: 4.497e+00\n",
      "Epoch 6662, Loss: 794.977294921875, Neurons: 11, Grad norm: 1.683e+01\n",
      "Epoch 6663, Loss: 794.9505004882812, Neurons: 11, Grad norm: 2.765e+01\n",
      "Epoch 6664, Loss: 794.923828125, Neurons: 11, Grad norm: 3.359e+00\n",
      "Epoch 6665, Loss: 794.8966674804688, Neurons: 11, Grad norm: 3.497e+01\n",
      "Epoch 6666, Loss: 794.8703002929688, Neurons: 11, Grad norm: 4.066e+01\n",
      "Epoch 6667, Loss: 794.8438720703125, Neurons: 11, Grad norm: 8.859e+00\n",
      "Epoch 6668, Loss: 794.8165893554688, Neurons: 11, Grad norm: 3.274e+01\n",
      "Epoch 6669, Loss: 794.7904052734375, Neurons: 11, Grad norm: 3.658e+00\n",
      "Epoch 6670, Loss: 794.76318359375, Neurons: 11, Grad norm: 3.353e+01\n",
      "Epoch 6671, Loss: 794.7369995117188, Neurons: 11, Grad norm: 1.087e+01\n",
      "Epoch 6672, Loss: 794.7098999023438, Neurons: 11, Grad norm: 2.517e+01\n",
      "Epoch 6673, Loss: 794.6834716796875, Neurons: 11, Grad norm: 1.898e+01\n",
      "Epoch 6674, Loss: 794.6566772460938, Neurons: 11, Grad norm: 2.035e+01\n",
      "Epoch 6675, Loss: 794.630126953125, Neurons: 11, Grad norm: 4.627e+01\n",
      "Epoch 6676, Loss: 794.6038818359375, Neurons: 11, Grad norm: 4.498e+01\n",
      "Epoch 6677, Loss: 794.5776977539062, Neurons: 11, Grad norm: 9.471e+00\n",
      "Epoch 6678, Loss: 794.5504760742188, Neurons: 11, Grad norm: 4.125e+01\n",
      "Epoch 6679, Loss: 794.524658203125, Neurons: 11, Grad norm: 1.429e+01\n",
      "Epoch 6680, Loss: 794.4976196289062, Neurons: 11, Grad norm: 3.214e+01\n",
      "Epoch 6681, Loss: 794.4716186523438, Neurons: 11, Grad norm: 2.177e+01\n",
      "Epoch 6682, Loss: 794.4450073242188, Neurons: 11, Grad norm: 2.127e+01\n",
      "Epoch 6683, Loss: 794.4185791015625, Neurons: 11, Grad norm: 2.822e+01\n",
      "Epoch 6684, Loss: 794.392333984375, Neurons: 11, Grad norm: 1.401e+01\n",
      "Epoch 6685, Loss: 794.3657836914062, Neurons: 11, Grad norm: 2.603e+01\n",
      "Epoch 6686, Loss: 794.3396606445312, Neurons: 11, Grad norm: 4.922e+00\n",
      "Epoch 6687, Loss: 794.3130493164062, Neurons: 11, Grad norm: 2.300e+01\n",
      "Epoch 6688, Loss: 794.286865234375, Neurons: 11, Grad norm: 4.761e+01\n",
      "Epoch 6689, Loss: 794.2611694335938, Neurons: 11, Grad norm: 5.944e+01\n",
      "Epoch 6690, Loss: 794.2357788085938, Neurons: 11, Grad norm: 4.995e+00\n",
      "Epoch 6691, Loss: 794.208251953125, Neurons: 11, Grad norm: 6.958e+01\n",
      "Epoch 6692, Loss: 794.18359375, Neurons: 11, Grad norm: 6.246e+01\n",
      "Epoch 6693, Loss: 794.1575317382812, Neurons: 11, Grad norm: 3.254e+01\n",
      "Epoch 6694, Loss: 794.1303100585938, Neurons: 11, Grad norm: 6.298e+01\n",
      "Epoch 6695, Loss: 794.1055908203125, Neurons: 11, Grad norm: 1.037e+01\n",
      "Epoch 6696, Loss: 794.077880859375, Neurons: 11, Grad norm: 5.978e+01\n",
      "Epoch 6697, Loss: 794.0534057617188, Neurons: 11, Grad norm: 8.100e+00\n",
      "Epoch 6698, Loss: 794.0259399414062, Neurons: 11, Grad norm: 4.908e+01\n",
      "Epoch 6699, Loss: 794.0010986328125, Neurons: 11, Grad norm: 2.509e+01\n",
      "Epoch 6699, Test loss: 801.939697265625\n",
      "Epoch 6700, Loss: 793.9743041992188, Neurons: 11, Grad norm: 4.174e+01\n",
      "Epoch 6701, Loss: 793.9487915039062, Neurons: 11, Grad norm: 3.049e+01\n",
      "Epoch 6702, Loss: 793.922607421875, Neurons: 11, Grad norm: 2.666e+01\n",
      "Epoch 6703, Loss: 793.8966064453125, Neurons: 11, Grad norm: 3.624e+01\n",
      "Epoch 6704, Loss: 793.8710327148438, Neurons: 11, Grad norm: 1.503e+01\n",
      "Epoch 6705, Loss: 793.8446655273438, Neurons: 11, Grad norm: 3.236e+01\n",
      "Epoch 6706, Loss: 793.8193359375, Neurons: 11, Grad norm: 5.460e+00\n",
      "Epoch 6707, Loss: 793.79296875, Neurons: 11, Grad norm: 3.328e+01\n",
      "Epoch 6708, Loss: 793.767578125, Neurons: 11, Grad norm: 3.627e+01\n",
      "Epoch 6709, Loss: 793.7417602539062, Neurons: 11, Grad norm: 4.160e+01\n",
      "Epoch 6710, Loss: 793.7163696289062, Neurons: 11, Grad norm: 1.874e+01\n",
      "Epoch 6711, Loss: 793.6901245117188, Neurons: 11, Grad norm: 6.335e+00\n",
      "Epoch 6712, Loss: 793.6644287109375, Neurons: 11, Grad norm: 1.027e+01\n",
      "Epoch 6713, Loss: 793.6387939453125, Neurons: 11, Grad norm: 7.109e+00\n",
      "Epoch 6714, Loss: 793.6131591796875, Neurons: 11, Grad norm: 9.352e+00\n",
      "Epoch 6715, Loss: 793.5875854492188, Neurons: 11, Grad norm: 5.481e+00\n",
      "Epoch 6716, Loss: 793.5619506835938, Neurons: 11, Grad norm: 1.076e+01\n",
      "Epoch 6717, Loss: 793.536376953125, Neurons: 11, Grad norm: 4.485e+00\n",
      "Epoch 6718, Loss: 793.5108032226562, Neurons: 11, Grad norm: 5.952e+00\n",
      "Epoch 6719, Loss: 793.4851684570312, Neurons: 11, Grad norm: 4.336e+00\n",
      "Epoch 6720, Loss: 793.4595947265625, Neurons: 11, Grad norm: 1.405e+01\n",
      "Epoch 6721, Loss: 793.4341430664062, Neurons: 11, Grad norm: 2.247e+01\n",
      "Epoch 6722, Loss: 793.4087524414062, Neurons: 11, Grad norm: 3.490e+01\n",
      "Epoch 6723, Loss: 793.383544921875, Neurons: 11, Grad norm: 1.297e+01\n",
      "Epoch 6724, Loss: 793.357666015625, Neurons: 11, Grad norm: 1.816e+01\n",
      "Epoch 6725, Loss: 793.3323974609375, Neurons: 11, Grad norm: 1.849e+01\n",
      "Epoch 6726, Loss: 793.306884765625, Neurons: 11, Grad norm: 1.425e+01\n",
      "Epoch 6727, Loss: 793.281494140625, Neurons: 11, Grad norm: 1.641e+01\n",
      "Epoch 6728, Loss: 793.256103515625, Neurons: 11, Grad norm: 9.170e+00\n",
      "Epoch 6729, Loss: 793.2305908203125, Neurons: 11, Grad norm: 1.607e+01\n",
      "Epoch 6730, Loss: 793.2052612304688, Neurons: 11, Grad norm: 6.826e+00\n",
      "Epoch 6731, Loss: 793.1797485351562, Neurons: 11, Grad norm: 4.140e+01\n",
      "Epoch 6732, Loss: 793.15478515625, Neurons: 11, Grad norm: 5.909e+01\n",
      "Epoch 6733, Loss: 793.1305541992188, Neurons: 11, Grad norm: 4.658e+00\n",
      "Epoch 6734, Loss: 793.1039428710938, Neurons: 11, Grad norm: 7.753e+01\n",
      "Epoch 6735, Loss: 793.080078125, Neurons: 11, Grad norm: 7.263e+01\n",
      "Epoch 6736, Loss: 793.0556030273438, Neurons: 11, Grad norm: 2.837e+01\n",
      "Epoch 6737, Loss: 793.028564453125, Neurons: 11, Grad norm: 7.138e+01\n",
      "Epoch 6738, Loss: 793.00537109375, Neurons: 11, Grad norm: 4.941e+00\n",
      "Epoch 6739, Loss: 792.9779663085938, Neurons: 11, Grad norm: 6.686e+01\n",
      "Epoch 6740, Loss: 792.9547119140625, Neurons: 11, Grad norm: 1.318e+01\n",
      "Epoch 6741, Loss: 792.9278564453125, Neurons: 11, Grad norm: 5.373e+01\n",
      "Epoch 6742, Loss: 792.9039916992188, Neurons: 11, Grad norm: 2.975e+01\n",
      "Epoch 6743, Loss: 792.8778686523438, Neurons: 11, Grad norm: 4.377e+01\n",
      "Epoch 6744, Loss: 792.853271484375, Neurons: 11, Grad norm: 3.572e+01\n",
      "Epoch 6745, Loss: 792.8280029296875, Neurons: 11, Grad norm: 2.785e+01\n",
      "Epoch 6746, Loss: 792.8027954101562, Neurons: 11, Grad norm: 4.133e+01\n",
      "Epoch 6747, Loss: 792.778076171875, Neurons: 11, Grad norm: 1.617e+01\n",
      "Epoch 6748, Loss: 792.75244140625, Neurons: 11, Grad norm: 3.902e+01\n",
      "Epoch 6749, Loss: 792.7280883789062, Neurons: 11, Grad norm: 3.291e+00\n",
      "Epoch 6749, Test loss: 800.6610107421875\n",
      "Epoch 6750, Loss: 792.702392578125, Neurons: 11, Grad norm: 3.862e+01\n",
      "Epoch 6751, Loss: 792.677978515625, Neurons: 11, Grad norm: 5.131e+00\n",
      "Epoch 6752, Loss: 792.6524047851562, Neurons: 11, Grad norm: 7.382e+01\n",
      "Epoch 6753, Loss: 792.628662109375, Neurons: 11, Grad norm: 9.131e+01\n",
      "Epoch 6754, Loss: 792.6060791015625, Neurons: 11, Grad norm: 1.437e+01\n",
      "Epoch 6755, Loss: 792.5779418945312, Neurons: 11, Grad norm: 1.121e+02\n",
      "Epoch 6756, Loss: 792.5564575195312, Neurons: 11, Grad norm: 7.464e+01\n",
      "Epoch 6757, Loss: 792.5305786132812, Neurons: 11, Grad norm: 6.022e+01\n",
      "Epoch 6758, Loss: 792.505126953125, Neurons: 11, Grad norm: 7.627e+01\n",
      "Epoch 6759, Loss: 792.4815673828125, Neurons: 11, Grad norm: 3.605e+01\n",
      "Epoch 6760, Loss: 792.4549560546875, Neurons: 11, Grad norm: 7.654e+01\n",
      "Epoch 6761, Loss: 792.432373046875, Neurons: 11, Grad norm: 1.742e+01\n",
      "Epoch 6762, Loss: 792.4052734375, Neurons: 11, Grad norm: 7.086e+01\n",
      "Epoch 6763, Loss: 792.3828125, Neurons: 11, Grad norm: 3.728e+00\n",
      "Epoch 6764, Loss: 792.35595703125, Neurons: 11, Grad norm: 6.772e+01\n",
      "Epoch 6765, Loss: 792.333251953125, Neurons: 11, Grad norm: 1.060e+01\n",
      "Epoch 6766, Loss: 792.3068237304688, Neurons: 11, Grad norm: 5.598e+01\n",
      "Epoch 6767, Loss: 792.2836303710938, Neurons: 11, Grad norm: 2.167e+01\n",
      "Epoch 6768, Loss: 792.2579345703125, Neurons: 11, Grad norm: 4.749e+01\n",
      "Epoch 6769, Loss: 792.234130859375, Neurons: 11, Grad norm: 2.707e+01\n",
      "Epoch 6770, Loss: 792.208984375, Neurons: 11, Grad norm: 3.585e+01\n",
      "Epoch 6771, Loss: 792.1847534179688, Neurons: 11, Grad norm: 3.396e+01\n",
      "Epoch 6772, Loss: 792.1600952148438, Neurons: 11, Grad norm: 2.976e+01\n",
      "Epoch 6773, Loss: 792.135498046875, Neurons: 11, Grad norm: 3.251e+01\n",
      "Epoch 6774, Loss: 792.1112060546875, Neurons: 11, Grad norm: 1.818e+01\n",
      "Epoch 6775, Loss: 792.0863647460938, Neurons: 11, Grad norm: 3.452e+01\n",
      "Epoch 6776, Loss: 792.062255859375, Neurons: 11, Grad norm: 1.171e+01\n",
      "Epoch 6777, Loss: 792.037353515625, Neurons: 11, Grad norm: 5.618e+01\n",
      "Epoch 6778, Loss: 792.0135498046875, Neurons: 11, Grad norm: 4.492e+01\n",
      "Epoch 6779, Loss: 791.9892578125, Neurons: 11, Grad norm: 2.523e+01\n",
      "Epoch 6780, Loss: 791.96435546875, Neurons: 11, Grad norm: 6.547e+01\n",
      "Epoch 6781, Loss: 791.9408569335938, Neurons: 11, Grad norm: 3.906e+01\n",
      "Epoch 6782, Loss: 791.9160766601562, Neurons: 11, Grad norm: 3.293e+01\n",
      "Epoch 6783, Loss: 791.8916625976562, Neurons: 11, Grad norm: 4.209e+01\n",
      "Epoch 6784, Loss: 791.86767578125, Neurons: 11, Grad norm: 1.365e+01\n",
      "Epoch 6785, Loss: 791.8428344726562, Neurons: 11, Grad norm: 3.740e+01\n",
      "Epoch 6786, Loss: 791.819091796875, Neurons: 11, Grad norm: 7.423e+00\n",
      "Epoch 6787, Loss: 791.7942504882812, Neurons: 11, Grad norm: 3.258e+01\n",
      "Epoch 6788, Loss: 791.7705078125, Neurons: 11, Grad norm: 4.315e+00\n",
      "Epoch 6789, Loss: 791.7457885742188, Neurons: 11, Grad norm: 3.251e+01\n",
      "Epoch 6790, Loss: 791.7219848632812, Neurons: 11, Grad norm: 5.893e+00\n",
      "Epoch 6791, Loss: 791.697265625, Neurons: 11, Grad norm: 2.599e+01\n",
      "Epoch 6792, Loss: 791.6734008789062, Neurons: 11, Grad norm: 1.129e+01\n",
      "Epoch 6793, Loss: 791.6489868164062, Neurons: 11, Grad norm: 2.296e+01\n",
      "Epoch 6794, Loss: 791.6248779296875, Neurons: 11, Grad norm: 1.665e+01\n",
      "Epoch 6795, Loss: 791.6004638671875, Neurons: 11, Grad norm: 1.925e+01\n",
      "Epoch 6796, Loss: 791.5763549804688, Neurons: 11, Grad norm: 3.780e+01\n",
      "Epoch 6797, Loss: 791.5526733398438, Neurons: 11, Grad norm: 3.919e+00\n",
      "Epoch 6798, Loss: 791.5279541015625, Neurons: 11, Grad norm: 4.768e+01\n",
      "Epoch 6799, Loss: 791.5043334960938, Neurons: 11, Grad norm: 5.739e+01\n",
      "Epoch 6799, Test loss: 799.3931884765625\n",
      "Epoch 6800, Loss: 791.4811401367188, Neurons: 11, Grad norm: 1.124e+01\n",
      "Epoch 6801, Loss: 791.4557495117188, Neurons: 11, Grad norm: 4.708e+01\n",
      "Epoch 6802, Loss: 791.4328002929688, Neurons: 11, Grad norm: 4.687e+00\n",
      "Epoch 6803, Loss: 791.4076538085938, Neurons: 11, Grad norm: 4.674e+01\n",
      "Epoch 6804, Loss: 791.3845825195312, Neurons: 11, Grad norm: 5.564e+00\n",
      "Epoch 6805, Loss: 791.3595581054688, Neurons: 11, Grad norm: 4.017e+01\n",
      "Epoch 6806, Loss: 791.3362426757812, Neurons: 11, Grad norm: 1.388e+01\n",
      "Epoch 6807, Loss: 791.3115234375, Neurons: 11, Grad norm: 3.726e+01\n",
      "Epoch 6808, Loss: 791.2879638671875, Neurons: 11, Grad norm: 1.524e+01\n",
      "Epoch 6809, Loss: 791.2635498046875, Neurons: 11, Grad norm: 2.489e+01\n",
      "Epoch 6810, Loss: 791.2396850585938, Neurons: 11, Grad norm: 1.573e+01\n",
      "Epoch 6811, Loss: 791.2154541015625, Neurons: 11, Grad norm: 2.344e+01\n",
      "Epoch 6812, Loss: 791.1915893554688, Neurons: 11, Grad norm: 5.441e+01\n",
      "Epoch 6813, Loss: 791.1680908203125, Neurons: 11, Grad norm: 5.346e+01\n",
      "Epoch 6814, Loss: 791.1445922851562, Neurons: 11, Grad norm: 1.211e+01\n",
      "Epoch 6815, Loss: 791.1196899414062, Neurons: 11, Grad norm: 5.522e+01\n",
      "Epoch 6816, Loss: 791.0966796875, Neurons: 11, Grad norm: 2.653e+01\n",
      "Epoch 6817, Loss: 791.072021484375, Neurons: 11, Grad norm: 3.809e+01\n",
      "Epoch 6818, Loss: 791.0485229492188, Neurons: 11, Grad norm: 2.946e+01\n",
      "Epoch 6819, Loss: 791.0244140625, Neurons: 11, Grad norm: 2.988e+01\n",
      "Epoch 6820, Loss: 791.0006103515625, Neurons: 11, Grad norm: 3.131e+01\n",
      "Epoch 6821, Loss: 790.9767456054688, Neurons: 11, Grad norm: 2.302e+01\n",
      "Epoch 6822, Loss: 790.9526977539062, Neurons: 11, Grad norm: 2.859e+01\n",
      "Epoch 6823, Loss: 790.9290771484375, Neurons: 11, Grad norm: 1.126e+01\n",
      "Epoch 6824, Loss: 790.9049072265625, Neurons: 11, Grad norm: 3.207e+01\n",
      "Epoch 6825, Loss: 790.8812866210938, Neurons: 11, Grad norm: 7.723e+00\n",
      "Epoch 6826, Loss: 790.8570556640625, Neurons: 11, Grad norm: 3.693e+01\n",
      "Epoch 6827, Loss: 790.8335571289062, Neurons: 11, Grad norm: 1.501e+01\n",
      "Epoch 6828, Loss: 790.8095092773438, Neurons: 11, Grad norm: 2.488e+01\n",
      "Epoch 6829, Loss: 790.7858276367188, Neurons: 11, Grad norm: 3.410e+01\n",
      "Epoch 6830, Loss: 790.761962890625, Neurons: 11, Grad norm: 2.103e+01\n",
      "Epoch 6831, Loss: 790.7381591796875, Neurons: 11, Grad norm: 1.542e+01\n",
      "Epoch 6832, Loss: 790.71435546875, Neurons: 11, Grad norm: 2.645e+01\n",
      "Epoch 6833, Loss: 790.690673828125, Neurons: 11, Grad norm: 1.202e+01\n",
      "Epoch 6834, Loss: 790.6668090820312, Neurons: 11, Grad norm: 1.469e+01\n",
      "Epoch 6835, Loss: 790.6431274414062, Neurons: 11, Grad norm: 1.173e+01\n",
      "Epoch 6836, Loss: 790.6193237304688, Neurons: 11, Grad norm: 1.217e+01\n",
      "Epoch 6837, Loss: 790.5956420898438, Neurons: 11, Grad norm: 1.584e+01\n",
      "Epoch 6838, Loss: 790.5718994140625, Neurons: 11, Grad norm: 1.355e+01\n",
      "Epoch 6839, Loss: 790.5481567382812, Neurons: 11, Grad norm: 5.084e+01\n",
      "Epoch 6840, Loss: 790.52490234375, Neurons: 11, Grad norm: 6.004e+01\n",
      "Epoch 6841, Loss: 790.502197265625, Neurons: 11, Grad norm: 7.757e+00\n",
      "Epoch 6842, Loss: 790.4771118164062, Neurons: 11, Grad norm: 5.894e+01\n",
      "Epoch 6843, Loss: 790.4544677734375, Neurons: 11, Grad norm: 2.869e+01\n",
      "Epoch 6844, Loss: 790.43017578125, Neurons: 11, Grad norm: 3.893e+01\n",
      "Epoch 6845, Loss: 790.4068603515625, Neurons: 11, Grad norm: 3.106e+01\n",
      "Epoch 6846, Loss: 790.383056640625, Neurons: 11, Grad norm: 2.835e+01\n",
      "Epoch 6847, Loss: 790.359375, Neurons: 11, Grad norm: 3.446e+01\n",
      "Epoch 6848, Loss: 790.3358764648438, Neurons: 11, Grad norm: 2.168e+01\n",
      "Epoch 6849, Loss: 790.3119506835938, Neurons: 11, Grad norm: 3.191e+01\n",
      "Epoch 6849, Test loss: 798.2352294921875\n",
      "Epoch 6850, Loss: 790.2886962890625, Neurons: 11, Grad norm: 1.075e+01\n",
      "Epoch 6851, Loss: 790.2647094726562, Neurons: 11, Grad norm: 3.368e+01\n",
      "Epoch 6852, Loss: 790.241455078125, Neurons: 11, Grad norm: 6.469e+00\n",
      "Epoch 6853, Loss: 790.2174072265625, Neurons: 11, Grad norm: 2.759e+01\n",
      "Epoch 6854, Loss: 790.1941528320312, Neurons: 11, Grad norm: 3.598e+00\n",
      "Epoch 6855, Loss: 790.170166015625, Neurons: 11, Grad norm: 2.597e+01\n",
      "Epoch 6856, Loss: 790.1468505859375, Neurons: 11, Grad norm: 4.247e+01\n",
      "Epoch 6857, Loss: 790.1235961914062, Neurons: 11, Grad norm: 5.275e+01\n",
      "Epoch 6858, Loss: 790.1005859375, Neurons: 11, Grad norm: 7.212e+00\n",
      "Epoch 6859, Loss: 790.076171875, Neurons: 11, Grad norm: 5.581e+01\n",
      "Epoch 6860, Loss: 790.0533447265625, Neurons: 11, Grad norm: 5.903e+01\n",
      "Epoch 6861, Loss: 790.030517578125, Neurons: 11, Grad norm: 2.170e+01\n",
      "Epoch 6862, Loss: 790.005859375, Neurons: 11, Grad norm: 5.451e+01\n",
      "Epoch 6863, Loss: 789.9835205078125, Neurons: 11, Grad norm: 9.930e+00\n",
      "Epoch 6864, Loss: 789.9589233398438, Neurons: 11, Grad norm: 5.069e+01\n",
      "Epoch 6865, Loss: 789.9364624023438, Neurons: 11, Grad norm: 3.082e+00\n",
      "Epoch 6866, Loss: 789.9119873046875, Neurons: 11, Grad norm: 4.328e+01\n",
      "Epoch 6867, Loss: 789.8894653320312, Neurons: 11, Grad norm: 1.146e+01\n",
      "Epoch 6868, Loss: 789.865234375, Neurons: 11, Grad norm: 4.140e+01\n",
      "Epoch 6869, Loss: 789.8424072265625, Neurons: 11, Grad norm: 1.381e+01\n",
      "Epoch 6870, Loss: 789.818359375, Neurons: 11, Grad norm: 3.292e+01\n",
      "Epoch 6871, Loss: 789.7952880859375, Neurons: 11, Grad norm: 1.908e+01\n",
      "Epoch 6872, Loss: 789.7716064453125, Neurons: 11, Grad norm: 2.726e+01\n",
      "Epoch 6873, Loss: 789.748291015625, Neurons: 11, Grad norm: 2.028e+01\n",
      "Epoch 6874, Loss: 789.7247924804688, Neurons: 11, Grad norm: 1.670e+01\n",
      "Epoch 6875, Loss: 789.7013549804688, Neurons: 11, Grad norm: 2.140e+01\n",
      "Epoch 6876, Loss: 789.6778564453125, Neurons: 11, Grad norm: 1.524e+01\n",
      "Epoch 6877, Loss: 789.6543579101562, Neurons: 11, Grad norm: 6.280e+01\n",
      "Epoch 6878, Loss: 789.6322021484375, Neurons: 11, Grad norm: 7.592e+01\n",
      "Epoch 6879, Loss: 789.60986328125, Neurons: 11, Grad norm: 9.961e+00\n",
      "Epoch 6880, Loss: 789.58447265625, Neurons: 11, Grad norm: 1.155e+02\n",
      "Epoch 6881, Loss: 789.5640869140625, Neurons: 11, Grad norm: 9.934e+01\n",
      "Epoch 6882, Loss: 789.5418701171875, Neurons: 11, Grad norm: 5.170e+01\n",
      "Epoch 6883, Loss: 789.515869140625, Neurons: 11, Grad norm: 9.176e+01\n",
      "Epoch 6884, Loss: 789.4953002929688, Neurons: 11, Grad norm: 3.204e+01\n",
      "Epoch 6885, Loss: 789.4689331054688, Neurons: 11, Grad norm: 8.689e+01\n",
      "Epoch 6886, Loss: 789.4486083984375, Neurons: 11, Grad norm: 1.809e+01\n",
      "Epoch 6887, Loss: 789.42236328125, Neurons: 11, Grad norm: 7.978e+01\n",
      "Epoch 6888, Loss: 789.4017944335938, Neurons: 11, Grad norm: 5.606e+00\n",
      "Epoch 6889, Loss: 789.3758544921875, Neurons: 11, Grad norm: 7.640e+01\n",
      "Epoch 6890, Loss: 789.35498046875, Neurons: 11, Grad norm: 3.224e+00\n",
      "Epoch 6891, Loss: 789.32958984375, Neurons: 11, Grad norm: 6.529e+01\n",
      "Epoch 6892, Loss: 789.3082885742188, Neurons: 11, Grad norm: 9.042e+00\n",
      "Epoch 6893, Loss: 789.2833862304688, Neurons: 11, Grad norm: 5.878e+01\n",
      "Epoch 6894, Loss: 789.2616577148438, Neurons: 11, Grad norm: 1.328e+01\n",
      "Epoch 6895, Loss: 789.237060546875, Neurons: 11, Grad norm: 5.040e+01\n",
      "Epoch 6896, Loss: 789.2149658203125, Neurons: 11, Grad norm: 1.933e+01\n",
      "Epoch 6897, Loss: 789.1908569335938, Neurons: 11, Grad norm: 4.707e+01\n",
      "Epoch 6898, Loss: 789.16845703125, Neurons: 11, Grad norm: 1.830e+01\n",
      "Epoch 6899, Loss: 789.1446533203125, Neurons: 11, Grad norm: 3.765e+01\n",
      "Epoch 6899, Test loss: 797.060791015625\n",
      "Epoch 6900, Loss: 789.1220092773438, Neurons: 11, Grad norm: 2.213e+01\n",
      "Epoch 6901, Loss: 789.0984497070312, Neurons: 11, Grad norm: 3.303e+01\n",
      "Epoch 6902, Loss: 789.0755615234375, Neurons: 11, Grad norm: 2.117e+01\n",
      "Epoch 6903, Loss: 789.0523071289062, Neurons: 11, Grad norm: 4.409e+01\n",
      "Epoch 6904, Loss: 789.029296875, Neurons: 11, Grad norm: 5.550e+01\n",
      "Epoch 6905, Loss: 789.0070190429688, Neurons: 11, Grad norm: 2.590e+01\n",
      "Epoch 6906, Loss: 788.9829711914062, Neurons: 11, Grad norm: 8.848e+01\n",
      "Epoch 6907, Loss: 788.9627685546875, Neurons: 11, Grad norm: 5.474e+01\n",
      "Epoch 6908, Loss: 788.9379272460938, Neurons: 11, Grad norm: 4.594e+01\n",
      "Epoch 6909, Loss: 788.91455078125, Neurons: 11, Grad norm: 8.340e+01\n",
      "Epoch 6910, Loss: 788.892333984375, Neurons: 11, Grad norm: 2.761e+01\n",
      "Epoch 6911, Loss: 788.8681640625, Neurons: 11, Grad norm: 4.578e+01\n",
      "Epoch 6912, Loss: 788.8458862304688, Neurons: 11, Grad norm: 2.463e+01\n",
      "Epoch 6913, Loss: 788.822509765625, Neurons: 11, Grad norm: 3.638e+01\n",
      "Epoch 6914, Loss: 788.7998046875, Neurons: 11, Grad norm: 2.690e+01\n",
      "Epoch 6915, Loss: 788.7766723632812, Neurons: 11, Grad norm: 3.191e+01\n",
      "Epoch 6916, Loss: 788.75390625, Neurons: 11, Grad norm: 2.560e+01\n",
      "Epoch 6917, Loss: 788.7308349609375, Neurons: 11, Grad norm: 2.515e+01\n",
      "Epoch 6918, Loss: 788.7078857421875, Neurons: 11, Grad norm: 2.753e+01\n",
      "Epoch 6919, Loss: 788.6849365234375, Neurons: 11, Grad norm: 2.372e+01\n",
      "Epoch 6920, Loss: 788.6619262695312, Neurons: 11, Grad norm: 2.349e+01\n",
      "Epoch 6921, Loss: 788.6390380859375, Neurons: 11, Grad norm: 1.695e+01\n",
      "Epoch 6922, Loss: 788.615966796875, Neurons: 11, Grad norm: 2.447e+01\n",
      "Epoch 6923, Loss: 788.5930786132812, Neurons: 11, Grad norm: 1.488e+01\n",
      "Epoch 6924, Loss: 788.5700073242188, Neurons: 11, Grad norm: 2.177e+01\n",
      "Epoch 6925, Loss: 788.5472412109375, Neurons: 11, Grad norm: 9.844e+00\n",
      "Epoch 6926, Loss: 788.5241088867188, Neurons: 11, Grad norm: 2.293e+01\n",
      "Epoch 6927, Loss: 788.5012817382812, Neurons: 11, Grad norm: 9.892e+00\n",
      "Epoch 6928, Loss: 788.4782104492188, Neurons: 11, Grad norm: 3.918e+01\n",
      "Epoch 6929, Loss: 788.4555053710938, Neurons: 11, Grad norm: 3.333e+01\n",
      "Epoch 6930, Loss: 788.4327392578125, Neurons: 11, Grad norm: 1.999e+01\n",
      "Epoch 6931, Loss: 788.4095458984375, Neurons: 11, Grad norm: 7.774e+01\n",
      "Epoch 6932, Loss: 788.3881225585938, Neurons: 11, Grad norm: 7.181e+01\n",
      "Epoch 6933, Loss: 788.3657836914062, Neurons: 11, Grad norm: 2.858e+01\n",
      "Epoch 6934, Loss: 788.34130859375, Neurons: 11, Grad norm: 6.954e+01\n",
      "Epoch 6935, Loss: 788.3198852539062, Neurons: 11, Grad norm: 3.865e+00\n",
      "Epoch 6936, Loss: 788.29541015625, Neurons: 11, Grad norm: 5.780e+01\n",
      "Epoch 6937, Loss: 788.2741088867188, Neurons: 11, Grad norm: 3.863e+00\n",
      "Epoch 6938, Loss: 788.2498779296875, Neurons: 11, Grad norm: 5.171e+01\n",
      "Epoch 6939, Loss: 788.2282104492188, Neurons: 11, Grad norm: 6.592e+00\n",
      "Epoch 6940, Loss: 788.2042846679688, Neurons: 11, Grad norm: 4.856e+01\n",
      "Epoch 6941, Loss: 788.182373046875, Neurons: 11, Grad norm: 6.026e+00\n",
      "Epoch 6942, Loss: 788.15869140625, Neurons: 11, Grad norm: 3.962e+01\n",
      "Epoch 6943, Loss: 788.1365966796875, Neurons: 11, Grad norm: 1.096e+01\n",
      "Epoch 6944, Loss: 788.1130981445312, Neurons: 11, Grad norm: 3.704e+01\n",
      "Epoch 6945, Loss: 788.0907592773438, Neurons: 11, Grad norm: 1.142e+01\n",
      "Epoch 6946, Loss: 788.0675048828125, Neurons: 11, Grad norm: 3.316e+01\n",
      "Epoch 6947, Loss: 788.0449829101562, Neurons: 11, Grad norm: 1.677e+01\n",
      "Epoch 6948, Loss: 788.0218505859375, Neurons: 11, Grad norm: 2.990e+01\n",
      "Epoch 6949, Loss: 787.999267578125, Neurons: 11, Grad norm: 6.320e+01\n",
      "Epoch 6949, Test loss: 795.8953247070312\n",
      "Epoch 6950, Loss: 787.97705078125, Neurons: 11, Grad norm: 6.514e+01\n",
      "Epoch 6951, Loss: 787.9551391601562, Neurons: 11, Grad norm: 1.470e+01\n",
      "Epoch 6952, Loss: 787.9309692382812, Neurons: 11, Grad norm: 8.800e+01\n",
      "Epoch 6953, Loss: 787.9098510742188, Neurons: 11, Grad norm: 5.765e+01\n",
      "Epoch 6954, Loss: 787.8867797851562, Neurons: 11, Grad norm: 4.808e+01\n",
      "Epoch 6955, Loss: 787.86376953125, Neurons: 11, Grad norm: 5.239e+01\n",
      "Epoch 6956, Loss: 787.8414306640625, Neurons: 11, Grad norm: 3.945e+01\n",
      "Epoch 6957, Loss: 787.8182983398438, Neurons: 11, Grad norm: 4.984e+01\n",
      "Epoch 6958, Loss: 787.7959594726562, Neurons: 11, Grad norm: 3.408e+01\n",
      "Epoch 6959, Loss: 787.7727661132812, Neurons: 11, Grad norm: 4.435e+01\n",
      "Epoch 6960, Loss: 787.7506103515625, Neurons: 11, Grad norm: 2.527e+01\n",
      "Epoch 6961, Loss: 787.7273559570312, Neurons: 11, Grad norm: 4.470e+01\n",
      "Epoch 6962, Loss: 787.705078125, Neurons: 11, Grad norm: 2.355e+01\n",
      "Epoch 6963, Loss: 787.681884765625, Neurons: 11, Grad norm: 3.938e+01\n",
      "Epoch 6964, Loss: 787.65966796875, Neurons: 11, Grad norm: 1.803e+01\n",
      "Epoch 6965, Loss: 787.636474609375, Neurons: 11, Grad norm: 3.752e+01\n",
      "Epoch 6966, Loss: 787.6141967773438, Neurons: 11, Grad norm: 1.597e+01\n",
      "Epoch 6967, Loss: 787.591064453125, Neurons: 11, Grad norm: 3.227e+01\n",
      "Epoch 6968, Loss: 787.5687255859375, Neurons: 11, Grad norm: 1.001e+01\n",
      "Epoch 6969, Loss: 787.545654296875, Neurons: 11, Grad norm: 3.264e+01\n",
      "Epoch 6970, Loss: 787.5232543945312, Neurons: 11, Grad norm: 1.004e+01\n",
      "Epoch 6971, Loss: 787.500244140625, Neurons: 11, Grad norm: 7.239e+01\n",
      "Epoch 6972, Loss: 787.4786987304688, Neurons: 11, Grad norm: 7.351e+01\n",
      "Epoch 6973, Loss: 787.4570922851562, Neurons: 11, Grad norm: 2.640e+01\n",
      "Epoch 6974, Loss: 787.4326782226562, Neurons: 11, Grad norm: 1.027e+02\n",
      "Epoch 6975, Loss: 787.4121704101562, Neurons: 11, Grad norm: 5.733e+01\n",
      "Epoch 6976, Loss: 787.3885498046875, Neurons: 11, Grad norm: 5.875e+01\n",
      "Epoch 6977, Loss: 787.3661499023438, Neurons: 11, Grad norm: 4.941e+01\n",
      "Epoch 6978, Loss: 787.3433837890625, Neurons: 11, Grad norm: 4.988e+01\n",
      "Epoch 6979, Loss: 787.3208618164062, Neurons: 11, Grad norm: 4.573e+01\n",
      "Epoch 6980, Loss: 787.2982788085938, Neurons: 11, Grad norm: 4.328e+01\n",
      "Epoch 6981, Loss: 787.2755737304688, Neurons: 11, Grad norm: 4.135e+01\n",
      "Epoch 6982, Loss: 787.2530517578125, Neurons: 11, Grad norm: 3.526e+01\n",
      "Epoch 6983, Loss: 787.2304077148438, Neurons: 11, Grad norm: 4.217e+01\n",
      "Epoch 6984, Loss: 787.2078857421875, Neurons: 11, Grad norm: 3.503e+01\n",
      "Epoch 6985, Loss: 787.1851806640625, Neurons: 11, Grad norm: 3.561e+01\n",
      "Epoch 6986, Loss: 787.1626586914062, Neurons: 11, Grad norm: 2.918e+01\n",
      "Epoch 6987, Loss: 787.1399536132812, Neurons: 11, Grad norm: 3.334e+01\n",
      "Epoch 6988, Loss: 787.1175537109375, Neurons: 11, Grad norm: 2.603e+01\n",
      "Epoch 6989, Loss: 787.0947875976562, Neurons: 11, Grad norm: 2.921e+01\n",
      "Epoch 6990, Loss: 787.072265625, Neurons: 11, Grad norm: 2.016e+01\n",
      "Epoch 6991, Loss: 787.0496215820312, Neurons: 11, Grad norm: 3.031e+01\n",
      "Epoch 6992, Loss: 787.027099609375, Neurons: 11, Grad norm: 2.093e+01\n",
      "Epoch 6993, Loss: 787.00439453125, Neurons: 11, Grad norm: 6.134e+01\n",
      "Epoch 6994, Loss: 786.9823608398438, Neurons: 11, Grad norm: 4.757e+01\n",
      "Epoch 6995, Loss: 786.9600830078125, Neurons: 11, Grad norm: 2.516e+01\n",
      "Epoch 6996, Loss: 786.9369506835938, Neurons: 11, Grad norm: 7.474e+01\n",
      "Epoch 6997, Loss: 786.9154052734375, Neurons: 11, Grad norm: 4.529e+01\n",
      "Epoch 6998, Loss: 786.8926391601562, Neurons: 11, Grad norm: 3.925e+01\n",
      "Epoch 6999, Loss: 786.8700561523438, Neurons: 11, Grad norm: 3.718e+01\n",
      "Epoch 6999, Test loss: 794.7716674804688\n",
      "Epoch 7000, Loss: 786.84765625, Neurons: 11, Grad norm: 3.233e+01\n",
      "Epoch 7001, Loss: 786.8250732421875, Neurons: 11, Grad norm: 3.478e+01\n",
      "Epoch 7002, Loss: 786.8027954101562, Neurons: 11, Grad norm: 2.850e+01\n",
      "Epoch 7003, Loss: 786.7800903320312, Neurons: 11, Grad norm: 3.124e+01\n",
      "Epoch 7004, Loss: 786.7577514648438, Neurons: 11, Grad norm: 2.313e+01\n",
      "Epoch 7005, Loss: 786.735107421875, Neurons: 11, Grad norm: 3.198e+01\n",
      "Epoch 7006, Loss: 786.7127685546875, Neurons: 11, Grad norm: 2.427e+01\n",
      "Epoch 7007, Loss: 786.690185546875, Neurons: 11, Grad norm: 2.584e+01\n",
      "Epoch 7008, Loss: 786.6677856445312, Neurons: 11, Grad norm: 1.927e+01\n",
      "Epoch 7009, Loss: 786.6452026367188, Neurons: 11, Grad norm: 2.482e+01\n",
      "Epoch 7010, Loss: 786.622802734375, Neurons: 11, Grad norm: 1.973e+01\n",
      "Epoch 7011, Loss: 786.60009765625, Neurons: 11, Grad norm: 7.007e+01\n",
      "Epoch 7012, Loss: 786.5789184570312, Neurons: 11, Grad norm: 6.548e+01\n",
      "Epoch 7013, Loss: 786.5567626953125, Neurons: 11, Grad norm: 2.787e+01\n",
      "Epoch 7014, Loss: 786.533203125, Neurons: 11, Grad norm: 9.578e+01\n",
      "Epoch 7015, Loss: 786.512451171875, Neurons: 11, Grad norm: 5.801e+01\n",
      "Epoch 7016, Loss: 786.4893798828125, Neurons: 11, Grad norm: 5.155e+01\n",
      "Epoch 7017, Loss: 786.4668579101562, Neurons: 11, Grad norm: 4.948e+01\n",
      "Epoch 7018, Loss: 786.4444580078125, Neurons: 11, Grad norm: 4.579e+01\n",
      "Epoch 7019, Loss: 786.4220581054688, Neurons: 11, Grad norm: 4.395e+01\n",
      "Epoch 7020, Loss: 786.399658203125, Neurons: 11, Grad norm: 4.098e+01\n",
      "Epoch 7021, Loss: 786.377197265625, Neurons: 11, Grad norm: 3.793e+01\n",
      "Epoch 7022, Loss: 786.3548583984375, Neurons: 11, Grad norm: 3.349e+01\n",
      "Epoch 7023, Loss: 786.3324584960938, Neurons: 11, Grad norm: 3.855e+01\n",
      "Epoch 7024, Loss: 786.31005859375, Neurons: 11, Grad norm: 3.416e+01\n",
      "Epoch 7025, Loss: 786.2875366210938, Neurons: 11, Grad norm: 3.222e+01\n",
      "Epoch 7026, Loss: 786.26513671875, Neurons: 11, Grad norm: 2.994e+01\n",
      "Epoch 7027, Loss: 786.24267578125, Neurons: 11, Grad norm: 2.929e+01\n",
      "Epoch 7028, Loss: 786.2202758789062, Neurons: 11, Grad norm: 2.764e+01\n",
      "Epoch 7029, Loss: 786.1978759765625, Neurons: 11, Grad norm: 2.447e+01\n",
      "Epoch 7030, Loss: 786.1754150390625, Neurons: 11, Grad norm: 2.182e+01\n",
      "Epoch 7031, Loss: 786.1529541015625, Neurons: 11, Grad norm: 2.575e+01\n",
      "Epoch 7032, Loss: 786.1305541992188, Neurons: 11, Grad norm: 2.492e+01\n",
      "Epoch 7033, Loss: 786.108154296875, Neurons: 11, Grad norm: 6.192e+01\n",
      "Epoch 7034, Loss: 786.0872802734375, Neurons: 11, Grad norm: 4.796e+01\n",
      "Epoch 7035, Loss: 786.06396484375, Neurons: 11, Grad norm: 9.644e+00\n",
      "Epoch 7036, Loss: 786.0411376953125, Neurons: 11, Grad norm: 5.614e+01\n",
      "Epoch 7037, Loss: 786.0194091796875, Neurons: 11, Grad norm: 5.862e+01\n",
      "Epoch 7038, Loss: 785.9977416992188, Neurons: 11, Grad norm: 1.949e+01\n",
      "Epoch 7039, Loss: 785.9744262695312, Neurons: 11, Grad norm: 5.081e+01\n",
      "Epoch 7040, Loss: 785.9530029296875, Neurons: 11, Grad norm: 8.675e+00\n",
      "Epoch 7041, Loss: 785.9298706054688, Neurons: 11, Grad norm: 4.225e+01\n",
      "Epoch 7042, Loss: 785.9083862304688, Neurons: 11, Grad norm: 7.113e+00\n",
      "Epoch 7043, Loss: 785.8853149414062, Neurons: 11, Grad norm: 3.846e+01\n",
      "Epoch 7044, Loss: 785.8636474609375, Neurons: 11, Grad norm: 4.827e+00\n",
      "Epoch 7045, Loss: 785.8407592773438, Neurons: 11, Grad norm: 3.875e+01\n",
      "Epoch 7046, Loss: 785.8189697265625, Neurons: 11, Grad norm: 8.817e+00\n",
      "Epoch 7047, Loss: 785.7962036132812, Neurons: 11, Grad norm: 3.074e+01\n",
      "Epoch 7048, Loss: 785.7742309570312, Neurons: 11, Grad norm: 6.390e+00\n",
      "Epoch 7049, Loss: 785.7515869140625, Neurons: 11, Grad norm: 2.831e+01\n",
      "Epoch 7049, Test loss: 793.6136474609375\n",
      "Epoch 7050, Loss: 785.7295532226562, Neurons: 11, Grad norm: 5.819e+00\n",
      "Epoch 7051, Loss: 785.7069091796875, Neurons: 11, Grad norm: 2.479e+01\n",
      "Epoch 7052, Loss: 785.6847534179688, Neurons: 11, Grad norm: 3.756e+00\n",
      "Epoch 7053, Loss: 785.6621704101562, Neurons: 11, Grad norm: 2.566e+01\n",
      "Epoch 7054, Loss: 785.6399536132812, Neurons: 11, Grad norm: 4.262e+01\n",
      "Epoch 7055, Loss: 785.618408203125, Neurons: 11, Grad norm: 5.982e+01\n",
      "Epoch 7056, Loss: 785.5965576171875, Neurons: 11, Grad norm: 3.634e+01\n",
      "Epoch 7057, Loss: 785.5734252929688, Neurons: 11, Grad norm: 1.607e+01\n",
      "Epoch 7058, Loss: 785.551025390625, Neurons: 11, Grad norm: 5.686e+00\n",
      "Epoch 7059, Loss: 785.5286865234375, Neurons: 11, Grad norm: 1.013e+01\n",
      "Epoch 7060, Loss: 785.5065307617188, Neurons: 11, Grad norm: 4.813e+00\n",
      "Epoch 7061, Loss: 785.4843139648438, Neurons: 11, Grad norm: 9.517e+00\n",
      "Epoch 7062, Loss: 785.462158203125, Neurons: 11, Grad norm: 4.197e+00\n",
      "Epoch 7063, Loss: 785.4398803710938, Neurons: 11, Grad norm: 7.940e+00\n",
      "Epoch 7064, Loss: 785.4176025390625, Neurons: 11, Grad norm: 3.999e+00\n",
      "Epoch 7065, Loss: 785.3953857421875, Neurons: 11, Grad norm: 1.124e+01\n",
      "Epoch 7066, Loss: 785.3731079101562, Neurons: 11, Grad norm: 4.491e+00\n",
      "Epoch 7067, Loss: 785.3507690429688, Neurons: 11, Grad norm: 7.086e+00\n",
      "Epoch 7068, Loss: 785.3284912109375, Neurons: 11, Grad norm: 4.930e+00\n",
      "Epoch 7069, Loss: 785.30615234375, Neurons: 11, Grad norm: 1.173e+01\n",
      "Epoch 7070, Loss: 785.2838745117188, Neurons: 11, Grad norm: 2.464e+01\n",
      "Epoch 7071, Loss: 785.2617797851562, Neurons: 11, Grad norm: 4.475e+01\n",
      "Epoch 7072, Loss: 785.2398681640625, Neurons: 11, Grad norm: 5.738e+01\n",
      "Epoch 7073, Loss: 785.2183837890625, Neurons: 11, Grad norm: 1.036e+01\n",
      "Epoch 7074, Loss: 785.1951904296875, Neurons: 11, Grad norm: 9.091e+01\n",
      "Epoch 7075, Loss: 785.1744384765625, Neurons: 11, Grad norm: 7.609e+01\n",
      "Epoch 7076, Loss: 785.1527709960938, Neurons: 11, Grad norm: 4.505e+01\n",
      "Epoch 7077, Loss: 785.1292724609375, Neurons: 11, Grad norm: 6.701e+01\n",
      "Epoch 7078, Loss: 785.1082153320312, Neurons: 11, Grad norm: 4.000e+01\n",
      "Epoch 7079, Loss: 785.0848999023438, Neurons: 11, Grad norm: 6.046e+01\n",
      "Epoch 7080, Loss: 785.0635986328125, Neurons: 11, Grad norm: 3.703e+01\n",
      "Epoch 7081, Loss: 785.0404052734375, Neurons: 11, Grad norm: 5.185e+01\n",
      "Epoch 7082, Loss: 785.0189208984375, Neurons: 11, Grad norm: 2.991e+01\n",
      "Epoch 7083, Loss: 784.9959716796875, Neurons: 11, Grad norm: 5.031e+01\n",
      "Epoch 7084, Loss: 784.974365234375, Neurons: 11, Grad norm: 3.009e+01\n",
      "Epoch 7085, Loss: 784.9514770507812, Neurons: 11, Grad norm: 4.351e+01\n",
      "Epoch 7086, Loss: 784.9297485351562, Neurons: 11, Grad norm: 2.651e+01\n",
      "Epoch 7087, Loss: 784.906982421875, Neurons: 11, Grad norm: 3.990e+01\n",
      "Epoch 7088, Loss: 784.8850708007812, Neurons: 11, Grad norm: 2.558e+01\n",
      "Epoch 7089, Loss: 784.8624877929688, Neurons: 11, Grad norm: 4.741e+01\n",
      "Epoch 7090, Loss: 784.840576171875, Neurons: 11, Grad norm: 6.389e+00\n",
      "Epoch 7091, Loss: 784.8178100585938, Neurons: 11, Grad norm: 3.419e+01\n",
      "Epoch 7092, Loss: 784.7959594726562, Neurons: 11, Grad norm: 4.368e+01\n",
      "Epoch 7093, Loss: 784.7738647460938, Neurons: 11, Grad norm: 4.532e+01\n",
      "Epoch 7094, Loss: 784.751953125, Neurons: 11, Grad norm: 3.760e+00\n",
      "Epoch 7095, Loss: 784.7291870117188, Neurons: 11, Grad norm: 5.844e+01\n",
      "Epoch 7096, Loss: 784.7075805664062, Neurons: 11, Grad norm: 6.018e+01\n",
      "Epoch 7097, Loss: 784.686279296875, Neurons: 11, Grad norm: 2.635e+01\n",
      "Epoch 7098, Loss: 784.6632080078125, Neurons: 11, Grad norm: 4.992e+01\n",
      "Epoch 7099, Loss: 784.6419067382812, Neurons: 11, Grad norm: 2.193e+01\n",
      "Epoch 7099, Test loss: 792.5253295898438\n",
      "Epoch 7100, Loss: 784.6189575195312, Neurons: 11, Grad norm: 4.553e+01\n",
      "Epoch 7101, Loss: 784.5975341796875, Neurons: 11, Grad norm: 2.019e+01\n",
      "Epoch 7102, Loss: 784.57470703125, Neurons: 11, Grad norm: 4.024e+01\n",
      "Epoch 7103, Loss: 784.5531005859375, Neurons: 11, Grad norm: 1.652e+01\n",
      "Epoch 7104, Loss: 784.5303955078125, Neurons: 11, Grad norm: 3.948e+01\n",
      "Epoch 7105, Loss: 784.5086669921875, Neurons: 11, Grad norm: 1.906e+01\n",
      "Epoch 7106, Loss: 784.4860229492188, Neurons: 11, Grad norm: 3.218e+01\n",
      "Epoch 7107, Loss: 784.4641723632812, Neurons: 11, Grad norm: 1.551e+01\n",
      "Epoch 7108, Loss: 784.441650390625, Neurons: 11, Grad norm: 3.003e+01\n",
      "Epoch 7109, Loss: 784.419677734375, Neurons: 11, Grad norm: 8.485e+00\n",
      "Epoch 7110, Loss: 784.3971557617188, Neurons: 11, Grad norm: 5.581e+01\n",
      "Epoch 7111, Loss: 784.3760986328125, Neurons: 11, Grad norm: 6.153e+01\n",
      "Epoch 7112, Loss: 784.354248046875, Neurons: 11, Grad norm: 2.289e+01\n",
      "Epoch 7113, Loss: 784.3310546875, Neurons: 11, Grad norm: 7.841e+01\n",
      "Epoch 7114, Loss: 784.3114013671875, Neurons: 11, Grad norm: 3.277e+01\n",
      "Epoch 7115, Loss: 784.2869262695312, Neurons: 11, Grad norm: 5.056e+01\n",
      "Epoch 7116, Loss: 784.2655029296875, Neurons: 11, Grad norm: 4.630e+01\n",
      "Epoch 7117, Loss: 784.2427978515625, Neurons: 11, Grad norm: 1.492e+01\n",
      "Epoch 7118, Loss: 784.220458984375, Neurons: 11, Grad norm: 2.636e+01\n",
      "Epoch 7119, Loss: 784.1986083984375, Neurons: 11, Grad norm: 1.694e+01\n",
      "Epoch 7120, Loss: 784.1763305664062, Neurons: 11, Grad norm: 1.920e+01\n",
      "Epoch 7121, Loss: 784.1543579101562, Neurons: 11, Grad norm: 1.148e+01\n",
      "Epoch 7122, Loss: 784.132080078125, Neurons: 11, Grad norm: 2.008e+01\n",
      "Epoch 7123, Loss: 784.1100463867188, Neurons: 11, Grad norm: 1.197e+01\n",
      "Epoch 7124, Loss: 784.0877685546875, Neurons: 11, Grad norm: 2.705e+01\n",
      "Epoch 7125, Loss: 784.0657348632812, Neurons: 11, Grad norm: 1.001e+01\n",
      "Epoch 7126, Loss: 784.04345703125, Neurons: 11, Grad norm: 1.756e+01\n",
      "Epoch 7127, Loss: 784.0213623046875, Neurons: 11, Grad norm: 5.172e+01\n",
      "Epoch 7128, Loss: 783.999755859375, Neurons: 11, Grad norm: 6.833e+01\n",
      "Epoch 7129, Loss: 783.978759765625, Neurons: 11, Grad norm: 1.541e+01\n",
      "Epoch 7130, Loss: 783.955078125, Neurons: 11, Grad norm: 8.526e+01\n",
      "Epoch 7131, Loss: 783.935791015625, Neurons: 11, Grad norm: 3.672e+01\n",
      "Epoch 7132, Loss: 783.9114379882812, Neurons: 11, Grad norm: 5.619e+01\n",
      "Epoch 7133, Loss: 783.8900756835938, Neurons: 11, Grad norm: 3.074e+01\n",
      "Epoch 7134, Loss: 783.8671875, Neurons: 11, Grad norm: 7.608e+01\n",
      "Epoch 7135, Loss: 783.8458862304688, Neurons: 11, Grad norm: 7.185e+01\n",
      "Epoch 7136, Loss: 783.8245849609375, Neurons: 11, Grad norm: 5.162e+01\n",
      "Epoch 7137, Loss: 783.8016967773438, Neurons: 11, Grad norm: 5.809e+01\n",
      "Epoch 7138, Loss: 783.7801513671875, Neurons: 11, Grad norm: 4.336e+01\n",
      "Epoch 7139, Loss: 783.7573852539062, Neurons: 11, Grad norm: 5.371e+01\n",
      "Epoch 7140, Loss: 783.7356567382812, Neurons: 11, Grad norm: 4.119e+01\n",
      "Epoch 7141, Loss: 783.7131958007812, Neurons: 11, Grad norm: 5.037e+01\n",
      "Epoch 7142, Loss: 783.6912231445312, Neurons: 11, Grad norm: 3.286e+01\n",
      "Epoch 7143, Loss: 783.668701171875, Neurons: 11, Grad norm: 4.257e+01\n",
      "Epoch 7144, Loss: 783.6467895507812, Neurons: 11, Grad norm: 3.529e+01\n",
      "Epoch 7145, Loss: 783.6243896484375, Neurons: 11, Grad norm: 6.530e+01\n",
      "Epoch 7146, Loss: 783.6035766601562, Neurons: 11, Grad norm: 3.015e+01\n",
      "Epoch 7147, Loss: 783.580078125, Neurons: 11, Grad norm: 3.210e+01\n",
      "Epoch 7148, Loss: 783.55810546875, Neurons: 11, Grad norm: 4.762e+01\n",
      "Epoch 7149, Loss: 783.5372924804688, Neurons: 11, Grad norm: 1.040e+01\n",
      "Epoch 7149, Test loss: 791.3983154296875\n",
      "Epoch 7150, Loss: 783.5138549804688, Neurons: 11, Grad norm: 6.708e+01\n",
      "Epoch 7151, Loss: 783.4933471679688, Neurons: 11, Grad norm: 7.900e+00\n",
      "Epoch 7152, Loss: 783.4697875976562, Neurons: 11, Grad norm: 1.029e+02\n",
      "Epoch 7153, Loss: 783.449951171875, Neurons: 11, Grad norm: 8.448e+01\n",
      "Epoch 7154, Loss: 783.428466796875, Neurons: 11, Grad norm: 6.142e+01\n",
      "Epoch 7155, Loss: 783.4053955078125, Neurons: 11, Grad norm: 6.862e+01\n",
      "Epoch 7156, Loss: 783.3839721679688, Neurons: 11, Grad norm: 5.639e+01\n",
      "Epoch 7157, Loss: 783.3613891601562, Neurons: 11, Grad norm: 5.935e+01\n",
      "Epoch 7158, Loss: 783.339599609375, Neurons: 11, Grad norm: 5.399e+01\n",
      "Epoch 7159, Loss: 783.3172607421875, Neurons: 11, Grad norm: 4.986e+01\n",
      "Epoch 7160, Loss: 783.2951049804688, Neurons: 11, Grad norm: 4.983e+01\n",
      "Epoch 7161, Loss: 783.273193359375, Neurons: 11, Grad norm: 4.498e+01\n",
      "Epoch 7162, Loss: 783.2507934570312, Neurons: 11, Grad norm: 5.158e+01\n",
      "Epoch 7163, Loss: 783.22900390625, Neurons: 11, Grad norm: 3.384e+01\n",
      "Epoch 7164, Loss: 783.2064208984375, Neurons: 11, Grad norm: 4.647e+01\n",
      "Epoch 7165, Loss: 783.1847534179688, Neurons: 11, Grad norm: 2.865e+01\n",
      "Epoch 7166, Loss: 783.162109375, Neurons: 11, Grad norm: 4.429e+01\n",
      "Epoch 7167, Loss: 783.1405029296875, Neurons: 11, Grad norm: 6.419e+01\n",
      "Epoch 7168, Loss: 783.1182861328125, Neurons: 11, Grad norm: 3.280e+01\n",
      "Epoch 7169, Loss: 783.0960083007812, Neurons: 11, Grad norm: 2.786e+01\n",
      "Epoch 7170, Loss: 783.0740356445312, Neurons: 11, Grad norm: 5.838e+01\n",
      "Epoch 7171, Loss: 783.0521850585938, Neurons: 11, Grad norm: 4.340e+01\n",
      "Epoch 7172, Loss: 783.0304565429688, Neurons: 11, Grad norm: 2.617e+01\n",
      "Epoch 7173, Loss: 783.008056640625, Neurons: 11, Grad norm: 3.596e+01\n",
      "Epoch 7174, Loss: 782.9863891601562, Neurons: 11, Grad norm: 2.462e+01\n",
      "Epoch 7175, Loss: 782.9641723632812, Neurons: 11, Grad norm: 2.952e+01\n",
      "Epoch 7176, Loss: 782.9422607421875, Neurons: 11, Grad norm: 2.416e+01\n",
      "Epoch 7177, Loss: 782.9201049804688, Neurons: 11, Grad norm: 2.549e+01\n",
      "Epoch 7178, Loss: 782.898193359375, Neurons: 11, Grad norm: 2.402e+01\n",
      "Epoch 7179, Loss: 782.8759765625, Neurons: 11, Grad norm: 3.969e+01\n",
      "Epoch 7180, Loss: 782.8543090820312, Neurons: 11, Grad norm: 2.353e+01\n",
      "Epoch 7181, Loss: 782.8319091796875, Neurons: 11, Grad norm: 3.960e+01\n",
      "Epoch 7182, Loss: 782.8115844726562, Neurons: 11, Grad norm: 1.873e+01\n",
      "Epoch 7183, Loss: 782.7890625, Neurons: 11, Grad norm: 1.199e+01\n",
      "Epoch 7184, Loss: 782.7669067382812, Neurons: 11, Grad norm: 9.094e+01\n",
      "Epoch 7185, Loss: 782.7467041015625, Neurons: 11, Grad norm: 3.690e+01\n",
      "Epoch 7186, Loss: 782.7235107421875, Neurons: 11, Grad norm: 5.637e+01\n",
      "Epoch 7187, Loss: 782.7027587890625, Neurons: 11, Grad norm: 2.692e+01\n",
      "Epoch 7188, Loss: 782.6781005859375, Neurons: 11, Grad norm: 5.484e+01\n",
      "Epoch 7189, Loss: 782.6571044921875, Neurons: 11, Grad norm: 5.007e+01\n",
      "Epoch 7190, Loss: 782.6353149414062, Neurons: 11, Grad norm: 3.659e+01\n",
      "Epoch 7191, Loss: 782.6123046875, Neurons: 11, Grad norm: 7.743e+01\n",
      "Epoch 7192, Loss: 782.5923461914062, Neurons: 11, Grad norm: 1.331e+01\n",
      "Epoch 7193, Loss: 782.5686645507812, Neurons: 11, Grad norm: 6.021e+01\n",
      "Epoch 7194, Loss: 782.5484008789062, Neurons: 11, Grad norm: 8.947e+00\n",
      "Epoch 7195, Loss: 782.524658203125, Neurons: 11, Grad norm: 5.720e+01\n",
      "Epoch 7196, Loss: 782.5039672851562, Neurons: 11, Grad norm: 1.280e+01\n",
      "Epoch 7197, Loss: 782.48095703125, Neurons: 11, Grad norm: 5.428e+01\n",
      "Epoch 7198, Loss: 782.4598999023438, Neurons: 11, Grad norm: 1.677e+01\n",
      "Epoch 7199, Loss: 782.436767578125, Neurons: 11, Grad norm: 4.843e+01\n",
      "Epoch 7199, Test loss: 790.2826538085938\n",
      "Epoch 7200, Loss: 782.41552734375, Neurons: 11, Grad norm: 2.337e+01\n",
      "Epoch 7201, Loss: 782.3928833007812, Neurons: 11, Grad norm: 6.203e+01\n",
      "Epoch 7202, Loss: 782.3713989257812, Neurons: 11, Grad norm: 2.795e+01\n",
      "Epoch 7203, Loss: 782.348876953125, Neurons: 11, Grad norm: 3.874e+01\n",
      "Epoch 7204, Loss: 782.3272094726562, Neurons: 11, Grad norm: 6.365e+01\n",
      "Epoch 7205, Loss: 782.3052978515625, Neurons: 11, Grad norm: 3.789e+01\n",
      "Epoch 7206, Loss: 782.2832641601562, Neurons: 11, Grad norm: 2.322e+01\n",
      "Epoch 7207, Loss: 782.260986328125, Neurons: 11, Grad norm: 2.842e+01\n",
      "Epoch 7208, Loss: 782.2393188476562, Neurons: 11, Grad norm: 1.885e+01\n",
      "Epoch 7209, Loss: 782.2171630859375, Neurons: 11, Grad norm: 2.786e+01\n",
      "Epoch 7210, Loss: 782.1951904296875, Neurons: 11, Grad norm: 2.131e+01\n",
      "Epoch 7211, Loss: 782.1731567382812, Neurons: 11, Grad norm: 6.061e+01\n",
      "Epoch 7212, Loss: 782.1513671875, Neurons: 11, Grad norm: 4.378e+01\n",
      "Epoch 7213, Loss: 782.1296997070312, Neurons: 11, Grad norm: 2.762e+01\n",
      "Epoch 7214, Loss: 782.1072998046875, Neurons: 11, Grad norm: 3.599e+01\n",
      "Epoch 7215, Loss: 782.0856323242188, Neurons: 11, Grad norm: 1.482e+01\n",
      "Epoch 7216, Loss: 782.063232421875, Neurons: 11, Grad norm: 3.152e+01\n",
      "Epoch 7217, Loss: 782.0414428710938, Neurons: 11, Grad norm: 1.754e+01\n",
      "Epoch 7218, Loss: 782.0191650390625, Neurons: 11, Grad norm: 5.966e+01\n",
      "Epoch 7219, Loss: 781.998291015625, Neurons: 11, Grad norm: 3.717e+01\n",
      "Epoch 7220, Loss: 781.9755249023438, Neurons: 11, Grad norm: 3.072e+01\n",
      "Epoch 7221, Loss: 781.953369140625, Neurons: 11, Grad norm: 7.014e+01\n",
      "Epoch 7222, Loss: 781.9320068359375, Neurons: 11, Grad norm: 5.228e+01\n",
      "Epoch 7223, Loss: 781.91015625, Neurons: 11, Grad norm: 3.454e+01\n",
      "Epoch 7224, Loss: 781.8876953125, Neurons: 11, Grad norm: 3.637e+01\n",
      "Epoch 7225, Loss: 781.865966796875, Neurons: 11, Grad norm: 3.541e+01\n",
      "Epoch 7226, Loss: 781.8439331054688, Neurons: 11, Grad norm: 2.703e+01\n",
      "Epoch 7227, Loss: 781.82177734375, Neurons: 11, Grad norm: 3.357e+01\n",
      "Epoch 7228, Loss: 781.7998046875, Neurons: 11, Grad norm: 4.090e+01\n",
      "Epoch 7229, Loss: 781.7774658203125, Neurons: 11, Grad norm: 6.455e+00\n",
      "Epoch 7230, Loss: 781.7553100585938, Neurons: 11, Grad norm: 2.670e+01\n",
      "Epoch 7231, Loss: 781.7334594726562, Neurons: 11, Grad norm: 4.457e+00\n",
      "Epoch 7232, Loss: 781.711181640625, Neurons: 11, Grad norm: 4.678e+01\n",
      "Epoch 7233, Loss: 781.6895751953125, Neurons: 11, Grad norm: 7.194e+01\n",
      "Epoch 7234, Loss: 781.6690063476562, Neurons: 11, Grad norm: 1.095e+01\n",
      "Epoch 7235, Loss: 781.6452026367188, Neurons: 11, Grad norm: 8.277e+01\n",
      "Epoch 7236, Loss: 781.6257934570312, Neurons: 11, Grad norm: 2.451e+01\n",
      "Epoch 7237, Loss: 781.6015014648438, Neurons: 11, Grad norm: 6.109e+01\n",
      "Epoch 7238, Loss: 781.5806884765625, Neurons: 11, Grad norm: 1.359e+01\n",
      "Epoch 7239, Loss: 781.5574340820312, Neurons: 11, Grad norm: 7.789e+01\n",
      "Epoch 7240, Loss: 781.5365600585938, Neurons: 11, Grad norm: 5.142e+01\n",
      "Epoch 7241, Loss: 781.5143432617188, Neurons: 11, Grad norm: 5.506e+01\n",
      "Epoch 7242, Loss: 781.4925537109375, Neurons: 11, Grad norm: 3.843e+01\n",
      "Epoch 7243, Loss: 781.469970703125, Neurons: 11, Grad norm: 5.277e+01\n",
      "Epoch 7244, Loss: 781.4483032226562, Neurons: 11, Grad norm: 3.581e+01\n",
      "Epoch 7245, Loss: 781.4256591796875, Neurons: 11, Grad norm: 5.053e+01\n",
      "Epoch 7246, Loss: 781.4041137695312, Neurons: 11, Grad norm: 6.935e+01\n",
      "Epoch 7247, Loss: 781.3817138671875, Neurons: 11, Grad norm: 2.762e+01\n",
      "Epoch 7248, Loss: 781.359375, Neurons: 11, Grad norm: 3.116e+01\n",
      "Epoch 7249, Loss: 781.3374633789062, Neurons: 11, Grad norm: 1.443e+01\n",
      "Epoch 7249, Test loss: 789.2144165039062\n",
      "Epoch 7250, Loss: 781.3153076171875, Neurons: 11, Grad norm: 6.896e+01\n",
      "Epoch 7251, Loss: 781.293701171875, Neurons: 11, Grad norm: 8.240e+01\n",
      "Epoch 7252, Loss: 781.2735595703125, Neurons: 11, Grad norm: 3.549e+01\n",
      "Epoch 7253, Loss: 781.2495727539062, Neurons: 11, Grad norm: 1.127e+02\n",
      "Epoch 7254, Loss: 781.2294921875, Neurons: 11, Grad norm: 3.778e+01\n",
      "Epoch 7255, Loss: 781.205810546875, Neurons: 11, Grad norm: 7.082e+01\n",
      "Epoch 7256, Loss: 781.1851806640625, Neurons: 11, Grad norm: 2.528e+01\n",
      "Epoch 7257, Loss: 781.1618041992188, Neurons: 11, Grad norm: 5.303e+01\n",
      "Epoch 7258, Loss: 781.1405639648438, Neurons: 11, Grad norm: 1.556e+01\n",
      "Epoch 7259, Loss: 781.1176147460938, Neurons: 11, Grad norm: 4.958e+01\n",
      "Epoch 7260, Loss: 781.0964965820312, Neurons: 11, Grad norm: 1.045e+01\n",
      "Epoch 7261, Loss: 781.0733642578125, Neurons: 11, Grad norm: 4.546e+01\n",
      "Epoch 7262, Loss: 781.0520629882812, Neurons: 11, Grad norm: 6.975e+00\n",
      "Epoch 7263, Loss: 781.0291137695312, Neurons: 11, Grad norm: 4.509e+01\n",
      "Epoch 7264, Loss: 781.0076904296875, Neurons: 11, Grad norm: 8.364e+00\n",
      "Epoch 7265, Loss: 780.9848022460938, Neurons: 11, Grad norm: 4.059e+01\n",
      "Epoch 7266, Loss: 780.9639892578125, Neurons: 11, Grad norm: 8.932e+00\n",
      "Epoch 7267, Loss: 780.9412231445312, Neurons: 11, Grad norm: 9.957e+00\n",
      "Epoch 7268, Loss: 780.9195556640625, Neurons: 11, Grad norm: 7.301e+01\n",
      "Epoch 7269, Loss: 780.8978881835938, Neurons: 11, Grad norm: 3.063e+01\n",
      "Epoch 7270, Loss: 780.8753662109375, Neurons: 11, Grad norm: 6.246e+01\n",
      "Epoch 7271, Loss: 780.8543701171875, Neurons: 11, Grad norm: 2.638e+01\n",
      "Epoch 7272, Loss: 780.830810546875, Neurons: 11, Grad norm: 6.191e+01\n",
      "Epoch 7273, Loss: 780.8097534179688, Neurons: 11, Grad norm: 1.815e+01\n",
      "Epoch 7274, Loss: 780.7862548828125, Neurons: 11, Grad norm: 5.881e+01\n",
      "Epoch 7275, Loss: 780.7651977539062, Neurons: 11, Grad norm: 1.031e+01\n",
      "Epoch 7276, Loss: 780.74169921875, Neurons: 11, Grad norm: 5.522e+01\n",
      "Epoch 7277, Loss: 780.7203979492188, Neurons: 11, Grad norm: 6.556e+00\n",
      "Epoch 7278, Loss: 780.6970825195312, Neurons: 11, Grad norm: 4.495e+01\n",
      "Epoch 7279, Loss: 780.6755981445312, Neurons: 11, Grad norm: 7.146e+00\n",
      "Epoch 7280, Loss: 780.6524047851562, Neurons: 11, Grad norm: 4.283e+01\n",
      "Epoch 7281, Loss: 780.6306762695312, Neurons: 11, Grad norm: 1.093e+01\n",
      "Epoch 7282, Loss: 780.6076049804688, Neurons: 11, Grad norm: 3.798e+01\n",
      "Epoch 7283, Loss: 780.585693359375, Neurons: 11, Grad norm: 1.269e+01\n",
      "Epoch 7284, Loss: 780.5628051757812, Neurons: 11, Grad norm: 3.484e+01\n",
      "Epoch 7285, Loss: 780.5407104492188, Neurons: 11, Grad norm: 1.759e+01\n",
      "Epoch 7286, Loss: 780.5178833007812, Neurons: 11, Grad norm: 2.618e+01\n",
      "Epoch 7287, Loss: 780.4956665039062, Neurons: 11, Grad norm: 1.560e+01\n",
      "Epoch 7288, Loss: 780.472900390625, Neurons: 11, Grad norm: 2.475e+01\n",
      "Epoch 7289, Loss: 780.4505004882812, Neurons: 11, Grad norm: 1.785e+01\n",
      "Epoch 7290, Loss: 780.4278564453125, Neurons: 11, Grad norm: 2.692e+01\n",
      "Epoch 7291, Loss: 780.4053955078125, Neurons: 11, Grad norm: 7.698e+00\n",
      "Epoch 7292, Loss: 780.3826904296875, Neurons: 11, Grad norm: 2.040e+01\n",
      "Epoch 7293, Loss: 780.3602294921875, Neurons: 11, Grad norm: 1.070e+01\n",
      "Epoch 7294, Loss: 780.3374633789062, Neurons: 11, Grad norm: 1.468e+01\n",
      "Epoch 7295, Loss: 780.31494140625, Neurons: 11, Grad norm: 9.398e+00\n",
      "Epoch 7296, Loss: 780.2922973632812, Neurons: 11, Grad norm: 1.503e+01\n",
      "Epoch 7297, Loss: 780.2696533203125, Neurons: 11, Grad norm: 1.079e+01\n",
      "Epoch 7298, Loss: 780.2470092773438, Neurons: 11, Grad norm: 1.263e+01\n",
      "Epoch 7299, Loss: 780.2243041992188, Neurons: 11, Grad norm: 9.592e+00\n",
      "Epoch 7299, Test loss: 788.0947265625\n",
      "Epoch 7300, Loss: 780.2015380859375, Neurons: 11, Grad norm: 1.317e+01\n",
      "Epoch 7301, Loss: 780.1787719726562, Neurons: 11, Grad norm: 1.205e+01\n",
      "Epoch 7302, Loss: 780.1560668945312, Neurons: 11, Grad norm: 9.607e+00\n",
      "Epoch 7303, Loss: 780.1332397460938, Neurons: 11, Grad norm: 1.021e+01\n",
      "Epoch 7304, Loss: 780.1103515625, Neurons: 11, Grad norm: 1.051e+01\n",
      "Epoch 7305, Loss: 780.0875244140625, Neurons: 11, Grad norm: 1.132e+01\n",
      "Epoch 7306, Loss: 780.064697265625, Neurons: 11, Grad norm: 9.052e+00\n",
      "Epoch 7307, Loss: 780.0418090820312, Neurons: 11, Grad norm: 9.714e+00\n",
      "Epoch 7308, Loss: 780.0188598632812, Neurons: 11, Grad norm: 9.727e+00\n",
      "Epoch 7309, Loss: 779.9959106445312, Neurons: 11, Grad norm: 1.152e+01\n",
      "Epoch 7310, Loss: 779.9729614257812, Neurons: 11, Grad norm: 8.409e+00\n",
      "Epoch 7311, Loss: 779.9498901367188, Neurons: 11, Grad norm: 9.904e+00\n",
      "Epoch 7312, Loss: 779.9268798828125, Neurons: 11, Grad norm: 9.193e+00\n",
      "Epoch 7313, Loss: 779.90380859375, Neurons: 11, Grad norm: 1.090e+01\n",
      "Epoch 7314, Loss: 779.8807983398438, Neurons: 11, Grad norm: 8.766e+00\n",
      "Epoch 7315, Loss: 779.8576049804688, Neurons: 11, Grad norm: 9.500e+00\n",
      "Epoch 7316, Loss: 779.83447265625, Neurons: 11, Grad norm: 9.110e+00\n",
      "Epoch 7317, Loss: 779.811279296875, Neurons: 11, Grad norm: 1.086e+01\n",
      "Epoch 7318, Loss: 779.7880859375, Neurons: 11, Grad norm: 9.058e+00\n",
      "Epoch 7319, Loss: 779.7648315429688, Neurons: 11, Grad norm: 9.787e+00\n",
      "Epoch 7320, Loss: 779.7415771484375, Neurons: 11, Grad norm: 9.468e+00\n",
      "Epoch 7321, Loss: 779.7182006835938, Neurons: 11, Grad norm: 1.067e+01\n",
      "Epoch 7322, Loss: 779.6948852539062, Neurons: 11, Grad norm: 9.581e+00\n",
      "Epoch 7323, Loss: 779.6714477539062, Neurons: 11, Grad norm: 9.759e+00\n",
      "Epoch 7324, Loss: 779.6480712890625, Neurons: 11, Grad norm: 9.674e+00\n",
      "Epoch 7325, Loss: 779.6245727539062, Neurons: 11, Grad norm: 1.076e+01\n",
      "Epoch 7326, Loss: 779.6010131835938, Neurons: 11, Grad norm: 1.006e+01\n",
      "Epoch 7327, Loss: 779.5774536132812, Neurons: 11, Grad norm: 1.024e+01\n",
      "Epoch 7328, Loss: 779.5538940429688, Neurons: 11, Grad norm: 1.026e+01\n",
      "Epoch 7329, Loss: 779.5302734375, Neurons: 11, Grad norm: 1.098e+01\n",
      "Epoch 7330, Loss: 779.506591796875, Neurons: 11, Grad norm: 1.058e+01\n",
      "Epoch 7331, Loss: 779.4828491210938, Neurons: 11, Grad norm: 1.053e+01\n",
      "Epoch 7332, Loss: 779.458984375, Neurons: 11, Grad norm: 1.063e+01\n",
      "Epoch 7333, Loss: 779.4351806640625, Neurons: 11, Grad norm: 1.129e+01\n",
      "Epoch 7334, Loss: 779.4112548828125, Neurons: 11, Grad norm: 1.113e+01\n",
      "Epoch 7335, Loss: 779.3873291015625, Neurons: 11, Grad norm: 1.116e+01\n",
      "Epoch 7336, Loss: 779.3633422851562, Neurons: 11, Grad norm: 1.132e+01\n",
      "Epoch 7337, Loss: 779.3392944335938, Neurons: 11, Grad norm: 1.177e+01\n",
      "Epoch 7338, Loss: 779.3150634765625, Neurons: 11, Grad norm: 1.173e+01\n",
      "Epoch 7339, Loss: 779.2909545898438, Neurons: 11, Grad norm: 1.168e+01\n",
      "Epoch 7340, Loss: 779.2666625976562, Neurons: 11, Grad norm: 1.186e+01\n",
      "Epoch 7341, Loss: 779.2423706054688, Neurons: 11, Grad norm: 1.230e+01\n",
      "Epoch 7342, Loss: 779.2179565429688, Neurons: 11, Grad norm: 1.239e+01\n",
      "Epoch 7343, Loss: 779.1934814453125, Neurons: 11, Grad norm: 1.244e+01\n",
      "Epoch 7344, Loss: 779.1690063476562, Neurons: 11, Grad norm: 1.264e+01\n",
      "Epoch 7345, Loss: 779.1444091796875, Neurons: 11, Grad norm: 1.298e+01\n",
      "Epoch 7346, Loss: 779.1197509765625, Neurons: 11, Grad norm: 1.310e+01\n",
      "Epoch 7347, Loss: 779.0949096679688, Neurons: 11, Grad norm: 1.314e+01\n",
      "Epoch 7348, Loss: 779.0700073242188, Neurons: 11, Grad norm: 1.336e+01\n",
      "Epoch 7349, Loss: 779.0451049804688, Neurons: 11, Grad norm: 1.371e+01\n",
      "Epoch 7349, Test loss: 786.9121704101562\n",
      "Epoch 7350, Loss: 779.0200805664062, Neurons: 11, Grad norm: 1.391e+01\n",
      "Epoch 7351, Loss: 778.9949951171875, Neurons: 11, Grad norm: 1.404e+01\n",
      "Epoch 7352, Loss: 778.9696655273438, Neurons: 11, Grad norm: 1.427e+01\n",
      "Epoch 7353, Loss: 778.9443969726562, Neurons: 11, Grad norm: 1.459e+01\n",
      "Epoch 7354, Loss: 778.9189453125, Neurons: 11, Grad norm: 1.480e+01\n",
      "Epoch 7355, Loss: 778.8933715820312, Neurons: 11, Grad norm: 1.495e+01\n",
      "Epoch 7356, Loss: 778.86767578125, Neurons: 11, Grad norm: 1.520e+01\n",
      "Epoch 7357, Loss: 778.8419799804688, Neurons: 11, Grad norm: 1.555e+01\n",
      "Epoch 7358, Loss: 778.8160400390625, Neurons: 11, Grad norm: 1.583e+01\n",
      "Epoch 7359, Loss: 778.7899780273438, Neurons: 11, Grad norm: 1.604e+01\n",
      "Epoch 7360, Loss: 778.7637939453125, Neurons: 11, Grad norm: 1.632e+01\n",
      "Epoch 7361, Loss: 778.7374877929688, Neurons: 11, Grad norm: 1.666e+01\n",
      "Epoch 7362, Loss: 778.7109985351562, Neurons: 11, Grad norm: 1.695e+01\n",
      "Epoch 7363, Loss: 778.6843872070312, Neurons: 11, Grad norm: 1.720e+01\n",
      "Epoch 7364, Loss: 778.6575927734375, Neurons: 11, Grad norm: 1.752e+01\n",
      "Epoch 7365, Loss: 778.6306762695312, Neurons: 11, Grad norm: 1.790e+01\n",
      "Epoch 7366, Loss: 778.6034545898438, Neurons: 11, Grad norm: 1.824e+01\n",
      "Epoch 7367, Loss: 778.576171875, Neurons: 11, Grad norm: 1.855e+01\n",
      "Epoch 7368, Loss: 778.5487670898438, Neurons: 11, Grad norm: 1.891e+01\n",
      "Epoch 7369, Loss: 778.5210571289062, Neurons: 11, Grad norm: 1.930e+01\n",
      "Epoch 7370, Loss: 778.4931030273438, Neurons: 11, Grad norm: 1.968e+01\n",
      "Epoch 7371, Loss: 778.4649658203125, Neurons: 11, Grad norm: 2.004e+01\n",
      "Epoch 7372, Loss: 778.4367065429688, Neurons: 11, Grad norm: 2.045e+01\n",
      "Epoch 7373, Loss: 778.4080200195312, Neurons: 11, Grad norm: 2.090e+01\n",
      "Epoch 7374, Loss: 778.3792114257812, Neurons: 11, Grad norm: 2.135e+01\n",
      "Epoch 7375, Loss: 778.3501586914062, Neurons: 11, Grad norm: 2.177e+01\n",
      "Epoch 7376, Loss: 778.3207397460938, Neurons: 11, Grad norm: 2.223e+01\n",
      "Epoch 7377, Loss: 778.2910766601562, Neurons: 11, Grad norm: 2.273e+01\n",
      "Epoch 7378, Loss: 778.2611083984375, Neurons: 11, Grad norm: 2.322e+01\n",
      "Epoch 7379, Loss: 778.2307739257812, Neurons: 11, Grad norm: 2.372e+01\n",
      "Epoch 7380, Loss: 778.2001342773438, Neurons: 11, Grad norm: 2.425e+01\n",
      "Epoch 7381, Loss: 778.1690673828125, Neurons: 11, Grad norm: 2.482e+01\n",
      "Epoch 7382, Loss: 778.1377563476562, Neurons: 11, Grad norm: 2.539e+01\n",
      "Epoch 7383, Loss: 778.10595703125, Neurons: 11, Grad norm: 2.597e+01\n",
      "Epoch 7384, Loss: 778.0737915039062, Neurons: 11, Grad norm: 2.658e+01\n",
      "Epoch 7385, Loss: 778.0411987304688, Neurons: 11, Grad norm: 2.723e+01\n",
      "Epoch 7386, Loss: 778.008056640625, Neurons: 11, Grad norm: 2.788e+01\n",
      "Epoch 7387, Loss: 777.9744873046875, Neurons: 11, Grad norm: 2.856e+01\n",
      "Epoch 7388, Loss: 777.9403686523438, Neurons: 11, Grad norm: 2.927e+01\n",
      "Epoch 7389, Loss: 777.90576171875, Neurons: 11, Grad norm: 3.002e+01\n",
      "Epoch 7390, Loss: 777.8705444335938, Neurons: 11, Grad norm: 3.079e+01\n",
      "Epoch 7391, Loss: 777.8346557617188, Neurons: 11, Grad norm: 3.158e+01\n",
      "Epoch 7392, Loss: 777.7981567382812, Neurons: 11, Grad norm: 3.240e+01\n",
      "Epoch 7393, Loss: 777.760986328125, Neurons: 11, Grad norm: 3.327e+01\n",
      "Epoch 7394, Loss: 777.7230834960938, Neurons: 11, Grad norm: 3.416e+01\n",
      "Epoch 7395, Loss: 777.684326171875, Neurons: 11, Grad norm: 3.509e+01\n",
      "Epoch 7396, Loss: 777.644775390625, Neurons: 11, Grad norm: 3.607e+01\n",
      "Epoch 7397, Loss: 777.6043701171875, Neurons: 11, Grad norm: 3.709e+01\n",
      "Epoch 7398, Loss: 777.5629272460938, Neurons: 11, Grad norm: 3.815e+01\n",
      "Epoch 7399, Loss: 777.5205688476562, Neurons: 11, Grad norm: 3.925e+01\n",
      "Epoch 7399, Test loss: 785.38818359375\n",
      "Epoch 7400, Loss: 777.4771118164062, Neurons: 11, Grad norm: 4.040e+01\n",
      "Epoch 7401, Loss: 777.4325561523438, Neurons: 11, Grad norm: 4.160e+01\n",
      "Epoch 7402, Loss: 777.3866577148438, Neurons: 11, Grad norm: 4.286e+01\n",
      "Epoch 7403, Loss: 777.3394775390625, Neurons: 11, Grad norm: 4.417e+01\n",
      "Epoch 7404, Loss: 777.2909545898438, Neurons: 11, Grad norm: 4.554e+01\n",
      "Epoch 7405, Loss: 777.2408447265625, Neurons: 11, Grad norm: 4.699e+01\n",
      "Epoch 7406, Loss: 777.1891479492188, Neurons: 11, Grad norm: 4.849e+01\n",
      "Epoch 7407, Loss: 777.1356811523438, Neurons: 11, Grad norm: 5.007e+01\n",
      "Epoch 7408, Loss: 777.0803833007812, Neurons: 11, Grad norm: 5.172e+01\n",
      "Epoch 7409, Loss: 777.0230102539062, Neurons: 11, Grad norm: 5.346e+01\n",
      "Epoch 7410, Loss: 776.9635009765625, Neurons: 11, Grad norm: 5.528e+01\n",
      "Epoch 7411, Loss: 776.9016723632812, Neurons: 11, Grad norm: 5.719e+01\n",
      "Epoch 7412, Loss: 776.8372192382812, Neurons: 11, Grad norm: 5.920e+01\n",
      "Epoch 7413, Loss: 776.7700805664062, Neurons: 11, Grad norm: 6.132e+01\n",
      "Epoch 7414, Loss: 776.699951171875, Neurons: 11, Grad norm: 6.355e+01\n",
      "Epoch 7415, Loss: 776.626708984375, Neurons: 11, Grad norm: 6.589e+01\n",
      "Epoch 7416, Loss: 776.5498657226562, Neurons: 11, Grad norm: 6.836e+01\n",
      "Epoch 7417, Loss: 776.46923828125, Neurons: 11, Grad norm: 7.097e+01\n",
      "Epoch 7418, Loss: 776.384521484375, Neurons: 11, Grad norm: 7.372e+01\n",
      "Epoch 7419, Loss: 776.2952880859375, Neurons: 11, Grad norm: 7.662e+01\n",
      "Epoch 7420, Loss: 776.201171875, Neurons: 11, Grad norm: 7.969e+01\n",
      "Epoch 7421, Loss: 776.101806640625, Neurons: 11, Grad norm: 8.294e+01\n",
      "Epoch 7422, Loss: 775.9964599609375, Neurons: 11, Grad norm: 8.638e+01\n",
      "Epoch 7423, Loss: 775.884765625, Neurons: 11, Grad norm: 9.002e+01\n",
      "Epoch 7424, Loss: 775.7660522460938, Neurons: 11, Grad norm: 9.388e+01\n",
      "Epoch 7425, Loss: 775.6397094726562, Neurons: 11, Grad norm: 9.798e+01\n",
      "Epoch 7426, Loss: 775.5048217773438, Neurons: 11, Grad norm: 1.023e+02\n",
      "Epoch 7427, Loss: 775.3606567382812, Neurons: 11, Grad norm: 1.069e+02\n",
      "Epoch 7428, Loss: 775.206298828125, Neurons: 11, Grad norm: 1.119e+02\n",
      "Epoch 7429, Loss: 775.0405883789062, Neurons: 11, Grad norm: 1.171e+02\n",
      "Epoch 7430, Loss: 774.8623657226562, Neurons: 11, Grad norm: 1.227e+02\n",
      "Epoch 7431, Loss: 774.67041015625, Neurons: 11, Grad norm: 1.286e+02\n",
      "Epoch 7432, Loss: 774.4629516601562, Neurons: 11, Grad norm: 1.349e+02\n",
      "Epoch 7433, Loss: 774.2387084960938, Neurons: 11, Grad norm: 1.417e+02\n",
      "Epoch 7434, Loss: 773.9954833984375, Neurons: 11, Grad norm: 1.489e+02\n",
      "Epoch 7435, Loss: 773.7313842773438, Neurons: 11, Grad norm: 1.567e+02\n",
      "Epoch 7436, Loss: 773.4439086914062, Neurons: 11, Grad norm: 1.649e+02\n",
      "Epoch 7437, Loss: 773.1304321289062, Neurons: 11, Grad norm: 1.738e+02\n",
      "Epoch 7438, Loss: 772.7879638671875, Neurons: 11, Grad norm: 1.832e+02\n",
      "Epoch 7439, Loss: 772.4132690429688, Neurons: 11, Grad norm: 1.933e+02\n",
      "Epoch 7440, Loss: 772.0023803710938, Neurons: 11, Grad norm: 2.042e+02\n",
      "Epoch 7441, Loss: 771.5512084960938, Neurons: 11, Grad norm: 2.158e+02\n",
      "Epoch 7442, Loss: 771.0550537109375, Neurons: 11, Grad norm: 2.282e+02\n",
      "Epoch 7443, Loss: 770.5086059570312, Neurons: 11, Grad norm: 2.416e+02\n",
      "Epoch 7444, Loss: 769.9060668945312, Neurons: 11, Grad norm: 2.558e+02\n",
      "Epoch 7445, Loss: 769.2409057617188, Neurons: 11, Grad norm: 2.711e+02\n",
      "Epoch 7446, Loss: 768.506103515625, Neurons: 11, Grad norm: 2.873e+02\n",
      "Epoch 7447, Loss: 767.6936645507812, Neurons: 11, Grad norm: 3.047e+02\n",
      "Epoch 7448, Loss: 766.795166015625, Neurons: 11, Grad norm: 3.233e+02\n",
      "Epoch 7449, Loss: 765.801513671875, Neurons: 11, Grad norm: 3.430e+02\n",
      "Epoch 7449, Test loss: 772.7496948242188\n",
      "Epoch 7450, Loss: 764.702880859375, Neurons: 11, Grad norm: 3.639e+02\n",
      "Epoch 7451, Loss: 763.4889526367188, Neurons: 11, Grad norm: 3.861e+02\n",
      "Epoch 7452, Loss: 762.149169921875, Neurons: 11, Grad norm: 4.094e+02\n",
      "Epoch 7453, Loss: 760.6724853515625, Neurons: 11, Grad norm: 4.340e+02\n",
      "Epoch 7454, Loss: 759.048095703125, Neurons: 11, Grad norm: 4.597e+02\n",
      "Epoch 7455, Loss: 757.2652587890625, Neurons: 11, Grad norm: 4.864e+02\n",
      "Epoch 7456, Loss: 755.3136596679688, Neurons: 11, Grad norm: 5.139e+02\n",
      "Epoch 7457, Loss: 753.1837158203125, Neurons: 11, Grad norm: 5.422e+02\n",
      "Epoch 7458, Loss: 750.8667602539062, Neurons: 11, Grad norm: 5.709e+02\n",
      "Epoch 7459, Loss: 748.3551635742188, Neurons: 11, Grad norm: 5.999e+02\n",
      "Epoch 7460, Loss: 745.6424560546875, Neurons: 11, Grad norm: 6.288e+02\n",
      "Epoch 7461, Loss: 742.7237548828125, Neurons: 11, Grad norm: 6.574e+02\n",
      "Epoch 7462, Loss: 739.595458984375, Neurons: 11, Grad norm: 6.853e+02\n",
      "Epoch 7463, Loss: 736.2555541992188, Neurons: 11, Grad norm: 7.122e+02\n",
      "Epoch 7464, Loss: 732.703369140625, Neurons: 11, Grad norm: 7.378e+02\n",
      "Epoch 7465, Loss: 728.9402465820312, Neurons: 11, Grad norm: 7.618e+02\n",
      "Epoch 7466, Loss: 724.9689331054688, Neurons: 11, Grad norm: 7.839e+02\n",
      "Epoch 7467, Loss: 720.7943115234375, Neurons: 11, Grad norm: 8.037e+02\n",
      "Epoch 7468, Loss: 716.4228515625, Neurons: 11, Grad norm: 8.210e+02\n",
      "Epoch 7469, Loss: 711.86328125, Neurons: 11, Grad norm: 8.356e+02\n",
      "Epoch 7470, Loss: 707.12646484375, Neurons: 11, Grad norm: 8.471e+02\n",
      "Epoch 7471, Loss: 702.2255859375, Neurons: 11, Grad norm: 8.553e+02\n",
      "Epoch 7472, Loss: 697.1761474609375, Neurons: 11, Grad norm: 8.601e+02\n",
      "Epoch 7473, Loss: 691.99609375, Neurons: 11, Grad norm: 8.614e+02\n",
      "Epoch 7474, Loss: 686.7059936523438, Neurons: 11, Grad norm: 8.590e+02\n",
      "Epoch 7475, Loss: 681.3290405273438, Neurons: 11, Grad norm: 8.529e+02\n",
      "Epoch 7476, Loss: 675.89111328125, Neurons: 11, Grad norm: 8.430e+02\n",
      "Epoch 7477, Loss: 670.4205932617188, Neurons: 11, Grad norm: 8.295e+02\n",
      "Epoch 7478, Loss: 664.9483032226562, Neurons: 11, Grad norm: 8.123e+02\n",
      "Epoch 7479, Loss: 659.50732421875, Neurons: 11, Grad norm: 7.916e+02\n",
      "Epoch 7480, Loss: 654.1324462890625, Neurons: 11, Grad norm: 7.677e+02\n",
      "Epoch 7481, Loss: 648.8595581054688, Neurons: 11, Grad norm: 7.409e+02\n",
      "Epoch 7482, Loss: 643.7249755859375, Neurons: 11, Grad norm: 7.113e+02\n",
      "Epoch 7483, Loss: 638.7637939453125, Neurons: 11, Grad norm: 6.796e+02\n",
      "Epoch 7484, Loss: 634.0092163085938, Neurons: 11, Grad norm: 6.460e+02\n",
      "Epoch 7485, Loss: 629.4906616210938, Neurons: 11, Grad norm: 6.111e+02\n",
      "Epoch 7486, Loss: 625.2322998046875, Neurons: 11, Grad norm: 5.754e+02\n",
      "Epoch 7487, Loss: 621.2520141601562, Neurons: 11, Grad norm: 5.392e+02\n",
      "Epoch 7488, Loss: 617.560302734375, Neurons: 11, Grad norm: 5.033e+02\n",
      "Epoch 7489, Loss: 614.1599731445312, Neurons: 11, Grad norm: 4.680e+02\n",
      "Epoch 7490, Loss: 611.0467529296875, Neurons: 11, Grad norm: 4.337e+02\n",
      "Epoch 7491, Loss: 608.20947265625, Neurons: 11, Grad norm: 4.008e+02\n",
      "Epoch 7492, Loss: 605.6319580078125, Neurons: 11, Grad norm: 3.697e+02\n",
      "Epoch 7493, Loss: 603.2942504882812, Neurons: 11, Grad norm: 3.405e+02\n",
      "Epoch 7494, Loss: 601.174072265625, Neurons: 11, Grad norm: 3.133e+02\n",
      "Epoch 7495, Loss: 599.2484130859375, Neurons: 11, Grad norm: 2.883e+02\n",
      "Epoch 7496, Loss: 597.4945068359375, Neurons: 11, Grad norm: 2.655e+02\n",
      "Epoch 7497, Loss: 595.8906860351562, Neurons: 11, Grad norm: 2.449e+02\n",
      "Epoch 7498, Loss: 594.4170532226562, Neurons: 11, Grad norm: 2.265e+02\n",
      "Epoch 7499, Loss: 593.055908203125, Neurons: 11, Grad norm: 2.100e+02\n",
      "Epoch 7499, Test loss: 596.3626708984375\n",
      "Epoch 7500, Loss: 591.7915649414062, Neurons: 11, Grad norm: 1.954e+02\n",
      "Epoch 7501, Loss: 590.6109008789062, Neurons: 11, Grad norm: 1.826e+02\n",
      "Epoch 7502, Loss: 589.5026245117188, Neurons: 11, Grad norm: 1.714e+02\n",
      "Epoch 7503, Loss: 588.457763671875, Neurons: 11, Grad norm: 1.616e+02\n",
      "Epoch 7504, Loss: 587.4688110351562, Neurons: 11, Grad norm: 1.531e+02\n",
      "Epoch 7505, Loss: 586.5300903320312, Neurons: 11, Grad norm: 1.456e+02\n",
      "Epoch 7506, Loss: 585.63720703125, Neurons: 11, Grad norm: 1.391e+02\n",
      "Epoch 7507, Loss: 584.786865234375, Neurons: 11, Grad norm: 1.334e+02\n",
      "Epoch 7508, Loss: 583.976806640625, Neurons: 11, Grad norm: 1.285e+02\n",
      "Epoch 7509, Loss: 583.2053833007812, Neurons: 11, Grad norm: 1.242e+02\n",
      "Epoch 7510, Loss: 582.471435546875, Neurons: 11, Grad norm: 1.205e+02\n",
      "Epoch 7511, Loss: 581.7742919921875, Neurons: 11, Grad norm: 1.173e+02\n",
      "Epoch 7512, Loss: 581.1133422851562, Neurons: 11, Grad norm: 1.146e+02\n",
      "Epoch 7513, Loss: 580.4882202148438, Neurons: 11, Grad norm: 1.124e+02\n",
      "Epoch 7514, Loss: 579.8983764648438, Neurons: 11, Grad norm: 1.108e+02\n",
      "Epoch 7515, Loss: 579.34326171875, Neurons: 11, Grad norm: 1.095e+02\n",
      "Epoch 7516, Loss: 578.8218994140625, Neurons: 11, Grad norm: 1.088e+02\n",
      "Epoch 7517, Loss: 578.3333129882812, Neurons: 11, Grad norm: 1.084e+02\n",
      "Epoch 7518, Loss: 577.8761596679688, Neurons: 11, Grad norm: 1.083e+02\n",
      "Epoch 7519, Loss: 577.448974609375, Neurons: 11, Grad norm: 1.086e+02\n",
      "Epoch 7520, Loss: 577.0499267578125, Neurons: 11, Grad norm: 1.091e+02\n",
      "Epoch 7521, Loss: 576.6771850585938, Neurons: 11, Grad norm: 1.097e+02\n",
      "Epoch 7522, Loss: 576.3286743164062, Neurons: 11, Grad norm: 1.104e+02\n",
      "Epoch 7523, Loss: 576.0023803710938, Neurons: 11, Grad norm: 1.111e+02\n",
      "Epoch 7524, Loss: 575.6961669921875, Neurons: 11, Grad norm: 1.118e+02\n",
      "Epoch 7525, Loss: 575.4080810546875, Neurons: 11, Grad norm: 1.124e+02\n",
      "Epoch 7526, Loss: 575.1361083984375, Neurons: 11, Grad norm: 1.129e+02\n",
      "Epoch 7527, Loss: 574.8784790039062, Neurons: 11, Grad norm: 1.132e+02\n",
      "Epoch 7528, Loss: 574.6336059570312, Neurons: 11, Grad norm: 1.133e+02\n",
      "Epoch 7529, Loss: 574.3999633789062, Neurons: 11, Grad norm: 1.132e+02\n",
      "Epoch 7530, Loss: 574.1762084960938, Neurons: 11, Grad norm: 1.129e+02\n",
      "Epoch 7531, Loss: 573.9612426757812, Neurons: 11, Grad norm: 1.124e+02\n",
      "Epoch 7532, Loss: 573.7540283203125, Neurons: 11, Grad norm: 1.117e+02\n",
      "Epoch 7533, Loss: 573.5537109375, Neurons: 11, Grad norm: 1.108e+02\n",
      "Epoch 7534, Loss: 573.3597412109375, Neurons: 11, Grad norm: 1.096e+02\n",
      "Epoch 7535, Loss: 573.1712646484375, Neurons: 11, Grad norm: 1.084e+02\n",
      "Epoch 7536, Loss: 572.9880981445312, Neurons: 11, Grad norm: 1.069e+02\n",
      "Epoch 7537, Loss: 572.8095092773438, Neurons: 11, Grad norm: 1.054e+02\n",
      "Epoch 7538, Loss: 572.6353759765625, Neurons: 11, Grad norm: 1.037e+02\n",
      "Epoch 7539, Loss: 572.4652709960938, Neurons: 11, Grad norm: 1.019e+02\n",
      "Epoch 7540, Loss: 572.2990112304688, Neurons: 11, Grad norm: 1.001e+02\n",
      "Epoch 7541, Loss: 572.1362915039062, Neurons: 11, Grad norm: 9.820e+01\n",
      "Epoch 7542, Loss: 571.9768676757812, Neurons: 11, Grad norm: 9.630e+01\n",
      "Epoch 7543, Loss: 571.820556640625, Neurons: 11, Grad norm: 9.439e+01\n",
      "Epoch 7544, Loss: 571.667236328125, Neurons: 11, Grad norm: 9.249e+01\n",
      "Epoch 7545, Loss: 571.5166015625, Neurons: 11, Grad norm: 9.062e+01\n",
      "Epoch 7546, Loss: 571.368408203125, Neurons: 11, Grad norm: 8.878e+01\n",
      "Epoch 7547, Loss: 571.2225952148438, Neurons: 11, Grad norm: 8.701e+01\n",
      "Epoch 7548, Loss: 571.078857421875, Neurons: 11, Grad norm: 8.529e+01\n",
      "Epoch 7549, Loss: 570.9370727539062, Neurons: 11, Grad norm: 8.366e+01\n",
      "Epoch 7549, Test loss: 574.5473022460938\n",
      "Epoch 7550, Loss: 570.7969970703125, Neurons: 11, Grad norm: 8.210e+01\n",
      "Epoch 7551, Loss: 570.6583862304688, Neurons: 11, Grad norm: 8.062e+01\n",
      "Epoch 7552, Loss: 570.5211181640625, Neurons: 11, Grad norm: 7.924e+01\n",
      "Epoch 7553, Loss: 570.385009765625, Neurons: 11, Grad norm: 7.795e+01\n",
      "Epoch 7554, Loss: 570.2498779296875, Neurons: 11, Grad norm: 7.675e+01\n",
      "Epoch 7555, Loss: 570.1156005859375, Neurons: 11, Grad norm: 7.566e+01\n",
      "Epoch 7556, Loss: 569.98193359375, Neurons: 11, Grad norm: 7.466e+01\n",
      "Epoch 7557, Loss: 569.8488159179688, Neurons: 11, Grad norm: 7.375e+01\n",
      "Epoch 7558, Loss: 569.7160034179688, Neurons: 11, Grad norm: 7.294e+01\n",
      "Epoch 7559, Loss: 569.58349609375, Neurons: 11, Grad norm: 7.222e+01\n",
      "Epoch 7560, Loss: 569.4511108398438, Neurons: 11, Grad norm: 7.158e+01\n",
      "Epoch 7561, Loss: 569.3186645507812, Neurons: 11, Grad norm: 7.103e+01\n",
      "Epoch 7562, Loss: 569.1861572265625, Neurons: 11, Grad norm: 7.056e+01\n",
      "Epoch 7563, Loss: 569.0534057617188, Neurons: 11, Grad norm: 7.016e+01\n",
      "Epoch 7564, Loss: 568.9203491210938, Neurons: 11, Grad norm: 6.983e+01\n",
      "Epoch 7565, Loss: 568.786865234375, Neurons: 11, Grad norm: 6.957e+01\n",
      "Epoch 7566, Loss: 568.6529541015625, Neurons: 11, Grad norm: 6.937e+01\n",
      "Epoch 7567, Loss: 568.5183715820312, Neurons: 11, Grad norm: 6.923e+01\n",
      "Epoch 7568, Loss: 568.3831787109375, Neurons: 11, Grad norm: 6.914e+01\n",
      "Epoch 7569, Loss: 568.2472534179688, Neurons: 11, Grad norm: 6.910e+01\n",
      "Epoch 7570, Loss: 568.1104736328125, Neurons: 11, Grad norm: 6.910e+01\n",
      "Epoch 7571, Loss: 567.9727172851562, Neurons: 11, Grad norm: 6.915e+01\n",
      "Epoch 7572, Loss: 567.833984375, Neurons: 11, Grad norm: 6.923e+01\n",
      "Epoch 7573, Loss: 567.6942138671875, Neurons: 11, Grad norm: 6.935e+01\n",
      "Epoch 7574, Loss: 567.5531616210938, Neurons: 11, Grad norm: 6.950e+01\n",
      "Epoch 7575, Loss: 567.410888671875, Neurons: 11, Grad norm: 6.967e+01\n",
      "Epoch 7576, Loss: 567.2672729492188, Neurons: 11, Grad norm: 6.985e+01\n",
      "Epoch 7577, Loss: 567.1221923828125, Neurons: 11, Grad norm: 7.007e+01\n",
      "Epoch 7578, Loss: 566.9755859375, Neurons: 11, Grad norm: 7.030e+01\n",
      "Epoch 7579, Loss: 566.8272705078125, Neurons: 11, Grad norm: 7.055e+01\n",
      "Epoch 7580, Loss: 566.6773071289062, Neurons: 11, Grad norm: 7.080e+01\n",
      "Epoch 7581, Loss: 566.5255737304688, Neurons: 11, Grad norm: 7.106e+01\n",
      "Epoch 7582, Loss: 566.3718872070312, Neurons: 11, Grad norm: 7.133e+01\n",
      "Epoch 7583, Loss: 566.2161254882812, Neurons: 11, Grad norm: 7.162e+01\n",
      "Epoch 7584, Loss: 566.0584106445312, Neurons: 11, Grad norm: 7.190e+01\n",
      "Epoch 7585, Loss: 565.8983154296875, Neurons: 11, Grad norm: 7.219e+01\n",
      "Epoch 7586, Loss: 565.736083984375, Neurons: 11, Grad norm: 7.247e+01\n",
      "Epoch 7587, Loss: 565.5714111328125, Neurons: 11, Grad norm: 7.276e+01\n",
      "Epoch 7588, Loss: 565.4041748046875, Neurons: 11, Grad norm: 7.304e+01\n",
      "Epoch 7589, Loss: 565.2344360351562, Neurons: 11, Grad norm: 7.332e+01\n",
      "Epoch 7590, Loss: 565.06201171875, Neurons: 11, Grad norm: 7.360e+01\n",
      "Epoch 7591, Loss: 564.8867797851562, Neurons: 11, Grad norm: 7.386e+01\n",
      "Epoch 7592, Loss: 564.7086791992188, Neurons: 11, Grad norm: 7.412e+01\n",
      "Epoch 7593, Loss: 564.527587890625, Neurons: 11, Grad norm: 7.437e+01\n",
      "Epoch 7594, Loss: 564.343505859375, Neurons: 11, Grad norm: 7.460e+01\n",
      "Epoch 7595, Loss: 564.1561889648438, Neurons: 11, Grad norm: 7.482e+01\n",
      "Epoch 7596, Loss: 563.965576171875, Neurons: 11, Grad norm: 7.502e+01\n",
      "Epoch 7597, Loss: 563.7717895507812, Neurons: 11, Grad norm: 7.521e+01\n",
      "Epoch 7598, Loss: 563.574462890625, Neurons: 11, Grad norm: 7.536e+01\n",
      "Epoch 7599, Loss: 563.3736572265625, Neurons: 11, Grad norm: 7.550e+01\n",
      "Epoch 7599, Test loss: 566.6047973632812\n",
      "Epoch 7600, Loss: 563.1693115234375, Neurons: 11, Grad norm: 7.560e+01\n",
      "Epoch 7601, Loss: 562.9613647460938, Neurons: 11, Grad norm: 7.567e+01\n",
      "Epoch 7602, Loss: 562.749755859375, Neurons: 11, Grad norm: 7.571e+01\n",
      "Epoch 7603, Loss: 562.5343627929688, Neurons: 11, Grad norm: 7.571e+01\n",
      "Epoch 7604, Loss: 562.3152465820312, Neurons: 11, Grad norm: 7.567e+01\n",
      "Epoch 7605, Loss: 562.09228515625, Neurons: 11, Grad norm: 7.558e+01\n",
      "Epoch 7606, Loss: 561.8656005859375, Neurons: 11, Grad norm: 7.545e+01\n",
      "Epoch 7607, Loss: 561.635009765625, Neurons: 11, Grad norm: 7.527e+01\n",
      "Epoch 7608, Loss: 561.400634765625, Neurons: 11, Grad norm: 7.503e+01\n",
      "Epoch 7609, Loss: 561.1624755859375, Neurons: 11, Grad norm: 7.474e+01\n",
      "Epoch 7610, Loss: 560.9205322265625, Neurons: 11, Grad norm: 7.438e+01\n",
      "Epoch 7611, Loss: 560.6748657226562, Neurons: 11, Grad norm: 7.397e+01\n",
      "Epoch 7612, Loss: 560.4255981445312, Neurons: 11, Grad norm: 7.350e+01\n",
      "Epoch 7613, Loss: 560.1727905273438, Neurons: 11, Grad norm: 7.296e+01\n",
      "Epoch 7614, Loss: 559.9163818359375, Neurons: 11, Grad norm: 7.235e+01\n",
      "Epoch 7615, Loss: 559.6565551757812, Neurons: 11, Grad norm: 7.169e+01\n",
      "Epoch 7616, Loss: 559.3934936523438, Neurons: 11, Grad norm: 7.096e+01\n",
      "Epoch 7617, Loss: 559.1272583007812, Neurons: 11, Grad norm: 7.016e+01\n",
      "Epoch 7618, Loss: 558.8579711914062, Neurons: 11, Grad norm: 6.931e+01\n",
      "Epoch 7619, Loss: 558.5857543945312, Neurons: 11, Grad norm: 6.841e+01\n",
      "Epoch 7620, Loss: 558.310791015625, Neurons: 11, Grad norm: 6.745e+01\n",
      "Epoch 7621, Loss: 558.033203125, Neurons: 11, Grad norm: 6.644e+01\n",
      "Epoch 7622, Loss: 557.7531127929688, Neurons: 11, Grad norm: 6.539e+01\n",
      "Epoch 7623, Loss: 557.470703125, Neurons: 11, Grad norm: 6.429e+01\n",
      "Epoch 7624, Loss: 557.1861572265625, Neurons: 11, Grad norm: 6.317e+01\n",
      "Epoch 7625, Loss: 556.8994750976562, Neurons: 11, Grad norm: 6.202e+01\n",
      "Epoch 7626, Loss: 556.6110229492188, Neurons: 11, Grad norm: 6.085e+01\n",
      "Epoch 7627, Loss: 556.3208618164062, Neurons: 11, Grad norm: 5.966e+01\n",
      "Epoch 7628, Loss: 556.029052734375, Neurons: 11, Grad norm: 5.846e+01\n",
      "Epoch 7629, Loss: 555.7357788085938, Neurons: 11, Grad norm: 5.727e+01\n",
      "Epoch 7630, Loss: 555.4412841796875, Neurons: 11, Grad norm: 5.608e+01\n",
      "Epoch 7631, Loss: 555.1455078125, Neurons: 11, Grad norm: 5.490e+01\n",
      "Epoch 7632, Loss: 554.8488159179688, Neurons: 11, Grad norm: 5.374e+01\n",
      "Epoch 7633, Loss: 554.551025390625, Neurons: 11, Grad norm: 5.260e+01\n",
      "Epoch 7634, Loss: 554.2525634765625, Neurons: 11, Grad norm: 5.150e+01\n",
      "Epoch 7635, Loss: 553.9533081054688, Neurons: 11, Grad norm: 5.042e+01\n",
      "Epoch 7636, Loss: 553.653564453125, Neurons: 11, Grad norm: 4.937e+01\n",
      "Epoch 7637, Loss: 553.3533325195312, Neurons: 11, Grad norm: 4.837e+01\n",
      "Epoch 7638, Loss: 553.0526733398438, Neurons: 11, Grad norm: 4.741e+01\n",
      "Epoch 7639, Loss: 552.7518920898438, Neurons: 11, Grad norm: 4.649e+01\n",
      "Epoch 7640, Loss: 552.450927734375, Neurons: 11, Grad norm: 4.561e+01\n",
      "Epoch 7641, Loss: 552.1499633789062, Neurons: 11, Grad norm: 4.478e+01\n",
      "Epoch 7642, Loss: 551.8489990234375, Neurons: 11, Grad norm: 4.399e+01\n",
      "Epoch 7643, Loss: 551.5482177734375, Neurons: 11, Grad norm: 4.326e+01\n",
      "Epoch 7644, Loss: 551.2476806640625, Neurons: 11, Grad norm: 4.256e+01\n",
      "Epoch 7645, Loss: 550.947509765625, Neurons: 11, Grad norm: 4.191e+01\n",
      "Epoch 7646, Loss: 550.6477661132812, Neurons: 11, Grad norm: 4.130e+01\n",
      "Epoch 7647, Loss: 550.3485107421875, Neurons: 11, Grad norm: 4.073e+01\n",
      "Epoch 7648, Loss: 550.0498046875, Neurons: 11, Grad norm: 4.020e+01\n",
      "Epoch 7649, Loss: 549.7517700195312, Neurons: 11, Grad norm: 3.971e+01\n",
      "Epoch 7649, Test loss: 552.6688842773438\n",
      "Epoch 7650, Loss: 549.4544677734375, Neurons: 11, Grad norm: 3.925e+01\n",
      "Epoch 7651, Loss: 549.1580200195312, Neurons: 11, Grad norm: 3.882e+01\n",
      "Epoch 7652, Loss: 548.8623657226562, Neurons: 11, Grad norm: 3.843e+01\n",
      "Epoch 7653, Loss: 548.5676879882812, Neurons: 11, Grad norm: 3.806e+01\n",
      "Epoch 7654, Loss: 548.2739868164062, Neurons: 11, Grad norm: 3.772e+01\n",
      "Epoch 7655, Loss: 547.9812622070312, Neurons: 11, Grad norm: 3.740e+01\n",
      "Epoch 7656, Loss: 547.6896362304688, Neurons: 11, Grad norm: 3.711e+01\n",
      "Epoch 7657, Loss: 547.3991088867188, Neurons: 11, Grad norm: 3.684e+01\n",
      "Epoch 7658, Loss: 547.1098022460938, Neurons: 11, Grad norm: 3.659e+01\n",
      "Epoch 7659, Loss: 546.8217163085938, Neurons: 11, Grad norm: 3.636e+01\n",
      "Epoch 7660, Loss: 546.5347900390625, Neurons: 11, Grad norm: 3.615e+01\n",
      "Epoch 7661, Loss: 546.2492065429688, Neurons: 11, Grad norm: 3.595e+01\n",
      "Epoch 7662, Loss: 545.9649658203125, Neurons: 11, Grad norm: 3.577e+01\n",
      "Epoch 7663, Loss: 545.6820068359375, Neurons: 11, Grad norm: 3.561e+01\n",
      "Epoch 7664, Loss: 545.4003295898438, Neurons: 11, Grad norm: 3.546e+01\n",
      "Epoch 7665, Loss: 545.1201171875, Neurons: 11, Grad norm: 3.533e+01\n",
      "Epoch 7666, Loss: 544.84130859375, Neurons: 11, Grad norm: 3.521e+01\n",
      "Epoch 7667, Loss: 544.5639038085938, Neurons: 11, Grad norm: 3.510e+01\n",
      "Epoch 7668, Loss: 544.2879028320312, Neurons: 11, Grad norm: 3.501e+01\n",
      "Epoch 7669, Loss: 544.0133666992188, Neurons: 11, Grad norm: 3.493e+01\n",
      "Epoch 7670, Loss: 543.740234375, Neurons: 11, Grad norm: 3.486e+01\n",
      "Epoch 7671, Loss: 543.4685668945312, Neurons: 11, Grad norm: 3.481e+01\n",
      "Epoch 7672, Loss: 543.1984252929688, Neurons: 11, Grad norm: 3.476e+01\n",
      "Epoch 7673, Loss: 542.9296875, Neurons: 11, Grad norm: 3.472e+01\n",
      "Epoch 7674, Loss: 542.6624755859375, Neurons: 11, Grad norm: 3.470e+01\n",
      "Epoch 7675, Loss: 542.396728515625, Neurons: 11, Grad norm: 3.468e+01\n",
      "Epoch 7676, Loss: 542.1323852539062, Neurons: 11, Grad norm: 3.467e+01\n",
      "Epoch 7677, Loss: 541.8695678710938, Neurons: 11, Grad norm: 3.467e+01\n",
      "Epoch 7678, Loss: 541.6082153320312, Neurons: 11, Grad norm: 3.467e+01\n",
      "Epoch 7679, Loss: 541.3482666015625, Neurons: 11, Grad norm: 3.468e+01\n",
      "Epoch 7680, Loss: 541.0897827148438, Neurons: 11, Grad norm: 3.469e+01\n",
      "Epoch 7681, Loss: 540.832763671875, Neurons: 11, Grad norm: 3.470e+01\n",
      "Epoch 7682, Loss: 540.5771484375, Neurons: 11, Grad norm: 3.472e+01\n",
      "Epoch 7683, Loss: 540.3229370117188, Neurons: 11, Grad norm: 3.474e+01\n",
      "Epoch 7684, Loss: 540.0701293945312, Neurons: 11, Grad norm: 3.476e+01\n",
      "Epoch 7685, Loss: 539.8187866210938, Neurons: 11, Grad norm: 3.478e+01\n",
      "Epoch 7686, Loss: 539.5687255859375, Neurons: 11, Grad norm: 3.480e+01\n",
      "Epoch 7687, Loss: 539.320068359375, Neurons: 11, Grad norm: 3.482e+01\n",
      "Epoch 7688, Loss: 539.0728149414062, Neurons: 11, Grad norm: 3.483e+01\n",
      "Epoch 7689, Loss: 538.8267822265625, Neurons: 11, Grad norm: 3.484e+01\n",
      "Epoch 7690, Loss: 538.5821533203125, Neurons: 11, Grad norm: 3.485e+01\n",
      "Epoch 7691, Loss: 538.3388061523438, Neurons: 11, Grad norm: 3.486e+01\n",
      "Epoch 7692, Loss: 538.0966796875, Neurons: 11, Grad norm: 3.486e+01\n",
      "Epoch 7693, Loss: 537.85595703125, Neurons: 11, Grad norm: 3.485e+01\n",
      "Epoch 7694, Loss: 537.6163330078125, Neurons: 11, Grad norm: 3.484e+01\n",
      "Epoch 7695, Loss: 537.3779907226562, Neurons: 11, Grad norm: 3.483e+01\n",
      "Epoch 7696, Loss: 537.1408081054688, Neurons: 11, Grad norm: 3.481e+01\n",
      "Epoch 7697, Loss: 536.9049072265625, Neurons: 11, Grad norm: 3.479e+01\n",
      "Epoch 7698, Loss: 536.670166015625, Neurons: 11, Grad norm: 3.476e+01\n",
      "Epoch 7699, Loss: 536.4364624023438, Neurons: 11, Grad norm: 3.472e+01\n",
      "Epoch 7699, Test loss: 538.9690551757812\n",
      "Epoch 7700, Loss: 536.2040405273438, Neurons: 11, Grad norm: 3.468e+01\n",
      "Epoch 7701, Loss: 535.9725952148438, Neurons: 11, Grad norm: 3.464e+01\n",
      "Epoch 7702, Loss: 535.7423095703125, Neurons: 11, Grad norm: 3.458e+01\n",
      "Epoch 7703, Loss: 535.5130615234375, Neurons: 11, Grad norm: 3.453e+01\n",
      "Epoch 7704, Loss: 535.284912109375, Neurons: 11, Grad norm: 3.447e+01\n",
      "Epoch 7705, Loss: 535.0578002929688, Neurons: 11, Grad norm: 3.440e+01\n",
      "Epoch 7706, Loss: 534.8316040039062, Neurons: 11, Grad norm: 3.433e+01\n",
      "Epoch 7707, Loss: 534.6064453125, Neurons: 11, Grad norm: 3.426e+01\n",
      "Epoch 7708, Loss: 534.3822631835938, Neurons: 11, Grad norm: 3.418e+01\n",
      "Epoch 7709, Loss: 534.1590576171875, Neurons: 11, Grad norm: 3.409e+01\n",
      "Epoch 7710, Loss: 533.9367065429688, Neurons: 11, Grad norm: 3.400e+01\n",
      "Epoch 7711, Loss: 533.71533203125, Neurons: 11, Grad norm: 3.392e+01\n",
      "Epoch 7712, Loss: 533.4948120117188, Neurons: 11, Grad norm: 3.382e+01\n",
      "Epoch 7713, Loss: 533.2752075195312, Neurons: 11, Grad norm: 3.372e+01\n",
      "Epoch 7714, Loss: 533.0564575195312, Neurons: 11, Grad norm: 3.362e+01\n",
      "Epoch 7715, Loss: 532.8385009765625, Neurons: 11, Grad norm: 3.352e+01\n",
      "Epoch 7716, Loss: 532.6213989257812, Neurons: 11, Grad norm: 3.342e+01\n",
      "Epoch 7717, Loss: 532.4050903320312, Neurons: 11, Grad norm: 3.331e+01\n",
      "Epoch 7718, Loss: 532.1895751953125, Neurons: 11, Grad norm: 3.319e+01\n",
      "Epoch 7719, Loss: 531.9749145507812, Neurons: 11, Grad norm: 3.308e+01\n",
      "Epoch 7720, Loss: 531.7608642578125, Neurons: 11, Grad norm: 3.297e+01\n",
      "Epoch 7721, Loss: 531.547607421875, Neurons: 11, Grad norm: 3.285e+01\n",
      "Epoch 7722, Loss: 531.3350830078125, Neurons: 11, Grad norm: 3.273e+01\n",
      "Epoch 7723, Loss: 531.1233520507812, Neurons: 11, Grad norm: 3.262e+01\n",
      "Epoch 7724, Loss: 530.9122924804688, Neurons: 11, Grad norm: 3.250e+01\n",
      "Epoch 7725, Loss: 530.7018432617188, Neurons: 11, Grad norm: 3.237e+01\n",
      "Epoch 7726, Loss: 530.4920654296875, Neurons: 11, Grad norm: 3.225e+01\n",
      "Epoch 7727, Loss: 530.282958984375, Neurons: 11, Grad norm: 3.213e+01\n",
      "Epoch 7728, Loss: 530.074462890625, Neurons: 11, Grad norm: 3.200e+01\n",
      "Epoch 7729, Loss: 529.86669921875, Neurons: 11, Grad norm: 3.187e+01\n",
      "Epoch 7730, Loss: 529.6594848632812, Neurons: 11, Grad norm: 3.175e+01\n",
      "Epoch 7731, Loss: 529.452880859375, Neurons: 11, Grad norm: 3.163e+01\n",
      "Epoch 7732, Loss: 529.2468872070312, Neurons: 11, Grad norm: 3.150e+01\n",
      "Epoch 7733, Loss: 529.04150390625, Neurons: 11, Grad norm: 3.137e+01\n",
      "Epoch 7734, Loss: 528.8366088867188, Neurons: 11, Grad norm: 3.124e+01\n",
      "Epoch 7735, Loss: 528.63232421875, Neurons: 11, Grad norm: 3.111e+01\n",
      "Epoch 7736, Loss: 528.4287109375, Neurons: 11, Grad norm: 3.099e+01\n",
      "Epoch 7737, Loss: 528.2254638671875, Neurons: 11, Grad norm: 3.086e+01\n",
      "Epoch 7738, Loss: 528.0227661132812, Neurons: 11, Grad norm: 3.073e+01\n",
      "Epoch 7739, Loss: 527.8206787109375, Neurons: 11, Grad norm: 3.060e+01\n",
      "Epoch 7740, Loss: 527.6190795898438, Neurons: 11, Grad norm: 3.048e+01\n",
      "Epoch 7741, Loss: 527.41796875, Neurons: 11, Grad norm: 3.034e+01\n",
      "Epoch 7742, Loss: 527.2174072265625, Neurons: 11, Grad norm: 3.022e+01\n",
      "Epoch 7743, Loss: 527.0172119140625, Neurons: 11, Grad norm: 3.009e+01\n",
      "Epoch 7744, Loss: 526.8176879882812, Neurons: 11, Grad norm: 2.997e+01\n",
      "Epoch 7745, Loss: 526.6185302734375, Neurons: 11, Grad norm: 2.984e+01\n",
      "Epoch 7746, Loss: 526.4198608398438, Neurons: 11, Grad norm: 2.971e+01\n",
      "Epoch 7747, Loss: 526.2216796875, Neurons: 11, Grad norm: 2.959e+01\n",
      "Epoch 7748, Loss: 526.0239868164062, Neurons: 11, Grad norm: 2.946e+01\n",
      "Epoch 7749, Loss: 525.82666015625, Neurons: 11, Grad norm: 2.934e+01\n",
      "Epoch 7749, Test loss: 527.713623046875\n",
      "Epoch 7750, Loss: 525.6298828125, Neurons: 11, Grad norm: 2.921e+01\n",
      "Epoch 7751, Loss: 525.4334716796875, Neurons: 11, Grad norm: 2.909e+01\n",
      "Epoch 7752, Loss: 525.237548828125, Neurons: 11, Grad norm: 2.897e+01\n",
      "Epoch 7753, Loss: 525.0420532226562, Neurons: 11, Grad norm: 2.884e+01\n",
      "Epoch 7754, Loss: 524.8469848632812, Neurons: 11, Grad norm: 2.872e+01\n",
      "Epoch 7755, Loss: 524.65234375, Neurons: 11, Grad norm: 2.860e+01\n",
      "Epoch 7756, Loss: 524.4580688476562, Neurons: 11, Grad norm: 2.848e+01\n",
      "Epoch 7757, Loss: 524.2642822265625, Neurons: 11, Grad norm: 2.835e+01\n",
      "Epoch 7758, Loss: 524.0709838867188, Neurons: 11, Grad norm: 2.823e+01\n",
      "Epoch 7759, Loss: 523.8779907226562, Neurons: 11, Grad norm: 2.812e+01\n",
      "Epoch 7760, Loss: 523.6853637695312, Neurons: 11, Grad norm: 2.800e+01\n",
      "Epoch 7761, Loss: 523.4932861328125, Neurons: 11, Grad norm: 2.788e+01\n",
      "Epoch 7762, Loss: 523.301513671875, Neurons: 11, Grad norm: 2.776e+01\n",
      "Epoch 7763, Loss: 523.1101684570312, Neurons: 11, Grad norm: 2.765e+01\n",
      "Epoch 7764, Loss: 522.919189453125, Neurons: 11, Grad norm: 2.753e+01\n",
      "Epoch 7765, Loss: 522.7286987304688, Neurons: 11, Grad norm: 2.741e+01\n",
      "Epoch 7766, Loss: 522.5385131835938, Neurons: 11, Grad norm: 2.730e+01\n",
      "Epoch 7767, Loss: 522.3488159179688, Neurons: 11, Grad norm: 2.718e+01\n",
      "Epoch 7768, Loss: 522.1593627929688, Neurons: 11, Grad norm: 2.706e+01\n",
      "Epoch 7769, Loss: 521.9703979492188, Neurons: 11, Grad norm: 2.695e+01\n",
      "Epoch 7770, Loss: 521.7817993164062, Neurons: 11, Grad norm: 2.684e+01\n",
      "Epoch 7771, Loss: 521.5935668945312, Neurons: 11, Grad norm: 2.672e+01\n",
      "Epoch 7772, Loss: 521.40576171875, Neurons: 11, Grad norm: 2.661e+01\n",
      "Epoch 7773, Loss: 521.21826171875, Neurons: 11, Grad norm: 2.650e+01\n",
      "Epoch 7774, Loss: 521.0313110351562, Neurons: 11, Grad norm: 2.639e+01\n",
      "Epoch 7775, Loss: 520.8446044921875, Neurons: 11, Grad norm: 2.628e+01\n",
      "Epoch 7776, Loss: 520.6582641601562, Neurons: 11, Grad norm: 2.617e+01\n",
      "Epoch 7777, Loss: 520.472412109375, Neurons: 11, Grad norm: 2.607e+01\n",
      "Epoch 7778, Loss: 520.2868041992188, Neurons: 11, Grad norm: 2.596e+01\n",
      "Epoch 7779, Loss: 520.1016235351562, Neurons: 11, Grad norm: 2.585e+01\n",
      "Epoch 7780, Loss: 519.9168090820312, Neurons: 11, Grad norm: 2.574e+01\n",
      "Epoch 7781, Loss: 519.732421875, Neurons: 11, Grad norm: 2.564e+01\n",
      "Epoch 7782, Loss: 519.5484008789062, Neurons: 11, Grad norm: 2.553e+01\n",
      "Epoch 7783, Loss: 519.3646850585938, Neurons: 11, Grad norm: 2.543e+01\n",
      "Epoch 7784, Loss: 519.1814575195312, Neurons: 11, Grad norm: 2.533e+01\n",
      "Epoch 7785, Loss: 518.99853515625, Neurons: 11, Grad norm: 2.522e+01\n",
      "Epoch 7786, Loss: 518.8159790039062, Neurons: 11, Grad norm: 2.512e+01\n",
      "Epoch 7787, Loss: 518.6337890625, Neurons: 11, Grad norm: 2.502e+01\n",
      "Epoch 7788, Loss: 518.4519653320312, Neurons: 11, Grad norm: 2.492e+01\n",
      "Epoch 7789, Loss: 518.2705688476562, Neurons: 11, Grad norm: 2.482e+01\n",
      "Epoch 7790, Loss: 518.0894775390625, Neurons: 11, Grad norm: 2.472e+01\n",
      "Epoch 7791, Loss: 517.9088134765625, Neurons: 11, Grad norm: 2.462e+01\n",
      "Epoch 7792, Loss: 517.728515625, Neurons: 11, Grad norm: 2.452e+01\n",
      "Epoch 7793, Loss: 517.5484619140625, Neurons: 11, Grad norm: 2.443e+01\n",
      "Epoch 7794, Loss: 517.368896484375, Neurons: 11, Grad norm: 2.433e+01\n",
      "Epoch 7795, Loss: 517.1896362304688, Neurons: 11, Grad norm: 2.424e+01\n",
      "Epoch 7796, Loss: 517.0108642578125, Neurons: 11, Grad norm: 2.414e+01\n",
      "Epoch 7797, Loss: 516.832275390625, Neurons: 11, Grad norm: 2.405e+01\n",
      "Epoch 7798, Loss: 516.6541748046875, Neurons: 11, Grad norm: 2.396e+01\n",
      "Epoch 7799, Loss: 516.4763793945312, Neurons: 11, Grad norm: 2.387e+01\n",
      "Epoch 7799, Test loss: 517.6685791015625\n",
      "Epoch 7800, Loss: 516.2990112304688, Neurons: 11, Grad norm: 2.378e+01\n",
      "Epoch 7801, Loss: 516.1220092773438, Neurons: 11, Grad norm: 2.369e+01\n",
      "Epoch 7802, Loss: 515.9453125, Neurons: 11, Grad norm: 2.360e+01\n",
      "Epoch 7803, Loss: 515.7689819335938, Neurons: 11, Grad norm: 2.351e+01\n",
      "Epoch 7804, Loss: 515.593017578125, Neurons: 11, Grad norm: 2.342e+01\n",
      "Epoch 7805, Loss: 515.41748046875, Neurons: 11, Grad norm: 2.334e+01\n",
      "Epoch 7806, Loss: 515.2422485351562, Neurons: 11, Grad norm: 2.325e+01\n",
      "Epoch 7807, Loss: 515.0673217773438, Neurons: 11, Grad norm: 2.317e+01\n",
      "Epoch 7808, Loss: 514.892822265625, Neurons: 11, Grad norm: 2.309e+01\n",
      "Epoch 7809, Loss: 514.7186889648438, Neurons: 11, Grad norm: 2.300e+01\n",
      "Epoch 7810, Loss: 514.5448608398438, Neurons: 11, Grad norm: 2.292e+01\n",
      "Epoch 7811, Loss: 514.3714599609375, Neurons: 11, Grad norm: 2.284e+01\n",
      "Epoch 7812, Loss: 514.1983642578125, Neurons: 11, Grad norm: 2.276e+01\n",
      "Epoch 7813, Loss: 514.0256958007812, Neurons: 11, Grad norm: 2.268e+01\n",
      "Epoch 7814, Loss: 513.8533325195312, Neurons: 11, Grad norm: 2.260e+01\n",
      "Epoch 7815, Loss: 513.6812744140625, Neurons: 11, Grad norm: 2.253e+01\n",
      "Epoch 7816, Loss: 513.5096435546875, Neurons: 11, Grad norm: 2.245e+01\n",
      "Epoch 7817, Loss: 513.3383178710938, Neurons: 11, Grad norm: 2.237e+01\n",
      "Epoch 7818, Loss: 513.1673583984375, Neurons: 11, Grad norm: 2.230e+01\n",
      "Epoch 7819, Loss: 512.9967651367188, Neurons: 11, Grad norm: 2.223e+01\n",
      "Epoch 7820, Loss: 512.8265380859375, Neurons: 11, Grad norm: 2.216e+01\n",
      "Epoch 7821, Loss: 512.6566772460938, Neurons: 11, Grad norm: 2.208e+01\n",
      "Epoch 7822, Loss: 512.487060546875, Neurons: 11, Grad norm: 2.201e+01\n",
      "Epoch 7823, Loss: 512.31787109375, Neurons: 11, Grad norm: 2.194e+01\n",
      "Epoch 7824, Loss: 512.1490478515625, Neurons: 11, Grad norm: 2.187e+01\n",
      "Epoch 7825, Loss: 511.98052978515625, Neurons: 11, Grad norm: 2.180e+01\n",
      "Epoch 7826, Loss: 511.8123779296875, Neurons: 11, Grad norm: 2.174e+01\n",
      "Epoch 7827, Loss: 511.64459228515625, Neurons: 11, Grad norm: 2.167e+01\n",
      "Epoch 7828, Loss: 511.4770812988281, Neurons: 11, Grad norm: 2.160e+01\n",
      "Epoch 7829, Loss: 511.3099365234375, Neurons: 11, Grad norm: 2.154e+01\n",
      "Epoch 7830, Loss: 511.14312744140625, Neurons: 11, Grad norm: 2.148e+01\n",
      "Epoch 7831, Loss: 510.9766845703125, Neurons: 11, Grad norm: 2.141e+01\n",
      "Epoch 7832, Loss: 510.8105773925781, Neurons: 11, Grad norm: 2.135e+01\n",
      "Epoch 7833, Loss: 510.644775390625, Neurons: 11, Grad norm: 2.129e+01\n",
      "Epoch 7834, Loss: 510.4794006347656, Neurons: 11, Grad norm: 2.123e+01\n",
      "Epoch 7835, Loss: 510.3142395019531, Neurons: 11, Grad norm: 2.116e+01\n",
      "Epoch 7836, Loss: 510.14947509765625, Neurons: 11, Grad norm: 2.111e+01\n",
      "Epoch 7837, Loss: 509.98504638671875, Neurons: 11, Grad norm: 2.105e+01\n",
      "Epoch 7838, Loss: 509.8209228515625, Neurons: 11, Grad norm: 2.099e+01\n",
      "Epoch 7839, Loss: 509.6571960449219, Neurons: 11, Grad norm: 2.093e+01\n",
      "Epoch 7840, Loss: 509.4936828613281, Neurons: 11, Grad norm: 2.088e+01\n",
      "Epoch 7841, Loss: 509.33062744140625, Neurons: 11, Grad norm: 2.082e+01\n",
      "Epoch 7842, Loss: 509.1678466796875, Neurons: 11, Grad norm: 2.076e+01\n",
      "Epoch 7843, Loss: 509.0054016113281, Neurons: 11, Grad norm: 2.071e+01\n",
      "Epoch 7844, Loss: 508.8432922363281, Neurons: 11, Grad norm: 2.065e+01\n",
      "Epoch 7845, Loss: 508.6814270019531, Neurons: 11, Grad norm: 2.060e+01\n",
      "Epoch 7846, Loss: 508.5199890136719, Neurons: 11, Grad norm: 2.055e+01\n",
      "Epoch 7847, Loss: 508.3587951660156, Neurons: 11, Grad norm: 2.049e+01\n",
      "Epoch 7848, Loss: 508.197998046875, Neurons: 11, Grad norm: 2.045e+01\n",
      "Epoch 7849, Loss: 508.0374450683594, Neurons: 11, Grad norm: 2.039e+01\n",
      "Epoch 7849, Test loss: 508.62109375\n",
      "Epoch 7850, Loss: 507.8772277832031, Neurons: 11, Grad norm: 2.035e+01\n",
      "Epoch 7851, Loss: 507.71734619140625, Neurons: 11, Grad norm: 2.029e+01\n",
      "Epoch 7852, Loss: 507.55780029296875, Neurons: 11, Grad norm: 2.025e+01\n",
      "Epoch 7853, Loss: 507.3985290527344, Neurons: 11, Grad norm: 2.020e+01\n",
      "Epoch 7854, Loss: 507.2395935058594, Neurons: 11, Grad norm: 2.015e+01\n",
      "Epoch 7855, Loss: 507.08099365234375, Neurons: 11, Grad norm: 2.010e+01\n",
      "Epoch 7856, Loss: 506.9226379394531, Neurons: 11, Grad norm: 2.005e+01\n",
      "Epoch 7857, Loss: 506.7646789550781, Neurons: 11, Grad norm: 2.000e+01\n",
      "Epoch 7858, Loss: 506.60699462890625, Neurons: 11, Grad norm: 1.996e+01\n",
      "Epoch 7859, Loss: 506.4495849609375, Neurons: 11, Grad norm: 1.992e+01\n",
      "Epoch 7860, Loss: 506.29248046875, Neurons: 11, Grad norm: 1.987e+01\n",
      "Epoch 7861, Loss: 506.1357727050781, Neurons: 11, Grad norm: 1.983e+01\n",
      "Epoch 7862, Loss: 505.9792785644531, Neurons: 11, Grad norm: 1.978e+01\n",
      "Epoch 7863, Loss: 505.8231506347656, Neurons: 11, Grad norm: 1.974e+01\n",
      "Epoch 7864, Loss: 505.66729736328125, Neurons: 11, Grad norm: 1.970e+01\n",
      "Epoch 7865, Loss: 505.51177978515625, Neurons: 11, Grad norm: 1.966e+01\n",
      "Epoch 7866, Loss: 505.3565368652344, Neurons: 11, Grad norm: 1.961e+01\n",
      "Epoch 7867, Loss: 505.20159912109375, Neurons: 11, Grad norm: 1.957e+01\n",
      "Epoch 7868, Loss: 505.046875, Neurons: 11, Grad norm: 1.954e+01\n",
      "Epoch 7869, Loss: 504.892578125, Neurons: 11, Grad norm: 1.949e+01\n",
      "Epoch 7870, Loss: 504.7384948730469, Neurons: 11, Grad norm: 1.944e+01\n",
      "Epoch 7871, Loss: 504.5847473144531, Neurons: 11, Grad norm: 1.941e+01\n",
      "Epoch 7872, Loss: 504.4312744140625, Neurons: 11, Grad norm: 1.937e+01\n",
      "Epoch 7873, Loss: 504.27813720703125, Neurons: 11, Grad norm: 1.932e+01\n",
      "Epoch 7874, Loss: 504.125244140625, Neurons: 11, Grad norm: 1.929e+01\n",
      "Epoch 7875, Loss: 503.9726867675781, Neurons: 11, Grad norm: 1.925e+01\n",
      "Epoch 7876, Loss: 503.82037353515625, Neurons: 11, Grad norm: 1.921e+01\n",
      "Epoch 7877, Loss: 503.6684265136719, Neurons: 11, Grad norm: 1.917e+01\n",
      "Epoch 7878, Loss: 503.5166931152344, Neurons: 11, Grad norm: 1.914e+01\n",
      "Epoch 7879, Loss: 503.3653259277344, Neurons: 11, Grad norm: 1.910e+01\n",
      "Epoch 7880, Loss: 503.21417236328125, Neurons: 11, Grad norm: 1.905e+01\n",
      "Epoch 7881, Loss: 503.06329345703125, Neurons: 11, Grad norm: 1.902e+01\n",
      "Epoch 7882, Loss: 502.912841796875, Neurons: 11, Grad norm: 1.898e+01\n",
      "Epoch 7883, Loss: 502.7625427246094, Neurons: 11, Grad norm: 1.894e+01\n",
      "Epoch 7884, Loss: 502.612548828125, Neurons: 11, Grad norm: 1.891e+01\n",
      "Epoch 7885, Loss: 502.462890625, Neurons: 11, Grad norm: 1.888e+01\n",
      "Epoch 7886, Loss: 502.3134765625, Neurons: 11, Grad norm: 1.883e+01\n",
      "Epoch 7887, Loss: 502.1642761230469, Neurons: 11, Grad norm: 1.881e+01\n",
      "Epoch 7888, Loss: 502.01544189453125, Neurons: 11, Grad norm: 1.877e+01\n",
      "Epoch 7889, Loss: 501.86688232421875, Neurons: 11, Grad norm: 1.873e+01\n",
      "Epoch 7890, Loss: 501.7185974121094, Neurons: 11, Grad norm: 1.870e+01\n",
      "Epoch 7891, Loss: 501.5705261230469, Neurons: 11, Grad norm: 1.867e+01\n",
      "Epoch 7892, Loss: 501.42279052734375, Neurons: 11, Grad norm: 1.862e+01\n",
      "Epoch 7893, Loss: 501.275390625, Neurons: 11, Grad norm: 1.859e+01\n",
      "Epoch 7894, Loss: 501.128173828125, Neurons: 11, Grad norm: 1.857e+01\n",
      "Epoch 7895, Loss: 500.9812927246094, Neurons: 11, Grad norm: 1.852e+01\n",
      "Epoch 7896, Loss: 500.8346862792969, Neurons: 11, Grad norm: 1.848e+01\n",
      "Epoch 7897, Loss: 500.68829345703125, Neurons: 11, Grad norm: 1.847e+01\n",
      "Epoch 7898, Loss: 500.542236328125, Neurons: 11, Grad norm: 1.843e+01\n",
      "Epoch 7899, Loss: 500.3963928222656, Neurons: 11, Grad norm: 1.838e+01\n",
      "Epoch 7899, Test loss: 500.46270751953125\n",
      "Epoch 7900, Loss: 500.2508850097656, Neurons: 11, Grad norm: 1.836e+01\n",
      "Epoch 7901, Loss: 500.10565185546875, Neurons: 11, Grad norm: 1.833e+01\n",
      "Epoch 7902, Loss: 499.96063232421875, Neurons: 11, Grad norm: 1.828e+01\n",
      "Epoch 7903, Loss: 499.8158874511719, Neurons: 11, Grad norm: 1.825e+01\n",
      "Epoch 7904, Loss: 499.6714782714844, Neurons: 11, Grad norm: 1.823e+01\n",
      "Epoch 7905, Loss: 499.52728271484375, Neurons: 11, Grad norm: 1.819e+01\n",
      "Epoch 7906, Loss: 499.3833923339844, Neurons: 11, Grad norm: 1.816e+01\n",
      "Epoch 7907, Loss: 499.23974609375, Neurons: 11, Grad norm: 1.813e+01\n",
      "Epoch 7908, Loss: 499.09637451171875, Neurons: 11, Grad norm: 1.809e+01\n",
      "Epoch 7909, Loss: 498.9532470703125, Neurons: 11, Grad norm: 1.806e+01\n",
      "Epoch 7910, Loss: 498.8103942871094, Neurons: 11, Grad norm: 1.803e+01\n",
      "Epoch 7911, Loss: 498.66778564453125, Neurons: 11, Grad norm: 1.800e+01\n",
      "Epoch 7912, Loss: 498.5254821777344, Neurons: 11, Grad norm: 1.796e+01\n",
      "Epoch 7913, Loss: 498.3834228515625, Neurons: 11, Grad norm: 1.793e+01\n",
      "Epoch 7914, Loss: 498.24169921875, Neurons: 11, Grad norm: 1.790e+01\n",
      "Epoch 7915, Loss: 498.1001892089844, Neurons: 11, Grad norm: 1.787e+01\n",
      "Epoch 7916, Loss: 497.9588928222656, Neurons: 11, Grad norm: 1.784e+01\n",
      "Epoch 7917, Loss: 497.8179931640625, Neurons: 11, Grad norm: 1.781e+01\n",
      "Epoch 7918, Loss: 497.67718505859375, Neurons: 11, Grad norm: 1.777e+01\n",
      "Epoch 7919, Loss: 497.5367736816406, Neurons: 11, Grad norm: 1.774e+01\n",
      "Epoch 7920, Loss: 497.396484375, Neurons: 11, Grad norm: 1.772e+01\n",
      "Epoch 7921, Loss: 497.256591796875, Neurons: 11, Grad norm: 1.768e+01\n",
      "Epoch 7922, Loss: 497.116943359375, Neurons: 11, Grad norm: 1.765e+01\n",
      "Epoch 7923, Loss: 496.9775390625, Neurons: 11, Grad norm: 1.761e+01\n",
      "Epoch 7924, Loss: 496.83837890625, Neurons: 11, Grad norm: 1.759e+01\n",
      "Epoch 7925, Loss: 496.6994934082031, Neurons: 11, Grad norm: 1.755e+01\n",
      "Epoch 7926, Loss: 496.56085205078125, Neurons: 11, Grad norm: 1.751e+01\n",
      "Epoch 7927, Loss: 496.42242431640625, Neurons: 11, Grad norm: 1.750e+01\n",
      "Epoch 7928, Loss: 496.2843933105469, Neurons: 11, Grad norm: 1.746e+01\n",
      "Epoch 7929, Loss: 496.146484375, Neurons: 11, Grad norm: 1.742e+01\n",
      "Epoch 7930, Loss: 496.0088806152344, Neurons: 11, Grad norm: 1.740e+01\n",
      "Epoch 7931, Loss: 495.8715515136719, Neurons: 11, Grad norm: 1.737e+01\n",
      "Epoch 7932, Loss: 495.7344970703125, Neurons: 11, Grad norm: 1.733e+01\n",
      "Epoch 7933, Loss: 495.59759521484375, Neurons: 11, Grad norm: 1.730e+01\n",
      "Epoch 7934, Loss: 495.4610290527344, Neurons: 11, Grad norm: 1.727e+01\n",
      "Epoch 7935, Loss: 495.3247985839844, Neurons: 11, Grad norm: 1.724e+01\n",
      "Epoch 7936, Loss: 495.1886901855469, Neurons: 11, Grad norm: 1.721e+01\n",
      "Epoch 7937, Loss: 495.0528869628906, Neurons: 11, Grad norm: 1.717e+01\n",
      "Epoch 7938, Loss: 494.9173278808594, Neurons: 11, Grad norm: 1.715e+01\n",
      "Epoch 7939, Loss: 494.7820739746094, Neurons: 11, Grad norm: 1.711e+01\n",
      "Epoch 7940, Loss: 494.64703369140625, Neurons: 11, Grad norm: 1.708e+01\n",
      "Epoch 7941, Loss: 494.5122985839844, Neurons: 11, Grad norm: 1.705e+01\n",
      "Epoch 7942, Loss: 494.3777770996094, Neurons: 11, Grad norm: 1.702e+01\n",
      "Epoch 7943, Loss: 494.2434997558594, Neurons: 11, Grad norm: 1.698e+01\n",
      "Epoch 7944, Loss: 494.1094970703125, Neurons: 11, Grad norm: 1.696e+01\n",
      "Epoch 7945, Loss: 493.9756774902344, Neurons: 11, Grad norm: 1.693e+01\n",
      "Epoch 7946, Loss: 493.84222412109375, Neurons: 11, Grad norm: 1.689e+01\n",
      "Epoch 7947, Loss: 493.708984375, Neurons: 11, Grad norm: 1.686e+01\n",
      "Epoch 7948, Loss: 493.57598876953125, Neurons: 11, Grad norm: 1.683e+01\n",
      "Epoch 7949, Loss: 493.44329833984375, Neurons: 11, Grad norm: 1.680e+01\n",
      "Epoch 7949, Test loss: 493.0346984863281\n",
      "Epoch 7950, Loss: 493.310791015625, Neurons: 11, Grad norm: 1.677e+01\n",
      "Epoch 7951, Loss: 493.1785888671875, Neurons: 11, Grad norm: 1.673e+01\n",
      "Epoch 7952, Loss: 493.0466003417969, Neurons: 11, Grad norm: 1.671e+01\n",
      "Epoch 7953, Loss: 492.9148864746094, Neurons: 11, Grad norm: 1.667e+01\n",
      "Epoch 7954, Loss: 492.783447265625, Neurons: 11, Grad norm: 1.664e+01\n",
      "Epoch 7955, Loss: 492.65228271484375, Neurons: 11, Grad norm: 1.661e+01\n",
      "Epoch 7956, Loss: 492.5213317871094, Neurons: 11, Grad norm: 1.658e+01\n",
      "Epoch 7957, Loss: 492.390625, Neurons: 11, Grad norm: 1.654e+01\n",
      "Epoch 7958, Loss: 492.26019287109375, Neurons: 11, Grad norm: 1.651e+01\n",
      "Epoch 7959, Loss: 492.1299743652344, Neurons: 11, Grad norm: 1.648e+01\n",
      "Epoch 7960, Loss: 492.0000305175781, Neurons: 11, Grad norm: 1.645e+01\n",
      "Epoch 7961, Loss: 491.8703918457031, Neurons: 11, Grad norm: 1.641e+01\n",
      "Epoch 7962, Loss: 491.7409973144531, Neurons: 11, Grad norm: 1.639e+01\n",
      "Epoch 7963, Loss: 491.6117858886719, Neurons: 11, Grad norm: 1.636e+01\n",
      "Epoch 7964, Loss: 491.4828796386719, Neurons: 11, Grad norm: 1.632e+01\n",
      "Epoch 7965, Loss: 491.3542785644531, Neurons: 11, Grad norm: 1.629e+01\n",
      "Epoch 7966, Loss: 491.2257995605469, Neurons: 11, Grad norm: 1.627e+01\n",
      "Epoch 7967, Loss: 491.0976867675781, Neurons: 11, Grad norm: 1.622e+01\n",
      "Epoch 7968, Loss: 490.96978759765625, Neurons: 11, Grad norm: 1.619e+01\n",
      "Epoch 7969, Loss: 490.8421936035156, Neurons: 11, Grad norm: 1.617e+01\n",
      "Epoch 7970, Loss: 490.7147521972656, Neurons: 11, Grad norm: 1.612e+01\n",
      "Epoch 7971, Loss: 490.587646484375, Neurons: 11, Grad norm: 1.609e+01\n",
      "Epoch 7972, Loss: 490.4607238769531, Neurons: 11, Grad norm: 1.607e+01\n",
      "Epoch 7973, Loss: 490.3340759277344, Neurons: 11, Grad norm: 1.603e+01\n",
      "Epoch 7974, Loss: 490.2077331542969, Neurons: 11, Grad norm: 1.600e+01\n",
      "Epoch 7975, Loss: 490.0816345214844, Neurons: 11, Grad norm: 1.598e+01\n",
      "Epoch 7976, Loss: 489.9557800292969, Neurons: 11, Grad norm: 1.594e+01\n",
      "Epoch 7977, Loss: 489.8302001953125, Neurons: 11, Grad norm: 1.590e+01\n",
      "Epoch 7978, Loss: 489.704833984375, Neurons: 11, Grad norm: 1.588e+01\n",
      "Epoch 7979, Loss: 489.57977294921875, Neurons: 11, Grad norm: 1.583e+01\n",
      "Epoch 7980, Loss: 489.4549255371094, Neurons: 11, Grad norm: 1.580e+01\n",
      "Epoch 7981, Loss: 489.3303527832031, Neurons: 11, Grad norm: 1.579e+01\n",
      "Epoch 7982, Loss: 489.20599365234375, Neurons: 11, Grad norm: 1.573e+01\n",
      "Epoch 7983, Loss: 489.0820007324219, Neurons: 11, Grad norm: 1.571e+01\n",
      "Epoch 7984, Loss: 488.9581298828125, Neurons: 11, Grad norm: 1.568e+01\n",
      "Epoch 7985, Loss: 488.8345947265625, Neurons: 11, Grad norm: 1.564e+01\n",
      "Epoch 7986, Loss: 488.7112731933594, Neurons: 11, Grad norm: 1.562e+01\n",
      "Epoch 7987, Loss: 488.5882873535156, Neurons: 11, Grad norm: 1.558e+01\n",
      "Epoch 7988, Loss: 488.4654846191406, Neurons: 11, Grad norm: 1.554e+01\n",
      "Epoch 7989, Loss: 488.3429870605469, Neurons: 11, Grad norm: 1.552e+01\n",
      "Epoch 7990, Loss: 488.2206726074219, Neurons: 11, Grad norm: 1.547e+01\n",
      "Epoch 7991, Loss: 488.09869384765625, Neurons: 11, Grad norm: 1.545e+01\n",
      "Epoch 7992, Loss: 487.97698974609375, Neurons: 11, Grad norm: 1.542e+01\n",
      "Epoch 7993, Loss: 487.8554992675781, Neurons: 11, Grad norm: 1.538e+01\n",
      "Epoch 7994, Loss: 487.7342834472656, Neurons: 11, Grad norm: 1.535e+01\n",
      "Epoch 7995, Loss: 487.61328125, Neurons: 11, Grad norm: 1.532e+01\n",
      "Epoch 7996, Loss: 487.4925842285156, Neurons: 11, Grad norm: 1.528e+01\n",
      "Epoch 7997, Loss: 487.3721008300781, Neurons: 11, Grad norm: 1.525e+01\n",
      "Epoch 7998, Loss: 487.2519226074219, Neurons: 11, Grad norm: 1.522e+01\n",
      "Epoch 7999, Loss: 487.1319885253906, Neurons: 11, Grad norm: 1.518e+01\n",
      "Epoch 7999, Test loss: 486.2445068359375\n",
      "Epoch 8000, Loss: 487.01239013671875, Neurons: 11, Grad norm: 1.515e+01\n",
      "Epoch 8001, Loss: 486.8929443359375, Neurons: 11, Grad norm: 1.512e+01\n",
      "Epoch 8002, Loss: 486.7737731933594, Neurons: 11, Grad norm: 1.508e+01\n",
      "Epoch 8003, Loss: 486.6549377441406, Neurons: 11, Grad norm: 1.506e+01\n",
      "Epoch 8004, Loss: 486.5362854003906, Neurons: 11, Grad norm: 1.502e+01\n",
      "Epoch 8005, Loss: 486.4179382324219, Neurons: 11, Grad norm: 1.498e+01\n",
      "Epoch 8006, Loss: 486.2998962402344, Neurons: 11, Grad norm: 1.496e+01\n",
      "Epoch 8007, Loss: 486.1820373535156, Neurons: 11, Grad norm: 1.492e+01\n",
      "Epoch 8008, Loss: 486.0644836425781, Neurons: 11, Grad norm: 1.488e+01\n",
      "Epoch 8009, Loss: 485.9471740722656, Neurons: 11, Grad norm: 1.487e+01\n",
      "Epoch 8010, Loss: 485.8302001953125, Neurons: 11, Grad norm: 1.481e+01\n",
      "Epoch 8011, Loss: 485.71337890625, Neurons: 11, Grad norm: 1.479e+01\n",
      "Epoch 8012, Loss: 485.5968933105469, Neurons: 11, Grad norm: 1.476e+01\n",
      "Epoch 8013, Loss: 485.48065185546875, Neurons: 11, Grad norm: 1.471e+01\n",
      "Epoch 8014, Loss: 485.36474609375, Neurons: 11, Grad norm: 1.470e+01\n",
      "Epoch 8015, Loss: 485.2489929199219, Neurons: 11, Grad norm: 1.466e+01\n",
      "Epoch 8016, Loss: 485.1335754394531, Neurons: 11, Grad norm: 1.462e+01\n",
      "Epoch 8017, Loss: 485.0184020996094, Neurons: 11, Grad norm: 1.460e+01\n",
      "Epoch 8018, Loss: 484.9034729003906, Neurons: 11, Grad norm: 1.456e+01\n",
      "Epoch 8019, Loss: 484.78887939453125, Neurons: 11, Grad norm: 1.452e+01\n",
      "Epoch 8020, Loss: 484.67449951171875, Neurons: 11, Grad norm: 1.450e+01\n",
      "Epoch 8021, Loss: 484.5603942871094, Neurons: 11, Grad norm: 1.446e+01\n",
      "Epoch 8022, Loss: 484.44659423828125, Neurons: 11, Grad norm: 1.443e+01\n",
      "Epoch 8023, Loss: 484.3330993652344, Neurons: 11, Grad norm: 1.440e+01\n",
      "Epoch 8024, Loss: 484.21978759765625, Neurons: 11, Grad norm: 1.435e+01\n",
      "Epoch 8025, Loss: 484.1067810058594, Neurons: 11, Grad norm: 1.434e+01\n",
      "Epoch 8026, Loss: 483.9940490722656, Neurons: 11, Grad norm: 1.430e+01\n",
      "Epoch 8027, Loss: 483.88153076171875, Neurons: 11, Grad norm: 1.426e+01\n",
      "Epoch 8028, Loss: 483.7693786621094, Neurons: 11, Grad norm: 1.424e+01\n",
      "Epoch 8029, Loss: 483.6575012207031, Neurons: 11, Grad norm: 1.419e+01\n",
      "Epoch 8030, Loss: 483.54583740234375, Neurons: 11, Grad norm: 1.417e+01\n",
      "Epoch 8031, Loss: 483.4344787597656, Neurons: 11, Grad norm: 1.414e+01\n",
      "Epoch 8032, Loss: 483.3233947753906, Neurons: 11, Grad norm: 1.409e+01\n",
      "Epoch 8033, Loss: 483.21258544921875, Neurons: 11, Grad norm: 1.408e+01\n",
      "Epoch 8034, Loss: 483.1020812988281, Neurons: 11, Grad norm: 1.403e+01\n",
      "Epoch 8035, Loss: 482.9917907714844, Neurons: 11, Grad norm: 1.400e+01\n",
      "Epoch 8036, Loss: 482.88177490234375, Neurons: 11, Grad norm: 1.398e+01\n",
      "Epoch 8037, Loss: 482.77203369140625, Neurons: 11, Grad norm: 1.393e+01\n",
      "Epoch 8038, Loss: 482.6626281738281, Neurons: 11, Grad norm: 1.391e+01\n",
      "Epoch 8039, Loss: 482.5534973144531, Neurons: 11, Grad norm: 1.387e+01\n",
      "Epoch 8040, Loss: 482.44464111328125, Neurons: 11, Grad norm: 1.384e+01\n",
      "Epoch 8041, Loss: 482.33599853515625, Neurons: 11, Grad norm: 1.382e+01\n",
      "Epoch 8042, Loss: 482.2277526855469, Neurons: 11, Grad norm: 1.378e+01\n",
      "Epoch 8043, Loss: 482.11968994140625, Neurons: 11, Grad norm: 1.375e+01\n",
      "Epoch 8044, Loss: 482.01190185546875, Neurons: 11, Grad norm: 1.372e+01\n",
      "Epoch 8045, Loss: 481.9044494628906, Neurons: 11, Grad norm: 1.368e+01\n",
      "Epoch 8046, Loss: 481.79730224609375, Neurons: 11, Grad norm: 1.366e+01\n",
      "Epoch 8047, Loss: 481.6903991699219, Neurons: 11, Grad norm: 1.362e+01\n",
      "Epoch 8048, Loss: 481.583740234375, Neurons: 11, Grad norm: 1.359e+01\n",
      "Epoch 8049, Loss: 481.4773864746094, Neurons: 11, Grad norm: 1.356e+01\n",
      "Epoch 8049, Test loss: 480.0853576660156\n",
      "Epoch 8050, Loss: 481.371337890625, Neurons: 11, Grad norm: 1.352e+01\n",
      "Epoch 8051, Loss: 481.2655944824219, Neurons: 11, Grad norm: 1.351e+01\n",
      "Epoch 8052, Loss: 481.16009521484375, Neurons: 11, Grad norm: 1.346e+01\n",
      "Epoch 8053, Loss: 481.0549011230469, Neurons: 11, Grad norm: 1.343e+01\n",
      "Epoch 8054, Loss: 480.9499816894531, Neurons: 11, Grad norm: 1.341e+01\n",
      "Epoch 8055, Loss: 480.8453369140625, Neurons: 11, Grad norm: 1.336e+01\n",
      "Epoch 8056, Loss: 480.7409973144531, Neurons: 11, Grad norm: 1.336e+01\n",
      "Epoch 8057, Loss: 480.6369323730469, Neurons: 11, Grad norm: 1.330e+01\n",
      "Epoch 8058, Loss: 480.5331726074219, Neurons: 11, Grad norm: 1.328e+01\n",
      "Epoch 8059, Loss: 480.4296875, Neurons: 11, Grad norm: 1.325e+01\n",
      "Epoch 8060, Loss: 480.32647705078125, Neurons: 11, Grad norm: 1.321e+01\n",
      "Epoch 8061, Loss: 480.2236328125, Neurons: 11, Grad norm: 1.320e+01\n",
      "Epoch 8062, Loss: 480.1210021972656, Neurons: 11, Grad norm: 1.315e+01\n",
      "Epoch 8063, Loss: 480.0186767578125, Neurons: 11, Grad norm: 1.313e+01\n",
      "Epoch 8064, Loss: 479.91668701171875, Neurons: 11, Grad norm: 1.310e+01\n",
      "Epoch 8065, Loss: 479.81488037109375, Neurons: 11, Grad norm: 1.306e+01\n",
      "Epoch 8066, Loss: 479.7135009765625, Neurons: 11, Grad norm: 1.305e+01\n",
      "Epoch 8067, Loss: 479.6122741699219, Neurons: 11, Grad norm: 1.300e+01\n",
      "Epoch 8068, Loss: 479.5114440917969, Neurons: 11, Grad norm: 1.298e+01\n",
      "Epoch 8069, Loss: 479.410888671875, Neurons: 11, Grad norm: 1.295e+01\n",
      "Epoch 8070, Loss: 479.3105773925781, Neurons: 11, Grad norm: 1.291e+01\n",
      "Epoch 8071, Loss: 479.2106018066406, Neurons: 11, Grad norm: 1.290e+01\n",
      "Epoch 8072, Loss: 479.11090087890625, Neurons: 11, Grad norm: 1.285e+01\n",
      "Epoch 8073, Loss: 479.011474609375, Neurons: 11, Grad norm: 1.284e+01\n",
      "Epoch 8074, Loss: 478.9123840332031, Neurons: 11, Grad norm: 1.280e+01\n",
      "Epoch 8075, Loss: 478.8135986328125, Neurons: 11, Grad norm: 1.277e+01\n",
      "Epoch 8076, Loss: 478.71502685546875, Neurons: 11, Grad norm: 1.275e+01\n",
      "Epoch 8077, Loss: 478.61688232421875, Neurons: 11, Grad norm: 1.271e+01\n",
      "Epoch 8078, Loss: 478.5188903808594, Neurons: 11, Grad norm: 1.269e+01\n",
      "Epoch 8079, Loss: 478.4212951660156, Neurons: 11, Grad norm: 1.265e+01\n",
      "Epoch 8080, Loss: 478.323974609375, Neurons: 11, Grad norm: 1.263e+01\n",
      "Epoch 8081, Loss: 478.2268981933594, Neurons: 11, Grad norm: 1.260e+01\n",
      "Epoch 8082, Loss: 478.13018798828125, Neurons: 11, Grad norm: 1.257e+01\n",
      "Epoch 8083, Loss: 478.03375244140625, Neurons: 11, Grad norm: 1.254e+01\n",
      "Epoch 8084, Loss: 477.9375915527344, Neurons: 11, Grad norm: 1.251e+01\n",
      "Epoch 8085, Loss: 477.84173583984375, Neurons: 11, Grad norm: 1.249e+01\n",
      "Epoch 8086, Loss: 477.7461853027344, Neurons: 11, Grad norm: 1.246e+01\n",
      "Epoch 8087, Loss: 477.65093994140625, Neurons: 11, Grad norm: 1.243e+01\n",
      "Epoch 8088, Loss: 477.5559997558594, Neurons: 11, Grad norm: 1.240e+01\n",
      "Epoch 8089, Loss: 477.4613342285156, Neurons: 11, Grad norm: 1.238e+01\n",
      "Epoch 8090, Loss: 477.366943359375, Neurons: 11, Grad norm: 1.235e+01\n",
      "Epoch 8091, Loss: 477.27288818359375, Neurons: 11, Grad norm: 1.232e+01\n",
      "Epoch 8092, Loss: 477.17919921875, Neurons: 11, Grad norm: 1.230e+01\n",
      "Epoch 8093, Loss: 477.085693359375, Neurons: 11, Grad norm: 1.226e+01\n",
      "Epoch 8094, Loss: 476.99249267578125, Neurons: 11, Grad norm: 1.224e+01\n",
      "Epoch 8095, Loss: 476.8996276855469, Neurons: 11, Grad norm: 1.221e+01\n",
      "Epoch 8096, Loss: 476.8070983886719, Neurons: 11, Grad norm: 1.219e+01\n",
      "Epoch 8097, Loss: 476.71484375, Neurons: 11, Grad norm: 1.216e+01\n",
      "Epoch 8098, Loss: 476.6228332519531, Neurons: 11, Grad norm: 1.213e+01\n",
      "Epoch 8099, Loss: 476.53118896484375, Neurons: 11, Grad norm: 1.211e+01\n",
      "Epoch 8099, Test loss: 474.6225891113281\n",
      "Epoch 8100, Loss: 476.4397888183594, Neurons: 11, Grad norm: 1.208e+01\n",
      "Epoch 8101, Loss: 476.3487243652344, Neurons: 11, Grad norm: 1.206e+01\n",
      "Epoch 8102, Loss: 476.25799560546875, Neurons: 11, Grad norm: 1.203e+01\n",
      "Epoch 8103, Loss: 476.16748046875, Neurons: 11, Grad norm: 1.201e+01\n",
      "Epoch 8104, Loss: 476.0773010253906, Neurons: 11, Grad norm: 1.198e+01\n",
      "Epoch 8105, Loss: 475.9873962402344, Neurons: 11, Grad norm: 1.195e+01\n",
      "Epoch 8106, Loss: 475.8978271484375, Neurons: 11, Grad norm: 1.193e+01\n",
      "Epoch 8107, Loss: 475.80859375, Neurons: 11, Grad norm: 1.190e+01\n",
      "Epoch 8108, Loss: 475.7195739746094, Neurons: 11, Grad norm: 1.187e+01\n",
      "Epoch 8109, Loss: 475.6308898925781, Neurons: 11, Grad norm: 1.185e+01\n",
      "Epoch 8110, Loss: 475.54254150390625, Neurons: 11, Grad norm: 1.182e+01\n",
      "Epoch 8111, Loss: 475.4544982910156, Neurons: 11, Grad norm: 1.180e+01\n",
      "Epoch 8112, Loss: 475.36669921875, Neurons: 11, Grad norm: 1.177e+01\n",
      "Epoch 8113, Loss: 475.2791748046875, Neurons: 11, Grad norm: 1.175e+01\n",
      "Epoch 8114, Loss: 475.1920471191406, Neurons: 11, Grad norm: 1.172e+01\n",
      "Epoch 8115, Loss: 475.1051940917969, Neurons: 11, Grad norm: 1.170e+01\n",
      "Epoch 8116, Loss: 475.0185852050781, Neurons: 11, Grad norm: 1.168e+01\n",
      "Epoch 8117, Loss: 474.9322509765625, Neurons: 11, Grad norm: 1.166e+01\n",
      "Epoch 8118, Loss: 474.8462829589844, Neurons: 11, Grad norm: 1.163e+01\n",
      "Epoch 8119, Loss: 474.7605895996094, Neurons: 11, Grad norm: 1.162e+01\n",
      "Epoch 8120, Loss: 474.6751403808594, Neurons: 11, Grad norm: 1.159e+01\n",
      "Epoch 8121, Loss: 474.590087890625, Neurons: 11, Grad norm: 1.160e+01\n",
      "Epoch 8122, Loss: 474.5052795410156, Neurons: 11, Grad norm: 1.157e+01\n",
      "Epoch 8123, Loss: 474.4207458496094, Neurons: 11, Grad norm: 1.161e+01\n",
      "Epoch 8124, Loss: 474.3365478515625, Neurons: 11, Grad norm: 1.160e+01\n",
      "Epoch 8125, Loss: 474.2525939941406, Neurons: 11, Grad norm: 1.170e+01\n",
      "Epoch 8126, Loss: 474.1689758300781, Neurons: 11, Grad norm: 1.173e+01\n",
      "Epoch 8127, Loss: 474.085693359375, Neurons: 11, Grad norm: 1.201e+01\n",
      "Epoch 8128, Loss: 474.00262451171875, Neurons: 11, Grad norm: 1.222e+01\n",
      "Epoch 8129, Loss: 473.9199523925781, Neurons: 11, Grad norm: 1.300e+01\n",
      "Epoch 8130, Loss: 473.8374328613281, Neurons: 11, Grad norm: 1.384e+01\n",
      "Epoch 8131, Loss: 473.7553405761719, Neurons: 11, Grad norm: 1.592e+01\n",
      "Epoch 8132, Loss: 473.6734924316406, Neurons: 11, Grad norm: 1.859e+01\n",
      "Epoch 8133, Loss: 473.59197998046875, Neurons: 11, Grad norm: 2.375e+01\n",
      "Epoch 8134, Loss: 473.51080322265625, Neurons: 11, Grad norm: 3.063e+01\n",
      "Epoch 8135, Loss: 473.42999267578125, Neurons: 11, Grad norm: 4.206e+01\n",
      "Epoch 8136, Loss: 473.3494873046875, Neurons: 11, Grad norm: 5.733e+01\n",
      "Epoch 8137, Loss: 473.2697448730469, Neurons: 11, Grad norm: 8.022e+01\n",
      "Epoch 8138, Loss: 473.190673828125, Neurons: 11, Grad norm: 1.088e+02\n",
      "Epoch 8139, Loss: 473.11297607421875, Neurons: 11, Grad norm: 1.440e+02\n",
      "Epoch 8140, Loss: 473.03692626953125, Neurons: 11, Grad norm: 1.728e+02\n",
      "Epoch 8141, Loss: 472.96234130859375, Neurons: 11, Grad norm: 1.794e+02\n",
      "Epoch 8142, Loss: 472.8876953125, Neurons: 11, Grad norm: 1.411e+02\n",
      "Epoch 8143, Loss: 472.8114013671875, Neurons: 11, Grad norm: 6.119e+01\n",
      "Epoch 8144, Loss: 472.7349853515625, Neurons: 11, Grad norm: 3.719e+01\n",
      "Epoch 8145, Loss: 472.6622009277344, Neurons: 11, Grad norm: 1.081e+02\n",
      "Epoch 8146, Loss: 472.59259033203125, Neurons: 11, Grad norm: 1.309e+02\n",
      "Epoch 8147, Loss: 472.52227783203125, Neurons: 11, Grad norm: 9.333e+01\n",
      "Epoch 8148, Loss: 472.4497985839844, Neurons: 11, Grad norm: 1.972e+01\n",
      "Epoch 8149, Loss: 472.377685546875, Neurons: 11, Grad norm: 6.279e+01\n",
      "Epoch 8149, Test loss: 469.9696350097656\n",
      "Epoch 8150, Loss: 472.30859375, Neurons: 11, Grad norm: 1.013e+02\n",
      "Epoch 8151, Loss: 472.240478515625, Neurons: 11, Grad norm: 8.739e+01\n",
      "Epoch 8152, Loss: 472.1707458496094, Neurons: 11, Grad norm: 2.958e+01\n",
      "Epoch 8153, Loss: 472.1005859375, Neurons: 11, Grad norm: 4.045e+01\n",
      "Epoch 8154, Loss: 472.0324401855469, Neurons: 11, Grad norm: 8.053e+01\n",
      "Epoch 8155, Loss: 471.96539306640625, Neurons: 11, Grad norm: 7.337e+01\n",
      "Epoch 8156, Loss: 471.8974304199219, Neurons: 11, Grad norm: 3.001e+01\n",
      "Epoch 8157, Loss: 471.8291015625, Neurons: 11, Grad norm: 3.101e+01\n",
      "Epoch 8158, Loss: 471.7619934082031, Neurons: 11, Grad norm: 6.395e+01\n",
      "Epoch 8159, Loss: 471.6958312988281, Neurons: 11, Grad norm: 6.188e+01\n",
      "Epoch 8160, Loss: 471.6292419433594, Neurons: 11, Grad norm: 2.574e+01\n",
      "Epoch 8161, Loss: 471.5623474121094, Neurons: 11, Grad norm: 2.384e+01\n",
      "Epoch 8162, Loss: 471.49639892578125, Neurons: 11, Grad norm: 5.305e+01\n",
      "Epoch 8163, Loss: 471.43109130859375, Neurons: 11, Grad norm: 5.029e+01\n",
      "Epoch 8164, Loss: 471.3656005859375, Neurons: 11, Grad norm: 2.368e+01\n",
      "Epoch 8165, Loss: 471.29998779296875, Neurons: 11, Grad norm: 2.028e+01\n",
      "Epoch 8166, Loss: 471.2350769042969, Neurons: 11, Grad norm: 4.227e+01\n",
      "Epoch 8167, Loss: 471.1707458496094, Neurons: 11, Grad norm: 4.301e+01\n",
      "Epoch 8168, Loss: 471.1062927246094, Neurons: 11, Grad norm: 2.057e+01\n",
      "Epoch 8169, Loss: 471.0418395996094, Neurons: 11, Grad norm: 1.539e+01\n",
      "Epoch 8170, Loss: 470.9778747558594, Neurons: 11, Grad norm: 3.529e+01\n",
      "Epoch 8171, Loss: 470.9143981933594, Neurons: 11, Grad norm: 3.532e+01\n",
      "Epoch 8172, Loss: 470.8509521484375, Neurons: 11, Grad norm: 2.057e+01\n",
      "Epoch 8173, Loss: 470.78759765625, Neurons: 11, Grad norm: 1.292e+01\n",
      "Epoch 8174, Loss: 470.72454833984375, Neurons: 11, Grad norm: 2.710e+01\n",
      "Epoch 8175, Loss: 470.6618957519531, Neurons: 11, Grad norm: 3.115e+01\n",
      "Epoch 8176, Loss: 470.59942626953125, Neurons: 11, Grad norm: 1.909e+01\n",
      "Epoch 8177, Loss: 470.53704833984375, Neurons: 11, Grad norm: 1.032e+01\n",
      "Epoch 8178, Loss: 470.4749450683594, Neurons: 11, Grad norm: 2.205e+01\n",
      "Epoch 8179, Loss: 470.4131774902344, Neurons: 11, Grad norm: 2.547e+01\n",
      "Epoch 8180, Loss: 470.3515930175781, Neurons: 11, Grad norm: 1.989e+01\n",
      "Epoch 8181, Loss: 470.2901916503906, Neurons: 11, Grad norm: 1.004e+01\n",
      "Epoch 8182, Loss: 470.2289733886719, Neurons: 11, Grad norm: 1.563e+01\n",
      "Epoch 8183, Loss: 470.1680908203125, Neurons: 11, Grad norm: 2.235e+01\n",
      "Epoch 8184, Loss: 470.1074523925781, Neurons: 11, Grad norm: 1.843e+01\n",
      "Epoch 8185, Loss: 470.046875, Neurons: 11, Grad norm: 1.165e+01\n",
      "Epoch 8186, Loss: 469.9866027832031, Neurons: 11, Grad norm: 1.233e+01\n",
      "Epoch 8187, Loss: 469.9265441894531, Neurons: 11, Grad norm: 1.711e+01\n",
      "Epoch 8188, Loss: 469.8667297363281, Neurons: 11, Grad norm: 1.839e+01\n",
      "Epoch 8189, Loss: 469.8070983886719, Neurons: 11, Grad norm: 1.249e+01\n",
      "Epoch 8190, Loss: 469.7476806640625, Neurons: 11, Grad norm: 9.838e+00\n",
      "Epoch 8191, Loss: 469.6884765625, Neurons: 11, Grad norm: 1.411e+01\n",
      "Epoch 8192, Loss: 469.6294860839844, Neurons: 11, Grad norm: 1.551e+01\n",
      "Epoch 8193, Loss: 469.57080078125, Neurons: 11, Grad norm: 1.444e+01\n",
      "Epoch 8194, Loss: 469.5121765136719, Neurons: 11, Grad norm: 1.007e+01\n",
      "Epoch 8195, Loss: 469.4538879394531, Neurons: 11, Grad norm: 1.038e+01\n",
      "Epoch 8196, Loss: 469.39569091796875, Neurons: 11, Grad norm: 1.385e+01\n",
      "Epoch 8197, Loss: 469.3377990722656, Neurons: 11, Grad norm: 1.332e+01\n",
      "Epoch 8198, Loss: 469.28009033203125, Neurons: 11, Grad norm: 1.186e+01\n",
      "Epoch 8199, Loss: 469.22259521484375, Neurons: 11, Grad norm: 9.635e+00\n",
      "Epoch 8199, Test loss: 466.4422912597656\n",
      "Epoch 8200, Loss: 469.165283203125, Neurons: 11, Grad norm: 1.053e+01\n",
      "Epoch 8201, Loss: 469.1081848144531, Neurons: 11, Grad norm: 1.283e+01\n",
      "Epoch 8202, Loss: 469.0513000488281, Neurons: 11, Grad norm: 1.166e+01\n",
      "Epoch 8203, Loss: 468.9945983886719, Neurons: 11, Grad norm: 1.065e+01\n",
      "Epoch 8204, Loss: 468.9381408691406, Neurons: 11, Grad norm: 9.602e+00\n",
      "Epoch 8205, Loss: 468.88189697265625, Neurons: 11, Grad norm: 1.022e+01\n",
      "Epoch 8206, Loss: 468.8257751464844, Neurons: 11, Grad norm: 1.179e+01\n",
      "Epoch 8207, Loss: 468.7698974609375, Neurons: 11, Grad norm: 1.070e+01\n",
      "Epoch 8208, Loss: 468.71429443359375, Neurons: 11, Grad norm: 1.015e+01\n",
      "Epoch 8209, Loss: 468.6588439941406, Neurons: 11, Grad norm: 9.489e+00\n",
      "Epoch 8210, Loss: 468.6035461425781, Neurons: 11, Grad norm: 9.778e+00\n",
      "Epoch 8211, Loss: 468.5484924316406, Neurons: 11, Grad norm: 1.092e+01\n",
      "Epoch 8212, Loss: 468.49359130859375, Neurons: 11, Grad norm: 1.014e+01\n",
      "Epoch 8213, Loss: 468.4388732910156, Neurons: 11, Grad norm: 9.984e+00\n",
      "Epoch 8214, Loss: 468.3844909667969, Neurons: 11, Grad norm: 9.331e+00\n",
      "Epoch 8215, Loss: 468.3302001953125, Neurons: 11, Grad norm: 9.404e+00\n",
      "Epoch 8216, Loss: 468.2760925292969, Neurons: 11, Grad norm: 1.020e+01\n",
      "Epoch 8217, Loss: 468.2221984863281, Neurons: 11, Grad norm: 9.720e+00\n",
      "Epoch 8218, Loss: 468.1684875488281, Neurons: 11, Grad norm: 9.831e+00\n",
      "Epoch 8219, Loss: 468.114990234375, Neurons: 11, Grad norm: 9.222e+00\n",
      "Epoch 8220, Loss: 468.0617370605469, Neurons: 11, Grad norm: 9.203e+00\n",
      "Epoch 8221, Loss: 468.0086364746094, Neurons: 11, Grad norm: 9.678e+00\n",
      "Epoch 8222, Loss: 467.9556884765625, Neurons: 11, Grad norm: 9.410e+00\n",
      "Epoch 8223, Loss: 467.9029846191406, Neurons: 11, Grad norm: 9.715e+00\n",
      "Epoch 8224, Loss: 467.85040283203125, Neurons: 11, Grad norm: 9.162e+00\n",
      "Epoch 8225, Loss: 467.79803466796875, Neurons: 11, Grad norm: 9.157e+00\n",
      "Epoch 8226, Loss: 467.7458801269531, Neurons: 11, Grad norm: 9.244e+00\n",
      "Epoch 8227, Loss: 467.6940002441406, Neurons: 11, Grad norm: 9.132e+00\n",
      "Epoch 8228, Loss: 467.64215087890625, Neurons: 11, Grad norm: 9.475e+00\n",
      "Epoch 8229, Loss: 467.5905456542969, Neurons: 11, Grad norm: 9.085e+00\n",
      "Epoch 8230, Loss: 467.5390930175781, Neurons: 11, Grad norm: 9.180e+00\n",
      "Epoch 8231, Loss: 467.4878845214844, Neurons: 11, Grad norm: 9.011e+00\n",
      "Epoch 8232, Loss: 467.4368896484375, Neurons: 11, Grad norm: 8.969e+00\n",
      "Epoch 8233, Loss: 467.385986328125, Neurons: 11, Grad norm: 9.207e+00\n",
      "Epoch 8234, Loss: 467.3352966308594, Neurons: 11, Grad norm: 8.976e+00\n",
      "Epoch 8235, Loss: 467.28485107421875, Neurons: 11, Grad norm: 9.180e+00\n",
      "Epoch 8236, Loss: 467.2344970703125, Neurons: 11, Grad norm: 8.899e+00\n",
      "Epoch 8237, Loss: 467.18438720703125, Neurons: 11, Grad norm: 8.943e+00\n",
      "Epoch 8238, Loss: 467.1343994140625, Neurons: 11, Grad norm: 8.928e+00\n",
      "Epoch 8239, Loss: 467.0846862792969, Neurons: 11, Grad norm: 8.843e+00\n",
      "Epoch 8240, Loss: 467.0350341796875, Neurons: 11, Grad norm: 9.056e+00\n",
      "Epoch 8241, Loss: 466.985595703125, Neurons: 11, Grad norm: 8.828e+00\n",
      "Epoch 8242, Loss: 466.9364013671875, Neurons: 11, Grad norm: 9.007e+00\n",
      "Epoch 8243, Loss: 466.8872985839844, Neurons: 11, Grad norm: 8.771e+00\n",
      "Epoch 8244, Loss: 466.83837890625, Neurons: 11, Grad norm: 8.830e+00\n",
      "Epoch 8245, Loss: 466.7897033691406, Neurons: 11, Grad norm: 8.770e+00\n",
      "Epoch 8246, Loss: 466.7411804199219, Neurons: 11, Grad norm: 8.722e+00\n",
      "Epoch 8247, Loss: 466.6927795410156, Neurons: 11, Grad norm: 8.840e+00\n",
      "Epoch 8248, Loss: 466.6446533203125, Neurons: 11, Grad norm: 8.685e+00\n",
      "Epoch 8249, Loss: 466.5965881347656, Neurons: 11, Grad norm: 8.838e+00\n",
      "Epoch 8249, Test loss: 463.4735107421875\n",
      "Epoch 8250, Loss: 466.5487365722656, Neurons: 11, Grad norm: 8.648e+00\n",
      "Epoch 8251, Loss: 466.50103759765625, Neurons: 11, Grad norm: 8.745e+00\n",
      "Epoch 8252, Loss: 466.45355224609375, Neurons: 11, Grad norm: 8.623e+00\n",
      "Epoch 8253, Loss: 466.40618896484375, Neurons: 11, Grad norm: 8.628e+00\n",
      "Epoch 8254, Loss: 466.3590393066406, Neurons: 11, Grad norm: 8.641e+00\n",
      "Epoch 8255, Loss: 466.3120422363281, Neurons: 11, Grad norm: 8.566e+00\n",
      "Epoch 8256, Loss: 466.26519775390625, Neurons: 11, Grad norm: 8.650e+00\n",
      "Epoch 8257, Loss: 466.2184753417969, Neurons: 11, Grad norm: 8.528e+00\n",
      "Epoch 8258, Loss: 466.1719970703125, Neurons: 11, Grad norm: 8.619e+00\n",
      "Epoch 8259, Loss: 466.1256408691406, Neurons: 11, Grad norm: 8.496e+00\n",
      "Epoch 8260, Loss: 466.0794982910156, Neurons: 11, Grad norm: 8.560e+00\n",
      "Epoch 8261, Loss: 466.0334777832031, Neurons: 11, Grad norm: 8.473e+00\n",
      "Epoch 8262, Loss: 465.9876403808594, Neurons: 11, Grad norm: 8.486e+00\n",
      "Epoch 8263, Loss: 465.94189453125, Neurons: 11, Grad norm: 8.465e+00\n",
      "Epoch 8264, Loss: 465.8963928222656, Neurons: 11, Grad norm: 8.428e+00\n",
      "Epoch 8265, Loss: 465.8510437011719, Neurons: 11, Grad norm: 8.464e+00\n",
      "Epoch 8266, Loss: 465.8057861328125, Neurons: 11, Grad norm: 8.381e+00\n",
      "Epoch 8267, Loss: 465.76080322265625, Neurons: 11, Grad norm: 8.466e+00\n",
      "Epoch 8268, Loss: 465.71588134765625, Neurons: 11, Grad norm: 8.343e+00\n",
      "Epoch 8269, Loss: 465.671142578125, Neurons: 11, Grad norm: 8.448e+00\n",
      "Epoch 8270, Loss: 465.6265869140625, Neurons: 11, Grad norm: 8.311e+00\n",
      "Epoch 8271, Loss: 465.5821838378906, Neurons: 11, Grad norm: 8.398e+00\n",
      "Epoch 8272, Loss: 465.53790283203125, Neurons: 11, Grad norm: 8.282e+00\n",
      "Epoch 8273, Loss: 465.4937744140625, Neurons: 11, Grad norm: 8.338e+00\n",
      "Epoch 8274, Loss: 465.4498291015625, Neurons: 11, Grad norm: 8.258e+00\n",
      "Epoch 8275, Loss: 465.4060363769531, Neurons: 11, Grad norm: 8.280e+00\n",
      "Epoch 8276, Loss: 465.3623962402344, Neurons: 11, Grad norm: 8.240e+00\n",
      "Epoch 8277, Loss: 465.3188781738281, Neurons: 11, Grad norm: 8.229e+00\n",
      "Epoch 8278, Loss: 465.2755432128906, Neurons: 11, Grad norm: 8.219e+00\n",
      "Epoch 8279, Loss: 465.2323303222656, Neurons: 11, Grad norm: 8.192e+00\n",
      "Epoch 8280, Loss: 465.1893005371094, Neurons: 11, Grad norm: 8.193e+00\n",
      "Epoch 8281, Loss: 465.1463928222656, Neurons: 11, Grad norm: 8.156e+00\n",
      "Epoch 8282, Loss: 465.1036376953125, Neurons: 11, Grad norm: 8.162e+00\n",
      "Epoch 8283, Loss: 465.06103515625, Neurons: 11, Grad norm: 8.125e+00\n",
      "Epoch 8284, Loss: 465.0185852050781, Neurons: 11, Grad norm: 8.129e+00\n",
      "Epoch 8285, Loss: 464.9762878417969, Neurons: 11, Grad norm: 8.093e+00\n",
      "Epoch 8286, Loss: 464.9341735839844, Neurons: 11, Grad norm: 8.104e+00\n",
      "Epoch 8287, Loss: 464.8921813964844, Neurons: 11, Grad norm: 8.058e+00\n",
      "Epoch 8288, Loss: 464.85028076171875, Neurons: 11, Grad norm: 8.078e+00\n",
      "Epoch 8289, Loss: 464.80859375, Neurons: 11, Grad norm: 8.023e+00\n",
      "Epoch 8290, Loss: 464.7669982910156, Neurons: 11, Grad norm: 8.056e+00\n",
      "Epoch 8291, Loss: 464.7255859375, Neurons: 11, Grad norm: 7.988e+00\n",
      "Epoch 8292, Loss: 464.6842956542969, Neurons: 11, Grad norm: 8.040e+00\n",
      "Epoch 8293, Loss: 464.64312744140625, Neurons: 11, Grad norm: 7.950e+00\n",
      "Epoch 8294, Loss: 464.6020812988281, Neurons: 11, Grad norm: 8.045e+00\n",
      "Epoch 8295, Loss: 464.5611877441406, Neurons: 11, Grad norm: 7.916e+00\n",
      "Epoch 8296, Loss: 464.5204772949219, Neurons: 11, Grad norm: 8.089e+00\n",
      "Epoch 8297, Loss: 464.4798889160156, Neurons: 11, Grad norm: 7.905e+00\n",
      "Epoch 8298, Loss: 464.4394836425781, Neurons: 11, Grad norm: 8.228e+00\n",
      "Epoch 8299, Loss: 464.3991394042969, Neurons: 11, Grad norm: 7.994e+00\n",
      "Epoch 8299, Test loss: 461.0007629394531\n",
      "Epoch 8300, Loss: 464.3589782714844, Neurons: 11, Grad norm: 8.667e+00\n",
      "Epoch 8301, Loss: 464.3189392089844, Neurons: 11, Grad norm: 8.476e+00\n",
      "Epoch 8302, Loss: 464.27899169921875, Neurons: 11, Grad norm: 9.941e+00\n",
      "Epoch 8303, Loss: 464.2392272949219, Neurons: 11, Grad norm: 1.030e+01\n",
      "Epoch 8304, Loss: 464.1995849609375, Neurons: 11, Grad norm: 1.354e+01\n",
      "Epoch 8305, Loss: 464.1601257324219, Neurons: 11, Grad norm: 1.577e+01\n",
      "Epoch 8306, Loss: 464.12078857421875, Neurons: 11, Grad norm: 2.236e+01\n",
      "Epoch 8307, Loss: 464.0815734863281, Neurons: 11, Grad norm: 2.891e+01\n",
      "Epoch 8308, Loss: 464.0426025390625, Neurons: 11, Grad norm: 4.196e+01\n",
      "Epoch 8309, Loss: 464.0037841796875, Neurons: 11, Grad norm: 5.737e+01\n",
      "Epoch 8310, Loss: 463.9653015136719, Neurons: 11, Grad norm: 8.261e+01\n",
      "Epoch 8311, Loss: 463.9272766113281, Neurons: 11, Grad norm: 1.138e+02\n",
      "Epoch 8312, Loss: 463.89007568359375, Neurons: 11, Grad norm: 1.562e+02\n",
      "Epoch 8313, Loss: 463.8540954589844, Neurons: 11, Grad norm: 1.981e+02\n",
      "Epoch 8314, Loss: 463.81927490234375, Neurons: 11, Grad norm: 2.259e+02\n",
      "Epoch 8315, Loss: 463.7843933105469, Neurons: 11, Grad norm: 2.066e+02\n",
      "Epoch 8316, Loss: 463.7464904785156, Neurons: 11, Grad norm: 1.290e+02\n",
      "Epoch 8317, Loss: 463.7056884765625, Neurons: 11, Grad norm: 1.222e+01\n",
      "Epoch 8318, Loss: 463.6671447753906, Neurons: 11, Grad norm: 1.001e+02\n",
      "Epoch 8319, Loss: 463.633544921875, Neurons: 11, Grad norm: 1.600e+02\n",
      "Epoch 8320, Loss: 463.6011962890625, Neurons: 11, Grad norm: 1.422e+02\n",
      "Epoch 8321, Loss: 463.5652770996094, Neurons: 11, Grad norm: 6.071e+01\n",
      "Epoch 8322, Loss: 463.527587890625, Neurons: 11, Grad norm: 4.634e+01\n",
      "Epoch 8323, Loss: 463.4927978515625, Neurons: 11, Grad norm: 1.162e+02\n",
      "Epoch 8324, Loss: 463.4606018066406, Neurons: 11, Grad norm: 1.214e+02\n",
      "Epoch 8325, Loss: 463.42669677734375, Neurons: 11, Grad norm: 5.902e+01\n",
      "Epoch 8326, Loss: 463.3907470703125, Neurons: 11, Grad norm: 2.924e+01\n",
      "Epoch 8327, Loss: 463.3564758300781, Neurons: 11, Grad norm: 9.300e+01\n",
      "Epoch 8328, Loss: 463.3241882324219, Neurons: 11, Grad norm: 9.711e+01\n",
      "Epoch 8329, Loss: 463.2909240722656, Neurons: 11, Grad norm: 4.744e+01\n",
      "Epoch 8330, Loss: 463.25628662109375, Neurons: 11, Grad norm: 2.821e+01\n",
      "Epoch 8331, Loss: 463.2227783203125, Neurons: 11, Grad norm: 7.660e+01\n",
      "Epoch 8332, Loss: 463.190673828125, Neurons: 11, Grad norm: 7.820e+01\n",
      "Epoch 8333, Loss: 463.15777587890625, Neurons: 11, Grad norm: 3.213e+01\n",
      "Epoch 8334, Loss: 463.12408447265625, Neurons: 11, Grad norm: 2.812e+01\n",
      "Epoch 8335, Loss: 463.0914001464844, Neurons: 11, Grad norm: 6.627e+01\n",
      "Epoch 8336, Loss: 463.0594787597656, Neurons: 11, Grad norm: 6.020e+01\n",
      "Epoch 8337, Loss: 463.0269470214844, Neurons: 11, Grad norm: 2.170e+01\n",
      "Epoch 8338, Loss: 462.99407958984375, Neurons: 11, Grad norm: 2.982e+01\n",
      "Epoch 8339, Loss: 462.9618835449219, Neurons: 11, Grad norm: 5.493e+01\n",
      "Epoch 8340, Loss: 462.93023681640625, Neurons: 11, Grad norm: 4.750e+01\n",
      "Epoch 8341, Loss: 462.8981018066406, Neurons: 11, Grad norm: 1.251e+01\n",
      "Epoch 8342, Loss: 462.8658752441406, Neurons: 11, Grad norm: 2.782e+01\n",
      "Epoch 8343, Loss: 462.83428955078125, Neurons: 11, Grad norm: 4.715e+01\n",
      "Epoch 8344, Loss: 462.8028869628906, Neurons: 11, Grad norm: 3.561e+01\n",
      "Epoch 8345, Loss: 462.7711486816406, Neurons: 11, Grad norm: 9.064e+00\n",
      "Epoch 8346, Loss: 462.739501953125, Neurons: 11, Grad norm: 2.676e+01\n",
      "Epoch 8347, Loss: 462.7082824707031, Neurons: 11, Grad norm: 3.801e+01\n",
      "Epoch 8348, Loss: 462.67718505859375, Neurons: 11, Grad norm: 2.878e+01\n",
      "Epoch 8349, Loss: 462.6458740234375, Neurons: 11, Grad norm: 7.105e+00\n",
      "Epoch 8349, Test loss: 459.04278564453125\n",
      "Epoch 8350, Loss: 462.61474609375, Neurons: 11, Grad norm: 2.255e+01\n",
      "Epoch 8351, Loss: 462.5838928222656, Neurons: 11, Grad norm: 3.241e+01\n",
      "Epoch 8352, Loss: 462.5531921386719, Neurons: 11, Grad norm: 2.199e+01\n",
      "Epoch 8353, Loss: 462.5223388671875, Neurons: 11, Grad norm: 7.031e+00\n",
      "Epoch 8354, Loss: 462.49163818359375, Neurons: 11, Grad norm: 2.032e+01\n",
      "Epoch 8355, Loss: 462.4611511230469, Neurons: 11, Grad norm: 2.573e+01\n",
      "Epoch 8356, Loss: 462.43072509765625, Neurons: 11, Grad norm: 1.922e+01\n",
      "Epoch 8357, Loss: 462.40032958984375, Neurons: 11, Grad norm: 6.887e+00\n",
      "Epoch 8358, Loss: 462.3700256347656, Neurons: 11, Grad norm: 1.594e+01\n",
      "Epoch 8359, Loss: 462.3398742675781, Neurons: 11, Grad norm: 2.233e+01\n",
      "Epoch 8360, Loss: 462.30987548828125, Neurons: 11, Grad norm: 1.555e+01\n",
      "Epoch 8361, Loss: 462.27984619140625, Neurons: 11, Grad norm: 7.033e+00\n",
      "Epoch 8362, Loss: 462.24993896484375, Neurons: 11, Grad norm: 1.406e+01\n",
      "Epoch 8363, Loss: 462.2201843261719, Neurons: 11, Grad norm: 1.769e+01\n",
      "Epoch 8364, Loss: 462.19049072265625, Neurons: 11, Grad norm: 1.479e+01\n",
      "Epoch 8365, Loss: 462.160888671875, Neurons: 11, Grad norm: 6.935e+00\n",
      "Epoch 8366, Loss: 462.13128662109375, Neurons: 11, Grad norm: 1.056e+01\n",
      "Epoch 8367, Loss: 462.1018981933594, Neurons: 11, Grad norm: 1.575e+01\n",
      "Epoch 8368, Loss: 462.0725402832031, Neurons: 11, Grad norm: 1.244e+01\n",
      "Epoch 8369, Loss: 462.04327392578125, Neurons: 11, Grad norm: 7.588e+00\n",
      "Epoch 8370, Loss: 462.01409912109375, Neurons: 11, Grad norm: 9.341e+00\n",
      "Epoch 8371, Loss: 461.98504638671875, Neurons: 11, Grad norm: 1.226e+01\n",
      "Epoch 8372, Loss: 461.9560241699219, Neurons: 11, Grad norm: 1.233e+01\n",
      "Epoch 8373, Loss: 461.9271240234375, Neurons: 11, Grad norm: 7.516e+00\n",
      "Epoch 8374, Loss: 461.8982849121094, Neurons: 11, Grad norm: 7.219e+00\n",
      "Epoch 8375, Loss: 461.8695983886719, Neurons: 11, Grad norm: 1.100e+01\n",
      "Epoch 8376, Loss: 461.84088134765625, Neurons: 11, Grad norm: 1.043e+01\n",
      "Epoch 8377, Loss: 461.8123779296875, Neurons: 11, Grad norm: 8.497e+00\n",
      "Epoch 8378, Loss: 461.78387451171875, Neurons: 11, Grad norm: 6.841e+00\n",
      "Epoch 8379, Loss: 461.7554931640625, Neurons: 11, Grad norm: 8.441e+00\n",
      "Epoch 8380, Loss: 461.7272033691406, Neurons: 11, Grad norm: 1.025e+01\n",
      "Epoch 8381, Loss: 461.698974609375, Neurons: 11, Grad norm: 8.070e+00\n",
      "Epoch 8382, Loss: 461.6707763671875, Neurons: 11, Grad norm: 6.743e+00\n",
      "Epoch 8383, Loss: 461.6427917480469, Neurons: 11, Grad norm: 7.720e+00\n",
      "Epoch 8384, Loss: 461.6147766113281, Neurons: 11, Grad norm: 8.360e+00\n",
      "Epoch 8385, Loss: 461.5868835449219, Neurons: 11, Grad norm: 8.627e+00\n",
      "Epoch 8386, Loss: 461.55908203125, Neurons: 11, Grad norm: 6.731e+00\n",
      "Epoch 8387, Loss: 461.5313415527344, Neurons: 11, Grad norm: 6.617e+00\n",
      "Epoch 8388, Loss: 461.5036926269531, Neurons: 11, Grad norm: 8.054e+00\n",
      "Epoch 8389, Loss: 461.47613525390625, Neurons: 11, Grad norm: 7.687e+00\n",
      "Epoch 8390, Loss: 461.4485778808594, Neurons: 11, Grad norm: 7.387e+00\n",
      "Epoch 8391, Loss: 461.4211730957031, Neurons: 11, Grad norm: 6.504e+00\n",
      "Epoch 8392, Loss: 461.3938903808594, Neurons: 11, Grad norm: 6.756e+00\n",
      "Epoch 8393, Loss: 461.36669921875, Neurons: 11, Grad norm: 7.739e+00\n",
      "Epoch 8394, Loss: 461.3394775390625, Neurons: 11, Grad norm: 7.008e+00\n",
      "Epoch 8395, Loss: 461.3123779296875, Neurons: 11, Grad norm: 6.762e+00\n",
      "Epoch 8396, Loss: 461.285400390625, Neurons: 11, Grad norm: 6.552e+00\n",
      "Epoch 8397, Loss: 461.25848388671875, Neurons: 11, Grad norm: 6.674e+00\n",
      "Epoch 8398, Loss: 461.2315979003906, Neurons: 11, Grad norm: 7.240e+00\n",
      "Epoch 8399, Loss: 461.2048034667969, Neurons: 11, Grad norm: 6.593e+00\n",
      "Epoch 8399, Test loss: 457.4405212402344\n",
      "Epoch 8400, Loss: 461.1781005859375, Neurons: 11, Grad norm: 6.487e+00\n",
      "Epoch 8401, Loss: 461.1514892578125, Neurons: 11, Grad norm: 6.569e+00\n",
      "Epoch 8402, Loss: 461.125, Neurons: 11, Grad norm: 6.549e+00\n",
      "Epoch 8403, Loss: 461.09844970703125, Neurons: 11, Grad norm: 6.896e+00\n",
      "Epoch 8404, Loss: 461.07208251953125, Neurons: 11, Grad norm: 6.407e+00\n",
      "Epoch 8405, Loss: 461.0457458496094, Neurons: 11, Grad norm: 6.379e+00\n",
      "Epoch 8406, Loss: 461.01953125, Neurons: 11, Grad norm: 6.499e+00\n",
      "Epoch 8407, Loss: 460.9932861328125, Neurons: 11, Grad norm: 6.413e+00\n",
      "Epoch 8408, Loss: 460.9671936035156, Neurons: 11, Grad norm: 6.660e+00\n",
      "Epoch 8409, Loss: 460.9411926269531, Neurons: 11, Grad norm: 6.318e+00\n",
      "Epoch 8410, Loss: 460.915283203125, Neurons: 11, Grad norm: 6.315e+00\n",
      "Epoch 8411, Loss: 460.8893737792969, Neurons: 11, Grad norm: 6.416e+00\n",
      "Epoch 8412, Loss: 460.86358642578125, Neurons: 11, Grad norm: 6.317e+00\n",
      "Epoch 8413, Loss: 460.837890625, Neurons: 11, Grad norm: 6.521e+00\n",
      "Epoch 8414, Loss: 460.81219482421875, Neurons: 11, Grad norm: 6.260e+00\n",
      "Epoch 8415, Loss: 460.7865905761719, Neurons: 11, Grad norm: 6.273e+00\n",
      "Epoch 8416, Loss: 460.7610778808594, Neurons: 11, Grad norm: 6.326e+00\n",
      "Epoch 8417, Loss: 460.7356262207031, Neurons: 11, Grad norm: 6.242e+00\n",
      "Epoch 8418, Loss: 460.7102966308594, Neurons: 11, Grad norm: 6.405e+00\n",
      "Epoch 8419, Loss: 460.68499755859375, Neurons: 11, Grad norm: 6.201e+00\n",
      "Epoch 8420, Loss: 460.6597900390625, Neurons: 11, Grad norm: 6.220e+00\n",
      "Epoch 8421, Loss: 460.6346435546875, Neurons: 11, Grad norm: 6.254e+00\n",
      "Epoch 8422, Loss: 460.6095275878906, Neurons: 11, Grad norm: 6.178e+00\n",
      "Epoch 8423, Loss: 460.5845031738281, Neurons: 11, Grad norm: 6.311e+00\n",
      "Epoch 8424, Loss: 460.5596008300781, Neurons: 11, Grad norm: 6.149e+00\n",
      "Epoch 8425, Loss: 460.5346984863281, Neurons: 11, Grad norm: 6.179e+00\n",
      "Epoch 8426, Loss: 460.5098876953125, Neurons: 11, Grad norm: 6.165e+00\n",
      "Epoch 8427, Loss: 460.4851379394531, Neurons: 11, Grad norm: 6.118e+00\n",
      "Epoch 8428, Loss: 460.4604797363281, Neurons: 11, Grad norm: 6.189e+00\n",
      "Epoch 8429, Loss: 460.4358825683594, Neurons: 11, Grad norm: 6.099e+00\n",
      "Epoch 8430, Loss: 460.4113464355469, Neurons: 11, Grad norm: 6.125e+00\n",
      "Epoch 8431, Loss: 460.38690185546875, Neurons: 11, Grad norm: 6.107e+00\n",
      "Epoch 8432, Loss: 460.36248779296875, Neurons: 11, Grad norm: 6.072e+00\n",
      "Epoch 8433, Loss: 460.338134765625, Neurons: 11, Grad norm: 6.129e+00\n",
      "Epoch 8434, Loss: 460.3138732910156, Neurons: 11, Grad norm: 6.050e+00\n",
      "Epoch 8435, Loss: 460.2897033691406, Neurons: 11, Grad norm: 6.092e+00\n",
      "Epoch 8436, Loss: 460.2655944824219, Neurons: 11, Grad norm: 6.042e+00\n",
      "Epoch 8437, Loss: 460.2414855957031, Neurons: 11, Grad norm: 6.029e+00\n",
      "Epoch 8438, Loss: 460.2174987792969, Neurons: 11, Grad norm: 6.077e+00\n",
      "Epoch 8439, Loss: 460.19354248046875, Neurons: 11, Grad norm: 6.002e+00\n",
      "Epoch 8440, Loss: 460.169677734375, Neurons: 11, Grad norm: 6.073e+00\n",
      "Epoch 8441, Loss: 460.1458740234375, Neurons: 11, Grad norm: 5.984e+00\n",
      "Epoch 8442, Loss: 460.12213134765625, Neurons: 11, Grad norm: 5.998e+00\n",
      "Epoch 8443, Loss: 460.0984802246094, Neurons: 11, Grad norm: 5.996e+00\n",
      "Epoch 8444, Loss: 460.0748291015625, Neurons: 11, Grad norm: 5.955e+00\n",
      "Epoch 8445, Loss: 460.0513000488281, Neurons: 11, Grad norm: 6.014e+00\n",
      "Epoch 8446, Loss: 460.0278015136719, Neurons: 11, Grad norm: 5.935e+00\n",
      "Epoch 8447, Loss: 460.0044250488281, Neurons: 11, Grad norm: 5.972e+00\n",
      "Epoch 8448, Loss: 459.9810485839844, Neurons: 11, Grad norm: 5.928e+00\n",
      "Epoch 8449, Loss: 459.9577941894531, Neurons: 11, Grad norm: 5.918e+00\n",
      "Epoch 8449, Test loss: 456.0689697265625\n",
      "Epoch 8450, Loss: 459.9345397949219, Neurons: 11, Grad norm: 5.951e+00\n",
      "Epoch 8451, Loss: 459.911376953125, Neurons: 11, Grad norm: 5.889e+00\n",
      "Epoch 8452, Loss: 459.8882751464844, Neurons: 11, Grad norm: 5.978e+00\n",
      "Epoch 8453, Loss: 459.86517333984375, Neurons: 11, Grad norm: 5.872e+00\n",
      "Epoch 8454, Loss: 459.8421936035156, Neurons: 11, Grad norm: 5.935e+00\n",
      "Epoch 8455, Loss: 459.8193359375, Neurons: 11, Grad norm: 5.855e+00\n",
      "Epoch 8456, Loss: 459.7964782714844, Neurons: 11, Grad norm: 5.859e+00\n",
      "Epoch 8457, Loss: 459.7736511230469, Neurons: 11, Grad norm: 5.885e+00\n",
      "Epoch 8458, Loss: 459.7509460449219, Neurons: 11, Grad norm: 5.826e+00\n",
      "Epoch 8459, Loss: 459.7283020019531, Neurons: 11, Grad norm: 5.897e+00\n",
      "Epoch 8460, Loss: 459.7056884765625, Neurons: 11, Grad norm: 5.808e+00\n",
      "Epoch 8461, Loss: 459.6830749511719, Neurons: 11, Grad norm: 5.850e+00\n",
      "Epoch 8462, Loss: 459.66058349609375, Neurons: 11, Grad norm: 5.796e+00\n",
      "Epoch 8463, Loss: 459.6381530761719, Neurons: 11, Grad norm: 5.794e+00\n",
      "Epoch 8464, Loss: 459.61578369140625, Neurons: 11, Grad norm: 5.808e+00\n",
      "Epoch 8465, Loss: 459.59344482421875, Neurons: 11, Grad norm: 5.764e+00\n",
      "Epoch 8466, Loss: 459.5711975097656, Neurons: 11, Grad norm: 5.806e+00\n",
      "Epoch 8467, Loss: 459.5489807128906, Neurons: 11, Grad norm: 5.748e+00\n",
      "Epoch 8468, Loss: 459.52679443359375, Neurons: 11, Grad norm: 5.764e+00\n",
      "Epoch 8469, Loss: 459.5047302246094, Neurons: 11, Grad norm: 5.748e+00\n",
      "Epoch 8470, Loss: 459.4826965332031, Neurons: 11, Grad norm: 5.723e+00\n",
      "Epoch 8471, Loss: 459.4607238769531, Neurons: 11, Grad norm: 5.757e+00\n",
      "Epoch 8472, Loss: 459.43878173828125, Neurons: 11, Grad norm: 5.703e+00\n",
      "Epoch 8473, Loss: 459.4169921875, Neurons: 11, Grad norm: 5.732e+00\n",
      "Epoch 8474, Loss: 459.39520263671875, Neurons: 11, Grad norm: 5.695e+00\n",
      "Epoch 8475, Loss: 459.3734436035156, Neurons: 11, Grad norm: 5.686e+00\n",
      "Epoch 8476, Loss: 459.3517761230469, Neurons: 11, Grad norm: 5.707e+00\n",
      "Epoch 8477, Loss: 459.33013916015625, Neurons: 11, Grad norm: 5.660e+00\n",
      "Epoch 8478, Loss: 459.30853271484375, Neurons: 11, Grad norm: 5.715e+00\n",
      "Epoch 8479, Loss: 459.28704833984375, Neurons: 11, Grad norm: 5.643e+00\n",
      "Epoch 8480, Loss: 459.2655944824219, Neurons: 11, Grad norm: 5.695e+00\n",
      "Epoch 8481, Loss: 459.244140625, Neurons: 11, Grad norm: 5.627e+00\n",
      "Epoch 8482, Loss: 459.2227783203125, Neurons: 11, Grad norm: 5.645e+00\n",
      "Epoch 8483, Loss: 459.20147705078125, Neurons: 11, Grad norm: 5.624e+00\n",
      "Epoch 8484, Loss: 459.18023681640625, Neurons: 11, Grad norm: 5.606e+00\n",
      "Epoch 8485, Loss: 459.1590881347656, Neurons: 11, Grad norm: 5.632e+00\n",
      "Epoch 8486, Loss: 459.137939453125, Neurons: 11, Grad norm: 5.585e+00\n",
      "Epoch 8487, Loss: 459.11688232421875, Neurons: 11, Grad norm: 5.631e+00\n",
      "Epoch 8488, Loss: 459.0957946777344, Neurons: 11, Grad norm: 5.568e+00\n",
      "Epoch 8489, Loss: 459.07489013671875, Neurons: 11, Grad norm: 5.609e+00\n",
      "Epoch 8490, Loss: 459.0539245605469, Neurons: 11, Grad norm: 5.552e+00\n",
      "Epoch 8491, Loss: 459.0330810546875, Neurons: 11, Grad norm: 5.589e+00\n",
      "Epoch 8492, Loss: 459.0122985839844, Neurons: 11, Grad norm: 5.537e+00\n",
      "Epoch 8493, Loss: 458.9914855957031, Neurons: 11, Grad norm: 5.560e+00\n",
      "Epoch 8494, Loss: 458.9707946777344, Neurons: 11, Grad norm: 5.524e+00\n",
      "Epoch 8495, Loss: 458.9501953125, Neurons: 11, Grad norm: 5.532e+00\n",
      "Epoch 8496, Loss: 458.9295349121094, Neurons: 11, Grad norm: 5.517e+00\n",
      "Epoch 8497, Loss: 458.90899658203125, Neurons: 11, Grad norm: 5.500e+00\n",
      "Epoch 8498, Loss: 458.88848876953125, Neurons: 11, Grad norm: 5.533e+00\n",
      "Epoch 8499, Loss: 458.8680419921875, Neurons: 11, Grad norm: 5.480e+00\n",
      "Epoch 8499, Test loss: 454.8868713378906\n",
      "Epoch 8500, Loss: 458.8476867675781, Neurons: 11, Grad norm: 5.550e+00\n",
      "Epoch 8501, Loss: 458.8273010253906, Neurons: 11, Grad norm: 5.469e+00\n",
      "Epoch 8502, Loss: 458.8069763183594, Neurons: 11, Grad norm: 5.544e+00\n",
      "Epoch 8503, Loss: 458.7867736816406, Neurons: 11, Grad norm: 5.452e+00\n",
      "Epoch 8504, Loss: 458.7666015625, Neurons: 11, Grad norm: 5.520e+00\n",
      "Epoch 8505, Loss: 458.7464294433594, Neurons: 11, Grad norm: 5.435e+00\n",
      "Epoch 8506, Loss: 458.7263488769531, Neurons: 11, Grad norm: 5.491e+00\n",
      "Epoch 8507, Loss: 458.706298828125, Neurons: 11, Grad norm: 5.418e+00\n",
      "Epoch 8508, Loss: 458.686279296875, Neurons: 11, Grad norm: 5.467e+00\n",
      "Epoch 8509, Loss: 458.6663818359375, Neurons: 11, Grad norm: 5.402e+00\n",
      "Epoch 8510, Loss: 458.646484375, Neurons: 11, Grad norm: 5.428e+00\n",
      "Epoch 8511, Loss: 458.62664794921875, Neurons: 11, Grad norm: 5.390e+00\n",
      "Epoch 8512, Loss: 458.6068420410156, Neurons: 11, Grad norm: 5.398e+00\n",
      "Epoch 8513, Loss: 458.58709716796875, Neurons: 11, Grad norm: 5.380e+00\n",
      "Epoch 8514, Loss: 458.5673828125, Neurons: 11, Grad norm: 5.376e+00\n",
      "Epoch 8515, Loss: 458.5476989746094, Neurons: 11, Grad norm: 5.369e+00\n",
      "Epoch 8516, Loss: 458.52813720703125, Neurons: 11, Grad norm: 5.354e+00\n",
      "Epoch 8517, Loss: 458.508544921875, Neurons: 11, Grad norm: 5.371e+00\n",
      "Epoch 8518, Loss: 458.48907470703125, Neurons: 11, Grad norm: 5.334e+00\n",
      "Epoch 8519, Loss: 458.4695739746094, Neurons: 11, Grad norm: 5.402e+00\n",
      "Epoch 8520, Loss: 458.4501953125, Neurons: 11, Grad norm: 5.337e+00\n",
      "Epoch 8521, Loss: 458.43084716796875, Neurons: 11, Grad norm: 5.483e+00\n",
      "Epoch 8522, Loss: 458.4115295410156, Neurons: 11, Grad norm: 5.386e+00\n",
      "Epoch 8523, Loss: 458.3923034667969, Neurons: 11, Grad norm: 5.619e+00\n",
      "Epoch 8524, Loss: 458.373046875, Neurons: 11, Grad norm: 5.496e+00\n",
      "Epoch 8525, Loss: 458.3538513183594, Neurons: 11, Grad norm: 5.835e+00\n",
      "Epoch 8526, Loss: 458.3347473144531, Neurons: 11, Grad norm: 5.713e+00\n",
      "Epoch 8527, Loss: 458.3155822753906, Neurons: 11, Grad norm: 6.213e+00\n",
      "Epoch 8528, Loss: 458.2966003417969, Neurons: 11, Grad norm: 6.164e+00\n",
      "Epoch 8529, Loss: 458.27764892578125, Neurons: 11, Grad norm: 6.991e+00\n",
      "Epoch 8530, Loss: 458.2586975097656, Neurons: 11, Grad norm: 7.173e+00\n",
      "Epoch 8531, Loss: 458.2397766113281, Neurons: 11, Grad norm: 8.508e+00\n",
      "Epoch 8532, Loss: 458.220947265625, Neurons: 11, Grad norm: 9.193e+00\n",
      "Epoch 8533, Loss: 458.20208740234375, Neurons: 11, Grad norm: 1.141e+01\n",
      "Epoch 8534, Loss: 458.183349609375, Neurons: 11, Grad norm: 1.314e+01\n",
      "Epoch 8535, Loss: 458.1646423339844, Neurons: 11, Grad norm: 1.684e+01\n",
      "Epoch 8536, Loss: 458.14599609375, Neurons: 11, Grad norm: 2.039e+01\n",
      "Epoch 8537, Loss: 458.12738037109375, Neurons: 11, Grad norm: 2.650e+01\n",
      "Epoch 8538, Loss: 458.10888671875, Neurons: 11, Grad norm: 3.311e+01\n",
      "Epoch 8539, Loss: 458.09039306640625, Neurons: 11, Grad norm: 4.320e+01\n",
      "Epoch 8540, Loss: 458.0719909667969, Neurons: 11, Grad norm: 5.493e+01\n",
      "Epoch 8541, Loss: 458.0538024902344, Neurons: 11, Grad norm: 7.138e+01\n",
      "Epoch 8542, Loss: 458.0357360839844, Neurons: 11, Grad norm: 9.058e+01\n",
      "Epoch 8543, Loss: 458.0179443359375, Neurons: 11, Grad norm: 1.148e+02\n",
      "Epoch 8544, Loss: 458.00054931640625, Neurons: 11, Grad norm: 1.401e+02\n",
      "Epoch 8545, Loss: 457.9834899902344, Neurons: 11, Grad norm: 1.642e+02\n",
      "Epoch 8546, Loss: 457.9666748046875, Neurons: 11, Grad norm: 1.767e+02\n",
      "Epoch 8547, Loss: 457.9495849609375, Neurons: 11, Grad norm: 1.691e+02\n",
      "Epoch 8548, Loss: 457.93157958984375, Neurons: 11, Grad norm: 1.327e+02\n",
      "Epoch 8549, Loss: 457.9123840332031, Neurons: 11, Grad norm: 7.229e+01\n",
      "Epoch 8549, Test loss: 453.8365173339844\n",
      "Epoch 8550, Loss: 457.8929748535156, Neurons: 11, Grad norm: 5.063e+00\n",
      "Epoch 8551, Loss: 457.8748779296875, Neurons: 11, Grad norm: 6.448e+01\n",
      "Epoch 8552, Loss: 457.85833740234375, Neurons: 11, Grad norm: 1.077e+02\n",
      "Epoch 8553, Loss: 457.8423767089844, Neurons: 11, Grad norm: 1.184e+02\n",
      "Epoch 8554, Loss: 457.82568359375, Neurons: 11, Grad norm: 9.693e+01\n",
      "Epoch 8555, Loss: 457.8079833984375, Neurons: 11, Grad norm: 4.869e+01\n",
      "Epoch 8556, Loss: 457.7898864746094, Neurons: 11, Grad norm: 1.002e+01\n",
      "Epoch 8557, Loss: 457.7726745605469, Neurons: 11, Grad norm: 5.862e+01\n",
      "Epoch 8558, Loss: 457.7563781738281, Neurons: 11, Grad norm: 8.505e+01\n",
      "Epoch 8559, Loss: 457.740234375, Neurons: 11, Grad norm: 8.368e+01\n",
      "Epoch 8560, Loss: 457.7234802246094, Neurons: 11, Grad norm: 5.552e+01\n",
      "Epoch 8561, Loss: 457.70623779296875, Neurons: 11, Grad norm: 1.388e+01\n",
      "Epoch 8562, Loss: 457.6891784667969, Neurons: 11, Grad norm: 3.054e+01\n",
      "Epoch 8563, Loss: 457.6727294921875, Neurons: 11, Grad norm: 5.867e+01\n",
      "Epoch 8564, Loss: 457.6565856933594, Neurons: 11, Grad norm: 6.629e+01\n",
      "Epoch 8565, Loss: 457.6403503417969, Neurons: 11, Grad norm: 5.094e+01\n",
      "Epoch 8566, Loss: 457.6236877441406, Neurons: 11, Grad norm: 2.168e+01\n",
      "Epoch 8567, Loss: 457.60699462890625, Neurons: 11, Grad norm: 1.403e+01\n",
      "Epoch 8568, Loss: 457.590576171875, Neurons: 11, Grad norm: 3.927e+01\n",
      "Epoch 8569, Loss: 457.5744934082031, Neurons: 11, Grad norm: 5.058e+01\n",
      "Epoch 8570, Loss: 457.5584411621094, Neurons: 11, Grad norm: 4.384e+01\n",
      "Epoch 8571, Loss: 457.5420837402344, Neurons: 11, Grad norm: 2.459e+01\n",
      "Epoch 8572, Loss: 457.5257873535156, Neurons: 11, Grad norm: 5.263e+00\n",
      "Epoch 8573, Loss: 457.50958251953125, Neurons: 11, Grad norm: 2.471e+01\n",
      "Epoch 8574, Loss: 457.49359130859375, Neurons: 11, Grad norm: 3.760e+01\n",
      "Epoch 8575, Loss: 457.4776916503906, Neurons: 11, Grad norm: 3.675e+01\n",
      "Epoch 8576, Loss: 457.4616394042969, Neurons: 11, Grad norm: 2.538e+01\n",
      "Epoch 8577, Loss: 457.4455871582031, Neurons: 11, Grad norm: 7.673e+00\n",
      "Epoch 8578, Loss: 457.4295959472656, Neurons: 11, Grad norm: 1.314e+01\n",
      "Epoch 8579, Loss: 457.4137268066406, Neurons: 11, Grad norm: 2.603e+01\n",
      "Epoch 8580, Loss: 457.3979797363281, Neurons: 11, Grad norm: 2.947e+01\n",
      "Epoch 8581, Loss: 457.3822021484375, Neurons: 11, Grad norm: 2.454e+01\n",
      "Epoch 8582, Loss: 457.36639404296875, Neurons: 11, Grad norm: 1.243e+01\n",
      "Epoch 8583, Loss: 457.3505859375, Neurons: 11, Grad norm: 5.432e+00\n",
      "Epoch 8584, Loss: 457.33489990234375, Neurons: 11, Grad norm: 1.584e+01\n",
      "Epoch 8585, Loss: 457.3192443847656, Neurons: 11, Grad norm: 2.168e+01\n",
      "Epoch 8586, Loss: 457.30364990234375, Neurons: 11, Grad norm: 2.165e+01\n",
      "Epoch 8587, Loss: 457.2879943847656, Neurons: 11, Grad norm: 1.497e+01\n",
      "Epoch 8588, Loss: 457.2724914550781, Neurons: 11, Grad norm: 6.594e+00\n",
      "Epoch 8589, Loss: 457.25689697265625, Neurons: 11, Grad norm: 7.761e+00\n",
      "Epoch 8590, Loss: 457.24139404296875, Neurons: 11, Grad norm: 1.414e+01\n",
      "Epoch 8591, Loss: 457.2259826660156, Neurons: 11, Grad norm: 1.743e+01\n",
      "Epoch 8592, Loss: 457.2106018066406, Neurons: 11, Grad norm: 1.525e+01\n",
      "Epoch 8593, Loss: 457.1951904296875, Neurons: 11, Grad norm: 1.031e+01\n",
      "Epoch 8594, Loss: 457.1797790527344, Neurons: 11, Grad norm: 4.876e+00\n",
      "Epoch 8595, Loss: 457.1644287109375, Neurons: 11, Grad norm: 7.432e+00\n",
      "Epoch 8596, Loss: 457.1492004394531, Neurons: 11, Grad norm: 1.209e+01\n",
      "Epoch 8597, Loss: 457.1340026855469, Neurons: 11, Grad norm: 1.325e+01\n",
      "Epoch 8598, Loss: 457.1187438964844, Neurons: 11, Grad norm: 1.191e+01\n",
      "Epoch 8599, Loss: 457.10357666015625, Neurons: 11, Grad norm: 7.742e+00\n",
      "Epoch 8599, Test loss: 453.01739501953125\n",
      "Epoch 8600, Loss: 457.08837890625, Neurons: 11, Grad norm: 4.794e+00\n",
      "Epoch 8601, Loss: 457.07330322265625, Neurons: 11, Grad norm: 6.705e+00\n",
      "Epoch 8602, Loss: 457.0582275390625, Neurons: 11, Grad norm: 9.319e+00\n",
      "Epoch 8603, Loss: 457.0431823730469, Neurons: 11, Grad norm: 1.076e+01\n",
      "Epoch 8604, Loss: 457.02813720703125, Neurons: 11, Grad norm: 9.376e+00\n",
      "Epoch 8605, Loss: 457.0131530761719, Neurons: 11, Grad norm: 7.194e+00\n",
      "Epoch 8606, Loss: 456.9981994628906, Neurons: 11, Grad norm: 4.808e+00\n",
      "Epoch 8607, Loss: 456.9832763671875, Neurons: 11, Grad norm: 5.246e+00\n",
      "Epoch 8608, Loss: 456.9683837890625, Neurons: 11, Grad norm: 7.353e+00\n",
      "Epoch 8609, Loss: 456.9534912109375, Neurons: 11, Grad norm: 8.156e+00\n",
      "Epoch 8610, Loss: 456.9386901855469, Neurons: 11, Grad norm: 8.179e+00\n",
      "Epoch 8611, Loss: 456.9239501953125, Neurons: 11, Grad norm: 6.554e+00\n",
      "Epoch 8612, Loss: 456.9091796875, Neurons: 11, Grad norm: 5.219e+00\n",
      "Epoch 8613, Loss: 456.8944396972656, Neurons: 11, Grad norm: 4.689e+00\n",
      "Epoch 8614, Loss: 456.8797302246094, Neurons: 11, Grad norm: 5.372e+00\n",
      "Epoch 8615, Loss: 456.86505126953125, Neurons: 11, Grad norm: 6.537e+00\n",
      "Epoch 8616, Loss: 456.85040283203125, Neurons: 11, Grad norm: 6.630e+00\n",
      "Epoch 8617, Loss: 456.8357849121094, Neurons: 11, Grad norm: 6.448e+00\n",
      "Epoch 8618, Loss: 456.82122802734375, Neurons: 11, Grad norm: 5.371e+00\n",
      "Epoch 8619, Loss: 456.80670166015625, Neurons: 11, Grad norm: 4.778e+00\n",
      "Epoch 8620, Loss: 456.79217529296875, Neurons: 11, Grad norm: 4.672e+00\n",
      "Epoch 8621, Loss: 456.7776794433594, Neurons: 11, Grad norm: 5.013e+00\n",
      "Epoch 8622, Loss: 456.76318359375, Neurons: 11, Grad norm: 5.631e+00\n",
      "Epoch 8623, Loss: 456.748779296875, Neurons: 11, Grad norm: 5.547e+00\n",
      "Epoch 8624, Loss: 456.73443603515625, Neurons: 11, Grad norm: 5.479e+00\n",
      "Epoch 8625, Loss: 456.7200927734375, Neurons: 11, Grad norm: 4.890e+00\n",
      "Epoch 8626, Loss: 456.70574951171875, Neurons: 11, Grad norm: 4.643e+00\n",
      "Epoch 8627, Loss: 456.6913757324219, Neurons: 11, Grad norm: 4.604e+00\n",
      "Epoch 8628, Loss: 456.67718505859375, Neurons: 11, Grad norm: 4.751e+00\n",
      "Epoch 8629, Loss: 456.66290283203125, Neurons: 11, Grad norm: 5.124e+00\n",
      "Epoch 8630, Loss: 456.648681640625, Neurons: 11, Grad norm: 5.079e+00\n",
      "Epoch 8631, Loss: 456.6344909667969, Neurons: 11, Grad norm: 5.145e+00\n",
      "Epoch 8632, Loss: 456.6203308105469, Neurons: 11, Grad norm: 4.810e+00\n",
      "Epoch 8633, Loss: 456.606201171875, Neurons: 11, Grad norm: 4.677e+00\n",
      "Epoch 8634, Loss: 456.5921325683594, Neurons: 11, Grad norm: 4.521e+00\n",
      "Epoch 8635, Loss: 456.5780944824219, Neurons: 11, Grad norm: 4.539e+00\n",
      "Epoch 8636, Loss: 456.5639953613281, Neurons: 11, Grad norm: 4.719e+00\n",
      "Epoch 8637, Loss: 456.54998779296875, Neurons: 11, Grad norm: 4.740e+00\n",
      "Epoch 8638, Loss: 456.5359802246094, Neurons: 11, Grad norm: 4.872e+00\n",
      "Epoch 8639, Loss: 456.52203369140625, Neurons: 11, Grad norm: 4.699e+00\n",
      "Epoch 8640, Loss: 456.5081481933594, Neurons: 11, Grad norm: 4.672e+00\n",
      "Epoch 8641, Loss: 456.4942932128906, Neurons: 11, Grad norm: 4.511e+00\n",
      "Epoch 8642, Loss: 456.4803771972656, Neurons: 11, Grad norm: 4.485e+00\n",
      "Epoch 8643, Loss: 456.4665832519531, Neurons: 11, Grad norm: 4.526e+00\n",
      "Epoch 8644, Loss: 456.4527282714844, Neurons: 11, Grad norm: 4.549e+00\n",
      "Epoch 8645, Loss: 456.4389343261719, Neurons: 11, Grad norm: 4.690e+00\n",
      "Epoch 8646, Loss: 456.4252014160156, Neurons: 11, Grad norm: 4.642e+00\n",
      "Epoch 8647, Loss: 456.4114990234375, Neurons: 11, Grad norm: 4.711e+00\n",
      "Epoch 8648, Loss: 456.3977966308594, Neurons: 11, Grad norm: 4.568e+00\n",
      "Epoch 8649, Loss: 456.38409423828125, Neurons: 11, Grad norm: 4.543e+00\n",
      "Epoch 8649, Test loss: 452.268310546875\n",
      "Epoch 8650, Loss: 456.3704528808594, Neurons: 11, Grad norm: 4.448e+00\n",
      "Epoch 8651, Loss: 456.3568420410156, Neurons: 11, Grad norm: 4.439e+00\n",
      "Epoch 8652, Loss: 456.3432312011719, Neurons: 11, Grad norm: 4.470e+00\n",
      "Epoch 8653, Loss: 456.3296813964844, Neurons: 11, Grad norm: 4.461e+00\n",
      "Epoch 8654, Loss: 456.3161315917969, Neurons: 11, Grad norm: 4.526e+00\n",
      "Epoch 8655, Loss: 456.3026428222656, Neurons: 11, Grad norm: 4.491e+00\n",
      "Epoch 8656, Loss: 456.28912353515625, Neurons: 11, Grad norm: 4.554e+00\n",
      "Epoch 8657, Loss: 456.27569580078125, Neurons: 11, Grad norm: 4.487e+00\n",
      "Epoch 8658, Loss: 456.2622985839844, Neurons: 11, Grad norm: 4.517e+00\n",
      "Epoch 8659, Loss: 456.2489013671875, Neurons: 11, Grad norm: 4.446e+00\n",
      "Epoch 8660, Loss: 456.2354736328125, Neurons: 11, Grad norm: 4.461e+00\n",
      "Epoch 8661, Loss: 456.2221984863281, Neurons: 11, Grad norm: 4.408e+00\n",
      "Epoch 8662, Loss: 456.20880126953125, Neurons: 11, Grad norm: 4.420e+00\n",
      "Epoch 8663, Loss: 456.19549560546875, Neurons: 11, Grad norm: 4.386e+00\n",
      "Epoch 8664, Loss: 456.1822814941406, Neurons: 11, Grad norm: 4.386e+00\n",
      "Epoch 8665, Loss: 456.1690368652344, Neurons: 11, Grad norm: 4.377e+00\n",
      "Epoch 8666, Loss: 456.1557922363281, Neurons: 11, Grad norm: 4.370e+00\n",
      "Epoch 8667, Loss: 456.142578125, Neurons: 11, Grad norm: 4.391e+00\n",
      "Epoch 8668, Loss: 456.1294250488281, Neurons: 11, Grad norm: 4.371e+00\n",
      "Epoch 8669, Loss: 456.1163024902344, Neurons: 11, Grad norm: 4.394e+00\n",
      "Epoch 8670, Loss: 456.1031799316406, Neurons: 11, Grad norm: 4.365e+00\n",
      "Epoch 8671, Loss: 456.090087890625, Neurons: 11, Grad norm: 4.391e+00\n",
      "Epoch 8672, Loss: 456.07708740234375, Neurons: 11, Grad norm: 4.361e+00\n",
      "Epoch 8673, Loss: 456.0639953613281, Neurons: 11, Grad norm: 4.382e+00\n",
      "Epoch 8674, Loss: 456.0509948730469, Neurons: 11, Grad norm: 4.348e+00\n",
      "Epoch 8675, Loss: 456.0379943847656, Neurons: 11, Grad norm: 4.362e+00\n",
      "Epoch 8676, Loss: 456.0250244140625, Neurons: 11, Grad norm: 4.331e+00\n",
      "Epoch 8677, Loss: 456.0120849609375, Neurons: 11, Grad norm: 4.341e+00\n",
      "Epoch 8678, Loss: 455.9991760253906, Neurons: 11, Grad norm: 4.318e+00\n",
      "Epoch 8679, Loss: 455.9862976074219, Neurons: 11, Grad norm: 4.327e+00\n",
      "Epoch 8680, Loss: 455.97344970703125, Neurons: 11, Grad norm: 4.310e+00\n",
      "Epoch 8681, Loss: 455.9606018066406, Neurons: 11, Grad norm: 4.323e+00\n",
      "Epoch 8682, Loss: 455.9477844238281, Neurons: 11, Grad norm: 4.303e+00\n",
      "Epoch 8683, Loss: 455.93499755859375, Neurons: 11, Grad norm: 4.318e+00\n",
      "Epoch 8684, Loss: 455.92218017578125, Neurons: 11, Grad norm: 4.297e+00\n",
      "Epoch 8685, Loss: 455.90948486328125, Neurons: 11, Grad norm: 4.308e+00\n",
      "Epoch 8686, Loss: 455.89678955078125, Neurons: 11, Grad norm: 4.286e+00\n",
      "Epoch 8687, Loss: 455.88409423828125, Neurons: 11, Grad norm: 4.297e+00\n",
      "Epoch 8688, Loss: 455.87139892578125, Neurons: 11, Grad norm: 4.278e+00\n",
      "Epoch 8689, Loss: 455.8587951660156, Neurons: 11, Grad norm: 4.286e+00\n",
      "Epoch 8690, Loss: 455.84613037109375, Neurons: 11, Grad norm: 4.268e+00\n",
      "Epoch 8691, Loss: 455.8335876464844, Neurons: 11, Grad norm: 4.280e+00\n",
      "Epoch 8692, Loss: 455.82098388671875, Neurons: 11, Grad norm: 4.262e+00\n",
      "Epoch 8693, Loss: 455.8084411621094, Neurons: 11, Grad norm: 4.272e+00\n",
      "Epoch 8694, Loss: 455.7958984375, Neurons: 11, Grad norm: 4.253e+00\n",
      "Epoch 8695, Loss: 455.78338623046875, Neurons: 11, Grad norm: 4.262e+00\n",
      "Epoch 8696, Loss: 455.7708740234375, Neurons: 11, Grad norm: 4.246e+00\n",
      "Epoch 8697, Loss: 455.75848388671875, Neurons: 11, Grad norm: 4.259e+00\n",
      "Epoch 8698, Loss: 455.74609375, Neurons: 11, Grad norm: 4.238e+00\n",
      "Epoch 8699, Loss: 455.73358154296875, Neurons: 11, Grad norm: 4.248e+00\n",
      "Epoch 8699, Test loss: 451.6038513183594\n",
      "Epoch 8700, Loss: 455.72119140625, Neurons: 11, Grad norm: 4.231e+00\n",
      "Epoch 8701, Loss: 455.7088928222656, Neurons: 11, Grad norm: 4.248e+00\n",
      "Epoch 8702, Loss: 455.6965026855469, Neurons: 11, Grad norm: 4.234e+00\n",
      "Epoch 8703, Loss: 455.6841735839844, Neurons: 11, Grad norm: 4.267e+00\n",
      "Epoch 8704, Loss: 455.671875, Neurons: 11, Grad norm: 4.254e+00\n",
      "Epoch 8705, Loss: 455.6596984863281, Neurons: 11, Grad norm: 4.304e+00\n",
      "Epoch 8706, Loss: 455.64739990234375, Neurons: 11, Grad norm: 4.301e+00\n",
      "Epoch 8707, Loss: 455.63519287109375, Neurons: 11, Grad norm: 4.399e+00\n",
      "Epoch 8708, Loss: 455.62298583984375, Neurons: 11, Grad norm: 4.437e+00\n",
      "Epoch 8709, Loss: 455.61077880859375, Neurons: 11, Grad norm: 4.638e+00\n",
      "Epoch 8710, Loss: 455.5986022949219, Neurons: 11, Grad norm: 4.774e+00\n",
      "Epoch 8711, Loss: 455.58648681640625, Neurons: 11, Grad norm: 5.218e+00\n",
      "Epoch 8712, Loss: 455.57440185546875, Neurons: 11, Grad norm: 5.668e+00\n",
      "Epoch 8713, Loss: 455.5622863769531, Neurons: 11, Grad norm: 6.632e+00\n",
      "Epoch 8714, Loss: 455.5502014160156, Neurons: 11, Grad norm: 7.776e+00\n",
      "Epoch 8715, Loss: 455.5381774902344, Neurons: 11, Grad norm: 9.756e+00\n",
      "Epoch 8716, Loss: 455.5261535644531, Neurons: 11, Grad norm: 1.222e+01\n",
      "Epoch 8717, Loss: 455.5141906738281, Neurons: 11, Grad norm: 1.599e+01\n",
      "Epoch 8718, Loss: 455.502197265625, Neurons: 11, Grad norm: 2.081e+01\n",
      "Epoch 8719, Loss: 455.490234375, Neurons: 11, Grad norm: 2.770e+01\n",
      "Epoch 8720, Loss: 455.4783935546875, Neurons: 11, Grad norm: 3.673e+01\n",
      "Epoch 8721, Loss: 455.466552734375, Neurons: 11, Grad norm: 4.934e+01\n",
      "Epoch 8722, Loss: 455.4548034667969, Neurons: 11, Grad norm: 6.596e+01\n",
      "Epoch 8723, Loss: 455.4432373046875, Neurons: 11, Grad norm: 8.830e+01\n",
      "Epoch 8724, Loss: 455.4319763183594, Neurons: 11, Grad norm: 1.167e+02\n",
      "Epoch 8725, Loss: 455.42108154296875, Neurons: 11, Grad norm: 1.514e+02\n",
      "Epoch 8726, Loss: 455.4107360839844, Neurons: 11, Grad norm: 1.882e+02\n",
      "Epoch 8727, Loss: 455.4010925292969, Neurons: 11, Grad norm: 2.176e+02\n",
      "Epoch 8728, Loss: 455.3913879394531, Neurons: 11, Grad norm: 2.228e+02\n",
      "Epoch 8729, Loss: 455.38043212890625, Neurons: 11, Grad norm: 1.874e+02\n",
      "Epoch 8730, Loss: 455.3670349121094, Neurons: 11, Grad norm: 1.095e+02\n",
      "Epoch 8731, Loss: 455.35247802734375, Neurons: 11, Grad norm: 9.062e+00\n",
      "Epoch 8732, Loss: 455.3396911621094, Neurons: 11, Grad norm: 8.559e+01\n",
      "Epoch 8733, Loss: 455.329833984375, Neurons: 11, Grad norm: 1.442e+02\n",
      "Epoch 8734, Loss: 455.3209533691406, Neurons: 11, Grad norm: 1.515e+02\n",
      "Epoch 8735, Loss: 455.3103942871094, Neurons: 11, Grad norm: 1.054e+02\n",
      "Epoch 8736, Loss: 455.29779052734375, Neurons: 11, Grad norm: 2.569e+01\n",
      "Epoch 8737, Loss: 455.2854309082031, Neurons: 11, Grad norm: 5.641e+01\n",
      "Epoch 8738, Loss: 455.275146484375, Neurons: 11, Grad norm: 1.086e+02\n",
      "Epoch 8739, Loss: 455.26568603515625, Neurons: 11, Grad norm: 1.139e+02\n",
      "Epoch 8740, Loss: 455.2552795410156, Neurons: 11, Grad norm: 7.344e+01\n",
      "Epoch 8741, Loss: 455.2434997558594, Neurons: 11, Grad norm: 7.992e+00\n",
      "Epoch 8742, Loss: 455.2321472167969, Neurons: 11, Grad norm: 5.575e+01\n",
      "Epoch 8743, Loss: 455.2220764160156, Neurons: 11, Grad norm: 8.918e+01\n",
      "Epoch 8744, Loss: 455.2122497558594, Neurons: 11, Grad norm: 8.237e+01\n",
      "Epoch 8745, Loss: 455.20159912109375, Neurons: 11, Grad norm: 4.143e+01\n",
      "Epoch 8746, Loss: 455.1903991699219, Neurons: 11, Grad norm: 1.376e+01\n",
      "Epoch 8747, Loss: 455.1796875, Neurons: 11, Grad norm: 5.681e+01\n",
      "Epoch 8748, Loss: 455.16973876953125, Neurons: 11, Grad norm: 7.183e+01\n",
      "Epoch 8749, Loss: 455.1596374511719, Neurons: 11, Grad norm: 5.470e+01\n",
      "Epoch 8749, Test loss: 451.0105895996094\n",
      "Epoch 8750, Loss: 455.14898681640625, Neurons: 11, Grad norm: 1.614e+01\n",
      "Epoch 8751, Loss: 455.13818359375, Neurons: 11, Grad norm: 2.647e+01\n",
      "Epoch 8752, Loss: 455.12799072265625, Neurons: 11, Grad norm: 5.274e+01\n",
      "Epoch 8753, Loss: 455.11798095703125, Neurons: 11, Grad norm: 5.396e+01\n",
      "Epoch 8754, Loss: 455.10772705078125, Neurons: 11, Grad norm: 3.213e+01\n",
      "Epoch 8755, Loss: 455.0971984863281, Neurons: 11, Grad norm: 4.173e+00\n",
      "Epoch 8756, Loss: 455.0867919921875, Neurons: 11, Grad norm: 3.114e+01\n",
      "Epoch 8757, Loss: 455.0766906738281, Neurons: 11, Grad norm: 4.435e+01\n",
      "Epoch 8758, Loss: 455.066650390625, Neurons: 11, Grad norm: 3.753e+01\n",
      "Epoch 8759, Loss: 455.056396484375, Neurons: 11, Grad norm: 1.578e+01\n",
      "Epoch 8760, Loss: 455.04608154296875, Neurons: 11, Grad norm: 1.166e+01\n",
      "Epoch 8761, Loss: 455.03594970703125, Neurons: 11, Grad norm: 3.031e+01\n",
      "Epoch 8762, Loss: 455.02587890625, Neurons: 11, Grad norm: 3.481e+01\n",
      "Epoch 8763, Loss: 455.0158996582031, Neurons: 11, Grad norm: 2.450e+01\n",
      "Epoch 8764, Loss: 455.00567626953125, Neurons: 11, Grad norm: 6.140e+00\n",
      "Epoch 8765, Loss: 454.9955749511719, Neurons: 11, Grad norm: 1.526e+01\n",
      "Epoch 8766, Loss: 454.98553466796875, Neurons: 11, Grad norm: 2.654e+01\n",
      "Epoch 8767, Loss: 454.9755859375, Neurons: 11, Grad norm: 2.619e+01\n",
      "Epoch 8768, Loss: 454.965576171875, Neurons: 11, Grad norm: 1.550e+01\n",
      "Epoch 8769, Loss: 454.9555358886719, Neurons: 11, Grad norm: 3.969e+00\n",
      "Epoch 8770, Loss: 454.94549560546875, Neurons: 11, Grad norm: 1.528e+01\n",
      "Epoch 8771, Loss: 454.9355773925781, Neurons: 11, Grad norm: 2.169e+01\n",
      "Epoch 8772, Loss: 454.9256896972656, Neurons: 11, Grad norm: 1.912e+01\n",
      "Epoch 8773, Loss: 454.9157409667969, Neurons: 11, Grad norm: 9.718e+00\n",
      "Epoch 8774, Loss: 454.9057922363281, Neurons: 11, Grad norm: 5.181e+00\n",
      "Epoch 8775, Loss: 454.8958740234375, Neurons: 11, Grad norm: 1.386e+01\n",
      "Epoch 8776, Loss: 454.88604736328125, Neurons: 11, Grad norm: 1.738e+01\n",
      "Epoch 8777, Loss: 454.8761901855469, Neurons: 11, Grad norm: 1.417e+01\n",
      "Epoch 8778, Loss: 454.8663024902344, Neurons: 11, Grad norm: 6.614e+00\n",
      "Epoch 8779, Loss: 454.8564758300781, Neurons: 11, Grad norm: 5.632e+00\n",
      "Epoch 8780, Loss: 454.8466796875, Neurons: 11, Grad norm: 1.172e+01\n",
      "Epoch 8781, Loss: 454.8368835449219, Neurons: 11, Grad norm: 1.369e+01\n",
      "Epoch 8782, Loss: 454.8271484375, Neurons: 11, Grad norm: 1.073e+01\n",
      "Epoch 8783, Loss: 454.8173522949219, Neurons: 11, Grad norm: 5.178e+00\n",
      "Epoch 8784, Loss: 454.8075866699219, Neurons: 11, Grad norm: 5.283e+00\n",
      "Epoch 8785, Loss: 454.7978515625, Neurons: 11, Grad norm: 9.560e+00\n",
      "Epoch 8786, Loss: 454.7881774902344, Neurons: 11, Grad norm: 1.088e+01\n",
      "Epoch 8787, Loss: 454.77850341796875, Neurons: 11, Grad norm: 8.646e+00\n",
      "Epoch 8788, Loss: 454.76873779296875, Neurons: 11, Grad norm: 4.713e+00\n",
      "Epoch 8789, Loss: 454.75909423828125, Neurons: 11, Grad norm: 4.669e+00\n",
      "Epoch 8790, Loss: 454.74945068359375, Neurons: 11, Grad norm: 7.680e+00\n",
      "Epoch 8791, Loss: 454.7397766113281, Neurons: 11, Grad norm: 8.798e+00\n",
      "Epoch 8792, Loss: 454.7301940917969, Neurons: 11, Grad norm: 7.317e+00\n",
      "Epoch 8793, Loss: 454.7205810546875, Neurons: 11, Grad norm: 4.566e+00\n",
      "Epoch 8794, Loss: 454.71099853515625, Neurons: 11, Grad norm: 4.146e+00\n",
      "Epoch 8795, Loss: 454.7013854980469, Neurons: 11, Grad norm: 6.175e+00\n",
      "Epoch 8796, Loss: 454.69183349609375, Neurons: 11, Grad norm: 7.177e+00\n",
      "Epoch 8797, Loss: 454.6822814941406, Neurons: 11, Grad norm: 6.377e+00\n",
      "Epoch 8798, Loss: 454.67279052734375, Neurons: 11, Grad norm: 4.555e+00\n",
      "Epoch 8799, Loss: 454.6632385253906, Neurons: 11, Grad norm: 3.828e+00\n",
      "Epoch 8799, Test loss: 450.5399169921875\n",
      "Epoch 8800, Loss: 454.65374755859375, Neurons: 11, Grad norm: 4.970e+00\n",
      "Epoch 8801, Loss: 454.64422607421875, Neurons: 11, Grad norm: 5.869e+00\n",
      "Epoch 8802, Loss: 454.6347961425781, Neurons: 11, Grad norm: 5.563e+00\n",
      "Epoch 8803, Loss: 454.6252746582031, Neurons: 11, Grad norm: 4.484e+00\n",
      "Epoch 8804, Loss: 454.6158752441406, Neurons: 11, Grad norm: 3.764e+00\n",
      "Epoch 8805, Loss: 454.6064453125, Neurons: 11, Grad norm: 4.206e+00\n",
      "Epoch 8806, Loss: 454.5970458984375, Neurons: 11, Grad norm: 4.900e+00\n",
      "Epoch 8807, Loss: 454.587646484375, Neurons: 11, Grad norm: 4.960e+00\n",
      "Epoch 8808, Loss: 454.5782775878906, Neurons: 11, Grad norm: 4.403e+00\n",
      "Epoch 8809, Loss: 454.5688781738281, Neurons: 11, Grad norm: 3.820e+00\n",
      "Epoch 8810, Loss: 454.5594787597656, Neurons: 11, Grad norm: 3.835e+00\n",
      "Epoch 8811, Loss: 454.5502014160156, Neurons: 11, Grad norm: 4.233e+00\n",
      "Epoch 8812, Loss: 454.54083251953125, Neurons: 11, Grad norm: 4.444e+00\n",
      "Epoch 8813, Loss: 454.5315246582031, Neurons: 11, Grad norm: 4.304e+00\n",
      "Epoch 8814, Loss: 454.5221862792969, Neurons: 11, Grad norm: 3.937e+00\n",
      "Epoch 8815, Loss: 454.512939453125, Neurons: 11, Grad norm: 3.735e+00\n",
      "Epoch 8816, Loss: 454.5036926269531, Neurons: 11, Grad norm: 3.892e+00\n",
      "Epoch 8817, Loss: 454.494384765625, Neurons: 11, Grad norm: 4.145e+00\n",
      "Epoch 8818, Loss: 454.4851379394531, Neurons: 11, Grad norm: 4.216e+00\n",
      "Epoch 8819, Loss: 454.47589111328125, Neurons: 11, Grad norm: 4.016e+00\n",
      "Epoch 8820, Loss: 454.46673583984375, Neurons: 11, Grad norm: 3.781e+00\n",
      "Epoch 8821, Loss: 454.4574890136719, Neurons: 11, Grad norm: 3.733e+00\n",
      "Epoch 8822, Loss: 454.44830322265625, Neurons: 11, Grad norm: 3.853e+00\n",
      "Epoch 8823, Loss: 454.43914794921875, Neurons: 11, Grad norm: 3.980e+00\n",
      "Epoch 8824, Loss: 454.42999267578125, Neurons: 11, Grad norm: 3.959e+00\n",
      "Epoch 8825, Loss: 454.42083740234375, Neurons: 11, Grad norm: 3.838e+00\n",
      "Epoch 8826, Loss: 454.41168212890625, Neurons: 11, Grad norm: 3.720e+00\n",
      "Epoch 8827, Loss: 454.402587890625, Neurons: 11, Grad norm: 3.726e+00\n",
      "Epoch 8828, Loss: 454.3934326171875, Neurons: 11, Grad norm: 3.809e+00\n",
      "Epoch 8829, Loss: 454.3843994140625, Neurons: 11, Grad norm: 3.846e+00\n",
      "Epoch 8830, Loss: 454.3752746582031, Neurons: 11, Grad norm: 3.817e+00\n",
      "Epoch 8831, Loss: 454.3661804199219, Neurons: 11, Grad norm: 3.740e+00\n",
      "Epoch 8832, Loss: 454.3571472167969, Neurons: 11, Grad norm: 3.698e+00\n",
      "Epoch 8833, Loss: 454.34808349609375, Neurons: 11, Grad norm: 3.705e+00\n",
      "Epoch 8834, Loss: 454.33905029296875, Neurons: 11, Grad norm: 3.730e+00\n",
      "Epoch 8835, Loss: 454.3300476074219, Neurons: 11, Grad norm: 3.748e+00\n",
      "Epoch 8836, Loss: 454.321044921875, Neurons: 11, Grad norm: 3.733e+00\n",
      "Epoch 8837, Loss: 454.3120422363281, Neurons: 11, Grad norm: 3.710e+00\n",
      "Epoch 8838, Loss: 454.3031005859375, Neurons: 11, Grad norm: 3.683e+00\n",
      "Epoch 8839, Loss: 454.2940979003906, Neurons: 11, Grad norm: 3.682e+00\n",
      "Epoch 8840, Loss: 454.28509521484375, Neurons: 11, Grad norm: 3.703e+00\n",
      "Epoch 8841, Loss: 454.27618408203125, Neurons: 11, Grad norm: 3.716e+00\n",
      "Epoch 8842, Loss: 454.2673034667969, Neurons: 11, Grad norm: 3.723e+00\n",
      "Epoch 8843, Loss: 454.2583923339844, Neurons: 11, Grad norm: 3.696e+00\n",
      "Epoch 8844, Loss: 454.24945068359375, Neurons: 11, Grad norm: 3.671e+00\n",
      "Epoch 8845, Loss: 454.2406005859375, Neurons: 11, Grad norm: 3.665e+00\n",
      "Epoch 8846, Loss: 454.231689453125, Neurons: 11, Grad norm: 3.677e+00\n",
      "Epoch 8847, Loss: 454.2227783203125, Neurons: 11, Grad norm: 3.696e+00\n",
      "Epoch 8848, Loss: 454.2139892578125, Neurons: 11, Grad norm: 3.692e+00\n",
      "Epoch 8849, Loss: 454.205078125, Neurons: 11, Grad norm: 3.682e+00\n",
      "Epoch 8849, Test loss: 450.09246826171875\n",
      "Epoch 8850, Loss: 454.1962890625, Neurons: 11, Grad norm: 3.661e+00\n",
      "Epoch 8851, Loss: 454.1875, Neurons: 11, Grad norm: 3.652e+00\n",
      "Epoch 8852, Loss: 454.17864990234375, Neurons: 11, Grad norm: 3.650e+00\n",
      "Epoch 8853, Loss: 454.1698913574219, Neurons: 11, Grad norm: 3.651e+00\n",
      "Epoch 8854, Loss: 454.1611022949219, Neurons: 11, Grad norm: 3.656e+00\n",
      "Epoch 8855, Loss: 454.15228271484375, Neurons: 11, Grad norm: 3.651e+00\n",
      "Epoch 8856, Loss: 454.1435852050781, Neurons: 11, Grad norm: 3.651e+00\n",
      "Epoch 8857, Loss: 454.13482666015625, Neurons: 11, Grad norm: 3.644e+00\n",
      "Epoch 8858, Loss: 454.1260986328125, Neurons: 11, Grad norm: 3.640e+00\n",
      "Epoch 8859, Loss: 454.1174011230469, Neurons: 11, Grad norm: 3.634e+00\n",
      "Epoch 8860, Loss: 454.10870361328125, Neurons: 11, Grad norm: 3.632e+00\n",
      "Epoch 8861, Loss: 454.0999450683594, Neurons: 11, Grad norm: 3.632e+00\n",
      "Epoch 8862, Loss: 454.0912780761719, Neurons: 11, Grad norm: 3.629e+00\n",
      "Epoch 8863, Loss: 454.08258056640625, Neurons: 11, Grad norm: 3.626e+00\n",
      "Epoch 8864, Loss: 454.0739440917969, Neurons: 11, Grad norm: 3.624e+00\n",
      "Epoch 8865, Loss: 454.0652770996094, Neurons: 11, Grad norm: 3.623e+00\n",
      "Epoch 8866, Loss: 454.05657958984375, Neurons: 11, Grad norm: 3.622e+00\n",
      "Epoch 8867, Loss: 454.0479736328125, Neurons: 11, Grad norm: 3.625e+00\n",
      "Epoch 8868, Loss: 454.0393981933594, Neurons: 11, Grad norm: 3.622e+00\n",
      "Epoch 8869, Loss: 454.0307922363281, Neurons: 11, Grad norm: 3.619e+00\n",
      "Epoch 8870, Loss: 454.0221862792969, Neurons: 11, Grad norm: 3.612e+00\n",
      "Epoch 8871, Loss: 454.0135803222656, Neurons: 11, Grad norm: 3.609e+00\n",
      "Epoch 8872, Loss: 454.0050354003906, Neurons: 11, Grad norm: 3.612e+00\n",
      "Epoch 8873, Loss: 453.9964904785156, Neurons: 11, Grad norm: 3.615e+00\n",
      "Epoch 8874, Loss: 453.9879455566406, Neurons: 11, Grad norm: 3.628e+00\n",
      "Epoch 8875, Loss: 453.9794006347656, Neurons: 11, Grad norm: 3.632e+00\n",
      "Epoch 8876, Loss: 453.97088623046875, Neurons: 11, Grad norm: 3.644e+00\n",
      "Epoch 8877, Loss: 453.96234130859375, Neurons: 11, Grad norm: 3.634e+00\n",
      "Epoch 8878, Loss: 453.9538879394531, Neurons: 11, Grad norm: 3.629e+00\n",
      "Epoch 8879, Loss: 453.9453430175781, Neurons: 11, Grad norm: 3.611e+00\n",
      "Epoch 8880, Loss: 453.9368896484375, Neurons: 11, Grad norm: 3.601e+00\n",
      "Epoch 8881, Loss: 453.9283752441406, Neurons: 11, Grad norm: 3.589e+00\n",
      "Epoch 8882, Loss: 453.9199523925781, Neurons: 11, Grad norm: 3.594e+00\n",
      "Epoch 8883, Loss: 453.9114990234375, Neurons: 11, Grad norm: 3.615e+00\n",
      "Epoch 8884, Loss: 453.903076171875, Neurons: 11, Grad norm: 3.624e+00\n",
      "Epoch 8885, Loss: 453.8946533203125, Neurons: 11, Grad norm: 3.647e+00\n",
      "Epoch 8886, Loss: 453.8861999511719, Neurons: 11, Grad norm: 3.649e+00\n",
      "Epoch 8887, Loss: 453.8777770996094, Neurons: 11, Grad norm: 3.653e+00\n",
      "Epoch 8888, Loss: 453.869384765625, Neurons: 11, Grad norm: 3.628e+00\n",
      "Epoch 8889, Loss: 453.8609924316406, Neurons: 11, Grad norm: 3.608e+00\n",
      "Epoch 8890, Loss: 453.85260009765625, Neurons: 11, Grad norm: 3.577e+00\n",
      "Epoch 8891, Loss: 453.84423828125, Neurons: 11, Grad norm: 3.571e+00\n",
      "Epoch 8892, Loss: 453.83587646484375, Neurons: 11, Grad norm: 3.587e+00\n",
      "Epoch 8893, Loss: 453.8275451660156, Neurons: 11, Grad norm: 3.603e+00\n",
      "Epoch 8894, Loss: 453.8192443847656, Neurons: 11, Grad norm: 3.637e+00\n",
      "Epoch 8895, Loss: 453.8108825683594, Neurons: 11, Grad norm: 3.656e+00\n",
      "Epoch 8896, Loss: 453.8025817871094, Neurons: 11, Grad norm: 3.692e+00\n",
      "Epoch 8897, Loss: 453.7942810058594, Neurons: 11, Grad norm: 3.680e+00\n",
      "Epoch 8898, Loss: 453.7859802246094, Neurons: 11, Grad norm: 3.669e+00\n",
      "Epoch 8899, Loss: 453.7776794433594, Neurons: 11, Grad norm: 3.637e+00\n",
      "Epoch 8899, Test loss: 449.6790771484375\n",
      "Epoch 8900, Loss: 453.7694396972656, Neurons: 11, Grad norm: 3.635e+00\n",
      "Epoch 8901, Loss: 453.7611999511719, Neurons: 11, Grad norm: 3.606e+00\n",
      "Epoch 8902, Loss: 453.7529296875, Neurons: 11, Grad norm: 3.589e+00\n",
      "Epoch 8903, Loss: 453.74468994140625, Neurons: 11, Grad norm: 3.566e+00\n",
      "Epoch 8904, Loss: 453.7364807128906, Neurons: 11, Grad norm: 3.558e+00\n",
      "Epoch 8905, Loss: 453.7281799316406, Neurons: 11, Grad norm: 3.548e+00\n",
      "Epoch 8906, Loss: 453.7200012207031, Neurons: 11, Grad norm: 3.546e+00\n",
      "Epoch 8907, Loss: 453.7117919921875, Neurons: 11, Grad norm: 3.543e+00\n",
      "Epoch 8908, Loss: 453.7035827636719, Neurons: 11, Grad norm: 3.543e+00\n",
      "Epoch 8909, Loss: 453.69537353515625, Neurons: 11, Grad norm: 3.539e+00\n",
      "Epoch 8910, Loss: 453.6872253417969, Neurons: 11, Grad norm: 3.539e+00\n",
      "Epoch 8911, Loss: 453.6790771484375, Neurons: 11, Grad norm: 3.539e+00\n",
      "Epoch 8912, Loss: 453.6709289550781, Neurons: 11, Grad norm: 3.549e+00\n",
      "Epoch 8913, Loss: 453.66278076171875, Neurons: 11, Grad norm: 3.554e+00\n",
      "Epoch 8914, Loss: 453.6546936035156, Neurons: 11, Grad norm: 3.579e+00\n",
      "Epoch 8915, Loss: 453.64654541015625, Neurons: 11, Grad norm: 3.583e+00\n",
      "Epoch 8916, Loss: 453.6383972167969, Neurons: 11, Grad norm: 3.605e+00\n",
      "Epoch 8917, Loss: 453.6302795410156, Neurons: 11, Grad norm: 3.613e+00\n",
      "Epoch 8918, Loss: 453.6221923828125, Neurons: 11, Grad norm: 3.642e+00\n",
      "Epoch 8919, Loss: 453.61407470703125, Neurons: 11, Grad norm: 3.629e+00\n",
      "Epoch 8920, Loss: 453.6059875488281, Neurons: 11, Grad norm: 3.630e+00\n",
      "Epoch 8921, Loss: 453.5979919433594, Neurons: 11, Grad norm: 3.600e+00\n",
      "Epoch 8922, Loss: 453.5898742675781, Neurons: 11, Grad norm: 3.592e+00\n",
      "Epoch 8923, Loss: 453.58184814453125, Neurons: 11, Grad norm: 3.560e+00\n",
      "Epoch 8924, Loss: 453.57379150390625, Neurons: 11, Grad norm: 3.549e+00\n",
      "Epoch 8925, Loss: 453.5657958984375, Neurons: 11, Grad norm: 3.531e+00\n",
      "Epoch 8926, Loss: 453.55767822265625, Neurons: 11, Grad norm: 3.529e+00\n",
      "Epoch 8927, Loss: 453.5496826171875, Neurons: 11, Grad norm: 3.519e+00\n",
      "Epoch 8928, Loss: 453.54168701171875, Neurons: 11, Grad norm: 3.524e+00\n",
      "Epoch 8929, Loss: 453.53369140625, Neurons: 11, Grad norm: 3.523e+00\n",
      "Epoch 8930, Loss: 453.5257263183594, Neurons: 11, Grad norm: 3.534e+00\n",
      "Epoch 8931, Loss: 453.5177917480469, Neurons: 11, Grad norm: 3.530e+00\n",
      "Epoch 8932, Loss: 453.5097961425781, Neurons: 11, Grad norm: 3.542e+00\n",
      "Epoch 8933, Loss: 453.5018005371094, Neurons: 11, Grad norm: 3.546e+00\n",
      "Epoch 8934, Loss: 453.493896484375, Neurons: 11, Grad norm: 3.579e+00\n",
      "Epoch 8935, Loss: 453.48590087890625, Neurons: 11, Grad norm: 3.601e+00\n",
      "Epoch 8936, Loss: 453.4779968261719, Neurons: 11, Grad norm: 3.659e+00\n",
      "Epoch 8937, Loss: 453.4700927734375, Neurons: 11, Grad norm: 3.701e+00\n",
      "Epoch 8938, Loss: 453.46209716796875, Neurons: 11, Grad norm: 3.821e+00\n",
      "Epoch 8939, Loss: 453.4541931152344, Neurons: 11, Grad norm: 3.928e+00\n",
      "Epoch 8940, Loss: 453.4462890625, Neurons: 11, Grad norm: 4.121e+00\n",
      "Epoch 8941, Loss: 453.4384460449219, Neurons: 11, Grad norm: 4.313e+00\n",
      "Epoch 8942, Loss: 453.4305419921875, Neurons: 11, Grad norm: 4.673e+00\n",
      "Epoch 8943, Loss: 453.4226989746094, Neurons: 11, Grad norm: 5.127e+00\n",
      "Epoch 8944, Loss: 453.414794921875, Neurons: 11, Grad norm: 5.890e+00\n",
      "Epoch 8945, Loss: 453.4069519042969, Neurons: 11, Grad norm: 6.815e+00\n",
      "Epoch 8946, Loss: 453.3990783691406, Neurons: 11, Grad norm: 8.119e+00\n",
      "Epoch 8947, Loss: 453.3912353515625, Neurons: 11, Grad norm: 9.719e+00\n",
      "Epoch 8948, Loss: 453.3833923339844, Neurons: 11, Grad norm: 1.200e+01\n",
      "Epoch 8949, Loss: 453.3755798339844, Neurons: 11, Grad norm: 1.496e+01\n",
      "Epoch 8949, Test loss: 449.2892761230469\n",
      "Epoch 8950, Loss: 453.3677978515625, Neurons: 11, Grad norm: 1.905e+01\n",
      "Epoch 8951, Loss: 453.3599853515625, Neurons: 11, Grad norm: 2.426e+01\n",
      "Epoch 8952, Loss: 453.35223388671875, Neurons: 11, Grad norm: 3.121e+01\n",
      "Epoch 8953, Loss: 453.344482421875, Neurons: 11, Grad norm: 4.017e+01\n",
      "Epoch 8954, Loss: 453.3367919921875, Neurons: 11, Grad norm: 5.196e+01\n",
      "Epoch 8955, Loss: 453.3291931152344, Neurons: 11, Grad norm: 6.713e+01\n",
      "Epoch 8956, Loss: 453.3216857910156, Neurons: 11, Grad norm: 8.663e+01\n",
      "Epoch 8957, Loss: 453.3143310546875, Neurons: 11, Grad norm: 1.108e+02\n",
      "Epoch 8958, Loss: 453.3074035644531, Neurons: 11, Grad norm: 1.396e+02\n",
      "Epoch 8959, Loss: 453.3006896972656, Neurons: 11, Grad norm: 1.703e+02\n",
      "Epoch 8960, Loss: 453.29443359375, Neurons: 11, Grad norm: 1.971e+02\n",
      "Epoch 8961, Loss: 453.2882995605469, Neurons: 11, Grad norm: 2.094e+02\n",
      "Epoch 8962, Loss: 453.2815246582031, Neurons: 11, Grad norm: 1.951e+02\n",
      "Epoch 8963, Loss: 453.2732849121094, Neurons: 11, Grad norm: 1.470e+02\n",
      "Epoch 8964, Loss: 453.2637023925781, Neurons: 11, Grad norm: 7.188e+01\n",
      "Epoch 8965, Loss: 453.25408935546875, Neurons: 11, Grad norm: 1.357e+01\n",
      "Epoch 8966, Loss: 453.2461242675781, Neurons: 11, Grad norm: 8.633e+01\n",
      "Epoch 8967, Loss: 453.239990234375, Neurons: 11, Grad norm: 1.312e+02\n",
      "Epoch 8968, Loss: 453.23419189453125, Neurons: 11, Grad norm: 1.377e+02\n",
      "Epoch 8969, Loss: 453.227294921875, Neurons: 11, Grad norm: 1.053e+02\n",
      "Epoch 8970, Loss: 453.218994140625, Neurons: 11, Grad norm: 4.495e+01\n",
      "Epoch 8971, Loss: 453.210693359375, Neurons: 11, Grad norm: 2.318e+01\n",
      "Epoch 8972, Loss: 453.2033386230469, Neurons: 11, Grad norm: 7.734e+01\n",
      "Epoch 8973, Loss: 453.1970520019531, Neurons: 11, Grad norm: 1.025e+02\n",
      "Epoch 8974, Loss: 453.1905822753906, Neurons: 11, Grad norm: 9.328e+01\n",
      "Epoch 8975, Loss: 453.18328857421875, Neurons: 11, Grad norm: 5.493e+01\n",
      "Epoch 8976, Loss: 453.17547607421875, Neurons: 11, Grad norm: 4.147e+00\n",
      "Epoch 8977, Loss: 453.1680908203125, Neurons: 11, Grad norm: 4.574e+01\n",
      "Epoch 8978, Loss: 453.1613464355469, Neurons: 11, Grad norm: 7.409e+01\n",
      "Epoch 8979, Loss: 453.1548767089844, Neurons: 11, Grad norm: 7.545e+01\n",
      "Epoch 8980, Loss: 453.1479797363281, Neurons: 11, Grad norm: 5.153e+01\n",
      "Epoch 8981, Loss: 453.1405944824219, Neurons: 11, Grad norm: 1.323e+01\n",
      "Epoch 8982, Loss: 453.1331787109375, Neurons: 11, Grad norm: 2.663e+01\n",
      "Epoch 8983, Loss: 453.12640380859375, Neurons: 11, Grad norm: 5.284e+01\n",
      "Epoch 8984, Loss: 453.1197509765625, Neurons: 11, Grad norm: 5.913e+01\n",
      "Epoch 8985, Loss: 453.1128845214844, Neurons: 11, Grad norm: 4.499e+01\n",
      "Epoch 8986, Loss: 453.10577392578125, Neurons: 11, Grad norm: 1.757e+01\n",
      "Epoch 8987, Loss: 453.09869384765625, Neurons: 11, Grad norm: 1.387e+01\n",
      "Epoch 8988, Loss: 453.091796875, Neurons: 11, Grad norm: 3.671e+01\n",
      "Epoch 8989, Loss: 453.0850524902344, Neurons: 11, Grad norm: 4.549e+01\n",
      "Epoch 8990, Loss: 453.0782775878906, Neurons: 11, Grad norm: 3.836e+01\n",
      "Epoch 8991, Loss: 453.0712890625, Neurons: 11, Grad norm: 1.958e+01\n",
      "Epoch 8992, Loss: 453.0643310546875, Neurons: 11, Grad norm: 5.371e+00\n",
      "Epoch 8993, Loss: 453.0574951171875, Neurons: 11, Grad norm: 2.409e+01\n",
      "Epoch 8994, Loss: 453.0506896972656, Neurons: 11, Grad norm: 3.416e+01\n",
      "Epoch 8995, Loss: 453.0439758300781, Neurons: 11, Grad norm: 3.220e+01\n",
      "Epoch 8996, Loss: 453.0370788574219, Neurons: 11, Grad norm: 2.034e+01\n",
      "Epoch 8997, Loss: 453.0301818847656, Neurons: 11, Grad norm: 4.356e+00\n",
      "Epoch 8998, Loss: 453.0232849121094, Neurons: 11, Grad norm: 1.389e+01\n",
      "Epoch 8999, Loss: 453.01654052734375, Neurons: 11, Grad norm: 2.420e+01\n",
      "Epoch 8999, Test loss: 448.9635925292969\n",
      "Epoch 9000, Loss: 453.0097961425781, Neurons: 11, Grad norm: 2.602e+01\n",
      "Epoch 9001, Loss: 453.00299072265625, Neurons: 11, Grad norm: 1.980e+01\n",
      "Epoch 9002, Loss: 452.9961853027344, Neurons: 11, Grad norm: 8.341e+00\n",
      "Epoch 9003, Loss: 452.9893798828125, Neurons: 11, Grad norm: 6.245e+00\n",
      "Epoch 9004, Loss: 452.9825744628906, Neurons: 11, Grad norm: 1.583e+01\n",
      "Epoch 9005, Loss: 452.97589111328125, Neurons: 11, Grad norm: 2.014e+01\n",
      "Epoch 9006, Loss: 452.9690856933594, Neurons: 11, Grad norm: 1.824e+01\n",
      "Epoch 9007, Loss: 452.96240234375, Neurons: 11, Grad norm: 1.124e+01\n",
      "Epoch 9008, Loss: 452.9555969238281, Neurons: 11, Grad norm: 3.514e+00\n",
      "Epoch 9009, Loss: 452.94879150390625, Neurons: 11, Grad norm: 8.571e+00\n",
      "Epoch 9010, Loss: 452.94207763671875, Neurons: 11, Grad norm: 1.407e+01\n",
      "Epoch 9011, Loss: 452.9353942871094, Neurons: 11, Grad norm: 1.537e+01\n",
      "Epoch 9012, Loss: 452.9286804199219, Neurons: 11, Grad norm: 1.231e+01\n",
      "Epoch 9013, Loss: 452.92193603515625, Neurons: 11, Grad norm: 6.666e+00\n",
      "Epoch 9014, Loss: 452.9151916503906, Neurons: 11, Grad norm: 3.594e+00\n",
      "Epoch 9015, Loss: 452.9084777832031, Neurons: 11, Grad norm: 8.110e+00\n",
      "Epoch 9016, Loss: 452.9018859863281, Neurons: 11, Grad norm: 1.130e+01\n",
      "Epoch 9017, Loss: 452.8951416015625, Neurons: 11, Grad norm: 1.134e+01\n",
      "Epoch 9018, Loss: 452.888427734375, Neurons: 11, Grad norm: 8.676e+00\n",
      "Epoch 9019, Loss: 452.88177490234375, Neurons: 11, Grad norm: 4.565e+00\n",
      "Epoch 9020, Loss: 452.8750915527344, Neurons: 11, Grad norm: 3.866e+00\n",
      "Epoch 9021, Loss: 452.8683776855469, Neurons: 11, Grad norm: 7.077e+00\n",
      "Epoch 9022, Loss: 452.8617248535156, Neurons: 11, Grad norm: 8.976e+00\n",
      "Epoch 9023, Loss: 452.8551025390625, Neurons: 11, Grad norm: 8.809e+00\n",
      "Epoch 9024, Loss: 452.84844970703125, Neurons: 11, Grad norm: 6.709e+00\n",
      "Epoch 9025, Loss: 452.841796875, Neurons: 11, Grad norm: 4.045e+00\n",
      "Epoch 9026, Loss: 452.83514404296875, Neurons: 11, Grad norm: 3.590e+00\n",
      "Epoch 9027, Loss: 452.8284912109375, Neurons: 11, Grad norm: 5.455e+00\n",
      "Epoch 9028, Loss: 452.8218994140625, Neurons: 11, Grad norm: 6.812e+00\n",
      "Epoch 9029, Loss: 452.81524658203125, Neurons: 11, Grad norm: 6.741e+00\n",
      "Epoch 9030, Loss: 452.80859375, Neurons: 11, Grad norm: 5.549e+00\n",
      "Epoch 9031, Loss: 452.802001953125, Neurons: 11, Grad norm: 3.876e+00\n",
      "Epoch 9032, Loss: 452.79534912109375, Neurons: 11, Grad norm: 3.318e+00\n",
      "Epoch 9033, Loss: 452.7887878417969, Neurons: 11, Grad norm: 4.239e+00\n",
      "Epoch 9034, Loss: 452.7821960449219, Neurons: 11, Grad norm: 5.130e+00\n",
      "Epoch 9035, Loss: 452.7755432128906, Neurons: 11, Grad norm: 5.343e+00\n",
      "Epoch 9036, Loss: 452.76898193359375, Neurons: 11, Grad norm: 4.749e+00\n",
      "Epoch 9037, Loss: 452.76239013671875, Neurons: 11, Grad norm: 3.862e+00\n",
      "Epoch 9038, Loss: 452.75579833984375, Neurons: 11, Grad norm: 3.291e+00\n",
      "Epoch 9039, Loss: 452.7492980957031, Neurons: 11, Grad norm: 3.543e+00\n",
      "Epoch 9040, Loss: 452.74267578125, Neurons: 11, Grad norm: 4.179e+00\n",
      "Epoch 9041, Loss: 452.736083984375, Neurons: 11, Grad norm: 4.526e+00\n",
      "Epoch 9042, Loss: 452.72955322265625, Neurons: 11, Grad norm: 4.485e+00\n",
      "Epoch 9043, Loss: 452.7229919433594, Neurons: 11, Grad norm: 3.991e+00\n",
      "Epoch 9044, Loss: 452.7164001464844, Neurons: 11, Grad norm: 3.482e+00\n",
      "Epoch 9045, Loss: 452.70989990234375, Neurons: 11, Grad norm: 3.276e+00\n",
      "Epoch 9046, Loss: 452.7033386230469, Neurons: 11, Grad norm: 3.452e+00\n",
      "Epoch 9047, Loss: 452.69677734375, Neurons: 11, Grad norm: 3.782e+00\n",
      "Epoch 9048, Loss: 452.6902770996094, Neurons: 11, Grad norm: 3.926e+00\n",
      "Epoch 9049, Loss: 452.68377685546875, Neurons: 11, Grad norm: 3.846e+00\n",
      "Epoch 9049, Test loss: 448.64276123046875\n",
      "Epoch 9050, Loss: 452.6772766113281, Neurons: 11, Grad norm: 3.592e+00\n",
      "Epoch 9051, Loss: 452.6707458496094, Neurons: 11, Grad norm: 3.376e+00\n",
      "Epoch 9052, Loss: 452.6641845703125, Neurons: 11, Grad norm: 3.269e+00\n",
      "Epoch 9053, Loss: 452.6576843261719, Neurons: 11, Grad norm: 3.317e+00\n",
      "Epoch 9054, Loss: 452.65118408203125, Neurons: 11, Grad norm: 3.442e+00\n",
      "Epoch 9055, Loss: 452.6446838378906, Neurons: 11, Grad norm: 3.521e+00\n",
      "Epoch 9056, Loss: 452.63818359375, Neurons: 11, Grad norm: 3.544e+00\n",
      "Epoch 9057, Loss: 452.6317443847656, Neurons: 11, Grad norm: 3.451e+00\n",
      "Epoch 9058, Loss: 452.625244140625, Neurons: 11, Grad norm: 3.344e+00\n",
      "Epoch 9059, Loss: 452.6187438964844, Neurons: 11, Grad norm: 3.269e+00\n",
      "Epoch 9060, Loss: 452.61224365234375, Neurons: 11, Grad norm: 3.274e+00\n",
      "Epoch 9061, Loss: 452.60577392578125, Neurons: 11, Grad norm: 3.336e+00\n",
      "Epoch 9062, Loss: 452.5993347167969, Neurons: 11, Grad norm: 3.378e+00\n",
      "Epoch 9063, Loss: 452.5928955078125, Neurons: 11, Grad norm: 3.390e+00\n",
      "Epoch 9064, Loss: 452.58642578125, Neurons: 11, Grad norm: 3.351e+00\n",
      "Epoch 9065, Loss: 452.5799865722656, Neurons: 11, Grad norm: 3.307e+00\n",
      "Epoch 9066, Loss: 452.573486328125, Neurons: 11, Grad norm: 3.263e+00\n",
      "Epoch 9067, Loss: 452.56707763671875, Neurons: 11, Grad norm: 3.258e+00\n",
      "Epoch 9068, Loss: 452.5606384277344, Neurons: 11, Grad norm: 3.284e+00\n",
      "Epoch 9069, Loss: 452.55419921875, Neurons: 11, Grad norm: 3.325e+00\n",
      "Epoch 9070, Loss: 452.54779052734375, Neurons: 11, Grad norm: 3.375e+00\n",
      "Epoch 9071, Loss: 452.5413818359375, Neurons: 11, Grad norm: 3.388e+00\n",
      "Epoch 9072, Loss: 452.5349426269531, Neurons: 11, Grad norm: 3.370e+00\n",
      "Epoch 9073, Loss: 452.5285339355469, Neurons: 11, Grad norm: 3.311e+00\n",
      "Epoch 9074, Loss: 452.5220947265625, Neurons: 11, Grad norm: 3.269e+00\n",
      "Epoch 9075, Loss: 452.51568603515625, Neurons: 11, Grad norm: 3.250e+00\n",
      "Epoch 9076, Loss: 452.50927734375, Neurons: 11, Grad norm: 3.252e+00\n",
      "Epoch 9077, Loss: 452.5028991699219, Neurons: 11, Grad norm: 3.265e+00\n",
      "Epoch 9078, Loss: 452.4964904785156, Neurons: 11, Grad norm: 3.270e+00\n",
      "Epoch 9079, Loss: 452.4900817871094, Neurons: 11, Grad norm: 3.270e+00\n",
      "Epoch 9080, Loss: 452.4837341308594, Neurons: 11, Grad norm: 3.262e+00\n",
      "Epoch 9081, Loss: 452.4773254394531, Neurons: 11, Grad norm: 3.258e+00\n",
      "Epoch 9082, Loss: 452.4709777832031, Neurons: 11, Grad norm: 3.250e+00\n",
      "Epoch 9083, Loss: 452.464599609375, Neurons: 11, Grad norm: 3.244e+00\n",
      "Epoch 9084, Loss: 452.45819091796875, Neurons: 11, Grad norm: 3.242e+00\n",
      "Epoch 9085, Loss: 452.4518737792969, Neurons: 11, Grad norm: 3.247e+00\n",
      "Epoch 9086, Loss: 452.44549560546875, Neurons: 11, Grad norm: 3.263e+00\n",
      "Epoch 9087, Loss: 452.4390869140625, Neurons: 11, Grad norm: 3.275e+00\n",
      "Epoch 9088, Loss: 452.43280029296875, Neurons: 11, Grad norm: 3.283e+00\n",
      "Epoch 9089, Loss: 452.4263916015625, Neurons: 11, Grad norm: 3.281e+00\n",
      "Epoch 9090, Loss: 452.4200744628906, Neurons: 11, Grad norm: 3.276e+00\n",
      "Epoch 9091, Loss: 452.4136962890625, Neurons: 11, Grad norm: 3.259e+00\n",
      "Epoch 9092, Loss: 452.4073791503906, Neurons: 11, Grad norm: 3.245e+00\n",
      "Epoch 9093, Loss: 452.4010314941406, Neurons: 11, Grad norm: 3.236e+00\n",
      "Epoch 9094, Loss: 452.3946838378906, Neurons: 11, Grad norm: 3.235e+00\n",
      "Epoch 9095, Loss: 452.3883972167969, Neurons: 11, Grad norm: 3.240e+00\n",
      "Epoch 9096, Loss: 452.382080078125, Neurons: 11, Grad norm: 3.240e+00\n",
      "Epoch 9097, Loss: 452.375732421875, Neurons: 11, Grad norm: 3.241e+00\n",
      "Epoch 9098, Loss: 452.369384765625, Neurons: 11, Grad norm: 3.240e+00\n",
      "Epoch 9099, Loss: 452.36309814453125, Neurons: 11, Grad norm: 3.239e+00\n",
      "Epoch 9099, Test loss: 448.33978271484375\n",
      "Epoch 9100, Loss: 452.3567810058594, Neurons: 11, Grad norm: 3.238e+00\n",
      "Epoch 9101, Loss: 452.3504943847656, Neurons: 11, Grad norm: 3.240e+00\n",
      "Epoch 9102, Loss: 452.34417724609375, Neurons: 11, Grad norm: 3.243e+00\n",
      "Epoch 9103, Loss: 452.337890625, Neurons: 11, Grad norm: 3.244e+00\n",
      "Epoch 9104, Loss: 452.3315734863281, Neurons: 11, Grad norm: 3.246e+00\n",
      "Epoch 9105, Loss: 452.3252868652344, Neurons: 11, Grad norm: 3.248e+00\n",
      "Epoch 9106, Loss: 452.3190002441406, Neurons: 11, Grad norm: 3.249e+00\n",
      "Epoch 9107, Loss: 452.312744140625, Neurons: 11, Grad norm: 3.249e+00\n",
      "Epoch 9108, Loss: 452.3064880371094, Neurons: 11, Grad norm: 3.252e+00\n",
      "Epoch 9109, Loss: 452.3002014160156, Neurons: 11, Grad norm: 3.256e+00\n",
      "Epoch 9110, Loss: 452.29388427734375, Neurons: 11, Grad norm: 3.255e+00\n",
      "Epoch 9111, Loss: 452.2876281738281, Neurons: 11, Grad norm: 3.252e+00\n",
      "Epoch 9112, Loss: 452.2813415527344, Neurons: 11, Grad norm: 3.248e+00\n",
      "Epoch 9113, Loss: 452.27508544921875, Neurons: 11, Grad norm: 3.243e+00\n",
      "Epoch 9114, Loss: 452.2688293457031, Neurons: 11, Grad norm: 3.243e+00\n",
      "Epoch 9115, Loss: 452.2626037597656, Neurons: 11, Grad norm: 3.239e+00\n",
      "Epoch 9116, Loss: 452.25634765625, Neurons: 11, Grad norm: 3.233e+00\n",
      "Epoch 9117, Loss: 452.2500915527344, Neurons: 11, Grad norm: 3.226e+00\n",
      "Epoch 9118, Loss: 452.24383544921875, Neurons: 11, Grad norm: 3.221e+00\n",
      "Epoch 9119, Loss: 452.2375793457031, Neurons: 11, Grad norm: 3.218e+00\n",
      "Epoch 9120, Loss: 452.23138427734375, Neurons: 11, Grad norm: 3.218e+00\n",
      "Epoch 9121, Loss: 452.22509765625, Neurons: 11, Grad norm: 3.218e+00\n",
      "Epoch 9122, Loss: 452.2189025878906, Neurons: 11, Grad norm: 3.221e+00\n",
      "Epoch 9123, Loss: 452.2126770019531, Neurons: 11, Grad norm: 3.226e+00\n",
      "Epoch 9124, Loss: 452.2064514160156, Neurons: 11, Grad norm: 3.234e+00\n",
      "Epoch 9125, Loss: 452.2001953125, Neurons: 11, Grad norm: 3.238e+00\n",
      "Epoch 9126, Loss: 452.1940002441406, Neurons: 11, Grad norm: 3.249e+00\n",
      "Epoch 9127, Loss: 452.1877746582031, Neurons: 11, Grad norm: 3.263e+00\n",
      "Epoch 9128, Loss: 452.18157958984375, Neurons: 11, Grad norm: 3.291e+00\n",
      "Epoch 9129, Loss: 452.1753845214844, Neurons: 11, Grad norm: 3.325e+00\n",
      "Epoch 9130, Loss: 452.16912841796875, Neurons: 11, Grad norm: 3.384e+00\n",
      "Epoch 9131, Loss: 452.1629943847656, Neurons: 11, Grad norm: 3.454e+00\n",
      "Epoch 9132, Loss: 452.15673828125, Neurons: 11, Grad norm: 3.566e+00\n",
      "Epoch 9133, Loss: 452.15057373046875, Neurons: 11, Grad norm: 3.697e+00\n",
      "Epoch 9134, Loss: 452.1443786621094, Neurons: 11, Grad norm: 3.898e+00\n",
      "Epoch 9135, Loss: 452.13818359375, Neurons: 11, Grad norm: 4.149e+00\n",
      "Epoch 9136, Loss: 452.1319885253906, Neurons: 11, Grad norm: 4.519e+00\n",
      "Epoch 9137, Loss: 452.12579345703125, Neurons: 11, Grad norm: 5.007e+00\n",
      "Epoch 9138, Loss: 452.11962890625, Neurons: 11, Grad norm: 5.678e+00\n",
      "Epoch 9139, Loss: 452.1134948730469, Neurons: 11, Grad norm: 6.471e+00\n",
      "Epoch 9140, Loss: 452.1072998046875, Neurons: 11, Grad norm: 7.458e+00\n",
      "Epoch 9141, Loss: 452.10113525390625, Neurons: 11, Grad norm: 8.683e+00\n",
      "Epoch 9142, Loss: 452.0950012207031, Neurons: 11, Grad norm: 1.031e+01\n",
      "Epoch 9143, Loss: 452.0887756347656, Neurons: 11, Grad norm: 1.233e+01\n",
      "Epoch 9144, Loss: 452.08258056640625, Neurons: 11, Grad norm: 1.499e+01\n",
      "Epoch 9145, Loss: 452.07647705078125, Neurons: 11, Grad norm: 1.836e+01\n",
      "Epoch 9146, Loss: 452.0703430175781, Neurons: 11, Grad norm: 2.273e+01\n",
      "Epoch 9147, Loss: 452.0642395019531, Neurons: 11, Grad norm: 2.831e+01\n",
      "Epoch 9148, Loss: 452.0580749511719, Neurons: 11, Grad norm: 3.554e+01\n",
      "Epoch 9149, Loss: 452.052001953125, Neurons: 11, Grad norm: 4.475e+01\n",
      "Epoch 9149, Test loss: 448.06011962890625\n",
      "Epoch 9150, Loss: 452.0459899902344, Neurons: 11, Grad norm: 5.652e+01\n",
      "Epoch 9151, Loss: 452.03997802734375, Neurons: 11, Grad norm: 7.129e+01\n",
      "Epoch 9152, Loss: 452.0341491699219, Neurons: 11, Grad norm: 8.972e+01\n",
      "Epoch 9153, Loss: 452.0284423828125, Neurons: 11, Grad norm: 1.119e+02\n",
      "Epoch 9154, Loss: 452.02294921875, Neurons: 11, Grad norm: 1.375e+02\n",
      "Epoch 9155, Loss: 452.0177307128906, Neurons: 11, Grad norm: 1.642e+02\n",
      "Epoch 9156, Loss: 452.0127868652344, Neurons: 11, Grad norm: 1.873e+02\n",
      "Epoch 9157, Loss: 452.0079345703125, Neurons: 11, Grad norm: 1.988e+02\n",
      "Epoch 9158, Loss: 452.0025939941406, Neurons: 11, Grad norm: 1.897e+02\n",
      "Epoch 9159, Loss: 451.9962463378906, Neurons: 11, Grad norm: 1.535e+02\n",
      "Epoch 9160, Loss: 451.9887390136719, Neurons: 11, Grad norm: 9.301e+01\n",
      "Epoch 9161, Loss: 451.9809875488281, Neurons: 11, Grad norm: 2.002e+01\n",
      "Epoch 9162, Loss: 451.9740295410156, Neurons: 11, Grad norm: 5.030e+01\n",
      "Epoch 9163, Loss: 451.9685974121094, Neurons: 11, Grad norm: 1.030e+02\n",
      "Epoch 9164, Loss: 451.9639892578125, Neurons: 11, Grad norm: 1.285e+02\n",
      "Epoch 9165, Loss: 451.95904541015625, Neurons: 11, Grad norm: 1.227e+02\n",
      "Epoch 9166, Loss: 451.953125, Neurons: 11, Grad norm: 8.778e+01\n",
      "Epoch 9167, Loss: 451.9465026855469, Neurons: 11, Grad norm: 3.437e+01\n",
      "Epoch 9168, Loss: 451.93988037109375, Neurons: 11, Grad norm: 2.292e+01\n",
      "Epoch 9169, Loss: 451.93414306640625, Neurons: 11, Grad norm: 6.825e+01\n",
      "Epoch 9170, Loss: 451.9290466308594, Neurons: 11, Grad norm: 9.178e+01\n",
      "Epoch 9171, Loss: 451.9239501953125, Neurons: 11, Grad norm: 8.896e+01\n",
      "Epoch 9172, Loss: 451.9181823730469, Neurons: 11, Grad norm: 6.277e+01\n",
      "Epoch 9173, Loss: 451.9120788574219, Neurons: 11, Grad norm: 2.213e+01\n",
      "Epoch 9174, Loss: 451.9059753417969, Neurons: 11, Grad norm: 2.096e+01\n",
      "Epoch 9175, Loss: 451.900390625, Neurons: 11, Grad norm: 5.378e+01\n",
      "Epoch 9176, Loss: 451.8950500488281, Neurons: 11, Grad norm: 6.881e+01\n",
      "Epoch 9177, Loss: 451.8897399902344, Neurons: 11, Grad norm: 6.373e+01\n",
      "Epoch 9178, Loss: 451.88409423828125, Neurons: 11, Grad norm: 4.165e+01\n",
      "Epoch 9179, Loss: 451.8780822753906, Neurons: 11, Grad norm: 1.076e+01\n",
      "Epoch 9180, Loss: 451.8723449707031, Neurons: 11, Grad norm: 2.093e+01\n",
      "Epoch 9181, Loss: 451.8667907714844, Neurons: 11, Grad norm: 4.300e+01\n",
      "Epoch 9182, Loss: 451.86138916015625, Neurons: 11, Grad norm: 5.147e+01\n",
      "Epoch 9183, Loss: 451.8559265136719, Neurons: 11, Grad norm: 4.511e+01\n",
      "Epoch 9184, Loss: 451.85028076171875, Neurons: 11, Grad norm: 2.743e+01\n",
      "Epoch 9185, Loss: 451.84454345703125, Neurons: 11, Grad norm: 4.874e+00\n",
      "Epoch 9186, Loss: 451.8388977050781, Neurons: 11, Grad norm: 1.856e+01\n",
      "Epoch 9187, Loss: 451.8333740234375, Neurons: 11, Grad norm: 3.358e+01\n",
      "Epoch 9188, Loss: 451.827880859375, Neurons: 11, Grad norm: 3.821e+01\n",
      "Epoch 9189, Loss: 451.8223876953125, Neurons: 11, Grad norm: 3.248e+01\n",
      "Epoch 9190, Loss: 451.81683349609375, Neurons: 11, Grad norm: 1.879e+01\n",
      "Epoch 9191, Loss: 451.8111877441406, Neurons: 11, Grad norm: 3.399e+00\n",
      "Epoch 9192, Loss: 451.80560302734375, Neurons: 11, Grad norm: 1.492e+01\n",
      "Epoch 9193, Loss: 451.8000793457031, Neurons: 11, Grad norm: 2.533e+01\n",
      "Epoch 9194, Loss: 451.7945861816406, Neurons: 11, Grad norm: 2.856e+01\n",
      "Epoch 9195, Loss: 451.7890930175781, Neurons: 11, Grad norm: 2.420e+01\n",
      "Epoch 9196, Loss: 451.7835998535156, Neurons: 11, Grad norm: 1.454e+01\n",
      "Epoch 9197, Loss: 451.7779846191406, Neurons: 11, Grad norm: 3.556e+00\n",
      "Epoch 9198, Loss: 451.77239990234375, Neurons: 11, Grad norm: 1.028e+01\n",
      "Epoch 9199, Loss: 451.7668762207031, Neurons: 11, Grad norm: 1.824e+01\n",
      "Epoch 9199, Test loss: 447.77294921875\n",
      "Epoch 9200, Loss: 451.7613830566406, Neurons: 11, Grad norm: 2.106e+01\n",
      "Epoch 9201, Loss: 451.7558898925781, Neurons: 11, Grad norm: 1.882e+01\n",
      "Epoch 9202, Loss: 451.7503967285156, Neurons: 11, Grad norm: 1.232e+01\n",
      "Epoch 9203, Loss: 451.7447814941406, Neurons: 11, Grad norm: 4.543e+00\n",
      "Epoch 9204, Loss: 451.7392883300781, Neurons: 11, Grad norm: 6.153e+00\n",
      "Epoch 9205, Loss: 451.7337951660156, Neurons: 11, Grad norm: 1.211e+01\n",
      "Epoch 9206, Loss: 451.7283020019531, Neurons: 11, Grad norm: 1.527e+01\n",
      "Epoch 9207, Loss: 451.72283935546875, Neurons: 11, Grad norm: 1.468e+01\n",
      "Epoch 9208, Loss: 451.71728515625, Neurons: 11, Grad norm: 1.123e+01\n",
      "Epoch 9209, Loss: 451.7117919921875, Neurons: 11, Grad norm: 5.918e+00\n",
      "Epoch 9210, Loss: 451.706298828125, Neurons: 11, Grad norm: 3.276e+00\n",
      "Epoch 9211, Loss: 451.7007751464844, Neurons: 11, Grad norm: 7.276e+00\n",
      "Epoch 9212, Loss: 451.6952819824219, Neurons: 11, Grad norm: 1.047e+01\n",
      "Epoch 9213, Loss: 451.6897888183594, Neurons: 11, Grad norm: 1.161e+01\n",
      "Epoch 9214, Loss: 451.6842956542969, Neurons: 11, Grad norm: 1.026e+01\n",
      "Epoch 9215, Loss: 451.6788024902344, Neurons: 11, Grad norm: 7.354e+00\n",
      "Epoch 9216, Loss: 451.67327880859375, Neurons: 11, Grad norm: 3.864e+00\n",
      "Epoch 9217, Loss: 451.6678466796875, Neurons: 11, Grad norm: 3.610e+00\n",
      "Epoch 9218, Loss: 451.66229248046875, Neurons: 11, Grad norm: 6.278e+00\n",
      "Epoch 9219, Loss: 451.6568908691406, Neurons: 11, Grad norm: 8.058e+00\n",
      "Epoch 9220, Loss: 451.6513977050781, Neurons: 11, Grad norm: 8.543e+00\n",
      "Epoch 9221, Loss: 451.6458740234375, Neurons: 11, Grad norm: 7.405e+00\n",
      "Epoch 9222, Loss: 451.640380859375, Neurons: 11, Grad norm: 5.496e+00\n",
      "Epoch 9223, Loss: 451.6349792480469, Neurons: 11, Grad norm: 3.454e+00\n",
      "Epoch 9224, Loss: 451.6294860839844, Neurons: 11, Grad norm: 3.317e+00\n",
      "Epoch 9225, Loss: 451.6239929199219, Neurons: 11, Grad norm: 4.855e+00\n",
      "Epoch 9226, Loss: 451.6185302734375, Neurons: 11, Grad norm: 6.002e+00\n",
      "Epoch 9227, Loss: 451.613037109375, Neurons: 11, Grad norm: 6.463e+00\n",
      "Epoch 9228, Loss: 451.6075744628906, Neurons: 11, Grad norm: 5.866e+00\n",
      "Epoch 9229, Loss: 451.6020812988281, Neurons: 11, Grad norm: 4.833e+00\n",
      "Epoch 9230, Loss: 451.5966796875, Neurons: 11, Grad norm: 3.538e+00\n",
      "Epoch 9231, Loss: 451.5911865234375, Neurons: 11, Grad norm: 3.082e+00\n",
      "Epoch 9232, Loss: 451.585693359375, Neurons: 11, Grad norm: 3.716e+00\n",
      "Epoch 9233, Loss: 451.5802917480469, Neurons: 11, Grad norm: 4.540e+00\n",
      "Epoch 9234, Loss: 451.5747985839844, Neurons: 11, Grad norm: 5.189e+00\n",
      "Epoch 9235, Loss: 451.56939697265625, Neurons: 11, Grad norm: 5.096e+00\n",
      "Epoch 9236, Loss: 451.56390380859375, Neurons: 11, Grad norm: 4.723e+00\n",
      "Epoch 9237, Loss: 451.5585021972656, Neurons: 11, Grad norm: 3.949e+00\n",
      "Epoch 9238, Loss: 451.552978515625, Neurons: 11, Grad norm: 3.363e+00\n",
      "Epoch 9239, Loss: 451.5474853515625, Neurons: 11, Grad norm: 3.076e+00\n",
      "Epoch 9240, Loss: 451.5420837402344, Neurons: 11, Grad norm: 3.253e+00\n",
      "Epoch 9241, Loss: 451.5366516113281, Neurons: 11, Grad norm: 3.683e+00\n",
      "Epoch 9242, Loss: 451.53118896484375, Neurons: 11, Grad norm: 3.896e+00\n",
      "Epoch 9243, Loss: 451.5257873535156, Neurons: 11, Grad norm: 4.032e+00\n",
      "Epoch 9244, Loss: 451.5202941894531, Neurons: 11, Grad norm: 3.800e+00\n",
      "Epoch 9245, Loss: 451.514892578125, Neurons: 11, Grad norm: 3.608e+00\n",
      "Epoch 9246, Loss: 451.5094299316406, Neurons: 11, Grad norm: 3.273e+00\n",
      "Epoch 9247, Loss: 451.5039978027344, Neurons: 11, Grad norm: 3.115e+00\n",
      "Epoch 9248, Loss: 451.49853515625, Neurons: 11, Grad norm: 3.087e+00\n",
      "Epoch 9249, Loss: 451.49310302734375, Neurons: 11, Grad norm: 3.153e+00\n",
      "Epoch 9249, Test loss: 447.5199279785156\n",
      "Epoch 9250, Loss: 451.4877014160156, Neurons: 11, Grad norm: 3.303e+00\n",
      "Epoch 9251, Loss: 451.48223876953125, Neurons: 11, Grad norm: 3.344e+00\n",
      "Epoch 9252, Loss: 451.4767761230469, Neurons: 11, Grad norm: 3.432e+00\n",
      "Epoch 9253, Loss: 451.47137451171875, Neurons: 11, Grad norm: 3.336e+00\n",
      "Epoch 9254, Loss: 451.4659423828125, Neurons: 11, Grad norm: 3.299e+00\n",
      "Epoch 9255, Loss: 451.4605407714844, Neurons: 11, Grad norm: 3.154e+00\n",
      "Epoch 9256, Loss: 451.455078125, Neurons: 11, Grad norm: 3.101e+00\n",
      "Epoch 9257, Loss: 451.4496765136719, Neurons: 11, Grad norm: 3.068e+00\n",
      "Epoch 9258, Loss: 451.44427490234375, Neurons: 11, Grad norm: 3.097e+00\n",
      "Epoch 9259, Loss: 451.43890380859375, Neurons: 11, Grad norm: 3.210e+00\n",
      "Epoch 9260, Loss: 451.4333801269531, Neurons: 11, Grad norm: 3.239e+00\n",
      "Epoch 9261, Loss: 451.427978515625, Neurons: 11, Grad norm: 3.331e+00\n",
      "Epoch 9262, Loss: 451.4225769042969, Neurons: 11, Grad norm: 3.277e+00\n",
      "Epoch 9263, Loss: 451.41717529296875, Neurons: 11, Grad norm: 3.290e+00\n",
      "Epoch 9264, Loss: 451.4117431640625, Neurons: 11, Grad norm: 3.183e+00\n",
      "Epoch 9265, Loss: 451.4062805175781, Neurons: 11, Grad norm: 3.160e+00\n",
      "Epoch 9266, Loss: 451.40087890625, Neurons: 11, Grad norm: 3.091e+00\n",
      "Epoch 9267, Loss: 451.3954772949219, Neurons: 11, Grad norm: 3.088e+00\n",
      "Epoch 9268, Loss: 451.39007568359375, Neurons: 11, Grad norm: 3.063e+00\n",
      "Epoch 9269, Loss: 451.3846740722656, Neurons: 11, Grad norm: 3.062e+00\n",
      "Epoch 9270, Loss: 451.3793029785156, Neurons: 11, Grad norm: 3.064e+00\n",
      "Epoch 9271, Loss: 451.3739013671875, Neurons: 11, Grad norm: 3.062e+00\n",
      "Epoch 9272, Loss: 451.3684997558594, Neurons: 11, Grad norm: 3.082e+00\n",
      "Epoch 9273, Loss: 451.36309814453125, Neurons: 11, Grad norm: 3.072e+00\n",
      "Epoch 9274, Loss: 451.3576354980469, Neurons: 11, Grad norm: 3.095e+00\n",
      "Epoch 9275, Loss: 451.352294921875, Neurons: 11, Grad norm: 3.078e+00\n",
      "Epoch 9276, Loss: 451.3468933105469, Neurons: 11, Grad norm: 3.100e+00\n",
      "Epoch 9277, Loss: 451.34149169921875, Neurons: 11, Grad norm: 3.073e+00\n",
      "Epoch 9278, Loss: 451.3360290527344, Neurons: 11, Grad norm: 3.083e+00\n",
      "Epoch 9279, Loss: 451.3306884765625, Neurons: 11, Grad norm: 3.060e+00\n",
      "Epoch 9280, Loss: 451.3252868652344, Neurons: 11, Grad norm: 3.066e+00\n",
      "Epoch 9281, Loss: 451.31982421875, Neurons: 11, Grad norm: 3.055e+00\n",
      "Epoch 9282, Loss: 451.3144836425781, Neurons: 11, Grad norm: 3.060e+00\n",
      "Epoch 9283, Loss: 451.30908203125, Neurons: 11, Grad norm: 3.053e+00\n",
      "Epoch 9284, Loss: 451.3036804199219, Neurons: 11, Grad norm: 3.058e+00\n",
      "Epoch 9285, Loss: 451.29827880859375, Neurons: 11, Grad norm: 3.052e+00\n",
      "Epoch 9286, Loss: 451.2928771972656, Neurons: 11, Grad norm: 3.063e+00\n",
      "Epoch 9287, Loss: 451.28753662109375, Neurons: 11, Grad norm: 3.057e+00\n",
      "Epoch 9288, Loss: 451.2821350097656, Neurons: 11, Grad norm: 3.082e+00\n",
      "Epoch 9289, Loss: 451.27679443359375, Neurons: 11, Grad norm: 3.069e+00\n",
      "Epoch 9290, Loss: 451.2713928222656, Neurons: 11, Grad norm: 3.097e+00\n",
      "Epoch 9291, Loss: 451.2659912109375, Neurons: 11, Grad norm: 3.076e+00\n",
      "Epoch 9292, Loss: 451.2605895996094, Neurons: 11, Grad norm: 3.107e+00\n",
      "Epoch 9293, Loss: 451.2552490234375, Neurons: 11, Grad norm: 3.082e+00\n",
      "Epoch 9294, Loss: 451.2498779296875, Neurons: 11, Grad norm: 3.116e+00\n",
      "Epoch 9295, Loss: 451.2444763183594, Neurons: 11, Grad norm: 3.087e+00\n",
      "Epoch 9296, Loss: 451.23907470703125, Neurons: 11, Grad norm: 3.110e+00\n",
      "Epoch 9297, Loss: 451.23370361328125, Neurons: 11, Grad norm: 3.073e+00\n",
      "Epoch 9298, Loss: 451.2283935546875, Neurons: 11, Grad norm: 3.096e+00\n",
      "Epoch 9299, Loss: 451.2229919433594, Neurons: 11, Grad norm: 3.066e+00\n",
      "Epoch 9299, Test loss: 447.26275634765625\n",
      "Epoch 9300, Loss: 451.21759033203125, Neurons: 11, Grad norm: 3.089e+00\n",
      "Epoch 9301, Loss: 451.2122497558594, Neurons: 11, Grad norm: 3.070e+00\n",
      "Epoch 9302, Loss: 451.206787109375, Neurons: 11, Grad norm: 3.113e+00\n",
      "Epoch 9303, Loss: 451.20147705078125, Neurons: 11, Grad norm: 3.100e+00\n",
      "Epoch 9304, Loss: 451.1960754394531, Neurons: 11, Grad norm: 3.156e+00\n",
      "Epoch 9305, Loss: 451.19073486328125, Neurons: 11, Grad norm: 3.127e+00\n",
      "Epoch 9306, Loss: 451.1853332519531, Neurons: 11, Grad norm: 3.195e+00\n",
      "Epoch 9307, Loss: 451.17999267578125, Neurons: 11, Grad norm: 3.183e+00\n",
      "Epoch 9308, Loss: 451.1746520996094, Neurons: 11, Grad norm: 3.313e+00\n",
      "Epoch 9309, Loss: 451.1692810058594, Neurons: 11, Grad norm: 3.333e+00\n",
      "Epoch 9310, Loss: 451.16387939453125, Neurons: 11, Grad norm: 3.551e+00\n",
      "Epoch 9311, Loss: 451.1585998535156, Neurons: 11, Grad norm: 3.670e+00\n",
      "Epoch 9312, Loss: 451.1531982421875, Neurons: 11, Grad norm: 4.057e+00\n",
      "Epoch 9313, Loss: 451.1477966308594, Neurons: 11, Grad norm: 4.275e+00\n",
      "Epoch 9314, Loss: 451.1424865722656, Neurons: 11, Grad norm: 4.880e+00\n",
      "Epoch 9315, Loss: 451.1370849609375, Neurons: 11, Grad norm: 5.421e+00\n",
      "Epoch 9316, Loss: 451.13177490234375, Neurons: 11, Grad norm: 6.543e+00\n",
      "Epoch 9317, Loss: 451.12640380859375, Neurons: 11, Grad norm: 7.686e+00\n",
      "Epoch 9318, Loss: 451.1210021972656, Neurons: 11, Grad norm: 9.573e+00\n",
      "Epoch 9319, Loss: 451.1156921386719, Neurons: 11, Grad norm: 1.161e+01\n",
      "Epoch 9320, Loss: 451.1103515625, Neurons: 11, Grad norm: 1.463e+01\n",
      "Epoch 9321, Loss: 451.10498046875, Neurons: 11, Grad norm: 1.811e+01\n",
      "Epoch 9322, Loss: 451.0996398925781, Neurons: 11, Grad norm: 2.303e+01\n",
      "Epoch 9323, Loss: 451.0943298339844, Neurons: 11, Grad norm: 2.906e+01\n",
      "Epoch 9324, Loss: 451.08905029296875, Neurons: 11, Grad norm: 3.739e+01\n",
      "Epoch 9325, Loss: 451.083740234375, Neurons: 11, Grad norm: 4.780e+01\n",
      "Epoch 9326, Loss: 451.0784912109375, Neurons: 11, Grad norm: 6.171e+01\n",
      "Epoch 9327, Loss: 451.0733947753906, Neurons: 11, Grad norm: 7.916e+01\n",
      "Epoch 9328, Loss: 451.0683898925781, Neurons: 11, Grad norm: 1.017e+02\n",
      "Epoch 9329, Loss: 451.0635986328125, Neurons: 11, Grad norm: 1.288e+02\n",
      "Epoch 9330, Loss: 451.05908203125, Neurons: 11, Grad norm: 1.607e+02\n",
      "Epoch 9331, Loss: 451.05499267578125, Neurons: 11, Grad norm: 1.933e+02\n",
      "Epoch 9332, Loss: 451.0512390136719, Neurons: 11, Grad norm: 2.204e+02\n",
      "Epoch 9333, Loss: 451.04754638671875, Neurons: 11, Grad norm: 2.295e+02\n",
      "Epoch 9334, Loss: 451.0428771972656, Neurons: 11, Grad norm: 2.092e+02\n",
      "Epoch 9335, Loss: 451.03668212890625, Neurons: 11, Grad norm: 1.529e+02\n",
      "Epoch 9336, Loss: 451.02899169921875, Neurons: 11, Grad norm: 6.999e+01\n",
      "Epoch 9337, Loss: 451.0216979980469, Neurons: 11, Grad norm: 2.136e+01\n",
      "Epoch 9338, Loss: 451.0160827636719, Neurons: 11, Grad norm: 9.800e+01\n",
      "Epoch 9339, Loss: 451.0122985839844, Neurons: 11, Grad norm: 1.445e+02\n",
      "Epoch 9340, Loss: 451.0087890625, Neurons: 11, Grad norm: 1.499e+02\n",
      "Epoch 9341, Loss: 451.0040283203125, Neurons: 11, Grad norm: 1.151e+02\n",
      "Epoch 9342, Loss: 450.9979248046875, Neurons: 11, Grad norm: 5.065e+01\n",
      "Epoch 9343, Loss: 450.99169921875, Neurons: 11, Grad norm: 2.205e+01\n",
      "Epoch 9344, Loss: 450.9864807128906, Neurons: 11, Grad norm: 8.121e+01\n",
      "Epoch 9345, Loss: 450.9823913574219, Neurons: 11, Grad norm: 1.106e+02\n",
      "Epoch 9346, Loss: 450.9782409667969, Neurons: 11, Grad norm: 1.044e+02\n",
      "Epoch 9347, Loss: 450.9731750488281, Neurons: 11, Grad norm: 6.636e+01\n",
      "Epoch 9348, Loss: 450.9674987792969, Neurons: 11, Grad norm: 1.207e+01\n",
      "Epoch 9349, Loss: 450.96209716796875, Neurons: 11, Grad norm: 4.164e+01\n",
      "Epoch 9349, Test loss: 447.00213623046875\n",
      "Epoch 9350, Loss: 450.9573974609375, Neurons: 11, Grad norm: 7.616e+01\n",
      "Epoch 9351, Loss: 450.9530944824219, Neurons: 11, Grad norm: 8.387e+01\n",
      "Epoch 9352, Loss: 450.9483947753906, Neurons: 11, Grad norm: 6.381e+01\n",
      "Epoch 9353, Loss: 450.94317626953125, Neurons: 11, Grad norm: 2.587e+01\n",
      "Epoch 9354, Loss: 450.9378967285156, Neurons: 11, Grad norm: 1.738e+01\n",
      "Epoch 9355, Loss: 450.9329833984375, Neurons: 11, Grad norm: 4.990e+01\n",
      "Epoch 9356, Loss: 450.9284973144531, Neurons: 11, Grad norm: 6.393e+01\n",
      "Epoch 9357, Loss: 450.923828125, Neurons: 11, Grad norm: 5.585e+01\n",
      "Epoch 9358, Loss: 450.91888427734375, Neurons: 11, Grad norm: 3.132e+01\n",
      "Epoch 9359, Loss: 450.9137878417969, Neurons: 11, Grad norm: 3.232e+00\n",
      "Epoch 9360, Loss: 450.90887451171875, Neurons: 11, Grad norm: 2.991e+01\n",
      "Epoch 9361, Loss: 450.9041442871094, Neurons: 11, Grad norm: 4.656e+01\n",
      "Epoch 9362, Loss: 450.89947509765625, Neurons: 11, Grad norm: 4.653e+01\n",
      "Epoch 9363, Loss: 450.8946838378906, Neurons: 11, Grad norm: 3.249e+01\n",
      "Epoch 9364, Loss: 450.8897399902344, Neurons: 11, Grad norm: 9.637e+00\n",
      "Epoch 9365, Loss: 450.88482666015625, Neurons: 11, Grad norm: 1.436e+01\n",
      "Epoch 9366, Loss: 450.8799743652344, Neurons: 11, Grad norm: 3.128e+01\n",
      "Epoch 9367, Loss: 450.8752746582031, Neurons: 11, Grad norm: 3.664e+01\n",
      "Epoch 9368, Loss: 450.8704833984375, Neurons: 11, Grad norm: 3.089e+01\n",
      "Epoch 9369, Loss: 450.8656921386719, Neurons: 11, Grad norm: 1.600e+01\n",
      "Epoch 9370, Loss: 450.86077880859375, Neurons: 11, Grad norm: 3.591e+00\n",
      "Epoch 9371, Loss: 450.8559265136719, Neurons: 11, Grad norm: 1.816e+01\n",
      "Epoch 9372, Loss: 450.8511962890625, Neurons: 11, Grad norm: 2.657e+01\n",
      "Epoch 9373, Loss: 450.84637451171875, Neurons: 11, Grad norm: 2.691e+01\n",
      "Epoch 9374, Loss: 450.8415832519531, Neurons: 11, Grad norm: 1.892e+01\n",
      "Epoch 9375, Loss: 450.8367919921875, Neurons: 11, Grad norm: 7.119e+00\n",
      "Epoch 9376, Loss: 450.8319396972656, Neurons: 11, Grad norm: 7.454e+00\n",
      "Epoch 9377, Loss: 450.8271789550781, Neurons: 11, Grad norm: 1.662e+01\n",
      "Epoch 9378, Loss: 450.8223876953125, Neurons: 11, Grad norm: 2.095e+01\n",
      "Epoch 9379, Loss: 450.8175964355469, Neurons: 11, Grad norm: 1.853e+01\n",
      "Epoch 9380, Loss: 450.812744140625, Neurons: 11, Grad norm: 1.180e+01\n",
      "Epoch 9381, Loss: 450.8079833984375, Neurons: 11, Grad norm: 3.330e+00\n",
      "Epoch 9382, Loss: 450.8031921386719, Neurons: 11, Grad norm: 7.843e+00\n",
      "Epoch 9383, Loss: 450.79833984375, Neurons: 11, Grad norm: 1.408e+01\n",
      "Epoch 9384, Loss: 450.7935791015625, Neurons: 11, Grad norm: 1.566e+01\n",
      "Epoch 9385, Loss: 450.7887878417969, Neurons: 11, Grad norm: 1.351e+01\n",
      "Epoch 9386, Loss: 450.78399658203125, Neurons: 11, Grad norm: 7.760e+00\n",
      "Epoch 9387, Loss: 450.7791748046875, Neurons: 11, Grad norm: 2.970e+00\n",
      "Epoch 9388, Loss: 450.7743835449219, Neurons: 11, Grad norm: 6.879e+00\n",
      "Epoch 9389, Loss: 450.76959228515625, Neurons: 11, Grad norm: 1.050e+01\n",
      "Epoch 9390, Loss: 450.7648010253906, Neurons: 11, Grad norm: 1.184e+01\n",
      "Epoch 9391, Loss: 450.7601013183594, Neurons: 11, Grad norm: 9.716e+00\n",
      "Epoch 9392, Loss: 450.75518798828125, Neurons: 11, Grad norm: 6.164e+00\n",
      "Epoch 9393, Loss: 450.75042724609375, Neurons: 11, Grad norm: 2.935e+00\n",
      "Epoch 9394, Loss: 450.7456359863281, Neurons: 11, Grad norm: 5.097e+00\n",
      "Epoch 9395, Loss: 450.7408447265625, Neurons: 11, Grad norm: 8.052e+00\n",
      "Epoch 9396, Loss: 450.7360534667969, Neurons: 11, Grad norm: 8.651e+00\n",
      "Epoch 9397, Loss: 450.7312927246094, Neurons: 11, Grad norm: 7.881e+00\n",
      "Epoch 9398, Loss: 450.72650146484375, Neurons: 11, Grad norm: 5.223e+00\n",
      "Epoch 9399, Loss: 450.7216796875, Neurons: 11, Grad norm: 3.144e+00\n",
      "Epoch 9399, Test loss: 446.7842712402344\n",
      "Epoch 9400, Loss: 450.7168884277344, Neurons: 11, Grad norm: 3.862e+00\n",
      "Epoch 9401, Loss: 450.71209716796875, Neurons: 11, Grad norm: 5.518e+00\n",
      "Epoch 9402, Loss: 450.707275390625, Neurons: 11, Grad norm: 6.759e+00\n",
      "Epoch 9403, Loss: 450.70257568359375, Neurons: 11, Grad norm: 6.180e+00\n",
      "Epoch 9404, Loss: 450.6977233886719, Neurons: 11, Grad norm: 5.137e+00\n",
      "Epoch 9405, Loss: 450.69293212890625, Neurons: 11, Grad norm: 3.375e+00\n",
      "Epoch 9406, Loss: 450.6882019042969, Neurons: 11, Grad norm: 2.962e+00\n",
      "Epoch 9407, Loss: 450.6833801269531, Neurons: 11, Grad norm: 4.060e+00\n",
      "Epoch 9408, Loss: 450.6785888671875, Neurons: 11, Grad norm: 4.785e+00\n",
      "Epoch 9409, Loss: 450.673828125, Neurons: 11, Grad norm: 5.287e+00\n",
      "Epoch 9410, Loss: 450.6690979003906, Neurons: 11, Grad norm: 4.549e+00\n",
      "Epoch 9411, Loss: 450.6642761230469, Neurons: 11, Grad norm: 3.871e+00\n",
      "Epoch 9412, Loss: 450.65948486328125, Neurons: 11, Grad norm: 3.001e+00\n",
      "Epoch 9413, Loss: 450.6546936035156, Neurons: 11, Grad norm: 2.981e+00\n",
      "Epoch 9414, Loss: 450.64990234375, Neurons: 11, Grad norm: 3.597e+00\n",
      "Epoch 9415, Loss: 450.64508056640625, Neurons: 11, Grad norm: 3.859e+00\n",
      "Epoch 9416, Loss: 450.6402893066406, Neurons: 11, Grad norm: 4.152e+00\n",
      "Epoch 9417, Loss: 450.6355895996094, Neurons: 11, Grad norm: 3.612e+00\n",
      "Epoch 9418, Loss: 450.63079833984375, Neurons: 11, Grad norm: 3.326e+00\n",
      "Epoch 9419, Loss: 450.6259765625, Neurons: 11, Grad norm: 2.937e+00\n",
      "Epoch 9420, Loss: 450.6212463378906, Neurons: 11, Grad norm: 2.955e+00\n",
      "Epoch 9421, Loss: 450.61639404296875, Neurons: 11, Grad norm: 3.323e+00\n",
      "Epoch 9422, Loss: 450.61163330078125, Neurons: 11, Grad norm: 3.405e+00\n",
      "Epoch 9423, Loss: 450.6069030761719, Neurons: 11, Grad norm: 3.626e+00\n",
      "Epoch 9424, Loss: 450.6020812988281, Neurons: 11, Grad norm: 3.295e+00\n",
      "Epoch 9425, Loss: 450.5972900390625, Neurons: 11, Grad norm: 3.181e+00\n",
      "Epoch 9426, Loss: 450.5924987792969, Neurons: 11, Grad norm: 2.928e+00\n",
      "Epoch 9427, Loss: 450.5876770019531, Neurons: 11, Grad norm: 2.927e+00\n",
      "Epoch 9428, Loss: 450.5829772949219, Neurons: 11, Grad norm: 3.135e+00\n",
      "Epoch 9429, Loss: 450.57818603515625, Neurons: 11, Grad norm: 3.169e+00\n",
      "Epoch 9430, Loss: 450.5733947753906, Neurons: 11, Grad norm: 3.396e+00\n",
      "Epoch 9431, Loss: 450.5686340332031, Neurons: 11, Grad norm: 3.201e+00\n",
      "Epoch 9432, Loss: 450.56390380859375, Neurons: 11, Grad norm: 3.202e+00\n",
      "Epoch 9433, Loss: 450.55908203125, Neurons: 11, Grad norm: 2.975e+00\n",
      "Epoch 9434, Loss: 450.5542907714844, Neurons: 11, Grad norm: 2.961e+00\n",
      "Epoch 9435, Loss: 450.54949951171875, Neurons: 11, Grad norm: 2.922e+00\n",
      "Epoch 9436, Loss: 450.54473876953125, Neurons: 11, Grad norm: 2.921e+00\n",
      "Epoch 9437, Loss: 450.5399475097656, Neurons: 11, Grad norm: 3.014e+00\n",
      "Epoch 9438, Loss: 450.5351867675781, Neurons: 11, Grad norm: 2.979e+00\n",
      "Epoch 9439, Loss: 450.5303955078125, Neurons: 11, Grad norm: 3.095e+00\n",
      "Epoch 9440, Loss: 450.52557373046875, Neurons: 11, Grad norm: 2.992e+00\n",
      "Epoch 9441, Loss: 450.5208435058594, Neurons: 11, Grad norm: 3.039e+00\n",
      "Epoch 9442, Loss: 450.5160827636719, Neurons: 11, Grad norm: 2.932e+00\n",
      "Epoch 9443, Loss: 450.51129150390625, Neurons: 11, Grad norm: 2.951e+00\n",
      "Epoch 9444, Loss: 450.50653076171875, Neurons: 11, Grad norm: 2.913e+00\n",
      "Epoch 9445, Loss: 450.5018005371094, Neurons: 11, Grad norm: 2.911e+00\n",
      "Epoch 9446, Loss: 450.4969787597656, Neurons: 11, Grad norm: 2.970e+00\n",
      "Epoch 9447, Loss: 450.4921875, Neurons: 11, Grad norm: 2.935e+00\n",
      "Epoch 9448, Loss: 450.4873962402344, Neurons: 11, Grad norm: 3.004e+00\n",
      "Epoch 9449, Loss: 450.4826354980469, Neurons: 11, Grad norm: 2.930e+00\n",
      "Epoch 9449, Test loss: 446.55438232421875\n",
      "Epoch 9450, Loss: 450.4778747558594, Neurons: 11, Grad norm: 2.972e+00\n",
      "Epoch 9451, Loss: 450.47308349609375, Neurons: 11, Grad norm: 2.918e+00\n",
      "Epoch 9452, Loss: 450.4682922363281, Neurons: 11, Grad norm: 2.965e+00\n",
      "Epoch 9453, Loss: 450.4635314941406, Neurons: 11, Grad norm: 2.915e+00\n",
      "Epoch 9454, Loss: 450.458740234375, Neurons: 11, Grad norm: 2.951e+00\n",
      "Epoch 9455, Loss: 450.4539794921875, Neurons: 11, Grad norm: 2.908e+00\n",
      "Epoch 9456, Loss: 450.4491882324219, Neurons: 11, Grad norm: 2.930e+00\n",
      "Epoch 9457, Loss: 450.44439697265625, Neurons: 11, Grad norm: 2.905e+00\n",
      "Epoch 9458, Loss: 450.43963623046875, Neurons: 11, Grad norm: 2.917e+00\n",
      "Epoch 9459, Loss: 450.43487548828125, Neurons: 11, Grad norm: 2.905e+00\n",
      "Epoch 9460, Loss: 450.4300842285156, Neurons: 11, Grad norm: 2.914e+00\n",
      "Epoch 9461, Loss: 450.4253234863281, Neurons: 11, Grad norm: 2.905e+00\n",
      "Epoch 9462, Loss: 450.42059326171875, Neurons: 11, Grad norm: 2.919e+00\n",
      "Epoch 9463, Loss: 450.4158020019531, Neurons: 11, Grad norm: 2.902e+00\n",
      "Epoch 9464, Loss: 450.4109802246094, Neurons: 11, Grad norm: 2.943e+00\n",
      "Epoch 9465, Loss: 450.40618896484375, Neurons: 11, Grad norm: 2.910e+00\n",
      "Epoch 9466, Loss: 450.40142822265625, Neurons: 11, Grad norm: 2.962e+00\n",
      "Epoch 9467, Loss: 450.3966979980469, Neurons: 11, Grad norm: 2.909e+00\n",
      "Epoch 9468, Loss: 450.3918762207031, Neurons: 11, Grad norm: 2.958e+00\n",
      "Epoch 9469, Loss: 450.3871765136719, Neurons: 11, Grad norm: 2.914e+00\n",
      "Epoch 9470, Loss: 450.38232421875, Neurons: 11, Grad norm: 2.982e+00\n",
      "Epoch 9471, Loss: 450.3775939941406, Neurons: 11, Grad norm: 2.918e+00\n",
      "Epoch 9472, Loss: 450.372802734375, Neurons: 11, Grad norm: 2.967e+00\n",
      "Epoch 9473, Loss: 450.36810302734375, Neurons: 11, Grad norm: 2.907e+00\n",
      "Epoch 9474, Loss: 450.3632507324219, Neurons: 11, Grad norm: 2.952e+00\n",
      "Epoch 9475, Loss: 450.3584899902344, Neurons: 11, Grad norm: 2.904e+00\n",
      "Epoch 9476, Loss: 450.35369873046875, Neurons: 11, Grad norm: 2.951e+00\n",
      "Epoch 9477, Loss: 450.34893798828125, Neurons: 11, Grad norm: 2.898e+00\n",
      "Epoch 9478, Loss: 450.34417724609375, Neurons: 11, Grad norm: 2.918e+00\n",
      "Epoch 9479, Loss: 450.3393859863281, Neurons: 11, Grad norm: 2.896e+00\n",
      "Epoch 9480, Loss: 450.3345947265625, Neurons: 11, Grad norm: 2.897e+00\n",
      "Epoch 9481, Loss: 450.32989501953125, Neurons: 11, Grad norm: 2.908e+00\n",
      "Epoch 9482, Loss: 450.3251037597656, Neurons: 11, Grad norm: 2.892e+00\n",
      "Epoch 9483, Loss: 450.3202819824219, Neurons: 11, Grad norm: 2.928e+00\n",
      "Epoch 9484, Loss: 450.3155517578125, Neurons: 11, Grad norm: 2.897e+00\n",
      "Epoch 9485, Loss: 450.310791015625, Neurons: 11, Grad norm: 2.958e+00\n",
      "Epoch 9486, Loss: 450.3059997558594, Neurons: 11, Grad norm: 2.908e+00\n",
      "Epoch 9487, Loss: 450.3012390136719, Neurons: 11, Grad norm: 2.970e+00\n",
      "Epoch 9488, Loss: 450.29644775390625, Neurons: 11, Grad norm: 2.900e+00\n",
      "Epoch 9489, Loss: 450.29168701171875, Neurons: 11, Grad norm: 2.935e+00\n",
      "Epoch 9490, Loss: 450.2868957519531, Neurons: 11, Grad norm: 2.889e+00\n",
      "Epoch 9491, Loss: 450.2821350097656, Neurons: 11, Grad norm: 2.914e+00\n",
      "Epoch 9492, Loss: 450.2773742675781, Neurons: 11, Grad norm: 2.887e+00\n",
      "Epoch 9493, Loss: 450.2725830078125, Neurons: 11, Grad norm: 2.913e+00\n",
      "Epoch 9494, Loss: 450.2677917480469, Neurons: 11, Grad norm: 2.886e+00\n",
      "Epoch 9495, Loss: 450.2630920410156, Neurons: 11, Grad norm: 2.914e+00\n",
      "Epoch 9496, Loss: 450.25830078125, Neurons: 11, Grad norm: 2.887e+00\n",
      "Epoch 9497, Loss: 450.25347900390625, Neurons: 11, Grad norm: 2.935e+00\n",
      "Epoch 9498, Loss: 450.2487487792969, Neurons: 11, Grad norm: 2.897e+00\n",
      "Epoch 9499, Loss: 450.2439880371094, Neurons: 11, Grad norm: 2.982e+00\n",
      "Epoch 9499, Test loss: 446.3227844238281\n",
      "Epoch 9500, Loss: 450.23919677734375, Neurons: 11, Grad norm: 2.934e+00\n",
      "Epoch 9501, Loss: 450.23443603515625, Neurons: 11, Grad norm: 3.098e+00\n",
      "Epoch 9502, Loss: 450.2296447753906, Neurons: 11, Grad norm: 3.048e+00\n",
      "Epoch 9503, Loss: 450.2248840332031, Neurons: 11, Grad norm: 3.308e+00\n",
      "Epoch 9504, Loss: 450.2200927734375, Neurons: 11, Grad norm: 3.263e+00\n",
      "Epoch 9505, Loss: 450.21539306640625, Neurons: 11, Grad norm: 3.649e+00\n",
      "Epoch 9506, Loss: 450.2106018066406, Neurons: 11, Grad norm: 3.693e+00\n",
      "Epoch 9507, Loss: 450.2057800292969, Neurons: 11, Grad norm: 4.395e+00\n",
      "Epoch 9508, Loss: 450.20098876953125, Neurons: 11, Grad norm: 4.712e+00\n",
      "Epoch 9509, Loss: 450.19622802734375, Neurons: 11, Grad norm: 5.801e+00\n",
      "Epoch 9510, Loss: 450.1914978027344, Neurons: 11, Grad norm: 6.488e+00\n",
      "Epoch 9511, Loss: 450.1866760253906, Neurons: 11, Grad norm: 8.223e+00\n",
      "Epoch 9512, Loss: 450.18194580078125, Neurons: 11, Grad norm: 9.648e+00\n",
      "Epoch 9513, Loss: 450.17718505859375, Neurons: 11, Grad norm: 1.227e+01\n",
      "Epoch 9514, Loss: 450.1723937988281, Neurons: 11, Grad norm: 1.481e+01\n",
      "Epoch 9515, Loss: 450.1676940917969, Neurons: 11, Grad norm: 1.894e+01\n",
      "Epoch 9516, Loss: 450.16290283203125, Neurons: 11, Grad norm: 2.339e+01\n",
      "Epoch 9517, Loss: 450.15814208984375, Neurons: 11, Grad norm: 2.995e+01\n",
      "Epoch 9518, Loss: 450.15338134765625, Neurons: 11, Grad norm: 3.749e+01\n",
      "Epoch 9519, Loss: 450.148681640625, Neurons: 11, Grad norm: 4.803e+01\n",
      "Epoch 9520, Loss: 450.1440734863281, Neurons: 11, Grad norm: 6.066e+01\n",
      "Epoch 9521, Loss: 450.1394348144531, Neurons: 11, Grad norm: 7.771e+01\n",
      "Epoch 9522, Loss: 450.1349792480469, Neurons: 11, Grad norm: 9.829e+01\n",
      "Epoch 9523, Loss: 450.1307373046875, Neurons: 11, Grad norm: 1.244e+02\n",
      "Epoch 9524, Loss: 450.1266784667969, Neurons: 11, Grad norm: 1.541e+02\n",
      "Epoch 9525, Loss: 450.12298583984375, Neurons: 11, Grad norm: 1.869e+02\n",
      "Epoch 9526, Loss: 450.11968994140625, Neurons: 11, Grad norm: 2.156e+02\n",
      "Epoch 9527, Loss: 450.1164855957031, Neurons: 11, Grad norm: 2.327e+02\n",
      "Epoch 9528, Loss: 450.11279296875, Neurons: 11, Grad norm: 2.244e+02\n",
      "Epoch 9529, Loss: 450.1077880859375, Neurons: 11, Grad norm: 1.844e+02\n",
      "Epoch 9530, Loss: 450.1011962890625, Neurons: 11, Grad norm: 1.125e+02\n",
      "Epoch 9531, Loss: 450.0941467285156, Neurons: 11, Grad norm: 2.485e+01\n",
      "Epoch 9532, Loss: 450.08819580078125, Neurons: 11, Grad norm: 6.060e+01\n",
      "Epoch 9533, Loss: 450.0840759277344, Neurons: 11, Grad norm: 1.234e+02\n",
      "Epoch 9534, Loss: 450.0810852050781, Neurons: 11, Grad norm: 1.530e+02\n",
      "Epoch 9535, Loss: 450.07757568359375, Neurons: 11, Grad norm: 1.422e+02\n",
      "Epoch 9536, Loss: 450.0728454589844, Neurons: 11, Grad norm: 9.674e+01\n",
      "Epoch 9537, Loss: 450.06707763671875, Neurons: 11, Grad norm: 2.911e+01\n",
      "Epoch 9538, Loss: 450.06158447265625, Neurons: 11, Grad norm: 3.932e+01\n",
      "Epoch 9539, Loss: 450.0572814941406, Neurons: 11, Grad norm: 9.080e+01\n",
      "Epoch 9540, Loss: 450.0537414550781, Neurons: 11, Grad norm: 1.116e+02\n",
      "Epoch 9541, Loss: 450.0498962402344, Neurons: 11, Grad norm: 9.993e+01\n",
      "Epoch 9542, Loss: 450.0451965332031, Neurons: 11, Grad norm: 5.990e+01\n",
      "Epoch 9543, Loss: 450.04010009765625, Neurons: 11, Grad norm: 7.635e+00\n",
      "Epoch 9544, Loss: 450.0352478027344, Neurons: 11, Grad norm: 4.338e+01\n",
      "Epoch 9545, Loss: 450.0310974121094, Neurons: 11, Grad norm: 7.541e+01\n",
      "Epoch 9546, Loss: 450.0271911621094, Neurons: 11, Grad norm: 8.322e+01\n",
      "Epoch 9547, Loss: 450.0229797363281, Neurons: 11, Grad norm: 6.510e+01\n",
      "Epoch 9548, Loss: 450.0184020996094, Neurons: 11, Grad norm: 3.049e+01\n",
      "Epoch 9549, Loss: 450.0135803222656, Neurons: 11, Grad norm: 1.098e+01\n",
      "Epoch 9549, Test loss: 446.0965270996094\n",
      "Epoch 9550, Loss: 450.0091247558594, Neurons: 11, Grad norm: 4.374e+01\n",
      "Epoch 9551, Loss: 450.0049743652344, Neurons: 11, Grad norm: 6.154e+01\n",
      "Epoch 9552, Loss: 450.0008850097656, Neurons: 11, Grad norm: 5.880e+01\n",
      "Epoch 9553, Loss: 449.9965515136719, Neurons: 11, Grad norm: 4.003e+01\n",
      "Epoch 9554, Loss: 449.991943359375, Neurons: 11, Grad norm: 1.090e+01\n",
      "Epoch 9555, Loss: 449.9873962402344, Neurons: 11, Grad norm: 1.836e+01\n",
      "Epoch 9556, Loss: 449.98309326171875, Neurons: 11, Grad norm: 3.964e+01\n",
      "Epoch 9557, Loss: 449.9788818359375, Neurons: 11, Grad norm: 4.670e+01\n",
      "Epoch 9558, Loss: 449.9747009277344, Neurons: 11, Grad norm: 4.057e+01\n",
      "Epoch 9559, Loss: 449.97027587890625, Neurons: 11, Grad norm: 2.267e+01\n",
      "Epoch 9560, Loss: 449.9657897949219, Neurons: 11, Grad norm: 2.904e+00\n",
      "Epoch 9561, Loss: 449.9613952636719, Neurons: 11, Grad norm: 2.012e+01\n",
      "Epoch 9562, Loss: 449.95709228515625, Neurons: 11, Grad norm: 3.221e+01\n",
      "Epoch 9563, Loss: 449.9528503417969, Neurons: 11, Grad norm: 3.512e+01\n",
      "Epoch 9564, Loss: 449.94854736328125, Neurons: 11, Grad norm: 2.726e+01\n",
      "Epoch 9565, Loss: 449.9441833496094, Neurons: 11, Grad norm: 1.374e+01\n",
      "Epoch 9566, Loss: 449.9397888183594, Neurons: 11, Grad norm: 4.415e+00\n",
      "Epoch 9567, Loss: 449.9354248046875, Neurons: 11, Grad norm: 1.709e+01\n",
      "Epoch 9568, Loss: 449.93109130859375, Neurons: 11, Grad norm: 2.545e+01\n",
      "Epoch 9569, Loss: 449.9267883300781, Neurons: 11, Grad norm: 2.546e+01\n",
      "Epoch 9570, Loss: 449.9224853515625, Neurons: 11, Grad norm: 1.970e+01\n",
      "Epoch 9571, Loss: 449.9180908203125, Neurons: 11, Grad norm: 8.745e+00\n",
      "Epoch 9572, Loss: 449.9137878417969, Neurons: 11, Grad norm: 4.228e+00\n",
      "Epoch 9573, Loss: 449.9093933105469, Neurons: 11, Grad norm: 1.384e+01\n",
      "Epoch 9574, Loss: 449.90509033203125, Neurons: 11, Grad norm: 1.880e+01\n",
      "Epoch 9575, Loss: 449.9007873535156, Neurons: 11, Grad norm: 1.949e+01\n",
      "Epoch 9576, Loss: 449.8964538574219, Neurons: 11, Grad norm: 1.445e+01\n",
      "Epoch 9577, Loss: 449.89208984375, Neurons: 11, Grad norm: 7.489e+00\n",
      "Epoch 9578, Loss: 449.8877868652344, Neurons: 11, Grad norm: 3.497e+00\n",
      "Epoch 9579, Loss: 449.8834533691406, Neurons: 11, Grad norm: 9.337e+00\n",
      "Epoch 9580, Loss: 449.87908935546875, Neurons: 11, Grad norm: 1.406e+01\n",
      "Epoch 9581, Loss: 449.8747863769531, Neurons: 11, Grad norm: 1.426e+01\n",
      "Epoch 9582, Loss: 449.8704833984375, Neurons: 11, Grad norm: 1.205e+01\n",
      "Epoch 9583, Loss: 449.8660888671875, Neurons: 11, Grad norm: 6.712e+00\n",
      "Epoch 9584, Loss: 449.8617858886719, Neurons: 11, Grad norm: 2.844e+00\n",
      "Epoch 9585, Loss: 449.85748291015625, Neurons: 11, Grad norm: 6.178e+00\n",
      "Epoch 9586, Loss: 449.85308837890625, Neurons: 11, Grad norm: 9.313e+00\n",
      "Epoch 9587, Loss: 449.8487854003906, Neurons: 11, Grad norm: 1.124e+01\n",
      "Epoch 9588, Loss: 449.844482421875, Neurons: 11, Grad norm: 9.791e+00\n",
      "Epoch 9589, Loss: 449.84014892578125, Neurons: 11, Grad norm: 7.361e+00\n",
      "Epoch 9590, Loss: 449.8357849121094, Neurons: 11, Grad norm: 3.482e+00\n",
      "Epoch 9591, Loss: 449.83148193359375, Neurons: 11, Grad norm: 3.311e+00\n",
      "Epoch 9592, Loss: 449.82708740234375, Neurons: 11, Grad norm: 6.410e+00\n",
      "Epoch 9593, Loss: 449.8227844238281, Neurons: 11, Grad norm: 7.775e+00\n",
      "Epoch 9594, Loss: 449.8184814453125, Neurons: 11, Grad norm: 8.432e+00\n",
      "Epoch 9595, Loss: 449.8140869140625, Neurons: 11, Grad norm: 6.657e+00\n",
      "Epoch 9596, Loss: 449.8097839355469, Neurons: 11, Grad norm: 4.885e+00\n",
      "Epoch 9597, Loss: 449.80548095703125, Neurons: 11, Grad norm: 2.833e+00\n",
      "Epoch 9598, Loss: 449.80108642578125, Neurons: 11, Grad norm: 3.353e+00\n",
      "Epoch 9599, Loss: 449.7967834472656, Neurons: 11, Grad norm: 5.292e+00\n",
      "Epoch 9599, Test loss: 445.8871154785156\n",
      "Epoch 9600, Loss: 449.79248046875, Neurons: 11, Grad norm: 5.792e+00\n",
      "Epoch 9601, Loss: 449.78814697265625, Neurons: 11, Grad norm: 6.189e+00\n",
      "Epoch 9602, Loss: 449.7837829589844, Neurons: 11, Grad norm: 4.876e+00\n",
      "Epoch 9603, Loss: 449.77947998046875, Neurons: 11, Grad norm: 3.975e+00\n",
      "Epoch 9604, Loss: 449.775146484375, Neurons: 11, Grad norm: 2.817e+00\n",
      "Epoch 9605, Loss: 449.7707824707031, Neurons: 11, Grad norm: 2.936e+00\n",
      "Epoch 9606, Loss: 449.7664794921875, Neurons: 11, Grad norm: 3.978e+00\n",
      "Epoch 9607, Loss: 449.76214599609375, Neurons: 11, Grad norm: 4.205e+00\n",
      "Epoch 9608, Loss: 449.7577819824219, Neurons: 11, Grad norm: 4.687e+00\n",
      "Epoch 9609, Loss: 449.75347900390625, Neurons: 11, Grad norm: 3.883e+00\n",
      "Epoch 9610, Loss: 449.7491455078125, Neurons: 11, Grad norm: 3.580e+00\n",
      "Epoch 9611, Loss: 449.7447814941406, Neurons: 11, Grad norm: 2.848e+00\n",
      "Epoch 9612, Loss: 449.7404479980469, Neurons: 11, Grad norm: 2.783e+00\n",
      "Epoch 9613, Loss: 449.73614501953125, Neurons: 11, Grad norm: 3.144e+00\n",
      "Epoch 9614, Loss: 449.7317810058594, Neurons: 11, Grad norm: 3.190e+00\n",
      "Epoch 9615, Loss: 449.7274475097656, Neurons: 11, Grad norm: 3.621e+00\n",
      "Epoch 9616, Loss: 449.72308349609375, Neurons: 11, Grad norm: 3.274e+00\n",
      "Epoch 9617, Loss: 449.7187805175781, Neurons: 11, Grad norm: 3.354e+00\n",
      "Epoch 9618, Loss: 449.7144470214844, Neurons: 11, Grad norm: 2.883e+00\n",
      "Epoch 9619, Loss: 449.7100830078125, Neurons: 11, Grad norm: 2.843e+00\n",
      "Epoch 9620, Loss: 449.70574951171875, Neurons: 11, Grad norm: 2.826e+00\n",
      "Epoch 9621, Loss: 449.7013854980469, Neurons: 11, Grad norm: 2.815e+00\n",
      "Epoch 9622, Loss: 449.69708251953125, Neurons: 11, Grad norm: 3.064e+00\n",
      "Epoch 9623, Loss: 449.6927795410156, Neurons: 11, Grad norm: 2.932e+00\n",
      "Epoch 9624, Loss: 449.6883850097656, Neurons: 11, Grad norm: 3.122e+00\n",
      "Epoch 9625, Loss: 449.68408203125, Neurons: 11, Grad norm: 2.863e+00\n",
      "Epoch 9626, Loss: 449.6796875, Neurons: 11, Grad norm: 2.911e+00\n",
      "Epoch 9627, Loss: 449.6753845214844, Neurons: 11, Grad norm: 2.776e+00\n",
      "Epoch 9628, Loss: 449.6710510253906, Neurons: 11, Grad norm: 2.778e+00\n",
      "Epoch 9629, Loss: 449.66668701171875, Neurons: 11, Grad norm: 2.870e+00\n",
      "Epoch 9630, Loss: 449.662353515625, Neurons: 11, Grad norm: 2.810e+00\n",
      "Epoch 9631, Loss: 449.6579895019531, Neurons: 11, Grad norm: 2.985e+00\n",
      "Epoch 9632, Loss: 449.6536865234375, Neurons: 11, Grad norm: 2.832e+00\n",
      "Epoch 9633, Loss: 449.64935302734375, Neurons: 11, Grad norm: 2.942e+00\n",
      "Epoch 9634, Loss: 449.6449890136719, Neurons: 11, Grad norm: 2.785e+00\n",
      "Epoch 9635, Loss: 449.640625, Neurons: 11, Grad norm: 2.820e+00\n",
      "Epoch 9636, Loss: 449.63629150390625, Neurons: 11, Grad norm: 2.780e+00\n",
      "Epoch 9637, Loss: 449.6319274902344, Neurons: 11, Grad norm: 2.772e+00\n",
      "Epoch 9638, Loss: 449.6275939941406, Neurons: 11, Grad norm: 2.832e+00\n",
      "Epoch 9639, Loss: 449.623291015625, Neurons: 11, Grad norm: 2.775e+00\n",
      "Epoch 9640, Loss: 449.6189270019531, Neurons: 11, Grad norm: 2.866e+00\n",
      "Epoch 9641, Loss: 449.6145935058594, Neurons: 11, Grad norm: 2.773e+00\n",
      "Epoch 9642, Loss: 449.6101989746094, Neurons: 11, Grad norm: 2.821e+00\n",
      "Epoch 9643, Loss: 449.60589599609375, Neurons: 11, Grad norm: 2.770e+00\n",
      "Epoch 9644, Loss: 449.6015930175781, Neurons: 11, Grad norm: 2.778e+00\n",
      "Epoch 9645, Loss: 449.5971984863281, Neurons: 11, Grad norm: 2.798e+00\n",
      "Epoch 9646, Loss: 449.5928955078125, Neurons: 11, Grad norm: 2.766e+00\n",
      "Epoch 9647, Loss: 449.5885314941406, Neurons: 11, Grad norm: 2.847e+00\n",
      "Epoch 9648, Loss: 449.5841979980469, Neurons: 11, Grad norm: 2.779e+00\n",
      "Epoch 9649, Loss: 449.5798034667969, Neurons: 11, Grad norm: 2.926e+00\n",
      "Epoch 9649, Test loss: 445.67547607421875\n",
      "Epoch 9650, Loss: 449.57550048828125, Neurons: 11, Grad norm: 2.809e+00\n",
      "Epoch 9651, Loss: 449.5711975097656, Neurons: 11, Grad norm: 2.964e+00\n",
      "Epoch 9652, Loss: 449.5668029785156, Neurons: 11, Grad norm: 2.822e+00\n",
      "Epoch 9653, Loss: 449.5625, Neurons: 11, Grad norm: 2.986e+00\n",
      "Epoch 9654, Loss: 449.5580749511719, Neurons: 11, Grad norm: 2.826e+00\n",
      "Epoch 9655, Loss: 449.5538024902344, Neurons: 11, Grad norm: 2.980e+00\n",
      "Epoch 9656, Loss: 449.5494384765625, Neurons: 11, Grad norm: 2.819e+00\n",
      "Epoch 9657, Loss: 449.5450744628906, Neurons: 11, Grad norm: 2.958e+00\n",
      "Epoch 9658, Loss: 449.5406799316406, Neurons: 11, Grad norm: 2.796e+00\n",
      "Epoch 9659, Loss: 449.5363464355469, Neurons: 11, Grad norm: 2.895e+00\n",
      "Epoch 9660, Loss: 449.53204345703125, Neurons: 11, Grad norm: 2.771e+00\n",
      "Epoch 9661, Loss: 449.5276794433594, Neurons: 11, Grad norm: 2.857e+00\n",
      "Epoch 9662, Loss: 449.5232849121094, Neurons: 11, Grad norm: 2.761e+00\n",
      "Epoch 9663, Loss: 449.51898193359375, Neurons: 11, Grad norm: 2.829e+00\n",
      "Epoch 9664, Loss: 449.51458740234375, Neurons: 11, Grad norm: 2.757e+00\n",
      "Epoch 9665, Loss: 449.5102844238281, Neurons: 11, Grad norm: 2.834e+00\n",
      "Epoch 9666, Loss: 449.5059509277344, Neurons: 11, Grad norm: 2.762e+00\n",
      "Epoch 9667, Loss: 449.5015869140625, Neurons: 11, Grad norm: 2.867e+00\n",
      "Epoch 9668, Loss: 449.4972839355469, Neurons: 11, Grad norm: 2.767e+00\n",
      "Epoch 9669, Loss: 449.4928894042969, Neurons: 11, Grad norm: 2.867e+00\n",
      "Epoch 9670, Loss: 449.488525390625, Neurons: 11, Grad norm: 2.770e+00\n",
      "Epoch 9671, Loss: 449.48419189453125, Neurons: 11, Grad norm: 2.912e+00\n",
      "Epoch 9672, Loss: 449.4798278808594, Neurons: 11, Grad norm: 2.804e+00\n",
      "Epoch 9673, Loss: 449.4754943847656, Neurons: 11, Grad norm: 3.008e+00\n",
      "Epoch 9674, Loss: 449.47113037109375, Neurons: 11, Grad norm: 2.867e+00\n",
      "Epoch 9675, Loss: 449.466796875, Neurons: 11, Grad norm: 3.112e+00\n",
      "Epoch 9676, Loss: 449.4624328613281, Neurons: 11, Grad norm: 2.928e+00\n",
      "Epoch 9677, Loss: 449.4580993652344, Neurons: 11, Grad norm: 3.179e+00\n",
      "Epoch 9678, Loss: 449.4537353515625, Neurons: 11, Grad norm: 2.963e+00\n",
      "Epoch 9679, Loss: 449.44940185546875, Neurons: 11, Grad norm: 3.261e+00\n",
      "Epoch 9680, Loss: 449.4450378417969, Neurons: 11, Grad norm: 3.070e+00\n",
      "Epoch 9681, Loss: 449.440673828125, Neurons: 11, Grad norm: 3.444e+00\n",
      "Epoch 9682, Loss: 449.436279296875, Neurons: 11, Grad norm: 3.260e+00\n",
      "Epoch 9683, Loss: 449.4319763183594, Neurons: 11, Grad norm: 3.770e+00\n",
      "Epoch 9684, Loss: 449.4276428222656, Neurons: 11, Grad norm: 3.644e+00\n",
      "Epoch 9685, Loss: 449.42327880859375, Neurons: 11, Grad norm: 4.344e+00\n",
      "Epoch 9686, Loss: 449.41888427734375, Neurons: 11, Grad norm: 4.275e+00\n",
      "Epoch 9687, Loss: 449.41455078125, Neurons: 11, Grad norm: 5.108e+00\n",
      "Epoch 9688, Loss: 449.4101867675781, Neurons: 11, Grad norm: 5.133e+00\n",
      "Epoch 9689, Loss: 449.4058837890625, Neurons: 11, Grad norm: 6.240e+00\n",
      "Epoch 9690, Loss: 449.4014892578125, Neurons: 11, Grad norm: 6.557e+00\n",
      "Epoch 9691, Loss: 449.3970947265625, Neurons: 11, Grad norm: 8.091e+00\n",
      "Epoch 9692, Loss: 449.3927917480469, Neurons: 11, Grad norm: 8.870e+00\n",
      "Epoch 9693, Loss: 449.3883972167969, Neurons: 11, Grad norm: 1.105e+01\n",
      "Epoch 9694, Loss: 449.38409423828125, Neurons: 11, Grad norm: 1.269e+01\n",
      "Epoch 9695, Loss: 449.37969970703125, Neurons: 11, Grad norm: 1.598e+01\n",
      "Epoch 9696, Loss: 449.3753967285156, Neurons: 11, Grad norm: 1.888e+01\n",
      "Epoch 9697, Loss: 449.3710021972656, Neurons: 11, Grad norm: 2.376e+01\n",
      "Epoch 9698, Loss: 449.36669921875, Neurons: 11, Grad norm: 2.870e+01\n",
      "Epoch 9699, Loss: 449.3623962402344, Neurons: 11, Grad norm: 3.624e+01\n",
      "Epoch 9699, Test loss: 445.4514465332031\n",
      "Epoch 9700, Loss: 449.3580322265625, Neurons: 11, Grad norm: 4.455e+01\n",
      "Epoch 9701, Loss: 449.3537902832031, Neurons: 11, Grad norm: 5.626e+01\n",
      "Epoch 9702, Loss: 449.3495788574219, Neurons: 11, Grad norm: 6.972e+01\n",
      "Epoch 9703, Loss: 449.34539794921875, Neurons: 11, Grad norm: 8.775e+01\n",
      "Epoch 9704, Loss: 449.3414001464844, Neurons: 11, Grad norm: 1.086e+02\n",
      "Epoch 9705, Loss: 449.33758544921875, Neurons: 11, Grad norm: 1.346e+02\n",
      "Epoch 9706, Loss: 449.333984375, Neurons: 11, Grad norm: 1.625e+02\n",
      "Epoch 9707, Loss: 449.3306884765625, Neurons: 11, Grad norm: 1.922e+02\n",
      "Epoch 9708, Loss: 449.32763671875, Neurons: 11, Grad norm: 2.155e+02\n",
      "Epoch 9709, Loss: 449.32452392578125, Neurons: 11, Grad norm: 2.266e+02\n",
      "Epoch 9710, Loss: 449.3208923339844, Neurons: 11, Grad norm: 2.132e+02\n",
      "Epoch 9711, Loss: 449.31597900390625, Neurons: 11, Grad norm: 1.724e+02\n",
      "Epoch 9712, Loss: 449.30999755859375, Neurons: 11, Grad norm: 1.049e+02\n",
      "Epoch 9713, Loss: 449.3036804199219, Neurons: 11, Grad norm: 2.555e+01\n",
      "Epoch 9714, Loss: 449.29840087890625, Neurons: 11, Grad norm: 5.220e+01\n",
      "Epoch 9715, Loss: 449.29449462890625, Neurons: 11, Grad norm: 1.109e+02\n",
      "Epoch 9716, Loss: 449.29150390625, Neurons: 11, Grad norm: 1.431e+02\n",
      "Epoch 9717, Loss: 449.28839111328125, Neurons: 11, Grad norm: 1.410e+02\n",
      "Epoch 9718, Loss: 449.2843017578125, Neurons: 11, Grad norm: 1.089e+02\n",
      "Epoch 9719, Loss: 449.27923583984375, Neurons: 11, Grad norm: 5.342e+01\n",
      "Epoch 9720, Loss: 449.2740783691406, Neurons: 11, Grad norm: 8.776e+00\n",
      "Epoch 9721, Loss: 449.269775390625, Neurons: 11, Grad norm: 6.310e+01\n",
      "Epoch 9722, Loss: 449.2661437988281, Neurons: 11, Grad norm: 9.633e+01\n",
      "Epoch 9723, Loss: 449.2627868652344, Neurons: 11, Grad norm: 1.042e+02\n",
      "Epoch 9724, Loss: 449.2588806152344, Neurons: 11, Grad norm: 8.450e+01\n",
      "Epoch 9725, Loss: 449.25439453125, Neurons: 11, Grad norm: 4.669e+01\n",
      "Epoch 9726, Loss: 449.2497863769531, Neurons: 11, Grad norm: 2.710e+00\n",
      "Epoch 9727, Loss: 449.2454833984375, Neurons: 11, Grad norm: 4.156e+01\n",
      "Epoch 9728, Loss: 449.24163818359375, Neurons: 11, Grad norm: 6.927e+01\n",
      "Epoch 9729, Loss: 449.23797607421875, Neurons: 11, Grad norm: 7.580e+01\n",
      "Epoch 9730, Loss: 449.2341003417969, Neurons: 11, Grad norm: 6.373e+01\n",
      "Epoch 9731, Loss: 449.2298278808594, Neurons: 11, Grad norm: 3.566e+01\n",
      "Epoch 9732, Loss: 449.22552490234375, Neurons: 11, Grad norm: 3.608e+00\n",
      "Epoch 9733, Loss: 449.22137451171875, Neurons: 11, Grad norm: 2.926e+01\n",
      "Epoch 9734, Loss: 449.2174377441406, Neurons: 11, Grad norm: 4.927e+01\n",
      "Epoch 9735, Loss: 449.2135925292969, Neurons: 11, Grad norm: 5.629e+01\n",
      "Epoch 9736, Loss: 449.2096862792969, Neurons: 11, Grad norm: 4.763e+01\n",
      "Epoch 9737, Loss: 449.2055969238281, Neurons: 11, Grad norm: 2.933e+01\n",
      "Epoch 9738, Loss: 449.2013854980469, Neurons: 11, Grad norm: 5.205e+00\n",
      "Epoch 9739, Loss: 449.1972961425781, Neurons: 11, Grad norm: 1.798e+01\n",
      "Epoch 9740, Loss: 449.19329833984375, Neurons: 11, Grad norm: 3.476e+01\n",
      "Epoch 9741, Loss: 449.18939208984375, Neurons: 11, Grad norm: 4.054e+01\n",
      "Epoch 9742, Loss: 449.1854248046875, Neurons: 11, Grad norm: 3.730e+01\n",
      "Epoch 9743, Loss: 449.181396484375, Neurons: 11, Grad norm: 2.449e+01\n",
      "Epoch 9744, Loss: 449.1772766113281, Neurons: 11, Grad norm: 8.606e+00\n",
      "Epoch 9745, Loss: 449.1732482910156, Neurons: 11, Grad norm: 9.800e+00\n",
      "Epoch 9746, Loss: 449.16925048828125, Neurons: 11, Grad norm: 2.216e+01\n",
      "Epoch 9747, Loss: 449.1652526855469, Neurons: 11, Grad norm: 2.960e+01\n",
      "Epoch 9748, Loss: 449.1612854003906, Neurons: 11, Grad norm: 2.853e+01\n",
      "Epoch 9749, Loss: 449.1572265625, Neurons: 11, Grad norm: 2.233e+01\n",
      "Epoch 9749, Test loss: 445.25396728515625\n",
      "Epoch 9750, Loss: 449.1531982421875, Neurons: 11, Grad norm: 1.084e+01\n",
      "Epoch 9751, Loss: 449.1492004394531, Neurons: 11, Grad norm: 2.929e+00\n",
      "Epoch 9752, Loss: 449.1451416015625, Neurons: 11, Grad norm: 1.283e+01\n",
      "Epoch 9753, Loss: 449.1411437988281, Neurons: 11, Grad norm: 1.914e+01\n",
      "Epoch 9754, Loss: 449.1371765136719, Neurons: 11, Grad norm: 2.200e+01\n",
      "Epoch 9755, Loss: 449.1331787109375, Neurons: 11, Grad norm: 1.888e+01\n",
      "Epoch 9756, Loss: 449.129150390625, Neurons: 11, Grad norm: 1.336e+01\n",
      "Epoch 9757, Loss: 449.1250915527344, Neurons: 11, Grad norm: 4.951e+00\n",
      "Epoch 9758, Loss: 449.12109375, Neurons: 11, Grad norm: 4.470e+00\n",
      "Epoch 9759, Loss: 449.1170959472656, Neurons: 11, Grad norm: 1.128e+01\n",
      "Epoch 9760, Loss: 449.11309814453125, Neurons: 11, Grad norm: 1.452e+01\n",
      "Epoch 9761, Loss: 449.1091003417969, Neurons: 11, Grad norm: 1.581e+01\n",
      "Epoch 9762, Loss: 449.10504150390625, Neurons: 11, Grad norm: 1.278e+01\n",
      "Epoch 9763, Loss: 449.1010437011719, Neurons: 11, Grad norm: 8.856e+00\n",
      "Epoch 9764, Loss: 449.09698486328125, Neurons: 11, Grad norm: 3.383e+00\n",
      "Epoch 9765, Loss: 449.0929870605469, Neurons: 11, Grad norm: 3.888e+00\n",
      "Epoch 9766, Loss: 449.08892822265625, Neurons: 11, Grad norm: 8.241e+00\n",
      "Epoch 9767, Loss: 449.0849914550781, Neurons: 11, Grad norm: 1.002e+01\n",
      "Epoch 9768, Loss: 449.08099365234375, Neurons: 11, Grad norm: 1.103e+01\n",
      "Epoch 9769, Loss: 449.0769958496094, Neurons: 11, Grad norm: 8.986e+00\n",
      "Epoch 9770, Loss: 449.07293701171875, Neurons: 11, Grad norm: 6.879e+00\n",
      "Epoch 9771, Loss: 449.0688781738281, Neurons: 11, Grad norm: 3.381e+00\n",
      "Epoch 9772, Loss: 449.06488037109375, Neurons: 11, Grad norm: 2.827e+00\n",
      "Epoch 9773, Loss: 449.0608825683594, Neurons: 11, Grad norm: 5.331e+00\n",
      "Epoch 9774, Loss: 449.056884765625, Neurons: 11, Grad norm: 6.572e+00\n",
      "Epoch 9775, Loss: 449.0528259277344, Neurons: 11, Grad norm: 7.966e+00\n",
      "Epoch 9776, Loss: 449.048828125, Neurons: 11, Grad norm: 7.038e+00\n",
      "Epoch 9777, Loss: 449.0447998046875, Neurons: 11, Grad norm: 6.357e+00\n",
      "Epoch 9778, Loss: 449.0408020019531, Neurons: 11, Grad norm: 4.005e+00\n",
      "Epoch 9779, Loss: 449.0367736816406, Neurons: 11, Grad norm: 2.924e+00\n",
      "Epoch 9780, Loss: 449.03277587890625, Neurons: 11, Grad norm: 3.190e+00\n",
      "Epoch 9781, Loss: 449.02874755859375, Neurons: 11, Grad norm: 3.995e+00\n",
      "Epoch 9782, Loss: 449.0246887207031, Neurons: 11, Grad norm: 5.565e+00\n",
      "Epoch 9783, Loss: 449.02069091796875, Neurons: 11, Grad norm: 5.432e+00\n",
      "Epoch 9784, Loss: 449.0166931152344, Neurons: 11, Grad norm: 5.744e+00\n",
      "Epoch 9785, Loss: 449.0126953125, Neurons: 11, Grad norm: 4.408e+00\n",
      "Epoch 9786, Loss: 449.0086364746094, Neurons: 11, Grad norm: 3.854e+00\n",
      "Epoch 9787, Loss: 449.00457763671875, Neurons: 11, Grad norm: 2.728e+00\n",
      "Epoch 9788, Loss: 449.0005798339844, Neurons: 11, Grad norm: 2.681e+00\n",
      "Epoch 9789, Loss: 448.99658203125, Neurons: 11, Grad norm: 3.510e+00\n",
      "Epoch 9790, Loss: 448.9925537109375, Neurons: 11, Grad norm: 3.726e+00\n",
      "Epoch 9791, Loss: 448.988525390625, Neurons: 11, Grad norm: 4.605e+00\n",
      "Epoch 9792, Loss: 448.9844970703125, Neurons: 11, Grad norm: 4.118e+00\n",
      "Epoch 9793, Loss: 448.9804992675781, Neurons: 11, Grad norm: 4.367e+00\n",
      "Epoch 9794, Loss: 448.97650146484375, Neurons: 11, Grad norm: 3.444e+00\n",
      "Epoch 9795, Loss: 448.9724426269531, Neurons: 11, Grad norm: 3.352e+00\n",
      "Epoch 9796, Loss: 448.9683837890625, Neurons: 11, Grad norm: 2.708e+00\n",
      "Epoch 9797, Loss: 448.9643859863281, Neurons: 11, Grad norm: 2.674e+00\n",
      "Epoch 9798, Loss: 448.96038818359375, Neurons: 11, Grad norm: 2.912e+00\n",
      "Epoch 9799, Loss: 448.9563903808594, Neurons: 11, Grad norm: 2.919e+00\n",
      "Epoch 9799, Test loss: 445.0621032714844\n",
      "Epoch 9800, Loss: 448.9523010253906, Neurons: 11, Grad norm: 3.516e+00\n",
      "Epoch 9801, Loss: 448.94830322265625, Neurons: 11, Grad norm: 3.237e+00\n",
      "Epoch 9802, Loss: 448.94427490234375, Neurons: 11, Grad norm: 3.619e+00\n",
      "Epoch 9803, Loss: 448.9402770996094, Neurons: 11, Grad norm: 3.075e+00\n",
      "Epoch 9804, Loss: 448.9362487792969, Neurons: 11, Grad norm: 3.219e+00\n",
      "Epoch 9805, Loss: 448.93218994140625, Neurons: 11, Grad norm: 2.733e+00\n",
      "Epoch 9806, Loss: 448.9281921386719, Neurons: 11, Grad norm: 2.760e+00\n",
      "Epoch 9807, Loss: 448.92413330078125, Neurons: 11, Grad norm: 2.684e+00\n",
      "Epoch 9808, Loss: 448.9200744628906, Neurons: 11, Grad norm: 2.660e+00\n",
      "Epoch 9809, Loss: 448.91607666015625, Neurons: 11, Grad norm: 2.940e+00\n",
      "Epoch 9810, Loss: 448.9119873046875, Neurons: 11, Grad norm: 2.845e+00\n",
      "Epoch 9811, Loss: 448.9079895019531, Neurons: 11, Grad norm: 3.357e+00\n",
      "Epoch 9812, Loss: 448.90399169921875, Neurons: 11, Grad norm: 3.114e+00\n",
      "Epoch 9813, Loss: 448.8999938964844, Neurons: 11, Grad norm: 3.545e+00\n",
      "Epoch 9814, Loss: 448.89593505859375, Neurons: 11, Grad norm: 3.100e+00\n",
      "Epoch 9815, Loss: 448.8918762207031, Neurons: 11, Grad norm: 3.336e+00\n",
      "Epoch 9816, Loss: 448.88787841796875, Neurons: 11, Grad norm: 2.850e+00\n",
      "Epoch 9817, Loss: 448.88385009765625, Neurons: 11, Grad norm: 2.995e+00\n",
      "Epoch 9818, Loss: 448.8797912597656, Neurons: 11, Grad norm: 2.680e+00\n",
      "Epoch 9819, Loss: 448.87579345703125, Neurons: 11, Grad norm: 2.759e+00\n",
      "Epoch 9820, Loss: 448.8717956542969, Neurons: 11, Grad norm: 2.650e+00\n",
      "Epoch 9821, Loss: 448.86767578125, Neurons: 11, Grad norm: 2.666e+00\n",
      "Epoch 9822, Loss: 448.8636779785156, Neurons: 11, Grad norm: 2.677e+00\n",
      "Epoch 9823, Loss: 448.8596496582031, Neurons: 11, Grad norm: 2.654e+00\n",
      "Epoch 9824, Loss: 448.8555908203125, Neurons: 11, Grad norm: 2.683e+00\n",
      "Epoch 9825, Loss: 448.8515930175781, Neurons: 11, Grad norm: 2.651e+00\n",
      "Epoch 9826, Loss: 448.84759521484375, Neurons: 11, Grad norm: 2.678e+00\n",
      "Epoch 9827, Loss: 448.8434753417969, Neurons: 11, Grad norm: 2.657e+00\n",
      "Epoch 9828, Loss: 448.8394775390625, Neurons: 11, Grad norm: 2.669e+00\n",
      "Epoch 9829, Loss: 448.83544921875, Neurons: 11, Grad norm: 2.655e+00\n",
      "Epoch 9830, Loss: 448.8313903808594, Neurons: 11, Grad norm: 2.667e+00\n",
      "Epoch 9831, Loss: 448.82733154296875, Neurons: 11, Grad norm: 2.664e+00\n",
      "Epoch 9832, Loss: 448.82330322265625, Neurons: 11, Grad norm: 2.655e+00\n",
      "Epoch 9833, Loss: 448.81927490234375, Neurons: 11, Grad norm: 2.666e+00\n",
      "Epoch 9834, Loss: 448.815185546875, Neurons: 11, Grad norm: 2.661e+00\n",
      "Epoch 9835, Loss: 448.8111877441406, Neurons: 11, Grad norm: 2.649e+00\n",
      "Epoch 9836, Loss: 448.80718994140625, Neurons: 11, Grad norm: 2.684e+00\n",
      "Epoch 9837, Loss: 448.8031311035156, Neurons: 11, Grad norm: 2.643e+00\n",
      "Epoch 9838, Loss: 448.7991027832031, Neurons: 11, Grad norm: 2.671e+00\n",
      "Epoch 9839, Loss: 448.79498291015625, Neurons: 11, Grad norm: 2.661e+00\n",
      "Epoch 9840, Loss: 448.7909851074219, Neurons: 11, Grad norm: 2.643e+00\n",
      "Epoch 9841, Loss: 448.7869873046875, Neurons: 11, Grad norm: 2.693e+00\n",
      "Epoch 9842, Loss: 448.7829284667969, Neurons: 11, Grad norm: 2.638e+00\n",
      "Epoch 9843, Loss: 448.7789001464844, Neurons: 11, Grad norm: 2.692e+00\n",
      "Epoch 9844, Loss: 448.7747802734375, Neurons: 11, Grad norm: 2.636e+00\n",
      "Epoch 9845, Loss: 448.7707824707031, Neurons: 11, Grad norm: 2.692e+00\n",
      "Epoch 9846, Loss: 448.7667236328125, Neurons: 11, Grad norm: 2.633e+00\n",
      "Epoch 9847, Loss: 448.7626953125, Neurons: 11, Grad norm: 2.723e+00\n",
      "Epoch 9848, Loss: 448.7586975097656, Neurons: 11, Grad norm: 2.637e+00\n",
      "Epoch 9849, Loss: 448.75457763671875, Neurons: 11, Grad norm: 2.817e+00\n",
      "Epoch 9849, Test loss: 444.861572265625\n",
      "Epoch 9850, Loss: 448.7505798339844, Neurons: 11, Grad norm: 2.682e+00\n",
      "Epoch 9851, Loss: 448.7465515136719, Neurons: 11, Grad norm: 2.981e+00\n",
      "Epoch 9852, Loss: 448.74249267578125, Neurons: 11, Grad norm: 2.804e+00\n",
      "Epoch 9853, Loss: 448.7384033203125, Neurons: 11, Grad norm: 3.272e+00\n",
      "Epoch 9854, Loss: 448.734375, Neurons: 11, Grad norm: 3.111e+00\n",
      "Epoch 9855, Loss: 448.7303771972656, Neurons: 11, Grad norm: 3.829e+00\n",
      "Epoch 9856, Loss: 448.7262878417969, Neurons: 11, Grad norm: 3.709e+00\n",
      "Epoch 9857, Loss: 448.7222900390625, Neurons: 11, Grad norm: 4.721e+00\n",
      "Epoch 9858, Loss: 448.71820068359375, Neurons: 11, Grad norm: 4.858e+00\n",
      "Epoch 9859, Loss: 448.7142028808594, Neurons: 11, Grad norm: 6.346e+00\n",
      "Epoch 9860, Loss: 448.7100830078125, Neurons: 11, Grad norm: 6.851e+00\n",
      "Epoch 9861, Loss: 448.7060852050781, Neurons: 11, Grad norm: 8.887e+00\n",
      "Epoch 9862, Loss: 448.7020263671875, Neurons: 11, Grad norm: 1.009e+01\n",
      "Epoch 9863, Loss: 448.697998046875, Neurons: 11, Grad norm: 1.317e+01\n",
      "Epoch 9864, Loss: 448.6939392089844, Neurons: 11, Grad norm: 1.566e+01\n",
      "Epoch 9865, Loss: 448.68988037109375, Neurons: 11, Grad norm: 2.036e+01\n",
      "Epoch 9866, Loss: 448.6858825683594, Neurons: 11, Grad norm: 2.487e+01\n",
      "Epoch 9867, Loss: 448.681884765625, Neurons: 11, Grad norm: 3.217e+01\n",
      "Epoch 9868, Loss: 448.6778869628906, Neurons: 11, Grad norm: 4.007e+01\n",
      "Epoch 9869, Loss: 448.67388916015625, Neurons: 11, Grad norm: 5.183e+01\n",
      "Epoch 9870, Loss: 448.6699523925781, Neurons: 11, Grad norm: 6.540e+01\n",
      "Epoch 9871, Loss: 448.66607666015625, Neurons: 11, Grad norm: 8.428e+01\n",
      "Epoch 9872, Loss: 448.6623840332031, Neurons: 11, Grad norm: 1.066e+02\n",
      "Epoch 9873, Loss: 448.6587829589844, Neurons: 11, Grad norm: 1.357e+02\n",
      "Epoch 9874, Loss: 448.65557861328125, Neurons: 11, Grad norm: 1.684e+02\n",
      "Epoch 9875, Loss: 448.6527404785156, Neurons: 11, Grad norm: 2.056e+02\n",
      "Epoch 9876, Loss: 448.6502990722656, Neurons: 11, Grad norm: 2.387e+02\n",
      "Epoch 9877, Loss: 448.6481018066406, Neurons: 11, Grad norm: 2.605e+02\n",
      "Epoch 9878, Loss: 448.6453857421875, Neurons: 11, Grad norm: 2.544e+02\n",
      "Epoch 9879, Loss: 448.64117431640625, Neurons: 11, Grad norm: 2.132e+02\n",
      "Epoch 9880, Loss: 448.6351318359375, Neurons: 11, Grad norm: 1.343e+02\n",
      "Epoch 9881, Loss: 448.628173828125, Neurons: 11, Grad norm: 3.617e+01\n",
      "Epoch 9882, Loss: 448.62249755859375, Neurons: 11, Grad norm: 6.161e+01\n",
      "Epoch 9883, Loss: 448.6189880371094, Neurons: 11, Grad norm: 1.347e+02\n",
      "Epoch 9884, Loss: 448.6168518066406, Neurons: 11, Grad norm: 1.713e+02\n",
      "Epoch 9885, Loss: 448.6142883300781, Neurons: 11, Grad norm: 1.614e+02\n",
      "Epoch 9886, Loss: 448.6102294921875, Neurons: 11, Grad norm: 1.119e+02\n",
      "Epoch 9887, Loss: 448.6049499511719, Neurons: 11, Grad norm: 3.572e+01\n",
      "Epoch 9888, Loss: 448.5999450683594, Neurons: 11, Grad norm: 4.168e+01\n",
      "Epoch 9889, Loss: 448.59625244140625, Neurons: 11, Grad norm: 1.010e+02\n",
      "Epoch 9890, Loss: 448.5934753417969, Neurons: 11, Grad norm: 1.251e+02\n",
      "Epoch 9891, Loss: 448.59039306640625, Neurons: 11, Grad norm: 1.126e+02\n",
      "Epoch 9892, Loss: 448.5863037109375, Neurons: 11, Grad norm: 6.723e+01\n",
      "Epoch 9893, Loss: 448.5816955566406, Neurons: 11, Grad norm: 8.142e+00\n",
      "Epoch 9894, Loss: 448.5774841308594, Neurons: 11, Grad norm: 4.951e+01\n",
      "Epoch 9895, Loss: 448.57403564453125, Neurons: 11, Grad norm: 8.514e+01\n",
      "Epoch 9896, Loss: 448.5708923339844, Neurons: 11, Grad norm: 9.348e+01\n",
      "Epoch 9897, Loss: 448.5673828125, Neurons: 11, Grad norm: 7.186e+01\n",
      "Epoch 9898, Loss: 448.563232421875, Neurons: 11, Grad norm: 3.209e+01\n",
      "Epoch 9899, Loss: 448.55908203125, Neurons: 11, Grad norm: 1.487e+01\n",
      "Epoch 9899, Test loss: 444.6641540527344\n",
      "Epoch 9900, Loss: 448.5552978515625, Neurons: 11, Grad norm: 5.125e+01\n",
      "Epoch 9901, Loss: 448.5517883300781, Neurons: 11, Grad norm: 6.995e+01\n",
      "Epoch 9902, Loss: 448.54840087890625, Neurons: 11, Grad norm: 6.490e+01\n",
      "Epoch 9903, Loss: 448.5445861816406, Neurons: 11, Grad norm: 4.193e+01\n",
      "Epoch 9904, Loss: 448.54058837890625, Neurons: 11, Grad norm: 8.138e+00\n",
      "Epoch 9905, Loss: 448.5365905761719, Neurons: 11, Grad norm: 2.481e+01\n",
      "Epoch 9906, Loss: 448.53289794921875, Neurons: 11, Grad norm: 4.708e+01\n",
      "Epoch 9907, Loss: 448.5291748046875, Neurons: 11, Grad norm: 5.329e+01\n",
      "Epoch 9908, Loss: 448.5252380371094, Neurons: 11, Grad norm: 4.294e+01\n",
      "Epoch 9909, Loss: 448.5208740234375, Neurons: 11, Grad norm: 2.211e+01\n",
      "Epoch 9910, Loss: 448.51617431640625, Neurons: 11, Grad norm: 5.903e+00\n",
      "Epoch 9911, Loss: 448.5108337402344, Neurons: 11, Grad norm: 2.538e+01\n",
      "Epoch 9912, Loss: 448.50433349609375, Neurons: 11, Grad norm: 4.015e+01\n",
      "Epoch 9913, Loss: 448.4956359863281, Neurons: 11, Grad norm: 3.675e+01\n",
      "Epoch 9914, Loss: 448.4830017089844, Neurons: 11, Grad norm: 3.009e+01\n",
      "Epoch 9915, Loss: 448.4640808105469, Neurons: 11, Grad norm: 1.382e+01\n",
      "Epoch 9916, Loss: 448.436279296875, Neurons: 11, Grad norm: 1.753e+01\n",
      "Epoch 9917, Loss: 448.3970031738281, Neurons: 11, Grad norm: 3.422e+01\n",
      "Epoch 9918, Loss: 448.3441467285156, Neurons: 11, Grad norm: 3.301e+01\n",
      "Epoch 9919, Loss: 448.2757873535156, Neurons: 11, Grad norm: 4.036e+01\n",
      "Epoch 9920, Loss: 448.1912841796875, Neurons: 11, Grad norm: 2.804e+01\n",
      "Epoch 9921, Loss: 448.0905456542969, Neurons: 11, Grad norm: 2.883e+01\n",
      "Epoch 9922, Loss: 447.97528076171875, Neurons: 11, Grad norm: 3.407e+01\n",
      "Epoch 9923, Loss: 447.84844970703125, Neurons: 11, Grad norm: 3.036e+01\n",
      "Epoch 9924, Loss: 447.71514892578125, Neurons: 11, Grad norm: 3.401e+01\n",
      "Epoch 9925, Loss: 447.5828857421875, Neurons: 11, Grad norm: 2.241e+01\n",
      "Epoch 9926, Loss: 447.46124267578125, Neurons: 11, Grad norm: 1.371e+01\n",
      "Epoch 9927, Loss: 447.3618469238281, Neurons: 11, Grad norm: 8.344e+00\n",
      "Epoch 9928, Loss: 447.2957458496094, Neurons: 11, Grad norm: 1.932e+01\n",
      "Epoch 9929, Loss: 447.2684326171875, Neurons: 11, Grad norm: 1.801e+01\n",
      "Epoch 9930, Loss: 447.2747802734375, Neurons: 11, Grad norm: 2.635e+01\n",
      "Epoch 9931, Loss: 447.3006896972656, Neurons: 11, Grad norm: 2.344e+01\n",
      "Epoch 9932, Loss: 447.3309326171875, Neurons: 11, Grad norm: 2.554e+01\n",
      "Epoch 9933, Loss: 447.3553771972656, Neurons: 11, Grad norm: 2.865e+01\n",
      "Epoch 9934, Loss: 447.3692932128906, Neurons: 11, Grad norm: 2.705e+01\n",
      "Epoch 9935, Loss: 447.3717956542969, Neurons: 11, Grad norm: 3.163e+01\n",
      "Epoch 9936, Loss: 447.3638916015625, Neurons: 11, Grad norm: 2.374e+01\n",
      "Epoch 9937, Loss: 447.34783935546875, Neurons: 11, Grad norm: 2.385e+01\n",
      "Epoch 9938, Loss: 447.3260803222656, Neurons: 11, Grad norm: 2.022e+01\n",
      "Epoch 9939, Loss: 447.30133056640625, Neurons: 11, Grad norm: 1.575e+01\n",
      "Epoch 9940, Loss: 447.27593994140625, Neurons: 11, Grad norm: 1.610e+01\n",
      "Epoch 9941, Loss: 447.2520751953125, Neurons: 11, Grad norm: 1.324e+01\n",
      "Epoch 9942, Loss: 447.231201171875, Neurons: 11, Grad norm: 8.164e+00\n",
      "Epoch 9943, Loss: 447.2141418457031, Neurons: 11, Grad norm: 6.697e+00\n",
      "Epoch 9944, Loss: 447.2010803222656, Neurons: 11, Grad norm: 7.435e+00\n",
      "Epoch 9945, Loss: 447.19189453125, Neurons: 11, Grad norm: 8.564e+00\n",
      "Epoch 9946, Loss: 447.1859436035156, Neurons: 11, Grad norm: 1.112e+01\n",
      "Epoch 9947, Loss: 447.1822509765625, Neurons: 11, Grad norm: 1.061e+01\n",
      "Epoch 9948, Loss: 447.17999267578125, Neurons: 11, Grad norm: 1.125e+01\n",
      "Epoch 9949, Loss: 447.1782531738281, Neurons: 11, Grad norm: 1.046e+01\n",
      "Epoch 9949, Test loss: 443.2328796386719\n",
      "Epoch 9950, Loss: 447.1763916015625, Neurons: 11, Grad norm: 1.041e+01\n",
      "Epoch 9951, Loss: 447.1739807128906, Neurons: 11, Grad norm: 1.280e+01\n",
      "Epoch 9952, Loss: 447.1707763671875, Neurons: 11, Grad norm: 9.594e+00\n",
      "Epoch 9953, Loss: 447.1666259765625, Neurons: 11, Grad norm: 1.121e+01\n",
      "Epoch 9954, Loss: 447.1615905761719, Neurons: 11, Grad norm: 7.761e+00\n",
      "Epoch 9955, Loss: 447.15570068359375, Neurons: 11, Grad norm: 6.868e+00\n",
      "Epoch 9956, Loss: 447.14923095703125, Neurons: 11, Grad norm: 5.905e+00\n",
      "Epoch 9957, Loss: 447.1423034667969, Neurons: 11, Grad norm: 6.127e+00\n",
      "Epoch 9958, Loss: 447.13525390625, Neurons: 11, Grad norm: 5.712e+00\n",
      "Epoch 9959, Loss: 447.128173828125, Neurons: 11, Grad norm: 6.289e+00\n",
      "Epoch 9960, Loss: 447.1212463378906, Neurons: 11, Grad norm: 5.788e+00\n",
      "Epoch 9961, Loss: 447.11468505859375, Neurons: 11, Grad norm: 5.952e+00\n",
      "Epoch 9962, Loss: 447.1084899902344, Neurons: 11, Grad norm: 6.117e+00\n",
      "Epoch 9963, Loss: 447.10260009765625, Neurons: 11, Grad norm: 6.561e+00\n",
      "Epoch 9964, Loss: 447.0971984863281, Neurons: 11, Grad norm: 8.041e+00\n",
      "Epoch 9965, Loss: 447.09210205078125, Neurons: 11, Grad norm: 7.204e+00\n",
      "Epoch 9966, Loss: 447.08740234375, Neurons: 11, Grad norm: 8.829e+00\n",
      "Epoch 9967, Loss: 447.0827941894531, Neurons: 11, Grad norm: 7.229e+00\n",
      "Epoch 9968, Loss: 447.0782775878906, Neurons: 11, Grad norm: 7.527e+00\n",
      "Epoch 9969, Loss: 447.0738830566406, Neurons: 11, Grad norm: 6.944e+00\n",
      "Epoch 9970, Loss: 447.0694274902344, Neurons: 11, Grad norm: 6.316e+00\n",
      "Epoch 9971, Loss: 447.06494140625, Neurons: 11, Grad norm: 6.425e+00\n",
      "Epoch 9972, Loss: 447.0603332519531, Neurons: 11, Grad norm: 5.445e+00\n",
      "Epoch 9973, Loss: 447.05560302734375, Neurons: 11, Grad norm: 5.435e+00\n",
      "Epoch 9974, Loss: 447.05078125, Neurons: 11, Grad norm: 4.248e+00\n",
      "Epoch 9975, Loss: 447.0458984375, Neurons: 11, Grad norm: 4.001e+00\n",
      "Epoch 9976, Loss: 447.0409851074219, Neurons: 11, Grad norm: 3.417e+00\n",
      "Epoch 9977, Loss: 447.0359802246094, Neurons: 11, Grad norm: 2.977e+00\n",
      "Epoch 9978, Loss: 447.0310974121094, Neurons: 11, Grad norm: 3.036e+00\n",
      "Epoch 9979, Loss: 447.0261535644531, Neurons: 11, Grad norm: 3.138e+00\n",
      "Epoch 9980, Loss: 447.02130126953125, Neurons: 11, Grad norm: 2.828e+00\n",
      "Epoch 9981, Loss: 447.0164489746094, Neurons: 11, Grad norm: 3.222e+00\n",
      "Epoch 9982, Loss: 447.0116882324219, Neurons: 11, Grad norm: 2.646e+00\n",
      "Epoch 9983, Loss: 447.0069885253906, Neurons: 11, Grad norm: 2.742e+00\n",
      "Epoch 9984, Loss: 447.0022888183594, Neurons: 11, Grad norm: 2.586e+00\n",
      "Epoch 9985, Loss: 446.9976806640625, Neurons: 11, Grad norm: 2.572e+00\n",
      "Epoch 9986, Loss: 446.99310302734375, Neurons: 11, Grad norm: 2.723e+00\n",
      "Epoch 9987, Loss: 446.98858642578125, Neurons: 11, Grad norm: 2.631e+00\n",
      "Epoch 9988, Loss: 446.98394775390625, Neurons: 11, Grad norm: 2.750e+00\n",
      "Epoch 9989, Loss: 446.9794006347656, Neurons: 11, Grad norm: 2.474e+00\n",
      "Epoch 9990, Loss: 446.97479248046875, Neurons: 11, Grad norm: 2.519e+00\n",
      "Epoch 9991, Loss: 446.9701843261719, Neurons: 11, Grad norm: 2.409e+00\n",
      "Epoch 9992, Loss: 446.965576171875, Neurons: 11, Grad norm: 2.476e+00\n",
      "Epoch 9993, Loss: 446.96099853515625, Neurons: 11, Grad norm: 2.564e+00\n",
      "Epoch 9994, Loss: 446.9563903808594, Neurons: 11, Grad norm: 2.876e+00\n",
      "Epoch 9995, Loss: 446.9517822265625, Neurons: 11, Grad norm: 2.799e+00\n",
      "Epoch 9996, Loss: 446.9471740722656, Neurons: 11, Grad norm: 3.208e+00\n",
      "Epoch 9997, Loss: 446.9425964355469, Neurons: 11, Grad norm: 3.037e+00\n",
      "Epoch 9998, Loss: 446.93798828125, Neurons: 11, Grad norm: 3.328e+00\n",
      "Epoch 9999, Loss: 446.9333801269531, Neurons: 11, Grad norm: 3.230e+00\n",
      "Epoch 9999, Test loss: 442.98870849609375\n",
      "Epoch 10000, Loss: 446.9288024902344, Neurons: 11, Grad norm: 3.331e+00\n",
      "Epoch 10001, Loss: 446.9242858886719, Neurons: 11, Grad norm: 3.442e+00\n",
      "Epoch 10002, Loss: 446.919677734375, Neurons: 11, Grad norm: 3.340e+00\n",
      "Epoch 10003, Loss: 446.9151306152344, Neurons: 11, Grad norm: 3.667e+00\n",
      "Epoch 10004, Loss: 446.91058349609375, Neurons: 11, Grad norm: 3.300e+00\n",
      "Epoch 10005, Loss: 446.9060974121094, Neurons: 11, Grad norm: 3.539e+00\n",
      "Epoch 10006, Loss: 446.90155029296875, Neurons: 11, Grad norm: 3.163e+00\n",
      "Epoch 10007, Loss: 446.8970031738281, Neurons: 11, Grad norm: 3.181e+00\n",
      "Epoch 10008, Loss: 446.8924865722656, Neurons: 11, Grad norm: 3.060e+00\n",
      "Epoch 10009, Loss: 446.88800048828125, Neurons: 11, Grad norm: 2.916e+00\n",
      "Epoch 10010, Loss: 446.8834533691406, Neurons: 11, Grad norm: 2.935e+00\n",
      "Epoch 10011, Loss: 446.8788757324219, Neurons: 11, Grad norm: 2.744e+00\n",
      "Epoch 10012, Loss: 446.87432861328125, Neurons: 11, Grad norm: 2.793e+00\n",
      "Epoch 10013, Loss: 446.8698425292969, Neurons: 11, Grad norm: 2.598e+00\n",
      "Epoch 10014, Loss: 446.86529541015625, Neurons: 11, Grad norm: 2.654e+00\n",
      "Epoch 10015, Loss: 446.86077880859375, Neurons: 11, Grad norm: 2.492e+00\n",
      "Epoch 10016, Loss: 446.8562927246094, Neurons: 11, Grad norm: 2.489e+00\n",
      "Epoch 10017, Loss: 446.85174560546875, Neurons: 11, Grad norm: 2.432e+00\n",
      "Epoch 10018, Loss: 446.84722900390625, Neurons: 11, Grad norm: 2.398e+00\n",
      "Epoch 10019, Loss: 446.8427429199219, Neurons: 11, Grad norm: 2.471e+00\n",
      "Epoch 10020, Loss: 446.8382263183594, Neurons: 11, Grad norm: 2.417e+00\n",
      "Epoch 10021, Loss: 446.83367919921875, Neurons: 11, Grad norm: 2.519e+00\n",
      "Epoch 10022, Loss: 446.8292236328125, Neurons: 11, Grad norm: 2.427e+00\n",
      "Epoch 10023, Loss: 446.8247985839844, Neurons: 11, Grad norm: 2.557e+00\n",
      "Epoch 10024, Loss: 446.82025146484375, Neurons: 11, Grad norm: 2.427e+00\n",
      "Epoch 10025, Loss: 446.81573486328125, Neurons: 11, Grad norm: 2.539e+00\n",
      "Epoch 10026, Loss: 446.8112487792969, Neurons: 11, Grad norm: 2.435e+00\n",
      "Epoch 10027, Loss: 446.8067321777344, Neurons: 11, Grad norm: 2.504e+00\n",
      "Epoch 10028, Loss: 446.80224609375, Neurons: 11, Grad norm: 2.484e+00\n",
      "Epoch 10029, Loss: 446.79779052734375, Neurons: 11, Grad norm: 2.513e+00\n",
      "Epoch 10030, Loss: 446.79327392578125, Neurons: 11, Grad norm: 2.573e+00\n",
      "Epoch 10031, Loss: 446.7887878417969, Neurons: 11, Grad norm: 2.558e+00\n",
      "Epoch 10032, Loss: 446.7843017578125, Neurons: 11, Grad norm: 2.688e+00\n",
      "Epoch 10033, Loss: 446.77978515625, Neurons: 11, Grad norm: 2.598e+00\n",
      "Epoch 10034, Loss: 446.77532958984375, Neurons: 11, Grad norm: 2.807e+00\n",
      "Epoch 10035, Loss: 446.7707824707031, Neurons: 11, Grad norm: 2.654e+00\n",
      "Epoch 10036, Loss: 446.7663879394531, Neurons: 11, Grad norm: 2.909e+00\n",
      "Epoch 10037, Loss: 446.7618408203125, Neurons: 11, Grad norm: 2.698e+00\n",
      "Epoch 10038, Loss: 446.75732421875, Neurons: 11, Grad norm: 2.928e+00\n",
      "Epoch 10039, Loss: 446.7528991699219, Neurons: 11, Grad norm: 2.699e+00\n",
      "Epoch 10040, Loss: 446.7483825683594, Neurons: 11, Grad norm: 2.910e+00\n",
      "Epoch 10041, Loss: 446.7439270019531, Neurons: 11, Grad norm: 2.696e+00\n",
      "Epoch 10042, Loss: 446.739501953125, Neurons: 11, Grad norm: 2.951e+00\n",
      "Epoch 10043, Loss: 446.7349853515625, Neurons: 11, Grad norm: 2.708e+00\n",
      "Epoch 10044, Loss: 446.7304992675781, Neurons: 11, Grad norm: 3.000e+00\n",
      "Epoch 10045, Loss: 446.7259826660156, Neurons: 11, Grad norm: 2.728e+00\n",
      "Epoch 10046, Loss: 446.7215270996094, Neurons: 11, Grad norm: 3.047e+00\n",
      "Epoch 10047, Loss: 446.717041015625, Neurons: 11, Grad norm: 2.779e+00\n",
      "Epoch 10048, Loss: 446.71258544921875, Neurons: 11, Grad norm: 3.153e+00\n",
      "Epoch 10049, Loss: 446.7080993652344, Neurons: 11, Grad norm: 2.834e+00\n",
      "Epoch 10049, Test loss: 442.7848205566406\n",
      "Epoch 10050, Loss: 446.7036437988281, Neurons: 11, Grad norm: 3.157e+00\n",
      "Epoch 10051, Loss: 446.6991882324219, Neurons: 11, Grad norm: 2.814e+00\n",
      "Epoch 10052, Loss: 446.6947021484375, Neurons: 11, Grad norm: 3.184e+00\n",
      "Epoch 10053, Loss: 446.690185546875, Neurons: 11, Grad norm: 2.881e+00\n",
      "Epoch 10054, Loss: 446.68572998046875, Neurons: 11, Grad norm: 3.296e+00\n",
      "Epoch 10055, Loss: 446.6812744140625, Neurons: 11, Grad norm: 2.959e+00\n",
      "Epoch 10056, Loss: 446.6767883300781, Neurons: 11, Grad norm: 3.365e+00\n",
      "Epoch 10057, Loss: 446.67230224609375, Neurons: 11, Grad norm: 3.091e+00\n",
      "Epoch 10058, Loss: 446.6678771972656, Neurons: 11, Grad norm: 3.650e+00\n",
      "Epoch 10059, Loss: 446.66339111328125, Neurons: 11, Grad norm: 3.464e+00\n",
      "Epoch 10060, Loss: 446.65887451171875, Neurons: 11, Grad norm: 4.196e+00\n",
      "Epoch 10061, Loss: 446.6543884277344, Neurons: 11, Grad norm: 4.059e+00\n",
      "Epoch 10062, Loss: 446.6499328613281, Neurons: 11, Grad norm: 5.051e+00\n",
      "Epoch 10063, Loss: 446.6454772949219, Neurons: 11, Grad norm: 5.168e+00\n",
      "Epoch 10064, Loss: 446.64105224609375, Neurons: 11, Grad norm: 6.597e+00\n",
      "Epoch 10065, Loss: 446.63653564453125, Neurons: 11, Grad norm: 7.147e+00\n",
      "Epoch 10066, Loss: 446.632080078125, Neurons: 11, Grad norm: 9.229e+00\n",
      "Epoch 10067, Loss: 446.6275939941406, Neurons: 11, Grad norm: 1.046e+01\n",
      "Epoch 10068, Loss: 446.6230773925781, Neurons: 11, Grad norm: 1.339e+01\n",
      "Epoch 10069, Loss: 446.61865234375, Neurons: 11, Grad norm: 1.570e+01\n",
      "Epoch 10070, Loss: 446.6142272949219, Neurons: 11, Grad norm: 2.013e+01\n",
      "Epoch 10071, Loss: 446.6097412109375, Neurons: 11, Grad norm: 2.426e+01\n",
      "Epoch 10072, Loss: 446.60528564453125, Neurons: 11, Grad norm: 3.101e+01\n",
      "Epoch 10073, Loss: 446.60089111328125, Neurons: 11, Grad norm: 3.816e+01\n",
      "Epoch 10074, Loss: 446.59649658203125, Neurons: 11, Grad norm: 4.889e+01\n",
      "Epoch 10075, Loss: 446.59210205078125, Neurons: 11, Grad norm: 6.105e+01\n",
      "Epoch 10076, Loss: 446.5877990722656, Neurons: 11, Grad norm: 7.804e+01\n",
      "Epoch 10077, Loss: 446.5835876464844, Neurons: 11, Grad norm: 9.787e+01\n",
      "Epoch 10078, Loss: 446.5794982910156, Neurons: 11, Grad norm: 1.239e+02\n",
      "Epoch 10079, Loss: 446.57568359375, Neurons: 11, Grad norm: 1.534e+02\n",
      "Epoch 10080, Loss: 446.5721740722656, Neurons: 11, Grad norm: 1.881e+02\n",
      "Epoch 10081, Loss: 446.5690002441406, Neurons: 11, Grad norm: 2.219e+02\n",
      "Epoch 10082, Loss: 446.5661926269531, Neurons: 11, Grad norm: 2.504e+02\n",
      "Epoch 10083, Loss: 446.563232421875, Neurons: 11, Grad norm: 2.596e+02\n",
      "Epoch 10084, Loss: 446.5594482421875, Neurons: 11, Grad norm: 2.408e+02\n",
      "Epoch 10085, Loss: 446.5540771484375, Neurons: 11, Grad norm: 1.853e+02\n",
      "Epoch 10086, Loss: 446.5472412109375, Neurons: 11, Grad norm: 1.019e+02\n",
      "Epoch 10087, Loss: 446.540283203125, Neurons: 11, Grad norm: 5.568e+00\n",
      "Epoch 10088, Loss: 446.5349426269531, Neurons: 11, Grad norm: 8.213e+01\n",
      "Epoch 10089, Loss: 446.53143310546875, Neurons: 11, Grad norm: 1.448e+02\n",
      "Epoch 10090, Loss: 446.52874755859375, Neurons: 11, Grad norm: 1.689e+02\n",
      "Epoch 10091, Loss: 446.525390625, Neurons: 11, Grad norm: 1.533e+02\n",
      "Epoch 10092, Loss: 446.5205993652344, Neurons: 11, Grad norm: 1.006e+02\n",
      "Epoch 10093, Loss: 446.514892578125, Neurons: 11, Grad norm: 2.887e+01\n",
      "Epoch 10094, Loss: 446.5096740722656, Neurons: 11, Grad norm: 4.446e+01\n",
      "Epoch 10095, Loss: 446.5056457519531, Neurons: 11, Grad norm: 9.783e+01\n",
      "Epoch 10096, Loss: 446.5022888183594, Neurons: 11, Grad norm: 1.220e+02\n",
      "Epoch 10097, Loss: 446.4986877441406, Neurons: 11, Grad norm: 1.105e+02\n",
      "Epoch 10098, Loss: 446.4942321777344, Neurons: 11, Grad norm: 7.178e+01\n",
      "Epoch 10099, Loss: 446.4892883300781, Neurons: 11, Grad norm: 1.620e+01\n",
      "Epoch 10099, Test loss: 442.58203125\n",
      "Epoch 10100, Loss: 446.4845886230469, Neurons: 11, Grad norm: 3.745e+01\n",
      "Epoch 10101, Loss: 446.4804992675781, Neurons: 11, Grad norm: 7.661e+01\n",
      "Epoch 10102, Loss: 446.4767761230469, Neurons: 11, Grad norm: 8.999e+01\n",
      "Epoch 10103, Loss: 446.4729309082031, Neurons: 11, Grad norm: 7.868e+01\n",
      "Epoch 10104, Loss: 446.4684753417969, Neurons: 11, Grad norm: 4.563e+01\n",
      "Epoch 10105, Loss: 446.4638977050781, Neurons: 11, Grad norm: 5.032e+00\n",
      "Epoch 10106, Loss: 446.4595031738281, Neurons: 11, Grad norm: 3.518e+01\n",
      "Epoch 10107, Loss: 446.4554748535156, Neurons: 11, Grad norm: 5.995e+01\n",
      "Epoch 10108, Loss: 446.45159912109375, Neurons: 11, Grad norm: 6.732e+01\n",
      "Epoch 10109, Loss: 446.4474792480469, Neurons: 11, Grad norm: 5.446e+01\n",
      "Epoch 10110, Loss: 446.44317626953125, Neurons: 11, Grad norm: 2.934e+01\n",
      "Epoch 10111, Loss: 446.43878173828125, Neurons: 11, Grad norm: 3.597e+00\n",
      "Epoch 10112, Loss: 446.4345397949219, Neurons: 11, Grad norm: 2.941e+01\n",
      "Epoch 10113, Loss: 446.43048095703125, Neurons: 11, Grad norm: 4.683e+01\n",
      "Epoch 10114, Loss: 446.42645263671875, Neurons: 11, Grad norm: 4.891e+01\n",
      "Epoch 10115, Loss: 446.42230224609375, Neurons: 11, Grad norm: 3.913e+01\n",
      "Epoch 10116, Loss: 446.4180908203125, Neurons: 11, Grad norm: 1.893e+01\n",
      "Epoch 10117, Loss: 446.4137878417969, Neurons: 11, Grad norm: 4.007e+00\n",
      "Epoch 10118, Loss: 446.4095764160156, Neurons: 11, Grad norm: 2.344e+01\n",
      "Epoch 10119, Loss: 446.4054260253906, Neurons: 11, Grad norm: 3.430e+01\n",
      "Epoch 10120, Loss: 446.4013977050781, Neurons: 11, Grad norm: 3.661e+01\n",
      "Epoch 10121, Loss: 446.3972473144531, Neurons: 11, Grad norm: 2.813e+01\n",
      "Epoch 10122, Loss: 446.3929748535156, Neurons: 11, Grad norm: 1.468e+01\n",
      "Epoch 10123, Loss: 446.3887939453125, Neurons: 11, Grad norm: 3.556e+00\n",
      "Epoch 10124, Loss: 446.38458251953125, Neurons: 11, Grad norm: 1.619e+01\n",
      "Epoch 10125, Loss: 446.3804931640625, Neurons: 11, Grad norm: 2.560e+01\n",
      "Epoch 10126, Loss: 446.37640380859375, Neurons: 11, Grad norm: 2.675e+01\n",
      "Epoch 10127, Loss: 446.3721923828125, Neurons: 11, Grad norm: 2.263e+01\n",
      "Epoch 10128, Loss: 446.3680419921875, Neurons: 11, Grad norm: 1.237e+01\n",
      "Epoch 10129, Loss: 446.36383056640625, Neurons: 11, Grad norm: 2.716e+00\n",
      "Epoch 10130, Loss: 446.3596496582031, Neurons: 11, Grad norm: 1.064e+01\n",
      "Epoch 10131, Loss: 446.3554992675781, Neurons: 11, Grad norm: 1.723e+01\n",
      "Epoch 10132, Loss: 446.35137939453125, Neurons: 11, Grad norm: 2.058e+01\n",
      "Epoch 10133, Loss: 446.3471984863281, Neurons: 11, Grad norm: 1.774e+01\n",
      "Epoch 10134, Loss: 446.34307861328125, Neurons: 11, Grad norm: 1.248e+01\n",
      "Epoch 10135, Loss: 446.3388977050781, Neurons: 11, Grad norm: 4.225e+00\n",
      "Epoch 10136, Loss: 446.3346862792969, Neurons: 11, Grad norm: 4.675e+00\n",
      "Epoch 10137, Loss: 446.3304748535156, Neurons: 11, Grad norm: 1.127e+01\n",
      "Epoch 10138, Loss: 446.3263854980469, Neurons: 11, Grad norm: 1.393e+01\n",
      "Epoch 10139, Loss: 446.3222351074219, Neurons: 11, Grad norm: 1.466e+01\n",
      "Epoch 10140, Loss: 446.3180847167969, Neurons: 11, Grad norm: 1.108e+01\n",
      "Epoch 10141, Loss: 446.31390380859375, Neurons: 11, Grad norm: 6.981e+00\n",
      "Epoch 10142, Loss: 446.3096923828125, Neurons: 11, Grad norm: 2.473e+00\n",
      "Epoch 10143, Loss: 446.30548095703125, Neurons: 11, Grad norm: 5.118e+00\n",
      "Epoch 10144, Loss: 446.3013916015625, Neurons: 11, Grad norm: 9.222e+00\n",
      "Epoch 10145, Loss: 446.29718017578125, Neurons: 11, Grad norm: 1.007e+01\n",
      "Epoch 10146, Loss: 446.2930908203125, Neurons: 11, Grad norm: 1.013e+01\n",
      "Epoch 10147, Loss: 446.28887939453125, Neurons: 11, Grad norm: 7.058e+00\n",
      "Epoch 10148, Loss: 446.2846984863281, Neurons: 11, Grad norm: 4.427e+00\n",
      "Epoch 10149, Loss: 446.28057861328125, Neurons: 11, Grad norm: 2.643e+00\n",
      "Epoch 10149, Test loss: 442.3789978027344\n",
      "Epoch 10150, Loss: 446.2763977050781, Neurons: 11, Grad norm: 4.437e+00\n",
      "Epoch 10151, Loss: 446.2721862792969, Neurons: 11, Grad norm: 7.253e+00\n",
      "Epoch 10152, Loss: 446.2680358886719, Neurons: 11, Grad norm: 7.555e+00\n",
      "Epoch 10153, Loss: 446.2638244628906, Neurons: 11, Grad norm: 7.766e+00\n",
      "Epoch 10154, Loss: 446.2596740722656, Neurons: 11, Grad norm: 5.523e+00\n",
      "Epoch 10155, Loss: 446.2555847167969, Neurons: 11, Grad norm: 4.004e+00\n",
      "Epoch 10156, Loss: 446.2513427734375, Neurons: 11, Grad norm: 2.486e+00\n",
      "Epoch 10157, Loss: 446.2471923828125, Neurons: 11, Grad norm: 3.251e+00\n",
      "Epoch 10158, Loss: 446.24298095703125, Neurons: 11, Grad norm: 5.353e+00\n",
      "Epoch 10159, Loss: 446.2388916015625, Neurons: 11, Grad norm: 5.569e+00\n",
      "Epoch 10160, Loss: 446.23468017578125, Neurons: 11, Grad norm: 6.225e+00\n",
      "Epoch 10161, Loss: 446.2304992675781, Neurons: 11, Grad norm: 4.826e+00\n",
      "Epoch 10162, Loss: 446.2263488769531, Neurons: 11, Grad norm: 4.176e+00\n",
      "Epoch 10163, Loss: 446.2221374511719, Neurons: 11, Grad norm: 2.611e+00\n",
      "Epoch 10164, Loss: 446.2179260253906, Neurons: 11, Grad norm: 2.468e+00\n",
      "Epoch 10165, Loss: 446.2137756347656, Neurons: 11, Grad norm: 3.527e+00\n",
      "Epoch 10166, Loss: 446.2095947265625, Neurons: 11, Grad norm: 3.805e+00\n",
      "Epoch 10167, Loss: 446.2054443359375, Neurons: 11, Grad norm: 4.731e+00\n",
      "Epoch 10168, Loss: 446.2012023925781, Neurons: 11, Grad norm: 4.041e+00\n",
      "Epoch 10169, Loss: 446.19708251953125, Neurons: 11, Grad norm: 4.147e+00\n",
      "Epoch 10170, Loss: 446.1929016113281, Neurons: 11, Grad norm: 2.957e+00\n",
      "Epoch 10171, Loss: 446.1886901855469, Neurons: 11, Grad norm: 2.704e+00\n",
      "Epoch 10172, Loss: 446.1844787597656, Neurons: 11, Grad norm: 2.550e+00\n",
      "Epoch 10173, Loss: 446.1803894042969, Neurons: 11, Grad norm: 2.622e+00\n",
      "Epoch 10174, Loss: 446.1761474609375, Neurons: 11, Grad norm: 3.360e+00\n",
      "Epoch 10175, Loss: 446.1719970703125, Neurons: 11, Grad norm: 3.144e+00\n",
      "Epoch 10176, Loss: 446.16778564453125, Neurons: 11, Grad norm: 3.680e+00\n",
      "Epoch 10177, Loss: 446.16363525390625, Neurons: 11, Grad norm: 3.022e+00\n",
      "Epoch 10178, Loss: 446.159423828125, Neurons: 11, Grad norm: 3.156e+00\n",
      "Epoch 10179, Loss: 446.1553039550781, Neurons: 11, Grad norm: 2.542e+00\n",
      "Epoch 10180, Loss: 446.1510925292969, Neurons: 11, Grad norm: 2.549e+00\n",
      "Epoch 10181, Loss: 446.1469421386719, Neurons: 11, Grad norm: 2.565e+00\n",
      "Epoch 10182, Loss: 446.1427001953125, Neurons: 11, Grad norm: 2.525e+00\n",
      "Epoch 10183, Loss: 446.13848876953125, Neurons: 11, Grad norm: 2.973e+00\n",
      "Epoch 10184, Loss: 446.13427734375, Neurons: 11, Grad norm: 2.700e+00\n",
      "Epoch 10185, Loss: 446.13018798828125, Neurons: 11, Grad norm: 3.069e+00\n",
      "Epoch 10186, Loss: 446.1259765625, Neurons: 11, Grad norm: 2.635e+00\n",
      "Epoch 10187, Loss: 446.1217956542969, Neurons: 11, Grad norm: 2.823e+00\n",
      "Epoch 10188, Loss: 446.1175842285156, Neurons: 11, Grad norm: 2.469e+00\n",
      "Epoch 10189, Loss: 446.1134033203125, Neurons: 11, Grad norm: 2.551e+00\n",
      "Epoch 10190, Loss: 446.1092529296875, Neurons: 11, Grad norm: 2.461e+00\n",
      "Epoch 10191, Loss: 446.10498046875, Neurons: 11, Grad norm: 2.460e+00\n",
      "Epoch 10192, Loss: 446.1007995605469, Neurons: 11, Grad norm: 2.603e+00\n",
      "Epoch 10193, Loss: 446.0966491699219, Neurons: 11, Grad norm: 2.477e+00\n",
      "Epoch 10194, Loss: 446.0924987792969, Neurons: 11, Grad norm: 2.748e+00\n",
      "Epoch 10195, Loss: 446.0882263183594, Neurons: 11, Grad norm: 2.527e+00\n",
      "Epoch 10196, Loss: 446.08404541015625, Neurons: 11, Grad norm: 2.805e+00\n",
      "Epoch 10197, Loss: 446.07989501953125, Neurons: 11, Grad norm: 2.509e+00\n",
      "Epoch 10198, Loss: 446.07568359375, Neurons: 11, Grad norm: 2.668e+00\n",
      "Epoch 10199, Loss: 446.0715026855469, Neurons: 11, Grad norm: 2.433e+00\n",
      "Epoch 10199, Test loss: 442.17828369140625\n",
      "Epoch 10200, Loss: 446.0672912597656, Neurons: 11, Grad norm: 2.484e+00\n",
      "Epoch 10201, Loss: 446.0630798339844, Neurons: 11, Grad norm: 2.506e+00\n",
      "Epoch 10202, Loss: 446.05889892578125, Neurons: 11, Grad norm: 2.448e+00\n",
      "Epoch 10203, Loss: 446.05474853515625, Neurons: 11, Grad norm: 2.744e+00\n",
      "Epoch 10204, Loss: 446.05047607421875, Neurons: 11, Grad norm: 2.557e+00\n",
      "Epoch 10205, Loss: 446.0462951660156, Neurons: 11, Grad norm: 2.932e+00\n",
      "Epoch 10206, Loss: 446.0420837402344, Neurons: 11, Grad norm: 2.619e+00\n",
      "Epoch 10207, Loss: 446.03790283203125, Neurons: 11, Grad norm: 2.938e+00\n",
      "Epoch 10208, Loss: 446.03369140625, Neurons: 11, Grad norm: 2.579e+00\n",
      "Epoch 10209, Loss: 446.02947998046875, Neurons: 11, Grad norm: 2.857e+00\n",
      "Epoch 10210, Loss: 446.0252990722656, Neurons: 11, Grad norm: 2.535e+00\n",
      "Epoch 10211, Loss: 446.0210876464844, Neurons: 11, Grad norm: 2.773e+00\n",
      "Epoch 10212, Loss: 446.0168762207031, Neurons: 11, Grad norm: 2.475e+00\n",
      "Epoch 10213, Loss: 446.0126953125, Neurons: 11, Grad norm: 2.661e+00\n",
      "Epoch 10214, Loss: 446.00848388671875, Neurons: 11, Grad norm: 2.445e+00\n",
      "Epoch 10215, Loss: 446.0043029785156, Neurons: 11, Grad norm: 2.556e+00\n",
      "Epoch 10216, Loss: 446.0000915527344, Neurons: 11, Grad norm: 2.434e+00\n",
      "Epoch 10217, Loss: 445.9958801269531, Neurons: 11, Grad norm: 2.451e+00\n",
      "Epoch 10218, Loss: 445.99169921875, Neurons: 11, Grad norm: 2.522e+00\n",
      "Epoch 10219, Loss: 445.98748779296875, Neurons: 11, Grad norm: 2.448e+00\n",
      "Epoch 10220, Loss: 445.9832763671875, Neurons: 11, Grad norm: 2.762e+00\n",
      "Epoch 10221, Loss: 445.9790344238281, Neurons: 11, Grad norm: 2.614e+00\n",
      "Epoch 10222, Loss: 445.9748840332031, Neurons: 11, Grad norm: 3.195e+00\n",
      "Epoch 10223, Loss: 445.9705810546875, Neurons: 11, Grad norm: 2.992e+00\n",
      "Epoch 10224, Loss: 445.9664306640625, Neurons: 11, Grad norm: 3.741e+00\n",
      "Epoch 10225, Loss: 445.9621887207031, Neurons: 11, Grad norm: 3.428e+00\n",
      "Epoch 10226, Loss: 445.9580383300781, Neurons: 11, Grad norm: 4.221e+00\n",
      "Epoch 10227, Loss: 445.95379638671875, Neurons: 11, Grad norm: 3.887e+00\n",
      "Epoch 10228, Loss: 445.9495849609375, Neurons: 11, Grad norm: 4.779e+00\n",
      "Epoch 10229, Loss: 445.94537353515625, Neurons: 11, Grad norm: 4.513e+00\n",
      "Epoch 10230, Loss: 445.9411926269531, Neurons: 11, Grad norm: 5.581e+00\n",
      "Epoch 10231, Loss: 445.9369812011719, Neurons: 11, Grad norm: 5.430e+00\n",
      "Epoch 10232, Loss: 445.93280029296875, Neurons: 11, Grad norm: 6.623e+00\n",
      "Epoch 10233, Loss: 445.92852783203125, Neurons: 11, Grad norm: 6.483e+00\n",
      "Epoch 10234, Loss: 445.9242858886719, Neurons: 11, Grad norm: 7.698e+00\n",
      "Epoch 10235, Loss: 445.9200744628906, Neurons: 11, Grad norm: 7.614e+00\n",
      "Epoch 10236, Loss: 445.9158935546875, Neurons: 11, Grad norm: 9.026e+00\n",
      "Epoch 10237, Loss: 445.91168212890625, Neurons: 11, Grad norm: 9.147e+00\n",
      "Epoch 10238, Loss: 445.9075012207031, Neurons: 11, Grad norm: 1.091e+01\n",
      "Epoch 10239, Loss: 445.9032897949219, Neurons: 11, Grad norm: 1.145e+01\n",
      "Epoch 10240, Loss: 445.8990478515625, Neurons: 11, Grad norm: 1.377e+01\n",
      "Epoch 10241, Loss: 445.894775390625, Neurons: 11, Grad norm: 1.502e+01\n",
      "Epoch 10242, Loss: 445.8905944824219, Neurons: 11, Grad norm: 1.812e+01\n",
      "Epoch 10243, Loss: 445.8863830566406, Neurons: 11, Grad norm: 2.032e+01\n",
      "Epoch 10244, Loss: 445.8822021484375, Neurons: 11, Grad norm: 2.464e+01\n",
      "Epoch 10245, Loss: 445.87799072265625, Neurons: 11, Grad norm: 2.835e+01\n",
      "Epoch 10246, Loss: 445.873779296875, Neurons: 11, Grad norm: 3.452e+01\n",
      "Epoch 10247, Loss: 445.8695983886719, Neurons: 11, Grad norm: 4.054e+01\n",
      "Epoch 10248, Loss: 445.8654479980469, Neurons: 11, Grad norm: 4.970e+01\n",
      "Epoch 10249, Loss: 445.8612976074219, Neurons: 11, Grad norm: 5.933e+01\n",
      "Epoch 10249, Test loss: 441.99090576171875\n",
      "Epoch 10250, Loss: 445.857177734375, Neurons: 11, Grad norm: 7.272e+01\n",
      "Epoch 10251, Loss: 445.8531799316406, Neurons: 11, Grad norm: 8.737e+01\n",
      "Epoch 10252, Loss: 445.84918212890625, Neurons: 11, Grad norm: 1.065e+02\n",
      "Epoch 10253, Loss: 445.84539794921875, Neurons: 11, Grad norm: 1.272e+02\n",
      "Epoch 10254, Loss: 445.8416748046875, Neurons: 11, Grad norm: 1.520e+02\n",
      "Epoch 10255, Loss: 445.8382873535156, Neurons: 11, Grad norm: 1.763e+02\n",
      "Epoch 10256, Loss: 445.8349914550781, Neurons: 11, Grad norm: 2.003e+02\n",
      "Epoch 10257, Loss: 445.8316955566406, Neurons: 11, Grad norm: 2.160e+02\n",
      "Epoch 10258, Loss: 445.8282775878906, Neurons: 11, Grad norm: 2.200e+02\n",
      "Epoch 10259, Loss: 445.82427978515625, Neurons: 11, Grad norm: 2.031e+02\n",
      "Epoch 10260, Loss: 445.8194274902344, Neurons: 11, Grad norm: 1.657e+02\n",
      "Epoch 10261, Loss: 445.81390380859375, Neurons: 11, Grad norm: 1.076e+02\n",
      "Epoch 10262, Loss: 445.8081359863281, Neurons: 11, Grad norm: 4.059e+01\n",
      "Epoch 10263, Loss: 445.802978515625, Neurons: 11, Grad norm: 2.758e+01\n",
      "Epoch 10264, Loss: 445.79888916015625, Neurons: 11, Grad norm: 8.322e+01\n",
      "Epoch 10265, Loss: 445.7955017089844, Neurons: 11, Grad norm: 1.221e+02\n",
      "Epoch 10266, Loss: 445.79229736328125, Neurons: 11, Grad norm: 1.364e+02\n",
      "Epoch 10267, Loss: 445.78863525390625, Neurons: 11, Grad norm: 1.279e+02\n",
      "Epoch 10268, Loss: 445.7843322753906, Neurons: 11, Grad norm: 9.624e+01\n",
      "Epoch 10269, Loss: 445.77960205078125, Neurons: 11, Grad norm: 5.159e+01\n",
      "Epoch 10270, Loss: 445.7747802734375, Neurons: 11, Grad norm: 2.439e+00\n",
      "Epoch 10271, Loss: 445.7704772949219, Neurons: 11, Grad norm: 4.450e+01\n",
      "Epoch 10272, Loss: 445.7666931152344, Neurons: 11, Grad norm: 7.814e+01\n",
      "Epoch 10273, Loss: 445.7630310058594, Neurons: 11, Grad norm: 9.276e+01\n",
      "Epoch 10274, Loss: 445.75933837890625, Neurons: 11, Grad norm: 9.012e+01\n",
      "Epoch 10275, Loss: 445.75518798828125, Neurons: 11, Grad norm: 6.931e+01\n",
      "Epoch 10276, Loss: 445.7508850097656, Neurons: 11, Grad norm: 3.883e+01\n",
      "Epoch 10277, Loss: 445.7464904785156, Neurons: 11, Grad norm: 3.539e+00\n",
      "Epoch 10278, Loss: 445.7422790527344, Neurons: 11, Grad norm: 2.916e+01\n",
      "Epoch 10279, Loss: 445.7384033203125, Neurons: 11, Grad norm: 5.361e+01\n",
      "Epoch 10280, Loss: 445.7345886230469, Neurons: 11, Grad norm: 6.437e+01\n",
      "Epoch 10281, Loss: 445.7306823730469, Neurons: 11, Grad norm: 6.356e+01\n",
      "Epoch 10282, Loss: 445.72662353515625, Neurons: 11, Grad norm: 4.976e+01\n",
      "Epoch 10283, Loss: 445.7225036621094, Neurons: 11, Grad norm: 2.968e+01\n",
      "Epoch 10284, Loss: 445.7182922363281, Neurons: 11, Grad norm: 5.223e+00\n",
      "Epoch 10285, Loss: 445.7142028808594, Neurons: 11, Grad norm: 1.748e+01\n",
      "Epoch 10286, Loss: 445.7101745605469, Neurons: 11, Grad norm: 3.546e+01\n",
      "Epoch 10287, Loss: 445.70623779296875, Neurons: 11, Grad norm: 4.404e+01\n",
      "Epoch 10288, Loss: 445.70233154296875, Neurons: 11, Grad norm: 4.547e+01\n",
      "Epoch 10289, Loss: 445.69830322265625, Neurons: 11, Grad norm: 3.758e+01\n",
      "Epoch 10290, Loss: 445.6941833496094, Neurons: 11, Grad norm: 2.541e+01\n",
      "Epoch 10291, Loss: 445.6900939941406, Neurons: 11, Grad norm: 8.866e+00\n",
      "Epoch 10292, Loss: 445.68603515625, Neurons: 11, Grad norm: 6.996e+00\n",
      "Epoch 10293, Loss: 445.6819763183594, Neurons: 11, Grad norm: 2.064e+01\n",
      "Epoch 10294, Loss: 445.677978515625, Neurons: 11, Grad norm: 2.838e+01\n",
      "Epoch 10295, Loss: 445.6741027832031, Neurons: 11, Grad norm: 3.220e+01\n",
      "Epoch 10296, Loss: 445.6700439453125, Neurons: 11, Grad norm: 2.903e+01\n",
      "Epoch 10297, Loss: 445.6659851074219, Neurons: 11, Grad norm: 2.297e+01\n",
      "Epoch 10298, Loss: 445.6619873046875, Neurons: 11, Grad norm: 1.259e+01\n",
      "Epoch 10299, Loss: 445.65789794921875, Neurons: 11, Grad norm: 3.383e+00\n",
      "Epoch 10299, Test loss: 441.7780456542969\n",
      "Epoch 10300, Loss: 445.6538391113281, Neurons: 11, Grad norm: 8.658e+00\n",
      "Epoch 10301, Loss: 445.64984130859375, Neurons: 11, Grad norm: 1.548e+01\n",
      "Epoch 10302, Loss: 445.6458435058594, Neurons: 11, Grad norm: 2.088e+01\n",
      "Epoch 10303, Loss: 445.641845703125, Neurons: 11, Grad norm: 2.145e+01\n",
      "Epoch 10304, Loss: 445.6377868652344, Neurons: 11, Grad norm: 2.038e+01\n",
      "Epoch 10305, Loss: 445.6337890625, Neurons: 11, Grad norm: 1.521e+01\n",
      "Epoch 10306, Loss: 445.6297302246094, Neurons: 11, Grad norm: 9.969e+00\n",
      "Epoch 10307, Loss: 445.6257019042969, Neurons: 11, Grad norm: 3.137e+00\n",
      "Epoch 10308, Loss: 445.6216735839844, Neurons: 11, Grad norm: 4.446e+00\n",
      "Epoch 10309, Loss: 445.6175842285156, Neurons: 11, Grad norm: 1.015e+01\n",
      "Epoch 10310, Loss: 445.61358642578125, Neurons: 11, Grad norm: 1.283e+01\n",
      "Epoch 10311, Loss: 445.6095886230469, Neurons: 11, Grad norm: 1.511e+01\n",
      "Epoch 10312, Loss: 445.6055908203125, Neurons: 11, Grad norm: 1.392e+01\n",
      "Epoch 10313, Loss: 445.6015319824219, Neurons: 11, Grad norm: 1.262e+01\n",
      "Epoch 10314, Loss: 445.5975036621094, Neurons: 11, Grad norm: 8.596e+00\n",
      "Epoch 10315, Loss: 445.59344482421875, Neurons: 11, Grad norm: 5.497e+00\n",
      "Epoch 10316, Loss: 445.5893859863281, Neurons: 11, Grad norm: 2.389e+00\n",
      "Epoch 10317, Loss: 445.58538818359375, Neurons: 11, Grad norm: 3.998e+00\n",
      "Epoch 10318, Loss: 445.5813293457031, Neurons: 11, Grad norm: 7.481e+00\n",
      "Epoch 10319, Loss: 445.5773010253906, Neurons: 11, Grad norm: 8.720e+00\n",
      "Epoch 10320, Loss: 445.57330322265625, Neurons: 11, Grad norm: 1.041e+01\n",
      "Epoch 10321, Loss: 445.5692443847656, Neurons: 11, Grad norm: 9.563e+00\n",
      "Epoch 10322, Loss: 445.565185546875, Neurons: 11, Grad norm: 9.274e+00\n",
      "Epoch 10323, Loss: 445.5611877441406, Neurons: 11, Grad norm: 6.773e+00\n",
      "Epoch 10324, Loss: 445.5570983886719, Neurons: 11, Grad norm: 5.329e+00\n",
      "Epoch 10325, Loss: 445.5531005859375, Neurons: 11, Grad norm: 2.769e+00\n",
      "Epoch 10326, Loss: 445.5490417480469, Neurons: 11, Grad norm: 2.411e+00\n",
      "Epoch 10327, Loss: 445.5450439453125, Neurons: 11, Grad norm: 4.068e+00\n",
      "Epoch 10328, Loss: 445.5409851074219, Neurons: 11, Grad norm: 4.862e+00\n",
      "Epoch 10329, Loss: 445.53692626953125, Neurons: 11, Grad norm: 6.647e+00\n",
      "Epoch 10330, Loss: 445.5329284667969, Neurons: 11, Grad norm: 6.417e+00\n",
      "Epoch 10331, Loss: 445.5289001464844, Neurons: 11, Grad norm: 7.107e+00\n",
      "Epoch 10332, Loss: 445.52484130859375, Neurons: 11, Grad norm: 5.860e+00\n",
      "Epoch 10333, Loss: 445.5207824707031, Neurons: 11, Grad norm: 5.709e+00\n",
      "Epoch 10334, Loss: 445.51678466796875, Neurons: 11, Grad norm: 3.954e+00\n",
      "Epoch 10335, Loss: 445.5126953125, Neurons: 11, Grad norm: 3.481e+00\n",
      "Epoch 10336, Loss: 445.5086975097656, Neurons: 11, Grad norm: 2.403e+00\n",
      "Epoch 10337, Loss: 445.504638671875, Neurons: 11, Grad norm: 2.392e+00\n",
      "Epoch 10338, Loss: 445.5005798339844, Neurons: 11, Grad norm: 3.209e+00\n",
      "Epoch 10339, Loss: 445.4965515136719, Neurons: 11, Grad norm: 3.374e+00\n",
      "Epoch 10340, Loss: 445.492431640625, Neurons: 11, Grad norm: 4.606e+00\n",
      "Epoch 10341, Loss: 445.4884033203125, Neurons: 11, Grad norm: 4.337e+00\n",
      "Epoch 10342, Loss: 445.484375, Neurons: 11, Grad norm: 5.225e+00\n",
      "Epoch 10343, Loss: 445.48028564453125, Neurons: 11, Grad norm: 4.598e+00\n",
      "Epoch 10344, Loss: 445.4762878417969, Neurons: 11, Grad norm: 5.244e+00\n",
      "Epoch 10345, Loss: 445.4721984863281, Neurons: 11, Grad norm: 4.406e+00\n",
      "Epoch 10346, Loss: 445.46820068359375, Neurons: 11, Grad norm: 4.763e+00\n",
      "Epoch 10347, Loss: 445.4640808105469, Neurons: 11, Grad norm: 3.748e+00\n",
      "Epoch 10348, Loss: 445.4600830078125, Neurons: 11, Grad norm: 3.961e+00\n",
      "Epoch 10349, Loss: 445.4560241699219, Neurons: 11, Grad norm: 2.981e+00\n",
      "Epoch 10349, Test loss: 441.58355712890625\n",
      "Epoch 10350, Loss: 445.4519958496094, Neurons: 11, Grad norm: 3.067e+00\n",
      "Epoch 10351, Loss: 445.4478759765625, Neurons: 11, Grad norm: 2.425e+00\n",
      "Epoch 10352, Loss: 445.4438781738281, Neurons: 11, Grad norm: 2.459e+00\n",
      "Epoch 10353, Loss: 445.4398498535156, Neurons: 11, Grad norm: 2.499e+00\n",
      "Epoch 10354, Loss: 445.43572998046875, Neurons: 11, Grad norm: 2.432e+00\n",
      "Epoch 10355, Loss: 445.43170166015625, Neurons: 11, Grad norm: 2.966e+00\n",
      "Epoch 10356, Loss: 445.4277038574219, Neurons: 11, Grad norm: 2.757e+00\n",
      "Epoch 10357, Loss: 445.423583984375, Neurons: 11, Grad norm: 3.501e+00\n",
      "Epoch 10358, Loss: 445.4195251464844, Neurons: 11, Grad norm: 3.185e+00\n",
      "Epoch 10359, Loss: 445.4154968261719, Neurons: 11, Grad norm: 3.955e+00\n",
      "Epoch 10360, Loss: 445.411376953125, Neurons: 11, Grad norm: 3.454e+00\n",
      "Epoch 10361, Loss: 445.4073791503906, Neurons: 11, Grad norm: 4.149e+00\n",
      "Epoch 10362, Loss: 445.4032897949219, Neurons: 11, Grad norm: 3.591e+00\n",
      "Epoch 10363, Loss: 445.3992004394531, Neurons: 11, Grad norm: 4.312e+00\n",
      "Epoch 10364, Loss: 445.3951416015625, Neurons: 11, Grad norm: 3.759e+00\n",
      "Epoch 10365, Loss: 445.3911437988281, Neurons: 11, Grad norm: 4.484e+00\n",
      "Epoch 10366, Loss: 445.38702392578125, Neurons: 11, Grad norm: 3.901e+00\n",
      "Epoch 10367, Loss: 445.38299560546875, Neurons: 11, Grad norm: 4.557e+00\n",
      "Epoch 10368, Loss: 445.3788757324219, Neurons: 11, Grad norm: 3.901e+00\n",
      "Epoch 10369, Loss: 445.3748779296875, Neurons: 11, Grad norm: 4.540e+00\n",
      "Epoch 10370, Loss: 445.37078857421875, Neurons: 11, Grad norm: 3.894e+00\n",
      "Epoch 10371, Loss: 445.36669921875, Neurons: 11, Grad norm: 4.555e+00\n",
      "Epoch 10372, Loss: 445.3627014160156, Neurons: 11, Grad norm: 3.981e+00\n",
      "Epoch 10373, Loss: 445.35858154296875, Neurons: 11, Grad norm: 4.883e+00\n",
      "Epoch 10374, Loss: 445.35455322265625, Neurons: 11, Grad norm: 4.526e+00\n",
      "Epoch 10375, Loss: 445.3504333496094, Neurons: 11, Grad norm: 5.729e+00\n",
      "Epoch 10376, Loss: 445.34637451171875, Neurons: 11, Grad norm: 5.676e+00\n",
      "Epoch 10377, Loss: 445.34234619140625, Neurons: 11, Grad norm: 7.268e+00\n",
      "Epoch 10378, Loss: 445.3382873535156, Neurons: 11, Grad norm: 7.609e+00\n",
      "Epoch 10379, Loss: 445.3341369628906, Neurons: 11, Grad norm: 9.748e+00\n",
      "Epoch 10380, Loss: 445.33013916015625, Neurons: 11, Grad norm: 1.064e+01\n",
      "Epoch 10381, Loss: 445.32598876953125, Neurons: 11, Grad norm: 1.340e+01\n",
      "Epoch 10382, Loss: 445.3219909667969, Neurons: 11, Grad norm: 1.504e+01\n",
      "Epoch 10383, Loss: 445.3179016113281, Neurons: 11, Grad norm: 1.884e+01\n",
      "Epoch 10384, Loss: 445.3138427734375, Neurons: 11, Grad norm: 2.187e+01\n",
      "Epoch 10385, Loss: 445.3097839355469, Neurons: 11, Grad norm: 2.742e+01\n",
      "Epoch 10386, Loss: 445.30572509765625, Neurons: 11, Grad norm: 3.255e+01\n",
      "Epoch 10387, Loss: 445.30169677734375, Neurons: 11, Grad norm: 4.072e+01\n",
      "Epoch 10388, Loss: 445.2976989746094, Neurons: 11, Grad norm: 4.910e+01\n",
      "Epoch 10389, Loss: 445.293701171875, Neurons: 11, Grad norm: 6.130e+01\n",
      "Epoch 10390, Loss: 445.2897033691406, Neurons: 11, Grad norm: 7.464e+01\n",
      "Epoch 10391, Loss: 445.285888671875, Neurons: 11, Grad norm: 9.281e+01\n",
      "Epoch 10392, Loss: 445.2820739746094, Neurons: 11, Grad norm: 1.132e+02\n",
      "Epoch 10393, Loss: 445.27850341796875, Neurons: 11, Grad norm: 1.391e+02\n",
      "Epoch 10394, Loss: 445.27508544921875, Neurons: 11, Grad norm: 1.669e+02\n",
      "Epoch 10395, Loss: 445.2719421386719, Neurons: 11, Grad norm: 1.981e+02\n",
      "Epoch 10396, Loss: 445.26910400390625, Neurons: 11, Grad norm: 2.253e+02\n",
      "Epoch 10397, Loss: 445.26629638671875, Neurons: 11, Grad norm: 2.452e+02\n",
      "Epoch 10398, Loss: 445.26318359375, Neurons: 11, Grad norm: 2.456e+02\n",
      "Epoch 10399, Loss: 445.2592468261719, Neurons: 11, Grad norm: 2.219e+02\n",
      "Epoch 10399, Test loss: 441.3333740234375\n",
      "Epoch 10400, Loss: 445.2541809082031, Neurons: 11, Grad norm: 1.685e+02\n",
      "Epoch 10401, Loss: 445.2480773925781, Neurons: 11, Grad norm: 9.464e+01\n",
      "Epoch 10402, Loss: 445.2420959472656, Neurons: 11, Grad norm: 1.076e+01\n",
      "Epoch 10403, Loss: 445.2372741699219, Neurons: 11, Grad norm: 6.564e+01\n",
      "Epoch 10404, Loss: 445.23382568359375, Neurons: 11, Grad norm: 1.243e+02\n",
      "Epoch 10405, Loss: 445.2310791015625, Neurons: 11, Grad norm: 1.536e+02\n",
      "Epoch 10406, Loss: 445.22802734375, Neurons: 11, Grad norm: 1.527e+02\n",
      "Epoch 10407, Loss: 445.2240905761719, Neurons: 11, Grad norm: 1.199e+02\n",
      "Epoch 10408, Loss: 445.21929931640625, Neurons: 11, Grad norm: 6.698e+01\n",
      "Epoch 10409, Loss: 445.2143859863281, Neurons: 11, Grad norm: 4.363e+00\n",
      "Epoch 10410, Loss: 445.2100524902344, Neurons: 11, Grad norm: 5.266e+01\n",
      "Epoch 10411, Loss: 445.20648193359375, Neurons: 11, Grad norm: 9.368e+01\n",
      "Epoch 10412, Loss: 445.20318603515625, Neurons: 11, Grad norm: 1.094e+02\n",
      "Epoch 10413, Loss: 445.19964599609375, Neurons: 11, Grad norm: 1.015e+02\n",
      "Epoch 10414, Loss: 445.1955871582031, Neurons: 11, Grad norm: 7.075e+01\n",
      "Epoch 10415, Loss: 445.1911926269531, Neurons: 11, Grad norm: 2.883e+01\n",
      "Epoch 10416, Loss: 445.1868896484375, Neurons: 11, Grad norm: 1.708e+01\n",
      "Epoch 10417, Loss: 445.1829833984375, Neurons: 11, Grad norm: 5.294e+01\n",
      "Epoch 10418, Loss: 445.17938232421875, Neurons: 11, Grad norm: 7.530e+01\n",
      "Epoch 10419, Loss: 445.17584228515625, Neurons: 11, Grad norm: 7.748e+01\n",
      "Epoch 10420, Loss: 445.1719970703125, Neurons: 11, Grad norm: 6.385e+01\n",
      "Epoch 10421, Loss: 445.1679382324219, Neurons: 11, Grad norm: 3.603e+01\n",
      "Epoch 10422, Loss: 445.1637878417969, Neurons: 11, Grad norm: 5.026e+00\n",
      "Epoch 10423, Loss: 445.1597900390625, Neurons: 11, Grad norm: 2.648e+01\n",
      "Epoch 10424, Loss: 445.1559753417969, Neurons: 11, Grad norm: 4.705e+01\n",
      "Epoch 10425, Loss: 445.15228271484375, Neurons: 11, Grad norm: 5.702e+01\n",
      "Epoch 10426, Loss: 445.14849853515625, Neurons: 11, Grad norm: 5.235e+01\n",
      "Epoch 10427, Loss: 445.1446838378906, Neurons: 11, Grad norm: 3.845e+01\n",
      "Epoch 10428, Loss: 445.140625, Neurons: 11, Grad norm: 1.636e+01\n",
      "Epoch 10429, Loss: 445.1366271972656, Neurons: 11, Grad norm: 6.158e+00\n",
      "Epoch 10430, Loss: 445.13275146484375, Neurons: 11, Grad norm: 2.583e+01\n",
      "Epoch 10431, Loss: 445.1289978027344, Neurons: 11, Grad norm: 3.703e+01\n",
      "Epoch 10432, Loss: 445.12518310546875, Neurons: 11, Grad norm: 4.109e+01\n",
      "Epoch 10433, Loss: 445.121337890625, Neurons: 11, Grad norm: 3.495e+01\n",
      "Epoch 10434, Loss: 445.117431640625, Neurons: 11, Grad norm: 2.389e+01\n",
      "Epoch 10435, Loss: 445.1134948730469, Neurons: 11, Grad norm: 7.814e+00\n",
      "Epoch 10436, Loss: 445.1095886230469, Neurons: 11, Grad norm: 7.641e+00\n",
      "Epoch 10437, Loss: 445.1056823730469, Neurons: 11, Grad norm: 2.075e+01\n",
      "Epoch 10438, Loss: 445.1018981933594, Neurons: 11, Grad norm: 2.730e+01\n",
      "Epoch 10439, Loss: 445.0980529785156, Neurons: 11, Grad norm: 2.956e+01\n",
      "Epoch 10440, Loss: 445.09417724609375, Neurons: 11, Grad norm: 2.456e+01\n",
      "Epoch 10441, Loss: 445.09033203125, Neurons: 11, Grad norm: 1.699e+01\n",
      "Epoch 10442, Loss: 445.0863952636719, Neurons: 11, Grad norm: 5.897e+00\n",
      "Epoch 10443, Loss: 445.0824890136719, Neurons: 11, Grad norm: 4.974e+00\n",
      "Epoch 10444, Loss: 445.07867431640625, Neurons: 11, Grad norm: 1.424e+01\n",
      "Epoch 10445, Loss: 445.0747985839844, Neurons: 11, Grad norm: 1.891e+01\n",
      "Epoch 10446, Loss: 445.0709533691406, Neurons: 11, Grad norm: 2.146e+01\n",
      "Epoch 10447, Loss: 445.06707763671875, Neurons: 11, Grad norm: 1.859e+01\n",
      "Epoch 10448, Loss: 445.0632019042969, Neurons: 11, Grad norm: 1.445e+01\n",
      "Epoch 10449, Loss: 445.0592956542969, Neurons: 11, Grad norm: 6.957e+00\n",
      "Epoch 10449, Test loss: 441.2000427246094\n",
      "Epoch 10450, Loss: 445.0554504394531, Neurons: 11, Grad norm: 2.340e+00\n",
      "Epoch 10451, Loss: 445.0515441894531, Neurons: 11, Grad norm: 7.785e+00\n",
      "Epoch 10452, Loss: 445.0477294921875, Neurons: 11, Grad norm: 1.163e+01\n",
      "Epoch 10453, Loss: 445.0438537597656, Neurons: 11, Grad norm: 1.482e+01\n",
      "Epoch 10454, Loss: 445.03997802734375, Neurons: 11, Grad norm: 1.399e+01\n",
      "Epoch 10455, Loss: 445.0361022949219, Neurons: 11, Grad norm: 1.268e+01\n",
      "Epoch 10456, Loss: 445.0321960449219, Neurons: 11, Grad norm: 8.149e+00\n",
      "Epoch 10457, Loss: 445.0283508300781, Neurons: 11, Grad norm: 4.637e+00\n",
      "Epoch 10458, Loss: 445.0243835449219, Neurons: 11, Grad norm: 2.745e+00\n",
      "Epoch 10459, Loss: 445.0205383300781, Neurons: 11, Grad norm: 5.192e+00\n",
      "Epoch 10460, Loss: 445.0166931152344, Neurons: 11, Grad norm: 8.718e+00\n",
      "Epoch 10461, Loss: 445.0127868652344, Neurons: 11, Grad norm: 9.433e+00\n",
      "Epoch 10462, Loss: 445.0088806152344, Neurons: 11, Grad norm: 1.036e+01\n",
      "Epoch 10463, Loss: 445.0050964355469, Neurons: 11, Grad norm: 8.391e+00\n",
      "Epoch 10464, Loss: 445.0011901855469, Neurons: 11, Grad norm: 7.137e+00\n",
      "Epoch 10465, Loss: 444.9973449707031, Neurons: 11, Grad norm: 3.904e+00\n",
      "Epoch 10466, Loss: 444.9933776855469, Neurons: 11, Grad norm: 2.533e+00\n",
      "Epoch 10467, Loss: 444.989501953125, Neurons: 11, Grad norm: 3.412e+00\n",
      "Epoch 10468, Loss: 444.9856262207031, Neurons: 11, Grad norm: 4.418e+00\n",
      "Epoch 10469, Loss: 444.98175048828125, Neurons: 11, Grad norm: 6.315e+00\n",
      "Epoch 10470, Loss: 444.9778747558594, Neurons: 11, Grad norm: 5.980e+00\n",
      "Epoch 10471, Loss: 444.9739990234375, Neurons: 11, Grad norm: 6.511e+00\n",
      "Epoch 10472, Loss: 444.9700927734375, Neurons: 11, Grad norm: 4.893e+00\n",
      "Epoch 10473, Loss: 444.96624755859375, Neurons: 11, Grad norm: 4.487e+00\n",
      "Epoch 10474, Loss: 444.96234130859375, Neurons: 11, Grad norm: 2.752e+00\n",
      "Epoch 10475, Loss: 444.9583740234375, Neurons: 11, Grad norm: 2.438e+00\n",
      "Epoch 10476, Loss: 444.95458984375, Neurons: 11, Grad norm: 2.855e+00\n",
      "Epoch 10477, Loss: 444.9506530761719, Neurons: 11, Grad norm: 3.134e+00\n",
      "Epoch 10478, Loss: 444.9467468261719, Neurons: 11, Grad norm: 4.564e+00\n",
      "Epoch 10479, Loss: 444.9429016113281, Neurons: 11, Grad norm: 4.333e+00\n",
      "Epoch 10480, Loss: 444.9389953613281, Neurons: 11, Grad norm: 5.212e+00\n",
      "Epoch 10481, Loss: 444.9350891113281, Neurons: 11, Grad norm: 4.314e+00\n",
      "Epoch 10482, Loss: 444.9311828613281, Neurons: 11, Grad norm: 4.586e+00\n",
      "Epoch 10483, Loss: 444.9272766113281, Neurons: 11, Grad norm: 3.295e+00\n",
      "Epoch 10484, Loss: 444.9234313964844, Neurons: 11, Grad norm: 3.211e+00\n",
      "Epoch 10485, Loss: 444.91949462890625, Neurons: 11, Grad norm: 2.345e+00\n",
      "Epoch 10486, Loss: 444.9156494140625, Neurons: 11, Grad norm: 2.321e+00\n",
      "Epoch 10487, Loss: 444.91168212890625, Neurons: 11, Grad norm: 2.836e+00\n",
      "Epoch 10488, Loss: 444.90777587890625, Neurons: 11, Grad norm: 2.764e+00\n",
      "Epoch 10489, Loss: 444.9039001464844, Neurons: 11, Grad norm: 3.650e+00\n",
      "Epoch 10490, Loss: 444.8999938964844, Neurons: 11, Grad norm: 3.214e+00\n",
      "Epoch 10491, Loss: 444.8961486816406, Neurons: 11, Grad norm: 3.817e+00\n",
      "Epoch 10492, Loss: 444.8922424316406, Neurons: 11, Grad norm: 3.056e+00\n",
      "Epoch 10493, Loss: 444.8883361816406, Neurons: 11, Grad norm: 3.411e+00\n",
      "Epoch 10494, Loss: 444.8844299316406, Neurons: 11, Grad norm: 2.654e+00\n",
      "Epoch 10495, Loss: 444.8804931640625, Neurons: 11, Grad norm: 2.892e+00\n",
      "Epoch 10496, Loss: 444.8765869140625, Neurons: 11, Grad norm: 2.360e+00\n",
      "Epoch 10497, Loss: 444.8726806640625, Neurons: 11, Grad norm: 2.432e+00\n",
      "Epoch 10498, Loss: 444.86883544921875, Neurons: 11, Grad norm: 2.434e+00\n",
      "Epoch 10499, Loss: 444.8648986816406, Neurons: 11, Grad norm: 2.354e+00\n",
      "Epoch 10499, Test loss: 441.009521484375\n",
      "Epoch 10500, Loss: 444.8609924316406, Neurons: 11, Grad norm: 2.833e+00\n",
      "Epoch 10501, Loss: 444.8570861816406, Neurons: 11, Grad norm: 2.564e+00\n",
      "Epoch 10502, Loss: 444.8531799316406, Neurons: 11, Grad norm: 3.202e+00\n",
      "Epoch 10503, Loss: 444.8492736816406, Neurons: 11, Grad norm: 2.810e+00\n",
      "Epoch 10504, Loss: 444.8453369140625, Neurons: 11, Grad norm: 3.452e+00\n",
      "Epoch 10505, Loss: 444.84149169921875, Neurons: 11, Grad norm: 2.874e+00\n",
      "Epoch 10506, Loss: 444.83758544921875, Neurons: 11, Grad norm: 3.353e+00\n",
      "Epoch 10507, Loss: 444.83367919921875, Neurons: 11, Grad norm: 2.681e+00\n",
      "Epoch 10508, Loss: 444.8297424316406, Neurons: 11, Grad norm: 2.999e+00\n",
      "Epoch 10509, Loss: 444.8258361816406, Neurons: 11, Grad norm: 2.441e+00\n",
      "Epoch 10510, Loss: 444.8218994140625, Neurons: 11, Grad norm: 2.694e+00\n",
      "Epoch 10511, Loss: 444.8179931640625, Neurons: 11, Grad norm: 2.332e+00\n",
      "Epoch 10512, Loss: 444.8140869140625, Neurons: 11, Grad norm: 2.491e+00\n",
      "Epoch 10513, Loss: 444.8101806640625, Neurons: 11, Grad norm: 2.308e+00\n",
      "Epoch 10514, Loss: 444.8062438964844, Neurons: 11, Grad norm: 2.358e+00\n",
      "Epoch 10515, Loss: 444.8022766113281, Neurons: 11, Grad norm: 2.380e+00\n",
      "Epoch 10516, Loss: 444.79840087890625, Neurons: 11, Grad norm: 2.304e+00\n",
      "Epoch 10517, Loss: 444.79449462890625, Neurons: 11, Grad norm: 2.545e+00\n",
      "Epoch 10518, Loss: 444.79058837890625, Neurons: 11, Grad norm: 2.340e+00\n",
      "Epoch 10519, Loss: 444.78668212890625, Neurons: 11, Grad norm: 2.699e+00\n",
      "Epoch 10520, Loss: 444.78277587890625, Neurons: 11, Grad norm: 2.390e+00\n",
      "Epoch 10521, Loss: 444.7788391113281, Neurons: 11, Grad norm: 2.729e+00\n",
      "Epoch 10522, Loss: 444.77490234375, Neurons: 11, Grad norm: 2.372e+00\n",
      "Epoch 10523, Loss: 444.77099609375, Neurons: 11, Grad norm: 2.670e+00\n",
      "Epoch 10524, Loss: 444.76702880859375, Neurons: 11, Grad norm: 2.366e+00\n",
      "Epoch 10525, Loss: 444.7630920410156, Neurons: 11, Grad norm: 2.703e+00\n",
      "Epoch 10526, Loss: 444.7591857910156, Neurons: 11, Grad norm: 2.386e+00\n",
      "Epoch 10527, Loss: 444.7552795410156, Neurons: 11, Grad norm: 2.740e+00\n",
      "Epoch 10528, Loss: 444.75140380859375, Neurons: 11, Grad norm: 2.400e+00\n",
      "Epoch 10529, Loss: 444.7474365234375, Neurons: 11, Grad norm: 2.778e+00\n",
      "Epoch 10530, Loss: 444.7435302734375, Neurons: 11, Grad norm: 2.435e+00\n",
      "Epoch 10531, Loss: 444.7395935058594, Neurons: 11, Grad norm: 2.918e+00\n",
      "Epoch 10532, Loss: 444.7356872558594, Neurons: 11, Grad norm: 2.569e+00\n",
      "Epoch 10533, Loss: 444.731689453125, Neurons: 11, Grad norm: 3.162e+00\n",
      "Epoch 10534, Loss: 444.727783203125, Neurons: 11, Grad norm: 2.786e+00\n",
      "Epoch 10535, Loss: 444.723876953125, Neurons: 11, Grad norm: 3.547e+00\n",
      "Epoch 10536, Loss: 444.7199401855469, Neurons: 11, Grad norm: 3.189e+00\n",
      "Epoch 10537, Loss: 444.71600341796875, Neurons: 11, Grad norm: 4.194e+00\n",
      "Epoch 10538, Loss: 444.71209716796875, Neurons: 11, Grad norm: 4.005e+00\n",
      "Epoch 10539, Loss: 444.7080993652344, Neurons: 11, Grad norm: 5.352e+00\n",
      "Epoch 10540, Loss: 444.7041931152344, Neurons: 11, Grad norm: 5.351e+00\n",
      "Epoch 10541, Loss: 444.7002868652344, Neurons: 11, Grad norm: 7.031e+00\n",
      "Epoch 10542, Loss: 444.6962890625, Neurons: 11, Grad norm: 7.430e+00\n",
      "Epoch 10543, Loss: 444.6923828125, Neurons: 11, Grad norm: 9.825e+00\n",
      "Epoch 10544, Loss: 444.6884765625, Neurons: 11, Grad norm: 1.101e+01\n",
      "Epoch 10545, Loss: 444.6844787597656, Neurons: 11, Grad norm: 1.443e+01\n",
      "Epoch 10546, Loss: 444.68060302734375, Neurons: 11, Grad norm: 1.692e+01\n",
      "Epoch 10547, Loss: 444.67669677734375, Neurons: 11, Grad norm: 2.209e+01\n",
      "Epoch 10548, Loss: 444.6727294921875, Neurons: 11, Grad norm: 2.680e+01\n",
      "Epoch 10549, Loss: 444.66888427734375, Neurons: 11, Grad norm: 3.483e+01\n",
      "Epoch 10549, Test loss: 440.8097229003906\n",
      "Epoch 10550, Loss: 444.6649475097656, Neurons: 11, Grad norm: 4.332e+01\n",
      "Epoch 10551, Loss: 444.6611022949219, Neurons: 11, Grad norm: 5.623e+01\n",
      "Epoch 10552, Loss: 444.6572265625, Neurons: 11, Grad norm: 7.083e+01\n",
      "Epoch 10553, Loss: 444.6535339355469, Neurons: 11, Grad norm: 9.149e+01\n",
      "Epoch 10554, Loss: 444.64990234375, Neurons: 11, Grad norm: 1.159e+02\n",
      "Epoch 10555, Loss: 444.646484375, Neurons: 11, Grad norm: 1.482e+02\n",
      "Epoch 10556, Loss: 444.6434020996094, Neurons: 11, Grad norm: 1.851e+02\n",
      "Epoch 10557, Loss: 444.6407470703125, Neurons: 11, Grad norm: 2.282e+02\n",
      "Epoch 10558, Loss: 444.6386413574219, Neurons: 11, Grad norm: 2.691e+02\n",
      "Epoch 10559, Loss: 444.6368408203125, Neurons: 11, Grad norm: 3.007e+02\n",
      "Epoch 10560, Loss: 444.6347351074219, Neurons: 11, Grad norm: 3.042e+02\n",
      "Epoch 10561, Loss: 444.6311950683594, Neurons: 11, Grad norm: 2.685e+02\n",
      "Epoch 10562, Loss: 444.6252746582031, Neurons: 11, Grad norm: 1.866e+02\n",
      "Epoch 10563, Loss: 444.6177978515625, Neurons: 11, Grad norm: 7.531e+01\n",
      "Epoch 10564, Loss: 444.611083984375, Neurons: 11, Grad norm: 4.309e+01\n",
      "Epoch 10565, Loss: 444.60699462890625, Neurons: 11, Grad norm: 1.385e+02\n",
      "Epoch 10566, Loss: 444.60498046875, Neurons: 11, Grad norm: 1.947e+02\n",
      "Epoch 10567, Loss: 444.6031494140625, Neurons: 11, Grad norm: 1.969e+02\n",
      "Epoch 10568, Loss: 444.59954833984375, Neurons: 11, Grad norm: 1.498e+02\n",
      "Epoch 10569, Loss: 444.5941467285156, Neurons: 11, Grad norm: 6.490e+01\n",
      "Epoch 10570, Loss: 444.5885925292969, Neurons: 11, Grad norm: 2.815e+01\n",
      "Epoch 10571, Loss: 444.5845947265625, Neurons: 11, Grad norm: 1.054e+02\n",
      "Epoch 10572, Loss: 444.5818786621094, Neurons: 11, Grad norm: 1.440e+02\n",
      "Epoch 10573, Loss: 444.5791931152344, Neurons: 11, Grad norm: 1.393e+02\n",
      "Epoch 10574, Loss: 444.5752868652344, Neurons: 11, Grad norm: 9.267e+01\n",
      "Epoch 10575, Loss: 444.5705871582031, Neurons: 11, Grad norm: 2.460e+01\n",
      "Epoch 10576, Loss: 444.56610107421875, Neurons: 11, Grad norm: 4.589e+01\n",
      "Epoch 10577, Loss: 444.5625305175781, Neurons: 11, Grad norm: 9.399e+01\n",
      "Epoch 10578, Loss: 444.5595397949219, Neurons: 11, Grad norm: 1.108e+02\n",
      "Epoch 10579, Loss: 444.5562438964844, Neurons: 11, Grad norm: 9.099e+01\n",
      "Epoch 10580, Loss: 444.5521240234375, Neurons: 11, Grad norm: 4.694e+01\n",
      "Epoch 10581, Loss: 444.5478515625, Neurons: 11, Grad norm: 8.977e+00\n",
      "Epoch 10582, Loss: 444.54388427734375, Neurons: 11, Grad norm: 5.467e+01\n",
      "Epoch 10583, Loss: 444.54058837890625, Neurons: 11, Grad norm: 8.096e+01\n",
      "Epoch 10584, Loss: 444.5372314453125, Neurons: 11, Grad norm: 7.858e+01\n",
      "Epoch 10585, Loss: 444.5335388183594, Neurons: 11, Grad norm: 5.411e+01\n",
      "Epoch 10586, Loss: 444.529541015625, Neurons: 11, Grad norm: 1.425e+01\n",
      "Epoch 10587, Loss: 444.52557373046875, Neurons: 11, Grad norm: 2.478e+01\n",
      "Epoch 10588, Loss: 444.5220031738281, Neurons: 11, Grad norm: 5.374e+01\n",
      "Epoch 10589, Loss: 444.51849365234375, Neurons: 11, Grad norm: 6.227e+01\n",
      "Epoch 10590, Loss: 444.51495361328125, Neurons: 11, Grad norm: 5.289e+01\n",
      "Epoch 10591, Loss: 444.5111389160156, Neurons: 11, Grad norm: 2.719e+01\n",
      "Epoch 10592, Loss: 444.5072937011719, Neurons: 11, Grad norm: 3.439e+00\n",
      "Epoch 10593, Loss: 444.5035400390625, Neurons: 11, Grad norm: 3.017e+01\n",
      "Epoch 10594, Loss: 444.49993896484375, Neurons: 11, Grad norm: 4.453e+01\n",
      "Epoch 10595, Loss: 444.49639892578125, Neurons: 11, Grad norm: 4.604e+01\n",
      "Epoch 10596, Loss: 444.49267578125, Neurons: 11, Grad norm: 3.247e+01\n",
      "Epoch 10597, Loss: 444.4888916015625, Neurons: 11, Grad norm: 1.251e+01\n",
      "Epoch 10598, Loss: 444.4851379394531, Neurons: 11, Grad norm: 1.111e+01\n",
      "Epoch 10599, Loss: 444.4814758300781, Neurons: 11, Grad norm: 2.713e+01\n",
      "Epoch 10599, Test loss: 440.6441345214844\n",
      "Epoch 10600, Loss: 444.4778747558594, Neurons: 11, Grad norm: 3.555e+01\n",
      "Epoch 10601, Loss: 444.47418212890625, Neurons: 11, Grad norm: 3.177e+01\n",
      "Epoch 10602, Loss: 444.4704895019531, Neurons: 11, Grad norm: 2.117e+01\n",
      "Epoch 10603, Loss: 444.466796875, Neurons: 11, Grad norm: 4.698e+00\n",
      "Epoch 10604, Loss: 444.46307373046875, Neurons: 11, Grad norm: 1.096e+01\n",
      "Epoch 10605, Loss: 444.4593811035156, Neurons: 11, Grad norm: 2.286e+01\n",
      "Epoch 10606, Loss: 444.4557800292969, Neurons: 11, Grad norm: 2.600e+01\n",
      "Epoch 10607, Loss: 444.45208740234375, Neurons: 11, Grad norm: 2.344e+01\n",
      "Epoch 10608, Loss: 444.4483947753906, Neurons: 11, Grad norm: 1.344e+01\n",
      "Epoch 10609, Loss: 444.4447021484375, Neurons: 11, Grad norm: 3.164e+00\n",
      "Epoch 10610, Loss: 444.44097900390625, Neurons: 11, Grad norm: 1.015e+01\n",
      "Epoch 10611, Loss: 444.4373474121094, Neurons: 11, Grad norm: 1.688e+01\n",
      "Epoch 10612, Loss: 444.4336853027344, Neurons: 11, Grad norm: 2.029e+01\n",
      "Epoch 10613, Loss: 444.42999267578125, Neurons: 11, Grad norm: 1.672e+01\n",
      "Epoch 10614, Loss: 444.4263000488281, Neurons: 11, Grad norm: 1.091e+01\n",
      "Epoch 10615, Loss: 444.4225769042969, Neurons: 11, Grad norm: 2.552e+00\n",
      "Epoch 10616, Loss: 444.41888427734375, Neurons: 11, Grad norm: 6.583e+00\n",
      "Epoch 10617, Loss: 444.4151916503906, Neurons: 11, Grad norm: 1.307e+01\n",
      "Epoch 10618, Loss: 444.4114990234375, Neurons: 11, Grad norm: 1.437e+01\n",
      "Epoch 10619, Loss: 444.40777587890625, Neurons: 11, Grad norm: 1.371e+01\n",
      "Epoch 10620, Loss: 444.4041748046875, Neurons: 11, Grad norm: 8.430e+00\n",
      "Epoch 10621, Loss: 444.400390625, Neurons: 11, Grad norm: 3.717e+00\n",
      "Epoch 10622, Loss: 444.396728515625, Neurons: 11, Grad norm: 4.567e+00\n",
      "Epoch 10623, Loss: 444.3930358886719, Neurons: 11, Grad norm: 7.957e+00\n",
      "Epoch 10624, Loss: 444.3893737792969, Neurons: 11, Grad norm: 1.102e+01\n",
      "Epoch 10625, Loss: 444.3855895996094, Neurons: 11, Grad norm: 9.814e+00\n",
      "Epoch 10626, Loss: 444.3819885253906, Neurons: 11, Grad norm: 8.105e+00\n",
      "Epoch 10627, Loss: 444.37823486328125, Neurons: 11, Grad norm: 3.628e+00\n",
      "Epoch 10628, Loss: 444.3746032714844, Neurons: 11, Grad norm: 2.367e+00\n",
      "Epoch 10629, Loss: 444.370849609375, Neurons: 11, Grad norm: 5.752e+00\n",
      "Epoch 10630, Loss: 444.36712646484375, Neurons: 11, Grad norm: 7.143e+00\n",
      "Epoch 10631, Loss: 444.3634948730469, Neurons: 11, Grad norm: 8.531e+00\n",
      "Epoch 10632, Loss: 444.35980224609375, Neurons: 11, Grad norm: 6.562e+00\n",
      "Epoch 10633, Loss: 444.3560791015625, Neurons: 11, Grad norm: 5.077e+00\n",
      "Epoch 10634, Loss: 444.3523254394531, Neurons: 11, Grad norm: 2.340e+00\n",
      "Epoch 10635, Loss: 444.34869384765625, Neurons: 11, Grad norm: 2.717e+00\n",
      "Epoch 10636, Loss: 444.3450012207031, Neurons: 11, Grad norm: 5.194e+00\n",
      "Epoch 10637, Loss: 444.3412780761719, Neurons: 11, Grad norm: 5.557e+00\n",
      "Epoch 10638, Loss: 444.33758544921875, Neurons: 11, Grad norm: 6.486e+00\n",
      "Epoch 10639, Loss: 444.3338928222656, Neurons: 11, Grad norm: 4.847e+00\n",
      "Epoch 10640, Loss: 444.3302001953125, Neurons: 11, Grad norm: 4.104e+00\n",
      "Epoch 10641, Loss: 444.3263854980469, Neurons: 11, Grad norm: 2.315e+00\n",
      "Epoch 10642, Loss: 444.32275390625, Neurons: 11, Grad norm: 2.377e+00\n",
      "Epoch 10643, Loss: 444.3190002441406, Neurons: 11, Grad norm: 3.888e+00\n",
      "Epoch 10644, Loss: 444.3152770996094, Neurons: 11, Grad norm: 3.884e+00\n",
      "Epoch 10645, Loss: 444.31158447265625, Neurons: 11, Grad norm: 4.756e+00\n",
      "Epoch 10646, Loss: 444.3078918457031, Neurons: 11, Grad norm: 3.598e+00\n",
      "Epoch 10647, Loss: 444.30419921875, Neurons: 11, Grad norm: 3.507e+00\n",
      "Epoch 10648, Loss: 444.30047607421875, Neurons: 11, Grad norm: 2.317e+00\n",
      "Epoch 10649, Loss: 444.2967529296875, Neurons: 11, Grad norm: 2.269e+00\n",
      "Epoch 10649, Test loss: 440.4579162597656\n",
      "Epoch 10650, Loss: 444.2930908203125, Neurons: 11, Grad norm: 2.986e+00\n",
      "Epoch 10651, Loss: 444.2892761230469, Neurons: 11, Grad norm: 2.843e+00\n",
      "Epoch 10652, Loss: 444.28564453125, Neurons: 11, Grad norm: 3.651e+00\n",
      "Epoch 10653, Loss: 444.2819519042969, Neurons: 11, Grad norm: 2.928e+00\n",
      "Epoch 10654, Loss: 444.2781982421875, Neurons: 11, Grad norm: 3.247e+00\n",
      "Epoch 10655, Loss: 444.27447509765625, Neurons: 11, Grad norm: 2.410e+00\n",
      "Epoch 10656, Loss: 444.270751953125, Neurons: 11, Grad norm: 2.472e+00\n",
      "Epoch 10657, Loss: 444.2669982910156, Neurons: 11, Grad norm: 2.339e+00\n",
      "Epoch 10658, Loss: 444.2632751464844, Neurons: 11, Grad norm: 2.298e+00\n",
      "Epoch 10659, Loss: 444.25958251953125, Neurons: 11, Grad norm: 2.937e+00\n",
      "Epoch 10660, Loss: 444.2558898925781, Neurons: 11, Grad norm: 2.630e+00\n",
      "Epoch 10661, Loss: 444.252197265625, Neurons: 11, Grad norm: 3.255e+00\n",
      "Epoch 10662, Loss: 444.2484436035156, Neurons: 11, Grad norm: 2.617e+00\n",
      "Epoch 10663, Loss: 444.24468994140625, Neurons: 11, Grad norm: 2.914e+00\n",
      "Epoch 10664, Loss: 444.2409973144531, Neurons: 11, Grad norm: 2.335e+00\n",
      "Epoch 10665, Loss: 444.2372741699219, Neurons: 11, Grad norm: 2.478e+00\n",
      "Epoch 10666, Loss: 444.2335510253906, Neurons: 11, Grad norm: 2.301e+00\n",
      "Epoch 10667, Loss: 444.22979736328125, Neurons: 11, Grad norm: 2.272e+00\n",
      "Epoch 10668, Loss: 444.22607421875, Neurons: 11, Grad norm: 2.490e+00\n",
      "Epoch 10669, Loss: 444.22235107421875, Neurons: 11, Grad norm: 2.291e+00\n",
      "Epoch 10670, Loss: 444.2186279296875, Neurons: 11, Grad norm: 2.640e+00\n",
      "Epoch 10671, Loss: 444.2148742675781, Neurons: 11, Grad norm: 2.308e+00\n",
      "Epoch 10672, Loss: 444.211181640625, Neurons: 11, Grad norm: 2.588e+00\n",
      "Epoch 10673, Loss: 444.2074279785156, Neurons: 11, Grad norm: 2.265e+00\n",
      "Epoch 10674, Loss: 444.20367431640625, Neurons: 11, Grad norm: 2.386e+00\n",
      "Epoch 10675, Loss: 444.1999816894531, Neurons: 11, Grad norm: 2.247e+00\n",
      "Epoch 10676, Loss: 444.19622802734375, Neurons: 11, Grad norm: 2.295e+00\n",
      "Epoch 10677, Loss: 444.1925354003906, Neurons: 11, Grad norm: 2.389e+00\n",
      "Epoch 10678, Loss: 444.18878173828125, Neurons: 11, Grad norm: 2.258e+00\n",
      "Epoch 10679, Loss: 444.1850280761719, Neurons: 11, Grad norm: 2.561e+00\n",
      "Epoch 10680, Loss: 444.1812744140625, Neurons: 11, Grad norm: 2.289e+00\n",
      "Epoch 10681, Loss: 444.1775817871094, Neurons: 11, Grad norm: 2.549e+00\n",
      "Epoch 10682, Loss: 444.173828125, Neurons: 11, Grad norm: 2.252e+00\n",
      "Epoch 10683, Loss: 444.1700744628906, Neurons: 11, Grad norm: 2.366e+00\n",
      "Epoch 10684, Loss: 444.1663818359375, Neurons: 11, Grad norm: 2.282e+00\n",
      "Epoch 10685, Loss: 444.16259765625, Neurons: 11, Grad norm: 2.267e+00\n",
      "Epoch 10686, Loss: 444.15887451171875, Neurons: 11, Grad norm: 2.350e+00\n",
      "Epoch 10687, Loss: 444.1551513671875, Neurons: 11, Grad norm: 2.247e+00\n",
      "Epoch 10688, Loss: 444.1513977050781, Neurons: 11, Grad norm: 2.413e+00\n",
      "Epoch 10689, Loss: 444.1475830078125, Neurons: 11, Grad norm: 2.267e+00\n",
      "Epoch 10690, Loss: 444.1438903808594, Neurons: 11, Grad norm: 2.593e+00\n",
      "Epoch 10691, Loss: 444.14019775390625, Neurons: 11, Grad norm: 2.307e+00\n",
      "Epoch 10692, Loss: 444.1364440917969, Neurons: 11, Grad norm: 2.640e+00\n",
      "Epoch 10693, Loss: 444.13262939453125, Neurons: 11, Grad norm: 2.290e+00\n",
      "Epoch 10694, Loss: 444.1288757324219, Neurons: 11, Grad norm: 2.541e+00\n",
      "Epoch 10695, Loss: 444.12518310546875, Neurons: 11, Grad norm: 2.256e+00\n",
      "Epoch 10696, Loss: 444.1214294433594, Neurons: 11, Grad norm: 2.352e+00\n",
      "Epoch 10697, Loss: 444.11767578125, Neurons: 11, Grad norm: 2.323e+00\n",
      "Epoch 10698, Loss: 444.1138916015625, Neurons: 11, Grad norm: 2.250e+00\n",
      "Epoch 10699, Loss: 444.1101989746094, Neurons: 11, Grad norm: 2.564e+00\n",
      "Epoch 10699, Test loss: 440.2760925292969\n",
      "Epoch 10700, Loss: 444.1064453125, Neurons: 11, Grad norm: 2.335e+00\n",
      "Epoch 10701, Loss: 444.1026916503906, Neurons: 11, Grad norm: 2.845e+00\n",
      "Epoch 10702, Loss: 444.09893798828125, Neurons: 11, Grad norm: 2.451e+00\n",
      "Epoch 10703, Loss: 444.0951843261719, Neurons: 11, Grad norm: 2.897e+00\n",
      "Epoch 10704, Loss: 444.0914001464844, Neurons: 11, Grad norm: 2.452e+00\n",
      "Epoch 10705, Loss: 444.087646484375, Neurons: 11, Grad norm: 2.941e+00\n",
      "Epoch 10706, Loss: 444.0839538574219, Neurons: 11, Grad norm: 2.472e+00\n",
      "Epoch 10707, Loss: 444.08013916015625, Neurons: 11, Grad norm: 2.959e+00\n",
      "Epoch 10708, Loss: 444.0763854980469, Neurons: 11, Grad norm: 2.456e+00\n",
      "Epoch 10709, Loss: 444.0726013183594, Neurons: 11, Grad norm: 2.888e+00\n",
      "Epoch 10710, Loss: 444.0688781738281, Neurons: 11, Grad norm: 2.388e+00\n",
      "Epoch 10711, Loss: 444.0650939941406, Neurons: 11, Grad norm: 2.723e+00\n",
      "Epoch 10712, Loss: 444.0614013671875, Neurons: 11, Grad norm: 2.295e+00\n",
      "Epoch 10713, Loss: 444.0575866699219, Neurons: 11, Grad norm: 2.532e+00\n",
      "Epoch 10714, Loss: 444.0538330078125, Neurons: 11, Grad norm: 2.238e+00\n",
      "Epoch 10715, Loss: 444.0500793457031, Neurons: 11, Grad norm: 2.450e+00\n",
      "Epoch 10716, Loss: 444.0462951660156, Neurons: 11, Grad norm: 2.251e+00\n",
      "Epoch 10717, Loss: 444.04254150390625, Neurons: 11, Grad norm: 2.396e+00\n",
      "Epoch 10718, Loss: 444.0387878417969, Neurons: 11, Grad norm: 2.249e+00\n",
      "Epoch 10719, Loss: 444.0350036621094, Neurons: 11, Grad norm: 2.387e+00\n",
      "Epoch 10720, Loss: 444.0312805175781, Neurons: 11, Grad norm: 2.249e+00\n",
      "Epoch 10721, Loss: 444.0274963378906, Neurons: 11, Grad norm: 2.347e+00\n",
      "Epoch 10722, Loss: 444.02374267578125, Neurons: 11, Grad norm: 2.258e+00\n",
      "Epoch 10723, Loss: 444.0199279785156, Neurons: 11, Grad norm: 2.313e+00\n",
      "Epoch 10724, Loss: 444.01617431640625, Neurons: 11, Grad norm: 2.276e+00\n",
      "Epoch 10725, Loss: 444.01239013671875, Neurons: 11, Grad norm: 2.266e+00\n",
      "Epoch 10726, Loss: 444.0086364746094, Neurons: 11, Grad norm: 2.342e+00\n",
      "Epoch 10727, Loss: 444.0048828125, Neurons: 11, Grad norm: 2.235e+00\n",
      "Epoch 10728, Loss: 444.0010986328125, Neurons: 11, Grad norm: 2.421e+00\n",
      "Epoch 10729, Loss: 443.9972839355469, Neurons: 11, Grad norm: 2.238e+00\n",
      "Epoch 10730, Loss: 443.9935302734375, Neurons: 11, Grad norm: 2.513e+00\n",
      "Epoch 10731, Loss: 443.9897766113281, Neurons: 11, Grad norm: 2.271e+00\n",
      "Epoch 10732, Loss: 443.9859924316406, Neurons: 11, Grad norm: 2.665e+00\n",
      "Epoch 10733, Loss: 443.98223876953125, Neurons: 11, Grad norm: 2.333e+00\n",
      "Epoch 10734, Loss: 443.9783935546875, Neurons: 11, Grad norm: 2.806e+00\n",
      "Epoch 10735, Loss: 443.9746398925781, Neurons: 11, Grad norm: 2.434e+00\n",
      "Epoch 10736, Loss: 443.97088623046875, Neurons: 11, Grad norm: 3.049e+00\n",
      "Epoch 10737, Loss: 443.96710205078125, Neurons: 11, Grad norm: 2.683e+00\n",
      "Epoch 10738, Loss: 443.9632873535156, Neurons: 11, Grad norm: 3.519e+00\n",
      "Epoch 10739, Loss: 443.9595031738281, Neurons: 11, Grad norm: 3.198e+00\n",
      "Epoch 10740, Loss: 443.95574951171875, Neurons: 11, Grad norm: 4.332e+00\n",
      "Epoch 10741, Loss: 443.9519958496094, Neurons: 11, Grad norm: 4.253e+00\n",
      "Epoch 10742, Loss: 443.94818115234375, Neurons: 11, Grad norm: 5.977e+00\n",
      "Epoch 10743, Loss: 443.94439697265625, Neurons: 11, Grad norm: 6.251e+00\n",
      "Epoch 10744, Loss: 443.9406433105469, Neurons: 11, Grad norm: 8.509e+00\n",
      "Epoch 10745, Loss: 443.93682861328125, Neurons: 11, Grad norm: 9.405e+00\n",
      "Epoch 10746, Loss: 443.9330749511719, Neurons: 11, Grad norm: 1.255e+01\n",
      "Epoch 10747, Loss: 443.9292907714844, Neurons: 11, Grad norm: 1.458e+01\n",
      "Epoch 10748, Loss: 443.92547607421875, Neurons: 11, Grad norm: 1.924e+01\n",
      "Epoch 10749, Loss: 443.92169189453125, Neurons: 11, Grad norm: 2.316e+01\n",
      "Epoch 10749, Test loss: 440.0986328125\n",
      "Epoch 10750, Loss: 443.9178771972656, Neurons: 11, Grad norm: 3.019e+01\n",
      "Epoch 10751, Loss: 443.9141845703125, Neurons: 11, Grad norm: 3.724e+01\n",
      "Epoch 10752, Loss: 443.9104309082031, Neurons: 11, Grad norm: 4.839e+01\n",
      "Epoch 10753, Loss: 443.90667724609375, Neurons: 11, Grad norm: 6.076e+01\n",
      "Epoch 10754, Loss: 443.903076171875, Neurons: 11, Grad norm: 7.872e+01\n",
      "Epoch 10755, Loss: 443.8995361328125, Neurons: 11, Grad norm: 9.981e+01\n",
      "Epoch 10756, Loss: 443.89617919921875, Neurons: 11, Grad norm: 1.284e+02\n",
      "Epoch 10757, Loss: 443.89288330078125, Neurons: 11, Grad norm: 1.619e+02\n",
      "Epoch 10758, Loss: 443.89013671875, Neurons: 11, Grad norm: 2.037e+02\n",
      "Epoch 10759, Loss: 443.88787841796875, Neurons: 11, Grad norm: 2.477e+02\n",
      "Epoch 10760, Loss: 443.8860778808594, Neurons: 11, Grad norm: 2.909e+02\n",
      "Epoch 10761, Loss: 443.88458251953125, Neurons: 11, Grad norm: 3.176e+02\n",
      "Epoch 10762, Loss: 443.8824768066406, Neurons: 11, Grad norm: 3.145e+02\n",
      "Epoch 10763, Loss: 443.87860107421875, Neurons: 11, Grad norm: 2.644e+02\n",
      "Epoch 10764, Loss: 443.8721923828125, Neurons: 11, Grad norm: 1.708e+02\n",
      "Epoch 10765, Loss: 443.8645324707031, Neurons: 11, Grad norm: 4.838e+01\n",
      "Epoch 10766, Loss: 443.8583984375, Neurons: 11, Grad norm: 7.122e+01\n",
      "Epoch 10767, Loss: 443.85498046875, Neurons: 11, Grad norm: 1.645e+02\n",
      "Epoch 10768, Loss: 443.8535461425781, Neurons: 11, Grad norm: 2.090e+02\n",
      "Epoch 10769, Loss: 443.8515930175781, Neurons: 11, Grad norm: 1.992e+02\n",
      "Epoch 10770, Loss: 443.84759521484375, Neurons: 11, Grad norm: 1.360e+02\n",
      "Epoch 10771, Loss: 443.84197998046875, Neurons: 11, Grad norm: 4.325e+01\n",
      "Epoch 10772, Loss: 443.8367919921875, Neurons: 11, Grad norm: 5.409e+01\n",
      "Epoch 10773, Loss: 443.8333435058594, Neurons: 11, Grad norm: 1.249e+02\n",
      "Epoch 10774, Loss: 443.83099365234375, Neurons: 11, Grad norm: 1.548e+02\n",
      "Epoch 10775, Loss: 443.82818603515625, Neurons: 11, Grad norm: 1.353e+02\n",
      "Epoch 10776, Loss: 443.8241882324219, Neurons: 11, Grad norm: 7.904e+01\n",
      "Epoch 10777, Loss: 443.8194274902344, Neurons: 11, Grad norm: 3.641e+00\n",
      "Epoch 10778, Loss: 443.8152770996094, Neurons: 11, Grad norm: 6.496e+01\n",
      "Epoch 10779, Loss: 443.8121032714844, Neurons: 11, Grad norm: 1.081e+02\n",
      "Epoch 10780, Loss: 443.8092956542969, Neurons: 11, Grad norm: 1.127e+02\n",
      "Epoch 10781, Loss: 443.8058776855469, Neurons: 11, Grad norm: 8.398e+01\n",
      "Epoch 10782, Loss: 443.8017883300781, Neurons: 11, Grad norm: 3.071e+01\n",
      "Epoch 10783, Loss: 443.7976379394531, Neurons: 11, Grad norm: 2.545e+01\n",
      "Epoch 10784, Loss: 443.7940979003906, Neurons: 11, Grad norm: 6.960e+01\n",
      "Epoch 10785, Loss: 443.7909851074219, Neurons: 11, Grad norm: 8.662e+01\n",
      "Epoch 10786, Loss: 443.7876892089844, Neurons: 11, Grad norm: 7.703e+01\n",
      "Epoch 10787, Loss: 443.783935546875, Neurons: 11, Grad norm: 4.311e+01\n",
      "Epoch 10788, Loss: 443.780029296875, Neurons: 11, Grad norm: 2.391e+00\n",
      "Epoch 10789, Loss: 443.7762756347656, Neurons: 11, Grad norm: 3.898e+01\n",
      "Epoch 10790, Loss: 443.77288818359375, Neurons: 11, Grad norm: 6.150e+01\n",
      "Epoch 10791, Loss: 443.76959228515625, Neurons: 11, Grad norm: 6.482e+01\n",
      "Epoch 10792, Loss: 443.7660827636719, Neurons: 11, Grad norm: 4.673e+01\n",
      "Epoch 10793, Loss: 443.76239013671875, Neurons: 11, Grad norm: 1.803e+01\n",
      "Epoch 10794, Loss: 443.7586364746094, Neurons: 11, Grad norm: 1.519e+01\n",
      "Epoch 10795, Loss: 443.7550964355469, Neurons: 11, Grad norm: 3.860e+01\n",
      "Epoch 10796, Loss: 443.7516784667969, Neurons: 11, Grad norm: 4.989e+01\n",
      "Epoch 10797, Loss: 443.7481994628906, Neurons: 11, Grad norm: 4.375e+01\n",
      "Epoch 10798, Loss: 443.74462890625, Neurons: 11, Grad norm: 2.703e+01\n",
      "Epoch 10799, Loss: 443.7409973144531, Neurons: 11, Grad norm: 3.215e+00\n",
      "Epoch 10799, Test loss: 439.91851806640625\n",
      "Epoch 10800, Loss: 443.7373352050781, Neurons: 11, Grad norm: 1.911e+01\n",
      "Epoch 10801, Loss: 443.73382568359375, Neurons: 11, Grad norm: 3.438e+01\n",
      "Epoch 10802, Loss: 443.7303771972656, Neurons: 11, Grad norm: 3.683e+01\n",
      "Epoch 10803, Loss: 443.7268371582031, Neurons: 11, Grad norm: 3.022e+01\n",
      "Epoch 10804, Loss: 443.7232971191406, Neurons: 11, Grad norm: 1.421e+01\n",
      "Epoch 10805, Loss: 443.7196350097656, Neurons: 11, Grad norm: 3.546e+00\n",
      "Epoch 10806, Loss: 443.7160949707031, Neurons: 11, Grad norm: 1.886e+01\n",
      "Epoch 10807, Loss: 443.71258544921875, Neurons: 11, Grad norm: 2.645e+01\n",
      "Epoch 10808, Loss: 443.7090759277344, Neurons: 11, Grad norm: 2.771e+01\n",
      "Epoch 10809, Loss: 443.7055358886719, Neurons: 11, Grad norm: 1.980e+01\n",
      "Epoch 10810, Loss: 443.7019958496094, Neurons: 11, Grad norm: 9.075e+00\n",
      "Epoch 10811, Loss: 443.6983947753906, Neurons: 11, Grad norm: 5.447e+00\n",
      "Epoch 10812, Loss: 443.6947937011719, Neurons: 11, Grad norm: 1.464e+01\n",
      "Epoch 10813, Loss: 443.6912841796875, Neurons: 11, Grad norm: 2.090e+01\n",
      "Epoch 10814, Loss: 443.687744140625, Neurons: 11, Grad norm: 1.951e+01\n",
      "Epoch 10815, Loss: 443.6841735839844, Neurons: 11, Grad norm: 1.492e+01\n",
      "Epoch 10816, Loss: 443.6806335449219, Neurons: 11, Grad norm: 5.573e+00\n",
      "Epoch 10817, Loss: 443.6770324707031, Neurons: 11, Grad norm: 3.927e+00\n",
      "Epoch 10818, Loss: 443.6734924316406, Neurons: 11, Grad norm: 1.183e+01\n",
      "Epoch 10819, Loss: 443.66998291015625, Neurons: 11, Grad norm: 1.480e+01\n",
      "Epoch 10820, Loss: 443.6663818359375, Neurons: 11, Grad norm: 1.555e+01\n",
      "Epoch 10821, Loss: 443.66290283203125, Neurons: 11, Grad norm: 1.093e+01\n",
      "Epoch 10822, Loss: 443.6593017578125, Neurons: 11, Grad norm: 5.931e+00\n",
      "Epoch 10823, Loss: 443.65570068359375, Neurons: 11, Grad norm: 3.134e+00\n",
      "Epoch 10824, Loss: 443.6521301269531, Neurons: 11, Grad norm: 7.323e+00\n",
      "Epoch 10825, Loss: 443.6485900878906, Neurons: 11, Grad norm: 1.151e+01\n",
      "Epoch 10826, Loss: 443.6450500488281, Neurons: 11, Grad norm: 1.115e+01\n",
      "Epoch 10827, Loss: 443.6414794921875, Neurons: 11, Grad norm: 9.987e+00\n",
      "Epoch 10828, Loss: 443.637939453125, Neurons: 11, Grad norm: 5.392e+00\n",
      "Epoch 10829, Loss: 443.63433837890625, Neurons: 11, Grad norm: 2.441e+00\n",
      "Epoch 10830, Loss: 443.63079833984375, Neurons: 11, Grad norm: 4.837e+00\n",
      "Epoch 10831, Loss: 443.627197265625, Neurons: 11, Grad norm: 6.828e+00\n",
      "Epoch 10832, Loss: 443.6236877441406, Neurons: 11, Grad norm: 8.862e+00\n",
      "Epoch 10833, Loss: 443.6200866699219, Neurons: 11, Grad norm: 7.309e+00\n",
      "Epoch 10834, Loss: 443.6164855957031, Neurons: 11, Grad norm: 6.082e+00\n",
      "Epoch 10835, Loss: 443.6129455566406, Neurons: 11, Grad norm: 2.754e+00\n",
      "Epoch 10836, Loss: 443.609375, Neurons: 11, Grad norm: 2.332e+00\n",
      "Epoch 10837, Loss: 443.6058349609375, Neurons: 11, Grad norm: 5.019e+00\n",
      "Epoch 10838, Loss: 443.6022033691406, Neurons: 11, Grad norm: 5.853e+00\n",
      "Epoch 10839, Loss: 443.59869384765625, Neurons: 11, Grad norm: 7.139e+00\n",
      "Epoch 10840, Loss: 443.5950927734375, Neurons: 11, Grad norm: 5.498e+00\n",
      "Epoch 10841, Loss: 443.591552734375, Neurons: 11, Grad norm: 4.760e+00\n",
      "Epoch 10842, Loss: 443.5879821777344, Neurons: 11, Grad norm: 2.438e+00\n",
      "Epoch 10843, Loss: 443.5843811035156, Neurons: 11, Grad norm: 2.232e+00\n",
      "Epoch 10844, Loss: 443.5807800292969, Neurons: 11, Grad norm: 3.791e+00\n",
      "Epoch 10845, Loss: 443.5771789550781, Neurons: 11, Grad norm: 4.034e+00\n",
      "Epoch 10846, Loss: 443.5736999511719, Neurons: 11, Grad norm: 5.176e+00\n",
      "Epoch 10847, Loss: 443.5700988769531, Neurons: 11, Grad norm: 3.989e+00\n",
      "Epoch 10848, Loss: 443.5664978027344, Neurons: 11, Grad norm: 3.869e+00\n",
      "Epoch 10849, Loss: 443.56292724609375, Neurons: 11, Grad norm: 2.328e+00\n",
      "Epoch 10849, Test loss: 439.74554443359375\n",
      "Epoch 10850, Loss: 443.5592956542969, Neurons: 11, Grad norm: 2.204e+00\n",
      "Epoch 10851, Loss: 443.5556945800781, Neurons: 11, Grad norm: 3.145e+00\n",
      "Epoch 10852, Loss: 443.55218505859375, Neurons: 11, Grad norm: 3.218e+00\n",
      "Epoch 10853, Loss: 443.548583984375, Neurons: 11, Grad norm: 4.284e+00\n",
      "Epoch 10854, Loss: 443.54498291015625, Neurons: 11, Grad norm: 3.403e+00\n",
      "Epoch 10855, Loss: 443.5413818359375, Neurons: 11, Grad norm: 3.618e+00\n",
      "Epoch 10856, Loss: 443.53790283203125, Neurons: 11, Grad norm: 2.410e+00\n",
      "Epoch 10857, Loss: 443.5341796875, Neurons: 11, Grad norm: 2.330e+00\n",
      "Epoch 10858, Loss: 443.53070068359375, Neurons: 11, Grad norm: 2.468e+00\n",
      "Epoch 10859, Loss: 443.527099609375, Neurons: 11, Grad norm: 2.392e+00\n",
      "Epoch 10860, Loss: 443.52349853515625, Neurons: 11, Grad norm: 3.174e+00\n",
      "Epoch 10861, Loss: 443.5199279785156, Neurons: 11, Grad norm: 2.649e+00\n",
      "Epoch 10862, Loss: 443.51629638671875, Neurons: 11, Grad norm: 3.086e+00\n",
      "Epoch 10863, Loss: 443.5127258300781, Neurons: 11, Grad norm: 2.325e+00\n",
      "Epoch 10864, Loss: 443.5091247558594, Neurons: 11, Grad norm: 2.415e+00\n",
      "Epoch 10865, Loss: 443.5055236816406, Neurons: 11, Grad norm: 2.264e+00\n",
      "Epoch 10866, Loss: 443.501953125, Neurons: 11, Grad norm: 2.232e+00\n",
      "Epoch 10867, Loss: 443.49835205078125, Neurons: 11, Grad norm: 2.857e+00\n",
      "Epoch 10868, Loss: 443.4947814941406, Neurons: 11, Grad norm: 2.493e+00\n",
      "Epoch 10869, Loss: 443.4911804199219, Neurons: 11, Grad norm: 3.069e+00\n",
      "Epoch 10870, Loss: 443.487548828125, Neurons: 11, Grad norm: 2.448e+00\n",
      "Epoch 10871, Loss: 443.48394775390625, Neurons: 11, Grad norm: 2.775e+00\n",
      "Epoch 10872, Loss: 443.4803771972656, Neurons: 11, Grad norm: 2.218e+00\n",
      "Epoch 10873, Loss: 443.4767761230469, Neurons: 11, Grad norm: 2.306e+00\n",
      "Epoch 10874, Loss: 443.4731750488281, Neurons: 11, Grad norm: 2.299e+00\n",
      "Epoch 10875, Loss: 443.4695739746094, Neurons: 11, Grad norm: 2.199e+00\n",
      "Epoch 10876, Loss: 443.46600341796875, Neurons: 11, Grad norm: 2.588e+00\n",
      "Epoch 10877, Loss: 443.46240234375, Neurons: 11, Grad norm: 2.295e+00\n",
      "Epoch 10878, Loss: 443.45880126953125, Neurons: 11, Grad norm: 2.739e+00\n",
      "Epoch 10879, Loss: 443.4552001953125, Neurons: 11, Grad norm: 2.258e+00\n",
      "Epoch 10880, Loss: 443.45159912109375, Neurons: 11, Grad norm: 2.459e+00\n",
      "Epoch 10881, Loss: 443.447998046875, Neurons: 11, Grad norm: 2.188e+00\n",
      "Epoch 10882, Loss: 443.4443359375, Neurons: 11, Grad norm: 2.287e+00\n",
      "Epoch 10883, Loss: 443.44073486328125, Neurons: 11, Grad norm: 2.243e+00\n",
      "Epoch 10884, Loss: 443.4371032714844, Neurons: 11, Grad norm: 2.193e+00\n",
      "Epoch 10885, Loss: 443.43353271484375, Neurons: 11, Grad norm: 2.365e+00\n",
      "Epoch 10886, Loss: 443.4299011230469, Neurons: 11, Grad norm: 2.186e+00\n",
      "Epoch 10887, Loss: 443.4263000488281, Neurons: 11, Grad norm: 2.429e+00\n",
      "Epoch 10888, Loss: 443.4226379394531, Neurons: 11, Grad norm: 2.186e+00\n",
      "Epoch 10889, Loss: 443.4190979003906, Neurons: 11, Grad norm: 2.380e+00\n",
      "Epoch 10890, Loss: 443.4154968261719, Neurons: 11, Grad norm: 2.180e+00\n",
      "Epoch 10891, Loss: 443.4118347167969, Neurons: 11, Grad norm: 2.333e+00\n",
      "Epoch 10892, Loss: 443.4082946777344, Neurons: 11, Grad norm: 2.224e+00\n",
      "Epoch 10893, Loss: 443.40460205078125, Neurons: 11, Grad norm: 2.239e+00\n",
      "Epoch 10894, Loss: 443.4010009765625, Neurons: 11, Grad norm: 2.322e+00\n",
      "Epoch 10895, Loss: 443.39739990234375, Neurons: 11, Grad norm: 2.195e+00\n",
      "Epoch 10896, Loss: 443.393798828125, Neurons: 11, Grad norm: 2.444e+00\n",
      "Epoch 10897, Loss: 443.39013671875, Neurons: 11, Grad norm: 2.202e+00\n",
      "Epoch 10898, Loss: 443.386474609375, Neurons: 11, Grad norm: 2.469e+00\n",
      "Epoch 10899, Loss: 443.3829040527344, Neurons: 11, Grad norm: 2.193e+00\n",
      "Epoch 10899, Test loss: 439.570556640625\n",
      "Epoch 10900, Loss: 443.3793029785156, Neurons: 11, Grad norm: 2.378e+00\n",
      "Epoch 10901, Loss: 443.3757019042969, Neurons: 11, Grad norm: 2.190e+00\n",
      "Epoch 10902, Loss: 443.3721008300781, Neurons: 11, Grad norm: 2.259e+00\n",
      "Epoch 10903, Loss: 443.3683776855469, Neurons: 11, Grad norm: 2.182e+00\n",
      "Epoch 10904, Loss: 443.3647766113281, Neurons: 11, Grad norm: 2.252e+00\n",
      "Epoch 10905, Loss: 443.36114501953125, Neurons: 11, Grad norm: 2.214e+00\n",
      "Epoch 10906, Loss: 443.3575439453125, Neurons: 11, Grad norm: 2.254e+00\n",
      "Epoch 10907, Loss: 443.3538818359375, Neurons: 11, Grad norm: 2.208e+00\n",
      "Epoch 10908, Loss: 443.35028076171875, Neurons: 11, Grad norm: 2.228e+00\n",
      "Epoch 10909, Loss: 443.3466796875, Neurons: 11, Grad norm: 2.238e+00\n",
      "Epoch 10910, Loss: 443.3430480957031, Neurons: 11, Grad norm: 2.196e+00\n",
      "Epoch 10911, Loss: 443.3393859863281, Neurons: 11, Grad norm: 2.274e+00\n",
      "Epoch 10912, Loss: 443.3357849121094, Neurons: 11, Grad norm: 2.178e+00\n",
      "Epoch 10913, Loss: 443.3321533203125, Neurons: 11, Grad norm: 2.352e+00\n",
      "Epoch 10914, Loss: 443.32855224609375, Neurons: 11, Grad norm: 2.174e+00\n",
      "Epoch 10915, Loss: 443.32489013671875, Neurons: 11, Grad norm: 2.439e+00\n",
      "Epoch 10916, Loss: 443.32122802734375, Neurons: 11, Grad norm: 2.197e+00\n",
      "Epoch 10917, Loss: 443.3175964355469, Neurons: 11, Grad norm: 2.506e+00\n",
      "Epoch 10918, Loss: 443.3139953613281, Neurons: 11, Grad norm: 2.222e+00\n",
      "Epoch 10919, Loss: 443.3103332519531, Neurons: 11, Grad norm: 2.581e+00\n",
      "Epoch 10920, Loss: 443.30670166015625, Neurons: 11, Grad norm: 2.235e+00\n",
      "Epoch 10921, Loss: 443.3031005859375, Neurons: 11, Grad norm: 2.570e+00\n",
      "Epoch 10922, Loss: 443.2994384765625, Neurons: 11, Grad norm: 2.225e+00\n",
      "Epoch 10923, Loss: 443.2957763671875, Neurons: 11, Grad norm: 2.591e+00\n",
      "Epoch 10924, Loss: 443.29217529296875, Neurons: 11, Grad norm: 2.256e+00\n",
      "Epoch 10925, Loss: 443.2884826660156, Neurons: 11, Grad norm: 2.713e+00\n",
      "Epoch 10926, Loss: 443.2848815917969, Neurons: 11, Grad norm: 2.343e+00\n",
      "Epoch 10927, Loss: 443.28118896484375, Neurons: 11, Grad norm: 2.959e+00\n",
      "Epoch 10928, Loss: 443.277587890625, Neurons: 11, Grad norm: 2.557e+00\n",
      "Epoch 10929, Loss: 443.27392578125, Neurons: 11, Grad norm: 3.368e+00\n",
      "Epoch 10930, Loss: 443.2702941894531, Neurons: 11, Grad norm: 2.981e+00\n",
      "Epoch 10931, Loss: 443.2666931152344, Neurons: 11, Grad norm: 4.016e+00\n",
      "Epoch 10932, Loss: 443.26300048828125, Neurons: 11, Grad norm: 3.746e+00\n",
      "Epoch 10933, Loss: 443.25927734375, Neurons: 11, Grad norm: 5.047e+00\n",
      "Epoch 10934, Loss: 443.25567626953125, Neurons: 11, Grad norm: 4.804e+00\n",
      "Epoch 10935, Loss: 443.2520751953125, Neurons: 11, Grad norm: 6.367e+00\n",
      "Epoch 10936, Loss: 443.2483825683594, Neurons: 11, Grad norm: 6.361e+00\n",
      "Epoch 10937, Loss: 443.2447509765625, Neurons: 11, Grad norm: 8.271e+00\n",
      "Epoch 10938, Loss: 443.2410888671875, Neurons: 11, Grad norm: 8.643e+00\n",
      "Epoch 10939, Loss: 443.2374267578125, Neurons: 11, Grad norm: 1.101e+01\n",
      "Epoch 10940, Loss: 443.2337951660156, Neurons: 11, Grad norm: 1.195e+01\n",
      "Epoch 10941, Loss: 443.2301330566406, Neurons: 11, Grad norm: 1.505e+01\n",
      "Epoch 10942, Loss: 443.22650146484375, Neurons: 11, Grad norm: 1.667e+01\n",
      "Epoch 10943, Loss: 443.2227783203125, Neurons: 11, Grad norm: 2.073e+01\n",
      "Epoch 10944, Loss: 443.21917724609375, Neurons: 11, Grad norm: 2.361e+01\n",
      "Epoch 10945, Loss: 443.2154846191406, Neurons: 11, Grad norm: 2.916e+01\n",
      "Epoch 10946, Loss: 443.2119445800781, Neurons: 11, Grad norm: 3.408e+01\n",
      "Epoch 10947, Loss: 443.2082824707031, Neurons: 11, Grad norm: 4.229e+01\n",
      "Epoch 10948, Loss: 443.2046813964844, Neurons: 11, Grad norm: 5.042e+01\n",
      "Epoch 10949, Loss: 443.2010803222656, Neurons: 11, Grad norm: 6.252e+01\n",
      "Epoch 10949, Test loss: 439.3785095214844\n",
      "Epoch 10950, Loss: 443.1976013183594, Neurons: 11, Grad norm: 7.554e+01\n",
      "Epoch 10951, Loss: 443.194091796875, Neurons: 11, Grad norm: 9.353e+01\n",
      "Epoch 10952, Loss: 443.190673828125, Neurons: 11, Grad norm: 1.134e+02\n",
      "Epoch 10953, Loss: 443.1873779296875, Neurons: 11, Grad norm: 1.390e+02\n",
      "Epoch 10954, Loss: 443.184326171875, Neurons: 11, Grad norm: 1.666e+02\n",
      "Epoch 10955, Loss: 443.1815490722656, Neurons: 11, Grad norm: 1.986e+02\n",
      "Epoch 10956, Loss: 443.1789855957031, Neurons: 11, Grad norm: 2.287e+02\n",
      "Epoch 10957, Loss: 443.1766357421875, Neurons: 11, Grad norm: 2.551e+02\n",
      "Epoch 10958, Loss: 443.1741943359375, Neurons: 11, Grad norm: 2.661e+02\n",
      "Epoch 10959, Loss: 443.17120361328125, Neurons: 11, Grad norm: 2.565e+02\n",
      "Epoch 10960, Loss: 443.1670837402344, Neurons: 11, Grad norm: 2.170e+02\n",
      "Epoch 10961, Loss: 443.1617736816406, Neurons: 11, Grad norm: 1.522e+02\n",
      "Epoch 10962, Loss: 443.1559753417969, Neurons: 11, Grad norm: 6.808e+01\n",
      "Epoch 10963, Loss: 443.15069580078125, Neurons: 11, Grad norm: 1.732e+01\n",
      "Epoch 10964, Loss: 443.14678955078125, Neurons: 11, Grad norm: 9.285e+01\n",
      "Epoch 10965, Loss: 443.14398193359375, Neurons: 11, Grad norm: 1.440e+02\n",
      "Epoch 10966, Loss: 443.1416931152344, Neurons: 11, Grad norm: 1.674e+02\n",
      "Epoch 10967, Loss: 443.1387939453125, Neurons: 11, Grad norm: 1.566e+02\n",
      "Epoch 10968, Loss: 443.1349792480469, Neurons: 11, Grad norm: 1.187e+02\n",
      "Epoch 10969, Loss: 443.1304931640625, Neurons: 11, Grad norm: 5.947e+01\n",
      "Epoch 10970, Loss: 443.12603759765625, Neurons: 11, Grad norm: 4.720e+00\n",
      "Epoch 10971, Loss: 443.1221923828125, Neurons: 11, Grad norm: 6.235e+01\n",
      "Epoch 10972, Loss: 443.1190490722656, Neurons: 11, Grad norm: 1.007e+02\n",
      "Epoch 10973, Loss: 443.1161804199219, Neurons: 11, Grad norm: 1.169e+02\n",
      "Epoch 10974, Loss: 443.11297607421875, Neurons: 11, Grad norm: 1.060e+02\n",
      "Epoch 10975, Loss: 443.1092529296875, Neurons: 11, Grad norm: 7.600e+01\n",
      "Epoch 10976, Loss: 443.1051940917969, Neurons: 11, Grad norm: 3.150e+01\n",
      "Epoch 10977, Loss: 443.1012878417969, Neurons: 11, Grad norm: 1.368e+01\n",
      "Epoch 10978, Loss: 443.0976867675781, Neurons: 11, Grad norm: 5.288e+01\n",
      "Epoch 10979, Loss: 443.094482421875, Neurons: 11, Grad norm: 7.587e+01\n",
      "Epoch 10980, Loss: 443.0912780761719, Neurons: 11, Grad norm: 8.270e+01\n",
      "Epoch 10981, Loss: 443.087890625, Neurons: 11, Grad norm: 7.033e+01\n",
      "Epoch 10982, Loss: 443.0841979980469, Neurons: 11, Grad norm: 4.637e+01\n",
      "Epoch 10983, Loss: 443.0804443359375, Neurons: 11, Grad norm: 1.370e+01\n",
      "Epoch 10984, Loss: 443.0767822265625, Neurons: 11, Grad norm: 1.724e+01\n",
      "Epoch 10985, Loss: 443.07330322265625, Neurons: 11, Grad norm: 4.293e+01\n",
      "Epoch 10986, Loss: 443.0699462890625, Neurons: 11, Grad norm: 5.585e+01\n",
      "Epoch 10987, Loss: 443.06658935546875, Neurons: 11, Grad norm: 5.805e+01\n",
      "Epoch 10988, Loss: 443.0630798339844, Neurons: 11, Grad norm: 4.682e+01\n",
      "Epoch 10989, Loss: 443.0594787597656, Neurons: 11, Grad norm: 2.917e+01\n",
      "Epoch 10990, Loss: 443.0558776855469, Neurons: 11, Grad norm: 6.107e+00\n",
      "Epoch 10991, Loss: 443.0522766113281, Neurons: 11, Grad norm: 1.487e+01\n",
      "Epoch 10992, Loss: 443.048828125, Neurons: 11, Grad norm: 3.203e+01\n",
      "Epoch 10993, Loss: 443.0453796386719, Neurons: 11, Grad norm: 3.985e+01\n",
      "Epoch 10994, Loss: 443.0419921875, Neurons: 11, Grad norm: 4.111e+01\n",
      "Epoch 10995, Loss: 443.0384826660156, Neurons: 11, Grad norm: 3.298e+01\n",
      "Epoch 10996, Loss: 443.0348815917969, Neurons: 11, Grad norm: 2.120e+01\n",
      "Epoch 10997, Loss: 443.0314025878906, Neurons: 11, Grad norm: 5.359e+00\n",
      "Epoch 10998, Loss: 443.0278015136719, Neurons: 11, Grad norm: 9.203e+00\n",
      "Epoch 10999, Loss: 443.02435302734375, Neurons: 11, Grad norm: 2.163e+01\n",
      "Epoch 10999, Test loss: 439.21759033203125\n",
      "Epoch 11000, Loss: 443.0208740234375, Neurons: 11, Grad norm: 2.749e+01\n",
      "Epoch 11001, Loss: 443.01739501953125, Neurons: 11, Grad norm: 2.971e+01\n",
      "Epoch 11002, Loss: 443.0138854980469, Neurons: 11, Grad norm: 2.483e+01\n",
      "Epoch 11003, Loss: 443.0103454589844, Neurons: 11, Grad norm: 1.787e+01\n",
      "Epoch 11004, Loss: 443.0068359375, Neurons: 11, Grad norm: 7.128e+00\n",
      "Epoch 11005, Loss: 443.0032958984375, Neurons: 11, Grad norm: 3.321e+00\n",
      "Epoch 11006, Loss: 442.9997863769531, Neurons: 11, Grad norm: 1.236e+01\n",
      "Epoch 11007, Loss: 442.99627685546875, Neurons: 11, Grad norm: 1.733e+01\n",
      "Epoch 11008, Loss: 442.9928283691406, Neurons: 11, Grad norm: 2.086e+01\n",
      "Epoch 11009, Loss: 442.9892883300781, Neurons: 11, Grad norm: 1.916e+01\n",
      "Epoch 11010, Loss: 442.98577880859375, Neurons: 11, Grad norm: 1.640e+01\n",
      "Epoch 11011, Loss: 442.9822998046875, Neurons: 11, Grad norm: 9.831e+00\n",
      "Epoch 11012, Loss: 442.97869873046875, Neurons: 11, Grad norm: 4.435e+00\n",
      "Epoch 11013, Loss: 442.9752502441406, Neurons: 11, Grad norm: 4.192e+00\n",
      "Epoch 11014, Loss: 442.9718017578125, Neurons: 11, Grad norm: 8.383e+00\n",
      "Epoch 11015, Loss: 442.9682312011719, Neurons: 11, Grad norm: 1.290e+01\n",
      "Epoch 11016, Loss: 442.9646911621094, Neurons: 11, Grad norm: 1.358e+01\n",
      "Epoch 11017, Loss: 442.961181640625, Neurons: 11, Grad norm: 1.405e+01\n",
      "Epoch 11018, Loss: 442.95770263671875, Neurons: 11, Grad norm: 1.101e+01\n",
      "Epoch 11019, Loss: 442.9541931152344, Neurons: 11, Grad norm: 8.528e+00\n",
      "Epoch 11020, Loss: 442.9506530761719, Neurons: 11, Grad norm: 3.846e+00\n",
      "Epoch 11021, Loss: 442.9471435546875, Neurons: 11, Grad norm: 2.169e+00\n",
      "Epoch 11022, Loss: 442.9436340332031, Neurons: 11, Grad norm: 5.515e+00\n",
      "Epoch 11023, Loss: 442.9400939941406, Neurons: 11, Grad norm: 7.389e+00\n",
      "Epoch 11024, Loss: 442.93658447265625, Neurons: 11, Grad norm: 9.904e+00\n",
      "Epoch 11025, Loss: 442.9330749511719, Neurons: 11, Grad norm: 9.390e+00\n",
      "Epoch 11026, Loss: 442.9294738769531, Neurons: 11, Grad norm: 9.569e+00\n",
      "Epoch 11027, Loss: 442.9259948730469, Neurons: 11, Grad norm: 7.210e+00\n",
      "Epoch 11028, Loss: 442.9224853515625, Neurons: 11, Grad norm: 6.011e+00\n",
      "Epoch 11029, Loss: 442.9189758300781, Neurons: 11, Grad norm: 3.064e+00\n",
      "Epoch 11030, Loss: 442.9154357910156, Neurons: 11, Grad norm: 2.231e+00\n",
      "Epoch 11031, Loss: 442.9118957519531, Neurons: 11, Grad norm: 3.435e+00\n",
      "Epoch 11032, Loss: 442.90838623046875, Neurons: 11, Grad norm: 4.113e+00\n",
      "Epoch 11033, Loss: 442.9048767089844, Neurons: 11, Grad norm: 6.015e+00\n",
      "Epoch 11034, Loss: 442.9013366699219, Neurons: 11, Grad norm: 5.688e+00\n",
      "Epoch 11035, Loss: 442.8978271484375, Neurons: 11, Grad norm: 6.419e+00\n",
      "Epoch 11036, Loss: 442.894287109375, Neurons: 11, Grad norm: 4.987e+00\n",
      "Epoch 11037, Loss: 442.8907775878906, Neurons: 11, Grad norm: 4.868e+00\n",
      "Epoch 11038, Loss: 442.8871765136719, Neurons: 11, Grad norm: 3.002e+00\n",
      "Epoch 11039, Loss: 442.8836975097656, Neurons: 11, Grad norm: 2.665e+00\n",
      "Epoch 11040, Loss: 442.88018798828125, Neurons: 11, Grad norm: 2.244e+00\n",
      "Epoch 11041, Loss: 442.87664794921875, Neurons: 11, Grad norm: 2.287e+00\n",
      "Epoch 11042, Loss: 442.8730773925781, Neurons: 11, Grad norm: 3.350e+00\n",
      "Epoch 11043, Loss: 442.8695983886719, Neurons: 11, Grad norm: 3.169e+00\n",
      "Epoch 11044, Loss: 442.8659973144531, Neurons: 11, Grad norm: 4.273e+00\n",
      "Epoch 11045, Loss: 442.86248779296875, Neurons: 11, Grad norm: 3.635e+00\n",
      "Epoch 11046, Loss: 442.85894775390625, Neurons: 11, Grad norm: 4.438e+00\n",
      "Epoch 11047, Loss: 442.8553771972656, Neurons: 11, Grad norm: 3.502e+00\n",
      "Epoch 11048, Loss: 442.8518981933594, Neurons: 11, Grad norm: 3.970e+00\n",
      "Epoch 11049, Loss: 442.84832763671875, Neurons: 11, Grad norm: 2.826e+00\n",
      "Epoch 11049, Test loss: 439.0526428222656\n",
      "Epoch 11050, Loss: 442.84478759765625, Neurons: 11, Grad norm: 3.032e+00\n",
      "Epoch 11051, Loss: 442.8412780761719, Neurons: 11, Grad norm: 2.190e+00\n",
      "Epoch 11052, Loss: 442.8377380371094, Neurons: 11, Grad norm: 2.230e+00\n",
      "Epoch 11053, Loss: 442.8341979980469, Neurons: 11, Grad norm: 2.337e+00\n",
      "Epoch 11054, Loss: 442.83062744140625, Neurons: 11, Grad norm: 2.223e+00\n",
      "Epoch 11055, Loss: 442.8270263671875, Neurons: 11, Grad norm: 3.010e+00\n",
      "Epoch 11056, Loss: 442.82354736328125, Neurons: 11, Grad norm: 2.705e+00\n",
      "Epoch 11057, Loss: 442.8199768066406, Neurons: 11, Grad norm: 3.624e+00\n",
      "Epoch 11058, Loss: 442.8163757324219, Neurons: 11, Grad norm: 3.268e+00\n",
      "Epoch 11059, Loss: 442.8128967285156, Neurons: 11, Grad norm: 4.276e+00\n",
      "Epoch 11060, Loss: 442.8092956542969, Neurons: 11, Grad norm: 3.597e+00\n",
      "Epoch 11061, Loss: 442.8057861328125, Neurons: 11, Grad norm: 4.416e+00\n",
      "Epoch 11062, Loss: 442.80218505859375, Neurons: 11, Grad norm: 3.580e+00\n",
      "Epoch 11063, Loss: 442.7986755371094, Neurons: 11, Grad norm: 4.214e+00\n",
      "Epoch 11064, Loss: 442.7951354980469, Neurons: 11, Grad norm: 3.275e+00\n",
      "Epoch 11065, Loss: 442.7915954589844, Neurons: 11, Grad norm: 3.772e+00\n",
      "Epoch 11066, Loss: 442.7879943847656, Neurons: 11, Grad norm: 2.864e+00\n",
      "Epoch 11067, Loss: 442.78448486328125, Neurons: 11, Grad norm: 3.299e+00\n",
      "Epoch 11068, Loss: 442.7808837890625, Neurons: 11, Grad norm: 2.484e+00\n",
      "Epoch 11069, Loss: 442.77734375, Neurons: 11, Grad norm: 2.832e+00\n",
      "Epoch 11070, Loss: 442.7738037109375, Neurons: 11, Grad norm: 2.203e+00\n",
      "Epoch 11071, Loss: 442.77020263671875, Neurons: 11, Grad norm: 2.404e+00\n",
      "Epoch 11072, Loss: 442.7666931152344, Neurons: 11, Grad norm: 2.165e+00\n",
      "Epoch 11073, Loss: 442.7630920410156, Neurons: 11, Grad norm: 2.153e+00\n",
      "Epoch 11074, Loss: 442.7595520019531, Neurons: 11, Grad norm: 2.442e+00\n",
      "Epoch 11075, Loss: 442.7559509277344, Neurons: 11, Grad norm: 2.208e+00\n",
      "Epoch 11076, Loss: 442.75244140625, Neurons: 11, Grad norm: 2.752e+00\n",
      "Epoch 11077, Loss: 442.7489013671875, Neurons: 11, Grad norm: 2.364e+00\n",
      "Epoch 11078, Loss: 442.74530029296875, Neurons: 11, Grad norm: 2.958e+00\n",
      "Epoch 11079, Loss: 442.7417297363281, Neurons: 11, Grad norm: 2.390e+00\n",
      "Epoch 11080, Loss: 442.7381286621094, Neurons: 11, Grad norm: 3.005e+00\n",
      "Epoch 11081, Loss: 442.7345886230469, Neurons: 11, Grad norm: 2.516e+00\n",
      "Epoch 11082, Loss: 442.7310485839844, Neurons: 11, Grad norm: 3.231e+00\n",
      "Epoch 11083, Loss: 442.7273864746094, Neurons: 11, Grad norm: 2.712e+00\n",
      "Epoch 11084, Loss: 442.7238464355469, Neurons: 11, Grad norm: 3.491e+00\n",
      "Epoch 11085, Loss: 442.72027587890625, Neurons: 11, Grad norm: 3.028e+00\n",
      "Epoch 11086, Loss: 442.7166748046875, Neurons: 11, Grad norm: 4.072e+00\n",
      "Epoch 11087, Loss: 442.71319580078125, Neurons: 11, Grad norm: 3.695e+00\n",
      "Epoch 11088, Loss: 442.7095947265625, Neurons: 11, Grad norm: 5.016e+00\n",
      "Epoch 11089, Loss: 442.70599365234375, Neurons: 11, Grad norm: 4.802e+00\n",
      "Epoch 11090, Loss: 442.70245361328125, Neurons: 11, Grad norm: 6.422e+00\n",
      "Epoch 11091, Loss: 442.69879150390625, Neurons: 11, Grad norm: 6.453e+00\n",
      "Epoch 11092, Loss: 442.6952819824219, Neurons: 11, Grad norm: 8.412e+00\n",
      "Epoch 11093, Loss: 442.6916809082031, Neurons: 11, Grad norm: 8.893e+00\n",
      "Epoch 11094, Loss: 442.6880798339844, Neurons: 11, Grad norm: 1.137e+01\n",
      "Epoch 11095, Loss: 442.6845397949219, Neurons: 11, Grad norm: 1.250e+01\n",
      "Epoch 11096, Loss: 442.6809387207031, Neurons: 11, Grad norm: 1.589e+01\n",
      "Epoch 11097, Loss: 442.6773986816406, Neurons: 11, Grad norm: 1.807e+01\n",
      "Epoch 11098, Loss: 442.673828125, Neurons: 11, Grad norm: 2.298e+01\n",
      "Epoch 11099, Loss: 442.67022705078125, Neurons: 11, Grad norm: 2.690e+01\n",
      "Epoch 11099, Test loss: 438.88580322265625\n",
      "Epoch 11100, Loss: 442.66668701171875, Neurons: 11, Grad norm: 3.395e+01\n",
      "Epoch 11101, Loss: 442.6631774902344, Neurons: 11, Grad norm: 4.064e+01\n",
      "Epoch 11102, Loss: 442.6595764160156, Neurons: 11, Grad norm: 5.107e+01\n",
      "Epoch 11103, Loss: 442.6560974121094, Neurons: 11, Grad norm: 6.211e+01\n",
      "Epoch 11104, Loss: 442.652587890625, Neurons: 11, Grad norm: 7.808e+01\n",
      "Epoch 11105, Loss: 442.6492919921875, Neurons: 11, Grad norm: 9.615e+01\n",
      "Epoch 11106, Loss: 442.64593505859375, Neurons: 11, Grad norm: 1.205e+02\n",
      "Epoch 11107, Loss: 442.6427917480469, Neurons: 11, Grad norm: 1.480e+02\n",
      "Epoch 11108, Loss: 442.6399841308594, Neurons: 11, Grad norm: 1.821e+02\n",
      "Epoch 11109, Loss: 442.63739013671875, Neurons: 11, Grad norm: 2.179e+02\n",
      "Epoch 11110, Loss: 442.63519287109375, Neurons: 11, Grad norm: 2.554e+02\n",
      "Epoch 11111, Loss: 442.6331787109375, Neurons: 11, Grad norm: 2.839e+02\n",
      "Epoch 11112, Loss: 442.6311950683594, Neurons: 11, Grad norm: 2.966e+02\n",
      "Epoch 11113, Loss: 442.6283264160156, Neurons: 11, Grad norm: 2.786e+02\n",
      "Epoch 11114, Loss: 442.6239013671875, Neurons: 11, Grad norm: 2.267e+02\n",
      "Epoch 11115, Loss: 442.61798095703125, Neurons: 11, Grad norm: 1.412e+02\n",
      "Epoch 11116, Loss: 442.6116943359375, Neurons: 11, Grad norm: 4.058e+01\n",
      "Epoch 11117, Loss: 442.6064758300781, Neurons: 11, Grad norm: 5.930e+01\n",
      "Epoch 11118, Loss: 442.6033020019531, Neurons: 11, Grad norm: 1.366e+02\n",
      "Epoch 11119, Loss: 442.6012878417969, Neurons: 11, Grad norm: 1.824e+02\n",
      "Epoch 11120, Loss: 442.5991516113281, Neurons: 11, Grad norm: 1.858e+02\n",
      "Epoch 11121, Loss: 442.59588623046875, Neurons: 11, Grad norm: 1.515e+02\n",
      "Epoch 11122, Loss: 442.5914001464844, Neurons: 11, Grad norm: 8.535e+01\n",
      "Epoch 11123, Loss: 442.58648681640625, Neurons: 11, Grad norm: 8.289e+00\n",
      "Epoch 11124, Loss: 442.5824279785156, Neurons: 11, Grad norm: 6.505e+01\n",
      "Epoch 11125, Loss: 442.5793762207031, Neurons: 11, Grad norm: 1.145e+02\n",
      "Epoch 11126, Loss: 442.5767822265625, Neurons: 11, Grad norm: 1.347e+02\n",
      "Epoch 11127, Loss: 442.5738525390625, Neurons: 11, Grad norm: 1.200e+02\n",
      "Epoch 11128, Loss: 442.57012939453125, Neurons: 11, Grad norm: 7.997e+01\n",
      "Epoch 11129, Loss: 442.5659484863281, Neurons: 11, Grad norm: 2.314e+01\n",
      "Epoch 11130, Loss: 442.5619812011719, Neurons: 11, Grad norm: 3.215e+01\n",
      "Epoch 11131, Loss: 442.5586853027344, Neurons: 11, Grad norm: 7.577e+01\n",
      "Epoch 11132, Loss: 442.5556945800781, Neurons: 11, Grad norm: 9.555e+01\n",
      "Epoch 11133, Loss: 442.5525817871094, Neurons: 11, Grad norm: 9.222e+01\n",
      "Epoch 11134, Loss: 442.54913330078125, Neurons: 11, Grad norm: 6.538e+01\n",
      "Epoch 11135, Loss: 442.5453796386719, Neurons: 11, Grad norm: 2.719e+01\n",
      "Epoch 11136, Loss: 442.5416259765625, Neurons: 11, Grad norm: 1.567e+01\n",
      "Epoch 11137, Loss: 442.5381774902344, Neurons: 11, Grad norm: 4.861e+01\n",
      "Epoch 11138, Loss: 442.5350036621094, Neurons: 11, Grad norm: 6.850e+01\n",
      "Epoch 11139, Loss: 442.53179931640625, Neurons: 11, Grad norm: 6.860e+01\n",
      "Epoch 11140, Loss: 442.52838134765625, Neurons: 11, Grad norm: 5.436e+01\n",
      "Epoch 11141, Loss: 442.52484130859375, Neurons: 11, Grad norm: 2.718e+01\n",
      "Epoch 11142, Loss: 442.521240234375, Neurons: 11, Grad norm: 3.071e+00\n",
      "Epoch 11143, Loss: 442.5177917480469, Neurons: 11, Grad norm: 2.980e+01\n",
      "Epoch 11144, Loss: 442.5144958496094, Neurons: 11, Grad norm: 4.606e+01\n",
      "Epoch 11145, Loss: 442.5111999511719, Neurons: 11, Grad norm: 5.179e+01\n",
      "Epoch 11146, Loss: 442.5077819824219, Neurons: 11, Grad norm: 4.352e+01\n",
      "Epoch 11147, Loss: 442.50433349609375, Neurons: 11, Grad norm: 2.795e+01\n",
      "Epoch 11148, Loss: 442.5008239746094, Neurons: 11, Grad norm: 6.286e+00\n",
      "Epoch 11149, Loss: 442.49737548828125, Neurons: 11, Grad norm: 1.369e+01\n",
      "Epoch 11149, Test loss: 438.7156677246094\n",
      "Epoch 11150, Loss: 442.4939880371094, Neurons: 11, Grad norm: 2.988e+01\n",
      "Epoch 11151, Loss: 442.4906311035156, Neurons: 11, Grad norm: 3.630e+01\n",
      "Epoch 11152, Loss: 442.4872741699219, Neurons: 11, Grad norm: 3.591e+01\n",
      "Epoch 11153, Loss: 442.48382568359375, Neurons: 11, Grad norm: 2.614e+01\n",
      "Epoch 11154, Loss: 442.4803771972656, Neurons: 11, Grad norm: 1.350e+01\n",
      "Epoch 11155, Loss: 442.47698974609375, Neurons: 11, Grad norm: 3.433e+00\n",
      "Epoch 11156, Loss: 442.4735412597656, Neurons: 11, Grad norm: 1.505e+01\n",
      "Epoch 11157, Loss: 442.4701843261719, Neurons: 11, Grad norm: 2.456e+01\n",
      "Epoch 11158, Loss: 442.466796875, Neurons: 11, Grad norm: 2.655e+01\n",
      "Epoch 11159, Loss: 442.46337890625, Neurons: 11, Grad norm: 2.480e+01\n",
      "Epoch 11160, Loss: 442.45989990234375, Neurons: 11, Grad norm: 1.672e+01\n",
      "Epoch 11161, Loss: 442.45648193359375, Neurons: 11, Grad norm: 7.983e+00\n",
      "Epoch 11162, Loss: 442.4530944824219, Neurons: 11, Grad norm: 4.161e+00\n",
      "Epoch 11163, Loss: 442.4495849609375, Neurons: 11, Grad norm: 1.152e+01\n",
      "Epoch 11164, Loss: 442.44622802734375, Neurons: 11, Grad norm: 1.787e+01\n",
      "Epoch 11165, Loss: 442.4428405761719, Neurons: 11, Grad norm: 1.869e+01\n",
      "Epoch 11166, Loss: 442.439453125, Neurons: 11, Grad norm: 1.771e+01\n",
      "Epoch 11167, Loss: 442.43597412109375, Neurons: 11, Grad norm: 1.206e+01\n",
      "Epoch 11168, Loss: 442.4325866699219, Neurons: 11, Grad norm: 6.667e+00\n",
      "Epoch 11169, Loss: 442.42913818359375, Neurons: 11, Grad norm: 2.598e+00\n",
      "Epoch 11170, Loss: 442.4257507324219, Neurons: 11, Grad norm: 6.933e+00\n",
      "Epoch 11171, Loss: 442.42230224609375, Neurons: 11, Grad norm: 1.194e+01\n",
      "Epoch 11172, Loss: 442.41888427734375, Neurons: 11, Grad norm: 1.292e+01\n",
      "Epoch 11173, Loss: 442.4154968261719, Neurons: 11, Grad norm: 1.327e+01\n",
      "Epoch 11174, Loss: 442.4119873046875, Neurons: 11, Grad norm: 9.732e+00\n",
      "Epoch 11175, Loss: 442.40863037109375, Neurons: 11, Grad norm: 6.777e+00\n",
      "Epoch 11176, Loss: 442.4051818847656, Neurons: 11, Grad norm: 2.270e+00\n",
      "Epoch 11177, Loss: 442.4017333984375, Neurons: 11, Grad norm: 3.424e+00\n",
      "Epoch 11178, Loss: 442.3982849121094, Neurons: 11, Grad norm: 7.464e+00\n",
      "Epoch 11179, Loss: 442.3948974609375, Neurons: 11, Grad norm: 8.537e+00\n",
      "Epoch 11180, Loss: 442.3914794921875, Neurons: 11, Grad norm: 9.909e+00\n",
      "Epoch 11181, Loss: 442.3880310058594, Neurons: 11, Grad norm: 8.142e+00\n",
      "Epoch 11182, Loss: 442.38458251953125, Neurons: 11, Grad norm: 7.117e+00\n",
      "Epoch 11183, Loss: 442.3811950683594, Neurons: 11, Grad norm: 3.868e+00\n",
      "Epoch 11184, Loss: 442.3777770996094, Neurons: 11, Grad norm: 2.444e+00\n",
      "Epoch 11185, Loss: 442.3742980957031, Neurons: 11, Grad norm: 3.332e+00\n",
      "Epoch 11186, Loss: 442.3708801269531, Neurons: 11, Grad norm: 4.396e+00\n",
      "Epoch 11187, Loss: 442.367431640625, Neurons: 11, Grad norm: 6.578e+00\n",
      "Epoch 11188, Loss: 442.3639831542969, Neurons: 11, Grad norm: 6.234e+00\n",
      "Epoch 11189, Loss: 442.360595703125, Neurons: 11, Grad norm: 6.856e+00\n",
      "Epoch 11190, Loss: 442.3570861816406, Neurons: 11, Grad norm: 5.098e+00\n",
      "Epoch 11191, Loss: 442.35369873046875, Neurons: 11, Grad norm: 4.547e+00\n",
      "Epoch 11192, Loss: 442.3502502441406, Neurons: 11, Grad norm: 2.417e+00\n",
      "Epoch 11193, Loss: 442.3468017578125, Neurons: 11, Grad norm: 2.109e+00\n",
      "Epoch 11194, Loss: 442.3433837890625, Neurons: 11, Grad norm: 3.307e+00\n",
      "Epoch 11195, Loss: 442.3398742675781, Neurons: 11, Grad norm: 3.593e+00\n",
      "Epoch 11196, Loss: 442.33648681640625, Neurons: 11, Grad norm: 5.056e+00\n",
      "Epoch 11197, Loss: 442.3330993652344, Neurons: 11, Grad norm: 4.362e+00\n",
      "Epoch 11198, Loss: 442.32958984375, Neurons: 11, Grad norm: 4.829e+00\n",
      "Epoch 11199, Loss: 442.3261413574219, Neurons: 11, Grad norm: 3.401e+00\n",
      "Epoch 11199, Test loss: 438.54742431640625\n",
      "Epoch 11200, Loss: 442.32269287109375, Neurons: 11, Grad norm: 3.297e+00\n",
      "Epoch 11201, Loss: 442.31927490234375, Neurons: 11, Grad norm: 2.152e+00\n",
      "Epoch 11202, Loss: 442.3158264160156, Neurons: 11, Grad norm: 2.136e+00\n",
      "Epoch 11203, Loss: 442.3123779296875, Neurons: 11, Grad norm: 2.763e+00\n",
      "Epoch 11204, Loss: 442.30889892578125, Neurons: 11, Grad norm: 2.643e+00\n",
      "Epoch 11205, Loss: 442.3054504394531, Neurons: 11, Grad norm: 3.775e+00\n",
      "Epoch 11206, Loss: 442.302001953125, Neurons: 11, Grad norm: 3.287e+00\n",
      "Epoch 11207, Loss: 442.2985534667969, Neurons: 11, Grad norm: 4.058e+00\n",
      "Epoch 11208, Loss: 442.2950744628906, Neurons: 11, Grad norm: 3.073e+00\n",
      "Epoch 11209, Loss: 442.2916259765625, Neurons: 11, Grad norm: 3.360e+00\n",
      "Epoch 11210, Loss: 442.2881774902344, Neurons: 11, Grad norm: 2.386e+00\n",
      "Epoch 11211, Loss: 442.28472900390625, Neurons: 11, Grad norm: 2.514e+00\n",
      "Epoch 11212, Loss: 442.2812805175781, Neurons: 11, Grad norm: 2.155e+00\n",
      "Epoch 11213, Loss: 442.2778015136719, Neurons: 11, Grad norm: 2.118e+00\n",
      "Epoch 11214, Loss: 442.27435302734375, Neurons: 11, Grad norm: 2.811e+00\n",
      "Epoch 11215, Loss: 442.2708740234375, Neurons: 11, Grad norm: 2.563e+00\n",
      "Epoch 11216, Loss: 442.26739501953125, Neurons: 11, Grad norm: 3.493e+00\n",
      "Epoch 11217, Loss: 442.26397705078125, Neurons: 11, Grad norm: 3.000e+00\n",
      "Epoch 11218, Loss: 442.2605285644531, Neurons: 11, Grad norm: 3.744e+00\n",
      "Epoch 11219, Loss: 442.257080078125, Neurons: 11, Grad norm: 2.946e+00\n",
      "Epoch 11220, Loss: 442.25360107421875, Neurons: 11, Grad norm: 3.475e+00\n",
      "Epoch 11221, Loss: 442.2501525878906, Neurons: 11, Grad norm: 2.534e+00\n",
      "Epoch 11222, Loss: 442.2466735839844, Neurons: 11, Grad norm: 2.763e+00\n",
      "Epoch 11223, Loss: 442.2431945800781, Neurons: 11, Grad norm: 2.097e+00\n",
      "Epoch 11224, Loss: 442.23968505859375, Neurons: 11, Grad norm: 2.133e+00\n",
      "Epoch 11225, Loss: 442.2362365722656, Neurons: 11, Grad norm: 2.359e+00\n",
      "Epoch 11226, Loss: 442.2327880859375, Neurons: 11, Grad norm: 2.226e+00\n",
      "Epoch 11227, Loss: 442.2292785644531, Neurons: 11, Grad norm: 2.966e+00\n",
      "Epoch 11228, Loss: 442.22589111328125, Neurons: 11, Grad norm: 2.565e+00\n",
      "Epoch 11229, Loss: 442.2223815917969, Neurons: 11, Grad norm: 3.312e+00\n",
      "Epoch 11230, Loss: 442.2189025878906, Neurons: 11, Grad norm: 2.630e+00\n",
      "Epoch 11231, Loss: 442.21539306640625, Neurons: 11, Grad norm: 3.308e+00\n",
      "Epoch 11232, Loss: 442.2118835449219, Neurons: 11, Grad norm: 2.581e+00\n",
      "Epoch 11233, Loss: 442.20843505859375, Neurons: 11, Grad norm: 3.112e+00\n",
      "Epoch 11234, Loss: 442.2049865722656, Neurons: 11, Grad norm: 2.383e+00\n",
      "Epoch 11235, Loss: 442.20147705078125, Neurons: 11, Grad norm: 2.723e+00\n",
      "Epoch 11236, Loss: 442.197998046875, Neurons: 11, Grad norm: 2.148e+00\n",
      "Epoch 11237, Loss: 442.1944885253906, Neurons: 11, Grad norm: 2.321e+00\n",
      "Epoch 11238, Loss: 442.1910400390625, Neurons: 11, Grad norm: 2.075e+00\n",
      "Epoch 11239, Loss: 442.1875915527344, Neurons: 11, Grad norm: 2.145e+00\n",
      "Epoch 11240, Loss: 442.18408203125, Neurons: 11, Grad norm: 2.290e+00\n",
      "Epoch 11241, Loss: 442.18060302734375, Neurons: 11, Grad norm: 2.116e+00\n",
      "Epoch 11242, Loss: 442.1770935058594, Neurons: 11, Grad norm: 2.633e+00\n",
      "Epoch 11243, Loss: 442.17364501953125, Neurons: 11, Grad norm: 2.304e+00\n",
      "Epoch 11244, Loss: 442.1701354980469, Neurons: 11, Grad norm: 2.987e+00\n",
      "Epoch 11245, Loss: 442.1666259765625, Neurons: 11, Grad norm: 2.533e+00\n",
      "Epoch 11246, Loss: 442.1631774902344, Neurons: 11, Grad norm: 3.233e+00\n",
      "Epoch 11247, Loss: 442.1596984863281, Neurons: 11, Grad norm: 2.699e+00\n",
      "Epoch 11248, Loss: 442.15618896484375, Neurons: 11, Grad norm: 3.519e+00\n",
      "Epoch 11249, Loss: 442.1526794433594, Neurons: 11, Grad norm: 2.984e+00\n",
      "Epoch 11249, Test loss: 438.37921142578125\n",
      "Epoch 11250, Loss: 442.1492004394531, Neurons: 11, Grad norm: 4.006e+00\n",
      "Epoch 11251, Loss: 442.14569091796875, Neurons: 11, Grad norm: 3.524e+00\n",
      "Epoch 11252, Loss: 442.1422424316406, Neurons: 11, Grad norm: 4.650e+00\n",
      "Epoch 11253, Loss: 442.1387023925781, Neurons: 11, Grad norm: 4.255e+00\n",
      "Epoch 11254, Loss: 442.13519287109375, Neurons: 11, Grad norm: 5.478e+00\n",
      "Epoch 11255, Loss: 442.1317443847656, Neurons: 11, Grad norm: 4.952e+00\n",
      "Epoch 11256, Loss: 442.12823486328125, Neurons: 11, Grad norm: 6.242e+00\n",
      "Epoch 11257, Loss: 442.1247863769531, Neurons: 11, Grad norm: 5.785e+00\n",
      "Epoch 11258, Loss: 442.12127685546875, Neurons: 11, Grad norm: 7.245e+00\n",
      "Epoch 11259, Loss: 442.11773681640625, Neurons: 11, Grad norm: 7.053e+00\n",
      "Epoch 11260, Loss: 442.1142272949219, Neurons: 11, Grad norm: 8.875e+00\n",
      "Epoch 11261, Loss: 442.1107482910156, Neurons: 11, Grad norm: 9.225e+00\n",
      "Epoch 11262, Loss: 442.107177734375, Neurons: 11, Grad norm: 1.152e+01\n",
      "Epoch 11263, Loss: 442.1037292480469, Neurons: 11, Grad norm: 1.240e+01\n",
      "Epoch 11264, Loss: 442.1001892089844, Neurons: 11, Grad norm: 1.561e+01\n",
      "Epoch 11265, Loss: 442.09674072265625, Neurons: 11, Grad norm: 1.730e+01\n",
      "Epoch 11266, Loss: 442.0932312011719, Neurons: 11, Grad norm: 2.157e+01\n",
      "Epoch 11267, Loss: 442.0897521972656, Neurons: 11, Grad norm: 2.483e+01\n",
      "Epoch 11268, Loss: 442.08624267578125, Neurons: 11, Grad norm: 3.093e+01\n",
      "Epoch 11269, Loss: 442.0827941894531, Neurons: 11, Grad norm: 3.651e+01\n",
      "Epoch 11270, Loss: 442.07928466796875, Neurons: 11, Grad norm: 4.549e+01\n",
      "Epoch 11271, Loss: 442.0757751464844, Neurons: 11, Grad norm: 5.467e+01\n",
      "Epoch 11272, Loss: 442.0723876953125, Neurons: 11, Grad norm: 6.827e+01\n",
      "Epoch 11273, Loss: 442.06903076171875, Neurons: 11, Grad norm: 8.325e+01\n",
      "Epoch 11274, Loss: 442.0657958984375, Neurons: 11, Grad norm: 1.038e+02\n",
      "Epoch 11275, Loss: 442.0625915527344, Neurons: 11, Grad norm: 1.267e+02\n",
      "Epoch 11276, Loss: 442.0595397949219, Neurons: 11, Grad norm: 1.561e+02\n",
      "Epoch 11277, Loss: 442.0567932128906, Neurons: 11, Grad norm: 1.881e+02\n",
      "Epoch 11278, Loss: 442.0542907714844, Neurons: 11, Grad norm: 2.245e+02\n",
      "Epoch 11279, Loss: 442.0521240234375, Neurons: 11, Grad norm: 2.578e+02\n",
      "Epoch 11280, Loss: 442.0501403808594, Neurons: 11, Grad norm: 2.846e+02\n",
      "Epoch 11281, Loss: 442.0479736328125, Neurons: 11, Grad norm: 2.912e+02\n",
      "Epoch 11282, Loss: 442.0448913574219, Neurons: 11, Grad norm: 2.712e+02\n",
      "Epoch 11283, Loss: 442.0404968261719, Neurons: 11, Grad norm: 2.160e+02\n",
      "Epoch 11284, Loss: 442.0346984863281, Neurons: 11, Grad norm: 1.343e+02\n",
      "Epoch 11285, Loss: 442.0286865234375, Neurons: 11, Grad norm: 3.621e+01\n",
      "Epoch 11286, Loss: 442.0238037109375, Neurons: 11, Grad norm: 5.696e+01\n",
      "Epoch 11287, Loss: 442.0206298828125, Neurons: 11, Grad norm: 1.326e+02\n",
      "Epoch 11288, Loss: 442.01849365234375, Neurons: 11, Grad norm: 1.756e+02\n",
      "Epoch 11289, Loss: 442.0163879394531, Neurons: 11, Grad norm: 1.836e+02\n",
      "Epoch 11290, Loss: 442.0132751464844, Neurons: 11, Grad norm: 1.529e+02\n",
      "Epoch 11291, Loss: 442.0090026855469, Neurons: 11, Grad norm: 9.540e+01\n",
      "Epoch 11292, Loss: 442.00433349609375, Neurons: 11, Grad norm: 2.188e+01\n",
      "Epoch 11293, Loss: 442.000244140625, Neurons: 11, Grad norm: 4.754e+01\n",
      "Epoch 11294, Loss: 441.9971008300781, Neurons: 11, Grad norm: 1.016e+02\n",
      "Epoch 11295, Loss: 441.994384765625, Neurons: 11, Grad norm: 1.271e+02\n",
      "Epoch 11296, Loss: 441.9915771484375, Neurons: 11, Grad norm: 1.242e+02\n",
      "Epoch 11297, Loss: 441.9881896972656, Neurons: 11, Grad norm: 9.267e+01\n",
      "Epoch 11298, Loss: 441.9842834472656, Neurons: 11, Grad norm: 4.527e+01\n",
      "Epoch 11299, Loss: 441.98028564453125, Neurons: 11, Grad norm: 9.597e+00\n",
      "Epoch 11299, Test loss: 438.2096252441406\n",
      "Epoch 11300, Loss: 441.9767761230469, Neurons: 11, Grad norm: 5.476e+01\n",
      "Epoch 11301, Loss: 441.97369384765625, Neurons: 11, Grad norm: 8.506e+01\n",
      "Epoch 11302, Loss: 441.9707336425781, Neurons: 11, Grad norm: 9.189e+01\n",
      "Epoch 11303, Loss: 441.967529296875, Neurons: 11, Grad norm: 7.939e+01\n",
      "Epoch 11304, Loss: 441.9639892578125, Neurons: 11, Grad norm: 4.878e+01\n",
      "Epoch 11305, Loss: 441.9602966308594, Neurons: 11, Grad norm: 1.215e+01\n",
      "Epoch 11306, Loss: 441.956787109375, Neurons: 11, Grad norm: 2.551e+01\n",
      "Epoch 11307, Loss: 441.95343017578125, Neurons: 11, Grad norm: 5.203e+01\n",
      "Epoch 11308, Loss: 441.9503479003906, Neurons: 11, Grad norm: 6.642e+01\n",
      "Epoch 11309, Loss: 441.9471435546875, Neurons: 11, Grad norm: 6.328e+01\n",
      "Epoch 11310, Loss: 441.9437255859375, Neurons: 11, Grad norm: 4.848e+01\n",
      "Epoch 11311, Loss: 441.9402770996094, Neurons: 11, Grad norm: 2.312e+01\n",
      "Epoch 11312, Loss: 441.9367980957031, Neurons: 11, Grad norm: 3.698e+00\n",
      "Epoch 11313, Loss: 441.9333801269531, Neurons: 11, Grad norm: 2.761e+01\n",
      "Epoch 11314, Loss: 441.9300842285156, Neurons: 11, Grad norm: 4.223e+01\n",
      "Epoch 11315, Loss: 441.9268798828125, Neurons: 11, Grad norm: 4.829e+01\n",
      "Epoch 11316, Loss: 441.923583984375, Neurons: 11, Grad norm: 4.218e+01\n",
      "Epoch 11317, Loss: 441.9201965332031, Neurons: 11, Grad norm: 2.977e+01\n",
      "Epoch 11318, Loss: 441.9167785644531, Neurons: 11, Grad norm: 1.109e+01\n",
      "Epoch 11319, Loss: 441.9132995605469, Neurons: 11, Grad norm: 6.801e+00\n",
      "Epoch 11320, Loss: 441.9100036621094, Neurons: 11, Grad norm: 2.272e+01\n",
      "Epoch 11321, Loss: 441.90667724609375, Neurons: 11, Grad norm: 3.101e+01\n",
      "Epoch 11322, Loss: 441.90338134765625, Neurons: 11, Grad norm: 3.413e+01\n",
      "Epoch 11323, Loss: 441.9000244140625, Neurons: 11, Grad norm: 2.870e+01\n",
      "Epoch 11324, Loss: 441.8966369628906, Neurons: 11, Grad norm: 1.996e+01\n",
      "Epoch 11325, Loss: 441.8932800292969, Neurons: 11, Grad norm: 6.824e+00\n",
      "Epoch 11326, Loss: 441.889892578125, Neurons: 11, Grad norm: 5.485e+00\n",
      "Epoch 11327, Loss: 441.88653564453125, Neurons: 11, Grad norm: 1.639e+01\n",
      "Epoch 11328, Loss: 441.8831787109375, Neurons: 11, Grad norm: 2.168e+01\n",
      "Epoch 11329, Loss: 441.8798828125, Neurons: 11, Grad norm: 2.434e+01\n",
      "Epoch 11330, Loss: 441.87652587890625, Neurons: 11, Grad norm: 2.073e+01\n",
      "Epoch 11331, Loss: 441.8731994628906, Neurons: 11, Grad norm: 1.555e+01\n",
      "Epoch 11332, Loss: 441.8698425292969, Neurons: 11, Grad norm: 6.655e+00\n",
      "Epoch 11333, Loss: 441.8664855957031, Neurons: 11, Grad norm: 2.452e+00\n",
      "Epoch 11334, Loss: 441.86309814453125, Neurons: 11, Grad norm: 9.862e+00\n",
      "Epoch 11335, Loss: 441.85968017578125, Neurons: 11, Grad norm: 1.386e+01\n",
      "Epoch 11336, Loss: 441.85638427734375, Neurons: 11, Grad norm: 1.700e+01\n",
      "Epoch 11337, Loss: 441.85302734375, Neurons: 11, Grad norm: 1.524e+01\n",
      "Epoch 11338, Loss: 441.8495788574219, Neurons: 11, Grad norm: 1.295e+01\n",
      "Epoch 11339, Loss: 441.8462829589844, Neurons: 11, Grad norm: 7.224e+00\n",
      "Epoch 11340, Loss: 441.8428955078125, Neurons: 11, Grad norm: 3.061e+00\n",
      "Epoch 11341, Loss: 441.83953857421875, Neurons: 11, Grad norm: 4.370e+00\n",
      "Epoch 11342, Loss: 441.836181640625, Neurons: 11, Grad norm: 7.519e+00\n",
      "Epoch 11343, Loss: 441.83282470703125, Neurons: 11, Grad norm: 1.102e+01\n",
      "Epoch 11344, Loss: 441.8294982910156, Neurons: 11, Grad norm: 1.093e+01\n",
      "Epoch 11345, Loss: 441.8260803222656, Neurons: 11, Grad norm: 1.111e+01\n",
      "Epoch 11346, Loss: 441.82275390625, Neurons: 11, Grad norm: 7.964e+00\n",
      "Epoch 11347, Loss: 441.8193359375, Neurons: 11, Grad norm: 5.866e+00\n",
      "Epoch 11348, Loss: 441.81597900390625, Neurons: 11, Grad norm: 2.341e+00\n",
      "Epoch 11349, Loss: 441.8125915527344, Neurons: 11, Grad norm: 2.442e+00\n",
      "Epoch 11349, Test loss: 438.0504150390625\n",
      "Epoch 11350, Loss: 441.8092346191406, Neurons: 11, Grad norm: 5.283e+00\n",
      "Epoch 11351, Loss: 441.80584716796875, Neurons: 11, Grad norm: 6.100e+00\n",
      "Epoch 11352, Loss: 441.802490234375, Neurons: 11, Grad norm: 7.834e+00\n",
      "Epoch 11353, Loss: 441.7991027832031, Neurons: 11, Grad norm: 6.859e+00\n",
      "Epoch 11354, Loss: 441.7957458496094, Neurons: 11, Grad norm: 6.944e+00\n",
      "Epoch 11355, Loss: 441.7923889160156, Neurons: 11, Grad norm: 4.589e+00\n",
      "Epoch 11356, Loss: 441.7890319824219, Neurons: 11, Grad norm: 3.705e+00\n",
      "Epoch 11357, Loss: 441.78558349609375, Neurons: 11, Grad norm: 2.060e+00\n",
      "Epoch 11358, Loss: 441.7822265625, Neurons: 11, Grad norm: 2.291e+00\n",
      "Epoch 11359, Loss: 441.7788391113281, Neurons: 11, Grad norm: 4.084e+00\n",
      "Epoch 11360, Loss: 441.7754821777344, Neurons: 11, Grad norm: 4.322e+00\n",
      "Epoch 11361, Loss: 441.7720947265625, Neurons: 11, Grad norm: 5.700e+00\n",
      "Epoch 11362, Loss: 441.76873779296875, Neurons: 11, Grad norm: 4.676e+00\n",
      "Epoch 11363, Loss: 441.7653503417969, Neurons: 11, Grad norm: 5.064e+00\n",
      "Epoch 11364, Loss: 441.7619934082031, Neurons: 11, Grad norm: 3.391e+00\n",
      "Epoch 11365, Loss: 441.7585754394531, Neurons: 11, Grad norm: 3.247e+00\n",
      "Epoch 11366, Loss: 441.75518798828125, Neurons: 11, Grad norm: 2.077e+00\n",
      "Epoch 11367, Loss: 441.7518005371094, Neurons: 11, Grad norm: 2.046e+00\n",
      "Epoch 11368, Loss: 441.7483825683594, Neurons: 11, Grad norm: 2.811e+00\n",
      "Epoch 11369, Loss: 441.7449951171875, Neurons: 11, Grad norm: 2.765e+00\n",
      "Epoch 11370, Loss: 441.74163818359375, Neurons: 11, Grad norm: 4.083e+00\n",
      "Epoch 11371, Loss: 441.7382507324219, Neurons: 11, Grad norm: 3.523e+00\n",
      "Epoch 11372, Loss: 441.7348327636719, Neurons: 11, Grad norm: 4.412e+00\n",
      "Epoch 11373, Loss: 441.7314453125, Neurons: 11, Grad norm: 3.463e+00\n",
      "Epoch 11374, Loss: 441.72802734375, Neurons: 11, Grad norm: 3.902e+00\n",
      "Epoch 11375, Loss: 441.7246398925781, Neurons: 11, Grad norm: 2.769e+00\n",
      "Epoch 11376, Loss: 441.7212829589844, Neurons: 11, Grad norm: 2.937e+00\n",
      "Epoch 11377, Loss: 441.7178955078125, Neurons: 11, Grad norm: 2.184e+00\n",
      "Epoch 11378, Loss: 441.7144775390625, Neurons: 11, Grad norm: 2.356e+00\n",
      "Epoch 11379, Loss: 441.7110900878906, Neurons: 11, Grad norm: 2.108e+00\n",
      "Epoch 11380, Loss: 441.70770263671875, Neurons: 11, Grad norm: 2.056e+00\n",
      "Epoch 11381, Loss: 441.70428466796875, Neurons: 11, Grad norm: 2.492e+00\n",
      "Epoch 11382, Loss: 441.7008972167969, Neurons: 11, Grad norm: 2.208e+00\n",
      "Epoch 11383, Loss: 441.6974792480469, Neurons: 11, Grad norm: 2.864e+00\n",
      "Epoch 11384, Loss: 441.694091796875, Neurons: 11, Grad norm: 2.469e+00\n",
      "Epoch 11385, Loss: 441.6906433105469, Neurons: 11, Grad norm: 3.231e+00\n",
      "Epoch 11386, Loss: 441.6872253417969, Neurons: 11, Grad norm: 2.688e+00\n",
      "Epoch 11387, Loss: 441.683837890625, Neurons: 11, Grad norm: 3.342e+00\n",
      "Epoch 11388, Loss: 441.68048095703125, Neurons: 11, Grad norm: 2.623e+00\n",
      "Epoch 11389, Loss: 441.6770324707031, Neurons: 11, Grad norm: 3.326e+00\n",
      "Epoch 11390, Loss: 441.673583984375, Neurons: 11, Grad norm: 2.548e+00\n",
      "Epoch 11391, Loss: 441.6701965332031, Neurons: 11, Grad norm: 3.085e+00\n",
      "Epoch 11392, Loss: 441.6667785644531, Neurons: 11, Grad norm: 2.357e+00\n",
      "Epoch 11393, Loss: 441.66339111328125, Neurons: 11, Grad norm: 2.724e+00\n",
      "Epoch 11394, Loss: 441.6600036621094, Neurons: 11, Grad norm: 2.199e+00\n",
      "Epoch 11395, Loss: 441.6565856933594, Neurons: 11, Grad norm: 2.560e+00\n",
      "Epoch 11396, Loss: 441.65313720703125, Neurons: 11, Grad norm: 2.104e+00\n",
      "Epoch 11397, Loss: 441.6497497558594, Neurons: 11, Grad norm: 2.396e+00\n",
      "Epoch 11398, Loss: 441.64630126953125, Neurons: 11, Grad norm: 2.062e+00\n",
      "Epoch 11399, Loss: 441.6429443359375, Neurons: 11, Grad norm: 2.187e+00\n",
      "Epoch 11399, Test loss: 437.8857727050781\n",
      "Epoch 11400, Loss: 441.6394958496094, Neurons: 11, Grad norm: 2.088e+00\n",
      "Epoch 11401, Loss: 441.63604736328125, Neurons: 11, Grad norm: 2.106e+00\n",
      "Epoch 11402, Loss: 441.63262939453125, Neurons: 11, Grad norm: 2.122e+00\n",
      "Epoch 11403, Loss: 441.6292419433594, Neurons: 11, Grad norm: 2.031e+00\n",
      "Epoch 11404, Loss: 441.62579345703125, Neurons: 11, Grad norm: 2.216e+00\n",
      "Epoch 11405, Loss: 441.62237548828125, Neurons: 11, Grad norm: 2.058e+00\n",
      "Epoch 11406, Loss: 441.6189880371094, Neurons: 11, Grad norm: 2.214e+00\n",
      "Epoch 11407, Loss: 441.615478515625, Neurons: 11, Grad norm: 2.056e+00\n",
      "Epoch 11408, Loss: 441.6120910644531, Neurons: 11, Grad norm: 2.181e+00\n",
      "Epoch 11409, Loss: 441.60870361328125, Neurons: 11, Grad norm: 2.055e+00\n",
      "Epoch 11410, Loss: 441.60528564453125, Neurons: 11, Grad norm: 2.141e+00\n",
      "Epoch 11411, Loss: 441.6018371582031, Neurons: 11, Grad norm: 2.051e+00\n",
      "Epoch 11412, Loss: 441.598388671875, Neurons: 11, Grad norm: 2.158e+00\n",
      "Epoch 11413, Loss: 441.5949401855469, Neurons: 11, Grad norm: 2.039e+00\n",
      "Epoch 11414, Loss: 441.5915832519531, Neurons: 11, Grad norm: 2.256e+00\n",
      "Epoch 11415, Loss: 441.58807373046875, Neurons: 11, Grad norm: 2.073e+00\n",
      "Epoch 11416, Loss: 441.5846252441406, Neurons: 11, Grad norm: 2.570e+00\n",
      "Epoch 11417, Loss: 441.5811767578125, Neurons: 11, Grad norm: 2.225e+00\n",
      "Epoch 11418, Loss: 441.5777893066406, Neurons: 11, Grad norm: 2.963e+00\n",
      "Epoch 11419, Loss: 441.5743408203125, Neurons: 11, Grad norm: 2.568e+00\n",
      "Epoch 11420, Loss: 441.5708923339844, Neurons: 11, Grad norm: 3.508e+00\n",
      "Epoch 11421, Loss: 441.5674743652344, Neurons: 11, Grad norm: 3.112e+00\n",
      "Epoch 11422, Loss: 441.56402587890625, Neurons: 11, Grad norm: 4.081e+00\n",
      "Epoch 11423, Loss: 441.5605773925781, Neurons: 11, Grad norm: 3.644e+00\n",
      "Epoch 11424, Loss: 441.55712890625, Neurons: 11, Grad norm: 4.878e+00\n",
      "Epoch 11425, Loss: 441.5536804199219, Neurons: 11, Grad norm: 4.591e+00\n",
      "Epoch 11426, Loss: 441.55023193359375, Neurons: 11, Grad norm: 6.387e+00\n",
      "Epoch 11427, Loss: 441.5467834472656, Neurons: 11, Grad norm: 6.479e+00\n",
      "Epoch 11428, Loss: 441.54339599609375, Neurons: 11, Grad norm: 8.646e+00\n",
      "Epoch 11429, Loss: 441.53997802734375, Neurons: 11, Grad norm: 9.444e+00\n",
      "Epoch 11430, Loss: 441.5364990234375, Neurons: 11, Grad norm: 1.236e+01\n",
      "Epoch 11431, Loss: 441.5330810546875, Neurons: 11, Grad norm: 1.411e+01\n",
      "Epoch 11432, Loss: 441.52960205078125, Neurons: 11, Grad norm: 1.831e+01\n",
      "Epoch 11433, Loss: 441.52618408203125, Neurons: 11, Grad norm: 2.148e+01\n",
      "Epoch 11434, Loss: 441.5226745605469, Neurons: 11, Grad norm: 2.763e+01\n",
      "Epoch 11435, Loss: 441.519287109375, Neurons: 11, Grad norm: 3.315e+01\n",
      "Epoch 11436, Loss: 441.5158386230469, Neurons: 11, Grad norm: 4.235e+01\n",
      "Epoch 11437, Loss: 441.5124816894531, Neurons: 11, Grad norm: 5.192e+01\n",
      "Epoch 11438, Loss: 441.50909423828125, Neurons: 11, Grad norm: 6.638e+01\n",
      "Epoch 11439, Loss: 441.50579833984375, Neurons: 11, Grad norm: 8.281e+01\n",
      "Epoch 11440, Loss: 441.5025939941406, Neurons: 11, Grad norm: 1.056e+02\n",
      "Epoch 11441, Loss: 441.4994812011719, Neurons: 11, Grad norm: 1.320e+02\n",
      "Epoch 11442, Loss: 441.49658203125, Neurons: 11, Grad norm: 1.663e+02\n",
      "Epoch 11443, Loss: 441.4940490722656, Neurons: 11, Grad norm: 2.049e+02\n",
      "Epoch 11444, Loss: 441.49188232421875, Neurons: 11, Grad norm: 2.497e+02\n",
      "Epoch 11445, Loss: 441.4902038574219, Neurons: 11, Grad norm: 2.920e+02\n",
      "Epoch 11446, Loss: 441.4888000488281, Neurons: 11, Grad norm: 3.256e+02\n",
      "Epoch 11447, Loss: 441.4872741699219, Neurons: 11, Grad norm: 3.329e+02\n",
      "Epoch 11448, Loss: 441.4843444824219, Neurons: 11, Grad norm: 3.028e+02\n",
      "Epoch 11449, Loss: 441.4792785644531, Neurons: 11, Grad norm: 2.264e+02\n",
      "Epoch 11449, Test loss: 437.77734375\n",
      "Epoch 11450, Loss: 441.4725036621094, Neurons: 11, Grad norm: 1.169e+02\n",
      "Epoch 11451, Loss: 441.46588134765625, Neurons: 11, Grad norm: 6.980e+00\n",
      "Epoch 11452, Loss: 441.4613952636719, Neurons: 11, Grad norm: 1.149e+02\n",
      "Epoch 11453, Loss: 441.459228515625, Neurons: 11, Grad norm: 1.907e+02\n",
      "Epoch 11454, Loss: 441.4579772949219, Neurons: 11, Grad norm: 2.166e+02\n",
      "Epoch 11455, Loss: 441.4556884765625, Neurons: 11, Grad norm: 1.926e+02\n",
      "Epoch 11456, Loss: 441.45147705078125, Neurons: 11, Grad norm: 1.227e+02\n",
      "Epoch 11457, Loss: 441.4462890625, Neurons: 11, Grad norm: 3.076e+01\n",
      "Epoch 11458, Loss: 441.4418029785156, Neurons: 11, Grad norm: 6.159e+01\n",
      "Epoch 11459, Loss: 441.43878173828125, Neurons: 11, Grad norm: 1.275e+02\n",
      "Epoch 11460, Loss: 441.4366455078125, Neurons: 11, Grad norm: 1.562e+02\n",
      "Epoch 11461, Loss: 441.43408203125, Neurons: 11, Grad norm: 1.397e+02\n",
      "Epoch 11462, Loss: 441.4303894042969, Neurons: 11, Grad norm: 8.929e+01\n",
      "Epoch 11463, Loss: 441.4261474609375, Neurons: 11, Grad norm: 1.827e+01\n",
      "Epoch 11464, Loss: 441.42218017578125, Neurons: 11, Grad norm: 4.904e+01\n",
      "Epoch 11465, Loss: 441.419189453125, Neurons: 11, Grad norm: 9.802e+01\n",
      "Epoch 11466, Loss: 441.4165344238281, Neurons: 11, Grad norm: 1.142e+02\n",
      "Epoch 11467, Loss: 441.41357421875, Neurons: 11, Grad norm: 9.960e+01\n",
      "Epoch 11468, Loss: 441.4100341796875, Neurons: 11, Grad norm: 5.754e+01\n",
      "Epoch 11469, Loss: 441.4062805175781, Neurons: 11, Grad norm: 5.899e+00\n",
      "Epoch 11470, Loss: 441.4027404785156, Neurons: 11, Grad norm: 4.425e+01\n",
      "Epoch 11471, Loss: 441.3996276855469, Neurons: 11, Grad norm: 7.553e+01\n",
      "Epoch 11472, Loss: 441.396728515625, Neurons: 11, Grad norm: 8.501e+01\n",
      "Epoch 11473, Loss: 441.3935852050781, Neurons: 11, Grad norm: 6.902e+01\n",
      "Epoch 11474, Loss: 441.39013671875, Neurons: 11, Grad norm: 3.778e+01\n",
      "Epoch 11475, Loss: 441.3865966796875, Neurons: 11, Grad norm: 2.995e+00\n",
      "Epoch 11476, Loss: 441.38323974609375, Neurons: 11, Grad norm: 3.576e+01\n",
      "Epoch 11477, Loss: 441.3800964355469, Neurons: 11, Grad norm: 5.814e+01\n",
      "Epoch 11478, Loss: 441.3769836425781, Neurons: 11, Grad norm: 6.145e+01\n",
      "Epoch 11479, Loss: 441.37384033203125, Neurons: 11, Grad norm: 4.989e+01\n",
      "Epoch 11480, Loss: 441.3704528808594, Neurons: 11, Grad norm: 2.477e+01\n",
      "Epoch 11481, Loss: 441.3670349121094, Neurons: 11, Grad norm: 3.407e+00\n",
      "Epoch 11482, Loss: 441.3638000488281, Neurons: 11, Grad norm: 2.846e+01\n",
      "Epoch 11483, Loss: 441.360595703125, Neurons: 11, Grad norm: 4.257e+01\n",
      "Epoch 11484, Loss: 441.3573913574219, Neurons: 11, Grad norm: 4.610e+01\n",
      "Epoch 11485, Loss: 441.35418701171875, Neurons: 11, Grad norm: 3.608e+01\n",
      "Epoch 11486, Loss: 441.35089111328125, Neurons: 11, Grad norm: 1.974e+01\n",
      "Epoch 11487, Loss: 441.34759521484375, Neurons: 11, Grad norm: 2.588e+00\n",
      "Epoch 11488, Loss: 441.34423828125, Neurons: 11, Grad norm: 1.864e+01\n",
      "Epoch 11489, Loss: 441.3410339355469, Neurons: 11, Grad norm: 3.097e+01\n",
      "Epoch 11490, Loss: 441.33782958984375, Neurons: 11, Grad norm: 3.289e+01\n",
      "Epoch 11491, Loss: 441.3345947265625, Neurons: 11, Grad norm: 2.840e+01\n",
      "Epoch 11492, Loss: 441.3313293457031, Neurons: 11, Grad norm: 1.596e+01\n",
      "Epoch 11493, Loss: 441.3280029296875, Neurons: 11, Grad norm: 3.138e+00\n",
      "Epoch 11494, Loss: 441.3247375488281, Neurons: 11, Grad norm: 1.213e+01\n",
      "Epoch 11495, Loss: 441.3215026855469, Neurons: 11, Grad norm: 2.055e+01\n",
      "Epoch 11496, Loss: 441.3182373046875, Neurons: 11, Grad norm: 2.529e+01\n",
      "Epoch 11497, Loss: 441.31500244140625, Neurons: 11, Grad norm: 2.221e+01\n",
      "Epoch 11498, Loss: 441.3117370605469, Neurons: 11, Grad norm: 1.630e+01\n",
      "Epoch 11499, Loss: 441.3084411621094, Neurons: 11, Grad norm: 5.717e+00\n",
      "Epoch 11499, Test loss: 437.56427001953125\n",
      "Epoch 11500, Loss: 441.3051452636719, Neurons: 11, Grad norm: 4.450e+00\n",
      "Epoch 11501, Loss: 441.30194091796875, Neurons: 11, Grad norm: 1.330e+01\n",
      "Epoch 11502, Loss: 441.2986755371094, Neurons: 11, Grad norm: 1.715e+01\n",
      "Epoch 11503, Loss: 441.2953796386719, Neurons: 11, Grad norm: 1.849e+01\n",
      "Epoch 11504, Loss: 441.2920837402344, Neurons: 11, Grad norm: 1.416e+01\n",
      "Epoch 11505, Loss: 441.2888488769531, Neurons: 11, Grad norm: 8.997e+00\n",
      "Epoch 11506, Loss: 441.28558349609375, Neurons: 11, Grad norm: 2.104e+00\n",
      "Epoch 11507, Loss: 441.28228759765625, Neurons: 11, Grad norm: 5.501e+00\n",
      "Epoch 11508, Loss: 441.279052734375, Neurons: 11, Grad norm: 1.108e+01\n",
      "Epoch 11509, Loss: 441.2757873535156, Neurons: 11, Grad norm: 1.228e+01\n",
      "Epoch 11510, Loss: 441.2724914550781, Neurons: 11, Grad norm: 1.254e+01\n",
      "Epoch 11511, Loss: 441.2691955566406, Neurons: 11, Grad norm: 8.777e+00\n",
      "Epoch 11512, Loss: 441.26593017578125, Neurons: 11, Grad norm: 5.411e+00\n",
      "Epoch 11513, Loss: 441.26263427734375, Neurons: 11, Grad norm: 2.182e+00\n",
      "Epoch 11514, Loss: 441.2593994140625, Neurons: 11, Grad norm: 4.587e+00\n",
      "Epoch 11515, Loss: 441.2561340332031, Neurons: 11, Grad norm: 8.316e+00\n",
      "Epoch 11516, Loss: 441.2527770996094, Neurons: 11, Grad norm: 8.509e+00\n",
      "Epoch 11517, Loss: 441.2496032714844, Neurons: 11, Grad norm: 8.880e+00\n",
      "Epoch 11518, Loss: 441.24627685546875, Neurons: 11, Grad norm: 5.993e+00\n",
      "Epoch 11519, Loss: 441.24298095703125, Neurons: 11, Grad norm: 4.113e+00\n",
      "Epoch 11520, Loss: 441.23968505859375, Neurons: 11, Grad norm: 2.089e+00\n",
      "Epoch 11521, Loss: 441.23638916015625, Neurons: 11, Grad norm: 3.237e+00\n",
      "Epoch 11522, Loss: 441.2331237792969, Neurons: 11, Grad norm: 5.880e+00\n",
      "Epoch 11523, Loss: 441.2298889160156, Neurons: 11, Grad norm: 5.929e+00\n",
      "Epoch 11524, Loss: 441.2265930175781, Neurons: 11, Grad norm: 6.651e+00\n",
      "Epoch 11525, Loss: 441.2232971191406, Neurons: 11, Grad norm: 4.661e+00\n",
      "Epoch 11526, Loss: 441.2200012207031, Neurons: 11, Grad norm: 3.858e+00\n",
      "Epoch 11527, Loss: 441.2166748046875, Neurons: 11, Grad norm: 2.022e+00\n",
      "Epoch 11528, Loss: 441.21343994140625, Neurons: 11, Grad norm: 2.263e+00\n",
      "Epoch 11529, Loss: 441.2101745605469, Neurons: 11, Grad norm: 4.198e+00\n",
      "Epoch 11530, Loss: 441.20684814453125, Neurons: 11, Grad norm: 4.236e+00\n",
      "Epoch 11531, Loss: 441.2035827636719, Neurons: 11, Grad norm: 5.285e+00\n",
      "Epoch 11532, Loss: 441.2002258300781, Neurons: 11, Grad norm: 4.036e+00\n",
      "Epoch 11533, Loss: 441.1969909667969, Neurons: 11, Grad norm: 3.996e+00\n",
      "Epoch 11534, Loss: 441.1936950683594, Neurons: 11, Grad norm: 2.320e+00\n",
      "Epoch 11535, Loss: 441.1903991699219, Neurons: 11, Grad norm: 2.111e+00\n",
      "Epoch 11536, Loss: 441.1871032714844, Neurons: 11, Grad norm: 2.765e+00\n",
      "Epoch 11537, Loss: 441.18377685546875, Neurons: 11, Grad norm: 3.044e+00\n",
      "Epoch 11538, Loss: 441.18048095703125, Neurons: 11, Grad norm: 4.422e+00\n",
      "Epoch 11539, Loss: 441.17718505859375, Neurons: 11, Grad norm: 3.813e+00\n",
      "Epoch 11540, Loss: 441.17388916015625, Neurons: 11, Grad norm: 4.542e+00\n",
      "Epoch 11541, Loss: 441.17059326171875, Neurons: 11, Grad norm: 3.238e+00\n",
      "Epoch 11542, Loss: 441.16729736328125, Neurons: 11, Grad norm: 3.237e+00\n",
      "Epoch 11543, Loss: 441.16400146484375, Neurons: 11, Grad norm: 2.076e+00\n",
      "Epoch 11544, Loss: 441.1606750488281, Neurons: 11, Grad norm: 2.030e+00\n",
      "Epoch 11545, Loss: 441.1573791503906, Neurons: 11, Grad norm: 2.693e+00\n",
      "Epoch 11546, Loss: 441.15399169921875, Neurons: 11, Grad norm: 2.646e+00\n",
      "Epoch 11547, Loss: 441.1507873535156, Neurons: 11, Grad norm: 3.785e+00\n",
      "Epoch 11548, Loss: 441.1474304199219, Neurons: 11, Grad norm: 3.109e+00\n",
      "Epoch 11549, Loss: 441.1441345214844, Neurons: 11, Grad norm: 3.661e+00\n",
      "Epoch 11549, Test loss: 437.4035949707031\n",
      "Epoch 11550, Loss: 441.1408386230469, Neurons: 11, Grad norm: 2.586e+00\n",
      "Epoch 11551, Loss: 441.1374816894531, Neurons: 11, Grad norm: 2.841e+00\n",
      "Epoch 11552, Loss: 441.1341857910156, Neurons: 11, Grad norm: 2.049e+00\n",
      "Epoch 11553, Loss: 441.1308898925781, Neurons: 11, Grad norm: 2.071e+00\n",
      "Epoch 11554, Loss: 441.1275939941406, Neurons: 11, Grad norm: 2.389e+00\n",
      "Epoch 11555, Loss: 441.1242370605469, Neurons: 11, Grad norm: 2.289e+00\n",
      "Epoch 11556, Loss: 441.1209411621094, Neurons: 11, Grad norm: 3.112e+00\n",
      "Epoch 11557, Loss: 441.1176452636719, Neurons: 11, Grad norm: 2.597e+00\n",
      "Epoch 11558, Loss: 441.1142883300781, Neurons: 11, Grad norm: 3.245e+00\n",
      "Epoch 11559, Loss: 441.1109924316406, Neurons: 11, Grad norm: 2.290e+00\n",
      "Epoch 11560, Loss: 441.1076965332031, Neurons: 11, Grad norm: 2.578e+00\n",
      "Epoch 11561, Loss: 441.1043395996094, Neurons: 11, Grad norm: 2.028e+00\n",
      "Epoch 11562, Loss: 441.1010437011719, Neurons: 11, Grad norm: 2.028e+00\n",
      "Epoch 11563, Loss: 441.0976867675781, Neurons: 11, Grad norm: 2.192e+00\n",
      "Epoch 11564, Loss: 441.0943298339844, Neurons: 11, Grad norm: 2.094e+00\n",
      "Epoch 11565, Loss: 441.0910339355469, Neurons: 11, Grad norm: 2.811e+00\n",
      "Epoch 11566, Loss: 441.0876770019531, Neurons: 11, Grad norm: 2.399e+00\n",
      "Epoch 11567, Loss: 441.0843811035156, Neurons: 11, Grad norm: 3.179e+00\n",
      "Epoch 11568, Loss: 441.0810852050781, Neurons: 11, Grad norm: 2.457e+00\n",
      "Epoch 11569, Loss: 441.0777893066406, Neurons: 11, Grad norm: 3.030e+00\n",
      "Epoch 11570, Loss: 441.07440185546875, Neurons: 11, Grad norm: 2.312e+00\n",
      "Epoch 11571, Loss: 441.0710754394531, Neurons: 11, Grad norm: 2.684e+00\n",
      "Epoch 11572, Loss: 441.0677490234375, Neurons: 11, Grad norm: 2.081e+00\n",
      "Epoch 11573, Loss: 441.064453125, Neurons: 11, Grad norm: 2.252e+00\n",
      "Epoch 11574, Loss: 441.06109619140625, Neurons: 11, Grad norm: 2.038e+00\n",
      "Epoch 11575, Loss: 441.0577392578125, Neurons: 11, Grad norm: 2.013e+00\n",
      "Epoch 11576, Loss: 441.05438232421875, Neurons: 11, Grad norm: 2.370e+00\n",
      "Epoch 11577, Loss: 441.051025390625, Neurons: 11, Grad norm: 2.102e+00\n",
      "Epoch 11578, Loss: 441.0476989746094, Neurons: 11, Grad norm: 2.705e+00\n",
      "Epoch 11579, Loss: 441.0444030761719, Neurons: 11, Grad norm: 2.275e+00\n",
      "Epoch 11580, Loss: 441.0409851074219, Neurons: 11, Grad norm: 2.889e+00\n",
      "Epoch 11581, Loss: 441.0376892089844, Neurons: 11, Grad norm: 2.314e+00\n",
      "Epoch 11582, Loss: 441.0343933105469, Neurons: 11, Grad norm: 2.753e+00\n",
      "Epoch 11583, Loss: 441.0310363769531, Neurons: 11, Grad norm: 2.182e+00\n",
      "Epoch 11584, Loss: 441.02764892578125, Neurons: 11, Grad norm: 2.624e+00\n",
      "Epoch 11585, Loss: 441.02435302734375, Neurons: 11, Grad norm: 2.079e+00\n",
      "Epoch 11586, Loss: 441.02099609375, Neurons: 11, Grad norm: 2.379e+00\n",
      "Epoch 11587, Loss: 441.01763916015625, Neurons: 11, Grad norm: 2.020e+00\n",
      "Epoch 11588, Loss: 441.0142822265625, Neurons: 11, Grad norm: 2.148e+00\n",
      "Epoch 11589, Loss: 441.0108947753906, Neurons: 11, Grad norm: 2.072e+00\n",
      "Epoch 11590, Loss: 441.0075988769531, Neurons: 11, Grad norm: 1.994e+00\n",
      "Epoch 11591, Loss: 441.0041809082031, Neurons: 11, Grad norm: 2.179e+00\n",
      "Epoch 11592, Loss: 441.0008850097656, Neurons: 11, Grad norm: 1.995e+00\n",
      "Epoch 11593, Loss: 440.99749755859375, Neurons: 11, Grad norm: 2.319e+00\n",
      "Epoch 11594, Loss: 440.99420166015625, Neurons: 11, Grad norm: 2.015e+00\n",
      "Epoch 11595, Loss: 440.9908447265625, Neurons: 11, Grad norm: 2.282e+00\n",
      "Epoch 11596, Loss: 440.98748779296875, Neurons: 11, Grad norm: 2.019e+00\n",
      "Epoch 11597, Loss: 440.9841003417969, Neurons: 11, Grad norm: 2.322e+00\n",
      "Epoch 11598, Loss: 440.9807434082031, Neurons: 11, Grad norm: 2.040e+00\n",
      "Epoch 11599, Loss: 440.9773864746094, Neurons: 11, Grad norm: 2.416e+00\n",
      "Epoch 11599, Test loss: 437.24267578125\n",
      "Epoch 11600, Loss: 440.9740295410156, Neurons: 11, Grad norm: 2.077e+00\n",
      "Epoch 11601, Loss: 440.970703125, Neurons: 11, Grad norm: 2.522e+00\n",
      "Epoch 11602, Loss: 440.96728515625, Neurons: 11, Grad norm: 2.092e+00\n",
      "Epoch 11603, Loss: 440.96392822265625, Neurons: 11, Grad norm: 2.569e+00\n",
      "Epoch 11604, Loss: 440.9605407714844, Neurons: 11, Grad norm: 2.106e+00\n",
      "Epoch 11605, Loss: 440.9571838378906, Neurons: 11, Grad norm: 2.608e+00\n",
      "Epoch 11606, Loss: 440.9538269042969, Neurons: 11, Grad norm: 2.172e+00\n",
      "Epoch 11607, Loss: 440.95050048828125, Neurons: 11, Grad norm: 2.690e+00\n",
      "Epoch 11608, Loss: 440.9471435546875, Neurons: 11, Grad norm: 2.131e+00\n",
      "Epoch 11609, Loss: 440.9437255859375, Neurons: 11, Grad norm: 2.551e+00\n",
      "Epoch 11610, Loss: 440.9403991699219, Neurons: 11, Grad norm: 2.072e+00\n",
      "Epoch 11611, Loss: 440.9369812011719, Neurons: 11, Grad norm: 2.418e+00\n",
      "Epoch 11612, Loss: 440.9336242675781, Neurons: 11, Grad norm: 2.055e+00\n",
      "Epoch 11613, Loss: 440.9302978515625, Neurons: 11, Grad norm: 2.509e+00\n",
      "Epoch 11614, Loss: 440.9268798828125, Neurons: 11, Grad norm: 2.165e+00\n",
      "Epoch 11615, Loss: 440.9234924316406, Neurons: 11, Grad norm: 2.971e+00\n",
      "Epoch 11616, Loss: 440.9201354980469, Neurons: 11, Grad norm: 2.499e+00\n",
      "Epoch 11617, Loss: 440.9167785644531, Neurons: 11, Grad norm: 3.459e+00\n",
      "Epoch 11618, Loss: 440.91339111328125, Neurons: 11, Grad norm: 3.132e+00\n",
      "Epoch 11619, Loss: 440.9100341796875, Neurons: 11, Grad norm: 4.403e+00\n",
      "Epoch 11620, Loss: 440.9065856933594, Neurons: 11, Grad norm: 4.298e+00\n",
      "Epoch 11621, Loss: 440.9032287597656, Neurons: 11, Grad norm: 5.783e+00\n",
      "Epoch 11622, Loss: 440.89990234375, Neurons: 11, Grad norm: 5.943e+00\n",
      "Epoch 11623, Loss: 440.896484375, Neurons: 11, Grad norm: 8.291e+00\n",
      "Epoch 11624, Loss: 440.89312744140625, Neurons: 11, Grad norm: 9.017e+00\n",
      "Epoch 11625, Loss: 440.8897399902344, Neurons: 11, Grad norm: 1.231e+01\n",
      "Epoch 11626, Loss: 440.8863525390625, Neurons: 11, Grad norm: 1.432e+01\n",
      "Epoch 11627, Loss: 440.88299560546875, Neurons: 11, Grad norm: 1.896e+01\n",
      "Epoch 11628, Loss: 440.8795471191406, Neurons: 11, Grad norm: 2.301e+01\n",
      "Epoch 11629, Loss: 440.8761901855469, Neurons: 11, Grad norm: 3.010e+01\n",
      "Epoch 11630, Loss: 440.8728332519531, Neurons: 11, Grad norm: 3.718e+01\n",
      "Epoch 11631, Loss: 440.8694763183594, Neurons: 11, Grad norm: 4.835e+01\n",
      "Epoch 11632, Loss: 440.8661804199219, Neurons: 11, Grad norm: 6.057e+01\n",
      "Epoch 11633, Loss: 440.8628845214844, Neurons: 11, Grad norm: 7.874e+01\n",
      "Epoch 11634, Loss: 440.85968017578125, Neurons: 11, Grad norm: 9.984e+01\n",
      "Epoch 11635, Loss: 440.856689453125, Neurons: 11, Grad norm: 1.290e+02\n",
      "Epoch 11636, Loss: 440.8537902832031, Neurons: 11, Grad norm: 1.638e+02\n",
      "Epoch 11637, Loss: 440.85137939453125, Neurons: 11, Grad norm: 2.079e+02\n",
      "Epoch 11638, Loss: 440.8493957519531, Neurons: 11, Grad norm: 2.571e+02\n",
      "Epoch 11639, Loss: 440.8479309082031, Neurons: 11, Grad norm: 3.100e+02\n",
      "Epoch 11640, Loss: 440.8471374511719, Neurons: 11, Grad norm: 3.526e+02\n",
      "Epoch 11641, Loss: 440.84625244140625, Neurons: 11, Grad norm: 3.714e+02\n",
      "Epoch 11642, Loss: 440.8441467285156, Neurons: 11, Grad norm: 3.434e+02\n",
      "Epoch 11643, Loss: 440.8392028808594, Neurons: 11, Grad norm: 2.623e+02\n",
      "Epoch 11644, Loss: 440.8316955566406, Neurons: 11, Grad norm: 1.341e+02\n",
      "Epoch 11645, Loss: 440.8241882324219, Neurons: 11, Grad norm: 9.728e+00\n",
      "Epoch 11646, Loss: 440.8194885253906, Neurons: 11, Grad norm: 1.383e+02\n",
      "Epoch 11647, Loss: 440.8178405761719, Neurons: 11, Grad norm: 2.212e+02\n",
      "Epoch 11648, Loss: 440.81719970703125, Neurons: 11, Grad norm: 2.448e+02\n",
      "Epoch 11649, Loss: 440.81488037109375, Neurons: 11, Grad norm: 2.014e+02\n",
      "Epoch 11649, Test loss: 437.1308288574219\n",
      "Epoch 11650, Loss: 440.8100891113281, Neurons: 11, Grad norm: 1.090e+02\n",
      "Epoch 11651, Loss: 440.8044738769531, Neurons: 11, Grad norm: 6.866e+00\n",
      "Epoch 11652, Loss: 440.80029296875, Neurons: 11, Grad norm: 1.072e+02\n",
      "Epoch 11653, Loss: 440.7981262207031, Neurons: 11, Grad norm: 1.689e+02\n",
      "Epoch 11654, Loss: 440.79638671875, Neurons: 11, Grad norm: 1.741e+02\n",
      "Epoch 11655, Loss: 440.79339599609375, Neurons: 11, Grad norm: 1.286e+02\n",
      "Epoch 11656, Loss: 440.7890319824219, Neurons: 11, Grad norm: 4.703e+01\n",
      "Epoch 11657, Loss: 440.7846984863281, Neurons: 11, Grad norm: 3.935e+01\n",
      "Epoch 11658, Loss: 440.781494140625, Neurons: 11, Grad norm: 1.067e+02\n",
      "Epoch 11659, Loss: 440.7791748046875, Neurons: 11, Grad norm: 1.332e+02\n",
      "Epoch 11660, Loss: 440.7764892578125, Neurons: 11, Grad norm: 1.177e+02\n",
      "Epoch 11661, Loss: 440.7730407714844, Neurons: 11, Grad norm: 6.535e+01\n",
      "Epoch 11662, Loss: 440.76910400390625, Neurons: 11, Grad norm: 2.078e+00\n",
      "Epoch 11663, Loss: 440.7655944824219, Neurons: 11, Grad norm: 6.129e+01\n",
      "Epoch 11664, Loss: 440.7627258300781, Neurons: 11, Grad norm: 9.531e+01\n",
      "Epoch 11665, Loss: 440.7600402832031, Neurons: 11, Grad norm: 9.801e+01\n",
      "Epoch 11666, Loss: 440.75689697265625, Neurons: 11, Grad norm: 6.827e+01\n",
      "Epoch 11667, Loss: 440.7533874511719, Neurons: 11, Grad norm: 2.200e+01\n",
      "Epoch 11668, Loss: 440.7498474121094, Neurons: 11, Grad norm: 2.828e+01\n",
      "Epoch 11669, Loss: 440.7467346191406, Neurons: 11, Grad norm: 6.311e+01\n",
      "Epoch 11670, Loss: 440.743896484375, Neurons: 11, Grad norm: 7.666e+01\n",
      "Epoch 11671, Loss: 440.7408752441406, Neurons: 11, Grad norm: 6.368e+01\n",
      "Epoch 11672, Loss: 440.7375793457031, Neurons: 11, Grad norm: 3.422e+01\n",
      "Epoch 11673, Loss: 440.734130859375, Neurons: 11, Grad norm: 4.800e+00\n",
      "Epoch 11674, Loss: 440.73089599609375, Neurons: 11, Grad norm: 3.626e+01\n",
      "Epoch 11675, Loss: 440.7278747558594, Neurons: 11, Grad norm: 5.560e+01\n",
      "Epoch 11676, Loss: 440.7248840332031, Neurons: 11, Grad norm: 5.482e+01\n",
      "Epoch 11677, Loss: 440.7216796875, Neurons: 11, Grad norm: 3.940e+01\n",
      "Epoch 11678, Loss: 440.7183837890625, Neurons: 11, Grad norm: 1.215e+01\n",
      "Epoch 11679, Loss: 440.7151794433594, Neurons: 11, Grad norm: 1.471e+01\n",
      "Epoch 11680, Loss: 440.7120361328125, Neurons: 11, Grad norm: 3.595e+01\n",
      "Epoch 11681, Loss: 440.7089538574219, Neurons: 11, Grad norm: 4.300e+01\n",
      "Epoch 11682, Loss: 440.7059020996094, Neurons: 11, Grad norm: 3.849e+01\n",
      "Epoch 11683, Loss: 440.70269775390625, Neurons: 11, Grad norm: 2.166e+01\n",
      "Epoch 11684, Loss: 440.6994323730469, Neurons: 11, Grad norm: 2.663e+00\n",
      "Epoch 11685, Loss: 440.69622802734375, Neurons: 11, Grad norm: 1.837e+01\n",
      "Epoch 11686, Loss: 440.6930847167969, Neurons: 11, Grad norm: 2.947e+01\n",
      "Epoch 11687, Loss: 440.69000244140625, Neurons: 11, Grad norm: 3.287e+01\n",
      "Epoch 11688, Loss: 440.6867980957031, Neurons: 11, Grad norm: 2.501e+01\n",
      "Epoch 11689, Loss: 440.6836242675781, Neurons: 11, Grad norm: 1.269e+01\n",
      "Epoch 11690, Loss: 440.6804504394531, Neurons: 11, Grad norm: 4.184e+00\n",
      "Epoch 11691, Loss: 440.6772766113281, Neurons: 11, Grad norm: 1.573e+01\n",
      "Epoch 11692, Loss: 440.67413330078125, Neurons: 11, Grad norm: 2.383e+01\n",
      "Epoch 11693, Loss: 440.6709899902344, Neurons: 11, Grad norm: 2.317e+01\n",
      "Epoch 11694, Loss: 440.66778564453125, Neurons: 11, Grad norm: 1.823e+01\n",
      "Epoch 11695, Loss: 440.6647033691406, Neurons: 11, Grad norm: 7.477e+00\n",
      "Epoch 11696, Loss: 440.66143798828125, Neurons: 11, Grad norm: 3.344e+00\n",
      "Epoch 11697, Loss: 440.6582946777344, Neurons: 11, Grad norm: 1.256e+01\n",
      "Epoch 11698, Loss: 440.65509033203125, Neurons: 11, Grad norm: 1.644e+01\n",
      "Epoch 11699, Loss: 440.6518859863281, Neurons: 11, Grad norm: 1.750e+01\n",
      "Epoch 11699, Test loss: 436.9250183105469\n",
      "Epoch 11700, Loss: 440.6488037109375, Neurons: 11, Grad norm: 1.243e+01\n",
      "Epoch 11701, Loss: 440.6455993652344, Neurons: 11, Grad norm: 6.665e+00\n",
      "Epoch 11702, Loss: 440.64239501953125, Neurons: 11, Grad norm: 3.077e+00\n",
      "Epoch 11703, Loss: 440.6392517089844, Neurons: 11, Grad norm: 8.027e+00\n",
      "Epoch 11704, Loss: 440.6360778808594, Neurons: 11, Grad norm: 1.239e+01\n",
      "Epoch 11705, Loss: 440.6329040527344, Neurons: 11, Grad norm: 1.190e+01\n",
      "Epoch 11706, Loss: 440.6297302246094, Neurons: 11, Grad norm: 1.039e+01\n",
      "Epoch 11707, Loss: 440.62652587890625, Neurons: 11, Grad norm: 5.296e+00\n",
      "Epoch 11708, Loss: 440.62335205078125, Neurons: 11, Grad norm: 2.130e+00\n",
      "Epoch 11709, Loss: 440.6201477050781, Neurons: 11, Grad norm: 5.339e+00\n",
      "Epoch 11710, Loss: 440.6169738769531, Neurons: 11, Grad norm: 7.406e+00\n",
      "Epoch 11711, Loss: 440.6138000488281, Neurons: 11, Grad norm: 9.356e+00\n",
      "Epoch 11712, Loss: 440.6106262207031, Neurons: 11, Grad norm: 7.421e+00\n",
      "Epoch 11713, Loss: 440.6074523925781, Neurons: 11, Grad norm: 5.647e+00\n",
      "Epoch 11714, Loss: 440.604248046875, Neurons: 11, Grad norm: 2.126e+00\n",
      "Epoch 11715, Loss: 440.6010437011719, Neurons: 11, Grad norm: 2.705e+00\n",
      "Epoch 11716, Loss: 440.59783935546875, Neurons: 11, Grad norm: 5.810e+00\n",
      "Epoch 11717, Loss: 440.5946960449219, Neurons: 11, Grad norm: 6.143e+00\n",
      "Epoch 11718, Loss: 440.59149169921875, Neurons: 11, Grad norm: 6.893e+00\n",
      "Epoch 11719, Loss: 440.5882873535156, Neurons: 11, Grad norm: 4.655e+00\n",
      "Epoch 11720, Loss: 440.5850830078125, Neurons: 11, Grad norm: 3.481e+00\n",
      "Epoch 11721, Loss: 440.5818786621094, Neurons: 11, Grad norm: 2.094e+00\n",
      "Epoch 11722, Loss: 440.5787353515625, Neurons: 11, Grad norm: 2.947e+00\n",
      "Epoch 11723, Loss: 440.57550048828125, Neurons: 11, Grad norm: 5.060e+00\n",
      "Epoch 11724, Loss: 440.57232666015625, Neurons: 11, Grad norm: 4.733e+00\n",
      "Epoch 11725, Loss: 440.5691833496094, Neurons: 11, Grad norm: 5.351e+00\n",
      "Epoch 11726, Loss: 440.5659484863281, Neurons: 11, Grad norm: 3.404e+00\n",
      "Epoch 11727, Loss: 440.5627746582031, Neurons: 11, Grad norm: 2.888e+00\n",
      "Epoch 11728, Loss: 440.5594787597656, Neurons: 11, Grad norm: 2.119e+00\n",
      "Epoch 11729, Loss: 440.5562744140625, Neurons: 11, Grad norm: 2.373e+00\n",
      "Epoch 11730, Loss: 440.5531921386719, Neurons: 11, Grad norm: 3.649e+00\n",
      "Epoch 11731, Loss: 440.5499267578125, Neurons: 11, Grad norm: 3.231e+00\n",
      "Epoch 11732, Loss: 440.5467529296875, Neurons: 11, Grad norm: 3.753e+00\n",
      "Epoch 11733, Loss: 440.5435791015625, Neurons: 11, Grad norm: 2.433e+00\n",
      "Epoch 11734, Loss: 440.5403747558594, Neurons: 11, Grad norm: 2.398e+00\n",
      "Epoch 11735, Loss: 440.5370788574219, Neurons: 11, Grad norm: 2.216e+00\n",
      "Epoch 11736, Loss: 440.533935546875, Neurons: 11, Grad norm: 2.228e+00\n",
      "Epoch 11737, Loss: 440.5307312011719, Neurons: 11, Grad norm: 3.239e+00\n",
      "Epoch 11738, Loss: 440.5274963378906, Neurons: 11, Grad norm: 2.707e+00\n",
      "Epoch 11739, Loss: 440.5242919921875, Neurons: 11, Grad norm: 3.135e+00\n",
      "Epoch 11740, Loss: 440.5210876464844, Neurons: 11, Grad norm: 2.223e+00\n",
      "Epoch 11741, Loss: 440.51788330078125, Neurons: 11, Grad norm: 2.341e+00\n",
      "Epoch 11742, Loss: 440.5146789550781, Neurons: 11, Grad norm: 2.040e+00\n",
      "Epoch 11743, Loss: 440.5114440917969, Neurons: 11, Grad norm: 1.986e+00\n",
      "Epoch 11744, Loss: 440.5081787109375, Neurons: 11, Grad norm: 2.597e+00\n",
      "Epoch 11745, Loss: 440.5049743652344, Neurons: 11, Grad norm: 2.219e+00\n",
      "Epoch 11746, Loss: 440.5018005371094, Neurons: 11, Grad norm: 2.796e+00\n",
      "Epoch 11747, Loss: 440.49859619140625, Neurons: 11, Grad norm: 2.137e+00\n",
      "Epoch 11748, Loss: 440.4953918457031, Neurons: 11, Grad norm: 2.344e+00\n",
      "Epoch 11749, Loss: 440.49212646484375, Neurons: 11, Grad norm: 1.973e+00\n",
      "Epoch 11749, Test loss: 436.77459716796875\n",
      "Epoch 11750, Loss: 440.4888916015625, Neurons: 11, Grad norm: 1.982e+00\n",
      "Epoch 11751, Loss: 440.4856872558594, Neurons: 11, Grad norm: 2.231e+00\n",
      "Epoch 11752, Loss: 440.48248291015625, Neurons: 11, Grad norm: 2.035e+00\n",
      "Epoch 11753, Loss: 440.479248046875, Neurons: 11, Grad norm: 2.645e+00\n",
      "Epoch 11754, Loss: 440.4759826660156, Neurons: 11, Grad norm: 2.138e+00\n",
      "Epoch 11755, Loss: 440.4727783203125, Neurons: 11, Grad norm: 2.615e+00\n",
      "Epoch 11756, Loss: 440.4695739746094, Neurons: 11, Grad norm: 2.007e+00\n",
      "Epoch 11757, Loss: 440.4663391113281, Neurons: 11, Grad norm: 2.058e+00\n",
      "Epoch 11758, Loss: 440.46307373046875, Neurons: 11, Grad norm: 2.101e+00\n",
      "Epoch 11759, Loss: 440.45989990234375, Neurons: 11, Grad norm: 2.008e+00\n",
      "Epoch 11760, Loss: 440.4566345214844, Neurons: 11, Grad norm: 2.652e+00\n",
      "Epoch 11761, Loss: 440.4533996582031, Neurons: 11, Grad norm: 2.227e+00\n",
      "Epoch 11762, Loss: 440.4501953125, Neurons: 11, Grad norm: 3.005e+00\n",
      "Epoch 11763, Loss: 440.4469299316406, Neurons: 11, Grad norm: 2.315e+00\n",
      "Epoch 11764, Loss: 440.4436950683594, Neurons: 11, Grad norm: 2.757e+00\n",
      "Epoch 11765, Loss: 440.44049072265625, Neurons: 11, Grad norm: 2.059e+00\n",
      "Epoch 11766, Loss: 440.4372253417969, Neurons: 11, Grad norm: 2.158e+00\n",
      "Epoch 11767, Loss: 440.4339904785156, Neurons: 11, Grad norm: 2.051e+00\n",
      "Epoch 11768, Loss: 440.43072509765625, Neurons: 11, Grad norm: 1.987e+00\n",
      "Epoch 11769, Loss: 440.42755126953125, Neurons: 11, Grad norm: 2.561e+00\n",
      "Epoch 11770, Loss: 440.4242858886719, Neurons: 11, Grad norm: 2.168e+00\n",
      "Epoch 11771, Loss: 440.4210510253906, Neurons: 11, Grad norm: 2.883e+00\n",
      "Epoch 11772, Loss: 440.4178466796875, Neurons: 11, Grad norm: 2.295e+00\n",
      "Epoch 11773, Loss: 440.41455078125, Neurons: 11, Grad norm: 2.848e+00\n",
      "Epoch 11774, Loss: 440.4112854003906, Neurons: 11, Grad norm: 2.168e+00\n",
      "Epoch 11775, Loss: 440.4080810546875, Neurons: 11, Grad norm: 2.461e+00\n",
      "Epoch 11776, Loss: 440.40478515625, Neurons: 11, Grad norm: 1.985e+00\n",
      "Epoch 11777, Loss: 440.4015808105469, Neurons: 11, Grad norm: 2.154e+00\n",
      "Epoch 11778, Loss: 440.3982849121094, Neurons: 11, Grad norm: 1.978e+00\n",
      "Epoch 11779, Loss: 440.3950500488281, Neurons: 11, Grad norm: 2.015e+00\n",
      "Epoch 11780, Loss: 440.39178466796875, Neurons: 11, Grad norm: 2.052e+00\n",
      "Epoch 11781, Loss: 440.3885803222656, Neurons: 11, Grad norm: 1.975e+00\n",
      "Epoch 11782, Loss: 440.3852844238281, Neurons: 11, Grad norm: 2.091e+00\n",
      "Epoch 11783, Loss: 440.3820495605469, Neurons: 11, Grad norm: 1.985e+00\n",
      "Epoch 11784, Loss: 440.3787841796875, Neurons: 11, Grad norm: 2.297e+00\n",
      "Epoch 11785, Loss: 440.37554931640625, Neurons: 11, Grad norm: 2.009e+00\n",
      "Epoch 11786, Loss: 440.3722839355469, Neurons: 11, Grad norm: 2.435e+00\n",
      "Epoch 11787, Loss: 440.3689880371094, Neurons: 11, Grad norm: 2.059e+00\n",
      "Epoch 11788, Loss: 440.3657531738281, Neurons: 11, Grad norm: 2.467e+00\n",
      "Epoch 11789, Loss: 440.3624267578125, Neurons: 11, Grad norm: 2.018e+00\n",
      "Epoch 11790, Loss: 440.3592529296875, Neurons: 11, Grad norm: 2.332e+00\n",
      "Epoch 11791, Loss: 440.3559875488281, Neurons: 11, Grad norm: 1.957e+00\n",
      "Epoch 11792, Loss: 440.3527526855469, Neurons: 11, Grad norm: 2.178e+00\n",
      "Epoch 11793, Loss: 440.34942626953125, Neurons: 11, Grad norm: 1.977e+00\n",
      "Epoch 11794, Loss: 440.34619140625, Neurons: 11, Grad norm: 2.214e+00\n",
      "Epoch 11795, Loss: 440.3429260253906, Neurons: 11, Grad norm: 1.971e+00\n",
      "Epoch 11796, Loss: 440.3396301269531, Neurons: 11, Grad norm: 2.273e+00\n",
      "Epoch 11797, Loss: 440.3363952636719, Neurons: 11, Grad norm: 2.000e+00\n",
      "Epoch 11798, Loss: 440.3331298828125, Neurons: 11, Grad norm: 2.363e+00\n",
      "Epoch 11799, Loss: 440.329833984375, Neurons: 11, Grad norm: 2.048e+00\n",
      "Epoch 11799, Test loss: 436.6178283691406\n",
      "Epoch 11800, Loss: 440.32659912109375, Neurons: 11, Grad norm: 2.589e+00\n",
      "Epoch 11801, Loss: 440.32330322265625, Neurons: 11, Grad norm: 2.133e+00\n",
      "Epoch 11802, Loss: 440.3199768066406, Neurons: 11, Grad norm: 2.723e+00\n",
      "Epoch 11803, Loss: 440.3167419433594, Neurons: 11, Grad norm: 2.167e+00\n",
      "Epoch 11804, Loss: 440.3134460449219, Neurons: 11, Grad norm: 2.743e+00\n",
      "Epoch 11805, Loss: 440.3101806640625, Neurons: 11, Grad norm: 2.224e+00\n",
      "Epoch 11806, Loss: 440.306884765625, Neurons: 11, Grad norm: 2.890e+00\n",
      "Epoch 11807, Loss: 440.30364990234375, Neurons: 11, Grad norm: 2.511e+00\n",
      "Epoch 11808, Loss: 440.30035400390625, Neurons: 11, Grad norm: 3.313e+00\n",
      "Epoch 11809, Loss: 440.2970275878906, Neurons: 11, Grad norm: 2.864e+00\n",
      "Epoch 11810, Loss: 440.2937927246094, Neurons: 11, Grad norm: 4.005e+00\n",
      "Epoch 11811, Loss: 440.2904968261719, Neurons: 11, Grad norm: 3.433e+00\n",
      "Epoch 11812, Loss: 440.2872009277344, Neurons: 11, Grad norm: 4.507e+00\n",
      "Epoch 11813, Loss: 440.28387451171875, Neurons: 11, Grad norm: 3.969e+00\n",
      "Epoch 11814, Loss: 440.2806396484375, Neurons: 11, Grad norm: 5.020e+00\n",
      "Epoch 11815, Loss: 440.2773742675781, Neurons: 11, Grad norm: 4.189e+00\n",
      "Epoch 11816, Loss: 440.2740783691406, Neurons: 11, Grad norm: 5.173e+00\n",
      "Epoch 11817, Loss: 440.2707824707031, Neurons: 11, Grad norm: 4.700e+00\n",
      "Epoch 11818, Loss: 440.2674865722656, Neurons: 11, Grad norm: 5.981e+00\n",
      "Epoch 11819, Loss: 440.2641906738281, Neurons: 11, Grad norm: 5.516e+00\n",
      "Epoch 11820, Loss: 440.2608947753906, Neurons: 11, Grad norm: 6.874e+00\n",
      "Epoch 11821, Loss: 440.2575988769531, Neurons: 11, Grad norm: 6.708e+00\n",
      "Epoch 11822, Loss: 440.25433349609375, Neurons: 11, Grad norm: 8.504e+00\n",
      "Epoch 11823, Loss: 440.25103759765625, Neurons: 11, Grad norm: 8.730e+00\n",
      "Epoch 11824, Loss: 440.24774169921875, Neurons: 11, Grad norm: 1.100e+01\n",
      "Epoch 11825, Loss: 440.2444763183594, Neurons: 11, Grad norm: 1.153e+01\n",
      "Epoch 11826, Loss: 440.24114990234375, Neurons: 11, Grad norm: 1.429e+01\n",
      "Epoch 11827, Loss: 440.2378845214844, Neurons: 11, Grad norm: 1.561e+01\n",
      "Epoch 11828, Loss: 440.2345275878906, Neurons: 11, Grad norm: 1.908e+01\n",
      "Epoch 11829, Loss: 440.2312316894531, Neurons: 11, Grad norm: 2.129e+01\n",
      "Epoch 11830, Loss: 440.2279357910156, Neurons: 11, Grad norm: 2.588e+01\n",
      "Epoch 11831, Loss: 440.2247009277344, Neurons: 11, Grad norm: 2.939e+01\n",
      "Epoch 11832, Loss: 440.22137451171875, Neurons: 11, Grad norm: 3.567e+01\n",
      "Epoch 11833, Loss: 440.21807861328125, Neurons: 11, Grad norm: 4.117e+01\n",
      "Epoch 11834, Loss: 440.2148742675781, Neurons: 11, Grad norm: 4.996e+01\n",
      "Epoch 11835, Loss: 440.2115783691406, Neurons: 11, Grad norm: 5.866e+01\n",
      "Epoch 11836, Loss: 440.2083740234375, Neurons: 11, Grad norm: 7.157e+01\n",
      "Epoch 11837, Loss: 440.2052307128906, Neurons: 11, Grad norm: 8.529e+01\n",
      "Epoch 11838, Loss: 440.20208740234375, Neurons: 11, Grad norm: 1.038e+02\n",
      "Epoch 11839, Loss: 440.1990966796875, Neurons: 11, Grad norm: 1.240e+02\n",
      "Epoch 11840, Loss: 440.1961975097656, Neurons: 11, Grad norm: 1.496e+02\n",
      "Epoch 11841, Loss: 440.1933898925781, Neurons: 11, Grad norm: 1.771e+02\n",
      "Epoch 11842, Loss: 440.1908874511719, Neurons: 11, Grad norm: 2.089e+02\n",
      "Epoch 11843, Loss: 440.1885986328125, Neurons: 11, Grad norm: 2.387e+02\n",
      "Epoch 11844, Loss: 440.1864929199219, Neurons: 11, Grad norm: 2.657e+02\n",
      "Epoch 11845, Loss: 440.184326171875, Neurons: 11, Grad norm: 2.792e+02\n",
      "Epoch 11846, Loss: 440.1817321777344, Neurons: 11, Grad norm: 2.750e+02\n",
      "Epoch 11847, Loss: 440.17828369140625, Neurons: 11, Grad norm: 2.435e+02\n",
      "Epoch 11848, Loss: 440.1737365722656, Neurons: 11, Grad norm: 1.873e+02\n",
      "Epoch 11849, Loss: 440.1684875488281, Neurons: 11, Grad norm: 1.095e+02\n",
      "Epoch 11849, Test loss: 436.4847106933594\n",
      "Epoch 11850, Loss: 440.16339111328125, Neurons: 11, Grad norm: 2.503e+01\n",
      "Epoch 11851, Loss: 440.1593017578125, Neurons: 11, Grad norm: 5.683e+01\n",
      "Epoch 11852, Loss: 440.1562805175781, Neurons: 11, Grad norm: 1.202e+02\n",
      "Epoch 11853, Loss: 440.154052734375, Neurons: 11, Grad norm: 1.615e+02\n",
      "Epoch 11854, Loss: 440.15179443359375, Neurons: 11, Grad norm: 1.722e+02\n",
      "Epoch 11855, Loss: 440.14898681640625, Neurons: 11, Grad norm: 1.555e+02\n",
      "Epoch 11856, Loss: 440.14532470703125, Neurons: 11, Grad norm: 1.124e+02\n",
      "Epoch 11857, Loss: 440.1412353515625, Neurons: 11, Grad norm: 5.569e+01\n",
      "Epoch 11858, Loss: 440.1372985839844, Neurons: 11, Grad norm: 7.032e+00\n",
      "Epoch 11859, Loss: 440.1338806152344, Neurons: 11, Grad norm: 6.011e+01\n",
      "Epoch 11860, Loss: 440.1309814453125, Neurons: 11, Grad norm: 9.941e+01\n",
      "Epoch 11861, Loss: 440.1283874511719, Neurons: 11, Grad norm: 1.157e+02\n",
      "Epoch 11862, Loss: 440.12548828125, Neurons: 11, Grad norm: 1.118e+02\n",
      "Epoch 11863, Loss: 440.1222839355469, Neurons: 11, Grad norm: 8.660e+01\n",
      "Epoch 11864, Loss: 440.1186828613281, Neurons: 11, Grad norm: 5.001e+01\n",
      "Epoch 11865, Loss: 440.1150817871094, Neurons: 11, Grad norm: 6.593e+00\n",
      "Epoch 11866, Loss: 440.1117248535156, Neurons: 11, Grad norm: 3.283e+01\n",
      "Epoch 11867, Loss: 440.10870361328125, Neurons: 11, Grad norm: 6.396e+01\n",
      "Epoch 11868, Loss: 440.10577392578125, Neurons: 11, Grad norm: 7.908e+01\n",
      "Epoch 11869, Loss: 440.102783203125, Neurons: 11, Grad norm: 8.046e+01\n",
      "Epoch 11870, Loss: 440.0997009277344, Neurons: 11, Grad norm: 6.581e+01\n",
      "Epoch 11871, Loss: 440.0963439941406, Neurons: 11, Grad norm: 4.282e+01\n",
      "Epoch 11872, Loss: 440.0929870605469, Neurons: 11, Grad norm: 1.307e+01\n",
      "Epoch 11873, Loss: 440.0896911621094, Neurons: 11, Grad norm: 1.472e+01\n",
      "Epoch 11874, Loss: 440.08648681640625, Neurons: 11, Grad norm: 3.871e+01\n",
      "Epoch 11875, Loss: 440.08349609375, Neurons: 11, Grad norm: 5.219e+01\n",
      "Epoch 11876, Loss: 440.0804443359375, Neurons: 11, Grad norm: 5.728e+01\n",
      "Epoch 11877, Loss: 440.0773010253906, Neurons: 11, Grad norm: 5.071e+01\n",
      "Epoch 11878, Loss: 440.0740966796875, Neurons: 11, Grad norm: 3.806e+01\n",
      "Epoch 11879, Loss: 440.07080078125, Neurons: 11, Grad norm: 1.895e+01\n",
      "Epoch 11880, Loss: 440.0675964355469, Neurons: 11, Grad norm: 1.988e+00\n",
      "Epoch 11881, Loss: 440.06439208984375, Neurons: 11, Grad norm: 1.827e+01\n",
      "Epoch 11882, Loss: 440.0611877441406, Neurons: 11, Grad norm: 3.026e+01\n",
      "Epoch 11883, Loss: 440.0581359863281, Neurons: 11, Grad norm: 3.817e+01\n",
      "Epoch 11884, Loss: 440.05499267578125, Neurons: 11, Grad norm: 3.771e+01\n",
      "Epoch 11885, Loss: 440.0517883300781, Neurons: 11, Grad norm: 3.320e+01\n",
      "Epoch 11886, Loss: 440.04864501953125, Neurons: 11, Grad norm: 2.249e+01\n",
      "Epoch 11887, Loss: 440.0453796386719, Neurons: 11, Grad norm: 1.125e+01\n",
      "Epoch 11888, Loss: 440.04217529296875, Neurons: 11, Grad norm: 3.200e+00\n",
      "Epoch 11889, Loss: 440.0390319824219, Neurons: 11, Grad norm: 1.289e+01\n",
      "Epoch 11890, Loss: 440.035888671875, Neurons: 11, Grad norm: 2.196e+01\n",
      "Epoch 11891, Loss: 440.0327453613281, Neurons: 11, Grad norm: 2.532e+01\n",
      "Epoch 11892, Loss: 440.02960205078125, Neurons: 11, Grad norm: 2.651e+01\n",
      "Epoch 11893, Loss: 440.0263977050781, Neurons: 11, Grad norm: 2.226e+01\n",
      "Epoch 11894, Loss: 440.0232238769531, Neurons: 11, Grad norm: 1.713e+01\n",
      "Epoch 11895, Loss: 440.0199890136719, Neurons: 11, Grad norm: 8.695e+00\n",
      "Epoch 11896, Loss: 440.01678466796875, Neurons: 11, Grad norm: 2.337e+00\n",
      "Epoch 11897, Loss: 440.0136413574219, Neurons: 11, Grad norm: 7.189e+00\n",
      "Epoch 11898, Loss: 440.010498046875, Neurons: 11, Grad norm: 1.198e+01\n",
      "Epoch 11899, Loss: 440.0072937011719, Neurons: 11, Grad norm: 1.680e+01\n",
      "Epoch 11899, Test loss: 436.30230712890625\n",
      "Epoch 11900, Loss: 440.00408935546875, Neurons: 11, Grad norm: 1.718e+01\n",
      "Epoch 11901, Loss: 440.0009765625, Neurons: 11, Grad norm: 1.727e+01\n",
      "Epoch 11902, Loss: 439.997802734375, Neurons: 11, Grad norm: 1.384e+01\n",
      "Epoch 11903, Loss: 439.9945983886719, Neurons: 11, Grad norm: 1.093e+01\n",
      "Epoch 11904, Loss: 439.99139404296875, Neurons: 11, Grad norm: 5.732e+00\n",
      "Epoch 11905, Loss: 439.9881896972656, Neurons: 11, Grad norm: 2.624e+00\n",
      "Epoch 11906, Loss: 439.9849853515625, Neurons: 11, Grad norm: 3.722e+00\n",
      "Epoch 11907, Loss: 439.9817810058594, Neurons: 11, Grad norm: 5.932e+00\n",
      "Epoch 11908, Loss: 439.97857666015625, Neurons: 11, Grad norm: 9.333e+00\n",
      "Epoch 11909, Loss: 439.9754333496094, Neurons: 11, Grad norm: 9.664e+00\n",
      "Epoch 11910, Loss: 439.97222900390625, Neurons: 11, Grad norm: 1.078e+01\n",
      "Epoch 11911, Loss: 439.9690856933594, Neurons: 11, Grad norm: 8.958e+00\n",
      "Epoch 11912, Loss: 439.96588134765625, Neurons: 11, Grad norm: 8.033e+00\n",
      "Epoch 11913, Loss: 439.9626770019531, Neurons: 11, Grad norm: 4.989e+00\n",
      "Epoch 11914, Loss: 439.9595031738281, Neurons: 11, Grad norm: 3.594e+00\n",
      "Epoch 11915, Loss: 439.956298828125, Neurons: 11, Grad norm: 1.956e+00\n",
      "Epoch 11916, Loss: 439.9530944824219, Neurons: 11, Grad norm: 2.832e+00\n",
      "Epoch 11917, Loss: 439.94989013671875, Neurons: 11, Grad norm: 5.580e+00\n",
      "Epoch 11918, Loss: 439.9466857910156, Neurons: 11, Grad norm: 6.006e+00\n",
      "Epoch 11919, Loss: 439.94354248046875, Neurons: 11, Grad norm: 7.735e+00\n",
      "Epoch 11920, Loss: 439.9402770996094, Neurons: 11, Grad norm: 7.099e+00\n",
      "Epoch 11921, Loss: 439.9371032714844, Neurons: 11, Grad norm: 7.750e+00\n",
      "Epoch 11922, Loss: 439.93389892578125, Neurons: 11, Grad norm: 6.386e+00\n",
      "Epoch 11923, Loss: 439.9306945800781, Neurons: 11, Grad norm: 6.255e+00\n",
      "Epoch 11924, Loss: 439.92755126953125, Neurons: 11, Grad norm: 4.277e+00\n",
      "Epoch 11925, Loss: 439.9242858886719, Neurons: 11, Grad norm: 3.868e+00\n",
      "Epoch 11926, Loss: 439.92108154296875, Neurons: 11, Grad norm: 2.209e+00\n",
      "Epoch 11927, Loss: 439.9178771972656, Neurons: 11, Grad norm: 2.171e+00\n",
      "Epoch 11928, Loss: 439.9147033691406, Neurons: 11, Grad norm: 2.312e+00\n",
      "Epoch 11929, Loss: 439.9114990234375, Neurons: 11, Grad norm: 2.292e+00\n",
      "Epoch 11930, Loss: 439.9082336425781, Neurons: 11, Grad norm: 3.394e+00\n",
      "Epoch 11931, Loss: 439.905029296875, Neurons: 11, Grad norm: 3.268e+00\n",
      "Epoch 11932, Loss: 439.90179443359375, Neurons: 11, Grad norm: 4.195e+00\n",
      "Epoch 11933, Loss: 439.8985900878906, Neurons: 11, Grad norm: 3.580e+00\n",
      "Epoch 11934, Loss: 439.8953857421875, Neurons: 11, Grad norm: 4.658e+00\n",
      "Epoch 11935, Loss: 439.8921813964844, Neurons: 11, Grad norm: 3.930e+00\n",
      "Epoch 11936, Loss: 439.88897705078125, Neurons: 11, Grad norm: 4.963e+00\n",
      "Epoch 11937, Loss: 439.8857421875, Neurons: 11, Grad norm: 3.896e+00\n",
      "Epoch 11938, Loss: 439.8824768066406, Neurons: 11, Grad norm: 4.469e+00\n",
      "Epoch 11939, Loss: 439.8793029785156, Neurons: 11, Grad norm: 3.354e+00\n",
      "Epoch 11940, Loss: 439.8760986328125, Neurons: 11, Grad norm: 3.615e+00\n",
      "Epoch 11941, Loss: 439.8728942871094, Neurons: 11, Grad norm: 2.754e+00\n",
      "Epoch 11942, Loss: 439.86968994140625, Neurons: 11, Grad norm: 3.065e+00\n",
      "Epoch 11943, Loss: 439.86639404296875, Neurons: 11, Grad norm: 2.067e+00\n",
      "Epoch 11944, Loss: 439.8631896972656, Neurons: 11, Grad norm: 2.300e+00\n",
      "Epoch 11945, Loss: 439.8599853515625, Neurons: 11, Grad norm: 1.964e+00\n",
      "Epoch 11946, Loss: 439.8567810058594, Neurons: 11, Grad norm: 1.931e+00\n",
      "Epoch 11947, Loss: 439.8534851074219, Neurons: 11, Grad norm: 2.302e+00\n",
      "Epoch 11948, Loss: 439.85028076171875, Neurons: 11, Grad norm: 2.157e+00\n",
      "Epoch 11949, Loss: 439.8470764160156, Neurons: 11, Grad norm: 2.939e+00\n",
      "Epoch 11949, Test loss: 436.1506652832031\n",
      "Epoch 11950, Loss: 439.8438415527344, Neurons: 11, Grad norm: 2.588e+00\n",
      "Epoch 11951, Loss: 439.840576171875, Neurons: 11, Grad norm: 3.449e+00\n",
      "Epoch 11952, Loss: 439.83740234375, Neurons: 11, Grad norm: 2.919e+00\n",
      "Epoch 11953, Loss: 439.8340759277344, Neurons: 11, Grad norm: 4.199e+00\n",
      "Epoch 11954, Loss: 439.8309020996094, Neurons: 11, Grad norm: 3.579e+00\n",
      "Epoch 11955, Loss: 439.82769775390625, Neurons: 11, Grad norm: 4.843e+00\n",
      "Epoch 11956, Loss: 439.8244323730469, Neurons: 11, Grad norm: 4.644e+00\n",
      "Epoch 11957, Loss: 439.8211975097656, Neurons: 11, Grad norm: 5.897e+00\n",
      "Epoch 11958, Loss: 439.81793212890625, Neurons: 11, Grad norm: 5.656e+00\n",
      "Epoch 11959, Loss: 439.814697265625, Neurons: 11, Grad norm: 7.067e+00\n",
      "Epoch 11960, Loss: 439.8114929199219, Neurons: 11, Grad norm: 6.840e+00\n",
      "Epoch 11961, Loss: 439.8081970214844, Neurons: 11, Grad norm: 8.476e+00\n",
      "Epoch 11962, Loss: 439.80499267578125, Neurons: 11, Grad norm: 8.067e+00\n",
      "Epoch 11963, Loss: 439.8017272949219, Neurons: 11, Grad norm: 9.956e+00\n",
      "Epoch 11964, Loss: 439.7984924316406, Neurons: 11, Grad norm: 1.003e+01\n",
      "Epoch 11965, Loss: 439.7952880859375, Neurons: 11, Grad norm: 1.210e+01\n",
      "Epoch 11966, Loss: 439.7919921875, Neurons: 11, Grad norm: 1.272e+01\n",
      "Epoch 11967, Loss: 439.7887268066406, Neurons: 11, Grad norm: 1.523e+01\n",
      "Epoch 11968, Loss: 439.7854919433594, Neurons: 11, Grad norm: 1.663e+01\n",
      "Epoch 11969, Loss: 439.78228759765625, Neurons: 11, Grad norm: 2.033e+01\n",
      "Epoch 11970, Loss: 439.77899169921875, Neurons: 11, Grad norm: 2.281e+01\n",
      "Epoch 11971, Loss: 439.7757873535156, Neurons: 11, Grad norm: 2.806e+01\n",
      "Epoch 11972, Loss: 439.7725524902344, Neurons: 11, Grad norm: 3.219e+01\n",
      "Epoch 11973, Loss: 439.769287109375, Neurons: 11, Grad norm: 3.937e+01\n",
      "Epoch 11974, Loss: 439.7660827636719, Neurons: 11, Grad norm: 4.583e+01\n",
      "Epoch 11975, Loss: 439.76287841796875, Neurons: 11, Grad norm: 5.548e+01\n",
      "Epoch 11976, Loss: 439.7596740722656, Neurons: 11, Grad norm: 6.531e+01\n",
      "Epoch 11977, Loss: 439.756591796875, Neurons: 11, Grad norm: 7.924e+01\n",
      "Epoch 11978, Loss: 439.75347900390625, Neurons: 11, Grad norm: 9.410e+01\n",
      "Epoch 11979, Loss: 439.7503967285156, Neurons: 11, Grad norm: 1.139e+02\n",
      "Epoch 11980, Loss: 439.74749755859375, Neurons: 11, Grad norm: 1.353e+02\n",
      "Epoch 11981, Loss: 439.74468994140625, Neurons: 11, Grad norm: 1.623e+02\n",
      "Epoch 11982, Loss: 439.7420959472656, Neurons: 11, Grad norm: 1.901e+02\n",
      "Epoch 11983, Loss: 439.73968505859375, Neurons: 11, Grad norm: 2.212e+02\n",
      "Epoch 11984, Loss: 439.73748779296875, Neurons: 11, Grad norm: 2.484e+02\n",
      "Epoch 11985, Loss: 439.7353515625, Neurons: 11, Grad norm: 2.702e+02\n",
      "Epoch 11986, Loss: 439.7330017089844, Neurons: 11, Grad norm: 2.764e+02\n",
      "Epoch 11987, Loss: 439.7301330566406, Neurons: 11, Grad norm: 2.631e+02\n",
      "Epoch 11988, Loss: 439.7263488769531, Neurons: 11, Grad norm: 2.229e+02\n",
      "Epoch 11989, Loss: 439.7215881347656, Neurons: 11, Grad norm: 1.611e+02\n",
      "Epoch 11990, Loss: 439.71649169921875, Neurons: 11, Grad norm: 8.184e+01\n",
      "Epoch 11991, Loss: 439.71185302734375, Neurons: 11, Grad norm: 2.123e+00\n",
      "Epoch 11992, Loss: 439.7081298828125, Neurons: 11, Grad norm: 7.415e+01\n",
      "Epoch 11993, Loss: 439.7054443359375, Neurons: 11, Grad norm: 1.295e+02\n",
      "Epoch 11994, Loss: 439.7032775878906, Neurons: 11, Grad norm: 1.629e+02\n",
      "Epoch 11995, Loss: 439.7008972167969, Neurons: 11, Grad norm: 1.669e+02\n",
      "Epoch 11996, Loss: 439.6978759765625, Neurons: 11, Grad norm: 1.460e+02\n",
      "Epoch 11997, Loss: 439.6941833496094, Neurons: 11, Grad norm: 1.018e+02\n",
      "Epoch 11998, Loss: 439.69024658203125, Neurons: 11, Grad norm: 4.640e+01\n",
      "Epoch 11999, Loss: 439.6864318847656, Neurons: 11, Grad norm: 1.316e+01\n",
      "Epoch 11999, Test loss: 435.9927673339844\n",
      "Epoch 12000, Loss: 439.6831970214844, Neurons: 11, Grad norm: 6.234e+01\n",
      "Epoch 12001, Loss: 439.6803894042969, Neurons: 11, Grad norm: 9.823e+01\n",
      "Epoch 12002, Loss: 439.6777038574219, Neurons: 11, Grad norm: 1.125e+02\n",
      "Epoch 12003, Loss: 439.6748352050781, Neurons: 11, Grad norm: 1.082e+02\n",
      "Epoch 12004, Loss: 439.671630859375, Neurons: 11, Grad norm: 8.439e+01\n",
      "Epoch 12005, Loss: 439.6681823730469, Neurons: 11, Grad norm: 5.034e+01\n",
      "Epoch 12006, Loss: 439.6647033691406, Neurons: 11, Grad norm: 9.505e+00\n",
      "Epoch 12007, Loss: 439.661376953125, Neurons: 11, Grad norm: 2.776e+01\n",
      "Epoch 12008, Loss: 439.6582946777344, Neurons: 11, Grad norm: 5.782e+01\n",
      "Epoch 12009, Loss: 439.6553955078125, Neurons: 11, Grad norm: 7.353e+01\n",
      "Epoch 12010, Loss: 439.6524353027344, Neurons: 11, Grad norm: 7.734e+01\n",
      "Epoch 12011, Loss: 439.6493835449219, Neurons: 11, Grad norm: 6.610e+01\n",
      "Epoch 12012, Loss: 439.64617919921875, Neurons: 11, Grad norm: 4.695e+01\n",
      "Epoch 12013, Loss: 439.64288330078125, Neurons: 11, Grad norm: 2.039e+01\n",
      "Epoch 12014, Loss: 439.63958740234375, Neurons: 11, Grad norm: 5.761e+00\n",
      "Epoch 12015, Loss: 439.636474609375, Neurons: 11, Grad norm: 2.941e+01\n",
      "Epoch 12016, Loss: 439.6333923339844, Neurons: 11, Grad norm: 4.473e+01\n",
      "Epoch 12017, Loss: 439.6304016113281, Neurons: 11, Grad norm: 5.307e+01\n",
      "Epoch 12018, Loss: 439.62738037109375, Neurons: 11, Grad norm: 5.049e+01\n",
      "Epoch 12019, Loss: 439.6241760253906, Neurons: 11, Grad norm: 4.189e+01\n",
      "Epoch 12020, Loss: 439.62103271484375, Neurons: 11, Grad norm: 2.593e+01\n",
      "Epoch 12021, Loss: 439.6178283691406, Neurons: 11, Grad norm: 9.661e+00\n",
      "Epoch 12022, Loss: 439.61468505859375, Neurons: 11, Grad norm: 8.825e+00\n",
      "Epoch 12023, Loss: 439.6115417480469, Neurons: 11, Grad norm: 2.201e+01\n",
      "Epoch 12024, Loss: 439.6084899902344, Neurons: 11, Grad norm: 3.249e+01\n",
      "Epoch 12025, Loss: 439.6053771972656, Neurons: 11, Grad norm: 3.595e+01\n",
      "Epoch 12026, Loss: 439.602294921875, Neurons: 11, Grad norm: 3.559e+01\n",
      "Epoch 12027, Loss: 439.5991516113281, Neurons: 11, Grad norm: 2.874e+01\n",
      "Epoch 12028, Loss: 439.5959777832031, Neurons: 11, Grad norm: 2.042e+01\n",
      "Epoch 12029, Loss: 439.5928955078125, Neurons: 11, Grad norm: 8.243e+00\n",
      "Epoch 12030, Loss: 439.5896911621094, Neurons: 11, Grad norm: 2.890e+00\n",
      "Epoch 12031, Loss: 439.5865783691406, Neurons: 11, Grad norm: 1.306e+01\n",
      "Epoch 12032, Loss: 439.58349609375, Neurons: 11, Grad norm: 1.937e+01\n",
      "Epoch 12033, Loss: 439.58038330078125, Neurons: 11, Grad norm: 2.427e+01\n",
      "Epoch 12034, Loss: 439.5771789550781, Neurons: 11, Grad norm: 2.440e+01\n",
      "Epoch 12035, Loss: 439.5740966796875, Neurons: 11, Grad norm: 2.317e+01\n",
      "Epoch 12036, Loss: 439.57098388671875, Neurons: 11, Grad norm: 1.751e+01\n",
      "Epoch 12037, Loss: 439.5678405761719, Neurons: 11, Grad norm: 1.220e+01\n",
      "Epoch 12038, Loss: 439.564697265625, Neurons: 11, Grad norm: 4.396e+00\n",
      "Epoch 12039, Loss: 439.5615539550781, Neurons: 11, Grad norm: 2.754e+00\n",
      "Epoch 12040, Loss: 439.5583801269531, Neurons: 11, Grad norm: 9.028e+00\n",
      "Epoch 12041, Loss: 439.5552978515625, Neurons: 11, Grad norm: 1.238e+01\n",
      "Epoch 12042, Loss: 439.55218505859375, Neurons: 11, Grad norm: 1.568e+01\n",
      "Epoch 12043, Loss: 439.5489807128906, Neurons: 11, Grad norm: 1.546e+01\n",
      "Epoch 12044, Loss: 439.5458984375, Neurons: 11, Grad norm: 1.518e+01\n",
      "Epoch 12045, Loss: 439.5426940917969, Neurons: 11, Grad norm: 1.176e+01\n",
      "Epoch 12046, Loss: 439.5395812988281, Neurons: 11, Grad norm: 9.527e+00\n",
      "Epoch 12047, Loss: 439.536376953125, Neurons: 11, Grad norm: 4.800e+00\n",
      "Epoch 12048, Loss: 439.5332946777344, Neurons: 11, Grad norm: 2.406e+00\n",
      "Epoch 12049, Loss: 439.5301818847656, Neurons: 11, Grad norm: 3.702e+00\n",
      "Epoch 12049, Test loss: 435.84405517578125\n",
      "Epoch 12050, Loss: 439.5269775390625, Neurons: 11, Grad norm: 5.969e+00\n",
      "Epoch 12051, Loss: 439.5238342285156, Neurons: 11, Grad norm: 9.040e+00\n",
      "Epoch 12052, Loss: 439.52069091796875, Neurons: 11, Grad norm: 9.644e+00\n",
      "Epoch 12053, Loss: 439.5175476074219, Neurons: 11, Grad norm: 1.101e+01\n",
      "Epoch 12054, Loss: 439.5143737792969, Neurons: 11, Grad norm: 9.539e+00\n",
      "Epoch 12055, Loss: 439.51129150390625, Neurons: 11, Grad norm: 9.558e+00\n",
      "Epoch 12056, Loss: 439.5080871582031, Neurons: 11, Grad norm: 6.890e+00\n",
      "Epoch 12057, Loss: 439.5049743652344, Neurons: 11, Grad norm: 5.847e+00\n",
      "Epoch 12058, Loss: 439.5018310546875, Neurons: 11, Grad norm: 3.114e+00\n",
      "Epoch 12059, Loss: 439.4986877441406, Neurons: 11, Grad norm: 2.180e+00\n",
      "Epoch 12060, Loss: 439.4954833984375, Neurons: 11, Grad norm: 2.665e+00\n",
      "Epoch 12061, Loss: 439.4924011230469, Neurons: 11, Grad norm: 3.364e+00\n",
      "Epoch 12062, Loss: 439.48919677734375, Neurons: 11, Grad norm: 5.527e+00\n",
      "Epoch 12063, Loss: 439.4859924316406, Neurons: 11, Grad norm: 5.516e+00\n",
      "Epoch 12064, Loss: 439.4828796386719, Neurons: 11, Grad norm: 6.764e+00\n",
      "Epoch 12065, Loss: 439.479736328125, Neurons: 11, Grad norm: 5.989e+00\n",
      "Epoch 12066, Loss: 439.4765930175781, Neurons: 11, Grad norm: 6.926e+00\n",
      "Epoch 12067, Loss: 439.473388671875, Neurons: 11, Grad norm: 5.641e+00\n",
      "Epoch 12068, Loss: 439.4702453613281, Neurons: 11, Grad norm: 5.887e+00\n",
      "Epoch 12069, Loss: 439.46710205078125, Neurons: 11, Grad norm: 4.388e+00\n",
      "Epoch 12070, Loss: 439.4638977050781, Neurons: 11, Grad norm: 4.252e+00\n",
      "Epoch 12071, Loss: 439.4607238769531, Neurons: 11, Grad norm: 2.734e+00\n",
      "Epoch 12072, Loss: 439.45758056640625, Neurons: 11, Grad norm: 2.871e+00\n",
      "Epoch 12073, Loss: 439.4543762207031, Neurons: 11, Grad norm: 1.956e+00\n",
      "Epoch 12074, Loss: 439.45123291015625, Neurons: 11, Grad norm: 2.026e+00\n",
      "Epoch 12075, Loss: 439.4480895996094, Neurons: 11, Grad norm: 1.973e+00\n",
      "Epoch 12076, Loss: 439.4449462890625, Neurons: 11, Grad norm: 1.891e+00\n",
      "Epoch 12077, Loss: 439.4417419433594, Neurons: 11, Grad norm: 2.289e+00\n",
      "Epoch 12078, Loss: 439.4385986328125, Neurons: 11, Grad norm: 2.025e+00\n",
      "Epoch 12079, Loss: 439.4353942871094, Neurons: 11, Grad norm: 2.694e+00\n",
      "Epoch 12080, Loss: 439.43218994140625, Neurons: 11, Grad norm: 2.307e+00\n",
      "Epoch 12081, Loss: 439.4290466308594, Neurons: 11, Grad norm: 3.347e+00\n",
      "Epoch 12082, Loss: 439.4259033203125, Neurons: 11, Grad norm: 2.796e+00\n",
      "Epoch 12083, Loss: 439.4226379394531, Neurons: 11, Grad norm: 3.758e+00\n",
      "Epoch 12084, Loss: 439.41949462890625, Neurons: 11, Grad norm: 3.190e+00\n",
      "Epoch 12085, Loss: 439.4162902832031, Neurons: 11, Grad norm: 3.799e+00\n",
      "Epoch 12086, Loss: 439.41314697265625, Neurons: 11, Grad norm: 3.171e+00\n",
      "Epoch 12087, Loss: 439.4099426269531, Neurons: 11, Grad norm: 4.216e+00\n",
      "Epoch 12088, Loss: 439.40679931640625, Neurons: 11, Grad norm: 3.389e+00\n",
      "Epoch 12089, Loss: 439.4035949707031, Neurons: 11, Grad norm: 4.403e+00\n",
      "Epoch 12090, Loss: 439.40045166015625, Neurons: 11, Grad norm: 3.659e+00\n",
      "Epoch 12091, Loss: 439.3972473144531, Neurons: 11, Grad norm: 4.564e+00\n",
      "Epoch 12092, Loss: 439.39404296875, Neurons: 11, Grad norm: 4.194e+00\n",
      "Epoch 12093, Loss: 439.3908386230469, Neurons: 11, Grad norm: 5.445e+00\n",
      "Epoch 12094, Loss: 439.38763427734375, Neurons: 11, Grad norm: 5.019e+00\n",
      "Epoch 12095, Loss: 439.3844909667969, Neurons: 11, Grad norm: 6.293e+00\n",
      "Epoch 12096, Loss: 439.38128662109375, Neurons: 11, Grad norm: 5.870e+00\n",
      "Epoch 12097, Loss: 439.3780822753906, Neurons: 11, Grad norm: 7.360e+00\n",
      "Epoch 12098, Loss: 439.3748779296875, Neurons: 11, Grad norm: 7.100e+00\n",
      "Epoch 12099, Loss: 439.3717041015625, Neurons: 11, Grad norm: 8.690e+00\n",
      "Epoch 12099, Test loss: 435.6895751953125\n",
      "Epoch 12100, Loss: 439.3684997558594, Neurons: 11, Grad norm: 8.540e+00\n",
      "Epoch 12101, Loss: 439.36529541015625, Neurons: 11, Grad norm: 1.017e+01\n",
      "Epoch 12102, Loss: 439.3620910644531, Neurons: 11, Grad norm: 1.024e+01\n",
      "Epoch 12103, Loss: 439.35888671875, Neurons: 11, Grad norm: 1.216e+01\n",
      "Epoch 12104, Loss: 439.3556823730469, Neurons: 11, Grad norm: 1.266e+01\n",
      "Epoch 12105, Loss: 439.3525390625, Neurons: 11, Grad norm: 1.562e+01\n",
      "Epoch 12106, Loss: 439.3492736816406, Neurons: 11, Grad norm: 1.687e+01\n",
      "Epoch 12107, Loss: 439.3460998535156, Neurons: 11, Grad norm: 2.050e+01\n",
      "Epoch 12108, Loss: 439.3428955078125, Neurons: 11, Grad norm: 2.304e+01\n",
      "Epoch 12109, Loss: 439.3397521972656, Neurons: 11, Grad norm: 2.816e+01\n",
      "Epoch 12110, Loss: 439.3365478515625, Neurons: 11, Grad norm: 3.255e+01\n",
      "Epoch 12111, Loss: 439.3333435058594, Neurons: 11, Grad norm: 3.966e+01\n",
      "Epoch 12112, Loss: 439.3302001953125, Neurons: 11, Grad norm: 4.632e+01\n",
      "Epoch 12113, Loss: 439.3270263671875, Neurons: 11, Grad norm: 5.675e+01\n",
      "Epoch 12114, Loss: 439.3238830566406, Neurons: 11, Grad norm: 6.729e+01\n",
      "Epoch 12115, Loss: 439.32080078125, Neurons: 11, Grad norm: 8.223e+01\n",
      "Epoch 12116, Loss: 439.3177490234375, Neurons: 11, Grad norm: 9.837e+01\n",
      "Epoch 12117, Loss: 439.3147888183594, Neurons: 11, Grad norm: 1.200e+02\n",
      "Epoch 12118, Loss: 439.3119812011719, Neurons: 11, Grad norm: 1.438e+02\n",
      "Epoch 12119, Loss: 439.3092956542969, Neurons: 11, Grad norm: 1.732e+02\n",
      "Epoch 12120, Loss: 439.30682373046875, Neurons: 11, Grad norm: 2.039e+02\n",
      "Epoch 12121, Loss: 439.3045959472656, Neurons: 11, Grad norm: 2.373e+02\n",
      "Epoch 12122, Loss: 439.3025817871094, Neurons: 11, Grad norm: 2.660e+02\n",
      "Epoch 12123, Loss: 439.30059814453125, Neurons: 11, Grad norm: 2.876e+02\n",
      "Epoch 12124, Loss: 439.29840087890625, Neurons: 11, Grad norm: 2.899e+02\n",
      "Epoch 12125, Loss: 439.2953796386719, Neurons: 11, Grad norm: 2.694e+02\n",
      "Epoch 12126, Loss: 439.2912902832031, Neurons: 11, Grad norm: 2.188e+02\n",
      "Epoch 12127, Loss: 439.2862243652344, Neurons: 11, Grad norm: 1.455e+02\n",
      "Epoch 12128, Loss: 439.2809753417969, Neurons: 11, Grad norm: 5.666e+01\n",
      "Epoch 12129, Loss: 439.2764892578125, Neurons: 11, Grad norm: 3.037e+01\n",
      "Epoch 12130, Loss: 439.273193359375, Neurons: 11, Grad norm: 1.058e+02\n",
      "Epoch 12131, Loss: 439.27099609375, Neurons: 11, Grad norm: 1.563e+02\n",
      "Epoch 12132, Loss: 439.2689514160156, Neurons: 11, Grad norm: 1.798e+02\n",
      "Epoch 12133, Loss: 439.2664794921875, Neurons: 11, Grad norm: 1.700e+02\n",
      "Epoch 12134, Loss: 439.26318359375, Neurons: 11, Grad norm: 1.342e+02\n",
      "Epoch 12135, Loss: 439.25927734375, Neurons: 11, Grad norm: 7.634e+01\n",
      "Epoch 12136, Loss: 439.25518798828125, Neurons: 11, Grad norm: 1.241e+01\n",
      "Epoch 12137, Loss: 439.2516784667969, Neurons: 11, Grad norm: 4.938e+01\n",
      "Epoch 12138, Loss: 439.24884033203125, Neurons: 11, Grad norm: 9.471e+01\n",
      "Epoch 12139, Loss: 439.24627685546875, Neurons: 11, Grad norm: 1.203e+02\n",
      "Epoch 12140, Loss: 439.2436828613281, Neurons: 11, Grad norm: 1.204e+02\n",
      "Epoch 12141, Loss: 439.2406921386719, Neurons: 11, Grad norm: 1.003e+02\n",
      "Epoch 12142, Loss: 439.2371826171875, Neurons: 11, Grad norm: 6.183e+01\n",
      "Epoch 12143, Loss: 439.23370361328125, Neurons: 11, Grad norm: 1.776e+01\n",
      "Epoch 12144, Loss: 439.2303466796875, Neurons: 11, Grad norm: 2.717e+01\n",
      "Epoch 12145, Loss: 439.2273254394531, Neurons: 11, Grad norm: 6.099e+01\n",
      "Epoch 12146, Loss: 439.22454833984375, Neurons: 11, Grad norm: 8.210e+01\n",
      "Epoch 12147, Loss: 439.2216796875, Neurons: 11, Grad norm: 8.485e+01\n",
      "Epoch 12148, Loss: 439.21868896484375, Neurons: 11, Grad norm: 7.357e+01\n",
      "Epoch 12149, Loss: 439.2154846191406, Neurons: 11, Grad norm: 4.859e+01\n",
      "Epoch 12149, Test loss: 435.5510559082031\n",
      "Epoch 12150, Loss: 439.2122497558594, Neurons: 11, Grad norm: 1.912e+01\n",
      "Epoch 12151, Loss: 439.208984375, Neurons: 11, Grad norm: 1.295e+01\n",
      "Epoch 12152, Loss: 439.20599365234375, Neurons: 11, Grad norm: 3.733e+01\n",
      "Epoch 12153, Loss: 439.2030029296875, Neurons: 11, Grad norm: 5.487e+01\n",
      "Epoch 12154, Loss: 439.2001037597656, Neurons: 11, Grad norm: 5.940e+01\n",
      "Epoch 12155, Loss: 439.19708251953125, Neurons: 11, Grad norm: 5.465e+01\n",
      "Epoch 12156, Loss: 439.1940002441406, Neurons: 11, Grad norm: 3.976e+01\n",
      "Epoch 12157, Loss: 439.1907958984375, Neurons: 11, Grad norm: 2.111e+01\n",
      "Epoch 12158, Loss: 439.18768310546875, Neurons: 11, Grad norm: 2.218e+00\n",
      "Epoch 12159, Loss: 439.1846008300781, Neurons: 11, Grad norm: 1.918e+01\n",
      "Epoch 12160, Loss: 439.18157958984375, Neurons: 11, Grad norm: 3.405e+01\n",
      "Epoch 12161, Loss: 439.17852783203125, Neurons: 11, Grad norm: 4.003e+01\n",
      "Epoch 12162, Loss: 439.17547607421875, Neurons: 11, Grad norm: 4.067e+01\n",
      "Epoch 12163, Loss: 439.1724853515625, Neurons: 11, Grad norm: 3.309e+01\n",
      "Epoch 12164, Loss: 439.1694030761719, Neurons: 11, Grad norm: 2.253e+01\n",
      "Epoch 12165, Loss: 439.1662902832031, Neurons: 11, Grad norm: 8.078e+00\n",
      "Epoch 12166, Loss: 439.1631774902344, Neurons: 11, Grad norm: 5.270e+00\n",
      "Epoch 12167, Loss: 439.16009521484375, Neurons: 11, Grad norm: 1.730e+01\n",
      "Epoch 12168, Loss: 439.15704345703125, Neurons: 11, Grad norm: 2.366e+01\n",
      "Epoch 12169, Loss: 439.15399169921875, Neurons: 11, Grad norm: 2.795e+01\n",
      "Epoch 12170, Loss: 439.1510009765625, Neurons: 11, Grad norm: 2.620e+01\n",
      "Epoch 12171, Loss: 439.14788818359375, Neurons: 11, Grad norm: 2.274e+01\n",
      "Epoch 12172, Loss: 439.144775390625, Neurons: 11, Grad norm: 1.502e+01\n",
      "Epoch 12173, Loss: 439.1417541503906, Neurons: 11, Grad norm: 7.899e+00\n",
      "Epoch 12174, Loss: 439.1386413574219, Neurons: 11, Grad norm: 2.299e+00\n",
      "Epoch 12175, Loss: 439.1355895996094, Neurons: 11, Grad norm: 8.077e+00\n",
      "Epoch 12176, Loss: 439.1324768066406, Neurons: 11, Grad norm: 1.472e+01\n",
      "Epoch 12177, Loss: 439.12939453125, Neurons: 11, Grad norm: 1.726e+01\n",
      "Epoch 12178, Loss: 439.12640380859375, Neurons: 11, Grad norm: 1.936e+01\n",
      "Epoch 12179, Loss: 439.123291015625, Neurons: 11, Grad norm: 1.692e+01\n",
      "Epoch 12180, Loss: 439.1202392578125, Neurons: 11, Grad norm: 1.442e+01\n",
      "Epoch 12181, Loss: 439.11712646484375, Neurons: 11, Grad norm: 8.814e+00\n",
      "Epoch 12182, Loss: 439.11407470703125, Neurons: 11, Grad norm: 4.478e+00\n",
      "Epoch 12183, Loss: 439.1109924316406, Neurons: 11, Grad norm: 2.525e+00\n",
      "Epoch 12184, Loss: 439.1078796386719, Neurons: 11, Grad norm: 5.677e+00\n",
      "Epoch 12185, Loss: 439.10479736328125, Neurons: 11, Grad norm: 1.013e+01\n",
      "Epoch 12186, Loss: 439.10174560546875, Neurons: 11, Grad norm: 1.122e+01\n",
      "Epoch 12187, Loss: 439.09869384765625, Neurons: 11, Grad norm: 1.298e+01\n",
      "Epoch 12188, Loss: 439.0955810546875, Neurons: 11, Grad norm: 1.133e+01\n",
      "Epoch 12189, Loss: 439.0924987792969, Neurons: 11, Grad norm: 1.035e+01\n",
      "Epoch 12190, Loss: 439.0893859863281, Neurons: 11, Grad norm: 6.946e+00\n",
      "Epoch 12191, Loss: 439.0863342285156, Neurons: 11, Grad norm: 4.764e+00\n",
      "Epoch 12192, Loss: 439.083251953125, Neurons: 11, Grad norm: 1.901e+00\n",
      "Epoch 12193, Loss: 439.0802001953125, Neurons: 11, Grad norm: 2.606e+00\n",
      "Epoch 12194, Loss: 439.07708740234375, Neurons: 11, Grad norm: 5.677e+00\n",
      "Epoch 12195, Loss: 439.073974609375, Neurons: 11, Grad norm: 6.594e+00\n",
      "Epoch 12196, Loss: 439.0708923339844, Neurons: 11, Grad norm: 8.978e+00\n",
      "Epoch 12197, Loss: 439.0677795410156, Neurons: 11, Grad norm: 8.655e+00\n",
      "Epoch 12198, Loss: 439.064697265625, Neurons: 11, Grad norm: 9.597e+00\n",
      "Epoch 12199, Loss: 439.0616455078125, Neurons: 11, Grad norm: 8.295e+00\n",
      "Epoch 12199, Test loss: 435.3932800292969\n",
      "Epoch 12200, Loss: 439.05853271484375, Neurons: 11, Grad norm: 7.876e+00\n",
      "Epoch 12201, Loss: 439.0554504394531, Neurons: 11, Grad norm: 5.513e+00\n",
      "Epoch 12202, Loss: 439.0523376464844, Neurons: 11, Grad norm: 4.824e+00\n",
      "Epoch 12203, Loss: 439.0491943359375, Neurons: 11, Grad norm: 2.681e+00\n",
      "Epoch 12204, Loss: 439.046142578125, Neurons: 11, Grad norm: 2.434e+00\n",
      "Epoch 12205, Loss: 439.04302978515625, Neurons: 11, Grad norm: 2.097e+00\n",
      "Epoch 12206, Loss: 439.0398864746094, Neurons: 11, Grad norm: 2.488e+00\n",
      "Epoch 12207, Loss: 439.0367736816406, Neurons: 11, Grad norm: 4.180e+00\n",
      "Epoch 12208, Loss: 439.03369140625, Neurons: 11, Grad norm: 4.362e+00\n",
      "Epoch 12209, Loss: 439.0306396484375, Neurons: 11, Grad norm: 6.082e+00\n",
      "Epoch 12210, Loss: 439.0274963378906, Neurons: 11, Grad norm: 5.581e+00\n",
      "Epoch 12211, Loss: 439.0243835449219, Neurons: 11, Grad norm: 6.667e+00\n",
      "Epoch 12212, Loss: 439.02130126953125, Neurons: 11, Grad norm: 5.648e+00\n",
      "Epoch 12213, Loss: 439.0181884765625, Neurons: 11, Grad norm: 6.174e+00\n",
      "Epoch 12214, Loss: 439.01507568359375, Neurons: 11, Grad norm: 4.796e+00\n",
      "Epoch 12215, Loss: 439.0119934082031, Neurons: 11, Grad norm: 4.965e+00\n",
      "Epoch 12216, Loss: 439.00885009765625, Neurons: 11, Grad norm: 3.404e+00\n",
      "Epoch 12217, Loss: 439.0057373046875, Neurons: 11, Grad norm: 3.181e+00\n",
      "Epoch 12218, Loss: 439.002685546875, Neurons: 11, Grad norm: 2.026e+00\n",
      "Epoch 12219, Loss: 438.9994812011719, Neurons: 11, Grad norm: 2.143e+00\n",
      "Epoch 12220, Loss: 438.99639892578125, Neurons: 11, Grad norm: 2.013e+00\n",
      "Epoch 12221, Loss: 438.9932861328125, Neurons: 11, Grad norm: 1.912e+00\n",
      "Epoch 12222, Loss: 438.9902038574219, Neurons: 11, Grad norm: 2.577e+00\n",
      "Epoch 12223, Loss: 438.9870910644531, Neurons: 11, Grad norm: 2.289e+00\n",
      "Epoch 12224, Loss: 438.98388671875, Neurons: 11, Grad norm: 3.247e+00\n",
      "Epoch 12225, Loss: 438.98077392578125, Neurons: 11, Grad norm: 3.082e+00\n",
      "Epoch 12226, Loss: 438.9776916503906, Neurons: 11, Grad norm: 4.374e+00\n",
      "Epoch 12227, Loss: 438.9745788574219, Neurons: 11, Grad norm: 4.149e+00\n",
      "Epoch 12228, Loss: 438.971435546875, Neurons: 11, Grad norm: 5.372e+00\n",
      "Epoch 12229, Loss: 438.9683532714844, Neurons: 11, Grad norm: 4.737e+00\n",
      "Epoch 12230, Loss: 438.9651794433594, Neurons: 11, Grad norm: 5.745e+00\n",
      "Epoch 12231, Loss: 438.96209716796875, Neurons: 11, Grad norm: 4.954e+00\n",
      "Epoch 12232, Loss: 438.9588928222656, Neurons: 11, Grad norm: 6.309e+00\n",
      "Epoch 12233, Loss: 438.9557800292969, Neurons: 11, Grad norm: 5.601e+00\n",
      "Epoch 12234, Loss: 438.95269775390625, Neurons: 11, Grad norm: 6.579e+00\n",
      "Epoch 12235, Loss: 438.94952392578125, Neurons: 11, Grad norm: 6.264e+00\n",
      "Epoch 12236, Loss: 438.9463806152344, Neurons: 11, Grad norm: 7.168e+00\n",
      "Epoch 12237, Loss: 438.94329833984375, Neurons: 11, Grad norm: 6.552e+00\n",
      "Epoch 12238, Loss: 438.940185546875, Neurons: 11, Grad norm: 7.952e+00\n",
      "Epoch 12239, Loss: 438.9369812011719, Neurons: 11, Grad norm: 7.179e+00\n",
      "Epoch 12240, Loss: 438.93389892578125, Neurons: 11, Grad norm: 8.588e+00\n",
      "Epoch 12241, Loss: 438.9306945800781, Neurons: 11, Grad norm: 7.924e+00\n",
      "Epoch 12242, Loss: 438.9275817871094, Neurons: 11, Grad norm: 9.080e+00\n",
      "Epoch 12243, Loss: 438.92449951171875, Neurons: 11, Grad norm: 9.007e+00\n",
      "Epoch 12244, Loss: 438.9212951660156, Neurons: 11, Grad norm: 1.038e+01\n",
      "Epoch 12245, Loss: 438.9181823730469, Neurons: 11, Grad norm: 1.017e+01\n",
      "Epoch 12246, Loss: 438.9150390625, Neurons: 11, Grad norm: 1.205e+01\n",
      "Epoch 12247, Loss: 438.9118957519531, Neurons: 11, Grad norm: 1.207e+01\n",
      "Epoch 12248, Loss: 438.9087829589844, Neurons: 11, Grad norm: 1.431e+01\n",
      "Epoch 12249, Loss: 438.90557861328125, Neurons: 11, Grad norm: 1.485e+01\n",
      "Epoch 12249, Test loss: 435.2437744140625\n",
      "Epoch 12250, Loss: 438.9024963378906, Neurons: 11, Grad norm: 1.758e+01\n",
      "Epoch 12251, Loss: 438.8992919921875, Neurons: 11, Grad norm: 1.907e+01\n",
      "Epoch 12252, Loss: 438.89617919921875, Neurons: 11, Grad norm: 2.266e+01\n",
      "Epoch 12253, Loss: 438.8929748535156, Neurons: 11, Grad norm: 2.518e+01\n",
      "Epoch 12254, Loss: 438.889892578125, Neurons: 11, Grad norm: 3.005e+01\n",
      "Epoch 12255, Loss: 438.8867492675781, Neurons: 11, Grad norm: 3.402e+01\n",
      "Epoch 12256, Loss: 438.8836364746094, Neurons: 11, Grad norm: 4.127e+01\n",
      "Epoch 12257, Loss: 438.8804931640625, Neurons: 11, Grad norm: 4.790e+01\n",
      "Epoch 12258, Loss: 438.87738037109375, Neurons: 11, Grad norm: 5.826e+01\n",
      "Epoch 12259, Loss: 438.87432861328125, Neurons: 11, Grad norm: 6.889e+01\n",
      "Epoch 12260, Loss: 438.87127685546875, Neurons: 11, Grad norm: 8.377e+01\n",
      "Epoch 12261, Loss: 438.8682861328125, Neurons: 11, Grad norm: 1.002e+02\n",
      "Epoch 12262, Loss: 438.8654479980469, Neurons: 11, Grad norm: 1.216e+02\n",
      "Epoch 12263, Loss: 438.8625793457031, Neurons: 11, Grad norm: 1.449e+02\n",
      "Epoch 12264, Loss: 438.8599853515625, Neurons: 11, Grad norm: 1.737e+02\n",
      "Epoch 12265, Loss: 438.8575439453125, Neurons: 11, Grad norm: 2.034e+02\n",
      "Epoch 12266, Loss: 438.8553466796875, Neurons: 11, Grad norm: 2.362e+02\n",
      "Epoch 12267, Loss: 438.8533020019531, Neurons: 11, Grad norm: 2.640e+02\n",
      "Epoch 12268, Loss: 438.8512878417969, Neurons: 11, Grad norm: 2.851e+02\n",
      "Epoch 12269, Loss: 438.8491516113281, Neurons: 11, Grad norm: 2.878e+02\n",
      "Epoch 12270, Loss: 438.84625244140625, Neurons: 11, Grad norm: 2.684e+02\n",
      "Epoch 12271, Loss: 438.84222412109375, Neurons: 11, Grad norm: 2.204e+02\n",
      "Epoch 12272, Loss: 438.83740234375, Neurons: 11, Grad norm: 1.505e+02\n",
      "Epoch 12273, Loss: 438.8322448730469, Neurons: 11, Grad norm: 6.516e+01\n",
      "Epoch 12274, Loss: 438.8277893066406, Neurons: 11, Grad norm: 1.938e+01\n",
      "Epoch 12275, Loss: 438.8244323730469, Neurons: 11, Grad norm: 9.461e+01\n",
      "Epoch 12276, Loss: 438.82208251953125, Neurons: 11, Grad norm: 1.469e+02\n",
      "Epoch 12277, Loss: 438.8200988769531, Neurons: 11, Grad norm: 1.745e+02\n",
      "Epoch 12278, Loss: 438.8177490234375, Neurons: 11, Grad norm: 1.709e+02\n",
      "Epoch 12279, Loss: 438.814697265625, Neurons: 11, Grad norm: 1.418e+02\n",
      "Epoch 12280, Loss: 438.81097412109375, Neurons: 11, Grad norm: 9.046e+01\n",
      "Epoch 12281, Loss: 438.8069763183594, Neurons: 11, Grad norm: 3.019e+01\n",
      "Epoch 12282, Loss: 438.8033752441406, Neurons: 11, Grad norm: 3.126e+01\n",
      "Epoch 12283, Loss: 438.8003845214844, Neurons: 11, Grad norm: 7.937e+01\n",
      "Epoch 12284, Loss: 438.7978515625, Neurons: 11, Grad norm: 1.113e+02\n",
      "Epoch 12285, Loss: 438.7952880859375, Neurons: 11, Grad norm: 1.190e+02\n",
      "Epoch 12286, Loss: 438.7924499511719, Neurons: 11, Grad norm: 1.073e+02\n",
      "Epoch 12287, Loss: 438.78924560546875, Neurons: 11, Grad norm: 7.623e+01\n",
      "Epoch 12288, Loss: 438.78582763671875, Neurons: 11, Grad norm: 3.622e+01\n",
      "Epoch 12289, Loss: 438.7823791503906, Neurons: 11, Grad norm: 7.874e+00\n",
      "Epoch 12290, Loss: 438.7793273925781, Neurons: 11, Grad norm: 4.440e+01\n",
      "Epoch 12291, Loss: 438.77655029296875, Neurons: 11, Grad norm: 7.136e+01\n",
      "Epoch 12292, Loss: 438.77374267578125, Neurons: 11, Grad norm: 8.185e+01\n",
      "Epoch 12293, Loss: 438.7708740234375, Neurons: 11, Grad norm: 7.908e+01\n",
      "Epoch 12294, Loss: 438.7678527832031, Neurons: 11, Grad norm: 6.128e+01\n",
      "Epoch 12295, Loss: 438.7646789550781, Neurons: 11, Grad norm: 3.691e+01\n",
      "Epoch 12296, Loss: 438.7614440917969, Neurons: 11, Grad norm: 7.169e+00\n",
      "Epoch 12297, Loss: 438.7583923339844, Neurons: 11, Grad norm: 1.949e+01\n",
      "Epoch 12298, Loss: 438.7554016113281, Neurons: 11, Grad norm: 4.140e+01\n",
      "Epoch 12299, Loss: 438.75250244140625, Neurons: 11, Grad norm: 5.323e+01\n",
      "Epoch 12299, Test loss: 435.1041259765625\n",
      "Epoch 12300, Loss: 438.7496032714844, Neurons: 11, Grad norm: 5.660e+01\n",
      "Epoch 12301, Loss: 438.74658203125, Neurons: 11, Grad norm: 4.868e+01\n",
      "Epoch 12302, Loss: 438.7434997558594, Neurons: 11, Grad norm: 3.545e+01\n",
      "Epoch 12303, Loss: 438.7404479980469, Neurons: 11, Grad norm: 1.580e+01\n",
      "Epoch 12304, Loss: 438.7373352050781, Neurons: 11, Grad norm: 3.197e+00\n",
      "Epoch 12305, Loss: 438.7343444824219, Neurons: 11, Grad norm: 2.063e+01\n",
      "Epoch 12306, Loss: 438.7313537597656, Neurons: 11, Grad norm: 3.215e+01\n",
      "Epoch 12307, Loss: 438.7283935546875, Neurons: 11, Grad norm: 3.898e+01\n",
      "Epoch 12308, Loss: 438.72540283203125, Neurons: 11, Grad norm: 3.794e+01\n",
      "Epoch 12309, Loss: 438.7223815917969, Neurons: 11, Grad norm: 3.321e+01\n",
      "Epoch 12310, Loss: 438.7193908691406, Neurons: 11, Grad norm: 2.262e+01\n",
      "Epoch 12311, Loss: 438.7162780761719, Neurons: 11, Grad norm: 1.183e+01\n",
      "Epoch 12312, Loss: 438.7132873535156, Neurons: 11, Grad norm: 2.467e+00\n",
      "Epoch 12313, Loss: 438.7102966308594, Neurons: 11, Grad norm: 1.173e+01\n",
      "Epoch 12314, Loss: 438.707275390625, Neurons: 11, Grad norm: 2.102e+01\n",
      "Epoch 12315, Loss: 438.70428466796875, Neurons: 11, Grad norm: 2.507e+01\n",
      "Epoch 12316, Loss: 438.7012939453125, Neurons: 11, Grad norm: 2.711e+01\n",
      "Epoch 12317, Loss: 438.69830322265625, Neurons: 11, Grad norm: 2.395e+01\n",
      "Epoch 12318, Loss: 438.69525146484375, Neurons: 11, Grad norm: 1.943e+01\n",
      "Epoch 12319, Loss: 438.69219970703125, Neurons: 11, Grad norm: 1.129e+01\n",
      "Epoch 12320, Loss: 438.6891784667969, Neurons: 11, Grad norm: 4.557e+00\n",
      "Epoch 12321, Loss: 438.6861267089844, Neurons: 11, Grad norm: 4.945e+00\n",
      "Epoch 12322, Loss: 438.6830749511719, Neurons: 11, Grad norm: 1.019e+01\n",
      "Epoch 12323, Loss: 438.6800842285156, Neurons: 11, Grad norm: 1.562e+01\n",
      "Epoch 12324, Loss: 438.6770935058594, Neurons: 11, Grad norm: 1.697e+01\n",
      "Epoch 12325, Loss: 438.6741027832031, Neurons: 11, Grad norm: 1.764e+01\n",
      "Epoch 12326, Loss: 438.67108154296875, Neurons: 11, Grad norm: 1.486e+01\n",
      "Epoch 12327, Loss: 438.6679992675781, Neurons: 11, Grad norm: 1.257e+01\n",
      "Epoch 12328, Loss: 438.66497802734375, Neurons: 11, Grad norm: 7.338e+00\n",
      "Epoch 12329, Loss: 438.6619873046875, Neurons: 11, Grad norm: 3.719e+00\n",
      "Epoch 12330, Loss: 438.658935546875, Neurons: 11, Grad norm: 3.114e+00\n",
      "Epoch 12331, Loss: 438.6558837890625, Neurons: 11, Grad norm: 6.279e+00\n",
      "Epoch 12332, Loss: 438.65283203125, Neurons: 11, Grad norm: 1.007e+01\n",
      "Epoch 12333, Loss: 438.6497802734375, Neurons: 11, Grad norm: 1.090e+01\n",
      "Epoch 12334, Loss: 438.64678955078125, Neurons: 11, Grad norm: 1.261e+01\n",
      "Epoch 12335, Loss: 438.643798828125, Neurons: 11, Grad norm: 1.143e+01\n",
      "Epoch 12336, Loss: 438.6407470703125, Neurons: 11, Grad norm: 1.130e+01\n",
      "Epoch 12337, Loss: 438.6376953125, Neurons: 11, Grad norm: 8.343e+00\n",
      "Epoch 12338, Loss: 438.6346435546875, Neurons: 11, Grad norm: 6.665e+00\n",
      "Epoch 12339, Loss: 438.631591796875, Neurons: 11, Grad norm: 3.276e+00\n",
      "Epoch 12340, Loss: 438.62860107421875, Neurons: 11, Grad norm: 1.974e+00\n",
      "Epoch 12341, Loss: 438.62554931640625, Neurons: 11, Grad norm: 3.285e+00\n",
      "Epoch 12342, Loss: 438.62249755859375, Neurons: 11, Grad norm: 4.652e+00\n",
      "Epoch 12343, Loss: 438.6194763183594, Neurons: 11, Grad norm: 7.366e+00\n",
      "Epoch 12344, Loss: 438.6164245605469, Neurons: 11, Grad norm: 7.411e+00\n",
      "Epoch 12345, Loss: 438.6134033203125, Neurons: 11, Grad norm: 8.895e+00\n",
      "Epoch 12346, Loss: 438.61029052734375, Neurons: 11, Grad norm: 7.787e+00\n",
      "Epoch 12347, Loss: 438.6072998046875, Neurons: 11, Grad norm: 7.944e+00\n",
      "Epoch 12348, Loss: 438.604248046875, Neurons: 11, Grad norm: 6.093e+00\n",
      "Epoch 12349, Loss: 438.6011962890625, Neurons: 11, Grad norm: 5.557e+00\n",
      "Epoch 12349, Test loss: 434.9444580078125\n",
      "Epoch 12350, Loss: 438.59808349609375, Neurons: 11, Grad norm: 3.473e+00\n",
      "Epoch 12351, Loss: 438.5950927734375, Neurons: 11, Grad norm: 2.928e+00\n",
      "Epoch 12352, Loss: 438.59197998046875, Neurons: 11, Grad norm: 1.834e+00\n",
      "Epoch 12353, Loss: 438.5889892578125, Neurons: 11, Grad norm: 1.879e+00\n",
      "Epoch 12354, Loss: 438.58587646484375, Neurons: 11, Grad norm: 3.095e+00\n",
      "Epoch 12355, Loss: 438.58282470703125, Neurons: 11, Grad norm: 3.099e+00\n",
      "Epoch 12356, Loss: 438.5798034667969, Neurons: 11, Grad norm: 4.762e+00\n",
      "Epoch 12357, Loss: 438.5767517089844, Neurons: 11, Grad norm: 4.345e+00\n",
      "Epoch 12358, Loss: 438.5736999511719, Neurons: 11, Grad norm: 5.392e+00\n",
      "Epoch 12359, Loss: 438.5706787109375, Neurons: 11, Grad norm: 4.966e+00\n",
      "Epoch 12360, Loss: 438.5675964355469, Neurons: 11, Grad norm: 5.588e+00\n",
      "Epoch 12361, Loss: 438.5644836425781, Neurons: 11, Grad norm: 4.610e+00\n",
      "Epoch 12362, Loss: 438.5614929199219, Neurons: 11, Grad norm: 5.486e+00\n",
      "Epoch 12363, Loss: 438.5583801269531, Neurons: 11, Grad norm: 4.513e+00\n",
      "Epoch 12364, Loss: 438.5553283691406, Neurons: 11, Grad norm: 5.604e+00\n",
      "Epoch 12365, Loss: 438.5522766113281, Neurons: 11, Grad norm: 4.523e+00\n",
      "Epoch 12366, Loss: 438.5492248535156, Neurons: 11, Grad norm: 5.150e+00\n",
      "Epoch 12367, Loss: 438.54608154296875, Neurons: 11, Grad norm: 4.480e+00\n",
      "Epoch 12368, Loss: 438.54302978515625, Neurons: 11, Grad norm: 4.836e+00\n",
      "Epoch 12369, Loss: 438.53997802734375, Neurons: 11, Grad norm: 3.523e+00\n",
      "Epoch 12370, Loss: 438.5368957519531, Neurons: 11, Grad norm: 3.882e+00\n",
      "Epoch 12371, Loss: 438.53387451171875, Neurons: 11, Grad norm: 2.557e+00\n",
      "Epoch 12372, Loss: 438.5307922363281, Neurons: 11, Grad norm: 2.967e+00\n",
      "Epoch 12373, Loss: 438.5276794433594, Neurons: 11, Grad norm: 2.041e+00\n",
      "Epoch 12374, Loss: 438.5246276855469, Neurons: 11, Grad norm: 2.244e+00\n",
      "Epoch 12375, Loss: 438.52154541015625, Neurons: 11, Grad norm: 1.838e+00\n",
      "Epoch 12376, Loss: 438.5184326171875, Neurons: 11, Grad norm: 1.807e+00\n",
      "Epoch 12377, Loss: 438.515380859375, Neurons: 11, Grad norm: 1.989e+00\n",
      "Epoch 12378, Loss: 438.5122985839844, Neurons: 11, Grad norm: 1.832e+00\n",
      "Epoch 12379, Loss: 438.5092468261719, Neurons: 11, Grad norm: 2.137e+00\n",
      "Epoch 12380, Loss: 438.5061340332031, Neurons: 11, Grad norm: 1.842e+00\n",
      "Epoch 12381, Loss: 438.5030822753906, Neurons: 11, Grad norm: 2.257e+00\n",
      "Epoch 12382, Loss: 438.5, Neurons: 11, Grad norm: 1.897e+00\n",
      "Epoch 12383, Loss: 438.49688720703125, Neurons: 11, Grad norm: 2.302e+00\n",
      "Epoch 12384, Loss: 438.4937744140625, Neurons: 11, Grad norm: 1.952e+00\n",
      "Epoch 12385, Loss: 438.4906921386719, Neurons: 11, Grad norm: 2.561e+00\n",
      "Epoch 12386, Loss: 438.4876403808594, Neurons: 11, Grad norm: 2.085e+00\n",
      "Epoch 12387, Loss: 438.4845275878906, Neurons: 11, Grad norm: 2.705e+00\n",
      "Epoch 12388, Loss: 438.4814758300781, Neurons: 11, Grad norm: 2.446e+00\n",
      "Epoch 12389, Loss: 438.4783935546875, Neurons: 11, Grad norm: 3.357e+00\n",
      "Epoch 12390, Loss: 438.47528076171875, Neurons: 11, Grad norm: 2.950e+00\n",
      "Epoch 12391, Loss: 438.4721984863281, Neurons: 11, Grad norm: 4.136e+00\n",
      "Epoch 12392, Loss: 438.4690856933594, Neurons: 11, Grad norm: 3.726e+00\n",
      "Epoch 12393, Loss: 438.46600341796875, Neurons: 11, Grad norm: 5.520e+00\n",
      "Epoch 12394, Loss: 438.462890625, Neurons: 11, Grad norm: 5.333e+00\n",
      "Epoch 12395, Loss: 438.45977783203125, Neurons: 11, Grad norm: 6.948e+00\n",
      "Epoch 12396, Loss: 438.4566955566406, Neurons: 11, Grad norm: 7.524e+00\n",
      "Epoch 12397, Loss: 438.4535827636719, Neurons: 11, Grad norm: 9.887e+00\n",
      "Epoch 12398, Loss: 438.45050048828125, Neurons: 11, Grad norm: 1.129e+01\n",
      "Epoch 12399, Loss: 438.4473876953125, Neurons: 11, Grad norm: 1.489e+01\n",
      "Epoch 12399, Test loss: 434.7935485839844\n",
      "Epoch 12400, Loss: 438.44427490234375, Neurons: 11, Grad norm: 1.679e+01\n",
      "Epoch 12401, Loss: 438.4411926269531, Neurons: 11, Grad norm: 2.145e+01\n",
      "Epoch 12402, Loss: 438.4380798339844, Neurons: 11, Grad norm: 2.516e+01\n",
      "Epoch 12403, Loss: 438.43499755859375, Neurons: 11, Grad norm: 3.184e+01\n",
      "Epoch 12404, Loss: 438.43194580078125, Neurons: 11, Grad norm: 3.790e+01\n",
      "Epoch 12405, Loss: 438.42889404296875, Neurons: 11, Grad norm: 4.718e+01\n",
      "Epoch 12406, Loss: 438.42584228515625, Neurons: 11, Grad norm: 5.730e+01\n",
      "Epoch 12407, Loss: 438.42279052734375, Neurons: 11, Grad norm: 7.166e+01\n",
      "Epoch 12408, Loss: 438.4197998046875, Neurons: 11, Grad norm: 8.741e+01\n",
      "Epoch 12409, Loss: 438.41693115234375, Neurons: 11, Grad norm: 1.094e+02\n",
      "Epoch 12410, Loss: 438.4141845703125, Neurons: 11, Grad norm: 1.342e+02\n",
      "Epoch 12411, Loss: 438.4115295410156, Neurons: 11, Grad norm: 1.662e+02\n",
      "Epoch 12412, Loss: 438.4091491699219, Neurons: 11, Grad norm: 2.020e+02\n",
      "Epoch 12413, Loss: 438.4070739746094, Neurons: 11, Grad norm: 2.442e+02\n",
      "Epoch 12414, Loss: 438.4054870605469, Neurons: 11, Grad norm: 2.858e+02\n",
      "Epoch 12415, Loss: 438.4041748046875, Neurons: 11, Grad norm: 3.232e+02\n",
      "Epoch 12416, Loss: 438.40289306640625, Neurons: 11, Grad norm: 3.424e+02\n",
      "Epoch 12417, Loss: 438.40087890625, Neurons: 11, Grad norm: 3.340e+02\n",
      "Epoch 12418, Loss: 438.39739990234375, Neurons: 11, Grad norm: 2.847e+02\n",
      "Epoch 12419, Loss: 438.39208984375, Neurons: 11, Grad norm: 1.990e+02\n",
      "Epoch 12420, Loss: 438.3858947753906, Neurons: 11, Grad norm: 8.578e+01\n",
      "Epoch 12421, Loss: 438.38043212890625, Neurons: 11, Grad norm: 3.005e+01\n",
      "Epoch 12422, Loss: 438.3769836425781, Neurons: 11, Grad norm: 1.304e+02\n",
      "Epoch 12423, Loss: 438.3752746582031, Neurons: 11, Grad norm: 1.959e+02\n",
      "Epoch 12424, Loss: 438.3740539550781, Neurons: 11, Grad norm: 2.196e+02\n",
      "Epoch 12425, Loss: 438.371826171875, Neurons: 11, Grad norm: 1.951e+02\n",
      "Epoch 12426, Loss: 438.3681945800781, Neurons: 11, Grad norm: 1.334e+02\n",
      "Epoch 12427, Loss: 438.36358642578125, Neurons: 11, Grad norm: 4.684e+01\n",
      "Epoch 12428, Loss: 438.3594970703125, Neurons: 11, Grad norm: 3.966e+01\n",
      "Epoch 12429, Loss: 438.3564758300781, Neurons: 11, Grad norm: 1.106e+02\n",
      "Epoch 12430, Loss: 438.35443115234375, Neurons: 11, Grad norm: 1.482e+02\n",
      "Epoch 12431, Loss: 438.352294921875, Neurons: 11, Grad norm: 1.504e+02\n",
      "Epoch 12432, Loss: 438.34942626953125, Neurons: 11, Grad norm: 1.166e+02\n",
      "Epoch 12433, Loss: 438.3458251953125, Neurons: 11, Grad norm: 6.054e+01\n",
      "Epoch 12434, Loss: 438.3421936035156, Neurons: 11, Grad norm: 5.982e+00\n",
      "Epoch 12435, Loss: 438.3389892578125, Neurons: 11, Grad norm: 6.221e+01\n",
      "Epoch 12436, Loss: 438.3363952636719, Neurons: 11, Grad norm: 1.002e+02\n",
      "Epoch 12437, Loss: 438.3339538574219, Neurons: 11, Grad norm: 1.094e+02\n",
      "Epoch 12438, Loss: 438.3311767578125, Neurons: 11, Grad norm: 9.406e+01\n",
      "Epoch 12439, Loss: 438.3280944824219, Neurons: 11, Grad norm: 5.661e+01\n",
      "Epoch 12440, Loss: 438.3247375488281, Neurons: 11, Grad norm: 1.127e+01\n",
      "Epoch 12441, Loss: 438.32159423828125, Neurons: 11, Grad norm: 3.413e+01\n",
      "Epoch 12442, Loss: 438.31878662109375, Neurons: 11, Grad norm: 6.521e+01\n",
      "Epoch 12443, Loss: 438.31610107421875, Neurons: 11, Grad norm: 7.947e+01\n",
      "Epoch 12444, Loss: 438.3133850097656, Neurons: 11, Grad norm: 7.258e+01\n",
      "Epoch 12445, Loss: 438.3103942871094, Neurons: 11, Grad norm: 5.149e+01\n",
      "Epoch 12446, Loss: 438.3073425292969, Neurons: 11, Grad norm: 1.890e+01\n",
      "Epoch 12447, Loss: 438.30419921875, Neurons: 11, Grad norm: 1.332e+01\n",
      "Epoch 12448, Loss: 438.3013000488281, Neurons: 11, Grad norm: 4.063e+01\n",
      "Epoch 12449, Loss: 438.2984924316406, Neurons: 11, Grad norm: 5.450e+01\n",
      "Epoch 12449, Test loss: 434.6644592285156\n",
      "Epoch 12450, Loss: 438.2957458496094, Neurons: 11, Grad norm: 5.676e+01\n",
      "Epoch 12451, Loss: 438.29278564453125, Neurons: 11, Grad norm: 4.463e+01\n",
      "Epoch 12452, Loss: 438.2898254394531, Neurons: 11, Grad norm: 2.558e+01\n",
      "Epoch 12453, Loss: 438.2867736816406, Neurons: 11, Grad norm: 2.242e+00\n",
      "Epoch 12454, Loss: 438.28387451171875, Neurons: 11, Grad norm: 1.933e+01\n",
      "Epoch 12455, Loss: 438.2809753417969, Neurons: 11, Grad norm: 3.512e+01\n",
      "Epoch 12456, Loss: 438.27813720703125, Neurons: 11, Grad norm: 4.014e+01\n",
      "Epoch 12457, Loss: 438.2752990722656, Neurons: 11, Grad norm: 3.772e+01\n",
      "Epoch 12458, Loss: 438.2723388671875, Neurons: 11, Grad norm: 2.572e+01\n",
      "Epoch 12459, Loss: 438.2693786621094, Neurons: 11, Grad norm: 1.167e+01\n",
      "Epoch 12460, Loss: 438.2664794921875, Neurons: 11, Grad norm: 5.766e+00\n",
      "Epoch 12461, Loss: 438.2635498046875, Neurons: 11, Grad norm: 1.796e+01\n",
      "Epoch 12462, Loss: 438.2606506347656, Neurons: 11, Grad norm: 2.702e+01\n",
      "Epoch 12463, Loss: 438.2577819824219, Neurons: 11, Grad norm: 2.877e+01\n",
      "Epoch 12464, Loss: 438.2548828125, Neurons: 11, Grad norm: 2.618e+01\n",
      "Epoch 12465, Loss: 438.251953125, Neurons: 11, Grad norm: 1.733e+01\n",
      "Epoch 12466, Loss: 438.2489929199219, Neurons: 11, Grad norm: 7.616e+00\n",
      "Epoch 12467, Loss: 438.24603271484375, Neurons: 11, Grad norm: 5.002e+00\n",
      "Epoch 12468, Loss: 438.24310302734375, Neurons: 11, Grad norm: 1.258e+01\n",
      "Epoch 12469, Loss: 438.2402038574219, Neurons: 11, Grad norm: 1.932e+01\n",
      "Epoch 12470, Loss: 438.2372741699219, Neurons: 11, Grad norm: 1.994e+01\n",
      "Epoch 12471, Loss: 438.234375, Neurons: 11, Grad norm: 1.834e+01\n",
      "Epoch 12472, Loss: 438.2314453125, Neurons: 11, Grad norm: 1.229e+01\n",
      "Epoch 12473, Loss: 438.2285461425781, Neurons: 11, Grad norm: 6.003e+00\n",
      "Epoch 12474, Loss: 438.2255859375, Neurons: 11, Grad norm: 3.093e+00\n",
      "Epoch 12475, Loss: 438.2226867675781, Neurons: 11, Grad norm: 8.078e+00\n",
      "Epoch 12476, Loss: 438.21978759765625, Neurons: 11, Grad norm: 1.323e+01\n",
      "Epoch 12477, Loss: 438.216796875, Neurons: 11, Grad norm: 1.365e+01\n",
      "Epoch 12478, Loss: 438.2138977050781, Neurons: 11, Grad norm: 1.365e+01\n",
      "Epoch 12479, Loss: 438.21099853515625, Neurons: 11, Grad norm: 9.468e+00\n",
      "Epoch 12480, Loss: 438.2080383300781, Neurons: 11, Grad norm: 5.814e+00\n",
      "Epoch 12481, Loss: 438.205078125, Neurons: 11, Grad norm: 1.833e+00\n",
      "Epoch 12482, Loss: 438.2021484375, Neurons: 11, Grad norm: 4.437e+00\n",
      "Epoch 12483, Loss: 438.1992492675781, Neurons: 11, Grad norm: 8.436e+00\n",
      "Epoch 12484, Loss: 438.1962890625, Neurons: 11, Grad norm: 9.379e+00\n",
      "Epoch 12485, Loss: 438.1933898925781, Neurons: 11, Grad norm: 1.031e+01\n",
      "Epoch 12486, Loss: 438.1904296875, Neurons: 11, Grad norm: 7.833e+00\n",
      "Epoch 12487, Loss: 438.1875, Neurons: 11, Grad norm: 6.204e+00\n",
      "Epoch 12488, Loss: 438.1846008300781, Neurons: 11, Grad norm: 2.207e+00\n",
      "Epoch 12489, Loss: 438.18157958984375, Neurons: 11, Grad norm: 2.233e+00\n",
      "Epoch 12490, Loss: 438.1786804199219, Neurons: 11, Grad norm: 5.397e+00\n",
      "Epoch 12491, Loss: 438.17578125, Neurons: 11, Grad norm: 6.878e+00\n",
      "Epoch 12492, Loss: 438.17279052734375, Neurons: 11, Grad norm: 8.356e+00\n",
      "Epoch 12493, Loss: 438.1698913574219, Neurons: 11, Grad norm: 7.281e+00\n",
      "Epoch 12494, Loss: 438.1669006347656, Neurons: 11, Grad norm: 7.188e+00\n",
      "Epoch 12495, Loss: 438.1639404296875, Neurons: 11, Grad norm: 4.527e+00\n",
      "Epoch 12496, Loss: 438.1609802246094, Neurons: 11, Grad norm: 3.708e+00\n",
      "Epoch 12497, Loss: 438.1580810546875, Neurons: 11, Grad norm: 1.837e+00\n",
      "Epoch 12498, Loss: 438.15509033203125, Neurons: 11, Grad norm: 2.280e+00\n",
      "Epoch 12499, Loss: 438.1521911621094, Neurons: 11, Grad norm: 4.041e+00\n",
      "Epoch 12499, Test loss: 434.5095520019531\n",
      "Epoch 12500, Loss: 438.1492004394531, Neurons: 11, Grad norm: 4.476e+00\n",
      "Epoch 12501, Loss: 438.14630126953125, Neurons: 11, Grad norm: 5.864e+00\n",
      "Epoch 12502, Loss: 438.1432800292969, Neurons: 11, Grad norm: 4.917e+00\n",
      "Epoch 12503, Loss: 438.140380859375, Neurons: 11, Grad norm: 5.312e+00\n",
      "Epoch 12504, Loss: 438.13739013671875, Neurons: 11, Grad norm: 3.420e+00\n",
      "Epoch 12505, Loss: 438.1343994140625, Neurons: 11, Grad norm: 3.113e+00\n",
      "Epoch 12506, Loss: 438.1315002441406, Neurons: 11, Grad norm: 1.774e+00\n",
      "Epoch 12507, Loss: 438.12860107421875, Neurons: 11, Grad norm: 2.047e+00\n",
      "Epoch 12508, Loss: 438.1255798339844, Neurons: 11, Grad norm: 3.875e+00\n",
      "Epoch 12509, Loss: 438.1225891113281, Neurons: 11, Grad norm: 4.009e+00\n",
      "Epoch 12510, Loss: 438.11968994140625, Neurons: 11, Grad norm: 5.347e+00\n",
      "Epoch 12511, Loss: 438.1167297363281, Neurons: 11, Grad norm: 4.498e+00\n",
      "Epoch 12512, Loss: 438.1137390136719, Neurons: 11, Grad norm: 4.845e+00\n",
      "Epoch 12513, Loss: 438.11077880859375, Neurons: 11, Grad norm: 3.326e+00\n",
      "Epoch 12514, Loss: 438.1077880859375, Neurons: 11, Grad norm: 3.237e+00\n",
      "Epoch 12515, Loss: 438.10479736328125, Neurons: 11, Grad norm: 1.960e+00\n",
      "Epoch 12516, Loss: 438.1018981933594, Neurons: 11, Grad norm: 1.915e+00\n",
      "Epoch 12517, Loss: 438.098876953125, Neurons: 11, Grad norm: 2.154e+00\n",
      "Epoch 12518, Loss: 438.095947265625, Neurons: 11, Grad norm: 1.944e+00\n",
      "Epoch 12519, Loss: 438.0929870605469, Neurons: 11, Grad norm: 2.786e+00\n",
      "Epoch 12520, Loss: 438.0899963378906, Neurons: 11, Grad norm: 2.566e+00\n",
      "Epoch 12521, Loss: 438.08697509765625, Neurons: 11, Grad norm: 3.249e+00\n",
      "Epoch 12522, Loss: 438.08404541015625, Neurons: 11, Grad norm: 2.549e+00\n",
      "Epoch 12523, Loss: 438.0810852050781, Neurons: 11, Grad norm: 2.977e+00\n",
      "Epoch 12524, Loss: 438.0780944824219, Neurons: 11, Grad norm: 1.887e+00\n",
      "Epoch 12525, Loss: 438.0751037597656, Neurons: 11, Grad norm: 1.988e+00\n",
      "Epoch 12526, Loss: 438.0721435546875, Neurons: 11, Grad norm: 1.822e+00\n",
      "Epoch 12527, Loss: 438.06915283203125, Neurons: 11, Grad norm: 1.825e+00\n",
      "Epoch 12528, Loss: 438.0661926269531, Neurons: 11, Grad norm: 2.463e+00\n",
      "Epoch 12529, Loss: 438.0632019042969, Neurons: 11, Grad norm: 2.119e+00\n",
      "Epoch 12530, Loss: 438.0601806640625, Neurons: 11, Grad norm: 2.623e+00\n",
      "Epoch 12531, Loss: 438.05718994140625, Neurons: 11, Grad norm: 1.920e+00\n",
      "Epoch 12532, Loss: 438.0542297363281, Neurons: 11, Grad norm: 2.201e+00\n",
      "Epoch 12533, Loss: 438.0512390136719, Neurons: 11, Grad norm: 1.853e+00\n",
      "Epoch 12534, Loss: 438.0482482910156, Neurons: 11, Grad norm: 2.245e+00\n",
      "Epoch 12535, Loss: 438.0452880859375, Neurons: 11, Grad norm: 1.814e+00\n",
      "Epoch 12536, Loss: 438.04229736328125, Neurons: 11, Grad norm: 1.990e+00\n",
      "Epoch 12537, Loss: 438.0392761230469, Neurons: 11, Grad norm: 1.797e+00\n",
      "Epoch 12538, Loss: 438.0362854003906, Neurons: 11, Grad norm: 1.810e+00\n",
      "Epoch 12539, Loss: 438.0332946777344, Neurons: 11, Grad norm: 2.465e+00\n",
      "Epoch 12540, Loss: 438.0303039550781, Neurons: 11, Grad norm: 2.221e+00\n",
      "Epoch 12541, Loss: 438.02728271484375, Neurons: 11, Grad norm: 3.216e+00\n",
      "Epoch 12542, Loss: 438.0242919921875, Neurons: 11, Grad norm: 2.720e+00\n",
      "Epoch 12543, Loss: 438.02130126953125, Neurons: 11, Grad norm: 3.644e+00\n",
      "Epoch 12544, Loss: 438.0183410644531, Neurons: 11, Grad norm: 2.976e+00\n",
      "Epoch 12545, Loss: 438.0153503417969, Neurons: 11, Grad norm: 3.626e+00\n",
      "Epoch 12546, Loss: 438.0122985839844, Neurons: 11, Grad norm: 2.781e+00\n",
      "Epoch 12547, Loss: 438.00933837890625, Neurons: 11, Grad norm: 3.271e+00\n",
      "Epoch 12548, Loss: 438.00634765625, Neurons: 11, Grad norm: 2.376e+00\n",
      "Epoch 12549, Loss: 438.0032958984375, Neurons: 11, Grad norm: 2.703e+00\n",
      "Epoch 12549, Test loss: 434.3658447265625\n",
      "Epoch 12550, Loss: 438.0003356933594, Neurons: 11, Grad norm: 1.988e+00\n",
      "Epoch 12551, Loss: 437.9972839355469, Neurons: 11, Grad norm: 2.606e+00\n",
      "Epoch 12552, Loss: 437.9942932128906, Neurons: 11, Grad norm: 1.959e+00\n",
      "Epoch 12553, Loss: 437.9913024902344, Neurons: 11, Grad norm: 2.186e+00\n",
      "Epoch 12554, Loss: 437.98828125, Neurons: 11, Grad norm: 1.802e+00\n",
      "Epoch 12555, Loss: 437.98529052734375, Neurons: 11, Grad norm: 1.964e+00\n",
      "Epoch 12556, Loss: 437.9822998046875, Neurons: 11, Grad norm: 2.033e+00\n",
      "Epoch 12557, Loss: 437.9792785644531, Neurons: 11, Grad norm: 1.807e+00\n",
      "Epoch 12558, Loss: 437.9762268066406, Neurons: 11, Grad norm: 2.276e+00\n",
      "Epoch 12559, Loss: 437.9732971191406, Neurons: 11, Grad norm: 2.024e+00\n",
      "Epoch 12560, Loss: 437.9701843261719, Neurons: 11, Grad norm: 2.822e+00\n",
      "Epoch 12561, Loss: 437.9671936035156, Neurons: 11, Grad norm: 2.211e+00\n",
      "Epoch 12562, Loss: 437.9641418457031, Neurons: 11, Grad norm: 3.092e+00\n",
      "Epoch 12563, Loss: 437.961181640625, Neurons: 11, Grad norm: 2.499e+00\n",
      "Epoch 12564, Loss: 437.95819091796875, Neurons: 11, Grad norm: 3.254e+00\n",
      "Epoch 12565, Loss: 437.95513916015625, Neurons: 11, Grad norm: 2.708e+00\n",
      "Epoch 12566, Loss: 437.95208740234375, Neurons: 11, Grad norm: 3.226e+00\n",
      "Epoch 12567, Loss: 437.9490966796875, Neurons: 11, Grad norm: 2.747e+00\n",
      "Epoch 12568, Loss: 437.9460754394531, Neurons: 11, Grad norm: 4.042e+00\n",
      "Epoch 12569, Loss: 437.9430847167969, Neurons: 11, Grad norm: 3.549e+00\n",
      "Epoch 12570, Loss: 437.94000244140625, Neurons: 11, Grad norm: 5.049e+00\n",
      "Epoch 12571, Loss: 437.9369812011719, Neurons: 11, Grad norm: 4.813e+00\n",
      "Epoch 12572, Loss: 437.9339294433594, Neurons: 11, Grad norm: 6.315e+00\n",
      "Epoch 12573, Loss: 437.9309387207031, Neurons: 11, Grad norm: 6.404e+00\n",
      "Epoch 12574, Loss: 437.9278869628906, Neurons: 11, Grad norm: 8.087e+00\n",
      "Epoch 12575, Loss: 437.9248962402344, Neurons: 11, Grad norm: 8.449e+00\n",
      "Epoch 12576, Loss: 437.9217834472656, Neurons: 11, Grad norm: 1.061e+01\n",
      "Epoch 12577, Loss: 437.9187927246094, Neurons: 11, Grad norm: 1.128e+01\n",
      "Epoch 12578, Loss: 437.9158020019531, Neurons: 11, Grad norm: 1.426e+01\n",
      "Epoch 12579, Loss: 437.9127502441406, Neurons: 11, Grad norm: 1.577e+01\n",
      "Epoch 12580, Loss: 437.9096984863281, Neurons: 11, Grad norm: 1.971e+01\n",
      "Epoch 12581, Loss: 437.90667724609375, Neurons: 11, Grad norm: 2.269e+01\n",
      "Epoch 12582, Loss: 437.9036865234375, Neurons: 11, Grad norm: 2.871e+01\n",
      "Epoch 12583, Loss: 437.90057373046875, Neurons: 11, Grad norm: 3.442e+01\n",
      "Epoch 12584, Loss: 437.8975830078125, Neurons: 11, Grad norm: 4.344e+01\n",
      "Epoch 12585, Loss: 437.89459228515625, Neurons: 11, Grad norm: 5.296e+01\n",
      "Epoch 12586, Loss: 437.8916320800781, Neurons: 11, Grad norm: 6.679e+01\n",
      "Epoch 12587, Loss: 437.88873291015625, Neurons: 11, Grad norm: 8.193e+01\n",
      "Epoch 12588, Loss: 437.8858947753906, Neurons: 11, Grad norm: 1.028e+02\n",
      "Epoch 12589, Loss: 437.8830871582031, Neurons: 11, Grad norm: 1.269e+02\n",
      "Epoch 12590, Loss: 437.8804931640625, Neurons: 11, Grad norm: 1.581e+02\n",
      "Epoch 12591, Loss: 437.8781433105469, Neurons: 11, Grad norm: 1.932e+02\n",
      "Epoch 12592, Loss: 437.8760986328125, Neurons: 11, Grad norm: 2.354e+02\n",
      "Epoch 12593, Loss: 437.8743896484375, Neurons: 11, Grad norm: 2.783e+02\n",
      "Epoch 12594, Loss: 437.8731384277344, Neurons: 11, Grad norm: 3.198e+02\n",
      "Epoch 12595, Loss: 437.8720397949219, Neurons: 11, Grad norm: 3.465e+02\n",
      "Epoch 12596, Loss: 437.8704833984375, Neurons: 11, Grad norm: 3.485e+02\n",
      "Epoch 12597, Loss: 437.8676452636719, Neurons: 11, Grad norm: 3.105e+02\n",
      "Epoch 12598, Loss: 437.86285400390625, Neurons: 11, Grad norm: 2.328e+02\n",
      "Epoch 12599, Loss: 437.85662841796875, Neurons: 11, Grad norm: 1.217e+02\n",
      "Epoch 12599, Test loss: 434.247802734375\n",
      "Epoch 12600, Loss: 437.8507995605469, Neurons: 11, Grad norm: 2.586e+00\n",
      "Epoch 12601, Loss: 437.84674072265625, Neurons: 11, Grad norm: 1.084e+02\n",
      "Epoch 12602, Loss: 437.84478759765625, Neurons: 11, Grad norm: 1.863e+02\n",
      "Epoch 12603, Loss: 437.84368896484375, Neurons: 11, Grad norm: 2.231e+02\n",
      "Epoch 12604, Loss: 437.84197998046875, Neurons: 11, Grad norm: 2.104e+02\n",
      "Epoch 12605, Loss: 437.83868408203125, Neurons: 11, Grad norm: 1.557e+02\n",
      "Epoch 12606, Loss: 437.8343505859375, Neurons: 11, Grad norm: 7.079e+01\n",
      "Epoch 12607, Loss: 437.8299865722656, Neurons: 11, Grad norm: 2.012e+01\n",
      "Epoch 12608, Loss: 437.8267822265625, Neurons: 11, Grad norm: 9.925e+01\n",
      "Epoch 12609, Loss: 437.8246765136719, Neurons: 11, Grad norm: 1.461e+02\n",
      "Epoch 12610, Loss: 437.8227844238281, Neurons: 11, Grad norm: 1.574e+02\n",
      "Epoch 12611, Loss: 437.82012939453125, Neurons: 11, Grad norm: 1.295e+02\n",
      "Epoch 12612, Loss: 437.8167419433594, Neurons: 11, Grad norm: 7.513e+01\n",
      "Epoch 12613, Loss: 437.81304931640625, Neurons: 11, Grad norm: 7.121e+00\n",
      "Epoch 12614, Loss: 437.8097839355469, Neurons: 11, Grad norm: 5.487e+01\n",
      "Epoch 12615, Loss: 437.80718994140625, Neurons: 11, Grad norm: 9.932e+01\n",
      "Epoch 12616, Loss: 437.8048400878906, Neurons: 11, Grad norm: 1.145e+02\n",
      "Epoch 12617, Loss: 437.8022766113281, Neurons: 11, Grad norm: 1.029e+02\n",
      "Epoch 12618, Loss: 437.7992858886719, Neurons: 11, Grad norm: 6.611e+01\n",
      "Epoch 12619, Loss: 437.7959899902344, Neurons: 11, Grad norm: 1.930e+01\n",
      "Epoch 12620, Loss: 437.79278564453125, Neurons: 11, Grad norm: 2.923e+01\n",
      "Epoch 12621, Loss: 437.7900390625, Neurons: 11, Grad norm: 6.437e+01\n",
      "Epoch 12622, Loss: 437.7874755859375, Neurons: 11, Grad norm: 8.254e+01\n",
      "Epoch 12623, Loss: 437.7848815917969, Neurons: 11, Grad norm: 7.862e+01\n",
      "Epoch 12624, Loss: 437.781982421875, Neurons: 11, Grad norm: 5.815e+01\n",
      "Epoch 12625, Loss: 437.77899169921875, Neurons: 11, Grad norm: 2.455e+01\n",
      "Epoch 12626, Loss: 437.77587890625, Neurons: 11, Grad norm: 9.680e+00\n",
      "Epoch 12627, Loss: 437.7730407714844, Neurons: 11, Grad norm: 3.985e+01\n",
      "Epoch 12628, Loss: 437.77032470703125, Neurons: 11, Grad norm: 5.637e+01\n",
      "Epoch 12629, Loss: 437.767578125, Neurons: 11, Grad norm: 6.007e+01\n",
      "Epoch 12630, Loss: 437.764892578125, Neurons: 11, Grad norm: 4.840e+01\n",
      "Epoch 12631, Loss: 437.76190185546875, Neurons: 11, Grad norm: 2.863e+01\n",
      "Epoch 12632, Loss: 437.7589416503906, Neurons: 11, Grad norm: 3.145e+00\n",
      "Epoch 12633, Loss: 437.756103515625, Neurons: 11, Grad norm: 1.976e+01\n",
      "Epoch 12634, Loss: 437.7532958984375, Neurons: 11, Grad norm: 3.707e+01\n",
      "Epoch 12635, Loss: 437.75048828125, Neurons: 11, Grad norm: 4.336e+01\n",
      "Epoch 12636, Loss: 437.7476806640625, Neurons: 11, Grad norm: 4.134e+01\n",
      "Epoch 12637, Loss: 437.7449035644531, Neurons: 11, Grad norm: 2.909e+01\n",
      "Epoch 12638, Loss: 437.7419738769531, Neurons: 11, Grad norm: 1.364e+01\n",
      "Epoch 12639, Loss: 437.73907470703125, Neurons: 11, Grad norm: 5.571e+00\n",
      "Epoch 12640, Loss: 437.7361755371094, Neurons: 11, Grad norm: 1.933e+01\n",
      "Epoch 12641, Loss: 437.7333984375, Neurons: 11, Grad norm: 2.954e+01\n",
      "Epoch 12642, Loss: 437.7305908203125, Neurons: 11, Grad norm: 3.161e+01\n",
      "Epoch 12643, Loss: 437.727783203125, Neurons: 11, Grad norm: 2.859e+01\n",
      "Epoch 12644, Loss: 437.7248840332031, Neurons: 11, Grad norm: 1.847e+01\n",
      "Epoch 12645, Loss: 437.7220458984375, Neurons: 11, Grad norm: 7.358e+00\n",
      "Epoch 12646, Loss: 437.71917724609375, Neurons: 11, Grad norm: 6.403e+00\n",
      "Epoch 12647, Loss: 437.7162780761719, Neurons: 11, Grad norm: 1.531e+01\n",
      "Epoch 12648, Loss: 437.7135009765625, Neurons: 11, Grad norm: 2.253e+01\n",
      "Epoch 12649, Loss: 437.710693359375, Neurons: 11, Grad norm: 2.317e+01\n",
      "Epoch 12649, Test loss: 434.0872497558594\n",
      "Epoch 12650, Loss: 437.7077941894531, Neurons: 11, Grad norm: 2.080e+01\n",
      "Epoch 12651, Loss: 437.7049865722656, Neurons: 11, Grad norm: 1.346e+01\n",
      "Epoch 12652, Loss: 437.70208740234375, Neurons: 11, Grad norm: 5.882e+00\n",
      "Epoch 12653, Loss: 437.6991882324219, Neurons: 11, Grad norm: 4.269e+00\n",
      "Epoch 12654, Loss: 437.6963806152344, Neurons: 11, Grad norm: 1.021e+01\n",
      "Epoch 12655, Loss: 437.6934814453125, Neurons: 11, Grad norm: 1.611e+01\n",
      "Epoch 12656, Loss: 437.690673828125, Neurons: 11, Grad norm: 1.700e+01\n",
      "Epoch 12657, Loss: 437.6878356933594, Neurons: 11, Grad norm: 1.669e+01\n",
      "Epoch 12658, Loss: 437.68499755859375, Neurons: 11, Grad norm: 1.217e+01\n",
      "Epoch 12659, Loss: 437.68212890625, Neurons: 11, Grad norm: 7.772e+00\n",
      "Epoch 12660, Loss: 437.6792907714844, Neurons: 11, Grad norm: 2.004e+00\n",
      "Epoch 12661, Loss: 437.6763916015625, Neurons: 11, Grad norm: 4.223e+00\n",
      "Epoch 12662, Loss: 437.6735534667969, Neurons: 11, Grad norm: 9.062e+00\n",
      "Epoch 12663, Loss: 437.6706848144531, Neurons: 11, Grad norm: 9.903e+00\n",
      "Epoch 12664, Loss: 437.6678466796875, Neurons: 11, Grad norm: 1.114e+01\n",
      "Epoch 12665, Loss: 437.66497802734375, Neurons: 11, Grad norm: 8.495e+00\n",
      "Epoch 12666, Loss: 437.6620788574219, Neurons: 11, Grad norm: 6.570e+00\n",
      "Epoch 12667, Loss: 437.65924072265625, Neurons: 11, Grad norm: 3.035e+00\n",
      "Epoch 12668, Loss: 437.6563415527344, Neurons: 11, Grad norm: 1.760e+00\n",
      "Epoch 12669, Loss: 437.65350341796875, Neurons: 11, Grad norm: 4.111e+00\n",
      "Epoch 12670, Loss: 437.650634765625, Neurons: 11, Grad norm: 4.697e+00\n",
      "Epoch 12671, Loss: 437.6477355957031, Neurons: 11, Grad norm: 6.636e+00\n",
      "Epoch 12672, Loss: 437.6448974609375, Neurons: 11, Grad norm: 5.578e+00\n",
      "Epoch 12673, Loss: 437.64208984375, Neurons: 11, Grad norm: 5.662e+00\n",
      "Epoch 12674, Loss: 437.6391906738281, Neurons: 11, Grad norm: 3.534e+00\n",
      "Epoch 12675, Loss: 437.63629150390625, Neurons: 11, Grad norm: 2.695e+00\n",
      "Epoch 12676, Loss: 437.6333923339844, Neurons: 11, Grad norm: 1.872e+00\n",
      "Epoch 12677, Loss: 437.6304931640625, Neurons: 11, Grad norm: 2.376e+00\n",
      "Epoch 12678, Loss: 437.627685546875, Neurons: 11, Grad norm: 4.176e+00\n",
      "Epoch 12679, Loss: 437.6247863769531, Neurons: 11, Grad norm: 3.997e+00\n",
      "Epoch 12680, Loss: 437.62188720703125, Neurons: 11, Grad norm: 5.048e+00\n",
      "Epoch 12681, Loss: 437.6189880371094, Neurons: 11, Grad norm: 3.730e+00\n",
      "Epoch 12682, Loss: 437.61614990234375, Neurons: 11, Grad norm: 3.771e+00\n",
      "Epoch 12683, Loss: 437.61328125, Neurons: 11, Grad norm: 2.137e+00\n",
      "Epoch 12684, Loss: 437.6103820800781, Neurons: 11, Grad norm: 1.894e+00\n",
      "Epoch 12685, Loss: 437.60748291015625, Neurons: 11, Grad norm: 2.227e+00\n",
      "Epoch 12686, Loss: 437.6045837402344, Neurons: 11, Grad norm: 2.446e+00\n",
      "Epoch 12687, Loss: 437.60174560546875, Neurons: 11, Grad norm: 3.804e+00\n",
      "Epoch 12688, Loss: 437.5988464355469, Neurons: 11, Grad norm: 3.561e+00\n",
      "Epoch 12689, Loss: 437.595947265625, Neurons: 11, Grad norm: 4.527e+00\n",
      "Epoch 12690, Loss: 437.5930480957031, Neurons: 11, Grad norm: 3.147e+00\n",
      "Epoch 12691, Loss: 437.5901794433594, Neurons: 11, Grad norm: 3.531e+00\n",
      "Epoch 12692, Loss: 437.5872802734375, Neurons: 11, Grad norm: 2.202e+00\n",
      "Epoch 12693, Loss: 437.5843811035156, Neurons: 11, Grad norm: 1.934e+00\n",
      "Epoch 12694, Loss: 437.58148193359375, Neurons: 11, Grad norm: 1.939e+00\n",
      "Epoch 12695, Loss: 437.5785827636719, Neurons: 11, Grad norm: 2.020e+00\n",
      "Epoch 12696, Loss: 437.57568359375, Neurons: 11, Grad norm: 3.160e+00\n",
      "Epoch 12697, Loss: 437.5727844238281, Neurons: 11, Grad norm: 2.402e+00\n",
      "Epoch 12698, Loss: 437.56988525390625, Neurons: 11, Grad norm: 3.267e+00\n",
      "Epoch 12699, Loss: 437.5670471191406, Neurons: 11, Grad norm: 2.312e+00\n",
      "Epoch 12699, Test loss: 433.9432067871094\n",
      "Epoch 12700, Loss: 437.5640869140625, Neurons: 11, Grad norm: 2.692e+00\n",
      "Epoch 12701, Loss: 437.5611877441406, Neurons: 11, Grad norm: 2.243e+00\n",
      "Epoch 12702, Loss: 437.55828857421875, Neurons: 11, Grad norm: 2.516e+00\n",
      "Epoch 12703, Loss: 437.5553894042969, Neurons: 11, Grad norm: 1.808e+00\n",
      "Epoch 12704, Loss: 437.552490234375, Neurons: 11, Grad norm: 1.957e+00\n",
      "Epoch 12705, Loss: 437.5495910644531, Neurons: 11, Grad norm: 1.917e+00\n",
      "Epoch 12706, Loss: 437.54669189453125, Neurons: 11, Grad norm: 1.778e+00\n",
      "Epoch 12707, Loss: 437.5437927246094, Neurons: 11, Grad norm: 2.299e+00\n",
      "Epoch 12708, Loss: 437.5408935546875, Neurons: 11, Grad norm: 2.283e+00\n",
      "Epoch 12709, Loss: 437.5379943847656, Neurons: 11, Grad norm: 3.475e+00\n",
      "Epoch 12710, Loss: 437.5350341796875, Neurons: 11, Grad norm: 3.021e+00\n",
      "Epoch 12711, Loss: 437.5321350097656, Neurons: 11, Grad norm: 3.764e+00\n",
      "Epoch 12712, Loss: 437.52923583984375, Neurons: 11, Grad norm: 2.830e+00\n",
      "Epoch 12713, Loss: 437.5262756347656, Neurons: 11, Grad norm: 3.245e+00\n",
      "Epoch 12714, Loss: 437.52337646484375, Neurons: 11, Grad norm: 2.263e+00\n",
      "Epoch 12715, Loss: 437.5204772949219, Neurons: 11, Grad norm: 2.504e+00\n",
      "Epoch 12716, Loss: 437.517578125, Neurons: 11, Grad norm: 1.779e+00\n",
      "Epoch 12717, Loss: 437.5146484375, Neurons: 11, Grad norm: 1.818e+00\n",
      "Epoch 12718, Loss: 437.5117492675781, Neurons: 11, Grad norm: 2.063e+00\n",
      "Epoch 12719, Loss: 437.5087890625, Neurons: 11, Grad norm: 1.967e+00\n",
      "Epoch 12720, Loss: 437.5058898925781, Neurons: 11, Grad norm: 2.847e+00\n",
      "Epoch 12721, Loss: 437.50299072265625, Neurons: 11, Grad norm: 2.599e+00\n",
      "Epoch 12722, Loss: 437.5000305175781, Neurons: 11, Grad norm: 4.010e+00\n",
      "Epoch 12723, Loss: 437.4971008300781, Neurons: 11, Grad norm: 3.545e+00\n",
      "Epoch 12724, Loss: 437.49420166015625, Neurons: 11, Grad norm: 4.662e+00\n",
      "Epoch 12725, Loss: 437.4913024902344, Neurons: 11, Grad norm: 4.529e+00\n",
      "Epoch 12726, Loss: 437.48834228515625, Neurons: 11, Grad norm: 5.414e+00\n",
      "Epoch 12727, Loss: 437.4853820800781, Neurons: 11, Grad norm: 4.800e+00\n",
      "Epoch 12728, Loss: 437.48248291015625, Neurons: 11, Grad norm: 5.713e+00\n",
      "Epoch 12729, Loss: 437.4795837402344, Neurons: 11, Grad norm: 4.738e+00\n",
      "Epoch 12730, Loss: 437.4765930175781, Neurons: 11, Grad norm: 5.972e+00\n",
      "Epoch 12731, Loss: 437.4736328125, Neurons: 11, Grad norm: 4.898e+00\n",
      "Epoch 12732, Loss: 437.470703125, Neurons: 11, Grad norm: 5.664e+00\n",
      "Epoch 12733, Loss: 437.46783447265625, Neurons: 11, Grad norm: 4.843e+00\n",
      "Epoch 12734, Loss: 437.4648742675781, Neurons: 11, Grad norm: 4.760e+00\n",
      "Epoch 12735, Loss: 437.4619445800781, Neurons: 11, Grad norm: 3.730e+00\n",
      "Epoch 12736, Loss: 437.458984375, Neurons: 11, Grad norm: 4.287e+00\n",
      "Epoch 12737, Loss: 437.4560241699219, Neurons: 11, Grad norm: 2.953e+00\n",
      "Epoch 12738, Loss: 437.4530944824219, Neurons: 11, Grad norm: 3.603e+00\n",
      "Epoch 12739, Loss: 437.45013427734375, Neurons: 11, Grad norm: 2.428e+00\n",
      "Epoch 12740, Loss: 437.4472351074219, Neurons: 11, Grad norm: 2.798e+00\n",
      "Epoch 12741, Loss: 437.44427490234375, Neurons: 11, Grad norm: 2.359e+00\n",
      "Epoch 12742, Loss: 437.4413757324219, Neurons: 11, Grad norm: 3.129e+00\n",
      "Epoch 12743, Loss: 437.4383850097656, Neurons: 11, Grad norm: 2.703e+00\n",
      "Epoch 12744, Loss: 437.4354248046875, Neurons: 11, Grad norm: 3.619e+00\n",
      "Epoch 12745, Loss: 437.4324951171875, Neurons: 11, Grad norm: 3.104e+00\n",
      "Epoch 12746, Loss: 437.4295349121094, Neurons: 11, Grad norm: 4.191e+00\n",
      "Epoch 12747, Loss: 437.42657470703125, Neurons: 11, Grad norm: 3.666e+00\n",
      "Epoch 12748, Loss: 437.42364501953125, Neurons: 11, Grad norm: 4.826e+00\n",
      "Epoch 12749, Loss: 437.4206848144531, Neurons: 11, Grad norm: 4.304e+00\n",
      "Epoch 12749, Test loss: 433.8021240234375\n",
      "Epoch 12750, Loss: 437.417724609375, Neurons: 11, Grad norm: 5.359e+00\n",
      "Epoch 12751, Loss: 437.414794921875, Neurons: 11, Grad norm: 4.953e+00\n",
      "Epoch 12752, Loss: 437.4118347167969, Neurons: 11, Grad norm: 6.070e+00\n",
      "Epoch 12753, Loss: 437.4088439941406, Neurons: 11, Grad norm: 5.839e+00\n",
      "Epoch 12754, Loss: 437.4058837890625, Neurons: 11, Grad norm: 7.748e+00\n",
      "Epoch 12755, Loss: 437.40289306640625, Neurons: 11, Grad norm: 8.199e+00\n",
      "Epoch 12756, Loss: 437.3999938964844, Neurons: 11, Grad norm: 1.081e+01\n",
      "Epoch 12757, Loss: 437.3970947265625, Neurons: 11, Grad norm: 1.215e+01\n",
      "Epoch 12758, Loss: 437.39410400390625, Neurons: 11, Grad norm: 1.575e+01\n",
      "Epoch 12759, Loss: 437.3911437988281, Neurons: 11, Grad norm: 1.831e+01\n",
      "Epoch 12760, Loss: 437.38818359375, Neurons: 11, Grad norm: 2.277e+01\n",
      "Epoch 12761, Loss: 437.38519287109375, Neurons: 11, Grad norm: 2.622e+01\n",
      "Epoch 12762, Loss: 437.3822326660156, Neurons: 11, Grad norm: 3.270e+01\n",
      "Epoch 12763, Loss: 437.3793029785156, Neurons: 11, Grad norm: 3.856e+01\n",
      "Epoch 12764, Loss: 437.37640380859375, Neurons: 11, Grad norm: 4.782e+01\n",
      "Epoch 12765, Loss: 437.37347412109375, Neurons: 11, Grad norm: 5.730e+01\n",
      "Epoch 12766, Loss: 437.3705749511719, Neurons: 11, Grad norm: 7.070e+01\n",
      "Epoch 12767, Loss: 437.36767578125, Neurons: 11, Grad norm: 8.535e+01\n",
      "Epoch 12768, Loss: 437.36492919921875, Neurons: 11, Grad norm: 1.054e+02\n",
      "Epoch 12769, Loss: 437.36224365234375, Neurons: 11, Grad norm: 1.278e+02\n",
      "Epoch 12770, Loss: 437.35968017578125, Neurons: 11, Grad norm: 1.564e+02\n",
      "Epoch 12771, Loss: 437.3573303222656, Neurons: 11, Grad norm: 1.877e+02\n",
      "Epoch 12772, Loss: 437.3551940917969, Neurons: 11, Grad norm: 2.244e+02\n",
      "Epoch 12773, Loss: 437.35333251953125, Neurons: 11, Grad norm: 2.607e+02\n",
      "Epoch 12774, Loss: 437.3517761230469, Neurons: 11, Grad norm: 2.955e+02\n",
      "Epoch 12775, Loss: 437.35028076171875, Neurons: 11, Grad norm: 3.178e+02\n",
      "Epoch 12776, Loss: 437.3484802246094, Neurons: 11, Grad norm: 3.211e+02\n",
      "Epoch 12777, Loss: 437.3457336425781, Neurons: 11, Grad norm: 2.927e+02\n",
      "Epoch 12778, Loss: 437.3415832519531, Neurons: 11, Grad norm: 2.331e+02\n",
      "Epoch 12779, Loss: 437.3363952636719, Neurons: 11, Grad norm: 1.442e+02\n",
      "Epoch 12780, Loss: 437.3310241699219, Neurons: 11, Grad norm: 4.406e+01\n",
      "Epoch 12781, Loss: 437.3267517089844, Neurons: 11, Grad norm: 5.469e+01\n",
      "Epoch 12782, Loss: 437.323974609375, Neurons: 11, Grad norm: 1.334e+02\n",
      "Epoch 12783, Loss: 437.3222961425781, Neurons: 11, Grad norm: 1.842e+02\n",
      "Epoch 12784, Loss: 437.3206787109375, Neurons: 11, Grad norm: 1.981e+02\n",
      "Epoch 12785, Loss: 437.31829833984375, Neurons: 11, Grad norm: 1.777e+02\n",
      "Epoch 12786, Loss: 437.31488037109375, Neurons: 11, Grad norm: 1.254e+02\n",
      "Epoch 12787, Loss: 437.31097412109375, Neurons: 11, Grad norm: 5.640e+01\n",
      "Epoch 12788, Loss: 437.30718994140625, Neurons: 11, Grad norm: 1.827e+01\n",
      "Epoch 12789, Loss: 437.30419921875, Neurons: 11, Grad norm: 7.993e+01\n",
      "Epoch 12790, Loss: 437.3018493652344, Neurons: 11, Grad norm: 1.224e+02\n",
      "Epoch 12791, Loss: 437.2996826171875, Neurons: 11, Grad norm: 1.359e+02\n",
      "Epoch 12792, Loss: 437.29718017578125, Neurons: 11, Grad norm: 1.235e+02\n",
      "Epoch 12793, Loss: 437.294189453125, Neurons: 11, Grad norm: 8.631e+01\n",
      "Epoch 12794, Loss: 437.2907409667969, Neurons: 11, Grad norm: 3.690e+01\n",
      "Epoch 12795, Loss: 437.2874755859375, Neurons: 11, Grad norm: 1.623e+01\n",
      "Epoch 12796, Loss: 437.2846984863281, Neurons: 11, Grad norm: 5.894e+01\n",
      "Epoch 12797, Loss: 437.2820739746094, Neurons: 11, Grad norm: 8.764e+01\n",
      "Epoch 12798, Loss: 437.27960205078125, Neurons: 11, Grad norm: 9.456e+01\n",
      "Epoch 12799, Loss: 437.27703857421875, Neurons: 11, Grad norm: 8.407e+01\n",
      "Epoch 12799, Test loss: 433.6435852050781\n",
      "Epoch 12800, Loss: 437.27398681640625, Neurons: 11, Grad norm: 5.686e+01\n",
      "Epoch 12801, Loss: 437.27099609375, Neurons: 11, Grad norm: 2.324e+01\n",
      "Epoch 12802, Loss: 437.2679748535156, Neurons: 11, Grad norm: 1.316e+01\n",
      "Epoch 12803, Loss: 437.26507568359375, Neurons: 11, Grad norm: 4.169e+01\n",
      "Epoch 12804, Loss: 437.2624816894531, Neurons: 11, Grad norm: 6.115e+01\n",
      "Epoch 12805, Loss: 437.25982666015625, Neurons: 11, Grad norm: 6.568e+01\n",
      "Epoch 12806, Loss: 437.257080078125, Neurons: 11, Grad norm: 5.946e+01\n",
      "Epoch 12807, Loss: 437.2542419433594, Neurons: 11, Grad norm: 4.087e+01\n",
      "Epoch 12808, Loss: 437.25128173828125, Neurons: 11, Grad norm: 1.849e+01\n",
      "Epoch 12809, Loss: 437.2483825683594, Neurons: 11, Grad norm: 6.834e+00\n",
      "Epoch 12810, Loss: 437.2455749511719, Neurons: 11, Grad norm: 2.658e+01\n",
      "Epoch 12811, Loss: 437.2428894042969, Neurons: 11, Grad norm: 4.106e+01\n",
      "Epoch 12812, Loss: 437.2402038574219, Neurons: 11, Grad norm: 4.548e+01\n",
      "Epoch 12813, Loss: 437.2373962402344, Neurons: 11, Grad norm: 4.259e+01\n",
      "Epoch 12814, Loss: 437.2345886230469, Neurons: 11, Grad norm: 3.068e+01\n",
      "Epoch 12815, Loss: 437.231689453125, Neurons: 11, Grad norm: 1.676e+01\n",
      "Epoch 12816, Loss: 437.2288818359375, Neurons: 11, Grad norm: 1.957e+00\n",
      "Epoch 12817, Loss: 437.22607421875, Neurons: 11, Grad norm: 1.481e+01\n",
      "Epoch 12818, Loss: 437.2232971191406, Neurons: 11, Grad norm: 2.610e+01\n",
      "Epoch 12819, Loss: 437.2204895019531, Neurons: 11, Grad norm: 3.067e+01\n",
      "Epoch 12820, Loss: 437.2177429199219, Neurons: 11, Grad norm: 3.114e+01\n",
      "Epoch 12821, Loss: 437.2149353027344, Neurons: 11, Grad norm: 2.529e+01\n",
      "Epoch 12822, Loss: 437.21209716796875, Neurons: 11, Grad norm: 1.761e+01\n",
      "Epoch 12823, Loss: 437.20928955078125, Neurons: 11, Grad norm: 6.465e+00\n",
      "Epoch 12824, Loss: 437.20648193359375, Neurons: 11, Grad norm: 3.763e+00\n",
      "Epoch 12825, Loss: 437.20367431640625, Neurons: 11, Grad norm: 1.336e+01\n",
      "Epoch 12826, Loss: 437.2008361816406, Neurons: 11, Grad norm: 1.840e+01\n",
      "Epoch 12827, Loss: 437.1980895996094, Neurons: 11, Grad norm: 2.186e+01\n",
      "Epoch 12828, Loss: 437.1952819824219, Neurons: 11, Grad norm: 2.003e+01\n",
      "Epoch 12829, Loss: 437.1924743652344, Neurons: 11, Grad norm: 1.735e+01\n",
      "Epoch 12830, Loss: 437.18963623046875, Neurons: 11, Grad norm: 1.123e+01\n",
      "Epoch 12831, Loss: 437.1867980957031, Neurons: 11, Grad norm: 5.842e+00\n",
      "Epoch 12832, Loss: 437.1839904785156, Neurons: 11, Grad norm: 2.208e+00\n",
      "Epoch 12833, Loss: 437.1811828613281, Neurons: 11, Grad norm: 5.808e+00\n",
      "Epoch 12834, Loss: 437.1783752441406, Neurons: 11, Grad norm: 1.055e+01\n",
      "Epoch 12835, Loss: 437.17559814453125, Neurons: 11, Grad norm: 1.212e+01\n",
      "Epoch 12836, Loss: 437.17279052734375, Neurons: 11, Grad norm: 1.333e+01\n",
      "Epoch 12837, Loss: 437.1699523925781, Neurons: 11, Grad norm: 1.114e+01\n",
      "Epoch 12838, Loss: 437.1670837402344, Neurons: 11, Grad norm: 9.825e+00\n",
      "Epoch 12839, Loss: 437.1642761230469, Neurons: 11, Grad norm: 5.386e+00\n",
      "Epoch 12840, Loss: 437.1614990234375, Neurons: 11, Grad norm: 2.633e+00\n",
      "Epoch 12841, Loss: 437.15869140625, Neurons: 11, Grad norm: 3.177e+00\n",
      "Epoch 12842, Loss: 437.1557922363281, Neurons: 11, Grad norm: 5.931e+00\n",
      "Epoch 12843, Loss: 437.1529846191406, Neurons: 11, Grad norm: 9.300e+00\n",
      "Epoch 12844, Loss: 437.1501770019531, Neurons: 11, Grad norm: 1.020e+01\n",
      "Epoch 12845, Loss: 437.1473388671875, Neurons: 11, Grad norm: 1.166e+01\n",
      "Epoch 12846, Loss: 437.14453125, Neurons: 11, Grad norm: 9.628e+00\n",
      "Epoch 12847, Loss: 437.1416931152344, Neurons: 11, Grad norm: 8.776e+00\n",
      "Epoch 12848, Loss: 437.1388854980469, Neurons: 11, Grad norm: 5.409e+00\n",
      "Epoch 12849, Loss: 437.13604736328125, Neurons: 11, Grad norm: 3.565e+00\n",
      "Epoch 12849, Test loss: 433.5242004394531\n",
      "Epoch 12850, Loss: 437.1331787109375, Neurons: 11, Grad norm: 1.761e+00\n",
      "Epoch 12851, Loss: 437.1304016113281, Neurons: 11, Grad norm: 2.751e+00\n",
      "Epoch 12852, Loss: 437.1275329589844, Neurons: 11, Grad norm: 5.213e+00\n",
      "Epoch 12853, Loss: 437.12469482421875, Neurons: 11, Grad norm: 5.751e+00\n",
      "Epoch 12854, Loss: 437.121826171875, Neurons: 11, Grad norm: 7.316e+00\n",
      "Epoch 12855, Loss: 437.1189880371094, Neurons: 11, Grad norm: 6.275e+00\n",
      "Epoch 12856, Loss: 437.1161804199219, Neurons: 11, Grad norm: 6.557e+00\n",
      "Epoch 12857, Loss: 437.1134033203125, Neurons: 11, Grad norm: 4.563e+00\n",
      "Epoch 12858, Loss: 437.11053466796875, Neurons: 11, Grad norm: 3.929e+00\n",
      "Epoch 12859, Loss: 437.10772705078125, Neurons: 11, Grad norm: 2.025e+00\n",
      "Epoch 12860, Loss: 437.1048278808594, Neurons: 11, Grad norm: 1.722e+00\n",
      "Epoch 12861, Loss: 437.10198974609375, Neurons: 11, Grad norm: 2.681e+00\n",
      "Epoch 12862, Loss: 437.0991516113281, Neurons: 11, Grad norm: 2.666e+00\n",
      "Epoch 12863, Loss: 437.0963439941406, Neurons: 11, Grad norm: 4.252e+00\n",
      "Epoch 12864, Loss: 437.0934753417969, Neurons: 11, Grad norm: 3.803e+00\n",
      "Epoch 12865, Loss: 437.090576171875, Neurons: 11, Grad norm: 4.260e+00\n",
      "Epoch 12866, Loss: 437.0877990722656, Neurons: 11, Grad norm: 3.254e+00\n",
      "Epoch 12867, Loss: 437.0849914550781, Neurons: 11, Grad norm: 3.370e+00\n",
      "Epoch 12868, Loss: 437.08209228515625, Neurons: 11, Grad norm: 2.124e+00\n",
      "Epoch 12869, Loss: 437.0791931152344, Neurons: 11, Grad norm: 2.232e+00\n",
      "Epoch 12870, Loss: 437.0763854980469, Neurons: 11, Grad norm: 1.958e+00\n",
      "Epoch 12871, Loss: 437.073486328125, Neurons: 11, Grad norm: 1.887e+00\n",
      "Epoch 12872, Loss: 437.0706787109375, Neurons: 11, Grad norm: 2.938e+00\n",
      "Epoch 12873, Loss: 437.0677795410156, Neurons: 11, Grad norm: 2.809e+00\n",
      "Epoch 12874, Loss: 437.06494140625, Neurons: 11, Grad norm: 3.670e+00\n",
      "Epoch 12875, Loss: 437.0621032714844, Neurons: 11, Grad norm: 3.758e+00\n",
      "Epoch 12876, Loss: 437.0592346191406, Neurons: 11, Grad norm: 4.688e+00\n",
      "Epoch 12877, Loss: 437.056396484375, Neurons: 11, Grad norm: 4.069e+00\n",
      "Epoch 12878, Loss: 437.0534973144531, Neurons: 11, Grad norm: 5.588e+00\n",
      "Epoch 12879, Loss: 437.0506896972656, Neurons: 11, Grad norm: 4.465e+00\n",
      "Epoch 12880, Loss: 437.04779052734375, Neurons: 11, Grad norm: 5.279e+00\n",
      "Epoch 12881, Loss: 437.0448913574219, Neurons: 11, Grad norm: 4.240e+00\n",
      "Epoch 12882, Loss: 437.0420837402344, Neurons: 11, Grad norm: 4.448e+00\n",
      "Epoch 12883, Loss: 437.0391845703125, Neurons: 11, Grad norm: 3.564e+00\n",
      "Epoch 12884, Loss: 437.0363464355469, Neurons: 11, Grad norm: 3.674e+00\n",
      "Epoch 12885, Loss: 437.0334777832031, Neurons: 11, Grad norm: 2.548e+00\n",
      "Epoch 12886, Loss: 437.03057861328125, Neurons: 11, Grad norm: 2.772e+00\n",
      "Epoch 12887, Loss: 437.0276794433594, Neurons: 11, Grad norm: 1.767e+00\n",
      "Epoch 12888, Loss: 437.02484130859375, Neurons: 11, Grad norm: 1.874e+00\n",
      "Epoch 12889, Loss: 437.0220031738281, Neurons: 11, Grad norm: 1.959e+00\n",
      "Epoch 12890, Loss: 437.01910400390625, Neurons: 11, Grad norm: 1.815e+00\n",
      "Epoch 12891, Loss: 437.01617431640625, Neurons: 11, Grad norm: 2.470e+00\n",
      "Epoch 12892, Loss: 437.0133972167969, Neurons: 11, Grad norm: 2.238e+00\n",
      "Epoch 12893, Loss: 437.010498046875, Neurons: 11, Grad norm: 2.857e+00\n",
      "Epoch 12894, Loss: 437.0075988769531, Neurons: 11, Grad norm: 2.454e+00\n",
      "Epoch 12895, Loss: 437.0047302246094, Neurons: 11, Grad norm: 3.288e+00\n",
      "Epoch 12896, Loss: 437.0018310546875, Neurons: 11, Grad norm: 2.232e+00\n",
      "Epoch 12897, Loss: 436.9989929199219, Neurons: 11, Grad norm: 2.893e+00\n",
      "Epoch 12898, Loss: 436.99609375, Neurons: 11, Grad norm: 2.007e+00\n",
      "Epoch 12899, Loss: 436.99322509765625, Neurons: 11, Grad norm: 2.087e+00\n",
      "Epoch 12899, Test loss: 433.3861389160156\n",
      "Epoch 12900, Loss: 436.99029541015625, Neurons: 11, Grad norm: 1.724e+00\n",
      "Epoch 12901, Loss: 436.9873962402344, Neurons: 11, Grad norm: 1.829e+00\n",
      "Epoch 12902, Loss: 436.9844970703125, Neurons: 11, Grad norm: 1.734e+00\n",
      "Epoch 12903, Loss: 436.9815979003906, Neurons: 11, Grad norm: 1.782e+00\n",
      "Epoch 12904, Loss: 436.9787902832031, Neurons: 11, Grad norm: 2.242e+00\n",
      "Epoch 12905, Loss: 436.97589111328125, Neurons: 11, Grad norm: 1.879e+00\n",
      "Epoch 12906, Loss: 436.9729919433594, Neurons: 11, Grad norm: 2.705e+00\n",
      "Epoch 12907, Loss: 436.9700927734375, Neurons: 11, Grad norm: 2.449e+00\n",
      "Epoch 12908, Loss: 436.9671936035156, Neurons: 11, Grad norm: 3.272e+00\n",
      "Epoch 12909, Loss: 436.96429443359375, Neurons: 11, Grad norm: 3.463e+00\n",
      "Epoch 12910, Loss: 436.9613952636719, Neurons: 11, Grad norm: 4.479e+00\n",
      "Epoch 12911, Loss: 436.95849609375, Neurons: 11, Grad norm: 4.244e+00\n",
      "Epoch 12912, Loss: 436.9555969238281, Neurons: 11, Grad norm: 6.274e+00\n",
      "Epoch 12913, Loss: 436.95269775390625, Neurons: 11, Grad norm: 5.966e+00\n",
      "Epoch 12914, Loss: 436.9497985839844, Neurons: 11, Grad norm: 8.013e+00\n",
      "Epoch 12915, Loss: 436.9468994140625, Neurons: 11, Grad norm: 8.344e+00\n",
      "Epoch 12916, Loss: 436.9440002441406, Neurons: 11, Grad norm: 1.032e+01\n",
      "Epoch 12917, Loss: 436.94110107421875, Neurons: 11, Grad norm: 1.142e+01\n",
      "Epoch 12918, Loss: 436.9382019042969, Neurons: 11, Grad norm: 1.392e+01\n",
      "Epoch 12919, Loss: 436.935302734375, Neurons: 11, Grad norm: 1.552e+01\n",
      "Epoch 12920, Loss: 436.9324035644531, Neurons: 11, Grad norm: 1.929e+01\n",
      "Epoch 12921, Loss: 436.9294738769531, Neurons: 11, Grad norm: 2.171e+01\n",
      "Epoch 12922, Loss: 436.92657470703125, Neurons: 11, Grad norm: 2.704e+01\n",
      "Epoch 12923, Loss: 436.9236755371094, Neurons: 11, Grad norm: 3.114e+01\n",
      "Epoch 12924, Loss: 436.9207763671875, Neurons: 11, Grad norm: 3.815e+01\n",
      "Epoch 12925, Loss: 436.9178771972656, Neurons: 11, Grad norm: 4.488e+01\n",
      "Epoch 12926, Loss: 436.91510009765625, Neurons: 11, Grad norm: 5.521e+01\n",
      "Epoch 12927, Loss: 436.9122314453125, Neurons: 11, Grad norm: 6.632e+01\n",
      "Epoch 12928, Loss: 436.909423828125, Neurons: 11, Grad norm: 8.165e+01\n",
      "Epoch 12929, Loss: 436.90667724609375, Neurons: 11, Grad norm: 9.936e+01\n",
      "Epoch 12930, Loss: 436.90399169921875, Neurons: 11, Grad norm: 1.228e+02\n",
      "Epoch 12931, Loss: 436.90142822265625, Neurons: 11, Grad norm: 1.492e+02\n",
      "Epoch 12932, Loss: 436.8990783691406, Neurons: 11, Grad norm: 1.831e+02\n",
      "Epoch 12933, Loss: 436.8970031738281, Neurons: 11, Grad norm: 2.193e+02\n",
      "Epoch 12934, Loss: 436.8952331542969, Neurons: 11, Grad norm: 2.599e+02\n",
      "Epoch 12935, Loss: 436.893798828125, Neurons: 11, Grad norm: 2.975e+02\n",
      "Epoch 12936, Loss: 436.8924865722656, Neurons: 11, Grad norm: 3.275e+02\n",
      "Epoch 12937, Loss: 436.8910827636719, Neurons: 11, Grad norm: 3.362e+02\n",
      "Epoch 12938, Loss: 436.8887023925781, Neurons: 11, Grad norm: 3.159e+02\n",
      "Epoch 12939, Loss: 436.8848876953125, Neurons: 11, Grad norm: 2.576e+02\n",
      "Epoch 12940, Loss: 436.87957763671875, Neurons: 11, Grad norm: 1.694e+02\n",
      "Epoch 12941, Loss: 436.8740539550781, Neurons: 11, Grad norm: 6.126e+01\n",
      "Epoch 12942, Loss: 436.869384765625, Neurons: 11, Grad norm: 4.459e+01\n",
      "Epoch 12943, Loss: 436.8665466308594, Neurons: 11, Grad norm: 1.343e+02\n",
      "Epoch 12944, Loss: 436.86492919921875, Neurons: 11, Grad norm: 1.910e+02\n",
      "Epoch 12945, Loss: 436.86358642578125, Neurons: 11, Grad norm: 2.104e+02\n",
      "Epoch 12946, Loss: 436.86138916015625, Neurons: 11, Grad norm: 1.880e+02\n",
      "Epoch 12947, Loss: 436.8580322265625, Neurons: 11, Grad norm: 1.329e+02\n",
      "Epoch 12948, Loss: 436.85394287109375, Neurons: 11, Grad norm: 5.494e+01\n",
      "Epoch 12949, Loss: 436.8501892089844, Neurons: 11, Grad norm: 2.480e+01\n",
      "Epoch 12949, Test loss: 433.2530212402344\n",
      "Epoch 12950, Loss: 436.84722900390625, Neurons: 11, Grad norm: 9.327e+01\n",
      "Epoch 12951, Loss: 436.84515380859375, Neurons: 11, Grad norm: 1.346e+02\n",
      "Epoch 12952, Loss: 436.84307861328125, Neurons: 11, Grad norm: 1.465e+02\n",
      "Epoch 12953, Loss: 436.840576171875, Neurons: 11, Grad norm: 1.253e+02\n",
      "Epoch 12954, Loss: 436.8374328613281, Neurons: 11, Grad norm: 8.167e+01\n",
      "Epoch 12955, Loss: 436.83404541015625, Neurons: 11, Grad norm: 2.398e+01\n",
      "Epoch 12956, Loss: 436.8309020996094, Neurons: 11, Grad norm: 3.181e+01\n",
      "Epoch 12957, Loss: 436.82818603515625, Neurons: 11, Grad norm: 7.669e+01\n",
      "Epoch 12958, Loss: 436.8258361816406, Neurons: 11, Grad norm: 9.917e+01\n",
      "Epoch 12959, Loss: 436.8233947753906, Neurons: 11, Grad norm: 1.005e+02\n",
      "Epoch 12960, Loss: 436.8206787109375, Neurons: 11, Grad norm: 7.931e+01\n",
      "Epoch 12961, Loss: 436.8177490234375, Neurons: 11, Grad norm: 4.543e+01\n",
      "Epoch 12962, Loss: 436.814697265625, Neurons: 11, Grad norm: 4.089e+00\n",
      "Epoch 12963, Loss: 436.81182861328125, Neurons: 11, Grad norm: 3.317e+01\n",
      "Epoch 12964, Loss: 436.8092041015625, Neurons: 11, Grad norm: 6.063e+01\n",
      "Epoch 12965, Loss: 436.80670166015625, Neurons: 11, Grad norm: 7.125e+01\n",
      "Epoch 12966, Loss: 436.8040771484375, Neurons: 11, Grad norm: 6.802e+01\n",
      "Epoch 12967, Loss: 436.8013000488281, Neurons: 11, Grad norm: 4.945e+01\n",
      "Epoch 12968, Loss: 436.7984313964844, Neurons: 11, Grad norm: 2.454e+01\n",
      "Epoch 12969, Loss: 436.7955322265625, Neurons: 11, Grad norm: 4.622e+00\n",
      "Epoch 12970, Loss: 436.79278564453125, Neurons: 11, Grad norm: 2.809e+01\n",
      "Epoch 12971, Loss: 436.79010009765625, Neurons: 11, Grad norm: 4.511e+01\n",
      "Epoch 12972, Loss: 436.7874755859375, Neurons: 11, Grad norm: 5.002e+01\n",
      "Epoch 12973, Loss: 436.7847900390625, Neurons: 11, Grad norm: 4.661e+01\n",
      "Epoch 12974, Loss: 436.78204345703125, Neurons: 11, Grad norm: 3.297e+01\n",
      "Epoch 12975, Loss: 436.779296875, Neurons: 11, Grad norm: 1.630e+01\n",
      "Epoch 12976, Loss: 436.7764892578125, Neurons: 11, Grad norm: 3.652e+00\n",
      "Epoch 12977, Loss: 436.77374267578125, Neurons: 11, Grad norm: 1.904e+01\n",
      "Epoch 12978, Loss: 436.77099609375, Neurons: 11, Grad norm: 3.127e+01\n",
      "Epoch 12979, Loss: 436.7683410644531, Neurons: 11, Grad norm: 3.466e+01\n",
      "Epoch 12980, Loss: 436.765625, Neurons: 11, Grad norm: 3.297e+01\n",
      "Epoch 12981, Loss: 436.76287841796875, Neurons: 11, Grad norm: 2.430e+01\n",
      "Epoch 12982, Loss: 436.7601013183594, Neurons: 11, Grad norm: 1.377e+01\n",
      "Epoch 12983, Loss: 436.75738525390625, Neurons: 11, Grad norm: 1.718e+00\n",
      "Epoch 12984, Loss: 436.75457763671875, Neurons: 11, Grad norm: 1.076e+01\n",
      "Epoch 12985, Loss: 436.75189208984375, Neurons: 11, Grad norm: 1.995e+01\n",
      "Epoch 12986, Loss: 436.7491760253906, Neurons: 11, Grad norm: 2.370e+01\n",
      "Epoch 12987, Loss: 436.74639892578125, Neurons: 11, Grad norm: 2.467e+01\n",
      "Epoch 12988, Loss: 436.7437438964844, Neurons: 11, Grad norm: 2.021e+01\n",
      "Epoch 12989, Loss: 436.7409362792969, Neurons: 11, Grad norm: 1.461e+01\n",
      "Epoch 12990, Loss: 436.7381896972656, Neurons: 11, Grad norm: 5.427e+00\n",
      "Epoch 12991, Loss: 436.7353820800781, Neurons: 11, Grad norm: 2.911e+00\n",
      "Epoch 12992, Loss: 436.7326965332031, Neurons: 11, Grad norm: 1.053e+01\n",
      "Epoch 12993, Loss: 436.72998046875, Neurons: 11, Grad norm: 1.452e+01\n",
      "Epoch 12994, Loss: 436.7272033691406, Neurons: 11, Grad norm: 1.708e+01\n",
      "Epoch 12995, Loss: 436.7244873046875, Neurons: 11, Grad norm: 1.523e+01\n",
      "Epoch 12996, Loss: 436.72174072265625, Neurons: 11, Grad norm: 1.257e+01\n",
      "Epoch 12997, Loss: 436.718994140625, Neurons: 11, Grad norm: 6.792e+00\n",
      "Epoch 12998, Loss: 436.71624755859375, Neurons: 11, Grad norm: 2.611e+00\n",
      "Epoch 12999, Loss: 436.7135009765625, Neurons: 11, Grad norm: 4.358e+00\n",
      "Epoch 12999, Test loss: 433.11407470703125\n",
      "Epoch 13000, Loss: 436.710693359375, Neurons: 11, Grad norm: 7.330e+00\n",
      "Epoch 13001, Loss: 436.7079772949219, Neurons: 11, Grad norm: 1.066e+01\n",
      "Epoch 13002, Loss: 436.7052307128906, Neurons: 11, Grad norm: 1.074e+01\n",
      "Epoch 13003, Loss: 436.7024841308594, Neurons: 11, Grad norm: 1.130e+01\n",
      "Epoch 13004, Loss: 436.6996765136719, Neurons: 11, Grad norm: 9.065e+00\n",
      "Epoch 13005, Loss: 436.6969299316406, Neurons: 11, Grad norm: 7.593e+00\n",
      "Epoch 13006, Loss: 436.6941833496094, Neurons: 11, Grad norm: 4.202e+00\n",
      "Epoch 13007, Loss: 436.6914367675781, Neurons: 11, Grad norm: 2.139e+00\n",
      "Epoch 13008, Loss: 436.6886901855469, Neurons: 11, Grad norm: 3.106e+00\n",
      "Epoch 13009, Loss: 436.6858825683594, Neurons: 11, Grad norm: 4.003e+00\n",
      "Epoch 13010, Loss: 436.6831970214844, Neurons: 11, Grad norm: 6.473e+00\n",
      "Epoch 13011, Loss: 436.6803894042969, Neurons: 11, Grad norm: 6.668e+00\n",
      "Epoch 13012, Loss: 436.6777038574219, Neurons: 11, Grad norm: 7.326e+00\n",
      "Epoch 13013, Loss: 436.6748962402344, Neurons: 11, Grad norm: 5.877e+00\n",
      "Epoch 13014, Loss: 436.6721496582031, Neurons: 11, Grad norm: 5.713e+00\n",
      "Epoch 13015, Loss: 436.6694030761719, Neurons: 11, Grad norm: 3.295e+00\n",
      "Epoch 13016, Loss: 436.6665954589844, Neurons: 11, Grad norm: 2.520e+00\n",
      "Epoch 13017, Loss: 436.6637878417969, Neurons: 11, Grad norm: 1.682e+00\n",
      "Epoch 13018, Loss: 436.6611022949219, Neurons: 11, Grad norm: 1.944e+00\n",
      "Epoch 13019, Loss: 436.6582946777344, Neurons: 11, Grad norm: 3.749e+00\n",
      "Epoch 13020, Loss: 436.6554870605469, Neurons: 11, Grad norm: 3.584e+00\n",
      "Epoch 13021, Loss: 436.6526794433594, Neurons: 11, Grad norm: 4.825e+00\n",
      "Epoch 13022, Loss: 436.6499328613281, Neurons: 11, Grad norm: 3.929e+00\n",
      "Epoch 13023, Loss: 436.6471862792969, Neurons: 11, Grad norm: 4.214e+00\n",
      "Epoch 13024, Loss: 436.6443786621094, Neurons: 11, Grad norm: 3.456e+00\n",
      "Epoch 13025, Loss: 436.6416015625, Neurons: 11, Grad norm: 3.992e+00\n",
      "Epoch 13026, Loss: 436.6388854980469, Neurons: 11, Grad norm: 2.840e+00\n",
      "Epoch 13027, Loss: 436.6360778808594, Neurons: 11, Grad norm: 3.158e+00\n",
      "Epoch 13028, Loss: 436.63330078125, Neurons: 11, Grad norm: 1.957e+00\n",
      "Epoch 13029, Loss: 436.6304931640625, Neurons: 11, Grad norm: 1.976e+00\n",
      "Epoch 13030, Loss: 436.62774658203125, Neurons: 11, Grad norm: 1.807e+00\n",
      "Epoch 13031, Loss: 436.62493896484375, Neurons: 11, Grad norm: 1.776e+00\n",
      "Epoch 13032, Loss: 436.62213134765625, Neurons: 11, Grad norm: 2.469e+00\n",
      "Epoch 13033, Loss: 436.619384765625, Neurons: 11, Grad norm: 2.152e+00\n",
      "Epoch 13034, Loss: 436.6165771484375, Neurons: 11, Grad norm: 2.855e+00\n",
      "Epoch 13035, Loss: 436.6138000488281, Neurons: 11, Grad norm: 2.223e+00\n",
      "Epoch 13036, Loss: 436.6109924316406, Neurons: 11, Grad norm: 2.742e+00\n",
      "Epoch 13037, Loss: 436.6082458496094, Neurons: 11, Grad norm: 2.042e+00\n",
      "Epoch 13038, Loss: 436.6054382324219, Neurons: 11, Grad norm: 2.445e+00\n",
      "Epoch 13039, Loss: 436.6026306152344, Neurons: 11, Grad norm: 1.781e+00\n",
      "Epoch 13040, Loss: 436.599853515625, Neurons: 11, Grad norm: 1.993e+00\n",
      "Epoch 13041, Loss: 436.5970458984375, Neurons: 11, Grad norm: 1.818e+00\n",
      "Epoch 13042, Loss: 436.59423828125, Neurons: 11, Grad norm: 1.721e+00\n",
      "Epoch 13043, Loss: 436.5914306640625, Neurons: 11, Grad norm: 2.180e+00\n",
      "Epoch 13044, Loss: 436.5886535644531, Neurons: 11, Grad norm: 2.267e+00\n",
      "Epoch 13045, Loss: 436.58587646484375, Neurons: 11, Grad norm: 3.060e+00\n",
      "Epoch 13046, Loss: 436.5830383300781, Neurons: 11, Grad norm: 2.650e+00\n",
      "Epoch 13047, Loss: 436.5802917480469, Neurons: 11, Grad norm: 3.495e+00\n",
      "Epoch 13048, Loss: 436.57745361328125, Neurons: 11, Grad norm: 2.171e+00\n",
      "Epoch 13049, Loss: 436.57464599609375, Neurons: 11, Grad norm: 2.586e+00\n",
      "Epoch 13049, Test loss: 432.97991943359375\n",
      "Epoch 13050, Loss: 436.5718994140625, Neurons: 11, Grad norm: 1.960e+00\n",
      "Epoch 13051, Loss: 436.56903076171875, Neurons: 11, Grad norm: 2.445e+00\n",
      "Epoch 13052, Loss: 436.5662536621094, Neurons: 11, Grad norm: 2.383e+00\n",
      "Epoch 13053, Loss: 436.5634460449219, Neurons: 11, Grad norm: 3.464e+00\n",
      "Epoch 13054, Loss: 436.5605773925781, Neurons: 11, Grad norm: 3.093e+00\n",
      "Epoch 13055, Loss: 436.55780029296875, Neurons: 11, Grad norm: 4.167e+00\n",
      "Epoch 13056, Loss: 436.55499267578125, Neurons: 11, Grad norm: 4.057e+00\n",
      "Epoch 13057, Loss: 436.55218505859375, Neurons: 11, Grad norm: 5.703e+00\n",
      "Epoch 13058, Loss: 436.54937744140625, Neurons: 11, Grad norm: 5.156e+00\n",
      "Epoch 13059, Loss: 436.5466003417969, Neurons: 11, Grad norm: 6.372e+00\n",
      "Epoch 13060, Loss: 436.543701171875, Neurons: 11, Grad norm: 6.302e+00\n",
      "Epoch 13061, Loss: 436.5409240722656, Neurons: 11, Grad norm: 7.708e+00\n",
      "Epoch 13062, Loss: 436.5380859375, Neurons: 11, Grad norm: 7.366e+00\n",
      "Epoch 13063, Loss: 436.5352783203125, Neurons: 11, Grad norm: 8.431e+00\n",
      "Epoch 13064, Loss: 436.5325012207031, Neurons: 11, Grad norm: 7.777e+00\n",
      "Epoch 13065, Loss: 436.52960205078125, Neurons: 11, Grad norm: 8.585e+00\n",
      "Epoch 13066, Loss: 436.52679443359375, Neurons: 11, Grad norm: 7.656e+00\n",
      "Epoch 13067, Loss: 436.52398681640625, Neurons: 11, Grad norm: 8.358e+00\n",
      "Epoch 13068, Loss: 436.52117919921875, Neurons: 11, Grad norm: 7.414e+00\n",
      "Epoch 13069, Loss: 436.5182800292969, Neurons: 11, Grad norm: 8.088e+00\n",
      "Epoch 13070, Loss: 436.5155334472656, Neurons: 11, Grad norm: 7.146e+00\n",
      "Epoch 13071, Loss: 436.5126953125, Neurons: 11, Grad norm: 7.778e+00\n",
      "Epoch 13072, Loss: 436.50982666015625, Neurons: 11, Grad norm: 6.951e+00\n",
      "Epoch 13073, Loss: 436.5069885253906, Neurons: 11, Grad norm: 7.675e+00\n",
      "Epoch 13074, Loss: 436.5042419433594, Neurons: 11, Grad norm: 6.335e+00\n",
      "Epoch 13075, Loss: 436.50128173828125, Neurons: 11, Grad norm: 7.013e+00\n",
      "Epoch 13076, Loss: 436.49847412109375, Neurons: 11, Grad norm: 6.503e+00\n",
      "Epoch 13077, Loss: 436.4956970214844, Neurons: 11, Grad norm: 7.284e+00\n",
      "Epoch 13078, Loss: 436.4928894042969, Neurons: 11, Grad norm: 6.987e+00\n",
      "Epoch 13079, Loss: 436.49005126953125, Neurons: 11, Grad norm: 8.290e+00\n",
      "Epoch 13080, Loss: 436.4871826171875, Neurons: 11, Grad norm: 8.027e+00\n",
      "Epoch 13081, Loss: 436.4843444824219, Neurons: 11, Grad norm: 1.034e+01\n",
      "Epoch 13082, Loss: 436.4814758300781, Neurons: 11, Grad norm: 1.052e+01\n",
      "Epoch 13083, Loss: 436.47869873046875, Neurons: 11, Grad norm: 1.285e+01\n",
      "Epoch 13084, Loss: 436.4757995605469, Neurons: 11, Grad norm: 1.455e+01\n",
      "Epoch 13085, Loss: 436.4729919433594, Neurons: 11, Grad norm: 1.804e+01\n",
      "Epoch 13086, Loss: 436.4701843261719, Neurons: 11, Grad norm: 2.092e+01\n",
      "Epoch 13087, Loss: 436.46734619140625, Neurons: 11, Grad norm: 2.592e+01\n",
      "Epoch 13088, Loss: 436.4644775390625, Neurons: 11, Grad norm: 3.002e+01\n",
      "Epoch 13089, Loss: 436.4617004394531, Neurons: 11, Grad norm: 3.706e+01\n",
      "Epoch 13090, Loss: 436.4588317871094, Neurons: 11, Grad norm: 4.327e+01\n",
      "Epoch 13091, Loss: 436.45599365234375, Neurons: 11, Grad norm: 5.288e+01\n",
      "Epoch 13092, Loss: 436.4532470703125, Neurons: 11, Grad norm: 6.276e+01\n",
      "Epoch 13093, Loss: 436.45050048828125, Neurons: 11, Grad norm: 7.687e+01\n",
      "Epoch 13094, Loss: 436.4477844238281, Neurons: 11, Grad norm: 9.227e+01\n",
      "Epoch 13095, Loss: 436.44512939453125, Neurons: 11, Grad norm: 1.120e+02\n",
      "Epoch 13096, Loss: 436.4425964355469, Neurons: 11, Grad norm: 1.339e+02\n",
      "Epoch 13097, Loss: 436.44012451171875, Neurons: 11, Grad norm: 1.608e+02\n",
      "Epoch 13098, Loss: 436.4378967285156, Neurons: 11, Grad norm: 1.893e+02\n",
      "Epoch 13099, Loss: 436.435791015625, Neurons: 11, Grad norm: 2.224e+02\n",
      "Epoch 13099, Test loss: 432.7998352050781\n",
      "Epoch 13100, Loss: 436.43389892578125, Neurons: 11, Grad norm: 2.536e+02\n",
      "Epoch 13101, Loss: 436.4322509765625, Neurons: 11, Grad norm: 2.822e+02\n",
      "Epoch 13102, Loss: 436.43060302734375, Neurons: 11, Grad norm: 2.986e+02\n",
      "Epoch 13103, Loss: 436.4284973144531, Neurons: 11, Grad norm: 2.980e+02\n",
      "Epoch 13104, Loss: 436.4256896972656, Neurons: 11, Grad norm: 2.710e+02\n",
      "Epoch 13105, Loss: 436.4218444824219, Neurons: 11, Grad norm: 2.195e+02\n",
      "Epoch 13106, Loss: 436.41717529296875, Neurons: 11, Grad norm: 1.437e+02\n",
      "Epoch 13107, Loss: 436.4124755859375, Neurons: 11, Grad norm: 5.795e+01\n",
      "Epoch 13108, Loss: 436.408447265625, Neurons: 11, Grad norm: 2.906e+01\n",
      "Epoch 13109, Loss: 436.40557861328125, Neurons: 11, Grad norm: 1.020e+02\n",
      "Epoch 13110, Loss: 436.4035949707031, Neurons: 11, Grad norm: 1.549e+02\n",
      "Epoch 13111, Loss: 436.4018249511719, Neurons: 11, Grad norm: 1.791e+02\n",
      "Epoch 13112, Loss: 436.3997802734375, Neurons: 11, Grad norm: 1.759e+02\n",
      "Epoch 13113, Loss: 436.3968811035156, Neurons: 11, Grad norm: 1.438e+02\n",
      "Epoch 13114, Loss: 436.39349365234375, Neurons: 11, Grad norm: 9.371e+01\n",
      "Epoch 13115, Loss: 436.389892578125, Neurons: 11, Grad norm: 3.185e+01\n",
      "Epoch 13116, Loss: 436.3866882324219, Neurons: 11, Grad norm: 2.735e+01\n",
      "Epoch 13117, Loss: 436.3840026855469, Neurons: 11, Grad norm: 7.737e+01\n",
      "Epoch 13118, Loss: 436.381591796875, Neurons: 11, Grad norm: 1.082e+02\n",
      "Epoch 13119, Loss: 436.37939453125, Neurons: 11, Grad norm: 1.196e+02\n",
      "Epoch 13120, Loss: 436.37689208984375, Neurons: 11, Grad norm: 1.089e+02\n",
      "Epoch 13121, Loss: 436.3739929199219, Neurons: 11, Grad norm: 8.298e+01\n",
      "Epoch 13122, Loss: 436.3708801269531, Neurons: 11, Grad norm: 4.406e+01\n",
      "Epoch 13123, Loss: 436.3678894042969, Neurons: 11, Grad norm: 3.549e+00\n",
      "Epoch 13124, Loss: 436.36505126953125, Neurons: 11, Grad norm: 3.605e+01\n",
      "Epoch 13125, Loss: 436.3624267578125, Neurons: 11, Grad norm: 6.417e+01\n",
      "Epoch 13126, Loss: 436.3599853515625, Neurons: 11, Grad norm: 8.031e+01\n",
      "Epoch 13127, Loss: 436.3574523925781, Neurons: 11, Grad norm: 8.025e+01\n",
      "Epoch 13128, Loss: 436.35479736328125, Neurons: 11, Grad norm: 6.912e+01\n",
      "Epoch 13129, Loss: 436.3518981933594, Neurons: 11, Grad norm: 4.639e+01\n",
      "Epoch 13130, Loss: 436.3490905761719, Neurons: 11, Grad norm: 1.998e+01\n",
      "Epoch 13131, Loss: 436.34625244140625, Neurons: 11, Grad norm: 9.092e+00\n",
      "Epoch 13132, Loss: 436.3434753417969, Neurons: 11, Grad norm: 3.184e+01\n",
      "Epoch 13133, Loss: 436.34088134765625, Neurons: 11, Grad norm: 4.877e+01\n",
      "Epoch 13134, Loss: 436.3382873535156, Neurons: 11, Grad norm: 5.533e+01\n",
      "Epoch 13135, Loss: 436.3356018066406, Neurons: 11, Grad norm: 5.400e+01\n",
      "Epoch 13136, Loss: 436.33294677734375, Neurons: 11, Grad norm: 4.315e+01\n",
      "Epoch 13137, Loss: 436.3302001953125, Neurons: 11, Grad norm: 2.845e+01\n",
      "Epoch 13138, Loss: 436.32733154296875, Neurons: 11, Grad norm: 8.948e+00\n",
      "Epoch 13139, Loss: 436.32464599609375, Neurons: 11, Grad norm: 8.646e+00\n",
      "Epoch 13140, Loss: 436.3219299316406, Neurons: 11, Grad norm: 2.500e+01\n",
      "Epoch 13141, Loss: 436.31927490234375, Neurons: 11, Grad norm: 3.491e+01\n",
      "Epoch 13142, Loss: 436.31658935546875, Neurons: 11, Grad norm: 4.035e+01\n",
      "Epoch 13143, Loss: 436.3139343261719, Neurons: 11, Grad norm: 3.837e+01\n",
      "Epoch 13144, Loss: 436.3112487792969, Neurons: 11, Grad norm: 3.209e+01\n",
      "Epoch 13145, Loss: 436.3085021972656, Neurons: 11, Grad norm: 2.118e+01\n",
      "Epoch 13146, Loss: 436.3056945800781, Neurons: 11, Grad norm: 1.018e+01\n",
      "Epoch 13147, Loss: 436.302978515625, Neurons: 11, Grad norm: 3.800e+00\n",
      "Epoch 13148, Loss: 436.30029296875, Neurons: 11, Grad norm: 1.297e+01\n",
      "Epoch 13149, Loss: 436.2975769042969, Neurons: 11, Grad norm: 2.208e+01\n",
      "Epoch 13149, Test loss: 432.7070007324219\n",
      "Epoch 13150, Loss: 436.2949523925781, Neurons: 11, Grad norm: 2.594e+01\n",
      "Epoch 13151, Loss: 436.292236328125, Neurons: 11, Grad norm: 2.757e+01\n",
      "Epoch 13152, Loss: 436.28948974609375, Neurons: 11, Grad norm: 2.482e+01\n",
      "Epoch 13153, Loss: 436.28680419921875, Neurons: 11, Grad norm: 2.042e+01\n",
      "Epoch 13154, Loss: 436.2840881347656, Neurons: 11, Grad norm: 1.303e+01\n",
      "Epoch 13155, Loss: 436.2813415527344, Neurons: 11, Grad norm: 6.675e+00\n",
      "Epoch 13156, Loss: 436.2785949707031, Neurons: 11, Grad norm: 2.404e+00\n",
      "Epoch 13157, Loss: 436.27587890625, Neurons: 11, Grad norm: 7.341e+00\n",
      "Epoch 13158, Loss: 436.273193359375, Neurons: 11, Grad norm: 1.308e+01\n",
      "Epoch 13159, Loss: 436.2704772949219, Neurons: 11, Grad norm: 1.519e+01\n",
      "Epoch 13160, Loss: 436.2677307128906, Neurons: 11, Grad norm: 1.738e+01\n",
      "Epoch 13161, Loss: 436.26507568359375, Neurons: 11, Grad norm: 1.561e+01\n",
      "Epoch 13162, Loss: 436.2623291015625, Neurons: 11, Grad norm: 1.358e+01\n",
      "Epoch 13163, Loss: 436.25958251953125, Neurons: 11, Grad norm: 9.124e+00\n",
      "Epoch 13164, Loss: 436.25689697265625, Neurons: 11, Grad norm: 5.371e+00\n",
      "Epoch 13165, Loss: 436.254150390625, Neurons: 11, Grad norm: 1.671e+00\n",
      "Epoch 13166, Loss: 436.25140380859375, Neurons: 11, Grad norm: 4.547e+00\n",
      "Epoch 13167, Loss: 436.2486877441406, Neurons: 11, Grad norm: 8.896e+00\n",
      "Epoch 13168, Loss: 436.2459411621094, Neurons: 11, Grad norm: 9.678e+00\n",
      "Epoch 13169, Loss: 436.24322509765625, Neurons: 11, Grad norm: 1.187e+01\n",
      "Epoch 13170, Loss: 436.240478515625, Neurons: 11, Grad norm: 1.069e+01\n",
      "Epoch 13171, Loss: 436.23773193359375, Neurons: 11, Grad norm: 1.016e+01\n",
      "Epoch 13172, Loss: 436.2349853515625, Neurons: 11, Grad norm: 8.270e+00\n",
      "Epoch 13173, Loss: 436.2322998046875, Neurons: 11, Grad norm: 6.938e+00\n",
      "Epoch 13174, Loss: 436.2295837402344, Neurons: 11, Grad norm: 4.018e+00\n",
      "Epoch 13175, Loss: 436.2267761230469, Neurons: 11, Grad norm: 2.607e+00\n",
      "Epoch 13176, Loss: 436.2240905761719, Neurons: 11, Grad norm: 2.164e+00\n",
      "Epoch 13177, Loss: 436.2213439941406, Neurons: 11, Grad norm: 2.965e+00\n",
      "Epoch 13178, Loss: 436.2185974121094, Neurons: 11, Grad norm: 5.247e+00\n",
      "Epoch 13179, Loss: 436.21588134765625, Neurons: 11, Grad norm: 5.372e+00\n",
      "Epoch 13180, Loss: 436.213134765625, Neurons: 11, Grad norm: 6.593e+00\n",
      "Epoch 13181, Loss: 436.21038818359375, Neurons: 11, Grad norm: 6.106e+00\n",
      "Epoch 13182, Loss: 436.2076416015625, Neurons: 11, Grad norm: 7.063e+00\n",
      "Epoch 13183, Loss: 436.20489501953125, Neurons: 11, Grad norm: 6.508e+00\n",
      "Epoch 13184, Loss: 436.2021484375, Neurons: 11, Grad norm: 6.809e+00\n",
      "Epoch 13185, Loss: 436.19940185546875, Neurons: 11, Grad norm: 5.452e+00\n",
      "Epoch 13186, Loss: 436.1966857910156, Neurons: 11, Grad norm: 6.015e+00\n",
      "Epoch 13187, Loss: 436.1938781738281, Neurons: 11, Grad norm: 4.703e+00\n",
      "Epoch 13188, Loss: 436.1911926269531, Neurons: 11, Grad norm: 4.776e+00\n",
      "Epoch 13189, Loss: 436.1883850097656, Neurons: 11, Grad norm: 3.289e+00\n",
      "Epoch 13190, Loss: 436.1856994628906, Neurons: 11, Grad norm: 3.203e+00\n",
      "Epoch 13191, Loss: 436.1829528808594, Neurons: 11, Grad norm: 1.745e+00\n",
      "Epoch 13192, Loss: 436.1801452636719, Neurons: 11, Grad norm: 1.698e+00\n",
      "Epoch 13193, Loss: 436.1773986816406, Neurons: 11, Grad norm: 2.338e+00\n",
      "Epoch 13194, Loss: 436.1746826171875, Neurons: 11, Grad norm: 2.937e+00\n",
      "Epoch 13195, Loss: 436.171875, Neurons: 11, Grad norm: 4.361e+00\n",
      "Epoch 13196, Loss: 436.1690979003906, Neurons: 11, Grad norm: 4.503e+00\n",
      "Epoch 13197, Loss: 436.1663818359375, Neurons: 11, Grad norm: 6.596e+00\n",
      "Epoch 13198, Loss: 436.16357421875, Neurons: 11, Grad norm: 6.087e+00\n",
      "Epoch 13199, Loss: 436.160888671875, Neurons: 11, Grad norm: 7.461e+00\n",
      "Epoch 13199, Test loss: 432.5775146484375\n",
      "Epoch 13200, Loss: 436.15814208984375, Neurons: 11, Grad norm: 7.458e+00\n",
      "Epoch 13201, Loss: 436.15533447265625, Neurons: 11, Grad norm: 8.805e+00\n",
      "Epoch 13202, Loss: 436.152587890625, Neurons: 11, Grad norm: 9.080e+00\n",
      "Epoch 13203, Loss: 436.1497802734375, Neurons: 11, Grad norm: 1.053e+01\n",
      "Epoch 13204, Loss: 436.1470031738281, Neurons: 11, Grad norm: 1.000e+01\n",
      "Epoch 13205, Loss: 436.144287109375, Neurons: 11, Grad norm: 1.104e+01\n",
      "Epoch 13206, Loss: 436.1414794921875, Neurons: 11, Grad norm: 9.966e+00\n",
      "Epoch 13207, Loss: 436.1387023925781, Neurons: 11, Grad norm: 1.047e+01\n",
      "Epoch 13208, Loss: 436.13592529296875, Neurons: 11, Grad norm: 9.089e+00\n",
      "Epoch 13209, Loss: 436.1331787109375, Neurons: 11, Grad norm: 9.202e+00\n",
      "Epoch 13210, Loss: 436.1304016113281, Neurons: 11, Grad norm: 8.424e+00\n",
      "Epoch 13211, Loss: 436.1275939941406, Neurons: 11, Grad norm: 9.149e+00\n",
      "Epoch 13212, Loss: 436.1248474121094, Neurons: 11, Grad norm: 7.986e+00\n",
      "Epoch 13213, Loss: 436.1221008300781, Neurons: 11, Grad norm: 8.469e+00\n",
      "Epoch 13214, Loss: 436.1192932128906, Neurons: 11, Grad norm: 7.260e+00\n",
      "Epoch 13215, Loss: 436.1164855957031, Neurons: 11, Grad norm: 7.799e+00\n",
      "Epoch 13216, Loss: 436.1136779785156, Neurons: 11, Grad norm: 6.998e+00\n",
      "Epoch 13217, Loss: 436.1109924316406, Neurons: 11, Grad norm: 7.650e+00\n",
      "Epoch 13218, Loss: 436.1081237792969, Neurons: 11, Grad norm: 6.969e+00\n",
      "Epoch 13219, Loss: 436.1053771972656, Neurons: 11, Grad norm: 8.374e+00\n",
      "Epoch 13220, Loss: 436.10260009765625, Neurons: 11, Grad norm: 7.832e+00\n",
      "Epoch 13221, Loss: 436.099853515625, Neurons: 11, Grad norm: 8.630e+00\n",
      "Epoch 13222, Loss: 436.0970458984375, Neurons: 11, Grad norm: 8.397e+00\n",
      "Epoch 13223, Loss: 436.09429931640625, Neurons: 11, Grad norm: 9.605e+00\n",
      "Epoch 13224, Loss: 436.09149169921875, Neurons: 11, Grad norm: 9.394e+00\n",
      "Epoch 13225, Loss: 436.08868408203125, Neurons: 11, Grad norm: 1.093e+01\n",
      "Epoch 13226, Loss: 436.08587646484375, Neurons: 11, Grad norm: 1.089e+01\n",
      "Epoch 13227, Loss: 436.0830993652344, Neurons: 11, Grad norm: 1.355e+01\n",
      "Epoch 13228, Loss: 436.0802917480469, Neurons: 11, Grad norm: 1.438e+01\n",
      "Epoch 13229, Loss: 436.0774841308594, Neurons: 11, Grad norm: 1.719e+01\n",
      "Epoch 13230, Loss: 436.0746765136719, Neurons: 11, Grad norm: 1.961e+01\n",
      "Epoch 13231, Loss: 436.0719299316406, Neurons: 11, Grad norm: 2.378e+01\n",
      "Epoch 13232, Loss: 436.0691833496094, Neurons: 11, Grad norm: 2.749e+01\n",
      "Epoch 13233, Loss: 436.06634521484375, Neurons: 11, Grad norm: 3.371e+01\n",
      "Epoch 13234, Loss: 436.0635986328125, Neurons: 11, Grad norm: 3.907e+01\n",
      "Epoch 13235, Loss: 436.060791015625, Neurons: 11, Grad norm: 4.777e+01\n",
      "Epoch 13236, Loss: 436.0580749511719, Neurons: 11, Grad norm: 5.601e+01\n",
      "Epoch 13237, Loss: 436.0553283691406, Neurons: 11, Grad norm: 6.790e+01\n",
      "Epoch 13238, Loss: 436.0526428222656, Neurons: 11, Grad norm: 8.044e+01\n",
      "Epoch 13239, Loss: 436.04998779296875, Neurons: 11, Grad norm: 9.736e+01\n",
      "Epoch 13240, Loss: 436.0473937988281, Neurons: 11, Grad norm: 1.161e+02\n",
      "Epoch 13241, Loss: 436.0448913574219, Neurons: 11, Grad norm: 1.396e+02\n",
      "Epoch 13242, Loss: 436.04254150390625, Neurons: 11, Grad norm: 1.649e+02\n",
      "Epoch 13243, Loss: 436.040283203125, Neurons: 11, Grad norm: 1.947e+02\n",
      "Epoch 13244, Loss: 436.0382995605469, Neurons: 11, Grad norm: 2.248e+02\n",
      "Epoch 13245, Loss: 436.03643798828125, Neurons: 11, Grad norm: 2.562e+02\n",
      "Epoch 13246, Loss: 436.0347900390625, Neurons: 11, Grad norm: 2.803e+02\n",
      "Epoch 13247, Loss: 436.0329895019531, Neurons: 11, Grad norm: 2.946e+02\n",
      "Epoch 13248, Loss: 436.0308532714844, Neurons: 11, Grad norm: 2.890e+02\n",
      "Epoch 13249, Loss: 436.02789306640625, Neurons: 11, Grad norm: 2.614e+02\n",
      "Epoch 13249, Test loss: 432.3942565917969\n",
      "Epoch 13250, Loss: 436.0240783691406, Neurons: 11, Grad norm: 2.071e+02\n",
      "Epoch 13251, Loss: 436.0195007324219, Neurons: 11, Grad norm: 1.341e+02\n",
      "Epoch 13252, Loss: 436.0149841308594, Neurons: 11, Grad norm: 4.952e+01\n",
      "Epoch 13253, Loss: 436.0111999511719, Neurons: 11, Grad norm: 3.226e+01\n",
      "Epoch 13254, Loss: 436.0083923339844, Neurons: 11, Grad norm: 1.029e+02\n",
      "Epoch 13255, Loss: 436.0064392089844, Neurons: 11, Grad norm: 1.513e+02\n",
      "Epoch 13256, Loss: 436.0047302246094, Neurons: 11, Grad norm: 1.767e+02\n",
      "Epoch 13257, Loss: 436.0025939941406, Neurons: 11, Grad norm: 1.725e+02\n",
      "Epoch 13258, Loss: 435.9998474121094, Neurons: 11, Grad norm: 1.446e+02\n",
      "Epoch 13259, Loss: 435.9965515136719, Neurons: 11, Grad norm: 9.588e+01\n",
      "Epoch 13260, Loss: 435.9930419921875, Neurons: 11, Grad norm: 3.791e+01\n",
      "Epoch 13261, Loss: 435.9898376464844, Neurons: 11, Grad norm: 2.163e+01\n",
      "Epoch 13262, Loss: 435.9870910644531, Neurons: 11, Grad norm: 7.053e+01\n",
      "Epoch 13263, Loss: 435.98480224609375, Neurons: 11, Grad norm: 1.053e+02\n",
      "Epoch 13264, Loss: 435.9825744628906, Neurons: 11, Grad norm: 1.181e+02\n",
      "Epoch 13265, Loss: 435.9801940917969, Neurons: 11, Grad norm: 1.132e+02\n",
      "Epoch 13266, Loss: 435.9773864746094, Neurons: 11, Grad norm: 8.940e+01\n",
      "Epoch 13267, Loss: 435.9743957519531, Neurons: 11, Grad norm: 5.489e+01\n",
      "Epoch 13268, Loss: 435.97137451171875, Neurons: 11, Grad norm: 1.359e+01\n",
      "Epoch 13269, Loss: 435.9684753417969, Neurons: 11, Grad norm: 2.435e+01\n",
      "Epoch 13270, Loss: 435.96588134765625, Neurons: 11, Grad norm: 5.604e+01\n",
      "Epoch 13271, Loss: 435.9635009765625, Neurons: 11, Grad norm: 7.448e+01\n",
      "Epoch 13272, Loss: 435.96099853515625, Neurons: 11, Grad norm: 8.084e+01\n",
      "Epoch 13273, Loss: 435.9583740234375, Neurons: 11, Grad norm: 7.233e+01\n",
      "Epoch 13274, Loss: 435.9556884765625, Neurons: 11, Grad norm: 5.492e+01\n",
      "Epoch 13275, Loss: 435.9527893066406, Neurons: 11, Grad norm: 2.927e+01\n",
      "Epoch 13276, Loss: 435.9500427246094, Neurons: 11, Grad norm: 3.754e+00\n",
      "Epoch 13277, Loss: 435.9472961425781, Neurons: 11, Grad norm: 2.227e+01\n",
      "Epoch 13278, Loss: 435.9447021484375, Neurons: 11, Grad norm: 4.027e+01\n",
      "Epoch 13279, Loss: 435.94207763671875, Neurons: 11, Grad norm: 5.174e+01\n",
      "Epoch 13280, Loss: 435.9395751953125, Neurons: 11, Grad norm: 5.362e+01\n",
      "Epoch 13281, Loss: 435.9368896484375, Neurons: 11, Grad norm: 4.864e+01\n",
      "Epoch 13282, Loss: 435.9342041015625, Neurons: 11, Grad norm: 3.589e+01\n",
      "Epoch 13283, Loss: 435.9314880371094, Neurons: 11, Grad norm: 2.089e+01\n",
      "Epoch 13284, Loss: 435.9288024902344, Neurons: 11, Grad norm: 2.848e+00\n",
      "Epoch 13285, Loss: 435.926025390625, Neurons: 11, Grad norm: 1.230e+01\n",
      "Epoch 13286, Loss: 435.92340087890625, Neurons: 11, Grad norm: 2.494e+01\n",
      "Epoch 13287, Loss: 435.9207763671875, Neurons: 11, Grad norm: 3.162e+01\n",
      "Epoch 13288, Loss: 435.9181823730469, Neurons: 11, Grad norm: 3.424e+01\n",
      "Epoch 13289, Loss: 435.9154968261719, Neurons: 11, Grad norm: 3.095e+01\n",
      "Epoch 13290, Loss: 435.91278076171875, Neurons: 11, Grad norm: 2.506e+01\n",
      "Epoch 13291, Loss: 435.9101867675781, Neurons: 11, Grad norm: 1.480e+01\n",
      "Epoch 13292, Loss: 435.9075012207031, Neurons: 11, Grad norm: 5.478e+00\n",
      "Epoch 13293, Loss: 435.90472412109375, Neurons: 11, Grad norm: 6.104e+00\n",
      "Epoch 13294, Loss: 435.902099609375, Neurons: 11, Grad norm: 1.343e+01\n",
      "Epoch 13295, Loss: 435.8994445800781, Neurons: 11, Grad norm: 2.004e+01\n",
      "Epoch 13296, Loss: 435.89678955078125, Neurons: 11, Grad norm: 2.221e+01\n",
      "Epoch 13297, Loss: 435.8941345214844, Neurons: 11, Grad norm: 2.328e+01\n",
      "Epoch 13298, Loss: 435.8914794921875, Neurons: 11, Grad norm: 2.050e+01\n",
      "Epoch 13299, Loss: 435.8887939453125, Neurons: 11, Grad norm: 1.721e+01\n",
      "Epoch 13299, Test loss: 432.3116455078125\n",
      "Epoch 13300, Loss: 435.8860778808594, Neurons: 11, Grad norm: 1.124e+01\n",
      "Epoch 13301, Loss: 435.8833923339844, Neurons: 11, Grad norm: 6.491e+00\n",
      "Epoch 13302, Loss: 435.88079833984375, Neurons: 11, Grad norm: 1.632e+00\n",
      "Epoch 13303, Loss: 435.8780822753906, Neurons: 11, Grad norm: 4.658e+00\n",
      "Epoch 13304, Loss: 435.8753967285156, Neurons: 11, Grad norm: 9.335e+00\n",
      "Epoch 13305, Loss: 435.87274169921875, Neurons: 11, Grad norm: 1.101e+01\n",
      "Epoch 13306, Loss: 435.8699951171875, Neurons: 11, Grad norm: 1.351e+01\n",
      "Epoch 13307, Loss: 435.8674011230469, Neurons: 11, Grad norm: 1.250e+01\n",
      "Epoch 13308, Loss: 435.86468505859375, Neurons: 11, Grad norm: 1.190e+01\n",
      "Epoch 13309, Loss: 435.86199951171875, Neurons: 11, Grad norm: 9.691e+00\n",
      "Epoch 13310, Loss: 435.8592834472656, Neurons: 11, Grad norm: 8.121e+00\n",
      "Epoch 13311, Loss: 435.856689453125, Neurons: 11, Grad norm: 5.199e+00\n",
      "Epoch 13312, Loss: 435.85394287109375, Neurons: 11, Grad norm: 3.858e+00\n",
      "Epoch 13313, Loss: 435.8512268066406, Neurons: 11, Grad norm: 1.668e+00\n",
      "Epoch 13314, Loss: 435.8486022949219, Neurons: 11, Grad norm: 2.140e+00\n",
      "Epoch 13315, Loss: 435.84588623046875, Neurons: 11, Grad norm: 4.430e+00\n",
      "Epoch 13316, Loss: 435.84320068359375, Neurons: 11, Grad norm: 5.539e+00\n",
      "Epoch 13317, Loss: 435.8404846191406, Neurons: 11, Grad norm: 6.965e+00\n",
      "Epoch 13318, Loss: 435.8377990722656, Neurons: 11, Grad norm: 6.867e+00\n",
      "Epoch 13319, Loss: 435.8350830078125, Neurons: 11, Grad norm: 7.916e+00\n",
      "Epoch 13320, Loss: 435.8323974609375, Neurons: 11, Grad norm: 6.407e+00\n",
      "Epoch 13321, Loss: 435.8296813964844, Neurons: 11, Grad norm: 6.943e+00\n",
      "Epoch 13322, Loss: 435.8269958496094, Neurons: 11, Grad norm: 5.545e+00\n",
      "Epoch 13323, Loss: 435.82427978515625, Neurons: 11, Grad norm: 5.145e+00\n",
      "Epoch 13324, Loss: 435.82159423828125, Neurons: 11, Grad norm: 3.578e+00\n",
      "Epoch 13325, Loss: 435.8188781738281, Neurons: 11, Grad norm: 3.090e+00\n",
      "Epoch 13326, Loss: 435.8161926269531, Neurons: 11, Grad norm: 1.771e+00\n",
      "Epoch 13327, Loss: 435.8134765625, Neurons: 11, Grad norm: 1.707e+00\n",
      "Epoch 13328, Loss: 435.810791015625, Neurons: 11, Grad norm: 2.241e+00\n",
      "Epoch 13329, Loss: 435.8081359863281, Neurons: 11, Grad norm: 2.187e+00\n",
      "Epoch 13330, Loss: 435.8053894042969, Neurons: 11, Grad norm: 3.423e+00\n",
      "Epoch 13331, Loss: 435.8027038574219, Neurons: 11, Grad norm: 3.065e+00\n",
      "Epoch 13332, Loss: 435.79998779296875, Neurons: 11, Grad norm: 3.798e+00\n",
      "Epoch 13333, Loss: 435.79730224609375, Neurons: 11, Grad norm: 3.329e+00\n",
      "Epoch 13334, Loss: 435.7945861816406, Neurons: 11, Grad norm: 3.903e+00\n",
      "Epoch 13335, Loss: 435.7918395996094, Neurons: 11, Grad norm: 2.566e+00\n",
      "Epoch 13336, Loss: 435.7890930175781, Neurons: 11, Grad norm: 2.817e+00\n",
      "Epoch 13337, Loss: 435.78643798828125, Neurons: 11, Grad norm: 2.070e+00\n",
      "Epoch 13338, Loss: 435.78369140625, Neurons: 11, Grad norm: 2.125e+00\n",
      "Epoch 13339, Loss: 435.7809753417969, Neurons: 11, Grad norm: 1.673e+00\n",
      "Epoch 13340, Loss: 435.7782897949219, Neurons: 11, Grad norm: 2.058e+00\n",
      "Epoch 13341, Loss: 435.7756042480469, Neurons: 11, Grad norm: 1.617e+00\n",
      "Epoch 13342, Loss: 435.7727966308594, Neurons: 11, Grad norm: 1.626e+00\n",
      "Epoch 13343, Loss: 435.77008056640625, Neurons: 11, Grad norm: 1.760e+00\n",
      "Epoch 13344, Loss: 435.76739501953125, Neurons: 11, Grad norm: 1.709e+00\n",
      "Epoch 13345, Loss: 435.7646789550781, Neurons: 11, Grad norm: 2.704e+00\n",
      "Epoch 13346, Loss: 435.7619934082031, Neurons: 11, Grad norm: 2.380e+00\n",
      "Epoch 13347, Loss: 435.7591857910156, Neurons: 11, Grad norm: 3.549e+00\n",
      "Epoch 13348, Loss: 435.7565002441406, Neurons: 11, Grad norm: 3.231e+00\n",
      "Epoch 13349, Loss: 435.7537841796875, Neurons: 11, Grad norm: 3.593e+00\n",
      "Epoch 13349, Test loss: 432.1839599609375\n",
      "Epoch 13350, Loss: 435.75103759765625, Neurons: 11, Grad norm: 3.114e+00\n",
      "Epoch 13351, Loss: 435.748291015625, Neurons: 11, Grad norm: 4.216e+00\n",
      "Epoch 13352, Loss: 435.7455749511719, Neurons: 11, Grad norm: 3.404e+00\n",
      "Epoch 13353, Loss: 435.7428894042969, Neurons: 11, Grad norm: 4.387e+00\n",
      "Epoch 13354, Loss: 435.7400817871094, Neurons: 11, Grad norm: 3.627e+00\n",
      "Epoch 13355, Loss: 435.7373962402344, Neurons: 11, Grad norm: 4.308e+00\n",
      "Epoch 13356, Loss: 435.7345886230469, Neurons: 11, Grad norm: 4.310e+00\n",
      "Epoch 13357, Loss: 435.7319030761719, Neurons: 11, Grad norm: 5.484e+00\n",
      "Epoch 13358, Loss: 435.72918701171875, Neurons: 11, Grad norm: 5.087e+00\n",
      "Epoch 13359, Loss: 435.72637939453125, Neurons: 11, Grad norm: 6.332e+00\n",
      "Epoch 13360, Loss: 435.7237243652344, Neurons: 11, Grad norm: 5.812e+00\n",
      "Epoch 13361, Loss: 435.720947265625, Neurons: 11, Grad norm: 6.873e+00\n",
      "Epoch 13362, Loss: 435.71820068359375, Neurons: 11, Grad norm: 6.359e+00\n",
      "Epoch 13363, Loss: 435.7154846191406, Neurons: 11, Grad norm: 7.381e+00\n",
      "Epoch 13364, Loss: 435.7126770019531, Neurons: 11, Grad norm: 7.104e+00\n",
      "Epoch 13365, Loss: 435.7099914550781, Neurons: 11, Grad norm: 8.348e+00\n",
      "Epoch 13366, Loss: 435.707275390625, Neurons: 11, Grad norm: 8.350e+00\n",
      "Epoch 13367, Loss: 435.7044982910156, Neurons: 11, Grad norm: 9.930e+00\n",
      "Epoch 13368, Loss: 435.7017517089844, Neurons: 11, Grad norm: 1.022e+01\n",
      "Epoch 13369, Loss: 435.698974609375, Neurons: 11, Grad norm: 1.299e+01\n",
      "Epoch 13370, Loss: 435.69622802734375, Neurons: 11, Grad norm: 1.450e+01\n",
      "Epoch 13371, Loss: 435.6934814453125, Neurons: 11, Grad norm: 1.821e+01\n",
      "Epoch 13372, Loss: 435.6907958984375, Neurons: 11, Grad norm: 2.108e+01\n",
      "Epoch 13373, Loss: 435.68798828125, Neurons: 11, Grad norm: 2.532e+01\n",
      "Epoch 13374, Loss: 435.685302734375, Neurons: 11, Grad norm: 2.876e+01\n",
      "Epoch 13375, Loss: 435.6824951171875, Neurons: 11, Grad norm: 3.503e+01\n",
      "Epoch 13376, Loss: 435.6797790527344, Neurons: 11, Grad norm: 4.062e+01\n",
      "Epoch 13377, Loss: 435.6770935058594, Neurons: 11, Grad norm: 4.933e+01\n",
      "Epoch 13378, Loss: 435.67437744140625, Neurons: 11, Grad norm: 5.781e+01\n",
      "Epoch 13379, Loss: 435.67169189453125, Neurons: 11, Grad norm: 6.967e+01\n",
      "Epoch 13380, Loss: 435.6689758300781, Neurons: 11, Grad norm: 8.217e+01\n",
      "Epoch 13381, Loss: 435.6663818359375, Neurons: 11, Grad norm: 9.846e+01\n",
      "Epoch 13382, Loss: 435.6638488769531, Neurons: 11, Grad norm: 1.169e+02\n",
      "Epoch 13383, Loss: 435.661376953125, Neurons: 11, Grad norm: 1.408e+02\n",
      "Epoch 13384, Loss: 435.6590881347656, Neurons: 11, Grad norm: 1.668e+02\n",
      "Epoch 13385, Loss: 435.656982421875, Neurons: 11, Grad norm: 1.984e+02\n",
      "Epoch 13386, Loss: 435.655029296875, Neurons: 11, Grad norm: 2.300e+02\n",
      "Epoch 13387, Loss: 435.6532897949219, Neurons: 11, Grad norm: 2.621e+02\n",
      "Epoch 13388, Loss: 435.6517028808594, Neurons: 11, Grad norm: 2.874e+02\n",
      "Epoch 13389, Loss: 435.6499938964844, Neurons: 11, Grad norm: 3.012e+02\n",
      "Epoch 13390, Loss: 435.64788818359375, Neurons: 11, Grad norm: 2.938e+02\n",
      "Epoch 13391, Loss: 435.6448974609375, Neurons: 11, Grad norm: 2.630e+02\n",
      "Epoch 13392, Loss: 435.6409912109375, Neurons: 11, Grad norm: 2.038e+02\n",
      "Epoch 13393, Loss: 435.6363830566406, Neurons: 11, Grad norm: 1.264e+02\n",
      "Epoch 13394, Loss: 435.63189697265625, Neurons: 11, Grad norm: 3.886e+01\n",
      "Epoch 13395, Loss: 435.628173828125, Neurons: 11, Grad norm: 4.413e+01\n",
      "Epoch 13396, Loss: 435.6255798339844, Neurons: 11, Grad norm: 1.141e+02\n",
      "Epoch 13397, Loss: 435.623779296875, Neurons: 11, Grad norm: 1.601e+02\n",
      "Epoch 13398, Loss: 435.6221008300781, Neurons: 11, Grad norm: 1.805e+02\n",
      "Epoch 13399, Loss: 435.61993408203125, Neurons: 11, Grad norm: 1.702e+02\n",
      "Epoch 13399, Test loss: 432.0910949707031\n",
      "Epoch 13400, Loss: 435.6170959472656, Neurons: 11, Grad norm: 1.366e+02\n",
      "Epoch 13401, Loss: 435.6136779785156, Neurons: 11, Grad norm: 8.305e+01\n",
      "Epoch 13402, Loss: 435.6102294921875, Neurons: 11, Grad norm: 2.285e+01\n",
      "Epoch 13403, Loss: 435.607177734375, Neurons: 11, Grad norm: 3.637e+01\n",
      "Epoch 13404, Loss: 435.6045837402344, Neurons: 11, Grad norm: 8.244e+01\n",
      "Epoch 13405, Loss: 435.6023864746094, Neurons: 11, Grad norm: 1.124e+02\n",
      "Epoch 13406, Loss: 435.6001892089844, Neurons: 11, Grad norm: 1.199e+02\n",
      "Epoch 13407, Loss: 435.5977783203125, Neurons: 11, Grad norm: 1.088e+02\n",
      "Epoch 13408, Loss: 435.5949401855469, Neurons: 11, Grad norm: 7.933e+01\n",
      "Epoch 13409, Loss: 435.59197998046875, Neurons: 11, Grad norm: 4.154e+01\n",
      "Epoch 13410, Loss: 435.5889892578125, Neurons: 11, Grad norm: 1.901e+00\n",
      "Epoch 13411, Loss: 435.5863037109375, Neurons: 11, Grad norm: 3.779e+01\n",
      "Epoch 13412, Loss: 435.58380126953125, Neurons: 11, Grad norm: 6.562e+01\n",
      "Epoch 13413, Loss: 435.5813903808594, Neurons: 11, Grad norm: 7.878e+01\n",
      "Epoch 13414, Loss: 435.5789489746094, Neurons: 11, Grad norm: 7.948e+01\n",
      "Epoch 13415, Loss: 435.5762939453125, Neurons: 11, Grad norm: 6.587e+01\n",
      "Epoch 13416, Loss: 435.5735778808594, Neurons: 11, Grad norm: 4.454e+01\n",
      "Epoch 13417, Loss: 435.57080078125, Neurons: 11, Grad norm: 1.696e+01\n",
      "Epoch 13418, Loss: 435.5680847167969, Neurons: 11, Grad norm: 9.040e+00\n",
      "Epoch 13419, Loss: 435.5653991699219, Neurons: 11, Grad norm: 3.241e+01\n",
      "Epoch 13420, Loss: 435.5628967285156, Neurons: 11, Grad norm: 4.680e+01\n",
      "Epoch 13421, Loss: 435.5603332519531, Neurons: 11, Grad norm: 5.394e+01\n",
      "Epoch 13422, Loss: 435.55780029296875, Neurons: 11, Grad norm: 5.115e+01\n",
      "Epoch 13423, Loss: 435.55517578125, Neurons: 11, Grad norm: 4.222e+01\n",
      "Epoch 13424, Loss: 435.552490234375, Neurons: 11, Grad norm: 2.665e+01\n",
      "Epoch 13425, Loss: 435.5498352050781, Neurons: 11, Grad norm: 9.932e+00\n",
      "Epoch 13426, Loss: 435.54718017578125, Neurons: 11, Grad norm: 8.471e+00\n",
      "Epoch 13427, Loss: 435.5445861816406, Neurons: 11, Grad norm: 2.187e+01\n",
      "Epoch 13428, Loss: 435.5419921875, Neurons: 11, Grad norm: 3.303e+01\n",
      "Epoch 13429, Loss: 435.5393981933594, Neurons: 11, Grad norm: 3.631e+01\n",
      "Epoch 13430, Loss: 435.53680419921875, Neurons: 11, Grad norm: 3.622e+01\n",
      "Epoch 13431, Loss: 435.5341796875, Neurons: 11, Grad norm: 3.010e+01\n",
      "Epoch 13432, Loss: 435.5315246582031, Neurons: 11, Grad norm: 2.108e+01\n",
      "Epoch 13433, Loss: 435.5289001464844, Neurons: 11, Grad norm: 9.317e+00\n",
      "Epoch 13434, Loss: 435.5262451171875, Neurons: 11, Grad norm: 2.343e+00\n",
      "Epoch 13435, Loss: 435.5235900878906, Neurons: 11, Grad norm: 1.302e+01\n",
      "Epoch 13436, Loss: 435.52099609375, Neurons: 11, Grad norm: 2.017e+01\n",
      "Epoch 13437, Loss: 435.5183410644531, Neurons: 11, Grad norm: 2.638e+01\n",
      "Epoch 13438, Loss: 435.5157775878906, Neurons: 11, Grad norm: 2.627e+01\n",
      "Epoch 13439, Loss: 435.51318359375, Neurons: 11, Grad norm: 2.459e+01\n",
      "Epoch 13440, Loss: 435.510498046875, Neurons: 11, Grad norm: 1.862e+01\n",
      "Epoch 13441, Loss: 435.5078430175781, Neurons: 11, Grad norm: 1.195e+01\n",
      "Epoch 13442, Loss: 435.50518798828125, Neurons: 11, Grad norm: 3.871e+00\n",
      "Epoch 13443, Loss: 435.5025939941406, Neurons: 11, Grad norm: 3.894e+00\n",
      "Epoch 13444, Loss: 435.5, Neurons: 11, Grad norm: 1.081e+01\n",
      "Epoch 13445, Loss: 435.49737548828125, Neurons: 11, Grad norm: 1.445e+01\n",
      "Epoch 13446, Loss: 435.49468994140625, Neurons: 11, Grad norm: 1.858e+01\n",
      "Epoch 13447, Loss: 435.4920959472656, Neurons: 11, Grad norm: 1.858e+01\n",
      "Epoch 13448, Loss: 435.48944091796875, Neurons: 11, Grad norm: 1.885e+01\n",
      "Epoch 13449, Loss: 435.4867858886719, Neurons: 11, Grad norm: 1.597e+01\n",
      "Epoch 13449, Test loss: 431.9293518066406\n",
      "Epoch 13450, Loss: 435.48419189453125, Neurons: 11, Grad norm: 1.246e+01\n",
      "Epoch 13451, Loss: 435.4815368652344, Neurons: 11, Grad norm: 7.224e+00\n",
      "Epoch 13452, Loss: 435.4788818359375, Neurons: 11, Grad norm: 2.994e+00\n",
      "Epoch 13453, Loss: 435.4761962890625, Neurons: 11, Grad norm: 3.427e+00\n",
      "Epoch 13454, Loss: 435.4736022949219, Neurons: 11, Grad norm: 5.504e+00\n",
      "Epoch 13455, Loss: 435.4709777832031, Neurons: 11, Grad norm: 9.139e+00\n",
      "Epoch 13456, Loss: 435.4682922363281, Neurons: 11, Grad norm: 1.029e+01\n",
      "Epoch 13457, Loss: 435.4656982421875, Neurons: 11, Grad norm: 1.208e+01\n",
      "Epoch 13458, Loss: 435.4630432128906, Neurons: 11, Grad norm: 1.177e+01\n",
      "Epoch 13459, Loss: 435.46038818359375, Neurons: 11, Grad norm: 1.180e+01\n",
      "Epoch 13460, Loss: 435.4577331542969, Neurons: 11, Grad norm: 1.010e+01\n",
      "Epoch 13461, Loss: 435.455078125, Neurons: 11, Grad norm: 9.457e+00\n",
      "Epoch 13462, Loss: 435.4524841308594, Neurons: 11, Grad norm: 6.968e+00\n",
      "Epoch 13463, Loss: 435.4497985839844, Neurons: 11, Grad norm: 6.093e+00\n",
      "Epoch 13464, Loss: 435.4471435546875, Neurons: 11, Grad norm: 2.923e+00\n",
      "Epoch 13465, Loss: 435.4444885253906, Neurons: 11, Grad norm: 1.871e+00\n",
      "Epoch 13466, Loss: 435.44183349609375, Neurons: 11, Grad norm: 1.955e+00\n",
      "Epoch 13467, Loss: 435.4391784667969, Neurons: 11, Grad norm: 2.782e+00\n",
      "Epoch 13468, Loss: 435.4364929199219, Neurons: 11, Grad norm: 4.891e+00\n",
      "Epoch 13469, Loss: 435.43389892578125, Neurons: 11, Grad norm: 5.071e+00\n",
      "Epoch 13470, Loss: 435.4311828613281, Neurons: 11, Grad norm: 6.530e+00\n",
      "Epoch 13471, Loss: 435.42852783203125, Neurons: 11, Grad norm: 5.879e+00\n",
      "Epoch 13472, Loss: 435.4259033203125, Neurons: 11, Grad norm: 6.481e+00\n",
      "Epoch 13473, Loss: 435.4231872558594, Neurons: 11, Grad norm: 5.235e+00\n",
      "Epoch 13474, Loss: 435.4205322265625, Neurons: 11, Grad norm: 5.106e+00\n",
      "Epoch 13475, Loss: 435.4178771972656, Neurons: 11, Grad norm: 3.543e+00\n",
      "Epoch 13476, Loss: 435.4152526855469, Neurons: 11, Grad norm: 3.289e+00\n",
      "Epoch 13477, Loss: 435.41253662109375, Neurons: 11, Grad norm: 1.960e+00\n",
      "Epoch 13478, Loss: 435.4098815917969, Neurons: 11, Grad norm: 1.954e+00\n",
      "Epoch 13479, Loss: 435.4072265625, Neurons: 11, Grad norm: 1.667e+00\n",
      "Epoch 13480, Loss: 435.404541015625, Neurons: 11, Grad norm: 1.616e+00\n",
      "Epoch 13481, Loss: 435.4018859863281, Neurons: 11, Grad norm: 2.103e+00\n",
      "Epoch 13482, Loss: 435.3992004394531, Neurons: 11, Grad norm: 1.853e+00\n",
      "Epoch 13483, Loss: 435.396484375, Neurons: 11, Grad norm: 2.510e+00\n",
      "Epoch 13484, Loss: 435.3938903808594, Neurons: 11, Grad norm: 2.215e+00\n",
      "Epoch 13485, Loss: 435.39117431640625, Neurons: 11, Grad norm: 2.918e+00\n",
      "Epoch 13486, Loss: 435.38848876953125, Neurons: 11, Grad norm: 2.500e+00\n",
      "Epoch 13487, Loss: 435.38580322265625, Neurons: 11, Grad norm: 3.757e+00\n",
      "Epoch 13488, Loss: 435.3831481933594, Neurons: 11, Grad norm: 3.152e+00\n",
      "Epoch 13489, Loss: 435.38043212890625, Neurons: 11, Grad norm: 4.113e+00\n",
      "Epoch 13490, Loss: 435.3777770996094, Neurons: 11, Grad norm: 4.305e+00\n",
      "Epoch 13491, Loss: 435.3750915527344, Neurons: 11, Grad norm: 5.140e+00\n",
      "Epoch 13492, Loss: 435.3724365234375, Neurons: 11, Grad norm: 4.813e+00\n",
      "Epoch 13493, Loss: 435.3697509765625, Neurons: 11, Grad norm: 5.737e+00\n",
      "Epoch 13494, Loss: 435.3669738769531, Neurons: 11, Grad norm: 4.959e+00\n",
      "Epoch 13495, Loss: 435.3643493652344, Neurons: 11, Grad norm: 6.674e+00\n",
      "Epoch 13496, Loss: 435.3616943359375, Neurons: 11, Grad norm: 5.952e+00\n",
      "Epoch 13497, Loss: 435.3589782714844, Neurons: 11, Grad norm: 6.856e+00\n",
      "Epoch 13498, Loss: 435.3562927246094, Neurons: 11, Grad norm: 7.044e+00\n",
      "Epoch 13499, Loss: 435.35357666015625, Neurons: 11, Grad norm: 7.349e+00\n",
      "Epoch 13499, Test loss: 431.79583740234375\n",
      "Epoch 13500, Loss: 435.35089111328125, Neurons: 11, Grad norm: 6.196e+00\n",
      "Epoch 13501, Loss: 435.3481750488281, Neurons: 11, Grad norm: 6.785e+00\n",
      "Epoch 13502, Loss: 435.3454895019531, Neurons: 11, Grad norm: 5.536e+00\n",
      "Epoch 13503, Loss: 435.34283447265625, Neurons: 11, Grad norm: 6.362e+00\n",
      "Epoch 13504, Loss: 435.34014892578125, Neurons: 11, Grad norm: 6.004e+00\n",
      "Epoch 13505, Loss: 435.33740234375, Neurons: 11, Grad norm: 7.468e+00\n",
      "Epoch 13506, Loss: 435.3346862792969, Neurons: 11, Grad norm: 7.900e+00\n",
      "Epoch 13507, Loss: 435.33203125, Neurons: 11, Grad norm: 9.889e+00\n",
      "Epoch 13508, Loss: 435.32928466796875, Neurons: 11, Grad norm: 1.033e+01\n",
      "Epoch 13509, Loss: 435.3266296386719, Neurons: 11, Grad norm: 1.233e+01\n",
      "Epoch 13510, Loss: 435.3238830566406, Neurons: 11, Grad norm: 1.285e+01\n",
      "Epoch 13511, Loss: 435.3211975097656, Neurons: 11, Grad norm: 1.492e+01\n",
      "Epoch 13512, Loss: 435.31854248046875, Neurons: 11, Grad norm: 1.564e+01\n",
      "Epoch 13513, Loss: 435.3157958984375, Neurons: 11, Grad norm: 1.797e+01\n",
      "Epoch 13514, Loss: 435.3130798339844, Neurons: 11, Grad norm: 1.884e+01\n",
      "Epoch 13515, Loss: 435.3103942871094, Neurons: 11, Grad norm: 2.158e+01\n",
      "Epoch 13516, Loss: 435.30767822265625, Neurons: 11, Grad norm: 2.306e+01\n",
      "Epoch 13517, Loss: 435.30499267578125, Neurons: 11, Grad norm: 2.636e+01\n",
      "Epoch 13518, Loss: 435.3022766113281, Neurons: 11, Grad norm: 2.875e+01\n",
      "Epoch 13519, Loss: 435.2995300292969, Neurons: 11, Grad norm: 3.319e+01\n",
      "Epoch 13520, Loss: 435.296875, Neurons: 11, Grad norm: 3.692e+01\n",
      "Epoch 13521, Loss: 435.294189453125, Neurons: 11, Grad norm: 4.372e+01\n",
      "Epoch 13522, Loss: 435.29150390625, Neurons: 11, Grad norm: 5.023e+01\n",
      "Epoch 13523, Loss: 435.2888488769531, Neurons: 11, Grad norm: 5.986e+01\n",
      "Epoch 13524, Loss: 435.28619384765625, Neurons: 11, Grad norm: 6.981e+01\n",
      "Epoch 13525, Loss: 435.2835998535156, Neurons: 11, Grad norm: 8.337e+01\n",
      "Epoch 13526, Loss: 435.2809753417969, Neurons: 11, Grad norm: 9.860e+01\n",
      "Epoch 13527, Loss: 435.27850341796875, Neurons: 11, Grad norm: 1.181e+02\n",
      "Epoch 13528, Loss: 435.2760314941406, Neurons: 11, Grad norm: 1.391e+02\n",
      "Epoch 13529, Loss: 435.2738037109375, Neurons: 11, Grad norm: 1.648e+02\n",
      "Epoch 13530, Loss: 435.2715759277344, Neurons: 11, Grad norm: 1.915e+02\n",
      "Epoch 13531, Loss: 435.26959228515625, Neurons: 11, Grad norm: 2.223e+02\n",
      "Epoch 13532, Loss: 435.2677917480469, Neurons: 11, Grad norm: 2.505e+02\n",
      "Epoch 13533, Loss: 435.2660827636719, Neurons: 11, Grad norm: 2.750e+02\n",
      "Epoch 13534, Loss: 435.2643737792969, Neurons: 11, Grad norm: 2.883e+02\n",
      "Epoch 13535, Loss: 435.2622985839844, Neurons: 11, Grad norm: 2.853e+02\n",
      "Epoch 13536, Loss: 435.2594909667969, Neurons: 11, Grad norm: 2.587e+02\n",
      "Epoch 13537, Loss: 435.2558288574219, Neurons: 11, Grad norm: 2.105e+02\n",
      "Epoch 13538, Loss: 435.2515869140625, Neurons: 11, Grad norm: 1.404e+02\n",
      "Epoch 13539, Loss: 435.2471923828125, Neurons: 11, Grad norm: 6.168e+01\n",
      "Epoch 13540, Loss: 435.2434997558594, Neurons: 11, Grad norm: 1.889e+01\n",
      "Epoch 13541, Loss: 435.2406005859375, Neurons: 11, Grad norm: 8.788e+01\n",
      "Epoch 13542, Loss: 435.2384948730469, Neurons: 11, Grad norm: 1.398e+02\n",
      "Epoch 13543, Loss: 435.2367858886719, Neurons: 11, Grad norm: 1.677e+02\n",
      "Epoch 13544, Loss: 435.2348327636719, Neurons: 11, Grad norm: 1.724e+02\n",
      "Epoch 13545, Loss: 435.2323303222656, Neurons: 11, Grad norm: 1.502e+02\n",
      "Epoch 13546, Loss: 435.2292785644531, Neurons: 11, Grad norm: 1.102e+02\n",
      "Epoch 13547, Loss: 435.2259521484375, Neurons: 11, Grad norm: 5.635e+01\n",
      "Epoch 13548, Loss: 435.2226867675781, Neurons: 11, Grad norm: 1.609e+00\n",
      "Epoch 13549, Loss: 435.2198791503906, Neurons: 11, Grad norm: 5.188e+01\n",
      "Epoch 13549, Test loss: 431.657470703125\n",
      "Epoch 13550, Loss: 435.2174987792969, Neurons: 11, Grad norm: 8.989e+01\n",
      "Epoch 13551, Loss: 435.21533203125, Neurons: 11, Grad norm: 1.120e+02\n",
      "Epoch 13552, Loss: 435.2131042480469, Neurons: 11, Grad norm: 1.132e+02\n",
      "Epoch 13553, Loss: 435.2105407714844, Neurons: 11, Grad norm: 9.931e+01\n",
      "Epoch 13554, Loss: 435.2077331542969, Neurons: 11, Grad norm: 7.008e+01\n",
      "Epoch 13555, Loss: 435.2048034667969, Neurons: 11, Grad norm: 3.478e+01\n",
      "Epoch 13556, Loss: 435.2019958496094, Neurons: 11, Grad norm: 3.964e+00\n",
      "Epoch 13557, Loss: 435.19927978515625, Neurons: 11, Grad norm: 3.678e+01\n",
      "Epoch 13558, Loss: 435.19683837890625, Neurons: 11, Grad norm: 6.253e+01\n",
      "Epoch 13559, Loss: 435.1944274902344, Neurons: 11, Grad norm: 7.526e+01\n",
      "Epoch 13560, Loss: 435.1919860839844, Neurons: 11, Grad norm: 7.704e+01\n",
      "Epoch 13561, Loss: 435.189453125, Neurons: 11, Grad norm: 6.622e+01\n",
      "Epoch 13562, Loss: 435.1867980957031, Neurons: 11, Grad norm: 4.857e+01\n",
      "Epoch 13563, Loss: 435.1839904785156, Neurons: 11, Grad norm: 2.365e+01\n",
      "Epoch 13564, Loss: 435.1812744140625, Neurons: 11, Grad norm: 1.832e+00\n",
      "Epoch 13565, Loss: 435.1786804199219, Neurons: 11, Grad norm: 2.439e+01\n",
      "Epoch 13566, Loss: 435.1761779785156, Neurons: 11, Grad norm: 4.073e+01\n",
      "Epoch 13567, Loss: 435.1736755371094, Neurons: 11, Grad norm: 5.144e+01\n",
      "Epoch 13568, Loss: 435.17120361328125, Neurons: 11, Grad norm: 5.276e+01\n",
      "Epoch 13569, Loss: 435.1685791015625, Neurons: 11, Grad norm: 4.797e+01\n",
      "Epoch 13570, Loss: 435.1659851074219, Neurons: 11, Grad norm: 3.590e+01\n",
      "Epoch 13571, Loss: 435.163330078125, Neurons: 11, Grad norm: 2.168e+01\n",
      "Epoch 13572, Loss: 435.1606750488281, Neurons: 11, Grad norm: 5.039e+00\n",
      "Epoch 13573, Loss: 435.1580505371094, Neurons: 11, Grad norm: 1.003e+01\n",
      "Epoch 13574, Loss: 435.1554870605469, Neurons: 11, Grad norm: 2.406e+01\n",
      "Epoch 13575, Loss: 435.1529541015625, Neurons: 11, Grad norm: 3.234e+01\n",
      "Epoch 13576, Loss: 435.150390625, Neurons: 11, Grad norm: 3.747e+01\n",
      "Epoch 13577, Loss: 435.1478271484375, Neurons: 11, Grad norm: 3.636e+01\n",
      "Epoch 13578, Loss: 435.1452331542969, Neurons: 11, Grad norm: 3.229e+01\n",
      "Epoch 13579, Loss: 435.142578125, Neurons: 11, Grad norm: 2.312e+01\n",
      "Epoch 13580, Loss: 435.1399841308594, Neurons: 11, Grad norm: 1.337e+01\n",
      "Epoch 13581, Loss: 435.13739013671875, Neurons: 11, Grad norm: 2.164e+00\n",
      "Epoch 13582, Loss: 435.1347961425781, Neurons: 11, Grad norm: 8.168e+00\n",
      "Epoch 13583, Loss: 435.1322021484375, Neurons: 11, Grad norm: 1.712e+01\n",
      "Epoch 13584, Loss: 435.12957763671875, Neurons: 11, Grad norm: 2.238e+01\n",
      "Epoch 13585, Loss: 435.1270446777344, Neurons: 11, Grad norm: 2.632e+01\n",
      "Epoch 13586, Loss: 435.1244812011719, Neurons: 11, Grad norm: 2.571e+01\n",
      "Epoch 13587, Loss: 435.121826171875, Neurons: 11, Grad norm: 2.420e+01\n",
      "Epoch 13588, Loss: 435.1192932128906, Neurons: 11, Grad norm: 1.901e+01\n",
      "Epoch 13589, Loss: 435.1165771484375, Neurons: 11, Grad norm: 1.401e+01\n",
      "Epoch 13590, Loss: 435.1139831542969, Neurons: 11, Grad norm: 6.508e+00\n",
      "Epoch 13591, Loss: 435.11138916015625, Neurons: 11, Grad norm: 1.589e+00\n",
      "Epoch 13592, Loss: 435.1087951660156, Neurons: 11, Grad norm: 6.661e+00\n",
      "Epoch 13593, Loss: 435.106201171875, Neurons: 11, Grad norm: 9.992e+00\n",
      "Epoch 13594, Loss: 435.10357666015625, Neurons: 11, Grad norm: 1.375e+01\n",
      "Epoch 13595, Loss: 435.1009826660156, Neurons: 11, Grad norm: 1.497e+01\n",
      "Epoch 13596, Loss: 435.098388671875, Neurons: 11, Grad norm: 1.569e+01\n",
      "Epoch 13597, Loss: 435.0957946777344, Neurons: 11, Grad norm: 1.371e+01\n",
      "Epoch 13598, Loss: 435.09320068359375, Neurons: 11, Grad norm: 1.228e+01\n",
      "Epoch 13599, Loss: 435.0905456542969, Neurons: 11, Grad norm: 8.919e+00\n",
      "Epoch 13599, Test loss: 431.5447082519531\n",
      "Epoch 13600, Loss: 435.087890625, Neurons: 11, Grad norm: 6.967e+00\n",
      "Epoch 13601, Loss: 435.0853271484375, Neurons: 11, Grad norm: 2.961e+00\n",
      "Epoch 13602, Loss: 435.0827331542969, Neurons: 11, Grad norm: 1.578e+00\n",
      "Epoch 13603, Loss: 435.080078125, Neurons: 11, Grad norm: 3.998e+00\n",
      "Epoch 13604, Loss: 435.0774841308594, Neurons: 11, Grad norm: 5.248e+00\n",
      "Epoch 13605, Loss: 435.07489013671875, Neurons: 11, Grad norm: 7.334e+00\n",
      "Epoch 13606, Loss: 435.0722961425781, Neurons: 11, Grad norm: 7.411e+00\n",
      "Epoch 13607, Loss: 435.06964111328125, Neurons: 11, Grad norm: 8.111e+00\n",
      "Epoch 13608, Loss: 435.0670471191406, Neurons: 11, Grad norm: 7.635e+00\n",
      "Epoch 13609, Loss: 435.06439208984375, Neurons: 11, Grad norm: 7.634e+00\n",
      "Epoch 13610, Loss: 435.0617980957031, Neurons: 11, Grad norm: 5.600e+00\n",
      "Epoch 13611, Loss: 435.0592041015625, Neurons: 11, Grad norm: 5.152e+00\n",
      "Epoch 13612, Loss: 435.0564880371094, Neurons: 11, Grad norm: 2.786e+00\n",
      "Epoch 13613, Loss: 435.05389404296875, Neurons: 11, Grad norm: 2.746e+00\n",
      "Epoch 13614, Loss: 435.0512390136719, Neurons: 11, Grad norm: 1.600e+00\n",
      "Epoch 13615, Loss: 435.04864501953125, Neurons: 11, Grad norm: 1.680e+00\n",
      "Epoch 13616, Loss: 435.0459899902344, Neurons: 11, Grad norm: 1.909e+00\n",
      "Epoch 13617, Loss: 435.04339599609375, Neurons: 11, Grad norm: 2.041e+00\n",
      "Epoch 13618, Loss: 435.0407409667969, Neurons: 11, Grad norm: 3.137e+00\n",
      "Epoch 13619, Loss: 435.0380859375, Neurons: 11, Grad norm: 2.547e+00\n",
      "Epoch 13620, Loss: 435.0354919433594, Neurons: 11, Grad norm: 3.679e+00\n",
      "Epoch 13621, Loss: 435.03289794921875, Neurons: 11, Grad norm: 2.578e+00\n",
      "Epoch 13622, Loss: 435.0301818847656, Neurons: 11, Grad norm: 3.040e+00\n",
      "Epoch 13623, Loss: 435.027587890625, Neurons: 11, Grad norm: 2.120e+00\n",
      "Epoch 13624, Loss: 435.02490234375, Neurons: 11, Grad norm: 1.657e+00\n",
      "Epoch 13625, Loss: 435.02227783203125, Neurons: 11, Grad norm: 1.695e+00\n",
      "Epoch 13626, Loss: 435.0196838378906, Neurons: 11, Grad norm: 1.601e+00\n",
      "Epoch 13627, Loss: 435.0169982910156, Neurons: 11, Grad norm: 2.211e+00\n",
      "Epoch 13628, Loss: 435.0143737792969, Neurons: 11, Grad norm: 1.804e+00\n",
      "Epoch 13629, Loss: 435.0116882324219, Neurons: 11, Grad norm: 2.542e+00\n",
      "Epoch 13630, Loss: 435.00909423828125, Neurons: 11, Grad norm: 2.024e+00\n",
      "Epoch 13631, Loss: 435.0064392089844, Neurons: 11, Grad norm: 2.443e+00\n",
      "Epoch 13632, Loss: 435.0037841796875, Neurons: 11, Grad norm: 1.983e+00\n",
      "Epoch 13633, Loss: 435.0011291503906, Neurons: 11, Grad norm: 2.299e+00\n",
      "Epoch 13634, Loss: 434.99847412109375, Neurons: 11, Grad norm: 1.871e+00\n",
      "Epoch 13635, Loss: 434.995849609375, Neurons: 11, Grad norm: 2.334e+00\n",
      "Epoch 13636, Loss: 434.9931945800781, Neurons: 11, Grad norm: 1.582e+00\n",
      "Epoch 13637, Loss: 434.9906005859375, Neurons: 11, Grad norm: 1.587e+00\n",
      "Epoch 13638, Loss: 434.98785400390625, Neurons: 11, Grad norm: 1.872e+00\n",
      "Epoch 13639, Loss: 434.9852294921875, Neurons: 11, Grad norm: 1.686e+00\n",
      "Epoch 13640, Loss: 434.9825744628906, Neurons: 11, Grad norm: 2.173e+00\n",
      "Epoch 13641, Loss: 434.9798889160156, Neurons: 11, Grad norm: 1.956e+00\n",
      "Epoch 13642, Loss: 434.977294921875, Neurons: 11, Grad norm: 2.788e+00\n",
      "Epoch 13643, Loss: 434.9745788574219, Neurons: 11, Grad norm: 1.992e+00\n",
      "Epoch 13644, Loss: 434.971923828125, Neurons: 11, Grad norm: 2.666e+00\n",
      "Epoch 13645, Loss: 434.96929931640625, Neurons: 11, Grad norm: 2.624e+00\n",
      "Epoch 13646, Loss: 434.9665832519531, Neurons: 11, Grad norm: 3.334e+00\n",
      "Epoch 13647, Loss: 434.96392822265625, Neurons: 11, Grad norm: 3.256e+00\n",
      "Epoch 13648, Loss: 434.9613037109375, Neurons: 11, Grad norm: 5.018e+00\n",
      "Epoch 13649, Loss: 434.9585876464844, Neurons: 11, Grad norm: 4.763e+00\n",
      "Epoch 13649, Test loss: 431.4165344238281\n",
      "Epoch 13650, Loss: 434.9559326171875, Neurons: 11, Grad norm: 6.481e+00\n",
      "Epoch 13651, Loss: 434.9532775878906, Neurons: 11, Grad norm: 7.346e+00\n",
      "Epoch 13652, Loss: 434.9505920410156, Neurons: 11, Grad norm: 9.046e+00\n",
      "Epoch 13653, Loss: 434.947998046875, Neurons: 11, Grad norm: 9.796e+00\n",
      "Epoch 13654, Loss: 434.9452819824219, Neurons: 11, Grad norm: 1.260e+01\n",
      "Epoch 13655, Loss: 434.9425964355469, Neurons: 11, Grad norm: 1.345e+01\n",
      "Epoch 13656, Loss: 434.93994140625, Neurons: 11, Grad norm: 1.634e+01\n",
      "Epoch 13657, Loss: 434.9372863769531, Neurons: 11, Grad norm: 1.872e+01\n",
      "Epoch 13658, Loss: 434.9345397949219, Neurons: 11, Grad norm: 2.294e+01\n",
      "Epoch 13659, Loss: 434.931884765625, Neurons: 11, Grad norm: 2.603e+01\n",
      "Epoch 13660, Loss: 434.9292907714844, Neurons: 11, Grad norm: 3.109e+01\n",
      "Epoch 13661, Loss: 434.92657470703125, Neurons: 11, Grad norm: 3.607e+01\n",
      "Epoch 13662, Loss: 434.92388916015625, Neurons: 11, Grad norm: 4.342e+01\n",
      "Epoch 13663, Loss: 434.9212951660156, Neurons: 11, Grad norm: 4.986e+01\n",
      "Epoch 13664, Loss: 434.91864013671875, Neurons: 11, Grad norm: 5.921e+01\n",
      "Epoch 13665, Loss: 434.9159851074219, Neurons: 11, Grad norm: 6.905e+01\n",
      "Epoch 13666, Loss: 434.9134826660156, Neurons: 11, Grad norm: 8.293e+01\n",
      "Epoch 13667, Loss: 434.91094970703125, Neurons: 11, Grad norm: 9.814e+01\n",
      "Epoch 13668, Loss: 434.908447265625, Neurons: 11, Grad norm: 1.178e+02\n",
      "Epoch 13669, Loss: 434.9060974121094, Neurons: 11, Grad norm: 1.394e+02\n",
      "Epoch 13670, Loss: 434.9037780761719, Neurons: 11, Grad norm: 1.663e+02\n",
      "Epoch 13671, Loss: 434.9017028808594, Neurons: 11, Grad norm: 1.947e+02\n",
      "Epoch 13672, Loss: 434.8997802734375, Neurons: 11, Grad norm: 2.262e+02\n",
      "Epoch 13673, Loss: 434.8981018066406, Neurons: 11, Grad norm: 2.557e+02\n",
      "Epoch 13674, Loss: 434.896484375, Neurons: 11, Grad norm: 2.812e+02\n",
      "Epoch 13675, Loss: 434.894775390625, Neurons: 11, Grad norm: 2.945e+02\n",
      "Epoch 13676, Loss: 434.8927001953125, Neurons: 11, Grad norm: 2.912e+02\n",
      "Epoch 13677, Loss: 434.8899841308594, Neurons: 11, Grad norm: 2.628e+02\n",
      "Epoch 13678, Loss: 434.88629150390625, Neurons: 11, Grad norm: 2.122e+02\n",
      "Epoch 13679, Loss: 434.8819274902344, Neurons: 11, Grad norm: 1.388e+02\n",
      "Epoch 13680, Loss: 434.8775329589844, Neurons: 11, Grad norm: 5.639e+01\n",
      "Epoch 13681, Loss: 434.87384033203125, Neurons: 11, Grad norm: 2.612e+01\n",
      "Epoch 13682, Loss: 434.87109375, Neurons: 11, Grad norm: 9.566e+01\n",
      "Epoch 13683, Loss: 434.869140625, Neurons: 11, Grad norm: 1.463e+02\n",
      "Epoch 13684, Loss: 434.86749267578125, Neurons: 11, Grad norm: 1.717e+02\n",
      "Epoch 13685, Loss: 434.865478515625, Neurons: 11, Grad norm: 1.723e+02\n",
      "Epoch 13686, Loss: 434.8629455566406, Neurons: 11, Grad norm: 1.457e+02\n",
      "Epoch 13687, Loss: 434.85980224609375, Neurons: 11, Grad norm: 1.021e+02\n",
      "Epoch 13688, Loss: 434.8564758300781, Neurons: 11, Grad norm: 4.554e+01\n",
      "Epoch 13689, Loss: 434.85333251953125, Neurons: 11, Grad norm: 1.151e+01\n",
      "Epoch 13690, Loss: 434.8506774902344, Neurons: 11, Grad norm: 6.204e+01\n",
      "Epoch 13691, Loss: 434.848388671875, Neurons: 11, Grad norm: 9.686e+01\n",
      "Epoch 13692, Loss: 434.8462829589844, Neurons: 11, Grad norm: 1.152e+02\n",
      "Epoch 13693, Loss: 434.843994140625, Neurons: 11, Grad norm: 1.127e+02\n",
      "Epoch 13694, Loss: 434.84149169921875, Neurons: 11, Grad norm: 9.434e+01\n",
      "Epoch 13695, Loss: 434.8385925292969, Neurons: 11, Grad norm: 6.190e+01\n",
      "Epoch 13696, Loss: 434.835693359375, Neurons: 11, Grad norm: 2.465e+01\n",
      "Epoch 13697, Loss: 434.83294677734375, Neurons: 11, Grad norm: 1.365e+01\n",
      "Epoch 13698, Loss: 434.83038330078125, Neurons: 11, Grad norm: 4.410e+01\n",
      "Epoch 13699, Loss: 434.8280029296875, Neurons: 11, Grad norm: 6.627e+01\n",
      "Epoch 13699, Test loss: 431.2756652832031\n",
      "Epoch 13700, Loss: 434.8255920410156, Neurons: 11, Grad norm: 7.474e+01\n",
      "Epoch 13701, Loss: 434.82318115234375, Neurons: 11, Grad norm: 7.240e+01\n",
      "Epoch 13702, Loss: 434.8205871582031, Neurons: 11, Grad norm: 5.787e+01\n",
      "Epoch 13703, Loss: 434.81793212890625, Neurons: 11, Grad norm: 3.737e+01\n",
      "Epoch 13704, Loss: 434.815185546875, Neurons: 11, Grad norm: 1.239e+01\n",
      "Epoch 13705, Loss: 434.8126525878906, Neurons: 11, Grad norm: 1.073e+01\n",
      "Epoch 13706, Loss: 434.8100891113281, Neurons: 11, Grad norm: 3.119e+01\n",
      "Epoch 13707, Loss: 434.8075866699219, Neurons: 11, Grad norm: 4.366e+01\n",
      "Epoch 13708, Loss: 434.8051452636719, Neurons: 11, Grad norm: 5.040e+01\n",
      "Epoch 13709, Loss: 434.8026428222656, Neurons: 11, Grad norm: 4.798e+01\n",
      "Epoch 13710, Loss: 434.8000793457031, Neurons: 11, Grad norm: 4.053e+01\n",
      "Epoch 13711, Loss: 434.7974853515625, Neurons: 11, Grad norm: 2.717e+01\n",
      "Epoch 13712, Loss: 434.7948303222656, Neurons: 11, Grad norm: 1.223e+01\n",
      "Epoch 13713, Loss: 434.792236328125, Neurons: 11, Grad norm: 4.617e+00\n",
      "Epoch 13714, Loss: 434.78973388671875, Neurons: 11, Grad norm: 1.800e+01\n",
      "Epoch 13715, Loss: 434.7872009277344, Neurons: 11, Grad norm: 2.964e+01\n",
      "Epoch 13716, Loss: 434.7846984863281, Neurons: 11, Grad norm: 3.418e+01\n",
      "Epoch 13717, Loss: 434.7821350097656, Neurons: 11, Grad norm: 3.557e+01\n",
      "Epoch 13718, Loss: 434.77960205078125, Neurons: 11, Grad norm: 3.063e+01\n",
      "Epoch 13719, Loss: 434.77703857421875, Neurons: 11, Grad norm: 2.403e+01\n",
      "Epoch 13720, Loss: 434.77447509765625, Neurons: 11, Grad norm: 1.437e+01\n",
      "Epoch 13721, Loss: 434.7718505859375, Neurons: 11, Grad norm: 5.212e+00\n",
      "Epoch 13722, Loss: 434.769287109375, Neurons: 11, Grad norm: 4.825e+00\n",
      "Epoch 13723, Loss: 434.7667541503906, Neurons: 11, Grad norm: 1.193e+01\n",
      "Epoch 13724, Loss: 434.7641906738281, Neurons: 11, Grad norm: 1.891e+01\n",
      "Epoch 13725, Loss: 434.7616271972656, Neurons: 11, Grad norm: 2.148e+01\n",
      "Epoch 13726, Loss: 434.7591247558594, Neurons: 11, Grad norm: 2.353e+01\n",
      "Epoch 13727, Loss: 434.75653076171875, Neurons: 11, Grad norm: 2.125e+01\n",
      "Epoch 13728, Loss: 434.7539978027344, Neurons: 11, Grad norm: 1.862e+01\n",
      "Epoch 13729, Loss: 434.75140380859375, Neurons: 11, Grad norm: 1.339e+01\n",
      "Epoch 13730, Loss: 434.748779296875, Neurons: 11, Grad norm: 7.835e+00\n",
      "Epoch 13731, Loss: 434.74627685546875, Neurons: 11, Grad norm: 1.917e+00\n",
      "Epoch 13732, Loss: 434.7436828613281, Neurons: 11, Grad norm: 3.556e+00\n",
      "Epoch 13733, Loss: 434.7410888671875, Neurons: 11, Grad norm: 8.676e+00\n",
      "Epoch 13734, Loss: 434.738525390625, Neurons: 11, Grad norm: 1.064e+01\n",
      "Epoch 13735, Loss: 434.7359924316406, Neurons: 11, Grad norm: 1.303e+01\n",
      "Epoch 13736, Loss: 434.7334289550781, Neurons: 11, Grad norm: 1.326e+01\n",
      "Epoch 13737, Loss: 434.73089599609375, Neurons: 11, Grad norm: 1.363e+01\n",
      "Epoch 13738, Loss: 434.7282409667969, Neurons: 11, Grad norm: 1.210e+01\n",
      "Epoch 13739, Loss: 434.7256774902344, Neurons: 11, Grad norm: 1.119e+01\n",
      "Epoch 13740, Loss: 434.72314453125, Neurons: 11, Grad norm: 7.745e+00\n",
      "Epoch 13741, Loss: 434.7205810546875, Neurons: 11, Grad norm: 5.788e+00\n",
      "Epoch 13742, Loss: 434.7179260253906, Neurons: 11, Grad norm: 2.305e+00\n",
      "Epoch 13743, Loss: 434.71539306640625, Neurons: 11, Grad norm: 1.611e+00\n",
      "Epoch 13744, Loss: 434.7127990722656, Neurons: 11, Grad norm: 3.252e+00\n",
      "Epoch 13745, Loss: 434.7102355957031, Neurons: 11, Grad norm: 3.770e+00\n",
      "Epoch 13746, Loss: 434.70758056640625, Neurons: 11, Grad norm: 5.333e+00\n",
      "Epoch 13747, Loss: 434.705078125, Neurons: 11, Grad norm: 4.921e+00\n",
      "Epoch 13748, Loss: 434.7024841308594, Neurons: 11, Grad norm: 5.657e+00\n",
      "Epoch 13749, Loss: 434.69989013671875, Neurons: 11, Grad norm: 4.512e+00\n",
      "Epoch 13749, Test loss: 431.1663818359375\n",
      "Epoch 13750, Loss: 434.6972961425781, Neurons: 11, Grad norm: 4.452e+00\n",
      "Epoch 13751, Loss: 434.6947326660156, Neurons: 11, Grad norm: 2.948e+00\n",
      "Epoch 13752, Loss: 434.69219970703125, Neurons: 11, Grad norm: 2.513e+00\n",
      "Epoch 13753, Loss: 434.6895446777344, Neurons: 11, Grad norm: 1.571e+00\n",
      "Epoch 13754, Loss: 434.68695068359375, Neurons: 11, Grad norm: 1.566e+00\n",
      "Epoch 13755, Loss: 434.68438720703125, Neurons: 11, Grad norm: 2.335e+00\n",
      "Epoch 13756, Loss: 434.6817321777344, Neurons: 11, Grad norm: 2.285e+00\n",
      "Epoch 13757, Loss: 434.67919921875, Neurons: 11, Grad norm: 3.226e+00\n",
      "Epoch 13758, Loss: 434.67657470703125, Neurons: 11, Grad norm: 2.238e+00\n",
      "Epoch 13759, Loss: 434.6739807128906, Neurons: 11, Grad norm: 2.766e+00\n",
      "Epoch 13760, Loss: 434.67138671875, Neurons: 11, Grad norm: 2.580e+00\n",
      "Epoch 13761, Loss: 434.6687927246094, Neurons: 11, Grad norm: 2.897e+00\n",
      "Epoch 13762, Loss: 434.66619873046875, Neurons: 11, Grad norm: 2.387e+00\n",
      "Epoch 13763, Loss: 434.66357421875, Neurons: 11, Grad norm: 2.714e+00\n",
      "Epoch 13764, Loss: 434.6609802246094, Neurons: 11, Grad norm: 1.881e+00\n",
      "Epoch 13765, Loss: 434.65838623046875, Neurons: 11, Grad norm: 2.790e+00\n",
      "Epoch 13766, Loss: 434.6557922363281, Neurons: 11, Grad norm: 1.866e+00\n",
      "Epoch 13767, Loss: 434.6531982421875, Neurons: 11, Grad norm: 1.792e+00\n",
      "Epoch 13768, Loss: 434.6506042480469, Neurons: 11, Grad norm: 1.583e+00\n",
      "Epoch 13769, Loss: 434.6479797363281, Neurons: 11, Grad norm: 1.766e+00\n",
      "Epoch 13770, Loss: 434.6453857421875, Neurons: 11, Grad norm: 1.546e+00\n",
      "Epoch 13771, Loss: 434.6427307128906, Neurons: 11, Grad norm: 1.585e+00\n",
      "Epoch 13772, Loss: 434.64007568359375, Neurons: 11, Grad norm: 2.446e+00\n",
      "Epoch 13773, Loss: 434.6374816894531, Neurons: 11, Grad norm: 2.189e+00\n",
      "Epoch 13774, Loss: 434.6348876953125, Neurons: 11, Grad norm: 2.769e+00\n",
      "Epoch 13775, Loss: 434.6322937011719, Neurons: 11, Grad norm: 2.468e+00\n",
      "Epoch 13776, Loss: 434.62969970703125, Neurons: 11, Grad norm: 3.927e+00\n",
      "Epoch 13777, Loss: 434.6270446777344, Neurons: 11, Grad norm: 3.684e+00\n",
      "Epoch 13778, Loss: 434.62445068359375, Neurons: 11, Grad norm: 4.873e+00\n",
      "Epoch 13779, Loss: 434.621826171875, Neurons: 11, Grad norm: 4.711e+00\n",
      "Epoch 13780, Loss: 434.61920166015625, Neurons: 11, Grad norm: 5.533e+00\n",
      "Epoch 13781, Loss: 434.6165771484375, Neurons: 11, Grad norm: 5.926e+00\n",
      "Epoch 13782, Loss: 434.61395263671875, Neurons: 11, Grad norm: 7.392e+00\n",
      "Epoch 13783, Loss: 434.61138916015625, Neurons: 11, Grad norm: 6.910e+00\n",
      "Epoch 13784, Loss: 434.60870361328125, Neurons: 11, Grad norm: 8.194e+00\n",
      "Epoch 13785, Loss: 434.6060791015625, Neurons: 11, Grad norm: 7.451e+00\n",
      "Epoch 13786, Loss: 434.6034851074219, Neurons: 11, Grad norm: 8.216e+00\n",
      "Epoch 13787, Loss: 434.6007995605469, Neurons: 11, Grad norm: 7.634e+00\n",
      "Epoch 13788, Loss: 434.5981750488281, Neurons: 11, Grad norm: 8.188e+00\n",
      "Epoch 13789, Loss: 434.5955810546875, Neurons: 11, Grad norm: 7.720e+00\n",
      "Epoch 13790, Loss: 434.5929260253906, Neurons: 11, Grad norm: 8.336e+00\n",
      "Epoch 13791, Loss: 434.5903015136719, Neurons: 11, Grad norm: 7.664e+00\n",
      "Epoch 13792, Loss: 434.5876770019531, Neurons: 11, Grad norm: 8.571e+00\n",
      "Epoch 13793, Loss: 434.5850524902344, Neurons: 11, Grad norm: 7.977e+00\n",
      "Epoch 13794, Loss: 434.5823974609375, Neurons: 11, Grad norm: 9.116e+00\n",
      "Epoch 13795, Loss: 434.5798034667969, Neurons: 11, Grad norm: 8.854e+00\n",
      "Epoch 13796, Loss: 434.57708740234375, Neurons: 11, Grad norm: 1.001e+01\n",
      "Epoch 13797, Loss: 434.5744934082031, Neurons: 11, Grad norm: 1.022e+01\n",
      "Epoch 13798, Loss: 434.5718994140625, Neurons: 11, Grad norm: 1.247e+01\n",
      "Epoch 13799, Loss: 434.5691833496094, Neurons: 11, Grad norm: 1.314e+01\n",
      "Epoch 13799, Test loss: 431.0422668457031\n",
      "Epoch 13800, Loss: 434.56658935546875, Neurons: 11, Grad norm: 1.549e+01\n",
      "Epoch 13801, Loss: 434.56390380859375, Neurons: 11, Grad norm: 1.753e+01\n",
      "Epoch 13802, Loss: 434.561279296875, Neurons: 11, Grad norm: 2.068e+01\n",
      "Epoch 13803, Loss: 434.5586242675781, Neurons: 11, Grad norm: 2.300e+01\n",
      "Epoch 13804, Loss: 434.5559997558594, Neurons: 11, Grad norm: 2.730e+01\n",
      "Epoch 13805, Loss: 434.5533752441406, Neurons: 11, Grad norm: 3.022e+01\n",
      "Epoch 13806, Loss: 434.5507507324219, Neurons: 11, Grad norm: 3.648e+01\n",
      "Epoch 13807, Loss: 434.548095703125, Neurons: 11, Grad norm: 4.217e+01\n",
      "Epoch 13808, Loss: 434.5455017089844, Neurons: 11, Grad norm: 5.067e+01\n",
      "Epoch 13809, Loss: 434.5428771972656, Neurons: 11, Grad norm: 6.005e+01\n",
      "Epoch 13810, Loss: 434.54034423828125, Neurons: 11, Grad norm: 7.217e+01\n",
      "Epoch 13811, Loss: 434.5377502441406, Neurons: 11, Grad norm: 8.583e+01\n",
      "Epoch 13812, Loss: 434.5352783203125, Neurons: 11, Grad norm: 1.042e+02\n",
      "Epoch 13813, Loss: 434.53289794921875, Neurons: 11, Grad norm: 1.241e+02\n",
      "Epoch 13814, Loss: 434.53057861328125, Neurons: 11, Grad norm: 1.496e+02\n",
      "Epoch 13815, Loss: 434.52838134765625, Neurons: 11, Grad norm: 1.768e+02\n",
      "Epoch 13816, Loss: 434.52642822265625, Neurons: 11, Grad norm: 2.082e+02\n",
      "Epoch 13817, Loss: 434.5246276855469, Neurons: 11, Grad norm: 2.398e+02\n",
      "Epoch 13818, Loss: 434.5229797363281, Neurons: 11, Grad norm: 2.710e+02\n",
      "Epoch 13819, Loss: 434.5215759277344, Neurons: 11, Grad norm: 2.945e+02\n",
      "Epoch 13820, Loss: 434.5198974609375, Neurons: 11, Grad norm: 3.052e+02\n",
      "Epoch 13821, Loss: 434.5177917480469, Neurons: 11, Grad norm: 2.931e+02\n",
      "Epoch 13822, Loss: 434.5147399902344, Neurons: 11, Grad norm: 2.566e+02\n",
      "Epoch 13823, Loss: 434.51068115234375, Neurons: 11, Grad norm: 1.930e+02\n",
      "Epoch 13824, Loss: 434.5061950683594, Neurons: 11, Grad norm: 1.131e+02\n",
      "Epoch 13825, Loss: 434.50189208984375, Neurons: 11, Grad norm: 2.428e+01\n",
      "Epoch 13826, Loss: 434.49847412109375, Neurons: 11, Grad norm: 5.736e+01\n",
      "Epoch 13827, Loss: 434.4961853027344, Neurons: 11, Grad norm: 1.242e+02\n",
      "Epoch 13828, Loss: 434.4944763183594, Neurons: 11, Grad norm: 1.668e+02\n",
      "Epoch 13829, Loss: 434.4928894042969, Neurons: 11, Grad norm: 1.826e+02\n",
      "Epoch 13830, Loss: 434.4906921386719, Neurons: 11, Grad norm: 1.691e+02\n",
      "Epoch 13831, Loss: 434.4878845214844, Neurons: 11, Grad norm: 1.325e+02\n",
      "Epoch 13832, Loss: 434.4845886230469, Neurons: 11, Grad norm: 7.655e+01\n",
      "Epoch 13833, Loss: 434.4812316894531, Neurons: 11, Grad norm: 1.594e+01\n",
      "Epoch 13834, Loss: 434.47833251953125, Neurons: 11, Grad norm: 4.315e+01\n",
      "Epoch 13835, Loss: 434.4759521484375, Neurons: 11, Grad norm: 8.851e+01\n",
      "Epoch 13836, Loss: 434.473876953125, Neurons: 11, Grad norm: 1.159e+02\n",
      "Epoch 13837, Loss: 434.4718017578125, Neurons: 11, Grad norm: 1.206e+02\n",
      "Epoch 13838, Loss: 434.4693908691406, Neurons: 11, Grad norm: 1.062e+02\n",
      "Epoch 13839, Loss: 434.4666442871094, Neurons: 11, Grad norm: 7.382e+01\n",
      "Epoch 13840, Loss: 434.46368408203125, Neurons: 11, Grad norm: 3.458e+01\n",
      "Epoch 13841, Loss: 434.4609375, Neurons: 11, Grad norm: 7.689e+00\n",
      "Epoch 13842, Loss: 434.4583435058594, Neurons: 11, Grad norm: 4.281e+01\n",
      "Epoch 13843, Loss: 434.45599365234375, Neurons: 11, Grad norm: 6.857e+01\n",
      "Epoch 13844, Loss: 434.45367431640625, Neurons: 11, Grad norm: 7.970e+01\n",
      "Epoch 13845, Loss: 434.4512939453125, Neurons: 11, Grad norm: 7.789e+01\n",
      "Epoch 13846, Loss: 434.44879150390625, Neurons: 11, Grad norm: 6.291e+01\n",
      "Epoch 13847, Loss: 434.4460754394531, Neurons: 11, Grad norm: 4.110e+01\n",
      "Epoch 13848, Loss: 434.4434814453125, Neurons: 11, Grad norm: 1.304e+01\n",
      "Epoch 13849, Loss: 434.4407958984375, Neurons: 11, Grad norm: 1.310e+01\n",
      "Epoch 13849, Test loss: 430.9184265136719\n",
      "Epoch 13850, Loss: 434.4383239746094, Neurons: 11, Grad norm: 3.561e+01\n",
      "Epoch 13851, Loss: 434.4358825683594, Neurons: 11, Grad norm: 4.911e+01\n",
      "Epoch 13852, Loss: 434.4335021972656, Neurons: 11, Grad norm: 5.501e+01\n",
      "Epoch 13853, Loss: 434.4310302734375, Neurons: 11, Grad norm: 5.032e+01\n",
      "Epoch 13854, Loss: 434.4284973144531, Neurons: 11, Grad norm: 4.009e+01\n",
      "Epoch 13855, Loss: 434.4259338378906, Neurons: 11, Grad norm: 2.374e+01\n",
      "Epoch 13856, Loss: 434.42333984375, Neurons: 11, Grad norm: 6.244e+00\n",
      "Epoch 13857, Loss: 434.4207763671875, Neurons: 11, Grad norm: 1.194e+01\n",
      "Epoch 13858, Loss: 434.41827392578125, Neurons: 11, Grad norm: 2.569e+01\n",
      "Epoch 13859, Loss: 434.4158020019531, Neurons: 11, Grad norm: 3.614e+01\n",
      "Epoch 13860, Loss: 434.41339111328125, Neurons: 11, Grad norm: 3.887e+01\n",
      "Epoch 13861, Loss: 434.410888671875, Neurons: 11, Grad norm: 3.802e+01\n",
      "Epoch 13862, Loss: 434.4083251953125, Neurons: 11, Grad norm: 3.059e+01\n",
      "Epoch 13863, Loss: 434.4057922363281, Neurons: 11, Grad norm: 2.133e+01\n",
      "Epoch 13864, Loss: 434.4031982421875, Neurons: 11, Grad norm: 9.464e+00\n",
      "Epoch 13865, Loss: 434.40069580078125, Neurons: 11, Grad norm: 2.198e+00\n",
      "Epoch 13866, Loss: 434.398193359375, Neurons: 11, Grad norm: 1.235e+01\n",
      "Epoch 13867, Loss: 434.39569091796875, Neurons: 11, Grad norm: 1.916e+01\n",
      "Epoch 13868, Loss: 434.3931884765625, Neurons: 11, Grad norm: 2.467e+01\n",
      "Epoch 13869, Loss: 434.390625, Neurons: 11, Grad norm: 2.532e+01\n",
      "Epoch 13870, Loss: 434.3881530761719, Neurons: 11, Grad norm: 2.453e+01\n",
      "Epoch 13871, Loss: 434.3855895996094, Neurons: 11, Grad norm: 1.961e+01\n",
      "Epoch 13872, Loss: 434.3830871582031, Neurons: 11, Grad norm: 1.369e+01\n",
      "Epoch 13873, Loss: 434.3805847167969, Neurons: 11, Grad norm: 5.513e+00\n",
      "Epoch 13874, Loss: 434.37799072265625, Neurons: 11, Grad norm: 2.199e+00\n",
      "Epoch 13875, Loss: 434.37548828125, Neurons: 11, Grad norm: 9.115e+00\n",
      "Epoch 13876, Loss: 434.37298583984375, Neurons: 11, Grad norm: 1.314e+01\n",
      "Epoch 13877, Loss: 434.3704528808594, Neurons: 11, Grad norm: 1.670e+01\n",
      "Epoch 13878, Loss: 434.3679504394531, Neurons: 11, Grad norm: 1.655e+01\n",
      "Epoch 13879, Loss: 434.3653869628906, Neurons: 11, Grad norm: 1.570e+01\n",
      "Epoch 13880, Loss: 434.36285400390625, Neurons: 11, Grad norm: 1.220e+01\n",
      "Epoch 13881, Loss: 434.36029052734375, Neurons: 11, Grad norm: 8.797e+00\n",
      "Epoch 13882, Loss: 434.3577880859375, Neurons: 11, Grad norm: 3.903e+00\n",
      "Epoch 13883, Loss: 434.3551940917969, Neurons: 11, Grad norm: 1.642e+00\n",
      "Epoch 13884, Loss: 434.3527526855469, Neurons: 11, Grad norm: 4.479e+00\n",
      "Epoch 13885, Loss: 434.3501892089844, Neurons: 11, Grad norm: 6.560e+00\n",
      "Epoch 13886, Loss: 434.34759521484375, Neurons: 11, Grad norm: 9.147e+00\n",
      "Epoch 13887, Loss: 434.3450927734375, Neurons: 11, Grad norm: 1.022e+01\n",
      "Epoch 13888, Loss: 434.342529296875, Neurons: 11, Grad norm: 1.071e+01\n",
      "Epoch 13889, Loss: 434.3399963378906, Neurons: 11, Grad norm: 9.245e+00\n",
      "Epoch 13890, Loss: 434.3374938964844, Neurons: 11, Grad norm: 8.444e+00\n",
      "Epoch 13891, Loss: 434.3349304199219, Neurons: 11, Grad norm: 4.550e+00\n",
      "Epoch 13892, Loss: 434.3323974609375, Neurons: 11, Grad norm: 2.991e+00\n",
      "Epoch 13893, Loss: 434.329833984375, Neurons: 11, Grad norm: 1.819e+00\n",
      "Epoch 13894, Loss: 434.3273010253906, Neurons: 11, Grad norm: 3.936e+00\n",
      "Epoch 13895, Loss: 434.3246765136719, Neurons: 11, Grad norm: 6.137e+00\n",
      "Epoch 13896, Loss: 434.3221740722656, Neurons: 11, Grad norm: 6.654e+00\n",
      "Epoch 13897, Loss: 434.319580078125, Neurons: 11, Grad norm: 7.975e+00\n",
      "Epoch 13898, Loss: 434.31707763671875, Neurons: 11, Grad norm: 6.976e+00\n",
      "Epoch 13899, Loss: 434.3145446777344, Neurons: 11, Grad norm: 7.269e+00\n",
      "Epoch 13899, Test loss: 430.7922668457031\n",
      "Epoch 13900, Loss: 434.3119812011719, Neurons: 11, Grad norm: 5.278e+00\n",
      "Epoch 13901, Loss: 434.3094482421875, Neurons: 11, Grad norm: 4.652e+00\n",
      "Epoch 13902, Loss: 434.306884765625, Neurons: 11, Grad norm: 3.417e+00\n",
      "Epoch 13903, Loss: 434.3042907714844, Neurons: 11, Grad norm: 2.768e+00\n",
      "Epoch 13904, Loss: 434.3017883300781, Neurons: 11, Grad norm: 1.557e+00\n",
      "Epoch 13905, Loss: 434.2991943359375, Neurons: 11, Grad norm: 1.682e+00\n",
      "Epoch 13906, Loss: 434.2966003417969, Neurons: 11, Grad norm: 3.066e+00\n",
      "Epoch 13907, Loss: 434.2940368652344, Neurons: 11, Grad norm: 3.278e+00\n",
      "Epoch 13908, Loss: 434.29150390625, Neurons: 11, Grad norm: 4.523e+00\n",
      "Epoch 13909, Loss: 434.2889404296875, Neurons: 11, Grad norm: 4.458e+00\n",
      "Epoch 13910, Loss: 434.286376953125, Neurons: 11, Grad norm: 5.134e+00\n",
      "Epoch 13911, Loss: 434.2838439941406, Neurons: 11, Grad norm: 4.463e+00\n",
      "Epoch 13912, Loss: 434.28125, Neurons: 11, Grad norm: 4.769e+00\n",
      "Epoch 13913, Loss: 434.2785949707031, Neurons: 11, Grad norm: 3.541e+00\n",
      "Epoch 13914, Loss: 434.2760925292969, Neurons: 11, Grad norm: 4.362e+00\n",
      "Epoch 13915, Loss: 434.2735290527344, Neurons: 11, Grad norm: 3.885e+00\n",
      "Epoch 13916, Loss: 434.27099609375, Neurons: 11, Grad norm: 4.349e+00\n",
      "Epoch 13917, Loss: 434.2684020996094, Neurons: 11, Grad norm: 3.704e+00\n",
      "Epoch 13918, Loss: 434.2657775878906, Neurons: 11, Grad norm: 3.985e+00\n",
      "Epoch 13919, Loss: 434.26318359375, Neurons: 11, Grad norm: 3.011e+00\n",
      "Epoch 13920, Loss: 434.26068115234375, Neurons: 11, Grad norm: 3.099e+00\n",
      "Epoch 13921, Loss: 434.2580871582031, Neurons: 11, Grad norm: 2.043e+00\n",
      "Epoch 13922, Loss: 434.2554931640625, Neurons: 11, Grad norm: 2.871e+00\n",
      "Epoch 13923, Loss: 434.2528991699219, Neurons: 11, Grad norm: 2.122e+00\n",
      "Epoch 13924, Loss: 434.2503356933594, Neurons: 11, Grad norm: 2.631e+00\n",
      "Epoch 13925, Loss: 434.247802734375, Neurons: 11, Grad norm: 2.829e+00\n",
      "Epoch 13926, Loss: 434.24517822265625, Neurons: 11, Grad norm: 3.194e+00\n",
      "Epoch 13927, Loss: 434.2425842285156, Neurons: 11, Grad norm: 2.750e+00\n",
      "Epoch 13928, Loss: 434.239990234375, Neurons: 11, Grad norm: 3.323e+00\n",
      "Epoch 13929, Loss: 434.2373962402344, Neurons: 11, Grad norm: 1.843e+00\n",
      "Epoch 13930, Loss: 434.23480224609375, Neurons: 11, Grad norm: 2.305e+00\n",
      "Epoch 13931, Loss: 434.232177734375, Neurons: 11, Grad norm: 1.558e+00\n",
      "Epoch 13932, Loss: 434.2296447753906, Neurons: 11, Grad norm: 1.571e+00\n",
      "Epoch 13933, Loss: 434.22698974609375, Neurons: 11, Grad norm: 2.009e+00\n",
      "Epoch 13934, Loss: 434.22442626953125, Neurons: 11, Grad norm: 1.810e+00\n",
      "Epoch 13935, Loss: 434.2218933105469, Neurons: 11, Grad norm: 2.478e+00\n",
      "Epoch 13936, Loss: 434.21929931640625, Neurons: 11, Grad norm: 2.056e+00\n",
      "Epoch 13937, Loss: 434.2166748046875, Neurons: 11, Grad norm: 2.986e+00\n",
      "Epoch 13938, Loss: 434.2140808105469, Neurons: 11, Grad norm: 3.279e+00\n",
      "Epoch 13939, Loss: 434.21148681640625, Neurons: 11, Grad norm: 5.234e+00\n",
      "Epoch 13940, Loss: 434.2088928222656, Neurons: 11, Grad norm: 6.338e+00\n",
      "Epoch 13941, Loss: 434.206298828125, Neurons: 11, Grad norm: 9.223e+00\n",
      "Epoch 13942, Loss: 434.2036437988281, Neurons: 11, Grad norm: 1.045e+01\n",
      "Epoch 13943, Loss: 434.2010803222656, Neurons: 11, Grad norm: 1.295e+01\n",
      "Epoch 13944, Loss: 434.19842529296875, Neurons: 11, Grad norm: 1.413e+01\n",
      "Epoch 13945, Loss: 434.1958923339844, Neurons: 11, Grad norm: 1.635e+01\n",
      "Epoch 13946, Loss: 434.1932373046875, Neurons: 11, Grad norm: 1.745e+01\n",
      "Epoch 13947, Loss: 434.190673828125, Neurons: 11, Grad norm: 1.991e+01\n",
      "Epoch 13948, Loss: 434.18804931640625, Neurons: 11, Grad norm: 2.114e+01\n",
      "Epoch 13949, Loss: 434.18548583984375, Neurons: 11, Grad norm: 2.410e+01\n",
      "Epoch 13949, Test loss: 430.6645812988281\n",
      "Epoch 13950, Loss: 434.18280029296875, Neurons: 11, Grad norm: 2.568e+01\n",
      "Epoch 13951, Loss: 434.18023681640625, Neurons: 11, Grad norm: 2.911e+01\n",
      "Epoch 13952, Loss: 434.1775817871094, Neurons: 11, Grad norm: 3.156e+01\n",
      "Epoch 13953, Loss: 434.175048828125, Neurons: 11, Grad norm: 3.581e+01\n",
      "Epoch 13954, Loss: 434.17242431640625, Neurons: 11, Grad norm: 3.962e+01\n",
      "Epoch 13955, Loss: 434.1698913574219, Neurons: 11, Grad norm: 4.625e+01\n",
      "Epoch 13956, Loss: 434.16729736328125, Neurons: 11, Grad norm: 5.281e+01\n",
      "Epoch 13957, Loss: 434.1647033691406, Neurons: 11, Grad norm: 6.234e+01\n",
      "Epoch 13958, Loss: 434.1621398925781, Neurons: 11, Grad norm: 7.310e+01\n",
      "Epoch 13959, Loss: 434.1595764160156, Neurons: 11, Grad norm: 8.731e+01\n",
      "Epoch 13960, Loss: 434.1571960449219, Neurons: 11, Grad norm: 1.026e+02\n",
      "Epoch 13961, Loss: 434.15478515625, Neurons: 11, Grad norm: 1.221e+02\n",
      "Epoch 13962, Loss: 434.1524963378906, Neurons: 11, Grad norm: 1.427e+02\n",
      "Epoch 13963, Loss: 434.1502990722656, Neurons: 11, Grad norm: 1.680e+02\n",
      "Epoch 13964, Loss: 434.148193359375, Neurons: 11, Grad norm: 1.939e+02\n",
      "Epoch 13965, Loss: 434.14630126953125, Neurons: 11, Grad norm: 2.223e+02\n",
      "Epoch 13966, Loss: 434.1445007324219, Neurons: 11, Grad norm: 2.478e+02\n",
      "Epoch 13967, Loss: 434.1427917480469, Neurons: 11, Grad norm: 2.683e+02\n",
      "Epoch 13968, Loss: 434.1409912109375, Neurons: 11, Grad norm: 2.774e+02\n",
      "Epoch 13969, Loss: 434.1387939453125, Neurons: 11, Grad norm: 2.714e+02\n",
      "Epoch 13970, Loss: 434.135986328125, Neurons: 11, Grad norm: 2.435e+02\n",
      "Epoch 13971, Loss: 434.1324462890625, Neurons: 11, Grad norm: 1.962e+02\n",
      "Epoch 13972, Loss: 434.1283874511719, Neurons: 11, Grad norm: 1.305e+02\n",
      "Epoch 13973, Loss: 434.1243896484375, Neurons: 11, Grad norm: 5.862e+01\n",
      "Epoch 13974, Loss: 434.1208801269531, Neurons: 11, Grad norm: 1.490e+01\n",
      "Epoch 13975, Loss: 434.1181945800781, Neurons: 11, Grad norm: 7.753e+01\n",
      "Epoch 13976, Loss: 434.1160888671875, Neurons: 11, Grad norm: 1.262e+02\n",
      "Epoch 13977, Loss: 434.1142883300781, Neurons: 11, Grad norm: 1.544e+02\n",
      "Epoch 13978, Loss: 434.1123962402344, Neurons: 11, Grad norm: 1.611e+02\n",
      "Epoch 13979, Loss: 434.1099853515625, Neurons: 11, Grad norm: 1.462e+02\n",
      "Epoch 13980, Loss: 434.107177734375, Neurons: 11, Grad norm: 1.146e+02\n",
      "Epoch 13981, Loss: 434.1040954589844, Neurons: 11, Grad norm: 6.830e+01\n",
      "Epoch 13982, Loss: 434.1009826660156, Neurons: 11, Grad norm: 1.984e+01\n",
      "Epoch 13983, Loss: 434.0981750488281, Neurons: 11, Grad norm: 2.894e+01\n",
      "Epoch 13984, Loss: 434.0957946777344, Neurons: 11, Grad norm: 6.791e+01\n",
      "Epoch 13985, Loss: 434.0935363769531, Neurons: 11, Grad norm: 9.443e+01\n",
      "Epoch 13986, Loss: 434.0914001464844, Neurons: 11, Grad norm: 1.049e+02\n",
      "Epoch 13987, Loss: 434.0889892578125, Neurons: 11, Grad norm: 1.011e+02\n",
      "Epoch 13988, Loss: 434.08642578125, Neurons: 11, Grad norm: 8.291e+01\n",
      "Epoch 13989, Loss: 434.083740234375, Neurons: 11, Grad norm: 5.671e+01\n",
      "Epoch 13990, Loss: 434.08099365234375, Neurons: 11, Grad norm: 2.351e+01\n",
      "Epoch 13991, Loss: 434.0782775878906, Neurons: 11, Grad norm: 8.492e+00\n",
      "Epoch 13992, Loss: 434.0757751464844, Neurons: 11, Grad norm: 3.717e+01\n",
      "Epoch 13993, Loss: 434.0733947753906, Neurons: 11, Grad norm: 5.656e+01\n",
      "Epoch 13994, Loss: 434.0710754394531, Neurons: 11, Grad norm: 6.800e+01\n",
      "Epoch 13995, Loss: 434.0686340332031, Neurons: 11, Grad norm: 6.879e+01\n",
      "Epoch 13996, Loss: 434.0661926269531, Neurons: 11, Grad norm: 6.188e+01\n",
      "Epoch 13997, Loss: 434.0635986328125, Neurons: 11, Grad norm: 4.701e+01\n",
      "Epoch 13998, Loss: 434.06097412109375, Neurons: 11, Grad norm: 2.929e+01\n",
      "Epoch 13999, Loss: 434.0583801269531, Neurons: 11, Grad norm: 8.239e+00\n",
      "Epoch 13999, Test loss: 430.54876708984375\n",
      "Epoch 14000, Loss: 434.0558776855469, Neurons: 11, Grad norm: 1.085e+01\n",
      "Epoch 14001, Loss: 434.0533447265625, Neurons: 11, Grad norm: 2.836e+01\n",
      "Epoch 14002, Loss: 434.0509948730469, Neurons: 11, Grad norm: 3.952e+01\n",
      "Epoch 14003, Loss: 434.0484313964844, Neurons: 11, Grad norm: 4.618e+01\n",
      "Epoch 14004, Loss: 434.0459899902344, Neurons: 11, Grad norm: 4.574e+01\n",
      "Epoch 14005, Loss: 434.0435485839844, Neurons: 11, Grad norm: 4.103e+01\n",
      "Epoch 14006, Loss: 434.0409851074219, Neurons: 11, Grad norm: 3.097e+01\n",
      "Epoch 14007, Loss: 434.0384521484375, Neurons: 11, Grad norm: 1.911e+01\n",
      "Epoch 14008, Loss: 434.035888671875, Neurons: 11, Grad norm: 5.046e+00\n",
      "Epoch 14009, Loss: 434.03338623046875, Neurons: 11, Grad norm: 7.448e+00\n",
      "Epoch 14010, Loss: 434.0308532714844, Neurons: 11, Grad norm: 1.975e+01\n",
      "Epoch 14011, Loss: 434.02838134765625, Neurons: 11, Grad norm: 2.662e+01\n",
      "Epoch 14012, Loss: 434.02587890625, Neurons: 11, Grad norm: 3.132e+01\n",
      "Epoch 14013, Loss: 434.02337646484375, Neurons: 11, Grad norm: 3.189e+01\n",
      "Epoch 14014, Loss: 434.0208740234375, Neurons: 11, Grad norm: 2.982e+01\n",
      "Epoch 14015, Loss: 434.0184020996094, Neurons: 11, Grad norm: 2.457e+01\n",
      "Epoch 14016, Loss: 434.0158386230469, Neurons: 11, Grad norm: 1.863e+01\n",
      "Epoch 14017, Loss: 434.0132751464844, Neurons: 11, Grad norm: 9.478e+00\n",
      "Epoch 14018, Loss: 434.01080322265625, Neurons: 11, Grad norm: 2.646e+00\n",
      "Epoch 14019, Loss: 434.00830078125, Neurons: 11, Grad norm: 6.530e+00\n",
      "Epoch 14020, Loss: 434.00579833984375, Neurons: 11, Grad norm: 1.265e+01\n",
      "Epoch 14021, Loss: 434.0032958984375, Neurons: 11, Grad norm: 1.743e+01\n",
      "Epoch 14022, Loss: 434.000732421875, Neurons: 11, Grad norm: 1.943e+01\n",
      "Epoch 14023, Loss: 433.99822998046875, Neurons: 11, Grad norm: 2.107e+01\n",
      "Epoch 14024, Loss: 433.9957275390625, Neurons: 11, Grad norm: 1.891e+01\n",
      "Epoch 14025, Loss: 433.9931945800781, Neurons: 11, Grad norm: 1.762e+01\n",
      "Epoch 14026, Loss: 433.9906921386719, Neurons: 11, Grad norm: 1.373e+01\n",
      "Epoch 14027, Loss: 433.9881896972656, Neurons: 11, Grad norm: 9.903e+00\n",
      "Epoch 14028, Loss: 433.985595703125, Neurons: 11, Grad norm: 5.016e+00\n",
      "Epoch 14029, Loss: 433.9831237792969, Neurons: 11, Grad norm: 1.705e+00\n",
      "Epoch 14030, Loss: 433.9805908203125, Neurons: 11, Grad norm: 4.328e+00\n",
      "Epoch 14031, Loss: 433.97802734375, Neurons: 11, Grad norm: 6.655e+00\n",
      "Epoch 14032, Loss: 433.9754943847656, Neurons: 11, Grad norm: 9.932e+00\n",
      "Epoch 14033, Loss: 433.9729919433594, Neurons: 11, Grad norm: 1.055e+01\n",
      "Epoch 14034, Loss: 433.9704895019531, Neurons: 11, Grad norm: 1.195e+01\n",
      "Epoch 14035, Loss: 433.9679260253906, Neurons: 11, Grad norm: 1.113e+01\n",
      "Epoch 14036, Loss: 433.96539306640625, Neurons: 11, Grad norm: 1.066e+01\n",
      "Epoch 14037, Loss: 433.96282958984375, Neurons: 11, Grad norm: 8.593e+00\n",
      "Epoch 14038, Loss: 433.9603271484375, Neurons: 11, Grad norm: 7.080e+00\n",
      "Epoch 14039, Loss: 433.9577941894531, Neurons: 11, Grad norm: 4.344e+00\n",
      "Epoch 14040, Loss: 433.9552307128906, Neurons: 11, Grad norm: 2.916e+00\n",
      "Epoch 14041, Loss: 433.95269775390625, Neurons: 11, Grad norm: 2.006e+00\n",
      "Epoch 14042, Loss: 433.9501953125, Neurons: 11, Grad norm: 2.944e+00\n",
      "Epoch 14043, Loss: 433.9476013183594, Neurons: 11, Grad norm: 4.638e+00\n",
      "Epoch 14044, Loss: 433.9450988769531, Neurons: 11, Grad norm: 5.520e+00\n",
      "Epoch 14045, Loss: 433.9425354003906, Neurons: 11, Grad norm: 6.771e+00\n",
      "Epoch 14046, Loss: 433.94000244140625, Neurons: 11, Grad norm: 6.799e+00\n",
      "Epoch 14047, Loss: 433.93743896484375, Neurons: 11, Grad norm: 8.463e+00\n",
      "Epoch 14048, Loss: 433.9349365234375, Neurons: 11, Grad norm: 7.508e+00\n",
      "Epoch 14049, Loss: 433.9324035644531, Neurons: 11, Grad norm: 8.146e+00\n",
      "Epoch 14049, Test loss: 430.42401123046875\n",
      "Epoch 14050, Loss: 433.9298400878906, Neurons: 11, Grad norm: 7.736e+00\n",
      "Epoch 14051, Loss: 433.9272766113281, Neurons: 11, Grad norm: 7.525e+00\n",
      "Epoch 14052, Loss: 433.9246826171875, Neurons: 11, Grad norm: 6.426e+00\n",
      "Epoch 14053, Loss: 433.92218017578125, Neurons: 11, Grad norm: 6.114e+00\n",
      "Epoch 14054, Loss: 433.919677734375, Neurons: 11, Grad norm: 3.604e+00\n",
      "Epoch 14055, Loss: 433.9170837402344, Neurons: 11, Grad norm: 3.295e+00\n",
      "Epoch 14056, Loss: 433.91448974609375, Neurons: 11, Grad norm: 1.677e+00\n",
      "Epoch 14057, Loss: 433.9119873046875, Neurons: 11, Grad norm: 1.533e+00\n",
      "Epoch 14058, Loss: 433.9093933105469, Neurons: 11, Grad norm: 2.212e+00\n",
      "Epoch 14059, Loss: 433.9068298339844, Neurons: 11, Grad norm: 3.445e+00\n",
      "Epoch 14060, Loss: 433.904296875, Neurons: 11, Grad norm: 5.527e+00\n",
      "Epoch 14061, Loss: 433.9017333984375, Neurons: 11, Grad norm: 6.722e+00\n",
      "Epoch 14062, Loss: 433.8992004394531, Neurons: 11, Grad norm: 9.566e+00\n",
      "Epoch 14063, Loss: 433.8965759277344, Neurons: 11, Grad norm: 9.794e+00\n",
      "Epoch 14064, Loss: 433.89410400390625, Neurons: 11, Grad norm: 1.188e+01\n",
      "Epoch 14065, Loss: 433.8914794921875, Neurons: 11, Grad norm: 1.213e+01\n",
      "Epoch 14066, Loss: 433.8889465332031, Neurons: 11, Grad norm: 1.338e+01\n",
      "Epoch 14067, Loss: 433.8863525390625, Neurons: 11, Grad norm: 1.447e+01\n",
      "Epoch 14068, Loss: 433.8837890625, Neurons: 11, Grad norm: 1.615e+01\n",
      "Epoch 14069, Loss: 433.8812255859375, Neurons: 11, Grad norm: 1.639e+01\n",
      "Epoch 14070, Loss: 433.87860107421875, Neurons: 11, Grad norm: 1.790e+01\n",
      "Epoch 14071, Loss: 433.8760986328125, Neurons: 11, Grad norm: 1.743e+01\n",
      "Epoch 14072, Loss: 433.87347412109375, Neurons: 11, Grad norm: 1.847e+01\n",
      "Epoch 14073, Loss: 433.8709411621094, Neurons: 11, Grad norm: 1.782e+01\n",
      "Epoch 14074, Loss: 433.8683776855469, Neurons: 11, Grad norm: 1.942e+01\n",
      "Epoch 14075, Loss: 433.86578369140625, Neurons: 11, Grad norm: 2.025e+01\n",
      "Epoch 14076, Loss: 433.8631896972656, Neurons: 11, Grad norm: 2.160e+01\n",
      "Epoch 14077, Loss: 433.8606262207031, Neurons: 11, Grad norm: 2.229e+01\n",
      "Epoch 14078, Loss: 433.85809326171875, Neurons: 11, Grad norm: 2.407e+01\n",
      "Epoch 14079, Loss: 433.8553771972656, Neurons: 11, Grad norm: 2.458e+01\n",
      "Epoch 14080, Loss: 433.8528747558594, Neurons: 11, Grad norm: 2.693e+01\n",
      "Epoch 14081, Loss: 433.850341796875, Neurons: 11, Grad norm: 2.764e+01\n",
      "Epoch 14082, Loss: 433.8477783203125, Neurons: 11, Grad norm: 3.121e+01\n",
      "Epoch 14083, Loss: 433.8451843261719, Neurons: 11, Grad norm: 3.392e+01\n",
      "Epoch 14084, Loss: 433.842529296875, Neurons: 11, Grad norm: 3.851e+01\n",
      "Epoch 14085, Loss: 433.84002685546875, Neurons: 11, Grad norm: 4.327e+01\n",
      "Epoch 14086, Loss: 433.8374938964844, Neurons: 11, Grad norm: 4.970e+01\n",
      "Epoch 14087, Loss: 433.8349304199219, Neurons: 11, Grad norm: 5.614e+01\n",
      "Epoch 14088, Loss: 433.8324279785156, Neurons: 11, Grad norm: 6.511e+01\n",
      "Epoch 14089, Loss: 433.82989501953125, Neurons: 11, Grad norm: 7.362e+01\n",
      "Epoch 14090, Loss: 433.827392578125, Neurons: 11, Grad norm: 8.548e+01\n",
      "Epoch 14091, Loss: 433.82489013671875, Neurons: 11, Grad norm: 9.791e+01\n",
      "Epoch 14092, Loss: 433.8224792480469, Neurons: 11, Grad norm: 1.135e+02\n",
      "Epoch 14093, Loss: 433.8200988769531, Neurons: 11, Grad norm: 1.299e+02\n",
      "Epoch 14094, Loss: 433.8179016113281, Neurons: 11, Grad norm: 1.496e+02\n",
      "Epoch 14095, Loss: 433.8156433105469, Neurons: 11, Grad norm: 1.689e+02\n",
      "Epoch 14096, Loss: 433.81353759765625, Neurons: 11, Grad norm: 1.903e+02\n",
      "Epoch 14097, Loss: 433.8114929199219, Neurons: 11, Grad norm: 2.101e+02\n",
      "Epoch 14098, Loss: 433.8094787597656, Neurons: 11, Grad norm: 2.275e+02\n",
      "Epoch 14099, Loss: 433.8074951171875, Neurons: 11, Grad norm: 2.385e+02\n",
      "Epoch 14099, Test loss: 430.3559265136719\n",
      "Epoch 14100, Loss: 433.8052978515625, Neurons: 11, Grad norm: 2.410e+02\n",
      "Epoch 14101, Loss: 433.80279541015625, Neurons: 11, Grad norm: 2.293e+02\n",
      "Epoch 14102, Loss: 433.79998779296875, Neurons: 11, Grad norm: 2.051e+02\n",
      "Epoch 14103, Loss: 433.796630859375, Neurons: 11, Grad norm: 1.642e+02\n",
      "Epoch 14104, Loss: 433.79315185546875, Neurons: 11, Grad norm: 1.138e+02\n",
      "Epoch 14105, Loss: 433.7895812988281, Neurons: 11, Grad norm: 5.609e+01\n",
      "Epoch 14106, Loss: 433.786376953125, Neurons: 11, Grad norm: 1.727e+00\n",
      "Epoch 14107, Loss: 433.78369140625, Neurons: 11, Grad norm: 5.280e+01\n",
      "Epoch 14108, Loss: 433.7814025878906, Neurons: 11, Grad norm: 9.315e+01\n",
      "Epoch 14109, Loss: 433.779296875, Neurons: 11, Grad norm: 1.217e+02\n",
      "Epoch 14110, Loss: 433.7771911621094, Neurons: 11, Grad norm: 1.344e+02\n",
      "Epoch 14111, Loss: 433.7749938964844, Neurons: 11, Grad norm: 1.335e+02\n",
      "Epoch 14112, Loss: 433.7724914550781, Neurons: 11, Grad norm: 1.172e+02\n",
      "Epoch 14113, Loss: 433.7696838378906, Neurons: 11, Grad norm: 9.159e+01\n",
      "Epoch 14114, Loss: 433.76678466796875, Neurons: 11, Grad norm: 5.749e+01\n",
      "Epoch 14115, Loss: 433.76397705078125, Neurons: 11, Grad norm: 2.233e+01\n",
      "Epoch 14116, Loss: 433.76129150390625, Neurons: 11, Grad norm: 1.312e+01\n",
      "Epoch 14117, Loss: 433.7587890625, Neurons: 11, Grad norm: 4.256e+01\n",
      "Epoch 14118, Loss: 433.7564392089844, Neurons: 11, Grad norm: 6.528e+01\n",
      "Epoch 14119, Loss: 433.75408935546875, Neurons: 11, Grad norm: 7.835e+01\n",
      "Epoch 14120, Loss: 433.7516784667969, Neurons: 11, Grad norm: 8.362e+01\n",
      "Epoch 14121, Loss: 433.7492980957031, Neurons: 11, Grad norm: 7.755e+01\n",
      "Epoch 14122, Loss: 433.7467346191406, Neurons: 11, Grad norm: 6.570e+01\n",
      "Epoch 14123, Loss: 433.74407958984375, Neurons: 11, Grad norm: 4.678e+01\n",
      "Epoch 14124, Loss: 433.7414855957031, Neurons: 11, Grad norm: 2.620e+01\n",
      "Epoch 14125, Loss: 433.7388916015625, Neurons: 11, Grad norm: 4.565e+00\n",
      "Epoch 14126, Loss: 433.7362976074219, Neurons: 11, Grad norm: 1.550e+01\n",
      "Epoch 14127, Loss: 433.73388671875, Neurons: 11, Grad norm: 3.228e+01\n",
      "Epoch 14128, Loss: 433.7314758300781, Neurons: 11, Grad norm: 4.298e+01\n",
      "Epoch 14129, Loss: 433.72900390625, Neurons: 11, Grad norm: 5.062e+01\n",
      "Epoch 14130, Loss: 433.7265319824219, Neurons: 11, Grad norm: 5.097e+01\n",
      "Epoch 14131, Loss: 433.7240905761719, Neurons: 11, Grad norm: 4.831e+01\n",
      "Epoch 14132, Loss: 433.7215881347656, Neurons: 11, Grad norm: 4.040e+01\n",
      "Epoch 14133, Loss: 433.718994140625, Neurons: 11, Grad norm: 3.073e+01\n",
      "Epoch 14134, Loss: 433.71649169921875, Neurons: 11, Grad norm: 1.798e+01\n",
      "Epoch 14135, Loss: 433.7138977050781, Neurons: 11, Grad norm: 5.964e+00\n",
      "Epoch 14136, Loss: 433.7113952636719, Neurons: 11, Grad norm: 6.019e+00\n",
      "Epoch 14137, Loss: 433.7088928222656, Neurons: 11, Grad norm: 1.515e+01\n",
      "Epoch 14138, Loss: 433.7063903808594, Neurons: 11, Grad norm: 2.409e+01\n",
      "Epoch 14139, Loss: 433.7038879394531, Neurons: 11, Grad norm: 2.863e+01\n",
      "Epoch 14140, Loss: 433.7014465332031, Neurons: 11, Grad norm: 3.251e+01\n",
      "Epoch 14141, Loss: 433.6989440917969, Neurons: 11, Grad norm: 3.124e+01\n",
      "Epoch 14142, Loss: 433.6964416503906, Neurons: 11, Grad norm: 2.897e+01\n",
      "Epoch 14143, Loss: 433.6938781738281, Neurons: 11, Grad norm: 2.459e+01\n",
      "Epoch 14144, Loss: 433.6913757324219, Neurons: 11, Grad norm: 1.944e+01\n",
      "Epoch 14145, Loss: 433.6888427734375, Neurons: 11, Grad norm: 1.237e+01\n",
      "Epoch 14146, Loss: 433.6864013671875, Neurons: 11, Grad norm: 6.416e+00\n",
      "Epoch 14147, Loss: 433.683837890625, Neurons: 11, Grad norm: 1.883e+00\n",
      "Epoch 14148, Loss: 433.6812744140625, Neurons: 11, Grad norm: 6.197e+00\n",
      "Epoch 14149, Loss: 433.6788024902344, Neurons: 11, Grad norm: 1.174e+01\n",
      "Epoch 14149, Test loss: 430.1794128417969\n",
      "Epoch 14150, Loss: 433.6763000488281, Neurons: 11, Grad norm: 1.455e+01\n",
      "Epoch 14151, Loss: 433.6737976074219, Neurons: 11, Grad norm: 1.742e+01\n",
      "Epoch 14152, Loss: 433.6712341308594, Neurons: 11, Grad norm: 1.868e+01\n",
      "Epoch 14153, Loss: 433.6687927246094, Neurons: 11, Grad norm: 1.983e+01\n",
      "Epoch 14154, Loss: 433.66619873046875, Neurons: 11, Grad norm: 1.849e+01\n",
      "Epoch 14155, Loss: 433.6636962890625, Neurons: 11, Grad norm: 1.762e+01\n",
      "Epoch 14156, Loss: 433.66119384765625, Neurons: 11, Grad norm: 1.453e+01\n",
      "Epoch 14157, Loss: 433.6585998535156, Neurons: 11, Grad norm: 1.225e+01\n",
      "Epoch 14158, Loss: 433.6560974121094, Neurons: 11, Grad norm: 8.405e+00\n",
      "Epoch 14159, Loss: 433.6535949707031, Neurons: 11, Grad norm: 6.471e+00\n",
      "Epoch 14160, Loss: 433.6510925292969, Neurons: 11, Grad norm: 3.771e+00\n",
      "Epoch 14161, Loss: 433.64849853515625, Neurons: 11, Grad norm: 2.009e+00\n",
      "Epoch 14162, Loss: 433.64599609375, Neurons: 11, Grad norm: 2.121e+00\n",
      "Epoch 14163, Loss: 433.64349365234375, Neurons: 11, Grad norm: 3.334e+00\n",
      "Epoch 14164, Loss: 433.64093017578125, Neurons: 11, Grad norm: 6.383e+00\n",
      "Epoch 14165, Loss: 433.6383972167969, Neurons: 11, Grad norm: 7.648e+00\n",
      "Epoch 14166, Loss: 433.6358947753906, Neurons: 11, Grad norm: 1.049e+01\n",
      "Epoch 14167, Loss: 433.6333312988281, Neurons: 11, Grad norm: 1.184e+01\n",
      "Epoch 14168, Loss: 433.6308288574219, Neurons: 11, Grad norm: 1.325e+01\n",
      "Epoch 14169, Loss: 433.6282958984375, Neurons: 11, Grad norm: 1.331e+01\n",
      "Epoch 14170, Loss: 433.625732421875, Neurons: 11, Grad norm: 1.397e+01\n",
      "Epoch 14171, Loss: 433.62322998046875, Neurons: 11, Grad norm: 1.314e+01\n",
      "Epoch 14172, Loss: 433.6206970214844, Neurons: 11, Grad norm: 1.427e+01\n",
      "Epoch 14173, Loss: 433.61810302734375, Neurons: 11, Grad norm: 1.282e+01\n",
      "Epoch 14174, Loss: 433.6156005859375, Neurons: 11, Grad norm: 1.283e+01\n",
      "Epoch 14175, Loss: 433.61297607421875, Neurons: 11, Grad norm: 1.130e+01\n",
      "Epoch 14176, Loss: 433.6105041503906, Neurons: 11, Grad norm: 1.057e+01\n",
      "Epoch 14177, Loss: 433.6079406738281, Neurons: 11, Grad norm: 9.922e+00\n",
      "Epoch 14178, Loss: 433.6053466796875, Neurons: 11, Grad norm: 9.533e+00\n",
      "Epoch 14179, Loss: 433.602783203125, Neurons: 11, Grad norm: 8.089e+00\n",
      "Epoch 14180, Loss: 433.60028076171875, Neurons: 11, Grad norm: 9.165e+00\n",
      "Epoch 14181, Loss: 433.5977478027344, Neurons: 11, Grad norm: 7.438e+00\n",
      "Epoch 14182, Loss: 433.5951843261719, Neurons: 11, Grad norm: 7.937e+00\n",
      "Epoch 14183, Loss: 433.59259033203125, Neurons: 11, Grad norm: 6.946e+00\n",
      "Epoch 14184, Loss: 433.590087890625, Neurons: 11, Grad norm: 5.842e+00\n",
      "Epoch 14185, Loss: 433.5874938964844, Neurons: 11, Grad norm: 5.143e+00\n",
      "Epoch 14186, Loss: 433.5849914550781, Neurons: 11, Grad norm: 5.384e+00\n",
      "Epoch 14187, Loss: 433.5823974609375, Neurons: 11, Grad norm: 4.305e+00\n",
      "Epoch 14188, Loss: 433.579833984375, Neurons: 11, Grad norm: 4.986e+00\n",
      "Epoch 14189, Loss: 433.5773010253906, Neurons: 11, Grad norm: 3.784e+00\n",
      "Epoch 14190, Loss: 433.5747375488281, Neurons: 11, Grad norm: 4.317e+00\n",
      "Epoch 14191, Loss: 433.5721740722656, Neurons: 11, Grad norm: 3.558e+00\n",
      "Epoch 14192, Loss: 433.569580078125, Neurons: 11, Grad norm: 3.806e+00\n",
      "Epoch 14193, Loss: 433.5670471191406, Neurons: 11, Grad norm: 3.478e+00\n",
      "Epoch 14194, Loss: 433.5644836425781, Neurons: 11, Grad norm: 3.957e+00\n",
      "Epoch 14195, Loss: 433.5618896484375, Neurons: 11, Grad norm: 3.609e+00\n",
      "Epoch 14196, Loss: 433.5592956542969, Neurons: 11, Grad norm: 4.491e+00\n",
      "Epoch 14197, Loss: 433.5567932128906, Neurons: 11, Grad norm: 4.002e+00\n",
      "Epoch 14198, Loss: 433.55419921875, Neurons: 11, Grad norm: 5.209e+00\n",
      "Epoch 14199, Loss: 433.5516357421875, Neurons: 11, Grad norm: 4.906e+00\n",
      "Epoch 14199, Test loss: 430.0606384277344\n",
      "Epoch 14200, Loss: 433.5490417480469, Neurons: 11, Grad norm: 5.970e+00\n",
      "Epoch 14201, Loss: 433.5464782714844, Neurons: 11, Grad norm: 6.027e+00\n",
      "Epoch 14202, Loss: 433.54388427734375, Neurons: 11, Grad norm: 7.119e+00\n",
      "Epoch 14203, Loss: 433.5412902832031, Neurons: 11, Grad norm: 6.543e+00\n",
      "Epoch 14204, Loss: 433.5387268066406, Neurons: 11, Grad norm: 7.855e+00\n",
      "Epoch 14205, Loss: 433.5361328125, Neurons: 11, Grad norm: 8.878e+00\n",
      "Epoch 14206, Loss: 433.5335998535156, Neurons: 11, Grad norm: 1.080e+01\n",
      "Epoch 14207, Loss: 433.5309753417969, Neurons: 11, Grad norm: 1.195e+01\n",
      "Epoch 14208, Loss: 433.52838134765625, Neurons: 11, Grad norm: 1.479e+01\n",
      "Epoch 14209, Loss: 433.5258483886719, Neurons: 11, Grad norm: 1.653e+01\n",
      "Epoch 14210, Loss: 433.5232849121094, Neurons: 11, Grad norm: 2.138e+01\n",
      "Epoch 14211, Loss: 433.52069091796875, Neurons: 11, Grad norm: 2.471e+01\n",
      "Epoch 14212, Loss: 433.51812744140625, Neurons: 11, Grad norm: 3.037e+01\n",
      "Epoch 14213, Loss: 433.5155944824219, Neurons: 11, Grad norm: 3.720e+01\n",
      "Epoch 14214, Loss: 433.51300048828125, Neurons: 11, Grad norm: 4.615e+01\n",
      "Epoch 14215, Loss: 433.51043701171875, Neurons: 11, Grad norm: 5.647e+01\n",
      "Epoch 14216, Loss: 433.5079345703125, Neurons: 11, Grad norm: 7.047e+01\n",
      "Epoch 14217, Loss: 433.5054931640625, Neurons: 11, Grad norm: 8.588e+01\n",
      "Epoch 14218, Loss: 433.5030822753906, Neurons: 11, Grad norm: 1.070e+02\n",
      "Epoch 14219, Loss: 433.5007019042969, Neurons: 11, Grad norm: 1.313e+02\n",
      "Epoch 14220, Loss: 433.49859619140625, Neurons: 11, Grad norm: 1.630e+02\n",
      "Epoch 14221, Loss: 433.49664306640625, Neurons: 11, Grad norm: 1.990e+02\n",
      "Epoch 14222, Loss: 433.4949951171875, Neurons: 11, Grad norm: 2.414e+02\n",
      "Epoch 14223, Loss: 433.4937744140625, Neurons: 11, Grad norm: 2.853e+02\n",
      "Epoch 14224, Loss: 433.4928894042969, Neurons: 11, Grad norm: 3.273e+02\n",
      "Epoch 14225, Loss: 433.4921875, Neurons: 11, Grad norm: 3.563e+02\n",
      "Epoch 14226, Loss: 433.4910888671875, Neurons: 11, Grad norm: 3.614e+02\n",
      "Epoch 14227, Loss: 433.48883056640625, Neurons: 11, Grad norm: 3.292e+02\n",
      "Epoch 14228, Loss: 433.48480224609375, Neurons: 11, Grad norm: 2.582e+02\n",
      "Epoch 14229, Loss: 433.4794006347656, Neurons: 11, Grad norm: 1.519e+02\n",
      "Epoch 14230, Loss: 433.4737854003906, Neurons: 11, Grad norm: 3.204e+01\n",
      "Epoch 14231, Loss: 433.46978759765625, Neurons: 11, Grad norm: 8.356e+01\n",
      "Epoch 14232, Loss: 433.4678039550781, Neurons: 11, Grad norm: 1.721e+02\n",
      "Epoch 14233, Loss: 433.46697998046875, Neurons: 11, Grad norm: 2.227e+02\n",
      "Epoch 14234, Loss: 433.4660339355469, Neurons: 11, Grad norm: 2.261e+02\n",
      "Epoch 14235, Loss: 433.4637451171875, Neurons: 11, Grad norm: 1.846e+02\n",
      "Epoch 14236, Loss: 433.4600830078125, Neurons: 11, Grad norm: 1.082e+02\n",
      "Epoch 14237, Loss: 433.4560852050781, Neurons: 11, Grad norm: 1.768e+01\n",
      "Epoch 14238, Loss: 433.452880859375, Neurons: 11, Grad norm: 6.946e+01\n",
      "Epoch 14239, Loss: 433.4508361816406, Neurons: 11, Grad norm: 1.306e+02\n",
      "Epoch 14240, Loss: 433.44927978515625, Neurons: 11, Grad norm: 1.598e+02\n",
      "Epoch 14241, Loss: 433.4475402832031, Neurons: 11, Grad norm: 1.495e+02\n",
      "Epoch 14242, Loss: 433.44488525390625, Neurons: 11, Grad norm: 1.071e+02\n",
      "Epoch 14243, Loss: 433.4416809082031, Neurons: 11, Grad norm: 4.425e+01\n",
      "Epoch 14244, Loss: 433.4386901855469, Neurons: 11, Grad norm: 2.225e+01\n",
      "Epoch 14245, Loss: 433.4361877441406, Neurons: 11, Grad norm: 7.793e+01\n",
      "Epoch 14246, Loss: 433.4342041015625, Neurons: 11, Grad norm: 1.093e+02\n",
      "Epoch 14247, Loss: 433.4322509765625, Neurons: 11, Grad norm: 1.156e+02\n",
      "Epoch 14248, Loss: 433.429931640625, Neurons: 11, Grad norm: 9.238e+01\n",
      "Epoch 14249, Loss: 433.42718505859375, Neurons: 11, Grad norm: 5.156e+01\n",
      "Epoch 14249, Test loss: 429.928955078125\n",
      "Epoch 14250, Loss: 433.42437744140625, Neurons: 11, Grad norm: 2.650e+00\n",
      "Epoch 14251, Loss: 433.4217834472656, Neurons: 11, Grad norm: 4.281e+01\n",
      "Epoch 14252, Loss: 433.4195861816406, Neurons: 11, Grad norm: 7.433e+01\n",
      "Epoch 14253, Loss: 433.4174499511719, Neurons: 11, Grad norm: 8.506e+01\n",
      "Epoch 14254, Loss: 433.4151916503906, Neurons: 11, Grad norm: 7.655e+01\n",
      "Epoch 14255, Loss: 433.4126892089844, Neurons: 11, Grad norm: 4.985e+01\n",
      "Epoch 14256, Loss: 433.41009521484375, Neurons: 11, Grad norm: 1.636e+01\n",
      "Epoch 14257, Loss: 433.4075927734375, Neurons: 11, Grad norm: 1.906e+01\n",
      "Epoch 14258, Loss: 433.4051818847656, Neurons: 11, Grad norm: 4.543e+01\n",
      "Epoch 14259, Loss: 433.40289306640625, Neurons: 11, Grad norm: 6.051e+01\n",
      "Epoch 14260, Loss: 433.4006042480469, Neurons: 11, Grad norm: 5.979e+01\n",
      "Epoch 14261, Loss: 433.3982238769531, Neurons: 11, Grad norm: 4.687e+01\n",
      "Epoch 14262, Loss: 433.395751953125, Neurons: 11, Grad norm: 2.439e+01\n",
      "Epoch 14263, Loss: 433.3931884765625, Neurons: 11, Grad norm: 1.513e+00\n",
      "Epoch 14264, Loss: 433.3907775878906, Neurons: 11, Grad norm: 2.348e+01\n",
      "Epoch 14265, Loss: 433.388427734375, Neurons: 11, Grad norm: 3.796e+01\n",
      "Epoch 14266, Loss: 433.3860778808594, Neurons: 11, Grad norm: 4.422e+01\n",
      "Epoch 14267, Loss: 433.38372802734375, Neurons: 11, Grad norm: 3.988e+01\n",
      "Epoch 14268, Loss: 433.38128662109375, Neurons: 11, Grad norm: 2.882e+01\n",
      "Epoch 14269, Loss: 433.3788757324219, Neurons: 11, Grad norm: 1.225e+01\n",
      "Epoch 14270, Loss: 433.3764343261719, Neurons: 11, Grad norm: 4.100e+00\n",
      "Epoch 14271, Loss: 433.3739929199219, Neurons: 11, Grad norm: 1.909e+01\n",
      "Epoch 14272, Loss: 433.37158203125, Neurons: 11, Grad norm: 2.750e+01\n",
      "Epoch 14273, Loss: 433.3692932128906, Neurons: 11, Grad norm: 3.080e+01\n",
      "Epoch 14274, Loss: 433.36688232421875, Neurons: 11, Grad norm: 2.722e+01\n",
      "Epoch 14275, Loss: 433.364501953125, Neurons: 11, Grad norm: 1.953e+01\n",
      "Epoch 14276, Loss: 433.3620300292969, Neurons: 11, Grad norm: 7.353e+00\n",
      "Epoch 14277, Loss: 433.3595886230469, Neurons: 11, Grad norm: 4.380e+00\n",
      "Epoch 14278, Loss: 433.357177734375, Neurons: 11, Grad norm: 1.489e+01\n",
      "Epoch 14279, Loss: 433.35479736328125, Neurons: 11, Grad norm: 2.037e+01\n",
      "Epoch 14280, Loss: 433.3523864746094, Neurons: 11, Grad norm: 2.257e+01\n",
      "Epoch 14281, Loss: 433.3499755859375, Neurons: 11, Grad norm: 1.923e+01\n",
      "Epoch 14282, Loss: 433.34759521484375, Neurons: 11, Grad norm: 1.362e+01\n",
      "Epoch 14283, Loss: 433.3451843261719, Neurons: 11, Grad norm: 5.046e+00\n",
      "Epoch 14284, Loss: 433.3428039550781, Neurons: 11, Grad norm: 3.262e+00\n",
      "Epoch 14285, Loss: 433.3403015136719, Neurons: 11, Grad norm: 1.062e+01\n",
      "Epoch 14286, Loss: 433.33795166015625, Neurons: 11, Grad norm: 1.439e+01\n",
      "Epoch 14287, Loss: 433.3355407714844, Neurons: 11, Grad norm: 1.639e+01\n",
      "Epoch 14288, Loss: 433.3331298828125, Neurons: 11, Grad norm: 1.405e+01\n",
      "Epoch 14289, Loss: 433.3306884765625, Neurons: 11, Grad norm: 1.137e+01\n",
      "Epoch 14290, Loss: 433.3282470703125, Neurons: 11, Grad norm: 6.173e+00\n",
      "Epoch 14291, Loss: 433.3258361816406, Neurons: 11, Grad norm: 1.683e+00\n",
      "Epoch 14292, Loss: 433.3233947753906, Neurons: 11, Grad norm: 5.131e+00\n",
      "Epoch 14293, Loss: 433.32098388671875, Neurons: 11, Grad norm: 8.455e+00\n",
      "Epoch 14294, Loss: 433.318603515625, Neurons: 11, Grad norm: 1.205e+01\n",
      "Epoch 14295, Loss: 433.3161315917969, Neurons: 11, Grad norm: 1.232e+01\n",
      "Epoch 14296, Loss: 433.3137512207031, Neurons: 11, Grad norm: 1.243e+01\n",
      "Epoch 14297, Loss: 433.311279296875, Neurons: 11, Grad norm: 9.639e+00\n",
      "Epoch 14298, Loss: 433.30889892578125, Neurons: 11, Grad norm: 6.294e+00\n",
      "Epoch 14299, Loss: 433.3064270019531, Neurons: 11, Grad norm: 2.008e+00\n",
      "Epoch 14299, Test loss: 429.82403564453125\n",
      "Epoch 14300, Loss: 433.3039855957031, Neurons: 11, Grad norm: 2.139e+00\n",
      "Epoch 14301, Loss: 433.30157470703125, Neurons: 11, Grad norm: 5.776e+00\n",
      "Epoch 14302, Loss: 433.2991943359375, Neurons: 11, Grad norm: 7.901e+00\n",
      "Epoch 14303, Loss: 433.29669189453125, Neurons: 11, Grad norm: 1.015e+01\n",
      "Epoch 14304, Loss: 433.29425048828125, Neurons: 11, Grad norm: 1.001e+01\n",
      "Epoch 14305, Loss: 433.2918395996094, Neurons: 11, Grad norm: 9.014e+00\n",
      "Epoch 14306, Loss: 433.2893981933594, Neurons: 11, Grad norm: 5.170e+00\n",
      "Epoch 14307, Loss: 433.28692626953125, Neurons: 11, Grad norm: 2.832e+00\n",
      "Epoch 14308, Loss: 433.28448486328125, Neurons: 11, Grad norm: 2.356e+00\n",
      "Epoch 14309, Loss: 433.2820739746094, Neurons: 11, Grad norm: 5.097e+00\n",
      "Epoch 14310, Loss: 433.2796325683594, Neurons: 11, Grad norm: 8.365e+00\n",
      "Epoch 14311, Loss: 433.2771911621094, Neurons: 11, Grad norm: 9.852e+00\n",
      "Epoch 14312, Loss: 433.2747802734375, Neurons: 11, Grad norm: 1.129e+01\n",
      "Epoch 14313, Loss: 433.27227783203125, Neurons: 11, Grad norm: 9.614e+00\n",
      "Epoch 14314, Loss: 433.2698974609375, Neurons: 11, Grad norm: 8.330e+00\n",
      "Epoch 14315, Loss: 433.2674255371094, Neurons: 11, Grad norm: 5.762e+00\n",
      "Epoch 14316, Loss: 433.2649841308594, Neurons: 11, Grad norm: 4.255e+00\n",
      "Epoch 14317, Loss: 433.2625427246094, Neurons: 11, Grad norm: 1.678e+00\n",
      "Epoch 14318, Loss: 433.2601013183594, Neurons: 11, Grad norm: 1.846e+00\n",
      "Epoch 14319, Loss: 433.2575988769531, Neurons: 11, Grad norm: 4.050e+00\n",
      "Epoch 14320, Loss: 433.25518798828125, Neurons: 11, Grad norm: 4.913e+00\n",
      "Epoch 14321, Loss: 433.252685546875, Neurons: 11, Grad norm: 6.120e+00\n",
      "Epoch 14322, Loss: 433.2502746582031, Neurons: 11, Grad norm: 5.481e+00\n",
      "Epoch 14323, Loss: 433.247802734375, Neurons: 11, Grad norm: 5.532e+00\n",
      "Epoch 14324, Loss: 433.2453918457031, Neurons: 11, Grad norm: 4.711e+00\n",
      "Epoch 14325, Loss: 433.2428894042969, Neurons: 11, Grad norm: 4.880e+00\n",
      "Epoch 14326, Loss: 433.2403869628906, Neurons: 11, Grad norm: 3.116e+00\n",
      "Epoch 14327, Loss: 433.2379455566406, Neurons: 11, Grad norm: 2.664e+00\n",
      "Epoch 14328, Loss: 433.2355041503906, Neurons: 11, Grad norm: 1.505e+00\n",
      "Epoch 14329, Loss: 433.2330017089844, Neurons: 11, Grad norm: 1.651e+00\n",
      "Epoch 14330, Loss: 433.2305908203125, Neurons: 11, Grad norm: 2.633e+00\n",
      "Epoch 14331, Loss: 433.22808837890625, Neurons: 11, Grad norm: 2.154e+00\n",
      "Epoch 14332, Loss: 433.2255859375, Neurons: 11, Grad norm: 2.730e+00\n",
      "Epoch 14333, Loss: 433.2231750488281, Neurons: 11, Grad norm: 2.693e+00\n",
      "Epoch 14334, Loss: 433.220703125, Neurons: 11, Grad norm: 3.011e+00\n",
      "Epoch 14335, Loss: 433.2182312011719, Neurons: 11, Grad norm: 2.370e+00\n",
      "Epoch 14336, Loss: 433.2157287597656, Neurons: 11, Grad norm: 2.693e+00\n",
      "Epoch 14337, Loss: 433.2132873535156, Neurons: 11, Grad norm: 1.703e+00\n",
      "Epoch 14338, Loss: 433.2107849121094, Neurons: 11, Grad norm: 1.711e+00\n",
      "Epoch 14339, Loss: 433.2083435058594, Neurons: 11, Grad norm: 1.646e+00\n",
      "Epoch 14340, Loss: 433.2058410644531, Neurons: 11, Grad norm: 1.522e+00\n",
      "Epoch 14341, Loss: 433.2033996582031, Neurons: 11, Grad norm: 1.614e+00\n",
      "Epoch 14342, Loss: 433.2008972167969, Neurons: 11, Grad norm: 1.822e+00\n",
      "Epoch 14343, Loss: 433.19842529296875, Neurons: 11, Grad norm: 1.983e+00\n",
      "Epoch 14344, Loss: 433.1959533691406, Neurons: 11, Grad norm: 1.512e+00\n",
      "Epoch 14345, Loss: 433.1934814453125, Neurons: 11, Grad norm: 1.573e+00\n",
      "Epoch 14346, Loss: 433.19097900390625, Neurons: 11, Grad norm: 1.495e+00\n",
      "Epoch 14347, Loss: 433.1884765625, Neurons: 11, Grad norm: 1.707e+00\n",
      "Epoch 14348, Loss: 433.18597412109375, Neurons: 11, Grad norm: 1.666e+00\n",
      "Epoch 14349, Loss: 433.1835021972656, Neurons: 11, Grad norm: 1.487e+00\n",
      "Epoch 14349, Test loss: 429.7058410644531\n",
      "Epoch 14350, Loss: 433.18109130859375, Neurons: 11, Grad norm: 1.489e+00\n",
      "Epoch 14351, Loss: 433.1785888671875, Neurons: 11, Grad norm: 1.579e+00\n",
      "Epoch 14352, Loss: 433.17608642578125, Neurons: 11, Grad norm: 1.546e+00\n",
      "Epoch 14353, Loss: 433.173583984375, Neurons: 11, Grad norm: 1.509e+00\n",
      "Epoch 14354, Loss: 433.17108154296875, Neurons: 11, Grad norm: 1.675e+00\n",
      "Epoch 14355, Loss: 433.1685791015625, Neurons: 11, Grad norm: 1.512e+00\n",
      "Epoch 14356, Loss: 433.16607666015625, Neurons: 11, Grad norm: 1.795e+00\n",
      "Epoch 14357, Loss: 433.16357421875, Neurons: 11, Grad norm: 2.084e+00\n",
      "Epoch 14358, Loss: 433.1611022949219, Neurons: 11, Grad norm: 2.735e+00\n",
      "Epoch 14359, Loss: 433.1585998535156, Neurons: 11, Grad norm: 1.773e+00\n",
      "Epoch 14360, Loss: 433.1560974121094, Neurons: 11, Grad norm: 2.065e+00\n",
      "Epoch 14361, Loss: 433.1535949707031, Neurons: 11, Grad norm: 1.517e+00\n",
      "Epoch 14362, Loss: 433.1510925292969, Neurons: 11, Grad norm: 1.577e+00\n",
      "Epoch 14363, Loss: 433.1485900878906, Neurons: 11, Grad norm: 1.500e+00\n",
      "Epoch 14364, Loss: 433.1460876464844, Neurons: 11, Grad norm: 1.491e+00\n",
      "Epoch 14365, Loss: 433.1435852050781, Neurons: 11, Grad norm: 1.580e+00\n",
      "Epoch 14366, Loss: 433.1410827636719, Neurons: 11, Grad norm: 1.494e+00\n",
      "Epoch 14367, Loss: 433.1385803222656, Neurons: 11, Grad norm: 1.653e+00\n",
      "Epoch 14368, Loss: 433.1360778808594, Neurons: 11, Grad norm: 1.509e+00\n",
      "Epoch 14369, Loss: 433.1335754394531, Neurons: 11, Grad norm: 1.600e+00\n",
      "Epoch 14370, Loss: 433.13104248046875, Neurons: 11, Grad norm: 1.502e+00\n",
      "Epoch 14371, Loss: 433.12847900390625, Neurons: 11, Grad norm: 1.548e+00\n",
      "Epoch 14372, Loss: 433.1259765625, Neurons: 11, Grad norm: 1.511e+00\n",
      "Epoch 14373, Loss: 433.12347412109375, Neurons: 11, Grad norm: 1.488e+00\n",
      "Epoch 14374, Loss: 433.1210021972656, Neurons: 11, Grad norm: 1.568e+00\n",
      "Epoch 14375, Loss: 433.1184997558594, Neurons: 11, Grad norm: 1.489e+00\n",
      "Epoch 14376, Loss: 433.1159362792969, Neurons: 11, Grad norm: 1.644e+00\n",
      "Epoch 14377, Loss: 433.1134338378906, Neurons: 11, Grad norm: 1.821e+00\n",
      "Epoch 14378, Loss: 433.11090087890625, Neurons: 11, Grad norm: 1.574e+00\n",
      "Epoch 14379, Loss: 433.1083984375, Neurons: 11, Grad norm: 1.672e+00\n",
      "Epoch 14380, Loss: 433.1058349609375, Neurons: 11, Grad norm: 1.544e+00\n",
      "Epoch 14381, Loss: 433.10333251953125, Neurons: 11, Grad norm: 1.609e+00\n",
      "Epoch 14382, Loss: 433.1007995605469, Neurons: 11, Grad norm: 1.493e+00\n",
      "Epoch 14383, Loss: 433.0982971191406, Neurons: 11, Grad norm: 1.557e+00\n",
      "Epoch 14384, Loss: 433.0957336425781, Neurons: 11, Grad norm: 2.284e+00\n",
      "Epoch 14385, Loss: 433.09320068359375, Neurons: 11, Grad norm: 2.051e+00\n",
      "Epoch 14386, Loss: 433.0906982421875, Neurons: 11, Grad norm: 3.182e+00\n",
      "Epoch 14387, Loss: 433.0881042480469, Neurons: 11, Grad norm: 4.227e+00\n",
      "Epoch 14388, Loss: 433.08563232421875, Neurons: 11, Grad norm: 5.176e+00\n",
      "Epoch 14389, Loss: 433.0830993652344, Neurons: 11, Grad norm: 5.757e+00\n",
      "Epoch 14390, Loss: 433.0805358886719, Neurons: 11, Grad norm: 8.127e+00\n",
      "Epoch 14391, Loss: 433.0780029296875, Neurons: 11, Grad norm: 8.384e+00\n",
      "Epoch 14392, Loss: 433.07550048828125, Neurons: 11, Grad norm: 1.074e+01\n",
      "Epoch 14393, Loss: 433.072998046875, Neurons: 11, Grad norm: 1.234e+01\n",
      "Epoch 14394, Loss: 433.0704040527344, Neurons: 11, Grad norm: 1.551e+01\n",
      "Epoch 14395, Loss: 433.0679016113281, Neurons: 11, Grad norm: 1.837e+01\n",
      "Epoch 14396, Loss: 433.0652770996094, Neurons: 11, Grad norm: 2.246e+01\n",
      "Epoch 14397, Loss: 433.0627746582031, Neurons: 11, Grad norm: 2.626e+01\n",
      "Epoch 14398, Loss: 433.060302734375, Neurons: 11, Grad norm: 3.176e+01\n",
      "Epoch 14399, Loss: 433.0577392578125, Neurons: 11, Grad norm: 3.566e+01\n",
      "Epoch 14399, Test loss: 429.59295654296875\n",
      "Epoch 14400, Loss: 433.05523681640625, Neurons: 11, Grad norm: 4.156e+01\n",
      "Epoch 14401, Loss: 433.0527038574219, Neurons: 11, Grad norm: 4.654e+01\n",
      "Epoch 14402, Loss: 433.0502014160156, Neurons: 11, Grad norm: 5.330e+01\n",
      "Epoch 14403, Loss: 433.0476989746094, Neurons: 11, Grad norm: 6.093e+01\n",
      "Epoch 14404, Loss: 433.0451965332031, Neurons: 11, Grad norm: 7.150e+01\n",
      "Epoch 14405, Loss: 433.042724609375, Neurons: 11, Grad norm: 8.288e+01\n",
      "Epoch 14406, Loss: 433.040283203125, Neurons: 11, Grad norm: 9.771e+01\n",
      "Epoch 14407, Loss: 433.0379333496094, Neurons: 11, Grad norm: 1.134e+02\n",
      "Epoch 14408, Loss: 433.03564453125, Neurons: 11, Grad norm: 1.327e+02\n",
      "Epoch 14409, Loss: 433.03338623046875, Neurons: 11, Grad norm: 1.526e+02\n",
      "Epoch 14410, Loss: 433.0313415527344, Neurons: 11, Grad norm: 1.753e+02\n",
      "Epoch 14411, Loss: 433.029296875, Neurons: 11, Grad norm: 1.983e+02\n",
      "Epoch 14412, Loss: 433.0273742675781, Neurons: 11, Grad norm: 2.219e+02\n",
      "Epoch 14413, Loss: 433.0255432128906, Neurons: 11, Grad norm: 2.408e+02\n",
      "Epoch 14414, Loss: 433.023681640625, Neurons: 11, Grad norm: 2.544e+02\n",
      "Epoch 14415, Loss: 433.0216369628906, Neurons: 11, Grad norm: 2.553e+02\n",
      "Epoch 14416, Loss: 433.0191345214844, Neurons: 11, Grad norm: 2.424e+02\n",
      "Epoch 14417, Loss: 433.01629638671875, Neurons: 11, Grad norm: 2.114e+02\n",
      "Epoch 14418, Loss: 433.0127868652344, Neurons: 11, Grad norm: 1.646e+02\n",
      "Epoch 14419, Loss: 433.00909423828125, Neurons: 11, Grad norm: 1.056e+02\n",
      "Epoch 14420, Loss: 433.0054931640625, Neurons: 11, Grad norm: 4.258e+01\n",
      "Epoch 14421, Loss: 433.00238037109375, Neurons: 11, Grad norm: 2.070e+01\n",
      "Epoch 14422, Loss: 432.9998474121094, Neurons: 11, Grad norm: 7.370e+01\n",
      "Epoch 14423, Loss: 432.99774169921875, Neurons: 11, Grad norm: 1.153e+02\n",
      "Epoch 14424, Loss: 432.9958801269531, Neurons: 11, Grad norm: 1.388e+02\n",
      "Epoch 14425, Loss: 432.99383544921875, Neurons: 11, Grad norm: 1.460e+02\n",
      "Epoch 14426, Loss: 432.9914855957031, Neurons: 11, Grad norm: 1.358e+02\n",
      "Epoch 14427, Loss: 432.9888916015625, Neurons: 11, Grad norm: 1.114e+02\n",
      "Epoch 14428, Loss: 432.9859924316406, Neurons: 11, Grad norm: 7.585e+01\n",
      "Epoch 14429, Loss: 432.98309326171875, Neurons: 11, Grad norm: 3.587e+01\n",
      "Epoch 14430, Loss: 432.9803466796875, Neurons: 11, Grad norm: 6.240e+00\n",
      "Epoch 14431, Loss: 432.977783203125, Neurons: 11, Grad norm: 4.154e+01\n",
      "Epoch 14432, Loss: 432.9754943847656, Neurons: 11, Grad norm: 7.060e+01\n",
      "Epoch 14433, Loss: 432.9732971191406, Neurons: 11, Grad norm: 8.686e+01\n",
      "Epoch 14434, Loss: 432.9710388183594, Neurons: 11, Grad norm: 9.311e+01\n",
      "Epoch 14435, Loss: 432.96868896484375, Neurons: 11, Grad norm: 8.711e+01\n",
      "Epoch 14436, Loss: 432.9661865234375, Neurons: 11, Grad norm: 7.123e+01\n",
      "Epoch 14437, Loss: 432.9635314941406, Neurons: 11, Grad norm: 4.822e+01\n",
      "Epoch 14438, Loss: 432.9609375, Neurons: 11, Grad norm: 2.262e+01\n",
      "Epoch 14439, Loss: 432.9583435058594, Neurons: 11, Grad norm: 4.389e+00\n",
      "Epoch 14440, Loss: 432.9559020996094, Neurons: 11, Grad norm: 2.545e+01\n",
      "Epoch 14441, Loss: 432.9534912109375, Neurons: 11, Grad norm: 4.370e+01\n",
      "Epoch 14442, Loss: 432.9510803222656, Neurons: 11, Grad norm: 5.299e+01\n",
      "Epoch 14443, Loss: 432.94873046875, Neurons: 11, Grad norm: 5.635e+01\n",
      "Epoch 14444, Loss: 432.94635009765625, Neurons: 11, Grad norm: 5.300e+01\n",
      "Epoch 14445, Loss: 432.9438781738281, Neurons: 11, Grad norm: 4.435e+01\n",
      "Epoch 14446, Loss: 432.94134521484375, Neurons: 11, Grad norm: 3.161e+01\n",
      "Epoch 14447, Loss: 432.93878173828125, Neurons: 11, Grad norm: 1.791e+01\n",
      "Epoch 14448, Loss: 432.9364013671875, Neurons: 11, Grad norm: 2.365e+00\n",
      "Epoch 14449, Loss: 432.93389892578125, Neurons: 11, Grad norm: 1.096e+01\n",
      "Epoch 14449, Test loss: 429.4689025878906\n",
      "Epoch 14450, Loss: 432.9314270019531, Neurons: 11, Grad norm: 2.376e+01\n",
      "Epoch 14451, Loss: 432.9289855957031, Neurons: 11, Grad norm: 3.160e+01\n",
      "Epoch 14452, Loss: 432.92657470703125, Neurons: 11, Grad norm: 3.581e+01\n",
      "Epoch 14453, Loss: 432.9241943359375, Neurons: 11, Grad norm: 3.648e+01\n",
      "Epoch 14454, Loss: 432.92169189453125, Neurons: 11, Grad norm: 3.393e+01\n",
      "Epoch 14455, Loss: 432.9192810058594, Neurons: 11, Grad norm: 2.699e+01\n",
      "Epoch 14456, Loss: 432.9167785644531, Neurons: 11, Grad norm: 1.966e+01\n",
      "Epoch 14457, Loss: 432.9142761230469, Neurons: 11, Grad norm: 9.392e+00\n",
      "Epoch 14458, Loss: 432.91180419921875, Neurons: 11, Grad norm: 1.693e+00\n",
      "Epoch 14459, Loss: 432.9093933105469, Neurons: 11, Grad norm: 8.363e+00\n",
      "Epoch 14460, Loss: 432.9068908691406, Neurons: 11, Grad norm: 1.475e+01\n",
      "Epoch 14461, Loss: 432.9043884277344, Neurons: 11, Grad norm: 2.079e+01\n",
      "Epoch 14462, Loss: 432.9019775390625, Neurons: 11, Grad norm: 2.409e+01\n",
      "Epoch 14463, Loss: 432.89959716796875, Neurons: 11, Grad norm: 2.609e+01\n",
      "Epoch 14464, Loss: 432.8970947265625, Neurons: 11, Grad norm: 2.523e+01\n",
      "Epoch 14465, Loss: 432.8946533203125, Neurons: 11, Grad norm: 2.302e+01\n",
      "Epoch 14466, Loss: 432.8921813964844, Neurons: 11, Grad norm: 1.776e+01\n",
      "Epoch 14467, Loss: 432.8896789550781, Neurons: 11, Grad norm: 1.303e+01\n",
      "Epoch 14468, Loss: 432.8871765136719, Neurons: 11, Grad norm: 6.260e+00\n",
      "Epoch 14469, Loss: 432.8847351074219, Neurons: 11, Grad norm: 2.345e+00\n",
      "Epoch 14470, Loss: 432.8822326660156, Neurons: 11, Grad norm: 4.291e+00\n",
      "Epoch 14471, Loss: 432.8797912597656, Neurons: 11, Grad norm: 8.886e+00\n",
      "Epoch 14472, Loss: 432.8772888183594, Neurons: 11, Grad norm: 1.239e+01\n",
      "Epoch 14473, Loss: 432.8748779296875, Neurons: 11, Grad norm: 1.475e+01\n",
      "Epoch 14474, Loss: 432.87237548828125, Neurons: 11, Grad norm: 1.739e+01\n",
      "Epoch 14475, Loss: 432.8699035644531, Neurons: 11, Grad norm: 1.657e+01\n",
      "Epoch 14476, Loss: 432.867431640625, Neurons: 11, Grad norm: 1.686e+01\n",
      "Epoch 14477, Loss: 432.864990234375, Neurons: 11, Grad norm: 1.537e+01\n",
      "Epoch 14478, Loss: 432.8624267578125, Neurons: 11, Grad norm: 1.475e+01\n",
      "Epoch 14479, Loss: 432.8599853515625, Neurons: 11, Grad norm: 1.286e+01\n",
      "Epoch 14480, Loss: 432.85748291015625, Neurons: 11, Grad norm: 1.074e+01\n",
      "Epoch 14481, Loss: 432.85504150390625, Neurons: 11, Grad norm: 7.844e+00\n",
      "Epoch 14482, Loss: 432.8525390625, Neurons: 11, Grad norm: 6.644e+00\n",
      "Epoch 14483, Loss: 432.85003662109375, Neurons: 11, Grad norm: 3.589e+00\n",
      "Epoch 14484, Loss: 432.84759521484375, Neurons: 11, Grad norm: 2.318e+00\n",
      "Epoch 14485, Loss: 432.84503173828125, Neurons: 11, Grad norm: 1.755e+00\n",
      "Epoch 14486, Loss: 432.84259033203125, Neurons: 11, Grad norm: 2.812e+00\n",
      "Epoch 14487, Loss: 432.840087890625, Neurons: 11, Grad norm: 4.546e+00\n",
      "Epoch 14488, Loss: 432.83758544921875, Neurons: 11, Grad norm: 5.285e+00\n",
      "Epoch 14489, Loss: 432.8350830078125, Neurons: 11, Grad norm: 6.686e+00\n",
      "Epoch 14490, Loss: 432.83258056640625, Neurons: 11, Grad norm: 7.441e+00\n",
      "Epoch 14491, Loss: 432.83013916015625, Neurons: 11, Grad norm: 9.532e+00\n",
      "Epoch 14492, Loss: 432.82763671875, Neurons: 11, Grad norm: 1.010e+01\n",
      "Epoch 14493, Loss: 432.82513427734375, Neurons: 11, Grad norm: 1.234e+01\n",
      "Epoch 14494, Loss: 432.8226318359375, Neurons: 11, Grad norm: 1.226e+01\n",
      "Epoch 14495, Loss: 432.82012939453125, Neurons: 11, Grad norm: 1.315e+01\n",
      "Epoch 14496, Loss: 432.81768798828125, Neurons: 11, Grad norm: 1.288e+01\n",
      "Epoch 14497, Loss: 432.815185546875, Neurons: 11, Grad norm: 1.279e+01\n",
      "Epoch 14498, Loss: 432.81268310546875, Neurons: 11, Grad norm: 1.204e+01\n",
      "Epoch 14499, Loss: 432.8101501464844, Neurons: 11, Grad norm: 1.273e+01\n",
      "Epoch 14499, Test loss: 429.3453063964844\n",
      "Epoch 14500, Loss: 432.8075866699219, Neurons: 11, Grad norm: 1.225e+01\n",
      "Epoch 14501, Loss: 432.8050842285156, Neurons: 11, Grad norm: 1.276e+01\n",
      "Epoch 14502, Loss: 432.8026428222656, Neurons: 11, Grad norm: 1.170e+01\n",
      "Epoch 14503, Loss: 432.8000793457031, Neurons: 11, Grad norm: 1.193e+01\n",
      "Epoch 14504, Loss: 432.7975769042969, Neurons: 11, Grad norm: 1.069e+01\n",
      "Epoch 14505, Loss: 432.7950744628906, Neurons: 11, Grad norm: 1.059e+01\n",
      "Epoch 14506, Loss: 432.7926025390625, Neurons: 11, Grad norm: 9.471e+00\n",
      "Epoch 14507, Loss: 432.79010009765625, Neurons: 11, Grad norm: 9.152e+00\n",
      "Epoch 14508, Loss: 432.78753662109375, Neurons: 11, Grad norm: 8.036e+00\n",
      "Epoch 14509, Loss: 432.7850341796875, Neurons: 11, Grad norm: 8.864e+00\n",
      "Epoch 14510, Loss: 432.78253173828125, Neurons: 11, Grad norm: 7.866e+00\n",
      "Epoch 14511, Loss: 432.7799987792969, Neurons: 11, Grad norm: 8.326e+00\n",
      "Epoch 14512, Loss: 432.7774963378906, Neurons: 11, Grad norm: 8.411e+00\n",
      "Epoch 14513, Loss: 432.7749938964844, Neurons: 11, Grad norm: 8.759e+00\n",
      "Epoch 14514, Loss: 432.7724304199219, Neurons: 11, Grad norm: 8.384e+00\n",
      "Epoch 14515, Loss: 432.7698974609375, Neurons: 11, Grad norm: 9.179e+00\n",
      "Epoch 14516, Loss: 432.76739501953125, Neurons: 11, Grad norm: 8.506e+00\n",
      "Epoch 14517, Loss: 432.764892578125, Neurons: 11, Grad norm: 1.049e+01\n",
      "Epoch 14518, Loss: 432.7623291015625, Neurons: 11, Grad norm: 1.035e+01\n",
      "Epoch 14519, Loss: 432.7597961425781, Neurons: 11, Grad norm: 1.181e+01\n",
      "Epoch 14520, Loss: 432.7572937011719, Neurons: 11, Grad norm: 1.363e+01\n",
      "Epoch 14521, Loss: 432.7547912597656, Neurons: 11, Grad norm: 1.608e+01\n",
      "Epoch 14522, Loss: 432.752197265625, Neurons: 11, Grad norm: 1.880e+01\n",
      "Epoch 14523, Loss: 432.7497253417969, Neurons: 11, Grad norm: 2.312e+01\n",
      "Epoch 14524, Loss: 432.7471923828125, Neurons: 11, Grad norm: 2.667e+01\n",
      "Epoch 14525, Loss: 432.74468994140625, Neurons: 11, Grad norm: 3.297e+01\n",
      "Epoch 14526, Loss: 432.74212646484375, Neurons: 11, Grad norm: 3.732e+01\n",
      "Epoch 14527, Loss: 432.73968505859375, Neurons: 11, Grad norm: 4.398e+01\n",
      "Epoch 14528, Loss: 432.7371520996094, Neurons: 11, Grad norm: 5.110e+01\n",
      "Epoch 14529, Loss: 432.7346496582031, Neurons: 11, Grad norm: 5.975e+01\n",
      "Epoch 14530, Loss: 432.732177734375, Neurons: 11, Grad norm: 6.971e+01\n",
      "Epoch 14531, Loss: 432.72979736328125, Neurons: 11, Grad norm: 8.297e+01\n",
      "Epoch 14532, Loss: 432.7273254394531, Neurons: 11, Grad norm: 9.710e+01\n",
      "Epoch 14533, Loss: 432.7249755859375, Neurons: 11, Grad norm: 1.153e+02\n",
      "Epoch 14534, Loss: 432.7226867675781, Neurons: 11, Grad norm: 1.343e+02\n",
      "Epoch 14535, Loss: 432.7204895019531, Neurons: 11, Grad norm: 1.570e+02\n",
      "Epoch 14536, Loss: 432.7184753417969, Neurons: 11, Grad norm: 1.811e+02\n",
      "Epoch 14537, Loss: 432.716552734375, Neurons: 11, Grad norm: 2.078e+02\n",
      "Epoch 14538, Loss: 432.7147521972656, Neurons: 11, Grad norm: 2.327e+02\n",
      "Epoch 14539, Loss: 432.7130432128906, Neurons: 11, Grad norm: 2.542e+02\n",
      "Epoch 14540, Loss: 432.7113037109375, Neurons: 11, Grad norm: 2.658e+02\n",
      "Epoch 14541, Loss: 432.7091979980469, Neurons: 11, Grad norm: 2.646e+02\n",
      "Epoch 14542, Loss: 432.70672607421875, Neurons: 11, Grad norm: 2.443e+02\n",
      "Epoch 14543, Loss: 432.7034912109375, Neurons: 11, Grad norm: 2.062e+02\n",
      "Epoch 14544, Loss: 432.6997985839844, Neurons: 11, Grad norm: 1.503e+02\n",
      "Epoch 14545, Loss: 432.69598388671875, Neurons: 11, Grad norm: 8.560e+01\n",
      "Epoch 14546, Loss: 432.6924743652344, Neurons: 11, Grad norm: 1.604e+01\n",
      "Epoch 14547, Loss: 432.6894836425781, Neurons: 11, Grad norm: 4.807e+01\n",
      "Epoch 14548, Loss: 432.6872863769531, Neurons: 11, Grad norm: 1.015e+02\n",
      "Epoch 14549, Loss: 432.6853942871094, Neurons: 11, Grad norm: 1.379e+02\n",
      "Epoch 14549, Test loss: 429.2577819824219\n",
      "Epoch 14550, Loss: 432.68359375, Neurons: 11, Grad norm: 1.555e+02\n",
      "Epoch 14551, Loss: 432.6814880371094, Neurons: 11, Grad norm: 1.516e+02\n",
      "Epoch 14552, Loss: 432.6789855957031, Neurons: 11, Grad norm: 1.313e+02\n",
      "Epoch 14553, Loss: 432.6761474609375, Neurons: 11, Grad norm: 9.509e+01\n",
      "Epoch 14554, Loss: 432.6731262207031, Neurons: 11, Grad norm: 5.134e+01\n",
      "Epoch 14555, Loss: 432.6702880859375, Neurons: 11, Grad norm: 4.273e+00\n",
      "Epoch 14556, Loss: 432.6676330566406, Neurons: 11, Grad norm: 3.865e+01\n",
      "Epoch 14557, Loss: 432.66534423828125, Neurons: 11, Grad norm: 7.325e+01\n",
      "Epoch 14558, Loss: 432.6631774902344, Neurons: 11, Grad norm: 9.414e+01\n",
      "Epoch 14559, Loss: 432.6610412597656, Neurons: 11, Grad norm: 1.017e+02\n",
      "Epoch 14560, Loss: 432.65869140625, Neurons: 11, Grad norm: 9.402e+01\n",
      "Epoch 14561, Loss: 432.65618896484375, Neurons: 11, Grad norm: 7.593e+01\n",
      "Epoch 14562, Loss: 432.6535339355469, Neurons: 11, Grad norm: 4.852e+01\n",
      "Epoch 14563, Loss: 432.65087890625, Neurons: 11, Grad norm: 1.882e+01\n",
      "Epoch 14564, Loss: 432.6483459472656, Neurons: 11, Grad norm: 1.132e+01\n",
      "Epoch 14565, Loss: 432.6458740234375, Neurons: 11, Grad norm: 3.614e+01\n",
      "Epoch 14566, Loss: 432.6435852050781, Neurons: 11, Grad norm: 5.538e+01\n",
      "Epoch 14567, Loss: 432.64129638671875, Neurons: 11, Grad norm: 6.481e+01\n",
      "Epoch 14568, Loss: 432.6389465332031, Neurons: 11, Grad norm: 6.723e+01\n",
      "Epoch 14569, Loss: 432.636474609375, Neurons: 11, Grad norm: 6.036e+01\n",
      "Epoch 14570, Loss: 432.6340026855469, Neurons: 11, Grad norm: 4.748e+01\n",
      "Epoch 14571, Loss: 432.6315002441406, Neurons: 11, Grad norm: 2.957e+01\n",
      "Epoch 14572, Loss: 432.6289978027344, Neurons: 11, Grad norm: 1.096e+01\n",
      "Epoch 14573, Loss: 432.6264953613281, Neurons: 11, Grad norm: 8.990e+00\n",
      "Epoch 14574, Loss: 432.62408447265625, Neurons: 11, Grad norm: 2.414e+01\n",
      "Epoch 14575, Loss: 432.6217041015625, Neurons: 11, Grad norm: 3.629e+01\n",
      "Epoch 14576, Loss: 432.6192932128906, Neurons: 11, Grad norm: 4.252e+01\n",
      "Epoch 14577, Loss: 432.61688232421875, Neurons: 11, Grad norm: 4.422e+01\n",
      "Epoch 14578, Loss: 432.614501953125, Neurons: 11, Grad norm: 4.012e+01\n",
      "Epoch 14579, Loss: 432.6120300292969, Neurons: 11, Grad norm: 3.313e+01\n",
      "Epoch 14580, Loss: 432.6095886230469, Neurons: 11, Grad norm: 2.149e+01\n",
      "Epoch 14581, Loss: 432.6071472167969, Neurons: 11, Grad norm: 9.924e+00\n",
      "Epoch 14582, Loss: 432.60467529296875, Neurons: 11, Grad norm: 3.297e+00\n",
      "Epoch 14583, Loss: 432.6022033691406, Neurons: 11, Grad norm: 1.320e+01\n",
      "Epoch 14584, Loss: 432.59979248046875, Neurons: 11, Grad norm: 2.170e+01\n",
      "Epoch 14585, Loss: 432.5973815917969, Neurons: 11, Grad norm: 2.618e+01\n",
      "Epoch 14586, Loss: 432.5948791503906, Neurons: 11, Grad norm: 2.912e+01\n",
      "Epoch 14587, Loss: 432.592529296875, Neurons: 11, Grad norm: 2.781e+01\n",
      "Epoch 14588, Loss: 432.590087890625, Neurons: 11, Grad norm: 2.458e+01\n",
      "Epoch 14589, Loss: 432.58758544921875, Neurons: 11, Grad norm: 1.817e+01\n",
      "Epoch 14590, Loss: 432.58514404296875, Neurons: 11, Grad norm: 1.172e+01\n",
      "Epoch 14591, Loss: 432.58270263671875, Neurons: 11, Grad norm: 3.678e+00\n",
      "Epoch 14592, Loss: 432.5802307128906, Neurons: 11, Grad norm: 3.462e+00\n",
      "Epoch 14593, Loss: 432.5778503417969, Neurons: 11, Grad norm: 1.000e+01\n",
      "Epoch 14594, Loss: 432.57537841796875, Neurons: 11, Grad norm: 1.415e+01\n",
      "Epoch 14595, Loss: 432.5728759765625, Neurons: 11, Grad norm: 1.757e+01\n",
      "Epoch 14596, Loss: 432.57049560546875, Neurons: 11, Grad norm: 1.822e+01\n",
      "Epoch 14597, Loss: 432.56805419921875, Neurons: 11, Grad norm: 1.905e+01\n",
      "Epoch 14598, Loss: 432.5655822753906, Neurons: 11, Grad norm: 1.762e+01\n",
      "Epoch 14599, Loss: 432.5630798339844, Neurons: 11, Grad norm: 1.645e+01\n",
      "Epoch 14599, Test loss: 429.10791015625\n",
      "Epoch 14600, Loss: 432.5606994628906, Neurons: 11, Grad norm: 1.369e+01\n",
      "Epoch 14601, Loss: 432.5581970214844, Neurons: 11, Grad norm: 1.071e+01\n",
      "Epoch 14602, Loss: 432.5556945800781, Neurons: 11, Grad norm: 6.587e+00\n",
      "Epoch 14603, Loss: 432.55328369140625, Neurons: 11, Grad norm: 4.347e+00\n",
      "Epoch 14604, Loss: 432.55078125, Neurons: 11, Grad norm: 1.513e+00\n",
      "Epoch 14605, Loss: 432.54833984375, Neurons: 11, Grad norm: 3.892e+00\n",
      "Epoch 14606, Loss: 432.5458984375, Neurons: 11, Grad norm: 6.814e+00\n",
      "Epoch 14607, Loss: 432.5434265136719, Neurons: 11, Grad norm: 8.692e+00\n",
      "Epoch 14608, Loss: 432.5409851074219, Neurons: 11, Grad norm: 1.143e+01\n",
      "Epoch 14609, Loss: 432.5384826660156, Neurons: 11, Grad norm: 1.154e+01\n",
      "Epoch 14610, Loss: 432.5361022949219, Neurons: 11, Grad norm: 1.241e+01\n",
      "Epoch 14611, Loss: 432.5335998535156, Neurons: 11, Grad norm: 1.209e+01\n",
      "Epoch 14612, Loss: 432.5310974121094, Neurons: 11, Grad norm: 1.137e+01\n",
      "Epoch 14613, Loss: 432.52862548828125, Neurons: 11, Grad norm: 9.473e+00\n",
      "Epoch 14614, Loss: 432.52618408203125, Neurons: 11, Grad norm: 9.136e+00\n",
      "Epoch 14615, Loss: 432.523681640625, Neurons: 11, Grad norm: 6.478e+00\n",
      "Epoch 14616, Loss: 432.521240234375, Neurons: 11, Grad norm: 5.422e+00\n",
      "Epoch 14617, Loss: 432.51873779296875, Neurons: 11, Grad norm: 3.131e+00\n",
      "Epoch 14618, Loss: 432.5162353515625, Neurons: 11, Grad norm: 1.922e+00\n",
      "Epoch 14619, Loss: 432.5137939453125, Neurons: 11, Grad norm: 1.724e+00\n",
      "Epoch 14620, Loss: 432.51129150390625, Neurons: 11, Grad norm: 3.436e+00\n",
      "Epoch 14621, Loss: 432.50885009765625, Neurons: 11, Grad norm: 6.253e+00\n",
      "Epoch 14622, Loss: 432.5063781738281, Neurons: 11, Grad norm: 6.948e+00\n",
      "Epoch 14623, Loss: 432.5038757324219, Neurons: 11, Grad norm: 9.187e+00\n",
      "Epoch 14624, Loss: 432.50140380859375, Neurons: 11, Grad norm: 1.013e+01\n",
      "Epoch 14625, Loss: 432.4989013671875, Neurons: 11, Grad norm: 1.225e+01\n",
      "Epoch 14626, Loss: 432.4964294433594, Neurons: 11, Grad norm: 1.252e+01\n",
      "Epoch 14627, Loss: 432.4939270019531, Neurons: 11, Grad norm: 1.340e+01\n",
      "Epoch 14628, Loss: 432.4914855957031, Neurons: 11, Grad norm: 1.317e+01\n",
      "Epoch 14629, Loss: 432.4889831542969, Neurons: 11, Grad norm: 1.312e+01\n",
      "Epoch 14630, Loss: 432.4864807128906, Neurons: 11, Grad norm: 1.198e+01\n",
      "Epoch 14631, Loss: 432.4839782714844, Neurons: 11, Grad norm: 1.163e+01\n",
      "Epoch 14632, Loss: 432.4814758300781, Neurons: 11, Grad norm: 9.835e+00\n",
      "Epoch 14633, Loss: 432.47900390625, Neurons: 11, Grad norm: 9.349e+00\n",
      "Epoch 14634, Loss: 432.47650146484375, Neurons: 11, Grad norm: 7.279e+00\n",
      "Epoch 14635, Loss: 432.4739990234375, Neurons: 11, Grad norm: 6.319e+00\n",
      "Epoch 14636, Loss: 432.47149658203125, Neurons: 11, Grad norm: 4.419e+00\n",
      "Epoch 14637, Loss: 432.468994140625, Neurons: 11, Grad norm: 3.475e+00\n",
      "Epoch 14638, Loss: 432.466552734375, Neurons: 11, Grad norm: 2.106e+00\n",
      "Epoch 14639, Loss: 432.4639892578125, Neurons: 11, Grad norm: 2.229e+00\n",
      "Epoch 14640, Loss: 432.46148681640625, Neurons: 11, Grad norm: 1.922e+00\n",
      "Epoch 14641, Loss: 432.45904541015625, Neurons: 11, Grad norm: 2.186e+00\n",
      "Epoch 14642, Loss: 432.45648193359375, Neurons: 11, Grad norm: 1.856e+00\n",
      "Epoch 14643, Loss: 432.4539794921875, Neurons: 11, Grad norm: 3.070e+00\n",
      "Epoch 14644, Loss: 432.45147705078125, Neurons: 11, Grad norm: 3.583e+00\n",
      "Epoch 14645, Loss: 432.448974609375, Neurons: 11, Grad norm: 4.938e+00\n",
      "Epoch 14646, Loss: 432.4465026855469, Neurons: 11, Grad norm: 5.405e+00\n",
      "Epoch 14647, Loss: 432.4440002441406, Neurons: 11, Grad norm: 7.665e+00\n",
      "Epoch 14648, Loss: 432.4414978027344, Neurons: 11, Grad norm: 8.136e+00\n",
      "Epoch 14649, Loss: 432.4389343261719, Neurons: 11, Grad norm: 9.998e+00\n",
      "Epoch 14649, Test loss: 428.990234375\n",
      "Epoch 14650, Loss: 432.4364318847656, Neurons: 11, Grad norm: 1.165e+01\n",
      "Epoch 14651, Loss: 432.4339294433594, Neurons: 11, Grad norm: 1.340e+01\n",
      "Epoch 14652, Loss: 432.431396484375, Neurons: 11, Grad norm: 1.446e+01\n",
      "Epoch 14653, Loss: 432.42889404296875, Neurons: 11, Grad norm: 1.669e+01\n",
      "Epoch 14654, Loss: 432.4263916015625, Neurons: 11, Grad norm: 1.640e+01\n",
      "Epoch 14655, Loss: 432.42388916015625, Neurons: 11, Grad norm: 1.854e+01\n",
      "Epoch 14656, Loss: 432.42138671875, Neurons: 11, Grad norm: 1.898e+01\n",
      "Epoch 14657, Loss: 432.4187927246094, Neurons: 11, Grad norm: 2.067e+01\n",
      "Epoch 14658, Loss: 432.4162902832031, Neurons: 11, Grad norm: 2.322e+01\n",
      "Epoch 14659, Loss: 432.4137878417969, Neurons: 11, Grad norm: 2.658e+01\n",
      "Epoch 14660, Loss: 432.4112854003906, Neurons: 11, Grad norm: 3.037e+01\n",
      "Epoch 14661, Loss: 432.4087829589844, Neurons: 11, Grad norm: 3.636e+01\n",
      "Epoch 14662, Loss: 432.40625, Neurons: 11, Grad norm: 4.181e+01\n",
      "Epoch 14663, Loss: 432.40374755859375, Neurons: 11, Grad norm: 5.034e+01\n",
      "Epoch 14664, Loss: 432.4012756347656, Neurons: 11, Grad norm: 5.738e+01\n",
      "Epoch 14665, Loss: 432.3988037109375, Neurons: 11, Grad norm: 6.686e+01\n",
      "Epoch 14666, Loss: 432.3963928222656, Neurons: 11, Grad norm: 7.790e+01\n",
      "Epoch 14667, Loss: 432.3939514160156, Neurons: 11, Grad norm: 9.194e+01\n",
      "Epoch 14668, Loss: 432.3916015625, Neurons: 11, Grad norm: 1.082e+02\n",
      "Epoch 14669, Loss: 432.3892822265625, Neurons: 11, Grad norm: 1.278e+02\n",
      "Epoch 14670, Loss: 432.3870849609375, Neurons: 11, Grad norm: 1.486e+02\n",
      "Epoch 14671, Loss: 432.3849792480469, Neurons: 11, Grad norm: 1.731e+02\n",
      "Epoch 14672, Loss: 432.3830261230469, Neurons: 11, Grad norm: 1.982e+02\n",
      "Epoch 14673, Loss: 432.3811950683594, Neurons: 11, Grad norm: 2.255e+02\n",
      "Epoch 14674, Loss: 432.3794860839844, Neurons: 11, Grad norm: 2.485e+02\n",
      "Epoch 14675, Loss: 432.3778381347656, Neurons: 11, Grad norm: 2.658e+02\n",
      "Epoch 14676, Loss: 432.3759765625, Neurons: 11, Grad norm: 2.712e+02\n",
      "Epoch 14677, Loss: 432.3736877441406, Neurons: 11, Grad norm: 2.614e+02\n",
      "Epoch 14678, Loss: 432.3708801269531, Neurons: 11, Grad norm: 2.305e+02\n",
      "Epoch 14679, Loss: 432.3673400878906, Neurons: 11, Grad norm: 1.821e+02\n",
      "Epoch 14680, Loss: 432.3634948730469, Neurons: 11, Grad norm: 1.174e+02\n",
      "Epoch 14681, Loss: 432.35968017578125, Neurons: 11, Grad norm: 4.633e+01\n",
      "Epoch 14682, Loss: 432.3564453125, Neurons: 11, Grad norm: 2.316e+01\n",
      "Epoch 14683, Loss: 432.3538818359375, Neurons: 11, Grad norm: 8.160e+01\n",
      "Epoch 14684, Loss: 432.3519287109375, Neurons: 11, Grad norm: 1.264e+02\n",
      "Epoch 14685, Loss: 432.3501281738281, Neurons: 11, Grad norm: 1.507e+02\n",
      "Epoch 14686, Loss: 432.3482971191406, Neurons: 11, Grad norm: 1.562e+02\n",
      "Epoch 14687, Loss: 432.34588623046875, Neurons: 11, Grad norm: 1.403e+02\n",
      "Epoch 14688, Loss: 432.34320068359375, Neurons: 11, Grad norm: 1.077e+02\n",
      "Epoch 14689, Loss: 432.3401794433594, Neurons: 11, Grad norm: 6.367e+01\n",
      "Epoch 14690, Loss: 432.3372802734375, Neurons: 11, Grad norm: 1.653e+01\n",
      "Epoch 14691, Loss: 432.3345947265625, Neurons: 11, Grad norm: 2.909e+01\n",
      "Epoch 14692, Loss: 432.3322448730469, Neurons: 11, Grad norm: 6.506e+01\n",
      "Epoch 14693, Loss: 432.330078125, Neurons: 11, Grad norm: 9.043e+01\n",
      "Epoch 14694, Loss: 432.32794189453125, Neurons: 11, Grad norm: 9.972e+01\n",
      "Epoch 14695, Loss: 432.32568359375, Neurons: 11, Grad norm: 9.667e+01\n",
      "Epoch 14696, Loss: 432.32318115234375, Neurons: 11, Grad norm: 8.005e+01\n",
      "Epoch 14697, Loss: 432.3205871582031, Neurons: 11, Grad norm: 5.452e+01\n",
      "Epoch 14698, Loss: 432.3179016113281, Neurons: 11, Grad norm: 2.397e+01\n",
      "Epoch 14699, Loss: 432.3153381347656, Neurons: 11, Grad norm: 6.990e+00\n",
      "Epoch 14699, Test loss: 428.8756103515625\n",
      "Epoch 14700, Loss: 432.31298828125, Neurons: 11, Grad norm: 3.439e+01\n",
      "Epoch 14701, Loss: 432.3105773925781, Neurons: 11, Grad norm: 5.297e+01\n",
      "Epoch 14702, Loss: 432.30828857421875, Neurons: 11, Grad norm: 6.507e+01\n",
      "Epoch 14703, Loss: 432.3059997558594, Neurons: 11, Grad norm: 6.570e+01\n",
      "Epoch 14704, Loss: 432.3035888671875, Neurons: 11, Grad norm: 6.003e+01\n",
      "Epoch 14705, Loss: 432.3011474609375, Neurons: 11, Grad norm: 4.686e+01\n",
      "Epoch 14706, Loss: 432.29864501953125, Neurons: 11, Grad norm: 2.909e+01\n",
      "Epoch 14707, Loss: 432.29608154296875, Neurons: 11, Grad norm: 9.060e+00\n",
      "Epoch 14708, Loss: 432.293701171875, Neurons: 11, Grad norm: 9.861e+00\n",
      "Epoch 14709, Loss: 432.2912292480469, Neurons: 11, Grad norm: 2.644e+01\n",
      "Epoch 14710, Loss: 432.28887939453125, Neurons: 11, Grad norm: 3.743e+01\n",
      "Epoch 14711, Loss: 432.2864990234375, Neurons: 11, Grad norm: 4.466e+01\n",
      "Epoch 14712, Loss: 432.2840881347656, Neurons: 11, Grad norm: 4.442e+01\n",
      "Epoch 14713, Loss: 432.28167724609375, Neurons: 11, Grad norm: 4.078e+01\n",
      "Epoch 14714, Loss: 432.279296875, Neurons: 11, Grad norm: 3.092e+01\n",
      "Epoch 14715, Loss: 432.27679443359375, Neurons: 11, Grad norm: 1.927e+01\n",
      "Epoch 14716, Loss: 432.27435302734375, Neurons: 11, Grad norm: 6.037e+00\n",
      "Epoch 14717, Loss: 432.2718811035156, Neurons: 11, Grad norm: 6.737e+00\n",
      "Epoch 14718, Loss: 432.2695007324219, Neurons: 11, Grad norm: 1.746e+01\n",
      "Epoch 14719, Loss: 432.26708984375, Neurons: 11, Grad norm: 2.427e+01\n",
      "Epoch 14720, Loss: 432.2646789550781, Neurons: 11, Grad norm: 2.892e+01\n",
      "Epoch 14721, Loss: 432.2622985839844, Neurons: 11, Grad norm: 2.836e+01\n",
      "Epoch 14722, Loss: 432.2598876953125, Neurons: 11, Grad norm: 2.637e+01\n",
      "Epoch 14723, Loss: 432.25738525390625, Neurons: 11, Grad norm: 2.023e+01\n",
      "Epoch 14724, Loss: 432.2549743652344, Neurons: 11, Grad norm: 1.367e+01\n",
      "Epoch 14725, Loss: 432.25250244140625, Neurons: 11, Grad norm: 5.752e+00\n",
      "Epoch 14726, Loss: 432.2500915527344, Neurons: 11, Grad norm: 2.276e+00\n",
      "Epoch 14727, Loss: 432.2476501464844, Neurons: 11, Grad norm: 8.913e+00\n",
      "Epoch 14728, Loss: 432.24517822265625, Neurons: 11, Grad norm: 1.367e+01\n",
      "Epoch 14729, Loss: 432.2427978515625, Neurons: 11, Grad norm: 1.760e+01\n",
      "Epoch 14730, Loss: 432.2403869628906, Neurons: 11, Grad norm: 1.822e+01\n",
      "Epoch 14731, Loss: 432.2378845214844, Neurons: 11, Grad norm: 1.930e+01\n",
      "Epoch 14732, Loss: 432.2355041503906, Neurons: 11, Grad norm: 1.752e+01\n",
      "Epoch 14733, Loss: 432.2330322265625, Neurons: 11, Grad norm: 1.495e+01\n",
      "Epoch 14734, Loss: 432.2305908203125, Neurons: 11, Grad norm: 1.084e+01\n",
      "Epoch 14735, Loss: 432.2281799316406, Neurons: 11, Grad norm: 7.685e+00\n",
      "Epoch 14736, Loss: 432.2256774902344, Neurons: 11, Grad norm: 3.841e+00\n",
      "Epoch 14737, Loss: 432.2232360839844, Neurons: 11, Grad norm: 1.480e+00\n",
      "Epoch 14738, Loss: 432.2208251953125, Neurons: 11, Grad norm: 3.887e+00\n",
      "Epoch 14739, Loss: 432.2183837890625, Neurons: 11, Grad norm: 4.833e+00\n",
      "Epoch 14740, Loss: 432.2159423828125, Neurons: 11, Grad norm: 7.269e+00\n",
      "Epoch 14741, Loss: 432.2135009765625, Neurons: 11, Grad norm: 8.393e+00\n",
      "Epoch 14742, Loss: 432.2110290527344, Neurons: 11, Grad norm: 9.227e+00\n",
      "Epoch 14743, Loss: 432.2085876464844, Neurons: 11, Grad norm: 9.026e+00\n",
      "Epoch 14744, Loss: 432.2061462402344, Neurons: 11, Grad norm: 9.776e+00\n",
      "Epoch 14745, Loss: 432.20367431640625, Neurons: 11, Grad norm: 9.116e+00\n",
      "Epoch 14746, Loss: 432.2012939453125, Neurons: 11, Grad norm: 9.722e+00\n",
      "Epoch 14747, Loss: 432.19879150390625, Neurons: 11, Grad norm: 8.021e+00\n",
      "Epoch 14748, Loss: 432.19635009765625, Neurons: 11, Grad norm: 7.428e+00\n",
      "Epoch 14749, Loss: 432.1938781738281, Neurons: 11, Grad norm: 6.494e+00\n",
      "Epoch 14749, Test loss: 428.75909423828125\n",
      "Epoch 14750, Loss: 432.1913757324219, Neurons: 11, Grad norm: 5.427e+00\n",
      "Epoch 14751, Loss: 432.1889343261719, Neurons: 11, Grad norm: 3.799e+00\n",
      "Epoch 14752, Loss: 432.1864929199219, Neurons: 11, Grad norm: 3.892e+00\n",
      "Epoch 14753, Loss: 432.1839904785156, Neurons: 11, Grad norm: 2.121e+00\n",
      "Epoch 14754, Loss: 432.18157958984375, Neurons: 11, Grad norm: 1.964e+00\n",
      "Epoch 14755, Loss: 432.1790771484375, Neurons: 11, Grad norm: 1.483e+00\n",
      "Epoch 14756, Loss: 432.17657470703125, Neurons: 11, Grad norm: 1.668e+00\n",
      "Epoch 14757, Loss: 432.1741943359375, Neurons: 11, Grad norm: 2.356e+00\n",
      "Epoch 14758, Loss: 432.17169189453125, Neurons: 11, Grad norm: 3.507e+00\n",
      "Epoch 14759, Loss: 432.169189453125, Neurons: 11, Grad norm: 5.579e+00\n",
      "Epoch 14760, Loss: 432.1667785644531, Neurons: 11, Grad norm: 5.826e+00\n",
      "Epoch 14761, Loss: 432.1642761230469, Neurons: 11, Grad norm: 7.574e+00\n",
      "Epoch 14762, Loss: 432.16180419921875, Neurons: 11, Grad norm: 8.220e+00\n",
      "Epoch 14763, Loss: 432.1593933105469, Neurons: 11, Grad norm: 1.020e+01\n",
      "Epoch 14764, Loss: 432.1568908691406, Neurons: 11, Grad norm: 1.025e+01\n",
      "Epoch 14765, Loss: 432.1544494628906, Neurons: 11, Grad norm: 1.083e+01\n",
      "Epoch 14766, Loss: 432.1518859863281, Neurons: 11, Grad norm: 1.035e+01\n",
      "Epoch 14767, Loss: 432.1494445800781, Neurons: 11, Grad norm: 1.015e+01\n",
      "Epoch 14768, Loss: 432.1470031738281, Neurons: 11, Grad norm: 9.071e+00\n",
      "Epoch 14769, Loss: 432.1445007324219, Neurons: 11, Grad norm: 8.741e+00\n",
      "Epoch 14770, Loss: 432.1419982910156, Neurons: 11, Grad norm: 7.122e+00\n",
      "Epoch 14771, Loss: 432.1395263671875, Neurons: 11, Grad norm: 6.876e+00\n",
      "Epoch 14772, Loss: 432.1369934082031, Neurons: 11, Grad norm: 5.219e+00\n",
      "Epoch 14773, Loss: 432.1345520019531, Neurons: 11, Grad norm: 4.771e+00\n",
      "Epoch 14774, Loss: 432.132080078125, Neurons: 11, Grad norm: 3.392e+00\n",
      "Epoch 14775, Loss: 432.1295471191406, Neurons: 11, Grad norm: 2.812e+00\n",
      "Epoch 14776, Loss: 432.1270751953125, Neurons: 11, Grad norm: 1.848e+00\n",
      "Epoch 14777, Loss: 432.1246032714844, Neurons: 11, Grad norm: 2.141e+00\n",
      "Epoch 14778, Loss: 432.1221008300781, Neurons: 11, Grad norm: 2.046e+00\n",
      "Epoch 14779, Loss: 432.1195983886719, Neurons: 11, Grad norm: 2.467e+00\n",
      "Epoch 14780, Loss: 432.1170959472656, Neurons: 11, Grad norm: 2.251e+00\n",
      "Epoch 14781, Loss: 432.1145935058594, Neurons: 11, Grad norm: 3.834e+00\n",
      "Epoch 14782, Loss: 432.1120910644531, Neurons: 11, Grad norm: 4.601e+00\n",
      "Epoch 14783, Loss: 432.1095886230469, Neurons: 11, Grad norm: 6.148e+00\n",
      "Epoch 14784, Loss: 432.1070861816406, Neurons: 11, Grad norm: 6.829e+00\n",
      "Epoch 14785, Loss: 432.1045837402344, Neurons: 11, Grad norm: 9.304e+00\n",
      "Epoch 14786, Loss: 432.1020812988281, Neurons: 11, Grad norm: 1.105e+01\n",
      "Epoch 14787, Loss: 432.0995788574219, Neurons: 11, Grad norm: 1.429e+01\n",
      "Epoch 14788, Loss: 432.0970764160156, Neurons: 11, Grad norm: 1.700e+01\n",
      "Epoch 14789, Loss: 432.0945739746094, Neurons: 11, Grad norm: 2.114e+01\n",
      "Epoch 14790, Loss: 432.09210205078125, Neurons: 11, Grad norm: 2.469e+01\n",
      "Epoch 14791, Loss: 432.089599609375, Neurons: 11, Grad norm: 2.991e+01\n",
      "Epoch 14792, Loss: 432.08709716796875, Neurons: 11, Grad norm: 3.449e+01\n",
      "Epoch 14793, Loss: 432.0846862792969, Neurons: 11, Grad norm: 4.094e+01\n",
      "Epoch 14794, Loss: 432.0821838378906, Neurons: 11, Grad norm: 4.687e+01\n",
      "Epoch 14795, Loss: 432.07965087890625, Neurons: 11, Grad norm: 5.452e+01\n",
      "Epoch 14796, Loss: 432.0771789550781, Neurons: 11, Grad norm: 6.198e+01\n",
      "Epoch 14797, Loss: 432.0747985839844, Neurons: 11, Grad norm: 7.140e+01\n",
      "Epoch 14798, Loss: 432.07232666015625, Neurons: 11, Grad norm: 8.110e+01\n",
      "Epoch 14799, Loss: 432.06988525390625, Neurons: 11, Grad norm: 9.396e+01\n",
      "Epoch 14799, Test loss: 428.6201477050781\n",
      "Epoch 14800, Loss: 432.0675964355469, Neurons: 11, Grad norm: 1.072e+02\n",
      "Epoch 14801, Loss: 432.06524658203125, Neurons: 11, Grad norm: 1.230e+02\n",
      "Epoch 14802, Loss: 432.06304931640625, Neurons: 11, Grad norm: 1.403e+02\n",
      "Epoch 14803, Loss: 432.06085205078125, Neurons: 11, Grad norm: 1.596e+02\n",
      "Epoch 14804, Loss: 432.0587463378906, Neurons: 11, Grad norm: 1.783e+02\n",
      "Epoch 14805, Loss: 432.05670166015625, Neurons: 11, Grad norm: 1.972e+02\n",
      "Epoch 14806, Loss: 432.0546875, Neurons: 11, Grad norm: 2.118e+02\n",
      "Epoch 14807, Loss: 432.0527038574219, Neurons: 11, Grad norm: 2.230e+02\n",
      "Epoch 14808, Loss: 432.05047607421875, Neurons: 11, Grad norm: 2.249e+02\n",
      "Epoch 14809, Loss: 432.048095703125, Neurons: 11, Grad norm: 2.170e+02\n",
      "Epoch 14810, Loss: 432.0453796386719, Neurons: 11, Grad norm: 1.964e+02\n",
      "Epoch 14811, Loss: 432.0423889160156, Neurons: 11, Grad norm: 1.643e+02\n",
      "Epoch 14812, Loss: 432.0390930175781, Neurons: 11, Grad norm: 1.209e+02\n",
      "Epoch 14813, Loss: 432.0357971191406, Neurons: 11, Grad norm: 7.223e+01\n",
      "Epoch 14814, Loss: 432.0326843261719, Neurons: 11, Grad norm: 2.137e+01\n",
      "Epoch 14815, Loss: 432.0298767089844, Neurons: 11, Grad norm: 2.526e+01\n",
      "Epoch 14816, Loss: 432.0274963378906, Neurons: 11, Grad norm: 6.639e+01\n",
      "Epoch 14817, Loss: 432.0252990722656, Neurons: 11, Grad norm: 9.663e+01\n",
      "Epoch 14818, Loss: 432.0232238769531, Neurons: 11, Grad norm: 1.172e+02\n",
      "Epoch 14819, Loss: 432.0210876464844, Neurons: 11, Grad norm: 1.244e+02\n",
      "Epoch 14820, Loss: 432.0188293457031, Neurons: 11, Grad norm: 1.213e+02\n",
      "Epoch 14821, Loss: 432.0163269042969, Neurons: 11, Grad norm: 1.068e+02\n",
      "Epoch 14822, Loss: 432.0137023925781, Neurons: 11, Grad norm: 8.380e+01\n",
      "Epoch 14823, Loss: 432.01092529296875, Neurons: 11, Grad norm: 5.399e+01\n",
      "Epoch 14824, Loss: 432.00823974609375, Neurons: 11, Grad norm: 2.320e+01\n",
      "Epoch 14825, Loss: 432.0056457519531, Neurons: 11, Grad norm: 7.987e+00\n",
      "Epoch 14826, Loss: 432.003173828125, Neurons: 11, Grad norm: 3.396e+01\n",
      "Epoch 14827, Loss: 432.00079345703125, Neurons: 11, Grad norm: 5.521e+01\n",
      "Epoch 14828, Loss: 431.99853515625, Neurons: 11, Grad norm: 6.873e+01\n",
      "Epoch 14829, Loss: 431.9961853027344, Neurons: 11, Grad norm: 7.653e+01\n",
      "Epoch 14830, Loss: 431.993896484375, Neurons: 11, Grad norm: 7.495e+01\n",
      "Epoch 14831, Loss: 431.9914245605469, Neurons: 11, Grad norm: 6.780e+01\n",
      "Epoch 14832, Loss: 431.9888916015625, Neurons: 11, Grad norm: 5.439e+01\n",
      "Epoch 14833, Loss: 431.98638916015625, Neurons: 11, Grad norm: 3.793e+01\n",
      "Epoch 14834, Loss: 431.98388671875, Neurons: 11, Grad norm: 1.959e+01\n",
      "Epoch 14835, Loss: 431.9813537597656, Neurons: 11, Grad norm: 2.818e+00\n",
      "Epoch 14836, Loss: 431.9788818359375, Neurons: 11, Grad norm: 1.381e+01\n",
      "Epoch 14837, Loss: 431.97650146484375, Neurons: 11, Grad norm: 2.609e+01\n",
      "Epoch 14838, Loss: 431.9740905761719, Neurons: 11, Grad norm: 3.686e+01\n",
      "Epoch 14839, Loss: 431.9716491699219, Neurons: 11, Grad norm: 4.220e+01\n",
      "Epoch 14840, Loss: 431.96929931640625, Neurons: 11, Grad norm: 4.503e+01\n",
      "Epoch 14841, Loss: 431.9668273925781, Neurons: 11, Grad norm: 4.333e+01\n",
      "Epoch 14842, Loss: 431.9644470214844, Neurons: 11, Grad norm: 3.921e+01\n",
      "Epoch 14843, Loss: 431.96197509765625, Neurons: 11, Grad norm: 3.214e+01\n",
      "Epoch 14844, Loss: 431.9595031738281, Neurons: 11, Grad norm: 2.405e+01\n",
      "Epoch 14845, Loss: 431.9570007324219, Neurons: 11, Grad norm: 1.338e+01\n",
      "Epoch 14846, Loss: 431.95458984375, Neurons: 11, Grad norm: 4.232e+00\n",
      "Epoch 14847, Loss: 431.95208740234375, Neurons: 11, Grad norm: 6.364e+00\n",
      "Epoch 14848, Loss: 431.94964599609375, Neurons: 11, Grad norm: 1.465e+01\n",
      "Epoch 14849, Loss: 431.9472351074219, Neurons: 11, Grad norm: 2.245e+01\n",
      "Epoch 14849, Test loss: 428.517333984375\n",
      "Epoch 14850, Loss: 431.9447937011719, Neurons: 11, Grad norm: 2.747e+01\n",
      "Epoch 14851, Loss: 431.9423828125, Neurons: 11, Grad norm: 3.146e+01\n",
      "Epoch 14852, Loss: 431.93994140625, Neurons: 11, Grad norm: 3.240e+01\n",
      "Epoch 14853, Loss: 431.9375, Neurons: 11, Grad norm: 3.260e+01\n",
      "Epoch 14854, Loss: 431.9350891113281, Neurons: 11, Grad norm: 2.917e+01\n",
      "Epoch 14855, Loss: 431.9325866699219, Neurons: 11, Grad norm: 2.531e+01\n",
      "Epoch 14856, Loss: 431.9301452636719, Neurons: 11, Grad norm: 1.941e+01\n",
      "Epoch 14857, Loss: 431.9277038574219, Neurons: 11, Grad norm: 1.362e+01\n",
      "Epoch 14858, Loss: 431.9252014160156, Neurons: 11, Grad norm: 6.961e+00\n",
      "Epoch 14859, Loss: 431.9226989746094, Neurons: 11, Grad norm: 1.892e+00\n",
      "Epoch 14860, Loss: 431.9202880859375, Neurons: 11, Grad norm: 5.179e+00\n",
      "Epoch 14861, Loss: 431.91778564453125, Neurons: 11, Grad norm: 9.166e+00\n",
      "Epoch 14862, Loss: 431.91534423828125, Neurons: 11, Grad norm: 1.360e+01\n",
      "Epoch 14863, Loss: 431.91290283203125, Neurons: 11, Grad norm: 1.568e+01\n",
      "Epoch 14864, Loss: 431.9104309082031, Neurons: 11, Grad norm: 1.797e+01\n",
      "Epoch 14865, Loss: 431.9079895019531, Neurons: 11, Grad norm: 1.820e+01\n",
      "Epoch 14866, Loss: 431.9054870605469, Neurons: 11, Grad norm: 1.829e+01\n",
      "Epoch 14867, Loss: 431.9030456542969, Neurons: 11, Grad norm: 1.682e+01\n",
      "Epoch 14868, Loss: 431.9006042480469, Neurons: 11, Grad norm: 1.551e+01\n",
      "Epoch 14869, Loss: 431.8981018066406, Neurons: 11, Grad norm: 1.275e+01\n",
      "Epoch 14870, Loss: 431.89569091796875, Neurons: 11, Grad norm: 1.075e+01\n",
      "Epoch 14871, Loss: 431.8931884765625, Neurons: 11, Grad norm: 7.443e+00\n",
      "Epoch 14872, Loss: 431.89068603515625, Neurons: 11, Grad norm: 5.369e+00\n",
      "Epoch 14873, Loss: 431.88818359375, Neurons: 11, Grad norm: 2.640e+00\n",
      "Epoch 14874, Loss: 431.8857421875, Neurons: 11, Grad norm: 1.973e+00\n",
      "Epoch 14875, Loss: 431.88330078125, Neurons: 11, Grad norm: 1.785e+00\n",
      "Epoch 14876, Loss: 431.88079833984375, Neurons: 11, Grad norm: 3.460e+00\n",
      "Epoch 14877, Loss: 431.8783264160156, Neurons: 11, Grad norm: 5.252e+00\n",
      "Epoch 14878, Loss: 431.8758850097656, Neurons: 11, Grad norm: 6.503e+00\n",
      "Epoch 14879, Loss: 431.8733825683594, Neurons: 11, Grad norm: 8.355e+00\n",
      "Epoch 14880, Loss: 431.8708801269531, Neurons: 11, Grad norm: 7.535e+00\n",
      "Epoch 14881, Loss: 431.8683776855469, Neurons: 11, Grad norm: 8.953e+00\n",
      "Epoch 14882, Loss: 431.8659362792969, Neurons: 11, Grad norm: 9.342e+00\n",
      "Epoch 14883, Loss: 431.8634338378906, Neurons: 11, Grad norm: 9.894e+00\n",
      "Epoch 14884, Loss: 431.8609924316406, Neurons: 11, Grad norm: 9.929e+00\n",
      "Epoch 14885, Loss: 431.8584899902344, Neurons: 11, Grad norm: 1.004e+01\n",
      "Epoch 14886, Loss: 431.8559875488281, Neurons: 11, Grad norm: 8.266e+00\n",
      "Epoch 14887, Loss: 431.8534851074219, Neurons: 11, Grad norm: 8.381e+00\n",
      "Epoch 14888, Loss: 431.8509826660156, Neurons: 11, Grad norm: 6.882e+00\n",
      "Epoch 14889, Loss: 431.8486022949219, Neurons: 11, Grad norm: 6.816e+00\n",
      "Epoch 14890, Loss: 431.8460388183594, Neurons: 11, Grad norm: 6.782e+00\n",
      "Epoch 14891, Loss: 431.8435974121094, Neurons: 11, Grad norm: 6.682e+00\n",
      "Epoch 14892, Loss: 431.8410339355469, Neurons: 11, Grad norm: 6.252e+00\n",
      "Epoch 14893, Loss: 431.8385314941406, Neurons: 11, Grad norm: 7.794e+00\n",
      "Epoch 14894, Loss: 431.8360900878906, Neurons: 11, Grad norm: 7.217e+00\n",
      "Epoch 14895, Loss: 431.8335876464844, Neurons: 11, Grad norm: 8.517e+00\n",
      "Epoch 14896, Loss: 431.8310852050781, Neurons: 11, Grad norm: 8.572e+00\n",
      "Epoch 14897, Loss: 431.8285827636719, Neurons: 11, Grad norm: 9.384e+00\n",
      "Epoch 14898, Loss: 431.8260803222656, Neurons: 11, Grad norm: 1.093e+01\n",
      "Epoch 14899, Loss: 431.8235778808594, Neurons: 11, Grad norm: 1.334e+01\n",
      "Epoch 14899, Test loss: 428.40106201171875\n",
      "Epoch 14900, Loss: 431.8210754394531, Neurons: 11, Grad norm: 1.577e+01\n",
      "Epoch 14901, Loss: 431.818603515625, Neurons: 11, Grad norm: 2.010e+01\n",
      "Epoch 14902, Loss: 431.8160400390625, Neurons: 11, Grad norm: 2.226e+01\n",
      "Epoch 14903, Loss: 431.8135986328125, Neurons: 11, Grad norm: 2.649e+01\n",
      "Epoch 14904, Loss: 431.81109619140625, Neurons: 11, Grad norm: 2.945e+01\n",
      "Epoch 14905, Loss: 431.80859375, Neurons: 11, Grad norm: 3.345e+01\n",
      "Epoch 14906, Loss: 431.80609130859375, Neurons: 11, Grad norm: 3.755e+01\n",
      "Epoch 14907, Loss: 431.8035888671875, Neurons: 11, Grad norm: 4.245e+01\n",
      "Epoch 14908, Loss: 431.80108642578125, Neurons: 11, Grad norm: 4.860e+01\n",
      "Epoch 14909, Loss: 431.798583984375, Neurons: 11, Grad norm: 5.672e+01\n",
      "Epoch 14910, Loss: 431.79620361328125, Neurons: 11, Grad norm: 6.372e+01\n",
      "Epoch 14911, Loss: 431.793701171875, Neurons: 11, Grad norm: 7.472e+01\n",
      "Epoch 14912, Loss: 431.7912902832031, Neurons: 11, Grad norm: 8.528e+01\n",
      "Epoch 14913, Loss: 431.78887939453125, Neurons: 11, Grad norm: 9.886e+01\n",
      "Epoch 14914, Loss: 431.7865905761719, Neurons: 11, Grad norm: 1.149e+02\n",
      "Epoch 14915, Loss: 431.7843322753906, Neurons: 11, Grad norm: 1.332e+02\n",
      "Epoch 14916, Loss: 431.7821350097656, Neurons: 11, Grad norm: 1.544e+02\n",
      "Epoch 14917, Loss: 431.78009033203125, Neurons: 11, Grad norm: 1.780e+02\n",
      "Epoch 14918, Loss: 431.778076171875, Neurons: 11, Grad norm: 1.998e+02\n",
      "Epoch 14919, Loss: 431.7762756347656, Neurons: 11, Grad norm: 2.230e+02\n",
      "Epoch 14920, Loss: 431.7744445800781, Neurons: 11, Grad norm: 2.405e+02\n",
      "Epoch 14921, Loss: 431.7725830078125, Neurons: 11, Grad norm: 2.523e+02\n",
      "Epoch 14922, Loss: 431.7704772949219, Neurons: 11, Grad norm: 2.518e+02\n",
      "Epoch 14923, Loss: 431.7680358886719, Neurons: 11, Grad norm: 2.362e+02\n",
      "Epoch 14924, Loss: 431.76507568359375, Neurons: 11, Grad norm: 2.038e+02\n",
      "Epoch 14925, Loss: 431.7616271972656, Neurons: 11, Grad norm: 1.559e+02\n",
      "Epoch 14926, Loss: 431.75799560546875, Neurons: 11, Grad norm: 9.571e+01\n",
      "Epoch 14927, Loss: 431.7544860839844, Neurons: 11, Grad norm: 3.294e+01\n",
      "Epoch 14928, Loss: 431.7514953613281, Neurons: 11, Grad norm: 2.917e+01\n",
      "Epoch 14929, Loss: 431.7489929199219, Neurons: 11, Grad norm: 8.015e+01\n",
      "Epoch 14930, Loss: 431.7469787597656, Neurons: 11, Grad norm: 1.190e+02\n",
      "Epoch 14931, Loss: 431.7451477050781, Neurons: 11, Grad norm: 1.409e+02\n",
      "Epoch 14932, Loss: 431.7431335449219, Neurons: 11, Grad norm: 1.461e+02\n",
      "Epoch 14933, Loss: 431.7408447265625, Neurons: 11, Grad norm: 1.339e+02\n",
      "Epoch 14934, Loss: 431.7382507324219, Neurons: 11, Grad norm: 1.080e+02\n",
      "Epoch 14935, Loss: 431.7353820800781, Neurons: 11, Grad norm: 7.042e+01\n",
      "Epoch 14936, Loss: 431.73248291015625, Neurons: 11, Grad norm: 2.995e+01\n",
      "Epoch 14937, Loss: 431.72979736328125, Neurons: 11, Grad norm: 1.096e+01\n",
      "Epoch 14938, Loss: 431.727294921875, Neurons: 11, Grad norm: 4.559e+01\n",
      "Epoch 14939, Loss: 431.72509765625, Neurons: 11, Grad norm: 7.263e+01\n",
      "Epoch 14940, Loss: 431.722900390625, Neurons: 11, Grad norm: 8.699e+01\n",
      "Epoch 14941, Loss: 431.72064208984375, Neurons: 11, Grad norm: 9.049e+01\n",
      "Epoch 14942, Loss: 431.7182922363281, Neurons: 11, Grad norm: 8.151e+01\n",
      "Epoch 14943, Loss: 431.7157287597656, Neurons: 11, Grad norm: 6.416e+01\n",
      "Epoch 14944, Loss: 431.71319580078125, Neurons: 11, Grad norm: 4.005e+01\n",
      "Epoch 14945, Loss: 431.7106018066406, Neurons: 11, Grad norm: 1.454e+01\n",
      "Epoch 14946, Loss: 431.7080993652344, Neurons: 11, Grad norm: 1.162e+01\n",
      "Epoch 14947, Loss: 431.7056884765625, Neurons: 11, Grad norm: 3.235e+01\n",
      "Epoch 14948, Loss: 431.7033996582031, Neurons: 11, Grad norm: 4.799e+01\n",
      "Epoch 14949, Loss: 431.70098876953125, Neurons: 11, Grad norm: 5.631e+01\n",
      "Epoch 14949, Test loss: 428.298583984375\n",
      "Epoch 14950, Loss: 431.6986999511719, Neurons: 11, Grad norm: 5.809e+01\n",
      "Epoch 14951, Loss: 431.6962890625, Neurons: 11, Grad norm: 5.127e+01\n",
      "Epoch 14952, Loss: 431.6938781738281, Neurons: 11, Grad norm: 4.124e+01\n",
      "Epoch 14953, Loss: 431.6913757324219, Neurons: 11, Grad norm: 2.742e+01\n",
      "Epoch 14954, Loss: 431.68890380859375, Neurons: 11, Grad norm: 1.272e+01\n",
      "Epoch 14955, Loss: 431.6864318847656, Neurons: 11, Grad norm: 3.347e+00\n",
      "Epoch 14956, Loss: 431.6839904785156, Neurons: 11, Grad norm: 1.582e+01\n",
      "Epoch 14957, Loss: 431.68157958984375, Neurons: 11, Grad norm: 2.657e+01\n",
      "Epoch 14958, Loss: 431.67919921875, Neurons: 11, Grad norm: 3.333e+01\n",
      "Epoch 14959, Loss: 431.6768493652344, Neurons: 11, Grad norm: 3.710e+01\n",
      "Epoch 14960, Loss: 431.6744384765625, Neurons: 11, Grad norm: 3.499e+01\n",
      "Epoch 14961, Loss: 431.6719970703125, Neurons: 11, Grad norm: 3.064e+01\n",
      "Epoch 14962, Loss: 431.6695861816406, Neurons: 11, Grad norm: 2.246e+01\n",
      "Epoch 14963, Loss: 431.6670837402344, Neurons: 11, Grad norm: 1.366e+01\n",
      "Epoch 14964, Loss: 431.6647033691406, Neurons: 11, Grad norm: 4.057e+00\n",
      "Epoch 14965, Loss: 431.66229248046875, Neurons: 11, Grad norm: 4.075e+00\n",
      "Epoch 14966, Loss: 431.6598815917969, Neurons: 11, Grad norm: 1.078e+01\n",
      "Epoch 14967, Loss: 431.6573791503906, Neurons: 11, Grad norm: 1.549e+01\n",
      "Epoch 14968, Loss: 431.6549987792969, Neurons: 11, Grad norm: 1.900e+01\n",
      "Epoch 14969, Loss: 431.652587890625, Neurons: 11, Grad norm: 1.942e+01\n",
      "Epoch 14970, Loss: 431.650146484375, Neurons: 11, Grad norm: 2.029e+01\n",
      "Epoch 14971, Loss: 431.6477355957031, Neurons: 11, Grad norm: 1.821e+01\n",
      "Epoch 14972, Loss: 431.6452941894531, Neurons: 11, Grad norm: 1.548e+01\n",
      "Epoch 14973, Loss: 431.6428527832031, Neurons: 11, Grad norm: 1.111e+01\n",
      "Epoch 14974, Loss: 431.640380859375, Neurons: 11, Grad norm: 6.814e+00\n",
      "Epoch 14975, Loss: 431.63800048828125, Neurons: 11, Grad norm: 2.068e+00\n",
      "Epoch 14976, Loss: 431.6355285644531, Neurons: 11, Grad norm: 2.934e+00\n",
      "Epoch 14977, Loss: 431.6330871582031, Neurons: 11, Grad norm: 8.102e+00\n",
      "Epoch 14978, Loss: 431.63067626953125, Neurons: 11, Grad norm: 1.048e+01\n",
      "Epoch 14979, Loss: 431.6282043457031, Neurons: 11, Grad norm: 1.325e+01\n",
      "Epoch 14980, Loss: 431.62579345703125, Neurons: 11, Grad norm: 1.482e+01\n",
      "Epoch 14981, Loss: 431.6233825683594, Neurons: 11, Grad norm: 1.498e+01\n",
      "Epoch 14982, Loss: 431.6208801269531, Neurons: 11, Grad norm: 1.385e+01\n",
      "Epoch 14983, Loss: 431.6184997558594, Neurons: 11, Grad norm: 1.376e+01\n",
      "Epoch 14984, Loss: 431.61602783203125, Neurons: 11, Grad norm: 1.181e+01\n",
      "Epoch 14985, Loss: 431.61358642578125, Neurons: 11, Grad norm: 1.148e+01\n",
      "Epoch 14986, Loss: 431.61114501953125, Neurons: 11, Grad norm: 9.655e+00\n",
      "Epoch 14987, Loss: 431.60870361328125, Neurons: 11, Grad norm: 8.900e+00\n",
      "Epoch 14988, Loss: 431.6062316894531, Neurons: 11, Grad norm: 7.670e+00\n",
      "Epoch 14989, Loss: 431.6037902832031, Neurons: 11, Grad norm: 7.048e+00\n",
      "Epoch 14990, Loss: 431.6013488769531, Neurons: 11, Grad norm: 5.169e+00\n",
      "Epoch 14991, Loss: 431.598876953125, Neurons: 11, Grad norm: 4.258e+00\n",
      "Epoch 14992, Loss: 431.59637451171875, Neurons: 11, Grad norm: 3.326e+00\n",
      "Epoch 14993, Loss: 431.59393310546875, Neurons: 11, Grad norm: 3.742e+00\n",
      "Epoch 14994, Loss: 431.591552734375, Neurons: 11, Grad norm: 3.466e+00\n",
      "Epoch 14995, Loss: 431.58905029296875, Neurons: 11, Grad norm: 4.890e+00\n",
      "Epoch 14996, Loss: 431.5865783691406, Neurons: 11, Grad norm: 4.438e+00\n",
      "Epoch 14997, Loss: 431.5840759277344, Neurons: 11, Grad norm: 5.087e+00\n",
      "Epoch 14998, Loss: 431.5816955566406, Neurons: 11, Grad norm: 5.734e+00\n",
      "Epoch 14999, Loss: 431.5791931152344, Neurons: 11, Grad norm: 6.880e+00\n",
      "Epoch 14999, Test loss: 428.16888427734375\n",
      "Epoch 15000, Loss: 431.5767517089844, Neurons: 11, Grad norm: 6.831e+00\n",
      "Epoch 15001, Loss: 431.57427978515625, Neurons: 11, Grad norm: 7.494e+00\n",
      "Epoch 15002, Loss: 431.57177734375, Neurons: 11, Grad norm: 6.735e+00\n",
      "Epoch 15003, Loss: 431.56927490234375, Neurons: 11, Grad norm: 7.072e+00\n",
      "Epoch 15004, Loss: 431.56689453125, Neurons: 11, Grad norm: 6.029e+00\n",
      "Epoch 15005, Loss: 431.56439208984375, Neurons: 11, Grad norm: 5.998e+00\n",
      "Epoch 15006, Loss: 431.56195068359375, Neurons: 11, Grad norm: 5.868e+00\n",
      "Epoch 15007, Loss: 431.5594787597656, Neurons: 11, Grad norm: 6.659e+00\n",
      "Epoch 15008, Loss: 431.5569763183594, Neurons: 11, Grad norm: 6.062e+00\n",
      "Epoch 15009, Loss: 431.5544738769531, Neurons: 11, Grad norm: 6.549e+00\n",
      "Epoch 15010, Loss: 431.552001953125, Neurons: 11, Grad norm: 5.774e+00\n",
      "Epoch 15011, Loss: 431.5495910644531, Neurons: 11, Grad norm: 5.771e+00\n",
      "Epoch 15012, Loss: 431.5470886230469, Neurons: 11, Grad norm: 4.955e+00\n",
      "Epoch 15013, Loss: 431.5445861816406, Neurons: 11, Grad norm: 4.814e+00\n",
      "Epoch 15014, Loss: 431.5420837402344, Neurons: 11, Grad norm: 3.928e+00\n",
      "Epoch 15015, Loss: 431.5396423339844, Neurons: 11, Grad norm: 4.827e+00\n",
      "Epoch 15016, Loss: 431.5371398925781, Neurons: 11, Grad norm: 4.937e+00\n",
      "Epoch 15017, Loss: 431.5346374511719, Neurons: 11, Grad norm: 5.627e+00\n",
      "Epoch 15018, Loss: 431.5321960449219, Neurons: 11, Grad norm: 5.491e+00\n",
      "Epoch 15019, Loss: 431.5296936035156, Neurons: 11, Grad norm: 6.075e+00\n",
      "Epoch 15020, Loss: 431.5271911621094, Neurons: 11, Grad norm: 5.554e+00\n",
      "Epoch 15021, Loss: 431.5246887207031, Neurons: 11, Grad norm: 6.115e+00\n",
      "Epoch 15022, Loss: 431.5222473144531, Neurons: 11, Grad norm: 5.643e+00\n",
      "Epoch 15023, Loss: 431.5197448730469, Neurons: 11, Grad norm: 7.327e+00\n",
      "Epoch 15024, Loss: 431.5172424316406, Neurons: 11, Grad norm: 7.257e+00\n",
      "Epoch 15025, Loss: 431.5147399902344, Neurons: 11, Grad norm: 7.219e+00\n",
      "Epoch 15026, Loss: 431.5122985839844, Neurons: 11, Grad norm: 7.262e+00\n",
      "Epoch 15027, Loss: 431.5097961425781, Neurons: 11, Grad norm: 7.520e+00\n",
      "Epoch 15028, Loss: 431.5072326660156, Neurons: 11, Grad norm: 7.043e+00\n",
      "Epoch 15029, Loss: 431.5047302246094, Neurons: 11, Grad norm: 8.954e+00\n",
      "Epoch 15030, Loss: 431.502197265625, Neurons: 11, Grad norm: 8.565e+00\n",
      "Epoch 15031, Loss: 431.4997253417969, Neurons: 11, Grad norm: 1.021e+01\n",
      "Epoch 15032, Loss: 431.49725341796875, Neurons: 11, Grad norm: 1.174e+01\n",
      "Epoch 15033, Loss: 431.49468994140625, Neurons: 11, Grad norm: 1.303e+01\n",
      "Epoch 15034, Loss: 431.49224853515625, Neurons: 11, Grad norm: 1.459e+01\n",
      "Epoch 15035, Loss: 431.48968505859375, Neurons: 11, Grad norm: 1.789e+01\n",
      "Epoch 15036, Loss: 431.4871826171875, Neurons: 11, Grad norm: 2.061e+01\n",
      "Epoch 15037, Loss: 431.48468017578125, Neurons: 11, Grad norm: 2.571e+01\n",
      "Epoch 15038, Loss: 431.482177734375, Neurons: 11, Grad norm: 2.903e+01\n",
      "Epoch 15039, Loss: 431.47967529296875, Neurons: 11, Grad norm: 3.430e+01\n",
      "Epoch 15040, Loss: 431.47723388671875, Neurons: 11, Grad norm: 4.035e+01\n",
      "Epoch 15041, Loss: 431.4747009277344, Neurons: 11, Grad norm: 4.779e+01\n",
      "Epoch 15042, Loss: 431.4722900390625, Neurons: 11, Grad norm: 5.638e+01\n",
      "Epoch 15043, Loss: 431.4698486328125, Neurons: 11, Grad norm: 6.718e+01\n",
      "Epoch 15044, Loss: 431.4673767089844, Neurons: 11, Grad norm: 7.873e+01\n",
      "Epoch 15045, Loss: 431.4649963378906, Neurons: 11, Grad norm: 9.494e+01\n",
      "Epoch 15046, Loss: 431.4626770019531, Neurons: 11, Grad norm: 1.123e+02\n",
      "Epoch 15047, Loss: 431.46044921875, Neurons: 11, Grad norm: 1.340e+02\n",
      "Epoch 15048, Loss: 431.4583435058594, Neurons: 11, Grad norm: 1.588e+02\n",
      "Epoch 15049, Loss: 431.4563903808594, Neurons: 11, Grad norm: 1.864e+02\n",
      "Epoch 15049, Test loss: 428.01519775390625\n",
      "Epoch 15050, Loss: 431.4544982910156, Neurons: 11, Grad norm: 2.151e+02\n",
      "Epoch 15051, Loss: 431.4528503417969, Neurons: 11, Grad norm: 2.443e+02\n",
      "Epoch 15052, Loss: 431.4513244628906, Neurons: 11, Grad norm: 2.675e+02\n",
      "Epoch 15053, Loss: 431.4496765136719, Neurons: 11, Grad norm: 2.831e+02\n",
      "Epoch 15054, Loss: 431.4478759765625, Neurons: 11, Grad norm: 2.823e+02\n",
      "Epoch 15055, Loss: 431.4454040527344, Neurons: 11, Grad norm: 2.617e+02\n",
      "Epoch 15056, Loss: 431.44219970703125, Neurons: 11, Grad norm: 2.177e+02\n",
      "Epoch 15057, Loss: 431.438232421875, Neurons: 11, Grad norm: 1.542e+02\n",
      "Epoch 15058, Loss: 431.43414306640625, Neurons: 11, Grad norm: 7.755e+01\n",
      "Epoch 15059, Loss: 431.43048095703125, Neurons: 11, Grad norm: 1.497e+00\n",
      "Epoch 15060, Loss: 431.4275817871094, Neurons: 11, Grad norm: 7.056e+01\n",
      "Epoch 15061, Loss: 431.42559814453125, Neurons: 11, Grad norm: 1.236e+02\n",
      "Epoch 15062, Loss: 431.4239807128906, Neurons: 11, Grad norm: 1.563e+02\n",
      "Epoch 15063, Loss: 431.4222412109375, Neurons: 11, Grad norm: 1.642e+02\n",
      "Epoch 15064, Loss: 431.4200439453125, Neurons: 11, Grad norm: 1.496e+02\n",
      "Epoch 15065, Loss: 431.4173278808594, Neurons: 11, Grad norm: 1.153e+02\n",
      "Epoch 15066, Loss: 431.4142761230469, Neurons: 11, Grad norm: 6.800e+01\n",
      "Epoch 15067, Loss: 431.4112854003906, Neurons: 11, Grad norm: 1.370e+01\n",
      "Epoch 15068, Loss: 431.4085998535156, Neurons: 11, Grad norm: 3.619e+01\n",
      "Epoch 15069, Loss: 431.4062805175781, Neurons: 11, Grad norm: 7.763e+01\n",
      "Epoch 15070, Loss: 431.4041748046875, Neurons: 11, Grad norm: 1.029e+02\n",
      "Epoch 15071, Loss: 431.4021911621094, Neurons: 11, Grad norm: 1.114e+02\n",
      "Epoch 15072, Loss: 431.39990234375, Neurons: 11, Grad norm: 1.020e+02\n",
      "Epoch 15073, Loss: 431.39739990234375, Neurons: 11, Grad norm: 7.889e+01\n",
      "Epoch 15074, Loss: 431.3946838378906, Neurons: 11, Grad norm: 4.497e+01\n",
      "Epoch 15075, Loss: 431.39202880859375, Neurons: 11, Grad norm: 8.844e+00\n",
      "Epoch 15076, Loss: 431.3895263671875, Neurons: 11, Grad norm: 2.692e+01\n",
      "Epoch 15077, Loss: 431.3871765136719, Neurons: 11, Grad norm: 5.442e+01\n",
      "Epoch 15078, Loss: 431.3849792480469, Neurons: 11, Grad norm: 7.192e+01\n",
      "Epoch 15079, Loss: 431.38275146484375, Neurons: 11, Grad norm: 7.616e+01\n",
      "Epoch 15080, Loss: 431.3804016113281, Neurons: 11, Grad norm: 6.970e+01\n",
      "Epoch 15081, Loss: 431.37799072265625, Neurons: 11, Grad norm: 5.361e+01\n",
      "Epoch 15082, Loss: 431.37542724609375, Neurons: 11, Grad norm: 3.285e+01\n",
      "Epoch 15083, Loss: 431.37298583984375, Neurons: 11, Grad norm: 8.303e+00\n",
      "Epoch 15084, Loss: 431.3704833984375, Neurons: 11, Grad norm: 1.441e+01\n",
      "Epoch 15085, Loss: 431.3681335449219, Neurons: 11, Grad norm: 3.428e+01\n",
      "Epoch 15086, Loss: 431.36578369140625, Neurons: 11, Grad norm: 4.663e+01\n",
      "Epoch 15087, Loss: 431.3634948730469, Neurons: 11, Grad norm: 5.211e+01\n",
      "Epoch 15088, Loss: 431.36114501953125, Neurons: 11, Grad norm: 4.961e+01\n",
      "Epoch 15089, Loss: 431.3587341308594, Neurons: 11, Grad norm: 4.116e+01\n",
      "Epoch 15090, Loss: 431.3562927246094, Neurons: 11, Grad norm: 2.648e+01\n",
      "Epoch 15091, Loss: 431.3538513183594, Neurons: 11, Grad norm: 1.076e+01\n",
      "Epoch 15092, Loss: 431.35137939453125, Neurons: 11, Grad norm: 6.400e+00\n",
      "Epoch 15093, Loss: 431.3489990234375, Neurons: 11, Grad norm: 1.953e+01\n",
      "Epoch 15094, Loss: 431.3466491699219, Neurons: 11, Grad norm: 2.986e+01\n",
      "Epoch 15095, Loss: 431.34429931640625, Neurons: 11, Grad norm: 3.509e+01\n",
      "Epoch 15096, Loss: 431.3418884277344, Neurons: 11, Grad norm: 3.519e+01\n",
      "Epoch 15097, Loss: 431.3394775390625, Neurons: 11, Grad norm: 2.999e+01\n",
      "Epoch 15098, Loss: 431.33709716796875, Neurons: 11, Grad norm: 2.349e+01\n",
      "Epoch 15099, Loss: 431.3346862792969, Neurons: 11, Grad norm: 1.270e+01\n",
      "Epoch 15099, Test loss: 427.9394226074219\n",
      "Epoch 15100, Loss: 431.332275390625, Neurons: 11, Grad norm: 3.115e+00\n",
      "Epoch 15101, Loss: 431.329833984375, Neurons: 11, Grad norm: 7.405e+00\n",
      "Epoch 15102, Loss: 431.32745361328125, Neurons: 11, Grad norm: 1.498e+01\n",
      "Epoch 15103, Loss: 431.3250427246094, Neurons: 11, Grad norm: 2.012e+01\n",
      "Epoch 15104, Loss: 431.3226318359375, Neurons: 11, Grad norm: 2.194e+01\n",
      "Epoch 15105, Loss: 431.3202819824219, Neurons: 11, Grad norm: 2.164e+01\n",
      "Epoch 15106, Loss: 431.3179016113281, Neurons: 11, Grad norm: 1.754e+01\n",
      "Epoch 15107, Loss: 431.3153991699219, Neurons: 11, Grad norm: 1.325e+01\n",
      "Epoch 15108, Loss: 431.31298828125, Neurons: 11, Grad norm: 6.321e+00\n",
      "Epoch 15109, Loss: 431.3105773925781, Neurons: 11, Grad norm: 1.555e+00\n",
      "Epoch 15110, Loss: 431.3081970214844, Neurons: 11, Grad norm: 4.745e+00\n",
      "Epoch 15111, Loss: 431.3057861328125, Neurons: 11, Grad norm: 7.786e+00\n",
      "Epoch 15112, Loss: 431.3033752441406, Neurons: 11, Grad norm: 1.050e+01\n",
      "Epoch 15113, Loss: 431.3009948730469, Neurons: 11, Grad norm: 1.100e+01\n",
      "Epoch 15114, Loss: 431.2984924316406, Neurons: 11, Grad norm: 1.103e+01\n",
      "Epoch 15115, Loss: 431.296142578125, Neurons: 11, Grad norm: 9.116e+00\n",
      "Epoch 15116, Loss: 431.293701171875, Neurons: 11, Grad norm: 7.339e+00\n",
      "Epoch 15117, Loss: 431.2912292480469, Neurons: 11, Grad norm: 4.165e+00\n",
      "Epoch 15118, Loss: 431.28887939453125, Neurons: 11, Grad norm: 2.852e+00\n",
      "Epoch 15119, Loss: 431.28643798828125, Neurons: 11, Grad norm: 1.513e+00\n",
      "Epoch 15120, Loss: 431.2840270996094, Neurons: 11, Grad norm: 1.658e+00\n",
      "Epoch 15121, Loss: 431.2815856933594, Neurons: 11, Grad norm: 2.607e+00\n",
      "Epoch 15122, Loss: 431.2791748046875, Neurons: 11, Grad norm: 2.931e+00\n",
      "Epoch 15123, Loss: 431.2767333984375, Neurons: 11, Grad norm: 4.832e+00\n",
      "Epoch 15124, Loss: 431.2742919921875, Neurons: 11, Grad norm: 5.492e+00\n",
      "Epoch 15125, Loss: 431.2718811035156, Neurons: 11, Grad norm: 6.365e+00\n",
      "Epoch 15126, Loss: 431.2695007324219, Neurons: 11, Grad norm: 5.850e+00\n",
      "Epoch 15127, Loss: 431.26702880859375, Neurons: 11, Grad norm: 5.702e+00\n",
      "Epoch 15128, Loss: 431.26458740234375, Neurons: 11, Grad norm: 4.365e+00\n",
      "Epoch 15129, Loss: 431.2621765136719, Neurons: 11, Grad norm: 4.669e+00\n",
      "Epoch 15130, Loss: 431.2597351074219, Neurons: 11, Grad norm: 2.993e+00\n",
      "Epoch 15131, Loss: 431.2572937011719, Neurons: 11, Grad norm: 2.444e+00\n",
      "Epoch 15132, Loss: 431.2548828125, Neurons: 11, Grad norm: 2.047e+00\n",
      "Epoch 15133, Loss: 431.25244140625, Neurons: 11, Grad norm: 1.597e+00\n",
      "Epoch 15134, Loss: 431.25, Neurons: 11, Grad norm: 1.516e+00\n",
      "Epoch 15135, Loss: 431.24749755859375, Neurons: 11, Grad norm: 1.559e+00\n",
      "Epoch 15136, Loss: 431.2450866699219, Neurons: 11, Grad norm: 3.317e+00\n",
      "Epoch 15137, Loss: 431.2426452636719, Neurons: 11, Grad norm: 2.956e+00\n",
      "Epoch 15138, Loss: 431.2402038574219, Neurons: 11, Grad norm: 3.997e+00\n",
      "Epoch 15139, Loss: 431.23779296875, Neurons: 11, Grad norm: 4.929e+00\n",
      "Epoch 15140, Loss: 431.2353515625, Neurons: 11, Grad norm: 4.996e+00\n",
      "Epoch 15141, Loss: 431.23284912109375, Neurons: 11, Grad norm: 5.138e+00\n",
      "Epoch 15142, Loss: 431.2303771972656, Neurons: 11, Grad norm: 6.279e+00\n",
      "Epoch 15143, Loss: 431.2279968261719, Neurons: 11, Grad norm: 5.242e+00\n",
      "Epoch 15144, Loss: 431.2254943847656, Neurons: 11, Grad norm: 5.830e+00\n",
      "Epoch 15145, Loss: 431.22308349609375, Neurons: 11, Grad norm: 4.521e+00\n",
      "Epoch 15146, Loss: 431.2205810546875, Neurons: 11, Grad norm: 4.244e+00\n",
      "Epoch 15147, Loss: 431.2181396484375, Neurons: 11, Grad norm: 4.253e+00\n",
      "Epoch 15148, Loss: 431.2156982421875, Neurons: 11, Grad norm: 3.759e+00\n",
      "Epoch 15149, Loss: 431.2132263183594, Neurons: 11, Grad norm: 2.273e+00\n",
      "Epoch 15149, Test loss: 427.8213195800781\n",
      "Epoch 15150, Loss: 431.2107849121094, Neurons: 11, Grad norm: 2.236e+00\n",
      "Epoch 15151, Loss: 431.2082824707031, Neurons: 11, Grad norm: 1.450e+00\n",
      "Epoch 15152, Loss: 431.2059020996094, Neurons: 11, Grad norm: 1.451e+00\n",
      "Epoch 15153, Loss: 431.2033996582031, Neurons: 11, Grad norm: 2.058e+00\n",
      "Epoch 15154, Loss: 431.2008972167969, Neurons: 11, Grad norm: 3.240e+00\n",
      "Epoch 15155, Loss: 431.198486328125, Neurons: 11, Grad norm: 5.088e+00\n",
      "Epoch 15156, Loss: 431.19598388671875, Neurons: 11, Grad norm: 5.730e+00\n",
      "Epoch 15157, Loss: 431.1934814453125, Neurons: 11, Grad norm: 7.146e+00\n",
      "Epoch 15158, Loss: 431.19110107421875, Neurons: 11, Grad norm: 7.058e+00\n",
      "Epoch 15159, Loss: 431.1885986328125, Neurons: 11, Grad norm: 7.801e+00\n",
      "Epoch 15160, Loss: 431.1861267089844, Neurons: 11, Grad norm: 7.289e+00\n",
      "Epoch 15161, Loss: 431.1836242675781, Neurons: 11, Grad norm: 7.597e+00\n",
      "Epoch 15162, Loss: 431.1811828613281, Neurons: 11, Grad norm: 6.945e+00\n",
      "Epoch 15163, Loss: 431.1786804199219, Neurons: 11, Grad norm: 6.944e+00\n",
      "Epoch 15164, Loss: 431.1761779785156, Neurons: 11, Grad norm: 5.993e+00\n",
      "Epoch 15165, Loss: 431.1736755371094, Neurons: 11, Grad norm: 5.829e+00\n",
      "Epoch 15166, Loss: 431.1712341308594, Neurons: 11, Grad norm: 4.671e+00\n",
      "Epoch 15167, Loss: 431.1687927246094, Neurons: 11, Grad norm: 4.522e+00\n",
      "Epoch 15168, Loss: 431.1662902832031, Neurons: 11, Grad norm: 3.414e+00\n",
      "Epoch 15169, Loss: 431.1637878417969, Neurons: 11, Grad norm: 3.189e+00\n",
      "Epoch 15170, Loss: 431.1612854003906, Neurons: 11, Grad norm: 2.236e+00\n",
      "Epoch 15171, Loss: 431.1587829589844, Neurons: 11, Grad norm: 2.061e+00\n",
      "Epoch 15172, Loss: 431.1563415527344, Neurons: 11, Grad norm: 1.579e+00\n",
      "Epoch 15173, Loss: 431.1538391113281, Neurons: 11, Grad norm: 2.555e+00\n",
      "Epoch 15174, Loss: 431.1513366699219, Neurons: 11, Grad norm: 4.011e+00\n",
      "Epoch 15175, Loss: 431.1488952636719, Neurons: 11, Grad norm: 4.965e+00\n",
      "Epoch 15176, Loss: 431.1463928222656, Neurons: 11, Grad norm: 7.618e+00\n",
      "Epoch 15177, Loss: 431.1438903808594, Neurons: 11, Grad norm: 9.380e+00\n",
      "Epoch 15178, Loss: 431.1413879394531, Neurons: 11, Grad norm: 1.282e+01\n",
      "Epoch 15179, Loss: 431.1388854980469, Neurons: 11, Grad norm: 1.561e+01\n",
      "Epoch 15180, Loss: 431.1363830566406, Neurons: 11, Grad norm: 1.876e+01\n",
      "Epoch 15181, Loss: 431.1338806152344, Neurons: 11, Grad norm: 2.127e+01\n",
      "Epoch 15182, Loss: 431.1314392089844, Neurons: 11, Grad norm: 2.568e+01\n",
      "Epoch 15183, Loss: 431.1288757324219, Neurons: 11, Grad norm: 2.944e+01\n",
      "Epoch 15184, Loss: 431.1264343261719, Neurons: 11, Grad norm: 3.505e+01\n",
      "Epoch 15185, Loss: 431.1239318847656, Neurons: 11, Grad norm: 4.026e+01\n",
      "Epoch 15186, Loss: 431.1214904785156, Neurons: 11, Grad norm: 4.702e+01\n",
      "Epoch 15187, Loss: 431.1190490722656, Neurons: 11, Grad norm: 5.384e+01\n",
      "Epoch 15188, Loss: 431.1165771484375, Neurons: 11, Grad norm: 6.246e+01\n",
      "Epoch 15189, Loss: 431.11407470703125, Neurons: 11, Grad norm: 7.124e+01\n",
      "Epoch 15190, Loss: 431.1117248535156, Neurons: 11, Grad norm: 8.212e+01\n",
      "Epoch 15191, Loss: 431.1092834472656, Neurons: 11, Grad norm: 9.314e+01\n",
      "Epoch 15192, Loss: 431.10699462890625, Neurons: 11, Grad norm: 1.075e+02\n",
      "Epoch 15193, Loss: 431.10467529296875, Neurons: 11, Grad norm: 1.234e+02\n",
      "Epoch 15194, Loss: 431.1023864746094, Neurons: 11, Grad norm: 1.419e+02\n",
      "Epoch 15195, Loss: 431.10028076171875, Neurons: 11, Grad norm: 1.610e+02\n",
      "Epoch 15196, Loss: 431.0981750488281, Neurons: 11, Grad norm: 1.813e+02\n",
      "Epoch 15197, Loss: 431.09619140625, Neurons: 11, Grad norm: 1.995e+02\n",
      "Epoch 15198, Loss: 431.09417724609375, Neurons: 11, Grad norm: 2.164e+02\n",
      "Epoch 15199, Loss: 431.09228515625, Neurons: 11, Grad norm: 2.263e+02\n",
      "Epoch 15199, Test loss: 427.7532043457031\n",
      "Epoch 15200, Loss: 431.090087890625, Neurons: 11, Grad norm: 2.285e+02\n",
      "Epoch 15201, Loss: 431.0876770019531, Neurons: 11, Grad norm: 2.183e+02\n",
      "Epoch 15202, Loss: 431.0849304199219, Neurons: 11, Grad norm: 1.958e+02\n",
      "Epoch 15203, Loss: 431.08184814453125, Neurons: 11, Grad norm: 1.601e+02\n",
      "Epoch 15204, Loss: 431.0784912109375, Neurons: 11, Grad norm: 1.148e+02\n",
      "Epoch 15205, Loss: 431.0751953125, Neurons: 11, Grad norm: 6.338e+01\n",
      "Epoch 15206, Loss: 431.07208251953125, Neurons: 11, Grad norm: 1.251e+01\n",
      "Epoch 15207, Loss: 431.06939697265625, Neurons: 11, Grad norm: 3.673e+01\n",
      "Epoch 15208, Loss: 431.06707763671875, Neurons: 11, Grad norm: 7.547e+01\n",
      "Epoch 15209, Loss: 431.06500244140625, Neurons: 11, Grad norm: 1.051e+02\n",
      "Epoch 15210, Loss: 431.06292724609375, Neurons: 11, Grad norm: 1.220e+02\n",
      "Epoch 15211, Loss: 431.060791015625, Neurons: 11, Grad norm: 1.258e+02\n",
      "Epoch 15212, Loss: 431.0583801269531, Neurons: 11, Grad norm: 1.171e+02\n",
      "Epoch 15213, Loss: 431.05584716796875, Neurons: 11, Grad norm: 9.810e+01\n",
      "Epoch 15214, Loss: 431.0531311035156, Neurons: 11, Grad norm: 7.036e+01\n",
      "Epoch 15215, Loss: 431.0503845214844, Neurons: 11, Grad norm: 4.018e+01\n",
      "Epoch 15216, Loss: 431.04779052734375, Neurons: 11, Grad norm: 7.087e+00\n",
      "Epoch 15217, Loss: 431.0451965332031, Neurons: 11, Grad norm: 2.245e+01\n",
      "Epoch 15218, Loss: 431.0428466796875, Neurons: 11, Grad norm: 4.732e+01\n",
      "Epoch 15219, Loss: 431.04052734375, Neurons: 11, Grad norm: 6.528e+01\n",
      "Epoch 15220, Loss: 431.0382995605469, Neurons: 11, Grad norm: 7.628e+01\n",
      "Epoch 15221, Loss: 431.0359802246094, Neurons: 11, Grad norm: 7.880e+01\n",
      "Epoch 15222, Loss: 431.0335998535156, Neurons: 11, Grad norm: 7.458e+01\n",
      "Epoch 15223, Loss: 431.0310974121094, Neurons: 11, Grad norm: 6.193e+01\n",
      "Epoch 15224, Loss: 431.0285949707031, Neurons: 11, Grad norm: 4.586e+01\n",
      "Epoch 15225, Loss: 431.0260314941406, Neurons: 11, Grad norm: 2.602e+01\n",
      "Epoch 15226, Loss: 431.0235290527344, Neurons: 11, Grad norm: 7.000e+00\n",
      "Epoch 15227, Loss: 431.0210876464844, Neurons: 11, Grad norm: 1.135e+01\n",
      "Epoch 15228, Loss: 431.0186462402344, Neurons: 11, Grad norm: 2.634e+01\n",
      "Epoch 15229, Loss: 431.01629638671875, Neurons: 11, Grad norm: 3.779e+01\n",
      "Epoch 15230, Loss: 431.0138854980469, Neurons: 11, Grad norm: 4.347e+01\n",
      "Epoch 15231, Loss: 431.011474609375, Neurons: 11, Grad norm: 4.670e+01\n",
      "Epoch 15232, Loss: 431.00909423828125, Neurons: 11, Grad norm: 4.423e+01\n",
      "Epoch 15233, Loss: 431.0066833496094, Neurons: 11, Grad norm: 3.969e+01\n",
      "Epoch 15234, Loss: 431.0041809082031, Neurons: 11, Grad norm: 3.174e+01\n",
      "Epoch 15235, Loss: 431.0017395019531, Neurons: 11, Grad norm: 2.172e+01\n",
      "Epoch 15236, Loss: 430.9992980957031, Neurons: 11, Grad norm: 1.068e+01\n",
      "Epoch 15237, Loss: 430.9967956542969, Neurons: 11, Grad norm: 1.834e+00\n",
      "Epoch 15238, Loss: 430.994384765625, Neurons: 11, Grad norm: 9.154e+00\n",
      "Epoch 15239, Loss: 430.9919738769531, Neurons: 11, Grad norm: 1.587e+01\n",
      "Epoch 15240, Loss: 430.9895324707031, Neurons: 11, Grad norm: 2.194e+01\n",
      "Epoch 15241, Loss: 430.9870910644531, Neurons: 11, Grad norm: 2.574e+01\n",
      "Epoch 15242, Loss: 430.98468017578125, Neurons: 11, Grad norm: 2.700e+01\n",
      "Epoch 15243, Loss: 430.9822998046875, Neurons: 11, Grad norm: 2.570e+01\n",
      "Epoch 15244, Loss: 430.9798278808594, Neurons: 11, Grad norm: 2.439e+01\n",
      "Epoch 15245, Loss: 430.9773864746094, Neurons: 11, Grad norm: 2.061e+01\n",
      "Epoch 15246, Loss: 430.9748840332031, Neurons: 11, Grad norm: 1.775e+01\n",
      "Epoch 15247, Loss: 430.9725036621094, Neurons: 11, Grad norm: 1.240e+01\n",
      "Epoch 15248, Loss: 430.9700012207031, Neurons: 11, Grad norm: 7.725e+00\n",
      "Epoch 15249, Loss: 430.96759033203125, Neurons: 11, Grad norm: 2.774e+00\n",
      "Epoch 15249, Test loss: 427.5869445800781\n",
      "Epoch 15250, Loss: 430.96514892578125, Neurons: 11, Grad norm: 2.669e+00\n",
      "Epoch 15251, Loss: 430.9626770019531, Neurons: 11, Grad norm: 5.720e+00\n",
      "Epoch 15252, Loss: 430.9602966308594, Neurons: 11, Grad norm: 8.347e+00\n",
      "Epoch 15253, Loss: 430.9577941894531, Neurons: 11, Grad norm: 1.213e+01\n",
      "Epoch 15254, Loss: 430.9553527832031, Neurons: 11, Grad norm: 1.246e+01\n",
      "Epoch 15255, Loss: 430.952880859375, Neurons: 11, Grad norm: 1.402e+01\n",
      "Epoch 15256, Loss: 430.95050048828125, Neurons: 11, Grad norm: 1.324e+01\n",
      "Epoch 15257, Loss: 430.947998046875, Neurons: 11, Grad norm: 1.247e+01\n",
      "Epoch 15258, Loss: 430.9455871582031, Neurons: 11, Grad norm: 1.102e+01\n",
      "Epoch 15259, Loss: 430.9430847167969, Neurons: 11, Grad norm: 9.139e+00\n",
      "Epoch 15260, Loss: 430.9405822753906, Neurons: 11, Grad norm: 7.886e+00\n",
      "Epoch 15261, Loss: 430.9381408691406, Neurons: 11, Grad norm: 7.554e+00\n",
      "Epoch 15262, Loss: 430.9356994628906, Neurons: 11, Grad norm: 5.215e+00\n",
      "Epoch 15263, Loss: 430.9332275390625, Neurons: 11, Grad norm: 5.020e+00\n",
      "Epoch 15264, Loss: 430.93072509765625, Neurons: 11, Grad norm: 3.015e+00\n",
      "Epoch 15265, Loss: 430.92828369140625, Neurons: 11, Grad norm: 2.259e+00\n",
      "Epoch 15266, Loss: 430.9259033203125, Neurons: 11, Grad norm: 1.524e+00\n",
      "Epoch 15267, Loss: 430.92340087890625, Neurons: 11, Grad norm: 1.542e+00\n",
      "Epoch 15268, Loss: 430.9208984375, Neurons: 11, Grad norm: 1.983e+00\n",
      "Epoch 15269, Loss: 430.9184265136719, Neurons: 11, Grad norm: 2.238e+00\n",
      "Epoch 15270, Loss: 430.9159240722656, Neurons: 11, Grad norm: 3.191e+00\n",
      "Epoch 15271, Loss: 430.9134826660156, Neurons: 11, Grad norm: 2.862e+00\n",
      "Epoch 15272, Loss: 430.9109802246094, Neurons: 11, Grad norm: 4.998e+00\n",
      "Epoch 15273, Loss: 430.9085388183594, Neurons: 11, Grad norm: 5.775e+00\n",
      "Epoch 15274, Loss: 430.9060974121094, Neurons: 11, Grad norm: 6.918e+00\n",
      "Epoch 15275, Loss: 430.9035949707031, Neurons: 11, Grad norm: 7.577e+00\n",
      "Epoch 15276, Loss: 430.9011535644531, Neurons: 11, Grad norm: 8.237e+00\n",
      "Epoch 15277, Loss: 430.8986511230469, Neurons: 11, Grad norm: 8.370e+00\n",
      "Epoch 15278, Loss: 430.89617919921875, Neurons: 11, Grad norm: 9.100e+00\n",
      "Epoch 15279, Loss: 430.8936767578125, Neurons: 11, Grad norm: 8.538e+00\n",
      "Epoch 15280, Loss: 430.89117431640625, Neurons: 11, Grad norm: 1.023e+01\n",
      "Epoch 15281, Loss: 430.88873291015625, Neurons: 11, Grad norm: 9.503e+00\n",
      "Epoch 15282, Loss: 430.88629150390625, Neurons: 11, Grad norm: 1.014e+01\n",
      "Epoch 15283, Loss: 430.88372802734375, Neurons: 11, Grad norm: 1.094e+01\n",
      "Epoch 15284, Loss: 430.88128662109375, Neurons: 11, Grad norm: 1.090e+01\n",
      "Epoch 15285, Loss: 430.8787841796875, Neurons: 11, Grad norm: 1.079e+01\n",
      "Epoch 15286, Loss: 430.87628173828125, Neurons: 11, Grad norm: 1.128e+01\n",
      "Epoch 15287, Loss: 430.873779296875, Neurons: 11, Grad norm: 1.034e+01\n",
      "Epoch 15288, Loss: 430.87127685546875, Neurons: 11, Grad norm: 1.246e+01\n",
      "Epoch 15289, Loss: 430.8687744140625, Neurons: 11, Grad norm: 1.197e+01\n",
      "Epoch 15290, Loss: 430.8663330078125, Neurons: 11, Grad norm: 1.297e+01\n",
      "Epoch 15291, Loss: 430.86383056640625, Neurons: 11, Grad norm: 1.463e+01\n",
      "Epoch 15292, Loss: 430.86138916015625, Neurons: 11, Grad norm: 1.519e+01\n",
      "Epoch 15293, Loss: 430.8587951660156, Neurons: 11, Grad norm: 1.635e+01\n",
      "Epoch 15294, Loss: 430.8563537597656, Neurons: 11, Grad norm: 1.887e+01\n",
      "Epoch 15295, Loss: 430.8538818359375, Neurons: 11, Grad norm: 1.922e+01\n",
      "Epoch 15296, Loss: 430.85137939453125, Neurons: 11, Grad norm: 2.207e+01\n",
      "Epoch 15297, Loss: 430.8488464355469, Neurons: 11, Grad norm: 2.306e+01\n",
      "Epoch 15298, Loss: 430.8463439941406, Neurons: 11, Grad norm: 2.538e+01\n",
      "Epoch 15299, Loss: 430.8438415527344, Neurons: 11, Grad norm: 2.847e+01\n",
      "Epoch 15299, Test loss: 427.4745178222656\n",
      "Epoch 15300, Loss: 430.8414001464844, Neurons: 11, Grad norm: 3.093e+01\n",
      "Epoch 15301, Loss: 430.8388977050781, Neurons: 11, Grad norm: 3.389e+01\n",
      "Epoch 15302, Loss: 430.8363952636719, Neurons: 11, Grad norm: 3.897e+01\n",
      "Epoch 15303, Loss: 430.8338928222656, Neurons: 11, Grad norm: 4.215e+01\n",
      "Epoch 15304, Loss: 430.8313903808594, Neurons: 11, Grad norm: 4.795e+01\n",
      "Epoch 15305, Loss: 430.8288879394531, Neurons: 11, Grad norm: 5.287e+01\n",
      "Epoch 15306, Loss: 430.82647705078125, Neurons: 11, Grad norm: 5.934e+01\n",
      "Epoch 15307, Loss: 430.823974609375, Neurons: 11, Grad norm: 6.766e+01\n",
      "Epoch 15308, Loss: 430.821533203125, Neurons: 11, Grad norm: 7.839e+01\n",
      "Epoch 15309, Loss: 430.8191833496094, Neurons: 11, Grad norm: 9.073e+01\n",
      "Epoch 15310, Loss: 430.8168029785156, Neurons: 11, Grad norm: 1.063e+02\n",
      "Epoch 15311, Loss: 430.8144836425781, Neurons: 11, Grad norm: 1.226e+02\n",
      "Epoch 15312, Loss: 430.8122253417969, Neurons: 11, Grad norm: 1.426e+02\n",
      "Epoch 15313, Loss: 430.8101501464844, Neurons: 11, Grad norm: 1.635e+02\n",
      "Epoch 15314, Loss: 430.8080749511719, Neurons: 11, Grad norm: 1.863e+02\n",
      "Epoch 15315, Loss: 430.80615234375, Neurons: 11, Grad norm: 2.079e+02\n",
      "Epoch 15316, Loss: 430.8042907714844, Neurons: 11, Grad norm: 2.281e+02\n",
      "Epoch 15317, Loss: 430.80242919921875, Neurons: 11, Grad norm: 2.415e+02\n",
      "Epoch 15318, Loss: 430.80047607421875, Neurons: 11, Grad norm: 2.467e+02\n",
      "Epoch 15319, Loss: 430.7981872558594, Neurons: 11, Grad norm: 2.378e+02\n",
      "Epoch 15320, Loss: 430.7953796386719, Neurons: 11, Grad norm: 2.143e+02\n",
      "Epoch 15321, Loss: 430.79217529296875, Neurons: 11, Grad norm: 1.746e+02\n",
      "Epoch 15322, Loss: 430.78863525390625, Neurons: 11, Grad norm: 1.231e+02\n",
      "Epoch 15323, Loss: 430.78509521484375, Neurons: 11, Grad norm: 6.319e+01\n",
      "Epoch 15324, Loss: 430.7818908691406, Neurons: 11, Grad norm: 3.454e+00\n",
      "Epoch 15325, Loss: 430.7791748046875, Neurons: 11, Grad norm: 5.277e+01\n",
      "Epoch 15326, Loss: 430.7769775390625, Neurons: 11, Grad norm: 9.694e+01\n",
      "Epoch 15327, Loss: 430.77508544921875, Neurons: 11, Grad norm: 1.284e+02\n",
      "Epoch 15328, Loss: 430.77313232421875, Neurons: 11, Grad norm: 1.420e+02\n",
      "Epoch 15329, Loss: 430.77099609375, Neurons: 11, Grad norm: 1.402e+02\n",
      "Epoch 15330, Loss: 430.7685852050781, Neurons: 11, Grad norm: 1.222e+02\n",
      "Epoch 15331, Loss: 430.7657775878906, Neurons: 11, Grad norm: 9.245e+01\n",
      "Epoch 15332, Loss: 430.76300048828125, Neurons: 11, Grad norm: 5.405e+01\n",
      "Epoch 15333, Loss: 430.7601318359375, Neurons: 11, Grad norm: 1.335e+01\n",
      "Epoch 15334, Loss: 430.7575988769531, Neurons: 11, Grad norm: 2.543e+01\n",
      "Epoch 15335, Loss: 430.75518798828125, Neurons: 11, Grad norm: 5.631e+01\n",
      "Epoch 15336, Loss: 430.75299072265625, Neurons: 11, Grad norm: 7.924e+01\n",
      "Epoch 15337, Loss: 430.75079345703125, Neurons: 11, Grad norm: 8.987e+01\n",
      "Epoch 15338, Loss: 430.74847412109375, Neurons: 11, Grad norm: 9.035e+01\n",
      "Epoch 15339, Loss: 430.74609375, Neurons: 11, Grad norm: 7.840e+01\n",
      "Epoch 15340, Loss: 430.7435302734375, Neurons: 11, Grad norm: 5.894e+01\n",
      "Epoch 15341, Loss: 430.7409362792969, Neurons: 11, Grad norm: 3.402e+01\n",
      "Epoch 15342, Loss: 430.7384033203125, Neurons: 11, Grad norm: 8.154e+00\n",
      "Epoch 15343, Loss: 430.73590087890625, Neurons: 11, Grad norm: 1.619e+01\n",
      "Epoch 15344, Loss: 430.7335510253906, Neurons: 11, Grad norm: 3.466e+01\n",
      "Epoch 15345, Loss: 430.73114013671875, Neurons: 11, Grad norm: 4.847e+01\n",
      "Epoch 15346, Loss: 430.7288513183594, Neurons: 11, Grad norm: 5.456e+01\n",
      "Epoch 15347, Loss: 430.72650146484375, Neurons: 11, Grad norm: 5.513e+01\n",
      "Epoch 15348, Loss: 430.7240295410156, Neurons: 11, Grad norm: 4.857e+01\n",
      "Epoch 15349, Loss: 430.7215881347656, Neurons: 11, Grad norm: 3.833e+01\n",
      "Epoch 15349, Test loss: 427.3441467285156\n",
      "Epoch 15350, Loss: 430.7191467285156, Neurons: 11, Grad norm: 2.447e+01\n",
      "Epoch 15351, Loss: 430.7166748046875, Neurons: 11, Grad norm: 1.039e+01\n",
      "Epoch 15352, Loss: 430.7142028808594, Neurons: 11, Grad norm: 4.836e+00\n",
      "Epoch 15353, Loss: 430.7117919921875, Neurons: 11, Grad norm: 1.668e+01\n",
      "Epoch 15354, Loss: 430.7093811035156, Neurons: 11, Grad norm: 2.662e+01\n",
      "Epoch 15355, Loss: 430.7070007324219, Neurons: 11, Grad norm: 3.297e+01\n",
      "Epoch 15356, Loss: 430.70458984375, Neurons: 11, Grad norm: 3.626e+01\n",
      "Epoch 15357, Loss: 430.7021789550781, Neurons: 11, Grad norm: 3.515e+01\n",
      "Epoch 15358, Loss: 430.6997985839844, Neurons: 11, Grad norm: 3.211e+01\n",
      "Epoch 15359, Loss: 430.6973876953125, Neurons: 11, Grad norm: 2.433e+01\n",
      "Epoch 15360, Loss: 430.69488525390625, Neurons: 11, Grad norm: 1.614e+01\n",
      "Epoch 15361, Loss: 430.6924743652344, Neurons: 11, Grad norm: 6.291e+00\n",
      "Epoch 15362, Loss: 430.69000244140625, Neurons: 11, Grad norm: 3.402e+00\n",
      "Epoch 15363, Loss: 430.6875915527344, Neurons: 11, Grad norm: 1.156e+01\n",
      "Epoch 15364, Loss: 430.6851501464844, Neurons: 11, Grad norm: 1.756e+01\n",
      "Epoch 15365, Loss: 430.68280029296875, Neurons: 11, Grad norm: 2.206e+01\n",
      "Epoch 15366, Loss: 430.6803283691406, Neurons: 11, Grad norm: 2.305e+01\n",
      "Epoch 15367, Loss: 430.6778869628906, Neurons: 11, Grad norm: 2.309e+01\n",
      "Epoch 15368, Loss: 430.6754455566406, Neurons: 11, Grad norm: 1.965e+01\n",
      "Epoch 15369, Loss: 430.67303466796875, Neurons: 11, Grad norm: 1.601e+01\n",
      "Epoch 15370, Loss: 430.67059326171875, Neurons: 11, Grad norm: 1.055e+01\n",
      "Epoch 15371, Loss: 430.6680908203125, Neurons: 11, Grad norm: 5.459e+00\n",
      "Epoch 15372, Loss: 430.6656799316406, Neurons: 11, Grad norm: 1.477e+00\n",
      "Epoch 15373, Loss: 430.6632995605469, Neurons: 11, Grad norm: 5.010e+00\n",
      "Epoch 15374, Loss: 430.6607971191406, Neurons: 11, Grad norm: 9.182e+00\n",
      "Epoch 15375, Loss: 430.65838623046875, Neurons: 11, Grad norm: 1.151e+01\n",
      "Epoch 15376, Loss: 430.65594482421875, Neurons: 11, Grad norm: 1.380e+01\n",
      "Epoch 15377, Loss: 430.65350341796875, Neurons: 11, Grad norm: 1.386e+01\n",
      "Epoch 15378, Loss: 430.6510314941406, Neurons: 11, Grad norm: 1.496e+01\n",
      "Epoch 15379, Loss: 430.6486511230469, Neurons: 11, Grad norm: 1.438e+01\n",
      "Epoch 15380, Loss: 430.6461486816406, Neurons: 11, Grad norm: 1.305e+01\n",
      "Epoch 15381, Loss: 430.6436767578125, Neurons: 11, Grad norm: 1.079e+01\n",
      "Epoch 15382, Loss: 430.64129638671875, Neurons: 11, Grad norm: 8.325e+00\n",
      "Epoch 15383, Loss: 430.6387939453125, Neurons: 11, Grad norm: 4.859e+00\n",
      "Epoch 15384, Loss: 430.6363525390625, Neurons: 11, Grad norm: 3.588e+00\n",
      "Epoch 15385, Loss: 430.6338806152344, Neurons: 11, Grad norm: 1.441e+00\n",
      "Epoch 15386, Loss: 430.6314392089844, Neurons: 11, Grad norm: 2.946e+00\n",
      "Epoch 15387, Loss: 430.6289978027344, Neurons: 11, Grad norm: 5.083e+00\n",
      "Epoch 15388, Loss: 430.62652587890625, Neurons: 11, Grad norm: 6.741e+00\n",
      "Epoch 15389, Loss: 430.62408447265625, Neurons: 11, Grad norm: 8.225e+00\n",
      "Epoch 15390, Loss: 430.62158203125, Neurons: 11, Grad norm: 7.288e+00\n",
      "Epoch 15391, Loss: 430.61920166015625, Neurons: 11, Grad norm: 8.033e+00\n",
      "Epoch 15392, Loss: 430.61669921875, Neurons: 11, Grad norm: 7.840e+00\n",
      "Epoch 15393, Loss: 430.61419677734375, Neurons: 11, Grad norm: 8.734e+00\n",
      "Epoch 15394, Loss: 430.6117858886719, Neurons: 11, Grad norm: 9.089e+00\n",
      "Epoch 15395, Loss: 430.6092834472656, Neurons: 11, Grad norm: 9.020e+00\n",
      "Epoch 15396, Loss: 430.6067810058594, Neurons: 11, Grad norm: 8.349e+00\n",
      "Epoch 15397, Loss: 430.6044006347656, Neurons: 11, Grad norm: 9.318e+00\n",
      "Epoch 15398, Loss: 430.6018981933594, Neurons: 11, Grad norm: 8.016e+00\n",
      "Epoch 15399, Loss: 430.5993957519531, Neurons: 11, Grad norm: 8.023e+00\n",
      "Epoch 15399, Test loss: 427.23406982421875\n",
      "Epoch 15400, Loss: 430.5969543457031, Neurons: 11, Grad norm: 6.625e+00\n",
      "Epoch 15401, Loss: 430.594482421875, Neurons: 11, Grad norm: 5.694e+00\n",
      "Epoch 15402, Loss: 430.59197998046875, Neurons: 11, Grad norm: 5.454e+00\n",
      "Epoch 15403, Loss: 430.5894775390625, Neurons: 11, Grad norm: 4.755e+00\n",
      "Epoch 15404, Loss: 430.58697509765625, Neurons: 11, Grad norm: 3.662e+00\n",
      "Epoch 15405, Loss: 430.58453369140625, Neurons: 11, Grad norm: 4.798e+00\n",
      "Epoch 15406, Loss: 430.58209228515625, Neurons: 11, Grad norm: 3.416e+00\n",
      "Epoch 15407, Loss: 430.57958984375, Neurons: 11, Grad norm: 3.871e+00\n",
      "Epoch 15408, Loss: 430.57708740234375, Neurons: 11, Grad norm: 3.349e+00\n",
      "Epoch 15409, Loss: 430.5745849609375, Neurons: 11, Grad norm: 3.078e+00\n",
      "Epoch 15410, Loss: 430.57208251953125, Neurons: 11, Grad norm: 2.988e+00\n",
      "Epoch 15411, Loss: 430.56964111328125, Neurons: 11, Grad norm: 2.811e+00\n",
      "Epoch 15412, Loss: 430.567138671875, Neurons: 11, Grad norm: 3.160e+00\n",
      "Epoch 15413, Loss: 430.56463623046875, Neurons: 11, Grad norm: 4.879e+00\n",
      "Epoch 15414, Loss: 430.56219482421875, Neurons: 11, Grad norm: 4.383e+00\n",
      "Epoch 15415, Loss: 430.5596923828125, Neurons: 11, Grad norm: 5.961e+00\n",
      "Epoch 15416, Loss: 430.55718994140625, Neurons: 11, Grad norm: 5.716e+00\n",
      "Epoch 15417, Loss: 430.5546875, Neurons: 11, Grad norm: 6.290e+00\n",
      "Epoch 15418, Loss: 430.55218505859375, Neurons: 11, Grad norm: 6.544e+00\n",
      "Epoch 15419, Loss: 430.5496826171875, Neurons: 11, Grad norm: 6.528e+00\n",
      "Epoch 15420, Loss: 430.54718017578125, Neurons: 11, Grad norm: 6.452e+00\n",
      "Epoch 15421, Loss: 430.544677734375, Neurons: 11, Grad norm: 6.701e+00\n",
      "Epoch 15422, Loss: 430.54217529296875, Neurons: 11, Grad norm: 5.735e+00\n",
      "Epoch 15423, Loss: 430.5397033691406, Neurons: 11, Grad norm: 6.407e+00\n",
      "Epoch 15424, Loss: 430.5372009277344, Neurons: 11, Grad norm: 5.461e+00\n",
      "Epoch 15425, Loss: 430.5346984863281, Neurons: 11, Grad norm: 5.950e+00\n",
      "Epoch 15426, Loss: 430.5321960449219, Neurons: 11, Grad norm: 5.673e+00\n",
      "Epoch 15427, Loss: 430.5296325683594, Neurons: 11, Grad norm: 5.868e+00\n",
      "Epoch 15428, Loss: 430.5271911621094, Neurons: 11, Grad norm: 6.031e+00\n",
      "Epoch 15429, Loss: 430.52459716796875, Neurons: 11, Grad norm: 6.392e+00\n",
      "Epoch 15430, Loss: 430.5220947265625, Neurons: 11, Grad norm: 5.197e+00\n",
      "Epoch 15431, Loss: 430.51959228515625, Neurons: 11, Grad norm: 5.782e+00\n",
      "Epoch 15432, Loss: 430.51708984375, Neurons: 11, Grad norm: 6.066e+00\n",
      "Epoch 15433, Loss: 430.5145263671875, Neurons: 11, Grad norm: 6.990e+00\n",
      "Epoch 15434, Loss: 430.5120849609375, Neurons: 11, Grad norm: 7.452e+00\n",
      "Epoch 15435, Loss: 430.5094909667969, Neurons: 11, Grad norm: 8.773e+00\n",
      "Epoch 15436, Loss: 430.5070495605469, Neurons: 11, Grad norm: 9.209e+00\n",
      "Epoch 15437, Loss: 430.5044860839844, Neurons: 11, Grad norm: 1.210e+01\n",
      "Epoch 15438, Loss: 430.501953125, Neurons: 11, Grad norm: 1.449e+01\n",
      "Epoch 15439, Loss: 430.4994812011719, Neurons: 11, Grad norm: 1.863e+01\n",
      "Epoch 15440, Loss: 430.49688720703125, Neurons: 11, Grad norm: 2.307e+01\n",
      "Epoch 15441, Loss: 430.494384765625, Neurons: 11, Grad norm: 2.894e+01\n",
      "Epoch 15442, Loss: 430.49188232421875, Neurons: 11, Grad norm: 3.542e+01\n",
      "Epoch 15443, Loss: 430.4893798828125, Neurons: 11, Grad norm: 4.407e+01\n",
      "Epoch 15444, Loss: 430.4869384765625, Neurons: 11, Grad norm: 5.319e+01\n",
      "Epoch 15445, Loss: 430.4844970703125, Neurons: 11, Grad norm: 6.544e+01\n",
      "Epoch 15446, Loss: 430.4820251464844, Neurons: 11, Grad norm: 7.847e+01\n",
      "Epoch 15447, Loss: 430.4796447753906, Neurons: 11, Grad norm: 9.503e+01\n",
      "Epoch 15448, Loss: 430.477294921875, Neurons: 11, Grad norm: 1.135e+02\n",
      "Epoch 15449, Loss: 430.47509765625, Neurons: 11, Grad norm: 1.367e+02\n",
      "Epoch 15449, Test loss: 427.0893859863281\n",
      "Epoch 15450, Loss: 430.4729919433594, Neurons: 11, Grad norm: 1.636e+02\n",
      "Epoch 15451, Loss: 430.4710388183594, Neurons: 11, Grad norm: 1.942e+02\n",
      "Epoch 15452, Loss: 430.46929931640625, Neurons: 11, Grad norm: 2.260e+02\n",
      "Epoch 15453, Loss: 430.4678039550781, Neurons: 11, Grad norm: 2.588e+02\n",
      "Epoch 15454, Loss: 430.4664306640625, Neurons: 11, Grad norm: 2.856e+02\n",
      "Epoch 15455, Loss: 430.46502685546875, Neurons: 11, Grad norm: 3.014e+02\n",
      "Epoch 15456, Loss: 430.4632873535156, Neurons: 11, Grad norm: 2.964e+02\n",
      "Epoch 15457, Loss: 430.4606018066406, Neurons: 11, Grad norm: 2.676e+02\n",
      "Epoch 15458, Loss: 430.4569396972656, Neurons: 11, Grad norm: 2.115e+02\n",
      "Epoch 15459, Loss: 430.45257568359375, Neurons: 11, Grad norm: 1.345e+02\n",
      "Epoch 15460, Loss: 430.4482421875, Neurons: 11, Grad norm: 4.578e+01\n",
      "Epoch 15461, Loss: 430.4447021484375, Neurons: 11, Grad norm: 4.045e+01\n",
      "Epoch 15462, Loss: 430.4422302246094, Neurons: 11, Grad norm: 1.129e+02\n",
      "Epoch 15463, Loss: 430.4406433105469, Neurons: 11, Grad norm: 1.612e+02\n",
      "Epoch 15464, Loss: 430.4392395019531, Neurons: 11, Grad norm: 1.824e+02\n",
      "Epoch 15465, Loss: 430.4373474121094, Neurons: 11, Grad norm: 1.726e+02\n",
      "Epoch 15466, Loss: 430.43475341796875, Neurons: 11, Grad norm: 1.383e+02\n",
      "Epoch 15467, Loss: 430.43157958984375, Neurons: 11, Grad norm: 8.317e+01\n",
      "Epoch 15468, Loss: 430.42828369140625, Neurons: 11, Grad norm: 2.041e+01\n",
      "Epoch 15469, Loss: 430.42547607421875, Neurons: 11, Grad norm: 4.009e+01\n",
      "Epoch 15470, Loss: 430.4231872558594, Neurons: 11, Grad norm: 8.848e+01\n",
      "Epoch 15471, Loss: 430.4212951660156, Neurons: 11, Grad norm: 1.180e+02\n",
      "Epoch 15472, Loss: 430.4192810058594, Neurons: 11, Grad norm: 1.237e+02\n",
      "Epoch 15473, Loss: 430.4170837402344, Neurons: 11, Grad norm: 1.088e+02\n",
      "Epoch 15474, Loss: 430.4143981933594, Neurons: 11, Grad norm: 7.510e+01\n",
      "Epoch 15475, Loss: 430.4115905761719, Neurons: 11, Grad norm: 3.333e+01\n",
      "Epoch 15476, Loss: 430.40887451171875, Neurons: 11, Grad norm: 1.145e+01\n",
      "Epoch 15477, Loss: 430.40643310546875, Neurons: 11, Grad norm: 4.915e+01\n",
      "Epoch 15478, Loss: 430.404296875, Neurons: 11, Grad norm: 7.427e+01\n",
      "Epoch 15479, Loss: 430.402099609375, Neurons: 11, Grad norm: 8.431e+01\n",
      "Epoch 15480, Loss: 430.39990234375, Neurons: 11, Grad norm: 7.972e+01\n",
      "Epoch 15481, Loss: 430.39739990234375, Neurons: 11, Grad norm: 6.005e+01\n",
      "Epoch 15482, Loss: 430.3948974609375, Neurons: 11, Grad norm: 3.356e+01\n",
      "Epoch 15483, Loss: 430.3923034667969, Neurons: 11, Grad norm: 3.297e+00\n",
      "Epoch 15484, Loss: 430.3898010253906, Neurons: 11, Grad norm: 2.461e+01\n",
      "Epoch 15485, Loss: 430.3874816894531, Neurons: 11, Grad norm: 4.641e+01\n",
      "Epoch 15486, Loss: 430.38519287109375, Neurons: 11, Grad norm: 5.773e+01\n",
      "Epoch 15487, Loss: 430.38299560546875, Neurons: 11, Grad norm: 5.882e+01\n",
      "Epoch 15488, Loss: 430.3805847167969, Neurons: 11, Grad norm: 4.929e+01\n",
      "Epoch 15489, Loss: 430.3780822753906, Neurons: 11, Grad norm: 3.250e+01\n",
      "Epoch 15490, Loss: 430.3755798339844, Neurons: 11, Grad norm: 1.106e+01\n",
      "Epoch 15491, Loss: 430.3731994628906, Neurons: 11, Grad norm: 9.322e+00\n",
      "Epoch 15492, Loss: 430.37078857421875, Neurons: 11, Grad norm: 2.702e+01\n",
      "Epoch 15493, Loss: 430.3684387207031, Neurons: 11, Grad norm: 3.744e+01\n",
      "Epoch 15494, Loss: 430.3660888671875, Neurons: 11, Grad norm: 4.245e+01\n",
      "Epoch 15495, Loss: 430.3637390136719, Neurons: 11, Grad norm: 3.854e+01\n",
      "Epoch 15496, Loss: 430.36138916015625, Neurons: 11, Grad norm: 2.930e+01\n",
      "Epoch 15497, Loss: 430.35888671875, Neurons: 11, Grad norm: 1.704e+01\n",
      "Epoch 15498, Loss: 430.3564758300781, Neurons: 11, Grad norm: 3.789e+00\n",
      "Epoch 15499, Loss: 430.3540344238281, Neurons: 11, Grad norm: 1.034e+01\n",
      "Epoch 15499, Test loss: 427.0000915527344\n",
      "Epoch 15500, Loss: 430.3516845703125, Neurons: 11, Grad norm: 2.081e+01\n",
      "Epoch 15501, Loss: 430.34930419921875, Neurons: 11, Grad norm: 2.895e+01\n",
      "Epoch 15502, Loss: 430.3469543457031, Neurons: 11, Grad norm: 3.081e+01\n",
      "Epoch 15503, Loss: 430.3445739746094, Neurons: 11, Grad norm: 2.968e+01\n",
      "Epoch 15504, Loss: 430.3421936035156, Neurons: 11, Grad norm: 2.366e+01\n",
      "Epoch 15505, Loss: 430.3397521972656, Neurons: 11, Grad norm: 1.588e+01\n",
      "Epoch 15506, Loss: 430.3372802734375, Neurons: 11, Grad norm: 6.884e+00\n",
      "Epoch 15507, Loss: 430.33489990234375, Neurons: 11, Grad norm: 2.151e+00\n",
      "Epoch 15508, Loss: 430.3324890136719, Neurons: 11, Grad norm: 9.849e+00\n",
      "Epoch 15509, Loss: 430.330078125, Neurons: 11, Grad norm: 1.481e+01\n",
      "Epoch 15510, Loss: 430.32769775390625, Neurons: 11, Grad norm: 1.824e+01\n",
      "Epoch 15511, Loss: 430.3252868652344, Neurons: 11, Grad norm: 1.883e+01\n",
      "Epoch 15512, Loss: 430.3228759765625, Neurons: 11, Grad norm: 1.803e+01\n",
      "Epoch 15513, Loss: 430.32049560546875, Neurons: 11, Grad norm: 1.339e+01\n",
      "Epoch 15514, Loss: 430.3180847167969, Neurons: 11, Grad norm: 8.583e+00\n",
      "Epoch 15515, Loss: 430.3157043457031, Neurons: 11, Grad norm: 2.469e+00\n",
      "Epoch 15516, Loss: 430.313232421875, Neurons: 11, Grad norm: 3.601e+00\n",
      "Epoch 15517, Loss: 430.31085205078125, Neurons: 11, Grad norm: 8.163e+00\n",
      "Epoch 15518, Loss: 430.3083801269531, Neurons: 11, Grad norm: 1.186e+01\n",
      "Epoch 15519, Loss: 430.3059997558594, Neurons: 11, Grad norm: 1.462e+01\n",
      "Epoch 15520, Loss: 430.3035888671875, Neurons: 11, Grad norm: 1.392e+01\n",
      "Epoch 15521, Loss: 430.3011779785156, Neurons: 11, Grad norm: 1.303e+01\n",
      "Epoch 15522, Loss: 430.2987976074219, Neurons: 11, Grad norm: 9.437e+00\n",
      "Epoch 15523, Loss: 430.2962951660156, Neurons: 11, Grad norm: 6.036e+00\n",
      "Epoch 15524, Loss: 430.2939453125, Neurons: 11, Grad norm: 2.053e+00\n",
      "Epoch 15525, Loss: 430.29150390625, Neurons: 11, Grad norm: 2.682e+00\n",
      "Epoch 15526, Loss: 430.2890319824219, Neurons: 11, Grad norm: 5.936e+00\n",
      "Epoch 15527, Loss: 430.2866516113281, Neurons: 11, Grad norm: 7.911e+00\n",
      "Epoch 15528, Loss: 430.28424072265625, Neurons: 11, Grad norm: 9.544e+00\n",
      "Epoch 15529, Loss: 430.28179931640625, Neurons: 11, Grad norm: 8.942e+00\n",
      "Epoch 15530, Loss: 430.2793273925781, Neurons: 11, Grad norm: 8.602e+00\n",
      "Epoch 15531, Loss: 430.2768859863281, Neurons: 11, Grad norm: 6.379e+00\n",
      "Epoch 15532, Loss: 430.27447509765625, Neurons: 11, Grad norm: 5.699e+00\n",
      "Epoch 15533, Loss: 430.27203369140625, Neurons: 11, Grad norm: 4.127e+00\n",
      "Epoch 15534, Loss: 430.26959228515625, Neurons: 11, Grad norm: 2.384e+00\n",
      "Epoch 15535, Loss: 430.2671813964844, Neurons: 11, Grad norm: 1.449e+00\n",
      "Epoch 15536, Loss: 430.2647399902344, Neurons: 11, Grad norm: 2.344e+00\n",
      "Epoch 15537, Loss: 430.2622985839844, Neurons: 11, Grad norm: 5.483e+00\n",
      "Epoch 15538, Loss: 430.25982666015625, Neurons: 11, Grad norm: 7.247e+00\n",
      "Epoch 15539, Loss: 430.25738525390625, Neurons: 11, Grad norm: 9.056e+00\n",
      "Epoch 15540, Loss: 430.2549743652344, Neurons: 11, Grad norm: 9.180e+00\n",
      "Epoch 15541, Loss: 430.25250244140625, Neurons: 11, Grad norm: 1.039e+01\n",
      "Epoch 15542, Loss: 430.2500915527344, Neurons: 11, Grad norm: 1.033e+01\n",
      "Epoch 15543, Loss: 430.2476501464844, Neurons: 11, Grad norm: 1.060e+01\n",
      "Epoch 15544, Loss: 430.24517822265625, Neurons: 11, Grad norm: 1.001e+01\n",
      "Epoch 15545, Loss: 430.24273681640625, Neurons: 11, Grad norm: 9.843e+00\n",
      "Epoch 15546, Loss: 430.24029541015625, Neurons: 11, Grad norm: 8.758e+00\n",
      "Epoch 15547, Loss: 430.2378845214844, Neurons: 11, Grad norm: 7.539e+00\n",
      "Epoch 15548, Loss: 430.2353515625, Neurons: 11, Grad norm: 4.033e+00\n",
      "Epoch 15549, Loss: 430.2328796386719, Neurons: 11, Grad norm: 2.565e+00\n",
      "Epoch 15549, Test loss: 426.8864440917969\n",
      "Epoch 15550, Loss: 430.2304382324219, Neurons: 11, Grad norm: 1.456e+00\n",
      "Epoch 15551, Loss: 430.2279968261719, Neurons: 11, Grad norm: 2.049e+00\n",
      "Epoch 15552, Loss: 430.22552490234375, Neurons: 11, Grad norm: 4.328e+00\n",
      "Epoch 15553, Loss: 430.22308349609375, Neurons: 11, Grad norm: 5.202e+00\n",
      "Epoch 15554, Loss: 430.2205810546875, Neurons: 11, Grad norm: 6.587e+00\n",
      "Epoch 15555, Loss: 430.2181396484375, Neurons: 11, Grad norm: 7.830e+00\n",
      "Epoch 15556, Loss: 430.2156982421875, Neurons: 11, Grad norm: 9.628e+00\n",
      "Epoch 15557, Loss: 430.21319580078125, Neurons: 11, Grad norm: 1.060e+01\n",
      "Epoch 15558, Loss: 430.2107849121094, Neurons: 11, Grad norm: 1.249e+01\n",
      "Epoch 15559, Loss: 430.2082824707031, Neurons: 11, Grad norm: 1.189e+01\n",
      "Epoch 15560, Loss: 430.2057800292969, Neurons: 11, Grad norm: 1.196e+01\n",
      "Epoch 15561, Loss: 430.2033996582031, Neurons: 11, Grad norm: 1.160e+01\n",
      "Epoch 15562, Loss: 430.2008972167969, Neurons: 11, Grad norm: 1.145e+01\n",
      "Epoch 15563, Loss: 430.1983947753906, Neurons: 11, Grad norm: 9.867e+00\n",
      "Epoch 15564, Loss: 430.1958923339844, Neurons: 11, Grad norm: 8.766e+00\n",
      "Epoch 15565, Loss: 430.1934814453125, Neurons: 11, Grad norm: 6.449e+00\n",
      "Epoch 15566, Loss: 430.19097900390625, Neurons: 11, Grad norm: 4.907e+00\n",
      "Epoch 15567, Loss: 430.1884765625, Neurons: 11, Grad norm: 3.504e+00\n",
      "Epoch 15568, Loss: 430.18597412109375, Neurons: 11, Grad norm: 3.249e+00\n",
      "Epoch 15569, Loss: 430.1835021972656, Neurons: 11, Grad norm: 1.835e+00\n",
      "Epoch 15570, Loss: 430.1810302734375, Neurons: 11, Grad norm: 1.586e+00\n",
      "Epoch 15571, Loss: 430.17852783203125, Neurons: 11, Grad norm: 1.594e+00\n",
      "Epoch 15572, Loss: 430.17608642578125, Neurons: 11, Grad norm: 1.916e+00\n",
      "Epoch 15573, Loss: 430.173583984375, Neurons: 11, Grad norm: 2.646e+00\n",
      "Epoch 15574, Loss: 430.17108154296875, Neurons: 11, Grad norm: 3.034e+00\n",
      "Epoch 15575, Loss: 430.1685791015625, Neurons: 11, Grad norm: 3.903e+00\n",
      "Epoch 15576, Loss: 430.16607666015625, Neurons: 11, Grad norm: 3.814e+00\n",
      "Epoch 15577, Loss: 430.16357421875, Neurons: 11, Grad norm: 4.557e+00\n",
      "Epoch 15578, Loss: 430.1611328125, Neurons: 11, Grad norm: 4.024e+00\n",
      "Epoch 15579, Loss: 430.15863037109375, Neurons: 11, Grad norm: 4.421e+00\n",
      "Epoch 15580, Loss: 430.1561279296875, Neurons: 11, Grad norm: 3.956e+00\n",
      "Epoch 15581, Loss: 430.15362548828125, Neurons: 11, Grad norm: 4.136e+00\n",
      "Epoch 15582, Loss: 430.1510925292969, Neurons: 11, Grad norm: 3.867e+00\n",
      "Epoch 15583, Loss: 430.1486511230469, Neurons: 11, Grad norm: 5.175e+00\n",
      "Epoch 15584, Loss: 430.14617919921875, Neurons: 11, Grad norm: 6.039e+00\n",
      "Epoch 15585, Loss: 430.1436462402344, Neurons: 11, Grad norm: 8.159e+00\n",
      "Epoch 15586, Loss: 430.1410827636719, Neurons: 11, Grad norm: 9.789e+00\n",
      "Epoch 15587, Loss: 430.1386413574219, Neurons: 11, Grad norm: 1.150e+01\n",
      "Epoch 15588, Loss: 430.1360778808594, Neurons: 11, Grad norm: 1.230e+01\n",
      "Epoch 15589, Loss: 430.1335754394531, Neurons: 11, Grad norm: 1.387e+01\n",
      "Epoch 15590, Loss: 430.131103515625, Neurons: 11, Grad norm: 1.405e+01\n",
      "Epoch 15591, Loss: 430.12860107421875, Neurons: 11, Grad norm: 1.646e+01\n",
      "Epoch 15592, Loss: 430.12603759765625, Neurons: 11, Grad norm: 1.806e+01\n",
      "Epoch 15593, Loss: 430.12359619140625, Neurons: 11, Grad norm: 2.081e+01\n",
      "Epoch 15594, Loss: 430.12109375, Neurons: 11, Grad norm: 2.362e+01\n",
      "Epoch 15595, Loss: 430.1185302734375, Neurons: 11, Grad norm: 2.685e+01\n",
      "Epoch 15596, Loss: 430.11602783203125, Neurons: 11, Grad norm: 2.996e+01\n",
      "Epoch 15597, Loss: 430.1134948730469, Neurons: 11, Grad norm: 3.425e+01\n",
      "Epoch 15598, Loss: 430.1109924316406, Neurons: 11, Grad norm: 3.767e+01\n",
      "Epoch 15599, Loss: 430.1085510253906, Neurons: 11, Grad norm: 4.292e+01\n",
      "Epoch 15599, Test loss: 426.75982666015625\n",
      "Epoch 15600, Loss: 430.1059875488281, Neurons: 11, Grad norm: 4.729e+01\n",
      "Epoch 15601, Loss: 430.1035461425781, Neurons: 11, Grad norm: 5.326e+01\n",
      "Epoch 15602, Loss: 430.1009826660156, Neurons: 11, Grad norm: 5.899e+01\n",
      "Epoch 15603, Loss: 430.0986022949219, Neurons: 11, Grad norm: 6.571e+01\n",
      "Epoch 15604, Loss: 430.09613037109375, Neurons: 11, Grad norm: 7.254e+01\n",
      "Epoch 15605, Loss: 430.09368896484375, Neurons: 11, Grad norm: 8.033e+01\n",
      "Epoch 15606, Loss: 430.0911865234375, Neurons: 11, Grad norm: 8.794e+01\n",
      "Epoch 15607, Loss: 430.0887756347656, Neurons: 11, Grad norm: 9.825e+01\n",
      "Epoch 15608, Loss: 430.0863952636719, Neurons: 11, Grad norm: 1.080e+02\n",
      "Epoch 15609, Loss: 430.08404541015625, Neurons: 11, Grad norm: 1.194e+02\n",
      "Epoch 15610, Loss: 430.0816345214844, Neurons: 11, Grad norm: 1.303e+02\n",
      "Epoch 15611, Loss: 430.079345703125, Neurons: 11, Grad norm: 1.414e+02\n",
      "Epoch 15612, Loss: 430.0770263671875, Neurons: 11, Grad norm: 1.522e+02\n",
      "Epoch 15613, Loss: 430.0747985839844, Neurons: 11, Grad norm: 1.619e+02\n",
      "Epoch 15614, Loss: 430.0724792480469, Neurons: 11, Grad norm: 1.682e+02\n",
      "Epoch 15615, Loss: 430.0701904296875, Neurons: 11, Grad norm: 1.719e+02\n",
      "Epoch 15616, Loss: 430.0677490234375, Neurons: 11, Grad norm: 1.693e+02\n",
      "Epoch 15617, Loss: 430.065185546875, Neurons: 11, Grad norm: 1.632e+02\n",
      "Epoch 15618, Loss: 430.0625305175781, Neurons: 11, Grad norm: 1.491e+02\n",
      "Epoch 15619, Loss: 430.05975341796875, Neurons: 11, Grad norm: 1.298e+02\n",
      "Epoch 15620, Loss: 430.056884765625, Neurons: 11, Grad norm: 1.055e+02\n",
      "Epoch 15621, Loss: 430.0539855957031, Neurons: 11, Grad norm: 7.681e+01\n",
      "Epoch 15622, Loss: 430.0511474609375, Neurons: 11, Grad norm: 4.679e+01\n",
      "Epoch 15623, Loss: 430.04840087890625, Neurons: 11, Grad norm: 1.742e+01\n",
      "Epoch 15624, Loss: 430.0457763671875, Neurons: 11, Grad norm: 1.229e+01\n",
      "Epoch 15625, Loss: 430.04327392578125, Neurons: 11, Grad norm: 3.579e+01\n",
      "Epoch 15626, Loss: 430.0408935546875, Neurons: 11, Grad norm: 5.648e+01\n",
      "Epoch 15627, Loss: 430.0385437011719, Neurons: 11, Grad norm: 7.023e+01\n",
      "Epoch 15628, Loss: 430.03619384765625, Neurons: 11, Grad norm: 7.940e+01\n",
      "Epoch 15629, Loss: 430.03387451171875, Neurons: 11, Grad norm: 8.411e+01\n",
      "Epoch 15630, Loss: 430.03143310546875, Neurons: 11, Grad norm: 8.355e+01\n",
      "Epoch 15631, Loss: 430.0289001464844, Neurons: 11, Grad norm: 7.876e+01\n",
      "Epoch 15632, Loss: 430.02642822265625, Neurons: 11, Grad norm: 7.098e+01\n",
      "Epoch 15633, Loss: 430.0238342285156, Neurons: 11, Grad norm: 5.777e+01\n",
      "Epoch 15634, Loss: 430.021240234375, Neurons: 11, Grad norm: 4.453e+01\n",
      "Epoch 15635, Loss: 430.0186462402344, Neurons: 11, Grad norm: 2.862e+01\n",
      "Epoch 15636, Loss: 430.0160827636719, Neurons: 11, Grad norm: 1.405e+01\n",
      "Epoch 15637, Loss: 430.0135803222656, Neurons: 11, Grad norm: 1.480e+00\n",
      "Epoch 15638, Loss: 430.01104736328125, Neurons: 11, Grad norm: 1.261e+01\n",
      "Epoch 15639, Loss: 430.0086364746094, Neurons: 11, Grad norm: 2.314e+01\n",
      "Epoch 15640, Loss: 430.0061340332031, Neurons: 11, Grad norm: 3.077e+01\n",
      "Epoch 15641, Loss: 430.0036926269531, Neurons: 11, Grad norm: 3.802e+01\n",
      "Epoch 15642, Loss: 430.00128173828125, Neurons: 11, Grad norm: 4.107e+01\n",
      "Epoch 15643, Loss: 429.998779296875, Neurons: 11, Grad norm: 4.372e+01\n",
      "Epoch 15644, Loss: 429.996337890625, Neurons: 11, Grad norm: 4.330e+01\n",
      "Epoch 15645, Loss: 429.99383544921875, Neurons: 11, Grad norm: 4.162e+01\n",
      "Epoch 15646, Loss: 429.9913330078125, Neurons: 11, Grad norm: 3.837e+01\n",
      "Epoch 15647, Loss: 429.98883056640625, Neurons: 11, Grad norm: 3.416e+01\n",
      "Epoch 15648, Loss: 429.9862976074219, Neurons: 11, Grad norm: 2.893e+01\n",
      "Epoch 15649, Loss: 429.9837951660156, Neurons: 11, Grad norm: 2.426e+01\n",
      "Epoch 15649, Test loss: 426.64508056640625\n",
      "Epoch 15650, Loss: 429.9812927246094, Neurons: 11, Grad norm: 1.714e+01\n",
      "Epoch 15651, Loss: 429.9787902832031, Neurons: 11, Grad norm: 1.176e+01\n",
      "Epoch 15652, Loss: 429.9762878417969, Neurons: 11, Grad norm: 6.272e+00\n",
      "Epoch 15653, Loss: 429.9737854003906, Neurons: 11, Grad norm: 2.481e+00\n",
      "Epoch 15654, Loss: 429.9712829589844, Neurons: 11, Grad norm: 2.105e+00\n",
      "Epoch 15655, Loss: 429.96875, Neurons: 11, Grad norm: 4.964e+00\n",
      "Epoch 15656, Loss: 429.9662780761719, Neurons: 11, Grad norm: 9.070e+00\n",
      "Epoch 15657, Loss: 429.9637451171875, Neurons: 11, Grad norm: 1.097e+01\n",
      "Epoch 15658, Loss: 429.9613037109375, Neurons: 11, Grad norm: 1.370e+01\n",
      "Epoch 15659, Loss: 429.958740234375, Neurons: 11, Grad norm: 1.462e+01\n",
      "Epoch 15660, Loss: 429.956298828125, Neurons: 11, Grad norm: 1.562e+01\n",
      "Epoch 15661, Loss: 429.9537353515625, Neurons: 11, Grad norm: 1.564e+01\n",
      "Epoch 15662, Loss: 429.95123291015625, Neurons: 11, Grad norm: 1.559e+01\n",
      "Epoch 15663, Loss: 429.94873046875, Neurons: 11, Grad norm: 1.458e+01\n",
      "Epoch 15664, Loss: 429.94622802734375, Neurons: 11, Grad norm: 1.426e+01\n",
      "Epoch 15665, Loss: 429.9436950683594, Neurons: 11, Grad norm: 1.369e+01\n",
      "Epoch 15666, Loss: 429.9411926269531, Neurons: 11, Grad norm: 1.450e+01\n",
      "Epoch 15667, Loss: 429.9386901855469, Neurons: 11, Grad norm: 1.327e+01\n",
      "Epoch 15668, Loss: 429.9361877441406, Neurons: 11, Grad norm: 1.320e+01\n",
      "Epoch 15669, Loss: 429.93359375, Neurons: 11, Grad norm: 1.197e+01\n",
      "Epoch 15670, Loss: 429.93109130859375, Neurons: 11, Grad norm: 1.095e+01\n",
      "Epoch 15671, Loss: 429.9285888671875, Neurons: 11, Grad norm: 9.752e+00\n",
      "Epoch 15672, Loss: 429.92608642578125, Neurons: 11, Grad norm: 8.704e+00\n",
      "Epoch 15673, Loss: 429.9235534667969, Neurons: 11, Grad norm: 7.186e+00\n",
      "Epoch 15674, Loss: 429.9209899902344, Neurons: 11, Grad norm: 6.724e+00\n",
      "Epoch 15675, Loss: 429.9184265136719, Neurons: 11, Grad norm: 5.240e+00\n",
      "Epoch 15676, Loss: 429.9159851074219, Neurons: 11, Grad norm: 6.312e+00\n",
      "Epoch 15677, Loss: 429.91339111328125, Neurons: 11, Grad norm: 6.737e+00\n",
      "Epoch 15678, Loss: 429.910888671875, Neurons: 11, Grad norm: 7.451e+00\n",
      "Epoch 15679, Loss: 429.90838623046875, Neurons: 11, Grad norm: 7.992e+00\n",
      "Epoch 15680, Loss: 429.9058532714844, Neurons: 11, Grad norm: 8.701e+00\n",
      "Epoch 15681, Loss: 429.9032897949219, Neurons: 11, Grad norm: 8.911e+00\n",
      "Epoch 15682, Loss: 429.9007873535156, Neurons: 11, Grad norm: 1.112e+01\n",
      "Epoch 15683, Loss: 429.898193359375, Neurons: 11, Grad norm: 1.236e+01\n",
      "Epoch 15684, Loss: 429.89569091796875, Neurons: 11, Grad norm: 1.560e+01\n",
      "Epoch 15685, Loss: 429.89312744140625, Neurons: 11, Grad norm: 1.850e+01\n",
      "Epoch 15686, Loss: 429.8905944824219, Neurons: 11, Grad norm: 2.146e+01\n",
      "Epoch 15687, Loss: 429.8880920410156, Neurons: 11, Grad norm: 2.434e+01\n",
      "Epoch 15688, Loss: 429.885498046875, Neurons: 11, Grad norm: 2.908e+01\n",
      "Epoch 15689, Loss: 429.88299560546875, Neurons: 11, Grad norm: 3.343e+01\n",
      "Epoch 15690, Loss: 429.8804931640625, Neurons: 11, Grad norm: 3.986e+01\n",
      "Epoch 15691, Loss: 429.87799072265625, Neurons: 11, Grad norm: 4.622e+01\n",
      "Epoch 15692, Loss: 429.87548828125, Neurons: 11, Grad norm: 5.444e+01\n",
      "Epoch 15693, Loss: 429.87298583984375, Neurons: 11, Grad norm: 6.296e+01\n",
      "Epoch 15694, Loss: 429.8704833984375, Neurons: 11, Grad norm: 7.319e+01\n",
      "Epoch 15695, Loss: 429.8680419921875, Neurons: 11, Grad norm: 8.415e+01\n",
      "Epoch 15696, Loss: 429.8656005859375, Neurons: 11, Grad norm: 9.847e+01\n",
      "Epoch 15697, Loss: 429.8631896972656, Neurons: 11, Grad norm: 1.134e+02\n",
      "Epoch 15698, Loss: 429.86090087890625, Neurons: 11, Grad norm: 1.297e+02\n",
      "Epoch 15699, Loss: 429.85870361328125, Neurons: 11, Grad norm: 1.475e+02\n",
      "Epoch 15699, Test loss: 426.56256103515625\n",
      "Epoch 15700, Loss: 429.8565368652344, Neurons: 11, Grad norm: 1.676e+02\n",
      "Epoch 15701, Loss: 429.8544006347656, Neurons: 11, Grad norm: 1.866e+02\n",
      "Epoch 15702, Loss: 429.8523864746094, Neurons: 11, Grad norm: 2.063e+02\n",
      "Epoch 15703, Loss: 429.85040283203125, Neurons: 11, Grad norm: 2.209e+02\n",
      "Epoch 15704, Loss: 429.848388671875, Neurons: 11, Grad norm: 2.294e+02\n",
      "Epoch 15705, Loss: 429.8460998535156, Neurons: 11, Grad norm: 2.283e+02\n",
      "Epoch 15706, Loss: 429.8435974121094, Neurons: 11, Grad norm: 2.146e+02\n",
      "Epoch 15707, Loss: 429.8406982421875, Neurons: 11, Grad norm: 1.857e+02\n",
      "Epoch 15708, Loss: 429.83740234375, Neurons: 11, Grad norm: 1.456e+02\n",
      "Epoch 15709, Loss: 429.8338928222656, Neurons: 11, Grad norm: 9.438e+01\n",
      "Epoch 15710, Loss: 429.8305358886719, Neurons: 11, Grad norm: 4.045e+01\n",
      "Epoch 15711, Loss: 429.8275451660156, Neurons: 11, Grad norm: 1.216e+01\n",
      "Epoch 15712, Loss: 429.8249816894531, Neurons: 11, Grad norm: 5.854e+01\n",
      "Epoch 15713, Loss: 429.82275390625, Neurons: 11, Grad norm: 9.515e+01\n",
      "Epoch 15714, Loss: 429.8206787109375, Neurons: 11, Grad norm: 1.178e+02\n",
      "Epoch 15715, Loss: 429.818603515625, Neurons: 11, Grad norm: 1.283e+02\n",
      "Epoch 15716, Loss: 429.81634521484375, Neurons: 11, Grad norm: 1.232e+02\n",
      "Epoch 15717, Loss: 429.81378173828125, Neurons: 11, Grad norm: 1.079e+02\n",
      "Epoch 15718, Loss: 429.81109619140625, Neurons: 11, Grad norm: 8.229e+01\n",
      "Epoch 15719, Loss: 429.80828857421875, Neurons: 11, Grad norm: 5.035e+01\n",
      "Epoch 15720, Loss: 429.80548095703125, Neurons: 11, Grad norm: 1.580e+01\n",
      "Epoch 15721, Loss: 429.8028869628906, Neurons: 11, Grad norm: 1.720e+01\n",
      "Epoch 15722, Loss: 429.8003845214844, Neurons: 11, Grad norm: 4.534e+01\n",
      "Epoch 15723, Loss: 429.798095703125, Neurons: 11, Grad norm: 6.424e+01\n",
      "Epoch 15724, Loss: 429.7957763671875, Neurons: 11, Grad norm: 7.656e+01\n",
      "Epoch 15725, Loss: 429.7934875488281, Neurons: 11, Grad norm: 7.873e+01\n",
      "Epoch 15726, Loss: 429.7909851074219, Neurons: 11, Grad norm: 7.380e+01\n",
      "Epoch 15727, Loss: 429.7884826660156, Neurons: 11, Grad norm: 6.162e+01\n",
      "Epoch 15728, Loss: 429.78594970703125, Neurons: 11, Grad norm: 4.500e+01\n",
      "Epoch 15729, Loss: 429.78338623046875, Neurons: 11, Grad norm: 2.489e+01\n",
      "Epoch 15730, Loss: 429.7807922363281, Neurons: 11, Grad norm: 5.465e+00\n",
      "Epoch 15731, Loss: 429.7782287597656, Neurons: 11, Grad norm: 1.312e+01\n",
      "Epoch 15732, Loss: 429.7757873535156, Neurons: 11, Grad norm: 2.777e+01\n",
      "Epoch 15733, Loss: 429.77337646484375, Neurons: 11, Grad norm: 3.978e+01\n",
      "Epoch 15734, Loss: 429.77099609375, Neurons: 11, Grad norm: 4.571e+01\n",
      "Epoch 15735, Loss: 429.7685852050781, Neurons: 11, Grad norm: 4.794e+01\n",
      "Epoch 15736, Loss: 429.7661437988281, Neurons: 11, Grad norm: 4.468e+01\n",
      "Epoch 15737, Loss: 429.7636413574219, Neurons: 11, Grad norm: 3.830e+01\n",
      "Epoch 15738, Loss: 429.7610778808594, Neurons: 11, Grad norm: 2.874e+01\n",
      "Epoch 15739, Loss: 429.7586975097656, Neurons: 11, Grad norm: 1.845e+01\n",
      "Epoch 15740, Loss: 429.756103515625, Neurons: 11, Grad norm: 7.426e+00\n",
      "Epoch 15741, Loss: 429.7536315917969, Neurons: 11, Grad norm: 3.526e+00\n",
      "Epoch 15742, Loss: 429.7511291503906, Neurons: 11, Grad norm: 1.428e+01\n",
      "Epoch 15743, Loss: 429.7486877441406, Neurons: 11, Grad norm: 2.106e+01\n",
      "Epoch 15744, Loss: 429.7461853027344, Neurons: 11, Grad norm: 2.665e+01\n",
      "Epoch 15745, Loss: 429.7437438964844, Neurons: 11, Grad norm: 2.959e+01\n",
      "Epoch 15746, Loss: 429.7413024902344, Neurons: 11, Grad norm: 3.030e+01\n",
      "Epoch 15747, Loss: 429.73883056640625, Neurons: 11, Grad norm: 2.868e+01\n",
      "Epoch 15748, Loss: 429.73638916015625, Neurons: 11, Grad norm: 2.577e+01\n",
      "Epoch 15749, Loss: 429.7337951660156, Neurons: 11, Grad norm: 2.071e+01\n",
      "Epoch 15749, Test loss: 426.4170227050781\n",
      "Epoch 15750, Loss: 429.73138427734375, Neurons: 11, Grad norm: 1.610e+01\n",
      "Epoch 15751, Loss: 429.7288513183594, Neurons: 11, Grad norm: 8.968e+00\n",
      "Epoch 15752, Loss: 429.72637939453125, Neurons: 11, Grad norm: 3.230e+00\n",
      "Epoch 15753, Loss: 429.7238464355469, Neurons: 11, Grad norm: 3.737e+00\n",
      "Epoch 15754, Loss: 429.72137451171875, Neurons: 11, Grad norm: 8.703e+00\n",
      "Epoch 15755, Loss: 429.7189025878906, Neurons: 11, Grad norm: 1.275e+01\n",
      "Epoch 15756, Loss: 429.7164001464844, Neurons: 11, Grad norm: 1.510e+01\n",
      "Epoch 15757, Loss: 429.7138977050781, Neurons: 11, Grad norm: 1.685e+01\n",
      "Epoch 15758, Loss: 429.7113952636719, Neurons: 11, Grad norm: 1.728e+01\n",
      "Epoch 15759, Loss: 429.7089538574219, Neurons: 11, Grad norm: 1.812e+01\n",
      "Epoch 15760, Loss: 429.70648193359375, Neurons: 11, Grad norm: 1.578e+01\n",
      "Epoch 15761, Loss: 429.7039489746094, Neurons: 11, Grad norm: 1.412e+01\n",
      "Epoch 15762, Loss: 429.7013854980469, Neurons: 11, Grad norm: 1.074e+01\n",
      "Epoch 15763, Loss: 429.6988830566406, Neurons: 11, Grad norm: 7.313e+00\n",
      "Epoch 15764, Loss: 429.6963806152344, Neurons: 11, Grad norm: 3.805e+00\n",
      "Epoch 15765, Loss: 429.6938781738281, Neurons: 11, Grad norm: 1.432e+00\n",
      "Epoch 15766, Loss: 429.6913757324219, Neurons: 11, Grad norm: 3.920e+00\n",
      "Epoch 15767, Loss: 429.68890380859375, Neurons: 11, Grad norm: 6.147e+00\n",
      "Epoch 15768, Loss: 429.6864013671875, Neurons: 11, Grad norm: 1.031e+01\n",
      "Epoch 15769, Loss: 429.68377685546875, Neurons: 11, Grad norm: 1.254e+01\n",
      "Epoch 15770, Loss: 429.68133544921875, Neurons: 11, Grad norm: 1.449e+01\n",
      "Epoch 15771, Loss: 429.6788330078125, Neurons: 11, Grad norm: 1.499e+01\n",
      "Epoch 15772, Loss: 429.67633056640625, Neurons: 11, Grad norm: 1.491e+01\n",
      "Epoch 15773, Loss: 429.6737976074219, Neurons: 11, Grad norm: 1.378e+01\n",
      "Epoch 15774, Loss: 429.6712951660156, Neurons: 11, Grad norm: 1.387e+01\n",
      "Epoch 15775, Loss: 429.6687927246094, Neurons: 11, Grad norm: 1.291e+01\n",
      "Epoch 15776, Loss: 429.66619873046875, Neurons: 11, Grad norm: 1.196e+01\n",
      "Epoch 15777, Loss: 429.6636962890625, Neurons: 11, Grad norm: 1.010e+01\n",
      "Epoch 15778, Loss: 429.66119384765625, Neurons: 11, Grad norm: 9.968e+00\n",
      "Epoch 15779, Loss: 429.65869140625, Neurons: 11, Grad norm: 9.179e+00\n",
      "Epoch 15780, Loss: 429.6561279296875, Neurons: 11, Grad norm: 9.762e+00\n",
      "Epoch 15781, Loss: 429.65362548828125, Neurons: 11, Grad norm: 9.996e+00\n",
      "Epoch 15782, Loss: 429.6510925292969, Neurons: 11, Grad norm: 1.110e+01\n",
      "Epoch 15783, Loss: 429.6485900878906, Neurons: 11, Grad norm: 1.188e+01\n",
      "Epoch 15784, Loss: 429.6460876464844, Neurons: 11, Grad norm: 1.373e+01\n",
      "Epoch 15785, Loss: 429.64349365234375, Neurons: 11, Grad norm: 1.487e+01\n",
      "Epoch 15786, Loss: 429.6409912109375, Neurons: 11, Grad norm: 1.715e+01\n",
      "Epoch 15787, Loss: 429.6383972167969, Neurons: 11, Grad norm: 1.841e+01\n",
      "Epoch 15788, Loss: 429.6358947753906, Neurons: 11, Grad norm: 2.074e+01\n",
      "Epoch 15789, Loss: 429.6333923339844, Neurons: 11, Grad norm: 2.233e+01\n",
      "Epoch 15790, Loss: 429.63079833984375, Neurons: 11, Grad norm: 2.473e+01\n",
      "Epoch 15791, Loss: 429.6282958984375, Neurons: 11, Grad norm: 2.666e+01\n",
      "Epoch 15792, Loss: 429.62579345703125, Neurons: 11, Grad norm: 2.915e+01\n",
      "Epoch 15793, Loss: 429.6231994628906, Neurons: 11, Grad norm: 2.972e+01\n",
      "Epoch 15794, Loss: 429.6207275390625, Neurons: 11, Grad norm: 3.081e+01\n",
      "Epoch 15795, Loss: 429.6181335449219, Neurons: 11, Grad norm: 3.057e+01\n",
      "Epoch 15796, Loss: 429.6156005859375, Neurons: 11, Grad norm: 3.074e+01\n",
      "Epoch 15797, Loss: 429.61297607421875, Neurons: 11, Grad norm: 3.115e+01\n",
      "Epoch 15798, Loss: 429.6105041503906, Neurons: 11, Grad norm: 3.225e+01\n",
      "Epoch 15799, Loss: 429.6079406738281, Neurons: 11, Grad norm: 3.283e+01\n",
      "Epoch 15799, Test loss: 426.3000793457031\n",
      "Epoch 15800, Loss: 429.6053771972656, Neurons: 11, Grad norm: 3.478e+01\n",
      "Epoch 15801, Loss: 429.60284423828125, Neurons: 11, Grad norm: 3.474e+01\n",
      "Epoch 15802, Loss: 429.60028076171875, Neurons: 11, Grad norm: 3.580e+01\n",
      "Epoch 15803, Loss: 429.5976867675781, Neurons: 11, Grad norm: 3.580e+01\n",
      "Epoch 15804, Loss: 429.5951843261719, Neurons: 11, Grad norm: 3.583e+01\n",
      "Epoch 15805, Loss: 429.59259033203125, Neurons: 11, Grad norm: 3.569e+01\n",
      "Epoch 15806, Loss: 429.59002685546875, Neurons: 11, Grad norm: 3.591e+01\n",
      "Epoch 15807, Loss: 429.5874938964844, Neurons: 11, Grad norm: 3.559e+01\n",
      "Epoch 15808, Loss: 429.5849304199219, Neurons: 11, Grad norm: 3.768e+01\n",
      "Epoch 15809, Loss: 429.582275390625, Neurons: 11, Grad norm: 3.873e+01\n",
      "Epoch 15810, Loss: 429.5798034667969, Neurons: 11, Grad norm: 4.068e+01\n",
      "Epoch 15811, Loss: 429.5771789550781, Neurons: 11, Grad norm: 4.328e+01\n",
      "Epoch 15812, Loss: 429.5746765136719, Neurons: 11, Grad norm: 4.687e+01\n",
      "Epoch 15813, Loss: 429.5721435546875, Neurons: 11, Grad norm: 4.944e+01\n",
      "Epoch 15814, Loss: 429.569580078125, Neurons: 11, Grad norm: 5.443e+01\n",
      "Epoch 15815, Loss: 429.56707763671875, Neurons: 11, Grad norm: 5.900e+01\n",
      "Epoch 15816, Loss: 429.5644836425781, Neurons: 11, Grad norm: 6.515e+01\n",
      "Epoch 15817, Loss: 429.5619812011719, Neurons: 11, Grad norm: 7.168e+01\n",
      "Epoch 15818, Loss: 429.5594787597656, Neurons: 11, Grad norm: 7.931e+01\n",
      "Epoch 15819, Loss: 429.5569763183594, Neurons: 11, Grad norm: 8.837e+01\n",
      "Epoch 15820, Loss: 429.5545349121094, Neurons: 11, Grad norm: 9.927e+01\n",
      "Epoch 15821, Loss: 429.5521240234375, Neurons: 11, Grad norm: 1.102e+02\n",
      "Epoch 15822, Loss: 429.54974365234375, Neurons: 11, Grad norm: 1.246e+02\n",
      "Epoch 15823, Loss: 429.5473937988281, Neurons: 11, Grad norm: 1.382e+02\n",
      "Epoch 15824, Loss: 429.5450744628906, Neurons: 11, Grad norm: 1.530e+02\n",
      "Epoch 15825, Loss: 429.5428771972656, Neurons: 11, Grad norm: 1.664e+02\n",
      "Epoch 15826, Loss: 429.5406494140625, Neurons: 11, Grad norm: 1.777e+02\n",
      "Epoch 15827, Loss: 429.53839111328125, Neurons: 11, Grad norm: 1.853e+02\n",
      "Epoch 15828, Loss: 429.5359802246094, Neurons: 11, Grad norm: 1.878e+02\n",
      "Epoch 15829, Loss: 429.5335998535156, Neurons: 11, Grad norm: 1.824e+02\n",
      "Epoch 15830, Loss: 429.5308837890625, Neurons: 11, Grad norm: 1.703e+02\n",
      "Epoch 15831, Loss: 429.5280456542969, Neurons: 11, Grad norm: 1.486e+02\n",
      "Epoch 15832, Loss: 429.5249938964844, Neurons: 11, Grad norm: 1.214e+02\n",
      "Epoch 15833, Loss: 429.5219421386719, Neurons: 11, Grad norm: 8.731e+01\n",
      "Epoch 15834, Loss: 429.5188903808594, Neurons: 11, Grad norm: 5.045e+01\n",
      "Epoch 15835, Loss: 429.51605224609375, Neurons: 11, Grad norm: 1.394e+01\n",
      "Epoch 15836, Loss: 429.5133972167969, Neurons: 11, Grad norm: 1.948e+01\n",
      "Epoch 15837, Loss: 429.51080322265625, Neurons: 11, Grad norm: 4.882e+01\n",
      "Epoch 15838, Loss: 429.50848388671875, Neurons: 11, Grad norm: 7.147e+01\n",
      "Epoch 15839, Loss: 429.5061950683594, Neurons: 11, Grad norm: 8.913e+01\n",
      "Epoch 15840, Loss: 429.50384521484375, Neurons: 11, Grad norm: 9.801e+01\n",
      "Epoch 15841, Loss: 429.5014953613281, Neurons: 11, Grad norm: 1.007e+02\n",
      "Epoch 15842, Loss: 429.4989929199219, Neurons: 11, Grad norm: 9.561e+01\n",
      "Epoch 15843, Loss: 429.4964294433594, Neurons: 11, Grad norm: 8.485e+01\n",
      "Epoch 15844, Loss: 429.4937744140625, Neurons: 11, Grad norm: 6.890e+01\n",
      "Epoch 15845, Loss: 429.4910888671875, Neurons: 11, Grad norm: 4.938e+01\n",
      "Epoch 15846, Loss: 429.4884033203125, Neurons: 11, Grad norm: 2.791e+01\n",
      "Epoch 15847, Loss: 429.48577880859375, Neurons: 11, Grad norm: 7.924e+00\n",
      "Epoch 15848, Loss: 429.4831848144531, Neurons: 11, Grad norm: 1.277e+01\n",
      "Epoch 15849, Loss: 429.4806823730469, Neurons: 11, Grad norm: 2.869e+01\n",
      "Epoch 15849, Test loss: 426.1784973144531\n",
      "Epoch 15850, Loss: 429.4781799316406, Neurons: 11, Grad norm: 4.299e+01\n",
      "Epoch 15851, Loss: 429.4757995605469, Neurons: 11, Grad norm: 5.254e+01\n",
      "Epoch 15852, Loss: 429.4732971191406, Neurons: 11, Grad norm: 5.662e+01\n",
      "Epoch 15853, Loss: 429.4708251953125, Neurons: 11, Grad norm: 5.775e+01\n",
      "Epoch 15854, Loss: 429.4682922363281, Neurons: 11, Grad norm: 5.617e+01\n",
      "Epoch 15855, Loss: 429.4657897949219, Neurons: 11, Grad norm: 4.956e+01\n",
      "Epoch 15856, Loss: 429.46319580078125, Neurons: 11, Grad norm: 4.254e+01\n",
      "Epoch 15857, Loss: 429.46063232421875, Neurons: 11, Grad norm: 3.198e+01\n",
      "Epoch 15858, Loss: 429.4580993652344, Neurons: 11, Grad norm: 2.083e+01\n",
      "Epoch 15859, Loss: 429.4554748535156, Neurons: 11, Grad norm: 9.153e+00\n",
      "Epoch 15860, Loss: 429.45294189453125, Neurons: 11, Grad norm: 2.499e+00\n",
      "Epoch 15861, Loss: 429.45037841796875, Neurons: 11, Grad norm: 1.224e+01\n",
      "Epoch 15862, Loss: 429.4478759765625, Neurons: 11, Grad norm: 2.007e+01\n",
      "Epoch 15863, Loss: 429.4454040527344, Neurons: 11, Grad norm: 2.790e+01\n",
      "Epoch 15864, Loss: 429.4429016113281, Neurons: 11, Grad norm: 3.258e+01\n",
      "Epoch 15865, Loss: 429.4403991699219, Neurons: 11, Grad norm: 3.654e+01\n",
      "Epoch 15866, Loss: 429.4378967285156, Neurons: 11, Grad norm: 3.784e+01\n",
      "Epoch 15867, Loss: 429.435302734375, Neurons: 11, Grad norm: 3.799e+01\n",
      "Epoch 15868, Loss: 429.43280029296875, Neurons: 11, Grad norm: 3.626e+01\n",
      "Epoch 15869, Loss: 429.43023681640625, Neurons: 11, Grad norm: 3.383e+01\n",
      "Epoch 15870, Loss: 429.4277038574219, Neurons: 11, Grad norm: 2.980e+01\n",
      "Epoch 15871, Loss: 429.4250793457031, Neurons: 11, Grad norm: 2.612e+01\n",
      "Epoch 15872, Loss: 429.4225769042969, Neurons: 11, Grad norm: 2.093e+01\n",
      "Epoch 15873, Loss: 429.41998291015625, Neurons: 11, Grad norm: 1.696e+01\n",
      "Epoch 15874, Loss: 429.4174499511719, Neurons: 11, Grad norm: 1.237e+01\n",
      "Epoch 15875, Loss: 429.4148254394531, Neurons: 11, Grad norm: 9.071e+00\n",
      "Epoch 15876, Loss: 429.412353515625, Neurons: 11, Grad norm: 5.909e+00\n",
      "Epoch 15877, Loss: 429.4097900390625, Neurons: 11, Grad norm: 3.937e+00\n",
      "Epoch 15878, Loss: 429.4072265625, Neurons: 11, Grad norm: 1.545e+00\n",
      "Epoch 15879, Loss: 429.4046936035156, Neurons: 11, Grad norm: 1.880e+00\n",
      "Epoch 15880, Loss: 429.402099609375, Neurons: 11, Grad norm: 3.858e+00\n",
      "Epoch 15881, Loss: 429.39959716796875, Neurons: 11, Grad norm: 5.021e+00\n",
      "Epoch 15882, Loss: 429.3970031738281, Neurons: 11, Grad norm: 5.435e+00\n",
      "Epoch 15883, Loss: 429.3945007324219, Neurons: 11, Grad norm: 5.630e+00\n",
      "Epoch 15884, Loss: 429.3918762207031, Neurons: 11, Grad norm: 7.323e+00\n",
      "Epoch 15885, Loss: 429.3892822265625, Neurons: 11, Grad norm: 6.841e+00\n",
      "Epoch 15886, Loss: 429.38677978515625, Neurons: 11, Grad norm: 7.667e+00\n",
      "Epoch 15887, Loss: 429.3841857910156, Neurons: 11, Grad norm: 7.370e+00\n",
      "Epoch 15888, Loss: 429.38165283203125, Neurons: 11, Grad norm: 7.229e+00\n",
      "Epoch 15889, Loss: 429.37908935546875, Neurons: 11, Grad norm: 7.011e+00\n",
      "Epoch 15890, Loss: 429.3764953613281, Neurons: 11, Grad norm: 6.789e+00\n",
      "Epoch 15891, Loss: 429.3739318847656, Neurons: 11, Grad norm: 6.040e+00\n",
      "Epoch 15892, Loss: 429.371337890625, Neurons: 11, Grad norm: 6.127e+00\n",
      "Epoch 15893, Loss: 429.3687744140625, Neurons: 11, Grad norm: 4.815e+00\n",
      "Epoch 15894, Loss: 429.3661804199219, Neurons: 11, Grad norm: 4.815e+00\n",
      "Epoch 15895, Loss: 429.3636474609375, Neurons: 11, Grad norm: 3.650e+00\n",
      "Epoch 15896, Loss: 429.3609924316406, Neurons: 11, Grad norm: 3.346e+00\n",
      "Epoch 15897, Loss: 429.3584899902344, Neurons: 11, Grad norm: 2.689e+00\n",
      "Epoch 15898, Loss: 429.35589599609375, Neurons: 11, Grad norm: 2.289e+00\n",
      "Epoch 15899, Loss: 429.3533020019531, Neurons: 11, Grad norm: 1.825e+00\n",
      "Epoch 15899, Test loss: 426.05169677734375\n",
      "Epoch 15900, Loss: 429.3506774902344, Neurons: 11, Grad norm: 2.753e+00\n",
      "Epoch 15901, Loss: 429.34814453125, Neurons: 11, Grad norm: 3.326e+00\n",
      "Epoch 15902, Loss: 429.3454895019531, Neurons: 11, Grad norm: 5.475e+00\n",
      "Epoch 15903, Loss: 429.3428955078125, Neurons: 11, Grad norm: 7.186e+00\n",
      "Epoch 15904, Loss: 429.34033203125, Neurons: 11, Grad norm: 8.960e+00\n",
      "Epoch 15905, Loss: 429.3377380371094, Neurons: 11, Grad norm: 1.016e+01\n",
      "Epoch 15906, Loss: 429.3351745605469, Neurons: 11, Grad norm: 1.201e+01\n",
      "Epoch 15907, Loss: 429.33258056640625, Neurons: 11, Grad norm: 1.296e+01\n",
      "Epoch 15908, Loss: 429.3299865722656, Neurons: 11, Grad norm: 1.593e+01\n",
      "Epoch 15909, Loss: 429.32733154296875, Neurons: 11, Grad norm: 1.697e+01\n",
      "Epoch 15910, Loss: 429.3247985839844, Neurons: 11, Grad norm: 1.913e+01\n",
      "Epoch 15911, Loss: 429.3221740722656, Neurons: 11, Grad norm: 2.224e+01\n",
      "Epoch 15912, Loss: 429.3195495605469, Neurons: 11, Grad norm: 2.595e+01\n",
      "Epoch 15913, Loss: 429.3169860839844, Neurons: 11, Grad norm: 3.027e+01\n",
      "Epoch 15914, Loss: 429.31439208984375, Neurons: 11, Grad norm: 3.627e+01\n",
      "Epoch 15915, Loss: 429.3117980957031, Neurons: 11, Grad norm: 4.176e+01\n",
      "Epoch 15916, Loss: 429.3092346191406, Neurons: 11, Grad norm: 4.983e+01\n",
      "Epoch 15917, Loss: 429.30670166015625, Neurons: 11, Grad norm: 5.746e+01\n",
      "Epoch 15918, Loss: 429.30413818359375, Neurons: 11, Grad norm: 6.713e+01\n",
      "Epoch 15919, Loss: 429.30157470703125, Neurons: 11, Grad norm: 7.753e+01\n",
      "Epoch 15920, Loss: 429.2991027832031, Neurons: 11, Grad norm: 8.925e+01\n",
      "Epoch 15921, Loss: 429.2966003417969, Neurons: 11, Grad norm: 1.023e+02\n",
      "Epoch 15922, Loss: 429.294189453125, Neurons: 11, Grad norm: 1.180e+02\n",
      "Epoch 15923, Loss: 429.2917785644531, Neurons: 11, Grad norm: 1.343e+02\n",
      "Epoch 15924, Loss: 429.28948974609375, Neurons: 11, Grad norm: 1.539e+02\n",
      "Epoch 15925, Loss: 429.287353515625, Neurons: 11, Grad norm: 1.730e+02\n",
      "Epoch 15926, Loss: 429.2851867675781, Neurons: 11, Grad norm: 1.911e+02\n",
      "Epoch 15927, Loss: 429.2830810546875, Neurons: 11, Grad norm: 2.067e+02\n",
      "Epoch 15928, Loss: 429.2809753417969, Neurons: 11, Grad norm: 2.173e+02\n",
      "Epoch 15929, Loss: 429.27874755859375, Neurons: 11, Grad norm: 2.188e+02\n",
      "Epoch 15930, Loss: 429.2762451171875, Neurons: 11, Grad norm: 2.119e+02\n",
      "Epoch 15931, Loss: 429.2734375, Neurons: 11, Grad norm: 1.913e+02\n",
      "Epoch 15932, Loss: 429.2702941894531, Neurons: 11, Grad norm: 1.602e+02\n",
      "Epoch 15933, Loss: 429.2669372558594, Neurons: 11, Grad norm: 1.192e+02\n",
      "Epoch 15934, Loss: 429.2635498046875, Neurons: 11, Grad norm: 7.205e+01\n",
      "Epoch 15935, Loss: 429.2603454589844, Neurons: 11, Grad norm: 2.229e+01\n",
      "Epoch 15936, Loss: 429.2574462890625, Neurons: 11, Grad norm: 2.356e+01\n",
      "Epoch 15937, Loss: 429.25494384765625, Neurons: 11, Grad norm: 6.381e+01\n",
      "Epoch 15938, Loss: 429.25262451171875, Neurons: 11, Grad norm: 9.360e+01\n",
      "Epoch 15939, Loss: 429.25048828125, Neurons: 11, Grad norm: 1.125e+02\n",
      "Epoch 15940, Loss: 429.24822998046875, Neurons: 11, Grad norm: 1.190e+02\n",
      "Epoch 15941, Loss: 429.245849609375, Neurons: 11, Grad norm: 1.144e+02\n",
      "Epoch 15942, Loss: 429.2431945800781, Neurons: 11, Grad norm: 9.821e+01\n",
      "Epoch 15943, Loss: 429.2404479980469, Neurons: 11, Grad norm: 7.532e+01\n",
      "Epoch 15944, Loss: 429.2375793457031, Neurons: 11, Grad norm: 4.668e+01\n",
      "Epoch 15945, Loss: 429.23480224609375, Neurons: 11, Grad norm: 1.784e+01\n",
      "Epoch 15946, Loss: 429.232177734375, Neurons: 11, Grad norm: 1.070e+01\n",
      "Epoch 15947, Loss: 429.2296447753906, Neurons: 11, Grad norm: 3.506e+01\n",
      "Epoch 15948, Loss: 429.2272033691406, Neurons: 11, Grad norm: 5.433e+01\n",
      "Epoch 15949, Loss: 429.22479248046875, Neurons: 11, Grad norm: 6.620e+01\n",
      "Epoch 15949, Test loss: 425.94378662109375\n",
      "Epoch 15950, Loss: 429.22235107421875, Neurons: 11, Grad norm: 7.233e+01\n",
      "Epoch 15951, Loss: 429.2198791503906, Neurons: 11, Grad norm: 7.065e+01\n",
      "Epoch 15952, Loss: 429.21728515625, Neurons: 11, Grad norm: 6.276e+01\n",
      "Epoch 15953, Loss: 429.2147521972656, Neurons: 11, Grad norm: 4.911e+01\n",
      "Epoch 15954, Loss: 429.21209716796875, Neurons: 11, Grad norm: 3.318e+01\n",
      "Epoch 15955, Loss: 429.2093811035156, Neurons: 11, Grad norm: 1.516e+01\n",
      "Epoch 15956, Loss: 429.20684814453125, Neurons: 11, Grad norm: 1.772e+00\n",
      "Epoch 15957, Loss: 429.2042541503906, Neurons: 11, Grad norm: 1.577e+01\n",
      "Epoch 15958, Loss: 429.2017822265625, Neurons: 11, Grad norm: 2.721e+01\n",
      "Epoch 15959, Loss: 429.1992492675781, Neurons: 11, Grad norm: 3.635e+01\n",
      "Epoch 15960, Loss: 429.1967468261719, Neurons: 11, Grad norm: 4.102e+01\n",
      "Epoch 15961, Loss: 429.19427490234375, Neurons: 11, Grad norm: 4.261e+01\n",
      "Epoch 15962, Loss: 429.1916809082031, Neurons: 11, Grad norm: 3.894e+01\n",
      "Epoch 15963, Loss: 429.18914794921875, Neurons: 11, Grad norm: 3.390e+01\n",
      "Epoch 15964, Loss: 429.1865539550781, Neurons: 11, Grad norm: 2.591e+01\n",
      "Epoch 15965, Loss: 429.1839904785156, Neurons: 11, Grad norm: 1.647e+01\n",
      "Epoch 15966, Loss: 429.181396484375, Neurons: 11, Grad norm: 6.370e+00\n",
      "Epoch 15967, Loss: 429.1788330078125, Neurons: 11, Grad norm: 3.335e+00\n",
      "Epoch 15968, Loss: 429.1763000488281, Neurons: 11, Grad norm: 1.104e+01\n",
      "Epoch 15969, Loss: 429.1737365722656, Neurons: 11, Grad norm: 1.671e+01\n",
      "Epoch 15970, Loss: 429.17120361328125, Neurons: 11, Grad norm: 2.279e+01\n",
      "Epoch 15971, Loss: 429.1685791015625, Neurons: 11, Grad norm: 2.439e+01\n",
      "Epoch 15972, Loss: 429.16607666015625, Neurons: 11, Grad norm: 2.509e+01\n",
      "Epoch 15973, Loss: 429.1635437011719, Neurons: 11, Grad norm: 2.326e+01\n",
      "Epoch 15974, Loss: 429.1609802246094, Neurons: 11, Grad norm: 2.073e+01\n",
      "Epoch 15975, Loss: 429.15838623046875, Neurons: 11, Grad norm: 1.773e+01\n",
      "Epoch 15976, Loss: 429.1557922363281, Neurons: 11, Grad norm: 1.315e+01\n",
      "Epoch 15977, Loss: 429.1532287597656, Neurons: 11, Grad norm: 8.107e+00\n",
      "Epoch 15978, Loss: 429.150634765625, Neurons: 11, Grad norm: 4.099e+00\n",
      "Epoch 15979, Loss: 429.1481018066406, Neurons: 11, Grad norm: 2.403e+00\n",
      "Epoch 15980, Loss: 429.1454772949219, Neurons: 11, Grad norm: 5.428e+00\n",
      "Epoch 15981, Loss: 429.14288330078125, Neurons: 11, Grad norm: 1.077e+01\n",
      "Epoch 15982, Loss: 429.1403503417969, Neurons: 11, Grad norm: 1.468e+01\n",
      "Epoch 15983, Loss: 429.1377868652344, Neurons: 11, Grad norm: 1.695e+01\n",
      "Epoch 15984, Loss: 429.13525390625, Neurons: 11, Grad norm: 1.874e+01\n",
      "Epoch 15985, Loss: 429.1325988769531, Neurons: 11, Grad norm: 1.891e+01\n",
      "Epoch 15986, Loss: 429.1300964355469, Neurons: 11, Grad norm: 1.755e+01\n",
      "Epoch 15987, Loss: 429.12750244140625, Neurons: 11, Grad norm: 1.756e+01\n",
      "Epoch 15988, Loss: 429.1248474121094, Neurons: 11, Grad norm: 1.417e+01\n",
      "Epoch 15989, Loss: 429.1222839355469, Neurons: 11, Grad norm: 1.235e+01\n",
      "Epoch 15990, Loss: 429.11968994140625, Neurons: 11, Grad norm: 1.033e+01\n",
      "Epoch 15991, Loss: 429.1170959472656, Neurons: 11, Grad norm: 7.438e+00\n",
      "Epoch 15992, Loss: 429.114501953125, Neurons: 11, Grad norm: 5.026e+00\n",
      "Epoch 15993, Loss: 429.11187744140625, Neurons: 11, Grad norm: 3.845e+00\n",
      "Epoch 15994, Loss: 429.1092834472656, Neurons: 11, Grad norm: 1.573e+00\n",
      "Epoch 15995, Loss: 429.106689453125, Neurons: 11, Grad norm: 1.444e+00\n",
      "Epoch 15996, Loss: 429.1040954589844, Neurons: 11, Grad norm: 2.909e+00\n",
      "Epoch 15997, Loss: 429.10150146484375, Neurons: 11, Grad norm: 4.907e+00\n",
      "Epoch 15998, Loss: 429.098876953125, Neurons: 11, Grad norm: 6.307e+00\n",
      "Epoch 15999, Loss: 429.0962829589844, Neurons: 11, Grad norm: 7.528e+00\n",
      "Epoch 15999, Test loss: 425.80938720703125\n",
      "Epoch 16000, Loss: 429.09368896484375, Neurons: 11, Grad norm: 1.009e+01\n",
      "Epoch 16001, Loss: 429.0910949707031, Neurons: 11, Grad norm: 1.045e+01\n",
      "Epoch 16002, Loss: 429.0885009765625, Neurons: 11, Grad norm: 1.186e+01\n",
      "Epoch 16003, Loss: 429.08587646484375, Neurons: 11, Grad norm: 1.186e+01\n",
      "Epoch 16004, Loss: 429.0832824707031, Neurons: 11, Grad norm: 1.182e+01\n",
      "Epoch 16005, Loss: 429.08062744140625, Neurons: 11, Grad norm: 1.131e+01\n",
      "Epoch 16006, Loss: 429.0780029296875, Neurons: 11, Grad norm: 1.074e+01\n",
      "Epoch 16007, Loss: 429.07537841796875, Neurons: 11, Grad norm: 9.582e+00\n",
      "Epoch 16008, Loss: 429.0727844238281, Neurons: 11, Grad norm: 9.315e+00\n",
      "Epoch 16009, Loss: 429.0701904296875, Neurons: 11, Grad norm: 7.621e+00\n",
      "Epoch 16010, Loss: 429.0675354003906, Neurons: 11, Grad norm: 7.204e+00\n",
      "Epoch 16011, Loss: 429.06494140625, Neurons: 11, Grad norm: 5.607e+00\n",
      "Epoch 16012, Loss: 429.0622863769531, Neurons: 11, Grad norm: 4.917e+00\n",
      "Epoch 16013, Loss: 429.0596923828125, Neurons: 11, Grad norm: 3.801e+00\n",
      "Epoch 16014, Loss: 429.0569763183594, Neurons: 11, Grad norm: 3.034e+00\n",
      "Epoch 16015, Loss: 429.054443359375, Neurons: 11, Grad norm: 2.098e+00\n",
      "Epoch 16016, Loss: 429.0517272949219, Neurons: 11, Grad norm: 1.694e+00\n",
      "Epoch 16017, Loss: 429.0491027832031, Neurons: 11, Grad norm: 1.531e+00\n",
      "Epoch 16018, Loss: 429.0464782714844, Neurons: 11, Grad norm: 1.725e+00\n",
      "Epoch 16019, Loss: 429.0438537597656, Neurons: 11, Grad norm: 3.939e+00\n",
      "Epoch 16020, Loss: 429.04119873046875, Neurons: 11, Grad norm: 4.718e+00\n",
      "Epoch 16021, Loss: 429.03857421875, Neurons: 11, Grad norm: 5.136e+00\n",
      "Epoch 16022, Loss: 429.035888671875, Neurons: 11, Grad norm: 6.068e+00\n",
      "Epoch 16023, Loss: 429.0332946777344, Neurons: 11, Grad norm: 6.649e+00\n",
      "Epoch 16024, Loss: 429.0306396484375, Neurons: 11, Grad norm: 7.009e+00\n",
      "Epoch 16025, Loss: 429.0279846191406, Neurons: 11, Grad norm: 9.626e+00\n",
      "Epoch 16026, Loss: 429.0252990722656, Neurons: 11, Grad norm: 9.858e+00\n",
      "Epoch 16027, Loss: 429.02264404296875, Neurons: 11, Grad norm: 1.199e+01\n",
      "Epoch 16028, Loss: 429.0199890136719, Neurons: 11, Grad norm: 1.448e+01\n",
      "Epoch 16029, Loss: 429.017333984375, Neurons: 11, Grad norm: 1.630e+01\n",
      "Epoch 16030, Loss: 429.0146789550781, Neurons: 11, Grad norm: 1.864e+01\n",
      "Epoch 16031, Loss: 429.01202392578125, Neurons: 11, Grad norm: 2.246e+01\n",
      "Epoch 16032, Loss: 429.0093994140625, Neurons: 11, Grad norm: 2.573e+01\n",
      "Epoch 16033, Loss: 429.00677490234375, Neurons: 11, Grad norm: 3.125e+01\n",
      "Epoch 16034, Loss: 429.00408935546875, Neurons: 11, Grad norm: 3.502e+01\n",
      "Epoch 16035, Loss: 429.0014343261719, Neurons: 11, Grad norm: 4.035e+01\n",
      "Epoch 16036, Loss: 428.998779296875, Neurons: 11, Grad norm: 4.688e+01\n",
      "Epoch 16037, Loss: 428.9961853027344, Neurons: 11, Grad norm: 5.414e+01\n",
      "Epoch 16038, Loss: 428.99359130859375, Neurons: 11, Grad norm: 6.276e+01\n",
      "Epoch 16039, Loss: 428.9909362792969, Neurons: 11, Grad norm: 7.458e+01\n",
      "Epoch 16040, Loss: 428.9884033203125, Neurons: 11, Grad norm: 8.720e+01\n",
      "Epoch 16041, Loss: 428.98590087890625, Neurons: 11, Grad norm: 1.034e+02\n",
      "Epoch 16042, Loss: 428.9834899902344, Neurons: 11, Grad norm: 1.204e+02\n",
      "Epoch 16043, Loss: 428.9810791015625, Neurons: 11, Grad norm: 1.401e+02\n",
      "Epoch 16044, Loss: 428.9787902832031, Neurons: 11, Grad norm: 1.606e+02\n",
      "Epoch 16045, Loss: 428.9765930175781, Neurons: 11, Grad norm: 1.820e+02\n",
      "Epoch 16046, Loss: 428.9744873046875, Neurons: 11, Grad norm: 2.029e+02\n",
      "Epoch 16047, Loss: 428.9724426269531, Neurons: 11, Grad norm: 2.222e+02\n",
      "Epoch 16048, Loss: 428.97039794921875, Neurons: 11, Grad norm: 2.343e+02\n",
      "Epoch 16049, Loss: 428.96820068359375, Neurons: 11, Grad norm: 2.379e+02\n",
      "Epoch 16049, Test loss: 425.6366271972656\n",
      "Epoch 16050, Loss: 428.9656982421875, Neurons: 11, Grad norm: 2.268e+02\n",
      "Epoch 16051, Loss: 428.9626770019531, Neurons: 11, Grad norm: 2.011e+02\n",
      "Epoch 16052, Loss: 428.95928955078125, Neurons: 11, Grad norm: 1.590e+02\n",
      "Epoch 16053, Loss: 428.9555358886719, Neurons: 11, Grad norm: 1.065e+02\n",
      "Epoch 16054, Loss: 428.9519348144531, Neurons: 11, Grad norm: 4.897e+01\n",
      "Epoch 16055, Loss: 428.9486999511719, Neurons: 11, Grad norm: 7.546e+00\n",
      "Epoch 16056, Loss: 428.9459533691406, Neurons: 11, Grad norm: 5.760e+01\n",
      "Epoch 16057, Loss: 428.943603515625, Neurons: 11, Grad norm: 9.577e+01\n",
      "Epoch 16058, Loss: 428.9414367675781, Neurons: 11, Grad norm: 1.214e+02\n",
      "Epoch 16059, Loss: 428.9393005371094, Neurons: 11, Grad norm: 1.309e+02\n",
      "Epoch 16060, Loss: 428.9368896484375, Neurons: 11, Grad norm: 1.272e+02\n",
      "Epoch 16061, Loss: 428.9342956542969, Neurons: 11, Grad norm: 1.093e+02\n",
      "Epoch 16062, Loss: 428.93133544921875, Neurons: 11, Grad norm: 8.060e+01\n",
      "Epoch 16063, Loss: 428.9283752441406, Neurons: 11, Grad norm: 4.464e+01\n",
      "Epoch 16064, Loss: 428.92547607421875, Neurons: 11, Grad norm: 7.798e+00\n",
      "Epoch 16065, Loss: 428.9227294921875, Neurons: 11, Grad norm: 2.646e+01\n",
      "Epoch 16066, Loss: 428.9202880859375, Neurons: 11, Grad norm: 5.363e+01\n",
      "Epoch 16067, Loss: 428.9178466796875, Neurons: 11, Grad norm: 7.319e+01\n",
      "Epoch 16068, Loss: 428.9154357910156, Neurons: 11, Grad norm: 8.120e+01\n",
      "Epoch 16069, Loss: 428.9129943847656, Neurons: 11, Grad norm: 8.123e+01\n",
      "Epoch 16070, Loss: 428.910400390625, Neurons: 11, Grad norm: 7.131e+01\n",
      "Epoch 16071, Loss: 428.9076843261719, Neurons: 11, Grad norm: 5.392e+01\n",
      "Epoch 16072, Loss: 428.9049987792969, Neurons: 11, Grad norm: 3.229e+01\n",
      "Epoch 16073, Loss: 428.9022521972656, Neurons: 11, Grad norm: 9.541e+00\n",
      "Epoch 16074, Loss: 428.89959716796875, Neurons: 11, Grad norm: 1.348e+01\n",
      "Epoch 16075, Loss: 428.89703369140625, Neurons: 11, Grad norm: 3.097e+01\n",
      "Epoch 16076, Loss: 428.8945007324219, Neurons: 11, Grad norm: 4.441e+01\n",
      "Epoch 16077, Loss: 428.8919982910156, Neurons: 11, Grad norm: 5.139e+01\n",
      "Epoch 16078, Loss: 428.8894348144531, Neurons: 11, Grad norm: 5.274e+01\n",
      "Epoch 16079, Loss: 428.88690185546875, Neurons: 11, Grad norm: 4.790e+01\n",
      "Epoch 16080, Loss: 428.8842468261719, Neurons: 11, Grad norm: 3.901e+01\n",
      "Epoch 16081, Loss: 428.881591796875, Neurons: 11, Grad norm: 2.531e+01\n",
      "Epoch 16082, Loss: 428.8789978027344, Neurons: 11, Grad norm: 1.221e+01\n",
      "Epoch 16083, Loss: 428.8763427734375, Neurons: 11, Grad norm: 2.013e+00\n",
      "Epoch 16084, Loss: 428.8736877441406, Neurons: 11, Grad norm: 1.352e+01\n",
      "Epoch 16085, Loss: 428.8711853027344, Neurons: 11, Grad norm: 2.284e+01\n",
      "Epoch 16086, Loss: 428.86859130859375, Neurons: 11, Grad norm: 2.843e+01\n",
      "Epoch 16087, Loss: 428.86602783203125, Neurons: 11, Grad norm: 3.112e+01\n",
      "Epoch 16088, Loss: 428.8634033203125, Neurons: 11, Grad norm: 2.909e+01\n",
      "Epoch 16089, Loss: 428.86077880859375, Neurons: 11, Grad norm: 2.555e+01\n",
      "Epoch 16090, Loss: 428.858154296875, Neurons: 11, Grad norm: 1.868e+01\n",
      "Epoch 16091, Loss: 428.85552978515625, Neurons: 11, Grad norm: 1.140e+01\n",
      "Epoch 16092, Loss: 428.8528747558594, Neurons: 11, Grad norm: 3.481e+00\n",
      "Epoch 16093, Loss: 428.85028076171875, Neurons: 11, Grad norm: 4.597e+00\n",
      "Epoch 16094, Loss: 428.8476867675781, Neurons: 11, Grad norm: 1.223e+01\n",
      "Epoch 16095, Loss: 428.8450927734375, Neurons: 11, Grad norm: 1.819e+01\n",
      "Epoch 16096, Loss: 428.8424987792969, Neurons: 11, Grad norm: 2.324e+01\n",
      "Epoch 16097, Loss: 428.8398742675781, Neurons: 11, Grad norm: 2.565e+01\n",
      "Epoch 16098, Loss: 428.8372802734375, Neurons: 11, Grad norm: 2.702e+01\n",
      "Epoch 16099, Loss: 428.8346862792969, Neurons: 11, Grad norm: 2.573e+01\n",
      "Epoch 16099, Test loss: 425.56500244140625\n",
      "Epoch 16100, Loss: 428.83209228515625, Neurons: 11, Grad norm: 2.398e+01\n",
      "Epoch 16101, Loss: 428.8293762207031, Neurons: 11, Grad norm: 2.016e+01\n",
      "Epoch 16102, Loss: 428.8267822265625, Neurons: 11, Grad norm: 1.522e+01\n",
      "Epoch 16103, Loss: 428.8240966796875, Neurons: 11, Grad norm: 9.243e+00\n",
      "Epoch 16104, Loss: 428.8215026855469, Neurons: 11, Grad norm: 4.955e+00\n",
      "Epoch 16105, Loss: 428.8188781738281, Neurons: 11, Grad norm: 1.849e+00\n",
      "Epoch 16106, Loss: 428.8161926269531, Neurons: 11, Grad norm: 5.600e+00\n",
      "Epoch 16107, Loss: 428.8135986328125, Neurons: 11, Grad norm: 9.646e+00\n",
      "Epoch 16108, Loss: 428.81097412109375, Neurons: 11, Grad norm: 1.360e+01\n",
      "Epoch 16109, Loss: 428.808349609375, Neurons: 11, Grad norm: 1.679e+01\n",
      "Epoch 16110, Loss: 428.8056945800781, Neurons: 11, Grad norm: 1.880e+01\n",
      "Epoch 16111, Loss: 428.80303955078125, Neurons: 11, Grad norm: 2.100e+01\n",
      "Epoch 16112, Loss: 428.8003845214844, Neurons: 11, Grad norm: 1.973e+01\n",
      "Epoch 16113, Loss: 428.79779052734375, Neurons: 11, Grad norm: 1.891e+01\n",
      "Epoch 16114, Loss: 428.7951354980469, Neurons: 11, Grad norm: 1.601e+01\n",
      "Epoch 16115, Loss: 428.7924499511719, Neurons: 11, Grad norm: 1.276e+01\n",
      "Epoch 16116, Loss: 428.789794921875, Neurons: 11, Grad norm: 9.099e+00\n",
      "Epoch 16117, Loss: 428.7871398925781, Neurons: 11, Grad norm: 5.198e+00\n",
      "Epoch 16118, Loss: 428.78448486328125, Neurons: 11, Grad norm: 1.636e+00\n",
      "Epoch 16119, Loss: 428.78179931640625, Neurons: 11, Grad norm: 2.590e+00\n",
      "Epoch 16120, Loss: 428.7791748046875, Neurons: 11, Grad norm: 6.020e+00\n",
      "Epoch 16121, Loss: 428.7764892578125, Neurons: 11, Grad norm: 7.616e+00\n",
      "Epoch 16122, Loss: 428.7738037109375, Neurons: 11, Grad norm: 9.881e+00\n",
      "Epoch 16123, Loss: 428.77117919921875, Neurons: 11, Grad norm: 1.063e+01\n",
      "Epoch 16124, Loss: 428.76849365234375, Neurons: 11, Grad norm: 1.122e+01\n",
      "Epoch 16125, Loss: 428.7658386230469, Neurons: 11, Grad norm: 1.124e+01\n",
      "Epoch 16126, Loss: 428.76318359375, Neurons: 11, Grad norm: 1.086e+01\n",
      "Epoch 16127, Loss: 428.760498046875, Neurons: 11, Grad norm: 9.651e+00\n",
      "Epoch 16128, Loss: 428.7578430175781, Neurons: 11, Grad norm: 9.900e+00\n",
      "Epoch 16129, Loss: 428.75518798828125, Neurons: 11, Grad norm: 9.272e+00\n",
      "Epoch 16130, Loss: 428.75250244140625, Neurons: 11, Grad norm: 1.003e+01\n",
      "Epoch 16131, Loss: 428.7497863769531, Neurons: 11, Grad norm: 1.026e+01\n",
      "Epoch 16132, Loss: 428.7471008300781, Neurons: 11, Grad norm: 1.001e+01\n",
      "Epoch 16133, Loss: 428.744384765625, Neurons: 11, Grad norm: 9.381e+00\n",
      "Epoch 16134, Loss: 428.74169921875, Neurons: 11, Grad norm: 1.027e+01\n",
      "Epoch 16135, Loss: 428.7390441894531, Neurons: 11, Grad norm: 1.046e+01\n",
      "Epoch 16136, Loss: 428.736328125, Neurons: 11, Grad norm: 1.205e+01\n",
      "Epoch 16137, Loss: 428.73370361328125, Neurons: 11, Grad norm: 1.301e+01\n",
      "Epoch 16138, Loss: 428.7309875488281, Neurons: 11, Grad norm: 1.477e+01\n",
      "Epoch 16139, Loss: 428.7283020019531, Neurons: 11, Grad norm: 1.617e+01\n",
      "Epoch 16140, Loss: 428.7255859375, Neurons: 11, Grad norm: 1.823e+01\n",
      "Epoch 16141, Loss: 428.722900390625, Neurons: 11, Grad norm: 1.866e+01\n",
      "Epoch 16142, Loss: 428.7201843261719, Neurons: 11, Grad norm: 1.967e+01\n",
      "Epoch 16143, Loss: 428.7174987792969, Neurons: 11, Grad norm: 2.056e+01\n",
      "Epoch 16144, Loss: 428.71478271484375, Neurons: 11, Grad norm: 2.217e+01\n",
      "Epoch 16145, Loss: 428.71209716796875, Neurons: 11, Grad norm: 2.334e+01\n",
      "Epoch 16146, Loss: 428.7093811035156, Neurons: 11, Grad norm: 2.549e+01\n",
      "Epoch 16147, Loss: 428.7066955566406, Neurons: 11, Grad norm: 2.551e+01\n",
      "Epoch 16148, Loss: 428.7039489746094, Neurons: 11, Grad norm: 2.638e+01\n",
      "Epoch 16149, Loss: 428.70123291015625, Neurons: 11, Grad norm: 2.628e+01\n",
      "Epoch 16149, Test loss: 425.43865966796875\n",
      "Epoch 16150, Loss: 428.69854736328125, Neurons: 11, Grad norm: 2.625e+01\n",
      "Epoch 16151, Loss: 428.69580078125, Neurons: 11, Grad norm: 2.582e+01\n",
      "Epoch 16152, Loss: 428.6930847167969, Neurons: 11, Grad norm: 2.552e+01\n",
      "Epoch 16153, Loss: 428.6903381347656, Neurons: 11, Grad norm: 2.435e+01\n",
      "Epoch 16154, Loss: 428.6876525878906, Neurons: 11, Grad norm: 2.403e+01\n",
      "Epoch 16155, Loss: 428.68487548828125, Neurons: 11, Grad norm: 2.252e+01\n",
      "Epoch 16156, Loss: 428.68218994140625, Neurons: 11, Grad norm: 2.214e+01\n",
      "Epoch 16157, Loss: 428.679443359375, Neurons: 11, Grad norm: 2.085e+01\n",
      "Epoch 16158, Loss: 428.6767272949219, Neurons: 11, Grad norm: 2.015e+01\n",
      "Epoch 16159, Loss: 428.6739807128906, Neurons: 11, Grad norm: 1.925e+01\n",
      "Epoch 16160, Loss: 428.6712341308594, Neurons: 11, Grad norm: 1.882e+01\n",
      "Epoch 16161, Loss: 428.6684875488281, Neurons: 11, Grad norm: 1.817e+01\n",
      "Epoch 16162, Loss: 428.6658020019531, Neurons: 11, Grad norm: 1.959e+01\n",
      "Epoch 16163, Loss: 428.6629943847656, Neurons: 11, Grad norm: 2.077e+01\n",
      "Epoch 16164, Loss: 428.6602783203125, Neurons: 11, Grad norm: 2.354e+01\n",
      "Epoch 16165, Loss: 428.6575012207031, Neurons: 11, Grad norm: 2.638e+01\n",
      "Epoch 16166, Loss: 428.65478515625, Neurons: 11, Grad norm: 3.059e+01\n",
      "Epoch 16167, Loss: 428.652099609375, Neurons: 11, Grad norm: 3.503e+01\n",
      "Epoch 16168, Loss: 428.6492919921875, Neurons: 11, Grad norm: 4.084e+01\n",
      "Epoch 16169, Loss: 428.6466369628906, Neurons: 11, Grad norm: 4.668e+01\n",
      "Epoch 16170, Loss: 428.6438903808594, Neurons: 11, Grad norm: 5.433e+01\n",
      "Epoch 16171, Loss: 428.64117431640625, Neurons: 11, Grad norm: 6.192e+01\n",
      "Epoch 16172, Loss: 428.63848876953125, Neurons: 11, Grad norm: 7.147e+01\n",
      "Epoch 16173, Loss: 428.6358337402344, Neurons: 11, Grad norm: 8.132e+01\n",
      "Epoch 16174, Loss: 428.6331787109375, Neurons: 11, Grad norm: 9.294e+01\n",
      "Epoch 16175, Loss: 428.6305847167969, Neurons: 11, Grad norm: 1.052e+02\n",
      "Epoch 16176, Loss: 428.6280517578125, Neurons: 11, Grad norm: 1.201e+02\n",
      "Epoch 16177, Loss: 428.62554931640625, Neurons: 11, Grad norm: 1.356e+02\n",
      "Epoch 16178, Loss: 428.6230773925781, Neurons: 11, Grad norm: 1.525e+02\n",
      "Epoch 16179, Loss: 428.6206970214844, Neurons: 11, Grad norm: 1.701e+02\n",
      "Epoch 16180, Loss: 428.6183776855469, Neurons: 11, Grad norm: 1.870e+02\n",
      "Epoch 16181, Loss: 428.6160888671875, Neurons: 11, Grad norm: 2.003e+02\n",
      "Epoch 16182, Loss: 428.6137390136719, Neurons: 11, Grad norm: 2.103e+02\n",
      "Epoch 16183, Loss: 428.611328125, Neurons: 11, Grad norm: 2.112e+02\n",
      "Epoch 16184, Loss: 428.60870361328125, Neurons: 11, Grad norm: 2.029e+02\n",
      "Epoch 16185, Loss: 428.6056823730469, Neurons: 11, Grad norm: 1.827e+02\n",
      "Epoch 16186, Loss: 428.6023864746094, Neurons: 11, Grad norm: 1.515e+02\n",
      "Epoch 16187, Loss: 428.5989990234375, Neurons: 11, Grad norm: 1.105e+02\n",
      "Epoch 16188, Loss: 428.5954895019531, Neurons: 11, Grad norm: 6.416e+01\n",
      "Epoch 16189, Loss: 428.5921936035156, Neurons: 11, Grad norm: 1.683e+01\n",
      "Epoch 16190, Loss: 428.5892028808594, Neurons: 11, Grad norm: 2.675e+01\n",
      "Epoch 16191, Loss: 428.5865783691406, Neurons: 11, Grad norm: 6.584e+01\n",
      "Epoch 16192, Loss: 428.5841369628906, Neurons: 11, Grad norm: 9.339e+01\n",
      "Epoch 16193, Loss: 428.581787109375, Neurons: 11, Grad norm: 1.108e+02\n",
      "Epoch 16194, Loss: 428.5793762207031, Neurons: 11, Grad norm: 1.166e+02\n",
      "Epoch 16195, Loss: 428.5767822265625, Neurons: 11, Grad norm: 1.108e+02\n",
      "Epoch 16196, Loss: 428.573974609375, Neurons: 11, Grad norm: 9.516e+01\n",
      "Epoch 16197, Loss: 428.5710754394531, Neurons: 11, Grad norm: 7.236e+01\n",
      "Epoch 16198, Loss: 428.56817626953125, Neurons: 11, Grad norm: 4.306e+01\n",
      "Epoch 16199, Loss: 428.565185546875, Neurons: 11, Grad norm: 1.415e+01\n",
      "Epoch 16199, Test loss: 425.3011474609375\n",
      "Epoch 16200, Loss: 428.5623779296875, Neurons: 11, Grad norm: 1.536e+01\n",
      "Epoch 16201, Loss: 428.55975341796875, Neurons: 11, Grad norm: 4.035e+01\n",
      "Epoch 16202, Loss: 428.55712890625, Neurons: 11, Grad norm: 5.932e+01\n",
      "Epoch 16203, Loss: 428.5545959472656, Neurons: 11, Grad norm: 7.092e+01\n",
      "Epoch 16204, Loss: 428.5520324707031, Neurons: 11, Grad norm: 7.485e+01\n",
      "Epoch 16205, Loss: 428.54937744140625, Neurons: 11, Grad norm: 7.056e+01\n",
      "Epoch 16206, Loss: 428.546630859375, Neurons: 11, Grad norm: 6.100e+01\n",
      "Epoch 16207, Loss: 428.54388427734375, Neurons: 11, Grad norm: 4.539e+01\n",
      "Epoch 16208, Loss: 428.54107666015625, Neurons: 11, Grad norm: 2.838e+01\n",
      "Epoch 16209, Loss: 428.5382995605469, Neurons: 11, Grad norm: 9.931e+00\n",
      "Epoch 16210, Loss: 428.5355529785156, Neurons: 11, Grad norm: 6.940e+00\n",
      "Epoch 16211, Loss: 428.5328369140625, Neurons: 11, Grad norm: 2.191e+01\n",
      "Epoch 16212, Loss: 428.5301818847656, Neurons: 11, Grad norm: 3.295e+01\n",
      "Epoch 16213, Loss: 428.52752685546875, Neurons: 11, Grad norm: 3.989e+01\n",
      "Epoch 16214, Loss: 428.52490234375, Neurons: 11, Grad norm: 4.305e+01\n",
      "Epoch 16215, Loss: 428.5221862792969, Neurons: 11, Grad norm: 4.269e+01\n",
      "Epoch 16216, Loss: 428.5195007324219, Neurons: 11, Grad norm: 3.682e+01\n",
      "Epoch 16217, Loss: 428.5167541503906, Neurons: 11, Grad norm: 2.959e+01\n",
      "Epoch 16218, Loss: 428.51397705078125, Neurons: 11, Grad norm: 1.911e+01\n",
      "Epoch 16219, Loss: 428.5111999511719, Neurons: 11, Grad norm: 8.742e+00\n",
      "Epoch 16220, Loss: 428.50848388671875, Neurons: 11, Grad norm: 2.367e+00\n",
      "Epoch 16221, Loss: 428.50579833984375, Neurons: 11, Grad norm: 1.124e+01\n",
      "Epoch 16222, Loss: 428.5030822753906, Neurons: 11, Grad norm: 1.868e+01\n",
      "Epoch 16223, Loss: 428.5003967285156, Neurons: 11, Grad norm: 2.343e+01\n",
      "Epoch 16224, Loss: 428.4976806640625, Neurons: 11, Grad norm: 2.660e+01\n",
      "Epoch 16225, Loss: 428.4949951171875, Neurons: 11, Grad norm: 2.624e+01\n",
      "Epoch 16226, Loss: 428.49224853515625, Neurons: 11, Grad norm: 2.614e+01\n",
      "Epoch 16227, Loss: 428.489501953125, Neurons: 11, Grad norm: 2.336e+01\n",
      "Epoch 16228, Loss: 428.4867858886719, Neurons: 11, Grad norm: 1.919e+01\n",
      "Epoch 16229, Loss: 428.4840393066406, Neurons: 11, Grad norm: 1.405e+01\n",
      "Epoch 16230, Loss: 428.4812927246094, Neurons: 11, Grad norm: 8.307e+00\n",
      "Epoch 16231, Loss: 428.47857666015625, Neurons: 11, Grad norm: 2.487e+00\n",
      "Epoch 16232, Loss: 428.4757995605469, Neurons: 11, Grad norm: 2.164e+00\n",
      "Epoch 16233, Loss: 428.47308349609375, Neurons: 11, Grad norm: 6.803e+00\n",
      "Epoch 16234, Loss: 428.47039794921875, Neurons: 11, Grad norm: 9.444e+00\n",
      "Epoch 16235, Loss: 428.46759033203125, Neurons: 11, Grad norm: 1.064e+01\n",
      "Epoch 16236, Loss: 428.4648742675781, Neurons: 11, Grad norm: 1.165e+01\n",
      "Epoch 16237, Loss: 428.46209716796875, Neurons: 11, Grad norm: 1.164e+01\n",
      "Epoch 16238, Loss: 428.4593811035156, Neurons: 11, Grad norm: 1.061e+01\n",
      "Epoch 16239, Loss: 428.45660400390625, Neurons: 11, Grad norm: 1.137e+01\n",
      "Epoch 16240, Loss: 428.4538879394531, Neurons: 11, Grad norm: 9.213e+00\n",
      "Epoch 16241, Loss: 428.4510803222656, Neurons: 11, Grad norm: 8.269e+00\n",
      "Epoch 16242, Loss: 428.4483337402344, Neurons: 11, Grad norm: 6.261e+00\n",
      "Epoch 16243, Loss: 428.4455871582031, Neurons: 11, Grad norm: 4.067e+00\n",
      "Epoch 16244, Loss: 428.4428405761719, Neurons: 11, Grad norm: 3.512e+00\n",
      "Epoch 16245, Loss: 428.4400939941406, Neurons: 11, Grad norm: 3.209e+00\n",
      "Epoch 16246, Loss: 428.4372863769531, Neurons: 11, Grad norm: 1.861e+00\n",
      "Epoch 16247, Loss: 428.4344787597656, Neurons: 11, Grad norm: 1.889e+00\n",
      "Epoch 16248, Loss: 428.4317321777344, Neurons: 11, Grad norm: 1.559e+00\n",
      "Epoch 16249, Loss: 428.4289855957031, Neurons: 11, Grad norm: 1.703e+00\n",
      "Epoch 16249, Test loss: 425.1748352050781\n",
      "Epoch 16250, Loss: 428.4261779785156, Neurons: 11, Grad norm: 1.515e+00\n",
      "Epoch 16251, Loss: 428.42340087890625, Neurons: 11, Grad norm: 1.457e+00\n",
      "Epoch 16252, Loss: 428.420654296875, Neurons: 11, Grad norm: 1.534e+00\n",
      "Epoch 16253, Loss: 428.4178771972656, Neurons: 11, Grad norm: 1.798e+00\n",
      "Epoch 16254, Loss: 428.41510009765625, Neurons: 11, Grad norm: 1.742e+00\n",
      "Epoch 16255, Loss: 428.41229248046875, Neurons: 11, Grad norm: 2.139e+00\n",
      "Epoch 16256, Loss: 428.40948486328125, Neurons: 11, Grad norm: 1.995e+00\n",
      "Epoch 16257, Loss: 428.40673828125, Neurons: 11, Grad norm: 3.551e+00\n",
      "Epoch 16258, Loss: 428.4039306640625, Neurons: 11, Grad norm: 4.708e+00\n",
      "Epoch 16259, Loss: 428.4011535644531, Neurons: 11, Grad norm: 5.751e+00\n",
      "Epoch 16260, Loss: 428.3983459472656, Neurons: 11, Grad norm: 6.728e+00\n",
      "Epoch 16261, Loss: 428.3955383300781, Neurons: 11, Grad norm: 7.679e+00\n",
      "Epoch 16262, Loss: 428.3927917480469, Neurons: 11, Grad norm: 7.796e+00\n",
      "Epoch 16263, Loss: 428.389892578125, Neurons: 11, Grad norm: 9.807e+00\n",
      "Epoch 16264, Loss: 428.38714599609375, Neurons: 11, Grad norm: 9.480e+00\n",
      "Epoch 16265, Loss: 428.38427734375, Neurons: 11, Grad norm: 1.025e+01\n",
      "Epoch 16266, Loss: 428.3815002441406, Neurons: 11, Grad norm: 1.147e+01\n",
      "Epoch 16267, Loss: 428.3786926269531, Neurons: 11, Grad norm: 1.167e+01\n",
      "Epoch 16268, Loss: 428.3758850097656, Neurons: 11, Grad norm: 1.194e+01\n",
      "Epoch 16269, Loss: 428.3730773925781, Neurons: 11, Grad norm: 1.247e+01\n",
      "Epoch 16270, Loss: 428.3702392578125, Neurons: 11, Grad norm: 1.027e+01\n",
      "Epoch 16271, Loss: 428.367431640625, Neurons: 11, Grad norm: 1.061e+01\n",
      "Epoch 16272, Loss: 428.3645324707031, Neurons: 11, Grad norm: 9.282e+00\n",
      "Epoch 16273, Loss: 428.3617858886719, Neurons: 11, Grad norm: 8.536e+00\n",
      "Epoch 16274, Loss: 428.35888671875, Neurons: 11, Grad norm: 8.128e+00\n",
      "Epoch 16275, Loss: 428.3560791015625, Neurons: 11, Grad norm: 7.216e+00\n",
      "Epoch 16276, Loss: 428.3533020019531, Neurons: 11, Grad norm: 7.725e+00\n",
      "Epoch 16277, Loss: 428.35040283203125, Neurons: 11, Grad norm: 9.330e+00\n",
      "Epoch 16278, Loss: 428.3475341796875, Neurons: 11, Grad norm: 8.959e+00\n",
      "Epoch 16279, Loss: 428.34478759765625, Neurons: 11, Grad norm: 1.093e+01\n",
      "Epoch 16280, Loss: 428.3418884277344, Neurons: 11, Grad norm: 1.100e+01\n",
      "Epoch 16281, Loss: 428.3390808105469, Neurons: 11, Grad norm: 1.212e+01\n",
      "Epoch 16282, Loss: 428.336181640625, Neurons: 11, Grad norm: 1.458e+01\n",
      "Epoch 16283, Loss: 428.3333740234375, Neurons: 11, Grad norm: 1.689e+01\n",
      "Epoch 16284, Loss: 428.3304748535156, Neurons: 11, Grad norm: 1.904e+01\n",
      "Epoch 16285, Loss: 428.32763671875, Neurons: 11, Grad norm: 2.172e+01\n",
      "Epoch 16286, Loss: 428.3247985839844, Neurons: 11, Grad norm: 2.341e+01\n",
      "Epoch 16287, Loss: 428.3219299316406, Neurons: 11, Grad norm: 2.770e+01\n",
      "Epoch 16288, Loss: 428.319091796875, Neurons: 11, Grad norm: 3.141e+01\n",
      "Epoch 16289, Loss: 428.3162841796875, Neurons: 11, Grad norm: 3.689e+01\n",
      "Epoch 16290, Loss: 428.3134460449219, Neurons: 11, Grad norm: 4.303e+01\n",
      "Epoch 16291, Loss: 428.3105773925781, Neurons: 11, Grad norm: 4.885e+01\n",
      "Epoch 16292, Loss: 428.30780029296875, Neurons: 11, Grad norm: 5.533e+01\n",
      "Epoch 16293, Loss: 428.304931640625, Neurons: 11, Grad norm: 6.421e+01\n",
      "Epoch 16294, Loss: 428.3021240234375, Neurons: 11, Grad norm: 7.287e+01\n",
      "Epoch 16295, Loss: 428.29937744140625, Neurons: 11, Grad norm: 8.464e+01\n",
      "Epoch 16296, Loss: 428.2966003417969, Neurons: 11, Grad norm: 9.797e+01\n",
      "Epoch 16297, Loss: 428.29388427734375, Neurons: 11, Grad norm: 1.136e+02\n",
      "Epoch 16298, Loss: 428.2912902832031, Neurons: 11, Grad norm: 1.308e+02\n",
      "Epoch 16299, Loss: 428.2887878417969, Neurons: 11, Grad norm: 1.508e+02\n",
      "Epoch 16299, Test loss: 425.0102844238281\n",
      "Epoch 16300, Loss: 428.2862854003906, Neurons: 11, Grad norm: 1.702e+02\n",
      "Epoch 16301, Loss: 428.28399658203125, Neurons: 11, Grad norm: 1.907e+02\n",
      "Epoch 16302, Loss: 428.28167724609375, Neurons: 11, Grad norm: 2.093e+02\n",
      "Epoch 16303, Loss: 428.2793884277344, Neurons: 11, Grad norm: 2.232e+02\n",
      "Epoch 16304, Loss: 428.2769775390625, Neurons: 11, Grad norm: 2.297e+02\n",
      "Epoch 16305, Loss: 428.2743835449219, Neurons: 11, Grad norm: 2.255e+02\n",
      "Epoch 16306, Loss: 428.2713928222656, Neurons: 11, Grad norm: 2.063e+02\n",
      "Epoch 16307, Loss: 428.2679748535156, Neurons: 11, Grad norm: 1.746e+02\n",
      "Epoch 16308, Loss: 428.2642822265625, Neurons: 11, Grad norm: 1.283e+02\n",
      "Epoch 16309, Loss: 428.2603759765625, Neurons: 11, Grad norm: 7.488e+01\n",
      "Epoch 16310, Loss: 428.2568359375, Neurons: 11, Grad norm: 1.884e+01\n",
      "Epoch 16311, Loss: 428.2536926269531, Neurons: 11, Grad norm: 3.389e+01\n",
      "Epoch 16312, Loss: 428.2509460449219, Neurons: 11, Grad norm: 7.750e+01\n",
      "Epoch 16313, Loss: 428.24853515625, Neurons: 11, Grad norm: 1.090e+02\n",
      "Epoch 16314, Loss: 428.2461853027344, Neurons: 11, Grad norm: 1.281e+02\n",
      "Epoch 16315, Loss: 428.2437438964844, Neurons: 11, Grad norm: 1.305e+02\n",
      "Epoch 16316, Loss: 428.24102783203125, Neurons: 11, Grad norm: 1.200e+02\n",
      "Epoch 16317, Loss: 428.238037109375, Neurons: 11, Grad norm: 9.630e+01\n",
      "Epoch 16318, Loss: 428.2348937988281, Neurons: 11, Grad norm: 6.390e+01\n",
      "Epoch 16319, Loss: 428.231689453125, Neurons: 11, Grad norm: 2.772e+01\n",
      "Epoch 16320, Loss: 428.22869873046875, Neurons: 11, Grad norm: 8.288e+00\n",
      "Epoch 16321, Loss: 428.225830078125, Neurons: 11, Grad norm: 4.034e+01\n",
      "Epoch 16322, Loss: 428.2231750488281, Neurons: 11, Grad norm: 6.287e+01\n",
      "Epoch 16323, Loss: 428.2205810546875, Neurons: 11, Grad norm: 7.760e+01\n",
      "Epoch 16324, Loss: 428.2179260253906, Neurons: 11, Grad norm: 8.038e+01\n",
      "Epoch 16325, Loss: 428.2151794433594, Neurons: 11, Grad norm: 7.378e+01\n",
      "Epoch 16326, Loss: 428.2122802734375, Neurons: 11, Grad norm: 6.030e+01\n",
      "Epoch 16327, Loss: 428.2093811035156, Neurons: 11, Grad norm: 4.129e+01\n",
      "Epoch 16328, Loss: 428.20648193359375, Neurons: 11, Grad norm: 1.910e+01\n",
      "Epoch 16329, Loss: 428.2035827636719, Neurons: 11, Grad norm: 2.186e+00\n",
      "Epoch 16330, Loss: 428.2007751464844, Neurons: 11, Grad norm: 2.188e+01\n",
      "Epoch 16331, Loss: 428.1980285644531, Neurons: 11, Grad norm: 3.711e+01\n",
      "Epoch 16332, Loss: 428.1952819824219, Neurons: 11, Grad norm: 4.766e+01\n",
      "Epoch 16333, Loss: 428.1925964355469, Neurons: 11, Grad norm: 5.178e+01\n",
      "Epoch 16334, Loss: 428.1897888183594, Neurons: 11, Grad norm: 5.022e+01\n",
      "Epoch 16335, Loss: 428.1869812011719, Neurons: 11, Grad norm: 4.325e+01\n",
      "Epoch 16336, Loss: 428.18414306640625, Neurons: 11, Grad norm: 3.305e+01\n",
      "Epoch 16337, Loss: 428.1812744140625, Neurons: 11, Grad norm: 1.992e+01\n",
      "Epoch 16338, Loss: 428.1783752441406, Neurons: 11, Grad norm: 7.300e+00\n",
      "Epoch 16339, Loss: 428.175537109375, Neurons: 11, Grad norm: 6.656e+00\n",
      "Epoch 16340, Loss: 428.17279052734375, Neurons: 11, Grad norm: 1.703e+01\n",
      "Epoch 16341, Loss: 428.16998291015625, Neurons: 11, Grad norm: 2.510e+01\n",
      "Epoch 16342, Loss: 428.16717529296875, Neurons: 11, Grad norm: 3.073e+01\n",
      "Epoch 16343, Loss: 428.1643981933594, Neurons: 11, Grad norm: 3.297e+01\n",
      "Epoch 16344, Loss: 428.1615295410156, Neurons: 11, Grad norm: 3.063e+01\n",
      "Epoch 16345, Loss: 428.15875244140625, Neurons: 11, Grad norm: 2.636e+01\n",
      "Epoch 16346, Loss: 428.1558837890625, Neurons: 11, Grad norm: 1.869e+01\n",
      "Epoch 16347, Loss: 428.1529846191406, Neurons: 11, Grad norm: 1.089e+01\n",
      "Epoch 16348, Loss: 428.1501770019531, Neurons: 11, Grad norm: 2.439e+00\n",
      "Epoch 16349, Loss: 428.1473388671875, Neurons: 11, Grad norm: 5.945e+00\n",
      "Epoch 16349, Test loss: 424.907958984375\n",
      "Epoch 16350, Loss: 428.1445007324219, Neurons: 11, Grad norm: 1.246e+01\n",
      "Epoch 16351, Loss: 428.1416931152344, Neurons: 11, Grad norm: 1.690e+01\n",
      "Epoch 16352, Loss: 428.1388244628906, Neurons: 11, Grad norm: 1.969e+01\n",
      "Epoch 16353, Loss: 428.135986328125, Neurons: 11, Grad norm: 1.964e+01\n",
      "Epoch 16354, Loss: 428.1331787109375, Neurons: 11, Grad norm: 1.979e+01\n",
      "Epoch 16355, Loss: 428.1303405761719, Neurons: 11, Grad norm: 1.763e+01\n",
      "Epoch 16356, Loss: 428.12750244140625, Neurons: 11, Grad norm: 1.425e+01\n",
      "Epoch 16357, Loss: 428.1246032714844, Neurons: 11, Grad norm: 9.842e+00\n",
      "Epoch 16358, Loss: 428.1217956542969, Neurons: 11, Grad norm: 5.414e+00\n",
      "Epoch 16359, Loss: 428.118896484375, Neurons: 11, Grad norm: 1.464e+00\n",
      "Epoch 16360, Loss: 428.1159973144531, Neurons: 11, Grad norm: 2.614e+00\n",
      "Epoch 16361, Loss: 428.1131896972656, Neurons: 11, Grad norm: 6.196e+00\n",
      "Epoch 16362, Loss: 428.11029052734375, Neurons: 11, Grad norm: 8.103e+00\n",
      "Epoch 16363, Loss: 428.1073913574219, Neurons: 11, Grad norm: 8.441e+00\n",
      "Epoch 16364, Loss: 428.1044921875, Neurons: 11, Grad norm: 8.868e+00\n",
      "Epoch 16365, Loss: 428.1016845703125, Neurons: 11, Grad norm: 8.251e+00\n",
      "Epoch 16366, Loss: 428.0987854003906, Neurons: 11, Grad norm: 5.293e+00\n",
      "Epoch 16367, Loss: 428.09588623046875, Neurons: 11, Grad norm: 4.369e+00\n",
      "Epoch 16368, Loss: 428.09307861328125, Neurons: 11, Grad norm: 1.908e+00\n",
      "Epoch 16369, Loss: 428.0901794433594, Neurons: 11, Grad norm: 1.537e+00\n",
      "Epoch 16370, Loss: 428.0872802734375, Neurons: 11, Grad norm: 1.689e+00\n",
      "Epoch 16371, Loss: 428.0843811035156, Neurons: 11, Grad norm: 2.568e+00\n",
      "Epoch 16372, Loss: 428.08148193359375, Neurons: 11, Grad norm: 4.241e+00\n",
      "Epoch 16373, Loss: 428.0785827636719, Neurons: 11, Grad norm: 4.422e+00\n",
      "Epoch 16374, Loss: 428.07568359375, Neurons: 11, Grad norm: 5.757e+00\n",
      "Epoch 16375, Loss: 428.0728454589844, Neurons: 11, Grad norm: 5.424e+00\n",
      "Epoch 16376, Loss: 428.06988525390625, Neurons: 11, Grad norm: 5.634e+00\n",
      "Epoch 16377, Loss: 428.0669860839844, Neurons: 11, Grad norm: 5.155e+00\n",
      "Epoch 16378, Loss: 428.0640869140625, Neurons: 11, Grad norm: 4.570e+00\n",
      "Epoch 16379, Loss: 428.0611877441406, Neurons: 11, Grad norm: 3.737e+00\n",
      "Epoch 16380, Loss: 428.05828857421875, Neurons: 11, Grad norm: 3.025e+00\n",
      "Epoch 16381, Loss: 428.0553894042969, Neurons: 11, Grad norm: 1.822e+00\n",
      "Epoch 16382, Loss: 428.05242919921875, Neurons: 11, Grad norm: 1.559e+00\n",
      "Epoch 16383, Loss: 428.04949951171875, Neurons: 11, Grad norm: 1.779e+00\n",
      "Epoch 16384, Loss: 428.0466003417969, Neurons: 11, Grad norm: 2.102e+00\n",
      "Epoch 16385, Loss: 428.04364013671875, Neurons: 11, Grad norm: 2.933e+00\n",
      "Epoch 16386, Loss: 428.0407409667969, Neurons: 11, Grad norm: 3.315e+00\n",
      "Epoch 16387, Loss: 428.03778076171875, Neurons: 11, Grad norm: 3.704e+00\n",
      "Epoch 16388, Loss: 428.0348815917969, Neurons: 11, Grad norm: 3.875e+00\n",
      "Epoch 16389, Loss: 428.031982421875, Neurons: 11, Grad norm: 5.413e+00\n",
      "Epoch 16390, Loss: 428.02899169921875, Neurons: 11, Grad norm: 5.370e+00\n",
      "Epoch 16391, Loss: 428.0260314941406, Neurons: 11, Grad norm: 6.261e+00\n",
      "Epoch 16392, Loss: 428.02313232421875, Neurons: 11, Grad norm: 7.552e+00\n",
      "Epoch 16393, Loss: 428.02020263671875, Neurons: 11, Grad norm: 7.945e+00\n",
      "Epoch 16394, Loss: 428.0172424316406, Neurons: 11, Grad norm: 7.996e+00\n",
      "Epoch 16395, Loss: 428.0142822265625, Neurons: 11, Grad norm: 9.860e+00\n",
      "Epoch 16396, Loss: 428.01129150390625, Neurons: 11, Grad norm: 1.042e+01\n",
      "Epoch 16397, Loss: 428.0083923339844, Neurons: 11, Grad norm: 1.271e+01\n",
      "Epoch 16398, Loss: 428.00543212890625, Neurons: 11, Grad norm: 1.445e+01\n",
      "Epoch 16399, Loss: 428.00244140625, Neurons: 11, Grad norm: 1.665e+01\n",
      "Epoch 16399, Test loss: 424.76519775390625\n",
      "Epoch 16400, Loss: 427.9994812011719, Neurons: 11, Grad norm: 1.782e+01\n",
      "Epoch 16401, Loss: 427.99658203125, Neurons: 11, Grad norm: 1.873e+01\n",
      "Epoch 16402, Loss: 427.99359130859375, Neurons: 11, Grad norm: 1.897e+01\n",
      "Epoch 16403, Loss: 427.9906005859375, Neurons: 11, Grad norm: 1.946e+01\n",
      "Epoch 16404, Loss: 427.9876403808594, Neurons: 11, Grad norm: 2.016e+01\n",
      "Epoch 16405, Loss: 427.9846496582031, Neurons: 11, Grad norm: 2.205e+01\n",
      "Epoch 16406, Loss: 427.98162841796875, Neurons: 11, Grad norm: 2.175e+01\n",
      "Epoch 16407, Loss: 427.97869873046875, Neurons: 11, Grad norm: 2.265e+01\n",
      "Epoch 16408, Loss: 427.9756774902344, Neurons: 11, Grad norm: 2.235e+01\n",
      "Epoch 16409, Loss: 427.9726867675781, Neurons: 11, Grad norm: 2.207e+01\n",
      "Epoch 16410, Loss: 427.9696960449219, Neurons: 11, Grad norm: 2.184e+01\n",
      "Epoch 16411, Loss: 427.9666748046875, Neurons: 11, Grad norm: 2.132e+01\n",
      "Epoch 16412, Loss: 427.96368408203125, Neurons: 11, Grad norm: 2.042e+01\n",
      "Epoch 16413, Loss: 427.960693359375, Neurons: 11, Grad norm: 2.010e+01\n",
      "Epoch 16414, Loss: 427.9577941894531, Neurons: 11, Grad norm: 1.872e+01\n",
      "Epoch 16415, Loss: 427.9546813964844, Neurons: 11, Grad norm: 1.993e+01\n",
      "Epoch 16416, Loss: 427.9516906738281, Neurons: 11, Grad norm: 2.050e+01\n",
      "Epoch 16417, Loss: 427.9486999511719, Neurons: 11, Grad norm: 2.104e+01\n",
      "Epoch 16418, Loss: 427.94573974609375, Neurons: 11, Grad norm: 2.191e+01\n",
      "Epoch 16419, Loss: 427.94268798828125, Neurons: 11, Grad norm: 2.265e+01\n",
      "Epoch 16420, Loss: 427.939697265625, Neurons: 11, Grad norm: 2.338e+01\n",
      "Epoch 16421, Loss: 427.9366455078125, Neurons: 11, Grad norm: 2.628e+01\n",
      "Epoch 16422, Loss: 427.93359375, Neurons: 11, Grad norm: 2.737e+01\n",
      "Epoch 16423, Loss: 427.93060302734375, Neurons: 11, Grad norm: 3.012e+01\n",
      "Epoch 16424, Loss: 427.9275817871094, Neurons: 11, Grad norm: 3.376e+01\n",
      "Epoch 16425, Loss: 427.9245910644531, Neurons: 11, Grad norm: 3.813e+01\n",
      "Epoch 16426, Loss: 427.9216003417969, Neurons: 11, Grad norm: 4.349e+01\n",
      "Epoch 16427, Loss: 427.9185791015625, Neurons: 11, Grad norm: 5.019e+01\n",
      "Epoch 16428, Loss: 427.91558837890625, Neurons: 11, Grad norm: 5.689e+01\n",
      "Epoch 16429, Loss: 427.91259765625, Neurons: 11, Grad norm: 6.584e+01\n",
      "Epoch 16430, Loss: 427.9096374511719, Neurons: 11, Grad norm: 7.459e+01\n",
      "Epoch 16431, Loss: 427.90667724609375, Neurons: 11, Grad norm: 8.542e+01\n",
      "Epoch 16432, Loss: 427.9037780761719, Neurons: 11, Grad norm: 9.696e+01\n",
      "Epoch 16433, Loss: 427.90087890625, Neurons: 11, Grad norm: 1.109e+02\n",
      "Epoch 16434, Loss: 427.8981018066406, Neurons: 11, Grad norm: 1.260e+02\n",
      "Epoch 16435, Loss: 427.8952941894531, Neurons: 11, Grad norm: 1.420e+02\n",
      "Epoch 16436, Loss: 427.892578125, Neurons: 11, Grad norm: 1.579e+02\n",
      "Epoch 16437, Loss: 427.889892578125, Neurons: 11, Grad norm: 1.746e+02\n",
      "Epoch 16438, Loss: 427.8872985839844, Neurons: 11, Grad norm: 1.892e+02\n",
      "Epoch 16439, Loss: 427.8846740722656, Neurons: 11, Grad norm: 2.010e+02\n",
      "Epoch 16440, Loss: 427.8820495605469, Neurons: 11, Grad norm: 2.055e+02\n",
      "Epoch 16441, Loss: 427.8791809082031, Neurons: 11, Grad norm: 2.021e+02\n",
      "Epoch 16442, Loss: 427.8760986328125, Neurons: 11, Grad norm: 1.873e+02\n",
      "Epoch 16443, Loss: 427.8726806640625, Neurons: 11, Grad norm: 1.622e+02\n",
      "Epoch 16444, Loss: 427.8690490722656, Neurons: 11, Grad norm: 1.273e+02\n",
      "Epoch 16445, Loss: 427.86529541015625, Neurons: 11, Grad norm: 8.531e+01\n",
      "Epoch 16446, Loss: 427.8616027832031, Neurons: 11, Grad norm: 3.971e+01\n",
      "Epoch 16447, Loss: 427.8582458496094, Neurons: 11, Grad norm: 3.602e+00\n",
      "Epoch 16448, Loss: 427.8551025390625, Neurons: 11, Grad norm: 4.353e+01\n",
      "Epoch 16449, Loss: 427.852294921875, Neurons: 11, Grad norm: 7.541e+01\n",
      "Epoch 16449, Test loss: 424.64215087890625\n",
      "Epoch 16450, Loss: 427.8497009277344, Neurons: 11, Grad norm: 9.741e+01\n",
      "Epoch 16451, Loss: 427.8469543457031, Neurons: 11, Grad norm: 1.082e+02\n",
      "Epoch 16452, Loss: 427.84417724609375, Neurons: 11, Grad norm: 1.076e+02\n",
      "Epoch 16453, Loss: 427.8411865234375, Neurons: 11, Grad norm: 9.732e+01\n",
      "Epoch 16454, Loss: 427.8380432128906, Neurons: 11, Grad norm: 7.957e+01\n",
      "Epoch 16455, Loss: 427.83477783203125, Neurons: 11, Grad norm: 5.400e+01\n",
      "Epoch 16456, Loss: 427.83160400390625, Neurons: 11, Grad norm: 2.733e+01\n",
      "Epoch 16457, Loss: 427.82843017578125, Neurons: 11, Grad norm: 1.428e+00\n",
      "Epoch 16458, Loss: 427.825439453125, Neurons: 11, Grad norm: 2.352e+01\n",
      "Epoch 16459, Loss: 427.8224792480469, Neurons: 11, Grad norm: 4.245e+01\n",
      "Epoch 16460, Loss: 427.819580078125, Neurons: 11, Grad norm: 5.629e+01\n",
      "Epoch 16461, Loss: 427.8167419433594, Neurons: 11, Grad norm: 6.326e+01\n",
      "Epoch 16462, Loss: 427.81378173828125, Neurons: 11, Grad norm: 6.342e+01\n",
      "Epoch 16463, Loss: 427.81085205078125, Neurons: 11, Grad norm: 5.862e+01\n",
      "Epoch 16464, Loss: 427.80780029296875, Neurons: 11, Grad norm: 4.755e+01\n",
      "Epoch 16465, Loss: 427.8046875, Neurons: 11, Grad norm: 3.597e+01\n",
      "Epoch 16466, Loss: 427.80169677734375, Neurons: 11, Grad norm: 2.078e+01\n",
      "Epoch 16467, Loss: 427.798583984375, Neurons: 11, Grad norm: 5.300e+00\n",
      "Epoch 16468, Loss: 427.79559326171875, Neurons: 11, Grad norm: 9.119e+00\n",
      "Epoch 16469, Loss: 427.79254150390625, Neurons: 11, Grad norm: 2.266e+01\n",
      "Epoch 16470, Loss: 427.7895812988281, Neurons: 11, Grad norm: 3.322e+01\n",
      "Epoch 16471, Loss: 427.7866516113281, Neurons: 11, Grad norm: 3.980e+01\n",
      "Epoch 16472, Loss: 427.78369140625, Neurons: 11, Grad norm: 4.423e+01\n",
      "Epoch 16473, Loss: 427.78070068359375, Neurons: 11, Grad norm: 4.176e+01\n",
      "Epoch 16474, Loss: 427.7776794433594, Neurons: 11, Grad norm: 3.854e+01\n",
      "Epoch 16475, Loss: 427.77459716796875, Neurons: 11, Grad norm: 3.193e+01\n",
      "Epoch 16476, Loss: 427.7715759277344, Neurons: 11, Grad norm: 2.209e+01\n",
      "Epoch 16477, Loss: 427.76849365234375, Neurons: 11, Grad norm: 1.262e+01\n",
      "Epoch 16478, Loss: 427.7655029296875, Neurons: 11, Grad norm: 2.494e+00\n",
      "Epoch 16479, Loss: 427.76239013671875, Neurons: 11, Grad norm: 8.067e+00\n",
      "Epoch 16480, Loss: 427.7593994140625, Neurons: 11, Grad norm: 1.500e+01\n",
      "Epoch 16481, Loss: 427.7563781738281, Neurons: 11, Grad norm: 2.326e+01\n",
      "Epoch 16482, Loss: 427.7533874511719, Neurons: 11, Grad norm: 2.742e+01\n",
      "Epoch 16483, Loss: 427.7503967285156, Neurons: 11, Grad norm: 3.080e+01\n",
      "Epoch 16484, Loss: 427.7472839355469, Neurons: 11, Grad norm: 3.200e+01\n",
      "Epoch 16485, Loss: 427.7442932128906, Neurons: 11, Grad norm: 2.931e+01\n",
      "Epoch 16486, Loss: 427.7411804199219, Neurons: 11, Grad norm: 2.565e+01\n",
      "Epoch 16487, Loss: 427.7381286621094, Neurons: 11, Grad norm: 2.032e+01\n",
      "Epoch 16488, Loss: 427.7350769042969, Neurons: 11, Grad norm: 1.308e+01\n",
      "Epoch 16489, Loss: 427.73199462890625, Neurons: 11, Grad norm: 8.442e+00\n",
      "Epoch 16490, Loss: 427.72900390625, Neurons: 11, Grad norm: 1.773e+00\n",
      "Epoch 16491, Loss: 427.72589111328125, Neurons: 11, Grad norm: 4.329e+00\n",
      "Epoch 16492, Loss: 427.7227783203125, Neurons: 11, Grad norm: 8.703e+00\n",
      "Epoch 16493, Loss: 427.71978759765625, Neurons: 11, Grad norm: 1.416e+01\n",
      "Epoch 16494, Loss: 427.71673583984375, Neurons: 11, Grad norm: 1.646e+01\n",
      "Epoch 16495, Loss: 427.71368408203125, Neurons: 11, Grad norm: 1.810e+01\n",
      "Epoch 16496, Loss: 427.7106018066406, Neurons: 11, Grad norm: 2.059e+01\n",
      "Epoch 16497, Loss: 427.7074890136719, Neurons: 11, Grad norm: 1.871e+01\n",
      "Epoch 16498, Loss: 427.7044372558594, Neurons: 11, Grad norm: 1.830e+01\n",
      "Epoch 16499, Loss: 427.7013244628906, Neurons: 11, Grad norm: 1.567e+01\n",
      "Epoch 16499, Test loss: 424.4843444824219\n",
      "Epoch 16500, Loss: 427.69830322265625, Neurons: 11, Grad norm: 1.250e+01\n",
      "Epoch 16501, Loss: 427.69512939453125, Neurons: 11, Grad norm: 9.897e+00\n",
      "Epoch 16502, Loss: 427.69207763671875, Neurons: 11, Grad norm: 6.206e+00\n",
      "Epoch 16503, Loss: 427.6889343261719, Neurons: 11, Grad norm: 4.171e+00\n",
      "Epoch 16504, Loss: 427.68585205078125, Neurons: 11, Grad norm: 3.379e+00\n",
      "Epoch 16505, Loss: 427.6827392578125, Neurons: 11, Grad norm: 1.479e+00\n",
      "Epoch 16506, Loss: 427.67962646484375, Neurons: 11, Grad norm: 1.503e+00\n",
      "Epoch 16507, Loss: 427.6764831542969, Neurons: 11, Grad norm: 2.732e+00\n",
      "Epoch 16508, Loss: 427.67340087890625, Neurons: 11, Grad norm: 3.648e+00\n",
      "Epoch 16509, Loss: 427.6702880859375, Neurons: 11, Grad norm: 3.904e+00\n",
      "Epoch 16510, Loss: 427.66717529296875, Neurons: 11, Grad norm: 4.884e+00\n",
      "Epoch 16511, Loss: 427.6640930175781, Neurons: 11, Grad norm: 4.847e+00\n",
      "Epoch 16512, Loss: 427.660888671875, Neurons: 11, Grad norm: 4.639e+00\n",
      "Epoch 16513, Loss: 427.65777587890625, Neurons: 11, Grad norm: 6.416e+00\n",
      "Epoch 16514, Loss: 427.6546936035156, Neurons: 11, Grad norm: 5.424e+00\n",
      "Epoch 16515, Loss: 427.65155029296875, Neurons: 11, Grad norm: 4.838e+00\n",
      "Epoch 16516, Loss: 427.64837646484375, Neurons: 11, Grad norm: 4.042e+00\n",
      "Epoch 16517, Loss: 427.6452331542969, Neurons: 11, Grad norm: 3.006e+00\n",
      "Epoch 16518, Loss: 427.64208984375, Neurons: 11, Grad norm: 2.233e+00\n",
      "Epoch 16519, Loss: 427.63897705078125, Neurons: 11, Grad norm: 1.636e+00\n",
      "Epoch 16520, Loss: 427.6358337402344, Neurons: 11, Grad norm: 2.388e+00\n",
      "Epoch 16521, Loss: 427.6326904296875, Neurons: 11, Grad norm: 2.898e+00\n",
      "Epoch 16522, Loss: 427.6294860839844, Neurons: 11, Grad norm: 4.477e+00\n",
      "Epoch 16523, Loss: 427.62640380859375, Neurons: 11, Grad norm: 6.571e+00\n",
      "Epoch 16524, Loss: 427.6231994628906, Neurons: 11, Grad norm: 7.531e+00\n",
      "Epoch 16525, Loss: 427.6200256347656, Neurons: 11, Grad norm: 8.657e+00\n",
      "Epoch 16526, Loss: 427.61688232421875, Neurons: 11, Grad norm: 1.119e+01\n",
      "Epoch 16527, Loss: 427.6136779785156, Neurons: 11, Grad norm: 1.142e+01\n",
      "Epoch 16528, Loss: 427.6105041503906, Neurons: 11, Grad norm: 1.288e+01\n",
      "Epoch 16529, Loss: 427.6073913574219, Neurons: 11, Grad norm: 1.316e+01\n",
      "Epoch 16530, Loss: 427.60418701171875, Neurons: 11, Grad norm: 1.346e+01\n",
      "Epoch 16531, Loss: 427.6009826660156, Neurons: 11, Grad norm: 1.390e+01\n",
      "Epoch 16532, Loss: 427.5977783203125, Neurons: 11, Grad norm: 1.406e+01\n",
      "Epoch 16533, Loss: 427.5946350097656, Neurons: 11, Grad norm: 1.515e+01\n",
      "Epoch 16534, Loss: 427.5914001464844, Neurons: 11, Grad norm: 1.735e+01\n",
      "Epoch 16535, Loss: 427.58819580078125, Neurons: 11, Grad norm: 1.747e+01\n",
      "Epoch 16536, Loss: 427.5850524902344, Neurons: 11, Grad norm: 1.934e+01\n",
      "Epoch 16537, Loss: 427.581787109375, Neurons: 11, Grad norm: 1.979e+01\n",
      "Epoch 16538, Loss: 427.5786437988281, Neurons: 11, Grad norm: 2.055e+01\n",
      "Epoch 16539, Loss: 427.57537841796875, Neurons: 11, Grad norm: 2.169e+01\n",
      "Epoch 16540, Loss: 427.5721740722656, Neurons: 11, Grad norm: 2.239e+01\n",
      "Epoch 16541, Loss: 427.5690002441406, Neurons: 11, Grad norm: 2.338e+01\n",
      "Epoch 16542, Loss: 427.5657958984375, Neurons: 11, Grad norm: 2.480e+01\n",
      "Epoch 16543, Loss: 427.5625915527344, Neurons: 11, Grad norm: 2.544e+01\n",
      "Epoch 16544, Loss: 427.5592956542969, Neurons: 11, Grad norm: 2.896e+01\n",
      "Epoch 16545, Loss: 427.55609130859375, Neurons: 11, Grad norm: 3.187e+01\n",
      "Epoch 16546, Loss: 427.5528869628906, Neurons: 11, Grad norm: 3.630e+01\n",
      "Epoch 16547, Loss: 427.5496520996094, Neurons: 11, Grad norm: 4.160e+01\n",
      "Epoch 16548, Loss: 427.54644775390625, Neurons: 11, Grad norm: 4.607e+01\n",
      "Epoch 16549, Loss: 427.5432434082031, Neurons: 11, Grad norm: 5.122e+01\n",
      "Epoch 16549, Test loss: 424.34088134765625\n",
      "Epoch 16550, Loss: 427.5400390625, Neurons: 11, Grad norm: 5.838e+01\n",
      "Epoch 16551, Loss: 427.5368957519531, Neurons: 11, Grad norm: 6.519e+01\n",
      "Epoch 16552, Loss: 427.53369140625, Neurons: 11, Grad norm: 7.465e+01\n",
      "Epoch 16553, Loss: 427.5304870605469, Neurons: 11, Grad norm: 8.413e+01\n",
      "Epoch 16554, Loss: 427.5273742675781, Neurons: 11, Grad norm: 9.515e+01\n",
      "Epoch 16555, Loss: 427.5242919921875, Neurons: 11, Grad norm: 1.071e+02\n",
      "Epoch 16556, Loss: 427.52117919921875, Neurons: 11, Grad norm: 1.211e+02\n",
      "Epoch 16557, Loss: 427.51824951171875, Neurons: 11, Grad norm: 1.371e+02\n",
      "Epoch 16558, Loss: 427.5152893066406, Neurons: 11, Grad norm: 1.543e+02\n",
      "Epoch 16559, Loss: 427.512451171875, Neurons: 11, Grad norm: 1.707e+02\n",
      "Epoch 16560, Loss: 427.50958251953125, Neurons: 11, Grad norm: 1.875e+02\n",
      "Epoch 16561, Loss: 427.50689697265625, Neurons: 11, Grad norm: 1.992e+02\n",
      "Epoch 16562, Loss: 427.5039978027344, Neurons: 11, Grad norm: 2.057e+02\n",
      "Epoch 16563, Loss: 427.5009765625, Neurons: 11, Grad norm: 2.028e+02\n",
      "Epoch 16564, Loss: 427.4976806640625, Neurons: 11, Grad norm: 1.878e+02\n",
      "Epoch 16565, Loss: 427.49407958984375, Neurons: 11, Grad norm: 1.615e+02\n",
      "Epoch 16566, Loss: 427.4902038574219, Neurons: 11, Grad norm: 1.253e+02\n",
      "Epoch 16567, Loss: 427.4861755371094, Neurons: 11, Grad norm: 8.042e+01\n",
      "Epoch 16568, Loss: 427.4823303222656, Neurons: 11, Grad norm: 3.483e+01\n",
      "Epoch 16569, Loss: 427.47869873046875, Neurons: 11, Grad norm: 1.078e+01\n",
      "Epoch 16570, Loss: 427.4754943847656, Neurons: 11, Grad norm: 5.025e+01\n",
      "Epoch 16571, Loss: 427.4725036621094, Neurons: 11, Grad norm: 8.054e+01\n",
      "Epoch 16572, Loss: 427.4696350097656, Neurons: 11, Grad norm: 1.016e+02\n",
      "Epoch 16573, Loss: 427.466796875, Neurons: 11, Grad norm: 1.119e+02\n",
      "Epoch 16574, Loss: 427.4637451171875, Neurons: 11, Grad norm: 1.102e+02\n",
      "Epoch 16575, Loss: 427.4606018066406, Neurons: 11, Grad norm: 9.944e+01\n",
      "Epoch 16576, Loss: 427.4571838378906, Neurons: 11, Grad norm: 7.916e+01\n",
      "Epoch 16577, Loss: 427.4537353515625, Neurons: 11, Grad norm: 5.435e+01\n",
      "Epoch 16578, Loss: 427.4502868652344, Neurons: 11, Grad norm: 2.562e+01\n",
      "Epoch 16579, Loss: 427.4469299316406, Neurons: 11, Grad norm: 2.640e+00\n",
      "Epoch 16580, Loss: 427.4436950683594, Neurons: 11, Grad norm: 2.614e+01\n",
      "Epoch 16581, Loss: 427.4405822753906, Neurons: 11, Grad norm: 4.569e+01\n",
      "Epoch 16582, Loss: 427.4375, Neurons: 11, Grad norm: 5.953e+01\n",
      "Epoch 16583, Loss: 427.4344482421875, Neurons: 11, Grad norm: 6.546e+01\n",
      "Epoch 16584, Loss: 427.4312744140625, Neurons: 11, Grad norm: 6.580e+01\n",
      "Epoch 16585, Loss: 427.4281311035156, Neurons: 11, Grad norm: 5.850e+01\n",
      "Epoch 16586, Loss: 427.4248962402344, Neurons: 11, Grad norm: 4.749e+01\n",
      "Epoch 16587, Loss: 427.4216003417969, Neurons: 11, Grad norm: 3.400e+01\n",
      "Epoch 16588, Loss: 427.4183044433594, Neurons: 11, Grad norm: 1.819e+01\n",
      "Epoch 16589, Loss: 427.41497802734375, Neurons: 11, Grad norm: 2.301e+00\n",
      "Epoch 16590, Loss: 427.41180419921875, Neurons: 11, Grad norm: 1.148e+01\n",
      "Epoch 16591, Loss: 427.4085998535156, Neurons: 11, Grad norm: 2.369e+01\n",
      "Epoch 16592, Loss: 427.4053955078125, Neurons: 11, Grad norm: 3.146e+01\n",
      "Epoch 16593, Loss: 427.4021911621094, Neurons: 11, Grad norm: 3.568e+01\n",
      "Epoch 16594, Loss: 427.3990478515625, Neurons: 11, Grad norm: 3.754e+01\n",
      "Epoch 16595, Loss: 427.3958435058594, Neurons: 11, Grad norm: 3.591e+01\n",
      "Epoch 16596, Loss: 427.392578125, Neurons: 11, Grad norm: 3.162e+01\n",
      "Epoch 16597, Loss: 427.38934326171875, Neurons: 11, Grad norm: 2.637e+01\n",
      "Epoch 16598, Loss: 427.3860778808594, Neurons: 11, Grad norm: 1.731e+01\n",
      "Epoch 16599, Loss: 427.3827819824219, Neurons: 11, Grad norm: 9.226e+00\n",
      "Epoch 16599, Test loss: 424.1736145019531\n",
      "Epoch 16600, Loss: 427.3795471191406, Neurons: 11, Grad norm: 1.984e+00\n",
      "Epoch 16601, Loss: 427.3763427734375, Neurons: 11, Grad norm: 5.513e+00\n",
      "Epoch 16602, Loss: 427.373046875, Neurons: 11, Grad norm: 1.123e+01\n",
      "Epoch 16603, Loss: 427.3697814941406, Neurons: 11, Grad norm: 1.536e+01\n",
      "Epoch 16604, Loss: 427.3665771484375, Neurons: 11, Grad norm: 1.814e+01\n",
      "Epoch 16605, Loss: 427.36334228515625, Neurons: 11, Grad norm: 1.864e+01\n",
      "Epoch 16606, Loss: 427.3600769042969, Neurons: 11, Grad norm: 1.835e+01\n",
      "Epoch 16607, Loss: 427.3567810058594, Neurons: 11, Grad norm: 1.562e+01\n",
      "Epoch 16608, Loss: 427.3535461425781, Neurons: 11, Grad norm: 1.265e+01\n",
      "Epoch 16609, Loss: 427.35028076171875, Neurons: 11, Grad norm: 8.386e+00\n",
      "Epoch 16610, Loss: 427.34698486328125, Neurons: 11, Grad norm: 4.420e+00\n",
      "Epoch 16611, Loss: 427.34368896484375, Neurons: 11, Grad norm: 1.502e+00\n",
      "Epoch 16612, Loss: 427.3404541015625, Neurons: 11, Grad norm: 3.891e+00\n",
      "Epoch 16613, Loss: 427.3371276855469, Neurons: 11, Grad norm: 7.033e+00\n",
      "Epoch 16614, Loss: 427.3338928222656, Neurons: 11, Grad norm: 9.061e+00\n",
      "Epoch 16615, Loss: 427.3305969238281, Neurons: 11, Grad norm: 1.081e+01\n",
      "Epoch 16616, Loss: 427.3273010253906, Neurons: 11, Grad norm: 1.123e+01\n",
      "Epoch 16617, Loss: 427.323974609375, Neurons: 11, Grad norm: 1.273e+01\n",
      "Epoch 16618, Loss: 427.32073974609375, Neurons: 11, Grad norm: 1.330e+01\n",
      "Epoch 16619, Loss: 427.3173828125, Neurons: 11, Grad norm: 1.403e+01\n",
      "Epoch 16620, Loss: 427.3140869140625, Neurons: 11, Grad norm: 1.457e+01\n",
      "Epoch 16621, Loss: 427.310791015625, Neurons: 11, Grad norm: 1.367e+01\n",
      "Epoch 16622, Loss: 427.3074951171875, Neurons: 11, Grad norm: 1.210e+01\n",
      "Epoch 16623, Loss: 427.30413818359375, Neurons: 11, Grad norm: 1.202e+01\n",
      "Epoch 16624, Loss: 427.30078125, Neurons: 11, Grad norm: 1.068e+01\n",
      "Epoch 16625, Loss: 427.29754638671875, Neurons: 11, Grad norm: 1.081e+01\n",
      "Epoch 16626, Loss: 427.294189453125, Neurons: 11, Grad norm: 1.054e+01\n",
      "Epoch 16627, Loss: 427.2908935546875, Neurons: 11, Grad norm: 1.076e+01\n",
      "Epoch 16628, Loss: 427.2874755859375, Neurons: 11, Grad norm: 1.134e+01\n",
      "Epoch 16629, Loss: 427.2841796875, Neurons: 11, Grad norm: 1.194e+01\n",
      "Epoch 16630, Loss: 427.2807922363281, Neurons: 11, Grad norm: 1.114e+01\n",
      "Epoch 16631, Loss: 427.2774963378906, Neurons: 11, Grad norm: 1.089e+01\n",
      "Epoch 16632, Loss: 427.2740783691406, Neurons: 11, Grad norm: 1.062e+01\n",
      "Epoch 16633, Loss: 427.2707824707031, Neurons: 11, Grad norm: 1.121e+01\n",
      "Epoch 16634, Loss: 427.26739501953125, Neurons: 11, Grad norm: 1.013e+01\n",
      "Epoch 16635, Loss: 427.2640380859375, Neurons: 11, Grad norm: 9.651e+00\n",
      "Epoch 16636, Loss: 427.26068115234375, Neurons: 11, Grad norm: 9.617e+00\n",
      "Epoch 16637, Loss: 427.2572937011719, Neurons: 11, Grad norm: 9.875e+00\n",
      "Epoch 16638, Loss: 427.2539978027344, Neurons: 11, Grad norm: 9.151e+00\n",
      "Epoch 16639, Loss: 427.2505798339844, Neurons: 11, Grad norm: 9.016e+00\n",
      "Epoch 16640, Loss: 427.2471923828125, Neurons: 11, Grad norm: 8.145e+00\n",
      "Epoch 16641, Loss: 427.2437744140625, Neurons: 11, Grad norm: 7.636e+00\n",
      "Epoch 16642, Loss: 427.2403869628906, Neurons: 11, Grad norm: 6.578e+00\n",
      "Epoch 16643, Loss: 427.23699951171875, Neurons: 11, Grad norm: 5.784e+00\n",
      "Epoch 16644, Loss: 427.233642578125, Neurons: 11, Grad norm: 4.578e+00\n",
      "Epoch 16645, Loss: 427.2301940917969, Neurons: 11, Grad norm: 3.767e+00\n",
      "Epoch 16646, Loss: 427.2267761230469, Neurons: 11, Grad norm: 2.551e+00\n",
      "Epoch 16647, Loss: 427.223388671875, Neurons: 11, Grad norm: 1.931e+00\n",
      "Epoch 16648, Loss: 427.2200012207031, Neurons: 11, Grad norm: 1.515e+00\n",
      "Epoch 16649, Loss: 427.2165832519531, Neurons: 11, Grad norm: 1.687e+00\n",
      "Epoch 16649, Test loss: 424.0158996582031\n",
      "Epoch 16650, Loss: 427.21319580078125, Neurons: 11, Grad norm: 2.371e+00\n",
      "Epoch 16651, Loss: 427.2097473144531, Neurons: 11, Grad norm: 2.944e+00\n",
      "Epoch 16652, Loss: 427.206298828125, Neurons: 11, Grad norm: 5.095e+00\n",
      "Epoch 16653, Loss: 427.202880859375, Neurons: 11, Grad norm: 7.217e+00\n",
      "Epoch 16654, Loss: 427.1994934082031, Neurons: 11, Grad norm: 1.013e+01\n",
      "Epoch 16655, Loss: 427.19598388671875, Neurons: 11, Grad norm: 1.326e+01\n",
      "Epoch 16656, Loss: 427.1925964355469, Neurons: 11, Grad norm: 1.702e+01\n",
      "Epoch 16657, Loss: 427.1890869140625, Neurons: 11, Grad norm: 2.051e+01\n",
      "Epoch 16658, Loss: 427.1856994628906, Neurons: 11, Grad norm: 2.363e+01\n",
      "Epoch 16659, Loss: 427.1822509765625, Neurons: 11, Grad norm: 2.595e+01\n",
      "Epoch 16660, Loss: 427.1788024902344, Neurons: 11, Grad norm: 3.016e+01\n",
      "Epoch 16661, Loss: 427.1753845214844, Neurons: 11, Grad norm: 3.353e+01\n",
      "Epoch 16662, Loss: 427.171875, Neurons: 11, Grad norm: 3.799e+01\n",
      "Epoch 16663, Loss: 427.1684875488281, Neurons: 11, Grad norm: 4.281e+01\n",
      "Epoch 16664, Loss: 427.16497802734375, Neurons: 11, Grad norm: 4.783e+01\n",
      "Epoch 16665, Loss: 427.1615905761719, Neurons: 11, Grad norm: 5.356e+01\n",
      "Epoch 16666, Loss: 427.1580810546875, Neurons: 11, Grad norm: 6.127e+01\n",
      "Epoch 16667, Loss: 427.15478515625, Neurons: 11, Grad norm: 6.916e+01\n",
      "Epoch 16668, Loss: 427.1512756347656, Neurons: 11, Grad norm: 7.903e+01\n",
      "Epoch 16669, Loss: 427.1479797363281, Neurons: 11, Grad norm: 8.892e+01\n",
      "Epoch 16670, Loss: 427.14459228515625, Neurons: 11, Grad norm: 1.001e+02\n",
      "Epoch 16671, Loss: 427.14129638671875, Neurons: 11, Grad norm: 1.113e+02\n",
      "Epoch 16672, Loss: 427.13800048828125, Neurons: 11, Grad norm: 1.217e+02\n",
      "Epoch 16673, Loss: 427.1346740722656, Neurons: 11, Grad norm: 1.322e+02\n",
      "Epoch 16674, Loss: 427.1314392089844, Neurons: 11, Grad norm: 1.430e+02\n",
      "Epoch 16675, Loss: 427.1282043457031, Neurons: 11, Grad norm: 1.499e+02\n",
      "Epoch 16676, Loss: 427.1248779296875, Neurons: 11, Grad norm: 1.561e+02\n",
      "Epoch 16677, Loss: 427.1215515136719, Neurons: 11, Grad norm: 1.576e+02\n",
      "Epoch 16678, Loss: 427.1181335449219, Neurons: 11, Grad norm: 1.528e+02\n",
      "Epoch 16679, Loss: 427.1145935058594, Neurons: 11, Grad norm: 1.444e+02\n",
      "Epoch 16680, Loss: 427.1109313964844, Neurons: 11, Grad norm: 1.299e+02\n",
      "Epoch 16681, Loss: 427.1071472167969, Neurons: 11, Grad norm: 1.090e+02\n",
      "Epoch 16682, Loss: 427.10333251953125, Neurons: 11, Grad norm: 8.703e+01\n",
      "Epoch 16683, Loss: 427.09954833984375, Neurons: 11, Grad norm: 5.992e+01\n",
      "Epoch 16684, Loss: 427.0957946777344, Neurons: 11, Grad norm: 3.265e+01\n",
      "Epoch 16685, Loss: 427.0921936035156, Neurons: 11, Grad norm: 6.741e+00\n",
      "Epoch 16686, Loss: 427.08868408203125, Neurons: 11, Grad norm: 1.882e+01\n",
      "Epoch 16687, Loss: 427.0852355957031, Neurons: 11, Grad norm: 3.937e+01\n",
      "Epoch 16688, Loss: 427.0818786621094, Neurons: 11, Grad norm: 5.657e+01\n",
      "Epoch 16689, Loss: 427.07855224609375, Neurons: 11, Grad norm: 7.109e+01\n",
      "Epoch 16690, Loss: 427.0752258300781, Neurons: 11, Grad norm: 7.762e+01\n",
      "Epoch 16691, Loss: 427.07183837890625, Neurons: 11, Grad norm: 8.094e+01\n",
      "Epoch 16692, Loss: 427.0684509277344, Neurons: 11, Grad norm: 7.810e+01\n",
      "Epoch 16693, Loss: 427.06494140625, Neurons: 11, Grad norm: 7.027e+01\n",
      "Epoch 16694, Loss: 427.0614013671875, Neurons: 11, Grad norm: 5.994e+01\n",
      "Epoch 16695, Loss: 427.05780029296875, Neurons: 11, Grad norm: 4.612e+01\n",
      "Epoch 16696, Loss: 427.0542907714844, Neurons: 11, Grad norm: 3.141e+01\n",
      "Epoch 16697, Loss: 427.0506896972656, Neurons: 11, Grad norm: 1.749e+01\n",
      "Epoch 16698, Loss: 427.0471496582031, Neurons: 11, Grad norm: 3.297e+00\n",
      "Epoch 16699, Loss: 427.04364013671875, Neurons: 11, Grad norm: 8.105e+00\n",
      "Epoch 16699, Test loss: 423.850830078125\n",
      "Epoch 16700, Loss: 427.0401916503906, Neurons: 11, Grad norm: 1.915e+01\n",
      "Epoch 16701, Loss: 427.0367431640625, Neurons: 11, Grad norm: 2.841e+01\n",
      "Epoch 16702, Loss: 427.0332336425781, Neurons: 11, Grad norm: 3.367e+01\n",
      "Epoch 16703, Loss: 427.02978515625, Neurons: 11, Grad norm: 3.743e+01\n",
      "Epoch 16704, Loss: 427.0262756347656, Neurons: 11, Grad norm: 3.953e+01\n",
      "Epoch 16705, Loss: 427.0228271484375, Neurons: 11, Grad norm: 3.775e+01\n",
      "Epoch 16706, Loss: 427.01934814453125, Neurons: 11, Grad norm: 3.524e+01\n",
      "Epoch 16707, Loss: 427.0158386230469, Neurons: 11, Grad norm: 2.988e+01\n",
      "Epoch 16708, Loss: 427.0122985839844, Neurons: 11, Grad norm: 2.382e+01\n",
      "Epoch 16709, Loss: 427.0086975097656, Neurons: 11, Grad norm: 1.706e+01\n",
      "Epoch 16710, Loss: 427.00518798828125, Neurons: 11, Grad norm: 9.946e+00\n",
      "Epoch 16711, Loss: 427.00164794921875, Neurons: 11, Grad norm: 4.432e+00\n",
      "Epoch 16712, Loss: 426.9981384277344, Neurons: 11, Grad norm: 1.502e+00\n",
      "Epoch 16713, Loss: 426.9945983886719, Neurons: 11, Grad norm: 5.538e+00\n",
      "Epoch 16714, Loss: 426.9910888671875, Neurons: 11, Grad norm: 8.373e+00\n",
      "Epoch 16715, Loss: 426.987548828125, Neurons: 11, Grad norm: 1.167e+01\n",
      "Epoch 16716, Loss: 426.9839782714844, Neurons: 11, Grad norm: 1.366e+01\n",
      "Epoch 16717, Loss: 426.9804382324219, Neurons: 11, Grad norm: 1.478e+01\n",
      "Epoch 16718, Loss: 426.9768981933594, Neurons: 11, Grad norm: 1.552e+01\n",
      "Epoch 16719, Loss: 426.9732971191406, Neurons: 11, Grad norm: 1.524e+01\n",
      "Epoch 16720, Loss: 426.96978759765625, Neurons: 11, Grad norm: 1.418e+01\n",
      "Epoch 16721, Loss: 426.9661865234375, Neurons: 11, Grad norm: 1.325e+01\n",
      "Epoch 16722, Loss: 426.962646484375, Neurons: 11, Grad norm: 1.090e+01\n",
      "Epoch 16723, Loss: 426.9590759277344, Neurons: 11, Grad norm: 9.312e+00\n",
      "Epoch 16724, Loss: 426.9554748535156, Neurons: 11, Grad norm: 6.926e+00\n",
      "Epoch 16725, Loss: 426.9519348144531, Neurons: 11, Grad norm: 6.163e+00\n",
      "Epoch 16726, Loss: 426.9483947753906, Neurons: 11, Grad norm: 5.871e+00\n",
      "Epoch 16727, Loss: 426.9447326660156, Neurons: 11, Grad norm: 4.583e+00\n",
      "Epoch 16728, Loss: 426.9411315917969, Neurons: 11, Grad norm: 3.726e+00\n",
      "Epoch 16729, Loss: 426.9375305175781, Neurons: 11, Grad norm: 2.890e+00\n",
      "Epoch 16730, Loss: 426.9339294433594, Neurons: 11, Grad norm: 1.568e+00\n",
      "Epoch 16731, Loss: 426.9303283691406, Neurons: 11, Grad norm: 1.998e+00\n",
      "Epoch 16732, Loss: 426.9267272949219, Neurons: 11, Grad norm: 2.523e+00\n",
      "Epoch 16733, Loss: 426.9231262207031, Neurons: 11, Grad norm: 3.468e+00\n",
      "Epoch 16734, Loss: 426.91949462890625, Neurons: 11, Grad norm: 3.712e+00\n",
      "Epoch 16735, Loss: 426.9158935546875, Neurons: 11, Grad norm: 4.034e+00\n",
      "Epoch 16736, Loss: 426.91229248046875, Neurons: 11, Grad norm: 5.846e+00\n",
      "Epoch 16737, Loss: 426.90863037109375, Neurons: 11, Grad norm: 5.897e+00\n",
      "Epoch 16738, Loss: 426.9049987792969, Neurons: 11, Grad norm: 6.948e+00\n",
      "Epoch 16739, Loss: 426.9013366699219, Neurons: 11, Grad norm: 7.215e+00\n",
      "Epoch 16740, Loss: 426.8976745605469, Neurons: 11, Grad norm: 6.085e+00\n",
      "Epoch 16741, Loss: 426.89410400390625, Neurons: 11, Grad norm: 6.087e+00\n",
      "Epoch 16742, Loss: 426.890380859375, Neurons: 11, Grad norm: 7.133e+00\n",
      "Epoch 16743, Loss: 426.88677978515625, Neurons: 11, Grad norm: 6.452e+00\n",
      "Epoch 16744, Loss: 426.8830871582031, Neurons: 11, Grad norm: 7.234e+00\n",
      "Epoch 16745, Loss: 426.87939453125, Neurons: 11, Grad norm: 6.765e+00\n",
      "Epoch 16746, Loss: 426.87579345703125, Neurons: 11, Grad norm: 6.751e+00\n",
      "Epoch 16747, Loss: 426.8721008300781, Neurons: 11, Grad norm: 8.294e+00\n",
      "Epoch 16748, Loss: 426.8683776855469, Neurons: 11, Grad norm: 9.981e+00\n",
      "Epoch 16749, Loss: 426.86468505859375, Neurons: 11, Grad norm: 1.236e+01\n",
      "Epoch 16749, Test loss: 423.67877197265625\n",
      "Epoch 16750, Loss: 426.8609924316406, Neurons: 11, Grad norm: 1.591e+01\n",
      "Epoch 16751, Loss: 426.8573913574219, Neurons: 11, Grad norm: 1.752e+01\n",
      "Epoch 16752, Loss: 426.85369873046875, Neurons: 11, Grad norm: 2.036e+01\n",
      "Epoch 16753, Loss: 426.8499755859375, Neurons: 11, Grad norm: 2.245e+01\n",
      "Epoch 16754, Loss: 426.8462829589844, Neurons: 11, Grad norm: 2.431e+01\n",
      "Epoch 16755, Loss: 426.84259033203125, Neurons: 11, Grad norm: 2.668e+01\n",
      "Epoch 16756, Loss: 426.8388977050781, Neurons: 11, Grad norm: 2.853e+01\n",
      "Epoch 16757, Loss: 426.83514404296875, Neurons: 11, Grad norm: 3.062e+01\n",
      "Epoch 16758, Loss: 426.8314514160156, Neurons: 11, Grad norm: 3.506e+01\n",
      "Epoch 16759, Loss: 426.82769775390625, Neurons: 11, Grad norm: 3.905e+01\n",
      "Epoch 16760, Loss: 426.82403564453125, Neurons: 11, Grad norm: 4.375e+01\n",
      "Epoch 16761, Loss: 426.8202819824219, Neurons: 11, Grad norm: 4.980e+01\n",
      "Epoch 16762, Loss: 426.81658935546875, Neurons: 11, Grad norm: 5.816e+01\n",
      "Epoch 16763, Loss: 426.81292724609375, Neurons: 11, Grad norm: 6.643e+01\n",
      "Epoch 16764, Loss: 426.8092956542969, Neurons: 11, Grad norm: 7.664e+01\n",
      "Epoch 16765, Loss: 426.8056335449219, Neurons: 11, Grad norm: 8.913e+01\n",
      "Epoch 16766, Loss: 426.8020935058594, Neurons: 11, Grad norm: 1.031e+02\n",
      "Epoch 16767, Loss: 426.798583984375, Neurons: 11, Grad norm: 1.187e+02\n",
      "Epoch 16768, Loss: 426.7950744628906, Neurons: 11, Grad norm: 1.373e+02\n",
      "Epoch 16769, Loss: 426.79168701171875, Neurons: 11, Grad norm: 1.559e+02\n",
      "Epoch 16770, Loss: 426.78839111328125, Neurons: 11, Grad norm: 1.749e+02\n",
      "Epoch 16771, Loss: 426.7851867675781, Neurons: 11, Grad norm: 1.915e+02\n",
      "Epoch 16772, Loss: 426.7819519042969, Neurons: 11, Grad norm: 2.047e+02\n",
      "Epoch 16773, Loss: 426.7786865234375, Neurons: 11, Grad norm: 2.122e+02\n",
      "Epoch 16774, Loss: 426.7751770019531, Neurons: 11, Grad norm: 2.099e+02\n",
      "Epoch 16775, Loss: 426.771484375, Neurons: 11, Grad norm: 1.953e+02\n",
      "Epoch 16776, Loss: 426.7673034667969, Neurons: 11, Grad norm: 1.673e+02\n",
      "Epoch 16777, Loss: 426.76287841796875, Neurons: 11, Grad norm: 1.259e+02\n",
      "Epoch 16778, Loss: 426.7583923339844, Neurons: 11, Grad norm: 7.807e+01\n",
      "Epoch 16779, Loss: 426.7538757324219, Neurons: 11, Grad norm: 2.624e+01\n",
      "Epoch 16780, Loss: 426.7498474121094, Neurons: 11, Grad norm: 2.278e+01\n",
      "Epoch 16781, Loss: 426.7461853027344, Neurons: 11, Grad norm: 6.415e+01\n",
      "Epoch 16782, Loss: 426.7428283691406, Neurons: 11, Grad norm: 9.588e+01\n",
      "Epoch 16783, Loss: 426.7395935058594, Neurons: 11, Grad norm: 1.138e+02\n",
      "Epoch 16784, Loss: 426.7362976074219, Neurons: 11, Grad norm: 1.173e+02\n",
      "Epoch 16785, Loss: 426.73272705078125, Neurons: 11, Grad norm: 1.094e+02\n",
      "Epoch 16786, Loss: 426.72894287109375, Neurons: 11, Grad norm: 8.873e+01\n",
      "Epoch 16787, Loss: 426.7249755859375, Neurons: 11, Grad norm: 6.152e+01\n",
      "Epoch 16788, Loss: 426.7210388183594, Neurons: 11, Grad norm: 3.037e+01\n",
      "Epoch 16789, Loss: 426.7171936035156, Neurons: 11, Grad norm: 2.354e+00\n",
      "Epoch 16790, Loss: 426.71343994140625, Neurons: 11, Grad norm: 2.883e+01\n",
      "Epoch 16791, Loss: 426.70989990234375, Neurons: 11, Grad norm: 5.057e+01\n",
      "Epoch 16792, Loss: 426.7063903808594, Neurons: 11, Grad norm: 6.524e+01\n",
      "Epoch 16793, Loss: 426.7027893066406, Neurons: 11, Grad norm: 6.873e+01\n",
      "Epoch 16794, Loss: 426.6991882324219, Neurons: 11, Grad norm: 6.617e+01\n",
      "Epoch 16795, Loss: 426.6955261230469, Neurons: 11, Grad norm: 5.547e+01\n",
      "Epoch 16796, Loss: 426.6918029785156, Neurons: 11, Grad norm: 3.832e+01\n",
      "Epoch 16797, Loss: 426.68798828125, Neurons: 11, Grad norm: 2.070e+01\n",
      "Epoch 16798, Loss: 426.6842041015625, Neurons: 11, Grad norm: 2.370e+00\n",
      "Epoch 16799, Loss: 426.6805419921875, Neurons: 11, Grad norm: 1.609e+01\n",
      "Epoch 16799, Test loss: 423.4947204589844\n",
      "Epoch 16800, Loss: 426.6768798828125, Neurons: 11, Grad norm: 2.881e+01\n",
      "Epoch 16801, Loss: 426.67327880859375, Neurons: 11, Grad norm: 3.983e+01\n",
      "Epoch 16802, Loss: 426.6696472167969, Neurons: 11, Grad norm: 4.428e+01\n",
      "Epoch 16803, Loss: 426.6659851074219, Neurons: 11, Grad norm: 4.305e+01\n",
      "Epoch 16804, Loss: 426.6622314453125, Neurons: 11, Grad norm: 3.907e+01\n",
      "Epoch 16805, Loss: 426.6585998535156, Neurons: 11, Grad norm: 3.069e+01\n",
      "Epoch 16806, Loss: 426.65478515625, Neurons: 11, Grad norm: 1.949e+01\n",
      "Epoch 16807, Loss: 426.6510314941406, Neurons: 11, Grad norm: 9.588e+00\n",
      "Epoch 16808, Loss: 426.64739990234375, Neurons: 11, Grad norm: 1.932e+00\n",
      "Epoch 16809, Loss: 426.6435852050781, Neurons: 11, Grad norm: 9.110e+00\n",
      "Epoch 16810, Loss: 426.639892578125, Neurons: 11, Grad norm: 1.466e+01\n",
      "Epoch 16811, Loss: 426.6361999511719, Neurons: 11, Grad norm: 1.888e+01\n",
      "Epoch 16812, Loss: 426.6324768066406, Neurons: 11, Grad norm: 2.001e+01\n",
      "Epoch 16813, Loss: 426.6287841796875, Neurons: 11, Grad norm: 1.904e+01\n",
      "Epoch 16814, Loss: 426.6250305175781, Neurons: 11, Grad norm: 1.803e+01\n",
      "Epoch 16815, Loss: 426.621337890625, Neurons: 11, Grad norm: 1.485e+01\n",
      "Epoch 16816, Loss: 426.6175537109375, Neurons: 11, Grad norm: 1.240e+01\n",
      "Epoch 16817, Loss: 426.6138000488281, Neurons: 11, Grad norm: 9.264e+00\n",
      "Epoch 16818, Loss: 426.6100769042969, Neurons: 11, Grad norm: 5.049e+00\n",
      "Epoch 16819, Loss: 426.6062927246094, Neurons: 11, Grad norm: 1.822e+00\n",
      "Epoch 16820, Loss: 426.60260009765625, Neurons: 11, Grad norm: 1.940e+00\n",
      "Epoch 16821, Loss: 426.5987854003906, Neurons: 11, Grad norm: 4.547e+00\n",
      "Epoch 16822, Loss: 426.5950012207031, Neurons: 11, Grad norm: 5.801e+00\n",
      "Epoch 16823, Loss: 426.5912780761719, Neurons: 11, Grad norm: 7.093e+00\n",
      "Epoch 16824, Loss: 426.5874938964844, Neurons: 11, Grad norm: 8.732e+00\n",
      "Epoch 16825, Loss: 426.58367919921875, Neurons: 11, Grad norm: 8.580e+00\n",
      "Epoch 16826, Loss: 426.57989501953125, Neurons: 11, Grad norm: 7.896e+00\n",
      "Epoch 16827, Loss: 426.5760803222656, Neurons: 11, Grad norm: 8.538e+00\n",
      "Epoch 16828, Loss: 426.5722961425781, Neurons: 11, Grad norm: 6.608e+00\n",
      "Epoch 16829, Loss: 426.5684814453125, Neurons: 11, Grad norm: 5.608e+00\n",
      "Epoch 16830, Loss: 426.564697265625, Neurons: 11, Grad norm: 4.074e+00\n",
      "Epoch 16831, Loss: 426.5608825683594, Neurons: 11, Grad norm: 2.316e+00\n",
      "Epoch 16832, Loss: 426.5570983886719, Neurons: 11, Grad norm: 2.183e+00\n",
      "Epoch 16833, Loss: 426.55328369140625, Neurons: 11, Grad norm: 2.067e+00\n",
      "Epoch 16834, Loss: 426.54937744140625, Neurons: 11, Grad norm: 1.552e+00\n",
      "Epoch 16835, Loss: 426.54559326171875, Neurons: 11, Grad norm: 1.612e+00\n",
      "Epoch 16836, Loss: 426.5417785644531, Neurons: 11, Grad norm: 1.737e+00\n",
      "Epoch 16837, Loss: 426.53790283203125, Neurons: 11, Grad norm: 1.793e+00\n",
      "Epoch 16838, Loss: 426.5340881347656, Neurons: 11, Grad norm: 2.062e+00\n",
      "Epoch 16839, Loss: 426.5303039550781, Neurons: 11, Grad norm: 3.329e+00\n",
      "Epoch 16840, Loss: 426.5263977050781, Neurons: 11, Grad norm: 4.518e+00\n",
      "Epoch 16841, Loss: 426.5225524902344, Neurons: 11, Grad norm: 5.105e+00\n",
      "Epoch 16842, Loss: 426.5186767578125, Neurons: 11, Grad norm: 6.011e+00\n",
      "Epoch 16843, Loss: 426.5148010253906, Neurons: 11, Grad norm: 5.634e+00\n",
      "Epoch 16844, Loss: 426.51092529296875, Neurons: 11, Grad norm: 5.665e+00\n",
      "Epoch 16845, Loss: 426.5070495605469, Neurons: 11, Grad norm: 4.981e+00\n",
      "Epoch 16846, Loss: 426.5032043457031, Neurons: 11, Grad norm: 4.167e+00\n",
      "Epoch 16847, Loss: 426.4992980957031, Neurons: 11, Grad norm: 3.431e+00\n",
      "Epoch 16848, Loss: 426.4953918457031, Neurons: 11, Grad norm: 2.558e+00\n",
      "Epoch 16849, Loss: 426.4914855957031, Neurons: 11, Grad norm: 1.770e+00\n",
      "Epoch 16849, Test loss: 423.31494140625\n",
      "Epoch 16850, Loss: 426.4876403808594, Neurons: 11, Grad norm: 2.295e+00\n",
      "Epoch 16851, Loss: 426.48370361328125, Neurons: 11, Grad norm: 2.656e+00\n",
      "Epoch 16852, Loss: 426.47979736328125, Neurons: 11, Grad norm: 2.957e+00\n",
      "Epoch 16853, Loss: 426.47589111328125, Neurons: 11, Grad norm: 3.067e+00\n",
      "Epoch 16854, Loss: 426.4719543457031, Neurons: 11, Grad norm: 2.964e+00\n",
      "Epoch 16855, Loss: 426.4680480957031, Neurons: 11, Grad norm: 1.691e+00\n",
      "Epoch 16856, Loss: 426.46405029296875, Neurons: 11, Grad norm: 2.080e+00\n",
      "Epoch 16857, Loss: 426.46014404296875, Neurons: 11, Grad norm: 3.153e+00\n",
      "Epoch 16858, Loss: 426.4561767578125, Neurons: 11, Grad norm: 3.124e+00\n",
      "Epoch 16859, Loss: 426.4523010253906, Neurons: 11, Grad norm: 4.014e+00\n",
      "Epoch 16860, Loss: 426.44830322265625, Neurons: 11, Grad norm: 5.378e+00\n",
      "Epoch 16861, Loss: 426.4443359375, Neurons: 11, Grad norm: 5.878e+00\n",
      "Epoch 16862, Loss: 426.4404296875, Neurons: 11, Grad norm: 6.301e+00\n",
      "Epoch 16863, Loss: 426.4364013671875, Neurons: 11, Grad norm: 8.240e+00\n",
      "Epoch 16864, Loss: 426.43243408203125, Neurons: 11, Grad norm: 7.982e+00\n",
      "Epoch 16865, Loss: 426.4284973144531, Neurons: 11, Grad norm: 8.756e+00\n",
      "Epoch 16866, Loss: 426.42449951171875, Neurons: 11, Grad norm: 1.030e+01\n",
      "Epoch 16867, Loss: 426.4205017089844, Neurons: 11, Grad norm: 1.169e+01\n",
      "Epoch 16868, Loss: 426.41650390625, Neurons: 11, Grad norm: 1.395e+01\n",
      "Epoch 16869, Loss: 426.4124755859375, Neurons: 11, Grad norm: 1.653e+01\n",
      "Epoch 16870, Loss: 426.4084777832031, Neurons: 11, Grad norm: 1.866e+01\n",
      "Epoch 16871, Loss: 426.404541015625, Neurons: 11, Grad norm: 2.184e+01\n",
      "Epoch 16872, Loss: 426.4004821777344, Neurons: 11, Grad norm: 2.271e+01\n",
      "Epoch 16873, Loss: 426.396484375, Neurons: 11, Grad norm: 2.395e+01\n",
      "Epoch 16874, Loss: 426.3924865722656, Neurons: 11, Grad norm: 2.600e+01\n",
      "Epoch 16875, Loss: 426.388427734375, Neurons: 11, Grad norm: 2.734e+01\n",
      "Epoch 16876, Loss: 426.3843994140625, Neurons: 11, Grad norm: 2.804e+01\n",
      "Epoch 16877, Loss: 426.3804016113281, Neurons: 11, Grad norm: 2.852e+01\n",
      "Epoch 16878, Loss: 426.3763427734375, Neurons: 11, Grad norm: 2.789e+01\n",
      "Epoch 16879, Loss: 426.3722839355469, Neurons: 11, Grad norm: 2.774e+01\n",
      "Epoch 16880, Loss: 426.36822509765625, Neurons: 11, Grad norm: 2.667e+01\n",
      "Epoch 16881, Loss: 426.36419677734375, Neurons: 11, Grad norm: 2.589e+01\n",
      "Epoch 16882, Loss: 426.3601379394531, Neurons: 11, Grad norm: 2.614e+01\n",
      "Epoch 16883, Loss: 426.3560791015625, Neurons: 11, Grad norm: 2.670e+01\n",
      "Epoch 16884, Loss: 426.35198974609375, Neurons: 11, Grad norm: 2.643e+01\n",
      "Epoch 16885, Loss: 426.3479309082031, Neurons: 11, Grad norm: 2.670e+01\n",
      "Epoch 16886, Loss: 426.3439025878906, Neurons: 11, Grad norm: 2.644e+01\n",
      "Epoch 16887, Loss: 426.3397521972656, Neurons: 11, Grad norm: 2.782e+01\n",
      "Epoch 16888, Loss: 426.335693359375, Neurons: 11, Grad norm: 2.959e+01\n",
      "Epoch 16889, Loss: 426.33160400390625, Neurons: 11, Grad norm: 3.053e+01\n",
      "Epoch 16890, Loss: 426.32745361328125, Neurons: 11, Grad norm: 3.191e+01\n",
      "Epoch 16891, Loss: 426.3233947753906, Neurons: 11, Grad norm: 3.484e+01\n",
      "Epoch 16892, Loss: 426.31927490234375, Neurons: 11, Grad norm: 3.740e+01\n",
      "Epoch 16893, Loss: 426.315185546875, Neurons: 11, Grad norm: 4.021e+01\n",
      "Epoch 16894, Loss: 426.31109619140625, Neurons: 11, Grad norm: 4.255e+01\n",
      "Epoch 16895, Loss: 426.3069763183594, Neurons: 11, Grad norm: 4.670e+01\n",
      "Epoch 16896, Loss: 426.3028869628906, Neurons: 11, Grad norm: 5.100e+01\n",
      "Epoch 16897, Loss: 426.2987976074219, Neurons: 11, Grad norm: 5.613e+01\n",
      "Epoch 16898, Loss: 426.294677734375, Neurons: 11, Grad norm: 6.344e+01\n",
      "Epoch 16899, Loss: 426.29058837890625, Neurons: 11, Grad norm: 7.160e+01\n",
      "Epoch 16899, Test loss: 423.104248046875\n",
      "Epoch 16900, Loss: 426.2865295410156, Neurons: 11, Grad norm: 7.941e+01\n",
      "Epoch 16901, Loss: 426.28253173828125, Neurons: 11, Grad norm: 8.856e+01\n",
      "Epoch 16902, Loss: 426.27850341796875, Neurons: 11, Grad norm: 9.710e+01\n",
      "Epoch 16903, Loss: 426.27447509765625, Neurons: 11, Grad norm: 1.075e+02\n",
      "Epoch 16904, Loss: 426.2704772949219, Neurons: 11, Grad norm: 1.193e+02\n",
      "Epoch 16905, Loss: 426.2666015625, Neurons: 11, Grad norm: 1.310e+02\n",
      "Epoch 16906, Loss: 426.2626953125, Neurons: 11, Grad norm: 1.427e+02\n",
      "Epoch 16907, Loss: 426.2587890625, Neurons: 11, Grad norm: 1.528e+02\n",
      "Epoch 16908, Loss: 426.2548828125, Neurons: 11, Grad norm: 1.594e+02\n",
      "Epoch 16909, Loss: 426.2509765625, Neurons: 11, Grad norm: 1.625e+02\n",
      "Epoch 16910, Loss: 426.2469787597656, Neurons: 11, Grad norm: 1.591e+02\n",
      "Epoch 16911, Loss: 426.2427978515625, Neurons: 11, Grad norm: 1.498e+02\n",
      "Epoch 16912, Loss: 426.2384948730469, Neurons: 11, Grad norm: 1.339e+02\n",
      "Epoch 16913, Loss: 426.2340393066406, Neurons: 11, Grad norm: 1.117e+02\n",
      "Epoch 16914, Loss: 426.2294921875, Neurons: 11, Grad norm: 8.452e+01\n",
      "Epoch 16915, Loss: 426.22503662109375, Neurons: 11, Grad norm: 5.497e+01\n",
      "Epoch 16916, Loss: 426.2205810546875, Neurons: 11, Grad norm: 2.536e+01\n",
      "Epoch 16917, Loss: 426.2164001464844, Neurons: 11, Grad norm: 3.380e+00\n",
      "Epoch 16918, Loss: 426.2122802734375, Neurons: 11, Grad norm: 2.895e+01\n",
      "Epoch 16919, Loss: 426.208251953125, Neurons: 11, Grad norm: 5.068e+01\n",
      "Epoch 16920, Loss: 426.20428466796875, Neurons: 11, Grad norm: 6.749e+01\n",
      "Epoch 16921, Loss: 426.20037841796875, Neurons: 11, Grad norm: 7.773e+01\n",
      "Epoch 16922, Loss: 426.1964416503906, Neurons: 11, Grad norm: 8.323e+01\n",
      "Epoch 16923, Loss: 426.1923828125, Neurons: 11, Grad norm: 8.278e+01\n",
      "Epoch 16924, Loss: 426.18829345703125, Neurons: 11, Grad norm: 7.710e+01\n",
      "Epoch 16925, Loss: 426.18414306640625, Neurons: 11, Grad norm: 6.749e+01\n",
      "Epoch 16926, Loss: 426.179931640625, Neurons: 11, Grad norm: 5.441e+01\n",
      "Epoch 16927, Loss: 426.1756896972656, Neurons: 11, Grad norm: 3.953e+01\n",
      "Epoch 16928, Loss: 426.1714782714844, Neurons: 11, Grad norm: 2.489e+01\n",
      "Epoch 16929, Loss: 426.16729736328125, Neurons: 11, Grad norm: 9.203e+00\n",
      "Epoch 16930, Loss: 426.1631774902344, Neurons: 11, Grad norm: 5.701e+00\n",
      "Epoch 16931, Loss: 426.1590270996094, Neurons: 11, Grad norm: 1.848e+01\n",
      "Epoch 16932, Loss: 426.1549987792969, Neurons: 11, Grad norm: 2.871e+01\n",
      "Epoch 16933, Loss: 426.1508483886719, Neurons: 11, Grad norm: 3.569e+01\n",
      "Epoch 16934, Loss: 426.14678955078125, Neurons: 11, Grad norm: 3.921e+01\n",
      "Epoch 16935, Loss: 426.1427001953125, Neurons: 11, Grad norm: 3.955e+01\n",
      "Epoch 16936, Loss: 426.1385803222656, Neurons: 11, Grad norm: 3.660e+01\n",
      "Epoch 16937, Loss: 426.13433837890625, Neurons: 11, Grad norm: 3.308e+01\n",
      "Epoch 16938, Loss: 426.13018798828125, Neurons: 11, Grad norm: 2.765e+01\n",
      "Epoch 16939, Loss: 426.12603759765625, Neurons: 11, Grad norm: 2.029e+01\n",
      "Epoch 16940, Loss: 426.12188720703125, Neurons: 11, Grad norm: 1.261e+01\n",
      "Epoch 16941, Loss: 426.11767578125, Neurons: 11, Grad norm: 4.716e+00\n",
      "Epoch 16942, Loss: 426.113525390625, Neurons: 11, Grad norm: 3.647e+00\n",
      "Epoch 16943, Loss: 426.1093444824219, Neurons: 11, Grad norm: 8.320e+00\n",
      "Epoch 16944, Loss: 426.1051330566406, Neurons: 11, Grad norm: 1.367e+01\n",
      "Epoch 16945, Loss: 426.1009826660156, Neurons: 11, Grad norm: 1.838e+01\n",
      "Epoch 16946, Loss: 426.0968017578125, Neurons: 11, Grad norm: 2.042e+01\n",
      "Epoch 16947, Loss: 426.09259033203125, Neurons: 11, Grad norm: 2.180e+01\n",
      "Epoch 16948, Loss: 426.08837890625, Neurons: 11, Grad norm: 2.304e+01\n",
      "Epoch 16949, Loss: 426.0841979980469, Neurons: 11, Grad norm: 2.277e+01\n",
      "Epoch 16949, Test loss: 422.9245910644531\n",
      "Epoch 16950, Loss: 426.0800476074219, Neurons: 11, Grad norm: 2.288e+01\n",
      "Epoch 16951, Loss: 426.0757751464844, Neurons: 11, Grad norm: 2.179e+01\n",
      "Epoch 16952, Loss: 426.07159423828125, Neurons: 11, Grad norm: 2.069e+01\n",
      "Epoch 16953, Loss: 426.0673522949219, Neurons: 11, Grad norm: 1.948e+01\n",
      "Epoch 16954, Loss: 426.0631408691406, Neurons: 11, Grad norm: 1.797e+01\n",
      "Epoch 16955, Loss: 426.058837890625, Neurons: 11, Grad norm: 1.667e+01\n",
      "Epoch 16956, Loss: 426.0545959472656, Neurons: 11, Grad norm: 1.566e+01\n",
      "Epoch 16957, Loss: 426.0503845214844, Neurons: 11, Grad norm: 1.433e+01\n",
      "Epoch 16958, Loss: 426.04608154296875, Neurons: 11, Grad norm: 1.371e+01\n",
      "Epoch 16959, Loss: 426.0418395996094, Neurons: 11, Grad norm: 1.141e+01\n",
      "Epoch 16960, Loss: 426.03759765625, Neurons: 11, Grad norm: 9.505e+00\n",
      "Epoch 16961, Loss: 426.0332946777344, Neurons: 11, Grad norm: 8.621e+00\n",
      "Epoch 16962, Loss: 426.029052734375, Neurons: 11, Grad norm: 7.580e+00\n",
      "Epoch 16963, Loss: 426.0247802734375, Neurons: 11, Grad norm: 5.915e+00\n",
      "Epoch 16964, Loss: 426.0204772949219, Neurons: 11, Grad norm: 4.779e+00\n",
      "Epoch 16965, Loss: 426.01617431640625, Neurons: 11, Grad norm: 4.244e+00\n",
      "Epoch 16966, Loss: 426.01190185546875, Neurons: 11, Grad norm: 4.693e+00\n",
      "Epoch 16967, Loss: 426.0075988769531, Neurons: 11, Grad norm: 4.052e+00\n",
      "Epoch 16968, Loss: 426.0032958984375, Neurons: 11, Grad norm: 4.015e+00\n",
      "Epoch 16969, Loss: 425.9989929199219, Neurons: 11, Grad norm: 3.678e+00\n",
      "Epoch 16970, Loss: 425.99462890625, Neurons: 11, Grad norm: 3.196e+00\n",
      "Epoch 16971, Loss: 425.9903259277344, Neurons: 11, Grad norm: 3.004e+00\n",
      "Epoch 16972, Loss: 425.9859924316406, Neurons: 11, Grad norm: 2.674e+00\n",
      "Epoch 16973, Loss: 425.981689453125, Neurons: 11, Grad norm: 2.239e+00\n",
      "Epoch 16974, Loss: 425.977294921875, Neurons: 11, Grad norm: 2.313e+00\n",
      "Epoch 16975, Loss: 425.9729309082031, Neurons: 11, Grad norm: 1.941e+00\n",
      "Epoch 16976, Loss: 425.9685974121094, Neurons: 11, Grad norm: 1.935e+00\n",
      "Epoch 16977, Loss: 425.9642028808594, Neurons: 11, Grad norm: 1.863e+00\n",
      "Epoch 16978, Loss: 425.95989990234375, Neurons: 11, Grad norm: 1.621e+00\n",
      "Epoch 16979, Loss: 425.9555969238281, Neurons: 11, Grad norm: 1.622e+00\n",
      "Epoch 16980, Loss: 425.9512023925781, Neurons: 11, Grad norm: 1.604e+00\n",
      "Epoch 16981, Loss: 425.94683837890625, Neurons: 11, Grad norm: 1.838e+00\n",
      "Epoch 16982, Loss: 425.9424743652344, Neurons: 11, Grad norm: 2.203e+00\n",
      "Epoch 16983, Loss: 425.9380798339844, Neurons: 11, Grad norm: 3.382e+00\n",
      "Epoch 16984, Loss: 425.9336853027344, Neurons: 11, Grad norm: 3.861e+00\n",
      "Epoch 16985, Loss: 425.9292907714844, Neurons: 11, Grad norm: 3.357e+00\n",
      "Epoch 16986, Loss: 425.9249267578125, Neurons: 11, Grad norm: 4.044e+00\n",
      "Epoch 16987, Loss: 425.9205017089844, Neurons: 11, Grad norm: 2.970e+00\n",
      "Epoch 16988, Loss: 425.9161376953125, Neurons: 11, Grad norm: 2.409e+00\n",
      "Epoch 16989, Loss: 425.9117431640625, Neurons: 11, Grad norm: 1.927e+00\n",
      "Epoch 16990, Loss: 425.90728759765625, Neurons: 11, Grad norm: 1.889e+00\n",
      "Epoch 16991, Loss: 425.90289306640625, Neurons: 11, Grad norm: 2.331e+00\n",
      "Epoch 16992, Loss: 425.89849853515625, Neurons: 11, Grad norm: 2.712e+00\n",
      "Epoch 16993, Loss: 425.89404296875, Neurons: 11, Grad norm: 4.714e+00\n",
      "Epoch 16994, Loss: 425.88958740234375, Neurons: 11, Grad norm: 5.881e+00\n",
      "Epoch 16995, Loss: 425.88519287109375, Neurons: 11, Grad norm: 6.847e+00\n",
      "Epoch 16996, Loss: 425.8807373046875, Neurons: 11, Grad norm: 1.007e+01\n",
      "Epoch 16997, Loss: 425.87628173828125, Neurons: 11, Grad norm: 1.093e+01\n",
      "Epoch 16998, Loss: 425.87188720703125, Neurons: 11, Grad norm: 1.267e+01\n",
      "Epoch 16999, Loss: 425.8674011230469, Neurons: 11, Grad norm: 1.607e+01\n",
      "Epoch 16999, Test loss: 422.7093811035156\n",
      "Epoch 17000, Loss: 425.8629455566406, Neurons: 11, Grad norm: 1.718e+01\n",
      "Epoch 17001, Loss: 425.8584899902344, Neurons: 11, Grad norm: 1.979e+01\n",
      "Epoch 17002, Loss: 425.8540344238281, Neurons: 11, Grad norm: 2.363e+01\n",
      "Epoch 17003, Loss: 425.8495788574219, Neurons: 11, Grad norm: 2.715e+01\n",
      "Epoch 17004, Loss: 425.8450927734375, Neurons: 11, Grad norm: 3.282e+01\n",
      "Epoch 17005, Loss: 425.84063720703125, Neurons: 11, Grad norm: 3.853e+01\n",
      "Epoch 17006, Loss: 425.836181640625, Neurons: 11, Grad norm: 4.349e+01\n",
      "Epoch 17007, Loss: 425.83172607421875, Neurons: 11, Grad norm: 5.111e+01\n",
      "Epoch 17008, Loss: 425.8273010253906, Neurons: 11, Grad norm: 5.997e+01\n",
      "Epoch 17009, Loss: 425.8228759765625, Neurons: 11, Grad norm: 7.033e+01\n",
      "Epoch 17010, Loss: 425.8184814453125, Neurons: 11, Grad norm: 8.304e+01\n",
      "Epoch 17011, Loss: 425.81414794921875, Neurons: 11, Grad norm: 9.624e+01\n",
      "Epoch 17012, Loss: 425.80987548828125, Neurons: 11, Grad norm: 1.116e+02\n",
      "Epoch 17013, Loss: 425.8056335449219, Neurons: 11, Grad norm: 1.289e+02\n",
      "Epoch 17014, Loss: 425.8014831542969, Neurons: 11, Grad norm: 1.452e+02\n",
      "Epoch 17015, Loss: 425.7973937988281, Neurons: 11, Grad norm: 1.612e+02\n",
      "Epoch 17016, Loss: 425.7933044433594, Neurons: 11, Grad norm: 1.758e+02\n",
      "Epoch 17017, Loss: 425.7892761230469, Neurons: 11, Grad norm: 1.860e+02\n",
      "Epoch 17018, Loss: 425.7851867675781, Neurons: 11, Grad norm: 1.899e+02\n",
      "Epoch 17019, Loss: 425.7808837890625, Neurons: 11, Grad norm: 1.869e+02\n",
      "Epoch 17020, Loss: 425.7763977050781, Neurons: 11, Grad norm: 1.731e+02\n",
      "Epoch 17021, Loss: 425.7716369628906, Neurons: 11, Grad norm: 1.500e+02\n",
      "Epoch 17022, Loss: 425.7666931152344, Neurons: 11, Grad norm: 1.167e+02\n",
      "Epoch 17023, Loss: 425.7615966796875, Neurons: 11, Grad norm: 7.638e+01\n",
      "Epoch 17024, Loss: 425.756591796875, Neurons: 11, Grad norm: 3.430e+01\n",
      "Epoch 17025, Loss: 425.75189208984375, Neurons: 11, Grad norm: 7.671e+00\n",
      "Epoch 17026, Loss: 425.7474365234375, Neurons: 11, Grad norm: 4.475e+01\n",
      "Epoch 17027, Loss: 425.7432861328125, Neurons: 11, Grad norm: 7.297e+01\n",
      "Epoch 17028, Loss: 425.7392272949219, Neurons: 11, Grad norm: 9.302e+01\n",
      "Epoch 17029, Loss: 425.7351989746094, Neurons: 11, Grad norm: 1.015e+02\n",
      "Epoch 17030, Loss: 425.7309265136719, Neurons: 11, Grad norm: 1.003e+02\n",
      "Epoch 17031, Loss: 425.7265930175781, Neurons: 11, Grad norm: 9.022e+01\n",
      "Epoch 17032, Loss: 425.7220764160156, Neurons: 11, Grad norm: 7.055e+01\n",
      "Epoch 17033, Loss: 425.7174987792969, Neurons: 11, Grad norm: 4.651e+01\n",
      "Epoch 17034, Loss: 425.71295166015625, Neurons: 11, Grad norm: 2.058e+01\n",
      "Epoch 17035, Loss: 425.70843505859375, Neurons: 11, Grad norm: 5.745e+00\n",
      "Epoch 17036, Loss: 425.7041015625, Neurons: 11, Grad norm: 2.607e+01\n",
      "Epoch 17037, Loss: 425.6997985839844, Neurons: 11, Grad norm: 4.323e+01\n",
      "Epoch 17038, Loss: 425.6955261230469, Neurons: 11, Grad norm: 5.476e+01\n",
      "Epoch 17039, Loss: 425.6912841796875, Neurons: 11, Grad norm: 5.881e+01\n",
      "Epoch 17040, Loss: 425.6869812011719, Neurons: 11, Grad norm: 5.664e+01\n",
      "Epoch 17041, Loss: 425.6825256347656, Neurons: 11, Grad norm: 4.921e+01\n",
      "Epoch 17042, Loss: 425.6781921386719, Neurons: 11, Grad norm: 3.791e+01\n",
      "Epoch 17043, Loss: 425.6737365722656, Neurons: 11, Grad norm: 2.454e+01\n",
      "Epoch 17044, Loss: 425.6692810058594, Neurons: 11, Grad norm: 1.033e+01\n",
      "Epoch 17045, Loss: 425.6648254394531, Neurons: 11, Grad norm: 4.234e+00\n",
      "Epoch 17046, Loss: 425.6604919433594, Neurons: 11, Grad norm: 1.634e+01\n",
      "Epoch 17047, Loss: 425.6560974121094, Neurons: 11, Grad norm: 2.553e+01\n",
      "Epoch 17048, Loss: 425.65179443359375, Neurons: 11, Grad norm: 3.279e+01\n",
      "Epoch 17049, Loss: 425.64739990234375, Neurons: 11, Grad norm: 3.648e+01\n",
      "Epoch 17049, Test loss: 422.4804992675781\n",
      "Epoch 17050, Loss: 425.6430358886719, Neurons: 11, Grad norm: 3.661e+01\n",
      "Epoch 17051, Loss: 425.6386413574219, Neurons: 11, Grad norm: 3.436e+01\n",
      "Epoch 17052, Loss: 425.6342468261719, Neurons: 11, Grad norm: 2.903e+01\n",
      "Epoch 17053, Loss: 425.6298522949219, Neurons: 11, Grad norm: 2.098e+01\n",
      "Epoch 17054, Loss: 425.6253356933594, Neurons: 11, Grad norm: 1.214e+01\n",
      "Epoch 17055, Loss: 425.6209411621094, Neurons: 11, Grad norm: 3.040e+00\n",
      "Epoch 17056, Loss: 425.6164855957031, Neurons: 11, Grad norm: 6.391e+00\n",
      "Epoch 17057, Loss: 425.6120910644531, Neurons: 11, Grad norm: 1.354e+01\n",
      "Epoch 17058, Loss: 425.6076965332031, Neurons: 11, Grad norm: 1.897e+01\n",
      "Epoch 17059, Loss: 425.6033020019531, Neurons: 11, Grad norm: 2.203e+01\n",
      "Epoch 17060, Loss: 425.598876953125, Neurons: 11, Grad norm: 2.292e+01\n",
      "Epoch 17061, Loss: 425.5943908691406, Neurons: 11, Grad norm: 2.299e+01\n",
      "Epoch 17062, Loss: 425.5899963378906, Neurons: 11, Grad norm: 2.140e+01\n",
      "Epoch 17063, Loss: 425.5854797363281, Neurons: 11, Grad norm: 1.902e+01\n",
      "Epoch 17064, Loss: 425.5810852050781, Neurons: 11, Grad norm: 1.615e+01\n",
      "Epoch 17065, Loss: 425.57659912109375, Neurons: 11, Grad norm: 1.285e+01\n",
      "Epoch 17066, Loss: 425.5721435546875, Neurons: 11, Grad norm: 9.789e+00\n",
      "Epoch 17067, Loss: 425.56768798828125, Neurons: 11, Grad norm: 7.178e+00\n",
      "Epoch 17068, Loss: 425.5632019042969, Neurons: 11, Grad norm: 3.666e+00\n",
      "Epoch 17069, Loss: 425.5586853027344, Neurons: 11, Grad norm: 1.771e+00\n",
      "Epoch 17070, Loss: 425.55419921875, Neurons: 11, Grad norm: 3.394e+00\n",
      "Epoch 17071, Loss: 425.5497741699219, Neurons: 11, Grad norm: 5.927e+00\n",
      "Epoch 17072, Loss: 425.5452880859375, Neurons: 11, Grad norm: 7.505e+00\n",
      "Epoch 17073, Loss: 425.5408020019531, Neurons: 11, Grad norm: 8.608e+00\n",
      "Epoch 17074, Loss: 425.5362854003906, Neurons: 11, Grad norm: 8.943e+00\n",
      "Epoch 17075, Loss: 425.53179931640625, Neurons: 11, Grad norm: 8.292e+00\n",
      "Epoch 17076, Loss: 425.52728271484375, Neurons: 11, Grad norm: 7.490e+00\n",
      "Epoch 17077, Loss: 425.5227966308594, Neurons: 11, Grad norm: 6.124e+00\n",
      "Epoch 17078, Loss: 425.5182800292969, Neurons: 11, Grad norm: 5.778e+00\n",
      "Epoch 17079, Loss: 425.5137023925781, Neurons: 11, Grad norm: 4.511e+00\n",
      "Epoch 17080, Loss: 425.5091857910156, Neurons: 11, Grad norm: 2.998e+00\n",
      "Epoch 17081, Loss: 425.50469970703125, Neurons: 11, Grad norm: 3.385e+00\n",
      "Epoch 17082, Loss: 425.5001525878906, Neurons: 11, Grad norm: 2.437e+00\n",
      "Epoch 17083, Loss: 425.4955749511719, Neurons: 11, Grad norm: 1.917e+00\n",
      "Epoch 17084, Loss: 425.4910888671875, Neurons: 11, Grad norm: 2.100e+00\n",
      "Epoch 17085, Loss: 425.4864807128906, Neurons: 11, Grad norm: 3.389e+00\n",
      "Epoch 17086, Loss: 425.48199462890625, Neurons: 11, Grad norm: 4.069e+00\n",
      "Epoch 17087, Loss: 425.4773864746094, Neurons: 11, Grad norm: 4.159e+00\n",
      "Epoch 17088, Loss: 425.472900390625, Neurons: 11, Grad norm: 5.005e+00\n",
      "Epoch 17089, Loss: 425.4682922363281, Neurons: 11, Grad norm: 4.640e+00\n",
      "Epoch 17090, Loss: 425.46368408203125, Neurons: 11, Grad norm: 4.640e+00\n",
      "Epoch 17091, Loss: 425.4590759277344, Neurons: 11, Grad norm: 4.683e+00\n",
      "Epoch 17092, Loss: 425.4544982910156, Neurons: 11, Grad norm: 3.941e+00\n",
      "Epoch 17093, Loss: 425.449951171875, Neurons: 11, Grad norm: 5.076e+00\n",
      "Epoch 17094, Loss: 425.4454040527344, Neurons: 11, Grad norm: 4.635e+00\n",
      "Epoch 17095, Loss: 425.4407958984375, Neurons: 11, Grad norm: 4.139e+00\n",
      "Epoch 17096, Loss: 425.4361877441406, Neurons: 11, Grad norm: 5.799e+00\n",
      "Epoch 17097, Loss: 425.4315490722656, Neurons: 11, Grad norm: 5.057e+00\n",
      "Epoch 17098, Loss: 425.4268798828125, Neurons: 11, Grad norm: 3.793e+00\n",
      "Epoch 17099, Loss: 425.42230224609375, Neurons: 11, Grad norm: 3.676e+00\n",
      "Epoch 17099, Test loss: 422.2645568847656\n",
      "Epoch 17100, Loss: 425.4176940917969, Neurons: 11, Grad norm: 2.183e+00\n",
      "Epoch 17101, Loss: 425.4130859375, Neurons: 11, Grad norm: 1.828e+00\n",
      "Epoch 17102, Loss: 425.4084777832031, Neurons: 11, Grad norm: 1.797e+00\n",
      "Epoch 17103, Loss: 425.4037780761719, Neurons: 11, Grad norm: 2.597e+00\n",
      "Epoch 17104, Loss: 425.3992004394531, Neurons: 11, Grad norm: 2.736e+00\n",
      "Epoch 17105, Loss: 425.39453125, Neurons: 11, Grad norm: 3.516e+00\n",
      "Epoch 17106, Loss: 425.389892578125, Neurons: 11, Grad norm: 4.078e+00\n",
      "Epoch 17107, Loss: 425.38525390625, Neurons: 11, Grad norm: 2.698e+00\n",
      "Epoch 17108, Loss: 425.3805847167969, Neurons: 11, Grad norm: 2.720e+00\n",
      "Epoch 17109, Loss: 425.3758850097656, Neurons: 11, Grad norm: 3.190e+00\n",
      "Epoch 17110, Loss: 425.3712463378906, Neurons: 11, Grad norm: 2.707e+00\n",
      "Epoch 17111, Loss: 425.3665771484375, Neurons: 11, Grad norm: 2.070e+00\n",
      "Epoch 17112, Loss: 425.36187744140625, Neurons: 11, Grad norm: 1.823e+00\n",
      "Epoch 17113, Loss: 425.357177734375, Neurons: 11, Grad norm: 1.877e+00\n",
      "Epoch 17114, Loss: 425.3525390625, Neurons: 11, Grad norm: 2.098e+00\n",
      "Epoch 17115, Loss: 425.347900390625, Neurons: 11, Grad norm: 2.446e+00\n",
      "Epoch 17116, Loss: 425.3431396484375, Neurons: 11, Grad norm: 2.697e+00\n",
      "Epoch 17117, Loss: 425.33843994140625, Neurons: 11, Grad norm: 3.078e+00\n",
      "Epoch 17118, Loss: 425.33367919921875, Neurons: 11, Grad norm: 3.391e+00\n",
      "Epoch 17119, Loss: 425.32904052734375, Neurons: 11, Grad norm: 3.639e+00\n",
      "Epoch 17120, Loss: 425.3243408203125, Neurons: 11, Grad norm: 3.853e+00\n",
      "Epoch 17121, Loss: 425.319580078125, Neurons: 11, Grad norm: 3.865e+00\n",
      "Epoch 17122, Loss: 425.31488037109375, Neurons: 11, Grad norm: 4.011e+00\n",
      "Epoch 17123, Loss: 425.3101501464844, Neurons: 11, Grad norm: 5.159e+00\n",
      "Epoch 17124, Loss: 425.3053894042969, Neurons: 11, Grad norm: 5.455e+00\n",
      "Epoch 17125, Loss: 425.3006286621094, Neurons: 11, Grad norm: 5.789e+00\n",
      "Epoch 17126, Loss: 425.2958984375, Neurons: 11, Grad norm: 6.516e+00\n",
      "Epoch 17127, Loss: 425.29107666015625, Neurons: 11, Grad norm: 6.583e+00\n",
      "Epoch 17128, Loss: 425.286376953125, Neurons: 11, Grad norm: 6.879e+00\n",
      "Epoch 17129, Loss: 425.2815856933594, Neurons: 11, Grad norm: 7.317e+00\n",
      "Epoch 17130, Loss: 425.2768249511719, Neurons: 11, Grad norm: 8.588e+00\n",
      "Epoch 17131, Loss: 425.2720947265625, Neurons: 11, Grad norm: 1.089e+01\n",
      "Epoch 17132, Loss: 425.2673034667969, Neurons: 11, Grad norm: 1.197e+01\n",
      "Epoch 17133, Loss: 425.2625427246094, Neurons: 11, Grad norm: 1.343e+01\n",
      "Epoch 17134, Loss: 425.2577819824219, Neurons: 11, Grad norm: 1.514e+01\n",
      "Epoch 17135, Loss: 425.25299072265625, Neurons: 11, Grad norm: 1.737e+01\n",
      "Epoch 17136, Loss: 425.2481384277344, Neurons: 11, Grad norm: 2.089e+01\n",
      "Epoch 17137, Loss: 425.2433776855469, Neurons: 11, Grad norm: 2.440e+01\n",
      "Epoch 17138, Loss: 425.23858642578125, Neurons: 11, Grad norm: 2.731e+01\n",
      "Epoch 17139, Loss: 425.2337951660156, Neurons: 11, Grad norm: 3.082e+01\n",
      "Epoch 17140, Loss: 425.22900390625, Neurons: 11, Grad norm: 3.525e+01\n",
      "Epoch 17141, Loss: 425.22418212890625, Neurons: 11, Grad norm: 4.041e+01\n",
      "Epoch 17142, Loss: 425.2193908691406, Neurons: 11, Grad norm: 4.627e+01\n",
      "Epoch 17143, Loss: 425.214599609375, Neurons: 11, Grad norm: 5.280e+01\n",
      "Epoch 17144, Loss: 425.2098388671875, Neurons: 11, Grad norm: 5.877e+01\n",
      "Epoch 17145, Loss: 425.205078125, Neurons: 11, Grad norm: 6.627e+01\n",
      "Epoch 17146, Loss: 425.2002868652344, Neurons: 11, Grad norm: 7.444e+01\n",
      "Epoch 17147, Loss: 425.1955871582031, Neurons: 11, Grad norm: 8.300e+01\n",
      "Epoch 17148, Loss: 425.1908874511719, Neurons: 11, Grad norm: 9.419e+01\n",
      "Epoch 17149, Loss: 425.1861877441406, Neurons: 11, Grad norm: 1.061e+02\n",
      "Epoch 17149, Test loss: 422.0516052246094\n",
      "Epoch 17150, Loss: 425.18157958984375, Neurons: 11, Grad norm: 1.181e+02\n",
      "Epoch 17151, Loss: 425.177001953125, Neurons: 11, Grad norm: 1.325e+02\n",
      "Epoch 17152, Loss: 425.1724853515625, Neurons: 11, Grad norm: 1.439e+02\n",
      "Epoch 17153, Loss: 425.1679992675781, Neurons: 11, Grad norm: 1.537e+02\n",
      "Epoch 17154, Loss: 425.16339111328125, Neurons: 11, Grad norm: 1.619e+02\n",
      "Epoch 17155, Loss: 425.1588439941406, Neurons: 11, Grad norm: 1.639e+02\n",
      "Epoch 17156, Loss: 425.1541748046875, Neurons: 11, Grad norm: 1.609e+02\n",
      "Epoch 17157, Loss: 425.1493835449219, Neurons: 11, Grad norm: 1.522e+02\n",
      "Epoch 17158, Loss: 425.1444396972656, Neurons: 11, Grad norm: 1.340e+02\n",
      "Epoch 17159, Loss: 425.13934326171875, Neurons: 11, Grad norm: 1.108e+02\n",
      "Epoch 17160, Loss: 425.1341857910156, Neurons: 11, Grad norm: 8.230e+01\n",
      "Epoch 17161, Loss: 425.1289978027344, Neurons: 11, Grad norm: 4.999e+01\n",
      "Epoch 17162, Loss: 425.1239929199219, Neurons: 11, Grad norm: 1.931e+01\n",
      "Epoch 17163, Loss: 425.11907958984375, Neurons: 11, Grad norm: 1.086e+01\n",
      "Epoch 17164, Loss: 425.114501953125, Neurons: 11, Grad norm: 3.856e+01\n",
      "Epoch 17165, Loss: 425.1098937988281, Neurons: 11, Grad norm: 5.968e+01\n",
      "Epoch 17166, Loss: 425.1053771972656, Neurons: 11, Grad norm: 7.527e+01\n",
      "Epoch 17167, Loss: 425.10089111328125, Neurons: 11, Grad norm: 8.331e+01\n",
      "Epoch 17168, Loss: 425.0962829589844, Neurons: 11, Grad norm: 8.491e+01\n",
      "Epoch 17169, Loss: 425.0915832519531, Neurons: 11, Grad norm: 8.097e+01\n",
      "Epoch 17170, Loss: 425.0868835449219, Neurons: 11, Grad norm: 7.076e+01\n",
      "Epoch 17171, Loss: 425.08209228515625, Neurons: 11, Grad norm: 5.699e+01\n",
      "Epoch 17172, Loss: 425.0772399902344, Neurons: 11, Grad norm: 4.095e+01\n",
      "Epoch 17173, Loss: 425.0723876953125, Neurons: 11, Grad norm: 2.211e+01\n",
      "Epoch 17174, Loss: 425.06768798828125, Neurons: 11, Grad norm: 3.921e+00\n",
      "Epoch 17175, Loss: 425.0628967285156, Neurons: 11, Grad norm: 1.400e+01\n",
      "Epoch 17176, Loss: 425.05828857421875, Neurons: 11, Grad norm: 2.853e+01\n",
      "Epoch 17177, Loss: 425.0535888671875, Neurons: 11, Grad norm: 3.869e+01\n",
      "Epoch 17178, Loss: 425.04888916015625, Neurons: 11, Grad norm: 4.491e+01\n",
      "Epoch 17179, Loss: 425.0442810058594, Neurons: 11, Grad norm: 4.745e+01\n",
      "Epoch 17180, Loss: 425.0396423339844, Neurons: 11, Grad norm: 4.626e+01\n",
      "Epoch 17181, Loss: 425.03485107421875, Neurons: 11, Grad norm: 4.347e+01\n",
      "Epoch 17182, Loss: 425.03009033203125, Neurons: 11, Grad norm: 3.699e+01\n",
      "Epoch 17183, Loss: 425.025390625, Neurons: 11, Grad norm: 2.752e+01\n",
      "Epoch 17184, Loss: 425.0205993652344, Neurons: 11, Grad norm: 1.874e+01\n",
      "Epoch 17185, Loss: 425.0158386230469, Neurons: 11, Grad norm: 9.278e+00\n",
      "Epoch 17186, Loss: 425.0110778808594, Neurons: 11, Grad norm: 1.984e+00\n",
      "Epoch 17187, Loss: 425.00634765625, Neurons: 11, Grad norm: 9.049e+00\n",
      "Epoch 17188, Loss: 425.0015869140625, Neurons: 11, Grad norm: 1.612e+01\n",
      "Epoch 17189, Loss: 424.99688720703125, Neurons: 11, Grad norm: 2.111e+01\n",
      "Epoch 17190, Loss: 424.9921875, Neurons: 11, Grad norm: 2.487e+01\n",
      "Epoch 17191, Loss: 424.9874267578125, Neurons: 11, Grad norm: 2.762e+01\n",
      "Epoch 17192, Loss: 424.9826965332031, Neurons: 11, Grad norm: 2.810e+01\n",
      "Epoch 17193, Loss: 424.9778747558594, Neurons: 11, Grad norm: 2.764e+01\n",
      "Epoch 17194, Loss: 424.9731750488281, Neurons: 11, Grad norm: 2.588e+01\n",
      "Epoch 17195, Loss: 424.9683532714844, Neurons: 11, Grad norm: 2.266e+01\n",
      "Epoch 17196, Loss: 424.9635925292969, Neurons: 11, Grad norm: 1.944e+01\n",
      "Epoch 17197, Loss: 424.95880126953125, Neurons: 11, Grad norm: 1.416e+01\n",
      "Epoch 17198, Loss: 424.9539794921875, Neurons: 11, Grad norm: 8.723e+00\n",
      "Epoch 17199, Loss: 424.9491882324219, Neurons: 11, Grad norm: 3.934e+00\n",
      "Epoch 17199, Test loss: 421.7928466796875\n",
      "Epoch 17200, Loss: 424.94439697265625, Neurons: 11, Grad norm: 2.820e+00\n",
      "Epoch 17201, Loss: 424.9395751953125, Neurons: 11, Grad norm: 6.603e+00\n",
      "Epoch 17202, Loss: 424.9348449707031, Neurons: 11, Grad norm: 1.002e+01\n",
      "Epoch 17203, Loss: 424.9300537109375, Neurons: 11, Grad norm: 1.282e+01\n",
      "Epoch 17204, Loss: 424.9252014160156, Neurons: 11, Grad norm: 1.388e+01\n",
      "Epoch 17205, Loss: 424.9203796386719, Neurons: 11, Grad norm: 1.585e+01\n",
      "Epoch 17206, Loss: 424.9156494140625, Neurons: 11, Grad norm: 1.562e+01\n",
      "Epoch 17207, Loss: 424.9107971191406, Neurons: 11, Grad norm: 1.426e+01\n",
      "Epoch 17208, Loss: 424.9059753417969, Neurons: 11, Grad norm: 1.465e+01\n",
      "Epoch 17209, Loss: 424.9010925292969, Neurons: 11, Grad norm: 1.352e+01\n",
      "Epoch 17210, Loss: 424.89630126953125, Neurons: 11, Grad norm: 1.156e+01\n",
      "Epoch 17211, Loss: 424.8914489746094, Neurons: 11, Grad norm: 9.972e+00\n",
      "Epoch 17212, Loss: 424.8865966796875, Neurons: 11, Grad norm: 6.902e+00\n",
      "Epoch 17213, Loss: 424.88177490234375, Neurons: 11, Grad norm: 4.619e+00\n",
      "Epoch 17214, Loss: 424.87689208984375, Neurons: 11, Grad norm: 2.535e+00\n",
      "Epoch 17215, Loss: 424.8719787597656, Neurons: 11, Grad norm: 2.034e+00\n",
      "Epoch 17216, Loss: 424.8671875, Neurons: 11, Grad norm: 3.109e+00\n",
      "Epoch 17217, Loss: 424.8622741699219, Neurons: 11, Grad norm: 5.006e+00\n",
      "Epoch 17218, Loss: 424.8574523925781, Neurons: 11, Grad norm: 7.730e+00\n",
      "Epoch 17219, Loss: 424.8525390625, Neurons: 11, Grad norm: 8.787e+00\n",
      "Epoch 17220, Loss: 424.8476867675781, Neurons: 11, Grad norm: 1.005e+01\n",
      "Epoch 17221, Loss: 424.8427429199219, Neurons: 11, Grad norm: 1.063e+01\n",
      "Epoch 17222, Loss: 424.837890625, Neurons: 11, Grad norm: 1.023e+01\n",
      "Epoch 17223, Loss: 424.8329772949219, Neurons: 11, Grad norm: 1.156e+01\n",
      "Epoch 17224, Loss: 424.8280944824219, Neurons: 11, Grad norm: 1.244e+01\n",
      "Epoch 17225, Loss: 424.82318115234375, Neurons: 11, Grad norm: 1.202e+01\n",
      "Epoch 17226, Loss: 424.81829833984375, Neurons: 11, Grad norm: 1.201e+01\n",
      "Epoch 17227, Loss: 424.81329345703125, Neurons: 11, Grad norm: 1.100e+01\n",
      "Epoch 17228, Loss: 424.8084411621094, Neurons: 11, Grad norm: 9.706e+00\n",
      "Epoch 17229, Loss: 424.8034973144531, Neurons: 11, Grad norm: 8.844e+00\n",
      "Epoch 17230, Loss: 424.798583984375, Neurons: 11, Grad norm: 8.321e+00\n",
      "Epoch 17231, Loss: 424.793701171875, Neurons: 11, Grad norm: 8.816e+00\n",
      "Epoch 17232, Loss: 424.7886962890625, Neurons: 11, Grad norm: 9.447e+00\n",
      "Epoch 17233, Loss: 424.7837829589844, Neurons: 11, Grad norm: 9.092e+00\n",
      "Epoch 17234, Loss: 424.7788391113281, Neurons: 11, Grad norm: 8.988e+00\n",
      "Epoch 17235, Loss: 424.7738342285156, Neurons: 11, Grad norm: 8.571e+00\n",
      "Epoch 17236, Loss: 424.7688903808594, Neurons: 11, Grad norm: 7.997e+00\n",
      "Epoch 17237, Loss: 424.7639465332031, Neurons: 11, Grad norm: 9.154e+00\n",
      "Epoch 17238, Loss: 424.7590026855469, Neurons: 11, Grad norm: 1.023e+01\n",
      "Epoch 17239, Loss: 424.7539978027344, Neurons: 11, Grad norm: 1.043e+01\n",
      "Epoch 17240, Loss: 424.7490539550781, Neurons: 11, Grad norm: 1.092e+01\n",
      "Epoch 17241, Loss: 424.7440490722656, Neurons: 11, Grad norm: 1.099e+01\n",
      "Epoch 17242, Loss: 424.73907470703125, Neurons: 11, Grad norm: 1.222e+01\n",
      "Epoch 17243, Loss: 424.7341003417969, Neurons: 11, Grad norm: 1.426e+01\n",
      "Epoch 17244, Loss: 424.7290954589844, Neurons: 11, Grad norm: 1.606e+01\n",
      "Epoch 17245, Loss: 424.7240905761719, Neurons: 11, Grad norm: 1.743e+01\n",
      "Epoch 17246, Loss: 424.7190856933594, Neurons: 11, Grad norm: 1.846e+01\n",
      "Epoch 17247, Loss: 424.7140808105469, Neurons: 11, Grad norm: 2.065e+01\n",
      "Epoch 17248, Loss: 424.70904541015625, Neurons: 11, Grad norm: 2.313e+01\n",
      "Epoch 17249, Loss: 424.7041015625, Neurons: 11, Grad norm: 2.422e+01\n",
      "Epoch 17249, Test loss: 421.54339599609375\n",
      "Epoch 17250, Loss: 424.69903564453125, Neurons: 11, Grad norm: 2.554e+01\n",
      "Epoch 17251, Loss: 424.6940002441406, Neurons: 11, Grad norm: 2.660e+01\n",
      "Epoch 17252, Loss: 424.6889953613281, Neurons: 11, Grad norm: 2.705e+01\n",
      "Epoch 17253, Loss: 424.6839294433594, Neurons: 11, Grad norm: 2.814e+01\n",
      "Epoch 17254, Loss: 424.67889404296875, Neurons: 11, Grad norm: 3.006e+01\n",
      "Epoch 17255, Loss: 424.67388916015625, Neurons: 11, Grad norm: 3.250e+01\n",
      "Epoch 17256, Loss: 424.6688537597656, Neurons: 11, Grad norm: 3.574e+01\n",
      "Epoch 17257, Loss: 424.6637878417969, Neurons: 11, Grad norm: 3.929e+01\n",
      "Epoch 17258, Loss: 424.6587829589844, Neurons: 11, Grad norm: 4.343e+01\n",
      "Epoch 17259, Loss: 424.6537780761719, Neurons: 11, Grad norm: 4.816e+01\n",
      "Epoch 17260, Loss: 424.648681640625, Neurons: 11, Grad norm: 5.292e+01\n",
      "Epoch 17261, Loss: 424.6436767578125, Neurons: 11, Grad norm: 5.690e+01\n",
      "Epoch 17262, Loss: 424.6387023925781, Neurons: 11, Grad norm: 6.191e+01\n",
      "Epoch 17263, Loss: 424.6336364746094, Neurons: 11, Grad norm: 6.875e+01\n",
      "Epoch 17264, Loss: 424.6286926269531, Neurons: 11, Grad norm: 7.582e+01\n",
      "Epoch 17265, Loss: 424.6236877441406, Neurons: 11, Grad norm: 8.399e+01\n",
      "Epoch 17266, Loss: 424.6186828613281, Neurons: 11, Grad norm: 9.275e+01\n",
      "Epoch 17267, Loss: 424.6138000488281, Neurons: 11, Grad norm: 9.960e+01\n",
      "Epoch 17268, Loss: 424.60888671875, Neurons: 11, Grad norm: 1.077e+02\n",
      "Epoch 17269, Loss: 424.60400390625, Neurons: 11, Grad norm: 1.161e+02\n",
      "Epoch 17270, Loss: 424.5990905761719, Neurons: 11, Grad norm: 1.231e+02\n",
      "Epoch 17271, Loss: 424.59417724609375, Neurons: 11, Grad norm: 1.293e+02\n",
      "Epoch 17272, Loss: 424.58929443359375, Neurons: 11, Grad norm: 1.327e+02\n",
      "Epoch 17273, Loss: 424.5843505859375, Neurons: 11, Grad norm: 1.311e+02\n",
      "Epoch 17274, Loss: 424.5793762207031, Neurons: 11, Grad norm: 1.258e+02\n",
      "Epoch 17275, Loss: 424.5742492675781, Neurons: 11, Grad norm: 1.151e+02\n",
      "Epoch 17276, Loss: 424.569091796875, Neurons: 11, Grad norm: 1.002e+02\n",
      "Epoch 17277, Loss: 424.5638427734375, Neurons: 11, Grad norm: 8.212e+01\n",
      "Epoch 17278, Loss: 424.55859375, Neurons: 11, Grad norm: 6.129e+01\n",
      "Epoch 17279, Loss: 424.5533752441406, Neurons: 11, Grad norm: 3.883e+01\n",
      "Epoch 17280, Loss: 424.5481872558594, Neurons: 11, Grad norm: 1.692e+01\n",
      "Epoch 17281, Loss: 424.5431823730469, Neurons: 11, Grad norm: 3.884e+00\n",
      "Epoch 17282, Loss: 424.5381774902344, Neurons: 11, Grad norm: 2.042e+01\n",
      "Epoch 17283, Loss: 424.5332946777344, Neurons: 11, Grad norm: 3.478e+01\n",
      "Epoch 17284, Loss: 424.5283508300781, Neurons: 11, Grad norm: 4.670e+01\n",
      "Epoch 17285, Loss: 424.5234375, Neurons: 11, Grad norm: 5.464e+01\n",
      "Epoch 17286, Loss: 424.5185852050781, Neurons: 11, Grad norm: 5.944e+01\n",
      "Epoch 17287, Loss: 424.5135803222656, Neurons: 11, Grad norm: 6.205e+01\n",
      "Epoch 17288, Loss: 424.5086975097656, Neurons: 11, Grad norm: 6.008e+01\n",
      "Epoch 17289, Loss: 424.5036926269531, Neurons: 11, Grad norm: 5.559e+01\n",
      "Epoch 17290, Loss: 424.4986877441406, Neurons: 11, Grad norm: 5.039e+01\n",
      "Epoch 17291, Loss: 424.49365234375, Neurons: 11, Grad norm: 4.310e+01\n",
      "Epoch 17292, Loss: 424.48858642578125, Neurons: 11, Grad norm: 3.437e+01\n",
      "Epoch 17293, Loss: 424.4835510253906, Neurons: 11, Grad norm: 2.542e+01\n",
      "Epoch 17294, Loss: 424.4785461425781, Neurons: 11, Grad norm: 1.612e+01\n",
      "Epoch 17295, Loss: 424.4734802246094, Neurons: 11, Grad norm: 7.853e+00\n",
      "Epoch 17296, Loss: 424.4684753417969, Neurons: 11, Grad norm: 2.063e+00\n",
      "Epoch 17297, Loss: 424.4635009765625, Neurons: 11, Grad norm: 8.832e+00\n",
      "Epoch 17298, Loss: 424.45843505859375, Neurons: 11, Grad norm: 1.460e+01\n",
      "Epoch 17299, Loss: 424.4534912109375, Neurons: 11, Grad norm: 2.106e+01\n",
      "Epoch 17299, Test loss: 421.295654296875\n",
      "Epoch 17300, Loss: 424.448486328125, Neurons: 11, Grad norm: 2.576e+01\n",
      "Epoch 17301, Loss: 424.4434814453125, Neurons: 11, Grad norm: 2.778e+01\n",
      "Epoch 17302, Loss: 424.4384765625, Neurons: 11, Grad norm: 3.041e+01\n",
      "Epoch 17303, Loss: 424.4335021972656, Neurons: 11, Grad norm: 3.125e+01\n",
      "Epoch 17304, Loss: 424.4284362792969, Neurons: 11, Grad norm: 3.096e+01\n",
      "Epoch 17305, Loss: 424.42340087890625, Neurons: 11, Grad norm: 3.091e+01\n",
      "Epoch 17306, Loss: 424.4183349609375, Neurons: 11, Grad norm: 2.884e+01\n",
      "Epoch 17307, Loss: 424.4132995605469, Neurons: 11, Grad norm: 2.689e+01\n",
      "Epoch 17308, Loss: 424.4082336425781, Neurons: 11, Grad norm: 2.468e+01\n",
      "Epoch 17309, Loss: 424.4032287597656, Neurons: 11, Grad norm: 2.171e+01\n",
      "Epoch 17310, Loss: 424.3981018066406, Neurons: 11, Grad norm: 1.937e+01\n",
      "Epoch 17311, Loss: 424.3930358886719, Neurons: 11, Grad norm: 1.540e+01\n",
      "Epoch 17312, Loss: 424.38800048828125, Neurons: 11, Grad norm: 1.105e+01\n",
      "Epoch 17313, Loss: 424.3829040527344, Neurons: 11, Grad norm: 7.650e+00\n",
      "Epoch 17314, Loss: 424.3778381347656, Neurons: 11, Grad norm: 3.353e+00\n",
      "Epoch 17315, Loss: 424.372802734375, Neurons: 11, Grad norm: 2.003e+00\n",
      "Epoch 17316, Loss: 424.36767578125, Neurons: 11, Grad norm: 2.895e+00\n",
      "Epoch 17317, Loss: 424.3625793457031, Neurons: 11, Grad norm: 5.348e+00\n",
      "Epoch 17318, Loss: 424.35748291015625, Neurons: 11, Grad norm: 6.550e+00\n",
      "Epoch 17319, Loss: 424.3524475097656, Neurons: 11, Grad norm: 6.027e+00\n",
      "Epoch 17320, Loss: 424.3472900390625, Neurons: 11, Grad norm: 6.798e+00\n",
      "Epoch 17321, Loss: 424.3421936035156, Neurons: 11, Grad norm: 7.465e+00\n",
      "Epoch 17322, Loss: 424.33709716796875, Neurons: 11, Grad norm: 7.164e+00\n",
      "Epoch 17323, Loss: 424.3320007324219, Neurons: 11, Grad norm: 7.219e+00\n",
      "Epoch 17324, Loss: 424.326904296875, Neurons: 11, Grad norm: 6.793e+00\n",
      "Epoch 17325, Loss: 424.3216857910156, Neurons: 11, Grad norm: 6.087e+00\n",
      "Epoch 17326, Loss: 424.316650390625, Neurons: 11, Grad norm: 5.708e+00\n",
      "Epoch 17327, Loss: 424.3114929199219, Neurons: 11, Grad norm: 4.790e+00\n",
      "Epoch 17328, Loss: 424.30633544921875, Neurons: 11, Grad norm: 2.896e+00\n",
      "Epoch 17329, Loss: 424.3012390136719, Neurons: 11, Grad norm: 2.108e+00\n",
      "Epoch 17330, Loss: 424.2959899902344, Neurons: 11, Grad norm: 1.794e+00\n",
      "Epoch 17331, Loss: 424.2908935546875, Neurons: 11, Grad norm: 3.872e+00\n",
      "Epoch 17332, Loss: 424.2857971191406, Neurons: 11, Grad norm: 4.972e+00\n",
      "Epoch 17333, Loss: 424.28057861328125, Neurons: 11, Grad norm: 5.201e+00\n",
      "Epoch 17334, Loss: 424.275390625, Neurons: 11, Grad norm: 6.306e+00\n",
      "Epoch 17335, Loss: 424.2702331542969, Neurons: 11, Grad norm: 6.379e+00\n",
      "Epoch 17336, Loss: 424.26507568359375, Neurons: 11, Grad norm: 6.435e+00\n",
      "Epoch 17337, Loss: 424.2598876953125, Neurons: 11, Grad norm: 7.005e+00\n",
      "Epoch 17338, Loss: 424.25469970703125, Neurons: 11, Grad norm: 6.590e+00\n",
      "Epoch 17339, Loss: 424.2494812011719, Neurons: 11, Grad norm: 6.865e+00\n",
      "Epoch 17340, Loss: 424.2442932128906, Neurons: 11, Grad norm: 8.138e+00\n",
      "Epoch 17341, Loss: 424.2391357421875, Neurons: 11, Grad norm: 8.080e+00\n",
      "Epoch 17342, Loss: 424.23394775390625, Neurons: 11, Grad norm: 8.441e+00\n",
      "Epoch 17343, Loss: 424.22869873046875, Neurons: 11, Grad norm: 1.044e+01\n",
      "Epoch 17344, Loss: 424.2234802246094, Neurons: 11, Grad norm: 1.207e+01\n",
      "Epoch 17345, Loss: 424.2182922363281, Neurons: 11, Grad norm: 1.505e+01\n",
      "Epoch 17346, Loss: 424.2131042480469, Neurons: 11, Grad norm: 1.836e+01\n",
      "Epoch 17347, Loss: 424.20782470703125, Neurons: 11, Grad norm: 2.035e+01\n",
      "Epoch 17348, Loss: 424.20257568359375, Neurons: 11, Grad norm: 2.275e+01\n",
      "Epoch 17349, Loss: 424.1973876953125, Neurons: 11, Grad norm: 2.503e+01\n",
      "Epoch 17349, Test loss: 421.0396728515625\n",
      "Epoch 17350, Loss: 424.19219970703125, Neurons: 11, Grad norm: 2.805e+01\n",
      "Epoch 17351, Loss: 424.18695068359375, Neurons: 11, Grad norm: 3.227e+01\n",
      "Epoch 17352, Loss: 424.18170166015625, Neurons: 11, Grad norm: 3.634e+01\n",
      "Epoch 17353, Loss: 424.17645263671875, Neurons: 11, Grad norm: 4.152e+01\n",
      "Epoch 17354, Loss: 424.1712951660156, Neurons: 11, Grad norm: 4.721e+01\n",
      "Epoch 17355, Loss: 424.1660461425781, Neurons: 11, Grad norm: 5.305e+01\n",
      "Epoch 17356, Loss: 424.1607971191406, Neurons: 11, Grad norm: 5.969e+01\n",
      "Epoch 17357, Loss: 424.15557861328125, Neurons: 11, Grad norm: 6.669e+01\n",
      "Epoch 17358, Loss: 424.15045166015625, Neurons: 11, Grad norm: 7.529e+01\n",
      "Epoch 17359, Loss: 424.1452941894531, Neurons: 11, Grad norm: 8.521e+01\n",
      "Epoch 17360, Loss: 424.14013671875, Neurons: 11, Grad norm: 9.507e+01\n",
      "Epoch 17361, Loss: 424.1350402832031, Neurons: 11, Grad norm: 1.045e+02\n",
      "Epoch 17362, Loss: 424.1299743652344, Neurons: 11, Grad norm: 1.147e+02\n",
      "Epoch 17363, Loss: 424.12493896484375, Neurons: 11, Grad norm: 1.251e+02\n",
      "Epoch 17364, Loss: 424.1199035644531, Neurons: 11, Grad norm: 1.346e+02\n",
      "Epoch 17365, Loss: 424.1148986816406, Neurons: 11, Grad norm: 1.420e+02\n",
      "Epoch 17366, Loss: 424.1098937988281, Neurons: 11, Grad norm: 1.463e+02\n",
      "Epoch 17367, Loss: 424.1048278808594, Neurons: 11, Grad norm: 1.461e+02\n",
      "Epoch 17368, Loss: 424.0997009277344, Neurons: 11, Grad norm: 1.405e+02\n",
      "Epoch 17369, Loss: 424.0943908691406, Neurons: 11, Grad norm: 1.291e+02\n",
      "Epoch 17370, Loss: 424.0889892578125, Neurons: 11, Grad norm: 1.118e+02\n",
      "Epoch 17371, Loss: 424.08349609375, Neurons: 11, Grad norm: 8.885e+01\n",
      "Epoch 17372, Loss: 424.0780029296875, Neurons: 11, Grad norm: 6.427e+01\n",
      "Epoch 17373, Loss: 424.0726013183594, Neurons: 11, Grad norm: 3.776e+01\n",
      "Epoch 17374, Loss: 424.0672302246094, Neurons: 11, Grad norm: 1.089e+01\n",
      "Epoch 17375, Loss: 424.0620422363281, Neurons: 11, Grad norm: 1.280e+01\n",
      "Epoch 17376, Loss: 424.056884765625, Neurons: 11, Grad norm: 3.397e+01\n",
      "Epoch 17377, Loss: 424.0518798828125, Neurons: 11, Grad norm: 5.149e+01\n",
      "Epoch 17378, Loss: 424.0469970703125, Neurons: 11, Grad norm: 6.314e+01\n",
      "Epoch 17379, Loss: 424.0419921875, Neurons: 11, Grad norm: 7.006e+01\n",
      "Epoch 17380, Loss: 424.0368957519531, Neurons: 11, Grad norm: 7.128e+01\n",
      "Epoch 17381, Loss: 424.03179931640625, Neurons: 11, Grad norm: 6.677e+01\n",
      "Epoch 17382, Loss: 424.0266418457031, Neurons: 11, Grad norm: 5.885e+01\n",
      "Epoch 17383, Loss: 424.021484375, Neurons: 11, Grad norm: 4.826e+01\n",
      "Epoch 17384, Loss: 424.01629638671875, Neurons: 11, Grad norm: 3.512e+01\n",
      "Epoch 17385, Loss: 424.01104736328125, Neurons: 11, Grad norm: 2.144e+01\n",
      "Epoch 17386, Loss: 424.0058288574219, Neurons: 11, Grad norm: 8.310e+00\n",
      "Epoch 17387, Loss: 424.0007019042969, Neurons: 11, Grad norm: 4.254e+00\n",
      "Epoch 17388, Loss: 423.99554443359375, Neurons: 11, Grad norm: 1.340e+01\n",
      "Epoch 17389, Loss: 423.9904479980469, Neurons: 11, Grad norm: 2.177e+01\n",
      "Epoch 17390, Loss: 423.98529052734375, Neurons: 11, Grad norm: 2.866e+01\n",
      "Epoch 17391, Loss: 423.9801940917969, Neurons: 11, Grad norm: 3.327e+01\n",
      "Epoch 17392, Loss: 423.97509765625, Neurons: 11, Grad norm: 3.577e+01\n",
      "Epoch 17393, Loss: 423.9700012207031, Neurons: 11, Grad norm: 3.487e+01\n",
      "Epoch 17394, Loss: 423.96478271484375, Neurons: 11, Grad norm: 3.125e+01\n",
      "Epoch 17395, Loss: 423.9596862792969, Neurons: 11, Grad norm: 2.625e+01\n",
      "Epoch 17396, Loss: 423.9544982910156, Neurons: 11, Grad norm: 1.920e+01\n",
      "Epoch 17397, Loss: 423.94927978515625, Neurons: 11, Grad norm: 1.188e+01\n",
      "Epoch 17398, Loss: 423.944091796875, Neurons: 11, Grad norm: 5.920e+00\n",
      "Epoch 17399, Loss: 423.93890380859375, Neurons: 11, Grad norm: 1.924e+00\n",
      "Epoch 17399, Test loss: 420.7897033691406\n",
      "Epoch 17400, Loss: 423.93377685546875, Neurons: 11, Grad norm: 4.254e+00\n",
      "Epoch 17401, Loss: 423.9285888671875, Neurons: 11, Grad norm: 6.319e+00\n",
      "Epoch 17402, Loss: 423.92340087890625, Neurons: 11, Grad norm: 9.283e+00\n",
      "Epoch 17403, Loss: 423.9181823730469, Neurons: 11, Grad norm: 1.183e+01\n",
      "Epoch 17404, Loss: 423.9129943847656, Neurons: 11, Grad norm: 1.286e+01\n",
      "Epoch 17405, Loss: 423.90777587890625, Neurons: 11, Grad norm: 1.326e+01\n",
      "Epoch 17406, Loss: 423.902587890625, Neurons: 11, Grad norm: 1.275e+01\n",
      "Epoch 17407, Loss: 423.8974304199219, Neurons: 11, Grad norm: 1.118e+01\n",
      "Epoch 17408, Loss: 423.8921813964844, Neurons: 11, Grad norm: 9.538e+00\n",
      "Epoch 17409, Loss: 423.8869934082031, Neurons: 11, Grad norm: 7.232e+00\n",
      "Epoch 17410, Loss: 423.88177490234375, Neurons: 11, Grad norm: 5.087e+00\n",
      "Epoch 17411, Loss: 423.87652587890625, Neurons: 11, Grad norm: 4.229e+00\n",
      "Epoch 17412, Loss: 423.871337890625, Neurons: 11, Grad norm: 2.575e+00\n",
      "Epoch 17413, Loss: 423.8660888671875, Neurons: 11, Grad norm: 2.358e+00\n",
      "Epoch 17414, Loss: 423.86083984375, Neurons: 11, Grad norm: 4.455e+00\n",
      "Epoch 17415, Loss: 423.8555908203125, Neurons: 11, Grad norm: 8.179e+00\n",
      "Epoch 17416, Loss: 423.850341796875, Neurons: 11, Grad norm: 1.162e+01\n",
      "Epoch 17417, Loss: 423.8450927734375, Neurons: 11, Grad norm: 1.341e+01\n",
      "Epoch 17418, Loss: 423.8398742675781, Neurons: 11, Grad norm: 1.501e+01\n",
      "Epoch 17419, Loss: 423.8345947265625, Neurons: 11, Grad norm: 1.569e+01\n",
      "Epoch 17420, Loss: 423.82928466796875, Neurons: 11, Grad norm: 1.518e+01\n",
      "Epoch 17421, Loss: 423.8240966796875, Neurons: 11, Grad norm: 1.484e+01\n",
      "Epoch 17422, Loss: 423.81878662109375, Neurons: 11, Grad norm: 1.451e+01\n",
      "Epoch 17423, Loss: 423.8134765625, Neurons: 11, Grad norm: 1.461e+01\n",
      "Epoch 17424, Loss: 423.8081970214844, Neurons: 11, Grad norm: 1.483e+01\n",
      "Epoch 17425, Loss: 423.802978515625, Neurons: 11, Grad norm: 1.557e+01\n",
      "Epoch 17426, Loss: 423.7976989746094, Neurons: 11, Grad norm: 1.644e+01\n",
      "Epoch 17427, Loss: 423.7923889160156, Neurons: 11, Grad norm: 1.608e+01\n",
      "Epoch 17428, Loss: 423.7870788574219, Neurons: 11, Grad norm: 1.509e+01\n",
      "Epoch 17429, Loss: 423.78179931640625, Neurons: 11, Grad norm: 1.404e+01\n",
      "Epoch 17430, Loss: 423.7764892578125, Neurons: 11, Grad norm: 1.212e+01\n",
      "Epoch 17431, Loss: 423.7711486816406, Neurons: 11, Grad norm: 1.067e+01\n",
      "Epoch 17432, Loss: 423.7657775878906, Neurons: 11, Grad norm: 8.846e+00\n",
      "Epoch 17433, Loss: 423.760498046875, Neurons: 11, Grad norm: 6.981e+00\n",
      "Epoch 17434, Loss: 423.75518798828125, Neurons: 11, Grad norm: 6.708e+00\n",
      "Epoch 17435, Loss: 423.7498474121094, Neurons: 11, Grad norm: 6.961e+00\n",
      "Epoch 17436, Loss: 423.7444763183594, Neurons: 11, Grad norm: 7.408e+00\n",
      "Epoch 17437, Loss: 423.7391357421875, Neurons: 11, Grad norm: 7.780e+00\n",
      "Epoch 17438, Loss: 423.7337951660156, Neurons: 11, Grad norm: 7.326e+00\n",
      "Epoch 17439, Loss: 423.7284240722656, Neurons: 11, Grad norm: 7.436e+00\n",
      "Epoch 17440, Loss: 423.72308349609375, Neurons: 11, Grad norm: 7.112e+00\n",
      "Epoch 17441, Loss: 423.7177429199219, Neurons: 11, Grad norm: 6.674e+00\n",
      "Epoch 17442, Loss: 423.71240234375, Neurons: 11, Grad norm: 6.505e+00\n",
      "Epoch 17443, Loss: 423.7070007324219, Neurons: 11, Grad norm: 6.027e+00\n",
      "Epoch 17444, Loss: 423.7016296386719, Neurons: 11, Grad norm: 5.398e+00\n",
      "Epoch 17445, Loss: 423.6961975097656, Neurons: 11, Grad norm: 5.302e+00\n",
      "Epoch 17446, Loss: 423.6908874511719, Neurons: 11, Grad norm: 5.884e+00\n",
      "Epoch 17447, Loss: 423.68548583984375, Neurons: 11, Grad norm: 6.131e+00\n",
      "Epoch 17448, Loss: 423.6800842285156, Neurons: 11, Grad norm: 6.069e+00\n",
      "Epoch 17449, Loss: 423.6746826171875, Neurons: 11, Grad norm: 6.468e+00\n",
      "Epoch 17449, Test loss: 420.52569580078125\n",
      "Epoch 17450, Loss: 423.6692810058594, Neurons: 11, Grad norm: 6.302e+00\n",
      "Epoch 17451, Loss: 423.66387939453125, Neurons: 11, Grad norm: 7.891e+00\n",
      "Epoch 17452, Loss: 423.658447265625, Neurons: 11, Grad norm: 9.822e+00\n",
      "Epoch 17453, Loss: 423.6530456542969, Neurons: 11, Grad norm: 1.074e+01\n",
      "Epoch 17454, Loss: 423.6475830078125, Neurons: 11, Grad norm: 1.200e+01\n",
      "Epoch 17455, Loss: 423.6421813964844, Neurons: 11, Grad norm: 1.333e+01\n",
      "Epoch 17456, Loss: 423.63677978515625, Neurons: 11, Grad norm: 1.508e+01\n",
      "Epoch 17457, Loss: 423.63134765625, Neurons: 11, Grad norm: 1.849e+01\n",
      "Epoch 17458, Loss: 423.6259460449219, Neurons: 11, Grad norm: 2.153e+01\n",
      "Epoch 17459, Loss: 423.6204833984375, Neurons: 11, Grad norm: 2.416e+01\n",
      "Epoch 17460, Loss: 423.614990234375, Neurons: 11, Grad norm: 2.707e+01\n",
      "Epoch 17461, Loss: 423.6095886230469, Neurons: 11, Grad norm: 3.113e+01\n",
      "Epoch 17462, Loss: 423.60418701171875, Neurons: 11, Grad norm: 3.570e+01\n",
      "Epoch 17463, Loss: 423.59869384765625, Neurons: 11, Grad norm: 3.971e+01\n",
      "Epoch 17464, Loss: 423.5932922363281, Neurons: 11, Grad norm: 4.361e+01\n",
      "Epoch 17465, Loss: 423.58782958984375, Neurons: 11, Grad norm: 4.819e+01\n",
      "Epoch 17466, Loss: 423.5823974609375, Neurons: 11, Grad norm: 5.353e+01\n",
      "Epoch 17467, Loss: 423.5769958496094, Neurons: 11, Grad norm: 6.021e+01\n",
      "Epoch 17468, Loss: 423.57159423828125, Neurons: 11, Grad norm: 6.737e+01\n",
      "Epoch 17469, Loss: 423.5661926269531, Neurons: 11, Grad norm: 7.533e+01\n",
      "Epoch 17470, Loss: 423.560791015625, Neurons: 11, Grad norm: 8.399e+01\n",
      "Epoch 17471, Loss: 423.5554504394531, Neurons: 11, Grad norm: 9.279e+01\n",
      "Epoch 17472, Loss: 423.5502014160156, Neurons: 11, Grad norm: 1.033e+02\n",
      "Epoch 17473, Loss: 423.5448913574219, Neurons: 11, Grad norm: 1.143e+02\n",
      "Epoch 17474, Loss: 423.5396423339844, Neurons: 11, Grad norm: 1.244e+02\n",
      "Epoch 17475, Loss: 423.5344543457031, Neurons: 11, Grad norm: 1.344e+02\n",
      "Epoch 17476, Loss: 423.52923583984375, Neurons: 11, Grad norm: 1.416e+02\n",
      "Epoch 17477, Loss: 423.52398681640625, Neurons: 11, Grad norm: 1.454e+02\n",
      "Epoch 17478, Loss: 423.51873779296875, Neurons: 11, Grad norm: 1.464e+02\n",
      "Epoch 17479, Loss: 423.5133972167969, Neurons: 11, Grad norm: 1.416e+02\n",
      "Epoch 17480, Loss: 423.5079345703125, Neurons: 11, Grad norm: 1.314e+02\n",
      "Epoch 17481, Loss: 423.50238037109375, Neurons: 11, Grad norm: 1.159e+02\n",
      "Epoch 17482, Loss: 423.4967041015625, Neurons: 11, Grad norm: 9.491e+01\n",
      "Epoch 17483, Loss: 423.4909973144531, Neurons: 11, Grad norm: 6.999e+01\n",
      "Epoch 17484, Loss: 423.4853820800781, Neurons: 11, Grad norm: 4.182e+01\n",
      "Epoch 17485, Loss: 423.4798889160156, Neurons: 11, Grad norm: 1.411e+01\n",
      "Epoch 17486, Loss: 423.4743957519531, Neurons: 11, Grad norm: 1.149e+01\n",
      "Epoch 17487, Loss: 423.4690856933594, Neurons: 11, Grad norm: 3.399e+01\n",
      "Epoch 17488, Loss: 423.4638977050781, Neurons: 11, Grad norm: 5.139e+01\n",
      "Epoch 17489, Loss: 423.458740234375, Neurons: 11, Grad norm: 6.400e+01\n",
      "Epoch 17490, Loss: 423.4535827636719, Neurons: 11, Grad norm: 7.179e+01\n",
      "Epoch 17491, Loss: 423.4483947753906, Neurons: 11, Grad norm: 7.276e+01\n",
      "Epoch 17492, Loss: 423.4430847167969, Neurons: 11, Grad norm: 6.923e+01\n",
      "Epoch 17493, Loss: 423.4377746582031, Neurons: 11, Grad norm: 6.079e+01\n",
      "Epoch 17494, Loss: 423.4323425292969, Neurons: 11, Grad norm: 4.843e+01\n",
      "Epoch 17495, Loss: 423.4268798828125, Neurons: 11, Grad norm: 3.461e+01\n",
      "Epoch 17496, Loss: 423.4214782714844, Neurons: 11, Grad norm: 1.974e+01\n",
      "Epoch 17497, Loss: 423.41619873046875, Neurons: 11, Grad norm: 5.508e+00\n",
      "Epoch 17498, Loss: 423.41082763671875, Neurons: 11, Grad norm: 8.331e+00\n",
      "Epoch 17499, Loss: 423.4055480957031, Neurons: 11, Grad norm: 2.030e+01\n",
      "Epoch 17499, Test loss: 420.257080078125\n",
      "Epoch 17500, Loss: 423.4002990722656, Neurons: 11, Grad norm: 3.005e+01\n",
      "Epoch 17501, Loss: 423.3949890136719, Neurons: 11, Grad norm: 3.769e+01\n",
      "Epoch 17502, Loss: 423.3896789550781, Neurons: 11, Grad norm: 4.220e+01\n",
      "Epoch 17503, Loss: 423.3844299316406, Neurons: 11, Grad norm: 4.386e+01\n",
      "Epoch 17504, Loss: 423.379150390625, Neurons: 11, Grad norm: 4.282e+01\n",
      "Epoch 17505, Loss: 423.373779296875, Neurons: 11, Grad norm: 3.923e+01\n",
      "Epoch 17506, Loss: 423.3683776855469, Neurons: 11, Grad norm: 3.361e+01\n",
      "Epoch 17507, Loss: 423.36309814453125, Neurons: 11, Grad norm: 2.726e+01\n",
      "Epoch 17508, Loss: 423.3576965332031, Neurons: 11, Grad norm: 1.976e+01\n",
      "Epoch 17509, Loss: 423.352294921875, Neurons: 11, Grad norm: 1.152e+01\n",
      "Epoch 17510, Loss: 423.34698486328125, Neurons: 11, Grad norm: 3.465e+00\n",
      "Epoch 17511, Loss: 423.3415832519531, Neurons: 11, Grad norm: 4.836e+00\n",
      "Epoch 17512, Loss: 423.3363037109375, Neurons: 11, Grad norm: 1.149e+01\n",
      "Epoch 17513, Loss: 423.3309020996094, Neurons: 11, Grad norm: 1.788e+01\n",
      "Epoch 17514, Loss: 423.3255310058594, Neurons: 11, Grad norm: 2.336e+01\n",
      "Epoch 17515, Loss: 423.3201904296875, Neurons: 11, Grad norm: 2.719e+01\n",
      "Epoch 17516, Loss: 423.31488037109375, Neurons: 11, Grad norm: 3.028e+01\n",
      "Epoch 17517, Loss: 423.3094787597656, Neurons: 11, Grad norm: 3.142e+01\n",
      "Epoch 17518, Loss: 423.30413818359375, Neurons: 11, Grad norm: 3.177e+01\n",
      "Epoch 17519, Loss: 423.2987365722656, Neurons: 11, Grad norm: 3.057e+01\n",
      "Epoch 17520, Loss: 423.29339599609375, Neurons: 11, Grad norm: 2.864e+01\n",
      "Epoch 17521, Loss: 423.2879943847656, Neurons: 11, Grad norm: 2.581e+01\n",
      "Epoch 17522, Loss: 423.2825927734375, Neurons: 11, Grad norm: 2.136e+01\n",
      "Epoch 17523, Loss: 423.2771301269531, Neurons: 11, Grad norm: 1.738e+01\n",
      "Epoch 17524, Loss: 423.271728515625, Neurons: 11, Grad norm: 1.404e+01\n",
      "Epoch 17525, Loss: 423.2663269042969, Neurons: 11, Grad norm: 8.775e+00\n",
      "Epoch 17526, Loss: 423.2608947753906, Neurons: 11, Grad norm: 4.921e+00\n",
      "Epoch 17527, Loss: 423.2554931640625, Neurons: 11, Grad norm: 2.539e+00\n",
      "Epoch 17528, Loss: 423.2500915527344, Neurons: 11, Grad norm: 2.963e+00\n",
      "Epoch 17529, Loss: 423.24462890625, Neurons: 11, Grad norm: 5.365e+00\n",
      "Epoch 17530, Loss: 423.2392272949219, Neurons: 11, Grad norm: 5.839e+00\n",
      "Epoch 17531, Loss: 423.23382568359375, Neurons: 11, Grad norm: 7.943e+00\n",
      "Epoch 17532, Loss: 423.2283935546875, Neurons: 11, Grad norm: 9.628e+00\n",
      "Epoch 17533, Loss: 423.2229309082031, Neurons: 11, Grad norm: 1.013e+01\n",
      "Epoch 17534, Loss: 423.2174987792969, Neurons: 11, Grad norm: 1.059e+01\n",
      "Epoch 17535, Loss: 423.21209716796875, Neurons: 11, Grad norm: 1.045e+01\n",
      "Epoch 17536, Loss: 423.20660400390625, Neurons: 11, Grad norm: 1.097e+01\n",
      "Epoch 17537, Loss: 423.2012023925781, Neurons: 11, Grad norm: 1.240e+01\n",
      "Epoch 17538, Loss: 423.1956787109375, Neurons: 11, Grad norm: 1.319e+01\n",
      "Epoch 17539, Loss: 423.190185546875, Neurons: 11, Grad norm: 1.528e+01\n",
      "Epoch 17540, Loss: 423.18475341796875, Neurons: 11, Grad norm: 1.700e+01\n",
      "Epoch 17541, Loss: 423.1792907714844, Neurons: 11, Grad norm: 1.893e+01\n",
      "Epoch 17542, Loss: 423.1737976074219, Neurons: 11, Grad norm: 2.103e+01\n",
      "Epoch 17543, Loss: 423.1683349609375, Neurons: 11, Grad norm: 2.142e+01\n",
      "Epoch 17544, Loss: 423.16290283203125, Neurons: 11, Grad norm: 2.110e+01\n",
      "Epoch 17545, Loss: 423.15728759765625, Neurons: 11, Grad norm: 2.083e+01\n",
      "Epoch 17546, Loss: 423.1518859863281, Neurons: 11, Grad norm: 1.878e+01\n",
      "Epoch 17547, Loss: 423.1463317871094, Neurons: 11, Grad norm: 1.717e+01\n",
      "Epoch 17548, Loss: 423.1407775878906, Neurons: 11, Grad norm: 1.476e+01\n",
      "Epoch 17549, Loss: 423.1352844238281, Neurons: 11, Grad norm: 1.204e+01\n",
      "Epoch 17549, Test loss: 419.9906005859375\n",
      "Epoch 17550, Loss: 423.1297912597656, Neurons: 11, Grad norm: 1.107e+01\n",
      "Epoch 17551, Loss: 423.1242980957031, Neurons: 11, Grad norm: 9.026e+00\n",
      "Epoch 17552, Loss: 423.1187438964844, Neurons: 11, Grad norm: 6.666e+00\n",
      "Epoch 17553, Loss: 423.1131896972656, Neurons: 11, Grad norm: 5.752e+00\n",
      "Epoch 17554, Loss: 423.1076354980469, Neurons: 11, Grad norm: 3.498e+00\n",
      "Epoch 17555, Loss: 423.1020812988281, Neurons: 11, Grad norm: 3.851e+00\n",
      "Epoch 17556, Loss: 423.0965881347656, Neurons: 11, Grad norm: 4.584e+00\n",
      "Epoch 17557, Loss: 423.09100341796875, Neurons: 11, Grad norm: 3.849e+00\n",
      "Epoch 17558, Loss: 423.0854797363281, Neurons: 11, Grad norm: 4.278e+00\n",
      "Epoch 17559, Loss: 423.07989501953125, Neurons: 11, Grad norm: 4.431e+00\n",
      "Epoch 17560, Loss: 423.07440185546875, Neurons: 11, Grad norm: 4.800e+00\n",
      "Epoch 17561, Loss: 423.06878662109375, Neurons: 11, Grad norm: 7.322e+00\n",
      "Epoch 17562, Loss: 423.06329345703125, Neurons: 11, Grad norm: 8.664e+00\n",
      "Epoch 17563, Loss: 423.05767822265625, Neurons: 11, Grad norm: 1.021e+01\n",
      "Epoch 17564, Loss: 423.0520935058594, Neurons: 11, Grad norm: 1.179e+01\n",
      "Epoch 17565, Loss: 423.0464782714844, Neurons: 11, Grad norm: 1.259e+01\n",
      "Epoch 17566, Loss: 423.0408935546875, Neurons: 11, Grad norm: 1.361e+01\n",
      "Epoch 17567, Loss: 423.0352783203125, Neurons: 11, Grad norm: 1.611e+01\n",
      "Epoch 17568, Loss: 423.0296936035156, Neurons: 11, Grad norm: 1.810e+01\n",
      "Epoch 17569, Loss: 423.0240783691406, Neurons: 11, Grad norm: 2.010e+01\n",
      "Epoch 17570, Loss: 423.01849365234375, Neurons: 11, Grad norm: 2.157e+01\n",
      "Epoch 17571, Loss: 423.01287841796875, Neurons: 11, Grad norm: 2.324e+01\n",
      "Epoch 17572, Loss: 423.0072937011719, Neurons: 11, Grad norm: 2.590e+01\n",
      "Epoch 17573, Loss: 423.0016784667969, Neurons: 11, Grad norm: 2.769e+01\n",
      "Epoch 17574, Loss: 422.99609375, Neurons: 11, Grad norm: 2.918e+01\n",
      "Epoch 17575, Loss: 422.990478515625, Neurons: 11, Grad norm: 3.303e+01\n",
      "Epoch 17576, Loss: 422.9848327636719, Neurons: 11, Grad norm: 3.627e+01\n",
      "Epoch 17577, Loss: 422.97918701171875, Neurons: 11, Grad norm: 4.090e+01\n",
      "Epoch 17578, Loss: 422.9736022949219, Neurons: 11, Grad norm: 4.625e+01\n",
      "Epoch 17579, Loss: 422.9679870605469, Neurons: 11, Grad norm: 5.041e+01\n",
      "Epoch 17580, Loss: 422.96240234375, Neurons: 11, Grad norm: 5.629e+01\n",
      "Epoch 17581, Loss: 422.95684814453125, Neurons: 11, Grad norm: 6.304e+01\n",
      "Epoch 17582, Loss: 422.9512939453125, Neurons: 11, Grad norm: 6.889e+01\n",
      "Epoch 17583, Loss: 422.9456787109375, Neurons: 11, Grad norm: 7.822e+01\n",
      "Epoch 17584, Loss: 422.94012451171875, Neurons: 11, Grad norm: 8.746e+01\n",
      "Epoch 17585, Loss: 422.93463134765625, Neurons: 11, Grad norm: 9.540e+01\n",
      "Epoch 17586, Loss: 422.92919921875, Neurons: 11, Grad norm: 1.058e+02\n",
      "Epoch 17587, Loss: 422.9236755371094, Neurons: 11, Grad norm: 1.150e+02\n",
      "Epoch 17588, Loss: 422.9183044433594, Neurons: 11, Grad norm: 1.227e+02\n",
      "Epoch 17589, Loss: 422.91290283203125, Neurons: 11, Grad norm: 1.318e+02\n",
      "Epoch 17590, Loss: 422.9075012207031, Neurons: 11, Grad norm: 1.366e+02\n",
      "Epoch 17591, Loss: 422.90203857421875, Neurons: 11, Grad norm: 1.374e+02\n",
      "Epoch 17592, Loss: 422.89654541015625, Neurons: 11, Grad norm: 1.356e+02\n",
      "Epoch 17593, Loss: 422.89093017578125, Neurons: 11, Grad norm: 1.275e+02\n",
      "Epoch 17594, Loss: 422.8852844238281, Neurons: 11, Grad norm: 1.149e+02\n",
      "Epoch 17595, Loss: 422.8794860839844, Neurons: 11, Grad norm: 9.834e+01\n",
      "Epoch 17596, Loss: 422.8736877441406, Neurons: 11, Grad norm: 7.567e+01\n",
      "Epoch 17597, Loss: 422.8678894042969, Neurons: 11, Grad norm: 5.079e+01\n",
      "Epoch 17598, Loss: 422.8620910644531, Neurons: 11, Grad norm: 2.480e+01\n",
      "Epoch 17599, Loss: 422.8564758300781, Neurons: 11, Grad norm: 2.432e+00\n",
      "Epoch 17599, Test loss: 419.71807861328125\n",
      "Epoch 17600, Loss: 422.85089111328125, Neurons: 11, Grad norm: 2.452e+01\n",
      "Epoch 17601, Loss: 422.8455505371094, Neurons: 11, Grad norm: 4.325e+01\n",
      "Epoch 17602, Loss: 422.84014892578125, Neurons: 11, Grad norm: 5.900e+01\n",
      "Epoch 17603, Loss: 422.8348388671875, Neurons: 11, Grad norm: 6.970e+01\n",
      "Epoch 17604, Loss: 422.8294982910156, Neurons: 11, Grad norm: 7.614e+01\n",
      "Epoch 17605, Loss: 422.8240966796875, Neurons: 11, Grad norm: 7.714e+01\n",
      "Epoch 17606, Loss: 422.8186340332031, Neurons: 11, Grad norm: 7.198e+01\n",
      "Epoch 17607, Loss: 422.8130798339844, Neurons: 11, Grad norm: 6.227e+01\n",
      "Epoch 17608, Loss: 422.8074951171875, Neurons: 11, Grad norm: 4.931e+01\n",
      "Epoch 17609, Loss: 422.8018798828125, Neurons: 11, Grad norm: 3.352e+01\n",
      "Epoch 17610, Loss: 422.7962951660156, Neurons: 11, Grad norm: 1.811e+01\n",
      "Epoch 17611, Loss: 422.7907409667969, Neurons: 11, Grad norm: 3.385e+00\n",
      "Epoch 17612, Loss: 422.7852478027344, Neurons: 11, Grad norm: 1.153e+01\n",
      "Epoch 17613, Loss: 422.77972412109375, Neurons: 11, Grad norm: 2.304e+01\n",
      "Epoch 17614, Loss: 422.7742919921875, Neurons: 11, Grad norm: 3.128e+01\n",
      "Epoch 17615, Loss: 422.7688293457031, Neurons: 11, Grad norm: 3.672e+01\n",
      "Epoch 17616, Loss: 422.7633972167969, Neurons: 11, Grad norm: 3.786e+01\n",
      "Epoch 17617, Loss: 422.7579040527344, Neurons: 11, Grad norm: 3.664e+01\n",
      "Epoch 17618, Loss: 422.75238037109375, Neurons: 11, Grad norm: 3.384e+01\n",
      "Epoch 17619, Loss: 422.746826171875, Neurons: 11, Grad norm: 2.953e+01\n",
      "Epoch 17620, Loss: 422.7413024902344, Neurons: 11, Grad norm: 2.399e+01\n",
      "Epoch 17621, Loss: 422.73577880859375, Neurons: 11, Grad norm: 1.863e+01\n",
      "Epoch 17622, Loss: 422.730224609375, Neurons: 11, Grad norm: 1.268e+01\n",
      "Epoch 17623, Loss: 422.7247009277344, Neurons: 11, Grad norm: 6.481e+00\n",
      "Epoch 17624, Loss: 422.71917724609375, Neurons: 11, Grad norm: 1.880e+00\n",
      "Epoch 17625, Loss: 422.7136535644531, Neurons: 11, Grad norm: 5.680e+00\n",
      "Epoch 17626, Loss: 422.7080993652344, Neurons: 11, Grad norm: 1.036e+01\n",
      "Epoch 17627, Loss: 422.70257568359375, Neurons: 11, Grad norm: 1.340e+01\n",
      "Epoch 17628, Loss: 422.6970520019531, Neurons: 11, Grad norm: 1.569e+01\n",
      "Epoch 17629, Loss: 422.6915283203125, Neurons: 11, Grad norm: 1.640e+01\n",
      "Epoch 17630, Loss: 422.68597412109375, Neurons: 11, Grad norm: 1.636e+01\n",
      "Epoch 17631, Loss: 422.6803894042969, Neurons: 11, Grad norm: 1.647e+01\n",
      "Epoch 17632, Loss: 422.6748352050781, Neurons: 11, Grad norm: 1.667e+01\n",
      "Epoch 17633, Loss: 422.66925048828125, Neurons: 11, Grad norm: 1.598e+01\n",
      "Epoch 17634, Loss: 422.6636962890625, Neurons: 11, Grad norm: 1.480e+01\n",
      "Epoch 17635, Loss: 422.6580810546875, Neurons: 11, Grad norm: 1.234e+01\n",
      "Epoch 17636, Loss: 422.65252685546875, Neurons: 11, Grad norm: 1.168e+01\n",
      "Epoch 17637, Loss: 422.6469421386719, Neurons: 11, Grad norm: 1.049e+01\n",
      "Epoch 17638, Loss: 422.6413879394531, Neurons: 11, Grad norm: 8.369e+00\n",
      "Epoch 17639, Loss: 422.63580322265625, Neurons: 11, Grad norm: 6.464e+00\n",
      "Epoch 17640, Loss: 422.630126953125, Neurons: 11, Grad norm: 4.541e+00\n",
      "Epoch 17641, Loss: 422.6245422363281, Neurons: 11, Grad norm: 2.313e+00\n",
      "Epoch 17642, Loss: 422.618896484375, Neurons: 11, Grad norm: 1.984e+00\n",
      "Epoch 17643, Loss: 422.61328125, Neurons: 11, Grad norm: 2.079e+00\n",
      "Epoch 17644, Loss: 422.60772705078125, Neurons: 11, Grad norm: 2.465e+00\n",
      "Epoch 17645, Loss: 422.6020812988281, Neurons: 11, Grad norm: 2.930e+00\n",
      "Epoch 17646, Loss: 422.596435546875, Neurons: 11, Grad norm: 2.167e+00\n",
      "Epoch 17647, Loss: 422.5907897949219, Neurons: 11, Grad norm: 1.924e+00\n",
      "Epoch 17648, Loss: 422.5851745605469, Neurons: 11, Grad norm: 2.173e+00\n",
      "Epoch 17649, Loss: 422.57958984375, Neurons: 11, Grad norm: 2.656e+00\n",
      "Epoch 17649, Test loss: 419.4452209472656\n",
      "Epoch 17650, Loss: 422.5738830566406, Neurons: 11, Grad norm: 3.322e+00\n",
      "Epoch 17651, Loss: 422.56829833984375, Neurons: 11, Grad norm: 3.415e+00\n",
      "Epoch 17652, Loss: 422.5625915527344, Neurons: 11, Grad norm: 4.116e+00\n",
      "Epoch 17653, Loss: 422.55694580078125, Neurons: 11, Grad norm: 3.971e+00\n",
      "Epoch 17654, Loss: 422.5513000488281, Neurons: 11, Grad norm: 4.277e+00\n",
      "Epoch 17655, Loss: 422.545654296875, Neurons: 11, Grad norm: 5.468e+00\n",
      "Epoch 17656, Loss: 422.5399475097656, Neurons: 11, Grad norm: 5.764e+00\n",
      "Epoch 17657, Loss: 422.5343017578125, Neurons: 11, Grad norm: 5.765e+00\n",
      "Epoch 17658, Loss: 422.5285339355469, Neurons: 11, Grad norm: 8.164e+00\n",
      "Epoch 17659, Loss: 422.52288818359375, Neurons: 11, Grad norm: 9.483e+00\n",
      "Epoch 17660, Loss: 422.5171813964844, Neurons: 11, Grad norm: 1.059e+01\n",
      "Epoch 17661, Loss: 422.511474609375, Neurons: 11, Grad norm: 1.165e+01\n",
      "Epoch 17662, Loss: 422.50579833984375, Neurons: 11, Grad norm: 1.211e+01\n",
      "Epoch 17663, Loss: 422.5000915527344, Neurons: 11, Grad norm: 1.206e+01\n",
      "Epoch 17664, Loss: 422.494384765625, Neurons: 11, Grad norm: 1.231e+01\n",
      "Epoch 17665, Loss: 422.4886779785156, Neurons: 11, Grad norm: 1.131e+01\n",
      "Epoch 17666, Loss: 422.4829406738281, Neurons: 11, Grad norm: 1.120e+01\n",
      "Epoch 17667, Loss: 422.4772033691406, Neurons: 11, Grad norm: 1.171e+01\n",
      "Epoch 17668, Loss: 422.47149658203125, Neurons: 11, Grad norm: 1.142e+01\n",
      "Epoch 17669, Loss: 422.4657897949219, Neurons: 11, Grad norm: 1.111e+01\n",
      "Epoch 17670, Loss: 422.4599914550781, Neurons: 11, Grad norm: 1.286e+01\n",
      "Epoch 17671, Loss: 422.4542541503906, Neurons: 11, Grad norm: 1.401e+01\n",
      "Epoch 17672, Loss: 422.448486328125, Neurons: 11, Grad norm: 1.502e+01\n",
      "Epoch 17673, Loss: 422.4427490234375, Neurons: 11, Grad norm: 1.585e+01\n",
      "Epoch 17674, Loss: 422.4369812011719, Neurons: 11, Grad norm: 1.661e+01\n",
      "Epoch 17675, Loss: 422.4312438964844, Neurons: 11, Grad norm: 1.664e+01\n",
      "Epoch 17676, Loss: 422.4254455566406, Neurons: 11, Grad norm: 1.728e+01\n",
      "Epoch 17677, Loss: 422.419677734375, Neurons: 11, Grad norm: 1.715e+01\n",
      "Epoch 17678, Loss: 422.41387939453125, Neurons: 11, Grad norm: 1.768e+01\n",
      "Epoch 17679, Loss: 422.4080810546875, Neurons: 11, Grad norm: 1.922e+01\n",
      "Epoch 17680, Loss: 422.40234375, Neurons: 11, Grad norm: 1.991e+01\n",
      "Epoch 17681, Loss: 422.39654541015625, Neurons: 11, Grad norm: 2.026e+01\n",
      "Epoch 17682, Loss: 422.3907775878906, Neurons: 11, Grad norm: 2.144e+01\n",
      "Epoch 17683, Loss: 422.38494873046875, Neurons: 11, Grad norm: 2.140e+01\n",
      "Epoch 17684, Loss: 422.3791809082031, Neurons: 11, Grad norm: 2.397e+01\n",
      "Epoch 17685, Loss: 422.3733825683594, Neurons: 11, Grad norm: 2.679e+01\n",
      "Epoch 17686, Loss: 422.3675537109375, Neurons: 11, Grad norm: 2.859e+01\n",
      "Epoch 17687, Loss: 422.3617248535156, Neurons: 11, Grad norm: 3.102e+01\n",
      "Epoch 17688, Loss: 422.3559265136719, Neurons: 11, Grad norm: 3.369e+01\n",
      "Epoch 17689, Loss: 422.35009765625, Neurons: 11, Grad norm: 3.700e+01\n",
      "Epoch 17690, Loss: 422.34429931640625, Neurons: 11, Grad norm: 4.243e+01\n",
      "Epoch 17691, Loss: 422.3385009765625, Neurons: 11, Grad norm: 4.726e+01\n",
      "Epoch 17692, Loss: 422.3327331542969, Neurons: 11, Grad norm: 5.384e+01\n",
      "Epoch 17693, Loss: 422.3269348144531, Neurons: 11, Grad norm: 6.270e+01\n",
      "Epoch 17694, Loss: 422.3211975097656, Neurons: 11, Grad norm: 7.246e+01\n",
      "Epoch 17695, Loss: 422.31549072265625, Neurons: 11, Grad norm: 8.361e+01\n",
      "Epoch 17696, Loss: 422.3098449707031, Neurons: 11, Grad norm: 9.648e+01\n",
      "Epoch 17697, Loss: 422.30419921875, Neurons: 11, Grad norm: 1.089e+02\n",
      "Epoch 17698, Loss: 422.29864501953125, Neurons: 11, Grad norm: 1.225e+02\n",
      "Epoch 17699, Loss: 422.29315185546875, Neurons: 11, Grad norm: 1.346e+02\n",
      "Epoch 17699, Test loss: 419.19189453125\n",
      "Epoch 17700, Loss: 422.2876281738281, Neurons: 11, Grad norm: 1.448e+02\n",
      "Epoch 17701, Loss: 422.2821350097656, Neurons: 11, Grad norm: 1.533e+02\n",
      "Epoch 17702, Loss: 422.2766418457031, Neurons: 11, Grad norm: 1.567e+02\n",
      "Epoch 17703, Loss: 422.2710266113281, Neurons: 11, Grad norm: 1.538e+02\n",
      "Epoch 17704, Loss: 422.2652893066406, Neurons: 11, Grad norm: 1.444e+02\n",
      "Epoch 17705, Loss: 422.25933837890625, Neurons: 11, Grad norm: 1.263e+02\n",
      "Epoch 17706, Loss: 422.25323486328125, Neurons: 11, Grad norm: 1.009e+02\n",
      "Epoch 17707, Loss: 422.2471008300781, Neurons: 11, Grad norm: 7.043e+01\n",
      "Epoch 17708, Loss: 422.2409973144531, Neurons: 11, Grad norm: 3.804e+01\n",
      "Epoch 17709, Loss: 422.2350769042969, Neurons: 11, Grad norm: 5.420e+00\n",
      "Epoch 17710, Loss: 422.2293395996094, Neurons: 11, Grad norm: 2.499e+01\n",
      "Epoch 17711, Loss: 422.2237854003906, Neurons: 11, Grad norm: 4.995e+01\n",
      "Epoch 17712, Loss: 422.2183532714844, Neurons: 11, Grad norm: 6.881e+01\n",
      "Epoch 17713, Loss: 422.2129821777344, Neurons: 11, Grad norm: 8.208e+01\n",
      "Epoch 17714, Loss: 422.2074890136719, Neurons: 11, Grad norm: 8.674e+01\n",
      "Epoch 17715, Loss: 422.2019958496094, Neurons: 11, Grad norm: 8.312e+01\n",
      "Epoch 17716, Loss: 422.19635009765625, Neurons: 11, Grad norm: 7.235e+01\n",
      "Epoch 17717, Loss: 422.1905822753906, Neurons: 11, Grad norm: 5.606e+01\n",
      "Epoch 17718, Loss: 422.1847839355469, Neurons: 11, Grad norm: 3.607e+01\n",
      "Epoch 17719, Loss: 422.1789855957031, Neurons: 11, Grad norm: 1.437e+01\n",
      "Epoch 17720, Loss: 422.17327880859375, Neurons: 11, Grad norm: 7.710e+00\n",
      "Epoch 17721, Loss: 422.1676940917969, Neurons: 11, Grad norm: 2.548e+01\n",
      "Epoch 17722, Loss: 422.1621398925781, Neurons: 11, Grad norm: 3.993e+01\n",
      "Epoch 17723, Loss: 422.1566467285156, Neurons: 11, Grad norm: 4.828e+01\n",
      "Epoch 17724, Loss: 422.1510314941406, Neurons: 11, Grad norm: 5.279e+01\n",
      "Epoch 17725, Loss: 422.1454772949219, Neurons: 11, Grad norm: 5.367e+01\n",
      "Epoch 17726, Loss: 422.139892578125, Neurons: 11, Grad norm: 4.900e+01\n",
      "Epoch 17727, Loss: 422.1341857910156, Neurons: 11, Grad norm: 4.088e+01\n",
      "Epoch 17728, Loss: 422.12847900390625, Neurons: 11, Grad norm: 3.128e+01\n",
      "Epoch 17729, Loss: 422.1228332519531, Neurons: 11, Grad norm: 1.891e+01\n",
      "Epoch 17730, Loss: 422.11712646484375, Neurons: 11, Grad norm: 8.262e+00\n",
      "Epoch 17731, Loss: 422.1114807128906, Neurons: 11, Grad norm: 2.941e+00\n",
      "Epoch 17732, Loss: 422.10589599609375, Neurons: 11, Grad norm: 1.206e+01\n",
      "Epoch 17733, Loss: 422.1001892089844, Neurons: 11, Grad norm: 1.908e+01\n",
      "Epoch 17734, Loss: 422.0946044921875, Neurons: 11, Grad norm: 2.358e+01\n",
      "Epoch 17735, Loss: 422.08892822265625, Neurons: 11, Grad norm: 2.785e+01\n",
      "Epoch 17736, Loss: 422.0832824707031, Neurons: 11, Grad norm: 2.845e+01\n",
      "Epoch 17737, Loss: 422.07769775390625, Neurons: 11, Grad norm: 2.692e+01\n",
      "Epoch 17738, Loss: 422.0719909667969, Neurons: 11, Grad norm: 2.447e+01\n",
      "Epoch 17739, Loss: 422.0662841796875, Neurons: 11, Grad norm: 2.096e+01\n",
      "Epoch 17740, Loss: 422.0606384277344, Neurons: 11, Grad norm: 1.643e+01\n",
      "Epoch 17741, Loss: 422.05499267578125, Neurons: 11, Grad norm: 1.263e+01\n",
      "Epoch 17742, Loss: 422.0492248535156, Neurons: 11, Grad norm: 8.106e+00\n",
      "Epoch 17743, Loss: 422.0435791015625, Neurons: 11, Grad norm: 5.145e+00\n",
      "Epoch 17744, Loss: 422.03790283203125, Neurons: 11, Grad norm: 2.765e+00\n",
      "Epoch 17745, Loss: 422.0321960449219, Neurons: 11, Grad norm: 2.189e+00\n",
      "Epoch 17746, Loss: 422.0264892578125, Neurons: 11, Grad norm: 4.137e+00\n",
      "Epoch 17747, Loss: 422.0207824707031, Neurons: 11, Grad norm: 5.548e+00\n",
      "Epoch 17748, Loss: 422.01507568359375, Neurons: 11, Grad norm: 7.496e+00\n",
      "Epoch 17749, Loss: 422.0093994140625, Neurons: 11, Grad norm: 7.773e+00\n",
      "Epoch 17749, Test loss: 418.8843078613281\n",
      "Epoch 17750, Loss: 422.0036315917969, Neurons: 11, Grad norm: 8.150e+00\n",
      "Epoch 17751, Loss: 421.9979248046875, Neurons: 11, Grad norm: 7.455e+00\n",
      "Epoch 17752, Loss: 421.9921875, Neurons: 11, Grad norm: 6.555e+00\n",
      "Epoch 17753, Loss: 421.9864807128906, Neurons: 11, Grad norm: 6.639e+00\n",
      "Epoch 17754, Loss: 421.9807434082031, Neurons: 11, Grad norm: 5.725e+00\n",
      "Epoch 17755, Loss: 421.9749755859375, Neurons: 11, Grad norm: 4.000e+00\n",
      "Epoch 17756, Loss: 421.96923828125, Neurons: 11, Grad norm: 5.015e+00\n",
      "Epoch 17757, Loss: 421.9635009765625, Neurons: 11, Grad norm: 3.447e+00\n",
      "Epoch 17758, Loss: 421.95770263671875, Neurons: 11, Grad norm: 2.010e+00\n",
      "Epoch 17759, Loss: 421.9519958496094, Neurons: 11, Grad norm: 1.939e+00\n",
      "Epoch 17760, Loss: 421.9461975097656, Neurons: 11, Grad norm: 2.676e+00\n",
      "Epoch 17761, Loss: 421.94049072265625, Neurons: 11, Grad norm: 3.776e+00\n",
      "Epoch 17762, Loss: 421.9346923828125, Neurons: 11, Grad norm: 3.667e+00\n",
      "Epoch 17763, Loss: 421.92889404296875, Neurons: 11, Grad norm: 5.057e+00\n",
      "Epoch 17764, Loss: 421.923095703125, Neurons: 11, Grad norm: 4.677e+00\n",
      "Epoch 17765, Loss: 421.91729736328125, Neurons: 11, Grad norm: 4.910e+00\n",
      "Epoch 17766, Loss: 421.9114990234375, Neurons: 11, Grad norm: 6.373e+00\n",
      "Epoch 17767, Loss: 421.9057312011719, Neurons: 11, Grad norm: 6.101e+00\n",
      "Epoch 17768, Loss: 421.89990234375, Neurons: 11, Grad norm: 5.864e+00\n",
      "Epoch 17769, Loss: 421.89410400390625, Neurons: 11, Grad norm: 8.005e+00\n",
      "Epoch 17770, Loss: 421.8882751464844, Neurons: 11, Grad norm: 8.495e+00\n",
      "Epoch 17771, Loss: 421.8824768066406, Neurons: 11, Grad norm: 1.099e+01\n",
      "Epoch 17772, Loss: 421.8766784667969, Neurons: 11, Grad norm: 1.329e+01\n",
      "Epoch 17773, Loss: 421.87078857421875, Neurons: 11, Grad norm: 1.372e+01\n",
      "Epoch 17774, Loss: 421.864990234375, Neurons: 11, Grad norm: 1.434e+01\n",
      "Epoch 17775, Loss: 421.859130859375, Neurons: 11, Grad norm: 1.448e+01\n",
      "Epoch 17776, Loss: 421.8533020019531, Neurons: 11, Grad norm: 1.433e+01\n",
      "Epoch 17777, Loss: 421.8475036621094, Neurons: 11, Grad norm: 1.604e+01\n",
      "Epoch 17778, Loss: 421.8415832519531, Neurons: 11, Grad norm: 1.623e+01\n",
      "Epoch 17779, Loss: 421.83575439453125, Neurons: 11, Grad norm: 1.767e+01\n",
      "Epoch 17780, Loss: 421.82989501953125, Neurons: 11, Grad norm: 1.907e+01\n",
      "Epoch 17781, Loss: 421.82403564453125, Neurons: 11, Grad norm: 2.011e+01\n",
      "Epoch 17782, Loss: 421.81817626953125, Neurons: 11, Grad norm: 2.170e+01\n",
      "Epoch 17783, Loss: 421.8122863769531, Neurons: 11, Grad norm: 2.360e+01\n",
      "Epoch 17784, Loss: 421.806396484375, Neurons: 11, Grad norm: 2.436e+01\n",
      "Epoch 17785, Loss: 421.800537109375, Neurons: 11, Grad norm: 2.508e+01\n",
      "Epoch 17786, Loss: 421.7946472167969, Neurons: 11, Grad norm: 2.394e+01\n",
      "Epoch 17787, Loss: 421.7887268066406, Neurons: 11, Grad norm: 2.319e+01\n",
      "Epoch 17788, Loss: 421.7828369140625, Neurons: 11, Grad norm: 2.305e+01\n",
      "Epoch 17789, Loss: 421.7768859863281, Neurons: 11, Grad norm: 2.316e+01\n",
      "Epoch 17790, Loss: 421.7710266113281, Neurons: 11, Grad norm: 2.337e+01\n",
      "Epoch 17791, Loss: 421.76507568359375, Neurons: 11, Grad norm: 2.446e+01\n",
      "Epoch 17792, Loss: 421.7591857910156, Neurons: 11, Grad norm: 2.338e+01\n",
      "Epoch 17793, Loss: 421.7532958984375, Neurons: 11, Grad norm: 2.309e+01\n",
      "Epoch 17794, Loss: 421.74737548828125, Neurons: 11, Grad norm: 2.334e+01\n",
      "Epoch 17795, Loss: 421.74139404296875, Neurons: 11, Grad norm: 2.237e+01\n",
      "Epoch 17796, Loss: 421.7355041503906, Neurons: 11, Grad norm: 2.106e+01\n",
      "Epoch 17797, Loss: 421.7295837402344, Neurons: 11, Grad norm: 2.029e+01\n",
      "Epoch 17798, Loss: 421.7236022949219, Neurons: 11, Grad norm: 1.789e+01\n",
      "Epoch 17799, Loss: 421.7176818847656, Neurons: 11, Grad norm: 1.659e+01\n",
      "Epoch 17799, Test loss: 418.59014892578125\n",
      "Epoch 17800, Loss: 421.7117004394531, Neurons: 11, Grad norm: 1.456e+01\n",
      "Epoch 17801, Loss: 421.70574951171875, Neurons: 11, Grad norm: 1.278e+01\n",
      "Epoch 17802, Loss: 421.6997985839844, Neurons: 11, Grad norm: 1.274e+01\n",
      "Epoch 17803, Loss: 421.69378662109375, Neurons: 11, Grad norm: 1.358e+01\n",
      "Epoch 17804, Loss: 421.6878356933594, Neurons: 11, Grad norm: 1.432e+01\n",
      "Epoch 17805, Loss: 421.6818542480469, Neurons: 11, Grad norm: 1.727e+01\n",
      "Epoch 17806, Loss: 421.6759033203125, Neurons: 11, Grad norm: 1.939e+01\n",
      "Epoch 17807, Loss: 421.6699523925781, Neurons: 11, Grad norm: 2.285e+01\n",
      "Epoch 17808, Loss: 421.66387939453125, Neurons: 11, Grad norm: 2.660e+01\n",
      "Epoch 17809, Loss: 421.6579284667969, Neurons: 11, Grad norm: 2.891e+01\n",
      "Epoch 17810, Loss: 421.6519775390625, Neurons: 11, Grad norm: 3.107e+01\n",
      "Epoch 17811, Loss: 421.64599609375, Neurons: 11, Grad norm: 3.371e+01\n",
      "Epoch 17812, Loss: 421.6399841308594, Neurons: 11, Grad norm: 3.455e+01\n",
      "Epoch 17813, Loss: 421.6340026855469, Neurons: 11, Grad norm: 3.681e+01\n",
      "Epoch 17814, Loss: 421.62799072265625, Neurons: 11, Grad norm: 3.955e+01\n",
      "Epoch 17815, Loss: 421.6219787597656, Neurons: 11, Grad norm: 4.294e+01\n",
      "Epoch 17816, Loss: 421.6159973144531, Neurons: 11, Grad norm: 4.695e+01\n",
      "Epoch 17817, Loss: 421.6099853515625, Neurons: 11, Grad norm: 5.187e+01\n",
      "Epoch 17818, Loss: 421.6040344238281, Neurons: 11, Grad norm: 5.654e+01\n",
      "Epoch 17819, Loss: 421.59808349609375, Neurons: 11, Grad norm: 6.245e+01\n",
      "Epoch 17820, Loss: 421.59210205078125, Neurons: 11, Grad norm: 6.781e+01\n",
      "Epoch 17821, Loss: 421.586181640625, Neurons: 11, Grad norm: 7.405e+01\n",
      "Epoch 17822, Loss: 421.5802001953125, Neurons: 11, Grad norm: 8.152e+01\n",
      "Epoch 17823, Loss: 421.57427978515625, Neurons: 11, Grad norm: 8.959e+01\n",
      "Epoch 17824, Loss: 421.5683898925781, Neurons: 11, Grad norm: 9.728e+01\n",
      "Epoch 17825, Loss: 421.5625305175781, Neurons: 11, Grad norm: 1.057e+02\n",
      "Epoch 17826, Loss: 421.55670166015625, Neurons: 11, Grad norm: 1.138e+02\n",
      "Epoch 17827, Loss: 421.5509338378906, Neurons: 11, Grad norm: 1.214e+02\n",
      "Epoch 17828, Loss: 421.5450744628906, Neurons: 11, Grad norm: 1.265e+02\n",
      "Epoch 17829, Loss: 421.5392761230469, Neurons: 11, Grad norm: 1.291e+02\n",
      "Epoch 17830, Loss: 421.53338623046875, Neurons: 11, Grad norm: 1.274e+02\n",
      "Epoch 17831, Loss: 421.5274963378906, Neurons: 11, Grad norm: 1.215e+02\n",
      "Epoch 17832, Loss: 421.521484375, Neurons: 11, Grad norm: 1.105e+02\n",
      "Epoch 17833, Loss: 421.5153503417969, Neurons: 11, Grad norm: 9.580e+01\n",
      "Epoch 17834, Loss: 421.5091857910156, Neurons: 11, Grad norm: 7.740e+01\n",
      "Epoch 17835, Loss: 421.5030822753906, Neurons: 11, Grad norm: 5.629e+01\n",
      "Epoch 17836, Loss: 421.4969482421875, Neurons: 11, Grad norm: 3.410e+01\n",
      "Epoch 17837, Loss: 421.4908752441406, Neurons: 11, Grad norm: 1.230e+01\n",
      "Epoch 17838, Loss: 421.4849853515625, Neurons: 11, Grad norm: 1.004e+01\n",
      "Epoch 17839, Loss: 421.4790954589844, Neurons: 11, Grad norm: 2.784e+01\n",
      "Epoch 17840, Loss: 421.4732971191406, Neurons: 11, Grad norm: 4.246e+01\n",
      "Epoch 17841, Loss: 421.467529296875, Neurons: 11, Grad norm: 5.364e+01\n",
      "Epoch 17842, Loss: 421.4617919921875, Neurons: 11, Grad norm: 6.034e+01\n",
      "Epoch 17843, Loss: 421.45599365234375, Neurons: 11, Grad norm: 6.211e+01\n",
      "Epoch 17844, Loss: 421.45013427734375, Neurons: 11, Grad norm: 6.065e+01\n",
      "Epoch 17845, Loss: 421.4442443847656, Neurons: 11, Grad norm: 5.421e+01\n",
      "Epoch 17846, Loss: 421.43829345703125, Neurons: 11, Grad norm: 4.591e+01\n",
      "Epoch 17847, Loss: 421.4323425292969, Neurons: 11, Grad norm: 3.504e+01\n",
      "Epoch 17848, Loss: 421.4263916015625, Neurons: 11, Grad norm: 2.193e+01\n",
      "Epoch 17849, Loss: 421.4203796386719, Neurons: 11, Grad norm: 8.759e+00\n",
      "Epoch 17849, Test loss: 418.30328369140625\n",
      "Epoch 17850, Loss: 421.41455078125, Neurons: 11, Grad norm: 4.114e+00\n",
      "Epoch 17851, Loss: 421.40863037109375, Neurons: 11, Grad norm: 1.547e+01\n",
      "Epoch 17852, Loss: 421.4028015136719, Neurons: 11, Grad norm: 2.348e+01\n",
      "Epoch 17853, Loss: 421.3969421386719, Neurons: 11, Grad norm: 3.013e+01\n",
      "Epoch 17854, Loss: 421.3910827636719, Neurons: 11, Grad norm: 3.482e+01\n",
      "Epoch 17855, Loss: 421.38519287109375, Neurons: 11, Grad norm: 3.732e+01\n",
      "Epoch 17856, Loss: 421.3793029785156, Neurons: 11, Grad norm: 3.745e+01\n",
      "Epoch 17857, Loss: 421.3733825683594, Neurons: 11, Grad norm: 3.641e+01\n",
      "Epoch 17858, Loss: 421.36749267578125, Neurons: 11, Grad norm: 3.285e+01\n",
      "Epoch 17859, Loss: 421.3616027832031, Neurons: 11, Grad norm: 2.910e+01\n",
      "Epoch 17860, Loss: 421.3555908203125, Neurons: 11, Grad norm: 2.392e+01\n",
      "Epoch 17861, Loss: 421.3496398925781, Neurons: 11, Grad norm: 1.738e+01\n",
      "Epoch 17862, Loss: 421.34368896484375, Neurons: 11, Grad norm: 1.024e+01\n",
      "Epoch 17863, Loss: 421.3377380371094, Neurons: 11, Grad norm: 3.932e+00\n",
      "Epoch 17864, Loss: 421.33184814453125, Neurons: 11, Grad norm: 4.231e+00\n",
      "Epoch 17865, Loss: 421.3258972167969, Neurons: 11, Grad norm: 9.168e+00\n",
      "Epoch 17866, Loss: 421.3199462890625, Neurons: 11, Grad norm: 1.401e+01\n",
      "Epoch 17867, Loss: 421.3139953613281, Neurons: 11, Grad norm: 1.706e+01\n",
      "Epoch 17868, Loss: 421.3080749511719, Neurons: 11, Grad norm: 1.912e+01\n",
      "Epoch 17869, Loss: 421.3020935058594, Neurons: 11, Grad norm: 2.107e+01\n",
      "Epoch 17870, Loss: 421.296142578125, Neurons: 11, Grad norm: 2.287e+01\n",
      "Epoch 17871, Loss: 421.2901916503906, Neurons: 11, Grad norm: 2.313e+01\n",
      "Epoch 17872, Loss: 421.2841796875, Neurons: 11, Grad norm: 2.434e+01\n",
      "Epoch 17873, Loss: 421.2781982421875, Neurons: 11, Grad norm: 2.382e+01\n",
      "Epoch 17874, Loss: 421.2722473144531, Neurons: 11, Grad norm: 2.210e+01\n",
      "Epoch 17875, Loss: 421.26629638671875, Neurons: 11, Grad norm: 1.938e+01\n",
      "Epoch 17876, Loss: 421.2602844238281, Neurons: 11, Grad norm: 1.617e+01\n",
      "Epoch 17877, Loss: 421.2543029785156, Neurons: 11, Grad norm: 1.200e+01\n",
      "Epoch 17878, Loss: 421.24822998046875, Neurons: 11, Grad norm: 8.547e+00\n",
      "Epoch 17879, Loss: 421.24224853515625, Neurons: 11, Grad norm: 4.228e+00\n",
      "Epoch 17880, Loss: 421.2361755371094, Neurons: 11, Grad norm: 1.927e+00\n",
      "Epoch 17881, Loss: 421.2301940917969, Neurons: 11, Grad norm: 3.910e+00\n",
      "Epoch 17882, Loss: 421.22418212890625, Neurons: 11, Grad norm: 6.599e+00\n",
      "Epoch 17883, Loss: 421.2181396484375, Neurons: 11, Grad norm: 7.666e+00\n",
      "Epoch 17884, Loss: 421.21209716796875, Neurons: 11, Grad norm: 8.714e+00\n",
      "Epoch 17885, Loss: 421.2060852050781, Neurons: 11, Grad norm: 1.005e+01\n",
      "Epoch 17886, Loss: 421.2000427246094, Neurons: 11, Grad norm: 9.548e+00\n",
      "Epoch 17887, Loss: 421.1940002441406, Neurons: 11, Grad norm: 1.173e+01\n",
      "Epoch 17888, Loss: 421.18792724609375, Neurons: 11, Grad norm: 1.304e+01\n",
      "Epoch 17889, Loss: 421.181884765625, Neurons: 11, Grad norm: 1.290e+01\n",
      "Epoch 17890, Loss: 421.17578125, Neurons: 11, Grad norm: 1.309e+01\n",
      "Epoch 17891, Loss: 421.1697998046875, Neurons: 11, Grad norm: 1.282e+01\n",
      "Epoch 17892, Loss: 421.1636962890625, Neurons: 11, Grad norm: 1.123e+01\n",
      "Epoch 17893, Loss: 421.15765380859375, Neurons: 11, Grad norm: 1.107e+01\n",
      "Epoch 17894, Loss: 421.1514892578125, Neurons: 11, Grad norm: 8.983e+00\n",
      "Epoch 17895, Loss: 421.1453857421875, Neurons: 11, Grad norm: 7.862e+00\n",
      "Epoch 17896, Loss: 421.13934326171875, Neurons: 11, Grad norm: 8.073e+00\n",
      "Epoch 17897, Loss: 421.1331787109375, Neurons: 11, Grad norm: 7.031e+00\n",
      "Epoch 17898, Loss: 421.127197265625, Neurons: 11, Grad norm: 6.081e+00\n",
      "Epoch 17899, Loss: 421.1210021972656, Neurons: 11, Grad norm: 7.848e+00\n",
      "Epoch 17899, Test loss: 418.0037841796875\n",
      "Epoch 17900, Loss: 421.11492919921875, Neurons: 11, Grad norm: 8.138e+00\n",
      "Epoch 17901, Loss: 421.1087951660156, Neurons: 11, Grad norm: 1.050e+01\n",
      "Epoch 17902, Loss: 421.1026916503906, Neurons: 11, Grad norm: 1.302e+01\n",
      "Epoch 17903, Loss: 421.0965270996094, Neurons: 11, Grad norm: 1.414e+01\n",
      "Epoch 17904, Loss: 421.09039306640625, Neurons: 11, Grad norm: 1.529e+01\n",
      "Epoch 17905, Loss: 421.08428955078125, Neurons: 11, Grad norm: 1.666e+01\n",
      "Epoch 17906, Loss: 421.078125, Neurons: 11, Grad norm: 1.631e+01\n",
      "Epoch 17907, Loss: 421.0719909667969, Neurons: 11, Grad norm: 1.744e+01\n",
      "Epoch 17908, Loss: 421.0657958984375, Neurons: 11, Grad norm: 1.870e+01\n",
      "Epoch 17909, Loss: 421.05963134765625, Neurons: 11, Grad norm: 2.074e+01\n",
      "Epoch 17910, Loss: 421.0534973144531, Neurons: 11, Grad norm: 2.324e+01\n",
      "Epoch 17911, Loss: 421.0473327636719, Neurons: 11, Grad norm: 2.653e+01\n",
      "Epoch 17912, Loss: 421.04119873046875, Neurons: 11, Grad norm: 2.961e+01\n",
      "Epoch 17913, Loss: 421.0350341796875, Neurons: 11, Grad norm: 3.412e+01\n",
      "Epoch 17914, Loss: 421.0289001464844, Neurons: 11, Grad norm: 3.793e+01\n",
      "Epoch 17915, Loss: 421.0226745605469, Neurons: 11, Grad norm: 4.303e+01\n",
      "Epoch 17916, Loss: 421.01654052734375, Neurons: 11, Grad norm: 4.934e+01\n",
      "Epoch 17917, Loss: 421.0103759765625, Neurons: 11, Grad norm: 5.516e+01\n",
      "Epoch 17918, Loss: 421.0043029785156, Neurons: 11, Grad norm: 6.085e+01\n",
      "Epoch 17919, Loss: 420.9981994628906, Neurons: 11, Grad norm: 6.926e+01\n",
      "Epoch 17920, Loss: 420.9920349121094, Neurons: 11, Grad norm: 7.680e+01\n",
      "Epoch 17921, Loss: 420.9859313964844, Neurons: 11, Grad norm: 8.543e+01\n",
      "Epoch 17922, Loss: 420.9798889160156, Neurons: 11, Grad norm: 9.398e+01\n",
      "Epoch 17923, Loss: 420.973876953125, Neurons: 11, Grad norm: 1.001e+02\n",
      "Epoch 17924, Loss: 420.96783447265625, Neurons: 11, Grad norm: 1.062e+02\n",
      "Epoch 17925, Loss: 420.9617919921875, Neurons: 11, Grad norm: 1.129e+02\n",
      "Epoch 17926, Loss: 420.9557800292969, Neurons: 11, Grad norm: 1.160e+02\n",
      "Epoch 17927, Loss: 420.9496765136719, Neurons: 11, Grad norm: 1.186e+02\n",
      "Epoch 17928, Loss: 420.9436340332031, Neurons: 11, Grad norm: 1.175e+02\n",
      "Epoch 17929, Loss: 420.9375, Neurons: 11, Grad norm: 1.110e+02\n",
      "Epoch 17930, Loss: 420.9312744140625, Neurons: 11, Grad norm: 1.012e+02\n",
      "Epoch 17931, Loss: 420.92498779296875, Neurons: 11, Grad norm: 8.736e+01\n",
      "Epoch 17932, Loss: 420.9187316894531, Neurons: 11, Grad norm: 6.950e+01\n",
      "Epoch 17933, Loss: 420.9124450683594, Neurons: 11, Grad norm: 5.173e+01\n",
      "Epoch 17934, Loss: 420.90618896484375, Neurons: 11, Grad norm: 3.216e+01\n",
      "Epoch 17935, Loss: 420.8999328613281, Neurons: 11, Grad norm: 1.330e+01\n",
      "Epoch 17936, Loss: 420.8938293457031, Neurons: 11, Grad norm: 5.865e+00\n",
      "Epoch 17937, Loss: 420.8876953125, Neurons: 11, Grad norm: 2.341e+01\n",
      "Epoch 17938, Loss: 420.8816833496094, Neurons: 11, Grad norm: 3.864e+01\n",
      "Epoch 17939, Loss: 420.8757019042969, Neurons: 11, Grad norm: 4.992e+01\n",
      "Epoch 17940, Loss: 420.8697814941406, Neurons: 11, Grad norm: 5.869e+01\n",
      "Epoch 17941, Loss: 420.8638000488281, Neurons: 11, Grad norm: 6.204e+01\n",
      "Epoch 17942, Loss: 420.85772705078125, Neurons: 11, Grad norm: 6.245e+01\n",
      "Epoch 17943, Loss: 420.8516845703125, Neurons: 11, Grad norm: 6.039e+01\n",
      "Epoch 17944, Loss: 420.8455810546875, Neurons: 11, Grad norm: 5.582e+01\n",
      "Epoch 17945, Loss: 420.8394775390625, Neurons: 11, Grad norm: 4.909e+01\n",
      "Epoch 17946, Loss: 420.8333435058594, Neurons: 11, Grad norm: 4.199e+01\n",
      "Epoch 17947, Loss: 420.8271789550781, Neurons: 11, Grad norm: 3.146e+01\n",
      "Epoch 17948, Loss: 420.821044921875, Neurons: 11, Grad norm: 2.036e+01\n",
      "Epoch 17949, Loss: 420.81488037109375, Neurons: 11, Grad norm: 1.018e+01\n",
      "Epoch 17949, Test loss: 417.7060852050781\n",
      "Epoch 17950, Loss: 420.80877685546875, Neurons: 11, Grad norm: 2.118e+00\n",
      "Epoch 17951, Loss: 420.8027038574219, Neurons: 11, Grad norm: 8.818e+00\n",
      "Epoch 17952, Loss: 420.7966003417969, Neurons: 11, Grad norm: 1.707e+01\n",
      "Epoch 17953, Loss: 420.7904968261719, Neurons: 11, Grad norm: 2.497e+01\n",
      "Epoch 17954, Loss: 420.7844543457031, Neurons: 11, Grad norm: 3.062e+01\n",
      "Epoch 17955, Loss: 420.7783508300781, Neurons: 11, Grad norm: 3.534e+01\n",
      "Epoch 17956, Loss: 420.77227783203125, Neurons: 11, Grad norm: 3.757e+01\n",
      "Epoch 17957, Loss: 420.7661437988281, Neurons: 11, Grad norm: 3.872e+01\n",
      "Epoch 17958, Loss: 420.7601013183594, Neurons: 11, Grad norm: 3.753e+01\n",
      "Epoch 17959, Loss: 420.7539367675781, Neurons: 11, Grad norm: 3.406e+01\n",
      "Epoch 17960, Loss: 420.747802734375, Neurons: 11, Grad norm: 2.987e+01\n",
      "Epoch 17961, Loss: 420.74163818359375, Neurons: 11, Grad norm: 2.594e+01\n",
      "Epoch 17962, Loss: 420.7354431152344, Neurons: 11, Grad norm: 1.888e+01\n",
      "Epoch 17963, Loss: 420.7292785644531, Neurons: 11, Grad norm: 1.281e+01\n",
      "Epoch 17964, Loss: 420.72314453125, Neurons: 11, Grad norm: 6.271e+00\n",
      "Epoch 17965, Loss: 420.71697998046875, Neurons: 11, Grad norm: 2.060e+00\n",
      "Epoch 17966, Loss: 420.7107849121094, Neurons: 11, Grad norm: 6.616e+00\n",
      "Epoch 17967, Loss: 420.70465087890625, Neurons: 11, Grad norm: 1.241e+01\n",
      "Epoch 17968, Loss: 420.698486328125, Neurons: 11, Grad norm: 1.718e+01\n",
      "Epoch 17969, Loss: 420.6922912597656, Neurons: 11, Grad norm: 1.900e+01\n",
      "Epoch 17970, Loss: 420.6861877441406, Neurons: 11, Grad norm: 2.340e+01\n",
      "Epoch 17971, Loss: 420.67999267578125, Neurons: 11, Grad norm: 2.541e+01\n",
      "Epoch 17972, Loss: 420.673828125, Neurons: 11, Grad norm: 2.541e+01\n",
      "Epoch 17973, Loss: 420.6676025390625, Neurons: 11, Grad norm: 2.526e+01\n",
      "Epoch 17974, Loss: 420.661376953125, Neurons: 11, Grad norm: 2.316e+01\n",
      "Epoch 17975, Loss: 420.6551818847656, Neurons: 11, Grad norm: 1.974e+01\n",
      "Epoch 17976, Loss: 420.64898681640625, Neurons: 11, Grad norm: 1.736e+01\n",
      "Epoch 17977, Loss: 420.6427917480469, Neurons: 11, Grad norm: 1.225e+01\n",
      "Epoch 17978, Loss: 420.63653564453125, Neurons: 11, Grad norm: 8.633e+00\n",
      "Epoch 17979, Loss: 420.6302795410156, Neurons: 11, Grad norm: 4.672e+00\n",
      "Epoch 17980, Loss: 420.62408447265625, Neurons: 11, Grad norm: 2.760e+00\n",
      "Epoch 17981, Loss: 420.6177978515625, Neurons: 11, Grad norm: 6.040e+00\n",
      "Epoch 17982, Loss: 420.6116027832031, Neurons: 11, Grad norm: 9.105e+00\n",
      "Epoch 17983, Loss: 420.6053466796875, Neurons: 11, Grad norm: 1.470e+01\n",
      "Epoch 17984, Loss: 420.5990905761719, Neurons: 11, Grad norm: 1.619e+01\n",
      "Epoch 17985, Loss: 420.5928955078125, Neurons: 11, Grad norm: 1.879e+01\n",
      "Epoch 17986, Loss: 420.5865783691406, Neurons: 11, Grad norm: 2.201e+01\n",
      "Epoch 17987, Loss: 420.58038330078125, Neurons: 11, Grad norm: 2.252e+01\n",
      "Epoch 17988, Loss: 420.5740966796875, Neurons: 11, Grad norm: 2.452e+01\n",
      "Epoch 17989, Loss: 420.5678405761719, Neurons: 11, Grad norm: 2.721e+01\n",
      "Epoch 17990, Loss: 420.5615539550781, Neurons: 11, Grad norm: 2.577e+01\n",
      "Epoch 17991, Loss: 420.5552978515625, Neurons: 11, Grad norm: 2.646e+01\n",
      "Epoch 17992, Loss: 420.5489807128906, Neurons: 11, Grad norm: 2.524e+01\n",
      "Epoch 17993, Loss: 420.5426940917969, Neurons: 11, Grad norm: 2.281e+01\n",
      "Epoch 17994, Loss: 420.536376953125, Neurons: 11, Grad norm: 2.294e+01\n",
      "Epoch 17995, Loss: 420.53009033203125, Neurons: 11, Grad norm: 2.255e+01\n",
      "Epoch 17996, Loss: 420.5238037109375, Neurons: 11, Grad norm: 2.166e+01\n",
      "Epoch 17997, Loss: 420.51739501953125, Neurons: 11, Grad norm: 2.379e+01\n",
      "Epoch 17998, Loss: 420.5111389160156, Neurons: 11, Grad norm: 2.357e+01\n",
      "Epoch 17999, Loss: 420.5048522949219, Neurons: 11, Grad norm: 2.535e+01\n",
      "Epoch 17999, Test loss: 417.3912048339844\n",
      "Epoch 18000, Loss: 420.49847412109375, Neurons: 11, Grad norm: 2.740e+01\n",
      "Epoch 18001, Loss: 420.4921875, Neurons: 11, Grad norm: 2.705e+01\n",
      "Epoch 18002, Loss: 420.48577880859375, Neurons: 11, Grad norm: 2.881e+01\n",
      "Epoch 18003, Loss: 420.4794921875, Neurons: 11, Grad norm: 3.111e+01\n",
      "Epoch 18004, Loss: 420.47314453125, Neurons: 11, Grad norm: 2.992e+01\n",
      "Epoch 18005, Loss: 420.466796875, Neurons: 11, Grad norm: 3.287e+01\n",
      "Epoch 18006, Loss: 420.4604797363281, Neurons: 11, Grad norm: 3.422e+01\n",
      "Epoch 18007, Loss: 420.4541015625, Neurons: 11, Grad norm: 3.383e+01\n",
      "Epoch 18008, Loss: 420.44775390625, Neurons: 11, Grad norm: 3.633e+01\n",
      "Epoch 18009, Loss: 420.4413757324219, Neurons: 11, Grad norm: 3.803e+01\n",
      "Epoch 18010, Loss: 420.4350280761719, Neurons: 11, Grad norm: 3.873e+01\n",
      "Epoch 18011, Loss: 420.4286804199219, Neurons: 11, Grad norm: 4.250e+01\n",
      "Epoch 18012, Loss: 420.4223327636719, Neurons: 11, Grad norm: 4.353e+01\n",
      "Epoch 18013, Loss: 420.41595458984375, Neurons: 11, Grad norm: 4.623e+01\n",
      "Epoch 18014, Loss: 420.4095764160156, Neurons: 11, Grad norm: 4.936e+01\n",
      "Epoch 18015, Loss: 420.4031982421875, Neurons: 11, Grad norm: 4.960e+01\n",
      "Epoch 18016, Loss: 420.39678955078125, Neurons: 11, Grad norm: 5.186e+01\n",
      "Epoch 18017, Loss: 420.3905029296875, Neurons: 11, Grad norm: 5.618e+01\n",
      "Epoch 18018, Loss: 420.3841247558594, Neurons: 11, Grad norm: 5.686e+01\n",
      "Epoch 18019, Loss: 420.3777770996094, Neurons: 11, Grad norm: 6.037e+01\n",
      "Epoch 18020, Loss: 420.37139892578125, Neurons: 11, Grad norm: 6.396e+01\n",
      "Epoch 18021, Loss: 420.3650817871094, Neurons: 11, Grad norm: 6.554e+01\n",
      "Epoch 18022, Loss: 420.35870361328125, Neurons: 11, Grad norm: 6.807e+01\n",
      "Epoch 18023, Loss: 420.352294921875, Neurons: 11, Grad norm: 6.975e+01\n",
      "Epoch 18024, Loss: 420.3459777832031, Neurons: 11, Grad norm: 6.928e+01\n",
      "Epoch 18025, Loss: 420.339599609375, Neurons: 11, Grad norm: 7.009e+01\n",
      "Epoch 18026, Loss: 420.333251953125, Neurons: 11, Grad norm: 6.813e+01\n",
      "Epoch 18027, Loss: 420.3267822265625, Neurons: 11, Grad norm: 6.617e+01\n",
      "Epoch 18028, Loss: 420.3204040527344, Neurons: 11, Grad norm: 6.366e+01\n",
      "Epoch 18029, Loss: 420.3139953613281, Neurons: 11, Grad norm: 5.990e+01\n",
      "Epoch 18030, Loss: 420.3075866699219, Neurons: 11, Grad norm: 5.730e+01\n",
      "Epoch 18031, Loss: 420.3011779785156, Neurons: 11, Grad norm: 5.548e+01\n",
      "Epoch 18032, Loss: 420.2947998046875, Neurons: 11, Grad norm: 5.216e+01\n",
      "Epoch 18033, Loss: 420.28839111328125, Neurons: 11, Grad norm: 5.131e+01\n",
      "Epoch 18034, Loss: 420.28204345703125, Neurons: 11, Grad norm: 4.937e+01\n",
      "Epoch 18035, Loss: 420.2756042480469, Neurons: 11, Grad norm: 4.640e+01\n",
      "Epoch 18036, Loss: 420.2691955566406, Neurons: 11, Grad norm: 4.384e+01\n",
      "Epoch 18037, Loss: 420.2627868652344, Neurons: 11, Grad norm: 4.056e+01\n",
      "Epoch 18038, Loss: 420.2563781738281, Neurons: 11, Grad norm: 3.482e+01\n",
      "Epoch 18039, Loss: 420.25, Neurons: 11, Grad norm: 3.015e+01\n",
      "Epoch 18040, Loss: 420.2435302734375, Neurons: 11, Grad norm: 2.523e+01\n",
      "Epoch 18041, Loss: 420.2371520996094, Neurons: 11, Grad norm: 2.155e+01\n",
      "Epoch 18042, Loss: 420.2306823730469, Neurons: 11, Grad norm: 1.797e+01\n",
      "Epoch 18043, Loss: 420.22430419921875, Neurons: 11, Grad norm: 1.390e+01\n",
      "Epoch 18044, Loss: 420.2178955078125, Neurons: 11, Grad norm: 9.630e+00\n",
      "Epoch 18045, Loss: 420.2113952636719, Neurons: 11, Grad norm: 6.328e+00\n",
      "Epoch 18046, Loss: 420.2049865722656, Neurons: 11, Grad norm: 2.594e+00\n",
      "Epoch 18047, Loss: 420.1985778808594, Neurons: 11, Grad norm: 2.348e+00\n",
      "Epoch 18048, Loss: 420.19207763671875, Neurons: 11, Grad norm: 4.968e+00\n",
      "Epoch 18049, Loss: 420.1856994628906, Neurons: 11, Grad norm: 7.143e+00\n",
      "Epoch 18049, Test loss: 417.0835266113281\n",
      "Epoch 18050, Loss: 420.1792907714844, Neurons: 11, Grad norm: 9.326e+00\n",
      "Epoch 18051, Loss: 420.17279052734375, Neurons: 11, Grad norm: 1.069e+01\n",
      "Epoch 18052, Loss: 420.1663818359375, Neurons: 11, Grad norm: 1.245e+01\n",
      "Epoch 18053, Loss: 420.1598815917969, Neurons: 11, Grad norm: 1.449e+01\n",
      "Epoch 18054, Loss: 420.15350341796875, Neurons: 11, Grad norm: 1.775e+01\n",
      "Epoch 18055, Loss: 420.1470031738281, Neurons: 11, Grad norm: 2.027e+01\n",
      "Epoch 18056, Loss: 420.1405029296875, Neurons: 11, Grad norm: 2.245e+01\n",
      "Epoch 18057, Loss: 420.134033203125, Neurons: 11, Grad norm: 2.377e+01\n",
      "Epoch 18058, Loss: 420.1275939941406, Neurons: 11, Grad norm: 2.697e+01\n",
      "Epoch 18059, Loss: 420.12109375, Neurons: 11, Grad norm: 2.956e+01\n",
      "Epoch 18060, Loss: 420.1145935058594, Neurons: 11, Grad norm: 3.314e+01\n",
      "Epoch 18061, Loss: 420.10809326171875, Neurons: 11, Grad norm: 3.666e+01\n",
      "Epoch 18062, Loss: 420.1015930175781, Neurons: 11, Grad norm: 3.927e+01\n",
      "Epoch 18063, Loss: 420.0950927734375, Neurons: 11, Grad norm: 4.223e+01\n",
      "Epoch 18064, Loss: 420.0886535644531, Neurons: 11, Grad norm: 4.636e+01\n",
      "Epoch 18065, Loss: 420.0821533203125, Neurons: 11, Grad norm: 4.903e+01\n",
      "Epoch 18066, Loss: 420.0756530761719, Neurons: 11, Grad norm: 5.312e+01\n",
      "Epoch 18067, Loss: 420.06915283203125, Neurons: 11, Grad norm: 5.684e+01\n",
      "Epoch 18068, Loss: 420.06268310546875, Neurons: 11, Grad norm: 6.191e+01\n",
      "Epoch 18069, Loss: 420.0562438964844, Neurons: 11, Grad norm: 6.777e+01\n",
      "Epoch 18070, Loss: 420.0497741699219, Neurons: 11, Grad norm: 7.239e+01\n",
      "Epoch 18071, Loss: 420.0433044433594, Neurons: 11, Grad norm: 7.592e+01\n",
      "Epoch 18072, Loss: 420.0368347167969, Neurons: 11, Grad norm: 8.025e+01\n",
      "Epoch 18073, Loss: 420.0303955078125, Neurons: 11, Grad norm: 8.308e+01\n",
      "Epoch 18074, Loss: 420.0238952636719, Neurons: 11, Grad norm: 8.684e+01\n",
      "Epoch 18075, Loss: 420.0174865722656, Neurons: 11, Grad norm: 8.912e+01\n",
      "Epoch 18076, Loss: 420.010986328125, Neurons: 11, Grad norm: 9.015e+01\n",
      "Epoch 18077, Loss: 420.0045471191406, Neurons: 11, Grad norm: 9.016e+01\n",
      "Epoch 18078, Loss: 419.9980773925781, Neurons: 11, Grad norm: 8.840e+01\n",
      "Epoch 18079, Loss: 419.9915771484375, Neurons: 11, Grad norm: 8.431e+01\n",
      "Epoch 18080, Loss: 419.9849853515625, Neurons: 11, Grad norm: 7.972e+01\n",
      "Epoch 18081, Loss: 419.9784851074219, Neurons: 11, Grad norm: 7.206e+01\n",
      "Epoch 18082, Loss: 419.9719543457031, Neurons: 11, Grad norm: 6.444e+01\n",
      "Epoch 18083, Loss: 419.96539306640625, Neurons: 11, Grad norm: 5.539e+01\n",
      "Epoch 18084, Loss: 419.95880126953125, Neurons: 11, Grad norm: 4.453e+01\n",
      "Epoch 18085, Loss: 419.9522399902344, Neurons: 11, Grad norm: 3.335e+01\n",
      "Epoch 18086, Loss: 419.94573974609375, Neurons: 11, Grad norm: 2.128e+01\n",
      "Epoch 18087, Loss: 419.9391784667969, Neurons: 11, Grad norm: 8.472e+00\n",
      "Epoch 18088, Loss: 419.93267822265625, Neurons: 11, Grad norm: 2.199e+00\n",
      "Epoch 18089, Loss: 419.9262390136719, Neurons: 11, Grad norm: 9.751e+00\n",
      "Epoch 18090, Loss: 419.9197998046875, Neurons: 11, Grad norm: 1.726e+01\n",
      "Epoch 18091, Loss: 419.9132995605469, Neurons: 11, Grad norm: 2.264e+01\n",
      "Epoch 18092, Loss: 419.90679931640625, Neurons: 11, Grad norm: 2.664e+01\n",
      "Epoch 18093, Loss: 419.90032958984375, Neurons: 11, Grad norm: 3.113e+01\n",
      "Epoch 18094, Loss: 419.8938903808594, Neurons: 11, Grad norm: 3.319e+01\n",
      "Epoch 18095, Loss: 419.88739013671875, Neurons: 11, Grad norm: 3.415e+01\n",
      "Epoch 18096, Loss: 419.8808898925781, Neurons: 11, Grad norm: 3.446e+01\n",
      "Epoch 18097, Loss: 419.8743896484375, Neurons: 11, Grad norm: 3.441e+01\n",
      "Epoch 18098, Loss: 419.8678894042969, Neurons: 11, Grad norm: 3.312e+01\n",
      "Epoch 18099, Loss: 419.86138916015625, Neurons: 11, Grad norm: 3.229e+01\n",
      "Epoch 18099, Test loss: 416.7536926269531\n",
      "Epoch 18100, Loss: 419.85479736328125, Neurons: 11, Grad norm: 3.028e+01\n",
      "Epoch 18101, Loss: 419.8482971191406, Neurons: 11, Grad norm: 2.874e+01\n",
      "Epoch 18102, Loss: 419.84173583984375, Neurons: 11, Grad norm: 2.667e+01\n",
      "Epoch 18103, Loss: 419.8351745605469, Neurons: 11, Grad norm: 2.523e+01\n",
      "Epoch 18104, Loss: 419.8286437988281, Neurons: 11, Grad norm: 2.330e+01\n",
      "Epoch 18105, Loss: 419.8220520019531, Neurons: 11, Grad norm: 2.233e+01\n",
      "Epoch 18106, Loss: 419.81549072265625, Neurons: 11, Grad norm: 2.058e+01\n",
      "Epoch 18107, Loss: 419.8089294433594, Neurons: 11, Grad norm: 1.829e+01\n",
      "Epoch 18108, Loss: 419.8023986816406, Neurons: 11, Grad norm: 1.512e+01\n",
      "Epoch 18109, Loss: 419.7957763671875, Neurons: 11, Grad norm: 1.247e+01\n",
      "Epoch 18110, Loss: 419.7891845703125, Neurons: 11, Grad norm: 1.047e+01\n",
      "Epoch 18111, Loss: 419.7825927734375, Neurons: 11, Grad norm: 9.837e+00\n",
      "Epoch 18112, Loss: 419.7760009765625, Neurons: 11, Grad norm: 7.434e+00\n",
      "Epoch 18113, Loss: 419.7693786621094, Neurons: 11, Grad norm: 6.059e+00\n",
      "Epoch 18114, Loss: 419.7627868652344, Neurons: 11, Grad norm: 4.296e+00\n",
      "Epoch 18115, Loss: 419.7561950683594, Neurons: 11, Grad norm: 2.939e+00\n",
      "Epoch 18116, Loss: 419.7496032714844, Neurons: 11, Grad norm: 2.731e+00\n",
      "Epoch 18117, Loss: 419.74298095703125, Neurons: 11, Grad norm: 2.454e+00\n",
      "Epoch 18118, Loss: 419.7362976074219, Neurons: 11, Grad norm: 2.176e+00\n",
      "Epoch 18119, Loss: 419.72967529296875, Neurons: 11, Grad norm: 2.103e+00\n",
      "Epoch 18120, Loss: 419.7230529785156, Neurons: 11, Grad norm: 2.447e+00\n",
      "Epoch 18121, Loss: 419.7164001464844, Neurons: 11, Grad norm: 2.783e+00\n",
      "Epoch 18122, Loss: 419.7096862792969, Neurons: 11, Grad norm: 4.231e+00\n",
      "Epoch 18123, Loss: 419.7030944824219, Neurons: 11, Grad norm: 6.803e+00\n",
      "Epoch 18124, Loss: 419.6964416503906, Neurons: 11, Grad norm: 8.399e+00\n",
      "Epoch 18125, Loss: 419.6897277832031, Neurons: 11, Grad norm: 9.380e+00\n",
      "Epoch 18126, Loss: 419.68304443359375, Neurons: 11, Grad norm: 1.184e+01\n",
      "Epoch 18127, Loss: 419.6763916015625, Neurons: 11, Grad norm: 1.178e+01\n",
      "Epoch 18128, Loss: 419.669677734375, Neurons: 11, Grad norm: 1.142e+01\n",
      "Epoch 18129, Loss: 419.6629943847656, Neurons: 11, Grad norm: 1.162e+01\n",
      "Epoch 18130, Loss: 419.65625, Neurons: 11, Grad norm: 1.297e+01\n",
      "Epoch 18131, Loss: 419.6495361328125, Neurons: 11, Grad norm: 1.482e+01\n",
      "Epoch 18132, Loss: 419.6427917480469, Neurons: 11, Grad norm: 1.793e+01\n",
      "Epoch 18133, Loss: 419.6360778808594, Neurons: 11, Grad norm: 1.903e+01\n",
      "Epoch 18134, Loss: 419.62933349609375, Neurons: 11, Grad norm: 2.108e+01\n",
      "Epoch 18135, Loss: 419.6226501464844, Neurons: 11, Grad norm: 2.382e+01\n",
      "Epoch 18136, Loss: 419.6158752441406, Neurons: 11, Grad norm: 2.562e+01\n",
      "Epoch 18137, Loss: 419.60919189453125, Neurons: 11, Grad norm: 2.687e+01\n",
      "Epoch 18138, Loss: 419.6023864746094, Neurons: 11, Grad norm: 2.911e+01\n",
      "Epoch 18139, Loss: 419.59564208984375, Neurons: 11, Grad norm: 2.966e+01\n",
      "Epoch 18140, Loss: 419.5888977050781, Neurons: 11, Grad norm: 3.118e+01\n",
      "Epoch 18141, Loss: 419.5821533203125, Neurons: 11, Grad norm: 3.400e+01\n",
      "Epoch 18142, Loss: 419.5753479003906, Neurons: 11, Grad norm: 3.721e+01\n",
      "Epoch 18143, Loss: 419.56854248046875, Neurons: 11, Grad norm: 3.914e+01\n",
      "Epoch 18144, Loss: 419.5617980957031, Neurons: 11, Grad norm: 4.192e+01\n",
      "Epoch 18145, Loss: 419.5550537109375, Neurons: 11, Grad norm: 4.529e+01\n",
      "Epoch 18146, Loss: 419.54827880859375, Neurons: 11, Grad norm: 4.988e+01\n",
      "Epoch 18147, Loss: 419.5415344238281, Neurons: 11, Grad norm: 5.437e+01\n",
      "Epoch 18148, Loss: 419.5347900390625, Neurons: 11, Grad norm: 6.014e+01\n",
      "Epoch 18149, Loss: 419.5280456542969, Neurons: 11, Grad norm: 6.574e+01\n",
      "Epoch 18149, Test loss: 416.4454650878906\n",
      "Epoch 18150, Loss: 419.52130126953125, Neurons: 11, Grad norm: 7.202e+01\n",
      "Epoch 18151, Loss: 419.51458740234375, Neurons: 11, Grad norm: 7.971e+01\n",
      "Epoch 18152, Loss: 419.5079345703125, Neurons: 11, Grad norm: 8.834e+01\n",
      "Epoch 18153, Loss: 419.5012512207031, Neurons: 11, Grad norm: 9.626e+01\n",
      "Epoch 18154, Loss: 419.4945983886719, Neurons: 11, Grad norm: 1.049e+02\n",
      "Epoch 18155, Loss: 419.48797607421875, Neurons: 11, Grad norm: 1.116e+02\n",
      "Epoch 18156, Loss: 419.48138427734375, Neurons: 11, Grad norm: 1.168e+02\n",
      "Epoch 18157, Loss: 419.47479248046875, Neurons: 11, Grad norm: 1.193e+02\n",
      "Epoch 18158, Loss: 419.46807861328125, Neurons: 11, Grad norm: 1.182e+02\n",
      "Epoch 18159, Loss: 419.4613952636719, Neurons: 11, Grad norm: 1.144e+02\n",
      "Epoch 18160, Loss: 419.45465087890625, Neurons: 11, Grad norm: 1.074e+02\n",
      "Epoch 18161, Loss: 419.4477844238281, Neurons: 11, Grad norm: 9.403e+01\n",
      "Epoch 18162, Loss: 419.4408874511719, Neurons: 11, Grad norm: 7.840e+01\n",
      "Epoch 18163, Loss: 419.4339294433594, Neurons: 11, Grad norm: 6.136e+01\n",
      "Epoch 18164, Loss: 419.4270935058594, Neurons: 11, Grad norm: 4.202e+01\n",
      "Epoch 18165, Loss: 419.42022705078125, Neurons: 11, Grad norm: 2.182e+01\n",
      "Epoch 18166, Loss: 419.4134521484375, Neurons: 11, Grad norm: 3.008e+00\n",
      "Epoch 18167, Loss: 419.4067687988281, Neurons: 11, Grad norm: 1.673e+01\n",
      "Epoch 18168, Loss: 419.4001159667969, Neurons: 11, Grad norm: 3.098e+01\n",
      "Epoch 18169, Loss: 419.3935241699219, Neurons: 11, Grad norm: 4.416e+01\n",
      "Epoch 18170, Loss: 419.386962890625, Neurons: 11, Grad norm: 5.310e+01\n",
      "Epoch 18171, Loss: 419.3804016113281, Neurons: 11, Grad norm: 5.794e+01\n",
      "Epoch 18172, Loss: 419.3737487792969, Neurons: 11, Grad norm: 6.090e+01\n",
      "Epoch 18173, Loss: 419.3670959472656, Neurons: 11, Grad norm: 5.902e+01\n",
      "Epoch 18174, Loss: 419.36041259765625, Neurons: 11, Grad norm: 5.268e+01\n",
      "Epoch 18175, Loss: 419.35369873046875, Neurons: 11, Grad norm: 4.585e+01\n",
      "Epoch 18176, Loss: 419.3469543457031, Neurons: 11, Grad norm: 3.515e+01\n",
      "Epoch 18177, Loss: 419.3401794433594, Neurons: 11, Grad norm: 2.441e+01\n",
      "Epoch 18178, Loss: 419.3334045410156, Neurons: 11, Grad norm: 1.269e+01\n",
      "Epoch 18179, Loss: 419.3266906738281, Neurons: 11, Grad norm: 2.232e+00\n",
      "Epoch 18180, Loss: 419.3199768066406, Neurons: 11, Grad norm: 8.996e+00\n",
      "Epoch 18181, Loss: 419.3132629394531, Neurons: 11, Grad norm: 1.668e+01\n",
      "Epoch 18182, Loss: 419.30657958984375, Neurons: 11, Grad norm: 2.571e+01\n",
      "Epoch 18183, Loss: 419.2998962402344, Neurons: 11, Grad norm: 3.005e+01\n",
      "Epoch 18184, Loss: 419.2931823730469, Neurons: 11, Grad norm: 3.478e+01\n",
      "Epoch 18185, Loss: 419.2865295410156, Neurons: 11, Grad norm: 3.716e+01\n",
      "Epoch 18186, Loss: 419.2797546386719, Neurons: 11, Grad norm: 3.479e+01\n",
      "Epoch 18187, Loss: 419.2730407714844, Neurons: 11, Grad norm: 3.330e+01\n",
      "Epoch 18188, Loss: 419.2662353515625, Neurons: 11, Grad norm: 3.034e+01\n",
      "Epoch 18189, Loss: 419.2594909667969, Neurons: 11, Grad norm: 2.301e+01\n",
      "Epoch 18190, Loss: 419.252685546875, Neurons: 11, Grad norm: 1.940e+01\n",
      "Epoch 18191, Loss: 419.2458801269531, Neurons: 11, Grad norm: 1.383e+01\n",
      "Epoch 18192, Loss: 419.23907470703125, Neurons: 11, Grad norm: 7.249e+00\n",
      "Epoch 18193, Loss: 419.2323303222656, Neurons: 11, Grad norm: 4.271e+00\n",
      "Epoch 18194, Loss: 419.22552490234375, Neurons: 11, Grad norm: 2.617e+00\n",
      "Epoch 18195, Loss: 419.21875, Neurons: 11, Grad norm: 8.727e+00\n",
      "Epoch 18196, Loss: 419.2119445800781, Neurons: 11, Grad norm: 1.091e+01\n",
      "Epoch 18197, Loss: 419.2051086425781, Neurons: 11, Grad norm: 1.504e+01\n",
      "Epoch 18198, Loss: 419.1983337402344, Neurons: 11, Grad norm: 1.872e+01\n",
      "Epoch 18199, Loss: 419.1915283203125, Neurons: 11, Grad norm: 1.899e+01\n",
      "Epoch 18199, Test loss: 416.0924072265625\n",
      "Epoch 18200, Loss: 419.18475341796875, Neurons: 11, Grad norm: 1.974e+01\n",
      "Epoch 18201, Loss: 419.1778869628906, Neurons: 11, Grad norm: 1.935e+01\n",
      "Epoch 18202, Loss: 419.1710510253906, Neurons: 11, Grad norm: 1.636e+01\n",
      "Epoch 18203, Loss: 419.1641845703125, Neurons: 11, Grad norm: 1.677e+01\n",
      "Epoch 18204, Loss: 419.15728759765625, Neurons: 11, Grad norm: 1.535e+01\n",
      "Epoch 18205, Loss: 419.15045166015625, Neurons: 11, Grad norm: 1.265e+01\n",
      "Epoch 18206, Loss: 419.1435546875, Neurons: 11, Grad norm: 1.087e+01\n",
      "Epoch 18207, Loss: 419.1366882324219, Neurons: 11, Grad norm: 8.031e+00\n",
      "Epoch 18208, Loss: 419.12982177734375, Neurons: 11, Grad norm: 6.254e+00\n",
      "Epoch 18209, Loss: 419.1228942871094, Neurons: 11, Grad norm: 6.579e+00\n",
      "Epoch 18210, Loss: 419.11602783203125, Neurons: 11, Grad norm: 4.135e+00\n",
      "Epoch 18211, Loss: 419.1091003417969, Neurons: 11, Grad norm: 3.651e+00\n",
      "Epoch 18212, Loss: 419.1021423339844, Neurons: 11, Grad norm: 4.146e+00\n",
      "Epoch 18213, Loss: 419.09527587890625, Neurons: 11, Grad norm: 2.967e+00\n",
      "Epoch 18214, Loss: 419.0883483886719, Neurons: 11, Grad norm: 2.525e+00\n",
      "Epoch 18215, Loss: 419.0813903808594, Neurons: 11, Grad norm: 3.903e+00\n",
      "Epoch 18216, Loss: 419.074462890625, Neurons: 11, Grad norm: 3.032e+00\n",
      "Epoch 18217, Loss: 419.0674743652344, Neurons: 11, Grad norm: 2.482e+00\n",
      "Epoch 18218, Loss: 419.0605773925781, Neurons: 11, Grad norm: 2.332e+00\n",
      "Epoch 18219, Loss: 419.0535583496094, Neurons: 11, Grad norm: 2.256e+00\n",
      "Epoch 18220, Loss: 419.0466003417969, Neurons: 11, Grad norm: 2.482e+00\n",
      "Epoch 18221, Loss: 419.03961181640625, Neurons: 11, Grad norm: 2.536e+00\n",
      "Epoch 18222, Loss: 419.0326232910156, Neurons: 11, Grad norm: 3.223e+00\n",
      "Epoch 18223, Loss: 419.025634765625, Neurons: 11, Grad norm: 3.052e+00\n",
      "Epoch 18224, Loss: 419.0186462402344, Neurons: 11, Grad norm: 3.437e+00\n",
      "Epoch 18225, Loss: 419.0115966796875, Neurons: 11, Grad norm: 3.682e+00\n",
      "Epoch 18226, Loss: 419.00457763671875, Neurons: 11, Grad norm: 2.627e+00\n",
      "Epoch 18227, Loss: 418.9975280761719, Neurons: 11, Grad norm: 2.175e+00\n",
      "Epoch 18228, Loss: 418.990478515625, Neurons: 11, Grad norm: 2.946e+00\n",
      "Epoch 18229, Loss: 418.9834289550781, Neurons: 11, Grad norm: 2.378e+00\n",
      "Epoch 18230, Loss: 418.97637939453125, Neurons: 11, Grad norm: 2.822e+00\n",
      "Epoch 18231, Loss: 418.9693298339844, Neurons: 11, Grad norm: 4.369e+00\n",
      "Epoch 18232, Loss: 418.9622497558594, Neurons: 11, Grad norm: 4.390e+00\n",
      "Epoch 18233, Loss: 418.9551696777344, Neurons: 11, Grad norm: 4.811e+00\n",
      "Epoch 18234, Loss: 418.9480895996094, Neurons: 11, Grad norm: 6.052e+00\n",
      "Epoch 18235, Loss: 418.94097900390625, Neurons: 11, Grad norm: 5.462e+00\n",
      "Epoch 18236, Loss: 418.93389892578125, Neurons: 11, Grad norm: 6.338e+00\n",
      "Epoch 18237, Loss: 418.9267883300781, Neurons: 11, Grad norm: 6.597e+00\n",
      "Epoch 18238, Loss: 418.9196472167969, Neurons: 11, Grad norm: 6.247e+00\n",
      "Epoch 18239, Loss: 418.9124755859375, Neurons: 11, Grad norm: 6.650e+00\n",
      "Epoch 18240, Loss: 418.9053955078125, Neurons: 11, Grad norm: 6.678e+00\n",
      "Epoch 18241, Loss: 418.8982238769531, Neurons: 11, Grad norm: 5.889e+00\n",
      "Epoch 18242, Loss: 418.89105224609375, Neurons: 11, Grad norm: 6.603e+00\n",
      "Epoch 18243, Loss: 418.8838806152344, Neurons: 11, Grad norm: 7.369e+00\n",
      "Epoch 18244, Loss: 418.8766784667969, Neurons: 11, Grad norm: 7.902e+00\n",
      "Epoch 18245, Loss: 418.8695373535156, Neurons: 11, Grad norm: 8.359e+00\n",
      "Epoch 18246, Loss: 418.8623352050781, Neurons: 11, Grad norm: 1.055e+01\n",
      "Epoch 18247, Loss: 418.85516357421875, Neurons: 11, Grad norm: 1.293e+01\n",
      "Epoch 18248, Loss: 418.84796142578125, Neurons: 11, Grad norm: 1.623e+01\n",
      "Epoch 18249, Loss: 418.8407287597656, Neurons: 11, Grad norm: 2.008e+01\n",
      "Epoch 18249, Test loss: 415.75115966796875\n",
      "Epoch 18250, Loss: 418.8335266113281, Neurons: 11, Grad norm: 2.495e+01\n",
      "Epoch 18251, Loss: 418.8263244628906, Neurons: 11, Grad norm: 2.961e+01\n",
      "Epoch 18252, Loss: 418.81915283203125, Neurons: 11, Grad norm: 3.404e+01\n",
      "Epoch 18253, Loss: 418.8118896484375, Neurons: 11, Grad norm: 3.918e+01\n",
      "Epoch 18254, Loss: 418.8046875, Neurons: 11, Grad norm: 4.531e+01\n",
      "Epoch 18255, Loss: 418.7974548339844, Neurons: 11, Grad norm: 5.134e+01\n",
      "Epoch 18256, Loss: 418.790283203125, Neurons: 11, Grad norm: 6.009e+01\n",
      "Epoch 18257, Loss: 418.7830810546875, Neurons: 11, Grad norm: 6.972e+01\n",
      "Epoch 18258, Loss: 418.77593994140625, Neurons: 11, Grad norm: 8.007e+01\n",
      "Epoch 18259, Loss: 418.7688293457031, Neurons: 11, Grad norm: 9.146e+01\n",
      "Epoch 18260, Loss: 418.76177978515625, Neurons: 11, Grad norm: 1.014e+02\n",
      "Epoch 18261, Loss: 418.7547302246094, Neurons: 11, Grad norm: 1.109e+02\n",
      "Epoch 18262, Loss: 418.7477111816406, Neurons: 11, Grad norm: 1.220e+02\n",
      "Epoch 18263, Loss: 418.7407531738281, Neurons: 11, Grad norm: 1.295e+02\n",
      "Epoch 18264, Loss: 418.7337341308594, Neurons: 11, Grad norm: 1.346e+02\n",
      "Epoch 18265, Loss: 418.72674560546875, Neurons: 11, Grad norm: 1.359e+02\n",
      "Epoch 18266, Loss: 418.7195739746094, Neurons: 11, Grad norm: 1.283e+02\n",
      "Epoch 18267, Loss: 418.71234130859375, Neurons: 11, Grad norm: 1.149e+02\n",
      "Epoch 18268, Loss: 418.704833984375, Neurons: 11, Grad norm: 9.571e+01\n",
      "Epoch 18269, Loss: 418.6973571777344, Neurons: 11, Grad norm: 7.023e+01\n",
      "Epoch 18270, Loss: 418.68988037109375, Neurons: 11, Grad norm: 4.430e+01\n",
      "Epoch 18271, Loss: 418.6824951171875, Neurons: 11, Grad norm: 1.632e+01\n",
      "Epoch 18272, Loss: 418.6752014160156, Neurons: 11, Grad norm: 1.166e+01\n",
      "Epoch 18273, Loss: 418.6681823730469, Neurons: 11, Grad norm: 3.395e+01\n",
      "Epoch 18274, Loss: 418.66119384765625, Neurons: 11, Grad norm: 5.341e+01\n",
      "Epoch 18275, Loss: 418.65423583984375, Neurons: 11, Grad norm: 6.719e+01\n",
      "Epoch 18276, Loss: 418.6473083496094, Neurons: 11, Grad norm: 7.261e+01\n",
      "Epoch 18277, Loss: 418.64031982421875, Neurons: 11, Grad norm: 7.332e+01\n",
      "Epoch 18278, Loss: 418.6332092285156, Neurons: 11, Grad norm: 6.673e+01\n",
      "Epoch 18279, Loss: 418.62603759765625, Neurons: 11, Grad norm: 5.461e+01\n",
      "Epoch 18280, Loss: 418.6187744140625, Neurons: 11, Grad norm: 4.015e+01\n",
      "Epoch 18281, Loss: 418.6115417480469, Neurons: 11, Grad norm: 2.312e+01\n",
      "Epoch 18282, Loss: 418.6043395996094, Neurons: 11, Grad norm: 6.603e+00\n",
      "Epoch 18283, Loss: 418.5971984863281, Neurons: 11, Grad norm: 9.489e+00\n",
      "Epoch 18284, Loss: 418.59002685546875, Neurons: 11, Grad norm: 2.348e+01\n",
      "Epoch 18285, Loss: 418.58294677734375, Neurons: 11, Grad norm: 3.249e+01\n",
      "Epoch 18286, Loss: 418.5758972167969, Neurons: 11, Grad norm: 3.807e+01\n",
      "Epoch 18287, Loss: 418.5687561035156, Neurons: 11, Grad norm: 3.960e+01\n",
      "Epoch 18288, Loss: 418.5616149902344, Neurons: 11, Grad norm: 3.612e+01\n",
      "Epoch 18289, Loss: 418.554443359375, Neurons: 11, Grad norm: 2.999e+01\n",
      "Epoch 18290, Loss: 418.5472412109375, Neurons: 11, Grad norm: 2.161e+01\n",
      "Epoch 18291, Loss: 418.5400085449219, Neurons: 11, Grad norm: 1.115e+01\n",
      "Epoch 18292, Loss: 418.53277587890625, Neurons: 11, Grad norm: 2.899e+00\n",
      "Epoch 18293, Loss: 418.5255432128906, Neurons: 11, Grad norm: 6.814e+00\n",
      "Epoch 18294, Loss: 418.5184020996094, Neurons: 11, Grad norm: 1.365e+01\n",
      "Epoch 18295, Loss: 418.5111999511719, Neurons: 11, Grad norm: 2.015e+01\n",
      "Epoch 18296, Loss: 418.50396728515625, Neurons: 11, Grad norm: 2.470e+01\n",
      "Epoch 18297, Loss: 418.4967956542969, Neurons: 11, Grad norm: 2.778e+01\n",
      "Epoch 18298, Loss: 418.4895324707031, Neurons: 11, Grad norm: 2.912e+01\n",
      "Epoch 18299, Loss: 418.4823303222656, Neurons: 11, Grad norm: 2.869e+01\n",
      "Epoch 18299, Test loss: 415.38055419921875\n",
      "Epoch 18300, Loss: 418.4750671386719, Neurons: 11, Grad norm: 2.646e+01\n",
      "Epoch 18301, Loss: 418.4678039550781, Neurons: 11, Grad norm: 2.362e+01\n",
      "Epoch 18302, Loss: 418.4604797363281, Neurons: 11, Grad norm: 1.938e+01\n",
      "Epoch 18303, Loss: 418.45318603515625, Neurons: 11, Grad norm: 1.380e+01\n",
      "Epoch 18304, Loss: 418.44586181640625, Neurons: 11, Grad norm: 9.202e+00\n",
      "Epoch 18305, Loss: 418.4385681152344, Neurons: 11, Grad norm: 5.429e+00\n",
      "Epoch 18306, Loss: 418.4312438964844, Neurons: 11, Grad norm: 2.313e+00\n",
      "Epoch 18307, Loss: 418.42388916015625, Neurons: 11, Grad norm: 4.692e+00\n",
      "Epoch 18308, Loss: 418.4165954589844, Neurons: 11, Grad norm: 7.540e+00\n",
      "Epoch 18309, Loss: 418.40924072265625, Neurons: 11, Grad norm: 1.026e+01\n",
      "Epoch 18310, Loss: 418.4018859863281, Neurons: 11, Grad norm: 1.156e+01\n",
      "Epoch 18311, Loss: 418.39453125, Neurons: 11, Grad norm: 1.334e+01\n",
      "Epoch 18312, Loss: 418.38714599609375, Neurons: 11, Grad norm: 1.541e+01\n",
      "Epoch 18313, Loss: 418.3797912597656, Neurons: 11, Grad norm: 1.597e+01\n",
      "Epoch 18314, Loss: 418.37237548828125, Neurons: 11, Grad norm: 1.559e+01\n",
      "Epoch 18315, Loss: 418.36492919921875, Neurons: 11, Grad norm: 1.411e+01\n",
      "Epoch 18316, Loss: 418.3575744628906, Neurons: 11, Grad norm: 1.305e+01\n",
      "Epoch 18317, Loss: 418.3501281738281, Neurons: 11, Grad norm: 1.237e+01\n",
      "Epoch 18318, Loss: 418.3426818847656, Neurons: 11, Grad norm: 9.611e+00\n",
      "Epoch 18319, Loss: 418.3351745605469, Neurons: 11, Grad norm: 7.062e+00\n",
      "Epoch 18320, Loss: 418.3277282714844, Neurons: 11, Grad norm: 4.877e+00\n",
      "Epoch 18321, Loss: 418.3202819824219, Neurons: 11, Grad norm: 2.506e+00\n",
      "Epoch 18322, Loss: 418.3127746582031, Neurons: 11, Grad norm: 2.762e+00\n",
      "Epoch 18323, Loss: 418.3052978515625, Neurons: 11, Grad norm: 4.207e+00\n",
      "Epoch 18324, Loss: 418.29779052734375, Neurons: 11, Grad norm: 6.225e+00\n",
      "Epoch 18325, Loss: 418.2902526855469, Neurons: 11, Grad norm: 7.021e+00\n",
      "Epoch 18326, Loss: 418.28277587890625, Neurons: 11, Grad norm: 9.393e+00\n",
      "Epoch 18327, Loss: 418.2751770019531, Neurons: 11, Grad norm: 1.210e+01\n",
      "Epoch 18328, Loss: 418.2677001953125, Neurons: 11, Grad norm: 1.375e+01\n",
      "Epoch 18329, Loss: 418.2601013183594, Neurons: 11, Grad norm: 1.672e+01\n",
      "Epoch 18330, Loss: 418.2525329589844, Neurons: 11, Grad norm: 1.876e+01\n",
      "Epoch 18331, Loss: 418.24493408203125, Neurons: 11, Grad norm: 2.004e+01\n",
      "Epoch 18332, Loss: 418.23736572265625, Neurons: 11, Grad norm: 2.201e+01\n",
      "Epoch 18333, Loss: 418.229736328125, Neurons: 11, Grad norm: 2.080e+01\n",
      "Epoch 18334, Loss: 418.2221374511719, Neurons: 11, Grad norm: 1.897e+01\n",
      "Epoch 18335, Loss: 418.2144470214844, Neurons: 11, Grad norm: 1.890e+01\n",
      "Epoch 18336, Loss: 418.20684814453125, Neurons: 11, Grad norm: 1.738e+01\n",
      "Epoch 18337, Loss: 418.1991271972656, Neurons: 11, Grad norm: 1.478e+01\n",
      "Epoch 18338, Loss: 418.1915283203125, Neurons: 11, Grad norm: 1.262e+01\n",
      "Epoch 18339, Loss: 418.18377685546875, Neurons: 11, Grad norm: 9.084e+00\n",
      "Epoch 18340, Loss: 418.17608642578125, Neurons: 11, Grad norm: 7.604e+00\n",
      "Epoch 18341, Loss: 418.16839599609375, Neurons: 11, Grad norm: 6.767e+00\n",
      "Epoch 18342, Loss: 418.1606750488281, Neurons: 11, Grad norm: 4.386e+00\n",
      "Epoch 18343, Loss: 418.1529541015625, Neurons: 11, Grad norm: 3.387e+00\n",
      "Epoch 18344, Loss: 418.1451721191406, Neurons: 11, Grad norm: 3.502e+00\n",
      "Epoch 18345, Loss: 418.1374206542969, Neurons: 11, Grad norm: 2.439e+00\n",
      "Epoch 18346, Loss: 418.1296081542969, Neurons: 11, Grad norm: 3.305e+00\n",
      "Epoch 18347, Loss: 418.121826171875, Neurons: 11, Grad norm: 5.479e+00\n",
      "Epoch 18348, Loss: 418.114013671875, Neurons: 11, Grad norm: 9.165e+00\n",
      "Epoch 18349, Loss: 418.106201171875, Neurons: 11, Grad norm: 1.290e+01\n",
      "Epoch 18349, Test loss: 415.0063781738281\n",
      "Epoch 18350, Loss: 418.098388671875, Neurons: 11, Grad norm: 1.475e+01\n",
      "Epoch 18351, Loss: 418.090576171875, Neurons: 11, Grad norm: 1.675e+01\n",
      "Epoch 18352, Loss: 418.08270263671875, Neurons: 11, Grad norm: 1.729e+01\n",
      "Epoch 18353, Loss: 418.0748291015625, Neurons: 11, Grad norm: 1.716e+01\n",
      "Epoch 18354, Loss: 418.0669250488281, Neurons: 11, Grad norm: 1.648e+01\n",
      "Epoch 18355, Loss: 418.0589904785156, Neurons: 11, Grad norm: 1.526e+01\n",
      "Epoch 18356, Loss: 418.05108642578125, Neurons: 11, Grad norm: 1.348e+01\n",
      "Epoch 18357, Loss: 418.04315185546875, Neurons: 11, Grad norm: 1.349e+01\n",
      "Epoch 18358, Loss: 418.03521728515625, Neurons: 11, Grad norm: 1.338e+01\n",
      "Epoch 18359, Loss: 418.0272521972656, Neurons: 11, Grad norm: 1.392e+01\n",
      "Epoch 18360, Loss: 418.019287109375, Neurons: 11, Grad norm: 1.517e+01\n",
      "Epoch 18361, Loss: 418.01129150390625, Neurons: 11, Grad norm: 1.683e+01\n",
      "Epoch 18362, Loss: 418.0032653808594, Neurons: 11, Grad norm: 1.840e+01\n",
      "Epoch 18363, Loss: 417.9952392578125, Neurons: 11, Grad norm: 2.105e+01\n",
      "Epoch 18364, Loss: 417.9871826171875, Neurons: 11, Grad norm: 2.107e+01\n",
      "Epoch 18365, Loss: 417.9791259765625, Neurons: 11, Grad norm: 2.127e+01\n",
      "Epoch 18366, Loss: 417.9710998535156, Neurons: 11, Grad norm: 2.082e+01\n",
      "Epoch 18367, Loss: 417.96295166015625, Neurons: 11, Grad norm: 1.943e+01\n",
      "Epoch 18368, Loss: 417.9548645019531, Neurons: 11, Grad norm: 1.770e+01\n",
      "Epoch 18369, Loss: 417.9466857910156, Neurons: 11, Grad norm: 1.627e+01\n",
      "Epoch 18370, Loss: 417.93853759765625, Neurons: 11, Grad norm: 1.347e+01\n",
      "Epoch 18371, Loss: 417.9303894042969, Neurons: 11, Grad norm: 1.353e+01\n",
      "Epoch 18372, Loss: 417.9222106933594, Neurons: 11, Grad norm: 1.333e+01\n",
      "Epoch 18373, Loss: 417.91400146484375, Neurons: 11, Grad norm: 1.374e+01\n",
      "Epoch 18374, Loss: 417.9057922363281, Neurons: 11, Grad norm: 1.522e+01\n",
      "Epoch 18375, Loss: 417.8975524902344, Neurons: 11, Grad norm: 1.725e+01\n",
      "Epoch 18376, Loss: 417.8893127441406, Neurons: 11, Grad norm: 1.887e+01\n",
      "Epoch 18377, Loss: 417.88104248046875, Neurons: 11, Grad norm: 2.243e+01\n",
      "Epoch 18378, Loss: 417.8727722167969, Neurons: 11, Grad norm: 2.289e+01\n",
      "Epoch 18379, Loss: 417.86444091796875, Neurons: 11, Grad norm: 2.406e+01\n",
      "Epoch 18380, Loss: 417.85614013671875, Neurons: 11, Grad norm: 2.466e+01\n",
      "Epoch 18381, Loss: 417.8477783203125, Neurons: 11, Grad norm: 2.434e+01\n",
      "Epoch 18382, Loss: 417.83935546875, Neurons: 11, Grad norm: 2.348e+01\n",
      "Epoch 18383, Loss: 417.83099365234375, Neurons: 11, Grad norm: 2.345e+01\n",
      "Epoch 18384, Loss: 417.82257080078125, Neurons: 11, Grad norm: 2.119e+01\n",
      "Epoch 18385, Loss: 417.8141174316406, Neurons: 11, Grad norm: 2.234e+01\n",
      "Epoch 18386, Loss: 417.8056335449219, Neurons: 11, Grad norm: 2.262e+01\n",
      "Epoch 18387, Loss: 417.7971496582031, Neurons: 11, Grad norm: 2.376e+01\n",
      "Epoch 18388, Loss: 417.7886047363281, Neurons: 11, Grad norm: 2.577e+01\n",
      "Epoch 18389, Loss: 417.7801208496094, Neurons: 11, Grad norm: 2.845e+01\n",
      "Epoch 18390, Loss: 417.7715759277344, Neurons: 11, Grad norm: 3.021e+01\n",
      "Epoch 18391, Loss: 417.7630310058594, Neurons: 11, Grad norm: 3.459e+01\n",
      "Epoch 18392, Loss: 417.75439453125, Neurons: 11, Grad norm: 3.517e+01\n",
      "Epoch 18393, Loss: 417.74578857421875, Neurons: 11, Grad norm: 3.692e+01\n",
      "Epoch 18394, Loss: 417.7371520996094, Neurons: 11, Grad norm: 3.749e+01\n",
      "Epoch 18395, Loss: 417.72845458984375, Neurons: 11, Grad norm: 3.732e+01\n",
      "Epoch 18396, Loss: 417.7197265625, Neurons: 11, Grad norm: 3.608e+01\n",
      "Epoch 18397, Loss: 417.7110290527344, Neurons: 11, Grad norm: 3.788e+01\n",
      "Epoch 18398, Loss: 417.70220947265625, Neurons: 11, Grad norm: 3.726e+01\n",
      "Epoch 18399, Loss: 417.6934509277344, Neurons: 11, Grad norm: 3.935e+01\n",
      "Epoch 18399, Test loss: 414.57513427734375\n",
      "Epoch 18400, Loss: 417.6846008300781, Neurons: 11, Grad norm: 4.026e+01\n",
      "Epoch 18401, Loss: 417.6757507324219, Neurons: 11, Grad norm: 4.231e+01\n",
      "Epoch 18402, Loss: 417.6669006347656, Neurons: 11, Grad norm: 4.359e+01\n",
      "Epoch 18403, Loss: 417.6579895019531, Neurons: 11, Grad norm: 4.652e+01\n",
      "Epoch 18404, Loss: 417.6490173339844, Neurons: 11, Grad norm: 4.526e+01\n",
      "Epoch 18405, Loss: 417.6400146484375, Neurons: 11, Grad norm: 4.766e+01\n",
      "Epoch 18406, Loss: 417.6309814453125, Neurons: 11, Grad norm: 4.776e+01\n",
      "Epoch 18407, Loss: 417.6219482421875, Neurons: 11, Grad norm: 4.897e+01\n",
      "Epoch 18408, Loss: 417.61285400390625, Neurons: 11, Grad norm: 5.087e+01\n",
      "Epoch 18409, Loss: 417.6037292480469, Neurons: 11, Grad norm: 5.494e+01\n",
      "Epoch 18410, Loss: 417.5945739746094, Neurons: 11, Grad norm: 5.438e+01\n",
      "Epoch 18411, Loss: 417.5853271484375, Neurons: 11, Grad norm: 5.738e+01\n",
      "Epoch 18412, Loss: 417.5760803222656, Neurons: 11, Grad norm: 5.654e+01\n",
      "Epoch 18413, Loss: 417.5667724609375, Neurons: 11, Grad norm: 5.854e+01\n",
      "Epoch 18414, Loss: 417.55743408203125, Neurons: 11, Grad norm: 5.932e+01\n",
      "Epoch 18415, Loss: 417.54803466796875, Neurons: 11, Grad norm: 6.121e+01\n",
      "Epoch 18416, Loss: 417.5385437011719, Neurons: 11, Grad norm: 5.857e+01\n",
      "Epoch 18417, Loss: 417.529052734375, Neurons: 11, Grad norm: 5.871e+01\n",
      "Epoch 18418, Loss: 417.5194396972656, Neurons: 11, Grad norm: 5.338e+01\n",
      "Epoch 18419, Loss: 417.5097351074219, Neurons: 11, Grad norm: 5.088e+01\n",
      "Epoch 18420, Loss: 417.4999694824219, Neurons: 11, Grad norm: 4.446e+01\n",
      "Epoch 18421, Loss: 417.4900817871094, Neurons: 11, Grad norm: 4.014e+01\n",
      "Epoch 18422, Loss: 417.4801330566406, Neurons: 11, Grad norm: 3.091e+01\n",
      "Epoch 18423, Loss: 417.4701232910156, Neurons: 11, Grad norm: 2.479e+01\n",
      "Epoch 18424, Loss: 417.4599914550781, Neurons: 11, Grad norm: 1.455e+01\n",
      "Epoch 18425, Loss: 417.44976806640625, Neurons: 11, Grad norm: 1.052e+01\n",
      "Epoch 18426, Loss: 417.439453125, Neurons: 11, Grad norm: 4.869e+00\n",
      "Epoch 18427, Loss: 417.4290466308594, Neurons: 11, Grad norm: 6.668e+00\n",
      "Epoch 18428, Loss: 417.41845703125, Neurons: 11, Grad norm: 1.281e+01\n",
      "Epoch 18429, Loss: 417.4077453613281, Neurons: 11, Grad norm: 1.491e+01\n",
      "Epoch 18430, Loss: 417.3968811035156, Neurons: 11, Grad norm: 2.241e+01\n",
      "Epoch 18431, Loss: 417.3858337402344, Neurons: 11, Grad norm: 2.369e+01\n",
      "Epoch 18432, Loss: 417.3746337890625, Neurons: 11, Grad norm: 3.053e+01\n",
      "Epoch 18433, Loss: 417.3631896972656, Neurons: 11, Grad norm: 2.924e+01\n",
      "Epoch 18434, Loss: 417.3515319824219, Neurons: 11, Grad norm: 3.386e+01\n",
      "Epoch 18435, Loss: 417.3396301269531, Neurons: 11, Grad norm: 3.224e+01\n",
      "Epoch 18436, Loss: 417.3274230957031, Neurons: 11, Grad norm: 3.582e+01\n",
      "Epoch 18437, Loss: 417.31494140625, Neurons: 11, Grad norm: 3.038e+01\n",
      "Epoch 18438, Loss: 417.30206298828125, Neurons: 11, Grad norm: 3.370e+01\n",
      "Epoch 18439, Loss: 417.288818359375, Neurons: 11, Grad norm: 2.628e+01\n",
      "Epoch 18440, Loss: 417.275146484375, Neurons: 11, Grad norm: 2.802e+01\n",
      "Epoch 18441, Loss: 417.26092529296875, Neurons: 11, Grad norm: 2.040e+01\n",
      "Epoch 18442, Loss: 417.2462158203125, Neurons: 11, Grad norm: 1.997e+01\n",
      "Epoch 18443, Loss: 417.23089599609375, Neurons: 11, Grad norm: 1.208e+01\n",
      "Epoch 18444, Loss: 417.21484375, Neurons: 11, Grad norm: 1.448e+01\n",
      "Epoch 18445, Loss: 417.197998046875, Neurons: 11, Grad norm: 9.950e+00\n",
      "Epoch 18446, Loss: 417.18023681640625, Neurons: 11, Grad norm: 1.036e+01\n",
      "Epoch 18447, Loss: 417.1614074707031, Neurons: 11, Grad norm: 1.252e+01\n",
      "Epoch 18448, Loss: 417.1413879394531, Neurons: 11, Grad norm: 1.149e+01\n",
      "Epoch 18449, Loss: 417.1199951171875, Neurons: 11, Grad norm: 1.658e+01\n",
      "Epoch 18449, Test loss: 413.8464660644531\n",
      "Epoch 18450, Loss: 417.09698486328125, Neurons: 11, Grad norm: 1.320e+01\n",
      "Epoch 18451, Loss: 417.0721435546875, Neurons: 11, Grad norm: 1.951e+01\n",
      "Epoch 18452, Loss: 417.0451965332031, Neurons: 11, Grad norm: 1.501e+01\n",
      "Epoch 18453, Loss: 417.01568603515625, Neurons: 11, Grad norm: 2.223e+01\n",
      "Epoch 18454, Loss: 416.9834289550781, Neurons: 11, Grad norm: 1.700e+01\n",
      "Epoch 18455, Loss: 416.9478759765625, Neurons: 11, Grad norm: 2.473e+01\n",
      "Epoch 18456, Loss: 416.9085998535156, Neurons: 11, Grad norm: 1.911e+01\n",
      "Epoch 18457, Loss: 416.8648986816406, Neurons: 11, Grad norm: 2.698e+01\n",
      "Epoch 18458, Loss: 416.8161926269531, Neurons: 11, Grad norm: 2.130e+01\n",
      "Epoch 18459, Loss: 416.7617492675781, Neurons: 11, Grad norm: 2.960e+01\n",
      "Epoch 18460, Loss: 416.70068359375, Neurons: 11, Grad norm: 2.377e+01\n",
      "Epoch 18461, Loss: 416.6319885253906, Neurons: 11, Grad norm: 3.053e+01\n",
      "Epoch 18462, Loss: 416.5546875, Neurons: 11, Grad norm: 2.698e+01\n",
      "Epoch 18463, Loss: 416.4676208496094, Neurons: 11, Grad norm: 3.153e+01\n",
      "Epoch 18464, Loss: 416.36944580078125, Neurons: 11, Grad norm: 3.212e+01\n",
      "Epoch 18465, Loss: 416.25885009765625, Neurons: 11, Grad norm: 3.321e+01\n",
      "Epoch 18466, Loss: 416.13427734375, Neurons: 11, Grad norm: 4.023e+01\n",
      "Epoch 18467, Loss: 415.9943542480469, Neurons: 11, Grad norm: 3.625e+01\n",
      "Epoch 18468, Loss: 415.8374938964844, Neurons: 11, Grad norm: 4.731e+01\n",
      "Epoch 18469, Loss: 415.6621398925781, Neurons: 11, Grad norm: 4.017e+01\n",
      "Epoch 18470, Loss: 415.4668884277344, Neurons: 11, Grad norm: 5.352e+01\n",
      "Epoch 18471, Loss: 415.250244140625, Neurons: 11, Grad norm: 4.380e+01\n",
      "Epoch 18472, Loss: 415.0108337402344, Neurons: 11, Grad norm: 5.676e+01\n",
      "Epoch 18473, Loss: 414.7472229003906, Neurons: 11, Grad norm: 4.713e+01\n",
      "Epoch 18474, Loss: 414.4584655761719, Neurons: 11, Grad norm: 5.789e+01\n",
      "Epoch 18475, Loss: 414.1435546875, Neurons: 11, Grad norm: 5.160e+01\n",
      "Epoch 18476, Loss: 413.8018798828125, Neurons: 11, Grad norm: 5.799e+01\n",
      "Epoch 18477, Loss: 413.4329528808594, Neurons: 11, Grad norm: 5.793e+01\n",
      "Epoch 18478, Loss: 413.03668212890625, Neurons: 11, Grad norm: 5.868e+01\n",
      "Epoch 18479, Loss: 412.6131591796875, Neurons: 11, Grad norm: 6.286e+01\n",
      "Epoch 18480, Loss: 412.1627502441406, Neurons: 11, Grad norm: 6.089e+01\n",
      "Epoch 18481, Loss: 411.68603515625, Neurons: 11, Grad norm: 6.597e+01\n",
      "Epoch 18482, Loss: 411.1839904785156, Neurons: 11, Grad norm: 6.372e+01\n",
      "Epoch 18483, Loss: 410.65765380859375, Neurons: 11, Grad norm: 6.776e+01\n",
      "Epoch 18484, Loss: 410.1084289550781, Neurons: 11, Grad norm: 6.583e+01\n",
      "Epoch 18485, Loss: 409.537841796875, Neurons: 11, Grad norm: 6.816e+01\n",
      "Epoch 18486, Loss: 408.9475402832031, Neurons: 11, Grad norm: 6.689e+01\n",
      "Epoch 18487, Loss: 408.3393859863281, Neurons: 11, Grad norm: 6.822e+01\n",
      "Epoch 18488, Loss: 407.71539306640625, Neurons: 11, Grad norm: 6.708e+01\n",
      "Epoch 18489, Loss: 407.0775451660156, Neurons: 11, Grad norm: 6.741e+01\n",
      "Epoch 18490, Loss: 406.4280090332031, Neurons: 11, Grad norm: 6.702e+01\n",
      "Epoch 18491, Loss: 405.76898193359375, Neurons: 11, Grad norm: 6.582e+01\n",
      "Epoch 18492, Loss: 405.1027526855469, Neurons: 11, Grad norm: 6.528e+01\n",
      "Epoch 18493, Loss: 404.4315490722656, Neurons: 11, Grad norm: 6.373e+01\n",
      "Epoch 18494, Loss: 403.75762939453125, Neurons: 11, Grad norm: 6.253e+01\n",
      "Epoch 18495, Loss: 403.08343505859375, Neurons: 11, Grad norm: 6.130e+01\n",
      "Epoch 18496, Loss: 402.4112548828125, Neurons: 11, Grad norm: 6.052e+01\n",
      "Epoch 18497, Loss: 401.7432861328125, Neurons: 11, Grad norm: 5.829e+01\n",
      "Epoch 18498, Loss: 401.081787109375, Neurons: 11, Grad norm: 5.717e+01\n",
      "Epoch 18499, Loss: 400.4288330078125, Neurons: 11, Grad norm: 5.531e+01\n",
      "Epoch 18499, Test loss: 395.50457763671875\n",
      "Epoch 18500, Loss: 399.786376953125, Neurons: 11, Grad norm: 5.392e+01\n",
      "Epoch 18501, Loss: 399.1563415527344, Neurons: 11, Grad norm: 5.242e+01\n",
      "Epoch 18502, Loss: 398.54034423828125, Neurons: 11, Grad norm: 5.129e+01\n",
      "Epoch 18503, Loss: 397.9397277832031, Neurons: 11, Grad norm: 4.946e+01\n",
      "Epoch 18504, Loss: 397.3558349609375, Neurons: 11, Grad norm: 4.835e+01\n",
      "Epoch 18505, Loss: 396.78961181640625, Neurons: 11, Grad norm: 4.660e+01\n",
      "Epoch 18506, Loss: 396.2418518066406, Neurons: 11, Grad norm: 4.579e+01\n",
      "Epoch 18507, Loss: 395.7130432128906, Neurons: 11, Grad norm: 4.402e+01\n",
      "Epoch 18508, Loss: 395.20355224609375, Neurons: 11, Grad norm: 4.318e+01\n",
      "Epoch 18509, Loss: 394.7135009765625, Neurons: 11, Grad norm: 4.173e+01\n",
      "Epoch 18510, Loss: 394.2428283691406, Neurons: 11, Grad norm: 4.065e+01\n",
      "Epoch 18511, Loss: 393.7912902832031, Neurons: 11, Grad norm: 3.960e+01\n",
      "Epoch 18512, Loss: 393.3585510253906, Neurons: 11, Grad norm: 3.842e+01\n",
      "Epoch 18513, Loss: 392.94415283203125, Neurons: 11, Grad norm: 3.793e+01\n",
      "Epoch 18514, Loss: 392.54754638671875, Neurons: 11, Grad norm: 3.649e+01\n",
      "Epoch 18515, Loss: 392.1680908203125, Neurons: 11, Grad norm: 3.575e+01\n",
      "Epoch 18516, Loss: 391.8050537109375, Neurons: 11, Grad norm: 3.475e+01\n",
      "Epoch 18517, Loss: 391.45782470703125, Neurons: 11, Grad norm: 3.388e+01\n",
      "Epoch 18518, Loss: 391.1256408691406, Neurons: 11, Grad norm: 3.335e+01\n",
      "Epoch 18519, Loss: 390.80780029296875, Neurons: 11, Grad norm: 3.233e+01\n",
      "Epoch 18520, Loss: 390.5035400390625, Neurons: 11, Grad norm: 3.186e+01\n",
      "Epoch 18521, Loss: 390.2121276855469, Neurons: 11, Grad norm: 3.090e+01\n",
      "Epoch 18522, Loss: 389.9329833984375, Neurons: 11, Grad norm: 3.056e+01\n",
      "Epoch 18523, Loss: 389.6653137207031, Neurons: 11, Grad norm: 2.952e+01\n",
      "Epoch 18524, Loss: 389.4085693359375, Neurons: 11, Grad norm: 2.908e+01\n",
      "Epoch 18525, Loss: 389.162109375, Neurons: 11, Grad norm: 2.835e+01\n",
      "Epoch 18526, Loss: 388.92529296875, Neurons: 11, Grad norm: 2.773e+01\n",
      "Epoch 18527, Loss: 388.69769287109375, Neurons: 11, Grad norm: 2.740e+01\n",
      "Epoch 18528, Loss: 388.4787292480469, Neurons: 11, Grad norm: 2.661e+01\n",
      "Epoch 18529, Loss: 388.2678527832031, Neurons: 11, Grad norm: 2.643e+01\n",
      "Epoch 18530, Loss: 388.064697265625, Neurons: 11, Grad norm: 2.555e+01\n",
      "Epoch 18531, Loss: 387.8688049316406, Neurons: 11, Grad norm: 2.515e+01\n",
      "Epoch 18532, Loss: 387.67962646484375, Neurons: 11, Grad norm: 2.506e+01\n",
      "Epoch 18533, Loss: 387.4969787597656, Neurons: 11, Grad norm: 2.423e+01\n",
      "Epoch 18534, Loss: 387.3203430175781, Neurons: 11, Grad norm: 2.436e+01\n",
      "Epoch 18535, Loss: 387.14947509765625, Neurons: 11, Grad norm: 2.345e+01\n",
      "Epoch 18536, Loss: 386.9839782714844, Neurons: 11, Grad norm: 2.374e+01\n",
      "Epoch 18537, Loss: 386.8236389160156, Neurons: 11, Grad norm: 2.258e+01\n",
      "Epoch 18538, Loss: 386.6680908203125, Neurons: 11, Grad norm: 2.240e+01\n",
      "Epoch 18539, Loss: 386.51715087890625, Neurons: 11, Grad norm: 2.251e+01\n",
      "Epoch 18540, Loss: 386.3704833984375, Neurons: 11, Grad norm: 2.163e+01\n",
      "Epoch 18541, Loss: 386.2279357910156, Neurons: 11, Grad norm: 2.225e+01\n",
      "Epoch 18542, Loss: 386.08929443359375, Neurons: 11, Grad norm: 2.100e+01\n",
      "Epoch 18543, Loss: 385.95428466796875, Neurons: 11, Grad norm: 2.099e+01\n",
      "Epoch 18544, Loss: 385.82275390625, Neurons: 11, Grad norm: 2.080e+01\n",
      "Epoch 18545, Loss: 385.6944885253906, Neurons: 11, Grad norm: 2.016e+01\n",
      "Epoch 18546, Loss: 385.5694274902344, Neurons: 11, Grad norm: 2.051e+01\n",
      "Epoch 18547, Loss: 385.4472961425781, Neurons: 11, Grad norm: 1.970e+01\n",
      "Epoch 18548, Loss: 385.3280334472656, Neurons: 11, Grad norm: 1.967e+01\n",
      "Epoch 18549, Loss: 385.2113952636719, Neurons: 11, Grad norm: 1.916e+01\n",
      "Epoch 18549, Test loss: 380.5400085449219\n",
      "Epoch 18550, Loss: 385.0973815917969, Neurons: 11, Grad norm: 1.939e+01\n",
      "Epoch 18551, Loss: 384.98577880859375, Neurons: 11, Grad norm: 1.871e+01\n",
      "Epoch 18552, Loss: 384.8764953613281, Neurons: 11, Grad norm: 1.946e+01\n",
      "Epoch 18553, Loss: 384.7694091796875, Neurons: 11, Grad norm: 1.826e+01\n",
      "Epoch 18554, Loss: 384.6644287109375, Neurons: 11, Grad norm: 1.810e+01\n",
      "Epoch 18555, Loss: 384.5614929199219, Neurons: 11, Grad norm: 1.798e+01\n",
      "Epoch 18556, Loss: 384.46044921875, Neurons: 11, Grad norm: 1.786e+01\n",
      "Epoch 18557, Loss: 384.3612365722656, Neurons: 11, Grad norm: 1.797e+01\n",
      "Epoch 18558, Loss: 384.2637939453125, Neurons: 11, Grad norm: 1.722e+01\n",
      "Epoch 18559, Loss: 384.1679992675781, Neurons: 11, Grad norm: 1.753e+01\n",
      "Epoch 18560, Loss: 384.0738220214844, Neurons: 11, Grad norm: 1.696e+01\n",
      "Epoch 18561, Loss: 383.9811706542969, Neurons: 11, Grad norm: 1.679e+01\n",
      "Epoch 18562, Loss: 383.88995361328125, Neurons: 11, Grad norm: 1.735e+01\n",
      "Epoch 18563, Loss: 383.8001403808594, Neurons: 11, Grad norm: 1.641e+01\n",
      "Epoch 18564, Loss: 383.7117004394531, Neurons: 11, Grad norm: 1.744e+01\n",
      "Epoch 18565, Loss: 383.6245422363281, Neurons: 11, Grad norm: 1.613e+01\n",
      "Epoch 18566, Loss: 383.5386047363281, Neurons: 11, Grad norm: 1.650e+01\n",
      "Epoch 18567, Loss: 383.4538269042969, Neurons: 11, Grad norm: 1.575e+01\n",
      "Epoch 18568, Loss: 383.37017822265625, Neurons: 11, Grad norm: 1.576e+01\n",
      "Epoch 18569, Loss: 383.28759765625, Neurons: 11, Grad norm: 1.630e+01\n",
      "Epoch 18570, Loss: 383.2060852050781, Neurons: 11, Grad norm: 1.549e+01\n",
      "Epoch 18571, Loss: 383.1255798339844, Neurons: 11, Grad norm: 1.747e+01\n",
      "Epoch 18572, Loss: 383.0459899902344, Neurons: 11, Grad norm: 1.580e+01\n",
      "Epoch 18573, Loss: 382.9673156738281, Neurons: 11, Grad norm: 1.694e+01\n",
      "Epoch 18574, Loss: 382.8895263671875, Neurons: 11, Grad norm: 1.490e+01\n",
      "Epoch 18575, Loss: 382.81256103515625, Neurons: 11, Grad norm: 1.511e+01\n",
      "Epoch 18576, Loss: 382.7364501953125, Neurons: 11, Grad norm: 1.584e+01\n",
      "Epoch 18577, Loss: 382.66107177734375, Neurons: 11, Grad norm: 1.514e+01\n",
      "Epoch 18578, Loss: 382.58642578125, Neurons: 11, Grad norm: 1.815e+01\n",
      "Epoch 18579, Loss: 382.5125427246094, Neurons: 11, Grad norm: 1.642e+01\n",
      "Epoch 18580, Loss: 382.4393005371094, Neurons: 11, Grad norm: 1.917e+01\n",
      "Epoch 18581, Loss: 382.3667297363281, Neurons: 11, Grad norm: 1.570e+01\n",
      "Epoch 18582, Loss: 382.2947692871094, Neurons: 11, Grad norm: 1.668e+01\n",
      "Epoch 18583, Loss: 382.223388671875, Neurons: 11, Grad norm: 1.406e+01\n",
      "Epoch 18584, Loss: 382.152587890625, Neurons: 11, Grad norm: 1.440e+01\n",
      "Epoch 18585, Loss: 382.0823974609375, Neurons: 11, Grad norm: 1.420e+01\n",
      "Epoch 18586, Loss: 382.0126647949219, Neurons: 11, Grad norm: 1.384e+01\n",
      "Epoch 18587, Loss: 381.9434509277344, Neurons: 11, Grad norm: 1.612e+01\n",
      "Epoch 18588, Loss: 381.8747253417969, Neurons: 11, Grad norm: 1.453e+01\n",
      "Epoch 18589, Loss: 381.8064880371094, Neurons: 11, Grad norm: 1.781e+01\n",
      "Epoch 18590, Loss: 381.7386779785156, Neurons: 11, Grad norm: 1.479e+01\n",
      "Epoch 18591, Loss: 381.6712951660156, Neurons: 11, Grad norm: 1.614e+01\n",
      "Epoch 18592, Loss: 381.6042785644531, Neurons: 11, Grad norm: 1.350e+01\n",
      "Epoch 18593, Loss: 381.53759765625, Neurons: 11, Grad norm: 1.462e+01\n",
      "Epoch 18594, Loss: 381.47137451171875, Neurons: 11, Grad norm: 1.322e+01\n",
      "Epoch 18595, Loss: 381.4054260253906, Neurons: 11, Grad norm: 1.324e+01\n",
      "Epoch 18596, Loss: 381.3398742675781, Neurons: 11, Grad norm: 1.458e+01\n",
      "Epoch 18597, Loss: 381.27459716796875, Neurons: 11, Grad norm: 1.337e+01\n",
      "Epoch 18598, Loss: 381.2095947265625, Neurons: 11, Grad norm: 1.568e+01\n",
      "Epoch 18599, Loss: 381.1448669433594, Neurons: 11, Grad norm: 1.333e+01\n",
      "Epoch 18599, Test loss: 376.6909484863281\n",
      "Epoch 18600, Loss: 381.08038330078125, Neurons: 11, Grad norm: 1.608e+01\n",
      "Epoch 18601, Loss: 381.0162048339844, Neurons: 11, Grad norm: 1.323e+01\n",
      "Epoch 18602, Loss: 380.9521789550781, Neurons: 11, Grad norm: 1.496e+01\n",
      "Epoch 18603, Loss: 380.888427734375, Neurons: 11, Grad norm: 1.285e+01\n",
      "Epoch 18604, Loss: 380.8248291015625, Neurons: 11, Grad norm: 1.368e+01\n",
      "Epoch 18605, Loss: 380.7614440917969, Neurons: 11, Grad norm: 1.291e+01\n",
      "Epoch 18606, Loss: 380.69818115234375, Neurons: 11, Grad norm: 1.297e+01\n",
      "Epoch 18607, Loss: 380.6351318359375, Neurons: 11, Grad norm: 1.448e+01\n",
      "Epoch 18608, Loss: 380.57220458984375, Neurons: 11, Grad norm: 1.288e+01\n",
      "Epoch 18609, Loss: 380.50933837890625, Neurons: 11, Grad norm: 1.484e+01\n",
      "Epoch 18610, Loss: 380.4466552734375, Neurons: 11, Grad norm: 1.289e+01\n",
      "Epoch 18611, Loss: 380.38409423828125, Neurons: 11, Grad norm: 1.604e+01\n",
      "Epoch 18612, Loss: 380.32159423828125, Neurons: 11, Grad norm: 1.257e+01\n",
      "Epoch 18613, Loss: 380.2591552734375, Neurons: 11, Grad norm: 1.411e+01\n",
      "Epoch 18614, Loss: 380.1967468261719, Neurons: 11, Grad norm: 1.231e+01\n",
      "Epoch 18615, Loss: 380.1344299316406, Neurons: 11, Grad norm: 1.258e+01\n",
      "Epoch 18616, Loss: 380.07208251953125, Neurons: 11, Grad norm: 1.339e+01\n",
      "Epoch 18617, Loss: 380.00982666015625, Neurons: 11, Grad norm: 1.253e+01\n",
      "Epoch 18618, Loss: 379.9475402832031, Neurons: 11, Grad norm: 1.327e+01\n",
      "Epoch 18619, Loss: 379.88525390625, Neurons: 11, Grad norm: 1.226e+01\n",
      "Epoch 18620, Loss: 379.822998046875, Neurons: 11, Grad norm: 1.296e+01\n",
      "Epoch 18621, Loss: 379.76068115234375, Neurons: 11, Grad norm: 1.241e+01\n",
      "Epoch 18622, Loss: 379.69830322265625, Neurons: 11, Grad norm: 1.312e+01\n",
      "Epoch 18623, Loss: 379.6358947753906, Neurons: 11, Grad norm: 1.337e+01\n",
      "Epoch 18624, Loss: 379.5733947753906, Neurons: 11, Grad norm: 1.222e+01\n",
      "Epoch 18625, Loss: 379.51080322265625, Neurons: 11, Grad norm: 1.357e+01\n",
      "Epoch 18626, Loss: 379.4481506347656, Neurons: 11, Grad norm: 1.219e+01\n",
      "Epoch 18627, Loss: 379.3853759765625, Neurons: 11, Grad norm: 1.417e+01\n",
      "Epoch 18628, Loss: 379.3224792480469, Neurons: 11, Grad norm: 1.236e+01\n",
      "Epoch 18629, Loss: 379.2594909667969, Neurons: 11, Grad norm: 1.334e+01\n",
      "Epoch 18630, Loss: 379.1963195800781, Neurons: 11, Grad norm: 1.253e+01\n",
      "Epoch 18631, Loss: 379.13299560546875, Neurons: 11, Grad norm: 1.246e+01\n",
      "Epoch 18632, Loss: 379.0695495605469, Neurons: 11, Grad norm: 1.409e+01\n",
      "Epoch 18633, Loss: 379.0058898925781, Neurons: 11, Grad norm: 1.231e+01\n",
      "Epoch 18634, Loss: 378.9419860839844, Neurons: 11, Grad norm: 1.517e+01\n",
      "Epoch 18635, Loss: 378.8779602050781, Neurons: 11, Grad norm: 1.256e+01\n",
      "Epoch 18636, Loss: 378.8136901855469, Neurons: 11, Grad norm: 1.731e+01\n",
      "Epoch 18637, Loss: 378.7491760253906, Neurons: 11, Grad norm: 1.338e+01\n",
      "Epoch 18638, Loss: 378.6844787597656, Neurons: 11, Grad norm: 1.848e+01\n",
      "Epoch 18639, Loss: 378.61944580078125, Neurons: 11, Grad norm: 1.427e+01\n",
      "Epoch 18640, Loss: 378.5541687011719, Neurons: 11, Grad norm: 1.954e+01\n",
      "Epoch 18641, Loss: 378.4886169433594, Neurons: 11, Grad norm: 1.336e+01\n",
      "Epoch 18642, Loss: 378.4227294921875, Neurons: 11, Grad norm: 1.638e+01\n",
      "Epoch 18643, Loss: 378.3565979003906, Neurons: 11, Grad norm: 1.251e+01\n",
      "Epoch 18644, Loss: 378.29010009765625, Neurons: 11, Grad norm: 1.494e+01\n",
      "Epoch 18645, Loss: 378.2232666015625, Neurons: 11, Grad norm: 1.260e+01\n",
      "Epoch 18646, Loss: 378.15606689453125, Neurons: 11, Grad norm: 1.469e+01\n",
      "Epoch 18647, Loss: 378.0885314941406, Neurons: 11, Grad norm: 1.246e+01\n",
      "Epoch 18648, Loss: 378.0206298828125, Neurons: 11, Grad norm: 1.497e+01\n",
      "Epoch 18649, Loss: 377.9523010253906, Neurons: 11, Grad norm: 1.274e+01\n",
      "Epoch 18649, Test loss: 373.7582702636719\n",
      "Epoch 18650, Loss: 377.8835754394531, Neurons: 11, Grad norm: 1.428e+01\n",
      "Epoch 18651, Loss: 377.81439208984375, Neurons: 11, Grad norm: 1.328e+01\n",
      "Epoch 18652, Loss: 377.7447814941406, Neurons: 11, Grad norm: 1.327e+01\n",
      "Epoch 18653, Loss: 377.6747741699219, Neurons: 11, Grad norm: 1.412e+01\n",
      "Epoch 18654, Loss: 377.6042175292969, Neurons: 11, Grad norm: 1.315e+01\n",
      "Epoch 18655, Loss: 377.5332336425781, Neurons: 11, Grad norm: 1.490e+01\n",
      "Epoch 18656, Loss: 377.46173095703125, Neurons: 11, Grad norm: 1.291e+01\n",
      "Epoch 18657, Loss: 377.3896789550781, Neurons: 11, Grad norm: 1.632e+01\n",
      "Epoch 18658, Loss: 377.317138671875, Neurons: 11, Grad norm: 1.304e+01\n",
      "Epoch 18659, Loss: 377.24407958984375, Neurons: 11, Grad norm: 1.568e+01\n",
      "Epoch 18660, Loss: 377.1704406738281, Neurons: 11, Grad norm: 1.331e+01\n",
      "Epoch 18661, Loss: 377.09613037109375, Neurons: 11, Grad norm: 1.454e+01\n",
      "Epoch 18662, Loss: 377.0213317871094, Neurons: 11, Grad norm: 1.378e+01\n",
      "Epoch 18663, Loss: 376.9458923339844, Neurons: 11, Grad norm: 1.500e+01\n",
      "Epoch 18664, Loss: 376.8697814941406, Neurons: 11, Grad norm: 1.465e+01\n",
      "Epoch 18665, Loss: 376.79302978515625, Neurons: 11, Grad norm: 1.411e+01\n",
      "Epoch 18666, Loss: 376.71563720703125, Neurons: 11, Grad norm: 1.410e+01\n",
      "Epoch 18667, Loss: 376.6375427246094, Neurons: 11, Grad norm: 1.499e+01\n",
      "Epoch 18668, Loss: 376.55877685546875, Neurons: 11, Grad norm: 1.446e+01\n",
      "Epoch 18669, Loss: 376.479248046875, Neurons: 11, Grad norm: 1.485e+01\n",
      "Epoch 18670, Loss: 376.3990173339844, Neurons: 11, Grad norm: 1.559e+01\n",
      "Epoch 18671, Loss: 376.3179931640625, Neurons: 11, Grad norm: 1.442e+01\n",
      "Epoch 18672, Loss: 376.2362365722656, Neurons: 11, Grad norm: 1.562e+01\n",
      "Epoch 18673, Loss: 376.1536865234375, Neurons: 11, Grad norm: 1.407e+01\n",
      "Epoch 18674, Loss: 376.07025146484375, Neurons: 11, Grad norm: 1.745e+01\n",
      "Epoch 18675, Loss: 375.9860534667969, Neurons: 11, Grad norm: 1.421e+01\n",
      "Epoch 18676, Loss: 375.9010009765625, Neurons: 11, Grad norm: 1.879e+01\n",
      "Epoch 18677, Loss: 375.8150634765625, Neurons: 11, Grad norm: 1.423e+01\n",
      "Epoch 18678, Loss: 375.7282409667969, Neurons: 11, Grad norm: 1.608e+01\n",
      "Epoch 18679, Loss: 375.6405029296875, Neurons: 11, Grad norm: 1.581e+01\n",
      "Epoch 18680, Loss: 375.5517883300781, Neurons: 11, Grad norm: 1.481e+01\n",
      "Epoch 18681, Loss: 375.4621887207031, Neurons: 11, Grad norm: 2.023e+01\n",
      "Epoch 18682, Loss: 375.3715515136719, Neurons: 11, Grad norm: 1.463e+01\n",
      "Epoch 18683, Loss: 375.27996826171875, Neurons: 11, Grad norm: 1.897e+01\n",
      "Epoch 18684, Loss: 375.1873779296875, Neurons: 11, Grad norm: 1.493e+01\n",
      "Epoch 18685, Loss: 375.0937194824219, Neurons: 11, Grad norm: 1.670e+01\n",
      "Epoch 18686, Loss: 374.9989929199219, Neurons: 11, Grad norm: 1.821e+01\n",
      "Epoch 18687, Loss: 374.9032287597656, Neurons: 11, Grad norm: 1.535e+01\n",
      "Epoch 18688, Loss: 374.80633544921875, Neurons: 11, Grad norm: 2.162e+01\n",
      "Epoch 18689, Loss: 374.7083435058594, Neurons: 11, Grad norm: 1.544e+01\n",
      "Epoch 18690, Loss: 374.60919189453125, Neurons: 11, Grad norm: 2.160e+01\n",
      "Epoch 18691, Loss: 374.5088806152344, Neurons: 11, Grad norm: 1.560e+01\n",
      "Epoch 18692, Loss: 374.4073791503906, Neurons: 11, Grad norm: 1.841e+01\n",
      "Epoch 18693, Loss: 374.30462646484375, Neurons: 11, Grad norm: 1.880e+01\n",
      "Epoch 18694, Loss: 374.20074462890625, Neurons: 11, Grad norm: 1.587e+01\n",
      "Epoch 18695, Loss: 374.0955505371094, Neurons: 11, Grad norm: 2.293e+01\n",
      "Epoch 18696, Loss: 373.98907470703125, Neurons: 11, Grad norm: 1.680e+01\n",
      "Epoch 18697, Loss: 373.8813171386719, Neurons: 11, Grad norm: 2.748e+01\n",
      "Epoch 18698, Loss: 373.7722473144531, Neurons: 11, Grad norm: 1.678e+01\n",
      "Epoch 18699, Loss: 373.66180419921875, Neurons: 11, Grad norm: 2.474e+01\n",
      "Epoch 18699, Test loss: 369.7632141113281\n",
      "Epoch 18700, Loss: 373.54998779296875, Neurons: 11, Grad norm: 1.647e+01\n",
      "Epoch 18701, Loss: 373.43682861328125, Neurons: 11, Grad norm: 1.984e+01\n",
      "Epoch 18702, Loss: 373.3222351074219, Neurons: 11, Grad norm: 1.852e+01\n",
      "Epoch 18703, Loss: 373.20623779296875, Neurons: 11, Grad norm: 1.752e+01\n",
      "Epoch 18704, Loss: 373.0887451171875, Neurons: 11, Grad norm: 2.288e+01\n",
      "Epoch 18705, Loss: 372.9698486328125, Neurons: 11, Grad norm: 1.714e+01\n",
      "Epoch 18706, Loss: 372.84942626953125, Neurons: 11, Grad norm: 2.404e+01\n",
      "Epoch 18707, Loss: 372.72747802734375, Neurons: 11, Grad norm: 1.711e+01\n",
      "Epoch 18708, Loss: 372.6039733886719, Neurons: 11, Grad norm: 2.211e+01\n",
      "Epoch 18709, Loss: 372.4788818359375, Neurons: 11, Grad norm: 1.874e+01\n",
      "Epoch 18710, Loss: 372.352294921875, Neurons: 11, Grad norm: 2.095e+01\n",
      "Epoch 18711, Loss: 372.22406005859375, Neurons: 11, Grad norm: 2.035e+01\n",
      "Epoch 18712, Loss: 372.0942077636719, Neurons: 11, Grad norm: 1.839e+01\n",
      "Epoch 18713, Loss: 371.9627380371094, Neurons: 11, Grad norm: 2.098e+01\n",
      "Epoch 18714, Loss: 371.82958984375, Neurons: 11, Grad norm: 2.024e+01\n",
      "Epoch 18715, Loss: 371.6947326660156, Neurons: 11, Grad norm: 2.063e+01\n",
      "Epoch 18716, Loss: 371.5582275390625, Neurons: 11, Grad norm: 2.130e+01\n",
      "Epoch 18717, Loss: 371.4199523925781, Neurons: 11, Grad norm: 1.958e+01\n",
      "Epoch 18718, Loss: 371.27996826171875, Neurons: 11, Grad norm: 2.157e+01\n",
      "Epoch 18719, Loss: 371.13824462890625, Neurons: 11, Grad norm: 2.021e+01\n",
      "Epoch 18720, Loss: 370.9947509765625, Neurons: 11, Grad norm: 2.289e+01\n",
      "Epoch 18721, Loss: 370.8493957519531, Neurons: 11, Grad norm: 1.980e+01\n",
      "Epoch 18722, Loss: 370.7023010253906, Neurons: 11, Grad norm: 2.453e+01\n",
      "Epoch 18723, Loss: 370.5533447265625, Neurons: 11, Grad norm: 1.922e+01\n",
      "Epoch 18724, Loss: 370.402587890625, Neurons: 11, Grad norm: 2.498e+01\n",
      "Epoch 18725, Loss: 370.24993896484375, Neurons: 11, Grad norm: 2.066e+01\n",
      "Epoch 18726, Loss: 370.0954284667969, Neurons: 11, Grad norm: 2.366e+01\n",
      "Epoch 18727, Loss: 369.93902587890625, Neurons: 11, Grad norm: 2.090e+01\n",
      "Epoch 18728, Loss: 369.7807922363281, Neurons: 11, Grad norm: 2.249e+01\n",
      "Epoch 18729, Loss: 369.62060546875, Neurons: 11, Grad norm: 2.289e+01\n",
      "Epoch 18730, Loss: 369.4584655761719, Neurons: 11, Grad norm: 2.195e+01\n",
      "Epoch 18731, Loss: 369.29443359375, Neurons: 11, Grad norm: 2.429e+01\n",
      "Epoch 18732, Loss: 369.1284484863281, Neurons: 11, Grad norm: 2.163e+01\n",
      "Epoch 18733, Loss: 368.9604797363281, Neurons: 11, Grad norm: 2.388e+01\n",
      "Epoch 18734, Loss: 368.79058837890625, Neurons: 11, Grad norm: 2.262e+01\n",
      "Epoch 18735, Loss: 368.6186828613281, Neurons: 11, Grad norm: 2.336e+01\n",
      "Epoch 18736, Loss: 368.4448547363281, Neurons: 11, Grad norm: 2.339e+01\n",
      "Epoch 18737, Loss: 368.26898193359375, Neurons: 11, Grad norm: 2.407e+01\n",
      "Epoch 18738, Loss: 368.09112548828125, Neurons: 11, Grad norm: 2.383e+01\n",
      "Epoch 18739, Loss: 367.91131591796875, Neurons: 11, Grad norm: 2.351e+01\n",
      "Epoch 18740, Loss: 367.7294616699219, Neurons: 11, Grad norm: 2.392e+01\n",
      "Epoch 18741, Loss: 367.545654296875, Neurons: 11, Grad norm: 2.361e+01\n",
      "Epoch 18742, Loss: 367.3597412109375, Neurons: 11, Grad norm: 2.385e+01\n",
      "Epoch 18743, Loss: 367.1719055175781, Neurons: 11, Grad norm: 2.578e+01\n",
      "Epoch 18744, Loss: 366.98199462890625, Neurons: 11, Grad norm: 2.386e+01\n",
      "Epoch 18745, Loss: 366.79010009765625, Neurons: 11, Grad norm: 2.503e+01\n",
      "Epoch 18746, Loss: 366.59619140625, Neurons: 11, Grad norm: 2.320e+01\n",
      "Epoch 18747, Loss: 366.4002990722656, Neurons: 11, Grad norm: 2.580e+01\n",
      "Epoch 18748, Loss: 366.20233154296875, Neurons: 11, Grad norm: 2.489e+01\n",
      "Epoch 18749, Loss: 366.00238037109375, Neurons: 11, Grad norm: 2.539e+01\n",
      "Epoch 18749, Test loss: 362.34503173828125\n",
      "Epoch 18750, Loss: 365.8004455566406, Neurons: 11, Grad norm: 2.559e+01\n",
      "Epoch 18751, Loss: 365.5965270996094, Neurons: 11, Grad norm: 2.409e+01\n",
      "Epoch 18752, Loss: 365.3906555175781, Neurons: 11, Grad norm: 2.517e+01\n",
      "Epoch 18753, Loss: 365.1827087402344, Neurons: 11, Grad norm: 2.623e+01\n",
      "Epoch 18754, Loss: 364.97283935546875, Neurons: 11, Grad norm: 2.554e+01\n",
      "Epoch 18755, Loss: 364.76104736328125, Neurons: 11, Grad norm: 2.579e+01\n",
      "Epoch 18756, Loss: 364.5472412109375, Neurons: 11, Grad norm: 2.605e+01\n",
      "Epoch 18757, Loss: 364.33154296875, Neurons: 11, Grad norm: 2.508e+01\n",
      "Epoch 18758, Loss: 364.1138916015625, Neurons: 11, Grad norm: 2.634e+01\n",
      "Epoch 18759, Loss: 363.89434814453125, Neurons: 11, Grad norm: 2.499e+01\n",
      "Epoch 18760, Loss: 363.6728820800781, Neurons: 11, Grad norm: 2.792e+01\n",
      "Epoch 18761, Loss: 363.4495544433594, Neurons: 11, Grad norm: 2.586e+01\n",
      "Epoch 18762, Loss: 363.2243347167969, Neurons: 11, Grad norm: 2.625e+01\n",
      "Epoch 18763, Loss: 362.9973449707031, Neurons: 11, Grad norm: 2.566e+01\n",
      "Epoch 18764, Loss: 362.7684631347656, Neurons: 11, Grad norm: 2.658e+01\n",
      "Epoch 18765, Loss: 362.53778076171875, Neurons: 11, Grad norm: 2.702e+01\n",
      "Epoch 18766, Loss: 362.3052978515625, Neurons: 11, Grad norm: 2.601e+01\n",
      "Epoch 18767, Loss: 362.0710754394531, Neurons: 11, Grad norm: 2.820e+01\n",
      "Epoch 18768, Loss: 361.8351135253906, Neurons: 11, Grad norm: 2.570e+01\n",
      "Epoch 18769, Loss: 361.597412109375, Neurons: 11, Grad norm: 2.696e+01\n",
      "Epoch 18770, Loss: 361.3580017089844, Neurons: 11, Grad norm: 2.599e+01\n",
      "Epoch 18771, Loss: 361.11700439453125, Neurons: 11, Grad norm: 2.771e+01\n",
      "Epoch 18772, Loss: 360.8742980957031, Neurons: 11, Grad norm: 2.764e+01\n",
      "Epoch 18773, Loss: 360.6300048828125, Neurons: 11, Grad norm: 2.660e+01\n",
      "Epoch 18774, Loss: 360.38409423828125, Neurons: 11, Grad norm: 2.665e+01\n",
      "Epoch 18775, Loss: 360.1366271972656, Neurons: 11, Grad norm: 2.725e+01\n",
      "Epoch 18776, Loss: 359.8876953125, Neurons: 11, Grad norm: 2.713e+01\n",
      "Epoch 18777, Loss: 359.6372375488281, Neurons: 11, Grad norm: 2.778e+01\n",
      "Epoch 18778, Loss: 359.38531494140625, Neurons: 11, Grad norm: 2.652e+01\n",
      "Epoch 18779, Loss: 359.1319274902344, Neurons: 11, Grad norm: 2.823e+01\n",
      "Epoch 18780, Loss: 358.877197265625, Neurons: 11, Grad norm: 2.681e+01\n",
      "Epoch 18781, Loss: 358.6211242675781, Neurons: 11, Grad norm: 2.728e+01\n",
      "Epoch 18782, Loss: 358.3636779785156, Neurons: 11, Grad norm: 2.688e+01\n",
      "Epoch 18783, Loss: 358.10498046875, Neurons: 11, Grad norm: 2.798e+01\n",
      "Epoch 18784, Loss: 357.8450012207031, Neurons: 11, Grad norm: 2.773e+01\n",
      "Epoch 18785, Loss: 357.5838317871094, Neurons: 11, Grad norm: 2.730e+01\n",
      "Epoch 18786, Loss: 357.3214416503906, Neurons: 11, Grad norm: 2.743e+01\n",
      "Epoch 18787, Loss: 357.0579528808594, Neurons: 11, Grad norm: 2.623e+01\n",
      "Epoch 18788, Loss: 356.7933349609375, Neurons: 11, Grad norm: 2.898e+01\n",
      "Epoch 18789, Loss: 356.5276794433594, Neurons: 11, Grad norm: 2.728e+01\n",
      "Epoch 18790, Loss: 356.260986328125, Neurons: 11, Grad norm: 2.788e+01\n",
      "Epoch 18791, Loss: 355.9933166503906, Neurons: 11, Grad norm: 2.761e+01\n",
      "Epoch 18792, Loss: 355.7247009277344, Neurons: 11, Grad norm: 2.645e+01\n",
      "Epoch 18793, Loss: 355.4551696777344, Neurons: 11, Grad norm: 2.811e+01\n",
      "Epoch 18794, Loss: 355.1847839355469, Neurons: 11, Grad norm: 2.662e+01\n",
      "Epoch 18795, Loss: 354.9136047363281, Neurons: 11, Grad norm: 2.913e+01\n",
      "Epoch 18796, Loss: 354.6416320800781, Neurons: 11, Grad norm: 2.753e+01\n",
      "Epoch 18797, Loss: 354.3689270019531, Neurons: 11, Grad norm: 2.675e+01\n",
      "Epoch 18798, Loss: 354.0955505371094, Neurons: 11, Grad norm: 2.774e+01\n",
      "Epoch 18799, Loss: 353.8215026855469, Neurons: 11, Grad norm: 2.637e+01\n",
      "Epoch 18799, Test loss: 350.2638244628906\n",
      "Epoch 18800, Loss: 353.5468444824219, Neurons: 11, Grad norm: 2.835e+01\n",
      "Epoch 18801, Loss: 353.2716369628906, Neurons: 11, Grad norm: 2.781e+01\n",
      "Epoch 18802, Loss: 352.9958801269531, Neurons: 11, Grad norm: 2.711e+01\n",
      "Epoch 18803, Loss: 352.7196350097656, Neurons: 11, Grad norm: 2.785e+01\n",
      "Epoch 18804, Loss: 352.4429931640625, Neurons: 11, Grad norm: 2.635e+01\n",
      "Epoch 18805, Loss: 352.1658935546875, Neurons: 11, Grad norm: 2.760e+01\n",
      "Epoch 18806, Loss: 351.8884582519531, Neurons: 11, Grad norm: 2.769e+01\n",
      "Epoch 18807, Loss: 351.6106872558594, Neurons: 11, Grad norm: 2.707e+01\n",
      "Epoch 18808, Loss: 351.3326721191406, Neurons: 11, Grad norm: 2.787e+01\n",
      "Epoch 18809, Loss: 351.05438232421875, Neurons: 11, Grad norm: 2.639e+01\n",
      "Epoch 18810, Loss: 350.77593994140625, Neurons: 11, Grad norm: 2.700e+01\n",
      "Epoch 18811, Loss: 350.4973449707031, Neurons: 11, Grad norm: 2.719e+01\n",
      "Epoch 18812, Loss: 350.2185974121094, Neurons: 11, Grad norm: 2.692e+01\n",
      "Epoch 18813, Loss: 349.9397888183594, Neurons: 11, Grad norm: 2.844e+01\n",
      "Epoch 18814, Loss: 349.66094970703125, Neurons: 11, Grad norm: 2.571e+01\n",
      "Epoch 18815, Loss: 349.382080078125, Neurons: 11, Grad norm: 2.698e+01\n",
      "Epoch 18816, Loss: 349.1032409667969, Neurons: 11, Grad norm: 2.694e+01\n",
      "Epoch 18817, Loss: 348.8244934082031, Neurons: 11, Grad norm: 2.641e+01\n",
      "Epoch 18818, Loss: 348.54583740234375, Neurons: 11, Grad norm: 2.816e+01\n",
      "Epoch 18819, Loss: 348.267333984375, Neurons: 11, Grad norm: 2.615e+01\n",
      "Epoch 18820, Loss: 347.9889831542969, Neurons: 11, Grad norm: 2.711e+01\n",
      "Epoch 18821, Loss: 347.71087646484375, Neurons: 11, Grad norm: 2.565e+01\n",
      "Epoch 18822, Loss: 347.4330139160156, Neurons: 11, Grad norm: 2.602e+01\n",
      "Epoch 18823, Loss: 347.1553955078125, Neurons: 11, Grad norm: 2.830e+01\n",
      "Epoch 18824, Loss: 346.8780517578125, Neurons: 11, Grad norm: 2.527e+01\n",
      "Epoch 18825, Loss: 346.6011047363281, Neurons: 11, Grad norm: 2.723e+01\n",
      "Epoch 18826, Loss: 346.3244934082031, Neurons: 11, Grad norm: 2.596e+01\n",
      "Epoch 18827, Loss: 346.04827880859375, Neurons: 11, Grad norm: 2.539e+01\n",
      "Epoch 18828, Loss: 345.7724914550781, Neurons: 11, Grad norm: 2.821e+01\n",
      "Epoch 18829, Loss: 345.49713134765625, Neurons: 11, Grad norm: 2.468e+01\n",
      "Epoch 18830, Loss: 345.2222900390625, Neurons: 11, Grad norm: 2.732e+01\n",
      "Epoch 18831, Loss: 344.9479064941406, Neurons: 11, Grad norm: 2.544e+01\n",
      "Epoch 18832, Loss: 344.6740417480469, Neurons: 11, Grad norm: 2.551e+01\n",
      "Epoch 18833, Loss: 344.4007263183594, Neurons: 11, Grad norm: 2.661e+01\n",
      "Epoch 18834, Loss: 344.1279296875, Neurons: 11, Grad norm: 2.559e+01\n",
      "Epoch 18835, Loss: 343.8558044433594, Neurons: 11, Grad norm: 2.565e+01\n",
      "Epoch 18836, Loss: 343.584228515625, Neurons: 11, Grad norm: 2.590e+01\n",
      "Epoch 18837, Loss: 343.31329345703125, Neurons: 11, Grad norm: 2.590e+01\n",
      "Epoch 18838, Loss: 343.0429992675781, Neurons: 11, Grad norm: 2.507e+01\n",
      "Epoch 18839, Loss: 342.77337646484375, Neurons: 11, Grad norm: 2.626e+01\n",
      "Epoch 18840, Loss: 342.5044250488281, Neurons: 11, Grad norm: 2.457e+01\n",
      "Epoch 18841, Loss: 342.2361755371094, Neurons: 11, Grad norm: 2.609e+01\n",
      "Epoch 18842, Loss: 341.9686279296875, Neurons: 11, Grad norm: 2.554e+01\n",
      "Epoch 18843, Loss: 341.7017822265625, Neurons: 11, Grad norm: 2.406e+01\n",
      "Epoch 18844, Loss: 341.4356994628906, Neurons: 11, Grad norm: 2.682e+01\n",
      "Epoch 18845, Loss: 341.1702880859375, Neurons: 11, Grad norm: 2.400e+01\n",
      "Epoch 18846, Loss: 340.9057312011719, Neurons: 11, Grad norm: 2.601e+01\n",
      "Epoch 18847, Loss: 340.6418762207031, Neurons: 11, Grad norm: 2.569e+01\n",
      "Epoch 18848, Loss: 340.3787841796875, Neurons: 11, Grad norm: 2.326e+01\n",
      "Epoch 18849, Loss: 340.1165466308594, Neurons: 11, Grad norm: 2.695e+01\n",
      "Epoch 18849, Test loss: 336.56561279296875\n",
      "Epoch 18850, Loss: 339.8551025390625, Neurons: 11, Grad norm: 2.407e+01\n",
      "Epoch 18851, Loss: 339.5943908691406, Neurons: 11, Grad norm: 2.388e+01\n",
      "Epoch 18852, Loss: 339.3345031738281, Neurons: 11, Grad norm: 2.718e+01\n",
      "Epoch 18853, Loss: 339.075439453125, Neurons: 11, Grad norm: 2.316e+01\n",
      "Epoch 18854, Loss: 338.81719970703125, Neurons: 11, Grad norm: 2.513e+01\n",
      "Epoch 18855, Loss: 338.55975341796875, Neurons: 11, Grad norm: 2.429e+01\n",
      "Epoch 18856, Loss: 338.30316162109375, Neurons: 11, Grad norm: 2.383e+01\n",
      "Epoch 18857, Loss: 338.0473937988281, Neurons: 11, Grad norm: 2.621e+01\n",
      "Epoch 18858, Loss: 337.79241943359375, Neurons: 11, Grad norm: 2.353e+01\n",
      "Epoch 18859, Loss: 337.538330078125, Neurons: 11, Grad norm: 2.358e+01\n",
      "Epoch 18860, Loss: 337.2850036621094, Neurons: 11, Grad norm: 2.545e+01\n",
      "Epoch 18861, Loss: 337.0325622558594, Neurons: 11, Grad norm: 2.315e+01\n",
      "Epoch 18862, Loss: 336.78094482421875, Neurons: 11, Grad norm: 2.487e+01\n",
      "Epoch 18863, Loss: 336.5301818847656, Neurons: 11, Grad norm: 2.429e+01\n",
      "Epoch 18864, Loss: 336.2802429199219, Neurons: 11, Grad norm: 2.301e+01\n",
      "Epoch 18865, Loss: 336.0310974121094, Neurons: 11, Grad norm: 2.469e+01\n",
      "Epoch 18866, Loss: 335.78277587890625, Neurons: 11, Grad norm: 2.289e+01\n",
      "Epoch 18867, Loss: 335.53533935546875, Neurons: 11, Grad norm: 2.460e+01\n",
      "Epoch 18868, Loss: 335.28863525390625, Neurons: 11, Grad norm: 2.465e+01\n",
      "Epoch 18869, Loss: 335.0428466796875, Neurons: 11, Grad norm: 2.267e+01\n",
      "Epoch 18870, Loss: 334.79779052734375, Neurons: 11, Grad norm: 2.411e+01\n",
      "Epoch 18871, Loss: 334.5535888671875, Neurons: 11, Grad norm: 2.314e+01\n",
      "Epoch 18872, Loss: 334.3102111816406, Neurons: 11, Grad norm: 2.371e+01\n",
      "Epoch 18873, Loss: 334.067626953125, Neurons: 11, Grad norm: 2.326e+01\n",
      "Epoch 18874, Loss: 333.8258056640625, Neurons: 11, Grad norm: 2.371e+01\n",
      "Epoch 18875, Loss: 333.58477783203125, Neurons: 11, Grad norm: 2.380e+01\n",
      "Epoch 18876, Loss: 333.34454345703125, Neurons: 11, Grad norm: 2.296e+01\n",
      "Epoch 18877, Loss: 333.1051025390625, Neurons: 11, Grad norm: 2.332e+01\n",
      "Epoch 18878, Loss: 332.8664245605469, Neurons: 11, Grad norm: 2.325e+01\n",
      "Epoch 18879, Loss: 332.62847900390625, Neurons: 11, Grad norm: 2.373e+01\n",
      "Epoch 18880, Loss: 332.3913269042969, Neurons: 11, Grad norm: 2.287e+01\n",
      "Epoch 18881, Loss: 332.1549377441406, Neurons: 11, Grad norm: 2.302e+01\n",
      "Epoch 18882, Loss: 331.9192810058594, Neurons: 11, Grad norm: 2.333e+01\n",
      "Epoch 18883, Loss: 331.684326171875, Neurons: 11, Grad norm: 2.296e+01\n",
      "Epoch 18884, Loss: 331.45013427734375, Neurons: 11, Grad norm: 2.337e+01\n",
      "Epoch 18885, Loss: 331.2165832519531, Neurons: 11, Grad norm: 2.308e+01\n",
      "Epoch 18886, Loss: 330.9838562011719, Neurons: 11, Grad norm: 2.261e+01\n",
      "Epoch 18887, Loss: 330.7517395019531, Neurons: 11, Grad norm: 2.296e+01\n",
      "Epoch 18888, Loss: 330.5203857421875, Neurons: 11, Grad norm: 2.265e+01\n",
      "Epoch 18889, Loss: 330.2897033691406, Neurons: 11, Grad norm: 2.286e+01\n",
      "Epoch 18890, Loss: 330.0596923828125, Neurons: 11, Grad norm: 2.358e+01\n",
      "Epoch 18891, Loss: 329.8303527832031, Neurons: 11, Grad norm: 2.182e+01\n",
      "Epoch 18892, Loss: 329.6016540527344, Neurons: 11, Grad norm: 2.253e+01\n",
      "Epoch 18893, Loss: 329.3736267089844, Neurons: 11, Grad norm: 2.294e+01\n",
      "Epoch 18894, Loss: 329.146240234375, Neurons: 11, Grad norm: 2.239e+01\n",
      "Epoch 18895, Loss: 328.9194641113281, Neurons: 11, Grad norm: 2.404e+01\n",
      "Epoch 18896, Loss: 328.6933288574219, Neurons: 11, Grad norm: 2.173e+01\n",
      "Epoch 18897, Loss: 328.4678039550781, Neurons: 11, Grad norm: 2.194e+01\n",
      "Epoch 18898, Loss: 328.2429504394531, Neurons: 11, Grad norm: 2.312e+01\n",
      "Epoch 18899, Loss: 328.01861572265625, Neurons: 11, Grad norm: 2.249e+01\n",
      "Epoch 18899, Test loss: 324.42303466796875\n",
      "Epoch 18900, Loss: 327.7948913574219, Neurons: 11, Grad norm: 2.243e+01\n",
      "Epoch 18901, Loss: 327.5717468261719, Neurons: 11, Grad norm: 2.257e+01\n",
      "Epoch 18902, Loss: 327.34918212890625, Neurons: 11, Grad norm: 2.187e+01\n",
      "Epoch 18903, Loss: 327.1271667480469, Neurons: 11, Grad norm: 2.308e+01\n",
      "Epoch 18904, Loss: 326.90570068359375, Neurons: 11, Grad norm: 2.188e+01\n",
      "Epoch 18905, Loss: 326.68475341796875, Neurons: 11, Grad norm: 2.210e+01\n",
      "Epoch 18906, Loss: 326.46435546875, Neurons: 11, Grad norm: 2.306e+01\n",
      "Epoch 18907, Loss: 326.2445068359375, Neurons: 11, Grad norm: 2.234e+01\n",
      "Epoch 18908, Loss: 326.025146484375, Neurons: 11, Grad norm: 2.177e+01\n",
      "Epoch 18909, Loss: 325.8062744140625, Neurons: 11, Grad norm: 2.244e+01\n",
      "Epoch 18910, Loss: 325.58782958984375, Neurons: 11, Grad norm: 2.256e+01\n",
      "Epoch 18911, Loss: 325.3697814941406, Neurons: 11, Grad norm: 2.230e+01\n",
      "Epoch 18912, Loss: 325.1520690917969, Neurons: 11, Grad norm: 2.334e+01\n",
      "Epoch 18913, Loss: 324.9346923828125, Neurons: 11, Grad norm: 2.300e+01\n",
      "Epoch 18914, Loss: 324.7176818847656, Neurons: 11, Grad norm: 2.272e+01\n",
      "Epoch 18915, Loss: 324.5010986328125, Neurons: 11, Grad norm: 2.279e+01\n",
      "Epoch 18916, Loss: 324.2848815917969, Neurons: 11, Grad norm: 2.170e+01\n",
      "Epoch 18917, Loss: 324.06915283203125, Neurons: 11, Grad norm: 2.295e+01\n",
      "Epoch 18918, Loss: 323.8538818359375, Neurons: 11, Grad norm: 2.228e+01\n",
      "Epoch 18919, Loss: 323.6391296386719, Neurons: 11, Grad norm: 2.122e+01\n",
      "Epoch 18920, Loss: 323.4248352050781, Neurons: 11, Grad norm: 2.205e+01\n",
      "Epoch 18921, Loss: 323.2109680175781, Neurons: 11, Grad norm: 2.019e+01\n",
      "Epoch 18922, Loss: 322.9975891113281, Neurons: 11, Grad norm: 2.170e+01\n",
      "Epoch 18923, Loss: 322.78460693359375, Neurons: 11, Grad norm: 2.127e+01\n",
      "Epoch 18924, Loss: 322.5720520019531, Neurons: 11, Grad norm: 2.083e+01\n",
      "Epoch 18925, Loss: 322.360107421875, Neurons: 11, Grad norm: 2.181e+01\n",
      "Epoch 18926, Loss: 322.1487121582031, Neurons: 11, Grad norm: 2.056e+01\n",
      "Epoch 18927, Loss: 321.9378967285156, Neurons: 11, Grad norm: 2.073e+01\n",
      "Epoch 18928, Loss: 321.7275695800781, Neurons: 11, Grad norm: 2.117e+01\n",
      "Epoch 18929, Loss: 321.5177917480469, Neurons: 11, Grad norm: 2.121e+01\n",
      "Epoch 18930, Loss: 321.30853271484375, Neurons: 11, Grad norm: 2.058e+01\n",
      "Epoch 18931, Loss: 321.0998229980469, Neurons: 11, Grad norm: 2.039e+01\n",
      "Epoch 18932, Loss: 320.8916320800781, Neurons: 11, Grad norm: 2.043e+01\n",
      "Epoch 18933, Loss: 320.6839904785156, Neurons: 11, Grad norm: 1.916e+01\n",
      "Epoch 18934, Loss: 320.4769287109375, Neurons: 11, Grad norm: 1.995e+01\n",
      "Epoch 18935, Loss: 320.27044677734375, Neurons: 11, Grad norm: 2.068e+01\n",
      "Epoch 18936, Loss: 320.0644836425781, Neurons: 11, Grad norm: 1.893e+01\n",
      "Epoch 18937, Loss: 319.8590393066406, Neurons: 11, Grad norm: 2.052e+01\n",
      "Epoch 18938, Loss: 319.6541442871094, Neurons: 11, Grad norm: 1.976e+01\n",
      "Epoch 18939, Loss: 319.4497985839844, Neurons: 11, Grad norm: 1.922e+01\n",
      "Epoch 18940, Loss: 319.2460021972656, Neurons: 11, Grad norm: 2.147e+01\n",
      "Epoch 18941, Loss: 319.0427551269531, Neurons: 11, Grad norm: 1.944e+01\n",
      "Epoch 18942, Loss: 318.84002685546875, Neurons: 11, Grad norm: 1.987e+01\n",
      "Epoch 18943, Loss: 318.637939453125, Neurons: 11, Grad norm: 2.111e+01\n",
      "Epoch 18944, Loss: 318.43634033203125, Neurons: 11, Grad norm: 1.884e+01\n",
      "Epoch 18945, Loss: 318.23529052734375, Neurons: 11, Grad norm: 2.102e+01\n",
      "Epoch 18946, Loss: 318.0347595214844, Neurons: 11, Grad norm: 2.035e+01\n",
      "Epoch 18947, Loss: 317.83477783203125, Neurons: 11, Grad norm: 1.868e+01\n",
      "Epoch 18948, Loss: 317.6353759765625, Neurons: 11, Grad norm: 2.063e+01\n",
      "Epoch 18949, Loss: 317.4365234375, Neurons: 11, Grad norm: 1.894e+01\n",
      "Epoch 18949, Test loss: 313.82470703125\n",
      "Epoch 18950, Loss: 317.2381286621094, Neurons: 11, Grad norm: 2.046e+01\n",
      "Epoch 18951, Loss: 317.04034423828125, Neurons: 11, Grad norm: 2.057e+01\n",
      "Epoch 18952, Loss: 316.843017578125, Neurons: 11, Grad norm: 1.878e+01\n",
      "Epoch 18953, Loss: 316.64630126953125, Neurons: 11, Grad norm: 2.040e+01\n",
      "Epoch 18954, Loss: 316.4500427246094, Neurons: 11, Grad norm: 1.981e+01\n",
      "Epoch 18955, Loss: 316.25433349609375, Neurons: 11, Grad norm: 1.947e+01\n",
      "Epoch 18956, Loss: 316.05914306640625, Neurons: 11, Grad norm: 2.091e+01\n",
      "Epoch 18957, Loss: 315.864501953125, Neurons: 11, Grad norm: 1.935e+01\n",
      "Epoch 18958, Loss: 315.67034912109375, Neurons: 11, Grad norm: 1.917e+01\n",
      "Epoch 18959, Loss: 315.4766845703125, Neurons: 11, Grad norm: 2.004e+01\n",
      "Epoch 18960, Loss: 315.2835388183594, Neurons: 11, Grad norm: 1.903e+01\n",
      "Epoch 18961, Loss: 315.0909423828125, Neurons: 11, Grad norm: 1.988e+01\n",
      "Epoch 18962, Loss: 314.8988037109375, Neurons: 11, Grad norm: 1.978e+01\n",
      "Epoch 18963, Loss: 314.7071838378906, Neurons: 11, Grad norm: 1.880e+01\n",
      "Epoch 18964, Loss: 314.51605224609375, Neurons: 11, Grad norm: 1.962e+01\n",
      "Epoch 18965, Loss: 314.325439453125, Neurons: 11, Grad norm: 1.940e+01\n",
      "Epoch 18966, Loss: 314.1352844238281, Neurons: 11, Grad norm: 1.951e+01\n",
      "Epoch 18967, Loss: 313.9456481933594, Neurons: 11, Grad norm: 1.932e+01\n",
      "Epoch 18968, Loss: 313.7564697265625, Neurons: 11, Grad norm: 1.902e+01\n",
      "Epoch 18969, Loss: 313.56781005859375, Neurons: 11, Grad norm: 1.921e+01\n",
      "Epoch 18970, Loss: 313.37957763671875, Neurons: 11, Grad norm: 1.932e+01\n",
      "Epoch 18971, Loss: 313.19183349609375, Neurons: 11, Grad norm: 1.910e+01\n",
      "Epoch 18972, Loss: 313.00457763671875, Neurons: 11, Grad norm: 1.899e+01\n",
      "Epoch 18973, Loss: 312.8177795410156, Neurons: 11, Grad norm: 1.886e+01\n",
      "Epoch 18974, Loss: 312.6314392089844, Neurons: 11, Grad norm: 1.877e+01\n",
      "Epoch 18975, Loss: 312.445556640625, Neurons: 11, Grad norm: 1.907e+01\n",
      "Epoch 18976, Loss: 312.2601318359375, Neurons: 11, Grad norm: 1.935e+01\n",
      "Epoch 18977, Loss: 312.07513427734375, Neurons: 11, Grad norm: 1.840e+01\n",
      "Epoch 18978, Loss: 311.890625, Neurons: 11, Grad norm: 1.883e+01\n",
      "Epoch 18979, Loss: 311.70654296875, Neurons: 11, Grad norm: 1.891e+01\n",
      "Epoch 18980, Loss: 311.52288818359375, Neurons: 11, Grad norm: 1.871e+01\n",
      "Epoch 18981, Loss: 311.3396911621094, Neurons: 11, Grad norm: 1.900e+01\n",
      "Epoch 18982, Loss: 311.1568908691406, Neurons: 11, Grad norm: 1.867e+01\n",
      "Epoch 18983, Loss: 310.97454833984375, Neurons: 11, Grad norm: 1.840e+01\n",
      "Epoch 18984, Loss: 310.7926025390625, Neurons: 11, Grad norm: 1.904e+01\n",
      "Epoch 18985, Loss: 310.611083984375, Neurons: 11, Grad norm: 1.822e+01\n",
      "Epoch 18986, Loss: 310.42999267578125, Neurons: 11, Grad norm: 1.854e+01\n",
      "Epoch 18987, Loss: 310.24932861328125, Neurons: 11, Grad norm: 1.908e+01\n",
      "Epoch 18988, Loss: 310.0690612792969, Neurons: 11, Grad norm: 1.821e+01\n",
      "Epoch 18989, Loss: 309.88922119140625, Neurons: 11, Grad norm: 1.871e+01\n",
      "Epoch 18990, Loss: 309.709716796875, Neurons: 11, Grad norm: 1.857e+01\n",
      "Epoch 18991, Loss: 309.5306701660156, Neurons: 11, Grad norm: 1.809e+01\n",
      "Epoch 18992, Loss: 309.3520202636719, Neurons: 11, Grad norm: 1.924e+01\n",
      "Epoch 18993, Loss: 309.1737060546875, Neurons: 11, Grad norm: 1.809e+01\n",
      "Epoch 18994, Loss: 308.995849609375, Neurons: 11, Grad norm: 1.814e+01\n",
      "Epoch 18995, Loss: 308.8183288574219, Neurons: 11, Grad norm: 1.889e+01\n",
      "Epoch 18996, Loss: 308.64117431640625, Neurons: 11, Grad norm: 1.797e+01\n",
      "Epoch 18997, Loss: 308.46441650390625, Neurons: 11, Grad norm: 1.855e+01\n",
      "Epoch 18998, Loss: 308.2880554199219, Neurons: 11, Grad norm: 1.842e+01\n",
      "Epoch 18999, Loss: 308.1120300292969, Neurons: 11, Grad norm: 1.800e+01\n",
      "Epoch 18999, Test loss: 304.56903076171875\n",
      "Epoch 19000, Loss: 307.9363708496094, Neurons: 11, Grad norm: 1.903e+01\n",
      "Epoch 19001, Loss: 307.76104736328125, Neurons: 11, Grad norm: 1.776e+01\n",
      "Epoch 19002, Loss: 307.5860900878906, Neurons: 11, Grad norm: 1.801e+01\n",
      "Epoch 19003, Loss: 307.4115295410156, Neurons: 11, Grad norm: 1.890e+01\n",
      "Epoch 19004, Loss: 307.2373046875, Neurons: 11, Grad norm: 1.782e+01\n",
      "Epoch 19005, Loss: 307.06341552734375, Neurons: 11, Grad norm: 1.829e+01\n",
      "Epoch 19006, Loss: 306.889892578125, Neurons: 11, Grad norm: 1.821e+01\n",
      "Epoch 19007, Loss: 306.7166748046875, Neurons: 11, Grad norm: 1.764e+01\n",
      "Epoch 19008, Loss: 306.5437316894531, Neurons: 11, Grad norm: 1.836e+01\n",
      "Epoch 19009, Loss: 306.3712463378906, Neurons: 11, Grad norm: 1.862e+01\n",
      "Epoch 19010, Loss: 306.1990051269531, Neurons: 11, Grad norm: 1.752e+01\n",
      "Epoch 19011, Loss: 306.0271301269531, Neurons: 11, Grad norm: 1.819e+01\n",
      "Epoch 19012, Loss: 305.8555908203125, Neurons: 11, Grad norm: 1.818e+01\n",
      "Epoch 19013, Loss: 305.6843566894531, Neurons: 11, Grad norm: 1.779e+01\n",
      "Epoch 19014, Loss: 305.5133972167969, Neurons: 11, Grad norm: 1.840e+01\n",
      "Epoch 19015, Loss: 305.3428039550781, Neurons: 11, Grad norm: 1.769e+01\n",
      "Epoch 19016, Loss: 305.1724548339844, Neurons: 11, Grad norm: 1.753e+01\n",
      "Epoch 19017, Loss: 305.00244140625, Neurons: 11, Grad norm: 1.820e+01\n",
      "Epoch 19018, Loss: 304.83270263671875, Neurons: 11, Grad norm: 1.779e+01\n",
      "Epoch 19019, Loss: 304.6632995605469, Neurons: 11, Grad norm: 1.848e+01\n",
      "Epoch 19020, Loss: 304.49420166015625, Neurons: 11, Grad norm: 1.767e+01\n",
      "Epoch 19021, Loss: 304.32537841796875, Neurons: 11, Grad norm: 1.748e+01\n",
      "Epoch 19022, Loss: 304.1568298339844, Neurons: 11, Grad norm: 1.818e+01\n",
      "Epoch 19023, Loss: 303.98858642578125, Neurons: 11, Grad norm: 1.776e+01\n",
      "Epoch 19024, Loss: 303.82061767578125, Neurons: 11, Grad norm: 1.799e+01\n",
      "Epoch 19025, Loss: 303.6529541015625, Neurons: 11, Grad norm: 1.776e+01\n",
      "Epoch 19026, Loss: 303.4855041503906, Neurons: 11, Grad norm: 1.744e+01\n",
      "Epoch 19027, Loss: 303.318359375, Neurons: 11, Grad norm: 1.761e+01\n",
      "Epoch 19028, Loss: 303.1515197753906, Neurons: 11, Grad norm: 1.786e+01\n",
      "Epoch 19029, Loss: 302.9849548339844, Neurons: 11, Grad norm: 1.762e+01\n",
      "Epoch 19030, Loss: 302.818603515625, Neurons: 11, Grad norm: 1.788e+01\n",
      "Epoch 19031, Loss: 302.6524963378906, Neurons: 11, Grad norm: 1.807e+01\n",
      "Epoch 19032, Loss: 302.4866638183594, Neurons: 11, Grad norm: 1.715e+01\n",
      "Epoch 19033, Loss: 302.3211364746094, Neurons: 11, Grad norm: 1.764e+01\n",
      "Epoch 19034, Loss: 302.1557922363281, Neurons: 11, Grad norm: 1.753e+01\n",
      "Epoch 19035, Loss: 301.9907531738281, Neurons: 11, Grad norm: 1.795e+01\n",
      "Epoch 19036, Loss: 301.825927734375, Neurons: 11, Grad norm: 1.817e+01\n",
      "Epoch 19037, Loss: 301.661376953125, Neurons: 11, Grad norm: 1.734e+01\n",
      "Epoch 19038, Loss: 301.4970397949219, Neurons: 11, Grad norm: 1.695e+01\n",
      "Epoch 19039, Loss: 301.33294677734375, Neurons: 11, Grad norm: 1.739e+01\n",
      "Epoch 19040, Loss: 301.1690673828125, Neurons: 11, Grad norm: 1.804e+01\n",
      "Epoch 19041, Loss: 301.00543212890625, Neurons: 11, Grad norm: 1.789e+01\n",
      "Epoch 19042, Loss: 300.842041015625, Neurons: 11, Grad norm: 1.765e+01\n",
      "Epoch 19043, Loss: 300.6788330078125, Neurons: 11, Grad norm: 1.729e+01\n",
      "Epoch 19044, Loss: 300.51593017578125, Neurons: 11, Grad norm: 1.698e+01\n",
      "Epoch 19045, Loss: 300.3531799316406, Neurons: 11, Grad norm: 1.788e+01\n",
      "Epoch 19046, Loss: 300.1907043457031, Neurons: 11, Grad norm: 1.772e+01\n",
      "Epoch 19047, Loss: 300.0284118652344, Neurons: 11, Grad norm: 1.749e+01\n",
      "Epoch 19048, Loss: 299.8663330078125, Neurons: 11, Grad norm: 1.748e+01\n",
      "Epoch 19049, Loss: 299.7044982910156, Neurons: 11, Grad norm: 1.714e+01\n",
      "Epoch 19049, Test loss: 296.2267761230469\n",
      "Epoch 19050, Loss: 299.5428161621094, Neurons: 11, Grad norm: 1.729e+01\n",
      "Epoch 19051, Loss: 299.3813781738281, Neurons: 11, Grad norm: 1.771e+01\n",
      "Epoch 19052, Loss: 299.22015380859375, Neurons: 11, Grad norm: 1.739e+01\n",
      "Epoch 19053, Loss: 299.05908203125, Neurons: 11, Grad norm: 1.758e+01\n",
      "Epoch 19054, Loss: 298.89825439453125, Neurons: 11, Grad norm: 1.743e+01\n",
      "Epoch 19055, Loss: 298.7375793457031, Neurons: 11, Grad norm: 1.699e+01\n",
      "Epoch 19056, Loss: 298.5771179199219, Neurons: 11, Grad norm: 1.760e+01\n",
      "Epoch 19057, Loss: 298.4168395996094, Neurons: 11, Grad norm: 1.754e+01\n",
      "Epoch 19058, Loss: 298.2568054199219, Neurons: 11, Grad norm: 1.716e+01\n",
      "Epoch 19059, Loss: 298.0969543457031, Neurons: 11, Grad norm: 1.769e+01\n",
      "Epoch 19060, Loss: 297.9372253417969, Neurons: 11, Grad norm: 1.707e+01\n",
      "Epoch 19061, Loss: 297.77764892578125, Neurons: 11, Grad norm: 1.726e+01\n",
      "Epoch 19062, Loss: 297.61834716796875, Neurons: 11, Grad norm: 1.754e+01\n",
      "Epoch 19063, Loss: 297.4591979980469, Neurons: 11, Grad norm: 1.730e+01\n",
      "Epoch 19064, Loss: 297.3002014160156, Neurons: 11, Grad norm: 1.717e+01\n",
      "Epoch 19065, Loss: 297.1413879394531, Neurons: 11, Grad norm: 1.725e+01\n",
      "Epoch 19066, Loss: 296.9827575683594, Neurons: 11, Grad norm: 1.752e+01\n",
      "Epoch 19067, Loss: 296.8242492675781, Neurons: 11, Grad norm: 1.697e+01\n",
      "Epoch 19068, Loss: 296.66595458984375, Neurons: 11, Grad norm: 1.785e+01\n",
      "Epoch 19069, Loss: 296.5077819824219, Neurons: 11, Grad norm: 1.717e+01\n",
      "Epoch 19070, Loss: 296.3498229980469, Neurons: 11, Grad norm: 1.671e+01\n",
      "Epoch 19071, Loss: 296.1919860839844, Neurons: 11, Grad norm: 1.789e+01\n",
      "Epoch 19072, Loss: 296.0343322753906, Neurons: 11, Grad norm: 1.722e+01\n",
      "Epoch 19073, Loss: 295.8768005371094, Neurons: 11, Grad norm: 1.711e+01\n",
      "Epoch 19074, Loss: 295.7194519042969, Neurons: 11, Grad norm: 1.748e+01\n",
      "Epoch 19075, Loss: 295.56219482421875, Neurons: 11, Grad norm: 1.683e+01\n",
      "Epoch 19076, Loss: 295.4051818847656, Neurons: 11, Grad norm: 1.723e+01\n",
      "Epoch 19077, Loss: 295.2482604980469, Neurons: 11, Grad norm: 1.770e+01\n",
      "Epoch 19078, Loss: 295.09149169921875, Neurons: 11, Grad norm: 1.713e+01\n",
      "Epoch 19079, Loss: 294.93487548828125, Neurons: 11, Grad norm: 1.741e+01\n",
      "Epoch 19080, Loss: 294.77838134765625, Neurons: 11, Grad norm: 1.728e+01\n",
      "Epoch 19081, Loss: 294.6220397949219, Neurons: 11, Grad norm: 1.680e+01\n",
      "Epoch 19082, Loss: 294.4658508300781, Neurons: 11, Grad norm: 1.725e+01\n",
      "Epoch 19083, Loss: 294.3097839355469, Neurons: 11, Grad norm: 1.748e+01\n",
      "Epoch 19084, Loss: 294.1538391113281, Neurons: 11, Grad norm: 1.715e+01\n",
      "Epoch 19085, Loss: 293.998046875, Neurons: 11, Grad norm: 1.713e+01\n",
      "Epoch 19086, Loss: 293.8424072265625, Neurons: 11, Grad norm: 1.724e+01\n",
      "Epoch 19087, Loss: 293.68682861328125, Neurons: 11, Grad norm: 1.709e+01\n",
      "Epoch 19088, Loss: 293.53143310546875, Neurons: 11, Grad norm: 1.733e+01\n",
      "Epoch 19089, Loss: 293.3761291503906, Neurons: 11, Grad norm: 1.761e+01\n",
      "Epoch 19090, Loss: 293.2209777832031, Neurons: 11, Grad norm: 1.716e+01\n",
      "Epoch 19091, Loss: 293.0659484863281, Neurons: 11, Grad norm: 1.715e+01\n",
      "Epoch 19092, Loss: 292.9110107421875, Neurons: 11, Grad norm: 1.674e+01\n",
      "Epoch 19093, Loss: 292.7561950683594, Neurons: 11, Grad norm: 1.727e+01\n",
      "Epoch 19094, Loss: 292.6015319824219, Neurons: 11, Grad norm: 1.749e+01\n",
      "Epoch 19095, Loss: 292.4469299316406, Neurons: 11, Grad norm: 1.722e+01\n",
      "Epoch 19096, Loss: 292.2925109863281, Neurons: 11, Grad norm: 1.729e+01\n",
      "Epoch 19097, Loss: 292.1381530761719, Neurons: 11, Grad norm: 1.694e+01\n",
      "Epoch 19098, Loss: 291.98388671875, Neurons: 11, Grad norm: 1.709e+01\n",
      "Epoch 19099, Loss: 291.82977294921875, Neurons: 11, Grad norm: 1.773e+01\n",
      "Epoch 19099, Test loss: 288.4305114746094\n",
      "Epoch 19100, Loss: 291.6757507324219, Neurons: 11, Grad norm: 1.735e+01\n",
      "Epoch 19101, Loss: 291.5218811035156, Neurons: 11, Grad norm: 1.714e+01\n",
      "Epoch 19102, Loss: 291.3680114746094, Neurons: 11, Grad norm: 1.692e+01\n",
      "Epoch 19103, Loss: 291.21435546875, Neurons: 11, Grad norm: 1.714e+01\n",
      "Epoch 19104, Loss: 291.06072998046875, Neurons: 11, Grad norm: 1.727e+01\n",
      "Epoch 19105, Loss: 290.9071960449219, Neurons: 11, Grad norm: 1.742e+01\n",
      "Epoch 19106, Loss: 290.7537841796875, Neurons: 11, Grad norm: 1.728e+01\n",
      "Epoch 19107, Loss: 290.6004638671875, Neurons: 11, Grad norm: 1.698e+01\n",
      "Epoch 19108, Loss: 290.447265625, Neurons: 11, Grad norm: 1.703e+01\n",
      "Epoch 19109, Loss: 290.29412841796875, Neurons: 11, Grad norm: 1.719e+01\n",
      "Epoch 19110, Loss: 290.1410827636719, Neurons: 11, Grad norm: 1.748e+01\n",
      "Epoch 19111, Loss: 289.9881286621094, Neurons: 11, Grad norm: 1.766e+01\n",
      "Epoch 19112, Loss: 289.8353271484375, Neurons: 11, Grad norm: 1.700e+01\n",
      "Epoch 19113, Loss: 289.68255615234375, Neurons: 11, Grad norm: 1.707e+01\n",
      "Epoch 19114, Loss: 289.52984619140625, Neurons: 11, Grad norm: 1.730e+01\n",
      "Epoch 19115, Loss: 289.3772277832031, Neurons: 11, Grad norm: 1.694e+01\n",
      "Epoch 19116, Loss: 289.2247314453125, Neurons: 11, Grad norm: 1.778e+01\n",
      "Epoch 19117, Loss: 289.0722961425781, Neurons: 11, Grad norm: 1.734e+01\n",
      "Epoch 19118, Loss: 288.9199523925781, Neurons: 11, Grad norm: 1.680e+01\n",
      "Epoch 19119, Loss: 288.7677001953125, Neurons: 11, Grad norm: 1.752e+01\n",
      "Epoch 19120, Loss: 288.615478515625, Neurons: 11, Grad norm: 1.697e+01\n",
      "Epoch 19121, Loss: 288.46337890625, Neurons: 11, Grad norm: 1.706e+01\n",
      "Epoch 19122, Loss: 288.3113098144531, Neurons: 11, Grad norm: 1.823e+01\n",
      "Epoch 19123, Loss: 288.1593322753906, Neurons: 11, Grad norm: 1.729e+01\n",
      "Epoch 19124, Loss: 288.0074768066406, Neurons: 11, Grad norm: 1.694e+01\n",
      "Epoch 19125, Loss: 287.8556213378906, Neurons: 11, Grad norm: 1.734e+01\n",
      "Epoch 19126, Loss: 287.7038879394531, Neurons: 11, Grad norm: 1.689e+01\n",
      "Epoch 19127, Loss: 287.55218505859375, Neurons: 11, Grad norm: 1.762e+01\n",
      "Epoch 19128, Loss: 287.4005432128906, Neurons: 11, Grad norm: 1.797e+01\n",
      "Epoch 19129, Loss: 287.2490234375, Neurons: 11, Grad norm: 1.709e+01\n",
      "Epoch 19130, Loss: 287.0975036621094, Neurons: 11, Grad norm: 1.702e+01\n",
      "Epoch 19131, Loss: 286.94610595703125, Neurons: 11, Grad norm: 1.703e+01\n",
      "Epoch 19132, Loss: 286.7947082519531, Neurons: 11, Grad norm: 1.740e+01\n",
      "Epoch 19133, Loss: 286.6434326171875, Neurons: 11, Grad norm: 1.807e+01\n",
      "Epoch 19134, Loss: 286.4921875, Neurons: 11, Grad norm: 1.730e+01\n",
      "Epoch 19135, Loss: 286.34100341796875, Neurons: 11, Grad norm: 1.713e+01\n",
      "Epoch 19136, Loss: 286.18988037109375, Neurons: 11, Grad norm: 1.723e+01\n",
      "Epoch 19137, Loss: 286.038818359375, Neurons: 11, Grad norm: 1.702e+01\n",
      "Epoch 19138, Loss: 285.8878479003906, Neurons: 11, Grad norm: 1.801e+01\n",
      "Epoch 19139, Loss: 285.7369079589844, Neurons: 11, Grad norm: 1.801e+01\n",
      "Epoch 19140, Loss: 285.5859680175781, Neurons: 11, Grad norm: 1.700e+01\n",
      "Epoch 19141, Loss: 285.4351501464844, Neurons: 11, Grad norm: 1.724e+01\n",
      "Epoch 19142, Loss: 285.2843322753906, Neurons: 11, Grad norm: 1.707e+01\n",
      "Epoch 19143, Loss: 285.13360595703125, Neurons: 11, Grad norm: 1.756e+01\n",
      "Epoch 19144, Loss: 284.98291015625, Neurons: 11, Grad norm: 1.830e+01\n",
      "Epoch 19145, Loss: 284.8322448730469, Neurons: 11, Grad norm: 1.727e+01\n",
      "Epoch 19146, Loss: 284.68170166015625, Neurons: 11, Grad norm: 1.714e+01\n",
      "Epoch 19147, Loss: 284.5311279296875, Neurons: 11, Grad norm: 1.734e+01\n",
      "Epoch 19148, Loss: 284.380615234375, Neurons: 11, Grad norm: 1.741e+01\n",
      "Epoch 19149, Loss: 284.23016357421875, Neurons: 11, Grad norm: 1.788e+01\n",
      "Epoch 19149, Test loss: 280.9176940917969\n",
      "Epoch 19150, Loss: 284.0797424316406, Neurons: 11, Grad norm: 1.791e+01\n",
      "Epoch 19151, Loss: 283.92938232421875, Neurons: 11, Grad norm: 1.693e+01\n",
      "Epoch 19152, Loss: 283.779052734375, Neurons: 11, Grad norm: 1.781e+01\n",
      "Epoch 19153, Loss: 283.6287536621094, Neurons: 11, Grad norm: 1.736e+01\n",
      "Epoch 19154, Loss: 283.478515625, Neurons: 11, Grad norm: 1.740e+01\n",
      "Epoch 19155, Loss: 283.3283386230469, Neurons: 11, Grad norm: 1.788e+01\n",
      "Epoch 19156, Loss: 283.1781311035156, Neurons: 11, Grad norm: 1.747e+01\n",
      "Epoch 19157, Loss: 283.0280456542969, Neurons: 11, Grad norm: 1.769e+01\n",
      "Epoch 19158, Loss: 282.8779296875, Neurons: 11, Grad norm: 1.762e+01\n",
      "Epoch 19159, Loss: 282.7278747558594, Neurons: 11, Grad norm: 1.720e+01\n",
      "Epoch 19160, Loss: 282.5778503417969, Neurons: 11, Grad norm: 1.796e+01\n",
      "Epoch 19161, Loss: 282.4278564453125, Neurons: 11, Grad norm: 1.783e+01\n",
      "Epoch 19162, Loss: 282.2778625488281, Neurons: 11, Grad norm: 1.734e+01\n",
      "Epoch 19163, Loss: 282.1279296875, Neurons: 11, Grad norm: 1.765e+01\n",
      "Epoch 19164, Loss: 281.9780578613281, Neurons: 11, Grad norm: 1.766e+01\n",
      "Epoch 19165, Loss: 281.82818603515625, Neurons: 11, Grad norm: 1.762e+01\n",
      "Epoch 19166, Loss: 281.6783447265625, Neurons: 11, Grad norm: 1.786e+01\n",
      "Epoch 19167, Loss: 281.5285339355469, Neurons: 11, Grad norm: 1.777e+01\n",
      "Epoch 19168, Loss: 281.3787841796875, Neurons: 11, Grad norm: 1.750e+01\n",
      "Epoch 19169, Loss: 281.22900390625, Neurons: 11, Grad norm: 1.794e+01\n",
      "Epoch 19170, Loss: 281.07928466796875, Neurons: 11, Grad norm: 1.770e+01\n",
      "Epoch 19171, Loss: 280.9295959472656, Neurons: 11, Grad norm: 1.742e+01\n",
      "Epoch 19172, Loss: 280.7799072265625, Neurons: 11, Grad norm: 1.815e+01\n",
      "Epoch 19173, Loss: 280.6302795410156, Neurons: 11, Grad norm: 1.770e+01\n",
      "Epoch 19174, Loss: 280.48065185546875, Neurons: 11, Grad norm: 1.776e+01\n",
      "Epoch 19175, Loss: 280.3310546875, Neurons: 11, Grad norm: 1.806e+01\n",
      "Epoch 19176, Loss: 280.18145751953125, Neurons: 11, Grad norm: 1.747e+01\n",
      "Epoch 19177, Loss: 280.0318908691406, Neurons: 11, Grad norm: 1.798e+01\n",
      "Epoch 19178, Loss: 279.88238525390625, Neurons: 11, Grad norm: 1.825e+01\n",
      "Epoch 19179, Loss: 279.73284912109375, Neurons: 11, Grad norm: 1.749e+01\n",
      "Epoch 19180, Loss: 279.5833435058594, Neurons: 11, Grad norm: 1.817e+01\n",
      "Epoch 19181, Loss: 279.433837890625, Neurons: 11, Grad norm: 1.796e+01\n",
      "Epoch 19182, Loss: 279.2843933105469, Neurons: 11, Grad norm: 1.748e+01\n",
      "Epoch 19183, Loss: 279.13494873046875, Neurons: 11, Grad norm: 1.842e+01\n",
      "Epoch 19184, Loss: 278.9855041503906, Neurons: 11, Grad norm: 1.787e+01\n",
      "Epoch 19185, Loss: 278.8360900878906, Neurons: 11, Grad norm: 1.785e+01\n",
      "Epoch 19186, Loss: 278.68670654296875, Neurons: 11, Grad norm: 1.856e+01\n",
      "Epoch 19187, Loss: 278.53729248046875, Neurons: 11, Grad norm: 1.752e+01\n",
      "Epoch 19188, Loss: 278.387939453125, Neurons: 11, Grad norm: 1.803e+01\n",
      "Epoch 19189, Loss: 278.2385559082031, Neurons: 11, Grad norm: 1.833e+01\n",
      "Epoch 19190, Loss: 278.0892028808594, Neurons: 11, Grad norm: 1.778e+01\n",
      "Epoch 19191, Loss: 277.93988037109375, Neurons: 11, Grad norm: 1.814e+01\n",
      "Epoch 19192, Loss: 277.7905578613281, Neurons: 11, Grad norm: 1.847e+01\n",
      "Epoch 19193, Loss: 277.6412658691406, Neurons: 11, Grad norm: 1.791e+01\n",
      "Epoch 19194, Loss: 277.49200439453125, Neurons: 11, Grad norm: 1.803e+01\n",
      "Epoch 19195, Loss: 277.3426818847656, Neurons: 11, Grad norm: 1.813e+01\n",
      "Epoch 19196, Loss: 277.1933898925781, Neurons: 11, Grad norm: 1.813e+01\n",
      "Epoch 19197, Loss: 277.04412841796875, Neurons: 11, Grad norm: 1.827e+01\n",
      "Epoch 19198, Loss: 276.8948974609375, Neurons: 11, Grad norm: 1.817e+01\n",
      "Epoch 19199, Loss: 276.74560546875, Neurons: 11, Grad norm: 1.822e+01\n",
      "Epoch 19199, Test loss: 273.5210266113281\n",
      "Epoch 19200, Loss: 276.5963439941406, Neurons: 11, Grad norm: 1.814e+01\n",
      "Epoch 19201, Loss: 276.4471130371094, Neurons: 11, Grad norm: 1.820e+01\n",
      "Epoch 19202, Loss: 276.2978820800781, Neurons: 11, Grad norm: 1.811e+01\n",
      "Epoch 19203, Loss: 276.1486511230469, Neurons: 11, Grad norm: 1.860e+01\n",
      "Epoch 19204, Loss: 275.99945068359375, Neurons: 11, Grad norm: 1.837e+01\n",
      "Epoch 19205, Loss: 275.8501892089844, Neurons: 11, Grad norm: 1.825e+01\n",
      "Epoch 19206, Loss: 275.70098876953125, Neurons: 11, Grad norm: 1.819e+01\n",
      "Epoch 19207, Loss: 275.5517883300781, Neurons: 11, Grad norm: 1.843e+01\n",
      "Epoch 19208, Loss: 275.4025573730469, Neurons: 11, Grad norm: 1.844e+01\n",
      "Epoch 19209, Loss: 275.25335693359375, Neurons: 11, Grad norm: 1.818e+01\n",
      "Epoch 19210, Loss: 275.1041564941406, Neurons: 11, Grad norm: 1.872e+01\n",
      "Epoch 19211, Loss: 274.9549560546875, Neurons: 11, Grad norm: 1.831e+01\n",
      "Epoch 19212, Loss: 274.8057556152344, Neurons: 11, Grad norm: 1.833e+01\n",
      "Epoch 19213, Loss: 274.65655517578125, Neurons: 11, Grad norm: 1.845e+01\n",
      "Epoch 19214, Loss: 274.5073547363281, Neurons: 11, Grad norm: 1.859e+01\n",
      "Epoch 19215, Loss: 274.358154296875, Neurons: 11, Grad norm: 1.856e+01\n",
      "Epoch 19216, Loss: 274.2089538574219, Neurons: 11, Grad norm: 1.860e+01\n",
      "Epoch 19217, Loss: 274.05975341796875, Neurons: 11, Grad norm: 1.828e+01\n",
      "Epoch 19218, Loss: 273.9105529785156, Neurons: 11, Grad norm: 1.873e+01\n",
      "Epoch 19219, Loss: 273.7613830566406, Neurons: 11, Grad norm: 1.864e+01\n",
      "Epoch 19220, Loss: 273.6121520996094, Neurons: 11, Grad norm: 1.858e+01\n",
      "Epoch 19221, Loss: 273.4629821777344, Neurons: 11, Grad norm: 1.857e+01\n",
      "Epoch 19222, Loss: 273.31378173828125, Neurons: 11, Grad norm: 1.875e+01\n",
      "Epoch 19223, Loss: 273.16455078125, Neurons: 11, Grad norm: 1.857e+01\n",
      "Epoch 19224, Loss: 273.0153503417969, Neurons: 11, Grad norm: 1.874e+01\n",
      "Epoch 19225, Loss: 272.8661193847656, Neurons: 11, Grad norm: 1.860e+01\n",
      "Epoch 19226, Loss: 272.7168884277344, Neurons: 11, Grad norm: 1.878e+01\n",
      "Epoch 19227, Loss: 272.56768798828125, Neurons: 11, Grad norm: 1.899e+01\n",
      "Epoch 19228, Loss: 272.4184875488281, Neurons: 11, Grad norm: 1.849e+01\n",
      "Epoch 19229, Loss: 272.2692565917969, Neurons: 11, Grad norm: 1.899e+01\n",
      "Epoch 19230, Loss: 272.1200256347656, Neurons: 11, Grad norm: 1.884e+01\n",
      "Epoch 19231, Loss: 271.97076416015625, Neurons: 11, Grad norm: 1.857e+01\n",
      "Epoch 19232, Loss: 271.821533203125, Neurons: 11, Grad norm: 1.915e+01\n",
      "Epoch 19233, Loss: 271.6722717285156, Neurons: 11, Grad norm: 1.884e+01\n",
      "Epoch 19234, Loss: 271.5230407714844, Neurons: 11, Grad norm: 1.891e+01\n",
      "Epoch 19235, Loss: 271.373779296875, Neurons: 11, Grad norm: 1.899e+01\n",
      "Epoch 19236, Loss: 271.2245178222656, Neurons: 11, Grad norm: 1.864e+01\n",
      "Epoch 19237, Loss: 271.07525634765625, Neurons: 11, Grad norm: 1.925e+01\n",
      "Epoch 19238, Loss: 270.9259338378906, Neurons: 11, Grad norm: 1.911e+01\n",
      "Epoch 19239, Loss: 270.7767028808594, Neurons: 11, Grad norm: 1.882e+01\n",
      "Epoch 19240, Loss: 270.6274108886719, Neurons: 11, Grad norm: 1.922e+01\n",
      "Epoch 19241, Loss: 270.47808837890625, Neurons: 11, Grad norm: 1.888e+01\n",
      "Epoch 19242, Loss: 270.32879638671875, Neurons: 11, Grad norm: 1.902e+01\n",
      "Epoch 19243, Loss: 270.17950439453125, Neurons: 11, Grad norm: 1.910e+01\n",
      "Epoch 19244, Loss: 270.0301513671875, Neurons: 11, Grad norm: 1.913e+01\n",
      "Epoch 19245, Loss: 269.8808288574219, Neurons: 11, Grad norm: 1.928e+01\n",
      "Epoch 19246, Loss: 269.73150634765625, Neurons: 11, Grad norm: 1.922e+01\n",
      "Epoch 19247, Loss: 269.5821838378906, Neurons: 11, Grad norm: 1.895e+01\n",
      "Epoch 19248, Loss: 269.4328308105469, Neurons: 11, Grad norm: 1.935e+01\n",
      "Epoch 19249, Loss: 269.2834777832031, Neurons: 11, Grad norm: 1.931e+01\n",
      "Epoch 19249, Test loss: 266.14190673828125\n",
      "Epoch 19250, Loss: 269.13409423828125, Neurons: 11, Grad norm: 1.925e+01\n",
      "Epoch 19251, Loss: 268.9847412109375, Neurons: 11, Grad norm: 1.923e+01\n",
      "Epoch 19252, Loss: 268.8353576660156, Neurons: 11, Grad norm: 1.932e+01\n",
      "Epoch 19253, Loss: 268.68597412109375, Neurons: 11, Grad norm: 1.921e+01\n",
      "Epoch 19254, Loss: 268.5365295410156, Neurons: 11, Grad norm: 1.932e+01\n",
      "Epoch 19255, Loss: 268.38714599609375, Neurons: 11, Grad norm: 1.934e+01\n",
      "Epoch 19256, Loss: 268.23773193359375, Neurons: 11, Grad norm: 1.955e+01\n",
      "Epoch 19257, Loss: 268.08831787109375, Neurons: 11, Grad norm: 1.940e+01\n",
      "Epoch 19258, Loss: 267.93890380859375, Neurons: 11, Grad norm: 1.932e+01\n",
      "Epoch 19259, Loss: 267.7894287109375, Neurons: 11, Grad norm: 1.942e+01\n",
      "Epoch 19260, Loss: 267.6399841308594, Neurons: 11, Grad norm: 1.952e+01\n",
      "Epoch 19261, Loss: 267.49053955078125, Neurons: 11, Grad norm: 1.970e+01\n",
      "Epoch 19262, Loss: 267.341064453125, Neurons: 11, Grad norm: 1.946e+01\n",
      "Epoch 19263, Loss: 267.19158935546875, Neurons: 11, Grad norm: 1.942e+01\n",
      "Epoch 19264, Loss: 267.0420837402344, Neurons: 11, Grad norm: 1.961e+01\n",
      "Epoch 19265, Loss: 266.89263916015625, Neurons: 11, Grad norm: 1.963e+01\n",
      "Epoch 19266, Loss: 266.74310302734375, Neurons: 11, Grad norm: 1.953e+01\n",
      "Epoch 19267, Loss: 266.5935974121094, Neurons: 11, Grad norm: 1.963e+01\n",
      "Epoch 19268, Loss: 266.444091796875, Neurons: 11, Grad norm: 1.972e+01\n",
      "Epoch 19269, Loss: 266.2945556640625, Neurons: 11, Grad norm: 1.966e+01\n",
      "Epoch 19270, Loss: 266.1449890136719, Neurons: 11, Grad norm: 1.976e+01\n",
      "Epoch 19271, Loss: 265.9954528808594, Neurons: 11, Grad norm: 1.954e+01\n",
      "Epoch 19272, Loss: 265.8459167480469, Neurons: 11, Grad norm: 1.977e+01\n",
      "Epoch 19273, Loss: 265.6963806152344, Neurons: 11, Grad norm: 1.989e+01\n",
      "Epoch 19274, Loss: 265.5467834472656, Neurons: 11, Grad norm: 1.979e+01\n",
      "Epoch 19275, Loss: 265.3971862792969, Neurons: 11, Grad norm: 1.992e+01\n",
      "Epoch 19276, Loss: 265.2476501464844, Neurons: 11, Grad norm: 1.975e+01\n",
      "Epoch 19277, Loss: 265.0980529785156, Neurons: 11, Grad norm: 1.989e+01\n",
      "Epoch 19278, Loss: 264.9484558105469, Neurons: 11, Grad norm: 1.987e+01\n",
      "Epoch 19279, Loss: 264.798828125, Neurons: 11, Grad norm: 1.979e+01\n",
      "Epoch 19280, Loss: 264.6492004394531, Neurons: 11, Grad norm: 1.995e+01\n",
      "Epoch 19281, Loss: 264.49957275390625, Neurons: 11, Grad norm: 2.005e+01\n",
      "Epoch 19282, Loss: 264.3499755859375, Neurons: 11, Grad norm: 1.996e+01\n",
      "Epoch 19283, Loss: 264.2003479003906, Neurons: 11, Grad norm: 2.007e+01\n",
      "Epoch 19284, Loss: 264.0506591796875, Neurons: 11, Grad norm: 1.981e+01\n",
      "Epoch 19285, Loss: 263.9010314941406, Neurons: 11, Grad norm: 1.988e+01\n",
      "Epoch 19286, Loss: 263.7513732910156, Neurons: 11, Grad norm: 2.022e+01\n",
      "Epoch 19287, Loss: 263.6017150878906, Neurons: 11, Grad norm: 2.012e+01\n",
      "Epoch 19288, Loss: 263.4520568847656, Neurons: 11, Grad norm: 2.020e+01\n",
      "Epoch 19289, Loss: 263.3023986816406, Neurons: 11, Grad norm: 2.014e+01\n",
      "Epoch 19290, Loss: 263.1526794433594, Neurons: 11, Grad norm: 1.994e+01\n",
      "Epoch 19291, Loss: 263.0030212402344, Neurons: 11, Grad norm: 2.025e+01\n",
      "Epoch 19292, Loss: 262.85333251953125, Neurons: 11, Grad norm: 2.029e+01\n",
      "Epoch 19293, Loss: 262.7036437988281, Neurons: 11, Grad norm: 2.015e+01\n",
      "Epoch 19294, Loss: 262.553955078125, Neurons: 11, Grad norm: 2.032e+01\n",
      "Epoch 19295, Loss: 262.40423583984375, Neurons: 11, Grad norm: 2.008e+01\n",
      "Epoch 19296, Loss: 262.2545471191406, Neurons: 11, Grad norm: 2.018e+01\n",
      "Epoch 19297, Loss: 262.1048583984375, Neurons: 11, Grad norm: 2.034e+01\n",
      "Epoch 19298, Loss: 261.95513916015625, Neurons: 11, Grad norm: 2.043e+01\n",
      "Epoch 19299, Loss: 261.8053894042969, Neurons: 11, Grad norm: 2.044e+01\n",
      "Epoch 19299, Test loss: 258.74554443359375\n",
      "Epoch 19300, Loss: 261.65570068359375, Neurons: 11, Grad norm: 2.038e+01\n",
      "Epoch 19301, Loss: 261.5059814453125, Neurons: 11, Grad norm: 2.021e+01\n",
      "Epoch 19302, Loss: 261.3562316894531, Neurons: 11, Grad norm: 2.035e+01\n",
      "Epoch 19303, Loss: 261.2065124511719, Neurons: 11, Grad norm: 2.033e+01\n",
      "Epoch 19304, Loss: 261.0567932128906, Neurons: 11, Grad norm: 2.063e+01\n",
      "Epoch 19305, Loss: 260.90704345703125, Neurons: 11, Grad norm: 2.044e+01\n",
      "Epoch 19306, Loss: 260.7573547363281, Neurons: 11, Grad norm: 2.049e+01\n",
      "Epoch 19307, Loss: 260.60760498046875, Neurons: 11, Grad norm: 2.047e+01\n",
      "Epoch 19308, Loss: 260.4578552246094, Neurons: 11, Grad norm: 2.049e+01\n",
      "Epoch 19309, Loss: 260.3081359863281, Neurons: 11, Grad norm: 2.057e+01\n",
      "Epoch 19310, Loss: 260.15838623046875, Neurons: 11, Grad norm: 2.059e+01\n",
      "Epoch 19311, Loss: 260.0086975097656, Neurons: 11, Grad norm: 2.052e+01\n",
      "Epoch 19312, Loss: 259.85894775390625, Neurons: 11, Grad norm: 2.058e+01\n",
      "Epoch 19313, Loss: 259.709228515625, Neurons: 11, Grad norm: 2.052e+01\n",
      "Epoch 19314, Loss: 259.5594787597656, Neurons: 11, Grad norm: 2.072e+01\n",
      "Epoch 19315, Loss: 259.4097900390625, Neurons: 11, Grad norm: 2.075e+01\n",
      "Epoch 19316, Loss: 259.2600402832031, Neurons: 11, Grad norm: 2.063e+01\n",
      "Epoch 19317, Loss: 259.1103515625, Neurons: 11, Grad norm: 2.077e+01\n",
      "Epoch 19318, Loss: 258.96063232421875, Neurons: 11, Grad norm: 2.064e+01\n",
      "Epoch 19319, Loss: 258.8109436035156, Neurons: 11, Grad norm: 2.064e+01\n",
      "Epoch 19320, Loss: 258.6612243652344, Neurons: 11, Grad norm: 2.081e+01\n",
      "Epoch 19321, Loss: 258.51153564453125, Neurons: 11, Grad norm: 2.073e+01\n",
      "Epoch 19322, Loss: 258.3617858886719, Neurons: 11, Grad norm: 2.077e+01\n",
      "Epoch 19323, Loss: 258.2121276855469, Neurons: 11, Grad norm: 2.082e+01\n",
      "Epoch 19324, Loss: 258.06243896484375, Neurons: 11, Grad norm: 2.074e+01\n",
      "Epoch 19325, Loss: 257.91278076171875, Neurons: 11, Grad norm: 2.094e+01\n",
      "Epoch 19326, Loss: 257.7630920410156, Neurons: 11, Grad norm: 2.088e+01\n",
      "Epoch 19327, Loss: 257.6134338378906, Neurons: 11, Grad norm: 2.084e+01\n",
      "Epoch 19328, Loss: 257.46380615234375, Neurons: 11, Grad norm: 2.093e+01\n",
      "Epoch 19329, Loss: 257.31414794921875, Neurons: 11, Grad norm: 2.079e+01\n",
      "Epoch 19330, Loss: 257.16448974609375, Neurons: 11, Grad norm: 2.085e+01\n",
      "Epoch 19331, Loss: 257.0148620605469, Neurons: 11, Grad norm: 2.100e+01\n",
      "Epoch 19332, Loss: 256.865234375, Neurons: 11, Grad norm: 2.093e+01\n",
      "Epoch 19333, Loss: 256.71563720703125, Neurons: 11, Grad norm: 2.095e+01\n",
      "Epoch 19334, Loss: 256.5660400390625, Neurons: 11, Grad norm: 2.107e+01\n",
      "Epoch 19335, Loss: 256.4164733886719, Neurons: 11, Grad norm: 2.093e+01\n",
      "Epoch 19336, Loss: 256.2668762207031, Neurons: 11, Grad norm: 2.101e+01\n",
      "Epoch 19337, Loss: 256.1173095703125, Neurons: 11, Grad norm: 2.109e+01\n",
      "Epoch 19338, Loss: 255.9677734375, Neurons: 11, Grad norm: 2.092e+01\n",
      "Epoch 19339, Loss: 255.8182373046875, Neurons: 11, Grad norm: 2.117e+01\n",
      "Epoch 19340, Loss: 255.66868591308594, Neurons: 11, Grad norm: 2.111e+01\n",
      "Epoch 19341, Loss: 255.51919555664062, Neurons: 11, Grad norm: 2.101e+01\n",
      "Epoch 19342, Loss: 255.36968994140625, Neurons: 11, Grad norm: 2.114e+01\n",
      "Epoch 19343, Loss: 255.22019958496094, Neurons: 11, Grad norm: 2.101e+01\n",
      "Epoch 19344, Loss: 255.07073974609375, Neurons: 11, Grad norm: 2.105e+01\n",
      "Epoch 19345, Loss: 254.92129516601562, Neurons: 11, Grad norm: 2.130e+01\n",
      "Epoch 19346, Loss: 254.77186584472656, Neurons: 11, Grad norm: 2.112e+01\n",
      "Epoch 19347, Loss: 254.6224365234375, Neurons: 11, Grad norm: 2.122e+01\n",
      "Epoch 19348, Loss: 254.47303771972656, Neurons: 11, Grad norm: 2.116e+01\n",
      "Epoch 19349, Loss: 254.32366943359375, Neurons: 11, Grad norm: 2.111e+01\n",
      "Epoch 19349, Test loss: 251.33885192871094\n",
      "Epoch 19350, Loss: 254.17431640625, Neurons: 11, Grad norm: 2.123e+01\n",
      "Epoch 19351, Loss: 254.02496337890625, Neurons: 11, Grad norm: 2.121e+01\n",
      "Epoch 19352, Loss: 253.87564086914062, Neurons: 11, Grad norm: 2.125e+01\n",
      "Epoch 19353, Loss: 253.72634887695312, Neurons: 11, Grad norm: 2.121e+01\n",
      "Epoch 19354, Loss: 253.5770721435547, Neurons: 11, Grad norm: 2.126e+01\n",
      "Epoch 19355, Loss: 253.42779541015625, Neurons: 11, Grad norm: 2.127e+01\n",
      "Epoch 19356, Loss: 253.278564453125, Neurons: 11, Grad norm: 2.123e+01\n",
      "Epoch 19357, Loss: 253.12936401367188, Neurons: 11, Grad norm: 2.138e+01\n",
      "Epoch 19358, Loss: 252.98016357421875, Neurons: 11, Grad norm: 2.128e+01\n",
      "Epoch 19359, Loss: 252.83099365234375, Neurons: 11, Grad norm: 2.129e+01\n",
      "Epoch 19360, Loss: 252.6818389892578, Neurons: 11, Grad norm: 2.129e+01\n",
      "Epoch 19361, Loss: 252.53269958496094, Neurons: 11, Grad norm: 2.130e+01\n",
      "Epoch 19362, Loss: 252.38363647460938, Neurons: 11, Grad norm: 2.138e+01\n",
      "Epoch 19363, Loss: 252.2345428466797, Neurons: 11, Grad norm: 2.133e+01\n",
      "Epoch 19364, Loss: 252.0855255126953, Neurons: 11, Grad norm: 2.143e+01\n",
      "Epoch 19365, Loss: 251.93649291992188, Neurons: 11, Grad norm: 2.137e+01\n",
      "Epoch 19366, Loss: 251.78749084472656, Neurons: 11, Grad norm: 2.129e+01\n",
      "Epoch 19367, Loss: 251.6385498046875, Neurons: 11, Grad norm: 2.145e+01\n",
      "Epoch 19368, Loss: 251.4896240234375, Neurons: 11, Grad norm: 2.137e+01\n",
      "Epoch 19369, Loss: 251.34066772460938, Neurons: 11, Grad norm: 2.138e+01\n",
      "Epoch 19370, Loss: 251.19178771972656, Neurons: 11, Grad norm: 2.153e+01\n",
      "Epoch 19371, Loss: 251.04296875, Neurons: 11, Grad norm: 2.135e+01\n",
      "Epoch 19372, Loss: 250.89414978027344, Neurons: 11, Grad norm: 2.138e+01\n",
      "Epoch 19373, Loss: 250.74534606933594, Neurons: 11, Grad norm: 2.150e+01\n",
      "Epoch 19374, Loss: 250.59657287597656, Neurons: 11, Grad norm: 2.138e+01\n",
      "Epoch 19375, Loss: 250.44784545898438, Neurons: 11, Grad norm: 2.148e+01\n",
      "Epoch 19376, Loss: 250.29916381835938, Neurons: 11, Grad norm: 2.156e+01\n",
      "Epoch 19377, Loss: 250.15049743652344, Neurons: 11, Grad norm: 2.136e+01\n",
      "Epoch 19378, Loss: 250.00184631347656, Neurons: 11, Grad norm: 2.157e+01\n",
      "Epoch 19379, Loss: 249.853271484375, Neurons: 11, Grad norm: 2.146e+01\n",
      "Epoch 19380, Loss: 249.70469665527344, Neurons: 11, Grad norm: 2.137e+01\n",
      "Epoch 19381, Loss: 249.5561981201172, Neurons: 11, Grad norm: 2.167e+01\n",
      "Epoch 19382, Loss: 249.40769958496094, Neurons: 11, Grad norm: 2.139e+01\n",
      "Epoch 19383, Loss: 249.25924682617188, Neurons: 11, Grad norm: 2.156e+01\n",
      "Epoch 19384, Loss: 249.11082458496094, Neurons: 11, Grad norm: 2.159e+01\n",
      "Epoch 19385, Loss: 248.9624481201172, Neurons: 11, Grad norm: 2.132e+01\n",
      "Epoch 19386, Loss: 248.8140869140625, Neurons: 11, Grad norm: 2.167e+01\n",
      "Epoch 19387, Loss: 248.66578674316406, Neurons: 11, Grad norm: 2.143e+01\n",
      "Epoch 19388, Loss: 248.51754760742188, Neurons: 11, Grad norm: 2.154e+01\n",
      "Epoch 19389, Loss: 248.36929321289062, Neurons: 11, Grad norm: 2.165e+01\n",
      "Epoch 19390, Loss: 248.22109985351562, Neurons: 11, Grad norm: 2.148e+01\n",
      "Epoch 19391, Loss: 248.07293701171875, Neurons: 11, Grad norm: 2.156e+01\n",
      "Epoch 19392, Loss: 247.9248504638672, Neurons: 11, Grad norm: 2.156e+01\n",
      "Epoch 19393, Loss: 247.77674865722656, Neurons: 11, Grad norm: 2.147e+01\n",
      "Epoch 19394, Loss: 247.6287384033203, Neurons: 11, Grad norm: 2.156e+01\n",
      "Epoch 19395, Loss: 247.48074340820312, Neurons: 11, Grad norm: 2.159e+01\n",
      "Epoch 19396, Loss: 247.33279418945312, Neurons: 11, Grad norm: 2.147e+01\n",
      "Epoch 19397, Loss: 247.1848907470703, Neurons: 11, Grad norm: 2.168e+01\n",
      "Epoch 19398, Loss: 247.0369873046875, Neurons: 11, Grad norm: 2.150e+01\n",
      "Epoch 19399, Loss: 246.88919067382812, Neurons: 11, Grad norm: 2.156e+01\n",
      "Epoch 19399, Test loss: 243.98013305664062\n",
      "Epoch 19400, Loss: 246.74142456054688, Neurons: 11, Grad norm: 2.169e+01\n",
      "Epoch 19401, Loss: 246.59368896484375, Neurons: 11, Grad norm: 2.145e+01\n",
      "Epoch 19402, Loss: 246.44601440429688, Neurons: 11, Grad norm: 2.169e+01\n",
      "Epoch 19403, Loss: 246.29833984375, Neurons: 11, Grad norm: 2.153e+01\n",
      "Epoch 19404, Loss: 246.15074157714844, Neurons: 11, Grad norm: 2.154e+01\n",
      "Epoch 19405, Loss: 246.00318908691406, Neurons: 11, Grad norm: 2.162e+01\n",
      "Epoch 19406, Loss: 245.85569763183594, Neurons: 11, Grad norm: 2.154e+01\n",
      "Epoch 19407, Loss: 245.70822143554688, Neurons: 11, Grad norm: 2.157e+01\n",
      "Epoch 19408, Loss: 245.56082153320312, Neurons: 11, Grad norm: 2.164e+01\n",
      "Epoch 19409, Loss: 245.41343688964844, Neurons: 11, Grad norm: 2.148e+01\n",
      "Epoch 19410, Loss: 245.26611328125, Neurons: 11, Grad norm: 2.164e+01\n",
      "Epoch 19411, Loss: 245.1188507080078, Neurons: 11, Grad norm: 2.153e+01\n",
      "Epoch 19412, Loss: 244.97164916992188, Neurons: 11, Grad norm: 2.154e+01\n",
      "Epoch 19413, Loss: 244.82444763183594, Neurons: 11, Grad norm: 2.173e+01\n",
      "Epoch 19414, Loss: 244.67733764648438, Neurons: 11, Grad norm: 2.148e+01\n",
      "Epoch 19415, Loss: 244.53024291992188, Neurons: 11, Grad norm: 2.166e+01\n",
      "Epoch 19416, Loss: 244.3832244873047, Neurons: 11, Grad norm: 2.155e+01\n",
      "Epoch 19417, Loss: 244.23623657226562, Neurons: 11, Grad norm: 2.148e+01\n",
      "Epoch 19418, Loss: 244.08932495117188, Neurons: 11, Grad norm: 2.171e+01\n",
      "Epoch 19419, Loss: 243.94241333007812, Neurons: 11, Grad norm: 2.146e+01\n",
      "Epoch 19420, Loss: 243.79559326171875, Neurons: 11, Grad norm: 2.165e+01\n",
      "Epoch 19421, Loss: 243.64878845214844, Neurons: 11, Grad norm: 2.157e+01\n",
      "Epoch 19422, Loss: 243.50209045410156, Neurons: 11, Grad norm: 2.145e+01\n",
      "Epoch 19423, Loss: 243.3553924560547, Neurons: 11, Grad norm: 2.171e+01\n",
      "Epoch 19424, Loss: 243.20880126953125, Neurons: 11, Grad norm: 2.146e+01\n",
      "Epoch 19425, Loss: 243.06219482421875, Neurons: 11, Grad norm: 2.158e+01\n",
      "Epoch 19426, Loss: 242.9156951904297, Neurons: 11, Grad norm: 2.168e+01\n",
      "Epoch 19427, Loss: 242.7692413330078, Neurons: 11, Grad norm: 2.143e+01\n",
      "Epoch 19428, Loss: 242.62278747558594, Neurons: 11, Grad norm: 2.165e+01\n",
      "Epoch 19429, Loss: 242.4764404296875, Neurons: 11, Grad norm: 2.155e+01\n",
      "Epoch 19430, Loss: 242.33013916015625, Neurons: 11, Grad norm: 2.143e+01\n",
      "Epoch 19431, Loss: 242.1839141845703, Neurons: 11, Grad norm: 2.169e+01\n",
      "Epoch 19432, Loss: 242.03768920898438, Neurons: 11, Grad norm: 2.148e+01\n",
      "Epoch 19433, Loss: 241.89157104492188, Neurons: 11, Grad norm: 2.154e+01\n",
      "Epoch 19434, Loss: 241.74546813964844, Neurons: 11, Grad norm: 2.159e+01\n",
      "Epoch 19435, Loss: 241.59942626953125, Neurons: 11, Grad norm: 2.142e+01\n",
      "Epoch 19436, Loss: 241.45347595214844, Neurons: 11, Grad norm: 2.158e+01\n",
      "Epoch 19437, Loss: 241.3075408935547, Neurons: 11, Grad norm: 2.153e+01\n",
      "Epoch 19438, Loss: 241.16163635253906, Neurons: 11, Grad norm: 2.149e+01\n",
      "Epoch 19439, Loss: 241.01583862304688, Neurons: 11, Grad norm: 2.162e+01\n",
      "Epoch 19440, Loss: 240.87008666992188, Neurons: 11, Grad norm: 2.141e+01\n",
      "Epoch 19441, Loss: 240.72434997558594, Neurons: 11, Grad norm: 2.152e+01\n",
      "Epoch 19442, Loss: 240.57872009277344, Neurons: 11, Grad norm: 2.154e+01\n",
      "Epoch 19443, Loss: 240.43312072753906, Neurons: 11, Grad norm: 2.139e+01\n",
      "Epoch 19444, Loss: 240.28759765625, Neurons: 11, Grad norm: 2.159e+01\n",
      "Epoch 19445, Loss: 240.14215087890625, Neurons: 11, Grad norm: 2.146e+01\n",
      "Epoch 19446, Loss: 239.99668884277344, Neurons: 11, Grad norm: 2.150e+01\n",
      "Epoch 19447, Loss: 239.85134887695312, Neurons: 11, Grad norm: 2.149e+01\n",
      "Epoch 19448, Loss: 239.70602416992188, Neurons: 11, Grad norm: 2.138e+01\n",
      "Epoch 19449, Loss: 239.560791015625, Neurons: 11, Grad norm: 2.154e+01\n",
      "Epoch 19449, Test loss: 236.72239685058594\n",
      "Epoch 19450, Loss: 239.41558837890625, Neurons: 11, Grad norm: 2.143e+01\n",
      "Epoch 19451, Loss: 239.27044677734375, Neurons: 11, Grad norm: 2.147e+01\n",
      "Epoch 19452, Loss: 239.12539672851562, Neurons: 11, Grad norm: 2.149e+01\n",
      "Epoch 19453, Loss: 238.98036193847656, Neurons: 11, Grad norm: 2.139e+01\n",
      "Epoch 19454, Loss: 238.83538818359375, Neurons: 11, Grad norm: 2.146e+01\n",
      "Epoch 19455, Loss: 238.69049072265625, Neurons: 11, Grad norm: 2.138e+01\n",
      "Epoch 19456, Loss: 238.54563903808594, Neurons: 11, Grad norm: 2.147e+01\n",
      "Epoch 19457, Loss: 238.40084838867188, Neurons: 11, Grad norm: 2.141e+01\n",
      "Epoch 19458, Loss: 238.25608825683594, Neurons: 11, Grad norm: 2.137e+01\n",
      "Epoch 19459, Loss: 238.1114501953125, Neurons: 11, Grad norm: 2.146e+01\n",
      "Epoch 19460, Loss: 237.96681213378906, Neurons: 11, Grad norm: 2.134e+01\n",
      "Epoch 19461, Loss: 237.822265625, Neurons: 11, Grad norm: 2.141e+01\n",
      "Epoch 19462, Loss: 237.67776489257812, Neurons: 11, Grad norm: 2.139e+01\n",
      "Epoch 19463, Loss: 237.53334045410156, Neurons: 11, Grad norm: 2.135e+01\n",
      "Epoch 19464, Loss: 237.38894653320312, Neurons: 11, Grad norm: 2.138e+01\n",
      "Epoch 19465, Loss: 237.24464416503906, Neurons: 11, Grad norm: 2.138e+01\n",
      "Epoch 19466, Loss: 237.100341796875, Neurons: 11, Grad norm: 2.136e+01\n",
      "Epoch 19467, Loss: 236.95614624023438, Neurons: 11, Grad norm: 2.134e+01\n",
      "Epoch 19468, Loss: 236.81201171875, Neurons: 11, Grad norm: 2.138e+01\n",
      "Epoch 19469, Loss: 236.6678924560547, Neurons: 11, Grad norm: 2.128e+01\n",
      "Epoch 19470, Loss: 236.52386474609375, Neurons: 11, Grad norm: 2.131e+01\n",
      "Epoch 19471, Loss: 236.37989807128906, Neurons: 11, Grad norm: 2.133e+01\n",
      "Epoch 19472, Loss: 236.23599243164062, Neurons: 11, Grad norm: 2.127e+01\n",
      "Epoch 19473, Loss: 236.0921173095703, Neurons: 11, Grad norm: 2.139e+01\n",
      "Epoch 19474, Loss: 235.9483184814453, Neurons: 11, Grad norm: 2.129e+01\n",
      "Epoch 19475, Loss: 235.80459594726562, Neurons: 11, Grad norm: 2.126e+01\n",
      "Epoch 19476, Loss: 235.66087341308594, Neurons: 11, Grad norm: 2.134e+01\n",
      "Epoch 19477, Loss: 235.51724243164062, Neurons: 11, Grad norm: 2.122e+01\n",
      "Epoch 19478, Loss: 235.37368774414062, Neurons: 11, Grad norm: 2.125e+01\n",
      "Epoch 19479, Loss: 235.2301483154297, Neurons: 11, Grad norm: 2.129e+01\n",
      "Epoch 19480, Loss: 235.08670043945312, Neurons: 11, Grad norm: 2.119e+01\n",
      "Epoch 19481, Loss: 234.94329833984375, Neurons: 11, Grad norm: 2.131e+01\n",
      "Epoch 19482, Loss: 234.79994201660156, Neurons: 11, Grad norm: 2.120e+01\n",
      "Epoch 19483, Loss: 234.6566925048828, Neurons: 11, Grad norm: 2.125e+01\n",
      "Epoch 19484, Loss: 234.51344299316406, Neurons: 11, Grad norm: 2.125e+01\n",
      "Epoch 19485, Loss: 234.37030029296875, Neurons: 11, Grad norm: 2.114e+01\n",
      "Epoch 19486, Loss: 234.22718811035156, Neurons: 11, Grad norm: 2.130e+01\n",
      "Epoch 19487, Loss: 234.08412170410156, Neurons: 11, Grad norm: 2.114e+01\n",
      "Epoch 19488, Loss: 233.9411163330078, Neurons: 11, Grad norm: 2.123e+01\n",
      "Epoch 19489, Loss: 233.79818725585938, Neurons: 11, Grad norm: 2.119e+01\n",
      "Epoch 19490, Loss: 233.65528869628906, Neurons: 11, Grad norm: 2.113e+01\n",
      "Epoch 19491, Loss: 233.5124969482422, Neurons: 11, Grad norm: 2.119e+01\n",
      "Epoch 19492, Loss: 233.36972045898438, Neurons: 11, Grad norm: 2.115e+01\n",
      "Epoch 19493, Loss: 233.22698974609375, Neurons: 11, Grad norm: 2.116e+01\n",
      "Epoch 19494, Loss: 233.0843505859375, Neurons: 11, Grad norm: 2.113e+01\n",
      "Epoch 19495, Loss: 232.94174194335938, Neurons: 11, Grad norm: 2.114e+01\n",
      "Epoch 19496, Loss: 232.7991943359375, Neurons: 11, Grad norm: 2.111e+01\n",
      "Epoch 19497, Loss: 232.6566925048828, Neurons: 11, Grad norm: 2.114e+01\n",
      "Epoch 19498, Loss: 232.51429748535156, Neurons: 11, Grad norm: 2.109e+01\n",
      "Epoch 19499, Loss: 232.37191772460938, Neurons: 11, Grad norm: 2.112e+01\n",
      "Epoch 19499, Test loss: 229.6059112548828\n",
      "Epoch 19500, Loss: 232.22959899902344, Neurons: 11, Grad norm: 2.107e+01\n",
      "Epoch 19501, Loss: 232.08734130859375, Neurons: 11, Grad norm: 2.110e+01\n",
      "Epoch 19502, Loss: 231.9451446533203, Neurons: 11, Grad norm: 2.106e+01\n",
      "Epoch 19503, Loss: 231.80299377441406, Neurons: 11, Grad norm: 2.107e+01\n",
      "Epoch 19504, Loss: 231.660888671875, Neurons: 11, Grad norm: 2.101e+01\n",
      "Epoch 19505, Loss: 231.5188446044922, Neurons: 11, Grad norm: 2.105e+01\n",
      "Epoch 19506, Loss: 231.37686157226562, Neurons: 11, Grad norm: 2.107e+01\n",
      "Epoch 19507, Loss: 231.2349395751953, Neurons: 11, Grad norm: 2.100e+01\n",
      "Epoch 19508, Loss: 231.09304809570312, Neurons: 11, Grad norm: 2.107e+01\n",
      "Epoch 19509, Loss: 230.9512176513672, Neurons: 11, Grad norm: 2.096e+01\n",
      "Epoch 19510, Loss: 230.8094482421875, Neurons: 11, Grad norm: 2.103e+01\n",
      "Epoch 19511, Loss: 230.66773986816406, Neurons: 11, Grad norm: 2.098e+01\n",
      "Epoch 19512, Loss: 230.52606201171875, Neurons: 11, Grad norm: 2.101e+01\n",
      "Epoch 19513, Loss: 230.3844451904297, Neurons: 11, Grad norm: 2.097e+01\n",
      "Epoch 19514, Loss: 230.24288940429688, Neurons: 11, Grad norm: 2.095e+01\n",
      "Epoch 19515, Loss: 230.1013946533203, Neurons: 11, Grad norm: 2.102e+01\n",
      "Epoch 19516, Loss: 229.95994567871094, Neurons: 11, Grad norm: 2.090e+01\n",
      "Epoch 19517, Loss: 229.81854248046875, Neurons: 11, Grad norm: 2.101e+01\n",
      "Epoch 19518, Loss: 229.6772003173828, Neurons: 11, Grad norm: 2.089e+01\n",
      "Epoch 19519, Loss: 229.53591918945312, Neurons: 11, Grad norm: 2.095e+01\n",
      "Epoch 19520, Loss: 229.39463806152344, Neurons: 11, Grad norm: 2.088e+01\n",
      "Epoch 19521, Loss: 229.2534637451172, Neurons: 11, Grad norm: 2.088e+01\n",
      "Epoch 19522, Loss: 229.1123504638672, Neurons: 11, Grad norm: 2.097e+01\n",
      "Epoch 19523, Loss: 228.9712371826172, Neurons: 11, Grad norm: 2.080e+01\n",
      "Epoch 19524, Loss: 228.83021545410156, Neurons: 11, Grad norm: 2.095e+01\n",
      "Epoch 19525, Loss: 228.68927001953125, Neurons: 11, Grad norm: 2.086e+01\n",
      "Epoch 19526, Loss: 228.54832458496094, Neurons: 11, Grad norm: 2.083e+01\n",
      "Epoch 19527, Loss: 228.40744018554688, Neurons: 11, Grad norm: 2.094e+01\n",
      "Epoch 19528, Loss: 228.26661682128906, Neurons: 11, Grad norm: 2.082e+01\n",
      "Epoch 19529, Loss: 228.12582397460938, Neurons: 11, Grad norm: 2.089e+01\n",
      "Epoch 19530, Loss: 227.98509216308594, Neurons: 11, Grad norm: 2.088e+01\n",
      "Epoch 19531, Loss: 227.84442138671875, Neurons: 11, Grad norm: 2.075e+01\n",
      "Epoch 19532, Loss: 227.70379638671875, Neurons: 11, Grad norm: 2.091e+01\n",
      "Epoch 19533, Loss: 227.5631866455078, Neurons: 11, Grad norm: 2.078e+01\n",
      "Epoch 19534, Loss: 227.42263793945312, Neurons: 11, Grad norm: 2.078e+01\n",
      "Epoch 19535, Loss: 227.28219604492188, Neurons: 11, Grad norm: 2.083e+01\n",
      "Epoch 19536, Loss: 227.14173889160156, Neurons: 11, Grad norm: 2.074e+01\n",
      "Epoch 19537, Loss: 227.0013427734375, Neurons: 11, Grad norm: 2.077e+01\n",
      "Epoch 19538, Loss: 226.86102294921875, Neurons: 11, Grad norm: 2.075e+01\n",
      "Epoch 19539, Loss: 226.72071838378906, Neurons: 11, Grad norm: 2.080e+01\n",
      "Epoch 19540, Loss: 226.5804901123047, Neurons: 11, Grad norm: 2.073e+01\n",
      "Epoch 19541, Loss: 226.44029235839844, Neurons: 11, Grad norm: 2.075e+01\n",
      "Epoch 19542, Loss: 226.3001708984375, Neurons: 11, Grad norm: 2.075e+01\n",
      "Epoch 19543, Loss: 226.16006469726562, Neurons: 11, Grad norm: 2.074e+01\n",
      "Epoch 19544, Loss: 226.02005004882812, Neurons: 11, Grad norm: 2.071e+01\n",
      "Epoch 19545, Loss: 225.8800506591797, Neurons: 11, Grad norm: 2.073e+01\n",
      "Epoch 19546, Loss: 225.7400665283203, Neurons: 11, Grad norm: 2.075e+01\n",
      "Epoch 19547, Loss: 225.6001434326172, Neurons: 11, Grad norm: 2.065e+01\n",
      "Epoch 19548, Loss: 225.46029663085938, Neurons: 11, Grad norm: 2.071e+01\n",
      "Epoch 19549, Loss: 225.32049560546875, Neurons: 11, Grad norm: 2.068e+01\n",
      "Epoch 19549, Test loss: 222.62158203125\n",
      "Epoch 19550, Loss: 225.18072509765625, Neurons: 11, Grad norm: 2.071e+01\n",
      "Epoch 19551, Loss: 225.04100036621094, Neurons: 11, Grad norm: 2.063e+01\n",
      "Epoch 19552, Loss: 224.9013214111328, Neurons: 11, Grad norm: 2.063e+01\n",
      "Epoch 19553, Loss: 224.76168823242188, Neurons: 11, Grad norm: 2.067e+01\n",
      "Epoch 19554, Loss: 224.62210083007812, Neurons: 11, Grad norm: 2.065e+01\n",
      "Epoch 19555, Loss: 224.4825439453125, Neurons: 11, Grad norm: 2.062e+01\n",
      "Epoch 19556, Loss: 224.3430633544922, Neurons: 11, Grad norm: 2.063e+01\n",
      "Epoch 19557, Loss: 224.20359802246094, Neurons: 11, Grad norm: 2.061e+01\n",
      "Epoch 19558, Loss: 224.06419372558594, Neurons: 11, Grad norm: 2.067e+01\n",
      "Epoch 19559, Loss: 223.9248504638672, Neurons: 11, Grad norm: 2.055e+01\n",
      "Epoch 19560, Loss: 223.78549194335938, Neurons: 11, Grad norm: 2.063e+01\n",
      "Epoch 19561, Loss: 223.646240234375, Neurons: 11, Grad norm: 2.056e+01\n",
      "Epoch 19562, Loss: 223.50698852539062, Neurons: 11, Grad norm: 2.060e+01\n",
      "Epoch 19563, Loss: 223.3678436279297, Neurons: 11, Grad norm: 2.065e+01\n",
      "Epoch 19564, Loss: 223.2286376953125, Neurons: 11, Grad norm: 2.048e+01\n",
      "Epoch 19565, Loss: 223.08956909179688, Neurons: 11, Grad norm: 2.063e+01\n",
      "Epoch 19566, Loss: 222.9505157470703, Neurons: 11, Grad norm: 2.046e+01\n",
      "Epoch 19567, Loss: 222.81149291992188, Neurons: 11, Grad norm: 2.061e+01\n",
      "Epoch 19568, Loss: 222.67251586914062, Neurons: 11, Grad norm: 2.059e+01\n",
      "Epoch 19569, Loss: 222.5336151123047, Neurons: 11, Grad norm: 2.047e+01\n",
      "Epoch 19570, Loss: 222.39471435546875, Neurons: 11, Grad norm: 2.059e+01\n",
      "Epoch 19571, Loss: 222.25588989257812, Neurons: 11, Grad norm: 2.040e+01\n",
      "Epoch 19572, Loss: 222.11709594726562, Neurons: 11, Grad norm: 2.057e+01\n",
      "Epoch 19573, Loss: 221.9783477783203, Neurons: 11, Grad norm: 2.049e+01\n",
      "Epoch 19574, Loss: 221.839599609375, Neurons: 11, Grad norm: 2.056e+01\n",
      "Epoch 19575, Loss: 221.70094299316406, Neurons: 11, Grad norm: 2.049e+01\n",
      "Epoch 19576, Loss: 221.5623016357422, Neurons: 11, Grad norm: 2.044e+01\n",
      "Epoch 19577, Loss: 221.4237518310547, Neurons: 11, Grad norm: 2.049e+01\n",
      "Epoch 19578, Loss: 221.28517150878906, Neurons: 11, Grad norm: 2.040e+01\n",
      "Epoch 19579, Loss: 221.14666748046875, Neurons: 11, Grad norm: 2.051e+01\n",
      "Epoch 19580, Loss: 221.00819396972656, Neurons: 11, Grad norm: 2.045e+01\n",
      "Epoch 19581, Loss: 220.8697967529297, Neurons: 11, Grad norm: 2.051e+01\n",
      "Epoch 19582, Loss: 220.73141479492188, Neurons: 11, Grad norm: 2.039e+01\n",
      "Epoch 19583, Loss: 220.59304809570312, Neurons: 11, Grad norm: 2.041e+01\n",
      "Epoch 19584, Loss: 220.45474243164062, Neurons: 11, Grad norm: 2.041e+01\n",
      "Epoch 19585, Loss: 220.31649780273438, Neurons: 11, Grad norm: 2.040e+01\n",
      "Epoch 19586, Loss: 220.1782684326172, Neurons: 11, Grad norm: 2.046e+01\n",
      "Epoch 19587, Loss: 220.04010009765625, Neurons: 11, Grad norm: 2.037e+01\n",
      "Epoch 19588, Loss: 219.90196228027344, Neurons: 11, Grad norm: 2.041e+01\n",
      "Epoch 19589, Loss: 219.7638397216797, Neurons: 11, Grad norm: 2.035e+01\n",
      "Epoch 19590, Loss: 219.62582397460938, Neurons: 11, Grad norm: 2.043e+01\n",
      "Epoch 19591, Loss: 219.48779296875, Neurons: 11, Grad norm: 2.033e+01\n",
      "Epoch 19592, Loss: 219.34979248046875, Neurons: 11, Grad norm: 2.042e+01\n",
      "Epoch 19593, Loss: 219.2118682861328, Neurons: 11, Grad norm: 2.035e+01\n",
      "Epoch 19594, Loss: 219.07398986816406, Neurons: 11, Grad norm: 2.036e+01\n",
      "Epoch 19595, Loss: 218.93614196777344, Neurons: 11, Grad norm: 2.034e+01\n",
      "Epoch 19596, Loss: 218.79833984375, Neurons: 11, Grad norm: 2.030e+01\n",
      "Epoch 19597, Loss: 218.66053771972656, Neurons: 11, Grad norm: 2.033e+01\n",
      "Epoch 19598, Loss: 218.52279663085938, Neurons: 11, Grad norm: 2.029e+01\n",
      "Epoch 19599, Loss: 218.38511657714844, Neurons: 11, Grad norm: 2.033e+01\n",
      "Epoch 19599, Test loss: 215.74562072753906\n",
      "Epoch 19600, Loss: 218.24745178222656, Neurons: 11, Grad norm: 2.029e+01\n",
      "Epoch 19601, Loss: 218.10984802246094, Neurons: 11, Grad norm: 2.031e+01\n",
      "Epoch 19602, Loss: 217.97227478027344, Neurons: 11, Grad norm: 2.028e+01\n",
      "Epoch 19603, Loss: 217.834716796875, Neurons: 11, Grad norm: 2.029e+01\n",
      "Epoch 19604, Loss: 217.69725036621094, Neurons: 11, Grad norm: 2.028e+01\n",
      "Epoch 19605, Loss: 217.5597686767578, Neurons: 11, Grad norm: 2.028e+01\n",
      "Epoch 19606, Loss: 217.42236328125, Neurons: 11, Grad norm: 2.031e+01\n",
      "Epoch 19607, Loss: 217.2849884033203, Neurons: 11, Grad norm: 2.032e+01\n",
      "Epoch 19608, Loss: 217.14764404296875, Neurons: 11, Grad norm: 2.022e+01\n",
      "Epoch 19609, Loss: 217.01034545898438, Neurons: 11, Grad norm: 2.029e+01\n",
      "Epoch 19610, Loss: 216.8731231689453, Neurons: 11, Grad norm: 2.018e+01\n",
      "Epoch 19611, Loss: 216.73590087890625, Neurons: 11, Grad norm: 2.028e+01\n",
      "Epoch 19612, Loss: 216.59873962402344, Neurons: 11, Grad norm: 2.019e+01\n",
      "Epoch 19613, Loss: 216.46163940429688, Neurons: 11, Grad norm: 2.023e+01\n",
      "Epoch 19614, Loss: 216.32452392578125, Neurons: 11, Grad norm: 2.018e+01\n",
      "Epoch 19615, Loss: 216.1875, Neurons: 11, Grad norm: 2.016e+01\n",
      "Epoch 19616, Loss: 216.0504913330078, Neurons: 11, Grad norm: 2.019e+01\n",
      "Epoch 19617, Loss: 215.91351318359375, Neurons: 11, Grad norm: 2.015e+01\n",
      "Epoch 19618, Loss: 215.77659606933594, Neurons: 11, Grad norm: 2.022e+01\n",
      "Epoch 19619, Loss: 215.63973999023438, Neurons: 11, Grad norm: 2.017e+01\n",
      "Epoch 19620, Loss: 215.50289916992188, Neurons: 11, Grad norm: 2.020e+01\n",
      "Epoch 19621, Loss: 215.3660888671875, Neurons: 11, Grad norm: 2.015e+01\n",
      "Epoch 19622, Loss: 215.22933959960938, Neurons: 11, Grad norm: 2.016e+01\n",
      "Epoch 19623, Loss: 215.09259033203125, Neurons: 11, Grad norm: 2.016e+01\n",
      "Epoch 19624, Loss: 214.95594787597656, Neurons: 11, Grad norm: 2.014e+01\n",
      "Epoch 19625, Loss: 214.8192901611328, Neurons: 11, Grad norm: 2.017e+01\n",
      "Epoch 19626, Loss: 214.6826934814453, Neurons: 11, Grad norm: 2.011e+01\n",
      "Epoch 19627, Loss: 214.546142578125, Neurons: 11, Grad norm: 2.014e+01\n",
      "Epoch 19628, Loss: 214.40963745117188, Neurons: 11, Grad norm: 2.008e+01\n",
      "Epoch 19629, Loss: 214.273193359375, Neurons: 11, Grad norm: 2.011e+01\n",
      "Epoch 19630, Loss: 214.1367950439453, Neurons: 11, Grad norm: 2.008e+01\n",
      "Epoch 19631, Loss: 214.00039672851562, Neurons: 11, Grad norm: 2.010e+01\n",
      "Epoch 19632, Loss: 213.86404418945312, Neurons: 11, Grad norm: 2.008e+01\n",
      "Epoch 19633, Loss: 213.7277374267578, Neurons: 11, Grad norm: 2.006e+01\n",
      "Epoch 19634, Loss: 213.59149169921875, Neurons: 11, Grad norm: 2.006e+01\n",
      "Epoch 19635, Loss: 213.4552764892578, Neurons: 11, Grad norm: 2.003e+01\n",
      "Epoch 19636, Loss: 213.319091796875, Neurons: 11, Grad norm: 2.008e+01\n",
      "Epoch 19637, Loss: 213.18299865722656, Neurons: 11, Grad norm: 2.000e+01\n",
      "Epoch 19638, Loss: 213.0469207763672, Neurons: 11, Grad norm: 2.002e+01\n",
      "Epoch 19639, Loss: 212.910888671875, Neurons: 11, Grad norm: 2.005e+01\n",
      "Epoch 19640, Loss: 212.77488708496094, Neurons: 11, Grad norm: 2.000e+01\n",
      "Epoch 19641, Loss: 212.638916015625, Neurons: 11, Grad norm: 2.005e+01\n",
      "Epoch 19642, Loss: 212.5030517578125, Neurons: 11, Grad norm: 1.996e+01\n",
      "Epoch 19643, Loss: 212.36717224121094, Neurons: 11, Grad norm: 2.005e+01\n",
      "Epoch 19644, Loss: 212.2313690185547, Neurons: 11, Grad norm: 1.997e+01\n",
      "Epoch 19645, Loss: 212.09559631347656, Neurons: 11, Grad norm: 2.005e+01\n",
      "Epoch 19646, Loss: 211.9598388671875, Neurons: 11, Grad norm: 1.995e+01\n",
      "Epoch 19647, Loss: 211.8241729736328, Neurons: 11, Grad norm: 2.002e+01\n",
      "Epoch 19648, Loss: 211.68853759765625, Neurons: 11, Grad norm: 1.992e+01\n",
      "Epoch 19649, Loss: 211.55294799804688, Neurons: 11, Grad norm: 1.998e+01\n",
      "Epoch 19649, Test loss: 208.9547576904297\n",
      "Epoch 19650, Loss: 211.41738891601562, Neurons: 11, Grad norm: 1.990e+01\n",
      "Epoch 19651, Loss: 211.28189086914062, Neurons: 11, Grad norm: 1.997e+01\n",
      "Epoch 19652, Loss: 211.14646911621094, Neurons: 11, Grad norm: 1.989e+01\n",
      "Epoch 19653, Loss: 211.0110626220703, Neurons: 11, Grad norm: 1.995e+01\n",
      "Epoch 19654, Loss: 210.87570190429688, Neurons: 11, Grad norm: 1.986e+01\n",
      "Epoch 19655, Loss: 210.7404022216797, Neurons: 11, Grad norm: 1.990e+01\n",
      "Epoch 19656, Loss: 210.6051483154297, Neurons: 11, Grad norm: 1.980e+01\n",
      "Epoch 19657, Loss: 210.4699249267578, Neurons: 11, Grad norm: 1.999e+01\n",
      "Epoch 19658, Loss: 210.33474731445312, Neurons: 11, Grad norm: 1.978e+01\n",
      "Epoch 19659, Loss: 210.19964599609375, Neurons: 11, Grad norm: 2.002e+01\n",
      "Epoch 19660, Loss: 210.06454467773438, Neurons: 11, Grad norm: 1.974e+01\n",
      "Epoch 19661, Loss: 209.92955017089844, Neurons: 11, Grad norm: 2.003e+01\n",
      "Epoch 19662, Loss: 209.79454040527344, Neurons: 11, Grad norm: 1.972e+01\n",
      "Epoch 19663, Loss: 209.65963745117188, Neurons: 11, Grad norm: 2.006e+01\n",
      "Epoch 19664, Loss: 209.5247802734375, Neurons: 11, Grad norm: 1.967e+01\n",
      "Epoch 19665, Loss: 209.38995361328125, Neurons: 11, Grad norm: 1.999e+01\n",
      "Epoch 19666, Loss: 209.25518798828125, Neurons: 11, Grad norm: 1.967e+01\n",
      "Epoch 19667, Loss: 209.12046813964844, Neurons: 11, Grad norm: 1.994e+01\n",
      "Epoch 19668, Loss: 208.98582458496094, Neurons: 11, Grad norm: 1.966e+01\n",
      "Epoch 19669, Loss: 208.8511962890625, Neurons: 11, Grad norm: 1.991e+01\n",
      "Epoch 19670, Loss: 208.71661376953125, Neurons: 11, Grad norm: 1.965e+01\n",
      "Epoch 19671, Loss: 208.5821075439453, Neurons: 11, Grad norm: 1.992e+01\n",
      "Epoch 19672, Loss: 208.44766235351562, Neurons: 11, Grad norm: 1.963e+01\n",
      "Epoch 19673, Loss: 208.31326293945312, Neurons: 11, Grad norm: 1.995e+01\n",
      "Epoch 19674, Loss: 208.17889404296875, Neurons: 11, Grad norm: 1.958e+01\n",
      "Epoch 19675, Loss: 208.04461669921875, Neurons: 11, Grad norm: 1.996e+01\n",
      "Epoch 19676, Loss: 207.91036987304688, Neurons: 11, Grad norm: 1.951e+01\n",
      "Epoch 19677, Loss: 207.7761993408203, Neurons: 11, Grad norm: 1.992e+01\n",
      "Epoch 19678, Loss: 207.6420440673828, Neurons: 11, Grad norm: 1.952e+01\n",
      "Epoch 19679, Loss: 207.50794982910156, Neurons: 11, Grad norm: 1.995e+01\n",
      "Epoch 19680, Loss: 207.3739471435547, Neurons: 11, Grad norm: 1.949e+01\n",
      "Epoch 19681, Loss: 207.239990234375, Neurons: 11, Grad norm: 1.994e+01\n",
      "Epoch 19682, Loss: 207.10606384277344, Neurons: 11, Grad norm: 1.944e+01\n",
      "Epoch 19683, Loss: 206.9722442626953, Neurons: 11, Grad norm: 2.002e+01\n",
      "Epoch 19684, Loss: 206.8384552001953, Neurons: 11, Grad norm: 1.937e+01\n",
      "Epoch 19685, Loss: 206.70472717285156, Neurons: 11, Grad norm: 2.012e+01\n",
      "Epoch 19686, Loss: 206.57107543945312, Neurons: 11, Grad norm: 1.936e+01\n",
      "Epoch 19687, Loss: 206.43743896484375, Neurons: 11, Grad norm: 2.000e+01\n",
      "Epoch 19688, Loss: 206.3038787841797, Neurons: 11, Grad norm: 1.934e+01\n",
      "Epoch 19689, Loss: 206.17039489746094, Neurons: 11, Grad norm: 1.997e+01\n",
      "Epoch 19690, Loss: 206.0369415283203, Neurons: 11, Grad norm: 1.932e+01\n",
      "Epoch 19691, Loss: 205.903564453125, Neurons: 11, Grad norm: 2.002e+01\n",
      "Epoch 19692, Loss: 205.770263671875, Neurons: 11, Grad norm: 1.930e+01\n",
      "Epoch 19693, Loss: 205.63702392578125, Neurons: 11, Grad norm: 2.003e+01\n",
      "Epoch 19694, Loss: 205.50384521484375, Neurons: 11, Grad norm: 1.926e+01\n",
      "Epoch 19695, Loss: 205.37071228027344, Neurons: 11, Grad norm: 2.002e+01\n",
      "Epoch 19696, Loss: 205.2376708984375, Neurons: 11, Grad norm: 1.921e+01\n",
      "Epoch 19697, Loss: 205.10467529296875, Neurons: 11, Grad norm: 1.996e+01\n",
      "Epoch 19698, Loss: 204.97177124023438, Neurons: 11, Grad norm: 1.924e+01\n",
      "Epoch 19699, Loss: 204.83889770507812, Neurons: 11, Grad norm: 1.969e+01\n",
      "Epoch 19699, Test loss: 202.28594970703125\n",
      "Epoch 19700, Loss: 204.7061004638672, Neurons: 11, Grad norm: 1.931e+01\n",
      "Epoch 19701, Loss: 204.5733642578125, Neurons: 11, Grad norm: 1.949e+01\n",
      "Epoch 19702, Loss: 204.44068908691406, Neurons: 11, Grad norm: 1.942e+01\n",
      "Epoch 19703, Loss: 204.30807495117188, Neurons: 11, Grad norm: 1.937e+01\n",
      "Epoch 19704, Loss: 204.17555236816406, Neurons: 11, Grad norm: 1.953e+01\n",
      "Epoch 19705, Loss: 204.04307556152344, Neurons: 11, Grad norm: 1.929e+01\n",
      "Epoch 19706, Loss: 203.91064453125, Neurons: 11, Grad norm: 1.958e+01\n",
      "Epoch 19707, Loss: 203.77833557128906, Neurons: 11, Grad norm: 1.916e+01\n",
      "Epoch 19708, Loss: 203.6460418701172, Neurons: 11, Grad norm: 1.977e+01\n",
      "Epoch 19709, Loss: 203.5138397216797, Neurons: 11, Grad norm: 1.910e+01\n",
      "Epoch 19710, Loss: 203.38169860839844, Neurons: 11, Grad norm: 1.989e+01\n",
      "Epoch 19711, Loss: 203.24961853027344, Neurons: 11, Grad norm: 1.904e+01\n",
      "Epoch 19712, Loss: 203.11761474609375, Neurons: 11, Grad norm: 1.996e+01\n",
      "Epoch 19713, Loss: 202.98568725585938, Neurons: 11, Grad norm: 1.900e+01\n",
      "Epoch 19714, Loss: 202.85379028320312, Neurons: 11, Grad norm: 2.000e+01\n",
      "Epoch 19715, Loss: 202.7220458984375, Neurons: 11, Grad norm: 1.897e+01\n",
      "Epoch 19716, Loss: 202.59030151367188, Neurons: 11, Grad norm: 1.988e+01\n",
      "Epoch 19717, Loss: 202.4586639404297, Neurons: 11, Grad norm: 1.896e+01\n",
      "Epoch 19718, Loss: 202.32708740234375, Neurons: 11, Grad norm: 1.962e+01\n",
      "Epoch 19719, Loss: 202.1956024169922, Neurons: 11, Grad norm: 1.900e+01\n",
      "Epoch 19720, Loss: 202.0641632080078, Neurons: 11, Grad norm: 1.934e+01\n",
      "Epoch 19721, Loss: 201.9328155517578, Neurons: 11, Grad norm: 1.908e+01\n",
      "Epoch 19722, Loss: 201.8015594482422, Neurons: 11, Grad norm: 1.908e+01\n",
      "Epoch 19723, Loss: 201.67034912109375, Neurons: 11, Grad norm: 1.930e+01\n",
      "Epoch 19724, Loss: 201.53921508789062, Neurons: 11, Grad norm: 1.896e+01\n",
      "Epoch 19725, Loss: 201.40814208984375, Neurons: 11, Grad norm: 1.945e+01\n",
      "Epoch 19726, Loss: 201.2771453857422, Neurons: 11, Grad norm: 1.889e+01\n",
      "Epoch 19727, Loss: 201.14622497558594, Neurons: 11, Grad norm: 1.950e+01\n",
      "Epoch 19728, Loss: 201.01539611816406, Neurons: 11, Grad norm: 1.888e+01\n",
      "Epoch 19729, Loss: 200.8846435546875, Neurons: 11, Grad norm: 1.945e+01\n",
      "Epoch 19730, Loss: 200.7539520263672, Neurons: 11, Grad norm: 1.886e+01\n",
      "Epoch 19731, Loss: 200.62332153320312, Neurons: 11, Grad norm: 1.923e+01\n",
      "Epoch 19732, Loss: 200.49278259277344, Neurons: 11, Grad norm: 1.893e+01\n",
      "Epoch 19733, Loss: 200.36228942871094, Neurons: 11, Grad norm: 1.904e+01\n",
      "Epoch 19734, Loss: 200.2318878173828, Neurons: 11, Grad norm: 1.902e+01\n",
      "Epoch 19735, Loss: 200.1015625, Neurons: 11, Grad norm: 1.889e+01\n",
      "Epoch 19736, Loss: 199.9713134765625, Neurons: 11, Grad norm: 1.911e+01\n",
      "Epoch 19737, Loss: 199.84117126464844, Neurons: 11, Grad norm: 1.882e+01\n",
      "Epoch 19738, Loss: 199.71102905273438, Neurons: 11, Grad norm: 1.916e+01\n",
      "Epoch 19739, Loss: 199.58103942871094, Neurons: 11, Grad norm: 1.877e+01\n",
      "Epoch 19740, Loss: 199.45106506347656, Neurons: 11, Grad norm: 1.913e+01\n",
      "Epoch 19741, Loss: 199.3212127685547, Neurons: 11, Grad norm: 1.875e+01\n",
      "Epoch 19742, Loss: 199.19139099121094, Neurons: 11, Grad norm: 1.908e+01\n",
      "Epoch 19743, Loss: 199.0616912841797, Neurons: 11, Grad norm: 1.873e+01\n",
      "Epoch 19744, Loss: 198.93206787109375, Neurons: 11, Grad norm: 1.903e+01\n",
      "Epoch 19745, Loss: 198.80252075195312, Neurons: 11, Grad norm: 1.872e+01\n",
      "Epoch 19746, Loss: 198.67303466796875, Neurons: 11, Grad norm: 1.895e+01\n",
      "Epoch 19747, Loss: 198.54364013671875, Neurons: 11, Grad norm: 1.869e+01\n",
      "Epoch 19748, Loss: 198.41432189941406, Neurons: 11, Grad norm: 1.890e+01\n",
      "Epoch 19749, Loss: 198.28509521484375, Neurons: 11, Grad norm: 1.869e+01\n",
      "Epoch 19749, Test loss: 195.76446533203125\n",
      "Epoch 19750, Loss: 198.15594482421875, Neurons: 11, Grad norm: 1.884e+01\n",
      "Epoch 19751, Loss: 198.02687072753906, Neurons: 11, Grad norm: 1.869e+01\n",
      "Epoch 19752, Loss: 197.8978729248047, Neurons: 11, Grad norm: 1.877e+01\n",
      "Epoch 19753, Loss: 197.7689666748047, Neurons: 11, Grad norm: 1.867e+01\n",
      "Epoch 19754, Loss: 197.64015197753906, Neurons: 11, Grad norm: 1.868e+01\n",
      "Epoch 19755, Loss: 197.5113983154297, Neurons: 11, Grad norm: 1.861e+01\n",
      "Epoch 19756, Loss: 197.38272094726562, Neurons: 11, Grad norm: 1.874e+01\n",
      "Epoch 19757, Loss: 197.25413513183594, Neurons: 11, Grad norm: 1.858e+01\n",
      "Epoch 19758, Loss: 197.12562561035156, Neurons: 11, Grad norm: 1.874e+01\n",
      "Epoch 19759, Loss: 196.99722290039062, Neurons: 11, Grad norm: 1.851e+01\n",
      "Epoch 19760, Loss: 196.86886596679688, Neurons: 11, Grad norm: 1.871e+01\n",
      "Epoch 19761, Loss: 196.74061584472656, Neurons: 11, Grad norm: 1.849e+01\n",
      "Epoch 19762, Loss: 196.61245727539062, Neurons: 11, Grad norm: 1.875e+01\n",
      "Epoch 19763, Loss: 196.48435974121094, Neurons: 11, Grad norm: 1.846e+01\n",
      "Epoch 19764, Loss: 196.3563690185547, Neurons: 11, Grad norm: 1.872e+01\n",
      "Epoch 19765, Loss: 196.2284393310547, Neurons: 11, Grad norm: 1.839e+01\n",
      "Epoch 19766, Loss: 196.10060119628906, Neurons: 11, Grad norm: 1.867e+01\n",
      "Epoch 19767, Loss: 195.97286987304688, Neurons: 11, Grad norm: 1.834e+01\n",
      "Epoch 19768, Loss: 195.84519958496094, Neurons: 11, Grad norm: 1.868e+01\n",
      "Epoch 19769, Loss: 195.71762084960938, Neurons: 11, Grad norm: 1.830e+01\n",
      "Epoch 19770, Loss: 195.59011840820312, Neurons: 11, Grad norm: 1.869e+01\n",
      "Epoch 19771, Loss: 195.46270751953125, Neurons: 11, Grad norm: 1.823e+01\n",
      "Epoch 19772, Loss: 195.33538818359375, Neurons: 11, Grad norm: 1.868e+01\n",
      "Epoch 19773, Loss: 195.2081756591797, Neurons: 11, Grad norm: 1.816e+01\n",
      "Epoch 19774, Loss: 195.08103942871094, Neurons: 11, Grad norm: 1.875e+01\n",
      "Epoch 19775, Loss: 194.9539794921875, Neurons: 11, Grad norm: 1.812e+01\n",
      "Epoch 19776, Loss: 194.8270263671875, Neurons: 11, Grad norm: 1.884e+01\n",
      "Epoch 19777, Loss: 194.7001495361328, Neurons: 11, Grad norm: 1.805e+01\n",
      "Epoch 19778, Loss: 194.5733642578125, Neurons: 11, Grad norm: 1.894e+01\n",
      "Epoch 19779, Loss: 194.4467010498047, Neurons: 11, Grad norm: 1.799e+01\n",
      "Epoch 19780, Loss: 194.3201141357422, Neurons: 11, Grad norm: 1.909e+01\n",
      "Epoch 19781, Loss: 194.19358825683594, Neurons: 11, Grad norm: 1.797e+01\n",
      "Epoch 19782, Loss: 194.06719970703125, Neurons: 11, Grad norm: 1.920e+01\n",
      "Epoch 19783, Loss: 193.94091796875, Neurons: 11, Grad norm: 1.793e+01\n",
      "Epoch 19784, Loss: 193.814697265625, Neurons: 11, Grad norm: 1.914e+01\n",
      "Epoch 19785, Loss: 193.68856811523438, Neurons: 11, Grad norm: 1.788e+01\n",
      "Epoch 19786, Loss: 193.5625457763672, Neurons: 11, Grad norm: 1.861e+01\n",
      "Epoch 19787, Loss: 193.43661499023438, Neurons: 11, Grad norm: 1.796e+01\n",
      "Epoch 19788, Loss: 193.31077575683594, Neurons: 11, Grad norm: 1.813e+01\n",
      "Epoch 19789, Loss: 193.18502807617188, Neurons: 11, Grad norm: 1.820e+01\n",
      "Epoch 19790, Loss: 193.0594024658203, Neurons: 11, Grad norm: 1.788e+01\n",
      "Epoch 19791, Loss: 192.933837890625, Neurons: 11, Grad norm: 1.844e+01\n",
      "Epoch 19792, Loss: 192.80836486816406, Neurons: 11, Grad norm: 1.777e+01\n",
      "Epoch 19793, Loss: 192.68301391601562, Neurons: 11, Grad norm: 1.855e+01\n",
      "Epoch 19794, Loss: 192.5577392578125, Neurons: 11, Grad norm: 1.773e+01\n",
      "Epoch 19795, Loss: 192.43255615234375, Neurons: 11, Grad norm: 1.844e+01\n",
      "Epoch 19796, Loss: 192.30746459960938, Neurons: 11, Grad norm: 1.773e+01\n",
      "Epoch 19797, Loss: 192.18246459960938, Neurons: 11, Grad norm: 1.816e+01\n",
      "Epoch 19798, Loss: 192.0575408935547, Neurons: 11, Grad norm: 1.782e+01\n",
      "Epoch 19799, Loss: 191.93275451660156, Neurons: 11, Grad norm: 1.791e+01\n",
      "Epoch 19799, Test loss: 189.43453979492188\n",
      "Epoch 19800, Loss: 191.80801391601562, Neurons: 11, Grad norm: 1.796e+01\n",
      "Epoch 19801, Loss: 191.6834259033203, Neurons: 11, Grad norm: 1.772e+01\n",
      "Epoch 19802, Loss: 191.5588836669922, Neurons: 11, Grad norm: 1.809e+01\n",
      "Epoch 19803, Loss: 191.43441772460938, Neurons: 11, Grad norm: 1.767e+01\n",
      "Epoch 19804, Loss: 191.31007385253906, Neurons: 11, Grad norm: 1.803e+01\n",
      "Epoch 19805, Loss: 191.18582153320312, Neurons: 11, Grad norm: 1.765e+01\n",
      "Epoch 19806, Loss: 191.06167602539062, Neurons: 11, Grad norm: 1.795e+01\n",
      "Epoch 19807, Loss: 190.93759155273438, Neurons: 11, Grad norm: 1.764e+01\n",
      "Epoch 19808, Loss: 190.81361389160156, Neurons: 11, Grad norm: 1.781e+01\n",
      "Epoch 19809, Loss: 190.68972778320312, Neurons: 11, Grad norm: 1.763e+01\n",
      "Epoch 19810, Loss: 190.56591796875, Neurons: 11, Grad norm: 1.774e+01\n",
      "Epoch 19811, Loss: 190.44219970703125, Neurons: 11, Grad norm: 1.770e+01\n",
      "Epoch 19812, Loss: 190.31858825683594, Neurons: 11, Grad norm: 1.758e+01\n",
      "Epoch 19813, Loss: 190.195068359375, Neurons: 11, Grad norm: 1.770e+01\n",
      "Epoch 19814, Loss: 190.07167053222656, Neurons: 11, Grad norm: 1.749e+01\n",
      "Epoch 19815, Loss: 189.94834899902344, Neurons: 11, Grad norm: 1.770e+01\n",
      "Epoch 19816, Loss: 189.82508850097656, Neurons: 11, Grad norm: 1.745e+01\n",
      "Epoch 19817, Loss: 189.70196533203125, Neurons: 11, Grad norm: 1.770e+01\n",
      "Epoch 19818, Loss: 189.5789337158203, Neurons: 11, Grad norm: 1.746e+01\n",
      "Epoch 19819, Loss: 189.4559783935547, Neurons: 11, Grad norm: 1.754e+01\n",
      "Epoch 19820, Loss: 189.33314514160156, Neurons: 11, Grad norm: 1.743e+01\n",
      "Epoch 19821, Loss: 189.2103729248047, Neurons: 11, Grad norm: 1.746e+01\n",
      "Epoch 19822, Loss: 189.0876922607422, Neurons: 11, Grad norm: 1.746e+01\n",
      "Epoch 19823, Loss: 188.96514892578125, Neurons: 11, Grad norm: 1.743e+01\n",
      "Epoch 19824, Loss: 188.84266662597656, Neurons: 11, Grad norm: 1.744e+01\n",
      "Epoch 19825, Loss: 188.72027587890625, Neurons: 11, Grad norm: 1.737e+01\n",
      "Epoch 19826, Loss: 188.59800720214844, Neurons: 11, Grad norm: 1.743e+01\n",
      "Epoch 19827, Loss: 188.47581481933594, Neurons: 11, Grad norm: 1.724e+01\n",
      "Epoch 19828, Loss: 188.3537139892578, Neurons: 11, Grad norm: 1.747e+01\n",
      "Epoch 19829, Loss: 188.23175048828125, Neurons: 11, Grad norm: 1.718e+01\n",
      "Epoch 19830, Loss: 188.10983276367188, Neurons: 11, Grad norm: 1.756e+01\n",
      "Epoch 19831, Loss: 187.98805236816406, Neurons: 11, Grad norm: 1.709e+01\n",
      "Epoch 19832, Loss: 187.8663330078125, Neurons: 11, Grad norm: 1.756e+01\n",
      "Epoch 19833, Loss: 187.74472045898438, Neurons: 11, Grad norm: 1.703e+01\n",
      "Epoch 19834, Loss: 187.62319946289062, Neurons: 11, Grad norm: 1.748e+01\n",
      "Epoch 19835, Loss: 187.50180053710938, Neurons: 11, Grad norm: 1.699e+01\n",
      "Epoch 19836, Loss: 187.3804931640625, Neurons: 11, Grad norm: 1.751e+01\n",
      "Epoch 19837, Loss: 187.25926208496094, Neurons: 11, Grad norm: 1.701e+01\n",
      "Epoch 19838, Loss: 187.1381378173828, Neurons: 11, Grad norm: 1.736e+01\n",
      "Epoch 19839, Loss: 187.01708984375, Neurons: 11, Grad norm: 1.694e+01\n",
      "Epoch 19840, Loss: 186.89617919921875, Neurons: 11, Grad norm: 1.721e+01\n",
      "Epoch 19841, Loss: 186.7753448486328, Neurons: 11, Grad norm: 1.694e+01\n",
      "Epoch 19842, Loss: 186.65463256835938, Neurons: 11, Grad norm: 1.725e+01\n",
      "Epoch 19843, Loss: 186.53399658203125, Neurons: 11, Grad norm: 1.688e+01\n",
      "Epoch 19844, Loss: 186.41343688964844, Neurons: 11, Grad norm: 1.719e+01\n",
      "Epoch 19845, Loss: 186.2930145263672, Neurons: 11, Grad norm: 1.682e+01\n",
      "Epoch 19846, Loss: 186.17266845703125, Neurons: 11, Grad norm: 1.721e+01\n",
      "Epoch 19847, Loss: 186.0524139404297, Neurons: 11, Grad norm: 1.680e+01\n",
      "Epoch 19848, Loss: 185.93228149414062, Neurons: 11, Grad norm: 1.712e+01\n",
      "Epoch 19849, Loss: 185.81222534179688, Neurons: 11, Grad norm: 1.674e+01\n",
      "Epoch 19849, Test loss: 183.32354736328125\n",
      "Epoch 19850, Loss: 185.69227600097656, Neurons: 11, Grad norm: 1.708e+01\n",
      "Epoch 19851, Loss: 185.57241821289062, Neurons: 11, Grad norm: 1.672e+01\n",
      "Epoch 19852, Loss: 185.45265197753906, Neurons: 11, Grad norm: 1.715e+01\n",
      "Epoch 19853, Loss: 185.3330078125, Neurons: 11, Grad norm: 1.663e+01\n",
      "Epoch 19854, Loss: 185.21347045898438, Neurons: 11, Grad norm: 1.717e+01\n",
      "Epoch 19855, Loss: 185.09400939941406, Neurons: 11, Grad norm: 1.656e+01\n",
      "Epoch 19856, Loss: 184.97462463378906, Neurons: 11, Grad norm: 1.736e+01\n",
      "Epoch 19857, Loss: 184.85537719726562, Neurons: 11, Grad norm: 1.647e+01\n",
      "Epoch 19858, Loss: 184.7362518310547, Neurons: 11, Grad norm: 1.761e+01\n",
      "Epoch 19859, Loss: 184.61720275878906, Neurons: 11, Grad norm: 1.646e+01\n",
      "Epoch 19860, Loss: 184.49822998046875, Neurons: 11, Grad norm: 1.768e+01\n",
      "Epoch 19861, Loss: 184.37939453125, Neurons: 11, Grad norm: 1.640e+01\n",
      "Epoch 19862, Loss: 184.2606201171875, Neurons: 11, Grad norm: 1.758e+01\n",
      "Epoch 19863, Loss: 184.14199829101562, Neurons: 11, Grad norm: 1.634e+01\n",
      "Epoch 19864, Loss: 184.02346801757812, Neurons: 11, Grad norm: 1.718e+01\n",
      "Epoch 19865, Loss: 183.905029296875, Neurons: 11, Grad norm: 1.630e+01\n",
      "Epoch 19866, Loss: 183.78672790527344, Neurons: 11, Grad norm: 1.677e+01\n",
      "Epoch 19867, Loss: 183.66847229003906, Neurons: 11, Grad norm: 1.644e+01\n",
      "Epoch 19868, Loss: 183.5503387451172, Neurons: 11, Grad norm: 1.641e+01\n",
      "Epoch 19869, Loss: 183.4323272705078, Neurons: 11, Grad norm: 1.667e+01\n",
      "Epoch 19870, Loss: 183.3144073486328, Neurons: 11, Grad norm: 1.629e+01\n",
      "Epoch 19871, Loss: 183.19656372070312, Neurons: 11, Grad norm: 1.676e+01\n",
      "Epoch 19872, Loss: 183.07882690429688, Neurons: 11, Grad norm: 1.620e+01\n",
      "Epoch 19873, Loss: 182.9612274169922, Neurons: 11, Grad norm: 1.677e+01\n",
      "Epoch 19874, Loss: 182.8436737060547, Neurons: 11, Grad norm: 1.619e+01\n",
      "Epoch 19875, Loss: 182.7262420654297, Neurons: 11, Grad norm: 1.658e+01\n",
      "Epoch 19876, Loss: 182.60890197753906, Neurons: 11, Grad norm: 1.619e+01\n",
      "Epoch 19877, Loss: 182.49166870117188, Neurons: 11, Grad norm: 1.645e+01\n",
      "Epoch 19878, Loss: 182.37452697753906, Neurons: 11, Grad norm: 1.616e+01\n",
      "Epoch 19879, Loss: 182.25747680664062, Neurons: 11, Grad norm: 1.634e+01\n",
      "Epoch 19880, Loss: 182.14051818847656, Neurons: 11, Grad norm: 1.623e+01\n",
      "Epoch 19881, Loss: 182.02366638183594, Neurons: 11, Grad norm: 1.616e+01\n",
      "Epoch 19882, Loss: 181.90695190429688, Neurons: 11, Grad norm: 1.629e+01\n",
      "Epoch 19883, Loss: 181.79029846191406, Neurons: 11, Grad norm: 1.609e+01\n",
      "Epoch 19884, Loss: 181.67373657226562, Neurons: 11, Grad norm: 1.630e+01\n",
      "Epoch 19885, Loss: 181.55728149414062, Neurons: 11, Grad norm: 1.603e+01\n",
      "Epoch 19886, Loss: 181.44090270996094, Neurons: 11, Grad norm: 1.634e+01\n",
      "Epoch 19887, Loss: 181.3246612548828, Neurons: 11, Grad norm: 1.591e+01\n",
      "Epoch 19888, Loss: 181.20849609375, Neurons: 11, Grad norm: 1.634e+01\n",
      "Epoch 19889, Loss: 181.0924530029297, Neurons: 11, Grad norm: 1.588e+01\n",
      "Epoch 19890, Loss: 180.97647094726562, Neurons: 11, Grad norm: 1.627e+01\n",
      "Epoch 19891, Loss: 180.86056518554688, Neurons: 11, Grad norm: 1.588e+01\n",
      "Epoch 19892, Loss: 180.7448272705078, Neurons: 11, Grad norm: 1.608e+01\n",
      "Epoch 19893, Loss: 180.62916564941406, Neurons: 11, Grad norm: 1.589e+01\n",
      "Epoch 19894, Loss: 180.51361083984375, Neurons: 11, Grad norm: 1.601e+01\n",
      "Epoch 19895, Loss: 180.3981475830078, Neurons: 11, Grad norm: 1.588e+01\n",
      "Epoch 19896, Loss: 180.28277587890625, Neurons: 11, Grad norm: 1.595e+01\n",
      "Epoch 19897, Loss: 180.16749572753906, Neurons: 11, Grad norm: 1.590e+01\n",
      "Epoch 19898, Loss: 180.0523223876953, Neurons: 11, Grad norm: 1.578e+01\n",
      "Epoch 19899, Loss: 179.937255859375, Neurons: 11, Grad norm: 1.590e+01\n",
      "Epoch 19899, Test loss: 177.44520568847656\n",
      "Epoch 19900, Loss: 179.82229614257812, Neurons: 11, Grad norm: 1.574e+01\n",
      "Epoch 19901, Loss: 179.70742797851562, Neurons: 11, Grad norm: 1.590e+01\n",
      "Epoch 19902, Loss: 179.5926513671875, Neurons: 11, Grad norm: 1.574e+01\n",
      "Epoch 19903, Loss: 179.47793579101562, Neurons: 11, Grad norm: 1.578e+01\n",
      "Epoch 19904, Loss: 179.36338806152344, Neurons: 11, Grad norm: 1.570e+01\n",
      "Epoch 19905, Loss: 179.2489013671875, Neurons: 11, Grad norm: 1.575e+01\n",
      "Epoch 19906, Loss: 179.134521484375, Neurons: 11, Grad norm: 1.564e+01\n",
      "Epoch 19907, Loss: 179.02024841308594, Neurons: 11, Grad norm: 1.580e+01\n",
      "Epoch 19908, Loss: 178.9060516357422, Neurons: 11, Grad norm: 1.551e+01\n",
      "Epoch 19909, Loss: 178.79197692871094, Neurons: 11, Grad norm: 1.583e+01\n",
      "Epoch 19910, Loss: 178.6780242919922, Neurons: 11, Grad norm: 1.547e+01\n",
      "Epoch 19911, Loss: 178.56411743164062, Neurons: 11, Grad norm: 1.581e+01\n",
      "Epoch 19912, Loss: 178.45033264160156, Neurons: 11, Grad norm: 1.544e+01\n",
      "Epoch 19913, Loss: 178.3366241455078, Neurons: 11, Grad norm: 1.573e+01\n",
      "Epoch 19914, Loss: 178.2230682373047, Neurons: 11, Grad norm: 1.540e+01\n",
      "Epoch 19915, Loss: 178.1095733642578, Neurons: 11, Grad norm: 1.576e+01\n",
      "Epoch 19916, Loss: 177.99620056152344, Neurons: 11, Grad norm: 1.530e+01\n",
      "Epoch 19917, Loss: 177.88291931152344, Neurons: 11, Grad norm: 1.589e+01\n",
      "Epoch 19918, Loss: 177.76976013183594, Neurons: 11, Grad norm: 1.521e+01\n",
      "Epoch 19919, Loss: 177.6566925048828, Neurons: 11, Grad norm: 1.622e+01\n",
      "Epoch 19920, Loss: 177.5437469482422, Neurons: 11, Grad norm: 1.519e+01\n",
      "Epoch 19921, Loss: 177.43087768554688, Neurons: 11, Grad norm: 1.674e+01\n",
      "Epoch 19922, Loss: 177.31814575195312, Neurons: 11, Grad norm: 1.527e+01\n",
      "Epoch 19923, Loss: 177.2055206298828, Neurons: 11, Grad norm: 1.709e+01\n",
      "Epoch 19924, Loss: 177.0929718017578, Neurons: 11, Grad norm: 1.530e+01\n",
      "Epoch 19925, Loss: 176.98057556152344, Neurons: 11, Grad norm: 1.677e+01\n",
      "Epoch 19926, Loss: 176.8682403564453, Neurons: 11, Grad norm: 1.506e+01\n",
      "Epoch 19927, Loss: 176.7560272216797, Neurons: 11, Grad norm: 1.573e+01\n",
      "Epoch 19928, Loss: 176.64389038085938, Neurons: 11, Grad norm: 1.514e+01\n",
      "Epoch 19929, Loss: 176.53189086914062, Neurons: 11, Grad norm: 1.500e+01\n",
      "Epoch 19930, Loss: 176.42001342773438, Neurons: 11, Grad norm: 1.590e+01\n",
      "Epoch 19931, Loss: 176.30824279785156, Neurons: 11, Grad norm: 1.498e+01\n",
      "Epoch 19932, Loss: 176.19659423828125, Neurons: 11, Grad norm: 1.655e+01\n",
      "Epoch 19933, Loss: 176.0850372314453, Neurons: 11, Grad norm: 1.497e+01\n",
      "Epoch 19934, Loss: 175.97354125976562, Neurons: 11, Grad norm: 1.612e+01\n",
      "Epoch 19935, Loss: 175.86221313476562, Neurons: 11, Grad norm: 1.484e+01\n",
      "Epoch 19936, Loss: 175.75091552734375, Neurons: 11, Grad norm: 1.522e+01\n",
      "Epoch 19937, Loss: 175.63980102539062, Neurons: 11, Grad norm: 1.509e+01\n",
      "Epoch 19938, Loss: 175.52871704101562, Neurons: 11, Grad norm: 1.480e+01\n",
      "Epoch 19939, Loss: 175.4177703857422, Neurons: 11, Grad norm: 1.554e+01\n",
      "Epoch 19940, Loss: 175.30694580078125, Neurons: 11, Grad norm: 1.472e+01\n",
      "Epoch 19941, Loss: 175.19622802734375, Neurons: 11, Grad norm: 1.544e+01\n",
      "Epoch 19942, Loss: 175.0855712890625, Neurons: 11, Grad norm: 1.472e+01\n",
      "Epoch 19943, Loss: 174.9750518798828, Neurons: 11, Grad norm: 1.498e+01\n",
      "Epoch 19944, Loss: 174.86460876464844, Neurons: 11, Grad norm: 1.496e+01\n",
      "Epoch 19945, Loss: 174.7542724609375, Neurons: 11, Grad norm: 1.469e+01\n",
      "Epoch 19946, Loss: 174.64404296875, Neurons: 11, Grad norm: 1.532e+01\n",
      "Epoch 19947, Loss: 174.5338897705078, Neurons: 11, Grad norm: 1.460e+01\n",
      "Epoch 19948, Loss: 174.4238739013672, Neurons: 11, Grad norm: 1.519e+01\n",
      "Epoch 19949, Loss: 174.31394958496094, Neurons: 11, Grad norm: 1.462e+01\n",
      "Epoch 19949, Test loss: 171.8036651611328\n",
      "Epoch 19950, Loss: 174.2041015625, Neurons: 11, Grad norm: 1.482e+01\n",
      "Epoch 19951, Loss: 174.09439086914062, Neurons: 11, Grad norm: 1.484e+01\n",
      "Epoch 19952, Loss: 173.98477172851562, Neurons: 11, Grad norm: 1.455e+01\n",
      "Epoch 19953, Loss: 173.875244140625, Neurons: 11, Grad norm: 1.508e+01\n",
      "Epoch 19954, Loss: 173.7658233642578, Neurons: 11, Grad norm: 1.445e+01\n",
      "Epoch 19955, Loss: 173.65652465820312, Neurons: 11, Grad norm: 1.507e+01\n",
      "Epoch 19956, Loss: 173.54730224609375, Neurons: 11, Grad norm: 1.445e+01\n",
      "Epoch 19957, Loss: 173.4381561279297, Neurons: 11, Grad norm: 1.480e+01\n",
      "Epoch 19958, Loss: 173.3291778564453, Neurons: 11, Grad norm: 1.456e+01\n",
      "Epoch 19959, Loss: 173.22024536132812, Neurons: 11, Grad norm: 1.451e+01\n",
      "Epoch 19960, Loss: 173.11141967773438, Neurons: 11, Grad norm: 1.471e+01\n",
      "Epoch 19961, Loss: 173.00271606445312, Neurons: 11, Grad norm: 1.435e+01\n",
      "Epoch 19962, Loss: 172.89413452148438, Neurons: 11, Grad norm: 1.484e+01\n",
      "Epoch 19963, Loss: 172.78564453125, Neurons: 11, Grad norm: 1.434e+01\n",
      "Epoch 19964, Loss: 172.67721557617188, Neurons: 11, Grad norm: 1.470e+01\n",
      "Epoch 19965, Loss: 172.56890869140625, Neurons: 11, Grad norm: 1.438e+01\n",
      "Epoch 19966, Loss: 172.46072387695312, Neurons: 11, Grad norm: 1.440e+01\n",
      "Epoch 19967, Loss: 172.35260009765625, Neurons: 11, Grad norm: 1.448e+01\n",
      "Epoch 19968, Loss: 172.24461364746094, Neurons: 11, Grad norm: 1.431e+01\n",
      "Epoch 19969, Loss: 172.13673400878906, Neurons: 11, Grad norm: 1.458e+01\n",
      "Epoch 19970, Loss: 172.02894592285156, Neurons: 11, Grad norm: 1.422e+01\n",
      "Epoch 19971, Loss: 171.92124938964844, Neurons: 11, Grad norm: 1.455e+01\n",
      "Epoch 19972, Loss: 171.8136749267578, Neurons: 11, Grad norm: 1.415e+01\n",
      "Epoch 19973, Loss: 171.7061767578125, Neurons: 11, Grad norm: 1.450e+01\n",
      "Epoch 19974, Loss: 171.5988006591797, Neurons: 11, Grad norm: 1.417e+01\n",
      "Epoch 19975, Loss: 171.49151611328125, Neurons: 11, Grad norm: 1.430e+01\n",
      "Epoch 19976, Loss: 171.3843231201172, Neurons: 11, Grad norm: 1.427e+01\n",
      "Epoch 19977, Loss: 171.2772674560547, Neurons: 11, Grad norm: 1.411e+01\n",
      "Epoch 19978, Loss: 171.17030334472656, Neurons: 11, Grad norm: 1.443e+01\n",
      "Epoch 19979, Loss: 171.0634307861328, Neurons: 11, Grad norm: 1.401e+01\n",
      "Epoch 19980, Loss: 170.9566650390625, Neurons: 11, Grad norm: 1.437e+01\n",
      "Epoch 19981, Loss: 170.8500213623047, Neurons: 11, Grad norm: 1.401e+01\n",
      "Epoch 19982, Loss: 170.74343872070312, Neurons: 11, Grad norm: 1.420e+01\n",
      "Epoch 19983, Loss: 170.63699340820312, Neurons: 11, Grad norm: 1.411e+01\n",
      "Epoch 19984, Loss: 170.5306396484375, Neurons: 11, Grad norm: 1.402e+01\n",
      "Epoch 19985, Loss: 170.4243927001953, Neurons: 11, Grad norm: 1.413e+01\n",
      "Epoch 19986, Loss: 170.31825256347656, Neurons: 11, Grad norm: 1.395e+01\n",
      "Epoch 19987, Loss: 170.21218872070312, Neurons: 11, Grad norm: 1.410e+01\n",
      "Epoch 19988, Loss: 170.1062774658203, Neurons: 11, Grad norm: 1.398e+01\n",
      "Epoch 19989, Loss: 170.00042724609375, Neurons: 11, Grad norm: 1.401e+01\n",
      "Epoch 19990, Loss: 169.89471435546875, Neurons: 11, Grad norm: 1.391e+01\n",
      "Epoch 19991, Loss: 169.7890625, Neurons: 11, Grad norm: 1.396e+01\n",
      "Epoch 19992, Loss: 169.68353271484375, Neurons: 11, Grad norm: 1.387e+01\n",
      "Epoch 19993, Loss: 169.57810974121094, Neurons: 11, Grad norm: 1.395e+01\n",
      "Epoch 19994, Loss: 169.47279357910156, Neurons: 11, Grad norm: 1.384e+01\n",
      "Epoch 19995, Loss: 169.3675994873047, Neurons: 11, Grad norm: 1.385e+01\n",
      "Epoch 19996, Loss: 169.26248168945312, Neurons: 11, Grad norm: 1.386e+01\n",
      "Epoch 19997, Loss: 169.157470703125, Neurons: 11, Grad norm: 1.376e+01\n",
      "Epoch 19998, Loss: 169.0525665283203, Neurons: 11, Grad norm: 1.396e+01\n",
      "Epoch 19999, Loss: 168.94775390625, Neurons: 11, Grad norm: 1.368e+01\n",
      "Epoch 19999, Test loss: 166.3797149658203\n",
      "Epoch 20000, Loss: 168.8430633544922, Neurons: 11, Grad norm: 1.389e+01\n",
      "Epoch 20001, Loss: 168.7384796142578, Neurons: 11, Grad norm: 1.365e+01\n",
      "Epoch 20002, Loss: 168.63400268554688, Neurons: 11, Grad norm: 1.379e+01\n",
      "Epoch 20003, Loss: 168.5296173095703, Neurons: 11, Grad norm: 1.372e+01\n",
      "Epoch 20004, Loss: 168.42532348632812, Neurons: 11, Grad norm: 1.368e+01\n",
      "Epoch 20005, Loss: 168.3211669921875, Neurons: 11, Grad norm: 1.369e+01\n",
      "Epoch 20006, Loss: 168.21707153320312, Neurons: 11, Grad norm: 1.363e+01\n",
      "Epoch 20007, Loss: 168.11312866210938, Neurons: 11, Grad norm: 1.366e+01\n",
      "Epoch 20008, Loss: 168.00927734375, Neurons: 11, Grad norm: 1.356e+01\n",
      "Epoch 20009, Loss: 167.905517578125, Neurons: 11, Grad norm: 1.372e+01\n",
      "Epoch 20010, Loss: 167.80184936523438, Neurons: 11, Grad norm: 1.349e+01\n",
      "Epoch 20011, Loss: 167.6983184814453, Neurons: 11, Grad norm: 1.365e+01\n",
      "Epoch 20012, Loss: 167.59487915039062, Neurons: 11, Grad norm: 1.347e+01\n",
      "Epoch 20013, Loss: 167.4915313720703, Neurons: 11, Grad norm: 1.359e+01\n",
      "Epoch 20014, Loss: 167.38829040527344, Neurons: 11, Grad norm: 1.342e+01\n",
      "Epoch 20015, Loss: 167.2852020263672, Neurons: 11, Grad norm: 1.362e+01\n",
      "Epoch 20016, Loss: 167.1821746826172, Neurons: 11, Grad norm: 1.336e+01\n",
      "Epoch 20017, Loss: 167.07925415039062, Neurons: 11, Grad norm: 1.353e+01\n",
      "Epoch 20018, Loss: 166.9764404296875, Neurons: 11, Grad norm: 1.336e+01\n",
      "Epoch 20019, Loss: 166.87371826171875, Neurons: 11, Grad norm: 1.348e+01\n",
      "Epoch 20020, Loss: 166.77114868164062, Neurons: 11, Grad norm: 1.334e+01\n",
      "Epoch 20021, Loss: 166.66864013671875, Neurons: 11, Grad norm: 1.337e+01\n",
      "Epoch 20022, Loss: 166.5662384033203, Neurons: 11, Grad norm: 1.339e+01\n",
      "Epoch 20023, Loss: 166.4639892578125, Neurons: 11, Grad norm: 1.328e+01\n",
      "Epoch 20024, Loss: 166.36180114746094, Neurons: 11, Grad norm: 1.335e+01\n",
      "Epoch 20025, Loss: 166.25973510742188, Neurons: 11, Grad norm: 1.327e+01\n",
      "Epoch 20026, Loss: 166.1577911376953, Neurons: 11, Grad norm: 1.325e+01\n",
      "Epoch 20027, Loss: 166.05593872070312, Neurons: 11, Grad norm: 1.320e+01\n",
      "Epoch 20028, Loss: 165.95419311523438, Neurons: 11, Grad norm: 1.328e+01\n",
      "Epoch 20029, Loss: 165.8525390625, Neurons: 11, Grad norm: 1.317e+01\n",
      "Epoch 20030, Loss: 165.75099182128906, Neurons: 11, Grad norm: 1.324e+01\n",
      "Epoch 20031, Loss: 165.64959716796875, Neurons: 11, Grad norm: 1.317e+01\n",
      "Epoch 20032, Loss: 165.5482635498047, Neurons: 11, Grad norm: 1.317e+01\n",
      "Epoch 20033, Loss: 165.44705200195312, Neurons: 11, Grad norm: 1.310e+01\n",
      "Epoch 20034, Loss: 165.345947265625, Neurons: 11, Grad norm: 1.321e+01\n",
      "Epoch 20035, Loss: 165.2449493408203, Neurons: 11, Grad norm: 1.304e+01\n",
      "Epoch 20036, Loss: 165.14405822753906, Neurons: 11, Grad norm: 1.317e+01\n",
      "Epoch 20037, Loss: 165.0432891845703, Neurons: 11, Grad norm: 1.302e+01\n",
      "Epoch 20038, Loss: 164.94259643554688, Neurons: 11, Grad norm: 1.315e+01\n",
      "Epoch 20039, Loss: 164.84202575683594, Neurons: 11, Grad norm: 1.295e+01\n",
      "Epoch 20040, Loss: 164.7415771484375, Neurons: 11, Grad norm: 1.309e+01\n",
      "Epoch 20041, Loss: 164.64122009277344, Neurons: 11, Grad norm: 1.295e+01\n",
      "Epoch 20042, Loss: 164.5409698486328, Neurons: 11, Grad norm: 1.303e+01\n",
      "Epoch 20043, Loss: 164.44082641601562, Neurons: 11, Grad norm: 1.289e+01\n",
      "Epoch 20044, Loss: 164.34078979492188, Neurons: 11, Grad norm: 1.293e+01\n",
      "Epoch 20045, Loss: 164.24087524414062, Neurons: 11, Grad norm: 1.293e+01\n",
      "Epoch 20046, Loss: 164.14105224609375, Neurons: 11, Grad norm: 1.289e+01\n",
      "Epoch 20047, Loss: 164.04132080078125, Neurons: 11, Grad norm: 1.290e+01\n",
      "Epoch 20048, Loss: 163.9417266845703, Neurons: 11, Grad norm: 1.287e+01\n",
      "Epoch 20049, Loss: 163.8422393798828, Neurons: 11, Grad norm: 1.286e+01\n",
      "Epoch 20049, Test loss: 161.2337188720703\n",
      "Epoch 20050, Loss: 163.74285888671875, Neurons: 11, Grad norm: 1.281e+01\n",
      "Epoch 20051, Loss: 163.6436004638672, Neurons: 11, Grad norm: 1.279e+01\n",
      "Epoch 20052, Loss: 163.54441833496094, Neurons: 11, Grad norm: 1.286e+01\n",
      "Epoch 20053, Loss: 163.44537353515625, Neurons: 11, Grad norm: 1.272e+01\n",
      "Epoch 20054, Loss: 163.34642028808594, Neurons: 11, Grad norm: 1.283e+01\n",
      "Epoch 20055, Loss: 163.24757385253906, Neurons: 11, Grad norm: 1.268e+01\n",
      "Epoch 20056, Loss: 163.14883422851562, Neurons: 11, Grad norm: 1.283e+01\n",
      "Epoch 20057, Loss: 163.0502166748047, Neurons: 11, Grad norm: 1.260e+01\n",
      "Epoch 20058, Loss: 162.9517059326172, Neurons: 11, Grad norm: 1.277e+01\n",
      "Epoch 20059, Loss: 162.85330200195312, Neurons: 11, Grad norm: 1.257e+01\n",
      "Epoch 20060, Loss: 162.75498962402344, Neurons: 11, Grad norm: 1.283e+01\n",
      "Epoch 20061, Loss: 162.65682983398438, Neurons: 11, Grad norm: 1.250e+01\n",
      "Epoch 20062, Loss: 162.55873107910156, Neurons: 11, Grad norm: 1.287e+01\n",
      "Epoch 20063, Loss: 162.46075439453125, Neurons: 11, Grad norm: 1.244e+01\n",
      "Epoch 20064, Loss: 162.3629150390625, Neurons: 11, Grad norm: 1.311e+01\n",
      "Epoch 20065, Loss: 162.26516723632812, Neurons: 11, Grad norm: 1.241e+01\n",
      "Epoch 20066, Loss: 162.16754150390625, Neurons: 11, Grad norm: 1.366e+01\n",
      "Epoch 20067, Loss: 162.07005310058594, Neurons: 11, Grad norm: 1.267e+01\n",
      "Epoch 20068, Loss: 161.97267150878906, Neurons: 11, Grad norm: 1.504e+01\n",
      "Epoch 20069, Loss: 161.8754425048828, Neurons: 11, Grad norm: 1.375e+01\n",
      "Epoch 20070, Loss: 161.7783660888672, Neurons: 11, Grad norm: 1.685e+01\n",
      "Epoch 20071, Loss: 161.68142700195312, Neurons: 11, Grad norm: 1.459e+01\n",
      "Epoch 20072, Loss: 161.5845947265625, Neurons: 11, Grad norm: 1.646e+01\n",
      "Epoch 20073, Loss: 161.48779296875, Neurons: 11, Grad norm: 1.287e+01\n",
      "Epoch 20074, Loss: 161.39109802246094, Neurons: 11, Grad norm: 1.279e+01\n",
      "Epoch 20075, Loss: 161.29454040527344, Neurons: 11, Grad norm: 1.282e+01\n",
      "Epoch 20076, Loss: 161.19822692871094, Neurons: 11, Grad norm: 1.271e+01\n",
      "Epoch 20077, Loss: 161.10206604003906, Neurons: 11, Grad norm: 1.496e+01\n",
      "Epoch 20078, Loss: 161.0060272216797, Neurons: 11, Grad norm: 1.269e+01\n",
      "Epoch 20079, Loss: 160.91000366210938, Neurons: 11, Grad norm: 1.337e+01\n",
      "Epoch 20080, Loss: 160.8140869140625, Neurons: 11, Grad norm: 1.230e+01\n",
      "Epoch 20081, Loss: 160.71829223632812, Neurons: 11, Grad norm: 1.214e+01\n",
      "Epoch 20082, Loss: 160.6227264404297, Neurons: 11, Grad norm: 1.377e+01\n",
      "Epoch 20083, Loss: 160.5272674560547, Neurons: 11, Grad norm: 1.236e+01\n",
      "Epoch 20084, Loss: 160.43186950683594, Neurons: 11, Grad norm: 1.318e+01\n",
      "Epoch 20085, Loss: 160.33657836914062, Neurons: 11, Grad norm: 1.217e+01\n",
      "Epoch 20086, Loss: 160.24139404296875, Neurons: 11, Grad norm: 1.200e+01\n",
      "Epoch 20087, Loss: 160.14634704589844, Neurons: 11, Grad norm: 1.309e+01\n",
      "Epoch 20088, Loss: 160.0514678955078, Neurons: 11, Grad norm: 1.208e+01\n",
      "Epoch 20089, Loss: 159.9566650390625, Neurons: 11, Grad norm: 1.261e+01\n",
      "Epoch 20090, Loss: 159.8619384765625, Neurons: 11, Grad norm: 1.206e+01\n",
      "Epoch 20091, Loss: 159.76734924316406, Neurons: 11, Grad norm: 1.194e+01\n",
      "Epoch 20092, Loss: 159.67286682128906, Neurons: 11, Grad norm: 1.278e+01\n",
      "Epoch 20093, Loss: 159.57855224609375, Neurons: 11, Grad norm: 1.191e+01\n",
      "Epoch 20094, Loss: 159.48431396484375, Neurons: 11, Grad norm: 1.239e+01\n",
      "Epoch 20095, Loss: 159.39016723632812, Neurons: 11, Grad norm: 1.192e+01\n",
      "Epoch 20096, Loss: 159.296142578125, Neurons: 11, Grad norm: 1.189e+01\n",
      "Epoch 20097, Loss: 159.20225524902344, Neurons: 11, Grad norm: 1.253e+01\n",
      "Epoch 20098, Loss: 159.1084747314453, Neurons: 11, Grad norm: 1.180e+01\n",
      "Epoch 20099, Loss: 159.01480102539062, Neurons: 11, Grad norm: 1.226e+01\n",
      "Epoch 20099, Test loss: 156.3732452392578\n",
      "Epoch 20100, Loss: 158.9212188720703, Neurons: 11, Grad norm: 1.181e+01\n",
      "Epoch 20101, Loss: 158.82777404785156, Neurons: 11, Grad norm: 1.180e+01\n",
      "Epoch 20102, Loss: 158.7344207763672, Neurons: 11, Grad norm: 1.232e+01\n",
      "Epoch 20103, Loss: 158.64122009277344, Neurons: 11, Grad norm: 1.171e+01\n",
      "Epoch 20104, Loss: 158.548095703125, Neurons: 11, Grad norm: 1.210e+01\n",
      "Epoch 20105, Loss: 158.45509338378906, Neurons: 11, Grad norm: 1.171e+01\n",
      "Epoch 20106, Loss: 158.36219787597656, Neurons: 11, Grad norm: 1.170e+01\n",
      "Epoch 20107, Loss: 158.26943969726562, Neurons: 11, Grad norm: 1.210e+01\n",
      "Epoch 20108, Loss: 158.17677307128906, Neurons: 11, Grad norm: 1.166e+01\n",
      "Epoch 20109, Loss: 158.084228515625, Neurons: 11, Grad norm: 1.208e+01\n",
      "Epoch 20110, Loss: 157.9917755126953, Neurons: 11, Grad norm: 1.166e+01\n",
      "Epoch 20111, Loss: 157.89942932128906, Neurons: 11, Grad norm: 1.165e+01\n",
      "Epoch 20112, Loss: 157.80722045898438, Neurons: 11, Grad norm: 1.183e+01\n",
      "Epoch 20113, Loss: 157.71511840820312, Neurons: 11, Grad norm: 1.158e+01\n",
      "Epoch 20114, Loss: 157.62313842773438, Neurons: 11, Grad norm: 1.195e+01\n",
      "Epoch 20115, Loss: 157.53126525878906, Neurons: 11, Grad norm: 1.159e+01\n",
      "Epoch 20116, Loss: 157.4394989013672, Neurons: 11, Grad norm: 1.165e+01\n",
      "Epoch 20117, Loss: 157.34783935546875, Neurons: 11, Grad norm: 1.166e+01\n",
      "Epoch 20118, Loss: 157.2563018798828, Neurons: 11, Grad norm: 1.149e+01\n",
      "Epoch 20119, Loss: 157.1648712158203, Neurons: 11, Grad norm: 1.188e+01\n",
      "Epoch 20120, Loss: 157.07357788085938, Neurons: 11, Grad norm: 1.148e+01\n",
      "Epoch 20121, Loss: 156.98236083984375, Neurons: 11, Grad norm: 1.165e+01\n",
      "Epoch 20122, Loss: 156.89126586914062, Neurons: 11, Grad norm: 1.153e+01\n",
      "Epoch 20123, Loss: 156.80029296875, Neurons: 11, Grad norm: 1.144e+01\n",
      "Epoch 20124, Loss: 156.7094268798828, Neurons: 11, Grad norm: 1.165e+01\n",
      "Epoch 20125, Loss: 156.61865234375, Neurons: 11, Grad norm: 1.145e+01\n",
      "Epoch 20126, Loss: 156.52804565429688, Neurons: 11, Grad norm: 1.162e+01\n",
      "Epoch 20127, Loss: 156.43751525878906, Neurons: 11, Grad norm: 1.140e+01\n",
      "Epoch 20128, Loss: 156.3470916748047, Neurons: 11, Grad norm: 1.142e+01\n",
      "Epoch 20129, Loss: 156.25677490234375, Neurons: 11, Grad norm: 1.145e+01\n",
      "Epoch 20130, Loss: 156.16659545898438, Neurons: 11, Grad norm: 1.136e+01\n",
      "Epoch 20131, Loss: 156.0764923095703, Neurons: 11, Grad norm: 1.160e+01\n",
      "Epoch 20132, Loss: 155.98654174804688, Neurons: 11, Grad norm: 1.134e+01\n",
      "Epoch 20133, Loss: 155.89669799804688, Neurons: 11, Grad norm: 1.135e+01\n",
      "Epoch 20134, Loss: 155.80694580078125, Neurons: 11, Grad norm: 1.133e+01\n",
      "Epoch 20135, Loss: 155.71731567382812, Neurons: 11, Grad norm: 1.127e+01\n",
      "Epoch 20136, Loss: 155.6278076171875, Neurons: 11, Grad norm: 1.146e+01\n",
      "Epoch 20137, Loss: 155.53842163085938, Neurons: 11, Grad norm: 1.126e+01\n",
      "Epoch 20138, Loss: 155.44912719726562, Neurons: 11, Grad norm: 1.142e+01\n",
      "Epoch 20139, Loss: 155.3599395751953, Neurons: 11, Grad norm: 1.123e+01\n",
      "Epoch 20140, Loss: 155.27088928222656, Neurons: 11, Grad norm: 1.119e+01\n",
      "Epoch 20141, Loss: 155.18194580078125, Neurons: 11, Grad norm: 1.129e+01\n",
      "Epoch 20142, Loss: 155.09310913085938, Neurons: 11, Grad norm: 1.118e+01\n",
      "Epoch 20143, Loss: 155.00439453125, Neurons: 11, Grad norm: 1.136e+01\n",
      "Epoch 20144, Loss: 154.91580200195312, Neurons: 11, Grad norm: 1.113e+01\n",
      "Epoch 20145, Loss: 154.82730102539062, Neurons: 11, Grad norm: 1.125e+01\n",
      "Epoch 20146, Loss: 154.73892211914062, Neurons: 11, Grad norm: 1.108e+01\n",
      "Epoch 20147, Loss: 154.65065002441406, Neurons: 11, Grad norm: 1.113e+01\n",
      "Epoch 20148, Loss: 154.5625, Neurons: 11, Grad norm: 1.117e+01\n",
      "Epoch 20149, Loss: 154.47447204589844, Neurons: 11, Grad norm: 1.111e+01\n",
      "Epoch 20149, Test loss: 151.8063507080078\n",
      "Epoch 20150, Loss: 154.3865203857422, Neurons: 11, Grad norm: 1.120e+01\n",
      "Epoch 20151, Loss: 154.2987518310547, Neurons: 11, Grad norm: 1.102e+01\n",
      "Epoch 20152, Loss: 154.21104431152344, Neurons: 11, Grad norm: 1.101e+01\n",
      "Epoch 20153, Loss: 154.12344360351562, Neurons: 11, Grad norm: 1.107e+01\n",
      "Epoch 20154, Loss: 154.03598022460938, Neurons: 11, Grad norm: 1.101e+01\n",
      "Epoch 20155, Loss: 153.94862365722656, Neurons: 11, Grad norm: 1.114e+01\n",
      "Epoch 20156, Loss: 153.86138916015625, Neurons: 11, Grad norm: 1.096e+01\n",
      "Epoch 20157, Loss: 153.77426147460938, Neurons: 11, Grad norm: 1.102e+01\n",
      "Epoch 20158, Loss: 153.68724060058594, Neurons: 11, Grad norm: 1.090e+01\n",
      "Epoch 20159, Loss: 153.600341796875, Neurons: 11, Grad norm: 1.095e+01\n",
      "Epoch 20160, Loss: 153.51356506347656, Neurons: 11, Grad norm: 1.094e+01\n",
      "Epoch 20161, Loss: 153.4268798828125, Neurons: 11, Grad norm: 1.099e+01\n",
      "Epoch 20162, Loss: 153.34033203125, Neurons: 11, Grad norm: 1.092e+01\n",
      "Epoch 20163, Loss: 153.25389099121094, Neurons: 11, Grad norm: 1.088e+01\n",
      "Epoch 20164, Loss: 153.16754150390625, Neurons: 11, Grad norm: 1.082e+01\n",
      "Epoch 20165, Loss: 153.0813446044922, Neurons: 11, Grad norm: 1.085e+01\n",
      "Epoch 20166, Loss: 152.9952392578125, Neurons: 11, Grad norm: 1.088e+01\n",
      "Epoch 20167, Loss: 152.90924072265625, Neurons: 11, Grad norm: 1.088e+01\n",
      "Epoch 20168, Loss: 152.8233642578125, Neurons: 11, Grad norm: 1.083e+01\n",
      "Epoch 20169, Loss: 152.73764038085938, Neurons: 11, Grad norm: 1.074e+01\n",
      "Epoch 20170, Loss: 152.6519775390625, Neurons: 11, Grad norm: 1.076e+01\n",
      "Epoch 20171, Loss: 152.56646728515625, Neurons: 11, Grad norm: 1.075e+01\n",
      "Epoch 20172, Loss: 152.48104858398438, Neurons: 11, Grad norm: 1.080e+01\n",
      "Epoch 20173, Loss: 152.395751953125, Neurons: 11, Grad norm: 1.076e+01\n",
      "Epoch 20174, Loss: 152.31057739257812, Neurons: 11, Grad norm: 1.073e+01\n",
      "Epoch 20175, Loss: 152.22549438476562, Neurons: 11, Grad norm: 1.065e+01\n",
      "Epoch 20176, Loss: 152.1405487060547, Neurons: 11, Grad norm: 1.068e+01\n",
      "Epoch 20177, Loss: 152.05569458007812, Neurons: 11, Grad norm: 1.067e+01\n",
      "Epoch 20178, Loss: 151.97097778320312, Neurons: 11, Grad norm: 1.071e+01\n",
      "Epoch 20179, Loss: 151.88636779785156, Neurons: 11, Grad norm: 1.063e+01\n",
      "Epoch 20180, Loss: 151.80186462402344, Neurons: 11, Grad norm: 1.068e+01\n",
      "Epoch 20181, Loss: 151.71746826171875, Neurons: 11, Grad norm: 1.053e+01\n",
      "Epoch 20182, Loss: 151.63320922851562, Neurons: 11, Grad norm: 1.063e+01\n",
      "Epoch 20183, Loss: 151.549072265625, Neurons: 11, Grad norm: 1.055e+01\n",
      "Epoch 20184, Loss: 151.46502685546875, Neurons: 11, Grad norm: 1.063e+01\n",
      "Epoch 20185, Loss: 151.381103515625, Neurons: 11, Grad norm: 1.058e+01\n",
      "Epoch 20186, Loss: 151.2972869873047, Neurons: 11, Grad norm: 1.049e+01\n",
      "Epoch 20187, Loss: 151.2135772705078, Neurons: 11, Grad norm: 1.055e+01\n",
      "Epoch 20188, Loss: 151.1300048828125, Neurons: 11, Grad norm: 1.043e+01\n",
      "Epoch 20189, Loss: 151.04653930664062, Neurons: 11, Grad norm: 1.056e+01\n",
      "Epoch 20190, Loss: 150.96319580078125, Neurons: 11, Grad norm: 1.051e+01\n",
      "Epoch 20191, Loss: 150.87997436523438, Neurons: 11, Grad norm: 1.044e+01\n",
      "Epoch 20192, Loss: 150.7968292236328, Neurons: 11, Grad norm: 1.045e+01\n",
      "Epoch 20193, Loss: 150.71383666992188, Neurons: 11, Grad norm: 1.036e+01\n",
      "Epoch 20194, Loss: 150.63096618652344, Neurons: 11, Grad norm: 1.050e+01\n",
      "Epoch 20195, Loss: 150.5481719970703, Neurons: 11, Grad norm: 1.038e+01\n",
      "Epoch 20196, Loss: 150.4654998779297, Neurons: 11, Grad norm: 1.044e+01\n",
      "Epoch 20197, Loss: 150.38296508789062, Neurons: 11, Grad norm: 1.034e+01\n",
      "Epoch 20198, Loss: 150.300537109375, Neurons: 11, Grad norm: 1.034e+01\n",
      "Epoch 20199, Loss: 150.2182159423828, Neurons: 11, Grad norm: 1.035e+01\n",
      "Epoch 20199, Test loss: 147.51918029785156\n",
      "Epoch 20200, Loss: 150.13600158691406, Neurons: 11, Grad norm: 1.032e+01\n",
      "Epoch 20201, Loss: 150.05393981933594, Neurons: 11, Grad norm: 1.029e+01\n",
      "Epoch 20202, Loss: 149.9719696044922, Neurons: 11, Grad norm: 1.033e+01\n",
      "Epoch 20203, Loss: 149.89012145996094, Neurons: 11, Grad norm: 1.024e+01\n",
      "Epoch 20204, Loss: 149.80836486816406, Neurons: 11, Grad norm: 1.030e+01\n",
      "Epoch 20205, Loss: 149.7267608642578, Neurons: 11, Grad norm: 1.022e+01\n",
      "Epoch 20206, Loss: 149.64523315429688, Neurons: 11, Grad norm: 1.024e+01\n",
      "Epoch 20207, Loss: 149.56382751464844, Neurons: 11, Grad norm: 1.022e+01\n",
      "Epoch 20208, Loss: 149.48255920410156, Neurons: 11, Grad norm: 1.021e+01\n",
      "Epoch 20209, Loss: 149.40139770507812, Neurons: 11, Grad norm: 1.023e+01\n",
      "Epoch 20210, Loss: 149.32032775878906, Neurons: 11, Grad norm: 1.017e+01\n",
      "Epoch 20211, Loss: 149.23939514160156, Neurons: 11, Grad norm: 1.015e+01\n",
      "Epoch 20212, Loss: 149.1585693359375, Neurons: 11, Grad norm: 1.013e+01\n",
      "Epoch 20213, Loss: 149.07786560058594, Neurons: 11, Grad norm: 1.013e+01\n",
      "Epoch 20214, Loss: 148.99728393554688, Neurons: 11, Grad norm: 1.014e+01\n",
      "Epoch 20215, Loss: 148.9168243408203, Neurons: 11, Grad norm: 1.010e+01\n",
      "Epoch 20216, Loss: 148.83644104003906, Neurons: 11, Grad norm: 1.002e+01\n",
      "Epoch 20217, Loss: 148.75619506835938, Neurons: 11, Grad norm: 1.013e+01\n",
      "Epoch 20218, Loss: 148.6760711669922, Neurons: 11, Grad norm: 9.991e+00\n",
      "Epoch 20219, Loss: 148.59603881835938, Neurons: 11, Grad norm: 1.019e+01\n",
      "Epoch 20220, Loss: 148.51614379882812, Neurons: 11, Grad norm: 9.954e+00\n",
      "Epoch 20221, Loss: 148.43637084960938, Neurons: 11, Grad norm: 1.010e+01\n",
      "Epoch 20222, Loss: 148.356689453125, Neurons: 11, Grad norm: 9.918e+00\n",
      "Epoch 20223, Loss: 148.27711486816406, Neurons: 11, Grad norm: 1.007e+01\n",
      "Epoch 20224, Loss: 148.19769287109375, Neurons: 11, Grad norm: 9.936e+00\n",
      "Epoch 20225, Loss: 148.11837768554688, Neurons: 11, Grad norm: 1.000e+01\n",
      "Epoch 20226, Loss: 148.03915405273438, Neurons: 11, Grad norm: 9.917e+00\n",
      "Epoch 20227, Loss: 147.96005249023438, Neurons: 11, Grad norm: 9.920e+00\n",
      "Epoch 20228, Loss: 147.881103515625, Neurons: 11, Grad norm: 9.913e+00\n",
      "Epoch 20229, Loss: 147.80221557617188, Neurons: 11, Grad norm: 9.918e+00\n",
      "Epoch 20230, Loss: 147.7234649658203, Neurons: 11, Grad norm: 9.869e+00\n",
      "Epoch 20231, Loss: 147.64483642578125, Neurons: 11, Grad norm: 9.888e+00\n",
      "Epoch 20232, Loss: 147.56631469726562, Neurons: 11, Grad norm: 9.811e+00\n",
      "Epoch 20233, Loss: 147.48789978027344, Neurons: 11, Grad norm: 9.908e+00\n",
      "Epoch 20234, Loss: 147.4096221923828, Neurons: 11, Grad norm: 9.739e+00\n",
      "Epoch 20235, Loss: 147.33143615722656, Neurons: 11, Grad norm: 9.905e+00\n",
      "Epoch 20236, Loss: 147.25340270996094, Neurons: 11, Grad norm: 9.725e+00\n",
      "Epoch 20237, Loss: 147.1754150390625, Neurons: 11, Grad norm: 9.932e+00\n",
      "Epoch 20238, Loss: 147.0976104736328, Neurons: 11, Grad norm: 9.679e+00\n",
      "Epoch 20239, Loss: 147.01986694335938, Neurons: 11, Grad norm: 9.850e+00\n",
      "Epoch 20240, Loss: 146.94229125976562, Neurons: 11, Grad norm: 9.648e+00\n",
      "Epoch 20241, Loss: 146.86477661132812, Neurons: 11, Grad norm: 9.910e+00\n",
      "Epoch 20242, Loss: 146.78741455078125, Neurons: 11, Grad norm: 9.629e+00\n",
      "Epoch 20243, Loss: 146.71017456054688, Neurons: 11, Grad norm: 9.880e+00\n",
      "Epoch 20244, Loss: 146.6330108642578, Neurons: 11, Grad norm: 9.589e+00\n",
      "Epoch 20245, Loss: 146.5559844970703, Neurons: 11, Grad norm: 9.896e+00\n",
      "Epoch 20246, Loss: 146.47906494140625, Neurons: 11, Grad norm: 9.560e+00\n",
      "Epoch 20247, Loss: 146.40228271484375, Neurons: 11, Grad norm: 9.985e+00\n",
      "Epoch 20248, Loss: 146.32559204101562, Neurons: 11, Grad norm: 9.555e+00\n",
      "Epoch 20249, Loss: 146.24903869628906, Neurons: 11, Grad norm: 1.013e+01\n",
      "Epoch 20249, Test loss: 143.51071166992188\n",
      "Epoch 20250, Loss: 146.17257690429688, Neurons: 11, Grad norm: 9.583e+00\n",
      "Epoch 20251, Loss: 146.09625244140625, Neurons: 11, Grad norm: 1.037e+01\n",
      "Epoch 20252, Loss: 146.0200653076172, Neurons: 11, Grad norm: 9.745e+00\n",
      "Epoch 20253, Loss: 145.94395446777344, Neurons: 11, Grad norm: 1.096e+01\n",
      "Epoch 20254, Loss: 145.8679962158203, Neurons: 11, Grad norm: 1.008e+01\n",
      "Epoch 20255, Loss: 145.7921600341797, Neurons: 11, Grad norm: 1.164e+01\n",
      "Epoch 20256, Loss: 145.71641540527344, Neurons: 11, Grad norm: 1.078e+01\n",
      "Epoch 20257, Loss: 145.64083862304688, Neurons: 11, Grad norm: 1.255e+01\n",
      "Epoch 20258, Loss: 145.56536865234375, Neurons: 11, Grad norm: 1.113e+01\n",
      "Epoch 20259, Loss: 145.49002075195312, Neurons: 11, Grad norm: 1.243e+01\n",
      "Epoch 20260, Loss: 145.41476440429688, Neurons: 11, Grad norm: 1.043e+01\n",
      "Epoch 20261, Loss: 145.339599609375, Neurons: 11, Grad norm: 1.076e+01\n",
      "Epoch 20262, Loss: 145.2645721435547, Neurons: 11, Grad norm: 9.406e+00\n",
      "Epoch 20263, Loss: 145.18966674804688, Neurons: 11, Grad norm: 9.420e+00\n",
      "Epoch 20264, Loss: 145.1149139404297, Neurons: 11, Grad norm: 9.774e+00\n",
      "Epoch 20265, Loss: 145.04029846191406, Neurons: 11, Grad norm: 9.521e+00\n",
      "Epoch 20266, Loss: 144.9657745361328, Neurons: 11, Grad norm: 1.076e+01\n",
      "Epoch 20267, Loss: 144.89137268066406, Neurons: 11, Grad norm: 9.854e+00\n",
      "Epoch 20268, Loss: 144.8170928955078, Neurons: 11, Grad norm: 1.080e+01\n",
      "Epoch 20269, Loss: 144.742919921875, Neurons: 11, Grad norm: 9.419e+00\n",
      "Epoch 20270, Loss: 144.66885375976562, Neurons: 11, Grad norm: 9.667e+00\n",
      "Epoch 20271, Loss: 144.5949249267578, Neurons: 11, Grad norm: 9.250e+00\n",
      "Epoch 20272, Loss: 144.5210723876953, Neurons: 11, Grad norm: 9.185e+00\n",
      "Epoch 20273, Loss: 144.44737243652344, Neurons: 11, Grad norm: 9.884e+00\n",
      "Epoch 20274, Loss: 144.37376403808594, Neurons: 11, Grad norm: 9.380e+00\n",
      "Epoch 20275, Loss: 144.30029296875, Neurons: 11, Grad norm: 1.018e+01\n",
      "Epoch 20276, Loss: 144.2269744873047, Neurons: 11, Grad norm: 9.296e+00\n",
      "Epoch 20277, Loss: 144.15371704101562, Neurons: 11, Grad norm: 9.645e+00\n",
      "Epoch 20278, Loss: 144.08059692382812, Neurons: 11, Grad norm: 9.117e+00\n",
      "Epoch 20279, Loss: 144.00753784179688, Neurons: 11, Grad norm: 9.166e+00\n",
      "Epoch 20280, Loss: 143.93466186523438, Neurons: 11, Grad norm: 9.412e+00\n",
      "Epoch 20281, Loss: 143.86187744140625, Neurons: 11, Grad norm: 9.116e+00\n",
      "Epoch 20282, Loss: 143.78921508789062, Neurons: 11, Grad norm: 9.711e+00\n",
      "Epoch 20283, Loss: 143.71664428710938, Neurons: 11, Grad norm: 9.126e+00\n",
      "Epoch 20284, Loss: 143.64422607421875, Neurons: 11, Grad norm: 9.692e+00\n",
      "Epoch 20285, Loss: 143.5718994140625, Neurons: 11, Grad norm: 9.040e+00\n",
      "Epoch 20286, Loss: 143.49966430664062, Neurons: 11, Grad norm: 9.229e+00\n",
      "Epoch 20287, Loss: 143.42755126953125, Neurons: 11, Grad norm: 9.044e+00\n",
      "Epoch 20288, Loss: 143.35557556152344, Neurons: 11, Grad norm: 8.982e+00\n",
      "Epoch 20289, Loss: 143.28367614746094, Neurons: 11, Grad norm: 9.328e+00\n",
      "Epoch 20290, Loss: 143.21194458007812, Neurons: 11, Grad norm: 8.968e+00\n",
      "Epoch 20291, Loss: 143.14028930664062, Neurons: 11, Grad norm: 9.476e+00\n",
      "Epoch 20292, Loss: 143.06875610351562, Neurons: 11, Grad norm: 8.965e+00\n",
      "Epoch 20293, Loss: 142.99732971191406, Neurons: 11, Grad norm: 9.260e+00\n",
      "Epoch 20294, Loss: 142.926025390625, Neurons: 11, Grad norm: 8.900e+00\n",
      "Epoch 20295, Loss: 142.85482788085938, Neurons: 11, Grad norm: 9.059e+00\n",
      "Epoch 20296, Loss: 142.7837371826172, Neurons: 11, Grad norm: 8.946e+00\n",
      "Epoch 20297, Loss: 142.71275329589844, Neurons: 11, Grad norm: 8.882e+00\n",
      "Epoch 20298, Loss: 142.6418914794922, Neurons: 11, Grad norm: 9.031e+00\n",
      "Epoch 20299, Loss: 142.57115173339844, Neurons: 11, Grad norm: 8.836e+00\n",
      "Epoch 20299, Test loss: 139.7786865234375\n",
      "Epoch 20300, Loss: 142.50050354003906, Neurons: 11, Grad norm: 9.052e+00\n",
      "Epoch 20301, Loss: 142.43002319335938, Neurons: 11, Grad norm: 8.818e+00\n",
      "Epoch 20302, Loss: 142.35960388183594, Neurons: 11, Grad norm: 8.967e+00\n",
      "Epoch 20303, Loss: 142.28929138183594, Neurons: 11, Grad norm: 8.810e+00\n",
      "Epoch 20304, Loss: 142.21910095214844, Neurons: 11, Grad norm: 8.825e+00\n",
      "Epoch 20305, Loss: 142.1490020751953, Neurons: 11, Grad norm: 8.845e+00\n",
      "Epoch 20306, Loss: 142.0790557861328, Neurons: 11, Grad norm: 8.775e+00\n",
      "Epoch 20307, Loss: 142.00921630859375, Neurons: 11, Grad norm: 8.848e+00\n",
      "Epoch 20308, Loss: 141.93946838378906, Neurons: 11, Grad norm: 8.742e+00\n",
      "Epoch 20309, Loss: 141.8698272705078, Neurons: 11, Grad norm: 8.822e+00\n",
      "Epoch 20310, Loss: 141.80032348632812, Neurons: 11, Grad norm: 8.732e+00\n",
      "Epoch 20311, Loss: 141.73089599609375, Neurons: 11, Grad norm: 8.745e+00\n",
      "Epoch 20312, Loss: 141.66163635253906, Neurons: 11, Grad norm: 8.725e+00\n",
      "Epoch 20313, Loss: 141.59242248535156, Neurons: 11, Grad norm: 8.710e+00\n",
      "Epoch 20314, Loss: 141.52334594726562, Neurons: 11, Grad norm: 8.705e+00\n",
      "Epoch 20315, Loss: 141.45437622070312, Neurons: 11, Grad norm: 8.684e+00\n",
      "Epoch 20316, Loss: 141.3855438232422, Neurons: 11, Grad norm: 8.684e+00\n",
      "Epoch 20317, Loss: 141.31680297851562, Neurons: 11, Grad norm: 8.668e+00\n",
      "Epoch 20318, Loss: 141.2481689453125, Neurons: 11, Grad norm: 8.634e+00\n",
      "Epoch 20319, Loss: 141.1796417236328, Neurons: 11, Grad norm: 8.647e+00\n",
      "Epoch 20320, Loss: 141.1112518310547, Neurons: 11, Grad norm: 8.618e+00\n",
      "Epoch 20321, Loss: 141.04295349121094, Neurons: 11, Grad norm: 8.603e+00\n",
      "Epoch 20322, Loss: 140.97476196289062, Neurons: 11, Grad norm: 8.603e+00\n",
      "Epoch 20323, Loss: 140.90667724609375, Neurons: 11, Grad norm: 8.580e+00\n",
      "Epoch 20324, Loss: 140.83868408203125, Neurons: 11, Grad norm: 8.564e+00\n",
      "Epoch 20325, Loss: 140.7708282470703, Neurons: 11, Grad norm: 8.564e+00\n",
      "Epoch 20326, Loss: 140.703125, Neurons: 11, Grad norm: 8.539e+00\n",
      "Epoch 20327, Loss: 140.6354522705078, Neurons: 11, Grad norm: 8.570e+00\n",
      "Epoch 20328, Loss: 140.5679168701172, Neurons: 11, Grad norm: 8.483e+00\n",
      "Epoch 20329, Loss: 140.50051879882812, Neurons: 11, Grad norm: 8.551e+00\n",
      "Epoch 20330, Loss: 140.4332275390625, Neurons: 11, Grad norm: 8.457e+00\n",
      "Epoch 20331, Loss: 140.36602783203125, Neurons: 11, Grad norm: 8.519e+00\n",
      "Epoch 20332, Loss: 140.29891967773438, Neurons: 11, Grad norm: 8.438e+00\n",
      "Epoch 20333, Loss: 140.23196411132812, Neurons: 11, Grad norm: 8.500e+00\n",
      "Epoch 20334, Loss: 140.16506958007812, Neurons: 11, Grad norm: 8.399e+00\n",
      "Epoch 20335, Loss: 140.09829711914062, Neurons: 11, Grad norm: 8.481e+00\n",
      "Epoch 20336, Loss: 140.0316925048828, Neurons: 11, Grad norm: 8.379e+00\n",
      "Epoch 20337, Loss: 139.96514892578125, Neurons: 11, Grad norm: 8.499e+00\n",
      "Epoch 20338, Loss: 139.8987274169922, Neurons: 11, Grad norm: 8.343e+00\n",
      "Epoch 20339, Loss: 139.8323974609375, Neurons: 11, Grad norm: 8.466e+00\n",
      "Epoch 20340, Loss: 139.7661895751953, Neurons: 11, Grad norm: 8.314e+00\n",
      "Epoch 20341, Loss: 139.70010375976562, Neurons: 11, Grad norm: 8.445e+00\n",
      "Epoch 20342, Loss: 139.63409423828125, Neurons: 11, Grad norm: 8.311e+00\n",
      "Epoch 20343, Loss: 139.56822204589844, Neurons: 11, Grad norm: 8.377e+00\n",
      "Epoch 20344, Loss: 139.50244140625, Neurons: 11, Grad norm: 8.280e+00\n",
      "Epoch 20345, Loss: 139.436767578125, Neurons: 11, Grad norm: 8.350e+00\n",
      "Epoch 20346, Loss: 139.37123107910156, Neurons: 11, Grad norm: 8.266e+00\n",
      "Epoch 20347, Loss: 139.30580139160156, Neurons: 11, Grad norm: 8.351e+00\n",
      "Epoch 20348, Loss: 139.240478515625, Neurons: 11, Grad norm: 8.219e+00\n",
      "Epoch 20349, Loss: 139.1752471923828, Neurons: 11, Grad norm: 8.321e+00\n",
      "Epoch 20349, Test loss: 136.32469177246094\n",
      "Epoch 20350, Loss: 139.11012268066406, Neurons: 11, Grad norm: 8.186e+00\n",
      "Epoch 20351, Loss: 139.0450897216797, Neurons: 11, Grad norm: 8.400e+00\n",
      "Epoch 20352, Loss: 138.980224609375, Neurons: 11, Grad norm: 8.169e+00\n",
      "Epoch 20353, Loss: 138.9154052734375, Neurons: 11, Grad norm: 8.452e+00\n",
      "Epoch 20354, Loss: 138.85072326660156, Neurons: 11, Grad norm: 8.164e+00\n",
      "Epoch 20355, Loss: 138.78614807128906, Neurons: 11, Grad norm: 8.521e+00\n",
      "Epoch 20356, Loss: 138.7217254638672, Neurons: 11, Grad norm: 8.193e+00\n",
      "Epoch 20357, Loss: 138.65733337402344, Neurons: 11, Grad norm: 8.741e+00\n",
      "Epoch 20358, Loss: 138.59312438964844, Neurons: 11, Grad norm: 8.218e+00\n",
      "Epoch 20359, Loss: 138.5289764404297, Neurons: 11, Grad norm: 8.666e+00\n",
      "Epoch 20360, Loss: 138.46495056152344, Neurons: 11, Grad norm: 8.243e+00\n",
      "Epoch 20361, Loss: 138.40101623535156, Neurons: 11, Grad norm: 8.864e+00\n",
      "Epoch 20362, Loss: 138.33724975585938, Neurons: 11, Grad norm: 8.400e+00\n",
      "Epoch 20363, Loss: 138.27352905273438, Neurons: 11, Grad norm: 9.250e+00\n",
      "Epoch 20364, Loss: 138.20994567871094, Neurons: 11, Grad norm: 8.678e+00\n",
      "Epoch 20365, Loss: 138.14646911621094, Neurons: 11, Grad norm: 9.655e+00\n",
      "Epoch 20366, Loss: 138.0831298828125, Neurons: 11, Grad norm: 9.157e+00\n",
      "Epoch 20367, Loss: 138.0198974609375, Neurons: 11, Grad norm: 1.041e+01\n",
      "Epoch 20368, Loss: 137.95677185058594, Neurons: 11, Grad norm: 9.533e+00\n",
      "Epoch 20369, Loss: 137.89376831054688, Neurons: 11, Grad norm: 1.064e+01\n",
      "Epoch 20370, Loss: 137.8308563232422, Neurons: 11, Grad norm: 9.674e+00\n",
      "Epoch 20371, Loss: 137.76805114746094, Neurons: 11, Grad norm: 1.041e+01\n",
      "Epoch 20372, Loss: 137.70535278320312, Neurons: 11, Grad norm: 9.038e+00\n",
      "Epoch 20373, Loss: 137.64271545410156, Neurons: 11, Grad norm: 9.142e+00\n",
      "Epoch 20374, Loss: 137.5802764892578, Neurons: 11, Grad norm: 7.988e+00\n",
      "Epoch 20375, Loss: 137.5178680419922, Neurons: 11, Grad norm: 7.945e+00\n",
      "Epoch 20376, Loss: 137.45562744140625, Neurons: 11, Grad norm: 8.083e+00\n",
      "Epoch 20377, Loss: 137.39352416992188, Neurons: 11, Grad norm: 8.018e+00\n",
      "Epoch 20378, Loss: 137.3314971923828, Neurons: 11, Grad norm: 9.001e+00\n",
      "Epoch 20379, Loss: 137.2695770263672, Neurons: 11, Grad norm: 8.516e+00\n",
      "Epoch 20380, Loss: 137.20779418945312, Neurons: 11, Grad norm: 9.321e+00\n",
      "Epoch 20381, Loss: 137.14610290527344, Neurons: 11, Grad norm: 8.452e+00\n",
      "Epoch 20382, Loss: 137.08447265625, Neurons: 11, Grad norm: 8.750e+00\n",
      "Epoch 20383, Loss: 137.0229949951172, Neurons: 11, Grad norm: 7.927e+00\n",
      "Epoch 20384, Loss: 136.9615936279297, Neurons: 11, Grad norm: 8.034e+00\n",
      "Epoch 20385, Loss: 136.9003143310547, Neurons: 11, Grad norm: 7.826e+00\n",
      "Epoch 20386, Loss: 136.83912658691406, Neurons: 11, Grad norm: 7.801e+00\n",
      "Epoch 20387, Loss: 136.77809143066406, Neurons: 11, Grad norm: 8.263e+00\n",
      "Epoch 20388, Loss: 136.7171173095703, Neurons: 11, Grad norm: 7.972e+00\n",
      "Epoch 20389, Loss: 136.65626525878906, Neurons: 11, Grad norm: 8.592e+00\n",
      "Epoch 20390, Loss: 136.59555053710938, Neurons: 11, Grad norm: 7.946e+00\n",
      "Epoch 20391, Loss: 136.53492736816406, Neurons: 11, Grad norm: 8.314e+00\n",
      "Epoch 20392, Loss: 136.47439575195312, Neurons: 11, Grad norm: 7.801e+00\n",
      "Epoch 20393, Loss: 136.4139404296875, Neurons: 11, Grad norm: 7.916e+00\n",
      "Epoch 20394, Loss: 136.35365295410156, Neurons: 11, Grad norm: 7.657e+00\n",
      "Epoch 20395, Loss: 136.29342651367188, Neurons: 11, Grad norm: 7.649e+00\n",
      "Epoch 20396, Loss: 136.23329162597656, Neurons: 11, Grad norm: 7.820e+00\n",
      "Epoch 20397, Loss: 136.17330932617188, Neurons: 11, Grad norm: 7.642e+00\n",
      "Epoch 20398, Loss: 136.1134033203125, Neurons: 11, Grad norm: 7.855e+00\n",
      "Epoch 20399, Loss: 136.05360412597656, Neurons: 11, Grad norm: 7.632e+00\n",
      "Epoch 20399, Test loss: 133.13218688964844\n",
      "Epoch 20400, Loss: 135.99392700195312, Neurons: 11, Grad norm: 7.949e+00\n",
      "Epoch 20401, Loss: 135.934326171875, Neurons: 11, Grad norm: 7.606e+00\n",
      "Epoch 20402, Loss: 135.87484741210938, Neurons: 11, Grad norm: 7.786e+00\n",
      "Epoch 20403, Loss: 135.8154754638672, Neurons: 11, Grad norm: 7.545e+00\n",
      "Epoch 20404, Loss: 135.75619506835938, Neurons: 11, Grad norm: 7.602e+00\n",
      "Epoch 20405, Loss: 135.697021484375, Neurons: 11, Grad norm: 7.547e+00\n",
      "Epoch 20406, Loss: 135.63796997070312, Neurons: 11, Grad norm: 7.532e+00\n",
      "Epoch 20407, Loss: 135.57899475097656, Neurons: 11, Grad norm: 7.574e+00\n",
      "Epoch 20408, Loss: 135.52017211914062, Neurons: 11, Grad norm: 7.477e+00\n",
      "Epoch 20409, Loss: 135.46139526367188, Neurons: 11, Grad norm: 7.631e+00\n",
      "Epoch 20410, Loss: 135.40272521972656, Neurons: 11, Grad norm: 7.477e+00\n",
      "Epoch 20411, Loss: 135.34420776367188, Neurons: 11, Grad norm: 7.623e+00\n",
      "Epoch 20412, Loss: 135.2857666015625, Neurons: 11, Grad norm: 7.444e+00\n",
      "Epoch 20413, Loss: 135.22740173339844, Neurons: 11, Grad norm: 7.539e+00\n",
      "Epoch 20414, Loss: 135.16915893554688, Neurons: 11, Grad norm: 7.414e+00\n",
      "Epoch 20415, Loss: 135.11105346679688, Neurons: 11, Grad norm: 7.494e+00\n",
      "Epoch 20416, Loss: 135.05300903320312, Neurons: 11, Grad norm: 7.399e+00\n",
      "Epoch 20417, Loss: 134.9950714111328, Neurons: 11, Grad norm: 7.439e+00\n",
      "Epoch 20418, Loss: 134.93722534179688, Neurons: 11, Grad norm: 7.386e+00\n",
      "Epoch 20419, Loss: 134.87950134277344, Neurons: 11, Grad norm: 7.374e+00\n",
      "Epoch 20420, Loss: 134.82186889648438, Neurons: 11, Grad norm: 7.393e+00\n",
      "Epoch 20421, Loss: 134.7643280029297, Neurons: 11, Grad norm: 7.354e+00\n",
      "Epoch 20422, Loss: 134.70692443847656, Neurons: 11, Grad norm: 7.405e+00\n",
      "Epoch 20423, Loss: 134.64959716796875, Neurons: 11, Grad norm: 7.312e+00\n",
      "Epoch 20424, Loss: 134.59239196777344, Neurons: 11, Grad norm: 7.424e+00\n",
      "Epoch 20425, Loss: 134.5352783203125, Neurons: 11, Grad norm: 7.304e+00\n",
      "Epoch 20426, Loss: 134.47824096679688, Neurons: 11, Grad norm: 7.464e+00\n",
      "Epoch 20427, Loss: 134.4213409423828, Neurons: 11, Grad norm: 7.274e+00\n",
      "Epoch 20428, Loss: 134.364501953125, Neurons: 11, Grad norm: 7.396e+00\n",
      "Epoch 20429, Loss: 134.30780029296875, Neurons: 11, Grad norm: 7.247e+00\n",
      "Epoch 20430, Loss: 134.25119018554688, Neurons: 11, Grad norm: 7.395e+00\n",
      "Epoch 20431, Loss: 134.19467163085938, Neurons: 11, Grad norm: 7.239e+00\n",
      "Epoch 20432, Loss: 134.13827514648438, Neurons: 11, Grad norm: 7.431e+00\n",
      "Epoch 20433, Loss: 134.08197021484375, Neurons: 11, Grad norm: 7.210e+00\n",
      "Epoch 20434, Loss: 134.0257568359375, Neurons: 11, Grad norm: 7.291e+00\n",
      "Epoch 20435, Loss: 133.96961975097656, Neurons: 11, Grad norm: 7.178e+00\n",
      "Epoch 20436, Loss: 133.9136199951172, Neurons: 11, Grad norm: 7.302e+00\n",
      "Epoch 20437, Loss: 133.8577423095703, Neurons: 11, Grad norm: 7.163e+00\n",
      "Epoch 20438, Loss: 133.80189514160156, Neurons: 11, Grad norm: 7.292e+00\n",
      "Epoch 20439, Loss: 133.74620056152344, Neurons: 11, Grad norm: 7.138e+00\n",
      "Epoch 20440, Loss: 133.6906280517578, Neurons: 11, Grad norm: 7.232e+00\n",
      "Epoch 20441, Loss: 133.6350860595703, Neurons: 11, Grad norm: 7.122e+00\n",
      "Epoch 20442, Loss: 133.57968139648438, Neurons: 11, Grad norm: 7.353e+00\n",
      "Epoch 20443, Loss: 133.52438354492188, Neurons: 11, Grad norm: 7.174e+00\n",
      "Epoch 20444, Loss: 133.46917724609375, Neurons: 11, Grad norm: 7.442e+00\n",
      "Epoch 20445, Loss: 133.41409301757812, Neurons: 11, Grad norm: 7.231e+00\n",
      "Epoch 20446, Loss: 133.3590545654297, Neurons: 11, Grad norm: 7.592e+00\n",
      "Epoch 20447, Loss: 133.3041534423828, Neurons: 11, Grad norm: 7.339e+00\n",
      "Epoch 20448, Loss: 133.2493438720703, Neurons: 11, Grad norm: 7.864e+00\n",
      "Epoch 20449, Loss: 133.19464111328125, Neurons: 11, Grad norm: 7.530e+00\n",
      "Epoch 20449, Test loss: 130.20657348632812\n",
      "Epoch 20450, Loss: 133.1400146484375, Neurons: 11, Grad norm: 8.082e+00\n",
      "Epoch 20451, Loss: 133.08555603027344, Neurons: 11, Grad norm: 7.742e+00\n",
      "Epoch 20452, Loss: 133.0311279296875, Neurons: 11, Grad norm: 8.295e+00\n",
      "Epoch 20453, Loss: 132.97682189941406, Neurons: 11, Grad norm: 7.999e+00\n",
      "Epoch 20454, Loss: 132.92262268066406, Neurons: 11, Grad norm: 8.845e+00\n",
      "Epoch 20455, Loss: 132.86851501464844, Neurons: 11, Grad norm: 8.340e+00\n",
      "Epoch 20456, Loss: 132.8145294189453, Neurons: 11, Grad norm: 9.033e+00\n",
      "Epoch 20457, Loss: 132.7606658935547, Neurons: 11, Grad norm: 8.643e+00\n",
      "Epoch 20458, Loss: 132.70681762695312, Neurons: 11, Grad norm: 9.172e+00\n",
      "Epoch 20459, Loss: 132.6531524658203, Neurons: 11, Grad norm: 8.411e+00\n",
      "Epoch 20460, Loss: 132.59954833984375, Neurons: 11, Grad norm: 8.812e+00\n",
      "Epoch 20461, Loss: 132.54603576660156, Neurons: 11, Grad norm: 7.880e+00\n",
      "Epoch 20462, Loss: 132.49261474609375, Neurons: 11, Grad norm: 7.832e+00\n",
      "Epoch 20463, Loss: 132.43931579589844, Neurons: 11, Grad norm: 7.156e+00\n",
      "Epoch 20464, Loss: 132.38612365722656, Neurons: 11, Grad norm: 7.112e+00\n",
      "Epoch 20465, Loss: 132.33303833007812, Neurons: 11, Grad norm: 6.860e+00\n",
      "Epoch 20466, Loss: 132.28001403808594, Neurons: 11, Grad norm: 6.839e+00\n",
      "Epoch 20467, Loss: 132.2271270751953, Neurons: 11, Grad norm: 7.159e+00\n",
      "Epoch 20468, Loss: 132.17431640625, Neurons: 11, Grad norm: 7.179e+00\n",
      "Epoch 20469, Loss: 132.1216278076172, Neurons: 11, Grad norm: 7.734e+00\n",
      "Epoch 20470, Loss: 132.0690155029297, Neurons: 11, Grad norm: 7.403e+00\n",
      "Epoch 20471, Loss: 132.01649475097656, Neurons: 11, Grad norm: 7.940e+00\n",
      "Epoch 20472, Loss: 131.96408081054688, Neurons: 11, Grad norm: 7.394e+00\n",
      "Epoch 20473, Loss: 131.91177368164062, Neurons: 11, Grad norm: 7.445e+00\n",
      "Epoch 20474, Loss: 131.8595428466797, Neurons: 11, Grad norm: 7.076e+00\n",
      "Epoch 20475, Loss: 131.8074493408203, Neurons: 11, Grad norm: 7.193e+00\n",
      "Epoch 20476, Loss: 131.75540161132812, Neurons: 11, Grad norm: 6.754e+00\n",
      "Epoch 20477, Loss: 131.70346069335938, Neurons: 11, Grad norm: 6.759e+00\n",
      "Epoch 20478, Loss: 131.65159606933594, Neurons: 11, Grad norm: 6.712e+00\n",
      "Epoch 20479, Loss: 131.5998992919922, Neurons: 11, Grad norm: 6.695e+00\n",
      "Epoch 20480, Loss: 131.5482177734375, Neurons: 11, Grad norm: 6.787e+00\n",
      "Epoch 20481, Loss: 131.4967041015625, Neurons: 11, Grad norm: 6.687e+00\n",
      "Epoch 20482, Loss: 131.44525146484375, Neurons: 11, Grad norm: 6.898e+00\n",
      "Epoch 20483, Loss: 131.39389038085938, Neurons: 11, Grad norm: 6.775e+00\n",
      "Epoch 20484, Loss: 131.34262084960938, Neurons: 11, Grad norm: 6.938e+00\n",
      "Epoch 20485, Loss: 131.29147338867188, Neurons: 11, Grad norm: 6.753e+00\n",
      "Epoch 20486, Loss: 131.2404022216797, Neurons: 11, Grad norm: 6.984e+00\n",
      "Epoch 20487, Loss: 131.1894073486328, Neurons: 11, Grad norm: 6.744e+00\n",
      "Epoch 20488, Loss: 131.13851928710938, Neurons: 11, Grad norm: 6.821e+00\n",
      "Epoch 20489, Loss: 131.08775329589844, Neurons: 11, Grad norm: 6.659e+00\n",
      "Epoch 20490, Loss: 131.0370635986328, Neurons: 11, Grad norm: 6.827e+00\n",
      "Epoch 20491, Loss: 130.9864501953125, Neurons: 11, Grad norm: 6.626e+00\n",
      "Epoch 20492, Loss: 130.93594360351562, Neurons: 11, Grad norm: 6.737e+00\n",
      "Epoch 20493, Loss: 130.88551330566406, Neurons: 11, Grad norm: 6.571e+00\n",
      "Epoch 20494, Loss: 130.83518981933594, Neurons: 11, Grad norm: 6.587e+00\n",
      "Epoch 20495, Loss: 130.7849578857422, Neurons: 11, Grad norm: 6.520e+00\n",
      "Epoch 20496, Loss: 130.73483276367188, Neurons: 11, Grad norm: 6.561e+00\n",
      "Epoch 20497, Loss: 130.68479919433594, Neurons: 11, Grad norm: 6.505e+00\n",
      "Epoch 20498, Loss: 130.63485717773438, Neurons: 11, Grad norm: 6.495e+00\n",
      "Epoch 20499, Loss: 130.58499145507812, Neurons: 11, Grad norm: 6.486e+00\n",
      "Epoch 20499, Test loss: 127.5239486694336\n",
      "Epoch 20500, Loss: 130.53524780273438, Neurons: 11, Grad norm: 6.478e+00\n",
      "Epoch 20501, Loss: 130.48556518554688, Neurons: 11, Grad norm: 6.544e+00\n",
      "Epoch 20502, Loss: 130.4359893798828, Neurons: 11, Grad norm: 6.465e+00\n",
      "Epoch 20503, Loss: 130.38648986816406, Neurons: 11, Grad norm: 6.526e+00\n",
      "Epoch 20504, Loss: 130.3371124267578, Neurons: 11, Grad norm: 6.458e+00\n",
      "Epoch 20505, Loss: 130.2877960205078, Neurons: 11, Grad norm: 6.537e+00\n",
      "Epoch 20506, Loss: 130.23861694335938, Neurons: 11, Grad norm: 6.430e+00\n",
      "Epoch 20507, Loss: 130.1894989013672, Neurons: 11, Grad norm: 6.611e+00\n",
      "Epoch 20508, Loss: 130.14047241210938, Neurons: 11, Grad norm: 6.491e+00\n",
      "Epoch 20509, Loss: 130.0915069580078, Neurons: 11, Grad norm: 6.573e+00\n",
      "Epoch 20510, Loss: 130.04269409179688, Neurons: 11, Grad norm: 6.484e+00\n",
      "Epoch 20511, Loss: 129.9939422607422, Neurons: 11, Grad norm: 6.672e+00\n",
      "Epoch 20512, Loss: 129.94529724121094, Neurons: 11, Grad norm: 6.499e+00\n",
      "Epoch 20513, Loss: 129.896728515625, Neurons: 11, Grad norm: 6.800e+00\n",
      "Epoch 20514, Loss: 129.8482666015625, Neurons: 11, Grad norm: 6.744e+00\n",
      "Epoch 20515, Loss: 129.7998809814453, Neurons: 11, Grad norm: 6.973e+00\n",
      "Epoch 20516, Loss: 129.75160217285156, Neurons: 11, Grad norm: 6.889e+00\n",
      "Epoch 20517, Loss: 129.70338439941406, Neurons: 11, Grad norm: 7.397e+00\n",
      "Epoch 20518, Loss: 129.6553192138672, Neurons: 11, Grad norm: 7.269e+00\n",
      "Epoch 20519, Loss: 129.6072998046875, Neurons: 11, Grad norm: 7.789e+00\n",
      "Epoch 20520, Loss: 129.5594024658203, Neurons: 11, Grad norm: 7.871e+00\n",
      "Epoch 20521, Loss: 129.5115509033203, Neurons: 11, Grad norm: 8.572e+00\n",
      "Epoch 20522, Loss: 129.46385192871094, Neurons: 11, Grad norm: 8.499e+00\n",
      "Epoch 20523, Loss: 129.41619873046875, Neurons: 11, Grad norm: 9.287e+00\n",
      "Epoch 20524, Loss: 129.36865234375, Neurons: 11, Grad norm: 9.274e+00\n",
      "Epoch 20525, Loss: 129.32119750976562, Neurons: 11, Grad norm: 9.700e+00\n",
      "Epoch 20526, Loss: 129.27386474609375, Neurons: 11, Grad norm: 9.277e+00\n",
      "Epoch 20527, Loss: 129.22662353515625, Neurons: 11, Grad norm: 9.350e+00\n",
      "Epoch 20528, Loss: 129.1793975830078, Neurons: 11, Grad norm: 8.319e+00\n",
      "Epoch 20529, Loss: 129.13232421875, Neurons: 11, Grad norm: 7.738e+00\n",
      "Epoch 20530, Loss: 129.08531188964844, Neurons: 11, Grad norm: 6.782e+00\n",
      "Epoch 20531, Loss: 129.0383758544922, Neurons: 11, Grad norm: 6.344e+00\n",
      "Epoch 20532, Loss: 128.9915771484375, Neurons: 11, Grad norm: 6.170e+00\n",
      "Epoch 20533, Loss: 128.94483947753906, Neurons: 11, Grad norm: 6.303e+00\n",
      "Epoch 20534, Loss: 128.89822387695312, Neurons: 11, Grad norm: 6.774e+00\n",
      "Epoch 20535, Loss: 128.8516845703125, Neurons: 11, Grad norm: 6.977e+00\n",
      "Epoch 20536, Loss: 128.8052520751953, Neurons: 11, Grad norm: 7.579e+00\n",
      "Epoch 20537, Loss: 128.7589111328125, Neurons: 11, Grad norm: 7.271e+00\n",
      "Epoch 20538, Loss: 128.712646484375, Neurons: 11, Grad norm: 7.334e+00\n",
      "Epoch 20539, Loss: 128.6664581298828, Neurons: 11, Grad norm: 6.845e+00\n",
      "Epoch 20540, Loss: 128.62039184570312, Neurons: 11, Grad norm: 6.565e+00\n",
      "Epoch 20541, Loss: 128.5743408203125, Neurons: 11, Grad norm: 6.164e+00\n",
      "Epoch 20542, Loss: 128.52842712402344, Neurons: 11, Grad norm: 6.114e+00\n",
      "Epoch 20543, Loss: 128.48260498046875, Neurons: 11, Grad norm: 6.025e+00\n",
      "Epoch 20544, Loss: 128.43687438964844, Neurons: 11, Grad norm: 6.051e+00\n",
      "Epoch 20545, Loss: 128.39122009277344, Neurons: 11, Grad norm: 6.151e+00\n",
      "Epoch 20546, Loss: 128.34567260742188, Neurons: 11, Grad norm: 6.115e+00\n",
      "Epoch 20547, Loss: 128.3001708984375, Neurons: 11, Grad norm: 6.407e+00\n",
      "Epoch 20548, Loss: 128.2548065185547, Neurons: 11, Grad norm: 6.282e+00\n",
      "Epoch 20549, Loss: 128.20950317382812, Neurons: 11, Grad norm: 6.260e+00\n",
      "Epoch 20549, Test loss: 125.08478546142578\n",
      "Epoch 20550, Loss: 128.16429138183594, Neurons: 11, Grad norm: 6.146e+00\n",
      "Epoch 20551, Loss: 128.11912536621094, Neurons: 11, Grad norm: 6.156e+00\n",
      "Epoch 20552, Loss: 128.07412719726562, Neurons: 11, Grad norm: 5.978e+00\n",
      "Epoch 20553, Loss: 128.02914428710938, Neurons: 11, Grad norm: 6.008e+00\n",
      "Epoch 20554, Loss: 127.98426818847656, Neurons: 11, Grad norm: 5.969e+00\n",
      "Epoch 20555, Loss: 127.93946838378906, Neurons: 11, Grad norm: 5.921e+00\n",
      "Epoch 20556, Loss: 127.894775390625, Neurons: 11, Grad norm: 5.908e+00\n",
      "Epoch 20557, Loss: 127.85017395019531, Neurons: 11, Grad norm: 5.884e+00\n",
      "Epoch 20558, Loss: 127.80564880371094, Neurons: 11, Grad norm: 5.938e+00\n",
      "Epoch 20559, Loss: 127.76119995117188, Neurons: 11, Grad norm: 5.948e+00\n",
      "Epoch 20560, Loss: 127.7168197631836, Neurons: 11, Grad norm: 5.945e+00\n",
      "Epoch 20561, Loss: 127.67254638671875, Neurons: 11, Grad norm: 5.900e+00\n",
      "Epoch 20562, Loss: 127.62834930419922, Neurons: 11, Grad norm: 5.968e+00\n",
      "Epoch 20563, Loss: 127.58425903320312, Neurons: 11, Grad norm: 5.879e+00\n",
      "Epoch 20564, Loss: 127.54022216796875, Neurons: 11, Grad norm: 5.930e+00\n",
      "Epoch 20565, Loss: 127.49629974365234, Neurons: 11, Grad norm: 5.962e+00\n",
      "Epoch 20566, Loss: 127.45246124267578, Neurons: 11, Grad norm: 5.953e+00\n",
      "Epoch 20567, Loss: 127.40868377685547, Neurons: 11, Grad norm: 5.856e+00\n",
      "Epoch 20568, Loss: 127.36499786376953, Neurons: 11, Grad norm: 5.912e+00\n",
      "Epoch 20569, Loss: 127.32139587402344, Neurons: 11, Grad norm: 5.819e+00\n",
      "Epoch 20570, Loss: 127.27786254882812, Neurons: 11, Grad norm: 5.773e+00\n",
      "Epoch 20571, Loss: 127.23444366455078, Neurons: 11, Grad norm: 5.752e+00\n",
      "Epoch 20572, Loss: 127.19107055664062, Neurons: 11, Grad norm: 5.762e+00\n",
      "Epoch 20573, Loss: 127.14783477783203, Neurons: 11, Grad norm: 5.738e+00\n",
      "Epoch 20574, Loss: 127.1046371459961, Neurons: 11, Grad norm: 5.726e+00\n",
      "Epoch 20575, Loss: 127.0615234375, Neurons: 11, Grad norm: 5.727e+00\n",
      "Epoch 20576, Loss: 127.0185317993164, Neurons: 11, Grad norm: 5.754e+00\n",
      "Epoch 20577, Loss: 126.9755859375, Neurons: 11, Grad norm: 5.790e+00\n",
      "Epoch 20578, Loss: 126.93274688720703, Neurons: 11, Grad norm: 5.729e+00\n",
      "Epoch 20579, Loss: 126.88996887207031, Neurons: 11, Grad norm: 5.775e+00\n",
      "Epoch 20580, Loss: 126.84727478027344, Neurons: 11, Grad norm: 5.750e+00\n",
      "Epoch 20581, Loss: 126.80467224121094, Neurons: 11, Grad norm: 5.692e+00\n",
      "Epoch 20582, Loss: 126.76214599609375, Neurons: 11, Grad norm: 5.677e+00\n",
      "Epoch 20583, Loss: 126.71968078613281, Neurons: 11, Grad norm: 5.748e+00\n",
      "Epoch 20584, Loss: 126.6773452758789, Neurons: 11, Grad norm: 5.700e+00\n",
      "Epoch 20585, Loss: 126.63507080078125, Neurons: 11, Grad norm: 5.720e+00\n",
      "Epoch 20586, Loss: 126.59284973144531, Neurons: 11, Grad norm: 5.790e+00\n",
      "Epoch 20587, Loss: 126.55074310302734, Neurons: 11, Grad norm: 5.778e+00\n",
      "Epoch 20588, Loss: 126.50868225097656, Neurons: 11, Grad norm: 5.753e+00\n",
      "Epoch 20589, Loss: 126.46675872802734, Neurons: 11, Grad norm: 6.000e+00\n",
      "Epoch 20590, Loss: 126.42489624023438, Neurons: 11, Grad norm: 6.033e+00\n",
      "Epoch 20591, Loss: 126.38311004638672, Neurons: 11, Grad norm: 6.072e+00\n",
      "Epoch 20592, Loss: 126.34138488769531, Neurons: 11, Grad norm: 6.482e+00\n",
      "Epoch 20593, Loss: 126.29975891113281, Neurons: 11, Grad norm: 6.912e+00\n",
      "Epoch 20594, Loss: 126.25823211669922, Neurons: 11, Grad norm: 6.865e+00\n",
      "Epoch 20595, Loss: 126.21678161621094, Neurons: 11, Grad norm: 7.280e+00\n",
      "Epoch 20596, Loss: 126.17539978027344, Neurons: 11, Grad norm: 8.080e+00\n",
      "Epoch 20597, Loss: 126.13412475585938, Neurons: 11, Grad norm: 8.600e+00\n",
      "Epoch 20598, Loss: 126.0929183959961, Neurons: 11, Grad norm: 9.255e+00\n",
      "Epoch 20599, Loss: 126.05181121826172, Neurons: 11, Grad norm: 1.030e+01\n",
      "Epoch 20599, Test loss: 122.87313079833984\n",
      "Epoch 20600, Loss: 126.01081848144531, Neurons: 11, Grad norm: 1.059e+01\n",
      "Epoch 20601, Loss: 125.96985626220703, Neurons: 11, Grad norm: 1.043e+01\n",
      "Epoch 20602, Loss: 125.92897033691406, Neurons: 11, Grad norm: 1.045e+01\n",
      "Epoch 20603, Loss: 125.88816833496094, Neurons: 11, Grad norm: 9.615e+00\n",
      "Epoch 20604, Loss: 125.8474349975586, Neurons: 11, Grad norm: 8.074e+00\n",
      "Epoch 20605, Loss: 125.8067855834961, Neurons: 11, Grad norm: 6.715e+00\n",
      "Epoch 20606, Loss: 125.76618194580078, Neurons: 11, Grad norm: 5.742e+00\n",
      "Epoch 20607, Loss: 125.72570037841797, Neurons: 11, Grad norm: 5.486e+00\n",
      "Epoch 20608, Loss: 125.68533325195312, Neurons: 11, Grad norm: 6.186e+00\n",
      "Epoch 20609, Loss: 125.64501953125, Neurons: 11, Grad norm: 7.097e+00\n",
      "Epoch 20610, Loss: 125.60482025146484, Neurons: 11, Grad norm: 7.857e+00\n",
      "Epoch 20611, Loss: 125.5647201538086, Neurons: 11, Grad norm: 8.049e+00\n",
      "Epoch 20612, Loss: 125.5246353149414, Neurons: 11, Grad norm: 7.730e+00\n",
      "Epoch 20613, Loss: 125.48467254638672, Neurons: 11, Grad norm: 7.199e+00\n",
      "Epoch 20614, Loss: 125.44474792480469, Neurons: 11, Grad norm: 6.350e+00\n",
      "Epoch 20615, Loss: 125.40489959716797, Neurons: 11, Grad norm: 5.662e+00\n",
      "Epoch 20616, Loss: 125.3651351928711, Neurons: 11, Grad norm: 5.335e+00\n",
      "Epoch 20617, Loss: 125.32544708251953, Neurons: 11, Grad norm: 5.461e+00\n",
      "Epoch 20618, Loss: 125.28587341308594, Neurons: 11, Grad norm: 6.036e+00\n",
      "Epoch 20619, Loss: 125.24638366699219, Neurons: 11, Grad norm: 6.366e+00\n",
      "Epoch 20620, Loss: 125.20696258544922, Neurons: 11, Grad norm: 6.395e+00\n",
      "Epoch 20621, Loss: 125.16761016845703, Neurons: 11, Grad norm: 6.201e+00\n",
      "Epoch 20622, Loss: 125.12833404541016, Neurons: 11, Grad norm: 5.998e+00\n",
      "Epoch 20623, Loss: 125.08911895751953, Neurons: 11, Grad norm: 5.531e+00\n",
      "Epoch 20624, Loss: 125.04998779296875, Neurons: 11, Grad norm: 5.290e+00\n",
      "Epoch 20625, Loss: 125.01092529296875, Neurons: 11, Grad norm: 5.265e+00\n",
      "Epoch 20626, Loss: 124.9719467163086, Neurons: 11, Grad norm: 5.325e+00\n",
      "Epoch 20627, Loss: 124.9330825805664, Neurons: 11, Grad norm: 5.575e+00\n",
      "Epoch 20628, Loss: 124.89424896240234, Neurons: 11, Grad norm: 5.735e+00\n",
      "Epoch 20629, Loss: 124.85549926757812, Neurons: 11, Grad norm: 5.928e+00\n",
      "Epoch 20630, Loss: 124.81684875488281, Neurons: 11, Grad norm: 5.788e+00\n",
      "Epoch 20631, Loss: 124.77827453613281, Neurons: 11, Grad norm: 5.704e+00\n",
      "Epoch 20632, Loss: 124.7397232055664, Neurons: 11, Grad norm: 5.417e+00\n",
      "Epoch 20633, Loss: 124.7012939453125, Neurons: 11, Grad norm: 5.266e+00\n",
      "Epoch 20634, Loss: 124.66289520263672, Neurons: 11, Grad norm: 5.174e+00\n",
      "Epoch 20635, Loss: 124.6246109008789, Neurons: 11, Grad norm: 5.163e+00\n",
      "Epoch 20636, Loss: 124.58639526367188, Neurons: 11, Grad norm: 5.243e+00\n",
      "Epoch 20637, Loss: 124.54824829101562, Neurons: 11, Grad norm: 5.281e+00\n",
      "Epoch 20638, Loss: 124.51020050048828, Neurons: 11, Grad norm: 5.428e+00\n",
      "Epoch 20639, Loss: 124.47220611572266, Neurons: 11, Grad norm: 5.416e+00\n",
      "Epoch 20640, Loss: 124.43427276611328, Neurons: 11, Grad norm: 5.537e+00\n",
      "Epoch 20641, Loss: 124.39646911621094, Neurons: 11, Grad norm: 5.456e+00\n",
      "Epoch 20642, Loss: 124.35869598388672, Neurons: 11, Grad norm: 5.477e+00\n",
      "Epoch 20643, Loss: 124.32096862792969, Neurons: 11, Grad norm: 5.234e+00\n",
      "Epoch 20644, Loss: 124.28337097167969, Neurons: 11, Grad norm: 5.202e+00\n",
      "Epoch 20645, Loss: 124.24579620361328, Neurons: 11, Grad norm: 5.103e+00\n",
      "Epoch 20646, Loss: 124.20833587646484, Neurons: 11, Grad norm: 5.077e+00\n",
      "Epoch 20647, Loss: 124.1708984375, Neurons: 11, Grad norm: 5.064e+00\n",
      "Epoch 20648, Loss: 124.13359832763672, Neurons: 11, Grad norm: 5.052e+00\n",
      "Epoch 20649, Loss: 124.09634399414062, Neurons: 11, Grad norm: 5.077e+00\n",
      "Epoch 20649, Test loss: 120.86552429199219\n",
      "Epoch 20650, Loss: 124.05914306640625, Neurons: 11, Grad norm: 5.104e+00\n",
      "Epoch 20651, Loss: 124.02205657958984, Neurons: 11, Grad norm: 5.254e+00\n",
      "Epoch 20652, Loss: 123.9850082397461, Neurons: 11, Grad norm: 5.146e+00\n",
      "Epoch 20653, Loss: 123.94804382324219, Neurons: 11, Grad norm: 5.234e+00\n",
      "Epoch 20654, Loss: 123.91117095947266, Neurons: 11, Grad norm: 5.173e+00\n",
      "Epoch 20655, Loss: 123.87434387207031, Neurons: 11, Grad norm: 5.231e+00\n",
      "Epoch 20656, Loss: 123.83760833740234, Neurons: 11, Grad norm: 5.057e+00\n",
      "Epoch 20657, Loss: 123.80091857910156, Neurons: 11, Grad norm: 5.104e+00\n",
      "Epoch 20658, Loss: 123.76429748535156, Neurons: 11, Grad norm: 5.062e+00\n",
      "Epoch 20659, Loss: 123.727783203125, Neurons: 11, Grad norm: 5.126e+00\n",
      "Epoch 20660, Loss: 123.69132232666016, Neurons: 11, Grad norm: 4.992e+00\n",
      "Epoch 20661, Loss: 123.65492248535156, Neurons: 11, Grad norm: 5.032e+00\n",
      "Epoch 20662, Loss: 123.61860656738281, Neurons: 11, Grad norm: 4.952e+00\n",
      "Epoch 20663, Loss: 123.5823745727539, Neurons: 11, Grad norm: 4.966e+00\n",
      "Epoch 20664, Loss: 123.54617309570312, Neurons: 11, Grad norm: 4.915e+00\n",
      "Epoch 20665, Loss: 123.51007080078125, Neurons: 11, Grad norm: 4.911e+00\n",
      "Epoch 20666, Loss: 123.47403717041016, Neurons: 11, Grad norm: 4.898e+00\n",
      "Epoch 20667, Loss: 123.43807220458984, Neurons: 11, Grad norm: 4.927e+00\n",
      "Epoch 20668, Loss: 123.40218353271484, Neurons: 11, Grad norm: 4.875e+00\n",
      "Epoch 20669, Loss: 123.36637115478516, Neurons: 11, Grad norm: 4.886e+00\n",
      "Epoch 20670, Loss: 123.33061981201172, Neurons: 11, Grad norm: 4.858e+00\n",
      "Epoch 20671, Loss: 123.294921875, Neurons: 11, Grad norm: 4.867e+00\n",
      "Epoch 20672, Loss: 123.25932312011719, Neurons: 11, Grad norm: 4.864e+00\n",
      "Epoch 20673, Loss: 123.22377014160156, Neurons: 11, Grad norm: 4.836e+00\n",
      "Epoch 20674, Loss: 123.18830871582031, Neurons: 11, Grad norm: 4.832e+00\n",
      "Epoch 20675, Loss: 123.15290832519531, Neurons: 11, Grad norm: 4.844e+00\n",
      "Epoch 20676, Loss: 123.11756896972656, Neurons: 11, Grad norm: 4.810e+00\n",
      "Epoch 20677, Loss: 123.08230590820312, Neurons: 11, Grad norm: 4.818e+00\n",
      "Epoch 20678, Loss: 123.047119140625, Neurons: 11, Grad norm: 4.801e+00\n",
      "Epoch 20679, Loss: 123.0119857788086, Neurons: 11, Grad norm: 4.818e+00\n",
      "Epoch 20680, Loss: 122.97692108154297, Neurons: 11, Grad norm: 4.784e+00\n",
      "Epoch 20681, Loss: 122.94193267822266, Neurons: 11, Grad norm: 4.868e+00\n",
      "Epoch 20682, Loss: 122.90699768066406, Neurons: 11, Grad norm: 4.847e+00\n",
      "Epoch 20683, Loss: 122.87214660644531, Neurons: 11, Grad norm: 5.126e+00\n",
      "Epoch 20684, Loss: 122.83737182617188, Neurons: 11, Grad norm: 5.050e+00\n",
      "Epoch 20685, Loss: 122.80265045166016, Neurons: 11, Grad norm: 5.373e+00\n",
      "Epoch 20686, Loss: 122.76799774169922, Neurons: 11, Grad norm: 5.371e+00\n",
      "Epoch 20687, Loss: 122.73343658447266, Neurons: 11, Grad norm: 6.056e+00\n",
      "Epoch 20688, Loss: 122.69893646240234, Neurons: 11, Grad norm: 6.151e+00\n",
      "Epoch 20689, Loss: 122.66448211669922, Neurons: 11, Grad norm: 7.054e+00\n",
      "Epoch 20690, Loss: 122.6301498413086, Neurons: 11, Grad norm: 7.299e+00\n",
      "Epoch 20691, Loss: 122.5958480834961, Neurons: 11, Grad norm: 8.478e+00\n",
      "Epoch 20692, Loss: 122.5616226196289, Neurons: 11, Grad norm: 8.810e+00\n",
      "Epoch 20693, Loss: 122.52749633789062, Neurons: 11, Grad norm: 1.003e+01\n",
      "Epoch 20694, Loss: 122.49342346191406, Neurons: 11, Grad norm: 1.012e+01\n",
      "Epoch 20695, Loss: 122.45943450927734, Neurons: 11, Grad norm: 1.129e+01\n",
      "Epoch 20696, Loss: 122.42549896240234, Neurons: 11, Grad norm: 1.120e+01\n",
      "Epoch 20697, Loss: 122.39163208007812, Neurons: 11, Grad norm: 1.138e+01\n",
      "Epoch 20698, Loss: 122.3578109741211, Neurons: 11, Grad norm: 9.769e+00\n",
      "Epoch 20699, Loss: 122.32404327392578, Neurons: 11, Grad norm: 8.839e+00\n",
      "Epoch 20699, Test loss: 119.03630065917969\n",
      "Epoch 20700, Loss: 122.29034423828125, Neurons: 11, Grad norm: 6.506e+00\n",
      "Epoch 20701, Loss: 122.25669860839844, Neurons: 11, Grad norm: 5.327e+00\n",
      "Epoch 20702, Loss: 122.22314453125, Neurons: 11, Grad norm: 4.620e+00\n",
      "Epoch 20703, Loss: 122.1896743774414, Neurons: 11, Grad norm: 5.008e+00\n",
      "Epoch 20704, Loss: 122.15628814697266, Neurons: 11, Grad norm: 6.464e+00\n",
      "Epoch 20705, Loss: 122.12297058105469, Neurons: 11, Grad norm: 6.951e+00\n",
      "Epoch 20706, Loss: 122.0897445678711, Neurons: 11, Grad norm: 7.754e+00\n",
      "Epoch 20707, Loss: 122.05657196044922, Neurons: 11, Grad norm: 7.110e+00\n",
      "Epoch 20708, Loss: 122.02344512939453, Neurons: 11, Grad norm: 6.910e+00\n",
      "Epoch 20709, Loss: 121.99037170410156, Neurons: 11, Grad norm: 5.494e+00\n",
      "Epoch 20710, Loss: 121.95734405517578, Neurons: 11, Grad norm: 4.945e+00\n",
      "Epoch 20711, Loss: 121.92440795898438, Neurons: 11, Grad norm: 4.575e+00\n",
      "Epoch 20712, Loss: 121.89154815673828, Neurons: 11, Grad norm: 4.738e+00\n",
      "Epoch 20713, Loss: 121.85874938964844, Neurons: 11, Grad norm: 5.459e+00\n",
      "Epoch 20714, Loss: 121.82601928710938, Neurons: 11, Grad norm: 5.378e+00\n",
      "Epoch 20715, Loss: 121.79337310791016, Neurons: 11, Grad norm: 5.988e+00\n",
      "Epoch 20716, Loss: 121.76077270507812, Neurons: 11, Grad norm: 5.586e+00\n",
      "Epoch 20717, Loss: 121.72822570800781, Neurons: 11, Grad norm: 5.778e+00\n",
      "Epoch 20718, Loss: 121.69573211669922, Neurons: 11, Grad norm: 4.967e+00\n",
      "Epoch 20719, Loss: 121.66332244873047, Neurons: 11, Grad norm: 4.831e+00\n",
      "Epoch 20720, Loss: 121.63099670410156, Neurons: 11, Grad norm: 4.464e+00\n",
      "Epoch 20721, Loss: 121.59867095947266, Neurons: 11, Grad norm: 4.446e+00\n",
      "Epoch 20722, Loss: 121.56647491455078, Neurons: 11, Grad norm: 4.646e+00\n",
      "Epoch 20723, Loss: 121.53434753417969, Neurons: 11, Grad norm: 4.591e+00\n",
      "Epoch 20724, Loss: 121.5022201538086, Neurons: 11, Grad norm: 4.980e+00\n",
      "Epoch 20725, Loss: 121.47019958496094, Neurons: 11, Grad norm: 4.675e+00\n",
      "Epoch 20726, Loss: 121.43824768066406, Neurons: 11, Grad norm: 4.892e+00\n",
      "Epoch 20727, Loss: 121.40633392333984, Neurons: 11, Grad norm: 4.558e+00\n",
      "Epoch 20728, Loss: 121.37447357177734, Neurons: 11, Grad norm: 4.720e+00\n",
      "Epoch 20729, Loss: 121.34271240234375, Neurons: 11, Grad norm: 4.413e+00\n",
      "Epoch 20730, Loss: 121.31099700927734, Neurons: 11, Grad norm: 4.417e+00\n",
      "Epoch 20731, Loss: 121.2793197631836, Neurons: 11, Grad norm: 4.462e+00\n",
      "Epoch 20732, Loss: 121.24771881103516, Neurons: 11, Grad norm: 4.387e+00\n",
      "Epoch 20733, Loss: 121.2162094116211, Neurons: 11, Grad norm: 4.572e+00\n",
      "Epoch 20734, Loss: 121.18474578857422, Neurons: 11, Grad norm: 4.402e+00\n",
      "Epoch 20735, Loss: 121.1533432006836, Neurons: 11, Grad norm: 4.623e+00\n",
      "Epoch 20736, Loss: 121.1219711303711, Neurons: 11, Grad norm: 4.372e+00\n",
      "Epoch 20737, Loss: 121.0906982421875, Neurons: 11, Grad norm: 4.468e+00\n",
      "Epoch 20738, Loss: 121.05949401855469, Neurons: 11, Grad norm: 4.319e+00\n",
      "Epoch 20739, Loss: 121.0283203125, Neurons: 11, Grad norm: 4.414e+00\n",
      "Epoch 20740, Loss: 120.99720001220703, Neurons: 11, Grad norm: 4.300e+00\n",
      "Epoch 20741, Loss: 120.96617126464844, Neurons: 11, Grad norm: 4.327e+00\n",
      "Epoch 20742, Loss: 120.93519592285156, Neurons: 11, Grad norm: 4.329e+00\n",
      "Epoch 20743, Loss: 120.90425872802734, Neurons: 11, Grad norm: 4.277e+00\n",
      "Epoch 20744, Loss: 120.87339782714844, Neurons: 11, Grad norm: 4.323e+00\n",
      "Epoch 20745, Loss: 120.84258270263672, Neurons: 11, Grad norm: 4.273e+00\n",
      "Epoch 20746, Loss: 120.81184387207031, Neurons: 11, Grad norm: 4.295e+00\n",
      "Epoch 20747, Loss: 120.78118133544922, Neurons: 11, Grad norm: 4.269e+00\n",
      "Epoch 20748, Loss: 120.75054931640625, Neurons: 11, Grad norm: 4.263e+00\n",
      "Epoch 20749, Loss: 120.7199935913086, Neurons: 11, Grad norm: 4.243e+00\n",
      "Epoch 20749, Test loss: 117.37312316894531\n",
      "Epoch 20750, Loss: 120.68949890136719, Neurons: 11, Grad norm: 4.291e+00\n",
      "Epoch 20751, Loss: 120.65904998779297, Neurons: 11, Grad norm: 4.239e+00\n",
      "Epoch 20752, Loss: 120.628662109375, Neurons: 11, Grad norm: 4.228e+00\n",
      "Epoch 20753, Loss: 120.59835052490234, Neurons: 11, Grad norm: 4.234e+00\n",
      "Epoch 20754, Loss: 120.56808471679688, Neurons: 11, Grad norm: 4.196e+00\n",
      "Epoch 20755, Loss: 120.53787231445312, Neurons: 11, Grad norm: 4.432e+00\n",
      "Epoch 20756, Loss: 120.50773620605469, Neurons: 11, Grad norm: 4.211e+00\n",
      "Epoch 20757, Loss: 120.47764587402344, Neurons: 11, Grad norm: 4.377e+00\n",
      "Epoch 20758, Loss: 120.44762420654297, Neurons: 11, Grad norm: 4.196e+00\n",
      "Epoch 20759, Loss: 120.4176254272461, Neurons: 11, Grad norm: 4.421e+00\n",
      "Epoch 20760, Loss: 120.38774871826172, Neurons: 11, Grad norm: 4.211e+00\n",
      "Epoch 20761, Loss: 120.35789489746094, Neurons: 11, Grad norm: 4.624e+00\n",
      "Epoch 20762, Loss: 120.32809448242188, Neurons: 11, Grad norm: 4.328e+00\n",
      "Epoch 20763, Loss: 120.29834747314453, Neurons: 11, Grad norm: 4.625e+00\n",
      "Epoch 20764, Loss: 120.26866912841797, Neurons: 11, Grad norm: 4.258e+00\n",
      "Epoch 20765, Loss: 120.23907470703125, Neurons: 11, Grad norm: 4.700e+00\n",
      "Epoch 20766, Loss: 120.20951080322266, Neurons: 11, Grad norm: 4.268e+00\n",
      "Epoch 20767, Loss: 120.18000030517578, Neurons: 11, Grad norm: 4.534e+00\n",
      "Epoch 20768, Loss: 120.15055847167969, Neurons: 11, Grad norm: 4.265e+00\n",
      "Epoch 20769, Loss: 120.12117004394531, Neurons: 11, Grad norm: 4.807e+00\n",
      "Epoch 20770, Loss: 120.09185028076172, Neurons: 11, Grad norm: 4.376e+00\n",
      "Epoch 20771, Loss: 120.06256103515625, Neurons: 11, Grad norm: 4.972e+00\n",
      "Epoch 20772, Loss: 120.03333282470703, Neurons: 11, Grad norm: 4.605e+00\n",
      "Epoch 20773, Loss: 120.00419616699219, Neurons: 11, Grad norm: 5.248e+00\n",
      "Epoch 20774, Loss: 119.97509765625, Neurons: 11, Grad norm: 4.837e+00\n",
      "Epoch 20775, Loss: 119.9460220336914, Neurons: 11, Grad norm: 5.948e+00\n",
      "Epoch 20776, Loss: 119.91704559326172, Neurons: 11, Grad norm: 5.737e+00\n",
      "Epoch 20777, Loss: 119.88814544677734, Neurons: 11, Grad norm: 7.224e+00\n",
      "Epoch 20778, Loss: 119.85928344726562, Neurons: 11, Grad norm: 7.141e+00\n",
      "Epoch 20779, Loss: 119.83048248291016, Neurons: 11, Grad norm: 8.731e+00\n",
      "Epoch 20780, Loss: 119.8017349243164, Neurons: 11, Grad norm: 8.449e+00\n",
      "Epoch 20781, Loss: 119.77305603027344, Neurons: 11, Grad norm: 1.041e+01\n",
      "Epoch 20782, Loss: 119.74443817138672, Neurons: 11, Grad norm: 1.047e+01\n",
      "Epoch 20783, Loss: 119.71589660644531, Neurons: 11, Grad norm: 1.199e+01\n",
      "Epoch 20784, Loss: 119.68737030029297, Neurons: 11, Grad norm: 1.112e+01\n",
      "Epoch 20785, Loss: 119.65892028808594, Neurons: 11, Grad norm: 1.187e+01\n",
      "Epoch 20786, Loss: 119.63052368164062, Neurons: 11, Grad norm: 9.677e+00\n",
      "Epoch 20787, Loss: 119.60213470458984, Neurons: 11, Grad norm: 8.984e+00\n",
      "Epoch 20788, Loss: 119.57380676269531, Neurons: 11, Grad norm: 6.116e+00\n",
      "Epoch 20789, Loss: 119.5455322265625, Neurons: 11, Grad norm: 5.063e+00\n",
      "Epoch 20790, Loss: 119.51731872558594, Neurons: 11, Grad norm: 4.008e+00\n",
      "Epoch 20791, Loss: 119.48919677734375, Neurons: 11, Grad norm: 4.481e+00\n",
      "Epoch 20792, Loss: 119.46117401123047, Neurons: 11, Grad norm: 6.654e+00\n",
      "Epoch 20793, Loss: 119.43315887451172, Neurons: 11, Grad norm: 6.996e+00\n",
      "Epoch 20794, Loss: 119.4052734375, Neurons: 11, Grad norm: 8.570e+00\n",
      "Epoch 20795, Loss: 119.37737274169922, Neurons: 11, Grad norm: 7.500e+00\n",
      "Epoch 20796, Loss: 119.34954833984375, Neurons: 11, Grad norm: 7.742e+00\n",
      "Epoch 20797, Loss: 119.32173156738281, Neurons: 11, Grad norm: 5.777e+00\n",
      "Epoch 20798, Loss: 119.29399871826172, Neurons: 11, Grad norm: 5.519e+00\n",
      "Epoch 20799, Loss: 119.26629638671875, Neurons: 11, Grad norm: 3.989e+00\n",
      "Epoch 20799, Test loss: 115.85464477539062\n",
      "Epoch 20800, Loss: 119.2386703491211, Neurons: 11, Grad norm: 3.888e+00\n",
      "Epoch 20801, Loss: 119.21109771728516, Neurons: 11, Grad norm: 4.616e+00\n",
      "Epoch 20802, Loss: 119.18359375, Neurons: 11, Grad norm: 4.692e+00\n",
      "Epoch 20803, Loss: 119.15613555908203, Neurons: 11, Grad norm: 6.038e+00\n",
      "Epoch 20804, Loss: 119.12876892089844, Neurons: 11, Grad norm: 5.367e+00\n",
      "Epoch 20805, Loss: 119.10139465332031, Neurons: 11, Grad norm: 5.965e+00\n",
      "Epoch 20806, Loss: 119.0740966796875, Neurons: 11, Grad norm: 4.644e+00\n",
      "Epoch 20807, Loss: 119.04684448242188, Neurons: 11, Grad norm: 4.855e+00\n",
      "Epoch 20808, Loss: 119.01966857910156, Neurons: 11, Grad norm: 3.954e+00\n",
      "Epoch 20809, Loss: 118.99250030517578, Neurons: 11, Grad norm: 4.060e+00\n",
      "Epoch 20810, Loss: 118.96540069580078, Neurons: 11, Grad norm: 3.905e+00\n",
      "Epoch 20811, Loss: 118.93840026855469, Neurons: 11, Grad norm: 3.853e+00\n",
      "Epoch 20812, Loss: 118.9113998413086, Neurons: 11, Grad norm: 4.706e+00\n",
      "Epoch 20813, Loss: 118.88447570800781, Neurons: 11, Grad norm: 4.287e+00\n",
      "Epoch 20814, Loss: 118.85759735107422, Neurons: 11, Grad norm: 5.015e+00\n",
      "Epoch 20815, Loss: 118.83077239990234, Neurons: 11, Grad norm: 4.198e+00\n",
      "Epoch 20816, Loss: 118.80399322509766, Neurons: 11, Grad norm: 4.726e+00\n",
      "Epoch 20817, Loss: 118.77727508544922, Neurons: 11, Grad norm: 3.930e+00\n",
      "Epoch 20818, Loss: 118.75059509277344, Neurons: 11, Grad norm: 4.223e+00\n",
      "Epoch 20819, Loss: 118.72398376464844, Neurons: 11, Grad norm: 3.754e+00\n",
      "Epoch 20820, Loss: 118.69739532470703, Neurons: 11, Grad norm: 3.907e+00\n",
      "Epoch 20821, Loss: 118.6708755493164, Neurons: 11, Grad norm: 3.804e+00\n",
      "Epoch 20822, Loss: 118.64442443847656, Neurons: 11, Grad norm: 3.720e+00\n",
      "Epoch 20823, Loss: 118.61799621582031, Neurons: 11, Grad norm: 4.193e+00\n",
      "Epoch 20824, Loss: 118.59163665771484, Neurons: 11, Grad norm: 3.829e+00\n",
      "Epoch 20825, Loss: 118.56532287597656, Neurons: 11, Grad norm: 4.341e+00\n",
      "Epoch 20826, Loss: 118.5390625, Neurons: 11, Grad norm: 3.776e+00\n",
      "Epoch 20827, Loss: 118.51284790039062, Neurons: 11, Grad norm: 4.237e+00\n",
      "Epoch 20828, Loss: 118.48665618896484, Neurons: 11, Grad norm: 3.779e+00\n",
      "Epoch 20829, Loss: 118.4605484008789, Neurons: 11, Grad norm: 4.220e+00\n",
      "Epoch 20830, Loss: 118.4344711303711, Neurons: 11, Grad norm: 3.718e+00\n",
      "Epoch 20831, Loss: 118.40846252441406, Neurons: 11, Grad norm: 4.120e+00\n",
      "Epoch 20832, Loss: 118.38249969482422, Neurons: 11, Grad norm: 3.653e+00\n",
      "Epoch 20833, Loss: 118.35659790039062, Neurons: 11, Grad norm: 3.824e+00\n",
      "Epoch 20834, Loss: 118.33071899414062, Neurons: 11, Grad norm: 3.660e+00\n",
      "Epoch 20835, Loss: 118.30489349365234, Neurons: 11, Grad norm: 3.754e+00\n",
      "Epoch 20836, Loss: 118.27912139892578, Neurons: 11, Grad norm: 3.681e+00\n",
      "Epoch 20837, Loss: 118.2533950805664, Neurons: 11, Grad norm: 3.668e+00\n",
      "Epoch 20838, Loss: 118.22772216796875, Neurons: 11, Grad norm: 3.728e+00\n",
      "Epoch 20839, Loss: 118.20209503173828, Neurons: 11, Grad norm: 3.611e+00\n",
      "Epoch 20840, Loss: 118.17654418945312, Neurons: 11, Grad norm: 3.858e+00\n",
      "Epoch 20841, Loss: 118.1510238647461, Neurons: 11, Grad norm: 3.597e+00\n",
      "Epoch 20842, Loss: 118.12553405761719, Neurons: 11, Grad norm: 3.952e+00\n",
      "Epoch 20843, Loss: 118.10009765625, Neurons: 11, Grad norm: 3.588e+00\n",
      "Epoch 20844, Loss: 118.07469940185547, Neurons: 11, Grad norm: 3.881e+00\n",
      "Epoch 20845, Loss: 118.04936981201172, Neurons: 11, Grad norm: 3.577e+00\n",
      "Epoch 20846, Loss: 118.02408599853516, Neurons: 11, Grad norm: 3.995e+00\n",
      "Epoch 20847, Loss: 117.99884796142578, Neurons: 11, Grad norm: 3.582e+00\n",
      "Epoch 20848, Loss: 117.97364807128906, Neurons: 11, Grad norm: 3.996e+00\n",
      "Epoch 20849, Loss: 117.94854736328125, Neurons: 11, Grad norm: 3.569e+00\n",
      "Epoch 20849, Test loss: 114.47174072265625\n",
      "Epoch 20850, Loss: 117.92343139648438, Neurons: 11, Grad norm: 4.018e+00\n",
      "Epoch 20851, Loss: 117.89838409423828, Neurons: 11, Grad norm: 3.562e+00\n",
      "Epoch 20852, Loss: 117.87339782714844, Neurons: 11, Grad norm: 4.096e+00\n",
      "Epoch 20853, Loss: 117.84844970703125, Neurons: 11, Grad norm: 3.631e+00\n",
      "Epoch 20854, Loss: 117.82352447509766, Neurons: 11, Grad norm: 4.252e+00\n",
      "Epoch 20855, Loss: 117.79864501953125, Neurons: 11, Grad norm: 3.642e+00\n",
      "Epoch 20856, Loss: 117.77387237548828, Neurons: 11, Grad norm: 4.325e+00\n",
      "Epoch 20857, Loss: 117.74908447265625, Neurons: 11, Grad norm: 3.626e+00\n",
      "Epoch 20858, Loss: 117.72437286376953, Neurons: 11, Grad norm: 4.288e+00\n",
      "Epoch 20859, Loss: 117.69970703125, Neurons: 11, Grad norm: 3.697e+00\n",
      "Epoch 20860, Loss: 117.67508697509766, Neurons: 11, Grad norm: 4.616e+00\n",
      "Epoch 20861, Loss: 117.65052032470703, Neurons: 11, Grad norm: 3.961e+00\n",
      "Epoch 20862, Loss: 117.6259994506836, Neurons: 11, Grad norm: 5.188e+00\n",
      "Epoch 20863, Loss: 117.60149383544922, Neurons: 11, Grad norm: 4.413e+00\n",
      "Epoch 20864, Loss: 117.57707214355469, Neurons: 11, Grad norm: 5.732e+00\n",
      "Epoch 20865, Loss: 117.55267333984375, Neurons: 11, Grad norm: 4.898e+00\n",
      "Epoch 20866, Loss: 117.52835083007812, Neurons: 11, Grad norm: 6.688e+00\n",
      "Epoch 20867, Loss: 117.50404357910156, Neurons: 11, Grad norm: 6.282e+00\n",
      "Epoch 20868, Loss: 117.47979736328125, Neurons: 11, Grad norm: 8.719e+00\n",
      "Epoch 20869, Loss: 117.45561981201172, Neurons: 11, Grad norm: 8.387e+00\n",
      "Epoch 20870, Loss: 117.43148803710938, Neurons: 11, Grad norm: 1.087e+01\n",
      "Epoch 20871, Loss: 117.40738677978516, Neurons: 11, Grad norm: 1.058e+01\n",
      "Epoch 20872, Loss: 117.38338470458984, Neurons: 11, Grad norm: 1.319e+01\n",
      "Epoch 20873, Loss: 117.35938262939453, Neurons: 11, Grad norm: 1.235e+01\n",
      "Epoch 20874, Loss: 117.3354721069336, Neurons: 11, Grad norm: 1.428e+01\n",
      "Epoch 20875, Loss: 117.31156921386719, Neurons: 11, Grad norm: 1.281e+01\n",
      "Epoch 20876, Loss: 117.2876968383789, Neurons: 11, Grad norm: 1.311e+01\n",
      "Epoch 20877, Loss: 117.26384735107422, Neurons: 11, Grad norm: 9.336e+00\n",
      "Epoch 20878, Loss: 117.23999786376953, Neurons: 11, Grad norm: 8.194e+00\n",
      "Epoch 20879, Loss: 117.2162094116211, Neurons: 11, Grad norm: 4.122e+00\n",
      "Epoch 20880, Loss: 117.19249725341797, Neurons: 11, Grad norm: 3.377e+00\n",
      "Epoch 20881, Loss: 117.16886901855469, Neurons: 11, Grad norm: 5.439e+00\n",
      "Epoch 20882, Loss: 117.14529418945312, Neurons: 11, Grad norm: 6.202e+00\n",
      "Epoch 20883, Loss: 117.12179565429688, Neurons: 11, Grad norm: 9.202e+00\n",
      "Epoch 20884, Loss: 117.09833526611328, Neurons: 11, Grad norm: 8.284e+00\n",
      "Epoch 20885, Loss: 117.07489776611328, Neurons: 11, Grad norm: 9.186e+00\n",
      "Epoch 20886, Loss: 117.05149841308594, Neurons: 11, Grad norm: 6.582e+00\n",
      "Epoch 20887, Loss: 117.02810668945312, Neurons: 11, Grad norm: 6.245e+00\n",
      "Epoch 20888, Loss: 117.00476837158203, Neurons: 11, Grad norm: 3.446e+00\n",
      "Epoch 20889, Loss: 116.98147583007812, Neurons: 11, Grad norm: 3.314e+00\n",
      "Epoch 20890, Loss: 116.95822143554688, Neurons: 11, Grad norm: 4.592e+00\n",
      "Epoch 20891, Loss: 116.93507385253906, Neurons: 11, Grad norm: 4.688e+00\n",
      "Epoch 20892, Loss: 116.91194915771484, Neurons: 11, Grad norm: 7.023e+00\n",
      "Epoch 20893, Loss: 116.88886260986328, Neurons: 11, Grad norm: 5.578e+00\n",
      "Epoch 20894, Loss: 116.8658218383789, Neurons: 11, Grad norm: 6.530e+00\n",
      "Epoch 20895, Loss: 116.8427963256836, Neurons: 11, Grad norm: 4.735e+00\n",
      "Epoch 20896, Loss: 116.81980895996094, Neurons: 11, Grad norm: 4.952e+00\n",
      "Epoch 20897, Loss: 116.79688262939453, Neurons: 11, Grad norm: 3.279e+00\n",
      "Epoch 20898, Loss: 116.77398681640625, Neurons: 11, Grad norm: 3.358e+00\n",
      "Epoch 20899, Loss: 116.75115966796875, Neurons: 11, Grad norm: 3.774e+00\n",
      "Epoch 20899, Test loss: 113.2108154296875\n",
      "Epoch 20900, Loss: 116.72834777832031, Neurons: 11, Grad norm: 3.701e+00\n",
      "Epoch 20901, Loss: 116.70559692382812, Neurons: 11, Grad norm: 5.503e+00\n",
      "Epoch 20902, Loss: 116.68289947509766, Neurons: 11, Grad norm: 4.257e+00\n",
      "Epoch 20903, Loss: 116.66022491455078, Neurons: 11, Grad norm: 5.598e+00\n",
      "Epoch 20904, Loss: 116.6375961303711, Neurons: 11, Grad norm: 4.174e+00\n",
      "Epoch 20905, Loss: 116.61499786376953, Neurons: 11, Grad norm: 4.559e+00\n",
      "Epoch 20906, Loss: 116.59244537353516, Neurons: 11, Grad norm: 3.227e+00\n",
      "Epoch 20907, Loss: 116.5699234008789, Neurons: 11, Grad norm: 3.442e+00\n",
      "Epoch 20908, Loss: 116.54747009277344, Neurons: 11, Grad norm: 3.493e+00\n",
      "Epoch 20909, Loss: 116.5250473022461, Neurons: 11, Grad norm: 3.269e+00\n",
      "Epoch 20910, Loss: 116.5026626586914, Neurons: 11, Grad norm: 4.279e+00\n",
      "Epoch 20911, Loss: 116.48030853271484, Neurons: 11, Grad norm: 3.482e+00\n",
      "Epoch 20912, Loss: 116.45802307128906, Neurons: 11, Grad norm: 4.815e+00\n",
      "Epoch 20913, Loss: 116.43574523925781, Neurons: 11, Grad norm: 3.571e+00\n",
      "Epoch 20914, Loss: 116.41353607177734, Neurons: 11, Grad norm: 4.239e+00\n",
      "Epoch 20915, Loss: 116.39134979248047, Neurons: 11, Grad norm: 3.272e+00\n",
      "Epoch 20916, Loss: 116.36920928955078, Neurons: 11, Grad norm: 3.977e+00\n",
      "Epoch 20917, Loss: 116.34710693359375, Neurons: 11, Grad norm: 3.147e+00\n",
      "Epoch 20918, Loss: 116.32501983642578, Neurons: 11, Grad norm: 3.535e+00\n",
      "Epoch 20919, Loss: 116.30302429199219, Neurons: 11, Grad norm: 3.143e+00\n",
      "Epoch 20920, Loss: 116.28104400634766, Neurons: 11, Grad norm: 3.196e+00\n",
      "Epoch 20921, Loss: 116.25910949707031, Neurons: 11, Grad norm: 3.599e+00\n",
      "Epoch 20922, Loss: 116.23719787597656, Neurons: 11, Grad norm: 3.117e+00\n",
      "Epoch 20923, Loss: 116.21534729003906, Neurons: 11, Grad norm: 3.834e+00\n",
      "Epoch 20924, Loss: 116.19351959228516, Neurons: 11, Grad norm: 3.195e+00\n",
      "Epoch 20925, Loss: 116.17172241210938, Neurons: 11, Grad norm: 3.955e+00\n",
      "Epoch 20926, Loss: 116.14999389648438, Neurons: 11, Grad norm: 3.143e+00\n",
      "Epoch 20927, Loss: 116.1282730102539, Neurons: 11, Grad norm: 3.958e+00\n",
      "Epoch 20928, Loss: 116.10662078857422, Neurons: 11, Grad norm: 3.096e+00\n",
      "Epoch 20929, Loss: 116.08499908447266, Neurons: 11, Grad norm: 3.522e+00\n",
      "Epoch 20930, Loss: 116.06342315673828, Neurons: 11, Grad norm: 3.082e+00\n",
      "Epoch 20931, Loss: 116.0418472290039, Neurons: 11, Grad norm: 3.471e+00\n",
      "Epoch 20932, Loss: 116.02034759521484, Neurons: 11, Grad norm: 3.086e+00\n",
      "Epoch 20933, Loss: 115.99887084960938, Neurons: 11, Grad norm: 3.421e+00\n",
      "Epoch 20934, Loss: 115.97742462158203, Neurons: 11, Grad norm: 3.047e+00\n",
      "Epoch 20935, Loss: 115.95602416992188, Neurons: 11, Grad norm: 3.309e+00\n",
      "Epoch 20936, Loss: 115.9346694946289, Neurons: 11, Grad norm: 3.176e+00\n",
      "Epoch 20937, Loss: 115.91334533691406, Neurons: 11, Grad norm: 3.142e+00\n",
      "Epoch 20938, Loss: 115.89207458496094, Neurons: 11, Grad norm: 3.377e+00\n",
      "Epoch 20939, Loss: 115.87083435058594, Neurons: 11, Grad norm: 3.015e+00\n",
      "Epoch 20940, Loss: 115.8496322631836, Neurons: 11, Grad norm: 3.685e+00\n",
      "Epoch 20941, Loss: 115.82846069335938, Neurons: 11, Grad norm: 3.030e+00\n",
      "Epoch 20942, Loss: 115.80731964111328, Neurons: 11, Grad norm: 3.861e+00\n",
      "Epoch 20943, Loss: 115.78622436523438, Neurons: 11, Grad norm: 3.089e+00\n",
      "Epoch 20944, Loss: 115.76518249511719, Neurons: 11, Grad norm: 4.048e+00\n",
      "Epoch 20945, Loss: 115.74415588378906, Neurons: 11, Grad norm: 3.101e+00\n",
      "Epoch 20946, Loss: 115.72315979003906, Neurons: 11, Grad norm: 4.091e+00\n",
      "Epoch 20947, Loss: 115.70222473144531, Neurons: 11, Grad norm: 3.141e+00\n",
      "Epoch 20948, Loss: 115.68132019042969, Neurons: 11, Grad norm: 4.282e+00\n",
      "Epoch 20949, Loss: 115.66044616699219, Neurons: 11, Grad norm: 3.333e+00\n",
      "Epoch 20949, Test loss: 112.06491088867188\n",
      "Epoch 20950, Loss: 115.6396255493164, Neurons: 11, Grad norm: 4.915e+00\n",
      "Epoch 20951, Loss: 115.61882019042969, Neurons: 11, Grad norm: 3.719e+00\n",
      "Epoch 20952, Loss: 115.59806060791016, Neurons: 11, Grad norm: 5.240e+00\n",
      "Epoch 20953, Loss: 115.57732391357422, Neurons: 11, Grad norm: 3.955e+00\n",
      "Epoch 20954, Loss: 115.55664825439453, Neurons: 11, Grad norm: 5.780e+00\n",
      "Epoch 20955, Loss: 115.53601837158203, Neurons: 11, Grad norm: 4.530e+00\n",
      "Epoch 20956, Loss: 115.51539611816406, Neurons: 11, Grad norm: 6.608e+00\n",
      "Epoch 20957, Loss: 115.49481964111328, Neurons: 11, Grad norm: 5.343e+00\n",
      "Epoch 20958, Loss: 115.47427368164062, Neurons: 11, Grad norm: 7.547e+00\n",
      "Epoch 20959, Loss: 115.45378112792969, Neurons: 11, Grad norm: 6.438e+00\n",
      "Epoch 20960, Loss: 115.43331909179688, Neurons: 11, Grad norm: 9.154e+00\n",
      "Epoch 20961, Loss: 115.41293334960938, Neurons: 11, Grad norm: 8.317e+00\n",
      "Epoch 20962, Loss: 115.39254760742188, Neurons: 11, Grad norm: 1.137e+01\n",
      "Epoch 20963, Loss: 115.37222290039062, Neurons: 11, Grad norm: 1.048e+01\n",
      "Epoch 20964, Loss: 115.35192108154297, Neurons: 11, Grad norm: 1.308e+01\n",
      "Epoch 20965, Loss: 115.33167266845703, Neurons: 11, Grad norm: 1.163e+01\n",
      "Epoch 20966, Loss: 115.31144714355469, Neurons: 11, Grad norm: 1.379e+01\n",
      "Epoch 20967, Loss: 115.29124450683594, Neurons: 11, Grad norm: 1.157e+01\n",
      "Epoch 20968, Loss: 115.27107238769531, Neurons: 11, Grad norm: 1.260e+01\n",
      "Epoch 20969, Loss: 115.25092315673828, Neurons: 11, Grad norm: 9.085e+00\n",
      "Epoch 20970, Loss: 115.23079681396484, Neurons: 11, Grad norm: 8.823e+00\n",
      "Epoch 20971, Loss: 115.210693359375, Neurons: 11, Grad norm: 4.581e+00\n",
      "Epoch 20972, Loss: 115.19064331054688, Neurons: 11, Grad norm: 4.066e+00\n",
      "Epoch 20973, Loss: 115.17066955566406, Neurons: 11, Grad norm: 3.307e+00\n",
      "Epoch 20974, Loss: 115.15071868896484, Neurons: 11, Grad norm: 3.411e+00\n",
      "Epoch 20975, Loss: 115.13082122802734, Neurons: 11, Grad norm: 6.312e+00\n",
      "Epoch 20976, Loss: 115.11096954345703, Neurons: 11, Grad norm: 5.690e+00\n",
      "Epoch 20977, Loss: 115.09114837646484, Neurons: 11, Grad norm: 8.282e+00\n",
      "Epoch 20978, Loss: 115.07135009765625, Neurons: 11, Grad norm: 6.472e+00\n",
      "Epoch 20979, Loss: 115.05158233642578, Neurons: 11, Grad norm: 7.803e+00\n",
      "Epoch 20980, Loss: 115.03184509277344, Neurons: 11, Grad norm: 5.121e+00\n",
      "Epoch 20981, Loss: 115.01213836669922, Neurons: 11, Grad norm: 5.875e+00\n",
      "Epoch 20982, Loss: 114.99246215820312, Neurons: 11, Grad norm: 3.190e+00\n",
      "Epoch 20983, Loss: 114.97282409667969, Neurons: 11, Grad norm: 3.429e+00\n",
      "Epoch 20984, Loss: 114.9532241821289, Neurons: 11, Grad norm: 3.185e+00\n",
      "Epoch 20985, Loss: 114.93364715576172, Neurons: 11, Grad norm: 2.845e+00\n",
      "Epoch 20986, Loss: 114.91412353515625, Neurons: 11, Grad norm: 4.482e+00\n",
      "Epoch 20987, Loss: 114.89460754394531, Neurons: 11, Grad norm: 3.422e+00\n",
      "Epoch 20988, Loss: 114.87516021728516, Neurons: 11, Grad norm: 5.178e+00\n",
      "Epoch 20989, Loss: 114.85574340820312, Neurons: 11, Grad norm: 3.758e+00\n",
      "Epoch 20990, Loss: 114.83634948730469, Neurons: 11, Grad norm: 5.400e+00\n",
      "Epoch 20991, Loss: 114.81698608398438, Neurons: 11, Grad norm: 3.494e+00\n",
      "Epoch 20992, Loss: 114.79764556884766, Neurons: 11, Grad norm: 4.586e+00\n",
      "Epoch 20993, Loss: 114.77835083007812, Neurons: 11, Grad norm: 2.891e+00\n",
      "Epoch 20994, Loss: 114.75907135009766, Neurons: 11, Grad norm: 3.653e+00\n",
      "Epoch 20995, Loss: 114.7398452758789, Neurons: 11, Grad norm: 2.751e+00\n",
      "Epoch 20996, Loss: 114.72063446044922, Neurons: 11, Grad norm: 3.193e+00\n",
      "Epoch 20997, Loss: 114.70146942138672, Neurons: 11, Grad norm: 2.897e+00\n",
      "Epoch 20998, Loss: 114.6823501586914, Neurons: 11, Grad norm: 2.823e+00\n",
      "Epoch 20999, Loss: 114.66322326660156, Neurons: 11, Grad norm: 3.215e+00\n",
      "Epoch 20999, Test loss: 111.0210952758789\n",
      "Epoch 21000, Loss: 114.64415740966797, Neurons: 11, Grad norm: 2.736e+00\n",
      "Epoch 21001, Loss: 114.6251220703125, Neurons: 11, Grad norm: 3.290e+00\n",
      "Epoch 21002, Loss: 114.60609436035156, Neurons: 11, Grad norm: 2.747e+00\n",
      "Epoch 21003, Loss: 114.58712005615234, Neurons: 11, Grad norm: 3.180e+00\n",
      "Epoch 21004, Loss: 114.56816864013672, Neurons: 11, Grad norm: 2.763e+00\n",
      "Epoch 21005, Loss: 114.54926300048828, Neurons: 11, Grad norm: 3.142e+00\n",
      "Epoch 21006, Loss: 114.53038787841797, Neurons: 11, Grad norm: 2.750e+00\n",
      "Epoch 21007, Loss: 114.51153564453125, Neurons: 11, Grad norm: 3.085e+00\n",
      "Epoch 21008, Loss: 114.4926986694336, Neurons: 11, Grad norm: 2.818e+00\n",
      "Epoch 21009, Loss: 114.47390747070312, Neurons: 11, Grad norm: 3.053e+00\n",
      "Epoch 21010, Loss: 114.45514678955078, Neurons: 11, Grad norm: 2.723e+00\n",
      "Epoch 21011, Loss: 114.43643188476562, Neurons: 11, Grad norm: 3.238e+00\n",
      "Epoch 21012, Loss: 114.417724609375, Neurons: 11, Grad norm: 2.679e+00\n",
      "Epoch 21013, Loss: 114.3990707397461, Neurons: 11, Grad norm: 3.380e+00\n",
      "Epoch 21014, Loss: 114.38043212890625, Neurons: 11, Grad norm: 2.664e+00\n",
      "Epoch 21015, Loss: 114.36182403564453, Neurons: 11, Grad norm: 3.318e+00\n",
      "Epoch 21016, Loss: 114.34326171875, Neurons: 11, Grad norm: 2.656e+00\n",
      "Epoch 21017, Loss: 114.32470703125, Neurons: 11, Grad norm: 3.482e+00\n",
      "Epoch 21018, Loss: 114.3061752319336, Neurons: 11, Grad norm: 2.641e+00\n",
      "Epoch 21019, Loss: 114.28771209716797, Neurons: 11, Grad norm: 3.267e+00\n",
      "Epoch 21020, Loss: 114.26924896240234, Neurons: 11, Grad norm: 2.673e+00\n",
      "Epoch 21021, Loss: 114.25082397460938, Neurons: 11, Grad norm: 3.147e+00\n",
      "Epoch 21022, Loss: 114.232421875, Neurons: 11, Grad norm: 2.703e+00\n",
      "Epoch 21023, Loss: 114.21407318115234, Neurons: 11, Grad norm: 3.105e+00\n",
      "Epoch 21024, Loss: 114.19572448730469, Neurons: 11, Grad norm: 2.652e+00\n",
      "Epoch 21025, Loss: 114.17742156982422, Neurons: 11, Grad norm: 3.144e+00\n",
      "Epoch 21026, Loss: 114.15914916992188, Neurons: 11, Grad norm: 2.673e+00\n",
      "Epoch 21027, Loss: 114.14089965820312, Neurons: 11, Grad norm: 3.277e+00\n",
      "Epoch 21028, Loss: 114.12267303466797, Neurons: 11, Grad norm: 2.600e+00\n",
      "Epoch 21029, Loss: 114.10449981689453, Neurons: 11, Grad norm: 3.709e+00\n",
      "Epoch 21030, Loss: 114.08633422851562, Neurons: 11, Grad norm: 2.690e+00\n",
      "Epoch 21031, Loss: 114.06822204589844, Neurons: 11, Grad norm: 4.321e+00\n",
      "Epoch 21032, Loss: 114.05012512207031, Neurons: 11, Grad norm: 3.036e+00\n",
      "Epoch 21033, Loss: 114.03204345703125, Neurons: 11, Grad norm: 5.278e+00\n",
      "Epoch 21034, Loss: 114.01399993896484, Neurons: 11, Grad norm: 4.075e+00\n",
      "Epoch 21035, Loss: 113.9959945678711, Neurons: 11, Grad norm: 6.660e+00\n",
      "Epoch 21036, Loss: 113.97801971435547, Neurons: 11, Grad norm: 5.371e+00\n",
      "Epoch 21037, Loss: 113.96007537841797, Neurons: 11, Grad norm: 8.784e+00\n",
      "Epoch 21038, Loss: 113.94218444824219, Neurons: 11, Grad norm: 7.936e+00\n",
      "Epoch 21039, Loss: 113.92430877685547, Neurons: 11, Grad norm: 1.176e+01\n",
      "Epoch 21040, Loss: 113.90648651123047, Neurons: 11, Grad norm: 1.174e+01\n",
      "Epoch 21041, Loss: 113.8886947631836, Neurons: 11, Grad norm: 1.636e+01\n",
      "Epoch 21042, Loss: 113.8709716796875, Neurons: 11, Grad norm: 1.634e+01\n",
      "Epoch 21043, Loss: 113.8532943725586, Neurons: 11, Grad norm: 2.089e+01\n",
      "Epoch 21044, Loss: 113.83566284179688, Neurons: 11, Grad norm: 2.025e+01\n",
      "Epoch 21045, Loss: 113.81802368164062, Neurons: 11, Grad norm: 2.266e+01\n",
      "Epoch 21046, Loss: 113.80038452148438, Neurons: 11, Grad norm: 1.866e+01\n",
      "Epoch 21047, Loss: 113.78268432617188, Neurons: 11, Grad norm: 1.697e+01\n",
      "Epoch 21048, Loss: 113.76494598388672, Neurons: 11, Grad norm: 8.765e+00\n",
      "Epoch 21049, Loss: 113.74723815917969, Neurons: 11, Grad norm: 4.737e+00\n",
      "Epoch 21049, Test loss: 110.06351470947266\n",
      "Epoch 21050, Loss: 113.72962188720703, Neurons: 11, Grad norm: 5.444e+00\n",
      "Epoch 21051, Loss: 113.7121353149414, Neurons: 11, Grad norm: 8.407e+00\n",
      "Epoch 21052, Loss: 113.69474792480469, Neurons: 11, Grad norm: 1.430e+01\n",
      "Epoch 21053, Loss: 113.67740631103516, Neurons: 11, Grad norm: 1.315e+01\n",
      "Epoch 21054, Loss: 113.66004943847656, Neurons: 11, Grad norm: 1.405e+01\n",
      "Epoch 21055, Loss: 113.64264678955078, Neurons: 11, Grad norm: 8.647e+00\n",
      "Epoch 21056, Loss: 113.6252212524414, Neurons: 11, Grad norm: 6.432e+00\n",
      "Epoch 21057, Loss: 113.60784912109375, Neurons: 11, Grad norm: 2.947e+00\n",
      "Epoch 21058, Loss: 113.59054565429688, Neurons: 11, Grad norm: 4.478e+00\n",
      "Epoch 21059, Loss: 113.57331085205078, Neurons: 11, Grad norm: 9.671e+00\n",
      "Epoch 21060, Loss: 113.55614471435547, Neurons: 11, Grad norm: 8.661e+00\n",
      "Epoch 21061, Loss: 113.53894805908203, Neurons: 11, Grad norm: 1.037e+01\n",
      "Epoch 21062, Loss: 113.52177429199219, Neurons: 11, Grad norm: 5.958e+00\n",
      "Epoch 21063, Loss: 113.50460052490234, Neurons: 11, Grad norm: 5.200e+00\n",
      "Epoch 21064, Loss: 113.48745727539062, Neurons: 11, Grad norm: 2.739e+00\n",
      "Epoch 21065, Loss: 113.47034454345703, Neurons: 11, Grad norm: 3.209e+00\n",
      "Epoch 21066, Loss: 113.45330047607422, Neurons: 11, Grad norm: 7.312e+00\n",
      "Epoch 21067, Loss: 113.43627166748047, Neurons: 11, Grad norm: 6.186e+00\n",
      "Epoch 21068, Loss: 113.41929626464844, Neurons: 11, Grad norm: 8.146e+00\n",
      "Epoch 21069, Loss: 113.40229797363281, Neurons: 11, Grad norm: 4.656e+00\n",
      "Epoch 21070, Loss: 113.38533782958984, Neurons: 11, Grad norm: 5.007e+00\n",
      "Epoch 21071, Loss: 113.36837005615234, Neurons: 11, Grad norm: 2.458e+00\n",
      "Epoch 21072, Loss: 113.35147094726562, Neurons: 11, Grad norm: 2.434e+00\n",
      "Epoch 21073, Loss: 113.33458709716797, Neurons: 11, Grad norm: 4.994e+00\n",
      "Epoch 21074, Loss: 113.3177490234375, Neurons: 11, Grad norm: 3.857e+00\n",
      "Epoch 21075, Loss: 113.30094909667969, Neurons: 11, Grad norm: 6.210e+00\n",
      "Epoch 21076, Loss: 113.28413391113281, Neurons: 11, Grad norm: 3.585e+00\n",
      "Epoch 21077, Loss: 113.26734924316406, Neurons: 11, Grad norm: 4.458e+00\n",
      "Epoch 21078, Loss: 113.25059509277344, Neurons: 11, Grad norm: 2.420e+00\n",
      "Epoch 21079, Loss: 113.23385620117188, Neurons: 11, Grad norm: 2.483e+00\n",
      "Epoch 21080, Loss: 113.2171630859375, Neurons: 11, Grad norm: 3.970e+00\n",
      "Epoch 21081, Loss: 113.20048522949219, Neurons: 11, Grad norm: 3.026e+00\n",
      "Epoch 21082, Loss: 113.18384552001953, Neurons: 11, Grad norm: 5.430e+00\n",
      "Epoch 21083, Loss: 113.167236328125, Neurons: 11, Grad norm: 3.281e+00\n",
      "Epoch 21084, Loss: 113.15061950683594, Neurons: 11, Grad norm: 4.784e+00\n",
      "Epoch 21085, Loss: 113.134033203125, Neurons: 11, Grad norm: 2.499e+00\n",
      "Epoch 21086, Loss: 113.11748504638672, Neurons: 11, Grad norm: 3.218e+00\n",
      "Epoch 21087, Loss: 113.10094451904297, Neurons: 11, Grad norm: 2.706e+00\n",
      "Epoch 21088, Loss: 113.08447265625, Neurons: 11, Grad norm: 2.401e+00\n",
      "Epoch 21089, Loss: 113.06798553466797, Neurons: 11, Grad norm: 3.595e+00\n",
      "Epoch 21090, Loss: 113.0515365600586, Neurons: 11, Grad norm: 2.462e+00\n",
      "Epoch 21091, Loss: 113.03511047363281, Neurons: 11, Grad norm: 4.074e+00\n",
      "Epoch 21092, Loss: 113.0186996459961, Neurons: 11, Grad norm: 2.403e+00\n",
      "Epoch 21093, Loss: 113.00233459472656, Neurons: 11, Grad norm: 3.426e+00\n",
      "Epoch 21094, Loss: 112.98596954345703, Neurons: 11, Grad norm: 2.384e+00\n",
      "Epoch 21095, Loss: 112.96965026855469, Neurons: 11, Grad norm: 2.808e+00\n",
      "Epoch 21096, Loss: 112.95333099365234, Neurons: 11, Grad norm: 2.896e+00\n",
      "Epoch 21097, Loss: 112.93704986572266, Neurons: 11, Grad norm: 2.341e+00\n",
      "Epoch 21098, Loss: 112.9207992553711, Neurons: 11, Grad norm: 3.618e+00\n",
      "Epoch 21099, Loss: 112.90454864501953, Neurons: 11, Grad norm: 2.380e+00\n",
      "Epoch 21099, Test loss: 109.18132019042969\n",
      "Epoch 21100, Loss: 112.88834381103516, Neurons: 11, Grad norm: 3.841e+00\n",
      "Epoch 21101, Loss: 112.87216186523438, Neurons: 11, Grad norm: 2.343e+00\n",
      "Epoch 21102, Loss: 112.85597229003906, Neurons: 11, Grad norm: 3.502e+00\n",
      "Epoch 21103, Loss: 112.83984375, Neurons: 11, Grad norm: 2.312e+00\n",
      "Epoch 21104, Loss: 112.82372283935547, Neurons: 11, Grad norm: 3.192e+00\n",
      "Epoch 21105, Loss: 112.80760955810547, Neurons: 11, Grad norm: 2.436e+00\n",
      "Epoch 21106, Loss: 112.79153442382812, Neurons: 11, Grad norm: 2.752e+00\n",
      "Epoch 21107, Loss: 112.77549743652344, Neurons: 11, Grad norm: 2.579e+00\n",
      "Epoch 21108, Loss: 112.75947570800781, Neurons: 11, Grad norm: 2.657e+00\n",
      "Epoch 21109, Loss: 112.74344635009766, Neurons: 11, Grad norm: 2.718e+00\n",
      "Epoch 21110, Loss: 112.72748565673828, Neurons: 11, Grad norm: 2.475e+00\n",
      "Epoch 21111, Loss: 112.7115249633789, Neurons: 11, Grad norm: 2.864e+00\n",
      "Epoch 21112, Loss: 112.69557189941406, Neurons: 11, Grad norm: 2.434e+00\n",
      "Epoch 21113, Loss: 112.67967224121094, Neurons: 11, Grad norm: 2.791e+00\n",
      "Epoch 21114, Loss: 112.66377258300781, Neurons: 11, Grad norm: 2.587e+00\n",
      "Epoch 21115, Loss: 112.64791107177734, Neurons: 11, Grad norm: 2.593e+00\n",
      "Epoch 21116, Loss: 112.63207244873047, Neurons: 11, Grad norm: 2.707e+00\n",
      "Epoch 21117, Loss: 112.61621856689453, Neurons: 11, Grad norm: 2.395e+00\n",
      "Epoch 21118, Loss: 112.60042572021484, Neurons: 11, Grad norm: 3.186e+00\n",
      "Epoch 21119, Loss: 112.58462524414062, Neurons: 11, Grad norm: 2.280e+00\n",
      "Epoch 21120, Loss: 112.56888580322266, Neurons: 11, Grad norm: 3.253e+00\n",
      "Epoch 21121, Loss: 112.55313110351562, Neurons: 11, Grad norm: 2.264e+00\n",
      "Epoch 21122, Loss: 112.53743743896484, Neurons: 11, Grad norm: 3.439e+00\n",
      "Epoch 21123, Loss: 112.52172088623047, Neurons: 11, Grad norm: 2.253e+00\n",
      "Epoch 21124, Loss: 112.50605010986328, Neurons: 11, Grad norm: 3.615e+00\n",
      "Epoch 21125, Loss: 112.49040985107422, Neurons: 11, Grad norm: 2.251e+00\n",
      "Epoch 21126, Loss: 112.47476959228516, Neurons: 11, Grad norm: 3.553e+00\n",
      "Epoch 21127, Loss: 112.45917510986328, Neurons: 11, Grad norm: 2.245e+00\n",
      "Epoch 21128, Loss: 112.44357299804688, Neurons: 11, Grad norm: 3.491e+00\n",
      "Epoch 21129, Loss: 112.42802429199219, Neurons: 11, Grad norm: 2.224e+00\n",
      "Epoch 21130, Loss: 112.4124755859375, Neurons: 11, Grad norm: 3.257e+00\n",
      "Epoch 21131, Loss: 112.39695739746094, Neurons: 11, Grad norm: 2.290e+00\n",
      "Epoch 21132, Loss: 112.3814468383789, Neurons: 11, Grad norm: 3.130e+00\n",
      "Epoch 21133, Loss: 112.36597442626953, Neurons: 11, Grad norm: 2.267e+00\n",
      "Epoch 21134, Loss: 112.35049438476562, Neurons: 11, Grad norm: 3.084e+00\n",
      "Epoch 21135, Loss: 112.33507537841797, Neurons: 11, Grad norm: 2.271e+00\n",
      "Epoch 21136, Loss: 112.31964874267578, Neurons: 11, Grad norm: 3.074e+00\n",
      "Epoch 21137, Loss: 112.30424499511719, Neurons: 11, Grad norm: 2.305e+00\n",
      "Epoch 21138, Loss: 112.28885650634766, Neurons: 11, Grad norm: 3.046e+00\n",
      "Epoch 21139, Loss: 112.27350616455078, Neurons: 11, Grad norm: 2.223e+00\n",
      "Epoch 21140, Loss: 112.25819396972656, Neurons: 11, Grad norm: 3.339e+00\n",
      "Epoch 21141, Loss: 112.24285888671875, Neurons: 11, Grad norm: 2.231e+00\n",
      "Epoch 21142, Loss: 112.22756958007812, Neurons: 11, Grad norm: 3.223e+00\n",
      "Epoch 21143, Loss: 112.21228790283203, Neurons: 11, Grad norm: 2.191e+00\n",
      "Epoch 21144, Loss: 112.19703674316406, Neurons: 11, Grad norm: 3.481e+00\n",
      "Epoch 21145, Loss: 112.18180084228516, Neurons: 11, Grad norm: 2.189e+00\n",
      "Epoch 21146, Loss: 112.16657257080078, Neurons: 11, Grad norm: 3.400e+00\n",
      "Epoch 21147, Loss: 112.15138244628906, Neurons: 11, Grad norm: 2.181e+00\n",
      "Epoch 21148, Loss: 112.13622283935547, Neurons: 11, Grad norm: 3.368e+00\n",
      "Epoch 21149, Loss: 112.1210708618164, Neurons: 11, Grad norm: 2.178e+00\n",
      "Epoch 21149, Test loss: 108.36505126953125\n",
      "Epoch 21150, Loss: 112.10591888427734, Neurons: 11, Grad norm: 3.296e+00\n",
      "Epoch 21151, Loss: 112.0907974243164, Neurons: 11, Grad norm: 2.222e+00\n",
      "Epoch 21152, Loss: 112.07572174072266, Neurons: 11, Grad norm: 3.109e+00\n",
      "Epoch 21153, Loss: 112.0606460571289, Neurons: 11, Grad norm: 2.199e+00\n",
      "Epoch 21154, Loss: 112.04558563232422, Neurons: 11, Grad norm: 3.251e+00\n",
      "Epoch 21155, Loss: 112.03054809570312, Neurons: 11, Grad norm: 2.189e+00\n",
      "Epoch 21156, Loss: 112.01553344726562, Neurons: 11, Grad norm: 3.178e+00\n",
      "Epoch 21157, Loss: 112.00053405761719, Neurons: 11, Grad norm: 2.182e+00\n",
      "Epoch 21158, Loss: 111.98555755615234, Neurons: 11, Grad norm: 3.289e+00\n",
      "Epoch 21159, Loss: 111.97059631347656, Neurons: 11, Grad norm: 2.151e+00\n",
      "Epoch 21160, Loss: 111.95565795898438, Neurons: 11, Grad norm: 3.338e+00\n",
      "Epoch 21161, Loss: 111.94073486328125, Neurons: 11, Grad norm: 2.155e+00\n",
      "Epoch 21162, Loss: 111.92581939697266, Neurons: 11, Grad norm: 3.750e+00\n",
      "Epoch 21163, Loss: 111.91094970703125, Neurons: 11, Grad norm: 2.312e+00\n",
      "Epoch 21164, Loss: 111.8960952758789, Neurons: 11, Grad norm: 4.850e+00\n",
      "Epoch 21165, Loss: 111.88125610351562, Neurons: 11, Grad norm: 3.224e+00\n",
      "Epoch 21166, Loss: 111.86644744873047, Neurons: 11, Grad norm: 6.719e+00\n",
      "Epoch 21167, Loss: 111.85164642333984, Neurons: 11, Grad norm: 5.616e+00\n",
      "Epoch 21168, Loss: 111.83687591552734, Neurons: 11, Grad norm: 1.028e+01\n",
      "Epoch 21169, Loss: 111.8221435546875, Neurons: 11, Grad norm: 9.959e+00\n",
      "Epoch 21170, Loss: 111.80744934082031, Neurons: 11, Grad norm: 1.575e+01\n",
      "Epoch 21171, Loss: 111.79280090332031, Neurons: 11, Grad norm: 1.690e+01\n",
      "Epoch 21172, Loss: 111.7782211303711, Neurons: 11, Grad norm: 2.412e+01\n",
      "Epoch 21173, Loss: 111.76372528076172, Neurons: 11, Grad norm: 2.604e+01\n",
      "Epoch 21174, Loss: 111.74931335449219, Neurons: 11, Grad norm: 3.262e+01\n",
      "Epoch 21175, Loss: 111.73492431640625, Neurons: 11, Grad norm: 3.187e+01\n",
      "Epoch 21176, Loss: 111.72047424316406, Neurons: 11, Grad norm: 3.267e+01\n",
      "Epoch 21177, Loss: 111.70582580566406, Neurons: 11, Grad norm: 2.331e+01\n",
      "Epoch 21178, Loss: 111.69095611572266, Neurons: 11, Grad norm: 1.503e+01\n",
      "Epoch 21179, Loss: 111.6761245727539, Neurons: 11, Grad norm: 2.247e+00\n",
      "Epoch 21180, Loss: 111.6615219116211, Neurons: 11, Grad norm: 9.749e+00\n",
      "Epoch 21181, Loss: 111.64723205566406, Neurons: 11, Grad norm: 2.048e+01\n",
      "Epoch 21182, Loss: 111.633056640625, Neurons: 11, Grad norm: 2.091e+01\n",
      "Epoch 21183, Loss: 111.61882019042969, Neurons: 11, Grad norm: 2.118e+01\n",
      "Epoch 21184, Loss: 111.6043701171875, Neurons: 11, Grad norm: 1.150e+01\n",
      "Epoch 21185, Loss: 111.58987426757812, Neurons: 11, Grad norm: 4.599e+00\n",
      "Epoch 21186, Loss: 111.57543182373047, Neurons: 11, Grad norm: 8.558e+00\n",
      "Epoch 21187, Loss: 111.56119537353516, Neurons: 11, Grad norm: 1.230e+01\n",
      "Epoch 21188, Loss: 111.54707336425781, Neurons: 11, Grad norm: 1.751e+01\n",
      "Epoch 21189, Loss: 111.53289794921875, Neurons: 11, Grad norm: 1.306e+01\n",
      "Epoch 21190, Loss: 111.51864624023438, Neurons: 11, Grad norm: 1.024e+01\n",
      "Epoch 21191, Loss: 111.50434875488281, Neurons: 11, Grad norm: 2.135e+00\n",
      "Epoch 21192, Loss: 111.4901123046875, Neurons: 11, Grad norm: 5.157e+00\n",
      "Epoch 21193, Loss: 111.47598266601562, Neurons: 11, Grad norm: 1.215e+01\n",
      "Epoch 21194, Loss: 111.46192169189453, Neurons: 11, Grad norm: 1.074e+01\n",
      "Epoch 21195, Loss: 111.44784545898438, Neurons: 11, Grad norm: 1.142e+01\n",
      "Epoch 21196, Loss: 111.43370056152344, Neurons: 11, Grad norm: 4.252e+00\n",
      "Epoch 21197, Loss: 111.41954803466797, Neurons: 11, Grad norm: 2.148e+00\n",
      "Epoch 21198, Loss: 111.40547180175781, Neurons: 11, Grad norm: 7.318e+00\n",
      "Epoch 21199, Loss: 111.3914566040039, Neurons: 11, Grad norm: 7.292e+00\n",
      "Epoch 21199, Test loss: 107.6038589477539\n",
      "Epoch 21200, Loss: 111.37748718261719, Neurons: 11, Grad norm: 1.029e+01\n",
      "Epoch 21201, Loss: 111.36347198486328, Neurons: 11, Grad norm: 5.504e+00\n",
      "Epoch 21202, Loss: 111.34944915771484, Neurons: 11, Grad norm: 4.607e+00\n",
      "Epoch 21203, Loss: 111.33545684814453, Neurons: 11, Grad norm: 3.458e+00\n",
      "Epoch 21204, Loss: 111.3215103149414, Neurons: 11, Grad norm: 4.004e+00\n",
      "Epoch 21205, Loss: 111.30757141113281, Neurons: 11, Grad norm: 8.391e+00\n",
      "Epoch 21206, Loss: 111.29368591308594, Neurons: 11, Grad norm: 5.418e+00\n",
      "Epoch 21207, Loss: 111.27976989746094, Neurons: 11, Grad norm: 6.202e+00\n",
      "Epoch 21208, Loss: 111.26586151123047, Neurons: 11, Grad norm: 2.047e+00\n",
      "Epoch 21209, Loss: 111.25196838378906, Neurons: 11, Grad norm: 2.037e+00\n",
      "Epoch 21210, Loss: 111.23812103271484, Neurons: 11, Grad norm: 5.638e+00\n",
      "Epoch 21211, Loss: 111.22431182861328, Neurons: 11, Grad norm: 4.243e+00\n",
      "Epoch 21212, Loss: 111.21049499511719, Neurons: 11, Grad norm: 6.466e+00\n",
      "Epoch 21213, Loss: 111.19667053222656, Neurons: 11, Grad norm: 2.716e+00\n",
      "Epoch 21214, Loss: 111.18289947509766, Neurons: 11, Grad norm: 3.374e+00\n",
      "Epoch 21215, Loss: 111.16912078857422, Neurons: 11, Grad norm: 3.107e+00\n",
      "Epoch 21216, Loss: 111.15535736083984, Neurons: 11, Grad norm: 2.395e+00\n",
      "Epoch 21217, Loss: 111.1416244506836, Neurons: 11, Grad norm: 5.467e+00\n",
      "Epoch 21218, Loss: 111.12789916992188, Neurons: 11, Grad norm: 3.046e+00\n",
      "Epoch 21219, Loss: 111.11419677734375, Neurons: 11, Grad norm: 4.724e+00\n",
      "Epoch 21220, Loss: 111.10052490234375, Neurons: 11, Grad norm: 2.014e+00\n",
      "Epoch 21221, Loss: 111.08683776855469, Neurons: 11, Grad norm: 2.190e+00\n",
      "Epoch 21222, Loss: 111.07317352294922, Neurons: 11, Grad norm: 3.843e+00\n",
      "Epoch 21223, Loss: 111.0595474243164, Neurons: 11, Grad norm: 2.495e+00\n",
      "Epoch 21224, Loss: 111.0458984375, Neurons: 11, Grad norm: 5.214e+00\n",
      "Epoch 21225, Loss: 111.03229522705078, Neurons: 11, Grad norm: 2.389e+00\n",
      "Epoch 21226, Loss: 111.0186996459961, Neurons: 11, Grad norm: 3.653e+00\n",
      "Epoch 21227, Loss: 111.00509643554688, Neurons: 11, Grad norm: 2.281e+00\n",
      "Epoch 21228, Loss: 110.99154663085938, Neurons: 11, Grad norm: 2.046e+00\n",
      "Epoch 21229, Loss: 110.97798156738281, Neurons: 11, Grad norm: 3.927e+00\n",
      "Epoch 21230, Loss: 110.96444702148438, Neurons: 11, Grad norm: 2.259e+00\n",
      "Epoch 21231, Loss: 110.95093536376953, Neurons: 11, Grad norm: 4.508e+00\n",
      "Epoch 21232, Loss: 110.93742370605469, Neurons: 11, Grad norm: 2.063e+00\n",
      "Epoch 21233, Loss: 110.92391967773438, Neurons: 11, Grad norm: 3.306e+00\n",
      "Epoch 21234, Loss: 110.91044616699219, Neurons: 11, Grad norm: 2.324e+00\n",
      "Epoch 21235, Loss: 110.89698791503906, Neurons: 11, Grad norm: 2.112e+00\n",
      "Epoch 21236, Loss: 110.883544921875, Neurons: 11, Grad norm: 3.524e+00\n",
      "Epoch 21237, Loss: 110.87012481689453, Neurons: 11, Grad norm: 2.041e+00\n",
      "Epoch 21238, Loss: 110.85669708251953, Neurons: 11, Grad norm: 4.139e+00\n",
      "Epoch 21239, Loss: 110.84326934814453, Neurons: 11, Grad norm: 1.991e+00\n",
      "Epoch 21240, Loss: 110.82989501953125, Neurons: 11, Grad norm: 3.353e+00\n",
      "Epoch 21241, Loss: 110.81652069091797, Neurons: 11, Grad norm: 2.098e+00\n",
      "Epoch 21242, Loss: 110.80316162109375, Neurons: 11, Grad norm: 2.455e+00\n",
      "Epoch 21243, Loss: 110.78981018066406, Neurons: 11, Grad norm: 3.041e+00\n",
      "Epoch 21244, Loss: 110.77648162841797, Neurons: 11, Grad norm: 1.943e+00\n",
      "Epoch 21245, Loss: 110.76314544677734, Neurons: 11, Grad norm: 3.816e+00\n",
      "Epoch 21246, Loss: 110.74987030029297, Neurons: 11, Grad norm: 1.988e+00\n",
      "Epoch 21247, Loss: 110.736572265625, Neurons: 11, Grad norm: 3.684e+00\n",
      "Epoch 21248, Loss: 110.72329711914062, Neurons: 11, Grad norm: 1.953e+00\n",
      "Epoch 21249, Loss: 110.71003723144531, Neurons: 11, Grad norm: 3.026e+00\n",
      "Epoch 21249, Test loss: 106.897705078125\n",
      "Epoch 21250, Loss: 110.69678497314453, Neurons: 11, Grad norm: 2.281e+00\n",
      "Epoch 21251, Loss: 110.68354797363281, Neurons: 11, Grad norm: 2.230e+00\n",
      "Epoch 21252, Loss: 110.67031860351562, Neurons: 11, Grad norm: 3.174e+00\n",
      "Epoch 21253, Loss: 110.65711975097656, Neurons: 11, Grad norm: 1.936e+00\n",
      "Epoch 21254, Loss: 110.6439208984375, Neurons: 11, Grad norm: 3.553e+00\n",
      "Epoch 21255, Loss: 110.63074493408203, Neurons: 11, Grad norm: 1.933e+00\n",
      "Epoch 21256, Loss: 110.61759948730469, Neurons: 11, Grad norm: 3.618e+00\n",
      "Epoch 21257, Loss: 110.60444641113281, Neurons: 11, Grad norm: 1.971e+00\n",
      "Epoch 21258, Loss: 110.59130096435547, Neurons: 11, Grad norm: 2.836e+00\n",
      "Epoch 21259, Loss: 110.57817077636719, Neurons: 11, Grad norm: 2.302e+00\n",
      "Epoch 21260, Loss: 110.56504821777344, Neurons: 11, Grad norm: 2.308e+00\n",
      "Epoch 21261, Loss: 110.55195617675781, Neurons: 11, Grad norm: 2.990e+00\n",
      "Epoch 21262, Loss: 110.53887176513672, Neurons: 11, Grad norm: 1.940e+00\n",
      "Epoch 21263, Loss: 110.52581024169922, Neurons: 11, Grad norm: 3.502e+00\n",
      "Epoch 21264, Loss: 110.51274871826172, Neurons: 11, Grad norm: 1.914e+00\n",
      "Epoch 21265, Loss: 110.49971008300781, Neurons: 11, Grad norm: 3.491e+00\n",
      "Epoch 21266, Loss: 110.4866714477539, Neurons: 11, Grad norm: 1.943e+00\n",
      "Epoch 21267, Loss: 110.47364807128906, Neurons: 11, Grad norm: 3.087e+00\n",
      "Epoch 21268, Loss: 110.46064758300781, Neurons: 11, Grad norm: 2.171e+00\n",
      "Epoch 21269, Loss: 110.44764709472656, Neurons: 11, Grad norm: 2.394e+00\n",
      "Epoch 21270, Loss: 110.4346694946289, Neurons: 11, Grad norm: 2.632e+00\n",
      "Epoch 21271, Loss: 110.42169952392578, Neurons: 11, Grad norm: 2.184e+00\n",
      "Epoch 21272, Loss: 110.40874481201172, Neurons: 11, Grad norm: 2.942e+00\n",
      "Epoch 21273, Loss: 110.39579772949219, Neurons: 11, Grad norm: 2.009e+00\n",
      "Epoch 21274, Loss: 110.38287353515625, Neurons: 11, Grad norm: 3.025e+00\n",
      "Epoch 21275, Loss: 110.36994934082031, Neurons: 11, Grad norm: 2.053e+00\n",
      "Epoch 21276, Loss: 110.35704803466797, Neurons: 11, Grad norm: 2.890e+00\n",
      "Epoch 21277, Loss: 110.34416198730469, Neurons: 11, Grad norm: 2.137e+00\n",
      "Epoch 21278, Loss: 110.3312759399414, Neurons: 11, Grad norm: 2.681e+00\n",
      "Epoch 21279, Loss: 110.31842041015625, Neurons: 11, Grad norm: 2.337e+00\n",
      "Epoch 21280, Loss: 110.30554962158203, Neurons: 11, Grad norm: 2.491e+00\n",
      "Epoch 21281, Loss: 110.292724609375, Neurons: 11, Grad norm: 2.343e+00\n",
      "Epoch 21282, Loss: 110.27986907958984, Neurons: 11, Grad norm: 2.545e+00\n",
      "Epoch 21283, Loss: 110.26705932617188, Neurons: 11, Grad norm: 2.339e+00\n",
      "Epoch 21284, Loss: 110.2542495727539, Neurons: 11, Grad norm: 2.449e+00\n",
      "Epoch 21285, Loss: 110.24146270751953, Neurons: 11, Grad norm: 2.553e+00\n",
      "Epoch 21286, Loss: 110.22867584228516, Neurons: 11, Grad norm: 2.282e+00\n",
      "Epoch 21287, Loss: 110.21591186523438, Neurons: 11, Grad norm: 2.622e+00\n",
      "Epoch 21288, Loss: 110.2031478881836, Neurons: 11, Grad norm: 2.128e+00\n",
      "Epoch 21289, Loss: 110.19039916992188, Neurons: 11, Grad norm: 3.040e+00\n",
      "Epoch 21290, Loss: 110.17767333984375, Neurons: 11, Grad norm: 2.002e+00\n",
      "Epoch 21291, Loss: 110.16494750976562, Neurons: 11, Grad norm: 3.070e+00\n",
      "Epoch 21292, Loss: 110.1522216796875, Neurons: 11, Grad norm: 1.922e+00\n",
      "Epoch 21293, Loss: 110.13951873779297, Neurons: 11, Grad norm: 3.340e+00\n",
      "Epoch 21294, Loss: 110.12684631347656, Neurons: 11, Grad norm: 1.932e+00\n",
      "Epoch 21295, Loss: 110.1141586303711, Neurons: 11, Grad norm: 3.092e+00\n",
      "Epoch 21296, Loss: 110.10149383544922, Neurons: 11, Grad norm: 1.992e+00\n",
      "Epoch 21297, Loss: 110.0888442993164, Neurons: 11, Grad norm: 3.091e+00\n",
      "Epoch 21298, Loss: 110.0761947631836, Neurons: 11, Grad norm: 1.969e+00\n",
      "Epoch 21299, Loss: 110.0635757446289, Neurons: 11, Grad norm: 3.040e+00\n",
      "Epoch 21299, Test loss: 106.22850799560547\n",
      "Epoch 21300, Loss: 110.05097198486328, Neurons: 11, Grad norm: 2.029e+00\n",
      "Epoch 21301, Loss: 110.03834533691406, Neurons: 11, Grad norm: 3.082e+00\n",
      "Epoch 21302, Loss: 110.02574920654297, Neurons: 11, Grad norm: 1.934e+00\n",
      "Epoch 21303, Loss: 110.01317596435547, Neurons: 11, Grad norm: 3.085e+00\n",
      "Epoch 21304, Loss: 110.00059509277344, Neurons: 11, Grad norm: 2.056e+00\n",
      "Epoch 21305, Loss: 109.988037109375, Neurons: 11, Grad norm: 2.985e+00\n",
      "Epoch 21306, Loss: 109.9754867553711, Neurons: 11, Grad norm: 1.995e+00\n",
      "Epoch 21307, Loss: 109.96292114257812, Neurons: 11, Grad norm: 2.791e+00\n",
      "Epoch 21308, Loss: 109.95039367675781, Neurons: 11, Grad norm: 2.237e+00\n",
      "Epoch 21309, Loss: 109.93789672851562, Neurons: 11, Grad norm: 2.853e+00\n",
      "Epoch 21310, Loss: 109.92536926269531, Neurons: 11, Grad norm: 2.019e+00\n",
      "Epoch 21311, Loss: 109.91288757324219, Neurons: 11, Grad norm: 2.991e+00\n",
      "Epoch 21312, Loss: 109.90039825439453, Neurons: 11, Grad norm: 1.952e+00\n",
      "Epoch 21313, Loss: 109.88792419433594, Neurons: 11, Grad norm: 3.373e+00\n",
      "Epoch 21314, Loss: 109.87545776367188, Neurons: 11, Grad norm: 1.854e+00\n",
      "Epoch 21315, Loss: 109.86299896240234, Neurons: 11, Grad norm: 3.722e+00\n",
      "Epoch 21316, Loss: 109.8505630493164, Neurons: 11, Grad norm: 1.874e+00\n",
      "Epoch 21317, Loss: 109.83811950683594, Neurons: 11, Grad norm: 4.219e+00\n",
      "Epoch 21318, Loss: 109.82569885253906, Neurons: 11, Grad norm: 2.115e+00\n",
      "Epoch 21319, Loss: 109.81329345703125, Neurons: 11, Grad norm: 5.176e+00\n",
      "Epoch 21320, Loss: 109.80089569091797, Neurons: 11, Grad norm: 2.906e+00\n",
      "Epoch 21321, Loss: 109.78849792480469, Neurons: 11, Grad norm: 6.491e+00\n",
      "Epoch 21322, Loss: 109.776123046875, Neurons: 11, Grad norm: 4.702e+00\n",
      "Epoch 21323, Loss: 109.76376342773438, Neurons: 11, Grad norm: 9.299e+00\n",
      "Epoch 21324, Loss: 109.75141906738281, Neurons: 11, Grad norm: 7.909e+00\n",
      "Epoch 21325, Loss: 109.73909759521484, Neurons: 11, Grad norm: 1.316e+01\n",
      "Epoch 21326, Loss: 109.72679901123047, Neurons: 11, Grad norm: 1.268e+01\n",
      "Epoch 21327, Loss: 109.71453094482422, Neurons: 11, Grad norm: 1.911e+01\n",
      "Epoch 21328, Loss: 109.70232391357422, Neurons: 11, Grad norm: 1.980e+01\n",
      "Epoch 21329, Loss: 109.6901626586914, Neurons: 11, Grad norm: 2.702e+01\n",
      "Epoch 21330, Loss: 109.67804718017578, Neurons: 11, Grad norm: 2.823e+01\n",
      "Epoch 21331, Loss: 109.66600036621094, Neurons: 11, Grad norm: 3.518e+01\n",
      "Epoch 21332, Loss: 109.65398406982422, Neurons: 11, Grad norm: 3.431e+01\n",
      "Epoch 21333, Loss: 109.64189910888672, Neurons: 11, Grad norm: 3.594e+01\n",
      "Epoch 21334, Loss: 109.62969970703125, Neurons: 11, Grad norm: 2.758e+01\n",
      "Epoch 21335, Loss: 109.61732482910156, Neurons: 11, Grad norm: 2.160e+01\n",
      "Epoch 21336, Loss: 109.60489654541016, Neurons: 11, Grad norm: 6.981e+00\n",
      "Epoch 21337, Loss: 109.59259796142578, Neurons: 11, Grad norm: 2.949e+00\n",
      "Epoch 21338, Loss: 109.58049774169922, Neurons: 11, Grad norm: 1.576e+01\n",
      "Epoch 21339, Loss: 109.56863403320312, Neurons: 11, Grad norm: 1.911e+01\n",
      "Epoch 21340, Loss: 109.55680084228516, Neurons: 11, Grad norm: 2.454e+01\n",
      "Epoch 21341, Loss: 109.54486846923828, Neurons: 11, Grad norm: 1.946e+01\n",
      "Epoch 21342, Loss: 109.53282165527344, Neurons: 11, Grad norm: 1.599e+01\n",
      "Epoch 21343, Loss: 109.52069854736328, Neurons: 11, Grad norm: 4.346e+00\n",
      "Epoch 21344, Loss: 109.50860595703125, Neurons: 11, Grad norm: 2.411e+00\n",
      "Epoch 21345, Loss: 109.49667358398438, Neurons: 11, Grad norm: 1.215e+01\n",
      "Epoch 21346, Loss: 109.48482513427734, Neurons: 11, Grad norm: 1.391e+01\n",
      "Epoch 21347, Loss: 109.47300720214844, Neurons: 11, Grad norm: 1.803e+01\n",
      "Epoch 21348, Loss: 109.46114349365234, Neurons: 11, Grad norm: 1.218e+01\n",
      "Epoch 21349, Loss: 109.44921875, Neurons: 11, Grad norm: 1.019e+01\n",
      "Epoch 21349, Test loss: 105.59428405761719\n",
      "Epoch 21350, Loss: 109.43726348876953, Neurons: 11, Grad norm: 1.890e+00\n",
      "Epoch 21351, Loss: 109.42534637451172, Neurons: 11, Grad norm: 3.268e+00\n",
      "Epoch 21352, Loss: 109.41351318359375, Neurons: 11, Grad norm: 1.088e+01\n",
      "Epoch 21353, Loss: 109.40172576904297, Neurons: 11, Grad norm: 9.963e+00\n",
      "Epoch 21354, Loss: 109.38993835449219, Neurons: 11, Grad norm: 1.263e+01\n",
      "Epoch 21355, Loss: 109.37812042236328, Neurons: 11, Grad norm: 7.113e+00\n",
      "Epoch 21356, Loss: 109.36628723144531, Neurons: 11, Grad norm: 6.130e+00\n",
      "Epoch 21357, Loss: 109.35446166992188, Neurons: 11, Grad norm: 2.702e+00\n",
      "Epoch 21358, Loss: 109.34265899658203, Neurons: 11, Grad norm: 3.355e+00\n",
      "Epoch 21359, Loss: 109.33089447021484, Neurons: 11, Grad norm: 8.753e+00\n",
      "Epoch 21360, Loss: 109.31917572021484, Neurons: 11, Grad norm: 6.766e+00\n",
      "Epoch 21361, Loss: 109.30741882324219, Neurons: 11, Grad norm: 9.330e+00\n",
      "Epoch 21362, Loss: 109.29566955566406, Neurons: 11, Grad norm: 4.333e+00\n",
      "Epoch 21363, Loss: 109.28392028808594, Neurons: 11, Grad norm: 4.390e+00\n",
      "Epoch 21364, Loss: 109.27218627929688, Neurons: 11, Grad norm: 3.000e+00\n",
      "Epoch 21365, Loss: 109.26045989990234, Neurons: 11, Grad norm: 2.678e+00\n",
      "Epoch 21366, Loss: 109.24877166748047, Neurons: 11, Grad norm: 7.211e+00\n",
      "Epoch 21367, Loss: 109.23709869384766, Neurons: 11, Grad norm: 4.855e+00\n",
      "Epoch 21368, Loss: 109.22542572021484, Neurons: 11, Grad norm: 7.376e+00\n",
      "Epoch 21369, Loss: 109.2137451171875, Neurons: 11, Grad norm: 2.980e+00\n",
      "Epoch 21370, Loss: 109.20205688476562, Neurons: 11, Grad norm: 3.808e+00\n",
      "Epoch 21371, Loss: 109.19039916992188, Neurons: 11, Grad norm: 2.640e+00\n",
      "Epoch 21372, Loss: 109.1787338256836, Neurons: 11, Grad norm: 1.926e+00\n",
      "Epoch 21373, Loss: 109.16710662841797, Neurons: 11, Grad norm: 5.654e+00\n",
      "Epoch 21374, Loss: 109.15547180175781, Neurons: 11, Grad norm: 3.237e+00\n",
      "Epoch 21375, Loss: 109.14387512207031, Neurons: 11, Grad norm: 5.980e+00\n",
      "Epoch 21376, Loss: 109.13224792480469, Neurons: 11, Grad norm: 2.668e+00\n",
      "Epoch 21377, Loss: 109.12063598632812, Neurons: 11, Grad norm: 4.421e+00\n",
      "Epoch 21378, Loss: 109.10904693603516, Neurons: 11, Grad norm: 1.984e+00\n",
      "Epoch 21379, Loss: 109.09745025634766, Neurons: 11, Grad norm: 1.952e+00\n",
      "Epoch 21380, Loss: 109.08586883544922, Neurons: 11, Grad norm: 3.819e+00\n",
      "Epoch 21381, Loss: 109.07429504394531, Neurons: 11, Grad norm: 2.078e+00\n",
      "Epoch 21382, Loss: 109.062744140625, Neurons: 11, Grad norm: 5.165e+00\n",
      "Epoch 21383, Loss: 109.05118560791016, Neurons: 11, Grad norm: 2.241e+00\n",
      "Epoch 21384, Loss: 109.0396499633789, Neurons: 11, Grad norm: 4.169e+00\n",
      "Epoch 21385, Loss: 109.0280990600586, Neurons: 11, Grad norm: 1.790e+00\n",
      "Epoch 21386, Loss: 109.01657104492188, Neurons: 11, Grad norm: 2.908e+00\n",
      "Epoch 21387, Loss: 109.00505065917969, Neurons: 11, Grad norm: 2.608e+00\n",
      "Epoch 21388, Loss: 108.99353790283203, Neurons: 11, Grad norm: 1.816e+00\n",
      "Epoch 21389, Loss: 108.98202514648438, Neurons: 11, Grad norm: 3.719e+00\n",
      "Epoch 21390, Loss: 108.97055053710938, Neurons: 11, Grad norm: 1.810e+00\n",
      "Epoch 21391, Loss: 108.95904541015625, Neurons: 11, Grad norm: 4.158e+00\n",
      "Epoch 21392, Loss: 108.94754791259766, Neurons: 11, Grad norm: 1.829e+00\n",
      "Epoch 21393, Loss: 108.93607330322266, Neurons: 11, Grad norm: 3.743e+00\n",
      "Epoch 21394, Loss: 108.92462158203125, Neurons: 11, Grad norm: 1.839e+00\n",
      "Epoch 21395, Loss: 108.91314697265625, Neurons: 11, Grad norm: 2.800e+00\n",
      "Epoch 21396, Loss: 108.9017105102539, Neurons: 11, Grad norm: 2.389e+00\n",
      "Epoch 21397, Loss: 108.8902587890625, Neurons: 11, Grad norm: 2.089e+00\n",
      "Epoch 21398, Loss: 108.87882232666016, Neurons: 11, Grad norm: 3.148e+00\n",
      "Epoch 21399, Loss: 108.86739349365234, Neurons: 11, Grad norm: 1.817e+00\n",
      "Epoch 21399, Test loss: 104.99225616455078\n",
      "Epoch 21400, Loss: 108.85599517822266, Neurons: 11, Grad norm: 9.852e+00\n",
      "Epoch 21401, Loss: 108.84769439697266, Neurons: 11, Grad norm: 2.884e+00\n",
      "Epoch 21402, Loss: 108.83489990234375, Neurons: 11, Grad norm: 7.336e+00\n",
      "Epoch 21403, Loss: 108.82522583007812, Neurons: 11, Grad norm: 6.864e+00\n",
      "Epoch 21404, Loss: 108.8154067993164, Neurons: 11, Grad norm: 4.541e+00\n",
      "Epoch 21405, Loss: 108.8047866821289, Neurons: 11, Grad norm: 5.371e+00\n",
      "Epoch 21406, Loss: 108.79402160644531, Neurons: 11, Grad norm: 3.304e+00\n",
      "Epoch 21407, Loss: 108.7836685180664, Neurons: 11, Grad norm: 3.499e+00\n",
      "Epoch 21408, Loss: 108.77361297607422, Neurons: 11, Grad norm: 2.358e+00\n",
      "Epoch 21409, Loss: 108.76361846923828, Neurons: 11, Grad norm: 5.453e+00\n",
      "Epoch 21410, Loss: 108.75362396240234, Neurons: 11, Grad norm: 3.985e+00\n",
      "Epoch 21411, Loss: 108.74368286132812, Neurons: 11, Grad norm: 1.018e+01\n",
      "Epoch 21412, Loss: 108.73373413085938, Neurons: 11, Grad norm: 3.780e+00\n",
      "Epoch 21413, Loss: 108.72362518310547, Neurons: 11, Grad norm: 7.587e+00\n",
      "Epoch 21414, Loss: 108.71334838867188, Neurons: 11, Grad norm: 2.404e+00\n",
      "Epoch 21415, Loss: 108.70317077636719, Neurons: 11, Grad norm: 4.177e+00\n",
      "Epoch 21416, Loss: 108.6933364868164, Neurons: 11, Grad norm: 3.858e+00\n",
      "Epoch 21417, Loss: 108.68402099609375, Neurons: 11, Grad norm: 3.160e+00\n",
      "Epoch 21418, Loss: 108.67427062988281, Neurons: 11, Grad norm: 2.995e+00\n",
      "Epoch 21419, Loss: 108.66437530517578, Neurons: 11, Grad norm: 2.229e+00\n",
      "Epoch 21420, Loss: 108.65464782714844, Neurons: 11, Grad norm: 3.745e+00\n",
      "Epoch 21421, Loss: 108.64482116699219, Neurons: 11, Grad norm: 2.018e+00\n",
      "Epoch 21422, Loss: 108.6349105834961, Neurons: 11, Grad norm: 5.096e+00\n",
      "Epoch 21423, Loss: 108.62527465820312, Neurons: 11, Grad norm: 2.403e+00\n",
      "Epoch 21424, Loss: 108.6156997680664, Neurons: 11, Grad norm: 5.699e+00\n",
      "Epoch 21425, Loss: 108.60602569580078, Neurons: 11, Grad norm: 2.043e+00\n",
      "Epoch 21426, Loss: 108.59645080566406, Neurons: 11, Grad norm: 4.052e+00\n",
      "Epoch 21427, Loss: 108.58686065673828, Neurons: 11, Grad norm: 1.811e+00\n",
      "Epoch 21428, Loss: 108.5772476196289, Neurons: 11, Grad norm: 2.469e+00\n",
      "Epoch 21429, Loss: 108.56758117675781, Neurons: 11, Grad norm: 1.988e+00\n",
      "Epoch 21430, Loss: 108.55794525146484, Neurons: 11, Grad norm: 2.746e+00\n",
      "Epoch 21431, Loss: 108.54832458496094, Neurons: 11, Grad norm: 2.850e+00\n",
      "Epoch 21432, Loss: 108.53887176513672, Neurons: 11, Grad norm: 1.991e+00\n",
      "Epoch 21433, Loss: 108.52937316894531, Neurons: 11, Grad norm: 2.328e+00\n",
      "Epoch 21434, Loss: 108.51981353759766, Neurons: 11, Grad norm: 1.776e+00\n",
      "Epoch 21435, Loss: 108.51034545898438, Neurons: 11, Grad norm: 3.325e+00\n",
      "Epoch 21436, Loss: 108.50084686279297, Neurons: 11, Grad norm: 1.793e+00\n",
      "Epoch 21437, Loss: 108.49132537841797, Neurons: 11, Grad norm: 3.021e+00\n",
      "Epoch 21438, Loss: 108.48189544677734, Neurons: 11, Grad norm: 1.946e+00\n",
      "Epoch 21439, Loss: 108.4725112915039, Neurons: 11, Grad norm: 3.947e+00\n",
      "Epoch 21440, Loss: 108.46305084228516, Neurons: 11, Grad norm: 2.207e+00\n",
      "Epoch 21441, Loss: 108.45364379882812, Neurons: 11, Grad norm: 3.921e+00\n",
      "Epoch 21442, Loss: 108.44428253173828, Neurons: 11, Grad norm: 2.040e+00\n",
      "Epoch 21443, Loss: 108.43487548828125, Neurons: 11, Grad norm: 3.039e+00\n",
      "Epoch 21444, Loss: 108.42549896240234, Neurons: 11, Grad norm: 2.341e+00\n",
      "Epoch 21445, Loss: 108.41614532470703, Neurons: 11, Grad norm: 2.427e+00\n",
      "Epoch 21446, Loss: 108.40679931640625, Neurons: 11, Grad norm: 2.073e+00\n",
      "Epoch 21447, Loss: 108.39746856689453, Neurons: 11, Grad norm: 1.701e+00\n",
      "Epoch 21448, Loss: 108.38817596435547, Neurons: 11, Grad norm: 2.612e+00\n",
      "Epoch 21449, Loss: 108.37887573242188, Neurons: 11, Grad norm: 1.711e+00\n",
      "Epoch 21449, Test loss: 104.44672393798828\n",
      "Epoch 21450, Loss: 108.36957550048828, Neurons: 11, Grad norm: 3.452e+00\n",
      "Epoch 21451, Loss: 108.36029815673828, Neurons: 11, Grad norm: 1.771e+00\n",
      "Epoch 21452, Loss: 108.35104370117188, Neurons: 11, Grad norm: 4.084e+00\n",
      "Epoch 21453, Loss: 108.3417739868164, Neurons: 11, Grad norm: 1.869e+00\n",
      "Epoch 21454, Loss: 108.33251953125, Neurons: 11, Grad norm: 5.131e+00\n",
      "Epoch 21455, Loss: 108.32331848144531, Neurons: 11, Grad norm: 2.414e+00\n",
      "Epoch 21456, Loss: 108.31409454345703, Neurons: 11, Grad norm: 5.440e+00\n",
      "Epoch 21457, Loss: 108.30487060546875, Neurons: 11, Grad norm: 3.331e+00\n",
      "Epoch 21458, Loss: 108.29570007324219, Neurons: 11, Grad norm: 6.646e+00\n",
      "Epoch 21459, Loss: 108.2864990234375, Neurons: 11, Grad norm: 4.137e+00\n",
      "Epoch 21460, Loss: 108.2773208618164, Neurons: 11, Grad norm: 7.840e+00\n",
      "Epoch 21461, Loss: 108.26817321777344, Neurons: 11, Grad norm: 6.073e+00\n",
      "Epoch 21462, Loss: 108.259033203125, Neurons: 11, Grad norm: 9.824e+00\n",
      "Epoch 21463, Loss: 108.24990844726562, Neurons: 11, Grad norm: 7.850e+00\n",
      "Epoch 21464, Loss: 108.24080657958984, Neurons: 11, Grad norm: 1.229e+01\n",
      "Epoch 21465, Loss: 108.23169708251953, Neurons: 11, Grad norm: 1.100e+01\n",
      "Epoch 21466, Loss: 108.22259521484375, Neurons: 11, Grad norm: 1.524e+01\n",
      "Epoch 21467, Loss: 108.21354675292969, Neurons: 11, Grad norm: 1.432e+01\n",
      "Epoch 21468, Loss: 108.20452117919922, Neurons: 11, Grad norm: 1.921e+01\n",
      "Epoch 21469, Loss: 108.19549560546875, Neurons: 11, Grad norm: 1.814e+01\n",
      "Epoch 21470, Loss: 108.1865005493164, Neurons: 11, Grad norm: 2.336e+01\n",
      "Epoch 21471, Loss: 108.17754364013672, Neurons: 11, Grad norm: 2.190e+01\n",
      "Epoch 21472, Loss: 108.16858673095703, Neurons: 11, Grad norm: 2.640e+01\n",
      "Epoch 21473, Loss: 108.15963745117188, Neurons: 11, Grad norm: 2.393e+01\n",
      "Epoch 21474, Loss: 108.15069580078125, Neurons: 11, Grad norm: 2.651e+01\n",
      "Epoch 21475, Loss: 108.1417236328125, Neurons: 11, Grad norm: 2.162e+01\n",
      "Epoch 21476, Loss: 108.13274383544922, Neurons: 11, Grad norm: 2.138e+01\n",
      "Epoch 21477, Loss: 108.12374877929688, Neurons: 11, Grad norm: 1.463e+01\n",
      "Epoch 21478, Loss: 108.1147689819336, Neurons: 11, Grad norm: 1.217e+01\n",
      "Epoch 21479, Loss: 108.10579681396484, Neurons: 11, Grad norm: 4.253e+00\n",
      "Epoch 21480, Loss: 108.0969009399414, Neurons: 11, Grad norm: 2.452e+00\n",
      "Epoch 21481, Loss: 108.08802032470703, Neurons: 11, Grad norm: 6.426e+00\n",
      "Epoch 21482, Loss: 108.07920837402344, Neurons: 11, Grad norm: 7.249e+00\n",
      "Epoch 21483, Loss: 108.0704116821289, Neurons: 11, Grad norm: 1.274e+01\n",
      "Epoch 21484, Loss: 108.0616226196289, Neurons: 11, Grad norm: 1.158e+01\n",
      "Epoch 21485, Loss: 108.0528335571289, Neurons: 11, Grad norm: 1.546e+01\n",
      "Epoch 21486, Loss: 108.0440444946289, Neurons: 11, Grad norm: 1.165e+01\n",
      "Epoch 21487, Loss: 108.03527069091797, Neurons: 11, Grad norm: 1.316e+01\n",
      "Epoch 21488, Loss: 108.02644348144531, Neurons: 11, Grad norm: 8.371e+00\n",
      "Epoch 21489, Loss: 108.01766204833984, Neurons: 11, Grad norm: 8.491e+00\n",
      "Epoch 21490, Loss: 108.00887298583984, Neurons: 11, Grad norm: 2.798e+00\n",
      "Epoch 21491, Loss: 108.00010681152344, Neurons: 11, Grad norm: 2.869e+00\n",
      "Epoch 21492, Loss: 107.99137115478516, Neurons: 11, Grad norm: 3.751e+00\n",
      "Epoch 21493, Loss: 107.98261260986328, Neurons: 11, Grad norm: 3.272e+00\n",
      "Epoch 21494, Loss: 107.97390747070312, Neurons: 11, Grad norm: 7.609e+00\n",
      "Epoch 21495, Loss: 107.9652099609375, Neurons: 11, Grad norm: 5.988e+00\n",
      "Epoch 21496, Loss: 107.95651245117188, Neurons: 11, Grad norm: 9.661e+00\n",
      "Epoch 21497, Loss: 107.94782257080078, Neurons: 11, Grad norm: 6.774e+00\n",
      "Epoch 21498, Loss: 107.93912506103516, Neurons: 11, Grad norm: 9.441e+00\n",
      "Epoch 21499, Loss: 107.930419921875, Neurons: 11, Grad norm: 6.080e+00\n",
      "Epoch 21499, Test loss: 103.98531341552734\n",
      "Epoch 21500, Loss: 107.92174530029297, Neurons: 11, Grad norm: 8.006e+00\n",
      "Epoch 21501, Loss: 107.91307067871094, Neurons: 11, Grad norm: 3.813e+00\n",
      "Epoch 21502, Loss: 107.9044189453125, Neurons: 11, Grad norm: 5.316e+00\n",
      "Epoch 21503, Loss: 107.89574432373047, Neurons: 11, Grad norm: 1.753e+00\n",
      "Epoch 21504, Loss: 107.88710021972656, Neurons: 11, Grad norm: 2.474e+00\n",
      "Epoch 21505, Loss: 107.87844848632812, Neurons: 11, Grad norm: 3.208e+00\n",
      "Epoch 21506, Loss: 107.86981964111328, Neurons: 11, Grad norm: 2.035e+00\n",
      "Epoch 21507, Loss: 107.86119842529297, Neurons: 11, Grad norm: 5.462e+00\n",
      "Epoch 21508, Loss: 107.85260009765625, Neurons: 11, Grad norm: 3.629e+00\n",
      "Epoch 21509, Loss: 107.8439712524414, Neurons: 11, Grad norm: 7.026e+00\n",
      "Epoch 21510, Loss: 107.83537292480469, Neurons: 11, Grad norm: 4.376e+00\n",
      "Epoch 21511, Loss: 107.82677459716797, Neurons: 11, Grad norm: 7.418e+00\n",
      "Epoch 21512, Loss: 107.81818389892578, Neurons: 11, Grad norm: 4.571e+00\n",
      "Epoch 21513, Loss: 107.80960083007812, Neurons: 11, Grad norm: 7.135e+00\n",
      "Epoch 21514, Loss: 107.80101013183594, Neurons: 11, Grad norm: 3.848e+00\n",
      "Epoch 21515, Loss: 107.79241180419922, Neurons: 11, Grad norm: 6.271e+00\n",
      "Epoch 21516, Loss: 107.78385925292969, Neurons: 11, Grad norm: 2.946e+00\n",
      "Epoch 21517, Loss: 107.77529907226562, Neurons: 11, Grad norm: 5.186e+00\n",
      "Epoch 21518, Loss: 107.7667236328125, Neurons: 11, Grad norm: 2.271e+00\n",
      "Epoch 21519, Loss: 107.75818634033203, Neurons: 11, Grad norm: 4.423e+00\n",
      "Epoch 21520, Loss: 107.74961853027344, Neurons: 11, Grad norm: 1.819e+00\n",
      "Epoch 21521, Loss: 107.74109649658203, Neurons: 11, Grad norm: 3.682e+00\n",
      "Epoch 21522, Loss: 107.73255920410156, Neurons: 11, Grad norm: 1.695e+00\n",
      "Epoch 21523, Loss: 107.72403717041016, Neurons: 11, Grad norm: 3.000e+00\n",
      "Epoch 21524, Loss: 107.71549987792969, Neurons: 11, Grad norm: 1.977e+00\n",
      "Epoch 21525, Loss: 107.70698547363281, Neurons: 11, Grad norm: 2.307e+00\n",
      "Epoch 21526, Loss: 107.69849395751953, Neurons: 11, Grad norm: 2.493e+00\n",
      "Epoch 21527, Loss: 107.68997192382812, Neurons: 11, Grad norm: 1.858e+00\n",
      "Epoch 21528, Loss: 107.68147277832031, Neurons: 11, Grad norm: 3.363e+00\n",
      "Epoch 21529, Loss: 107.6729736328125, Neurons: 11, Grad norm: 1.719e+00\n",
      "Epoch 21530, Loss: 107.66448211669922, Neurons: 11, Grad norm: 4.036e+00\n",
      "Epoch 21531, Loss: 107.65601348876953, Neurons: 11, Grad norm: 2.084e+00\n",
      "Epoch 21532, Loss: 107.64752197265625, Neurons: 11, Grad norm: 5.067e+00\n",
      "Epoch 21533, Loss: 107.63904571533203, Neurons: 11, Grad norm: 2.730e+00\n",
      "Epoch 21534, Loss: 107.63056945800781, Neurons: 11, Grad norm: 6.042e+00\n",
      "Epoch 21535, Loss: 107.62212371826172, Neurons: 11, Grad norm: 3.681e+00\n",
      "Epoch 21536, Loss: 107.6136474609375, Neurons: 11, Grad norm: 6.781e+00\n",
      "Epoch 21537, Loss: 107.60519409179688, Neurons: 11, Grad norm: 4.444e+00\n",
      "Epoch 21538, Loss: 107.59674835205078, Neurons: 11, Grad norm: 8.191e+00\n",
      "Epoch 21539, Loss: 107.58832550048828, Neurons: 11, Grad norm: 5.806e+00\n",
      "Epoch 21540, Loss: 107.57987213134766, Neurons: 11, Grad norm: 9.337e+00\n",
      "Epoch 21541, Loss: 107.57144927978516, Neurons: 11, Grad norm: 7.433e+00\n",
      "Epoch 21542, Loss: 107.56301879882812, Neurons: 11, Grad norm: 1.166e+01\n",
      "Epoch 21543, Loss: 107.55461883544922, Neurons: 11, Grad norm: 9.989e+00\n",
      "Epoch 21544, Loss: 107.54621887207031, Neurons: 11, Grad norm: 1.471e+01\n",
      "Epoch 21545, Loss: 107.53784942626953, Neurons: 11, Grad norm: 1.392e+01\n",
      "Epoch 21546, Loss: 107.52948760986328, Neurons: 11, Grad norm: 1.932e+01\n",
      "Epoch 21547, Loss: 107.52114868164062, Neurons: 11, Grad norm: 1.902e+01\n",
      "Epoch 21548, Loss: 107.51284790039062, Neurons: 11, Grad norm: 2.514e+01\n",
      "Epoch 21549, Loss: 107.50457000732422, Neurons: 11, Grad norm: 2.525e+01\n",
      "Epoch 21549, Test loss: 103.54740905761719\n",
      "Epoch 21550, Loss: 107.49630737304688, Neurons: 11, Grad norm: 3.097e+01\n",
      "Epoch 21551, Loss: 107.48807525634766, Neurons: 11, Grad norm: 3.047e+01\n",
      "Epoch 21552, Loss: 107.47987365722656, Neurons: 11, Grad norm: 3.450e+01\n",
      "Epoch 21553, Loss: 107.47161865234375, Neurons: 11, Grad norm: 3.071e+01\n",
      "Epoch 21554, Loss: 107.46333312988281, Neurons: 11, Grad norm: 3.076e+01\n",
      "Epoch 21555, Loss: 107.45497131347656, Neurons: 11, Grad norm: 2.247e+01\n",
      "Epoch 21556, Loss: 107.44658660888672, Neurons: 11, Grad norm: 1.778e+01\n",
      "Epoch 21557, Loss: 107.43818664550781, Neurons: 11, Grad norm: 6.565e+00\n",
      "Epoch 21558, Loss: 107.42987060546875, Neurons: 11, Grad norm: 1.898e+00\n",
      "Epoch 21559, Loss: 107.42164611816406, Neurons: 11, Grad norm: 1.008e+01\n",
      "Epoch 21560, Loss: 107.41352081298828, Neurons: 11, Grad norm: 1.312e+01\n",
      "Epoch 21561, Loss: 107.40544891357422, Neurons: 11, Grad norm: 1.973e+01\n",
      "Epoch 21562, Loss: 107.39736938476562, Neurons: 11, Grad norm: 1.833e+01\n",
      "Epoch 21563, Loss: 107.38924407958984, Neurons: 11, Grad norm: 2.044e+01\n",
      "Epoch 21564, Loss: 107.38109588623047, Neurons: 11, Grad norm: 1.437e+01\n",
      "Epoch 21565, Loss: 107.37289428710938, Neurons: 11, Grad norm: 1.248e+01\n",
      "Epoch 21566, Loss: 107.36470031738281, Neurons: 11, Grad norm: 4.111e+00\n",
      "Epoch 21567, Loss: 107.35652160644531, Neurons: 11, Grad norm: 2.035e+00\n",
      "Epoch 21568, Loss: 107.3484115600586, Neurons: 11, Grad norm: 7.133e+00\n",
      "Epoch 21569, Loss: 107.3403091430664, Neurons: 11, Grad norm: 8.110e+00\n",
      "Epoch 21570, Loss: 107.33224487304688, Neurons: 11, Grad norm: 1.326e+01\n",
      "Epoch 21571, Loss: 107.32417297363281, Neurons: 11, Grad norm: 1.105e+01\n",
      "Epoch 21572, Loss: 107.31610870361328, Neurons: 11, Grad norm: 1.305e+01\n",
      "Epoch 21573, Loss: 107.30799865722656, Neurons: 11, Grad norm: 7.787e+00\n",
      "Epoch 21574, Loss: 107.29991149902344, Neurons: 11, Grad norm: 7.646e+00\n",
      "Epoch 21575, Loss: 107.29179382324219, Neurons: 11, Grad norm: 1.979e+00\n",
      "Epoch 21576, Loss: 107.28372192382812, Neurons: 11, Grad norm: 1.812e+00\n",
      "Epoch 21577, Loss: 107.27565002441406, Neurons: 11, Grad norm: 5.660e+00\n",
      "Epoch 21578, Loss: 107.26758575439453, Neurons: 11, Grad norm: 5.097e+00\n",
      "Epoch 21579, Loss: 107.25955963134766, Neurons: 11, Grad norm: 9.143e+00\n",
      "Epoch 21580, Loss: 107.25149536132812, Neurons: 11, Grad norm: 6.592e+00\n",
      "Epoch 21581, Loss: 107.24346160888672, Neurons: 11, Grad norm: 9.395e+00\n",
      "Epoch 21582, Loss: 107.23541259765625, Neurons: 11, Grad norm: 5.498e+00\n",
      "Epoch 21583, Loss: 107.22734832763672, Neurons: 11, Grad norm: 6.588e+00\n",
      "Epoch 21584, Loss: 107.21929931640625, Neurons: 11, Grad norm: 2.389e+00\n",
      "Epoch 21585, Loss: 107.21127319335938, Neurons: 11, Grad norm: 3.207e+00\n",
      "Epoch 21586, Loss: 107.2032470703125, Neurons: 11, Grad norm: 3.027e+00\n",
      "Epoch 21587, Loss: 107.19519805908203, Neurons: 11, Grad norm: 1.990e+00\n",
      "Epoch 21588, Loss: 107.1871566772461, Neurons: 11, Grad norm: 5.412e+00\n",
      "Epoch 21589, Loss: 107.17916107177734, Neurons: 11, Grad norm: 3.700e+00\n",
      "Epoch 21590, Loss: 107.17115020751953, Neurons: 11, Grad norm: 6.969e+00\n",
      "Epoch 21591, Loss: 107.16312408447266, Neurons: 11, Grad norm: 3.747e+00\n",
      "Epoch 21592, Loss: 107.15512084960938, Neurons: 11, Grad norm: 6.033e+00\n",
      "Epoch 21593, Loss: 107.14710998535156, Neurons: 11, Grad norm: 2.978e+00\n",
      "Epoch 21594, Loss: 107.13909912109375, Neurons: 11, Grad norm: 4.812e+00\n",
      "Epoch 21595, Loss: 107.13109588623047, Neurons: 11, Grad norm: 1.725e+00\n",
      "Epoch 21596, Loss: 107.1230697631836, Neurons: 11, Grad norm: 3.060e+00\n",
      "Epoch 21597, Loss: 107.11507415771484, Neurons: 11, Grad norm: 2.104e+00\n",
      "Epoch 21598, Loss: 107.10709381103516, Neurons: 11, Grad norm: 1.708e+00\n",
      "Epoch 21599, Loss: 107.0990982055664, Neurons: 11, Grad norm: 3.765e+00\n",
      "Epoch 21599, Test loss: 103.13819885253906\n",
      "Epoch 21600, Loss: 107.09109497070312, Neurons: 11, Grad norm: 1.863e+00\n",
      "Epoch 21601, Loss: 107.0831069946289, Neurons: 11, Grad norm: 4.792e+00\n",
      "Epoch 21602, Loss: 107.07511901855469, Neurons: 11, Grad norm: 2.563e+00\n",
      "Epoch 21603, Loss: 107.06714630126953, Neurons: 11, Grad norm: 5.074e+00\n",
      "Epoch 21604, Loss: 107.05917358398438, Neurons: 11, Grad norm: 2.439e+00\n",
      "Epoch 21605, Loss: 107.0511703491211, Neurons: 11, Grad norm: 5.036e+00\n",
      "Epoch 21606, Loss: 107.043212890625, Neurons: 11, Grad norm: 2.264e+00\n",
      "Epoch 21607, Loss: 107.03523254394531, Neurons: 11, Grad norm: 4.542e+00\n",
      "Epoch 21608, Loss: 107.0272445678711, Neurons: 11, Grad norm: 1.901e+00\n",
      "Epoch 21609, Loss: 107.01929473876953, Neurons: 11, Grad norm: 3.988e+00\n",
      "Epoch 21610, Loss: 107.01132202148438, Neurons: 11, Grad norm: 1.686e+00\n",
      "Epoch 21611, Loss: 107.00337219238281, Neurons: 11, Grad norm: 3.067e+00\n",
      "Epoch 21612, Loss: 106.99539947509766, Neurons: 11, Grad norm: 1.885e+00\n",
      "Epoch 21613, Loss: 106.98741912841797, Neurons: 11, Grad norm: 2.408e+00\n",
      "Epoch 21614, Loss: 106.9794692993164, Neurons: 11, Grad norm: 2.568e+00\n",
      "Epoch 21615, Loss: 106.97151184082031, Neurons: 11, Grad norm: 1.768e+00\n",
      "Epoch 21616, Loss: 106.96356964111328, Neurons: 11, Grad norm: 3.288e+00\n",
      "Epoch 21617, Loss: 106.95561218261719, Neurons: 11, Grad norm: 1.727e+00\n",
      "Epoch 21618, Loss: 106.94764709472656, Neurons: 11, Grad norm: 3.999e+00\n",
      "Epoch 21619, Loss: 106.9397201538086, Neurons: 11, Grad norm: 1.866e+00\n",
      "Epoch 21620, Loss: 106.9317626953125, Neurons: 11, Grad norm: 4.456e+00\n",
      "Epoch 21621, Loss: 106.92382049560547, Neurons: 11, Grad norm: 2.098e+00\n",
      "Epoch 21622, Loss: 106.9158706665039, Neurons: 11, Grad norm: 4.797e+00\n",
      "Epoch 21623, Loss: 106.90792083740234, Neurons: 11, Grad norm: 2.412e+00\n",
      "Epoch 21624, Loss: 106.89999389648438, Neurons: 11, Grad norm: 5.330e+00\n",
      "Epoch 21625, Loss: 106.89207458496094, Neurons: 11, Grad norm: 2.910e+00\n",
      "Epoch 21626, Loss: 106.88412475585938, Neurons: 11, Grad norm: 5.970e+00\n",
      "Epoch 21627, Loss: 106.8761978149414, Neurons: 11, Grad norm: 3.594e+00\n",
      "Epoch 21628, Loss: 106.86827087402344, Neurons: 11, Grad norm: 7.227e+00\n",
      "Epoch 21629, Loss: 106.86033630371094, Neurons: 11, Grad norm: 5.178e+00\n",
      "Epoch 21630, Loss: 106.85242462158203, Neurons: 11, Grad norm: 8.734e+00\n",
      "Epoch 21631, Loss: 106.84449768066406, Neurons: 11, Grad norm: 6.657e+00\n",
      "Epoch 21632, Loss: 106.83659362792969, Neurons: 11, Grad norm: 1.069e+01\n",
      "Epoch 21633, Loss: 106.82867431640625, Neurons: 11, Grad norm: 8.608e+00\n",
      "Epoch 21634, Loss: 106.82077026367188, Neurons: 11, Grad norm: 1.292e+01\n",
      "Epoch 21635, Loss: 106.81287384033203, Neurons: 11, Grad norm: 1.178e+01\n",
      "Epoch 21636, Loss: 106.80498504638672, Neurons: 11, Grad norm: 1.660e+01\n",
      "Epoch 21637, Loss: 106.797119140625, Neurons: 11, Grad norm: 1.555e+01\n",
      "Epoch 21638, Loss: 106.78926849365234, Neurons: 11, Grad norm: 2.111e+01\n",
      "Epoch 21639, Loss: 106.78143310546875, Neurons: 11, Grad norm: 2.079e+01\n",
      "Epoch 21640, Loss: 106.77361297607422, Neurons: 11, Grad norm: 2.633e+01\n",
      "Epoch 21641, Loss: 106.76583099365234, Neurons: 11, Grad norm: 2.605e+01\n",
      "Epoch 21642, Loss: 106.75807189941406, Neurons: 11, Grad norm: 3.138e+01\n",
      "Epoch 21643, Loss: 106.75032043457031, Neurons: 11, Grad norm: 2.983e+01\n",
      "Epoch 21644, Loss: 106.74254608154297, Neurons: 11, Grad norm: 3.292e+01\n",
      "Epoch 21645, Loss: 106.73477172851562, Neurons: 11, Grad norm: 2.858e+01\n",
      "Epoch 21646, Loss: 106.72692108154297, Neurons: 11, Grad norm: 2.784e+01\n",
      "Epoch 21647, Loss: 106.71904754638672, Neurons: 11, Grad norm: 1.953e+01\n",
      "Epoch 21648, Loss: 106.71114349365234, Neurons: 11, Grad norm: 1.612e+01\n",
      "Epoch 21649, Loss: 106.70328521728516, Neurons: 11, Grad norm: 5.942e+00\n",
      "Epoch 21649, Test loss: 102.7362060546875\n",
      "Epoch 21650, Loss: 106.6954574584961, Neurons: 11, Grad norm: 2.126e+00\n",
      "Epoch 21651, Loss: 106.6877212524414, Neurons: 11, Grad norm: 8.143e+00\n",
      "Epoch 21652, Loss: 106.68002319335938, Neurons: 11, Grad norm: 1.047e+01\n",
      "Epoch 21653, Loss: 106.67237091064453, Neurons: 11, Grad norm: 1.754e+01\n",
      "Epoch 21654, Loss: 106.6646957397461, Neurons: 11, Grad norm: 1.652e+01\n",
      "Epoch 21655, Loss: 106.65705108642578, Neurons: 11, Grad norm: 1.956e+01\n",
      "Epoch 21656, Loss: 106.64937591552734, Neurons: 11, Grad norm: 1.542e+01\n",
      "Epoch 21657, Loss: 106.64163208007812, Neurons: 11, Grad norm: 1.561e+01\n",
      "Epoch 21658, Loss: 106.6338882446289, Neurons: 11, Grad norm: 8.500e+00\n",
      "Epoch 21659, Loss: 106.62614440917969, Neurons: 11, Grad norm: 6.848e+00\n",
      "Epoch 21660, Loss: 106.6184310913086, Neurons: 11, Grad norm: 1.808e+00\n",
      "Epoch 21661, Loss: 106.61074829101562, Neurons: 11, Grad norm: 2.514e+00\n",
      "Epoch 21662, Loss: 106.60308837890625, Neurons: 11, Grad norm: 8.677e+00\n",
      "Epoch 21663, Loss: 106.59542083740234, Neurons: 11, Grad norm: 8.081e+00\n",
      "Epoch 21664, Loss: 106.58779907226562, Neurons: 11, Grad norm: 1.230e+01\n",
      "Epoch 21665, Loss: 106.58012390136719, Neurons: 11, Grad norm: 1.010e+01\n",
      "Epoch 21666, Loss: 106.57249450683594, Neurons: 11, Grad norm: 1.241e+01\n",
      "Epoch 21667, Loss: 106.5648193359375, Neurons: 11, Grad norm: 7.642e+00\n",
      "Epoch 21668, Loss: 106.55712127685547, Neurons: 11, Grad norm: 8.824e+00\n",
      "Epoch 21669, Loss: 106.54946899414062, Neurons: 11, Grad norm: 3.923e+00\n",
      "Epoch 21670, Loss: 106.54179382324219, Neurons: 11, Grad norm: 4.118e+00\n",
      "Epoch 21671, Loss: 106.53411865234375, Neurons: 11, Grad norm: 2.262e+00\n",
      "Epoch 21672, Loss: 106.52649688720703, Neurons: 11, Grad norm: 1.745e+00\n",
      "Epoch 21673, Loss: 106.51883697509766, Neurons: 11, Grad norm: 5.312e+00\n",
      "Epoch 21674, Loss: 106.51119995117188, Neurons: 11, Grad norm: 3.742e+00\n",
      "Epoch 21675, Loss: 106.50354766845703, Neurons: 11, Grad norm: 7.098e+00\n",
      "Epoch 21676, Loss: 106.49592590332031, Neurons: 11, Grad norm: 4.487e+00\n",
      "Epoch 21677, Loss: 106.4882583618164, Neurons: 11, Grad norm: 7.229e+00\n",
      "Epoch 21678, Loss: 106.48062133789062, Neurons: 11, Grad norm: 3.902e+00\n",
      "Epoch 21679, Loss: 106.47296905517578, Neurons: 11, Grad norm: 6.042e+00\n",
      "Epoch 21680, Loss: 106.46533203125, Neurons: 11, Grad norm: 2.604e+00\n",
      "Epoch 21681, Loss: 106.45769500732422, Neurons: 11, Grad norm: 4.346e+00\n",
      "Epoch 21682, Loss: 106.4500503540039, Neurons: 11, Grad norm: 1.714e+00\n",
      "Epoch 21683, Loss: 106.44241333007812, Neurons: 11, Grad norm: 2.511e+00\n",
      "Epoch 21684, Loss: 106.43476867675781, Neurons: 11, Grad norm: 2.546e+00\n",
      "Epoch 21685, Loss: 106.4271469116211, Neurons: 11, Grad norm: 1.728e+00\n",
      "Epoch 21686, Loss: 106.41950988769531, Neurons: 11, Grad norm: 3.856e+00\n",
      "Epoch 21687, Loss: 106.41187286376953, Neurons: 11, Grad norm: 1.998e+00\n",
      "Epoch 21688, Loss: 106.40425872802734, Neurons: 11, Grad norm: 4.957e+00\n",
      "Epoch 21689, Loss: 106.3966064453125, Neurons: 11, Grad norm: 2.700e+00\n",
      "Epoch 21690, Loss: 106.38896942138672, Neurons: 11, Grad norm: 5.566e+00\n",
      "Epoch 21691, Loss: 106.38134765625, Neurons: 11, Grad norm: 2.967e+00\n",
      "Epoch 21692, Loss: 106.37372589111328, Neurons: 11, Grad norm: 5.865e+00\n",
      "Epoch 21693, Loss: 106.36609649658203, Neurons: 11, Grad norm: 3.049e+00\n",
      "Epoch 21694, Loss: 106.35844421386719, Neurons: 11, Grad norm: 5.477e+00\n",
      "Epoch 21695, Loss: 106.35083770751953, Neurons: 11, Grad norm: 2.769e+00\n",
      "Epoch 21696, Loss: 106.34320831298828, Neurons: 11, Grad norm: 5.595e+00\n",
      "Epoch 21697, Loss: 106.3355712890625, Neurons: 11, Grad norm: 2.819e+00\n",
      "Epoch 21698, Loss: 106.32794952392578, Neurons: 11, Grad norm: 5.347e+00\n",
      "Epoch 21699, Loss: 106.3203353881836, Neurons: 11, Grad norm: 2.698e+00\n",
      "Epoch 21699, Test loss: 102.35005187988281\n",
      "Epoch 21700, Loss: 106.3127212524414, Neurons: 11, Grad norm: 5.220e+00\n",
      "Epoch 21701, Loss: 106.30508422851562, Neurons: 11, Grad norm: 2.515e+00\n",
      "Epoch 21702, Loss: 106.2974624633789, Neurons: 11, Grad norm: 5.339e+00\n",
      "Epoch 21703, Loss: 106.28983306884766, Neurons: 11, Grad norm: 2.696e+00\n",
      "Epoch 21704, Loss: 106.28221893310547, Neurons: 11, Grad norm: 5.586e+00\n",
      "Epoch 21705, Loss: 106.27459716796875, Neurons: 11, Grad norm: 3.243e+00\n",
      "Epoch 21706, Loss: 106.26698303222656, Neurons: 11, Grad norm: 6.354e+00\n",
      "Epoch 21707, Loss: 106.25936889648438, Neurons: 11, Grad norm: 3.913e+00\n",
      "Epoch 21708, Loss: 106.25174713134766, Neurons: 11, Grad norm: 7.446e+00\n",
      "Epoch 21709, Loss: 106.24412536621094, Neurons: 11, Grad norm: 5.215e+00\n",
      "Epoch 21710, Loss: 106.23651885986328, Neurons: 11, Grad norm: 8.628e+00\n",
      "Epoch 21711, Loss: 106.22891998291016, Neurons: 11, Grad norm: 6.654e+00\n",
      "Epoch 21712, Loss: 106.22129821777344, Neurons: 11, Grad norm: 1.064e+01\n",
      "Epoch 21713, Loss: 106.21369934082031, Neurons: 11, Grad norm: 8.580e+00\n",
      "Epoch 21714, Loss: 106.20610046386719, Neurons: 11, Grad norm: 1.281e+01\n",
      "Epoch 21715, Loss: 106.19849395751953, Neurons: 11, Grad norm: 1.136e+01\n",
      "Epoch 21716, Loss: 106.19092559814453, Neurons: 11, Grad norm: 1.602e+01\n",
      "Epoch 21717, Loss: 106.18333435058594, Neurons: 11, Grad norm: 1.493e+01\n",
      "Epoch 21718, Loss: 106.17578125, Neurons: 11, Grad norm: 2.022e+01\n",
      "Epoch 21719, Loss: 106.1682357788086, Neurons: 11, Grad norm: 1.979e+01\n",
      "Epoch 21720, Loss: 106.16072082519531, Neurons: 11, Grad norm: 2.514e+01\n",
      "Epoch 21721, Loss: 106.15321350097656, Neurons: 11, Grad norm: 2.465e+01\n",
      "Epoch 21722, Loss: 106.14570617675781, Neurons: 11, Grad norm: 3.019e+01\n",
      "Epoch 21723, Loss: 106.13823699951172, Neurons: 11, Grad norm: 2.945e+01\n",
      "Epoch 21724, Loss: 106.13078308105469, Neurons: 11, Grad norm: 3.375e+01\n",
      "Epoch 21725, Loss: 106.12332153320312, Neurons: 11, Grad norm: 3.119e+01\n",
      "Epoch 21726, Loss: 106.1158447265625, Neurons: 11, Grad norm: 3.312e+01\n",
      "Epoch 21727, Loss: 106.10834503173828, Neurons: 11, Grad norm: 2.733e+01\n",
      "Epoch 21728, Loss: 106.10076904296875, Neurons: 11, Grad norm: 2.544e+01\n",
      "Epoch 21729, Loss: 106.09318542480469, Neurons: 11, Grad norm: 1.617e+01\n",
      "Epoch 21730, Loss: 106.0855941772461, Neurons: 11, Grad norm: 1.184e+01\n",
      "Epoch 21731, Loss: 106.07807159423828, Neurons: 11, Grad norm: 2.105e+00\n",
      "Epoch 21732, Loss: 106.07058715820312, Neurons: 11, Grad norm: 3.575e+00\n",
      "Epoch 21733, Loss: 106.06317138671875, Neurons: 11, Grad norm: 1.214e+01\n",
      "Epoch 21734, Loss: 106.0558090209961, Neurons: 11, Grad norm: 1.371e+01\n",
      "Epoch 21735, Loss: 106.0484619140625, Neurons: 11, Grad norm: 1.981e+01\n",
      "Epoch 21736, Loss: 106.04112243652344, Neurons: 11, Grad norm: 1.784e+01\n",
      "Epoch 21737, Loss: 106.03373718261719, Neurons: 11, Grad norm: 1.999e+01\n",
      "Epoch 21738, Loss: 106.02629852294922, Neurons: 11, Grad norm: 1.498e+01\n",
      "Epoch 21739, Loss: 106.01887512207031, Neurons: 11, Grad norm: 1.434e+01\n",
      "Epoch 21740, Loss: 106.01142120361328, Neurons: 11, Grad norm: 7.035e+00\n",
      "Epoch 21741, Loss: 106.00398254394531, Neurons: 11, Grad norm: 5.366e+00\n",
      "Epoch 21742, Loss: 105.99657440185547, Neurons: 11, Grad norm: 3.014e+00\n",
      "Epoch 21743, Loss: 105.98919677734375, Neurons: 11, Grad norm: 3.887e+00\n",
      "Epoch 21744, Loss: 105.98181915283203, Neurons: 11, Grad norm: 9.600e+00\n",
      "Epoch 21745, Loss: 105.97445678710938, Neurons: 11, Grad norm: 9.013e+00\n",
      "Epoch 21746, Loss: 105.96710968017578, Neurons: 11, Grad norm: 1.320e+01\n",
      "Epoch 21747, Loss: 105.95974731445312, Neurons: 11, Grad norm: 1.029e+01\n",
      "Epoch 21748, Loss: 105.9523696899414, Neurons: 11, Grad norm: 1.236e+01\n",
      "Epoch 21749, Loss: 105.94498443603516, Neurons: 11, Grad norm: 7.744e+00\n",
      "Epoch 21749, Test loss: 101.96973419189453\n",
      "Epoch 21750, Loss: 105.9375991821289, Neurons: 11, Grad norm: 8.246e+00\n",
      "Epoch 21751, Loss: 105.93020629882812, Neurons: 11, Grad norm: 3.035e+00\n",
      "Epoch 21752, Loss: 105.92281341552734, Neurons: 11, Grad norm: 3.241e+00\n",
      "Epoch 21753, Loss: 105.91545104980469, Neurons: 11, Grad norm: 3.348e+00\n",
      "Epoch 21754, Loss: 105.90807342529297, Neurons: 11, Grad norm: 2.853e+00\n",
      "Epoch 21755, Loss: 105.90071868896484, Neurons: 11, Grad norm: 7.232e+00\n",
      "Epoch 21756, Loss: 105.89335632324219, Neurons: 11, Grad norm: 5.666e+00\n",
      "Epoch 21757, Loss: 105.88599395751953, Neurons: 11, Grad norm: 9.527e+00\n",
      "Epoch 21758, Loss: 105.87862396240234, Neurons: 11, Grad norm: 6.981e+00\n",
      "Epoch 21759, Loss: 105.87126922607422, Neurons: 11, Grad norm: 9.627e+00\n",
      "Epoch 21760, Loss: 105.86390686035156, Neurons: 11, Grad norm: 6.207e+00\n",
      "Epoch 21761, Loss: 105.85653686523438, Neurons: 11, Grad norm: 8.150e+00\n",
      "Epoch 21762, Loss: 105.84917449951172, Neurons: 11, Grad norm: 4.164e+00\n",
      "Epoch 21763, Loss: 105.841796875, Neurons: 11, Grad norm: 5.695e+00\n",
      "Epoch 21764, Loss: 105.83441925048828, Neurons: 11, Grad norm: 2.063e+00\n",
      "Epoch 21765, Loss: 105.8270492553711, Neurons: 11, Grad norm: 3.204e+00\n",
      "Epoch 21766, Loss: 105.81969451904297, Neurons: 11, Grad norm: 2.261e+00\n",
      "Epoch 21767, Loss: 105.81232452392578, Neurons: 11, Grad norm: 1.780e+00\n",
      "Epoch 21768, Loss: 105.80496978759766, Neurons: 11, Grad norm: 4.004e+00\n",
      "Epoch 21769, Loss: 105.797607421875, Neurons: 11, Grad norm: 2.123e+00\n",
      "Epoch 21770, Loss: 105.79024505615234, Neurons: 11, Grad norm: 5.065e+00\n",
      "Epoch 21771, Loss: 105.78288269042969, Neurons: 11, Grad norm: 2.850e+00\n",
      "Epoch 21772, Loss: 105.7755126953125, Neurons: 11, Grad norm: 5.437e+00\n",
      "Epoch 21773, Loss: 105.76815795898438, Neurons: 11, Grad norm: 2.802e+00\n",
      "Epoch 21774, Loss: 105.76078796386719, Neurons: 11, Grad norm: 5.615e+00\n",
      "Epoch 21775, Loss: 105.75343322753906, Neurons: 11, Grad norm: 2.850e+00\n",
      "Epoch 21776, Loss: 105.7460708618164, Neurons: 11, Grad norm: 5.384e+00\n",
      "Epoch 21777, Loss: 105.73870849609375, Neurons: 11, Grad norm: 2.748e+00\n",
      "Epoch 21778, Loss: 105.7313461303711, Neurons: 11, Grad norm: 5.208e+00\n",
      "Epoch 21779, Loss: 105.72398376464844, Neurons: 11, Grad norm: 2.436e+00\n",
      "Epoch 21780, Loss: 105.71662139892578, Neurons: 11, Grad norm: 4.768e+00\n",
      "Epoch 21781, Loss: 105.70925903320312, Neurons: 11, Grad norm: 2.134e+00\n",
      "Epoch 21782, Loss: 105.70189666748047, Neurons: 11, Grad norm: 4.074e+00\n",
      "Epoch 21783, Loss: 105.69451904296875, Neurons: 11, Grad norm: 1.820e+00\n",
      "Epoch 21784, Loss: 105.6871566772461, Neurons: 11, Grad norm: 3.797e+00\n",
      "Epoch 21785, Loss: 105.67979431152344, Neurons: 11, Grad norm: 1.787e+00\n",
      "Epoch 21786, Loss: 105.67242431640625, Neurons: 11, Grad norm: 3.841e+00\n",
      "Epoch 21787, Loss: 105.66506958007812, Neurons: 11, Grad norm: 1.954e+00\n",
      "Epoch 21788, Loss: 105.65770721435547, Neurons: 11, Grad norm: 4.495e+00\n",
      "Epoch 21789, Loss: 105.65034484863281, Neurons: 11, Grad norm: 2.227e+00\n",
      "Epoch 21790, Loss: 105.64297485351562, Neurons: 11, Grad norm: 5.224e+00\n",
      "Epoch 21791, Loss: 105.6356201171875, Neurons: 11, Grad norm: 3.090e+00\n",
      "Epoch 21792, Loss: 105.62825775146484, Neurons: 11, Grad norm: 6.011e+00\n",
      "Epoch 21793, Loss: 105.62088775634766, Neurons: 11, Grad norm: 3.960e+00\n",
      "Epoch 21794, Loss: 105.613525390625, Neurons: 11, Grad norm: 7.653e+00\n",
      "Epoch 21795, Loss: 105.60616302490234, Neurons: 11, Grad norm: 5.465e+00\n",
      "Epoch 21796, Loss: 105.59880065917969, Neurons: 11, Grad norm: 9.487e+00\n",
      "Epoch 21797, Loss: 105.59143829345703, Neurons: 11, Grad norm: 8.218e+00\n",
      "Epoch 21798, Loss: 105.58409881591797, Neurons: 11, Grad norm: 1.277e+01\n",
      "Epoch 21799, Loss: 105.57673645019531, Neurons: 11, Grad norm: 1.152e+01\n",
      "Epoch 21799, Test loss: 101.59799194335938\n",
      "Epoch 21800, Loss: 105.56941223144531, Neurons: 11, Grad norm: 1.689e+01\n",
      "Epoch 21801, Loss: 105.56208801269531, Neurons: 11, Grad norm: 1.671e+01\n",
      "Epoch 21802, Loss: 105.55477142333984, Neurons: 11, Grad norm: 2.250e+01\n",
      "Epoch 21803, Loss: 105.5475082397461, Neurons: 11, Grad norm: 2.309e+01\n",
      "Epoch 21804, Loss: 105.5402603149414, Neurons: 11, Grad norm: 2.999e+01\n",
      "Epoch 21805, Loss: 105.53303527832031, Neurons: 11, Grad norm: 3.109e+01\n",
      "Epoch 21806, Loss: 105.52586364746094, Neurons: 11, Grad norm: 3.768e+01\n",
      "Epoch 21807, Loss: 105.5186996459961, Neurons: 11, Grad norm: 3.789e+01\n",
      "Epoch 21808, Loss: 105.5115737915039, Neurons: 11, Grad norm: 4.229e+01\n",
      "Epoch 21809, Loss: 105.50439453125, Neurons: 11, Grad norm: 3.851e+01\n",
      "Epoch 21810, Loss: 105.49713134765625, Neurons: 11, Grad norm: 3.779e+01\n",
      "Epoch 21811, Loss: 105.48979949951172, Neurons: 11, Grad norm: 2.815e+01\n",
      "Epoch 21812, Loss: 105.48237609863281, Neurons: 11, Grad norm: 2.154e+01\n",
      "Epoch 21813, Loss: 105.47494506835938, Neurons: 11, Grad norm: 8.063e+00\n",
      "Epoch 21814, Loss: 105.46764373779297, Neurons: 11, Grad norm: 1.789e+00\n",
      "Epoch 21815, Loss: 105.46044921875, Neurons: 11, Grad norm: 1.261e+01\n",
      "Epoch 21816, Loss: 105.453369140625, Neurons: 11, Grad norm: 1.690e+01\n",
      "Epoch 21817, Loss: 105.44635009765625, Neurons: 11, Grad norm: 2.398e+01\n",
      "Epoch 21818, Loss: 105.43930053710938, Neurons: 11, Grad norm: 2.239e+01\n",
      "Epoch 21819, Loss: 105.43222045898438, Neurons: 11, Grad norm: 2.343e+01\n",
      "Epoch 21820, Loss: 105.425048828125, Neurons: 11, Grad norm: 1.603e+01\n",
      "Epoch 21821, Loss: 105.41783142089844, Neurons: 11, Grad norm: 1.269e+01\n",
      "Epoch 21822, Loss: 105.41063690185547, Neurons: 11, Grad norm: 3.080e+00\n",
      "Epoch 21823, Loss: 105.40345764160156, Neurons: 11, Grad norm: 2.314e+00\n",
      "Epoch 21824, Loss: 105.39634704589844, Neurons: 11, Grad norm: 1.017e+01\n",
      "Epoch 21825, Loss: 105.3892822265625, Neurons: 11, Grad norm: 1.129e+01\n",
      "Epoch 21826, Loss: 105.3822250366211, Neurons: 11, Grad norm: 1.631e+01\n",
      "Epoch 21827, Loss: 105.3751449584961, Neurons: 11, Grad norm: 1.355e+01\n",
      "Epoch 21828, Loss: 105.36804962158203, Neurons: 11, Grad norm: 1.455e+01\n",
      "Epoch 21829, Loss: 105.36092376708984, Neurons: 11, Grad norm: 8.640e+00\n",
      "Epoch 21830, Loss: 105.35379791259766, Neurons: 11, Grad norm: 7.648e+00\n",
      "Epoch 21831, Loss: 105.3466567993164, Neurons: 11, Grad norm: 1.799e+00\n",
      "Epoch 21832, Loss: 105.33954620361328, Neurons: 11, Grad norm: 2.101e+00\n",
      "Epoch 21833, Loss: 105.33245849609375, Neurons: 11, Grad norm: 7.445e+00\n",
      "Epoch 21834, Loss: 105.32539367675781, Neurons: 11, Grad norm: 7.015e+00\n",
      "Epoch 21835, Loss: 105.31829833984375, Neurons: 11, Grad norm: 1.103e+01\n",
      "Epoch 21836, Loss: 105.31122589111328, Neurons: 11, Grad norm: 8.025e+00\n",
      "Epoch 21837, Loss: 105.30413818359375, Neurons: 11, Grad norm: 9.956e+00\n",
      "Epoch 21838, Loss: 105.2970199584961, Neurons: 11, Grad norm: 5.565e+00\n",
      "Epoch 21839, Loss: 105.28992462158203, Neurons: 11, Grad norm: 6.143e+00\n",
      "Epoch 21840, Loss: 105.28282165527344, Neurons: 11, Grad norm: 1.887e+00\n",
      "Epoch 21841, Loss: 105.2757339477539, Neurons: 11, Grad norm: 2.090e+00\n",
      "Epoch 21842, Loss: 105.26863861083984, Neurons: 11, Grad norm: 4.301e+00\n",
      "Epoch 21843, Loss: 105.26155090332031, Neurons: 11, Grad norm: 3.118e+00\n",
      "Epoch 21844, Loss: 105.25444793701172, Neurons: 11, Grad norm: 6.884e+00\n",
      "Epoch 21845, Loss: 105.24737548828125, Neurons: 11, Grad norm: 4.829e+00\n",
      "Epoch 21846, Loss: 105.24027252197266, Neurons: 11, Grad norm: 7.518e+00\n",
      "Epoch 21847, Loss: 105.23320007324219, Neurons: 11, Grad norm: 4.226e+00\n",
      "Epoch 21848, Loss: 105.22608184814453, Neurons: 11, Grad norm: 6.294e+00\n",
      "Epoch 21849, Loss: 105.21898651123047, Neurons: 11, Grad norm: 2.745e+00\n",
      "Epoch 21849, Test loss: 101.23540496826172\n",
      "Epoch 21850, Loss: 105.21188354492188, Neurons: 11, Grad norm: 3.957e+00\n",
      "Epoch 21851, Loss: 105.20479583740234, Neurons: 11, Grad norm: 1.948e+00\n",
      "Epoch 21852, Loss: 105.19770050048828, Neurons: 11, Grad norm: 2.001e+00\n",
      "Epoch 21853, Loss: 105.19059753417969, Neurons: 11, Grad norm: 3.797e+00\n",
      "Epoch 21854, Loss: 105.18352508544922, Neurons: 11, Grad norm: 2.326e+00\n",
      "Epoch 21855, Loss: 105.17642211914062, Neurons: 11, Grad norm: 5.428e+00\n",
      "Epoch 21856, Loss: 105.16931915283203, Neurons: 11, Grad norm: 3.336e+00\n",
      "Epoch 21857, Loss: 105.16222381591797, Neurons: 11, Grad norm: 6.263e+00\n",
      "Epoch 21858, Loss: 105.15512084960938, Neurons: 11, Grad norm: 3.488e+00\n",
      "Epoch 21859, Loss: 105.14802551269531, Neurons: 11, Grad norm: 5.904e+00\n",
      "Epoch 21860, Loss: 105.14092254638672, Neurons: 11, Grad norm: 2.882e+00\n",
      "Epoch 21861, Loss: 105.13381958007812, Neurons: 11, Grad norm: 4.739e+00\n",
      "Epoch 21862, Loss: 105.1267318725586, Neurons: 11, Grad norm: 1.988e+00\n",
      "Epoch 21863, Loss: 105.11962127685547, Neurons: 11, Grad norm: 3.533e+00\n",
      "Epoch 21864, Loss: 105.1125259399414, Neurons: 11, Grad norm: 1.988e+00\n",
      "Epoch 21865, Loss: 105.10540771484375, Neurons: 11, Grad norm: 2.269e+00\n",
      "Epoch 21866, Loss: 105.09832000732422, Neurons: 11, Grad norm: 2.730e+00\n",
      "Epoch 21867, Loss: 105.09122467041016, Neurons: 11, Grad norm: 1.812e+00\n",
      "Epoch 21868, Loss: 105.08412170410156, Neurons: 11, Grad norm: 3.918e+00\n",
      "Epoch 21869, Loss: 105.07699584960938, Neurons: 11, Grad norm: 2.030e+00\n",
      "Epoch 21870, Loss: 105.0699234008789, Neurons: 11, Grad norm: 4.670e+00\n",
      "Epoch 21871, Loss: 105.06279754638672, Neurons: 11, Grad norm: 2.575e+00\n",
      "Epoch 21872, Loss: 105.0556869506836, Neurons: 11, Grad norm: 5.040e+00\n",
      "Epoch 21873, Loss: 105.048583984375, Neurons: 11, Grad norm: 2.673e+00\n",
      "Epoch 21874, Loss: 105.04147338867188, Neurons: 11, Grad norm: 5.619e+00\n",
      "Epoch 21875, Loss: 105.03437042236328, Neurons: 11, Grad norm: 3.175e+00\n",
      "Epoch 21876, Loss: 105.02725982666016, Neurons: 11, Grad norm: 5.878e+00\n",
      "Epoch 21877, Loss: 105.02015686035156, Neurons: 11, Grad norm: 3.553e+00\n",
      "Epoch 21878, Loss: 105.01304626464844, Neurons: 11, Grad norm: 6.481e+00\n",
      "Epoch 21879, Loss: 105.00595092773438, Neurons: 11, Grad norm: 3.674e+00\n",
      "Epoch 21880, Loss: 104.99882507324219, Neurons: 11, Grad norm: 6.439e+00\n",
      "Epoch 21881, Loss: 104.99170684814453, Neurons: 11, Grad norm: 4.026e+00\n",
      "Epoch 21882, Loss: 104.9845962524414, Neurons: 11, Grad norm: 6.659e+00\n",
      "Epoch 21883, Loss: 104.97750091552734, Neurons: 11, Grad norm: 3.781e+00\n",
      "Epoch 21884, Loss: 104.97037506103516, Neurons: 11, Grad norm: 6.926e+00\n",
      "Epoch 21885, Loss: 104.9632568359375, Neurons: 11, Grad norm: 4.497e+00\n",
      "Epoch 21886, Loss: 104.95614624023438, Neurons: 11, Grad norm: 7.109e+00\n",
      "Epoch 21887, Loss: 104.94905090332031, Neurons: 11, Grad norm: 4.763e+00\n",
      "Epoch 21888, Loss: 104.94193267822266, Neurons: 11, Grad norm: 8.036e+00\n",
      "Epoch 21889, Loss: 104.93482208251953, Neurons: 11, Grad norm: 5.163e+00\n",
      "Epoch 21890, Loss: 104.92769622802734, Neurons: 11, Grad norm: 8.170e+00\n",
      "Epoch 21891, Loss: 104.92058563232422, Neurons: 11, Grad norm: 6.191e+00\n",
      "Epoch 21892, Loss: 104.9134750366211, Neurons: 11, Grad norm: 9.555e+00\n",
      "Epoch 21893, Loss: 104.9063720703125, Neurons: 11, Grad norm: 7.271e+00\n",
      "Epoch 21894, Loss: 104.8992691040039, Neurons: 11, Grad norm: 1.136e+01\n",
      "Epoch 21895, Loss: 104.89217376708984, Neurons: 11, Grad norm: 9.788e+00\n",
      "Epoch 21896, Loss: 104.88504791259766, Neurons: 11, Grad norm: 1.397e+01\n",
      "Epoch 21897, Loss: 104.87797546386719, Neurons: 11, Grad norm: 1.303e+01\n",
      "Epoch 21898, Loss: 104.8708724975586, Neurons: 11, Grad norm: 1.840e+01\n",
      "Epoch 21899, Loss: 104.86382293701172, Neurons: 11, Grad norm: 1.830e+01\n",
      "Epoch 21899, Test loss: 100.87409973144531\n",
      "Epoch 21900, Loss: 104.85678100585938, Neurons: 11, Grad norm: 2.449e+01\n",
      "Epoch 21901, Loss: 104.84974670410156, Neurons: 11, Grad norm: 2.584e+01\n",
      "Epoch 21902, Loss: 104.84275817871094, Neurons: 11, Grad norm: 3.316e+01\n",
      "Epoch 21903, Loss: 104.8358383178711, Neurons: 11, Grad norm: 3.470e+01\n",
      "Epoch 21904, Loss: 104.82893371582031, Neurons: 11, Grad norm: 4.191e+01\n",
      "Epoch 21905, Loss: 104.82205963134766, Neurons: 11, Grad norm: 4.248e+01\n",
      "Epoch 21906, Loss: 104.81520080566406, Neurons: 11, Grad norm: 4.634e+01\n",
      "Epoch 21907, Loss: 104.80828857421875, Neurons: 11, Grad norm: 4.176e+01\n",
      "Epoch 21908, Loss: 104.80123138427734, Neurons: 11, Grad norm: 3.926e+01\n",
      "Epoch 21909, Loss: 104.79407501220703, Neurons: 11, Grad norm: 2.722e+01\n",
      "Epoch 21910, Loss: 104.78684997558594, Neurons: 11, Grad norm: 1.850e+01\n",
      "Epoch 21911, Loss: 104.77967071533203, Neurons: 11, Grad norm: 3.745e+00\n",
      "Epoch 21912, Loss: 104.77265167236328, Neurons: 11, Grad norm: 6.171e+00\n",
      "Epoch 21913, Loss: 104.76578521728516, Neurons: 11, Grad norm: 1.879e+01\n",
      "Epoch 21914, Loss: 104.75902557373047, Neurons: 11, Grad norm: 2.253e+01\n",
      "Epoch 21915, Loss: 104.75228118896484, Neurons: 11, Grad norm: 2.833e+01\n",
      "Epoch 21916, Loss: 104.74549865722656, Neurons: 11, Grad norm: 2.491e+01\n",
      "Epoch 21917, Loss: 104.73860931396484, Neurons: 11, Grad norm: 2.335e+01\n",
      "Epoch 21918, Loss: 104.73162841796875, Neurons: 11, Grad norm: 1.350e+01\n",
      "Epoch 21919, Loss: 104.72464752197266, Neurons: 11, Grad norm: 8.151e+00\n",
      "Epoch 21920, Loss: 104.71771240234375, Neurons: 11, Grad norm: 3.796e+00\n",
      "Epoch 21921, Loss: 104.7108383178711, Neurons: 11, Grad norm: 7.996e+00\n",
      "Epoch 21922, Loss: 104.70402526855469, Neurons: 11, Grad norm: 1.580e+01\n",
      "Epoch 21923, Loss: 104.69723510742188, Neurons: 11, Grad norm: 1.555e+01\n",
      "Epoch 21924, Loss: 104.69043731689453, Neurons: 11, Grad norm: 1.852e+01\n",
      "Epoch 21925, Loss: 104.68359375, Neurons: 11, Grad norm: 1.350e+01\n",
      "Epoch 21926, Loss: 104.67671203613281, Neurons: 11, Grad norm: 1.236e+01\n",
      "Epoch 21927, Loss: 104.66981506347656, Neurons: 11, Grad norm: 5.012e+00\n",
      "Epoch 21928, Loss: 104.66294860839844, Neurons: 11, Grad norm: 2.890e+00\n",
      "Epoch 21929, Loss: 104.65608215332031, Neurons: 11, Grad norm: 5.760e+00\n",
      "Epoch 21930, Loss: 104.6492691040039, Neurons: 11, Grad norm: 6.332e+00\n",
      "Epoch 21931, Loss: 104.6424331665039, Neurons: 11, Grad norm: 1.112e+01\n",
      "Epoch 21932, Loss: 104.63561248779297, Neurons: 11, Grad norm: 9.073e+00\n",
      "Epoch 21933, Loss: 104.62879943847656, Neurons: 11, Grad norm: 1.102e+01\n",
      "Epoch 21934, Loss: 104.6219253540039, Neurons: 11, Grad norm: 6.398e+00\n",
      "Epoch 21935, Loss: 104.61508178710938, Neurons: 11, Grad norm: 6.720e+00\n",
      "Epoch 21936, Loss: 104.60823822021484, Neurons: 11, Grad norm: 1.974e+00\n",
      "Epoch 21937, Loss: 104.60137939453125, Neurons: 11, Grad norm: 1.928e+00\n",
      "Epoch 21938, Loss: 104.59453582763672, Neurons: 11, Grad norm: 5.002e+00\n",
      "Epoch 21939, Loss: 104.58769989013672, Neurons: 11, Grad norm: 4.218e+00\n",
      "Epoch 21940, Loss: 104.58087158203125, Neurons: 11, Grad norm: 8.086e+00\n",
      "Epoch 21941, Loss: 104.57404327392578, Neurons: 11, Grad norm: 5.558e+00\n",
      "Epoch 21942, Loss: 104.56720733642578, Neurons: 11, Grad norm: 7.681e+00\n",
      "Epoch 21943, Loss: 104.56035614013672, Neurons: 11, Grad norm: 4.022e+00\n",
      "Epoch 21944, Loss: 104.55349731445312, Neurons: 11, Grad norm: 5.130e+00\n",
      "Epoch 21945, Loss: 104.54663848876953, Neurons: 11, Grad norm: 1.871e+00\n",
      "Epoch 21946, Loss: 104.539794921875, Neurons: 11, Grad norm: 2.187e+00\n",
      "Epoch 21947, Loss: 104.53296661376953, Neurons: 11, Grad norm: 3.751e+00\n",
      "Epoch 21948, Loss: 104.52613067626953, Neurons: 11, Grad norm: 2.641e+00\n",
      "Epoch 21949, Loss: 104.51927947998047, Neurons: 11, Grad norm: 5.696e+00\n",
      "Epoch 21949, Test loss: 100.52799987792969\n",
      "Epoch 21950, Loss: 104.5124282836914, Neurons: 11, Grad norm: 3.271e+00\n",
      "Epoch 21951, Loss: 104.50557708740234, Neurons: 11, Grad norm: 5.846e+00\n",
      "Epoch 21952, Loss: 104.49874114990234, Neurons: 11, Grad norm: 2.920e+00\n",
      "Epoch 21953, Loss: 104.49188232421875, Neurons: 11, Grad norm: 4.535e+00\n",
      "Epoch 21954, Loss: 104.48502349853516, Neurons: 11, Grad norm: 1.950e+00\n",
      "Epoch 21955, Loss: 104.47818756103516, Neurons: 11, Grad norm: 3.228e+00\n",
      "Epoch 21956, Loss: 104.4713134765625, Neurons: 11, Grad norm: 2.287e+00\n",
      "Epoch 21957, Loss: 104.46446990966797, Neurons: 11, Grad norm: 2.020e+00\n",
      "Epoch 21958, Loss: 104.45761108398438, Neurons: 11, Grad norm: 3.037e+00\n",
      "Epoch 21959, Loss: 104.45077514648438, Neurons: 11, Grad norm: 1.887e+00\n",
      "Epoch 21960, Loss: 104.44390106201172, Neurons: 11, Grad norm: 4.004e+00\n",
      "Epoch 21961, Loss: 104.43704986572266, Neurons: 11, Grad norm: 2.009e+00\n",
      "Epoch 21962, Loss: 104.43019104003906, Neurons: 11, Grad norm: 4.055e+00\n",
      "Epoch 21963, Loss: 104.42333221435547, Neurons: 11, Grad norm: 2.106e+00\n",
      "Epoch 21964, Loss: 104.41646575927734, Neurons: 11, Grad norm: 4.100e+00\n",
      "Epoch 21965, Loss: 104.40959930419922, Neurons: 11, Grad norm: 1.924e+00\n",
      "Epoch 21966, Loss: 104.40276336669922, Neurons: 11, Grad norm: 3.498e+00\n",
      "Epoch 21967, Loss: 104.3958740234375, Neurons: 11, Grad norm: 1.876e+00\n",
      "Epoch 21968, Loss: 104.38902282714844, Neurons: 11, Grad norm: 2.592e+00\n",
      "Epoch 21969, Loss: 104.38215637207031, Neurons: 11, Grad norm: 2.468e+00\n",
      "Epoch 21970, Loss: 104.37528228759766, Neurons: 11, Grad norm: 2.245e+00\n",
      "Epoch 21971, Loss: 104.368408203125, Neurons: 11, Grad norm: 2.796e+00\n",
      "Epoch 21972, Loss: 104.36155700683594, Neurons: 11, Grad norm: 1.895e+00\n",
      "Epoch 21973, Loss: 104.35468292236328, Neurons: 11, Grad norm: 2.959e+00\n",
      "Epoch 21974, Loss: 104.34781646728516, Neurons: 11, Grad norm: 1.959e+00\n",
      "Epoch 21975, Loss: 104.34095764160156, Neurons: 11, Grad norm: 3.349e+00\n",
      "Epoch 21976, Loss: 104.33407592773438, Neurons: 11, Grad norm: 1.920e+00\n",
      "Epoch 21977, Loss: 104.32719421386719, Neurons: 11, Grad norm: 3.054e+00\n",
      "Epoch 21978, Loss: 104.3203353881836, Neurons: 11, Grad norm: 1.878e+00\n",
      "Epoch 21979, Loss: 104.31343841552734, Neurons: 11, Grad norm: 3.208e+00\n",
      "Epoch 21980, Loss: 104.30657196044922, Neurons: 11, Grad norm: 1.975e+00\n",
      "Epoch 21981, Loss: 104.2996826171875, Neurons: 11, Grad norm: 3.003e+00\n",
      "Epoch 21982, Loss: 104.29280853271484, Neurons: 11, Grad norm: 1.964e+00\n",
      "Epoch 21983, Loss: 104.28594207763672, Neurons: 11, Grad norm: 2.773e+00\n",
      "Epoch 21984, Loss: 104.279052734375, Neurons: 11, Grad norm: 2.061e+00\n",
      "Epoch 21985, Loss: 104.27217102050781, Neurons: 11, Grad norm: 2.775e+00\n",
      "Epoch 21986, Loss: 104.26528930664062, Neurons: 11, Grad norm: 2.208e+00\n",
      "Epoch 21987, Loss: 104.25840759277344, Neurons: 11, Grad norm: 2.408e+00\n",
      "Epoch 21988, Loss: 104.25151824951172, Neurons: 11, Grad norm: 2.187e+00\n",
      "Epoch 21989, Loss: 104.24462890625, Neurons: 11, Grad norm: 2.480e+00\n",
      "Epoch 21990, Loss: 104.23774719238281, Neurons: 11, Grad norm: 2.476e+00\n",
      "Epoch 21991, Loss: 104.2308578491211, Neurons: 11, Grad norm: 2.290e+00\n",
      "Epoch 21992, Loss: 104.22396850585938, Neurons: 11, Grad norm: 2.515e+00\n",
      "Epoch 21993, Loss: 104.21707153320312, Neurons: 11, Grad norm: 1.956e+00\n",
      "Epoch 21994, Loss: 104.2101821899414, Neurons: 11, Grad norm: 3.146e+00\n",
      "Epoch 21995, Loss: 104.20330047607422, Neurons: 11, Grad norm: 1.988e+00\n",
      "Epoch 21996, Loss: 104.19639587402344, Neurons: 11, Grad norm: 3.493e+00\n",
      "Epoch 21997, Loss: 104.18951416015625, Neurons: 11, Grad norm: 1.975e+00\n",
      "Epoch 21998, Loss: 104.18260955810547, Neurons: 11, Grad norm: 3.779e+00\n",
      "Epoch 21999, Loss: 104.17571258544922, Neurons: 11, Grad norm: 2.089e+00\n",
      "Epoch 21999, Test loss: 100.1806411743164\n",
      "Epoch 22000, Loss: 104.16880798339844, Neurons: 11, Grad norm: 4.966e+00\n",
      "Epoch 22001, Loss: 104.16191864013672, Neurons: 11, Grad norm: 2.944e+00\n",
      "Epoch 22002, Loss: 104.15501403808594, Neurons: 11, Grad norm: 5.983e+00\n",
      "Epoch 22003, Loss: 104.14810943603516, Neurons: 11, Grad norm: 4.732e+00\n",
      "Epoch 22004, Loss: 104.1412124633789, Neurons: 11, Grad norm: 8.849e+00\n",
      "Epoch 22005, Loss: 104.13432312011719, Neurons: 11, Grad norm: 7.379e+00\n",
      "Epoch 22006, Loss: 104.12742614746094, Neurons: 11, Grad norm: 1.246e+01\n",
      "Epoch 22007, Loss: 104.12054443359375, Neurons: 11, Grad norm: 1.281e+01\n",
      "Epoch 22008, Loss: 104.11368560791016, Neurons: 11, Grad norm: 1.897e+01\n",
      "Epoch 22009, Loss: 104.1068344116211, Neurons: 11, Grad norm: 2.056e+01\n",
      "Epoch 22010, Loss: 104.10004425048828, Neurons: 11, Grad norm: 2.939e+01\n",
      "Epoch 22011, Loss: 104.0932846069336, Neurons: 11, Grad norm: 3.369e+01\n",
      "Epoch 22012, Loss: 104.08663940429688, Neurons: 11, Grad norm: 4.437e+01\n",
      "Epoch 22013, Loss: 104.08010864257812, Neurons: 11, Grad norm: 5.073e+01\n",
      "Epoch 22014, Loss: 104.07371520996094, Neurons: 11, Grad norm: 6.187e+01\n",
      "Epoch 22015, Loss: 104.06737518310547, Neurons: 11, Grad norm: 6.414e+01\n",
      "Epoch 22016, Loss: 104.06098175048828, Neurons: 11, Grad norm: 6.610e+01\n",
      "Epoch 22017, Loss: 104.05423736572266, Neurons: 11, Grad norm: 5.432e+01\n",
      "Epoch 22018, Loss: 104.04703521728516, Neurons: 11, Grad norm: 3.873e+01\n",
      "Epoch 22019, Loss: 104.03958129882812, Neurons: 11, Grad norm: 1.232e+01\n",
      "Epoch 22020, Loss: 104.03239440917969, Neurons: 11, Grad norm: 9.169e+00\n",
      "Epoch 22021, Loss: 104.02578735351562, Neurons: 11, Grad norm: 3.143e+01\n",
      "Epoch 22022, Loss: 104.01960754394531, Neurons: 11, Grad norm: 4.017e+01\n",
      "Epoch 22023, Loss: 104.01345825195312, Neurons: 11, Grad norm: 4.373e+01\n",
      "Epoch 22024, Loss: 104.00697326660156, Neurons: 11, Grad norm: 3.195e+01\n",
      "Epoch 22025, Loss: 104.00009155273438, Neurons: 11, Grad norm: 1.841e+01\n",
      "Epoch 22026, Loss: 103.9931640625, Neurons: 11, Grad norm: 4.119e+00\n",
      "Epoch 22027, Loss: 103.98651885986328, Neurons: 11, Grad norm: 1.788e+01\n",
      "Epoch 22028, Loss: 103.98018646240234, Neurons: 11, Grad norm: 3.065e+01\n",
      "Epoch 22029, Loss: 103.97393035888672, Neurons: 11, Grad norm: 2.956e+01\n",
      "Epoch 22030, Loss: 103.96748352050781, Neurons: 11, Grad norm: 2.569e+01\n",
      "Epoch 22031, Loss: 103.9608154296875, Neurons: 11, Grad norm: 1.042e+01\n",
      "Epoch 22032, Loss: 103.95410919189453, Neurons: 11, Grad norm: 2.490e+00\n",
      "Epoch 22033, Loss: 103.94757080078125, Neurons: 11, Grad norm: 1.660e+01\n",
      "Epoch 22034, Loss: 103.94120788574219, Neurons: 11, Grad norm: 2.090e+01\n",
      "Epoch 22035, Loss: 103.93487548828125, Neurons: 11, Grad norm: 2.396e+01\n",
      "Epoch 22036, Loss: 103.92839813232422, Neurons: 11, Grad norm: 1.534e+01\n",
      "Epoch 22037, Loss: 103.92180633544922, Neurons: 11, Grad norm: 8.356e+00\n",
      "Epoch 22038, Loss: 103.91524505615234, Neurons: 11, Grad norm: 5.547e+00\n",
      "Epoch 22039, Loss: 103.90876007080078, Neurons: 11, Grad norm: 1.128e+01\n",
      "Epoch 22040, Loss: 103.9023666381836, Neurons: 11, Grad norm: 1.808e+01\n",
      "Epoch 22041, Loss: 103.89595031738281, Neurons: 11, Grad norm: 1.466e+01\n",
      "Epoch 22042, Loss: 103.88948059082031, Neurons: 11, Grad norm: 1.254e+01\n",
      "Epoch 22043, Loss: 103.88294982910156, Neurons: 11, Grad norm: 2.859e+00\n",
      "Epoch 22044, Loss: 103.87643432617188, Neurons: 11, Grad norm: 3.463e+00\n",
      "Epoch 22045, Loss: 103.86998748779297, Neurons: 11, Grad norm: 1.133e+01\n",
      "Epoch 22046, Loss: 103.86356353759766, Neurons: 11, Grad norm: 1.132e+01\n",
      "Epoch 22047, Loss: 103.85713195800781, Neurons: 11, Grad norm: 1.307e+01\n",
      "Epoch 22048, Loss: 103.85064697265625, Neurons: 11, Grad norm: 6.474e+00\n",
      "Epoch 22049, Loss: 103.84416198730469, Neurons: 11, Grad norm: 4.004e+00\n",
      "Epoch 22049, Test loss: 99.84369659423828\n",
      "Epoch 22050, Loss: 103.8376693725586, Neurons: 11, Grad norm: 5.038e+00\n",
      "Epoch 22051, Loss: 103.83120727539062, Neurons: 11, Grad norm: 6.617e+00\n",
      "Epoch 22052, Loss: 103.82476043701172, Neurons: 11, Grad norm: 1.112e+01\n",
      "Epoch 22053, Loss: 103.81832122802734, Neurons: 11, Grad norm: 7.687e+00\n",
      "Epoch 22054, Loss: 103.81184387207031, Neurons: 11, Grad norm: 7.768e+00\n",
      "Epoch 22055, Loss: 103.80535888671875, Neurons: 11, Grad norm: 2.119e+00\n",
      "Epoch 22056, Loss: 103.79888153076172, Neurons: 11, Grad norm: 2.113e+00\n",
      "Epoch 22057, Loss: 103.79241943359375, Neurons: 11, Grad norm: 7.042e+00\n",
      "Epoch 22058, Loss: 103.78597259521484, Neurons: 11, Grad norm: 5.850e+00\n",
      "Epoch 22059, Loss: 103.77950286865234, Neurons: 11, Grad norm: 8.364e+00\n",
      "Epoch 22060, Loss: 103.77303314208984, Neurons: 11, Grad norm: 4.038e+00\n",
      "Epoch 22061, Loss: 103.76655578613281, Neurons: 11, Grad norm: 3.608e+00\n",
      "Epoch 22062, Loss: 103.76007080078125, Neurons: 11, Grad norm: 3.172e+00\n",
      "Epoch 22063, Loss: 103.75360107421875, Neurons: 11, Grad norm: 2.711e+00\n",
      "Epoch 22064, Loss: 103.74713134765625, Neurons: 11, Grad norm: 6.528e+00\n",
      "Epoch 22065, Loss: 103.74066162109375, Neurons: 11, Grad norm: 4.108e+00\n",
      "Epoch 22066, Loss: 103.73419189453125, Neurons: 11, Grad norm: 5.294e+00\n",
      "Epoch 22067, Loss: 103.72770690917969, Neurons: 11, Grad norm: 2.082e+00\n",
      "Epoch 22068, Loss: 103.72123718261719, Neurons: 11, Grad norm: 2.621e+00\n",
      "Epoch 22069, Loss: 103.7147445678711, Neurons: 11, Grad norm: 3.499e+00\n",
      "Epoch 22070, Loss: 103.7082748413086, Neurons: 11, Grad norm: 2.362e+00\n",
      "Epoch 22071, Loss: 103.70179748535156, Neurons: 11, Grad norm: 4.869e+00\n",
      "Epoch 22072, Loss: 103.6953125, Neurons: 11, Grad norm: 2.725e+00\n",
      "Epoch 22073, Loss: 103.68883514404297, Neurons: 11, Grad norm: 4.542e+00\n",
      "Epoch 22074, Loss: 103.6823501586914, Neurons: 11, Grad norm: 1.968e+00\n",
      "Epoch 22075, Loss: 103.67586517333984, Neurons: 11, Grad norm: 2.683e+00\n",
      "Epoch 22076, Loss: 103.66935729980469, Neurons: 11, Grad norm: 2.776e+00\n",
      "Epoch 22077, Loss: 103.66289520263672, Neurons: 11, Grad norm: 2.004e+00\n",
      "Epoch 22078, Loss: 103.6563949584961, Neurons: 11, Grad norm: 4.292e+00\n",
      "Epoch 22079, Loss: 103.64991760253906, Neurons: 11, Grad norm: 2.290e+00\n",
      "Epoch 22080, Loss: 103.64342498779297, Neurons: 11, Grad norm: 4.169e+00\n",
      "Epoch 22081, Loss: 103.63693237304688, Neurons: 11, Grad norm: 1.974e+00\n",
      "Epoch 22082, Loss: 103.63043212890625, Neurons: 11, Grad norm: 2.684e+00\n",
      "Epoch 22083, Loss: 103.62393188476562, Neurons: 11, Grad norm: 2.813e+00\n",
      "Epoch 22084, Loss: 103.61744689941406, Neurons: 11, Grad norm: 1.964e+00\n",
      "Epoch 22085, Loss: 103.6109390258789, Neurons: 11, Grad norm: 3.951e+00\n",
      "Epoch 22086, Loss: 103.60443115234375, Neurons: 11, Grad norm: 2.215e+00\n",
      "Epoch 22087, Loss: 103.59794616699219, Neurons: 11, Grad norm: 3.900e+00\n",
      "Epoch 22088, Loss: 103.59143829345703, Neurons: 11, Grad norm: 1.983e+00\n",
      "Epoch 22089, Loss: 103.5849380493164, Neurons: 11, Grad norm: 2.897e+00\n",
      "Epoch 22090, Loss: 103.57843780517578, Neurons: 11, Grad norm: 2.595e+00\n",
      "Epoch 22091, Loss: 103.57193756103516, Neurons: 11, Grad norm: 1.950e+00\n",
      "Epoch 22092, Loss: 103.56542205810547, Neurons: 11, Grad norm: 3.589e+00\n",
      "Epoch 22093, Loss: 103.55892181396484, Neurons: 11, Grad norm: 2.025e+00\n",
      "Epoch 22094, Loss: 103.55240631103516, Neurons: 11, Grad norm: 3.637e+00\n",
      "Epoch 22095, Loss: 103.54591369628906, Neurons: 11, Grad norm: 1.994e+00\n",
      "Epoch 22096, Loss: 103.53939056396484, Neurons: 11, Grad norm: 2.672e+00\n",
      "Epoch 22097, Loss: 103.53288269042969, Neurons: 11, Grad norm: 2.336e+00\n",
      "Epoch 22098, Loss: 103.52635955810547, Neurons: 11, Grad norm: 2.183e+00\n",
      "Epoch 22099, Loss: 103.51985168457031, Neurons: 11, Grad norm: 2.925e+00\n",
      "Epoch 22099, Test loss: 99.5169448852539\n",
      "Epoch 22100, Loss: 103.51332092285156, Neurons: 11, Grad norm: 2.036e+00\n",
      "Epoch 22101, Loss: 103.5068130493164, Neurons: 11, Grad norm: 2.843e+00\n",
      "Epoch 22102, Loss: 103.50028991699219, Neurons: 11, Grad norm: 2.074e+00\n",
      "Epoch 22103, Loss: 103.49378204345703, Neurons: 11, Grad norm: 2.642e+00\n",
      "Epoch 22104, Loss: 103.48724365234375, Neurons: 11, Grad norm: 2.386e+00\n",
      "Epoch 22105, Loss: 103.48074340820312, Neurons: 11, Grad norm: 2.380e+00\n",
      "Epoch 22106, Loss: 103.47421264648438, Neurons: 11, Grad norm: 2.487e+00\n",
      "Epoch 22107, Loss: 103.46768188476562, Neurons: 11, Grad norm: 2.107e+00\n",
      "Epoch 22108, Loss: 103.46116638183594, Neurons: 11, Grad norm: 2.730e+00\n",
      "Epoch 22109, Loss: 103.45462036132812, Neurons: 11, Grad norm: 2.278e+00\n",
      "Epoch 22110, Loss: 103.4480972290039, Neurons: 11, Grad norm: 2.634e+00\n",
      "Epoch 22111, Loss: 103.44157409667969, Neurons: 11, Grad norm: 2.305e+00\n",
      "Epoch 22112, Loss: 103.43502044677734, Neurons: 11, Grad norm: 2.154e+00\n",
      "Epoch 22113, Loss: 103.42849731445312, Neurons: 11, Grad norm: 2.699e+00\n",
      "Epoch 22114, Loss: 103.4219741821289, Neurons: 11, Grad norm: 2.140e+00\n",
      "Epoch 22115, Loss: 103.41543579101562, Neurons: 11, Grad norm: 3.194e+00\n",
      "Epoch 22116, Loss: 103.40888977050781, Neurons: 11, Grad norm: 2.014e+00\n",
      "Epoch 22117, Loss: 103.40234375, Neurons: 11, Grad norm: 2.761e+00\n",
      "Epoch 22118, Loss: 103.39579772949219, Neurons: 11, Grad norm: 2.126e+00\n",
      "Epoch 22119, Loss: 103.38924407958984, Neurons: 11, Grad norm: 2.601e+00\n",
      "Epoch 22120, Loss: 103.3827133178711, Neurons: 11, Grad norm: 2.652e+00\n",
      "Epoch 22121, Loss: 103.37616729736328, Neurons: 11, Grad norm: 2.092e+00\n",
      "Epoch 22122, Loss: 103.36962127685547, Neurons: 11, Grad norm: 2.851e+00\n",
      "Epoch 22123, Loss: 103.36307525634766, Neurons: 11, Grad norm: 1.978e+00\n",
      "Epoch 22124, Loss: 103.35652160644531, Neurons: 11, Grad norm: 3.463e+00\n",
      "Epoch 22125, Loss: 103.3499755859375, Neurons: 11, Grad norm: 2.014e+00\n",
      "Epoch 22126, Loss: 103.34343719482422, Neurons: 11, Grad norm: 3.129e+00\n",
      "Epoch 22127, Loss: 103.33685302734375, Neurons: 11, Grad norm: 1.973e+00\n",
      "Epoch 22128, Loss: 103.33031463623047, Neurons: 11, Grad norm: 3.043e+00\n",
      "Epoch 22129, Loss: 103.32376098632812, Neurons: 11, Grad norm: 2.131e+00\n",
      "Epoch 22130, Loss: 103.31720733642578, Neurons: 11, Grad norm: 2.918e+00\n",
      "Epoch 22131, Loss: 103.3106460571289, Neurons: 11, Grad norm: 2.121e+00\n",
      "Epoch 22132, Loss: 103.3040771484375, Neurons: 11, Grad norm: 2.384e+00\n",
      "Epoch 22133, Loss: 103.29751586914062, Neurons: 11, Grad norm: 2.361e+00\n",
      "Epoch 22134, Loss: 103.29094696044922, Neurons: 11, Grad norm: 2.572e+00\n",
      "Epoch 22135, Loss: 103.2844009399414, Neurons: 11, Grad norm: 2.453e+00\n",
      "Epoch 22136, Loss: 103.2778091430664, Neurons: 11, Grad norm: 2.406e+00\n",
      "Epoch 22137, Loss: 103.27124786376953, Neurons: 11, Grad norm: 2.064e+00\n",
      "Epoch 22138, Loss: 103.2646713256836, Neurons: 11, Grad norm: 3.010e+00\n",
      "Epoch 22139, Loss: 103.25809478759766, Neurons: 11, Grad norm: 2.026e+00\n",
      "Epoch 22140, Loss: 103.25153350830078, Neurons: 11, Grad norm: 3.750e+00\n",
      "Epoch 22141, Loss: 103.24495697021484, Neurons: 11, Grad norm: 2.150e+00\n",
      "Epoch 22142, Loss: 103.23838806152344, Neurons: 11, Grad norm: 4.023e+00\n",
      "Epoch 22143, Loss: 103.23179626464844, Neurons: 11, Grad norm: 2.350e+00\n",
      "Epoch 22144, Loss: 103.22522735595703, Neurons: 11, Grad norm: 4.823e+00\n",
      "Epoch 22145, Loss: 103.21865844726562, Neurons: 11, Grad norm: 2.602e+00\n",
      "Epoch 22146, Loss: 103.21208190917969, Neurons: 11, Grad norm: 4.868e+00\n",
      "Epoch 22147, Loss: 103.2054672241211, Neurons: 11, Grad norm: 2.899e+00\n",
      "Epoch 22148, Loss: 103.19891357421875, Neurons: 11, Grad norm: 5.102e+00\n",
      "Epoch 22149, Loss: 103.19232177734375, Neurons: 11, Grad norm: 2.686e+00\n",
      "Epoch 22149, Test loss: 99.18688201904297\n",
      "Epoch 22150, Loss: 103.18572998046875, Neurons: 11, Grad norm: 5.054e+00\n",
      "Epoch 22151, Loss: 103.17914581298828, Neurons: 11, Grad norm: 2.746e+00\n",
      "Epoch 22152, Loss: 103.17256164550781, Neurons: 11, Grad norm: 4.577e+00\n",
      "Epoch 22153, Loss: 103.16596984863281, Neurons: 11, Grad norm: 2.489e+00\n",
      "Epoch 22154, Loss: 103.15937042236328, Neurons: 11, Grad norm: 4.895e+00\n",
      "Epoch 22155, Loss: 103.15278625488281, Neurons: 11, Grad norm: 2.586e+00\n",
      "Epoch 22156, Loss: 103.14618682861328, Neurons: 11, Grad norm: 4.953e+00\n",
      "Epoch 22157, Loss: 103.13959503173828, Neurons: 11, Grad norm: 3.399e+00\n",
      "Epoch 22158, Loss: 103.13299560546875, Neurons: 11, Grad norm: 6.366e+00\n",
      "Epoch 22159, Loss: 103.12641143798828, Neurons: 11, Grad norm: 4.457e+00\n",
      "Epoch 22160, Loss: 103.11981201171875, Neurons: 11, Grad norm: 8.179e+00\n",
      "Epoch 22161, Loss: 103.11321258544922, Neurons: 11, Grad norm: 6.817e+00\n",
      "Epoch 22162, Loss: 103.10662078857422, Neurons: 11, Grad norm: 1.050e+01\n",
      "Epoch 22163, Loss: 103.10003662109375, Neurons: 11, Grad norm: 9.495e+00\n",
      "Epoch 22164, Loss: 103.09344482421875, Neurons: 11, Grad norm: 1.416e+01\n",
      "Epoch 22165, Loss: 103.08686065673828, Neurons: 11, Grad norm: 1.375e+01\n",
      "Epoch 22166, Loss: 103.08028411865234, Neurons: 11, Grad norm: 1.929e+01\n",
      "Epoch 22167, Loss: 103.07373809814453, Neurons: 11, Grad norm: 2.027e+01\n",
      "Epoch 22168, Loss: 103.06719970703125, Neurons: 11, Grad norm: 2.719e+01\n",
      "Epoch 22169, Loss: 103.06070709228516, Neurons: 11, Grad norm: 2.959e+01\n",
      "Epoch 22170, Loss: 103.05426025390625, Neurons: 11, Grad norm: 3.799e+01\n",
      "Epoch 22171, Loss: 103.04786682128906, Neurons: 11, Grad norm: 4.155e+01\n",
      "Epoch 22172, Loss: 103.04154968261719, Neurons: 11, Grad norm: 5.026e+01\n",
      "Epoch 22173, Loss: 103.03527069091797, Neurons: 11, Grad norm: 5.254e+01\n",
      "Epoch 22174, Loss: 103.02900695800781, Neurons: 11, Grad norm: 5.721e+01\n",
      "Epoch 22175, Loss: 103.02263641357422, Neurons: 11, Grad norm: 5.230e+01\n",
      "Epoch 22176, Loss: 103.01607513427734, Neurons: 11, Grad norm: 4.731e+01\n",
      "Epoch 22177, Loss: 103.0093002319336, Neurons: 11, Grad norm: 3.168e+01\n",
      "Epoch 22178, Loss: 103.00242614746094, Neurons: 11, Grad norm: 1.779e+01\n",
      "Epoch 22179, Loss: 102.99565887451172, Neurons: 11, Grad norm: 2.944e+00\n",
      "Epoch 22180, Loss: 102.98915100097656, Neurons: 11, Grad norm: 1.502e+01\n",
      "Epoch 22181, Loss: 102.98290252685547, Neurons: 11, Grad norm: 2.924e+01\n",
      "Epoch 22182, Loss: 102.97677612304688, Neurons: 11, Grad norm: 3.268e+01\n",
      "Epoch 22183, Loss: 102.97058868408203, Neurons: 11, Grad norm: 3.529e+01\n",
      "Epoch 22184, Loss: 102.96422576904297, Neurons: 11, Grad norm: 2.745e+01\n",
      "Epoch 22185, Loss: 102.95772552490234, Neurons: 11, Grad norm: 2.025e+01\n",
      "Epoch 22186, Loss: 102.951171875, Neurons: 11, Grad norm: 5.578e+00\n",
      "Epoch 22187, Loss: 102.94469451904297, Neurons: 11, Grad norm: 4.590e+00\n",
      "Epoch 22188, Loss: 102.9383544921875, Neurons: 11, Grad norm: 1.681e+01\n",
      "Epoch 22189, Loss: 102.93211364746094, Neurons: 11, Grad norm: 2.079e+01\n",
      "Epoch 22190, Loss: 102.92591094970703, Neurons: 11, Grad norm: 2.527e+01\n",
      "Epoch 22191, Loss: 102.91959381103516, Neurons: 11, Grad norm: 2.010e+01\n",
      "Epoch 22192, Loss: 102.91322326660156, Neurons: 11, Grad norm: 1.693e+01\n",
      "Epoch 22193, Loss: 102.90679931640625, Neurons: 11, Grad norm: 6.539e+00\n",
      "Epoch 22194, Loss: 102.90038299560547, Neurons: 11, Grad norm: 2.019e+00\n",
      "Epoch 22195, Loss: 102.89403533935547, Neurons: 11, Grad norm: 1.025e+01\n",
      "Epoch 22196, Loss: 102.88775634765625, Neurons: 11, Grad norm: 1.274e+01\n",
      "Epoch 22197, Loss: 102.88147735595703, Neurons: 11, Grad norm: 1.766e+01\n",
      "Epoch 22198, Loss: 102.87518310546875, Neurons: 11, Grad norm: 1.450e+01\n",
      "Epoch 22199, Loss: 102.86885833740234, Neurons: 11, Grad norm: 1.369e+01\n",
      "Epoch 22199, Test loss: 98.86238098144531\n",
      "Epoch 22200, Loss: 102.86248016357422, Neurons: 11, Grad norm: 6.134e+00\n",
      "Epoch 22201, Loss: 102.85612487792969, Neurons: 11, Grad norm: 3.520e+00\n",
      "Epoch 22202, Loss: 102.84976959228516, Neurons: 11, Grad norm: 5.404e+00\n",
      "Epoch 22203, Loss: 102.84346008300781, Neurons: 11, Grad norm: 7.100e+00\n",
      "Epoch 22204, Loss: 102.837158203125, Neurons: 11, Grad norm: 1.199e+01\n",
      "Epoch 22205, Loss: 102.83085632324219, Neurons: 11, Grad norm: 9.776e+00\n",
      "Epoch 22206, Loss: 102.82452392578125, Neurons: 11, Grad norm: 1.100e+01\n",
      "Epoch 22207, Loss: 102.81820678710938, Neurons: 11, Grad norm: 5.869e+00\n",
      "Epoch 22208, Loss: 102.81184387207031, Neurons: 11, Grad norm: 4.851e+00\n",
      "Epoch 22209, Loss: 102.80548858642578, Neurons: 11, Grad norm: 2.957e+00\n",
      "Epoch 22210, Loss: 102.79915618896484, Neurons: 11, Grad norm: 3.474e+00\n",
      "Epoch 22211, Loss: 102.79283142089844, Neurons: 11, Grad norm: 8.240e+00\n",
      "Epoch 22212, Loss: 102.7864990234375, Neurons: 11, Grad norm: 7.171e+00\n",
      "Epoch 22213, Loss: 102.78018188476562, Neurons: 11, Grad norm: 9.608e+00\n",
      "Epoch 22214, Loss: 102.77384948730469, Neurons: 11, Grad norm: 5.965e+00\n",
      "Epoch 22215, Loss: 102.76750183105469, Neurons: 11, Grad norm: 6.720e+00\n",
      "Epoch 22216, Loss: 102.76114654541016, Neurons: 11, Grad norm: 2.432e+00\n",
      "Epoch 22217, Loss: 102.75479888916016, Neurons: 11, Grad norm: 2.427e+00\n",
      "Epoch 22218, Loss: 102.74845886230469, Neurons: 11, Grad norm: 3.781e+00\n",
      "Epoch 22219, Loss: 102.74211883544922, Neurons: 11, Grad norm: 2.949e+00\n",
      "Epoch 22220, Loss: 102.73577880859375, Neurons: 11, Grad norm: 6.116e+00\n",
      "Epoch 22221, Loss: 102.72945404052734, Neurons: 11, Grad norm: 3.884e+00\n",
      "Epoch 22222, Loss: 102.72309875488281, Neurons: 11, Grad norm: 5.869e+00\n",
      "Epoch 22223, Loss: 102.71675109863281, Neurons: 11, Grad norm: 2.954e+00\n",
      "Epoch 22224, Loss: 102.71039581298828, Neurons: 11, Grad norm: 3.975e+00\n",
      "Epoch 22225, Loss: 102.70404815673828, Neurons: 11, Grad norm: 2.187e+00\n",
      "Epoch 22226, Loss: 102.69768524169922, Neurons: 11, Grad norm: 2.064e+00\n",
      "Epoch 22227, Loss: 102.69133758544922, Neurons: 11, Grad norm: 4.139e+00\n",
      "Epoch 22228, Loss: 102.68498229980469, Neurons: 11, Grad norm: 2.942e+00\n",
      "Epoch 22229, Loss: 102.67861938476562, Neurons: 11, Grad norm: 5.578e+00\n",
      "Epoch 22230, Loss: 102.6722640991211, Neurons: 11, Grad norm: 3.285e+00\n",
      "Epoch 22231, Loss: 102.66590881347656, Neurons: 11, Grad norm: 5.297e+00\n",
      "Epoch 22232, Loss: 102.65953826904297, Neurons: 11, Grad norm: 2.608e+00\n",
      "Epoch 22233, Loss: 102.65318298339844, Neurons: 11, Grad norm: 3.916e+00\n",
      "Epoch 22234, Loss: 102.64681243896484, Neurons: 11, Grad norm: 2.041e+00\n",
      "Epoch 22235, Loss: 102.64044189453125, Neurons: 11, Grad norm: 2.602e+00\n",
      "Epoch 22236, Loss: 102.63407897949219, Neurons: 11, Grad norm: 2.870e+00\n",
      "Epoch 22237, Loss: 102.6277084350586, Neurons: 11, Grad norm: 2.044e+00\n",
      "Epoch 22238, Loss: 102.62134552001953, Neurons: 11, Grad norm: 3.663e+00\n",
      "Epoch 22239, Loss: 102.61495971679688, Neurons: 11, Grad norm: 2.228e+00\n",
      "Epoch 22240, Loss: 102.60858154296875, Neurons: 11, Grad norm: 4.108e+00\n",
      "Epoch 22241, Loss: 102.60221862792969, Neurons: 11, Grad norm: 2.185e+00\n",
      "Epoch 22242, Loss: 102.59583282470703, Neurons: 11, Grad norm: 3.686e+00\n",
      "Epoch 22243, Loss: 102.5894546508789, Neurons: 11, Grad norm: 2.053e+00\n",
      "Epoch 22244, Loss: 102.58306884765625, Neurons: 11, Grad norm: 2.952e+00\n",
      "Epoch 22245, Loss: 102.5766830444336, Neurons: 11, Grad norm: 2.196e+00\n",
      "Epoch 22246, Loss: 102.5703125, Neurons: 11, Grad norm: 2.571e+00\n",
      "Epoch 22247, Loss: 102.56393432617188, Neurons: 11, Grad norm: 2.480e+00\n",
      "Epoch 22248, Loss: 102.55753326416016, Neurons: 11, Grad norm: 2.223e+00\n",
      "Epoch 22249, Loss: 102.5511474609375, Neurons: 11, Grad norm: 2.937e+00\n",
      "Epoch 22249, Test loss: 98.54289245605469\n",
      "Epoch 22250, Loss: 102.54474639892578, Neurons: 11, Grad norm: 2.053e+00\n",
      "Epoch 22251, Loss: 102.53836059570312, Neurons: 11, Grad norm: 3.330e+00\n",
      "Epoch 22252, Loss: 102.53196716308594, Neurons: 11, Grad norm: 2.064e+00\n",
      "Epoch 22253, Loss: 102.52557373046875, Neurons: 11, Grad norm: 3.259e+00\n",
      "Epoch 22254, Loss: 102.51915740966797, Neurons: 11, Grad norm: 2.076e+00\n",
      "Epoch 22255, Loss: 102.51277160644531, Neurons: 11, Grad norm: 2.868e+00\n",
      "Epoch 22256, Loss: 102.5063705444336, Neurons: 11, Grad norm: 2.269e+00\n",
      "Epoch 22257, Loss: 102.49996948242188, Neurons: 11, Grad norm: 2.448e+00\n",
      "Epoch 22258, Loss: 102.4935531616211, Neurons: 11, Grad norm: 2.626e+00\n",
      "Epoch 22259, Loss: 102.4871597290039, Neurons: 11, Grad norm: 2.132e+00\n",
      "Epoch 22260, Loss: 102.48075103759766, Neurons: 11, Grad norm: 3.115e+00\n",
      "Epoch 22261, Loss: 102.47433471679688, Neurons: 11, Grad norm: 2.072e+00\n",
      "Epoch 22262, Loss: 102.46792602539062, Neurons: 11, Grad norm: 3.919e+00\n",
      "Epoch 22263, Loss: 102.46150970458984, Neurons: 11, Grad norm: 2.356e+00\n",
      "Epoch 22264, Loss: 102.4551010131836, Neurons: 11, Grad norm: 4.644e+00\n",
      "Epoch 22265, Loss: 102.44869995117188, Neurons: 11, Grad norm: 2.969e+00\n",
      "Epoch 22266, Loss: 102.4422607421875, Neurons: 11, Grad norm: 5.494e+00\n",
      "Epoch 22267, Loss: 102.43584442138672, Neurons: 11, Grad norm: 3.509e+00\n",
      "Epoch 22268, Loss: 102.42942810058594, Neurons: 11, Grad norm: 6.153e+00\n",
      "Epoch 22269, Loss: 102.4229965209961, Neurons: 11, Grad norm: 4.134e+00\n",
      "Epoch 22270, Loss: 102.41658020019531, Neurons: 11, Grad norm: 6.874e+00\n",
      "Epoch 22271, Loss: 102.41015625, Neurons: 11, Grad norm: 4.846e+00\n",
      "Epoch 22272, Loss: 102.40373992919922, Neurons: 11, Grad norm: 7.741e+00\n",
      "Epoch 22273, Loss: 102.39730834960938, Neurons: 11, Grad norm: 5.979e+00\n",
      "Epoch 22274, Loss: 102.39087677001953, Neurons: 11, Grad norm: 9.089e+00\n",
      "Epoch 22275, Loss: 102.38445281982422, Neurons: 11, Grad norm: 7.395e+00\n",
      "Epoch 22276, Loss: 102.3780288696289, Neurons: 11, Grad norm: 1.110e+01\n",
      "Epoch 22277, Loss: 102.37159729003906, Neurons: 11, Grad norm: 9.931e+00\n",
      "Epoch 22278, Loss: 102.36517333984375, Neurons: 11, Grad norm: 1.393e+01\n",
      "Epoch 22279, Loss: 102.35875701904297, Neurons: 11, Grad norm: 1.336e+01\n",
      "Epoch 22280, Loss: 102.35235595703125, Neurons: 11, Grad norm: 1.824e+01\n",
      "Epoch 22281, Loss: 102.34595489501953, Neurons: 11, Grad norm: 1.817e+01\n",
      "Epoch 22282, Loss: 102.33956909179688, Neurons: 11, Grad norm: 2.373e+01\n",
      "Epoch 22283, Loss: 102.33319091796875, Neurons: 11, Grad norm: 2.469e+01\n",
      "Epoch 22284, Loss: 102.32683563232422, Neurons: 11, Grad norm: 3.086e+01\n",
      "Epoch 22285, Loss: 102.32051849365234, Neurons: 11, Grad norm: 3.223e+01\n",
      "Epoch 22286, Loss: 102.314208984375, Neurons: 11, Grad norm: 3.885e+01\n",
      "Epoch 22287, Loss: 102.30793762207031, Neurons: 11, Grad norm: 3.995e+01\n",
      "Epoch 22288, Loss: 102.30167388916016, Neurons: 11, Grad norm: 4.496e+01\n",
      "Epoch 22289, Loss: 102.29542541503906, Neurons: 11, Grad norm: 4.340e+01\n",
      "Epoch 22290, Loss: 102.28910064697266, Neurons: 11, Grad norm: 4.473e+01\n",
      "Epoch 22291, Loss: 102.28270721435547, Neurons: 11, Grad norm: 3.797e+01\n",
      "Epoch 22292, Loss: 102.27623748779297, Neurons: 11, Grad norm: 3.343e+01\n",
      "Epoch 22293, Loss: 102.26972198486328, Neurons: 11, Grad norm: 2.162e+01\n",
      "Epoch 22294, Loss: 102.26319885253906, Neurons: 11, Grad norm: 1.352e+01\n",
      "Epoch 22295, Loss: 102.2567367553711, Neurons: 11, Grad norm: 2.077e+00\n",
      "Epoch 22296, Loss: 102.25038146972656, Neurons: 11, Grad norm: 7.654e+00\n",
      "Epoch 22297, Loss: 102.24412536621094, Neurons: 11, Grad norm: 1.806e+01\n",
      "Epoch 22298, Loss: 102.2379379272461, Neurons: 11, Grad norm: 2.107e+01\n",
      "Epoch 22299, Loss: 102.23173522949219, Neurons: 11, Grad norm: 2.634e+01\n",
      "Epoch 22299, Test loss: 98.22755432128906\n",
      "Epoch 22300, Loss: 102.22550964355469, Neurons: 11, Grad norm: 2.390e+01\n",
      "Epoch 22301, Loss: 102.21922302246094, Neurons: 11, Grad norm: 2.387e+01\n",
      "Epoch 22302, Loss: 102.21289825439453, Neurons: 11, Grad norm: 1.680e+01\n",
      "Epoch 22303, Loss: 102.20653533935547, Neurons: 11, Grad norm: 1.349e+01\n",
      "Epoch 22304, Loss: 102.20018768310547, Neurons: 11, Grad norm: 4.601e+00\n",
      "Epoch 22305, Loss: 102.1938705444336, Neurons: 11, Grad norm: 2.072e+00\n",
      "Epoch 22306, Loss: 102.18756866455078, Neurons: 11, Grad norm: 8.365e+00\n",
      "Epoch 22307, Loss: 102.18132019042969, Neurons: 11, Grad norm: 1.031e+01\n",
      "Epoch 22308, Loss: 102.17509460449219, Neurons: 11, Grad norm: 1.580e+01\n",
      "Epoch 22309, Loss: 102.16883850097656, Neurons: 11, Grad norm: 1.442e+01\n",
      "Epoch 22310, Loss: 102.16258239746094, Neurons: 11, Grad norm: 1.640e+01\n",
      "Epoch 22311, Loss: 102.15628814697266, Neurons: 11, Grad norm: 1.224e+01\n",
      "Epoch 22312, Loss: 102.14999389648438, Neurons: 11, Grad norm: 1.178e+01\n",
      "Epoch 22313, Loss: 102.1436767578125, Neurons: 11, Grad norm: 5.678e+00\n",
      "Epoch 22314, Loss: 102.13738250732422, Neurons: 11, Grad norm: 4.443e+00\n",
      "Epoch 22315, Loss: 102.13108825683594, Neurons: 11, Grad norm: 3.122e+00\n",
      "Epoch 22316, Loss: 102.12482452392578, Neurons: 11, Grad norm: 3.743e+00\n",
      "Epoch 22317, Loss: 102.11852264404297, Neurons: 11, Grad norm: 8.510e+00\n",
      "Epoch 22318, Loss: 102.11225891113281, Neurons: 11, Grad norm: 7.744e+00\n",
      "Epoch 22319, Loss: 102.10598754882812, Neurons: 11, Grad norm: 1.097e+01\n",
      "Epoch 22320, Loss: 102.09970092773438, Neurons: 11, Grad norm: 8.420e+00\n",
      "Epoch 22321, Loss: 102.0934066772461, Neurons: 11, Grad norm: 9.937e+00\n",
      "Epoch 22322, Loss: 102.08712005615234, Neurons: 11, Grad norm: 6.210e+00\n",
      "Epoch 22323, Loss: 102.08082580566406, Neurons: 11, Grad norm: 6.912e+00\n",
      "Epoch 22324, Loss: 102.07452392578125, Neurons: 11, Grad norm: 2.965e+00\n",
      "Epoch 22325, Loss: 102.06822204589844, Neurons: 11, Grad norm: 3.467e+00\n",
      "Epoch 22326, Loss: 102.06192016601562, Neurons: 11, Grad norm: 2.483e+00\n",
      "Epoch 22327, Loss: 102.05562591552734, Neurons: 11, Grad norm: 2.104e+00\n",
      "Epoch 22328, Loss: 102.04933166503906, Neurons: 11, Grad norm: 4.372e+00\n",
      "Epoch 22329, Loss: 102.04303741455078, Neurons: 11, Grad norm: 3.078e+00\n",
      "Epoch 22330, Loss: 102.03675079345703, Neurons: 11, Grad norm: 5.835e+00\n",
      "Epoch 22331, Loss: 102.03043365478516, Neurons: 11, Grad norm: 3.897e+00\n",
      "Epoch 22332, Loss: 102.02413177490234, Neurons: 11, Grad norm: 6.386e+00\n",
      "Epoch 22333, Loss: 102.01783752441406, Neurons: 11, Grad norm: 4.082e+00\n",
      "Epoch 22334, Loss: 102.01151275634766, Neurons: 11, Grad norm: 6.056e+00\n",
      "Epoch 22335, Loss: 102.00520324707031, Neurons: 11, Grad norm: 3.675e+00\n",
      "Epoch 22336, Loss: 101.99889373779297, Neurons: 11, Grad norm: 5.610e+00\n",
      "Epoch 22337, Loss: 101.99256896972656, Neurons: 11, Grad norm: 2.967e+00\n",
      "Epoch 22338, Loss: 101.98627471923828, Neurons: 11, Grad norm: 4.757e+00\n",
      "Epoch 22339, Loss: 101.97994995117188, Neurons: 11, Grad norm: 2.575e+00\n",
      "Epoch 22340, Loss: 101.9736328125, Neurons: 11, Grad norm: 3.989e+00\n",
      "Epoch 22341, Loss: 101.96731567382812, Neurons: 11, Grad norm: 2.153e+00\n",
      "Epoch 22342, Loss: 101.96099853515625, Neurons: 11, Grad norm: 3.470e+00\n",
      "Epoch 22343, Loss: 101.95466613769531, Neurons: 11, Grad norm: 2.112e+00\n",
      "Epoch 22344, Loss: 101.94834899902344, Neurons: 11, Grad norm: 2.931e+00\n",
      "Epoch 22345, Loss: 101.94200897216797, Neurons: 11, Grad norm: 2.169e+00\n",
      "Epoch 22346, Loss: 101.93568420410156, Neurons: 11, Grad norm: 2.729e+00\n",
      "Epoch 22347, Loss: 101.9293441772461, Neurons: 11, Grad norm: 2.415e+00\n",
      "Epoch 22348, Loss: 101.92303466796875, Neurons: 11, Grad norm: 2.432e+00\n",
      "Epoch 22349, Loss: 101.91667175292969, Neurons: 11, Grad norm: 2.464e+00\n",
      "Epoch 22349, Test loss: 97.9095687866211\n",
      "Epoch 22350, Loss: 101.91034698486328, Neurons: 11, Grad norm: 2.333e+00\n",
      "Epoch 22351, Loss: 101.90399932861328, Neurons: 11, Grad norm: 2.722e+00\n",
      "Epoch 22352, Loss: 101.89765930175781, Neurons: 11, Grad norm: 2.216e+00\n",
      "Epoch 22353, Loss: 101.89131927490234, Neurons: 11, Grad norm: 2.971e+00\n",
      "Epoch 22354, Loss: 101.88497161865234, Neurons: 11, Grad norm: 2.099e+00\n",
      "Epoch 22355, Loss: 101.87861633300781, Neurons: 11, Grad norm: 3.581e+00\n",
      "Epoch 22356, Loss: 101.87228393554688, Neurons: 11, Grad norm: 2.201e+00\n",
      "Epoch 22357, Loss: 101.86591339111328, Neurons: 11, Grad norm: 4.042e+00\n",
      "Epoch 22358, Loss: 101.85957336425781, Neurons: 11, Grad norm: 2.494e+00\n",
      "Epoch 22359, Loss: 101.85322570800781, Neurons: 11, Grad norm: 4.621e+00\n",
      "Epoch 22360, Loss: 101.84686279296875, Neurons: 11, Grad norm: 2.924e+00\n",
      "Epoch 22361, Loss: 101.84049987792969, Neurons: 11, Grad norm: 5.667e+00\n",
      "Epoch 22362, Loss: 101.83415985107422, Neurons: 11, Grad norm: 4.133e+00\n",
      "Epoch 22363, Loss: 101.82779693603516, Neurons: 11, Grad norm: 7.177e+00\n",
      "Epoch 22364, Loss: 101.8214340209961, Neurons: 11, Grad norm: 5.968e+00\n",
      "Epoch 22365, Loss: 101.81507873535156, Neurons: 11, Grad norm: 9.748e+00\n",
      "Epoch 22366, Loss: 101.80870819091797, Neurons: 11, Grad norm: 8.625e+00\n",
      "Epoch 22367, Loss: 101.80235290527344, Neurons: 11, Grad norm: 1.263e+01\n",
      "Epoch 22368, Loss: 101.79601287841797, Neurons: 11, Grad norm: 1.242e+01\n",
      "Epoch 22369, Loss: 101.7896499633789, Neurons: 11, Grad norm: 1.737e+01\n",
      "Epoch 22370, Loss: 101.78330993652344, Neurons: 11, Grad norm: 1.795e+01\n",
      "Epoch 22371, Loss: 101.77698516845703, Neurons: 11, Grad norm: 2.427e+01\n",
      "Epoch 22372, Loss: 101.77069091796875, Neurons: 11, Grad norm: 2.643e+01\n",
      "Epoch 22373, Loss: 101.76444244384766, Neurons: 11, Grad norm: 3.420e+01\n",
      "Epoch 22374, Loss: 101.75822448730469, Neurons: 11, Grad norm: 3.770e+01\n",
      "Epoch 22375, Loss: 101.75205993652344, Neurons: 11, Grad norm: 4.660e+01\n",
      "Epoch 22376, Loss: 101.7459716796875, Neurons: 11, Grad norm: 5.043e+01\n",
      "Epoch 22377, Loss: 101.73990631103516, Neurons: 11, Grad norm: 5.770e+01\n",
      "Epoch 22378, Loss: 101.73385620117188, Neurons: 11, Grad norm: 5.724e+01\n",
      "Epoch 22379, Loss: 101.72769927978516, Neurons: 11, Grad norm: 5.762e+01\n",
      "Epoch 22380, Loss: 101.72136688232422, Neurons: 11, Grad norm: 4.747e+01\n",
      "Epoch 22381, Loss: 101.71478271484375, Neurons: 11, Grad norm: 3.663e+01\n",
      "Epoch 22382, Loss: 101.7081069946289, Neurons: 11, Grad norm: 1.759e+01\n",
      "Epoch 22383, Loss: 101.7015380859375, Neurons: 11, Grad norm: 3.049e+00\n",
      "Epoch 22384, Loss: 101.6952133178711, Neurons: 11, Grad norm: 1.673e+01\n",
      "Epoch 22385, Loss: 101.68912506103516, Neurons: 11, Grad norm: 2.654e+01\n",
      "Epoch 22386, Loss: 101.68318176269531, Neurons: 11, Grad norm: 3.584e+01\n",
      "Epoch 22387, Loss: 101.67720794677734, Neurons: 11, Grad norm: 3.448e+01\n",
      "Epoch 22388, Loss: 101.67106628417969, Neurons: 11, Grad norm: 3.212e+01\n",
      "Epoch 22389, Loss: 101.66477966308594, Neurons: 11, Grad norm: 2.010e+01\n",
      "Epoch 22390, Loss: 101.65840911865234, Neurons: 11, Grad norm: 1.049e+01\n",
      "Epoch 22391, Loss: 101.65210723876953, Neurons: 11, Grad norm: 4.984e+00\n",
      "Epoch 22392, Loss: 101.64593505859375, Neurons: 11, Grad norm: 1.284e+01\n",
      "Epoch 22393, Loss: 101.63984680175781, Neurons: 11, Grad norm: 2.250e+01\n",
      "Epoch 22394, Loss: 101.63381958007812, Neurons: 11, Grad norm: 2.296e+01\n",
      "Epoch 22395, Loss: 101.62774658203125, Neurons: 11, Grad norm: 2.372e+01\n",
      "Epoch 22396, Loss: 101.6215591430664, Neurons: 11, Grad norm: 1.606e+01\n",
      "Epoch 22397, Loss: 101.6153335571289, Neurons: 11, Grad norm: 1.067e+01\n",
      "Epoch 22398, Loss: 101.60910034179688, Neurons: 11, Grad norm: 2.287e+00\n",
      "Epoch 22399, Loss: 101.60292053222656, Neurons: 11, Grad norm: 6.640e+00\n",
      "Epoch 22399, Test loss: 97.59400177001953\n",
      "Epoch 22400, Loss: 101.59679412841797, Neurons: 11, Grad norm: 1.461e+01\n",
      "Epoch 22401, Loss: 101.59071350097656, Neurons: 11, Grad norm: 1.529e+01\n",
      "Epoch 22402, Loss: 101.58460235595703, Neurons: 11, Grad norm: 1.783e+01\n",
      "Epoch 22403, Loss: 101.5784683227539, Neurons: 11, Grad norm: 1.273e+01\n",
      "Epoch 22404, Loss: 101.5722885131836, Neurons: 11, Grad norm: 1.056e+01\n",
      "Epoch 22405, Loss: 101.56610107421875, Neurons: 11, Grad norm: 3.213e+00\n",
      "Epoch 22406, Loss: 101.5599136352539, Neurons: 11, Grad norm: 2.347e+00\n",
      "Epoch 22407, Loss: 101.55376434326172, Neurons: 11, Grad norm: 8.760e+00\n",
      "Epoch 22408, Loss: 101.54763793945312, Neurons: 11, Grad norm: 9.667e+00\n",
      "Epoch 22409, Loss: 101.54151916503906, Neurons: 11, Grad norm: 1.351e+01\n",
      "Epoch 22410, Loss: 101.53536987304688, Neurons: 11, Grad norm: 1.083e+01\n",
      "Epoch 22411, Loss: 101.52921295166016, Neurons: 11, Grad norm: 1.093e+01\n",
      "Epoch 22412, Loss: 101.5230484008789, Neurons: 11, Grad norm: 5.349e+00\n",
      "Epoch 22413, Loss: 101.51686096191406, Neurons: 11, Grad norm: 4.233e+00\n",
      "Epoch 22414, Loss: 101.51068115234375, Neurons: 11, Grad norm: 3.344e+00\n",
      "Epoch 22415, Loss: 101.50452423095703, Neurons: 11, Grad norm: 4.090e+00\n",
      "Epoch 22416, Loss: 101.49837493896484, Neurons: 11, Grad norm: 8.328e+00\n",
      "Epoch 22417, Loss: 101.4922103881836, Neurons: 11, Grad norm: 6.991e+00\n",
      "Epoch 22418, Loss: 101.48604583740234, Neurons: 11, Grad norm: 9.322e+00\n",
      "Epoch 22419, Loss: 101.47989654541016, Neurons: 11, Grad norm: 5.958e+00\n",
      "Epoch 22420, Loss: 101.47372436523438, Neurons: 11, Grad norm: 6.426e+00\n",
      "Epoch 22421, Loss: 101.46753692626953, Neurons: 11, Grad norm: 2.515e+00\n",
      "Epoch 22422, Loss: 101.46135711669922, Neurons: 11, Grad norm: 2.498e+00\n",
      "Epoch 22423, Loss: 101.45516204833984, Neurons: 11, Grad norm: 4.176e+00\n",
      "Epoch 22424, Loss: 101.4489974975586, Neurons: 11, Grad norm: 3.880e+00\n",
      "Epoch 22425, Loss: 101.44282531738281, Neurons: 11, Grad norm: 7.132e+00\n",
      "Epoch 22426, Loss: 101.43663787841797, Neurons: 11, Grad norm: 5.478e+00\n",
      "Epoch 22427, Loss: 101.43047332763672, Neurons: 11, Grad norm: 7.665e+00\n",
      "Epoch 22428, Loss: 101.42427062988281, Neurons: 11, Grad norm: 4.408e+00\n",
      "Epoch 22429, Loss: 101.41808319091797, Neurons: 11, Grad norm: 5.295e+00\n",
      "Epoch 22430, Loss: 101.41191101074219, Neurons: 11, Grad norm: 2.395e+00\n",
      "Epoch 22431, Loss: 101.40570831298828, Neurons: 11, Grad norm: 2.769e+00\n",
      "Epoch 22432, Loss: 101.3995132446289, Neurons: 11, Grad norm: 3.221e+00\n",
      "Epoch 22433, Loss: 101.393310546875, Neurons: 11, Grad norm: 2.405e+00\n",
      "Epoch 22434, Loss: 101.38712310791016, Neurons: 11, Grad norm: 4.887e+00\n",
      "Epoch 22435, Loss: 101.38092041015625, Neurons: 11, Grad norm: 3.477e+00\n",
      "Epoch 22436, Loss: 101.3747329711914, Neurons: 11, Grad norm: 5.638e+00\n",
      "Epoch 22437, Loss: 101.36852264404297, Neurons: 11, Grad norm: 3.372e+00\n",
      "Epoch 22438, Loss: 101.36231994628906, Neurons: 11, Grad norm: 5.119e+00\n",
      "Epoch 22439, Loss: 101.35610961914062, Neurons: 11, Grad norm: 2.726e+00\n",
      "Epoch 22440, Loss: 101.34989929199219, Neurons: 11, Grad norm: 3.857e+00\n",
      "Epoch 22441, Loss: 101.34368133544922, Neurons: 11, Grad norm: 2.162e+00\n",
      "Epoch 22442, Loss: 101.33746337890625, Neurons: 11, Grad norm: 2.778e+00\n",
      "Epoch 22443, Loss: 101.33124542236328, Neurons: 11, Grad norm: 2.598e+00\n",
      "Epoch 22444, Loss: 101.32503509521484, Neurons: 11, Grad norm: 2.165e+00\n",
      "Epoch 22445, Loss: 101.31880950927734, Neurons: 11, Grad norm: 3.363e+00\n",
      "Epoch 22446, Loss: 101.31258392333984, Neurons: 11, Grad norm: 2.232e+00\n",
      "Epoch 22447, Loss: 101.30636596679688, Neurons: 11, Grad norm: 3.816e+00\n",
      "Epoch 22448, Loss: 101.30014038085938, Neurons: 11, Grad norm: 2.265e+00\n",
      "Epoch 22449, Loss: 101.29390716552734, Neurons: 11, Grad norm: 3.625e+00\n",
      "Epoch 22449, Test loss: 97.28816223144531\n",
      "Epoch 22450, Loss: 101.28767395019531, Neurons: 11, Grad norm: 2.182e+00\n",
      "Epoch 22451, Loss: 101.28143310546875, Neurons: 11, Grad norm: 3.207e+00\n",
      "Epoch 22452, Loss: 101.27518463134766, Neurons: 11, Grad norm: 2.176e+00\n",
      "Epoch 22453, Loss: 101.26895904541016, Neurons: 11, Grad norm: 2.963e+00\n",
      "Epoch 22454, Loss: 101.26272583007812, Neurons: 11, Grad norm: 2.237e+00\n",
      "Epoch 22455, Loss: 101.25648498535156, Neurons: 11, Grad norm: 2.754e+00\n",
      "Epoch 22456, Loss: 101.25023651123047, Neurons: 11, Grad norm: 2.247e+00\n",
      "Epoch 22457, Loss: 101.24398803710938, Neurons: 11, Grad norm: 2.749e+00\n",
      "Epoch 22458, Loss: 101.23773193359375, Neurons: 11, Grad norm: 2.344e+00\n",
      "Epoch 22459, Loss: 101.23147583007812, Neurons: 11, Grad norm: 2.529e+00\n",
      "Epoch 22460, Loss: 101.22522735595703, Neurons: 11, Grad norm: 2.490e+00\n",
      "Epoch 22461, Loss: 101.21896362304688, Neurons: 11, Grad norm: 2.360e+00\n",
      "Epoch 22462, Loss: 101.21270751953125, Neurons: 11, Grad norm: 2.746e+00\n",
      "Epoch 22463, Loss: 101.2064437866211, Neurons: 11, Grad norm: 2.266e+00\n",
      "Epoch 22464, Loss: 101.20018768310547, Neurons: 11, Grad norm: 2.789e+00\n",
      "Epoch 22465, Loss: 101.19392395019531, Neurons: 11, Grad norm: 2.235e+00\n",
      "Epoch 22466, Loss: 101.18765258789062, Neurons: 11, Grad norm: 2.769e+00\n",
      "Epoch 22467, Loss: 101.18138122558594, Neurons: 11, Grad norm: 2.309e+00\n",
      "Epoch 22468, Loss: 101.17511749267578, Neurons: 11, Grad norm: 2.624e+00\n",
      "Epoch 22469, Loss: 101.16883087158203, Neurons: 11, Grad norm: 2.428e+00\n",
      "Epoch 22470, Loss: 101.16254425048828, Neurons: 11, Grad norm: 2.416e+00\n",
      "Epoch 22471, Loss: 101.1562728881836, Neurons: 11, Grad norm: 2.625e+00\n",
      "Epoch 22472, Loss: 101.14999389648438, Neurons: 11, Grad norm: 2.299e+00\n",
      "Epoch 22473, Loss: 101.14370727539062, Neurons: 11, Grad norm: 2.746e+00\n",
      "Epoch 22474, Loss: 101.13743591308594, Neurons: 11, Grad norm: 2.219e+00\n",
      "Epoch 22475, Loss: 101.13113403320312, Neurons: 11, Grad norm: 3.118e+00\n",
      "Epoch 22476, Loss: 101.12483215332031, Neurons: 11, Grad norm: 2.175e+00\n",
      "Epoch 22477, Loss: 101.11854553222656, Neurons: 11, Grad norm: 3.424e+00\n",
      "Epoch 22478, Loss: 101.11224365234375, Neurons: 11, Grad norm: 2.280e+00\n",
      "Epoch 22479, Loss: 101.10594940185547, Neurons: 11, Grad norm: 3.975e+00\n",
      "Epoch 22480, Loss: 101.09965515136719, Neurons: 11, Grad norm: 2.601e+00\n",
      "Epoch 22481, Loss: 101.0933609008789, Neurons: 11, Grad norm: 4.819e+00\n",
      "Epoch 22482, Loss: 101.0870361328125, Neurons: 11, Grad norm: 3.212e+00\n",
      "Epoch 22483, Loss: 101.08073425292969, Neurons: 11, Grad norm: 5.826e+00\n",
      "Epoch 22484, Loss: 101.07443237304688, Neurons: 11, Grad norm: 4.557e+00\n",
      "Epoch 22485, Loss: 101.068115234375, Neurons: 11, Grad norm: 7.743e+00\n",
      "Epoch 22486, Loss: 101.06181335449219, Neurons: 11, Grad norm: 6.779e+00\n",
      "Epoch 22487, Loss: 101.05551147460938, Neurons: 11, Grad norm: 1.061e+01\n",
      "Epoch 22488, Loss: 101.0491943359375, Neurons: 11, Grad norm: 1.018e+01\n",
      "Epoch 22489, Loss: 101.04290008544922, Neurons: 11, Grad norm: 1.496e+01\n",
      "Epoch 22490, Loss: 101.03659057617188, Neurons: 11, Grad norm: 1.556e+01\n",
      "Epoch 22491, Loss: 101.03031921386719, Neurons: 11, Grad norm: 2.145e+01\n",
      "Epoch 22492, Loss: 101.0240478515625, Neurons: 11, Grad norm: 2.364e+01\n",
      "Epoch 22493, Loss: 101.017822265625, Neurons: 11, Grad norm: 3.141e+01\n",
      "Epoch 22494, Loss: 101.0116195678711, Neurons: 11, Grad norm: 3.547e+01\n",
      "Epoch 22495, Loss: 101.00550079345703, Neurons: 11, Grad norm: 4.514e+01\n",
      "Epoch 22496, Loss: 100.99945831298828, Neurons: 11, Grad norm: 5.069e+01\n",
      "Epoch 22497, Loss: 100.99349212646484, Neurons: 11, Grad norm: 6.057e+01\n",
      "Epoch 22498, Loss: 100.9875717163086, Neurons: 11, Grad norm: 6.372e+01\n",
      "Epoch 22499, Loss: 100.98162841796875, Neurons: 11, Grad norm: 6.727e+01\n",
      "Epoch 22499, Test loss: 96.98731231689453\n",
      "Epoch 22500, Loss: 100.97549438476562, Neurons: 11, Grad norm: 6.005e+01\n",
      "Epoch 22501, Loss: 100.96906280517578, Neurons: 11, Grad norm: 5.021e+01\n",
      "Epoch 22502, Loss: 100.96235656738281, Neurons: 11, Grad norm: 2.934e+01\n",
      "Epoch 22503, Loss: 100.95561218261719, Neurons: 11, Grad norm: 1.039e+01\n",
      "Epoch 22504, Loss: 100.9491195678711, Neurons: 11, Grad norm: 1.311e+01\n",
      "Epoch 22505, Loss: 100.94303894042969, Neurons: 11, Grad norm: 2.768e+01\n",
      "Epoch 22506, Loss: 100.93721008300781, Neurons: 11, Grad norm: 4.038e+01\n",
      "Epoch 22507, Loss: 100.93140411376953, Neurons: 11, Grad norm: 4.048e+01\n",
      "Epoch 22508, Loss: 100.92536926269531, Neurons: 11, Grad norm: 3.753e+01\n",
      "Epoch 22509, Loss: 100.91910552978516, Neurons: 11, Grad norm: 2.358e+01\n",
      "Epoch 22510, Loss: 100.9127197265625, Neurons: 11, Grad norm: 1.061e+01\n",
      "Epoch 22511, Loss: 100.90642547607422, Neurons: 11, Grad norm: 7.844e+00\n",
      "Epoch 22512, Loss: 100.90032196044922, Neurons: 11, Grad norm: 1.818e+01\n",
      "Epoch 22513, Loss: 100.89437103271484, Neurons: 11, Grad norm: 2.810e+01\n",
      "Epoch 22514, Loss: 100.88842010498047, Neurons: 11, Grad norm: 2.737e+01\n",
      "Epoch 22515, Loss: 100.88238525390625, Neurons: 11, Grad norm: 2.524e+01\n",
      "Epoch 22516, Loss: 100.8761978149414, Neurons: 11, Grad norm: 1.388e+01\n",
      "Epoch 22517, Loss: 100.86995697021484, Neurons: 11, Grad norm: 5.263e+00\n",
      "Epoch 22518, Loss: 100.86380767822266, Neurons: 11, Grad norm: 8.786e+00\n",
      "Epoch 22519, Loss: 100.85774230957031, Neurons: 11, Grad norm: 1.498e+01\n",
      "Epoch 22520, Loss: 100.85173797607422, Neurons: 11, Grad norm: 2.167e+01\n",
      "Epoch 22521, Loss: 100.84573364257812, Neurons: 11, Grad norm: 1.923e+01\n",
      "Epoch 22522, Loss: 100.83963775634766, Neurons: 11, Grad norm: 1.739e+01\n",
      "Epoch 22523, Loss: 100.83349609375, Neurons: 11, Grad norm: 8.173e+00\n",
      "Epoch 22524, Loss: 100.82733154296875, Neurons: 11, Grad norm: 2.920e+00\n",
      "Epoch 22525, Loss: 100.82121276855469, Neurons: 11, Grad norm: 8.151e+00\n",
      "Epoch 22526, Loss: 100.81514739990234, Neurons: 11, Grad norm: 1.128e+01\n",
      "Epoch 22527, Loss: 100.80911254882812, Neurons: 11, Grad norm: 1.610e+01\n",
      "Epoch 22528, Loss: 100.80304718017578, Neurons: 11, Grad norm: 1.330e+01\n",
      "Epoch 22529, Loss: 100.79694366455078, Neurons: 11, Grad norm: 1.238e+01\n",
      "Epoch 22530, Loss: 100.79080963134766, Neurons: 11, Grad norm: 5.347e+00\n",
      "Epoch 22531, Loss: 100.78468322753906, Neurons: 11, Grad norm: 2.709e+00\n",
      "Epoch 22532, Loss: 100.77857208251953, Neurons: 11, Grad norm: 6.328e+00\n",
      "Epoch 22533, Loss: 100.7724838256836, Neurons: 11, Grad norm: 7.936e+00\n",
      "Epoch 22534, Loss: 100.76639556884766, Neurons: 11, Grad norm: 1.203e+01\n",
      "Epoch 22535, Loss: 100.76032257080078, Neurons: 11, Grad norm: 9.645e+00\n",
      "Epoch 22536, Loss: 100.75421905517578, Neurons: 11, Grad norm: 1.001e+01\n",
      "Epoch 22537, Loss: 100.74808502197266, Neurons: 11, Grad norm: 4.766e+00\n",
      "Epoch 22538, Loss: 100.74195098876953, Neurons: 11, Grad norm: 3.441e+00\n",
      "Epoch 22539, Loss: 100.73583984375, Neurons: 11, Grad norm: 4.025e+00\n",
      "Epoch 22540, Loss: 100.72972106933594, Neurons: 11, Grad norm: 4.603e+00\n",
      "Epoch 22541, Loss: 100.72361755371094, Neurons: 11, Grad norm: 8.465e+00\n",
      "Epoch 22542, Loss: 100.7175064086914, Neurons: 11, Grad norm: 6.835e+00\n",
      "Epoch 22543, Loss: 100.71138763427734, Neurons: 11, Grad norm: 8.377e+00\n",
      "Epoch 22544, Loss: 100.70526885986328, Neurons: 11, Grad norm: 4.824e+00\n",
      "Epoch 22545, Loss: 100.6991195678711, Neurons: 11, Grad norm: 4.991e+00\n",
      "Epoch 22546, Loss: 100.69298553466797, Neurons: 11, Grad norm: 2.270e+00\n",
      "Epoch 22547, Loss: 100.68687438964844, Neurons: 11, Grad norm: 2.354e+00\n",
      "Epoch 22548, Loss: 100.68072509765625, Neurons: 11, Grad norm: 5.566e+00\n",
      "Epoch 22549, Loss: 100.67459869384766, Neurons: 11, Grad norm: 4.839e+00\n",
      "Epoch 22549, Test loss: 96.67155456542969\n",
      "Epoch 22550, Loss: 100.66845703125, Neurons: 11, Grad norm: 7.569e+00\n",
      "Epoch 22551, Loss: 100.6623306274414, Neurons: 11, Grad norm: 5.067e+00\n",
      "Epoch 22552, Loss: 100.65618133544922, Neurons: 11, Grad norm: 6.195e+00\n",
      "Epoch 22553, Loss: 100.6500244140625, Neurons: 11, Grad norm: 2.960e+00\n",
      "Epoch 22554, Loss: 100.64387512207031, Neurons: 11, Grad norm: 3.302e+00\n",
      "Epoch 22555, Loss: 100.63772583007812, Neurons: 11, Grad norm: 2.648e+00\n",
      "Epoch 22556, Loss: 100.63158416748047, Neurons: 11, Grad norm: 2.284e+00\n",
      "Epoch 22557, Loss: 100.62541961669922, Neurons: 11, Grad norm: 4.423e+00\n",
      "Epoch 22558, Loss: 100.6192626953125, Neurons: 11, Grad norm: 3.093e+00\n",
      "Epoch 22559, Loss: 100.61310577392578, Neurons: 11, Grad norm: 5.030e+00\n",
      "Epoch 22560, Loss: 100.60693359375, Neurons: 11, Grad norm: 2.806e+00\n",
      "Epoch 22561, Loss: 100.60076904296875, Neurons: 11, Grad norm: 3.899e+00\n",
      "Epoch 22562, Loss: 100.5946044921875, Neurons: 11, Grad norm: 2.215e+00\n",
      "Epoch 22563, Loss: 100.58843231201172, Neurons: 11, Grad norm: 2.598e+00\n",
      "Epoch 22564, Loss: 100.58226013183594, Neurons: 11, Grad norm: 2.970e+00\n",
      "Epoch 22565, Loss: 100.57608795166016, Neurons: 11, Grad norm: 2.264e+00\n",
      "Epoch 22566, Loss: 100.56990814208984, Neurons: 11, Grad norm: 3.889e+00\n",
      "Epoch 22567, Loss: 100.563720703125, Neurons: 11, Grad norm: 2.550e+00\n",
      "Epoch 22568, Loss: 100.55754852294922, Neurons: 11, Grad norm: 4.011e+00\n",
      "Epoch 22569, Loss: 100.55134582519531, Neurons: 11, Grad norm: 2.378e+00\n",
      "Epoch 22570, Loss: 100.54515838623047, Neurons: 11, Grad norm: 3.647e+00\n",
      "Epoch 22571, Loss: 100.53897094726562, Neurons: 11, Grad norm: 2.246e+00\n",
      "Epoch 22572, Loss: 100.53278350830078, Neurons: 11, Grad norm: 3.156e+00\n",
      "Epoch 22573, Loss: 100.52657318115234, Neurons: 11, Grad norm: 2.246e+00\n",
      "Epoch 22574, Loss: 100.52037048339844, Neurons: 11, Grad norm: 2.930e+00\n",
      "Epoch 22575, Loss: 100.51417541503906, Neurons: 11, Grad norm: 2.317e+00\n",
      "Epoch 22576, Loss: 100.50796508789062, Neurons: 11, Grad norm: 2.526e+00\n",
      "Epoch 22577, Loss: 100.50176239013672, Neurons: 11, Grad norm: 2.557e+00\n",
      "Epoch 22578, Loss: 100.49555206298828, Neurons: 11, Grad norm: 2.353e+00\n",
      "Epoch 22579, Loss: 100.48933410644531, Neurons: 11, Grad norm: 2.863e+00\n",
      "Epoch 22580, Loss: 100.48310852050781, Neurons: 11, Grad norm: 2.263e+00\n",
      "Epoch 22581, Loss: 100.4769058227539, Neurons: 11, Grad norm: 2.934e+00\n",
      "Epoch 22582, Loss: 100.47068786621094, Neurons: 11, Grad norm: 2.225e+00\n",
      "Epoch 22583, Loss: 100.46446228027344, Neurons: 11, Grad norm: 3.123e+00\n",
      "Epoch 22584, Loss: 100.45820617675781, Neurons: 11, Grad norm: 2.231e+00\n",
      "Epoch 22585, Loss: 100.45199584960938, Neurons: 11, Grad norm: 3.182e+00\n",
      "Epoch 22586, Loss: 100.44576263427734, Neurons: 11, Grad norm: 2.229e+00\n",
      "Epoch 22587, Loss: 100.43950653076172, Neurons: 11, Grad norm: 3.268e+00\n",
      "Epoch 22588, Loss: 100.43328857421875, Neurons: 11, Grad norm: 2.237e+00\n",
      "Epoch 22589, Loss: 100.42704772949219, Neurons: 11, Grad norm: 3.203e+00\n",
      "Epoch 22590, Loss: 100.42080688476562, Neurons: 11, Grad norm: 2.228e+00\n",
      "Epoch 22591, Loss: 100.41455078125, Neurons: 11, Grad norm: 2.923e+00\n",
      "Epoch 22592, Loss: 100.40830993652344, Neurons: 11, Grad norm: 2.310e+00\n",
      "Epoch 22593, Loss: 100.40203857421875, Neurons: 11, Grad norm: 2.669e+00\n",
      "Epoch 22594, Loss: 100.39579772949219, Neurons: 11, Grad norm: 2.456e+00\n",
      "Epoch 22595, Loss: 100.38954162597656, Neurons: 11, Grad norm: 2.487e+00\n",
      "Epoch 22596, Loss: 100.38327026367188, Neurons: 11, Grad norm: 2.539e+00\n",
      "Epoch 22597, Loss: 100.37702178955078, Neurons: 11, Grad norm: 2.344e+00\n",
      "Epoch 22598, Loss: 100.37074279785156, Neurons: 11, Grad norm: 2.825e+00\n",
      "Epoch 22599, Loss: 100.36447143554688, Neurons: 11, Grad norm: 2.256e+00\n",
      "Epoch 22599, Test loss: 96.3662109375\n",
      "Epoch 22600, Loss: 100.35820007324219, Neurons: 11, Grad norm: 3.192e+00\n",
      "Epoch 22601, Loss: 100.35193634033203, Neurons: 11, Grad norm: 2.246e+00\n",
      "Epoch 22602, Loss: 100.34565734863281, Neurons: 11, Grad norm: 3.390e+00\n",
      "Epoch 22603, Loss: 100.33937072753906, Neurons: 11, Grad norm: 2.301e+00\n",
      "Epoch 22604, Loss: 100.33308410644531, Neurons: 11, Grad norm: 3.710e+00\n",
      "Epoch 22605, Loss: 100.32681274414062, Neurons: 11, Grad norm: 2.459e+00\n",
      "Epoch 22606, Loss: 100.32051849365234, Neurons: 11, Grad norm: 4.115e+00\n",
      "Epoch 22607, Loss: 100.3142318725586, Neurons: 11, Grad norm: 2.711e+00\n",
      "Epoch 22608, Loss: 100.30794525146484, Neurons: 11, Grad norm: 4.594e+00\n",
      "Epoch 22609, Loss: 100.30164337158203, Neurons: 11, Grad norm: 2.924e+00\n",
      "Epoch 22610, Loss: 100.29534149169922, Neurons: 11, Grad norm: 4.863e+00\n",
      "Epoch 22611, Loss: 100.28903198242188, Neurons: 11, Grad norm: 3.372e+00\n",
      "Epoch 22612, Loss: 100.2827377319336, Neurons: 11, Grad norm: 5.563e+00\n",
      "Epoch 22613, Loss: 100.27642059326172, Neurons: 11, Grad norm: 4.024e+00\n",
      "Epoch 22614, Loss: 100.27010345458984, Neurons: 11, Grad norm: 6.591e+00\n",
      "Epoch 22615, Loss: 100.26380157470703, Neurons: 11, Grad norm: 5.073e+00\n",
      "Epoch 22616, Loss: 100.25747680664062, Neurons: 11, Grad norm: 7.723e+00\n",
      "Epoch 22617, Loss: 100.25115966796875, Neurons: 11, Grad norm: 6.400e+00\n",
      "Epoch 22618, Loss: 100.2448501586914, Neurons: 11, Grad norm: 9.375e+00\n",
      "Epoch 22619, Loss: 100.238525390625, Neurons: 11, Grad norm: 8.208e+00\n",
      "Epoch 22620, Loss: 100.23220825195312, Neurons: 11, Grad norm: 1.156e+01\n",
      "Epoch 22621, Loss: 100.22589111328125, Neurons: 11, Grad norm: 1.109e+01\n",
      "Epoch 22622, Loss: 100.2195816040039, Neurons: 11, Grad norm: 1.530e+01\n",
      "Epoch 22623, Loss: 100.21326446533203, Neurons: 11, Grad norm: 1.540e+01\n",
      "Epoch 22624, Loss: 100.20696258544922, Neurons: 11, Grad norm: 2.045e+01\n",
      "Epoch 22625, Loss: 100.20067596435547, Neurons: 11, Grad norm: 2.186e+01\n",
      "Epoch 22626, Loss: 100.19439697265625, Neurons: 11, Grad norm: 2.829e+01\n",
      "Epoch 22627, Loss: 100.18814849853516, Neurons: 11, Grad norm: 3.104e+01\n",
      "Epoch 22628, Loss: 100.18193817138672, Neurons: 11, Grad norm: 3.885e+01\n",
      "Epoch 22629, Loss: 100.17578125, Neurons: 11, Grad norm: 4.294e+01\n",
      "Epoch 22630, Loss: 100.16966247558594, Neurons: 11, Grad norm: 5.165e+01\n",
      "Epoch 22631, Loss: 100.16360473632812, Neurons: 11, Grad norm: 5.522e+01\n",
      "Epoch 22632, Loss: 100.1575698852539, Neurons: 11, Grad norm: 6.126e+01\n",
      "Epoch 22633, Loss: 100.15149688720703, Neurons: 11, Grad norm: 5.950e+01\n",
      "Epoch 22634, Loss: 100.14527130126953, Neurons: 11, Grad norm: 5.715e+01\n",
      "Epoch 22635, Loss: 100.13883209228516, Neurons: 11, Grad norm: 4.492e+01\n",
      "Epoch 22636, Loss: 100.13223266601562, Neurons: 11, Grad norm: 3.237e+01\n",
      "Epoch 22637, Loss: 100.1255874633789, Neurons: 11, Grad norm: 1.262e+01\n",
      "Epoch 22638, Loss: 100.11908721923828, Neurons: 11, Grad norm: 3.924e+00\n",
      "Epoch 22639, Loss: 100.11283874511719, Neurons: 11, Grad norm: 2.088e+01\n",
      "Epoch 22640, Loss: 100.10680389404297, Neurons: 11, Grad norm: 2.985e+01\n",
      "Epoch 22641, Loss: 100.10086059570312, Neurons: 11, Grad norm: 3.777e+01\n",
      "Epoch 22642, Loss: 100.09483337402344, Neurons: 11, Grad norm: 3.532e+01\n",
      "Epoch 22643, Loss: 100.08866119384766, Neurons: 11, Grad norm: 3.173e+01\n",
      "Epoch 22644, Loss: 100.08233642578125, Neurons: 11, Grad norm: 1.954e+01\n",
      "Epoch 22645, Loss: 100.07596588134766, Neurons: 11, Grad norm: 9.299e+00\n",
      "Epoch 22646, Loss: 100.06965637207031, Neurons: 11, Grad norm: 6.088e+00\n",
      "Epoch 22647, Loss: 100.0634765625, Neurons: 11, Grad norm: 1.417e+01\n",
      "Epoch 22648, Loss: 100.0573959350586, Neurons: 11, Grad norm: 2.326e+01\n",
      "Epoch 22649, Loss: 100.05133819580078, Neurons: 11, Grad norm: 2.387e+01\n",
      "Epoch 22649, Test loss: 96.05353546142578\n",
      "Epoch 22650, Loss: 100.04521942138672, Neurons: 11, Grad norm: 2.460e+01\n",
      "Epoch 22651, Loss: 100.03901672363281, Neurons: 11, Grad norm: 1.735e+01\n",
      "Epoch 22652, Loss: 100.03277587890625, Neurons: 11, Grad norm: 1.184e+01\n",
      "Epoch 22653, Loss: 100.02651977539062, Neurons: 11, Grad norm: 2.400e+00\n",
      "Epoch 22654, Loss: 100.02030181884766, Neurons: 11, Grad norm: 5.620e+00\n",
      "Epoch 22655, Loss: 100.01414489746094, Neurons: 11, Grad norm: 1.386e+01\n",
      "Epoch 22656, Loss: 100.00802612304688, Neurons: 11, Grad norm: 1.550e+01\n",
      "Epoch 22657, Loss: 100.00188446044922, Neurons: 11, Grad norm: 1.858e+01\n",
      "Epoch 22658, Loss: 99.99571990966797, Neurons: 11, Grad norm: 1.461e+01\n",
      "Epoch 22659, Loss: 99.9895248413086, Neurons: 11, Grad norm: 1.275e+01\n",
      "Epoch 22660, Loss: 99.98330688476562, Neurons: 11, Grad norm: 5.686e+00\n",
      "Epoch 22661, Loss: 99.97708129882812, Neurons: 11, Grad norm: 2.895e+00\n",
      "Epoch 22662, Loss: 99.97088623046875, Neurons: 11, Grad norm: 5.873e+00\n",
      "Epoch 22663, Loss: 99.96470642089844, Neurons: 11, Grad norm: 7.465e+00\n",
      "Epoch 22664, Loss: 99.95853424072266, Neurons: 11, Grad norm: 1.175e+01\n",
      "Epoch 22665, Loss: 99.95234680175781, Neurons: 11, Grad norm: 1.026e+01\n",
      "Epoch 22666, Loss: 99.9461669921875, Neurons: 11, Grad norm: 1.150e+01\n",
      "Epoch 22667, Loss: 99.93994903564453, Neurons: 11, Grad norm: 7.335e+00\n",
      "Epoch 22668, Loss: 99.93374633789062, Neurons: 11, Grad norm: 6.421e+00\n",
      "Epoch 22669, Loss: 99.9275131225586, Neurons: 11, Grad norm: 2.338e+00\n",
      "Epoch 22670, Loss: 99.92131042480469, Neurons: 11, Grad norm: 2.301e+00\n",
      "Epoch 22671, Loss: 99.91510772705078, Neurons: 11, Grad norm: 5.548e+00\n",
      "Epoch 22672, Loss: 99.90889739990234, Neurons: 11, Grad norm: 5.130e+00\n",
      "Epoch 22673, Loss: 99.90269470214844, Neurons: 11, Grad norm: 7.938e+00\n",
      "Epoch 22674, Loss: 99.896484375, Neurons: 11, Grad norm: 5.893e+00\n",
      "Epoch 22675, Loss: 99.89025115966797, Neurons: 11, Grad norm: 7.114e+00\n",
      "Epoch 22676, Loss: 99.88402557373047, Neurons: 11, Grad norm: 3.959e+00\n",
      "Epoch 22677, Loss: 99.87779998779297, Neurons: 11, Grad norm: 4.257e+00\n",
      "Epoch 22678, Loss: 99.87156677246094, Neurons: 11, Grad norm: 2.288e+00\n",
      "Epoch 22679, Loss: 99.86532592773438, Neurons: 11, Grad norm: 2.280e+00\n",
      "Epoch 22680, Loss: 99.85908508300781, Neurons: 11, Grad norm: 4.092e+00\n",
      "Epoch 22681, Loss: 99.85285186767578, Neurons: 11, Grad norm: 3.198e+00\n",
      "Epoch 22682, Loss: 99.84661865234375, Neurons: 11, Grad norm: 5.335e+00\n",
      "Epoch 22683, Loss: 99.84037780761719, Neurons: 11, Grad norm: 3.583e+00\n",
      "Epoch 22684, Loss: 99.83412170410156, Neurons: 11, Grad norm: 5.051e+00\n",
      "Epoch 22685, Loss: 99.82787322998047, Neurons: 11, Grad norm: 2.727e+00\n",
      "Epoch 22686, Loss: 99.82161712646484, Neurons: 11, Grad norm: 3.470e+00\n",
      "Epoch 22687, Loss: 99.81536102294922, Neurons: 11, Grad norm: 2.330e+00\n",
      "Epoch 22688, Loss: 99.80909729003906, Neurons: 11, Grad norm: 2.361e+00\n",
      "Epoch 22689, Loss: 99.80282592773438, Neurons: 11, Grad norm: 3.211e+00\n",
      "Epoch 22690, Loss: 99.79656219482422, Neurons: 11, Grad norm: 2.400e+00\n",
      "Epoch 22691, Loss: 99.79029846191406, Neurons: 11, Grad norm: 4.031e+00\n",
      "Epoch 22692, Loss: 99.78401947021484, Neurons: 11, Grad norm: 2.764e+00\n",
      "Epoch 22693, Loss: 99.77774810791016, Neurons: 11, Grad norm: 4.383e+00\n",
      "Epoch 22694, Loss: 99.7714614868164, Neurons: 11, Grad norm: 2.655e+00\n",
      "Epoch 22695, Loss: 99.76518249511719, Neurons: 11, Grad norm: 3.867e+00\n",
      "Epoch 22696, Loss: 99.7588882446289, Neurons: 11, Grad norm: 2.363e+00\n",
      "Epoch 22697, Loss: 99.75259399414062, Neurons: 11, Grad norm: 3.219e+00\n",
      "Epoch 22698, Loss: 99.74630737304688, Neurons: 11, Grad norm: 2.293e+00\n",
      "Epoch 22699, Loss: 99.7400131225586, Neurons: 11, Grad norm: 2.733e+00\n",
      "Epoch 22699, Test loss: 95.75157928466797\n",
      "Epoch 22700, Loss: 99.73371124267578, Neurons: 11, Grad norm: 2.441e+00\n",
      "Epoch 22701, Loss: 99.72740173339844, Neurons: 11, Grad norm: 2.511e+00\n",
      "Epoch 22702, Loss: 99.72111511230469, Neurons: 11, Grad norm: 2.589e+00\n",
      "Epoch 22703, Loss: 99.71479797363281, Neurons: 11, Grad norm: 2.422e+00\n",
      "Epoch 22704, Loss: 99.70848846435547, Neurons: 11, Grad norm: 2.565e+00\n",
      "Epoch 22705, Loss: 99.70216369628906, Neurons: 11, Grad norm: 2.446e+00\n",
      "Epoch 22706, Loss: 99.69584655761719, Neurons: 11, Grad norm: 2.577e+00\n",
      "Epoch 22707, Loss: 99.68952178955078, Neurons: 11, Grad norm: 2.474e+00\n",
      "Epoch 22708, Loss: 99.68318939208984, Neurons: 11, Grad norm: 2.603e+00\n",
      "Epoch 22709, Loss: 99.67687225341797, Neurons: 11, Grad norm: 2.415e+00\n",
      "Epoch 22710, Loss: 99.6705322265625, Neurons: 11, Grad norm: 2.665e+00\n",
      "Epoch 22711, Loss: 99.6642074584961, Neurons: 11, Grad norm: 2.355e+00\n",
      "Epoch 22712, Loss: 99.6578598022461, Neurons: 11, Grad norm: 2.850e+00\n",
      "Epoch 22713, Loss: 99.65152740478516, Neurons: 11, Grad norm: 2.291e+00\n",
      "Epoch 22714, Loss: 99.64517211914062, Neurons: 11, Grad norm: 3.151e+00\n",
      "Epoch 22715, Loss: 99.63882446289062, Neurons: 11, Grad norm: 2.308e+00\n",
      "Epoch 22716, Loss: 99.63247680664062, Neurons: 11, Grad norm: 3.418e+00\n",
      "Epoch 22717, Loss: 99.62612915039062, Neurons: 11, Grad norm: 2.338e+00\n",
      "Epoch 22718, Loss: 99.6197509765625, Neurons: 11, Grad norm: 3.375e+00\n",
      "Epoch 22719, Loss: 99.61341094970703, Neurons: 11, Grad norm: 2.305e+00\n",
      "Epoch 22720, Loss: 99.6070327758789, Neurons: 11, Grad norm: 3.263e+00\n",
      "Epoch 22721, Loss: 99.60066223144531, Neurons: 11, Grad norm: 2.301e+00\n",
      "Epoch 22722, Loss: 99.59428405761719, Neurons: 11, Grad norm: 3.312e+00\n",
      "Epoch 22723, Loss: 99.58789825439453, Neurons: 11, Grad norm: 2.326e+00\n",
      "Epoch 22724, Loss: 99.58153533935547, Neurons: 11, Grad norm: 3.431e+00\n",
      "Epoch 22725, Loss: 99.57514953613281, Neurons: 11, Grad norm: 2.377e+00\n",
      "Epoch 22726, Loss: 99.56877136230469, Neurons: 11, Grad norm: 3.685e+00\n",
      "Epoch 22727, Loss: 99.56238555908203, Neurons: 11, Grad norm: 2.442e+00\n",
      "Epoch 22728, Loss: 99.55598449707031, Neurons: 11, Grad norm: 3.753e+00\n",
      "Epoch 22729, Loss: 99.54957580566406, Neurons: 11, Grad norm: 2.601e+00\n",
      "Epoch 22730, Loss: 99.54318237304688, Neurons: 11, Grad norm: 4.266e+00\n",
      "Epoch 22731, Loss: 99.53678131103516, Neurons: 11, Grad norm: 2.857e+00\n",
      "Epoch 22732, Loss: 99.53038024902344, Neurons: 11, Grad norm: 4.693e+00\n",
      "Epoch 22733, Loss: 99.52396392822266, Neurons: 11, Grad norm: 3.456e+00\n",
      "Epoch 22734, Loss: 99.51756286621094, Neurons: 11, Grad norm: 5.556e+00\n",
      "Epoch 22735, Loss: 99.51114654541016, Neurons: 11, Grad norm: 4.158e+00\n",
      "Epoch 22736, Loss: 99.50472259521484, Neurons: 11, Grad norm: 6.683e+00\n",
      "Epoch 22737, Loss: 99.49829864501953, Neurons: 11, Grad norm: 5.494e+00\n",
      "Epoch 22738, Loss: 99.49188232421875, Neurons: 11, Grad norm: 8.270e+00\n",
      "Epoch 22739, Loss: 99.48545837402344, Neurons: 11, Grad norm: 7.545e+00\n",
      "Epoch 22740, Loss: 99.4790267944336, Neurons: 11, Grad norm: 1.118e+01\n",
      "Epoch 22741, Loss: 99.47261047363281, Neurons: 11, Grad norm: 1.102e+01\n",
      "Epoch 22742, Loss: 99.46620178222656, Neurons: 11, Grad norm: 1.536e+01\n",
      "Epoch 22743, Loss: 99.45978546142578, Neurons: 11, Grad norm: 1.658e+01\n",
      "Epoch 22744, Loss: 99.453369140625, Neurons: 11, Grad norm: 2.239e+01\n",
      "Epoch 22745, Loss: 99.4469985961914, Neurons: 11, Grad norm: 2.473e+01\n",
      "Epoch 22746, Loss: 99.44062805175781, Neurons: 11, Grad norm: 3.249e+01\n",
      "Epoch 22747, Loss: 99.434326171875, Neurons: 11, Grad norm: 3.734e+01\n",
      "Epoch 22748, Loss: 99.42804718017578, Neurons: 11, Grad norm: 4.693e+01\n",
      "Epoch 22749, Loss: 99.421875, Neurons: 11, Grad norm: 5.325e+01\n",
      "Epoch 22749, Test loss: 95.43370819091797\n",
      "Epoch 22750, Loss: 99.4157943725586, Neurons: 11, Grad norm: 6.370e+01\n",
      "Epoch 22751, Loss: 99.40975952148438, Neurons: 11, Grad norm: 6.819e+01\n",
      "Epoch 22752, Loss: 99.40372467041016, Neurons: 11, Grad norm: 7.266e+01\n",
      "Epoch 22753, Loss: 99.39750671386719, Neurons: 11, Grad norm: 6.686e+01\n",
      "Epoch 22754, Loss: 99.39097595214844, Neurons: 11, Grad norm: 5.746e+01\n",
      "Epoch 22755, Loss: 99.3841323852539, Neurons: 11, Grad norm: 3.652e+01\n",
      "Epoch 22756, Loss: 99.377197265625, Neurons: 11, Grad norm: 1.558e+01\n",
      "Epoch 22757, Loss: 99.3704605102539, Neurons: 11, Grad norm: 1.003e+01\n",
      "Epoch 22758, Loss: 99.36412811279297, Neurons: 11, Grad norm: 2.745e+01\n",
      "Epoch 22759, Loss: 99.35814666748047, Neurons: 11, Grad norm: 4.250e+01\n",
      "Epoch 22760, Loss: 99.35223388671875, Neurons: 11, Grad norm: 4.482e+01\n",
      "Epoch 22761, Loss: 99.34612274169922, Neurons: 11, Grad norm: 4.241e+01\n",
      "Epoch 22762, Loss: 99.3397216796875, Neurons: 11, Grad norm: 2.857e+01\n",
      "Epoch 22763, Loss: 99.33313751220703, Neurons: 11, Grad norm: 1.377e+01\n",
      "Epoch 22764, Loss: 99.32662200927734, Neurons: 11, Grad norm: 6.557e+00\n",
      "Epoch 22765, Loss: 99.32035064697266, Neurons: 11, Grad norm: 1.911e+01\n",
      "Epoch 22766, Loss: 99.31423950195312, Neurons: 11, Grad norm: 3.067e+01\n",
      "Epoch 22767, Loss: 99.30817413330078, Neurons: 11, Grad norm: 3.124e+01\n",
      "Epoch 22768, Loss: 99.3019790649414, Neurons: 11, Grad norm: 2.874e+01\n",
      "Epoch 22769, Loss: 99.29564666748047, Neurons: 11, Grad norm: 1.687e+01\n",
      "Epoch 22770, Loss: 99.2892074584961, Neurons: 11, Grad norm: 6.452e+00\n",
      "Epoch 22771, Loss: 99.28286743164062, Neurons: 11, Grad norm: 8.814e+00\n",
      "Epoch 22772, Loss: 99.2766342163086, Neurons: 11, Grad norm: 1.644e+01\n",
      "Epoch 22773, Loss: 99.27046966552734, Neurons: 11, Grad norm: 2.353e+01\n",
      "Epoch 22774, Loss: 99.26429748535156, Neurons: 11, Grad norm: 2.141e+01\n",
      "Epoch 22775, Loss: 99.25804901123047, Neurons: 11, Grad norm: 1.854e+01\n",
      "Epoch 22776, Loss: 99.25171661376953, Neurons: 11, Grad norm: 8.651e+00\n",
      "Epoch 22777, Loss: 99.2453842163086, Neurons: 11, Grad norm: 2.528e+00\n",
      "Epoch 22778, Loss: 99.23908233642578, Neurons: 11, Grad norm: 9.702e+00\n",
      "Epoch 22779, Loss: 99.23285675048828, Neurons: 11, Grad norm: 1.354e+01\n",
      "Epoch 22780, Loss: 99.22664642333984, Neurons: 11, Grad norm: 1.779e+01\n",
      "Epoch 22781, Loss: 99.22041320800781, Neurons: 11, Grad norm: 1.448e+01\n",
      "Epoch 22782, Loss: 99.21411895751953, Neurons: 11, Grad norm: 1.228e+01\n",
      "Epoch 22783, Loss: 99.20780181884766, Neurons: 11, Grad norm: 4.599e+00\n",
      "Epoch 22784, Loss: 99.20149993896484, Neurons: 11, Grad norm: 2.425e+00\n",
      "Epoch 22785, Loss: 99.1952133178711, Neurons: 11, Grad norm: 8.643e+00\n",
      "Epoch 22786, Loss: 99.1889419555664, Neurons: 11, Grad norm: 1.025e+01\n",
      "Epoch 22787, Loss: 99.18268585205078, Neurons: 11, Grad norm: 1.345e+01\n",
      "Epoch 22788, Loss: 99.17639923095703, Neurons: 11, Grad norm: 1.038e+01\n",
      "Epoch 22789, Loss: 99.17011260986328, Neurons: 11, Grad norm: 9.147e+00\n",
      "Epoch 22790, Loss: 99.16378784179688, Neurons: 11, Grad norm: 3.260e+00\n",
      "Epoch 22791, Loss: 99.157470703125, Neurons: 11, Grad norm: 2.334e+00\n",
      "Epoch 22792, Loss: 99.15116882324219, Neurons: 11, Grad norm: 6.681e+00\n",
      "Epoch 22793, Loss: 99.1448745727539, Neurons: 11, Grad norm: 7.465e+00\n",
      "Epoch 22794, Loss: 99.13858795166016, Neurons: 11, Grad norm: 1.025e+01\n",
      "Epoch 22795, Loss: 99.13227081298828, Neurons: 11, Grad norm: 7.641e+00\n",
      "Epoch 22796, Loss: 99.12596130371094, Neurons: 11, Grad norm: 7.590e+00\n",
      "Epoch 22797, Loss: 99.11963653564453, Neurons: 11, Grad norm: 3.304e+00\n",
      "Epoch 22798, Loss: 99.11328887939453, Neurons: 11, Grad norm: 2.588e+00\n",
      "Epoch 22799, Loss: 99.10697174072266, Neurons: 11, Grad norm: 4.218e+00\n",
      "Epoch 22799, Test loss: 95.13172149658203\n",
      "Epoch 22800, Loss: 99.10063171386719, Neurons: 11, Grad norm: 4.264e+00\n",
      "Epoch 22801, Loss: 99.09432220458984, Neurons: 11, Grad norm: 7.014e+00\n",
      "Epoch 22802, Loss: 99.08798217773438, Neurons: 11, Grad norm: 5.127e+00\n",
      "Epoch 22803, Loss: 99.08164978027344, Neurons: 11, Grad norm: 6.020e+00\n",
      "Epoch 22804, Loss: 99.0752944946289, Neurons: 11, Grad norm: 3.004e+00\n",
      "Epoch 22805, Loss: 99.0689468383789, Neurons: 11, Grad norm: 3.120e+00\n",
      "Epoch 22806, Loss: 99.06258392333984, Neurons: 11, Grad norm: 2.810e+00\n",
      "Epoch 22807, Loss: 99.05622100830078, Neurons: 11, Grad norm: 2.639e+00\n",
      "Epoch 22808, Loss: 99.04987335205078, Neurons: 11, Grad norm: 4.874e+00\n",
      "Epoch 22809, Loss: 99.04351043701172, Neurons: 11, Grad norm: 3.802e+00\n",
      "Epoch 22810, Loss: 99.03716278076172, Neurons: 11, Grad norm: 5.631e+00\n",
      "Epoch 22811, Loss: 99.03079986572266, Neurons: 11, Grad norm: 3.636e+00\n",
      "Epoch 22812, Loss: 99.0244140625, Neurons: 11, Grad norm: 4.641e+00\n",
      "Epoch 22813, Loss: 99.01802062988281, Neurons: 11, Grad norm: 2.547e+00\n",
      "Epoch 22814, Loss: 99.01164245605469, Neurons: 11, Grad norm: 2.872e+00\n",
      "Epoch 22815, Loss: 99.00525665283203, Neurons: 11, Grad norm: 2.804e+00\n",
      "Epoch 22816, Loss: 98.99887084960938, Neurons: 11, Grad norm: 2.407e+00\n",
      "Epoch 22817, Loss: 98.99247741699219, Neurons: 11, Grad norm: 4.051e+00\n",
      "Epoch 22818, Loss: 98.986083984375, Neurons: 11, Grad norm: 2.965e+00\n",
      "Epoch 22819, Loss: 98.97969818115234, Neurons: 11, Grad norm: 4.522e+00\n",
      "Epoch 22820, Loss: 98.97328186035156, Neurons: 11, Grad norm: 2.842e+00\n",
      "Epoch 22821, Loss: 98.96687316894531, Neurons: 11, Grad norm: 3.816e+00\n",
      "Epoch 22822, Loss: 98.96045684814453, Neurons: 11, Grad norm: 2.346e+00\n",
      "Epoch 22823, Loss: 98.95404815673828, Neurons: 11, Grad norm: 2.638e+00\n",
      "Epoch 22824, Loss: 98.94761657714844, Neurons: 11, Grad norm: 2.878e+00\n",
      "Epoch 22825, Loss: 98.94120788574219, Neurons: 11, Grad norm: 2.435e+00\n",
      "Epoch 22826, Loss: 98.93477630615234, Neurons: 11, Grad norm: 4.138e+00\n",
      "Epoch 22827, Loss: 98.9283447265625, Neurons: 11, Grad norm: 3.006e+00\n",
      "Epoch 22828, Loss: 98.92190551757812, Neurons: 11, Grad norm: 4.537e+00\n",
      "Epoch 22829, Loss: 98.91546630859375, Neurons: 11, Grad norm: 2.978e+00\n",
      "Epoch 22830, Loss: 98.90901184082031, Neurons: 11, Grad norm: 4.182e+00\n",
      "Epoch 22831, Loss: 98.90257263183594, Neurons: 11, Grad norm: 2.533e+00\n",
      "Epoch 22832, Loss: 98.89613342285156, Neurons: 11, Grad norm: 3.193e+00\n",
      "Epoch 22833, Loss: 98.88967895507812, Neurons: 11, Grad norm: 2.366e+00\n",
      "Epoch 22834, Loss: 98.88322448730469, Neurons: 11, Grad norm: 2.425e+00\n",
      "Epoch 22835, Loss: 98.87675476074219, Neurons: 11, Grad norm: 3.168e+00\n",
      "Epoch 22836, Loss: 98.87026977539062, Neurons: 11, Grad norm: 2.512e+00\n",
      "Epoch 22837, Loss: 98.86380767822266, Neurons: 11, Grad norm: 4.129e+00\n",
      "Epoch 22838, Loss: 98.85733795166016, Neurons: 11, Grad norm: 3.119e+00\n",
      "Epoch 22839, Loss: 98.8508529663086, Neurons: 11, Grad norm: 4.980e+00\n",
      "Epoch 22840, Loss: 98.8443832397461, Neurons: 11, Grad norm: 3.480e+00\n",
      "Epoch 22841, Loss: 98.83789825439453, Neurons: 11, Grad norm: 5.038e+00\n",
      "Epoch 22842, Loss: 98.83141326904297, Neurons: 11, Grad norm: 3.405e+00\n",
      "Epoch 22843, Loss: 98.82491302490234, Neurons: 11, Grad norm: 4.793e+00\n",
      "Epoch 22844, Loss: 98.81841278076172, Neurons: 11, Grad norm: 3.037e+00\n",
      "Epoch 22845, Loss: 98.81190490722656, Neurons: 11, Grad norm: 4.059e+00\n",
      "Epoch 22846, Loss: 98.80541229248047, Neurons: 11, Grad norm: 2.477e+00\n",
      "Epoch 22847, Loss: 98.79888153076172, Neurons: 11, Grad norm: 3.059e+00\n",
      "Epoch 22848, Loss: 98.79237365722656, Neurons: 11, Grad norm: 2.465e+00\n",
      "Epoch 22849, Loss: 98.78585815429688, Neurons: 11, Grad norm: 2.355e+00\n",
      "Epoch 22849, Test loss: 94.81878662109375\n",
      "Epoch 22850, Loss: 98.77933502197266, Neurons: 11, Grad norm: 3.261e+00\n",
      "Epoch 22851, Loss: 98.7728042602539, Neurons: 11, Grad norm: 2.572e+00\n",
      "Epoch 22852, Loss: 98.76628875732422, Neurons: 11, Grad norm: 4.365e+00\n",
      "Epoch 22853, Loss: 98.75975036621094, Neurons: 11, Grad norm: 3.355e+00\n",
      "Epoch 22854, Loss: 98.7531967163086, Neurons: 11, Grad norm: 5.304e+00\n",
      "Epoch 22855, Loss: 98.74667358398438, Neurons: 11, Grad norm: 4.091e+00\n",
      "Epoch 22856, Loss: 98.74011993408203, Neurons: 11, Grad norm: 6.022e+00\n",
      "Epoch 22857, Loss: 98.73357391357422, Neurons: 11, Grad norm: 4.459e+00\n",
      "Epoch 22858, Loss: 98.7270278930664, Neurons: 11, Grad norm: 6.210e+00\n",
      "Epoch 22859, Loss: 98.720458984375, Neurons: 11, Grad norm: 4.418e+00\n",
      "Epoch 22860, Loss: 98.71391296386719, Neurons: 11, Grad norm: 5.804e+00\n",
      "Epoch 22861, Loss: 98.70732116699219, Neurons: 11, Grad norm: 3.954e+00\n",
      "Epoch 22862, Loss: 98.70074462890625, Neurons: 11, Grad norm: 5.458e+00\n",
      "Epoch 22863, Loss: 98.69418334960938, Neurons: 11, Grad norm: 3.757e+00\n",
      "Epoch 22864, Loss: 98.68758392333984, Neurons: 11, Grad norm: 5.172e+00\n",
      "Epoch 22865, Loss: 98.68102264404297, Neurons: 11, Grad norm: 3.550e+00\n",
      "Epoch 22866, Loss: 98.6744384765625, Neurons: 11, Grad norm: 5.096e+00\n",
      "Epoch 22867, Loss: 98.66783905029297, Neurons: 11, Grad norm: 3.471e+00\n",
      "Epoch 22868, Loss: 98.66123962402344, Neurons: 11, Grad norm: 4.952e+00\n",
      "Epoch 22869, Loss: 98.65463256835938, Neurons: 11, Grad norm: 3.478e+00\n",
      "Epoch 22870, Loss: 98.6480484008789, Neurons: 11, Grad norm: 5.097e+00\n",
      "Epoch 22871, Loss: 98.64144134521484, Neurons: 11, Grad norm: 3.695e+00\n",
      "Epoch 22872, Loss: 98.63482666015625, Neurons: 11, Grad norm: 5.534e+00\n",
      "Epoch 22873, Loss: 98.62821960449219, Neurons: 11, Grad norm: 4.332e+00\n",
      "Epoch 22874, Loss: 98.62159729003906, Neurons: 11, Grad norm: 6.621e+00\n",
      "Epoch 22875, Loss: 98.61498260498047, Neurons: 11, Grad norm: 5.555e+00\n",
      "Epoch 22876, Loss: 98.60835266113281, Neurons: 11, Grad norm: 8.071e+00\n",
      "Epoch 22877, Loss: 98.60173797607422, Neurons: 11, Grad norm: 7.304e+00\n",
      "Epoch 22878, Loss: 98.59510040283203, Neurons: 11, Grad norm: 1.022e+01\n",
      "Epoch 22879, Loss: 98.58845520019531, Neurons: 11, Grad norm: 9.705e+00\n",
      "Epoch 22880, Loss: 98.58182525634766, Neurons: 11, Grad norm: 1.314e+01\n",
      "Epoch 22881, Loss: 98.5751953125, Neurons: 11, Grad norm: 1.357e+01\n",
      "Epoch 22882, Loss: 98.56856536865234, Neurons: 11, Grad norm: 1.813e+01\n",
      "Epoch 22883, Loss: 98.56195068359375, Neurons: 11, Grad norm: 1.944e+01\n",
      "Epoch 22884, Loss: 98.55535125732422, Neurons: 11, Grad norm: 2.527e+01\n",
      "Epoch 22885, Loss: 98.54874420166016, Neurons: 11, Grad norm: 2.844e+01\n",
      "Epoch 22886, Loss: 98.54218292236328, Neurons: 11, Grad norm: 3.590e+01\n",
      "Epoch 22887, Loss: 98.53568267822266, Neurons: 11, Grad norm: 4.045e+01\n",
      "Epoch 22888, Loss: 98.52920532226562, Neurons: 11, Grad norm: 4.942e+01\n",
      "Epoch 22889, Loss: 98.52279663085938, Neurons: 11, Grad norm: 5.485e+01\n",
      "Epoch 22890, Loss: 98.51644897460938, Neurons: 11, Grad norm: 6.298e+01\n",
      "Epoch 22891, Loss: 98.51010131835938, Neurons: 11, Grad norm: 6.506e+01\n",
      "Epoch 22892, Loss: 98.5036849975586, Neurons: 11, Grad norm: 6.683e+01\n",
      "Epoch 22893, Loss: 98.49710845947266, Neurons: 11, Grad norm: 5.922e+01\n",
      "Epoch 22894, Loss: 98.49028778076172, Neurons: 11, Grad norm: 4.908e+01\n",
      "Epoch 22895, Loss: 98.48326873779297, Neurons: 11, Grad norm: 3.028e+01\n",
      "Epoch 22896, Loss: 98.47624969482422, Neurons: 11, Grad norm: 1.262e+01\n",
      "Epoch 22897, Loss: 98.46941375732422, Neurons: 11, Grad norm: 9.072e+00\n",
      "Epoch 22898, Loss: 98.46286010742188, Neurons: 11, Grad norm: 2.321e+01\n",
      "Epoch 22899, Loss: 98.45653533935547, Neurons: 11, Grad norm: 3.619e+01\n",
      "Epoch 22899, Test loss: 94.50299072265625\n",
      "Epoch 22900, Loss: 98.45024871826172, Neurons: 11, Grad norm: 3.929e+01\n",
      "Epoch 22901, Loss: 98.44385528564453, Neurons: 11, Grad norm: 3.937e+01\n",
      "Epoch 22902, Loss: 98.43728637695312, Neurons: 11, Grad norm: 2.990e+01\n",
      "Epoch 22903, Loss: 98.4305648803711, Neurons: 11, Grad norm: 1.976e+01\n",
      "Epoch 22904, Loss: 98.42384338378906, Neurons: 11, Grad norm: 4.545e+00\n",
      "Epoch 22905, Loss: 98.41720581054688, Neurons: 11, Grad norm: 7.985e+00\n",
      "Epoch 22906, Loss: 98.41069793701172, Neurons: 11, Grad norm: 2.012e+01\n",
      "Epoch 22907, Loss: 98.40425872802734, Neurons: 11, Grad norm: 2.479e+01\n",
      "Epoch 22908, Loss: 98.39786529541016, Neurons: 11, Grad norm: 2.824e+01\n",
      "Epoch 22909, Loss: 98.39137268066406, Neurons: 11, Grad norm: 2.348e+01\n",
      "Epoch 22910, Loss: 98.38477325439453, Neurons: 11, Grad norm: 1.843e+01\n",
      "Epoch 22911, Loss: 98.3781509399414, Neurons: 11, Grad norm: 7.730e+00\n",
      "Epoch 22912, Loss: 98.37153625488281, Neurons: 11, Grad norm: 2.366e+00\n",
      "Epoch 22913, Loss: 98.36495971679688, Neurons: 11, Grad norm: 1.073e+01\n",
      "Epoch 22914, Loss: 98.35845947265625, Neurons: 11, Grad norm: 1.482e+01\n",
      "Epoch 22915, Loss: 98.35196685791016, Neurons: 11, Grad norm: 1.935e+01\n",
      "Epoch 22916, Loss: 98.34546661376953, Neurons: 11, Grad norm: 1.716e+01\n",
      "Epoch 22917, Loss: 98.33891296386719, Neurons: 11, Grad norm: 1.566e+01\n",
      "Epoch 22918, Loss: 98.33232116699219, Neurons: 11, Grad norm: 8.742e+00\n",
      "Epoch 22919, Loss: 98.32569885253906, Neurons: 11, Grad norm: 4.461e+00\n",
      "Epoch 22920, Loss: 98.3191146850586, Neurons: 11, Grad norm: 4.774e+00\n",
      "Epoch 22921, Loss: 98.31256866455078, Neurons: 11, Grad norm: 7.674e+00\n",
      "Epoch 22922, Loss: 98.3060073852539, Neurons: 11, Grad norm: 1.244e+01\n",
      "Epoch 22923, Loss: 98.29946899414062, Neurons: 11, Grad norm: 1.183e+01\n",
      "Epoch 22924, Loss: 98.29290008544922, Neurons: 11, Grad norm: 1.263e+01\n",
      "Epoch 22925, Loss: 98.28630828857422, Neurons: 11, Grad norm: 8.360e+00\n",
      "Epoch 22926, Loss: 98.27972412109375, Neurons: 11, Grad norm: 6.572e+00\n",
      "Epoch 22927, Loss: 98.27311706542969, Neurons: 11, Grad norm: 2.342e+00\n",
      "Epoch 22928, Loss: 98.26651000976562, Neurons: 11, Grad norm: 3.166e+00\n",
      "Epoch 22929, Loss: 98.25990295410156, Neurons: 11, Grad norm: 7.732e+00\n",
      "Epoch 22930, Loss: 98.25333404541016, Neurons: 11, Grad norm: 8.066e+00\n",
      "Epoch 22931, Loss: 98.2467269897461, Neurons: 11, Grad norm: 1.048e+01\n",
      "Epoch 22932, Loss: 98.24015045166016, Neurons: 11, Grad norm: 8.293e+00\n",
      "Epoch 22933, Loss: 98.2335205078125, Neurons: 11, Grad norm: 8.306e+00\n",
      "Epoch 22934, Loss: 98.22688293457031, Neurons: 11, Grad norm: 4.363e+00\n",
      "Epoch 22935, Loss: 98.22026824951172, Neurons: 11, Grad norm: 3.556e+00\n",
      "Epoch 22936, Loss: 98.21363830566406, Neurons: 11, Grad norm: 2.855e+00\n",
      "Epoch 22937, Loss: 98.20700073242188, Neurons: 11, Grad norm: 3.178e+00\n",
      "Epoch 22938, Loss: 98.20035552978516, Neurons: 11, Grad norm: 5.866e+00\n",
      "Epoch 22939, Loss: 98.19373321533203, Neurons: 11, Grad norm: 4.880e+00\n",
      "Epoch 22940, Loss: 98.18709564208984, Neurons: 11, Grad norm: 6.588e+00\n",
      "Epoch 22941, Loss: 98.18045043945312, Neurons: 11, Grad norm: 4.548e+00\n",
      "Epoch 22942, Loss: 98.17379760742188, Neurons: 11, Grad norm: 5.121e+00\n",
      "Epoch 22943, Loss: 98.1671371459961, Neurons: 11, Grad norm: 2.812e+00\n",
      "Epoch 22944, Loss: 98.16048431396484, Neurons: 11, Grad norm: 3.042e+00\n",
      "Epoch 22945, Loss: 98.15380859375, Neurons: 11, Grad norm: 2.616e+00\n",
      "Epoch 22946, Loss: 98.14714050292969, Neurons: 11, Grad norm: 2.405e+00\n",
      "Epoch 22947, Loss: 98.14047241210938, Neurons: 11, Grad norm: 3.801e+00\n",
      "Epoch 22948, Loss: 98.13378143310547, Neurons: 11, Grad norm: 2.912e+00\n",
      "Epoch 22949, Loss: 98.12712097167969, Neurons: 11, Grad norm: 4.338e+00\n",
      "Epoch 22949, Test loss: 94.1784896850586\n",
      "Epoch 22950, Loss: 98.12042236328125, Neurons: 11, Grad norm: 2.809e+00\n",
      "Epoch 22951, Loss: 98.11373901367188, Neurons: 11, Grad norm: 3.605e+00\n",
      "Epoch 22952, Loss: 98.1070327758789, Neurons: 11, Grad norm: 2.401e+00\n",
      "Epoch 22953, Loss: 98.100341796875, Neurons: 11, Grad norm: 2.851e+00\n",
      "Epoch 22954, Loss: 98.0936279296875, Neurons: 11, Grad norm: 2.444e+00\n",
      "Epoch 22955, Loss: 98.08692169189453, Neurons: 11, Grad norm: 2.408e+00\n",
      "Epoch 22956, Loss: 98.08020782470703, Neurons: 11, Grad norm: 2.759e+00\n",
      "Epoch 22957, Loss: 98.073486328125, Neurons: 11, Grad norm: 2.342e+00\n",
      "Epoch 22958, Loss: 98.0667724609375, Neurons: 11, Grad norm: 3.196e+00\n",
      "Epoch 22959, Loss: 98.06002807617188, Neurons: 11, Grad norm: 2.382e+00\n",
      "Epoch 22960, Loss: 98.05330657958984, Neurons: 11, Grad norm: 3.166e+00\n",
      "Epoch 22961, Loss: 98.04656982421875, Neurons: 11, Grad norm: 2.368e+00\n",
      "Epoch 22962, Loss: 98.0398178100586, Neurons: 11, Grad norm: 3.055e+00\n",
      "Epoch 22963, Loss: 98.03307342529297, Neurons: 11, Grad norm: 2.339e+00\n",
      "Epoch 22964, Loss: 98.02632141113281, Neurons: 11, Grad norm: 2.947e+00\n",
      "Epoch 22965, Loss: 98.01956939697266, Neurons: 11, Grad norm: 2.342e+00\n",
      "Epoch 22966, Loss: 98.0128173828125, Neurons: 11, Grad norm: 2.598e+00\n",
      "Epoch 22967, Loss: 98.00603485107422, Neurons: 11, Grad norm: 2.546e+00\n",
      "Epoch 22968, Loss: 97.99927520751953, Neurons: 11, Grad norm: 2.354e+00\n",
      "Epoch 22969, Loss: 97.99246978759766, Neurons: 11, Grad norm: 3.022e+00\n",
      "Epoch 22970, Loss: 97.98570251464844, Neurons: 11, Grad norm: 2.444e+00\n",
      "Epoch 22971, Loss: 97.97891998291016, Neurons: 11, Grad norm: 3.660e+00\n",
      "Epoch 22972, Loss: 97.97213745117188, Neurons: 11, Grad norm: 2.746e+00\n",
      "Epoch 22973, Loss: 97.96533966064453, Neurons: 11, Grad norm: 4.063e+00\n",
      "Epoch 22974, Loss: 97.95854187011719, Neurons: 11, Grad norm: 2.821e+00\n",
      "Epoch 22975, Loss: 97.95172882080078, Neurons: 11, Grad norm: 3.879e+00\n",
      "Epoch 22976, Loss: 97.94491577148438, Neurons: 11, Grad norm: 2.682e+00\n",
      "Epoch 22977, Loss: 97.93812561035156, Neurons: 11, Grad norm: 3.731e+00\n",
      "Epoch 22978, Loss: 97.9312973022461, Neurons: 11, Grad norm: 2.599e+00\n",
      "Epoch 22979, Loss: 97.92446899414062, Neurons: 11, Grad norm: 3.683e+00\n",
      "Epoch 22980, Loss: 97.91766357421875, Neurons: 11, Grad norm: 2.638e+00\n",
      "Epoch 22981, Loss: 97.91082000732422, Neurons: 11, Grad norm: 3.661e+00\n",
      "Epoch 22982, Loss: 97.90396881103516, Neurons: 11, Grad norm: 2.547e+00\n",
      "Epoch 22983, Loss: 97.89713287353516, Neurons: 11, Grad norm: 3.470e+00\n",
      "Epoch 22984, Loss: 97.8902816772461, Neurons: 11, Grad norm: 2.436e+00\n",
      "Epoch 22985, Loss: 97.88343811035156, Neurons: 11, Grad norm: 3.184e+00\n",
      "Epoch 22986, Loss: 97.87657928466797, Neurons: 11, Grad norm: 2.358e+00\n",
      "Epoch 22987, Loss: 97.86972045898438, Neurons: 11, Grad norm: 3.020e+00\n",
      "Epoch 22988, Loss: 97.86286163330078, Neurons: 11, Grad norm: 2.335e+00\n",
      "Epoch 22989, Loss: 97.85597229003906, Neurons: 11, Grad norm: 2.751e+00\n",
      "Epoch 22990, Loss: 97.84911346435547, Neurons: 11, Grad norm: 2.341e+00\n",
      "Epoch 22991, Loss: 97.84223175048828, Neurons: 11, Grad norm: 2.602e+00\n",
      "Epoch 22992, Loss: 97.8353271484375, Neurons: 11, Grad norm: 2.500e+00\n",
      "Epoch 22993, Loss: 97.82846069335938, Neurons: 11, Grad norm: 2.380e+00\n",
      "Epoch 22994, Loss: 97.82154846191406, Neurons: 11, Grad norm: 2.732e+00\n",
      "Epoch 22995, Loss: 97.81465911865234, Neurons: 11, Grad norm: 2.333e+00\n",
      "Epoch 22996, Loss: 97.80775451660156, Neurons: 11, Grad norm: 2.947e+00\n",
      "Epoch 22997, Loss: 97.80084991455078, Neurons: 11, Grad norm: 2.346e+00\n",
      "Epoch 22998, Loss: 97.79393768310547, Neurons: 11, Grad norm: 3.056e+00\n",
      "Epoch 22999, Loss: 97.78701782226562, Neurons: 11, Grad norm: 2.390e+00\n",
      "Epoch 22999, Test loss: 93.84857940673828\n",
      "Epoch 23000, Loss: 97.78009033203125, Neurons: 11, Grad norm: 3.369e+00\n",
      "Epoch 23001, Loss: 97.7731704711914, Neurons: 11, Grad norm: 2.587e+00\n",
      "Epoch 23002, Loss: 97.76622772216797, Neurons: 11, Grad norm: 3.936e+00\n",
      "Epoch 23003, Loss: 97.75929260253906, Neurons: 11, Grad norm: 3.120e+00\n",
      "Epoch 23004, Loss: 97.7523422241211, Neurons: 11, Grad norm: 4.944e+00\n",
      "Epoch 23005, Loss: 97.74539184570312, Neurons: 11, Grad norm: 4.250e+00\n",
      "Epoch 23006, Loss: 97.73845672607422, Neurons: 11, Grad norm: 6.689e+00\n",
      "Epoch 23007, Loss: 97.73149108886719, Neurons: 11, Grad norm: 6.567e+00\n",
      "Epoch 23008, Loss: 97.72454833984375, Neurons: 11, Grad norm: 9.904e+00\n",
      "Epoch 23009, Loss: 97.71758270263672, Neurons: 11, Grad norm: 1.061e+01\n",
      "Epoch 23010, Loss: 97.71063232421875, Neurons: 11, Grad norm: 1.516e+01\n",
      "Epoch 23011, Loss: 97.70367431640625, Neurons: 11, Grad norm: 1.728e+01\n",
      "Epoch 23012, Loss: 97.69673156738281, Neurons: 11, Grad norm: 2.367e+01\n",
      "Epoch 23013, Loss: 97.6898193359375, Neurons: 11, Grad norm: 2.812e+01\n",
      "Epoch 23014, Loss: 97.6829605102539, Neurons: 11, Grad norm: 3.722e+01\n",
      "Epoch 23015, Loss: 97.6761474609375, Neurons: 11, Grad norm: 4.488e+01\n",
      "Epoch 23016, Loss: 97.66943359375, Neurons: 11, Grad norm: 5.749e+01\n",
      "Epoch 23017, Loss: 97.66285705566406, Neurons: 11, Grad norm: 6.813e+01\n",
      "Epoch 23018, Loss: 97.65646362304688, Neurons: 11, Grad norm: 8.156e+01\n",
      "Epoch 23019, Loss: 97.65016174316406, Neurons: 11, Grad norm: 8.832e+01\n",
      "Epoch 23020, Loss: 97.64375305175781, Neurons: 11, Grad norm: 9.073e+01\n",
      "Epoch 23021, Loss: 97.636962890625, Neurons: 11, Grad norm: 7.808e+01\n",
      "Epoch 23022, Loss: 97.62947082519531, Neurons: 11, Grad norm: 5.650e+01\n",
      "Epoch 23023, Loss: 97.62157440185547, Neurons: 11, Grad norm: 2.322e+01\n",
      "Epoch 23024, Loss: 97.61389923095703, Neurons: 11, Grad norm: 9.078e+00\n",
      "Epoch 23025, Loss: 97.6069564819336, Neurons: 11, Grad norm: 3.862e+01\n",
      "Epoch 23026, Loss: 97.60066223144531, Neurons: 11, Grad norm: 5.423e+01\n",
      "Epoch 23027, Loss: 97.59444427490234, Neurons: 11, Grad norm: 5.923e+01\n",
      "Epoch 23028, Loss: 97.58782196044922, Neurons: 11, Grad norm: 4.674e+01\n",
      "Epoch 23029, Loss: 97.58065032958984, Neurons: 11, Grad norm: 2.661e+01\n",
      "Epoch 23030, Loss: 97.5733413696289, Neurons: 11, Grad norm: 2.608e+00\n",
      "Epoch 23031, Loss: 97.56636047363281, Neurons: 11, Grad norm: 2.327e+01\n",
      "Epoch 23032, Loss: 97.55982208251953, Neurons: 11, Grad norm: 3.985e+01\n",
      "Epoch 23033, Loss: 97.55341339111328, Neurons: 11, Grad norm: 4.158e+01\n",
      "Epoch 23034, Loss: 97.54676055908203, Neurons: 11, Grad norm: 3.465e+01\n",
      "Epoch 23035, Loss: 97.539794921875, Neurons: 11, Grad norm: 1.618e+01\n",
      "Epoch 23036, Loss: 97.5327377319336, Neurons: 11, Grad norm: 3.348e+00\n",
      "Epoch 23037, Loss: 97.52589416503906, Neurons: 11, Grad norm: 2.144e+01\n",
      "Epoch 23038, Loss: 97.51929473876953, Neurons: 11, Grad norm: 2.987e+01\n",
      "Epoch 23039, Loss: 97.5127182006836, Neurons: 11, Grad norm: 3.184e+01\n",
      "Epoch 23040, Loss: 97.5059814453125, Neurons: 11, Grad norm: 2.200e+01\n",
      "Epoch 23041, Loss: 97.49906921386719, Neurons: 11, Grad norm: 9.952e+00\n",
      "Epoch 23042, Loss: 97.4921646118164, Neurons: 11, Grad norm: 7.265e+00\n",
      "Epoch 23043, Loss: 97.48538208007812, Neurons: 11, Grad norm: 1.728e+01\n",
      "Epoch 23044, Loss: 97.47871398925781, Neurons: 11, Grad norm: 2.433e+01\n",
      "Epoch 23045, Loss: 97.47203826904297, Neurons: 11, Grad norm: 2.125e+01\n",
      "Epoch 23046, Loss: 97.4652328491211, Neurons: 11, Grad norm: 1.551e+01\n",
      "Epoch 23047, Loss: 97.45838165283203, Neurons: 11, Grad norm: 3.900e+00\n",
      "Epoch 23048, Loss: 97.4515380859375, Neurons: 11, Grad norm: 6.595e+00\n",
      "Epoch 23049, Loss: 97.44476318359375, Neurons: 11, Grad norm: 1.573e+01\n",
      "Epoch 23049, Test loss: 93.51720428466797\n",
      "Epoch 23050, Loss: 97.43803405761719, Neurons: 11, Grad norm: 1.738e+01\n",
      "Epoch 23051, Loss: 97.43128204345703, Neurons: 11, Grad norm: 1.708e+01\n",
      "Epoch 23052, Loss: 97.42447662353516, Neurons: 11, Grad norm: 9.582e+00\n",
      "Epoch 23053, Loss: 97.4176254272461, Neurons: 11, Grad norm: 3.491e+00\n",
      "Epoch 23054, Loss: 97.41078186035156, Neurons: 11, Grad norm: 7.145e+00\n",
      "Epoch 23055, Loss: 97.40399169921875, Neurons: 11, Grad norm: 1.100e+01\n",
      "Epoch 23056, Loss: 97.397216796875, Neurons: 11, Grad norm: 1.444e+01\n",
      "Epoch 23057, Loss: 97.39041137695312, Neurons: 11, Grad norm: 1.122e+01\n",
      "Epoch 23058, Loss: 97.38357543945312, Neurons: 11, Grad norm: 8.355e+00\n",
      "Epoch 23059, Loss: 97.3767318725586, Neurons: 11, Grad norm: 2.376e+00\n",
      "Epoch 23060, Loss: 97.36988830566406, Neurons: 11, Grad norm: 4.171e+00\n",
      "Epoch 23061, Loss: 97.3630599975586, Neurons: 11, Grad norm: 9.193e+00\n",
      "Epoch 23062, Loss: 97.35624694824219, Neurons: 11, Grad norm: 9.232e+00\n",
      "Epoch 23063, Loss: 97.34941101074219, Neurons: 11, Grad norm: 9.944e+00\n",
      "Epoch 23064, Loss: 97.34254455566406, Neurons: 11, Grad norm: 5.613e+00\n",
      "Epoch 23065, Loss: 97.33567810058594, Neurons: 11, Grad norm: 3.243e+00\n",
      "Epoch 23066, Loss: 97.32881927490234, Neurons: 11, Grad norm: 4.022e+00\n",
      "Epoch 23067, Loss: 97.32196044921875, Neurons: 11, Grad norm: 5.444e+00\n",
      "Epoch 23068, Loss: 97.31510925292969, Neurons: 11, Grad norm: 8.366e+00\n",
      "Epoch 23069, Loss: 97.30824279785156, Neurons: 11, Grad norm: 6.589e+00\n",
      "Epoch 23070, Loss: 97.30136108398438, Neurons: 11, Grad norm: 6.181e+00\n",
      "Epoch 23071, Loss: 97.29447174072266, Neurons: 11, Grad norm: 2.760e+00\n",
      "Epoch 23072, Loss: 97.2875747680664, Neurons: 11, Grad norm: 2.295e+00\n",
      "Epoch 23073, Loss: 97.28067779541016, Neurons: 11, Grad norm: 4.658e+00\n",
      "Epoch 23074, Loss: 97.27379608154297, Neurons: 11, Grad norm: 4.744e+00\n",
      "Epoch 23075, Loss: 97.26688385009766, Neurons: 11, Grad norm: 6.443e+00\n",
      "Epoch 23076, Loss: 97.2599868774414, Neurons: 11, Grad norm: 4.428e+00\n",
      "Epoch 23077, Loss: 97.2530746459961, Neurons: 11, Grad norm: 4.301e+00\n",
      "Epoch 23078, Loss: 97.24616241455078, Neurons: 11, Grad norm: 2.289e+00\n",
      "Epoch 23079, Loss: 97.23925018310547, Neurons: 11, Grad norm: 2.304e+00\n",
      "Epoch 23080, Loss: 97.23231506347656, Neurons: 11, Grad norm: 4.049e+00\n",
      "Epoch 23081, Loss: 97.22538757324219, Neurons: 11, Grad norm: 3.504e+00\n",
      "Epoch 23082, Loss: 97.21846008300781, Neurons: 11, Grad norm: 4.863e+00\n",
      "Epoch 23083, Loss: 97.21151733398438, Neurons: 11, Grad norm: 3.182e+00\n",
      "Epoch 23084, Loss: 97.2045669555664, Neurons: 11, Grad norm: 3.321e+00\n",
      "Epoch 23085, Loss: 97.19762420654297, Neurons: 11, Grad norm: 2.352e+00\n",
      "Epoch 23086, Loss: 97.19066619873047, Neurons: 11, Grad norm: 2.308e+00\n",
      "Epoch 23087, Loss: 97.18370056152344, Neurons: 11, Grad norm: 3.364e+00\n",
      "Epoch 23088, Loss: 97.1767349243164, Neurons: 11, Grad norm: 2.734e+00\n",
      "Epoch 23089, Loss: 97.16976928710938, Neurons: 11, Grad norm: 3.575e+00\n",
      "Epoch 23090, Loss: 97.16278076171875, Neurons: 11, Grad norm: 2.404e+00\n",
      "Epoch 23091, Loss: 97.15580749511719, Neurons: 11, Grad norm: 2.767e+00\n",
      "Epoch 23092, Loss: 97.14881134033203, Neurons: 11, Grad norm: 2.364e+00\n",
      "Epoch 23093, Loss: 97.14183807373047, Neurons: 11, Grad norm: 2.264e+00\n",
      "Epoch 23094, Loss: 97.13482666015625, Neurons: 11, Grad norm: 2.888e+00\n",
      "Epoch 23095, Loss: 97.12781524658203, Neurons: 11, Grad norm: 2.333e+00\n",
      "Epoch 23096, Loss: 97.12081146240234, Neurons: 11, Grad norm: 3.136e+00\n",
      "Epoch 23097, Loss: 97.11380767822266, Neurons: 11, Grad norm: 2.329e+00\n",
      "Epoch 23098, Loss: 97.10678100585938, Neurons: 11, Grad norm: 2.716e+00\n",
      "Epoch 23099, Loss: 97.09976196289062, Neurons: 11, Grad norm: 2.279e+00\n",
      "Epoch 23099, Test loss: 93.18214416503906\n",
      "Epoch 23100, Loss: 97.09274291992188, Neurons: 11, Grad norm: 2.480e+00\n",
      "Epoch 23101, Loss: 97.08570098876953, Neurons: 11, Grad norm: 2.397e+00\n",
      "Epoch 23102, Loss: 97.07867431640625, Neurons: 11, Grad norm: 2.313e+00\n",
      "Epoch 23103, Loss: 97.07161712646484, Neurons: 11, Grad norm: 2.439e+00\n",
      "Epoch 23104, Loss: 97.0645751953125, Neurons: 11, Grad norm: 2.332e+00\n",
      "Epoch 23105, Loss: 97.0575180053711, Neurons: 11, Grad norm: 2.494e+00\n",
      "Epoch 23106, Loss: 97.05046081542969, Neurons: 11, Grad norm: 2.312e+00\n",
      "Epoch 23107, Loss: 97.04339599609375, Neurons: 11, Grad norm: 2.510e+00\n",
      "Epoch 23108, Loss: 97.03632354736328, Neurons: 11, Grad norm: 2.290e+00\n",
      "Epoch 23109, Loss: 97.02924346923828, Neurons: 11, Grad norm: 2.577e+00\n",
      "Epoch 23110, Loss: 97.02217102050781, Neurons: 11, Grad norm: 2.268e+00\n",
      "Epoch 23111, Loss: 97.01507568359375, Neurons: 11, Grad norm: 2.538e+00\n",
      "Epoch 23112, Loss: 97.00799560546875, Neurons: 11, Grad norm: 2.307e+00\n",
      "Epoch 23113, Loss: 97.00088500976562, Neurons: 11, Grad norm: 2.404e+00\n",
      "Epoch 23114, Loss: 96.9937973022461, Neurons: 11, Grad norm: 2.454e+00\n",
      "Epoch 23115, Loss: 96.9866714477539, Neurons: 11, Grad norm: 2.264e+00\n",
      "Epoch 23116, Loss: 96.97957611083984, Neurons: 11, Grad norm: 2.731e+00\n",
      "Epoch 23117, Loss: 96.97245788574219, Neurons: 11, Grad norm: 2.290e+00\n",
      "Epoch 23118, Loss: 96.96532440185547, Neurons: 11, Grad norm: 2.899e+00\n",
      "Epoch 23119, Loss: 96.95821380615234, Neurons: 11, Grad norm: 2.264e+00\n",
      "Epoch 23120, Loss: 96.9510726928711, Neurons: 11, Grad norm: 2.560e+00\n",
      "Epoch 23121, Loss: 96.94393157958984, Neurons: 11, Grad norm: 2.322e+00\n",
      "Epoch 23122, Loss: 96.93678283691406, Neurons: 11, Grad norm: 2.279e+00\n",
      "Epoch 23123, Loss: 96.92961883544922, Neurons: 11, Grad norm: 2.707e+00\n",
      "Epoch 23124, Loss: 96.9224853515625, Neurons: 11, Grad norm: 2.320e+00\n",
      "Epoch 23125, Loss: 96.91532135009766, Neurons: 11, Grad norm: 3.250e+00\n",
      "Epoch 23126, Loss: 96.90815734863281, Neurons: 11, Grad norm: 2.562e+00\n",
      "Epoch 23127, Loss: 96.90098571777344, Neurons: 11, Grad norm: 3.443e+00\n",
      "Epoch 23128, Loss: 96.8938217163086, Neurons: 11, Grad norm: 2.503e+00\n",
      "Epoch 23129, Loss: 96.88665008544922, Neurons: 11, Grad norm: 3.073e+00\n",
      "Epoch 23130, Loss: 96.87944030761719, Neurons: 11, Grad norm: 2.256e+00\n",
      "Epoch 23131, Loss: 96.87226104736328, Neurons: 11, Grad norm: 2.365e+00\n",
      "Epoch 23132, Loss: 96.86506652832031, Neurons: 11, Grad norm: 2.526e+00\n",
      "Epoch 23133, Loss: 96.85785675048828, Neurons: 11, Grad norm: 2.272e+00\n",
      "Epoch 23134, Loss: 96.85064697265625, Neurons: 11, Grad norm: 3.124e+00\n",
      "Epoch 23135, Loss: 96.84344482421875, Neurons: 11, Grad norm: 2.526e+00\n",
      "Epoch 23136, Loss: 96.83621978759766, Neurons: 11, Grad norm: 3.601e+00\n",
      "Epoch 23137, Loss: 96.82901000976562, Neurons: 11, Grad norm: 2.816e+00\n",
      "Epoch 23138, Loss: 96.82177734375, Neurons: 11, Grad norm: 3.771e+00\n",
      "Epoch 23139, Loss: 96.81454467773438, Neurons: 11, Grad norm: 2.710e+00\n",
      "Epoch 23140, Loss: 96.80729675292969, Neurons: 11, Grad norm: 3.501e+00\n",
      "Epoch 23141, Loss: 96.80005645751953, Neurons: 11, Grad norm: 2.437e+00\n",
      "Epoch 23142, Loss: 96.79281616210938, Neurons: 11, Grad norm: 2.958e+00\n",
      "Epoch 23143, Loss: 96.78555297851562, Neurons: 11, Grad norm: 2.253e+00\n",
      "Epoch 23144, Loss: 96.77828216552734, Neurons: 11, Grad norm: 2.528e+00\n",
      "Epoch 23145, Loss: 96.77103424072266, Neurons: 11, Grad norm: 2.312e+00\n",
      "Epoch 23146, Loss: 96.76376342773438, Neurons: 11, Grad norm: 2.281e+00\n",
      "Epoch 23147, Loss: 96.75648498535156, Neurons: 11, Grad norm: 2.614e+00\n",
      "Epoch 23148, Loss: 96.74919891357422, Neurons: 11, Grad norm: 2.277e+00\n",
      "Epoch 23149, Loss: 96.74191284179688, Neurons: 11, Grad norm: 3.017e+00\n",
      "Epoch 23149, Test loss: 92.83659362792969\n",
      "Epoch 23150, Loss: 96.73463439941406, Neurons: 11, Grad norm: 2.366e+00\n",
      "Epoch 23151, Loss: 96.72732543945312, Neurons: 11, Grad norm: 3.155e+00\n",
      "Epoch 23152, Loss: 96.72002410888672, Neurons: 11, Grad norm: 2.383e+00\n",
      "Epoch 23153, Loss: 96.71271514892578, Neurons: 11, Grad norm: 2.854e+00\n",
      "Epoch 23154, Loss: 96.70540618896484, Neurons: 11, Grad norm: 2.244e+00\n",
      "Epoch 23155, Loss: 96.69808197021484, Neurons: 11, Grad norm: 2.613e+00\n",
      "Epoch 23156, Loss: 96.69076538085938, Neurons: 11, Grad norm: 2.272e+00\n",
      "Epoch 23157, Loss: 96.68343353271484, Neurons: 11, Grad norm: 2.255e+00\n",
      "Epoch 23158, Loss: 96.67609405517578, Neurons: 11, Grad norm: 2.481e+00\n",
      "Epoch 23159, Loss: 96.66876220703125, Neurons: 11, Grad norm: 2.249e+00\n",
      "Epoch 23160, Loss: 96.66140747070312, Neurons: 11, Grad norm: 2.829e+00\n",
      "Epoch 23161, Loss: 96.65406799316406, Neurons: 11, Grad norm: 2.341e+00\n",
      "Epoch 23162, Loss: 96.64669799804688, Neurons: 11, Grad norm: 3.106e+00\n",
      "Epoch 23163, Loss: 96.63933563232422, Neurons: 11, Grad norm: 2.560e+00\n",
      "Epoch 23164, Loss: 96.63198852539062, Neurons: 11, Grad norm: 3.849e+00\n",
      "Epoch 23165, Loss: 96.62459564208984, Neurons: 11, Grad norm: 3.124e+00\n",
      "Epoch 23166, Loss: 96.61722564697266, Neurons: 11, Grad norm: 4.408e+00\n",
      "Epoch 23167, Loss: 96.6098403930664, Neurons: 11, Grad norm: 3.804e+00\n",
      "Epoch 23168, Loss: 96.60245513916016, Neurons: 11, Grad norm: 5.528e+00\n",
      "Epoch 23169, Loss: 96.5950698852539, Neurons: 11, Grad norm: 4.698e+00\n",
      "Epoch 23170, Loss: 96.58765411376953, Neurons: 11, Grad norm: 6.303e+00\n",
      "Epoch 23171, Loss: 96.58026123046875, Neurons: 11, Grad norm: 5.965e+00\n",
      "Epoch 23172, Loss: 96.57284545898438, Neurons: 11, Grad norm: 8.081e+00\n",
      "Epoch 23173, Loss: 96.56544494628906, Neurons: 11, Grad norm: 7.823e+00\n",
      "Epoch 23174, Loss: 96.55803680419922, Neurons: 11, Grad norm: 1.047e+01\n",
      "Epoch 23175, Loss: 96.55061340332031, Neurons: 11, Grad norm: 1.113e+01\n",
      "Epoch 23176, Loss: 96.54320526123047, Neurons: 11, Grad norm: 1.445e+01\n",
      "Epoch 23177, Loss: 96.53577423095703, Neurons: 11, Grad norm: 1.559e+01\n",
      "Epoch 23178, Loss: 96.52836608886719, Neurons: 11, Grad norm: 2.010e+01\n",
      "Epoch 23179, Loss: 96.5209732055664, Neurons: 11, Grad norm: 2.272e+01\n",
      "Epoch 23180, Loss: 96.51356506347656, Neurons: 11, Grad norm: 2.832e+01\n",
      "Epoch 23181, Loss: 96.50619506835938, Neurons: 11, Grad norm: 3.223e+01\n",
      "Epoch 23182, Loss: 96.49884796142578, Neurons: 11, Grad norm: 3.989e+01\n",
      "Epoch 23183, Loss: 96.49156188964844, Neurons: 11, Grad norm: 4.574e+01\n",
      "Epoch 23184, Loss: 96.48431396484375, Neurons: 11, Grad norm: 5.426e+01\n",
      "Epoch 23185, Loss: 96.47713470458984, Neurons: 11, Grad norm: 6.022e+01\n",
      "Epoch 23186, Loss: 96.46996307373047, Neurons: 11, Grad norm: 6.768e+01\n",
      "Epoch 23187, Loss: 96.46283721923828, Neurons: 11, Grad norm: 6.940e+01\n",
      "Epoch 23188, Loss: 96.45555114746094, Neurons: 11, Grad norm: 6.896e+01\n",
      "Epoch 23189, Loss: 96.44813537597656, Neurons: 11, Grad norm: 6.029e+01\n",
      "Epoch 23190, Loss: 96.44046020507812, Neurons: 11, Grad norm: 4.811e+01\n",
      "Epoch 23191, Loss: 96.43264770507812, Neurons: 11, Grad norm: 2.835e+01\n",
      "Epoch 23192, Loss: 96.42481994628906, Neurons: 11, Grad norm: 9.429e+00\n",
      "Epoch 23193, Loss: 96.41726684570312, Neurons: 11, Grad norm: 1.164e+01\n",
      "Epoch 23194, Loss: 96.40995025634766, Neurons: 11, Grad norm: 2.627e+01\n",
      "Epoch 23195, Loss: 96.4028091430664, Neurons: 11, Grad norm: 3.830e+01\n",
      "Epoch 23196, Loss: 96.39571380615234, Neurons: 11, Grad norm: 4.143e+01\n",
      "Epoch 23197, Loss: 96.38848876953125, Neurons: 11, Grad norm: 4.057e+01\n",
      "Epoch 23198, Loss: 96.38111877441406, Neurons: 11, Grad norm: 3.165e+01\n",
      "Epoch 23199, Loss: 96.37358856201172, Neurons: 11, Grad norm: 2.101e+01\n",
      "Epoch 23199, Test loss: 92.48192596435547\n",
      "Epoch 23200, Loss: 96.36607360839844, Neurons: 11, Grad norm: 5.948e+00\n",
      "Epoch 23201, Loss: 96.35861206054688, Neurons: 11, Grad norm: 7.273e+00\n",
      "Epoch 23202, Loss: 96.35128784179688, Neurons: 11, Grad norm: 1.934e+01\n",
      "Epoch 23203, Loss: 96.34405517578125, Neurons: 11, Grad norm: 2.530e+01\n",
      "Epoch 23204, Loss: 96.33679962158203, Neurons: 11, Grad norm: 2.902e+01\n",
      "Epoch 23205, Loss: 96.32950592041016, Neurons: 11, Grad norm: 2.540e+01\n",
      "Epoch 23206, Loss: 96.32211303710938, Neurons: 11, Grad norm: 2.035e+01\n",
      "Epoch 23207, Loss: 96.31468200683594, Neurons: 11, Grad norm: 1.071e+01\n",
      "Epoch 23208, Loss: 96.30724334716797, Neurons: 11, Grad norm: 3.073e+00\n",
      "Epoch 23209, Loss: 96.29984283447266, Neurons: 11, Grad norm: 8.310e+00\n",
      "Epoch 23210, Loss: 96.29251098632812, Neurons: 11, Grad norm: 1.381e+01\n",
      "Epoch 23211, Loss: 96.28519439697266, Neurons: 11, Grad norm: 1.896e+01\n",
      "Epoch 23212, Loss: 96.27787017822266, Neurons: 11, Grad norm: 1.868e+01\n",
      "Epoch 23213, Loss: 96.2705078125, Neurons: 11, Grad norm: 1.780e+01\n",
      "Epoch 23214, Loss: 96.26310729980469, Neurons: 11, Grad norm: 1.203e+01\n",
      "Epoch 23215, Loss: 96.25568389892578, Neurons: 11, Grad norm: 7.416e+00\n",
      "Epoch 23216, Loss: 96.24827575683594, Neurons: 11, Grad norm: 2.184e+00\n",
      "Epoch 23217, Loss: 96.24085998535156, Neurons: 11, Grad norm: 5.575e+00\n",
      "Epoch 23218, Loss: 96.23348236083984, Neurons: 11, Grad norm: 1.106e+01\n",
      "Epoch 23219, Loss: 96.22611236572266, Neurons: 11, Grad norm: 1.252e+01\n",
      "Epoch 23220, Loss: 96.2187271118164, Neurons: 11, Grad norm: 1.438e+01\n",
      "Epoch 23221, Loss: 96.21131896972656, Neurons: 11, Grad norm: 1.210e+01\n",
      "Epoch 23222, Loss: 96.20391082763672, Neurons: 11, Grad norm: 1.066e+01\n",
      "Epoch 23223, Loss: 96.19647216796875, Neurons: 11, Grad norm: 6.099e+00\n",
      "Epoch 23224, Loss: 96.18902587890625, Neurons: 11, Grad norm: 3.661e+00\n",
      "Epoch 23225, Loss: 96.18160247802734, Neurons: 11, Grad norm: 3.047e+00\n",
      "Epoch 23226, Loss: 96.17416381835938, Neurons: 11, Grad norm: 4.949e+00\n",
      "Epoch 23227, Loss: 96.16673278808594, Neurons: 11, Grad norm: 8.559e+00\n",
      "Epoch 23228, Loss: 96.15929412841797, Neurons: 11, Grad norm: 8.901e+00\n",
      "Epoch 23229, Loss: 96.15186309814453, Neurons: 11, Grad norm: 1.046e+01\n",
      "Epoch 23230, Loss: 96.14442443847656, Neurons: 11, Grad norm: 8.750e+00\n",
      "Epoch 23231, Loss: 96.136962890625, Neurons: 11, Grad norm: 8.357e+00\n",
      "Epoch 23232, Loss: 96.12950134277344, Neurons: 11, Grad norm: 5.263e+00\n",
      "Epoch 23233, Loss: 96.12200927734375, Neurons: 11, Grad norm: 4.100e+00\n",
      "Epoch 23234, Loss: 96.11453247070312, Neurons: 11, Grad norm: 2.158e+00\n",
      "Epoch 23235, Loss: 96.10704803466797, Neurons: 11, Grad norm: 2.735e+00\n",
      "Epoch 23236, Loss: 96.09957122802734, Neurons: 11, Grad norm: 5.383e+00\n",
      "Epoch 23237, Loss: 96.09208679199219, Neurons: 11, Grad norm: 5.595e+00\n",
      "Epoch 23238, Loss: 96.08460998535156, Neurons: 11, Grad norm: 7.454e+00\n",
      "Epoch 23239, Loss: 96.07711791992188, Neurons: 11, Grad norm: 6.452e+00\n",
      "Epoch 23240, Loss: 96.0696029663086, Neurons: 11, Grad norm: 7.033e+00\n",
      "Epoch 23241, Loss: 96.0621109008789, Neurons: 11, Grad norm: 5.101e+00\n",
      "Epoch 23242, Loss: 96.05458068847656, Neurons: 11, Grad norm: 4.965e+00\n",
      "Epoch 23243, Loss: 96.04705810546875, Neurons: 11, Grad norm: 2.845e+00\n",
      "Epoch 23244, Loss: 96.03953552246094, Neurons: 11, Grad norm: 2.545e+00\n",
      "Epoch 23245, Loss: 96.03199768066406, Neurons: 11, Grad norm: 2.462e+00\n",
      "Epoch 23246, Loss: 96.02445983886719, Neurons: 11, Grad norm: 2.491e+00\n",
      "Epoch 23247, Loss: 96.01692199707031, Neurons: 11, Grad norm: 3.970e+00\n",
      "Epoch 23248, Loss: 96.0093765258789, Neurons: 11, Grad norm: 3.476e+00\n",
      "Epoch 23249, Loss: 96.00183868408203, Neurons: 11, Grad norm: 4.421e+00\n",
      "Epoch 23249, Test loss: 92.12122344970703\n",
      "Epoch 23250, Loss: 95.99429321289062, Neurons: 11, Grad norm: 3.294e+00\n",
      "Epoch 23251, Loss: 95.98672485351562, Neurons: 11, Grad norm: 3.903e+00\n",
      "Epoch 23252, Loss: 95.9791488647461, Neurons: 11, Grad norm: 2.652e+00\n",
      "Epoch 23253, Loss: 95.97158813476562, Neurons: 11, Grad norm: 2.893e+00\n",
      "Epoch 23254, Loss: 95.9640121459961, Neurons: 11, Grad norm: 2.125e+00\n",
      "Epoch 23255, Loss: 95.95643615722656, Neurons: 11, Grad norm: 2.191e+00\n",
      "Epoch 23256, Loss: 95.94884490966797, Neurons: 11, Grad norm: 2.387e+00\n",
      "Epoch 23257, Loss: 95.94123840332031, Neurons: 11, Grad norm: 2.180e+00\n",
      "Epoch 23258, Loss: 95.93364715576172, Neurons: 11, Grad norm: 3.040e+00\n",
      "Epoch 23259, Loss: 95.92604064941406, Neurons: 11, Grad norm: 2.633e+00\n",
      "Epoch 23260, Loss: 95.91842651367188, Neurons: 11, Grad norm: 3.783e+00\n",
      "Epoch 23261, Loss: 95.91082000732422, Neurons: 11, Grad norm: 3.130e+00\n",
      "Epoch 23262, Loss: 95.90320587158203, Neurons: 11, Grad norm: 4.101e+00\n",
      "Epoch 23263, Loss: 95.89558410644531, Neurons: 11, Grad norm: 3.159e+00\n",
      "Epoch 23264, Loss: 95.88793182373047, Neurons: 11, Grad norm: 3.838e+00\n",
      "Epoch 23265, Loss: 95.88031005859375, Neurons: 11, Grad norm: 2.733e+00\n",
      "Epoch 23266, Loss: 95.87267303466797, Neurons: 11, Grad norm: 3.123e+00\n",
      "Epoch 23267, Loss: 95.86502838134766, Neurons: 11, Grad norm: 2.272e+00\n",
      "Epoch 23268, Loss: 95.85738372802734, Neurons: 11, Grad norm: 2.493e+00\n",
      "Epoch 23269, Loss: 95.8497085571289, Neurons: 11, Grad norm: 2.151e+00\n",
      "Epoch 23270, Loss: 95.84204864501953, Neurons: 11, Grad norm: 2.142e+00\n",
      "Epoch 23271, Loss: 95.83438873291016, Neurons: 11, Grad norm: 2.314e+00\n",
      "Epoch 23272, Loss: 95.82671356201172, Neurons: 11, Grad norm: 2.122e+00\n",
      "Epoch 23273, Loss: 95.81903839111328, Neurons: 11, Grad norm: 2.585e+00\n",
      "Epoch 23274, Loss: 95.81133270263672, Neurons: 11, Grad norm: 2.154e+00\n",
      "Epoch 23275, Loss: 95.80365753173828, Neurons: 11, Grad norm: 2.700e+00\n",
      "Epoch 23276, Loss: 95.79595947265625, Neurons: 11, Grad norm: 2.204e+00\n",
      "Epoch 23277, Loss: 95.78826904296875, Neurons: 11, Grad norm: 2.637e+00\n",
      "Epoch 23278, Loss: 95.78056335449219, Neurons: 11, Grad norm: 2.170e+00\n",
      "Epoch 23279, Loss: 95.7728500366211, Neurons: 11, Grad norm: 2.713e+00\n",
      "Epoch 23280, Loss: 95.76512145996094, Neurons: 11, Grad norm: 2.181e+00\n",
      "Epoch 23281, Loss: 95.75741577148438, Neurons: 11, Grad norm: 2.689e+00\n",
      "Epoch 23282, Loss: 95.74968719482422, Neurons: 11, Grad norm: 2.172e+00\n",
      "Epoch 23283, Loss: 95.74195098876953, Neurons: 11, Grad norm: 2.543e+00\n",
      "Epoch 23284, Loss: 95.73420715332031, Neurons: 11, Grad norm: 2.091e+00\n",
      "Epoch 23285, Loss: 95.72647094726562, Neurons: 11, Grad norm: 2.427e+00\n",
      "Epoch 23286, Loss: 95.71871948242188, Neurons: 11, Grad norm: 2.082e+00\n",
      "Epoch 23287, Loss: 95.71097564697266, Neurons: 11, Grad norm: 2.398e+00\n",
      "Epoch 23288, Loss: 95.70320129394531, Neurons: 11, Grad norm: 2.132e+00\n",
      "Epoch 23289, Loss: 95.69544982910156, Neurons: 11, Grad norm: 2.700e+00\n",
      "Epoch 23290, Loss: 95.68767547607422, Neurons: 11, Grad norm: 2.324e+00\n",
      "Epoch 23291, Loss: 95.6799087524414, Neurons: 11, Grad norm: 3.356e+00\n",
      "Epoch 23292, Loss: 95.672119140625, Neurons: 11, Grad norm: 2.879e+00\n",
      "Epoch 23293, Loss: 95.66433715820312, Neurons: 11, Grad norm: 3.886e+00\n",
      "Epoch 23294, Loss: 95.65654754638672, Neurons: 11, Grad norm: 3.413e+00\n",
      "Epoch 23295, Loss: 95.64875030517578, Neurons: 11, Grad norm: 4.656e+00\n",
      "Epoch 23296, Loss: 95.64096069335938, Neurons: 11, Grad norm: 4.139e+00\n",
      "Epoch 23297, Loss: 95.63314056396484, Neurons: 11, Grad norm: 5.626e+00\n",
      "Epoch 23298, Loss: 95.62533569335938, Neurons: 11, Grad norm: 5.503e+00\n",
      "Epoch 23299, Loss: 95.61752319335938, Neurons: 11, Grad norm: 7.489e+00\n",
      "Epoch 23299, Test loss: 91.75225067138672\n",
      "Epoch 23300, Loss: 95.60969543457031, Neurons: 11, Grad norm: 8.062e+00\n",
      "Epoch 23301, Loss: 95.60188293457031, Neurons: 11, Grad norm: 1.109e+01\n",
      "Epoch 23302, Loss: 95.59406280517578, Neurons: 11, Grad norm: 1.272e+01\n",
      "Epoch 23303, Loss: 95.58623504638672, Neurons: 11, Grad norm: 1.701e+01\n",
      "Epoch 23304, Loss: 95.57843780517578, Neurons: 11, Grad norm: 2.035e+01\n",
      "Epoch 23305, Loss: 95.57063293457031, Neurons: 11, Grad norm: 2.684e+01\n",
      "Epoch 23306, Loss: 95.5628662109375, Neurons: 11, Grad norm: 3.277e+01\n",
      "Epoch 23307, Loss: 95.55516052246094, Neurons: 11, Grad norm: 4.257e+01\n",
      "Epoch 23308, Loss: 95.54752349853516, Neurons: 11, Grad norm: 5.246e+01\n",
      "Epoch 23309, Loss: 95.54000854492188, Neurons: 11, Grad norm: 6.611e+01\n",
      "Epoch 23310, Loss: 95.53266143798828, Neurons: 11, Grad norm: 7.879e+01\n",
      "Epoch 23311, Loss: 95.52547454833984, Neurons: 11, Grad norm: 9.245e+01\n",
      "Epoch 23312, Loss: 95.51838684082031, Neurons: 11, Grad norm: 9.906e+01\n",
      "Epoch 23313, Loss: 95.51112365722656, Neurons: 11, Grad norm: 9.785e+01\n",
      "Epoch 23314, Loss: 95.5032958984375, Neurons: 11, Grad norm: 8.075e+01\n",
      "Epoch 23315, Loss: 95.4947280883789, Neurons: 11, Grad norm: 5.263e+01\n",
      "Epoch 23316, Loss: 95.4858627319336, Neurons: 11, Grad norm: 1.449e+01\n",
      "Epoch 23317, Loss: 95.47746276855469, Neurons: 11, Grad norm: 2.142e+01\n",
      "Epoch 23318, Loss: 95.4699478149414, Neurons: 11, Grad norm: 5.051e+01\n",
      "Epoch 23319, Loss: 95.46298217773438, Neurons: 11, Grad norm: 6.377e+01\n",
      "Epoch 23320, Loss: 95.4559097290039, Neurons: 11, Grad norm: 6.271e+01\n",
      "Epoch 23321, Loss: 95.44823455810547, Neurons: 11, Grad norm: 4.397e+01\n",
      "Epoch 23322, Loss: 95.44005584716797, Neurons: 11, Grad norm: 1.729e+01\n",
      "Epoch 23323, Loss: 95.43197631835938, Neurons: 11, Grad norm: 1.317e+01\n",
      "Epoch 23324, Loss: 95.42436981201172, Neurons: 11, Grad norm: 3.528e+01\n",
      "Epoch 23325, Loss: 95.41716003417969, Neurons: 11, Grad norm: 4.747e+01\n",
      "Epoch 23326, Loss: 95.40988159179688, Neurons: 11, Grad norm: 4.344e+01\n",
      "Epoch 23327, Loss: 95.40222930908203, Neurons: 11, Grad norm: 2.926e+01\n",
      "Epoch 23328, Loss: 95.39432525634766, Neurons: 11, Grad norm: 6.797e+00\n",
      "Epoch 23329, Loss: 95.38652038574219, Neurons: 11, Grad norm: 1.436e+01\n",
      "Epoch 23330, Loss: 95.37901306152344, Neurons: 11, Grad norm: 3.062e+01\n",
      "Epoch 23331, Loss: 95.37167358398438, Neurons: 11, Grad norm: 3.476e+01\n",
      "Epoch 23332, Loss: 95.36421966552734, Neurons: 11, Grad norm: 3.031e+01\n",
      "Epoch 23333, Loss: 95.3565444946289, Neurons: 11, Grad norm: 1.607e+01\n",
      "Epoch 23334, Loss: 95.34878540039062, Neurons: 11, Grad norm: 1.981e+00\n",
      "Epoch 23335, Loss: 95.34113311767578, Neurons: 11, Grad norm: 1.627e+01\n",
      "Epoch 23336, Loss: 95.33364868164062, Neurons: 11, Grad norm: 2.426e+01\n",
      "Epoch 23337, Loss: 95.32618713378906, Neurons: 11, Grad norm: 2.648e+01\n",
      "Epoch 23338, Loss: 95.31863403320312, Neurons: 11, Grad norm: 1.944e+01\n",
      "Epoch 23339, Loss: 95.31095123291016, Neurons: 11, Grad norm: 9.008e+00\n",
      "Epoch 23340, Loss: 95.30326843261719, Neurons: 11, Grad norm: 5.230e+00\n",
      "Epoch 23341, Loss: 95.29566955566406, Neurons: 11, Grad norm: 1.425e+01\n",
      "Epoch 23342, Loss: 95.28814697265625, Neurons: 11, Grad norm: 2.037e+01\n",
      "Epoch 23343, Loss: 95.28060150146484, Neurons: 11, Grad norm: 1.860e+01\n",
      "Epoch 23344, Loss: 95.27299499511719, Neurons: 11, Grad norm: 1.335e+01\n",
      "Epoch 23345, Loss: 95.26535034179688, Neurons: 11, Grad norm: 3.701e+00\n",
      "Epoch 23346, Loss: 95.25768280029297, Neurons: 11, Grad norm: 5.547e+00\n",
      "Epoch 23347, Loss: 95.25007629394531, Neurons: 11, Grad norm: 1.321e+01\n",
      "Epoch 23348, Loss: 95.24250793457031, Neurons: 11, Grad norm: 1.511e+01\n",
      "Epoch 23349, Loss: 95.23490905761719, Neurons: 11, Grad norm: 1.434e+01\n",
      "Epoch 23349, Test loss: 91.3826904296875\n",
      "Epoch 23350, Loss: 95.22727966308594, Neurons: 11, Grad norm: 8.453e+00\n",
      "Epoch 23351, Loss: 95.21961975097656, Neurons: 11, Grad norm: 3.026e+00\n",
      "Epoch 23352, Loss: 95.21197509765625, Neurons: 11, Grad norm: 5.502e+00\n",
      "Epoch 23353, Loss: 95.20433807373047, Neurons: 11, Grad norm: 8.950e+00\n",
      "Epoch 23354, Loss: 95.19670104980469, Neurons: 11, Grad norm: 1.140e+01\n",
      "Epoch 23355, Loss: 95.18907928466797, Neurons: 11, Grad norm: 9.398e+00\n",
      "Epoch 23356, Loss: 95.1814193725586, Neurons: 11, Grad norm: 6.802e+00\n",
      "Epoch 23357, Loss: 95.17374420166016, Neurons: 11, Grad norm: 2.100e+00\n",
      "Epoch 23358, Loss: 95.16609191894531, Neurons: 11, Grad norm: 3.374e+00\n",
      "Epoch 23359, Loss: 95.1584243774414, Neurons: 11, Grad norm: 7.175e+00\n",
      "Epoch 23360, Loss: 95.15076446533203, Neurons: 11, Grad norm: 7.906e+00\n",
      "Epoch 23361, Loss: 95.14311218261719, Neurons: 11, Grad norm: 8.191e+00\n",
      "Epoch 23362, Loss: 95.13542175292969, Neurons: 11, Grad norm: 4.995e+00\n",
      "Epoch 23363, Loss: 95.12773132324219, Neurons: 11, Grad norm: 2.934e+00\n",
      "Epoch 23364, Loss: 95.12003326416016, Neurons: 11, Grad norm: 2.684e+00\n",
      "Epoch 23365, Loss: 95.11235046386719, Neurons: 11, Grad norm: 4.259e+00\n",
      "Epoch 23366, Loss: 95.10465240478516, Neurons: 11, Grad norm: 6.500e+00\n",
      "Epoch 23367, Loss: 95.09696960449219, Neurons: 11, Grad norm: 5.538e+00\n",
      "Epoch 23368, Loss: 95.08924865722656, Neurons: 11, Grad norm: 5.173e+00\n",
      "Epoch 23369, Loss: 95.08155059814453, Neurons: 11, Grad norm: 2.715e+00\n",
      "Epoch 23370, Loss: 95.07383728027344, Neurons: 11, Grad norm: 1.943e+00\n",
      "Epoch 23371, Loss: 95.06608581542969, Neurons: 11, Grad norm: 3.589e+00\n",
      "Epoch 23372, Loss: 95.0583724975586, Neurons: 11, Grad norm: 4.135e+00\n",
      "Epoch 23373, Loss: 95.05064392089844, Neurons: 11, Grad norm: 5.387e+00\n",
      "Epoch 23374, Loss: 95.04292297363281, Neurons: 11, Grad norm: 4.307e+00\n",
      "Epoch 23375, Loss: 95.03518676757812, Neurons: 11, Grad norm: 3.985e+00\n",
      "Epoch 23376, Loss: 95.02742767333984, Neurons: 11, Grad norm: 2.055e+00\n",
      "Epoch 23377, Loss: 95.0196762084961, Neurons: 11, Grad norm: 1.964e+00\n",
      "Epoch 23378, Loss: 95.01192474365234, Neurons: 11, Grad norm: 3.501e+00\n",
      "Epoch 23379, Loss: 95.00418090820312, Neurons: 11, Grad norm: 3.711e+00\n",
      "Epoch 23380, Loss: 94.99640655517578, Neurons: 11, Grad norm: 4.739e+00\n",
      "Epoch 23381, Loss: 94.98863983154297, Neurons: 11, Grad norm: 3.421e+00\n",
      "Epoch 23382, Loss: 94.98086547851562, Neurons: 11, Grad norm: 2.948e+00\n",
      "Epoch 23383, Loss: 94.97308349609375, Neurons: 11, Grad norm: 1.908e+00\n",
      "Epoch 23384, Loss: 94.9653091430664, Neurons: 11, Grad norm: 2.183e+00\n",
      "Epoch 23385, Loss: 94.95751190185547, Neurons: 11, Grad norm: 3.702e+00\n",
      "Epoch 23386, Loss: 94.94972229003906, Neurons: 11, Grad norm: 3.386e+00\n",
      "Epoch 23387, Loss: 94.94192504882812, Neurons: 11, Grad norm: 3.787e+00\n",
      "Epoch 23388, Loss: 94.93412017822266, Neurons: 11, Grad norm: 2.593e+00\n",
      "Epoch 23389, Loss: 94.92630767822266, Neurons: 11, Grad norm: 2.641e+00\n",
      "Epoch 23390, Loss: 94.91851043701172, Neurons: 11, Grad norm: 1.895e+00\n",
      "Epoch 23391, Loss: 94.91068267822266, Neurons: 11, Grad norm: 1.892e+00\n",
      "Epoch 23392, Loss: 94.90286254882812, Neurons: 11, Grad norm: 2.359e+00\n",
      "Epoch 23393, Loss: 94.8950424194336, Neurons: 11, Grad norm: 2.137e+00\n",
      "Epoch 23394, Loss: 94.88720703125, Neurons: 11, Grad norm: 2.839e+00\n",
      "Epoch 23395, Loss: 94.87936401367188, Neurons: 11, Grad norm: 2.359e+00\n",
      "Epoch 23396, Loss: 94.87152862548828, Neurons: 11, Grad norm: 2.622e+00\n",
      "Epoch 23397, Loss: 94.86367797851562, Neurons: 11, Grad norm: 1.951e+00\n",
      "Epoch 23398, Loss: 94.8558349609375, Neurons: 11, Grad norm: 2.044e+00\n",
      "Epoch 23399, Loss: 94.84798431396484, Neurons: 11, Grad norm: 1.947e+00\n",
      "Epoch 23399, Test loss: 91.00940704345703\n",
      "Epoch 23400, Loss: 94.84011840820312, Neurons: 11, Grad norm: 1.879e+00\n",
      "Epoch 23401, Loss: 94.83226013183594, Neurons: 11, Grad norm: 2.192e+00\n",
      "Epoch 23402, Loss: 94.82437896728516, Neurons: 11, Grad norm: 1.911e+00\n",
      "Epoch 23403, Loss: 94.8165054321289, Neurons: 11, Grad norm: 2.244e+00\n",
      "Epoch 23404, Loss: 94.8086166381836, Neurons: 11, Grad norm: 1.893e+00\n",
      "Epoch 23405, Loss: 94.80074310302734, Neurons: 11, Grad norm: 1.999e+00\n",
      "Epoch 23406, Loss: 94.79286193847656, Neurons: 11, Grad norm: 1.881e+00\n",
      "Epoch 23407, Loss: 94.78495788574219, Neurons: 11, Grad norm: 1.896e+00\n",
      "Epoch 23408, Loss: 94.77706146240234, Neurons: 11, Grad norm: 1.977e+00\n",
      "Epoch 23409, Loss: 94.76915740966797, Neurons: 11, Grad norm: 1.862e+00\n",
      "Epoch 23410, Loss: 94.76123809814453, Neurons: 11, Grad norm: 2.033e+00\n",
      "Epoch 23411, Loss: 94.75332641601562, Neurons: 11, Grad norm: 1.858e+00\n",
      "Epoch 23412, Loss: 94.74540710449219, Neurons: 11, Grad norm: 2.069e+00\n",
      "Epoch 23413, Loss: 94.73748779296875, Neurons: 11, Grad norm: 1.867e+00\n",
      "Epoch 23414, Loss: 94.72956085205078, Neurons: 11, Grad norm: 1.883e+00\n",
      "Epoch 23415, Loss: 94.72162628173828, Neurons: 11, Grad norm: 1.968e+00\n",
      "Epoch 23416, Loss: 94.71369934082031, Neurons: 11, Grad norm: 1.879e+00\n",
      "Epoch 23417, Loss: 94.70574188232422, Neurons: 11, Grad norm: 2.253e+00\n",
      "Epoch 23418, Loss: 94.69780731201172, Neurons: 11, Grad norm: 1.948e+00\n",
      "Epoch 23419, Loss: 94.68983459472656, Neurons: 11, Grad norm: 2.297e+00\n",
      "Epoch 23420, Loss: 94.681884765625, Neurons: 11, Grad norm: 1.936e+00\n",
      "Epoch 23421, Loss: 94.6739273071289, Neurons: 11, Grad norm: 2.048e+00\n",
      "Epoch 23422, Loss: 94.66594696044922, Neurons: 11, Grad norm: 1.865e+00\n",
      "Epoch 23423, Loss: 94.6579818725586, Neurons: 11, Grad norm: 1.889e+00\n",
      "Epoch 23424, Loss: 94.65000915527344, Neurons: 11, Grad norm: 2.000e+00\n",
      "Epoch 23425, Loss: 94.64201354980469, Neurons: 11, Grad norm: 1.870e+00\n",
      "Epoch 23426, Loss: 94.63404846191406, Neurons: 11, Grad norm: 2.137e+00\n",
      "Epoch 23427, Loss: 94.62603759765625, Neurons: 11, Grad norm: 1.938e+00\n",
      "Epoch 23428, Loss: 94.61804962158203, Neurons: 11, Grad norm: 2.494e+00\n",
      "Epoch 23429, Loss: 94.61004638671875, Neurons: 11, Grad norm: 2.091e+00\n",
      "Epoch 23430, Loss: 94.60203552246094, Neurons: 11, Grad norm: 2.528e+00\n",
      "Epoch 23431, Loss: 94.5940170288086, Neurons: 11, Grad norm: 2.258e+00\n",
      "Epoch 23432, Loss: 94.58601379394531, Neurons: 11, Grad norm: 2.802e+00\n",
      "Epoch 23433, Loss: 94.57798767089844, Neurons: 11, Grad norm: 2.267e+00\n",
      "Epoch 23434, Loss: 94.5699691772461, Neurons: 11, Grad norm: 2.787e+00\n",
      "Epoch 23435, Loss: 94.56193542480469, Neurons: 11, Grad norm: 2.274e+00\n",
      "Epoch 23436, Loss: 94.55389404296875, Neurons: 11, Grad norm: 2.506e+00\n",
      "Epoch 23437, Loss: 94.54586029052734, Neurons: 11, Grad norm: 1.936e+00\n",
      "Epoch 23438, Loss: 94.53780364990234, Neurons: 11, Grad norm: 2.169e+00\n",
      "Epoch 23439, Loss: 94.5297622680664, Neurons: 11, Grad norm: 1.817e+00\n",
      "Epoch 23440, Loss: 94.5217056274414, Neurons: 11, Grad norm: 1.880e+00\n",
      "Epoch 23441, Loss: 94.5136489868164, Neurons: 11, Grad norm: 1.845e+00\n",
      "Epoch 23442, Loss: 94.50556945800781, Neurons: 11, Grad norm: 1.835e+00\n",
      "Epoch 23443, Loss: 94.49751281738281, Neurons: 11, Grad norm: 1.971e+00\n",
      "Epoch 23444, Loss: 94.48942565917969, Neurons: 11, Grad norm: 1.841e+00\n",
      "Epoch 23445, Loss: 94.4813461303711, Neurons: 11, Grad norm: 2.117e+00\n",
      "Epoch 23446, Loss: 94.4732666015625, Neurons: 11, Grad norm: 1.910e+00\n",
      "Epoch 23447, Loss: 94.4651870727539, Neurons: 11, Grad norm: 2.416e+00\n",
      "Epoch 23448, Loss: 94.45708465576172, Neurons: 11, Grad norm: 2.106e+00\n",
      "Epoch 23449, Loss: 94.44898223876953, Neurons: 11, Grad norm: 2.758e+00\n",
      "Epoch 23449, Test loss: 90.62657928466797\n",
      "Epoch 23450, Loss: 94.44087982177734, Neurons: 11, Grad norm: 2.516e+00\n",
      "Epoch 23451, Loss: 94.43276977539062, Neurons: 11, Grad norm: 3.017e+00\n",
      "Epoch 23452, Loss: 94.4246597290039, Neurons: 11, Grad norm: 2.468e+00\n",
      "Epoch 23453, Loss: 94.41653442382812, Neurons: 11, Grad norm: 3.002e+00\n",
      "Epoch 23454, Loss: 94.4084243774414, Neurons: 11, Grad norm: 2.481e+00\n",
      "Epoch 23455, Loss: 94.4002914428711, Neurons: 11, Grad norm: 2.899e+00\n",
      "Epoch 23456, Loss: 94.39215087890625, Neurons: 11, Grad norm: 2.439e+00\n",
      "Epoch 23457, Loss: 94.38401794433594, Neurons: 11, Grad norm: 2.948e+00\n",
      "Epoch 23458, Loss: 94.37586975097656, Neurons: 11, Grad norm: 2.333e+00\n",
      "Epoch 23459, Loss: 94.36772918701172, Neurons: 11, Grad norm: 2.868e+00\n",
      "Epoch 23460, Loss: 94.35958099365234, Neurons: 11, Grad norm: 2.511e+00\n",
      "Epoch 23461, Loss: 94.35142517089844, Neurons: 11, Grad norm: 3.036e+00\n",
      "Epoch 23462, Loss: 94.34326934814453, Neurons: 11, Grad norm: 2.714e+00\n",
      "Epoch 23463, Loss: 94.3350830078125, Neurons: 11, Grad norm: 3.588e+00\n",
      "Epoch 23464, Loss: 94.3269271850586, Neurons: 11, Grad norm: 3.377e+00\n",
      "Epoch 23465, Loss: 94.31873321533203, Neurons: 11, Grad norm: 4.224e+00\n",
      "Epoch 23466, Loss: 94.3105697631836, Neurons: 11, Grad norm: 4.115e+00\n",
      "Epoch 23467, Loss: 94.30238342285156, Neurons: 11, Grad norm: 5.188e+00\n",
      "Epoch 23468, Loss: 94.29419708251953, Neurons: 11, Grad norm: 5.104e+00\n",
      "Epoch 23469, Loss: 94.28599548339844, Neurons: 11, Grad norm: 6.564e+00\n",
      "Epoch 23470, Loss: 94.2778091430664, Neurons: 11, Grad norm: 7.018e+00\n",
      "Epoch 23471, Loss: 94.26960754394531, Neurons: 11, Grad norm: 8.768e+00\n",
      "Epoch 23472, Loss: 94.26140594482422, Neurons: 11, Grad norm: 9.395e+00\n",
      "Epoch 23473, Loss: 94.2531967163086, Neurons: 11, Grad norm: 1.157e+01\n",
      "Epoch 23474, Loss: 94.2449951171875, Neurons: 11, Grad norm: 1.293e+01\n",
      "Epoch 23475, Loss: 94.23678588867188, Neurons: 11, Grad norm: 1.610e+01\n",
      "Epoch 23476, Loss: 94.22856903076172, Neurons: 11, Grad norm: 1.858e+01\n",
      "Epoch 23477, Loss: 94.22037506103516, Neurons: 11, Grad norm: 2.312e+01\n",
      "Epoch 23478, Loss: 94.21220397949219, Neurons: 11, Grad norm: 2.756e+01\n",
      "Epoch 23479, Loss: 94.20405578613281, Neurons: 11, Grad norm: 3.438e+01\n",
      "Epoch 23480, Loss: 94.1959228515625, Neurons: 11, Grad norm: 4.133e+01\n",
      "Epoch 23481, Loss: 94.18785858154297, Neurons: 11, Grad norm: 5.113e+01\n",
      "Epoch 23482, Loss: 94.17990112304688, Neurons: 11, Grad norm: 6.078e+01\n",
      "Epoch 23483, Loss: 94.1720199584961, Neurons: 11, Grad norm: 7.206e+01\n",
      "Epoch 23484, Loss: 94.16425323486328, Neurons: 11, Grad norm: 8.104e+01\n",
      "Epoch 23485, Loss: 94.1565170288086, Neurons: 11, Grad norm: 8.804e+01\n",
      "Epoch 23486, Loss: 94.14871215820312, Neurons: 11, Grad norm: 8.696e+01\n",
      "Epoch 23487, Loss: 94.14059448242188, Neurons: 11, Grad norm: 7.822e+01\n",
      "Epoch 23488, Loss: 94.1320571899414, Neurons: 11, Grad norm: 5.853e+01\n",
      "Epoch 23489, Loss: 94.12323760986328, Neurons: 11, Grad norm: 3.280e+01\n",
      "Epoch 23490, Loss: 94.11449432373047, Neurons: 11, Grad norm: 3.369e+00\n",
      "Epoch 23491, Loss: 94.10617065429688, Neurons: 11, Grad norm: 2.325e+01\n",
      "Epoch 23492, Loss: 94.09832000732422, Neurons: 11, Grad norm: 4.398e+01\n",
      "Epoch 23493, Loss: 94.0906982421875, Neurons: 11, Grad norm: 5.407e+01\n",
      "Epoch 23494, Loss: 94.08300018310547, Neurons: 11, Grad norm: 5.439e+01\n",
      "Epoch 23495, Loss: 94.07498931884766, Neurons: 11, Grad norm: 4.313e+01\n",
      "Epoch 23496, Loss: 94.0666732788086, Neurons: 11, Grad norm: 2.565e+01\n",
      "Epoch 23497, Loss: 94.05831909179688, Neurons: 11, Grad norm: 3.813e+00\n",
      "Epoch 23498, Loss: 94.0501480102539, Neurons: 11, Grad norm: 1.629e+01\n",
      "Epoch 23499, Loss: 94.042236328125, Neurons: 11, Grad norm: 3.156e+01\n",
      "Epoch 23499, Test loss: 90.2376480102539\n",
      "Epoch 23500, Loss: 94.03445434570312, Neurons: 11, Grad norm: 3.810e+01\n",
      "Epoch 23501, Loss: 94.026611328125, Neurons: 11, Grad norm: 3.740e+01\n",
      "Epoch 23502, Loss: 94.01859283447266, Neurons: 11, Grad norm: 2.796e+01\n",
      "Epoch 23503, Loss: 94.01042938232422, Neurons: 11, Grad norm: 1.479e+01\n",
      "Epoch 23504, Loss: 94.00226593017578, Neurons: 11, Grad norm: 2.171e+00\n",
      "Epoch 23505, Loss: 93.99420928955078, Neurons: 11, Grad norm: 1.458e+01\n",
      "Epoch 23506, Loss: 93.98628234863281, Neurons: 11, Grad norm: 2.438e+01\n",
      "Epoch 23507, Loss: 93.97838592529297, Neurons: 11, Grad norm: 2.696e+01\n",
      "Epoch 23508, Loss: 93.97045135498047, Neurons: 11, Grad norm: 2.500e+01\n",
      "Epoch 23509, Loss: 93.96239471435547, Neurons: 11, Grad norm: 1.716e+01\n",
      "Epoch 23510, Loss: 93.95430755615234, Neurons: 11, Grad norm: 7.626e+00\n",
      "Epoch 23511, Loss: 93.94623565673828, Neurons: 11, Grad norm: 4.101e+00\n",
      "Epoch 23512, Loss: 93.93822479248047, Neurons: 11, Grad norm: 1.189e+01\n",
      "Epoch 23513, Loss: 93.93024444580078, Neurons: 11, Grad norm: 1.769e+01\n",
      "Epoch 23514, Loss: 93.92227935791016, Neurons: 11, Grad norm: 1.861e+01\n",
      "Epoch 23515, Loss: 93.91427612304688, Neurons: 11, Grad norm: 1.663e+01\n",
      "Epoch 23516, Loss: 93.9062271118164, Neurons: 11, Grad norm: 1.047e+01\n",
      "Epoch 23517, Loss: 93.8981704711914, Neurons: 11, Grad norm: 4.334e+00\n",
      "Epoch 23518, Loss: 93.8901138305664, Neurons: 11, Grad norm: 3.778e+00\n",
      "Epoch 23519, Loss: 93.882080078125, Neurons: 11, Grad norm: 8.713e+00\n",
      "Epoch 23520, Loss: 93.87406921386719, Neurons: 11, Grad norm: 1.274e+01\n",
      "Epoch 23521, Loss: 93.86605072021484, Neurons: 11, Grad norm: 1.291e+01\n",
      "Epoch 23522, Loss: 93.85802459716797, Neurons: 11, Grad norm: 1.197e+01\n",
      "Epoch 23523, Loss: 93.8499526977539, Neurons: 11, Grad norm: 8.084e+00\n",
      "Epoch 23524, Loss: 93.8418960571289, Neurons: 11, Grad norm: 4.078e+00\n",
      "Epoch 23525, Loss: 93.83382415771484, Neurons: 11, Grad norm: 2.313e+00\n",
      "Epoch 23526, Loss: 93.82575988769531, Neurons: 11, Grad norm: 5.225e+00\n",
      "Epoch 23527, Loss: 93.81770324707031, Neurons: 11, Grad norm: 8.634e+00\n",
      "Epoch 23528, Loss: 93.80966186523438, Neurons: 11, Grad norm: 9.454e+00\n",
      "Epoch 23529, Loss: 93.80158996582031, Neurons: 11, Grad norm: 9.353e+00\n",
      "Epoch 23530, Loss: 93.79351043701172, Neurons: 11, Grad norm: 6.907e+00\n",
      "Epoch 23531, Loss: 93.78543090820312, Neurons: 11, Grad norm: 4.842e+00\n",
      "Epoch 23532, Loss: 93.77733612060547, Neurons: 11, Grad norm: 1.761e+00\n",
      "Epoch 23533, Loss: 93.76924896240234, Neurons: 11, Grad norm: 2.943e+00\n",
      "Epoch 23534, Loss: 93.76115417480469, Neurons: 11, Grad norm: 5.630e+00\n",
      "Epoch 23535, Loss: 93.75308227539062, Neurons: 11, Grad norm: 6.482e+00\n",
      "Epoch 23536, Loss: 93.74497985839844, Neurons: 11, Grad norm: 7.443e+00\n",
      "Epoch 23537, Loss: 93.73686981201172, Neurons: 11, Grad norm: 6.085e+00\n",
      "Epoch 23538, Loss: 93.72874450683594, Neurons: 11, Grad norm: 4.914e+00\n",
      "Epoch 23539, Loss: 93.72064971923828, Neurons: 11, Grad norm: 2.745e+00\n",
      "Epoch 23540, Loss: 93.7125244140625, Neurons: 11, Grad norm: 1.773e+00\n",
      "Epoch 23541, Loss: 93.70439910888672, Neurons: 11, Grad norm: 2.694e+00\n",
      "Epoch 23542, Loss: 93.69627380371094, Neurons: 11, Grad norm: 3.434e+00\n",
      "Epoch 23543, Loss: 93.68814849853516, Neurons: 11, Grad norm: 4.573e+00\n",
      "Epoch 23544, Loss: 93.6800308227539, Neurons: 11, Grad norm: 4.542e+00\n",
      "Epoch 23545, Loss: 93.6718978881836, Neurons: 11, Grad norm: 4.855e+00\n",
      "Epoch 23546, Loss: 93.66373443603516, Neurons: 11, Grad norm: 3.421e+00\n",
      "Epoch 23547, Loss: 93.65560150146484, Neurons: 11, Grad norm: 2.973e+00\n",
      "Epoch 23548, Loss: 93.6474380493164, Neurons: 11, Grad norm: 1.902e+00\n",
      "Epoch 23549, Loss: 93.6392822265625, Neurons: 11, Grad norm: 1.669e+00\n",
      "Epoch 23549, Test loss: 89.8476791381836\n",
      "Epoch 23550, Loss: 93.63113403320312, Neurons: 11, Grad norm: 2.394e+00\n",
      "Epoch 23551, Loss: 93.62296295166016, Neurons: 11, Grad norm: 2.349e+00\n",
      "Epoch 23552, Loss: 93.61480712890625, Neurons: 11, Grad norm: 3.152e+00\n",
      "Epoch 23553, Loss: 93.60662841796875, Neurons: 11, Grad norm: 3.002e+00\n",
      "Epoch 23554, Loss: 93.59845733642578, Neurons: 11, Grad norm: 3.176e+00\n",
      "Epoch 23555, Loss: 93.59027099609375, Neurons: 11, Grad norm: 2.570e+00\n",
      "Epoch 23556, Loss: 93.58208465576172, Neurons: 11, Grad norm: 2.812e+00\n",
      "Epoch 23557, Loss: 93.57390594482422, Neurons: 11, Grad norm: 2.017e+00\n",
      "Epoch 23558, Loss: 93.5656967163086, Neurons: 11, Grad norm: 1.861e+00\n",
      "Epoch 23559, Loss: 93.5575180053711, Neurons: 11, Grad norm: 1.641e+00\n",
      "Epoch 23560, Loss: 93.54930877685547, Neurons: 11, Grad norm: 1.670e+00\n",
      "Epoch 23561, Loss: 93.54110717773438, Neurons: 11, Grad norm: 2.303e+00\n",
      "Epoch 23562, Loss: 93.53289794921875, Neurons: 11, Grad norm: 2.311e+00\n",
      "Epoch 23563, Loss: 93.5246810913086, Neurons: 11, Grad norm: 2.940e+00\n",
      "Epoch 23564, Loss: 93.5164566040039, Neurons: 11, Grad norm: 2.876e+00\n",
      "Epoch 23565, Loss: 93.50823211669922, Neurons: 11, Grad norm: 3.390e+00\n",
      "Epoch 23566, Loss: 93.5000228881836, Neurons: 11, Grad norm: 2.711e+00\n",
      "Epoch 23567, Loss: 93.49177551269531, Neurons: 11, Grad norm: 2.770e+00\n",
      "Epoch 23568, Loss: 93.4835433959961, Neurons: 11, Grad norm: 2.235e+00\n",
      "Epoch 23569, Loss: 93.47528839111328, Neurons: 11, Grad norm: 2.232e+00\n",
      "Epoch 23570, Loss: 93.4670639038086, Neurons: 11, Grad norm: 1.750e+00\n",
      "Epoch 23571, Loss: 93.45880126953125, Neurons: 11, Grad norm: 1.840e+00\n",
      "Epoch 23572, Loss: 93.4505386352539, Neurons: 11, Grad norm: 1.654e+00\n",
      "Epoch 23573, Loss: 93.4422836303711, Neurons: 11, Grad norm: 1.684e+00\n",
      "Epoch 23574, Loss: 93.43402099609375, Neurons: 11, Grad norm: 1.720e+00\n",
      "Epoch 23575, Loss: 93.42575073242188, Neurons: 11, Grad norm: 1.655e+00\n",
      "Epoch 23576, Loss: 93.41748809814453, Neurons: 11, Grad norm: 1.835e+00\n",
      "Epoch 23577, Loss: 93.40921020507812, Neurons: 11, Grad norm: 1.753e+00\n",
      "Epoch 23578, Loss: 93.40092468261719, Neurons: 11, Grad norm: 2.112e+00\n",
      "Epoch 23579, Loss: 93.39264678955078, Neurons: 11, Grad norm: 1.892e+00\n",
      "Epoch 23580, Loss: 93.38436126708984, Neurons: 11, Grad norm: 2.200e+00\n",
      "Epoch 23581, Loss: 93.37606048583984, Neurons: 11, Grad norm: 2.002e+00\n",
      "Epoch 23582, Loss: 93.3677749633789, Neurons: 11, Grad norm: 2.239e+00\n",
      "Epoch 23583, Loss: 93.3594741821289, Neurons: 11, Grad norm: 1.843e+00\n",
      "Epoch 23584, Loss: 93.35115814208984, Neurons: 11, Grad norm: 2.082e+00\n",
      "Epoch 23585, Loss: 93.34284210205078, Neurons: 11, Grad norm: 1.850e+00\n",
      "Epoch 23586, Loss: 93.33452606201172, Neurons: 11, Grad norm: 2.049e+00\n",
      "Epoch 23587, Loss: 93.32621002197266, Neurons: 11, Grad norm: 1.879e+00\n",
      "Epoch 23588, Loss: 93.3178939819336, Neurons: 11, Grad norm: 2.269e+00\n",
      "Epoch 23589, Loss: 93.3095703125, Neurons: 11, Grad norm: 1.959e+00\n",
      "Epoch 23590, Loss: 93.30123138427734, Neurons: 11, Grad norm: 2.068e+00\n",
      "Epoch 23591, Loss: 93.29290008544922, Neurons: 11, Grad norm: 1.831e+00\n",
      "Epoch 23592, Loss: 93.28456115722656, Neurons: 11, Grad norm: 2.070e+00\n",
      "Epoch 23593, Loss: 93.27620697021484, Neurons: 11, Grad norm: 1.761e+00\n",
      "Epoch 23594, Loss: 93.26786041259766, Neurons: 11, Grad norm: 2.010e+00\n",
      "Epoch 23595, Loss: 93.25951385498047, Neurons: 11, Grad norm: 1.872e+00\n",
      "Epoch 23596, Loss: 93.25115966796875, Neurons: 11, Grad norm: 2.098e+00\n",
      "Epoch 23597, Loss: 93.2427978515625, Neurons: 11, Grad norm: 1.870e+00\n",
      "Epoch 23598, Loss: 93.23442077636719, Neurons: 11, Grad norm: 2.191e+00\n",
      "Epoch 23599, Loss: 93.2260513305664, Neurons: 11, Grad norm: 1.973e+00\n",
      "Epoch 23599, Test loss: 89.452392578125\n",
      "Epoch 23600, Loss: 93.2176742553711, Neurons: 11, Grad norm: 2.238e+00\n",
      "Epoch 23601, Loss: 93.20929718017578, Neurons: 11, Grad norm: 2.077e+00\n",
      "Epoch 23602, Loss: 93.200927734375, Neurons: 11, Grad norm: 2.383e+00\n",
      "Epoch 23603, Loss: 93.19253540039062, Neurons: 11, Grad norm: 2.076e+00\n",
      "Epoch 23604, Loss: 93.18414306640625, Neurons: 11, Grad norm: 2.449e+00\n",
      "Epoch 23605, Loss: 93.17574310302734, Neurons: 11, Grad norm: 2.222e+00\n",
      "Epoch 23606, Loss: 93.16735076904297, Neurons: 11, Grad norm: 2.618e+00\n",
      "Epoch 23607, Loss: 93.15895080566406, Neurons: 11, Grad norm: 2.511e+00\n",
      "Epoch 23608, Loss: 93.15052032470703, Neurons: 11, Grad norm: 3.315e+00\n",
      "Epoch 23609, Loss: 93.14212036132812, Neurons: 11, Grad norm: 3.338e+00\n",
      "Epoch 23610, Loss: 93.13370513916016, Neurons: 11, Grad norm: 4.242e+00\n",
      "Epoch 23611, Loss: 93.12527465820312, Neurons: 11, Grad norm: 4.837e+00\n",
      "Epoch 23612, Loss: 93.11685943603516, Neurons: 11, Grad norm: 6.184e+00\n",
      "Epoch 23613, Loss: 93.10842895507812, Neurons: 11, Grad norm: 6.942e+00\n",
      "Epoch 23614, Loss: 93.0999984741211, Neurons: 11, Grad norm: 9.066e+00\n",
      "Epoch 23615, Loss: 93.0915756225586, Neurons: 11, Grad norm: 1.083e+01\n",
      "Epoch 23616, Loss: 93.08313751220703, Neurons: 11, Grad norm: 1.384e+01\n",
      "Epoch 23617, Loss: 93.07470703125, Neurons: 11, Grad norm: 1.702e+01\n",
      "Epoch 23618, Loss: 93.06629943847656, Neurons: 11, Grad norm: 2.215e+01\n",
      "Epoch 23619, Loss: 93.0578842163086, Neurons: 11, Grad norm: 2.744e+01\n",
      "Epoch 23620, Loss: 93.04952239990234, Neurons: 11, Grad norm: 3.495e+01\n",
      "Epoch 23621, Loss: 93.04119873046875, Neurons: 11, Grad norm: 4.355e+01\n",
      "Epoch 23622, Loss: 93.0329360961914, Neurons: 11, Grad norm: 5.453e+01\n",
      "Epoch 23623, Loss: 93.02479553222656, Neurons: 11, Grad norm: 6.622e+01\n",
      "Epoch 23624, Loss: 93.01678466796875, Neurons: 11, Grad norm: 7.988e+01\n",
      "Epoch 23625, Loss: 93.00894165039062, Neurons: 11, Grad norm: 9.211e+01\n",
      "Epoch 23626, Loss: 93.00118255615234, Neurons: 11, Grad norm: 1.012e+02\n",
      "Epoch 23627, Loss: 92.99333953857422, Neurons: 11, Grad norm: 1.014e+02\n",
      "Epoch 23628, Loss: 92.98509979248047, Neurons: 11, Grad norm: 9.079e+01\n",
      "Epoch 23629, Loss: 92.97625732421875, Neurons: 11, Grad norm: 6.574e+01\n",
      "Epoch 23630, Loss: 92.96698760986328, Neurons: 11, Grad norm: 3.212e+01\n",
      "Epoch 23631, Loss: 92.95787048339844, Neurons: 11, Grad norm: 5.307e+00\n",
      "Epoch 23632, Loss: 92.94943237304688, Neurons: 11, Grad norm: 3.676e+01\n",
      "Epoch 23633, Loss: 92.94165802001953, Neurons: 11, Grad norm: 5.882e+01\n",
      "Epoch 23634, Loss: 92.93408203125, Neurons: 11, Grad norm: 6.568e+01\n",
      "Epoch 23635, Loss: 92.92620086669922, Neurons: 11, Grad norm: 5.838e+01\n",
      "Epoch 23636, Loss: 92.9178237915039, Neurons: 11, Grad norm: 3.785e+01\n",
      "Epoch 23637, Loss: 92.90913391113281, Neurons: 11, Grad norm: 1.100e+01\n",
      "Epoch 23638, Loss: 92.9006576538086, Neurons: 11, Grad norm: 1.658e+01\n",
      "Epoch 23639, Loss: 92.8926010131836, Neurons: 11, Grad norm: 3.646e+01\n",
      "Epoch 23640, Loss: 92.88479614257812, Neurons: 11, Grad norm: 4.625e+01\n",
      "Epoch 23641, Loss: 92.87690734863281, Neurons: 11, Grad norm: 4.297e+01\n",
      "Epoch 23642, Loss: 92.86872863769531, Neurons: 11, Grad norm: 2.988e+01\n",
      "Epoch 23643, Loss: 92.86036682128906, Neurons: 11, Grad norm: 9.882e+00\n",
      "Epoch 23644, Loss: 92.85205078125, Neurons: 11, Grad norm: 1.042e+01\n",
      "Epoch 23645, Loss: 92.84396362304688, Neurons: 11, Grad norm: 2.650e+01\n",
      "Epoch 23646, Loss: 92.83601379394531, Neurons: 11, Grad norm: 3.369e+01\n",
      "Epoch 23647, Loss: 92.82806396484375, Neurons: 11, Grad norm: 3.248e+01\n",
      "Epoch 23648, Loss: 92.81993865966797, Neurons: 11, Grad norm: 2.245e+01\n",
      "Epoch 23649, Loss: 92.81169128417969, Neurons: 11, Grad norm: 8.229e+00\n",
      "Epoch 23649, Test loss: 89.05400848388672\n",
      "Epoch 23650, Loss: 92.80347442626953, Neurons: 11, Grad norm: 7.547e+00\n",
      "Epoch 23651, Loss: 92.79535675048828, Neurons: 11, Grad norm: 1.870e+01\n",
      "Epoch 23652, Loss: 92.78736114501953, Neurons: 11, Grad norm: 2.497e+01\n",
      "Epoch 23653, Loss: 92.7793197631836, Neurons: 11, Grad norm: 2.383e+01\n",
      "Epoch 23654, Loss: 92.77119445800781, Neurons: 11, Grad norm: 1.740e+01\n",
      "Epoch 23655, Loss: 92.76302337646484, Neurons: 11, Grad norm: 6.898e+00\n",
      "Epoch 23656, Loss: 92.75483703613281, Neurons: 11, Grad norm: 4.119e+00\n",
      "Epoch 23657, Loss: 92.74671936035156, Neurons: 11, Grad norm: 1.325e+01\n",
      "Epoch 23658, Loss: 92.73863983154297, Neurons: 11, Grad norm: 1.784e+01\n",
      "Epoch 23659, Loss: 92.73056030273438, Neurons: 11, Grad norm: 1.829e+01\n",
      "Epoch 23660, Loss: 92.72245025634766, Neurons: 11, Grad norm: 1.396e+01\n",
      "Epoch 23661, Loss: 92.71428680419922, Neurons: 11, Grad norm: 7.704e+00\n",
      "Epoch 23662, Loss: 92.70612335205078, Neurons: 11, Grad norm: 1.831e+00\n",
      "Epoch 23663, Loss: 92.6979751586914, Neurons: 11, Grad norm: 7.973e+00\n",
      "Epoch 23664, Loss: 92.68987274169922, Neurons: 11, Grad norm: 1.271e+01\n",
      "Epoch 23665, Loss: 92.68175506591797, Neurons: 11, Grad norm: 1.365e+01\n",
      "Epoch 23666, Loss: 92.67362976074219, Neurons: 11, Grad norm: 1.213e+01\n",
      "Epoch 23667, Loss: 92.66548156738281, Neurons: 11, Grad norm: 7.166e+00\n",
      "Epoch 23668, Loss: 92.65730285644531, Neurons: 11, Grad norm: 2.114e+00\n",
      "Epoch 23669, Loss: 92.64913177490234, Neurons: 11, Grad norm: 4.500e+00\n",
      "Epoch 23670, Loss: 92.64098358154297, Neurons: 11, Grad norm: 8.129e+00\n",
      "Epoch 23671, Loss: 92.63284301757812, Neurons: 11, Grad norm: 1.049e+01\n",
      "Epoch 23672, Loss: 92.62470245361328, Neurons: 11, Grad norm: 9.665e+00\n",
      "Epoch 23673, Loss: 92.61653137207031, Neurons: 11, Grad norm: 7.537e+00\n",
      "Epoch 23674, Loss: 92.60836029052734, Neurons: 11, Grad norm: 3.723e+00\n",
      "Epoch 23675, Loss: 92.60017395019531, Neurons: 11, Grad norm: 1.560e+00\n",
      "Epoch 23676, Loss: 92.59199523925781, Neurons: 11, Grad norm: 4.277e+00\n",
      "Epoch 23677, Loss: 92.58383178710938, Neurons: 11, Grad norm: 6.096e+00\n",
      "Epoch 23678, Loss: 92.5756607055664, Neurons: 11, Grad norm: 7.111e+00\n",
      "Epoch 23679, Loss: 92.56746673583984, Neurons: 11, Grad norm: 6.165e+00\n",
      "Epoch 23680, Loss: 92.55928039550781, Neurons: 11, Grad norm: 4.682e+00\n",
      "Epoch 23681, Loss: 92.55106353759766, Neurons: 11, Grad norm: 2.048e+00\n",
      "Epoch 23682, Loss: 92.5428695678711, Neurons: 11, Grad norm: 1.874e+00\n",
      "Epoch 23683, Loss: 92.53468322753906, Neurons: 11, Grad norm: 3.898e+00\n",
      "Epoch 23684, Loss: 92.52648162841797, Neurons: 11, Grad norm: 5.027e+00\n",
      "Epoch 23685, Loss: 92.5182876586914, Neurons: 11, Grad norm: 5.816e+00\n",
      "Epoch 23686, Loss: 92.51007080078125, Neurons: 11, Grad norm: 4.921e+00\n",
      "Epoch 23687, Loss: 92.5018539428711, Neurons: 11, Grad norm: 3.947e+00\n",
      "Epoch 23688, Loss: 92.49363708496094, Neurons: 11, Grad norm: 2.191e+00\n",
      "Epoch 23689, Loss: 92.48539733886719, Neurons: 11, Grad norm: 1.533e+00\n",
      "Epoch 23690, Loss: 92.4771728515625, Neurons: 11, Grad norm: 2.740e+00\n",
      "Epoch 23691, Loss: 92.46894836425781, Neurons: 11, Grad norm: 3.591e+00\n",
      "Epoch 23692, Loss: 92.46072387695312, Neurons: 11, Grad norm: 4.397e+00\n",
      "Epoch 23693, Loss: 92.45246887207031, Neurons: 11, Grad norm: 4.053e+00\n",
      "Epoch 23694, Loss: 92.44422149658203, Neurons: 11, Grad norm: 3.555e+00\n",
      "Epoch 23695, Loss: 92.43598175048828, Neurons: 11, Grad norm: 2.142e+00\n",
      "Epoch 23696, Loss: 92.427734375, Neurons: 11, Grad norm: 1.539e+00\n",
      "Epoch 23697, Loss: 92.41948699951172, Neurons: 11, Grad norm: 2.021e+00\n",
      "Epoch 23698, Loss: 92.41122436523438, Neurons: 11, Grad norm: 2.596e+00\n",
      "Epoch 23699, Loss: 92.40296936035156, Neurons: 11, Grad norm: 3.463e+00\n",
      "Epoch 23699, Test loss: 88.66361236572266\n",
      "Epoch 23700, Loss: 92.39469909667969, Neurons: 11, Grad norm: 3.370e+00\n",
      "Epoch 23701, Loss: 92.38642120361328, Neurons: 11, Grad norm: 3.535e+00\n",
      "Epoch 23702, Loss: 92.37815856933594, Neurons: 11, Grad norm: 2.991e+00\n",
      "Epoch 23703, Loss: 92.36988830566406, Neurons: 11, Grad norm: 2.585e+00\n",
      "Epoch 23704, Loss: 92.36161041259766, Neurons: 11, Grad norm: 1.744e+00\n",
      "Epoch 23705, Loss: 92.35331726074219, Neurons: 11, Grad norm: 1.577e+00\n",
      "Epoch 23706, Loss: 92.34502410888672, Neurons: 11, Grad norm: 1.660e+00\n",
      "Epoch 23707, Loss: 92.33673858642578, Neurons: 11, Grad norm: 1.941e+00\n",
      "Epoch 23708, Loss: 92.32843780517578, Neurons: 11, Grad norm: 2.484e+00\n",
      "Epoch 23709, Loss: 92.32014465332031, Neurons: 11, Grad norm: 2.509e+00\n",
      "Epoch 23710, Loss: 92.31184387207031, Neurons: 11, Grad norm: 3.022e+00\n",
      "Epoch 23711, Loss: 92.30355072021484, Neurons: 11, Grad norm: 2.778e+00\n",
      "Epoch 23712, Loss: 92.29522705078125, Neurons: 11, Grad norm: 2.837e+00\n",
      "Epoch 23713, Loss: 92.28692626953125, Neurons: 11, Grad norm: 2.508e+00\n",
      "Epoch 23714, Loss: 92.27859497070312, Neurons: 11, Grad norm: 2.465e+00\n",
      "Epoch 23715, Loss: 92.27027130126953, Neurons: 11, Grad norm: 1.843e+00\n",
      "Epoch 23716, Loss: 92.261962890625, Neurons: 11, Grad norm: 1.716e+00\n",
      "Epoch 23717, Loss: 92.25362396240234, Neurons: 11, Grad norm: 1.521e+00\n",
      "Epoch 23718, Loss: 92.24528503417969, Neurons: 11, Grad norm: 1.596e+00\n",
      "Epoch 23719, Loss: 92.23694610595703, Neurons: 11, Grad norm: 1.889e+00\n",
      "Epoch 23720, Loss: 92.22859954833984, Neurons: 11, Grad norm: 1.826e+00\n",
      "Epoch 23721, Loss: 92.22026062011719, Neurons: 11, Grad norm: 2.117e+00\n",
      "Epoch 23722, Loss: 92.21192169189453, Neurons: 11, Grad norm: 2.004e+00\n",
      "Epoch 23723, Loss: 92.20355987548828, Neurons: 11, Grad norm: 2.225e+00\n",
      "Epoch 23724, Loss: 92.1952133178711, Neurons: 11, Grad norm: 2.113e+00\n",
      "Epoch 23725, Loss: 92.18684387207031, Neurons: 11, Grad norm: 2.393e+00\n",
      "Epoch 23726, Loss: 92.17848205566406, Neurons: 11, Grad norm: 2.123e+00\n",
      "Epoch 23727, Loss: 92.17012023925781, Neurons: 11, Grad norm: 2.146e+00\n",
      "Epoch 23728, Loss: 92.16175079345703, Neurons: 11, Grad norm: 1.839e+00\n",
      "Epoch 23729, Loss: 92.15337371826172, Neurons: 11, Grad norm: 1.773e+00\n",
      "Epoch 23730, Loss: 92.1449966430664, Neurons: 11, Grad norm: 1.512e+00\n",
      "Epoch 23731, Loss: 92.13660430908203, Neurons: 11, Grad norm: 1.500e+00\n",
      "Epoch 23732, Loss: 92.12821960449219, Neurons: 11, Grad norm: 1.556e+00\n",
      "Epoch 23733, Loss: 92.11981964111328, Neurons: 11, Grad norm: 1.552e+00\n",
      "Epoch 23734, Loss: 92.11143493652344, Neurons: 11, Grad norm: 1.749e+00\n",
      "Epoch 23735, Loss: 92.10302734375, Neurons: 11, Grad norm: 1.661e+00\n",
      "Epoch 23736, Loss: 92.09461975097656, Neurons: 11, Grad norm: 1.782e+00\n",
      "Epoch 23737, Loss: 92.08621978759766, Neurons: 11, Grad norm: 1.659e+00\n",
      "Epoch 23738, Loss: 92.07781219482422, Neurons: 11, Grad norm: 1.748e+00\n",
      "Epoch 23739, Loss: 92.06939697265625, Neurons: 11, Grad norm: 1.613e+00\n",
      "Epoch 23740, Loss: 92.06098175048828, Neurons: 11, Grad norm: 1.803e+00\n",
      "Epoch 23741, Loss: 92.05257415771484, Neurons: 11, Grad norm: 1.740e+00\n",
      "Epoch 23742, Loss: 92.04415130615234, Neurons: 11, Grad norm: 1.836e+00\n",
      "Epoch 23743, Loss: 92.03571319580078, Neurons: 11, Grad norm: 1.660e+00\n",
      "Epoch 23744, Loss: 92.02728271484375, Neurons: 11, Grad norm: 1.679e+00\n",
      "Epoch 23745, Loss: 92.01884460449219, Neurons: 11, Grad norm: 1.531e+00\n",
      "Epoch 23746, Loss: 92.01040649414062, Neurons: 11, Grad norm: 1.535e+00\n",
      "Epoch 23747, Loss: 92.0019760131836, Neurons: 11, Grad norm: 1.548e+00\n",
      "Epoch 23748, Loss: 91.99352264404297, Neurons: 11, Grad norm: 1.519e+00\n",
      "Epoch 23749, Loss: 91.98506927490234, Neurons: 11, Grad norm: 1.583e+00\n",
      "Epoch 23749, Test loss: 88.2637710571289\n",
      "Epoch 23750, Loss: 91.97662353515625, Neurons: 11, Grad norm: 1.546e+00\n",
      "Epoch 23751, Loss: 91.96814727783203, Neurons: 11, Grad norm: 1.670e+00\n",
      "Epoch 23752, Loss: 91.9596939086914, Neurons: 11, Grad norm: 1.612e+00\n",
      "Epoch 23753, Loss: 91.95122528076172, Neurons: 11, Grad norm: 1.893e+00\n",
      "Epoch 23754, Loss: 91.94274139404297, Neurons: 11, Grad norm: 2.030e+00\n",
      "Epoch 23755, Loss: 91.93425750732422, Neurons: 11, Grad norm: 2.442e+00\n",
      "Epoch 23756, Loss: 91.92579650878906, Neurons: 11, Grad norm: 2.505e+00\n",
      "Epoch 23757, Loss: 91.91732025146484, Neurons: 11, Grad norm: 3.081e+00\n",
      "Epoch 23758, Loss: 91.90882110595703, Neurons: 11, Grad norm: 3.371e+00\n",
      "Epoch 23759, Loss: 91.90032958984375, Neurons: 11, Grad norm: 4.046e+00\n",
      "Epoch 23760, Loss: 91.89185333251953, Neurons: 11, Grad norm: 4.376e+00\n",
      "Epoch 23761, Loss: 91.88334655761719, Neurons: 11, Grad norm: 5.184e+00\n",
      "Epoch 23762, Loss: 91.87483978271484, Neurons: 11, Grad norm: 5.506e+00\n",
      "Epoch 23763, Loss: 91.8663558959961, Neurons: 11, Grad norm: 6.289e+00\n",
      "Epoch 23764, Loss: 91.85783386230469, Neurons: 11, Grad norm: 6.869e+00\n",
      "Epoch 23765, Loss: 91.84934997558594, Neurons: 11, Grad norm: 7.954e+00\n",
      "Epoch 23766, Loss: 91.8408203125, Neurons: 11, Grad norm: 8.762e+00\n",
      "Epoch 23767, Loss: 91.83231353759766, Neurons: 11, Grad norm: 1.038e+01\n",
      "Epoch 23768, Loss: 91.82379913330078, Neurons: 11, Grad norm: 1.191e+01\n",
      "Epoch 23769, Loss: 91.8152847290039, Neurons: 11, Grad norm: 1.416e+01\n",
      "Epoch 23770, Loss: 91.80677032470703, Neurons: 11, Grad norm: 1.657e+01\n",
      "Epoch 23771, Loss: 91.79826354980469, Neurons: 11, Grad norm: 2.014e+01\n",
      "Epoch 23772, Loss: 91.7897720336914, Neurons: 11, Grad norm: 2.407e+01\n",
      "Epoch 23773, Loss: 91.78128051757812, Neurons: 11, Grad norm: 2.936e+01\n",
      "Epoch 23774, Loss: 91.77281951904297, Neurons: 11, Grad norm: 3.536e+01\n",
      "Epoch 23775, Loss: 91.76439666748047, Neurons: 11, Grad norm: 4.301e+01\n",
      "Epoch 23776, Loss: 91.75603485107422, Neurons: 11, Grad norm: 5.149e+01\n",
      "Epoch 23777, Loss: 91.74772644042969, Neurons: 11, Grad norm: 6.167e+01\n",
      "Epoch 23778, Loss: 91.7395248413086, Neurons: 11, Grad norm: 7.187e+01\n",
      "Epoch 23779, Loss: 91.73140716552734, Neurons: 11, Grad norm: 8.195e+01\n",
      "Epoch 23780, Loss: 91.72335052490234, Neurons: 11, Grad norm: 8.873e+01\n",
      "Epoch 23781, Loss: 91.71525573730469, Neurons: 11, Grad norm: 9.062e+01\n",
      "Epoch 23782, Loss: 91.70694732666016, Neurons: 11, Grad norm: 8.394e+01\n",
      "Epoch 23783, Loss: 91.69828796386719, Neurons: 11, Grad norm: 6.868e+01\n",
      "Epoch 23784, Loss: 91.68933868408203, Neurons: 11, Grad norm: 4.469e+01\n",
      "Epoch 23785, Loss: 91.68031311035156, Neurons: 11, Grad norm: 1.684e+01\n",
      "Epoch 23786, Loss: 91.67156219482422, Neurons: 11, Grad norm: 1.157e+01\n",
      "Epoch 23787, Loss: 91.66323852539062, Neurons: 11, Grad norm: 3.503e+01\n",
      "Epoch 23788, Loss: 91.65524291992188, Neurons: 11, Grad norm: 5.132e+01\n",
      "Epoch 23789, Loss: 91.6473388671875, Neurons: 11, Grad norm: 5.739e+01\n",
      "Epoch 23790, Loss: 91.63924407958984, Neurons: 11, Grad norm: 5.370e+01\n",
      "Epoch 23791, Loss: 91.63086700439453, Neurons: 11, Grad norm: 4.039e+01\n",
      "Epoch 23792, Loss: 91.62227630615234, Neurons: 11, Grad norm: 2.118e+01\n",
      "Epoch 23793, Loss: 91.61372375488281, Neurons: 11, Grad norm: 1.515e+00\n",
      "Epoch 23794, Loss: 91.60536193847656, Neurons: 11, Grad norm: 1.938e+01\n",
      "Epoch 23795, Loss: 91.59721374511719, Neurons: 11, Grad norm: 3.330e+01\n",
      "Epoch 23796, Loss: 91.58915710449219, Neurons: 11, Grad norm: 3.928e+01\n",
      "Epoch 23797, Loss: 91.58104705810547, Neurons: 11, Grad norm: 3.772e+01\n",
      "Epoch 23798, Loss: 91.57276916503906, Neurons: 11, Grad norm: 2.901e+01\n",
      "Epoch 23799, Loss: 91.56438446044922, Neurons: 11, Grad norm: 1.612e+01\n",
      "Epoch 23799, Test loss: 87.8612289428711\n",
      "Epoch 23800, Loss: 91.55598449707031, Neurons: 11, Grad norm: 1.759e+00\n",
      "Epoch 23801, Loss: 91.54767608642578, Neurons: 11, Grad norm: 1.236e+01\n",
      "Epoch 23802, Loss: 91.53948211669922, Neurons: 11, Grad norm: 2.204e+01\n",
      "Epoch 23803, Loss: 91.53133392333984, Neurons: 11, Grad norm: 2.627e+01\n",
      "Epoch 23804, Loss: 91.52314758300781, Neurons: 11, Grad norm: 2.560e+01\n",
      "Epoch 23805, Loss: 91.51490020751953, Neurons: 11, Grad norm: 1.976e+01\n",
      "Epoch 23806, Loss: 91.50657653808594, Neurons: 11, Grad norm: 1.129e+01\n",
      "Epoch 23807, Loss: 91.49824523925781, Neurons: 11, Grad norm: 1.835e+00\n",
      "Epoch 23808, Loss: 91.48998260498047, Neurons: 11, Grad norm: 8.123e+00\n",
      "Epoch 23809, Loss: 91.48174285888672, Neurons: 11, Grad norm: 1.532e+01\n",
      "Epoch 23810, Loss: 91.47352600097656, Neurons: 11, Grad norm: 1.891e+01\n",
      "Epoch 23811, Loss: 91.4653091430664, Neurons: 11, Grad norm: 1.923e+01\n",
      "Epoch 23812, Loss: 91.45706939697266, Neurons: 11, Grad norm: 1.594e+01\n",
      "Epoch 23813, Loss: 91.44878387451172, Neurons: 11, Grad norm: 1.071e+01\n",
      "Epoch 23814, Loss: 91.44047546386719, Neurons: 11, Grad norm: 3.977e+00\n",
      "Epoch 23815, Loss: 91.43218231201172, Neurons: 11, Grad norm: 3.205e+00\n",
      "Epoch 23816, Loss: 91.42391967773438, Neurons: 11, Grad norm: 8.783e+00\n",
      "Epoch 23817, Loss: 91.41566467285156, Neurons: 11, Grad norm: 1.228e+01\n",
      "Epoch 23818, Loss: 91.40739440917969, Neurons: 11, Grad norm: 1.408e+01\n",
      "Epoch 23819, Loss: 91.39913177490234, Neurons: 11, Grad norm: 1.310e+01\n",
      "Epoch 23820, Loss: 91.3908462524414, Neurons: 11, Grad norm: 1.056e+01\n",
      "Epoch 23821, Loss: 91.3825454711914, Neurons: 11, Grad norm: 6.458e+00\n",
      "Epoch 23822, Loss: 91.3742446899414, Neurons: 11, Grad norm: 2.389e+00\n",
      "Epoch 23823, Loss: 91.3659439086914, Neurons: 11, Grad norm: 3.071e+00\n",
      "Epoch 23824, Loss: 91.35767364501953, Neurons: 11, Grad norm: 6.171e+00\n",
      "Epoch 23825, Loss: 91.3493881225586, Neurons: 11, Grad norm: 8.399e+00\n",
      "Epoch 23826, Loss: 91.3410873413086, Neurons: 11, Grad norm: 8.726e+00\n",
      "Epoch 23827, Loss: 91.3327865600586, Neurons: 11, Grad norm: 7.946e+00\n",
      "Epoch 23828, Loss: 91.32447052001953, Neurons: 11, Grad norm: 5.808e+00\n",
      "Epoch 23829, Loss: 91.316162109375, Neurons: 11, Grad norm: 3.523e+00\n",
      "Epoch 23830, Loss: 91.30784606933594, Neurons: 11, Grad norm: 1.467e+00\n",
      "Epoch 23831, Loss: 91.29952239990234, Neurons: 11, Grad norm: 2.600e+00\n",
      "Epoch 23832, Loss: 91.29121398925781, Neurons: 11, Grad norm: 4.345e+00\n",
      "Epoch 23833, Loss: 91.28289031982422, Neurons: 11, Grad norm: 5.172e+00\n",
      "Epoch 23834, Loss: 91.27456665039062, Neurons: 11, Grad norm: 5.537e+00\n",
      "Epoch 23835, Loss: 91.2662353515625, Neurons: 11, Grad norm: 4.870e+00\n",
      "Epoch 23836, Loss: 91.25790405273438, Neurons: 11, Grad norm: 4.027e+00\n",
      "Epoch 23837, Loss: 91.24957275390625, Neurons: 11, Grad norm: 2.585e+00\n",
      "Epoch 23838, Loss: 91.24122619628906, Neurons: 11, Grad norm: 1.606e+00\n",
      "Epoch 23839, Loss: 91.23289489746094, Neurons: 11, Grad norm: 1.660e+00\n",
      "Epoch 23840, Loss: 91.22454071044922, Neurons: 11, Grad norm: 2.296e+00\n",
      "Epoch 23841, Loss: 91.2161865234375, Neurons: 11, Grad norm: 3.022e+00\n",
      "Epoch 23842, Loss: 91.20783233642578, Neurons: 11, Grad norm: 3.153e+00\n",
      "Epoch 23843, Loss: 91.1994857788086, Neurons: 11, Grad norm: 3.572e+00\n",
      "Epoch 23844, Loss: 91.19113159179688, Neurons: 11, Grad norm: 3.569e+00\n",
      "Epoch 23845, Loss: 91.18276977539062, Neurons: 11, Grad norm: 3.543e+00\n",
      "Epoch 23846, Loss: 91.17438507080078, Neurons: 11, Grad norm: 3.127e+00\n",
      "Epoch 23847, Loss: 91.16602325439453, Neurons: 11, Grad norm: 2.891e+00\n",
      "Epoch 23848, Loss: 91.15763854980469, Neurons: 11, Grad norm: 2.188e+00\n",
      "Epoch 23849, Loss: 91.1492691040039, Neurons: 11, Grad norm: 1.870e+00\n",
      "Epoch 23849, Test loss: 87.46297454833984\n",
      "Epoch 23850, Loss: 91.14088439941406, Neurons: 11, Grad norm: 1.582e+00\n",
      "Epoch 23851, Loss: 91.13250732421875, Neurons: 11, Grad norm: 1.458e+00\n",
      "Epoch 23852, Loss: 91.12411499023438, Neurons: 11, Grad norm: 1.544e+00\n",
      "Epoch 23853, Loss: 91.11570739746094, Neurons: 11, Grad norm: 1.593e+00\n",
      "Epoch 23854, Loss: 91.10733795166016, Neurons: 11, Grad norm: 1.944e+00\n",
      "Epoch 23855, Loss: 91.09893035888672, Neurons: 11, Grad norm: 2.174e+00\n",
      "Epoch 23856, Loss: 91.09053802490234, Neurons: 11, Grad norm: 2.493e+00\n",
      "Epoch 23857, Loss: 91.08210754394531, Neurons: 11, Grad norm: 2.600e+00\n",
      "Epoch 23858, Loss: 91.07372283935547, Neurons: 11, Grad norm: 3.178e+00\n",
      "Epoch 23859, Loss: 91.0653076171875, Neurons: 11, Grad norm: 3.032e+00\n",
      "Epoch 23860, Loss: 91.05690002441406, Neurons: 11, Grad norm: 3.077e+00\n",
      "Epoch 23861, Loss: 91.04846954345703, Neurons: 11, Grad norm: 2.945e+00\n",
      "Epoch 23862, Loss: 91.04004669189453, Neurons: 11, Grad norm: 2.721e+00\n",
      "Epoch 23863, Loss: 91.03162384033203, Neurons: 11, Grad norm: 2.165e+00\n",
      "Epoch 23864, Loss: 91.02320098876953, Neurons: 11, Grad norm: 2.065e+00\n",
      "Epoch 23865, Loss: 91.01476287841797, Neurons: 11, Grad norm: 1.806e+00\n",
      "Epoch 23866, Loss: 91.00631713867188, Neurons: 11, Grad norm: 1.690e+00\n",
      "Epoch 23867, Loss: 90.99788665771484, Neurons: 11, Grad norm: 1.574e+00\n",
      "Epoch 23868, Loss: 90.98942565917969, Neurons: 11, Grad norm: 1.593e+00\n",
      "Epoch 23869, Loss: 90.98098754882812, Neurons: 11, Grad norm: 1.460e+00\n",
      "Epoch 23870, Loss: 90.97254943847656, Neurons: 11, Grad norm: 1.446e+00\n",
      "Epoch 23871, Loss: 90.9640884399414, Neurons: 11, Grad norm: 1.459e+00\n",
      "Epoch 23872, Loss: 90.95563507080078, Neurons: 11, Grad norm: 1.506e+00\n",
      "Epoch 23873, Loss: 90.94715881347656, Neurons: 11, Grad norm: 1.637e+00\n",
      "Epoch 23874, Loss: 90.93871307373047, Neurons: 11, Grad norm: 1.643e+00\n",
      "Epoch 23875, Loss: 90.93023681640625, Neurons: 11, Grad norm: 1.801e+00\n",
      "Epoch 23876, Loss: 90.9217758178711, Neurons: 11, Grad norm: 1.921e+00\n",
      "Epoch 23877, Loss: 90.91329956054688, Neurons: 11, Grad norm: 2.264e+00\n",
      "Epoch 23878, Loss: 90.90481567382812, Neurons: 11, Grad norm: 2.468e+00\n",
      "Epoch 23879, Loss: 90.89633178710938, Neurons: 11, Grad norm: 2.963e+00\n",
      "Epoch 23880, Loss: 90.88784790039062, Neurons: 11, Grad norm: 3.305e+00\n",
      "Epoch 23881, Loss: 90.87936401367188, Neurons: 11, Grad norm: 3.844e+00\n",
      "Epoch 23882, Loss: 90.87088012695312, Neurons: 11, Grad norm: 3.893e+00\n",
      "Epoch 23883, Loss: 90.86237335205078, Neurons: 11, Grad norm: 4.112e+00\n",
      "Epoch 23884, Loss: 90.8538818359375, Neurons: 11, Grad norm: 4.083e+00\n",
      "Epoch 23885, Loss: 90.84538269042969, Neurons: 11, Grad norm: 4.317e+00\n",
      "Epoch 23886, Loss: 90.83687591552734, Neurons: 11, Grad norm: 4.451e+00\n",
      "Epoch 23887, Loss: 90.82838439941406, Neurons: 11, Grad norm: 5.061e+00\n",
      "Epoch 23888, Loss: 90.81986236572266, Neurons: 11, Grad norm: 5.436e+00\n",
      "Epoch 23889, Loss: 90.81134796142578, Neurons: 11, Grad norm: 6.011e+00\n",
      "Epoch 23890, Loss: 90.8028335571289, Neurons: 11, Grad norm: 6.678e+00\n",
      "Epoch 23891, Loss: 90.79431915283203, Neurons: 11, Grad norm: 7.726e+00\n",
      "Epoch 23892, Loss: 90.7857894897461, Neurons: 11, Grad norm: 8.662e+00\n",
      "Epoch 23893, Loss: 90.77725982666016, Neurons: 11, Grad norm: 1.038e+01\n",
      "Epoch 23894, Loss: 90.76874542236328, Neurons: 11, Grad norm: 1.194e+01\n",
      "Epoch 23895, Loss: 90.76022338867188, Neurons: 11, Grad norm: 1.400e+01\n",
      "Epoch 23896, Loss: 90.751708984375, Neurons: 11, Grad norm: 1.638e+01\n",
      "Epoch 23897, Loss: 90.74317169189453, Neurons: 11, Grad norm: 1.962e+01\n",
      "Epoch 23898, Loss: 90.73465728759766, Neurons: 11, Grad norm: 2.313e+01\n",
      "Epoch 23899, Loss: 90.72615814208984, Neurons: 11, Grad norm: 2.794e+01\n",
      "Epoch 23899, Test loss: 87.06100463867188\n",
      "Epoch 23900, Loss: 90.7176742553711, Neurons: 11, Grad norm: 3.362e+01\n",
      "Epoch 23901, Loss: 90.70923614501953, Neurons: 11, Grad norm: 4.056e+01\n",
      "Epoch 23902, Loss: 90.70083618164062, Neurons: 11, Grad norm: 4.864e+01\n",
      "Epoch 23903, Loss: 90.6924819946289, Neurons: 11, Grad norm: 5.828e+01\n",
      "Epoch 23904, Loss: 90.68421936035156, Neurons: 11, Grad norm: 6.842e+01\n",
      "Epoch 23905, Loss: 90.67607116699219, Neurons: 11, Grad norm: 7.880e+01\n",
      "Epoch 23906, Loss: 90.66797637939453, Neurons: 11, Grad norm: 8.756e+01\n",
      "Epoch 23907, Loss: 90.65991973876953, Neurons: 11, Grad norm: 9.271e+01\n",
      "Epoch 23908, Loss: 90.65172576904297, Neurons: 11, Grad norm: 9.084e+01\n",
      "Epoch 23909, Loss: 90.6432876586914, Neurons: 11, Grad norm: 8.088e+01\n",
      "Epoch 23910, Loss: 90.6344985961914, Neurons: 11, Grad norm: 6.154e+01\n",
      "Epoch 23911, Loss: 90.62548828125, Neurons: 11, Grad norm: 3.565e+01\n",
      "Epoch 23912, Loss: 90.61653900146484, Neurons: 11, Grad norm: 6.888e+00\n",
      "Epoch 23913, Loss: 90.60794067382812, Neurons: 11, Grad norm: 1.992e+01\n",
      "Epoch 23914, Loss: 90.59976196289062, Neurons: 11, Grad norm: 4.118e+01\n",
      "Epoch 23915, Loss: 90.59180450439453, Neurons: 11, Grad norm: 5.382e+01\n",
      "Epoch 23916, Loss: 90.5838623046875, Neurons: 11, Grad norm: 5.673e+01\n",
      "Epoch 23917, Loss: 90.57568359375, Neurons: 11, Grad norm: 4.969e+01\n",
      "Epoch 23918, Loss: 90.5672378540039, Neurons: 11, Grad norm: 3.487e+01\n",
      "Epoch 23919, Loss: 90.55867004394531, Neurons: 11, Grad norm: 1.504e+01\n",
      "Epoch 23920, Loss: 90.5501708984375, Neurons: 11, Grad norm: 5.780e+00\n",
      "Epoch 23921, Loss: 90.54188537597656, Neurons: 11, Grad norm: 2.338e+01\n",
      "Epoch 23922, Loss: 90.53378295898438, Neurons: 11, Grad norm: 3.495e+01\n",
      "Epoch 23923, Loss: 90.52571105957031, Neurons: 11, Grad norm: 3.955e+01\n",
      "Epoch 23924, Loss: 90.51756286621094, Neurons: 11, Grad norm: 3.639e+01\n",
      "Epoch 23925, Loss: 90.50926971435547, Neurons: 11, Grad norm: 2.716e+01\n",
      "Epoch 23926, Loss: 90.50088500976562, Neurons: 11, Grad norm: 1.369e+01\n",
      "Epoch 23927, Loss: 90.49252319335938, Neurons: 11, Grad norm: 1.605e+00\n",
      "Epoch 23928, Loss: 90.48423767089844, Neurons: 11, Grad norm: 1.389e+01\n",
      "Epoch 23929, Loss: 90.47605895996094, Neurons: 11, Grad norm: 2.304e+01\n",
      "Epoch 23930, Loss: 90.4678955078125, Neurons: 11, Grad norm: 2.737e+01\n",
      "Epoch 23931, Loss: 90.45970916748047, Neurons: 11, Grad norm: 2.622e+01\n",
      "Epoch 23932, Loss: 90.45146942138672, Neurons: 11, Grad norm: 2.094e+01\n",
      "Epoch 23933, Loss: 90.44316864013672, Neurons: 11, Grad norm: 1.238e+01\n",
      "Epoch 23934, Loss: 90.43484497070312, Neurons: 11, Grad norm: 2.802e+00\n",
      "Epoch 23935, Loss: 90.42658233642578, Neurons: 11, Grad norm: 7.308e+00\n",
      "Epoch 23936, Loss: 90.4183578491211, Neurons: 11, Grad norm: 1.456e+01\n",
      "Epoch 23937, Loss: 90.41014862060547, Neurons: 11, Grad norm: 1.925e+01\n",
      "Epoch 23938, Loss: 90.40194702148438, Neurons: 11, Grad norm: 2.013e+01\n",
      "Epoch 23939, Loss: 90.39370727539062, Neurons: 11, Grad norm: 1.778e+01\n",
      "Epoch 23940, Loss: 90.38542175292969, Neurons: 11, Grad norm: 1.264e+01\n",
      "Epoch 23941, Loss: 90.37712860107422, Neurons: 11, Grad norm: 6.158e+00\n",
      "Epoch 23942, Loss: 90.36885070800781, Neurons: 11, Grad norm: 1.894e+00\n",
      "Epoch 23943, Loss: 90.36058044433594, Neurons: 11, Grad norm: 7.299e+00\n",
      "Epoch 23944, Loss: 90.35234069824219, Neurons: 11, Grad norm: 1.148e+01\n",
      "Epoch 23945, Loss: 90.3440933227539, Neurons: 11, Grad norm: 1.332e+01\n",
      "Epoch 23946, Loss: 90.3358383178711, Neurons: 11, Grad norm: 1.317e+01\n",
      "Epoch 23947, Loss: 90.32756805419922, Neurons: 11, Grad norm: 1.083e+01\n",
      "Epoch 23948, Loss: 90.31928253173828, Neurons: 11, Grad norm: 7.503e+00\n",
      "Epoch 23949, Loss: 90.31100463867188, Neurons: 11, Grad norm: 3.425e+00\n",
      "Epoch 23949, Test loss: 86.65876007080078\n",
      "Epoch 23950, Loss: 90.30271911621094, Neurons: 11, Grad norm: 1.765e+00\n",
      "Epoch 23951, Loss: 90.29442596435547, Neurons: 11, Grad norm: 4.790e+00\n",
      "Epoch 23952, Loss: 90.28614807128906, Neurons: 11, Grad norm: 6.890e+00\n",
      "Epoch 23953, Loss: 90.27787017822266, Neurons: 11, Grad norm: 8.211e+00\n",
      "Epoch 23954, Loss: 90.26958465576172, Neurons: 11, Grad norm: 7.975e+00\n",
      "Epoch 23955, Loss: 90.26129913330078, Neurons: 11, Grad norm: 6.662e+00\n",
      "Epoch 23956, Loss: 90.25299835205078, Neurons: 11, Grad norm: 4.585e+00\n",
      "Epoch 23957, Loss: 90.24468231201172, Neurons: 11, Grad norm: 2.446e+00\n",
      "Epoch 23958, Loss: 90.23638153076172, Neurons: 11, Grad norm: 1.687e+00\n",
      "Epoch 23959, Loss: 90.22808074951172, Neurons: 11, Grad norm: 3.511e+00\n",
      "Epoch 23960, Loss: 90.21976470947266, Neurons: 11, Grad norm: 5.278e+00\n",
      "Epoch 23961, Loss: 90.21146392822266, Neurons: 11, Grad norm: 6.375e+00\n",
      "Epoch 23962, Loss: 90.2031478881836, Neurons: 11, Grad norm: 6.679e+00\n",
      "Epoch 23963, Loss: 90.19483184814453, Neurons: 11, Grad norm: 5.977e+00\n",
      "Epoch 23964, Loss: 90.18650817871094, Neurons: 11, Grad norm: 5.022e+00\n",
      "Epoch 23965, Loss: 90.1781997680664, Neurons: 11, Grad norm: 3.595e+00\n",
      "Epoch 23966, Loss: 90.16986083984375, Neurons: 11, Grad norm: 2.276e+00\n",
      "Epoch 23967, Loss: 90.1615219116211, Neurons: 11, Grad norm: 1.458e+00\n",
      "Epoch 23968, Loss: 90.1531982421875, Neurons: 11, Grad norm: 1.588e+00\n",
      "Epoch 23969, Loss: 90.14484405517578, Neurons: 11, Grad norm: 2.321e+00\n",
      "Epoch 23970, Loss: 90.13653564453125, Neurons: 11, Grad norm: 2.725e+00\n",
      "Epoch 23971, Loss: 90.128173828125, Neurons: 11, Grad norm: 2.950e+00\n",
      "Epoch 23972, Loss: 90.11983489990234, Neurons: 11, Grad norm: 2.921e+00\n",
      "Epoch 23973, Loss: 90.11148834228516, Neurons: 11, Grad norm: 2.862e+00\n",
      "Epoch 23974, Loss: 90.1031265258789, Neurons: 11, Grad norm: 2.341e+00\n",
      "Epoch 23975, Loss: 90.09477996826172, Neurons: 11, Grad norm: 2.077e+00\n",
      "Epoch 23976, Loss: 90.08642578125, Neurons: 11, Grad norm: 1.815e+00\n",
      "Epoch 23977, Loss: 90.07806396484375, Neurons: 11, Grad norm: 1.499e+00\n",
      "Epoch 23978, Loss: 90.06968688964844, Neurons: 11, Grad norm: 1.482e+00\n",
      "Epoch 23979, Loss: 90.06132507324219, Neurons: 11, Grad norm: 1.577e+00\n",
      "Epoch 23980, Loss: 90.0529556274414, Neurons: 11, Grad norm: 1.839e+00\n",
      "Epoch 23981, Loss: 90.04457092285156, Neurons: 11, Grad norm: 2.186e+00\n",
      "Epoch 23982, Loss: 90.03621673583984, Neurons: 11, Grad norm: 2.314e+00\n",
      "Epoch 23983, Loss: 90.02783203125, Neurons: 11, Grad norm: 2.222e+00\n",
      "Epoch 23984, Loss: 90.01944732666016, Neurons: 11, Grad norm: 2.555e+00\n",
      "Epoch 23985, Loss: 90.01104736328125, Neurons: 11, Grad norm: 2.222e+00\n",
      "Epoch 23986, Loss: 90.00264739990234, Neurons: 11, Grad norm: 1.873e+00\n",
      "Epoch 23987, Loss: 89.9942626953125, Neurons: 11, Grad norm: 1.750e+00\n",
      "Epoch 23988, Loss: 89.98587036132812, Neurons: 11, Grad norm: 1.669e+00\n",
      "Epoch 23989, Loss: 89.97747802734375, Neurons: 11, Grad norm: 1.482e+00\n",
      "Epoch 23990, Loss: 89.96908569335938, Neurons: 11, Grad norm: 1.472e+00\n",
      "Epoch 23991, Loss: 89.96066284179688, Neurons: 11, Grad norm: 1.466e+00\n",
      "Epoch 23992, Loss: 89.95226287841797, Neurons: 11, Grad norm: 1.446e+00\n",
      "Epoch 23993, Loss: 89.94383239746094, Neurons: 11, Grad norm: 1.436e+00\n",
      "Epoch 23994, Loss: 89.93540954589844, Neurons: 11, Grad norm: 1.490e+00\n",
      "Epoch 23995, Loss: 89.92699432373047, Neurons: 11, Grad norm: 1.508e+00\n",
      "Epoch 23996, Loss: 89.91858673095703, Neurons: 11, Grad norm: 1.559e+00\n",
      "Epoch 23997, Loss: 89.91014862060547, Neurons: 11, Grad norm: 1.685e+00\n",
      "Epoch 23998, Loss: 89.90171813964844, Neurons: 11, Grad norm: 1.895e+00\n",
      "Epoch 23999, Loss: 89.8932876586914, Neurons: 11, Grad norm: 1.794e+00\n",
      "Epoch 23999, Test loss: 86.2591323852539\n",
      "Epoch 24000, Loss: 89.88484954833984, Neurons: 11, Grad norm: 1.803e+00\n",
      "Epoch 24001, Loss: 89.87641143798828, Neurons: 11, Grad norm: 1.862e+00\n",
      "Epoch 24002, Loss: 89.86796569824219, Neurons: 11, Grad norm: 1.890e+00\n",
      "Epoch 24003, Loss: 89.8595199584961, Neurons: 11, Grad norm: 1.832e+00\n",
      "Epoch 24004, Loss: 89.85107421875, Neurons: 11, Grad norm: 1.949e+00\n",
      "Epoch 24005, Loss: 89.8426284790039, Neurons: 11, Grad norm: 1.859e+00\n",
      "Epoch 24006, Loss: 89.83415985107422, Neurons: 11, Grad norm: 1.694e+00\n",
      "Epoch 24007, Loss: 89.8257064819336, Neurons: 11, Grad norm: 1.621e+00\n",
      "Epoch 24008, Loss: 89.8172378540039, Neurons: 11, Grad norm: 1.612e+00\n",
      "Epoch 24009, Loss: 89.80879211425781, Neurons: 11, Grad norm: 1.441e+00\n",
      "Epoch 24010, Loss: 89.80030822753906, Neurons: 11, Grad norm: 1.417e+00\n",
      "Epoch 24011, Loss: 89.79183197021484, Neurons: 11, Grad norm: 1.455e+00\n",
      "Epoch 24012, Loss: 89.78336334228516, Neurons: 11, Grad norm: 1.548e+00\n",
      "Epoch 24013, Loss: 89.77489471435547, Neurons: 11, Grad norm: 1.816e+00\n",
      "Epoch 24014, Loss: 89.76640319824219, Neurons: 11, Grad norm: 1.914e+00\n",
      "Epoch 24015, Loss: 89.75792694091797, Neurons: 11, Grad norm: 2.298e+00\n",
      "Epoch 24016, Loss: 89.74944305419922, Neurons: 11, Grad norm: 2.779e+00\n",
      "Epoch 24017, Loss: 89.74095916748047, Neurons: 11, Grad norm: 3.332e+00\n",
      "Epoch 24018, Loss: 89.7324447631836, Neurons: 11, Grad norm: 3.824e+00\n",
      "Epoch 24019, Loss: 89.7239761352539, Neurons: 11, Grad norm: 4.840e+00\n",
      "Epoch 24020, Loss: 89.71546936035156, Neurons: 11, Grad norm: 5.823e+00\n",
      "Epoch 24021, Loss: 89.70695495605469, Neurons: 11, Grad norm: 6.871e+00\n",
      "Epoch 24022, Loss: 89.6984634399414, Neurons: 11, Grad norm: 8.152e+00\n",
      "Epoch 24023, Loss: 89.68995666503906, Neurons: 11, Grad norm: 1.003e+01\n",
      "Epoch 24024, Loss: 89.68144989013672, Neurons: 11, Grad norm: 1.188e+01\n",
      "Epoch 24025, Loss: 89.6729507446289, Neurons: 11, Grad norm: 1.459e+01\n",
      "Epoch 24026, Loss: 89.66444396972656, Neurons: 11, Grad norm: 1.826e+01\n",
      "Epoch 24027, Loss: 89.65595245361328, Neurons: 11, Grad norm: 2.265e+01\n",
      "Epoch 24028, Loss: 89.64747619628906, Neurons: 11, Grad norm: 2.807e+01\n",
      "Epoch 24029, Loss: 89.63904571533203, Neurons: 11, Grad norm: 3.541e+01\n",
      "Epoch 24030, Loss: 89.6306381225586, Neurons: 11, Grad norm: 4.421e+01\n",
      "Epoch 24031, Loss: 89.62228393554688, Neurons: 11, Grad norm: 5.506e+01\n",
      "Epoch 24032, Loss: 89.61405944824219, Neurons: 11, Grad norm: 6.824e+01\n",
      "Epoch 24033, Loss: 89.60595703125, Neurons: 11, Grad norm: 8.343e+01\n",
      "Epoch 24034, Loss: 89.59806060791016, Neurons: 11, Grad norm: 9.848e+01\n",
      "Epoch 24035, Loss: 89.59032440185547, Neurons: 11, Grad norm: 1.112e+02\n",
      "Epoch 24036, Loss: 89.5826187133789, Neurons: 11, Grad norm: 1.170e+02\n",
      "Epoch 24037, Loss: 89.5746078491211, Neurons: 11, Grad norm: 1.103e+02\n",
      "Epoch 24038, Loss: 89.56596374511719, Neurons: 11, Grad norm: 8.809e+01\n",
      "Epoch 24039, Loss: 89.5566635131836, Neurons: 11, Grad norm: 5.289e+01\n",
      "Epoch 24040, Loss: 89.54723358154297, Neurons: 11, Grad norm: 1.067e+01\n",
      "Epoch 24041, Loss: 89.53841400146484, Neurons: 11, Grad norm: 2.980e+01\n",
      "Epoch 24042, Loss: 89.53044891357422, Neurons: 11, Grad norm: 6.031e+01\n",
      "Epoch 24043, Loss: 89.52298736572266, Neurons: 11, Grad norm: 7.529e+01\n",
      "Epoch 24044, Loss: 89.51537322998047, Neurons: 11, Grad norm: 7.303e+01\n",
      "Epoch 24045, Loss: 89.50716400146484, Neurons: 11, Grad norm: 5.347e+01\n",
      "Epoch 24046, Loss: 89.49844360351562, Neurons: 11, Grad norm: 2.274e+01\n",
      "Epoch 24047, Loss: 89.4897689819336, Neurons: 11, Grad norm: 1.053e+01\n",
      "Epoch 24048, Loss: 89.4815902709961, Neurons: 11, Grad norm: 3.776e+01\n",
      "Epoch 24049, Loss: 89.47383880615234, Neurons: 11, Grad norm: 5.343e+01\n",
      "Epoch 24049, Test loss: 85.86109161376953\n",
      "Epoch 24050, Loss: 89.46612548828125, Neurons: 11, Grad norm: 5.370e+01\n",
      "Epoch 24051, Loss: 89.45807647705078, Neurons: 11, Grad norm: 4.017e+01\n",
      "Epoch 24052, Loss: 89.44969940185547, Neurons: 11, Grad norm: 1.779e+01\n",
      "Epoch 24053, Loss: 89.4413070678711, Neurons: 11, Grad norm: 7.295e+00\n",
      "Epoch 24054, Loss: 89.43319702148438, Neurons: 11, Grad norm: 2.802e+01\n",
      "Epoch 24055, Loss: 89.42533111572266, Neurons: 11, Grad norm: 3.888e+01\n",
      "Epoch 24056, Loss: 89.4174575805664, Neurons: 11, Grad norm: 3.875e+01\n",
      "Epoch 24057, Loss: 89.4094009399414, Neurons: 11, Grad norm: 2.874e+01\n",
      "Epoch 24058, Loss: 89.40118408203125, Neurons: 11, Grad norm: 1.222e+01\n",
      "Epoch 24059, Loss: 89.39297485351562, Neurons: 11, Grad norm: 6.341e+00\n",
      "Epoch 24060, Loss: 89.3849105834961, Neurons: 11, Grad norm: 2.062e+01\n",
      "Epoch 24061, Loss: 89.376953125, Neurons: 11, Grad norm: 2.849e+01\n",
      "Epoch 24062, Loss: 89.3689956665039, Neurons: 11, Grad norm: 2.844e+01\n",
      "Epoch 24063, Loss: 89.3609390258789, Neurons: 11, Grad norm: 2.103e+01\n",
      "Epoch 24064, Loss: 89.35279846191406, Neurons: 11, Grad norm: 8.836e+00\n",
      "Epoch 24065, Loss: 89.34467315673828, Neurons: 11, Grad norm: 4.292e+00\n",
      "Epoch 24066, Loss: 89.33658599853516, Neurons: 11, Grad norm: 1.466e+01\n",
      "Epoch 24067, Loss: 89.32859802246094, Neurons: 11, Grad norm: 2.075e+01\n",
      "Epoch 24068, Loss: 89.3205795288086, Neurons: 11, Grad norm: 2.103e+01\n",
      "Epoch 24069, Loss: 89.3125228881836, Neurons: 11, Grad norm: 1.598e+01\n",
      "Epoch 24070, Loss: 89.3044204711914, Neurons: 11, Grad norm: 8.060e+00\n",
      "Epoch 24071, Loss: 89.29632568359375, Neurons: 11, Grad norm: 1.995e+00\n",
      "Epoch 24072, Loss: 89.28823852539062, Neurons: 11, Grad norm: 9.781e+00\n",
      "Epoch 24073, Loss: 89.28021240234375, Neurons: 11, Grad norm: 1.472e+01\n",
      "Epoch 24074, Loss: 89.27216339111328, Neurons: 11, Grad norm: 1.562e+01\n",
      "Epoch 24075, Loss: 89.26409912109375, Neurons: 11, Grad norm: 1.337e+01\n",
      "Epoch 24076, Loss: 89.25599670410156, Neurons: 11, Grad norm: 8.158e+00\n",
      "Epoch 24077, Loss: 89.2479019165039, Neurons: 11, Grad norm: 2.019e+00\n",
      "Epoch 24078, Loss: 89.23980712890625, Neurons: 11, Grad norm: 5.031e+00\n",
      "Epoch 24079, Loss: 89.23171997070312, Neurons: 11, Grad norm: 9.359e+00\n",
      "Epoch 24080, Loss: 89.22366333007812, Neurons: 11, Grad norm: 1.158e+01\n",
      "Epoch 24081, Loss: 89.21558380126953, Neurons: 11, Grad norm: 1.095e+01\n",
      "Epoch 24082, Loss: 89.20748901367188, Neurons: 11, Grad norm: 8.027e+00\n",
      "Epoch 24083, Loss: 89.19939422607422, Neurons: 11, Grad norm: 3.828e+00\n",
      "Epoch 24084, Loss: 89.19127655029297, Neurons: 11, Grad norm: 1.805e+00\n",
      "Epoch 24085, Loss: 89.18317413330078, Neurons: 11, Grad norm: 5.594e+00\n",
      "Epoch 24086, Loss: 89.1750717163086, Neurons: 11, Grad norm: 8.218e+00\n",
      "Epoch 24087, Loss: 89.16698455810547, Neurons: 11, Grad norm: 9.035e+00\n",
      "Epoch 24088, Loss: 89.15888977050781, Neurons: 11, Grad norm: 7.940e+00\n",
      "Epoch 24089, Loss: 89.15077209472656, Neurons: 11, Grad norm: 5.683e+00\n",
      "Epoch 24090, Loss: 89.14264678955078, Neurons: 11, Grad norm: 2.528e+00\n",
      "Epoch 24091, Loss: 89.13452911376953, Neurons: 11, Grad norm: 1.933e+00\n",
      "Epoch 24092, Loss: 89.12641143798828, Neurons: 11, Grad norm: 4.613e+00\n",
      "Epoch 24093, Loss: 89.1183090209961, Neurons: 11, Grad norm: 6.441e+00\n",
      "Epoch 24094, Loss: 89.11017608642578, Neurons: 11, Grad norm: 7.149e+00\n",
      "Epoch 24095, Loss: 89.10205078125, Neurons: 11, Grad norm: 6.428e+00\n",
      "Epoch 24096, Loss: 89.09392547607422, Neurons: 11, Grad norm: 4.745e+00\n",
      "Epoch 24097, Loss: 89.08580017089844, Neurons: 11, Grad norm: 2.572e+00\n",
      "Epoch 24098, Loss: 89.07765197753906, Neurons: 11, Grad norm: 1.431e+00\n",
      "Epoch 24099, Loss: 89.06949615478516, Neurons: 11, Grad norm: 2.818e+00\n",
      "Epoch 24099, Test loss: 85.46781921386719\n",
      "Epoch 24100, Loss: 89.06136322021484, Neurons: 11, Grad norm: 4.234e+00\n",
      "Epoch 24101, Loss: 89.05323791503906, Neurons: 11, Grad norm: 5.107e+00\n",
      "Epoch 24102, Loss: 89.04508209228516, Neurons: 11, Grad norm: 5.070e+00\n",
      "Epoch 24103, Loss: 89.03694152832031, Neurons: 11, Grad norm: 4.391e+00\n",
      "Epoch 24104, Loss: 89.02877044677734, Neurons: 11, Grad norm: 3.130e+00\n",
      "Epoch 24105, Loss: 89.0206298828125, Neurons: 11, Grad norm: 1.901e+00\n",
      "Epoch 24106, Loss: 89.0124740600586, Neurons: 11, Grad norm: 1.432e+00\n",
      "Epoch 24107, Loss: 89.00431060791016, Neurons: 11, Grad norm: 2.055e+00\n",
      "Epoch 24108, Loss: 88.99613189697266, Neurons: 11, Grad norm: 2.718e+00\n",
      "Epoch 24109, Loss: 88.98797607421875, Neurons: 11, Grad norm: 3.049e+00\n",
      "Epoch 24110, Loss: 88.97979736328125, Neurons: 11, Grad norm: 3.154e+00\n",
      "Epoch 24111, Loss: 88.97162628173828, Neurons: 11, Grad norm: 2.896e+00\n",
      "Epoch 24112, Loss: 88.96344757080078, Neurons: 11, Grad norm: 2.501e+00\n",
      "Epoch 24113, Loss: 88.95527648925781, Neurons: 11, Grad norm: 1.975e+00\n",
      "Epoch 24114, Loss: 88.94709777832031, Neurons: 11, Grad norm: 1.622e+00\n",
      "Epoch 24115, Loss: 88.93889617919922, Neurons: 11, Grad norm: 1.415e+00\n",
      "Epoch 24116, Loss: 88.93072509765625, Neurons: 11, Grad norm: 1.427e+00\n",
      "Epoch 24117, Loss: 88.92253112792969, Neurons: 11, Grad norm: 1.515e+00\n",
      "Epoch 24118, Loss: 88.91434478759766, Neurons: 11, Grad norm: 1.525e+00\n",
      "Epoch 24119, Loss: 88.90613555908203, Neurons: 11, Grad norm: 1.491e+00\n",
      "Epoch 24120, Loss: 88.8979263305664, Neurons: 11, Grad norm: 1.420e+00\n",
      "Epoch 24121, Loss: 88.88972473144531, Neurons: 11, Grad norm: 1.406e+00\n",
      "Epoch 24122, Loss: 88.88152313232422, Neurons: 11, Grad norm: 1.429e+00\n",
      "Epoch 24123, Loss: 88.87329864501953, Neurons: 11, Grad norm: 1.430e+00\n",
      "Epoch 24124, Loss: 88.86508178710938, Neurons: 11, Grad norm: 1.423e+00\n",
      "Epoch 24125, Loss: 88.85687255859375, Neurons: 11, Grad norm: 1.408e+00\n",
      "Epoch 24126, Loss: 88.84866333007812, Neurons: 11, Grad norm: 1.408e+00\n",
      "Epoch 24127, Loss: 88.84043884277344, Neurons: 11, Grad norm: 1.482e+00\n",
      "Epoch 24128, Loss: 88.83220672607422, Neurons: 11, Grad norm: 1.564e+00\n",
      "Epoch 24129, Loss: 88.82398223876953, Neurons: 11, Grad norm: 1.699e+00\n",
      "Epoch 24130, Loss: 88.81574249267578, Neurons: 11, Grad norm: 1.742e+00\n",
      "Epoch 24131, Loss: 88.80752563476562, Neurons: 11, Grad norm: 1.823e+00\n",
      "Epoch 24132, Loss: 88.79927825927734, Neurons: 11, Grad norm: 1.871e+00\n",
      "Epoch 24133, Loss: 88.79103088378906, Neurons: 11, Grad norm: 1.918e+00\n",
      "Epoch 24134, Loss: 88.78279876708984, Neurons: 11, Grad norm: 1.926e+00\n",
      "Epoch 24135, Loss: 88.77455139160156, Neurons: 11, Grad norm: 1.956e+00\n",
      "Epoch 24136, Loss: 88.76629638671875, Neurons: 11, Grad norm: 1.935e+00\n",
      "Epoch 24137, Loss: 88.75804901123047, Neurons: 11, Grad norm: 1.936e+00\n",
      "Epoch 24138, Loss: 88.74978637695312, Neurons: 11, Grad norm: 1.853e+00\n",
      "Epoch 24139, Loss: 88.74153900146484, Neurons: 11, Grad norm: 1.718e+00\n",
      "Epoch 24140, Loss: 88.7332763671875, Neurons: 11, Grad norm: 1.486e+00\n",
      "Epoch 24141, Loss: 88.7249984741211, Neurons: 11, Grad norm: 1.415e+00\n",
      "Epoch 24142, Loss: 88.71673583984375, Neurons: 11, Grad norm: 1.405e+00\n",
      "Epoch 24143, Loss: 88.7084732055664, Neurons: 11, Grad norm: 1.415e+00\n",
      "Epoch 24144, Loss: 88.7001953125, Neurons: 11, Grad norm: 1.406e+00\n",
      "Epoch 24145, Loss: 88.69192504882812, Neurons: 11, Grad norm: 1.423e+00\n",
      "Epoch 24146, Loss: 88.68363189697266, Neurons: 11, Grad norm: 1.456e+00\n",
      "Epoch 24147, Loss: 88.67535400390625, Neurons: 11, Grad norm: 1.551e+00\n",
      "Epoch 24148, Loss: 88.66706848144531, Neurons: 11, Grad norm: 1.679e+00\n",
      "Epoch 24149, Loss: 88.65878295898438, Neurons: 11, Grad norm: 1.739e+00\n",
      "Epoch 24149, Test loss: 85.07392883300781\n",
      "Epoch 24150, Loss: 88.65048217773438, Neurons: 11, Grad norm: 1.766e+00\n",
      "Epoch 24151, Loss: 88.6421890258789, Neurons: 11, Grad norm: 2.088e+00\n",
      "Epoch 24152, Loss: 88.63390350341797, Neurons: 11, Grad norm: 2.126e+00\n",
      "Epoch 24153, Loss: 88.62559509277344, Neurons: 11, Grad norm: 2.091e+00\n",
      "Epoch 24154, Loss: 88.6172866821289, Neurons: 11, Grad norm: 2.135e+00\n",
      "Epoch 24155, Loss: 88.60897064208984, Neurons: 11, Grad norm: 2.026e+00\n",
      "Epoch 24156, Loss: 88.60066986083984, Neurons: 11, Grad norm: 1.655e+00\n",
      "Epoch 24157, Loss: 88.59236907958984, Neurons: 11, Grad norm: 1.473e+00\n",
      "Epoch 24158, Loss: 88.58403778076172, Neurons: 11, Grad norm: 1.402e+00\n",
      "Epoch 24159, Loss: 88.57571411132812, Neurons: 11, Grad norm: 1.543e+00\n",
      "Epoch 24160, Loss: 88.5674057006836, Neurons: 11, Grad norm: 1.897e+00\n",
      "Epoch 24161, Loss: 88.55907440185547, Neurons: 11, Grad norm: 2.060e+00\n",
      "Epoch 24162, Loss: 88.55075073242188, Neurons: 11, Grad norm: 2.245e+00\n",
      "Epoch 24163, Loss: 88.54241943359375, Neurons: 11, Grad norm: 2.292e+00\n",
      "Epoch 24164, Loss: 88.5340805053711, Neurons: 11, Grad norm: 2.022e+00\n",
      "Epoch 24165, Loss: 88.5257568359375, Neurons: 11, Grad norm: 1.818e+00\n",
      "Epoch 24166, Loss: 88.51739501953125, Neurons: 11, Grad norm: 1.680e+00\n",
      "Epoch 24167, Loss: 88.50906372070312, Neurons: 11, Grad norm: 1.456e+00\n",
      "Epoch 24168, Loss: 88.50071716308594, Neurons: 11, Grad norm: 1.418e+00\n",
      "Epoch 24169, Loss: 88.49236297607422, Neurons: 11, Grad norm: 1.564e+00\n",
      "Epoch 24170, Loss: 88.4840087890625, Neurons: 11, Grad norm: 1.982e+00\n",
      "Epoch 24171, Loss: 88.47566986083984, Neurons: 11, Grad norm: 2.571e+00\n",
      "Epoch 24172, Loss: 88.46730041503906, Neurons: 11, Grad norm: 3.136e+00\n",
      "Epoch 24173, Loss: 88.45893096923828, Neurons: 11, Grad norm: 4.014e+00\n",
      "Epoch 24174, Loss: 88.4505844116211, Neurons: 11, Grad norm: 4.886e+00\n",
      "Epoch 24175, Loss: 88.44220733642578, Neurons: 11, Grad norm: 5.781e+00\n",
      "Epoch 24176, Loss: 88.43384552001953, Neurons: 11, Grad norm: 6.602e+00\n",
      "Epoch 24177, Loss: 88.42546081542969, Neurons: 11, Grad norm: 7.741e+00\n",
      "Epoch 24178, Loss: 88.41709899902344, Neurons: 11, Grad norm: 9.014e+00\n",
      "Epoch 24179, Loss: 88.40872955322266, Neurons: 11, Grad norm: 1.055e+01\n",
      "Epoch 24180, Loss: 88.40035247802734, Neurons: 11, Grad norm: 1.229e+01\n",
      "Epoch 24181, Loss: 88.39197540283203, Neurons: 11, Grad norm: 1.444e+01\n",
      "Epoch 24182, Loss: 88.38359832763672, Neurons: 11, Grad norm: 1.700e+01\n",
      "Epoch 24183, Loss: 88.375244140625, Neurons: 11, Grad norm: 2.029e+01\n",
      "Epoch 24184, Loss: 88.36688232421875, Neurons: 11, Grad norm: 2.447e+01\n",
      "Epoch 24185, Loss: 88.35852813720703, Neurons: 11, Grad norm: 2.965e+01\n",
      "Epoch 24186, Loss: 88.35021209716797, Neurons: 11, Grad norm: 3.607e+01\n",
      "Epoch 24187, Loss: 88.34192657470703, Neurons: 11, Grad norm: 4.409e+01\n",
      "Epoch 24188, Loss: 88.33369445800781, Neurons: 11, Grad norm: 5.374e+01\n",
      "Epoch 24189, Loss: 88.32554626464844, Neurons: 11, Grad norm: 6.494e+01\n",
      "Epoch 24190, Loss: 88.3175048828125, Neurons: 11, Grad norm: 7.717e+01\n",
      "Epoch 24191, Loss: 88.30957794189453, Neurons: 11, Grad norm: 8.988e+01\n",
      "Epoch 24192, Loss: 88.3017578125, Neurons: 11, Grad norm: 1.004e+02\n",
      "Epoch 24193, Loss: 88.29397583007812, Neurons: 11, Grad norm: 1.060e+02\n",
      "Epoch 24194, Loss: 88.28602600097656, Neurons: 11, Grad norm: 1.034e+02\n",
      "Epoch 24195, Loss: 88.27769470214844, Neurons: 11, Grad norm: 8.984e+01\n",
      "Epoch 24196, Loss: 88.26891326904297, Neurons: 11, Grad norm: 6.511e+01\n",
      "Epoch 24197, Loss: 88.2599105834961, Neurons: 11, Grad norm: 3.286e+01\n",
      "Epoch 24198, Loss: 88.25106048583984, Neurons: 11, Grad norm: 2.214e+00\n",
      "Epoch 24199, Loss: 88.24274444580078, Neurons: 11, Grad norm: 3.266e+01\n",
      "Epoch 24199, Test loss: 84.67134094238281\n",
      "Epoch 24200, Loss: 88.23490905761719, Neurons: 11, Grad norm: 5.552e+01\n",
      "Epoch 24201, Loss: 88.22732543945312, Neurons: 11, Grad norm: 6.665e+01\n",
      "Epoch 24202, Loss: 88.21959686279297, Neurons: 11, Grad norm: 6.492e+01\n",
      "Epoch 24203, Loss: 88.21148681640625, Neurons: 11, Grad norm: 5.130e+01\n",
      "Epoch 24204, Loss: 88.20307159423828, Neurons: 11, Grad norm: 2.902e+01\n",
      "Epoch 24205, Loss: 88.19462585449219, Neurons: 11, Grad norm: 3.287e+00\n",
      "Epoch 24206, Loss: 88.1864013671875, Neurons: 11, Grad norm: 2.094e+01\n",
      "Epoch 24207, Loss: 88.17848205566406, Neurons: 11, Grad norm: 3.836e+01\n",
      "Epoch 24208, Loss: 88.17072296142578, Neurons: 11, Grad norm: 4.685e+01\n",
      "Epoch 24209, Loss: 88.1628646850586, Neurons: 11, Grad norm: 4.499e+01\n",
      "Epoch 24210, Loss: 88.15481567382812, Neurons: 11, Grad norm: 3.404e+01\n",
      "Epoch 24211, Loss: 88.14661407470703, Neurons: 11, Grad norm: 1.758e+01\n",
      "Epoch 24212, Loss: 88.1384048461914, Neurons: 11, Grad norm: 1.830e+00\n",
      "Epoch 24213, Loss: 88.13032531738281, Neurons: 11, Grad norm: 1.775e+01\n",
      "Epoch 24214, Loss: 88.12238311767578, Neurons: 11, Grad norm: 2.894e+01\n",
      "Epoch 24215, Loss: 88.11450958251953, Neurons: 11, Grad norm: 3.317e+01\n",
      "Epoch 24216, Loss: 88.10657501220703, Neurons: 11, Grad norm: 3.051e+01\n",
      "Epoch 24217, Loss: 88.09852600097656, Neurons: 11, Grad norm: 2.192e+01\n",
      "Epoch 24218, Loss: 88.09040069580078, Neurons: 11, Grad norm: 9.907e+00\n",
      "Epoch 24219, Loss: 88.08231353759766, Neurons: 11, Grad norm: 3.254e+00\n",
      "Epoch 24220, Loss: 88.07428741455078, Neurons: 11, Grad norm: 1.390e+01\n",
      "Epoch 24221, Loss: 88.06632232666016, Neurons: 11, Grad norm: 2.117e+01\n",
      "Epoch 24222, Loss: 88.0583724975586, Neurons: 11, Grad norm: 2.359e+01\n",
      "Epoch 24223, Loss: 88.05036926269531, Neurons: 11, Grad norm: 2.141e+01\n",
      "Epoch 24224, Loss: 88.04235076904297, Neurons: 11, Grad norm: 1.539e+01\n",
      "Epoch 24225, Loss: 88.03427124023438, Neurons: 11, Grad norm: 7.272e+00\n",
      "Epoch 24226, Loss: 88.02620697021484, Neurons: 11, Grad norm: 2.145e+00\n",
      "Epoch 24227, Loss: 88.0181884765625, Neurons: 11, Grad norm: 9.324e+00\n",
      "Epoch 24228, Loss: 88.01018524169922, Neurons: 11, Grad norm: 1.447e+01\n",
      "Epoch 24229, Loss: 88.00218963623047, Neurons: 11, Grad norm: 1.629e+01\n",
      "Epoch 24230, Loss: 87.99418640136719, Neurons: 11, Grad norm: 1.509e+01\n",
      "Epoch 24231, Loss: 87.98614501953125, Neurons: 11, Grad norm: 1.134e+01\n",
      "Epoch 24232, Loss: 87.97809600830078, Neurons: 11, Grad norm: 6.161e+00\n",
      "Epoch 24233, Loss: 87.97004699707031, Neurons: 11, Grad norm: 1.435e+00\n",
      "Epoch 24234, Loss: 87.96199798583984, Neurons: 11, Grad norm: 5.100e+00\n",
      "Epoch 24235, Loss: 87.9539566040039, Neurons: 11, Grad norm: 8.956e+00\n",
      "Epoch 24236, Loss: 87.9459457397461, Neurons: 11, Grad norm: 1.102e+01\n",
      "Epoch 24237, Loss: 87.93791961669922, Neurons: 11, Grad norm: 1.126e+01\n",
      "Epoch 24238, Loss: 87.92987060546875, Neurons: 11, Grad norm: 9.814e+00\n",
      "Epoch 24239, Loss: 87.92180633544922, Neurons: 11, Grad norm: 7.229e+00\n",
      "Epoch 24240, Loss: 87.91375732421875, Neurons: 11, Grad norm: 3.795e+00\n",
      "Epoch 24241, Loss: 87.90568542480469, Neurons: 11, Grad norm: 1.448e+00\n",
      "Epoch 24242, Loss: 87.89763641357422, Neurons: 11, Grad norm: 4.125e+00\n",
      "Epoch 24243, Loss: 87.88958740234375, Neurons: 11, Grad norm: 6.560e+00\n",
      "Epoch 24244, Loss: 87.88152313232422, Neurons: 11, Grad norm: 8.065e+00\n",
      "Epoch 24245, Loss: 87.87347412109375, Neurons: 11, Grad norm: 8.096e+00\n",
      "Epoch 24246, Loss: 87.86539459228516, Neurons: 11, Grad norm: 7.219e+00\n",
      "Epoch 24247, Loss: 87.85733795166016, Neurons: 11, Grad norm: 5.532e+00\n",
      "Epoch 24248, Loss: 87.84925079345703, Neurons: 11, Grad norm: 3.558e+00\n",
      "Epoch 24249, Loss: 87.8411865234375, Neurons: 11, Grad norm: 1.661e+00\n",
      "Epoch 24249, Test loss: 84.28883361816406\n",
      "Epoch 24250, Loss: 87.83309936523438, Neurons: 11, Grad norm: 2.036e+00\n",
      "Epoch 24251, Loss: 87.82501983642578, Neurons: 11, Grad norm: 3.832e+00\n",
      "Epoch 24252, Loss: 87.81694793701172, Neurons: 11, Grad norm: 5.128e+00\n",
      "Epoch 24253, Loss: 87.8088607788086, Neurons: 11, Grad norm: 5.767e+00\n",
      "Epoch 24254, Loss: 87.80077362060547, Neurons: 11, Grad norm: 5.579e+00\n",
      "Epoch 24255, Loss: 87.79268646240234, Neurons: 11, Grad norm: 4.701e+00\n",
      "Epoch 24256, Loss: 87.78458404541016, Neurons: 11, Grad norm: 3.571e+00\n",
      "Epoch 24257, Loss: 87.7764892578125, Neurons: 11, Grad norm: 2.342e+00\n",
      "Epoch 24258, Loss: 87.76838684082031, Neurons: 11, Grad norm: 1.440e+00\n",
      "Epoch 24259, Loss: 87.76029968261719, Neurons: 11, Grad norm: 1.734e+00\n",
      "Epoch 24260, Loss: 87.75218200683594, Neurons: 11, Grad norm: 2.585e+00\n",
      "Epoch 24261, Loss: 87.74407196044922, Neurons: 11, Grad norm: 3.429e+00\n",
      "Epoch 24262, Loss: 87.73596954345703, Neurons: 11, Grad norm: 3.834e+00\n",
      "Epoch 24263, Loss: 87.72785186767578, Neurons: 11, Grad norm: 3.719e+00\n",
      "Epoch 24264, Loss: 87.7197494506836, Neurons: 11, Grad norm: 3.397e+00\n",
      "Epoch 24265, Loss: 87.71160888671875, Neurons: 11, Grad norm: 3.009e+00\n",
      "Epoch 24266, Loss: 87.70349884033203, Neurons: 11, Grad norm: 2.547e+00\n",
      "Epoch 24267, Loss: 87.69535827636719, Neurons: 11, Grad norm: 2.003e+00\n",
      "Epoch 24268, Loss: 87.68724822998047, Neurons: 11, Grad norm: 1.682e+00\n",
      "Epoch 24269, Loss: 87.67910766601562, Neurons: 11, Grad norm: 1.420e+00\n",
      "Epoch 24270, Loss: 87.67097473144531, Neurons: 11, Grad norm: 1.432e+00\n",
      "Epoch 24271, Loss: 87.66284942626953, Neurons: 11, Grad norm: 1.550e+00\n",
      "Epoch 24272, Loss: 87.65470123291016, Neurons: 11, Grad norm: 1.703e+00\n",
      "Epoch 24273, Loss: 87.64656066894531, Neurons: 11, Grad norm: 1.928e+00\n",
      "Epoch 24274, Loss: 87.63842010498047, Neurons: 11, Grad norm: 2.067e+00\n",
      "Epoch 24275, Loss: 87.6302719116211, Neurons: 11, Grad norm: 2.141e+00\n",
      "Epoch 24276, Loss: 87.62212371826172, Neurons: 11, Grad norm: 2.284e+00\n",
      "Epoch 24277, Loss: 87.61397552490234, Neurons: 11, Grad norm: 2.415e+00\n",
      "Epoch 24278, Loss: 87.6058120727539, Neurons: 11, Grad norm: 2.457e+00\n",
      "Epoch 24279, Loss: 87.59765625, Neurons: 11, Grad norm: 2.576e+00\n",
      "Epoch 24280, Loss: 87.5894775390625, Neurons: 11, Grad norm: 2.470e+00\n",
      "Epoch 24281, Loss: 87.5813217163086, Neurons: 11, Grad norm: 2.241e+00\n",
      "Epoch 24282, Loss: 87.57315826416016, Neurons: 11, Grad norm: 1.895e+00\n",
      "Epoch 24283, Loss: 87.56499481201172, Neurons: 11, Grad norm: 1.572e+00\n",
      "Epoch 24284, Loss: 87.55680847167969, Neurons: 11, Grad norm: 1.400e+00\n",
      "Epoch 24285, Loss: 87.54864501953125, Neurons: 11, Grad norm: 1.437e+00\n",
      "Epoch 24286, Loss: 87.54045867919922, Neurons: 11, Grad norm: 1.526e+00\n",
      "Epoch 24287, Loss: 87.53227233886719, Neurons: 11, Grad norm: 1.636e+00\n",
      "Epoch 24288, Loss: 87.52410125732422, Neurons: 11, Grad norm: 1.834e+00\n",
      "Epoch 24289, Loss: 87.51590728759766, Neurons: 11, Grad norm: 2.076e+00\n",
      "Epoch 24290, Loss: 87.50772857666016, Neurons: 11, Grad norm: 2.375e+00\n",
      "Epoch 24291, Loss: 87.49951934814453, Neurons: 11, Grad norm: 2.667e+00\n",
      "Epoch 24292, Loss: 87.49132537841797, Neurons: 11, Grad norm: 3.020e+00\n",
      "Epoch 24293, Loss: 87.48312377929688, Neurons: 11, Grad norm: 3.299e+00\n",
      "Epoch 24294, Loss: 87.47490692138672, Neurons: 11, Grad norm: 3.664e+00\n",
      "Epoch 24295, Loss: 87.46671295166016, Neurons: 11, Grad norm: 4.175e+00\n",
      "Epoch 24296, Loss: 87.45851135253906, Neurons: 11, Grad norm: 4.578e+00\n",
      "Epoch 24297, Loss: 87.4502944946289, Neurons: 11, Grad norm: 4.816e+00\n",
      "Epoch 24298, Loss: 87.44208526611328, Neurons: 11, Grad norm: 5.270e+00\n",
      "Epoch 24299, Loss: 87.43387603759766, Neurons: 11, Grad norm: 5.722e+00\n",
      "Epoch 24299, Test loss: 83.89817810058594\n",
      "Epoch 24300, Loss: 87.42565155029297, Neurons: 11, Grad norm: 6.279e+00\n",
      "Epoch 24301, Loss: 87.41743469238281, Neurons: 11, Grad norm: 6.993e+00\n",
      "Epoch 24302, Loss: 87.40919494628906, Neurons: 11, Grad norm: 7.903e+00\n",
      "Epoch 24303, Loss: 87.40098571777344, Neurons: 11, Grad norm: 8.811e+00\n",
      "Epoch 24304, Loss: 87.39275360107422, Neurons: 11, Grad norm: 9.733e+00\n",
      "Epoch 24305, Loss: 87.384521484375, Neurons: 11, Grad norm: 1.093e+01\n",
      "Epoch 24306, Loss: 87.37628173828125, Neurons: 11, Grad norm: 1.241e+01\n",
      "Epoch 24307, Loss: 87.36805725097656, Neurons: 11, Grad norm: 1.411e+01\n",
      "Epoch 24308, Loss: 87.35983276367188, Neurons: 11, Grad norm: 1.638e+01\n",
      "Epoch 24309, Loss: 87.35160827636719, Neurons: 11, Grad norm: 1.908e+01\n",
      "Epoch 24310, Loss: 87.3433837890625, Neurons: 11, Grad norm: 2.226e+01\n",
      "Epoch 24311, Loss: 87.3351821899414, Neurons: 11, Grad norm: 2.611e+01\n",
      "Epoch 24312, Loss: 87.32698059082031, Neurons: 11, Grad norm: 3.091e+01\n",
      "Epoch 24313, Loss: 87.31879425048828, Neurons: 11, Grad norm: 3.647e+01\n",
      "Epoch 24314, Loss: 87.3106460571289, Neurons: 11, Grad norm: 4.280e+01\n",
      "Epoch 24315, Loss: 87.30253601074219, Neurons: 11, Grad norm: 5.013e+01\n",
      "Epoch 24316, Loss: 87.29444885253906, Neurons: 11, Grad norm: 5.809e+01\n",
      "Epoch 24317, Loss: 87.28642272949219, Neurons: 11, Grad norm: 6.632e+01\n",
      "Epoch 24318, Loss: 87.27845764160156, Neurons: 11, Grad norm: 7.478e+01\n",
      "Epoch 24319, Loss: 87.27053833007812, Neurons: 11, Grad norm: 8.214e+01\n",
      "Epoch 24320, Loss: 87.26262664794922, Neurons: 11, Grad norm: 8.703e+01\n",
      "Epoch 24321, Loss: 87.25469970703125, Neurons: 11, Grad norm: 8.768e+01\n",
      "Epoch 24322, Loss: 87.24661254882812, Neurons: 11, Grad norm: 8.260e+01\n",
      "Epoch 24323, Loss: 87.23834228515625, Neurons: 11, Grad norm: 7.054e+01\n",
      "Epoch 24324, Loss: 87.2298583984375, Neurons: 11, Grad norm: 5.244e+01\n",
      "Epoch 24325, Loss: 87.2213363647461, Neurons: 11, Grad norm: 3.042e+01\n",
      "Epoch 24326, Loss: 87.21287536621094, Neurons: 11, Grad norm: 6.946e+00\n",
      "Epoch 24327, Loss: 87.20465850830078, Neurons: 11, Grad norm: 1.546e+01\n",
      "Epoch 24328, Loss: 87.19668579101562, Neurons: 11, Grad norm: 3.322e+01\n",
      "Epoch 24329, Loss: 87.18888092041016, Neurons: 11, Grad norm: 4.571e+01\n",
      "Epoch 24330, Loss: 87.18109130859375, Neurons: 11, Grad norm: 5.169e+01\n",
      "Epoch 24331, Loss: 87.17321014404297, Neurons: 11, Grad norm: 5.046e+01\n",
      "Epoch 24332, Loss: 87.16519165039062, Neurons: 11, Grad norm: 4.275e+01\n",
      "Epoch 24333, Loss: 87.15703582763672, Neurons: 11, Grad norm: 3.034e+01\n",
      "Epoch 24334, Loss: 87.14883422851562, Neurons: 11, Grad norm: 1.490e+01\n",
      "Epoch 24335, Loss: 87.14070129394531, Neurons: 11, Grad norm: 1.774e+00\n",
      "Epoch 24336, Loss: 87.13265991210938, Neurons: 11, Grad norm: 1.493e+01\n",
      "Epoch 24337, Loss: 87.12472534179688, Neurons: 11, Grad norm: 2.537e+01\n",
      "Epoch 24338, Loss: 87.1168441772461, Neurons: 11, Grad norm: 3.180e+01\n",
      "Epoch 24339, Loss: 87.10893249511719, Neurons: 11, Grad norm: 3.329e+01\n",
      "Epoch 24340, Loss: 87.10096740722656, Neurons: 11, Grad norm: 3.042e+01\n",
      "Epoch 24341, Loss: 87.09294891357422, Neurons: 11, Grad norm: 2.393e+01\n",
      "Epoch 24342, Loss: 87.08486938476562, Neurons: 11, Grad norm: 1.492e+01\n",
      "Epoch 24343, Loss: 87.07681274414062, Neurons: 11, Grad norm: 4.875e+00\n",
      "Epoch 24344, Loss: 87.06878662109375, Neurons: 11, Grad norm: 5.176e+00\n",
      "Epoch 24345, Loss: 87.06079864501953, Neurons: 11, Grad norm: 1.335e+01\n",
      "Epoch 24346, Loss: 87.0528335571289, Neurons: 11, Grad norm: 1.938e+01\n",
      "Epoch 24347, Loss: 87.0448989868164, Neurons: 11, Grad norm: 2.267e+01\n",
      "Epoch 24348, Loss: 87.03693389892578, Neurons: 11, Grad norm: 2.306e+01\n",
      "Epoch 24349, Loss: 87.02893829345703, Neurons: 11, Grad norm: 2.101e+01\n",
      "Epoch 24349, Test loss: 83.51216125488281\n",
      "Epoch 24350, Loss: 87.02091979980469, Neurons: 11, Grad norm: 1.675e+01\n",
      "Epoch 24351, Loss: 87.01290130615234, Neurons: 11, Grad norm: 1.089e+01\n",
      "Epoch 24352, Loss: 87.00485229492188, Neurons: 11, Grad norm: 4.558e+00\n",
      "Epoch 24353, Loss: 86.996826171875, Neurons: 11, Grad norm: 2.427e+00\n",
      "Epoch 24354, Loss: 86.98883056640625, Neurons: 11, Grad norm: 7.829e+00\n",
      "Epoch 24355, Loss: 86.98084259033203, Neurons: 11, Grad norm: 1.211e+01\n",
      "Epoch 24356, Loss: 86.97284698486328, Neurons: 11, Grad norm: 1.497e+01\n",
      "Epoch 24357, Loss: 86.96485137939453, Neurons: 11, Grad norm: 1.629e+01\n",
      "Epoch 24358, Loss: 86.95685577392578, Neurons: 11, Grad norm: 1.616e+01\n",
      "Epoch 24359, Loss: 86.94883728027344, Neurons: 11, Grad norm: 1.441e+01\n",
      "Epoch 24360, Loss: 86.9408187866211, Neurons: 11, Grad norm: 1.172e+01\n",
      "Epoch 24361, Loss: 86.93278503417969, Neurons: 11, Grad norm: 8.445e+00\n",
      "Epoch 24362, Loss: 86.92473602294922, Neurons: 11, Grad norm: 4.850e+00\n",
      "Epoch 24363, Loss: 86.91670989990234, Neurons: 11, Grad norm: 1.682e+00\n",
      "Epoch 24364, Loss: 86.90868377685547, Neurons: 11, Grad norm: 2.718e+00\n",
      "Epoch 24365, Loss: 86.9006576538086, Neurons: 11, Grad norm: 5.260e+00\n",
      "Epoch 24366, Loss: 86.89263153076172, Neurons: 11, Grad norm: 7.504e+00\n",
      "Epoch 24367, Loss: 86.88461303710938, Neurons: 11, Grad norm: 9.043e+00\n",
      "Epoch 24368, Loss: 86.87657165527344, Neurons: 11, Grad norm: 9.677e+00\n",
      "Epoch 24369, Loss: 86.86854553222656, Neurons: 11, Grad norm: 1.005e+01\n",
      "Epoch 24370, Loss: 86.86051177978516, Neurons: 11, Grad norm: 9.874e+00\n",
      "Epoch 24371, Loss: 86.85244750976562, Neurons: 11, Grad norm: 9.103e+00\n",
      "Epoch 24372, Loss: 86.84441375732422, Neurons: 11, Grad norm: 8.090e+00\n",
      "Epoch 24373, Loss: 86.83635711669922, Neurons: 11, Grad norm: 7.109e+00\n",
      "Epoch 24374, Loss: 86.82830810546875, Neurons: 11, Grad norm: 5.827e+00\n",
      "Epoch 24375, Loss: 86.82025146484375, Neurons: 11, Grad norm: 4.506e+00\n",
      "Epoch 24376, Loss: 86.81219482421875, Neurons: 11, Grad norm: 3.327e+00\n",
      "Epoch 24377, Loss: 86.80413818359375, Neurons: 11, Grad norm: 2.104e+00\n",
      "Epoch 24378, Loss: 86.79607391357422, Neurons: 11, Grad norm: 1.408e+00\n",
      "Epoch 24379, Loss: 86.78800964355469, Neurons: 11, Grad norm: 1.862e+00\n",
      "Epoch 24380, Loss: 86.77994537353516, Neurons: 11, Grad norm: 2.648e+00\n",
      "Epoch 24381, Loss: 86.7718734741211, Neurons: 11, Grad norm: 3.554e+00\n",
      "Epoch 24382, Loss: 86.76380920410156, Neurons: 11, Grad norm: 4.210e+00\n",
      "Epoch 24383, Loss: 86.7557373046875, Neurons: 11, Grad norm: 4.432e+00\n",
      "Epoch 24384, Loss: 86.7476577758789, Neurons: 11, Grad norm: 4.697e+00\n",
      "Epoch 24385, Loss: 86.73958587646484, Neurons: 11, Grad norm: 4.841e+00\n",
      "Epoch 24386, Loss: 86.73149871826172, Neurons: 11, Grad norm: 4.819e+00\n",
      "Epoch 24387, Loss: 86.72341918945312, Neurons: 11, Grad norm: 4.965e+00\n",
      "Epoch 24388, Loss: 86.71531677246094, Neurons: 11, Grad norm: 5.193e+00\n",
      "Epoch 24389, Loss: 86.70723724365234, Neurons: 11, Grad norm: 5.051e+00\n",
      "Epoch 24390, Loss: 86.69913482666016, Neurons: 11, Grad norm: 4.870e+00\n",
      "Epoch 24391, Loss: 86.6910400390625, Neurons: 11, Grad norm: 4.587e+00\n",
      "Epoch 24392, Loss: 86.68293762207031, Neurons: 11, Grad norm: 4.195e+00\n",
      "Epoch 24393, Loss: 86.67481994628906, Neurons: 11, Grad norm: 3.626e+00\n",
      "Epoch 24394, Loss: 86.66673278808594, Neurons: 11, Grad norm: 3.107e+00\n",
      "Epoch 24395, Loss: 86.65860748291016, Neurons: 11, Grad norm: 2.632e+00\n",
      "Epoch 24396, Loss: 86.6505126953125, Neurons: 11, Grad norm: 2.148e+00\n",
      "Epoch 24397, Loss: 86.64239501953125, Neurons: 11, Grad norm: 1.875e+00\n",
      "Epoch 24398, Loss: 86.63427734375, Neurons: 11, Grad norm: 1.798e+00\n",
      "Epoch 24399, Loss: 86.62615966796875, Neurons: 11, Grad norm: 1.637e+00\n",
      "Epoch 24399, Test loss: 83.12446594238281\n",
      "Epoch 24400, Loss: 86.61804962158203, Neurons: 11, Grad norm: 1.445e+00\n",
      "Epoch 24401, Loss: 86.60992431640625, Neurons: 11, Grad norm: 1.400e+00\n",
      "Epoch 24402, Loss: 86.60179138183594, Neurons: 11, Grad norm: 1.455e+00\n",
      "Epoch 24403, Loss: 86.5936508178711, Neurons: 11, Grad norm: 1.725e+00\n",
      "Epoch 24404, Loss: 86.58553314208984, Neurons: 11, Grad norm: 1.975e+00\n",
      "Epoch 24405, Loss: 86.57740020751953, Neurons: 11, Grad norm: 2.316e+00\n",
      "Epoch 24406, Loss: 86.56925201416016, Neurons: 11, Grad norm: 2.912e+00\n",
      "Epoch 24407, Loss: 86.56111145019531, Neurons: 11, Grad norm: 3.524e+00\n",
      "Epoch 24408, Loss: 86.55296325683594, Neurons: 11, Grad norm: 4.058e+00\n",
      "Epoch 24409, Loss: 86.5448226928711, Neurons: 11, Grad norm: 4.769e+00\n",
      "Epoch 24410, Loss: 86.53667449951172, Neurons: 11, Grad norm: 5.722e+00\n",
      "Epoch 24411, Loss: 86.52853393554688, Neurons: 11, Grad norm: 6.808e+00\n",
      "Epoch 24412, Loss: 86.52037048339844, Neurons: 11, Grad norm: 8.425e+00\n",
      "Epoch 24413, Loss: 86.51221466064453, Neurons: 11, Grad norm: 1.065e+01\n",
      "Epoch 24414, Loss: 86.50407409667969, Neurons: 11, Grad norm: 1.305e+01\n",
      "Epoch 24415, Loss: 86.49593353271484, Neurons: 11, Grad norm: 1.619e+01\n",
      "Epoch 24416, Loss: 86.4877700805664, Neurons: 11, Grad norm: 2.013e+01\n",
      "Epoch 24417, Loss: 86.47964477539062, Neurons: 11, Grad norm: 2.482e+01\n",
      "Epoch 24418, Loss: 86.47151947021484, Neurons: 11, Grad norm: 3.073e+01\n",
      "Epoch 24419, Loss: 86.46344757080078, Neurons: 11, Grad norm: 3.838e+01\n",
      "Epoch 24420, Loss: 86.45539855957031, Neurons: 11, Grad norm: 4.777e+01\n",
      "Epoch 24421, Loss: 86.4474105834961, Neurons: 11, Grad norm: 5.933e+01\n",
      "Epoch 24422, Loss: 86.43953704833984, Neurons: 11, Grad norm: 7.329e+01\n",
      "Epoch 24423, Loss: 86.43181610107422, Neurons: 11, Grad norm: 8.908e+01\n",
      "Epoch 24424, Loss: 86.42427062988281, Neurons: 11, Grad norm: 1.053e+02\n",
      "Epoch 24425, Loss: 86.41690063476562, Neurons: 11, Grad norm: 1.193e+02\n",
      "Epoch 24426, Loss: 86.40959930419922, Neurons: 11, Grad norm: 1.264e+02\n",
      "Epoch 24427, Loss: 86.4020004272461, Neurons: 11, Grad norm: 1.212e+02\n",
      "Epoch 24428, Loss: 86.393798828125, Neurons: 11, Grad norm: 9.998e+01\n",
      "Epoch 24429, Loss: 86.3848876953125, Neurons: 11, Grad norm: 6.418e+01\n",
      "Epoch 24430, Loss: 86.375732421875, Neurons: 11, Grad norm: 1.977e+01\n",
      "Epoch 24431, Loss: 86.36711120605469, Neurons: 11, Grad norm: 2.414e+01\n",
      "Epoch 24432, Loss: 86.35934448242188, Neurons: 11, Grad norm: 5.888e+01\n",
      "Epoch 24433, Loss: 86.35221099853516, Neurons: 11, Grad norm: 7.848e+01\n",
      "Epoch 24434, Loss: 86.34504699707031, Neurons: 11, Grad norm: 8.013e+01\n",
      "Epoch 24435, Loss: 86.33733367919922, Neurons: 11, Grad norm: 6.379e+01\n",
      "Epoch 24436, Loss: 86.32906341552734, Neurons: 11, Grad norm: 3.439e+01\n",
      "Epoch 24437, Loss: 86.32069396972656, Neurons: 11, Grad norm: 1.434e+00\n",
      "Epoch 24438, Loss: 86.31271362304688, Neurons: 11, Grad norm: 3.147e+01\n",
      "Epoch 24439, Loss: 86.30521392822266, Neurons: 11, Grad norm: 5.233e+01\n",
      "Epoch 24440, Loss: 86.29788208007812, Neurons: 11, Grad norm: 5.861e+01\n",
      "Epoch 24441, Loss: 86.29032897949219, Neurons: 11, Grad norm: 5.003e+01\n",
      "Epoch 24442, Loss: 86.28242492675781, Neurons: 11, Grad norm: 2.988e+01\n",
      "Epoch 24443, Loss: 86.27436065673828, Neurons: 11, Grad norm: 4.572e+00\n",
      "Epoch 24444, Loss: 86.26646423339844, Neurons: 11, Grad norm: 1.985e+01\n",
      "Epoch 24445, Loss: 86.25885772705078, Neurons: 11, Grad norm: 3.674e+01\n",
      "Epoch 24446, Loss: 86.25137329101562, Neurons: 11, Grad norm: 4.304e+01\n",
      "Epoch 24447, Loss: 86.2437973022461, Neurons: 11, Grad norm: 3.788e+01\n",
      "Epoch 24448, Loss: 86.23602294921875, Neurons: 11, Grad norm: 2.393e+01\n",
      "Epoch 24449, Loss: 86.2281265258789, Neurons: 11, Grad norm: 5.390e+00\n",
      "Epoch 24449, Test loss: 82.74115753173828\n",
      "Epoch 24450, Loss: 86.22032928466797, Neurons: 11, Grad norm: 1.306e+01\n",
      "Epoch 24451, Loss: 86.2126693725586, Neurons: 11, Grad norm: 2.621e+01\n",
      "Epoch 24452, Loss: 86.2051010131836, Neurons: 11, Grad norm: 3.174e+01\n",
      "Epoch 24453, Loss: 86.19747161865234, Neurons: 11, Grad norm: 2.926e+01\n",
      "Epoch 24454, Loss: 86.18975067138672, Neurons: 11, Grad norm: 1.995e+01\n",
      "Epoch 24455, Loss: 86.18197631835938, Neurons: 11, Grad norm: 6.803e+00\n",
      "Epoch 24456, Loss: 86.17418670654297, Neurons: 11, Grad norm: 6.992e+00\n",
      "Epoch 24457, Loss: 86.16648864746094, Neurons: 11, Grad norm: 1.728e+01\n",
      "Epoch 24458, Loss: 86.15885925292969, Neurons: 11, Grad norm: 2.277e+01\n",
      "Epoch 24459, Loss: 86.15120697021484, Neurons: 11, Grad norm: 2.233e+01\n",
      "Epoch 24460, Loss: 86.14350128173828, Neurons: 11, Grad norm: 1.681e+01\n",
      "Epoch 24461, Loss: 86.13575744628906, Neurons: 11, Grad norm: 8.111e+00\n",
      "Epoch 24462, Loss: 86.12801361083984, Neurons: 11, Grad norm: 2.180e+00\n",
      "Epoch 24463, Loss: 86.12030792236328, Neurons: 11, Grad norm: 1.023e+01\n",
      "Epoch 24464, Loss: 86.11260986328125, Neurons: 11, Grad norm: 1.530e+01\n",
      "Epoch 24465, Loss: 86.10493469238281, Neurons: 11, Grad norm: 1.662e+01\n",
      "Epoch 24466, Loss: 86.09723663330078, Neurons: 11, Grad norm: 1.408e+01\n",
      "Epoch 24467, Loss: 86.08952331542969, Neurons: 11, Grad norm: 8.854e+00\n",
      "Epoch 24468, Loss: 86.08177947998047, Neurons: 11, Grad norm: 2.494e+00\n",
      "Epoch 24469, Loss: 86.07404327392578, Neurons: 11, Grad norm: 4.593e+00\n",
      "Epoch 24470, Loss: 86.06632232666016, Neurons: 11, Grad norm: 9.430e+00\n",
      "Epoch 24471, Loss: 86.05863189697266, Neurons: 11, Grad norm: 1.210e+01\n",
      "Epoch 24472, Loss: 86.05091094970703, Neurons: 11, Grad norm: 1.221e+01\n",
      "Epoch 24473, Loss: 86.04318237304688, Neurons: 11, Grad norm: 9.995e+00\n",
      "Epoch 24474, Loss: 86.03544616699219, Neurons: 11, Grad norm: 6.073e+00\n",
      "Epoch 24475, Loss: 86.0277099609375, Neurons: 11, Grad norm: 1.833e+00\n",
      "Epoch 24476, Loss: 86.01997375488281, Neurons: 11, Grad norm: 3.666e+00\n",
      "Epoch 24477, Loss: 86.01223754882812, Neurons: 11, Grad norm: 7.201e+00\n",
      "Epoch 24478, Loss: 86.00450897216797, Neurons: 11, Grad norm: 8.877e+00\n",
      "Epoch 24479, Loss: 85.99677276611328, Neurons: 11, Grad norm: 8.972e+00\n",
      "Epoch 24480, Loss: 85.98904418945312, Neurons: 11, Grad norm: 7.437e+00\n",
      "Epoch 24481, Loss: 85.98128509521484, Neurons: 11, Grad norm: 4.888e+00\n",
      "Epoch 24482, Loss: 85.9735336303711, Neurons: 11, Grad norm: 2.021e+00\n",
      "Epoch 24483, Loss: 85.96577453613281, Neurons: 11, Grad norm: 2.113e+00\n",
      "Epoch 24484, Loss: 85.95802307128906, Neurons: 11, Grad norm: 4.395e+00\n",
      "Epoch 24485, Loss: 85.95027160644531, Neurons: 11, Grad norm: 6.092e+00\n",
      "Epoch 24486, Loss: 85.94252014160156, Neurons: 11, Grad norm: 6.721e+00\n",
      "Epoch 24487, Loss: 85.93476104736328, Neurons: 11, Grad norm: 5.972e+00\n",
      "Epoch 24488, Loss: 85.927001953125, Neurons: 11, Grad norm: 4.493e+00\n",
      "Epoch 24489, Loss: 85.91923522949219, Neurons: 11, Grad norm: 2.688e+00\n",
      "Epoch 24490, Loss: 85.91146087646484, Neurons: 11, Grad norm: 1.406e+00\n",
      "Epoch 24491, Loss: 85.90369415283203, Neurons: 11, Grad norm: 2.415e+00\n",
      "Epoch 24492, Loss: 85.89591217041016, Neurons: 11, Grad norm: 3.314e+00\n",
      "Epoch 24493, Loss: 85.88813781738281, Neurons: 11, Grad norm: 3.939e+00\n",
      "Epoch 24494, Loss: 85.88036346435547, Neurons: 11, Grad norm: 3.866e+00\n",
      "Epoch 24495, Loss: 85.87257385253906, Neurons: 11, Grad norm: 3.005e+00\n",
      "Epoch 24496, Loss: 85.86478424072266, Neurons: 11, Grad norm: 2.019e+00\n",
      "Epoch 24497, Loss: 85.85700988769531, Neurons: 11, Grad norm: 1.446e+00\n",
      "Epoch 24498, Loss: 85.8492202758789, Neurons: 11, Grad norm: 1.825e+00\n",
      "Epoch 24499, Loss: 85.84142303466797, Neurons: 11, Grad norm: 2.755e+00\n",
      "Epoch 24499, Test loss: 82.37194061279297\n",
      "Epoch 24500, Loss: 85.8336410522461, Neurons: 11, Grad norm: 3.197e+00\n",
      "Epoch 24501, Loss: 85.8258285522461, Neurons: 11, Grad norm: 3.316e+00\n",
      "Epoch 24502, Loss: 85.81803131103516, Neurons: 11, Grad norm: 3.012e+00\n",
      "Epoch 24503, Loss: 85.81022644042969, Neurons: 11, Grad norm: 2.148e+00\n",
      "Epoch 24504, Loss: 85.80241394042969, Neurons: 11, Grad norm: 1.536e+00\n",
      "Epoch 24505, Loss: 85.79460906982422, Neurons: 11, Grad norm: 1.418e+00\n",
      "Epoch 24506, Loss: 85.78681182861328, Neurons: 11, Grad norm: 1.663e+00\n",
      "Epoch 24507, Loss: 85.77898406982422, Neurons: 11, Grad norm: 2.071e+00\n",
      "Epoch 24508, Loss: 85.77118682861328, Neurons: 11, Grad norm: 1.974e+00\n",
      "Epoch 24509, Loss: 85.76336669921875, Neurons: 11, Grad norm: 1.837e+00\n",
      "Epoch 24510, Loss: 85.75553894042969, Neurons: 11, Grad norm: 1.677e+00\n",
      "Epoch 24511, Loss: 85.74771118164062, Neurons: 11, Grad norm: 1.421e+00\n",
      "Epoch 24512, Loss: 85.73987579345703, Neurons: 11, Grad norm: 1.494e+00\n",
      "Epoch 24513, Loss: 85.73204040527344, Neurons: 11, Grad norm: 1.633e+00\n",
      "Epoch 24514, Loss: 85.72422790527344, Neurons: 11, Grad norm: 1.925e+00\n",
      "Epoch 24515, Loss: 85.71637725830078, Neurons: 11, Grad norm: 2.219e+00\n",
      "Epoch 24516, Loss: 85.70853424072266, Neurons: 11, Grad norm: 2.287e+00\n",
      "Epoch 24517, Loss: 85.70071411132812, Neurons: 11, Grad norm: 2.316e+00\n",
      "Epoch 24518, Loss: 85.6928482055664, Neurons: 11, Grad norm: 2.501e+00\n",
      "Epoch 24519, Loss: 85.68501281738281, Neurons: 11, Grad norm: 2.345e+00\n",
      "Epoch 24520, Loss: 85.67715454101562, Neurons: 11, Grad norm: 2.274e+00\n",
      "Epoch 24521, Loss: 85.6693115234375, Neurons: 11, Grad norm: 2.198e+00\n",
      "Epoch 24522, Loss: 85.66146087646484, Neurons: 11, Grad norm: 2.108e+00\n",
      "Epoch 24523, Loss: 85.65359497070312, Neurons: 11, Grad norm: 1.921e+00\n",
      "Epoch 24524, Loss: 85.64572143554688, Neurons: 11, Grad norm: 1.778e+00\n",
      "Epoch 24525, Loss: 85.63788604736328, Neurons: 11, Grad norm: 1.623e+00\n",
      "Epoch 24526, Loss: 85.63001251220703, Neurons: 11, Grad norm: 1.516e+00\n",
      "Epoch 24527, Loss: 85.62213897705078, Neurons: 11, Grad norm: 1.460e+00\n",
      "Epoch 24528, Loss: 85.61426544189453, Neurons: 11, Grad norm: 1.406e+00\n",
      "Epoch 24529, Loss: 85.60640716552734, Neurons: 11, Grad norm: 1.405e+00\n",
      "Epoch 24530, Loss: 85.59851837158203, Neurons: 11, Grad norm: 1.453e+00\n",
      "Epoch 24531, Loss: 85.59062957763672, Neurons: 11, Grad norm: 1.571e+00\n",
      "Epoch 24532, Loss: 85.58274841308594, Neurons: 11, Grad norm: 1.724e+00\n",
      "Epoch 24533, Loss: 85.57487487792969, Neurons: 11, Grad norm: 1.871e+00\n",
      "Epoch 24534, Loss: 85.56698608398438, Neurons: 11, Grad norm: 2.043e+00\n",
      "Epoch 24535, Loss: 85.55908203125, Neurons: 11, Grad norm: 2.319e+00\n",
      "Epoch 24536, Loss: 85.55120849609375, Neurons: 11, Grad norm: 2.383e+00\n",
      "Epoch 24537, Loss: 85.54329681396484, Neurons: 11, Grad norm: 2.496e+00\n",
      "Epoch 24538, Loss: 85.53540802001953, Neurons: 11, Grad norm: 2.734e+00\n",
      "Epoch 24539, Loss: 85.52751159667969, Neurons: 11, Grad norm: 2.894e+00\n",
      "Epoch 24540, Loss: 85.51959991455078, Neurons: 11, Grad norm: 2.899e+00\n",
      "Epoch 24541, Loss: 85.51168823242188, Neurons: 11, Grad norm: 2.945e+00\n",
      "Epoch 24542, Loss: 85.5037841796875, Neurons: 11, Grad norm: 2.665e+00\n",
      "Epoch 24543, Loss: 85.49588012695312, Neurons: 11, Grad norm: 2.287e+00\n",
      "Epoch 24544, Loss: 85.48795318603516, Neurons: 11, Grad norm: 1.885e+00\n",
      "Epoch 24545, Loss: 85.48004150390625, Neurons: 11, Grad norm: 1.779e+00\n",
      "Epoch 24546, Loss: 85.47212219238281, Neurons: 11, Grad norm: 1.552e+00\n",
      "Epoch 24547, Loss: 85.46419525146484, Neurons: 11, Grad norm: 1.469e+00\n",
      "Epoch 24548, Loss: 85.4562759399414, Neurons: 11, Grad norm: 1.424e+00\n",
      "Epoch 24549, Loss: 85.4483413696289, Neurons: 11, Grad norm: 1.407e+00\n",
      "Epoch 24549, Test loss: 81.99629974365234\n",
      "Epoch 24550, Loss: 85.4404067993164, Neurons: 11, Grad norm: 1.402e+00\n",
      "Epoch 24551, Loss: 85.43247985839844, Neurons: 11, Grad norm: 1.398e+00\n",
      "Epoch 24552, Loss: 85.42454528808594, Neurons: 11, Grad norm: 1.396e+00\n",
      "Epoch 24553, Loss: 85.41659545898438, Neurons: 11, Grad norm: 1.403e+00\n",
      "Epoch 24554, Loss: 85.40866088867188, Neurons: 11, Grad norm: 1.399e+00\n",
      "Epoch 24555, Loss: 85.40071105957031, Neurons: 11, Grad norm: 1.423e+00\n",
      "Epoch 24556, Loss: 85.39277648925781, Neurons: 11, Grad norm: 1.441e+00\n",
      "Epoch 24557, Loss: 85.38483428955078, Neurons: 11, Grad norm: 1.414e+00\n",
      "Epoch 24558, Loss: 85.37687683105469, Neurons: 11, Grad norm: 1.400e+00\n",
      "Epoch 24559, Loss: 85.36891174316406, Neurons: 11, Grad norm: 1.425e+00\n",
      "Epoch 24560, Loss: 85.36094665527344, Neurons: 11, Grad norm: 1.473e+00\n",
      "Epoch 24561, Loss: 85.35299682617188, Neurons: 11, Grad norm: 1.550e+00\n",
      "Epoch 24562, Loss: 85.34503173828125, Neurons: 11, Grad norm: 1.479e+00\n",
      "Epoch 24563, Loss: 85.3370590209961, Neurons: 11, Grad norm: 1.503e+00\n",
      "Epoch 24564, Loss: 85.32908630371094, Neurons: 11, Grad norm: 1.543e+00\n",
      "Epoch 24565, Loss: 85.32112121582031, Neurons: 11, Grad norm: 1.612e+00\n",
      "Epoch 24566, Loss: 85.31315612792969, Neurons: 11, Grad norm: 1.700e+00\n",
      "Epoch 24567, Loss: 85.30517578125, Neurons: 11, Grad norm: 1.916e+00\n",
      "Epoch 24568, Loss: 85.29719543457031, Neurons: 11, Grad norm: 2.167e+00\n",
      "Epoch 24569, Loss: 85.2892074584961, Neurons: 11, Grad norm: 2.617e+00\n",
      "Epoch 24570, Loss: 85.2812271118164, Neurons: 11, Grad norm: 3.250e+00\n",
      "Epoch 24571, Loss: 85.27323913574219, Neurons: 11, Grad norm: 3.975e+00\n",
      "Epoch 24572, Loss: 85.26525115966797, Neurons: 11, Grad norm: 4.688e+00\n",
      "Epoch 24573, Loss: 85.25726318359375, Neurons: 11, Grad norm: 5.625e+00\n",
      "Epoch 24574, Loss: 85.24925231933594, Neurons: 11, Grad norm: 6.665e+00\n",
      "Epoch 24575, Loss: 85.24127197265625, Neurons: 11, Grad norm: 8.312e+00\n",
      "Epoch 24576, Loss: 85.2332763671875, Neurons: 11, Grad norm: 1.043e+01\n",
      "Epoch 24577, Loss: 85.22528839111328, Neurons: 11, Grad norm: 1.341e+01\n",
      "Epoch 24578, Loss: 85.21730041503906, Neurons: 11, Grad norm: 1.751e+01\n",
      "Epoch 24579, Loss: 85.20932006835938, Neurons: 11, Grad norm: 2.296e+01\n",
      "Epoch 24580, Loss: 85.20134735107422, Neurons: 11, Grad norm: 2.994e+01\n",
      "Epoch 24581, Loss: 85.19342041015625, Neurons: 11, Grad norm: 3.943e+01\n",
      "Epoch 24582, Loss: 85.185546875, Neurons: 11, Grad norm: 5.174e+01\n",
      "Epoch 24583, Loss: 85.17779541015625, Neurons: 11, Grad norm: 6.732e+01\n",
      "Epoch 24584, Loss: 85.17021179199219, Neurons: 11, Grad norm: 8.702e+01\n",
      "Epoch 24585, Loss: 85.16288757324219, Neurons: 11, Grad norm: 1.102e+02\n",
      "Epoch 24586, Loss: 85.15592956542969, Neurons: 11, Grad norm: 1.346e+02\n",
      "Epoch 24587, Loss: 85.14932250976562, Neurons: 11, Grad norm: 1.548e+02\n",
      "Epoch 24588, Loss: 85.14278411865234, Neurons: 11, Grad norm: 1.621e+02\n",
      "Epoch 24589, Loss: 85.13554382324219, Neurons: 11, Grad norm: 1.460e+02\n",
      "Epoch 24590, Loss: 85.12683868408203, Neurons: 11, Grad norm: 1.024e+02\n",
      "Epoch 24591, Loss: 85.1169204711914, Neurons: 11, Grad norm: 3.922e+01\n",
      "Epoch 24592, Loss: 85.10746002197266, Neurons: 11, Grad norm: 2.798e+01\n",
      "Epoch 24593, Loss: 85.09976959228516, Neurons: 11, Grad norm: 8.088e+01\n",
      "Epoch 24594, Loss: 85.09351348876953, Neurons: 11, Grad norm: 1.076e+02\n",
      "Epoch 24595, Loss: 85.08711242675781, Neurons: 11, Grad norm: 1.011e+02\n",
      "Epoch 24596, Loss: 85.07936096191406, Neurons: 11, Grad norm: 6.462e+01\n",
      "Epoch 24597, Loss: 85.07062530517578, Neurons: 11, Grad norm: 1.114e+01\n",
      "Epoch 24598, Loss: 85.06233978271484, Neurons: 11, Grad norm: 4.080e+01\n",
      "Epoch 24599, Loss: 85.05525970458984, Neurons: 11, Grad norm: 7.463e+01\n",
      "Epoch 24599, Test loss: 81.62612915039062\n",
      "Epoch 24600, Loss: 85.04872131347656, Neurons: 11, Grad norm: 8.089e+01\n",
      "Epoch 24601, Loss: 85.04153442382812, Neurons: 11, Grad norm: 5.913e+01\n",
      "Epoch 24602, Loss: 85.03350830078125, Neurons: 11, Grad norm: 1.910e+01\n",
      "Epoch 24603, Loss: 85.02547454833984, Neurons: 11, Grad norm: 2.325e+01\n",
      "Epoch 24604, Loss: 85.01815032958984, Neurons: 11, Grad norm: 5.336e+01\n",
      "Epoch 24605, Loss: 85.01129913330078, Neurons: 11, Grad norm: 6.164e+01\n",
      "Epoch 24606, Loss: 85.004150390625, Neurons: 11, Grad norm: 4.701e+01\n",
      "Epoch 24607, Loss: 84.9964599609375, Neurons: 11, Grad norm: 1.715e+01\n",
      "Epoch 24608, Loss: 84.98870086669922, Neurons: 11, Grad norm: 1.592e+01\n",
      "Epoch 24609, Loss: 84.98136901855469, Neurons: 11, Grad norm: 4.032e+01\n",
      "Epoch 24610, Loss: 84.97431945800781, Neurons: 11, Grad norm: 4.774e+01\n",
      "Epoch 24611, Loss: 84.96713256835938, Neurons: 11, Grad norm: 3.748e+01\n",
      "Epoch 24612, Loss: 84.95960235595703, Neurons: 11, Grad norm: 1.479e+01\n",
      "Epoch 24613, Loss: 84.9520263671875, Neurons: 11, Grad norm: 1.103e+01\n",
      "Epoch 24614, Loss: 84.9446792602539, Neurons: 11, Grad norm: 3.042e+01\n",
      "Epoch 24615, Loss: 84.93750762939453, Neurons: 11, Grad norm: 3.687e+01\n",
      "Epoch 24616, Loss: 84.93026733398438, Neurons: 11, Grad norm: 2.978e+01\n",
      "Epoch 24617, Loss: 84.92283630371094, Neurons: 11, Grad norm: 1.300e+01\n",
      "Epoch 24618, Loss: 84.91535949707031, Neurons: 11, Grad norm: 6.908e+00\n",
      "Epoch 24619, Loss: 84.90799713134766, Neurons: 11, Grad norm: 2.235e+01\n",
      "Epoch 24620, Loss: 84.9007568359375, Neurons: 11, Grad norm: 2.841e+01\n",
      "Epoch 24621, Loss: 84.89350128173828, Neurons: 11, Grad norm: 2.427e+01\n",
      "Epoch 24622, Loss: 84.88610076904297, Neurons: 11, Grad norm: 1.224e+01\n",
      "Epoch 24623, Loss: 84.87866973876953, Neurons: 11, Grad norm: 3.322e+00\n",
      "Epoch 24624, Loss: 84.87130737304688, Neurons: 11, Grad norm: 1.602e+01\n",
      "Epoch 24625, Loss: 84.86402893066406, Neurons: 11, Grad norm: 2.198e+01\n",
      "Epoch 24626, Loss: 84.85671997070312, Neurons: 11, Grad norm: 2.031e+01\n",
      "Epoch 24627, Loss: 84.84937286376953, Neurons: 11, Grad norm: 1.183e+01\n",
      "Epoch 24628, Loss: 84.84197998046875, Neurons: 11, Grad norm: 1.411e+00\n",
      "Epoch 24629, Loss: 84.8345947265625, Neurons: 11, Grad norm: 1.059e+01\n",
      "Epoch 24630, Loss: 84.8272705078125, Neurons: 11, Grad norm: 1.624e+01\n",
      "Epoch 24631, Loss: 84.81995391845703, Neurons: 11, Grad norm: 1.611e+01\n",
      "Epoch 24632, Loss: 84.81259155273438, Neurons: 11, Grad norm: 1.065e+01\n",
      "Epoch 24633, Loss: 84.80521392822266, Neurons: 11, Grad norm: 2.368e+00\n",
      "Epoch 24634, Loss: 84.79784393310547, Neurons: 11, Grad norm: 6.486e+00\n",
      "Epoch 24635, Loss: 84.79048156738281, Neurons: 11, Grad norm: 1.182e+01\n",
      "Epoch 24636, Loss: 84.78314971923828, Neurons: 11, Grad norm: 1.310e+01\n",
      "Epoch 24637, Loss: 84.77577209472656, Neurons: 11, Grad norm: 9.920e+00\n",
      "Epoch 24638, Loss: 84.76839447021484, Neurons: 11, Grad norm: 4.295e+00\n",
      "Epoch 24639, Loss: 84.7610092163086, Neurons: 11, Grad norm: 2.919e+00\n",
      "Epoch 24640, Loss: 84.7536392211914, Neurons: 11, Grad norm: 7.696e+00\n",
      "Epoch 24641, Loss: 84.74628448486328, Neurons: 11, Grad norm: 9.836e+00\n",
      "Epoch 24642, Loss: 84.73889923095703, Neurons: 11, Grad norm: 8.563e+00\n",
      "Epoch 24643, Loss: 84.73151397705078, Neurons: 11, Grad norm: 4.877e+00\n",
      "Epoch 24644, Loss: 84.7241439819336, Neurons: 11, Grad norm: 1.467e+00\n",
      "Epoch 24645, Loss: 84.71675109863281, Neurons: 11, Grad norm: 4.960e+00\n",
      "Epoch 24646, Loss: 84.70935821533203, Neurons: 11, Grad norm: 7.593e+00\n",
      "Epoch 24647, Loss: 84.70198059082031, Neurons: 11, Grad norm: 7.864e+00\n",
      "Epoch 24648, Loss: 84.69459533691406, Neurons: 11, Grad norm: 6.041e+00\n",
      "Epoch 24649, Loss: 84.68718719482422, Neurons: 11, Grad norm: 2.806e+00\n",
      "Epoch 24649, Test loss: 81.266845703125\n",
      "Epoch 24650, Loss: 84.67979431152344, Neurons: 11, Grad norm: 1.750e+00\n",
      "Epoch 24651, Loss: 84.67239379882812, Neurons: 11, Grad norm: 4.192e+00\n",
      "Epoch 24652, Loss: 84.66500091552734, Neurons: 11, Grad norm: 5.505e+00\n",
      "Epoch 24653, Loss: 84.65760040283203, Neurons: 11, Grad norm: 5.257e+00\n",
      "Epoch 24654, Loss: 84.65018463134766, Neurons: 11, Grad norm: 3.616e+00\n",
      "Epoch 24655, Loss: 84.64277648925781, Neurons: 11, Grad norm: 1.864e+00\n",
      "Epoch 24656, Loss: 84.63536071777344, Neurons: 11, Grad norm: 1.791e+00\n",
      "Epoch 24657, Loss: 84.62794494628906, Neurons: 11, Grad norm: 3.001e+00\n",
      "Epoch 24658, Loss: 84.62053680419922, Neurons: 11, Grad norm: 3.678e+00\n",
      "Epoch 24659, Loss: 84.61312103271484, Neurons: 11, Grad norm: 3.194e+00\n",
      "Epoch 24660, Loss: 84.60569763183594, Neurons: 11, Grad norm: 2.199e+00\n",
      "Epoch 24661, Loss: 84.59825897216797, Neurons: 11, Grad norm: 1.408e+00\n",
      "Epoch 24662, Loss: 84.59085083007812, Neurons: 11, Grad norm: 2.226e+00\n",
      "Epoch 24663, Loss: 84.58341979980469, Neurons: 11, Grad norm: 3.002e+00\n",
      "Epoch 24664, Loss: 84.57598876953125, Neurons: 11, Grad norm: 3.051e+00\n",
      "Epoch 24665, Loss: 84.56855773925781, Neurons: 11, Grad norm: 2.667e+00\n",
      "Epoch 24666, Loss: 84.56111907958984, Neurons: 11, Grad norm: 1.941e+00\n",
      "Epoch 24667, Loss: 84.55367279052734, Neurons: 11, Grad norm: 1.424e+00\n",
      "Epoch 24668, Loss: 84.54622650146484, Neurons: 11, Grad norm: 1.467e+00\n",
      "Epoch 24669, Loss: 84.53878784179688, Neurons: 11, Grad norm: 1.630e+00\n",
      "Epoch 24670, Loss: 84.5313491821289, Neurons: 11, Grad norm: 1.966e+00\n",
      "Epoch 24671, Loss: 84.52389526367188, Neurons: 11, Grad norm: 2.060e+00\n",
      "Epoch 24672, Loss: 84.51644897460938, Neurons: 11, Grad norm: 2.032e+00\n",
      "Epoch 24673, Loss: 84.50898742675781, Neurons: 11, Grad norm: 1.820e+00\n",
      "Epoch 24674, Loss: 84.50151824951172, Neurons: 11, Grad norm: 1.732e+00\n",
      "Epoch 24675, Loss: 84.49407196044922, Neurons: 11, Grad norm: 1.433e+00\n",
      "Epoch 24676, Loss: 84.48661041259766, Neurons: 11, Grad norm: 1.435e+00\n",
      "Epoch 24677, Loss: 84.47914123535156, Neurons: 11, Grad norm: 1.553e+00\n",
      "Epoch 24678, Loss: 84.47166442871094, Neurons: 11, Grad norm: 1.625e+00\n",
      "Epoch 24679, Loss: 84.46420288085938, Neurons: 11, Grad norm: 1.640e+00\n",
      "Epoch 24680, Loss: 84.45671844482422, Neurons: 11, Grad norm: 1.506e+00\n",
      "Epoch 24681, Loss: 84.44925689697266, Neurons: 11, Grad norm: 1.497e+00\n",
      "Epoch 24682, Loss: 84.4417724609375, Neurons: 11, Grad norm: 1.449e+00\n",
      "Epoch 24683, Loss: 84.43428802490234, Neurons: 11, Grad norm: 1.419e+00\n",
      "Epoch 24684, Loss: 84.42680358886719, Neurons: 11, Grad norm: 1.405e+00\n",
      "Epoch 24685, Loss: 84.41931915283203, Neurons: 11, Grad norm: 1.413e+00\n",
      "Epoch 24686, Loss: 84.41182708740234, Neurons: 11, Grad norm: 1.491e+00\n",
      "Epoch 24687, Loss: 84.40435028076172, Neurons: 11, Grad norm: 1.498e+00\n",
      "Epoch 24688, Loss: 84.39683532714844, Neurons: 11, Grad norm: 1.559e+00\n",
      "Epoch 24689, Loss: 84.38935089111328, Neurons: 11, Grad norm: 1.648e+00\n",
      "Epoch 24690, Loss: 84.3818588256836, Neurons: 11, Grad norm: 1.783e+00\n",
      "Epoch 24691, Loss: 84.37435150146484, Neurons: 11, Grad norm: 1.855e+00\n",
      "Epoch 24692, Loss: 84.3668441772461, Neurons: 11, Grad norm: 1.820e+00\n",
      "Epoch 24693, Loss: 84.35933685302734, Neurons: 11, Grad norm: 1.815e+00\n",
      "Epoch 24694, Loss: 84.35182189941406, Neurons: 11, Grad norm: 1.673e+00\n",
      "Epoch 24695, Loss: 84.34430694580078, Neurons: 11, Grad norm: 1.490e+00\n",
      "Epoch 24696, Loss: 84.33680725097656, Neurons: 11, Grad norm: 1.429e+00\n",
      "Epoch 24697, Loss: 84.32927703857422, Neurons: 11, Grad norm: 1.410e+00\n",
      "Epoch 24698, Loss: 84.32176208496094, Neurons: 11, Grad norm: 1.447e+00\n",
      "Epoch 24699, Loss: 84.3142318725586, Neurons: 11, Grad norm: 1.465e+00\n",
      "Epoch 24699, Test loss: 80.9105224609375\n",
      "Epoch 24700, Loss: 84.30670166015625, Neurons: 11, Grad norm: 1.413e+00\n",
      "Epoch 24701, Loss: 84.29918670654297, Neurons: 11, Grad norm: 1.446e+00\n",
      "Epoch 24702, Loss: 84.29166412353516, Neurons: 11, Grad norm: 1.404e+00\n",
      "Epoch 24703, Loss: 84.28412628173828, Neurons: 11, Grad norm: 1.416e+00\n",
      "Epoch 24704, Loss: 84.2765884399414, Neurons: 11, Grad norm: 1.417e+00\n",
      "Epoch 24705, Loss: 84.26905059814453, Neurons: 11, Grad norm: 1.442e+00\n",
      "Epoch 24706, Loss: 84.2614974975586, Neurons: 11, Grad norm: 1.475e+00\n",
      "Epoch 24707, Loss: 84.25395202636719, Neurons: 11, Grad norm: 1.695e+00\n",
      "Epoch 24708, Loss: 84.24641418457031, Neurons: 11, Grad norm: 1.880e+00\n",
      "Epoch 24709, Loss: 84.2388687133789, Neurons: 11, Grad norm: 1.886e+00\n",
      "Epoch 24710, Loss: 84.23130798339844, Neurons: 11, Grad norm: 1.688e+00\n",
      "Epoch 24711, Loss: 84.22376251220703, Neurons: 11, Grad norm: 1.678e+00\n",
      "Epoch 24712, Loss: 84.2162094116211, Neurons: 11, Grad norm: 1.427e+00\n",
      "Epoch 24713, Loss: 84.20864868164062, Neurons: 11, Grad norm: 1.413e+00\n",
      "Epoch 24714, Loss: 84.2010726928711, Neurons: 11, Grad norm: 1.502e+00\n",
      "Epoch 24715, Loss: 84.19351959228516, Neurons: 11, Grad norm: 1.659e+00\n",
      "Epoch 24716, Loss: 84.18595886230469, Neurons: 11, Grad norm: 1.730e+00\n",
      "Epoch 24717, Loss: 84.17837524414062, Neurons: 11, Grad norm: 1.656e+00\n",
      "Epoch 24718, Loss: 84.17080688476562, Neurons: 11, Grad norm: 1.684e+00\n",
      "Epoch 24719, Loss: 84.16323852539062, Neurons: 11, Grad norm: 1.628e+00\n",
      "Epoch 24720, Loss: 84.15564727783203, Neurons: 11, Grad norm: 1.463e+00\n",
      "Epoch 24721, Loss: 84.1480712890625, Neurons: 11, Grad norm: 1.402e+00\n",
      "Epoch 24722, Loss: 84.14049530029297, Neurons: 11, Grad norm: 1.421e+00\n",
      "Epoch 24723, Loss: 84.1329116821289, Neurons: 11, Grad norm: 1.563e+00\n",
      "Epoch 24724, Loss: 84.12531280517578, Neurons: 11, Grad norm: 1.664e+00\n",
      "Epoch 24725, Loss: 84.11772918701172, Neurons: 11, Grad norm: 1.968e+00\n",
      "Epoch 24726, Loss: 84.11013793945312, Neurons: 11, Grad norm: 2.409e+00\n",
      "Epoch 24727, Loss: 84.10253143310547, Neurons: 11, Grad norm: 2.861e+00\n",
      "Epoch 24728, Loss: 84.09494018554688, Neurons: 11, Grad norm: 2.907e+00\n",
      "Epoch 24729, Loss: 84.08735656738281, Neurons: 11, Grad norm: 3.062e+00\n",
      "Epoch 24730, Loss: 84.0797348022461, Neurons: 11, Grad norm: 3.247e+00\n",
      "Epoch 24731, Loss: 84.0721435546875, Neurons: 11, Grad norm: 3.097e+00\n",
      "Epoch 24732, Loss: 84.06452941894531, Neurons: 11, Grad norm: 2.942e+00\n",
      "Epoch 24733, Loss: 84.05692291259766, Neurons: 11, Grad norm: 2.650e+00\n",
      "Epoch 24734, Loss: 84.04930114746094, Neurons: 11, Grad norm: 1.939e+00\n",
      "Epoch 24735, Loss: 84.04169464111328, Neurons: 11, Grad norm: 1.565e+00\n",
      "Epoch 24736, Loss: 84.0340805053711, Neurons: 11, Grad norm: 1.412e+00\n",
      "Epoch 24737, Loss: 84.02644348144531, Neurons: 11, Grad norm: 1.708e+00\n",
      "Epoch 24738, Loss: 84.01881408691406, Neurons: 11, Grad norm: 2.226e+00\n",
      "Epoch 24739, Loss: 84.01119995117188, Neurons: 11, Grad norm: 2.682e+00\n",
      "Epoch 24740, Loss: 84.0035629272461, Neurons: 11, Grad norm: 3.434e+00\n",
      "Epoch 24741, Loss: 83.99593353271484, Neurons: 11, Grad norm: 3.931e+00\n",
      "Epoch 24742, Loss: 83.98828887939453, Neurons: 11, Grad norm: 4.451e+00\n",
      "Epoch 24743, Loss: 83.98067474365234, Neurons: 11, Grad norm: 4.806e+00\n",
      "Epoch 24744, Loss: 83.9730224609375, Neurons: 11, Grad norm: 5.169e+00\n",
      "Epoch 24745, Loss: 83.96538543701172, Neurons: 11, Grad norm: 5.152e+00\n",
      "Epoch 24746, Loss: 83.95772552490234, Neurons: 11, Grad norm: 5.259e+00\n",
      "Epoch 24747, Loss: 83.9500961303711, Neurons: 11, Grad norm: 5.230e+00\n",
      "Epoch 24748, Loss: 83.94244384765625, Neurons: 11, Grad norm: 4.892e+00\n",
      "Epoch 24749, Loss: 83.93479919433594, Neurons: 11, Grad norm: 4.490e+00\n",
      "Epoch 24749, Test loss: 80.54745483398438\n",
      "Epoch 24750, Loss: 83.92713165283203, Neurons: 11, Grad norm: 4.389e+00\n",
      "Epoch 24751, Loss: 83.91948699951172, Neurons: 11, Grad norm: 3.955e+00\n",
      "Epoch 24752, Loss: 83.91181945800781, Neurons: 11, Grad norm: 3.744e+00\n",
      "Epoch 24753, Loss: 83.9041519165039, Neurons: 11, Grad norm: 3.414e+00\n",
      "Epoch 24754, Loss: 83.896484375, Neurons: 11, Grad norm: 3.085e+00\n",
      "Epoch 24755, Loss: 83.88882446289062, Neurons: 11, Grad norm: 2.471e+00\n",
      "Epoch 24756, Loss: 83.88114929199219, Neurons: 11, Grad norm: 2.298e+00\n",
      "Epoch 24757, Loss: 83.87346649169922, Neurons: 11, Grad norm: 2.066e+00\n",
      "Epoch 24758, Loss: 83.86579895019531, Neurons: 11, Grad norm: 1.888e+00\n",
      "Epoch 24759, Loss: 83.85812377929688, Neurons: 11, Grad norm: 1.719e+00\n",
      "Epoch 24760, Loss: 83.85043334960938, Neurons: 11, Grad norm: 1.616e+00\n",
      "Epoch 24761, Loss: 83.84275817871094, Neurons: 11, Grad norm: 1.437e+00\n",
      "Epoch 24762, Loss: 83.8350830078125, Neurons: 11, Grad norm: 1.396e+00\n",
      "Epoch 24763, Loss: 83.82738494873047, Neurons: 11, Grad norm: 1.401e+00\n",
      "Epoch 24764, Loss: 83.81969451904297, Neurons: 11, Grad norm: 1.414e+00\n",
      "Epoch 24765, Loss: 83.81199645996094, Neurons: 11, Grad norm: 1.421e+00\n",
      "Epoch 24766, Loss: 83.80431365966797, Neurons: 11, Grad norm: 1.525e+00\n",
      "Epoch 24767, Loss: 83.79660034179688, Neurons: 11, Grad norm: 1.549e+00\n",
      "Epoch 24768, Loss: 83.78889465332031, Neurons: 11, Grad norm: 1.610e+00\n",
      "Epoch 24769, Loss: 83.78119659423828, Neurons: 11, Grad norm: 1.651e+00\n",
      "Epoch 24770, Loss: 83.77350616455078, Neurons: 11, Grad norm: 1.848e+00\n",
      "Epoch 24771, Loss: 83.76578521728516, Neurons: 11, Grad norm: 2.067e+00\n",
      "Epoch 24772, Loss: 83.75807189941406, Neurons: 11, Grad norm: 2.464e+00\n",
      "Epoch 24773, Loss: 83.75035858154297, Neurons: 11, Grad norm: 2.992e+00\n",
      "Epoch 24774, Loss: 83.74263763427734, Neurons: 11, Grad norm: 3.684e+00\n",
      "Epoch 24775, Loss: 83.73493194580078, Neurons: 11, Grad norm: 4.415e+00\n",
      "Epoch 24776, Loss: 83.7271957397461, Neurons: 11, Grad norm: 5.388e+00\n",
      "Epoch 24777, Loss: 83.719482421875, Neurons: 11, Grad norm: 6.445e+00\n",
      "Epoch 24778, Loss: 83.71174621582031, Neurons: 11, Grad norm: 7.847e+00\n",
      "Epoch 24779, Loss: 83.70403289794922, Neurons: 11, Grad norm: 9.584e+00\n",
      "Epoch 24780, Loss: 83.69629669189453, Neurons: 11, Grad norm: 1.207e+01\n",
      "Epoch 24781, Loss: 83.68858337402344, Neurons: 11, Grad norm: 1.507e+01\n",
      "Epoch 24782, Loss: 83.68084716796875, Neurons: 11, Grad norm: 1.924e+01\n",
      "Epoch 24783, Loss: 83.67314910888672, Neurons: 11, Grad norm: 2.436e+01\n",
      "Epoch 24784, Loss: 83.66545104980469, Neurons: 11, Grad norm: 3.105e+01\n",
      "Epoch 24785, Loss: 83.65779113769531, Neurons: 11, Grad norm: 3.987e+01\n",
      "Epoch 24786, Loss: 83.65018463134766, Neurons: 11, Grad norm: 5.130e+01\n",
      "Epoch 24787, Loss: 83.64265441894531, Neurons: 11, Grad norm: 6.561e+01\n",
      "Epoch 24788, Loss: 83.63526916503906, Neurons: 11, Grad norm: 8.372e+01\n",
      "Epoch 24789, Loss: 83.62812042236328, Neurons: 11, Grad norm: 1.049e+02\n",
      "Epoch 24790, Loss: 83.62126159667969, Neurons: 11, Grad norm: 1.275e+02\n",
      "Epoch 24791, Loss: 83.61470031738281, Neurons: 11, Grad norm: 1.476e+02\n",
      "Epoch 24792, Loss: 83.60824584960938, Neurons: 11, Grad norm: 1.580e+02\n",
      "Epoch 24793, Loss: 83.60138702392578, Neurons: 11, Grad norm: 1.498e+02\n",
      "Epoch 24794, Loss: 83.59343719482422, Neurons: 11, Grad norm: 1.179e+02\n",
      "Epoch 24795, Loss: 83.58431243896484, Neurons: 11, Grad norm: 6.491e+01\n",
      "Epoch 24796, Loss: 83.57499694824219, Neurons: 11, Grad norm: 3.215e+00\n",
      "Epoch 24797, Loss: 83.56683349609375, Neurons: 11, Grad norm: 5.371e+01\n",
      "Epoch 24798, Loss: 83.56012725830078, Neurons: 11, Grad norm: 9.196e+01\n",
      "Epoch 24799, Loss: 83.55398559570312, Neurons: 11, Grad norm: 1.042e+02\n",
      "Epoch 24799, Test loss: 80.19291687011719\n",
      "Epoch 24800, Loss: 83.54721069335938, Neurons: 11, Grad norm: 8.776e+01\n",
      "Epoch 24801, Loss: 83.53931427001953, Neurons: 11, Grad norm: 4.905e+01\n",
      "Epoch 24802, Loss: 83.53102111816406, Neurons: 11, Grad norm: 1.418e+00\n",
      "Epoch 24803, Loss: 83.52332305908203, Neurons: 11, Grad norm: 4.421e+01\n",
      "Epoch 24804, Loss: 83.51651000976562, Neurons: 11, Grad norm: 7.138e+01\n",
      "Epoch 24805, Loss: 83.50996398925781, Neurons: 11, Grad norm: 7.468e+01\n",
      "Epoch 24806, Loss: 83.50286865234375, Neurons: 11, Grad norm: 5.531e+01\n",
      "Epoch 24807, Loss: 83.49518585205078, Neurons: 11, Grad norm: 2.080e+01\n",
      "Epoch 24808, Loss: 83.48745727539062, Neurons: 11, Grad norm: 1.674e+01\n",
      "Epoch 24809, Loss: 83.48026275634766, Neurons: 11, Grad norm: 4.530e+01\n",
      "Epoch 24810, Loss: 83.47345733642578, Neurons: 11, Grad norm: 5.716e+01\n",
      "Epoch 24811, Loss: 83.46654510498047, Neurons: 11, Grad norm: 5.027e+01\n",
      "Epoch 24812, Loss: 83.45923614501953, Neurons: 11, Grad norm: 2.806e+01\n",
      "Epoch 24813, Loss: 83.45172119140625, Neurons: 11, Grad norm: 1.538e+00\n",
      "Epoch 24814, Loss: 83.44439697265625, Neurons: 11, Grad norm: 2.658e+01\n",
      "Epoch 24815, Loss: 83.43739318847656, Neurons: 11, Grad norm: 4.149e+01\n",
      "Epoch 24816, Loss: 83.43045043945312, Neurons: 11, Grad norm: 4.226e+01\n",
      "Epoch 24817, Loss: 83.42330932617188, Neurons: 11, Grad norm: 2.934e+01\n",
      "Epoch 24818, Loss: 83.41596984863281, Neurons: 11, Grad norm: 8.880e+00\n",
      "Epoch 24819, Loss: 83.40864562988281, Neurons: 11, Grad norm: 1.279e+01\n",
      "Epoch 24820, Loss: 83.40151977539062, Neurons: 11, Grad norm: 2.820e+01\n",
      "Epoch 24821, Loss: 83.39450073242188, Neurons: 11, Grad norm: 3.360e+01\n",
      "Epoch 24822, Loss: 83.38739776611328, Neurons: 11, Grad norm: 2.803e+01\n",
      "Epoch 24823, Loss: 83.38018035888672, Neurons: 11, Grad norm: 1.482e+01\n",
      "Epoch 24824, Loss: 83.37290954589844, Neurons: 11, Grad norm: 2.329e+00\n",
      "Epoch 24825, Loss: 83.36572265625, Neurons: 11, Grad norm: 1.608e+01\n",
      "Epoch 24826, Loss: 83.3586196899414, Neurons: 11, Grad norm: 2.405e+01\n",
      "Epoch 24827, Loss: 83.35152435302734, Neurons: 11, Grad norm: 2.392e+01\n",
      "Epoch 24828, Loss: 83.3443603515625, Neurons: 11, Grad norm: 1.676e+01\n",
      "Epoch 24829, Loss: 83.33712768554688, Neurons: 11, Grad norm: 5.303e+00\n",
      "Epoch 24830, Loss: 83.32991027832031, Neurons: 11, Grad norm: 6.729e+00\n",
      "Epoch 24831, Loss: 83.32275390625, Neurons: 11, Grad norm: 1.560e+01\n",
      "Epoch 24832, Loss: 83.31562042236328, Neurons: 11, Grad norm: 1.891e+01\n",
      "Epoch 24833, Loss: 83.30847930908203, Neurons: 11, Grad norm: 1.649e+01\n",
      "Epoch 24834, Loss: 83.30130004882812, Neurons: 11, Grad norm: 9.453e+00\n",
      "Epoch 24835, Loss: 83.29407501220703, Neurons: 11, Grad norm: 1.437e+00\n",
      "Epoch 24836, Loss: 83.2868881225586, Neurons: 11, Grad norm: 8.492e+00\n",
      "Epoch 24837, Loss: 83.27972412109375, Neurons: 11, Grad norm: 1.383e+01\n",
      "Epoch 24838, Loss: 83.2725601196289, Neurons: 11, Grad norm: 1.507e+01\n",
      "Epoch 24839, Loss: 83.26539611816406, Neurons: 11, Grad norm: 1.190e+01\n",
      "Epoch 24840, Loss: 83.25819396972656, Neurons: 11, Grad norm: 6.011e+00\n",
      "Epoch 24841, Loss: 83.25098419189453, Neurons: 11, Grad norm: 1.860e+00\n",
      "Epoch 24842, Loss: 83.2437973022461, Neurons: 11, Grad norm: 7.244e+00\n",
      "Epoch 24843, Loss: 83.23661041259766, Neurons: 11, Grad norm: 1.072e+01\n",
      "Epoch 24844, Loss: 83.22943115234375, Neurons: 11, Grad norm: 1.086e+01\n",
      "Epoch 24845, Loss: 83.22223663330078, Neurons: 11, Grad norm: 8.320e+00\n",
      "Epoch 24846, Loss: 83.21503448486328, Neurons: 11, Grad norm: 3.852e+00\n",
      "Epoch 24847, Loss: 83.20782470703125, Neurons: 11, Grad norm: 2.065e+00\n",
      "Epoch 24848, Loss: 83.20060729980469, Neurons: 11, Grad norm: 6.166e+00\n",
      "Epoch 24849, Loss: 83.19341278076172, Neurons: 11, Grad norm: 8.432e+00\n",
      "Epoch 24849, Test loss: 79.83714294433594\n",
      "Epoch 24850, Loss: 83.18622589111328, Neurons: 11, Grad norm: 8.563e+00\n",
      "Epoch 24851, Loss: 83.17900848388672, Neurons: 11, Grad norm: 6.727e+00\n",
      "Epoch 24852, Loss: 83.17178344726562, Neurons: 11, Grad norm: 3.735e+00\n",
      "Epoch 24853, Loss: 83.1645736694336, Neurons: 11, Grad norm: 1.604e+00\n",
      "Epoch 24854, Loss: 83.15736389160156, Neurons: 11, Grad norm: 4.151e+00\n",
      "Epoch 24855, Loss: 83.15013885498047, Neurons: 11, Grad norm: 6.184e+00\n",
      "Epoch 24856, Loss: 83.1429214477539, Neurons: 11, Grad norm: 6.693e+00\n",
      "Epoch 24857, Loss: 83.13569641113281, Neurons: 11, Grad norm: 5.660e+00\n",
      "Epoch 24858, Loss: 83.12847137451172, Neurons: 11, Grad norm: 3.071e+00\n",
      "Epoch 24859, Loss: 83.12124633789062, Neurons: 11, Grad norm: 1.410e+00\n",
      "Epoch 24860, Loss: 83.11399841308594, Neurons: 11, Grad norm: 3.058e+00\n",
      "Epoch 24861, Loss: 83.10677337646484, Neurons: 11, Grad norm: 5.014e+00\n",
      "Epoch 24862, Loss: 83.09954833984375, Neurons: 11, Grad norm: 6.061e+00\n",
      "Epoch 24863, Loss: 83.09229278564453, Neurons: 11, Grad norm: 5.460e+00\n",
      "Epoch 24864, Loss: 83.0850601196289, Neurons: 11, Grad norm: 4.214e+00\n",
      "Epoch 24865, Loss: 83.07781219482422, Neurons: 11, Grad norm: 2.221e+00\n",
      "Epoch 24866, Loss: 83.070556640625, Neurons: 11, Grad norm: 1.577e+00\n",
      "Epoch 24867, Loss: 83.06330108642578, Neurons: 11, Grad norm: 3.017e+00\n",
      "Epoch 24868, Loss: 83.0560531616211, Neurons: 11, Grad norm: 3.933e+00\n",
      "Epoch 24869, Loss: 83.04881286621094, Neurons: 11, Grad norm: 4.393e+00\n",
      "Epoch 24870, Loss: 83.04155731201172, Neurons: 11, Grad norm: 3.703e+00\n",
      "Epoch 24871, Loss: 83.03429412841797, Neurons: 11, Grad norm: 2.606e+00\n",
      "Epoch 24872, Loss: 83.02703857421875, Neurons: 11, Grad norm: 1.602e+00\n",
      "Epoch 24873, Loss: 83.019775390625, Neurons: 11, Grad norm: 1.507e+00\n",
      "Epoch 24874, Loss: 83.01251220703125, Neurons: 11, Grad norm: 2.299e+00\n",
      "Epoch 24875, Loss: 83.00523376464844, Neurons: 11, Grad norm: 2.708e+00\n",
      "Epoch 24876, Loss: 82.99797821044922, Neurons: 11, Grad norm: 2.813e+00\n",
      "Epoch 24877, Loss: 82.9906997680664, Neurons: 11, Grad norm: 2.375e+00\n",
      "Epoch 24878, Loss: 82.98341369628906, Neurons: 11, Grad norm: 1.759e+00\n",
      "Epoch 24879, Loss: 82.97615051269531, Neurons: 11, Grad norm: 1.401e+00\n",
      "Epoch 24880, Loss: 82.96885681152344, Neurons: 11, Grad norm: 1.537e+00\n",
      "Epoch 24881, Loss: 82.96157836914062, Neurons: 11, Grad norm: 1.971e+00\n",
      "Epoch 24882, Loss: 82.95429229736328, Neurons: 11, Grad norm: 2.089e+00\n",
      "Epoch 24883, Loss: 82.94700622558594, Neurons: 11, Grad norm: 2.243e+00\n",
      "Epoch 24884, Loss: 82.93971252441406, Neurons: 11, Grad norm: 2.100e+00\n",
      "Epoch 24885, Loss: 82.93242645263672, Neurons: 11, Grad norm: 1.948e+00\n",
      "Epoch 24886, Loss: 82.92513275146484, Neurons: 11, Grad norm: 1.476e+00\n",
      "Epoch 24887, Loss: 82.9178237915039, Neurons: 11, Grad norm: 1.410e+00\n",
      "Epoch 24888, Loss: 82.9105224609375, Neurons: 11, Grad norm: 1.606e+00\n",
      "Epoch 24889, Loss: 82.9032211303711, Neurons: 11, Grad norm: 1.854e+00\n",
      "Epoch 24890, Loss: 82.89591217041016, Neurons: 11, Grad norm: 1.957e+00\n",
      "Epoch 24891, Loss: 82.88861083984375, Neurons: 11, Grad norm: 1.792e+00\n",
      "Epoch 24892, Loss: 82.88129425048828, Neurons: 11, Grad norm: 1.876e+00\n",
      "Epoch 24893, Loss: 82.87398529052734, Neurons: 11, Grad norm: 1.634e+00\n",
      "Epoch 24894, Loss: 82.86666107177734, Neurons: 11, Grad norm: 1.482e+00\n",
      "Epoch 24895, Loss: 82.85934448242188, Neurons: 11, Grad norm: 1.402e+00\n",
      "Epoch 24896, Loss: 82.85202026367188, Neurons: 11, Grad norm: 1.436e+00\n",
      "Epoch 24897, Loss: 82.84469604492188, Neurons: 11, Grad norm: 1.684e+00\n",
      "Epoch 24898, Loss: 82.83737182617188, Neurons: 11, Grad norm: 1.735e+00\n",
      "Epoch 24899, Loss: 82.83003997802734, Neurons: 11, Grad norm: 1.781e+00\n",
      "Epoch 24899, Test loss: 79.49073028564453\n",
      "Epoch 24900, Loss: 82.82270812988281, Neurons: 11, Grad norm: 1.663e+00\n",
      "Epoch 24901, Loss: 82.81538391113281, Neurons: 11, Grad norm: 1.487e+00\n",
      "Epoch 24902, Loss: 82.80804443359375, Neurons: 11, Grad norm: 1.416e+00\n",
      "Epoch 24903, Loss: 82.80070495605469, Neurons: 11, Grad norm: 1.506e+00\n",
      "Epoch 24904, Loss: 82.79337310791016, Neurons: 11, Grad norm: 1.835e+00\n",
      "Epoch 24905, Loss: 82.78602600097656, Neurons: 11, Grad norm: 2.058e+00\n",
      "Epoch 24906, Loss: 82.77867889404297, Neurons: 11, Grad norm: 2.158e+00\n",
      "Epoch 24907, Loss: 82.77132415771484, Neurons: 11, Grad norm: 1.981e+00\n",
      "Epoch 24908, Loss: 82.76396942138672, Neurons: 11, Grad norm: 1.912e+00\n",
      "Epoch 24909, Loss: 82.75662231445312, Neurons: 11, Grad norm: 1.564e+00\n",
      "Epoch 24910, Loss: 82.74925231933594, Neurons: 11, Grad norm: 1.408e+00\n",
      "Epoch 24911, Loss: 82.7419204711914, Neurons: 11, Grad norm: 1.393e+00\n",
      "Epoch 24912, Loss: 82.73453521728516, Neurons: 11, Grad norm: 1.498e+00\n",
      "Epoch 24913, Loss: 82.72718048095703, Neurons: 11, Grad norm: 1.721e+00\n",
      "Epoch 24914, Loss: 82.7198257446289, Neurons: 11, Grad norm: 1.593e+00\n",
      "Epoch 24915, Loss: 82.71244812011719, Neurons: 11, Grad norm: 1.722e+00\n",
      "Epoch 24916, Loss: 82.70507049560547, Neurons: 11, Grad norm: 1.673e+00\n",
      "Epoch 24917, Loss: 82.69770050048828, Neurons: 11, Grad norm: 1.580e+00\n",
      "Epoch 24918, Loss: 82.69033813476562, Neurons: 11, Grad norm: 1.467e+00\n",
      "Epoch 24919, Loss: 82.68293762207031, Neurons: 11, Grad norm: 1.533e+00\n",
      "Epoch 24920, Loss: 82.6755599975586, Neurons: 11, Grad norm: 1.459e+00\n",
      "Epoch 24921, Loss: 82.66818237304688, Neurons: 11, Grad norm: 1.529e+00\n",
      "Epoch 24922, Loss: 82.6607894897461, Neurons: 11, Grad norm: 1.539e+00\n",
      "Epoch 24923, Loss: 82.65339660644531, Neurons: 11, Grad norm: 1.584e+00\n",
      "Epoch 24924, Loss: 82.64601135253906, Neurons: 11, Grad norm: 1.503e+00\n",
      "Epoch 24925, Loss: 82.63862609863281, Neurons: 11, Grad norm: 1.484e+00\n",
      "Epoch 24926, Loss: 82.63121795654297, Neurons: 11, Grad norm: 1.406e+00\n",
      "Epoch 24927, Loss: 82.62382507324219, Neurons: 11, Grad norm: 1.421e+00\n",
      "Epoch 24928, Loss: 82.61641693115234, Neurons: 11, Grad norm: 1.557e+00\n",
      "Epoch 24929, Loss: 82.60900115966797, Neurons: 11, Grad norm: 1.631e+00\n",
      "Epoch 24930, Loss: 82.60159301757812, Neurons: 11, Grad norm: 1.684e+00\n",
      "Epoch 24931, Loss: 82.59419250488281, Neurons: 11, Grad norm: 1.638e+00\n",
      "Epoch 24932, Loss: 82.5867691040039, Neurons: 11, Grad norm: 1.779e+00\n",
      "Epoch 24933, Loss: 82.5793685913086, Neurons: 11, Grad norm: 1.904e+00\n",
      "Epoch 24934, Loss: 82.57193756103516, Neurons: 11, Grad norm: 2.229e+00\n",
      "Epoch 24935, Loss: 82.56452941894531, Neurons: 11, Grad norm: 2.480e+00\n",
      "Epoch 24936, Loss: 82.55709838867188, Neurons: 11, Grad norm: 2.865e+00\n",
      "Epoch 24937, Loss: 82.5496826171875, Neurons: 11, Grad norm: 3.056e+00\n",
      "Epoch 24938, Loss: 82.5422592163086, Neurons: 11, Grad norm: 3.394e+00\n",
      "Epoch 24939, Loss: 82.5348129272461, Neurons: 11, Grad norm: 3.678e+00\n",
      "Epoch 24940, Loss: 82.52739715576172, Neurons: 11, Grad norm: 4.213e+00\n",
      "Epoch 24941, Loss: 82.51996612548828, Neurons: 11, Grad norm: 4.447e+00\n",
      "Epoch 24942, Loss: 82.51252746582031, Neurons: 11, Grad norm: 4.903e+00\n",
      "Epoch 24943, Loss: 82.50508117675781, Neurons: 11, Grad norm: 5.031e+00\n",
      "Epoch 24944, Loss: 82.49764251708984, Neurons: 11, Grad norm: 5.132e+00\n",
      "Epoch 24945, Loss: 82.49019622802734, Neurons: 11, Grad norm: 5.412e+00\n",
      "Epoch 24946, Loss: 82.48274993896484, Neurons: 11, Grad norm: 5.966e+00\n",
      "Epoch 24947, Loss: 82.47529602050781, Neurons: 11, Grad norm: 6.326e+00\n",
      "Epoch 24948, Loss: 82.46785736083984, Neurons: 11, Grad norm: 7.202e+00\n",
      "Epoch 24949, Loss: 82.46041107177734, Neurons: 11, Grad norm: 8.065e+00\n",
      "Epoch 24949, Test loss: 79.13652038574219\n",
      "Epoch 24950, Loss: 82.45296478271484, Neurons: 11, Grad norm: 9.060e+00\n",
      "Epoch 24951, Loss: 82.44548797607422, Neurons: 11, Grad norm: 1.011e+01\n",
      "Epoch 24952, Loss: 82.43803405761719, Neurons: 11, Grad norm: 1.179e+01\n",
      "Epoch 24953, Loss: 82.43057250976562, Neurons: 11, Grad norm: 1.322e+01\n",
      "Epoch 24954, Loss: 82.42312622070312, Neurons: 11, Grad norm: 1.535e+01\n",
      "Epoch 24955, Loss: 82.4156723022461, Neurons: 11, Grad norm: 1.776e+01\n",
      "Epoch 24956, Loss: 82.40821075439453, Neurons: 11, Grad norm: 2.104e+01\n",
      "Epoch 24957, Loss: 82.4007568359375, Neurons: 11, Grad norm: 2.473e+01\n",
      "Epoch 24958, Loss: 82.3933334350586, Neurons: 11, Grad norm: 2.961e+01\n",
      "Epoch 24959, Loss: 82.38589477539062, Neurons: 11, Grad norm: 3.514e+01\n",
      "Epoch 24960, Loss: 82.37850952148438, Neurons: 11, Grad norm: 4.186e+01\n",
      "Epoch 24961, Loss: 82.37113189697266, Neurons: 11, Grad norm: 4.986e+01\n",
      "Epoch 24962, Loss: 82.36380767822266, Neurons: 11, Grad norm: 5.945e+01\n",
      "Epoch 24963, Loss: 82.35655975341797, Neurons: 11, Grad norm: 7.012e+01\n",
      "Epoch 24964, Loss: 82.34939575195312, Neurons: 11, Grad norm: 8.207e+01\n",
      "Epoch 24965, Loss: 82.34232330322266, Neurons: 11, Grad norm: 9.448e+01\n",
      "Epoch 24966, Loss: 82.33533477783203, Neurons: 11, Grad norm: 1.058e+02\n",
      "Epoch 24967, Loss: 82.32839965820312, Neurons: 11, Grad norm: 1.133e+02\n",
      "Epoch 24968, Loss: 82.32137298583984, Neurons: 11, Grad norm: 1.148e+02\n",
      "Epoch 24969, Loss: 82.31413269042969, Neurons: 11, Grad norm: 1.068e+02\n",
      "Epoch 24970, Loss: 82.30651092529297, Neurons: 11, Grad norm: 8.838e+01\n",
      "Epoch 24971, Loss: 82.29854583740234, Neurons: 11, Grad norm: 6.060e+01\n",
      "Epoch 24972, Loss: 82.29051971435547, Neurons: 11, Grad norm: 2.765e+01\n",
      "Epoch 24973, Loss: 82.28274536132812, Neurons: 11, Grad norm: 6.323e+00\n",
      "Epoch 24974, Loss: 82.27538299560547, Neurons: 11, Grad norm: 3.566e+01\n",
      "Epoch 24975, Loss: 82.26842498779297, Neurons: 11, Grad norm: 5.755e+01\n",
      "Epoch 24976, Loss: 82.2616195678711, Neurons: 11, Grad norm: 6.905e+01\n",
      "Epoch 24977, Loss: 82.25472259521484, Neurons: 11, Grad norm: 6.982e+01\n",
      "Epoch 24978, Loss: 82.24754333496094, Neurons: 11, Grad norm: 5.954e+01\n",
      "Epoch 24979, Loss: 82.2401123046875, Neurons: 11, Grad norm: 4.087e+01\n",
      "Epoch 24980, Loss: 82.23257446289062, Neurons: 11, Grad norm: 1.728e+01\n",
      "Epoch 24981, Loss: 82.22514343261719, Neurons: 11, Grad norm: 6.800e+00\n",
      "Epoch 24982, Loss: 82.21792602539062, Neurons: 11, Grad norm: 2.763e+01\n",
      "Epoch 24983, Loss: 82.21089935302734, Neurons: 11, Grad norm: 4.169e+01\n",
      "Epoch 24984, Loss: 82.20392608642578, Neurons: 11, Grad norm: 4.788e+01\n",
      "Epoch 24985, Loss: 82.19688415527344, Neurons: 11, Grad norm: 4.587e+01\n",
      "Epoch 24986, Loss: 82.18968200683594, Neurons: 11, Grad norm: 3.693e+01\n",
      "Epoch 24987, Loss: 82.18238830566406, Neurons: 11, Grad norm: 2.258e+01\n",
      "Epoch 24988, Loss: 82.17506408691406, Neurons: 11, Grad norm: 6.620e+00\n",
      "Epoch 24989, Loss: 82.16783142089844, Neurons: 11, Grad norm: 9.205e+00\n",
      "Epoch 24990, Loss: 82.16068267822266, Neurons: 11, Grad norm: 2.161e+01\n",
      "Epoch 24991, Loss: 82.15360260009766, Neurons: 11, Grad norm: 2.976e+01\n",
      "Epoch 24992, Loss: 82.14652252197266, Neurons: 11, Grad norm: 3.219e+01\n",
      "Epoch 24993, Loss: 82.13938903808594, Neurons: 11, Grad norm: 2.959e+01\n",
      "Epoch 24994, Loss: 82.1322021484375, Neurons: 11, Grad norm: 2.268e+01\n",
      "Epoch 24995, Loss: 82.12498474121094, Neurons: 11, Grad norm: 1.304e+01\n",
      "Epoch 24996, Loss: 82.11774444580078, Neurons: 11, Grad norm: 2.405e+00\n",
      "Epoch 24997, Loss: 82.11055755615234, Neurons: 11, Grad norm: 7.945e+00\n",
      "Epoch 24998, Loss: 82.10342407226562, Neurons: 11, Grad norm: 1.573e+01\n",
      "Epoch 24999, Loss: 82.0962905883789, Neurons: 11, Grad norm: 2.033e+01\n",
      "Epoch 24999, Test loss: 78.78716278076172\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_loss, mlp, opt_state = train_step(mlp, x_train, y_train, opt_state, opt.update)\n",
    "    _, grads  = compute_loss(mlp, x_train, y_train)\n",
    "    grad_norm_val = grad_norm(grads)\n",
    "    n_neurons = sum(mlp.get_shape())\n",
    "\n",
    "    logging.info(f\"Epoch {epoch :03d}, Loss: {train_loss.item()}, Neurons: {n_neurons}, Grad norm: {grad_norm_val :.3e}\")\n",
    "    wandb.log({\"train_loss\": train_loss.item(), \"neurons\": n_neurons, \"grad_norm\": grad_norm_val})\n",
    "    train_loss_history.append((epoch, train_loss))\n",
    "    grad_norm_history.append((epoch,grad_norm_val))\n",
    "    node_history.append((epoch, n_neurons))\n",
    "\n",
    "    if test_loss < threshold:\n",
    "        logging.info(f\"Threshold reached, stopping training at epoch {epoch}\")\n",
    "        wandb.log({\"threshold reached\": epoch})\n",
    "        break\n",
    "\n",
    "    # key, add_key, sub_key = jax.random.split(key,3)\n",
    "\n",
    "    if (epoch + 1) % intervene_every == 0 or grad_norm_val < grad_norm_threshold:\n",
    "        test_loss = test_step(mlp, x_test, y_test)\n",
    "        logging.info(f\"Epoch {epoch :03d}, Test loss: {test_loss.item()}\")\n",
    "        wandb.log({\"test_loss\": test_loss.item()})\n",
    "        test_loss_history.append((epoch,test_loss))\n",
    "    \n",
    "    \n",
    "\n",
    "    if grad_norm_val < grad_norm_threshold/10:\n",
    "        logging.info(f\"Gradient norm below threshold, stopping training at epoch {epoch}\")\n",
    "        wandb.log({\"grad_norm_threshold\": epoch})\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f\"{out_folder}/neurons.txt\", node_history)\n",
    "np.savetxt(f\"{out_folder}/train_loss.txt\", train_loss_history)\n",
    "np.savetxt(f\"{out_folder}/test_loss.txt\", test_loss_history)\n",
    "np.savetxt(f\"{out_folder}/grad_norm.txt\", grad_norm_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = jax.vmap(mlp)(x_test)\n",
    "test_mse = jnp.mean((y_pred - y_test) ** 2)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x_test, y_test, \"b.\", alpha=0.2, label=\"True Poly Function\")\n",
    "plt.plot(x_test, y_pred, \"r.\", alpha=0.2, label=\"MLP Predictions\\n Test MSE: {:.4f}\".format(test_mse))\n",
    "plt.legend()\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.title(\"MLP Approximation of polynomial Function\")\n",
    "plt.savefig(f\"{fig_folder}/polynomial_approximation.png\")\n",
    "wandb.log({\"polynomial approximation\": wandb.Image(plt, caption=\"polynomial approximation\")})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_adjacency_matrix = mlp.adjacency_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f\"{out_folder}/final_adjacency_matrix.txt\", final_adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_wt = np.max(np.abs(final_adjacency_matrix))\n",
    "norm = MidpointNormalize(vmin=-max_wt, vmax=max_wt, midpoint=0)\n",
    "cmap = plt.get_cmap('coolwarm')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "cax = ax.matshow(final_adjacency_matrix, cmap=cmap, norm=norm)\n",
    "cbar = fig.colorbar(cax, ticks=[-max_wt,\n",
    "                                -max_wt/2, \n",
    "                                0,\n",
    "                                max_wt/2,\n",
    "                                max_wt])\n",
    "\n",
    "# plt.colorbar()\n",
    "plt.title(\"final adjacency matrix\")\n",
    "plt.savefig(f\"{fig_folder}/final_adjacency_matrix.png\")\n",
    "wandb.log({\"final adjacency matrix\": wandb.Image(plt, caption=\"final adjacency matrix\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_matrices = np.split(final_adjacency_matrix, np.cumsum(mlp.get_shape())[:-1])[:-1]\n",
    "\n",
    "fig, axs = plt.subplots(1, len(sub_matrices), figsize=(20, 5))\n",
    "\n",
    "for i, (sub_matrix, ax) in enumerate(zip(sub_matrices, axs), start=1):\n",
    "    weights = sub_matrix.flatten()\n",
    "    weights = weights[weights != 0]\n",
    "    ax.hist(weights, bins=\"auto\", density=False, alpha=0.6, color='g')\n",
    "    ax.set_xlabel('Weights')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'Layer {i}-Layer {i+1} ')\n",
    "\n",
    "# Display the figure with its subplots\n",
    "plt.suptitle('Final Weight Distribution (excluding zero weights)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epochs, train_loss = zip(*train_loss_history)\n",
    "test_epochs, test_loss = zip(*test_loss_history)\n",
    "grad_epochs, grad_norm_val = zip(*grad_norm_history)\n",
    "node_epochs, n_neurons = zip(*node_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss', color=color)\n",
    "ax1.plot(train_epochs, train_loss, \"-.\", color=color, label=\"Train Loss\")\n",
    "ax1.plot(test_epochs, test_loss, \"*\", color=\"darkred\", label=\"Test Loss\")\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.set_yscale(\"log\")\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Number of Nodes', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(node_epochs, n_neurons, \"-.\", color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.spines['right'].set_color(color)\n",
    "\n",
    "\n",
    "ax3 = ax1.twinx()\n",
    "\n",
    "color = 'tab:green'\n",
    "ax3.spines['right'].set_position(('outward', 60))  # Offset the third y-axis\n",
    "ax3.plot(grad_epochs, grad_norm_val, '.', color=color)\n",
    "ax3.set_ylabel('Gradient norm', color=color)\n",
    "ax3.tick_params(axis='y', labelcolor=color)\n",
    "ax3.set_yscale(\"log\")\n",
    "ax3.spines['right'].set_color(color)\n",
    "\n",
    "# ax1.set_xscale(\"log\")\n",
    "ax1.legend()\n",
    "plt.suptitle(f\"Heterogenous {act_string} Neural Network with no strategic Node Addition and Removal\")\n",
    "fig.tight_layout()\n",
    "plt.savefig(f\"{fig_folder}/loss_curve.png\")\n",
    "wandb.log({\"loss and nodes\": wandb.Image(plt, caption=\"loss and nodes\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss', color=color)\n",
    "ax1.plot(train_epochs, train_loss, \"-.\", color=color, label=\"Train Loss\")\n",
    "ax1.plot(test_epochs, test_loss, \"*\", color=\"darkred\", label=\"Test Loss\")\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.legend()\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Number of Nodes', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(node_epochs, n_neurons, \"-.\", color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.spines['right'].set_color(color)\n",
    "\n",
    "\n",
    "ax3 = ax1.twinx()\n",
    "\n",
    "color = 'tab:green'\n",
    "ax3.spines['right'].set_position(('outward', 60))  # Offset the third y-axis\n",
    "ax3.plot(grad_epochs, grad_norm_val, '.', color=color)\n",
    "ax3.set_ylabel('Gradient norm', color=color)\n",
    "ax3.tick_params(axis='y', labelcolor=color)\n",
    "ax3.set_yscale(\"log\")\n",
    "ax3.spines['right'].set_color(color)\n",
    "\n",
    "ax1.set_xscale(\"log\")\n",
    "\n",
    "plt.suptitle(f\"Heterogenous {act_string} Neural Network with no strategic Node Addition and Removal\")\n",
    "fig.tight_layout()\n",
    "plt.savefig(f\"{fig_folder}/loss_curve_loglog.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G, neuron_labels, neuron_importances = mlp.visualize_graph()\n",
    "fig = mlp_plot(G, neuron_labels, neuron_importances)\n",
    "plt.savefig(f\"{fig_folder}/final_graph.png\")\n",
    "wandb.log({\"final neural network\": wandb.Image(plt, caption=\"final neural network\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
