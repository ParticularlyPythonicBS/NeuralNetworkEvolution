{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Neuron with activation function included to create neural networks with\n",
    "  individual neuron activations\n",
    "output-file: neuron.html\n",
    "title: Neuron\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Neuron\n",
       "\n",
       ">      Neuron (in_features, activation=<jax._src.custom_derivatives.custom_jvp\n",
       ">              object at 0x7ff772952a50>, bias=False, key=None)\n",
       "\n",
       "*A simple neuron with a weight vector, bias, and activation function.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Neuron\n",
       "\n",
       ">      Neuron (in_features, activation=<jax._src.custom_derivatives.custom_jvp\n",
       ">              object at 0x7ff772952a50>, bias=False, key=None)\n",
       "\n",
       "*A simple neuron with a weight vector, bias, and activation function.*"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(Neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 08:32:20.707579: W external/xla/xla/service/gpu/nvptx_compiler.cc:760] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.4.131). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "neuron = Neuron(10)\n",
    "x = jax.random.normal(jax.random.PRNGKey(0), (10,))\n",
    "y = neuron(x)\n",
    "assert y.shape == ()\n",
    "assert neuron.importance().shape == ()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
