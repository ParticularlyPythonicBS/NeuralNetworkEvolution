{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test loss linear scaling with #Neurons and grad norm checks based strategy for Polynomial prediction with a heterogenous MLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### env management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: \"WANDB_NOTEBOOK_NAME\"=\"25_hetero_poly_test_linear_grad_strat_capped.ipynb\"\n",
      "env: WANDB_SILENT=True\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%env \"WANDB_NOTEBOOK_NAME\" \"25_hetero_poly_test_linear_grad_strat_capped.ipynb\"\n",
    "%env WANDB_SILENT=True\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "# %env XLA_PYTHON_CLIENT_MEM_FRACTION=0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "import optax\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.style as mplstyle\n",
    "import seaborn as sns\n",
    "\n",
    "from NeuralNetworkEvolution.config import MLPConfig\n",
    "from NeuralNetworkEvolution.activations import sin\n",
    "from NeuralNetworkEvolution.mlp import CustomMLP, mlp_plot\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "sns.set_theme(context='paper', style='white', palette='vlag', font='serif',\n",
    "            font_scale=2, color_codes=True, rc={'text.usetex' : True})\n",
    "mplstyle.use('fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidpointNormalize(Normalize):\n",
    "    \"\"\"\n",
    "    Normalize and shift the colormap to center 0\n",
    "    \"\"\"\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        result, is_scalar = self.process_value(value)\n",
    "        (vmin, vmax, midpoint) = self.vmin, self.vmax, self.midpoint\n",
    "        if vmin is None or vmax is None:\n",
    "            vmin, vmax = np.min(value), np.max(value)\n",
    "        if midpoint is None:\n",
    "            midpoint = (vmin + vmax) / 2\n",
    "        result = np.ma.masked_array(np.interp(value, [vmin, midpoint, vmax], [0, 0.5, 1]))\n",
    "        if is_scalar:\n",
    "            result = np.atleast_1d(result)[0]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "hidden_sizes = [5, 5] \n",
    "min_neurons = 4\n",
    "max_neurons = 64\n",
    "output_size = 1\n",
    "initial_activation_list = [sin, jax.nn.relu, jax.nn.tanh]\n",
    "activation_list = [sin, jax.nn.relu, jax.nn.tanh]\n",
    "optimizer = optax.adabelief\n",
    "bias = False\n",
    "num_epochs = 15000\n",
    "intervene_every = 100\n",
    "seed = 0\n",
    "key = jax.random.PRNGKey(seed)\n",
    "threshold = 1e-4\n",
    "grad_norm_threshold = 1e-3\n",
    "n_samples = 20000\n",
    "test_size = 0.2\n",
    "learning_rate = 3e-4\n",
    "\n",
    "act_string = \"_\".join([act.__name__ for act in initial_activation_list])\n",
    "\n",
    "config = MLPConfig(input_size=input_size,\n",
    "                output_size=output_size,\n",
    "                hidden_sizes=hidden_sizes,\n",
    "                initial_activation_list=initial_activation_list,\n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.__dict__.update({'n_samples': n_samples,\n",
    "                        'learning_rate': learning_rate,\n",
    "                        'num_epochs': num_epochs,\n",
    "                        'intervene_every': intervene_every,\n",
    "                        'threshold': threshold,\n",
    "                        'activation_list': activation_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jax.config.update(\"jax_enable_x64\", True)\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "Description = f\"Homo_{act_string}_poly_test_linear_grad_strat_{optimizer.__name__}_no_bias_min_{min_neurons}_max_{max_neurons}_{hidden_sizes[0]}_{hidden_sizes[1]}_{num_epochs}_{intervene_every}_{threshold}_{seed}\"\n",
    "fig_folder = f\"../figures/{Description}\"\n",
    "out_folder = f\"../output/{Description}\"\n",
    "os.makedirs(fig_folder, exist_ok=True)\n",
    "os.makedirs(out_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# devices: 4\n",
      "Description: Homo_sin_relu_tanh_poly_test_linear_grad_strat_adabelief_no_bias_min_4_max_64_5_5_15000_100_0.0001_0\n",
      "Description: Homo_sin_relu_tanh_poly_test_linear_grad_strat_adabelief_no_bias_min_4_max_64_5_5_15000_100_0.0001_0\n",
      "jax backend: cpu\n",
      "jax backend: cpu\n",
      "jax devices: [cuda(id=0), cuda(id=1), cuda(id=2), cuda(id=3)]\n",
      "jax devices: [cuda(id=0), cuda(id=1), cuda(id=2), cuda(id=3)]\n"
     ]
    }
   ],
   "source": [
    "print(f\"# devices: {jax.local_device_count()}\")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, filename=f\"{out_folder}/info.log\", filemode=\"w\")\n",
    "console = logging.StreamHandler(sys.stdout)\n",
    "console.setLevel(logging.INFO)\n",
    "logging.getLogger(\"\").addHandler(console)\n",
    "logging.info(f\"Description: {Description}\")\n",
    "logging.info(f\"jax backend: {jax.lib.xla_bridge.get_backend().platform}\")\n",
    "logging.info(f\"jax devices: {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=\"neural-network-evolution\", name=Description, config=config.__dict__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly(x):\n",
    "    \"\"\"\n",
    "    7th degree polynomial to predict\n",
    "    \"\"\"\n",
    "    return (x - 3)*(x - 2)*(x - 1)*x*(x + 1)*(x + 2)*(x + 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.linspace(-3, 3, n_samples).reshape(-1, 1)\n",
    "y = poly(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'Data')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_train, y_train, \"k.\", alpha=0.2, label=f\"train:{len(x_train)}\")\n",
    "plt.plot(x_test, y_test, \"r.\", alpha = 0.2, label=f\"test:{len(x_test)}\")\n",
    "plt.legend()\n",
    "plt.suptitle(\"Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training and eval scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_optimizer_state(mlp, optimizer):\n",
    "    \"\"\"\n",
    "    Optimizer initialization that filters for float arrays in the jax pytrees\n",
    "    \"\"\"\n",
    "    return optimizer.init(eqx.filter(mlp, eqx.is_inexact_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_value_and_grad()\n",
    "def compute_loss(mlp, x, y):\n",
    "    pred = jax.vmap(mlp)(x)\n",
    "    return jnp.mean((pred - y) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit()\n",
    "def train_step(mlp, x, y, opt_state, opt_update):\n",
    "    loss, grads = compute_loss(mlp, x, y)\n",
    "    updates, opt_state = opt_update(grads, opt_state)\n",
    "    mlp = eqx.apply_updates(mlp, updates)\n",
    "    return loss, mlp, opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit()\n",
    "def test_step(mlp, x, y):\n",
    "    return compute_loss(mlp, x, y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_norm(grads):\n",
    "    return jnp.sqrt(sum(jnp.sum(jnp.square(p)) for p in jax.tree_util.tree_leaves(grads)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initializing MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neurons at start: 11\n",
      "Number of neurons at start: 11\n"
     ]
    }
   ],
   "source": [
    "mlp = CustomMLP(config)\n",
    "init_neurons = sum(mlp.get_shape())\n",
    "logging.info(f\"Number of neurons at start: {init_neurons}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G, neuron_labels, neuron_importances = mlp.visualize_graph()\n",
    "fig = mlp_plot(G, neuron_labels, neuron_importances)\n",
    "plt.suptitle(\"Initial neural network\")\n",
    "plt.savefig(f\"{fig_folder}/initial_graph.png\")\n",
    "wandb.log({\"initial neural network\": wandb.Image(plt, caption=\"initial neural network\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_adjacency_matrix = mlp.adjacency_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_wt = np.max(np.abs(initial_adjacency_matrix))\n",
    "norm = MidpointNormalize(vmin=-max_wt, vmax=max_wt, midpoint=0)\n",
    "cmap = plt.get_cmap('coolwarm')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "cax = ax.matshow(initial_adjacency_matrix, cmap=cmap, norm=norm)\n",
    "cbar = fig.colorbar(cax, ticks=[-max_wt,\n",
    "                                -max_wt/2, \n",
    "                                0,\n",
    "                                max_wt/2,\n",
    "                                max_wt])\n",
    "\n",
    "# plt.colorbar()\n",
    "plt.title(\"Initial adjacency matrix\")\n",
    "plt.savefig(f\"{fig_folder}/initial_adjacency_matrix.png\")\n",
    "wandb.log({\"initial adjacency matrix\": wandb.Image(plt, caption=\"initial adjacency matrix\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initializing optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizer(learning_rate=learning_rate)\n",
    "opt_state = initialize_optimizer_state(mlp, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "node_history = []\n",
    "grad_norm_history = []\n",
    "graph_history = []\n",
    "update_history = []\n",
    "time_history = []\n",
    "\n",
    "test_loss = np.inf # initialize test loss to infinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000, Loss: 1508.8878173828125, Neurons: 11, Grad norm: 4.791e+01\n",
      "Epoch 000, Loss: 1508.8878173828125, Neurons: 11, Grad norm: 4.791e+01\n",
      "Epoch 001, Loss: 1508.8140869140625, Neurons: 11, Grad norm: 4.791e+01\n",
      "Epoch 001, Loss: 1508.8140869140625, Neurons: 11, Grad norm: 4.791e+01\n",
      "Epoch 002, Loss: 1508.736572265625, Neurons: 11, Grad norm: 4.790e+01\n",
      "Epoch 002, Loss: 1508.736572265625, Neurons: 11, Grad norm: 4.790e+01\n",
      "Epoch 003, Loss: 1508.6552734375, Neurons: 11, Grad norm: 4.790e+01\n",
      "Epoch 003, Loss: 1508.6552734375, Neurons: 11, Grad norm: 4.790e+01\n",
      "Epoch 004, Loss: 1508.5703125, Neurons: 11, Grad norm: 4.789e+01\n",
      "Epoch 004, Loss: 1508.5703125, Neurons: 11, Grad norm: 4.789e+01\n",
      "Epoch 005, Loss: 1508.4814453125, Neurons: 11, Grad norm: 4.789e+01\n",
      "Epoch 005, Loss: 1508.4814453125, Neurons: 11, Grad norm: 4.789e+01\n",
      "Epoch 006, Loss: 1508.3885498046875, Neurons: 11, Grad norm: 4.788e+01\n",
      "Epoch 006, Loss: 1508.3885498046875, Neurons: 11, Grad norm: 4.788e+01\n",
      "Epoch 007, Loss: 1508.2921142578125, Neurons: 11, Grad norm: 4.788e+01\n",
      "Epoch 007, Loss: 1508.2921142578125, Neurons: 11, Grad norm: 4.788e+01\n",
      "Epoch 008, Loss: 1508.1915283203125, Neurons: 11, Grad norm: 4.788e+01\n",
      "Epoch 008, Loss: 1508.1915283203125, Neurons: 11, Grad norm: 4.788e+01\n",
      "Epoch 009, Loss: 1508.08740234375, Neurons: 11, Grad norm: 4.787e+01\n",
      "Epoch 009, Loss: 1508.08740234375, Neurons: 11, Grad norm: 4.787e+01\n",
      "Epoch 010, Loss: 1507.9794921875, Neurons: 11, Grad norm: 4.787e+01\n",
      "Epoch 010, Loss: 1507.9794921875, Neurons: 11, Grad norm: 4.787e+01\n",
      "Epoch 011, Loss: 1507.86767578125, Neurons: 11, Grad norm: 4.786e+01\n",
      "Epoch 011, Loss: 1507.86767578125, Neurons: 11, Grad norm: 4.786e+01\n",
      "Epoch 012, Loss: 1507.752197265625, Neurons: 11, Grad norm: 4.786e+01\n",
      "Epoch 012, Loss: 1507.752197265625, Neurons: 11, Grad norm: 4.786e+01\n",
      "Epoch 013, Loss: 1507.633056640625, Neurons: 11, Grad norm: 4.786e+01\n",
      "Epoch 013, Loss: 1507.633056640625, Neurons: 11, Grad norm: 4.786e+01\n",
      "Epoch 014, Loss: 1507.5103759765625, Neurons: 11, Grad norm: 4.785e+01\n",
      "Epoch 014, Loss: 1507.5103759765625, Neurons: 11, Grad norm: 4.785e+01\n",
      "Epoch 015, Loss: 1507.384033203125, Neurons: 11, Grad norm: 4.785e+01\n",
      "Epoch 015, Loss: 1507.384033203125, Neurons: 11, Grad norm: 4.785e+01\n",
      "Epoch 016, Loss: 1507.2540283203125, Neurons: 11, Grad norm: 4.785e+01\n",
      "Epoch 016, Loss: 1507.2540283203125, Neurons: 11, Grad norm: 4.785e+01\n",
      "Epoch 017, Loss: 1507.1209716796875, Neurons: 11, Grad norm: 4.785e+01\n",
      "Epoch 017, Loss: 1507.1209716796875, Neurons: 11, Grad norm: 4.785e+01\n",
      "Epoch 018, Loss: 1506.9842529296875, Neurons: 11, Grad norm: 4.785e+01\n",
      "Epoch 018, Loss: 1506.9842529296875, Neurons: 11, Grad norm: 4.785e+01\n",
      "Epoch 019, Loss: 1506.8441162109375, Neurons: 11, Grad norm: 4.785e+01\n",
      "Epoch 019, Loss: 1506.8441162109375, Neurons: 11, Grad norm: 4.785e+01\n",
      "Epoch 020, Loss: 1506.7008056640625, Neurons: 11, Grad norm: 4.786e+01\n",
      "Epoch 020, Loss: 1506.7008056640625, Neurons: 11, Grad norm: 4.786e+01\n",
      "Epoch 021, Loss: 1506.5543212890625, Neurons: 11, Grad norm: 4.786e+01\n",
      "Epoch 021, Loss: 1506.5543212890625, Neurons: 11, Grad norm: 4.786e+01\n",
      "Epoch 022, Loss: 1506.4044189453125, Neurons: 11, Grad norm: 4.787e+01\n",
      "Epoch 022, Loss: 1506.4044189453125, Neurons: 11, Grad norm: 4.787e+01\n",
      "Epoch 023, Loss: 1506.2515869140625, Neurons: 11, Grad norm: 4.788e+01\n",
      "Epoch 023, Loss: 1506.2515869140625, Neurons: 11, Grad norm: 4.788e+01\n",
      "Epoch 024, Loss: 1506.0955810546875, Neurons: 11, Grad norm: 4.788e+01\n",
      "Epoch 024, Loss: 1506.0955810546875, Neurons: 11, Grad norm: 4.788e+01\n",
      "Epoch 025, Loss: 1505.9365234375, Neurons: 11, Grad norm: 4.789e+01\n",
      "Epoch 025, Loss: 1505.9365234375, Neurons: 11, Grad norm: 4.789e+01\n",
      "Epoch 026, Loss: 1505.7744140625, Neurons: 11, Grad norm: 4.791e+01\n",
      "Epoch 026, Loss: 1505.7744140625, Neurons: 11, Grad norm: 4.791e+01\n",
      "Epoch 027, Loss: 1505.609375, Neurons: 11, Grad norm: 4.792e+01\n",
      "Epoch 027, Loss: 1505.609375, Neurons: 11, Grad norm: 4.792e+01\n",
      "Epoch 028, Loss: 1505.4412841796875, Neurons: 11, Grad norm: 4.794e+01\n",
      "Epoch 028, Loss: 1505.4412841796875, Neurons: 11, Grad norm: 4.794e+01\n",
      "Epoch 029, Loss: 1505.2706298828125, Neurons: 11, Grad norm: 4.795e+01\n",
      "Epoch 029, Loss: 1505.2706298828125, Neurons: 11, Grad norm: 4.795e+01\n",
      "Epoch 030, Loss: 1505.0968017578125, Neurons: 11, Grad norm: 4.797e+01\n",
      "Epoch 030, Loss: 1505.0968017578125, Neurons: 11, Grad norm: 4.797e+01\n",
      "Epoch 031, Loss: 1504.920166015625, Neurons: 11, Grad norm: 4.800e+01\n",
      "Epoch 031, Loss: 1504.920166015625, Neurons: 11, Grad norm: 4.800e+01\n",
      "Epoch 032, Loss: 1504.7408447265625, Neurons: 11, Grad norm: 4.802e+01\n",
      "Epoch 032, Loss: 1504.7408447265625, Neurons: 11, Grad norm: 4.802e+01\n",
      "Epoch 033, Loss: 1504.55859375, Neurons: 11, Grad norm: 4.805e+01\n",
      "Epoch 033, Loss: 1504.55859375, Neurons: 11, Grad norm: 4.805e+01\n",
      "Epoch 034, Loss: 1504.37353515625, Neurons: 11, Grad norm: 4.808e+01\n",
      "Epoch 034, Loss: 1504.37353515625, Neurons: 11, Grad norm: 4.808e+01\n",
      "Epoch 035, Loss: 1504.185791015625, Neurons: 11, Grad norm: 4.811e+01\n",
      "Epoch 035, Loss: 1504.185791015625, Neurons: 11, Grad norm: 4.811e+01\n",
      "Epoch 036, Loss: 1503.9952392578125, Neurons: 11, Grad norm: 4.814e+01\n",
      "Epoch 036, Loss: 1503.9952392578125, Neurons: 11, Grad norm: 4.814e+01\n",
      "Epoch 037, Loss: 1503.802001953125, Neurons: 11, Grad norm: 4.818e+01\n",
      "Epoch 037, Loss: 1503.802001953125, Neurons: 11, Grad norm: 4.818e+01\n",
      "Epoch 038, Loss: 1503.6058349609375, Neurons: 11, Grad norm: 4.822e+01\n",
      "Epoch 038, Loss: 1503.6058349609375, Neurons: 11, Grad norm: 4.822e+01\n",
      "Epoch 039, Loss: 1503.4071044921875, Neurons: 11, Grad norm: 4.826e+01\n",
      "Epoch 039, Loss: 1503.4071044921875, Neurons: 11, Grad norm: 4.826e+01\n",
      "Epoch 040, Loss: 1503.20556640625, Neurons: 11, Grad norm: 4.830e+01\n",
      "Epoch 040, Loss: 1503.20556640625, Neurons: 11, Grad norm: 4.830e+01\n",
      "Epoch 041, Loss: 1503.00146484375, Neurons: 11, Grad norm: 4.835e+01\n",
      "Epoch 041, Loss: 1503.00146484375, Neurons: 11, Grad norm: 4.835e+01\n",
      "Epoch 042, Loss: 1502.7943115234375, Neurons: 11, Grad norm: 4.840e+01\n",
      "Epoch 042, Loss: 1502.7943115234375, Neurons: 11, Grad norm: 4.840e+01\n",
      "Epoch 043, Loss: 1502.5845947265625, Neurons: 11, Grad norm: 4.845e+01\n",
      "Epoch 043, Loss: 1502.5845947265625, Neurons: 11, Grad norm: 4.845e+01\n",
      "Epoch 044, Loss: 1502.3720703125, Neurons: 11, Grad norm: 4.850e+01\n",
      "Epoch 044, Loss: 1502.3720703125, Neurons: 11, Grad norm: 4.850e+01\n",
      "Epoch 045, Loss: 1502.1568603515625, Neurons: 11, Grad norm: 4.856e+01\n",
      "Epoch 045, Loss: 1502.1568603515625, Neurons: 11, Grad norm: 4.856e+01\n",
      "Epoch 046, Loss: 1501.9388427734375, Neurons: 11, Grad norm: 4.862e+01\n",
      "Epoch 046, Loss: 1501.9388427734375, Neurons: 11, Grad norm: 4.862e+01\n",
      "Epoch 047, Loss: 1501.718017578125, Neurons: 11, Grad norm: 4.868e+01\n",
      "Epoch 047, Loss: 1501.718017578125, Neurons: 11, Grad norm: 4.868e+01\n",
      "Epoch 048, Loss: 1501.4942626953125, Neurons: 11, Grad norm: 4.875e+01\n",
      "Epoch 048, Loss: 1501.4942626953125, Neurons: 11, Grad norm: 4.875e+01\n",
      "Epoch 049, Loss: 1501.26806640625, Neurons: 11, Grad norm: 4.882e+01\n",
      "Epoch 049, Loss: 1501.26806640625, Neurons: 11, Grad norm: 4.882e+01\n",
      "Epoch 050, Loss: 1501.0386962890625, Neurons: 11, Grad norm: 4.889e+01\n",
      "Epoch 050, Loss: 1501.0386962890625, Neurons: 11, Grad norm: 4.889e+01\n",
      "Epoch 051, Loss: 1500.8065185546875, Neurons: 11, Grad norm: 4.896e+01\n",
      "Epoch 051, Loss: 1500.8065185546875, Neurons: 11, Grad norm: 4.896e+01\n",
      "Epoch 052, Loss: 1500.571533203125, Neurons: 11, Grad norm: 4.904e+01\n",
      "Epoch 052, Loss: 1500.571533203125, Neurons: 11, Grad norm: 4.904e+01\n",
      "Epoch 053, Loss: 1500.333740234375, Neurons: 11, Grad norm: 4.912e+01\n",
      "Epoch 053, Loss: 1500.333740234375, Neurons: 11, Grad norm: 4.912e+01\n",
      "Epoch 054, Loss: 1500.0928955078125, Neurons: 11, Grad norm: 4.920e+01\n",
      "Epoch 054, Loss: 1500.0928955078125, Neurons: 11, Grad norm: 4.920e+01\n",
      "Epoch 055, Loss: 1499.8492431640625, Neurons: 11, Grad norm: 4.928e+01\n",
      "Epoch 055, Loss: 1499.8492431640625, Neurons: 11, Grad norm: 4.928e+01\n",
      "Epoch 056, Loss: 1499.6024169921875, Neurons: 11, Grad norm: 4.937e+01\n",
      "Epoch 056, Loss: 1499.6024169921875, Neurons: 11, Grad norm: 4.937e+01\n",
      "Epoch 057, Loss: 1499.352783203125, Neurons: 11, Grad norm: 4.946e+01\n",
      "Epoch 057, Loss: 1499.352783203125, Neurons: 11, Grad norm: 4.946e+01\n",
      "Epoch 058, Loss: 1499.10009765625, Neurons: 11, Grad norm: 4.955e+01\n",
      "Epoch 058, Loss: 1499.10009765625, Neurons: 11, Grad norm: 4.955e+01\n",
      "Epoch 059, Loss: 1498.84423828125, Neurons: 11, Grad norm: 4.965e+01\n",
      "Epoch 059, Loss: 1498.84423828125, Neurons: 11, Grad norm: 4.965e+01\n",
      "Epoch 060, Loss: 1498.58544921875, Neurons: 11, Grad norm: 4.975e+01\n",
      "Epoch 060, Loss: 1498.58544921875, Neurons: 11, Grad norm: 4.975e+01\n",
      "Epoch 061, Loss: 1498.323486328125, Neurons: 11, Grad norm: 4.985e+01\n",
      "Epoch 061, Loss: 1498.323486328125, Neurons: 11, Grad norm: 4.985e+01\n",
      "Epoch 062, Loss: 1498.0584716796875, Neurons: 11, Grad norm: 4.995e+01\n",
      "Epoch 062, Loss: 1498.0584716796875, Neurons: 11, Grad norm: 4.995e+01\n",
      "Epoch 063, Loss: 1497.7901611328125, Neurons: 11, Grad norm: 5.006e+01\n",
      "Epoch 063, Loss: 1497.7901611328125, Neurons: 11, Grad norm: 5.006e+01\n",
      "Epoch 064, Loss: 1497.518798828125, Neurons: 11, Grad norm: 5.016e+01\n",
      "Epoch 064, Loss: 1497.518798828125, Neurons: 11, Grad norm: 5.016e+01\n",
      "Epoch 065, Loss: 1497.244140625, Neurons: 11, Grad norm: 5.027e+01\n",
      "Epoch 065, Loss: 1497.244140625, Neurons: 11, Grad norm: 5.027e+01\n",
      "Epoch 066, Loss: 1496.96630859375, Neurons: 11, Grad norm: 5.039e+01\n",
      "Epoch 066, Loss: 1496.96630859375, Neurons: 11, Grad norm: 5.039e+01\n",
      "Epoch 067, Loss: 1496.68505859375, Neurons: 11, Grad norm: 5.050e+01\n",
      "Epoch 067, Loss: 1496.68505859375, Neurons: 11, Grad norm: 5.050e+01\n",
      "Epoch 068, Loss: 1496.4005126953125, Neurons: 11, Grad norm: 5.062e+01\n",
      "Epoch 068, Loss: 1496.4005126953125, Neurons: 11, Grad norm: 5.062e+01\n",
      "Epoch 069, Loss: 1496.11279296875, Neurons: 11, Grad norm: 5.074e+01\n",
      "Epoch 069, Loss: 1496.11279296875, Neurons: 11, Grad norm: 5.074e+01\n",
      "Epoch 070, Loss: 1495.821533203125, Neurons: 11, Grad norm: 5.086e+01\n",
      "Epoch 070, Loss: 1495.821533203125, Neurons: 11, Grad norm: 5.086e+01\n",
      "Epoch 071, Loss: 1495.5269775390625, Neurons: 11, Grad norm: 5.098e+01\n",
      "Epoch 071, Loss: 1495.5269775390625, Neurons: 11, Grad norm: 5.098e+01\n",
      "Epoch 072, Loss: 1495.2288818359375, Neurons: 11, Grad norm: 5.111e+01\n",
      "Epoch 072, Loss: 1495.2288818359375, Neurons: 11, Grad norm: 5.111e+01\n",
      "Epoch 073, Loss: 1494.9273681640625, Neurons: 11, Grad norm: 5.124e+01\n",
      "Epoch 073, Loss: 1494.9273681640625, Neurons: 11, Grad norm: 5.124e+01\n",
      "Epoch 074, Loss: 1494.622314453125, Neurons: 11, Grad norm: 5.137e+01\n",
      "Epoch 074, Loss: 1494.622314453125, Neurons: 11, Grad norm: 5.137e+01\n",
      "Epoch 075, Loss: 1494.3138427734375, Neurons: 11, Grad norm: 5.150e+01\n",
      "Epoch 075, Loss: 1494.3138427734375, Neurons: 11, Grad norm: 5.150e+01\n",
      "Epoch 076, Loss: 1494.0015869140625, Neurons: 11, Grad norm: 5.163e+01\n",
      "Epoch 076, Loss: 1494.0015869140625, Neurons: 11, Grad norm: 5.163e+01\n",
      "Epoch 077, Loss: 1493.68603515625, Neurons: 11, Grad norm: 5.177e+01\n",
      "Epoch 077, Loss: 1493.68603515625, Neurons: 11, Grad norm: 5.177e+01\n",
      "Epoch 078, Loss: 1493.36669921875, Neurons: 11, Grad norm: 5.190e+01\n",
      "Epoch 078, Loss: 1493.36669921875, Neurons: 11, Grad norm: 5.190e+01\n",
      "Epoch 079, Loss: 1493.0438232421875, Neurons: 11, Grad norm: 5.204e+01\n",
      "Epoch 079, Loss: 1493.0438232421875, Neurons: 11, Grad norm: 5.204e+01\n",
      "Epoch 080, Loss: 1492.7171630859375, Neurons: 11, Grad norm: 5.218e+01\n",
      "Epoch 080, Loss: 1492.7171630859375, Neurons: 11, Grad norm: 5.218e+01\n",
      "Epoch 081, Loss: 1492.386962890625, Neurons: 11, Grad norm: 5.232e+01\n",
      "Epoch 081, Loss: 1492.386962890625, Neurons: 11, Grad norm: 5.232e+01\n",
      "Epoch 082, Loss: 1492.052978515625, Neurons: 11, Grad norm: 5.247e+01\n",
      "Epoch 082, Loss: 1492.052978515625, Neurons: 11, Grad norm: 5.247e+01\n",
      "Epoch 083, Loss: 1491.715087890625, Neurons: 11, Grad norm: 5.261e+01\n",
      "Epoch 083, Loss: 1491.715087890625, Neurons: 11, Grad norm: 5.261e+01\n",
      "Epoch 084, Loss: 1491.3736572265625, Neurons: 11, Grad norm: 5.275e+01\n",
      "Epoch 084, Loss: 1491.3736572265625, Neurons: 11, Grad norm: 5.275e+01\n",
      "Epoch 085, Loss: 1491.0284423828125, Neurons: 11, Grad norm: 5.290e+01\n",
      "Epoch 085, Loss: 1491.0284423828125, Neurons: 11, Grad norm: 5.290e+01\n",
      "Epoch 086, Loss: 1490.6793212890625, Neurons: 11, Grad norm: 5.305e+01\n",
      "Epoch 086, Loss: 1490.6793212890625, Neurons: 11, Grad norm: 5.305e+01\n",
      "Epoch 087, Loss: 1490.326416015625, Neurons: 11, Grad norm: 5.319e+01\n",
      "Epoch 087, Loss: 1490.326416015625, Neurons: 11, Grad norm: 5.319e+01\n",
      "Epoch 088, Loss: 1489.9697265625, Neurons: 11, Grad norm: 5.334e+01\n",
      "Epoch 088, Loss: 1489.9697265625, Neurons: 11, Grad norm: 5.334e+01\n",
      "Epoch 089, Loss: 1489.609130859375, Neurons: 11, Grad norm: 5.349e+01\n",
      "Epoch 089, Loss: 1489.609130859375, Neurons: 11, Grad norm: 5.349e+01\n",
      "Epoch 090, Loss: 1489.244873046875, Neurons: 11, Grad norm: 5.364e+01\n",
      "Epoch 090, Loss: 1489.244873046875, Neurons: 11, Grad norm: 5.364e+01\n",
      "Epoch 091, Loss: 1488.87646484375, Neurons: 11, Grad norm: 5.379e+01\n",
      "Epoch 091, Loss: 1488.87646484375, Neurons: 11, Grad norm: 5.379e+01\n",
      "Epoch 092, Loss: 1488.504150390625, Neurons: 11, Grad norm: 5.394e+01\n",
      "Epoch 092, Loss: 1488.504150390625, Neurons: 11, Grad norm: 5.394e+01\n",
      "Epoch 093, Loss: 1488.1280517578125, Neurons: 11, Grad norm: 5.409e+01\n",
      "Epoch 093, Loss: 1488.1280517578125, Neurons: 11, Grad norm: 5.409e+01\n",
      "Epoch 094, Loss: 1487.748046875, Neurons: 11, Grad norm: 5.424e+01\n",
      "Epoch 094, Loss: 1487.748046875, Neurons: 11, Grad norm: 5.424e+01\n",
      "Epoch 095, Loss: 1487.3641357421875, Neurons: 11, Grad norm: 5.439e+01\n",
      "Epoch 095, Loss: 1487.3641357421875, Neurons: 11, Grad norm: 5.439e+01\n",
      "Epoch 096, Loss: 1486.976318359375, Neurons: 11, Grad norm: 5.454e+01\n",
      "Epoch 096, Loss: 1486.976318359375, Neurons: 11, Grad norm: 5.454e+01\n",
      "Epoch 097, Loss: 1486.5845947265625, Neurons: 11, Grad norm: 5.469e+01\n",
      "Epoch 097, Loss: 1486.5845947265625, Neurons: 11, Grad norm: 5.469e+01\n",
      "Epoch 098, Loss: 1486.1888427734375, Neurons: 11, Grad norm: 5.484e+01\n",
      "Epoch 098, Loss: 1486.1888427734375, Neurons: 11, Grad norm: 5.484e+01\n",
      "Epoch 099, Loss: 1485.789306640625, Neurons: 11, Grad norm: 5.499e+01\n",
      "Epoch 099, Loss: 1485.789306640625, Neurons: 11, Grad norm: 5.499e+01\n",
      "Epoch 099, Test loss: 1515.2196044921875\n",
      "Epoch 099, Test loss: 1515.2196044921875\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "network shape updated to :[5, 6, 1]\n",
      "network shape updated to :[5, 6, 1]\n",
      "Epoch 100, Loss: 1490.678466796875, Neurons: 12, Grad norm: 8.221e+01\n",
      "Epoch 100, Loss: 1490.678466796875, Neurons: 12, Grad norm: 8.221e+01\n",
      "Epoch 101, Loss: 1490.5531005859375, Neurons: 12, Grad norm: 8.227e+01\n",
      "Epoch 101, Loss: 1490.5531005859375, Neurons: 12, Grad norm: 8.227e+01\n",
      "Epoch 102, Loss: 1490.42138671875, Neurons: 12, Grad norm: 8.233e+01\n",
      "Epoch 102, Loss: 1490.42138671875, Neurons: 12, Grad norm: 8.233e+01\n",
      "Epoch 103, Loss: 1490.2830810546875, Neurons: 12, Grad norm: 8.240e+01\n",
      "Epoch 103, Loss: 1490.2830810546875, Neurons: 12, Grad norm: 8.240e+01\n",
      "Epoch 104, Loss: 1490.13818359375, Neurons: 12, Grad norm: 8.246e+01\n",
      "Epoch 104, Loss: 1490.13818359375, Neurons: 12, Grad norm: 8.246e+01\n",
      "Epoch 105, Loss: 1489.986572265625, Neurons: 12, Grad norm: 8.253e+01\n",
      "Epoch 105, Loss: 1489.986572265625, Neurons: 12, Grad norm: 8.253e+01\n",
      "Epoch 106, Loss: 1489.828369140625, Neurons: 12, Grad norm: 8.260e+01\n",
      "Epoch 106, Loss: 1489.828369140625, Neurons: 12, Grad norm: 8.260e+01\n",
      "Epoch 107, Loss: 1489.663330078125, Neurons: 12, Grad norm: 8.268e+01\n",
      "Epoch 107, Loss: 1489.663330078125, Neurons: 12, Grad norm: 8.268e+01\n",
      "Epoch 108, Loss: 1489.4915771484375, Neurons: 12, Grad norm: 8.275e+01\n",
      "Epoch 108, Loss: 1489.4915771484375, Neurons: 12, Grad norm: 8.275e+01\n",
      "Epoch 109, Loss: 1489.3131103515625, Neurons: 12, Grad norm: 8.283e+01\n",
      "Epoch 109, Loss: 1489.3131103515625, Neurons: 12, Grad norm: 8.283e+01\n",
      "Epoch 110, Loss: 1489.1278076171875, Neurons: 12, Grad norm: 8.291e+01\n",
      "Epoch 110, Loss: 1489.1278076171875, Neurons: 12, Grad norm: 8.291e+01\n",
      "Epoch 111, Loss: 1488.935791015625, Neurons: 12, Grad norm: 8.300e+01\n",
      "Epoch 111, Loss: 1488.935791015625, Neurons: 12, Grad norm: 8.300e+01\n",
      "Epoch 112, Loss: 1488.7371826171875, Neurons: 12, Grad norm: 8.309e+01\n",
      "Epoch 112, Loss: 1488.7371826171875, Neurons: 12, Grad norm: 8.309e+01\n",
      "Epoch 113, Loss: 1488.5321044921875, Neurons: 12, Grad norm: 8.318e+01\n",
      "Epoch 113, Loss: 1488.5321044921875, Neurons: 12, Grad norm: 8.318e+01\n",
      "Epoch 114, Loss: 1488.3201904296875, Neurons: 12, Grad norm: 8.327e+01\n",
      "Epoch 114, Loss: 1488.3201904296875, Neurons: 12, Grad norm: 8.327e+01\n",
      "Epoch 115, Loss: 1488.1019287109375, Neurons: 12, Grad norm: 8.337e+01\n",
      "Epoch 115, Loss: 1488.1019287109375, Neurons: 12, Grad norm: 8.337e+01\n",
      "Epoch 116, Loss: 1487.8770751953125, Neurons: 12, Grad norm: 8.347e+01\n",
      "Epoch 116, Loss: 1487.8770751953125, Neurons: 12, Grad norm: 8.347e+01\n",
      "Epoch 117, Loss: 1487.6458740234375, Neurons: 12, Grad norm: 8.357e+01\n",
      "Epoch 117, Loss: 1487.6458740234375, Neurons: 12, Grad norm: 8.357e+01\n",
      "Epoch 118, Loss: 1487.4083251953125, Neurons: 12, Grad norm: 8.368e+01\n",
      "Epoch 118, Loss: 1487.4083251953125, Neurons: 12, Grad norm: 8.368e+01\n",
      "Epoch 119, Loss: 1487.16455078125, Neurons: 12, Grad norm: 8.379e+01\n",
      "Epoch 119, Loss: 1487.16455078125, Neurons: 12, Grad norm: 8.379e+01\n",
      "Epoch 120, Loss: 1486.9144287109375, Neurons: 12, Grad norm: 8.390e+01\n",
      "Epoch 120, Loss: 1486.9144287109375, Neurons: 12, Grad norm: 8.390e+01\n",
      "Epoch 121, Loss: 1486.6583251953125, Neurons: 12, Grad norm: 8.401e+01\n",
      "Epoch 121, Loss: 1486.6583251953125, Neurons: 12, Grad norm: 8.401e+01\n",
      "Epoch 122, Loss: 1486.3961181640625, Neurons: 12, Grad norm: 8.413e+01\n",
      "Epoch 122, Loss: 1486.3961181640625, Neurons: 12, Grad norm: 8.413e+01\n",
      "Epoch 123, Loss: 1486.1275634765625, Neurons: 12, Grad norm: 8.425e+01\n",
      "Epoch 123, Loss: 1486.1275634765625, Neurons: 12, Grad norm: 8.425e+01\n",
      "Epoch 124, Loss: 1485.853271484375, Neurons: 12, Grad norm: 8.437e+01\n",
      "Epoch 124, Loss: 1485.853271484375, Neurons: 12, Grad norm: 8.437e+01\n",
      "Epoch 125, Loss: 1485.5731201171875, Neurons: 12, Grad norm: 8.449e+01\n",
      "Epoch 125, Loss: 1485.5731201171875, Neurons: 12, Grad norm: 8.449e+01\n",
      "Epoch 126, Loss: 1485.286865234375, Neurons: 12, Grad norm: 8.462e+01\n",
      "Epoch 126, Loss: 1485.286865234375, Neurons: 12, Grad norm: 8.462e+01\n",
      "Epoch 127, Loss: 1484.994873046875, Neurons: 12, Grad norm: 8.475e+01\n",
      "Epoch 127, Loss: 1484.994873046875, Neurons: 12, Grad norm: 8.475e+01\n",
      "Epoch 128, Loss: 1484.6968994140625, Neurons: 12, Grad norm: 8.487e+01\n",
      "Epoch 128, Loss: 1484.6968994140625, Neurons: 12, Grad norm: 8.487e+01\n",
      "Epoch 129, Loss: 1484.3934326171875, Neurons: 12, Grad norm: 8.500e+01\n",
      "Epoch 129, Loss: 1484.3934326171875, Neurons: 12, Grad norm: 8.500e+01\n",
      "Epoch 130, Loss: 1484.0843505859375, Neurons: 12, Grad norm: 8.514e+01\n",
      "Epoch 130, Loss: 1484.0843505859375, Neurons: 12, Grad norm: 8.514e+01\n",
      "Epoch 131, Loss: 1483.7694091796875, Neurons: 12, Grad norm: 8.527e+01\n",
      "Epoch 131, Loss: 1483.7694091796875, Neurons: 12, Grad norm: 8.527e+01\n",
      "Epoch 132, Loss: 1483.44921875, Neurons: 12, Grad norm: 8.541e+01\n",
      "Epoch 132, Loss: 1483.44921875, Neurons: 12, Grad norm: 8.541e+01\n",
      "Epoch 133, Loss: 1483.1231689453125, Neurons: 12, Grad norm: 8.555e+01\n",
      "Epoch 133, Loss: 1483.1231689453125, Neurons: 12, Grad norm: 8.555e+01\n",
      "Epoch 134, Loss: 1482.791748046875, Neurons: 12, Grad norm: 8.569e+01\n",
      "Epoch 134, Loss: 1482.791748046875, Neurons: 12, Grad norm: 8.569e+01\n",
      "Epoch 135, Loss: 1482.454833984375, Neurons: 12, Grad norm: 8.583e+01\n",
      "Epoch 135, Loss: 1482.454833984375, Neurons: 12, Grad norm: 8.583e+01\n",
      "Epoch 136, Loss: 1482.1124267578125, Neurons: 12, Grad norm: 8.598e+01\n",
      "Epoch 136, Loss: 1482.1124267578125, Neurons: 12, Grad norm: 8.598e+01\n",
      "Epoch 137, Loss: 1481.7646484375, Neurons: 12, Grad norm: 8.613e+01\n",
      "Epoch 137, Loss: 1481.7646484375, Neurons: 12, Grad norm: 8.613e+01\n",
      "Epoch 138, Loss: 1481.4114990234375, Neurons: 12, Grad norm: 8.628e+01\n",
      "Epoch 138, Loss: 1481.4114990234375, Neurons: 12, Grad norm: 8.628e+01\n",
      "Epoch 139, Loss: 1481.0528564453125, Neurons: 12, Grad norm: 8.644e+01\n",
      "Epoch 139, Loss: 1481.0528564453125, Neurons: 12, Grad norm: 8.644e+01\n",
      "Epoch 140, Loss: 1480.6888427734375, Neurons: 12, Grad norm: 8.659e+01\n",
      "Epoch 140, Loss: 1480.6888427734375, Neurons: 12, Grad norm: 8.659e+01\n",
      "Epoch 141, Loss: 1480.3194580078125, Neurons: 12, Grad norm: 8.675e+01\n",
      "Epoch 141, Loss: 1480.3194580078125, Neurons: 12, Grad norm: 8.675e+01\n",
      "Epoch 142, Loss: 1479.944580078125, Neurons: 12, Grad norm: 8.692e+01\n",
      "Epoch 142, Loss: 1479.944580078125, Neurons: 12, Grad norm: 8.692e+01\n",
      "Epoch 143, Loss: 1479.564453125, Neurons: 12, Grad norm: 8.709e+01\n",
      "Epoch 143, Loss: 1479.564453125, Neurons: 12, Grad norm: 8.709e+01\n",
      "Epoch 144, Loss: 1479.1788330078125, Neurons: 12, Grad norm: 8.726e+01\n",
      "Epoch 144, Loss: 1479.1788330078125, Neurons: 12, Grad norm: 8.726e+01\n",
      "Epoch 145, Loss: 1478.787841796875, Neurons: 12, Grad norm: 8.743e+01\n",
      "Epoch 145, Loss: 1478.787841796875, Neurons: 12, Grad norm: 8.743e+01\n",
      "Epoch 146, Loss: 1478.391357421875, Neurons: 12, Grad norm: 8.761e+01\n",
      "Epoch 146, Loss: 1478.391357421875, Neurons: 12, Grad norm: 8.761e+01\n",
      "Epoch 147, Loss: 1477.9891357421875, Neurons: 12, Grad norm: 8.779e+01\n",
      "Epoch 147, Loss: 1477.9891357421875, Neurons: 12, Grad norm: 8.779e+01\n",
      "Epoch 148, Loss: 1477.5816650390625, Neurons: 12, Grad norm: 8.797e+01\n",
      "Epoch 148, Loss: 1477.5816650390625, Neurons: 12, Grad norm: 8.797e+01\n",
      "Epoch 149, Loss: 1477.1685791015625, Neurons: 12, Grad norm: 8.816e+01\n",
      "Epoch 149, Loss: 1477.1685791015625, Neurons: 12, Grad norm: 8.816e+01\n",
      "Epoch 150, Loss: 1476.7498779296875, Neurons: 12, Grad norm: 8.835e+01\n",
      "Epoch 150, Loss: 1476.7498779296875, Neurons: 12, Grad norm: 8.835e+01\n",
      "Epoch 151, Loss: 1476.3253173828125, Neurons: 12, Grad norm: 8.855e+01\n",
      "Epoch 151, Loss: 1476.3253173828125, Neurons: 12, Grad norm: 8.855e+01\n",
      "Epoch 152, Loss: 1475.89501953125, Neurons: 12, Grad norm: 8.875e+01\n",
      "Epoch 152, Loss: 1475.89501953125, Neurons: 12, Grad norm: 8.875e+01\n",
      "Epoch 153, Loss: 1475.4591064453125, Neurons: 12, Grad norm: 8.896e+01\n",
      "Epoch 153, Loss: 1475.4591064453125, Neurons: 12, Grad norm: 8.896e+01\n",
      "Epoch 154, Loss: 1475.0172119140625, Neurons: 12, Grad norm: 8.916e+01\n",
      "Epoch 154, Loss: 1475.0172119140625, Neurons: 12, Grad norm: 8.916e+01\n",
      "Epoch 155, Loss: 1474.5693359375, Neurons: 12, Grad norm: 8.938e+01\n",
      "Epoch 155, Loss: 1474.5693359375, Neurons: 12, Grad norm: 8.938e+01\n",
      "Epoch 156, Loss: 1474.1153564453125, Neurons: 12, Grad norm: 8.959e+01\n",
      "Epoch 156, Loss: 1474.1153564453125, Neurons: 12, Grad norm: 8.959e+01\n",
      "Epoch 157, Loss: 1473.655029296875, Neurons: 12, Grad norm: 8.981e+01\n",
      "Epoch 157, Loss: 1473.655029296875, Neurons: 12, Grad norm: 8.981e+01\n",
      "Epoch 158, Loss: 1473.1888427734375, Neurons: 12, Grad norm: 9.003e+01\n",
      "Epoch 158, Loss: 1473.1888427734375, Neurons: 12, Grad norm: 9.003e+01\n",
      "Epoch 159, Loss: 1472.716064453125, Neurons: 12, Grad norm: 9.026e+01\n",
      "Epoch 159, Loss: 1472.716064453125, Neurons: 12, Grad norm: 9.026e+01\n",
      "Epoch 160, Loss: 1472.237060546875, Neurons: 12, Grad norm: 9.047e+01\n",
      "Epoch 160, Loss: 1472.237060546875, Neurons: 12, Grad norm: 9.047e+01\n",
      "Epoch 161, Loss: 1471.7515869140625, Neurons: 12, Grad norm: 9.069e+01\n",
      "Epoch 161, Loss: 1471.7515869140625, Neurons: 12, Grad norm: 9.069e+01\n",
      "Epoch 162, Loss: 1471.259765625, Neurons: 12, Grad norm: 9.089e+01\n",
      "Epoch 162, Loss: 1471.259765625, Neurons: 12, Grad norm: 9.089e+01\n",
      "Epoch 163, Loss: 1470.7615966796875, Neurons: 12, Grad norm: 9.107e+01\n",
      "Epoch 163, Loss: 1470.7615966796875, Neurons: 12, Grad norm: 9.107e+01\n",
      "Epoch 164, Loss: 1470.2569580078125, Neurons: 12, Grad norm: 9.122e+01\n",
      "Epoch 164, Loss: 1470.2569580078125, Neurons: 12, Grad norm: 9.122e+01\n",
      "Epoch 165, Loss: 1469.74658203125, Neurons: 12, Grad norm: 9.131e+01\n",
      "Epoch 165, Loss: 1469.74658203125, Neurons: 12, Grad norm: 9.131e+01\n",
      "Epoch 166, Loss: 1469.2308349609375, Neurons: 12, Grad norm: 9.132e+01\n",
      "Epoch 166, Loss: 1469.2308349609375, Neurons: 12, Grad norm: 9.132e+01\n",
      "Epoch 167, Loss: 1468.7108154296875, Neurons: 12, Grad norm: 9.121e+01\n",
      "Epoch 167, Loss: 1468.7108154296875, Neurons: 12, Grad norm: 9.121e+01\n",
      "Epoch 168, Loss: 1468.1878662109375, Neurons: 12, Grad norm: 9.088e+01\n",
      "Epoch 168, Loss: 1468.1878662109375, Neurons: 12, Grad norm: 9.088e+01\n",
      "Epoch 169, Loss: 1467.66552734375, Neurons: 12, Grad norm: 9.043e+01\n",
      "Epoch 169, Loss: 1467.66552734375, Neurons: 12, Grad norm: 9.043e+01\n",
      "Epoch 170, Loss: 1467.1522216796875, Neurons: 12, Grad norm: 9.057e+01\n",
      "Epoch 170, Loss: 1467.1522216796875, Neurons: 12, Grad norm: 9.057e+01\n",
      "Epoch 171, Loss: 1466.6400146484375, Neurons: 12, Grad norm: 9.069e+01\n",
      "Epoch 171, Loss: 1466.6400146484375, Neurons: 12, Grad norm: 9.069e+01\n",
      "Epoch 172, Loss: 1466.124267578125, Neurons: 12, Grad norm: 9.082e+01\n",
      "Epoch 172, Loss: 1466.124267578125, Neurons: 12, Grad norm: 9.082e+01\n",
      "Epoch 173, Loss: 1465.6048583984375, Neurons: 12, Grad norm: 9.093e+01\n",
      "Epoch 173, Loss: 1465.6048583984375, Neurons: 12, Grad norm: 9.093e+01\n",
      "Epoch 174, Loss: 1465.0814208984375, Neurons: 12, Grad norm: 9.104e+01\n",
      "Epoch 174, Loss: 1465.0814208984375, Neurons: 12, Grad norm: 9.104e+01\n",
      "Epoch 175, Loss: 1464.5540771484375, Neurons: 12, Grad norm: 9.115e+01\n",
      "Epoch 175, Loss: 1464.5540771484375, Neurons: 12, Grad norm: 9.115e+01\n",
      "Epoch 176, Loss: 1464.0225830078125, Neurons: 12, Grad norm: 9.125e+01\n",
      "Epoch 176, Loss: 1464.0225830078125, Neurons: 12, Grad norm: 9.125e+01\n",
      "Epoch 177, Loss: 1463.487060546875, Neurons: 12, Grad norm: 9.134e+01\n",
      "Epoch 177, Loss: 1463.487060546875, Neurons: 12, Grad norm: 9.134e+01\n",
      "Epoch 178, Loss: 1462.9473876953125, Neurons: 12, Grad norm: 9.143e+01\n",
      "Epoch 178, Loss: 1462.9473876953125, Neurons: 12, Grad norm: 9.143e+01\n",
      "Epoch 179, Loss: 1462.403564453125, Neurons: 12, Grad norm: 9.151e+01\n",
      "Epoch 179, Loss: 1462.403564453125, Neurons: 12, Grad norm: 9.151e+01\n",
      "Epoch 180, Loss: 1461.8555908203125, Neurons: 12, Grad norm: 9.158e+01\n",
      "Epoch 180, Loss: 1461.8555908203125, Neurons: 12, Grad norm: 9.158e+01\n",
      "Epoch 181, Loss: 1461.3033447265625, Neurons: 12, Grad norm: 9.165e+01\n",
      "Epoch 181, Loss: 1461.3033447265625, Neurons: 12, Grad norm: 9.165e+01\n",
      "Epoch 182, Loss: 1460.7470703125, Neurons: 12, Grad norm: 9.170e+01\n",
      "Epoch 182, Loss: 1460.7470703125, Neurons: 12, Grad norm: 9.170e+01\n",
      "Epoch 183, Loss: 1460.1866455078125, Neurons: 12, Grad norm: 9.175e+01\n",
      "Epoch 183, Loss: 1460.1866455078125, Neurons: 12, Grad norm: 9.175e+01\n",
      "Epoch 184, Loss: 1459.6221923828125, Neurons: 12, Grad norm: 9.179e+01\n",
      "Epoch 184, Loss: 1459.6221923828125, Neurons: 12, Grad norm: 9.179e+01\n",
      "Epoch 185, Loss: 1459.0537109375, Neurons: 12, Grad norm: 9.183e+01\n",
      "Epoch 185, Loss: 1459.0537109375, Neurons: 12, Grad norm: 9.183e+01\n",
      "Epoch 186, Loss: 1458.481201171875, Neurons: 12, Grad norm: 9.185e+01\n",
      "Epoch 186, Loss: 1458.481201171875, Neurons: 12, Grad norm: 9.185e+01\n",
      "Epoch 187, Loss: 1457.90478515625, Neurons: 12, Grad norm: 9.187e+01\n",
      "Epoch 187, Loss: 1457.90478515625, Neurons: 12, Grad norm: 9.187e+01\n",
      "Epoch 188, Loss: 1457.3245849609375, Neurons: 12, Grad norm: 9.188e+01\n",
      "Epoch 188, Loss: 1457.3245849609375, Neurons: 12, Grad norm: 9.188e+01\n",
      "Epoch 189, Loss: 1456.7403564453125, Neurons: 12, Grad norm: 9.187e+01\n",
      "Epoch 189, Loss: 1456.7403564453125, Neurons: 12, Grad norm: 9.187e+01\n",
      "Epoch 190, Loss: 1456.152587890625, Neurons: 12, Grad norm: 9.186e+01\n",
      "Epoch 190, Loss: 1456.152587890625, Neurons: 12, Grad norm: 9.186e+01\n",
      "Epoch 191, Loss: 1455.56103515625, Neurons: 12, Grad norm: 9.184e+01\n",
      "Epoch 191, Loss: 1455.56103515625, Neurons: 12, Grad norm: 9.184e+01\n",
      "Epoch 192, Loss: 1454.9656982421875, Neurons: 12, Grad norm: 9.181e+01\n",
      "Epoch 192, Loss: 1454.9656982421875, Neurons: 12, Grad norm: 9.181e+01\n",
      "Epoch 193, Loss: 1454.3670654296875, Neurons: 12, Grad norm: 9.177e+01\n",
      "Epoch 193, Loss: 1454.3670654296875, Neurons: 12, Grad norm: 9.177e+01\n",
      "Epoch 194, Loss: 1453.7647705078125, Neurons: 12, Grad norm: 9.173e+01\n",
      "Epoch 194, Loss: 1453.7647705078125, Neurons: 12, Grad norm: 9.173e+01\n",
      "Epoch 195, Loss: 1453.1591796875, Neurons: 12, Grad norm: 9.167e+01\n",
      "Epoch 195, Loss: 1453.1591796875, Neurons: 12, Grad norm: 9.167e+01\n",
      "Epoch 196, Loss: 1452.55029296875, Neurons: 12, Grad norm: 9.160e+01\n",
      "Epoch 196, Loss: 1452.55029296875, Neurons: 12, Grad norm: 9.160e+01\n",
      "Epoch 197, Loss: 1451.938232421875, Neurons: 12, Grad norm: 9.152e+01\n",
      "Epoch 197, Loss: 1451.938232421875, Neurons: 12, Grad norm: 9.152e+01\n",
      "Epoch 198, Loss: 1451.3228759765625, Neurons: 12, Grad norm: 9.144e+01\n",
      "Epoch 198, Loss: 1451.3228759765625, Neurons: 12, Grad norm: 9.144e+01\n",
      "Epoch 199, Loss: 1450.7047119140625, Neurons: 12, Grad norm: 9.134e+01\n",
      "Epoch 199, Loss: 1450.7047119140625, Neurons: 12, Grad norm: 9.134e+01\n",
      "Epoch 199, Test loss: 1479.4166259765625\n",
      "Epoch 199, Test loss: 1479.4166259765625\n",
      "Added neuron to hidden layer 1 with activation tanh\n",
      "Added neuron to hidden layer 1 with activation tanh\n",
      "network shape updated to :[6, 6, 1]\n",
      "network shape updated to :[6, 6, 1]\n",
      "Epoch 200, Loss: 1455.0947265625, Neurons: 13, Grad norm: 9.752e+01\n",
      "Epoch 200, Loss: 1455.0947265625, Neurons: 13, Grad norm: 9.752e+01\n",
      "Epoch 201, Loss: 1454.9453125, Neurons: 13, Grad norm: 9.749e+01\n",
      "Epoch 201, Loss: 1454.9453125, Neurons: 13, Grad norm: 9.749e+01\n",
      "Epoch 202, Loss: 1454.7882080078125, Neurons: 13, Grad norm: 9.747e+01\n",
      "Epoch 202, Loss: 1454.7882080078125, Neurons: 13, Grad norm: 9.747e+01\n",
      "Epoch 203, Loss: 1454.62353515625, Neurons: 13, Grad norm: 9.744e+01\n",
      "Epoch 203, Loss: 1454.62353515625, Neurons: 13, Grad norm: 9.744e+01\n",
      "Epoch 204, Loss: 1454.451171875, Neurons: 13, Grad norm: 9.742e+01\n",
      "Epoch 204, Loss: 1454.451171875, Neurons: 13, Grad norm: 9.742e+01\n",
      "Epoch 205, Loss: 1454.2711181640625, Neurons: 13, Grad norm: 9.738e+01\n",
      "Epoch 205, Loss: 1454.2711181640625, Neurons: 13, Grad norm: 9.738e+01\n",
      "Epoch 206, Loss: 1454.0833740234375, Neurons: 13, Grad norm: 9.735e+01\n",
      "Epoch 206, Loss: 1454.0833740234375, Neurons: 13, Grad norm: 9.735e+01\n",
      "Epoch 207, Loss: 1453.8875732421875, Neurons: 13, Grad norm: 9.732e+01\n",
      "Epoch 207, Loss: 1453.8875732421875, Neurons: 13, Grad norm: 9.732e+01\n",
      "Epoch 208, Loss: 1453.684326171875, Neurons: 13, Grad norm: 9.728e+01\n",
      "Epoch 208, Loss: 1453.684326171875, Neurons: 13, Grad norm: 9.728e+01\n",
      "Epoch 209, Loss: 1453.4732666015625, Neurons: 13, Grad norm: 9.724e+01\n",
      "Epoch 209, Loss: 1453.4732666015625, Neurons: 13, Grad norm: 9.724e+01\n",
      "Epoch 210, Loss: 1453.2547607421875, Neurons: 13, Grad norm: 9.720e+01\n",
      "Epoch 210, Loss: 1453.2547607421875, Neurons: 13, Grad norm: 9.720e+01\n",
      "Epoch 211, Loss: 1453.02880859375, Neurons: 13, Grad norm: 9.716e+01\n",
      "Epoch 211, Loss: 1453.02880859375, Neurons: 13, Grad norm: 9.716e+01\n",
      "Epoch 212, Loss: 1452.7952880859375, Neurons: 13, Grad norm: 9.711e+01\n",
      "Epoch 212, Loss: 1452.7952880859375, Neurons: 13, Grad norm: 9.711e+01\n",
      "Epoch 213, Loss: 1452.554443359375, Neurons: 13, Grad norm: 9.706e+01\n",
      "Epoch 213, Loss: 1452.554443359375, Neurons: 13, Grad norm: 9.706e+01\n",
      "Epoch 214, Loss: 1452.306396484375, Neurons: 13, Grad norm: 9.701e+01\n",
      "Epoch 214, Loss: 1452.306396484375, Neurons: 13, Grad norm: 9.701e+01\n",
      "Epoch 215, Loss: 1452.05126953125, Neurons: 13, Grad norm: 9.695e+01\n",
      "Epoch 215, Loss: 1452.05126953125, Neurons: 13, Grad norm: 9.695e+01\n",
      "Epoch 216, Loss: 1451.789306640625, Neurons: 13, Grad norm: 9.689e+01\n",
      "Epoch 216, Loss: 1451.789306640625, Neurons: 13, Grad norm: 9.689e+01\n",
      "Epoch 217, Loss: 1451.5206298828125, Neurons: 13, Grad norm: 9.683e+01\n",
      "Epoch 217, Loss: 1451.5206298828125, Neurons: 13, Grad norm: 9.683e+01\n",
      "Epoch 218, Loss: 1451.2449951171875, Neurons: 13, Grad norm: 9.676e+01\n",
      "Epoch 218, Loss: 1451.2449951171875, Neurons: 13, Grad norm: 9.676e+01\n",
      "Epoch 219, Loss: 1450.962890625, Neurons: 13, Grad norm: 9.670e+01\n",
      "Epoch 219, Loss: 1450.962890625, Neurons: 13, Grad norm: 9.670e+01\n",
      "Epoch 220, Loss: 1450.674560546875, Neurons: 13, Grad norm: 9.662e+01\n",
      "Epoch 220, Loss: 1450.674560546875, Neurons: 13, Grad norm: 9.662e+01\n",
      "Epoch 221, Loss: 1450.3797607421875, Neurons: 13, Grad norm: 9.655e+01\n",
      "Epoch 221, Loss: 1450.3797607421875, Neurons: 13, Grad norm: 9.655e+01\n",
      "Epoch 222, Loss: 1450.0791015625, Neurons: 13, Grad norm: 9.647e+01\n",
      "Epoch 222, Loss: 1450.0791015625, Neurons: 13, Grad norm: 9.647e+01\n",
      "Epoch 223, Loss: 1449.7724609375, Neurons: 13, Grad norm: 9.639e+01\n",
      "Epoch 223, Loss: 1449.7724609375, Neurons: 13, Grad norm: 9.639e+01\n",
      "Epoch 224, Loss: 1449.4598388671875, Neurons: 13, Grad norm: 9.631e+01\n",
      "Epoch 224, Loss: 1449.4598388671875, Neurons: 13, Grad norm: 9.631e+01\n",
      "Epoch 225, Loss: 1449.1417236328125, Neurons: 13, Grad norm: 9.622e+01\n",
      "Epoch 225, Loss: 1449.1417236328125, Neurons: 13, Grad norm: 9.622e+01\n",
      "Epoch 226, Loss: 1448.8182373046875, Neurons: 13, Grad norm: 9.613e+01\n",
      "Epoch 226, Loss: 1448.8182373046875, Neurons: 13, Grad norm: 9.613e+01\n",
      "Epoch 227, Loss: 1448.489013671875, Neurons: 13, Grad norm: 9.603e+01\n",
      "Epoch 227, Loss: 1448.489013671875, Neurons: 13, Grad norm: 9.603e+01\n",
      "Epoch 228, Loss: 1448.15478515625, Neurons: 13, Grad norm: 9.593e+01\n",
      "Epoch 228, Loss: 1448.15478515625, Neurons: 13, Grad norm: 9.593e+01\n",
      "Epoch 229, Loss: 1447.8155517578125, Neurons: 13, Grad norm: 9.583e+01\n",
      "Epoch 229, Loss: 1447.8155517578125, Neurons: 13, Grad norm: 9.583e+01\n",
      "Epoch 230, Loss: 1447.4713134765625, Neurons: 13, Grad norm: 9.572e+01\n",
      "Epoch 230, Loss: 1447.4713134765625, Neurons: 13, Grad norm: 9.572e+01\n",
      "Epoch 231, Loss: 1447.1221923828125, Neurons: 13, Grad norm: 9.561e+01\n",
      "Epoch 231, Loss: 1447.1221923828125, Neurons: 13, Grad norm: 9.561e+01\n",
      "Epoch 232, Loss: 1446.7685546875, Neurons: 13, Grad norm: 9.550e+01\n",
      "Epoch 232, Loss: 1446.7685546875, Neurons: 13, Grad norm: 9.550e+01\n",
      "Epoch 233, Loss: 1446.4100341796875, Neurons: 13, Grad norm: 9.538e+01\n",
      "Epoch 233, Loss: 1446.4100341796875, Neurons: 13, Grad norm: 9.538e+01\n",
      "Epoch 234, Loss: 1446.04736328125, Neurons: 13, Grad norm: 9.526e+01\n",
      "Epoch 234, Loss: 1446.04736328125, Neurons: 13, Grad norm: 9.526e+01\n",
      "Epoch 235, Loss: 1445.6802978515625, Neurons: 13, Grad norm: 9.513e+01\n",
      "Epoch 235, Loss: 1445.6802978515625, Neurons: 13, Grad norm: 9.513e+01\n",
      "Epoch 236, Loss: 1445.3089599609375, Neurons: 13, Grad norm: 9.500e+01\n",
      "Epoch 236, Loss: 1445.3089599609375, Neurons: 13, Grad norm: 9.500e+01\n",
      "Epoch 237, Loss: 1444.93359375, Neurons: 13, Grad norm: 9.487e+01\n",
      "Epoch 237, Loss: 1444.93359375, Neurons: 13, Grad norm: 9.487e+01\n",
      "Epoch 238, Loss: 1444.5543212890625, Neurons: 13, Grad norm: 9.474e+01\n",
      "Epoch 238, Loss: 1444.5543212890625, Neurons: 13, Grad norm: 9.474e+01\n",
      "Epoch 239, Loss: 1444.1710205078125, Neurons: 13, Grad norm: 9.460e+01\n",
      "Epoch 239, Loss: 1444.1710205078125, Neurons: 13, Grad norm: 9.460e+01\n",
      "Epoch 240, Loss: 1443.7840576171875, Neurons: 13, Grad norm: 9.445e+01\n",
      "Epoch 240, Loss: 1443.7840576171875, Neurons: 13, Grad norm: 9.445e+01\n",
      "Epoch 241, Loss: 1443.3935546875, Neurons: 13, Grad norm: 9.431e+01\n",
      "Epoch 241, Loss: 1443.3935546875, Neurons: 13, Grad norm: 9.431e+01\n",
      "Epoch 242, Loss: 1442.99951171875, Neurons: 13, Grad norm: 9.416e+01\n",
      "Epoch 242, Loss: 1442.99951171875, Neurons: 13, Grad norm: 9.416e+01\n",
      "Epoch 243, Loss: 1442.601806640625, Neurons: 13, Grad norm: 9.400e+01\n",
      "Epoch 243, Loss: 1442.601806640625, Neurons: 13, Grad norm: 9.400e+01\n",
      "Epoch 244, Loss: 1442.2010498046875, Neurons: 13, Grad norm: 9.384e+01\n",
      "Epoch 244, Loss: 1442.2010498046875, Neurons: 13, Grad norm: 9.384e+01\n",
      "Epoch 245, Loss: 1441.796875, Neurons: 13, Grad norm: 9.368e+01\n",
      "Epoch 245, Loss: 1441.796875, Neurons: 13, Grad norm: 9.368e+01\n",
      "Epoch 246, Loss: 1441.3895263671875, Neurons: 13, Grad norm: 9.352e+01\n",
      "Epoch 246, Loss: 1441.3895263671875, Neurons: 13, Grad norm: 9.352e+01\n",
      "Epoch 247, Loss: 1440.9791259765625, Neurons: 13, Grad norm: 9.335e+01\n",
      "Epoch 247, Loss: 1440.9791259765625, Neurons: 13, Grad norm: 9.335e+01\n",
      "Epoch 248, Loss: 1440.5657958984375, Neurons: 13, Grad norm: 9.318e+01\n",
      "Epoch 248, Loss: 1440.5657958984375, Neurons: 13, Grad norm: 9.318e+01\n",
      "Epoch 249, Loss: 1440.1494140625, Neurons: 13, Grad norm: 9.301e+01\n",
      "Epoch 249, Loss: 1440.1494140625, Neurons: 13, Grad norm: 9.301e+01\n",
      "Epoch 250, Loss: 1439.73046875, Neurons: 13, Grad norm: 9.283e+01\n",
      "Epoch 250, Loss: 1439.73046875, Neurons: 13, Grad norm: 9.283e+01\n",
      "Epoch 251, Loss: 1439.30859375, Neurons: 13, Grad norm: 9.265e+01\n",
      "Epoch 251, Loss: 1439.30859375, Neurons: 13, Grad norm: 9.265e+01\n",
      "Epoch 252, Loss: 1438.8841552734375, Neurons: 13, Grad norm: 9.247e+01\n",
      "Epoch 252, Loss: 1438.8841552734375, Neurons: 13, Grad norm: 9.247e+01\n",
      "Epoch 253, Loss: 1438.45703125, Neurons: 13, Grad norm: 9.228e+01\n",
      "Epoch 253, Loss: 1438.45703125, Neurons: 13, Grad norm: 9.228e+01\n",
      "Epoch 254, Loss: 1438.027587890625, Neurons: 13, Grad norm: 9.210e+01\n",
      "Epoch 254, Loss: 1438.027587890625, Neurons: 13, Grad norm: 9.210e+01\n",
      "Epoch 255, Loss: 1437.5955810546875, Neurons: 13, Grad norm: 9.191e+01\n",
      "Epoch 255, Loss: 1437.5955810546875, Neurons: 13, Grad norm: 9.191e+01\n",
      "Epoch 256, Loss: 1437.161376953125, Neurons: 13, Grad norm: 9.171e+01\n",
      "Epoch 256, Loss: 1437.161376953125, Neurons: 13, Grad norm: 9.171e+01\n",
      "Epoch 257, Loss: 1436.724853515625, Neurons: 13, Grad norm: 9.152e+01\n",
      "Epoch 257, Loss: 1436.724853515625, Neurons: 13, Grad norm: 9.152e+01\n",
      "Epoch 258, Loss: 1436.2857666015625, Neurons: 13, Grad norm: 9.132e+01\n",
      "Epoch 258, Loss: 1436.2857666015625, Neurons: 13, Grad norm: 9.132e+01\n",
      "Epoch 259, Loss: 1435.844970703125, Neurons: 13, Grad norm: 9.112e+01\n",
      "Epoch 259, Loss: 1435.844970703125, Neurons: 13, Grad norm: 9.112e+01\n",
      "Epoch 260, Loss: 1435.40185546875, Neurons: 13, Grad norm: 9.092e+01\n",
      "Epoch 260, Loss: 1435.40185546875, Neurons: 13, Grad norm: 9.092e+01\n",
      "Epoch 261, Loss: 1434.95654296875, Neurons: 13, Grad norm: 9.072e+01\n",
      "Epoch 261, Loss: 1434.95654296875, Neurons: 13, Grad norm: 9.072e+01\n",
      "Epoch 262, Loss: 1434.509521484375, Neurons: 13, Grad norm: 9.051e+01\n",
      "Epoch 262, Loss: 1434.509521484375, Neurons: 13, Grad norm: 9.051e+01\n",
      "Epoch 263, Loss: 1434.0604248046875, Neurons: 13, Grad norm: 9.031e+01\n",
      "Epoch 263, Loss: 1434.0604248046875, Neurons: 13, Grad norm: 9.031e+01\n",
      "Epoch 264, Loss: 1433.6094970703125, Neurons: 13, Grad norm: 9.010e+01\n",
      "Epoch 264, Loss: 1433.6094970703125, Neurons: 13, Grad norm: 9.010e+01\n",
      "Epoch 265, Loss: 1433.15673828125, Neurons: 13, Grad norm: 8.989e+01\n",
      "Epoch 265, Loss: 1433.15673828125, Neurons: 13, Grad norm: 8.989e+01\n",
      "Epoch 266, Loss: 1432.7020263671875, Neurons: 13, Grad norm: 8.968e+01\n",
      "Epoch 266, Loss: 1432.7020263671875, Neurons: 13, Grad norm: 8.968e+01\n",
      "Epoch 267, Loss: 1432.245849609375, Neurons: 13, Grad norm: 8.947e+01\n",
      "Epoch 267, Loss: 1432.245849609375, Neurons: 13, Grad norm: 8.947e+01\n",
      "Epoch 268, Loss: 1431.7877197265625, Neurons: 13, Grad norm: 8.926e+01\n",
      "Epoch 268, Loss: 1431.7877197265625, Neurons: 13, Grad norm: 8.926e+01\n",
      "Epoch 269, Loss: 1431.328125, Neurons: 13, Grad norm: 8.904e+01\n",
      "Epoch 269, Loss: 1431.328125, Neurons: 13, Grad norm: 8.904e+01\n",
      "Epoch 270, Loss: 1430.8668212890625, Neurons: 13, Grad norm: 8.883e+01\n",
      "Epoch 270, Loss: 1430.8668212890625, Neurons: 13, Grad norm: 8.883e+01\n",
      "Epoch 271, Loss: 1430.40380859375, Neurons: 13, Grad norm: 8.862e+01\n",
      "Epoch 271, Loss: 1430.40380859375, Neurons: 13, Grad norm: 8.862e+01\n",
      "Epoch 272, Loss: 1429.939453125, Neurons: 13, Grad norm: 8.840e+01\n",
      "Epoch 272, Loss: 1429.939453125, Neurons: 13, Grad norm: 8.840e+01\n",
      "Epoch 273, Loss: 1429.4735107421875, Neurons: 13, Grad norm: 8.819e+01\n",
      "Epoch 273, Loss: 1429.4735107421875, Neurons: 13, Grad norm: 8.819e+01\n",
      "Epoch 274, Loss: 1429.006103515625, Neurons: 13, Grad norm: 8.797e+01\n",
      "Epoch 274, Loss: 1429.006103515625, Neurons: 13, Grad norm: 8.797e+01\n",
      "Epoch 275, Loss: 1428.5372314453125, Neurons: 13, Grad norm: 8.776e+01\n",
      "Epoch 275, Loss: 1428.5372314453125, Neurons: 13, Grad norm: 8.776e+01\n",
      "Epoch 276, Loss: 1428.0667724609375, Neurons: 13, Grad norm: 8.755e+01\n",
      "Epoch 276, Loss: 1428.0667724609375, Neurons: 13, Grad norm: 8.755e+01\n",
      "Epoch 277, Loss: 1427.5950927734375, Neurons: 13, Grad norm: 8.733e+01\n",
      "Epoch 277, Loss: 1427.5950927734375, Neurons: 13, Grad norm: 8.733e+01\n",
      "Epoch 278, Loss: 1427.1220703125, Neurons: 13, Grad norm: 8.712e+01\n",
      "Epoch 278, Loss: 1427.1220703125, Neurons: 13, Grad norm: 8.712e+01\n",
      "Epoch 279, Loss: 1426.6475830078125, Neurons: 13, Grad norm: 8.691e+01\n",
      "Epoch 279, Loss: 1426.6475830078125, Neurons: 13, Grad norm: 8.691e+01\n",
      "Epoch 280, Loss: 1426.1717529296875, Neurons: 13, Grad norm: 8.670e+01\n",
      "Epoch 280, Loss: 1426.1717529296875, Neurons: 13, Grad norm: 8.670e+01\n",
      "Epoch 281, Loss: 1425.694580078125, Neurons: 13, Grad norm: 8.648e+01\n",
      "Epoch 281, Loss: 1425.694580078125, Neurons: 13, Grad norm: 8.648e+01\n",
      "Epoch 282, Loss: 1425.216064453125, Neurons: 13, Grad norm: 8.627e+01\n",
      "Epoch 282, Loss: 1425.216064453125, Neurons: 13, Grad norm: 8.627e+01\n",
      "Epoch 283, Loss: 1424.736328125, Neurons: 13, Grad norm: 8.607e+01\n",
      "Epoch 283, Loss: 1424.736328125, Neurons: 13, Grad norm: 8.607e+01\n",
      "Epoch 284, Loss: 1424.25537109375, Neurons: 13, Grad norm: 8.586e+01\n",
      "Epoch 284, Loss: 1424.25537109375, Neurons: 13, Grad norm: 8.586e+01\n",
      "Epoch 285, Loss: 1423.7728271484375, Neurons: 13, Grad norm: 8.565e+01\n",
      "Epoch 285, Loss: 1423.7728271484375, Neurons: 13, Grad norm: 8.565e+01\n",
      "Epoch 286, Loss: 1423.289306640625, Neurons: 13, Grad norm: 8.545e+01\n",
      "Epoch 286, Loss: 1423.289306640625, Neurons: 13, Grad norm: 8.545e+01\n",
      "Epoch 287, Loss: 1422.8043212890625, Neurons: 13, Grad norm: 8.524e+01\n",
      "Epoch 287, Loss: 1422.8043212890625, Neurons: 13, Grad norm: 8.524e+01\n",
      "Epoch 288, Loss: 1422.3182373046875, Neurons: 13, Grad norm: 8.504e+01\n",
      "Epoch 288, Loss: 1422.3182373046875, Neurons: 13, Grad norm: 8.504e+01\n",
      "Epoch 289, Loss: 1421.830810546875, Neurons: 13, Grad norm: 8.484e+01\n",
      "Epoch 289, Loss: 1421.830810546875, Neurons: 13, Grad norm: 8.484e+01\n",
      "Epoch 290, Loss: 1421.342041015625, Neurons: 13, Grad norm: 8.465e+01\n",
      "Epoch 290, Loss: 1421.342041015625, Neurons: 13, Grad norm: 8.465e+01\n",
      "Epoch 291, Loss: 1420.85205078125, Neurons: 13, Grad norm: 8.445e+01\n",
      "Epoch 291, Loss: 1420.85205078125, Neurons: 13, Grad norm: 8.445e+01\n",
      "Epoch 292, Loss: 1420.36083984375, Neurons: 13, Grad norm: 8.426e+01\n",
      "Epoch 292, Loss: 1420.36083984375, Neurons: 13, Grad norm: 8.426e+01\n",
      "Epoch 293, Loss: 1419.868408203125, Neurons: 13, Grad norm: 8.406e+01\n",
      "Epoch 293, Loss: 1419.868408203125, Neurons: 13, Grad norm: 8.406e+01\n",
      "Epoch 294, Loss: 1419.37451171875, Neurons: 13, Grad norm: 8.388e+01\n",
      "Epoch 294, Loss: 1419.37451171875, Neurons: 13, Grad norm: 8.388e+01\n",
      "Epoch 295, Loss: 1418.8795166015625, Neurons: 13, Grad norm: 8.369e+01\n",
      "Epoch 295, Loss: 1418.8795166015625, Neurons: 13, Grad norm: 8.369e+01\n",
      "Epoch 296, Loss: 1418.3831787109375, Neurons: 13, Grad norm: 8.350e+01\n",
      "Epoch 296, Loss: 1418.3831787109375, Neurons: 13, Grad norm: 8.350e+01\n",
      "Epoch 297, Loss: 1417.8856201171875, Neurons: 13, Grad norm: 8.332e+01\n",
      "Epoch 297, Loss: 1417.8856201171875, Neurons: 13, Grad norm: 8.332e+01\n",
      "Epoch 298, Loss: 1417.38671875, Neurons: 13, Grad norm: 8.314e+01\n",
      "Epoch 298, Loss: 1417.38671875, Neurons: 13, Grad norm: 8.314e+01\n",
      "Epoch 299, Loss: 1416.8863525390625, Neurons: 13, Grad norm: 8.296e+01\n",
      "Epoch 299, Loss: 1416.8863525390625, Neurons: 13, Grad norm: 8.296e+01\n",
      "Epoch 299, Test loss: 1444.81005859375\n",
      "Epoch 299, Test loss: 1444.81005859375\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "network shape updated to :[6, 7, 1]\n",
      "network shape updated to :[6, 7, 1]\n",
      "Epoch 300, Loss: 1415.7178955078125, Neurons: 14, Grad norm: 8.330e+01\n",
      "Epoch 300, Loss: 1415.7178955078125, Neurons: 14, Grad norm: 8.330e+01\n",
      "Epoch 301, Loss: 1415.592041015625, Neurons: 14, Grad norm: 8.324e+01\n",
      "Epoch 301, Loss: 1415.592041015625, Neurons: 14, Grad norm: 8.324e+01\n",
      "Epoch 302, Loss: 1415.4600830078125, Neurons: 14, Grad norm: 8.317e+01\n",
      "Epoch 302, Loss: 1415.4600830078125, Neurons: 14, Grad norm: 8.317e+01\n",
      "Epoch 303, Loss: 1415.3212890625, Neurons: 14, Grad norm: 8.310e+01\n",
      "Epoch 303, Loss: 1415.3212890625, Neurons: 14, Grad norm: 8.310e+01\n",
      "Epoch 304, Loss: 1415.176513671875, Neurons: 14, Grad norm: 8.302e+01\n",
      "Epoch 304, Loss: 1415.176513671875, Neurons: 14, Grad norm: 8.302e+01\n",
      "Epoch 305, Loss: 1415.0250244140625, Neurons: 14, Grad norm: 8.294e+01\n",
      "Epoch 305, Loss: 1415.0250244140625, Neurons: 14, Grad norm: 8.294e+01\n",
      "Epoch 306, Loss: 1414.8673095703125, Neurons: 14, Grad norm: 8.286e+01\n",
      "Epoch 306, Loss: 1414.8673095703125, Neurons: 14, Grad norm: 8.286e+01\n",
      "Epoch 307, Loss: 1414.7032470703125, Neurons: 14, Grad norm: 8.278e+01\n",
      "Epoch 307, Loss: 1414.7032470703125, Neurons: 14, Grad norm: 8.278e+01\n",
      "Epoch 308, Loss: 1414.53271484375, Neurons: 14, Grad norm: 8.269e+01\n",
      "Epoch 308, Loss: 1414.53271484375, Neurons: 14, Grad norm: 8.269e+01\n",
      "Epoch 309, Loss: 1414.3558349609375, Neurons: 14, Grad norm: 8.261e+01\n",
      "Epoch 309, Loss: 1414.3558349609375, Neurons: 14, Grad norm: 8.261e+01\n",
      "Epoch 310, Loss: 1414.1727294921875, Neurons: 14, Grad norm: 8.251e+01\n",
      "Epoch 310, Loss: 1414.1727294921875, Neurons: 14, Grad norm: 8.251e+01\n",
      "Epoch 311, Loss: 1413.9833984375, Neurons: 14, Grad norm: 8.242e+01\n",
      "Epoch 311, Loss: 1413.9833984375, Neurons: 14, Grad norm: 8.242e+01\n",
      "Epoch 312, Loss: 1413.7880859375, Neurons: 14, Grad norm: 8.232e+01\n",
      "Epoch 312, Loss: 1413.7880859375, Neurons: 14, Grad norm: 8.232e+01\n",
      "Epoch 313, Loss: 1413.5867919921875, Neurons: 14, Grad norm: 8.223e+01\n",
      "Epoch 313, Loss: 1413.5867919921875, Neurons: 14, Grad norm: 8.223e+01\n",
      "Epoch 314, Loss: 1413.379638671875, Neurons: 14, Grad norm: 8.213e+01\n",
      "Epoch 314, Loss: 1413.379638671875, Neurons: 14, Grad norm: 8.213e+01\n",
      "Epoch 315, Loss: 1413.1668701171875, Neurons: 14, Grad norm: 8.202e+01\n",
      "Epoch 315, Loss: 1413.1668701171875, Neurons: 14, Grad norm: 8.202e+01\n",
      "Epoch 316, Loss: 1412.9482421875, Neurons: 14, Grad norm: 8.192e+01\n",
      "Epoch 316, Loss: 1412.9482421875, Neurons: 14, Grad norm: 8.192e+01\n",
      "Epoch 317, Loss: 1412.72412109375, Neurons: 14, Grad norm: 8.182e+01\n",
      "Epoch 317, Loss: 1412.72412109375, Neurons: 14, Grad norm: 8.182e+01\n",
      "Epoch 318, Loss: 1412.4947509765625, Neurons: 14, Grad norm: 8.171e+01\n",
      "Epoch 318, Loss: 1412.4947509765625, Neurons: 14, Grad norm: 8.171e+01\n",
      "Epoch 319, Loss: 1412.260009765625, Neurons: 14, Grad norm: 8.160e+01\n",
      "Epoch 319, Loss: 1412.260009765625, Neurons: 14, Grad norm: 8.160e+01\n",
      "Epoch 320, Loss: 1412.020263671875, Neurons: 14, Grad norm: 8.149e+01\n",
      "Epoch 320, Loss: 1412.020263671875, Neurons: 14, Grad norm: 8.149e+01\n",
      "Epoch 321, Loss: 1411.7755126953125, Neurons: 14, Grad norm: 8.138e+01\n",
      "Epoch 321, Loss: 1411.7755126953125, Neurons: 14, Grad norm: 8.138e+01\n",
      "Epoch 322, Loss: 1411.5260009765625, Neurons: 14, Grad norm: 8.127e+01\n",
      "Epoch 322, Loss: 1411.5260009765625, Neurons: 14, Grad norm: 8.127e+01\n",
      "Epoch 323, Loss: 1411.271484375, Neurons: 14, Grad norm: 8.116e+01\n",
      "Epoch 323, Loss: 1411.271484375, Neurons: 14, Grad norm: 8.116e+01\n",
      "Epoch 324, Loss: 1411.0125732421875, Neurons: 14, Grad norm: 8.105e+01\n",
      "Epoch 324, Loss: 1411.0125732421875, Neurons: 14, Grad norm: 8.105e+01\n",
      "Epoch 325, Loss: 1410.7490234375, Neurons: 14, Grad norm: 8.093e+01\n",
      "Epoch 325, Loss: 1410.7490234375, Neurons: 14, Grad norm: 8.093e+01\n",
      "Epoch 326, Loss: 1410.4810791015625, Neurons: 14, Grad norm: 8.082e+01\n",
      "Epoch 326, Loss: 1410.4810791015625, Neurons: 14, Grad norm: 8.082e+01\n",
      "Epoch 327, Loss: 1410.2091064453125, Neurons: 14, Grad norm: 8.071e+01\n",
      "Epoch 327, Loss: 1410.2091064453125, Neurons: 14, Grad norm: 8.071e+01\n",
      "Epoch 328, Loss: 1409.9326171875, Neurons: 14, Grad norm: 8.060e+01\n",
      "Epoch 328, Loss: 1409.9326171875, Neurons: 14, Grad norm: 8.060e+01\n",
      "Epoch 329, Loss: 1409.6522216796875, Neurons: 14, Grad norm: 8.049e+01\n",
      "Epoch 329, Loss: 1409.6522216796875, Neurons: 14, Grad norm: 8.049e+01\n",
      "Epoch 330, Loss: 1409.3677978515625, Neurons: 14, Grad norm: 8.038e+01\n",
      "Epoch 330, Loss: 1409.3677978515625, Neurons: 14, Grad norm: 8.038e+01\n",
      "Epoch 331, Loss: 1409.0794677734375, Neurons: 14, Grad norm: 8.026e+01\n",
      "Epoch 331, Loss: 1409.0794677734375, Neurons: 14, Grad norm: 8.026e+01\n",
      "Epoch 332, Loss: 1408.787353515625, Neurons: 14, Grad norm: 8.015e+01\n",
      "Epoch 332, Loss: 1408.787353515625, Neurons: 14, Grad norm: 8.015e+01\n",
      "Epoch 333, Loss: 1408.4915771484375, Neurons: 14, Grad norm: 8.005e+01\n",
      "Epoch 333, Loss: 1408.4915771484375, Neurons: 14, Grad norm: 8.005e+01\n",
      "Epoch 334, Loss: 1408.1920166015625, Neurons: 14, Grad norm: 7.994e+01\n",
      "Epoch 334, Loss: 1408.1920166015625, Neurons: 14, Grad norm: 7.994e+01\n",
      "Epoch 335, Loss: 1407.8890380859375, Neurons: 14, Grad norm: 7.983e+01\n",
      "Epoch 335, Loss: 1407.8890380859375, Neurons: 14, Grad norm: 7.983e+01\n",
      "Epoch 336, Loss: 1407.58251953125, Neurons: 14, Grad norm: 7.973e+01\n",
      "Epoch 336, Loss: 1407.58251953125, Neurons: 14, Grad norm: 7.973e+01\n",
      "Epoch 337, Loss: 1407.2725830078125, Neurons: 14, Grad norm: 7.962e+01\n",
      "Epoch 337, Loss: 1407.2725830078125, Neurons: 14, Grad norm: 7.962e+01\n",
      "Epoch 338, Loss: 1406.9593505859375, Neurons: 14, Grad norm: 7.952e+01\n",
      "Epoch 338, Loss: 1406.9593505859375, Neurons: 14, Grad norm: 7.952e+01\n",
      "Epoch 339, Loss: 1406.642578125, Neurons: 14, Grad norm: 7.942e+01\n",
      "Epoch 339, Loss: 1406.642578125, Neurons: 14, Grad norm: 7.942e+01\n",
      "Epoch 340, Loss: 1406.3226318359375, Neurons: 14, Grad norm: 7.932e+01\n",
      "Epoch 340, Loss: 1406.3226318359375, Neurons: 14, Grad norm: 7.932e+01\n",
      "Epoch 341, Loss: 1405.9993896484375, Neurons: 14, Grad norm: 7.922e+01\n",
      "Epoch 341, Loss: 1405.9993896484375, Neurons: 14, Grad norm: 7.922e+01\n",
      "Epoch 342, Loss: 1405.673095703125, Neurons: 14, Grad norm: 7.913e+01\n",
      "Epoch 342, Loss: 1405.673095703125, Neurons: 14, Grad norm: 7.913e+01\n",
      "Epoch 343, Loss: 1405.343505859375, Neurons: 14, Grad norm: 7.903e+01\n",
      "Epoch 343, Loss: 1405.343505859375, Neurons: 14, Grad norm: 7.903e+01\n",
      "Epoch 344, Loss: 1405.010986328125, Neurons: 14, Grad norm: 7.894e+01\n",
      "Epoch 344, Loss: 1405.010986328125, Neurons: 14, Grad norm: 7.894e+01\n",
      "Epoch 345, Loss: 1404.6751708984375, Neurons: 14, Grad norm: 7.885e+01\n",
      "Epoch 345, Loss: 1404.6751708984375, Neurons: 14, Grad norm: 7.885e+01\n",
      "Epoch 346, Loss: 1404.33642578125, Neurons: 14, Grad norm: 7.877e+01\n",
      "Epoch 346, Loss: 1404.33642578125, Neurons: 14, Grad norm: 7.877e+01\n",
      "Epoch 347, Loss: 1403.9945068359375, Neurons: 14, Grad norm: 7.868e+01\n",
      "Epoch 347, Loss: 1403.9945068359375, Neurons: 14, Grad norm: 7.868e+01\n",
      "Epoch 348, Loss: 1403.649658203125, Neurons: 14, Grad norm: 7.860e+01\n",
      "Epoch 348, Loss: 1403.649658203125, Neurons: 14, Grad norm: 7.860e+01\n",
      "Epoch 349, Loss: 1403.3017578125, Neurons: 14, Grad norm: 7.852e+01\n",
      "Epoch 349, Loss: 1403.3017578125, Neurons: 14, Grad norm: 7.852e+01\n",
      "Epoch 350, Loss: 1402.950927734375, Neurons: 14, Grad norm: 7.844e+01\n",
      "Epoch 350, Loss: 1402.950927734375, Neurons: 14, Grad norm: 7.844e+01\n",
      "Epoch 351, Loss: 1402.5970458984375, Neurons: 14, Grad norm: 7.837e+01\n",
      "Epoch 351, Loss: 1402.5970458984375, Neurons: 14, Grad norm: 7.837e+01\n",
      "Epoch 352, Loss: 1402.2403564453125, Neurons: 14, Grad norm: 7.830e+01\n",
      "Epoch 352, Loss: 1402.2403564453125, Neurons: 14, Grad norm: 7.830e+01\n",
      "Epoch 353, Loss: 1401.8804931640625, Neurons: 14, Grad norm: 7.823e+01\n",
      "Epoch 353, Loss: 1401.8804931640625, Neurons: 14, Grad norm: 7.823e+01\n",
      "Epoch 354, Loss: 1401.517578125, Neurons: 14, Grad norm: 7.816e+01\n",
      "Epoch 354, Loss: 1401.517578125, Neurons: 14, Grad norm: 7.816e+01\n",
      "Epoch 355, Loss: 1401.1519775390625, Neurons: 14, Grad norm: 7.810e+01\n",
      "Epoch 355, Loss: 1401.1519775390625, Neurons: 14, Grad norm: 7.810e+01\n",
      "Epoch 356, Loss: 1400.783203125, Neurons: 14, Grad norm: 7.804e+01\n",
      "Epoch 356, Loss: 1400.783203125, Neurons: 14, Grad norm: 7.804e+01\n",
      "Epoch 357, Loss: 1400.4114990234375, Neurons: 14, Grad norm: 7.798e+01\n",
      "Epoch 357, Loss: 1400.4114990234375, Neurons: 14, Grad norm: 7.798e+01\n",
      "Epoch 358, Loss: 1400.0367431640625, Neurons: 14, Grad norm: 7.793e+01\n",
      "Epoch 358, Loss: 1400.0367431640625, Neurons: 14, Grad norm: 7.793e+01\n",
      "Epoch 359, Loss: 1399.6590576171875, Neurons: 14, Grad norm: 7.787e+01\n",
      "Epoch 359, Loss: 1399.6590576171875, Neurons: 14, Grad norm: 7.787e+01\n",
      "Epoch 360, Loss: 1399.2783203125, Neurons: 14, Grad norm: 7.783e+01\n",
      "Epoch 360, Loss: 1399.2783203125, Neurons: 14, Grad norm: 7.783e+01\n",
      "Epoch 361, Loss: 1398.894287109375, Neurons: 14, Grad norm: 7.778e+01\n",
      "Epoch 361, Loss: 1398.894287109375, Neurons: 14, Grad norm: 7.778e+01\n",
      "Epoch 362, Loss: 1398.507568359375, Neurons: 14, Grad norm: 7.774e+01\n",
      "Epoch 362, Loss: 1398.507568359375, Neurons: 14, Grad norm: 7.774e+01\n",
      "Epoch 363, Loss: 1398.1177978515625, Neurons: 14, Grad norm: 7.770e+01\n",
      "Epoch 363, Loss: 1398.1177978515625, Neurons: 14, Grad norm: 7.770e+01\n",
      "Epoch 364, Loss: 1397.7247314453125, Neurons: 14, Grad norm: 7.766e+01\n",
      "Epoch 364, Loss: 1397.7247314453125, Neurons: 14, Grad norm: 7.766e+01\n",
      "Epoch 365, Loss: 1397.32861328125, Neurons: 14, Grad norm: 7.763e+01\n",
      "Epoch 365, Loss: 1397.32861328125, Neurons: 14, Grad norm: 7.763e+01\n",
      "Epoch 366, Loss: 1396.929443359375, Neurons: 14, Grad norm: 7.760e+01\n",
      "Epoch 366, Loss: 1396.929443359375, Neurons: 14, Grad norm: 7.760e+01\n",
      "Epoch 367, Loss: 1396.527099609375, Neurons: 14, Grad norm: 7.757e+01\n",
      "Epoch 367, Loss: 1396.527099609375, Neurons: 14, Grad norm: 7.757e+01\n",
      "Epoch 368, Loss: 1396.1214599609375, Neurons: 14, Grad norm: 7.755e+01\n",
      "Epoch 368, Loss: 1396.1214599609375, Neurons: 14, Grad norm: 7.755e+01\n",
      "Epoch 369, Loss: 1395.7125244140625, Neurons: 14, Grad norm: 7.753e+01\n",
      "Epoch 369, Loss: 1395.7125244140625, Neurons: 14, Grad norm: 7.753e+01\n",
      "Epoch 370, Loss: 1395.3004150390625, Neurons: 14, Grad norm: 7.751e+01\n",
      "Epoch 370, Loss: 1395.3004150390625, Neurons: 14, Grad norm: 7.751e+01\n",
      "Epoch 371, Loss: 1394.8851318359375, Neurons: 14, Grad norm: 7.750e+01\n",
      "Epoch 371, Loss: 1394.8851318359375, Neurons: 14, Grad norm: 7.750e+01\n",
      "Epoch 372, Loss: 1394.466552734375, Neurons: 14, Grad norm: 7.749e+01\n",
      "Epoch 372, Loss: 1394.466552734375, Neurons: 14, Grad norm: 7.749e+01\n",
      "Epoch 373, Loss: 1394.0445556640625, Neurons: 14, Grad norm: 7.748e+01\n",
      "Epoch 373, Loss: 1394.0445556640625, Neurons: 14, Grad norm: 7.748e+01\n",
      "Epoch 374, Loss: 1393.6190185546875, Neurons: 14, Grad norm: 7.748e+01\n",
      "Epoch 374, Loss: 1393.6190185546875, Neurons: 14, Grad norm: 7.748e+01\n",
      "Epoch 375, Loss: 1393.190185546875, Neurons: 14, Grad norm: 7.748e+01\n",
      "Epoch 375, Loss: 1393.190185546875, Neurons: 14, Grad norm: 7.748e+01\n",
      "Epoch 376, Loss: 1392.7579345703125, Neurons: 14, Grad norm: 7.748e+01\n",
      "Epoch 376, Loss: 1392.7579345703125, Neurons: 14, Grad norm: 7.748e+01\n",
      "Epoch 377, Loss: 1392.3221435546875, Neurons: 14, Grad norm: 7.749e+01\n",
      "Epoch 377, Loss: 1392.3221435546875, Neurons: 14, Grad norm: 7.749e+01\n",
      "Epoch 378, Loss: 1391.8828125, Neurons: 14, Grad norm: 7.750e+01\n",
      "Epoch 378, Loss: 1391.8828125, Neurons: 14, Grad norm: 7.750e+01\n",
      "Epoch 379, Loss: 1391.4398193359375, Neurons: 14, Grad norm: 7.751e+01\n",
      "Epoch 379, Loss: 1391.4398193359375, Neurons: 14, Grad norm: 7.751e+01\n",
      "Epoch 380, Loss: 1390.9932861328125, Neurons: 14, Grad norm: 7.753e+01\n",
      "Epoch 380, Loss: 1390.9932861328125, Neurons: 14, Grad norm: 7.753e+01\n",
      "Epoch 381, Loss: 1390.5430908203125, Neurons: 14, Grad norm: 7.755e+01\n",
      "Epoch 381, Loss: 1390.5430908203125, Neurons: 14, Grad norm: 7.755e+01\n",
      "Epoch 382, Loss: 1390.089111328125, Neurons: 14, Grad norm: 7.757e+01\n",
      "Epoch 382, Loss: 1390.089111328125, Neurons: 14, Grad norm: 7.757e+01\n",
      "Epoch 383, Loss: 1389.63134765625, Neurons: 14, Grad norm: 7.760e+01\n",
      "Epoch 383, Loss: 1389.63134765625, Neurons: 14, Grad norm: 7.760e+01\n",
      "Epoch 384, Loss: 1389.1697998046875, Neurons: 14, Grad norm: 7.763e+01\n",
      "Epoch 384, Loss: 1389.1697998046875, Neurons: 14, Grad norm: 7.763e+01\n",
      "Epoch 385, Loss: 1388.704345703125, Neurons: 14, Grad norm: 7.766e+01\n",
      "Epoch 385, Loss: 1388.704345703125, Neurons: 14, Grad norm: 7.766e+01\n",
      "Epoch 386, Loss: 1388.235107421875, Neurons: 14, Grad norm: 7.770e+01\n",
      "Epoch 386, Loss: 1388.235107421875, Neurons: 14, Grad norm: 7.770e+01\n",
      "Epoch 387, Loss: 1387.7618408203125, Neurons: 14, Grad norm: 7.774e+01\n",
      "Epoch 387, Loss: 1387.7618408203125, Neurons: 14, Grad norm: 7.774e+01\n",
      "Epoch 388, Loss: 1387.284423828125, Neurons: 14, Grad norm: 7.779e+01\n",
      "Epoch 388, Loss: 1387.284423828125, Neurons: 14, Grad norm: 7.779e+01\n",
      "Epoch 389, Loss: 1386.8031005859375, Neurons: 14, Grad norm: 7.784e+01\n",
      "Epoch 389, Loss: 1386.8031005859375, Neurons: 14, Grad norm: 7.784e+01\n",
      "Epoch 390, Loss: 1386.3175048828125, Neurons: 14, Grad norm: 7.789e+01\n",
      "Epoch 390, Loss: 1386.3175048828125, Neurons: 14, Grad norm: 7.789e+01\n",
      "Epoch 391, Loss: 1385.8277587890625, Neurons: 14, Grad norm: 7.795e+01\n",
      "Epoch 391, Loss: 1385.8277587890625, Neurons: 14, Grad norm: 7.795e+01\n",
      "Epoch 392, Loss: 1385.333984375, Neurons: 14, Grad norm: 7.800e+01\n",
      "Epoch 392, Loss: 1385.333984375, Neurons: 14, Grad norm: 7.800e+01\n",
      "Epoch 393, Loss: 1384.8358154296875, Neurons: 14, Grad norm: 7.807e+01\n",
      "Epoch 393, Loss: 1384.8358154296875, Neurons: 14, Grad norm: 7.807e+01\n",
      "Epoch 394, Loss: 1384.3333740234375, Neurons: 14, Grad norm: 7.813e+01\n",
      "Epoch 394, Loss: 1384.3333740234375, Neurons: 14, Grad norm: 7.813e+01\n",
      "Epoch 395, Loss: 1383.8262939453125, Neurons: 14, Grad norm: 7.820e+01\n",
      "Epoch 395, Loss: 1383.8262939453125, Neurons: 14, Grad norm: 7.820e+01\n",
      "Epoch 396, Loss: 1383.31494140625, Neurons: 14, Grad norm: 7.828e+01\n",
      "Epoch 396, Loss: 1383.31494140625, Neurons: 14, Grad norm: 7.828e+01\n",
      "Epoch 397, Loss: 1382.799072265625, Neurons: 14, Grad norm: 7.836e+01\n",
      "Epoch 397, Loss: 1382.799072265625, Neurons: 14, Grad norm: 7.836e+01\n",
      "Epoch 398, Loss: 1382.278564453125, Neurons: 14, Grad norm: 7.844e+01\n",
      "Epoch 398, Loss: 1382.278564453125, Neurons: 14, Grad norm: 7.844e+01\n",
      "Epoch 399, Loss: 1381.7532958984375, Neurons: 14, Grad norm: 7.852e+01\n",
      "Epoch 399, Loss: 1381.7532958984375, Neurons: 14, Grad norm: 7.852e+01\n",
      "Epoch 399, Test loss: 1408.5633544921875\n",
      "Epoch 399, Test loss: 1408.5633544921875\n",
      "Added neuron to hidden layer 1 with activation tanh\n",
      "Added neuron to hidden layer 1 with activation tanh\n",
      "network shape updated to :[7, 7, 1]\n",
      "network shape updated to :[7, 7, 1]\n",
      "Epoch 400, Loss: 1383.0958251953125, Neurons: 15, Grad norm: 8.571e+01\n",
      "Epoch 400, Loss: 1383.0958251953125, Neurons: 15, Grad norm: 8.571e+01\n",
      "Epoch 401, Loss: 1382.9598388671875, Neurons: 15, Grad norm: 8.566e+01\n",
      "Epoch 401, Loss: 1382.9598388671875, Neurons: 15, Grad norm: 8.566e+01\n",
      "Epoch 402, Loss: 1382.81689453125, Neurons: 15, Grad norm: 8.560e+01\n",
      "Epoch 402, Loss: 1382.81689453125, Neurons: 15, Grad norm: 8.560e+01\n",
      "Epoch 403, Loss: 1382.6671142578125, Neurons: 15, Grad norm: 8.554e+01\n",
      "Epoch 403, Loss: 1382.6671142578125, Neurons: 15, Grad norm: 8.554e+01\n",
      "Epoch 404, Loss: 1382.5106201171875, Neurons: 15, Grad norm: 8.548e+01\n",
      "Epoch 404, Loss: 1382.5106201171875, Neurons: 15, Grad norm: 8.548e+01\n",
      "Epoch 405, Loss: 1382.346923828125, Neurons: 15, Grad norm: 8.542e+01\n",
      "Epoch 405, Loss: 1382.346923828125, Neurons: 15, Grad norm: 8.542e+01\n",
      "Epoch 406, Loss: 1382.1763916015625, Neurons: 15, Grad norm: 8.535e+01\n",
      "Epoch 406, Loss: 1382.1763916015625, Neurons: 15, Grad norm: 8.535e+01\n",
      "Epoch 407, Loss: 1381.9990234375, Neurons: 15, Grad norm: 8.529e+01\n",
      "Epoch 407, Loss: 1381.9990234375, Neurons: 15, Grad norm: 8.529e+01\n",
      "Epoch 408, Loss: 1381.81494140625, Neurons: 15, Grad norm: 8.522e+01\n",
      "Epoch 408, Loss: 1381.81494140625, Neurons: 15, Grad norm: 8.522e+01\n",
      "Epoch 409, Loss: 1381.623779296875, Neurons: 15, Grad norm: 8.515e+01\n",
      "Epoch 409, Loss: 1381.623779296875, Neurons: 15, Grad norm: 8.515e+01\n",
      "Epoch 410, Loss: 1381.4261474609375, Neurons: 15, Grad norm: 8.508e+01\n",
      "Epoch 410, Loss: 1381.4261474609375, Neurons: 15, Grad norm: 8.508e+01\n",
      "Epoch 411, Loss: 1381.221923828125, Neurons: 15, Grad norm: 8.501e+01\n",
      "Epoch 411, Loss: 1381.221923828125, Neurons: 15, Grad norm: 8.501e+01\n",
      "Epoch 412, Loss: 1381.0111083984375, Neurons: 15, Grad norm: 8.493e+01\n",
      "Epoch 412, Loss: 1381.0111083984375, Neurons: 15, Grad norm: 8.493e+01\n",
      "Epoch 413, Loss: 1380.7938232421875, Neurons: 15, Grad norm: 8.486e+01\n",
      "Epoch 413, Loss: 1380.7938232421875, Neurons: 15, Grad norm: 8.486e+01\n",
      "Epoch 414, Loss: 1380.5703125, Neurons: 15, Grad norm: 8.478e+01\n",
      "Epoch 414, Loss: 1380.5703125, Neurons: 15, Grad norm: 8.478e+01\n",
      "Epoch 415, Loss: 1380.340576171875, Neurons: 15, Grad norm: 8.471e+01\n",
      "Epoch 415, Loss: 1380.340576171875, Neurons: 15, Grad norm: 8.471e+01\n",
      "Epoch 416, Loss: 1380.1048583984375, Neurons: 15, Grad norm: 8.463e+01\n",
      "Epoch 416, Loss: 1380.1048583984375, Neurons: 15, Grad norm: 8.463e+01\n",
      "Epoch 417, Loss: 1379.8631591796875, Neurons: 15, Grad norm: 8.456e+01\n",
      "Epoch 417, Loss: 1379.8631591796875, Neurons: 15, Grad norm: 8.456e+01\n",
      "Epoch 418, Loss: 1379.6158447265625, Neurons: 15, Grad norm: 8.448e+01\n",
      "Epoch 418, Loss: 1379.6158447265625, Neurons: 15, Grad norm: 8.448e+01\n",
      "Epoch 419, Loss: 1379.3626708984375, Neurons: 15, Grad norm: 8.441e+01\n",
      "Epoch 419, Loss: 1379.3626708984375, Neurons: 15, Grad norm: 8.441e+01\n",
      "Epoch 420, Loss: 1379.1041259765625, Neurons: 15, Grad norm: 8.433e+01\n",
      "Epoch 420, Loss: 1379.1041259765625, Neurons: 15, Grad norm: 8.433e+01\n",
      "Epoch 421, Loss: 1378.840087890625, Neurons: 15, Grad norm: 8.426e+01\n",
      "Epoch 421, Loss: 1378.840087890625, Neurons: 15, Grad norm: 8.426e+01\n",
      "Epoch 422, Loss: 1378.571044921875, Neurons: 15, Grad norm: 8.418e+01\n",
      "Epoch 422, Loss: 1378.571044921875, Neurons: 15, Grad norm: 8.418e+01\n",
      "Epoch 423, Loss: 1378.296875, Neurons: 15, Grad norm: 8.411e+01\n",
      "Epoch 423, Loss: 1378.296875, Neurons: 15, Grad norm: 8.411e+01\n",
      "Epoch 424, Loss: 1378.017578125, Neurons: 15, Grad norm: 8.404e+01\n",
      "Epoch 424, Loss: 1378.017578125, Neurons: 15, Grad norm: 8.404e+01\n",
      "Epoch 425, Loss: 1377.7335205078125, Neurons: 15, Grad norm: 8.396e+01\n",
      "Epoch 425, Loss: 1377.7335205078125, Neurons: 15, Grad norm: 8.396e+01\n",
      "Epoch 426, Loss: 1377.4449462890625, Neurons: 15, Grad norm: 8.389e+01\n",
      "Epoch 426, Loss: 1377.4449462890625, Neurons: 15, Grad norm: 8.389e+01\n",
      "Epoch 427, Loss: 1377.1517333984375, Neurons: 15, Grad norm: 8.382e+01\n",
      "Epoch 427, Loss: 1377.1517333984375, Neurons: 15, Grad norm: 8.382e+01\n",
      "Epoch 428, Loss: 1376.8538818359375, Neurons: 15, Grad norm: 8.376e+01\n",
      "Epoch 428, Loss: 1376.8538818359375, Neurons: 15, Grad norm: 8.376e+01\n",
      "Epoch 429, Loss: 1376.5517578125, Neurons: 15, Grad norm: 8.369e+01\n",
      "Epoch 429, Loss: 1376.5517578125, Neurons: 15, Grad norm: 8.369e+01\n",
      "Epoch 430, Loss: 1376.24560546875, Neurons: 15, Grad norm: 8.362e+01\n",
      "Epoch 430, Loss: 1376.24560546875, Neurons: 15, Grad norm: 8.362e+01\n",
      "Epoch 431, Loss: 1375.9349365234375, Neurons: 15, Grad norm: 8.356e+01\n",
      "Epoch 431, Loss: 1375.9349365234375, Neurons: 15, Grad norm: 8.356e+01\n",
      "Epoch 432, Loss: 1375.6204833984375, Neurons: 15, Grad norm: 8.350e+01\n",
      "Epoch 432, Loss: 1375.6204833984375, Neurons: 15, Grad norm: 8.350e+01\n",
      "Epoch 433, Loss: 1375.3021240234375, Neurons: 15, Grad norm: 8.344e+01\n",
      "Epoch 433, Loss: 1375.3021240234375, Neurons: 15, Grad norm: 8.344e+01\n",
      "Epoch 434, Loss: 1374.979736328125, Neurons: 15, Grad norm: 8.338e+01\n",
      "Epoch 434, Loss: 1374.979736328125, Neurons: 15, Grad norm: 8.338e+01\n",
      "Epoch 435, Loss: 1374.653564453125, Neurons: 15, Grad norm: 8.333e+01\n",
      "Epoch 435, Loss: 1374.653564453125, Neurons: 15, Grad norm: 8.333e+01\n",
      "Epoch 436, Loss: 1374.3238525390625, Neurons: 15, Grad norm: 8.328e+01\n",
      "Epoch 436, Loss: 1374.3238525390625, Neurons: 15, Grad norm: 8.328e+01\n",
      "Epoch 437, Loss: 1373.9903564453125, Neurons: 15, Grad norm: 8.322e+01\n",
      "Epoch 437, Loss: 1373.9903564453125, Neurons: 15, Grad norm: 8.322e+01\n",
      "Epoch 438, Loss: 1373.6533203125, Neurons: 15, Grad norm: 8.318e+01\n",
      "Epoch 438, Loss: 1373.6533203125, Neurons: 15, Grad norm: 8.318e+01\n",
      "Epoch 439, Loss: 1373.3128662109375, Neurons: 15, Grad norm: 8.313e+01\n",
      "Epoch 439, Loss: 1373.3128662109375, Neurons: 15, Grad norm: 8.313e+01\n",
      "Epoch 440, Loss: 1372.968994140625, Neurons: 15, Grad norm: 8.309e+01\n",
      "Epoch 440, Loss: 1372.968994140625, Neurons: 15, Grad norm: 8.309e+01\n",
      "Epoch 441, Loss: 1372.62158203125, Neurons: 15, Grad norm: 8.304e+01\n",
      "Epoch 441, Loss: 1372.62158203125, Neurons: 15, Grad norm: 8.304e+01\n",
      "Epoch 442, Loss: 1372.2711181640625, Neurons: 15, Grad norm: 8.301e+01\n",
      "Epoch 442, Loss: 1372.2711181640625, Neurons: 15, Grad norm: 8.301e+01\n",
      "Epoch 443, Loss: 1371.9171142578125, Neurons: 15, Grad norm: 8.297e+01\n",
      "Epoch 443, Loss: 1371.9171142578125, Neurons: 15, Grad norm: 8.297e+01\n",
      "Epoch 444, Loss: 1371.5599365234375, Neurons: 15, Grad norm: 8.294e+01\n",
      "Epoch 444, Loss: 1371.5599365234375, Neurons: 15, Grad norm: 8.294e+01\n",
      "Epoch 445, Loss: 1371.1995849609375, Neurons: 15, Grad norm: 8.290e+01\n",
      "Epoch 445, Loss: 1371.1995849609375, Neurons: 15, Grad norm: 8.290e+01\n",
      "Epoch 446, Loss: 1370.836181640625, Neurons: 15, Grad norm: 8.288e+01\n",
      "Epoch 446, Loss: 1370.836181640625, Neurons: 15, Grad norm: 8.288e+01\n",
      "Epoch 447, Loss: 1370.4696044921875, Neurons: 15, Grad norm: 8.285e+01\n",
      "Epoch 447, Loss: 1370.4696044921875, Neurons: 15, Grad norm: 8.285e+01\n",
      "Epoch 448, Loss: 1370.099853515625, Neurons: 15, Grad norm: 8.283e+01\n",
      "Epoch 448, Loss: 1370.099853515625, Neurons: 15, Grad norm: 8.283e+01\n",
      "Epoch 449, Loss: 1369.72705078125, Neurons: 15, Grad norm: 8.281e+01\n",
      "Epoch 449, Loss: 1369.72705078125, Neurons: 15, Grad norm: 8.281e+01\n",
      "Epoch 450, Loss: 1369.3511962890625, Neurons: 15, Grad norm: 8.279e+01\n",
      "Epoch 450, Loss: 1369.3511962890625, Neurons: 15, Grad norm: 8.279e+01\n",
      "Epoch 451, Loss: 1368.9725341796875, Neurons: 15, Grad norm: 8.277e+01\n",
      "Epoch 451, Loss: 1368.9725341796875, Neurons: 15, Grad norm: 8.277e+01\n",
      "Epoch 452, Loss: 1368.5908203125, Neurons: 15, Grad norm: 8.276e+01\n",
      "Epoch 452, Loss: 1368.5908203125, Neurons: 15, Grad norm: 8.276e+01\n",
      "Epoch 453, Loss: 1368.2060546875, Neurons: 15, Grad norm: 8.275e+01\n",
      "Epoch 453, Loss: 1368.2060546875, Neurons: 15, Grad norm: 8.275e+01\n",
      "Epoch 454, Loss: 1367.8184814453125, Neurons: 15, Grad norm: 8.274e+01\n",
      "Epoch 454, Loss: 1367.8184814453125, Neurons: 15, Grad norm: 8.274e+01\n",
      "Epoch 455, Loss: 1367.4278564453125, Neurons: 15, Grad norm: 8.274e+01\n",
      "Epoch 455, Loss: 1367.4278564453125, Neurons: 15, Grad norm: 8.274e+01\n",
      "Epoch 456, Loss: 1367.0343017578125, Neurons: 15, Grad norm: 8.274e+01\n",
      "Epoch 456, Loss: 1367.0343017578125, Neurons: 15, Grad norm: 8.274e+01\n",
      "Epoch 457, Loss: 1366.6378173828125, Neurons: 15, Grad norm: 8.274e+01\n",
      "Epoch 457, Loss: 1366.6378173828125, Neurons: 15, Grad norm: 8.274e+01\n",
      "Epoch 458, Loss: 1366.238525390625, Neurons: 15, Grad norm: 8.274e+01\n",
      "Epoch 458, Loss: 1366.238525390625, Neurons: 15, Grad norm: 8.274e+01\n",
      "Epoch 459, Loss: 1365.8365478515625, Neurons: 15, Grad norm: 8.275e+01\n",
      "Epoch 459, Loss: 1365.8365478515625, Neurons: 15, Grad norm: 8.275e+01\n",
      "Epoch 460, Loss: 1365.431396484375, Neurons: 15, Grad norm: 8.276e+01\n",
      "Epoch 460, Loss: 1365.431396484375, Neurons: 15, Grad norm: 8.276e+01\n",
      "Epoch 461, Loss: 1365.0235595703125, Neurons: 15, Grad norm: 8.277e+01\n",
      "Epoch 461, Loss: 1365.0235595703125, Neurons: 15, Grad norm: 8.277e+01\n",
      "Epoch 462, Loss: 1364.61279296875, Neurons: 15, Grad norm: 8.278e+01\n",
      "Epoch 462, Loss: 1364.61279296875, Neurons: 15, Grad norm: 8.278e+01\n",
      "Epoch 463, Loss: 1364.1993408203125, Neurons: 15, Grad norm: 8.280e+01\n",
      "Epoch 463, Loss: 1364.1993408203125, Neurons: 15, Grad norm: 8.280e+01\n",
      "Epoch 464, Loss: 1363.7828369140625, Neurons: 15, Grad norm: 8.282e+01\n",
      "Epoch 464, Loss: 1363.7828369140625, Neurons: 15, Grad norm: 8.282e+01\n",
      "Epoch 465, Loss: 1363.363525390625, Neurons: 15, Grad norm: 8.284e+01\n",
      "Epoch 465, Loss: 1363.363525390625, Neurons: 15, Grad norm: 8.284e+01\n",
      "Epoch 466, Loss: 1362.94140625, Neurons: 15, Grad norm: 8.287e+01\n",
      "Epoch 466, Loss: 1362.94140625, Neurons: 15, Grad norm: 8.287e+01\n",
      "Epoch 467, Loss: 1362.5166015625, Neurons: 15, Grad norm: 8.289e+01\n",
      "Epoch 467, Loss: 1362.5166015625, Neurons: 15, Grad norm: 8.289e+01\n",
      "Epoch 468, Loss: 1362.0888671875, Neurons: 15, Grad norm: 8.292e+01\n",
      "Epoch 468, Loss: 1362.0888671875, Neurons: 15, Grad norm: 8.292e+01\n",
      "Epoch 469, Loss: 1361.6580810546875, Neurons: 15, Grad norm: 8.295e+01\n",
      "Epoch 469, Loss: 1361.6580810546875, Neurons: 15, Grad norm: 8.295e+01\n",
      "Epoch 470, Loss: 1361.224609375, Neurons: 15, Grad norm: 8.299e+01\n",
      "Epoch 470, Loss: 1361.224609375, Neurons: 15, Grad norm: 8.299e+01\n",
      "Epoch 471, Loss: 1360.7880859375, Neurons: 15, Grad norm: 8.302e+01\n",
      "Epoch 471, Loss: 1360.7880859375, Neurons: 15, Grad norm: 8.302e+01\n",
      "Epoch 472, Loss: 1360.3489990234375, Neurons: 15, Grad norm: 8.306e+01\n",
      "Epoch 472, Loss: 1360.3489990234375, Neurons: 15, Grad norm: 8.306e+01\n",
      "Epoch 473, Loss: 1359.9068603515625, Neurons: 15, Grad norm: 8.310e+01\n",
      "Epoch 473, Loss: 1359.9068603515625, Neurons: 15, Grad norm: 8.310e+01\n",
      "Epoch 474, Loss: 1359.4617919921875, Neurons: 15, Grad norm: 8.315e+01\n",
      "Epoch 474, Loss: 1359.4617919921875, Neurons: 15, Grad norm: 8.315e+01\n",
      "Epoch 475, Loss: 1359.013916015625, Neurons: 15, Grad norm: 8.319e+01\n",
      "Epoch 475, Loss: 1359.013916015625, Neurons: 15, Grad norm: 8.319e+01\n",
      "Epoch 476, Loss: 1358.563232421875, Neurons: 15, Grad norm: 8.324e+01\n",
      "Epoch 476, Loss: 1358.563232421875, Neurons: 15, Grad norm: 8.324e+01\n",
      "Epoch 477, Loss: 1358.109619140625, Neurons: 15, Grad norm: 8.329e+01\n",
      "Epoch 477, Loss: 1358.109619140625, Neurons: 15, Grad norm: 8.329e+01\n",
      "Epoch 478, Loss: 1357.6529541015625, Neurons: 15, Grad norm: 8.334e+01\n",
      "Epoch 478, Loss: 1357.6529541015625, Neurons: 15, Grad norm: 8.334e+01\n",
      "Epoch 479, Loss: 1357.193359375, Neurons: 15, Grad norm: 8.340e+01\n",
      "Epoch 479, Loss: 1357.193359375, Neurons: 15, Grad norm: 8.340e+01\n",
      "Epoch 480, Loss: 1356.7308349609375, Neurons: 15, Grad norm: 8.345e+01\n",
      "Epoch 480, Loss: 1356.7308349609375, Neurons: 15, Grad norm: 8.345e+01\n",
      "Epoch 481, Loss: 1356.2652587890625, Neurons: 15, Grad norm: 8.351e+01\n",
      "Epoch 481, Loss: 1356.2652587890625, Neurons: 15, Grad norm: 8.351e+01\n",
      "Epoch 482, Loss: 1355.796875, Neurons: 15, Grad norm: 8.357e+01\n",
      "Epoch 482, Loss: 1355.796875, Neurons: 15, Grad norm: 8.357e+01\n",
      "Epoch 483, Loss: 1355.3253173828125, Neurons: 15, Grad norm: 8.364e+01\n",
      "Epoch 483, Loss: 1355.3253173828125, Neurons: 15, Grad norm: 8.364e+01\n",
      "Epoch 484, Loss: 1354.8509521484375, Neurons: 15, Grad norm: 8.370e+01\n",
      "Epoch 484, Loss: 1354.8509521484375, Neurons: 15, Grad norm: 8.370e+01\n",
      "Epoch 485, Loss: 1354.373291015625, Neurons: 15, Grad norm: 8.377e+01\n",
      "Epoch 485, Loss: 1354.373291015625, Neurons: 15, Grad norm: 8.377e+01\n",
      "Epoch 486, Loss: 1353.892822265625, Neurons: 15, Grad norm: 8.384e+01\n",
      "Epoch 486, Loss: 1353.892822265625, Neurons: 15, Grad norm: 8.384e+01\n",
      "Epoch 487, Loss: 1353.4091796875, Neurons: 15, Grad norm: 8.391e+01\n",
      "Epoch 487, Loss: 1353.4091796875, Neurons: 15, Grad norm: 8.391e+01\n",
      "Epoch 488, Loss: 1352.9224853515625, Neurons: 15, Grad norm: 8.398e+01\n",
      "Epoch 488, Loss: 1352.9224853515625, Neurons: 15, Grad norm: 8.398e+01\n",
      "Epoch 489, Loss: 1352.4327392578125, Neurons: 15, Grad norm: 8.405e+01\n",
      "Epoch 489, Loss: 1352.4327392578125, Neurons: 15, Grad norm: 8.405e+01\n",
      "Epoch 490, Loss: 1351.939697265625, Neurons: 15, Grad norm: 8.413e+01\n",
      "Epoch 490, Loss: 1351.939697265625, Neurons: 15, Grad norm: 8.413e+01\n",
      "Epoch 491, Loss: 1351.443603515625, Neurons: 15, Grad norm: 8.421e+01\n",
      "Epoch 491, Loss: 1351.443603515625, Neurons: 15, Grad norm: 8.421e+01\n",
      "Epoch 492, Loss: 1350.9443359375, Neurons: 15, Grad norm: 8.429e+01\n",
      "Epoch 492, Loss: 1350.9443359375, Neurons: 15, Grad norm: 8.429e+01\n",
      "Epoch 493, Loss: 1350.4417724609375, Neurons: 15, Grad norm: 8.437e+01\n",
      "Epoch 493, Loss: 1350.4417724609375, Neurons: 15, Grad norm: 8.437e+01\n",
      "Epoch 494, Loss: 1349.936279296875, Neurons: 15, Grad norm: 8.446e+01\n",
      "Epoch 494, Loss: 1349.936279296875, Neurons: 15, Grad norm: 8.446e+01\n",
      "Epoch 495, Loss: 1349.4273681640625, Neurons: 15, Grad norm: 8.454e+01\n",
      "Epoch 495, Loss: 1349.4273681640625, Neurons: 15, Grad norm: 8.454e+01\n",
      "Epoch 496, Loss: 1348.915283203125, Neurons: 15, Grad norm: 8.463e+01\n",
      "Epoch 496, Loss: 1348.915283203125, Neurons: 15, Grad norm: 8.463e+01\n",
      "Epoch 497, Loss: 1348.3997802734375, Neurons: 15, Grad norm: 8.472e+01\n",
      "Epoch 497, Loss: 1348.3997802734375, Neurons: 15, Grad norm: 8.472e+01\n",
      "Epoch 498, Loss: 1347.8812255859375, Neurons: 15, Grad norm: 8.481e+01\n",
      "Epoch 498, Loss: 1347.8812255859375, Neurons: 15, Grad norm: 8.481e+01\n",
      "Epoch 499, Loss: 1347.359130859375, Neurons: 15, Grad norm: 8.490e+01\n",
      "Epoch 499, Loss: 1347.359130859375, Neurons: 15, Grad norm: 8.490e+01\n",
      "Epoch 499, Test loss: 1372.896484375\n",
      "Epoch 499, Test loss: 1372.896484375\n",
      "Added neuron to hidden layer 1 with activation relu\n",
      "Added neuron to hidden layer 1 with activation relu\n",
      "network shape updated to :[8, 7, 1]\n",
      "network shape updated to :[8, 7, 1]\n",
      "Epoch 500, Loss: 1354.419921875, Neurons: 16, Grad norm: 1.431e+02\n",
      "Epoch 500, Loss: 1354.419921875, Neurons: 16, Grad norm: 1.431e+02\n",
      "Epoch 501, Loss: 1354.1810302734375, Neurons: 16, Grad norm: 1.430e+02\n",
      "Epoch 501, Loss: 1354.1810302734375, Neurons: 16, Grad norm: 1.430e+02\n",
      "Epoch 502, Loss: 1353.9305419921875, Neurons: 16, Grad norm: 1.428e+02\n",
      "Epoch 502, Loss: 1353.9305419921875, Neurons: 16, Grad norm: 1.428e+02\n",
      "Epoch 503, Loss: 1353.6678466796875, Neurons: 16, Grad norm: 1.427e+02\n",
      "Epoch 503, Loss: 1353.6678466796875, Neurons: 16, Grad norm: 1.427e+02\n",
      "Epoch 504, Loss: 1353.393310546875, Neurons: 16, Grad norm: 1.425e+02\n",
      "Epoch 504, Loss: 1353.393310546875, Neurons: 16, Grad norm: 1.425e+02\n",
      "Epoch 505, Loss: 1353.1068115234375, Neurons: 16, Grad norm: 1.423e+02\n",
      "Epoch 505, Loss: 1353.1068115234375, Neurons: 16, Grad norm: 1.423e+02\n",
      "Epoch 506, Loss: 1352.808349609375, Neurons: 16, Grad norm: 1.421e+02\n",
      "Epoch 506, Loss: 1352.808349609375, Neurons: 16, Grad norm: 1.421e+02\n",
      "Epoch 507, Loss: 1352.497802734375, Neurons: 16, Grad norm: 1.419e+02\n",
      "Epoch 507, Loss: 1352.497802734375, Neurons: 16, Grad norm: 1.419e+02\n",
      "Epoch 508, Loss: 1352.1756591796875, Neurons: 16, Grad norm: 1.416e+02\n",
      "Epoch 508, Loss: 1352.1756591796875, Neurons: 16, Grad norm: 1.416e+02\n",
      "Epoch 509, Loss: 1351.8419189453125, Neurons: 16, Grad norm: 1.414e+02\n",
      "Epoch 509, Loss: 1351.8419189453125, Neurons: 16, Grad norm: 1.414e+02\n",
      "Epoch 510, Loss: 1351.496826171875, Neurons: 16, Grad norm: 1.412e+02\n",
      "Epoch 510, Loss: 1351.496826171875, Neurons: 16, Grad norm: 1.412e+02\n",
      "Epoch 511, Loss: 1351.1402587890625, Neurons: 16, Grad norm: 1.409e+02\n",
      "Epoch 511, Loss: 1351.1402587890625, Neurons: 16, Grad norm: 1.409e+02\n",
      "Epoch 512, Loss: 1350.7728271484375, Neurons: 16, Grad norm: 1.407e+02\n",
      "Epoch 512, Loss: 1350.7728271484375, Neurons: 16, Grad norm: 1.407e+02\n",
      "Epoch 513, Loss: 1350.394775390625, Neurons: 16, Grad norm: 1.404e+02\n",
      "Epoch 513, Loss: 1350.394775390625, Neurons: 16, Grad norm: 1.404e+02\n",
      "Epoch 514, Loss: 1350.006103515625, Neurons: 16, Grad norm: 1.401e+02\n",
      "Epoch 514, Loss: 1350.006103515625, Neurons: 16, Grad norm: 1.401e+02\n",
      "Epoch 515, Loss: 1349.6072998046875, Neurons: 16, Grad norm: 1.398e+02\n",
      "Epoch 515, Loss: 1349.6072998046875, Neurons: 16, Grad norm: 1.398e+02\n",
      "Epoch 516, Loss: 1349.1986083984375, Neurons: 16, Grad norm: 1.395e+02\n",
      "Epoch 516, Loss: 1349.1986083984375, Neurons: 16, Grad norm: 1.395e+02\n",
      "Epoch 517, Loss: 1348.7802734375, Neurons: 16, Grad norm: 1.392e+02\n",
      "Epoch 517, Loss: 1348.7802734375, Neurons: 16, Grad norm: 1.392e+02\n",
      "Epoch 518, Loss: 1348.352783203125, Neurons: 16, Grad norm: 1.389e+02\n",
      "Epoch 518, Loss: 1348.352783203125, Neurons: 16, Grad norm: 1.389e+02\n",
      "Epoch 519, Loss: 1347.916259765625, Neurons: 16, Grad norm: 1.385e+02\n",
      "Epoch 519, Loss: 1347.916259765625, Neurons: 16, Grad norm: 1.385e+02\n",
      "Epoch 520, Loss: 1347.4713134765625, Neurons: 16, Grad norm: 1.382e+02\n",
      "Epoch 520, Loss: 1347.4713134765625, Neurons: 16, Grad norm: 1.382e+02\n",
      "Epoch 521, Loss: 1347.01806640625, Neurons: 16, Grad norm: 1.378e+02\n",
      "Epoch 521, Loss: 1347.01806640625, Neurons: 16, Grad norm: 1.378e+02\n",
      "Epoch 522, Loss: 1346.5567626953125, Neurons: 16, Grad norm: 1.375e+02\n",
      "Epoch 522, Loss: 1346.5567626953125, Neurons: 16, Grad norm: 1.375e+02\n",
      "Epoch 523, Loss: 1346.0877685546875, Neurons: 16, Grad norm: 1.371e+02\n",
      "Epoch 523, Loss: 1346.0877685546875, Neurons: 16, Grad norm: 1.371e+02\n",
      "Epoch 524, Loss: 1345.61181640625, Neurons: 16, Grad norm: 1.367e+02\n",
      "Epoch 524, Loss: 1345.61181640625, Neurons: 16, Grad norm: 1.367e+02\n",
      "Epoch 525, Loss: 1345.128662109375, Neurons: 16, Grad norm: 1.363e+02\n",
      "Epoch 525, Loss: 1345.128662109375, Neurons: 16, Grad norm: 1.363e+02\n",
      "Epoch 526, Loss: 1344.638916015625, Neurons: 16, Grad norm: 1.359e+02\n",
      "Epoch 526, Loss: 1344.638916015625, Neurons: 16, Grad norm: 1.359e+02\n",
      "Epoch 527, Loss: 1344.142822265625, Neurons: 16, Grad norm: 1.355e+02\n",
      "Epoch 527, Loss: 1344.142822265625, Neurons: 16, Grad norm: 1.355e+02\n",
      "Epoch 528, Loss: 1343.6405029296875, Neurons: 16, Grad norm: 1.351e+02\n",
      "Epoch 528, Loss: 1343.6405029296875, Neurons: 16, Grad norm: 1.351e+02\n",
      "Epoch 529, Loss: 1343.1328125, Neurons: 16, Grad norm: 1.347e+02\n",
      "Epoch 529, Loss: 1343.1328125, Neurons: 16, Grad norm: 1.347e+02\n",
      "Epoch 530, Loss: 1342.6195068359375, Neurons: 16, Grad norm: 1.342e+02\n",
      "Epoch 530, Loss: 1342.6195068359375, Neurons: 16, Grad norm: 1.342e+02\n",
      "Epoch 531, Loss: 1342.10107421875, Neurons: 16, Grad norm: 1.338e+02\n",
      "Epoch 531, Loss: 1342.10107421875, Neurons: 16, Grad norm: 1.338e+02\n",
      "Epoch 532, Loss: 1341.5777587890625, Neurons: 16, Grad norm: 1.334e+02\n",
      "Epoch 532, Loss: 1341.5777587890625, Neurons: 16, Grad norm: 1.334e+02\n",
      "Epoch 533, Loss: 1341.0499267578125, Neurons: 16, Grad norm: 1.329e+02\n",
      "Epoch 533, Loss: 1341.0499267578125, Neurons: 16, Grad norm: 1.329e+02\n",
      "Epoch 534, Loss: 1340.5177001953125, Neurons: 16, Grad norm: 1.325e+02\n",
      "Epoch 534, Loss: 1340.5177001953125, Neurons: 16, Grad norm: 1.325e+02\n",
      "Epoch 535, Loss: 1339.9814453125, Neurons: 16, Grad norm: 1.320e+02\n",
      "Epoch 535, Loss: 1339.9814453125, Neurons: 16, Grad norm: 1.320e+02\n",
      "Epoch 536, Loss: 1339.4412841796875, Neurons: 16, Grad norm: 1.316e+02\n",
      "Epoch 536, Loss: 1339.4412841796875, Neurons: 16, Grad norm: 1.316e+02\n",
      "Epoch 537, Loss: 1338.8975830078125, Neurons: 16, Grad norm: 1.311e+02\n",
      "Epoch 537, Loss: 1338.8975830078125, Neurons: 16, Grad norm: 1.311e+02\n",
      "Epoch 538, Loss: 1338.3505859375, Neurons: 16, Grad norm: 1.306e+02\n",
      "Epoch 538, Loss: 1338.3505859375, Neurons: 16, Grad norm: 1.306e+02\n",
      "Epoch 539, Loss: 1337.8001708984375, Neurons: 16, Grad norm: 1.302e+02\n",
      "Epoch 539, Loss: 1337.8001708984375, Neurons: 16, Grad norm: 1.302e+02\n",
      "Epoch 540, Loss: 1337.2469482421875, Neurons: 16, Grad norm: 1.297e+02\n",
      "Epoch 540, Loss: 1337.2469482421875, Neurons: 16, Grad norm: 1.297e+02\n",
      "Epoch 541, Loss: 1336.6910400390625, Neurons: 16, Grad norm: 1.292e+02\n",
      "Epoch 541, Loss: 1336.6910400390625, Neurons: 16, Grad norm: 1.292e+02\n",
      "Epoch 542, Loss: 1336.132568359375, Neurons: 16, Grad norm: 1.287e+02\n",
      "Epoch 542, Loss: 1336.132568359375, Neurons: 16, Grad norm: 1.287e+02\n",
      "Epoch 543, Loss: 1335.57177734375, Neurons: 16, Grad norm: 1.283e+02\n",
      "Epoch 543, Loss: 1335.57177734375, Neurons: 16, Grad norm: 1.283e+02\n",
      "Epoch 544, Loss: 1335.0086669921875, Neurons: 16, Grad norm: 1.278e+02\n",
      "Epoch 544, Loss: 1335.0086669921875, Neurons: 16, Grad norm: 1.278e+02\n",
      "Epoch 545, Loss: 1334.443603515625, Neurons: 16, Grad norm: 1.273e+02\n",
      "Epoch 545, Loss: 1334.443603515625, Neurons: 16, Grad norm: 1.273e+02\n",
      "Epoch 546, Loss: 1333.8768310546875, Neurons: 16, Grad norm: 1.268e+02\n",
      "Epoch 546, Loss: 1333.8768310546875, Neurons: 16, Grad norm: 1.268e+02\n",
      "Epoch 547, Loss: 1333.30810546875, Neurons: 16, Grad norm: 1.264e+02\n",
      "Epoch 547, Loss: 1333.30810546875, Neurons: 16, Grad norm: 1.264e+02\n",
      "Epoch 548, Loss: 1332.73779296875, Neurons: 16, Grad norm: 1.259e+02\n",
      "Epoch 548, Loss: 1332.73779296875, Neurons: 16, Grad norm: 1.259e+02\n",
      "Epoch 549, Loss: 1332.166259765625, Neurons: 16, Grad norm: 1.254e+02\n",
      "Epoch 549, Loss: 1332.166259765625, Neurons: 16, Grad norm: 1.254e+02\n",
      "Epoch 550, Loss: 1331.59326171875, Neurons: 16, Grad norm: 1.250e+02\n",
      "Epoch 550, Loss: 1331.59326171875, Neurons: 16, Grad norm: 1.250e+02\n",
      "Epoch 551, Loss: 1331.0191650390625, Neurons: 16, Grad norm: 1.245e+02\n",
      "Epoch 551, Loss: 1331.0191650390625, Neurons: 16, Grad norm: 1.245e+02\n",
      "Epoch 552, Loss: 1330.444091796875, Neurons: 16, Grad norm: 1.240e+02\n",
      "Epoch 552, Loss: 1330.444091796875, Neurons: 16, Grad norm: 1.240e+02\n",
      "Epoch 553, Loss: 1329.8677978515625, Neurons: 16, Grad norm: 1.236e+02\n",
      "Epoch 553, Loss: 1329.8677978515625, Neurons: 16, Grad norm: 1.236e+02\n",
      "Epoch 554, Loss: 1329.290771484375, Neurons: 16, Grad norm: 1.231e+02\n",
      "Epoch 554, Loss: 1329.290771484375, Neurons: 16, Grad norm: 1.231e+02\n",
      "Epoch 555, Loss: 1328.712890625, Neurons: 16, Grad norm: 1.227e+02\n",
      "Epoch 555, Loss: 1328.712890625, Neurons: 16, Grad norm: 1.227e+02\n",
      "Epoch 556, Loss: 1328.13427734375, Neurons: 16, Grad norm: 1.222e+02\n",
      "Epoch 556, Loss: 1328.13427734375, Neurons: 16, Grad norm: 1.222e+02\n",
      "Epoch 557, Loss: 1327.55517578125, Neurons: 16, Grad norm: 1.218e+02\n",
      "Epoch 557, Loss: 1327.55517578125, Neurons: 16, Grad norm: 1.218e+02\n",
      "Epoch 558, Loss: 1326.9754638671875, Neurons: 16, Grad norm: 1.214e+02\n",
      "Epoch 558, Loss: 1326.9754638671875, Neurons: 16, Grad norm: 1.214e+02\n",
      "Epoch 559, Loss: 1326.3951416015625, Neurons: 16, Grad norm: 1.209e+02\n",
      "Epoch 559, Loss: 1326.3951416015625, Neurons: 16, Grad norm: 1.209e+02\n",
      "Epoch 560, Loss: 1325.8145751953125, Neurons: 16, Grad norm: 1.205e+02\n",
      "Epoch 560, Loss: 1325.8145751953125, Neurons: 16, Grad norm: 1.205e+02\n",
      "Epoch 561, Loss: 1325.2332763671875, Neurons: 16, Grad norm: 1.201e+02\n",
      "Epoch 561, Loss: 1325.2332763671875, Neurons: 16, Grad norm: 1.201e+02\n",
      "Epoch 562, Loss: 1324.6519775390625, Neurons: 16, Grad norm: 1.197e+02\n",
      "Epoch 562, Loss: 1324.6519775390625, Neurons: 16, Grad norm: 1.197e+02\n",
      "Epoch 563, Loss: 1324.0701904296875, Neurons: 16, Grad norm: 1.193e+02\n",
      "Epoch 563, Loss: 1324.0701904296875, Neurons: 16, Grad norm: 1.193e+02\n",
      "Epoch 564, Loss: 1323.488037109375, Neurons: 16, Grad norm: 1.189e+02\n",
      "Epoch 564, Loss: 1323.488037109375, Neurons: 16, Grad norm: 1.189e+02\n",
      "Epoch 565, Loss: 1322.90576171875, Neurons: 16, Grad norm: 1.185e+02\n",
      "Epoch 565, Loss: 1322.90576171875, Neurons: 16, Grad norm: 1.185e+02\n",
      "Epoch 566, Loss: 1322.3232421875, Neurons: 16, Grad norm: 1.181e+02\n",
      "Epoch 566, Loss: 1322.3232421875, Neurons: 16, Grad norm: 1.181e+02\n",
      "Epoch 567, Loss: 1321.740478515625, Neurons: 16, Grad norm: 1.178e+02\n",
      "Epoch 567, Loss: 1321.740478515625, Neurons: 16, Grad norm: 1.178e+02\n",
      "Epoch 568, Loss: 1321.1573486328125, Neurons: 16, Grad norm: 1.174e+02\n",
      "Epoch 568, Loss: 1321.1573486328125, Neurons: 16, Grad norm: 1.174e+02\n",
      "Epoch 569, Loss: 1320.5743408203125, Neurons: 16, Grad norm: 1.170e+02\n",
      "Epoch 569, Loss: 1320.5743408203125, Neurons: 16, Grad norm: 1.170e+02\n",
      "Epoch 570, Loss: 1319.990966796875, Neurons: 16, Grad norm: 1.167e+02\n",
      "Epoch 570, Loss: 1319.990966796875, Neurons: 16, Grad norm: 1.167e+02\n",
      "Epoch 571, Loss: 1319.4073486328125, Neurons: 16, Grad norm: 1.164e+02\n",
      "Epoch 571, Loss: 1319.4073486328125, Neurons: 16, Grad norm: 1.164e+02\n",
      "Epoch 572, Loss: 1318.82373046875, Neurons: 16, Grad norm: 1.160e+02\n",
      "Epoch 572, Loss: 1318.82373046875, Neurons: 16, Grad norm: 1.160e+02\n",
      "Epoch 573, Loss: 1318.23974609375, Neurons: 16, Grad norm: 1.157e+02\n",
      "Epoch 573, Loss: 1318.23974609375, Neurons: 16, Grad norm: 1.157e+02\n",
      "Epoch 574, Loss: 1317.655517578125, Neurons: 16, Grad norm: 1.154e+02\n",
      "Epoch 574, Loss: 1317.655517578125, Neurons: 16, Grad norm: 1.154e+02\n",
      "Epoch 575, Loss: 1317.0712890625, Neurons: 16, Grad norm: 1.151e+02\n",
      "Epoch 575, Loss: 1317.0712890625, Neurons: 16, Grad norm: 1.151e+02\n",
      "Epoch 576, Loss: 1316.4866943359375, Neurons: 16, Grad norm: 1.148e+02\n",
      "Epoch 576, Loss: 1316.4866943359375, Neurons: 16, Grad norm: 1.148e+02\n",
      "Epoch 577, Loss: 1315.90185546875, Neurons: 16, Grad norm: 1.145e+02\n",
      "Epoch 577, Loss: 1315.90185546875, Neurons: 16, Grad norm: 1.145e+02\n",
      "Epoch 578, Loss: 1315.31689453125, Neurons: 16, Grad norm: 1.142e+02\n",
      "Epoch 578, Loss: 1315.31689453125, Neurons: 16, Grad norm: 1.142e+02\n",
      "Epoch 579, Loss: 1314.7315673828125, Neurons: 16, Grad norm: 1.139e+02\n",
      "Epoch 579, Loss: 1314.7315673828125, Neurons: 16, Grad norm: 1.139e+02\n",
      "Epoch 580, Loss: 1314.145751953125, Neurons: 16, Grad norm: 1.136e+02\n",
      "Epoch 580, Loss: 1314.145751953125, Neurons: 16, Grad norm: 1.136e+02\n",
      "Epoch 581, Loss: 1313.56005859375, Neurons: 16, Grad norm: 1.133e+02\n",
      "Epoch 581, Loss: 1313.56005859375, Neurons: 16, Grad norm: 1.133e+02\n",
      "Epoch 582, Loss: 1312.9736328125, Neurons: 16, Grad norm: 1.131e+02\n",
      "Epoch 582, Loss: 1312.9736328125, Neurons: 16, Grad norm: 1.131e+02\n",
      "Epoch 583, Loss: 1312.3870849609375, Neurons: 16, Grad norm: 1.128e+02\n",
      "Epoch 583, Loss: 1312.3870849609375, Neurons: 16, Grad norm: 1.128e+02\n",
      "Epoch 584, Loss: 1311.7999267578125, Neurons: 16, Grad norm: 1.126e+02\n",
      "Epoch 584, Loss: 1311.7999267578125, Neurons: 16, Grad norm: 1.126e+02\n",
      "Epoch 585, Loss: 1311.2125244140625, Neurons: 16, Grad norm: 1.123e+02\n",
      "Epoch 585, Loss: 1311.2125244140625, Neurons: 16, Grad norm: 1.123e+02\n",
      "Epoch 586, Loss: 1310.62451171875, Neurons: 16, Grad norm: 1.121e+02\n",
      "Epoch 586, Loss: 1310.62451171875, Neurons: 16, Grad norm: 1.121e+02\n",
      "Epoch 587, Loss: 1310.0360107421875, Neurons: 16, Grad norm: 1.119e+02\n",
      "Epoch 587, Loss: 1310.0360107421875, Neurons: 16, Grad norm: 1.119e+02\n",
      "Epoch 588, Loss: 1309.447021484375, Neurons: 16, Grad norm: 1.117e+02\n",
      "Epoch 588, Loss: 1309.447021484375, Neurons: 16, Grad norm: 1.117e+02\n",
      "Epoch 589, Loss: 1308.8575439453125, Neurons: 16, Grad norm: 1.115e+02\n",
      "Epoch 589, Loss: 1308.8575439453125, Neurons: 16, Grad norm: 1.115e+02\n",
      "Epoch 590, Loss: 1308.2674560546875, Neurons: 16, Grad norm: 1.113e+02\n",
      "Epoch 590, Loss: 1308.2674560546875, Neurons: 16, Grad norm: 1.113e+02\n",
      "Epoch 591, Loss: 1307.6767578125, Neurons: 16, Grad norm: 1.111e+02\n",
      "Epoch 591, Loss: 1307.6767578125, Neurons: 16, Grad norm: 1.111e+02\n",
      "Epoch 592, Loss: 1307.0853271484375, Neurons: 16, Grad norm: 1.109e+02\n",
      "Epoch 592, Loss: 1307.0853271484375, Neurons: 16, Grad norm: 1.109e+02\n",
      "Epoch 593, Loss: 1306.4932861328125, Neurons: 16, Grad norm: 1.107e+02\n",
      "Epoch 593, Loss: 1306.4932861328125, Neurons: 16, Grad norm: 1.107e+02\n",
      "Epoch 594, Loss: 1305.900390625, Neurons: 16, Grad norm: 1.105e+02\n",
      "Epoch 594, Loss: 1305.900390625, Neurons: 16, Grad norm: 1.105e+02\n",
      "Epoch 595, Loss: 1305.3067626953125, Neurons: 16, Grad norm: 1.103e+02\n",
      "Epoch 595, Loss: 1305.3067626953125, Neurons: 16, Grad norm: 1.103e+02\n",
      "Epoch 596, Loss: 1304.7125244140625, Neurons: 16, Grad norm: 1.102e+02\n",
      "Epoch 596, Loss: 1304.7125244140625, Neurons: 16, Grad norm: 1.102e+02\n",
      "Epoch 597, Loss: 1304.1173095703125, Neurons: 16, Grad norm: 1.100e+02\n",
      "Epoch 597, Loss: 1304.1173095703125, Neurons: 16, Grad norm: 1.100e+02\n",
      "Epoch 598, Loss: 1303.5213623046875, Neurons: 16, Grad norm: 1.098e+02\n",
      "Epoch 598, Loss: 1303.5213623046875, Neurons: 16, Grad norm: 1.098e+02\n",
      "Epoch 599, Loss: 1302.92431640625, Neurons: 16, Grad norm: 1.097e+02\n",
      "Epoch 599, Loss: 1302.92431640625, Neurons: 16, Grad norm: 1.097e+02\n",
      "Epoch 599, Test loss: 1326.5008544921875\n",
      "Epoch 599, Test loss: 1326.5008544921875\n",
      "Added neuron to hidden layer 2 with activation sin\n",
      "Added neuron to hidden layer 2 with activation sin\n",
      "network shape updated to :[8, 8, 1]\n",
      "network shape updated to :[8, 8, 1]\n",
      "Epoch 600, Loss: 1302.289794921875, Neurons: 17, Grad norm: 1.096e+02\n",
      "Epoch 600, Loss: 1302.289794921875, Neurons: 17, Grad norm: 1.096e+02\n",
      "Epoch 601, Loss: 1302.132080078125, Neurons: 17, Grad norm: 1.095e+02\n",
      "Epoch 601, Loss: 1302.132080078125, Neurons: 17, Grad norm: 1.095e+02\n",
      "Epoch 602, Loss: 1301.9664306640625, Neurons: 17, Grad norm: 1.095e+02\n",
      "Epoch 602, Loss: 1301.9664306640625, Neurons: 17, Grad norm: 1.095e+02\n",
      "Epoch 603, Loss: 1301.7930908203125, Neurons: 17, Grad norm: 1.094e+02\n",
      "Epoch 603, Loss: 1301.7930908203125, Neurons: 17, Grad norm: 1.094e+02\n",
      "Epoch 604, Loss: 1301.61181640625, Neurons: 17, Grad norm: 1.093e+02\n",
      "Epoch 604, Loss: 1301.61181640625, Neurons: 17, Grad norm: 1.093e+02\n",
      "Epoch 605, Loss: 1301.4227294921875, Neurons: 17, Grad norm: 1.092e+02\n",
      "Epoch 605, Loss: 1301.4227294921875, Neurons: 17, Grad norm: 1.092e+02\n",
      "Epoch 606, Loss: 1301.225830078125, Neurons: 17, Grad norm: 1.091e+02\n",
      "Epoch 606, Loss: 1301.225830078125, Neurons: 17, Grad norm: 1.091e+02\n",
      "Epoch 607, Loss: 1301.021240234375, Neurons: 17, Grad norm: 1.090e+02\n",
      "Epoch 607, Loss: 1301.021240234375, Neurons: 17, Grad norm: 1.090e+02\n",
      "Epoch 608, Loss: 1300.808837890625, Neurons: 17, Grad norm: 1.089e+02\n",
      "Epoch 608, Loss: 1300.808837890625, Neurons: 17, Grad norm: 1.089e+02\n",
      "Epoch 609, Loss: 1300.5888671875, Neurons: 17, Grad norm: 1.088e+02\n",
      "Epoch 609, Loss: 1300.5888671875, Neurons: 17, Grad norm: 1.088e+02\n",
      "Epoch 610, Loss: 1300.361328125, Neurons: 17, Grad norm: 1.087e+02\n",
      "Epoch 610, Loss: 1300.361328125, Neurons: 17, Grad norm: 1.087e+02\n",
      "Epoch 611, Loss: 1300.12646484375, Neurons: 17, Grad norm: 1.086e+02\n",
      "Epoch 611, Loss: 1300.12646484375, Neurons: 17, Grad norm: 1.086e+02\n",
      "Epoch 612, Loss: 1299.88427734375, Neurons: 17, Grad norm: 1.085e+02\n",
      "Epoch 612, Loss: 1299.88427734375, Neurons: 17, Grad norm: 1.085e+02\n",
      "Epoch 613, Loss: 1299.63525390625, Neurons: 17, Grad norm: 1.084e+02\n",
      "Epoch 613, Loss: 1299.63525390625, Neurons: 17, Grad norm: 1.084e+02\n",
      "Epoch 614, Loss: 1299.3790283203125, Neurons: 17, Grad norm: 1.083e+02\n",
      "Epoch 614, Loss: 1299.3790283203125, Neurons: 17, Grad norm: 1.083e+02\n",
      "Epoch 615, Loss: 1299.1163330078125, Neurons: 17, Grad norm: 1.082e+02\n",
      "Epoch 615, Loss: 1299.1163330078125, Neurons: 17, Grad norm: 1.082e+02\n",
      "Epoch 616, Loss: 1298.8468017578125, Neurons: 17, Grad norm: 1.081e+02\n",
      "Epoch 616, Loss: 1298.8468017578125, Neurons: 17, Grad norm: 1.081e+02\n",
      "Epoch 617, Loss: 1298.571044921875, Neurons: 17, Grad norm: 1.080e+02\n",
      "Epoch 617, Loss: 1298.571044921875, Neurons: 17, Grad norm: 1.080e+02\n",
      "Epoch 618, Loss: 1298.288818359375, Neurons: 17, Grad norm: 1.079e+02\n",
      "Epoch 618, Loss: 1298.288818359375, Neurons: 17, Grad norm: 1.079e+02\n",
      "Epoch 619, Loss: 1298.0006103515625, Neurons: 17, Grad norm: 1.078e+02\n",
      "Epoch 619, Loss: 1298.0006103515625, Neurons: 17, Grad norm: 1.078e+02\n",
      "Epoch 620, Loss: 1297.7060546875, Neurons: 17, Grad norm: 1.077e+02\n",
      "Epoch 620, Loss: 1297.7060546875, Neurons: 17, Grad norm: 1.077e+02\n",
      "Epoch 621, Loss: 1297.40576171875, Neurons: 17, Grad norm: 1.076e+02\n",
      "Epoch 621, Loss: 1297.40576171875, Neurons: 17, Grad norm: 1.076e+02\n",
      "Epoch 622, Loss: 1297.099853515625, Neurons: 17, Grad norm: 1.075e+02\n",
      "Epoch 622, Loss: 1297.099853515625, Neurons: 17, Grad norm: 1.075e+02\n",
      "Epoch 623, Loss: 1296.788330078125, Neurons: 17, Grad norm: 1.074e+02\n",
      "Epoch 623, Loss: 1296.788330078125, Neurons: 17, Grad norm: 1.074e+02\n",
      "Epoch 624, Loss: 1296.4710693359375, Neurons: 17, Grad norm: 1.073e+02\n",
      "Epoch 624, Loss: 1296.4710693359375, Neurons: 17, Grad norm: 1.073e+02\n",
      "Epoch 625, Loss: 1296.1485595703125, Neurons: 17, Grad norm: 1.072e+02\n",
      "Epoch 625, Loss: 1296.1485595703125, Neurons: 17, Grad norm: 1.072e+02\n",
      "Epoch 626, Loss: 1295.82080078125, Neurons: 17, Grad norm: 1.071e+02\n",
      "Epoch 626, Loss: 1295.82080078125, Neurons: 17, Grad norm: 1.071e+02\n",
      "Epoch 627, Loss: 1295.48779296875, Neurons: 17, Grad norm: 1.070e+02\n",
      "Epoch 627, Loss: 1295.48779296875, Neurons: 17, Grad norm: 1.070e+02\n",
      "Epoch 628, Loss: 1295.1497802734375, Neurons: 17, Grad norm: 1.070e+02\n",
      "Epoch 628, Loss: 1295.1497802734375, Neurons: 17, Grad norm: 1.070e+02\n",
      "Epoch 629, Loss: 1294.8065185546875, Neurons: 17, Grad norm: 1.069e+02\n",
      "Epoch 629, Loss: 1294.8065185546875, Neurons: 17, Grad norm: 1.069e+02\n",
      "Epoch 630, Loss: 1294.4586181640625, Neurons: 17, Grad norm: 1.068e+02\n",
      "Epoch 630, Loss: 1294.4586181640625, Neurons: 17, Grad norm: 1.068e+02\n",
      "Epoch 631, Loss: 1294.105712890625, Neurons: 17, Grad norm: 1.067e+02\n",
      "Epoch 631, Loss: 1294.105712890625, Neurons: 17, Grad norm: 1.067e+02\n",
      "Epoch 632, Loss: 1293.748046875, Neurons: 17, Grad norm: 1.067e+02\n",
      "Epoch 632, Loss: 1293.748046875, Neurons: 17, Grad norm: 1.067e+02\n",
      "Epoch 633, Loss: 1293.3856201171875, Neurons: 17, Grad norm: 1.066e+02\n",
      "Epoch 633, Loss: 1293.3856201171875, Neurons: 17, Grad norm: 1.066e+02\n",
      "Epoch 634, Loss: 1293.0185546875, Neurons: 17, Grad norm: 1.065e+02\n",
      "Epoch 634, Loss: 1293.0185546875, Neurons: 17, Grad norm: 1.065e+02\n",
      "Epoch 635, Loss: 1292.6470947265625, Neurons: 17, Grad norm: 1.065e+02\n",
      "Epoch 635, Loss: 1292.6470947265625, Neurons: 17, Grad norm: 1.065e+02\n",
      "Epoch 636, Loss: 1292.27099609375, Neurons: 17, Grad norm: 1.064e+02\n",
      "Epoch 636, Loss: 1292.27099609375, Neurons: 17, Grad norm: 1.064e+02\n",
      "Epoch 637, Loss: 1291.8902587890625, Neurons: 17, Grad norm: 1.064e+02\n",
      "Epoch 637, Loss: 1291.8902587890625, Neurons: 17, Grad norm: 1.064e+02\n",
      "Epoch 638, Loss: 1291.50537109375, Neurons: 17, Grad norm: 1.063e+02\n",
      "Epoch 638, Loss: 1291.50537109375, Neurons: 17, Grad norm: 1.063e+02\n",
      "Epoch 639, Loss: 1291.115966796875, Neurons: 17, Grad norm: 1.063e+02\n",
      "Epoch 639, Loss: 1291.115966796875, Neurons: 17, Grad norm: 1.063e+02\n",
      "Epoch 640, Loss: 1290.72216796875, Neurons: 17, Grad norm: 1.062e+02\n",
      "Epoch 640, Loss: 1290.72216796875, Neurons: 17, Grad norm: 1.062e+02\n",
      "Epoch 641, Loss: 1290.32421875, Neurons: 17, Grad norm: 1.062e+02\n",
      "Epoch 641, Loss: 1290.32421875, Neurons: 17, Grad norm: 1.062e+02\n",
      "Epoch 642, Loss: 1289.9217529296875, Neurons: 17, Grad norm: 1.061e+02\n",
      "Epoch 642, Loss: 1289.9217529296875, Neurons: 17, Grad norm: 1.061e+02\n",
      "Epoch 643, Loss: 1289.515380859375, Neurons: 17, Grad norm: 1.061e+02\n",
      "Epoch 643, Loss: 1289.515380859375, Neurons: 17, Grad norm: 1.061e+02\n",
      "Epoch 644, Loss: 1289.104736328125, Neurons: 17, Grad norm: 1.060e+02\n",
      "Epoch 644, Loss: 1289.104736328125, Neurons: 17, Grad norm: 1.060e+02\n",
      "Epoch 645, Loss: 1288.6898193359375, Neurons: 17, Grad norm: 1.060e+02\n",
      "Epoch 645, Loss: 1288.6898193359375, Neurons: 17, Grad norm: 1.060e+02\n",
      "Epoch 646, Loss: 1288.27099609375, Neurons: 17, Grad norm: 1.060e+02\n",
      "Epoch 646, Loss: 1288.27099609375, Neurons: 17, Grad norm: 1.060e+02\n",
      "Epoch 647, Loss: 1287.847900390625, Neurons: 17, Grad norm: 1.059e+02\n",
      "Epoch 647, Loss: 1287.847900390625, Neurons: 17, Grad norm: 1.059e+02\n",
      "Epoch 648, Loss: 1287.4207763671875, Neurons: 17, Grad norm: 1.059e+02\n",
      "Epoch 648, Loss: 1287.4207763671875, Neurons: 17, Grad norm: 1.059e+02\n",
      "Epoch 649, Loss: 1286.98974609375, Neurons: 17, Grad norm: 1.059e+02\n",
      "Epoch 649, Loss: 1286.98974609375, Neurons: 17, Grad norm: 1.059e+02\n",
      "Epoch 650, Loss: 1286.5545654296875, Neurons: 17, Grad norm: 1.058e+02\n",
      "Epoch 650, Loss: 1286.5545654296875, Neurons: 17, Grad norm: 1.058e+02\n",
      "Epoch 651, Loss: 1286.1156005859375, Neurons: 17, Grad norm: 1.058e+02\n",
      "Epoch 651, Loss: 1286.1156005859375, Neurons: 17, Grad norm: 1.058e+02\n",
      "Epoch 652, Loss: 1285.6727294921875, Neurons: 17, Grad norm: 1.058e+02\n",
      "Epoch 652, Loss: 1285.6727294921875, Neurons: 17, Grad norm: 1.058e+02\n",
      "Epoch 653, Loss: 1285.2257080078125, Neurons: 17, Grad norm: 1.058e+02\n",
      "Epoch 653, Loss: 1285.2257080078125, Neurons: 17, Grad norm: 1.058e+02\n",
      "Epoch 654, Loss: 1284.7750244140625, Neurons: 17, Grad norm: 1.057e+02\n",
      "Epoch 654, Loss: 1284.7750244140625, Neurons: 17, Grad norm: 1.057e+02\n",
      "Epoch 655, Loss: 1284.3203125, Neurons: 17, Grad norm: 1.057e+02\n",
      "Epoch 655, Loss: 1284.3203125, Neurons: 17, Grad norm: 1.057e+02\n",
      "Epoch 656, Loss: 1283.86181640625, Neurons: 17, Grad norm: 1.057e+02\n",
      "Epoch 656, Loss: 1283.86181640625, Neurons: 17, Grad norm: 1.057e+02\n",
      "Epoch 657, Loss: 1283.399658203125, Neurons: 17, Grad norm: 1.057e+02\n",
      "Epoch 657, Loss: 1283.399658203125, Neurons: 17, Grad norm: 1.057e+02\n",
      "Epoch 658, Loss: 1282.9337158203125, Neurons: 17, Grad norm: 1.056e+02\n",
      "Epoch 658, Loss: 1282.9337158203125, Neurons: 17, Grad norm: 1.056e+02\n",
      "Epoch 659, Loss: 1282.464111328125, Neurons: 17, Grad norm: 1.056e+02\n",
      "Epoch 659, Loss: 1282.464111328125, Neurons: 17, Grad norm: 1.056e+02\n",
      "Epoch 660, Loss: 1281.99072265625, Neurons: 17, Grad norm: 1.056e+02\n",
      "Epoch 660, Loss: 1281.99072265625, Neurons: 17, Grad norm: 1.056e+02\n",
      "Epoch 661, Loss: 1281.5135498046875, Neurons: 17, Grad norm: 1.056e+02\n",
      "Epoch 661, Loss: 1281.5135498046875, Neurons: 17, Grad norm: 1.056e+02\n",
      "Epoch 662, Loss: 1281.032958984375, Neurons: 17, Grad norm: 1.056e+02\n",
      "Epoch 662, Loss: 1281.032958984375, Neurons: 17, Grad norm: 1.056e+02\n",
      "Epoch 663, Loss: 1280.548583984375, Neurons: 17, Grad norm: 1.056e+02\n",
      "Epoch 663, Loss: 1280.548583984375, Neurons: 17, Grad norm: 1.056e+02\n",
      "Epoch 664, Loss: 1280.060791015625, Neurons: 17, Grad norm: 1.055e+02\n",
      "Epoch 664, Loss: 1280.060791015625, Neurons: 17, Grad norm: 1.055e+02\n",
      "Epoch 665, Loss: 1279.5693359375, Neurons: 17, Grad norm: 1.055e+02\n",
      "Epoch 665, Loss: 1279.5693359375, Neurons: 17, Grad norm: 1.055e+02\n",
      "Epoch 666, Loss: 1279.074462890625, Neurons: 17, Grad norm: 1.055e+02\n",
      "Epoch 666, Loss: 1279.074462890625, Neurons: 17, Grad norm: 1.055e+02\n",
      "Epoch 667, Loss: 1278.5760498046875, Neurons: 17, Grad norm: 1.055e+02\n",
      "Epoch 667, Loss: 1278.5760498046875, Neurons: 17, Grad norm: 1.055e+02\n",
      "Epoch 668, Loss: 1278.0743408203125, Neurons: 17, Grad norm: 1.055e+02\n",
      "Epoch 668, Loss: 1278.0743408203125, Neurons: 17, Grad norm: 1.055e+02\n",
      "Epoch 669, Loss: 1277.569091796875, Neurons: 17, Grad norm: 1.054e+02\n",
      "Epoch 669, Loss: 1277.569091796875, Neurons: 17, Grad norm: 1.054e+02\n",
      "Epoch 670, Loss: 1277.060302734375, Neurons: 17, Grad norm: 1.054e+02\n",
      "Epoch 670, Loss: 1277.060302734375, Neurons: 17, Grad norm: 1.054e+02\n",
      "Epoch 671, Loss: 1276.5482177734375, Neurons: 17, Grad norm: 1.054e+02\n",
      "Epoch 671, Loss: 1276.5482177734375, Neurons: 17, Grad norm: 1.054e+02\n",
      "Epoch 672, Loss: 1276.0328369140625, Neurons: 17, Grad norm: 1.054e+02\n",
      "Epoch 672, Loss: 1276.0328369140625, Neurons: 17, Grad norm: 1.054e+02\n",
      "Epoch 673, Loss: 1275.5140380859375, Neurons: 17, Grad norm: 1.054e+02\n",
      "Epoch 673, Loss: 1275.5140380859375, Neurons: 17, Grad norm: 1.054e+02\n",
      "Epoch 674, Loss: 1274.991943359375, Neurons: 17, Grad norm: 1.053e+02\n",
      "Epoch 674, Loss: 1274.991943359375, Neurons: 17, Grad norm: 1.053e+02\n",
      "Epoch 675, Loss: 1274.4666748046875, Neurons: 17, Grad norm: 1.053e+02\n",
      "Epoch 675, Loss: 1274.4666748046875, Neurons: 17, Grad norm: 1.053e+02\n",
      "Epoch 676, Loss: 1273.9381103515625, Neurons: 17, Grad norm: 1.053e+02\n",
      "Epoch 676, Loss: 1273.9381103515625, Neurons: 17, Grad norm: 1.053e+02\n",
      "Epoch 677, Loss: 1273.406005859375, Neurons: 17, Grad norm: 1.053e+02\n",
      "Epoch 677, Loss: 1273.406005859375, Neurons: 17, Grad norm: 1.053e+02\n",
      "Epoch 678, Loss: 1272.870849609375, Neurons: 17, Grad norm: 1.053e+02\n",
      "Epoch 678, Loss: 1272.870849609375, Neurons: 17, Grad norm: 1.053e+02\n",
      "Epoch 679, Loss: 1272.3323974609375, Neurons: 17, Grad norm: 1.052e+02\n",
      "Epoch 679, Loss: 1272.3323974609375, Neurons: 17, Grad norm: 1.052e+02\n",
      "Epoch 680, Loss: 1271.790771484375, Neurons: 17, Grad norm: 1.052e+02\n",
      "Epoch 680, Loss: 1271.790771484375, Neurons: 17, Grad norm: 1.052e+02\n",
      "Epoch 681, Loss: 1271.245849609375, Neurons: 17, Grad norm: 1.052e+02\n",
      "Epoch 681, Loss: 1271.245849609375, Neurons: 17, Grad norm: 1.052e+02\n",
      "Epoch 682, Loss: 1270.69775390625, Neurons: 17, Grad norm: 1.052e+02\n",
      "Epoch 682, Loss: 1270.69775390625, Neurons: 17, Grad norm: 1.052e+02\n",
      "Epoch 683, Loss: 1270.1466064453125, Neurons: 17, Grad norm: 1.051e+02\n",
      "Epoch 683, Loss: 1270.1466064453125, Neurons: 17, Grad norm: 1.051e+02\n",
      "Epoch 684, Loss: 1269.592041015625, Neurons: 17, Grad norm: 1.051e+02\n",
      "Epoch 684, Loss: 1269.592041015625, Neurons: 17, Grad norm: 1.051e+02\n",
      "Epoch 685, Loss: 1269.0345458984375, Neurons: 17, Grad norm: 1.051e+02\n",
      "Epoch 685, Loss: 1269.0345458984375, Neurons: 17, Grad norm: 1.051e+02\n",
      "Epoch 686, Loss: 1268.4735107421875, Neurons: 17, Grad norm: 1.051e+02\n",
      "Epoch 686, Loss: 1268.4735107421875, Neurons: 17, Grad norm: 1.051e+02\n",
      "Epoch 687, Loss: 1267.9097900390625, Neurons: 17, Grad norm: 1.050e+02\n",
      "Epoch 687, Loss: 1267.9097900390625, Neurons: 17, Grad norm: 1.050e+02\n",
      "Epoch 688, Loss: 1267.342529296875, Neurons: 17, Grad norm: 1.050e+02\n",
      "Epoch 688, Loss: 1267.342529296875, Neurons: 17, Grad norm: 1.050e+02\n",
      "Epoch 689, Loss: 1266.7725830078125, Neurons: 17, Grad norm: 1.050e+02\n",
      "Epoch 689, Loss: 1266.7725830078125, Neurons: 17, Grad norm: 1.050e+02\n",
      "Epoch 690, Loss: 1266.1993408203125, Neurons: 17, Grad norm: 1.049e+02\n",
      "Epoch 690, Loss: 1266.1993408203125, Neurons: 17, Grad norm: 1.049e+02\n",
      "Epoch 691, Loss: 1265.622802734375, Neurons: 17, Grad norm: 1.049e+02\n",
      "Epoch 691, Loss: 1265.622802734375, Neurons: 17, Grad norm: 1.049e+02\n",
      "Epoch 692, Loss: 1265.0433349609375, Neurons: 17, Grad norm: 1.049e+02\n",
      "Epoch 692, Loss: 1265.0433349609375, Neurons: 17, Grad norm: 1.049e+02\n",
      "Epoch 693, Loss: 1264.4609375, Neurons: 17, Grad norm: 1.048e+02\n",
      "Epoch 693, Loss: 1264.4609375, Neurons: 17, Grad norm: 1.048e+02\n",
      "Epoch 694, Loss: 1263.87548828125, Neurons: 17, Grad norm: 1.048e+02\n",
      "Epoch 694, Loss: 1263.87548828125, Neurons: 17, Grad norm: 1.048e+02\n",
      "Epoch 695, Loss: 1263.2869873046875, Neurons: 17, Grad norm: 1.048e+02\n",
      "Epoch 695, Loss: 1263.2869873046875, Neurons: 17, Grad norm: 1.048e+02\n",
      "Epoch 696, Loss: 1262.6953125, Neurons: 17, Grad norm: 1.047e+02\n",
      "Epoch 696, Loss: 1262.6953125, Neurons: 17, Grad norm: 1.047e+02\n",
      "Epoch 697, Loss: 1262.1009521484375, Neurons: 17, Grad norm: 1.047e+02\n",
      "Epoch 697, Loss: 1262.1009521484375, Neurons: 17, Grad norm: 1.047e+02\n",
      "Epoch 698, Loss: 1261.5035400390625, Neurons: 17, Grad norm: 1.046e+02\n",
      "Epoch 698, Loss: 1261.5035400390625, Neurons: 17, Grad norm: 1.046e+02\n",
      "Epoch 699, Loss: 1260.9031982421875, Neurons: 17, Grad norm: 1.046e+02\n",
      "Epoch 699, Loss: 1260.9031982421875, Neurons: 17, Grad norm: 1.046e+02\n",
      "Epoch 699, Test loss: 1282.4039306640625\n",
      "Epoch 699, Test loss: 1282.4039306640625\n",
      "Added neuron to hidden layer 1 with activation sin\n",
      "Added neuron to hidden layer 1 with activation sin\n",
      "network shape updated to :[9, 8, 1]\n",
      "network shape updated to :[9, 8, 1]\n",
      "Epoch 700, Loss: 1283.6954345703125, Neurons: 18, Grad norm: 1.671e+02\n",
      "Epoch 700, Loss: 1283.6954345703125, Neurons: 18, Grad norm: 1.671e+02\n",
      "Epoch 701, Loss: 1283.3870849609375, Neurons: 18, Grad norm: 1.668e+02\n",
      "Epoch 701, Loss: 1283.3870849609375, Neurons: 18, Grad norm: 1.668e+02\n",
      "Epoch 702, Loss: 1283.0635986328125, Neurons: 18, Grad norm: 1.665e+02\n",
      "Epoch 702, Loss: 1283.0635986328125, Neurons: 18, Grad norm: 1.665e+02\n",
      "Epoch 703, Loss: 1282.7249755859375, Neurons: 18, Grad norm: 1.661e+02\n",
      "Epoch 703, Loss: 1282.7249755859375, Neurons: 18, Grad norm: 1.661e+02\n",
      "Epoch 704, Loss: 1282.3712158203125, Neurons: 18, Grad norm: 1.658e+02\n",
      "Epoch 704, Loss: 1282.3712158203125, Neurons: 18, Grad norm: 1.658e+02\n",
      "Epoch 705, Loss: 1282.002197265625, Neurons: 18, Grad norm: 1.654e+02\n",
      "Epoch 705, Loss: 1282.002197265625, Neurons: 18, Grad norm: 1.654e+02\n",
      "Epoch 706, Loss: 1281.6182861328125, Neurons: 18, Grad norm: 1.650e+02\n",
      "Epoch 706, Loss: 1281.6182861328125, Neurons: 18, Grad norm: 1.650e+02\n",
      "Epoch 707, Loss: 1281.2196044921875, Neurons: 18, Grad norm: 1.646e+02\n",
      "Epoch 707, Loss: 1281.2196044921875, Neurons: 18, Grad norm: 1.646e+02\n",
      "Epoch 708, Loss: 1280.8060302734375, Neurons: 18, Grad norm: 1.641e+02\n",
      "Epoch 708, Loss: 1280.8060302734375, Neurons: 18, Grad norm: 1.641e+02\n",
      "Epoch 709, Loss: 1280.3782958984375, Neurons: 18, Grad norm: 1.637e+02\n",
      "Epoch 709, Loss: 1280.3782958984375, Neurons: 18, Grad norm: 1.637e+02\n",
      "Epoch 710, Loss: 1279.9364013671875, Neurons: 18, Grad norm: 1.632e+02\n",
      "Epoch 710, Loss: 1279.9364013671875, Neurons: 18, Grad norm: 1.632e+02\n",
      "Epoch 711, Loss: 1279.4808349609375, Neurons: 18, Grad norm: 1.627e+02\n",
      "Epoch 711, Loss: 1279.4808349609375, Neurons: 18, Grad norm: 1.627e+02\n",
      "Epoch 712, Loss: 1279.01171875, Neurons: 18, Grad norm: 1.622e+02\n",
      "Epoch 712, Loss: 1279.01171875, Neurons: 18, Grad norm: 1.622e+02\n",
      "Epoch 713, Loss: 1278.5296630859375, Neurons: 18, Grad norm: 1.617e+02\n",
      "Epoch 713, Loss: 1278.5296630859375, Neurons: 18, Grad norm: 1.617e+02\n",
      "Epoch 714, Loss: 1278.034912109375, Neurons: 18, Grad norm: 1.611e+02\n",
      "Epoch 714, Loss: 1278.034912109375, Neurons: 18, Grad norm: 1.611e+02\n",
      "Epoch 715, Loss: 1277.5283203125, Neurons: 18, Grad norm: 1.606e+02\n",
      "Epoch 715, Loss: 1277.5283203125, Neurons: 18, Grad norm: 1.606e+02\n",
      "Epoch 716, Loss: 1277.009765625, Neurons: 18, Grad norm: 1.600e+02\n",
      "Epoch 716, Loss: 1277.009765625, Neurons: 18, Grad norm: 1.600e+02\n",
      "Epoch 717, Loss: 1276.4803466796875, Neurons: 18, Grad norm: 1.594e+02\n",
      "Epoch 717, Loss: 1276.4803466796875, Neurons: 18, Grad norm: 1.594e+02\n",
      "Epoch 718, Loss: 1275.940185546875, Neurons: 18, Grad norm: 1.588e+02\n",
      "Epoch 718, Loss: 1275.940185546875, Neurons: 18, Grad norm: 1.588e+02\n",
      "Epoch 719, Loss: 1275.3897705078125, Neurons: 18, Grad norm: 1.582e+02\n",
      "Epoch 719, Loss: 1275.3897705078125, Neurons: 18, Grad norm: 1.582e+02\n",
      "Epoch 720, Loss: 1274.829833984375, Neurons: 18, Grad norm: 1.576e+02\n",
      "Epoch 720, Loss: 1274.829833984375, Neurons: 18, Grad norm: 1.576e+02\n",
      "Epoch 721, Loss: 1274.2606201171875, Neurons: 18, Grad norm: 1.569e+02\n",
      "Epoch 721, Loss: 1274.2606201171875, Neurons: 18, Grad norm: 1.569e+02\n",
      "Epoch 722, Loss: 1273.6826171875, Neurons: 18, Grad norm: 1.563e+02\n",
      "Epoch 722, Loss: 1273.6826171875, Neurons: 18, Grad norm: 1.563e+02\n",
      "Epoch 723, Loss: 1273.0965576171875, Neurons: 18, Grad norm: 1.556e+02\n",
      "Epoch 723, Loss: 1273.0965576171875, Neurons: 18, Grad norm: 1.556e+02\n",
      "Epoch 724, Loss: 1272.5029296875, Neurons: 18, Grad norm: 1.549e+02\n",
      "Epoch 724, Loss: 1272.5029296875, Neurons: 18, Grad norm: 1.549e+02\n",
      "Epoch 725, Loss: 1271.9019775390625, Neurons: 18, Grad norm: 1.542e+02\n",
      "Epoch 725, Loss: 1271.9019775390625, Neurons: 18, Grad norm: 1.542e+02\n",
      "Epoch 726, Loss: 1271.294189453125, Neurons: 18, Grad norm: 1.535e+02\n",
      "Epoch 726, Loss: 1271.294189453125, Neurons: 18, Grad norm: 1.535e+02\n",
      "Epoch 727, Loss: 1270.6800537109375, Neurons: 18, Grad norm: 1.528e+02\n",
      "Epoch 727, Loss: 1270.6800537109375, Neurons: 18, Grad norm: 1.528e+02\n",
      "Epoch 728, Loss: 1270.060302734375, Neurons: 18, Grad norm: 1.521e+02\n",
      "Epoch 728, Loss: 1270.060302734375, Neurons: 18, Grad norm: 1.521e+02\n",
      "Epoch 729, Loss: 1269.4349365234375, Neurons: 18, Grad norm: 1.514e+02\n",
      "Epoch 729, Loss: 1269.4349365234375, Neurons: 18, Grad norm: 1.514e+02\n",
      "Epoch 730, Loss: 1268.8045654296875, Neurons: 18, Grad norm: 1.506e+02\n",
      "Epoch 730, Loss: 1268.8045654296875, Neurons: 18, Grad norm: 1.506e+02\n",
      "Epoch 731, Loss: 1268.1695556640625, Neurons: 18, Grad norm: 1.499e+02\n",
      "Epoch 731, Loss: 1268.1695556640625, Neurons: 18, Grad norm: 1.499e+02\n",
      "Epoch 732, Loss: 1267.5302734375, Neurons: 18, Grad norm: 1.492e+02\n",
      "Epoch 732, Loss: 1267.5302734375, Neurons: 18, Grad norm: 1.492e+02\n",
      "Epoch 733, Loss: 1266.8873291015625, Neurons: 18, Grad norm: 1.484e+02\n",
      "Epoch 733, Loss: 1266.8873291015625, Neurons: 18, Grad norm: 1.484e+02\n",
      "Epoch 734, Loss: 1266.2406005859375, Neurons: 18, Grad norm: 1.476e+02\n",
      "Epoch 734, Loss: 1266.2406005859375, Neurons: 18, Grad norm: 1.476e+02\n",
      "Epoch 735, Loss: 1265.5909423828125, Neurons: 18, Grad norm: 1.469e+02\n",
      "Epoch 735, Loss: 1265.5909423828125, Neurons: 18, Grad norm: 1.469e+02\n",
      "Epoch 736, Loss: 1264.9383544921875, Neurons: 18, Grad norm: 1.461e+02\n",
      "Epoch 736, Loss: 1264.9383544921875, Neurons: 18, Grad norm: 1.461e+02\n",
      "Epoch 737, Loss: 1264.282958984375, Neurons: 18, Grad norm: 1.454e+02\n",
      "Epoch 737, Loss: 1264.282958984375, Neurons: 18, Grad norm: 1.454e+02\n",
      "Epoch 738, Loss: 1263.62548828125, Neurons: 18, Grad norm: 1.446e+02\n",
      "Epoch 738, Loss: 1263.62548828125, Neurons: 18, Grad norm: 1.446e+02\n",
      "Epoch 739, Loss: 1262.9659423828125, Neurons: 18, Grad norm: 1.438e+02\n",
      "Epoch 739, Loss: 1262.9659423828125, Neurons: 18, Grad norm: 1.438e+02\n",
      "Epoch 740, Loss: 1262.3048095703125, Neurons: 18, Grad norm: 1.431e+02\n",
      "Epoch 740, Loss: 1262.3048095703125, Neurons: 18, Grad norm: 1.431e+02\n",
      "Epoch 741, Loss: 1261.64208984375, Neurons: 18, Grad norm: 1.423e+02\n",
      "Epoch 741, Loss: 1261.64208984375, Neurons: 18, Grad norm: 1.423e+02\n",
      "Epoch 742, Loss: 1260.97802734375, Neurons: 18, Grad norm: 1.415e+02\n",
      "Epoch 742, Loss: 1260.97802734375, Neurons: 18, Grad norm: 1.415e+02\n",
      "Epoch 743, Loss: 1260.3131103515625, Neurons: 18, Grad norm: 1.408e+02\n",
      "Epoch 743, Loss: 1260.3131103515625, Neurons: 18, Grad norm: 1.408e+02\n",
      "Epoch 744, Loss: 1259.6473388671875, Neurons: 18, Grad norm: 1.400e+02\n",
      "Epoch 744, Loss: 1259.6473388671875, Neurons: 18, Grad norm: 1.400e+02\n",
      "Epoch 745, Loss: 1258.9810791015625, Neurons: 18, Grad norm: 1.393e+02\n",
      "Epoch 745, Loss: 1258.9810791015625, Neurons: 18, Grad norm: 1.393e+02\n",
      "Epoch 746, Loss: 1258.3143310546875, Neurons: 18, Grad norm: 1.385e+02\n",
      "Epoch 746, Loss: 1258.3143310546875, Neurons: 18, Grad norm: 1.385e+02\n",
      "Epoch 747, Loss: 1257.6473388671875, Neurons: 18, Grad norm: 1.377e+02\n",
      "Epoch 747, Loss: 1257.6473388671875, Neurons: 18, Grad norm: 1.377e+02\n",
      "Epoch 748, Loss: 1256.9803466796875, Neurons: 18, Grad norm: 1.370e+02\n",
      "Epoch 748, Loss: 1256.9803466796875, Neurons: 18, Grad norm: 1.370e+02\n",
      "Epoch 749, Loss: 1256.3133544921875, Neurons: 18, Grad norm: 1.362e+02\n",
      "Epoch 749, Loss: 1256.3133544921875, Neurons: 18, Grad norm: 1.362e+02\n",
      "Epoch 750, Loss: 1255.646728515625, Neurons: 18, Grad norm: 1.355e+02\n",
      "Epoch 750, Loss: 1255.646728515625, Neurons: 18, Grad norm: 1.355e+02\n",
      "Epoch 751, Loss: 1254.9805908203125, Neurons: 18, Grad norm: 1.347e+02\n",
      "Epoch 751, Loss: 1254.9805908203125, Neurons: 18, Grad norm: 1.347e+02\n",
      "Epoch 752, Loss: 1254.3148193359375, Neurons: 18, Grad norm: 1.340e+02\n",
      "Epoch 752, Loss: 1254.3148193359375, Neurons: 18, Grad norm: 1.340e+02\n",
      "Epoch 753, Loss: 1253.6497802734375, Neurons: 18, Grad norm: 1.333e+02\n",
      "Epoch 753, Loss: 1253.6497802734375, Neurons: 18, Grad norm: 1.333e+02\n",
      "Epoch 754, Loss: 1252.9857177734375, Neurons: 18, Grad norm: 1.325e+02\n",
      "Epoch 754, Loss: 1252.9857177734375, Neurons: 18, Grad norm: 1.325e+02\n",
      "Epoch 755, Loss: 1252.3223876953125, Neurons: 18, Grad norm: 1.318e+02\n",
      "Epoch 755, Loss: 1252.3223876953125, Neurons: 18, Grad norm: 1.318e+02\n",
      "Epoch 756, Loss: 1251.66015625, Neurons: 18, Grad norm: 1.311e+02\n",
      "Epoch 756, Loss: 1251.66015625, Neurons: 18, Grad norm: 1.311e+02\n",
      "Epoch 757, Loss: 1250.9991455078125, Neurons: 18, Grad norm: 1.304e+02\n",
      "Epoch 757, Loss: 1250.9991455078125, Neurons: 18, Grad norm: 1.304e+02\n",
      "Epoch 758, Loss: 1250.3392333984375, Neurons: 18, Grad norm: 1.296e+02\n",
      "Epoch 758, Loss: 1250.3392333984375, Neurons: 18, Grad norm: 1.296e+02\n",
      "Epoch 759, Loss: 1249.6806640625, Neurons: 18, Grad norm: 1.289e+02\n",
      "Epoch 759, Loss: 1249.6806640625, Neurons: 18, Grad norm: 1.289e+02\n",
      "Epoch 760, Loss: 1249.0235595703125, Neurons: 18, Grad norm: 1.282e+02\n",
      "Epoch 760, Loss: 1249.0235595703125, Neurons: 18, Grad norm: 1.282e+02\n",
      "Epoch 761, Loss: 1248.367919921875, Neurons: 18, Grad norm: 1.275e+02\n",
      "Epoch 761, Loss: 1248.367919921875, Neurons: 18, Grad norm: 1.275e+02\n",
      "Epoch 762, Loss: 1247.7138671875, Neurons: 18, Grad norm: 1.268e+02\n",
      "Epoch 762, Loss: 1247.7138671875, Neurons: 18, Grad norm: 1.268e+02\n",
      "Epoch 763, Loss: 1247.061279296875, Neurons: 18, Grad norm: 1.261e+02\n",
      "Epoch 763, Loss: 1247.061279296875, Neurons: 18, Grad norm: 1.261e+02\n",
      "Epoch 764, Loss: 1246.4105224609375, Neurons: 18, Grad norm: 1.255e+02\n",
      "Epoch 764, Loss: 1246.4105224609375, Neurons: 18, Grad norm: 1.255e+02\n",
      "Epoch 765, Loss: 1245.7618408203125, Neurons: 18, Grad norm: 1.248e+02\n",
      "Epoch 765, Loss: 1245.7618408203125, Neurons: 18, Grad norm: 1.248e+02\n",
      "Epoch 766, Loss: 1245.114501953125, Neurons: 18, Grad norm: 1.241e+02\n",
      "Epoch 766, Loss: 1245.114501953125, Neurons: 18, Grad norm: 1.241e+02\n",
      "Epoch 767, Loss: 1244.469482421875, Neurons: 18, Grad norm: 1.234e+02\n",
      "Epoch 767, Loss: 1244.469482421875, Neurons: 18, Grad norm: 1.234e+02\n",
      "Epoch 768, Loss: 1243.8260498046875, Neurons: 18, Grad norm: 1.228e+02\n",
      "Epoch 768, Loss: 1243.8260498046875, Neurons: 18, Grad norm: 1.228e+02\n",
      "Epoch 769, Loss: 1243.1849365234375, Neurons: 18, Grad norm: 1.221e+02\n",
      "Epoch 769, Loss: 1243.1849365234375, Neurons: 18, Grad norm: 1.221e+02\n",
      "Epoch 770, Loss: 1242.545654296875, Neurons: 18, Grad norm: 1.214e+02\n",
      "Epoch 770, Loss: 1242.545654296875, Neurons: 18, Grad norm: 1.214e+02\n",
      "Epoch 771, Loss: 1241.9085693359375, Neurons: 18, Grad norm: 1.208e+02\n",
      "Epoch 771, Loss: 1241.9085693359375, Neurons: 18, Grad norm: 1.208e+02\n",
      "Epoch 772, Loss: 1241.2735595703125, Neurons: 18, Grad norm: 1.201e+02\n",
      "Epoch 772, Loss: 1241.2735595703125, Neurons: 18, Grad norm: 1.201e+02\n",
      "Epoch 773, Loss: 1240.640869140625, Neurons: 18, Grad norm: 1.195e+02\n",
      "Epoch 773, Loss: 1240.640869140625, Neurons: 18, Grad norm: 1.195e+02\n",
      "Epoch 774, Loss: 1240.0101318359375, Neurons: 18, Grad norm: 1.189e+02\n",
      "Epoch 774, Loss: 1240.0101318359375, Neurons: 18, Grad norm: 1.189e+02\n",
      "Epoch 775, Loss: 1239.3818359375, Neurons: 18, Grad norm: 1.182e+02\n",
      "Epoch 775, Loss: 1239.3818359375, Neurons: 18, Grad norm: 1.182e+02\n",
      "Epoch 776, Loss: 1238.755859375, Neurons: 18, Grad norm: 1.176e+02\n",
      "Epoch 776, Loss: 1238.755859375, Neurons: 18, Grad norm: 1.176e+02\n",
      "Epoch 777, Loss: 1238.132080078125, Neurons: 18, Grad norm: 1.170e+02\n",
      "Epoch 777, Loss: 1238.132080078125, Neurons: 18, Grad norm: 1.170e+02\n",
      "Epoch 778, Loss: 1237.5107421875, Neurons: 18, Grad norm: 1.164e+02\n",
      "Epoch 778, Loss: 1237.5107421875, Neurons: 18, Grad norm: 1.164e+02\n",
      "Epoch 779, Loss: 1236.8916015625, Neurons: 18, Grad norm: 1.158e+02\n",
      "Epoch 779, Loss: 1236.8916015625, Neurons: 18, Grad norm: 1.158e+02\n",
      "Epoch 780, Loss: 1236.27490234375, Neurons: 18, Grad norm: 1.152e+02\n",
      "Epoch 780, Loss: 1236.27490234375, Neurons: 18, Grad norm: 1.152e+02\n",
      "Epoch 781, Loss: 1235.6607666015625, Neurons: 18, Grad norm: 1.146e+02\n",
      "Epoch 781, Loss: 1235.6607666015625, Neurons: 18, Grad norm: 1.146e+02\n",
      "Epoch 782, Loss: 1235.0489501953125, Neurons: 18, Grad norm: 1.140e+02\n",
      "Epoch 782, Loss: 1235.0489501953125, Neurons: 18, Grad norm: 1.140e+02\n",
      "Epoch 783, Loss: 1234.4395751953125, Neurons: 18, Grad norm: 1.134e+02\n",
      "Epoch 783, Loss: 1234.4395751953125, Neurons: 18, Grad norm: 1.134e+02\n",
      "Epoch 784, Loss: 1233.8326416015625, Neurons: 18, Grad norm: 1.128e+02\n",
      "Epoch 784, Loss: 1233.8326416015625, Neurons: 18, Grad norm: 1.128e+02\n",
      "Epoch 785, Loss: 1233.228271484375, Neurons: 18, Grad norm: 1.122e+02\n",
      "Epoch 785, Loss: 1233.228271484375, Neurons: 18, Grad norm: 1.122e+02\n",
      "Epoch 786, Loss: 1232.6263427734375, Neurons: 18, Grad norm: 1.116e+02\n",
      "Epoch 786, Loss: 1232.6263427734375, Neurons: 18, Grad norm: 1.116e+02\n",
      "Epoch 787, Loss: 1232.02685546875, Neurons: 18, Grad norm: 1.111e+02\n",
      "Epoch 787, Loss: 1232.02685546875, Neurons: 18, Grad norm: 1.111e+02\n",
      "Epoch 788, Loss: 1231.4298095703125, Neurons: 18, Grad norm: 1.105e+02\n",
      "Epoch 788, Loss: 1231.4298095703125, Neurons: 18, Grad norm: 1.105e+02\n",
      "Epoch 789, Loss: 1230.8353271484375, Neurons: 18, Grad norm: 1.099e+02\n",
      "Epoch 789, Loss: 1230.8353271484375, Neurons: 18, Grad norm: 1.099e+02\n",
      "Epoch 790, Loss: 1230.2432861328125, Neurons: 18, Grad norm: 1.094e+02\n",
      "Epoch 790, Loss: 1230.2432861328125, Neurons: 18, Grad norm: 1.094e+02\n",
      "Epoch 791, Loss: 1229.65380859375, Neurons: 18, Grad norm: 1.088e+02\n",
      "Epoch 791, Loss: 1229.65380859375, Neurons: 18, Grad norm: 1.088e+02\n",
      "Epoch 792, Loss: 1229.0667724609375, Neurons: 18, Grad norm: 1.083e+02\n",
      "Epoch 792, Loss: 1229.0667724609375, Neurons: 18, Grad norm: 1.083e+02\n",
      "Epoch 793, Loss: 1228.4822998046875, Neurons: 18, Grad norm: 1.077e+02\n",
      "Epoch 793, Loss: 1228.4822998046875, Neurons: 18, Grad norm: 1.077e+02\n",
      "Epoch 794, Loss: 1227.9002685546875, Neurons: 18, Grad norm: 1.072e+02\n",
      "Epoch 794, Loss: 1227.9002685546875, Neurons: 18, Grad norm: 1.072e+02\n",
      "Epoch 795, Loss: 1227.32080078125, Neurons: 18, Grad norm: 1.067e+02\n",
      "Epoch 795, Loss: 1227.32080078125, Neurons: 18, Grad norm: 1.067e+02\n",
      "Epoch 796, Loss: 1226.74365234375, Neurons: 18, Grad norm: 1.062e+02\n",
      "Epoch 796, Loss: 1226.74365234375, Neurons: 18, Grad norm: 1.062e+02\n",
      "Epoch 797, Loss: 1226.1693115234375, Neurons: 18, Grad norm: 1.056e+02\n",
      "Epoch 797, Loss: 1226.1693115234375, Neurons: 18, Grad norm: 1.056e+02\n",
      "Epoch 798, Loss: 1225.5970458984375, Neurons: 18, Grad norm: 1.051e+02\n",
      "Epoch 798, Loss: 1225.5970458984375, Neurons: 18, Grad norm: 1.051e+02\n",
      "Epoch 799, Loss: 1225.0274658203125, Neurons: 18, Grad norm: 1.046e+02\n",
      "Epoch 799, Loss: 1225.0274658203125, Neurons: 18, Grad norm: 1.046e+02\n",
      "Epoch 799, Test loss: 1244.0577392578125\n",
      "Epoch 799, Test loss: 1244.0577392578125\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "network shape updated to :[9, 9, 1]\n",
      "network shape updated to :[9, 9, 1]\n",
      "Epoch 800, Loss: 1224.8380126953125, Neurons: 19, Grad norm: 1.044e+02\n",
      "Epoch 800, Loss: 1224.8380126953125, Neurons: 19, Grad norm: 1.044e+02\n",
      "Epoch 801, Loss: 1224.6600341796875, Neurons: 19, Grad norm: 1.041e+02\n",
      "Epoch 801, Loss: 1224.6600341796875, Neurons: 19, Grad norm: 1.041e+02\n",
      "Epoch 802, Loss: 1224.4736328125, Neurons: 19, Grad norm: 1.039e+02\n",
      "Epoch 802, Loss: 1224.4736328125, Neurons: 19, Grad norm: 1.039e+02\n",
      "Epoch 803, Loss: 1224.279052734375, Neurons: 19, Grad norm: 1.036e+02\n",
      "Epoch 803, Loss: 1224.279052734375, Neurons: 19, Grad norm: 1.036e+02\n",
      "Epoch 804, Loss: 1224.0758056640625, Neurons: 19, Grad norm: 1.033e+02\n",
      "Epoch 804, Loss: 1224.0758056640625, Neurons: 19, Grad norm: 1.033e+02\n",
      "Epoch 805, Loss: 1223.8642578125, Neurons: 19, Grad norm: 1.031e+02\n",
      "Epoch 805, Loss: 1223.8642578125, Neurons: 19, Grad norm: 1.031e+02\n",
      "Epoch 806, Loss: 1223.644775390625, Neurons: 19, Grad norm: 1.028e+02\n",
      "Epoch 806, Loss: 1223.644775390625, Neurons: 19, Grad norm: 1.028e+02\n",
      "Epoch 807, Loss: 1223.417236328125, Neurons: 19, Grad norm: 1.025e+02\n",
      "Epoch 807, Loss: 1223.417236328125, Neurons: 19, Grad norm: 1.025e+02\n",
      "Epoch 808, Loss: 1223.1817626953125, Neurons: 19, Grad norm: 1.022e+02\n",
      "Epoch 808, Loss: 1223.1817626953125, Neurons: 19, Grad norm: 1.022e+02\n",
      "Epoch 809, Loss: 1222.9388427734375, Neurons: 19, Grad norm: 1.019e+02\n",
      "Epoch 809, Loss: 1222.9388427734375, Neurons: 19, Grad norm: 1.019e+02\n",
      "Epoch 810, Loss: 1222.6883544921875, Neurons: 19, Grad norm: 1.016e+02\n",
      "Epoch 810, Loss: 1222.6883544921875, Neurons: 19, Grad norm: 1.016e+02\n",
      "Epoch 811, Loss: 1222.4307861328125, Neurons: 19, Grad norm: 1.012e+02\n",
      "Epoch 811, Loss: 1222.4307861328125, Neurons: 19, Grad norm: 1.012e+02\n",
      "Epoch 812, Loss: 1222.166259765625, Neurons: 19, Grad norm: 1.009e+02\n",
      "Epoch 812, Loss: 1222.166259765625, Neurons: 19, Grad norm: 1.009e+02\n",
      "Epoch 813, Loss: 1221.895263671875, Neurons: 19, Grad norm: 1.006e+02\n",
      "Epoch 813, Loss: 1221.895263671875, Neurons: 19, Grad norm: 1.006e+02\n",
      "Epoch 814, Loss: 1221.6180419921875, Neurons: 19, Grad norm: 1.002e+02\n",
      "Epoch 814, Loss: 1221.6180419921875, Neurons: 19, Grad norm: 1.002e+02\n",
      "Epoch 815, Loss: 1221.3348388671875, Neurons: 19, Grad norm: 9.987e+01\n",
      "Epoch 815, Loss: 1221.3348388671875, Neurons: 19, Grad norm: 9.987e+01\n",
      "Epoch 816, Loss: 1221.0458984375, Neurons: 19, Grad norm: 9.952e+01\n",
      "Epoch 816, Loss: 1221.0458984375, Neurons: 19, Grad norm: 9.952e+01\n",
      "Epoch 817, Loss: 1220.751708984375, Neurons: 19, Grad norm: 9.917e+01\n",
      "Epoch 817, Loss: 1220.751708984375, Neurons: 19, Grad norm: 9.917e+01\n",
      "Epoch 818, Loss: 1220.452392578125, Neurons: 19, Grad norm: 9.881e+01\n",
      "Epoch 818, Loss: 1220.452392578125, Neurons: 19, Grad norm: 9.881e+01\n",
      "Epoch 819, Loss: 1220.1483154296875, Neurons: 19, Grad norm: 9.846e+01\n",
      "Epoch 819, Loss: 1220.1483154296875, Neurons: 19, Grad norm: 9.846e+01\n",
      "Epoch 820, Loss: 1219.8399658203125, Neurons: 19, Grad norm: 9.810e+01\n",
      "Epoch 820, Loss: 1219.8399658203125, Neurons: 19, Grad norm: 9.810e+01\n",
      "Epoch 821, Loss: 1219.5274658203125, Neurons: 19, Grad norm: 9.774e+01\n",
      "Epoch 821, Loss: 1219.5274658203125, Neurons: 19, Grad norm: 9.774e+01\n",
      "Epoch 822, Loss: 1219.2109375, Neurons: 19, Grad norm: 9.739e+01\n",
      "Epoch 822, Loss: 1219.2109375, Neurons: 19, Grad norm: 9.739e+01\n",
      "Epoch 823, Loss: 1218.8909912109375, Neurons: 19, Grad norm: 9.703e+01\n",
      "Epoch 823, Loss: 1218.8909912109375, Neurons: 19, Grad norm: 9.703e+01\n",
      "Epoch 824, Loss: 1218.5675048828125, Neurons: 19, Grad norm: 9.668e+01\n",
      "Epoch 824, Loss: 1218.5675048828125, Neurons: 19, Grad norm: 9.668e+01\n",
      "Epoch 825, Loss: 1218.2410888671875, Neurons: 19, Grad norm: 9.632e+01\n",
      "Epoch 825, Loss: 1218.2410888671875, Neurons: 19, Grad norm: 9.632e+01\n",
      "Epoch 826, Loss: 1217.9114990234375, Neurons: 19, Grad norm: 9.597e+01\n",
      "Epoch 826, Loss: 1217.9114990234375, Neurons: 19, Grad norm: 9.597e+01\n",
      "Epoch 827, Loss: 1217.5794677734375, Neurons: 19, Grad norm: 9.562e+01\n",
      "Epoch 827, Loss: 1217.5794677734375, Neurons: 19, Grad norm: 9.562e+01\n",
      "Epoch 828, Loss: 1217.2447509765625, Neurons: 19, Grad norm: 9.528e+01\n",
      "Epoch 828, Loss: 1217.2447509765625, Neurons: 19, Grad norm: 9.528e+01\n",
      "Epoch 829, Loss: 1216.907958984375, Neurons: 19, Grad norm: 9.493e+01\n",
      "Epoch 829, Loss: 1216.907958984375, Neurons: 19, Grad norm: 9.493e+01\n",
      "Epoch 830, Loss: 1216.56884765625, Neurons: 19, Grad norm: 9.459e+01\n",
      "Epoch 830, Loss: 1216.56884765625, Neurons: 19, Grad norm: 9.459e+01\n",
      "Epoch 831, Loss: 1216.2276611328125, Neurons: 19, Grad norm: 9.425e+01\n",
      "Epoch 831, Loss: 1216.2276611328125, Neurons: 19, Grad norm: 9.425e+01\n",
      "Epoch 832, Loss: 1215.884521484375, Neurons: 19, Grad norm: 9.392e+01\n",
      "Epoch 832, Loss: 1215.884521484375, Neurons: 19, Grad norm: 9.392e+01\n",
      "Epoch 833, Loss: 1215.539794921875, Neurons: 19, Grad norm: 9.359e+01\n",
      "Epoch 833, Loss: 1215.539794921875, Neurons: 19, Grad norm: 9.359e+01\n",
      "Epoch 834, Loss: 1215.1934814453125, Neurons: 19, Grad norm: 9.327e+01\n",
      "Epoch 834, Loss: 1215.1934814453125, Neurons: 19, Grad norm: 9.327e+01\n",
      "Epoch 835, Loss: 1214.8455810546875, Neurons: 19, Grad norm: 9.294e+01\n",
      "Epoch 835, Loss: 1214.8455810546875, Neurons: 19, Grad norm: 9.294e+01\n",
      "Epoch 836, Loss: 1214.49609375, Neurons: 19, Grad norm: 9.263e+01\n",
      "Epoch 836, Loss: 1214.49609375, Neurons: 19, Grad norm: 9.263e+01\n",
      "Epoch 837, Loss: 1214.145263671875, Neurons: 19, Grad norm: 9.231e+01\n",
      "Epoch 837, Loss: 1214.145263671875, Neurons: 19, Grad norm: 9.231e+01\n",
      "Epoch 838, Loss: 1213.793212890625, Neurons: 19, Grad norm: 9.200e+01\n",
      "Epoch 838, Loss: 1213.793212890625, Neurons: 19, Grad norm: 9.200e+01\n",
      "Epoch 839, Loss: 1213.4398193359375, Neurons: 19, Grad norm: 9.169e+01\n",
      "Epoch 839, Loss: 1213.4398193359375, Neurons: 19, Grad norm: 9.169e+01\n",
      "Epoch 840, Loss: 1213.085205078125, Neurons: 19, Grad norm: 9.139e+01\n",
      "Epoch 840, Loss: 1213.085205078125, Neurons: 19, Grad norm: 9.139e+01\n",
      "Epoch 841, Loss: 1212.7296142578125, Neurons: 19, Grad norm: 9.109e+01\n",
      "Epoch 841, Loss: 1212.7296142578125, Neurons: 19, Grad norm: 9.109e+01\n",
      "Epoch 842, Loss: 1212.37255859375, Neurons: 19, Grad norm: 9.080e+01\n",
      "Epoch 842, Loss: 1212.37255859375, Neurons: 19, Grad norm: 9.080e+01\n",
      "Epoch 843, Loss: 1212.0146484375, Neurons: 19, Grad norm: 9.051e+01\n",
      "Epoch 843, Loss: 1212.0146484375, Neurons: 19, Grad norm: 9.051e+01\n",
      "Epoch 844, Loss: 1211.655517578125, Neurons: 19, Grad norm: 9.022e+01\n",
      "Epoch 844, Loss: 1211.655517578125, Neurons: 19, Grad norm: 9.022e+01\n",
      "Epoch 845, Loss: 1211.2955322265625, Neurons: 19, Grad norm: 8.993e+01\n",
      "Epoch 845, Loss: 1211.2955322265625, Neurons: 19, Grad norm: 8.993e+01\n",
      "Epoch 846, Loss: 1210.9345703125, Neurons: 19, Grad norm: 8.965e+01\n",
      "Epoch 846, Loss: 1210.9345703125, Neurons: 19, Grad norm: 8.965e+01\n",
      "Epoch 847, Loss: 1210.5723876953125, Neurons: 19, Grad norm: 8.937e+01\n",
      "Epoch 847, Loss: 1210.5723876953125, Neurons: 19, Grad norm: 8.937e+01\n",
      "Epoch 848, Loss: 1210.2093505859375, Neurons: 19, Grad norm: 8.910e+01\n",
      "Epoch 848, Loss: 1210.2093505859375, Neurons: 19, Grad norm: 8.910e+01\n",
      "Epoch 849, Loss: 1209.8453369140625, Neurons: 19, Grad norm: 8.883e+01\n",
      "Epoch 849, Loss: 1209.8453369140625, Neurons: 19, Grad norm: 8.883e+01\n",
      "Epoch 850, Loss: 1209.4801025390625, Neurons: 19, Grad norm: 8.856e+01\n",
      "Epoch 850, Loss: 1209.4801025390625, Neurons: 19, Grad norm: 8.856e+01\n",
      "Epoch 851, Loss: 1209.114013671875, Neurons: 19, Grad norm: 8.829e+01\n",
      "Epoch 851, Loss: 1209.114013671875, Neurons: 19, Grad norm: 8.829e+01\n",
      "Epoch 852, Loss: 1208.7470703125, Neurons: 19, Grad norm: 8.803e+01\n",
      "Epoch 852, Loss: 1208.7470703125, Neurons: 19, Grad norm: 8.803e+01\n",
      "Epoch 853, Loss: 1208.3790283203125, Neurons: 19, Grad norm: 8.777e+01\n",
      "Epoch 853, Loss: 1208.3790283203125, Neurons: 19, Grad norm: 8.777e+01\n",
      "Epoch 854, Loss: 1208.0101318359375, Neurons: 19, Grad norm: 8.751e+01\n",
      "Epoch 854, Loss: 1208.0101318359375, Neurons: 19, Grad norm: 8.751e+01\n",
      "Epoch 855, Loss: 1207.6402587890625, Neurons: 19, Grad norm: 8.725e+01\n",
      "Epoch 855, Loss: 1207.6402587890625, Neurons: 19, Grad norm: 8.725e+01\n",
      "Epoch 856, Loss: 1207.269287109375, Neurons: 19, Grad norm: 8.700e+01\n",
      "Epoch 856, Loss: 1207.269287109375, Neurons: 19, Grad norm: 8.700e+01\n",
      "Epoch 857, Loss: 1206.8974609375, Neurons: 19, Grad norm: 8.674e+01\n",
      "Epoch 857, Loss: 1206.8974609375, Neurons: 19, Grad norm: 8.674e+01\n",
      "Epoch 858, Loss: 1206.5245361328125, Neurons: 19, Grad norm: 8.649e+01\n",
      "Epoch 858, Loss: 1206.5245361328125, Neurons: 19, Grad norm: 8.649e+01\n",
      "Epoch 859, Loss: 1206.150634765625, Neurons: 19, Grad norm: 8.624e+01\n",
      "Epoch 859, Loss: 1206.150634765625, Neurons: 19, Grad norm: 8.624e+01\n",
      "Epoch 860, Loss: 1205.7757568359375, Neurons: 19, Grad norm: 8.600e+01\n",
      "Epoch 860, Loss: 1205.7757568359375, Neurons: 19, Grad norm: 8.600e+01\n",
      "Epoch 861, Loss: 1205.3997802734375, Neurons: 19, Grad norm: 8.575e+01\n",
      "Epoch 861, Loss: 1205.3997802734375, Neurons: 19, Grad norm: 8.575e+01\n",
      "Epoch 862, Loss: 1205.0230712890625, Neurons: 19, Grad norm: 8.551e+01\n",
      "Epoch 862, Loss: 1205.0230712890625, Neurons: 19, Grad norm: 8.551e+01\n",
      "Epoch 863, Loss: 1204.6451416015625, Neurons: 19, Grad norm: 8.526e+01\n",
      "Epoch 863, Loss: 1204.6451416015625, Neurons: 19, Grad norm: 8.526e+01\n",
      "Epoch 864, Loss: 1204.266357421875, Neurons: 19, Grad norm: 8.502e+01\n",
      "Epoch 864, Loss: 1204.266357421875, Neurons: 19, Grad norm: 8.502e+01\n",
      "Epoch 865, Loss: 1203.8863525390625, Neurons: 19, Grad norm: 8.478e+01\n",
      "Epoch 865, Loss: 1203.8863525390625, Neurons: 19, Grad norm: 8.478e+01\n",
      "Epoch 866, Loss: 1203.505615234375, Neurons: 19, Grad norm: 8.454e+01\n",
      "Epoch 866, Loss: 1203.505615234375, Neurons: 19, Grad norm: 8.454e+01\n",
      "Epoch 867, Loss: 1203.1236572265625, Neurons: 19, Grad norm: 8.430e+01\n",
      "Epoch 867, Loss: 1203.1236572265625, Neurons: 19, Grad norm: 8.430e+01\n",
      "Epoch 868, Loss: 1202.74072265625, Neurons: 19, Grad norm: 8.406e+01\n",
      "Epoch 868, Loss: 1202.74072265625, Neurons: 19, Grad norm: 8.406e+01\n",
      "Epoch 869, Loss: 1202.3568115234375, Neurons: 19, Grad norm: 8.382e+01\n",
      "Epoch 869, Loss: 1202.3568115234375, Neurons: 19, Grad norm: 8.382e+01\n",
      "Epoch 870, Loss: 1201.9718017578125, Neurons: 19, Grad norm: 8.358e+01\n",
      "Epoch 870, Loss: 1201.9718017578125, Neurons: 19, Grad norm: 8.358e+01\n",
      "Epoch 871, Loss: 1201.5858154296875, Neurons: 19, Grad norm: 8.335e+01\n",
      "Epoch 871, Loss: 1201.5858154296875, Neurons: 19, Grad norm: 8.335e+01\n",
      "Epoch 872, Loss: 1201.1988525390625, Neurons: 19, Grad norm: 8.311e+01\n",
      "Epoch 872, Loss: 1201.1988525390625, Neurons: 19, Grad norm: 8.311e+01\n",
      "Epoch 873, Loss: 1200.810546875, Neurons: 19, Grad norm: 8.288e+01\n",
      "Epoch 873, Loss: 1200.810546875, Neurons: 19, Grad norm: 8.288e+01\n",
      "Epoch 874, Loss: 1200.4215087890625, Neurons: 19, Grad norm: 8.264e+01\n",
      "Epoch 874, Loss: 1200.4215087890625, Neurons: 19, Grad norm: 8.264e+01\n",
      "Epoch 875, Loss: 1200.0313720703125, Neurons: 19, Grad norm: 8.240e+01\n",
      "Epoch 875, Loss: 1200.0313720703125, Neurons: 19, Grad norm: 8.240e+01\n",
      "Epoch 876, Loss: 1199.64013671875, Neurons: 19, Grad norm: 8.217e+01\n",
      "Epoch 876, Loss: 1199.64013671875, Neurons: 19, Grad norm: 8.217e+01\n",
      "Epoch 877, Loss: 1199.2479248046875, Neurons: 19, Grad norm: 8.194e+01\n",
      "Epoch 877, Loss: 1199.2479248046875, Neurons: 19, Grad norm: 8.194e+01\n",
      "Epoch 878, Loss: 1198.8548583984375, Neurons: 19, Grad norm: 8.170e+01\n",
      "Epoch 878, Loss: 1198.8548583984375, Neurons: 19, Grad norm: 8.170e+01\n",
      "Epoch 879, Loss: 1198.46044921875, Neurons: 19, Grad norm: 8.147e+01\n",
      "Epoch 879, Loss: 1198.46044921875, Neurons: 19, Grad norm: 8.147e+01\n",
      "Epoch 880, Loss: 1198.0650634765625, Neurons: 19, Grad norm: 8.123e+01\n",
      "Epoch 880, Loss: 1198.0650634765625, Neurons: 19, Grad norm: 8.123e+01\n",
      "Epoch 881, Loss: 1197.668701171875, Neurons: 19, Grad norm: 8.100e+01\n",
      "Epoch 881, Loss: 1197.668701171875, Neurons: 19, Grad norm: 8.100e+01\n",
      "Epoch 882, Loss: 1197.27099609375, Neurons: 19, Grad norm: 8.076e+01\n",
      "Epoch 882, Loss: 1197.27099609375, Neurons: 19, Grad norm: 8.076e+01\n",
      "Epoch 883, Loss: 1196.87255859375, Neurons: 19, Grad norm: 8.053e+01\n",
      "Epoch 883, Loss: 1196.87255859375, Neurons: 19, Grad norm: 8.053e+01\n",
      "Epoch 884, Loss: 1196.4730224609375, Neurons: 19, Grad norm: 8.029e+01\n",
      "Epoch 884, Loss: 1196.4730224609375, Neurons: 19, Grad norm: 8.029e+01\n",
      "Epoch 885, Loss: 1196.072265625, Neurons: 19, Grad norm: 8.006e+01\n",
      "Epoch 885, Loss: 1196.072265625, Neurons: 19, Grad norm: 8.006e+01\n",
      "Epoch 886, Loss: 1195.6705322265625, Neurons: 19, Grad norm: 7.982e+01\n",
      "Epoch 886, Loss: 1195.6705322265625, Neurons: 19, Grad norm: 7.982e+01\n",
      "Epoch 887, Loss: 1195.267822265625, Neurons: 19, Grad norm: 7.959e+01\n",
      "Epoch 887, Loss: 1195.267822265625, Neurons: 19, Grad norm: 7.959e+01\n",
      "Epoch 888, Loss: 1194.86376953125, Neurons: 19, Grad norm: 7.935e+01\n",
      "Epoch 888, Loss: 1194.86376953125, Neurons: 19, Grad norm: 7.935e+01\n",
      "Epoch 889, Loss: 1194.4588623046875, Neurons: 19, Grad norm: 7.912e+01\n",
      "Epoch 889, Loss: 1194.4588623046875, Neurons: 19, Grad norm: 7.912e+01\n",
      "Epoch 890, Loss: 1194.052734375, Neurons: 19, Grad norm: 7.888e+01\n",
      "Epoch 890, Loss: 1194.052734375, Neurons: 19, Grad norm: 7.888e+01\n",
      "Epoch 891, Loss: 1193.6455078125, Neurons: 19, Grad norm: 7.865e+01\n",
      "Epoch 891, Loss: 1193.6455078125, Neurons: 19, Grad norm: 7.865e+01\n",
      "Epoch 892, Loss: 1193.237060546875, Neurons: 19, Grad norm: 7.841e+01\n",
      "Epoch 892, Loss: 1193.237060546875, Neurons: 19, Grad norm: 7.841e+01\n",
      "Epoch 893, Loss: 1192.82763671875, Neurons: 19, Grad norm: 7.818e+01\n",
      "Epoch 893, Loss: 1192.82763671875, Neurons: 19, Grad norm: 7.818e+01\n",
      "Epoch 894, Loss: 1192.4171142578125, Neurons: 19, Grad norm: 7.794e+01\n",
      "Epoch 894, Loss: 1192.4171142578125, Neurons: 19, Grad norm: 7.794e+01\n",
      "Epoch 895, Loss: 1192.0052490234375, Neurons: 19, Grad norm: 7.771e+01\n",
      "Epoch 895, Loss: 1192.0052490234375, Neurons: 19, Grad norm: 7.771e+01\n",
      "Epoch 896, Loss: 1191.59228515625, Neurons: 19, Grad norm: 7.748e+01\n",
      "Epoch 896, Loss: 1191.59228515625, Neurons: 19, Grad norm: 7.748e+01\n",
      "Epoch 897, Loss: 1191.1783447265625, Neurons: 19, Grad norm: 7.724e+01\n",
      "Epoch 897, Loss: 1191.1783447265625, Neurons: 19, Grad norm: 7.724e+01\n",
      "Epoch 898, Loss: 1190.7630615234375, Neurons: 19, Grad norm: 7.701e+01\n",
      "Epoch 898, Loss: 1190.7630615234375, Neurons: 19, Grad norm: 7.701e+01\n",
      "Epoch 899, Loss: 1190.3466796875, Neurons: 19, Grad norm: 7.677e+01\n",
      "Epoch 899, Loss: 1190.3466796875, Neurons: 19, Grad norm: 7.677e+01\n",
      "Epoch 899, Test loss: 1207.3724365234375\n",
      "Epoch 899, Test loss: 1207.3724365234375\n",
      "Added neuron to hidden layer 1 with activation tanh\n",
      "Added neuron to hidden layer 1 with activation tanh\n",
      "network shape updated to :[10, 9, 1]\n",
      "network shape updated to :[10, 9, 1]\n",
      "Epoch 900, Loss: 1190.07421875, Neurons: 20, Grad norm: 7.700e+01\n",
      "Epoch 900, Loss: 1190.07421875, Neurons: 20, Grad norm: 7.700e+01\n",
      "Epoch 901, Loss: 1189.9598388671875, Neurons: 20, Grad norm: 7.689e+01\n",
      "Epoch 901, Loss: 1189.9598388671875, Neurons: 20, Grad norm: 7.689e+01\n",
      "Epoch 902, Loss: 1189.83984375, Neurons: 20, Grad norm: 7.678e+01\n",
      "Epoch 902, Loss: 1189.83984375, Neurons: 20, Grad norm: 7.678e+01\n",
      "Epoch 903, Loss: 1189.714111328125, Neurons: 20, Grad norm: 7.666e+01\n",
      "Epoch 903, Loss: 1189.714111328125, Neurons: 20, Grad norm: 7.666e+01\n",
      "Epoch 904, Loss: 1189.58251953125, Neurons: 20, Grad norm: 7.654e+01\n",
      "Epoch 904, Loss: 1189.58251953125, Neurons: 20, Grad norm: 7.654e+01\n",
      "Epoch 905, Loss: 1189.445556640625, Neurons: 20, Grad norm: 7.641e+01\n",
      "Epoch 905, Loss: 1189.445556640625, Neurons: 20, Grad norm: 7.641e+01\n",
      "Epoch 906, Loss: 1189.3028564453125, Neurons: 20, Grad norm: 7.628e+01\n",
      "Epoch 906, Loss: 1189.3028564453125, Neurons: 20, Grad norm: 7.628e+01\n",
      "Epoch 907, Loss: 1189.1544189453125, Neurons: 20, Grad norm: 7.614e+01\n",
      "Epoch 907, Loss: 1189.1544189453125, Neurons: 20, Grad norm: 7.614e+01\n",
      "Epoch 908, Loss: 1189.0006103515625, Neurons: 20, Grad norm: 7.600e+01\n",
      "Epoch 908, Loss: 1189.0006103515625, Neurons: 20, Grad norm: 7.600e+01\n",
      "Epoch 909, Loss: 1188.841064453125, Neurons: 20, Grad norm: 7.585e+01\n",
      "Epoch 909, Loss: 1188.841064453125, Neurons: 20, Grad norm: 7.585e+01\n",
      "Epoch 910, Loss: 1188.67626953125, Neurons: 20, Grad norm: 7.570e+01\n",
      "Epoch 910, Loss: 1188.67626953125, Neurons: 20, Grad norm: 7.570e+01\n",
      "Epoch 911, Loss: 1188.506103515625, Neurons: 20, Grad norm: 7.554e+01\n",
      "Epoch 911, Loss: 1188.506103515625, Neurons: 20, Grad norm: 7.554e+01\n",
      "Epoch 912, Loss: 1188.330810546875, Neurons: 20, Grad norm: 7.538e+01\n",
      "Epoch 912, Loss: 1188.330810546875, Neurons: 20, Grad norm: 7.538e+01\n",
      "Epoch 913, Loss: 1188.1502685546875, Neurons: 20, Grad norm: 7.522e+01\n",
      "Epoch 913, Loss: 1188.1502685546875, Neurons: 20, Grad norm: 7.522e+01\n",
      "Epoch 914, Loss: 1187.96484375, Neurons: 20, Grad norm: 7.505e+01\n",
      "Epoch 914, Loss: 1187.96484375, Neurons: 20, Grad norm: 7.505e+01\n",
      "Epoch 915, Loss: 1187.7745361328125, Neurons: 20, Grad norm: 7.488e+01\n",
      "Epoch 915, Loss: 1187.7745361328125, Neurons: 20, Grad norm: 7.488e+01\n",
      "Epoch 916, Loss: 1187.5794677734375, Neurons: 20, Grad norm: 7.470e+01\n",
      "Epoch 916, Loss: 1187.5794677734375, Neurons: 20, Grad norm: 7.470e+01\n",
      "Epoch 917, Loss: 1187.379638671875, Neurons: 20, Grad norm: 7.452e+01\n",
      "Epoch 917, Loss: 1187.379638671875, Neurons: 20, Grad norm: 7.452e+01\n",
      "Epoch 918, Loss: 1187.17529296875, Neurons: 20, Grad norm: 7.434e+01\n",
      "Epoch 918, Loss: 1187.17529296875, Neurons: 20, Grad norm: 7.434e+01\n",
      "Epoch 919, Loss: 1186.9666748046875, Neurons: 20, Grad norm: 7.416e+01\n",
      "Epoch 919, Loss: 1186.9666748046875, Neurons: 20, Grad norm: 7.416e+01\n",
      "Epoch 920, Loss: 1186.753662109375, Neurons: 20, Grad norm: 7.397e+01\n",
      "Epoch 920, Loss: 1186.753662109375, Neurons: 20, Grad norm: 7.397e+01\n",
      "Epoch 921, Loss: 1186.536376953125, Neurons: 20, Grad norm: 7.378e+01\n",
      "Epoch 921, Loss: 1186.536376953125, Neurons: 20, Grad norm: 7.378e+01\n",
      "Epoch 922, Loss: 1186.315185546875, Neurons: 20, Grad norm: 7.359e+01\n",
      "Epoch 922, Loss: 1186.315185546875, Neurons: 20, Grad norm: 7.359e+01\n",
      "Epoch 923, Loss: 1186.090087890625, Neurons: 20, Grad norm: 7.340e+01\n",
      "Epoch 923, Loss: 1186.090087890625, Neurons: 20, Grad norm: 7.340e+01\n",
      "Epoch 924, Loss: 1185.861083984375, Neurons: 20, Grad norm: 7.320e+01\n",
      "Epoch 924, Loss: 1185.861083984375, Neurons: 20, Grad norm: 7.320e+01\n",
      "Epoch 925, Loss: 1185.6282958984375, Neurons: 20, Grad norm: 7.300e+01\n",
      "Epoch 925, Loss: 1185.6282958984375, Neurons: 20, Grad norm: 7.300e+01\n",
      "Epoch 926, Loss: 1185.391845703125, Neurons: 20, Grad norm: 7.281e+01\n",
      "Epoch 926, Loss: 1185.391845703125, Neurons: 20, Grad norm: 7.281e+01\n",
      "Epoch 927, Loss: 1185.1517333984375, Neurons: 20, Grad norm: 7.261e+01\n",
      "Epoch 927, Loss: 1185.1517333984375, Neurons: 20, Grad norm: 7.261e+01\n",
      "Epoch 928, Loss: 1184.908203125, Neurons: 20, Grad norm: 7.241e+01\n",
      "Epoch 928, Loss: 1184.908203125, Neurons: 20, Grad norm: 7.241e+01\n",
      "Epoch 929, Loss: 1184.6612548828125, Neurons: 20, Grad norm: 7.221e+01\n",
      "Epoch 929, Loss: 1184.6612548828125, Neurons: 20, Grad norm: 7.221e+01\n",
      "Epoch 930, Loss: 1184.4110107421875, Neurons: 20, Grad norm: 7.200e+01\n",
      "Epoch 930, Loss: 1184.4110107421875, Neurons: 20, Grad norm: 7.200e+01\n",
      "Epoch 931, Loss: 1184.1575927734375, Neurons: 20, Grad norm: 7.180e+01\n",
      "Epoch 931, Loss: 1184.1575927734375, Neurons: 20, Grad norm: 7.180e+01\n",
      "Epoch 932, Loss: 1183.9010009765625, Neurons: 20, Grad norm: 7.160e+01\n",
      "Epoch 932, Loss: 1183.9010009765625, Neurons: 20, Grad norm: 7.160e+01\n",
      "Epoch 933, Loss: 1183.641357421875, Neurons: 20, Grad norm: 7.139e+01\n",
      "Epoch 933, Loss: 1183.641357421875, Neurons: 20, Grad norm: 7.139e+01\n",
      "Epoch 934, Loss: 1183.3787841796875, Neurons: 20, Grad norm: 7.119e+01\n",
      "Epoch 934, Loss: 1183.3787841796875, Neurons: 20, Grad norm: 7.119e+01\n",
      "Epoch 935, Loss: 1183.113037109375, Neurons: 20, Grad norm: 7.099e+01\n",
      "Epoch 935, Loss: 1183.113037109375, Neurons: 20, Grad norm: 7.099e+01\n",
      "Epoch 936, Loss: 1182.844482421875, Neurons: 20, Grad norm: 7.078e+01\n",
      "Epoch 936, Loss: 1182.844482421875, Neurons: 20, Grad norm: 7.078e+01\n",
      "Epoch 937, Loss: 1182.572998046875, Neurons: 20, Grad norm: 7.058e+01\n",
      "Epoch 937, Loss: 1182.572998046875, Neurons: 20, Grad norm: 7.058e+01\n",
      "Epoch 938, Loss: 1182.298828125, Neurons: 20, Grad norm: 7.037e+01\n",
      "Epoch 938, Loss: 1182.298828125, Neurons: 20, Grad norm: 7.037e+01\n",
      "Epoch 939, Loss: 1182.0218505859375, Neurons: 20, Grad norm: 6.974e+01\n",
      "Epoch 939, Loss: 1182.0218505859375, Neurons: 20, Grad norm: 6.974e+01\n",
      "Epoch 940, Loss: 1181.7535400390625, Neurons: 20, Grad norm: 6.953e+01\n",
      "Epoch 940, Loss: 1181.7535400390625, Neurons: 20, Grad norm: 6.953e+01\n",
      "Epoch 941, Loss: 1181.4903564453125, Neurons: 20, Grad norm: 6.932e+01\n",
      "Epoch 941, Loss: 1181.4903564453125, Neurons: 20, Grad norm: 6.932e+01\n",
      "Epoch 942, Loss: 1181.2239990234375, Neurons: 20, Grad norm: 6.910e+01\n",
      "Epoch 942, Loss: 1181.2239990234375, Neurons: 20, Grad norm: 6.910e+01\n",
      "Epoch 943, Loss: 1180.955810546875, Neurons: 20, Grad norm: 6.889e+01\n",
      "Epoch 943, Loss: 1180.955810546875, Neurons: 20, Grad norm: 6.889e+01\n",
      "Epoch 944, Loss: 1180.685791015625, Neurons: 20, Grad norm: 6.868e+01\n",
      "Epoch 944, Loss: 1180.685791015625, Neurons: 20, Grad norm: 6.868e+01\n",
      "Epoch 945, Loss: 1180.413818359375, Neurons: 20, Grad norm: 6.847e+01\n",
      "Epoch 945, Loss: 1180.413818359375, Neurons: 20, Grad norm: 6.847e+01\n",
      "Epoch 946, Loss: 1180.1400146484375, Neurons: 20, Grad norm: 6.826e+01\n",
      "Epoch 946, Loss: 1180.1400146484375, Neurons: 20, Grad norm: 6.826e+01\n",
      "Epoch 947, Loss: 1179.8642578125, Neurons: 20, Grad norm: 6.805e+01\n",
      "Epoch 947, Loss: 1179.8642578125, Neurons: 20, Grad norm: 6.805e+01\n",
      "Epoch 948, Loss: 1179.5867919921875, Neurons: 20, Grad norm: 6.784e+01\n",
      "Epoch 948, Loss: 1179.5867919921875, Neurons: 20, Grad norm: 6.784e+01\n",
      "Epoch 949, Loss: 1179.307373046875, Neurons: 20, Grad norm: 6.764e+01\n",
      "Epoch 949, Loss: 1179.307373046875, Neurons: 20, Grad norm: 6.764e+01\n",
      "Epoch 950, Loss: 1179.0262451171875, Neurons: 20, Grad norm: 6.743e+01\n",
      "Epoch 950, Loss: 1179.0262451171875, Neurons: 20, Grad norm: 6.743e+01\n",
      "Epoch 951, Loss: 1178.7432861328125, Neurons: 20, Grad norm: 6.723e+01\n",
      "Epoch 951, Loss: 1178.7432861328125, Neurons: 20, Grad norm: 6.723e+01\n",
      "Epoch 952, Loss: 1178.45849609375, Neurons: 20, Grad norm: 6.703e+01\n",
      "Epoch 952, Loss: 1178.45849609375, Neurons: 20, Grad norm: 6.703e+01\n",
      "Epoch 953, Loss: 1178.171875, Neurons: 20, Grad norm: 6.683e+01\n",
      "Epoch 953, Loss: 1178.171875, Neurons: 20, Grad norm: 6.683e+01\n",
      "Epoch 954, Loss: 1177.883544921875, Neurons: 20, Grad norm: 6.663e+01\n",
      "Epoch 954, Loss: 1177.883544921875, Neurons: 20, Grad norm: 6.663e+01\n",
      "Epoch 955, Loss: 1177.59326171875, Neurons: 20, Grad norm: 6.644e+01\n",
      "Epoch 955, Loss: 1177.59326171875, Neurons: 20, Grad norm: 6.644e+01\n",
      "Epoch 956, Loss: 1177.301513671875, Neurons: 20, Grad norm: 6.625e+01\n",
      "Epoch 956, Loss: 1177.301513671875, Neurons: 20, Grad norm: 6.625e+01\n",
      "Epoch 957, Loss: 1177.0078125, Neurons: 20, Grad norm: 6.605e+01\n",
      "Epoch 957, Loss: 1177.0078125, Neurons: 20, Grad norm: 6.605e+01\n",
      "Epoch 958, Loss: 1176.7125244140625, Neurons: 20, Grad norm: 6.587e+01\n",
      "Epoch 958, Loss: 1176.7125244140625, Neurons: 20, Grad norm: 6.587e+01\n",
      "Epoch 959, Loss: 1176.4154052734375, Neurons: 20, Grad norm: 6.568e+01\n",
      "Epoch 959, Loss: 1176.4154052734375, Neurons: 20, Grad norm: 6.568e+01\n",
      "Epoch 960, Loss: 1176.1165771484375, Neurons: 20, Grad norm: 6.550e+01\n",
      "Epoch 960, Loss: 1176.1165771484375, Neurons: 20, Grad norm: 6.550e+01\n",
      "Epoch 961, Loss: 1175.8157958984375, Neurons: 20, Grad norm: 6.532e+01\n",
      "Epoch 961, Loss: 1175.8157958984375, Neurons: 20, Grad norm: 6.532e+01\n",
      "Epoch 962, Loss: 1175.513427734375, Neurons: 20, Grad norm: 6.514e+01\n",
      "Epoch 962, Loss: 1175.513427734375, Neurons: 20, Grad norm: 6.514e+01\n",
      "Epoch 963, Loss: 1175.20947265625, Neurons: 20, Grad norm: 6.496e+01\n",
      "Epoch 963, Loss: 1175.20947265625, Neurons: 20, Grad norm: 6.496e+01\n",
      "Epoch 964, Loss: 1174.9036865234375, Neurons: 20, Grad norm: 6.479e+01\n",
      "Epoch 964, Loss: 1174.9036865234375, Neurons: 20, Grad norm: 6.479e+01\n",
      "Epoch 965, Loss: 1174.59619140625, Neurons: 20, Grad norm: 6.462e+01\n",
      "Epoch 965, Loss: 1174.59619140625, Neurons: 20, Grad norm: 6.462e+01\n",
      "Epoch 966, Loss: 1174.287109375, Neurons: 20, Grad norm: 6.445e+01\n",
      "Epoch 966, Loss: 1174.287109375, Neurons: 20, Grad norm: 6.445e+01\n",
      "Epoch 967, Loss: 1173.9761962890625, Neurons: 20, Grad norm: 6.428e+01\n",
      "Epoch 967, Loss: 1173.9761962890625, Neurons: 20, Grad norm: 6.428e+01\n",
      "Epoch 968, Loss: 1173.66357421875, Neurons: 20, Grad norm: 6.412e+01\n",
      "Epoch 968, Loss: 1173.66357421875, Neurons: 20, Grad norm: 6.412e+01\n",
      "Epoch 969, Loss: 1173.349365234375, Neurons: 20, Grad norm: 6.396e+01\n",
      "Epoch 969, Loss: 1173.349365234375, Neurons: 20, Grad norm: 6.396e+01\n",
      "Epoch 970, Loss: 1173.0335693359375, Neurons: 20, Grad norm: 6.380e+01\n",
      "Epoch 970, Loss: 1173.0335693359375, Neurons: 20, Grad norm: 6.380e+01\n",
      "Epoch 971, Loss: 1172.716064453125, Neurons: 20, Grad norm: 6.365e+01\n",
      "Epoch 971, Loss: 1172.716064453125, Neurons: 20, Grad norm: 6.365e+01\n",
      "Epoch 972, Loss: 1172.3970947265625, Neurons: 20, Grad norm: 6.349e+01\n",
      "Epoch 972, Loss: 1172.3970947265625, Neurons: 20, Grad norm: 6.349e+01\n",
      "Epoch 973, Loss: 1172.0762939453125, Neurons: 20, Grad norm: 6.334e+01\n",
      "Epoch 973, Loss: 1172.0762939453125, Neurons: 20, Grad norm: 6.334e+01\n",
      "Epoch 974, Loss: 1171.7540283203125, Neurons: 20, Grad norm: 6.319e+01\n",
      "Epoch 974, Loss: 1171.7540283203125, Neurons: 20, Grad norm: 6.319e+01\n",
      "Epoch 975, Loss: 1171.4302978515625, Neurons: 20, Grad norm: 6.304e+01\n",
      "Epoch 975, Loss: 1171.4302978515625, Neurons: 20, Grad norm: 6.304e+01\n",
      "Epoch 976, Loss: 1171.1051025390625, Neurons: 20, Grad norm: 6.290e+01\n",
      "Epoch 976, Loss: 1171.1051025390625, Neurons: 20, Grad norm: 6.290e+01\n",
      "Epoch 977, Loss: 1170.7784423828125, Neurons: 20, Grad norm: 6.275e+01\n",
      "Epoch 977, Loss: 1170.7784423828125, Neurons: 20, Grad norm: 6.275e+01\n",
      "Epoch 978, Loss: 1170.4500732421875, Neurons: 20, Grad norm: 6.261e+01\n",
      "Epoch 978, Loss: 1170.4500732421875, Neurons: 20, Grad norm: 6.261e+01\n",
      "Epoch 979, Loss: 1170.1204833984375, Neurons: 20, Grad norm: 6.246e+01\n",
      "Epoch 979, Loss: 1170.1204833984375, Neurons: 20, Grad norm: 6.246e+01\n",
      "Epoch 980, Loss: 1169.789306640625, Neurons: 20, Grad norm: 6.232e+01\n",
      "Epoch 980, Loss: 1169.789306640625, Neurons: 20, Grad norm: 6.232e+01\n",
      "Epoch 981, Loss: 1169.456787109375, Neurons: 20, Grad norm: 6.218e+01\n",
      "Epoch 981, Loss: 1169.456787109375, Neurons: 20, Grad norm: 6.218e+01\n",
      "Epoch 982, Loss: 1169.123046875, Neurons: 20, Grad norm: 6.203e+01\n",
      "Epoch 982, Loss: 1169.123046875, Neurons: 20, Grad norm: 6.203e+01\n",
      "Epoch 983, Loss: 1168.7877197265625, Neurons: 20, Grad norm: 6.189e+01\n",
      "Epoch 983, Loss: 1168.7877197265625, Neurons: 20, Grad norm: 6.189e+01\n",
      "Epoch 984, Loss: 1168.4510498046875, Neurons: 20, Grad norm: 6.175e+01\n",
      "Epoch 984, Loss: 1168.4510498046875, Neurons: 20, Grad norm: 6.175e+01\n",
      "Epoch 985, Loss: 1168.113037109375, Neurons: 20, Grad norm: 6.160e+01\n",
      "Epoch 985, Loss: 1168.113037109375, Neurons: 20, Grad norm: 6.160e+01\n",
      "Epoch 986, Loss: 1167.773681640625, Neurons: 20, Grad norm: 6.146e+01\n",
      "Epoch 986, Loss: 1167.773681640625, Neurons: 20, Grad norm: 6.146e+01\n",
      "Epoch 987, Loss: 1167.4329833984375, Neurons: 20, Grad norm: 6.131e+01\n",
      "Epoch 987, Loss: 1167.4329833984375, Neurons: 20, Grad norm: 6.131e+01\n",
      "Epoch 988, Loss: 1167.0906982421875, Neurons: 20, Grad norm: 6.116e+01\n",
      "Epoch 988, Loss: 1167.0906982421875, Neurons: 20, Grad norm: 6.116e+01\n",
      "Epoch 989, Loss: 1166.7471923828125, Neurons: 20, Grad norm: 6.101e+01\n",
      "Epoch 989, Loss: 1166.7471923828125, Neurons: 20, Grad norm: 6.101e+01\n",
      "Epoch 990, Loss: 1166.402099609375, Neurons: 20, Grad norm: 6.086e+01\n",
      "Epoch 990, Loss: 1166.402099609375, Neurons: 20, Grad norm: 6.086e+01\n",
      "Epoch 991, Loss: 1166.0555419921875, Neurons: 20, Grad norm: 6.071e+01\n",
      "Epoch 991, Loss: 1166.0555419921875, Neurons: 20, Grad norm: 6.071e+01\n",
      "Epoch 992, Loss: 1165.70751953125, Neurons: 20, Grad norm: 6.055e+01\n",
      "Epoch 992, Loss: 1165.70751953125, Neurons: 20, Grad norm: 6.055e+01\n",
      "Epoch 993, Loss: 1165.3580322265625, Neurons: 20, Grad norm: 6.040e+01\n",
      "Epoch 993, Loss: 1165.3580322265625, Neurons: 20, Grad norm: 6.040e+01\n",
      "Epoch 994, Loss: 1165.007080078125, Neurons: 20, Grad norm: 6.024e+01\n",
      "Epoch 994, Loss: 1165.007080078125, Neurons: 20, Grad norm: 6.024e+01\n",
      "Epoch 995, Loss: 1164.654296875, Neurons: 20, Grad norm: 6.008e+01\n",
      "Epoch 995, Loss: 1164.654296875, Neurons: 20, Grad norm: 6.008e+01\n",
      "Epoch 996, Loss: 1164.300048828125, Neurons: 20, Grad norm: 5.992e+01\n",
      "Epoch 996, Loss: 1164.300048828125, Neurons: 20, Grad norm: 5.992e+01\n",
      "Epoch 997, Loss: 1163.944091796875, Neurons: 20, Grad norm: 5.976e+01\n",
      "Epoch 997, Loss: 1163.944091796875, Neurons: 20, Grad norm: 5.976e+01\n",
      "Epoch 998, Loss: 1163.5867919921875, Neurons: 20, Grad norm: 5.959e+01\n",
      "Epoch 998, Loss: 1163.5867919921875, Neurons: 20, Grad norm: 5.959e+01\n",
      "Epoch 999, Loss: 1163.2276611328125, Neurons: 20, Grad norm: 5.943e+01\n",
      "Epoch 999, Loss: 1163.2276611328125, Neurons: 20, Grad norm: 5.943e+01\n",
      "Epoch 999, Test loss: 1178.5517578125\n",
      "Epoch 999, Test loss: 1178.5517578125\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "network shape updated to :[10, 10, 1]\n",
      "network shape updated to :[10, 10, 1]\n",
      "Epoch 1000, Loss: 1170.505859375, Neurons: 21, Grad norm: 9.182e+01\n",
      "Epoch 1000, Loss: 1170.505859375, Neurons: 21, Grad norm: 9.182e+01\n",
      "Epoch 1001, Loss: 1170.342041015625, Neurons: 21, Grad norm: 9.174e+01\n",
      "Epoch 1001, Loss: 1170.342041015625, Neurons: 21, Grad norm: 9.174e+01\n",
      "Epoch 1002, Loss: 1170.1702880859375, Neurons: 21, Grad norm: 9.165e+01\n",
      "Epoch 1002, Loss: 1170.1702880859375, Neurons: 21, Grad norm: 9.165e+01\n",
      "Epoch 1003, Loss: 1169.9903564453125, Neurons: 21, Grad norm: 9.156e+01\n",
      "Epoch 1003, Loss: 1169.9903564453125, Neurons: 21, Grad norm: 9.156e+01\n",
      "Epoch 1004, Loss: 1169.802001953125, Neurons: 21, Grad norm: 9.147e+01\n",
      "Epoch 1004, Loss: 1169.802001953125, Neurons: 21, Grad norm: 9.147e+01\n",
      "Epoch 1005, Loss: 1169.6055908203125, Neurons: 21, Grad norm: 9.138e+01\n",
      "Epoch 1005, Loss: 1169.6055908203125, Neurons: 21, Grad norm: 9.138e+01\n",
      "Epoch 1006, Loss: 1169.4010009765625, Neurons: 21, Grad norm: 9.128e+01\n",
      "Epoch 1006, Loss: 1169.4010009765625, Neurons: 21, Grad norm: 9.128e+01\n",
      "Epoch 1007, Loss: 1169.188232421875, Neurons: 21, Grad norm: 9.119e+01\n",
      "Epoch 1007, Loss: 1169.188232421875, Neurons: 21, Grad norm: 9.119e+01\n",
      "Epoch 1008, Loss: 1168.967041015625, Neurons: 21, Grad norm: 9.109e+01\n",
      "Epoch 1008, Loss: 1168.967041015625, Neurons: 21, Grad norm: 9.109e+01\n",
      "Epoch 1009, Loss: 1168.73779296875, Neurons: 21, Grad norm: 9.099e+01\n",
      "Epoch 1009, Loss: 1168.73779296875, Neurons: 21, Grad norm: 9.099e+01\n",
      "Epoch 1010, Loss: 1168.5003662109375, Neurons: 21, Grad norm: 9.088e+01\n",
      "Epoch 1010, Loss: 1168.5003662109375, Neurons: 21, Grad norm: 9.088e+01\n",
      "Epoch 1011, Loss: 1168.2547607421875, Neurons: 21, Grad norm: 9.078e+01\n",
      "Epoch 1011, Loss: 1168.2547607421875, Neurons: 21, Grad norm: 9.078e+01\n",
      "Epoch 1012, Loss: 1168.00146484375, Neurons: 21, Grad norm: 9.066e+01\n",
      "Epoch 1012, Loss: 1168.00146484375, Neurons: 21, Grad norm: 9.066e+01\n",
      "Epoch 1013, Loss: 1167.740234375, Neurons: 21, Grad norm: 9.055e+01\n",
      "Epoch 1013, Loss: 1167.740234375, Neurons: 21, Grad norm: 9.055e+01\n",
      "Epoch 1014, Loss: 1167.47119140625, Neurons: 21, Grad norm: 9.043e+01\n",
      "Epoch 1014, Loss: 1167.47119140625, Neurons: 21, Grad norm: 9.043e+01\n",
      "Epoch 1015, Loss: 1167.1947021484375, Neurons: 21, Grad norm: 9.031e+01\n",
      "Epoch 1015, Loss: 1167.1947021484375, Neurons: 21, Grad norm: 9.031e+01\n",
      "Epoch 1016, Loss: 1166.9107666015625, Neurons: 21, Grad norm: 9.017e+01\n",
      "Epoch 1016, Loss: 1166.9107666015625, Neurons: 21, Grad norm: 9.017e+01\n",
      "Epoch 1017, Loss: 1166.6195068359375, Neurons: 21, Grad norm: 9.004e+01\n",
      "Epoch 1017, Loss: 1166.6195068359375, Neurons: 21, Grad norm: 9.004e+01\n",
      "Epoch 1018, Loss: 1166.3212890625, Neurons: 21, Grad norm: 8.989e+01\n",
      "Epoch 1018, Loss: 1166.3212890625, Neurons: 21, Grad norm: 8.989e+01\n",
      "Epoch 1019, Loss: 1166.01611328125, Neurons: 21, Grad norm: 8.974e+01\n",
      "Epoch 1019, Loss: 1166.01611328125, Neurons: 21, Grad norm: 8.974e+01\n",
      "Epoch 1020, Loss: 1165.7041015625, Neurons: 21, Grad norm: 8.959e+01\n",
      "Epoch 1020, Loss: 1165.7041015625, Neurons: 21, Grad norm: 8.959e+01\n",
      "Epoch 1021, Loss: 1165.385498046875, Neurons: 21, Grad norm: 8.942e+01\n",
      "Epoch 1021, Loss: 1165.385498046875, Neurons: 21, Grad norm: 8.942e+01\n",
      "Epoch 1022, Loss: 1165.060791015625, Neurons: 21, Grad norm: 8.925e+01\n",
      "Epoch 1022, Loss: 1165.060791015625, Neurons: 21, Grad norm: 8.925e+01\n",
      "Epoch 1023, Loss: 1164.7298583984375, Neurons: 21, Grad norm: 8.906e+01\n",
      "Epoch 1023, Loss: 1164.7298583984375, Neurons: 21, Grad norm: 8.906e+01\n",
      "Epoch 1024, Loss: 1164.392822265625, Neurons: 21, Grad norm: 8.887e+01\n",
      "Epoch 1024, Loss: 1164.392822265625, Neurons: 21, Grad norm: 8.887e+01\n",
      "Epoch 1025, Loss: 1164.0498046875, Neurons: 21, Grad norm: 8.867e+01\n",
      "Epoch 1025, Loss: 1164.0498046875, Neurons: 21, Grad norm: 8.867e+01\n",
      "Epoch 1026, Loss: 1163.701416015625, Neurons: 21, Grad norm: 8.846e+01\n",
      "Epoch 1026, Loss: 1163.701416015625, Neurons: 21, Grad norm: 8.846e+01\n",
      "Epoch 1027, Loss: 1163.34765625, Neurons: 21, Grad norm: 8.824e+01\n",
      "Epoch 1027, Loss: 1163.34765625, Neurons: 21, Grad norm: 8.824e+01\n",
      "Epoch 1028, Loss: 1162.988525390625, Neurons: 21, Grad norm: 8.801e+01\n",
      "Epoch 1028, Loss: 1162.988525390625, Neurons: 21, Grad norm: 8.801e+01\n",
      "Epoch 1029, Loss: 1162.62451171875, Neurons: 21, Grad norm: 8.776e+01\n",
      "Epoch 1029, Loss: 1162.62451171875, Neurons: 21, Grad norm: 8.776e+01\n",
      "Epoch 1030, Loss: 1162.255615234375, Neurons: 21, Grad norm: 8.750e+01\n",
      "Epoch 1030, Loss: 1162.255615234375, Neurons: 21, Grad norm: 8.750e+01\n",
      "Epoch 1031, Loss: 1161.882080078125, Neurons: 21, Grad norm: 8.723e+01\n",
      "Epoch 1031, Loss: 1161.882080078125, Neurons: 21, Grad norm: 8.723e+01\n",
      "Epoch 1032, Loss: 1161.5042724609375, Neurons: 21, Grad norm: 8.695e+01\n",
      "Epoch 1032, Loss: 1161.5042724609375, Neurons: 21, Grad norm: 8.695e+01\n",
      "Epoch 1033, Loss: 1161.1221923828125, Neurons: 21, Grad norm: 8.666e+01\n",
      "Epoch 1033, Loss: 1161.1221923828125, Neurons: 21, Grad norm: 8.666e+01\n",
      "Epoch 1034, Loss: 1160.736083984375, Neurons: 21, Grad norm: 8.635e+01\n",
      "Epoch 1034, Loss: 1160.736083984375, Neurons: 21, Grad norm: 8.635e+01\n",
      "Epoch 1035, Loss: 1160.34619140625, Neurons: 21, Grad norm: 8.602e+01\n",
      "Epoch 1035, Loss: 1160.34619140625, Neurons: 21, Grad norm: 8.602e+01\n",
      "Epoch 1036, Loss: 1159.95263671875, Neurons: 21, Grad norm: 8.569e+01\n",
      "Epoch 1036, Loss: 1159.95263671875, Neurons: 21, Grad norm: 8.569e+01\n",
      "Epoch 1037, Loss: 1159.5557861328125, Neurons: 21, Grad norm: 8.533e+01\n",
      "Epoch 1037, Loss: 1159.5557861328125, Neurons: 21, Grad norm: 8.533e+01\n",
      "Epoch 1038, Loss: 1159.15576171875, Neurons: 21, Grad norm: 8.497e+01\n",
      "Epoch 1038, Loss: 1159.15576171875, Neurons: 21, Grad norm: 8.497e+01\n",
      "Epoch 1039, Loss: 1158.752685546875, Neurons: 21, Grad norm: 8.459e+01\n",
      "Epoch 1039, Loss: 1158.752685546875, Neurons: 21, Grad norm: 8.459e+01\n",
      "Epoch 1040, Loss: 1158.3468017578125, Neurons: 21, Grad norm: 8.419e+01\n",
      "Epoch 1040, Loss: 1158.3468017578125, Neurons: 21, Grad norm: 8.419e+01\n",
      "Epoch 1041, Loss: 1157.9385986328125, Neurons: 21, Grad norm: 8.379e+01\n",
      "Epoch 1041, Loss: 1157.9385986328125, Neurons: 21, Grad norm: 8.379e+01\n",
      "Epoch 1042, Loss: 1157.527587890625, Neurons: 21, Grad norm: 8.336e+01\n",
      "Epoch 1042, Loss: 1157.527587890625, Neurons: 21, Grad norm: 8.336e+01\n",
      "Epoch 1043, Loss: 1157.114501953125, Neurons: 21, Grad norm: 8.293e+01\n",
      "Epoch 1043, Loss: 1157.114501953125, Neurons: 21, Grad norm: 8.293e+01\n",
      "Epoch 1044, Loss: 1156.69970703125, Neurons: 21, Grad norm: 8.248e+01\n",
      "Epoch 1044, Loss: 1156.69970703125, Neurons: 21, Grad norm: 8.248e+01\n",
      "Epoch 1045, Loss: 1156.2828369140625, Neurons: 21, Grad norm: 8.202e+01\n",
      "Epoch 1045, Loss: 1156.2828369140625, Neurons: 21, Grad norm: 8.202e+01\n",
      "Epoch 1046, Loss: 1155.8643798828125, Neurons: 21, Grad norm: 8.156e+01\n",
      "Epoch 1046, Loss: 1155.8643798828125, Neurons: 21, Grad norm: 8.156e+01\n",
      "Epoch 1047, Loss: 1155.444580078125, Neurons: 21, Grad norm: 8.108e+01\n",
      "Epoch 1047, Loss: 1155.444580078125, Neurons: 21, Grad norm: 8.108e+01\n",
      "Epoch 1048, Loss: 1155.0233154296875, Neurons: 21, Grad norm: 8.059e+01\n",
      "Epoch 1048, Loss: 1155.0233154296875, Neurons: 21, Grad norm: 8.059e+01\n",
      "Epoch 1049, Loss: 1154.60107421875, Neurons: 21, Grad norm: 8.009e+01\n",
      "Epoch 1049, Loss: 1154.60107421875, Neurons: 21, Grad norm: 8.009e+01\n",
      "Epoch 1050, Loss: 1154.1778564453125, Neurons: 21, Grad norm: 7.959e+01\n",
      "Epoch 1050, Loss: 1154.1778564453125, Neurons: 21, Grad norm: 7.959e+01\n",
      "Epoch 1051, Loss: 1153.7537841796875, Neurons: 21, Grad norm: 7.908e+01\n",
      "Epoch 1051, Loss: 1153.7537841796875, Neurons: 21, Grad norm: 7.908e+01\n",
      "Epoch 1052, Loss: 1153.3292236328125, Neurons: 21, Grad norm: 7.857e+01\n",
      "Epoch 1052, Loss: 1153.3292236328125, Neurons: 21, Grad norm: 7.857e+01\n",
      "Epoch 1053, Loss: 1152.9041748046875, Neurons: 21, Grad norm: 7.805e+01\n",
      "Epoch 1053, Loss: 1152.9041748046875, Neurons: 21, Grad norm: 7.805e+01\n",
      "Epoch 1054, Loss: 1152.478515625, Neurons: 21, Grad norm: 7.753e+01\n",
      "Epoch 1054, Loss: 1152.478515625, Neurons: 21, Grad norm: 7.753e+01\n",
      "Epoch 1055, Loss: 1152.0528564453125, Neurons: 21, Grad norm: 7.700e+01\n",
      "Epoch 1055, Loss: 1152.0528564453125, Neurons: 21, Grad norm: 7.700e+01\n",
      "Epoch 1056, Loss: 1151.6268310546875, Neurons: 21, Grad norm: 7.648e+01\n",
      "Epoch 1056, Loss: 1151.6268310546875, Neurons: 21, Grad norm: 7.648e+01\n",
      "Epoch 1057, Loss: 1151.200927734375, Neurons: 21, Grad norm: 7.596e+01\n",
      "Epoch 1057, Loss: 1151.200927734375, Neurons: 21, Grad norm: 7.596e+01\n",
      "Epoch 1058, Loss: 1150.7750244140625, Neurons: 21, Grad norm: 7.544e+01\n",
      "Epoch 1058, Loss: 1150.7750244140625, Neurons: 21, Grad norm: 7.544e+01\n",
      "Epoch 1059, Loss: 1150.349365234375, Neurons: 21, Grad norm: 7.492e+01\n",
      "Epoch 1059, Loss: 1150.349365234375, Neurons: 21, Grad norm: 7.492e+01\n",
      "Epoch 1060, Loss: 1149.923828125, Neurons: 21, Grad norm: 7.440e+01\n",
      "Epoch 1060, Loss: 1149.923828125, Neurons: 21, Grad norm: 7.440e+01\n",
      "Epoch 1061, Loss: 1149.4984130859375, Neurons: 21, Grad norm: 7.389e+01\n",
      "Epoch 1061, Loss: 1149.4984130859375, Neurons: 21, Grad norm: 7.389e+01\n",
      "Epoch 1062, Loss: 1149.0736083984375, Neurons: 21, Grad norm: 7.338e+01\n",
      "Epoch 1062, Loss: 1149.0736083984375, Neurons: 21, Grad norm: 7.338e+01\n",
      "Epoch 1063, Loss: 1148.6490478515625, Neurons: 21, Grad norm: 7.288e+01\n",
      "Epoch 1063, Loss: 1148.6490478515625, Neurons: 21, Grad norm: 7.288e+01\n",
      "Epoch 1064, Loss: 1148.224853515625, Neurons: 21, Grad norm: 7.238e+01\n",
      "Epoch 1064, Loss: 1148.224853515625, Neurons: 21, Grad norm: 7.238e+01\n",
      "Epoch 1065, Loss: 1147.801025390625, Neurons: 21, Grad norm: 7.189e+01\n",
      "Epoch 1065, Loss: 1147.801025390625, Neurons: 21, Grad norm: 7.189e+01\n",
      "Epoch 1066, Loss: 1147.3778076171875, Neurons: 21, Grad norm: 7.141e+01\n",
      "Epoch 1066, Loss: 1147.3778076171875, Neurons: 21, Grad norm: 7.141e+01\n",
      "Epoch 1067, Loss: 1146.955078125, Neurons: 21, Grad norm: 7.093e+01\n",
      "Epoch 1067, Loss: 1146.955078125, Neurons: 21, Grad norm: 7.093e+01\n",
      "Epoch 1068, Loss: 1146.5328369140625, Neurons: 21, Grad norm: 7.047e+01\n",
      "Epoch 1068, Loss: 1146.5328369140625, Neurons: 21, Grad norm: 7.047e+01\n",
      "Epoch 1069, Loss: 1146.1107177734375, Neurons: 21, Grad norm: 7.001e+01\n",
      "Epoch 1069, Loss: 1146.1107177734375, Neurons: 21, Grad norm: 7.001e+01\n",
      "Epoch 1070, Loss: 1145.6893310546875, Neurons: 21, Grad norm: 6.956e+01\n",
      "Epoch 1070, Loss: 1145.6893310546875, Neurons: 21, Grad norm: 6.956e+01\n",
      "Epoch 1071, Loss: 1145.268310546875, Neurons: 21, Grad norm: 6.912e+01\n",
      "Epoch 1071, Loss: 1145.268310546875, Neurons: 21, Grad norm: 6.912e+01\n",
      "Epoch 1072, Loss: 1144.8475341796875, Neurons: 21, Grad norm: 6.868e+01\n",
      "Epoch 1072, Loss: 1144.8475341796875, Neurons: 21, Grad norm: 6.868e+01\n",
      "Epoch 1073, Loss: 1144.42724609375, Neurons: 21, Grad norm: 6.826e+01\n",
      "Epoch 1073, Loss: 1144.42724609375, Neurons: 21, Grad norm: 6.826e+01\n",
      "Epoch 1074, Loss: 1144.00732421875, Neurons: 21, Grad norm: 6.785e+01\n",
      "Epoch 1074, Loss: 1144.00732421875, Neurons: 21, Grad norm: 6.785e+01\n",
      "Epoch 1075, Loss: 1143.587646484375, Neurons: 21, Grad norm: 6.745e+01\n",
      "Epoch 1075, Loss: 1143.587646484375, Neurons: 21, Grad norm: 6.745e+01\n",
      "Epoch 1076, Loss: 1143.1683349609375, Neurons: 21, Grad norm: 6.705e+01\n",
      "Epoch 1076, Loss: 1143.1683349609375, Neurons: 21, Grad norm: 6.705e+01\n",
      "Epoch 1077, Loss: 1142.7490234375, Neurons: 21, Grad norm: 6.667e+01\n",
      "Epoch 1077, Loss: 1142.7490234375, Neurons: 21, Grad norm: 6.667e+01\n",
      "Epoch 1078, Loss: 1142.329833984375, Neurons: 21, Grad norm: 6.630e+01\n",
      "Epoch 1078, Loss: 1142.329833984375, Neurons: 21, Grad norm: 6.630e+01\n",
      "Epoch 1079, Loss: 1141.9107666015625, Neurons: 21, Grad norm: 6.594e+01\n",
      "Epoch 1079, Loss: 1141.9107666015625, Neurons: 21, Grad norm: 6.594e+01\n",
      "Epoch 1080, Loss: 1141.4918212890625, Neurons: 21, Grad norm: 6.559e+01\n",
      "Epoch 1080, Loss: 1141.4918212890625, Neurons: 21, Grad norm: 6.559e+01\n",
      "Epoch 1081, Loss: 1141.0726318359375, Neurons: 21, Grad norm: 6.526e+01\n",
      "Epoch 1081, Loss: 1141.0726318359375, Neurons: 21, Grad norm: 6.526e+01\n",
      "Epoch 1082, Loss: 1140.653564453125, Neurons: 21, Grad norm: 6.493e+01\n",
      "Epoch 1082, Loss: 1140.653564453125, Neurons: 21, Grad norm: 6.493e+01\n",
      "Epoch 1083, Loss: 1140.2342529296875, Neurons: 21, Grad norm: 6.462e+01\n",
      "Epoch 1083, Loss: 1140.2342529296875, Neurons: 21, Grad norm: 6.462e+01\n",
      "Epoch 1084, Loss: 1139.8145751953125, Neurons: 21, Grad norm: 6.431e+01\n",
      "Epoch 1084, Loss: 1139.8145751953125, Neurons: 21, Grad norm: 6.431e+01\n",
      "Epoch 1085, Loss: 1139.394775390625, Neurons: 21, Grad norm: 6.402e+01\n",
      "Epoch 1085, Loss: 1139.394775390625, Neurons: 21, Grad norm: 6.402e+01\n",
      "Epoch 1086, Loss: 1138.974609375, Neurons: 21, Grad norm: 6.374e+01\n",
      "Epoch 1086, Loss: 1138.974609375, Neurons: 21, Grad norm: 6.374e+01\n",
      "Epoch 1087, Loss: 1138.5538330078125, Neurons: 21, Grad norm: 6.347e+01\n",
      "Epoch 1087, Loss: 1138.5538330078125, Neurons: 21, Grad norm: 6.347e+01\n",
      "Epoch 1088, Loss: 1138.1328125, Neurons: 21, Grad norm: 6.321e+01\n",
      "Epoch 1088, Loss: 1138.1328125, Neurons: 21, Grad norm: 6.321e+01\n",
      "Epoch 1089, Loss: 1137.7108154296875, Neurons: 21, Grad norm: 6.297e+01\n",
      "Epoch 1089, Loss: 1137.7108154296875, Neurons: 21, Grad norm: 6.297e+01\n",
      "Epoch 1090, Loss: 1137.288330078125, Neurons: 21, Grad norm: 6.273e+01\n",
      "Epoch 1090, Loss: 1137.288330078125, Neurons: 21, Grad norm: 6.273e+01\n",
      "Epoch 1091, Loss: 1136.865234375, Neurons: 21, Grad norm: 6.251e+01\n",
      "Epoch 1091, Loss: 1136.865234375, Neurons: 21, Grad norm: 6.251e+01\n",
      "Epoch 1092, Loss: 1136.441162109375, Neurons: 21, Grad norm: 6.230e+01\n",
      "Epoch 1092, Loss: 1136.441162109375, Neurons: 21, Grad norm: 6.230e+01\n",
      "Epoch 1093, Loss: 1136.01611328125, Neurons: 21, Grad norm: 6.210e+01\n",
      "Epoch 1093, Loss: 1136.01611328125, Neurons: 21, Grad norm: 6.210e+01\n",
      "Epoch 1094, Loss: 1135.59033203125, Neurons: 21, Grad norm: 6.192e+01\n",
      "Epoch 1094, Loss: 1135.59033203125, Neurons: 21, Grad norm: 6.192e+01\n",
      "Epoch 1095, Loss: 1135.163330078125, Neurons: 21, Grad norm: 6.175e+01\n",
      "Epoch 1095, Loss: 1135.163330078125, Neurons: 21, Grad norm: 6.175e+01\n",
      "Epoch 1096, Loss: 1134.735107421875, Neurons: 21, Grad norm: 6.159e+01\n",
      "Epoch 1096, Loss: 1134.735107421875, Neurons: 21, Grad norm: 6.159e+01\n",
      "Epoch 1097, Loss: 1134.3056640625, Neurons: 21, Grad norm: 6.144e+01\n",
      "Epoch 1097, Loss: 1134.3056640625, Neurons: 21, Grad norm: 6.144e+01\n",
      "Epoch 1098, Loss: 1133.875, Neurons: 21, Grad norm: 6.131e+01\n",
      "Epoch 1098, Loss: 1133.875, Neurons: 21, Grad norm: 6.131e+01\n",
      "Epoch 1099, Loss: 1133.44287109375, Neurons: 21, Grad norm: 6.119e+01\n",
      "Epoch 1099, Loss: 1133.44287109375, Neurons: 21, Grad norm: 6.119e+01\n",
      "Epoch 1099, Test loss: 1147.1685791015625\n",
      "Epoch 1099, Test loss: 1147.1685791015625\n",
      "Added neuron to hidden layer 2 with activation sin\n",
      "Added neuron to hidden layer 2 with activation sin\n",
      "network shape updated to :[10, 11, 1]\n",
      "network shape updated to :[10, 11, 1]\n",
      "Epoch 1100, Loss: 1131.8692626953125, Neurons: 22, Grad norm: 6.096e+01\n",
      "Epoch 1100, Loss: 1131.8692626953125, Neurons: 22, Grad norm: 6.096e+01\n",
      "Epoch 1101, Loss: 1131.7506103515625, Neurons: 22, Grad norm: 6.092e+01\n",
      "Epoch 1101, Loss: 1131.7506103515625, Neurons: 22, Grad norm: 6.092e+01\n",
      "Epoch 1102, Loss: 1131.6260986328125, Neurons: 22, Grad norm: 6.087e+01\n",
      "Epoch 1102, Loss: 1131.6260986328125, Neurons: 22, Grad norm: 6.087e+01\n",
      "Epoch 1103, Loss: 1131.4959716796875, Neurons: 22, Grad norm: 6.082e+01\n",
      "Epoch 1103, Loss: 1131.4959716796875, Neurons: 22, Grad norm: 6.082e+01\n",
      "Epoch 1104, Loss: 1131.3599853515625, Neurons: 22, Grad norm: 6.077e+01\n",
      "Epoch 1104, Loss: 1131.3599853515625, Neurons: 22, Grad norm: 6.077e+01\n",
      "Epoch 1105, Loss: 1131.218017578125, Neurons: 22, Grad norm: 6.072e+01\n",
      "Epoch 1105, Loss: 1131.218017578125, Neurons: 22, Grad norm: 6.072e+01\n",
      "Epoch 1106, Loss: 1131.0703125, Neurons: 22, Grad norm: 6.066e+01\n",
      "Epoch 1106, Loss: 1131.0703125, Neurons: 22, Grad norm: 6.066e+01\n",
      "Epoch 1107, Loss: 1130.916748046875, Neurons: 22, Grad norm: 6.059e+01\n",
      "Epoch 1107, Loss: 1130.916748046875, Neurons: 22, Grad norm: 6.059e+01\n",
      "Epoch 1108, Loss: 1130.7572021484375, Neurons: 22, Grad norm: 6.052e+01\n",
      "Epoch 1108, Loss: 1130.7572021484375, Neurons: 22, Grad norm: 6.052e+01\n",
      "Epoch 1109, Loss: 1130.591552734375, Neurons: 22, Grad norm: 6.045e+01\n",
      "Epoch 1109, Loss: 1130.591552734375, Neurons: 22, Grad norm: 6.045e+01\n",
      "Epoch 1110, Loss: 1130.420166015625, Neurons: 22, Grad norm: 6.037e+01\n",
      "Epoch 1110, Loss: 1130.420166015625, Neurons: 22, Grad norm: 6.037e+01\n",
      "Epoch 1111, Loss: 1130.2430419921875, Neurons: 22, Grad norm: 6.028e+01\n",
      "Epoch 1111, Loss: 1130.2430419921875, Neurons: 22, Grad norm: 6.028e+01\n",
      "Epoch 1112, Loss: 1130.0601806640625, Neurons: 22, Grad norm: 6.020e+01\n",
      "Epoch 1112, Loss: 1130.0601806640625, Neurons: 22, Grad norm: 6.020e+01\n",
      "Epoch 1113, Loss: 1129.871826171875, Neurons: 22, Grad norm: 6.011e+01\n",
      "Epoch 1113, Loss: 1129.871826171875, Neurons: 22, Grad norm: 6.011e+01\n",
      "Epoch 1114, Loss: 1129.6781005859375, Neurons: 22, Grad norm: 6.002e+01\n",
      "Epoch 1114, Loss: 1129.6781005859375, Neurons: 22, Grad norm: 6.002e+01\n",
      "Epoch 1115, Loss: 1129.4788818359375, Neurons: 22, Grad norm: 5.993e+01\n",
      "Epoch 1115, Loss: 1129.4788818359375, Neurons: 22, Grad norm: 5.993e+01\n",
      "Epoch 1116, Loss: 1129.2745361328125, Neurons: 22, Grad norm: 5.984e+01\n",
      "Epoch 1116, Loss: 1129.2745361328125, Neurons: 22, Grad norm: 5.984e+01\n",
      "Epoch 1117, Loss: 1129.0650634765625, Neurons: 22, Grad norm: 5.976e+01\n",
      "Epoch 1117, Loss: 1129.0650634765625, Neurons: 22, Grad norm: 5.976e+01\n",
      "Epoch 1118, Loss: 1128.8507080078125, Neurons: 22, Grad norm: 5.967e+01\n",
      "Epoch 1118, Loss: 1128.8507080078125, Neurons: 22, Grad norm: 5.967e+01\n",
      "Epoch 1119, Loss: 1128.631591796875, Neurons: 22, Grad norm: 5.959e+01\n",
      "Epoch 1119, Loss: 1128.631591796875, Neurons: 22, Grad norm: 5.959e+01\n",
      "Epoch 1120, Loss: 1128.4073486328125, Neurons: 22, Grad norm: 5.951e+01\n",
      "Epoch 1120, Loss: 1128.4073486328125, Neurons: 22, Grad norm: 5.951e+01\n",
      "Epoch 1121, Loss: 1128.1787109375, Neurons: 22, Grad norm: 5.943e+01\n",
      "Epoch 1121, Loss: 1128.1787109375, Neurons: 22, Grad norm: 5.943e+01\n",
      "Epoch 1122, Loss: 1127.945556640625, Neurons: 22, Grad norm: 5.936e+01\n",
      "Epoch 1122, Loss: 1127.945556640625, Neurons: 22, Grad norm: 5.936e+01\n",
      "Epoch 1123, Loss: 1127.7078857421875, Neurons: 22, Grad norm: 5.928e+01\n",
      "Epoch 1123, Loss: 1127.7078857421875, Neurons: 22, Grad norm: 5.928e+01\n",
      "Epoch 1124, Loss: 1127.466064453125, Neurons: 22, Grad norm: 5.921e+01\n",
      "Epoch 1124, Loss: 1127.466064453125, Neurons: 22, Grad norm: 5.921e+01\n",
      "Epoch 1125, Loss: 1127.2200927734375, Neurons: 22, Grad norm: 5.915e+01\n",
      "Epoch 1125, Loss: 1127.2200927734375, Neurons: 22, Grad norm: 5.915e+01\n",
      "Epoch 1126, Loss: 1126.9700927734375, Neurons: 22, Grad norm: 5.908e+01\n",
      "Epoch 1126, Loss: 1126.9700927734375, Neurons: 22, Grad norm: 5.908e+01\n",
      "Epoch 1127, Loss: 1126.716064453125, Neurons: 22, Grad norm: 5.902e+01\n",
      "Epoch 1127, Loss: 1126.716064453125, Neurons: 22, Grad norm: 5.902e+01\n",
      "Epoch 1128, Loss: 1126.4581298828125, Neurons: 22, Grad norm: 5.896e+01\n",
      "Epoch 1128, Loss: 1126.4581298828125, Neurons: 22, Grad norm: 5.896e+01\n",
      "Epoch 1129, Loss: 1126.196533203125, Neurons: 22, Grad norm: 5.890e+01\n",
      "Epoch 1129, Loss: 1126.196533203125, Neurons: 22, Grad norm: 5.890e+01\n",
      "Epoch 1130, Loss: 1125.9310302734375, Neurons: 22, Grad norm: 5.884e+01\n",
      "Epoch 1130, Loss: 1125.9310302734375, Neurons: 22, Grad norm: 5.884e+01\n",
      "Epoch 1131, Loss: 1125.662353515625, Neurons: 22, Grad norm: 5.879e+01\n",
      "Epoch 1131, Loss: 1125.662353515625, Neurons: 22, Grad norm: 5.879e+01\n",
      "Epoch 1132, Loss: 1125.3897705078125, Neurons: 22, Grad norm: 5.873e+01\n",
      "Epoch 1132, Loss: 1125.3897705078125, Neurons: 22, Grad norm: 5.873e+01\n",
      "Epoch 1133, Loss: 1125.11376953125, Neurons: 22, Grad norm: 5.869e+01\n",
      "Epoch 1133, Loss: 1125.11376953125, Neurons: 22, Grad norm: 5.869e+01\n",
      "Epoch 1134, Loss: 1124.8345947265625, Neurons: 22, Grad norm: 5.864e+01\n",
      "Epoch 1134, Loss: 1124.8345947265625, Neurons: 22, Grad norm: 5.864e+01\n",
      "Epoch 1135, Loss: 1124.5518798828125, Neurons: 22, Grad norm: 5.861e+01\n",
      "Epoch 1135, Loss: 1124.5518798828125, Neurons: 22, Grad norm: 5.861e+01\n",
      "Epoch 1136, Loss: 1124.265869140625, Neurons: 22, Grad norm: 5.858e+01\n",
      "Epoch 1136, Loss: 1124.265869140625, Neurons: 22, Grad norm: 5.858e+01\n",
      "Epoch 1137, Loss: 1123.976806640625, Neurons: 22, Grad norm: 5.855e+01\n",
      "Epoch 1137, Loss: 1123.976806640625, Neurons: 22, Grad norm: 5.855e+01\n",
      "Epoch 1138, Loss: 1123.6845703125, Neurons: 22, Grad norm: 5.853e+01\n",
      "Epoch 1138, Loss: 1123.6845703125, Neurons: 22, Grad norm: 5.853e+01\n",
      "Epoch 1139, Loss: 1123.3890380859375, Neurons: 22, Grad norm: 5.852e+01\n",
      "Epoch 1139, Loss: 1123.3890380859375, Neurons: 22, Grad norm: 5.852e+01\n",
      "Epoch 1140, Loss: 1123.0904541015625, Neurons: 22, Grad norm: 5.852e+01\n",
      "Epoch 1140, Loss: 1123.0904541015625, Neurons: 22, Grad norm: 5.852e+01\n",
      "Epoch 1141, Loss: 1122.788818359375, Neurons: 22, Grad norm: 5.853e+01\n",
      "Epoch 1141, Loss: 1122.788818359375, Neurons: 22, Grad norm: 5.853e+01\n",
      "Epoch 1142, Loss: 1122.4840087890625, Neurons: 22, Grad norm: 5.854e+01\n",
      "Epoch 1142, Loss: 1122.4840087890625, Neurons: 22, Grad norm: 5.854e+01\n",
      "Epoch 1143, Loss: 1122.17626953125, Neurons: 22, Grad norm: 5.857e+01\n",
      "Epoch 1143, Loss: 1122.17626953125, Neurons: 22, Grad norm: 5.857e+01\n",
      "Epoch 1144, Loss: 1121.86572265625, Neurons: 22, Grad norm: 5.860e+01\n",
      "Epoch 1144, Loss: 1121.86572265625, Neurons: 22, Grad norm: 5.860e+01\n",
      "Epoch 1145, Loss: 1121.5517578125, Neurons: 22, Grad norm: 5.864e+01\n",
      "Epoch 1145, Loss: 1121.5517578125, Neurons: 22, Grad norm: 5.864e+01\n",
      "Epoch 1146, Loss: 1121.235107421875, Neurons: 22, Grad norm: 5.869e+01\n",
      "Epoch 1146, Loss: 1121.235107421875, Neurons: 22, Grad norm: 5.869e+01\n",
      "Epoch 1147, Loss: 1120.915283203125, Neurons: 22, Grad norm: 5.875e+01\n",
      "Epoch 1147, Loss: 1120.915283203125, Neurons: 22, Grad norm: 5.875e+01\n",
      "Epoch 1148, Loss: 1120.592529296875, Neurons: 22, Grad norm: 5.881e+01\n",
      "Epoch 1148, Loss: 1120.592529296875, Neurons: 22, Grad norm: 5.881e+01\n",
      "Epoch 1149, Loss: 1120.266845703125, Neurons: 22, Grad norm: 5.889e+01\n",
      "Epoch 1149, Loss: 1120.266845703125, Neurons: 22, Grad norm: 5.889e+01\n",
      "Epoch 1150, Loss: 1119.937744140625, Neurons: 22, Grad norm: 5.897e+01\n",
      "Epoch 1150, Loss: 1119.937744140625, Neurons: 22, Grad norm: 5.897e+01\n",
      "Epoch 1151, Loss: 1119.6060791015625, Neurons: 22, Grad norm: 5.907e+01\n",
      "Epoch 1151, Loss: 1119.6060791015625, Neurons: 22, Grad norm: 5.907e+01\n",
      "Epoch 1152, Loss: 1119.27099609375, Neurons: 22, Grad norm: 5.918e+01\n",
      "Epoch 1152, Loss: 1119.27099609375, Neurons: 22, Grad norm: 5.918e+01\n",
      "Epoch 1153, Loss: 1118.9332275390625, Neurons: 22, Grad norm: 5.930e+01\n",
      "Epoch 1153, Loss: 1118.9332275390625, Neurons: 22, Grad norm: 5.930e+01\n",
      "Epoch 1154, Loss: 1118.591796875, Neurons: 22, Grad norm: 5.943e+01\n",
      "Epoch 1154, Loss: 1118.591796875, Neurons: 22, Grad norm: 5.943e+01\n",
      "Epoch 1155, Loss: 1118.2476806640625, Neurons: 22, Grad norm: 5.957e+01\n",
      "Epoch 1155, Loss: 1118.2476806640625, Neurons: 22, Grad norm: 5.957e+01\n",
      "Epoch 1156, Loss: 1117.900146484375, Neurons: 22, Grad norm: 5.973e+01\n",
      "Epoch 1156, Loss: 1117.900146484375, Neurons: 22, Grad norm: 5.973e+01\n",
      "Epoch 1157, Loss: 1117.549560546875, Neurons: 22, Grad norm: 5.990e+01\n",
      "Epoch 1157, Loss: 1117.549560546875, Neurons: 22, Grad norm: 5.990e+01\n",
      "Epoch 1158, Loss: 1117.195556640625, Neurons: 22, Grad norm: 6.008e+01\n",
      "Epoch 1158, Loss: 1117.195556640625, Neurons: 22, Grad norm: 6.008e+01\n",
      "Epoch 1159, Loss: 1116.8382568359375, Neurons: 22, Grad norm: 6.028e+01\n",
      "Epoch 1159, Loss: 1116.8382568359375, Neurons: 22, Grad norm: 6.028e+01\n",
      "Epoch 1160, Loss: 1116.4775390625, Neurons: 22, Grad norm: 6.049e+01\n",
      "Epoch 1160, Loss: 1116.4775390625, Neurons: 22, Grad norm: 6.049e+01\n",
      "Epoch 1161, Loss: 1116.1134033203125, Neurons: 22, Grad norm: 6.072e+01\n",
      "Epoch 1161, Loss: 1116.1134033203125, Neurons: 22, Grad norm: 6.072e+01\n",
      "Epoch 1162, Loss: 1115.7459716796875, Neurons: 22, Grad norm: 6.097e+01\n",
      "Epoch 1162, Loss: 1115.7459716796875, Neurons: 22, Grad norm: 6.097e+01\n",
      "Epoch 1163, Loss: 1115.374755859375, Neurons: 22, Grad norm: 6.122e+01\n",
      "Epoch 1163, Loss: 1115.374755859375, Neurons: 22, Grad norm: 6.122e+01\n",
      "Epoch 1164, Loss: 1114.9998779296875, Neurons: 22, Grad norm: 6.150e+01\n",
      "Epoch 1164, Loss: 1114.9998779296875, Neurons: 22, Grad norm: 6.150e+01\n",
      "Epoch 1165, Loss: 1114.62158203125, Neurons: 22, Grad norm: 6.179e+01\n",
      "Epoch 1165, Loss: 1114.62158203125, Neurons: 22, Grad norm: 6.179e+01\n",
      "Epoch 1166, Loss: 1114.2392578125, Neurons: 22, Grad norm: 6.209e+01\n",
      "Epoch 1166, Loss: 1114.2392578125, Neurons: 22, Grad norm: 6.209e+01\n",
      "Epoch 1167, Loss: 1113.853271484375, Neurons: 22, Grad norm: 6.241e+01\n",
      "Epoch 1167, Loss: 1113.853271484375, Neurons: 22, Grad norm: 6.241e+01\n",
      "Epoch 1168, Loss: 1113.46337890625, Neurons: 22, Grad norm: 6.274e+01\n",
      "Epoch 1168, Loss: 1113.46337890625, Neurons: 22, Grad norm: 6.274e+01\n",
      "Epoch 1169, Loss: 1113.0694580078125, Neurons: 22, Grad norm: 6.309e+01\n",
      "Epoch 1169, Loss: 1113.0694580078125, Neurons: 22, Grad norm: 6.309e+01\n",
      "Epoch 1170, Loss: 1112.6712646484375, Neurons: 22, Grad norm: 6.346e+01\n",
      "Epoch 1170, Loss: 1112.6712646484375, Neurons: 22, Grad norm: 6.346e+01\n",
      "Epoch 1171, Loss: 1112.26904296875, Neurons: 22, Grad norm: 6.385e+01\n",
      "Epoch 1171, Loss: 1112.26904296875, Neurons: 22, Grad norm: 6.385e+01\n",
      "Epoch 1172, Loss: 1111.8626708984375, Neurons: 22, Grad norm: 6.425e+01\n",
      "Epoch 1172, Loss: 1111.8626708984375, Neurons: 22, Grad norm: 6.425e+01\n",
      "Epoch 1173, Loss: 1111.4517822265625, Neurons: 22, Grad norm: 6.467e+01\n",
      "Epoch 1173, Loss: 1111.4517822265625, Neurons: 22, Grad norm: 6.467e+01\n",
      "Epoch 1174, Loss: 1111.0364990234375, Neurons: 22, Grad norm: 6.511e+01\n",
      "Epoch 1174, Loss: 1111.0364990234375, Neurons: 22, Grad norm: 6.511e+01\n",
      "Epoch 1175, Loss: 1110.6168212890625, Neurons: 22, Grad norm: 6.557e+01\n",
      "Epoch 1175, Loss: 1110.6168212890625, Neurons: 22, Grad norm: 6.557e+01\n",
      "Epoch 1176, Loss: 1110.1922607421875, Neurons: 22, Grad norm: 6.604e+01\n",
      "Epoch 1176, Loss: 1110.1922607421875, Neurons: 22, Grad norm: 6.604e+01\n",
      "Epoch 1177, Loss: 1109.76318359375, Neurons: 22, Grad norm: 6.653e+01\n",
      "Epoch 1177, Loss: 1109.76318359375, Neurons: 22, Grad norm: 6.653e+01\n",
      "Epoch 1178, Loss: 1109.3291015625, Neurons: 22, Grad norm: 6.704e+01\n",
      "Epoch 1178, Loss: 1109.3291015625, Neurons: 22, Grad norm: 6.704e+01\n",
      "Epoch 1179, Loss: 1108.8902587890625, Neurons: 22, Grad norm: 6.757e+01\n",
      "Epoch 1179, Loss: 1108.8902587890625, Neurons: 22, Grad norm: 6.757e+01\n",
      "Epoch 1180, Loss: 1108.4461669921875, Neurons: 22, Grad norm: 6.812e+01\n",
      "Epoch 1180, Loss: 1108.4461669921875, Neurons: 22, Grad norm: 6.812e+01\n",
      "Epoch 1181, Loss: 1107.9970703125, Neurons: 22, Grad norm: 6.868e+01\n",
      "Epoch 1181, Loss: 1107.9970703125, Neurons: 22, Grad norm: 6.868e+01\n",
      "Epoch 1182, Loss: 1107.5426025390625, Neurons: 22, Grad norm: 6.926e+01\n",
      "Epoch 1182, Loss: 1107.5426025390625, Neurons: 22, Grad norm: 6.926e+01\n",
      "Epoch 1183, Loss: 1107.082763671875, Neurons: 22, Grad norm: 6.986e+01\n",
      "Epoch 1183, Loss: 1107.082763671875, Neurons: 22, Grad norm: 6.986e+01\n",
      "Epoch 1184, Loss: 1106.6175537109375, Neurons: 22, Grad norm: 7.048e+01\n",
      "Epoch 1184, Loss: 1106.6175537109375, Neurons: 22, Grad norm: 7.048e+01\n",
      "Epoch 1185, Loss: 1106.1466064453125, Neurons: 22, Grad norm: 7.111e+01\n",
      "Epoch 1185, Loss: 1106.1466064453125, Neurons: 22, Grad norm: 7.111e+01\n",
      "Epoch 1186, Loss: 1105.6700439453125, Neurons: 22, Grad norm: 7.176e+01\n",
      "Epoch 1186, Loss: 1105.6700439453125, Neurons: 22, Grad norm: 7.176e+01\n",
      "Epoch 1187, Loss: 1105.1875, Neurons: 22, Grad norm: 7.243e+01\n",
      "Epoch 1187, Loss: 1105.1875, Neurons: 22, Grad norm: 7.243e+01\n",
      "Epoch 1188, Loss: 1104.69921875, Neurons: 22, Grad norm: 7.312e+01\n",
      "Epoch 1188, Loss: 1104.69921875, Neurons: 22, Grad norm: 7.312e+01\n",
      "Epoch 1189, Loss: 1104.2047119140625, Neurons: 22, Grad norm: 7.382e+01\n",
      "Epoch 1189, Loss: 1104.2047119140625, Neurons: 22, Grad norm: 7.382e+01\n",
      "Epoch 1190, Loss: 1103.7039794921875, Neurons: 22, Grad norm: 7.454e+01\n",
      "Epoch 1190, Loss: 1103.7039794921875, Neurons: 22, Grad norm: 7.454e+01\n",
      "Epoch 1191, Loss: 1103.1968994140625, Neurons: 22, Grad norm: 7.528e+01\n",
      "Epoch 1191, Loss: 1103.1968994140625, Neurons: 22, Grad norm: 7.528e+01\n",
      "Epoch 1192, Loss: 1102.68359375, Neurons: 22, Grad norm: 7.604e+01\n",
      "Epoch 1192, Loss: 1102.68359375, Neurons: 22, Grad norm: 7.604e+01\n",
      "Epoch 1193, Loss: 1102.16357421875, Neurons: 22, Grad norm: 7.681e+01\n",
      "Epoch 1193, Loss: 1102.16357421875, Neurons: 22, Grad norm: 7.681e+01\n",
      "Epoch 1194, Loss: 1101.6368408203125, Neurons: 22, Grad norm: 7.759e+01\n",
      "Epoch 1194, Loss: 1101.6368408203125, Neurons: 22, Grad norm: 7.759e+01\n",
      "Epoch 1195, Loss: 1101.103271484375, Neurons: 22, Grad norm: 7.840e+01\n",
      "Epoch 1195, Loss: 1101.103271484375, Neurons: 22, Grad norm: 7.840e+01\n",
      "Epoch 1196, Loss: 1100.56298828125, Neurons: 22, Grad norm: 7.921e+01\n",
      "Epoch 1196, Loss: 1100.56298828125, Neurons: 22, Grad norm: 7.921e+01\n",
      "Epoch 1197, Loss: 1100.015380859375, Neurons: 22, Grad norm: 8.004e+01\n",
      "Epoch 1197, Loss: 1100.015380859375, Neurons: 22, Grad norm: 8.004e+01\n",
      "Epoch 1198, Loss: 1099.4608154296875, Neurons: 22, Grad norm: 8.089e+01\n",
      "Epoch 1198, Loss: 1099.4608154296875, Neurons: 22, Grad norm: 8.089e+01\n",
      "Epoch 1199, Loss: 1098.8988037109375, Neurons: 22, Grad norm: 8.175e+01\n",
      "Epoch 1199, Loss: 1098.8988037109375, Neurons: 22, Grad norm: 8.175e+01\n",
      "Epoch 1199, Test loss: 1111.404296875\n",
      "Epoch 1199, Test loss: 1111.404296875\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "network shape updated to :[10, 12, 1]\n",
      "network shape updated to :[10, 12, 1]\n",
      "Epoch 1200, Loss: 1097.4207763671875, Neurons: 23, Grad norm: 8.176e+01\n",
      "Epoch 1200, Loss: 1097.4207763671875, Neurons: 23, Grad norm: 8.176e+01\n",
      "Epoch 1201, Loss: 1097.2984619140625, Neurons: 23, Grad norm: 8.174e+01\n",
      "Epoch 1201, Loss: 1097.2984619140625, Neurons: 23, Grad norm: 8.174e+01\n",
      "Epoch 1202, Loss: 1097.1708984375, Neurons: 23, Grad norm: 8.174e+01\n",
      "Epoch 1202, Loss: 1097.1708984375, Neurons: 23, Grad norm: 8.174e+01\n",
      "Epoch 1203, Loss: 1097.0382080078125, Neurons: 23, Grad norm: 8.176e+01\n",
      "Epoch 1203, Loss: 1097.0382080078125, Neurons: 23, Grad norm: 8.176e+01\n",
      "Epoch 1204, Loss: 1096.900390625, Neurons: 23, Grad norm: 8.182e+01\n",
      "Epoch 1204, Loss: 1096.900390625, Neurons: 23, Grad norm: 8.182e+01\n",
      "Epoch 1205, Loss: 1096.757080078125, Neurons: 23, Grad norm: 8.190e+01\n",
      "Epoch 1205, Loss: 1096.757080078125, Neurons: 23, Grad norm: 8.190e+01\n",
      "Epoch 1206, Loss: 1096.608154296875, Neurons: 23, Grad norm: 8.201e+01\n",
      "Epoch 1206, Loss: 1096.608154296875, Neurons: 23, Grad norm: 8.201e+01\n",
      "Epoch 1207, Loss: 1096.4532470703125, Neurons: 23, Grad norm: 8.213e+01\n",
      "Epoch 1207, Loss: 1096.4532470703125, Neurons: 23, Grad norm: 8.213e+01\n",
      "Epoch 1208, Loss: 1096.2923583984375, Neurons: 23, Grad norm: 8.228e+01\n",
      "Epoch 1208, Loss: 1096.2923583984375, Neurons: 23, Grad norm: 8.228e+01\n",
      "Epoch 1209, Loss: 1096.125244140625, Neurons: 23, Grad norm: 8.244e+01\n",
      "Epoch 1209, Loss: 1096.125244140625, Neurons: 23, Grad norm: 8.244e+01\n",
      "Epoch 1210, Loss: 1095.9522705078125, Neurons: 23, Grad norm: 8.261e+01\n",
      "Epoch 1210, Loss: 1095.9522705078125, Neurons: 23, Grad norm: 8.261e+01\n",
      "Epoch 1211, Loss: 1095.773193359375, Neurons: 23, Grad norm: 8.280e+01\n",
      "Epoch 1211, Loss: 1095.773193359375, Neurons: 23, Grad norm: 8.280e+01\n",
      "Epoch 1212, Loss: 1095.5885009765625, Neurons: 23, Grad norm: 8.301e+01\n",
      "Epoch 1212, Loss: 1095.5885009765625, Neurons: 23, Grad norm: 8.301e+01\n",
      "Epoch 1213, Loss: 1095.3980712890625, Neurons: 23, Grad norm: 8.322e+01\n",
      "Epoch 1213, Loss: 1095.3980712890625, Neurons: 23, Grad norm: 8.322e+01\n",
      "Epoch 1214, Loss: 1095.2022705078125, Neurons: 23, Grad norm: 8.344e+01\n",
      "Epoch 1214, Loss: 1095.2022705078125, Neurons: 23, Grad norm: 8.344e+01\n",
      "Epoch 1215, Loss: 1095.0009765625, Neurons: 23, Grad norm: 8.366e+01\n",
      "Epoch 1215, Loss: 1095.0009765625, Neurons: 23, Grad norm: 8.366e+01\n",
      "Epoch 1216, Loss: 1094.7943115234375, Neurons: 23, Grad norm: 8.387e+01\n",
      "Epoch 1216, Loss: 1094.7943115234375, Neurons: 23, Grad norm: 8.387e+01\n",
      "Epoch 1217, Loss: 1094.58251953125, Neurons: 23, Grad norm: 8.408e+01\n",
      "Epoch 1217, Loss: 1094.58251953125, Neurons: 23, Grad norm: 8.408e+01\n",
      "Epoch 1218, Loss: 1094.365478515625, Neurons: 23, Grad norm: 8.428e+01\n",
      "Epoch 1218, Loss: 1094.365478515625, Neurons: 23, Grad norm: 8.428e+01\n",
      "Epoch 1219, Loss: 1094.14306640625, Neurons: 23, Grad norm: 8.447e+01\n",
      "Epoch 1219, Loss: 1094.14306640625, Neurons: 23, Grad norm: 8.447e+01\n",
      "Epoch 1220, Loss: 1093.91552734375, Neurons: 23, Grad norm: 8.466e+01\n",
      "Epoch 1220, Loss: 1093.91552734375, Neurons: 23, Grad norm: 8.466e+01\n",
      "Epoch 1221, Loss: 1093.68310546875, Neurons: 23, Grad norm: 8.484e+01\n",
      "Epoch 1221, Loss: 1093.68310546875, Neurons: 23, Grad norm: 8.484e+01\n",
      "Epoch 1222, Loss: 1093.445556640625, Neurons: 23, Grad norm: 8.503e+01\n",
      "Epoch 1222, Loss: 1093.445556640625, Neurons: 23, Grad norm: 8.503e+01\n",
      "Epoch 1223, Loss: 1093.2034912109375, Neurons: 23, Grad norm: 8.522e+01\n",
      "Epoch 1223, Loss: 1093.2034912109375, Neurons: 23, Grad norm: 8.522e+01\n",
      "Epoch 1224, Loss: 1092.95654296875, Neurons: 23, Grad norm: 8.542e+01\n",
      "Epoch 1224, Loss: 1092.95654296875, Neurons: 23, Grad norm: 8.542e+01\n",
      "Epoch 1225, Loss: 1092.705078125, Neurons: 23, Grad norm: 8.564e+01\n",
      "Epoch 1225, Loss: 1092.705078125, Neurons: 23, Grad norm: 8.564e+01\n",
      "Epoch 1226, Loss: 1092.448974609375, Neurons: 23, Grad norm: 8.586e+01\n",
      "Epoch 1226, Loss: 1092.448974609375, Neurons: 23, Grad norm: 8.586e+01\n",
      "Epoch 1227, Loss: 1092.1883544921875, Neurons: 23, Grad norm: 8.610e+01\n",
      "Epoch 1227, Loss: 1092.1883544921875, Neurons: 23, Grad norm: 8.610e+01\n",
      "Epoch 1228, Loss: 1091.92333984375, Neurons: 23, Grad norm: 8.635e+01\n",
      "Epoch 1228, Loss: 1091.92333984375, Neurons: 23, Grad norm: 8.635e+01\n",
      "Epoch 1229, Loss: 1091.65380859375, Neurons: 23, Grad norm: 8.662e+01\n",
      "Epoch 1229, Loss: 1091.65380859375, Neurons: 23, Grad norm: 8.662e+01\n",
      "Epoch 1230, Loss: 1091.3800048828125, Neurons: 23, Grad norm: 8.689e+01\n",
      "Epoch 1230, Loss: 1091.3800048828125, Neurons: 23, Grad norm: 8.689e+01\n",
      "Epoch 1231, Loss: 1091.101806640625, Neurons: 23, Grad norm: 8.718e+01\n",
      "Epoch 1231, Loss: 1091.101806640625, Neurons: 23, Grad norm: 8.718e+01\n",
      "Epoch 1232, Loss: 1090.8193359375, Neurons: 23, Grad norm: 8.748e+01\n",
      "Epoch 1232, Loss: 1090.8193359375, Neurons: 23, Grad norm: 8.748e+01\n",
      "Epoch 1233, Loss: 1090.5328369140625, Neurons: 23, Grad norm: 8.778e+01\n",
      "Epoch 1233, Loss: 1090.5328369140625, Neurons: 23, Grad norm: 8.778e+01\n",
      "Epoch 1234, Loss: 1090.241943359375, Neurons: 23, Grad norm: 8.810e+01\n",
      "Epoch 1234, Loss: 1090.241943359375, Neurons: 23, Grad norm: 8.810e+01\n",
      "Epoch 1235, Loss: 1089.9468994140625, Neurons: 23, Grad norm: 8.841e+01\n",
      "Epoch 1235, Loss: 1089.9468994140625, Neurons: 23, Grad norm: 8.841e+01\n",
      "Epoch 1236, Loss: 1089.6480712890625, Neurons: 23, Grad norm: 8.873e+01\n",
      "Epoch 1236, Loss: 1089.6480712890625, Neurons: 23, Grad norm: 8.873e+01\n",
      "Epoch 1237, Loss: 1089.3448486328125, Neurons: 23, Grad norm: 8.905e+01\n",
      "Epoch 1237, Loss: 1089.3448486328125, Neurons: 23, Grad norm: 8.905e+01\n",
      "Epoch 1238, Loss: 1089.037353515625, Neurons: 23, Grad norm: 8.938e+01\n",
      "Epoch 1238, Loss: 1089.037353515625, Neurons: 23, Grad norm: 8.938e+01\n",
      "Epoch 1239, Loss: 1088.72607421875, Neurons: 23, Grad norm: 8.971e+01\n",
      "Epoch 1239, Loss: 1088.72607421875, Neurons: 23, Grad norm: 8.971e+01\n",
      "Epoch 1240, Loss: 1088.410400390625, Neurons: 23, Grad norm: 9.004e+01\n",
      "Epoch 1240, Loss: 1088.410400390625, Neurons: 23, Grad norm: 9.004e+01\n",
      "Epoch 1241, Loss: 1088.0908203125, Neurons: 23, Grad norm: 9.038e+01\n",
      "Epoch 1241, Loss: 1088.0908203125, Neurons: 23, Grad norm: 9.038e+01\n",
      "Epoch 1242, Loss: 1087.76708984375, Neurons: 23, Grad norm: 9.072e+01\n",
      "Epoch 1242, Loss: 1087.76708984375, Neurons: 23, Grad norm: 9.072e+01\n",
      "Epoch 1243, Loss: 1087.4393310546875, Neurons: 23, Grad norm: 9.108e+01\n",
      "Epoch 1243, Loss: 1087.4393310546875, Neurons: 23, Grad norm: 9.108e+01\n",
      "Epoch 1244, Loss: 1087.1072998046875, Neurons: 23, Grad norm: 9.144e+01\n",
      "Epoch 1244, Loss: 1087.1072998046875, Neurons: 23, Grad norm: 9.144e+01\n",
      "Epoch 1245, Loss: 1086.7713623046875, Neurons: 23, Grad norm: 9.182e+01\n",
      "Epoch 1245, Loss: 1086.7713623046875, Neurons: 23, Grad norm: 9.182e+01\n",
      "Epoch 1246, Loss: 1086.4310302734375, Neurons: 23, Grad norm: 9.220e+01\n",
      "Epoch 1246, Loss: 1086.4310302734375, Neurons: 23, Grad norm: 9.220e+01\n",
      "Epoch 1247, Loss: 1086.0867919921875, Neurons: 23, Grad norm: 9.260e+01\n",
      "Epoch 1247, Loss: 1086.0867919921875, Neurons: 23, Grad norm: 9.260e+01\n",
      "Epoch 1248, Loss: 1085.7381591796875, Neurons: 23, Grad norm: 9.300e+01\n",
      "Epoch 1248, Loss: 1085.7381591796875, Neurons: 23, Grad norm: 9.300e+01\n",
      "Epoch 1249, Loss: 1085.38525390625, Neurons: 23, Grad norm: 9.341e+01\n",
      "Epoch 1249, Loss: 1085.38525390625, Neurons: 23, Grad norm: 9.341e+01\n",
      "Epoch 1250, Loss: 1085.0283203125, Neurons: 23, Grad norm: 9.384e+01\n",
      "Epoch 1250, Loss: 1085.0283203125, Neurons: 23, Grad norm: 9.384e+01\n",
      "Epoch 1251, Loss: 1084.6668701171875, Neurons: 23, Grad norm: 9.426e+01\n",
      "Epoch 1251, Loss: 1084.6668701171875, Neurons: 23, Grad norm: 9.426e+01\n",
      "Epoch 1252, Loss: 1084.30126953125, Neurons: 23, Grad norm: 9.470e+01\n",
      "Epoch 1252, Loss: 1084.30126953125, Neurons: 23, Grad norm: 9.470e+01\n",
      "Epoch 1253, Loss: 1083.9312744140625, Neurons: 23, Grad norm: 9.514e+01\n",
      "Epoch 1253, Loss: 1083.9312744140625, Neurons: 23, Grad norm: 9.514e+01\n",
      "Epoch 1254, Loss: 1083.556884765625, Neurons: 23, Grad norm: 9.558e+01\n",
      "Epoch 1254, Loss: 1083.556884765625, Neurons: 23, Grad norm: 9.558e+01\n",
      "Epoch 1255, Loss: 1083.1781005859375, Neurons: 23, Grad norm: 9.603e+01\n",
      "Epoch 1255, Loss: 1083.1781005859375, Neurons: 23, Grad norm: 9.603e+01\n",
      "Epoch 1256, Loss: 1082.7947998046875, Neurons: 23, Grad norm: 9.649e+01\n",
      "Epoch 1256, Loss: 1082.7947998046875, Neurons: 23, Grad norm: 9.649e+01\n",
      "Epoch 1257, Loss: 1082.4068603515625, Neurons: 23, Grad norm: 9.695e+01\n",
      "Epoch 1257, Loss: 1082.4068603515625, Neurons: 23, Grad norm: 9.695e+01\n",
      "Epoch 1258, Loss: 1082.014404296875, Neurons: 23, Grad norm: 9.742e+01\n",
      "Epoch 1258, Loss: 1082.014404296875, Neurons: 23, Grad norm: 9.742e+01\n",
      "Epoch 1259, Loss: 1081.6173095703125, Neurons: 23, Grad norm: 9.789e+01\n",
      "Epoch 1259, Loss: 1081.6173095703125, Neurons: 23, Grad norm: 9.789e+01\n",
      "Epoch 1260, Loss: 1081.2154541015625, Neurons: 23, Grad norm: 9.838e+01\n",
      "Epoch 1260, Loss: 1081.2154541015625, Neurons: 23, Grad norm: 9.838e+01\n",
      "Epoch 1261, Loss: 1080.808837890625, Neurons: 23, Grad norm: 9.887e+01\n",
      "Epoch 1261, Loss: 1080.808837890625, Neurons: 23, Grad norm: 9.887e+01\n",
      "Epoch 1262, Loss: 1080.3973388671875, Neurons: 23, Grad norm: 9.938e+01\n",
      "Epoch 1262, Loss: 1080.3973388671875, Neurons: 23, Grad norm: 9.938e+01\n",
      "Epoch 1263, Loss: 1079.9810791015625, Neurons: 23, Grad norm: 9.989e+01\n",
      "Epoch 1263, Loss: 1079.9810791015625, Neurons: 23, Grad norm: 9.989e+01\n",
      "Epoch 1264, Loss: 1079.559814453125, Neurons: 23, Grad norm: 1.004e+02\n",
      "Epoch 1264, Loss: 1079.559814453125, Neurons: 23, Grad norm: 1.004e+02\n",
      "Epoch 1265, Loss: 1079.133544921875, Neurons: 23, Grad norm: 1.009e+02\n",
      "Epoch 1265, Loss: 1079.133544921875, Neurons: 23, Grad norm: 1.009e+02\n",
      "Epoch 1266, Loss: 1078.7020263671875, Neurons: 23, Grad norm: 1.015e+02\n",
      "Epoch 1266, Loss: 1078.7020263671875, Neurons: 23, Grad norm: 1.015e+02\n",
      "Epoch 1267, Loss: 1078.2655029296875, Neurons: 23, Grad norm: 1.020e+02\n",
      "Epoch 1267, Loss: 1078.2655029296875, Neurons: 23, Grad norm: 1.020e+02\n",
      "Epoch 1268, Loss: 1077.8238525390625, Neurons: 23, Grad norm: 1.026e+02\n",
      "Epoch 1268, Loss: 1077.8238525390625, Neurons: 23, Grad norm: 1.026e+02\n",
      "Epoch 1269, Loss: 1077.3765869140625, Neurons: 23, Grad norm: 1.032e+02\n",
      "Epoch 1269, Loss: 1077.3765869140625, Neurons: 23, Grad norm: 1.032e+02\n",
      "Epoch 1270, Loss: 1076.9241943359375, Neurons: 23, Grad norm: 1.037e+02\n",
      "Epoch 1270, Loss: 1076.9241943359375, Neurons: 23, Grad norm: 1.037e+02\n",
      "Epoch 1271, Loss: 1076.46630859375, Neurons: 23, Grad norm: 1.043e+02\n",
      "Epoch 1271, Loss: 1076.46630859375, Neurons: 23, Grad norm: 1.043e+02\n",
      "Epoch 1272, Loss: 1076.002685546875, Neurons: 23, Grad norm: 1.049e+02\n",
      "Epoch 1272, Loss: 1076.002685546875, Neurons: 23, Grad norm: 1.049e+02\n",
      "Epoch 1273, Loss: 1075.5335693359375, Neurons: 23, Grad norm: 1.055e+02\n",
      "Epoch 1273, Loss: 1075.5335693359375, Neurons: 23, Grad norm: 1.055e+02\n",
      "Epoch 1274, Loss: 1075.0587158203125, Neurons: 23, Grad norm: 1.061e+02\n",
      "Epoch 1274, Loss: 1075.0587158203125, Neurons: 23, Grad norm: 1.061e+02\n",
      "Epoch 1275, Loss: 1074.5780029296875, Neurons: 23, Grad norm: 1.067e+02\n",
      "Epoch 1275, Loss: 1074.5780029296875, Neurons: 23, Grad norm: 1.067e+02\n",
      "Epoch 1276, Loss: 1074.091552734375, Neurons: 23, Grad norm: 1.073e+02\n",
      "Epoch 1276, Loss: 1074.091552734375, Neurons: 23, Grad norm: 1.073e+02\n",
      "Epoch 1277, Loss: 1073.5989990234375, Neurons: 23, Grad norm: 1.079e+02\n",
      "Epoch 1277, Loss: 1073.5989990234375, Neurons: 23, Grad norm: 1.079e+02\n",
      "Epoch 1278, Loss: 1073.1005859375, Neurons: 23, Grad norm: 1.085e+02\n",
      "Epoch 1278, Loss: 1073.1005859375, Neurons: 23, Grad norm: 1.085e+02\n",
      "Epoch 1279, Loss: 1072.5958251953125, Neurons: 23, Grad norm: 1.092e+02\n",
      "Epoch 1279, Loss: 1072.5958251953125, Neurons: 23, Grad norm: 1.092e+02\n",
      "Epoch 1280, Loss: 1072.0848388671875, Neurons: 23, Grad norm: 1.098e+02\n",
      "Epoch 1280, Loss: 1072.0848388671875, Neurons: 23, Grad norm: 1.098e+02\n",
      "Epoch 1281, Loss: 1071.5675048828125, Neurons: 23, Grad norm: 1.105e+02\n",
      "Epoch 1281, Loss: 1071.5675048828125, Neurons: 23, Grad norm: 1.105e+02\n",
      "Epoch 1282, Loss: 1071.0438232421875, Neurons: 23, Grad norm: 1.111e+02\n",
      "Epoch 1282, Loss: 1071.0438232421875, Neurons: 23, Grad norm: 1.111e+02\n",
      "Epoch 1283, Loss: 1070.5135498046875, Neurons: 23, Grad norm: 1.118e+02\n",
      "Epoch 1283, Loss: 1070.5135498046875, Neurons: 23, Grad norm: 1.118e+02\n",
      "Epoch 1284, Loss: 1069.9766845703125, Neurons: 23, Grad norm: 1.125e+02\n",
      "Epoch 1284, Loss: 1069.9766845703125, Neurons: 23, Grad norm: 1.125e+02\n",
      "Epoch 1285, Loss: 1069.43310546875, Neurons: 23, Grad norm: 1.132e+02\n",
      "Epoch 1285, Loss: 1069.43310546875, Neurons: 23, Grad norm: 1.132e+02\n",
      "Epoch 1286, Loss: 1068.8828125, Neurons: 23, Grad norm: 1.138e+02\n",
      "Epoch 1286, Loss: 1068.8828125, Neurons: 23, Grad norm: 1.138e+02\n",
      "Epoch 1287, Loss: 1068.3253173828125, Neurons: 23, Grad norm: 1.145e+02\n",
      "Epoch 1287, Loss: 1068.3253173828125, Neurons: 23, Grad norm: 1.145e+02\n",
      "Epoch 1288, Loss: 1067.7611083984375, Neurons: 23, Grad norm: 1.152e+02\n",
      "Epoch 1288, Loss: 1067.7611083984375, Neurons: 23, Grad norm: 1.152e+02\n",
      "Epoch 1289, Loss: 1067.189697265625, Neurons: 23, Grad norm: 1.159e+02\n",
      "Epoch 1289, Loss: 1067.189697265625, Neurons: 23, Grad norm: 1.159e+02\n",
      "Epoch 1290, Loss: 1066.611083984375, Neurons: 23, Grad norm: 1.166e+02\n",
      "Epoch 1290, Loss: 1066.611083984375, Neurons: 23, Grad norm: 1.166e+02\n",
      "Epoch 1291, Loss: 1066.0250244140625, Neurons: 23, Grad norm: 1.174e+02\n",
      "Epoch 1291, Loss: 1066.0250244140625, Neurons: 23, Grad norm: 1.174e+02\n",
      "Epoch 1292, Loss: 1065.4315185546875, Neurons: 23, Grad norm: 1.181e+02\n",
      "Epoch 1292, Loss: 1065.4315185546875, Neurons: 23, Grad norm: 1.181e+02\n",
      "Epoch 1293, Loss: 1064.830810546875, Neurons: 23, Grad norm: 1.188e+02\n",
      "Epoch 1293, Loss: 1064.830810546875, Neurons: 23, Grad norm: 1.188e+02\n",
      "Epoch 1294, Loss: 1064.2222900390625, Neurons: 23, Grad norm: 1.195e+02\n",
      "Epoch 1294, Loss: 1064.2222900390625, Neurons: 23, Grad norm: 1.195e+02\n",
      "Epoch 1295, Loss: 1063.6060791015625, Neurons: 23, Grad norm: 1.203e+02\n",
      "Epoch 1295, Loss: 1063.6060791015625, Neurons: 23, Grad norm: 1.203e+02\n",
      "Epoch 1296, Loss: 1062.9818115234375, Neurons: 23, Grad norm: 1.210e+02\n",
      "Epoch 1296, Loss: 1062.9818115234375, Neurons: 23, Grad norm: 1.210e+02\n",
      "Epoch 1297, Loss: 1062.3499755859375, Neurons: 23, Grad norm: 1.218e+02\n",
      "Epoch 1297, Loss: 1062.3499755859375, Neurons: 23, Grad norm: 1.218e+02\n",
      "Epoch 1298, Loss: 1061.7099609375, Neurons: 23, Grad norm: 1.225e+02\n",
      "Epoch 1298, Loss: 1061.7099609375, Neurons: 23, Grad norm: 1.225e+02\n",
      "Epoch 1299, Loss: 1061.0616455078125, Neurons: 23, Grad norm: 1.233e+02\n",
      "Epoch 1299, Loss: 1061.0616455078125, Neurons: 23, Grad norm: 1.233e+02\n",
      "Epoch 1299, Test loss: 1072.5430908203125\n",
      "Epoch 1299, Test loss: 1072.5430908203125\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "network shape updated to :[10, 13, 1]\n",
      "network shape updated to :[10, 13, 1]\n",
      "Epoch 1300, Loss: 1060.477294921875, Neurons: 24, Grad norm: 1.236e+02\n",
      "Epoch 1300, Loss: 1060.477294921875, Neurons: 24, Grad norm: 1.236e+02\n",
      "Epoch 1301, Loss: 1060.3519287109375, Neurons: 24, Grad norm: 1.237e+02\n",
      "Epoch 1301, Loss: 1060.3519287109375, Neurons: 24, Grad norm: 1.237e+02\n",
      "Epoch 1302, Loss: 1060.220458984375, Neurons: 24, Grad norm: 1.239e+02\n",
      "Epoch 1302, Loss: 1060.220458984375, Neurons: 24, Grad norm: 1.239e+02\n",
      "Epoch 1303, Loss: 1060.08251953125, Neurons: 24, Grad norm: 1.242e+02\n",
      "Epoch 1303, Loss: 1060.08251953125, Neurons: 24, Grad norm: 1.242e+02\n",
      "Epoch 1304, Loss: 1059.9383544921875, Neurons: 24, Grad norm: 1.244e+02\n",
      "Epoch 1304, Loss: 1059.9383544921875, Neurons: 24, Grad norm: 1.244e+02\n",
      "Epoch 1305, Loss: 1059.787353515625, Neurons: 24, Grad norm: 1.245e+02\n",
      "Epoch 1305, Loss: 1059.787353515625, Neurons: 24, Grad norm: 1.245e+02\n",
      "Epoch 1306, Loss: 1059.6298828125, Neurons: 24, Grad norm: 1.246e+02\n",
      "Epoch 1306, Loss: 1059.6298828125, Neurons: 24, Grad norm: 1.246e+02\n",
      "Epoch 1307, Loss: 1059.4658203125, Neurons: 24, Grad norm: 1.248e+02\n",
      "Epoch 1307, Loss: 1059.4658203125, Neurons: 24, Grad norm: 1.248e+02\n",
      "Epoch 1308, Loss: 1059.2947998046875, Neurons: 24, Grad norm: 1.250e+02\n",
      "Epoch 1308, Loss: 1059.2947998046875, Neurons: 24, Grad norm: 1.250e+02\n",
      "Epoch 1309, Loss: 1059.1171875, Neurons: 24, Grad norm: 1.251e+02\n",
      "Epoch 1309, Loss: 1059.1171875, Neurons: 24, Grad norm: 1.251e+02\n",
      "Epoch 1310, Loss: 1058.93310546875, Neurons: 24, Grad norm: 1.253e+02\n",
      "Epoch 1310, Loss: 1058.93310546875, Neurons: 24, Grad norm: 1.253e+02\n",
      "Epoch 1311, Loss: 1058.7420654296875, Neurons: 24, Grad norm: 1.254e+02\n",
      "Epoch 1311, Loss: 1058.7420654296875, Neurons: 24, Grad norm: 1.254e+02\n",
      "Epoch 1312, Loss: 1058.544677734375, Neurons: 24, Grad norm: 1.256e+02\n",
      "Epoch 1312, Loss: 1058.544677734375, Neurons: 24, Grad norm: 1.256e+02\n",
      "Epoch 1313, Loss: 1058.3406982421875, Neurons: 24, Grad norm: 1.258e+02\n",
      "Epoch 1313, Loss: 1058.3406982421875, Neurons: 24, Grad norm: 1.258e+02\n",
      "Epoch 1314, Loss: 1058.130126953125, Neurons: 24, Grad norm: 1.261e+02\n",
      "Epoch 1314, Loss: 1058.130126953125, Neurons: 24, Grad norm: 1.261e+02\n",
      "Epoch 1315, Loss: 1057.913330078125, Neurons: 24, Grad norm: 1.263e+02\n",
      "Epoch 1315, Loss: 1057.913330078125, Neurons: 24, Grad norm: 1.263e+02\n",
      "Epoch 1316, Loss: 1057.6898193359375, Neurons: 24, Grad norm: 1.265e+02\n",
      "Epoch 1316, Loss: 1057.6898193359375, Neurons: 24, Grad norm: 1.265e+02\n",
      "Epoch 1317, Loss: 1057.460205078125, Neurons: 24, Grad norm: 1.267e+02\n",
      "Epoch 1317, Loss: 1057.460205078125, Neurons: 24, Grad norm: 1.267e+02\n",
      "Epoch 1318, Loss: 1057.2242431640625, Neurons: 24, Grad norm: 1.270e+02\n",
      "Epoch 1318, Loss: 1057.2242431640625, Neurons: 24, Grad norm: 1.270e+02\n",
      "Epoch 1319, Loss: 1056.9820556640625, Neurons: 24, Grad norm: 1.272e+02\n",
      "Epoch 1319, Loss: 1056.9820556640625, Neurons: 24, Grad norm: 1.272e+02\n",
      "Epoch 1320, Loss: 1056.7337646484375, Neurons: 24, Grad norm: 1.275e+02\n",
      "Epoch 1320, Loss: 1056.7337646484375, Neurons: 24, Grad norm: 1.275e+02\n",
      "Epoch 1321, Loss: 1056.4794921875, Neurons: 24, Grad norm: 1.277e+02\n",
      "Epoch 1321, Loss: 1056.4794921875, Neurons: 24, Grad norm: 1.277e+02\n",
      "Epoch 1322, Loss: 1056.2191162109375, Neurons: 24, Grad norm: 1.280e+02\n",
      "Epoch 1322, Loss: 1056.2191162109375, Neurons: 24, Grad norm: 1.280e+02\n",
      "Epoch 1323, Loss: 1055.9527587890625, Neurons: 24, Grad norm: 1.283e+02\n",
      "Epoch 1323, Loss: 1055.9527587890625, Neurons: 24, Grad norm: 1.283e+02\n",
      "Epoch 1324, Loss: 1055.6806640625, Neurons: 24, Grad norm: 1.285e+02\n",
      "Epoch 1324, Loss: 1055.6806640625, Neurons: 24, Grad norm: 1.285e+02\n",
      "Epoch 1325, Loss: 1055.402587890625, Neurons: 24, Grad norm: 1.288e+02\n",
      "Epoch 1325, Loss: 1055.402587890625, Neurons: 24, Grad norm: 1.288e+02\n",
      "Epoch 1326, Loss: 1055.1187744140625, Neurons: 24, Grad norm: 1.291e+02\n",
      "Epoch 1326, Loss: 1055.1187744140625, Neurons: 24, Grad norm: 1.291e+02\n",
      "Epoch 1327, Loss: 1054.829345703125, Neurons: 24, Grad norm: 1.294e+02\n",
      "Epoch 1327, Loss: 1054.829345703125, Neurons: 24, Grad norm: 1.294e+02\n",
      "Epoch 1328, Loss: 1054.5340576171875, Neurons: 24, Grad norm: 1.297e+02\n",
      "Epoch 1328, Loss: 1054.5340576171875, Neurons: 24, Grad norm: 1.297e+02\n",
      "Epoch 1329, Loss: 1054.2330322265625, Neurons: 24, Grad norm: 1.300e+02\n",
      "Epoch 1329, Loss: 1054.2330322265625, Neurons: 24, Grad norm: 1.300e+02\n",
      "Epoch 1330, Loss: 1053.926513671875, Neurons: 24, Grad norm: 1.303e+02\n",
      "Epoch 1330, Loss: 1053.926513671875, Neurons: 24, Grad norm: 1.303e+02\n",
      "Epoch 1331, Loss: 1053.6143798828125, Neurons: 24, Grad norm: 1.306e+02\n",
      "Epoch 1331, Loss: 1053.6143798828125, Neurons: 24, Grad norm: 1.306e+02\n",
      "Epoch 1332, Loss: 1053.2967529296875, Neurons: 24, Grad norm: 1.309e+02\n",
      "Epoch 1332, Loss: 1053.2967529296875, Neurons: 24, Grad norm: 1.309e+02\n",
      "Epoch 1333, Loss: 1052.9735107421875, Neurons: 24, Grad norm: 1.312e+02\n",
      "Epoch 1333, Loss: 1052.9735107421875, Neurons: 24, Grad norm: 1.312e+02\n",
      "Epoch 1334, Loss: 1052.644775390625, Neurons: 24, Grad norm: 1.316e+02\n",
      "Epoch 1334, Loss: 1052.644775390625, Neurons: 24, Grad norm: 1.316e+02\n",
      "Epoch 1335, Loss: 1052.310546875, Neurons: 24, Grad norm: 1.319e+02\n",
      "Epoch 1335, Loss: 1052.310546875, Neurons: 24, Grad norm: 1.319e+02\n",
      "Epoch 1336, Loss: 1051.970947265625, Neurons: 24, Grad norm: 1.323e+02\n",
      "Epoch 1336, Loss: 1051.970947265625, Neurons: 24, Grad norm: 1.323e+02\n",
      "Epoch 1337, Loss: 1051.6258544921875, Neurons: 24, Grad norm: 1.326e+02\n",
      "Epoch 1337, Loss: 1051.6258544921875, Neurons: 24, Grad norm: 1.326e+02\n",
      "Epoch 1338, Loss: 1051.2752685546875, Neurons: 24, Grad norm: 1.330e+02\n",
      "Epoch 1338, Loss: 1051.2752685546875, Neurons: 24, Grad norm: 1.330e+02\n",
      "Epoch 1339, Loss: 1050.91943359375, Neurons: 24, Grad norm: 1.333e+02\n",
      "Epoch 1339, Loss: 1050.91943359375, Neurons: 24, Grad norm: 1.333e+02\n",
      "Epoch 1340, Loss: 1050.55810546875, Neurons: 24, Grad norm: 1.337e+02\n",
      "Epoch 1340, Loss: 1050.55810546875, Neurons: 24, Grad norm: 1.337e+02\n",
      "Epoch 1341, Loss: 1050.1912841796875, Neurons: 24, Grad norm: 1.340e+02\n",
      "Epoch 1341, Loss: 1050.1912841796875, Neurons: 24, Grad norm: 1.340e+02\n",
      "Epoch 1342, Loss: 1049.819091796875, Neurons: 24, Grad norm: 1.344e+02\n",
      "Epoch 1342, Loss: 1049.819091796875, Neurons: 24, Grad norm: 1.344e+02\n",
      "Epoch 1343, Loss: 1049.4415283203125, Neurons: 24, Grad norm: 1.348e+02\n",
      "Epoch 1343, Loss: 1049.4415283203125, Neurons: 24, Grad norm: 1.348e+02\n",
      "Epoch 1344, Loss: 1049.05859375, Neurons: 24, Grad norm: 1.352e+02\n",
      "Epoch 1344, Loss: 1049.05859375, Neurons: 24, Grad norm: 1.352e+02\n",
      "Epoch 1345, Loss: 1048.670166015625, Neurons: 24, Grad norm: 1.356e+02\n",
      "Epoch 1345, Loss: 1048.670166015625, Neurons: 24, Grad norm: 1.356e+02\n",
      "Epoch 1346, Loss: 1048.2763671875, Neurons: 24, Grad norm: 1.360e+02\n",
      "Epoch 1346, Loss: 1048.2763671875, Neurons: 24, Grad norm: 1.360e+02\n",
      "Epoch 1347, Loss: 1047.8770751953125, Neurons: 24, Grad norm: 1.363e+02\n",
      "Epoch 1347, Loss: 1047.8770751953125, Neurons: 24, Grad norm: 1.363e+02\n",
      "Epoch 1348, Loss: 1047.472412109375, Neurons: 24, Grad norm: 1.368e+02\n",
      "Epoch 1348, Loss: 1047.472412109375, Neurons: 24, Grad norm: 1.368e+02\n",
      "Epoch 1349, Loss: 1047.0623779296875, Neurons: 24, Grad norm: 1.372e+02\n",
      "Epoch 1349, Loss: 1047.0623779296875, Neurons: 24, Grad norm: 1.372e+02\n",
      "Epoch 1350, Loss: 1046.646728515625, Neurons: 24, Grad norm: 1.376e+02\n",
      "Epoch 1350, Loss: 1046.646728515625, Neurons: 24, Grad norm: 1.376e+02\n",
      "Epoch 1351, Loss: 1046.2257080078125, Neurons: 24, Grad norm: 1.380e+02\n",
      "Epoch 1351, Loss: 1046.2257080078125, Neurons: 24, Grad norm: 1.380e+02\n",
      "Epoch 1352, Loss: 1045.7991943359375, Neurons: 24, Grad norm: 1.384e+02\n",
      "Epoch 1352, Loss: 1045.7991943359375, Neurons: 24, Grad norm: 1.384e+02\n",
      "Epoch 1353, Loss: 1045.3670654296875, Neurons: 24, Grad norm: 1.388e+02\n",
      "Epoch 1353, Loss: 1045.3670654296875, Neurons: 24, Grad norm: 1.388e+02\n",
      "Epoch 1354, Loss: 1044.9295654296875, Neurons: 24, Grad norm: 1.392e+02\n",
      "Epoch 1354, Loss: 1044.9295654296875, Neurons: 24, Grad norm: 1.392e+02\n",
      "Epoch 1355, Loss: 1044.486572265625, Neurons: 24, Grad norm: 1.397e+02\n",
      "Epoch 1355, Loss: 1044.486572265625, Neurons: 24, Grad norm: 1.397e+02\n",
      "Epoch 1356, Loss: 1044.037841796875, Neurons: 24, Grad norm: 1.401e+02\n",
      "Epoch 1356, Loss: 1044.037841796875, Neurons: 24, Grad norm: 1.401e+02\n",
      "Epoch 1357, Loss: 1043.58349609375, Neurons: 24, Grad norm: 1.405e+02\n",
      "Epoch 1357, Loss: 1043.58349609375, Neurons: 24, Grad norm: 1.405e+02\n",
      "Epoch 1358, Loss: 1043.1236572265625, Neurons: 24, Grad norm: 1.410e+02\n",
      "Epoch 1358, Loss: 1043.1236572265625, Neurons: 24, Grad norm: 1.410e+02\n",
      "Epoch 1359, Loss: 1042.658203125, Neurons: 24, Grad norm: 1.414e+02\n",
      "Epoch 1359, Loss: 1042.658203125, Neurons: 24, Grad norm: 1.414e+02\n",
      "Epoch 1360, Loss: 1042.18701171875, Neurons: 24, Grad norm: 1.419e+02\n",
      "Epoch 1360, Loss: 1042.18701171875, Neurons: 24, Grad norm: 1.419e+02\n",
      "Epoch 1361, Loss: 1041.710205078125, Neurons: 24, Grad norm: 1.423e+02\n",
      "Epoch 1361, Loss: 1041.710205078125, Neurons: 24, Grad norm: 1.423e+02\n",
      "Epoch 1362, Loss: 1041.2275390625, Neurons: 24, Grad norm: 1.428e+02\n",
      "Epoch 1362, Loss: 1041.2275390625, Neurons: 24, Grad norm: 1.428e+02\n",
      "Epoch 1363, Loss: 1040.7392578125, Neurons: 24, Grad norm: 1.432e+02\n",
      "Epoch 1363, Loss: 1040.7392578125, Neurons: 24, Grad norm: 1.432e+02\n",
      "Epoch 1364, Loss: 1040.2451171875, Neurons: 24, Grad norm: 1.437e+02\n",
      "Epoch 1364, Loss: 1040.2451171875, Neurons: 24, Grad norm: 1.437e+02\n",
      "Epoch 1365, Loss: 1039.7451171875, Neurons: 24, Grad norm: 1.441e+02\n",
      "Epoch 1365, Loss: 1039.7451171875, Neurons: 24, Grad norm: 1.441e+02\n",
      "Epoch 1366, Loss: 1039.239501953125, Neurons: 24, Grad norm: 1.446e+02\n",
      "Epoch 1366, Loss: 1039.239501953125, Neurons: 24, Grad norm: 1.446e+02\n",
      "Epoch 1367, Loss: 1038.727783203125, Neurons: 24, Grad norm: 1.450e+02\n",
      "Epoch 1367, Loss: 1038.727783203125, Neurons: 24, Grad norm: 1.450e+02\n",
      "Epoch 1368, Loss: 1038.210205078125, Neurons: 24, Grad norm: 1.455e+02\n",
      "Epoch 1368, Loss: 1038.210205078125, Neurons: 24, Grad norm: 1.455e+02\n",
      "Epoch 1369, Loss: 1037.686767578125, Neurons: 24, Grad norm: 1.460e+02\n",
      "Epoch 1369, Loss: 1037.686767578125, Neurons: 24, Grad norm: 1.460e+02\n",
      "Epoch 1370, Loss: 1037.1572265625, Neurons: 24, Grad norm: 1.464e+02\n",
      "Epoch 1370, Loss: 1037.1572265625, Neurons: 24, Grad norm: 1.464e+02\n",
      "Epoch 1371, Loss: 1036.6217041015625, Neurons: 24, Grad norm: 1.469e+02\n",
      "Epoch 1371, Loss: 1036.6217041015625, Neurons: 24, Grad norm: 1.469e+02\n",
      "Epoch 1372, Loss: 1036.080078125, Neurons: 24, Grad norm: 1.474e+02\n",
      "Epoch 1372, Loss: 1036.080078125, Neurons: 24, Grad norm: 1.474e+02\n",
      "Epoch 1373, Loss: 1035.5323486328125, Neurons: 24, Grad norm: 1.478e+02\n",
      "Epoch 1373, Loss: 1035.5323486328125, Neurons: 24, Grad norm: 1.478e+02\n",
      "Epoch 1374, Loss: 1034.978515625, Neurons: 24, Grad norm: 1.483e+02\n",
      "Epoch 1374, Loss: 1034.978515625, Neurons: 24, Grad norm: 1.483e+02\n",
      "Epoch 1375, Loss: 1034.41845703125, Neurons: 24, Grad norm: 1.488e+02\n",
      "Epoch 1375, Loss: 1034.41845703125, Neurons: 24, Grad norm: 1.488e+02\n",
      "Epoch 1376, Loss: 1033.852294921875, Neurons: 24, Grad norm: 1.493e+02\n",
      "Epoch 1376, Loss: 1033.852294921875, Neurons: 24, Grad norm: 1.493e+02\n",
      "Epoch 1377, Loss: 1033.2796630859375, Neurons: 24, Grad norm: 1.497e+02\n",
      "Epoch 1377, Loss: 1033.2796630859375, Neurons: 24, Grad norm: 1.497e+02\n",
      "Epoch 1378, Loss: 1032.700927734375, Neurons: 24, Grad norm: 1.502e+02\n",
      "Epoch 1378, Loss: 1032.700927734375, Neurons: 24, Grad norm: 1.502e+02\n",
      "Epoch 1379, Loss: 1032.11572265625, Neurons: 24, Grad norm: 1.507e+02\n",
      "Epoch 1379, Loss: 1032.11572265625, Neurons: 24, Grad norm: 1.507e+02\n",
      "Epoch 1380, Loss: 1031.524169921875, Neurons: 24, Grad norm: 1.512e+02\n",
      "Epoch 1380, Loss: 1031.524169921875, Neurons: 24, Grad norm: 1.512e+02\n",
      "Epoch 1381, Loss: 1030.926025390625, Neurons: 24, Grad norm: 1.516e+02\n",
      "Epoch 1381, Loss: 1030.926025390625, Neurons: 24, Grad norm: 1.516e+02\n",
      "Epoch 1382, Loss: 1030.3216552734375, Neurons: 24, Grad norm: 1.521e+02\n",
      "Epoch 1382, Loss: 1030.3216552734375, Neurons: 24, Grad norm: 1.521e+02\n",
      "Epoch 1383, Loss: 1029.710693359375, Neurons: 24, Grad norm: 1.526e+02\n",
      "Epoch 1383, Loss: 1029.710693359375, Neurons: 24, Grad norm: 1.526e+02\n",
      "Epoch 1384, Loss: 1029.093017578125, Neurons: 24, Grad norm: 1.530e+02\n",
      "Epoch 1384, Loss: 1029.093017578125, Neurons: 24, Grad norm: 1.530e+02\n",
      "Epoch 1385, Loss: 1028.46875, Neurons: 24, Grad norm: 1.535e+02\n",
      "Epoch 1385, Loss: 1028.46875, Neurons: 24, Grad norm: 1.535e+02\n",
      "Epoch 1386, Loss: 1027.837890625, Neurons: 24, Grad norm: 1.540e+02\n",
      "Epoch 1386, Loss: 1027.837890625, Neurons: 24, Grad norm: 1.540e+02\n",
      "Epoch 1387, Loss: 1027.200439453125, Neurons: 24, Grad norm: 1.545e+02\n",
      "Epoch 1387, Loss: 1027.200439453125, Neurons: 24, Grad norm: 1.545e+02\n",
      "Epoch 1388, Loss: 1026.55615234375, Neurons: 24, Grad norm: 1.549e+02\n",
      "Epoch 1388, Loss: 1026.55615234375, Neurons: 24, Grad norm: 1.549e+02\n",
      "Epoch 1389, Loss: 1025.905029296875, Neurons: 24, Grad norm: 1.554e+02\n",
      "Epoch 1389, Loss: 1025.905029296875, Neurons: 24, Grad norm: 1.554e+02\n",
      "Epoch 1390, Loss: 1025.2470703125, Neurons: 24, Grad norm: 1.559e+02\n",
      "Epoch 1390, Loss: 1025.2470703125, Neurons: 24, Grad norm: 1.559e+02\n",
      "Epoch 1391, Loss: 1024.582275390625, Neurons: 24, Grad norm: 1.563e+02\n",
      "Epoch 1391, Loss: 1024.582275390625, Neurons: 24, Grad norm: 1.563e+02\n",
      "Epoch 1392, Loss: 1023.91064453125, Neurons: 24, Grad norm: 1.568e+02\n",
      "Epoch 1392, Loss: 1023.91064453125, Neurons: 24, Grad norm: 1.568e+02\n",
      "Epoch 1393, Loss: 1023.23193359375, Neurons: 24, Grad norm: 1.573e+02\n",
      "Epoch 1393, Loss: 1023.23193359375, Neurons: 24, Grad norm: 1.573e+02\n",
      "Epoch 1394, Loss: 1022.5462646484375, Neurons: 24, Grad norm: 1.577e+02\n",
      "Epoch 1394, Loss: 1022.5462646484375, Neurons: 24, Grad norm: 1.577e+02\n",
      "Epoch 1395, Loss: 1021.853515625, Neurons: 24, Grad norm: 1.582e+02\n",
      "Epoch 1395, Loss: 1021.853515625, Neurons: 24, Grad norm: 1.582e+02\n",
      "Epoch 1396, Loss: 1021.153564453125, Neurons: 24, Grad norm: 1.586e+02\n",
      "Epoch 1396, Loss: 1021.153564453125, Neurons: 24, Grad norm: 1.586e+02\n",
      "Epoch 1397, Loss: 1020.4465942382812, Neurons: 24, Grad norm: 1.591e+02\n",
      "Epoch 1397, Loss: 1020.4465942382812, Neurons: 24, Grad norm: 1.591e+02\n",
      "Epoch 1398, Loss: 1019.732421875, Neurons: 24, Grad norm: 1.595e+02\n",
      "Epoch 1398, Loss: 1019.732421875, Neurons: 24, Grad norm: 1.595e+02\n",
      "Epoch 1399, Loss: 1019.010986328125, Neurons: 24, Grad norm: 1.600e+02\n",
      "Epoch 1399, Loss: 1019.010986328125, Neurons: 24, Grad norm: 1.600e+02\n",
      "Epoch 1399, Test loss: 1029.6815185546875\n",
      "Epoch 1399, Test loss: 1029.6815185546875\n",
      "Added neuron to hidden layer 2 with activation sin\n",
      "Added neuron to hidden layer 2 with activation sin\n",
      "network shape updated to :[10, 14, 1]\n",
      "network shape updated to :[10, 14, 1]\n",
      "Epoch 1400, Loss: 1018.2058715820312, Neurons: 25, Grad norm: 1.685e+02\n",
      "Epoch 1400, Loss: 1018.2058715820312, Neurons: 25, Grad norm: 1.685e+02\n",
      "Epoch 1401, Loss: 1018.044677734375, Neurons: 25, Grad norm: 1.683e+02\n",
      "Epoch 1401, Loss: 1018.044677734375, Neurons: 25, Grad norm: 1.683e+02\n",
      "Epoch 1402, Loss: 1017.8765258789062, Neurons: 25, Grad norm: 1.683e+02\n",
      "Epoch 1402, Loss: 1017.8765258789062, Neurons: 25, Grad norm: 1.683e+02\n",
      "Epoch 1403, Loss: 1017.6998901367188, Neurons: 25, Grad norm: 1.684e+02\n",
      "Epoch 1403, Loss: 1017.6998901367188, Neurons: 25, Grad norm: 1.684e+02\n",
      "Epoch 1404, Loss: 1017.5146484375, Neurons: 25, Grad norm: 1.686e+02\n",
      "Epoch 1404, Loss: 1017.5146484375, Neurons: 25, Grad norm: 1.686e+02\n",
      "Epoch 1405, Loss: 1017.3212280273438, Neurons: 25, Grad norm: 1.687e+02\n",
      "Epoch 1405, Loss: 1017.3212280273438, Neurons: 25, Grad norm: 1.687e+02\n",
      "Epoch 1406, Loss: 1017.1196899414062, Neurons: 25, Grad norm: 1.689e+02\n",
      "Epoch 1406, Loss: 1017.1196899414062, Neurons: 25, Grad norm: 1.689e+02\n",
      "Epoch 1407, Loss: 1016.909912109375, Neurons: 25, Grad norm: 1.690e+02\n",
      "Epoch 1407, Loss: 1016.909912109375, Neurons: 25, Grad norm: 1.690e+02\n",
      "Epoch 1408, Loss: 1016.6918334960938, Neurons: 25, Grad norm: 1.691e+02\n",
      "Epoch 1408, Loss: 1016.6918334960938, Neurons: 25, Grad norm: 1.691e+02\n",
      "Epoch 1409, Loss: 1016.4655151367188, Neurons: 25, Grad norm: 1.691e+02\n",
      "Epoch 1409, Loss: 1016.4655151367188, Neurons: 25, Grad norm: 1.691e+02\n",
      "Epoch 1410, Loss: 1016.2307739257812, Neurons: 25, Grad norm: 1.691e+02\n",
      "Epoch 1410, Loss: 1016.2307739257812, Neurons: 25, Grad norm: 1.691e+02\n",
      "Epoch 1411, Loss: 1015.9879150390625, Neurons: 25, Grad norm: 1.692e+02\n",
      "Epoch 1411, Loss: 1015.9879150390625, Neurons: 25, Grad norm: 1.692e+02\n",
      "Epoch 1412, Loss: 1015.7369995117188, Neurons: 25, Grad norm: 1.692e+02\n",
      "Epoch 1412, Loss: 1015.7369995117188, Neurons: 25, Grad norm: 1.692e+02\n",
      "Epoch 1413, Loss: 1015.4779663085938, Neurons: 25, Grad norm: 1.693e+02\n",
      "Epoch 1413, Loss: 1015.4779663085938, Neurons: 25, Grad norm: 1.693e+02\n",
      "Epoch 1414, Loss: 1015.2110595703125, Neurons: 25, Grad norm: 1.695e+02\n",
      "Epoch 1414, Loss: 1015.2110595703125, Neurons: 25, Grad norm: 1.695e+02\n",
      "Epoch 1415, Loss: 1014.9361572265625, Neurons: 25, Grad norm: 1.696e+02\n",
      "Epoch 1415, Loss: 1014.9361572265625, Neurons: 25, Grad norm: 1.696e+02\n",
      "Epoch 1416, Loss: 1014.653564453125, Neurons: 25, Grad norm: 1.698e+02\n",
      "Epoch 1416, Loss: 1014.653564453125, Neurons: 25, Grad norm: 1.698e+02\n",
      "Epoch 1417, Loss: 1014.3631591796875, Neurons: 25, Grad norm: 1.701e+02\n",
      "Epoch 1417, Loss: 1014.3631591796875, Neurons: 25, Grad norm: 1.701e+02\n",
      "Epoch 1418, Loss: 1014.0653076171875, Neurons: 25, Grad norm: 1.703e+02\n",
      "Epoch 1418, Loss: 1014.0653076171875, Neurons: 25, Grad norm: 1.703e+02\n",
      "Epoch 1419, Loss: 1013.7598876953125, Neurons: 25, Grad norm: 1.705e+02\n",
      "Epoch 1419, Loss: 1013.7598876953125, Neurons: 25, Grad norm: 1.705e+02\n",
      "Epoch 1420, Loss: 1013.4470825195312, Neurons: 25, Grad norm: 1.706e+02\n",
      "Epoch 1420, Loss: 1013.4470825195312, Neurons: 25, Grad norm: 1.706e+02\n",
      "Epoch 1421, Loss: 1013.1270141601562, Neurons: 25, Grad norm: 1.708e+02\n",
      "Epoch 1421, Loss: 1013.1270141601562, Neurons: 25, Grad norm: 1.708e+02\n",
      "Epoch 1422, Loss: 1012.7997436523438, Neurons: 25, Grad norm: 1.709e+02\n",
      "Epoch 1422, Loss: 1012.7997436523438, Neurons: 25, Grad norm: 1.709e+02\n",
      "Epoch 1423, Loss: 1012.4652709960938, Neurons: 25, Grad norm: 1.711e+02\n",
      "Epoch 1423, Loss: 1012.4652709960938, Neurons: 25, Grad norm: 1.711e+02\n",
      "Epoch 1424, Loss: 1012.1239013671875, Neurons: 25, Grad norm: 1.712e+02\n",
      "Epoch 1424, Loss: 1012.1239013671875, Neurons: 25, Grad norm: 1.712e+02\n",
      "Epoch 1425, Loss: 1011.7755737304688, Neurons: 25, Grad norm: 1.714e+02\n",
      "Epoch 1425, Loss: 1011.7755737304688, Neurons: 25, Grad norm: 1.714e+02\n",
      "Epoch 1426, Loss: 1011.4202880859375, Neurons: 25, Grad norm: 1.716e+02\n",
      "Epoch 1426, Loss: 1011.4202880859375, Neurons: 25, Grad norm: 1.716e+02\n",
      "Epoch 1427, Loss: 1011.0582275390625, Neurons: 25, Grad norm: 1.718e+02\n",
      "Epoch 1427, Loss: 1011.0582275390625, Neurons: 25, Grad norm: 1.718e+02\n",
      "Epoch 1428, Loss: 1010.689453125, Neurons: 25, Grad norm: 1.720e+02\n",
      "Epoch 1428, Loss: 1010.689453125, Neurons: 25, Grad norm: 1.720e+02\n",
      "Epoch 1429, Loss: 1010.31396484375, Neurons: 25, Grad norm: 1.722e+02\n",
      "Epoch 1429, Loss: 1010.31396484375, Neurons: 25, Grad norm: 1.722e+02\n",
      "Epoch 1430, Loss: 1009.9320068359375, Neurons: 25, Grad norm: 1.724e+02\n",
      "Epoch 1430, Loss: 1009.9320068359375, Neurons: 25, Grad norm: 1.724e+02\n",
      "Epoch 1431, Loss: 1009.5433959960938, Neurons: 25, Grad norm: 1.726e+02\n",
      "Epoch 1431, Loss: 1009.5433959960938, Neurons: 25, Grad norm: 1.726e+02\n",
      "Epoch 1432, Loss: 1009.1484375, Neurons: 25, Grad norm: 1.727e+02\n",
      "Epoch 1432, Loss: 1009.1484375, Neurons: 25, Grad norm: 1.727e+02\n",
      "Epoch 1433, Loss: 1008.7469482421875, Neurons: 25, Grad norm: 1.729e+02\n",
      "Epoch 1433, Loss: 1008.7469482421875, Neurons: 25, Grad norm: 1.729e+02\n",
      "Epoch 1434, Loss: 1008.3390502929688, Neurons: 25, Grad norm: 1.730e+02\n",
      "Epoch 1434, Loss: 1008.3390502929688, Neurons: 25, Grad norm: 1.730e+02\n",
      "Epoch 1435, Loss: 1007.9249267578125, Neurons: 25, Grad norm: 1.732e+02\n",
      "Epoch 1435, Loss: 1007.9249267578125, Neurons: 25, Grad norm: 1.732e+02\n",
      "Epoch 1436, Loss: 1007.50439453125, Neurons: 25, Grad norm: 1.734e+02\n",
      "Epoch 1436, Loss: 1007.50439453125, Neurons: 25, Grad norm: 1.734e+02\n",
      "Epoch 1437, Loss: 1007.0778198242188, Neurons: 25, Grad norm: 1.735e+02\n",
      "Epoch 1437, Loss: 1007.0778198242188, Neurons: 25, Grad norm: 1.735e+02\n",
      "Epoch 1438, Loss: 1006.6448974609375, Neurons: 25, Grad norm: 1.738e+02\n",
      "Epoch 1438, Loss: 1006.6448974609375, Neurons: 25, Grad norm: 1.738e+02\n",
      "Epoch 1439, Loss: 1006.2059326171875, Neurons: 25, Grad norm: 1.740e+02\n",
      "Epoch 1439, Loss: 1006.2059326171875, Neurons: 25, Grad norm: 1.740e+02\n",
      "Epoch 1440, Loss: 1005.7606811523438, Neurons: 25, Grad norm: 1.742e+02\n",
      "Epoch 1440, Loss: 1005.7606811523438, Neurons: 25, Grad norm: 1.742e+02\n",
      "Epoch 1441, Loss: 1005.3093872070312, Neurons: 25, Grad norm: 1.744e+02\n",
      "Epoch 1441, Loss: 1005.3093872070312, Neurons: 25, Grad norm: 1.744e+02\n",
      "Epoch 1442, Loss: 1004.8519287109375, Neurons: 25, Grad norm: 1.746e+02\n",
      "Epoch 1442, Loss: 1004.8519287109375, Neurons: 25, Grad norm: 1.746e+02\n",
      "Epoch 1443, Loss: 1004.3884887695312, Neurons: 25, Grad norm: 1.748e+02\n",
      "Epoch 1443, Loss: 1004.3884887695312, Neurons: 25, Grad norm: 1.748e+02\n",
      "Epoch 1444, Loss: 1003.9189453125, Neurons: 25, Grad norm: 1.750e+02\n",
      "Epoch 1444, Loss: 1003.9189453125, Neurons: 25, Grad norm: 1.750e+02\n",
      "Epoch 1445, Loss: 1003.443359375, Neurons: 25, Grad norm: 1.751e+02\n",
      "Epoch 1445, Loss: 1003.443359375, Neurons: 25, Grad norm: 1.751e+02\n",
      "Epoch 1446, Loss: 1002.9618530273438, Neurons: 25, Grad norm: 1.753e+02\n",
      "Epoch 1446, Loss: 1002.9618530273438, Neurons: 25, Grad norm: 1.753e+02\n",
      "Epoch 1447, Loss: 1002.4743041992188, Neurons: 25, Grad norm: 1.755e+02\n",
      "Epoch 1447, Loss: 1002.4743041992188, Neurons: 25, Grad norm: 1.755e+02\n",
      "Epoch 1448, Loss: 1001.9806518554688, Neurons: 25, Grad norm: 1.758e+02\n",
      "Epoch 1448, Loss: 1001.9806518554688, Neurons: 25, Grad norm: 1.758e+02\n",
      "Epoch 1449, Loss: 1001.481201171875, Neurons: 25, Grad norm: 1.760e+02\n",
      "Epoch 1449, Loss: 1001.481201171875, Neurons: 25, Grad norm: 1.760e+02\n",
      "Epoch 1450, Loss: 1000.9756469726562, Neurons: 25, Grad norm: 1.762e+02\n",
      "Epoch 1450, Loss: 1000.9756469726562, Neurons: 25, Grad norm: 1.762e+02\n",
      "Epoch 1451, Loss: 1000.4642944335938, Neurons: 25, Grad norm: 1.764e+02\n",
      "Epoch 1451, Loss: 1000.4642944335938, Neurons: 25, Grad norm: 1.764e+02\n",
      "Epoch 1452, Loss: 999.94677734375, Neurons: 25, Grad norm: 1.766e+02\n",
      "Epoch 1452, Loss: 999.94677734375, Neurons: 25, Grad norm: 1.766e+02\n",
      "Epoch 1453, Loss: 999.4234008789062, Neurons: 25, Grad norm: 1.768e+02\n",
      "Epoch 1453, Loss: 999.4234008789062, Neurons: 25, Grad norm: 1.768e+02\n",
      "Epoch 1454, Loss: 998.8941040039062, Neurons: 25, Grad norm: 1.770e+02\n",
      "Epoch 1454, Loss: 998.8941040039062, Neurons: 25, Grad norm: 1.770e+02\n",
      "Epoch 1455, Loss: 998.3588256835938, Neurons: 25, Grad norm: 1.772e+02\n",
      "Epoch 1455, Loss: 998.3588256835938, Neurons: 25, Grad norm: 1.772e+02\n",
      "Epoch 1456, Loss: 997.817626953125, Neurons: 25, Grad norm: 1.774e+02\n",
      "Epoch 1456, Loss: 997.817626953125, Neurons: 25, Grad norm: 1.774e+02\n",
      "Epoch 1457, Loss: 997.2704467773438, Neurons: 25, Grad norm: 1.776e+02\n",
      "Epoch 1457, Loss: 997.2704467773438, Neurons: 25, Grad norm: 1.776e+02\n",
      "Epoch 1458, Loss: 996.71728515625, Neurons: 25, Grad norm: 1.778e+02\n",
      "Epoch 1458, Loss: 996.71728515625, Neurons: 25, Grad norm: 1.778e+02\n",
      "Epoch 1459, Loss: 996.1581420898438, Neurons: 25, Grad norm: 1.781e+02\n",
      "Epoch 1459, Loss: 996.1581420898438, Neurons: 25, Grad norm: 1.781e+02\n",
      "Epoch 1460, Loss: 995.5932006835938, Neurons: 25, Grad norm: 1.783e+02\n",
      "Epoch 1460, Loss: 995.5932006835938, Neurons: 25, Grad norm: 1.783e+02\n",
      "Epoch 1461, Loss: 995.0220947265625, Neurons: 25, Grad norm: 1.785e+02\n",
      "Epoch 1461, Loss: 995.0220947265625, Neurons: 25, Grad norm: 1.785e+02\n",
      "Epoch 1462, Loss: 994.4451904296875, Neurons: 25, Grad norm: 1.787e+02\n",
      "Epoch 1462, Loss: 994.4451904296875, Neurons: 25, Grad norm: 1.787e+02\n",
      "Epoch 1463, Loss: 993.8621215820312, Neurons: 25, Grad norm: 1.789e+02\n",
      "Epoch 1463, Loss: 993.8621215820312, Neurons: 25, Grad norm: 1.789e+02\n",
      "Epoch 1464, Loss: 993.273193359375, Neurons: 25, Grad norm: 1.791e+02\n",
      "Epoch 1464, Loss: 993.273193359375, Neurons: 25, Grad norm: 1.791e+02\n",
      "Epoch 1465, Loss: 992.6781616210938, Neurons: 25, Grad norm: 1.793e+02\n",
      "Epoch 1465, Loss: 992.6781616210938, Neurons: 25, Grad norm: 1.793e+02\n",
      "Epoch 1466, Loss: 992.0772094726562, Neurons: 25, Grad norm: 1.795e+02\n",
      "Epoch 1466, Loss: 992.0772094726562, Neurons: 25, Grad norm: 1.795e+02\n",
      "Epoch 1467, Loss: 991.47021484375, Neurons: 25, Grad norm: 1.797e+02\n",
      "Epoch 1467, Loss: 991.47021484375, Neurons: 25, Grad norm: 1.797e+02\n",
      "Epoch 1468, Loss: 990.857177734375, Neurons: 25, Grad norm: 1.800e+02\n",
      "Epoch 1468, Loss: 990.857177734375, Neurons: 25, Grad norm: 1.800e+02\n",
      "Epoch 1469, Loss: 990.2380981445312, Neurons: 25, Grad norm: 1.802e+02\n",
      "Epoch 1469, Loss: 990.2380981445312, Neurons: 25, Grad norm: 1.802e+02\n",
      "Epoch 1470, Loss: 989.6129760742188, Neurons: 25, Grad norm: 1.804e+02\n",
      "Epoch 1470, Loss: 989.6129760742188, Neurons: 25, Grad norm: 1.804e+02\n",
      "Epoch 1471, Loss: 988.9818115234375, Neurons: 25, Grad norm: 1.806e+02\n",
      "Epoch 1471, Loss: 988.9818115234375, Neurons: 25, Grad norm: 1.806e+02\n",
      "Epoch 1472, Loss: 988.3444213867188, Neurons: 25, Grad norm: 1.809e+02\n",
      "Epoch 1472, Loss: 988.3444213867188, Neurons: 25, Grad norm: 1.809e+02\n",
      "Epoch 1473, Loss: 987.7009887695312, Neurons: 25, Grad norm: 1.811e+02\n",
      "Epoch 1473, Loss: 987.7009887695312, Neurons: 25, Grad norm: 1.811e+02\n",
      "Epoch 1474, Loss: 987.0513916015625, Neurons: 25, Grad norm: 1.813e+02\n",
      "Epoch 1474, Loss: 987.0513916015625, Neurons: 25, Grad norm: 1.813e+02\n",
      "Epoch 1475, Loss: 986.3956909179688, Neurons: 25, Grad norm: 1.815e+02\n",
      "Epoch 1475, Loss: 986.3956909179688, Neurons: 25, Grad norm: 1.815e+02\n",
      "Epoch 1476, Loss: 985.7338256835938, Neurons: 25, Grad norm: 1.817e+02\n",
      "Epoch 1476, Loss: 985.7338256835938, Neurons: 25, Grad norm: 1.817e+02\n",
      "Epoch 1477, Loss: 985.0657348632812, Neurons: 25, Grad norm: 1.820e+02\n",
      "Epoch 1477, Loss: 985.0657348632812, Neurons: 25, Grad norm: 1.820e+02\n",
      "Epoch 1478, Loss: 984.3914184570312, Neurons: 25, Grad norm: 1.822e+02\n",
      "Epoch 1478, Loss: 984.3914184570312, Neurons: 25, Grad norm: 1.822e+02\n",
      "Epoch 1479, Loss: 983.7109985351562, Neurons: 25, Grad norm: 1.824e+02\n",
      "Epoch 1479, Loss: 983.7109985351562, Neurons: 25, Grad norm: 1.824e+02\n",
      "Epoch 1480, Loss: 983.0242309570312, Neurons: 25, Grad norm: 1.826e+02\n",
      "Epoch 1480, Loss: 983.0242309570312, Neurons: 25, Grad norm: 1.826e+02\n",
      "Epoch 1481, Loss: 982.3311767578125, Neurons: 25, Grad norm: 1.828e+02\n",
      "Epoch 1481, Loss: 982.3311767578125, Neurons: 25, Grad norm: 1.828e+02\n",
      "Epoch 1482, Loss: 981.6317749023438, Neurons: 25, Grad norm: 1.830e+02\n",
      "Epoch 1482, Loss: 981.6317749023438, Neurons: 25, Grad norm: 1.830e+02\n",
      "Epoch 1483, Loss: 980.92626953125, Neurons: 25, Grad norm: 1.833e+02\n",
      "Epoch 1483, Loss: 980.92626953125, Neurons: 25, Grad norm: 1.833e+02\n",
      "Epoch 1484, Loss: 980.2142944335938, Neurons: 25, Grad norm: 1.835e+02\n",
      "Epoch 1484, Loss: 980.2142944335938, Neurons: 25, Grad norm: 1.835e+02\n",
      "Epoch 1485, Loss: 979.4959106445312, Neurons: 25, Grad norm: 1.837e+02\n",
      "Epoch 1485, Loss: 979.4959106445312, Neurons: 25, Grad norm: 1.837e+02\n",
      "Epoch 1486, Loss: 978.7713012695312, Neurons: 25, Grad norm: 1.839e+02\n",
      "Epoch 1486, Loss: 978.7713012695312, Neurons: 25, Grad norm: 1.839e+02\n",
      "Epoch 1487, Loss: 978.0402221679688, Neurons: 25, Grad norm: 1.841e+02\n",
      "Epoch 1487, Loss: 978.0402221679688, Neurons: 25, Grad norm: 1.841e+02\n",
      "Epoch 1488, Loss: 977.3026733398438, Neurons: 25, Grad norm: 1.844e+02\n",
      "Epoch 1488, Loss: 977.3026733398438, Neurons: 25, Grad norm: 1.844e+02\n",
      "Epoch 1489, Loss: 976.5587768554688, Neurons: 25, Grad norm: 1.846e+02\n",
      "Epoch 1489, Loss: 976.5587768554688, Neurons: 25, Grad norm: 1.846e+02\n",
      "Epoch 1490, Loss: 975.8082885742188, Neurons: 25, Grad norm: 1.848e+02\n",
      "Epoch 1490, Loss: 975.8082885742188, Neurons: 25, Grad norm: 1.848e+02\n",
      "Epoch 1491, Loss: 975.0513305664062, Neurons: 25, Grad norm: 1.850e+02\n",
      "Epoch 1491, Loss: 975.0513305664062, Neurons: 25, Grad norm: 1.850e+02\n",
      "Epoch 1492, Loss: 974.2879028320312, Neurons: 25, Grad norm: 1.852e+02\n",
      "Epoch 1492, Loss: 974.2879028320312, Neurons: 25, Grad norm: 1.852e+02\n",
      "Epoch 1493, Loss: 973.5179443359375, Neurons: 25, Grad norm: 1.854e+02\n",
      "Epoch 1493, Loss: 973.5179443359375, Neurons: 25, Grad norm: 1.854e+02\n",
      "Epoch 1494, Loss: 972.7412719726562, Neurons: 25, Grad norm: 1.856e+02\n",
      "Epoch 1494, Loss: 972.7412719726562, Neurons: 25, Grad norm: 1.856e+02\n",
      "Epoch 1495, Loss: 971.9580688476562, Neurons: 25, Grad norm: 1.859e+02\n",
      "Epoch 1495, Loss: 971.9580688476562, Neurons: 25, Grad norm: 1.859e+02\n",
      "Epoch 1496, Loss: 971.168212890625, Neurons: 25, Grad norm: 1.861e+02\n",
      "Epoch 1496, Loss: 971.168212890625, Neurons: 25, Grad norm: 1.861e+02\n",
      "Epoch 1497, Loss: 970.3716430664062, Neurons: 25, Grad norm: 1.863e+02\n",
      "Epoch 1497, Loss: 970.3716430664062, Neurons: 25, Grad norm: 1.863e+02\n",
      "Epoch 1498, Loss: 969.5685424804688, Neurons: 25, Grad norm: 1.865e+02\n",
      "Epoch 1498, Loss: 969.5685424804688, Neurons: 25, Grad norm: 1.865e+02\n",
      "Epoch 1499, Loss: 968.758544921875, Neurons: 25, Grad norm: 1.867e+02\n",
      "Epoch 1499, Loss: 968.758544921875, Neurons: 25, Grad norm: 1.867e+02\n",
      "Epoch 1499, Test loss: 978.4578247070312\n",
      "Epoch 1499, Test loss: 978.4578247070312\n",
      "Added neuron to hidden layer 1 with activation relu\n",
      "Added neuron to hidden layer 1 with activation relu\n",
      "network shape updated to :[11, 14, 1]\n",
      "network shape updated to :[11, 14, 1]\n",
      "Epoch 1500, Loss: 1003.5939331054688, Neurons: 26, Grad norm: 1.203e+02\n",
      "Epoch 1500, Loss: 1003.5939331054688, Neurons: 26, Grad norm: 1.203e+02\n",
      "Epoch 1501, Loss: 1003.3340454101562, Neurons: 26, Grad norm: 1.193e+02\n",
      "Epoch 1501, Loss: 1003.3340454101562, Neurons: 26, Grad norm: 1.193e+02\n",
      "Epoch 1502, Loss: 1003.0634765625, Neurons: 26, Grad norm: 1.183e+02\n",
      "Epoch 1502, Loss: 1003.0634765625, Neurons: 26, Grad norm: 1.183e+02\n",
      "Epoch 1503, Loss: 1002.7826538085938, Neurons: 26, Grad norm: 1.173e+02\n",
      "Epoch 1503, Loss: 1002.7826538085938, Neurons: 26, Grad norm: 1.173e+02\n",
      "Epoch 1504, Loss: 1002.4920043945312, Neurons: 26, Grad norm: 1.164e+02\n",
      "Epoch 1504, Loss: 1002.4920043945312, Neurons: 26, Grad norm: 1.164e+02\n",
      "Epoch 1505, Loss: 1002.191650390625, Neurons: 26, Grad norm: 1.155e+02\n",
      "Epoch 1505, Loss: 1002.191650390625, Neurons: 26, Grad norm: 1.155e+02\n",
      "Epoch 1506, Loss: 1001.8822631835938, Neurons: 26, Grad norm: 1.147e+02\n",
      "Epoch 1506, Loss: 1001.8822631835938, Neurons: 26, Grad norm: 1.147e+02\n",
      "Epoch 1507, Loss: 1001.5640258789062, Neurons: 26, Grad norm: 1.140e+02\n",
      "Epoch 1507, Loss: 1001.5640258789062, Neurons: 26, Grad norm: 1.140e+02\n",
      "Epoch 1508, Loss: 1001.2371215820312, Neurons: 26, Grad norm: 1.133e+02\n",
      "Epoch 1508, Loss: 1001.2371215820312, Neurons: 26, Grad norm: 1.133e+02\n",
      "Epoch 1509, Loss: 1000.90185546875, Neurons: 26, Grad norm: 1.127e+02\n",
      "Epoch 1509, Loss: 1000.90185546875, Neurons: 26, Grad norm: 1.127e+02\n",
      "Epoch 1510, Loss: 1000.5582885742188, Neurons: 26, Grad norm: 1.122e+02\n",
      "Epoch 1510, Loss: 1000.5582885742188, Neurons: 26, Grad norm: 1.122e+02\n",
      "Epoch 1511, Loss: 1000.20654296875, Neurons: 26, Grad norm: 1.118e+02\n",
      "Epoch 1511, Loss: 1000.20654296875, Neurons: 26, Grad norm: 1.118e+02\n",
      "Epoch 1512, Loss: 999.8468627929688, Neurons: 26, Grad norm: 1.114e+02\n",
      "Epoch 1512, Loss: 999.8468627929688, Neurons: 26, Grad norm: 1.114e+02\n",
      "Epoch 1513, Loss: 999.4790649414062, Neurons: 26, Grad norm: 1.112e+02\n",
      "Epoch 1513, Loss: 999.4790649414062, Neurons: 26, Grad norm: 1.112e+02\n",
      "Epoch 1514, Loss: 999.1035766601562, Neurons: 26, Grad norm: 1.109e+02\n",
      "Epoch 1514, Loss: 999.1035766601562, Neurons: 26, Grad norm: 1.109e+02\n",
      "Epoch 1515, Loss: 998.7200317382812, Neurons: 26, Grad norm: 1.108e+02\n",
      "Epoch 1515, Loss: 998.7200317382812, Neurons: 26, Grad norm: 1.108e+02\n",
      "Epoch 1516, Loss: 998.3287963867188, Neurons: 26, Grad norm: 1.106e+02\n",
      "Epoch 1516, Loss: 998.3287963867188, Neurons: 26, Grad norm: 1.106e+02\n",
      "Epoch 1517, Loss: 997.9298095703125, Neurons: 26, Grad norm: 1.106e+02\n",
      "Epoch 1517, Loss: 997.9298095703125, Neurons: 26, Grad norm: 1.106e+02\n",
      "Epoch 1518, Loss: 997.5230102539062, Neurons: 26, Grad norm: 1.105e+02\n",
      "Epoch 1518, Loss: 997.5230102539062, Neurons: 26, Grad norm: 1.105e+02\n",
      "Epoch 1519, Loss: 997.1082763671875, Neurons: 26, Grad norm: 1.105e+02\n",
      "Epoch 1519, Loss: 997.1082763671875, Neurons: 26, Grad norm: 1.105e+02\n",
      "Epoch 1520, Loss: 996.6859130859375, Neurons: 26, Grad norm: 1.105e+02\n",
      "Epoch 1520, Loss: 996.6859130859375, Neurons: 26, Grad norm: 1.105e+02\n",
      "Epoch 1521, Loss: 996.255615234375, Neurons: 26, Grad norm: 1.105e+02\n",
      "Epoch 1521, Loss: 996.255615234375, Neurons: 26, Grad norm: 1.105e+02\n",
      "Epoch 1522, Loss: 995.8174438476562, Neurons: 26, Grad norm: 1.106e+02\n",
      "Epoch 1522, Loss: 995.8174438476562, Neurons: 26, Grad norm: 1.106e+02\n",
      "Epoch 1523, Loss: 995.3713989257812, Neurons: 26, Grad norm: 1.106e+02\n",
      "Epoch 1523, Loss: 995.3713989257812, Neurons: 26, Grad norm: 1.106e+02\n",
      "Epoch 1524, Loss: 994.9175415039062, Neurons: 26, Grad norm: 1.107e+02\n",
      "Epoch 1524, Loss: 994.9175415039062, Neurons: 26, Grad norm: 1.107e+02\n",
      "Epoch 1525, Loss: 994.455810546875, Neurons: 26, Grad norm: 1.108e+02\n",
      "Epoch 1525, Loss: 994.455810546875, Neurons: 26, Grad norm: 1.108e+02\n",
      "Epoch 1526, Loss: 993.9861450195312, Neurons: 26, Grad norm: 1.108e+02\n",
      "Epoch 1526, Loss: 993.9861450195312, Neurons: 26, Grad norm: 1.108e+02\n",
      "Epoch 1527, Loss: 993.5089111328125, Neurons: 26, Grad norm: 1.109e+02\n",
      "Epoch 1527, Loss: 993.5089111328125, Neurons: 26, Grad norm: 1.109e+02\n",
      "Epoch 1528, Loss: 993.0237426757812, Neurons: 26, Grad norm: 1.110e+02\n",
      "Epoch 1528, Loss: 993.0237426757812, Neurons: 26, Grad norm: 1.110e+02\n",
      "Epoch 1529, Loss: 992.5309448242188, Neurons: 26, Grad norm: 1.110e+02\n",
      "Epoch 1529, Loss: 992.5309448242188, Neurons: 26, Grad norm: 1.110e+02\n",
      "Epoch 1530, Loss: 992.030517578125, Neurons: 26, Grad norm: 1.110e+02\n",
      "Epoch 1530, Loss: 992.030517578125, Neurons: 26, Grad norm: 1.110e+02\n",
      "Epoch 1531, Loss: 991.522705078125, Neurons: 26, Grad norm: 1.111e+02\n",
      "Epoch 1531, Loss: 991.522705078125, Neurons: 26, Grad norm: 1.111e+02\n",
      "Epoch 1532, Loss: 991.0075073242188, Neurons: 26, Grad norm: 1.111e+02\n",
      "Epoch 1532, Loss: 991.0075073242188, Neurons: 26, Grad norm: 1.111e+02\n",
      "Epoch 1533, Loss: 990.4850463867188, Neurons: 26, Grad norm: 1.111e+02\n",
      "Epoch 1533, Loss: 990.4850463867188, Neurons: 26, Grad norm: 1.111e+02\n",
      "Epoch 1534, Loss: 989.9554443359375, Neurons: 26, Grad norm: 1.111e+02\n",
      "Epoch 1534, Loss: 989.9554443359375, Neurons: 26, Grad norm: 1.111e+02\n",
      "Epoch 1535, Loss: 989.4187622070312, Neurons: 26, Grad norm: 1.111e+02\n",
      "Epoch 1535, Loss: 989.4187622070312, Neurons: 26, Grad norm: 1.111e+02\n",
      "Epoch 1536, Loss: 988.8750610351562, Neurons: 26, Grad norm: 1.111e+02\n",
      "Epoch 1536, Loss: 988.8750610351562, Neurons: 26, Grad norm: 1.111e+02\n",
      "Epoch 1537, Loss: 988.3246459960938, Neurons: 26, Grad norm: 1.111e+02\n",
      "Epoch 1537, Loss: 988.3246459960938, Neurons: 26, Grad norm: 1.111e+02\n",
      "Epoch 1538, Loss: 987.7675170898438, Neurons: 26, Grad norm: 1.110e+02\n",
      "Epoch 1538, Loss: 987.7675170898438, Neurons: 26, Grad norm: 1.110e+02\n",
      "Epoch 1539, Loss: 987.2037353515625, Neurons: 26, Grad norm: 1.109e+02\n",
      "Epoch 1539, Loss: 987.2037353515625, Neurons: 26, Grad norm: 1.109e+02\n",
      "Epoch 1540, Loss: 986.63330078125, Neurons: 26, Grad norm: 1.109e+02\n",
      "Epoch 1540, Loss: 986.63330078125, Neurons: 26, Grad norm: 1.109e+02\n",
      "Epoch 1541, Loss: 986.0563354492188, Neurons: 26, Grad norm: 1.108e+02\n",
      "Epoch 1541, Loss: 986.0563354492188, Neurons: 26, Grad norm: 1.108e+02\n",
      "Epoch 1542, Loss: 985.472900390625, Neurons: 26, Grad norm: 1.107e+02\n",
      "Epoch 1542, Loss: 985.472900390625, Neurons: 26, Grad norm: 1.107e+02\n",
      "Epoch 1543, Loss: 984.8829956054688, Neurons: 26, Grad norm: 1.106e+02\n",
      "Epoch 1543, Loss: 984.8829956054688, Neurons: 26, Grad norm: 1.106e+02\n",
      "Epoch 1544, Loss: 984.28662109375, Neurons: 26, Grad norm: 1.104e+02\n",
      "Epoch 1544, Loss: 984.28662109375, Neurons: 26, Grad norm: 1.104e+02\n",
      "Epoch 1545, Loss: 983.6837768554688, Neurons: 26, Grad norm: 1.103e+02\n",
      "Epoch 1545, Loss: 983.6837768554688, Neurons: 26, Grad norm: 1.103e+02\n",
      "Epoch 1546, Loss: 983.0745849609375, Neurons: 26, Grad norm: 1.101e+02\n",
      "Epoch 1546, Loss: 983.0745849609375, Neurons: 26, Grad norm: 1.101e+02\n",
      "Epoch 1547, Loss: 982.4589233398438, Neurons: 26, Grad norm: 1.099e+02\n",
      "Epoch 1547, Loss: 982.4589233398438, Neurons: 26, Grad norm: 1.099e+02\n",
      "Epoch 1548, Loss: 981.8369750976562, Neurons: 26, Grad norm: 1.097e+02\n",
      "Epoch 1548, Loss: 981.8369750976562, Neurons: 26, Grad norm: 1.097e+02\n",
      "Epoch 1549, Loss: 981.2086791992188, Neurons: 26, Grad norm: 1.095e+02\n",
      "Epoch 1549, Loss: 981.2086791992188, Neurons: 26, Grad norm: 1.095e+02\n",
      "Epoch 1550, Loss: 980.573974609375, Neurons: 26, Grad norm: 1.093e+02\n",
      "Epoch 1550, Loss: 980.573974609375, Neurons: 26, Grad norm: 1.093e+02\n",
      "Epoch 1551, Loss: 979.9332275390625, Neurons: 26, Grad norm: 1.090e+02\n",
      "Epoch 1551, Loss: 979.9332275390625, Neurons: 26, Grad norm: 1.090e+02\n",
      "Epoch 1552, Loss: 979.2861938476562, Neurons: 26, Grad norm: 1.088e+02\n",
      "Epoch 1552, Loss: 979.2861938476562, Neurons: 26, Grad norm: 1.088e+02\n",
      "Epoch 1553, Loss: 978.63330078125, Neurons: 26, Grad norm: 1.085e+02\n",
      "Epoch 1553, Loss: 978.63330078125, Neurons: 26, Grad norm: 1.085e+02\n",
      "Epoch 1554, Loss: 977.9743041992188, Neurons: 26, Grad norm: 1.082e+02\n",
      "Epoch 1554, Loss: 977.9743041992188, Neurons: 26, Grad norm: 1.082e+02\n",
      "Epoch 1555, Loss: 977.3095703125, Neurons: 26, Grad norm: 1.079e+02\n",
      "Epoch 1555, Loss: 977.3095703125, Neurons: 26, Grad norm: 1.079e+02\n",
      "Epoch 1556, Loss: 976.6390380859375, Neurons: 26, Grad norm: 1.075e+02\n",
      "Epoch 1556, Loss: 976.6390380859375, Neurons: 26, Grad norm: 1.075e+02\n",
      "Epoch 1557, Loss: 975.9630737304688, Neurons: 26, Grad norm: 1.072e+02\n",
      "Epoch 1557, Loss: 975.9630737304688, Neurons: 26, Grad norm: 1.072e+02\n",
      "Epoch 1558, Loss: 975.2816772460938, Neurons: 26, Grad norm: 1.068e+02\n",
      "Epoch 1558, Loss: 975.2816772460938, Neurons: 26, Grad norm: 1.068e+02\n",
      "Epoch 1559, Loss: 974.5951538085938, Neurons: 26, Grad norm: 1.064e+02\n",
      "Epoch 1559, Loss: 974.5951538085938, Neurons: 26, Grad norm: 1.064e+02\n",
      "Epoch 1560, Loss: 973.90380859375, Neurons: 26, Grad norm: 1.059e+02\n",
      "Epoch 1560, Loss: 973.90380859375, Neurons: 26, Grad norm: 1.059e+02\n",
      "Epoch 1561, Loss: 973.2076416015625, Neurons: 26, Grad norm: 1.055e+02\n",
      "Epoch 1561, Loss: 973.2076416015625, Neurons: 26, Grad norm: 1.055e+02\n",
      "Epoch 1562, Loss: 972.50732421875, Neurons: 26, Grad norm: 1.050e+02\n",
      "Epoch 1562, Loss: 972.50732421875, Neurons: 26, Grad norm: 1.050e+02\n",
      "Epoch 1563, Loss: 971.8026733398438, Neurons: 26, Grad norm: 1.045e+02\n",
      "Epoch 1563, Loss: 971.8026733398438, Neurons: 26, Grad norm: 1.045e+02\n",
      "Epoch 1564, Loss: 971.0942993164062, Neurons: 26, Grad norm: 1.039e+02\n",
      "Epoch 1564, Loss: 971.0942993164062, Neurons: 26, Grad norm: 1.039e+02\n",
      "Epoch 1565, Loss: 970.3826904296875, Neurons: 26, Grad norm: 1.034e+02\n",
      "Epoch 1565, Loss: 970.3826904296875, Neurons: 26, Grad norm: 1.034e+02\n",
      "Epoch 1566, Loss: 969.6680297851562, Neurons: 26, Grad norm: 1.028e+02\n",
      "Epoch 1566, Loss: 969.6680297851562, Neurons: 26, Grad norm: 1.028e+02\n",
      "Epoch 1567, Loss: 968.950927734375, Neurons: 26, Grad norm: 1.021e+02\n",
      "Epoch 1567, Loss: 968.950927734375, Neurons: 26, Grad norm: 1.021e+02\n",
      "Epoch 1568, Loss: 968.23193359375, Neurons: 26, Grad norm: 1.015e+02\n",
      "Epoch 1568, Loss: 968.23193359375, Neurons: 26, Grad norm: 1.015e+02\n",
      "Epoch 1569, Loss: 967.5115356445312, Neurons: 26, Grad norm: 1.008e+02\n",
      "Epoch 1569, Loss: 967.5115356445312, Neurons: 26, Grad norm: 1.008e+02\n",
      "Epoch 1570, Loss: 966.7903442382812, Neurons: 26, Grad norm: 1.000e+02\n",
      "Epoch 1570, Loss: 966.7903442382812, Neurons: 26, Grad norm: 1.000e+02\n",
      "Epoch 1571, Loss: 966.0690307617188, Neurons: 26, Grad norm: 9.924e+01\n",
      "Epoch 1571, Loss: 966.0690307617188, Neurons: 26, Grad norm: 9.924e+01\n",
      "Epoch 1572, Loss: 965.3484497070312, Neurons: 26, Grad norm: 9.843e+01\n",
      "Epoch 1572, Loss: 965.3484497070312, Neurons: 26, Grad norm: 9.843e+01\n",
      "Epoch 1573, Loss: 964.629150390625, Neurons: 26, Grad norm: 9.759e+01\n",
      "Epoch 1573, Loss: 964.629150390625, Neurons: 26, Grad norm: 9.759e+01\n",
      "Epoch 1574, Loss: 963.9120483398438, Neurons: 26, Grad norm: 9.672e+01\n",
      "Epoch 1574, Loss: 963.9120483398438, Neurons: 26, Grad norm: 9.672e+01\n",
      "Epoch 1575, Loss: 963.1979370117188, Neurons: 26, Grad norm: 9.582e+01\n",
      "Epoch 1575, Loss: 963.1979370117188, Neurons: 26, Grad norm: 9.582e+01\n",
      "Epoch 1576, Loss: 962.4876708984375, Neurons: 26, Grad norm: 9.490e+01\n",
      "Epoch 1576, Loss: 962.4876708984375, Neurons: 26, Grad norm: 9.490e+01\n",
      "Epoch 1577, Loss: 961.7821655273438, Neurons: 26, Grad norm: 9.396e+01\n",
      "Epoch 1577, Loss: 961.7821655273438, Neurons: 26, Grad norm: 9.396e+01\n",
      "Epoch 1578, Loss: 961.0818481445312, Neurons: 26, Grad norm: 9.299e+01\n",
      "Epoch 1578, Loss: 961.0818481445312, Neurons: 26, Grad norm: 9.299e+01\n",
      "Epoch 1579, Loss: 960.3875732421875, Neurons: 26, Grad norm: 9.201e+01\n",
      "Epoch 1579, Loss: 960.3875732421875, Neurons: 26, Grad norm: 9.201e+01\n",
      "Epoch 1580, Loss: 959.6997680664062, Neurons: 26, Grad norm: 9.102e+01\n",
      "Epoch 1580, Loss: 959.6997680664062, Neurons: 26, Grad norm: 9.102e+01\n",
      "Epoch 1581, Loss: 959.01904296875, Neurons: 26, Grad norm: 9.002e+01\n",
      "Epoch 1581, Loss: 959.01904296875, Neurons: 26, Grad norm: 9.002e+01\n",
      "Epoch 1582, Loss: 958.3453979492188, Neurons: 26, Grad norm: 8.901e+01\n",
      "Epoch 1582, Loss: 958.3453979492188, Neurons: 26, Grad norm: 8.901e+01\n",
      "Epoch 1583, Loss: 957.6790161132812, Neurons: 26, Grad norm: 8.799e+01\n",
      "Epoch 1583, Loss: 957.6790161132812, Neurons: 26, Grad norm: 8.799e+01\n",
      "Epoch 1584, Loss: 957.019775390625, Neurons: 26, Grad norm: 8.698e+01\n",
      "Epoch 1584, Loss: 957.019775390625, Neurons: 26, Grad norm: 8.698e+01\n",
      "Epoch 1585, Loss: 956.367431640625, Neurons: 26, Grad norm: 8.597e+01\n",
      "Epoch 1585, Loss: 956.367431640625, Neurons: 26, Grad norm: 8.597e+01\n",
      "Epoch 1586, Loss: 955.721923828125, Neurons: 26, Grad norm: 8.497e+01\n",
      "Epoch 1586, Loss: 955.721923828125, Neurons: 26, Grad norm: 8.497e+01\n",
      "Epoch 1587, Loss: 955.0828857421875, Neurons: 26, Grad norm: 8.398e+01\n",
      "Epoch 1587, Loss: 955.0828857421875, Neurons: 26, Grad norm: 8.398e+01\n",
      "Epoch 1588, Loss: 954.4501953125, Neurons: 26, Grad norm: 8.300e+01\n",
      "Epoch 1588, Loss: 954.4501953125, Neurons: 26, Grad norm: 8.300e+01\n",
      "Epoch 1589, Loss: 953.8235473632812, Neurons: 26, Grad norm: 8.203e+01\n",
      "Epoch 1589, Loss: 953.8235473632812, Neurons: 26, Grad norm: 8.203e+01\n",
      "Epoch 1590, Loss: 953.2029418945312, Neurons: 26, Grad norm: 8.109e+01\n",
      "Epoch 1590, Loss: 953.2029418945312, Neurons: 26, Grad norm: 8.109e+01\n",
      "Epoch 1591, Loss: 952.588134765625, Neurons: 26, Grad norm: 8.017e+01\n",
      "Epoch 1591, Loss: 952.588134765625, Neurons: 26, Grad norm: 8.017e+01\n",
      "Epoch 1592, Loss: 951.9788818359375, Neurons: 26, Grad norm: 7.928e+01\n",
      "Epoch 1592, Loss: 951.9788818359375, Neurons: 26, Grad norm: 7.928e+01\n",
      "Epoch 1593, Loss: 951.3749389648438, Neurons: 26, Grad norm: 7.842e+01\n",
      "Epoch 1593, Loss: 951.3749389648438, Neurons: 26, Grad norm: 7.842e+01\n",
      "Epoch 1594, Loss: 950.776123046875, Neurons: 26, Grad norm: 7.759e+01\n",
      "Epoch 1594, Loss: 950.776123046875, Neurons: 26, Grad norm: 7.759e+01\n",
      "Epoch 1595, Loss: 950.1820678710938, Neurons: 26, Grad norm: 7.679e+01\n",
      "Epoch 1595, Loss: 950.1820678710938, Neurons: 26, Grad norm: 7.679e+01\n",
      "Epoch 1596, Loss: 949.5925903320312, Neurons: 26, Grad norm: 7.602e+01\n",
      "Epoch 1596, Loss: 949.5925903320312, Neurons: 26, Grad norm: 7.602e+01\n",
      "Epoch 1597, Loss: 949.00732421875, Neurons: 26, Grad norm: 7.529e+01\n",
      "Epoch 1597, Loss: 949.00732421875, Neurons: 26, Grad norm: 7.529e+01\n",
      "Epoch 1598, Loss: 948.426025390625, Neurons: 26, Grad norm: 7.459e+01\n",
      "Epoch 1598, Loss: 948.426025390625, Neurons: 26, Grad norm: 7.459e+01\n",
      "Epoch 1599, Loss: 947.8482666015625, Neurons: 26, Grad norm: 7.393e+01\n",
      "Epoch 1599, Loss: 947.8482666015625, Neurons: 26, Grad norm: 7.393e+01\n",
      "Epoch 1599, Test loss: 957.7379150390625\n",
      "Epoch 1599, Test loss: 957.7379150390625\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "network shape updated to :[11, 15, 1]\n",
      "network shape updated to :[11, 15, 1]\n",
      "Epoch 1600, Loss: 948.2637939453125, Neurons: 27, Grad norm: 8.330e+01\n",
      "Epoch 1600, Loss: 948.2637939453125, Neurons: 27, Grad norm: 8.330e+01\n",
      "Epoch 1601, Loss: 948.087890625, Neurons: 27, Grad norm: 8.281e+01\n",
      "Epoch 1601, Loss: 948.087890625, Neurons: 27, Grad norm: 8.281e+01\n",
      "Epoch 1602, Loss: 947.905517578125, Neurons: 27, Grad norm: 8.237e+01\n",
      "Epoch 1602, Loss: 947.905517578125, Neurons: 27, Grad norm: 8.237e+01\n",
      "Epoch 1603, Loss: 947.7162475585938, Neurons: 27, Grad norm: 8.194e+01\n",
      "Epoch 1603, Loss: 947.7162475585938, Neurons: 27, Grad norm: 8.194e+01\n",
      "Epoch 1604, Loss: 947.5198974609375, Neurons: 27, Grad norm: 8.149e+01\n",
      "Epoch 1604, Loss: 947.5198974609375, Neurons: 27, Grad norm: 8.149e+01\n",
      "Epoch 1605, Loss: 947.3168334960938, Neurons: 27, Grad norm: 8.103e+01\n",
      "Epoch 1605, Loss: 947.3168334960938, Neurons: 27, Grad norm: 8.103e+01\n",
      "Epoch 1606, Loss: 947.1069946289062, Neurons: 27, Grad norm: 8.054e+01\n",
      "Epoch 1606, Loss: 947.1069946289062, Neurons: 27, Grad norm: 8.054e+01\n",
      "Epoch 1607, Loss: 946.8905639648438, Neurons: 27, Grad norm: 8.004e+01\n",
      "Epoch 1607, Loss: 946.8905639648438, Neurons: 27, Grad norm: 8.004e+01\n",
      "Epoch 1608, Loss: 946.6676025390625, Neurons: 27, Grad norm: 7.952e+01\n",
      "Epoch 1608, Loss: 946.6676025390625, Neurons: 27, Grad norm: 7.952e+01\n",
      "Epoch 1609, Loss: 946.4384765625, Neurons: 27, Grad norm: 7.900e+01\n",
      "Epoch 1609, Loss: 946.4384765625, Neurons: 27, Grad norm: 7.900e+01\n",
      "Epoch 1610, Loss: 946.2033081054688, Neurons: 27, Grad norm: 7.848e+01\n",
      "Epoch 1610, Loss: 946.2033081054688, Neurons: 27, Grad norm: 7.848e+01\n",
      "Epoch 1611, Loss: 945.96240234375, Neurons: 27, Grad norm: 7.795e+01\n",
      "Epoch 1611, Loss: 945.96240234375, Neurons: 27, Grad norm: 7.795e+01\n",
      "Epoch 1612, Loss: 945.7161254882812, Neurons: 27, Grad norm: 7.744e+01\n",
      "Epoch 1612, Loss: 945.7161254882812, Neurons: 27, Grad norm: 7.744e+01\n",
      "Epoch 1613, Loss: 945.4645385742188, Neurons: 27, Grad norm: 7.694e+01\n",
      "Epoch 1613, Loss: 945.4645385742188, Neurons: 27, Grad norm: 7.694e+01\n",
      "Epoch 1614, Loss: 945.2080078125, Neurons: 27, Grad norm: 7.646e+01\n",
      "Epoch 1614, Loss: 945.2080078125, Neurons: 27, Grad norm: 7.646e+01\n",
      "Epoch 1615, Loss: 944.9467163085938, Neurons: 27, Grad norm: 7.599e+01\n",
      "Epoch 1615, Loss: 944.9467163085938, Neurons: 27, Grad norm: 7.599e+01\n",
      "Epoch 1616, Loss: 944.6807861328125, Neurons: 27, Grad norm: 7.555e+01\n",
      "Epoch 1616, Loss: 944.6807861328125, Neurons: 27, Grad norm: 7.555e+01\n",
      "Epoch 1617, Loss: 944.41064453125, Neurons: 27, Grad norm: 7.513e+01\n",
      "Epoch 1617, Loss: 944.41064453125, Neurons: 27, Grad norm: 7.513e+01\n",
      "Epoch 1618, Loss: 944.1362915039062, Neurons: 27, Grad norm: 7.474e+01\n",
      "Epoch 1618, Loss: 944.1362915039062, Neurons: 27, Grad norm: 7.474e+01\n",
      "Epoch 1619, Loss: 943.8580322265625, Neurons: 27, Grad norm: 7.436e+01\n",
      "Epoch 1619, Loss: 943.8580322265625, Neurons: 27, Grad norm: 7.436e+01\n",
      "Epoch 1620, Loss: 943.575927734375, Neurons: 27, Grad norm: 7.401e+01\n",
      "Epoch 1620, Loss: 943.575927734375, Neurons: 27, Grad norm: 7.401e+01\n",
      "Epoch 1621, Loss: 943.290283203125, Neurons: 27, Grad norm: 7.367e+01\n",
      "Epoch 1621, Loss: 943.290283203125, Neurons: 27, Grad norm: 7.367e+01\n",
      "Epoch 1622, Loss: 943.0011596679688, Neurons: 27, Grad norm: 7.335e+01\n",
      "Epoch 1622, Loss: 943.0011596679688, Neurons: 27, Grad norm: 7.335e+01\n",
      "Epoch 1623, Loss: 942.7086791992188, Neurons: 27, Grad norm: 7.305e+01\n",
      "Epoch 1623, Loss: 942.7086791992188, Neurons: 27, Grad norm: 7.305e+01\n",
      "Epoch 1624, Loss: 942.4129638671875, Neurons: 27, Grad norm: 7.276e+01\n",
      "Epoch 1624, Loss: 942.4129638671875, Neurons: 27, Grad norm: 7.276e+01\n",
      "Epoch 1625, Loss: 942.1142578125, Neurons: 27, Grad norm: 7.248e+01\n",
      "Epoch 1625, Loss: 942.1142578125, Neurons: 27, Grad norm: 7.248e+01\n",
      "Epoch 1626, Loss: 941.8123168945312, Neurons: 27, Grad norm: 7.222e+01\n",
      "Epoch 1626, Loss: 941.8123168945312, Neurons: 27, Grad norm: 7.222e+01\n",
      "Epoch 1627, Loss: 941.5074462890625, Neurons: 27, Grad norm: 7.196e+01\n",
      "Epoch 1627, Loss: 941.5074462890625, Neurons: 27, Grad norm: 7.196e+01\n",
      "Epoch 1628, Loss: 941.199462890625, Neurons: 27, Grad norm: 7.170e+01\n",
      "Epoch 1628, Loss: 941.199462890625, Neurons: 27, Grad norm: 7.170e+01\n",
      "Epoch 1629, Loss: 940.8885498046875, Neurons: 27, Grad norm: 7.146e+01\n",
      "Epoch 1629, Loss: 940.8885498046875, Neurons: 27, Grad norm: 7.146e+01\n",
      "Epoch 1630, Loss: 940.5745849609375, Neurons: 27, Grad norm: 7.122e+01\n",
      "Epoch 1630, Loss: 940.5745849609375, Neurons: 27, Grad norm: 7.122e+01\n",
      "Epoch 1631, Loss: 940.2577514648438, Neurons: 27, Grad norm: 7.098e+01\n",
      "Epoch 1631, Loss: 940.2577514648438, Neurons: 27, Grad norm: 7.098e+01\n",
      "Epoch 1632, Loss: 939.9378051757812, Neurons: 27, Grad norm: 7.076e+01\n",
      "Epoch 1632, Loss: 939.9378051757812, Neurons: 27, Grad norm: 7.076e+01\n",
      "Epoch 1633, Loss: 939.6148681640625, Neurons: 27, Grad norm: 7.054e+01\n",
      "Epoch 1633, Loss: 939.6148681640625, Neurons: 27, Grad norm: 7.054e+01\n",
      "Epoch 1634, Loss: 939.2889404296875, Neurons: 27, Grad norm: 7.034e+01\n",
      "Epoch 1634, Loss: 939.2889404296875, Neurons: 27, Grad norm: 7.034e+01\n",
      "Epoch 1635, Loss: 938.9597778320312, Neurons: 27, Grad norm: 7.014e+01\n",
      "Epoch 1635, Loss: 938.9597778320312, Neurons: 27, Grad norm: 7.014e+01\n",
      "Epoch 1636, Loss: 938.6275634765625, Neurons: 27, Grad norm: 6.996e+01\n",
      "Epoch 1636, Loss: 938.6275634765625, Neurons: 27, Grad norm: 6.996e+01\n",
      "Epoch 1637, Loss: 938.2921752929688, Neurons: 27, Grad norm: 6.980e+01\n",
      "Epoch 1637, Loss: 938.2921752929688, Neurons: 27, Grad norm: 6.980e+01\n",
      "Epoch 1638, Loss: 937.9535522460938, Neurons: 27, Grad norm: 6.964e+01\n",
      "Epoch 1638, Loss: 937.9535522460938, Neurons: 27, Grad norm: 6.964e+01\n",
      "Epoch 1639, Loss: 937.6116333007812, Neurons: 27, Grad norm: 6.950e+01\n",
      "Epoch 1639, Loss: 937.6116333007812, Neurons: 27, Grad norm: 6.950e+01\n",
      "Epoch 1640, Loss: 937.2664184570312, Neurons: 27, Grad norm: 6.937e+01\n",
      "Epoch 1640, Loss: 937.2664184570312, Neurons: 27, Grad norm: 6.937e+01\n",
      "Epoch 1641, Loss: 936.9178466796875, Neurons: 27, Grad norm: 6.925e+01\n",
      "Epoch 1641, Loss: 936.9178466796875, Neurons: 27, Grad norm: 6.925e+01\n",
      "Epoch 1642, Loss: 936.5658569335938, Neurons: 27, Grad norm: 6.915e+01\n",
      "Epoch 1642, Loss: 936.5658569335938, Neurons: 27, Grad norm: 6.915e+01\n",
      "Epoch 1643, Loss: 936.2103271484375, Neurons: 27, Grad norm: 6.905e+01\n",
      "Epoch 1643, Loss: 936.2103271484375, Neurons: 27, Grad norm: 6.905e+01\n",
      "Epoch 1644, Loss: 935.8514404296875, Neurons: 27, Grad norm: 6.897e+01\n",
      "Epoch 1644, Loss: 935.8514404296875, Neurons: 27, Grad norm: 6.897e+01\n",
      "Epoch 1645, Loss: 935.48876953125, Neurons: 27, Grad norm: 6.890e+01\n",
      "Epoch 1645, Loss: 935.48876953125, Neurons: 27, Grad norm: 6.890e+01\n",
      "Epoch 1646, Loss: 935.12255859375, Neurons: 27, Grad norm: 6.884e+01\n",
      "Epoch 1646, Loss: 935.12255859375, Neurons: 27, Grad norm: 6.884e+01\n",
      "Epoch 1647, Loss: 934.752685546875, Neurons: 27, Grad norm: 6.878e+01\n",
      "Epoch 1647, Loss: 934.752685546875, Neurons: 27, Grad norm: 6.878e+01\n",
      "Epoch 1648, Loss: 934.3790283203125, Neurons: 27, Grad norm: 6.874e+01\n",
      "Epoch 1648, Loss: 934.3790283203125, Neurons: 27, Grad norm: 6.874e+01\n",
      "Epoch 1649, Loss: 934.0015258789062, Neurons: 27, Grad norm: 6.870e+01\n",
      "Epoch 1649, Loss: 934.0015258789062, Neurons: 27, Grad norm: 6.870e+01\n",
      "Epoch 1650, Loss: 933.6201171875, Neurons: 27, Grad norm: 6.868e+01\n",
      "Epoch 1650, Loss: 933.6201171875, Neurons: 27, Grad norm: 6.868e+01\n",
      "Epoch 1651, Loss: 933.2348022460938, Neurons: 27, Grad norm: 6.866e+01\n",
      "Epoch 1651, Loss: 933.2348022460938, Neurons: 27, Grad norm: 6.866e+01\n",
      "Epoch 1652, Loss: 932.8452758789062, Neurons: 27, Grad norm: 6.866e+01\n",
      "Epoch 1652, Loss: 932.8452758789062, Neurons: 27, Grad norm: 6.866e+01\n",
      "Epoch 1653, Loss: 932.451904296875, Neurons: 27, Grad norm: 6.866e+01\n",
      "Epoch 1653, Loss: 932.451904296875, Neurons: 27, Grad norm: 6.866e+01\n",
      "Epoch 1654, Loss: 932.0542602539062, Neurons: 27, Grad norm: 6.869e+01\n",
      "Epoch 1654, Loss: 932.0542602539062, Neurons: 27, Grad norm: 6.869e+01\n",
      "Epoch 1655, Loss: 931.652099609375, Neurons: 27, Grad norm: 6.870e+01\n",
      "Epoch 1655, Loss: 931.652099609375, Neurons: 27, Grad norm: 6.870e+01\n",
      "Epoch 1656, Loss: 931.2457275390625, Neurons: 27, Grad norm: 6.868e+01\n",
      "Epoch 1656, Loss: 931.2457275390625, Neurons: 27, Grad norm: 6.868e+01\n",
      "Epoch 1657, Loss: 930.8353271484375, Neurons: 27, Grad norm: 6.865e+01\n",
      "Epoch 1657, Loss: 930.8353271484375, Neurons: 27, Grad norm: 6.865e+01\n",
      "Epoch 1658, Loss: 930.4212646484375, Neurons: 27, Grad norm: 6.861e+01\n",
      "Epoch 1658, Loss: 930.4212646484375, Neurons: 27, Grad norm: 6.861e+01\n",
      "Epoch 1659, Loss: 930.0037841796875, Neurons: 27, Grad norm: 6.858e+01\n",
      "Epoch 1659, Loss: 930.0037841796875, Neurons: 27, Grad norm: 6.858e+01\n",
      "Epoch 1660, Loss: 929.5831909179688, Neurons: 27, Grad norm: 6.854e+01\n",
      "Epoch 1660, Loss: 929.5831909179688, Neurons: 27, Grad norm: 6.854e+01\n",
      "Epoch 1661, Loss: 929.1593627929688, Neurons: 27, Grad norm: 6.852e+01\n",
      "Epoch 1661, Loss: 929.1593627929688, Neurons: 27, Grad norm: 6.852e+01\n",
      "Epoch 1662, Loss: 928.732666015625, Neurons: 27, Grad norm: 6.852e+01\n",
      "Epoch 1662, Loss: 928.732666015625, Neurons: 27, Grad norm: 6.852e+01\n",
      "Epoch 1663, Loss: 928.3029174804688, Neurons: 27, Grad norm: 6.852e+01\n",
      "Epoch 1663, Loss: 928.3029174804688, Neurons: 27, Grad norm: 6.852e+01\n",
      "Epoch 1664, Loss: 927.8703002929688, Neurons: 27, Grad norm: 6.856e+01\n",
      "Epoch 1664, Loss: 927.8703002929688, Neurons: 27, Grad norm: 6.856e+01\n",
      "Epoch 1665, Loss: 927.4345092773438, Neurons: 27, Grad norm: 6.861e+01\n",
      "Epoch 1665, Loss: 927.4345092773438, Neurons: 27, Grad norm: 6.861e+01\n",
      "Epoch 1666, Loss: 926.9952392578125, Neurons: 27, Grad norm: 6.868e+01\n",
      "Epoch 1666, Loss: 926.9952392578125, Neurons: 27, Grad norm: 6.868e+01\n",
      "Epoch 1667, Loss: 926.5523071289062, Neurons: 27, Grad norm: 6.877e+01\n",
      "Epoch 1667, Loss: 926.5523071289062, Neurons: 27, Grad norm: 6.877e+01\n",
      "Epoch 1668, Loss: 926.1055908203125, Neurons: 27, Grad norm: 6.891e+01\n",
      "Epoch 1668, Loss: 926.1055908203125, Neurons: 27, Grad norm: 6.891e+01\n",
      "Epoch 1669, Loss: 925.654541015625, Neurons: 27, Grad norm: 6.906e+01\n",
      "Epoch 1669, Loss: 925.654541015625, Neurons: 27, Grad norm: 6.906e+01\n",
      "Epoch 1670, Loss: 925.1986694335938, Neurons: 27, Grad norm: 6.924e+01\n",
      "Epoch 1670, Loss: 925.1986694335938, Neurons: 27, Grad norm: 6.924e+01\n",
      "Epoch 1671, Loss: 924.73779296875, Neurons: 27, Grad norm: 6.946e+01\n",
      "Epoch 1671, Loss: 924.73779296875, Neurons: 27, Grad norm: 6.946e+01\n",
      "Epoch 1672, Loss: 924.2711181640625, Neurons: 27, Grad norm: 6.972e+01\n",
      "Epoch 1672, Loss: 924.2711181640625, Neurons: 27, Grad norm: 6.972e+01\n",
      "Epoch 1673, Loss: 923.7982177734375, Neurons: 27, Grad norm: 7.001e+01\n",
      "Epoch 1673, Loss: 923.7982177734375, Neurons: 27, Grad norm: 7.001e+01\n",
      "Epoch 1674, Loss: 923.3187255859375, Neurons: 27, Grad norm: 7.034e+01\n",
      "Epoch 1674, Loss: 923.3187255859375, Neurons: 27, Grad norm: 7.034e+01\n",
      "Epoch 1675, Loss: 922.8319702148438, Neurons: 27, Grad norm: 7.074e+01\n",
      "Epoch 1675, Loss: 922.8319702148438, Neurons: 27, Grad norm: 7.074e+01\n",
      "Epoch 1676, Loss: 922.3374633789062, Neurons: 27, Grad norm: 7.118e+01\n",
      "Epoch 1676, Loss: 922.3374633789062, Neurons: 27, Grad norm: 7.118e+01\n",
      "Epoch 1677, Loss: 921.8345336914062, Neurons: 27, Grad norm: 7.170e+01\n",
      "Epoch 1677, Loss: 921.8345336914062, Neurons: 27, Grad norm: 7.170e+01\n",
      "Epoch 1678, Loss: 921.3225708007812, Neurons: 27, Grad norm: 7.229e+01\n",
      "Epoch 1678, Loss: 921.3225708007812, Neurons: 27, Grad norm: 7.229e+01\n",
      "Epoch 1679, Loss: 920.80078125, Neurons: 27, Grad norm: 7.295e+01\n",
      "Epoch 1679, Loss: 920.80078125, Neurons: 27, Grad norm: 7.295e+01\n",
      "Epoch 1680, Loss: 920.2684936523438, Neurons: 27, Grad norm: 7.372e+01\n",
      "Epoch 1680, Loss: 920.2684936523438, Neurons: 27, Grad norm: 7.372e+01\n",
      "Epoch 1681, Loss: 919.7249145507812, Neurons: 27, Grad norm: 7.459e+01\n",
      "Epoch 1681, Loss: 919.7249145507812, Neurons: 27, Grad norm: 7.459e+01\n",
      "Epoch 1682, Loss: 919.1692504882812, Neurons: 27, Grad norm: 7.559e+01\n",
      "Epoch 1682, Loss: 919.1692504882812, Neurons: 27, Grad norm: 7.559e+01\n",
      "Epoch 1683, Loss: 918.600341796875, Neurons: 27, Grad norm: 7.672e+01\n",
      "Epoch 1683, Loss: 918.600341796875, Neurons: 27, Grad norm: 7.672e+01\n",
      "Epoch 1684, Loss: 918.0172729492188, Neurons: 27, Grad norm: 7.802e+01\n",
      "Epoch 1684, Loss: 918.0172729492188, Neurons: 27, Grad norm: 7.802e+01\n",
      "Epoch 1685, Loss: 917.4190063476562, Neurons: 27, Grad norm: 7.949e+01\n",
      "Epoch 1685, Loss: 917.4190063476562, Neurons: 27, Grad norm: 7.949e+01\n",
      "Epoch 1686, Loss: 916.8041381835938, Neurons: 27, Grad norm: 8.115e+01\n",
      "Epoch 1686, Loss: 916.8041381835938, Neurons: 27, Grad norm: 8.115e+01\n",
      "Epoch 1687, Loss: 916.1715698242188, Neurons: 27, Grad norm: 8.304e+01\n",
      "Epoch 1687, Loss: 916.1715698242188, Neurons: 27, Grad norm: 8.304e+01\n",
      "Epoch 1688, Loss: 915.5197143554688, Neurons: 27, Grad norm: 8.517e+01\n",
      "Epoch 1688, Loss: 915.5197143554688, Neurons: 27, Grad norm: 8.517e+01\n",
      "Epoch 1689, Loss: 914.84716796875, Neurons: 27, Grad norm: 8.757e+01\n",
      "Epoch 1689, Loss: 914.84716796875, Neurons: 27, Grad norm: 8.757e+01\n",
      "Epoch 1690, Loss: 914.1522827148438, Neurons: 27, Grad norm: 9.025e+01\n",
      "Epoch 1690, Loss: 914.1522827148438, Neurons: 27, Grad norm: 9.025e+01\n",
      "Epoch 1691, Loss: 913.4332885742188, Neurons: 27, Grad norm: 9.326e+01\n",
      "Epoch 1691, Loss: 913.4332885742188, Neurons: 27, Grad norm: 9.326e+01\n",
      "Epoch 1692, Loss: 912.688232421875, Neurons: 27, Grad norm: 9.660e+01\n",
      "Epoch 1692, Loss: 912.688232421875, Neurons: 27, Grad norm: 9.660e+01\n",
      "Epoch 1693, Loss: 911.9151611328125, Neurons: 27, Grad norm: 1.003e+02\n",
      "Epoch 1693, Loss: 911.9151611328125, Neurons: 27, Grad norm: 1.003e+02\n",
      "Epoch 1694, Loss: 911.1119384765625, Neurons: 27, Grad norm: 1.044e+02\n",
      "Epoch 1694, Loss: 911.1119384765625, Neurons: 27, Grad norm: 1.044e+02\n",
      "Epoch 1695, Loss: 910.2763061523438, Neurons: 27, Grad norm: 1.088e+02\n",
      "Epoch 1695, Loss: 910.2763061523438, Neurons: 27, Grad norm: 1.088e+02\n",
      "Epoch 1696, Loss: 909.4059448242188, Neurons: 27, Grad norm: 1.136e+02\n",
      "Epoch 1696, Loss: 909.4059448242188, Neurons: 27, Grad norm: 1.136e+02\n",
      "Epoch 1697, Loss: 908.4984130859375, Neurons: 27, Grad norm: 1.187e+02\n",
      "Epoch 1697, Loss: 908.4984130859375, Neurons: 27, Grad norm: 1.187e+02\n",
      "Epoch 1698, Loss: 907.55126953125, Neurons: 27, Grad norm: 1.241e+02\n",
      "Epoch 1698, Loss: 907.55126953125, Neurons: 27, Grad norm: 1.241e+02\n",
      "Epoch 1699, Loss: 906.5623168945312, Neurons: 27, Grad norm: 1.299e+02\n",
      "Epoch 1699, Loss: 906.5623168945312, Neurons: 27, Grad norm: 1.299e+02\n",
      "Epoch 1699, Test loss: 914.8329467773438\n",
      "Epoch 1699, Test loss: 914.8329467773438\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "network shape updated to :[11, 16, 1]\n",
      "network shape updated to :[11, 16, 1]\n",
      "Epoch 1700, Loss: 913.529052734375, Neurons: 28, Grad norm: 1.369e+02\n",
      "Epoch 1700, Loss: 913.529052734375, Neurons: 28, Grad norm: 1.369e+02\n",
      "Epoch 1701, Loss: 913.2355346679688, Neurons: 28, Grad norm: 1.365e+02\n",
      "Epoch 1701, Loss: 913.2355346679688, Neurons: 28, Grad norm: 1.365e+02\n",
      "Epoch 1702, Loss: 912.9299926757812, Neurons: 28, Grad norm: 1.362e+02\n",
      "Epoch 1702, Loss: 912.9299926757812, Neurons: 28, Grad norm: 1.362e+02\n",
      "Epoch 1703, Loss: 912.6124267578125, Neurons: 28, Grad norm: 1.359e+02\n",
      "Epoch 1703, Loss: 912.6124267578125, Neurons: 28, Grad norm: 1.359e+02\n",
      "Epoch 1704, Loss: 912.2830200195312, Neurons: 28, Grad norm: 1.358e+02\n",
      "Epoch 1704, Loss: 912.2830200195312, Neurons: 28, Grad norm: 1.358e+02\n",
      "Epoch 1705, Loss: 911.94189453125, Neurons: 28, Grad norm: 1.358e+02\n",
      "Epoch 1705, Loss: 911.94189453125, Neurons: 28, Grad norm: 1.358e+02\n",
      "Epoch 1706, Loss: 911.5888061523438, Neurons: 28, Grad norm: 1.360e+02\n",
      "Epoch 1706, Loss: 911.5888061523438, Neurons: 28, Grad norm: 1.360e+02\n",
      "Epoch 1707, Loss: 911.2232666015625, Neurons: 28, Grad norm: 1.363e+02\n",
      "Epoch 1707, Loss: 911.2232666015625, Neurons: 28, Grad norm: 1.363e+02\n",
      "Epoch 1708, Loss: 910.8455200195312, Neurons: 28, Grad norm: 1.367e+02\n",
      "Epoch 1708, Loss: 910.8455200195312, Neurons: 28, Grad norm: 1.367e+02\n",
      "Epoch 1709, Loss: 910.4548950195312, Neurons: 28, Grad norm: 1.374e+02\n",
      "Epoch 1709, Loss: 910.4548950195312, Neurons: 28, Grad norm: 1.374e+02\n",
      "Epoch 1710, Loss: 910.0511474609375, Neurons: 28, Grad norm: 1.381e+02\n",
      "Epoch 1710, Loss: 910.0511474609375, Neurons: 28, Grad norm: 1.381e+02\n",
      "Epoch 1711, Loss: 909.6339111328125, Neurons: 28, Grad norm: 1.391e+02\n",
      "Epoch 1711, Loss: 909.6339111328125, Neurons: 28, Grad norm: 1.391e+02\n",
      "Epoch 1712, Loss: 909.2028198242188, Neurons: 28, Grad norm: 1.401e+02\n",
      "Epoch 1712, Loss: 909.2028198242188, Neurons: 28, Grad norm: 1.401e+02\n",
      "Epoch 1713, Loss: 908.7572631835938, Neurons: 28, Grad norm: 1.414e+02\n",
      "Epoch 1713, Loss: 908.7572631835938, Neurons: 28, Grad norm: 1.414e+02\n",
      "Epoch 1714, Loss: 908.2966918945312, Neurons: 28, Grad norm: 1.427e+02\n",
      "Epoch 1714, Loss: 908.2966918945312, Neurons: 28, Grad norm: 1.427e+02\n",
      "Epoch 1715, Loss: 907.820556640625, Neurons: 28, Grad norm: 1.442e+02\n",
      "Epoch 1715, Loss: 907.820556640625, Neurons: 28, Grad norm: 1.442e+02\n",
      "Epoch 1716, Loss: 907.328369140625, Neurons: 28, Grad norm: 1.458e+02\n",
      "Epoch 1716, Loss: 907.328369140625, Neurons: 28, Grad norm: 1.458e+02\n",
      "Epoch 1717, Loss: 906.8195190429688, Neurons: 28, Grad norm: 1.476e+02\n",
      "Epoch 1717, Loss: 906.8195190429688, Neurons: 28, Grad norm: 1.476e+02\n",
      "Epoch 1718, Loss: 906.2932739257812, Neurons: 28, Grad norm: 1.494e+02\n",
      "Epoch 1718, Loss: 906.2932739257812, Neurons: 28, Grad norm: 1.494e+02\n",
      "Epoch 1719, Loss: 905.7491455078125, Neurons: 28, Grad norm: 1.514e+02\n",
      "Epoch 1719, Loss: 905.7491455078125, Neurons: 28, Grad norm: 1.514e+02\n",
      "Epoch 1720, Loss: 905.1865844726562, Neurons: 28, Grad norm: 1.534e+02\n",
      "Epoch 1720, Loss: 905.1865844726562, Neurons: 28, Grad norm: 1.534e+02\n",
      "Epoch 1721, Loss: 904.6047973632812, Neurons: 28, Grad norm: 1.555e+02\n",
      "Epoch 1721, Loss: 904.6047973632812, Neurons: 28, Grad norm: 1.555e+02\n",
      "Epoch 1722, Loss: 904.003173828125, Neurons: 28, Grad norm: 1.577e+02\n",
      "Epoch 1722, Loss: 904.003173828125, Neurons: 28, Grad norm: 1.577e+02\n",
      "Epoch 1723, Loss: 903.3810424804688, Neurons: 28, Grad norm: 1.600e+02\n",
      "Epoch 1723, Loss: 903.3810424804688, Neurons: 28, Grad norm: 1.600e+02\n",
      "Epoch 1724, Loss: 902.7379150390625, Neurons: 28, Grad norm: 1.623e+02\n",
      "Epoch 1724, Loss: 902.7379150390625, Neurons: 28, Grad norm: 1.623e+02\n",
      "Epoch 1725, Loss: 902.0731201171875, Neurons: 28, Grad norm: 1.646e+02\n",
      "Epoch 1725, Loss: 902.0731201171875, Neurons: 28, Grad norm: 1.646e+02\n",
      "Epoch 1726, Loss: 901.3860473632812, Neurons: 28, Grad norm: 1.669e+02\n",
      "Epoch 1726, Loss: 901.3860473632812, Neurons: 28, Grad norm: 1.669e+02\n",
      "Epoch 1727, Loss: 900.6761474609375, Neurons: 28, Grad norm: 1.692e+02\n",
      "Epoch 1727, Loss: 900.6761474609375, Neurons: 28, Grad norm: 1.692e+02\n",
      "Epoch 1728, Loss: 899.9431762695312, Neurons: 28, Grad norm: 1.715e+02\n",
      "Epoch 1728, Loss: 899.9431762695312, Neurons: 28, Grad norm: 1.715e+02\n",
      "Epoch 1729, Loss: 899.1865234375, Neurons: 28, Grad norm: 1.737e+02\n",
      "Epoch 1729, Loss: 899.1865234375, Neurons: 28, Grad norm: 1.737e+02\n",
      "Epoch 1730, Loss: 898.4060668945312, Neurons: 28, Grad norm: 1.758e+02\n",
      "Epoch 1730, Loss: 898.4060668945312, Neurons: 28, Grad norm: 1.758e+02\n",
      "Epoch 1731, Loss: 897.6015625, Neurons: 28, Grad norm: 1.778e+02\n",
      "Epoch 1731, Loss: 897.6015625, Neurons: 28, Grad norm: 1.778e+02\n",
      "Epoch 1732, Loss: 896.7728881835938, Neurons: 28, Grad norm: 1.798e+02\n",
      "Epoch 1732, Loss: 896.7728881835938, Neurons: 28, Grad norm: 1.798e+02\n",
      "Epoch 1733, Loss: 895.920166015625, Neurons: 28, Grad norm: 1.815e+02\n",
      "Epoch 1733, Loss: 895.920166015625, Neurons: 28, Grad norm: 1.815e+02\n",
      "Epoch 1734, Loss: 895.0436401367188, Neurons: 28, Grad norm: 1.831e+02\n",
      "Epoch 1734, Loss: 895.0436401367188, Neurons: 28, Grad norm: 1.831e+02\n",
      "Epoch 1735, Loss: 894.1439208984375, Neurons: 28, Grad norm: 1.845e+02\n",
      "Epoch 1735, Loss: 894.1439208984375, Neurons: 28, Grad norm: 1.845e+02\n",
      "Epoch 1736, Loss: 893.2213745117188, Neurons: 28, Grad norm: 1.856e+02\n",
      "Epoch 1736, Loss: 893.2213745117188, Neurons: 28, Grad norm: 1.856e+02\n",
      "Epoch 1737, Loss: 892.2767944335938, Neurons: 28, Grad norm: 1.865e+02\n",
      "Epoch 1737, Loss: 892.2767944335938, Neurons: 28, Grad norm: 1.865e+02\n",
      "Epoch 1738, Loss: 891.311279296875, Neurons: 28, Grad norm: 1.872e+02\n",
      "Epoch 1738, Loss: 891.311279296875, Neurons: 28, Grad norm: 1.872e+02\n",
      "Epoch 1739, Loss: 890.326171875, Neurons: 28, Grad norm: 1.875e+02\n",
      "Epoch 1739, Loss: 890.326171875, Neurons: 28, Grad norm: 1.875e+02\n",
      "Epoch 1740, Loss: 889.32275390625, Neurons: 28, Grad norm: 1.876e+02\n",
      "Epoch 1740, Loss: 889.32275390625, Neurons: 28, Grad norm: 1.876e+02\n",
      "Epoch 1741, Loss: 888.302490234375, Neurons: 28, Grad norm: 1.873e+02\n",
      "Epoch 1741, Loss: 888.302490234375, Neurons: 28, Grad norm: 1.873e+02\n",
      "Epoch 1742, Loss: 887.2671508789062, Neurons: 28, Grad norm: 1.868e+02\n",
      "Epoch 1742, Loss: 887.2671508789062, Neurons: 28, Grad norm: 1.868e+02\n",
      "Epoch 1743, Loss: 886.2186279296875, Neurons: 28, Grad norm: 1.860e+02\n",
      "Epoch 1743, Loss: 886.2186279296875, Neurons: 28, Grad norm: 1.860e+02\n",
      "Epoch 1744, Loss: 885.158447265625, Neurons: 28, Grad norm: 1.849e+02\n",
      "Epoch 1744, Loss: 885.158447265625, Neurons: 28, Grad norm: 1.849e+02\n",
      "Epoch 1745, Loss: 884.0884399414062, Neurons: 28, Grad norm: 1.836e+02\n",
      "Epoch 1745, Loss: 884.0884399414062, Neurons: 28, Grad norm: 1.836e+02\n",
      "Epoch 1746, Loss: 883.0101928710938, Neurons: 28, Grad norm: 1.820e+02\n",
      "Epoch 1746, Loss: 883.0101928710938, Neurons: 28, Grad norm: 1.820e+02\n",
      "Epoch 1747, Loss: 881.9253540039062, Neurons: 28, Grad norm: 1.803e+02\n",
      "Epoch 1747, Loss: 881.9253540039062, Neurons: 28, Grad norm: 1.803e+02\n",
      "Epoch 1748, Loss: 880.8353881835938, Neurons: 28, Grad norm: 1.784e+02\n",
      "Epoch 1748, Loss: 880.8353881835938, Neurons: 28, Grad norm: 1.784e+02\n",
      "Epoch 1749, Loss: 879.7418212890625, Neurons: 28, Grad norm: 1.764e+02\n",
      "Epoch 1749, Loss: 879.7418212890625, Neurons: 28, Grad norm: 1.764e+02\n",
      "Epoch 1750, Loss: 878.6456909179688, Neurons: 28, Grad norm: 1.743e+02\n",
      "Epoch 1750, Loss: 878.6456909179688, Neurons: 28, Grad norm: 1.743e+02\n",
      "Epoch 1751, Loss: 877.5481567382812, Neurons: 28, Grad norm: 1.722e+02\n",
      "Epoch 1751, Loss: 877.5481567382812, Neurons: 28, Grad norm: 1.722e+02\n",
      "Epoch 1752, Loss: 876.4501953125, Neurons: 28, Grad norm: 1.701e+02\n",
      "Epoch 1752, Loss: 876.4501953125, Neurons: 28, Grad norm: 1.701e+02\n",
      "Epoch 1753, Loss: 875.3525390625, Neurons: 28, Grad norm: 1.680e+02\n",
      "Epoch 1753, Loss: 875.3525390625, Neurons: 28, Grad norm: 1.680e+02\n",
      "Epoch 1754, Loss: 874.2557983398438, Neurons: 28, Grad norm: 1.660e+02\n",
      "Epoch 1754, Loss: 874.2557983398438, Neurons: 28, Grad norm: 1.660e+02\n",
      "Epoch 1755, Loss: 873.1602783203125, Neurons: 28, Grad norm: 1.641e+02\n",
      "Epoch 1755, Loss: 873.1602783203125, Neurons: 28, Grad norm: 1.641e+02\n",
      "Epoch 1756, Loss: 872.0662841796875, Neurons: 28, Grad norm: 1.622e+02\n",
      "Epoch 1756, Loss: 872.0662841796875, Neurons: 28, Grad norm: 1.622e+02\n",
      "Epoch 1757, Loss: 870.9738159179688, Neurons: 28, Grad norm: 1.605e+02\n",
      "Epoch 1757, Loss: 870.9738159179688, Neurons: 28, Grad norm: 1.605e+02\n",
      "Epoch 1758, Loss: 869.8826904296875, Neurons: 28, Grad norm: 1.590e+02\n",
      "Epoch 1758, Loss: 869.8826904296875, Neurons: 28, Grad norm: 1.590e+02\n",
      "Epoch 1759, Loss: 868.7925415039062, Neurons: 28, Grad norm: 1.576e+02\n",
      "Epoch 1759, Loss: 868.7925415039062, Neurons: 28, Grad norm: 1.576e+02\n",
      "Epoch 1760, Loss: 867.7030029296875, Neurons: 28, Grad norm: 1.564e+02\n",
      "Epoch 1760, Loss: 867.7030029296875, Neurons: 28, Grad norm: 1.564e+02\n",
      "Epoch 1761, Loss: 866.6134033203125, Neurons: 28, Grad norm: 1.553e+02\n",
      "Epoch 1761, Loss: 866.6134033203125, Neurons: 28, Grad norm: 1.553e+02\n",
      "Epoch 1762, Loss: 865.5233764648438, Neurons: 28, Grad norm: 1.544e+02\n",
      "Epoch 1762, Loss: 865.5233764648438, Neurons: 28, Grad norm: 1.544e+02\n",
      "Epoch 1763, Loss: 864.4319458007812, Neurons: 28, Grad norm: 1.536e+02\n",
      "Epoch 1763, Loss: 864.4319458007812, Neurons: 28, Grad norm: 1.536e+02\n",
      "Epoch 1764, Loss: 863.3383178710938, Neurons: 28, Grad norm: 1.530e+02\n",
      "Epoch 1764, Loss: 863.3383178710938, Neurons: 28, Grad norm: 1.530e+02\n",
      "Epoch 1765, Loss: 862.2420043945312, Neurons: 28, Grad norm: 1.525e+02\n",
      "Epoch 1765, Loss: 862.2420043945312, Neurons: 28, Grad norm: 1.525e+02\n",
      "Epoch 1766, Loss: 861.1419677734375, Neurons: 28, Grad norm: 1.522e+02\n",
      "Epoch 1766, Loss: 861.1419677734375, Neurons: 28, Grad norm: 1.522e+02\n",
      "Epoch 1767, Loss: 860.0377197265625, Neurons: 28, Grad norm: 1.519e+02\n",
      "Epoch 1767, Loss: 860.0377197265625, Neurons: 28, Grad norm: 1.519e+02\n",
      "Epoch 1768, Loss: 858.9285888671875, Neurons: 28, Grad norm: 1.518e+02\n",
      "Epoch 1768, Loss: 858.9285888671875, Neurons: 28, Grad norm: 1.518e+02\n",
      "Epoch 1769, Loss: 857.8139038085938, Neurons: 28, Grad norm: 1.517e+02\n",
      "Epoch 1769, Loss: 857.8139038085938, Neurons: 28, Grad norm: 1.517e+02\n",
      "Epoch 1770, Loss: 856.6931762695312, Neurons: 28, Grad norm: 1.517e+02\n",
      "Epoch 1770, Loss: 856.6931762695312, Neurons: 28, Grad norm: 1.517e+02\n",
      "Epoch 1771, Loss: 855.5657958984375, Neurons: 28, Grad norm: 1.518e+02\n",
      "Epoch 1771, Loss: 855.5657958984375, Neurons: 28, Grad norm: 1.518e+02\n",
      "Epoch 1772, Loss: 854.4315795898438, Neurons: 28, Grad norm: 1.519e+02\n",
      "Epoch 1772, Loss: 854.4315795898438, Neurons: 28, Grad norm: 1.519e+02\n",
      "Epoch 1773, Loss: 853.2901611328125, Neurons: 28, Grad norm: 1.520e+02\n",
      "Epoch 1773, Loss: 853.2901611328125, Neurons: 28, Grad norm: 1.520e+02\n",
      "Epoch 1774, Loss: 852.1412353515625, Neurons: 28, Grad norm: 1.520e+02\n",
      "Epoch 1774, Loss: 852.1412353515625, Neurons: 28, Grad norm: 1.520e+02\n",
      "Epoch 1775, Loss: 850.9848022460938, Neurons: 28, Grad norm: 1.521e+02\n",
      "Epoch 1775, Loss: 850.9848022460938, Neurons: 28, Grad norm: 1.521e+02\n",
      "Epoch 1776, Loss: 849.8208618164062, Neurons: 28, Grad norm: 1.520e+02\n",
      "Epoch 1776, Loss: 849.8208618164062, Neurons: 28, Grad norm: 1.520e+02\n",
      "Epoch 1777, Loss: 848.6494140625, Neurons: 28, Grad norm: 1.519e+02\n",
      "Epoch 1777, Loss: 848.6494140625, Neurons: 28, Grad norm: 1.519e+02\n",
      "Epoch 1778, Loss: 847.4707641601562, Neurons: 28, Grad norm: 1.517e+02\n",
      "Epoch 1778, Loss: 847.4707641601562, Neurons: 28, Grad norm: 1.517e+02\n",
      "Epoch 1779, Loss: 846.2853393554688, Neurons: 28, Grad norm: 1.513e+02\n",
      "Epoch 1779, Loss: 846.2853393554688, Neurons: 28, Grad norm: 1.513e+02\n",
      "Epoch 1780, Loss: 845.0938110351562, Neurons: 28, Grad norm: 1.507e+02\n",
      "Epoch 1780, Loss: 845.0938110351562, Neurons: 28, Grad norm: 1.507e+02\n",
      "Epoch 1781, Loss: 843.8966674804688, Neurons: 28, Grad norm: 1.499e+02\n",
      "Epoch 1781, Loss: 843.8966674804688, Neurons: 28, Grad norm: 1.499e+02\n",
      "Epoch 1782, Loss: 842.6951904296875, Neurons: 28, Grad norm: 1.490e+02\n",
      "Epoch 1782, Loss: 842.6951904296875, Neurons: 28, Grad norm: 1.490e+02\n",
      "Epoch 1783, Loss: 841.4902954101562, Neurons: 28, Grad norm: 1.478e+02\n",
      "Epoch 1783, Loss: 841.4902954101562, Neurons: 28, Grad norm: 1.478e+02\n",
      "Epoch 1784, Loss: 840.2836303710938, Neurons: 28, Grad norm: 1.464e+02\n",
      "Epoch 1784, Loss: 840.2836303710938, Neurons: 28, Grad norm: 1.464e+02\n",
      "Epoch 1785, Loss: 839.07666015625, Neurons: 28, Grad norm: 1.448e+02\n",
      "Epoch 1785, Loss: 839.07666015625, Neurons: 28, Grad norm: 1.448e+02\n",
      "Epoch 1786, Loss: 837.8712768554688, Neurons: 28, Grad norm: 1.429e+02\n",
      "Epoch 1786, Loss: 837.8712768554688, Neurons: 28, Grad norm: 1.429e+02\n",
      "Epoch 1787, Loss: 836.6695556640625, Neurons: 28, Grad norm: 1.409e+02\n",
      "Epoch 1787, Loss: 836.6695556640625, Neurons: 28, Grad norm: 1.409e+02\n",
      "Epoch 1788, Loss: 835.4735717773438, Neurons: 28, Grad norm: 1.387e+02\n",
      "Epoch 1788, Loss: 835.4735717773438, Neurons: 28, Grad norm: 1.387e+02\n",
      "Epoch 1789, Loss: 834.285888671875, Neurons: 28, Grad norm: 1.364e+02\n",
      "Epoch 1789, Loss: 834.285888671875, Neurons: 28, Grad norm: 1.364e+02\n",
      "Epoch 1790, Loss: 833.1087036132812, Neurons: 28, Grad norm: 1.339e+02\n",
      "Epoch 1790, Loss: 833.1087036132812, Neurons: 28, Grad norm: 1.339e+02\n",
      "Epoch 1791, Loss: 831.9443969726562, Neurons: 28, Grad norm: 1.314e+02\n",
      "Epoch 1791, Loss: 831.9443969726562, Neurons: 28, Grad norm: 1.314e+02\n",
      "Epoch 1792, Loss: 830.795166015625, Neurons: 28, Grad norm: 1.288e+02\n",
      "Epoch 1792, Loss: 830.795166015625, Neurons: 28, Grad norm: 1.288e+02\n",
      "Epoch 1793, Loss: 829.6629028320312, Neurons: 28, Grad norm: 1.263e+02\n",
      "Epoch 1793, Loss: 829.6629028320312, Neurons: 28, Grad norm: 1.263e+02\n",
      "Epoch 1794, Loss: 828.5490112304688, Neurons: 28, Grad norm: 1.238e+02\n",
      "Epoch 1794, Loss: 828.5490112304688, Neurons: 28, Grad norm: 1.238e+02\n",
      "Epoch 1795, Loss: 827.4547729492188, Neurons: 28, Grad norm: 1.214e+02\n",
      "Epoch 1795, Loss: 827.4547729492188, Neurons: 28, Grad norm: 1.214e+02\n",
      "Epoch 1796, Loss: 826.3806762695312, Neurons: 28, Grad norm: 1.191e+02\n",
      "Epoch 1796, Loss: 826.3806762695312, Neurons: 28, Grad norm: 1.191e+02\n",
      "Epoch 1797, Loss: 825.326904296875, Neurons: 28, Grad norm: 1.170e+02\n",
      "Epoch 1797, Loss: 825.326904296875, Neurons: 28, Grad norm: 1.170e+02\n",
      "Epoch 1798, Loss: 824.2930908203125, Neurons: 28, Grad norm: 1.150e+02\n",
      "Epoch 1798, Loss: 824.2930908203125, Neurons: 28, Grad norm: 1.150e+02\n",
      "Epoch 1799, Loss: 823.2786865234375, Neurons: 28, Grad norm: 1.131e+02\n",
      "Epoch 1799, Loss: 823.2786865234375, Neurons: 28, Grad norm: 1.131e+02\n",
      "Epoch 1799, Test loss: 829.5995483398438\n",
      "Epoch 1799, Test loss: 829.5995483398438\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "network shape updated to :[11, 17, 1]\n",
      "network shape updated to :[11, 17, 1]\n",
      "Epoch 1800, Loss: 821.9037475585938, Neurons: 29, Grad norm: 1.162e+02\n",
      "Epoch 1800, Loss: 821.9037475585938, Neurons: 29, Grad norm: 1.162e+02\n",
      "Epoch 1801, Loss: 821.6461791992188, Neurons: 29, Grad norm: 1.157e+02\n",
      "Epoch 1801, Loss: 821.6461791992188, Neurons: 29, Grad norm: 1.157e+02\n",
      "Epoch 1802, Loss: 821.37744140625, Neurons: 29, Grad norm: 1.152e+02\n",
      "Epoch 1802, Loss: 821.37744140625, Neurons: 29, Grad norm: 1.152e+02\n",
      "Epoch 1803, Loss: 821.09765625, Neurons: 29, Grad norm: 1.147e+02\n",
      "Epoch 1803, Loss: 821.09765625, Neurons: 29, Grad norm: 1.147e+02\n",
      "Epoch 1804, Loss: 820.8071899414062, Neurons: 29, Grad norm: 1.141e+02\n",
      "Epoch 1804, Loss: 820.8071899414062, Neurons: 29, Grad norm: 1.141e+02\n",
      "Epoch 1805, Loss: 820.5062255859375, Neurons: 29, Grad norm: 1.136e+02\n",
      "Epoch 1805, Loss: 820.5062255859375, Neurons: 29, Grad norm: 1.136e+02\n",
      "Epoch 1806, Loss: 820.1951293945312, Neurons: 29, Grad norm: 1.130e+02\n",
      "Epoch 1806, Loss: 820.1951293945312, Neurons: 29, Grad norm: 1.130e+02\n",
      "Epoch 1807, Loss: 819.8740234375, Neurons: 29, Grad norm: 1.123e+02\n",
      "Epoch 1807, Loss: 819.8740234375, Neurons: 29, Grad norm: 1.123e+02\n",
      "Epoch 1808, Loss: 819.5435180664062, Neurons: 29, Grad norm: 1.117e+02\n",
      "Epoch 1808, Loss: 819.5435180664062, Neurons: 29, Grad norm: 1.117e+02\n",
      "Epoch 1809, Loss: 819.2040405273438, Neurons: 29, Grad norm: 1.110e+02\n",
      "Epoch 1809, Loss: 819.2040405273438, Neurons: 29, Grad norm: 1.110e+02\n",
      "Epoch 1810, Loss: 818.8558959960938, Neurons: 29, Grad norm: 1.103e+02\n",
      "Epoch 1810, Loss: 818.8558959960938, Neurons: 29, Grad norm: 1.103e+02\n",
      "Epoch 1811, Loss: 818.4993896484375, Neurons: 29, Grad norm: 1.096e+02\n",
      "Epoch 1811, Loss: 818.4993896484375, Neurons: 29, Grad norm: 1.096e+02\n",
      "Epoch 1812, Loss: 818.13525390625, Neurons: 29, Grad norm: 1.088e+02\n",
      "Epoch 1812, Loss: 818.13525390625, Neurons: 29, Grad norm: 1.088e+02\n",
      "Epoch 1813, Loss: 817.763916015625, Neurons: 29, Grad norm: 1.080e+02\n",
      "Epoch 1813, Loss: 817.763916015625, Neurons: 29, Grad norm: 1.080e+02\n",
      "Epoch 1814, Loss: 817.3856811523438, Neurons: 29, Grad norm: 1.073e+02\n",
      "Epoch 1814, Loss: 817.3856811523438, Neurons: 29, Grad norm: 1.073e+02\n",
      "Epoch 1815, Loss: 817.0009765625, Neurons: 29, Grad norm: 1.065e+02\n",
      "Epoch 1815, Loss: 817.0009765625, Neurons: 29, Grad norm: 1.065e+02\n",
      "Epoch 1816, Loss: 816.6101684570312, Neurons: 29, Grad norm: 1.057e+02\n",
      "Epoch 1816, Loss: 816.6101684570312, Neurons: 29, Grad norm: 1.057e+02\n",
      "Epoch 1817, Loss: 816.2138061523438, Neurons: 29, Grad norm: 1.049e+02\n",
      "Epoch 1817, Loss: 816.2138061523438, Neurons: 29, Grad norm: 1.049e+02\n",
      "Epoch 1818, Loss: 815.81201171875, Neurons: 29, Grad norm: 1.041e+02\n",
      "Epoch 1818, Loss: 815.81201171875, Neurons: 29, Grad norm: 1.041e+02\n",
      "Epoch 1819, Loss: 815.4052124023438, Neurons: 29, Grad norm: 1.034e+02\n",
      "Epoch 1819, Loss: 815.4052124023438, Neurons: 29, Grad norm: 1.034e+02\n",
      "Epoch 1820, Loss: 814.9935302734375, Neurons: 29, Grad norm: 1.026e+02\n",
      "Epoch 1820, Loss: 814.9935302734375, Neurons: 29, Grad norm: 1.026e+02\n",
      "Epoch 1821, Loss: 814.5772705078125, Neurons: 29, Grad norm: 1.019e+02\n",
      "Epoch 1821, Loss: 814.5772705078125, Neurons: 29, Grad norm: 1.019e+02\n",
      "Epoch 1822, Loss: 814.15673828125, Neurons: 29, Grad norm: 1.012e+02\n",
      "Epoch 1822, Loss: 814.15673828125, Neurons: 29, Grad norm: 1.012e+02\n",
      "Epoch 1823, Loss: 813.73193359375, Neurons: 29, Grad norm: 1.005e+02\n",
      "Epoch 1823, Loss: 813.73193359375, Neurons: 29, Grad norm: 1.005e+02\n",
      "Epoch 1824, Loss: 813.3028564453125, Neurons: 29, Grad norm: 9.983e+01\n",
      "Epoch 1824, Loss: 813.3028564453125, Neurons: 29, Grad norm: 9.983e+01\n",
      "Epoch 1825, Loss: 812.869873046875, Neurons: 29, Grad norm: 9.920e+01\n",
      "Epoch 1825, Loss: 812.869873046875, Neurons: 29, Grad norm: 9.920e+01\n",
      "Epoch 1826, Loss: 812.4330444335938, Neurons: 29, Grad norm: 9.861e+01\n",
      "Epoch 1826, Loss: 812.4330444335938, Neurons: 29, Grad norm: 9.861e+01\n",
      "Epoch 1827, Loss: 811.9923706054688, Neurons: 29, Grad norm: 9.805e+01\n",
      "Epoch 1827, Loss: 811.9923706054688, Neurons: 29, Grad norm: 9.805e+01\n",
      "Epoch 1828, Loss: 811.5478515625, Neurons: 29, Grad norm: 9.754e+01\n",
      "Epoch 1828, Loss: 811.5478515625, Neurons: 29, Grad norm: 9.754e+01\n",
      "Epoch 1829, Loss: 811.0997314453125, Neurons: 29, Grad norm: 9.706e+01\n",
      "Epoch 1829, Loss: 811.0997314453125, Neurons: 29, Grad norm: 9.706e+01\n",
      "Epoch 1830, Loss: 810.6477661132812, Neurons: 29, Grad norm: 9.661e+01\n",
      "Epoch 1830, Loss: 810.6477661132812, Neurons: 29, Grad norm: 9.661e+01\n",
      "Epoch 1831, Loss: 810.1922607421875, Neurons: 29, Grad norm: 9.619e+01\n",
      "Epoch 1831, Loss: 810.1922607421875, Neurons: 29, Grad norm: 9.619e+01\n",
      "Epoch 1832, Loss: 809.7330932617188, Neurons: 29, Grad norm: 9.580e+01\n",
      "Epoch 1832, Loss: 809.7330932617188, Neurons: 29, Grad norm: 9.580e+01\n",
      "Epoch 1833, Loss: 809.270263671875, Neurons: 29, Grad norm: 9.544e+01\n",
      "Epoch 1833, Loss: 809.270263671875, Neurons: 29, Grad norm: 9.544e+01\n",
      "Epoch 1834, Loss: 808.8037719726562, Neurons: 29, Grad norm: 9.511e+01\n",
      "Epoch 1834, Loss: 808.8037719726562, Neurons: 29, Grad norm: 9.511e+01\n",
      "Epoch 1835, Loss: 808.3336791992188, Neurons: 29, Grad norm: 9.480e+01\n",
      "Epoch 1835, Loss: 808.3336791992188, Neurons: 29, Grad norm: 9.480e+01\n",
      "Epoch 1836, Loss: 807.8599243164062, Neurons: 29, Grad norm: 9.452e+01\n",
      "Epoch 1836, Loss: 807.8599243164062, Neurons: 29, Grad norm: 9.452e+01\n",
      "Epoch 1837, Loss: 807.3823852539062, Neurons: 29, Grad norm: 9.426e+01\n",
      "Epoch 1837, Loss: 807.3823852539062, Neurons: 29, Grad norm: 9.426e+01\n",
      "Epoch 1838, Loss: 806.9012451171875, Neurons: 29, Grad norm: 9.402e+01\n",
      "Epoch 1838, Loss: 806.9012451171875, Neurons: 29, Grad norm: 9.402e+01\n",
      "Epoch 1839, Loss: 806.4161376953125, Neurons: 29, Grad norm: 9.379e+01\n",
      "Epoch 1839, Loss: 806.4161376953125, Neurons: 29, Grad norm: 9.379e+01\n",
      "Epoch 1840, Loss: 805.9273071289062, Neurons: 29, Grad norm: 9.359e+01\n",
      "Epoch 1840, Loss: 805.9273071289062, Neurons: 29, Grad norm: 9.359e+01\n",
      "Epoch 1841, Loss: 805.4345092773438, Neurons: 29, Grad norm: 9.340e+01\n",
      "Epoch 1841, Loss: 805.4345092773438, Neurons: 29, Grad norm: 9.340e+01\n",
      "Epoch 1842, Loss: 804.9378051757812, Neurons: 29, Grad norm: 9.324e+01\n",
      "Epoch 1842, Loss: 804.9378051757812, Neurons: 29, Grad norm: 9.324e+01\n",
      "Epoch 1843, Loss: 804.43701171875, Neurons: 29, Grad norm: 9.309e+01\n",
      "Epoch 1843, Loss: 804.43701171875, Neurons: 29, Grad norm: 9.309e+01\n",
      "Epoch 1844, Loss: 803.9321899414062, Neurons: 29, Grad norm: 9.296e+01\n",
      "Epoch 1844, Loss: 803.9321899414062, Neurons: 29, Grad norm: 9.296e+01\n",
      "Epoch 1845, Loss: 803.423095703125, Neurons: 29, Grad norm: 9.285e+01\n",
      "Epoch 1845, Loss: 803.423095703125, Neurons: 29, Grad norm: 9.285e+01\n",
      "Epoch 1846, Loss: 802.9097900390625, Neurons: 29, Grad norm: 9.276e+01\n",
      "Epoch 1846, Loss: 802.9097900390625, Neurons: 29, Grad norm: 9.276e+01\n",
      "Epoch 1847, Loss: 802.39208984375, Neurons: 29, Grad norm: 9.269e+01\n",
      "Epoch 1847, Loss: 802.39208984375, Neurons: 29, Grad norm: 9.269e+01\n",
      "Epoch 1848, Loss: 801.8699951171875, Neurons: 29, Grad norm: 9.264e+01\n",
      "Epoch 1848, Loss: 801.8699951171875, Neurons: 29, Grad norm: 9.264e+01\n",
      "Epoch 1849, Loss: 801.34326171875, Neurons: 29, Grad norm: 9.262e+01\n",
      "Epoch 1849, Loss: 801.34326171875, Neurons: 29, Grad norm: 9.262e+01\n",
      "Epoch 1850, Loss: 800.8119506835938, Neurons: 29, Grad norm: 9.262e+01\n",
      "Epoch 1850, Loss: 800.8119506835938, Neurons: 29, Grad norm: 9.262e+01\n",
      "Epoch 1851, Loss: 800.2760009765625, Neurons: 29, Grad norm: 9.263e+01\n",
      "Epoch 1851, Loss: 800.2760009765625, Neurons: 29, Grad norm: 9.263e+01\n",
      "Epoch 1852, Loss: 799.7351684570312, Neurons: 29, Grad norm: 9.267e+01\n",
      "Epoch 1852, Loss: 799.7351684570312, Neurons: 29, Grad norm: 9.267e+01\n",
      "Epoch 1853, Loss: 799.1893920898438, Neurons: 29, Grad norm: 9.274e+01\n",
      "Epoch 1853, Loss: 799.1893920898438, Neurons: 29, Grad norm: 9.274e+01\n",
      "Epoch 1854, Loss: 798.638671875, Neurons: 29, Grad norm: 9.283e+01\n",
      "Epoch 1854, Loss: 798.638671875, Neurons: 29, Grad norm: 9.283e+01\n",
      "Epoch 1855, Loss: 798.0827026367188, Neurons: 29, Grad norm: 9.295e+01\n",
      "Epoch 1855, Loss: 798.0827026367188, Neurons: 29, Grad norm: 9.295e+01\n",
      "Epoch 1856, Loss: 797.5215454101562, Neurons: 29, Grad norm: 9.308e+01\n",
      "Epoch 1856, Loss: 797.5215454101562, Neurons: 29, Grad norm: 9.308e+01\n",
      "Epoch 1857, Loss: 796.9550170898438, Neurons: 29, Grad norm: 9.325e+01\n",
      "Epoch 1857, Loss: 796.9550170898438, Neurons: 29, Grad norm: 9.325e+01\n",
      "Epoch 1858, Loss: 796.383056640625, Neurons: 29, Grad norm: 9.345e+01\n",
      "Epoch 1858, Loss: 796.383056640625, Neurons: 29, Grad norm: 9.345e+01\n",
      "Epoch 1859, Loss: 795.805419921875, Neurons: 29, Grad norm: 9.366e+01\n",
      "Epoch 1859, Loss: 795.805419921875, Neurons: 29, Grad norm: 9.366e+01\n",
      "Epoch 1860, Loss: 795.2220458984375, Neurons: 29, Grad norm: 9.390e+01\n",
      "Epoch 1860, Loss: 795.2220458984375, Neurons: 29, Grad norm: 9.390e+01\n",
      "Epoch 1861, Loss: 794.6328125, Neurons: 29, Grad norm: 9.416e+01\n",
      "Epoch 1861, Loss: 794.6328125, Neurons: 29, Grad norm: 9.416e+01\n",
      "Epoch 1862, Loss: 794.03759765625, Neurons: 29, Grad norm: 9.444e+01\n",
      "Epoch 1862, Loss: 794.03759765625, Neurons: 29, Grad norm: 9.444e+01\n",
      "Epoch 1863, Loss: 793.4361572265625, Neurons: 29, Grad norm: 9.475e+01\n",
      "Epoch 1863, Loss: 793.4361572265625, Neurons: 29, Grad norm: 9.475e+01\n",
      "Epoch 1864, Loss: 792.8285522460938, Neurons: 29, Grad norm: 9.507e+01\n",
      "Epoch 1864, Loss: 792.8285522460938, Neurons: 29, Grad norm: 9.507e+01\n",
      "Epoch 1865, Loss: 792.2144165039062, Neurons: 29, Grad norm: 9.541e+01\n",
      "Epoch 1865, Loss: 792.2144165039062, Neurons: 29, Grad norm: 9.541e+01\n",
      "Epoch 1866, Loss: 791.5936889648438, Neurons: 29, Grad norm: 9.577e+01\n",
      "Epoch 1866, Loss: 791.5936889648438, Neurons: 29, Grad norm: 9.577e+01\n",
      "Epoch 1867, Loss: 790.96630859375, Neurons: 29, Grad norm: 9.615e+01\n",
      "Epoch 1867, Loss: 790.96630859375, Neurons: 29, Grad norm: 9.615e+01\n",
      "Epoch 1868, Loss: 790.3319091796875, Neurons: 29, Grad norm: 9.654e+01\n",
      "Epoch 1868, Loss: 790.3319091796875, Neurons: 29, Grad norm: 9.654e+01\n",
      "Epoch 1869, Loss: 789.690673828125, Neurons: 29, Grad norm: 9.695e+01\n",
      "Epoch 1869, Loss: 789.690673828125, Neurons: 29, Grad norm: 9.695e+01\n",
      "Epoch 1870, Loss: 789.0420532226562, Neurons: 29, Grad norm: 9.737e+01\n",
      "Epoch 1870, Loss: 789.0420532226562, Neurons: 29, Grad norm: 9.737e+01\n",
      "Epoch 1871, Loss: 788.38623046875, Neurons: 29, Grad norm: 9.781e+01\n",
      "Epoch 1871, Loss: 788.38623046875, Neurons: 29, Grad norm: 9.781e+01\n",
      "Epoch 1872, Loss: 787.7228393554688, Neurons: 29, Grad norm: 9.827e+01\n",
      "Epoch 1872, Loss: 787.7228393554688, Neurons: 29, Grad norm: 9.827e+01\n",
      "Epoch 1873, Loss: 787.0518798828125, Neurons: 29, Grad norm: 9.873e+01\n",
      "Epoch 1873, Loss: 787.0518798828125, Neurons: 29, Grad norm: 9.873e+01\n",
      "Epoch 1874, Loss: 786.373046875, Neurons: 29, Grad norm: 9.921e+01\n",
      "Epoch 1874, Loss: 786.373046875, Neurons: 29, Grad norm: 9.921e+01\n",
      "Epoch 1875, Loss: 785.6864013671875, Neurons: 29, Grad norm: 9.970e+01\n",
      "Epoch 1875, Loss: 785.6864013671875, Neurons: 29, Grad norm: 9.970e+01\n",
      "Epoch 1876, Loss: 784.9915161132812, Neurons: 29, Grad norm: 1.002e+02\n",
      "Epoch 1876, Loss: 784.9915161132812, Neurons: 29, Grad norm: 1.002e+02\n",
      "Epoch 1877, Loss: 784.2885131835938, Neurons: 29, Grad norm: 1.007e+02\n",
      "Epoch 1877, Loss: 784.2885131835938, Neurons: 29, Grad norm: 1.007e+02\n",
      "Epoch 1878, Loss: 783.5772094726562, Neurons: 29, Grad norm: 1.012e+02\n",
      "Epoch 1878, Loss: 783.5772094726562, Neurons: 29, Grad norm: 1.012e+02\n",
      "Epoch 1879, Loss: 782.857421875, Neurons: 29, Grad norm: 1.017e+02\n",
      "Epoch 1879, Loss: 782.857421875, Neurons: 29, Grad norm: 1.017e+02\n",
      "Epoch 1880, Loss: 782.1290283203125, Neurons: 29, Grad norm: 1.023e+02\n",
      "Epoch 1880, Loss: 782.1290283203125, Neurons: 29, Grad norm: 1.023e+02\n",
      "Epoch 1881, Loss: 781.3919677734375, Neurons: 29, Grad norm: 1.028e+02\n",
      "Epoch 1881, Loss: 781.3919677734375, Neurons: 29, Grad norm: 1.028e+02\n",
      "Epoch 1882, Loss: 780.6461791992188, Neurons: 29, Grad norm: 1.033e+02\n",
      "Epoch 1882, Loss: 780.6461791992188, Neurons: 29, Grad norm: 1.033e+02\n",
      "Epoch 1883, Loss: 779.891357421875, Neurons: 29, Grad norm: 1.038e+02\n",
      "Epoch 1883, Loss: 779.891357421875, Neurons: 29, Grad norm: 1.038e+02\n",
      "Epoch 1884, Loss: 779.1278076171875, Neurons: 29, Grad norm: 1.043e+02\n",
      "Epoch 1884, Loss: 779.1278076171875, Neurons: 29, Grad norm: 1.043e+02\n",
      "Epoch 1885, Loss: 778.3551635742188, Neurons: 29, Grad norm: 1.048e+02\n",
      "Epoch 1885, Loss: 778.3551635742188, Neurons: 29, Grad norm: 1.048e+02\n",
      "Epoch 1886, Loss: 777.5735473632812, Neurons: 29, Grad norm: 1.053e+02\n",
      "Epoch 1886, Loss: 777.5735473632812, Neurons: 29, Grad norm: 1.053e+02\n",
      "Epoch 1887, Loss: 776.7827758789062, Neurons: 29, Grad norm: 1.057e+02\n",
      "Epoch 1887, Loss: 776.7827758789062, Neurons: 29, Grad norm: 1.057e+02\n",
      "Epoch 1888, Loss: 775.983154296875, Neurons: 29, Grad norm: 1.062e+02\n",
      "Epoch 1888, Loss: 775.983154296875, Neurons: 29, Grad norm: 1.062e+02\n",
      "Epoch 1889, Loss: 775.1743774414062, Neurons: 29, Grad norm: 1.066e+02\n",
      "Epoch 1889, Loss: 775.1743774414062, Neurons: 29, Grad norm: 1.066e+02\n",
      "Epoch 1890, Loss: 774.356689453125, Neurons: 29, Grad norm: 1.070e+02\n",
      "Epoch 1890, Loss: 774.356689453125, Neurons: 29, Grad norm: 1.070e+02\n",
      "Epoch 1891, Loss: 773.5300903320312, Neurons: 29, Grad norm: 1.073e+02\n",
      "Epoch 1891, Loss: 773.5300903320312, Neurons: 29, Grad norm: 1.073e+02\n",
      "Epoch 1892, Loss: 772.6946411132812, Neurons: 29, Grad norm: 1.077e+02\n",
      "Epoch 1892, Loss: 772.6946411132812, Neurons: 29, Grad norm: 1.077e+02\n",
      "Epoch 1893, Loss: 771.8505249023438, Neurons: 29, Grad norm: 1.080e+02\n",
      "Epoch 1893, Loss: 771.8505249023438, Neurons: 29, Grad norm: 1.080e+02\n",
      "Epoch 1894, Loss: 770.9979858398438, Neurons: 29, Grad norm: 1.082e+02\n",
      "Epoch 1894, Loss: 770.9979858398438, Neurons: 29, Grad norm: 1.082e+02\n",
      "Epoch 1895, Loss: 770.1370239257812, Neurons: 29, Grad norm: 1.084e+02\n",
      "Epoch 1895, Loss: 770.1370239257812, Neurons: 29, Grad norm: 1.084e+02\n",
      "Epoch 1896, Loss: 769.2679443359375, Neurons: 29, Grad norm: 1.086e+02\n",
      "Epoch 1896, Loss: 769.2679443359375, Neurons: 29, Grad norm: 1.086e+02\n",
      "Epoch 1897, Loss: 768.3909301757812, Neurons: 29, Grad norm: 1.087e+02\n",
      "Epoch 1897, Loss: 768.3909301757812, Neurons: 29, Grad norm: 1.087e+02\n",
      "Epoch 1898, Loss: 767.5064697265625, Neurons: 29, Grad norm: 1.088e+02\n",
      "Epoch 1898, Loss: 767.5064697265625, Neurons: 29, Grad norm: 1.088e+02\n",
      "Epoch 1899, Loss: 766.6146850585938, Neurons: 29, Grad norm: 1.088e+02\n",
      "Epoch 1899, Loss: 766.6146850585938, Neurons: 29, Grad norm: 1.088e+02\n",
      "Epoch 1899, Test loss: 772.3659057617188\n",
      "Epoch 1899, Test loss: 772.3659057617188\n",
      "Added neuron to hidden layer 1 with activation relu\n",
      "Added neuron to hidden layer 1 with activation relu\n",
      "network shape updated to :[12, 17, 1]\n",
      "network shape updated to :[12, 17, 1]\n",
      "Epoch 1900, Loss: 1054.791015625, Neurons: 30, Grad norm: 6.827e+02\n",
      "Epoch 1900, Loss: 1054.791015625, Neurons: 30, Grad norm: 6.827e+02\n",
      "Epoch 1901, Loss: 1053.927490234375, Neurons: 30, Grad norm: 6.821e+02\n",
      "Epoch 1901, Loss: 1053.927490234375, Neurons: 30, Grad norm: 6.821e+02\n",
      "Epoch 1902, Loss: 1053.0218505859375, Neurons: 30, Grad norm: 6.815e+02\n",
      "Epoch 1902, Loss: 1053.0218505859375, Neurons: 30, Grad norm: 6.815e+02\n",
      "Epoch 1903, Loss: 1052.07275390625, Neurons: 30, Grad norm: 6.808e+02\n",
      "Epoch 1903, Loss: 1052.07275390625, Neurons: 30, Grad norm: 6.808e+02\n",
      "Epoch 1904, Loss: 1051.0804443359375, Neurons: 30, Grad norm: 6.801e+02\n",
      "Epoch 1904, Loss: 1051.0804443359375, Neurons: 30, Grad norm: 6.801e+02\n",
      "Epoch 1905, Loss: 1050.04443359375, Neurons: 30, Grad norm: 6.793e+02\n",
      "Epoch 1905, Loss: 1050.04443359375, Neurons: 30, Grad norm: 6.793e+02\n",
      "Epoch 1906, Loss: 1048.964599609375, Neurons: 30, Grad norm: 6.785e+02\n",
      "Epoch 1906, Loss: 1048.964599609375, Neurons: 30, Grad norm: 6.785e+02\n",
      "Epoch 1907, Loss: 1047.841064453125, Neurons: 30, Grad norm: 6.776e+02\n",
      "Epoch 1907, Loss: 1047.841064453125, Neurons: 30, Grad norm: 6.776e+02\n",
      "Epoch 1908, Loss: 1046.674072265625, Neurons: 30, Grad norm: 6.766e+02\n",
      "Epoch 1908, Loss: 1046.674072265625, Neurons: 30, Grad norm: 6.766e+02\n",
      "Epoch 1909, Loss: 1045.4637451171875, Neurons: 30, Grad norm: 6.756e+02\n",
      "Epoch 1909, Loss: 1045.4637451171875, Neurons: 30, Grad norm: 6.756e+02\n",
      "Epoch 1910, Loss: 1044.210693359375, Neurons: 30, Grad norm: 6.745e+02\n",
      "Epoch 1910, Loss: 1044.210693359375, Neurons: 30, Grad norm: 6.745e+02\n",
      "Epoch 1911, Loss: 1042.91552734375, Neurons: 30, Grad norm: 6.734e+02\n",
      "Epoch 1911, Loss: 1042.91552734375, Neurons: 30, Grad norm: 6.734e+02\n",
      "Epoch 1912, Loss: 1041.5789794921875, Neurons: 30, Grad norm: 6.722e+02\n",
      "Epoch 1912, Loss: 1041.5789794921875, Neurons: 30, Grad norm: 6.722e+02\n",
      "Epoch 1913, Loss: 1040.201416015625, Neurons: 30, Grad norm: 6.710e+02\n",
      "Epoch 1913, Loss: 1040.201416015625, Neurons: 30, Grad norm: 6.710e+02\n",
      "Epoch 1914, Loss: 1038.783935546875, Neurons: 30, Grad norm: 6.697e+02\n",
      "Epoch 1914, Loss: 1038.783935546875, Neurons: 30, Grad norm: 6.697e+02\n",
      "Epoch 1915, Loss: 1037.3270263671875, Neurons: 30, Grad norm: 6.684e+02\n",
      "Epoch 1915, Loss: 1037.3270263671875, Neurons: 30, Grad norm: 6.684e+02\n",
      "Epoch 1916, Loss: 1035.8319091796875, Neurons: 30, Grad norm: 6.671e+02\n",
      "Epoch 1916, Loss: 1035.8319091796875, Neurons: 30, Grad norm: 6.671e+02\n",
      "Epoch 1917, Loss: 1034.2991943359375, Neurons: 30, Grad norm: 6.657e+02\n",
      "Epoch 1917, Loss: 1034.2991943359375, Neurons: 30, Grad norm: 6.657e+02\n",
      "Epoch 1918, Loss: 1032.7298583984375, Neurons: 30, Grad norm: 6.643e+02\n",
      "Epoch 1918, Loss: 1032.7298583984375, Neurons: 30, Grad norm: 6.643e+02\n",
      "Epoch 1919, Loss: 1031.124755859375, Neurons: 30, Grad norm: 6.629e+02\n",
      "Epoch 1919, Loss: 1031.124755859375, Neurons: 30, Grad norm: 6.629e+02\n",
      "Epoch 1920, Loss: 1029.485107421875, Neurons: 30, Grad norm: 6.615e+02\n",
      "Epoch 1920, Loss: 1029.485107421875, Neurons: 30, Grad norm: 6.615e+02\n",
      "Epoch 1921, Loss: 1027.811279296875, Neurons: 30, Grad norm: 6.600e+02\n",
      "Epoch 1921, Loss: 1027.811279296875, Neurons: 30, Grad norm: 6.600e+02\n",
      "Epoch 1922, Loss: 1026.104736328125, Neurons: 30, Grad norm: 6.585e+02\n",
      "Epoch 1922, Loss: 1026.104736328125, Neurons: 30, Grad norm: 6.585e+02\n",
      "Epoch 1923, Loss: 1024.3663330078125, Neurons: 30, Grad norm: 6.569e+02\n",
      "Epoch 1923, Loss: 1024.3663330078125, Neurons: 30, Grad norm: 6.569e+02\n",
      "Epoch 1924, Loss: 1022.5968627929688, Neurons: 30, Grad norm: 6.554e+02\n",
      "Epoch 1924, Loss: 1022.5968627929688, Neurons: 30, Grad norm: 6.554e+02\n",
      "Epoch 1925, Loss: 1020.7971801757812, Neurons: 30, Grad norm: 6.538e+02\n",
      "Epoch 1925, Loss: 1020.7971801757812, Neurons: 30, Grad norm: 6.538e+02\n",
      "Epoch 1926, Loss: 1018.9684448242188, Neurons: 30, Grad norm: 6.522e+02\n",
      "Epoch 1926, Loss: 1018.9684448242188, Neurons: 30, Grad norm: 6.522e+02\n",
      "Epoch 1927, Loss: 1017.1112060546875, Neurons: 30, Grad norm: 6.505e+02\n",
      "Epoch 1927, Loss: 1017.1112060546875, Neurons: 30, Grad norm: 6.505e+02\n",
      "Epoch 1928, Loss: 1015.2265014648438, Neurons: 30, Grad norm: 6.488e+02\n",
      "Epoch 1928, Loss: 1015.2265014648438, Neurons: 30, Grad norm: 6.488e+02\n",
      "Epoch 1929, Loss: 1013.315185546875, Neurons: 30, Grad norm: 6.471e+02\n",
      "Epoch 1929, Loss: 1013.315185546875, Neurons: 30, Grad norm: 6.471e+02\n",
      "Epoch 1930, Loss: 1011.3780517578125, Neurons: 30, Grad norm: 6.454e+02\n",
      "Epoch 1930, Loss: 1011.3780517578125, Neurons: 30, Grad norm: 6.454e+02\n",
      "Epoch 1931, Loss: 1009.415771484375, Neurons: 30, Grad norm: 6.436e+02\n",
      "Epoch 1931, Loss: 1009.415771484375, Neurons: 30, Grad norm: 6.436e+02\n",
      "Epoch 1932, Loss: 1007.4293212890625, Neurons: 30, Grad norm: 6.418e+02\n",
      "Epoch 1932, Loss: 1007.4293212890625, Neurons: 30, Grad norm: 6.418e+02\n",
      "Epoch 1933, Loss: 1005.41943359375, Neurons: 30, Grad norm: 6.400e+02\n",
      "Epoch 1933, Loss: 1005.41943359375, Neurons: 30, Grad norm: 6.400e+02\n",
      "Epoch 1934, Loss: 1003.3866577148438, Neurons: 30, Grad norm: 6.382e+02\n",
      "Epoch 1934, Loss: 1003.3866577148438, Neurons: 30, Grad norm: 6.382e+02\n",
      "Epoch 1935, Loss: 1001.3319091796875, Neurons: 30, Grad norm: 6.363e+02\n",
      "Epoch 1935, Loss: 1001.3319091796875, Neurons: 30, Grad norm: 6.363e+02\n",
      "Epoch 1936, Loss: 999.2557983398438, Neurons: 30, Grad norm: 6.345e+02\n",
      "Epoch 1936, Loss: 999.2557983398438, Neurons: 30, Grad norm: 6.345e+02\n",
      "Epoch 1937, Loss: 997.1588134765625, Neurons: 30, Grad norm: 6.326e+02\n",
      "Epoch 1937, Loss: 997.1588134765625, Neurons: 30, Grad norm: 6.326e+02\n",
      "Epoch 1938, Loss: 995.0416870117188, Neurons: 30, Grad norm: 6.307e+02\n",
      "Epoch 1938, Loss: 995.0416870117188, Neurons: 30, Grad norm: 6.307e+02\n",
      "Epoch 1939, Loss: 992.90478515625, Neurons: 30, Grad norm: 6.288e+02\n",
      "Epoch 1939, Loss: 992.90478515625, Neurons: 30, Grad norm: 6.288e+02\n",
      "Epoch 1940, Loss: 990.7490234375, Neurons: 30, Grad norm: 6.269e+02\n",
      "Epoch 1940, Loss: 990.7490234375, Neurons: 30, Grad norm: 6.269e+02\n",
      "Epoch 1941, Loss: 988.5750732421875, Neurons: 30, Grad norm: 6.250e+02\n",
      "Epoch 1941, Loss: 988.5750732421875, Neurons: 30, Grad norm: 6.250e+02\n",
      "Epoch 1942, Loss: 986.3831176757812, Neurons: 30, Grad norm: 6.230e+02\n",
      "Epoch 1942, Loss: 986.3831176757812, Neurons: 30, Grad norm: 6.230e+02\n",
      "Epoch 1943, Loss: 984.1737670898438, Neurons: 30, Grad norm: 6.210e+02\n",
      "Epoch 1943, Loss: 984.1737670898438, Neurons: 30, Grad norm: 6.210e+02\n",
      "Epoch 1944, Loss: 981.9476928710938, Neurons: 30, Grad norm: 6.190e+02\n",
      "Epoch 1944, Loss: 981.9476928710938, Neurons: 30, Grad norm: 6.190e+02\n",
      "Epoch 1945, Loss: 979.7052001953125, Neurons: 30, Grad norm: 6.170e+02\n",
      "Epoch 1945, Loss: 979.7052001953125, Neurons: 30, Grad norm: 6.170e+02\n",
      "Epoch 1946, Loss: 977.44677734375, Neurons: 30, Grad norm: 6.150e+02\n",
      "Epoch 1946, Loss: 977.44677734375, Neurons: 30, Grad norm: 6.150e+02\n",
      "Epoch 1947, Loss: 975.1729125976562, Neurons: 30, Grad norm: 6.130e+02\n",
      "Epoch 1947, Loss: 975.1729125976562, Neurons: 30, Grad norm: 6.130e+02\n",
      "Epoch 1948, Loss: 972.8839111328125, Neurons: 30, Grad norm: 6.109e+02\n",
      "Epoch 1948, Loss: 972.8839111328125, Neurons: 30, Grad norm: 6.109e+02\n",
      "Epoch 1949, Loss: 970.5802612304688, Neurons: 30, Grad norm: 6.089e+02\n",
      "Epoch 1949, Loss: 970.5802612304688, Neurons: 30, Grad norm: 6.089e+02\n",
      "Epoch 1950, Loss: 968.2621459960938, Neurons: 30, Grad norm: 6.068e+02\n",
      "Epoch 1950, Loss: 968.2621459960938, Neurons: 30, Grad norm: 6.068e+02\n",
      "Epoch 1951, Loss: 965.9305419921875, Neurons: 30, Grad norm: 6.047e+02\n",
      "Epoch 1951, Loss: 965.9305419921875, Neurons: 30, Grad norm: 6.047e+02\n",
      "Epoch 1952, Loss: 963.585205078125, Neurons: 30, Grad norm: 6.026e+02\n",
      "Epoch 1952, Loss: 963.585205078125, Neurons: 30, Grad norm: 6.026e+02\n",
      "Epoch 1953, Loss: 961.2269287109375, Neurons: 30, Grad norm: 6.004e+02\n",
      "Epoch 1953, Loss: 961.2269287109375, Neurons: 30, Grad norm: 6.004e+02\n",
      "Epoch 1954, Loss: 958.8557739257812, Neurons: 30, Grad norm: 5.983e+02\n",
      "Epoch 1954, Loss: 958.8557739257812, Neurons: 30, Grad norm: 5.983e+02\n",
      "Epoch 1955, Loss: 956.4725341796875, Neurons: 30, Grad norm: 5.961e+02\n",
      "Epoch 1955, Loss: 956.4725341796875, Neurons: 30, Grad norm: 5.961e+02\n",
      "Epoch 1956, Loss: 954.0771484375, Neurons: 30, Grad norm: 5.940e+02\n",
      "Epoch 1956, Loss: 954.0771484375, Neurons: 30, Grad norm: 5.940e+02\n",
      "Epoch 1957, Loss: 951.669921875, Neurons: 30, Grad norm: 5.918e+02\n",
      "Epoch 1957, Loss: 951.669921875, Neurons: 30, Grad norm: 5.918e+02\n",
      "Epoch 1958, Loss: 949.2512817382812, Neurons: 30, Grad norm: 5.896e+02\n",
      "Epoch 1958, Loss: 949.2512817382812, Neurons: 30, Grad norm: 5.896e+02\n",
      "Epoch 1959, Loss: 946.8216552734375, Neurons: 30, Grad norm: 5.873e+02\n",
      "Epoch 1959, Loss: 946.8216552734375, Neurons: 30, Grad norm: 5.873e+02\n",
      "Epoch 1960, Loss: 944.3812866210938, Neurons: 30, Grad norm: 5.851e+02\n",
      "Epoch 1960, Loss: 944.3812866210938, Neurons: 30, Grad norm: 5.851e+02\n",
      "Epoch 1961, Loss: 941.9305419921875, Neurons: 30, Grad norm: 5.828e+02\n",
      "Epoch 1961, Loss: 941.9305419921875, Neurons: 30, Grad norm: 5.828e+02\n",
      "Epoch 1962, Loss: 939.4699096679688, Neurons: 30, Grad norm: 5.805e+02\n",
      "Epoch 1962, Loss: 939.4699096679688, Neurons: 30, Grad norm: 5.805e+02\n",
      "Epoch 1963, Loss: 936.9995727539062, Neurons: 30, Grad norm: 5.781e+02\n",
      "Epoch 1963, Loss: 936.9995727539062, Neurons: 30, Grad norm: 5.781e+02\n",
      "Epoch 1964, Loss: 934.5198974609375, Neurons: 30, Grad norm: 5.758e+02\n",
      "Epoch 1964, Loss: 934.5198974609375, Neurons: 30, Grad norm: 5.758e+02\n",
      "Epoch 1965, Loss: 932.0313720703125, Neurons: 30, Grad norm: 5.734e+02\n",
      "Epoch 1965, Loss: 932.0313720703125, Neurons: 30, Grad norm: 5.734e+02\n",
      "Epoch 1966, Loss: 929.5340576171875, Neurons: 30, Grad norm: 5.709e+02\n",
      "Epoch 1966, Loss: 929.5340576171875, Neurons: 30, Grad norm: 5.709e+02\n",
      "Epoch 1967, Loss: 927.028564453125, Neurons: 30, Grad norm: 5.685e+02\n",
      "Epoch 1967, Loss: 927.028564453125, Neurons: 30, Grad norm: 5.685e+02\n",
      "Epoch 1968, Loss: 924.5154418945312, Neurons: 30, Grad norm: 5.660e+02\n",
      "Epoch 1968, Loss: 924.5154418945312, Neurons: 30, Grad norm: 5.660e+02\n",
      "Epoch 1969, Loss: 921.9947509765625, Neurons: 30, Grad norm: 5.634e+02\n",
      "Epoch 1969, Loss: 921.9947509765625, Neurons: 30, Grad norm: 5.634e+02\n",
      "Epoch 1970, Loss: 919.4671630859375, Neurons: 30, Grad norm: 5.609e+02\n",
      "Epoch 1970, Loss: 919.4671630859375, Neurons: 30, Grad norm: 5.609e+02\n",
      "Epoch 1971, Loss: 916.9330444335938, Neurons: 30, Grad norm: 5.582e+02\n",
      "Epoch 1971, Loss: 916.9330444335938, Neurons: 30, Grad norm: 5.582e+02\n",
      "Epoch 1972, Loss: 914.3930053710938, Neurons: 30, Grad norm: 5.556e+02\n",
      "Epoch 1972, Loss: 914.3930053710938, Neurons: 30, Grad norm: 5.556e+02\n",
      "Epoch 1973, Loss: 911.8472900390625, Neurons: 30, Grad norm: 5.529e+02\n",
      "Epoch 1973, Loss: 911.8472900390625, Neurons: 30, Grad norm: 5.529e+02\n",
      "Epoch 1974, Loss: 909.2965087890625, Neurons: 30, Grad norm: 5.501e+02\n",
      "Epoch 1974, Loss: 909.2965087890625, Neurons: 30, Grad norm: 5.501e+02\n",
      "Epoch 1975, Loss: 906.7411499023438, Neurons: 30, Grad norm: 5.473e+02\n",
      "Epoch 1975, Loss: 906.7411499023438, Neurons: 30, Grad norm: 5.473e+02\n",
      "Epoch 1976, Loss: 904.1819458007812, Neurons: 30, Grad norm: 5.444e+02\n",
      "Epoch 1976, Loss: 904.1819458007812, Neurons: 30, Grad norm: 5.444e+02\n",
      "Epoch 1977, Loss: 901.619140625, Neurons: 30, Grad norm: 5.415e+02\n",
      "Epoch 1977, Loss: 901.619140625, Neurons: 30, Grad norm: 5.415e+02\n",
      "Epoch 1978, Loss: 899.0534057617188, Neurons: 30, Grad norm: 5.386e+02\n",
      "Epoch 1978, Loss: 899.0534057617188, Neurons: 30, Grad norm: 5.386e+02\n",
      "Epoch 1979, Loss: 896.4853515625, Neurons: 30, Grad norm: 5.356e+02\n",
      "Epoch 1979, Loss: 896.4853515625, Neurons: 30, Grad norm: 5.356e+02\n",
      "Epoch 1980, Loss: 893.9156494140625, Neurons: 30, Grad norm: 5.325e+02\n",
      "Epoch 1980, Loss: 893.9156494140625, Neurons: 30, Grad norm: 5.325e+02\n",
      "Epoch 1981, Loss: 891.3447875976562, Neurons: 30, Grad norm: 5.293e+02\n",
      "Epoch 1981, Loss: 891.3447875976562, Neurons: 30, Grad norm: 5.293e+02\n",
      "Epoch 1982, Loss: 888.773681640625, Neurons: 30, Grad norm: 5.262e+02\n",
      "Epoch 1982, Loss: 888.773681640625, Neurons: 30, Grad norm: 5.262e+02\n",
      "Epoch 1983, Loss: 886.2025146484375, Neurons: 30, Grad norm: 5.229e+02\n",
      "Epoch 1983, Loss: 886.2025146484375, Neurons: 30, Grad norm: 5.229e+02\n",
      "Epoch 1984, Loss: 883.6324462890625, Neurons: 30, Grad norm: 5.196e+02\n",
      "Epoch 1984, Loss: 883.6324462890625, Neurons: 30, Grad norm: 5.196e+02\n",
      "Epoch 1985, Loss: 881.0637817382812, Neurons: 30, Grad norm: 5.163e+02\n",
      "Epoch 1985, Loss: 881.0637817382812, Neurons: 30, Grad norm: 5.163e+02\n",
      "Epoch 1986, Loss: 878.49755859375, Neurons: 30, Grad norm: 5.129e+02\n",
      "Epoch 1986, Loss: 878.49755859375, Neurons: 30, Grad norm: 5.129e+02\n",
      "Epoch 1987, Loss: 875.9341430664062, Neurons: 30, Grad norm: 5.095e+02\n",
      "Epoch 1987, Loss: 875.9341430664062, Neurons: 30, Grad norm: 5.095e+02\n",
      "Epoch 1988, Loss: 873.3741455078125, Neurons: 30, Grad norm: 5.060e+02\n",
      "Epoch 1988, Loss: 873.3741455078125, Neurons: 30, Grad norm: 5.060e+02\n",
      "Epoch 1989, Loss: 870.8182983398438, Neurons: 30, Grad norm: 5.025e+02\n",
      "Epoch 1989, Loss: 870.8182983398438, Neurons: 30, Grad norm: 5.025e+02\n",
      "Epoch 1990, Loss: 868.2673950195312, Neurons: 30, Grad norm: 4.989e+02\n",
      "Epoch 1990, Loss: 868.2673950195312, Neurons: 30, Grad norm: 4.989e+02\n",
      "Epoch 1991, Loss: 865.7221069335938, Neurons: 30, Grad norm: 4.952e+02\n",
      "Epoch 1991, Loss: 865.7221069335938, Neurons: 30, Grad norm: 4.952e+02\n",
      "Epoch 1992, Loss: 863.1831665039062, Neurons: 30, Grad norm: 4.914e+02\n",
      "Epoch 1992, Loss: 863.1831665039062, Neurons: 30, Grad norm: 4.914e+02\n",
      "Epoch 1993, Loss: 860.6515502929688, Neurons: 30, Grad norm: 4.876e+02\n",
      "Epoch 1993, Loss: 860.6515502929688, Neurons: 30, Grad norm: 4.876e+02\n",
      "Epoch 1994, Loss: 858.128173828125, Neurons: 30, Grad norm: 4.838e+02\n",
      "Epoch 1994, Loss: 858.128173828125, Neurons: 30, Grad norm: 4.838e+02\n",
      "Epoch 1995, Loss: 855.613037109375, Neurons: 30, Grad norm: 4.799e+02\n",
      "Epoch 1995, Loss: 855.613037109375, Neurons: 30, Grad norm: 4.799e+02\n",
      "Epoch 1996, Loss: 853.107421875, Neurons: 30, Grad norm: 4.759e+02\n",
      "Epoch 1996, Loss: 853.107421875, Neurons: 30, Grad norm: 4.759e+02\n",
      "Epoch 1997, Loss: 850.6119384765625, Neurons: 30, Grad norm: 4.719e+02\n",
      "Epoch 1997, Loss: 850.6119384765625, Neurons: 30, Grad norm: 4.719e+02\n",
      "Epoch 1998, Loss: 848.12744140625, Neurons: 30, Grad norm: 4.679e+02\n",
      "Epoch 1998, Loss: 848.12744140625, Neurons: 30, Grad norm: 4.679e+02\n",
      "Epoch 1999, Loss: 845.654541015625, Neurons: 30, Grad norm: 4.639e+02\n",
      "Epoch 1999, Loss: 845.654541015625, Neurons: 30, Grad norm: 4.639e+02\n",
      "Epoch 1999, Test loss: 847.8162841796875\n",
      "Epoch 1999, Test loss: 847.8162841796875\n",
      "Removed neuron to hidden layer 1 at index 11\n",
      "Removed neuron to hidden layer 1 at index 11\n",
      "network shape updated to :[11, 17, 1]\n",
      "network shape updated to :[11, 17, 1]\n",
      "Epoch 2000, Loss: 753.495361328125, Neurons: 29, Grad norm: 3.149e+02\n",
      "Epoch 2000, Loss: 753.495361328125, Neurons: 29, Grad norm: 3.149e+02\n",
      "Epoch 2001, Loss: 753.1099243164062, Neurons: 29, Grad norm: 3.089e+02\n",
      "Epoch 2001, Loss: 753.1099243164062, Neurons: 29, Grad norm: 3.089e+02\n",
      "Epoch 2002, Loss: 752.7130737304688, Neurons: 29, Grad norm: 3.036e+02\n",
      "Epoch 2002, Loss: 752.7130737304688, Neurons: 29, Grad norm: 3.036e+02\n",
      "Epoch 2003, Loss: 752.3035278320312, Neurons: 29, Grad norm: 2.985e+02\n",
      "Epoch 2003, Loss: 752.3035278320312, Neurons: 29, Grad norm: 2.985e+02\n",
      "Epoch 2004, Loss: 751.8801879882812, Neurons: 29, Grad norm: 2.936e+02\n",
      "Epoch 2004, Loss: 751.8801879882812, Neurons: 29, Grad norm: 2.936e+02\n",
      "Epoch 2005, Loss: 751.4432373046875, Neurons: 29, Grad norm: 2.888e+02\n",
      "Epoch 2005, Loss: 751.4432373046875, Neurons: 29, Grad norm: 2.888e+02\n",
      "Epoch 2006, Loss: 750.9934692382812, Neurons: 29, Grad norm: 2.840e+02\n",
      "Epoch 2006, Loss: 750.9934692382812, Neurons: 29, Grad norm: 2.840e+02\n",
      "Epoch 2007, Loss: 750.5317993164062, Neurons: 29, Grad norm: 2.791e+02\n",
      "Epoch 2007, Loss: 750.5317993164062, Neurons: 29, Grad norm: 2.791e+02\n",
      "Epoch 2008, Loss: 750.0588989257812, Neurons: 29, Grad norm: 2.742e+02\n",
      "Epoch 2008, Loss: 750.0588989257812, Neurons: 29, Grad norm: 2.742e+02\n",
      "Epoch 2009, Loss: 749.5758056640625, Neurons: 29, Grad norm: 2.694e+02\n",
      "Epoch 2009, Loss: 749.5758056640625, Neurons: 29, Grad norm: 2.694e+02\n",
      "Epoch 2010, Loss: 749.0833129882812, Neurons: 29, Grad norm: 2.645e+02\n",
      "Epoch 2010, Loss: 749.0833129882812, Neurons: 29, Grad norm: 2.645e+02\n",
      "Epoch 2011, Loss: 748.5823974609375, Neurons: 29, Grad norm: 2.598e+02\n",
      "Epoch 2011, Loss: 748.5823974609375, Neurons: 29, Grad norm: 2.598e+02\n",
      "Epoch 2012, Loss: 748.0738525390625, Neurons: 29, Grad norm: 2.551e+02\n",
      "Epoch 2012, Loss: 748.0738525390625, Neurons: 29, Grad norm: 2.551e+02\n",
      "Epoch 2013, Loss: 747.5585327148438, Neurons: 29, Grad norm: 2.505e+02\n",
      "Epoch 2013, Loss: 747.5585327148438, Neurons: 29, Grad norm: 2.505e+02\n",
      "Epoch 2014, Loss: 747.0371704101562, Neurons: 29, Grad norm: 2.461e+02\n",
      "Epoch 2014, Loss: 747.0371704101562, Neurons: 29, Grad norm: 2.461e+02\n",
      "Epoch 2015, Loss: 746.5101318359375, Neurons: 29, Grad norm: 2.418e+02\n",
      "Epoch 2015, Loss: 746.5101318359375, Neurons: 29, Grad norm: 2.418e+02\n",
      "Epoch 2016, Loss: 745.978271484375, Neurons: 29, Grad norm: 2.377e+02\n",
      "Epoch 2016, Loss: 745.978271484375, Neurons: 29, Grad norm: 2.377e+02\n",
      "Epoch 2017, Loss: 745.44189453125, Neurons: 29, Grad norm: 2.337e+02\n",
      "Epoch 2017, Loss: 745.44189453125, Neurons: 29, Grad norm: 2.337e+02\n",
      "Epoch 2018, Loss: 744.9015502929688, Neurons: 29, Grad norm: 2.299e+02\n",
      "Epoch 2018, Loss: 744.9015502929688, Neurons: 29, Grad norm: 2.299e+02\n",
      "Epoch 2019, Loss: 744.3572998046875, Neurons: 29, Grad norm: 2.262e+02\n",
      "Epoch 2019, Loss: 744.3572998046875, Neurons: 29, Grad norm: 2.262e+02\n",
      "Epoch 2020, Loss: 743.8096923828125, Neurons: 29, Grad norm: 2.227e+02\n",
      "Epoch 2020, Loss: 743.8096923828125, Neurons: 29, Grad norm: 2.227e+02\n",
      "Epoch 2021, Loss: 743.2588500976562, Neurons: 29, Grad norm: 2.194e+02\n",
      "Epoch 2021, Loss: 743.2588500976562, Neurons: 29, Grad norm: 2.194e+02\n",
      "Epoch 2022, Loss: 742.7049560546875, Neurons: 29, Grad norm: 2.162e+02\n",
      "Epoch 2022, Loss: 742.7049560546875, Neurons: 29, Grad norm: 2.162e+02\n",
      "Epoch 2023, Loss: 742.1483154296875, Neurons: 29, Grad norm: 2.132e+02\n",
      "Epoch 2023, Loss: 742.1483154296875, Neurons: 29, Grad norm: 2.132e+02\n",
      "Epoch 2024, Loss: 741.5889282226562, Neurons: 29, Grad norm: 2.104e+02\n",
      "Epoch 2024, Loss: 741.5889282226562, Neurons: 29, Grad norm: 2.104e+02\n",
      "Epoch 2025, Loss: 741.0271606445312, Neurons: 29, Grad norm: 2.077e+02\n",
      "Epoch 2025, Loss: 741.0271606445312, Neurons: 29, Grad norm: 2.077e+02\n",
      "Epoch 2026, Loss: 740.463134765625, Neurons: 29, Grad norm: 2.052e+02\n",
      "Epoch 2026, Loss: 740.463134765625, Neurons: 29, Grad norm: 2.052e+02\n",
      "Epoch 2027, Loss: 739.8971557617188, Neurons: 29, Grad norm: 2.029e+02\n",
      "Epoch 2027, Loss: 739.8971557617188, Neurons: 29, Grad norm: 2.029e+02\n",
      "Epoch 2028, Loss: 739.329345703125, Neurons: 29, Grad norm: 2.007e+02\n",
      "Epoch 2028, Loss: 739.329345703125, Neurons: 29, Grad norm: 2.007e+02\n",
      "Epoch 2029, Loss: 738.760009765625, Neurons: 29, Grad norm: 1.986e+02\n",
      "Epoch 2029, Loss: 738.760009765625, Neurons: 29, Grad norm: 1.986e+02\n",
      "Epoch 2030, Loss: 738.1895141601562, Neurons: 29, Grad norm: 1.966e+02\n",
      "Epoch 2030, Loss: 738.1895141601562, Neurons: 29, Grad norm: 1.966e+02\n",
      "Epoch 2031, Loss: 737.6180419921875, Neurons: 29, Grad norm: 1.947e+02\n",
      "Epoch 2031, Loss: 737.6180419921875, Neurons: 29, Grad norm: 1.947e+02\n",
      "Epoch 2032, Loss: 737.045654296875, Neurons: 29, Grad norm: 1.929e+02\n",
      "Epoch 2032, Loss: 737.045654296875, Neurons: 29, Grad norm: 1.929e+02\n",
      "Epoch 2033, Loss: 736.4727783203125, Neurons: 29, Grad norm: 1.912e+02\n",
      "Epoch 2033, Loss: 736.4727783203125, Neurons: 29, Grad norm: 1.912e+02\n",
      "Epoch 2034, Loss: 735.8994750976562, Neurons: 29, Grad norm: 1.895e+02\n",
      "Epoch 2034, Loss: 735.8994750976562, Neurons: 29, Grad norm: 1.895e+02\n",
      "Epoch 2035, Loss: 735.3258666992188, Neurons: 29, Grad norm: 1.879e+02\n",
      "Epoch 2035, Loss: 735.3258666992188, Neurons: 29, Grad norm: 1.879e+02\n",
      "Epoch 2036, Loss: 734.7520141601562, Neurons: 29, Grad norm: 1.863e+02\n",
      "Epoch 2036, Loss: 734.7520141601562, Neurons: 29, Grad norm: 1.863e+02\n",
      "Epoch 2037, Loss: 734.1781005859375, Neurons: 29, Grad norm: 1.848e+02\n",
      "Epoch 2037, Loss: 734.1781005859375, Neurons: 29, Grad norm: 1.848e+02\n",
      "Epoch 2038, Loss: 733.6038818359375, Neurons: 29, Grad norm: 1.832e+02\n",
      "Epoch 2038, Loss: 733.6038818359375, Neurons: 29, Grad norm: 1.832e+02\n",
      "Epoch 2039, Loss: 733.029541015625, Neurons: 29, Grad norm: 1.817e+02\n",
      "Epoch 2039, Loss: 733.029541015625, Neurons: 29, Grad norm: 1.817e+02\n",
      "Epoch 2040, Loss: 732.4547729492188, Neurons: 29, Grad norm: 1.802e+02\n",
      "Epoch 2040, Loss: 732.4547729492188, Neurons: 29, Grad norm: 1.802e+02\n",
      "Epoch 2041, Loss: 731.8796997070312, Neurons: 29, Grad norm: 1.787e+02\n",
      "Epoch 2041, Loss: 731.8796997070312, Neurons: 29, Grad norm: 1.787e+02\n",
      "Epoch 2042, Loss: 731.3040161132812, Neurons: 29, Grad norm: 1.773e+02\n",
      "Epoch 2042, Loss: 731.3040161132812, Neurons: 29, Grad norm: 1.773e+02\n",
      "Epoch 2043, Loss: 730.7279052734375, Neurons: 29, Grad norm: 1.758e+02\n",
      "Epoch 2043, Loss: 730.7279052734375, Neurons: 29, Grad norm: 1.758e+02\n",
      "Epoch 2044, Loss: 730.1510009765625, Neurons: 29, Grad norm: 1.743e+02\n",
      "Epoch 2044, Loss: 730.1510009765625, Neurons: 29, Grad norm: 1.743e+02\n",
      "Epoch 2045, Loss: 729.5732421875, Neurons: 29, Grad norm: 1.729e+02\n",
      "Epoch 2045, Loss: 729.5732421875, Neurons: 29, Grad norm: 1.729e+02\n",
      "Epoch 2046, Loss: 728.9945068359375, Neurons: 29, Grad norm: 1.714e+02\n",
      "Epoch 2046, Loss: 728.9945068359375, Neurons: 29, Grad norm: 1.714e+02\n",
      "Epoch 2047, Loss: 728.4148559570312, Neurons: 29, Grad norm: 1.700e+02\n",
      "Epoch 2047, Loss: 728.4148559570312, Neurons: 29, Grad norm: 1.700e+02\n",
      "Epoch 2048, Loss: 727.8340454101562, Neurons: 29, Grad norm: 1.686e+02\n",
      "Epoch 2048, Loss: 727.8340454101562, Neurons: 29, Grad norm: 1.686e+02\n",
      "Epoch 2049, Loss: 727.2520141601562, Neurons: 29, Grad norm: 1.673e+02\n",
      "Epoch 2049, Loss: 727.2520141601562, Neurons: 29, Grad norm: 1.673e+02\n",
      "Epoch 2050, Loss: 726.6688842773438, Neurons: 29, Grad norm: 1.659e+02\n",
      "Epoch 2050, Loss: 726.6688842773438, Neurons: 29, Grad norm: 1.659e+02\n",
      "Epoch 2051, Loss: 726.0844116210938, Neurons: 29, Grad norm: 1.646e+02\n",
      "Epoch 2051, Loss: 726.0844116210938, Neurons: 29, Grad norm: 1.646e+02\n",
      "Epoch 2052, Loss: 725.4986572265625, Neurons: 29, Grad norm: 1.633e+02\n",
      "Epoch 2052, Loss: 725.4986572265625, Neurons: 29, Grad norm: 1.633e+02\n",
      "Epoch 2053, Loss: 724.91162109375, Neurons: 29, Grad norm: 1.620e+02\n",
      "Epoch 2053, Loss: 724.91162109375, Neurons: 29, Grad norm: 1.620e+02\n",
      "Epoch 2054, Loss: 724.3232421875, Neurons: 29, Grad norm: 1.608e+02\n",
      "Epoch 2054, Loss: 724.3232421875, Neurons: 29, Grad norm: 1.608e+02\n",
      "Epoch 2055, Loss: 723.7335205078125, Neurons: 29, Grad norm: 1.596e+02\n",
      "Epoch 2055, Loss: 723.7335205078125, Neurons: 29, Grad norm: 1.596e+02\n",
      "Epoch 2056, Loss: 723.1425170898438, Neurons: 29, Grad norm: 1.585e+02\n",
      "Epoch 2056, Loss: 723.1425170898438, Neurons: 29, Grad norm: 1.585e+02\n",
      "Epoch 2057, Loss: 722.55029296875, Neurons: 29, Grad norm: 1.574e+02\n",
      "Epoch 2057, Loss: 722.55029296875, Neurons: 29, Grad norm: 1.574e+02\n",
      "Epoch 2058, Loss: 721.956787109375, Neurons: 29, Grad norm: 1.563e+02\n",
      "Epoch 2058, Loss: 721.956787109375, Neurons: 29, Grad norm: 1.563e+02\n",
      "Epoch 2059, Loss: 721.362060546875, Neurons: 29, Grad norm: 1.552e+02\n",
      "Epoch 2059, Loss: 721.362060546875, Neurons: 29, Grad norm: 1.552e+02\n",
      "Epoch 2060, Loss: 720.7660522460938, Neurons: 29, Grad norm: 1.542e+02\n",
      "Epoch 2060, Loss: 720.7660522460938, Neurons: 29, Grad norm: 1.542e+02\n",
      "Epoch 2061, Loss: 720.1688842773438, Neurons: 29, Grad norm: 1.532e+02\n",
      "Epoch 2061, Loss: 720.1688842773438, Neurons: 29, Grad norm: 1.532e+02\n",
      "Epoch 2062, Loss: 719.570556640625, Neurons: 29, Grad norm: 1.523e+02\n",
      "Epoch 2062, Loss: 719.570556640625, Neurons: 29, Grad norm: 1.523e+02\n",
      "Epoch 2063, Loss: 718.9710693359375, Neurons: 29, Grad norm: 1.513e+02\n",
      "Epoch 2063, Loss: 718.9710693359375, Neurons: 29, Grad norm: 1.513e+02\n",
      "Epoch 2064, Loss: 718.3705444335938, Neurons: 29, Grad norm: 1.504e+02\n",
      "Epoch 2064, Loss: 718.3705444335938, Neurons: 29, Grad norm: 1.504e+02\n",
      "Epoch 2065, Loss: 717.768798828125, Neurons: 29, Grad norm: 1.496e+02\n",
      "Epoch 2065, Loss: 717.768798828125, Neurons: 29, Grad norm: 1.496e+02\n",
      "Epoch 2066, Loss: 717.166015625, Neurons: 29, Grad norm: 1.487e+02\n",
      "Epoch 2066, Loss: 717.166015625, Neurons: 29, Grad norm: 1.487e+02\n",
      "Epoch 2067, Loss: 716.562255859375, Neurons: 29, Grad norm: 1.479e+02\n",
      "Epoch 2067, Loss: 716.562255859375, Neurons: 29, Grad norm: 1.479e+02\n",
      "Epoch 2068, Loss: 715.9576416015625, Neurons: 29, Grad norm: 1.471e+02\n",
      "Epoch 2068, Loss: 715.9576416015625, Neurons: 29, Grad norm: 1.471e+02\n",
      "Epoch 2069, Loss: 715.35205078125, Neurons: 29, Grad norm: 1.464e+02\n",
      "Epoch 2069, Loss: 715.35205078125, Neurons: 29, Grad norm: 1.464e+02\n",
      "Epoch 2070, Loss: 714.7455444335938, Neurons: 29, Grad norm: 1.456e+02\n",
      "Epoch 2070, Loss: 714.7455444335938, Neurons: 29, Grad norm: 1.456e+02\n",
      "Epoch 2071, Loss: 714.1382446289062, Neurons: 29, Grad norm: 1.449e+02\n",
      "Epoch 2071, Loss: 714.1382446289062, Neurons: 29, Grad norm: 1.449e+02\n",
      "Epoch 2072, Loss: 713.530029296875, Neurons: 29, Grad norm: 1.442e+02\n",
      "Epoch 2072, Loss: 713.530029296875, Neurons: 29, Grad norm: 1.442e+02\n",
      "Epoch 2073, Loss: 712.9210815429688, Neurons: 29, Grad norm: 1.435e+02\n",
      "Epoch 2073, Loss: 712.9210815429688, Neurons: 29, Grad norm: 1.435e+02\n",
      "Epoch 2074, Loss: 712.3113403320312, Neurons: 29, Grad norm: 1.429e+02\n",
      "Epoch 2074, Loss: 712.3113403320312, Neurons: 29, Grad norm: 1.429e+02\n",
      "Epoch 2075, Loss: 711.7008056640625, Neurons: 29, Grad norm: 1.422e+02\n",
      "Epoch 2075, Loss: 711.7008056640625, Neurons: 29, Grad norm: 1.422e+02\n",
      "Epoch 2076, Loss: 711.0895385742188, Neurons: 29, Grad norm: 1.415e+02\n",
      "Epoch 2076, Loss: 711.0895385742188, Neurons: 29, Grad norm: 1.415e+02\n",
      "Epoch 2077, Loss: 710.4774780273438, Neurons: 29, Grad norm: 1.409e+02\n",
      "Epoch 2077, Loss: 710.4774780273438, Neurons: 29, Grad norm: 1.409e+02\n",
      "Epoch 2078, Loss: 709.8646850585938, Neurons: 29, Grad norm: 1.403e+02\n",
      "Epoch 2078, Loss: 709.8646850585938, Neurons: 29, Grad norm: 1.403e+02\n",
      "Epoch 2079, Loss: 709.2510986328125, Neurons: 29, Grad norm: 1.396e+02\n",
      "Epoch 2079, Loss: 709.2510986328125, Neurons: 29, Grad norm: 1.396e+02\n",
      "Epoch 2080, Loss: 708.6367797851562, Neurons: 29, Grad norm: 1.390e+02\n",
      "Epoch 2080, Loss: 708.6367797851562, Neurons: 29, Grad norm: 1.390e+02\n",
      "Epoch 2081, Loss: 708.0215454101562, Neurons: 29, Grad norm: 1.384e+02\n",
      "Epoch 2081, Loss: 708.0215454101562, Neurons: 29, Grad norm: 1.384e+02\n",
      "Epoch 2082, Loss: 707.4056396484375, Neurons: 29, Grad norm: 1.378e+02\n",
      "Epoch 2082, Loss: 707.4056396484375, Neurons: 29, Grad norm: 1.378e+02\n",
      "Epoch 2083, Loss: 706.7888793945312, Neurons: 29, Grad norm: 1.371e+02\n",
      "Epoch 2083, Loss: 706.7888793945312, Neurons: 29, Grad norm: 1.371e+02\n",
      "Epoch 2084, Loss: 706.1712646484375, Neurons: 29, Grad norm: 1.365e+02\n",
      "Epoch 2084, Loss: 706.1712646484375, Neurons: 29, Grad norm: 1.365e+02\n",
      "Epoch 2085, Loss: 705.5527954101562, Neurons: 29, Grad norm: 1.359e+02\n",
      "Epoch 2085, Loss: 705.5527954101562, Neurons: 29, Grad norm: 1.359e+02\n",
      "Epoch 2086, Loss: 704.9334106445312, Neurons: 29, Grad norm: 1.353e+02\n",
      "Epoch 2086, Loss: 704.9334106445312, Neurons: 29, Grad norm: 1.353e+02\n",
      "Epoch 2087, Loss: 704.313232421875, Neurons: 29, Grad norm: 1.346e+02\n",
      "Epoch 2087, Loss: 704.313232421875, Neurons: 29, Grad norm: 1.346e+02\n",
      "Epoch 2088, Loss: 703.6920166015625, Neurons: 29, Grad norm: 1.340e+02\n",
      "Epoch 2088, Loss: 703.6920166015625, Neurons: 29, Grad norm: 1.340e+02\n",
      "Epoch 2089, Loss: 703.06982421875, Neurons: 29, Grad norm: 1.334e+02\n",
      "Epoch 2089, Loss: 703.06982421875, Neurons: 29, Grad norm: 1.334e+02\n",
      "Epoch 2090, Loss: 702.4466552734375, Neurons: 29, Grad norm: 1.328e+02\n",
      "Epoch 2090, Loss: 702.4466552734375, Neurons: 29, Grad norm: 1.328e+02\n",
      "Epoch 2091, Loss: 701.8224487304688, Neurons: 29, Grad norm: 1.322e+02\n",
      "Epoch 2091, Loss: 701.8224487304688, Neurons: 29, Grad norm: 1.322e+02\n",
      "Epoch 2092, Loss: 701.1971435546875, Neurons: 29, Grad norm: 1.316e+02\n",
      "Epoch 2092, Loss: 701.1971435546875, Neurons: 29, Grad norm: 1.316e+02\n",
      "Epoch 2093, Loss: 700.57080078125, Neurons: 29, Grad norm: 1.310e+02\n",
      "Epoch 2093, Loss: 700.57080078125, Neurons: 29, Grad norm: 1.310e+02\n",
      "Epoch 2094, Loss: 699.9431762695312, Neurons: 29, Grad norm: 1.304e+02\n",
      "Epoch 2094, Loss: 699.9431762695312, Neurons: 29, Grad norm: 1.304e+02\n",
      "Epoch 2095, Loss: 699.3142700195312, Neurons: 29, Grad norm: 1.298e+02\n",
      "Epoch 2095, Loss: 699.3142700195312, Neurons: 29, Grad norm: 1.298e+02\n",
      "Epoch 2096, Loss: 698.6841430664062, Neurons: 29, Grad norm: 1.292e+02\n",
      "Epoch 2096, Loss: 698.6841430664062, Neurons: 29, Grad norm: 1.292e+02\n",
      "Epoch 2097, Loss: 698.052734375, Neurons: 29, Grad norm: 1.286e+02\n",
      "Epoch 2097, Loss: 698.052734375, Neurons: 29, Grad norm: 1.286e+02\n",
      "Epoch 2098, Loss: 697.4197998046875, Neurons: 29, Grad norm: 1.280e+02\n",
      "Epoch 2098, Loss: 697.4197998046875, Neurons: 29, Grad norm: 1.280e+02\n",
      "Epoch 2099, Loss: 696.7855224609375, Neurons: 29, Grad norm: 1.275e+02\n",
      "Epoch 2099, Loss: 696.7855224609375, Neurons: 29, Grad norm: 1.275e+02\n",
      "Epoch 2099, Test loss: 701.54150390625\n",
      "Epoch 2099, Test loss: 701.54150390625\n",
      "Added neuron to hidden layer 1 with activation relu\n",
      "Added neuron to hidden layer 1 with activation relu\n",
      "network shape updated to :[12, 17, 1]\n",
      "network shape updated to :[12, 17, 1]\n",
      "Epoch 2100, Loss: 754.1434326171875, Neurons: 30, Grad norm: 4.737e+02\n",
      "Epoch 2100, Loss: 754.1434326171875, Neurons: 30, Grad norm: 4.737e+02\n",
      "Epoch 2101, Loss: 753.4854125976562, Neurons: 30, Grad norm: 4.687e+02\n",
      "Epoch 2101, Loss: 753.4854125976562, Neurons: 30, Grad norm: 4.687e+02\n",
      "Epoch 2102, Loss: 752.7992553710938, Neurons: 30, Grad norm: 4.637e+02\n",
      "Epoch 2102, Loss: 752.7992553710938, Neurons: 30, Grad norm: 4.637e+02\n",
      "Epoch 2103, Loss: 752.0850219726562, Neurons: 30, Grad norm: 4.587e+02\n",
      "Epoch 2103, Loss: 752.0850219726562, Neurons: 30, Grad norm: 4.587e+02\n",
      "Epoch 2104, Loss: 751.3427734375, Neurons: 30, Grad norm: 4.537e+02\n",
      "Epoch 2104, Loss: 751.3427734375, Neurons: 30, Grad norm: 4.537e+02\n",
      "Epoch 2105, Loss: 750.5729370117188, Neurons: 30, Grad norm: 4.487e+02\n",
      "Epoch 2105, Loss: 750.5729370117188, Neurons: 30, Grad norm: 4.487e+02\n",
      "Epoch 2106, Loss: 749.7762451171875, Neurons: 30, Grad norm: 4.436e+02\n",
      "Epoch 2106, Loss: 749.7762451171875, Neurons: 30, Grad norm: 4.436e+02\n",
      "Epoch 2107, Loss: 748.9534301757812, Neurons: 30, Grad norm: 4.385e+02\n",
      "Epoch 2107, Loss: 748.9534301757812, Neurons: 30, Grad norm: 4.385e+02\n",
      "Epoch 2108, Loss: 748.1058349609375, Neurons: 30, Grad norm: 4.332e+02\n",
      "Epoch 2108, Loss: 748.1058349609375, Neurons: 30, Grad norm: 4.332e+02\n",
      "Epoch 2109, Loss: 747.2345581054688, Neurons: 30, Grad norm: 4.279e+02\n",
      "Epoch 2109, Loss: 747.2345581054688, Neurons: 30, Grad norm: 4.279e+02\n",
      "Epoch 2110, Loss: 746.341064453125, Neurons: 30, Grad norm: 4.225e+02\n",
      "Epoch 2110, Loss: 746.341064453125, Neurons: 30, Grad norm: 4.225e+02\n",
      "Epoch 2111, Loss: 745.4266967773438, Neurons: 30, Grad norm: 4.170e+02\n",
      "Epoch 2111, Loss: 745.4266967773438, Neurons: 30, Grad norm: 4.170e+02\n",
      "Epoch 2112, Loss: 744.4931640625, Neurons: 30, Grad norm: 4.114e+02\n",
      "Epoch 2112, Loss: 744.4931640625, Neurons: 30, Grad norm: 4.114e+02\n",
      "Epoch 2113, Loss: 743.5419311523438, Neurons: 30, Grad norm: 4.057e+02\n",
      "Epoch 2113, Loss: 743.5419311523438, Neurons: 30, Grad norm: 4.057e+02\n",
      "Epoch 2114, Loss: 742.5747680664062, Neurons: 30, Grad norm: 4.000e+02\n",
      "Epoch 2114, Loss: 742.5747680664062, Neurons: 30, Grad norm: 4.000e+02\n",
      "Epoch 2115, Loss: 741.5931396484375, Neurons: 30, Grad norm: 3.942e+02\n",
      "Epoch 2115, Loss: 741.5931396484375, Neurons: 30, Grad norm: 3.942e+02\n",
      "Epoch 2116, Loss: 740.5990600585938, Neurons: 30, Grad norm: 3.883e+02\n",
      "Epoch 2116, Loss: 740.5990600585938, Neurons: 30, Grad norm: 3.883e+02\n",
      "Epoch 2117, Loss: 739.5938110351562, Neurons: 30, Grad norm: 3.824e+02\n",
      "Epoch 2117, Loss: 739.5938110351562, Neurons: 30, Grad norm: 3.824e+02\n",
      "Epoch 2118, Loss: 738.5791625976562, Neurons: 30, Grad norm: 3.764e+02\n",
      "Epoch 2118, Loss: 738.5791625976562, Neurons: 30, Grad norm: 3.764e+02\n",
      "Epoch 2119, Loss: 737.556884765625, Neurons: 30, Grad norm: 3.704e+02\n",
      "Epoch 2119, Loss: 737.556884765625, Neurons: 30, Grad norm: 3.704e+02\n",
      "Epoch 2120, Loss: 736.5282592773438, Neurons: 30, Grad norm: 3.643e+02\n",
      "Epoch 2120, Loss: 736.5282592773438, Neurons: 30, Grad norm: 3.643e+02\n",
      "Epoch 2121, Loss: 735.4949951171875, Neurons: 30, Grad norm: 3.583e+02\n",
      "Epoch 2121, Loss: 735.4949951171875, Neurons: 30, Grad norm: 3.583e+02\n",
      "Epoch 2122, Loss: 734.4583129882812, Neurons: 30, Grad norm: 3.522e+02\n",
      "Epoch 2122, Loss: 734.4583129882812, Neurons: 30, Grad norm: 3.522e+02\n",
      "Epoch 2123, Loss: 733.4196166992188, Neurons: 30, Grad norm: 3.461e+02\n",
      "Epoch 2123, Loss: 733.4196166992188, Neurons: 30, Grad norm: 3.461e+02\n",
      "Epoch 2124, Loss: 732.380126953125, Neurons: 30, Grad norm: 3.400e+02\n",
      "Epoch 2124, Loss: 732.380126953125, Neurons: 30, Grad norm: 3.400e+02\n",
      "Epoch 2125, Loss: 731.3409423828125, Neurons: 30, Grad norm: 3.340e+02\n",
      "Epoch 2125, Loss: 731.3409423828125, Neurons: 30, Grad norm: 3.340e+02\n",
      "Epoch 2126, Loss: 730.3031616210938, Neurons: 30, Grad norm: 3.280e+02\n",
      "Epoch 2126, Loss: 730.3031616210938, Neurons: 30, Grad norm: 3.280e+02\n",
      "Epoch 2127, Loss: 729.2674560546875, Neurons: 30, Grad norm: 3.221e+02\n",
      "Epoch 2127, Loss: 729.2674560546875, Neurons: 30, Grad norm: 3.221e+02\n",
      "Epoch 2128, Loss: 728.2348022460938, Neurons: 30, Grad norm: 3.162e+02\n",
      "Epoch 2128, Loss: 728.2348022460938, Neurons: 30, Grad norm: 3.162e+02\n",
      "Epoch 2129, Loss: 727.2058715820312, Neurons: 30, Grad norm: 3.104e+02\n",
      "Epoch 2129, Loss: 727.2058715820312, Neurons: 30, Grad norm: 3.104e+02\n",
      "Epoch 2130, Loss: 726.1812744140625, Neurons: 30, Grad norm: 3.047e+02\n",
      "Epoch 2130, Loss: 726.1812744140625, Neurons: 30, Grad norm: 3.047e+02\n",
      "Epoch 2131, Loss: 725.1612548828125, Neurons: 30, Grad norm: 2.991e+02\n",
      "Epoch 2131, Loss: 725.1612548828125, Neurons: 30, Grad norm: 2.991e+02\n",
      "Epoch 2132, Loss: 724.1466674804688, Neurons: 30, Grad norm: 2.935e+02\n",
      "Epoch 2132, Loss: 724.1466674804688, Neurons: 30, Grad norm: 2.935e+02\n",
      "Epoch 2133, Loss: 723.1375122070312, Neurons: 30, Grad norm: 2.881e+02\n",
      "Epoch 2133, Loss: 723.1375122070312, Neurons: 30, Grad norm: 2.881e+02\n",
      "Epoch 2134, Loss: 722.1341552734375, Neurons: 30, Grad norm: 2.827e+02\n",
      "Epoch 2134, Loss: 722.1341552734375, Neurons: 30, Grad norm: 2.827e+02\n",
      "Epoch 2135, Loss: 721.1367797851562, Neurons: 30, Grad norm: 2.775e+02\n",
      "Epoch 2135, Loss: 721.1367797851562, Neurons: 30, Grad norm: 2.775e+02\n",
      "Epoch 2136, Loss: 720.1453247070312, Neurons: 30, Grad norm: 2.723e+02\n",
      "Epoch 2136, Loss: 720.1453247070312, Neurons: 30, Grad norm: 2.723e+02\n",
      "Epoch 2137, Loss: 719.1600952148438, Neurons: 30, Grad norm: 2.672e+02\n",
      "Epoch 2137, Loss: 719.1600952148438, Neurons: 30, Grad norm: 2.672e+02\n",
      "Epoch 2138, Loss: 718.180908203125, Neurons: 30, Grad norm: 2.623e+02\n",
      "Epoch 2138, Loss: 718.180908203125, Neurons: 30, Grad norm: 2.623e+02\n",
      "Epoch 2139, Loss: 717.2076416015625, Neurons: 30, Grad norm: 2.575e+02\n",
      "Epoch 2139, Loss: 717.2076416015625, Neurons: 30, Grad norm: 2.575e+02\n",
      "Epoch 2140, Loss: 716.2402954101562, Neurons: 30, Grad norm: 2.528e+02\n",
      "Epoch 2140, Loss: 716.2402954101562, Neurons: 30, Grad norm: 2.528e+02\n",
      "Epoch 2141, Loss: 715.2786254882812, Neurons: 30, Grad norm: 2.482e+02\n",
      "Epoch 2141, Loss: 715.2786254882812, Neurons: 30, Grad norm: 2.482e+02\n",
      "Epoch 2142, Loss: 714.3223876953125, Neurons: 30, Grad norm: 2.438e+02\n",
      "Epoch 2142, Loss: 714.3223876953125, Neurons: 30, Grad norm: 2.438e+02\n",
      "Epoch 2143, Loss: 713.3715209960938, Neurons: 30, Grad norm: 2.395e+02\n",
      "Epoch 2143, Loss: 713.3715209960938, Neurons: 30, Grad norm: 2.395e+02\n",
      "Epoch 2144, Loss: 712.4256591796875, Neurons: 30, Grad norm: 2.353e+02\n",
      "Epoch 2144, Loss: 712.4256591796875, Neurons: 30, Grad norm: 2.353e+02\n",
      "Epoch 2145, Loss: 711.484619140625, Neurons: 30, Grad norm: 2.312e+02\n",
      "Epoch 2145, Loss: 711.484619140625, Neurons: 30, Grad norm: 2.312e+02\n",
      "Epoch 2146, Loss: 710.5479125976562, Neurons: 30, Grad norm: 2.273e+02\n",
      "Epoch 2146, Loss: 710.5479125976562, Neurons: 30, Grad norm: 2.273e+02\n",
      "Epoch 2147, Loss: 709.6155395507812, Neurons: 30, Grad norm: 2.235e+02\n",
      "Epoch 2147, Loss: 709.6155395507812, Neurons: 30, Grad norm: 2.235e+02\n",
      "Epoch 2148, Loss: 708.6868896484375, Neurons: 30, Grad norm: 2.199e+02\n",
      "Epoch 2148, Loss: 708.6868896484375, Neurons: 30, Grad norm: 2.199e+02\n",
      "Epoch 2149, Loss: 707.7619018554688, Neurons: 30, Grad norm: 2.163e+02\n",
      "Epoch 2149, Loss: 707.7619018554688, Neurons: 30, Grad norm: 2.163e+02\n",
      "Epoch 2150, Loss: 706.8402709960938, Neurons: 30, Grad norm: 2.129e+02\n",
      "Epoch 2150, Loss: 706.8402709960938, Neurons: 30, Grad norm: 2.129e+02\n",
      "Epoch 2151, Loss: 705.9215087890625, Neurons: 30, Grad norm: 2.096e+02\n",
      "Epoch 2151, Loss: 705.9215087890625, Neurons: 30, Grad norm: 2.096e+02\n",
      "Epoch 2152, Loss: 705.0054931640625, Neurons: 30, Grad norm: 2.064e+02\n",
      "Epoch 2152, Loss: 705.0054931640625, Neurons: 30, Grad norm: 2.064e+02\n",
      "Epoch 2153, Loss: 704.091796875, Neurons: 30, Grad norm: 2.033e+02\n",
      "Epoch 2153, Loss: 704.091796875, Neurons: 30, Grad norm: 2.033e+02\n",
      "Epoch 2154, Loss: 703.1802978515625, Neurons: 30, Grad norm: 2.003e+02\n",
      "Epoch 2154, Loss: 703.1802978515625, Neurons: 30, Grad norm: 2.003e+02\n",
      "Epoch 2155, Loss: 702.2705078125, Neurons: 30, Grad norm: 1.974e+02\n",
      "Epoch 2155, Loss: 702.2705078125, Neurons: 30, Grad norm: 1.974e+02\n",
      "Epoch 2156, Loss: 701.3624267578125, Neurons: 30, Grad norm: 1.946e+02\n",
      "Epoch 2156, Loss: 701.3624267578125, Neurons: 30, Grad norm: 1.946e+02\n",
      "Epoch 2157, Loss: 700.4556884765625, Neurons: 30, Grad norm: 1.919e+02\n",
      "Epoch 2157, Loss: 700.4556884765625, Neurons: 30, Grad norm: 1.919e+02\n",
      "Epoch 2158, Loss: 699.550048828125, Neurons: 30, Grad norm: 1.893e+02\n",
      "Epoch 2158, Loss: 699.550048828125, Neurons: 30, Grad norm: 1.893e+02\n",
      "Epoch 2159, Loss: 698.6453857421875, Neurons: 30, Grad norm: 1.867e+02\n",
      "Epoch 2159, Loss: 698.6453857421875, Neurons: 30, Grad norm: 1.867e+02\n",
      "Epoch 2160, Loss: 697.7417602539062, Neurons: 30, Grad norm: 1.842e+02\n",
      "Epoch 2160, Loss: 697.7417602539062, Neurons: 30, Grad norm: 1.842e+02\n",
      "Epoch 2161, Loss: 696.8388061523438, Neurons: 30, Grad norm: 1.818e+02\n",
      "Epoch 2161, Loss: 696.8388061523438, Neurons: 30, Grad norm: 1.818e+02\n",
      "Epoch 2162, Loss: 695.9364624023438, Neurons: 30, Grad norm: 1.795e+02\n",
      "Epoch 2162, Loss: 695.9364624023438, Neurons: 30, Grad norm: 1.795e+02\n",
      "Epoch 2163, Loss: 695.0347900390625, Neurons: 30, Grad norm: 1.772e+02\n",
      "Epoch 2163, Loss: 695.0347900390625, Neurons: 30, Grad norm: 1.772e+02\n",
      "Epoch 2164, Loss: 694.1337280273438, Neurons: 30, Grad norm: 1.750e+02\n",
      "Epoch 2164, Loss: 694.1337280273438, Neurons: 30, Grad norm: 1.750e+02\n",
      "Epoch 2165, Loss: 693.2333984375, Neurons: 30, Grad norm: 1.729e+02\n",
      "Epoch 2165, Loss: 693.2333984375, Neurons: 30, Grad norm: 1.729e+02\n",
      "Epoch 2166, Loss: 692.3338012695312, Neurons: 30, Grad norm: 1.708e+02\n",
      "Epoch 2166, Loss: 692.3338012695312, Neurons: 30, Grad norm: 1.708e+02\n",
      "Epoch 2167, Loss: 691.435302734375, Neurons: 30, Grad norm: 1.687e+02\n",
      "Epoch 2167, Loss: 691.435302734375, Neurons: 30, Grad norm: 1.687e+02\n",
      "Epoch 2168, Loss: 690.537841796875, Neurons: 30, Grad norm: 1.667e+02\n",
      "Epoch 2168, Loss: 690.537841796875, Neurons: 30, Grad norm: 1.667e+02\n",
      "Epoch 2169, Loss: 689.6419677734375, Neurons: 30, Grad norm: 1.648e+02\n",
      "Epoch 2169, Loss: 689.6419677734375, Neurons: 30, Grad norm: 1.648e+02\n",
      "Epoch 2170, Loss: 688.7479248046875, Neurons: 30, Grad norm: 1.629e+02\n",
      "Epoch 2170, Loss: 688.7479248046875, Neurons: 30, Grad norm: 1.629e+02\n",
      "Epoch 2171, Loss: 687.8561401367188, Neurons: 30, Grad norm: 1.610e+02\n",
      "Epoch 2171, Loss: 687.8561401367188, Neurons: 30, Grad norm: 1.610e+02\n",
      "Epoch 2172, Loss: 686.967041015625, Neurons: 30, Grad norm: 1.591e+02\n",
      "Epoch 2172, Loss: 686.967041015625, Neurons: 30, Grad norm: 1.591e+02\n",
      "Epoch 2173, Loss: 686.0811767578125, Neurons: 30, Grad norm: 1.573e+02\n",
      "Epoch 2173, Loss: 686.0811767578125, Neurons: 30, Grad norm: 1.573e+02\n",
      "Epoch 2174, Loss: 685.1992797851562, Neurons: 30, Grad norm: 1.556e+02\n",
      "Epoch 2174, Loss: 685.1992797851562, Neurons: 30, Grad norm: 1.556e+02\n",
      "Epoch 2175, Loss: 684.32177734375, Neurons: 30, Grad norm: 1.539e+02\n",
      "Epoch 2175, Loss: 684.32177734375, Neurons: 30, Grad norm: 1.539e+02\n",
      "Epoch 2176, Loss: 683.449462890625, Neurons: 30, Grad norm: 1.522e+02\n",
      "Epoch 2176, Loss: 683.449462890625, Neurons: 30, Grad norm: 1.522e+02\n",
      "Epoch 2177, Loss: 682.5828247070312, Neurons: 30, Grad norm: 1.506e+02\n",
      "Epoch 2177, Loss: 682.5828247070312, Neurons: 30, Grad norm: 1.506e+02\n",
      "Epoch 2178, Loss: 681.722412109375, Neurons: 30, Grad norm: 1.490e+02\n",
      "Epoch 2178, Loss: 681.722412109375, Neurons: 30, Grad norm: 1.490e+02\n",
      "Epoch 2179, Loss: 680.8685913085938, Neurons: 30, Grad norm: 1.475e+02\n",
      "Epoch 2179, Loss: 680.8685913085938, Neurons: 30, Grad norm: 1.475e+02\n",
      "Epoch 2180, Loss: 680.0215454101562, Neurons: 30, Grad norm: 1.461e+02\n",
      "Epoch 2180, Loss: 680.0215454101562, Neurons: 30, Grad norm: 1.461e+02\n",
      "Epoch 2181, Loss: 679.1814575195312, Neurons: 30, Grad norm: 1.447e+02\n",
      "Epoch 2181, Loss: 679.1814575195312, Neurons: 30, Grad norm: 1.447e+02\n",
      "Epoch 2182, Loss: 678.34814453125, Neurons: 30, Grad norm: 1.434e+02\n",
      "Epoch 2182, Loss: 678.34814453125, Neurons: 30, Grad norm: 1.434e+02\n",
      "Epoch 2183, Loss: 677.5214233398438, Neurons: 30, Grad norm: 1.421e+02\n",
      "Epoch 2183, Loss: 677.5214233398438, Neurons: 30, Grad norm: 1.421e+02\n",
      "Epoch 2184, Loss: 676.700927734375, Neurons: 30, Grad norm: 1.409e+02\n",
      "Epoch 2184, Loss: 676.700927734375, Neurons: 30, Grad norm: 1.409e+02\n",
      "Epoch 2185, Loss: 675.8863525390625, Neurons: 30, Grad norm: 1.397e+02\n",
      "Epoch 2185, Loss: 675.8863525390625, Neurons: 30, Grad norm: 1.397e+02\n",
      "Epoch 2186, Loss: 675.0773315429688, Neurons: 30, Grad norm: 1.385e+02\n",
      "Epoch 2186, Loss: 675.0773315429688, Neurons: 30, Grad norm: 1.385e+02\n",
      "Epoch 2187, Loss: 674.2735595703125, Neurons: 30, Grad norm: 1.374e+02\n",
      "Epoch 2187, Loss: 674.2735595703125, Neurons: 30, Grad norm: 1.374e+02\n",
      "Epoch 2188, Loss: 673.4745483398438, Neurons: 30, Grad norm: 1.364e+02\n",
      "Epoch 2188, Loss: 673.4745483398438, Neurons: 30, Grad norm: 1.364e+02\n",
      "Epoch 2189, Loss: 672.6800537109375, Neurons: 30, Grad norm: 1.353e+02\n",
      "Epoch 2189, Loss: 672.6800537109375, Neurons: 30, Grad norm: 1.353e+02\n",
      "Epoch 2190, Loss: 671.8898315429688, Neurons: 30, Grad norm: 1.343e+02\n",
      "Epoch 2190, Loss: 671.8898315429688, Neurons: 30, Grad norm: 1.343e+02\n",
      "Epoch 2191, Loss: 671.1033935546875, Neurons: 30, Grad norm: 1.334e+02\n",
      "Epoch 2191, Loss: 671.1033935546875, Neurons: 30, Grad norm: 1.334e+02\n",
      "Epoch 2192, Loss: 670.32080078125, Neurons: 30, Grad norm: 1.324e+02\n",
      "Epoch 2192, Loss: 670.32080078125, Neurons: 30, Grad norm: 1.324e+02\n",
      "Epoch 2193, Loss: 669.5413818359375, Neurons: 30, Grad norm: 1.316e+02\n",
      "Epoch 2193, Loss: 669.5413818359375, Neurons: 30, Grad norm: 1.316e+02\n",
      "Epoch 2194, Loss: 668.765380859375, Neurons: 30, Grad norm: 1.307e+02\n",
      "Epoch 2194, Loss: 668.765380859375, Neurons: 30, Grad norm: 1.307e+02\n",
      "Epoch 2195, Loss: 667.9926147460938, Neurons: 30, Grad norm: 1.299e+02\n",
      "Epoch 2195, Loss: 667.9926147460938, Neurons: 30, Grad norm: 1.299e+02\n",
      "Epoch 2196, Loss: 667.222900390625, Neurons: 30, Grad norm: 1.291e+02\n",
      "Epoch 2196, Loss: 667.222900390625, Neurons: 30, Grad norm: 1.291e+02\n",
      "Epoch 2197, Loss: 666.456298828125, Neurons: 30, Grad norm: 1.283e+02\n",
      "Epoch 2197, Loss: 666.456298828125, Neurons: 30, Grad norm: 1.283e+02\n",
      "Epoch 2198, Loss: 665.692626953125, Neurons: 30, Grad norm: 1.276e+02\n",
      "Epoch 2198, Loss: 665.692626953125, Neurons: 30, Grad norm: 1.276e+02\n",
      "Epoch 2199, Loss: 664.931884765625, Neurons: 30, Grad norm: 1.269e+02\n",
      "Epoch 2199, Loss: 664.931884765625, Neurons: 30, Grad norm: 1.269e+02\n",
      "Epoch 2199, Test loss: 668.5366821289062\n",
      "Epoch 2199, Test loss: 668.5366821289062\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "network shape updated to :[12, 18, 1]\n",
      "network shape updated to :[12, 18, 1]\n",
      "Epoch 2200, Loss: 668.1240234375, Neurons: 31, Grad norm: 1.333e+02\n",
      "Epoch 2200, Loss: 668.1240234375, Neurons: 31, Grad norm: 1.333e+02\n",
      "Epoch 2201, Loss: 667.7980346679688, Neurons: 31, Grad norm: 1.329e+02\n",
      "Epoch 2201, Loss: 667.7980346679688, Neurons: 31, Grad norm: 1.329e+02\n",
      "Epoch 2202, Loss: 667.4634399414062, Neurons: 31, Grad norm: 1.325e+02\n",
      "Epoch 2202, Loss: 667.4634399414062, Neurons: 31, Grad norm: 1.325e+02\n",
      "Epoch 2203, Loss: 667.119384765625, Neurons: 31, Grad norm: 1.323e+02\n",
      "Epoch 2203, Loss: 667.119384765625, Neurons: 31, Grad norm: 1.323e+02\n",
      "Epoch 2204, Loss: 666.76611328125, Neurons: 31, Grad norm: 1.321e+02\n",
      "Epoch 2204, Loss: 666.76611328125, Neurons: 31, Grad norm: 1.321e+02\n",
      "Epoch 2205, Loss: 666.4039306640625, Neurons: 31, Grad norm: 1.319e+02\n",
      "Epoch 2205, Loss: 666.4039306640625, Neurons: 31, Grad norm: 1.319e+02\n",
      "Epoch 2206, Loss: 666.0330200195312, Neurons: 31, Grad norm: 1.317e+02\n",
      "Epoch 2206, Loss: 666.0330200195312, Neurons: 31, Grad norm: 1.317e+02\n",
      "Epoch 2207, Loss: 665.6535034179688, Neurons: 31, Grad norm: 1.315e+02\n",
      "Epoch 2207, Loss: 665.6535034179688, Neurons: 31, Grad norm: 1.315e+02\n",
      "Epoch 2208, Loss: 665.2650146484375, Neurons: 31, Grad norm: 1.311e+02\n",
      "Epoch 2208, Loss: 665.2650146484375, Neurons: 31, Grad norm: 1.311e+02\n",
      "Epoch 2209, Loss: 664.867431640625, Neurons: 31, Grad norm: 1.307e+02\n",
      "Epoch 2209, Loss: 664.867431640625, Neurons: 31, Grad norm: 1.307e+02\n",
      "Epoch 2210, Loss: 664.4602661132812, Neurons: 31, Grad norm: 1.300e+02\n",
      "Epoch 2210, Loss: 664.4602661132812, Neurons: 31, Grad norm: 1.300e+02\n",
      "Epoch 2211, Loss: 664.0435180664062, Neurons: 31, Grad norm: 1.292e+02\n",
      "Epoch 2211, Loss: 664.0435180664062, Neurons: 31, Grad norm: 1.292e+02\n",
      "Epoch 2212, Loss: 663.6170043945312, Neurons: 31, Grad norm: 1.283e+02\n",
      "Epoch 2212, Loss: 663.6170043945312, Neurons: 31, Grad norm: 1.283e+02\n",
      "Epoch 2213, Loss: 663.18115234375, Neurons: 31, Grad norm: 1.273e+02\n",
      "Epoch 2213, Loss: 663.18115234375, Neurons: 31, Grad norm: 1.273e+02\n",
      "Epoch 2214, Loss: 662.7361450195312, Neurons: 31, Grad norm: 1.262e+02\n",
      "Epoch 2214, Loss: 662.7361450195312, Neurons: 31, Grad norm: 1.262e+02\n",
      "Epoch 2215, Loss: 662.2826538085938, Neurons: 31, Grad norm: 1.250e+02\n",
      "Epoch 2215, Loss: 662.2826538085938, Neurons: 31, Grad norm: 1.250e+02\n",
      "Epoch 2216, Loss: 661.821044921875, Neurons: 31, Grad norm: 1.238e+02\n",
      "Epoch 2216, Loss: 661.821044921875, Neurons: 31, Grad norm: 1.238e+02\n",
      "Epoch 2217, Loss: 661.351806640625, Neurons: 31, Grad norm: 1.226e+02\n",
      "Epoch 2217, Loss: 661.351806640625, Neurons: 31, Grad norm: 1.226e+02\n",
      "Epoch 2218, Loss: 660.87548828125, Neurons: 31, Grad norm: 1.214e+02\n",
      "Epoch 2218, Loss: 660.87548828125, Neurons: 31, Grad norm: 1.214e+02\n",
      "Epoch 2219, Loss: 660.3925170898438, Neurons: 31, Grad norm: 1.202e+02\n",
      "Epoch 2219, Loss: 660.3925170898438, Neurons: 31, Grad norm: 1.202e+02\n",
      "Epoch 2220, Loss: 659.9033203125, Neurons: 31, Grad norm: 1.191e+02\n",
      "Epoch 2220, Loss: 659.9033203125, Neurons: 31, Grad norm: 1.191e+02\n",
      "Epoch 2221, Loss: 659.4081420898438, Neurons: 31, Grad norm: 1.181e+02\n",
      "Epoch 2221, Loss: 659.4081420898438, Neurons: 31, Grad norm: 1.181e+02\n",
      "Epoch 2222, Loss: 658.9071655273438, Neurons: 31, Grad norm: 1.172e+02\n",
      "Epoch 2222, Loss: 658.9071655273438, Neurons: 31, Grad norm: 1.172e+02\n",
      "Epoch 2223, Loss: 658.4007568359375, Neurons: 31, Grad norm: 1.163e+02\n",
      "Epoch 2223, Loss: 658.4007568359375, Neurons: 31, Grad norm: 1.163e+02\n",
      "Epoch 2224, Loss: 657.8890991210938, Neurons: 31, Grad norm: 1.155e+02\n",
      "Epoch 2224, Loss: 657.8890991210938, Neurons: 31, Grad norm: 1.155e+02\n",
      "Epoch 2225, Loss: 657.3724365234375, Neurons: 31, Grad norm: 1.147e+02\n",
      "Epoch 2225, Loss: 657.3724365234375, Neurons: 31, Grad norm: 1.147e+02\n",
      "Epoch 2226, Loss: 656.8508911132812, Neurons: 31, Grad norm: 1.140e+02\n",
      "Epoch 2226, Loss: 656.8508911132812, Neurons: 31, Grad norm: 1.140e+02\n",
      "Epoch 2227, Loss: 656.3248901367188, Neurons: 31, Grad norm: 1.133e+02\n",
      "Epoch 2227, Loss: 656.3248901367188, Neurons: 31, Grad norm: 1.133e+02\n",
      "Epoch 2228, Loss: 655.7947387695312, Neurons: 31, Grad norm: 1.127e+02\n",
      "Epoch 2228, Loss: 655.7947387695312, Neurons: 31, Grad norm: 1.127e+02\n",
      "Epoch 2229, Loss: 655.2606811523438, Neurons: 31, Grad norm: 1.121e+02\n",
      "Epoch 2229, Loss: 655.2606811523438, Neurons: 31, Grad norm: 1.121e+02\n",
      "Epoch 2230, Loss: 654.722900390625, Neurons: 31, Grad norm: 1.116e+02\n",
      "Epoch 2230, Loss: 654.722900390625, Neurons: 31, Grad norm: 1.116e+02\n",
      "Epoch 2231, Loss: 654.181884765625, Neurons: 31, Grad norm: 1.110e+02\n",
      "Epoch 2231, Loss: 654.181884765625, Neurons: 31, Grad norm: 1.110e+02\n",
      "Epoch 2232, Loss: 653.6377563476562, Neurons: 31, Grad norm: 1.105e+02\n",
      "Epoch 2232, Loss: 653.6377563476562, Neurons: 31, Grad norm: 1.105e+02\n",
      "Epoch 2233, Loss: 653.0908813476562, Neurons: 31, Grad norm: 1.100e+02\n",
      "Epoch 2233, Loss: 653.0908813476562, Neurons: 31, Grad norm: 1.100e+02\n",
      "Epoch 2234, Loss: 652.5411987304688, Neurons: 31, Grad norm: 1.095e+02\n",
      "Epoch 2234, Loss: 652.5411987304688, Neurons: 31, Grad norm: 1.095e+02\n",
      "Epoch 2235, Loss: 651.989013671875, Neurons: 31, Grad norm: 1.090e+02\n",
      "Epoch 2235, Loss: 651.989013671875, Neurons: 31, Grad norm: 1.090e+02\n",
      "Epoch 2236, Loss: 651.4345092773438, Neurons: 31, Grad norm: 1.085e+02\n",
      "Epoch 2236, Loss: 651.4345092773438, Neurons: 31, Grad norm: 1.085e+02\n",
      "Epoch 2237, Loss: 650.8778076171875, Neurons: 31, Grad norm: 1.080e+02\n",
      "Epoch 2237, Loss: 650.8778076171875, Neurons: 31, Grad norm: 1.080e+02\n",
      "Epoch 2238, Loss: 650.3187866210938, Neurons: 31, Grad norm: 1.074e+02\n",
      "Epoch 2238, Loss: 650.3187866210938, Neurons: 31, Grad norm: 1.074e+02\n",
      "Epoch 2239, Loss: 649.7577514648438, Neurons: 31, Grad norm: 1.068e+02\n",
      "Epoch 2239, Loss: 649.7577514648438, Neurons: 31, Grad norm: 1.068e+02\n",
      "Epoch 2240, Loss: 649.1948852539062, Neurons: 31, Grad norm: 1.063e+02\n",
      "Epoch 2240, Loss: 649.1948852539062, Neurons: 31, Grad norm: 1.063e+02\n",
      "Epoch 2241, Loss: 648.6303100585938, Neurons: 31, Grad norm: 1.057e+02\n",
      "Epoch 2241, Loss: 648.6303100585938, Neurons: 31, Grad norm: 1.057e+02\n",
      "Epoch 2242, Loss: 648.06396484375, Neurons: 31, Grad norm: 1.051e+02\n",
      "Epoch 2242, Loss: 648.06396484375, Neurons: 31, Grad norm: 1.051e+02\n",
      "Epoch 2243, Loss: 647.4962768554688, Neurons: 31, Grad norm: 1.045e+02\n",
      "Epoch 2243, Loss: 647.4962768554688, Neurons: 31, Grad norm: 1.045e+02\n",
      "Epoch 2244, Loss: 646.9269409179688, Neurons: 31, Grad norm: 1.039e+02\n",
      "Epoch 2244, Loss: 646.9269409179688, Neurons: 31, Grad norm: 1.039e+02\n",
      "Epoch 2245, Loss: 646.3563842773438, Neurons: 31, Grad norm: 1.034e+02\n",
      "Epoch 2245, Loss: 646.3563842773438, Neurons: 31, Grad norm: 1.034e+02\n",
      "Epoch 2246, Loss: 645.78466796875, Neurons: 31, Grad norm: 1.029e+02\n",
      "Epoch 2246, Loss: 645.78466796875, Neurons: 31, Grad norm: 1.029e+02\n",
      "Epoch 2247, Loss: 645.211669921875, Neurons: 31, Grad norm: 1.023e+02\n",
      "Epoch 2247, Loss: 645.211669921875, Neurons: 31, Grad norm: 1.023e+02\n",
      "Epoch 2248, Loss: 644.6376342773438, Neurons: 31, Grad norm: 1.019e+02\n",
      "Epoch 2248, Loss: 644.6376342773438, Neurons: 31, Grad norm: 1.019e+02\n",
      "Epoch 2249, Loss: 644.0623779296875, Neurons: 31, Grad norm: 1.014e+02\n",
      "Epoch 2249, Loss: 644.0623779296875, Neurons: 31, Grad norm: 1.014e+02\n",
      "Epoch 2250, Loss: 643.4862670898438, Neurons: 31, Grad norm: 1.009e+02\n",
      "Epoch 2250, Loss: 643.4862670898438, Neurons: 31, Grad norm: 1.009e+02\n",
      "Epoch 2251, Loss: 642.9091186523438, Neurons: 31, Grad norm: 1.005e+02\n",
      "Epoch 2251, Loss: 642.9091186523438, Neurons: 31, Grad norm: 1.005e+02\n",
      "Epoch 2252, Loss: 642.3308715820312, Neurons: 31, Grad norm: 1.001e+02\n",
      "Epoch 2252, Loss: 642.3308715820312, Neurons: 31, Grad norm: 1.001e+02\n",
      "Epoch 2253, Loss: 641.751708984375, Neurons: 31, Grad norm: 9.967e+01\n",
      "Epoch 2253, Loss: 641.751708984375, Neurons: 31, Grad norm: 9.967e+01\n",
      "Epoch 2254, Loss: 641.1715698242188, Neurons: 31, Grad norm: 9.928e+01\n",
      "Epoch 2254, Loss: 641.1715698242188, Neurons: 31, Grad norm: 9.928e+01\n",
      "Epoch 2255, Loss: 640.5905151367188, Neurons: 31, Grad norm: 9.890e+01\n",
      "Epoch 2255, Loss: 640.5905151367188, Neurons: 31, Grad norm: 9.890e+01\n",
      "Epoch 2256, Loss: 640.0087280273438, Neurons: 31, Grad norm: 9.851e+01\n",
      "Epoch 2256, Loss: 640.0087280273438, Neurons: 31, Grad norm: 9.851e+01\n",
      "Epoch 2257, Loss: 639.4259643554688, Neurons: 31, Grad norm: 9.811e+01\n",
      "Epoch 2257, Loss: 639.4259643554688, Neurons: 31, Grad norm: 9.811e+01\n",
      "Epoch 2258, Loss: 638.8424072265625, Neurons: 31, Grad norm: 9.773e+01\n",
      "Epoch 2258, Loss: 638.8424072265625, Neurons: 31, Grad norm: 9.773e+01\n",
      "Epoch 2259, Loss: 638.258056640625, Neurons: 31, Grad norm: 9.732e+01\n",
      "Epoch 2259, Loss: 638.258056640625, Neurons: 31, Grad norm: 9.732e+01\n",
      "Epoch 2260, Loss: 637.6727905273438, Neurons: 31, Grad norm: 9.690e+01\n",
      "Epoch 2260, Loss: 637.6727905273438, Neurons: 31, Grad norm: 9.690e+01\n",
      "Epoch 2261, Loss: 637.0867919921875, Neurons: 31, Grad norm: 9.648e+01\n",
      "Epoch 2261, Loss: 637.0867919921875, Neurons: 31, Grad norm: 9.648e+01\n",
      "Epoch 2262, Loss: 636.4998168945312, Neurons: 31, Grad norm: 9.604e+01\n",
      "Epoch 2262, Loss: 636.4998168945312, Neurons: 31, Grad norm: 9.604e+01\n",
      "Epoch 2263, Loss: 635.9120483398438, Neurons: 31, Grad norm: 9.561e+01\n",
      "Epoch 2263, Loss: 635.9120483398438, Neurons: 31, Grad norm: 9.561e+01\n",
      "Epoch 2264, Loss: 635.323486328125, Neurons: 31, Grad norm: 9.517e+01\n",
      "Epoch 2264, Loss: 635.323486328125, Neurons: 31, Grad norm: 9.517e+01\n",
      "Epoch 2265, Loss: 634.7340698242188, Neurons: 31, Grad norm: 9.474e+01\n",
      "Epoch 2265, Loss: 634.7340698242188, Neurons: 31, Grad norm: 9.474e+01\n",
      "Epoch 2266, Loss: 634.1439208984375, Neurons: 31, Grad norm: 9.430e+01\n",
      "Epoch 2266, Loss: 634.1439208984375, Neurons: 31, Grad norm: 9.430e+01\n",
      "Epoch 2267, Loss: 633.5528564453125, Neurons: 31, Grad norm: 9.386e+01\n",
      "Epoch 2267, Loss: 633.5528564453125, Neurons: 31, Grad norm: 9.386e+01\n",
      "Epoch 2268, Loss: 632.9609375, Neurons: 31, Grad norm: 9.344e+01\n",
      "Epoch 2268, Loss: 632.9609375, Neurons: 31, Grad norm: 9.344e+01\n",
      "Epoch 2269, Loss: 632.3683471679688, Neurons: 31, Grad norm: 9.303e+01\n",
      "Epoch 2269, Loss: 632.3683471679688, Neurons: 31, Grad norm: 9.303e+01\n",
      "Epoch 2270, Loss: 631.77490234375, Neurons: 31, Grad norm: 9.263e+01\n",
      "Epoch 2270, Loss: 631.77490234375, Neurons: 31, Grad norm: 9.263e+01\n",
      "Epoch 2271, Loss: 631.1806640625, Neurons: 31, Grad norm: 9.224e+01\n",
      "Epoch 2271, Loss: 631.1806640625, Neurons: 31, Grad norm: 9.224e+01\n",
      "Epoch 2272, Loss: 630.5855102539062, Neurons: 31, Grad norm: 9.185e+01\n",
      "Epoch 2272, Loss: 630.5855102539062, Neurons: 31, Grad norm: 9.185e+01\n",
      "Epoch 2273, Loss: 629.9896850585938, Neurons: 31, Grad norm: 9.149e+01\n",
      "Epoch 2273, Loss: 629.9896850585938, Neurons: 31, Grad norm: 9.149e+01\n",
      "Epoch 2274, Loss: 629.3927612304688, Neurons: 31, Grad norm: 9.114e+01\n",
      "Epoch 2274, Loss: 629.3927612304688, Neurons: 31, Grad norm: 9.114e+01\n",
      "Epoch 2275, Loss: 628.795166015625, Neurons: 31, Grad norm: 9.079e+01\n",
      "Epoch 2275, Loss: 628.795166015625, Neurons: 31, Grad norm: 9.079e+01\n",
      "Epoch 2276, Loss: 628.1966552734375, Neurons: 31, Grad norm: 9.045e+01\n",
      "Epoch 2276, Loss: 628.1966552734375, Neurons: 31, Grad norm: 9.045e+01\n",
      "Epoch 2277, Loss: 627.5972900390625, Neurons: 31, Grad norm: 9.012e+01\n",
      "Epoch 2277, Loss: 627.5972900390625, Neurons: 31, Grad norm: 9.012e+01\n",
      "Epoch 2278, Loss: 626.9968872070312, Neurons: 31, Grad norm: 8.980e+01\n",
      "Epoch 2278, Loss: 626.9968872070312, Neurons: 31, Grad norm: 8.980e+01\n",
      "Epoch 2279, Loss: 626.3955688476562, Neurons: 31, Grad norm: 8.948e+01\n",
      "Epoch 2279, Loss: 626.3955688476562, Neurons: 31, Grad norm: 8.948e+01\n",
      "Epoch 2280, Loss: 625.7933959960938, Neurons: 31, Grad norm: 8.915e+01\n",
      "Epoch 2280, Loss: 625.7933959960938, Neurons: 31, Grad norm: 8.915e+01\n",
      "Epoch 2281, Loss: 625.1901245117188, Neurons: 31, Grad norm: 8.884e+01\n",
      "Epoch 2281, Loss: 625.1901245117188, Neurons: 31, Grad norm: 8.884e+01\n",
      "Epoch 2282, Loss: 624.5860595703125, Neurons: 31, Grad norm: 8.853e+01\n",
      "Epoch 2282, Loss: 624.5860595703125, Neurons: 31, Grad norm: 8.853e+01\n",
      "Epoch 2283, Loss: 623.9808349609375, Neurons: 31, Grad norm: 8.822e+01\n",
      "Epoch 2283, Loss: 623.9808349609375, Neurons: 31, Grad norm: 8.822e+01\n",
      "Epoch 2284, Loss: 623.3746337890625, Neurons: 31, Grad norm: 8.791e+01\n",
      "Epoch 2284, Loss: 623.3746337890625, Neurons: 31, Grad norm: 8.791e+01\n",
      "Epoch 2285, Loss: 622.7674560546875, Neurons: 31, Grad norm: 8.762e+01\n",
      "Epoch 2285, Loss: 622.7674560546875, Neurons: 31, Grad norm: 8.762e+01\n",
      "Epoch 2286, Loss: 622.1593017578125, Neurons: 31, Grad norm: 8.732e+01\n",
      "Epoch 2286, Loss: 622.1593017578125, Neurons: 31, Grad norm: 8.732e+01\n",
      "Epoch 2287, Loss: 621.550048828125, Neurons: 31, Grad norm: 8.703e+01\n",
      "Epoch 2287, Loss: 621.550048828125, Neurons: 31, Grad norm: 8.703e+01\n",
      "Epoch 2288, Loss: 620.939697265625, Neurons: 31, Grad norm: 8.675e+01\n",
      "Epoch 2288, Loss: 620.939697265625, Neurons: 31, Grad norm: 8.675e+01\n",
      "Epoch 2289, Loss: 620.3284301757812, Neurons: 31, Grad norm: 8.646e+01\n",
      "Epoch 2289, Loss: 620.3284301757812, Neurons: 31, Grad norm: 8.646e+01\n",
      "Epoch 2290, Loss: 619.7160034179688, Neurons: 31, Grad norm: 8.617e+01\n",
      "Epoch 2290, Loss: 619.7160034179688, Neurons: 31, Grad norm: 8.617e+01\n",
      "Epoch 2291, Loss: 619.1025390625, Neurons: 31, Grad norm: 8.589e+01\n",
      "Epoch 2291, Loss: 619.1025390625, Neurons: 31, Grad norm: 8.589e+01\n",
      "Epoch 2292, Loss: 618.4879150390625, Neurons: 31, Grad norm: 8.562e+01\n",
      "Epoch 2292, Loss: 618.4879150390625, Neurons: 31, Grad norm: 8.562e+01\n",
      "Epoch 2293, Loss: 617.8722534179688, Neurons: 31, Grad norm: 8.536e+01\n",
      "Epoch 2293, Loss: 617.8722534179688, Neurons: 31, Grad norm: 8.536e+01\n",
      "Epoch 2294, Loss: 617.2554321289062, Neurons: 31, Grad norm: 8.510e+01\n",
      "Epoch 2294, Loss: 617.2554321289062, Neurons: 31, Grad norm: 8.510e+01\n",
      "Epoch 2295, Loss: 616.6375122070312, Neurons: 31, Grad norm: 8.484e+01\n",
      "Epoch 2295, Loss: 616.6375122070312, Neurons: 31, Grad norm: 8.484e+01\n",
      "Epoch 2296, Loss: 616.0185546875, Neurons: 31, Grad norm: 8.459e+01\n",
      "Epoch 2296, Loss: 616.0185546875, Neurons: 31, Grad norm: 8.459e+01\n",
      "Epoch 2297, Loss: 615.3983764648438, Neurons: 31, Grad norm: 8.435e+01\n",
      "Epoch 2297, Loss: 615.3983764648438, Neurons: 31, Grad norm: 8.435e+01\n",
      "Epoch 2298, Loss: 614.7771606445312, Neurons: 31, Grad norm: 8.411e+01\n",
      "Epoch 2298, Loss: 614.7771606445312, Neurons: 31, Grad norm: 8.411e+01\n",
      "Epoch 2299, Loss: 614.15478515625, Neurons: 31, Grad norm: 8.387e+01\n",
      "Epoch 2299, Loss: 614.15478515625, Neurons: 31, Grad norm: 8.387e+01\n",
      "Epoch 2299, Test loss: 617.1213989257812\n",
      "Epoch 2299, Test loss: 617.1213989257812\n",
      "Added neuron to hidden layer 1 with activation sin\n",
      "Added neuron to hidden layer 1 with activation sin\n",
      "network shape updated to :[13, 18, 1]\n",
      "network shape updated to :[13, 18, 1]\n",
      "Epoch 2300, Loss: 619.5100708007812, Neurons: 32, Grad norm: 1.655e+02\n",
      "Epoch 2300, Loss: 619.5100708007812, Neurons: 32, Grad norm: 1.655e+02\n",
      "Epoch 2301, Loss: 619.100341796875, Neurons: 32, Grad norm: 1.586e+02\n",
      "Epoch 2301, Loss: 619.100341796875, Neurons: 32, Grad norm: 1.586e+02\n",
      "Epoch 2302, Loss: 618.6829223632812, Neurons: 32, Grad norm: 1.515e+02\n",
      "Epoch 2302, Loss: 618.6829223632812, Neurons: 32, Grad norm: 1.515e+02\n",
      "Epoch 2303, Loss: 618.260009765625, Neurons: 32, Grad norm: 1.444e+02\n",
      "Epoch 2303, Loss: 618.260009765625, Neurons: 32, Grad norm: 1.444e+02\n",
      "Epoch 2304, Loss: 617.8341064453125, Neurons: 32, Grad norm: 1.372e+02\n",
      "Epoch 2304, Loss: 617.8341064453125, Neurons: 32, Grad norm: 1.372e+02\n",
      "Epoch 2305, Loss: 617.4074096679688, Neurons: 32, Grad norm: 1.301e+02\n",
      "Epoch 2305, Loss: 617.4074096679688, Neurons: 32, Grad norm: 1.301e+02\n",
      "Epoch 2306, Loss: 616.9827270507812, Neurons: 32, Grad norm: 1.232e+02\n",
      "Epoch 2306, Loss: 616.9827270507812, Neurons: 32, Grad norm: 1.232e+02\n",
      "Epoch 2307, Loss: 616.562255859375, Neurons: 32, Grad norm: 1.167e+02\n",
      "Epoch 2307, Loss: 616.562255859375, Neurons: 32, Grad norm: 1.167e+02\n",
      "Epoch 2308, Loss: 616.1483764648438, Neurons: 32, Grad norm: 1.108e+02\n",
      "Epoch 2308, Loss: 616.1483764648438, Neurons: 32, Grad norm: 1.108e+02\n",
      "Epoch 2309, Loss: 615.74267578125, Neurons: 32, Grad norm: 1.055e+02\n",
      "Epoch 2309, Loss: 615.74267578125, Neurons: 32, Grad norm: 1.055e+02\n",
      "Epoch 2310, Loss: 615.3461303710938, Neurons: 32, Grad norm: 1.010e+02\n",
      "Epoch 2310, Loss: 615.3461303710938, Neurons: 32, Grad norm: 1.010e+02\n",
      "Epoch 2311, Loss: 614.9592895507812, Neurons: 32, Grad norm: 9.730e+01\n",
      "Epoch 2311, Loss: 614.9592895507812, Neurons: 32, Grad norm: 9.730e+01\n",
      "Epoch 2312, Loss: 614.5817260742188, Neurons: 32, Grad norm: 9.448e+01\n",
      "Epoch 2312, Loss: 614.5817260742188, Neurons: 32, Grad norm: 9.448e+01\n",
      "Epoch 2313, Loss: 614.2125244140625, Neurons: 32, Grad norm: 9.241e+01\n",
      "Epoch 2313, Loss: 614.2125244140625, Neurons: 32, Grad norm: 9.241e+01\n",
      "Epoch 2314, Loss: 613.8505249023438, Neurons: 32, Grad norm: 9.099e+01\n",
      "Epoch 2314, Loss: 613.8505249023438, Neurons: 32, Grad norm: 9.099e+01\n",
      "Epoch 2315, Loss: 613.494140625, Neurons: 32, Grad norm: 9.012e+01\n",
      "Epoch 2315, Loss: 613.494140625, Neurons: 32, Grad norm: 9.012e+01\n",
      "Epoch 2316, Loss: 613.1420288085938, Neurons: 32, Grad norm: 8.966e+01\n",
      "Epoch 2316, Loss: 613.1420288085938, Neurons: 32, Grad norm: 8.966e+01\n",
      "Epoch 2317, Loss: 612.792724609375, Neurons: 32, Grad norm: 8.948e+01\n",
      "Epoch 2317, Loss: 612.792724609375, Neurons: 32, Grad norm: 8.948e+01\n",
      "Epoch 2318, Loss: 612.4447631835938, Neurons: 32, Grad norm: 8.943e+01\n",
      "Epoch 2318, Loss: 612.4447631835938, Neurons: 32, Grad norm: 8.943e+01\n",
      "Epoch 2319, Loss: 612.0970458984375, Neurons: 32, Grad norm: 8.947e+01\n",
      "Epoch 2319, Loss: 612.0970458984375, Neurons: 32, Grad norm: 8.947e+01\n",
      "Epoch 2320, Loss: 611.7489013671875, Neurons: 32, Grad norm: 8.950e+01\n",
      "Epoch 2320, Loss: 611.7489013671875, Neurons: 32, Grad norm: 8.950e+01\n",
      "Epoch 2321, Loss: 611.3995971679688, Neurons: 32, Grad norm: 8.943e+01\n",
      "Epoch 2321, Loss: 611.3995971679688, Neurons: 32, Grad norm: 8.943e+01\n",
      "Epoch 2322, Loss: 611.0486450195312, Neurons: 32, Grad norm: 8.930e+01\n",
      "Epoch 2322, Loss: 611.0486450195312, Neurons: 32, Grad norm: 8.930e+01\n",
      "Epoch 2323, Loss: 610.6959228515625, Neurons: 32, Grad norm: 8.904e+01\n",
      "Epoch 2323, Loss: 610.6959228515625, Neurons: 32, Grad norm: 8.904e+01\n",
      "Epoch 2324, Loss: 610.3410034179688, Neurons: 32, Grad norm: 8.872e+01\n",
      "Epoch 2324, Loss: 610.3410034179688, Neurons: 32, Grad norm: 8.872e+01\n",
      "Epoch 2325, Loss: 609.9839477539062, Neurons: 32, Grad norm: 8.824e+01\n",
      "Epoch 2325, Loss: 609.9839477539062, Neurons: 32, Grad norm: 8.824e+01\n",
      "Epoch 2326, Loss: 609.6248779296875, Neurons: 32, Grad norm: 8.772e+01\n",
      "Epoch 2326, Loss: 609.6248779296875, Neurons: 32, Grad norm: 8.772e+01\n",
      "Epoch 2327, Loss: 609.2637329101562, Neurons: 32, Grad norm: 8.714e+01\n",
      "Epoch 2327, Loss: 609.2637329101562, Neurons: 32, Grad norm: 8.714e+01\n",
      "Epoch 2328, Loss: 608.9004516601562, Neurons: 32, Grad norm: 8.654e+01\n",
      "Epoch 2328, Loss: 608.9004516601562, Neurons: 32, Grad norm: 8.654e+01\n",
      "Epoch 2329, Loss: 608.53515625, Neurons: 32, Grad norm: 8.593e+01\n",
      "Epoch 2329, Loss: 608.53515625, Neurons: 32, Grad norm: 8.593e+01\n",
      "Epoch 2330, Loss: 608.1676635742188, Neurons: 32, Grad norm: 8.534e+01\n",
      "Epoch 2330, Loss: 608.1676635742188, Neurons: 32, Grad norm: 8.534e+01\n",
      "Epoch 2331, Loss: 607.7980346679688, Neurons: 32, Grad norm: 8.476e+01\n",
      "Epoch 2331, Loss: 607.7980346679688, Neurons: 32, Grad norm: 8.476e+01\n",
      "Epoch 2332, Loss: 607.426025390625, Neurons: 32, Grad norm: 8.423e+01\n",
      "Epoch 2332, Loss: 607.426025390625, Neurons: 32, Grad norm: 8.423e+01\n",
      "Epoch 2333, Loss: 607.0513305664062, Neurons: 32, Grad norm: 8.370e+01\n",
      "Epoch 2333, Loss: 607.0513305664062, Neurons: 32, Grad norm: 8.370e+01\n",
      "Epoch 2334, Loss: 606.6741333007812, Neurons: 32, Grad norm: 8.325e+01\n",
      "Epoch 2334, Loss: 606.6741333007812, Neurons: 32, Grad norm: 8.325e+01\n",
      "Epoch 2335, Loss: 606.294189453125, Neurons: 32, Grad norm: 8.284e+01\n",
      "Epoch 2335, Loss: 606.294189453125, Neurons: 32, Grad norm: 8.284e+01\n",
      "Epoch 2336, Loss: 605.9111328125, Neurons: 32, Grad norm: 8.248e+01\n",
      "Epoch 2336, Loss: 605.9111328125, Neurons: 32, Grad norm: 8.248e+01\n",
      "Epoch 2337, Loss: 605.5250244140625, Neurons: 32, Grad norm: 8.214e+01\n",
      "Epoch 2337, Loss: 605.5250244140625, Neurons: 32, Grad norm: 8.214e+01\n",
      "Epoch 2338, Loss: 605.1353759765625, Neurons: 32, Grad norm: 8.183e+01\n",
      "Epoch 2338, Loss: 605.1353759765625, Neurons: 32, Grad norm: 8.183e+01\n",
      "Epoch 2339, Loss: 604.742431640625, Neurons: 32, Grad norm: 8.155e+01\n",
      "Epoch 2339, Loss: 604.742431640625, Neurons: 32, Grad norm: 8.155e+01\n",
      "Epoch 2340, Loss: 604.3458251953125, Neurons: 32, Grad norm: 8.129e+01\n",
      "Epoch 2340, Loss: 604.3458251953125, Neurons: 32, Grad norm: 8.129e+01\n",
      "Epoch 2341, Loss: 603.94580078125, Neurons: 32, Grad norm: 8.105e+01\n",
      "Epoch 2341, Loss: 603.94580078125, Neurons: 32, Grad norm: 8.105e+01\n",
      "Epoch 2342, Loss: 603.5420532226562, Neurons: 32, Grad norm: 8.086e+01\n",
      "Epoch 2342, Loss: 603.5420532226562, Neurons: 32, Grad norm: 8.086e+01\n",
      "Epoch 2343, Loss: 603.1345825195312, Neurons: 32, Grad norm: 8.064e+01\n",
      "Epoch 2343, Loss: 603.1345825195312, Neurons: 32, Grad norm: 8.064e+01\n",
      "Epoch 2344, Loss: 602.7236328125, Neurons: 32, Grad norm: 8.045e+01\n",
      "Epoch 2344, Loss: 602.7236328125, Neurons: 32, Grad norm: 8.045e+01\n",
      "Epoch 2345, Loss: 602.3092651367188, Neurons: 32, Grad norm: 8.026e+01\n",
      "Epoch 2345, Loss: 602.3092651367188, Neurons: 32, Grad norm: 8.026e+01\n",
      "Epoch 2346, Loss: 601.8914184570312, Neurons: 32, Grad norm: 8.007e+01\n",
      "Epoch 2346, Loss: 601.8914184570312, Neurons: 32, Grad norm: 8.007e+01\n",
      "Epoch 2347, Loss: 601.4703979492188, Neurons: 32, Grad norm: 7.990e+01\n",
      "Epoch 2347, Loss: 601.4703979492188, Neurons: 32, Grad norm: 7.990e+01\n",
      "Epoch 2348, Loss: 601.0462646484375, Neurons: 32, Grad norm: 7.975e+01\n",
      "Epoch 2348, Loss: 601.0462646484375, Neurons: 32, Grad norm: 7.975e+01\n",
      "Epoch 2349, Loss: 600.6190795898438, Neurons: 32, Grad norm: 7.961e+01\n",
      "Epoch 2349, Loss: 600.6190795898438, Neurons: 32, Grad norm: 7.961e+01\n",
      "Epoch 2350, Loss: 600.18896484375, Neurons: 32, Grad norm: 7.950e+01\n",
      "Epoch 2350, Loss: 600.18896484375, Neurons: 32, Grad norm: 7.950e+01\n",
      "Epoch 2351, Loss: 599.7559814453125, Neurons: 32, Grad norm: 7.939e+01\n",
      "Epoch 2351, Loss: 599.7559814453125, Neurons: 32, Grad norm: 7.939e+01\n",
      "Epoch 2352, Loss: 599.3201293945312, Neurons: 32, Grad norm: 7.929e+01\n",
      "Epoch 2352, Loss: 599.3201293945312, Neurons: 32, Grad norm: 7.929e+01\n",
      "Epoch 2353, Loss: 598.8816528320312, Neurons: 32, Grad norm: 7.921e+01\n",
      "Epoch 2353, Loss: 598.8816528320312, Neurons: 32, Grad norm: 7.921e+01\n",
      "Epoch 2354, Loss: 598.4403686523438, Neurons: 32, Grad norm: 7.912e+01\n",
      "Epoch 2354, Loss: 598.4403686523438, Neurons: 32, Grad norm: 7.912e+01\n",
      "Epoch 2355, Loss: 597.9963989257812, Neurons: 32, Grad norm: 7.904e+01\n",
      "Epoch 2355, Loss: 597.9963989257812, Neurons: 32, Grad norm: 7.904e+01\n",
      "Epoch 2356, Loss: 597.5496826171875, Neurons: 32, Grad norm: 7.897e+01\n",
      "Epoch 2356, Loss: 597.5496826171875, Neurons: 32, Grad norm: 7.897e+01\n",
      "Epoch 2357, Loss: 597.1000366210938, Neurons: 32, Grad norm: 7.889e+01\n",
      "Epoch 2357, Loss: 597.1000366210938, Neurons: 32, Grad norm: 7.889e+01\n",
      "Epoch 2358, Loss: 596.6476440429688, Neurons: 32, Grad norm: 7.881e+01\n",
      "Epoch 2358, Loss: 596.6476440429688, Neurons: 32, Grad norm: 7.881e+01\n",
      "Epoch 2359, Loss: 596.1923828125, Neurons: 32, Grad norm: 7.872e+01\n",
      "Epoch 2359, Loss: 596.1923828125, Neurons: 32, Grad norm: 7.872e+01\n",
      "Epoch 2360, Loss: 595.7342529296875, Neurons: 32, Grad norm: 7.863e+01\n",
      "Epoch 2360, Loss: 595.7342529296875, Neurons: 32, Grad norm: 7.863e+01\n",
      "Epoch 2361, Loss: 595.2730712890625, Neurons: 32, Grad norm: 7.854e+01\n",
      "Epoch 2361, Loss: 595.2730712890625, Neurons: 32, Grad norm: 7.854e+01\n",
      "Epoch 2362, Loss: 594.8090209960938, Neurons: 32, Grad norm: 7.843e+01\n",
      "Epoch 2362, Loss: 594.8090209960938, Neurons: 32, Grad norm: 7.843e+01\n",
      "Epoch 2363, Loss: 594.341796875, Neurons: 32, Grad norm: 7.835e+01\n",
      "Epoch 2363, Loss: 594.341796875, Neurons: 32, Grad norm: 7.835e+01\n",
      "Epoch 2364, Loss: 593.8715209960938, Neurons: 32, Grad norm: 7.823e+01\n",
      "Epoch 2364, Loss: 593.8715209960938, Neurons: 32, Grad norm: 7.823e+01\n",
      "Epoch 2365, Loss: 593.39794921875, Neurons: 32, Grad norm: 7.813e+01\n",
      "Epoch 2365, Loss: 593.39794921875, Neurons: 32, Grad norm: 7.813e+01\n",
      "Epoch 2366, Loss: 592.9213256835938, Neurons: 32, Grad norm: 7.802e+01\n",
      "Epoch 2366, Loss: 592.9213256835938, Neurons: 32, Grad norm: 7.802e+01\n",
      "Epoch 2367, Loss: 592.4413452148438, Neurons: 32, Grad norm: 7.793e+01\n",
      "Epoch 2367, Loss: 592.4413452148438, Neurons: 32, Grad norm: 7.793e+01\n",
      "Epoch 2368, Loss: 591.9581298828125, Neurons: 32, Grad norm: 7.783e+01\n",
      "Epoch 2368, Loss: 591.9581298828125, Neurons: 32, Grad norm: 7.783e+01\n",
      "Epoch 2369, Loss: 591.4715576171875, Neurons: 32, Grad norm: 7.773e+01\n",
      "Epoch 2369, Loss: 591.4715576171875, Neurons: 32, Grad norm: 7.773e+01\n",
      "Epoch 2370, Loss: 590.981689453125, Neurons: 32, Grad norm: 7.763e+01\n",
      "Epoch 2370, Loss: 590.981689453125, Neurons: 32, Grad norm: 7.763e+01\n",
      "Epoch 2371, Loss: 590.48828125, Neurons: 32, Grad norm: 7.756e+01\n",
      "Epoch 2371, Loss: 590.48828125, Neurons: 32, Grad norm: 7.756e+01\n",
      "Epoch 2372, Loss: 589.9913940429688, Neurons: 32, Grad norm: 7.749e+01\n",
      "Epoch 2372, Loss: 589.9913940429688, Neurons: 32, Grad norm: 7.749e+01\n",
      "Epoch 2373, Loss: 589.490966796875, Neurons: 32, Grad norm: 7.744e+01\n",
      "Epoch 2373, Loss: 589.490966796875, Neurons: 32, Grad norm: 7.744e+01\n",
      "Epoch 2374, Loss: 588.9867553710938, Neurons: 32, Grad norm: 7.739e+01\n",
      "Epoch 2374, Loss: 588.9867553710938, Neurons: 32, Grad norm: 7.739e+01\n",
      "Epoch 2375, Loss: 588.4788208007812, Neurons: 32, Grad norm: 7.736e+01\n",
      "Epoch 2375, Loss: 588.4788208007812, Neurons: 32, Grad norm: 7.736e+01\n",
      "Epoch 2376, Loss: 587.9671020507812, Neurons: 32, Grad norm: 7.734e+01\n",
      "Epoch 2376, Loss: 587.9671020507812, Neurons: 32, Grad norm: 7.734e+01\n",
      "Epoch 2377, Loss: 587.4513549804688, Neurons: 32, Grad norm: 7.733e+01\n",
      "Epoch 2377, Loss: 587.4513549804688, Neurons: 32, Grad norm: 7.733e+01\n",
      "Epoch 2378, Loss: 586.9315185546875, Neurons: 32, Grad norm: 7.733e+01\n",
      "Epoch 2378, Loss: 586.9315185546875, Neurons: 32, Grad norm: 7.733e+01\n",
      "Epoch 2379, Loss: 586.4076538085938, Neurons: 32, Grad norm: 7.734e+01\n",
      "Epoch 2379, Loss: 586.4076538085938, Neurons: 32, Grad norm: 7.734e+01\n",
      "Epoch 2380, Loss: 585.87939453125, Neurons: 32, Grad norm: 7.737e+01\n",
      "Epoch 2380, Loss: 585.87939453125, Neurons: 32, Grad norm: 7.737e+01\n",
      "Epoch 2381, Loss: 585.346923828125, Neurons: 32, Grad norm: 7.740e+01\n",
      "Epoch 2381, Loss: 585.346923828125, Neurons: 32, Grad norm: 7.740e+01\n",
      "Epoch 2382, Loss: 584.8099975585938, Neurons: 32, Grad norm: 7.744e+01\n",
      "Epoch 2382, Loss: 584.8099975585938, Neurons: 32, Grad norm: 7.744e+01\n",
      "Epoch 2383, Loss: 584.2686767578125, Neurons: 32, Grad norm: 7.749e+01\n",
      "Epoch 2383, Loss: 584.2686767578125, Neurons: 32, Grad norm: 7.749e+01\n",
      "Epoch 2384, Loss: 583.72265625, Neurons: 32, Grad norm: 7.755e+01\n",
      "Epoch 2384, Loss: 583.72265625, Neurons: 32, Grad norm: 7.755e+01\n",
      "Epoch 2385, Loss: 583.1720581054688, Neurons: 32, Grad norm: 7.761e+01\n",
      "Epoch 2385, Loss: 583.1720581054688, Neurons: 32, Grad norm: 7.761e+01\n",
      "Epoch 2386, Loss: 582.6167602539062, Neurons: 32, Grad norm: 7.767e+01\n",
      "Epoch 2386, Loss: 582.6167602539062, Neurons: 32, Grad norm: 7.767e+01\n",
      "Epoch 2387, Loss: 582.0567626953125, Neurons: 32, Grad norm: 7.773e+01\n",
      "Epoch 2387, Loss: 582.0567626953125, Neurons: 32, Grad norm: 7.773e+01\n",
      "Epoch 2388, Loss: 581.4918823242188, Neurons: 32, Grad norm: 7.778e+01\n",
      "Epoch 2388, Loss: 581.4918823242188, Neurons: 32, Grad norm: 7.778e+01\n",
      "Epoch 2389, Loss: 580.9224243164062, Neurons: 32, Grad norm: 7.783e+01\n",
      "Epoch 2389, Loss: 580.9224243164062, Neurons: 32, Grad norm: 7.783e+01\n",
      "Epoch 2390, Loss: 580.34814453125, Neurons: 32, Grad norm: 7.786e+01\n",
      "Epoch 2390, Loss: 580.34814453125, Neurons: 32, Grad norm: 7.786e+01\n",
      "Epoch 2391, Loss: 579.7692260742188, Neurons: 32, Grad norm: 7.788e+01\n",
      "Epoch 2391, Loss: 579.7692260742188, Neurons: 32, Grad norm: 7.788e+01\n",
      "Epoch 2392, Loss: 579.1856689453125, Neurons: 32, Grad norm: 7.788e+01\n",
      "Epoch 2392, Loss: 579.1856689453125, Neurons: 32, Grad norm: 7.788e+01\n",
      "Epoch 2393, Loss: 578.59765625, Neurons: 32, Grad norm: 7.786e+01\n",
      "Epoch 2393, Loss: 578.59765625, Neurons: 32, Grad norm: 7.786e+01\n",
      "Epoch 2394, Loss: 578.0054321289062, Neurons: 32, Grad norm: 7.779e+01\n",
      "Epoch 2394, Loss: 578.0054321289062, Neurons: 32, Grad norm: 7.779e+01\n",
      "Epoch 2395, Loss: 577.4090576171875, Neurons: 32, Grad norm: 7.770e+01\n",
      "Epoch 2395, Loss: 577.4090576171875, Neurons: 32, Grad norm: 7.770e+01\n",
      "Epoch 2396, Loss: 576.8088989257812, Neurons: 32, Grad norm: 7.756e+01\n",
      "Epoch 2396, Loss: 576.8088989257812, Neurons: 32, Grad norm: 7.756e+01\n",
      "Epoch 2397, Loss: 576.2055053710938, Neurons: 32, Grad norm: 7.738e+01\n",
      "Epoch 2397, Loss: 576.2055053710938, Neurons: 32, Grad norm: 7.738e+01\n",
      "Epoch 2398, Loss: 575.5991821289062, Neurons: 32, Grad norm: 7.716e+01\n",
      "Epoch 2398, Loss: 575.5991821289062, Neurons: 32, Grad norm: 7.716e+01\n",
      "Epoch 2399, Loss: 574.990478515625, Neurons: 32, Grad norm: 7.689e+01\n",
      "Epoch 2399, Loss: 574.990478515625, Neurons: 32, Grad norm: 7.689e+01\n",
      "Epoch 2399, Test loss: 576.9557495117188\n",
      "Epoch 2399, Test loss: 576.9557495117188\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "network shape updated to :[13, 19, 1]\n",
      "network shape updated to :[13, 19, 1]\n",
      "Epoch 2400, Loss: 570.9380493164062, Neurons: 33, Grad norm: 8.181e+01\n",
      "Epoch 2400, Loss: 570.9380493164062, Neurons: 33, Grad norm: 8.181e+01\n",
      "Epoch 2401, Loss: 570.7251586914062, Neurons: 33, Grad norm: 8.056e+01\n",
      "Epoch 2401, Loss: 570.7251586914062, Neurons: 33, Grad norm: 8.056e+01\n",
      "Epoch 2402, Loss: 570.51220703125, Neurons: 33, Grad norm: 8.001e+01\n",
      "Epoch 2402, Loss: 570.51220703125, Neurons: 33, Grad norm: 8.001e+01\n",
      "Epoch 2403, Loss: 570.2988891601562, Neurons: 33, Grad norm: 8.004e+01\n",
      "Epoch 2403, Loss: 570.2988891601562, Neurons: 33, Grad norm: 8.004e+01\n",
      "Epoch 2404, Loss: 570.08447265625, Neurons: 33, Grad norm: 8.041e+01\n",
      "Epoch 2404, Loss: 570.08447265625, Neurons: 33, Grad norm: 8.041e+01\n",
      "Epoch 2405, Loss: 569.8665161132812, Neurons: 33, Grad norm: 8.087e+01\n",
      "Epoch 2405, Loss: 569.8665161132812, Neurons: 33, Grad norm: 8.087e+01\n",
      "Epoch 2406, Loss: 569.642822265625, Neurons: 33, Grad norm: 8.120e+01\n",
      "Epoch 2406, Loss: 569.642822265625, Neurons: 33, Grad norm: 8.120e+01\n",
      "Epoch 2407, Loss: 569.4112548828125, Neurons: 33, Grad norm: 8.133e+01\n",
      "Epoch 2407, Loss: 569.4112548828125, Neurons: 33, Grad norm: 8.133e+01\n",
      "Epoch 2408, Loss: 569.1707763671875, Neurons: 33, Grad norm: 8.122e+01\n",
      "Epoch 2408, Loss: 569.1707763671875, Neurons: 33, Grad norm: 8.122e+01\n",
      "Epoch 2409, Loss: 568.9208984375, Neurons: 33, Grad norm: 8.086e+01\n",
      "Epoch 2409, Loss: 568.9208984375, Neurons: 33, Grad norm: 8.086e+01\n",
      "Epoch 2410, Loss: 568.6620483398438, Neurons: 33, Grad norm: 8.033e+01\n",
      "Epoch 2410, Loss: 568.6620483398438, Neurons: 33, Grad norm: 8.033e+01\n",
      "Epoch 2411, Loss: 568.3945922851562, Neurons: 33, Grad norm: 7.970e+01\n",
      "Epoch 2411, Loss: 568.3945922851562, Neurons: 33, Grad norm: 7.970e+01\n",
      "Epoch 2412, Loss: 568.119384765625, Neurons: 33, Grad norm: 7.904e+01\n",
      "Epoch 2412, Loss: 568.119384765625, Neurons: 33, Grad norm: 7.904e+01\n",
      "Epoch 2413, Loss: 567.8372192382812, Neurons: 33, Grad norm: 7.840e+01\n",
      "Epoch 2413, Loss: 567.8372192382812, Neurons: 33, Grad norm: 7.840e+01\n",
      "Epoch 2414, Loss: 567.5486450195312, Neurons: 33, Grad norm: 7.782e+01\n",
      "Epoch 2414, Loss: 567.5486450195312, Neurons: 33, Grad norm: 7.782e+01\n",
      "Epoch 2415, Loss: 567.2543334960938, Neurons: 33, Grad norm: 7.735e+01\n",
      "Epoch 2415, Loss: 567.2543334960938, Neurons: 33, Grad norm: 7.735e+01\n",
      "Epoch 2416, Loss: 566.9545288085938, Neurons: 33, Grad norm: 7.697e+01\n",
      "Epoch 2416, Loss: 566.9545288085938, Neurons: 33, Grad norm: 7.697e+01\n",
      "Epoch 2417, Loss: 566.6492919921875, Neurons: 33, Grad norm: 7.668e+01\n",
      "Epoch 2417, Loss: 566.6492919921875, Neurons: 33, Grad norm: 7.668e+01\n",
      "Epoch 2418, Loss: 566.3385009765625, Neurons: 33, Grad norm: 7.644e+01\n",
      "Epoch 2418, Loss: 566.3385009765625, Neurons: 33, Grad norm: 7.644e+01\n",
      "Epoch 2419, Loss: 566.022216796875, Neurons: 33, Grad norm: 7.622e+01\n",
      "Epoch 2419, Loss: 566.022216796875, Neurons: 33, Grad norm: 7.622e+01\n",
      "Epoch 2420, Loss: 565.7000732421875, Neurons: 33, Grad norm: 7.601e+01\n",
      "Epoch 2420, Loss: 565.7000732421875, Neurons: 33, Grad norm: 7.601e+01\n",
      "Epoch 2421, Loss: 565.3721313476562, Neurons: 33, Grad norm: 7.580e+01\n",
      "Epoch 2421, Loss: 565.3721313476562, Neurons: 33, Grad norm: 7.580e+01\n",
      "Epoch 2422, Loss: 565.0387573242188, Neurons: 33, Grad norm: 7.559e+01\n",
      "Epoch 2422, Loss: 565.0387573242188, Neurons: 33, Grad norm: 7.559e+01\n",
      "Epoch 2423, Loss: 564.6998901367188, Neurons: 33, Grad norm: 7.539e+01\n",
      "Epoch 2423, Loss: 564.6998901367188, Neurons: 33, Grad norm: 7.539e+01\n",
      "Epoch 2424, Loss: 564.3560791015625, Neurons: 33, Grad norm: 7.521e+01\n",
      "Epoch 2424, Loss: 564.3560791015625, Neurons: 33, Grad norm: 7.521e+01\n",
      "Epoch 2425, Loss: 564.0076293945312, Neurons: 33, Grad norm: 7.506e+01\n",
      "Epoch 2425, Loss: 564.0076293945312, Neurons: 33, Grad norm: 7.506e+01\n",
      "Epoch 2426, Loss: 563.6549072265625, Neurons: 33, Grad norm: 7.493e+01\n",
      "Epoch 2426, Loss: 563.6549072265625, Neurons: 33, Grad norm: 7.493e+01\n",
      "Epoch 2427, Loss: 563.2981567382812, Neurons: 33, Grad norm: 7.481e+01\n",
      "Epoch 2427, Loss: 563.2981567382812, Neurons: 33, Grad norm: 7.481e+01\n",
      "Epoch 2428, Loss: 562.9375, Neurons: 33, Grad norm: 7.468e+01\n",
      "Epoch 2428, Loss: 562.9375, Neurons: 33, Grad norm: 7.468e+01\n",
      "Epoch 2429, Loss: 562.5730590820312, Neurons: 33, Grad norm: 7.454e+01\n",
      "Epoch 2429, Loss: 562.5730590820312, Neurons: 33, Grad norm: 7.454e+01\n",
      "Epoch 2430, Loss: 562.2048950195312, Neurons: 33, Grad norm: 7.436e+01\n",
      "Epoch 2430, Loss: 562.2048950195312, Neurons: 33, Grad norm: 7.436e+01\n",
      "Epoch 2431, Loss: 561.8329467773438, Neurons: 33, Grad norm: 7.415e+01\n",
      "Epoch 2431, Loss: 561.8329467773438, Neurons: 33, Grad norm: 7.415e+01\n",
      "Epoch 2432, Loss: 561.457275390625, Neurons: 33, Grad norm: 7.389e+01\n",
      "Epoch 2432, Loss: 561.457275390625, Neurons: 33, Grad norm: 7.389e+01\n",
      "Epoch 2433, Loss: 561.0780639648438, Neurons: 33, Grad norm: 7.361e+01\n",
      "Epoch 2433, Loss: 561.0780639648438, Neurons: 33, Grad norm: 7.361e+01\n",
      "Epoch 2434, Loss: 560.695556640625, Neurons: 33, Grad norm: 7.332e+01\n",
      "Epoch 2434, Loss: 560.695556640625, Neurons: 33, Grad norm: 7.332e+01\n",
      "Epoch 2435, Loss: 560.3096923828125, Neurons: 33, Grad norm: 7.304e+01\n",
      "Epoch 2435, Loss: 560.3096923828125, Neurons: 33, Grad norm: 7.304e+01\n",
      "Epoch 2436, Loss: 559.9208984375, Neurons: 33, Grad norm: 7.277e+01\n",
      "Epoch 2436, Loss: 559.9208984375, Neurons: 33, Grad norm: 7.277e+01\n",
      "Epoch 2437, Loss: 559.5291748046875, Neurons: 33, Grad norm: 7.252e+01\n",
      "Epoch 2437, Loss: 559.5291748046875, Neurons: 33, Grad norm: 7.252e+01\n",
      "Epoch 2438, Loss: 559.1346435546875, Neurons: 33, Grad norm: 7.229e+01\n",
      "Epoch 2438, Loss: 559.1346435546875, Neurons: 33, Grad norm: 7.229e+01\n",
      "Epoch 2439, Loss: 558.737548828125, Neurons: 33, Grad norm: 7.209e+01\n",
      "Epoch 2439, Loss: 558.737548828125, Neurons: 33, Grad norm: 7.209e+01\n",
      "Epoch 2440, Loss: 558.3377075195312, Neurons: 33, Grad norm: 7.191e+01\n",
      "Epoch 2440, Loss: 558.3377075195312, Neurons: 33, Grad norm: 7.191e+01\n",
      "Epoch 2441, Loss: 557.9352416992188, Neurons: 33, Grad norm: 7.173e+01\n",
      "Epoch 2441, Loss: 557.9352416992188, Neurons: 33, Grad norm: 7.173e+01\n",
      "Epoch 2442, Loss: 557.530029296875, Neurons: 33, Grad norm: 7.157e+01\n",
      "Epoch 2442, Loss: 557.530029296875, Neurons: 33, Grad norm: 7.157e+01\n",
      "Epoch 2443, Loss: 557.1221313476562, Neurons: 33, Grad norm: 7.141e+01\n",
      "Epoch 2443, Loss: 557.1221313476562, Neurons: 33, Grad norm: 7.141e+01\n",
      "Epoch 2444, Loss: 556.7117919921875, Neurons: 33, Grad norm: 7.126e+01\n",
      "Epoch 2444, Loss: 556.7117919921875, Neurons: 33, Grad norm: 7.126e+01\n",
      "Epoch 2445, Loss: 556.2987670898438, Neurons: 33, Grad norm: 7.112e+01\n",
      "Epoch 2445, Loss: 556.2987670898438, Neurons: 33, Grad norm: 7.112e+01\n",
      "Epoch 2446, Loss: 555.8831787109375, Neurons: 33, Grad norm: 7.099e+01\n",
      "Epoch 2446, Loss: 555.8831787109375, Neurons: 33, Grad norm: 7.099e+01\n",
      "Epoch 2447, Loss: 555.4652099609375, Neurons: 33, Grad norm: 7.087e+01\n",
      "Epoch 2447, Loss: 555.4652099609375, Neurons: 33, Grad norm: 7.087e+01\n",
      "Epoch 2448, Loss: 555.0448608398438, Neurons: 33, Grad norm: 7.075e+01\n",
      "Epoch 2448, Loss: 555.0448608398438, Neurons: 33, Grad norm: 7.075e+01\n",
      "Epoch 2449, Loss: 554.6220092773438, Neurons: 33, Grad norm: 7.063e+01\n",
      "Epoch 2449, Loss: 554.6220092773438, Neurons: 33, Grad norm: 7.063e+01\n",
      "Epoch 2450, Loss: 554.1967163085938, Neurons: 33, Grad norm: 7.051e+01\n",
      "Epoch 2450, Loss: 554.1967163085938, Neurons: 33, Grad norm: 7.051e+01\n",
      "Epoch 2451, Loss: 553.76904296875, Neurons: 33, Grad norm: 7.039e+01\n",
      "Epoch 2451, Loss: 553.76904296875, Neurons: 33, Grad norm: 7.039e+01\n",
      "Epoch 2452, Loss: 553.3388671875, Neurons: 33, Grad norm: 7.026e+01\n",
      "Epoch 2452, Loss: 553.3388671875, Neurons: 33, Grad norm: 7.026e+01\n",
      "Epoch 2453, Loss: 552.9061889648438, Neurons: 33, Grad norm: 7.012e+01\n",
      "Epoch 2453, Loss: 552.9061889648438, Neurons: 33, Grad norm: 7.012e+01\n",
      "Epoch 2454, Loss: 552.4712524414062, Neurons: 33, Grad norm: 6.999e+01\n",
      "Epoch 2454, Loss: 552.4712524414062, Neurons: 33, Grad norm: 6.999e+01\n",
      "Epoch 2455, Loss: 552.0338134765625, Neurons: 33, Grad norm: 6.986e+01\n",
      "Epoch 2455, Loss: 552.0338134765625, Neurons: 33, Grad norm: 6.986e+01\n",
      "Epoch 2456, Loss: 551.5941772460938, Neurons: 33, Grad norm: 6.974e+01\n",
      "Epoch 2456, Loss: 551.5941772460938, Neurons: 33, Grad norm: 6.974e+01\n",
      "Epoch 2457, Loss: 551.152099609375, Neurons: 33, Grad norm: 6.962e+01\n",
      "Epoch 2457, Loss: 551.152099609375, Neurons: 33, Grad norm: 6.962e+01\n",
      "Epoch 2458, Loss: 550.7077026367188, Neurons: 33, Grad norm: 6.950e+01\n",
      "Epoch 2458, Loss: 550.7077026367188, Neurons: 33, Grad norm: 6.950e+01\n",
      "Epoch 2459, Loss: 550.2611694335938, Neurons: 33, Grad norm: 6.939e+01\n",
      "Epoch 2459, Loss: 550.2611694335938, Neurons: 33, Grad norm: 6.939e+01\n",
      "Epoch 2460, Loss: 549.812255859375, Neurons: 33, Grad norm: 6.928e+01\n",
      "Epoch 2460, Loss: 549.812255859375, Neurons: 33, Grad norm: 6.928e+01\n",
      "Epoch 2461, Loss: 549.3612060546875, Neurons: 33, Grad norm: 6.918e+01\n",
      "Epoch 2461, Loss: 549.3612060546875, Neurons: 33, Grad norm: 6.918e+01\n",
      "Epoch 2462, Loss: 548.907958984375, Neurons: 33, Grad norm: 6.907e+01\n",
      "Epoch 2462, Loss: 548.907958984375, Neurons: 33, Grad norm: 6.907e+01\n",
      "Epoch 2463, Loss: 548.4525146484375, Neurons: 33, Grad norm: 6.897e+01\n",
      "Epoch 2463, Loss: 548.4525146484375, Neurons: 33, Grad norm: 6.897e+01\n",
      "Epoch 2464, Loss: 547.9951782226562, Neurons: 33, Grad norm: 6.887e+01\n",
      "Epoch 2464, Loss: 547.9951782226562, Neurons: 33, Grad norm: 6.887e+01\n",
      "Epoch 2465, Loss: 547.53564453125, Neurons: 33, Grad norm: 6.878e+01\n",
      "Epoch 2465, Loss: 547.53564453125, Neurons: 33, Grad norm: 6.878e+01\n",
      "Epoch 2466, Loss: 547.0741577148438, Neurons: 33, Grad norm: 6.868e+01\n",
      "Epoch 2466, Loss: 547.0741577148438, Neurons: 33, Grad norm: 6.868e+01\n",
      "Epoch 2467, Loss: 546.6107788085938, Neurons: 33, Grad norm: 6.858e+01\n",
      "Epoch 2467, Loss: 546.6107788085938, Neurons: 33, Grad norm: 6.858e+01\n",
      "Epoch 2468, Loss: 546.1454467773438, Neurons: 33, Grad norm: 6.849e+01\n",
      "Epoch 2468, Loss: 546.1454467773438, Neurons: 33, Grad norm: 6.849e+01\n",
      "Epoch 2469, Loss: 545.6782836914062, Neurons: 33, Grad norm: 6.839e+01\n",
      "Epoch 2469, Loss: 545.6782836914062, Neurons: 33, Grad norm: 6.839e+01\n",
      "Epoch 2470, Loss: 545.2092895507812, Neurons: 33, Grad norm: 6.829e+01\n",
      "Epoch 2470, Loss: 545.2092895507812, Neurons: 33, Grad norm: 6.829e+01\n",
      "Epoch 2471, Loss: 544.7384033203125, Neurons: 33, Grad norm: 6.820e+01\n",
      "Epoch 2471, Loss: 544.7384033203125, Neurons: 33, Grad norm: 6.820e+01\n",
      "Epoch 2472, Loss: 544.2657470703125, Neurons: 33, Grad norm: 6.810e+01\n",
      "Epoch 2472, Loss: 544.2657470703125, Neurons: 33, Grad norm: 6.810e+01\n",
      "Epoch 2473, Loss: 543.7913818359375, Neurons: 33, Grad norm: 6.800e+01\n",
      "Epoch 2473, Loss: 543.7913818359375, Neurons: 33, Grad norm: 6.800e+01\n",
      "Epoch 2474, Loss: 543.3154296875, Neurons: 33, Grad norm: 6.790e+01\n",
      "Epoch 2474, Loss: 543.3154296875, Neurons: 33, Grad norm: 6.790e+01\n",
      "Epoch 2475, Loss: 542.837646484375, Neurons: 33, Grad norm: 6.780e+01\n",
      "Epoch 2475, Loss: 542.837646484375, Neurons: 33, Grad norm: 6.780e+01\n",
      "Epoch 2476, Loss: 542.3582763671875, Neurons: 33, Grad norm: 6.770e+01\n",
      "Epoch 2476, Loss: 542.3582763671875, Neurons: 33, Grad norm: 6.770e+01\n",
      "Epoch 2477, Loss: 541.8771362304688, Neurons: 33, Grad norm: 6.761e+01\n",
      "Epoch 2477, Loss: 541.8771362304688, Neurons: 33, Grad norm: 6.761e+01\n",
      "Epoch 2478, Loss: 541.39453125, Neurons: 33, Grad norm: 6.751e+01\n",
      "Epoch 2478, Loss: 541.39453125, Neurons: 33, Grad norm: 6.751e+01\n",
      "Epoch 2479, Loss: 540.9102172851562, Neurons: 33, Grad norm: 6.742e+01\n",
      "Epoch 2479, Loss: 540.9102172851562, Neurons: 33, Grad norm: 6.742e+01\n",
      "Epoch 2480, Loss: 540.4242553710938, Neurons: 33, Grad norm: 6.732e+01\n",
      "Epoch 2480, Loss: 540.4242553710938, Neurons: 33, Grad norm: 6.732e+01\n",
      "Epoch 2481, Loss: 539.9368286132812, Neurons: 33, Grad norm: 6.723e+01\n",
      "Epoch 2481, Loss: 539.9368286132812, Neurons: 33, Grad norm: 6.723e+01\n",
      "Epoch 2482, Loss: 539.44775390625, Neurons: 33, Grad norm: 6.714e+01\n",
      "Epoch 2482, Loss: 539.44775390625, Neurons: 33, Grad norm: 6.714e+01\n",
      "Epoch 2483, Loss: 538.957275390625, Neurons: 33, Grad norm: 6.704e+01\n",
      "Epoch 2483, Loss: 538.957275390625, Neurons: 33, Grad norm: 6.704e+01\n",
      "Epoch 2484, Loss: 538.4651489257812, Neurons: 33, Grad norm: 6.695e+01\n",
      "Epoch 2484, Loss: 538.4651489257812, Neurons: 33, Grad norm: 6.695e+01\n",
      "Epoch 2485, Loss: 537.9716796875, Neurons: 33, Grad norm: 6.685e+01\n",
      "Epoch 2485, Loss: 537.9716796875, Neurons: 33, Grad norm: 6.685e+01\n",
      "Epoch 2486, Loss: 537.4765625, Neurons: 33, Grad norm: 6.675e+01\n",
      "Epoch 2486, Loss: 537.4765625, Neurons: 33, Grad norm: 6.675e+01\n",
      "Epoch 2487, Loss: 536.9800415039062, Neurons: 33, Grad norm: 6.666e+01\n",
      "Epoch 2487, Loss: 536.9800415039062, Neurons: 33, Grad norm: 6.666e+01\n",
      "Epoch 2488, Loss: 536.4820556640625, Neurons: 33, Grad norm: 6.656e+01\n",
      "Epoch 2488, Loss: 536.4820556640625, Neurons: 33, Grad norm: 6.656e+01\n",
      "Epoch 2489, Loss: 535.982666015625, Neurons: 33, Grad norm: 6.646e+01\n",
      "Epoch 2489, Loss: 535.982666015625, Neurons: 33, Grad norm: 6.646e+01\n",
      "Epoch 2490, Loss: 535.4817504882812, Neurons: 33, Grad norm: 6.637e+01\n",
      "Epoch 2490, Loss: 535.4817504882812, Neurons: 33, Grad norm: 6.637e+01\n",
      "Epoch 2491, Loss: 534.9795532226562, Neurons: 33, Grad norm: 6.627e+01\n",
      "Epoch 2491, Loss: 534.9795532226562, Neurons: 33, Grad norm: 6.627e+01\n",
      "Epoch 2492, Loss: 534.4758911132812, Neurons: 33, Grad norm: 6.617e+01\n",
      "Epoch 2492, Loss: 534.4758911132812, Neurons: 33, Grad norm: 6.617e+01\n",
      "Epoch 2493, Loss: 533.9708862304688, Neurons: 33, Grad norm: 6.608e+01\n",
      "Epoch 2493, Loss: 533.9708862304688, Neurons: 33, Grad norm: 6.608e+01\n",
      "Epoch 2494, Loss: 533.464599609375, Neurons: 33, Grad norm: 6.598e+01\n",
      "Epoch 2494, Loss: 533.464599609375, Neurons: 33, Grad norm: 6.598e+01\n",
      "Epoch 2495, Loss: 532.9569091796875, Neurons: 33, Grad norm: 6.588e+01\n",
      "Epoch 2495, Loss: 532.9569091796875, Neurons: 33, Grad norm: 6.588e+01\n",
      "Epoch 2496, Loss: 532.447998046875, Neurons: 33, Grad norm: 6.578e+01\n",
      "Epoch 2496, Loss: 532.447998046875, Neurons: 33, Grad norm: 6.578e+01\n",
      "Epoch 2497, Loss: 531.9378051757812, Neurons: 33, Grad norm: 6.568e+01\n",
      "Epoch 2497, Loss: 531.9378051757812, Neurons: 33, Grad norm: 6.568e+01\n",
      "Epoch 2498, Loss: 531.42626953125, Neurons: 33, Grad norm: 6.559e+01\n",
      "Epoch 2498, Loss: 531.42626953125, Neurons: 33, Grad norm: 6.559e+01\n",
      "Epoch 2499, Loss: 530.9135131835938, Neurons: 33, Grad norm: 6.549e+01\n",
      "Epoch 2499, Loss: 530.9135131835938, Neurons: 33, Grad norm: 6.549e+01\n",
      "Epoch 2499, Test loss: 532.1271362304688\n",
      "Epoch 2499, Test loss: 532.1271362304688\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "network shape updated to :[13, 20, 1]\n",
      "network shape updated to :[13, 20, 1]\n",
      "Epoch 2500, Loss: 528.7652587890625, Neurons: 34, Grad norm: 6.990e+01\n",
      "Epoch 2500, Loss: 528.7652587890625, Neurons: 34, Grad norm: 6.990e+01\n",
      "Epoch 2501, Loss: 528.6004028320312, Neurons: 34, Grad norm: 6.974e+01\n",
      "Epoch 2501, Loss: 528.6004028320312, Neurons: 34, Grad norm: 6.974e+01\n",
      "Epoch 2502, Loss: 528.4354858398438, Neurons: 34, Grad norm: 6.978e+01\n",
      "Epoch 2502, Loss: 528.4354858398438, Neurons: 34, Grad norm: 6.978e+01\n",
      "Epoch 2503, Loss: 528.2659301757812, Neurons: 34, Grad norm: 6.969e+01\n",
      "Epoch 2503, Loss: 528.2659301757812, Neurons: 34, Grad norm: 6.969e+01\n",
      "Epoch 2504, Loss: 528.0885009765625, Neurons: 34, Grad norm: 6.947e+01\n",
      "Epoch 2504, Loss: 528.0885009765625, Neurons: 34, Grad norm: 6.947e+01\n",
      "Epoch 2505, Loss: 527.9032592773438, Neurons: 34, Grad norm: 6.923e+01\n",
      "Epoch 2505, Loss: 527.9032592773438, Neurons: 34, Grad norm: 6.923e+01\n",
      "Epoch 2506, Loss: 527.7108764648438, Neurons: 34, Grad norm: 6.906e+01\n",
      "Epoch 2506, Loss: 527.7108764648438, Neurons: 34, Grad norm: 6.906e+01\n",
      "Epoch 2507, Loss: 527.5121459960938, Neurons: 34, Grad norm: 6.899e+01\n",
      "Epoch 2507, Loss: 527.5121459960938, Neurons: 34, Grad norm: 6.899e+01\n",
      "Epoch 2508, Loss: 527.3070678710938, Neurons: 34, Grad norm: 6.896e+01\n",
      "Epoch 2508, Loss: 527.3070678710938, Neurons: 34, Grad norm: 6.896e+01\n",
      "Epoch 2509, Loss: 527.0953979492188, Neurons: 34, Grad norm: 6.892e+01\n",
      "Epoch 2509, Loss: 527.0953979492188, Neurons: 34, Grad norm: 6.892e+01\n",
      "Epoch 2510, Loss: 526.8767700195312, Neurons: 34, Grad norm: 6.884e+01\n",
      "Epoch 2510, Loss: 526.8767700195312, Neurons: 34, Grad norm: 6.884e+01\n",
      "Epoch 2511, Loss: 526.6509399414062, Neurons: 34, Grad norm: 6.874e+01\n",
      "Epoch 2511, Loss: 526.6509399414062, Neurons: 34, Grad norm: 6.874e+01\n",
      "Epoch 2512, Loss: 526.4182739257812, Neurons: 34, Grad norm: 6.865e+01\n",
      "Epoch 2512, Loss: 526.4182739257812, Neurons: 34, Grad norm: 6.865e+01\n",
      "Epoch 2513, Loss: 526.1787719726562, Neurons: 34, Grad norm: 6.857e+01\n",
      "Epoch 2513, Loss: 526.1787719726562, Neurons: 34, Grad norm: 6.857e+01\n",
      "Epoch 2514, Loss: 525.9329223632812, Neurons: 34, Grad norm: 6.851e+01\n",
      "Epoch 2514, Loss: 525.9329223632812, Neurons: 34, Grad norm: 6.851e+01\n",
      "Epoch 2515, Loss: 525.6805419921875, Neurons: 34, Grad norm: 6.846e+01\n",
      "Epoch 2515, Loss: 525.6805419921875, Neurons: 34, Grad norm: 6.846e+01\n",
      "Epoch 2516, Loss: 525.421630859375, Neurons: 34, Grad norm: 6.841e+01\n",
      "Epoch 2516, Loss: 525.421630859375, Neurons: 34, Grad norm: 6.841e+01\n",
      "Epoch 2517, Loss: 525.1561889648438, Neurons: 34, Grad norm: 6.834e+01\n",
      "Epoch 2517, Loss: 525.1561889648438, Neurons: 34, Grad norm: 6.834e+01\n",
      "Epoch 2518, Loss: 524.88427734375, Neurons: 34, Grad norm: 6.826e+01\n",
      "Epoch 2518, Loss: 524.88427734375, Neurons: 34, Grad norm: 6.826e+01\n",
      "Epoch 2519, Loss: 524.6060180664062, Neurons: 34, Grad norm: 6.819e+01\n",
      "Epoch 2519, Loss: 524.6060180664062, Neurons: 34, Grad norm: 6.819e+01\n",
      "Epoch 2520, Loss: 524.32177734375, Neurons: 34, Grad norm: 6.812e+01\n",
      "Epoch 2520, Loss: 524.32177734375, Neurons: 34, Grad norm: 6.812e+01\n",
      "Epoch 2521, Loss: 524.0316162109375, Neurons: 34, Grad norm: 6.805e+01\n",
      "Epoch 2521, Loss: 524.0316162109375, Neurons: 34, Grad norm: 6.805e+01\n",
      "Epoch 2522, Loss: 523.7356567382812, Neurons: 34, Grad norm: 6.799e+01\n",
      "Epoch 2522, Loss: 523.7356567382812, Neurons: 34, Grad norm: 6.799e+01\n",
      "Epoch 2523, Loss: 523.4341430664062, Neurons: 34, Grad norm: 6.791e+01\n",
      "Epoch 2523, Loss: 523.4341430664062, Neurons: 34, Grad norm: 6.791e+01\n",
      "Epoch 2524, Loss: 523.126953125, Neurons: 34, Grad norm: 6.783e+01\n",
      "Epoch 2524, Loss: 523.126953125, Neurons: 34, Grad norm: 6.783e+01\n",
      "Epoch 2525, Loss: 522.814453125, Neurons: 34, Grad norm: 6.776e+01\n",
      "Epoch 2525, Loss: 522.814453125, Neurons: 34, Grad norm: 6.776e+01\n",
      "Epoch 2526, Loss: 522.496826171875, Neurons: 34, Grad norm: 6.768e+01\n",
      "Epoch 2526, Loss: 522.496826171875, Neurons: 34, Grad norm: 6.768e+01\n",
      "Epoch 2527, Loss: 522.1741333007812, Neurons: 34, Grad norm: 6.761e+01\n",
      "Epoch 2527, Loss: 522.1741333007812, Neurons: 34, Grad norm: 6.761e+01\n",
      "Epoch 2528, Loss: 521.8465576171875, Neurons: 34, Grad norm: 6.754e+01\n",
      "Epoch 2528, Loss: 521.8465576171875, Neurons: 34, Grad norm: 6.754e+01\n",
      "Epoch 2529, Loss: 521.5142822265625, Neurons: 34, Grad norm: 6.746e+01\n",
      "Epoch 2529, Loss: 521.5142822265625, Neurons: 34, Grad norm: 6.746e+01\n",
      "Epoch 2530, Loss: 521.17724609375, Neurons: 34, Grad norm: 6.738e+01\n",
      "Epoch 2530, Loss: 521.17724609375, Neurons: 34, Grad norm: 6.738e+01\n",
      "Epoch 2531, Loss: 520.835693359375, Neurons: 34, Grad norm: 6.729e+01\n",
      "Epoch 2531, Loss: 520.835693359375, Neurons: 34, Grad norm: 6.729e+01\n",
      "Epoch 2532, Loss: 520.4896850585938, Neurons: 34, Grad norm: 6.720e+01\n",
      "Epoch 2532, Loss: 520.4896850585938, Neurons: 34, Grad norm: 6.720e+01\n",
      "Epoch 2533, Loss: 520.1394653320312, Neurons: 34, Grad norm: 6.711e+01\n",
      "Epoch 2533, Loss: 520.1394653320312, Neurons: 34, Grad norm: 6.711e+01\n",
      "Epoch 2534, Loss: 519.7850341796875, Neurons: 34, Grad norm: 6.703e+01\n",
      "Epoch 2534, Loss: 519.7850341796875, Neurons: 34, Grad norm: 6.703e+01\n",
      "Epoch 2535, Loss: 519.4265747070312, Neurons: 34, Grad norm: 6.694e+01\n",
      "Epoch 2535, Loss: 519.4265747070312, Neurons: 34, Grad norm: 6.694e+01\n",
      "Epoch 2536, Loss: 519.0640258789062, Neurons: 34, Grad norm: 6.685e+01\n",
      "Epoch 2536, Loss: 519.0640258789062, Neurons: 34, Grad norm: 6.685e+01\n",
      "Epoch 2537, Loss: 518.6976318359375, Neurons: 34, Grad norm: 6.676e+01\n",
      "Epoch 2537, Loss: 518.6976318359375, Neurons: 34, Grad norm: 6.676e+01\n",
      "Epoch 2538, Loss: 518.327392578125, Neurons: 34, Grad norm: 6.667e+01\n",
      "Epoch 2538, Loss: 518.327392578125, Neurons: 34, Grad norm: 6.667e+01\n",
      "Epoch 2539, Loss: 517.9534912109375, Neurons: 34, Grad norm: 6.658e+01\n",
      "Epoch 2539, Loss: 517.9534912109375, Neurons: 34, Grad norm: 6.658e+01\n",
      "Epoch 2540, Loss: 517.575927734375, Neurons: 34, Grad norm: 6.649e+01\n",
      "Epoch 2540, Loss: 517.575927734375, Neurons: 34, Grad norm: 6.649e+01\n",
      "Epoch 2541, Loss: 517.1947631835938, Neurons: 34, Grad norm: 6.640e+01\n",
      "Epoch 2541, Loss: 517.1947631835938, Neurons: 34, Grad norm: 6.640e+01\n",
      "Epoch 2542, Loss: 516.8101196289062, Neurons: 34, Grad norm: 6.630e+01\n",
      "Epoch 2542, Loss: 516.8101196289062, Neurons: 34, Grad norm: 6.630e+01\n",
      "Epoch 2543, Loss: 516.422119140625, Neurons: 34, Grad norm: 6.620e+01\n",
      "Epoch 2543, Loss: 516.422119140625, Neurons: 34, Grad norm: 6.620e+01\n",
      "Epoch 2544, Loss: 516.03076171875, Neurons: 34, Grad norm: 6.611e+01\n",
      "Epoch 2544, Loss: 516.03076171875, Neurons: 34, Grad norm: 6.611e+01\n",
      "Epoch 2545, Loss: 515.63623046875, Neurons: 34, Grad norm: 6.601e+01\n",
      "Epoch 2545, Loss: 515.63623046875, Neurons: 34, Grad norm: 6.601e+01\n",
      "Epoch 2546, Loss: 515.238525390625, Neurons: 34, Grad norm: 6.591e+01\n",
      "Epoch 2546, Loss: 515.238525390625, Neurons: 34, Grad norm: 6.591e+01\n",
      "Epoch 2547, Loss: 514.8377075195312, Neurons: 34, Grad norm: 6.582e+01\n",
      "Epoch 2547, Loss: 514.8377075195312, Neurons: 34, Grad norm: 6.582e+01\n",
      "Epoch 2548, Loss: 514.4339599609375, Neurons: 34, Grad norm: 6.572e+01\n",
      "Epoch 2548, Loss: 514.4339599609375, Neurons: 34, Grad norm: 6.572e+01\n",
      "Epoch 2549, Loss: 514.0271606445312, Neurons: 34, Grad norm: 6.562e+01\n",
      "Epoch 2549, Loss: 514.0271606445312, Neurons: 34, Grad norm: 6.562e+01\n",
      "Epoch 2550, Loss: 513.6175537109375, Neurons: 34, Grad norm: 6.552e+01\n",
      "Epoch 2550, Loss: 513.6175537109375, Neurons: 34, Grad norm: 6.552e+01\n",
      "Epoch 2551, Loss: 513.205078125, Neurons: 34, Grad norm: 6.543e+01\n",
      "Epoch 2551, Loss: 513.205078125, Neurons: 34, Grad norm: 6.543e+01\n",
      "Epoch 2552, Loss: 512.7899169921875, Neurons: 34, Grad norm: 6.533e+01\n",
      "Epoch 2552, Loss: 512.7899169921875, Neurons: 34, Grad norm: 6.533e+01\n",
      "Epoch 2553, Loss: 512.3719482421875, Neurons: 34, Grad norm: 6.523e+01\n",
      "Epoch 2553, Loss: 512.3719482421875, Neurons: 34, Grad norm: 6.523e+01\n",
      "Epoch 2554, Loss: 511.951416015625, Neurons: 34, Grad norm: 6.513e+01\n",
      "Epoch 2554, Loss: 511.951416015625, Neurons: 34, Grad norm: 6.513e+01\n",
      "Epoch 2555, Loss: 511.52825927734375, Neurons: 34, Grad norm: 6.503e+01\n",
      "Epoch 2555, Loss: 511.52825927734375, Neurons: 34, Grad norm: 6.503e+01\n",
      "Epoch 2556, Loss: 511.1026611328125, Neurons: 34, Grad norm: 6.492e+01\n",
      "Epoch 2556, Loss: 511.1026611328125, Neurons: 34, Grad norm: 6.492e+01\n",
      "Epoch 2557, Loss: 510.6744689941406, Neurons: 34, Grad norm: 6.482e+01\n",
      "Epoch 2557, Loss: 510.6744689941406, Neurons: 34, Grad norm: 6.482e+01\n",
      "Epoch 2558, Loss: 510.243896484375, Neurons: 34, Grad norm: 6.472e+01\n",
      "Epoch 2558, Loss: 510.243896484375, Neurons: 34, Grad norm: 6.472e+01\n",
      "Epoch 2559, Loss: 509.8109130859375, Neurons: 34, Grad norm: 6.462e+01\n",
      "Epoch 2559, Loss: 509.8109130859375, Neurons: 34, Grad norm: 6.462e+01\n",
      "Epoch 2560, Loss: 509.3755187988281, Neurons: 34, Grad norm: 6.452e+01\n",
      "Epoch 2560, Loss: 509.3755187988281, Neurons: 34, Grad norm: 6.452e+01\n",
      "Epoch 2561, Loss: 508.93792724609375, Neurons: 34, Grad norm: 6.441e+01\n",
      "Epoch 2561, Loss: 508.93792724609375, Neurons: 34, Grad norm: 6.441e+01\n",
      "Epoch 2562, Loss: 508.4980163574219, Neurons: 34, Grad norm: 6.431e+01\n",
      "Epoch 2562, Loss: 508.4980163574219, Neurons: 34, Grad norm: 6.431e+01\n",
      "Epoch 2563, Loss: 508.055908203125, Neurons: 34, Grad norm: 6.421e+01\n",
      "Epoch 2563, Loss: 508.055908203125, Neurons: 34, Grad norm: 6.421e+01\n",
      "Epoch 2564, Loss: 507.6116027832031, Neurons: 34, Grad norm: 6.411e+01\n",
      "Epoch 2564, Loss: 507.6116027832031, Neurons: 34, Grad norm: 6.411e+01\n",
      "Epoch 2565, Loss: 507.1651611328125, Neurons: 34, Grad norm: 6.401e+01\n",
      "Epoch 2565, Loss: 507.1651611328125, Neurons: 34, Grad norm: 6.401e+01\n",
      "Epoch 2566, Loss: 506.7165832519531, Neurons: 34, Grad norm: 6.390e+01\n",
      "Epoch 2566, Loss: 506.7165832519531, Neurons: 34, Grad norm: 6.390e+01\n",
      "Epoch 2567, Loss: 506.2659606933594, Neurons: 34, Grad norm: 6.380e+01\n",
      "Epoch 2567, Loss: 506.2659606933594, Neurons: 34, Grad norm: 6.380e+01\n",
      "Epoch 2568, Loss: 505.813232421875, Neurons: 34, Grad norm: 6.370e+01\n",
      "Epoch 2568, Loss: 505.813232421875, Neurons: 34, Grad norm: 6.370e+01\n",
      "Epoch 2569, Loss: 505.3585205078125, Neurons: 34, Grad norm: 6.360e+01\n",
      "Epoch 2569, Loss: 505.3585205078125, Neurons: 34, Grad norm: 6.360e+01\n",
      "Epoch 2570, Loss: 504.9018249511719, Neurons: 34, Grad norm: 6.350e+01\n",
      "Epoch 2570, Loss: 504.9018249511719, Neurons: 34, Grad norm: 6.350e+01\n",
      "Epoch 2571, Loss: 504.4431457519531, Neurons: 34, Grad norm: 6.340e+01\n",
      "Epoch 2571, Loss: 504.4431457519531, Neurons: 34, Grad norm: 6.340e+01\n",
      "Epoch 2572, Loss: 503.9825439453125, Neurons: 34, Grad norm: 6.329e+01\n",
      "Epoch 2572, Loss: 503.9825439453125, Neurons: 34, Grad norm: 6.329e+01\n",
      "Epoch 2573, Loss: 503.5199890136719, Neurons: 34, Grad norm: 6.319e+01\n",
      "Epoch 2573, Loss: 503.5199890136719, Neurons: 34, Grad norm: 6.319e+01\n",
      "Epoch 2574, Loss: 503.0555114746094, Neurons: 34, Grad norm: 6.309e+01\n",
      "Epoch 2574, Loss: 503.0555114746094, Neurons: 34, Grad norm: 6.309e+01\n",
      "Epoch 2575, Loss: 502.5892028808594, Neurons: 34, Grad norm: 6.299e+01\n",
      "Epoch 2575, Loss: 502.5892028808594, Neurons: 34, Grad norm: 6.299e+01\n",
      "Epoch 2576, Loss: 502.1209716796875, Neurons: 34, Grad norm: 6.289e+01\n",
      "Epoch 2576, Loss: 502.1209716796875, Neurons: 34, Grad norm: 6.289e+01\n",
      "Epoch 2577, Loss: 501.6509094238281, Neurons: 34, Grad norm: 6.279e+01\n",
      "Epoch 2577, Loss: 501.6509094238281, Neurons: 34, Grad norm: 6.279e+01\n",
      "Epoch 2578, Loss: 501.17901611328125, Neurons: 34, Grad norm: 6.270e+01\n",
      "Epoch 2578, Loss: 501.17901611328125, Neurons: 34, Grad norm: 6.270e+01\n",
      "Epoch 2579, Loss: 500.7052307128906, Neurons: 34, Grad norm: 6.260e+01\n",
      "Epoch 2579, Loss: 500.7052307128906, Neurons: 34, Grad norm: 6.260e+01\n",
      "Epoch 2580, Loss: 500.22967529296875, Neurons: 34, Grad norm: 6.250e+01\n",
      "Epoch 2580, Loss: 500.22967529296875, Neurons: 34, Grad norm: 6.250e+01\n",
      "Epoch 2581, Loss: 499.7523498535156, Neurons: 34, Grad norm: 6.241e+01\n",
      "Epoch 2581, Loss: 499.7523498535156, Neurons: 34, Grad norm: 6.241e+01\n",
      "Epoch 2582, Loss: 499.2731628417969, Neurons: 34, Grad norm: 6.231e+01\n",
      "Epoch 2582, Loss: 499.2731628417969, Neurons: 34, Grad norm: 6.231e+01\n",
      "Epoch 2583, Loss: 498.7921447753906, Neurons: 34, Grad norm: 6.221e+01\n",
      "Epoch 2583, Loss: 498.7921447753906, Neurons: 34, Grad norm: 6.221e+01\n",
      "Epoch 2584, Loss: 498.30938720703125, Neurons: 34, Grad norm: 6.212e+01\n",
      "Epoch 2584, Loss: 498.30938720703125, Neurons: 34, Grad norm: 6.212e+01\n",
      "Epoch 2585, Loss: 497.8248596191406, Neurons: 34, Grad norm: 6.202e+01\n",
      "Epoch 2585, Loss: 497.8248596191406, Neurons: 34, Grad norm: 6.202e+01\n",
      "Epoch 2586, Loss: 497.3385925292969, Neurons: 34, Grad norm: 6.193e+01\n",
      "Epoch 2586, Loss: 497.3385925292969, Neurons: 34, Grad norm: 6.193e+01\n",
      "Epoch 2587, Loss: 496.8504638671875, Neurons: 34, Grad norm: 6.184e+01\n",
      "Epoch 2587, Loss: 496.8504638671875, Neurons: 34, Grad norm: 6.184e+01\n",
      "Epoch 2588, Loss: 496.360595703125, Neurons: 34, Grad norm: 6.175e+01\n",
      "Epoch 2588, Loss: 496.360595703125, Neurons: 34, Grad norm: 6.175e+01\n",
      "Epoch 2589, Loss: 495.8689270019531, Neurons: 34, Grad norm: 6.166e+01\n",
      "Epoch 2589, Loss: 495.8689270019531, Neurons: 34, Grad norm: 6.166e+01\n",
      "Epoch 2590, Loss: 495.37548828125, Neurons: 34, Grad norm: 6.157e+01\n",
      "Epoch 2590, Loss: 495.37548828125, Neurons: 34, Grad norm: 6.157e+01\n",
      "Epoch 2591, Loss: 494.8802795410156, Neurons: 34, Grad norm: 6.148e+01\n",
      "Epoch 2591, Loss: 494.8802795410156, Neurons: 34, Grad norm: 6.148e+01\n",
      "Epoch 2592, Loss: 494.3832092285156, Neurons: 34, Grad norm: 6.139e+01\n",
      "Epoch 2592, Loss: 494.3832092285156, Neurons: 34, Grad norm: 6.139e+01\n",
      "Epoch 2593, Loss: 493.8844299316406, Neurons: 34, Grad norm: 6.131e+01\n",
      "Epoch 2593, Loss: 493.8844299316406, Neurons: 34, Grad norm: 6.131e+01\n",
      "Epoch 2594, Loss: 493.38385009765625, Neurons: 34, Grad norm: 6.122e+01\n",
      "Epoch 2594, Loss: 493.38385009765625, Neurons: 34, Grad norm: 6.122e+01\n",
      "Epoch 2595, Loss: 492.8813781738281, Neurons: 34, Grad norm: 6.114e+01\n",
      "Epoch 2595, Loss: 492.8813781738281, Neurons: 34, Grad norm: 6.114e+01\n",
      "Epoch 2596, Loss: 492.37713623046875, Neurons: 34, Grad norm: 6.105e+01\n",
      "Epoch 2596, Loss: 492.37713623046875, Neurons: 34, Grad norm: 6.105e+01\n",
      "Epoch 2597, Loss: 491.8711242675781, Neurons: 34, Grad norm: 6.097e+01\n",
      "Epoch 2597, Loss: 491.8711242675781, Neurons: 34, Grad norm: 6.097e+01\n",
      "Epoch 2598, Loss: 491.3632507324219, Neurons: 34, Grad norm: 6.089e+01\n",
      "Epoch 2598, Loss: 491.3632507324219, Neurons: 34, Grad norm: 6.089e+01\n",
      "Epoch 2599, Loss: 490.853515625, Neurons: 34, Grad norm: 6.081e+01\n",
      "Epoch 2599, Loss: 490.853515625, Neurons: 34, Grad norm: 6.081e+01\n",
      "Epoch 2599, Test loss: 491.22503662109375\n",
      "Epoch 2599, Test loss: 491.22503662109375\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "network shape updated to :[13, 21, 1]\n",
      "network shape updated to :[13, 21, 1]\n",
      "Epoch 2600, Loss: 489.89276123046875, Neurons: 35, Grad norm: 6.673e+01\n",
      "Epoch 2600, Loss: 489.89276123046875, Neurons: 35, Grad norm: 6.673e+01\n",
      "Epoch 2601, Loss: 489.7442626953125, Neurons: 35, Grad norm: 6.666e+01\n",
      "Epoch 2601, Loss: 489.7442626953125, Neurons: 35, Grad norm: 6.666e+01\n",
      "Epoch 2602, Loss: 489.5887756347656, Neurons: 35, Grad norm: 6.660e+01\n",
      "Epoch 2602, Loss: 489.5887756347656, Neurons: 35, Grad norm: 6.660e+01\n",
      "Epoch 2603, Loss: 489.4264831542969, Neurons: 35, Grad norm: 6.655e+01\n",
      "Epoch 2603, Loss: 489.4264831542969, Neurons: 35, Grad norm: 6.655e+01\n",
      "Epoch 2604, Loss: 489.25714111328125, Neurons: 35, Grad norm: 6.653e+01\n",
      "Epoch 2604, Loss: 489.25714111328125, Neurons: 35, Grad norm: 6.653e+01\n",
      "Epoch 2605, Loss: 489.0807189941406, Neurons: 35, Grad norm: 6.650e+01\n",
      "Epoch 2605, Loss: 489.0807189941406, Neurons: 35, Grad norm: 6.650e+01\n",
      "Epoch 2606, Loss: 488.89715576171875, Neurons: 35, Grad norm: 6.648e+01\n",
      "Epoch 2606, Loss: 488.89715576171875, Neurons: 35, Grad norm: 6.648e+01\n",
      "Epoch 2607, Loss: 488.706298828125, Neurons: 35, Grad norm: 6.644e+01\n",
      "Epoch 2607, Loss: 488.706298828125, Neurons: 35, Grad norm: 6.644e+01\n",
      "Epoch 2608, Loss: 488.5082702636719, Neurons: 35, Grad norm: 6.640e+01\n",
      "Epoch 2608, Loss: 488.5082702636719, Neurons: 35, Grad norm: 6.640e+01\n",
      "Epoch 2609, Loss: 488.3029479980469, Neurons: 35, Grad norm: 6.636e+01\n",
      "Epoch 2609, Loss: 488.3029479980469, Neurons: 35, Grad norm: 6.636e+01\n",
      "Epoch 2610, Loss: 488.0904846191406, Neurons: 35, Grad norm: 6.631e+01\n",
      "Epoch 2610, Loss: 488.0904846191406, Neurons: 35, Grad norm: 6.631e+01\n",
      "Epoch 2611, Loss: 487.87091064453125, Neurons: 35, Grad norm: 6.627e+01\n",
      "Epoch 2611, Loss: 487.87091064453125, Neurons: 35, Grad norm: 6.627e+01\n",
      "Epoch 2612, Loss: 487.64434814453125, Neurons: 35, Grad norm: 6.622e+01\n",
      "Epoch 2612, Loss: 487.64434814453125, Neurons: 35, Grad norm: 6.622e+01\n",
      "Epoch 2613, Loss: 487.4108581542969, Neurons: 35, Grad norm: 6.618e+01\n",
      "Epoch 2613, Loss: 487.4108581542969, Neurons: 35, Grad norm: 6.618e+01\n",
      "Epoch 2614, Loss: 487.170654296875, Neurons: 35, Grad norm: 6.614e+01\n",
      "Epoch 2614, Loss: 487.170654296875, Neurons: 35, Grad norm: 6.614e+01\n",
      "Epoch 2615, Loss: 486.92376708984375, Neurons: 35, Grad norm: 6.610e+01\n",
      "Epoch 2615, Loss: 486.92376708984375, Neurons: 35, Grad norm: 6.610e+01\n",
      "Epoch 2616, Loss: 486.67041015625, Neurons: 35, Grad norm: 6.606e+01\n",
      "Epoch 2616, Loss: 486.67041015625, Neurons: 35, Grad norm: 6.606e+01\n",
      "Epoch 2617, Loss: 486.4105529785156, Neurons: 35, Grad norm: 6.601e+01\n",
      "Epoch 2617, Loss: 486.4105529785156, Neurons: 35, Grad norm: 6.601e+01\n",
      "Epoch 2618, Loss: 486.1443786621094, Neurons: 35, Grad norm: 6.596e+01\n",
      "Epoch 2618, Loss: 486.1443786621094, Neurons: 35, Grad norm: 6.596e+01\n",
      "Epoch 2619, Loss: 485.87200927734375, Neurons: 35, Grad norm: 6.592e+01\n",
      "Epoch 2619, Loss: 485.87200927734375, Neurons: 35, Grad norm: 6.592e+01\n",
      "Epoch 2620, Loss: 485.59356689453125, Neurons: 35, Grad norm: 6.587e+01\n",
      "Epoch 2620, Loss: 485.59356689453125, Neurons: 35, Grad norm: 6.587e+01\n",
      "Epoch 2621, Loss: 485.30914306640625, Neurons: 35, Grad norm: 6.582e+01\n",
      "Epoch 2621, Loss: 485.30914306640625, Neurons: 35, Grad norm: 6.582e+01\n",
      "Epoch 2622, Loss: 485.0189514160156, Neurons: 35, Grad norm: 6.577e+01\n",
      "Epoch 2622, Loss: 485.0189514160156, Neurons: 35, Grad norm: 6.577e+01\n",
      "Epoch 2623, Loss: 484.7231140136719, Neurons: 35, Grad norm: 6.573e+01\n",
      "Epoch 2623, Loss: 484.7231140136719, Neurons: 35, Grad norm: 6.573e+01\n",
      "Epoch 2624, Loss: 484.4217529296875, Neurons: 35, Grad norm: 6.568e+01\n",
      "Epoch 2624, Loss: 484.4217529296875, Neurons: 35, Grad norm: 6.568e+01\n",
      "Epoch 2625, Loss: 484.1148986816406, Neurons: 35, Grad norm: 6.564e+01\n",
      "Epoch 2625, Loss: 484.1148986816406, Neurons: 35, Grad norm: 6.564e+01\n",
      "Epoch 2626, Loss: 483.8027648925781, Neurons: 35, Grad norm: 6.559e+01\n",
      "Epoch 2626, Loss: 483.8027648925781, Neurons: 35, Grad norm: 6.559e+01\n",
      "Epoch 2627, Loss: 483.4853210449219, Neurons: 35, Grad norm: 6.554e+01\n",
      "Epoch 2627, Loss: 483.4853210449219, Neurons: 35, Grad norm: 6.554e+01\n",
      "Epoch 2628, Loss: 483.162841796875, Neurons: 35, Grad norm: 6.550e+01\n",
      "Epoch 2628, Loss: 483.162841796875, Neurons: 35, Grad norm: 6.550e+01\n",
      "Epoch 2629, Loss: 482.8352966308594, Neurons: 35, Grad norm: 6.545e+01\n",
      "Epoch 2629, Loss: 482.8352966308594, Neurons: 35, Grad norm: 6.545e+01\n",
      "Epoch 2630, Loss: 482.50286865234375, Neurons: 35, Grad norm: 6.541e+01\n",
      "Epoch 2630, Loss: 482.50286865234375, Neurons: 35, Grad norm: 6.541e+01\n",
      "Epoch 2631, Loss: 482.1656188964844, Neurons: 35, Grad norm: 6.537e+01\n",
      "Epoch 2631, Loss: 482.1656188964844, Neurons: 35, Grad norm: 6.537e+01\n",
      "Epoch 2632, Loss: 481.8236389160156, Neurons: 35, Grad norm: 6.533e+01\n",
      "Epoch 2632, Loss: 481.8236389160156, Neurons: 35, Grad norm: 6.533e+01\n",
      "Epoch 2633, Loss: 481.47705078125, Neurons: 35, Grad norm: 6.528e+01\n",
      "Epoch 2633, Loss: 481.47705078125, Neurons: 35, Grad norm: 6.528e+01\n",
      "Epoch 2634, Loss: 481.1259460449219, Neurons: 35, Grad norm: 6.524e+01\n",
      "Epoch 2634, Loss: 481.1259460449219, Neurons: 35, Grad norm: 6.524e+01\n",
      "Epoch 2635, Loss: 480.7702941894531, Neurons: 35, Grad norm: 6.520e+01\n",
      "Epoch 2635, Loss: 480.7702941894531, Neurons: 35, Grad norm: 6.520e+01\n",
      "Epoch 2636, Loss: 480.4102478027344, Neurons: 35, Grad norm: 6.516e+01\n",
      "Epoch 2636, Loss: 480.4102478027344, Neurons: 35, Grad norm: 6.516e+01\n",
      "Epoch 2637, Loss: 480.0458679199219, Neurons: 35, Grad norm: 6.512e+01\n",
      "Epoch 2637, Loss: 480.0458679199219, Neurons: 35, Grad norm: 6.512e+01\n",
      "Epoch 2638, Loss: 479.67718505859375, Neurons: 35, Grad norm: 6.508e+01\n",
      "Epoch 2638, Loss: 479.67718505859375, Neurons: 35, Grad norm: 6.508e+01\n",
      "Epoch 2639, Loss: 479.30426025390625, Neurons: 35, Grad norm: 6.504e+01\n",
      "Epoch 2639, Loss: 479.30426025390625, Neurons: 35, Grad norm: 6.504e+01\n",
      "Epoch 2640, Loss: 478.9272155761719, Neurons: 35, Grad norm: 6.500e+01\n",
      "Epoch 2640, Loss: 478.9272155761719, Neurons: 35, Grad norm: 6.500e+01\n",
      "Epoch 2641, Loss: 478.54608154296875, Neurons: 35, Grad norm: 6.496e+01\n",
      "Epoch 2641, Loss: 478.54608154296875, Neurons: 35, Grad norm: 6.496e+01\n",
      "Epoch 2642, Loss: 478.16082763671875, Neurons: 35, Grad norm: 6.493e+01\n",
      "Epoch 2642, Loss: 478.16082763671875, Neurons: 35, Grad norm: 6.493e+01\n",
      "Epoch 2643, Loss: 477.7715759277344, Neurons: 35, Grad norm: 6.489e+01\n",
      "Epoch 2643, Loss: 477.7715759277344, Neurons: 35, Grad norm: 6.489e+01\n",
      "Epoch 2644, Loss: 477.3783874511719, Neurons: 35, Grad norm: 6.486e+01\n",
      "Epoch 2644, Loss: 477.3783874511719, Neurons: 35, Grad norm: 6.486e+01\n",
      "Epoch 2645, Loss: 476.98126220703125, Neurons: 35, Grad norm: 6.482e+01\n",
      "Epoch 2645, Loss: 476.98126220703125, Neurons: 35, Grad norm: 6.482e+01\n",
      "Epoch 2646, Loss: 476.5802001953125, Neurons: 35, Grad norm: 6.479e+01\n",
      "Epoch 2646, Loss: 476.5802001953125, Neurons: 35, Grad norm: 6.479e+01\n",
      "Epoch 2647, Loss: 476.1753234863281, Neurons: 35, Grad norm: 6.475e+01\n",
      "Epoch 2647, Loss: 476.1753234863281, Neurons: 35, Grad norm: 6.475e+01\n",
      "Epoch 2648, Loss: 475.76666259765625, Neurons: 35, Grad norm: 6.472e+01\n",
      "Epoch 2648, Loss: 475.76666259765625, Neurons: 35, Grad norm: 6.472e+01\n",
      "Epoch 2649, Loss: 475.3541564941406, Neurons: 35, Grad norm: 6.469e+01\n",
      "Epoch 2649, Loss: 475.3541564941406, Neurons: 35, Grad norm: 6.469e+01\n",
      "Epoch 2650, Loss: 474.9378967285156, Neurons: 35, Grad norm: 6.466e+01\n",
      "Epoch 2650, Loss: 474.9378967285156, Neurons: 35, Grad norm: 6.466e+01\n",
      "Epoch 2651, Loss: 474.51788330078125, Neurons: 35, Grad norm: 6.463e+01\n",
      "Epoch 2651, Loss: 474.51788330078125, Neurons: 35, Grad norm: 6.463e+01\n",
      "Epoch 2652, Loss: 474.0942077636719, Neurons: 35, Grad norm: 6.461e+01\n",
      "Epoch 2652, Loss: 474.0942077636719, Neurons: 35, Grad norm: 6.461e+01\n",
      "Epoch 2653, Loss: 473.6667785644531, Neurons: 35, Grad norm: 6.458e+01\n",
      "Epoch 2653, Loss: 473.6667785644531, Neurons: 35, Grad norm: 6.458e+01\n",
      "Epoch 2654, Loss: 473.23565673828125, Neurons: 35, Grad norm: 6.456e+01\n",
      "Epoch 2654, Loss: 473.23565673828125, Neurons: 35, Grad norm: 6.456e+01\n",
      "Epoch 2655, Loss: 472.8009338378906, Neurons: 35, Grad norm: 6.453e+01\n",
      "Epoch 2655, Loss: 472.8009338378906, Neurons: 35, Grad norm: 6.453e+01\n",
      "Epoch 2656, Loss: 472.3625183105469, Neurons: 35, Grad norm: 6.451e+01\n",
      "Epoch 2656, Loss: 472.3625183105469, Neurons: 35, Grad norm: 6.451e+01\n",
      "Epoch 2657, Loss: 471.9205322265625, Neurons: 35, Grad norm: 6.449e+01\n",
      "Epoch 2657, Loss: 471.9205322265625, Neurons: 35, Grad norm: 6.449e+01\n",
      "Epoch 2658, Loss: 471.47491455078125, Neurons: 35, Grad norm: 6.446e+01\n",
      "Epoch 2658, Loss: 471.47491455078125, Neurons: 35, Grad norm: 6.446e+01\n",
      "Epoch 2659, Loss: 471.02569580078125, Neurons: 35, Grad norm: 6.444e+01\n",
      "Epoch 2659, Loss: 471.02569580078125, Neurons: 35, Grad norm: 6.444e+01\n",
      "Epoch 2660, Loss: 470.5729064941406, Neurons: 35, Grad norm: 6.443e+01\n",
      "Epoch 2660, Loss: 470.5729064941406, Neurons: 35, Grad norm: 6.443e+01\n",
      "Epoch 2661, Loss: 470.11651611328125, Neurons: 35, Grad norm: 6.441e+01\n",
      "Epoch 2661, Loss: 470.11651611328125, Neurons: 35, Grad norm: 6.441e+01\n",
      "Epoch 2662, Loss: 469.6565246582031, Neurons: 35, Grad norm: 6.439e+01\n",
      "Epoch 2662, Loss: 469.6565246582031, Neurons: 35, Grad norm: 6.439e+01\n",
      "Epoch 2663, Loss: 469.1930236816406, Neurons: 35, Grad norm: 6.437e+01\n",
      "Epoch 2663, Loss: 469.1930236816406, Neurons: 35, Grad norm: 6.437e+01\n",
      "Epoch 2664, Loss: 468.72589111328125, Neurons: 35, Grad norm: 6.436e+01\n",
      "Epoch 2664, Loss: 468.72589111328125, Neurons: 35, Grad norm: 6.436e+01\n",
      "Epoch 2665, Loss: 468.25518798828125, Neurons: 35, Grad norm: 6.434e+01\n",
      "Epoch 2665, Loss: 468.25518798828125, Neurons: 35, Grad norm: 6.434e+01\n",
      "Epoch 2666, Loss: 467.7809143066406, Neurons: 35, Grad norm: 6.433e+01\n",
      "Epoch 2666, Loss: 467.7809143066406, Neurons: 35, Grad norm: 6.433e+01\n",
      "Epoch 2667, Loss: 467.3030700683594, Neurons: 35, Grad norm: 6.432e+01\n",
      "Epoch 2667, Loss: 467.3030700683594, Neurons: 35, Grad norm: 6.432e+01\n",
      "Epoch 2668, Loss: 466.82171630859375, Neurons: 35, Grad norm: 6.431e+01\n",
      "Epoch 2668, Loss: 466.82171630859375, Neurons: 35, Grad norm: 6.431e+01\n",
      "Epoch 2669, Loss: 466.33673095703125, Neurons: 35, Grad norm: 6.430e+01\n",
      "Epoch 2669, Loss: 466.33673095703125, Neurons: 35, Grad norm: 6.430e+01\n",
      "Epoch 2670, Loss: 465.84814453125, Neurons: 35, Grad norm: 6.429e+01\n",
      "Epoch 2670, Loss: 465.84814453125, Neurons: 35, Grad norm: 6.429e+01\n",
      "Epoch 2671, Loss: 465.35601806640625, Neurons: 35, Grad norm: 6.429e+01\n",
      "Epoch 2671, Loss: 465.35601806640625, Neurons: 35, Grad norm: 6.429e+01\n",
      "Epoch 2672, Loss: 464.8602294921875, Neurons: 35, Grad norm: 6.428e+01\n",
      "Epoch 2672, Loss: 464.8602294921875, Neurons: 35, Grad norm: 6.428e+01\n",
      "Epoch 2673, Loss: 464.36090087890625, Neurons: 35, Grad norm: 6.428e+01\n",
      "Epoch 2673, Loss: 464.36090087890625, Neurons: 35, Grad norm: 6.428e+01\n",
      "Epoch 2674, Loss: 463.85797119140625, Neurons: 35, Grad norm: 6.428e+01\n",
      "Epoch 2674, Loss: 463.85797119140625, Neurons: 35, Grad norm: 6.428e+01\n",
      "Epoch 2675, Loss: 463.35137939453125, Neurons: 35, Grad norm: 6.427e+01\n",
      "Epoch 2675, Loss: 463.35137939453125, Neurons: 35, Grad norm: 6.427e+01\n",
      "Epoch 2676, Loss: 462.8411560058594, Neurons: 35, Grad norm: 6.427e+01\n",
      "Epoch 2676, Loss: 462.8411560058594, Neurons: 35, Grad norm: 6.427e+01\n",
      "Epoch 2677, Loss: 462.3272705078125, Neurons: 35, Grad norm: 6.427e+01\n",
      "Epoch 2677, Loss: 462.3272705078125, Neurons: 35, Grad norm: 6.427e+01\n",
      "Epoch 2678, Loss: 461.80975341796875, Neurons: 35, Grad norm: 6.428e+01\n",
      "Epoch 2678, Loss: 461.80975341796875, Neurons: 35, Grad norm: 6.428e+01\n",
      "Epoch 2679, Loss: 461.28851318359375, Neurons: 35, Grad norm: 6.428e+01\n",
      "Epoch 2679, Loss: 461.28851318359375, Neurons: 35, Grad norm: 6.428e+01\n",
      "Epoch 2680, Loss: 460.76361083984375, Neurons: 35, Grad norm: 6.428e+01\n",
      "Epoch 2680, Loss: 460.76361083984375, Neurons: 35, Grad norm: 6.428e+01\n",
      "Epoch 2681, Loss: 460.2349853515625, Neurons: 35, Grad norm: 6.429e+01\n",
      "Epoch 2681, Loss: 460.2349853515625, Neurons: 35, Grad norm: 6.429e+01\n",
      "Epoch 2682, Loss: 459.70263671875, Neurons: 35, Grad norm: 6.430e+01\n",
      "Epoch 2682, Loss: 459.70263671875, Neurons: 35, Grad norm: 6.430e+01\n",
      "Epoch 2683, Loss: 459.1665344238281, Neurons: 35, Grad norm: 6.431e+01\n",
      "Epoch 2683, Loss: 459.1665344238281, Neurons: 35, Grad norm: 6.431e+01\n",
      "Epoch 2684, Loss: 458.62664794921875, Neurons: 35, Grad norm: 6.431e+01\n",
      "Epoch 2684, Loss: 458.62664794921875, Neurons: 35, Grad norm: 6.431e+01\n",
      "Epoch 2685, Loss: 458.0830078125, Neurons: 35, Grad norm: 6.433e+01\n",
      "Epoch 2685, Loss: 458.0830078125, Neurons: 35, Grad norm: 6.433e+01\n",
      "Epoch 2686, Loss: 457.5355224609375, Neurons: 35, Grad norm: 6.434e+01\n",
      "Epoch 2686, Loss: 457.5355224609375, Neurons: 35, Grad norm: 6.434e+01\n",
      "Epoch 2687, Loss: 456.9842224121094, Neurons: 35, Grad norm: 6.435e+01\n",
      "Epoch 2687, Loss: 456.9842224121094, Neurons: 35, Grad norm: 6.435e+01\n",
      "Epoch 2688, Loss: 456.42901611328125, Neurons: 35, Grad norm: 6.437e+01\n",
      "Epoch 2688, Loss: 456.42901611328125, Neurons: 35, Grad norm: 6.437e+01\n",
      "Epoch 2689, Loss: 455.8699035644531, Neurons: 35, Grad norm: 6.439e+01\n",
      "Epoch 2689, Loss: 455.8699035644531, Neurons: 35, Grad norm: 6.439e+01\n",
      "Epoch 2690, Loss: 455.306884765625, Neurons: 35, Grad norm: 6.440e+01\n",
      "Epoch 2690, Loss: 455.306884765625, Neurons: 35, Grad norm: 6.440e+01\n",
      "Epoch 2691, Loss: 454.7399597167969, Neurons: 35, Grad norm: 6.442e+01\n",
      "Epoch 2691, Loss: 454.7399597167969, Neurons: 35, Grad norm: 6.442e+01\n",
      "Epoch 2692, Loss: 454.16900634765625, Neurons: 35, Grad norm: 6.444e+01\n",
      "Epoch 2692, Loss: 454.16900634765625, Neurons: 35, Grad norm: 6.444e+01\n",
      "Epoch 2693, Loss: 453.5940856933594, Neurons: 35, Grad norm: 6.447e+01\n",
      "Epoch 2693, Loss: 453.5940856933594, Neurons: 35, Grad norm: 6.447e+01\n",
      "Epoch 2694, Loss: 453.01507568359375, Neurons: 35, Grad norm: 6.449e+01\n",
      "Epoch 2694, Loss: 453.01507568359375, Neurons: 35, Grad norm: 6.449e+01\n",
      "Epoch 2695, Loss: 452.4320068359375, Neurons: 35, Grad norm: 6.452e+01\n",
      "Epoch 2695, Loss: 452.4320068359375, Neurons: 35, Grad norm: 6.452e+01\n",
      "Epoch 2696, Loss: 451.8448791503906, Neurons: 35, Grad norm: 6.455e+01\n",
      "Epoch 2696, Loss: 451.8448791503906, Neurons: 35, Grad norm: 6.455e+01\n",
      "Epoch 2697, Loss: 451.2535705566406, Neurons: 35, Grad norm: 6.457e+01\n",
      "Epoch 2697, Loss: 451.2535705566406, Neurons: 35, Grad norm: 6.457e+01\n",
      "Epoch 2698, Loss: 450.6581115722656, Neurons: 35, Grad norm: 6.460e+01\n",
      "Epoch 2698, Loss: 450.6581115722656, Neurons: 35, Grad norm: 6.460e+01\n",
      "Epoch 2699, Loss: 450.0584716796875, Neurons: 35, Grad norm: 6.463e+01\n",
      "Epoch 2699, Loss: 450.0584716796875, Neurons: 35, Grad norm: 6.463e+01\n",
      "Epoch 2699, Test loss: 449.6422119140625\n",
      "Epoch 2699, Test loss: 449.6422119140625\n",
      "Added neuron to hidden layer 1 with activation tanh\n",
      "Added neuron to hidden layer 1 with activation tanh\n",
      "network shape updated to :[14, 21, 1]\n",
      "network shape updated to :[14, 21, 1]\n",
      "Epoch 2700, Loss: 449.4328308105469, Neurons: 36, Grad norm: 6.541e+01\n",
      "Epoch 2700, Loss: 449.4328308105469, Neurons: 36, Grad norm: 6.541e+01\n",
      "Epoch 2701, Loss: 449.2934875488281, Neurons: 36, Grad norm: 6.525e+01\n",
      "Epoch 2701, Loss: 449.2934875488281, Neurons: 36, Grad norm: 6.525e+01\n",
      "Epoch 2702, Loss: 449.14520263671875, Neurons: 36, Grad norm: 6.531e+01\n",
      "Epoch 2702, Loss: 449.14520263671875, Neurons: 36, Grad norm: 6.531e+01\n",
      "Epoch 2703, Loss: 448.9913330078125, Neurons: 36, Grad norm: 6.527e+01\n",
      "Epoch 2703, Loss: 448.9913330078125, Neurons: 36, Grad norm: 6.527e+01\n",
      "Epoch 2704, Loss: 448.8296813964844, Neurons: 36, Grad norm: 6.520e+01\n",
      "Epoch 2704, Loss: 448.8296813964844, Neurons: 36, Grad norm: 6.520e+01\n",
      "Epoch 2705, Loss: 448.66070556640625, Neurons: 36, Grad norm: 6.521e+01\n",
      "Epoch 2705, Loss: 448.66070556640625, Neurons: 36, Grad norm: 6.521e+01\n",
      "Epoch 2706, Loss: 448.4849853515625, Neurons: 36, Grad norm: 6.523e+01\n",
      "Epoch 2706, Loss: 448.4849853515625, Neurons: 36, Grad norm: 6.523e+01\n",
      "Epoch 2707, Loss: 448.3019104003906, Neurons: 36, Grad norm: 6.521e+01\n",
      "Epoch 2707, Loss: 448.3019104003906, Neurons: 36, Grad norm: 6.521e+01\n",
      "Epoch 2708, Loss: 448.11114501953125, Neurons: 36, Grad norm: 6.518e+01\n",
      "Epoch 2708, Loss: 448.11114501953125, Neurons: 36, Grad norm: 6.518e+01\n",
      "Epoch 2709, Loss: 447.9132385253906, Neurons: 36, Grad norm: 6.519e+01\n",
      "Epoch 2709, Loss: 447.9132385253906, Neurons: 36, Grad norm: 6.519e+01\n",
      "Epoch 2710, Loss: 447.70843505859375, Neurons: 36, Grad norm: 6.520e+01\n",
      "Epoch 2710, Loss: 447.70843505859375, Neurons: 36, Grad norm: 6.520e+01\n",
      "Epoch 2711, Loss: 447.4965515136719, Neurons: 36, Grad norm: 6.517e+01\n",
      "Epoch 2711, Loss: 447.4965515136719, Neurons: 36, Grad norm: 6.517e+01\n",
      "Epoch 2712, Loss: 447.2774353027344, Neurons: 36, Grad norm: 6.515e+01\n",
      "Epoch 2712, Loss: 447.2774353027344, Neurons: 36, Grad norm: 6.515e+01\n",
      "Epoch 2713, Loss: 447.05133056640625, Neurons: 36, Grad norm: 6.514e+01\n",
      "Epoch 2713, Loss: 447.05133056640625, Neurons: 36, Grad norm: 6.514e+01\n",
      "Epoch 2714, Loss: 446.8185119628906, Neurons: 36, Grad norm: 6.514e+01\n",
      "Epoch 2714, Loss: 446.8185119628906, Neurons: 36, Grad norm: 6.514e+01\n",
      "Epoch 2715, Loss: 446.5789794921875, Neurons: 36, Grad norm: 6.512e+01\n",
      "Epoch 2715, Loss: 446.5789794921875, Neurons: 36, Grad norm: 6.512e+01\n",
      "Epoch 2716, Loss: 446.3326416015625, Neurons: 36, Grad norm: 6.510e+01\n",
      "Epoch 2716, Loss: 446.3326416015625, Neurons: 36, Grad norm: 6.510e+01\n",
      "Epoch 2717, Loss: 446.07965087890625, Neurons: 36, Grad norm: 6.510e+01\n",
      "Epoch 2717, Loss: 446.07965087890625, Neurons: 36, Grad norm: 6.510e+01\n",
      "Epoch 2718, Loss: 445.82025146484375, Neurons: 36, Grad norm: 6.510e+01\n",
      "Epoch 2718, Loss: 445.82025146484375, Neurons: 36, Grad norm: 6.510e+01\n",
      "Epoch 2719, Loss: 445.5545349121094, Neurons: 36, Grad norm: 6.509e+01\n",
      "Epoch 2719, Loss: 445.5545349121094, Neurons: 36, Grad norm: 6.509e+01\n",
      "Epoch 2720, Loss: 445.2824401855469, Neurons: 36, Grad norm: 6.508e+01\n",
      "Epoch 2720, Loss: 445.2824401855469, Neurons: 36, Grad norm: 6.508e+01\n",
      "Epoch 2721, Loss: 445.0041809082031, Neurons: 36, Grad norm: 6.507e+01\n",
      "Epoch 2721, Loss: 445.0041809082031, Neurons: 36, Grad norm: 6.507e+01\n",
      "Epoch 2722, Loss: 444.71990966796875, Neurons: 36, Grad norm: 6.507e+01\n",
      "Epoch 2722, Loss: 444.71990966796875, Neurons: 36, Grad norm: 6.507e+01\n",
      "Epoch 2723, Loss: 444.4297180175781, Neurons: 36, Grad norm: 6.505e+01\n",
      "Epoch 2723, Loss: 444.4297180175781, Neurons: 36, Grad norm: 6.505e+01\n",
      "Epoch 2724, Loss: 444.1335144042969, Neurons: 36, Grad norm: 6.504e+01\n",
      "Epoch 2724, Loss: 444.1335144042969, Neurons: 36, Grad norm: 6.504e+01\n",
      "Epoch 2725, Loss: 443.8315734863281, Neurons: 36, Grad norm: 6.503e+01\n",
      "Epoch 2725, Loss: 443.8315734863281, Neurons: 36, Grad norm: 6.503e+01\n",
      "Epoch 2726, Loss: 443.52398681640625, Neurons: 36, Grad norm: 6.502e+01\n",
      "Epoch 2726, Loss: 443.52398681640625, Neurons: 36, Grad norm: 6.502e+01\n",
      "Epoch 2727, Loss: 443.2108459472656, Neurons: 36, Grad norm: 6.501e+01\n",
      "Epoch 2727, Loss: 443.2108459472656, Neurons: 36, Grad norm: 6.501e+01\n",
      "Epoch 2728, Loss: 442.89215087890625, Neurons: 36, Grad norm: 6.500e+01\n",
      "Epoch 2728, Loss: 442.89215087890625, Neurons: 36, Grad norm: 6.500e+01\n",
      "Epoch 2729, Loss: 442.5680236816406, Neurons: 36, Grad norm: 6.500e+01\n",
      "Epoch 2729, Loss: 442.5680236816406, Neurons: 36, Grad norm: 6.500e+01\n",
      "Epoch 2730, Loss: 442.23858642578125, Neurons: 36, Grad norm: 6.500e+01\n",
      "Epoch 2730, Loss: 442.23858642578125, Neurons: 36, Grad norm: 6.500e+01\n",
      "Epoch 2731, Loss: 441.9039001464844, Neurons: 36, Grad norm: 6.499e+01\n",
      "Epoch 2731, Loss: 441.9039001464844, Neurons: 36, Grad norm: 6.499e+01\n",
      "Epoch 2732, Loss: 441.5639953613281, Neurons: 36, Grad norm: 6.499e+01\n",
      "Epoch 2732, Loss: 441.5639953613281, Neurons: 36, Grad norm: 6.499e+01\n",
      "Epoch 2733, Loss: 441.218994140625, Neurons: 36, Grad norm: 6.499e+01\n",
      "Epoch 2733, Loss: 441.218994140625, Neurons: 36, Grad norm: 6.499e+01\n",
      "Epoch 2734, Loss: 440.8689270019531, Neurons: 36, Grad norm: 6.498e+01\n",
      "Epoch 2734, Loss: 440.8689270019531, Neurons: 36, Grad norm: 6.498e+01\n",
      "Epoch 2735, Loss: 440.5138854980469, Neurons: 36, Grad norm: 6.497e+01\n",
      "Epoch 2735, Loss: 440.5138854980469, Neurons: 36, Grad norm: 6.497e+01\n",
      "Epoch 2736, Loss: 440.1539001464844, Neurons: 36, Grad norm: 6.497e+01\n",
      "Epoch 2736, Loss: 440.1539001464844, Neurons: 36, Grad norm: 6.497e+01\n",
      "Epoch 2737, Loss: 439.7890319824219, Neurons: 36, Grad norm: 6.497e+01\n",
      "Epoch 2737, Loss: 439.7890319824219, Neurons: 36, Grad norm: 6.497e+01\n",
      "Epoch 2738, Loss: 439.4193420410156, Neurons: 36, Grad norm: 6.497e+01\n",
      "Epoch 2738, Loss: 439.4193420410156, Neurons: 36, Grad norm: 6.497e+01\n",
      "Epoch 2739, Loss: 439.0448303222656, Neurons: 36, Grad norm: 6.497e+01\n",
      "Epoch 2739, Loss: 439.0448303222656, Neurons: 36, Grad norm: 6.497e+01\n",
      "Epoch 2740, Loss: 438.66558837890625, Neurons: 36, Grad norm: 6.497e+01\n",
      "Epoch 2740, Loss: 438.66558837890625, Neurons: 36, Grad norm: 6.497e+01\n",
      "Epoch 2741, Loss: 438.2816467285156, Neurons: 36, Grad norm: 6.497e+01\n",
      "Epoch 2741, Loss: 438.2816467285156, Neurons: 36, Grad norm: 6.497e+01\n",
      "Epoch 2742, Loss: 437.8930969238281, Neurons: 36, Grad norm: 6.497e+01\n",
      "Epoch 2742, Loss: 437.8930969238281, Neurons: 36, Grad norm: 6.497e+01\n",
      "Epoch 2743, Loss: 437.4998474121094, Neurons: 36, Grad norm: 6.498e+01\n",
      "Epoch 2743, Loss: 437.4998474121094, Neurons: 36, Grad norm: 6.498e+01\n",
      "Epoch 2744, Loss: 437.1020202636719, Neurons: 36, Grad norm: 6.498e+01\n",
      "Epoch 2744, Loss: 437.1020202636719, Neurons: 36, Grad norm: 6.498e+01\n",
      "Epoch 2745, Loss: 436.6996154785156, Neurons: 36, Grad norm: 6.498e+01\n",
      "Epoch 2745, Loss: 436.6996154785156, Neurons: 36, Grad norm: 6.498e+01\n",
      "Epoch 2746, Loss: 436.2926330566406, Neurons: 36, Grad norm: 6.499e+01\n",
      "Epoch 2746, Loss: 436.2926330566406, Neurons: 36, Grad norm: 6.499e+01\n",
      "Epoch 2747, Loss: 435.8811340332031, Neurons: 36, Grad norm: 6.499e+01\n",
      "Epoch 2747, Loss: 435.8811340332031, Neurons: 36, Grad norm: 6.499e+01\n",
      "Epoch 2748, Loss: 435.46514892578125, Neurons: 36, Grad norm: 6.500e+01\n",
      "Epoch 2748, Loss: 435.46514892578125, Neurons: 36, Grad norm: 6.500e+01\n",
      "Epoch 2749, Loss: 435.04461669921875, Neurons: 36, Grad norm: 6.501e+01\n",
      "Epoch 2749, Loss: 435.04461669921875, Neurons: 36, Grad norm: 6.501e+01\n",
      "Epoch 2750, Loss: 434.6196594238281, Neurons: 36, Grad norm: 6.502e+01\n",
      "Epoch 2750, Loss: 434.6196594238281, Neurons: 36, Grad norm: 6.502e+01\n",
      "Epoch 2751, Loss: 434.19024658203125, Neurons: 36, Grad norm: 6.503e+01\n",
      "Epoch 2751, Loss: 434.19024658203125, Neurons: 36, Grad norm: 6.503e+01\n",
      "Epoch 2752, Loss: 433.75634765625, Neurons: 36, Grad norm: 6.504e+01\n",
      "Epoch 2752, Loss: 433.75634765625, Neurons: 36, Grad norm: 6.504e+01\n",
      "Epoch 2753, Loss: 433.3180236816406, Neurons: 36, Grad norm: 6.504e+01\n",
      "Epoch 2753, Loss: 433.3180236816406, Neurons: 36, Grad norm: 6.504e+01\n",
      "Epoch 2754, Loss: 432.8752136230469, Neurons: 36, Grad norm: 6.506e+01\n",
      "Epoch 2754, Loss: 432.8752136230469, Neurons: 36, Grad norm: 6.506e+01\n",
      "Epoch 2755, Loss: 432.42791748046875, Neurons: 36, Grad norm: 6.507e+01\n",
      "Epoch 2755, Loss: 432.42791748046875, Neurons: 36, Grad norm: 6.507e+01\n",
      "Epoch 2756, Loss: 431.9761962890625, Neurons: 36, Grad norm: 6.508e+01\n",
      "Epoch 2756, Loss: 431.9761962890625, Neurons: 36, Grad norm: 6.508e+01\n",
      "Epoch 2757, Loss: 431.51995849609375, Neurons: 36, Grad norm: 6.510e+01\n",
      "Epoch 2757, Loss: 431.51995849609375, Neurons: 36, Grad norm: 6.510e+01\n",
      "Epoch 2758, Loss: 431.0592041015625, Neurons: 36, Grad norm: 6.512e+01\n",
      "Epoch 2758, Loss: 431.0592041015625, Neurons: 36, Grad norm: 6.512e+01\n",
      "Epoch 2759, Loss: 430.5939636230469, Neurons: 36, Grad norm: 6.514e+01\n",
      "Epoch 2759, Loss: 430.5939636230469, Neurons: 36, Grad norm: 6.514e+01\n",
      "Epoch 2760, Loss: 430.1241149902344, Neurons: 36, Grad norm: 6.515e+01\n",
      "Epoch 2760, Loss: 430.1241149902344, Neurons: 36, Grad norm: 6.515e+01\n",
      "Epoch 2761, Loss: 429.6497802734375, Neurons: 36, Grad norm: 6.518e+01\n",
      "Epoch 2761, Loss: 429.6497802734375, Neurons: 36, Grad norm: 6.518e+01\n",
      "Epoch 2762, Loss: 429.1708984375, Neurons: 36, Grad norm: 6.520e+01\n",
      "Epoch 2762, Loss: 429.1708984375, Neurons: 36, Grad norm: 6.520e+01\n",
      "Epoch 2763, Loss: 428.6874084472656, Neurons: 36, Grad norm: 6.522e+01\n",
      "Epoch 2763, Loss: 428.6874084472656, Neurons: 36, Grad norm: 6.522e+01\n",
      "Epoch 2764, Loss: 428.19921875, Neurons: 36, Grad norm: 6.525e+01\n",
      "Epoch 2764, Loss: 428.19921875, Neurons: 36, Grad norm: 6.525e+01\n",
      "Epoch 2765, Loss: 427.7063293457031, Neurons: 36, Grad norm: 6.527e+01\n",
      "Epoch 2765, Loss: 427.7063293457031, Neurons: 36, Grad norm: 6.527e+01\n",
      "Epoch 2766, Loss: 427.2087707519531, Neurons: 36, Grad norm: 6.530e+01\n",
      "Epoch 2766, Loss: 427.2087707519531, Neurons: 36, Grad norm: 6.530e+01\n",
      "Epoch 2767, Loss: 426.7064514160156, Neurons: 36, Grad norm: 6.533e+01\n",
      "Epoch 2767, Loss: 426.7064514160156, Neurons: 36, Grad norm: 6.533e+01\n",
      "Epoch 2768, Loss: 426.1994323730469, Neurons: 36, Grad norm: 6.536e+01\n",
      "Epoch 2768, Loss: 426.1994323730469, Neurons: 36, Grad norm: 6.536e+01\n",
      "Epoch 2769, Loss: 425.68756103515625, Neurons: 36, Grad norm: 6.539e+01\n",
      "Epoch 2769, Loss: 425.68756103515625, Neurons: 36, Grad norm: 6.539e+01\n",
      "Epoch 2770, Loss: 425.1707458496094, Neurons: 36, Grad norm: 6.543e+01\n",
      "Epoch 2770, Loss: 425.1707458496094, Neurons: 36, Grad norm: 6.543e+01\n",
      "Epoch 2771, Loss: 424.6490173339844, Neurons: 36, Grad norm: 6.546e+01\n",
      "Epoch 2771, Loss: 424.6490173339844, Neurons: 36, Grad norm: 6.546e+01\n",
      "Epoch 2772, Loss: 424.12237548828125, Neurons: 36, Grad norm: 6.550e+01\n",
      "Epoch 2772, Loss: 424.12237548828125, Neurons: 36, Grad norm: 6.550e+01\n",
      "Epoch 2773, Loss: 423.590576171875, Neurons: 36, Grad norm: 6.554e+01\n",
      "Epoch 2773, Loss: 423.590576171875, Neurons: 36, Grad norm: 6.554e+01\n",
      "Epoch 2774, Loss: 423.0537109375, Neurons: 36, Grad norm: 6.557e+01\n",
      "Epoch 2774, Loss: 423.0537109375, Neurons: 36, Grad norm: 6.557e+01\n",
      "Epoch 2775, Loss: 422.51171875, Neurons: 36, Grad norm: 6.562e+01\n",
      "Epoch 2775, Loss: 422.51171875, Neurons: 36, Grad norm: 6.562e+01\n",
      "Epoch 2776, Loss: 421.964599609375, Neurons: 36, Grad norm: 6.566e+01\n",
      "Epoch 2776, Loss: 421.964599609375, Neurons: 36, Grad norm: 6.566e+01\n",
      "Epoch 2777, Loss: 421.4122009277344, Neurons: 36, Grad norm: 6.570e+01\n",
      "Epoch 2777, Loss: 421.4122009277344, Neurons: 36, Grad norm: 6.570e+01\n",
      "Epoch 2778, Loss: 420.8545837402344, Neurons: 36, Grad norm: 6.575e+01\n",
      "Epoch 2778, Loss: 420.8545837402344, Neurons: 36, Grad norm: 6.575e+01\n",
      "Epoch 2779, Loss: 420.2915344238281, Neurons: 36, Grad norm: 6.579e+01\n",
      "Epoch 2779, Loss: 420.2915344238281, Neurons: 36, Grad norm: 6.579e+01\n",
      "Epoch 2780, Loss: 419.72296142578125, Neurons: 36, Grad norm: 6.584e+01\n",
      "Epoch 2780, Loss: 419.72296142578125, Neurons: 36, Grad norm: 6.584e+01\n",
      "Epoch 2781, Loss: 419.14892578125, Neurons: 36, Grad norm: 6.589e+01\n",
      "Epoch 2781, Loss: 419.14892578125, Neurons: 36, Grad norm: 6.589e+01\n",
      "Epoch 2782, Loss: 418.56927490234375, Neurons: 36, Grad norm: 6.594e+01\n",
      "Epoch 2782, Loss: 418.56927490234375, Neurons: 36, Grad norm: 6.594e+01\n",
      "Epoch 2783, Loss: 417.9840087890625, Neurons: 36, Grad norm: 6.600e+01\n",
      "Epoch 2783, Loss: 417.9840087890625, Neurons: 36, Grad norm: 6.600e+01\n",
      "Epoch 2784, Loss: 417.39300537109375, Neurons: 36, Grad norm: 6.606e+01\n",
      "Epoch 2784, Loss: 417.39300537109375, Neurons: 36, Grad norm: 6.606e+01\n",
      "Epoch 2785, Loss: 416.7961730957031, Neurons: 36, Grad norm: 6.612e+01\n",
      "Epoch 2785, Loss: 416.7961730957031, Neurons: 36, Grad norm: 6.612e+01\n",
      "Epoch 2786, Loss: 416.19342041015625, Neurons: 36, Grad norm: 6.618e+01\n",
      "Epoch 2786, Loss: 416.19342041015625, Neurons: 36, Grad norm: 6.618e+01\n",
      "Epoch 2787, Loss: 415.58477783203125, Neurons: 36, Grad norm: 6.624e+01\n",
      "Epoch 2787, Loss: 415.58477783203125, Neurons: 36, Grad norm: 6.624e+01\n",
      "Epoch 2788, Loss: 414.9700927734375, Neurons: 36, Grad norm: 6.630e+01\n",
      "Epoch 2788, Loss: 414.9700927734375, Neurons: 36, Grad norm: 6.630e+01\n",
      "Epoch 2789, Loss: 414.3492736816406, Neurons: 36, Grad norm: 6.636e+01\n",
      "Epoch 2789, Loss: 414.3492736816406, Neurons: 36, Grad norm: 6.636e+01\n",
      "Epoch 2790, Loss: 413.7222595214844, Neurons: 36, Grad norm: 6.643e+01\n",
      "Epoch 2790, Loss: 413.7222595214844, Neurons: 36, Grad norm: 6.643e+01\n",
      "Epoch 2791, Loss: 413.0890808105469, Neurons: 36, Grad norm: 6.649e+01\n",
      "Epoch 2791, Loss: 413.0890808105469, Neurons: 36, Grad norm: 6.649e+01\n",
      "Epoch 2792, Loss: 412.4496765136719, Neurons: 36, Grad norm: 6.656e+01\n",
      "Epoch 2792, Loss: 412.4496765136719, Neurons: 36, Grad norm: 6.656e+01\n",
      "Epoch 2793, Loss: 411.8038330078125, Neurons: 36, Grad norm: 6.663e+01\n",
      "Epoch 2793, Loss: 411.8038330078125, Neurons: 36, Grad norm: 6.663e+01\n",
      "Epoch 2794, Loss: 411.1515197753906, Neurons: 36, Grad norm: 6.670e+01\n",
      "Epoch 2794, Loss: 411.1515197753906, Neurons: 36, Grad norm: 6.670e+01\n",
      "Epoch 2795, Loss: 410.4927978515625, Neurons: 36, Grad norm: 6.677e+01\n",
      "Epoch 2795, Loss: 410.4927978515625, Neurons: 36, Grad norm: 6.677e+01\n",
      "Epoch 2796, Loss: 409.827392578125, Neurons: 36, Grad norm: 6.685e+01\n",
      "Epoch 2796, Loss: 409.827392578125, Neurons: 36, Grad norm: 6.685e+01\n",
      "Epoch 2797, Loss: 409.15533447265625, Neurons: 36, Grad norm: 6.692e+01\n",
      "Epoch 2797, Loss: 409.15533447265625, Neurons: 36, Grad norm: 6.692e+01\n",
      "Epoch 2798, Loss: 408.47637939453125, Neurons: 36, Grad norm: 6.700e+01\n",
      "Epoch 2798, Loss: 408.47637939453125, Neurons: 36, Grad norm: 6.700e+01\n",
      "Epoch 2799, Loss: 407.7906799316406, Neurons: 36, Grad norm: 6.708e+01\n",
      "Epoch 2799, Loss: 407.7906799316406, Neurons: 36, Grad norm: 6.708e+01\n",
      "Epoch 2799, Test loss: 406.6653747558594\n",
      "Epoch 2799, Test loss: 406.6653747558594\n",
      "Added neuron to hidden layer 1 with activation relu\n",
      "Added neuron to hidden layer 1 with activation relu\n",
      "network shape updated to :[15, 21, 1]\n",
      "network shape updated to :[15, 21, 1]\n",
      "Epoch 2800, Loss: 419.02362060546875, Neurons: 37, Grad norm: 1.507e+02\n",
      "Epoch 2800, Loss: 419.02362060546875, Neurons: 37, Grad norm: 1.507e+02\n",
      "Epoch 2801, Loss: 418.5790710449219, Neurons: 37, Grad norm: 1.485e+02\n",
      "Epoch 2801, Loss: 418.5790710449219, Neurons: 37, Grad norm: 1.485e+02\n",
      "Epoch 2802, Loss: 418.1175231933594, Neurons: 37, Grad norm: 1.465e+02\n",
      "Epoch 2802, Loss: 418.1175231933594, Neurons: 37, Grad norm: 1.465e+02\n",
      "Epoch 2803, Loss: 417.6389465332031, Neurons: 37, Grad norm: 1.445e+02\n",
      "Epoch 2803, Loss: 417.6389465332031, Neurons: 37, Grad norm: 1.445e+02\n",
      "Epoch 2804, Loss: 417.1441955566406, Neurons: 37, Grad norm: 1.425e+02\n",
      "Epoch 2804, Loss: 417.1441955566406, Neurons: 37, Grad norm: 1.425e+02\n",
      "Epoch 2805, Loss: 416.6340637207031, Neurons: 37, Grad norm: 1.405e+02\n",
      "Epoch 2805, Loss: 416.6340637207031, Neurons: 37, Grad norm: 1.405e+02\n",
      "Epoch 2806, Loss: 416.1094665527344, Neurons: 37, Grad norm: 1.384e+02\n",
      "Epoch 2806, Loss: 416.1094665527344, Neurons: 37, Grad norm: 1.384e+02\n",
      "Epoch 2807, Loss: 415.5713806152344, Neurons: 37, Grad norm: 1.364e+02\n",
      "Epoch 2807, Loss: 415.5713806152344, Neurons: 37, Grad norm: 1.364e+02\n",
      "Epoch 2808, Loss: 415.0208435058594, Neurons: 37, Grad norm: 1.345e+02\n",
      "Epoch 2808, Loss: 415.0208435058594, Neurons: 37, Grad norm: 1.345e+02\n",
      "Epoch 2809, Loss: 414.4589538574219, Neurons: 37, Grad norm: 1.327e+02\n",
      "Epoch 2809, Loss: 414.4589538574219, Neurons: 37, Grad norm: 1.327e+02\n",
      "Epoch 2810, Loss: 413.88671875, Neurons: 37, Grad norm: 1.309e+02\n",
      "Epoch 2810, Loss: 413.88671875, Neurons: 37, Grad norm: 1.309e+02\n",
      "Epoch 2811, Loss: 413.30517578125, Neurons: 37, Grad norm: 1.291e+02\n",
      "Epoch 2811, Loss: 413.30517578125, Neurons: 37, Grad norm: 1.291e+02\n",
      "Epoch 2812, Loss: 412.7152404785156, Neurons: 37, Grad norm: 1.275e+02\n",
      "Epoch 2812, Loss: 412.7152404785156, Neurons: 37, Grad norm: 1.275e+02\n",
      "Epoch 2813, Loss: 412.1179504394531, Neurons: 37, Grad norm: 1.258e+02\n",
      "Epoch 2813, Loss: 412.1179504394531, Neurons: 37, Grad norm: 1.258e+02\n",
      "Epoch 2814, Loss: 411.5141296386719, Neurons: 37, Grad norm: 1.242e+02\n",
      "Epoch 2814, Loss: 411.5141296386719, Neurons: 37, Grad norm: 1.242e+02\n",
      "Epoch 2815, Loss: 410.90484619140625, Neurons: 37, Grad norm: 1.225e+02\n",
      "Epoch 2815, Loss: 410.90484619140625, Neurons: 37, Grad norm: 1.225e+02\n",
      "Epoch 2816, Loss: 410.29107666015625, Neurons: 37, Grad norm: 1.209e+02\n",
      "Epoch 2816, Loss: 410.29107666015625, Neurons: 37, Grad norm: 1.209e+02\n",
      "Epoch 2817, Loss: 409.6739807128906, Neurons: 37, Grad norm: 1.192e+02\n",
      "Epoch 2817, Loss: 409.6739807128906, Neurons: 37, Grad norm: 1.192e+02\n",
      "Epoch 2818, Loss: 409.05450439453125, Neurons: 37, Grad norm: 1.175e+02\n",
      "Epoch 2818, Loss: 409.05450439453125, Neurons: 37, Grad norm: 1.175e+02\n",
      "Epoch 2819, Loss: 408.43377685546875, Neurons: 37, Grad norm: 1.158e+02\n",
      "Epoch 2819, Loss: 408.43377685546875, Neurons: 37, Grad norm: 1.158e+02\n",
      "Epoch 2820, Loss: 407.8127746582031, Neurons: 37, Grad norm: 1.142e+02\n",
      "Epoch 2820, Loss: 407.8127746582031, Neurons: 37, Grad norm: 1.142e+02\n",
      "Epoch 2821, Loss: 407.1925354003906, Neurons: 37, Grad norm: 1.126e+02\n",
      "Epoch 2821, Loss: 407.1925354003906, Neurons: 37, Grad norm: 1.126e+02\n",
      "Epoch 2822, Loss: 406.57373046875, Neurons: 37, Grad norm: 1.109e+02\n",
      "Epoch 2822, Loss: 406.57373046875, Neurons: 37, Grad norm: 1.109e+02\n",
      "Epoch 2823, Loss: 405.9573059082031, Neurons: 37, Grad norm: 1.093e+02\n",
      "Epoch 2823, Loss: 405.9573059082031, Neurons: 37, Grad norm: 1.093e+02\n",
      "Epoch 2824, Loss: 405.3437805175781, Neurons: 37, Grad norm: 1.077e+02\n",
      "Epoch 2824, Loss: 405.3437805175781, Neurons: 37, Grad norm: 1.077e+02\n",
      "Epoch 2825, Loss: 404.7336730957031, Neurons: 37, Grad norm: 1.062e+02\n",
      "Epoch 2825, Loss: 404.7336730957031, Neurons: 37, Grad norm: 1.062e+02\n",
      "Epoch 2826, Loss: 404.1274108886719, Neurons: 37, Grad norm: 1.046e+02\n",
      "Epoch 2826, Loss: 404.1274108886719, Neurons: 37, Grad norm: 1.046e+02\n",
      "Epoch 2827, Loss: 403.5252685546875, Neurons: 37, Grad norm: 1.031e+02\n",
      "Epoch 2827, Loss: 403.5252685546875, Neurons: 37, Grad norm: 1.031e+02\n",
      "Epoch 2828, Loss: 402.9278259277344, Neurons: 37, Grad norm: 1.016e+02\n",
      "Epoch 2828, Loss: 402.9278259277344, Neurons: 37, Grad norm: 1.016e+02\n",
      "Epoch 2829, Loss: 402.33544921875, Neurons: 37, Grad norm: 1.001e+02\n",
      "Epoch 2829, Loss: 402.33544921875, Neurons: 37, Grad norm: 1.001e+02\n",
      "Epoch 2830, Loss: 401.7481689453125, Neurons: 37, Grad norm: 9.870e+01\n",
      "Epoch 2830, Loss: 401.7481689453125, Neurons: 37, Grad norm: 9.870e+01\n",
      "Epoch 2831, Loss: 401.16619873046875, Neurons: 37, Grad norm: 9.722e+01\n",
      "Epoch 2831, Loss: 401.16619873046875, Neurons: 37, Grad norm: 9.722e+01\n",
      "Epoch 2832, Loss: 400.58990478515625, Neurons: 37, Grad norm: 9.579e+01\n",
      "Epoch 2832, Loss: 400.58990478515625, Neurons: 37, Grad norm: 9.579e+01\n",
      "Epoch 2833, Loss: 400.01953125, Neurons: 37, Grad norm: 9.448e+01\n",
      "Epoch 2833, Loss: 400.01953125, Neurons: 37, Grad norm: 9.448e+01\n",
      "Epoch 2834, Loss: 399.45501708984375, Neurons: 37, Grad norm: 9.325e+01\n",
      "Epoch 2834, Loss: 399.45501708984375, Neurons: 37, Grad norm: 9.325e+01\n",
      "Epoch 2835, Loss: 398.8960266113281, Neurons: 37, Grad norm: 9.196e+01\n",
      "Epoch 2835, Loss: 398.8960266113281, Neurons: 37, Grad norm: 9.196e+01\n",
      "Epoch 2836, Loss: 398.3426818847656, Neurons: 37, Grad norm: 9.072e+01\n",
      "Epoch 2836, Loss: 398.3426818847656, Neurons: 37, Grad norm: 9.072e+01\n",
      "Epoch 2837, Loss: 397.794921875, Neurons: 37, Grad norm: 8.954e+01\n",
      "Epoch 2837, Loss: 397.794921875, Neurons: 37, Grad norm: 8.954e+01\n",
      "Epoch 2838, Loss: 397.2527160644531, Neurons: 37, Grad norm: 8.843e+01\n",
      "Epoch 2838, Loss: 397.2527160644531, Neurons: 37, Grad norm: 8.843e+01\n",
      "Epoch 2839, Loss: 396.71563720703125, Neurons: 37, Grad norm: 8.743e+01\n",
      "Epoch 2839, Loss: 396.71563720703125, Neurons: 37, Grad norm: 8.743e+01\n",
      "Epoch 2840, Loss: 396.1833801269531, Neurons: 37, Grad norm: 8.639e+01\n",
      "Epoch 2840, Loss: 396.1833801269531, Neurons: 37, Grad norm: 8.639e+01\n",
      "Epoch 2841, Loss: 395.65576171875, Neurons: 37, Grad norm: 8.540e+01\n",
      "Epoch 2841, Loss: 395.65576171875, Neurons: 37, Grad norm: 8.540e+01\n",
      "Epoch 2842, Loss: 395.13275146484375, Neurons: 37, Grad norm: 8.443e+01\n",
      "Epoch 2842, Loss: 395.13275146484375, Neurons: 37, Grad norm: 8.443e+01\n",
      "Epoch 2843, Loss: 394.6139221191406, Neurons: 37, Grad norm: 8.355e+01\n",
      "Epoch 2843, Loss: 394.6139221191406, Neurons: 37, Grad norm: 8.355e+01\n",
      "Epoch 2844, Loss: 394.0992431640625, Neurons: 37, Grad norm: 8.270e+01\n",
      "Epoch 2844, Loss: 394.0992431640625, Neurons: 37, Grad norm: 8.270e+01\n",
      "Epoch 2845, Loss: 393.588134765625, Neurons: 37, Grad norm: 8.192e+01\n",
      "Epoch 2845, Loss: 393.588134765625, Neurons: 37, Grad norm: 8.192e+01\n",
      "Epoch 2846, Loss: 393.08038330078125, Neurons: 37, Grad norm: 8.109e+01\n",
      "Epoch 2846, Loss: 393.08038330078125, Neurons: 37, Grad norm: 8.109e+01\n",
      "Epoch 2847, Loss: 392.5758361816406, Neurons: 37, Grad norm: 8.035e+01\n",
      "Epoch 2847, Loss: 392.5758361816406, Neurons: 37, Grad norm: 8.035e+01\n",
      "Epoch 2848, Loss: 392.07421875, Neurons: 37, Grad norm: 7.966e+01\n",
      "Epoch 2848, Loss: 392.07421875, Neurons: 37, Grad norm: 7.966e+01\n",
      "Epoch 2849, Loss: 391.5751647949219, Neurons: 37, Grad norm: 7.903e+01\n",
      "Epoch 2849, Loss: 391.5751647949219, Neurons: 37, Grad norm: 7.903e+01\n",
      "Epoch 2850, Loss: 391.0783996582031, Neurons: 37, Grad norm: 7.840e+01\n",
      "Epoch 2850, Loss: 391.0783996582031, Neurons: 37, Grad norm: 7.840e+01\n",
      "Epoch 2851, Loss: 390.58349609375, Neurons: 37, Grad norm: 7.782e+01\n",
      "Epoch 2851, Loss: 390.58349609375, Neurons: 37, Grad norm: 7.782e+01\n",
      "Epoch 2852, Loss: 390.09027099609375, Neurons: 37, Grad norm: 7.724e+01\n",
      "Epoch 2852, Loss: 390.09027099609375, Neurons: 37, Grad norm: 7.724e+01\n",
      "Epoch 2853, Loss: 389.59857177734375, Neurons: 37, Grad norm: 7.670e+01\n",
      "Epoch 2853, Loss: 389.59857177734375, Neurons: 37, Grad norm: 7.670e+01\n",
      "Epoch 2854, Loss: 389.108154296875, Neurons: 37, Grad norm: 7.622e+01\n",
      "Epoch 2854, Loss: 389.108154296875, Neurons: 37, Grad norm: 7.622e+01\n",
      "Epoch 2855, Loss: 388.61871337890625, Neurons: 37, Grad norm: 7.575e+01\n",
      "Epoch 2855, Loss: 388.61871337890625, Neurons: 37, Grad norm: 7.575e+01\n",
      "Epoch 2856, Loss: 388.1299133300781, Neurons: 37, Grad norm: 7.533e+01\n",
      "Epoch 2856, Loss: 388.1299133300781, Neurons: 37, Grad norm: 7.533e+01\n",
      "Epoch 2857, Loss: 387.6415710449219, Neurons: 37, Grad norm: 7.494e+01\n",
      "Epoch 2857, Loss: 387.6415710449219, Neurons: 37, Grad norm: 7.494e+01\n",
      "Epoch 2858, Loss: 387.15338134765625, Neurons: 37, Grad norm: 7.457e+01\n",
      "Epoch 2858, Loss: 387.15338134765625, Neurons: 37, Grad norm: 7.457e+01\n",
      "Epoch 2859, Loss: 386.66510009765625, Neurons: 37, Grad norm: 7.423e+01\n",
      "Epoch 2859, Loss: 386.66510009765625, Neurons: 37, Grad norm: 7.423e+01\n",
      "Epoch 2860, Loss: 386.1766357421875, Neurons: 37, Grad norm: 7.388e+01\n",
      "Epoch 2860, Loss: 386.1766357421875, Neurons: 37, Grad norm: 7.388e+01\n",
      "Epoch 2861, Loss: 385.6877136230469, Neurons: 37, Grad norm: 7.356e+01\n",
      "Epoch 2861, Loss: 385.6877136230469, Neurons: 37, Grad norm: 7.356e+01\n",
      "Epoch 2862, Loss: 385.1982727050781, Neurons: 37, Grad norm: 7.328e+01\n",
      "Epoch 2862, Loss: 385.1982727050781, Neurons: 37, Grad norm: 7.328e+01\n",
      "Epoch 2863, Loss: 384.7081298828125, Neurons: 37, Grad norm: 7.298e+01\n",
      "Epoch 2863, Loss: 384.7081298828125, Neurons: 37, Grad norm: 7.298e+01\n",
      "Epoch 2864, Loss: 384.2170715332031, Neurons: 37, Grad norm: 7.273e+01\n",
      "Epoch 2864, Loss: 384.2170715332031, Neurons: 37, Grad norm: 7.273e+01\n",
      "Epoch 2865, Loss: 383.7250671386719, Neurons: 37, Grad norm: 7.247e+01\n",
      "Epoch 2865, Loss: 383.7250671386719, Neurons: 37, Grad norm: 7.247e+01\n",
      "Epoch 2866, Loss: 383.2319641113281, Neurons: 37, Grad norm: 7.224e+01\n",
      "Epoch 2866, Loss: 383.2319641113281, Neurons: 37, Grad norm: 7.224e+01\n",
      "Epoch 2867, Loss: 382.7374572753906, Neurons: 37, Grad norm: 7.202e+01\n",
      "Epoch 2867, Loss: 382.7374572753906, Neurons: 37, Grad norm: 7.202e+01\n",
      "Epoch 2868, Loss: 382.24151611328125, Neurons: 37, Grad norm: 7.182e+01\n",
      "Epoch 2868, Loss: 382.24151611328125, Neurons: 37, Grad norm: 7.182e+01\n",
      "Epoch 2869, Loss: 381.74407958984375, Neurons: 37, Grad norm: 7.163e+01\n",
      "Epoch 2869, Loss: 381.74407958984375, Neurons: 37, Grad norm: 7.163e+01\n",
      "Epoch 2870, Loss: 381.24493408203125, Neurons: 37, Grad norm: 7.144e+01\n",
      "Epoch 2870, Loss: 381.24493408203125, Neurons: 37, Grad norm: 7.144e+01\n",
      "Epoch 2871, Loss: 380.7440185546875, Neurons: 37, Grad norm: 7.128e+01\n",
      "Epoch 2871, Loss: 380.7440185546875, Neurons: 37, Grad norm: 7.128e+01\n",
      "Epoch 2872, Loss: 380.2412109375, Neurons: 37, Grad norm: 7.112e+01\n",
      "Epoch 2872, Loss: 380.2412109375, Neurons: 37, Grad norm: 7.112e+01\n",
      "Epoch 2873, Loss: 379.7364501953125, Neurons: 37, Grad norm: 7.098e+01\n",
      "Epoch 2873, Loss: 379.7364501953125, Neurons: 37, Grad norm: 7.098e+01\n",
      "Epoch 2874, Loss: 379.2296447753906, Neurons: 37, Grad norm: 7.085e+01\n",
      "Epoch 2874, Loss: 379.2296447753906, Neurons: 37, Grad norm: 7.085e+01\n",
      "Epoch 2875, Loss: 378.72064208984375, Neurons: 37, Grad norm: 7.071e+01\n",
      "Epoch 2875, Loss: 378.72064208984375, Neurons: 37, Grad norm: 7.071e+01\n",
      "Epoch 2876, Loss: 378.2094421386719, Neurons: 37, Grad norm: 7.058e+01\n",
      "Epoch 2876, Loss: 378.2094421386719, Neurons: 37, Grad norm: 7.058e+01\n",
      "Epoch 2877, Loss: 377.696044921875, Neurons: 37, Grad norm: 7.047e+01\n",
      "Epoch 2877, Loss: 377.696044921875, Neurons: 37, Grad norm: 7.047e+01\n",
      "Epoch 2878, Loss: 377.1802673339844, Neurons: 37, Grad norm: 7.035e+01\n",
      "Epoch 2878, Loss: 377.1802673339844, Neurons: 37, Grad norm: 7.035e+01\n",
      "Epoch 2879, Loss: 376.6620788574219, Neurons: 37, Grad norm: 7.025e+01\n",
      "Epoch 2879, Loss: 376.6620788574219, Neurons: 37, Grad norm: 7.025e+01\n",
      "Epoch 2880, Loss: 376.1414794921875, Neurons: 37, Grad norm: 7.014e+01\n",
      "Epoch 2880, Loss: 376.1414794921875, Neurons: 37, Grad norm: 7.014e+01\n",
      "Epoch 2881, Loss: 375.6183776855469, Neurons: 37, Grad norm: 7.005e+01\n",
      "Epoch 2881, Loss: 375.6183776855469, Neurons: 37, Grad norm: 7.005e+01\n",
      "Epoch 2882, Loss: 375.0928039550781, Neurons: 37, Grad norm: 6.995e+01\n",
      "Epoch 2882, Loss: 375.0928039550781, Neurons: 37, Grad norm: 6.995e+01\n",
      "Epoch 2883, Loss: 374.56463623046875, Neurons: 37, Grad norm: 6.986e+01\n",
      "Epoch 2883, Loss: 374.56463623046875, Neurons: 37, Grad norm: 6.986e+01\n",
      "Epoch 2884, Loss: 374.0339660644531, Neurons: 37, Grad norm: 6.976e+01\n",
      "Epoch 2884, Loss: 374.0339660644531, Neurons: 37, Grad norm: 6.976e+01\n",
      "Epoch 2885, Loss: 373.5006408691406, Neurons: 37, Grad norm: 6.968e+01\n",
      "Epoch 2885, Loss: 373.5006408691406, Neurons: 37, Grad norm: 6.968e+01\n",
      "Epoch 2886, Loss: 372.9648132324219, Neurons: 37, Grad norm: 6.959e+01\n",
      "Epoch 2886, Loss: 372.9648132324219, Neurons: 37, Grad norm: 6.959e+01\n",
      "Epoch 2887, Loss: 372.42633056640625, Neurons: 37, Grad norm: 6.950e+01\n",
      "Epoch 2887, Loss: 372.42633056640625, Neurons: 37, Grad norm: 6.950e+01\n",
      "Epoch 2888, Loss: 371.88519287109375, Neurons: 37, Grad norm: 6.943e+01\n",
      "Epoch 2888, Loss: 371.88519287109375, Neurons: 37, Grad norm: 6.943e+01\n",
      "Epoch 2889, Loss: 371.3415222167969, Neurons: 37, Grad norm: 6.935e+01\n",
      "Epoch 2889, Loss: 371.3415222167969, Neurons: 37, Grad norm: 6.935e+01\n",
      "Epoch 2890, Loss: 370.7951965332031, Neurons: 37, Grad norm: 6.928e+01\n",
      "Epoch 2890, Loss: 370.7951965332031, Neurons: 37, Grad norm: 6.928e+01\n",
      "Epoch 2891, Loss: 370.2462158203125, Neurons: 37, Grad norm: 6.921e+01\n",
      "Epoch 2891, Loss: 370.2462158203125, Neurons: 37, Grad norm: 6.921e+01\n",
      "Epoch 2892, Loss: 369.69464111328125, Neurons: 37, Grad norm: 6.914e+01\n",
      "Epoch 2892, Loss: 369.69464111328125, Neurons: 37, Grad norm: 6.914e+01\n",
      "Epoch 2893, Loss: 369.1404724121094, Neurons: 37, Grad norm: 6.907e+01\n",
      "Epoch 2893, Loss: 369.1404724121094, Neurons: 37, Grad norm: 6.907e+01\n",
      "Epoch 2894, Loss: 368.5837097167969, Neurons: 37, Grad norm: 6.900e+01\n",
      "Epoch 2894, Loss: 368.5837097167969, Neurons: 37, Grad norm: 6.900e+01\n",
      "Epoch 2895, Loss: 368.0243835449219, Neurons: 37, Grad norm: 6.893e+01\n",
      "Epoch 2895, Loss: 368.0243835449219, Neurons: 37, Grad norm: 6.893e+01\n",
      "Epoch 2896, Loss: 367.4624938964844, Neurons: 37, Grad norm: 6.887e+01\n",
      "Epoch 2896, Loss: 367.4624938964844, Neurons: 37, Grad norm: 6.887e+01\n",
      "Epoch 2897, Loss: 366.89813232421875, Neurons: 37, Grad norm: 6.880e+01\n",
      "Epoch 2897, Loss: 366.89813232421875, Neurons: 37, Grad norm: 6.880e+01\n",
      "Epoch 2898, Loss: 366.3313293457031, Neurons: 37, Grad norm: 6.874e+01\n",
      "Epoch 2898, Loss: 366.3313293457031, Neurons: 37, Grad norm: 6.874e+01\n",
      "Epoch 2899, Loss: 365.76202392578125, Neurons: 37, Grad norm: 6.867e+01\n",
      "Epoch 2899, Loss: 365.76202392578125, Neurons: 37, Grad norm: 6.867e+01\n",
      "Epoch 2899, Test loss: 363.9950866699219\n",
      "Epoch 2899, Test loss: 363.9950866699219\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "network shape updated to :[15, 22, 1]\n",
      "network shape updated to :[15, 22, 1]\n",
      "Epoch 2900, Loss: 366.1516418457031, Neurons: 38, Grad norm: 8.278e+01\n",
      "Epoch 2900, Loss: 366.1516418457031, Neurons: 38, Grad norm: 8.278e+01\n",
      "Epoch 2901, Loss: 365.9031066894531, Neurons: 38, Grad norm: 7.771e+01\n",
      "Epoch 2901, Loss: 365.9031066894531, Neurons: 38, Grad norm: 7.771e+01\n",
      "Epoch 2902, Loss: 365.6605529785156, Neurons: 38, Grad norm: 7.425e+01\n",
      "Epoch 2902, Loss: 365.6605529785156, Neurons: 38, Grad norm: 7.425e+01\n",
      "Epoch 2903, Loss: 365.424560546875, Neurons: 38, Grad norm: 7.246e+01\n",
      "Epoch 2903, Loss: 365.424560546875, Neurons: 38, Grad norm: 7.246e+01\n",
      "Epoch 2904, Loss: 365.1942443847656, Neurons: 38, Grad norm: 7.203e+01\n",
      "Epoch 2904, Loss: 365.1942443847656, Neurons: 38, Grad norm: 7.203e+01\n",
      "Epoch 2905, Loss: 364.96734619140625, Neurons: 38, Grad norm: 7.238e+01\n",
      "Epoch 2905, Loss: 364.96734619140625, Neurons: 38, Grad norm: 7.238e+01\n",
      "Epoch 2906, Loss: 364.7403564453125, Neurons: 38, Grad norm: 7.295e+01\n",
      "Epoch 2906, Loss: 364.7403564453125, Neurons: 38, Grad norm: 7.295e+01\n",
      "Epoch 2907, Loss: 364.5097961425781, Neurons: 38, Grad norm: 7.335e+01\n",
      "Epoch 2907, Loss: 364.5097961425781, Neurons: 38, Grad norm: 7.335e+01\n",
      "Epoch 2908, Loss: 364.2732238769531, Neurons: 38, Grad norm: 7.339e+01\n",
      "Epoch 2908, Loss: 364.2732238769531, Neurons: 38, Grad norm: 7.339e+01\n",
      "Epoch 2909, Loss: 364.0293884277344, Neurons: 38, Grad norm: 7.305e+01\n",
      "Epoch 2909, Loss: 364.0293884277344, Neurons: 38, Grad norm: 7.305e+01\n",
      "Epoch 2910, Loss: 363.77813720703125, Neurons: 38, Grad norm: 7.239e+01\n",
      "Epoch 2910, Loss: 363.77813720703125, Neurons: 38, Grad norm: 7.239e+01\n",
      "Epoch 2911, Loss: 363.51983642578125, Neurons: 38, Grad norm: 7.155e+01\n",
      "Epoch 2911, Loss: 363.51983642578125, Neurons: 38, Grad norm: 7.155e+01\n",
      "Epoch 2912, Loss: 363.2551574707031, Neurons: 38, Grad norm: 7.070e+01\n",
      "Epoch 2912, Loss: 363.2551574707031, Neurons: 38, Grad norm: 7.070e+01\n",
      "Epoch 2913, Loss: 362.98486328125, Neurons: 38, Grad norm: 6.992e+01\n",
      "Epoch 2913, Loss: 362.98486328125, Neurons: 38, Grad norm: 6.992e+01\n",
      "Epoch 2914, Loss: 362.70941162109375, Neurons: 38, Grad norm: 6.932e+01\n",
      "Epoch 2914, Loss: 362.70941162109375, Neurons: 38, Grad norm: 6.932e+01\n",
      "Epoch 2915, Loss: 362.42919921875, Neurons: 38, Grad norm: 6.891e+01\n",
      "Epoch 2915, Loss: 362.42919921875, Neurons: 38, Grad norm: 6.891e+01\n",
      "Epoch 2916, Loss: 362.1441955566406, Neurons: 38, Grad norm: 6.866e+01\n",
      "Epoch 2916, Loss: 362.1441955566406, Neurons: 38, Grad norm: 6.866e+01\n",
      "Epoch 2917, Loss: 361.8543395996094, Neurons: 38, Grad norm: 6.852e+01\n",
      "Epoch 2917, Loss: 361.8543395996094, Neurons: 38, Grad norm: 6.852e+01\n",
      "Epoch 2918, Loss: 361.5595703125, Neurons: 38, Grad norm: 6.845e+01\n",
      "Epoch 2918, Loss: 361.5595703125, Neurons: 38, Grad norm: 6.845e+01\n",
      "Epoch 2919, Loss: 361.2596740722656, Neurons: 38, Grad norm: 6.837e+01\n",
      "Epoch 2919, Loss: 361.2596740722656, Neurons: 38, Grad norm: 6.837e+01\n",
      "Epoch 2920, Loss: 360.95465087890625, Neurons: 38, Grad norm: 6.827e+01\n",
      "Epoch 2920, Loss: 360.95465087890625, Neurons: 38, Grad norm: 6.827e+01\n",
      "Epoch 2921, Loss: 360.64471435546875, Neurons: 38, Grad norm: 6.814e+01\n",
      "Epoch 2921, Loss: 360.64471435546875, Neurons: 38, Grad norm: 6.814e+01\n",
      "Epoch 2922, Loss: 360.33026123046875, Neurons: 38, Grad norm: 6.800e+01\n",
      "Epoch 2922, Loss: 360.33026123046875, Neurons: 38, Grad norm: 6.800e+01\n",
      "Epoch 2923, Loss: 360.0113525390625, Neurons: 38, Grad norm: 6.787e+01\n",
      "Epoch 2923, Loss: 360.0113525390625, Neurons: 38, Grad norm: 6.787e+01\n",
      "Epoch 2924, Loss: 359.6882629394531, Neurons: 38, Grad norm: 6.778e+01\n",
      "Epoch 2924, Loss: 359.6882629394531, Neurons: 38, Grad norm: 6.778e+01\n",
      "Epoch 2925, Loss: 359.3609313964844, Neurons: 38, Grad norm: 6.774e+01\n",
      "Epoch 2925, Loss: 359.3609313964844, Neurons: 38, Grad norm: 6.774e+01\n",
      "Epoch 2926, Loss: 359.0291748046875, Neurons: 38, Grad norm: 6.774e+01\n",
      "Epoch 2926, Loss: 359.0291748046875, Neurons: 38, Grad norm: 6.774e+01\n",
      "Epoch 2927, Loss: 358.692626953125, Neurons: 38, Grad norm: 6.779e+01\n",
      "Epoch 2927, Loss: 358.692626953125, Neurons: 38, Grad norm: 6.779e+01\n",
      "Epoch 2928, Loss: 358.35113525390625, Neurons: 38, Grad norm: 6.786e+01\n",
      "Epoch 2928, Loss: 358.35113525390625, Neurons: 38, Grad norm: 6.786e+01\n",
      "Epoch 2929, Loss: 358.00445556640625, Neurons: 38, Grad norm: 6.793e+01\n",
      "Epoch 2929, Loss: 358.00445556640625, Neurons: 38, Grad norm: 6.793e+01\n",
      "Epoch 2930, Loss: 357.6523132324219, Neurons: 38, Grad norm: 6.799e+01\n",
      "Epoch 2930, Loss: 357.6523132324219, Neurons: 38, Grad norm: 6.799e+01\n",
      "Epoch 2931, Loss: 357.2945861816406, Neurons: 38, Grad norm: 6.800e+01\n",
      "Epoch 2931, Loss: 357.2945861816406, Neurons: 38, Grad norm: 6.800e+01\n",
      "Epoch 2932, Loss: 356.9312744140625, Neurons: 38, Grad norm: 6.797e+01\n",
      "Epoch 2932, Loss: 356.9312744140625, Neurons: 38, Grad norm: 6.797e+01\n",
      "Epoch 2933, Loss: 356.5623474121094, Neurons: 38, Grad norm: 6.790e+01\n",
      "Epoch 2933, Loss: 356.5623474121094, Neurons: 38, Grad norm: 6.790e+01\n",
      "Epoch 2934, Loss: 356.1880798339844, Neurons: 38, Grad norm: 6.781e+01\n",
      "Epoch 2934, Loss: 356.1880798339844, Neurons: 38, Grad norm: 6.781e+01\n",
      "Epoch 2935, Loss: 355.80859375, Neurons: 38, Grad norm: 6.771e+01\n",
      "Epoch 2935, Loss: 355.80859375, Neurons: 38, Grad norm: 6.771e+01\n",
      "Epoch 2936, Loss: 355.424072265625, Neurons: 38, Grad norm: 6.761e+01\n",
      "Epoch 2936, Loss: 355.424072265625, Neurons: 38, Grad norm: 6.761e+01\n",
      "Epoch 2937, Loss: 355.0348205566406, Neurons: 38, Grad norm: 6.753e+01\n",
      "Epoch 2937, Loss: 355.0348205566406, Neurons: 38, Grad norm: 6.753e+01\n",
      "Epoch 2938, Loss: 354.6409912109375, Neurons: 38, Grad norm: 6.745e+01\n",
      "Epoch 2938, Loss: 354.6409912109375, Neurons: 38, Grad norm: 6.745e+01\n",
      "Epoch 2939, Loss: 354.2427673339844, Neurons: 38, Grad norm: 6.739e+01\n",
      "Epoch 2939, Loss: 354.2427673339844, Neurons: 38, Grad norm: 6.739e+01\n",
      "Epoch 2940, Loss: 353.84014892578125, Neurons: 38, Grad norm: 6.734e+01\n",
      "Epoch 2940, Loss: 353.84014892578125, Neurons: 38, Grad norm: 6.734e+01\n",
      "Epoch 2941, Loss: 353.4333190917969, Neurons: 38, Grad norm: 6.730e+01\n",
      "Epoch 2941, Loss: 353.4333190917969, Neurons: 38, Grad norm: 6.730e+01\n",
      "Epoch 2942, Loss: 353.02239990234375, Neurons: 38, Grad norm: 6.727e+01\n",
      "Epoch 2942, Loss: 353.02239990234375, Neurons: 38, Grad norm: 6.727e+01\n",
      "Epoch 2943, Loss: 352.6073303222656, Neurons: 38, Grad norm: 6.725e+01\n",
      "Epoch 2943, Loss: 352.6073303222656, Neurons: 38, Grad norm: 6.725e+01\n",
      "Epoch 2944, Loss: 352.18829345703125, Neurons: 38, Grad norm: 6.722e+01\n",
      "Epoch 2944, Loss: 352.18829345703125, Neurons: 38, Grad norm: 6.722e+01\n",
      "Epoch 2945, Loss: 351.7652282714844, Neurons: 38, Grad norm: 6.721e+01\n",
      "Epoch 2945, Loss: 351.7652282714844, Neurons: 38, Grad norm: 6.721e+01\n",
      "Epoch 2946, Loss: 351.3382568359375, Neurons: 38, Grad norm: 6.719e+01\n",
      "Epoch 2946, Loss: 351.3382568359375, Neurons: 38, Grad norm: 6.719e+01\n",
      "Epoch 2947, Loss: 350.9073791503906, Neurons: 38, Grad norm: 6.718e+01\n",
      "Epoch 2947, Loss: 350.9073791503906, Neurons: 38, Grad norm: 6.718e+01\n",
      "Epoch 2948, Loss: 350.4725036621094, Neurons: 38, Grad norm: 6.717e+01\n",
      "Epoch 2948, Loss: 350.4725036621094, Neurons: 38, Grad norm: 6.717e+01\n",
      "Epoch 2949, Loss: 350.03375244140625, Neurons: 38, Grad norm: 6.715e+01\n",
      "Epoch 2949, Loss: 350.03375244140625, Neurons: 38, Grad norm: 6.715e+01\n",
      "Epoch 2950, Loss: 349.5911560058594, Neurons: 38, Grad norm: 6.713e+01\n",
      "Epoch 2950, Loss: 349.5911560058594, Neurons: 38, Grad norm: 6.713e+01\n",
      "Epoch 2951, Loss: 349.14459228515625, Neurons: 38, Grad norm: 6.710e+01\n",
      "Epoch 2951, Loss: 349.14459228515625, Neurons: 38, Grad norm: 6.710e+01\n",
      "Epoch 2952, Loss: 348.6942138671875, Neurons: 38, Grad norm: 6.707e+01\n",
      "Epoch 2952, Loss: 348.6942138671875, Neurons: 38, Grad norm: 6.707e+01\n",
      "Epoch 2953, Loss: 348.239990234375, Neurons: 38, Grad norm: 6.703e+01\n",
      "Epoch 2953, Loss: 348.239990234375, Neurons: 38, Grad norm: 6.703e+01\n",
      "Epoch 2954, Loss: 347.7818908691406, Neurons: 38, Grad norm: 6.698e+01\n",
      "Epoch 2954, Loss: 347.7818908691406, Neurons: 38, Grad norm: 6.698e+01\n",
      "Epoch 2955, Loss: 347.32000732421875, Neurons: 38, Grad norm: 6.693e+01\n",
      "Epoch 2955, Loss: 347.32000732421875, Neurons: 38, Grad norm: 6.693e+01\n",
      "Epoch 2956, Loss: 346.8544006347656, Neurons: 38, Grad norm: 6.688e+01\n",
      "Epoch 2956, Loss: 346.8544006347656, Neurons: 38, Grad norm: 6.688e+01\n",
      "Epoch 2957, Loss: 346.38507080078125, Neurons: 38, Grad norm: 6.683e+01\n",
      "Epoch 2957, Loss: 346.38507080078125, Neurons: 38, Grad norm: 6.683e+01\n",
      "Epoch 2958, Loss: 345.9121398925781, Neurons: 38, Grad norm: 6.678e+01\n",
      "Epoch 2958, Loss: 345.9121398925781, Neurons: 38, Grad norm: 6.678e+01\n",
      "Epoch 2959, Loss: 345.4355773925781, Neurons: 38, Grad norm: 6.672e+01\n",
      "Epoch 2959, Loss: 345.4355773925781, Neurons: 38, Grad norm: 6.672e+01\n",
      "Epoch 2960, Loss: 344.95550537109375, Neurons: 38, Grad norm: 6.668e+01\n",
      "Epoch 2960, Loss: 344.95550537109375, Neurons: 38, Grad norm: 6.668e+01\n",
      "Epoch 2961, Loss: 344.471923828125, Neurons: 38, Grad norm: 6.663e+01\n",
      "Epoch 2961, Loss: 344.471923828125, Neurons: 38, Grad norm: 6.663e+01\n",
      "Epoch 2962, Loss: 343.98492431640625, Neurons: 38, Grad norm: 6.659e+01\n",
      "Epoch 2962, Loss: 343.98492431640625, Neurons: 38, Grad norm: 6.659e+01\n",
      "Epoch 2963, Loss: 343.49456787109375, Neurons: 38, Grad norm: 6.655e+01\n",
      "Epoch 2963, Loss: 343.49456787109375, Neurons: 38, Grad norm: 6.655e+01\n",
      "Epoch 2964, Loss: 343.0008850097656, Neurons: 38, Grad norm: 6.651e+01\n",
      "Epoch 2964, Loss: 343.0008850097656, Neurons: 38, Grad norm: 6.651e+01\n",
      "Epoch 2965, Loss: 342.50396728515625, Neurons: 38, Grad norm: 6.647e+01\n",
      "Epoch 2965, Loss: 342.50396728515625, Neurons: 38, Grad norm: 6.647e+01\n",
      "Epoch 2966, Loss: 342.0037536621094, Neurons: 38, Grad norm: 6.643e+01\n",
      "Epoch 2966, Loss: 342.0037536621094, Neurons: 38, Grad norm: 6.643e+01\n",
      "Epoch 2967, Loss: 341.5003356933594, Neurons: 38, Grad norm: 6.640e+01\n",
      "Epoch 2967, Loss: 341.5003356933594, Neurons: 38, Grad norm: 6.640e+01\n",
      "Epoch 2968, Loss: 340.9936828613281, Neurons: 38, Grad norm: 6.636e+01\n",
      "Epoch 2968, Loss: 340.9936828613281, Neurons: 38, Grad norm: 6.636e+01\n",
      "Epoch 2969, Loss: 340.48388671875, Neurons: 38, Grad norm: 6.631e+01\n",
      "Epoch 2969, Loss: 340.48388671875, Neurons: 38, Grad norm: 6.631e+01\n",
      "Epoch 2970, Loss: 339.97088623046875, Neurons: 38, Grad norm: 6.627e+01\n",
      "Epoch 2970, Loss: 339.97088623046875, Neurons: 38, Grad norm: 6.627e+01\n",
      "Epoch 2971, Loss: 339.4548645019531, Neurons: 38, Grad norm: 6.622e+01\n",
      "Epoch 2971, Loss: 339.4548645019531, Neurons: 38, Grad norm: 6.622e+01\n",
      "Epoch 2972, Loss: 338.9356994628906, Neurons: 38, Grad norm: 6.617e+01\n",
      "Epoch 2972, Loss: 338.9356994628906, Neurons: 38, Grad norm: 6.617e+01\n",
      "Epoch 2973, Loss: 338.41351318359375, Neurons: 38, Grad norm: 6.613e+01\n",
      "Epoch 2973, Loss: 338.41351318359375, Neurons: 38, Grad norm: 6.613e+01\n",
      "Epoch 2974, Loss: 337.8882751464844, Neurons: 38, Grad norm: 6.608e+01\n",
      "Epoch 2974, Loss: 337.8882751464844, Neurons: 38, Grad norm: 6.608e+01\n",
      "Epoch 2975, Loss: 337.3600158691406, Neurons: 38, Grad norm: 6.603e+01\n",
      "Epoch 2975, Loss: 337.3600158691406, Neurons: 38, Grad norm: 6.603e+01\n",
      "Epoch 2976, Loss: 336.8287658691406, Neurons: 38, Grad norm: 6.598e+01\n",
      "Epoch 2976, Loss: 336.8287658691406, Neurons: 38, Grad norm: 6.598e+01\n",
      "Epoch 2977, Loss: 336.2945251464844, Neurons: 38, Grad norm: 6.593e+01\n",
      "Epoch 2977, Loss: 336.2945251464844, Neurons: 38, Grad norm: 6.593e+01\n",
      "Epoch 2978, Loss: 335.75738525390625, Neurons: 38, Grad norm: 6.588e+01\n",
      "Epoch 2978, Loss: 335.75738525390625, Neurons: 38, Grad norm: 6.588e+01\n",
      "Epoch 2979, Loss: 335.2174072265625, Neurons: 38, Grad norm: 6.584e+01\n",
      "Epoch 2979, Loss: 335.2174072265625, Neurons: 38, Grad norm: 6.584e+01\n",
      "Epoch 2980, Loss: 334.674560546875, Neurons: 38, Grad norm: 6.579e+01\n",
      "Epoch 2980, Loss: 334.674560546875, Neurons: 38, Grad norm: 6.579e+01\n",
      "Epoch 2981, Loss: 334.1288146972656, Neurons: 38, Grad norm: 6.575e+01\n",
      "Epoch 2981, Loss: 334.1288146972656, Neurons: 38, Grad norm: 6.575e+01\n",
      "Epoch 2982, Loss: 333.58026123046875, Neurons: 38, Grad norm: 6.571e+01\n",
      "Epoch 2982, Loss: 333.58026123046875, Neurons: 38, Grad norm: 6.571e+01\n",
      "Epoch 2983, Loss: 333.0288391113281, Neurons: 38, Grad norm: 6.567e+01\n",
      "Epoch 2983, Loss: 333.0288391113281, Neurons: 38, Grad norm: 6.567e+01\n",
      "Epoch 2984, Loss: 332.4746398925781, Neurons: 38, Grad norm: 6.562e+01\n",
      "Epoch 2984, Loss: 332.4746398925781, Neurons: 38, Grad norm: 6.562e+01\n",
      "Epoch 2985, Loss: 331.91766357421875, Neurons: 38, Grad norm: 6.557e+01\n",
      "Epoch 2985, Loss: 331.91766357421875, Neurons: 38, Grad norm: 6.557e+01\n",
      "Epoch 2986, Loss: 331.3580017089844, Neurons: 38, Grad norm: 6.553e+01\n",
      "Epoch 2986, Loss: 331.3580017089844, Neurons: 38, Grad norm: 6.553e+01\n",
      "Epoch 2987, Loss: 330.7956848144531, Neurons: 38, Grad norm: 6.549e+01\n",
      "Epoch 2987, Loss: 330.7956848144531, Neurons: 38, Grad norm: 6.549e+01\n",
      "Epoch 2988, Loss: 330.23065185546875, Neurons: 38, Grad norm: 6.544e+01\n",
      "Epoch 2988, Loss: 330.23065185546875, Neurons: 38, Grad norm: 6.544e+01\n",
      "Epoch 2989, Loss: 329.66290283203125, Neurons: 38, Grad norm: 6.539e+01\n",
      "Epoch 2989, Loss: 329.66290283203125, Neurons: 38, Grad norm: 6.539e+01\n",
      "Epoch 2990, Loss: 329.092529296875, Neurons: 38, Grad norm: 6.534e+01\n",
      "Epoch 2990, Loss: 329.092529296875, Neurons: 38, Grad norm: 6.534e+01\n",
      "Epoch 2991, Loss: 328.5195007324219, Neurons: 38, Grad norm: 6.529e+01\n",
      "Epoch 2991, Loss: 328.5195007324219, Neurons: 38, Grad norm: 6.529e+01\n",
      "Epoch 2992, Loss: 327.9438781738281, Neurons: 38, Grad norm: 6.524e+01\n",
      "Epoch 2992, Loss: 327.9438781738281, Neurons: 38, Grad norm: 6.524e+01\n",
      "Epoch 2993, Loss: 327.3656921386719, Neurons: 38, Grad norm: 6.519e+01\n",
      "Epoch 2993, Loss: 327.3656921386719, Neurons: 38, Grad norm: 6.519e+01\n",
      "Epoch 2994, Loss: 326.7848815917969, Neurons: 38, Grad norm: 6.514e+01\n",
      "Epoch 2994, Loss: 326.7848815917969, Neurons: 38, Grad norm: 6.514e+01\n",
      "Epoch 2995, Loss: 326.20147705078125, Neurons: 38, Grad norm: 6.509e+01\n",
      "Epoch 2995, Loss: 326.20147705078125, Neurons: 38, Grad norm: 6.509e+01\n",
      "Epoch 2996, Loss: 325.6155090332031, Neurons: 38, Grad norm: 6.504e+01\n",
      "Epoch 2996, Loss: 325.6155090332031, Neurons: 38, Grad norm: 6.504e+01\n",
      "Epoch 2997, Loss: 325.0269470214844, Neurons: 38, Grad norm: 6.500e+01\n",
      "Epoch 2997, Loss: 325.0269470214844, Neurons: 38, Grad norm: 6.500e+01\n",
      "Epoch 2998, Loss: 324.4358215332031, Neurons: 38, Grad norm: 6.495e+01\n",
      "Epoch 2998, Loss: 324.4358215332031, Neurons: 38, Grad norm: 6.495e+01\n",
      "Epoch 2999, Loss: 323.8421325683594, Neurons: 38, Grad norm: 6.490e+01\n",
      "Epoch 2999, Loss: 323.8421325683594, Neurons: 38, Grad norm: 6.490e+01\n",
      "Epoch 2999, Test loss: 321.5193176269531\n",
      "Epoch 2999, Test loss: 321.5193176269531\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "network shape updated to :[15, 23, 1]\n",
      "network shape updated to :[15, 23, 1]\n",
      "Epoch 3000, Loss: 324.79583740234375, Neurons: 39, Grad norm: 6.856e+01\n",
      "Epoch 3000, Loss: 324.79583740234375, Neurons: 39, Grad norm: 6.856e+01\n",
      "Epoch 3001, Loss: 324.6154479980469, Neurons: 39, Grad norm: 6.688e+01\n",
      "Epoch 3001, Loss: 324.6154479980469, Neurons: 39, Grad norm: 6.688e+01\n",
      "Epoch 3002, Loss: 324.43939208984375, Neurons: 39, Grad norm: 6.649e+01\n",
      "Epoch 3002, Loss: 324.43939208984375, Neurons: 39, Grad norm: 6.649e+01\n",
      "Epoch 3003, Loss: 324.26336669921875, Neurons: 39, Grad norm: 6.661e+01\n",
      "Epoch 3003, Loss: 324.26336669921875, Neurons: 39, Grad norm: 6.661e+01\n",
      "Epoch 3004, Loss: 324.0821533203125, Neurons: 39, Grad norm: 6.671e+01\n",
      "Epoch 3004, Loss: 324.0821533203125, Neurons: 39, Grad norm: 6.671e+01\n",
      "Epoch 3005, Loss: 323.892578125, Neurons: 39, Grad norm: 6.664e+01\n",
      "Epoch 3005, Loss: 323.892578125, Neurons: 39, Grad norm: 6.664e+01\n",
      "Epoch 3006, Loss: 323.6938171386719, Neurons: 39, Grad norm: 6.645e+01\n",
      "Epoch 3006, Loss: 323.6938171386719, Neurons: 39, Grad norm: 6.645e+01\n",
      "Epoch 3007, Loss: 323.48626708984375, Neurons: 39, Grad norm: 6.627e+01\n",
      "Epoch 3007, Loss: 323.48626708984375, Neurons: 39, Grad norm: 6.627e+01\n",
      "Epoch 3008, Loss: 323.2705078125, Neurons: 39, Grad norm: 6.619e+01\n",
      "Epoch 3008, Loss: 323.2705078125, Neurons: 39, Grad norm: 6.619e+01\n",
      "Epoch 3009, Loss: 323.0470275878906, Neurons: 39, Grad norm: 6.622e+01\n",
      "Epoch 3009, Loss: 323.0470275878906, Neurons: 39, Grad norm: 6.622e+01\n",
      "Epoch 3010, Loss: 322.8158264160156, Neurons: 39, Grad norm: 6.632e+01\n",
      "Epoch 3010, Loss: 322.8158264160156, Neurons: 39, Grad norm: 6.632e+01\n",
      "Epoch 3011, Loss: 322.5769348144531, Neurons: 39, Grad norm: 6.645e+01\n",
      "Epoch 3011, Loss: 322.5769348144531, Neurons: 39, Grad norm: 6.645e+01\n",
      "Epoch 3012, Loss: 322.3301696777344, Neurons: 39, Grad norm: 6.654e+01\n",
      "Epoch 3012, Loss: 322.3301696777344, Neurons: 39, Grad norm: 6.654e+01\n",
      "Epoch 3013, Loss: 322.07525634765625, Neurons: 39, Grad norm: 6.655e+01\n",
      "Epoch 3013, Loss: 322.07525634765625, Neurons: 39, Grad norm: 6.655e+01\n",
      "Epoch 3014, Loss: 321.8121337890625, Neurons: 39, Grad norm: 6.648e+01\n",
      "Epoch 3014, Loss: 321.8121337890625, Neurons: 39, Grad norm: 6.648e+01\n",
      "Epoch 3015, Loss: 321.5408935546875, Neurons: 39, Grad norm: 6.635e+01\n",
      "Epoch 3015, Loss: 321.5408935546875, Neurons: 39, Grad norm: 6.635e+01\n",
      "Epoch 3016, Loss: 321.2618713378906, Neurons: 39, Grad norm: 6.621e+01\n",
      "Epoch 3016, Loss: 321.2618713378906, Neurons: 39, Grad norm: 6.621e+01\n",
      "Epoch 3017, Loss: 320.97540283203125, Neurons: 39, Grad norm: 6.609e+01\n",
      "Epoch 3017, Loss: 320.97540283203125, Neurons: 39, Grad norm: 6.609e+01\n",
      "Epoch 3018, Loss: 320.6817626953125, Neurons: 39, Grad norm: 6.601e+01\n",
      "Epoch 3018, Loss: 320.6817626953125, Neurons: 39, Grad norm: 6.601e+01\n",
      "Epoch 3019, Loss: 320.38116455078125, Neurons: 39, Grad norm: 6.595e+01\n",
      "Epoch 3019, Loss: 320.38116455078125, Neurons: 39, Grad norm: 6.595e+01\n",
      "Epoch 3020, Loss: 320.0736999511719, Neurons: 39, Grad norm: 6.592e+01\n",
      "Epoch 3020, Loss: 320.0736999511719, Neurons: 39, Grad norm: 6.592e+01\n",
      "Epoch 3021, Loss: 319.7593688964844, Neurons: 39, Grad norm: 6.590e+01\n",
      "Epoch 3021, Loss: 319.7593688964844, Neurons: 39, Grad norm: 6.590e+01\n",
      "Epoch 3022, Loss: 319.43804931640625, Neurons: 39, Grad norm: 6.588e+01\n",
      "Epoch 3022, Loss: 319.43804931640625, Neurons: 39, Grad norm: 6.588e+01\n",
      "Epoch 3023, Loss: 319.10980224609375, Neurons: 39, Grad norm: 6.585e+01\n",
      "Epoch 3023, Loss: 319.10980224609375, Neurons: 39, Grad norm: 6.585e+01\n",
      "Epoch 3024, Loss: 318.77471923828125, Neurons: 39, Grad norm: 6.583e+01\n",
      "Epoch 3024, Loss: 318.77471923828125, Neurons: 39, Grad norm: 6.583e+01\n",
      "Epoch 3025, Loss: 318.43304443359375, Neurons: 39, Grad norm: 6.582e+01\n",
      "Epoch 3025, Loss: 318.43304443359375, Neurons: 39, Grad norm: 6.582e+01\n",
      "Epoch 3026, Loss: 318.0849304199219, Neurons: 39, Grad norm: 6.580e+01\n",
      "Epoch 3026, Loss: 318.0849304199219, Neurons: 39, Grad norm: 6.580e+01\n",
      "Epoch 3027, Loss: 317.73052978515625, Neurons: 39, Grad norm: 6.579e+01\n",
      "Epoch 3027, Loss: 317.73052978515625, Neurons: 39, Grad norm: 6.579e+01\n",
      "Epoch 3028, Loss: 317.3700866699219, Neurons: 39, Grad norm: 6.577e+01\n",
      "Epoch 3028, Loss: 317.3700866699219, Neurons: 39, Grad norm: 6.577e+01\n",
      "Epoch 3029, Loss: 317.003662109375, Neurons: 39, Grad norm: 6.573e+01\n",
      "Epoch 3029, Loss: 317.003662109375, Neurons: 39, Grad norm: 6.573e+01\n",
      "Epoch 3030, Loss: 316.6315002441406, Neurons: 39, Grad norm: 6.567e+01\n",
      "Epoch 3030, Loss: 316.6315002441406, Neurons: 39, Grad norm: 6.567e+01\n",
      "Epoch 3031, Loss: 316.253662109375, Neurons: 39, Grad norm: 6.560e+01\n",
      "Epoch 3031, Loss: 316.253662109375, Neurons: 39, Grad norm: 6.560e+01\n",
      "Epoch 3032, Loss: 315.8703308105469, Neurons: 39, Grad norm: 6.552e+01\n",
      "Epoch 3032, Loss: 315.8703308105469, Neurons: 39, Grad norm: 6.552e+01\n",
      "Epoch 3033, Loss: 315.4816589355469, Neurons: 39, Grad norm: 6.544e+01\n",
      "Epoch 3033, Loss: 315.4816589355469, Neurons: 39, Grad norm: 6.544e+01\n",
      "Epoch 3034, Loss: 315.0878601074219, Neurons: 39, Grad norm: 6.537e+01\n",
      "Epoch 3034, Loss: 315.0878601074219, Neurons: 39, Grad norm: 6.537e+01\n",
      "Epoch 3035, Loss: 314.68914794921875, Neurons: 39, Grad norm: 6.530e+01\n",
      "Epoch 3035, Loss: 314.68914794921875, Neurons: 39, Grad norm: 6.530e+01\n",
      "Epoch 3036, Loss: 314.28564453125, Neurons: 39, Grad norm: 6.524e+01\n",
      "Epoch 3036, Loss: 314.28564453125, Neurons: 39, Grad norm: 6.524e+01\n",
      "Epoch 3037, Loss: 313.8776550292969, Neurons: 39, Grad norm: 6.517e+01\n",
      "Epoch 3037, Loss: 313.8776550292969, Neurons: 39, Grad norm: 6.517e+01\n",
      "Epoch 3038, Loss: 313.4652099609375, Neurons: 39, Grad norm: 6.512e+01\n",
      "Epoch 3038, Loss: 313.4652099609375, Neurons: 39, Grad norm: 6.512e+01\n",
      "Epoch 3039, Loss: 313.048583984375, Neurons: 39, Grad norm: 6.505e+01\n",
      "Epoch 3039, Loss: 313.048583984375, Neurons: 39, Grad norm: 6.505e+01\n",
      "Epoch 3040, Loss: 312.6279602050781, Neurons: 39, Grad norm: 6.499e+01\n",
      "Epoch 3040, Loss: 312.6279602050781, Neurons: 39, Grad norm: 6.499e+01\n",
      "Epoch 3041, Loss: 312.20361328125, Neurons: 39, Grad norm: 6.494e+01\n",
      "Epoch 3041, Loss: 312.20361328125, Neurons: 39, Grad norm: 6.494e+01\n",
      "Epoch 3042, Loss: 311.77557373046875, Neurons: 39, Grad norm: 6.487e+01\n",
      "Epoch 3042, Loss: 311.77557373046875, Neurons: 39, Grad norm: 6.487e+01\n",
      "Epoch 3043, Loss: 311.34405517578125, Neurons: 39, Grad norm: 6.482e+01\n",
      "Epoch 3043, Loss: 311.34405517578125, Neurons: 39, Grad norm: 6.482e+01\n",
      "Epoch 3044, Loss: 310.9091796875, Neurons: 39, Grad norm: 6.475e+01\n",
      "Epoch 3044, Loss: 310.9091796875, Neurons: 39, Grad norm: 6.475e+01\n",
      "Epoch 3045, Loss: 310.47100830078125, Neurons: 39, Grad norm: 6.469e+01\n",
      "Epoch 3045, Loss: 310.47100830078125, Neurons: 39, Grad norm: 6.469e+01\n",
      "Epoch 3046, Loss: 310.029541015625, Neurons: 39, Grad norm: 6.462e+01\n",
      "Epoch 3046, Loss: 310.029541015625, Neurons: 39, Grad norm: 6.462e+01\n",
      "Epoch 3047, Loss: 309.584716796875, Neurons: 39, Grad norm: 6.455e+01\n",
      "Epoch 3047, Loss: 309.584716796875, Neurons: 39, Grad norm: 6.455e+01\n",
      "Epoch 3048, Loss: 309.13641357421875, Neurons: 39, Grad norm: 6.447e+01\n",
      "Epoch 3048, Loss: 309.13641357421875, Neurons: 39, Grad norm: 6.447e+01\n",
      "Epoch 3049, Loss: 308.684814453125, Neurons: 39, Grad norm: 6.441e+01\n",
      "Epoch 3049, Loss: 308.684814453125, Neurons: 39, Grad norm: 6.441e+01\n",
      "Epoch 3050, Loss: 308.2298278808594, Neurons: 39, Grad norm: 6.434e+01\n",
      "Epoch 3050, Loss: 308.2298278808594, Neurons: 39, Grad norm: 6.434e+01\n",
      "Epoch 3051, Loss: 307.7713928222656, Neurons: 39, Grad norm: 6.427e+01\n",
      "Epoch 3051, Loss: 307.7713928222656, Neurons: 39, Grad norm: 6.427e+01\n",
      "Epoch 3052, Loss: 307.30950927734375, Neurons: 39, Grad norm: 6.420e+01\n",
      "Epoch 3052, Loss: 307.30950927734375, Neurons: 39, Grad norm: 6.420e+01\n",
      "Epoch 3053, Loss: 306.8442077636719, Neurons: 39, Grad norm: 6.412e+01\n",
      "Epoch 3053, Loss: 306.8442077636719, Neurons: 39, Grad norm: 6.412e+01\n",
      "Epoch 3054, Loss: 306.3753967285156, Neurons: 39, Grad norm: 6.405e+01\n",
      "Epoch 3054, Loss: 306.3753967285156, Neurons: 39, Grad norm: 6.405e+01\n",
      "Epoch 3055, Loss: 305.9030456542969, Neurons: 39, Grad norm: 6.398e+01\n",
      "Epoch 3055, Loss: 305.9030456542969, Neurons: 39, Grad norm: 6.398e+01\n",
      "Epoch 3056, Loss: 305.4272766113281, Neurons: 39, Grad norm: 6.390e+01\n",
      "Epoch 3056, Loss: 305.4272766113281, Neurons: 39, Grad norm: 6.390e+01\n",
      "Epoch 3057, Loss: 304.9480285644531, Neurons: 39, Grad norm: 6.383e+01\n",
      "Epoch 3057, Loss: 304.9480285644531, Neurons: 39, Grad norm: 6.383e+01\n",
      "Epoch 3058, Loss: 304.46533203125, Neurons: 39, Grad norm: 6.376e+01\n",
      "Epoch 3058, Loss: 304.46533203125, Neurons: 39, Grad norm: 6.376e+01\n",
      "Epoch 3059, Loss: 303.9792785644531, Neurons: 39, Grad norm: 6.369e+01\n",
      "Epoch 3059, Loss: 303.9792785644531, Neurons: 39, Grad norm: 6.369e+01\n",
      "Epoch 3060, Loss: 303.4897766113281, Neurons: 39, Grad norm: 6.362e+01\n",
      "Epoch 3060, Loss: 303.4897766113281, Neurons: 39, Grad norm: 6.362e+01\n",
      "Epoch 3061, Loss: 302.9970703125, Neurons: 39, Grad norm: 6.354e+01\n",
      "Epoch 3061, Loss: 302.9970703125, Neurons: 39, Grad norm: 6.354e+01\n",
      "Epoch 3062, Loss: 302.5010681152344, Neurons: 39, Grad norm: 6.346e+01\n",
      "Epoch 3062, Loss: 302.5010681152344, Neurons: 39, Grad norm: 6.346e+01\n",
      "Epoch 3063, Loss: 302.0019226074219, Neurons: 39, Grad norm: 6.338e+01\n",
      "Epoch 3063, Loss: 302.0019226074219, Neurons: 39, Grad norm: 6.338e+01\n",
      "Epoch 3064, Loss: 301.4996337890625, Neurons: 39, Grad norm: 6.329e+01\n",
      "Epoch 3064, Loss: 301.4996337890625, Neurons: 39, Grad norm: 6.329e+01\n",
      "Epoch 3065, Loss: 300.994384765625, Neurons: 39, Grad norm: 6.320e+01\n",
      "Epoch 3065, Loss: 300.994384765625, Neurons: 39, Grad norm: 6.320e+01\n",
      "Epoch 3066, Loss: 300.4861755371094, Neurons: 39, Grad norm: 6.311e+01\n",
      "Epoch 3066, Loss: 300.4861755371094, Neurons: 39, Grad norm: 6.311e+01\n",
      "Epoch 3067, Loss: 299.97503662109375, Neurons: 39, Grad norm: 6.302e+01\n",
      "Epoch 3067, Loss: 299.97503662109375, Neurons: 39, Grad norm: 6.302e+01\n",
      "Epoch 3068, Loss: 299.4611511230469, Neurons: 39, Grad norm: 6.293e+01\n",
      "Epoch 3068, Loss: 299.4611511230469, Neurons: 39, Grad norm: 6.293e+01\n",
      "Epoch 3069, Loss: 298.9444885253906, Neurons: 39, Grad norm: 6.284e+01\n",
      "Epoch 3069, Loss: 298.9444885253906, Neurons: 39, Grad norm: 6.284e+01\n",
      "Epoch 3070, Loss: 298.4252014160156, Neurons: 39, Grad norm: 6.275e+01\n",
      "Epoch 3070, Loss: 298.4252014160156, Neurons: 39, Grad norm: 6.275e+01\n",
      "Epoch 3071, Loss: 297.90338134765625, Neurons: 39, Grad norm: 6.266e+01\n",
      "Epoch 3071, Loss: 297.90338134765625, Neurons: 39, Grad norm: 6.266e+01\n",
      "Epoch 3072, Loss: 297.3790283203125, Neurons: 39, Grad norm: 6.256e+01\n",
      "Epoch 3072, Loss: 297.3790283203125, Neurons: 39, Grad norm: 6.256e+01\n",
      "Epoch 3073, Loss: 296.8522644042969, Neurons: 39, Grad norm: 6.247e+01\n",
      "Epoch 3073, Loss: 296.8522644042969, Neurons: 39, Grad norm: 6.247e+01\n",
      "Epoch 3074, Loss: 296.3232116699219, Neurons: 39, Grad norm: 6.237e+01\n",
      "Epoch 3074, Loss: 296.3232116699219, Neurons: 39, Grad norm: 6.237e+01\n",
      "Epoch 3075, Loss: 295.7919006347656, Neurons: 39, Grad norm: 6.226e+01\n",
      "Epoch 3075, Loss: 295.7919006347656, Neurons: 39, Grad norm: 6.226e+01\n",
      "Epoch 3076, Loss: 295.2583923339844, Neurons: 39, Grad norm: 6.215e+01\n",
      "Epoch 3076, Loss: 295.2583923339844, Neurons: 39, Grad norm: 6.215e+01\n",
      "Epoch 3077, Loss: 294.72283935546875, Neurons: 39, Grad norm: 6.204e+01\n",
      "Epoch 3077, Loss: 294.72283935546875, Neurons: 39, Grad norm: 6.204e+01\n",
      "Epoch 3078, Loss: 294.1852111816406, Neurons: 39, Grad norm: 6.193e+01\n",
      "Epoch 3078, Loss: 294.1852111816406, Neurons: 39, Grad norm: 6.193e+01\n",
      "Epoch 3079, Loss: 293.6456298828125, Neurons: 39, Grad norm: 6.182e+01\n",
      "Epoch 3079, Loss: 293.6456298828125, Neurons: 39, Grad norm: 6.182e+01\n",
      "Epoch 3080, Loss: 293.10418701171875, Neurons: 39, Grad norm: 6.171e+01\n",
      "Epoch 3080, Loss: 293.10418701171875, Neurons: 39, Grad norm: 6.171e+01\n",
      "Epoch 3081, Loss: 292.5608825683594, Neurons: 39, Grad norm: 6.161e+01\n",
      "Epoch 3081, Loss: 292.5608825683594, Neurons: 39, Grad norm: 6.161e+01\n",
      "Epoch 3082, Loss: 292.0158386230469, Neurons: 39, Grad norm: 6.150e+01\n",
      "Epoch 3082, Loss: 292.0158386230469, Neurons: 39, Grad norm: 6.150e+01\n",
      "Epoch 3083, Loss: 291.4690856933594, Neurons: 39, Grad norm: 6.139e+01\n",
      "Epoch 3083, Loss: 291.4690856933594, Neurons: 39, Grad norm: 6.139e+01\n",
      "Epoch 3084, Loss: 290.9206848144531, Neurons: 39, Grad norm: 6.129e+01\n",
      "Epoch 3084, Loss: 290.9206848144531, Neurons: 39, Grad norm: 6.129e+01\n",
      "Epoch 3085, Loss: 290.37066650390625, Neurons: 39, Grad norm: 6.119e+01\n",
      "Epoch 3085, Loss: 290.37066650390625, Neurons: 39, Grad norm: 6.119e+01\n",
      "Epoch 3086, Loss: 289.8191223144531, Neurons: 39, Grad norm: 6.109e+01\n",
      "Epoch 3086, Loss: 289.8191223144531, Neurons: 39, Grad norm: 6.109e+01\n",
      "Epoch 3087, Loss: 289.2660827636719, Neurons: 39, Grad norm: 6.098e+01\n",
      "Epoch 3087, Loss: 289.2660827636719, Neurons: 39, Grad norm: 6.098e+01\n",
      "Epoch 3088, Loss: 288.7115783691406, Neurons: 39, Grad norm: 6.087e+01\n",
      "Epoch 3088, Loss: 288.7115783691406, Neurons: 39, Grad norm: 6.087e+01\n",
      "Epoch 3089, Loss: 288.1556701660156, Neurons: 39, Grad norm: 6.076e+01\n",
      "Epoch 3089, Loss: 288.1556701660156, Neurons: 39, Grad norm: 6.076e+01\n",
      "Epoch 3090, Loss: 287.598388671875, Neurons: 39, Grad norm: 6.065e+01\n",
      "Epoch 3090, Loss: 287.598388671875, Neurons: 39, Grad norm: 6.065e+01\n",
      "Epoch 3091, Loss: 287.0397644042969, Neurons: 39, Grad norm: 6.055e+01\n",
      "Epoch 3091, Loss: 287.0397644042969, Neurons: 39, Grad norm: 6.055e+01\n",
      "Epoch 3092, Loss: 286.4798889160156, Neurons: 39, Grad norm: 6.044e+01\n",
      "Epoch 3092, Loss: 286.4798889160156, Neurons: 39, Grad norm: 6.044e+01\n",
      "Epoch 3093, Loss: 285.91876220703125, Neurons: 39, Grad norm: 6.034e+01\n",
      "Epoch 3093, Loss: 285.91876220703125, Neurons: 39, Grad norm: 6.034e+01\n",
      "Epoch 3094, Loss: 285.35638427734375, Neurons: 39, Grad norm: 6.023e+01\n",
      "Epoch 3094, Loss: 285.35638427734375, Neurons: 39, Grad norm: 6.023e+01\n",
      "Epoch 3095, Loss: 284.7928466796875, Neurons: 39, Grad norm: 6.013e+01\n",
      "Epoch 3095, Loss: 284.7928466796875, Neurons: 39, Grad norm: 6.013e+01\n",
      "Epoch 3096, Loss: 284.2281494140625, Neurons: 39, Grad norm: 6.002e+01\n",
      "Epoch 3096, Loss: 284.2281494140625, Neurons: 39, Grad norm: 6.002e+01\n",
      "Epoch 3097, Loss: 283.66229248046875, Neurons: 39, Grad norm: 5.991e+01\n",
      "Epoch 3097, Loss: 283.66229248046875, Neurons: 39, Grad norm: 5.991e+01\n",
      "Epoch 3098, Loss: 283.0953369140625, Neurons: 39, Grad norm: 5.980e+01\n",
      "Epoch 3098, Loss: 283.0953369140625, Neurons: 39, Grad norm: 5.980e+01\n",
      "Epoch 3099, Loss: 282.5272521972656, Neurons: 39, Grad norm: 5.970e+01\n",
      "Epoch 3099, Loss: 282.5272521972656, Neurons: 39, Grad norm: 5.970e+01\n",
      "Epoch 3099, Test loss: 279.6127624511719\n",
      "Epoch 3099, Test loss: 279.6127624511719\n",
      "Added neuron to hidden layer 1 with activation tanh\n",
      "Added neuron to hidden layer 1 with activation tanh\n",
      "network shape updated to :[16, 23, 1]\n",
      "network shape updated to :[16, 23, 1]\n",
      "Epoch 3100, Loss: 334.68170166015625, Neurons: 40, Grad norm: 3.963e+02\n",
      "Epoch 3100, Loss: 334.68170166015625, Neurons: 40, Grad norm: 3.963e+02\n",
      "Epoch 3101, Loss: 333.5896911621094, Neurons: 40, Grad norm: 3.881e+02\n",
      "Epoch 3101, Loss: 333.5896911621094, Neurons: 40, Grad norm: 3.881e+02\n",
      "Epoch 3102, Loss: 332.45806884765625, Neurons: 40, Grad norm: 3.797e+02\n",
      "Epoch 3102, Loss: 332.45806884765625, Neurons: 40, Grad norm: 3.797e+02\n",
      "Epoch 3103, Loss: 331.28887939453125, Neurons: 40, Grad norm: 3.711e+02\n",
      "Epoch 3103, Loss: 331.28887939453125, Neurons: 40, Grad norm: 3.711e+02\n",
      "Epoch 3104, Loss: 330.0843200683594, Neurons: 40, Grad norm: 3.624e+02\n",
      "Epoch 3104, Loss: 330.0843200683594, Neurons: 40, Grad norm: 3.624e+02\n",
      "Epoch 3105, Loss: 328.8471374511719, Neurons: 40, Grad norm: 3.534e+02\n",
      "Epoch 3105, Loss: 328.8471374511719, Neurons: 40, Grad norm: 3.534e+02\n",
      "Epoch 3106, Loss: 327.58038330078125, Neurons: 40, Grad norm: 3.443e+02\n",
      "Epoch 3106, Loss: 327.58038330078125, Neurons: 40, Grad norm: 3.443e+02\n",
      "Epoch 3107, Loss: 326.2875061035156, Neurons: 40, Grad norm: 3.351e+02\n",
      "Epoch 3107, Loss: 326.2875061035156, Neurons: 40, Grad norm: 3.351e+02\n",
      "Epoch 3108, Loss: 324.9720458984375, Neurons: 40, Grad norm: 3.259e+02\n",
      "Epoch 3108, Loss: 324.9720458984375, Neurons: 40, Grad norm: 3.259e+02\n",
      "Epoch 3109, Loss: 323.6378173828125, Neurons: 40, Grad norm: 3.167e+02\n",
      "Epoch 3109, Loss: 323.6378173828125, Neurons: 40, Grad norm: 3.167e+02\n",
      "Epoch 3110, Loss: 322.28863525390625, Neurons: 40, Grad norm: 3.075e+02\n",
      "Epoch 3110, Loss: 322.28863525390625, Neurons: 40, Grad norm: 3.075e+02\n",
      "Epoch 3111, Loss: 320.9283752441406, Neurons: 40, Grad norm: 2.984e+02\n",
      "Epoch 3111, Loss: 320.9283752441406, Neurons: 40, Grad norm: 2.984e+02\n",
      "Epoch 3112, Loss: 319.5610046386719, Neurons: 40, Grad norm: 2.895e+02\n",
      "Epoch 3112, Loss: 319.5610046386719, Neurons: 40, Grad norm: 2.895e+02\n",
      "Epoch 3113, Loss: 318.19024658203125, Neurons: 40, Grad norm: 2.807e+02\n",
      "Epoch 3113, Loss: 318.19024658203125, Neurons: 40, Grad norm: 2.807e+02\n",
      "Epoch 3114, Loss: 316.81951904296875, Neurons: 40, Grad norm: 2.721e+02\n",
      "Epoch 3114, Loss: 316.81951904296875, Neurons: 40, Grad norm: 2.721e+02\n",
      "Epoch 3115, Loss: 315.4521484375, Neurons: 40, Grad norm: 2.638e+02\n",
      "Epoch 3115, Loss: 315.4521484375, Neurons: 40, Grad norm: 2.638e+02\n",
      "Epoch 3116, Loss: 314.09130859375, Neurons: 40, Grad norm: 2.558e+02\n",
      "Epoch 3116, Loss: 314.09130859375, Neurons: 40, Grad norm: 2.558e+02\n",
      "Epoch 3117, Loss: 312.7394714355469, Neurons: 40, Grad norm: 2.480e+02\n",
      "Epoch 3117, Loss: 312.7394714355469, Neurons: 40, Grad norm: 2.480e+02\n",
      "Epoch 3118, Loss: 311.3991394042969, Neurons: 40, Grad norm: 2.405e+02\n",
      "Epoch 3118, Loss: 311.3991394042969, Neurons: 40, Grad norm: 2.405e+02\n",
      "Epoch 3119, Loss: 310.0726013183594, Neurons: 40, Grad norm: 2.332e+02\n",
      "Epoch 3119, Loss: 310.0726013183594, Neurons: 40, Grad norm: 2.332e+02\n",
      "Epoch 3120, Loss: 308.76214599609375, Neurons: 40, Grad norm: 2.262e+02\n",
      "Epoch 3120, Loss: 308.76214599609375, Neurons: 40, Grad norm: 2.262e+02\n",
      "Epoch 3121, Loss: 307.46942138671875, Neurons: 40, Grad norm: 2.195e+02\n",
      "Epoch 3121, Loss: 307.46942138671875, Neurons: 40, Grad norm: 2.195e+02\n",
      "Epoch 3122, Loss: 306.1961364746094, Neurons: 40, Grad norm: 2.129e+02\n",
      "Epoch 3122, Loss: 306.1961364746094, Neurons: 40, Grad norm: 2.129e+02\n",
      "Epoch 3123, Loss: 304.9437561035156, Neurons: 40, Grad norm: 2.066e+02\n",
      "Epoch 3123, Loss: 304.9437561035156, Neurons: 40, Grad norm: 2.066e+02\n",
      "Epoch 3124, Loss: 303.7136535644531, Neurons: 40, Grad norm: 2.004e+02\n",
      "Epoch 3124, Loss: 303.7136535644531, Neurons: 40, Grad norm: 2.004e+02\n",
      "Epoch 3125, Loss: 302.5072021484375, Neurons: 40, Grad norm: 1.944e+02\n",
      "Epoch 3125, Loss: 302.5072021484375, Neurons: 40, Grad norm: 1.944e+02\n",
      "Epoch 3126, Loss: 301.32537841796875, Neurons: 40, Grad norm: 1.886e+02\n",
      "Epoch 3126, Loss: 301.32537841796875, Neurons: 40, Grad norm: 1.886e+02\n",
      "Epoch 3127, Loss: 300.1688232421875, Neurons: 40, Grad norm: 1.829e+02\n",
      "Epoch 3127, Loss: 300.1688232421875, Neurons: 40, Grad norm: 1.829e+02\n",
      "Epoch 3128, Loss: 299.0383605957031, Neurons: 40, Grad norm: 1.774e+02\n",
      "Epoch 3128, Loss: 299.0383605957031, Neurons: 40, Grad norm: 1.774e+02\n",
      "Epoch 3129, Loss: 297.93450927734375, Neurons: 40, Grad norm: 1.720e+02\n",
      "Epoch 3129, Loss: 297.93450927734375, Neurons: 40, Grad norm: 1.720e+02\n",
      "Epoch 3130, Loss: 296.85791015625, Neurons: 40, Grad norm: 1.667e+02\n",
      "Epoch 3130, Loss: 296.85791015625, Neurons: 40, Grad norm: 1.667e+02\n",
      "Epoch 3131, Loss: 295.8087158203125, Neurons: 40, Grad norm: 1.616e+02\n",
      "Epoch 3131, Loss: 295.8087158203125, Neurons: 40, Grad norm: 1.616e+02\n",
      "Epoch 3132, Loss: 294.7870178222656, Neurons: 40, Grad norm: 1.565e+02\n",
      "Epoch 3132, Loss: 294.7870178222656, Neurons: 40, Grad norm: 1.565e+02\n",
      "Epoch 3133, Loss: 293.7926940917969, Neurons: 40, Grad norm: 1.517e+02\n",
      "Epoch 3133, Loss: 293.7926940917969, Neurons: 40, Grad norm: 1.517e+02\n",
      "Epoch 3134, Loss: 292.8254699707031, Neurons: 40, Grad norm: 1.469e+02\n",
      "Epoch 3134, Loss: 292.8254699707031, Neurons: 40, Grad norm: 1.469e+02\n",
      "Epoch 3135, Loss: 291.8851318359375, Neurons: 40, Grad norm: 1.423e+02\n",
      "Epoch 3135, Loss: 291.8851318359375, Neurons: 40, Grad norm: 1.423e+02\n",
      "Epoch 3136, Loss: 290.9713134765625, Neurons: 40, Grad norm: 1.378e+02\n",
      "Epoch 3136, Loss: 290.9713134765625, Neurons: 40, Grad norm: 1.378e+02\n",
      "Epoch 3137, Loss: 290.08343505859375, Neurons: 40, Grad norm: 1.335e+02\n",
      "Epoch 3137, Loss: 290.08343505859375, Neurons: 40, Grad norm: 1.335e+02\n",
      "Epoch 3138, Loss: 289.2207336425781, Neurons: 40, Grad norm: 1.293e+02\n",
      "Epoch 3138, Loss: 289.2207336425781, Neurons: 40, Grad norm: 1.293e+02\n",
      "Epoch 3139, Loss: 288.382568359375, Neurons: 40, Grad norm: 1.252e+02\n",
      "Epoch 3139, Loss: 288.382568359375, Neurons: 40, Grad norm: 1.252e+02\n",
      "Epoch 3140, Loss: 287.5682678222656, Neurons: 40, Grad norm: 1.213e+02\n",
      "Epoch 3140, Loss: 287.5682678222656, Neurons: 40, Grad norm: 1.213e+02\n",
      "Epoch 3141, Loss: 286.7772521972656, Neurons: 40, Grad norm: 1.175e+02\n",
      "Epoch 3141, Loss: 286.7772521972656, Neurons: 40, Grad norm: 1.175e+02\n",
      "Epoch 3142, Loss: 286.0086669921875, Neurons: 40, Grad norm: 1.139e+02\n",
      "Epoch 3142, Loss: 286.0086669921875, Neurons: 40, Grad norm: 1.139e+02\n",
      "Epoch 3143, Loss: 285.2618713378906, Neurons: 40, Grad norm: 1.104e+02\n",
      "Epoch 3143, Loss: 285.2618713378906, Neurons: 40, Grad norm: 1.104e+02\n",
      "Epoch 3144, Loss: 284.5361022949219, Neurons: 40, Grad norm: 1.070e+02\n",
      "Epoch 3144, Loss: 284.5361022949219, Neurons: 40, Grad norm: 1.070e+02\n",
      "Epoch 3145, Loss: 283.83056640625, Neurons: 40, Grad norm: 1.038e+02\n",
      "Epoch 3145, Loss: 283.83056640625, Neurons: 40, Grad norm: 1.038e+02\n",
      "Epoch 3146, Loss: 283.1448059082031, Neurons: 40, Grad norm: 1.007e+02\n",
      "Epoch 3146, Loss: 283.1448059082031, Neurons: 40, Grad norm: 1.007e+02\n",
      "Epoch 3147, Loss: 282.47845458984375, Neurons: 40, Grad norm: 9.771e+01\n",
      "Epoch 3147, Loss: 282.47845458984375, Neurons: 40, Grad norm: 9.771e+01\n",
      "Epoch 3148, Loss: 281.8311767578125, Neurons: 40, Grad norm: 9.486e+01\n",
      "Epoch 3148, Loss: 281.8311767578125, Neurons: 40, Grad norm: 9.486e+01\n",
      "Epoch 3149, Loss: 281.20257568359375, Neurons: 40, Grad norm: 9.213e+01\n",
      "Epoch 3149, Loss: 281.20257568359375, Neurons: 40, Grad norm: 9.213e+01\n",
      "Epoch 3150, Loss: 280.5921936035156, Neurons: 40, Grad norm: 8.952e+01\n",
      "Epoch 3150, Loss: 280.5921936035156, Neurons: 40, Grad norm: 8.952e+01\n",
      "Epoch 3151, Loss: 279.999755859375, Neurons: 40, Grad norm: 8.709e+01\n",
      "Epoch 3151, Loss: 279.999755859375, Neurons: 40, Grad norm: 8.709e+01\n",
      "Epoch 3152, Loss: 279.4250183105469, Neurons: 40, Grad norm: 8.483e+01\n",
      "Epoch 3152, Loss: 279.4250183105469, Neurons: 40, Grad norm: 8.483e+01\n",
      "Epoch 3153, Loss: 278.8673400878906, Neurons: 40, Grad norm: 8.265e+01\n",
      "Epoch 3153, Loss: 278.8673400878906, Neurons: 40, Grad norm: 8.265e+01\n",
      "Epoch 3154, Loss: 278.3260192871094, Neurons: 40, Grad norm: 8.061e+01\n",
      "Epoch 3154, Loss: 278.3260192871094, Neurons: 40, Grad norm: 8.061e+01\n",
      "Epoch 3155, Loss: 277.800537109375, Neurons: 40, Grad norm: 7.879e+01\n",
      "Epoch 3155, Loss: 277.800537109375, Neurons: 40, Grad norm: 7.879e+01\n",
      "Epoch 3156, Loss: 277.2897644042969, Neurons: 40, Grad norm: 7.706e+01\n",
      "Epoch 3156, Loss: 277.2897644042969, Neurons: 40, Grad norm: 7.706e+01\n",
      "Epoch 3157, Loss: 276.7926330566406, Neurons: 40, Grad norm: 7.552e+01\n",
      "Epoch 3157, Loss: 276.7926330566406, Neurons: 40, Grad norm: 7.552e+01\n",
      "Epoch 3158, Loss: 276.3073425292969, Neurons: 40, Grad norm: 7.406e+01\n",
      "Epoch 3158, Loss: 276.3073425292969, Neurons: 40, Grad norm: 7.406e+01\n",
      "Epoch 3159, Loss: 275.8326721191406, Neurons: 40, Grad norm: 7.278e+01\n",
      "Epoch 3159, Loss: 275.8326721191406, Neurons: 40, Grad norm: 7.278e+01\n",
      "Epoch 3160, Loss: 275.3671875, Neurons: 40, Grad norm: 7.160e+01\n",
      "Epoch 3160, Loss: 275.3671875, Neurons: 40, Grad norm: 7.160e+01\n",
      "Epoch 3161, Loss: 274.909912109375, Neurons: 40, Grad norm: 7.052e+01\n",
      "Epoch 3161, Loss: 274.909912109375, Neurons: 40, Grad norm: 7.052e+01\n",
      "Epoch 3162, Loss: 274.4595642089844, Neurons: 40, Grad norm: 6.956e+01\n",
      "Epoch 3162, Loss: 274.4595642089844, Neurons: 40, Grad norm: 6.956e+01\n",
      "Epoch 3163, Loss: 274.01495361328125, Neurons: 40, Grad norm: 6.866e+01\n",
      "Epoch 3163, Loss: 274.01495361328125, Neurons: 40, Grad norm: 6.866e+01\n",
      "Epoch 3164, Loss: 273.5751953125, Neurons: 40, Grad norm: 6.791e+01\n",
      "Epoch 3164, Loss: 273.5751953125, Neurons: 40, Grad norm: 6.791e+01\n",
      "Epoch 3165, Loss: 273.1395263671875, Neurons: 40, Grad norm: 6.722e+01\n",
      "Epoch 3165, Loss: 273.1395263671875, Neurons: 40, Grad norm: 6.722e+01\n",
      "Epoch 3166, Loss: 272.7070617675781, Neurons: 40, Grad norm: 6.663e+01\n",
      "Epoch 3166, Loss: 272.7070617675781, Neurons: 40, Grad norm: 6.663e+01\n",
      "Epoch 3167, Loss: 272.27716064453125, Neurons: 40, Grad norm: 6.603e+01\n",
      "Epoch 3167, Loss: 272.27716064453125, Neurons: 40, Grad norm: 6.603e+01\n",
      "Epoch 3168, Loss: 271.8494567871094, Neurons: 40, Grad norm: 6.546e+01\n",
      "Epoch 3168, Loss: 271.8494567871094, Neurons: 40, Grad norm: 6.546e+01\n",
      "Epoch 3169, Loss: 271.4237060546875, Neurons: 40, Grad norm: 6.493e+01\n",
      "Epoch 3169, Loss: 271.4237060546875, Neurons: 40, Grad norm: 6.493e+01\n",
      "Epoch 3170, Loss: 270.99969482421875, Neurons: 40, Grad norm: 6.445e+01\n",
      "Epoch 3170, Loss: 270.99969482421875, Neurons: 40, Grad norm: 6.445e+01\n",
      "Epoch 3171, Loss: 270.5771484375, Neurons: 40, Grad norm: 6.399e+01\n",
      "Epoch 3171, Loss: 270.5771484375, Neurons: 40, Grad norm: 6.399e+01\n",
      "Epoch 3172, Loss: 270.1559753417969, Neurons: 40, Grad norm: 6.357e+01\n",
      "Epoch 3172, Loss: 270.1559753417969, Neurons: 40, Grad norm: 6.357e+01\n",
      "Epoch 3173, Loss: 269.7359619140625, Neurons: 40, Grad norm: 6.320e+01\n",
      "Epoch 3173, Loss: 269.7359619140625, Neurons: 40, Grad norm: 6.320e+01\n",
      "Epoch 3174, Loss: 269.31695556640625, Neurons: 40, Grad norm: 6.285e+01\n",
      "Epoch 3174, Loss: 269.31695556640625, Neurons: 40, Grad norm: 6.285e+01\n",
      "Epoch 3175, Loss: 268.8988952636719, Neurons: 40, Grad norm: 6.250e+01\n",
      "Epoch 3175, Loss: 268.8988952636719, Neurons: 40, Grad norm: 6.250e+01\n",
      "Epoch 3176, Loss: 268.4816589355469, Neurons: 40, Grad norm: 6.224e+01\n",
      "Epoch 3176, Loss: 268.4816589355469, Neurons: 40, Grad norm: 6.224e+01\n",
      "Epoch 3177, Loss: 268.065185546875, Neurons: 40, Grad norm: 6.197e+01\n",
      "Epoch 3177, Loss: 268.065185546875, Neurons: 40, Grad norm: 6.197e+01\n",
      "Epoch 3178, Loss: 267.6494140625, Neurons: 40, Grad norm: 6.170e+01\n",
      "Epoch 3178, Loss: 267.6494140625, Neurons: 40, Grad norm: 6.170e+01\n",
      "Epoch 3179, Loss: 267.2342529296875, Neurons: 40, Grad norm: 6.144e+01\n",
      "Epoch 3179, Loss: 267.2342529296875, Neurons: 40, Grad norm: 6.144e+01\n",
      "Epoch 3180, Loss: 266.81976318359375, Neurons: 40, Grad norm: 6.118e+01\n",
      "Epoch 3180, Loss: 266.81976318359375, Neurons: 40, Grad norm: 6.118e+01\n",
      "Epoch 3181, Loss: 266.40594482421875, Neurons: 40, Grad norm: 6.097e+01\n",
      "Epoch 3181, Loss: 266.40594482421875, Neurons: 40, Grad norm: 6.097e+01\n",
      "Epoch 3182, Loss: 265.9927062988281, Neurons: 40, Grad norm: 6.076e+01\n",
      "Epoch 3182, Loss: 265.9927062988281, Neurons: 40, Grad norm: 6.076e+01\n",
      "Epoch 3183, Loss: 265.57989501953125, Neurons: 40, Grad norm: 6.058e+01\n",
      "Epoch 3183, Loss: 265.57989501953125, Neurons: 40, Grad norm: 6.058e+01\n",
      "Epoch 3184, Loss: 265.16754150390625, Neurons: 40, Grad norm: 6.039e+01\n",
      "Epoch 3184, Loss: 265.16754150390625, Neurons: 40, Grad norm: 6.039e+01\n",
      "Epoch 3185, Loss: 264.7555236816406, Neurons: 40, Grad norm: 6.021e+01\n",
      "Epoch 3185, Loss: 264.7555236816406, Neurons: 40, Grad norm: 6.021e+01\n",
      "Epoch 3186, Loss: 264.34381103515625, Neurons: 40, Grad norm: 6.005e+01\n",
      "Epoch 3186, Loss: 264.34381103515625, Neurons: 40, Grad norm: 6.005e+01\n",
      "Epoch 3187, Loss: 263.932373046875, Neurons: 40, Grad norm: 5.988e+01\n",
      "Epoch 3187, Loss: 263.932373046875, Neurons: 40, Grad norm: 5.988e+01\n",
      "Epoch 3188, Loss: 263.5212097167969, Neurons: 40, Grad norm: 5.970e+01\n",
      "Epoch 3188, Loss: 263.5212097167969, Neurons: 40, Grad norm: 5.970e+01\n",
      "Epoch 3189, Loss: 263.1101989746094, Neurons: 40, Grad norm: 5.951e+01\n",
      "Epoch 3189, Loss: 263.1101989746094, Neurons: 40, Grad norm: 5.951e+01\n",
      "Epoch 3190, Loss: 262.69940185546875, Neurons: 40, Grad norm: 5.935e+01\n",
      "Epoch 3190, Loss: 262.69940185546875, Neurons: 40, Grad norm: 5.935e+01\n",
      "Epoch 3191, Loss: 262.2887878417969, Neurons: 40, Grad norm: 5.916e+01\n",
      "Epoch 3191, Loss: 262.2887878417969, Neurons: 40, Grad norm: 5.916e+01\n",
      "Epoch 3192, Loss: 261.8782958984375, Neurons: 40, Grad norm: 5.898e+01\n",
      "Epoch 3192, Loss: 261.8782958984375, Neurons: 40, Grad norm: 5.898e+01\n",
      "Epoch 3193, Loss: 261.4678955078125, Neurons: 40, Grad norm: 5.881e+01\n",
      "Epoch 3193, Loss: 261.4678955078125, Neurons: 40, Grad norm: 5.881e+01\n",
      "Epoch 3194, Loss: 261.0575866699219, Neurons: 40, Grad norm: 5.864e+01\n",
      "Epoch 3194, Loss: 261.0575866699219, Neurons: 40, Grad norm: 5.864e+01\n",
      "Epoch 3195, Loss: 260.6472473144531, Neurons: 40, Grad norm: 5.844e+01\n",
      "Epoch 3195, Loss: 260.6472473144531, Neurons: 40, Grad norm: 5.844e+01\n",
      "Epoch 3196, Loss: 260.23699951171875, Neurons: 40, Grad norm: 5.825e+01\n",
      "Epoch 3196, Loss: 260.23699951171875, Neurons: 40, Grad norm: 5.825e+01\n",
      "Epoch 3197, Loss: 259.8267822265625, Neurons: 40, Grad norm: 5.805e+01\n",
      "Epoch 3197, Loss: 259.8267822265625, Neurons: 40, Grad norm: 5.805e+01\n",
      "Epoch 3198, Loss: 259.4166259765625, Neurons: 40, Grad norm: 5.786e+01\n",
      "Epoch 3198, Loss: 259.4166259765625, Neurons: 40, Grad norm: 5.786e+01\n",
      "Epoch 3199, Loss: 259.00653076171875, Neurons: 40, Grad norm: 5.765e+01\n",
      "Epoch 3199, Loss: 259.00653076171875, Neurons: 40, Grad norm: 5.765e+01\n",
      "Epoch 3199, Test loss: 255.7978057861328\n",
      "Epoch 3199, Test loss: 255.7978057861328\n",
      "Added neuron to hidden layer 2 with activation sin\n",
      "Added neuron to hidden layer 2 with activation sin\n",
      "network shape updated to :[16, 24, 1]\n",
      "network shape updated to :[16, 24, 1]\n",
      "Epoch 3200, Loss: 257.3055419921875, Neurons: 41, Grad norm: 6.751e+01\n",
      "Epoch 3200, Loss: 257.3055419921875, Neurons: 41, Grad norm: 6.751e+01\n",
      "Epoch 3201, Loss: 257.0869140625, Neurons: 41, Grad norm: 6.231e+01\n",
      "Epoch 3201, Loss: 257.0869140625, Neurons: 41, Grad norm: 6.231e+01\n",
      "Epoch 3202, Loss: 256.8747863769531, Neurons: 41, Grad norm: 5.892e+01\n",
      "Epoch 3202, Loss: 256.8747863769531, Neurons: 41, Grad norm: 5.892e+01\n",
      "Epoch 3203, Loss: 256.669921875, Neurons: 41, Grad norm: 5.734e+01\n",
      "Epoch 3203, Loss: 256.669921875, Neurons: 41, Grad norm: 5.734e+01\n",
      "Epoch 3204, Loss: 256.4703369140625, Neurons: 41, Grad norm: 5.693e+01\n",
      "Epoch 3204, Loss: 256.4703369140625, Neurons: 41, Grad norm: 5.693e+01\n",
      "Epoch 3205, Loss: 256.272216796875, Neurons: 41, Grad norm: 5.699e+01\n",
      "Epoch 3205, Loss: 256.272216796875, Neurons: 41, Grad norm: 5.699e+01\n",
      "Epoch 3206, Loss: 256.07171630859375, Neurons: 41, Grad norm: 5.705e+01\n",
      "Epoch 3206, Loss: 256.07171630859375, Neurons: 41, Grad norm: 5.705e+01\n",
      "Epoch 3207, Loss: 255.86676025390625, Neurons: 41, Grad norm: 5.688e+01\n",
      "Epoch 3207, Loss: 255.86676025390625, Neurons: 41, Grad norm: 5.688e+01\n",
      "Epoch 3208, Loss: 255.6563262939453, Neurons: 41, Grad norm: 5.650e+01\n",
      "Epoch 3208, Loss: 255.6563262939453, Neurons: 41, Grad norm: 5.650e+01\n",
      "Epoch 3209, Loss: 255.44024658203125, Neurons: 41, Grad norm: 5.595e+01\n",
      "Epoch 3209, Loss: 255.44024658203125, Neurons: 41, Grad norm: 5.595e+01\n",
      "Epoch 3210, Loss: 255.2186737060547, Neurons: 41, Grad norm: 5.533e+01\n",
      "Epoch 3210, Loss: 255.2186737060547, Neurons: 41, Grad norm: 5.533e+01\n",
      "Epoch 3211, Loss: 254.9921417236328, Neurons: 41, Grad norm: 5.473e+01\n",
      "Epoch 3211, Loss: 254.9921417236328, Neurons: 41, Grad norm: 5.473e+01\n",
      "Epoch 3212, Loss: 254.76119995117188, Neurons: 41, Grad norm: 5.427e+01\n",
      "Epoch 3212, Loss: 254.76119995117188, Neurons: 41, Grad norm: 5.427e+01\n",
      "Epoch 3213, Loss: 254.52630615234375, Neurons: 41, Grad norm: 5.398e+01\n",
      "Epoch 3213, Loss: 254.52630615234375, Neurons: 41, Grad norm: 5.398e+01\n",
      "Epoch 3214, Loss: 254.28790283203125, Neurons: 41, Grad norm: 5.386e+01\n",
      "Epoch 3214, Loss: 254.28790283203125, Neurons: 41, Grad norm: 5.386e+01\n",
      "Epoch 3215, Loss: 254.04617309570312, Neurons: 41, Grad norm: 5.385e+01\n",
      "Epoch 3215, Loss: 254.04617309570312, Neurons: 41, Grad norm: 5.385e+01\n",
      "Epoch 3216, Loss: 253.80101013183594, Neurons: 41, Grad norm: 5.390e+01\n",
      "Epoch 3216, Loss: 253.80101013183594, Neurons: 41, Grad norm: 5.390e+01\n",
      "Epoch 3217, Loss: 253.55210876464844, Neurons: 41, Grad norm: 5.391e+01\n",
      "Epoch 3217, Loss: 253.55210876464844, Neurons: 41, Grad norm: 5.391e+01\n",
      "Epoch 3218, Loss: 253.29922485351562, Neurons: 41, Grad norm: 5.386e+01\n",
      "Epoch 3218, Loss: 253.29922485351562, Neurons: 41, Grad norm: 5.386e+01\n",
      "Epoch 3219, Loss: 253.04225158691406, Neurons: 41, Grad norm: 5.373e+01\n",
      "Epoch 3219, Loss: 253.04225158691406, Neurons: 41, Grad norm: 5.373e+01\n",
      "Epoch 3220, Loss: 252.781005859375, Neurons: 41, Grad norm: 5.354e+01\n",
      "Epoch 3220, Loss: 252.781005859375, Neurons: 41, Grad norm: 5.354e+01\n",
      "Epoch 3221, Loss: 252.51559448242188, Neurons: 41, Grad norm: 5.334e+01\n",
      "Epoch 3221, Loss: 252.51559448242188, Neurons: 41, Grad norm: 5.334e+01\n",
      "Epoch 3222, Loss: 252.2460174560547, Neurons: 41, Grad norm: 5.315e+01\n",
      "Epoch 3222, Loss: 252.2460174560547, Neurons: 41, Grad norm: 5.315e+01\n",
      "Epoch 3223, Loss: 251.9722442626953, Neurons: 41, Grad norm: 5.301e+01\n",
      "Epoch 3223, Loss: 251.9722442626953, Neurons: 41, Grad norm: 5.301e+01\n",
      "Epoch 3224, Loss: 251.69432067871094, Neurons: 41, Grad norm: 5.292e+01\n",
      "Epoch 3224, Loss: 251.69432067871094, Neurons: 41, Grad norm: 5.292e+01\n",
      "Epoch 3225, Loss: 251.4121856689453, Neurons: 41, Grad norm: 5.287e+01\n",
      "Epoch 3225, Loss: 251.4121856689453, Neurons: 41, Grad norm: 5.287e+01\n",
      "Epoch 3226, Loss: 251.12567138671875, Neurons: 41, Grad norm: 5.284e+01\n",
      "Epoch 3226, Loss: 251.12567138671875, Neurons: 41, Grad norm: 5.284e+01\n",
      "Epoch 3227, Loss: 250.83477783203125, Neurons: 41, Grad norm: 5.279e+01\n",
      "Epoch 3227, Loss: 250.83477783203125, Neurons: 41, Grad norm: 5.279e+01\n",
      "Epoch 3228, Loss: 250.5393829345703, Neurons: 41, Grad norm: 5.273e+01\n",
      "Epoch 3228, Loss: 250.5393829345703, Neurons: 41, Grad norm: 5.273e+01\n",
      "Epoch 3229, Loss: 250.23948669433594, Neurons: 41, Grad norm: 5.263e+01\n",
      "Epoch 3229, Loss: 250.23948669433594, Neurons: 41, Grad norm: 5.263e+01\n",
      "Epoch 3230, Loss: 249.9351043701172, Neurons: 41, Grad norm: 5.250e+01\n",
      "Epoch 3230, Loss: 249.9351043701172, Neurons: 41, Grad norm: 5.250e+01\n",
      "Epoch 3231, Loss: 249.6264190673828, Neurons: 41, Grad norm: 5.235e+01\n",
      "Epoch 3231, Loss: 249.6264190673828, Neurons: 41, Grad norm: 5.235e+01\n",
      "Epoch 3232, Loss: 249.31353759765625, Neurons: 41, Grad norm: 5.220e+01\n",
      "Epoch 3232, Loss: 249.31353759765625, Neurons: 41, Grad norm: 5.220e+01\n",
      "Epoch 3233, Loss: 248.9966583251953, Neurons: 41, Grad norm: 5.206e+01\n",
      "Epoch 3233, Loss: 248.9966583251953, Neurons: 41, Grad norm: 5.206e+01\n",
      "Epoch 3234, Loss: 248.6759490966797, Neurons: 41, Grad norm: 5.194e+01\n",
      "Epoch 3234, Loss: 248.6759490966797, Neurons: 41, Grad norm: 5.194e+01\n",
      "Epoch 3235, Loss: 248.35157775878906, Neurons: 41, Grad norm: 5.184e+01\n",
      "Epoch 3235, Loss: 248.35157775878906, Neurons: 41, Grad norm: 5.184e+01\n",
      "Epoch 3236, Loss: 248.02362060546875, Neurons: 41, Grad norm: 5.175e+01\n",
      "Epoch 3236, Loss: 248.02362060546875, Neurons: 41, Grad norm: 5.175e+01\n",
      "Epoch 3237, Loss: 247.692138671875, Neurons: 41, Grad norm: 5.166e+01\n",
      "Epoch 3237, Loss: 247.692138671875, Neurons: 41, Grad norm: 5.166e+01\n",
      "Epoch 3238, Loss: 247.35714721679688, Neurons: 41, Grad norm: 5.157e+01\n",
      "Epoch 3238, Loss: 247.35714721679688, Neurons: 41, Grad norm: 5.157e+01\n",
      "Epoch 3239, Loss: 247.01873779296875, Neurons: 41, Grad norm: 5.146e+01\n",
      "Epoch 3239, Loss: 247.01873779296875, Neurons: 41, Grad norm: 5.146e+01\n",
      "Epoch 3240, Loss: 246.6768798828125, Neurons: 41, Grad norm: 5.134e+01\n",
      "Epoch 3240, Loss: 246.6768798828125, Neurons: 41, Grad norm: 5.134e+01\n",
      "Epoch 3241, Loss: 246.33169555664062, Neurons: 41, Grad norm: 5.122e+01\n",
      "Epoch 3241, Loss: 246.33169555664062, Neurons: 41, Grad norm: 5.122e+01\n",
      "Epoch 3242, Loss: 245.98324584960938, Neurons: 41, Grad norm: 5.109e+01\n",
      "Epoch 3242, Loss: 245.98324584960938, Neurons: 41, Grad norm: 5.109e+01\n",
      "Epoch 3243, Loss: 245.6316375732422, Neurons: 41, Grad norm: 5.098e+01\n",
      "Epoch 3243, Loss: 245.6316375732422, Neurons: 41, Grad norm: 5.098e+01\n",
      "Epoch 3244, Loss: 245.2769775390625, Neurons: 41, Grad norm: 5.087e+01\n",
      "Epoch 3244, Loss: 245.2769775390625, Neurons: 41, Grad norm: 5.087e+01\n",
      "Epoch 3245, Loss: 244.91932678222656, Neurons: 41, Grad norm: 5.078e+01\n",
      "Epoch 3245, Loss: 244.91932678222656, Neurons: 41, Grad norm: 5.078e+01\n",
      "Epoch 3246, Loss: 244.55873107910156, Neurons: 41, Grad norm: 5.069e+01\n",
      "Epoch 3246, Loss: 244.55873107910156, Neurons: 41, Grad norm: 5.069e+01\n",
      "Epoch 3247, Loss: 244.1952362060547, Neurons: 41, Grad norm: 5.060e+01\n",
      "Epoch 3247, Loss: 244.1952362060547, Neurons: 41, Grad norm: 5.060e+01\n",
      "Epoch 3248, Loss: 243.82888793945312, Neurons: 41, Grad norm: 5.050e+01\n",
      "Epoch 3248, Loss: 243.82888793945312, Neurons: 41, Grad norm: 5.050e+01\n",
      "Epoch 3249, Loss: 243.4596405029297, Neurons: 41, Grad norm: 5.040e+01\n",
      "Epoch 3249, Loss: 243.4596405029297, Neurons: 41, Grad norm: 5.040e+01\n",
      "Epoch 3250, Loss: 243.08753967285156, Neurons: 41, Grad norm: 5.030e+01\n",
      "Epoch 3250, Loss: 243.08753967285156, Neurons: 41, Grad norm: 5.030e+01\n",
      "Epoch 3251, Loss: 242.7126922607422, Neurons: 41, Grad norm: 5.019e+01\n",
      "Epoch 3251, Loss: 242.7126922607422, Neurons: 41, Grad norm: 5.019e+01\n",
      "Epoch 3252, Loss: 242.33506774902344, Neurons: 41, Grad norm: 5.008e+01\n",
      "Epoch 3252, Loss: 242.33506774902344, Neurons: 41, Grad norm: 5.008e+01\n",
      "Epoch 3253, Loss: 241.9547882080078, Neurons: 41, Grad norm: 4.997e+01\n",
      "Epoch 3253, Loss: 241.9547882080078, Neurons: 41, Grad norm: 4.997e+01\n",
      "Epoch 3254, Loss: 241.5718231201172, Neurons: 41, Grad norm: 4.987e+01\n",
      "Epoch 3254, Loss: 241.5718231201172, Neurons: 41, Grad norm: 4.987e+01\n",
      "Epoch 3255, Loss: 241.18626403808594, Neurons: 41, Grad norm: 4.976e+01\n",
      "Epoch 3255, Loss: 241.18626403808594, Neurons: 41, Grad norm: 4.976e+01\n",
      "Epoch 3256, Loss: 240.79811096191406, Neurons: 41, Grad norm: 4.965e+01\n",
      "Epoch 3256, Loss: 240.79811096191406, Neurons: 41, Grad norm: 4.965e+01\n",
      "Epoch 3257, Loss: 240.40745544433594, Neurons: 41, Grad norm: 4.954e+01\n",
      "Epoch 3257, Loss: 240.40745544433594, Neurons: 41, Grad norm: 4.954e+01\n",
      "Epoch 3258, Loss: 240.01426696777344, Neurons: 41, Grad norm: 4.943e+01\n",
      "Epoch 3258, Loss: 240.01426696777344, Neurons: 41, Grad norm: 4.943e+01\n",
      "Epoch 3259, Loss: 239.6186065673828, Neurons: 41, Grad norm: 4.932e+01\n",
      "Epoch 3259, Loss: 239.6186065673828, Neurons: 41, Grad norm: 4.932e+01\n",
      "Epoch 3260, Loss: 239.2205810546875, Neurons: 41, Grad norm: 4.921e+01\n",
      "Epoch 3260, Loss: 239.2205810546875, Neurons: 41, Grad norm: 4.921e+01\n",
      "Epoch 3261, Loss: 238.82012939453125, Neurons: 41, Grad norm: 4.910e+01\n",
      "Epoch 3261, Loss: 238.82012939453125, Neurons: 41, Grad norm: 4.910e+01\n",
      "Epoch 3262, Loss: 238.41738891601562, Neurons: 41, Grad norm: 4.900e+01\n",
      "Epoch 3262, Loss: 238.41738891601562, Neurons: 41, Grad norm: 4.900e+01\n",
      "Epoch 3263, Loss: 238.0123291015625, Neurons: 41, Grad norm: 4.889e+01\n",
      "Epoch 3263, Loss: 238.0123291015625, Neurons: 41, Grad norm: 4.889e+01\n",
      "Epoch 3264, Loss: 237.60499572753906, Neurons: 41, Grad norm: 4.879e+01\n",
      "Epoch 3264, Loss: 237.60499572753906, Neurons: 41, Grad norm: 4.879e+01\n",
      "Epoch 3265, Loss: 237.19541931152344, Neurons: 41, Grad norm: 4.868e+01\n",
      "Epoch 3265, Loss: 237.19541931152344, Neurons: 41, Grad norm: 4.868e+01\n",
      "Epoch 3266, Loss: 236.7836151123047, Neurons: 41, Grad norm: 4.857e+01\n",
      "Epoch 3266, Loss: 236.7836151123047, Neurons: 41, Grad norm: 4.857e+01\n",
      "Epoch 3267, Loss: 236.36962890625, Neurons: 41, Grad norm: 4.846e+01\n",
      "Epoch 3267, Loss: 236.36962890625, Neurons: 41, Grad norm: 4.846e+01\n",
      "Epoch 3268, Loss: 235.95347595214844, Neurons: 41, Grad norm: 4.836e+01\n",
      "Epoch 3268, Loss: 235.95347595214844, Neurons: 41, Grad norm: 4.836e+01\n",
      "Epoch 3269, Loss: 235.53518676757812, Neurons: 41, Grad norm: 4.825e+01\n",
      "Epoch 3269, Loss: 235.53518676757812, Neurons: 41, Grad norm: 4.825e+01\n",
      "Epoch 3270, Loss: 235.11480712890625, Neurons: 41, Grad norm: 4.814e+01\n",
      "Epoch 3270, Loss: 235.11480712890625, Neurons: 41, Grad norm: 4.814e+01\n",
      "Epoch 3271, Loss: 234.69235229492188, Neurons: 41, Grad norm: 4.803e+01\n",
      "Epoch 3271, Loss: 234.69235229492188, Neurons: 41, Grad norm: 4.803e+01\n",
      "Epoch 3272, Loss: 234.2678680419922, Neurons: 41, Grad norm: 4.792e+01\n",
      "Epoch 3272, Loss: 234.2678680419922, Neurons: 41, Grad norm: 4.792e+01\n",
      "Epoch 3273, Loss: 233.84140014648438, Neurons: 41, Grad norm: 4.781e+01\n",
      "Epoch 3273, Loss: 233.84140014648438, Neurons: 41, Grad norm: 4.781e+01\n",
      "Epoch 3274, Loss: 233.41293334960938, Neurons: 41, Grad norm: 4.770e+01\n",
      "Epoch 3274, Loss: 233.41293334960938, Neurons: 41, Grad norm: 4.770e+01\n",
      "Epoch 3275, Loss: 232.98251342773438, Neurons: 41, Grad norm: 4.759e+01\n",
      "Epoch 3275, Loss: 232.98251342773438, Neurons: 41, Grad norm: 4.759e+01\n",
      "Epoch 3276, Loss: 232.5501708984375, Neurons: 41, Grad norm: 4.748e+01\n",
      "Epoch 3276, Loss: 232.5501708984375, Neurons: 41, Grad norm: 4.748e+01\n",
      "Epoch 3277, Loss: 232.1159210205078, Neurons: 41, Grad norm: 4.737e+01\n",
      "Epoch 3277, Loss: 232.1159210205078, Neurons: 41, Grad norm: 4.737e+01\n",
      "Epoch 3278, Loss: 231.67979431152344, Neurons: 41, Grad norm: 4.726e+01\n",
      "Epoch 3278, Loss: 231.67979431152344, Neurons: 41, Grad norm: 4.726e+01\n",
      "Epoch 3279, Loss: 231.24185180664062, Neurons: 41, Grad norm: 4.714e+01\n",
      "Epoch 3279, Loss: 231.24185180664062, Neurons: 41, Grad norm: 4.714e+01\n",
      "Epoch 3280, Loss: 230.8020782470703, Neurons: 41, Grad norm: 4.703e+01\n",
      "Epoch 3280, Loss: 230.8020782470703, Neurons: 41, Grad norm: 4.703e+01\n",
      "Epoch 3281, Loss: 230.36053466796875, Neurons: 41, Grad norm: 4.692e+01\n",
      "Epoch 3281, Loss: 230.36053466796875, Neurons: 41, Grad norm: 4.692e+01\n",
      "Epoch 3282, Loss: 229.917236328125, Neurons: 41, Grad norm: 4.680e+01\n",
      "Epoch 3282, Loss: 229.917236328125, Neurons: 41, Grad norm: 4.680e+01\n",
      "Epoch 3283, Loss: 229.47222900390625, Neurons: 41, Grad norm: 4.668e+01\n",
      "Epoch 3283, Loss: 229.47222900390625, Neurons: 41, Grad norm: 4.668e+01\n",
      "Epoch 3284, Loss: 229.0255126953125, Neurons: 41, Grad norm: 4.656e+01\n",
      "Epoch 3284, Loss: 229.0255126953125, Neurons: 41, Grad norm: 4.656e+01\n",
      "Epoch 3285, Loss: 228.57716369628906, Neurons: 41, Grad norm: 4.645e+01\n",
      "Epoch 3285, Loss: 228.57716369628906, Neurons: 41, Grad norm: 4.645e+01\n",
      "Epoch 3286, Loss: 228.127197265625, Neurons: 41, Grad norm: 4.633e+01\n",
      "Epoch 3286, Loss: 228.127197265625, Neurons: 41, Grad norm: 4.633e+01\n",
      "Epoch 3287, Loss: 227.67568969726562, Neurons: 41, Grad norm: 4.621e+01\n",
      "Epoch 3287, Loss: 227.67568969726562, Neurons: 41, Grad norm: 4.621e+01\n",
      "Epoch 3288, Loss: 227.2226104736328, Neurons: 41, Grad norm: 4.609e+01\n",
      "Epoch 3288, Loss: 227.2226104736328, Neurons: 41, Grad norm: 4.609e+01\n",
      "Epoch 3289, Loss: 226.76805114746094, Neurons: 41, Grad norm: 4.597e+01\n",
      "Epoch 3289, Loss: 226.76805114746094, Neurons: 41, Grad norm: 4.597e+01\n",
      "Epoch 3290, Loss: 226.31207275390625, Neurons: 41, Grad norm: 4.585e+01\n",
      "Epoch 3290, Loss: 226.31207275390625, Neurons: 41, Grad norm: 4.585e+01\n",
      "Epoch 3291, Loss: 225.8546600341797, Neurons: 41, Grad norm: 4.573e+01\n",
      "Epoch 3291, Loss: 225.8546600341797, Neurons: 41, Grad norm: 4.573e+01\n",
      "Epoch 3292, Loss: 225.39588928222656, Neurons: 41, Grad norm: 4.561e+01\n",
      "Epoch 3292, Loss: 225.39588928222656, Neurons: 41, Grad norm: 4.561e+01\n",
      "Epoch 3293, Loss: 224.93580627441406, Neurons: 41, Grad norm: 4.549e+01\n",
      "Epoch 3293, Loss: 224.93580627441406, Neurons: 41, Grad norm: 4.549e+01\n",
      "Epoch 3294, Loss: 224.47445678710938, Neurons: 41, Grad norm: 4.537e+01\n",
      "Epoch 3294, Loss: 224.47445678710938, Neurons: 41, Grad norm: 4.537e+01\n",
      "Epoch 3295, Loss: 224.0119171142578, Neurons: 41, Grad norm: 4.525e+01\n",
      "Epoch 3295, Loss: 224.0119171142578, Neurons: 41, Grad norm: 4.525e+01\n",
      "Epoch 3296, Loss: 223.54820251464844, Neurons: 41, Grad norm: 4.513e+01\n",
      "Epoch 3296, Loss: 223.54820251464844, Neurons: 41, Grad norm: 4.513e+01\n",
      "Epoch 3297, Loss: 223.08340454101562, Neurons: 41, Grad norm: 4.500e+01\n",
      "Epoch 3297, Loss: 223.08340454101562, Neurons: 41, Grad norm: 4.500e+01\n",
      "Epoch 3298, Loss: 222.61752319335938, Neurons: 41, Grad norm: 4.487e+01\n",
      "Epoch 3298, Loss: 222.61752319335938, Neurons: 41, Grad norm: 4.487e+01\n",
      "Epoch 3299, Loss: 222.15066528320312, Neurons: 41, Grad norm: 4.474e+01\n",
      "Epoch 3299, Loss: 222.15066528320312, Neurons: 41, Grad norm: 4.474e+01\n",
      "Epoch 3299, Test loss: 218.58224487304688\n",
      "Epoch 3299, Test loss: 218.58224487304688\n",
      "Added neuron to hidden layer 2 with activation sin\n",
      "Added neuron to hidden layer 2 with activation sin\n",
      "network shape updated to :[16, 25, 1]\n",
      "network shape updated to :[16, 25, 1]\n",
      "Epoch 3300, Loss: 221.65164184570312, Neurons: 42, Grad norm: 5.712e+01\n",
      "Epoch 3300, Loss: 221.65164184570312, Neurons: 42, Grad norm: 5.712e+01\n",
      "Epoch 3301, Loss: 221.46043395996094, Neurons: 42, Grad norm: 5.149e+01\n",
      "Epoch 3301, Loss: 221.46043395996094, Neurons: 42, Grad norm: 5.149e+01\n",
      "Epoch 3302, Loss: 221.2816925048828, Neurons: 42, Grad norm: 4.849e+01\n",
      "Epoch 3302, Loss: 221.2816925048828, Neurons: 42, Grad norm: 4.849e+01\n",
      "Epoch 3303, Loss: 221.11544799804688, Neurons: 42, Grad norm: 4.774e+01\n",
      "Epoch 3303, Loss: 221.11544799804688, Neurons: 42, Grad norm: 4.774e+01\n",
      "Epoch 3304, Loss: 220.95745849609375, Neurons: 42, Grad norm: 4.814e+01\n",
      "Epoch 3304, Loss: 220.95745849609375, Neurons: 42, Grad norm: 4.814e+01\n",
      "Epoch 3305, Loss: 220.80242919921875, Neurons: 42, Grad norm: 4.874e+01\n",
      "Epoch 3305, Loss: 220.80242919921875, Neurons: 42, Grad norm: 4.874e+01\n",
      "Epoch 3306, Loss: 220.64588928222656, Neurons: 42, Grad norm: 4.908e+01\n",
      "Epoch 3306, Loss: 220.64588928222656, Neurons: 42, Grad norm: 4.908e+01\n",
      "Epoch 3307, Loss: 220.48492431640625, Neurons: 42, Grad norm: 4.907e+01\n",
      "Epoch 3307, Loss: 220.48492431640625, Neurons: 42, Grad norm: 4.907e+01\n",
      "Epoch 3308, Loss: 220.31788635253906, Neurons: 42, Grad norm: 4.874e+01\n",
      "Epoch 3308, Loss: 220.31788635253906, Neurons: 42, Grad norm: 4.874e+01\n",
      "Epoch 3309, Loss: 220.14414978027344, Neurons: 42, Grad norm: 4.827e+01\n",
      "Epoch 3309, Loss: 220.14414978027344, Neurons: 42, Grad norm: 4.827e+01\n",
      "Epoch 3310, Loss: 219.96363830566406, Neurons: 42, Grad norm: 4.779e+01\n",
      "Epoch 3310, Loss: 219.96363830566406, Neurons: 42, Grad norm: 4.779e+01\n",
      "Epoch 3311, Loss: 219.77667236328125, Neurons: 42, Grad norm: 4.739e+01\n",
      "Epoch 3311, Loss: 219.77667236328125, Neurons: 42, Grad norm: 4.739e+01\n",
      "Epoch 3312, Loss: 219.58375549316406, Neurons: 42, Grad norm: 4.713e+01\n",
      "Epoch 3312, Loss: 219.58375549316406, Neurons: 42, Grad norm: 4.713e+01\n",
      "Epoch 3313, Loss: 219.38543701171875, Neurons: 42, Grad norm: 4.701e+01\n",
      "Epoch 3313, Loss: 219.38543701171875, Neurons: 42, Grad norm: 4.701e+01\n",
      "Epoch 3314, Loss: 219.1820068359375, Neurons: 42, Grad norm: 4.698e+01\n",
      "Epoch 3314, Loss: 219.1820068359375, Neurons: 42, Grad norm: 4.698e+01\n",
      "Epoch 3315, Loss: 218.97369384765625, Neurons: 42, Grad norm: 4.699e+01\n",
      "Epoch 3315, Loss: 218.97369384765625, Neurons: 42, Grad norm: 4.699e+01\n",
      "Epoch 3316, Loss: 218.7605438232422, Neurons: 42, Grad norm: 4.695e+01\n",
      "Epoch 3316, Loss: 218.7605438232422, Neurons: 42, Grad norm: 4.695e+01\n",
      "Epoch 3317, Loss: 218.54244995117188, Neurons: 42, Grad norm: 4.685e+01\n",
      "Epoch 3317, Loss: 218.54244995117188, Neurons: 42, Grad norm: 4.685e+01\n",
      "Epoch 3318, Loss: 218.3193817138672, Neurons: 42, Grad norm: 4.667e+01\n",
      "Epoch 3318, Loss: 218.3193817138672, Neurons: 42, Grad norm: 4.667e+01\n",
      "Epoch 3319, Loss: 218.0913848876953, Neurons: 42, Grad norm: 4.643e+01\n",
      "Epoch 3319, Loss: 218.0913848876953, Neurons: 42, Grad norm: 4.643e+01\n",
      "Epoch 3320, Loss: 217.85865783691406, Neurons: 42, Grad norm: 4.616e+01\n",
      "Epoch 3320, Loss: 217.85865783691406, Neurons: 42, Grad norm: 4.616e+01\n",
      "Epoch 3321, Loss: 217.62130737304688, Neurons: 42, Grad norm: 4.591e+01\n",
      "Epoch 3321, Loss: 217.62130737304688, Neurons: 42, Grad norm: 4.591e+01\n",
      "Epoch 3322, Loss: 217.379638671875, Neurons: 42, Grad norm: 4.567e+01\n",
      "Epoch 3322, Loss: 217.379638671875, Neurons: 42, Grad norm: 4.567e+01\n",
      "Epoch 3323, Loss: 217.1337890625, Neurons: 42, Grad norm: 4.548e+01\n",
      "Epoch 3323, Loss: 217.1337890625, Neurons: 42, Grad norm: 4.548e+01\n",
      "Epoch 3324, Loss: 216.88394165039062, Neurons: 42, Grad norm: 4.532e+01\n",
      "Epoch 3324, Loss: 216.88394165039062, Neurons: 42, Grad norm: 4.532e+01\n",
      "Epoch 3325, Loss: 216.6302032470703, Neurons: 42, Grad norm: 4.519e+01\n",
      "Epoch 3325, Loss: 216.6302032470703, Neurons: 42, Grad norm: 4.519e+01\n",
      "Epoch 3326, Loss: 216.3726348876953, Neurons: 42, Grad norm: 4.507e+01\n",
      "Epoch 3326, Loss: 216.3726348876953, Neurons: 42, Grad norm: 4.507e+01\n",
      "Epoch 3327, Loss: 216.11135864257812, Neurons: 42, Grad norm: 4.495e+01\n",
      "Epoch 3327, Loss: 216.11135864257812, Neurons: 42, Grad norm: 4.495e+01\n",
      "Epoch 3328, Loss: 215.84645080566406, Neurons: 42, Grad norm: 4.482e+01\n",
      "Epoch 3328, Loss: 215.84645080566406, Neurons: 42, Grad norm: 4.482e+01\n",
      "Epoch 3329, Loss: 215.57794189453125, Neurons: 42, Grad norm: 4.469e+01\n",
      "Epoch 3329, Loss: 215.57794189453125, Neurons: 42, Grad norm: 4.469e+01\n",
      "Epoch 3330, Loss: 215.3059539794922, Neurons: 42, Grad norm: 4.456e+01\n",
      "Epoch 3330, Loss: 215.3059539794922, Neurons: 42, Grad norm: 4.456e+01\n",
      "Epoch 3331, Loss: 215.03054809570312, Neurons: 42, Grad norm: 4.442e+01\n",
      "Epoch 3331, Loss: 215.03054809570312, Neurons: 42, Grad norm: 4.442e+01\n",
      "Epoch 3332, Loss: 214.7518768310547, Neurons: 42, Grad norm: 4.428e+01\n",
      "Epoch 3332, Loss: 214.7518768310547, Neurons: 42, Grad norm: 4.428e+01\n",
      "Epoch 3333, Loss: 214.4700469970703, Neurons: 42, Grad norm: 4.413e+01\n",
      "Epoch 3333, Loss: 214.4700469970703, Neurons: 42, Grad norm: 4.413e+01\n",
      "Epoch 3334, Loss: 214.18521118164062, Neurons: 42, Grad norm: 4.398e+01\n",
      "Epoch 3334, Loss: 214.18521118164062, Neurons: 42, Grad norm: 4.398e+01\n",
      "Epoch 3335, Loss: 213.89755249023438, Neurons: 42, Grad norm: 4.382e+01\n",
      "Epoch 3335, Loss: 213.89755249023438, Neurons: 42, Grad norm: 4.382e+01\n",
      "Epoch 3336, Loss: 213.6072235107422, Neurons: 42, Grad norm: 4.367e+01\n",
      "Epoch 3336, Loss: 213.6072235107422, Neurons: 42, Grad norm: 4.367e+01\n",
      "Epoch 3337, Loss: 213.31439208984375, Neurons: 42, Grad norm: 4.351e+01\n",
      "Epoch 3337, Loss: 213.31439208984375, Neurons: 42, Grad norm: 4.351e+01\n",
      "Epoch 3338, Loss: 213.0191650390625, Neurons: 42, Grad norm: 4.335e+01\n",
      "Epoch 3338, Loss: 213.0191650390625, Neurons: 42, Grad norm: 4.335e+01\n",
      "Epoch 3339, Loss: 212.72171020507812, Neurons: 42, Grad norm: 4.320e+01\n",
      "Epoch 3339, Loss: 212.72171020507812, Neurons: 42, Grad norm: 4.320e+01\n",
      "Epoch 3340, Loss: 212.42201232910156, Neurons: 42, Grad norm: 4.306e+01\n",
      "Epoch 3340, Loss: 212.42201232910156, Neurons: 42, Grad norm: 4.306e+01\n",
      "Epoch 3341, Loss: 212.12013244628906, Neurons: 42, Grad norm: 4.291e+01\n",
      "Epoch 3341, Loss: 212.12013244628906, Neurons: 42, Grad norm: 4.291e+01\n",
      "Epoch 3342, Loss: 211.816162109375, Neurons: 42, Grad norm: 4.276e+01\n",
      "Epoch 3342, Loss: 211.816162109375, Neurons: 42, Grad norm: 4.276e+01\n",
      "Epoch 3343, Loss: 211.51011657714844, Neurons: 42, Grad norm: 4.261e+01\n",
      "Epoch 3343, Loss: 211.51011657714844, Neurons: 42, Grad norm: 4.261e+01\n",
      "Epoch 3344, Loss: 211.2021026611328, Neurons: 42, Grad norm: 4.246e+01\n",
      "Epoch 3344, Loss: 211.2021026611328, Neurons: 42, Grad norm: 4.246e+01\n",
      "Epoch 3345, Loss: 210.89218139648438, Neurons: 42, Grad norm: 4.231e+01\n",
      "Epoch 3345, Loss: 210.89218139648438, Neurons: 42, Grad norm: 4.231e+01\n",
      "Epoch 3346, Loss: 210.58050537109375, Neurons: 42, Grad norm: 4.216e+01\n",
      "Epoch 3346, Loss: 210.58050537109375, Neurons: 42, Grad norm: 4.216e+01\n",
      "Epoch 3347, Loss: 210.26719665527344, Neurons: 42, Grad norm: 4.200e+01\n",
      "Epoch 3347, Loss: 210.26719665527344, Neurons: 42, Grad norm: 4.200e+01\n",
      "Epoch 3348, Loss: 209.95236206054688, Neurons: 42, Grad norm: 4.184e+01\n",
      "Epoch 3348, Loss: 209.95236206054688, Neurons: 42, Grad norm: 4.184e+01\n",
      "Epoch 3349, Loss: 209.63613891601562, Neurons: 42, Grad norm: 4.169e+01\n",
      "Epoch 3349, Loss: 209.63613891601562, Neurons: 42, Grad norm: 4.169e+01\n",
      "Epoch 3350, Loss: 209.31858825683594, Neurons: 42, Grad norm: 4.153e+01\n",
      "Epoch 3350, Loss: 209.31858825683594, Neurons: 42, Grad norm: 4.153e+01\n",
      "Epoch 3351, Loss: 208.999755859375, Neurons: 42, Grad norm: 4.136e+01\n",
      "Epoch 3351, Loss: 208.999755859375, Neurons: 42, Grad norm: 4.136e+01\n",
      "Epoch 3352, Loss: 208.67974853515625, Neurons: 42, Grad norm: 4.120e+01\n",
      "Epoch 3352, Loss: 208.67974853515625, Neurons: 42, Grad norm: 4.120e+01\n",
      "Epoch 3353, Loss: 208.3585968017578, Neurons: 42, Grad norm: 4.103e+01\n",
      "Epoch 3353, Loss: 208.3585968017578, Neurons: 42, Grad norm: 4.103e+01\n",
      "Epoch 3354, Loss: 208.03634643554688, Neurons: 42, Grad norm: 4.086e+01\n",
      "Epoch 3354, Loss: 208.03634643554688, Neurons: 42, Grad norm: 4.086e+01\n",
      "Epoch 3355, Loss: 207.71310424804688, Neurons: 42, Grad norm: 4.068e+01\n",
      "Epoch 3355, Loss: 207.71310424804688, Neurons: 42, Grad norm: 4.068e+01\n",
      "Epoch 3356, Loss: 207.388916015625, Neurons: 42, Grad norm: 4.051e+01\n",
      "Epoch 3356, Loss: 207.388916015625, Neurons: 42, Grad norm: 4.051e+01\n",
      "Epoch 3357, Loss: 207.06387329101562, Neurons: 42, Grad norm: 4.033e+01\n",
      "Epoch 3357, Loss: 207.06387329101562, Neurons: 42, Grad norm: 4.033e+01\n",
      "Epoch 3358, Loss: 206.73802185058594, Neurons: 42, Grad norm: 4.016e+01\n",
      "Epoch 3358, Loss: 206.73802185058594, Neurons: 42, Grad norm: 4.016e+01\n",
      "Epoch 3359, Loss: 206.4114532470703, Neurons: 42, Grad norm: 3.998e+01\n",
      "Epoch 3359, Loss: 206.4114532470703, Neurons: 42, Grad norm: 3.998e+01\n",
      "Epoch 3360, Loss: 206.08419799804688, Neurons: 42, Grad norm: 3.980e+01\n",
      "Epoch 3360, Loss: 206.08419799804688, Neurons: 42, Grad norm: 3.980e+01\n",
      "Epoch 3361, Loss: 205.75631713867188, Neurons: 42, Grad norm: 3.963e+01\n",
      "Epoch 3361, Loss: 205.75631713867188, Neurons: 42, Grad norm: 3.963e+01\n",
      "Epoch 3362, Loss: 205.4279022216797, Neurons: 42, Grad norm: 3.946e+01\n",
      "Epoch 3362, Loss: 205.4279022216797, Neurons: 42, Grad norm: 3.946e+01\n",
      "Epoch 3363, Loss: 205.0989227294922, Neurons: 42, Grad norm: 3.929e+01\n",
      "Epoch 3363, Loss: 205.0989227294922, Neurons: 42, Grad norm: 3.929e+01\n",
      "Epoch 3364, Loss: 204.7694854736328, Neurons: 42, Grad norm: 3.912e+01\n",
      "Epoch 3364, Loss: 204.7694854736328, Neurons: 42, Grad norm: 3.912e+01\n",
      "Epoch 3365, Loss: 204.43960571289062, Neurons: 42, Grad norm: 3.896e+01\n",
      "Epoch 3365, Loss: 204.43960571289062, Neurons: 42, Grad norm: 3.896e+01\n",
      "Epoch 3366, Loss: 204.109375, Neurons: 42, Grad norm: 3.880e+01\n",
      "Epoch 3366, Loss: 204.109375, Neurons: 42, Grad norm: 3.880e+01\n",
      "Epoch 3367, Loss: 203.77882385253906, Neurons: 42, Grad norm: 3.863e+01\n",
      "Epoch 3367, Loss: 203.77882385253906, Neurons: 42, Grad norm: 3.863e+01\n",
      "Epoch 3368, Loss: 203.44798278808594, Neurons: 42, Grad norm: 3.847e+01\n",
      "Epoch 3368, Loss: 203.44798278808594, Neurons: 42, Grad norm: 3.847e+01\n",
      "Epoch 3369, Loss: 203.11688232421875, Neurons: 42, Grad norm: 3.831e+01\n",
      "Epoch 3369, Loss: 203.11688232421875, Neurons: 42, Grad norm: 3.831e+01\n",
      "Epoch 3370, Loss: 202.7855987548828, Neurons: 42, Grad norm: 3.814e+01\n",
      "Epoch 3370, Loss: 202.7855987548828, Neurons: 42, Grad norm: 3.814e+01\n",
      "Epoch 3371, Loss: 202.45416259765625, Neurons: 42, Grad norm: 3.798e+01\n",
      "Epoch 3371, Loss: 202.45416259765625, Neurons: 42, Grad norm: 3.798e+01\n",
      "Epoch 3372, Loss: 202.12257385253906, Neurons: 42, Grad norm: 3.782e+01\n",
      "Epoch 3372, Loss: 202.12257385253906, Neurons: 42, Grad norm: 3.782e+01\n",
      "Epoch 3373, Loss: 201.79090881347656, Neurons: 42, Grad norm: 3.766e+01\n",
      "Epoch 3373, Loss: 201.79090881347656, Neurons: 42, Grad norm: 3.766e+01\n",
      "Epoch 3374, Loss: 201.45919799804688, Neurons: 42, Grad norm: 3.749e+01\n",
      "Epoch 3374, Loss: 201.45919799804688, Neurons: 42, Grad norm: 3.749e+01\n",
      "Epoch 3375, Loss: 201.1273956298828, Neurons: 42, Grad norm: 3.733e+01\n",
      "Epoch 3375, Loss: 201.1273956298828, Neurons: 42, Grad norm: 3.733e+01\n",
      "Epoch 3376, Loss: 200.79562377929688, Neurons: 42, Grad norm: 3.716e+01\n",
      "Epoch 3376, Loss: 200.79562377929688, Neurons: 42, Grad norm: 3.716e+01\n",
      "Epoch 3377, Loss: 200.46385192871094, Neurons: 42, Grad norm: 3.700e+01\n",
      "Epoch 3377, Loss: 200.46385192871094, Neurons: 42, Grad norm: 3.700e+01\n",
      "Epoch 3378, Loss: 200.1321563720703, Neurons: 42, Grad norm: 3.683e+01\n",
      "Epoch 3378, Loss: 200.1321563720703, Neurons: 42, Grad norm: 3.683e+01\n",
      "Epoch 3379, Loss: 199.8004913330078, Neurons: 42, Grad norm: 3.667e+01\n",
      "Epoch 3379, Loss: 199.8004913330078, Neurons: 42, Grad norm: 3.667e+01\n",
      "Epoch 3380, Loss: 199.4689483642578, Neurons: 42, Grad norm: 3.651e+01\n",
      "Epoch 3380, Loss: 199.4689483642578, Neurons: 42, Grad norm: 3.651e+01\n",
      "Epoch 3381, Loss: 199.13751220703125, Neurons: 42, Grad norm: 3.635e+01\n",
      "Epoch 3381, Loss: 199.13751220703125, Neurons: 42, Grad norm: 3.635e+01\n",
      "Epoch 3382, Loss: 198.8061981201172, Neurons: 42, Grad norm: 3.619e+01\n",
      "Epoch 3382, Loss: 198.8061981201172, Neurons: 42, Grad norm: 3.619e+01\n",
      "Epoch 3383, Loss: 198.47503662109375, Neurons: 42, Grad norm: 3.604e+01\n",
      "Epoch 3383, Loss: 198.47503662109375, Neurons: 42, Grad norm: 3.604e+01\n",
      "Epoch 3384, Loss: 198.14405822753906, Neurons: 42, Grad norm: 3.588e+01\n",
      "Epoch 3384, Loss: 198.14405822753906, Neurons: 42, Grad norm: 3.588e+01\n",
      "Epoch 3385, Loss: 197.81326293945312, Neurons: 42, Grad norm: 3.573e+01\n",
      "Epoch 3385, Loss: 197.81326293945312, Neurons: 42, Grad norm: 3.573e+01\n",
      "Epoch 3386, Loss: 197.482666015625, Neurons: 42, Grad norm: 3.558e+01\n",
      "Epoch 3386, Loss: 197.482666015625, Neurons: 42, Grad norm: 3.558e+01\n",
      "Epoch 3387, Loss: 197.15225219726562, Neurons: 42, Grad norm: 3.543e+01\n",
      "Epoch 3387, Loss: 197.15225219726562, Neurons: 42, Grad norm: 3.543e+01\n",
      "Epoch 3388, Loss: 196.82208251953125, Neurons: 42, Grad norm: 3.528e+01\n",
      "Epoch 3388, Loss: 196.82208251953125, Neurons: 42, Grad norm: 3.528e+01\n",
      "Epoch 3389, Loss: 196.49215698242188, Neurons: 42, Grad norm: 3.513e+01\n",
      "Epoch 3389, Loss: 196.49215698242188, Neurons: 42, Grad norm: 3.513e+01\n",
      "Epoch 3390, Loss: 196.16244506835938, Neurons: 42, Grad norm: 3.498e+01\n",
      "Epoch 3390, Loss: 196.16244506835938, Neurons: 42, Grad norm: 3.498e+01\n",
      "Epoch 3391, Loss: 195.83299255371094, Neurons: 42, Grad norm: 3.483e+01\n",
      "Epoch 3391, Loss: 195.83299255371094, Neurons: 42, Grad norm: 3.483e+01\n",
      "Epoch 3392, Loss: 195.50379943847656, Neurons: 42, Grad norm: 3.468e+01\n",
      "Epoch 3392, Loss: 195.50379943847656, Neurons: 42, Grad norm: 3.468e+01\n",
      "Epoch 3393, Loss: 195.17489624023438, Neurons: 42, Grad norm: 3.453e+01\n",
      "Epoch 3393, Loss: 195.17489624023438, Neurons: 42, Grad norm: 3.453e+01\n",
      "Epoch 3394, Loss: 194.84625244140625, Neurons: 42, Grad norm: 3.439e+01\n",
      "Epoch 3394, Loss: 194.84625244140625, Neurons: 42, Grad norm: 3.439e+01\n",
      "Epoch 3395, Loss: 194.5178985595703, Neurons: 42, Grad norm: 3.424e+01\n",
      "Epoch 3395, Loss: 194.5178985595703, Neurons: 42, Grad norm: 3.424e+01\n",
      "Epoch 3396, Loss: 194.18984985351562, Neurons: 42, Grad norm: 3.410e+01\n",
      "Epoch 3396, Loss: 194.18984985351562, Neurons: 42, Grad norm: 3.410e+01\n",
      "Epoch 3397, Loss: 193.86209106445312, Neurons: 42, Grad norm: 3.396e+01\n",
      "Epoch 3397, Loss: 193.86209106445312, Neurons: 42, Grad norm: 3.396e+01\n",
      "Epoch 3398, Loss: 193.53460693359375, Neurons: 42, Grad norm: 3.382e+01\n",
      "Epoch 3398, Loss: 193.53460693359375, Neurons: 42, Grad norm: 3.382e+01\n",
      "Epoch 3399, Loss: 193.20742797851562, Neurons: 42, Grad norm: 3.368e+01\n",
      "Epoch 3399, Loss: 193.20742797851562, Neurons: 42, Grad norm: 3.368e+01\n",
      "Epoch 3399, Test loss: 189.05938720703125\n",
      "Epoch 3399, Test loss: 189.05938720703125\n",
      "Added neuron to hidden layer 1 with activation sin\n",
      "Added neuron to hidden layer 1 with activation sin\n",
      "network shape updated to :[17, 25, 1]\n",
      "network shape updated to :[17, 25, 1]\n",
      "Epoch 3400, Loss: 747.8096313476562, Neurons: 43, Grad norm: 1.230e+03\n",
      "Epoch 3400, Loss: 747.8096313476562, Neurons: 43, Grad norm: 1.230e+03\n",
      "Epoch 3401, Loss: 744.5679321289062, Neurons: 43, Grad norm: 1.231e+03\n",
      "Epoch 3401, Loss: 744.5679321289062, Neurons: 43, Grad norm: 1.231e+03\n",
      "Epoch 3402, Loss: 741.1597900390625, Neurons: 43, Grad norm: 1.233e+03\n",
      "Epoch 3402, Loss: 741.1597900390625, Neurons: 43, Grad norm: 1.233e+03\n",
      "Epoch 3403, Loss: 737.5831298828125, Neurons: 43, Grad norm: 1.234e+03\n",
      "Epoch 3403, Loss: 737.5831298828125, Neurons: 43, Grad norm: 1.234e+03\n",
      "Epoch 3404, Loss: 733.836669921875, Neurons: 43, Grad norm: 1.236e+03\n",
      "Epoch 3404, Loss: 733.836669921875, Neurons: 43, Grad norm: 1.236e+03\n",
      "Epoch 3405, Loss: 729.91943359375, Neurons: 43, Grad norm: 1.237e+03\n",
      "Epoch 3405, Loss: 729.91943359375, Neurons: 43, Grad norm: 1.237e+03\n",
      "Epoch 3406, Loss: 725.831298828125, Neurons: 43, Grad norm: 1.238e+03\n",
      "Epoch 3406, Loss: 725.831298828125, Neurons: 43, Grad norm: 1.238e+03\n",
      "Epoch 3407, Loss: 721.5723876953125, Neurons: 43, Grad norm: 1.239e+03\n",
      "Epoch 3407, Loss: 721.5723876953125, Neurons: 43, Grad norm: 1.239e+03\n",
      "Epoch 3408, Loss: 717.1430053710938, Neurons: 43, Grad norm: 1.241e+03\n",
      "Epoch 3408, Loss: 717.1430053710938, Neurons: 43, Grad norm: 1.241e+03\n",
      "Epoch 3409, Loss: 712.5445556640625, Neurons: 43, Grad norm: 1.241e+03\n",
      "Epoch 3409, Loss: 712.5445556640625, Neurons: 43, Grad norm: 1.241e+03\n",
      "Epoch 3410, Loss: 707.7785034179688, Neurons: 43, Grad norm: 1.242e+03\n",
      "Epoch 3410, Loss: 707.7785034179688, Neurons: 43, Grad norm: 1.242e+03\n",
      "Epoch 3411, Loss: 702.84716796875, Neurons: 43, Grad norm: 1.243e+03\n",
      "Epoch 3411, Loss: 702.84716796875, Neurons: 43, Grad norm: 1.243e+03\n",
      "Epoch 3412, Loss: 697.7528686523438, Neurons: 43, Grad norm: 1.244e+03\n",
      "Epoch 3412, Loss: 697.7528686523438, Neurons: 43, Grad norm: 1.244e+03\n",
      "Epoch 3413, Loss: 692.4981689453125, Neurons: 43, Grad norm: 1.244e+03\n",
      "Epoch 3413, Loss: 692.4981689453125, Neurons: 43, Grad norm: 1.244e+03\n",
      "Epoch 3414, Loss: 687.08642578125, Neurons: 43, Grad norm: 1.244e+03\n",
      "Epoch 3414, Loss: 687.08642578125, Neurons: 43, Grad norm: 1.244e+03\n",
      "Epoch 3415, Loss: 681.5210571289062, Neurons: 43, Grad norm: 1.244e+03\n",
      "Epoch 3415, Loss: 681.5210571289062, Neurons: 43, Grad norm: 1.244e+03\n",
      "Epoch 3416, Loss: 675.8054809570312, Neurons: 43, Grad norm: 1.244e+03\n",
      "Epoch 3416, Loss: 675.8054809570312, Neurons: 43, Grad norm: 1.244e+03\n",
      "Epoch 3417, Loss: 669.9437255859375, Neurons: 43, Grad norm: 1.244e+03\n",
      "Epoch 3417, Loss: 669.9437255859375, Neurons: 43, Grad norm: 1.244e+03\n",
      "Epoch 3418, Loss: 663.9398803710938, Neurons: 43, Grad norm: 1.243e+03\n",
      "Epoch 3418, Loss: 663.9398803710938, Neurons: 43, Grad norm: 1.243e+03\n",
      "Epoch 3419, Loss: 657.7986450195312, Neurons: 43, Grad norm: 1.242e+03\n",
      "Epoch 3419, Loss: 657.7986450195312, Neurons: 43, Grad norm: 1.242e+03\n",
      "Epoch 3420, Loss: 651.5245361328125, Neurons: 43, Grad norm: 1.241e+03\n",
      "Epoch 3420, Loss: 651.5245361328125, Neurons: 43, Grad norm: 1.241e+03\n",
      "Epoch 3421, Loss: 645.122802734375, Neurons: 43, Grad norm: 1.239e+03\n",
      "Epoch 3421, Loss: 645.122802734375, Neurons: 43, Grad norm: 1.239e+03\n",
      "Epoch 3422, Loss: 638.5980834960938, Neurons: 43, Grad norm: 1.237e+03\n",
      "Epoch 3422, Loss: 638.5980834960938, Neurons: 43, Grad norm: 1.237e+03\n",
      "Epoch 3423, Loss: 631.9557495117188, Neurons: 43, Grad norm: 1.235e+03\n",
      "Epoch 3423, Loss: 631.9557495117188, Neurons: 43, Grad norm: 1.235e+03\n",
      "Epoch 3424, Loss: 625.2013549804688, Neurons: 43, Grad norm: 1.233e+03\n",
      "Epoch 3424, Loss: 625.2013549804688, Neurons: 43, Grad norm: 1.233e+03\n",
      "Epoch 3425, Loss: 618.3406372070312, Neurons: 43, Grad norm: 1.230e+03\n",
      "Epoch 3425, Loss: 618.3406372070312, Neurons: 43, Grad norm: 1.230e+03\n",
      "Epoch 3426, Loss: 611.37939453125, Neurons: 43, Grad norm: 1.226e+03\n",
      "Epoch 3426, Loss: 611.37939453125, Neurons: 43, Grad norm: 1.226e+03\n",
      "Epoch 3427, Loss: 604.32373046875, Neurons: 43, Grad norm: 1.223e+03\n",
      "Epoch 3427, Loss: 604.32373046875, Neurons: 43, Grad norm: 1.223e+03\n",
      "Epoch 3428, Loss: 597.1795043945312, Neurons: 43, Grad norm: 1.219e+03\n",
      "Epoch 3428, Loss: 597.1795043945312, Neurons: 43, Grad norm: 1.219e+03\n",
      "Epoch 3429, Loss: 589.9530029296875, Neurons: 43, Grad norm: 1.214e+03\n",
      "Epoch 3429, Loss: 589.9530029296875, Neurons: 43, Grad norm: 1.214e+03\n",
      "Epoch 3430, Loss: 582.650146484375, Neurons: 43, Grad norm: 1.209e+03\n",
      "Epoch 3430, Loss: 582.650146484375, Neurons: 43, Grad norm: 1.209e+03\n",
      "Epoch 3431, Loss: 575.2777099609375, Neurons: 43, Grad norm: 1.204e+03\n",
      "Epoch 3431, Loss: 575.2777099609375, Neurons: 43, Grad norm: 1.204e+03\n",
      "Epoch 3432, Loss: 567.8427734375, Neurons: 43, Grad norm: 1.198e+03\n",
      "Epoch 3432, Loss: 567.8427734375, Neurons: 43, Grad norm: 1.198e+03\n",
      "Epoch 3433, Loss: 560.3522338867188, Neurons: 43, Grad norm: 1.191e+03\n",
      "Epoch 3433, Loss: 560.3522338867188, Neurons: 43, Grad norm: 1.191e+03\n",
      "Epoch 3434, Loss: 552.8135986328125, Neurons: 43, Grad norm: 1.185e+03\n",
      "Epoch 3434, Loss: 552.8135986328125, Neurons: 43, Grad norm: 1.185e+03\n",
      "Epoch 3435, Loss: 545.2335205078125, Neurons: 43, Grad norm: 1.177e+03\n",
      "Epoch 3435, Loss: 545.2335205078125, Neurons: 43, Grad norm: 1.177e+03\n",
      "Epoch 3436, Loss: 537.6196899414062, Neurons: 43, Grad norm: 1.170e+03\n",
      "Epoch 3436, Loss: 537.6196899414062, Neurons: 43, Grad norm: 1.170e+03\n",
      "Epoch 3437, Loss: 529.9780883789062, Neurons: 43, Grad norm: 1.162e+03\n",
      "Epoch 3437, Loss: 529.9780883789062, Neurons: 43, Grad norm: 1.162e+03\n",
      "Epoch 3438, Loss: 522.3125610351562, Neurons: 43, Grad norm: 1.154e+03\n",
      "Epoch 3438, Loss: 522.3125610351562, Neurons: 43, Grad norm: 1.154e+03\n",
      "Epoch 3439, Loss: 514.6307373046875, Neurons: 43, Grad norm: 1.145e+03\n",
      "Epoch 3439, Loss: 514.6307373046875, Neurons: 43, Grad norm: 1.145e+03\n",
      "Epoch 3440, Loss: 506.9401550292969, Neurons: 43, Grad norm: 1.135e+03\n",
      "Epoch 3440, Loss: 506.9401550292969, Neurons: 43, Grad norm: 1.135e+03\n",
      "Epoch 3441, Loss: 499.24884033203125, Neurons: 43, Grad norm: 1.125e+03\n",
      "Epoch 3441, Loss: 499.24884033203125, Neurons: 43, Grad norm: 1.125e+03\n",
      "Epoch 3442, Loss: 491.5650939941406, Neurons: 43, Grad norm: 1.115e+03\n",
      "Epoch 3442, Loss: 491.5650939941406, Neurons: 43, Grad norm: 1.115e+03\n",
      "Epoch 3443, Loss: 483.8974914550781, Neurons: 43, Grad norm: 1.104e+03\n",
      "Epoch 3443, Loss: 483.8974914550781, Neurons: 43, Grad norm: 1.104e+03\n",
      "Epoch 3444, Loss: 476.2546081542969, Neurons: 43, Grad norm: 1.093e+03\n",
      "Epoch 3444, Loss: 476.2546081542969, Neurons: 43, Grad norm: 1.093e+03\n",
      "Epoch 3445, Loss: 468.64501953125, Neurons: 43, Grad norm: 1.081e+03\n",
      "Epoch 3445, Loss: 468.64501953125, Neurons: 43, Grad norm: 1.081e+03\n",
      "Epoch 3446, Loss: 461.076904296875, Neurons: 43, Grad norm: 1.069e+03\n",
      "Epoch 3446, Loss: 461.076904296875, Neurons: 43, Grad norm: 1.069e+03\n",
      "Epoch 3447, Loss: 453.55877685546875, Neurons: 43, Grad norm: 1.056e+03\n",
      "Epoch 3447, Loss: 453.55877685546875, Neurons: 43, Grad norm: 1.056e+03\n",
      "Epoch 3448, Loss: 446.0990295410156, Neurons: 43, Grad norm: 1.043e+03\n",
      "Epoch 3448, Loss: 446.0990295410156, Neurons: 43, Grad norm: 1.043e+03\n",
      "Epoch 3449, Loss: 438.7053527832031, Neurons: 43, Grad norm: 1.029e+03\n",
      "Epoch 3449, Loss: 438.7053527832031, Neurons: 43, Grad norm: 1.029e+03\n",
      "Epoch 3450, Loss: 431.3852844238281, Neurons: 43, Grad norm: 1.015e+03\n",
      "Epoch 3450, Loss: 431.3852844238281, Neurons: 43, Grad norm: 1.015e+03\n",
      "Epoch 3451, Loss: 424.1467590332031, Neurons: 43, Grad norm: 1.001e+03\n",
      "Epoch 3451, Loss: 424.1467590332031, Neurons: 43, Grad norm: 1.001e+03\n",
      "Epoch 3452, Loss: 416.99688720703125, Neurons: 43, Grad norm: 9.863e+02\n",
      "Epoch 3452, Loss: 416.99688720703125, Neurons: 43, Grad norm: 9.863e+02\n",
      "Epoch 3453, Loss: 409.94158935546875, Neurons: 43, Grad norm: 9.713e+02\n",
      "Epoch 3453, Loss: 409.94158935546875, Neurons: 43, Grad norm: 9.713e+02\n",
      "Epoch 3454, Loss: 402.9873962402344, Neurons: 43, Grad norm: 9.560e+02\n",
      "Epoch 3454, Loss: 402.9873962402344, Neurons: 43, Grad norm: 9.560e+02\n",
      "Epoch 3455, Loss: 396.1408996582031, Neurons: 43, Grad norm: 9.405e+02\n",
      "Epoch 3455, Loss: 396.1408996582031, Neurons: 43, Grad norm: 9.405e+02\n",
      "Epoch 3456, Loss: 389.40771484375, Neurons: 43, Grad norm: 9.248e+02\n",
      "Epoch 3456, Loss: 389.40771484375, Neurons: 43, Grad norm: 9.248e+02\n",
      "Epoch 3457, Loss: 382.7922058105469, Neurons: 43, Grad norm: 9.088e+02\n",
      "Epoch 3457, Loss: 382.7922058105469, Neurons: 43, Grad norm: 9.088e+02\n",
      "Epoch 3458, Loss: 376.2995910644531, Neurons: 43, Grad norm: 8.926e+02\n",
      "Epoch 3458, Loss: 376.2995910644531, Neurons: 43, Grad norm: 8.926e+02\n",
      "Epoch 3459, Loss: 369.9343566894531, Neurons: 43, Grad norm: 8.764e+02\n",
      "Epoch 3459, Loss: 369.9343566894531, Neurons: 43, Grad norm: 8.764e+02\n",
      "Epoch 3460, Loss: 363.7003173828125, Neurons: 43, Grad norm: 8.599e+02\n",
      "Epoch 3460, Loss: 363.7003173828125, Neurons: 43, Grad norm: 8.599e+02\n",
      "Epoch 3461, Loss: 357.6011962890625, Neurons: 43, Grad norm: 8.433e+02\n",
      "Epoch 3461, Loss: 357.6011962890625, Neurons: 43, Grad norm: 8.433e+02\n",
      "Epoch 3462, Loss: 351.640869140625, Neurons: 43, Grad norm: 8.267e+02\n",
      "Epoch 3462, Loss: 351.640869140625, Neurons: 43, Grad norm: 8.267e+02\n",
      "Epoch 3463, Loss: 345.8226318359375, Neurons: 43, Grad norm: 8.100e+02\n",
      "Epoch 3463, Loss: 345.8226318359375, Neurons: 43, Grad norm: 8.100e+02\n",
      "Epoch 3464, Loss: 340.14935302734375, Neurons: 43, Grad norm: 7.932e+02\n",
      "Epoch 3464, Loss: 340.14935302734375, Neurons: 43, Grad norm: 7.932e+02\n",
      "Epoch 3465, Loss: 334.62445068359375, Neurons: 43, Grad norm: 7.764e+02\n",
      "Epoch 3465, Loss: 334.62445068359375, Neurons: 43, Grad norm: 7.764e+02\n",
      "Epoch 3466, Loss: 329.2506408691406, Neurons: 43, Grad norm: 7.597e+02\n",
      "Epoch 3466, Loss: 329.2506408691406, Neurons: 43, Grad norm: 7.597e+02\n",
      "Epoch 3467, Loss: 324.0299377441406, Neurons: 43, Grad norm: 7.431e+02\n",
      "Epoch 3467, Loss: 324.0299377441406, Neurons: 43, Grad norm: 7.431e+02\n",
      "Epoch 3468, Loss: 318.9641418457031, Neurons: 43, Grad norm: 7.266e+02\n",
      "Epoch 3468, Loss: 318.9641418457031, Neurons: 43, Grad norm: 7.266e+02\n",
      "Epoch 3469, Loss: 314.0544738769531, Neurons: 43, Grad norm: 7.102e+02\n",
      "Epoch 3469, Loss: 314.0544738769531, Neurons: 43, Grad norm: 7.102e+02\n",
      "Epoch 3470, Loss: 309.3013916015625, Neurons: 43, Grad norm: 6.939e+02\n",
      "Epoch 3470, Loss: 309.3013916015625, Neurons: 43, Grad norm: 6.939e+02\n",
      "Epoch 3471, Loss: 304.7043762207031, Neurons: 43, Grad norm: 6.779e+02\n",
      "Epoch 3471, Loss: 304.7043762207031, Neurons: 43, Grad norm: 6.779e+02\n",
      "Epoch 3472, Loss: 300.2613830566406, Neurons: 43, Grad norm: 6.621e+02\n",
      "Epoch 3472, Loss: 300.2613830566406, Neurons: 43, Grad norm: 6.621e+02\n",
      "Epoch 3473, Loss: 295.9698181152344, Neurons: 43, Grad norm: 6.466e+02\n",
      "Epoch 3473, Loss: 295.9698181152344, Neurons: 43, Grad norm: 6.466e+02\n",
      "Epoch 3474, Loss: 291.825927734375, Neurons: 43, Grad norm: 6.314e+02\n",
      "Epoch 3474, Loss: 291.825927734375, Neurons: 43, Grad norm: 6.314e+02\n",
      "Epoch 3475, Loss: 287.8253479003906, Neurons: 43, Grad norm: 6.165e+02\n",
      "Epoch 3475, Loss: 287.8253479003906, Neurons: 43, Grad norm: 6.165e+02\n",
      "Epoch 3476, Loss: 283.9639587402344, Neurons: 43, Grad norm: 6.020e+02\n",
      "Epoch 3476, Loss: 283.9639587402344, Neurons: 43, Grad norm: 6.020e+02\n",
      "Epoch 3477, Loss: 280.2370910644531, Neurons: 43, Grad norm: 5.877e+02\n",
      "Epoch 3477, Loss: 280.2370910644531, Neurons: 43, Grad norm: 5.877e+02\n",
      "Epoch 3478, Loss: 276.6402282714844, Neurons: 43, Grad norm: 5.737e+02\n",
      "Epoch 3478, Loss: 276.6402282714844, Neurons: 43, Grad norm: 5.737e+02\n",
      "Epoch 3479, Loss: 273.1693115234375, Neurons: 43, Grad norm: 5.600e+02\n",
      "Epoch 3479, Loss: 273.1693115234375, Neurons: 43, Grad norm: 5.600e+02\n",
      "Epoch 3480, Loss: 269.8201904296875, Neurons: 43, Grad norm: 5.466e+02\n",
      "Epoch 3480, Loss: 269.8201904296875, Neurons: 43, Grad norm: 5.466e+02\n",
      "Epoch 3481, Loss: 266.5892639160156, Neurons: 43, Grad norm: 5.336e+02\n",
      "Epoch 3481, Loss: 266.5892639160156, Neurons: 43, Grad norm: 5.336e+02\n",
      "Epoch 3482, Loss: 263.4726867675781, Neurons: 43, Grad norm: 5.210e+02\n",
      "Epoch 3482, Loss: 263.4726867675781, Neurons: 43, Grad norm: 5.210e+02\n",
      "Epoch 3483, Loss: 260.4660339355469, Neurons: 43, Grad norm: 5.088e+02\n",
      "Epoch 3483, Loss: 260.4660339355469, Neurons: 43, Grad norm: 5.088e+02\n",
      "Epoch 3484, Loss: 257.5659484863281, Neurons: 43, Grad norm: 4.967e+02\n",
      "Epoch 3484, Loss: 257.5659484863281, Neurons: 43, Grad norm: 4.967e+02\n",
      "Epoch 3485, Loss: 254.76901245117188, Neurons: 43, Grad norm: 4.850e+02\n",
      "Epoch 3485, Loss: 254.76901245117188, Neurons: 43, Grad norm: 4.850e+02\n",
      "Epoch 3486, Loss: 252.07254028320312, Neurons: 43, Grad norm: 4.733e+02\n",
      "Epoch 3486, Loss: 252.07254028320312, Neurons: 43, Grad norm: 4.733e+02\n",
      "Epoch 3487, Loss: 249.47410583496094, Neurons: 43, Grad norm: 4.619e+02\n",
      "Epoch 3487, Loss: 249.47410583496094, Neurons: 43, Grad norm: 4.619e+02\n",
      "Epoch 3488, Loss: 246.97108459472656, Neurons: 43, Grad norm: 4.508e+02\n",
      "Epoch 3488, Loss: 246.97108459472656, Neurons: 43, Grad norm: 4.508e+02\n",
      "Epoch 3489, Loss: 244.56117248535156, Neurons: 43, Grad norm: 4.401e+02\n",
      "Epoch 3489, Loss: 244.56117248535156, Neurons: 43, Grad norm: 4.401e+02\n",
      "Epoch 3490, Loss: 242.24166870117188, Neurons: 43, Grad norm: 4.297e+02\n",
      "Epoch 3490, Loss: 242.24166870117188, Neurons: 43, Grad norm: 4.297e+02\n",
      "Epoch 3491, Loss: 240.00888061523438, Neurons: 43, Grad norm: 4.195e+02\n",
      "Epoch 3491, Loss: 240.00888061523438, Neurons: 43, Grad norm: 4.195e+02\n",
      "Epoch 3492, Loss: 237.86073303222656, Neurons: 43, Grad norm: 4.096e+02\n",
      "Epoch 3492, Loss: 237.86073303222656, Neurons: 43, Grad norm: 4.096e+02\n",
      "Epoch 3493, Loss: 235.7947540283203, Neurons: 43, Grad norm: 3.999e+02\n",
      "Epoch 3493, Loss: 235.7947540283203, Neurons: 43, Grad norm: 3.999e+02\n",
      "Epoch 3494, Loss: 233.8087921142578, Neurons: 43, Grad norm: 3.902e+02\n",
      "Epoch 3494, Loss: 233.8087921142578, Neurons: 43, Grad norm: 3.902e+02\n",
      "Epoch 3495, Loss: 231.9012451171875, Neurons: 43, Grad norm: 3.807e+02\n",
      "Epoch 3495, Loss: 231.9012451171875, Neurons: 43, Grad norm: 3.807e+02\n",
      "Epoch 3496, Loss: 230.07015991210938, Neurons: 43, Grad norm: 3.715e+02\n",
      "Epoch 3496, Loss: 230.07015991210938, Neurons: 43, Grad norm: 3.715e+02\n",
      "Epoch 3497, Loss: 228.31350708007812, Neurons: 43, Grad norm: 3.625e+02\n",
      "Epoch 3497, Loss: 228.31350708007812, Neurons: 43, Grad norm: 3.625e+02\n",
      "Epoch 3498, Loss: 226.62904357910156, Neurons: 43, Grad norm: 3.537e+02\n",
      "Epoch 3498, Loss: 226.62904357910156, Neurons: 43, Grad norm: 3.537e+02\n",
      "Epoch 3499, Loss: 225.0144500732422, Neurons: 43, Grad norm: 3.451e+02\n",
      "Epoch 3499, Loss: 225.0144500732422, Neurons: 43, Grad norm: 3.451e+02\n",
      "Epoch 3499, Test loss: 220.6807861328125\n",
      "Epoch 3499, Test loss: 220.6807861328125\n",
      "Removed neuron to hidden layer 1 at index 16\n",
      "Removed neuron to hidden layer 1 at index 16\n",
      "network shape updated to :[16, 25, 1]\n",
      "network shape updated to :[16, 25, 1]\n",
      "Epoch 3500, Loss: 437.19158935546875, Neurons: 42, Grad norm: 1.138e+03\n",
      "Epoch 3500, Loss: 437.19158935546875, Neurons: 42, Grad norm: 1.138e+03\n",
      "Epoch 3501, Loss: 434.5925598144531, Neurons: 42, Grad norm: 1.131e+03\n",
      "Epoch 3501, Loss: 434.5925598144531, Neurons: 42, Grad norm: 1.131e+03\n",
      "Epoch 3502, Loss: 431.8753662109375, Neurons: 42, Grad norm: 1.123e+03\n",
      "Epoch 3502, Loss: 431.8753662109375, Neurons: 42, Grad norm: 1.123e+03\n",
      "Epoch 3503, Loss: 429.04107666015625, Neurons: 42, Grad norm: 1.115e+03\n",
      "Epoch 3503, Loss: 429.04107666015625, Neurons: 42, Grad norm: 1.115e+03\n",
      "Epoch 3504, Loss: 426.09149169921875, Neurons: 42, Grad norm: 1.107e+03\n",
      "Epoch 3504, Loss: 426.09149169921875, Neurons: 42, Grad norm: 1.107e+03\n",
      "Epoch 3505, Loss: 423.0290832519531, Neurons: 42, Grad norm: 1.098e+03\n",
      "Epoch 3505, Loss: 423.0290832519531, Neurons: 42, Grad norm: 1.098e+03\n",
      "Epoch 3506, Loss: 419.8570861816406, Neurons: 42, Grad norm: 1.089e+03\n",
      "Epoch 3506, Loss: 419.8570861816406, Neurons: 42, Grad norm: 1.089e+03\n",
      "Epoch 3507, Loss: 416.5843811035156, Neurons: 42, Grad norm: 1.079e+03\n",
      "Epoch 3507, Loss: 416.5843811035156, Neurons: 42, Grad norm: 1.079e+03\n",
      "Epoch 3508, Loss: 413.2282409667969, Neurons: 42, Grad norm: 1.069e+03\n",
      "Epoch 3508, Loss: 413.2282409667969, Neurons: 42, Grad norm: 1.069e+03\n",
      "Epoch 3509, Loss: 409.77496337890625, Neurons: 42, Grad norm: 1.058e+03\n",
      "Epoch 3509, Loss: 409.77496337890625, Neurons: 42, Grad norm: 1.058e+03\n",
      "Epoch 3510, Loss: 406.2261962890625, Neurons: 42, Grad norm: 1.046e+03\n",
      "Epoch 3510, Loss: 406.2261962890625, Neurons: 42, Grad norm: 1.046e+03\n",
      "Epoch 3511, Loss: 402.5887451171875, Neurons: 42, Grad norm: 1.034e+03\n",
      "Epoch 3511, Loss: 402.5887451171875, Neurons: 42, Grad norm: 1.034e+03\n",
      "Epoch 3512, Loss: 398.8702392578125, Neurons: 42, Grad norm: 1.022e+03\n",
      "Epoch 3512, Loss: 398.8702392578125, Neurons: 42, Grad norm: 1.022e+03\n",
      "Epoch 3513, Loss: 395.0789489746094, Neurons: 42, Grad norm: 1.009e+03\n",
      "Epoch 3513, Loss: 395.0789489746094, Neurons: 42, Grad norm: 1.009e+03\n",
      "Epoch 3514, Loss: 391.22344970703125, Neurons: 42, Grad norm: 9.955e+02\n",
      "Epoch 3514, Loss: 391.22344970703125, Neurons: 42, Grad norm: 9.955e+02\n",
      "Epoch 3515, Loss: 387.31207275390625, Neurons: 42, Grad norm: 9.819e+02\n",
      "Epoch 3515, Loss: 387.31207275390625, Neurons: 42, Grad norm: 9.819e+02\n",
      "Epoch 3516, Loss: 383.35333251953125, Neurons: 42, Grad norm: 9.680e+02\n",
      "Epoch 3516, Loss: 383.35333251953125, Neurons: 42, Grad norm: 9.680e+02\n",
      "Epoch 3517, Loss: 379.3555908203125, Neurons: 42, Grad norm: 9.539e+02\n",
      "Epoch 3517, Loss: 379.3555908203125, Neurons: 42, Grad norm: 9.539e+02\n",
      "Epoch 3518, Loss: 375.32196044921875, Neurons: 42, Grad norm: 9.395e+02\n",
      "Epoch 3518, Loss: 375.32196044921875, Neurons: 42, Grad norm: 9.395e+02\n",
      "Epoch 3519, Loss: 371.2594909667969, Neurons: 42, Grad norm: 9.250e+02\n",
      "Epoch 3519, Loss: 371.2594909667969, Neurons: 42, Grad norm: 9.250e+02\n",
      "Epoch 3520, Loss: 367.1756896972656, Neurons: 42, Grad norm: 9.102e+02\n",
      "Epoch 3520, Loss: 367.1756896972656, Neurons: 42, Grad norm: 9.102e+02\n",
      "Epoch 3521, Loss: 363.077880859375, Neurons: 42, Grad norm: 8.952e+02\n",
      "Epoch 3521, Loss: 363.077880859375, Neurons: 42, Grad norm: 8.952e+02\n",
      "Epoch 3522, Loss: 358.97320556640625, Neurons: 42, Grad norm: 8.801e+02\n",
      "Epoch 3522, Loss: 358.97320556640625, Neurons: 42, Grad norm: 8.801e+02\n",
      "Epoch 3523, Loss: 354.8687744140625, Neurons: 42, Grad norm: 8.649e+02\n",
      "Epoch 3523, Loss: 354.8687744140625, Neurons: 42, Grad norm: 8.649e+02\n",
      "Epoch 3524, Loss: 350.77325439453125, Neurons: 42, Grad norm: 8.496e+02\n",
      "Epoch 3524, Loss: 350.77325439453125, Neurons: 42, Grad norm: 8.496e+02\n",
      "Epoch 3525, Loss: 346.6923828125, Neurons: 42, Grad norm: 8.343e+02\n",
      "Epoch 3525, Loss: 346.6923828125, Neurons: 42, Grad norm: 8.343e+02\n",
      "Epoch 3526, Loss: 342.6313781738281, Neurons: 42, Grad norm: 8.189e+02\n",
      "Epoch 3526, Loss: 342.6313781738281, Neurons: 42, Grad norm: 8.189e+02\n",
      "Epoch 3527, Loss: 338.5953369140625, Neurons: 42, Grad norm: 8.035e+02\n",
      "Epoch 3527, Loss: 338.5953369140625, Neurons: 42, Grad norm: 8.035e+02\n",
      "Epoch 3528, Loss: 334.5890808105469, Neurons: 42, Grad norm: 7.881e+02\n",
      "Epoch 3528, Loss: 334.5890808105469, Neurons: 42, Grad norm: 7.881e+02\n",
      "Epoch 3529, Loss: 330.6170654296875, Neurons: 42, Grad norm: 7.728e+02\n",
      "Epoch 3529, Loss: 330.6170654296875, Neurons: 42, Grad norm: 7.728e+02\n",
      "Epoch 3530, Loss: 326.6837158203125, Neurons: 42, Grad norm: 7.575e+02\n",
      "Epoch 3530, Loss: 326.6837158203125, Neurons: 42, Grad norm: 7.575e+02\n",
      "Epoch 3531, Loss: 322.7930908203125, Neurons: 42, Grad norm: 7.423e+02\n",
      "Epoch 3531, Loss: 322.7930908203125, Neurons: 42, Grad norm: 7.423e+02\n",
      "Epoch 3532, Loss: 318.9489440917969, Neurons: 42, Grad norm: 7.273e+02\n",
      "Epoch 3532, Loss: 318.9489440917969, Neurons: 42, Grad norm: 7.273e+02\n",
      "Epoch 3533, Loss: 315.15460205078125, Neurons: 42, Grad norm: 7.124e+02\n",
      "Epoch 3533, Loss: 315.15460205078125, Neurons: 42, Grad norm: 7.124e+02\n",
      "Epoch 3534, Loss: 311.41302490234375, Neurons: 42, Grad norm: 6.977e+02\n",
      "Epoch 3534, Loss: 311.41302490234375, Neurons: 42, Grad norm: 6.977e+02\n",
      "Epoch 3535, Loss: 307.726806640625, Neurons: 42, Grad norm: 6.831e+02\n",
      "Epoch 3535, Loss: 307.726806640625, Neurons: 42, Grad norm: 6.831e+02\n",
      "Epoch 3536, Loss: 304.09808349609375, Neurons: 42, Grad norm: 6.688e+02\n",
      "Epoch 3536, Loss: 304.09808349609375, Neurons: 42, Grad norm: 6.688e+02\n",
      "Epoch 3537, Loss: 300.5287780761719, Neurons: 42, Grad norm: 6.547e+02\n",
      "Epoch 3537, Loss: 300.5287780761719, Neurons: 42, Grad norm: 6.547e+02\n",
      "Epoch 3538, Loss: 297.0201721191406, Neurons: 42, Grad norm: 6.408e+02\n",
      "Epoch 3538, Loss: 297.0201721191406, Neurons: 42, Grad norm: 6.408e+02\n",
      "Epoch 3539, Loss: 293.5735778808594, Neurons: 42, Grad norm: 6.272e+02\n",
      "Epoch 3539, Loss: 293.5735778808594, Neurons: 42, Grad norm: 6.272e+02\n",
      "Epoch 3540, Loss: 290.1900634765625, Neurons: 42, Grad norm: 6.137e+02\n",
      "Epoch 3540, Loss: 290.1900634765625, Neurons: 42, Grad norm: 6.137e+02\n",
      "Epoch 3541, Loss: 286.87042236328125, Neurons: 42, Grad norm: 6.005e+02\n",
      "Epoch 3541, Loss: 286.87042236328125, Neurons: 42, Grad norm: 6.005e+02\n",
      "Epoch 3542, Loss: 283.6154479980469, Neurons: 42, Grad norm: 5.875e+02\n",
      "Epoch 3542, Loss: 283.6154479980469, Neurons: 42, Grad norm: 5.875e+02\n",
      "Epoch 3543, Loss: 280.4256896972656, Neurons: 42, Grad norm: 5.748e+02\n",
      "Epoch 3543, Loss: 280.4256896972656, Neurons: 42, Grad norm: 5.748e+02\n",
      "Epoch 3544, Loss: 277.3014221191406, Neurons: 42, Grad norm: 5.623e+02\n",
      "Epoch 3544, Loss: 277.3014221191406, Neurons: 42, Grad norm: 5.623e+02\n",
      "Epoch 3545, Loss: 274.2428283691406, Neurons: 42, Grad norm: 5.500e+02\n",
      "Epoch 3545, Loss: 274.2428283691406, Neurons: 42, Grad norm: 5.500e+02\n",
      "Epoch 3546, Loss: 271.2501525878906, Neurons: 42, Grad norm: 5.379e+02\n",
      "Epoch 3546, Loss: 271.2501525878906, Neurons: 42, Grad norm: 5.379e+02\n",
      "Epoch 3547, Loss: 268.3228759765625, Neurons: 42, Grad norm: 5.261e+02\n",
      "Epoch 3547, Loss: 268.3228759765625, Neurons: 42, Grad norm: 5.261e+02\n",
      "Epoch 3548, Loss: 265.46099853515625, Neurons: 42, Grad norm: 5.145e+02\n",
      "Epoch 3548, Loss: 265.46099853515625, Neurons: 42, Grad norm: 5.145e+02\n",
      "Epoch 3549, Loss: 262.6640930175781, Neurons: 42, Grad norm: 5.031e+02\n",
      "Epoch 3549, Loss: 262.6640930175781, Neurons: 42, Grad norm: 5.031e+02\n",
      "Epoch 3550, Loss: 259.9320068359375, Neurons: 42, Grad norm: 4.918e+02\n",
      "Epoch 3550, Loss: 259.9320068359375, Neurons: 42, Grad norm: 4.918e+02\n",
      "Epoch 3551, Loss: 257.2641906738281, Neurons: 42, Grad norm: 4.808e+02\n",
      "Epoch 3551, Loss: 257.2641906738281, Neurons: 42, Grad norm: 4.808e+02\n",
      "Epoch 3552, Loss: 254.66041564941406, Neurons: 42, Grad norm: 4.700e+02\n",
      "Epoch 3552, Loss: 254.66041564941406, Neurons: 42, Grad norm: 4.700e+02\n",
      "Epoch 3553, Loss: 252.1199493408203, Neurons: 42, Grad norm: 4.594e+02\n",
      "Epoch 3553, Loss: 252.1199493408203, Neurons: 42, Grad norm: 4.594e+02\n",
      "Epoch 3554, Loss: 249.64256286621094, Neurons: 42, Grad norm: 4.489e+02\n",
      "Epoch 3554, Loss: 249.64256286621094, Neurons: 42, Grad norm: 4.489e+02\n",
      "Epoch 3555, Loss: 247.2276611328125, Neurons: 42, Grad norm: 4.386e+02\n",
      "Epoch 3555, Loss: 247.2276611328125, Neurons: 42, Grad norm: 4.386e+02\n",
      "Epoch 3556, Loss: 244.87460327148438, Neurons: 42, Grad norm: 4.285e+02\n",
      "Epoch 3556, Loss: 244.87460327148438, Neurons: 42, Grad norm: 4.285e+02\n",
      "Epoch 3557, Loss: 242.5828857421875, Neurons: 42, Grad norm: 4.185e+02\n",
      "Epoch 3557, Loss: 242.5828857421875, Neurons: 42, Grad norm: 4.185e+02\n",
      "Epoch 3558, Loss: 240.35214233398438, Neurons: 42, Grad norm: 4.088e+02\n",
      "Epoch 3558, Loss: 240.35214233398438, Neurons: 42, Grad norm: 4.088e+02\n",
      "Epoch 3559, Loss: 238.1817626953125, Neurons: 42, Grad norm: 3.991e+02\n",
      "Epoch 3559, Loss: 238.1817626953125, Neurons: 42, Grad norm: 3.991e+02\n",
      "Epoch 3560, Loss: 236.07144165039062, Neurons: 42, Grad norm: 3.897e+02\n",
      "Epoch 3560, Loss: 236.07144165039062, Neurons: 42, Grad norm: 3.897e+02\n",
      "Epoch 3561, Loss: 234.02088928222656, Neurons: 42, Grad norm: 3.804e+02\n",
      "Epoch 3561, Loss: 234.02088928222656, Neurons: 42, Grad norm: 3.804e+02\n",
      "Epoch 3562, Loss: 232.0298614501953, Neurons: 42, Grad norm: 3.713e+02\n",
      "Epoch 3562, Loss: 232.0298614501953, Neurons: 42, Grad norm: 3.713e+02\n",
      "Epoch 3563, Loss: 230.09799194335938, Neurons: 42, Grad norm: 3.623e+02\n",
      "Epoch 3563, Loss: 230.09799194335938, Neurons: 42, Grad norm: 3.623e+02\n",
      "Epoch 3564, Loss: 228.22494506835938, Neurons: 42, Grad norm: 3.536e+02\n",
      "Epoch 3564, Loss: 228.22494506835938, Neurons: 42, Grad norm: 3.536e+02\n",
      "Epoch 3565, Loss: 226.41017150878906, Neurons: 42, Grad norm: 3.451e+02\n",
      "Epoch 3565, Loss: 226.41017150878906, Neurons: 42, Grad norm: 3.451e+02\n",
      "Epoch 3566, Loss: 224.65313720703125, Neurons: 42, Grad norm: 3.368e+02\n",
      "Epoch 3566, Loss: 224.65313720703125, Neurons: 42, Grad norm: 3.368e+02\n",
      "Epoch 3567, Loss: 222.95321655273438, Neurons: 42, Grad norm: 3.288e+02\n",
      "Epoch 3567, Loss: 222.95321655273438, Neurons: 42, Grad norm: 3.288e+02\n",
      "Epoch 3568, Loss: 221.30950927734375, Neurons: 42, Grad norm: 3.210e+02\n",
      "Epoch 3568, Loss: 221.30950927734375, Neurons: 42, Grad norm: 3.210e+02\n",
      "Epoch 3569, Loss: 219.7208709716797, Neurons: 42, Grad norm: 3.134e+02\n",
      "Epoch 3569, Loss: 219.7208709716797, Neurons: 42, Grad norm: 3.134e+02\n",
      "Epoch 3570, Loss: 218.1862030029297, Neurons: 42, Grad norm: 3.061e+02\n",
      "Epoch 3570, Loss: 218.1862030029297, Neurons: 42, Grad norm: 3.061e+02\n",
      "Epoch 3571, Loss: 216.70391845703125, Neurons: 42, Grad norm: 2.991e+02\n",
      "Epoch 3571, Loss: 216.70391845703125, Neurons: 42, Grad norm: 2.991e+02\n",
      "Epoch 3572, Loss: 215.27281188964844, Neurons: 42, Grad norm: 2.923e+02\n",
      "Epoch 3572, Loss: 215.27281188964844, Neurons: 42, Grad norm: 2.923e+02\n",
      "Epoch 3573, Loss: 213.89112854003906, Neurons: 42, Grad norm: 2.857e+02\n",
      "Epoch 3573, Loss: 213.89112854003906, Neurons: 42, Grad norm: 2.857e+02\n",
      "Epoch 3574, Loss: 212.5576171875, Neurons: 42, Grad norm: 2.794e+02\n",
      "Epoch 3574, Loss: 212.5576171875, Neurons: 42, Grad norm: 2.794e+02\n",
      "Epoch 3575, Loss: 211.27090454101562, Neurons: 42, Grad norm: 2.733e+02\n",
      "Epoch 3575, Loss: 211.27090454101562, Neurons: 42, Grad norm: 2.733e+02\n",
      "Epoch 3576, Loss: 210.02947998046875, Neurons: 42, Grad norm: 2.674e+02\n",
      "Epoch 3576, Loss: 210.02947998046875, Neurons: 42, Grad norm: 2.674e+02\n",
      "Epoch 3577, Loss: 208.83204650878906, Neurons: 42, Grad norm: 2.616e+02\n",
      "Epoch 3577, Loss: 208.83204650878906, Neurons: 42, Grad norm: 2.616e+02\n",
      "Epoch 3578, Loss: 207.6773223876953, Neurons: 42, Grad norm: 2.561e+02\n",
      "Epoch 3578, Loss: 207.6773223876953, Neurons: 42, Grad norm: 2.561e+02\n",
      "Epoch 3579, Loss: 206.56375122070312, Neurons: 42, Grad norm: 2.507e+02\n",
      "Epoch 3579, Loss: 206.56375122070312, Neurons: 42, Grad norm: 2.507e+02\n",
      "Epoch 3580, Loss: 205.48997497558594, Neurons: 42, Grad norm: 2.455e+02\n",
      "Epoch 3580, Loss: 205.48997497558594, Neurons: 42, Grad norm: 2.455e+02\n",
      "Epoch 3581, Loss: 204.4546356201172, Neurons: 42, Grad norm: 2.404e+02\n",
      "Epoch 3581, Loss: 204.4546356201172, Neurons: 42, Grad norm: 2.404e+02\n",
      "Epoch 3582, Loss: 203.45632934570312, Neurons: 42, Grad norm: 2.355e+02\n",
      "Epoch 3582, Loss: 203.45632934570312, Neurons: 42, Grad norm: 2.355e+02\n",
      "Epoch 3583, Loss: 202.4937744140625, Neurons: 42, Grad norm: 2.306e+02\n",
      "Epoch 3583, Loss: 202.4937744140625, Neurons: 42, Grad norm: 2.306e+02\n",
      "Epoch 3584, Loss: 201.56544494628906, Neurons: 42, Grad norm: 2.258e+02\n",
      "Epoch 3584, Loss: 201.56544494628906, Neurons: 42, Grad norm: 2.258e+02\n",
      "Epoch 3585, Loss: 200.6701202392578, Neurons: 42, Grad norm: 2.212e+02\n",
      "Epoch 3585, Loss: 200.6701202392578, Neurons: 42, Grad norm: 2.212e+02\n",
      "Epoch 3586, Loss: 199.80638122558594, Neurons: 42, Grad norm: 2.166e+02\n",
      "Epoch 3586, Loss: 199.80638122558594, Neurons: 42, Grad norm: 2.166e+02\n",
      "Epoch 3587, Loss: 198.9730224609375, Neurons: 42, Grad norm: 2.120e+02\n",
      "Epoch 3587, Loss: 198.9730224609375, Neurons: 42, Grad norm: 2.120e+02\n",
      "Epoch 3588, Loss: 198.16847229003906, Neurons: 42, Grad norm: 2.076e+02\n",
      "Epoch 3588, Loss: 198.16847229003906, Neurons: 42, Grad norm: 2.076e+02\n",
      "Epoch 3589, Loss: 197.3914337158203, Neurons: 42, Grad norm: 2.032e+02\n",
      "Epoch 3589, Loss: 197.3914337158203, Neurons: 42, Grad norm: 2.032e+02\n",
      "Epoch 3590, Loss: 196.6404571533203, Neurons: 42, Grad norm: 1.988e+02\n",
      "Epoch 3590, Loss: 196.6404571533203, Neurons: 42, Grad norm: 1.988e+02\n",
      "Epoch 3591, Loss: 195.91444396972656, Neurons: 42, Grad norm: 1.945e+02\n",
      "Epoch 3591, Loss: 195.91444396972656, Neurons: 42, Grad norm: 1.945e+02\n",
      "Epoch 3592, Loss: 195.2122039794922, Neurons: 42, Grad norm: 1.902e+02\n",
      "Epoch 3592, Loss: 195.2122039794922, Neurons: 42, Grad norm: 1.902e+02\n",
      "Epoch 3593, Loss: 194.5327606201172, Neurons: 42, Grad norm: 1.860e+02\n",
      "Epoch 3593, Loss: 194.5327606201172, Neurons: 42, Grad norm: 1.860e+02\n",
      "Epoch 3594, Loss: 193.8750762939453, Neurons: 42, Grad norm: 1.819e+02\n",
      "Epoch 3594, Loss: 193.8750762939453, Neurons: 42, Grad norm: 1.819e+02\n",
      "Epoch 3595, Loss: 193.2382354736328, Neurons: 42, Grad norm: 1.777e+02\n",
      "Epoch 3595, Loss: 193.2382354736328, Neurons: 42, Grad norm: 1.777e+02\n",
      "Epoch 3596, Loss: 192.621337890625, Neurons: 42, Grad norm: 1.737e+02\n",
      "Epoch 3596, Loss: 192.621337890625, Neurons: 42, Grad norm: 1.737e+02\n",
      "Epoch 3597, Loss: 192.02345275878906, Neurons: 42, Grad norm: 1.697e+02\n",
      "Epoch 3597, Loss: 192.02345275878906, Neurons: 42, Grad norm: 1.697e+02\n",
      "Epoch 3598, Loss: 191.44357299804688, Neurons: 42, Grad norm: 1.657e+02\n",
      "Epoch 3598, Loss: 191.44357299804688, Neurons: 42, Grad norm: 1.657e+02\n",
      "Epoch 3599, Loss: 190.881103515625, Neurons: 42, Grad norm: 1.618e+02\n",
      "Epoch 3599, Loss: 190.881103515625, Neurons: 42, Grad norm: 1.618e+02\n",
      "Epoch 3599, Test loss: 186.31268310546875\n",
      "Epoch 3599, Test loss: 186.31268310546875\n",
      "Added neuron to hidden layer 1 with activation tanh\n",
      "Added neuron to hidden layer 1 with activation tanh\n",
      "network shape updated to :[17, 25, 1]\n",
      "network shape updated to :[17, 25, 1]\n",
      "Epoch 3600, Loss: 546.521728515625, Neurons: 43, Grad norm: 1.267e+03\n",
      "Epoch 3600, Loss: 546.521728515625, Neurons: 43, Grad norm: 1.267e+03\n",
      "Epoch 3601, Loss: 543.1113891601562, Neurons: 43, Grad norm: 1.260e+03\n",
      "Epoch 3601, Loss: 543.1113891601562, Neurons: 43, Grad norm: 1.260e+03\n",
      "Epoch 3602, Loss: 539.5433349609375, Neurons: 43, Grad norm: 1.252e+03\n",
      "Epoch 3602, Loss: 539.5433349609375, Neurons: 43, Grad norm: 1.252e+03\n",
      "Epoch 3603, Loss: 535.8185424804688, Neurons: 43, Grad norm: 1.244e+03\n",
      "Epoch 3603, Loss: 535.8185424804688, Neurons: 43, Grad norm: 1.244e+03\n",
      "Epoch 3604, Loss: 531.9389038085938, Neurons: 43, Grad norm: 1.236e+03\n",
      "Epoch 3604, Loss: 531.9389038085938, Neurons: 43, Grad norm: 1.236e+03\n",
      "Epoch 3605, Loss: 527.9071655273438, Neurons: 43, Grad norm: 1.226e+03\n",
      "Epoch 3605, Loss: 527.9071655273438, Neurons: 43, Grad norm: 1.226e+03\n",
      "Epoch 3606, Loss: 523.7269897460938, Neurons: 43, Grad norm: 1.217e+03\n",
      "Epoch 3606, Loss: 523.7269897460938, Neurons: 43, Grad norm: 1.217e+03\n",
      "Epoch 3607, Loss: 519.4025268554688, Neurons: 43, Grad norm: 1.207e+03\n",
      "Epoch 3607, Loss: 519.4025268554688, Neurons: 43, Grad norm: 1.207e+03\n",
      "Epoch 3608, Loss: 514.9391479492188, Neurons: 43, Grad norm: 1.196e+03\n",
      "Epoch 3608, Loss: 514.9391479492188, Neurons: 43, Grad norm: 1.196e+03\n",
      "Epoch 3609, Loss: 510.342529296875, Neurons: 43, Grad norm: 1.185e+03\n",
      "Epoch 3609, Loss: 510.342529296875, Neurons: 43, Grad norm: 1.185e+03\n",
      "Epoch 3610, Loss: 505.61920166015625, Neurons: 43, Grad norm: 1.174e+03\n",
      "Epoch 3610, Loss: 505.61920166015625, Neurons: 43, Grad norm: 1.174e+03\n",
      "Epoch 3611, Loss: 500.77655029296875, Neurons: 43, Grad norm: 1.161e+03\n",
      "Epoch 3611, Loss: 500.77655029296875, Neurons: 43, Grad norm: 1.161e+03\n",
      "Epoch 3612, Loss: 495.8223876953125, Neurons: 43, Grad norm: 1.149e+03\n",
      "Epoch 3612, Loss: 495.8223876953125, Neurons: 43, Grad norm: 1.149e+03\n",
      "Epoch 3613, Loss: 490.7649841308594, Neurons: 43, Grad norm: 1.136e+03\n",
      "Epoch 3613, Loss: 490.7649841308594, Neurons: 43, Grad norm: 1.136e+03\n",
      "Epoch 3614, Loss: 485.6129455566406, Neurons: 43, Grad norm: 1.123e+03\n",
      "Epoch 3614, Loss: 485.6129455566406, Neurons: 43, Grad norm: 1.123e+03\n",
      "Epoch 3615, Loss: 480.3750305175781, Neurons: 43, Grad norm: 1.109e+03\n",
      "Epoch 3615, Loss: 480.3750305175781, Neurons: 43, Grad norm: 1.109e+03\n",
      "Epoch 3616, Loss: 475.06072998046875, Neurons: 43, Grad norm: 1.095e+03\n",
      "Epoch 3616, Loss: 475.06072998046875, Neurons: 43, Grad norm: 1.095e+03\n",
      "Epoch 3617, Loss: 469.6795959472656, Neurons: 43, Grad norm: 1.080e+03\n",
      "Epoch 3617, Loss: 469.6795959472656, Neurons: 43, Grad norm: 1.080e+03\n",
      "Epoch 3618, Loss: 464.240966796875, Neurons: 43, Grad norm: 1.065e+03\n",
      "Epoch 3618, Loss: 464.240966796875, Neurons: 43, Grad norm: 1.065e+03\n",
      "Epoch 3619, Loss: 458.75457763671875, Neurons: 43, Grad norm: 1.050e+03\n",
      "Epoch 3619, Loss: 458.75457763671875, Neurons: 43, Grad norm: 1.050e+03\n",
      "Epoch 3620, Loss: 453.2299499511719, Neurons: 43, Grad norm: 1.034e+03\n",
      "Epoch 3620, Loss: 453.2299499511719, Neurons: 43, Grad norm: 1.034e+03\n",
      "Epoch 3621, Loss: 447.67657470703125, Neurons: 43, Grad norm: 1.019e+03\n",
      "Epoch 3621, Loss: 447.67657470703125, Neurons: 43, Grad norm: 1.019e+03\n",
      "Epoch 3622, Loss: 442.1036682128906, Neurons: 43, Grad norm: 1.003e+03\n",
      "Epoch 3622, Loss: 442.1036682128906, Neurons: 43, Grad norm: 1.003e+03\n",
      "Epoch 3623, Loss: 436.5204162597656, Neurons: 43, Grad norm: 9.867e+02\n",
      "Epoch 3623, Loss: 436.5204162597656, Neurons: 43, Grad norm: 9.867e+02\n",
      "Epoch 3624, Loss: 430.9354553222656, Neurons: 43, Grad norm: 9.704e+02\n",
      "Epoch 3624, Loss: 430.9354553222656, Neurons: 43, Grad norm: 9.704e+02\n",
      "Epoch 3625, Loss: 425.35693359375, Neurons: 43, Grad norm: 9.540e+02\n",
      "Epoch 3625, Loss: 425.35693359375, Neurons: 43, Grad norm: 9.540e+02\n",
      "Epoch 3626, Loss: 419.7928466796875, Neurons: 43, Grad norm: 9.376e+02\n",
      "Epoch 3626, Loss: 419.7928466796875, Neurons: 43, Grad norm: 9.376e+02\n",
      "Epoch 3627, Loss: 414.25091552734375, Neurons: 43, Grad norm: 9.211e+02\n",
      "Epoch 3627, Loss: 414.25091552734375, Neurons: 43, Grad norm: 9.211e+02\n",
      "Epoch 3628, Loss: 408.73834228515625, Neurons: 43, Grad norm: 9.046e+02\n",
      "Epoch 3628, Loss: 408.73834228515625, Neurons: 43, Grad norm: 9.046e+02\n",
      "Epoch 3629, Loss: 403.2618713378906, Neurons: 43, Grad norm: 8.881e+02\n",
      "Epoch 3629, Loss: 403.2618713378906, Neurons: 43, Grad norm: 8.881e+02\n",
      "Epoch 3630, Loss: 397.82763671875, Neurons: 43, Grad norm: 8.717e+02\n",
      "Epoch 3630, Loss: 397.82763671875, Neurons: 43, Grad norm: 8.717e+02\n",
      "Epoch 3631, Loss: 392.4414978027344, Neurons: 43, Grad norm: 8.553e+02\n",
      "Epoch 3631, Loss: 392.4414978027344, Neurons: 43, Grad norm: 8.553e+02\n",
      "Epoch 3632, Loss: 387.10882568359375, Neurons: 43, Grad norm: 8.391e+02\n",
      "Epoch 3632, Loss: 387.10882568359375, Neurons: 43, Grad norm: 8.391e+02\n",
      "Epoch 3633, Loss: 381.8345031738281, Neurons: 43, Grad norm: 8.229e+02\n",
      "Epoch 3633, Loss: 381.8345031738281, Neurons: 43, Grad norm: 8.229e+02\n",
      "Epoch 3634, Loss: 376.6224060058594, Neurons: 43, Grad norm: 8.070e+02\n",
      "Epoch 3634, Loss: 376.6224060058594, Neurons: 43, Grad norm: 8.070e+02\n",
      "Epoch 3635, Loss: 371.4768371582031, Neurons: 43, Grad norm: 7.911e+02\n",
      "Epoch 3635, Loss: 371.4768371582031, Neurons: 43, Grad norm: 7.911e+02\n",
      "Epoch 3636, Loss: 366.4012756347656, Neurons: 43, Grad norm: 7.755e+02\n",
      "Epoch 3636, Loss: 366.4012756347656, Neurons: 43, Grad norm: 7.755e+02\n",
      "Epoch 3637, Loss: 361.3991394042969, Neurons: 43, Grad norm: 7.600e+02\n",
      "Epoch 3637, Loss: 361.3991394042969, Neurons: 43, Grad norm: 7.600e+02\n",
      "Epoch 3638, Loss: 356.47296142578125, Neurons: 43, Grad norm: 7.448e+02\n",
      "Epoch 3638, Loss: 356.47296142578125, Neurons: 43, Grad norm: 7.448e+02\n",
      "Epoch 3639, Loss: 351.6251220703125, Neurons: 43, Grad norm: 7.298e+02\n",
      "Epoch 3639, Loss: 351.6251220703125, Neurons: 43, Grad norm: 7.298e+02\n",
      "Epoch 3640, Loss: 346.8576965332031, Neurons: 43, Grad norm: 7.150e+02\n",
      "Epoch 3640, Loss: 346.8576965332031, Neurons: 43, Grad norm: 7.150e+02\n",
      "Epoch 3641, Loss: 342.1722717285156, Neurons: 43, Grad norm: 7.004e+02\n",
      "Epoch 3641, Loss: 342.1722717285156, Neurons: 43, Grad norm: 7.004e+02\n",
      "Epoch 3642, Loss: 337.5703430175781, Neurons: 43, Grad norm: 6.861e+02\n",
      "Epoch 3642, Loss: 337.5703430175781, Neurons: 43, Grad norm: 6.861e+02\n",
      "Epoch 3643, Loss: 333.0530700683594, Neurons: 43, Grad norm: 6.720e+02\n",
      "Epoch 3643, Loss: 333.0530700683594, Neurons: 43, Grad norm: 6.720e+02\n",
      "Epoch 3644, Loss: 328.62158203125, Neurons: 43, Grad norm: 6.582e+02\n",
      "Epoch 3644, Loss: 328.62158203125, Neurons: 43, Grad norm: 6.582e+02\n",
      "Epoch 3645, Loss: 324.2761535644531, Neurons: 43, Grad norm: 6.447e+02\n",
      "Epoch 3645, Loss: 324.2761535644531, Neurons: 43, Grad norm: 6.447e+02\n",
      "Epoch 3646, Loss: 320.01763916015625, Neurons: 43, Grad norm: 6.314e+02\n",
      "Epoch 3646, Loss: 320.01763916015625, Neurons: 43, Grad norm: 6.314e+02\n",
      "Epoch 3647, Loss: 315.8465881347656, Neurons: 43, Grad norm: 6.183e+02\n",
      "Epoch 3647, Loss: 315.8465881347656, Neurons: 43, Grad norm: 6.183e+02\n",
      "Epoch 3648, Loss: 311.7620849609375, Neurons: 43, Grad norm: 6.055e+02\n",
      "Epoch 3648, Loss: 311.7620849609375, Neurons: 43, Grad norm: 6.055e+02\n",
      "Epoch 3649, Loss: 307.7645263671875, Neurons: 43, Grad norm: 5.929e+02\n",
      "Epoch 3649, Loss: 307.7645263671875, Neurons: 43, Grad norm: 5.929e+02\n",
      "Epoch 3650, Loss: 303.85406494140625, Neurons: 43, Grad norm: 5.806e+02\n",
      "Epoch 3650, Loss: 303.85406494140625, Neurons: 43, Grad norm: 5.806e+02\n",
      "Epoch 3651, Loss: 300.0303955078125, Neurons: 43, Grad norm: 5.685e+02\n",
      "Epoch 3651, Loss: 300.0303955078125, Neurons: 43, Grad norm: 5.685e+02\n",
      "Epoch 3652, Loss: 296.29345703125, Neurons: 43, Grad norm: 5.566e+02\n",
      "Epoch 3652, Loss: 296.29345703125, Neurons: 43, Grad norm: 5.566e+02\n",
      "Epoch 3653, Loss: 292.6425476074219, Neurons: 43, Grad norm: 5.450e+02\n",
      "Epoch 3653, Loss: 292.6425476074219, Neurons: 43, Grad norm: 5.450e+02\n",
      "Epoch 3654, Loss: 289.0771789550781, Neurons: 43, Grad norm: 5.336e+02\n",
      "Epoch 3654, Loss: 289.0771789550781, Neurons: 43, Grad norm: 5.336e+02\n",
      "Epoch 3655, Loss: 285.59637451171875, Neurons: 43, Grad norm: 5.224e+02\n",
      "Epoch 3655, Loss: 285.59637451171875, Neurons: 43, Grad norm: 5.224e+02\n",
      "Epoch 3656, Loss: 282.2003173828125, Neurons: 43, Grad norm: 5.114e+02\n",
      "Epoch 3656, Loss: 282.2003173828125, Neurons: 43, Grad norm: 5.114e+02\n",
      "Epoch 3657, Loss: 278.8883361816406, Neurons: 43, Grad norm: 5.006e+02\n",
      "Epoch 3657, Loss: 278.8883361816406, Neurons: 43, Grad norm: 5.006e+02\n",
      "Epoch 3658, Loss: 275.6595153808594, Neurons: 43, Grad norm: 4.900e+02\n",
      "Epoch 3658, Loss: 275.6595153808594, Neurons: 43, Grad norm: 4.900e+02\n",
      "Epoch 3659, Loss: 272.5131530761719, Neurons: 43, Grad norm: 4.796e+02\n",
      "Epoch 3659, Loss: 272.5131530761719, Neurons: 43, Grad norm: 4.796e+02\n",
      "Epoch 3660, Loss: 269.4485168457031, Neurons: 43, Grad norm: 4.694e+02\n",
      "Epoch 3660, Loss: 269.4485168457031, Neurons: 43, Grad norm: 4.694e+02\n",
      "Epoch 3661, Loss: 266.4651184082031, Neurons: 43, Grad norm: 4.593e+02\n",
      "Epoch 3661, Loss: 266.4651184082031, Neurons: 43, Grad norm: 4.593e+02\n",
      "Epoch 3662, Loss: 263.5622253417969, Neurons: 43, Grad norm: 4.495e+02\n",
      "Epoch 3662, Loss: 263.5622253417969, Neurons: 43, Grad norm: 4.495e+02\n",
      "Epoch 3663, Loss: 260.73895263671875, Neurons: 43, Grad norm: 4.398e+02\n",
      "Epoch 3663, Loss: 260.73895263671875, Neurons: 43, Grad norm: 4.398e+02\n",
      "Epoch 3664, Loss: 257.9944152832031, Neurons: 43, Grad norm: 4.302e+02\n",
      "Epoch 3664, Loss: 257.9944152832031, Neurons: 43, Grad norm: 4.302e+02\n",
      "Epoch 3665, Loss: 255.327880859375, Neurons: 43, Grad norm: 4.209e+02\n",
      "Epoch 3665, Loss: 255.327880859375, Neurons: 43, Grad norm: 4.209e+02\n",
      "Epoch 3666, Loss: 252.73855590820312, Neurons: 43, Grad norm: 4.117e+02\n",
      "Epoch 3666, Loss: 252.73855590820312, Neurons: 43, Grad norm: 4.117e+02\n",
      "Epoch 3667, Loss: 250.22535705566406, Neurons: 43, Grad norm: 4.027e+02\n",
      "Epoch 3667, Loss: 250.22535705566406, Neurons: 43, Grad norm: 4.027e+02\n",
      "Epoch 3668, Loss: 247.78738403320312, Neurons: 43, Grad norm: 3.938e+02\n",
      "Epoch 3668, Loss: 247.78738403320312, Neurons: 43, Grad norm: 3.938e+02\n",
      "Epoch 3669, Loss: 245.42343139648438, Neurons: 43, Grad norm: 3.852e+02\n",
      "Epoch 3669, Loss: 245.42343139648438, Neurons: 43, Grad norm: 3.852e+02\n",
      "Epoch 3670, Loss: 243.13241577148438, Neurons: 43, Grad norm: 3.766e+02\n",
      "Epoch 3670, Loss: 243.13241577148438, Neurons: 43, Grad norm: 3.766e+02\n",
      "Epoch 3671, Loss: 240.91278076171875, Neurons: 43, Grad norm: 3.683e+02\n",
      "Epoch 3671, Loss: 240.91278076171875, Neurons: 43, Grad norm: 3.683e+02\n",
      "Epoch 3672, Loss: 238.76356506347656, Neurons: 43, Grad norm: 3.601e+02\n",
      "Epoch 3672, Loss: 238.76356506347656, Neurons: 43, Grad norm: 3.601e+02\n",
      "Epoch 3673, Loss: 236.68321228027344, Neurons: 43, Grad norm: 3.520e+02\n",
      "Epoch 3673, Loss: 236.68321228027344, Neurons: 43, Grad norm: 3.520e+02\n",
      "Epoch 3674, Loss: 234.6705780029297, Neurons: 43, Grad norm: 3.441e+02\n",
      "Epoch 3674, Loss: 234.6705780029297, Neurons: 43, Grad norm: 3.441e+02\n",
      "Epoch 3675, Loss: 232.72454833984375, Neurons: 43, Grad norm: 3.363e+02\n",
      "Epoch 3675, Loss: 232.72454833984375, Neurons: 43, Grad norm: 3.363e+02\n",
      "Epoch 3676, Loss: 230.8433837890625, Neurons: 43, Grad norm: 3.287e+02\n",
      "Epoch 3676, Loss: 230.8433837890625, Neurons: 43, Grad norm: 3.287e+02\n",
      "Epoch 3677, Loss: 229.02557373046875, Neurons: 43, Grad norm: 3.212e+02\n",
      "Epoch 3677, Loss: 229.02557373046875, Neurons: 43, Grad norm: 3.212e+02\n",
      "Epoch 3678, Loss: 227.2696533203125, Neurons: 43, Grad norm: 3.138e+02\n",
      "Epoch 3678, Loss: 227.2696533203125, Neurons: 43, Grad norm: 3.138e+02\n",
      "Epoch 3679, Loss: 225.573974609375, Neurons: 43, Grad norm: 3.066e+02\n",
      "Epoch 3679, Loss: 225.573974609375, Neurons: 43, Grad norm: 3.066e+02\n",
      "Epoch 3680, Loss: 223.93638610839844, Neurons: 43, Grad norm: 2.995e+02\n",
      "Epoch 3680, Loss: 223.93638610839844, Neurons: 43, Grad norm: 2.995e+02\n",
      "Epoch 3681, Loss: 222.35475158691406, Neurons: 43, Grad norm: 2.926e+02\n",
      "Epoch 3681, Loss: 222.35475158691406, Neurons: 43, Grad norm: 2.926e+02\n",
      "Epoch 3682, Loss: 220.8270721435547, Neurons: 43, Grad norm: 2.858e+02\n",
      "Epoch 3682, Loss: 220.8270721435547, Neurons: 43, Grad norm: 2.858e+02\n",
      "Epoch 3683, Loss: 219.35191345214844, Neurons: 43, Grad norm: 2.791e+02\n",
      "Epoch 3683, Loss: 219.35191345214844, Neurons: 43, Grad norm: 2.791e+02\n",
      "Epoch 3684, Loss: 217.92701721191406, Neurons: 43, Grad norm: 2.726e+02\n",
      "Epoch 3684, Loss: 217.92701721191406, Neurons: 43, Grad norm: 2.726e+02\n",
      "Epoch 3685, Loss: 216.55014038085938, Neurons: 43, Grad norm: 2.662e+02\n",
      "Epoch 3685, Loss: 216.55014038085938, Neurons: 43, Grad norm: 2.662e+02\n",
      "Epoch 3686, Loss: 215.21961975097656, Neurons: 43, Grad norm: 2.599e+02\n",
      "Epoch 3686, Loss: 215.21961975097656, Neurons: 43, Grad norm: 2.599e+02\n",
      "Epoch 3687, Loss: 213.93324279785156, Neurons: 43, Grad norm: 2.538e+02\n",
      "Epoch 3687, Loss: 213.93324279785156, Neurons: 43, Grad norm: 2.538e+02\n",
      "Epoch 3688, Loss: 212.6891326904297, Neurons: 43, Grad norm: 2.478e+02\n",
      "Epoch 3688, Loss: 212.6891326904297, Neurons: 43, Grad norm: 2.478e+02\n",
      "Epoch 3689, Loss: 211.48580932617188, Neurons: 43, Grad norm: 2.419e+02\n",
      "Epoch 3689, Loss: 211.48580932617188, Neurons: 43, Grad norm: 2.419e+02\n",
      "Epoch 3690, Loss: 210.3217010498047, Neurons: 43, Grad norm: 2.361e+02\n",
      "Epoch 3690, Loss: 210.3217010498047, Neurons: 43, Grad norm: 2.361e+02\n",
      "Epoch 3691, Loss: 209.1952667236328, Neurons: 43, Grad norm: 2.305e+02\n",
      "Epoch 3691, Loss: 209.1952667236328, Neurons: 43, Grad norm: 2.305e+02\n",
      "Epoch 3692, Loss: 208.10508728027344, Neurons: 43, Grad norm: 2.251e+02\n",
      "Epoch 3692, Loss: 208.10508728027344, Neurons: 43, Grad norm: 2.251e+02\n",
      "Epoch 3693, Loss: 207.0497589111328, Neurons: 43, Grad norm: 2.197e+02\n",
      "Epoch 3693, Loss: 207.0497589111328, Neurons: 43, Grad norm: 2.197e+02\n",
      "Epoch 3694, Loss: 206.02798461914062, Neurons: 43, Grad norm: 2.145e+02\n",
      "Epoch 3694, Loss: 206.02798461914062, Neurons: 43, Grad norm: 2.145e+02\n",
      "Epoch 3695, Loss: 205.03851318359375, Neurons: 43, Grad norm: 2.095e+02\n",
      "Epoch 3695, Loss: 205.03851318359375, Neurons: 43, Grad norm: 2.095e+02\n",
      "Epoch 3696, Loss: 204.08030700683594, Neurons: 43, Grad norm: 2.046e+02\n",
      "Epoch 3696, Loss: 204.08030700683594, Neurons: 43, Grad norm: 2.046e+02\n",
      "Epoch 3697, Loss: 203.15219116210938, Neurons: 43, Grad norm: 1.998e+02\n",
      "Epoch 3697, Loss: 203.15219116210938, Neurons: 43, Grad norm: 1.998e+02\n",
      "Epoch 3698, Loss: 202.2530059814453, Neurons: 43, Grad norm: 1.951e+02\n",
      "Epoch 3698, Loss: 202.2530059814453, Neurons: 43, Grad norm: 1.951e+02\n",
      "Epoch 3699, Loss: 201.38180541992188, Neurons: 43, Grad norm: 1.907e+02\n",
      "Epoch 3699, Loss: 201.38180541992188, Neurons: 43, Grad norm: 1.907e+02\n",
      "Epoch 3699, Test loss: 196.18429565429688\n",
      "Epoch 3699, Test loss: 196.18429565429688\n",
      "Removed neuron to hidden layer 1 at index 16\n",
      "Removed neuron to hidden layer 1 at index 16\n",
      "network shape updated to :[16, 25, 1]\n",
      "network shape updated to :[16, 25, 1]\n",
      "Epoch 3700, Loss: 259.8062438964844, Neurons: 42, Grad norm: 5.088e+02\n",
      "Epoch 3700, Loss: 259.8062438964844, Neurons: 42, Grad norm: 5.088e+02\n",
      "Epoch 3701, Loss: 258.3826599121094, Neurons: 42, Grad norm: 5.031e+02\n",
      "Epoch 3701, Loss: 258.3826599121094, Neurons: 42, Grad norm: 5.031e+02\n",
      "Epoch 3702, Loss: 256.9017333984375, Neurons: 42, Grad norm: 4.971e+02\n",
      "Epoch 3702, Loss: 256.9017333984375, Neurons: 42, Grad norm: 4.971e+02\n",
      "Epoch 3703, Loss: 255.364990234375, Neurons: 42, Grad norm: 4.908e+02\n",
      "Epoch 3703, Loss: 255.364990234375, Neurons: 42, Grad norm: 4.908e+02\n",
      "Epoch 3704, Loss: 253.7749786376953, Neurons: 42, Grad norm: 4.842e+02\n",
      "Epoch 3704, Loss: 253.7749786376953, Neurons: 42, Grad norm: 4.842e+02\n",
      "Epoch 3705, Loss: 252.1344451904297, Neurons: 42, Grad norm: 4.775e+02\n",
      "Epoch 3705, Loss: 252.1344451904297, Neurons: 42, Grad norm: 4.775e+02\n",
      "Epoch 3706, Loss: 250.44654846191406, Neurons: 42, Grad norm: 4.705e+02\n",
      "Epoch 3706, Loss: 250.44654846191406, Neurons: 42, Grad norm: 4.705e+02\n",
      "Epoch 3707, Loss: 248.71481323242188, Neurons: 42, Grad norm: 4.633e+02\n",
      "Epoch 3707, Loss: 248.71481323242188, Neurons: 42, Grad norm: 4.633e+02\n",
      "Epoch 3708, Loss: 246.94320678710938, Neurons: 42, Grad norm: 4.559e+02\n",
      "Epoch 3708, Loss: 246.94320678710938, Neurons: 42, Grad norm: 4.559e+02\n",
      "Epoch 3709, Loss: 245.13571166992188, Neurons: 42, Grad norm: 4.484e+02\n",
      "Epoch 3709, Loss: 245.13571166992188, Neurons: 42, Grad norm: 4.484e+02\n",
      "Epoch 3710, Loss: 243.29701232910156, Neurons: 42, Grad norm: 4.407e+02\n",
      "Epoch 3710, Loss: 243.29701232910156, Neurons: 42, Grad norm: 4.407e+02\n",
      "Epoch 3711, Loss: 241.4318084716797, Neurons: 42, Grad norm: 4.329e+02\n",
      "Epoch 3711, Loss: 241.4318084716797, Neurons: 42, Grad norm: 4.329e+02\n",
      "Epoch 3712, Loss: 239.54486083984375, Neurons: 42, Grad norm: 4.249e+02\n",
      "Epoch 3712, Loss: 239.54486083984375, Neurons: 42, Grad norm: 4.249e+02\n",
      "Epoch 3713, Loss: 237.64085388183594, Neurons: 42, Grad norm: 4.169e+02\n",
      "Epoch 3713, Loss: 237.64085388183594, Neurons: 42, Grad norm: 4.169e+02\n",
      "Epoch 3714, Loss: 235.72470092773438, Neurons: 42, Grad norm: 4.088e+02\n",
      "Epoch 3714, Loss: 235.72470092773438, Neurons: 42, Grad norm: 4.088e+02\n",
      "Epoch 3715, Loss: 233.80116271972656, Neurons: 42, Grad norm: 4.006e+02\n",
      "Epoch 3715, Loss: 233.80116271972656, Neurons: 42, Grad norm: 4.006e+02\n",
      "Epoch 3716, Loss: 231.8748779296875, Neurons: 42, Grad norm: 3.924e+02\n",
      "Epoch 3716, Loss: 231.8748779296875, Neurons: 42, Grad norm: 3.924e+02\n",
      "Epoch 3717, Loss: 229.95018005371094, Neurons: 42, Grad norm: 3.842e+02\n",
      "Epoch 3717, Loss: 229.95018005371094, Neurons: 42, Grad norm: 3.842e+02\n",
      "Epoch 3718, Loss: 228.03163146972656, Neurons: 42, Grad norm: 3.760e+02\n",
      "Epoch 3718, Loss: 228.03163146972656, Neurons: 42, Grad norm: 3.760e+02\n",
      "Epoch 3719, Loss: 226.1234130859375, Neurons: 42, Grad norm: 3.677e+02\n",
      "Epoch 3719, Loss: 226.1234130859375, Neurons: 42, Grad norm: 3.677e+02\n",
      "Epoch 3720, Loss: 224.22958374023438, Neurons: 42, Grad norm: 3.595e+02\n",
      "Epoch 3720, Loss: 224.22958374023438, Neurons: 42, Grad norm: 3.595e+02\n",
      "Epoch 3721, Loss: 222.35382080078125, Neurons: 42, Grad norm: 3.513e+02\n",
      "Epoch 3721, Loss: 222.35382080078125, Neurons: 42, Grad norm: 3.513e+02\n",
      "Epoch 3722, Loss: 220.4992218017578, Neurons: 42, Grad norm: 3.432e+02\n",
      "Epoch 3722, Loss: 220.4992218017578, Neurons: 42, Grad norm: 3.432e+02\n",
      "Epoch 3723, Loss: 218.66900634765625, Neurons: 42, Grad norm: 3.351e+02\n",
      "Epoch 3723, Loss: 218.66900634765625, Neurons: 42, Grad norm: 3.351e+02\n",
      "Epoch 3724, Loss: 216.86590576171875, Neurons: 42, Grad norm: 3.271e+02\n",
      "Epoch 3724, Loss: 216.86590576171875, Neurons: 42, Grad norm: 3.271e+02\n",
      "Epoch 3725, Loss: 215.0926971435547, Neurons: 42, Grad norm: 3.191e+02\n",
      "Epoch 3725, Loss: 215.0926971435547, Neurons: 42, Grad norm: 3.191e+02\n",
      "Epoch 3726, Loss: 213.3517303466797, Neurons: 42, Grad norm: 3.113e+02\n",
      "Epoch 3726, Loss: 213.3517303466797, Neurons: 42, Grad norm: 3.113e+02\n",
      "Epoch 3727, Loss: 211.6448974609375, Neurons: 42, Grad norm: 3.035e+02\n",
      "Epoch 3727, Loss: 211.6448974609375, Neurons: 42, Grad norm: 3.035e+02\n",
      "Epoch 3728, Loss: 209.9740753173828, Neurons: 42, Grad norm: 2.957e+02\n",
      "Epoch 3728, Loss: 209.9740753173828, Neurons: 42, Grad norm: 2.957e+02\n",
      "Epoch 3729, Loss: 208.34103393554688, Neurons: 42, Grad norm: 2.880e+02\n",
      "Epoch 3729, Loss: 208.34103393554688, Neurons: 42, Grad norm: 2.880e+02\n",
      "Epoch 3730, Loss: 206.74729919433594, Neurons: 42, Grad norm: 2.804e+02\n",
      "Epoch 3730, Loss: 206.74729919433594, Neurons: 42, Grad norm: 2.804e+02\n",
      "Epoch 3731, Loss: 205.19407653808594, Neurons: 42, Grad norm: 2.729e+02\n",
      "Epoch 3731, Loss: 205.19407653808594, Neurons: 42, Grad norm: 2.729e+02\n",
      "Epoch 3732, Loss: 203.6825714111328, Neurons: 42, Grad norm: 2.655e+02\n",
      "Epoch 3732, Loss: 203.6825714111328, Neurons: 42, Grad norm: 2.655e+02\n",
      "Epoch 3733, Loss: 202.213623046875, Neurons: 42, Grad norm: 2.582e+02\n",
      "Epoch 3733, Loss: 202.213623046875, Neurons: 42, Grad norm: 2.582e+02\n",
      "Epoch 3734, Loss: 200.787841796875, Neurons: 42, Grad norm: 2.510e+02\n",
      "Epoch 3734, Loss: 200.787841796875, Neurons: 42, Grad norm: 2.510e+02\n",
      "Epoch 3735, Loss: 199.40560913085938, Neurons: 42, Grad norm: 2.439e+02\n",
      "Epoch 3735, Loss: 199.40560913085938, Neurons: 42, Grad norm: 2.439e+02\n",
      "Epoch 3736, Loss: 198.06727600097656, Neurons: 42, Grad norm: 2.368e+02\n",
      "Epoch 3736, Loss: 198.06727600097656, Neurons: 42, Grad norm: 2.368e+02\n",
      "Epoch 3737, Loss: 196.77325439453125, Neurons: 42, Grad norm: 2.299e+02\n",
      "Epoch 3737, Loss: 196.77325439453125, Neurons: 42, Grad norm: 2.299e+02\n",
      "Epoch 3738, Loss: 195.52357482910156, Neurons: 42, Grad norm: 2.231e+02\n",
      "Epoch 3738, Loss: 195.52357482910156, Neurons: 42, Grad norm: 2.231e+02\n",
      "Epoch 3739, Loss: 194.318115234375, Neurons: 42, Grad norm: 2.164e+02\n",
      "Epoch 3739, Loss: 194.318115234375, Neurons: 42, Grad norm: 2.164e+02\n",
      "Epoch 3740, Loss: 193.15634155273438, Neurons: 42, Grad norm: 2.099e+02\n",
      "Epoch 3740, Loss: 193.15634155273438, Neurons: 42, Grad norm: 2.099e+02\n",
      "Epoch 3741, Loss: 192.03797912597656, Neurons: 42, Grad norm: 2.035e+02\n",
      "Epoch 3741, Loss: 192.03797912597656, Neurons: 42, Grad norm: 2.035e+02\n",
      "Epoch 3742, Loss: 190.9625244140625, Neurons: 42, Grad norm: 1.972e+02\n",
      "Epoch 3742, Loss: 190.9625244140625, Neurons: 42, Grad norm: 1.972e+02\n",
      "Epoch 3743, Loss: 189.92942810058594, Neurons: 42, Grad norm: 1.911e+02\n",
      "Epoch 3743, Loss: 189.92942810058594, Neurons: 42, Grad norm: 1.911e+02\n",
      "Epoch 3744, Loss: 188.93785095214844, Neurons: 42, Grad norm: 1.851e+02\n",
      "Epoch 3744, Loss: 188.93785095214844, Neurons: 42, Grad norm: 1.851e+02\n",
      "Epoch 3745, Loss: 187.98683166503906, Neurons: 42, Grad norm: 1.792e+02\n",
      "Epoch 3745, Loss: 187.98683166503906, Neurons: 42, Grad norm: 1.792e+02\n",
      "Epoch 3746, Loss: 187.07542419433594, Neurons: 42, Grad norm: 1.735e+02\n",
      "Epoch 3746, Loss: 187.07542419433594, Neurons: 42, Grad norm: 1.735e+02\n",
      "Epoch 3747, Loss: 186.20266723632812, Neurons: 42, Grad norm: 1.679e+02\n",
      "Epoch 3747, Loss: 186.20266723632812, Neurons: 42, Grad norm: 1.679e+02\n",
      "Epoch 3748, Loss: 185.36741638183594, Neurons: 42, Grad norm: 1.626e+02\n",
      "Epoch 3748, Loss: 185.36741638183594, Neurons: 42, Grad norm: 1.626e+02\n",
      "Epoch 3749, Loss: 184.568359375, Neurons: 42, Grad norm: 1.573e+02\n",
      "Epoch 3749, Loss: 184.568359375, Neurons: 42, Grad norm: 1.573e+02\n",
      "Epoch 3750, Loss: 183.80419921875, Neurons: 42, Grad norm: 1.522e+02\n",
      "Epoch 3750, Loss: 183.80419921875, Neurons: 42, Grad norm: 1.522e+02\n",
      "Epoch 3751, Loss: 183.07383728027344, Neurons: 42, Grad norm: 1.473e+02\n",
      "Epoch 3751, Loss: 183.07383728027344, Neurons: 42, Grad norm: 1.473e+02\n",
      "Epoch 3752, Loss: 182.37599182128906, Neurons: 42, Grad norm: 1.425e+02\n",
      "Epoch 3752, Loss: 182.37599182128906, Neurons: 42, Grad norm: 1.425e+02\n",
      "Epoch 3753, Loss: 181.70924377441406, Neurons: 42, Grad norm: 1.379e+02\n",
      "Epoch 3753, Loss: 181.70924377441406, Neurons: 42, Grad norm: 1.379e+02\n",
      "Epoch 3754, Loss: 181.07228088378906, Neurons: 42, Grad norm: 1.333e+02\n",
      "Epoch 3754, Loss: 181.07228088378906, Neurons: 42, Grad norm: 1.333e+02\n",
      "Epoch 3755, Loss: 180.46392822265625, Neurons: 42, Grad norm: 1.290e+02\n",
      "Epoch 3755, Loss: 180.46392822265625, Neurons: 42, Grad norm: 1.290e+02\n",
      "Epoch 3756, Loss: 179.8828582763672, Neurons: 42, Grad norm: 1.248e+02\n",
      "Epoch 3756, Loss: 179.8828582763672, Neurons: 42, Grad norm: 1.248e+02\n",
      "Epoch 3757, Loss: 179.3278045654297, Neurons: 42, Grad norm: 1.206e+02\n",
      "Epoch 3757, Loss: 179.3278045654297, Neurons: 42, Grad norm: 1.206e+02\n",
      "Epoch 3758, Loss: 178.79757690429688, Neurons: 42, Grad norm: 1.167e+02\n",
      "Epoch 3758, Loss: 178.79757690429688, Neurons: 42, Grad norm: 1.167e+02\n",
      "Epoch 3759, Loss: 178.29104614257812, Neurons: 42, Grad norm: 1.128e+02\n",
      "Epoch 3759, Loss: 178.29104614257812, Neurons: 42, Grad norm: 1.128e+02\n",
      "Epoch 3760, Loss: 177.80706787109375, Neurons: 42, Grad norm: 1.091e+02\n",
      "Epoch 3760, Loss: 177.80706787109375, Neurons: 42, Grad norm: 1.091e+02\n",
      "Epoch 3761, Loss: 177.34446716308594, Neurons: 42, Grad norm: 1.055e+02\n",
      "Epoch 3761, Loss: 177.34446716308594, Neurons: 42, Grad norm: 1.055e+02\n",
      "Epoch 3762, Loss: 176.9022216796875, Neurons: 42, Grad norm: 1.020e+02\n",
      "Epoch 3762, Loss: 176.9022216796875, Neurons: 42, Grad norm: 1.020e+02\n",
      "Epoch 3763, Loss: 176.47927856445312, Neurons: 42, Grad norm: 9.862e+01\n",
      "Epoch 3763, Loss: 176.47927856445312, Neurons: 42, Grad norm: 9.862e+01\n",
      "Epoch 3764, Loss: 176.0745849609375, Neurons: 42, Grad norm: 9.538e+01\n",
      "Epoch 3764, Loss: 176.0745849609375, Neurons: 42, Grad norm: 9.538e+01\n",
      "Epoch 3765, Loss: 175.68719482421875, Neurons: 42, Grad norm: 9.226e+01\n",
      "Epoch 3765, Loss: 175.68719482421875, Neurons: 42, Grad norm: 9.226e+01\n",
      "Epoch 3766, Loss: 175.31607055664062, Neurons: 42, Grad norm: 8.922e+01\n",
      "Epoch 3766, Loss: 175.31607055664062, Neurons: 42, Grad norm: 8.922e+01\n",
      "Epoch 3767, Loss: 174.96035766601562, Neurons: 42, Grad norm: 8.631e+01\n",
      "Epoch 3767, Loss: 174.96035766601562, Neurons: 42, Grad norm: 8.631e+01\n",
      "Epoch 3768, Loss: 174.61920166015625, Neurons: 42, Grad norm: 8.349e+01\n",
      "Epoch 3768, Loss: 174.61920166015625, Neurons: 42, Grad norm: 8.349e+01\n",
      "Epoch 3769, Loss: 174.29176330566406, Neurons: 42, Grad norm: 8.077e+01\n",
      "Epoch 3769, Loss: 174.29176330566406, Neurons: 42, Grad norm: 8.077e+01\n",
      "Epoch 3770, Loss: 173.9772186279297, Neurons: 42, Grad norm: 7.816e+01\n",
      "Epoch 3770, Loss: 173.9772186279297, Neurons: 42, Grad norm: 7.816e+01\n",
      "Epoch 3771, Loss: 173.6748504638672, Neurons: 42, Grad norm: 7.565e+01\n",
      "Epoch 3771, Loss: 173.6748504638672, Neurons: 42, Grad norm: 7.565e+01\n",
      "Epoch 3772, Loss: 173.38385009765625, Neurons: 42, Grad norm: 7.328e+01\n",
      "Epoch 3772, Loss: 173.38385009765625, Neurons: 42, Grad norm: 7.328e+01\n",
      "Epoch 3773, Loss: 173.10354614257812, Neurons: 42, Grad norm: 7.098e+01\n",
      "Epoch 3773, Loss: 173.10354614257812, Neurons: 42, Grad norm: 7.098e+01\n",
      "Epoch 3774, Loss: 172.83322143554688, Neurons: 42, Grad norm: 6.879e+01\n",
      "Epoch 3774, Loss: 172.83322143554688, Neurons: 42, Grad norm: 6.879e+01\n",
      "Epoch 3775, Loss: 172.5722198486328, Neurons: 42, Grad norm: 6.667e+01\n",
      "Epoch 3775, Loss: 172.5722198486328, Neurons: 42, Grad norm: 6.667e+01\n",
      "Epoch 3776, Loss: 172.31996154785156, Neurons: 42, Grad norm: 6.469e+01\n",
      "Epoch 3776, Loss: 172.31996154785156, Neurons: 42, Grad norm: 6.469e+01\n",
      "Epoch 3777, Loss: 172.07586669921875, Neurons: 42, Grad norm: 6.274e+01\n",
      "Epoch 3777, Loss: 172.07586669921875, Neurons: 42, Grad norm: 6.274e+01\n",
      "Epoch 3778, Loss: 171.83938598632812, Neurons: 42, Grad norm: 6.090e+01\n",
      "Epoch 3778, Loss: 171.83938598632812, Neurons: 42, Grad norm: 6.090e+01\n",
      "Epoch 3779, Loss: 171.6100616455078, Neurons: 42, Grad norm: 5.914e+01\n",
      "Epoch 3779, Loss: 171.6100616455078, Neurons: 42, Grad norm: 5.914e+01\n",
      "Epoch 3780, Loss: 171.3873291015625, Neurons: 42, Grad norm: 5.744e+01\n",
      "Epoch 3780, Loss: 171.3873291015625, Neurons: 42, Grad norm: 5.744e+01\n",
      "Epoch 3781, Loss: 171.17088317871094, Neurons: 42, Grad norm: 5.584e+01\n",
      "Epoch 3781, Loss: 171.17088317871094, Neurons: 42, Grad norm: 5.584e+01\n",
      "Epoch 3782, Loss: 170.96018981933594, Neurons: 42, Grad norm: 5.431e+01\n",
      "Epoch 3782, Loss: 170.96018981933594, Neurons: 42, Grad norm: 5.431e+01\n",
      "Epoch 3783, Loss: 170.75491333007812, Neurons: 42, Grad norm: 5.286e+01\n",
      "Epoch 3783, Loss: 170.75491333007812, Neurons: 42, Grad norm: 5.286e+01\n",
      "Epoch 3784, Loss: 170.55462646484375, Neurons: 42, Grad norm: 5.148e+01\n",
      "Epoch 3784, Loss: 170.55462646484375, Neurons: 42, Grad norm: 5.148e+01\n",
      "Epoch 3785, Loss: 170.35897827148438, Neurons: 42, Grad norm: 5.018e+01\n",
      "Epoch 3785, Loss: 170.35897827148438, Neurons: 42, Grad norm: 5.018e+01\n",
      "Epoch 3786, Loss: 170.16763305664062, Neurons: 42, Grad norm: 4.896e+01\n",
      "Epoch 3786, Loss: 170.16763305664062, Neurons: 42, Grad norm: 4.896e+01\n",
      "Epoch 3787, Loss: 169.980224609375, Neurons: 42, Grad norm: 4.779e+01\n",
      "Epoch 3787, Loss: 169.980224609375, Neurons: 42, Grad norm: 4.779e+01\n",
      "Epoch 3788, Loss: 169.79652404785156, Neurons: 42, Grad norm: 4.668e+01\n",
      "Epoch 3788, Loss: 169.79652404785156, Neurons: 42, Grad norm: 4.668e+01\n",
      "Epoch 3789, Loss: 169.61619567871094, Neurons: 42, Grad norm: 4.561e+01\n",
      "Epoch 3789, Loss: 169.61619567871094, Neurons: 42, Grad norm: 4.561e+01\n",
      "Epoch 3790, Loss: 169.43905639648438, Neurons: 42, Grad norm: 4.462e+01\n",
      "Epoch 3790, Loss: 169.43905639648438, Neurons: 42, Grad norm: 4.462e+01\n",
      "Epoch 3791, Loss: 169.2648468017578, Neurons: 42, Grad norm: 4.368e+01\n",
      "Epoch 3791, Loss: 169.2648468017578, Neurons: 42, Grad norm: 4.368e+01\n",
      "Epoch 3792, Loss: 169.0933074951172, Neurons: 42, Grad norm: 4.278e+01\n",
      "Epoch 3792, Loss: 169.0933074951172, Neurons: 42, Grad norm: 4.278e+01\n",
      "Epoch 3793, Loss: 168.92425537109375, Neurons: 42, Grad norm: 4.194e+01\n",
      "Epoch 3793, Loss: 168.92425537109375, Neurons: 42, Grad norm: 4.194e+01\n",
      "Epoch 3794, Loss: 168.75750732421875, Neurons: 42, Grad norm: 4.114e+01\n",
      "Epoch 3794, Loss: 168.75750732421875, Neurons: 42, Grad norm: 4.114e+01\n",
      "Epoch 3795, Loss: 168.59288024902344, Neurons: 42, Grad norm: 4.038e+01\n",
      "Epoch 3795, Loss: 168.59288024902344, Neurons: 42, Grad norm: 4.038e+01\n",
      "Epoch 3796, Loss: 168.43019104003906, Neurons: 42, Grad norm: 3.968e+01\n",
      "Epoch 3796, Loss: 168.43019104003906, Neurons: 42, Grad norm: 3.968e+01\n",
      "Epoch 3797, Loss: 168.26934814453125, Neurons: 42, Grad norm: 3.902e+01\n",
      "Epoch 3797, Loss: 168.26934814453125, Neurons: 42, Grad norm: 3.902e+01\n",
      "Epoch 3798, Loss: 168.11012268066406, Neurons: 42, Grad norm: 3.838e+01\n",
      "Epoch 3798, Loss: 168.11012268066406, Neurons: 42, Grad norm: 3.838e+01\n",
      "Epoch 3799, Loss: 167.95237731933594, Neurons: 42, Grad norm: 3.777e+01\n",
      "Epoch 3799, Loss: 167.95237731933594, Neurons: 42, Grad norm: 3.777e+01\n",
      "Epoch 3799, Test loss: 163.50941467285156\n",
      "Epoch 3799, Test loss: 163.50941467285156\n",
      "Added neuron to hidden layer 1 with activation tanh\n",
      "Added neuron to hidden layer 1 with activation tanh\n",
      "network shape updated to :[17, 25, 1]\n",
      "network shape updated to :[17, 25, 1]\n",
      "Epoch 3800, Loss: 184.3238525390625, Neurons: 43, Grad norm: 2.069e+02\n",
      "Epoch 3800, Loss: 184.3238525390625, Neurons: 43, Grad norm: 2.069e+02\n",
      "Epoch 3801, Loss: 183.69712829589844, Neurons: 43, Grad norm: 2.021e+02\n",
      "Epoch 3801, Loss: 183.69712829589844, Neurons: 43, Grad norm: 2.021e+02\n",
      "Epoch 3802, Loss: 183.0538787841797, Neurons: 43, Grad norm: 1.970e+02\n",
      "Epoch 3802, Loss: 183.0538787841797, Neurons: 43, Grad norm: 1.970e+02\n",
      "Epoch 3803, Loss: 182.3963165283203, Neurons: 43, Grad norm: 1.918e+02\n",
      "Epoch 3803, Loss: 182.3963165283203, Neurons: 43, Grad norm: 1.918e+02\n",
      "Epoch 3804, Loss: 181.7267608642578, Neurons: 43, Grad norm: 1.865e+02\n",
      "Epoch 3804, Loss: 181.7267608642578, Neurons: 43, Grad norm: 1.865e+02\n",
      "Epoch 3805, Loss: 181.04776000976562, Neurons: 43, Grad norm: 1.810e+02\n",
      "Epoch 3805, Loss: 181.04776000976562, Neurons: 43, Grad norm: 1.810e+02\n",
      "Epoch 3806, Loss: 180.36181640625, Neurons: 43, Grad norm: 1.754e+02\n",
      "Epoch 3806, Loss: 180.36181640625, Neurons: 43, Grad norm: 1.754e+02\n",
      "Epoch 3807, Loss: 179.67164611816406, Neurons: 43, Grad norm: 1.698e+02\n",
      "Epoch 3807, Loss: 179.67164611816406, Neurons: 43, Grad norm: 1.698e+02\n",
      "Epoch 3808, Loss: 178.97996520996094, Neurons: 43, Grad norm: 1.641e+02\n",
      "Epoch 3808, Loss: 178.97996520996094, Neurons: 43, Grad norm: 1.641e+02\n",
      "Epoch 3809, Loss: 178.28956604003906, Neurons: 43, Grad norm: 1.584e+02\n",
      "Epoch 3809, Loss: 178.28956604003906, Neurons: 43, Grad norm: 1.584e+02\n",
      "Epoch 3810, Loss: 177.6031036376953, Neurons: 43, Grad norm: 1.528e+02\n",
      "Epoch 3810, Loss: 177.6031036376953, Neurons: 43, Grad norm: 1.528e+02\n",
      "Epoch 3811, Loss: 176.92320251464844, Neurons: 43, Grad norm: 1.471e+02\n",
      "Epoch 3811, Loss: 176.92320251464844, Neurons: 43, Grad norm: 1.471e+02\n",
      "Epoch 3812, Loss: 176.25247192382812, Neurons: 43, Grad norm: 1.415e+02\n",
      "Epoch 3812, Loss: 176.25247192382812, Neurons: 43, Grad norm: 1.415e+02\n",
      "Epoch 3813, Loss: 175.59335327148438, Neurons: 43, Grad norm: 1.360e+02\n",
      "Epoch 3813, Loss: 175.59335327148438, Neurons: 43, Grad norm: 1.360e+02\n",
      "Epoch 3814, Loss: 174.9480438232422, Neurons: 43, Grad norm: 1.305e+02\n",
      "Epoch 3814, Loss: 174.9480438232422, Neurons: 43, Grad norm: 1.305e+02\n",
      "Epoch 3815, Loss: 174.31869506835938, Neurons: 43, Grad norm: 1.251e+02\n",
      "Epoch 3815, Loss: 174.31869506835938, Neurons: 43, Grad norm: 1.251e+02\n",
      "Epoch 3816, Loss: 173.70730590820312, Neurons: 43, Grad norm: 1.197e+02\n",
      "Epoch 3816, Loss: 173.70730590820312, Neurons: 43, Grad norm: 1.197e+02\n",
      "Epoch 3817, Loss: 173.11553955078125, Neurons: 43, Grad norm: 1.145e+02\n",
      "Epoch 3817, Loss: 173.11553955078125, Neurons: 43, Grad norm: 1.145e+02\n",
      "Epoch 3818, Loss: 172.5448760986328, Neurons: 43, Grad norm: 1.094e+02\n",
      "Epoch 3818, Loss: 172.5448760986328, Neurons: 43, Grad norm: 1.094e+02\n",
      "Epoch 3819, Loss: 171.99661254882812, Neurons: 43, Grad norm: 1.043e+02\n",
      "Epoch 3819, Loss: 171.99661254882812, Neurons: 43, Grad norm: 1.043e+02\n",
      "Epoch 3820, Loss: 171.4716339111328, Neurons: 43, Grad norm: 9.939e+01\n",
      "Epoch 3820, Loss: 171.4716339111328, Neurons: 43, Grad norm: 9.939e+01\n",
      "Epoch 3821, Loss: 170.970947265625, Neurons: 43, Grad norm: 9.460e+01\n",
      "Epoch 3821, Loss: 170.970947265625, Neurons: 43, Grad norm: 9.460e+01\n",
      "Epoch 3822, Loss: 170.49508666992188, Neurons: 43, Grad norm: 8.996e+01\n",
      "Epoch 3822, Loss: 170.49508666992188, Neurons: 43, Grad norm: 8.996e+01\n",
      "Epoch 3823, Loss: 170.04454040527344, Neurons: 43, Grad norm: 8.555e+01\n",
      "Epoch 3823, Loss: 170.04454040527344, Neurons: 43, Grad norm: 8.555e+01\n",
      "Epoch 3824, Loss: 169.6194305419922, Neurons: 43, Grad norm: 8.135e+01\n",
      "Epoch 3824, Loss: 169.6194305419922, Neurons: 43, Grad norm: 8.135e+01\n",
      "Epoch 3825, Loss: 169.2201690673828, Neurons: 43, Grad norm: 8.192e+01\n",
      "Epoch 3825, Loss: 169.2201690673828, Neurons: 43, Grad norm: 8.192e+01\n",
      "Epoch 3826, Loss: 168.82566833496094, Neurons: 43, Grad norm: 7.445e+01\n",
      "Epoch 3826, Loss: 168.82566833496094, Neurons: 43, Grad norm: 7.445e+01\n",
      "Epoch 3827, Loss: 168.45358276367188, Neurons: 43, Grad norm: 6.982e+01\n",
      "Epoch 3827, Loss: 168.45358276367188, Neurons: 43, Grad norm: 6.982e+01\n",
      "Epoch 3828, Loss: 168.11968994140625, Neurons: 43, Grad norm: 6.647e+01\n",
      "Epoch 3828, Loss: 168.11968994140625, Neurons: 43, Grad norm: 6.647e+01\n",
      "Epoch 3829, Loss: 167.81317138671875, Neurons: 43, Grad norm: 6.328e+01\n",
      "Epoch 3829, Loss: 167.81317138671875, Neurons: 43, Grad norm: 6.328e+01\n",
      "Epoch 3830, Loss: 167.52435302734375, Neurons: 43, Grad norm: 6.029e+01\n",
      "Epoch 3830, Loss: 167.52435302734375, Neurons: 43, Grad norm: 6.029e+01\n",
      "Epoch 3831, Loss: 167.25181579589844, Neurons: 43, Grad norm: 5.751e+01\n",
      "Epoch 3831, Loss: 167.25181579589844, Neurons: 43, Grad norm: 5.751e+01\n",
      "Epoch 3832, Loss: 166.99429321289062, Neurons: 43, Grad norm: 5.495e+01\n",
      "Epoch 3832, Loss: 166.99429321289062, Neurons: 43, Grad norm: 5.495e+01\n",
      "Epoch 3833, Loss: 166.7505645751953, Neurons: 43, Grad norm: 5.260e+01\n",
      "Epoch 3833, Loss: 166.7505645751953, Neurons: 43, Grad norm: 5.260e+01\n",
      "Epoch 3834, Loss: 166.5194549560547, Neurons: 43, Grad norm: 5.039e+01\n",
      "Epoch 3834, Loss: 166.5194549560547, Neurons: 43, Grad norm: 5.039e+01\n",
      "Epoch 3835, Loss: 166.29977416992188, Neurons: 43, Grad norm: 4.840e+01\n",
      "Epoch 3835, Loss: 166.29977416992188, Neurons: 43, Grad norm: 4.840e+01\n",
      "Epoch 3836, Loss: 166.09039306640625, Neurons: 43, Grad norm: 4.660e+01\n",
      "Epoch 3836, Loss: 166.09039306640625, Neurons: 43, Grad norm: 4.660e+01\n",
      "Epoch 3837, Loss: 165.89019775390625, Neurons: 43, Grad norm: 4.495e+01\n",
      "Epoch 3837, Loss: 165.89019775390625, Neurons: 43, Grad norm: 4.495e+01\n",
      "Epoch 3838, Loss: 165.69810485839844, Neurons: 43, Grad norm: 4.348e+01\n",
      "Epoch 3838, Loss: 165.69810485839844, Neurons: 43, Grad norm: 4.348e+01\n",
      "Epoch 3839, Loss: 165.51312255859375, Neurons: 43, Grad norm: 4.210e+01\n",
      "Epoch 3839, Loss: 165.51312255859375, Neurons: 43, Grad norm: 4.210e+01\n",
      "Epoch 3840, Loss: 165.33448791503906, Neurons: 43, Grad norm: 4.088e+01\n",
      "Epoch 3840, Loss: 165.33448791503906, Neurons: 43, Grad norm: 4.088e+01\n",
      "Epoch 3841, Loss: 165.16140747070312, Neurons: 43, Grad norm: 3.978e+01\n",
      "Epoch 3841, Loss: 165.16140747070312, Neurons: 43, Grad norm: 3.978e+01\n",
      "Epoch 3842, Loss: 164.99313354492188, Neurons: 43, Grad norm: 3.881e+01\n",
      "Epoch 3842, Loss: 164.99313354492188, Neurons: 43, Grad norm: 3.881e+01\n",
      "Epoch 3843, Loss: 164.82896423339844, Neurons: 43, Grad norm: 3.796e+01\n",
      "Epoch 3843, Loss: 164.82896423339844, Neurons: 43, Grad norm: 3.796e+01\n",
      "Epoch 3844, Loss: 164.6682891845703, Neurons: 43, Grad norm: 3.721e+01\n",
      "Epoch 3844, Loss: 164.6682891845703, Neurons: 43, Grad norm: 3.721e+01\n",
      "Epoch 3845, Loss: 164.51051330566406, Neurons: 43, Grad norm: 3.656e+01\n",
      "Epoch 3845, Loss: 164.51051330566406, Neurons: 43, Grad norm: 3.656e+01\n",
      "Epoch 3846, Loss: 164.35507202148438, Neurons: 43, Grad norm: 3.599e+01\n",
      "Epoch 3846, Loss: 164.35507202148438, Neurons: 43, Grad norm: 3.599e+01\n",
      "Epoch 3847, Loss: 164.20152282714844, Neurons: 43, Grad norm: 3.551e+01\n",
      "Epoch 3847, Loss: 164.20152282714844, Neurons: 43, Grad norm: 3.551e+01\n",
      "Epoch 3848, Loss: 164.0495147705078, Neurons: 43, Grad norm: 3.512e+01\n",
      "Epoch 3848, Loss: 164.0495147705078, Neurons: 43, Grad norm: 3.512e+01\n",
      "Epoch 3849, Loss: 163.8986358642578, Neurons: 43, Grad norm: 3.476e+01\n",
      "Epoch 3849, Loss: 163.8986358642578, Neurons: 43, Grad norm: 3.476e+01\n",
      "Epoch 3850, Loss: 163.74859619140625, Neurons: 43, Grad norm: 3.445e+01\n",
      "Epoch 3850, Loss: 163.74859619140625, Neurons: 43, Grad norm: 3.445e+01\n",
      "Epoch 3851, Loss: 163.5991668701172, Neurons: 43, Grad norm: 3.418e+01\n",
      "Epoch 3851, Loss: 163.5991668701172, Neurons: 43, Grad norm: 3.418e+01\n",
      "Epoch 3852, Loss: 163.45008850097656, Neurons: 43, Grad norm: 3.391e+01\n",
      "Epoch 3852, Loss: 163.45008850097656, Neurons: 43, Grad norm: 3.391e+01\n",
      "Epoch 3853, Loss: 163.30125427246094, Neurons: 43, Grad norm: 3.369e+01\n",
      "Epoch 3853, Loss: 163.30125427246094, Neurons: 43, Grad norm: 3.369e+01\n",
      "Epoch 3854, Loss: 163.15248107910156, Neurons: 43, Grad norm: 3.348e+01\n",
      "Epoch 3854, Loss: 163.15248107910156, Neurons: 43, Grad norm: 3.348e+01\n",
      "Epoch 3855, Loss: 163.00363159179688, Neurons: 43, Grad norm: 3.324e+01\n",
      "Epoch 3855, Loss: 163.00363159179688, Neurons: 43, Grad norm: 3.324e+01\n",
      "Epoch 3856, Loss: 162.85462951660156, Neurons: 43, Grad norm: 3.302e+01\n",
      "Epoch 3856, Loss: 162.85462951660156, Neurons: 43, Grad norm: 3.302e+01\n",
      "Epoch 3857, Loss: 162.70542907714844, Neurons: 43, Grad norm: 3.279e+01\n",
      "Epoch 3857, Loss: 162.70542907714844, Neurons: 43, Grad norm: 3.279e+01\n",
      "Epoch 3858, Loss: 162.55604553222656, Neurons: 43, Grad norm: 3.258e+01\n",
      "Epoch 3858, Loss: 162.55604553222656, Neurons: 43, Grad norm: 3.258e+01\n",
      "Epoch 3859, Loss: 162.40635681152344, Neurons: 43, Grad norm: 3.236e+01\n",
      "Epoch 3859, Loss: 162.40635681152344, Neurons: 43, Grad norm: 3.236e+01\n",
      "Epoch 3860, Loss: 162.2564239501953, Neurons: 43, Grad norm: 3.216e+01\n",
      "Epoch 3860, Loss: 162.2564239501953, Neurons: 43, Grad norm: 3.216e+01\n",
      "Epoch 3861, Loss: 162.1062469482422, Neurons: 43, Grad norm: 3.196e+01\n",
      "Epoch 3861, Loss: 162.1062469482422, Neurons: 43, Grad norm: 3.196e+01\n",
      "Epoch 3862, Loss: 161.955810546875, Neurons: 43, Grad norm: 3.178e+01\n",
      "Epoch 3862, Loss: 161.955810546875, Neurons: 43, Grad norm: 3.178e+01\n",
      "Epoch 3863, Loss: 161.80516052246094, Neurons: 43, Grad norm: 3.161e+01\n",
      "Epoch 3863, Loss: 161.80516052246094, Neurons: 43, Grad norm: 3.161e+01\n",
      "Epoch 3864, Loss: 161.65428161621094, Neurons: 43, Grad norm: 3.144e+01\n",
      "Epoch 3864, Loss: 161.65428161621094, Neurons: 43, Grad norm: 3.144e+01\n",
      "Epoch 3865, Loss: 161.50320434570312, Neurons: 43, Grad norm: 3.130e+01\n",
      "Epoch 3865, Loss: 161.50320434570312, Neurons: 43, Grad norm: 3.130e+01\n",
      "Epoch 3866, Loss: 161.3519744873047, Neurons: 43, Grad norm: 3.116e+01\n",
      "Epoch 3866, Loss: 161.3519744873047, Neurons: 43, Grad norm: 3.116e+01\n",
      "Epoch 3867, Loss: 161.2006072998047, Neurons: 43, Grad norm: 3.104e+01\n",
      "Epoch 3867, Loss: 161.2006072998047, Neurons: 43, Grad norm: 3.104e+01\n",
      "Epoch 3868, Loss: 161.04910278320312, Neurons: 43, Grad norm: 3.091e+01\n",
      "Epoch 3868, Loss: 161.04910278320312, Neurons: 43, Grad norm: 3.091e+01\n",
      "Epoch 3869, Loss: 160.8975067138672, Neurons: 43, Grad norm: 3.083e+01\n",
      "Epoch 3869, Loss: 160.8975067138672, Neurons: 43, Grad norm: 3.083e+01\n",
      "Epoch 3870, Loss: 160.74606323242188, Neurons: 43, Grad norm: 3.091e+01\n",
      "Epoch 3870, Loss: 160.74606323242188, Neurons: 43, Grad norm: 3.091e+01\n",
      "Epoch 3871, Loss: 160.59478759765625, Neurons: 43, Grad norm: 3.079e+01\n",
      "Epoch 3871, Loss: 160.59478759765625, Neurons: 43, Grad norm: 3.079e+01\n",
      "Epoch 3872, Loss: 160.44309997558594, Neurons: 43, Grad norm: 3.049e+01\n",
      "Epoch 3872, Loss: 160.44309997558594, Neurons: 43, Grad norm: 3.049e+01\n",
      "Epoch 3873, Loss: 160.29116821289062, Neurons: 43, Grad norm: 3.043e+01\n",
      "Epoch 3873, Loss: 160.29116821289062, Neurons: 43, Grad norm: 3.043e+01\n",
      "Epoch 3874, Loss: 160.1395263671875, Neurons: 43, Grad norm: 3.036e+01\n",
      "Epoch 3874, Loss: 160.1395263671875, Neurons: 43, Grad norm: 3.036e+01\n",
      "Epoch 3875, Loss: 159.988037109375, Neurons: 43, Grad norm: 3.027e+01\n",
      "Epoch 3875, Loss: 159.988037109375, Neurons: 43, Grad norm: 3.027e+01\n",
      "Epoch 3876, Loss: 159.83656311035156, Neurons: 43, Grad norm: 3.020e+01\n",
      "Epoch 3876, Loss: 159.83656311035156, Neurons: 43, Grad norm: 3.020e+01\n",
      "Epoch 3877, Loss: 159.68504333496094, Neurons: 43, Grad norm: 3.010e+01\n",
      "Epoch 3877, Loss: 159.68504333496094, Neurons: 43, Grad norm: 3.010e+01\n",
      "Epoch 3878, Loss: 159.53350830078125, Neurons: 43, Grad norm: 3.000e+01\n",
      "Epoch 3878, Loss: 159.53350830078125, Neurons: 43, Grad norm: 3.000e+01\n",
      "Epoch 3879, Loss: 159.38197326660156, Neurons: 43, Grad norm: 2.991e+01\n",
      "Epoch 3879, Loss: 159.38197326660156, Neurons: 43, Grad norm: 2.991e+01\n",
      "Epoch 3880, Loss: 159.23043823242188, Neurons: 43, Grad norm: 2.980e+01\n",
      "Epoch 3880, Loss: 159.23043823242188, Neurons: 43, Grad norm: 2.980e+01\n",
      "Epoch 3881, Loss: 159.07894897460938, Neurons: 43, Grad norm: 2.970e+01\n",
      "Epoch 3881, Loss: 159.07894897460938, Neurons: 43, Grad norm: 2.970e+01\n",
      "Epoch 3882, Loss: 158.9274139404297, Neurons: 43, Grad norm: 2.961e+01\n",
      "Epoch 3882, Loss: 158.9274139404297, Neurons: 43, Grad norm: 2.961e+01\n",
      "Epoch 3883, Loss: 158.77584838867188, Neurons: 43, Grad norm: 2.945e+01\n",
      "Epoch 3883, Loss: 158.77584838867188, Neurons: 43, Grad norm: 2.945e+01\n",
      "Epoch 3884, Loss: 158.6243438720703, Neurons: 43, Grad norm: 2.947e+01\n",
      "Epoch 3884, Loss: 158.6243438720703, Neurons: 43, Grad norm: 2.947e+01\n",
      "Epoch 3885, Loss: 158.47299194335938, Neurons: 43, Grad norm: 2.937e+01\n",
      "Epoch 3885, Loss: 158.47299194335938, Neurons: 43, Grad norm: 2.937e+01\n",
      "Epoch 3886, Loss: 158.32144165039062, Neurons: 43, Grad norm: 2.920e+01\n",
      "Epoch 3886, Loss: 158.32144165039062, Neurons: 43, Grad norm: 2.920e+01\n",
      "Epoch 3887, Loss: 158.16978454589844, Neurons: 43, Grad norm: 2.919e+01\n",
      "Epoch 3887, Loss: 158.16978454589844, Neurons: 43, Grad norm: 2.919e+01\n",
      "Epoch 3888, Loss: 158.0181884765625, Neurons: 43, Grad norm: 2.911e+01\n",
      "Epoch 3888, Loss: 158.0181884765625, Neurons: 43, Grad norm: 2.911e+01\n",
      "Epoch 3889, Loss: 157.86660766601562, Neurons: 43, Grad norm: 2.904e+01\n",
      "Epoch 3889, Loss: 157.86660766601562, Neurons: 43, Grad norm: 2.904e+01\n",
      "Epoch 3890, Loss: 157.71493530273438, Neurons: 43, Grad norm: 2.896e+01\n",
      "Epoch 3890, Loss: 157.71493530273438, Neurons: 43, Grad norm: 2.896e+01\n",
      "Epoch 3891, Loss: 157.56314086914062, Neurons: 43, Grad norm: 2.887e+01\n",
      "Epoch 3891, Loss: 157.56314086914062, Neurons: 43, Grad norm: 2.887e+01\n",
      "Epoch 3892, Loss: 157.41128540039062, Neurons: 43, Grad norm: 2.871e+01\n",
      "Epoch 3892, Loss: 157.41128540039062, Neurons: 43, Grad norm: 2.871e+01\n",
      "Epoch 3893, Loss: 157.2593536376953, Neurons: 43, Grad norm: 2.861e+01\n",
      "Epoch 3893, Loss: 157.2593536376953, Neurons: 43, Grad norm: 2.861e+01\n",
      "Epoch 3894, Loss: 157.107421875, Neurons: 43, Grad norm: 2.855e+01\n",
      "Epoch 3894, Loss: 157.107421875, Neurons: 43, Grad norm: 2.855e+01\n",
      "Epoch 3895, Loss: 156.95545959472656, Neurons: 43, Grad norm: 2.842e+01\n",
      "Epoch 3895, Loss: 156.95545959472656, Neurons: 43, Grad norm: 2.842e+01\n",
      "Epoch 3896, Loss: 156.80331420898438, Neurons: 43, Grad norm: 2.833e+01\n",
      "Epoch 3896, Loss: 156.80331420898438, Neurons: 43, Grad norm: 2.833e+01\n",
      "Epoch 3897, Loss: 156.651123046875, Neurons: 43, Grad norm: 2.831e+01\n",
      "Epoch 3897, Loss: 156.651123046875, Neurons: 43, Grad norm: 2.831e+01\n",
      "Epoch 3898, Loss: 156.49891662597656, Neurons: 43, Grad norm: 2.821e+01\n",
      "Epoch 3898, Loss: 156.49891662597656, Neurons: 43, Grad norm: 2.821e+01\n",
      "Epoch 3899, Loss: 156.3466339111328, Neurons: 43, Grad norm: 2.809e+01\n",
      "Epoch 3899, Loss: 156.3466339111328, Neurons: 43, Grad norm: 2.809e+01\n",
      "Epoch 3899, Test loss: 151.63230895996094\n",
      "Epoch 3899, Test loss: 151.63230895996094\n",
      "Added neuron to hidden layer 1 with activation sin\n",
      "Added neuron to hidden layer 1 with activation sin\n",
      "network shape updated to :[18, 25, 1]\n",
      "network shape updated to :[18, 25, 1]\n",
      "Epoch 3900, Loss: 241.55142211914062, Neurons: 44, Grad norm: 4.481e+02\n",
      "Epoch 3900, Loss: 241.55142211914062, Neurons: 44, Grad norm: 4.481e+02\n",
      "Epoch 3901, Loss: 240.0129852294922, Neurons: 44, Grad norm: 4.416e+02\n",
      "Epoch 3901, Loss: 240.0129852294922, Neurons: 44, Grad norm: 4.416e+02\n",
      "Epoch 3902, Loss: 238.41778564453125, Neurons: 44, Grad norm: 4.349e+02\n",
      "Epoch 3902, Loss: 238.41778564453125, Neurons: 44, Grad norm: 4.349e+02\n",
      "Epoch 3903, Loss: 236.76853942871094, Neurons: 44, Grad norm: 4.280e+02\n",
      "Epoch 3903, Loss: 236.76853942871094, Neurons: 44, Grad norm: 4.280e+02\n",
      "Epoch 3904, Loss: 235.0684051513672, Neurons: 44, Grad norm: 4.209e+02\n",
      "Epoch 3904, Loss: 235.0684051513672, Neurons: 44, Grad norm: 4.209e+02\n",
      "Epoch 3905, Loss: 233.32119750976562, Neurons: 44, Grad norm: 4.135e+02\n",
      "Epoch 3905, Loss: 233.32119750976562, Neurons: 44, Grad norm: 4.135e+02\n",
      "Epoch 3906, Loss: 231.53118896484375, Neurons: 44, Grad norm: 4.060e+02\n",
      "Epoch 3906, Loss: 231.53118896484375, Neurons: 44, Grad norm: 4.060e+02\n",
      "Epoch 3907, Loss: 229.70291137695312, Neurons: 44, Grad norm: 3.984e+02\n",
      "Epoch 3907, Loss: 229.70291137695312, Neurons: 44, Grad norm: 3.984e+02\n",
      "Epoch 3908, Loss: 227.8411865234375, Neurons: 44, Grad norm: 3.907e+02\n",
      "Epoch 3908, Loss: 227.8411865234375, Neurons: 44, Grad norm: 3.907e+02\n",
      "Epoch 3909, Loss: 225.9509735107422, Neurons: 44, Grad norm: 3.828e+02\n",
      "Epoch 3909, Loss: 225.9509735107422, Neurons: 44, Grad norm: 3.828e+02\n",
      "Epoch 3910, Loss: 224.03738403320312, Neurons: 44, Grad norm: 3.749e+02\n",
      "Epoch 3910, Loss: 224.03738403320312, Neurons: 44, Grad norm: 3.749e+02\n",
      "Epoch 3911, Loss: 222.10577392578125, Neurons: 44, Grad norm: 3.668e+02\n",
      "Epoch 3911, Loss: 222.10577392578125, Neurons: 44, Grad norm: 3.668e+02\n",
      "Epoch 3912, Loss: 220.16146850585938, Neurons: 44, Grad norm: 3.587e+02\n",
      "Epoch 3912, Loss: 220.16146850585938, Neurons: 44, Grad norm: 3.587e+02\n",
      "Epoch 3913, Loss: 218.20965576171875, Neurons: 44, Grad norm: 3.506e+02\n",
      "Epoch 3913, Loss: 218.20965576171875, Neurons: 44, Grad norm: 3.506e+02\n",
      "Epoch 3914, Loss: 216.2555389404297, Neurons: 44, Grad norm: 3.423e+02\n",
      "Epoch 3914, Loss: 216.2555389404297, Neurons: 44, Grad norm: 3.423e+02\n",
      "Epoch 3915, Loss: 214.30447387695312, Neurons: 44, Grad norm: 3.340e+02\n",
      "Epoch 3915, Loss: 214.30447387695312, Neurons: 44, Grad norm: 3.340e+02\n",
      "Epoch 3916, Loss: 212.36190795898438, Neurons: 44, Grad norm: 3.257e+02\n",
      "Epoch 3916, Loss: 212.36190795898438, Neurons: 44, Grad norm: 3.257e+02\n",
      "Epoch 3917, Loss: 210.43307495117188, Neurons: 44, Grad norm: 3.173e+02\n",
      "Epoch 3917, Loss: 210.43307495117188, Neurons: 44, Grad norm: 3.173e+02\n",
      "Epoch 3918, Loss: 208.52279663085938, Neurons: 44, Grad norm: 3.090e+02\n",
      "Epoch 3918, Loss: 208.52279663085938, Neurons: 44, Grad norm: 3.090e+02\n",
      "Epoch 3919, Loss: 206.63560485839844, Neurons: 44, Grad norm: 3.006e+02\n",
      "Epoch 3919, Loss: 206.63560485839844, Neurons: 44, Grad norm: 3.006e+02\n",
      "Epoch 3920, Loss: 204.7762451171875, Neurons: 44, Grad norm: 2.923e+02\n",
      "Epoch 3920, Loss: 204.7762451171875, Neurons: 44, Grad norm: 2.923e+02\n",
      "Epoch 3921, Loss: 202.94857788085938, Neurons: 44, Grad norm: 2.840e+02\n",
      "Epoch 3921, Loss: 202.94857788085938, Neurons: 44, Grad norm: 2.840e+02\n",
      "Epoch 3922, Loss: 201.15647888183594, Neurons: 44, Grad norm: 2.757e+02\n",
      "Epoch 3922, Loss: 201.15647888183594, Neurons: 44, Grad norm: 2.757e+02\n",
      "Epoch 3923, Loss: 199.40328979492188, Neurons: 44, Grad norm: 2.676e+02\n",
      "Epoch 3923, Loss: 199.40328979492188, Neurons: 44, Grad norm: 2.676e+02\n",
      "Epoch 3924, Loss: 197.69178771972656, Neurons: 44, Grad norm: 2.595e+02\n",
      "Epoch 3924, Loss: 197.69178771972656, Neurons: 44, Grad norm: 2.595e+02\n",
      "Epoch 3925, Loss: 196.0248565673828, Neurons: 44, Grad norm: 2.515e+02\n",
      "Epoch 3925, Loss: 196.0248565673828, Neurons: 44, Grad norm: 2.515e+02\n",
      "Epoch 3926, Loss: 194.4043426513672, Neurons: 44, Grad norm: 2.436e+02\n",
      "Epoch 3926, Loss: 194.4043426513672, Neurons: 44, Grad norm: 2.436e+02\n",
      "Epoch 3927, Loss: 192.8319854736328, Neurons: 44, Grad norm: 2.359e+02\n",
      "Epoch 3927, Loss: 192.8319854736328, Neurons: 44, Grad norm: 2.359e+02\n",
      "Epoch 3928, Loss: 191.30897521972656, Neurons: 44, Grad norm: 2.282e+02\n",
      "Epoch 3928, Loss: 191.30897521972656, Neurons: 44, Grad norm: 2.282e+02\n",
      "Epoch 3929, Loss: 189.8363800048828, Neurons: 44, Grad norm: 2.207e+02\n",
      "Epoch 3929, Loss: 189.8363800048828, Neurons: 44, Grad norm: 2.207e+02\n",
      "Epoch 3930, Loss: 188.41477966308594, Neurons: 44, Grad norm: 2.133e+02\n",
      "Epoch 3930, Loss: 188.41477966308594, Neurons: 44, Grad norm: 2.133e+02\n",
      "Epoch 3931, Loss: 187.04444885253906, Neurons: 44, Grad norm: 2.060e+02\n",
      "Epoch 3931, Loss: 187.04444885253906, Neurons: 44, Grad norm: 2.060e+02\n",
      "Epoch 3932, Loss: 185.72564697265625, Neurons: 44, Grad norm: 1.988e+02\n",
      "Epoch 3932, Loss: 185.72564697265625, Neurons: 44, Grad norm: 1.988e+02\n",
      "Epoch 3933, Loss: 184.45799255371094, Neurons: 44, Grad norm: 1.911e+02\n",
      "Epoch 3933, Loss: 184.45799255371094, Neurons: 44, Grad norm: 1.911e+02\n",
      "Epoch 3934, Loss: 183.24424743652344, Neurons: 44, Grad norm: 1.839e+02\n",
      "Epoch 3934, Loss: 183.24424743652344, Neurons: 44, Grad norm: 1.839e+02\n",
      "Epoch 3935, Loss: 182.08506774902344, Neurons: 44, Grad norm: 1.768e+02\n",
      "Epoch 3935, Loss: 182.08506774902344, Neurons: 44, Grad norm: 1.768e+02\n",
      "Epoch 3936, Loss: 180.97901916503906, Neurons: 44, Grad norm: 1.701e+02\n",
      "Epoch 3936, Loss: 180.97901916503906, Neurons: 44, Grad norm: 1.701e+02\n",
      "Epoch 3937, Loss: 179.92404174804688, Neurons: 44, Grad norm: 1.637e+02\n",
      "Epoch 3937, Loss: 179.92404174804688, Neurons: 44, Grad norm: 1.637e+02\n",
      "Epoch 3938, Loss: 178.91781616210938, Neurons: 44, Grad norm: 1.575e+02\n",
      "Epoch 3938, Loss: 178.91781616210938, Neurons: 44, Grad norm: 1.575e+02\n",
      "Epoch 3939, Loss: 177.9581298828125, Neurons: 44, Grad norm: 1.515e+02\n",
      "Epoch 3939, Loss: 177.9581298828125, Neurons: 44, Grad norm: 1.515e+02\n",
      "Epoch 3940, Loss: 177.0430908203125, Neurons: 44, Grad norm: 1.457e+02\n",
      "Epoch 3940, Loss: 177.0430908203125, Neurons: 44, Grad norm: 1.457e+02\n",
      "Epoch 3941, Loss: 176.17112731933594, Neurons: 44, Grad norm: 1.401e+02\n",
      "Epoch 3941, Loss: 176.17112731933594, Neurons: 44, Grad norm: 1.401e+02\n",
      "Epoch 3942, Loss: 175.34048461914062, Neurons: 44, Grad norm: 1.347e+02\n",
      "Epoch 3942, Loss: 175.34048461914062, Neurons: 44, Grad norm: 1.347e+02\n",
      "Epoch 3943, Loss: 174.5496063232422, Neurons: 44, Grad norm: 1.295e+02\n",
      "Epoch 3943, Loss: 174.5496063232422, Neurons: 44, Grad norm: 1.295e+02\n",
      "Epoch 3944, Loss: 173.79710388183594, Neurons: 44, Grad norm: 1.246e+02\n",
      "Epoch 3944, Loss: 173.79710388183594, Neurons: 44, Grad norm: 1.246e+02\n",
      "Epoch 3945, Loss: 173.08148193359375, Neurons: 44, Grad norm: 1.198e+02\n",
      "Epoch 3945, Loss: 173.08148193359375, Neurons: 44, Grad norm: 1.198e+02\n",
      "Epoch 3946, Loss: 172.40138244628906, Neurons: 44, Grad norm: 1.151e+02\n",
      "Epoch 3946, Loss: 172.40138244628906, Neurons: 44, Grad norm: 1.151e+02\n",
      "Epoch 3947, Loss: 171.75555419921875, Neurons: 44, Grad norm: 1.107e+02\n",
      "Epoch 3947, Loss: 171.75555419921875, Neurons: 44, Grad norm: 1.107e+02\n",
      "Epoch 3948, Loss: 171.1425018310547, Neurons: 44, Grad norm: 1.066e+02\n",
      "Epoch 3948, Loss: 171.1425018310547, Neurons: 44, Grad norm: 1.066e+02\n",
      "Epoch 3949, Loss: 170.56027221679688, Neurons: 44, Grad norm: 1.026e+02\n",
      "Epoch 3949, Loss: 170.56027221679688, Neurons: 44, Grad norm: 1.026e+02\n",
      "Epoch 3950, Loss: 170.00767517089844, Neurons: 44, Grad norm: 9.883e+01\n",
      "Epoch 3950, Loss: 170.00767517089844, Neurons: 44, Grad norm: 9.883e+01\n",
      "Epoch 3951, Loss: 169.48336791992188, Neurons: 44, Grad norm: 9.528e+01\n",
      "Epoch 3951, Loss: 169.48336791992188, Neurons: 44, Grad norm: 9.528e+01\n",
      "Epoch 3952, Loss: 168.98573303222656, Neurons: 44, Grad norm: 9.200e+01\n",
      "Epoch 3952, Loss: 168.98573303222656, Neurons: 44, Grad norm: 9.200e+01\n",
      "Epoch 3953, Loss: 168.51290893554688, Neurons: 44, Grad norm: 8.893e+01\n",
      "Epoch 3953, Loss: 168.51290893554688, Neurons: 44, Grad norm: 8.893e+01\n",
      "Epoch 3954, Loss: 168.063232421875, Neurons: 44, Grad norm: 8.612e+01\n",
      "Epoch 3954, Loss: 168.063232421875, Neurons: 44, Grad norm: 8.612e+01\n",
      "Epoch 3955, Loss: 167.63482666015625, Neurons: 44, Grad norm: 8.355e+01\n",
      "Epoch 3955, Loss: 167.63482666015625, Neurons: 44, Grad norm: 8.355e+01\n",
      "Epoch 3956, Loss: 167.2258758544922, Neurons: 44, Grad norm: 8.116e+01\n",
      "Epoch 3956, Loss: 167.2258758544922, Neurons: 44, Grad norm: 8.116e+01\n",
      "Epoch 3957, Loss: 166.8347625732422, Neurons: 44, Grad norm: 7.896e+01\n",
      "Epoch 3957, Loss: 166.8347625732422, Neurons: 44, Grad norm: 7.896e+01\n",
      "Epoch 3958, Loss: 166.459716796875, Neurons: 44, Grad norm: 7.694e+01\n",
      "Epoch 3958, Loss: 166.459716796875, Neurons: 44, Grad norm: 7.694e+01\n",
      "Epoch 3959, Loss: 166.0992889404297, Neurons: 44, Grad norm: 7.503e+01\n",
      "Epoch 3959, Loss: 166.0992889404297, Neurons: 44, Grad norm: 7.503e+01\n",
      "Epoch 3960, Loss: 165.75230407714844, Neurons: 44, Grad norm: 7.325e+01\n",
      "Epoch 3960, Loss: 165.75230407714844, Neurons: 44, Grad norm: 7.325e+01\n",
      "Epoch 3961, Loss: 165.417724609375, Neurons: 44, Grad norm: 7.157e+01\n",
      "Epoch 3961, Loss: 165.417724609375, Neurons: 44, Grad norm: 7.157e+01\n",
      "Epoch 3962, Loss: 165.09449768066406, Neurons: 44, Grad norm: 6.999e+01\n",
      "Epoch 3962, Loss: 165.09449768066406, Neurons: 44, Grad norm: 6.999e+01\n",
      "Epoch 3963, Loss: 164.7817840576172, Neurons: 44, Grad norm: 6.853e+01\n",
      "Epoch 3963, Loss: 164.7817840576172, Neurons: 44, Grad norm: 6.853e+01\n",
      "Epoch 3964, Loss: 164.47891235351562, Neurons: 44, Grad norm: 6.713e+01\n",
      "Epoch 3964, Loss: 164.47891235351562, Neurons: 44, Grad norm: 6.713e+01\n",
      "Epoch 3965, Loss: 164.1851348876953, Neurons: 44, Grad norm: 6.583e+01\n",
      "Epoch 3965, Loss: 164.1851348876953, Neurons: 44, Grad norm: 6.583e+01\n",
      "Epoch 3966, Loss: 163.8999786376953, Neurons: 44, Grad norm: 6.462e+01\n",
      "Epoch 3966, Loss: 163.8999786376953, Neurons: 44, Grad norm: 6.462e+01\n",
      "Epoch 3967, Loss: 163.62283325195312, Neurons: 44, Grad norm: 6.350e+01\n",
      "Epoch 3967, Loss: 163.62283325195312, Neurons: 44, Grad norm: 6.350e+01\n",
      "Epoch 3968, Loss: 163.3531951904297, Neurons: 44, Grad norm: 6.246e+01\n",
      "Epoch 3968, Loss: 163.3531951904297, Neurons: 44, Grad norm: 6.246e+01\n",
      "Epoch 3969, Loss: 163.09054565429688, Neurons: 44, Grad norm: 6.147e+01\n",
      "Epoch 3969, Loss: 163.09054565429688, Neurons: 44, Grad norm: 6.147e+01\n",
      "Epoch 3970, Loss: 162.83453369140625, Neurons: 44, Grad norm: 6.056e+01\n",
      "Epoch 3970, Loss: 162.83453369140625, Neurons: 44, Grad norm: 6.056e+01\n",
      "Epoch 3971, Loss: 162.58473205566406, Neurons: 44, Grad norm: 5.970e+01\n",
      "Epoch 3971, Loss: 162.58473205566406, Neurons: 44, Grad norm: 5.970e+01\n",
      "Epoch 3972, Loss: 162.3406524658203, Neurons: 44, Grad norm: 5.887e+01\n",
      "Epoch 3972, Loss: 162.3406524658203, Neurons: 44, Grad norm: 5.887e+01\n",
      "Epoch 3973, Loss: 162.1016387939453, Neurons: 44, Grad norm: 5.805e+01\n",
      "Epoch 3973, Loss: 162.1016387939453, Neurons: 44, Grad norm: 5.805e+01\n",
      "Epoch 3974, Loss: 161.8674774169922, Neurons: 44, Grad norm: 5.728e+01\n",
      "Epoch 3974, Loss: 161.8674774169922, Neurons: 44, Grad norm: 5.728e+01\n",
      "Epoch 3975, Loss: 161.63792419433594, Neurons: 44, Grad norm: 5.653e+01\n",
      "Epoch 3975, Loss: 161.63792419433594, Neurons: 44, Grad norm: 5.653e+01\n",
      "Epoch 3976, Loss: 161.4127960205078, Neurons: 44, Grad norm: 5.582e+01\n",
      "Epoch 3976, Loss: 161.4127960205078, Neurons: 44, Grad norm: 5.582e+01\n",
      "Epoch 3977, Loss: 161.1919403076172, Neurons: 44, Grad norm: 5.514e+01\n",
      "Epoch 3977, Loss: 161.1919403076172, Neurons: 44, Grad norm: 5.514e+01\n",
      "Epoch 3978, Loss: 160.97515869140625, Neurons: 44, Grad norm: 5.449e+01\n",
      "Epoch 3978, Loss: 160.97515869140625, Neurons: 44, Grad norm: 5.449e+01\n",
      "Epoch 3979, Loss: 160.76222229003906, Neurons: 44, Grad norm: 5.384e+01\n",
      "Epoch 3979, Loss: 160.76222229003906, Neurons: 44, Grad norm: 5.384e+01\n",
      "Epoch 3980, Loss: 160.55303955078125, Neurons: 44, Grad norm: 5.323e+01\n",
      "Epoch 3980, Loss: 160.55303955078125, Neurons: 44, Grad norm: 5.323e+01\n",
      "Epoch 3981, Loss: 160.34739685058594, Neurons: 44, Grad norm: 5.261e+01\n",
      "Epoch 3981, Loss: 160.34739685058594, Neurons: 44, Grad norm: 5.261e+01\n",
      "Epoch 3982, Loss: 160.14515686035156, Neurons: 44, Grad norm: 5.203e+01\n",
      "Epoch 3982, Loss: 160.14515686035156, Neurons: 44, Grad norm: 5.203e+01\n",
      "Epoch 3983, Loss: 159.9461669921875, Neurons: 44, Grad norm: 5.146e+01\n",
      "Epoch 3983, Loss: 159.9461669921875, Neurons: 44, Grad norm: 5.146e+01\n",
      "Epoch 3984, Loss: 159.7502899169922, Neurons: 44, Grad norm: 5.092e+01\n",
      "Epoch 3984, Loss: 159.7502899169922, Neurons: 44, Grad norm: 5.092e+01\n",
      "Epoch 3985, Loss: 159.55738830566406, Neurons: 44, Grad norm: 5.040e+01\n",
      "Epoch 3985, Loss: 159.55738830566406, Neurons: 44, Grad norm: 5.040e+01\n",
      "Epoch 3986, Loss: 159.36724853515625, Neurons: 44, Grad norm: 4.990e+01\n",
      "Epoch 3986, Loss: 159.36724853515625, Neurons: 44, Grad norm: 4.990e+01\n",
      "Epoch 3987, Loss: 159.17974853515625, Neurons: 44, Grad norm: 4.940e+01\n",
      "Epoch 3987, Loss: 159.17974853515625, Neurons: 44, Grad norm: 4.940e+01\n",
      "Epoch 3988, Loss: 158.9947509765625, Neurons: 44, Grad norm: 4.891e+01\n",
      "Epoch 3988, Loss: 158.9947509765625, Neurons: 44, Grad norm: 4.891e+01\n",
      "Epoch 3989, Loss: 158.81214904785156, Neurons: 44, Grad norm: 4.844e+01\n",
      "Epoch 3989, Loss: 158.81214904785156, Neurons: 44, Grad norm: 4.844e+01\n",
      "Epoch 3990, Loss: 158.6317901611328, Neurons: 44, Grad norm: 4.797e+01\n",
      "Epoch 3990, Loss: 158.6317901611328, Neurons: 44, Grad norm: 4.797e+01\n",
      "Epoch 3991, Loss: 158.45361328125, Neurons: 44, Grad norm: 4.751e+01\n",
      "Epoch 3991, Loss: 158.45361328125, Neurons: 44, Grad norm: 4.751e+01\n",
      "Epoch 3992, Loss: 158.27748107910156, Neurons: 44, Grad norm: 4.706e+01\n",
      "Epoch 3992, Loss: 158.27748107910156, Neurons: 44, Grad norm: 4.706e+01\n",
      "Epoch 3993, Loss: 158.10328674316406, Neurons: 44, Grad norm: 4.662e+01\n",
      "Epoch 3993, Loss: 158.10328674316406, Neurons: 44, Grad norm: 4.662e+01\n",
      "Epoch 3994, Loss: 157.93093872070312, Neurons: 44, Grad norm: 4.619e+01\n",
      "Epoch 3994, Loss: 157.93093872070312, Neurons: 44, Grad norm: 4.619e+01\n",
      "Epoch 3995, Loss: 157.76034545898438, Neurons: 44, Grad norm: 4.578e+01\n",
      "Epoch 3995, Loss: 157.76034545898438, Neurons: 44, Grad norm: 4.578e+01\n",
      "Epoch 3996, Loss: 157.5914764404297, Neurons: 44, Grad norm: 4.536e+01\n",
      "Epoch 3996, Loss: 157.5914764404297, Neurons: 44, Grad norm: 4.536e+01\n",
      "Epoch 3997, Loss: 157.4241943359375, Neurons: 44, Grad norm: 4.496e+01\n",
      "Epoch 3997, Loss: 157.4241943359375, Neurons: 44, Grad norm: 4.496e+01\n",
      "Epoch 3998, Loss: 157.25843811035156, Neurons: 44, Grad norm: 4.456e+01\n",
      "Epoch 3998, Loss: 157.25843811035156, Neurons: 44, Grad norm: 4.456e+01\n",
      "Epoch 3999, Loss: 157.09413146972656, Neurons: 44, Grad norm: 4.417e+01\n",
      "Epoch 3999, Loss: 157.09413146972656, Neurons: 44, Grad norm: 4.417e+01\n",
      "Epoch 3999, Test loss: 152.98361206054688\n",
      "Epoch 3999, Test loss: 152.98361206054688\n",
      "Removed neuron to hidden layer 1 at index 17\n",
      "Removed neuron to hidden layer 1 at index 17\n",
      "network shape updated to :[17, 25, 1]\n",
      "network shape updated to :[17, 25, 1]\n",
      "Epoch 4000, Loss: 195.8997344970703, Neurons: 43, Grad norm: 3.732e+02\n",
      "Epoch 4000, Loss: 195.8997344970703, Neurons: 43, Grad norm: 3.732e+02\n",
      "Epoch 4001, Loss: 194.76394653320312, Neurons: 43, Grad norm: 3.644e+02\n",
      "Epoch 4001, Loss: 194.76394653320312, Neurons: 43, Grad norm: 3.644e+02\n",
      "Epoch 4002, Loss: 193.59344482421875, Neurons: 43, Grad norm: 3.556e+02\n",
      "Epoch 4002, Loss: 193.59344482421875, Neurons: 43, Grad norm: 3.556e+02\n",
      "Epoch 4003, Loss: 192.39031982421875, Neurons: 43, Grad norm: 3.466e+02\n",
      "Epoch 4003, Loss: 192.39031982421875, Neurons: 43, Grad norm: 3.466e+02\n",
      "Epoch 4004, Loss: 191.1577606201172, Neurons: 43, Grad norm: 3.374e+02\n",
      "Epoch 4004, Loss: 191.1577606201172, Neurons: 43, Grad norm: 3.374e+02\n",
      "Epoch 4005, Loss: 189.89935302734375, Neurons: 43, Grad norm: 3.282e+02\n",
      "Epoch 4005, Loss: 189.89935302734375, Neurons: 43, Grad norm: 3.282e+02\n",
      "Epoch 4006, Loss: 188.6193389892578, Neurons: 43, Grad norm: 3.188e+02\n",
      "Epoch 4006, Loss: 188.6193389892578, Neurons: 43, Grad norm: 3.188e+02\n",
      "Epoch 4007, Loss: 187.32200622558594, Neurons: 43, Grad norm: 3.094e+02\n",
      "Epoch 4007, Loss: 187.32200622558594, Neurons: 43, Grad norm: 3.094e+02\n",
      "Epoch 4008, Loss: 186.01210021972656, Neurons: 43, Grad norm: 3.000e+02\n",
      "Epoch 4008, Loss: 186.01210021972656, Neurons: 43, Grad norm: 3.000e+02\n",
      "Epoch 4009, Loss: 184.69439697265625, Neurons: 43, Grad norm: 2.906e+02\n",
      "Epoch 4009, Loss: 184.69439697265625, Neurons: 43, Grad norm: 2.906e+02\n",
      "Epoch 4010, Loss: 183.37379455566406, Neurons: 43, Grad norm: 2.814e+02\n",
      "Epoch 4010, Loss: 183.37379455566406, Neurons: 43, Grad norm: 2.814e+02\n",
      "Epoch 4011, Loss: 182.0548858642578, Neurons: 43, Grad norm: 2.724e+02\n",
      "Epoch 4011, Loss: 182.0548858642578, Neurons: 43, Grad norm: 2.724e+02\n",
      "Epoch 4012, Loss: 180.74241638183594, Neurons: 43, Grad norm: 2.635e+02\n",
      "Epoch 4012, Loss: 180.74241638183594, Neurons: 43, Grad norm: 2.635e+02\n",
      "Epoch 4013, Loss: 179.44078063964844, Neurons: 43, Grad norm: 2.548e+02\n",
      "Epoch 4013, Loss: 179.44078063964844, Neurons: 43, Grad norm: 2.548e+02\n",
      "Epoch 4014, Loss: 178.15403747558594, Neurons: 43, Grad norm: 2.464e+02\n",
      "Epoch 4014, Loss: 178.15403747558594, Neurons: 43, Grad norm: 2.464e+02\n",
      "Epoch 4015, Loss: 176.8859405517578, Neurons: 43, Grad norm: 2.383e+02\n",
      "Epoch 4015, Loss: 176.8859405517578, Neurons: 43, Grad norm: 2.383e+02\n",
      "Epoch 4016, Loss: 175.63975524902344, Neurons: 43, Grad norm: 2.304e+02\n",
      "Epoch 4016, Loss: 175.63975524902344, Neurons: 43, Grad norm: 2.304e+02\n",
      "Epoch 4017, Loss: 174.4185333251953, Neurons: 43, Grad norm: 2.228e+02\n",
      "Epoch 4017, Loss: 174.4185333251953, Neurons: 43, Grad norm: 2.228e+02\n",
      "Epoch 4018, Loss: 173.2245635986328, Neurons: 43, Grad norm: 2.155e+02\n",
      "Epoch 4018, Loss: 173.2245635986328, Neurons: 43, Grad norm: 2.155e+02\n",
      "Epoch 4019, Loss: 172.05992126464844, Neurons: 43, Grad norm: 2.085e+02\n",
      "Epoch 4019, Loss: 172.05992126464844, Neurons: 43, Grad norm: 2.085e+02\n",
      "Epoch 4020, Loss: 170.92623901367188, Neurons: 43, Grad norm: 2.016e+02\n",
      "Epoch 4020, Loss: 170.92623901367188, Neurons: 43, Grad norm: 2.016e+02\n",
      "Epoch 4021, Loss: 169.82489013671875, Neurons: 43, Grad norm: 1.949e+02\n",
      "Epoch 4021, Loss: 169.82489013671875, Neurons: 43, Grad norm: 1.949e+02\n",
      "Epoch 4022, Loss: 168.75704956054688, Neurons: 43, Grad norm: 1.885e+02\n",
      "Epoch 4022, Loss: 168.75704956054688, Neurons: 43, Grad norm: 1.885e+02\n",
      "Epoch 4023, Loss: 167.72341918945312, Neurons: 43, Grad norm: 1.821e+02\n",
      "Epoch 4023, Loss: 167.72341918945312, Neurons: 43, Grad norm: 1.821e+02\n",
      "Epoch 4024, Loss: 166.72479248046875, Neurons: 43, Grad norm: 1.762e+02\n",
      "Epoch 4024, Loss: 166.72479248046875, Neurons: 43, Grad norm: 1.762e+02\n",
      "Epoch 4025, Loss: 165.7605438232422, Neurons: 43, Grad norm: 1.715e+02\n",
      "Epoch 4025, Loss: 165.7605438232422, Neurons: 43, Grad norm: 1.715e+02\n",
      "Epoch 4026, Loss: 164.8274383544922, Neurons: 43, Grad norm: 1.650e+02\n",
      "Epoch 4026, Loss: 164.8274383544922, Neurons: 43, Grad norm: 1.650e+02\n",
      "Epoch 4027, Loss: 163.92288208007812, Neurons: 43, Grad norm: 1.596e+02\n",
      "Epoch 4027, Loss: 163.92288208007812, Neurons: 43, Grad norm: 1.596e+02\n",
      "Epoch 4028, Loss: 163.048095703125, Neurons: 43, Grad norm: 1.535e+02\n",
      "Epoch 4028, Loss: 163.048095703125, Neurons: 43, Grad norm: 1.535e+02\n",
      "Epoch 4029, Loss: 162.20730590820312, Neurons: 43, Grad norm: 1.474e+02\n",
      "Epoch 4029, Loss: 162.20730590820312, Neurons: 43, Grad norm: 1.474e+02\n",
      "Epoch 4030, Loss: 161.4051971435547, Neurons: 43, Grad norm: 1.416e+02\n",
      "Epoch 4030, Loss: 161.4051971435547, Neurons: 43, Grad norm: 1.416e+02\n",
      "Epoch 4031, Loss: 160.6414794921875, Neurons: 43, Grad norm: 1.359e+02\n",
      "Epoch 4031, Loss: 160.6414794921875, Neurons: 43, Grad norm: 1.359e+02\n",
      "Epoch 4032, Loss: 159.9142608642578, Neurons: 43, Grad norm: 1.305e+02\n",
      "Epoch 4032, Loss: 159.9142608642578, Neurons: 43, Grad norm: 1.305e+02\n",
      "Epoch 4033, Loss: 159.22271728515625, Neurons: 43, Grad norm: 1.251e+02\n",
      "Epoch 4033, Loss: 159.22271728515625, Neurons: 43, Grad norm: 1.251e+02\n",
      "Epoch 4034, Loss: 158.5654754638672, Neurons: 43, Grad norm: 1.199e+02\n",
      "Epoch 4034, Loss: 158.5654754638672, Neurons: 43, Grad norm: 1.199e+02\n",
      "Epoch 4035, Loss: 157.94190979003906, Neurons: 43, Grad norm: 1.148e+02\n",
      "Epoch 4035, Loss: 157.94190979003906, Neurons: 43, Grad norm: 1.148e+02\n",
      "Epoch 4036, Loss: 157.35147094726562, Neurons: 43, Grad norm: 1.099e+02\n",
      "Epoch 4036, Loss: 157.35147094726562, Neurons: 43, Grad norm: 1.099e+02\n",
      "Epoch 4037, Loss: 156.79331970214844, Neurons: 43, Grad norm: 1.052e+02\n",
      "Epoch 4037, Loss: 156.79331970214844, Neurons: 43, Grad norm: 1.052e+02\n",
      "Epoch 4038, Loss: 156.266357421875, Neurons: 43, Grad norm: 1.006e+02\n",
      "Epoch 4038, Loss: 156.266357421875, Neurons: 43, Grad norm: 1.006e+02\n",
      "Epoch 4039, Loss: 155.76953125, Neurons: 43, Grad norm: 9.623e+01\n",
      "Epoch 4039, Loss: 155.76953125, Neurons: 43, Grad norm: 9.623e+01\n",
      "Epoch 4040, Loss: 155.3017120361328, Neurons: 43, Grad norm: 9.204e+01\n",
      "Epoch 4040, Loss: 155.3017120361328, Neurons: 43, Grad norm: 9.204e+01\n",
      "Epoch 4041, Loss: 154.86146545410156, Neurons: 43, Grad norm: 8.802e+01\n",
      "Epoch 4041, Loss: 154.86146545410156, Neurons: 43, Grad norm: 8.802e+01\n",
      "Epoch 4042, Loss: 154.44747924804688, Neurons: 43, Grad norm: 8.421e+01\n",
      "Epoch 4042, Loss: 154.44747924804688, Neurons: 43, Grad norm: 8.421e+01\n",
      "Epoch 4043, Loss: 154.05831909179688, Neurons: 43, Grad norm: 8.055e+01\n",
      "Epoch 4043, Loss: 154.05831909179688, Neurons: 43, Grad norm: 8.055e+01\n",
      "Epoch 4044, Loss: 153.6925048828125, Neurons: 43, Grad norm: 7.702e+01\n",
      "Epoch 4044, Loss: 153.6925048828125, Neurons: 43, Grad norm: 7.702e+01\n",
      "Epoch 4045, Loss: 153.3487548828125, Neurons: 43, Grad norm: 7.368e+01\n",
      "Epoch 4045, Loss: 153.3487548828125, Neurons: 43, Grad norm: 7.368e+01\n",
      "Epoch 4046, Loss: 153.02566528320312, Neurons: 43, Grad norm: 7.044e+01\n",
      "Epoch 4046, Loss: 153.02566528320312, Neurons: 43, Grad norm: 7.044e+01\n",
      "Epoch 4047, Loss: 152.72193908691406, Neurons: 43, Grad norm: 6.740e+01\n",
      "Epoch 4047, Loss: 152.72193908691406, Neurons: 43, Grad norm: 6.740e+01\n",
      "Epoch 4048, Loss: 152.4361572265625, Neurons: 43, Grad norm: 6.445e+01\n",
      "Epoch 4048, Loss: 152.4361572265625, Neurons: 43, Grad norm: 6.445e+01\n",
      "Epoch 4049, Loss: 152.16712951660156, Neurons: 43, Grad norm: 6.163e+01\n",
      "Epoch 4049, Loss: 152.16712951660156, Neurons: 43, Grad norm: 6.163e+01\n",
      "Epoch 4050, Loss: 151.91355895996094, Neurons: 43, Grad norm: 5.895e+01\n",
      "Epoch 4050, Loss: 151.91355895996094, Neurons: 43, Grad norm: 5.895e+01\n",
      "Epoch 4051, Loss: 151.67445373535156, Neurons: 43, Grad norm: 5.642e+01\n",
      "Epoch 4051, Loss: 151.67445373535156, Neurons: 43, Grad norm: 5.642e+01\n",
      "Epoch 4052, Loss: 151.44862365722656, Neurons: 43, Grad norm: 5.403e+01\n",
      "Epoch 4052, Loss: 151.44862365722656, Neurons: 43, Grad norm: 5.403e+01\n",
      "Epoch 4053, Loss: 151.23501586914062, Neurons: 43, Grad norm: 5.182e+01\n",
      "Epoch 4053, Loss: 151.23501586914062, Neurons: 43, Grad norm: 5.182e+01\n",
      "Epoch 4054, Loss: 151.03265380859375, Neurons: 43, Grad norm: 4.974e+01\n",
      "Epoch 4054, Loss: 151.03265380859375, Neurons: 43, Grad norm: 4.974e+01\n",
      "Epoch 4055, Loss: 150.8404541015625, Neurons: 43, Grad norm: 4.784e+01\n",
      "Epoch 4055, Loss: 150.8404541015625, Neurons: 43, Grad norm: 4.784e+01\n",
      "Epoch 4056, Loss: 150.65750122070312, Neurons: 43, Grad norm: 4.603e+01\n",
      "Epoch 4056, Loss: 150.65750122070312, Neurons: 43, Grad norm: 4.603e+01\n",
      "Epoch 4057, Loss: 150.48284912109375, Neurons: 43, Grad norm: 4.439e+01\n",
      "Epoch 4057, Loss: 150.48284912109375, Neurons: 43, Grad norm: 4.439e+01\n",
      "Epoch 4058, Loss: 150.3157196044922, Neurons: 43, Grad norm: 4.286e+01\n",
      "Epoch 4058, Loss: 150.3157196044922, Neurons: 43, Grad norm: 4.286e+01\n",
      "Epoch 4059, Loss: 150.15542602539062, Neurons: 43, Grad norm: 4.146e+01\n",
      "Epoch 4059, Loss: 150.15542602539062, Neurons: 43, Grad norm: 4.146e+01\n",
      "Epoch 4060, Loss: 150.00128173828125, Neurons: 43, Grad norm: 4.020e+01\n",
      "Epoch 4060, Loss: 150.00128173828125, Neurons: 43, Grad norm: 4.020e+01\n",
      "Epoch 4061, Loss: 149.8525848388672, Neurons: 43, Grad norm: 3.905e+01\n",
      "Epoch 4061, Loss: 149.8525848388672, Neurons: 43, Grad norm: 3.905e+01\n",
      "Epoch 4062, Loss: 149.70875549316406, Neurons: 43, Grad norm: 3.803e+01\n",
      "Epoch 4062, Loss: 149.70875549316406, Neurons: 43, Grad norm: 3.803e+01\n",
      "Epoch 4063, Loss: 149.5692596435547, Neurons: 43, Grad norm: 3.712e+01\n",
      "Epoch 4063, Loss: 149.5692596435547, Neurons: 43, Grad norm: 3.712e+01\n",
      "Epoch 4064, Loss: 149.43348693847656, Neurons: 43, Grad norm: 3.629e+01\n",
      "Epoch 4064, Loss: 149.43348693847656, Neurons: 43, Grad norm: 3.629e+01\n",
      "Epoch 4065, Loss: 149.30101013183594, Neurons: 43, Grad norm: 3.554e+01\n",
      "Epoch 4065, Loss: 149.30101013183594, Neurons: 43, Grad norm: 3.554e+01\n",
      "Epoch 4066, Loss: 149.17138671875, Neurons: 43, Grad norm: 3.488e+01\n",
      "Epoch 4066, Loss: 149.17138671875, Neurons: 43, Grad norm: 3.488e+01\n",
      "Epoch 4067, Loss: 149.04425048828125, Neurons: 43, Grad norm: 3.427e+01\n",
      "Epoch 4067, Loss: 149.04425048828125, Neurons: 43, Grad norm: 3.427e+01\n",
      "Epoch 4068, Loss: 148.91925048828125, Neurons: 43, Grad norm: 3.373e+01\n",
      "Epoch 4068, Loss: 148.91925048828125, Neurons: 43, Grad norm: 3.373e+01\n",
      "Epoch 4069, Loss: 148.79612731933594, Neurons: 43, Grad norm: 3.324e+01\n",
      "Epoch 4069, Loss: 148.79612731933594, Neurons: 43, Grad norm: 3.324e+01\n",
      "Epoch 4070, Loss: 148.67466735839844, Neurons: 43, Grad norm: 3.280e+01\n",
      "Epoch 4070, Loss: 148.67466735839844, Neurons: 43, Grad norm: 3.280e+01\n",
      "Epoch 4071, Loss: 148.5545654296875, Neurons: 43, Grad norm: 3.240e+01\n",
      "Epoch 4071, Loss: 148.5545654296875, Neurons: 43, Grad norm: 3.240e+01\n",
      "Epoch 4072, Loss: 148.4356689453125, Neurons: 43, Grad norm: 3.204e+01\n",
      "Epoch 4072, Loss: 148.4356689453125, Neurons: 43, Grad norm: 3.204e+01\n",
      "Epoch 4073, Loss: 148.3177032470703, Neurons: 43, Grad norm: 3.172e+01\n",
      "Epoch 4073, Loss: 148.3177032470703, Neurons: 43, Grad norm: 3.172e+01\n",
      "Epoch 4074, Loss: 148.20057678222656, Neurons: 43, Grad norm: 3.142e+01\n",
      "Epoch 4074, Loss: 148.20057678222656, Neurons: 43, Grad norm: 3.142e+01\n",
      "Epoch 4075, Loss: 148.08413696289062, Neurons: 43, Grad norm: 3.116e+01\n",
      "Epoch 4075, Loss: 148.08413696289062, Neurons: 43, Grad norm: 3.116e+01\n",
      "Epoch 4076, Loss: 147.9683074951172, Neurons: 43, Grad norm: 3.091e+01\n",
      "Epoch 4076, Loss: 147.9683074951172, Neurons: 43, Grad norm: 3.091e+01\n",
      "Epoch 4077, Loss: 147.85296630859375, Neurons: 43, Grad norm: 3.069e+01\n",
      "Epoch 4077, Loss: 147.85296630859375, Neurons: 43, Grad norm: 3.069e+01\n",
      "Epoch 4078, Loss: 147.73797607421875, Neurons: 43, Grad norm: 3.049e+01\n",
      "Epoch 4078, Loss: 147.73797607421875, Neurons: 43, Grad norm: 3.049e+01\n",
      "Epoch 4079, Loss: 147.62332153320312, Neurons: 43, Grad norm: 3.030e+01\n",
      "Epoch 4079, Loss: 147.62332153320312, Neurons: 43, Grad norm: 3.030e+01\n",
      "Epoch 4080, Loss: 147.50894165039062, Neurons: 43, Grad norm: 3.013e+01\n",
      "Epoch 4080, Loss: 147.50894165039062, Neurons: 43, Grad norm: 3.013e+01\n",
      "Epoch 4081, Loss: 147.394775390625, Neurons: 43, Grad norm: 2.997e+01\n",
      "Epoch 4081, Loss: 147.394775390625, Neurons: 43, Grad norm: 2.997e+01\n",
      "Epoch 4082, Loss: 147.2808074951172, Neurons: 43, Grad norm: 2.982e+01\n",
      "Epoch 4082, Loss: 147.2808074951172, Neurons: 43, Grad norm: 2.982e+01\n",
      "Epoch 4083, Loss: 147.1669921875, Neurons: 43, Grad norm: 2.968e+01\n",
      "Epoch 4083, Loss: 147.1669921875, Neurons: 43, Grad norm: 2.968e+01\n",
      "Epoch 4084, Loss: 147.0533447265625, Neurons: 43, Grad norm: 2.955e+01\n",
      "Epoch 4084, Loss: 147.0533447265625, Neurons: 43, Grad norm: 2.955e+01\n",
      "Epoch 4085, Loss: 146.93984985351562, Neurons: 43, Grad norm: 2.942e+01\n",
      "Epoch 4085, Loss: 146.93984985351562, Neurons: 43, Grad norm: 2.942e+01\n",
      "Epoch 4086, Loss: 146.82647705078125, Neurons: 43, Grad norm: 2.931e+01\n",
      "Epoch 4086, Loss: 146.82647705078125, Neurons: 43, Grad norm: 2.931e+01\n",
      "Epoch 4087, Loss: 146.71319580078125, Neurons: 43, Grad norm: 2.920e+01\n",
      "Epoch 4087, Loss: 146.71319580078125, Neurons: 43, Grad norm: 2.920e+01\n",
      "Epoch 4088, Loss: 146.60003662109375, Neurons: 43, Grad norm: 2.909e+01\n",
      "Epoch 4088, Loss: 146.60003662109375, Neurons: 43, Grad norm: 2.909e+01\n",
      "Epoch 4089, Loss: 146.48699951171875, Neurons: 43, Grad norm: 2.898e+01\n",
      "Epoch 4089, Loss: 146.48699951171875, Neurons: 43, Grad norm: 2.898e+01\n",
      "Epoch 4090, Loss: 146.3740692138672, Neurons: 43, Grad norm: 2.888e+01\n",
      "Epoch 4090, Loss: 146.3740692138672, Neurons: 43, Grad norm: 2.888e+01\n",
      "Epoch 4091, Loss: 146.26126098632812, Neurons: 43, Grad norm: 2.878e+01\n",
      "Epoch 4091, Loss: 146.26126098632812, Neurons: 43, Grad norm: 2.878e+01\n",
      "Epoch 4092, Loss: 146.14857482910156, Neurons: 43, Grad norm: 2.869e+01\n",
      "Epoch 4092, Loss: 146.14857482910156, Neurons: 43, Grad norm: 2.869e+01\n",
      "Epoch 4093, Loss: 146.0360107421875, Neurons: 43, Grad norm: 2.860e+01\n",
      "Epoch 4093, Loss: 146.0360107421875, Neurons: 43, Grad norm: 2.860e+01\n",
      "Epoch 4094, Loss: 145.92356872558594, Neurons: 43, Grad norm: 2.850e+01\n",
      "Epoch 4094, Loss: 145.92356872558594, Neurons: 43, Grad norm: 2.850e+01\n",
      "Epoch 4095, Loss: 145.81121826171875, Neurons: 43, Grad norm: 2.842e+01\n",
      "Epoch 4095, Loss: 145.81121826171875, Neurons: 43, Grad norm: 2.842e+01\n",
      "Epoch 4096, Loss: 145.6990203857422, Neurons: 43, Grad norm: 2.834e+01\n",
      "Epoch 4096, Loss: 145.6990203857422, Neurons: 43, Grad norm: 2.834e+01\n",
      "Epoch 4097, Loss: 145.58694458007812, Neurons: 43, Grad norm: 2.825e+01\n",
      "Epoch 4097, Loss: 145.58694458007812, Neurons: 43, Grad norm: 2.825e+01\n",
      "Epoch 4098, Loss: 145.47499084472656, Neurons: 43, Grad norm: 2.817e+01\n",
      "Epoch 4098, Loss: 145.47499084472656, Neurons: 43, Grad norm: 2.817e+01\n",
      "Epoch 4099, Loss: 145.3631591796875, Neurons: 43, Grad norm: 2.809e+01\n",
      "Epoch 4099, Loss: 145.3631591796875, Neurons: 43, Grad norm: 2.809e+01\n",
      "Epoch 4099, Test loss: 140.64756774902344\n",
      "Epoch 4099, Test loss: 140.64756774902344\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "network shape updated to :[17, 26, 1]\n",
      "network shape updated to :[17, 26, 1]\n",
      "Epoch 4100, Loss: 146.05816650390625, Neurons: 44, Grad norm: 4.946e+01\n",
      "Epoch 4100, Loss: 146.05816650390625, Neurons: 44, Grad norm: 4.946e+01\n",
      "Epoch 4101, Loss: 145.92141723632812, Neurons: 44, Grad norm: 4.243e+01\n",
      "Epoch 4101, Loss: 145.92141723632812, Neurons: 44, Grad norm: 4.243e+01\n",
      "Epoch 4102, Loss: 145.79037475585938, Neurons: 44, Grad norm: 3.728e+01\n",
      "Epoch 4102, Loss: 145.79037475585938, Neurons: 44, Grad norm: 3.728e+01\n",
      "Epoch 4103, Loss: 145.6642303466797, Neurons: 44, Grad norm: 3.408e+01\n",
      "Epoch 4103, Loss: 145.6642303466797, Neurons: 44, Grad norm: 3.408e+01\n",
      "Epoch 4104, Loss: 145.54051208496094, Neurons: 44, Grad norm: 3.209e+01\n",
      "Epoch 4104, Loss: 145.54051208496094, Neurons: 44, Grad norm: 3.209e+01\n",
      "Epoch 4105, Loss: 145.4173126220703, Neurons: 44, Grad norm: 3.078e+01\n",
      "Epoch 4105, Loss: 145.4173126220703, Neurons: 44, Grad norm: 3.078e+01\n",
      "Epoch 4106, Loss: 145.2939453125, Neurons: 44, Grad norm: 2.982e+01\n",
      "Epoch 4106, Loss: 145.2939453125, Neurons: 44, Grad norm: 2.982e+01\n",
      "Epoch 4107, Loss: 145.1702880859375, Neurons: 44, Grad norm: 2.911e+01\n",
      "Epoch 4107, Loss: 145.1702880859375, Neurons: 44, Grad norm: 2.911e+01\n",
      "Epoch 4108, Loss: 145.04644775390625, Neurons: 44, Grad norm: 2.867e+01\n",
      "Epoch 4108, Loss: 145.04644775390625, Neurons: 44, Grad norm: 2.867e+01\n",
      "Epoch 4109, Loss: 144.92237854003906, Neurons: 44, Grad norm: 2.850e+01\n",
      "Epoch 4109, Loss: 144.92237854003906, Neurons: 44, Grad norm: 2.850e+01\n",
      "Epoch 4110, Loss: 144.79783630371094, Neurons: 44, Grad norm: 2.854e+01\n",
      "Epoch 4110, Loss: 144.79783630371094, Neurons: 44, Grad norm: 2.854e+01\n",
      "Epoch 4111, Loss: 144.67221069335938, Neurons: 44, Grad norm: 2.867e+01\n",
      "Epoch 4111, Loss: 144.67221069335938, Neurons: 44, Grad norm: 2.867e+01\n",
      "Epoch 4112, Loss: 144.54486083984375, Neurons: 44, Grad norm: 2.877e+01\n",
      "Epoch 4112, Loss: 144.54486083984375, Neurons: 44, Grad norm: 2.877e+01\n",
      "Epoch 4113, Loss: 144.41531372070312, Neurons: 44, Grad norm: 2.879e+01\n",
      "Epoch 4113, Loss: 144.41531372070312, Neurons: 44, Grad norm: 2.879e+01\n",
      "Epoch 4114, Loss: 144.28321838378906, Neurons: 44, Grad norm: 2.864e+01\n",
      "Epoch 4114, Loss: 144.28321838378906, Neurons: 44, Grad norm: 2.864e+01\n",
      "Epoch 4115, Loss: 144.1483917236328, Neurons: 44, Grad norm: 2.837e+01\n",
      "Epoch 4115, Loss: 144.1483917236328, Neurons: 44, Grad norm: 2.837e+01\n",
      "Epoch 4116, Loss: 144.01097106933594, Neurons: 44, Grad norm: 2.803e+01\n",
      "Epoch 4116, Loss: 144.01097106933594, Neurons: 44, Grad norm: 2.803e+01\n",
      "Epoch 4117, Loss: 143.87107849121094, Neurons: 44, Grad norm: 2.767e+01\n",
      "Epoch 4117, Loss: 143.87107849121094, Neurons: 44, Grad norm: 2.767e+01\n",
      "Epoch 4118, Loss: 143.72894287109375, Neurons: 44, Grad norm: 2.735e+01\n",
      "Epoch 4118, Loss: 143.72894287109375, Neurons: 44, Grad norm: 2.735e+01\n",
      "Epoch 4119, Loss: 143.5847930908203, Neurons: 44, Grad norm: 2.710e+01\n",
      "Epoch 4119, Loss: 143.5847930908203, Neurons: 44, Grad norm: 2.710e+01\n",
      "Epoch 4120, Loss: 143.4387664794922, Neurons: 44, Grad norm: 2.696e+01\n",
      "Epoch 4120, Loss: 143.4387664794922, Neurons: 44, Grad norm: 2.696e+01\n",
      "Epoch 4121, Loss: 143.29107666015625, Neurons: 44, Grad norm: 2.692e+01\n",
      "Epoch 4121, Loss: 143.29107666015625, Neurons: 44, Grad norm: 2.692e+01\n",
      "Epoch 4122, Loss: 143.14178466796875, Neurons: 44, Grad norm: 2.702e+01\n",
      "Epoch 4122, Loss: 143.14178466796875, Neurons: 44, Grad norm: 2.702e+01\n",
      "Epoch 4123, Loss: 142.9910125732422, Neurons: 44, Grad norm: 2.718e+01\n",
      "Epoch 4123, Loss: 142.9910125732422, Neurons: 44, Grad norm: 2.718e+01\n",
      "Epoch 4124, Loss: 142.83888244628906, Neurons: 44, Grad norm: 2.744e+01\n",
      "Epoch 4124, Loss: 142.83888244628906, Neurons: 44, Grad norm: 2.744e+01\n",
      "Epoch 4125, Loss: 142.68545532226562, Neurons: 44, Grad norm: 2.767e+01\n",
      "Epoch 4125, Loss: 142.68545532226562, Neurons: 44, Grad norm: 2.767e+01\n",
      "Epoch 4126, Loss: 142.53082275390625, Neurons: 44, Grad norm: 2.789e+01\n",
      "Epoch 4126, Loss: 142.53082275390625, Neurons: 44, Grad norm: 2.789e+01\n",
      "Epoch 4127, Loss: 142.37486267089844, Neurons: 44, Grad norm: 2.801e+01\n",
      "Epoch 4127, Loss: 142.37486267089844, Neurons: 44, Grad norm: 2.801e+01\n",
      "Epoch 4128, Loss: 142.2176513671875, Neurons: 44, Grad norm: 2.799e+01\n",
      "Epoch 4128, Loss: 142.2176513671875, Neurons: 44, Grad norm: 2.799e+01\n",
      "Epoch 4129, Loss: 142.05906677246094, Neurons: 44, Grad norm: 2.781e+01\n",
      "Epoch 4129, Loss: 142.05906677246094, Neurons: 44, Grad norm: 2.781e+01\n",
      "Epoch 4130, Loss: 141.8990936279297, Neurons: 44, Grad norm: 2.752e+01\n",
      "Epoch 4130, Loss: 141.8990936279297, Neurons: 44, Grad norm: 2.752e+01\n",
      "Epoch 4131, Loss: 141.73770141601562, Neurons: 44, Grad norm: 2.717e+01\n",
      "Epoch 4131, Loss: 141.73770141601562, Neurons: 44, Grad norm: 2.717e+01\n",
      "Epoch 4132, Loss: 141.5748291015625, Neurons: 44, Grad norm: 2.680e+01\n",
      "Epoch 4132, Loss: 141.5748291015625, Neurons: 44, Grad norm: 2.680e+01\n",
      "Epoch 4133, Loss: 141.41053771972656, Neurons: 44, Grad norm: 2.644e+01\n",
      "Epoch 4133, Loss: 141.41053771972656, Neurons: 44, Grad norm: 2.644e+01\n",
      "Epoch 4134, Loss: 141.24481201171875, Neurons: 44, Grad norm: 2.614e+01\n",
      "Epoch 4134, Loss: 141.24481201171875, Neurons: 44, Grad norm: 2.614e+01\n",
      "Epoch 4135, Loss: 141.07772827148438, Neurons: 44, Grad norm: 2.591e+01\n",
      "Epoch 4135, Loss: 141.07772827148438, Neurons: 44, Grad norm: 2.591e+01\n",
      "Epoch 4136, Loss: 140.9093475341797, Neurons: 44, Grad norm: 2.928e+01\n",
      "Epoch 4136, Loss: 140.9093475341797, Neurons: 44, Grad norm: 2.928e+01\n",
      "Epoch 4137, Loss: 140.748291015625, Neurons: 44, Grad norm: 2.833e+01\n",
      "Epoch 4137, Loss: 140.748291015625, Neurons: 44, Grad norm: 2.833e+01\n",
      "Epoch 4138, Loss: 140.57736206054688, Neurons: 44, Grad norm: 2.663e+01\n",
      "Epoch 4138, Loss: 140.57736206054688, Neurons: 44, Grad norm: 2.663e+01\n",
      "Epoch 4139, Loss: 140.40478515625, Neurons: 44, Grad norm: 2.667e+01\n",
      "Epoch 4139, Loss: 140.40478515625, Neurons: 44, Grad norm: 2.667e+01\n",
      "Epoch 4140, Loss: 140.2348175048828, Neurons: 44, Grad norm: 2.668e+01\n",
      "Epoch 4140, Loss: 140.2348175048828, Neurons: 44, Grad norm: 2.668e+01\n",
      "Epoch 4141, Loss: 140.06517028808594, Neurons: 44, Grad norm: 2.642e+01\n",
      "Epoch 4141, Loss: 140.06517028808594, Neurons: 44, Grad norm: 2.642e+01\n",
      "Epoch 4142, Loss: 139.8942108154297, Neurons: 44, Grad norm: 2.594e+01\n",
      "Epoch 4142, Loss: 139.8942108154297, Neurons: 44, Grad norm: 2.594e+01\n",
      "Epoch 4143, Loss: 139.72210693359375, Neurons: 44, Grad norm: 2.535e+01\n",
      "Epoch 4143, Loss: 139.72210693359375, Neurons: 44, Grad norm: 2.535e+01\n",
      "Epoch 4144, Loss: 139.54910278320312, Neurons: 44, Grad norm: 2.479e+01\n",
      "Epoch 4144, Loss: 139.54910278320312, Neurons: 44, Grad norm: 2.479e+01\n",
      "Epoch 4145, Loss: 139.37548828125, Neurons: 44, Grad norm: 2.438e+01\n",
      "Epoch 4145, Loss: 139.37548828125, Neurons: 44, Grad norm: 2.438e+01\n",
      "Epoch 4146, Loss: 139.2013702392578, Neurons: 44, Grad norm: 2.417e+01\n",
      "Epoch 4146, Loss: 139.2013702392578, Neurons: 44, Grad norm: 2.417e+01\n",
      "Epoch 4147, Loss: 139.02659606933594, Neurons: 44, Grad norm: 2.413e+01\n",
      "Epoch 4147, Loss: 139.02659606933594, Neurons: 44, Grad norm: 2.413e+01\n",
      "Epoch 4148, Loss: 138.85101318359375, Neurons: 44, Grad norm: 2.424e+01\n",
      "Epoch 4148, Loss: 138.85101318359375, Neurons: 44, Grad norm: 2.424e+01\n",
      "Epoch 4149, Loss: 138.6744384765625, Neurons: 44, Grad norm: 2.449e+01\n",
      "Epoch 4149, Loss: 138.6744384765625, Neurons: 44, Grad norm: 2.449e+01\n",
      "Epoch 4150, Loss: 138.4969940185547, Neurons: 44, Grad norm: 2.479e+01\n",
      "Epoch 4150, Loss: 138.4969940185547, Neurons: 44, Grad norm: 2.479e+01\n",
      "Epoch 4151, Loss: 138.31875610351562, Neurons: 44, Grad norm: 2.507e+01\n",
      "Epoch 4151, Loss: 138.31875610351562, Neurons: 44, Grad norm: 2.507e+01\n",
      "Epoch 4152, Loss: 138.1398162841797, Neurons: 44, Grad norm: 2.528e+01\n",
      "Epoch 4152, Loss: 138.1398162841797, Neurons: 44, Grad norm: 2.528e+01\n",
      "Epoch 4153, Loss: 137.96023559570312, Neurons: 44, Grad norm: 2.535e+01\n",
      "Epoch 4153, Loss: 137.96023559570312, Neurons: 44, Grad norm: 2.535e+01\n",
      "Epoch 4154, Loss: 137.77996826171875, Neurons: 44, Grad norm: 2.521e+01\n",
      "Epoch 4154, Loss: 137.77996826171875, Neurons: 44, Grad norm: 2.521e+01\n",
      "Epoch 4155, Loss: 137.59902954101562, Neurons: 44, Grad norm: 2.490e+01\n",
      "Epoch 4155, Loss: 137.59902954101562, Neurons: 44, Grad norm: 2.490e+01\n",
      "Epoch 4156, Loss: 137.4173126220703, Neurons: 44, Grad norm: 2.450e+01\n",
      "Epoch 4156, Loss: 137.4173126220703, Neurons: 44, Grad norm: 2.450e+01\n",
      "Epoch 4157, Loss: 137.2349395751953, Neurons: 44, Grad norm: 2.410e+01\n",
      "Epoch 4157, Loss: 137.2349395751953, Neurons: 44, Grad norm: 2.410e+01\n",
      "Epoch 4158, Loss: 137.05191040039062, Neurons: 44, Grad norm: 2.377e+01\n",
      "Epoch 4158, Loss: 137.05191040039062, Neurons: 44, Grad norm: 2.377e+01\n",
      "Epoch 4159, Loss: 136.86825561523438, Neurons: 44, Grad norm: 2.352e+01\n",
      "Epoch 4159, Loss: 136.86825561523438, Neurons: 44, Grad norm: 2.352e+01\n",
      "Epoch 4160, Loss: 136.68397521972656, Neurons: 44, Grad norm: 2.360e+01\n",
      "Epoch 4160, Loss: 136.68397521972656, Neurons: 44, Grad norm: 2.360e+01\n",
      "Epoch 4161, Loss: 136.499755859375, Neurons: 44, Grad norm: 2.388e+01\n",
      "Epoch 4161, Loss: 136.499755859375, Neurons: 44, Grad norm: 2.388e+01\n",
      "Epoch 4162, Loss: 136.31500244140625, Neurons: 44, Grad norm: 2.399e+01\n",
      "Epoch 4162, Loss: 136.31500244140625, Neurons: 44, Grad norm: 2.399e+01\n",
      "Epoch 4163, Loss: 136.12893676757812, Neurons: 44, Grad norm: 2.388e+01\n",
      "Epoch 4163, Loss: 136.12893676757812, Neurons: 44, Grad norm: 2.388e+01\n",
      "Epoch 4164, Loss: 135.9419403076172, Neurons: 44, Grad norm: 2.417e+01\n",
      "Epoch 4164, Loss: 135.9419403076172, Neurons: 44, Grad norm: 2.417e+01\n",
      "Epoch 4165, Loss: 135.75497436523438, Neurons: 44, Grad norm: 2.427e+01\n",
      "Epoch 4165, Loss: 135.75497436523438, Neurons: 44, Grad norm: 2.427e+01\n",
      "Epoch 4166, Loss: 135.567626953125, Neurons: 44, Grad norm: 2.417e+01\n",
      "Epoch 4166, Loss: 135.567626953125, Neurons: 44, Grad norm: 2.417e+01\n",
      "Epoch 4167, Loss: 135.3795928955078, Neurons: 44, Grad norm: 2.391e+01\n",
      "Epoch 4167, Loss: 135.3795928955078, Neurons: 44, Grad norm: 2.391e+01\n",
      "Epoch 4168, Loss: 135.19091796875, Neurons: 44, Grad norm: 2.360e+01\n",
      "Epoch 4168, Loss: 135.19091796875, Neurons: 44, Grad norm: 2.360e+01\n",
      "Epoch 4169, Loss: 135.00157165527344, Neurons: 44, Grad norm: 2.323e+01\n",
      "Epoch 4169, Loss: 135.00157165527344, Neurons: 44, Grad norm: 2.323e+01\n",
      "Epoch 4170, Loss: 134.8116912841797, Neurons: 44, Grad norm: 2.294e+01\n",
      "Epoch 4170, Loss: 134.8116912841797, Neurons: 44, Grad norm: 2.294e+01\n",
      "Epoch 4171, Loss: 134.62130737304688, Neurons: 44, Grad norm: 2.272e+01\n",
      "Epoch 4171, Loss: 134.62130737304688, Neurons: 44, Grad norm: 2.272e+01\n",
      "Epoch 4172, Loss: 134.4303436279297, Neurons: 44, Grad norm: 2.259e+01\n",
      "Epoch 4172, Loss: 134.4303436279297, Neurons: 44, Grad norm: 2.259e+01\n",
      "Epoch 4173, Loss: 134.2388458251953, Neurons: 44, Grad norm: 2.258e+01\n",
      "Epoch 4173, Loss: 134.2388458251953, Neurons: 44, Grad norm: 2.258e+01\n",
      "Epoch 4174, Loss: 134.04698181152344, Neurons: 44, Grad norm: 2.278e+01\n",
      "Epoch 4174, Loss: 134.04698181152344, Neurons: 44, Grad norm: 2.278e+01\n",
      "Epoch 4175, Loss: 133.85470581054688, Neurons: 44, Grad norm: 2.292e+01\n",
      "Epoch 4175, Loss: 133.85470581054688, Neurons: 44, Grad norm: 2.292e+01\n",
      "Epoch 4176, Loss: 133.66172790527344, Neurons: 44, Grad norm: 2.303e+01\n",
      "Epoch 4176, Loss: 133.66172790527344, Neurons: 44, Grad norm: 2.303e+01\n",
      "Epoch 4177, Loss: 133.46826171875, Neurons: 44, Grad norm: 2.319e+01\n",
      "Epoch 4177, Loss: 133.46826171875, Neurons: 44, Grad norm: 2.319e+01\n",
      "Epoch 4178, Loss: 133.2744598388672, Neurons: 44, Grad norm: 2.319e+01\n",
      "Epoch 4178, Loss: 133.2744598388672, Neurons: 44, Grad norm: 2.319e+01\n",
      "Epoch 4179, Loss: 133.08026123046875, Neurons: 44, Grad norm: 2.299e+01\n",
      "Epoch 4179, Loss: 133.08026123046875, Neurons: 44, Grad norm: 2.299e+01\n",
      "Epoch 4180, Loss: 132.88546752929688, Neurons: 44, Grad norm: 2.270e+01\n",
      "Epoch 4180, Loss: 132.88546752929688, Neurons: 44, Grad norm: 2.270e+01\n",
      "Epoch 4181, Loss: 132.69020080566406, Neurons: 44, Grad norm: 2.231e+01\n",
      "Epoch 4181, Loss: 132.69020080566406, Neurons: 44, Grad norm: 2.231e+01\n",
      "Epoch 4182, Loss: 132.49449157714844, Neurons: 44, Grad norm: 2.204e+01\n",
      "Epoch 4182, Loss: 132.49449157714844, Neurons: 44, Grad norm: 2.204e+01\n",
      "Epoch 4183, Loss: 132.2984619140625, Neurons: 44, Grad norm: 2.189e+01\n",
      "Epoch 4183, Loss: 132.2984619140625, Neurons: 44, Grad norm: 2.189e+01\n",
      "Epoch 4184, Loss: 132.10205078125, Neurons: 44, Grad norm: 2.180e+01\n",
      "Epoch 4184, Loss: 132.10205078125, Neurons: 44, Grad norm: 2.180e+01\n",
      "Epoch 4185, Loss: 131.90516662597656, Neurons: 44, Grad norm: 2.182e+01\n",
      "Epoch 4185, Loss: 131.90516662597656, Neurons: 44, Grad norm: 2.182e+01\n",
      "Epoch 4186, Loss: 131.70782470703125, Neurons: 44, Grad norm: 2.195e+01\n",
      "Epoch 4186, Loss: 131.70782470703125, Neurons: 44, Grad norm: 2.195e+01\n",
      "Epoch 4187, Loss: 131.5101776123047, Neurons: 44, Grad norm: 2.207e+01\n",
      "Epoch 4187, Loss: 131.5101776123047, Neurons: 44, Grad norm: 2.207e+01\n",
      "Epoch 4188, Loss: 131.31219482421875, Neurons: 44, Grad norm: 2.214e+01\n",
      "Epoch 4188, Loss: 131.31219482421875, Neurons: 44, Grad norm: 2.214e+01\n",
      "Epoch 4189, Loss: 131.11378479003906, Neurons: 44, Grad norm: 2.207e+01\n",
      "Epoch 4189, Loss: 131.11378479003906, Neurons: 44, Grad norm: 2.207e+01\n",
      "Epoch 4190, Loss: 130.91500854492188, Neurons: 44, Grad norm: 2.198e+01\n",
      "Epoch 4190, Loss: 130.91500854492188, Neurons: 44, Grad norm: 2.198e+01\n",
      "Epoch 4191, Loss: 130.7159423828125, Neurons: 44, Grad norm: 2.186e+01\n",
      "Epoch 4191, Loss: 130.7159423828125, Neurons: 44, Grad norm: 2.186e+01\n",
      "Epoch 4192, Loss: 130.51654052734375, Neurons: 44, Grad norm: 2.170e+01\n",
      "Epoch 4192, Loss: 130.51654052734375, Neurons: 44, Grad norm: 2.170e+01\n",
      "Epoch 4193, Loss: 130.31678771972656, Neurons: 44, Grad norm: 2.154e+01\n",
      "Epoch 4193, Loss: 130.31678771972656, Neurons: 44, Grad norm: 2.154e+01\n",
      "Epoch 4194, Loss: 130.11671447753906, Neurons: 44, Grad norm: 2.145e+01\n",
      "Epoch 4194, Loss: 130.11671447753906, Neurons: 44, Grad norm: 2.145e+01\n",
      "Epoch 4195, Loss: 129.91636657714844, Neurons: 44, Grad norm: 2.139e+01\n",
      "Epoch 4195, Loss: 129.91636657714844, Neurons: 44, Grad norm: 2.139e+01\n",
      "Epoch 4196, Loss: 129.71572875976562, Neurons: 44, Grad norm: 2.132e+01\n",
      "Epoch 4196, Loss: 129.71572875976562, Neurons: 44, Grad norm: 2.132e+01\n",
      "Epoch 4197, Loss: 129.51480102539062, Neurons: 44, Grad norm: 2.124e+01\n",
      "Epoch 4197, Loss: 129.51480102539062, Neurons: 44, Grad norm: 2.124e+01\n",
      "Epoch 4198, Loss: 129.31356811523438, Neurons: 44, Grad norm: 2.120e+01\n",
      "Epoch 4198, Loss: 129.31356811523438, Neurons: 44, Grad norm: 2.120e+01\n",
      "Epoch 4199, Loss: 129.11209106445312, Neurons: 44, Grad norm: 2.118e+01\n",
      "Epoch 4199, Loss: 129.11209106445312, Neurons: 44, Grad norm: 2.118e+01\n",
      "Epoch 4199, Test loss: 124.25106811523438\n",
      "Epoch 4199, Test loss: 124.25106811523438\n",
      "Added neuron to hidden layer 1 with activation sin\n",
      "Added neuron to hidden layer 1 with activation sin\n",
      "network shape updated to :[18, 26, 1]\n",
      "network shape updated to :[18, 26, 1]\n",
      "Epoch 4200, Loss: 132.45582580566406, Neurons: 45, Grad norm: 9.051e+01\n",
      "Epoch 4200, Loss: 132.45582580566406, Neurons: 45, Grad norm: 9.051e+01\n",
      "Epoch 4201, Loss: 132.14215087890625, Neurons: 45, Grad norm: 8.416e+01\n",
      "Epoch 4201, Loss: 132.14215087890625, Neurons: 45, Grad norm: 8.416e+01\n",
      "Epoch 4202, Loss: 131.8367919921875, Neurons: 45, Grad norm: 7.856e+01\n",
      "Epoch 4202, Loss: 131.8367919921875, Neurons: 45, Grad norm: 7.856e+01\n",
      "Epoch 4203, Loss: 131.54278564453125, Neurons: 45, Grad norm: 7.380e+01\n",
      "Epoch 4203, Loss: 131.54278564453125, Neurons: 45, Grad norm: 7.380e+01\n",
      "Epoch 4204, Loss: 131.2627716064453, Neurons: 45, Grad norm: 6.992e+01\n",
      "Epoch 4204, Loss: 131.2627716064453, Neurons: 45, Grad norm: 6.992e+01\n",
      "Epoch 4205, Loss: 130.99794006347656, Neurons: 45, Grad norm: 6.666e+01\n",
      "Epoch 4205, Loss: 130.99794006347656, Neurons: 45, Grad norm: 6.666e+01\n",
      "Epoch 4206, Loss: 130.74815368652344, Neurons: 45, Grad norm: 6.365e+01\n",
      "Epoch 4206, Loss: 130.74815368652344, Neurons: 45, Grad norm: 6.365e+01\n",
      "Epoch 4207, Loss: 130.51292419433594, Neurons: 45, Grad norm: 6.057e+01\n",
      "Epoch 4207, Loss: 130.51292419433594, Neurons: 45, Grad norm: 6.057e+01\n",
      "Epoch 4208, Loss: 130.29171752929688, Neurons: 45, Grad norm: 5.719e+01\n",
      "Epoch 4208, Loss: 130.29171752929688, Neurons: 45, Grad norm: 5.719e+01\n",
      "Epoch 4209, Loss: 130.0841064453125, Neurons: 45, Grad norm: 5.338e+01\n",
      "Epoch 4209, Loss: 130.0841064453125, Neurons: 45, Grad norm: 5.338e+01\n",
      "Epoch 4210, Loss: 129.8898468017578, Neurons: 45, Grad norm: 4.913e+01\n",
      "Epoch 4210, Loss: 129.8898468017578, Neurons: 45, Grad norm: 4.913e+01\n",
      "Epoch 4211, Loss: 129.70880126953125, Neurons: 45, Grad norm: 4.449e+01\n",
      "Epoch 4211, Loss: 129.70880126953125, Neurons: 45, Grad norm: 4.449e+01\n",
      "Epoch 4212, Loss: 129.54086303710938, Neurons: 45, Grad norm: 3.969e+01\n",
      "Epoch 4212, Loss: 129.54086303710938, Neurons: 45, Grad norm: 3.969e+01\n",
      "Epoch 4213, Loss: 129.38612365722656, Neurons: 45, Grad norm: 3.502e+01\n",
      "Epoch 4213, Loss: 129.38612365722656, Neurons: 45, Grad norm: 3.502e+01\n",
      "Epoch 4214, Loss: 129.2444610595703, Neurons: 45, Grad norm: 3.091e+01\n",
      "Epoch 4214, Loss: 129.2444610595703, Neurons: 45, Grad norm: 3.091e+01\n",
      "Epoch 4215, Loss: 129.11546325683594, Neurons: 45, Grad norm: 2.780e+01\n",
      "Epoch 4215, Loss: 129.11546325683594, Neurons: 45, Grad norm: 2.780e+01\n",
      "Epoch 4216, Loss: 128.9984130859375, Neurons: 45, Grad norm: 2.595e+01\n",
      "Epoch 4216, Loss: 128.9984130859375, Neurons: 45, Grad norm: 2.595e+01\n",
      "Epoch 4217, Loss: 128.89208984375, Neurons: 45, Grad norm: 2.541e+01\n",
      "Epoch 4217, Loss: 128.89208984375, Neurons: 45, Grad norm: 2.541e+01\n",
      "Epoch 4218, Loss: 128.7947235107422, Neurons: 45, Grad norm: 2.574e+01\n",
      "Epoch 4218, Loss: 128.7947235107422, Neurons: 45, Grad norm: 2.574e+01\n",
      "Epoch 4219, Loss: 128.7042694091797, Neurons: 45, Grad norm: 2.649e+01\n",
      "Epoch 4219, Loss: 128.7042694091797, Neurons: 45, Grad norm: 2.649e+01\n",
      "Epoch 4220, Loss: 128.6187744140625, Neurons: 45, Grad norm: 2.727e+01\n",
      "Epoch 4220, Loss: 128.6187744140625, Neurons: 45, Grad norm: 2.727e+01\n",
      "Epoch 4221, Loss: 128.5364227294922, Neurons: 45, Grad norm: 2.783e+01\n",
      "Epoch 4221, Loss: 128.5364227294922, Neurons: 45, Grad norm: 2.783e+01\n",
      "Epoch 4222, Loss: 128.45582580566406, Neurons: 45, Grad norm: 2.807e+01\n",
      "Epoch 4222, Loss: 128.45582580566406, Neurons: 45, Grad norm: 2.807e+01\n",
      "Epoch 4223, Loss: 128.3757781982422, Neurons: 45, Grad norm: 2.795e+01\n",
      "Epoch 4223, Loss: 128.3757781982422, Neurons: 45, Grad norm: 2.795e+01\n",
      "Epoch 4224, Loss: 128.2955322265625, Neurons: 45, Grad norm: 2.754e+01\n",
      "Epoch 4224, Loss: 128.2955322265625, Neurons: 45, Grad norm: 2.754e+01\n",
      "Epoch 4225, Loss: 128.21458435058594, Neurons: 45, Grad norm: 2.689e+01\n",
      "Epoch 4225, Loss: 128.21458435058594, Neurons: 45, Grad norm: 2.689e+01\n",
      "Epoch 4226, Loss: 128.13259887695312, Neurons: 45, Grad norm: 2.610e+01\n",
      "Epoch 4226, Loss: 128.13259887695312, Neurons: 45, Grad norm: 2.610e+01\n",
      "Epoch 4227, Loss: 128.04940795898438, Neurons: 45, Grad norm: 2.526e+01\n",
      "Epoch 4227, Loss: 128.04940795898438, Neurons: 45, Grad norm: 2.526e+01\n",
      "Epoch 4228, Loss: 127.96491241455078, Neurons: 45, Grad norm: 2.442e+01\n",
      "Epoch 4228, Loss: 127.96491241455078, Neurons: 45, Grad norm: 2.442e+01\n",
      "Epoch 4229, Loss: 127.87906646728516, Neurons: 45, Grad norm: 2.365e+01\n",
      "Epoch 4229, Loss: 127.87906646728516, Neurons: 45, Grad norm: 2.365e+01\n",
      "Epoch 4230, Loss: 127.79185485839844, Neurons: 45, Grad norm: 2.295e+01\n",
      "Epoch 4230, Loss: 127.79185485839844, Neurons: 45, Grad norm: 2.295e+01\n",
      "Epoch 4231, Loss: 127.70328521728516, Neurons: 45, Grad norm: 2.238e+01\n",
      "Epoch 4231, Loss: 127.70328521728516, Neurons: 45, Grad norm: 2.238e+01\n",
      "Epoch 4232, Loss: 127.61345672607422, Neurons: 45, Grad norm: 2.191e+01\n",
      "Epoch 4232, Loss: 127.61345672607422, Neurons: 45, Grad norm: 2.191e+01\n",
      "Epoch 4233, Loss: 127.5223617553711, Neurons: 45, Grad norm: 2.179e+01\n",
      "Epoch 4233, Loss: 127.5223617553711, Neurons: 45, Grad norm: 2.179e+01\n",
      "Epoch 4234, Loss: 127.43096160888672, Neurons: 45, Grad norm: 2.191e+01\n",
      "Epoch 4234, Loss: 127.43096160888672, Neurons: 45, Grad norm: 2.191e+01\n",
      "Epoch 4235, Loss: 127.33895111083984, Neurons: 45, Grad norm: 2.168e+01\n",
      "Epoch 4235, Loss: 127.33895111083984, Neurons: 45, Grad norm: 2.168e+01\n",
      "Epoch 4236, Loss: 127.24528503417969, Neurons: 45, Grad norm: 2.131e+01\n",
      "Epoch 4236, Loss: 127.24528503417969, Neurons: 45, Grad norm: 2.131e+01\n",
      "Epoch 4237, Loss: 127.15022277832031, Neurons: 45, Grad norm: 2.086e+01\n",
      "Epoch 4237, Loss: 127.15022277832031, Neurons: 45, Grad norm: 2.086e+01\n",
      "Epoch 4238, Loss: 127.05455017089844, Neurons: 45, Grad norm: 2.078e+01\n",
      "Epoch 4238, Loss: 127.05455017089844, Neurons: 45, Grad norm: 2.078e+01\n",
      "Epoch 4239, Loss: 126.95924377441406, Neurons: 45, Grad norm: 2.083e+01\n",
      "Epoch 4239, Loss: 126.95924377441406, Neurons: 45, Grad norm: 2.083e+01\n",
      "Epoch 4240, Loss: 126.86424255371094, Neurons: 45, Grad norm: 2.089e+01\n",
      "Epoch 4240, Loss: 126.86424255371094, Neurons: 45, Grad norm: 2.089e+01\n",
      "Epoch 4241, Loss: 126.76918029785156, Neurons: 45, Grad norm: 2.093e+01\n",
      "Epoch 4241, Loss: 126.76918029785156, Neurons: 45, Grad norm: 2.093e+01\n",
      "Epoch 4242, Loss: 126.67404174804688, Neurons: 45, Grad norm: 2.095e+01\n",
      "Epoch 4242, Loss: 126.67404174804688, Neurons: 45, Grad norm: 2.095e+01\n",
      "Epoch 4243, Loss: 126.57878875732422, Neurons: 45, Grad norm: 2.092e+01\n",
      "Epoch 4243, Loss: 126.57878875732422, Neurons: 45, Grad norm: 2.092e+01\n",
      "Epoch 4244, Loss: 126.48329162597656, Neurons: 45, Grad norm: 2.083e+01\n",
      "Epoch 4244, Loss: 126.48329162597656, Neurons: 45, Grad norm: 2.083e+01\n",
      "Epoch 4245, Loss: 126.38751983642578, Neurons: 45, Grad norm: 2.067e+01\n",
      "Epoch 4245, Loss: 126.38751983642578, Neurons: 45, Grad norm: 2.067e+01\n",
      "Epoch 4246, Loss: 126.29139709472656, Neurons: 45, Grad norm: 2.050e+01\n",
      "Epoch 4246, Loss: 126.29139709472656, Neurons: 45, Grad norm: 2.050e+01\n",
      "Epoch 4247, Loss: 126.19483184814453, Neurons: 45, Grad norm: 2.030e+01\n",
      "Epoch 4247, Loss: 126.19483184814453, Neurons: 45, Grad norm: 2.030e+01\n",
      "Epoch 4248, Loss: 126.09779357910156, Neurons: 45, Grad norm: 2.014e+01\n",
      "Epoch 4248, Loss: 126.09779357910156, Neurons: 45, Grad norm: 2.014e+01\n",
      "Epoch 4249, Loss: 126.00019073486328, Neurons: 45, Grad norm: 1.999e+01\n",
      "Epoch 4249, Loss: 126.00019073486328, Neurons: 45, Grad norm: 1.999e+01\n",
      "Epoch 4250, Loss: 125.9019775390625, Neurons: 45, Grad norm: 1.989e+01\n",
      "Epoch 4250, Loss: 125.9019775390625, Neurons: 45, Grad norm: 1.989e+01\n",
      "Epoch 4251, Loss: 125.80313110351562, Neurons: 45, Grad norm: 1.982e+01\n",
      "Epoch 4251, Loss: 125.80313110351562, Neurons: 45, Grad norm: 1.982e+01\n",
      "Epoch 4252, Loss: 125.70350646972656, Neurons: 45, Grad norm: 1.971e+01\n",
      "Epoch 4252, Loss: 125.70350646972656, Neurons: 45, Grad norm: 1.971e+01\n",
      "Epoch 4253, Loss: 125.60322570800781, Neurons: 45, Grad norm: 1.973e+01\n",
      "Epoch 4253, Loss: 125.60322570800781, Neurons: 45, Grad norm: 1.973e+01\n",
      "Epoch 4254, Loss: 125.50242614746094, Neurons: 45, Grad norm: 1.985e+01\n",
      "Epoch 4254, Loss: 125.50242614746094, Neurons: 45, Grad norm: 1.985e+01\n",
      "Epoch 4255, Loss: 125.40093994140625, Neurons: 45, Grad norm: 1.983e+01\n",
      "Epoch 4255, Loss: 125.40093994140625, Neurons: 45, Grad norm: 1.983e+01\n",
      "Epoch 4256, Loss: 125.29840850830078, Neurons: 45, Grad norm: 1.970e+01\n",
      "Epoch 4256, Loss: 125.29840850830078, Neurons: 45, Grad norm: 1.970e+01\n",
      "Epoch 4257, Loss: 125.19488525390625, Neurons: 45, Grad norm: 1.962e+01\n",
      "Epoch 4257, Loss: 125.19488525390625, Neurons: 45, Grad norm: 1.962e+01\n",
      "Epoch 4258, Loss: 125.09061431884766, Neurons: 45, Grad norm: 1.965e+01\n",
      "Epoch 4258, Loss: 125.09061431884766, Neurons: 45, Grad norm: 1.965e+01\n",
      "Epoch 4259, Loss: 124.98579406738281, Neurons: 45, Grad norm: 1.971e+01\n",
      "Epoch 4259, Loss: 124.98579406738281, Neurons: 45, Grad norm: 1.971e+01\n",
      "Epoch 4260, Loss: 124.88041687011719, Neurons: 45, Grad norm: 1.971e+01\n",
      "Epoch 4260, Loss: 124.88041687011719, Neurons: 45, Grad norm: 1.971e+01\n",
      "Epoch 4261, Loss: 124.77427673339844, Neurons: 45, Grad norm: 1.971e+01\n",
      "Epoch 4261, Loss: 124.77427673339844, Neurons: 45, Grad norm: 1.971e+01\n",
      "Epoch 4262, Loss: 124.66743469238281, Neurons: 45, Grad norm: 1.970e+01\n",
      "Epoch 4262, Loss: 124.66743469238281, Neurons: 45, Grad norm: 1.970e+01\n",
      "Epoch 4263, Loss: 124.5599136352539, Neurons: 45, Grad norm: 1.958e+01\n",
      "Epoch 4263, Loss: 124.5599136352539, Neurons: 45, Grad norm: 1.958e+01\n",
      "Epoch 4264, Loss: 124.4517593383789, Neurons: 45, Grad norm: 1.949e+01\n",
      "Epoch 4264, Loss: 124.4517593383789, Neurons: 45, Grad norm: 1.949e+01\n",
      "Epoch 4265, Loss: 124.3431396484375, Neurons: 45, Grad norm: 1.945e+01\n",
      "Epoch 4265, Loss: 124.3431396484375, Neurons: 45, Grad norm: 1.945e+01\n",
      "Epoch 4266, Loss: 124.2340316772461, Neurons: 45, Grad norm: 1.943e+01\n",
      "Epoch 4266, Loss: 124.2340316772461, Neurons: 45, Grad norm: 1.943e+01\n",
      "Epoch 4267, Loss: 124.12438201904297, Neurons: 45, Grad norm: 1.936e+01\n",
      "Epoch 4267, Loss: 124.12438201904297, Neurons: 45, Grad norm: 1.936e+01\n",
      "Epoch 4268, Loss: 124.01410675048828, Neurons: 45, Grad norm: 1.927e+01\n",
      "Epoch 4268, Loss: 124.01410675048828, Neurons: 45, Grad norm: 1.927e+01\n",
      "Epoch 4269, Loss: 123.90328979492188, Neurons: 45, Grad norm: 1.922e+01\n",
      "Epoch 4269, Loss: 123.90328979492188, Neurons: 45, Grad norm: 1.922e+01\n",
      "Epoch 4270, Loss: 123.79200744628906, Neurons: 45, Grad norm: 1.921e+01\n",
      "Epoch 4270, Loss: 123.79200744628906, Neurons: 45, Grad norm: 1.921e+01\n",
      "Epoch 4271, Loss: 123.6802749633789, Neurons: 45, Grad norm: 1.922e+01\n",
      "Epoch 4271, Loss: 123.6802749633789, Neurons: 45, Grad norm: 1.922e+01\n",
      "Epoch 4272, Loss: 123.56805419921875, Neurons: 45, Grad norm: 1.914e+01\n",
      "Epoch 4272, Loss: 123.56805419921875, Neurons: 45, Grad norm: 1.914e+01\n",
      "Epoch 4273, Loss: 123.45529174804688, Neurons: 45, Grad norm: 1.903e+01\n",
      "Epoch 4273, Loss: 123.45529174804688, Neurons: 45, Grad norm: 1.903e+01\n",
      "Epoch 4274, Loss: 123.34195709228516, Neurons: 45, Grad norm: 1.895e+01\n",
      "Epoch 4274, Loss: 123.34195709228516, Neurons: 45, Grad norm: 1.895e+01\n",
      "Epoch 4275, Loss: 123.22816467285156, Neurons: 45, Grad norm: 1.890e+01\n",
      "Epoch 4275, Loss: 123.22816467285156, Neurons: 45, Grad norm: 1.890e+01\n",
      "Epoch 4276, Loss: 123.1138687133789, Neurons: 45, Grad norm: 1.888e+01\n",
      "Epoch 4276, Loss: 123.1138687133789, Neurons: 45, Grad norm: 1.888e+01\n",
      "Epoch 4277, Loss: 122.99907684326172, Neurons: 45, Grad norm: 1.887e+01\n",
      "Epoch 4277, Loss: 122.99907684326172, Neurons: 45, Grad norm: 1.887e+01\n",
      "Epoch 4278, Loss: 122.88375854492188, Neurons: 45, Grad norm: 1.886e+01\n",
      "Epoch 4278, Loss: 122.88375854492188, Neurons: 45, Grad norm: 1.886e+01\n",
      "Epoch 4279, Loss: 122.76789093017578, Neurons: 45, Grad norm: 1.887e+01\n",
      "Epoch 4279, Loss: 122.76789093017578, Neurons: 45, Grad norm: 1.887e+01\n",
      "Epoch 4280, Loss: 122.65153503417969, Neurons: 45, Grad norm: 1.889e+01\n",
      "Epoch 4280, Loss: 122.65153503417969, Neurons: 45, Grad norm: 1.889e+01\n",
      "Epoch 4281, Loss: 122.5346908569336, Neurons: 45, Grad norm: 1.892e+01\n",
      "Epoch 4281, Loss: 122.5346908569336, Neurons: 45, Grad norm: 1.892e+01\n",
      "Epoch 4282, Loss: 122.41738891601562, Neurons: 45, Grad norm: 1.895e+01\n",
      "Epoch 4282, Loss: 122.41738891601562, Neurons: 45, Grad norm: 1.895e+01\n",
      "Epoch 4283, Loss: 122.2995834350586, Neurons: 45, Grad norm: 1.891e+01\n",
      "Epoch 4283, Loss: 122.2995834350586, Neurons: 45, Grad norm: 1.891e+01\n",
      "Epoch 4284, Loss: 122.1812973022461, Neurons: 45, Grad norm: 1.887e+01\n",
      "Epoch 4284, Loss: 122.1812973022461, Neurons: 45, Grad norm: 1.887e+01\n",
      "Epoch 4285, Loss: 122.06253814697266, Neurons: 45, Grad norm: 1.882e+01\n",
      "Epoch 4285, Loss: 122.06253814697266, Neurons: 45, Grad norm: 1.882e+01\n",
      "Epoch 4286, Loss: 121.9433364868164, Neurons: 45, Grad norm: 1.877e+01\n",
      "Epoch 4286, Loss: 121.9433364868164, Neurons: 45, Grad norm: 1.877e+01\n",
      "Epoch 4287, Loss: 121.82366943359375, Neurons: 45, Grad norm: 1.873e+01\n",
      "Epoch 4287, Loss: 121.82366943359375, Neurons: 45, Grad norm: 1.873e+01\n",
      "Epoch 4288, Loss: 121.70358276367188, Neurons: 45, Grad norm: 1.868e+01\n",
      "Epoch 4288, Loss: 121.70358276367188, Neurons: 45, Grad norm: 1.868e+01\n",
      "Epoch 4289, Loss: 121.58306884765625, Neurons: 45, Grad norm: 1.864e+01\n",
      "Epoch 4289, Loss: 121.58306884765625, Neurons: 45, Grad norm: 1.864e+01\n",
      "Epoch 4290, Loss: 121.46212005615234, Neurons: 45, Grad norm: 1.860e+01\n",
      "Epoch 4290, Loss: 121.46212005615234, Neurons: 45, Grad norm: 1.860e+01\n",
      "Epoch 4291, Loss: 121.34075927734375, Neurons: 45, Grad norm: 1.857e+01\n",
      "Epoch 4291, Loss: 121.34075927734375, Neurons: 45, Grad norm: 1.857e+01\n",
      "Epoch 4292, Loss: 121.21897888183594, Neurons: 45, Grad norm: 1.854e+01\n",
      "Epoch 4292, Loss: 121.21897888183594, Neurons: 45, Grad norm: 1.854e+01\n",
      "Epoch 4293, Loss: 121.09678649902344, Neurons: 45, Grad norm: 1.851e+01\n",
      "Epoch 4293, Loss: 121.09678649902344, Neurons: 45, Grad norm: 1.851e+01\n",
      "Epoch 4294, Loss: 120.97421264648438, Neurons: 45, Grad norm: 1.849e+01\n",
      "Epoch 4294, Loss: 120.97421264648438, Neurons: 45, Grad norm: 1.849e+01\n",
      "Epoch 4295, Loss: 120.85122680664062, Neurons: 45, Grad norm: 1.846e+01\n",
      "Epoch 4295, Loss: 120.85122680664062, Neurons: 45, Grad norm: 1.846e+01\n",
      "Epoch 4296, Loss: 120.72785949707031, Neurons: 45, Grad norm: 1.843e+01\n",
      "Epoch 4296, Loss: 120.72785949707031, Neurons: 45, Grad norm: 1.843e+01\n",
      "Epoch 4297, Loss: 120.60407257080078, Neurons: 45, Grad norm: 1.841e+01\n",
      "Epoch 4297, Loss: 120.60407257080078, Neurons: 45, Grad norm: 1.841e+01\n",
      "Epoch 4298, Loss: 120.47993469238281, Neurons: 45, Grad norm: 1.840e+01\n",
      "Epoch 4298, Loss: 120.47993469238281, Neurons: 45, Grad norm: 1.840e+01\n",
      "Epoch 4299, Loss: 120.35541534423828, Neurons: 45, Grad norm: 1.839e+01\n",
      "Epoch 4299, Loss: 120.35541534423828, Neurons: 45, Grad norm: 1.839e+01\n",
      "Epoch 4299, Test loss: 115.4345932006836\n",
      "Epoch 4299, Test loss: 115.4345932006836\n",
      "Added neuron to hidden layer 2 with activation sin\n",
      "Added neuron to hidden layer 2 with activation sin\n",
      "network shape updated to :[18, 27, 1]\n",
      "network shape updated to :[18, 27, 1]\n",
      "Epoch 4300, Loss: 120.77056884765625, Neurons: 46, Grad norm: 5.457e+01\n",
      "Epoch 4300, Loss: 120.77056884765625, Neurons: 46, Grad norm: 5.457e+01\n",
      "Epoch 4301, Loss: 120.5757064819336, Neurons: 46, Grad norm: 4.014e+01\n",
      "Epoch 4301, Loss: 120.5757064819336, Neurons: 46, Grad norm: 4.014e+01\n",
      "Epoch 4302, Loss: 120.40859985351562, Neurons: 46, Grad norm: 2.821e+01\n",
      "Epoch 4302, Loss: 120.40859985351562, Neurons: 46, Grad norm: 2.821e+01\n",
      "Epoch 4303, Loss: 120.27277374267578, Neurons: 46, Grad norm: 2.154e+01\n",
      "Epoch 4303, Loss: 120.27277374267578, Neurons: 46, Grad norm: 2.154e+01\n",
      "Epoch 4304, Loss: 120.16938018798828, Neurons: 46, Grad norm: 2.262e+01\n",
      "Epoch 4304, Loss: 120.16938018798828, Neurons: 46, Grad norm: 2.262e+01\n",
      "Epoch 4305, Loss: 120.0954360961914, Neurons: 46, Grad norm: 2.789e+01\n",
      "Epoch 4305, Loss: 120.0954360961914, Neurons: 46, Grad norm: 2.789e+01\n",
      "Epoch 4306, Loss: 120.04325866699219, Neurons: 46, Grad norm: 3.313e+01\n",
      "Epoch 4306, Loss: 120.04325866699219, Neurons: 46, Grad norm: 3.313e+01\n",
      "Epoch 4307, Loss: 120.0027084350586, Neurons: 46, Grad norm: 3.690e+01\n",
      "Epoch 4307, Loss: 120.0027084350586, Neurons: 46, Grad norm: 3.690e+01\n",
      "Epoch 4308, Loss: 119.9646224975586, Neurons: 46, Grad norm: 3.894e+01\n",
      "Epoch 4308, Loss: 119.9646224975586, Neurons: 46, Grad norm: 3.894e+01\n",
      "Epoch 4309, Loss: 119.92247009277344, Neurons: 46, Grad norm: 3.934e+01\n",
      "Epoch 4309, Loss: 119.92247009277344, Neurons: 46, Grad norm: 3.934e+01\n",
      "Epoch 4310, Loss: 119.8726577758789, Neurons: 46, Grad norm: 3.842e+01\n",
      "Epoch 4310, Loss: 119.8726577758789, Neurons: 46, Grad norm: 3.842e+01\n",
      "Epoch 4311, Loss: 119.81409454345703, Neurons: 46, Grad norm: 3.643e+01\n",
      "Epoch 4311, Loss: 119.81409454345703, Neurons: 46, Grad norm: 3.643e+01\n",
      "Epoch 4312, Loss: 119.7474365234375, Neurons: 46, Grad norm: 3.369e+01\n",
      "Epoch 4312, Loss: 119.7474365234375, Neurons: 46, Grad norm: 3.369e+01\n",
      "Epoch 4313, Loss: 119.67417907714844, Neurons: 46, Grad norm: 3.047e+01\n",
      "Epoch 4313, Loss: 119.67417907714844, Neurons: 46, Grad norm: 3.047e+01\n",
      "Epoch 4314, Loss: 119.59635925292969, Neurons: 46, Grad norm: 2.720e+01\n",
      "Epoch 4314, Loss: 119.59635925292969, Neurons: 46, Grad norm: 2.720e+01\n",
      "Epoch 4315, Loss: 119.51593017578125, Neurons: 46, Grad norm: 2.414e+01\n",
      "Epoch 4315, Loss: 119.51593017578125, Neurons: 46, Grad norm: 2.414e+01\n",
      "Epoch 4316, Loss: 119.43470764160156, Neurons: 46, Grad norm: 2.156e+01\n",
      "Epoch 4316, Loss: 119.43470764160156, Neurons: 46, Grad norm: 2.156e+01\n",
      "Epoch 4317, Loss: 119.35401916503906, Neurons: 46, Grad norm: 1.972e+01\n",
      "Epoch 4317, Loss: 119.35401916503906, Neurons: 46, Grad norm: 1.972e+01\n",
      "Epoch 4318, Loss: 119.27465057373047, Neurons: 46, Grad norm: 1.865e+01\n",
      "Epoch 4318, Loss: 119.27465057373047, Neurons: 46, Grad norm: 1.865e+01\n",
      "Epoch 4319, Loss: 119.1968994140625, Neurons: 46, Grad norm: 1.820e+01\n",
      "Epoch 4319, Loss: 119.1968994140625, Neurons: 46, Grad norm: 1.820e+01\n",
      "Epoch 4320, Loss: 119.12047576904297, Neurons: 46, Grad norm: 1.818e+01\n",
      "Epoch 4320, Loss: 119.12047576904297, Neurons: 46, Grad norm: 1.818e+01\n",
      "Epoch 4321, Loss: 119.04473876953125, Neurons: 46, Grad norm: 1.838e+01\n",
      "Epoch 4321, Loss: 119.04473876953125, Neurons: 46, Grad norm: 1.838e+01\n",
      "Epoch 4322, Loss: 118.9688720703125, Neurons: 46, Grad norm: 1.864e+01\n",
      "Epoch 4322, Loss: 118.9688720703125, Neurons: 46, Grad norm: 1.864e+01\n",
      "Epoch 4323, Loss: 118.89197540283203, Neurons: 46, Grad norm: 1.889e+01\n",
      "Epoch 4323, Loss: 118.89197540283203, Neurons: 46, Grad norm: 1.889e+01\n",
      "Epoch 4324, Loss: 118.81321716308594, Neurons: 46, Grad norm: 1.908e+01\n",
      "Epoch 4324, Loss: 118.81321716308594, Neurons: 46, Grad norm: 1.908e+01\n",
      "Epoch 4325, Loss: 118.73197174072266, Neurons: 46, Grad norm: 1.918e+01\n",
      "Epoch 4325, Loss: 118.73197174072266, Neurons: 46, Grad norm: 1.918e+01\n",
      "Epoch 4326, Loss: 118.64801788330078, Neurons: 46, Grad norm: 1.921e+01\n",
      "Epoch 4326, Loss: 118.64801788330078, Neurons: 46, Grad norm: 1.921e+01\n",
      "Epoch 4327, Loss: 118.56134796142578, Neurons: 46, Grad norm: 1.918e+01\n",
      "Epoch 4327, Loss: 118.56134796142578, Neurons: 46, Grad norm: 1.918e+01\n",
      "Epoch 4328, Loss: 118.4722900390625, Neurons: 46, Grad norm: 1.911e+01\n",
      "Epoch 4328, Loss: 118.4722900390625, Neurons: 46, Grad norm: 1.911e+01\n",
      "Epoch 4329, Loss: 118.38134765625, Neurons: 46, Grad norm: 1.905e+01\n",
      "Epoch 4329, Loss: 118.38134765625, Neurons: 46, Grad norm: 1.905e+01\n",
      "Epoch 4330, Loss: 118.28905487060547, Neurons: 46, Grad norm: 1.901e+01\n",
      "Epoch 4330, Loss: 118.28905487060547, Neurons: 46, Grad norm: 1.901e+01\n",
      "Epoch 4331, Loss: 118.19593048095703, Neurons: 46, Grad norm: 1.901e+01\n",
      "Epoch 4331, Loss: 118.19593048095703, Neurons: 46, Grad norm: 1.901e+01\n",
      "Epoch 4332, Loss: 118.1023178100586, Neurons: 46, Grad norm: 1.906e+01\n",
      "Epoch 4332, Loss: 118.1023178100586, Neurons: 46, Grad norm: 1.906e+01\n",
      "Epoch 4333, Loss: 118.00843811035156, Neurons: 46, Grad norm: 1.919e+01\n",
      "Epoch 4333, Loss: 118.00843811035156, Neurons: 46, Grad norm: 1.919e+01\n",
      "Epoch 4334, Loss: 117.91423797607422, Neurons: 46, Grad norm: 1.934e+01\n",
      "Epoch 4334, Loss: 117.91423797607422, Neurons: 46, Grad norm: 1.934e+01\n",
      "Epoch 4335, Loss: 117.81954193115234, Neurons: 46, Grad norm: 1.943e+01\n",
      "Epoch 4335, Loss: 117.81954193115234, Neurons: 46, Grad norm: 1.943e+01\n",
      "Epoch 4336, Loss: 117.72407531738281, Neurons: 46, Grad norm: 1.952e+01\n",
      "Epoch 4336, Loss: 117.72407531738281, Neurons: 46, Grad norm: 1.952e+01\n",
      "Epoch 4337, Loss: 117.62783813476562, Neurons: 46, Grad norm: 1.972e+01\n",
      "Epoch 4337, Loss: 117.62783813476562, Neurons: 46, Grad norm: 1.972e+01\n",
      "Epoch 4338, Loss: 117.53054809570312, Neurons: 46, Grad norm: 1.988e+01\n",
      "Epoch 4338, Loss: 117.53054809570312, Neurons: 46, Grad norm: 1.988e+01\n",
      "Epoch 4339, Loss: 117.43183135986328, Neurons: 46, Grad norm: 1.996e+01\n",
      "Epoch 4339, Loss: 117.43183135986328, Neurons: 46, Grad norm: 1.996e+01\n",
      "Epoch 4340, Loss: 117.33145904541016, Neurons: 46, Grad norm: 1.992e+01\n",
      "Epoch 4340, Loss: 117.33145904541016, Neurons: 46, Grad norm: 1.992e+01\n",
      "Epoch 4341, Loss: 117.22950744628906, Neurons: 46, Grad norm: 1.987e+01\n",
      "Epoch 4341, Loss: 117.22950744628906, Neurons: 46, Grad norm: 1.987e+01\n",
      "Epoch 4342, Loss: 117.12628173828125, Neurons: 46, Grad norm: 1.980e+01\n",
      "Epoch 4342, Loss: 117.12628173828125, Neurons: 46, Grad norm: 1.980e+01\n",
      "Epoch 4343, Loss: 117.02203369140625, Neurons: 46, Grad norm: 1.980e+01\n",
      "Epoch 4343, Loss: 117.02203369140625, Neurons: 46, Grad norm: 1.980e+01\n",
      "Epoch 4344, Loss: 116.91691589355469, Neurons: 46, Grad norm: 1.964e+01\n",
      "Epoch 4344, Loss: 116.91691589355469, Neurons: 46, Grad norm: 1.964e+01\n",
      "Epoch 4345, Loss: 116.81098175048828, Neurons: 46, Grad norm: 1.941e+01\n",
      "Epoch 4345, Loss: 116.81098175048828, Neurons: 46, Grad norm: 1.941e+01\n",
      "Epoch 4346, Loss: 116.70425415039062, Neurons: 46, Grad norm: 1.912e+01\n",
      "Epoch 4346, Loss: 116.70425415039062, Neurons: 46, Grad norm: 1.912e+01\n",
      "Epoch 4347, Loss: 116.5968017578125, Neurons: 46, Grad norm: 1.884e+01\n",
      "Epoch 4347, Loss: 116.5968017578125, Neurons: 46, Grad norm: 1.884e+01\n",
      "Epoch 4348, Loss: 116.4887466430664, Neurons: 46, Grad norm: 1.862e+01\n",
      "Epoch 4348, Loss: 116.4887466430664, Neurons: 46, Grad norm: 1.862e+01\n",
      "Epoch 4349, Loss: 116.38002014160156, Neurons: 46, Grad norm: 1.843e+01\n",
      "Epoch 4349, Loss: 116.38002014160156, Neurons: 46, Grad norm: 1.843e+01\n",
      "Epoch 4350, Loss: 116.27052307128906, Neurons: 46, Grad norm: 1.828e+01\n",
      "Epoch 4350, Loss: 116.27052307128906, Neurons: 46, Grad norm: 1.828e+01\n",
      "Epoch 4351, Loss: 116.1601333618164, Neurons: 46, Grad norm: 1.815e+01\n",
      "Epoch 4351, Loss: 116.1601333618164, Neurons: 46, Grad norm: 1.815e+01\n",
      "Epoch 4352, Loss: 116.04877471923828, Neurons: 46, Grad norm: 1.805e+01\n",
      "Epoch 4352, Loss: 116.04877471923828, Neurons: 46, Grad norm: 1.805e+01\n",
      "Epoch 4353, Loss: 115.93644714355469, Neurons: 46, Grad norm: 1.800e+01\n",
      "Epoch 4353, Loss: 115.93644714355469, Neurons: 46, Grad norm: 1.800e+01\n",
      "Epoch 4354, Loss: 115.82325744628906, Neurons: 46, Grad norm: 1.802e+01\n",
      "Epoch 4354, Loss: 115.82325744628906, Neurons: 46, Grad norm: 1.802e+01\n",
      "Epoch 4355, Loss: 115.7092056274414, Neurons: 46, Grad norm: 1.806e+01\n",
      "Epoch 4355, Loss: 115.7092056274414, Neurons: 46, Grad norm: 1.806e+01\n",
      "Epoch 4356, Loss: 115.59434509277344, Neurons: 46, Grad norm: 1.814e+01\n",
      "Epoch 4356, Loss: 115.59434509277344, Neurons: 46, Grad norm: 1.814e+01\n",
      "Epoch 4357, Loss: 115.47867584228516, Neurons: 46, Grad norm: 1.821e+01\n",
      "Epoch 4357, Loss: 115.47867584228516, Neurons: 46, Grad norm: 1.821e+01\n",
      "Epoch 4358, Loss: 115.36228942871094, Neurons: 46, Grad norm: 1.831e+01\n",
      "Epoch 4358, Loss: 115.36228942871094, Neurons: 46, Grad norm: 1.831e+01\n",
      "Epoch 4359, Loss: 115.24523162841797, Neurons: 46, Grad norm: 1.848e+01\n",
      "Epoch 4359, Loss: 115.24523162841797, Neurons: 46, Grad norm: 1.848e+01\n",
      "Epoch 4360, Loss: 115.12760162353516, Neurons: 46, Grad norm: 1.864e+01\n",
      "Epoch 4360, Loss: 115.12760162353516, Neurons: 46, Grad norm: 1.864e+01\n",
      "Epoch 4361, Loss: 115.0093002319336, Neurons: 46, Grad norm: 1.879e+01\n",
      "Epoch 4361, Loss: 115.0093002319336, Neurons: 46, Grad norm: 1.879e+01\n",
      "Epoch 4362, Loss: 114.8903579711914, Neurons: 46, Grad norm: 1.889e+01\n",
      "Epoch 4362, Loss: 114.8903579711914, Neurons: 46, Grad norm: 1.889e+01\n",
      "Epoch 4363, Loss: 114.77069091796875, Neurons: 46, Grad norm: 1.897e+01\n",
      "Epoch 4363, Loss: 114.77069091796875, Neurons: 46, Grad norm: 1.897e+01\n",
      "Epoch 4364, Loss: 114.65032196044922, Neurons: 46, Grad norm: 1.898e+01\n",
      "Epoch 4364, Loss: 114.65032196044922, Neurons: 46, Grad norm: 1.898e+01\n",
      "Epoch 4365, Loss: 114.52928161621094, Neurons: 46, Grad norm: 1.894e+01\n",
      "Epoch 4365, Loss: 114.52928161621094, Neurons: 46, Grad norm: 1.894e+01\n",
      "Epoch 4366, Loss: 114.40755462646484, Neurons: 46, Grad norm: 1.886e+01\n",
      "Epoch 4366, Loss: 114.40755462646484, Neurons: 46, Grad norm: 1.886e+01\n",
      "Epoch 4367, Loss: 114.28514099121094, Neurons: 46, Grad norm: 1.872e+01\n",
      "Epoch 4367, Loss: 114.28514099121094, Neurons: 46, Grad norm: 1.872e+01\n",
      "Epoch 4368, Loss: 114.16205596923828, Neurons: 46, Grad norm: 1.855e+01\n",
      "Epoch 4368, Loss: 114.16205596923828, Neurons: 46, Grad norm: 1.855e+01\n",
      "Epoch 4369, Loss: 114.03836059570312, Neurons: 46, Grad norm: 1.839e+01\n",
      "Epoch 4369, Loss: 114.03836059570312, Neurons: 46, Grad norm: 1.839e+01\n",
      "Epoch 4370, Loss: 113.91405487060547, Neurons: 46, Grad norm: 1.826e+01\n",
      "Epoch 4370, Loss: 113.91405487060547, Neurons: 46, Grad norm: 1.826e+01\n",
      "Epoch 4371, Loss: 113.78919219970703, Neurons: 46, Grad norm: 1.816e+01\n",
      "Epoch 4371, Loss: 113.78919219970703, Neurons: 46, Grad norm: 1.816e+01\n",
      "Epoch 4372, Loss: 113.66377258300781, Neurons: 46, Grad norm: 1.809e+01\n",
      "Epoch 4372, Loss: 113.66377258300781, Neurons: 46, Grad norm: 1.809e+01\n",
      "Epoch 4373, Loss: 113.53778076171875, Neurons: 46, Grad norm: 1.805e+01\n",
      "Epoch 4373, Loss: 113.53778076171875, Neurons: 46, Grad norm: 1.805e+01\n",
      "Epoch 4374, Loss: 113.4112319946289, Neurons: 46, Grad norm: 1.804e+01\n",
      "Epoch 4374, Loss: 113.4112319946289, Neurons: 46, Grad norm: 1.804e+01\n",
      "Epoch 4375, Loss: 113.28412628173828, Neurons: 46, Grad norm: 1.806e+01\n",
      "Epoch 4375, Loss: 113.28412628173828, Neurons: 46, Grad norm: 1.806e+01\n",
      "Epoch 4376, Loss: 113.15644836425781, Neurons: 46, Grad norm: 1.809e+01\n",
      "Epoch 4376, Loss: 113.15644836425781, Neurons: 46, Grad norm: 1.809e+01\n",
      "Epoch 4377, Loss: 113.02824401855469, Neurons: 46, Grad norm: 1.812e+01\n",
      "Epoch 4377, Loss: 113.02824401855469, Neurons: 46, Grad norm: 1.812e+01\n",
      "Epoch 4378, Loss: 112.89949035644531, Neurons: 46, Grad norm: 1.813e+01\n",
      "Epoch 4378, Loss: 112.89949035644531, Neurons: 46, Grad norm: 1.813e+01\n",
      "Epoch 4379, Loss: 112.77018737792969, Neurons: 46, Grad norm: 1.813e+01\n",
      "Epoch 4379, Loss: 112.77018737792969, Neurons: 46, Grad norm: 1.813e+01\n",
      "Epoch 4380, Loss: 112.640380859375, Neurons: 46, Grad norm: 1.815e+01\n",
      "Epoch 4380, Loss: 112.640380859375, Neurons: 46, Grad norm: 1.815e+01\n",
      "Epoch 4381, Loss: 112.51007080078125, Neurons: 46, Grad norm: 1.816e+01\n",
      "Epoch 4381, Loss: 112.51007080078125, Neurons: 46, Grad norm: 1.816e+01\n",
      "Epoch 4382, Loss: 112.37928009033203, Neurons: 46, Grad norm: 1.815e+01\n",
      "Epoch 4382, Loss: 112.37928009033203, Neurons: 46, Grad norm: 1.815e+01\n",
      "Epoch 4383, Loss: 112.24800872802734, Neurons: 46, Grad norm: 1.814e+01\n",
      "Epoch 4383, Loss: 112.24800872802734, Neurons: 46, Grad norm: 1.814e+01\n",
      "Epoch 4384, Loss: 112.11624908447266, Neurons: 46, Grad norm: 1.815e+01\n",
      "Epoch 4384, Loss: 112.11624908447266, Neurons: 46, Grad norm: 1.815e+01\n",
      "Epoch 4385, Loss: 111.98402404785156, Neurons: 46, Grad norm: 1.812e+01\n",
      "Epoch 4385, Loss: 111.98402404785156, Neurons: 46, Grad norm: 1.812e+01\n",
      "Epoch 4386, Loss: 111.85137176513672, Neurons: 46, Grad norm: 1.809e+01\n",
      "Epoch 4386, Loss: 111.85137176513672, Neurons: 46, Grad norm: 1.809e+01\n",
      "Epoch 4387, Loss: 111.71823120117188, Neurons: 46, Grad norm: 1.808e+01\n",
      "Epoch 4387, Loss: 111.71823120117188, Neurons: 46, Grad norm: 1.808e+01\n",
      "Epoch 4388, Loss: 111.58464813232422, Neurons: 46, Grad norm: 1.807e+01\n",
      "Epoch 4388, Loss: 111.58464813232422, Neurons: 46, Grad norm: 1.807e+01\n",
      "Epoch 4389, Loss: 111.45061492919922, Neurons: 46, Grad norm: 1.821e+01\n",
      "Epoch 4389, Loss: 111.45061492919922, Neurons: 46, Grad norm: 1.821e+01\n",
      "Epoch 4390, Loss: 111.31649780273438, Neurons: 46, Grad norm: 1.854e+01\n",
      "Epoch 4390, Loss: 111.31649780273438, Neurons: 46, Grad norm: 1.854e+01\n",
      "Epoch 4391, Loss: 111.18311309814453, Neurons: 46, Grad norm: 1.809e+01\n",
      "Epoch 4391, Loss: 111.18311309814453, Neurons: 46, Grad norm: 1.809e+01\n",
      "Epoch 4392, Loss: 111.04756927490234, Neurons: 46, Grad norm: 1.813e+01\n",
      "Epoch 4392, Loss: 111.04756927490234, Neurons: 46, Grad norm: 1.813e+01\n",
      "Epoch 4393, Loss: 110.91301727294922, Neurons: 46, Grad norm: 1.814e+01\n",
      "Epoch 4393, Loss: 110.91301727294922, Neurons: 46, Grad norm: 1.814e+01\n",
      "Epoch 4394, Loss: 110.778076171875, Neurons: 46, Grad norm: 1.808e+01\n",
      "Epoch 4394, Loss: 110.778076171875, Neurons: 46, Grad norm: 1.808e+01\n",
      "Epoch 4395, Loss: 110.64270782470703, Neurons: 46, Grad norm: 1.800e+01\n",
      "Epoch 4395, Loss: 110.64270782470703, Neurons: 46, Grad norm: 1.800e+01\n",
      "Epoch 4396, Loss: 110.50689697265625, Neurons: 46, Grad norm: 1.789e+01\n",
      "Epoch 4396, Loss: 110.50689697265625, Neurons: 46, Grad norm: 1.789e+01\n",
      "Epoch 4397, Loss: 110.37067413330078, Neurons: 46, Grad norm: 1.777e+01\n",
      "Epoch 4397, Loss: 110.37067413330078, Neurons: 46, Grad norm: 1.777e+01\n",
      "Epoch 4398, Loss: 110.23403930664062, Neurons: 46, Grad norm: 1.766e+01\n",
      "Epoch 4398, Loss: 110.23403930664062, Neurons: 46, Grad norm: 1.766e+01\n",
      "Epoch 4399, Loss: 110.09700775146484, Neurons: 46, Grad norm: 1.755e+01\n",
      "Epoch 4399, Loss: 110.09700775146484, Neurons: 46, Grad norm: 1.755e+01\n",
      "Epoch 4399, Test loss: 105.20346069335938\n",
      "Epoch 4399, Test loss: 105.20346069335938\n",
      "Added neuron to hidden layer 1 with activation sin\n",
      "Added neuron to hidden layer 1 with activation sin\n",
      "network shape updated to :[19, 27, 1]\n",
      "network shape updated to :[19, 27, 1]\n",
      "Epoch 4400, Loss: 109.93899536132812, Neurons: 47, Grad norm: 2.006e+01\n",
      "Epoch 4400, Loss: 109.93899536132812, Neurons: 47, Grad norm: 2.006e+01\n",
      "Epoch 4401, Loss: 109.8788833618164, Neurons: 47, Grad norm: 2.089e+01\n",
      "Epoch 4401, Loss: 109.8788833618164, Neurons: 47, Grad norm: 2.089e+01\n",
      "Epoch 4402, Loss: 109.82697296142578, Neurons: 47, Grad norm: 1.968e+01\n",
      "Epoch 4402, Loss: 109.82697296142578, Neurons: 47, Grad norm: 1.968e+01\n",
      "Epoch 4403, Loss: 109.77420806884766, Neurons: 47, Grad norm: 1.823e+01\n",
      "Epoch 4403, Loss: 109.77420806884766, Neurons: 47, Grad norm: 1.823e+01\n",
      "Epoch 4404, Loss: 109.71882629394531, Neurons: 47, Grad norm: 1.736e+01\n",
      "Epoch 4404, Loss: 109.71882629394531, Neurons: 47, Grad norm: 1.736e+01\n",
      "Epoch 4405, Loss: 109.66046905517578, Neurons: 47, Grad norm: 1.696e+01\n",
      "Epoch 4405, Loss: 109.66046905517578, Neurons: 47, Grad norm: 1.696e+01\n",
      "Epoch 4406, Loss: 109.59912872314453, Neurons: 47, Grad norm: 1.776e+01\n",
      "Epoch 4406, Loss: 109.59912872314453, Neurons: 47, Grad norm: 1.776e+01\n",
      "Epoch 4407, Loss: 109.53783416748047, Neurons: 47, Grad norm: 1.762e+01\n",
      "Epoch 4407, Loss: 109.53783416748047, Neurons: 47, Grad norm: 1.762e+01\n",
      "Epoch 4408, Loss: 109.47117614746094, Neurons: 47, Grad norm: 1.762e+01\n",
      "Epoch 4408, Loss: 109.47117614746094, Neurons: 47, Grad norm: 1.762e+01\n",
      "Epoch 4409, Loss: 109.40239715576172, Neurons: 47, Grad norm: 1.809e+01\n",
      "Epoch 4409, Loss: 109.40239715576172, Neurons: 47, Grad norm: 1.809e+01\n",
      "Epoch 4410, Loss: 109.33275604248047, Neurons: 47, Grad norm: 1.836e+01\n",
      "Epoch 4410, Loss: 109.33275604248047, Neurons: 47, Grad norm: 1.836e+01\n",
      "Epoch 4411, Loss: 109.2608642578125, Neurons: 47, Grad norm: 1.835e+01\n",
      "Epoch 4411, Loss: 109.2608642578125, Neurons: 47, Grad norm: 1.835e+01\n",
      "Epoch 4412, Loss: 109.18666076660156, Neurons: 47, Grad norm: 1.803e+01\n",
      "Epoch 4412, Loss: 109.18666076660156, Neurons: 47, Grad norm: 1.803e+01\n",
      "Epoch 4413, Loss: 109.1103744506836, Neurons: 47, Grad norm: 1.793e+01\n",
      "Epoch 4413, Loss: 109.1103744506836, Neurons: 47, Grad norm: 1.793e+01\n",
      "Epoch 4414, Loss: 109.03215789794922, Neurons: 47, Grad norm: 1.777e+01\n",
      "Epoch 4414, Loss: 109.03215789794922, Neurons: 47, Grad norm: 1.777e+01\n",
      "Epoch 4415, Loss: 108.95140838623047, Neurons: 47, Grad norm: 1.748e+01\n",
      "Epoch 4415, Loss: 108.95140838623047, Neurons: 47, Grad norm: 1.748e+01\n",
      "Epoch 4416, Loss: 108.86800384521484, Neurons: 47, Grad norm: 1.727e+01\n",
      "Epoch 4416, Loss: 108.86800384521484, Neurons: 47, Grad norm: 1.727e+01\n",
      "Epoch 4417, Loss: 108.78243255615234, Neurons: 47, Grad norm: 1.733e+01\n",
      "Epoch 4417, Loss: 108.78243255615234, Neurons: 47, Grad norm: 1.733e+01\n",
      "Epoch 4418, Loss: 108.6951675415039, Neurons: 47, Grad norm: 1.737e+01\n",
      "Epoch 4418, Loss: 108.6951675415039, Neurons: 47, Grad norm: 1.737e+01\n",
      "Epoch 4419, Loss: 108.60613250732422, Neurons: 47, Grad norm: 1.727e+01\n",
      "Epoch 4419, Loss: 108.60613250732422, Neurons: 47, Grad norm: 1.727e+01\n",
      "Epoch 4420, Loss: 108.51502227783203, Neurons: 47, Grad norm: 1.712e+01\n",
      "Epoch 4420, Loss: 108.51502227783203, Neurons: 47, Grad norm: 1.712e+01\n",
      "Epoch 4421, Loss: 108.42183685302734, Neurons: 47, Grad norm: 1.696e+01\n",
      "Epoch 4421, Loss: 108.42183685302734, Neurons: 47, Grad norm: 1.696e+01\n",
      "Epoch 4422, Loss: 108.32665252685547, Neurons: 47, Grad norm: 1.692e+01\n",
      "Epoch 4422, Loss: 108.32665252685547, Neurons: 47, Grad norm: 1.692e+01\n",
      "Epoch 4423, Loss: 108.22966003417969, Neurons: 47, Grad norm: 1.701e+01\n",
      "Epoch 4423, Loss: 108.22966003417969, Neurons: 47, Grad norm: 1.701e+01\n",
      "Epoch 4424, Loss: 108.1311264038086, Neurons: 47, Grad norm: 1.696e+01\n",
      "Epoch 4424, Loss: 108.1311264038086, Neurons: 47, Grad norm: 1.696e+01\n",
      "Epoch 4425, Loss: 108.03057861328125, Neurons: 47, Grad norm: 1.705e+01\n",
      "Epoch 4425, Loss: 108.03057861328125, Neurons: 47, Grad norm: 1.705e+01\n",
      "Epoch 4426, Loss: 107.9284896850586, Neurons: 47, Grad norm: 1.720e+01\n",
      "Epoch 4426, Loss: 107.9284896850586, Neurons: 47, Grad norm: 1.720e+01\n",
      "Epoch 4427, Loss: 107.8248519897461, Neurons: 47, Grad norm: 1.719e+01\n",
      "Epoch 4427, Loss: 107.8248519897461, Neurons: 47, Grad norm: 1.719e+01\n",
      "Epoch 4428, Loss: 107.71936798095703, Neurons: 47, Grad norm: 1.704e+01\n",
      "Epoch 4428, Loss: 107.71936798095703, Neurons: 47, Grad norm: 1.704e+01\n",
      "Epoch 4429, Loss: 107.61214447021484, Neurons: 47, Grad norm: 1.685e+01\n",
      "Epoch 4429, Loss: 107.61214447021484, Neurons: 47, Grad norm: 1.685e+01\n",
      "Epoch 4430, Loss: 107.50334930419922, Neurons: 47, Grad norm: 1.670e+01\n",
      "Epoch 4430, Loss: 107.50334930419922, Neurons: 47, Grad norm: 1.670e+01\n",
      "Epoch 4431, Loss: 107.39308166503906, Neurons: 47, Grad norm: 1.661e+01\n",
      "Epoch 4431, Loss: 107.39308166503906, Neurons: 47, Grad norm: 1.661e+01\n",
      "Epoch 4432, Loss: 107.28125, Neurons: 47, Grad norm: 1.663e+01\n",
      "Epoch 4432, Loss: 107.28125, Neurons: 47, Grad norm: 1.663e+01\n",
      "Epoch 4433, Loss: 107.16796112060547, Neurons: 47, Grad norm: 1.659e+01\n",
      "Epoch 4433, Loss: 107.16796112060547, Neurons: 47, Grad norm: 1.659e+01\n",
      "Epoch 4434, Loss: 107.05307006835938, Neurons: 47, Grad norm: 1.655e+01\n",
      "Epoch 4434, Loss: 107.05307006835938, Neurons: 47, Grad norm: 1.655e+01\n",
      "Epoch 4435, Loss: 106.93663787841797, Neurons: 47, Grad norm: 1.659e+01\n",
      "Epoch 4435, Loss: 106.93663787841797, Neurons: 47, Grad norm: 1.659e+01\n",
      "Epoch 4436, Loss: 106.81897735595703, Neurons: 47, Grad norm: 1.656e+01\n",
      "Epoch 4436, Loss: 106.81897735595703, Neurons: 47, Grad norm: 1.656e+01\n",
      "Epoch 4437, Loss: 106.69987487792969, Neurons: 47, Grad norm: 1.649e+01\n",
      "Epoch 4437, Loss: 106.69987487792969, Neurons: 47, Grad norm: 1.649e+01\n",
      "Epoch 4438, Loss: 106.57936096191406, Neurons: 47, Grad norm: 1.642e+01\n",
      "Epoch 4438, Loss: 106.57936096191406, Neurons: 47, Grad norm: 1.642e+01\n",
      "Epoch 4439, Loss: 106.45747375488281, Neurons: 47, Grad norm: 1.637e+01\n",
      "Epoch 4439, Loss: 106.45747375488281, Neurons: 47, Grad norm: 1.637e+01\n",
      "Epoch 4440, Loss: 106.33423614501953, Neurons: 47, Grad norm: 1.631e+01\n",
      "Epoch 4440, Loss: 106.33423614501953, Neurons: 47, Grad norm: 1.631e+01\n",
      "Epoch 4441, Loss: 106.20960235595703, Neurons: 47, Grad norm: 1.633e+01\n",
      "Epoch 4441, Loss: 106.20960235595703, Neurons: 47, Grad norm: 1.633e+01\n",
      "Epoch 4442, Loss: 106.08375549316406, Neurons: 47, Grad norm: 1.633e+01\n",
      "Epoch 4442, Loss: 106.08375549316406, Neurons: 47, Grad norm: 1.633e+01\n",
      "Epoch 4443, Loss: 105.95658111572266, Neurons: 47, Grad norm: 1.628e+01\n",
      "Epoch 4443, Loss: 105.95658111572266, Neurons: 47, Grad norm: 1.628e+01\n",
      "Epoch 4444, Loss: 105.82814025878906, Neurons: 47, Grad norm: 1.624e+01\n",
      "Epoch 4444, Loss: 105.82814025878906, Neurons: 47, Grad norm: 1.624e+01\n",
      "Epoch 4445, Loss: 105.69841003417969, Neurons: 47, Grad norm: 1.618e+01\n",
      "Epoch 4445, Loss: 105.69841003417969, Neurons: 47, Grad norm: 1.618e+01\n",
      "Epoch 4446, Loss: 105.56743621826172, Neurons: 47, Grad norm: 1.614e+01\n",
      "Epoch 4446, Loss: 105.56743621826172, Neurons: 47, Grad norm: 1.614e+01\n",
      "Epoch 4447, Loss: 105.43525695800781, Neurons: 47, Grad norm: 1.613e+01\n",
      "Epoch 4447, Loss: 105.43525695800781, Neurons: 47, Grad norm: 1.613e+01\n",
      "Epoch 4448, Loss: 105.30184173583984, Neurons: 47, Grad norm: 1.614e+01\n",
      "Epoch 4448, Loss: 105.30184173583984, Neurons: 47, Grad norm: 1.614e+01\n",
      "Epoch 4449, Loss: 105.16720581054688, Neurons: 47, Grad norm: 1.614e+01\n",
      "Epoch 4449, Loss: 105.16720581054688, Neurons: 47, Grad norm: 1.614e+01\n",
      "Epoch 4450, Loss: 105.03138732910156, Neurons: 47, Grad norm: 1.608e+01\n",
      "Epoch 4450, Loss: 105.03138732910156, Neurons: 47, Grad norm: 1.608e+01\n",
      "Epoch 4451, Loss: 104.89437866210938, Neurons: 47, Grad norm: 1.602e+01\n",
      "Epoch 4451, Loss: 104.89437866210938, Neurons: 47, Grad norm: 1.602e+01\n",
      "Epoch 4452, Loss: 104.7562255859375, Neurons: 47, Grad norm: 1.596e+01\n",
      "Epoch 4452, Loss: 104.7562255859375, Neurons: 47, Grad norm: 1.596e+01\n",
      "Epoch 4453, Loss: 104.61688995361328, Neurons: 47, Grad norm: 1.589e+01\n",
      "Epoch 4453, Loss: 104.61688995361328, Neurons: 47, Grad norm: 1.589e+01\n",
      "Epoch 4454, Loss: 104.47638702392578, Neurons: 47, Grad norm: 1.587e+01\n",
      "Epoch 4454, Loss: 104.47638702392578, Neurons: 47, Grad norm: 1.587e+01\n",
      "Epoch 4455, Loss: 104.33470916748047, Neurons: 47, Grad norm: 1.589e+01\n",
      "Epoch 4455, Loss: 104.33470916748047, Neurons: 47, Grad norm: 1.589e+01\n",
      "Epoch 4456, Loss: 104.19192504882812, Neurons: 47, Grad norm: 1.591e+01\n",
      "Epoch 4456, Loss: 104.19192504882812, Neurons: 47, Grad norm: 1.591e+01\n",
      "Epoch 4457, Loss: 104.04800415039062, Neurons: 47, Grad norm: 1.590e+01\n",
      "Epoch 4457, Loss: 104.04800415039062, Neurons: 47, Grad norm: 1.590e+01\n",
      "Epoch 4458, Loss: 103.90293884277344, Neurons: 47, Grad norm: 1.587e+01\n",
      "Epoch 4458, Loss: 103.90293884277344, Neurons: 47, Grad norm: 1.587e+01\n",
      "Epoch 4459, Loss: 103.7567367553711, Neurons: 47, Grad norm: 1.580e+01\n",
      "Epoch 4459, Loss: 103.7567367553711, Neurons: 47, Grad norm: 1.580e+01\n",
      "Epoch 4460, Loss: 103.60942840576172, Neurons: 47, Grad norm: 1.575e+01\n",
      "Epoch 4460, Loss: 103.60942840576172, Neurons: 47, Grad norm: 1.575e+01\n",
      "Epoch 4461, Loss: 103.46099853515625, Neurons: 47, Grad norm: 1.574e+01\n",
      "Epoch 4461, Loss: 103.46099853515625, Neurons: 47, Grad norm: 1.574e+01\n",
      "Epoch 4462, Loss: 103.31145477294922, Neurons: 47, Grad norm: 1.572e+01\n",
      "Epoch 4462, Loss: 103.31145477294922, Neurons: 47, Grad norm: 1.572e+01\n",
      "Epoch 4463, Loss: 103.16077423095703, Neurons: 47, Grad norm: 1.573e+01\n",
      "Epoch 4463, Loss: 103.16077423095703, Neurons: 47, Grad norm: 1.573e+01\n",
      "Epoch 4464, Loss: 103.00901794433594, Neurons: 47, Grad norm: 1.571e+01\n",
      "Epoch 4464, Loss: 103.00901794433594, Neurons: 47, Grad norm: 1.571e+01\n",
      "Epoch 4465, Loss: 102.85613250732422, Neurons: 47, Grad norm: 1.570e+01\n",
      "Epoch 4465, Loss: 102.85613250732422, Neurons: 47, Grad norm: 1.570e+01\n",
      "Epoch 4466, Loss: 102.70213317871094, Neurons: 47, Grad norm: 1.563e+01\n",
      "Epoch 4466, Loss: 102.70213317871094, Neurons: 47, Grad norm: 1.563e+01\n",
      "Epoch 4467, Loss: 102.54698944091797, Neurons: 47, Grad norm: 1.560e+01\n",
      "Epoch 4467, Loss: 102.54698944091797, Neurons: 47, Grad norm: 1.560e+01\n",
      "Epoch 4468, Loss: 102.3907241821289, Neurons: 47, Grad norm: 1.558e+01\n",
      "Epoch 4468, Loss: 102.3907241821289, Neurons: 47, Grad norm: 1.558e+01\n",
      "Epoch 4469, Loss: 102.23332977294922, Neurons: 47, Grad norm: 1.559e+01\n",
      "Epoch 4469, Loss: 102.23332977294922, Neurons: 47, Grad norm: 1.559e+01\n",
      "Epoch 4470, Loss: 102.07482147216797, Neurons: 47, Grad norm: 1.558e+01\n",
      "Epoch 4470, Loss: 102.07482147216797, Neurons: 47, Grad norm: 1.558e+01\n",
      "Epoch 4471, Loss: 101.91516876220703, Neurons: 47, Grad norm: 1.556e+01\n",
      "Epoch 4471, Loss: 101.91516876220703, Neurons: 47, Grad norm: 1.556e+01\n",
      "Epoch 4472, Loss: 101.75436401367188, Neurons: 47, Grad norm: 1.554e+01\n",
      "Epoch 4472, Loss: 101.75436401367188, Neurons: 47, Grad norm: 1.554e+01\n",
      "Epoch 4473, Loss: 101.59239959716797, Neurons: 47, Grad norm: 1.554e+01\n",
      "Epoch 4473, Loss: 101.59239959716797, Neurons: 47, Grad norm: 1.554e+01\n",
      "Epoch 4474, Loss: 101.4292984008789, Neurons: 47, Grad norm: 1.551e+01\n",
      "Epoch 4474, Loss: 101.4292984008789, Neurons: 47, Grad norm: 1.551e+01\n",
      "Epoch 4475, Loss: 101.26505279541016, Neurons: 47, Grad norm: 1.549e+01\n",
      "Epoch 4475, Loss: 101.26505279541016, Neurons: 47, Grad norm: 1.549e+01\n",
      "Epoch 4476, Loss: 101.09960174560547, Neurons: 47, Grad norm: 1.550e+01\n",
      "Epoch 4476, Loss: 101.09960174560547, Neurons: 47, Grad norm: 1.550e+01\n",
      "Epoch 4477, Loss: 100.93299102783203, Neurons: 47, Grad norm: 1.545e+01\n",
      "Epoch 4477, Loss: 100.93299102783203, Neurons: 47, Grad norm: 1.545e+01\n",
      "Epoch 4478, Loss: 100.76517486572266, Neurons: 47, Grad norm: 1.544e+01\n",
      "Epoch 4478, Loss: 100.76517486572266, Neurons: 47, Grad norm: 1.544e+01\n",
      "Epoch 4479, Loss: 100.59620666503906, Neurons: 47, Grad norm: 1.541e+01\n",
      "Epoch 4479, Loss: 100.59620666503906, Neurons: 47, Grad norm: 1.541e+01\n",
      "Epoch 4480, Loss: 100.426025390625, Neurons: 47, Grad norm: 1.542e+01\n",
      "Epoch 4480, Loss: 100.426025390625, Neurons: 47, Grad norm: 1.542e+01\n",
      "Epoch 4481, Loss: 100.2546615600586, Neurons: 47, Grad norm: 1.539e+01\n",
      "Epoch 4481, Loss: 100.2546615600586, Neurons: 47, Grad norm: 1.539e+01\n",
      "Epoch 4482, Loss: 100.08209991455078, Neurons: 47, Grad norm: 1.539e+01\n",
      "Epoch 4482, Loss: 100.08209991455078, Neurons: 47, Grad norm: 1.539e+01\n",
      "Epoch 4483, Loss: 99.90831756591797, Neurons: 47, Grad norm: 1.540e+01\n",
      "Epoch 4483, Loss: 99.90831756591797, Neurons: 47, Grad norm: 1.540e+01\n",
      "Epoch 4484, Loss: 99.73332214355469, Neurons: 47, Grad norm: 1.537e+01\n",
      "Epoch 4484, Loss: 99.73332214355469, Neurons: 47, Grad norm: 1.537e+01\n",
      "Epoch 4485, Loss: 99.5571060180664, Neurons: 47, Grad norm: 1.535e+01\n",
      "Epoch 4485, Loss: 99.5571060180664, Neurons: 47, Grad norm: 1.535e+01\n",
      "Epoch 4486, Loss: 99.37969970703125, Neurons: 47, Grad norm: 1.533e+01\n",
      "Epoch 4486, Loss: 99.37969970703125, Neurons: 47, Grad norm: 1.533e+01\n",
      "Epoch 4487, Loss: 99.20105743408203, Neurons: 47, Grad norm: 1.533e+01\n",
      "Epoch 4487, Loss: 99.20105743408203, Neurons: 47, Grad norm: 1.533e+01\n",
      "Epoch 4488, Loss: 99.02122497558594, Neurons: 47, Grad norm: 1.533e+01\n",
      "Epoch 4488, Loss: 99.02122497558594, Neurons: 47, Grad norm: 1.533e+01\n",
      "Epoch 4489, Loss: 98.84017181396484, Neurons: 47, Grad norm: 1.533e+01\n",
      "Epoch 4489, Loss: 98.84017181396484, Neurons: 47, Grad norm: 1.533e+01\n",
      "Epoch 4490, Loss: 98.65791320800781, Neurons: 47, Grad norm: 1.532e+01\n",
      "Epoch 4490, Loss: 98.65791320800781, Neurons: 47, Grad norm: 1.532e+01\n",
      "Epoch 4491, Loss: 98.47444152832031, Neurons: 47, Grad norm: 1.528e+01\n",
      "Epoch 4491, Loss: 98.47444152832031, Neurons: 47, Grad norm: 1.528e+01\n",
      "Epoch 4492, Loss: 98.289794921875, Neurons: 47, Grad norm: 1.528e+01\n",
      "Epoch 4492, Loss: 98.289794921875, Neurons: 47, Grad norm: 1.528e+01\n",
      "Epoch 4493, Loss: 98.10396575927734, Neurons: 47, Grad norm: 1.530e+01\n",
      "Epoch 4493, Loss: 98.10396575927734, Neurons: 47, Grad norm: 1.530e+01\n",
      "Epoch 4494, Loss: 97.91695404052734, Neurons: 47, Grad norm: 1.529e+01\n",
      "Epoch 4494, Loss: 97.91695404052734, Neurons: 47, Grad norm: 1.529e+01\n",
      "Epoch 4495, Loss: 97.7287826538086, Neurons: 47, Grad norm: 1.529e+01\n",
      "Epoch 4495, Loss: 97.7287826538086, Neurons: 47, Grad norm: 1.529e+01\n",
      "Epoch 4496, Loss: 97.53947448730469, Neurons: 47, Grad norm: 1.527e+01\n",
      "Epoch 4496, Loss: 97.53947448730469, Neurons: 47, Grad norm: 1.527e+01\n",
      "Epoch 4497, Loss: 97.34901428222656, Neurons: 47, Grad norm: 1.526e+01\n",
      "Epoch 4497, Loss: 97.34901428222656, Neurons: 47, Grad norm: 1.526e+01\n",
      "Epoch 4498, Loss: 97.15744018554688, Neurons: 47, Grad norm: 1.525e+01\n",
      "Epoch 4498, Loss: 97.15744018554688, Neurons: 47, Grad norm: 1.525e+01\n",
      "Epoch 4499, Loss: 96.96476745605469, Neurons: 47, Grad norm: 1.525e+01\n",
      "Epoch 4499, Loss: 96.96476745605469, Neurons: 47, Grad norm: 1.525e+01\n",
      "Epoch 4499, Test loss: 92.25458526611328\n",
      "Epoch 4499, Test loss: 92.25458526611328\n",
      "Added neuron to hidden layer 1 with activation relu\n",
      "Added neuron to hidden layer 1 with activation relu\n",
      "network shape updated to :[20, 27, 1]\n",
      "network shape updated to :[20, 27, 1]\n",
      "Epoch 4500, Loss: 113.06128692626953, Neurons: 48, Grad norm: 2.455e+02\n",
      "Epoch 4500, Loss: 113.06128692626953, Neurons: 48, Grad norm: 2.455e+02\n",
      "Epoch 4501, Loss: 112.33433532714844, Neurons: 48, Grad norm: 2.321e+02\n",
      "Epoch 4501, Loss: 112.33433532714844, Neurons: 48, Grad norm: 2.321e+02\n",
      "Epoch 4502, Loss: 111.6085433959961, Neurons: 48, Grad norm: 2.189e+02\n",
      "Epoch 4502, Loss: 111.6085433959961, Neurons: 48, Grad norm: 2.189e+02\n",
      "Epoch 4503, Loss: 110.89202880859375, Neurons: 48, Grad norm: 2.061e+02\n",
      "Epoch 4503, Loss: 110.89202880859375, Neurons: 48, Grad norm: 2.061e+02\n",
      "Epoch 4504, Loss: 110.18952941894531, Neurons: 48, Grad norm: 1.941e+02\n",
      "Epoch 4504, Loss: 110.18952941894531, Neurons: 48, Grad norm: 1.941e+02\n",
      "Epoch 4505, Loss: 109.50579833984375, Neurons: 48, Grad norm: 1.832e+02\n",
      "Epoch 4505, Loss: 109.50579833984375, Neurons: 48, Grad norm: 1.832e+02\n",
      "Epoch 4506, Loss: 108.84400177001953, Neurons: 48, Grad norm: 1.734e+02\n",
      "Epoch 4506, Loss: 108.84400177001953, Neurons: 48, Grad norm: 1.734e+02\n",
      "Epoch 4507, Loss: 108.20602416992188, Neurons: 48, Grad norm: 1.648e+02\n",
      "Epoch 4507, Loss: 108.20602416992188, Neurons: 48, Grad norm: 1.648e+02\n",
      "Epoch 4508, Loss: 107.59288787841797, Neurons: 48, Grad norm: 1.573e+02\n",
      "Epoch 4508, Loss: 107.59288787841797, Neurons: 48, Grad norm: 1.573e+02\n",
      "Epoch 4509, Loss: 107.00524139404297, Neurons: 48, Grad norm: 1.507e+02\n",
      "Epoch 4509, Loss: 107.00524139404297, Neurons: 48, Grad norm: 1.507e+02\n",
      "Epoch 4510, Loss: 106.44319152832031, Neurons: 48, Grad norm: 1.449e+02\n",
      "Epoch 4510, Loss: 106.44319152832031, Neurons: 48, Grad norm: 1.449e+02\n",
      "Epoch 4511, Loss: 105.9064712524414, Neurons: 48, Grad norm: 1.397e+02\n",
      "Epoch 4511, Loss: 105.9064712524414, Neurons: 48, Grad norm: 1.397e+02\n",
      "Epoch 4512, Loss: 105.39447021484375, Neurons: 48, Grad norm: 1.350e+02\n",
      "Epoch 4512, Loss: 105.39447021484375, Neurons: 48, Grad norm: 1.350e+02\n",
      "Epoch 4513, Loss: 104.9064712524414, Neurons: 48, Grad norm: 1.304e+02\n",
      "Epoch 4513, Loss: 104.9064712524414, Neurons: 48, Grad norm: 1.304e+02\n",
      "Epoch 4514, Loss: 104.44170379638672, Neurons: 48, Grad norm: 1.260e+02\n",
      "Epoch 4514, Loss: 104.44170379638672, Neurons: 48, Grad norm: 1.260e+02\n",
      "Epoch 4515, Loss: 103.9994888305664, Neurons: 48, Grad norm: 1.216e+02\n",
      "Epoch 4515, Loss: 103.9994888305664, Neurons: 48, Grad norm: 1.216e+02\n",
      "Epoch 4516, Loss: 103.57920837402344, Neurons: 48, Grad norm: 1.171e+02\n",
      "Epoch 4516, Loss: 103.57920837402344, Neurons: 48, Grad norm: 1.171e+02\n",
      "Epoch 4517, Loss: 103.18018341064453, Neurons: 48, Grad norm: 1.125e+02\n",
      "Epoch 4517, Loss: 103.18018341064453, Neurons: 48, Grad norm: 1.125e+02\n",
      "Epoch 4518, Loss: 102.8017578125, Neurons: 48, Grad norm: 1.080e+02\n",
      "Epoch 4518, Loss: 102.8017578125, Neurons: 48, Grad norm: 1.080e+02\n",
      "Epoch 4519, Loss: 102.4428939819336, Neurons: 48, Grad norm: 1.035e+02\n",
      "Epoch 4519, Loss: 102.4428939819336, Neurons: 48, Grad norm: 1.035e+02\n",
      "Epoch 4520, Loss: 102.10248565673828, Neurons: 48, Grad norm: 9.907e+01\n",
      "Epoch 4520, Loss: 102.10248565673828, Neurons: 48, Grad norm: 9.907e+01\n",
      "Epoch 4521, Loss: 101.77912902832031, Neurons: 48, Grad norm: 9.478e+01\n",
      "Epoch 4521, Loss: 101.77912902832031, Neurons: 48, Grad norm: 9.478e+01\n",
      "Epoch 4522, Loss: 101.47129821777344, Neurons: 48, Grad norm: 9.067e+01\n",
      "Epoch 4522, Loss: 101.47129821777344, Neurons: 48, Grad norm: 9.067e+01\n",
      "Epoch 4523, Loss: 101.17752838134766, Neurons: 48, Grad norm: 8.675e+01\n",
      "Epoch 4523, Loss: 101.17752838134766, Neurons: 48, Grad norm: 8.675e+01\n",
      "Epoch 4524, Loss: 100.8963851928711, Neurons: 48, Grad norm: 8.304e+01\n",
      "Epoch 4524, Loss: 100.8963851928711, Neurons: 48, Grad norm: 8.304e+01\n",
      "Epoch 4525, Loss: 100.62657928466797, Neurons: 48, Grad norm: 7.955e+01\n",
      "Epoch 4525, Loss: 100.62657928466797, Neurons: 48, Grad norm: 7.955e+01\n",
      "Epoch 4526, Loss: 100.36703491210938, Neurons: 48, Grad norm: 7.627e+01\n",
      "Epoch 4526, Loss: 100.36703491210938, Neurons: 48, Grad norm: 7.627e+01\n",
      "Epoch 4527, Loss: 100.11676788330078, Neurons: 48, Grad norm: 7.319e+01\n",
      "Epoch 4527, Loss: 100.11676788330078, Neurons: 48, Grad norm: 7.319e+01\n",
      "Epoch 4528, Loss: 99.87503814697266, Neurons: 48, Grad norm: 7.030e+01\n",
      "Epoch 4528, Loss: 99.87503814697266, Neurons: 48, Grad norm: 7.030e+01\n",
      "Epoch 4529, Loss: 99.64120483398438, Neurons: 48, Grad norm: 6.758e+01\n",
      "Epoch 4529, Loss: 99.64120483398438, Neurons: 48, Grad norm: 6.758e+01\n",
      "Epoch 4530, Loss: 99.41475677490234, Neurons: 48, Grad norm: 6.501e+01\n",
      "Epoch 4530, Loss: 99.41475677490234, Neurons: 48, Grad norm: 6.501e+01\n",
      "Epoch 4531, Loss: 99.1953353881836, Neurons: 48, Grad norm: 6.257e+01\n",
      "Epoch 4531, Loss: 99.1953353881836, Neurons: 48, Grad norm: 6.257e+01\n",
      "Epoch 4532, Loss: 98.98255157470703, Neurons: 48, Grad norm: 6.026e+01\n",
      "Epoch 4532, Loss: 98.98255157470703, Neurons: 48, Grad norm: 6.026e+01\n",
      "Epoch 4533, Loss: 98.77619171142578, Neurons: 48, Grad norm: 5.807e+01\n",
      "Epoch 4533, Loss: 98.77619171142578, Neurons: 48, Grad norm: 5.807e+01\n",
      "Epoch 4534, Loss: 98.57601928710938, Neurons: 48, Grad norm: 5.597e+01\n",
      "Epoch 4534, Loss: 98.57601928710938, Neurons: 48, Grad norm: 5.597e+01\n",
      "Epoch 4535, Loss: 98.38188934326172, Neurons: 48, Grad norm: 5.399e+01\n",
      "Epoch 4535, Loss: 98.38188934326172, Neurons: 48, Grad norm: 5.399e+01\n",
      "Epoch 4536, Loss: 98.19358825683594, Neurons: 48, Grad norm: 5.210e+01\n",
      "Epoch 4536, Loss: 98.19358825683594, Neurons: 48, Grad norm: 5.210e+01\n",
      "Epoch 4537, Loss: 98.01092529296875, Neurons: 48, Grad norm: 5.031e+01\n",
      "Epoch 4537, Loss: 98.01092529296875, Neurons: 48, Grad norm: 5.031e+01\n",
      "Epoch 4538, Loss: 97.83372497558594, Neurons: 48, Grad norm: 4.861e+01\n",
      "Epoch 4538, Loss: 97.83372497558594, Neurons: 48, Grad norm: 4.861e+01\n",
      "Epoch 4539, Loss: 97.66180419921875, Neurons: 48, Grad norm: 4.702e+01\n",
      "Epoch 4539, Loss: 97.66180419921875, Neurons: 48, Grad norm: 4.702e+01\n",
      "Epoch 4540, Loss: 97.49495697021484, Neurons: 48, Grad norm: 4.551e+01\n",
      "Epoch 4540, Loss: 97.49495697021484, Neurons: 48, Grad norm: 4.551e+01\n",
      "Epoch 4541, Loss: 97.3329849243164, Neurons: 48, Grad norm: 4.409e+01\n",
      "Epoch 4541, Loss: 97.3329849243164, Neurons: 48, Grad norm: 4.409e+01\n",
      "Epoch 4542, Loss: 97.17569732666016, Neurons: 48, Grad norm: 4.276e+01\n",
      "Epoch 4542, Loss: 97.17569732666016, Neurons: 48, Grad norm: 4.276e+01\n",
      "Epoch 4543, Loss: 97.02294158935547, Neurons: 48, Grad norm: 4.153e+01\n",
      "Epoch 4543, Loss: 97.02294158935547, Neurons: 48, Grad norm: 4.153e+01\n",
      "Epoch 4544, Loss: 96.87452697753906, Neurons: 48, Grad norm: 4.038e+01\n",
      "Epoch 4544, Loss: 96.87452697753906, Neurons: 48, Grad norm: 4.038e+01\n",
      "Epoch 4545, Loss: 96.73027038574219, Neurons: 48, Grad norm: 3.932e+01\n",
      "Epoch 4545, Loss: 96.73027038574219, Neurons: 48, Grad norm: 3.932e+01\n",
      "Epoch 4546, Loss: 96.5899887084961, Neurons: 48, Grad norm: 3.835e+01\n",
      "Epoch 4546, Loss: 96.5899887084961, Neurons: 48, Grad norm: 3.835e+01\n",
      "Epoch 4547, Loss: 96.45349884033203, Neurons: 48, Grad norm: 3.746e+01\n",
      "Epoch 4547, Loss: 96.45349884033203, Neurons: 48, Grad norm: 3.746e+01\n",
      "Epoch 4548, Loss: 96.3205795288086, Neurons: 48, Grad norm: 3.665e+01\n",
      "Epoch 4548, Loss: 96.3205795288086, Neurons: 48, Grad norm: 3.665e+01\n",
      "Epoch 4549, Loss: 96.19097137451172, Neurons: 48, Grad norm: 3.587e+01\n",
      "Epoch 4549, Loss: 96.19097137451172, Neurons: 48, Grad norm: 3.587e+01\n",
      "Epoch 4550, Loss: 96.06450653076172, Neurons: 48, Grad norm: 3.515e+01\n",
      "Epoch 4550, Loss: 96.06450653076172, Neurons: 48, Grad norm: 3.515e+01\n",
      "Epoch 4551, Loss: 95.94080352783203, Neurons: 48, Grad norm: 3.448e+01\n",
      "Epoch 4551, Loss: 95.94080352783203, Neurons: 48, Grad norm: 3.448e+01\n",
      "Epoch 4552, Loss: 95.81967163085938, Neurons: 48, Grad norm: 3.383e+01\n",
      "Epoch 4552, Loss: 95.81967163085938, Neurons: 48, Grad norm: 3.383e+01\n",
      "Epoch 4553, Loss: 95.70085144042969, Neurons: 48, Grad norm: 3.318e+01\n",
      "Epoch 4553, Loss: 95.70085144042969, Neurons: 48, Grad norm: 3.318e+01\n",
      "Epoch 4554, Loss: 95.58407592773438, Neurons: 48, Grad norm: 3.252e+01\n",
      "Epoch 4554, Loss: 95.58407592773438, Neurons: 48, Grad norm: 3.252e+01\n",
      "Epoch 4555, Loss: 95.4691390991211, Neurons: 48, Grad norm: 3.185e+01\n",
      "Epoch 4555, Loss: 95.4691390991211, Neurons: 48, Grad norm: 3.185e+01\n",
      "Epoch 4556, Loss: 95.35581970214844, Neurons: 48, Grad norm: 3.117e+01\n",
      "Epoch 4556, Loss: 95.35581970214844, Neurons: 48, Grad norm: 3.117e+01\n",
      "Epoch 4557, Loss: 95.24396514892578, Neurons: 48, Grad norm: 3.047e+01\n",
      "Epoch 4557, Loss: 95.24396514892578, Neurons: 48, Grad norm: 3.047e+01\n",
      "Epoch 4558, Loss: 95.1334228515625, Neurons: 48, Grad norm: 2.975e+01\n",
      "Epoch 4558, Loss: 95.1334228515625, Neurons: 48, Grad norm: 2.975e+01\n",
      "Epoch 4559, Loss: 95.0240707397461, Neurons: 48, Grad norm: 2.905e+01\n",
      "Epoch 4559, Loss: 95.0240707397461, Neurons: 48, Grad norm: 2.905e+01\n",
      "Epoch 4560, Loss: 94.91583251953125, Neurons: 48, Grad norm: 2.834e+01\n",
      "Epoch 4560, Loss: 94.91583251953125, Neurons: 48, Grad norm: 2.834e+01\n",
      "Epoch 4561, Loss: 94.80862426757812, Neurons: 48, Grad norm: 2.765e+01\n",
      "Epoch 4561, Loss: 94.80862426757812, Neurons: 48, Grad norm: 2.765e+01\n",
      "Epoch 4562, Loss: 94.70240020751953, Neurons: 48, Grad norm: 2.698e+01\n",
      "Epoch 4562, Loss: 94.70240020751953, Neurons: 48, Grad norm: 2.698e+01\n",
      "Epoch 4563, Loss: 94.59706115722656, Neurons: 48, Grad norm: 2.634e+01\n",
      "Epoch 4563, Loss: 94.59706115722656, Neurons: 48, Grad norm: 2.634e+01\n",
      "Epoch 4564, Loss: 94.49261474609375, Neurons: 48, Grad norm: 2.572e+01\n",
      "Epoch 4564, Loss: 94.49261474609375, Neurons: 48, Grad norm: 2.572e+01\n",
      "Epoch 4565, Loss: 94.38947296142578, Neurons: 48, Grad norm: 2.520e+01\n",
      "Epoch 4565, Loss: 94.38947296142578, Neurons: 48, Grad norm: 2.520e+01\n",
      "Epoch 4566, Loss: 94.28715515136719, Neurons: 48, Grad norm: 2.475e+01\n",
      "Epoch 4566, Loss: 94.28715515136719, Neurons: 48, Grad norm: 2.475e+01\n",
      "Epoch 4567, Loss: 94.18510437011719, Neurons: 48, Grad norm: 2.434e+01\n",
      "Epoch 4567, Loss: 94.18510437011719, Neurons: 48, Grad norm: 2.434e+01\n",
      "Epoch 4568, Loss: 94.08341979980469, Neurons: 48, Grad norm: 2.400e+01\n",
      "Epoch 4568, Loss: 94.08341979980469, Neurons: 48, Grad norm: 2.400e+01\n",
      "Epoch 4569, Loss: 93.98250579833984, Neurons: 48, Grad norm: 2.371e+01\n",
      "Epoch 4569, Loss: 93.98250579833984, Neurons: 48, Grad norm: 2.371e+01\n",
      "Epoch 4570, Loss: 93.882568359375, Neurons: 48, Grad norm: 2.343e+01\n",
      "Epoch 4570, Loss: 93.882568359375, Neurons: 48, Grad norm: 2.343e+01\n",
      "Epoch 4571, Loss: 93.78316497802734, Neurons: 48, Grad norm: 2.316e+01\n",
      "Epoch 4571, Loss: 93.78316497802734, Neurons: 48, Grad norm: 2.316e+01\n",
      "Epoch 4572, Loss: 93.6842269897461, Neurons: 48, Grad norm: 2.291e+01\n",
      "Epoch 4572, Loss: 93.6842269897461, Neurons: 48, Grad norm: 2.291e+01\n",
      "Epoch 4573, Loss: 93.58567810058594, Neurons: 48, Grad norm: 2.269e+01\n",
      "Epoch 4573, Loss: 93.58567810058594, Neurons: 48, Grad norm: 2.269e+01\n",
      "Epoch 4574, Loss: 93.48750305175781, Neurons: 48, Grad norm: 2.247e+01\n",
      "Epoch 4574, Loss: 93.48750305175781, Neurons: 48, Grad norm: 2.247e+01\n",
      "Epoch 4575, Loss: 93.38964080810547, Neurons: 48, Grad norm: 2.223e+01\n",
      "Epoch 4575, Loss: 93.38964080810547, Neurons: 48, Grad norm: 2.223e+01\n",
      "Epoch 4576, Loss: 93.29203796386719, Neurons: 48, Grad norm: 2.199e+01\n",
      "Epoch 4576, Loss: 93.29203796386719, Neurons: 48, Grad norm: 2.199e+01\n",
      "Epoch 4577, Loss: 93.1947021484375, Neurons: 48, Grad norm: 2.176e+01\n",
      "Epoch 4577, Loss: 93.1947021484375, Neurons: 48, Grad norm: 2.176e+01\n",
      "Epoch 4578, Loss: 93.0975341796875, Neurons: 48, Grad norm: 2.153e+01\n",
      "Epoch 4578, Loss: 93.0975341796875, Neurons: 48, Grad norm: 2.153e+01\n",
      "Epoch 4579, Loss: 93.00056457519531, Neurons: 48, Grad norm: 2.131e+01\n",
      "Epoch 4579, Loss: 93.00056457519531, Neurons: 48, Grad norm: 2.131e+01\n",
      "Epoch 4580, Loss: 92.90372467041016, Neurons: 48, Grad norm: 2.106e+01\n",
      "Epoch 4580, Loss: 92.90372467041016, Neurons: 48, Grad norm: 2.106e+01\n",
      "Epoch 4581, Loss: 92.80716705322266, Neurons: 48, Grad norm: 2.088e+01\n",
      "Epoch 4581, Loss: 92.80716705322266, Neurons: 48, Grad norm: 2.088e+01\n",
      "Epoch 4582, Loss: 92.71078491210938, Neurons: 48, Grad norm: 2.073e+01\n",
      "Epoch 4582, Loss: 92.71078491210938, Neurons: 48, Grad norm: 2.073e+01\n",
      "Epoch 4583, Loss: 92.61434173583984, Neurons: 48, Grad norm: 2.063e+01\n",
      "Epoch 4583, Loss: 92.61434173583984, Neurons: 48, Grad norm: 2.063e+01\n",
      "Epoch 4584, Loss: 92.5178451538086, Neurons: 48, Grad norm: 2.052e+01\n",
      "Epoch 4584, Loss: 92.5178451538086, Neurons: 48, Grad norm: 2.052e+01\n",
      "Epoch 4585, Loss: 92.42134857177734, Neurons: 48, Grad norm: 2.049e+01\n",
      "Epoch 4585, Loss: 92.42134857177734, Neurons: 48, Grad norm: 2.049e+01\n",
      "Epoch 4586, Loss: 92.32495880126953, Neurons: 48, Grad norm: 2.039e+01\n",
      "Epoch 4586, Loss: 92.32495880126953, Neurons: 48, Grad norm: 2.039e+01\n",
      "Epoch 4587, Loss: 92.22862243652344, Neurons: 48, Grad norm: 2.031e+01\n",
      "Epoch 4587, Loss: 92.22862243652344, Neurons: 48, Grad norm: 2.031e+01\n",
      "Epoch 4588, Loss: 92.13223266601562, Neurons: 48, Grad norm: 2.021e+01\n",
      "Epoch 4588, Loss: 92.13223266601562, Neurons: 48, Grad norm: 2.021e+01\n",
      "Epoch 4589, Loss: 92.03578186035156, Neurons: 48, Grad norm: 2.009e+01\n",
      "Epoch 4589, Loss: 92.03578186035156, Neurons: 48, Grad norm: 2.009e+01\n",
      "Epoch 4590, Loss: 91.93925476074219, Neurons: 48, Grad norm: 1.999e+01\n",
      "Epoch 4590, Loss: 91.93925476074219, Neurons: 48, Grad norm: 1.999e+01\n",
      "Epoch 4591, Loss: 91.84265899658203, Neurons: 48, Grad norm: 1.986e+01\n",
      "Epoch 4591, Loss: 91.84265899658203, Neurons: 48, Grad norm: 1.986e+01\n",
      "Epoch 4592, Loss: 91.74594116210938, Neurons: 48, Grad norm: 1.970e+01\n",
      "Epoch 4592, Loss: 91.74594116210938, Neurons: 48, Grad norm: 1.970e+01\n",
      "Epoch 4593, Loss: 91.64918518066406, Neurons: 48, Grad norm: 1.960e+01\n",
      "Epoch 4593, Loss: 91.64918518066406, Neurons: 48, Grad norm: 1.960e+01\n",
      "Epoch 4594, Loss: 91.5523452758789, Neurons: 48, Grad norm: 1.950e+01\n",
      "Epoch 4594, Loss: 91.5523452758789, Neurons: 48, Grad norm: 1.950e+01\n",
      "Epoch 4595, Loss: 91.4554443359375, Neurons: 48, Grad norm: 1.941e+01\n",
      "Epoch 4595, Loss: 91.4554443359375, Neurons: 48, Grad norm: 1.941e+01\n",
      "Epoch 4596, Loss: 91.3583755493164, Neurons: 48, Grad norm: 1.934e+01\n",
      "Epoch 4596, Loss: 91.3583755493164, Neurons: 48, Grad norm: 1.934e+01\n",
      "Epoch 4597, Loss: 91.26117706298828, Neurons: 48, Grad norm: 1.929e+01\n",
      "Epoch 4597, Loss: 91.26117706298828, Neurons: 48, Grad norm: 1.929e+01\n",
      "Epoch 4598, Loss: 91.1638412475586, Neurons: 48, Grad norm: 1.926e+01\n",
      "Epoch 4598, Loss: 91.1638412475586, Neurons: 48, Grad norm: 1.926e+01\n",
      "Epoch 4599, Loss: 91.06635284423828, Neurons: 48, Grad norm: 1.924e+01\n",
      "Epoch 4599, Loss: 91.06635284423828, Neurons: 48, Grad norm: 1.924e+01\n",
      "Epoch 4599, Test loss: 86.48246002197266\n",
      "Epoch 4599, Test loss: 86.48246002197266\n",
      "Added neuron to hidden layer 1 with activation relu\n",
      "Added neuron to hidden layer 1 with activation relu\n",
      "network shape updated to :[21, 27, 1]\n",
      "network shape updated to :[21, 27, 1]\n",
      "Epoch 4600, Loss: 322.9350891113281, Neurons: 49, Grad norm: 1.194e+03\n",
      "Epoch 4600, Loss: 322.9350891113281, Neurons: 49, Grad norm: 1.194e+03\n",
      "Epoch 4601, Loss: 320.2107849121094, Neurons: 49, Grad norm: 1.186e+03\n",
      "Epoch 4601, Loss: 320.2107849121094, Neurons: 49, Grad norm: 1.186e+03\n",
      "Epoch 4602, Loss: 317.3653259277344, Neurons: 49, Grad norm: 1.177e+03\n",
      "Epoch 4602, Loss: 317.3653259277344, Neurons: 49, Grad norm: 1.177e+03\n",
      "Epoch 4603, Loss: 314.39990234375, Neurons: 49, Grad norm: 1.168e+03\n",
      "Epoch 4603, Loss: 314.39990234375, Neurons: 49, Grad norm: 1.168e+03\n",
      "Epoch 4604, Loss: 311.31549072265625, Neurons: 49, Grad norm: 1.157e+03\n",
      "Epoch 4604, Loss: 311.31549072265625, Neurons: 49, Grad norm: 1.157e+03\n",
      "Epoch 4605, Loss: 308.1147155761719, Neurons: 49, Grad norm: 1.146e+03\n",
      "Epoch 4605, Loss: 308.1147155761719, Neurons: 49, Grad norm: 1.146e+03\n",
      "Epoch 4606, Loss: 304.8006286621094, Neurons: 49, Grad norm: 1.135e+03\n",
      "Epoch 4606, Loss: 304.8006286621094, Neurons: 49, Grad norm: 1.135e+03\n",
      "Epoch 4607, Loss: 301.37774658203125, Neurons: 49, Grad norm: 1.122e+03\n",
      "Epoch 4607, Loss: 301.37774658203125, Neurons: 49, Grad norm: 1.122e+03\n",
      "Epoch 4608, Loss: 297.8507385253906, Neurons: 49, Grad norm: 1.110e+03\n",
      "Epoch 4608, Loss: 297.8507385253906, Neurons: 49, Grad norm: 1.110e+03\n",
      "Epoch 4609, Loss: 294.2248840332031, Neurons: 49, Grad norm: 1.097e+03\n",
      "Epoch 4609, Loss: 294.2248840332031, Neurons: 49, Grad norm: 1.097e+03\n",
      "Epoch 4610, Loss: 290.5057678222656, Neurons: 49, Grad norm: 1.083e+03\n",
      "Epoch 4610, Loss: 290.5057678222656, Neurons: 49, Grad norm: 1.083e+03\n",
      "Epoch 4611, Loss: 286.69970703125, Neurons: 49, Grad norm: 1.070e+03\n",
      "Epoch 4611, Loss: 286.69970703125, Neurons: 49, Grad norm: 1.070e+03\n",
      "Epoch 4612, Loss: 282.8131408691406, Neurons: 49, Grad norm: 1.056e+03\n",
      "Epoch 4612, Loss: 282.8131408691406, Neurons: 49, Grad norm: 1.056e+03\n",
      "Epoch 4613, Loss: 278.853271484375, Neurons: 49, Grad norm: 1.042e+03\n",
      "Epoch 4613, Loss: 278.853271484375, Neurons: 49, Grad norm: 1.042e+03\n",
      "Epoch 4614, Loss: 274.82757568359375, Neurons: 49, Grad norm: 1.028e+03\n",
      "Epoch 4614, Loss: 274.82757568359375, Neurons: 49, Grad norm: 1.028e+03\n",
      "Epoch 4615, Loss: 270.74395751953125, Neurons: 49, Grad norm: 1.013e+03\n",
      "Epoch 4615, Loss: 270.74395751953125, Neurons: 49, Grad norm: 1.013e+03\n",
      "Epoch 4616, Loss: 266.6107177734375, Neurons: 49, Grad norm: 9.977e+02\n",
      "Epoch 4616, Loss: 266.6107177734375, Neurons: 49, Grad norm: 9.977e+02\n",
      "Epoch 4617, Loss: 262.4357604980469, Neurons: 49, Grad norm: 9.822e+02\n",
      "Epoch 4617, Loss: 262.4357604980469, Neurons: 49, Grad norm: 9.822e+02\n",
      "Epoch 4618, Loss: 258.2281188964844, Neurons: 49, Grad norm: 9.664e+02\n",
      "Epoch 4618, Loss: 258.2281188964844, Neurons: 49, Grad norm: 9.664e+02\n",
      "Epoch 4619, Loss: 253.99777221679688, Neurons: 49, Grad norm: 9.503e+02\n",
      "Epoch 4619, Loss: 253.99777221679688, Neurons: 49, Grad norm: 9.503e+02\n",
      "Epoch 4620, Loss: 249.74871826171875, Neurons: 49, Grad norm: 9.340e+02\n",
      "Epoch 4620, Loss: 249.74871826171875, Neurons: 49, Grad norm: 9.340e+02\n",
      "Epoch 4621, Loss: 245.48971557617188, Neurons: 49, Grad norm: 9.177e+02\n",
      "Epoch 4621, Loss: 245.48971557617188, Neurons: 49, Grad norm: 9.177e+02\n",
      "Epoch 4622, Loss: 241.22959899902344, Neurons: 49, Grad norm: 9.013e+02\n",
      "Epoch 4622, Loss: 241.22959899902344, Neurons: 49, Grad norm: 9.013e+02\n",
      "Epoch 4623, Loss: 236.97747802734375, Neurons: 49, Grad norm: 8.848e+02\n",
      "Epoch 4623, Loss: 236.97747802734375, Neurons: 49, Grad norm: 8.848e+02\n",
      "Epoch 4624, Loss: 232.74063110351562, Neurons: 49, Grad norm: 8.682e+02\n",
      "Epoch 4624, Loss: 232.74063110351562, Neurons: 49, Grad norm: 8.682e+02\n",
      "Epoch 4625, Loss: 228.5257568359375, Neurons: 49, Grad norm: 8.517e+02\n",
      "Epoch 4625, Loss: 228.5257568359375, Neurons: 49, Grad norm: 8.517e+02\n",
      "Epoch 4626, Loss: 224.3399658203125, Neurons: 49, Grad norm: 8.351e+02\n",
      "Epoch 4626, Loss: 224.3399658203125, Neurons: 49, Grad norm: 8.351e+02\n",
      "Epoch 4627, Loss: 220.18994140625, Neurons: 49, Grad norm: 8.186e+02\n",
      "Epoch 4627, Loss: 220.18994140625, Neurons: 49, Grad norm: 8.186e+02\n",
      "Epoch 4628, Loss: 216.08160400390625, Neurons: 49, Grad norm: 8.021e+02\n",
      "Epoch 4628, Loss: 216.08160400390625, Neurons: 49, Grad norm: 8.021e+02\n",
      "Epoch 4629, Loss: 212.02078247070312, Neurons: 49, Grad norm: 7.856e+02\n",
      "Epoch 4629, Loss: 212.02078247070312, Neurons: 49, Grad norm: 7.856e+02\n",
      "Epoch 4630, Loss: 208.0126495361328, Neurons: 49, Grad norm: 7.692e+02\n",
      "Epoch 4630, Loss: 208.0126495361328, Neurons: 49, Grad norm: 7.692e+02\n",
      "Epoch 4631, Loss: 204.0625457763672, Neurons: 49, Grad norm: 7.527e+02\n",
      "Epoch 4631, Loss: 204.0625457763672, Neurons: 49, Grad norm: 7.527e+02\n",
      "Epoch 4632, Loss: 200.17535400390625, Neurons: 49, Grad norm: 7.364e+02\n",
      "Epoch 4632, Loss: 200.17535400390625, Neurons: 49, Grad norm: 7.364e+02\n",
      "Epoch 4633, Loss: 196.35557556152344, Neurons: 49, Grad norm: 7.201e+02\n",
      "Epoch 4633, Loss: 196.35557556152344, Neurons: 49, Grad norm: 7.201e+02\n",
      "Epoch 4634, Loss: 192.6068878173828, Neurons: 49, Grad norm: 7.040e+02\n",
      "Epoch 4634, Loss: 192.6068878173828, Neurons: 49, Grad norm: 7.040e+02\n",
      "Epoch 4635, Loss: 188.9328155517578, Neurons: 49, Grad norm: 6.880e+02\n",
      "Epoch 4635, Loss: 188.9328155517578, Neurons: 49, Grad norm: 6.880e+02\n",
      "Epoch 4636, Loss: 185.33636474609375, Neurons: 49, Grad norm: 6.722e+02\n",
      "Epoch 4636, Loss: 185.33636474609375, Neurons: 49, Grad norm: 6.722e+02\n",
      "Epoch 4637, Loss: 181.82054138183594, Neurons: 49, Grad norm: 6.565e+02\n",
      "Epoch 4637, Loss: 181.82054138183594, Neurons: 49, Grad norm: 6.565e+02\n",
      "Epoch 4638, Loss: 178.387451171875, Neurons: 49, Grad norm: 6.411e+02\n",
      "Epoch 4638, Loss: 178.387451171875, Neurons: 49, Grad norm: 6.411e+02\n",
      "Epoch 4639, Loss: 175.03903198242188, Neurons: 49, Grad norm: 6.257e+02\n",
      "Epoch 4639, Loss: 175.03903198242188, Neurons: 49, Grad norm: 6.257e+02\n",
      "Epoch 4640, Loss: 171.77706909179688, Neurons: 49, Grad norm: 6.107e+02\n",
      "Epoch 4640, Loss: 171.77706909179688, Neurons: 49, Grad norm: 6.107e+02\n",
      "Epoch 4641, Loss: 168.60269165039062, Neurons: 49, Grad norm: 5.958e+02\n",
      "Epoch 4641, Loss: 168.60269165039062, Neurons: 49, Grad norm: 5.958e+02\n",
      "Epoch 4642, Loss: 165.51654052734375, Neurons: 49, Grad norm: 5.812e+02\n",
      "Epoch 4642, Loss: 165.51654052734375, Neurons: 49, Grad norm: 5.812e+02\n",
      "Epoch 4643, Loss: 162.5193328857422, Neurons: 49, Grad norm: 5.667e+02\n",
      "Epoch 4643, Loss: 162.5193328857422, Neurons: 49, Grad norm: 5.667e+02\n",
      "Epoch 4644, Loss: 159.6121826171875, Neurons: 49, Grad norm: 5.525e+02\n",
      "Epoch 4644, Loss: 159.6121826171875, Neurons: 49, Grad norm: 5.525e+02\n",
      "Epoch 4645, Loss: 156.795166015625, Neurons: 49, Grad norm: 5.385e+02\n",
      "Epoch 4645, Loss: 156.795166015625, Neurons: 49, Grad norm: 5.385e+02\n",
      "Epoch 4646, Loss: 154.06813049316406, Neurons: 49, Grad norm: 5.247e+02\n",
      "Epoch 4646, Loss: 154.06813049316406, Neurons: 49, Grad norm: 5.247e+02\n",
      "Epoch 4647, Loss: 151.430419921875, Neurons: 49, Grad norm: 5.110e+02\n",
      "Epoch 4647, Loss: 151.430419921875, Neurons: 49, Grad norm: 5.110e+02\n",
      "Epoch 4648, Loss: 148.88162231445312, Neurons: 49, Grad norm: 4.977e+02\n",
      "Epoch 4648, Loss: 148.88162231445312, Neurons: 49, Grad norm: 4.977e+02\n",
      "Epoch 4649, Loss: 146.42115783691406, Neurons: 49, Grad norm: 4.845e+02\n",
      "Epoch 4649, Loss: 146.42115783691406, Neurons: 49, Grad norm: 4.845e+02\n",
      "Epoch 4650, Loss: 144.04782104492188, Neurons: 49, Grad norm: 4.715e+02\n",
      "Epoch 4650, Loss: 144.04782104492188, Neurons: 49, Grad norm: 4.715e+02\n",
      "Epoch 4651, Loss: 141.76060485839844, Neurons: 49, Grad norm: 4.587e+02\n",
      "Epoch 4651, Loss: 141.76060485839844, Neurons: 49, Grad norm: 4.587e+02\n",
      "Epoch 4652, Loss: 139.55859375, Neurons: 49, Grad norm: 4.462e+02\n",
      "Epoch 4652, Loss: 139.55859375, Neurons: 49, Grad norm: 4.462e+02\n",
      "Epoch 4653, Loss: 137.4402618408203, Neurons: 49, Grad norm: 4.339e+02\n",
      "Epoch 4653, Loss: 137.4402618408203, Neurons: 49, Grad norm: 4.339e+02\n",
      "Epoch 4654, Loss: 135.40408325195312, Neurons: 49, Grad norm: 4.218e+02\n",
      "Epoch 4654, Loss: 135.40408325195312, Neurons: 49, Grad norm: 4.218e+02\n",
      "Epoch 4655, Loss: 133.44847106933594, Neurons: 49, Grad norm: 4.100e+02\n",
      "Epoch 4655, Loss: 133.44847106933594, Neurons: 49, Grad norm: 4.100e+02\n",
      "Epoch 4656, Loss: 131.5717315673828, Neurons: 49, Grad norm: 3.984e+02\n",
      "Epoch 4656, Loss: 131.5717315673828, Neurons: 49, Grad norm: 3.984e+02\n",
      "Epoch 4657, Loss: 129.77206420898438, Neurons: 49, Grad norm: 3.871e+02\n",
      "Epoch 4657, Loss: 129.77206420898438, Neurons: 49, Grad norm: 3.871e+02\n",
      "Epoch 4658, Loss: 128.0477294921875, Neurons: 49, Grad norm: 3.760e+02\n",
      "Epoch 4658, Loss: 128.0477294921875, Neurons: 49, Grad norm: 3.760e+02\n",
      "Epoch 4659, Loss: 126.39669036865234, Neurons: 49, Grad norm: 3.652e+02\n",
      "Epoch 4659, Loss: 126.39669036865234, Neurons: 49, Grad norm: 3.652e+02\n",
      "Epoch 4660, Loss: 124.81683349609375, Neurons: 49, Grad norm: 3.545e+02\n",
      "Epoch 4660, Loss: 124.81683349609375, Neurons: 49, Grad norm: 3.545e+02\n",
      "Epoch 4661, Loss: 123.30609893798828, Neurons: 49, Grad norm: 3.441e+02\n",
      "Epoch 4661, Loss: 123.30609893798828, Neurons: 49, Grad norm: 3.441e+02\n",
      "Epoch 4662, Loss: 121.86241149902344, Neurons: 49, Grad norm: 3.340e+02\n",
      "Epoch 4662, Loss: 121.86241149902344, Neurons: 49, Grad norm: 3.340e+02\n",
      "Epoch 4663, Loss: 120.48360443115234, Neurons: 49, Grad norm: 3.241e+02\n",
      "Epoch 4663, Loss: 120.48360443115234, Neurons: 49, Grad norm: 3.241e+02\n",
      "Epoch 4664, Loss: 119.16740417480469, Neurons: 49, Grad norm: 3.144e+02\n",
      "Epoch 4664, Loss: 119.16740417480469, Neurons: 49, Grad norm: 3.144e+02\n",
      "Epoch 4665, Loss: 117.91150665283203, Neurons: 49, Grad norm: 3.050e+02\n",
      "Epoch 4665, Loss: 117.91150665283203, Neurons: 49, Grad norm: 3.050e+02\n",
      "Epoch 4666, Loss: 116.71369934082031, Neurons: 49, Grad norm: 2.959e+02\n",
      "Epoch 4666, Loss: 116.71369934082031, Neurons: 49, Grad norm: 2.959e+02\n",
      "Epoch 4667, Loss: 115.57177734375, Neurons: 49, Grad norm: 2.870e+02\n",
      "Epoch 4667, Loss: 115.57177734375, Neurons: 49, Grad norm: 2.870e+02\n",
      "Epoch 4668, Loss: 114.48341369628906, Neurons: 49, Grad norm: 2.784e+02\n",
      "Epoch 4668, Loss: 114.48341369628906, Neurons: 49, Grad norm: 2.784e+02\n",
      "Epoch 4669, Loss: 113.44624328613281, Neurons: 49, Grad norm: 2.700e+02\n",
      "Epoch 4669, Loss: 113.44624328613281, Neurons: 49, Grad norm: 2.700e+02\n",
      "Epoch 4670, Loss: 112.4580078125, Neurons: 49, Grad norm: 2.619e+02\n",
      "Epoch 4670, Loss: 112.4580078125, Neurons: 49, Grad norm: 2.619e+02\n",
      "Epoch 4671, Loss: 111.51644134521484, Neurons: 49, Grad norm: 2.540e+02\n",
      "Epoch 4671, Loss: 111.51644134521484, Neurons: 49, Grad norm: 2.540e+02\n",
      "Epoch 4672, Loss: 110.61934661865234, Neurons: 49, Grad norm: 2.464e+02\n",
      "Epoch 4672, Loss: 110.61934661865234, Neurons: 49, Grad norm: 2.464e+02\n",
      "Epoch 4673, Loss: 109.7645492553711, Neurons: 49, Grad norm: 2.390e+02\n",
      "Epoch 4673, Loss: 109.7645492553711, Neurons: 49, Grad norm: 2.390e+02\n",
      "Epoch 4674, Loss: 108.95000457763672, Neurons: 49, Grad norm: 2.319e+02\n",
      "Epoch 4674, Loss: 108.95000457763672, Neurons: 49, Grad norm: 2.319e+02\n",
      "Epoch 4675, Loss: 108.17367553710938, Neurons: 49, Grad norm: 2.250e+02\n",
      "Epoch 4675, Loss: 108.17367553710938, Neurons: 49, Grad norm: 2.250e+02\n",
      "Epoch 4676, Loss: 107.4334945678711, Neurons: 49, Grad norm: 2.183e+02\n",
      "Epoch 4676, Loss: 107.4334945678711, Neurons: 49, Grad norm: 2.183e+02\n",
      "Epoch 4677, Loss: 106.72750854492188, Neurons: 49, Grad norm: 2.119e+02\n",
      "Epoch 4677, Loss: 106.72750854492188, Neurons: 49, Grad norm: 2.119e+02\n",
      "Epoch 4678, Loss: 106.05378723144531, Neurons: 49, Grad norm: 2.057e+02\n",
      "Epoch 4678, Loss: 106.05378723144531, Neurons: 49, Grad norm: 2.057e+02\n",
      "Epoch 4679, Loss: 105.41046142578125, Neurons: 49, Grad norm: 1.998e+02\n",
      "Epoch 4679, Loss: 105.41046142578125, Neurons: 49, Grad norm: 1.998e+02\n",
      "Epoch 4680, Loss: 104.79573059082031, Neurons: 49, Grad norm: 1.940e+02\n",
      "Epoch 4680, Loss: 104.79573059082031, Neurons: 49, Grad norm: 1.940e+02\n",
      "Epoch 4681, Loss: 104.20799255371094, Neurons: 49, Grad norm: 1.885e+02\n",
      "Epoch 4681, Loss: 104.20799255371094, Neurons: 49, Grad norm: 1.885e+02\n",
      "Epoch 4682, Loss: 103.6456298828125, Neurons: 49, Grad norm: 1.832e+02\n",
      "Epoch 4682, Loss: 103.6456298828125, Neurons: 49, Grad norm: 1.832e+02\n",
      "Epoch 4683, Loss: 103.10707092285156, Neurons: 49, Grad norm: 1.781e+02\n",
      "Epoch 4683, Loss: 103.10707092285156, Neurons: 49, Grad norm: 1.781e+02\n",
      "Epoch 4684, Loss: 102.59087371826172, Neurons: 49, Grad norm: 1.732e+02\n",
      "Epoch 4684, Loss: 102.59087371826172, Neurons: 49, Grad norm: 1.732e+02\n",
      "Epoch 4685, Loss: 102.09549713134766, Neurons: 49, Grad norm: 1.684e+02\n",
      "Epoch 4685, Loss: 102.09549713134766, Neurons: 49, Grad norm: 1.684e+02\n",
      "Epoch 4686, Loss: 101.61964416503906, Neurons: 49, Grad norm: 1.639e+02\n",
      "Epoch 4686, Loss: 101.61964416503906, Neurons: 49, Grad norm: 1.639e+02\n",
      "Epoch 4687, Loss: 101.16194152832031, Neurons: 49, Grad norm: 1.595e+02\n",
      "Epoch 4687, Loss: 101.16194152832031, Neurons: 49, Grad norm: 1.595e+02\n",
      "Epoch 4688, Loss: 100.72123718261719, Neurons: 49, Grad norm: 1.554e+02\n",
      "Epoch 4688, Loss: 100.72123718261719, Neurons: 49, Grad norm: 1.554e+02\n",
      "Epoch 4689, Loss: 100.2962875366211, Neurons: 49, Grad norm: 1.514e+02\n",
      "Epoch 4689, Loss: 100.2962875366211, Neurons: 49, Grad norm: 1.514e+02\n",
      "Epoch 4690, Loss: 99.88592529296875, Neurons: 49, Grad norm: 1.475e+02\n",
      "Epoch 4690, Loss: 99.88592529296875, Neurons: 49, Grad norm: 1.475e+02\n",
      "Epoch 4691, Loss: 99.4892578125, Neurons: 49, Grad norm: 1.438e+02\n",
      "Epoch 4691, Loss: 99.4892578125, Neurons: 49, Grad norm: 1.438e+02\n",
      "Epoch 4692, Loss: 99.10514068603516, Neurons: 49, Grad norm: 1.403e+02\n",
      "Epoch 4692, Loss: 99.10514068603516, Neurons: 49, Grad norm: 1.403e+02\n",
      "Epoch 4693, Loss: 98.73251342773438, Neurons: 49, Grad norm: 1.369e+02\n",
      "Epoch 4693, Loss: 98.73251342773438, Neurons: 49, Grad norm: 1.369e+02\n",
      "Epoch 4694, Loss: 98.3704833984375, Neurons: 49, Grad norm: 1.337e+02\n",
      "Epoch 4694, Loss: 98.3704833984375, Neurons: 49, Grad norm: 1.337e+02\n",
      "Epoch 4695, Loss: 98.01844787597656, Neurons: 49, Grad norm: 1.306e+02\n",
      "Epoch 4695, Loss: 98.01844787597656, Neurons: 49, Grad norm: 1.306e+02\n",
      "Epoch 4696, Loss: 97.6753158569336, Neurons: 49, Grad norm: 1.276e+02\n",
      "Epoch 4696, Loss: 97.6753158569336, Neurons: 49, Grad norm: 1.276e+02\n",
      "Epoch 4697, Loss: 97.34027862548828, Neurons: 49, Grad norm: 1.248e+02\n",
      "Epoch 4697, Loss: 97.34027862548828, Neurons: 49, Grad norm: 1.248e+02\n",
      "Epoch 4698, Loss: 97.01262664794922, Neurons: 49, Grad norm: 1.221e+02\n",
      "Epoch 4698, Loss: 97.01262664794922, Neurons: 49, Grad norm: 1.221e+02\n",
      "Epoch 4699, Loss: 96.69172668457031, Neurons: 49, Grad norm: 1.194e+02\n",
      "Epoch 4699, Loss: 96.69172668457031, Neurons: 49, Grad norm: 1.194e+02\n",
      "Epoch 4699, Test loss: 92.1059341430664\n",
      "Epoch 4699, Test loss: 92.1059341430664\n",
      "Removed neuron to hidden layer 1 at index 20\n",
      "Removed neuron to hidden layer 1 at index 20\n",
      "network shape updated to :[20, 27, 1]\n",
      "network shape updated to :[20, 27, 1]\n",
      "Epoch 4700, Loss: 156.11988830566406, Neurons: 48, Grad norm: 4.242e+02\n",
      "Epoch 4700, Loss: 156.11988830566406, Neurons: 48, Grad norm: 4.242e+02\n",
      "Epoch 4701, Loss: 154.8980255126953, Neurons: 48, Grad norm: 4.166e+02\n",
      "Epoch 4701, Loss: 154.8980255126953, Neurons: 48, Grad norm: 4.166e+02\n",
      "Epoch 4702, Loss: 153.63272094726562, Neurons: 48, Grad norm: 4.098e+02\n",
      "Epoch 4702, Loss: 153.63272094726562, Neurons: 48, Grad norm: 4.098e+02\n",
      "Epoch 4703, Loss: 152.3253936767578, Neurons: 48, Grad norm: 4.030e+02\n",
      "Epoch 4703, Loss: 152.3253936767578, Neurons: 48, Grad norm: 4.030e+02\n",
      "Epoch 4704, Loss: 150.9805450439453, Neurons: 48, Grad norm: 3.957e+02\n",
      "Epoch 4704, Loss: 150.9805450439453, Neurons: 48, Grad norm: 3.957e+02\n",
      "Epoch 4705, Loss: 149.6012725830078, Neurons: 48, Grad norm: 3.879e+02\n",
      "Epoch 4705, Loss: 149.6012725830078, Neurons: 48, Grad norm: 3.879e+02\n",
      "Epoch 4706, Loss: 148.1904754638672, Neurons: 48, Grad norm: 3.798e+02\n",
      "Epoch 4706, Loss: 148.1904754638672, Neurons: 48, Grad norm: 3.798e+02\n",
      "Epoch 4707, Loss: 146.75242614746094, Neurons: 48, Grad norm: 3.717e+02\n",
      "Epoch 4707, Loss: 146.75242614746094, Neurons: 48, Grad norm: 3.717e+02\n",
      "Epoch 4708, Loss: 145.2908477783203, Neurons: 48, Grad norm: 3.635e+02\n",
      "Epoch 4708, Loss: 145.2908477783203, Neurons: 48, Grad norm: 3.635e+02\n",
      "Epoch 4709, Loss: 143.80909729003906, Neurons: 48, Grad norm: 3.555e+02\n",
      "Epoch 4709, Loss: 143.80909729003906, Neurons: 48, Grad norm: 3.555e+02\n",
      "Epoch 4710, Loss: 142.3109588623047, Neurons: 48, Grad norm: 3.474e+02\n",
      "Epoch 4710, Loss: 142.3109588623047, Neurons: 48, Grad norm: 3.474e+02\n",
      "Epoch 4711, Loss: 140.800537109375, Neurons: 48, Grad norm: 3.394e+02\n",
      "Epoch 4711, Loss: 140.800537109375, Neurons: 48, Grad norm: 3.394e+02\n",
      "Epoch 4712, Loss: 139.28199768066406, Neurons: 48, Grad norm: 3.313e+02\n",
      "Epoch 4712, Loss: 139.28199768066406, Neurons: 48, Grad norm: 3.313e+02\n",
      "Epoch 4713, Loss: 137.75912475585938, Neurons: 48, Grad norm: 3.233e+02\n",
      "Epoch 4713, Loss: 137.75912475585938, Neurons: 48, Grad norm: 3.233e+02\n",
      "Epoch 4714, Loss: 136.23599243164062, Neurons: 48, Grad norm: 3.152e+02\n",
      "Epoch 4714, Loss: 136.23599243164062, Neurons: 48, Grad norm: 3.152e+02\n",
      "Epoch 4715, Loss: 134.71688842773438, Neurons: 48, Grad norm: 3.072e+02\n",
      "Epoch 4715, Loss: 134.71688842773438, Neurons: 48, Grad norm: 3.072e+02\n",
      "Epoch 4716, Loss: 133.20594787597656, Neurons: 48, Grad norm: 2.993e+02\n",
      "Epoch 4716, Loss: 133.20594787597656, Neurons: 48, Grad norm: 2.993e+02\n",
      "Epoch 4717, Loss: 131.70672607421875, Neurons: 48, Grad norm: 2.915e+02\n",
      "Epoch 4717, Loss: 131.70672607421875, Neurons: 48, Grad norm: 2.915e+02\n",
      "Epoch 4718, Loss: 130.22293090820312, Neurons: 48, Grad norm: 2.838e+02\n",
      "Epoch 4718, Loss: 130.22293090820312, Neurons: 48, Grad norm: 2.838e+02\n",
      "Epoch 4719, Loss: 128.75794982910156, Neurons: 48, Grad norm: 2.763e+02\n",
      "Epoch 4719, Loss: 128.75794982910156, Neurons: 48, Grad norm: 2.763e+02\n",
      "Epoch 4720, Loss: 127.31488800048828, Neurons: 48, Grad norm: 2.689e+02\n",
      "Epoch 4720, Loss: 127.31488800048828, Neurons: 48, Grad norm: 2.689e+02\n",
      "Epoch 4721, Loss: 125.89640808105469, Neurons: 48, Grad norm: 2.616e+02\n",
      "Epoch 4721, Loss: 125.89640808105469, Neurons: 48, Grad norm: 2.616e+02\n",
      "Epoch 4722, Loss: 124.50492858886719, Neurons: 48, Grad norm: 2.544e+02\n",
      "Epoch 4722, Loss: 124.50492858886719, Neurons: 48, Grad norm: 2.544e+02\n",
      "Epoch 4723, Loss: 123.14260864257812, Neurons: 48, Grad norm: 2.474e+02\n",
      "Epoch 4723, Loss: 123.14260864257812, Neurons: 48, Grad norm: 2.474e+02\n",
      "Epoch 4724, Loss: 121.81121826171875, Neurons: 48, Grad norm: 2.407e+02\n",
      "Epoch 4724, Loss: 121.81121826171875, Neurons: 48, Grad norm: 2.407e+02\n",
      "Epoch 4725, Loss: 120.51225280761719, Neurons: 48, Grad norm: 2.341e+02\n",
      "Epoch 4725, Loss: 120.51225280761719, Neurons: 48, Grad norm: 2.341e+02\n",
      "Epoch 4726, Loss: 119.24678039550781, Neurons: 48, Grad norm: 2.277e+02\n",
      "Epoch 4726, Loss: 119.24678039550781, Neurons: 48, Grad norm: 2.277e+02\n",
      "Epoch 4727, Loss: 118.01567840576172, Neurons: 48, Grad norm: 2.216e+02\n",
      "Epoch 4727, Loss: 118.01567840576172, Neurons: 48, Grad norm: 2.216e+02\n",
      "Epoch 4728, Loss: 116.81964111328125, Neurons: 48, Grad norm: 2.155e+02\n",
      "Epoch 4728, Loss: 116.81964111328125, Neurons: 48, Grad norm: 2.155e+02\n",
      "Epoch 4729, Loss: 115.6589584350586, Neurons: 48, Grad norm: 2.096e+02\n",
      "Epoch 4729, Loss: 115.6589584350586, Neurons: 48, Grad norm: 2.096e+02\n",
      "Epoch 4730, Loss: 114.53384399414062, Neurons: 48, Grad norm: 2.039e+02\n",
      "Epoch 4730, Loss: 114.53384399414062, Neurons: 48, Grad norm: 2.039e+02\n",
      "Epoch 4731, Loss: 113.44432067871094, Neurons: 48, Grad norm: 1.983e+02\n",
      "Epoch 4731, Loss: 113.44432067871094, Neurons: 48, Grad norm: 1.983e+02\n",
      "Epoch 4732, Loss: 112.3903579711914, Neurons: 48, Grad norm: 1.930e+02\n",
      "Epoch 4732, Loss: 112.3903579711914, Neurons: 48, Grad norm: 1.930e+02\n",
      "Epoch 4733, Loss: 111.37159729003906, Neurons: 48, Grad norm: 1.877e+02\n",
      "Epoch 4733, Loss: 111.37159729003906, Neurons: 48, Grad norm: 1.877e+02\n",
      "Epoch 4734, Loss: 110.38777160644531, Neurons: 48, Grad norm: 1.826e+02\n",
      "Epoch 4734, Loss: 110.38777160644531, Neurons: 48, Grad norm: 1.826e+02\n",
      "Epoch 4735, Loss: 109.43851470947266, Neurons: 48, Grad norm: 1.776e+02\n",
      "Epoch 4735, Loss: 109.43851470947266, Neurons: 48, Grad norm: 1.776e+02\n",
      "Epoch 4736, Loss: 108.52333068847656, Neurons: 48, Grad norm: 1.728e+02\n",
      "Epoch 4736, Loss: 108.52333068847656, Neurons: 48, Grad norm: 1.728e+02\n",
      "Epoch 4737, Loss: 107.64176940917969, Neurons: 48, Grad norm: 1.680e+02\n",
      "Epoch 4737, Loss: 107.64176940917969, Neurons: 48, Grad norm: 1.680e+02\n",
      "Epoch 4738, Loss: 106.79325103759766, Neurons: 48, Grad norm: 1.633e+02\n",
      "Epoch 4738, Loss: 106.79325103759766, Neurons: 48, Grad norm: 1.633e+02\n",
      "Epoch 4739, Loss: 105.97730255126953, Neurons: 48, Grad norm: 1.588e+02\n",
      "Epoch 4739, Loss: 105.97730255126953, Neurons: 48, Grad norm: 1.588e+02\n",
      "Epoch 4740, Loss: 105.19335174560547, Neurons: 48, Grad norm: 1.543e+02\n",
      "Epoch 4740, Loss: 105.19335174560547, Neurons: 48, Grad norm: 1.543e+02\n",
      "Epoch 4741, Loss: 104.44084930419922, Neurons: 48, Grad norm: 1.499e+02\n",
      "Epoch 4741, Loss: 104.44084930419922, Neurons: 48, Grad norm: 1.499e+02\n",
      "Epoch 4742, Loss: 103.71915435791016, Neurons: 48, Grad norm: 1.457e+02\n",
      "Epoch 4742, Loss: 103.71915435791016, Neurons: 48, Grad norm: 1.457e+02\n",
      "Epoch 4743, Loss: 103.02766418457031, Neurons: 48, Grad norm: 1.416e+02\n",
      "Epoch 4743, Loss: 103.02766418457031, Neurons: 48, Grad norm: 1.416e+02\n",
      "Epoch 4744, Loss: 102.36543273925781, Neurons: 48, Grad norm: 1.376e+02\n",
      "Epoch 4744, Loss: 102.36543273925781, Neurons: 48, Grad norm: 1.376e+02\n",
      "Epoch 4745, Loss: 101.73180389404297, Neurons: 48, Grad norm: 1.338e+02\n",
      "Epoch 4745, Loss: 101.73180389404297, Neurons: 48, Grad norm: 1.338e+02\n",
      "Epoch 4746, Loss: 101.12596130371094, Neurons: 48, Grad norm: 1.300e+02\n",
      "Epoch 4746, Loss: 101.12596130371094, Neurons: 48, Grad norm: 1.300e+02\n",
      "Epoch 4747, Loss: 100.54705047607422, Neurons: 48, Grad norm: 1.264e+02\n",
      "Epoch 4747, Loss: 100.54705047607422, Neurons: 48, Grad norm: 1.264e+02\n",
      "Epoch 4748, Loss: 99.99425506591797, Neurons: 48, Grad norm: 1.229e+02\n",
      "Epoch 4748, Loss: 99.99425506591797, Neurons: 48, Grad norm: 1.229e+02\n",
      "Epoch 4749, Loss: 99.46656036376953, Neurons: 48, Grad norm: 1.196e+02\n",
      "Epoch 4749, Loss: 99.46656036376953, Neurons: 48, Grad norm: 1.196e+02\n",
      "Epoch 4750, Loss: 98.96306610107422, Neurons: 48, Grad norm: 1.165e+02\n",
      "Epoch 4750, Loss: 98.96306610107422, Neurons: 48, Grad norm: 1.165e+02\n",
      "Epoch 4751, Loss: 98.48265838623047, Neurons: 48, Grad norm: 1.134e+02\n",
      "Epoch 4751, Loss: 98.48265838623047, Neurons: 48, Grad norm: 1.134e+02\n",
      "Epoch 4752, Loss: 98.02430725097656, Neurons: 48, Grad norm: 1.105e+02\n",
      "Epoch 4752, Loss: 98.02430725097656, Neurons: 48, Grad norm: 1.105e+02\n",
      "Epoch 4753, Loss: 97.58699035644531, Neurons: 48, Grad norm: 1.077e+02\n",
      "Epoch 4753, Loss: 97.58699035644531, Neurons: 48, Grad norm: 1.077e+02\n",
      "Epoch 4754, Loss: 97.1695327758789, Neurons: 48, Grad norm: 1.050e+02\n",
      "Epoch 4754, Loss: 97.1695327758789, Neurons: 48, Grad norm: 1.050e+02\n",
      "Epoch 4755, Loss: 96.77093505859375, Neurons: 48, Grad norm: 1.024e+02\n",
      "Epoch 4755, Loss: 96.77093505859375, Neurons: 48, Grad norm: 1.024e+02\n",
      "Epoch 4756, Loss: 96.39008331298828, Neurons: 48, Grad norm: 1.000e+02\n",
      "Epoch 4756, Loss: 96.39008331298828, Neurons: 48, Grad norm: 1.000e+02\n",
      "Epoch 4757, Loss: 96.02592468261719, Neurons: 48, Grad norm: 9.762e+01\n",
      "Epoch 4757, Loss: 96.02592468261719, Neurons: 48, Grad norm: 9.762e+01\n",
      "Epoch 4758, Loss: 95.67740631103516, Neurons: 48, Grad norm: 9.534e+01\n",
      "Epoch 4758, Loss: 95.67740631103516, Neurons: 48, Grad norm: 9.534e+01\n",
      "Epoch 4759, Loss: 95.34352111816406, Neurons: 48, Grad norm: 9.315e+01\n",
      "Epoch 4759, Loss: 95.34352111816406, Neurons: 48, Grad norm: 9.315e+01\n",
      "Epoch 4760, Loss: 95.02326965332031, Neurons: 48, Grad norm: 9.109e+01\n",
      "Epoch 4760, Loss: 95.02326965332031, Neurons: 48, Grad norm: 9.109e+01\n",
      "Epoch 4761, Loss: 94.7156753540039, Neurons: 48, Grad norm: 8.913e+01\n",
      "Epoch 4761, Loss: 94.7156753540039, Neurons: 48, Grad norm: 8.913e+01\n",
      "Epoch 4762, Loss: 94.4197998046875, Neurons: 48, Grad norm: 8.722e+01\n",
      "Epoch 4762, Loss: 94.4197998046875, Neurons: 48, Grad norm: 8.722e+01\n",
      "Epoch 4763, Loss: 94.13478088378906, Neurons: 48, Grad norm: 8.538e+01\n",
      "Epoch 4763, Loss: 94.13478088378906, Neurons: 48, Grad norm: 8.538e+01\n",
      "Epoch 4764, Loss: 93.85980224609375, Neurons: 48, Grad norm: 8.363e+01\n",
      "Epoch 4764, Loss: 93.85980224609375, Neurons: 48, Grad norm: 8.363e+01\n",
      "Epoch 4765, Loss: 93.59402465820312, Neurons: 48, Grad norm: 8.188e+01\n",
      "Epoch 4765, Loss: 93.59402465820312, Neurons: 48, Grad norm: 8.188e+01\n",
      "Epoch 4766, Loss: 93.33670806884766, Neurons: 48, Grad norm: 8.020e+01\n",
      "Epoch 4766, Loss: 93.33670806884766, Neurons: 48, Grad norm: 8.020e+01\n",
      "Epoch 4767, Loss: 93.087158203125, Neurons: 48, Grad norm: 7.854e+01\n",
      "Epoch 4767, Loss: 93.087158203125, Neurons: 48, Grad norm: 7.854e+01\n",
      "Epoch 4768, Loss: 92.84467315673828, Neurons: 48, Grad norm: 7.693e+01\n",
      "Epoch 4768, Loss: 92.84467315673828, Neurons: 48, Grad norm: 7.693e+01\n",
      "Epoch 4769, Loss: 92.60871887207031, Neurons: 48, Grad norm: 7.544e+01\n",
      "Epoch 4769, Loss: 92.60871887207031, Neurons: 48, Grad norm: 7.544e+01\n",
      "Epoch 4770, Loss: 92.37863159179688, Neurons: 48, Grad norm: 7.399e+01\n",
      "Epoch 4770, Loss: 92.37863159179688, Neurons: 48, Grad norm: 7.399e+01\n",
      "Epoch 4771, Loss: 92.15386962890625, Neurons: 48, Grad norm: 7.251e+01\n",
      "Epoch 4771, Loss: 92.15386962890625, Neurons: 48, Grad norm: 7.251e+01\n",
      "Epoch 4772, Loss: 91.93391418457031, Neurons: 48, Grad norm: 7.106e+01\n",
      "Epoch 4772, Loss: 91.93391418457031, Neurons: 48, Grad norm: 7.106e+01\n",
      "Epoch 4773, Loss: 91.71831512451172, Neurons: 48, Grad norm: 6.967e+01\n",
      "Epoch 4773, Loss: 91.71831512451172, Neurons: 48, Grad norm: 6.967e+01\n",
      "Epoch 4774, Loss: 91.50662231445312, Neurons: 48, Grad norm: 6.828e+01\n",
      "Epoch 4774, Loss: 91.50662231445312, Neurons: 48, Grad norm: 6.828e+01\n",
      "Epoch 4775, Loss: 91.29841613769531, Neurons: 48, Grad norm: 6.696e+01\n",
      "Epoch 4775, Loss: 91.29841613769531, Neurons: 48, Grad norm: 6.696e+01\n",
      "Epoch 4776, Loss: 91.09331512451172, Neurons: 48, Grad norm: 6.567e+01\n",
      "Epoch 4776, Loss: 91.09331512451172, Neurons: 48, Grad norm: 6.567e+01\n",
      "Epoch 4777, Loss: 90.89093780517578, Neurons: 48, Grad norm: 6.443e+01\n",
      "Epoch 4777, Loss: 90.89093780517578, Neurons: 48, Grad norm: 6.443e+01\n",
      "Epoch 4778, Loss: 90.69091796875, Neurons: 48, Grad norm: 6.324e+01\n",
      "Epoch 4778, Loss: 90.69091796875, Neurons: 48, Grad norm: 6.324e+01\n",
      "Epoch 4779, Loss: 90.49295043945312, Neurons: 48, Grad norm: 6.204e+01\n",
      "Epoch 4779, Loss: 90.49295043945312, Neurons: 48, Grad norm: 6.204e+01\n",
      "Epoch 4780, Loss: 90.29671478271484, Neurons: 48, Grad norm: 6.090e+01\n",
      "Epoch 4780, Loss: 90.29671478271484, Neurons: 48, Grad norm: 6.090e+01\n",
      "Epoch 4781, Loss: 90.10195922851562, Neurons: 48, Grad norm: 5.982e+01\n",
      "Epoch 4781, Loss: 90.10195922851562, Neurons: 48, Grad norm: 5.982e+01\n",
      "Epoch 4782, Loss: 89.90840911865234, Neurons: 48, Grad norm: 5.876e+01\n",
      "Epoch 4782, Loss: 89.90840911865234, Neurons: 48, Grad norm: 5.876e+01\n",
      "Epoch 4783, Loss: 89.71583557128906, Neurons: 48, Grad norm: 5.769e+01\n",
      "Epoch 4783, Loss: 89.71583557128906, Neurons: 48, Grad norm: 5.769e+01\n",
      "Epoch 4784, Loss: 89.52403259277344, Neurons: 48, Grad norm: 5.665e+01\n",
      "Epoch 4784, Loss: 89.52403259277344, Neurons: 48, Grad norm: 5.665e+01\n",
      "Epoch 4785, Loss: 89.3327865600586, Neurons: 48, Grad norm: 5.564e+01\n",
      "Epoch 4785, Loss: 89.3327865600586, Neurons: 48, Grad norm: 5.564e+01\n",
      "Epoch 4786, Loss: 89.14190673828125, Neurons: 48, Grad norm: 5.468e+01\n",
      "Epoch 4786, Loss: 89.14190673828125, Neurons: 48, Grad norm: 5.468e+01\n",
      "Epoch 4787, Loss: 88.95125579833984, Neurons: 48, Grad norm: 5.374e+01\n",
      "Epoch 4787, Loss: 88.95125579833984, Neurons: 48, Grad norm: 5.374e+01\n",
      "Epoch 4788, Loss: 88.7606201171875, Neurons: 48, Grad norm: 5.286e+01\n",
      "Epoch 4788, Loss: 88.7606201171875, Neurons: 48, Grad norm: 5.286e+01\n",
      "Epoch 4789, Loss: 88.56987762451172, Neurons: 48, Grad norm: 5.197e+01\n",
      "Epoch 4789, Loss: 88.56987762451172, Neurons: 48, Grad norm: 5.197e+01\n",
      "Epoch 4790, Loss: 88.37892150878906, Neurons: 48, Grad norm: 5.112e+01\n",
      "Epoch 4790, Loss: 88.37892150878906, Neurons: 48, Grad norm: 5.112e+01\n",
      "Epoch 4791, Loss: 88.18760681152344, Neurons: 48, Grad norm: 5.030e+01\n",
      "Epoch 4791, Loss: 88.18760681152344, Neurons: 48, Grad norm: 5.030e+01\n",
      "Epoch 4792, Loss: 87.99585723876953, Neurons: 48, Grad norm: 4.950e+01\n",
      "Epoch 4792, Loss: 87.99585723876953, Neurons: 48, Grad norm: 4.950e+01\n",
      "Epoch 4793, Loss: 87.80355072021484, Neurons: 48, Grad norm: 4.873e+01\n",
      "Epoch 4793, Loss: 87.80355072021484, Neurons: 48, Grad norm: 4.873e+01\n",
      "Epoch 4794, Loss: 87.6106185913086, Neurons: 48, Grad norm: 4.796e+01\n",
      "Epoch 4794, Loss: 87.6106185913086, Neurons: 48, Grad norm: 4.796e+01\n",
      "Epoch 4795, Loss: 87.41705322265625, Neurons: 48, Grad norm: 4.721e+01\n",
      "Epoch 4795, Loss: 87.41705322265625, Neurons: 48, Grad norm: 4.721e+01\n",
      "Epoch 4796, Loss: 87.22289276123047, Neurons: 48, Grad norm: 4.648e+01\n",
      "Epoch 4796, Loss: 87.22289276123047, Neurons: 48, Grad norm: 4.648e+01\n",
      "Epoch 4797, Loss: 87.02812194824219, Neurons: 48, Grad norm: 4.569e+01\n",
      "Epoch 4797, Loss: 87.02812194824219, Neurons: 48, Grad norm: 4.569e+01\n",
      "Epoch 4798, Loss: 86.83283996582031, Neurons: 48, Grad norm: 4.488e+01\n",
      "Epoch 4798, Loss: 86.83283996582031, Neurons: 48, Grad norm: 4.488e+01\n",
      "Epoch 4799, Loss: 86.63716125488281, Neurons: 48, Grad norm: 4.415e+01\n",
      "Epoch 4799, Loss: 86.63716125488281, Neurons: 48, Grad norm: 4.415e+01\n",
      "Epoch 4799, Test loss: 82.43829345703125\n",
      "Epoch 4799, Test loss: 82.43829345703125\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "network shape updated to :[20, 28, 1]\n",
      "network shape updated to :[20, 28, 1]\n",
      "Epoch 4800, Loss: 86.46710205078125, Neurons: 49, Grad norm: 4.940e+01\n",
      "Epoch 4800, Loss: 86.46710205078125, Neurons: 49, Grad norm: 4.940e+01\n",
      "Epoch 4801, Loss: 86.32780456542969, Neurons: 49, Grad norm: 4.635e+01\n",
      "Epoch 4801, Loss: 86.32780456542969, Neurons: 49, Grad norm: 4.635e+01\n",
      "Epoch 4802, Loss: 86.18698120117188, Neurons: 49, Grad norm: 4.366e+01\n",
      "Epoch 4802, Loss: 86.18698120117188, Neurons: 49, Grad norm: 4.366e+01\n",
      "Epoch 4803, Loss: 86.0464859008789, Neurons: 49, Grad norm: 4.125e+01\n",
      "Epoch 4803, Loss: 86.0464859008789, Neurons: 49, Grad norm: 4.125e+01\n",
      "Epoch 4804, Loss: 85.90564727783203, Neurons: 49, Grad norm: 3.916e+01\n",
      "Epoch 4804, Loss: 85.90564727783203, Neurons: 49, Grad norm: 3.916e+01\n",
      "Epoch 4805, Loss: 85.7649917602539, Neurons: 49, Grad norm: 3.734e+01\n",
      "Epoch 4805, Loss: 85.7649917602539, Neurons: 49, Grad norm: 3.734e+01\n",
      "Epoch 4806, Loss: 85.62504577636719, Neurons: 49, Grad norm: 3.568e+01\n",
      "Epoch 4806, Loss: 85.62504577636719, Neurons: 49, Grad norm: 3.568e+01\n",
      "Epoch 4807, Loss: 85.48561096191406, Neurons: 49, Grad norm: 3.412e+01\n",
      "Epoch 4807, Loss: 85.48561096191406, Neurons: 49, Grad norm: 3.412e+01\n",
      "Epoch 4808, Loss: 85.34712982177734, Neurons: 49, Grad norm: 3.263e+01\n",
      "Epoch 4808, Loss: 85.34712982177734, Neurons: 49, Grad norm: 3.263e+01\n",
      "Epoch 4809, Loss: 85.21001434326172, Neurons: 49, Grad norm: 3.129e+01\n",
      "Epoch 4809, Loss: 85.21001434326172, Neurons: 49, Grad norm: 3.129e+01\n",
      "Epoch 4810, Loss: 85.0745849609375, Neurons: 49, Grad norm: 3.006e+01\n",
      "Epoch 4810, Loss: 85.0745849609375, Neurons: 49, Grad norm: 3.006e+01\n",
      "Epoch 4811, Loss: 84.94100952148438, Neurons: 49, Grad norm: 2.899e+01\n",
      "Epoch 4811, Loss: 84.94100952148438, Neurons: 49, Grad norm: 2.899e+01\n",
      "Epoch 4812, Loss: 84.80948638916016, Neurons: 49, Grad norm: 2.804e+01\n",
      "Epoch 4812, Loss: 84.80948638916016, Neurons: 49, Grad norm: 2.804e+01\n",
      "Epoch 4813, Loss: 84.68013000488281, Neurons: 49, Grad norm: 2.719e+01\n",
      "Epoch 4813, Loss: 84.68013000488281, Neurons: 49, Grad norm: 2.719e+01\n",
      "Epoch 4814, Loss: 84.55280303955078, Neurons: 49, Grad norm: 2.639e+01\n",
      "Epoch 4814, Loss: 84.55280303955078, Neurons: 49, Grad norm: 2.639e+01\n",
      "Epoch 4815, Loss: 84.4273452758789, Neurons: 49, Grad norm: 2.559e+01\n",
      "Epoch 4815, Loss: 84.4273452758789, Neurons: 49, Grad norm: 2.559e+01\n",
      "Epoch 4816, Loss: 84.30355834960938, Neurons: 49, Grad norm: 2.479e+01\n",
      "Epoch 4816, Loss: 84.30355834960938, Neurons: 49, Grad norm: 2.479e+01\n",
      "Epoch 4817, Loss: 84.18128967285156, Neurons: 49, Grad norm: 2.405e+01\n",
      "Epoch 4817, Loss: 84.18128967285156, Neurons: 49, Grad norm: 2.405e+01\n",
      "Epoch 4818, Loss: 84.06050109863281, Neurons: 49, Grad norm: 2.342e+01\n",
      "Epoch 4818, Loss: 84.06050109863281, Neurons: 49, Grad norm: 2.342e+01\n",
      "Epoch 4819, Loss: 83.94111633300781, Neurons: 49, Grad norm: 2.288e+01\n",
      "Epoch 4819, Loss: 83.94111633300781, Neurons: 49, Grad norm: 2.288e+01\n",
      "Epoch 4820, Loss: 83.82305908203125, Neurons: 49, Grad norm: 2.242e+01\n",
      "Epoch 4820, Loss: 83.82305908203125, Neurons: 49, Grad norm: 2.242e+01\n",
      "Epoch 4821, Loss: 83.70630645751953, Neurons: 49, Grad norm: 2.205e+01\n",
      "Epoch 4821, Loss: 83.70630645751953, Neurons: 49, Grad norm: 2.205e+01\n",
      "Epoch 4822, Loss: 83.5907974243164, Neurons: 49, Grad norm: 2.179e+01\n",
      "Epoch 4822, Loss: 83.5907974243164, Neurons: 49, Grad norm: 2.179e+01\n",
      "Epoch 4823, Loss: 83.47637939453125, Neurons: 49, Grad norm: 2.166e+01\n",
      "Epoch 4823, Loss: 83.47637939453125, Neurons: 49, Grad norm: 2.166e+01\n",
      "Epoch 4824, Loss: 83.36290740966797, Neurons: 49, Grad norm: 2.160e+01\n",
      "Epoch 4824, Loss: 83.36290740966797, Neurons: 49, Grad norm: 2.160e+01\n",
      "Epoch 4825, Loss: 83.2502212524414, Neurons: 49, Grad norm: 2.152e+01\n",
      "Epoch 4825, Loss: 83.2502212524414, Neurons: 49, Grad norm: 2.152e+01\n",
      "Epoch 4826, Loss: 83.13815307617188, Neurons: 49, Grad norm: 2.146e+01\n",
      "Epoch 4826, Loss: 83.13815307617188, Neurons: 49, Grad norm: 2.146e+01\n",
      "Epoch 4827, Loss: 83.02658081054688, Neurons: 49, Grad norm: 2.136e+01\n",
      "Epoch 4827, Loss: 83.02658081054688, Neurons: 49, Grad norm: 2.136e+01\n",
      "Epoch 4828, Loss: 82.915283203125, Neurons: 49, Grad norm: 2.122e+01\n",
      "Epoch 4828, Loss: 82.915283203125, Neurons: 49, Grad norm: 2.122e+01\n",
      "Epoch 4829, Loss: 82.80419158935547, Neurons: 49, Grad norm: 2.104e+01\n",
      "Epoch 4829, Loss: 82.80419158935547, Neurons: 49, Grad norm: 2.104e+01\n",
      "Epoch 4830, Loss: 82.69316101074219, Neurons: 49, Grad norm: 2.086e+01\n",
      "Epoch 4830, Loss: 82.69316101074219, Neurons: 49, Grad norm: 2.086e+01\n",
      "Epoch 4831, Loss: 82.58211517333984, Neurons: 49, Grad norm: 2.070e+01\n",
      "Epoch 4831, Loss: 82.58211517333984, Neurons: 49, Grad norm: 2.070e+01\n",
      "Epoch 4832, Loss: 82.47099304199219, Neurons: 49, Grad norm: 2.058e+01\n",
      "Epoch 4832, Loss: 82.47099304199219, Neurons: 49, Grad norm: 2.058e+01\n",
      "Epoch 4833, Loss: 82.35972595214844, Neurons: 49, Grad norm: 2.041e+01\n",
      "Epoch 4833, Loss: 82.35972595214844, Neurons: 49, Grad norm: 2.041e+01\n",
      "Epoch 4834, Loss: 82.2482681274414, Neurons: 49, Grad norm: 2.015e+01\n",
      "Epoch 4834, Loss: 82.2482681274414, Neurons: 49, Grad norm: 2.015e+01\n",
      "Epoch 4835, Loss: 82.13661193847656, Neurons: 49, Grad norm: 1.984e+01\n",
      "Epoch 4835, Loss: 82.13661193847656, Neurons: 49, Grad norm: 1.984e+01\n",
      "Epoch 4836, Loss: 82.02468872070312, Neurons: 49, Grad norm: 1.958e+01\n",
      "Epoch 4836, Loss: 82.02468872070312, Neurons: 49, Grad norm: 1.958e+01\n",
      "Epoch 4837, Loss: 81.91250610351562, Neurons: 49, Grad norm: 1.945e+01\n",
      "Epoch 4837, Loss: 81.91250610351562, Neurons: 49, Grad norm: 1.945e+01\n",
      "Epoch 4838, Loss: 81.79999542236328, Neurons: 49, Grad norm: 1.939e+01\n",
      "Epoch 4838, Loss: 81.79999542236328, Neurons: 49, Grad norm: 1.939e+01\n",
      "Epoch 4839, Loss: 81.68718719482422, Neurons: 49, Grad norm: 1.931e+01\n",
      "Epoch 4839, Loss: 81.68718719482422, Neurons: 49, Grad norm: 1.931e+01\n",
      "Epoch 4840, Loss: 81.5740737915039, Neurons: 49, Grad norm: 1.914e+01\n",
      "Epoch 4840, Loss: 81.5740737915039, Neurons: 49, Grad norm: 1.914e+01\n",
      "Epoch 4841, Loss: 81.46060943603516, Neurons: 49, Grad norm: 1.894e+01\n",
      "Epoch 4841, Loss: 81.46060943603516, Neurons: 49, Grad norm: 1.894e+01\n",
      "Epoch 4842, Loss: 81.34679412841797, Neurons: 49, Grad norm: 1.882e+01\n",
      "Epoch 4842, Loss: 81.34679412841797, Neurons: 49, Grad norm: 1.882e+01\n",
      "Epoch 4843, Loss: 81.23262786865234, Neurons: 49, Grad norm: 1.878e+01\n",
      "Epoch 4843, Loss: 81.23262786865234, Neurons: 49, Grad norm: 1.878e+01\n",
      "Epoch 4844, Loss: 81.11805725097656, Neurons: 49, Grad norm: 1.876e+01\n",
      "Epoch 4844, Loss: 81.11805725097656, Neurons: 49, Grad norm: 1.876e+01\n",
      "Epoch 4845, Loss: 81.00311279296875, Neurons: 49, Grad norm: 1.865e+01\n",
      "Epoch 4845, Loss: 81.00311279296875, Neurons: 49, Grad norm: 1.865e+01\n",
      "Epoch 4846, Loss: 80.88772583007812, Neurons: 49, Grad norm: 1.849e+01\n",
      "Epoch 4846, Loss: 80.88772583007812, Neurons: 49, Grad norm: 1.849e+01\n",
      "Epoch 4847, Loss: 80.77192687988281, Neurons: 49, Grad norm: 1.833e+01\n",
      "Epoch 4847, Loss: 80.77192687988281, Neurons: 49, Grad norm: 1.833e+01\n",
      "Epoch 4848, Loss: 80.65571594238281, Neurons: 49, Grad norm: 1.820e+01\n",
      "Epoch 4848, Loss: 80.65571594238281, Neurons: 49, Grad norm: 1.820e+01\n",
      "Epoch 4849, Loss: 80.53904724121094, Neurons: 49, Grad norm: 1.810e+01\n",
      "Epoch 4849, Loss: 80.53904724121094, Neurons: 49, Grad norm: 1.810e+01\n",
      "Epoch 4850, Loss: 80.42198944091797, Neurons: 49, Grad norm: 1.797e+01\n",
      "Epoch 4850, Loss: 80.42198944091797, Neurons: 49, Grad norm: 1.797e+01\n",
      "Epoch 4851, Loss: 80.30448150634766, Neurons: 49, Grad norm: 1.780e+01\n",
      "Epoch 4851, Loss: 80.30448150634766, Neurons: 49, Grad norm: 1.780e+01\n",
      "Epoch 4852, Loss: 80.1865463256836, Neurons: 49, Grad norm: 1.767e+01\n",
      "Epoch 4852, Loss: 80.1865463256836, Neurons: 49, Grad norm: 1.767e+01\n",
      "Epoch 4853, Loss: 80.06822204589844, Neurons: 49, Grad norm: 1.759e+01\n",
      "Epoch 4853, Loss: 80.06822204589844, Neurons: 49, Grad norm: 1.759e+01\n",
      "Epoch 4854, Loss: 79.94944763183594, Neurons: 49, Grad norm: 1.751e+01\n",
      "Epoch 4854, Loss: 79.94944763183594, Neurons: 49, Grad norm: 1.751e+01\n",
      "Epoch 4855, Loss: 79.83023834228516, Neurons: 49, Grad norm: 1.739e+01\n",
      "Epoch 4855, Loss: 79.83023834228516, Neurons: 49, Grad norm: 1.739e+01\n",
      "Epoch 4856, Loss: 79.71057891845703, Neurons: 49, Grad norm: 1.729e+01\n",
      "Epoch 4856, Loss: 79.71057891845703, Neurons: 49, Grad norm: 1.729e+01\n",
      "Epoch 4857, Loss: 79.59043884277344, Neurons: 49, Grad norm: 1.723e+01\n",
      "Epoch 4857, Loss: 79.59043884277344, Neurons: 49, Grad norm: 1.723e+01\n",
      "Epoch 4858, Loss: 79.46985626220703, Neurons: 49, Grad norm: 1.722e+01\n",
      "Epoch 4858, Loss: 79.46985626220703, Neurons: 49, Grad norm: 1.722e+01\n",
      "Epoch 4859, Loss: 79.3487777709961, Neurons: 49, Grad norm: 1.718e+01\n",
      "Epoch 4859, Loss: 79.3487777709961, Neurons: 49, Grad norm: 1.718e+01\n",
      "Epoch 4860, Loss: 79.22720336914062, Neurons: 49, Grad norm: 1.710e+01\n",
      "Epoch 4860, Loss: 79.22720336914062, Neurons: 49, Grad norm: 1.710e+01\n",
      "Epoch 4861, Loss: 79.1050796508789, Neurons: 49, Grad norm: 1.697e+01\n",
      "Epoch 4861, Loss: 79.1050796508789, Neurons: 49, Grad norm: 1.697e+01\n",
      "Epoch 4862, Loss: 78.9824447631836, Neurons: 49, Grad norm: 1.691e+01\n",
      "Epoch 4862, Loss: 78.9824447631836, Neurons: 49, Grad norm: 1.691e+01\n",
      "Epoch 4863, Loss: 78.85926818847656, Neurons: 49, Grad norm: 1.688e+01\n",
      "Epoch 4863, Loss: 78.85926818847656, Neurons: 49, Grad norm: 1.688e+01\n",
      "Epoch 4864, Loss: 78.73551940917969, Neurons: 49, Grad norm: 1.682e+01\n",
      "Epoch 4864, Loss: 78.73551940917969, Neurons: 49, Grad norm: 1.682e+01\n",
      "Epoch 4865, Loss: 78.6112060546875, Neurons: 49, Grad norm: 1.670e+01\n",
      "Epoch 4865, Loss: 78.6112060546875, Neurons: 49, Grad norm: 1.670e+01\n",
      "Epoch 4866, Loss: 78.48623657226562, Neurons: 49, Grad norm: 1.658e+01\n",
      "Epoch 4866, Loss: 78.48623657226562, Neurons: 49, Grad norm: 1.658e+01\n",
      "Epoch 4867, Loss: 78.3606948852539, Neurons: 49, Grad norm: 1.650e+01\n",
      "Epoch 4867, Loss: 78.3606948852539, Neurons: 49, Grad norm: 1.650e+01\n",
      "Epoch 4868, Loss: 78.23452758789062, Neurons: 49, Grad norm: 1.648e+01\n",
      "Epoch 4868, Loss: 78.23452758789062, Neurons: 49, Grad norm: 1.648e+01\n",
      "Epoch 4869, Loss: 78.10770416259766, Neurons: 49, Grad norm: 1.643e+01\n",
      "Epoch 4869, Loss: 78.10770416259766, Neurons: 49, Grad norm: 1.643e+01\n",
      "Epoch 4870, Loss: 77.98025512695312, Neurons: 49, Grad norm: 1.632e+01\n",
      "Epoch 4870, Loss: 77.98025512695312, Neurons: 49, Grad norm: 1.632e+01\n",
      "Epoch 4871, Loss: 77.85208129882812, Neurons: 49, Grad norm: 1.622e+01\n",
      "Epoch 4871, Loss: 77.85208129882812, Neurons: 49, Grad norm: 1.622e+01\n",
      "Epoch 4872, Loss: 77.72322082519531, Neurons: 49, Grad norm: 1.619e+01\n",
      "Epoch 4872, Loss: 77.72322082519531, Neurons: 49, Grad norm: 1.619e+01\n",
      "Epoch 4873, Loss: 77.59369659423828, Neurons: 49, Grad norm: 1.621e+01\n",
      "Epoch 4873, Loss: 77.59369659423828, Neurons: 49, Grad norm: 1.621e+01\n",
      "Epoch 4874, Loss: 77.46343231201172, Neurons: 49, Grad norm: 1.618e+01\n",
      "Epoch 4874, Loss: 77.46343231201172, Neurons: 49, Grad norm: 1.618e+01\n",
      "Epoch 4875, Loss: 77.33245849609375, Neurons: 49, Grad norm: 1.609e+01\n",
      "Epoch 4875, Loss: 77.33245849609375, Neurons: 49, Grad norm: 1.609e+01\n",
      "Epoch 4876, Loss: 77.20069885253906, Neurons: 49, Grad norm: 1.603e+01\n",
      "Epoch 4876, Loss: 77.20069885253906, Neurons: 49, Grad norm: 1.603e+01\n",
      "Epoch 4877, Loss: 77.06822204589844, Neurons: 49, Grad norm: 1.604e+01\n",
      "Epoch 4877, Loss: 77.06822204589844, Neurons: 49, Grad norm: 1.604e+01\n",
      "Epoch 4878, Loss: 76.93500518798828, Neurons: 49, Grad norm: 1.605e+01\n",
      "Epoch 4878, Loss: 76.93500518798828, Neurons: 49, Grad norm: 1.605e+01\n",
      "Epoch 4879, Loss: 76.80104064941406, Neurons: 49, Grad norm: 1.601e+01\n",
      "Epoch 4879, Loss: 76.80104064941406, Neurons: 49, Grad norm: 1.601e+01\n",
      "Epoch 4880, Loss: 76.66629791259766, Neurons: 49, Grad norm: 1.594e+01\n",
      "Epoch 4880, Loss: 76.66629791259766, Neurons: 49, Grad norm: 1.594e+01\n",
      "Epoch 4881, Loss: 76.5307846069336, Neurons: 49, Grad norm: 1.588e+01\n",
      "Epoch 4881, Loss: 76.5307846069336, Neurons: 49, Grad norm: 1.588e+01\n",
      "Epoch 4882, Loss: 76.39447021484375, Neurons: 49, Grad norm: 1.584e+01\n",
      "Epoch 4882, Loss: 76.39447021484375, Neurons: 49, Grad norm: 1.584e+01\n",
      "Epoch 4883, Loss: 76.25737762451172, Neurons: 49, Grad norm: 1.582e+01\n",
      "Epoch 4883, Loss: 76.25737762451172, Neurons: 49, Grad norm: 1.582e+01\n",
      "Epoch 4884, Loss: 76.1194839477539, Neurons: 49, Grad norm: 1.581e+01\n",
      "Epoch 4884, Loss: 76.1194839477539, Neurons: 49, Grad norm: 1.581e+01\n",
      "Epoch 4885, Loss: 75.98077392578125, Neurons: 49, Grad norm: 1.577e+01\n",
      "Epoch 4885, Loss: 75.98077392578125, Neurons: 49, Grad norm: 1.577e+01\n",
      "Epoch 4886, Loss: 75.8412857055664, Neurons: 49, Grad norm: 1.569e+01\n",
      "Epoch 4886, Loss: 75.8412857055664, Neurons: 49, Grad norm: 1.569e+01\n",
      "Epoch 4887, Loss: 75.70095825195312, Neurons: 49, Grad norm: 1.565e+01\n",
      "Epoch 4887, Loss: 75.70095825195312, Neurons: 49, Grad norm: 1.565e+01\n",
      "Epoch 4888, Loss: 75.559814453125, Neurons: 49, Grad norm: 1.564e+01\n",
      "Epoch 4888, Loss: 75.559814453125, Neurons: 49, Grad norm: 1.564e+01\n",
      "Epoch 4889, Loss: 75.41787719726562, Neurons: 49, Grad norm: 1.563e+01\n",
      "Epoch 4889, Loss: 75.41787719726562, Neurons: 49, Grad norm: 1.563e+01\n",
      "Epoch 4890, Loss: 75.27511596679688, Neurons: 49, Grad norm: 1.561e+01\n",
      "Epoch 4890, Loss: 75.27511596679688, Neurons: 49, Grad norm: 1.561e+01\n",
      "Epoch 4891, Loss: 75.13147735595703, Neurons: 49, Grad norm: 1.553e+01\n",
      "Epoch 4891, Loss: 75.13147735595703, Neurons: 49, Grad norm: 1.553e+01\n",
      "Epoch 4892, Loss: 74.9870376586914, Neurons: 49, Grad norm: 1.548e+01\n",
      "Epoch 4892, Loss: 74.9870376586914, Neurons: 49, Grad norm: 1.548e+01\n",
      "Epoch 4893, Loss: 74.84172821044922, Neurons: 49, Grad norm: 1.550e+01\n",
      "Epoch 4893, Loss: 74.84172821044922, Neurons: 49, Grad norm: 1.550e+01\n",
      "Epoch 4894, Loss: 74.69559478759766, Neurons: 49, Grad norm: 1.549e+01\n",
      "Epoch 4894, Loss: 74.69559478759766, Neurons: 49, Grad norm: 1.549e+01\n",
      "Epoch 4895, Loss: 74.54862976074219, Neurons: 49, Grad norm: 1.541e+01\n",
      "Epoch 4895, Loss: 74.54862976074219, Neurons: 49, Grad norm: 1.541e+01\n",
      "Epoch 4896, Loss: 74.40080261230469, Neurons: 49, Grad norm: 1.534e+01\n",
      "Epoch 4896, Loss: 74.40080261230469, Neurons: 49, Grad norm: 1.534e+01\n",
      "Epoch 4897, Loss: 74.25212860107422, Neurons: 49, Grad norm: 1.531e+01\n",
      "Epoch 4897, Loss: 74.25212860107422, Neurons: 49, Grad norm: 1.531e+01\n",
      "Epoch 4898, Loss: 74.10260772705078, Neurons: 49, Grad norm: 1.531e+01\n",
      "Epoch 4898, Loss: 74.10260772705078, Neurons: 49, Grad norm: 1.531e+01\n",
      "Epoch 4899, Loss: 73.95223999023438, Neurons: 49, Grad norm: 1.525e+01\n",
      "Epoch 4899, Loss: 73.95223999023438, Neurons: 49, Grad norm: 1.525e+01\n",
      "Epoch 4899, Test loss: 70.11595916748047\n",
      "Epoch 4899, Test loss: 70.11595916748047\n",
      "Added neuron to hidden layer 1 with activation tanh\n",
      "Added neuron to hidden layer 1 with activation tanh\n",
      "network shape updated to :[21, 28, 1]\n",
      "network shape updated to :[21, 28, 1]\n",
      "Epoch 4900, Loss: 74.50800323486328, Neurons: 50, Grad norm: 5.049e+01\n",
      "Epoch 4900, Loss: 74.50800323486328, Neurons: 50, Grad norm: 5.049e+01\n",
      "Epoch 4901, Loss: 74.32485961914062, Neurons: 50, Grad norm: 4.041e+01\n",
      "Epoch 4901, Loss: 74.32485961914062, Neurons: 50, Grad norm: 4.041e+01\n",
      "Epoch 4902, Loss: 74.17086791992188, Neurons: 50, Grad norm: 3.436e+01\n",
      "Epoch 4902, Loss: 74.17086791992188, Neurons: 50, Grad norm: 3.436e+01\n",
      "Epoch 4903, Loss: 74.04256439208984, Neurons: 50, Grad norm: 3.131e+01\n",
      "Epoch 4903, Loss: 74.04256439208984, Neurons: 50, Grad norm: 3.131e+01\n",
      "Epoch 4904, Loss: 73.93489074707031, Neurons: 50, Grad norm: 2.927e+01\n",
      "Epoch 4904, Loss: 73.93489074707031, Neurons: 50, Grad norm: 2.927e+01\n",
      "Epoch 4905, Loss: 73.84326171875, Neurons: 50, Grad norm: 2.676e+01\n",
      "Epoch 4905, Loss: 73.84326171875, Neurons: 50, Grad norm: 2.676e+01\n",
      "Epoch 4906, Loss: 73.76390838623047, Neurons: 50, Grad norm: 2.328e+01\n",
      "Epoch 4906, Loss: 73.76390838623047, Neurons: 50, Grad norm: 2.328e+01\n",
      "Epoch 4907, Loss: 73.69441986083984, Neurons: 50, Grad norm: 1.922e+01\n",
      "Epoch 4907, Loss: 73.69441986083984, Neurons: 50, Grad norm: 1.922e+01\n",
      "Epoch 4908, Loss: 73.63349914550781, Neurons: 50, Grad norm: 1.614e+01\n",
      "Epoch 4908, Loss: 73.63349914550781, Neurons: 50, Grad norm: 1.614e+01\n",
      "Epoch 4909, Loss: 73.5804443359375, Neurons: 50, Grad norm: 1.591e+01\n",
      "Epoch 4909, Loss: 73.5804443359375, Neurons: 50, Grad norm: 1.591e+01\n",
      "Epoch 4910, Loss: 73.53398132324219, Neurons: 50, Grad norm: 1.854e+01\n",
      "Epoch 4910, Loss: 73.53398132324219, Neurons: 50, Grad norm: 1.854e+01\n",
      "Epoch 4911, Loss: 73.49171447753906, Neurons: 50, Grad norm: 2.200e+01\n",
      "Epoch 4911, Loss: 73.49171447753906, Neurons: 50, Grad norm: 2.200e+01\n",
      "Epoch 4912, Loss: 73.45050811767578, Neurons: 50, Grad norm: 2.489e+01\n",
      "Epoch 4912, Loss: 73.45050811767578, Neurons: 50, Grad norm: 2.489e+01\n",
      "Epoch 4913, Loss: 73.40751647949219, Neurons: 50, Grad norm: 2.659e+01\n",
      "Epoch 4913, Loss: 73.40751647949219, Neurons: 50, Grad norm: 2.659e+01\n",
      "Epoch 4914, Loss: 73.36099243164062, Neurons: 50, Grad norm: 2.708e+01\n",
      "Epoch 4914, Loss: 73.36099243164062, Neurons: 50, Grad norm: 2.708e+01\n",
      "Epoch 4915, Loss: 73.31036376953125, Neurons: 50, Grad norm: 2.650e+01\n",
      "Epoch 4915, Loss: 73.31036376953125, Neurons: 50, Grad norm: 2.650e+01\n",
      "Epoch 4916, Loss: 73.2560043334961, Neurons: 50, Grad norm: 2.510e+01\n",
      "Epoch 4916, Loss: 73.2560043334961, Neurons: 50, Grad norm: 2.510e+01\n",
      "Epoch 4917, Loss: 73.19865417480469, Neurons: 50, Grad norm: 2.324e+01\n",
      "Epoch 4917, Loss: 73.19865417480469, Neurons: 50, Grad norm: 2.324e+01\n",
      "Epoch 4918, Loss: 73.13923645019531, Neurons: 50, Grad norm: 2.122e+01\n",
      "Epoch 4918, Loss: 73.13923645019531, Neurons: 50, Grad norm: 2.122e+01\n",
      "Epoch 4919, Loss: 73.07853698730469, Neurons: 50, Grad norm: 1.932e+01\n",
      "Epoch 4919, Loss: 73.07853698730469, Neurons: 50, Grad norm: 1.932e+01\n",
      "Epoch 4920, Loss: 73.01707458496094, Neurons: 50, Grad norm: 1.771e+01\n",
      "Epoch 4920, Loss: 73.01707458496094, Neurons: 50, Grad norm: 1.771e+01\n",
      "Epoch 4921, Loss: 72.95530700683594, Neurons: 50, Grad norm: 1.652e+01\n",
      "Epoch 4921, Loss: 72.95530700683594, Neurons: 50, Grad norm: 1.652e+01\n",
      "Epoch 4922, Loss: 72.89354705810547, Neurons: 50, Grad norm: 1.573e+01\n",
      "Epoch 4922, Loss: 72.89354705810547, Neurons: 50, Grad norm: 1.573e+01\n",
      "Epoch 4923, Loss: 72.83209228515625, Neurons: 50, Grad norm: 1.529e+01\n",
      "Epoch 4923, Loss: 72.83209228515625, Neurons: 50, Grad norm: 1.529e+01\n",
      "Epoch 4924, Loss: 72.77119445800781, Neurons: 50, Grad norm: 1.514e+01\n",
      "Epoch 4924, Loss: 72.77119445800781, Neurons: 50, Grad norm: 1.514e+01\n",
      "Epoch 4925, Loss: 72.71089172363281, Neurons: 50, Grad norm: 1.525e+01\n",
      "Epoch 4925, Loss: 72.71089172363281, Neurons: 50, Grad norm: 1.525e+01\n",
      "Epoch 4926, Loss: 72.65113067626953, Neurons: 50, Grad norm: 1.555e+01\n",
      "Epoch 4926, Loss: 72.65113067626953, Neurons: 50, Grad norm: 1.555e+01\n",
      "Epoch 4927, Loss: 72.5916748046875, Neurons: 50, Grad norm: 1.594e+01\n",
      "Epoch 4927, Loss: 72.5916748046875, Neurons: 50, Grad norm: 1.594e+01\n",
      "Epoch 4928, Loss: 72.53208923339844, Neurons: 50, Grad norm: 1.624e+01\n",
      "Epoch 4928, Loss: 72.53208923339844, Neurons: 50, Grad norm: 1.624e+01\n",
      "Epoch 4929, Loss: 72.4717788696289, Neurons: 50, Grad norm: 1.642e+01\n",
      "Epoch 4929, Loss: 72.4717788696289, Neurons: 50, Grad norm: 1.642e+01\n",
      "Epoch 4930, Loss: 72.41031646728516, Neurons: 50, Grad norm: 1.642e+01\n",
      "Epoch 4930, Loss: 72.41031646728516, Neurons: 50, Grad norm: 1.642e+01\n",
      "Epoch 4931, Loss: 72.34738159179688, Neurons: 50, Grad norm: 1.627e+01\n",
      "Epoch 4931, Loss: 72.34738159179688, Neurons: 50, Grad norm: 1.627e+01\n",
      "Epoch 4932, Loss: 72.28294372558594, Neurons: 50, Grad norm: 1.602e+01\n",
      "Epoch 4932, Loss: 72.28294372558594, Neurons: 50, Grad norm: 1.602e+01\n",
      "Epoch 4933, Loss: 72.21698760986328, Neurons: 50, Grad norm: 1.572e+01\n",
      "Epoch 4933, Loss: 72.21698760986328, Neurons: 50, Grad norm: 1.572e+01\n",
      "Epoch 4934, Loss: 72.14970397949219, Neurons: 50, Grad norm: 1.542e+01\n",
      "Epoch 4934, Loss: 72.14970397949219, Neurons: 50, Grad norm: 1.542e+01\n",
      "Epoch 4935, Loss: 72.08113861083984, Neurons: 50, Grad norm: 1.513e+01\n",
      "Epoch 4935, Loss: 72.08113861083984, Neurons: 50, Grad norm: 1.513e+01\n",
      "Epoch 4936, Loss: 72.01144409179688, Neurons: 50, Grad norm: 1.489e+01\n",
      "Epoch 4936, Loss: 72.01144409179688, Neurons: 50, Grad norm: 1.489e+01\n",
      "Epoch 4937, Loss: 71.94075775146484, Neurons: 50, Grad norm: 1.470e+01\n",
      "Epoch 4937, Loss: 71.94075775146484, Neurons: 50, Grad norm: 1.470e+01\n",
      "Epoch 4938, Loss: 71.8692626953125, Neurons: 50, Grad norm: 1.461e+01\n",
      "Epoch 4938, Loss: 71.8692626953125, Neurons: 50, Grad norm: 1.461e+01\n",
      "Epoch 4939, Loss: 71.79708099365234, Neurons: 50, Grad norm: 1.460e+01\n",
      "Epoch 4939, Loss: 71.79708099365234, Neurons: 50, Grad norm: 1.460e+01\n",
      "Epoch 4940, Loss: 71.72425842285156, Neurons: 50, Grad norm: 1.462e+01\n",
      "Epoch 4940, Loss: 71.72425842285156, Neurons: 50, Grad norm: 1.462e+01\n",
      "Epoch 4941, Loss: 71.65086364746094, Neurons: 50, Grad norm: 1.472e+01\n",
      "Epoch 4941, Loss: 71.65086364746094, Neurons: 50, Grad norm: 1.472e+01\n",
      "Epoch 4942, Loss: 71.5769271850586, Neurons: 50, Grad norm: 1.492e+01\n",
      "Epoch 4942, Loss: 71.5769271850586, Neurons: 50, Grad norm: 1.492e+01\n",
      "Epoch 4943, Loss: 71.50249481201172, Neurons: 50, Grad norm: 1.512e+01\n",
      "Epoch 4943, Loss: 71.50249481201172, Neurons: 50, Grad norm: 1.512e+01\n",
      "Epoch 4944, Loss: 71.42758178710938, Neurons: 50, Grad norm: 1.534e+01\n",
      "Epoch 4944, Loss: 71.42758178710938, Neurons: 50, Grad norm: 1.534e+01\n",
      "Epoch 4945, Loss: 71.35205841064453, Neurons: 50, Grad norm: 1.551e+01\n",
      "Epoch 4945, Loss: 71.35205841064453, Neurons: 50, Grad norm: 1.551e+01\n",
      "Epoch 4946, Loss: 71.27583312988281, Neurons: 50, Grad norm: 1.560e+01\n",
      "Epoch 4946, Loss: 71.27583312988281, Neurons: 50, Grad norm: 1.560e+01\n",
      "Epoch 4947, Loss: 71.1987533569336, Neurons: 50, Grad norm: 1.559e+01\n",
      "Epoch 4947, Loss: 71.1987533569336, Neurons: 50, Grad norm: 1.559e+01\n",
      "Epoch 4948, Loss: 71.12081146240234, Neurons: 50, Grad norm: 1.551e+01\n",
      "Epoch 4948, Loss: 71.12081146240234, Neurons: 50, Grad norm: 1.551e+01\n",
      "Epoch 4949, Loss: 71.04192352294922, Neurons: 50, Grad norm: 1.533e+01\n",
      "Epoch 4949, Loss: 71.04192352294922, Neurons: 50, Grad norm: 1.533e+01\n",
      "Epoch 4950, Loss: 70.962158203125, Neurons: 50, Grad norm: 1.512e+01\n",
      "Epoch 4950, Loss: 70.962158203125, Neurons: 50, Grad norm: 1.512e+01\n",
      "Epoch 4951, Loss: 70.88148498535156, Neurons: 50, Grad norm: 1.490e+01\n",
      "Epoch 4951, Loss: 70.88148498535156, Neurons: 50, Grad norm: 1.490e+01\n",
      "Epoch 4952, Loss: 70.79996490478516, Neurons: 50, Grad norm: 1.470e+01\n",
      "Epoch 4952, Loss: 70.79996490478516, Neurons: 50, Grad norm: 1.470e+01\n",
      "Epoch 4953, Loss: 70.7176284790039, Neurons: 50, Grad norm: 1.454e+01\n",
      "Epoch 4953, Loss: 70.7176284790039, Neurons: 50, Grad norm: 1.454e+01\n",
      "Epoch 4954, Loss: 70.63453674316406, Neurons: 50, Grad norm: 1.444e+01\n",
      "Epoch 4954, Loss: 70.63453674316406, Neurons: 50, Grad norm: 1.444e+01\n",
      "Epoch 4955, Loss: 70.55068969726562, Neurons: 50, Grad norm: 1.442e+01\n",
      "Epoch 4955, Loss: 70.55068969726562, Neurons: 50, Grad norm: 1.442e+01\n",
      "Epoch 4956, Loss: 70.46614074707031, Neurons: 50, Grad norm: 1.446e+01\n",
      "Epoch 4956, Loss: 70.46614074707031, Neurons: 50, Grad norm: 1.446e+01\n",
      "Epoch 4957, Loss: 70.38081359863281, Neurons: 50, Grad norm: 1.453e+01\n",
      "Epoch 4957, Loss: 70.38081359863281, Neurons: 50, Grad norm: 1.453e+01\n",
      "Epoch 4958, Loss: 70.2947998046875, Neurons: 50, Grad norm: 1.462e+01\n",
      "Epoch 4958, Loss: 70.2947998046875, Neurons: 50, Grad norm: 1.462e+01\n",
      "Epoch 4959, Loss: 70.20806121826172, Neurons: 50, Grad norm: 1.467e+01\n",
      "Epoch 4959, Loss: 70.20806121826172, Neurons: 50, Grad norm: 1.467e+01\n",
      "Epoch 4960, Loss: 70.12056732177734, Neurons: 50, Grad norm: 1.466e+01\n",
      "Epoch 4960, Loss: 70.12056732177734, Neurons: 50, Grad norm: 1.466e+01\n",
      "Epoch 4961, Loss: 70.03229522705078, Neurons: 50, Grad norm: 1.461e+01\n",
      "Epoch 4961, Loss: 70.03229522705078, Neurons: 50, Grad norm: 1.461e+01\n",
      "Epoch 4962, Loss: 69.9432144165039, Neurons: 50, Grad norm: 1.452e+01\n",
      "Epoch 4962, Loss: 69.9432144165039, Neurons: 50, Grad norm: 1.452e+01\n",
      "Epoch 4963, Loss: 69.85330963134766, Neurons: 50, Grad norm: 1.441e+01\n",
      "Epoch 4963, Loss: 69.85330963134766, Neurons: 50, Grad norm: 1.441e+01\n",
      "Epoch 4964, Loss: 69.7625961303711, Neurons: 50, Grad norm: 1.431e+01\n",
      "Epoch 4964, Loss: 69.7625961303711, Neurons: 50, Grad norm: 1.431e+01\n",
      "Epoch 4965, Loss: 69.67105102539062, Neurons: 50, Grad norm: 1.421e+01\n",
      "Epoch 4965, Loss: 69.67105102539062, Neurons: 50, Grad norm: 1.421e+01\n",
      "Epoch 4966, Loss: 69.57868194580078, Neurons: 50, Grad norm: 1.416e+01\n",
      "Epoch 4966, Loss: 69.57868194580078, Neurons: 50, Grad norm: 1.416e+01\n",
      "Epoch 4967, Loss: 69.48551177978516, Neurons: 50, Grad norm: 1.414e+01\n",
      "Epoch 4967, Loss: 69.48551177978516, Neurons: 50, Grad norm: 1.414e+01\n",
      "Epoch 4968, Loss: 69.39151763916016, Neurons: 50, Grad norm: 1.414e+01\n",
      "Epoch 4968, Loss: 69.39151763916016, Neurons: 50, Grad norm: 1.414e+01\n",
      "Epoch 4969, Loss: 69.29672241210938, Neurons: 50, Grad norm: 1.419e+01\n",
      "Epoch 4969, Loss: 69.29672241210938, Neurons: 50, Grad norm: 1.419e+01\n",
      "Epoch 4970, Loss: 69.20115661621094, Neurons: 50, Grad norm: 1.424e+01\n",
      "Epoch 4970, Loss: 69.20115661621094, Neurons: 50, Grad norm: 1.424e+01\n",
      "Epoch 4971, Loss: 69.10479736328125, Neurons: 50, Grad norm: 1.430e+01\n",
      "Epoch 4971, Loss: 69.10479736328125, Neurons: 50, Grad norm: 1.430e+01\n",
      "Epoch 4972, Loss: 69.00765991210938, Neurons: 50, Grad norm: 1.436e+01\n",
      "Epoch 4972, Loss: 69.00765991210938, Neurons: 50, Grad norm: 1.436e+01\n",
      "Epoch 4973, Loss: 68.90974426269531, Neurons: 50, Grad norm: 1.439e+01\n",
      "Epoch 4973, Loss: 68.90974426269531, Neurons: 50, Grad norm: 1.439e+01\n",
      "Epoch 4974, Loss: 68.81106567382812, Neurons: 50, Grad norm: 1.442e+01\n",
      "Epoch 4974, Loss: 68.81106567382812, Neurons: 50, Grad norm: 1.442e+01\n",
      "Epoch 4975, Loss: 68.71157836914062, Neurons: 50, Grad norm: 1.442e+01\n",
      "Epoch 4975, Loss: 68.71157836914062, Neurons: 50, Grad norm: 1.442e+01\n",
      "Epoch 4976, Loss: 68.611328125, Neurons: 50, Grad norm: 1.441e+01\n",
      "Epoch 4976, Loss: 68.611328125, Neurons: 50, Grad norm: 1.441e+01\n",
      "Epoch 4977, Loss: 68.51025390625, Neurons: 50, Grad norm: 1.437e+01\n",
      "Epoch 4977, Loss: 68.51025390625, Neurons: 50, Grad norm: 1.437e+01\n",
      "Epoch 4978, Loss: 68.40841674804688, Neurons: 50, Grad norm: 1.432e+01\n",
      "Epoch 4978, Loss: 68.40841674804688, Neurons: 50, Grad norm: 1.432e+01\n",
      "Epoch 4979, Loss: 68.30581665039062, Neurons: 50, Grad norm: 1.425e+01\n",
      "Epoch 4979, Loss: 68.30581665039062, Neurons: 50, Grad norm: 1.425e+01\n",
      "Epoch 4980, Loss: 68.20246124267578, Neurons: 50, Grad norm: 1.415e+01\n",
      "Epoch 4980, Loss: 68.20246124267578, Neurons: 50, Grad norm: 1.415e+01\n",
      "Epoch 4981, Loss: 68.09832763671875, Neurons: 50, Grad norm: 1.405e+01\n",
      "Epoch 4981, Loss: 68.09832763671875, Neurons: 50, Grad norm: 1.405e+01\n",
      "Epoch 4982, Loss: 67.99349975585938, Neurons: 50, Grad norm: 1.399e+01\n",
      "Epoch 4982, Loss: 67.99349975585938, Neurons: 50, Grad norm: 1.399e+01\n",
      "Epoch 4983, Loss: 67.88795471191406, Neurons: 50, Grad norm: 1.395e+01\n",
      "Epoch 4983, Loss: 67.88795471191406, Neurons: 50, Grad norm: 1.395e+01\n",
      "Epoch 4984, Loss: 67.78175354003906, Neurons: 50, Grad norm: 1.394e+01\n",
      "Epoch 4984, Loss: 67.78175354003906, Neurons: 50, Grad norm: 1.394e+01\n",
      "Epoch 4985, Loss: 67.67494201660156, Neurons: 50, Grad norm: 1.395e+01\n",
      "Epoch 4985, Loss: 67.67494201660156, Neurons: 50, Grad norm: 1.395e+01\n",
      "Epoch 4986, Loss: 67.56748962402344, Neurons: 50, Grad norm: 1.396e+01\n",
      "Epoch 4986, Loss: 67.56748962402344, Neurons: 50, Grad norm: 1.396e+01\n",
      "Epoch 4987, Loss: 67.45944213867188, Neurons: 50, Grad norm: 1.397e+01\n",
      "Epoch 4987, Loss: 67.45944213867188, Neurons: 50, Grad norm: 1.397e+01\n",
      "Epoch 4988, Loss: 67.35089111328125, Neurons: 50, Grad norm: 1.396e+01\n",
      "Epoch 4988, Loss: 67.35089111328125, Neurons: 50, Grad norm: 1.396e+01\n",
      "Epoch 4989, Loss: 67.2418441772461, Neurons: 50, Grad norm: 1.392e+01\n",
      "Epoch 4989, Loss: 67.2418441772461, Neurons: 50, Grad norm: 1.392e+01\n",
      "Epoch 4990, Loss: 67.13232421875, Neurons: 50, Grad norm: 1.385e+01\n",
      "Epoch 4990, Loss: 67.13232421875, Neurons: 50, Grad norm: 1.385e+01\n",
      "Epoch 4991, Loss: 67.0223617553711, Neurons: 50, Grad norm: 1.375e+01\n",
      "Epoch 4991, Loss: 67.0223617553711, Neurons: 50, Grad norm: 1.375e+01\n",
      "Epoch 4992, Loss: 66.91203308105469, Neurons: 50, Grad norm: 1.367e+01\n",
      "Epoch 4992, Loss: 66.91203308105469, Neurons: 50, Grad norm: 1.367e+01\n",
      "Epoch 4993, Loss: 66.80140686035156, Neurons: 50, Grad norm: 1.359e+01\n",
      "Epoch 4993, Loss: 66.80140686035156, Neurons: 50, Grad norm: 1.359e+01\n",
      "Epoch 4994, Loss: 66.69050598144531, Neurons: 50, Grad norm: 1.350e+01\n",
      "Epoch 4994, Loss: 66.69050598144531, Neurons: 50, Grad norm: 1.350e+01\n",
      "Epoch 4995, Loss: 66.57936096191406, Neurons: 50, Grad norm: 1.346e+01\n",
      "Epoch 4995, Loss: 66.57936096191406, Neurons: 50, Grad norm: 1.346e+01\n",
      "Epoch 4996, Loss: 66.46807861328125, Neurons: 50, Grad norm: 1.343e+01\n",
      "Epoch 4996, Loss: 66.46807861328125, Neurons: 50, Grad norm: 1.343e+01\n",
      "Epoch 4997, Loss: 66.35663604736328, Neurons: 50, Grad norm: 1.341e+01\n",
      "Epoch 4997, Loss: 66.35663604736328, Neurons: 50, Grad norm: 1.341e+01\n",
      "Epoch 4998, Loss: 66.24512481689453, Neurons: 50, Grad norm: 1.340e+01\n",
      "Epoch 4998, Loss: 66.24512481689453, Neurons: 50, Grad norm: 1.340e+01\n",
      "Epoch 4999, Loss: 66.1335678100586, Neurons: 50, Grad norm: 1.337e+01\n",
      "Epoch 4999, Loss: 66.1335678100586, Neurons: 50, Grad norm: 1.337e+01\n",
      "Epoch 4999, Test loss: 62.614036560058594\n",
      "Epoch 4999, Test loss: 62.614036560058594\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "network shape updated to :[21, 29, 1]\n",
      "network shape updated to :[21, 29, 1]\n",
      "Epoch 5000, Loss: 66.02181243896484, Neurons: 51, Grad norm: 1.343e+01\n",
      "Epoch 5000, Loss: 66.02181243896484, Neurons: 51, Grad norm: 1.343e+01\n",
      "Epoch 5001, Loss: 65.98357391357422, Neurons: 51, Grad norm: 1.338e+01\n",
      "Epoch 5001, Loss: 65.98357391357422, Neurons: 51, Grad norm: 1.338e+01\n",
      "Epoch 5002, Loss: 65.94261169433594, Neurons: 51, Grad norm: 1.355e+01\n",
      "Epoch 5002, Loss: 65.94261169433594, Neurons: 51, Grad norm: 1.355e+01\n",
      "Epoch 5003, Loss: 65.90116119384766, Neurons: 51, Grad norm: 1.309e+01\n",
      "Epoch 5003, Loss: 65.90116119384766, Neurons: 51, Grad norm: 1.309e+01\n",
      "Epoch 5004, Loss: 65.85728454589844, Neurons: 51, Grad norm: 1.285e+01\n",
      "Epoch 5004, Loss: 65.85728454589844, Neurons: 51, Grad norm: 1.285e+01\n",
      "Epoch 5005, Loss: 65.81218719482422, Neurons: 51, Grad norm: 1.285e+01\n",
      "Epoch 5005, Loss: 65.81218719482422, Neurons: 51, Grad norm: 1.285e+01\n",
      "Epoch 5006, Loss: 65.76557922363281, Neurons: 51, Grad norm: 1.287e+01\n",
      "Epoch 5006, Loss: 65.76557922363281, Neurons: 51, Grad norm: 1.287e+01\n",
      "Epoch 5007, Loss: 65.71697235107422, Neurons: 51, Grad norm: 1.291e+01\n",
      "Epoch 5007, Loss: 65.71697235107422, Neurons: 51, Grad norm: 1.291e+01\n",
      "Epoch 5008, Loss: 65.66683959960938, Neurons: 51, Grad norm: 1.293e+01\n",
      "Epoch 5008, Loss: 65.66683959960938, Neurons: 51, Grad norm: 1.293e+01\n",
      "Epoch 5009, Loss: 65.61539459228516, Neurons: 51, Grad norm: 1.280e+01\n",
      "Epoch 5009, Loss: 65.61539459228516, Neurons: 51, Grad norm: 1.280e+01\n",
      "Epoch 5010, Loss: 65.56217193603516, Neurons: 51, Grad norm: 1.260e+01\n",
      "Epoch 5010, Loss: 65.56217193603516, Neurons: 51, Grad norm: 1.260e+01\n",
      "Epoch 5011, Loss: 65.50704193115234, Neurons: 51, Grad norm: 1.251e+01\n",
      "Epoch 5011, Loss: 65.50704193115234, Neurons: 51, Grad norm: 1.251e+01\n",
      "Epoch 5012, Loss: 65.45033264160156, Neurons: 51, Grad norm: 1.253e+01\n",
      "Epoch 5012, Loss: 65.45033264160156, Neurons: 51, Grad norm: 1.253e+01\n",
      "Epoch 5013, Loss: 65.39218139648438, Neurons: 51, Grad norm: 1.256e+01\n",
      "Epoch 5013, Loss: 65.39218139648438, Neurons: 51, Grad norm: 1.256e+01\n",
      "Epoch 5014, Loss: 65.33245849609375, Neurons: 51, Grad norm: 1.251e+01\n",
      "Epoch 5014, Loss: 65.33245849609375, Neurons: 51, Grad norm: 1.251e+01\n",
      "Epoch 5015, Loss: 65.2711181640625, Neurons: 51, Grad norm: 1.241e+01\n",
      "Epoch 5015, Loss: 65.2711181640625, Neurons: 51, Grad norm: 1.241e+01\n",
      "Epoch 5016, Loss: 65.20830535888672, Neurons: 51, Grad norm: 1.236e+01\n",
      "Epoch 5016, Loss: 65.20830535888672, Neurons: 51, Grad norm: 1.236e+01\n",
      "Epoch 5017, Loss: 65.14402770996094, Neurons: 51, Grad norm: 1.237e+01\n",
      "Epoch 5017, Loss: 65.14402770996094, Neurons: 51, Grad norm: 1.237e+01\n",
      "Epoch 5018, Loss: 65.07829284667969, Neurons: 51, Grad norm: 1.240e+01\n",
      "Epoch 5018, Loss: 65.07829284667969, Neurons: 51, Grad norm: 1.240e+01\n",
      "Epoch 5019, Loss: 65.0111312866211, Neurons: 51, Grad norm: 1.237e+01\n",
      "Epoch 5019, Loss: 65.0111312866211, Neurons: 51, Grad norm: 1.237e+01\n",
      "Epoch 5020, Loss: 64.94261169433594, Neurons: 51, Grad norm: 1.227e+01\n",
      "Epoch 5020, Loss: 64.94261169433594, Neurons: 51, Grad norm: 1.227e+01\n",
      "Epoch 5021, Loss: 64.87273406982422, Neurons: 51, Grad norm: 1.219e+01\n",
      "Epoch 5021, Loss: 64.87273406982422, Neurons: 51, Grad norm: 1.219e+01\n",
      "Epoch 5022, Loss: 64.80158996582031, Neurons: 51, Grad norm: 1.219e+01\n",
      "Epoch 5022, Loss: 64.80158996582031, Neurons: 51, Grad norm: 1.219e+01\n",
      "Epoch 5023, Loss: 64.72916412353516, Neurons: 51, Grad norm: 1.222e+01\n",
      "Epoch 5023, Loss: 64.72916412353516, Neurons: 51, Grad norm: 1.222e+01\n",
      "Epoch 5024, Loss: 64.65553283691406, Neurons: 51, Grad norm: 1.222e+01\n",
      "Epoch 5024, Loss: 64.65553283691406, Neurons: 51, Grad norm: 1.222e+01\n",
      "Epoch 5025, Loss: 64.58065795898438, Neurons: 51, Grad norm: 1.215e+01\n",
      "Epoch 5025, Loss: 64.58065795898438, Neurons: 51, Grad norm: 1.215e+01\n",
      "Epoch 5026, Loss: 64.50463104248047, Neurons: 51, Grad norm: 1.209e+01\n",
      "Epoch 5026, Loss: 64.50463104248047, Neurons: 51, Grad norm: 1.209e+01\n",
      "Epoch 5027, Loss: 64.42750549316406, Neurons: 51, Grad norm: 1.207e+01\n",
      "Epoch 5027, Loss: 64.42750549316406, Neurons: 51, Grad norm: 1.207e+01\n",
      "Epoch 5028, Loss: 64.34923553466797, Neurons: 51, Grad norm: 1.205e+01\n",
      "Epoch 5028, Loss: 64.34923553466797, Neurons: 51, Grad norm: 1.205e+01\n",
      "Epoch 5029, Loss: 64.26986694335938, Neurons: 51, Grad norm: 1.204e+01\n",
      "Epoch 5029, Loss: 64.26986694335938, Neurons: 51, Grad norm: 1.204e+01\n",
      "Epoch 5030, Loss: 64.18946075439453, Neurons: 51, Grad norm: 1.199e+01\n",
      "Epoch 5030, Loss: 64.18946075439453, Neurons: 51, Grad norm: 1.199e+01\n",
      "Epoch 5031, Loss: 64.10801696777344, Neurons: 51, Grad norm: 1.192e+01\n",
      "Epoch 5031, Loss: 64.10801696777344, Neurons: 51, Grad norm: 1.192e+01\n",
      "Epoch 5032, Loss: 64.02558898925781, Neurons: 51, Grad norm: 1.189e+01\n",
      "Epoch 5032, Loss: 64.02558898925781, Neurons: 51, Grad norm: 1.189e+01\n",
      "Epoch 5033, Loss: 63.94216537475586, Neurons: 51, Grad norm: 1.189e+01\n",
      "Epoch 5033, Loss: 63.94216537475586, Neurons: 51, Grad norm: 1.189e+01\n",
      "Epoch 5034, Loss: 63.857810974121094, Neurons: 51, Grad norm: 1.188e+01\n",
      "Epoch 5034, Loss: 63.857810974121094, Neurons: 51, Grad norm: 1.188e+01\n",
      "Epoch 5035, Loss: 63.772518157958984, Neurons: 51, Grad norm: 1.184e+01\n",
      "Epoch 5035, Loss: 63.772518157958984, Neurons: 51, Grad norm: 1.184e+01\n",
      "Epoch 5036, Loss: 63.68630599975586, Neurons: 51, Grad norm: 1.178e+01\n",
      "Epoch 5036, Loss: 63.68630599975586, Neurons: 51, Grad norm: 1.178e+01\n",
      "Epoch 5037, Loss: 63.599205017089844, Neurons: 51, Grad norm: 1.176e+01\n",
      "Epoch 5037, Loss: 63.599205017089844, Neurons: 51, Grad norm: 1.176e+01\n",
      "Epoch 5038, Loss: 63.51123046875, Neurons: 51, Grad norm: 1.177e+01\n",
      "Epoch 5038, Loss: 63.51123046875, Neurons: 51, Grad norm: 1.177e+01\n",
      "Epoch 5039, Loss: 63.422393798828125, Neurons: 51, Grad norm: 1.175e+01\n",
      "Epoch 5039, Loss: 63.422393798828125, Neurons: 51, Grad norm: 1.175e+01\n",
      "Epoch 5040, Loss: 63.33273696899414, Neurons: 51, Grad norm: 1.169e+01\n",
      "Epoch 5040, Loss: 63.33273696899414, Neurons: 51, Grad norm: 1.169e+01\n",
      "Epoch 5041, Loss: 63.24223327636719, Neurons: 51, Grad norm: 1.166e+01\n",
      "Epoch 5041, Loss: 63.24223327636719, Neurons: 51, Grad norm: 1.166e+01\n",
      "Epoch 5042, Loss: 63.150936126708984, Neurons: 51, Grad norm: 1.167e+01\n",
      "Epoch 5042, Loss: 63.150936126708984, Neurons: 51, Grad norm: 1.167e+01\n",
      "Epoch 5043, Loss: 63.05884552001953, Neurons: 51, Grad norm: 1.165e+01\n",
      "Epoch 5043, Loss: 63.05884552001953, Neurons: 51, Grad norm: 1.165e+01\n",
      "Epoch 5044, Loss: 62.96598434448242, Neurons: 51, Grad norm: 1.161e+01\n",
      "Epoch 5044, Loss: 62.96598434448242, Neurons: 51, Grad norm: 1.161e+01\n",
      "Epoch 5045, Loss: 62.87236022949219, Neurons: 51, Grad norm: 1.156e+01\n",
      "Epoch 5045, Loss: 62.87236022949219, Neurons: 51, Grad norm: 1.156e+01\n",
      "Epoch 5046, Loss: 62.77798843383789, Neurons: 51, Grad norm: 1.155e+01\n",
      "Epoch 5046, Loss: 62.77798843383789, Neurons: 51, Grad norm: 1.155e+01\n",
      "Epoch 5047, Loss: 62.68291091918945, Neurons: 51, Grad norm: 1.155e+01\n",
      "Epoch 5047, Loss: 62.68291091918945, Neurons: 51, Grad norm: 1.155e+01\n",
      "Epoch 5048, Loss: 62.58708953857422, Neurons: 51, Grad norm: 1.152e+01\n",
      "Epoch 5048, Loss: 62.58708953857422, Neurons: 51, Grad norm: 1.152e+01\n",
      "Epoch 5049, Loss: 62.49055480957031, Neurons: 51, Grad norm: 1.147e+01\n",
      "Epoch 5049, Loss: 62.49055480957031, Neurons: 51, Grad norm: 1.147e+01\n",
      "Epoch 5050, Loss: 62.39334487915039, Neurons: 51, Grad norm: 1.145e+01\n",
      "Epoch 5050, Loss: 62.39334487915039, Neurons: 51, Grad norm: 1.145e+01\n",
      "Epoch 5051, Loss: 62.29545974731445, Neurons: 51, Grad norm: 1.145e+01\n",
      "Epoch 5051, Loss: 62.29545974731445, Neurons: 51, Grad norm: 1.145e+01\n",
      "Epoch 5052, Loss: 62.1969108581543, Neurons: 51, Grad norm: 1.142e+01\n",
      "Epoch 5052, Loss: 62.1969108581543, Neurons: 51, Grad norm: 1.142e+01\n",
      "Epoch 5053, Loss: 62.09769821166992, Neurons: 51, Grad norm: 1.138e+01\n",
      "Epoch 5053, Loss: 62.09769821166992, Neurons: 51, Grad norm: 1.138e+01\n",
      "Epoch 5054, Loss: 61.997867584228516, Neurons: 51, Grad norm: 1.135e+01\n",
      "Epoch 5054, Loss: 61.997867584228516, Neurons: 51, Grad norm: 1.135e+01\n",
      "Epoch 5055, Loss: 61.89739990234375, Neurons: 51, Grad norm: 1.134e+01\n",
      "Epoch 5055, Loss: 61.89739990234375, Neurons: 51, Grad norm: 1.134e+01\n",
      "Epoch 5056, Loss: 61.79630661010742, Neurons: 51, Grad norm: 1.133e+01\n",
      "Epoch 5056, Loss: 61.79630661010742, Neurons: 51, Grad norm: 1.133e+01\n",
      "Epoch 5057, Loss: 61.69465255737305, Neurons: 51, Grad norm: 1.129e+01\n",
      "Epoch 5057, Loss: 61.69465255737305, Neurons: 51, Grad norm: 1.129e+01\n",
      "Epoch 5058, Loss: 61.592384338378906, Neurons: 51, Grad norm: 1.126e+01\n",
      "Epoch 5058, Loss: 61.592384338378906, Neurons: 51, Grad norm: 1.126e+01\n",
      "Epoch 5059, Loss: 61.48956298828125, Neurons: 51, Grad norm: 1.125e+01\n",
      "Epoch 5059, Loss: 61.48956298828125, Neurons: 51, Grad norm: 1.125e+01\n",
      "Epoch 5060, Loss: 61.386173248291016, Neurons: 51, Grad norm: 1.124e+01\n",
      "Epoch 5060, Loss: 61.386173248291016, Neurons: 51, Grad norm: 1.124e+01\n",
      "Epoch 5061, Loss: 61.28226089477539, Neurons: 51, Grad norm: 1.120e+01\n",
      "Epoch 5061, Loss: 61.28226089477539, Neurons: 51, Grad norm: 1.120e+01\n",
      "Epoch 5062, Loss: 61.17780303955078, Neurons: 51, Grad norm: 1.117e+01\n",
      "Epoch 5062, Loss: 61.17780303955078, Neurons: 51, Grad norm: 1.117e+01\n",
      "Epoch 5063, Loss: 61.07283020019531, Neurons: 51, Grad norm: 1.116e+01\n",
      "Epoch 5063, Loss: 61.07283020019531, Neurons: 51, Grad norm: 1.116e+01\n",
      "Epoch 5064, Loss: 60.96735382080078, Neurons: 51, Grad norm: 1.114e+01\n",
      "Epoch 5064, Loss: 60.96735382080078, Neurons: 51, Grad norm: 1.114e+01\n",
      "Epoch 5065, Loss: 60.861419677734375, Neurons: 51, Grad norm: 1.111e+01\n",
      "Epoch 5065, Loss: 60.861419677734375, Neurons: 51, Grad norm: 1.111e+01\n",
      "Epoch 5066, Loss: 60.7549934387207, Neurons: 51, Grad norm: 1.109e+01\n",
      "Epoch 5066, Loss: 60.7549934387207, Neurons: 51, Grad norm: 1.109e+01\n",
      "Epoch 5067, Loss: 60.648128509521484, Neurons: 51, Grad norm: 1.107e+01\n",
      "Epoch 5067, Loss: 60.648128509521484, Neurons: 51, Grad norm: 1.107e+01\n",
      "Epoch 5068, Loss: 60.54078674316406, Neurons: 51, Grad norm: 1.105e+01\n",
      "Epoch 5068, Loss: 60.54078674316406, Neurons: 51, Grad norm: 1.105e+01\n",
      "Epoch 5069, Loss: 60.43301010131836, Neurons: 51, Grad norm: 1.102e+01\n",
      "Epoch 5069, Loss: 60.43301010131836, Neurons: 51, Grad norm: 1.102e+01\n",
      "Epoch 5070, Loss: 60.324806213378906, Neurons: 51, Grad norm: 1.100e+01\n",
      "Epoch 5070, Loss: 60.324806213378906, Neurons: 51, Grad norm: 1.100e+01\n",
      "Epoch 5071, Loss: 60.21617889404297, Neurons: 51, Grad norm: 1.098e+01\n",
      "Epoch 5071, Loss: 60.21617889404297, Neurons: 51, Grad norm: 1.098e+01\n",
      "Epoch 5072, Loss: 60.10714340209961, Neurons: 51, Grad norm: 1.096e+01\n",
      "Epoch 5072, Loss: 60.10714340209961, Neurons: 51, Grad norm: 1.096e+01\n",
      "Epoch 5073, Loss: 59.99767303466797, Neurons: 51, Grad norm: 1.093e+01\n",
      "Epoch 5073, Loss: 59.99767303466797, Neurons: 51, Grad norm: 1.093e+01\n",
      "Epoch 5074, Loss: 59.88779067993164, Neurons: 51, Grad norm: 1.091e+01\n",
      "Epoch 5074, Loss: 59.88779067993164, Neurons: 51, Grad norm: 1.091e+01\n",
      "Epoch 5075, Loss: 59.77753829956055, Neurons: 51, Grad norm: 1.089e+01\n",
      "Epoch 5075, Loss: 59.77753829956055, Neurons: 51, Grad norm: 1.089e+01\n",
      "Epoch 5076, Loss: 59.66687774658203, Neurons: 51, Grad norm: 1.087e+01\n",
      "Epoch 5076, Loss: 59.66687774658203, Neurons: 51, Grad norm: 1.087e+01\n",
      "Epoch 5077, Loss: 59.55584716796875, Neurons: 51, Grad norm: 1.084e+01\n",
      "Epoch 5077, Loss: 59.55584716796875, Neurons: 51, Grad norm: 1.084e+01\n",
      "Epoch 5078, Loss: 59.444454193115234, Neurons: 51, Grad norm: 1.082e+01\n",
      "Epoch 5078, Loss: 59.444454193115234, Neurons: 51, Grad norm: 1.082e+01\n",
      "Epoch 5079, Loss: 59.33268356323242, Neurons: 51, Grad norm: 1.081e+01\n",
      "Epoch 5079, Loss: 59.33268356323242, Neurons: 51, Grad norm: 1.081e+01\n",
      "Epoch 5080, Loss: 59.220577239990234, Neurons: 51, Grad norm: 1.079e+01\n",
      "Epoch 5080, Loss: 59.220577239990234, Neurons: 51, Grad norm: 1.079e+01\n",
      "Epoch 5081, Loss: 59.10811996459961, Neurons: 51, Grad norm: 1.075e+01\n",
      "Epoch 5081, Loss: 59.10811996459961, Neurons: 51, Grad norm: 1.075e+01\n",
      "Epoch 5082, Loss: 58.99531555175781, Neurons: 51, Grad norm: 1.074e+01\n",
      "Epoch 5082, Loss: 58.99531555175781, Neurons: 51, Grad norm: 1.074e+01\n",
      "Epoch 5083, Loss: 58.88215255737305, Neurons: 51, Grad norm: 1.073e+01\n",
      "Epoch 5083, Loss: 58.88215255737305, Neurons: 51, Grad norm: 1.073e+01\n",
      "Epoch 5084, Loss: 58.768646240234375, Neurons: 51, Grad norm: 1.069e+01\n",
      "Epoch 5084, Loss: 58.768646240234375, Neurons: 51, Grad norm: 1.069e+01\n",
      "Epoch 5085, Loss: 58.654808044433594, Neurons: 51, Grad norm: 1.067e+01\n",
      "Epoch 5085, Loss: 58.654808044433594, Neurons: 51, Grad norm: 1.067e+01\n",
      "Epoch 5086, Loss: 58.5406379699707, Neurons: 51, Grad norm: 1.066e+01\n",
      "Epoch 5086, Loss: 58.5406379699707, Neurons: 51, Grad norm: 1.066e+01\n",
      "Epoch 5087, Loss: 58.42610549926758, Neurons: 51, Grad norm: 1.064e+01\n",
      "Epoch 5087, Loss: 58.42610549926758, Neurons: 51, Grad norm: 1.064e+01\n",
      "Epoch 5088, Loss: 58.31125259399414, Neurons: 51, Grad norm: 1.061e+01\n",
      "Epoch 5088, Loss: 58.31125259399414, Neurons: 51, Grad norm: 1.061e+01\n",
      "Epoch 5089, Loss: 58.19606399536133, Neurons: 51, Grad norm: 1.059e+01\n",
      "Epoch 5089, Loss: 58.19606399536133, Neurons: 51, Grad norm: 1.059e+01\n",
      "Epoch 5090, Loss: 58.080535888671875, Neurons: 51, Grad norm: 1.058e+01\n",
      "Epoch 5090, Loss: 58.080535888671875, Neurons: 51, Grad norm: 1.058e+01\n",
      "Epoch 5091, Loss: 57.964683532714844, Neurons: 51, Grad norm: 1.056e+01\n",
      "Epoch 5091, Loss: 57.964683532714844, Neurons: 51, Grad norm: 1.056e+01\n",
      "Epoch 5092, Loss: 57.84853744506836, Neurons: 51, Grad norm: 1.053e+01\n",
      "Epoch 5092, Loss: 57.84853744506836, Neurons: 51, Grad norm: 1.053e+01\n",
      "Epoch 5093, Loss: 57.7320556640625, Neurons: 51, Grad norm: 1.051e+01\n",
      "Epoch 5093, Loss: 57.7320556640625, Neurons: 51, Grad norm: 1.051e+01\n",
      "Epoch 5094, Loss: 57.61525344848633, Neurons: 51, Grad norm: 1.050e+01\n",
      "Epoch 5094, Loss: 57.61525344848633, Neurons: 51, Grad norm: 1.050e+01\n",
      "Epoch 5095, Loss: 57.49808883666992, Neurons: 51, Grad norm: 1.048e+01\n",
      "Epoch 5095, Loss: 57.49808883666992, Neurons: 51, Grad norm: 1.048e+01\n",
      "Epoch 5096, Loss: 57.38056564331055, Neurons: 51, Grad norm: 1.046e+01\n",
      "Epoch 5096, Loss: 57.38056564331055, Neurons: 51, Grad norm: 1.046e+01\n",
      "Epoch 5097, Loss: 57.262691497802734, Neurons: 51, Grad norm: 1.045e+01\n",
      "Epoch 5097, Loss: 57.262691497802734, Neurons: 51, Grad norm: 1.045e+01\n",
      "Epoch 5098, Loss: 57.14443588256836, Neurons: 51, Grad norm: 1.044e+01\n",
      "Epoch 5098, Loss: 57.14443588256836, Neurons: 51, Grad norm: 1.044e+01\n",
      "Epoch 5099, Loss: 57.025814056396484, Neurons: 51, Grad norm: 1.040e+01\n",
      "Epoch 5099, Loss: 57.025814056396484, Neurons: 51, Grad norm: 1.040e+01\n",
      "Epoch 5099, Test loss: 53.8419075012207\n",
      "Epoch 5099, Test loss: 53.8419075012207\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "network shape updated to :[21, 30, 1]\n",
      "network shape updated to :[21, 30, 1]\n",
      "Epoch 5100, Loss: 56.90668869018555, Neurons: 52, Grad norm: 1.078e+01\n",
      "Epoch 5100, Loss: 56.90668869018555, Neurons: 52, Grad norm: 1.078e+01\n",
      "Epoch 5101, Loss: 56.87654113769531, Neurons: 52, Grad norm: 1.052e+01\n",
      "Epoch 5101, Loss: 56.87654113769531, Neurons: 52, Grad norm: 1.052e+01\n",
      "Epoch 5102, Loss: 56.84434509277344, Neurons: 52, Grad norm: 1.053e+01\n",
      "Epoch 5102, Loss: 56.84434509277344, Neurons: 52, Grad norm: 1.053e+01\n",
      "Epoch 5103, Loss: 56.81131362915039, Neurons: 52, Grad norm: 1.038e+01\n",
      "Epoch 5103, Loss: 56.81131362915039, Neurons: 52, Grad norm: 1.038e+01\n",
      "Epoch 5104, Loss: 56.77686309814453, Neurons: 52, Grad norm: 1.044e+01\n",
      "Epoch 5104, Loss: 56.77686309814453, Neurons: 52, Grad norm: 1.044e+01\n",
      "Epoch 5105, Loss: 56.74115753173828, Neurons: 52, Grad norm: 1.049e+01\n",
      "Epoch 5105, Loss: 56.74115753173828, Neurons: 52, Grad norm: 1.049e+01\n",
      "Epoch 5106, Loss: 56.70376968383789, Neurons: 52, Grad norm: 1.038e+01\n",
      "Epoch 5106, Loss: 56.70376968383789, Neurons: 52, Grad norm: 1.038e+01\n",
      "Epoch 5107, Loss: 56.664695739746094, Neurons: 52, Grad norm: 1.028e+01\n",
      "Epoch 5107, Loss: 56.664695739746094, Neurons: 52, Grad norm: 1.028e+01\n",
      "Epoch 5108, Loss: 56.62429428100586, Neurons: 52, Grad norm: 1.030e+01\n",
      "Epoch 5108, Loss: 56.62429428100586, Neurons: 52, Grad norm: 1.030e+01\n",
      "Epoch 5109, Loss: 56.5825080871582, Neurons: 52, Grad norm: 1.029e+01\n",
      "Epoch 5109, Loss: 56.5825080871582, Neurons: 52, Grad norm: 1.029e+01\n",
      "Epoch 5110, Loss: 56.53910446166992, Neurons: 52, Grad norm: 1.031e+01\n",
      "Epoch 5110, Loss: 56.53910446166992, Neurons: 52, Grad norm: 1.031e+01\n",
      "Epoch 5111, Loss: 56.494384765625, Neurons: 52, Grad norm: 1.032e+01\n",
      "Epoch 5111, Loss: 56.494384765625, Neurons: 52, Grad norm: 1.032e+01\n",
      "Epoch 5112, Loss: 56.448360443115234, Neurons: 52, Grad norm: 1.027e+01\n",
      "Epoch 5112, Loss: 56.448360443115234, Neurons: 52, Grad norm: 1.027e+01\n",
      "Epoch 5113, Loss: 56.40080642700195, Neurons: 52, Grad norm: 1.022e+01\n",
      "Epoch 5113, Loss: 56.40080642700195, Neurons: 52, Grad norm: 1.022e+01\n",
      "Epoch 5114, Loss: 56.35187911987305, Neurons: 52, Grad norm: 1.021e+01\n",
      "Epoch 5114, Loss: 56.35187911987305, Neurons: 52, Grad norm: 1.021e+01\n",
      "Epoch 5115, Loss: 56.301631927490234, Neurons: 52, Grad norm: 1.019e+01\n",
      "Epoch 5115, Loss: 56.301631927490234, Neurons: 52, Grad norm: 1.019e+01\n",
      "Epoch 5116, Loss: 56.25002670288086, Neurons: 52, Grad norm: 1.019e+01\n",
      "Epoch 5116, Loss: 56.25002670288086, Neurons: 52, Grad norm: 1.019e+01\n",
      "Epoch 5117, Loss: 56.1971435546875, Neurons: 52, Grad norm: 1.022e+01\n",
      "Epoch 5117, Loss: 56.1971435546875, Neurons: 52, Grad norm: 1.022e+01\n",
      "Epoch 5118, Loss: 56.14299011230469, Neurons: 52, Grad norm: 1.020e+01\n",
      "Epoch 5118, Loss: 56.14299011230469, Neurons: 52, Grad norm: 1.020e+01\n",
      "Epoch 5119, Loss: 56.0875244140625, Neurons: 52, Grad norm: 1.017e+01\n",
      "Epoch 5119, Loss: 56.0875244140625, Neurons: 52, Grad norm: 1.017e+01\n",
      "Epoch 5120, Loss: 56.030784606933594, Neurons: 52, Grad norm: 1.013e+01\n",
      "Epoch 5120, Loss: 56.030784606933594, Neurons: 52, Grad norm: 1.013e+01\n",
      "Epoch 5121, Loss: 55.97285461425781, Neurons: 52, Grad norm: 1.013e+01\n",
      "Epoch 5121, Loss: 55.97285461425781, Neurons: 52, Grad norm: 1.013e+01\n",
      "Epoch 5122, Loss: 55.91372299194336, Neurons: 52, Grad norm: 1.012e+01\n",
      "Epoch 5122, Loss: 55.91372299194336, Neurons: 52, Grad norm: 1.012e+01\n",
      "Epoch 5123, Loss: 55.853355407714844, Neurons: 52, Grad norm: 1.013e+01\n",
      "Epoch 5123, Loss: 55.853355407714844, Neurons: 52, Grad norm: 1.013e+01\n",
      "Epoch 5124, Loss: 55.79187774658203, Neurons: 52, Grad norm: 1.012e+01\n",
      "Epoch 5124, Loss: 55.79187774658203, Neurons: 52, Grad norm: 1.012e+01\n",
      "Epoch 5125, Loss: 55.72926712036133, Neurons: 52, Grad norm: 1.010e+01\n",
      "Epoch 5125, Loss: 55.72926712036133, Neurons: 52, Grad norm: 1.010e+01\n",
      "Epoch 5126, Loss: 55.665523529052734, Neurons: 52, Grad norm: 1.008e+01\n",
      "Epoch 5126, Loss: 55.665523529052734, Neurons: 52, Grad norm: 1.008e+01\n",
      "Epoch 5127, Loss: 55.6006965637207, Neurons: 52, Grad norm: 1.006e+01\n",
      "Epoch 5127, Loss: 55.6006965637207, Neurons: 52, Grad norm: 1.006e+01\n",
      "Epoch 5128, Loss: 55.534767150878906, Neurons: 52, Grad norm: 1.006e+01\n",
      "Epoch 5128, Loss: 55.534767150878906, Neurons: 52, Grad norm: 1.006e+01\n",
      "Epoch 5129, Loss: 55.467796325683594, Neurons: 52, Grad norm: 1.006e+01\n",
      "Epoch 5129, Loss: 55.467796325683594, Neurons: 52, Grad norm: 1.006e+01\n",
      "Epoch 5130, Loss: 55.39984893798828, Neurons: 52, Grad norm: 1.006e+01\n",
      "Epoch 5130, Loss: 55.39984893798828, Neurons: 52, Grad norm: 1.006e+01\n",
      "Epoch 5131, Loss: 55.330848693847656, Neurons: 52, Grad norm: 1.002e+01\n",
      "Epoch 5131, Loss: 55.330848693847656, Neurons: 52, Grad norm: 1.002e+01\n",
      "Epoch 5132, Loss: 55.26085662841797, Neurons: 52, Grad norm: 1.001e+01\n",
      "Epoch 5132, Loss: 55.26085662841797, Neurons: 52, Grad norm: 1.001e+01\n",
      "Epoch 5133, Loss: 55.18988037109375, Neurons: 52, Grad norm: 1.000e+01\n",
      "Epoch 5133, Loss: 55.18988037109375, Neurons: 52, Grad norm: 1.000e+01\n",
      "Epoch 5134, Loss: 55.11795425415039, Neurons: 52, Grad norm: 9.994e+00\n",
      "Epoch 5134, Loss: 55.11795425415039, Neurons: 52, Grad norm: 9.994e+00\n",
      "Epoch 5135, Loss: 55.04505920410156, Neurons: 52, Grad norm: 1.000e+01\n",
      "Epoch 5135, Loss: 55.04505920410156, Neurons: 52, Grad norm: 1.000e+01\n",
      "Epoch 5136, Loss: 54.97124481201172, Neurons: 52, Grad norm: 9.987e+00\n",
      "Epoch 5136, Loss: 54.97124481201172, Neurons: 52, Grad norm: 9.987e+00\n",
      "Epoch 5137, Loss: 54.89651870727539, Neurons: 52, Grad norm: 9.959e+00\n",
      "Epoch 5137, Loss: 54.89651870727539, Neurons: 52, Grad norm: 9.959e+00\n",
      "Epoch 5138, Loss: 54.82088851928711, Neurons: 52, Grad norm: 9.942e+00\n",
      "Epoch 5138, Loss: 54.82088851928711, Neurons: 52, Grad norm: 9.942e+00\n",
      "Epoch 5139, Loss: 54.7443733215332, Neurons: 52, Grad norm: 9.936e+00\n",
      "Epoch 5139, Loss: 54.7443733215332, Neurons: 52, Grad norm: 9.936e+00\n",
      "Epoch 5140, Loss: 54.666996002197266, Neurons: 52, Grad norm: 9.935e+00\n",
      "Epoch 5140, Loss: 54.666996002197266, Neurons: 52, Grad norm: 9.935e+00\n",
      "Epoch 5141, Loss: 54.588783264160156, Neurons: 52, Grad norm: 9.920e+00\n",
      "Epoch 5141, Loss: 54.588783264160156, Neurons: 52, Grad norm: 9.920e+00\n",
      "Epoch 5142, Loss: 54.50971221923828, Neurons: 52, Grad norm: 9.899e+00\n",
      "Epoch 5142, Loss: 54.50971221923828, Neurons: 52, Grad norm: 9.899e+00\n",
      "Epoch 5143, Loss: 54.4297981262207, Neurons: 52, Grad norm: 9.888e+00\n",
      "Epoch 5143, Loss: 54.4297981262207, Neurons: 52, Grad norm: 9.888e+00\n",
      "Epoch 5144, Loss: 54.349082946777344, Neurons: 52, Grad norm: 9.875e+00\n",
      "Epoch 5144, Loss: 54.349082946777344, Neurons: 52, Grad norm: 9.875e+00\n",
      "Epoch 5145, Loss: 54.2675666809082, Neurons: 52, Grad norm: 9.868e+00\n",
      "Epoch 5145, Loss: 54.2675666809082, Neurons: 52, Grad norm: 9.868e+00\n",
      "Epoch 5146, Loss: 54.18525695800781, Neurons: 52, Grad norm: 9.861e+00\n",
      "Epoch 5146, Loss: 54.18525695800781, Neurons: 52, Grad norm: 9.861e+00\n",
      "Epoch 5147, Loss: 54.10218048095703, Neurons: 52, Grad norm: 9.847e+00\n",
      "Epoch 5147, Loss: 54.10218048095703, Neurons: 52, Grad norm: 9.847e+00\n",
      "Epoch 5148, Loss: 54.01833724975586, Neurons: 52, Grad norm: 9.829e+00\n",
      "Epoch 5148, Loss: 54.01833724975586, Neurons: 52, Grad norm: 9.829e+00\n",
      "Epoch 5149, Loss: 53.93375778198242, Neurons: 52, Grad norm: 9.817e+00\n",
      "Epoch 5149, Loss: 53.93375778198242, Neurons: 52, Grad norm: 9.817e+00\n",
      "Epoch 5150, Loss: 53.84844207763672, Neurons: 52, Grad norm: 9.810e+00\n",
      "Epoch 5150, Loss: 53.84844207763672, Neurons: 52, Grad norm: 9.810e+00\n",
      "Epoch 5151, Loss: 53.762428283691406, Neurons: 52, Grad norm: 9.797e+00\n",
      "Epoch 5151, Loss: 53.762428283691406, Neurons: 52, Grad norm: 9.797e+00\n",
      "Epoch 5152, Loss: 53.67573165893555, Neurons: 52, Grad norm: 9.778e+00\n",
      "Epoch 5152, Loss: 53.67573165893555, Neurons: 52, Grad norm: 9.778e+00\n",
      "Epoch 5153, Loss: 53.58837890625, Neurons: 52, Grad norm: 9.767e+00\n",
      "Epoch 5153, Loss: 53.58837890625, Neurons: 52, Grad norm: 9.767e+00\n",
      "Epoch 5154, Loss: 53.5003662109375, Neurons: 52, Grad norm: 9.753e+00\n",
      "Epoch 5154, Loss: 53.5003662109375, Neurons: 52, Grad norm: 9.753e+00\n",
      "Epoch 5155, Loss: 53.41175079345703, Neurons: 52, Grad norm: 9.742e+00\n",
      "Epoch 5155, Loss: 53.41175079345703, Neurons: 52, Grad norm: 9.742e+00\n",
      "Epoch 5156, Loss: 53.32252502441406, Neurons: 52, Grad norm: 9.732e+00\n",
      "Epoch 5156, Loss: 53.32252502441406, Neurons: 52, Grad norm: 9.732e+00\n",
      "Epoch 5157, Loss: 53.23276138305664, Neurons: 52, Grad norm: 9.713e+00\n",
      "Epoch 5157, Loss: 53.23276138305664, Neurons: 52, Grad norm: 9.713e+00\n",
      "Epoch 5158, Loss: 53.14247131347656, Neurons: 52, Grad norm: 9.705e+00\n",
      "Epoch 5158, Loss: 53.14247131347656, Neurons: 52, Grad norm: 9.705e+00\n",
      "Epoch 5159, Loss: 53.051673889160156, Neurons: 52, Grad norm: 9.687e+00\n",
      "Epoch 5159, Loss: 53.051673889160156, Neurons: 52, Grad norm: 9.687e+00\n",
      "Epoch 5160, Loss: 52.96039962768555, Neurons: 52, Grad norm: 9.670e+00\n",
      "Epoch 5160, Loss: 52.96039962768555, Neurons: 52, Grad norm: 9.670e+00\n",
      "Epoch 5161, Loss: 52.86874008178711, Neurons: 52, Grad norm: 9.654e+00\n",
      "Epoch 5161, Loss: 52.86874008178711, Neurons: 52, Grad norm: 9.654e+00\n",
      "Epoch 5162, Loss: 52.77666473388672, Neurons: 52, Grad norm: 9.644e+00\n",
      "Epoch 5162, Loss: 52.77666473388672, Neurons: 52, Grad norm: 9.644e+00\n",
      "Epoch 5163, Loss: 52.68421936035156, Neurons: 52, Grad norm: 9.626e+00\n",
      "Epoch 5163, Loss: 52.68421936035156, Neurons: 52, Grad norm: 9.626e+00\n",
      "Epoch 5164, Loss: 52.591407775878906, Neurons: 52, Grad norm: 9.611e+00\n",
      "Epoch 5164, Loss: 52.591407775878906, Neurons: 52, Grad norm: 9.611e+00\n",
      "Epoch 5165, Loss: 52.49823760986328, Neurons: 52, Grad norm: 9.599e+00\n",
      "Epoch 5165, Loss: 52.49823760986328, Neurons: 52, Grad norm: 9.599e+00\n",
      "Epoch 5166, Loss: 52.404727935791016, Neurons: 52, Grad norm: 9.586e+00\n",
      "Epoch 5166, Loss: 52.404727935791016, Neurons: 52, Grad norm: 9.586e+00\n",
      "Epoch 5167, Loss: 52.31087875366211, Neurons: 52, Grad norm: 9.573e+00\n",
      "Epoch 5167, Loss: 52.31087875366211, Neurons: 52, Grad norm: 9.573e+00\n",
      "Epoch 5168, Loss: 52.216670989990234, Neurons: 52, Grad norm: 9.557e+00\n",
      "Epoch 5168, Loss: 52.216670989990234, Neurons: 52, Grad norm: 9.557e+00\n",
      "Epoch 5169, Loss: 52.12208938598633, Neurons: 52, Grad norm: 9.549e+00\n",
      "Epoch 5169, Loss: 52.12208938598633, Neurons: 52, Grad norm: 9.549e+00\n",
      "Epoch 5170, Loss: 52.0270881652832, Neurons: 52, Grad norm: 9.530e+00\n",
      "Epoch 5170, Loss: 52.0270881652832, Neurons: 52, Grad norm: 9.530e+00\n",
      "Epoch 5171, Loss: 51.93167495727539, Neurons: 52, Grad norm: 9.520e+00\n",
      "Epoch 5171, Loss: 51.93167495727539, Neurons: 52, Grad norm: 9.520e+00\n",
      "Epoch 5172, Loss: 51.835777282714844, Neurons: 52, Grad norm: 9.509e+00\n",
      "Epoch 5172, Loss: 51.835777282714844, Neurons: 52, Grad norm: 9.509e+00\n",
      "Epoch 5173, Loss: 51.73944091796875, Neurons: 52, Grad norm: 9.498e+00\n",
      "Epoch 5173, Loss: 51.73944091796875, Neurons: 52, Grad norm: 9.498e+00\n",
      "Epoch 5174, Loss: 51.642581939697266, Neurons: 52, Grad norm: 9.482e+00\n",
      "Epoch 5174, Loss: 51.642581939697266, Neurons: 52, Grad norm: 9.482e+00\n",
      "Epoch 5175, Loss: 51.54521942138672, Neurons: 52, Grad norm: 9.472e+00\n",
      "Epoch 5175, Loss: 51.54521942138672, Neurons: 52, Grad norm: 9.472e+00\n",
      "Epoch 5176, Loss: 51.44731903076172, Neurons: 52, Grad norm: 9.467e+00\n",
      "Epoch 5176, Loss: 51.44731903076172, Neurons: 52, Grad norm: 9.467e+00\n",
      "Epoch 5177, Loss: 51.348899841308594, Neurons: 52, Grad norm: 9.456e+00\n",
      "Epoch 5177, Loss: 51.348899841308594, Neurons: 52, Grad norm: 9.456e+00\n",
      "Epoch 5178, Loss: 51.249916076660156, Neurons: 52, Grad norm: 9.444e+00\n",
      "Epoch 5178, Loss: 51.249916076660156, Neurons: 52, Grad norm: 9.444e+00\n",
      "Epoch 5179, Loss: 51.1503791809082, Neurons: 52, Grad norm: 9.428e+00\n",
      "Epoch 5179, Loss: 51.1503791809082, Neurons: 52, Grad norm: 9.428e+00\n",
      "Epoch 5180, Loss: 51.050270080566406, Neurons: 52, Grad norm: 9.426e+00\n",
      "Epoch 5180, Loss: 51.050270080566406, Neurons: 52, Grad norm: 9.426e+00\n",
      "Epoch 5181, Loss: 50.949615478515625, Neurons: 52, Grad norm: 9.411e+00\n",
      "Epoch 5181, Loss: 50.949615478515625, Neurons: 52, Grad norm: 9.411e+00\n",
      "Epoch 5182, Loss: 50.848365783691406, Neurons: 52, Grad norm: 9.405e+00\n",
      "Epoch 5182, Loss: 50.848365783691406, Neurons: 52, Grad norm: 9.405e+00\n",
      "Epoch 5183, Loss: 50.746551513671875, Neurons: 52, Grad norm: 9.393e+00\n",
      "Epoch 5183, Loss: 50.746551513671875, Neurons: 52, Grad norm: 9.393e+00\n",
      "Epoch 5184, Loss: 50.6441535949707, Neurons: 52, Grad norm: 9.381e+00\n",
      "Epoch 5184, Loss: 50.6441535949707, Neurons: 52, Grad norm: 9.381e+00\n",
      "Epoch 5185, Loss: 50.54120635986328, Neurons: 52, Grad norm: 9.378e+00\n",
      "Epoch 5185, Loss: 50.54120635986328, Neurons: 52, Grad norm: 9.378e+00\n",
      "Epoch 5186, Loss: 50.43766784667969, Neurons: 52, Grad norm: 9.381e+00\n",
      "Epoch 5186, Loss: 50.43766784667969, Neurons: 52, Grad norm: 9.381e+00\n",
      "Epoch 5187, Loss: 50.33355712890625, Neurons: 52, Grad norm: 9.355e+00\n",
      "Epoch 5187, Loss: 50.33355712890625, Neurons: 52, Grad norm: 9.355e+00\n",
      "Epoch 5188, Loss: 50.228878021240234, Neurons: 52, Grad norm: 9.347e+00\n",
      "Epoch 5188, Loss: 50.228878021240234, Neurons: 52, Grad norm: 9.347e+00\n",
      "Epoch 5189, Loss: 50.12361145019531, Neurons: 52, Grad norm: 9.340e+00\n",
      "Epoch 5189, Loss: 50.12361145019531, Neurons: 52, Grad norm: 9.340e+00\n",
      "Epoch 5190, Loss: 50.01778793334961, Neurons: 52, Grad norm: 9.332e+00\n",
      "Epoch 5190, Loss: 50.01778793334961, Neurons: 52, Grad norm: 9.332e+00\n",
      "Epoch 5191, Loss: 49.911376953125, Neurons: 52, Grad norm: 9.324e+00\n",
      "Epoch 5191, Loss: 49.911376953125, Neurons: 52, Grad norm: 9.324e+00\n",
      "Epoch 5192, Loss: 49.80440902709961, Neurons: 52, Grad norm: 9.455e+00\n",
      "Epoch 5192, Loss: 49.80440902709961, Neurons: 52, Grad norm: 9.455e+00\n",
      "Epoch 5193, Loss: 49.69763946533203, Neurons: 52, Grad norm: 9.538e+00\n",
      "Epoch 5193, Loss: 49.69763946533203, Neurons: 52, Grad norm: 9.538e+00\n",
      "Epoch 5194, Loss: 49.59044647216797, Neurons: 52, Grad norm: 9.387e+00\n",
      "Epoch 5194, Loss: 49.59044647216797, Neurons: 52, Grad norm: 9.387e+00\n",
      "Epoch 5195, Loss: 49.481868743896484, Neurons: 52, Grad norm: 9.326e+00\n",
      "Epoch 5195, Loss: 49.481868743896484, Neurons: 52, Grad norm: 9.326e+00\n",
      "Epoch 5196, Loss: 49.37335205078125, Neurons: 52, Grad norm: 9.278e+00\n",
      "Epoch 5196, Loss: 49.37335205078125, Neurons: 52, Grad norm: 9.278e+00\n",
      "Epoch 5197, Loss: 49.264549255371094, Neurons: 52, Grad norm: 9.290e+00\n",
      "Epoch 5197, Loss: 49.264549255371094, Neurons: 52, Grad norm: 9.290e+00\n",
      "Epoch 5198, Loss: 49.15520095825195, Neurons: 52, Grad norm: 9.311e+00\n",
      "Epoch 5198, Loss: 49.15520095825195, Neurons: 52, Grad norm: 9.311e+00\n",
      "Epoch 5199, Loss: 49.045352935791016, Neurons: 52, Grad norm: 9.259e+00\n",
      "Epoch 5199, Loss: 49.045352935791016, Neurons: 52, Grad norm: 9.259e+00\n",
      "Epoch 5199, Test loss: 46.21709442138672\n",
      "Epoch 5199, Test loss: 46.21709442138672\n",
      "Added neuron to hidden layer 1 with activation relu\n",
      "Added neuron to hidden layer 1 with activation relu\n",
      "network shape updated to :[22, 30, 1]\n",
      "network shape updated to :[22, 30, 1]\n",
      "Epoch 5200, Loss: 49.13336944580078, Neurons: 53, Grad norm: 2.081e+01\n",
      "Epoch 5200, Loss: 49.13336944580078, Neurons: 53, Grad norm: 2.081e+01\n",
      "Epoch 5201, Loss: 49.05354309082031, Neurons: 53, Grad norm: 1.651e+01\n",
      "Epoch 5201, Loss: 49.05354309082031, Neurons: 53, Grad norm: 1.651e+01\n",
      "Epoch 5202, Loss: 48.99048614501953, Neurons: 53, Grad norm: 1.401e+01\n",
      "Epoch 5202, Loss: 48.99048614501953, Neurons: 53, Grad norm: 1.401e+01\n",
      "Epoch 5203, Loss: 48.939659118652344, Neurons: 53, Grad norm: 1.184e+01\n",
      "Epoch 5203, Loss: 48.939659118652344, Neurons: 53, Grad norm: 1.184e+01\n",
      "Epoch 5204, Loss: 48.89813232421875, Neurons: 53, Grad norm: 1.079e+01\n",
      "Epoch 5204, Loss: 48.89813232421875, Neurons: 53, Grad norm: 1.079e+01\n",
      "Epoch 5205, Loss: 48.86333084106445, Neurons: 53, Grad norm: 1.069e+01\n",
      "Epoch 5205, Loss: 48.86333084106445, Neurons: 53, Grad norm: 1.069e+01\n",
      "Epoch 5206, Loss: 48.83155059814453, Neurons: 53, Grad norm: 1.078e+01\n",
      "Epoch 5206, Loss: 48.83155059814453, Neurons: 53, Grad norm: 1.078e+01\n",
      "Epoch 5207, Loss: 48.7997932434082, Neurons: 53, Grad norm: 1.084e+01\n",
      "Epoch 5207, Loss: 48.7997932434082, Neurons: 53, Grad norm: 1.084e+01\n",
      "Epoch 5208, Loss: 48.7665901184082, Neurons: 53, Grad norm: 1.090e+01\n",
      "Epoch 5208, Loss: 48.7665901184082, Neurons: 53, Grad norm: 1.090e+01\n",
      "Epoch 5209, Loss: 48.73149871826172, Neurons: 53, Grad norm: 1.084e+01\n",
      "Epoch 5209, Loss: 48.73149871826172, Neurons: 53, Grad norm: 1.084e+01\n",
      "Epoch 5210, Loss: 48.69466018676758, Neurons: 53, Grad norm: 1.056e+01\n",
      "Epoch 5210, Loss: 48.69466018676758, Neurons: 53, Grad norm: 1.056e+01\n",
      "Epoch 5211, Loss: 48.656463623046875, Neurons: 53, Grad norm: 1.015e+01\n",
      "Epoch 5211, Loss: 48.656463623046875, Neurons: 53, Grad norm: 1.015e+01\n",
      "Epoch 5212, Loss: 48.61751937866211, Neurons: 53, Grad norm: 9.846e+00\n",
      "Epoch 5212, Loss: 48.61751937866211, Neurons: 53, Grad norm: 9.846e+00\n",
      "Epoch 5213, Loss: 48.57828140258789, Neurons: 53, Grad norm: 9.742e+00\n",
      "Epoch 5213, Loss: 48.57828140258789, Neurons: 53, Grad norm: 9.742e+00\n",
      "Epoch 5214, Loss: 48.5389404296875, Neurons: 53, Grad norm: 9.720e+00\n",
      "Epoch 5214, Loss: 48.5389404296875, Neurons: 53, Grad norm: 9.720e+00\n",
      "Epoch 5215, Loss: 48.499332427978516, Neurons: 53, Grad norm: 9.695e+00\n",
      "Epoch 5215, Loss: 48.499332427978516, Neurons: 53, Grad norm: 9.695e+00\n",
      "Epoch 5216, Loss: 48.45924377441406, Neurons: 53, Grad norm: 9.678e+00\n",
      "Epoch 5216, Loss: 48.45924377441406, Neurons: 53, Grad norm: 9.678e+00\n",
      "Epoch 5217, Loss: 48.418479919433594, Neurons: 53, Grad norm: 9.683e+00\n",
      "Epoch 5217, Loss: 48.418479919433594, Neurons: 53, Grad norm: 9.683e+00\n",
      "Epoch 5218, Loss: 48.37687683105469, Neurons: 53, Grad norm: 9.671e+00\n",
      "Epoch 5218, Loss: 48.37687683105469, Neurons: 53, Grad norm: 9.671e+00\n",
      "Epoch 5219, Loss: 48.33432388305664, Neurons: 53, Grad norm: 9.662e+00\n",
      "Epoch 5219, Loss: 48.33432388305664, Neurons: 53, Grad norm: 9.662e+00\n",
      "Epoch 5220, Loss: 48.29081344604492, Neurons: 53, Grad norm: 9.728e+00\n",
      "Epoch 5220, Loss: 48.29081344604492, Neurons: 53, Grad norm: 9.728e+00\n",
      "Epoch 5221, Loss: 48.24639129638672, Neurons: 53, Grad norm: 9.864e+00\n",
      "Epoch 5221, Loss: 48.24639129638672, Neurons: 53, Grad norm: 9.864e+00\n",
      "Epoch 5222, Loss: 48.20109939575195, Neurons: 53, Grad norm: 9.956e+00\n",
      "Epoch 5222, Loss: 48.20109939575195, Neurons: 53, Grad norm: 9.956e+00\n",
      "Epoch 5223, Loss: 48.1550178527832, Neurons: 53, Grad norm: 9.886e+00\n",
      "Epoch 5223, Loss: 48.1550178527832, Neurons: 53, Grad norm: 9.886e+00\n",
      "Epoch 5224, Loss: 48.108036041259766, Neurons: 53, Grad norm: 9.736e+00\n",
      "Epoch 5224, Loss: 48.108036041259766, Neurons: 53, Grad norm: 9.736e+00\n",
      "Epoch 5225, Loss: 48.06019973754883, Neurons: 53, Grad norm: 9.613e+00\n",
      "Epoch 5225, Loss: 48.06019973754883, Neurons: 53, Grad norm: 9.613e+00\n",
      "Epoch 5226, Loss: 48.011531829833984, Neurons: 53, Grad norm: 9.513e+00\n",
      "Epoch 5226, Loss: 48.011531829833984, Neurons: 53, Grad norm: 9.513e+00\n",
      "Epoch 5227, Loss: 47.9620475769043, Neurons: 53, Grad norm: 9.458e+00\n",
      "Epoch 5227, Loss: 47.9620475769043, Neurons: 53, Grad norm: 9.458e+00\n",
      "Epoch 5228, Loss: 47.91172790527344, Neurons: 53, Grad norm: 9.438e+00\n",
      "Epoch 5228, Loss: 47.91172790527344, Neurons: 53, Grad norm: 9.438e+00\n",
      "Epoch 5229, Loss: 47.86063003540039, Neurons: 53, Grad norm: 9.440e+00\n",
      "Epoch 5229, Loss: 47.86063003540039, Neurons: 53, Grad norm: 9.440e+00\n",
      "Epoch 5230, Loss: 47.80886459350586, Neurons: 53, Grad norm: 9.418e+00\n",
      "Epoch 5230, Loss: 47.80886459350586, Neurons: 53, Grad norm: 9.418e+00\n",
      "Epoch 5231, Loss: 47.7564697265625, Neurons: 53, Grad norm: 9.342e+00\n",
      "Epoch 5231, Loss: 47.7564697265625, Neurons: 53, Grad norm: 9.342e+00\n",
      "Epoch 5232, Loss: 47.703495025634766, Neurons: 53, Grad norm: 9.232e+00\n",
      "Epoch 5232, Loss: 47.703495025634766, Neurons: 53, Grad norm: 9.232e+00\n",
      "Epoch 5233, Loss: 47.64994812011719, Neurons: 53, Grad norm: 9.176e+00\n",
      "Epoch 5233, Loss: 47.64994812011719, Neurons: 53, Grad norm: 9.176e+00\n",
      "Epoch 5234, Loss: 47.59577178955078, Neurons: 53, Grad norm: 9.145e+00\n",
      "Epoch 5234, Loss: 47.59577178955078, Neurons: 53, Grad norm: 9.145e+00\n",
      "Epoch 5235, Loss: 47.540977478027344, Neurons: 53, Grad norm: 9.124e+00\n",
      "Epoch 5235, Loss: 47.540977478027344, Neurons: 53, Grad norm: 9.124e+00\n",
      "Epoch 5236, Loss: 47.4854621887207, Neurons: 53, Grad norm: 9.115e+00\n",
      "Epoch 5236, Loss: 47.4854621887207, Neurons: 53, Grad norm: 9.115e+00\n",
      "Epoch 5237, Loss: 47.429229736328125, Neurons: 53, Grad norm: 9.124e+00\n",
      "Epoch 5237, Loss: 47.429229736328125, Neurons: 53, Grad norm: 9.124e+00\n",
      "Epoch 5238, Loss: 47.37223815917969, Neurons: 53, Grad norm: 9.140e+00\n",
      "Epoch 5238, Loss: 47.37223815917969, Neurons: 53, Grad norm: 9.140e+00\n",
      "Epoch 5239, Loss: 47.314537048339844, Neurons: 53, Grad norm: 9.144e+00\n",
      "Epoch 5239, Loss: 47.314537048339844, Neurons: 53, Grad norm: 9.144e+00\n",
      "Epoch 5240, Loss: 47.25611114501953, Neurons: 53, Grad norm: 9.131e+00\n",
      "Epoch 5240, Loss: 47.25611114501953, Neurons: 53, Grad norm: 9.131e+00\n",
      "Epoch 5241, Loss: 47.19702911376953, Neurons: 53, Grad norm: 9.104e+00\n",
      "Epoch 5241, Loss: 47.19702911376953, Neurons: 53, Grad norm: 9.104e+00\n",
      "Epoch 5242, Loss: 47.13732147216797, Neurons: 53, Grad norm: 9.094e+00\n",
      "Epoch 5242, Loss: 47.13732147216797, Neurons: 53, Grad norm: 9.094e+00\n",
      "Epoch 5243, Loss: 47.07704544067383, Neurons: 53, Grad norm: 9.113e+00\n",
      "Epoch 5243, Loss: 47.07704544067383, Neurons: 53, Grad norm: 9.113e+00\n",
      "Epoch 5244, Loss: 47.0162353515625, Neurons: 53, Grad norm: 9.167e+00\n",
      "Epoch 5244, Loss: 47.0162353515625, Neurons: 53, Grad norm: 9.167e+00\n",
      "Epoch 5245, Loss: 46.95486068725586, Neurons: 53, Grad norm: 9.232e+00\n",
      "Epoch 5245, Loss: 46.95486068725586, Neurons: 53, Grad norm: 9.232e+00\n",
      "Epoch 5246, Loss: 46.892974853515625, Neurons: 53, Grad norm: 9.228e+00\n",
      "Epoch 5246, Loss: 46.892974853515625, Neurons: 53, Grad norm: 9.228e+00\n",
      "Epoch 5247, Loss: 46.83049774169922, Neurons: 53, Grad norm: 9.210e+00\n",
      "Epoch 5247, Loss: 46.83049774169922, Neurons: 53, Grad norm: 9.210e+00\n",
      "Epoch 5248, Loss: 46.767478942871094, Neurons: 53, Grad norm: 9.160e+00\n",
      "Epoch 5248, Loss: 46.767478942871094, Neurons: 53, Grad norm: 9.160e+00\n",
      "Epoch 5249, Loss: 46.703880310058594, Neurons: 53, Grad norm: 9.113e+00\n",
      "Epoch 5249, Loss: 46.703880310058594, Neurons: 53, Grad norm: 9.113e+00\n",
      "Epoch 5250, Loss: 46.639774322509766, Neurons: 53, Grad norm: 9.081e+00\n",
      "Epoch 5250, Loss: 46.639774322509766, Neurons: 53, Grad norm: 9.081e+00\n",
      "Epoch 5251, Loss: 46.57514190673828, Neurons: 53, Grad norm: 9.069e+00\n",
      "Epoch 5251, Loss: 46.57514190673828, Neurons: 53, Grad norm: 9.069e+00\n",
      "Epoch 5252, Loss: 46.510009765625, Neurons: 53, Grad norm: 9.064e+00\n",
      "Epoch 5252, Loss: 46.510009765625, Neurons: 53, Grad norm: 9.064e+00\n",
      "Epoch 5253, Loss: 46.44442367553711, Neurons: 53, Grad norm: 9.069e+00\n",
      "Epoch 5253, Loss: 46.44442367553711, Neurons: 53, Grad norm: 9.069e+00\n",
      "Epoch 5254, Loss: 46.37837600708008, Neurons: 53, Grad norm: 9.045e+00\n",
      "Epoch 5254, Loss: 46.37837600708008, Neurons: 53, Grad norm: 9.045e+00\n",
      "Epoch 5255, Loss: 46.311824798583984, Neurons: 53, Grad norm: 9.020e+00\n",
      "Epoch 5255, Loss: 46.311824798583984, Neurons: 53, Grad norm: 9.020e+00\n",
      "Epoch 5256, Loss: 46.24480056762695, Neurons: 53, Grad norm: 8.989e+00\n",
      "Epoch 5256, Loss: 46.24480056762695, Neurons: 53, Grad norm: 8.989e+00\n",
      "Epoch 5257, Loss: 46.177330017089844, Neurons: 53, Grad norm: 8.954e+00\n",
      "Epoch 5257, Loss: 46.177330017089844, Neurons: 53, Grad norm: 8.954e+00\n",
      "Epoch 5258, Loss: 46.109371185302734, Neurons: 53, Grad norm: 8.940e+00\n",
      "Epoch 5258, Loss: 46.109371185302734, Neurons: 53, Grad norm: 8.940e+00\n",
      "Epoch 5259, Loss: 46.040977478027344, Neurons: 53, Grad norm: 8.925e+00\n",
      "Epoch 5259, Loss: 46.040977478027344, Neurons: 53, Grad norm: 8.925e+00\n",
      "Epoch 5260, Loss: 45.97216033935547, Neurons: 53, Grad norm: 8.925e+00\n",
      "Epoch 5260, Loss: 45.97216033935547, Neurons: 53, Grad norm: 8.925e+00\n",
      "Epoch 5261, Loss: 45.902950286865234, Neurons: 53, Grad norm: 8.931e+00\n",
      "Epoch 5261, Loss: 45.902950286865234, Neurons: 53, Grad norm: 8.931e+00\n",
      "Epoch 5262, Loss: 45.83333969116211, Neurons: 53, Grad norm: 8.923e+00\n",
      "Epoch 5262, Loss: 45.83333969116211, Neurons: 53, Grad norm: 8.923e+00\n",
      "Epoch 5263, Loss: 45.76334762573242, Neurons: 53, Grad norm: 8.901e+00\n",
      "Epoch 5263, Loss: 45.76334762573242, Neurons: 53, Grad norm: 8.901e+00\n",
      "Epoch 5264, Loss: 45.69297409057617, Neurons: 53, Grad norm: 8.890e+00\n",
      "Epoch 5264, Loss: 45.69297409057617, Neurons: 53, Grad norm: 8.890e+00\n",
      "Epoch 5265, Loss: 45.622230529785156, Neurons: 53, Grad norm: 8.875e+00\n",
      "Epoch 5265, Loss: 45.622230529785156, Neurons: 53, Grad norm: 8.875e+00\n",
      "Epoch 5266, Loss: 45.5511360168457, Neurons: 53, Grad norm: 8.870e+00\n",
      "Epoch 5266, Loss: 45.5511360168457, Neurons: 53, Grad norm: 8.870e+00\n",
      "Epoch 5267, Loss: 45.47966003417969, Neurons: 53, Grad norm: 8.861e+00\n",
      "Epoch 5267, Loss: 45.47966003417969, Neurons: 53, Grad norm: 8.861e+00\n",
      "Epoch 5268, Loss: 45.407806396484375, Neurons: 53, Grad norm: 8.848e+00\n",
      "Epoch 5268, Loss: 45.407806396484375, Neurons: 53, Grad norm: 8.848e+00\n",
      "Epoch 5269, Loss: 45.33565139770508, Neurons: 53, Grad norm: 8.831e+00\n",
      "Epoch 5269, Loss: 45.33565139770508, Neurons: 53, Grad norm: 8.831e+00\n",
      "Epoch 5270, Loss: 45.26314926147461, Neurons: 53, Grad norm: 8.809e+00\n",
      "Epoch 5270, Loss: 45.26314926147461, Neurons: 53, Grad norm: 8.809e+00\n",
      "Epoch 5271, Loss: 45.190338134765625, Neurons: 53, Grad norm: 8.799e+00\n",
      "Epoch 5271, Loss: 45.190338134765625, Neurons: 53, Grad norm: 8.799e+00\n",
      "Epoch 5272, Loss: 45.11724090576172, Neurons: 53, Grad norm: 8.790e+00\n",
      "Epoch 5272, Loss: 45.11724090576172, Neurons: 53, Grad norm: 8.790e+00\n",
      "Epoch 5273, Loss: 45.0438232421875, Neurons: 53, Grad norm: 8.776e+00\n",
      "Epoch 5273, Loss: 45.0438232421875, Neurons: 53, Grad norm: 8.776e+00\n",
      "Epoch 5274, Loss: 44.970123291015625, Neurons: 53, Grad norm: 8.768e+00\n",
      "Epoch 5274, Loss: 44.970123291015625, Neurons: 53, Grad norm: 8.768e+00\n",
      "Epoch 5275, Loss: 44.896148681640625, Neurons: 53, Grad norm: 8.755e+00\n",
      "Epoch 5275, Loss: 44.896148681640625, Neurons: 53, Grad norm: 8.755e+00\n",
      "Epoch 5276, Loss: 44.821895599365234, Neurons: 53, Grad norm: 8.731e+00\n",
      "Epoch 5276, Loss: 44.821895599365234, Neurons: 53, Grad norm: 8.731e+00\n",
      "Epoch 5277, Loss: 44.747379302978516, Neurons: 53, Grad norm: 8.700e+00\n",
      "Epoch 5277, Loss: 44.747379302978516, Neurons: 53, Grad norm: 8.700e+00\n",
      "Epoch 5278, Loss: 44.672611236572266, Neurons: 53, Grad norm: 8.685e+00\n",
      "Epoch 5278, Loss: 44.672611236572266, Neurons: 53, Grad norm: 8.685e+00\n",
      "Epoch 5279, Loss: 44.59758758544922, Neurons: 53, Grad norm: 8.670e+00\n",
      "Epoch 5279, Loss: 44.59758758544922, Neurons: 53, Grad norm: 8.670e+00\n",
      "Epoch 5280, Loss: 44.522315979003906, Neurons: 53, Grad norm: 8.664e+00\n",
      "Epoch 5280, Loss: 44.522315979003906, Neurons: 53, Grad norm: 8.664e+00\n",
      "Epoch 5281, Loss: 44.44683074951172, Neurons: 53, Grad norm: 8.655e+00\n",
      "Epoch 5281, Loss: 44.44683074951172, Neurons: 53, Grad norm: 8.655e+00\n",
      "Epoch 5282, Loss: 44.371116638183594, Neurons: 53, Grad norm: 8.649e+00\n",
      "Epoch 5282, Loss: 44.371116638183594, Neurons: 53, Grad norm: 8.649e+00\n",
      "Epoch 5283, Loss: 44.29515838623047, Neurons: 53, Grad norm: 8.637e+00\n",
      "Epoch 5283, Loss: 44.29515838623047, Neurons: 53, Grad norm: 8.637e+00\n",
      "Epoch 5284, Loss: 44.218997955322266, Neurons: 53, Grad norm: 8.604e+00\n",
      "Epoch 5284, Loss: 44.218997955322266, Neurons: 53, Grad norm: 8.604e+00\n",
      "Epoch 5285, Loss: 44.14262771606445, Neurons: 53, Grad norm: 8.580e+00\n",
      "Epoch 5285, Loss: 44.14262771606445, Neurons: 53, Grad norm: 8.580e+00\n",
      "Epoch 5286, Loss: 44.0660514831543, Neurons: 53, Grad norm: 8.565e+00\n",
      "Epoch 5286, Loss: 44.0660514831543, Neurons: 53, Grad norm: 8.565e+00\n",
      "Epoch 5287, Loss: 43.98928451538086, Neurons: 53, Grad norm: 8.552e+00\n",
      "Epoch 5287, Loss: 43.98928451538086, Neurons: 53, Grad norm: 8.552e+00\n",
      "Epoch 5288, Loss: 43.91234588623047, Neurons: 53, Grad norm: 8.518e+00\n",
      "Epoch 5288, Loss: 43.91234588623047, Neurons: 53, Grad norm: 8.518e+00\n",
      "Epoch 5289, Loss: 43.83525085449219, Neurons: 53, Grad norm: 8.492e+00\n",
      "Epoch 5289, Loss: 43.83525085449219, Neurons: 53, Grad norm: 8.492e+00\n",
      "Epoch 5290, Loss: 43.75800704956055, Neurons: 53, Grad norm: 8.477e+00\n",
      "Epoch 5290, Loss: 43.75800704956055, Neurons: 53, Grad norm: 8.477e+00\n",
      "Epoch 5291, Loss: 43.68061828613281, Neurons: 53, Grad norm: 8.464e+00\n",
      "Epoch 5291, Loss: 43.68061828613281, Neurons: 53, Grad norm: 8.464e+00\n",
      "Epoch 5292, Loss: 43.60309982299805, Neurons: 53, Grad norm: 8.455e+00\n",
      "Epoch 5292, Loss: 43.60309982299805, Neurons: 53, Grad norm: 8.455e+00\n",
      "Epoch 5293, Loss: 43.52544403076172, Neurons: 53, Grad norm: 8.443e+00\n",
      "Epoch 5293, Loss: 43.52544403076172, Neurons: 53, Grad norm: 8.443e+00\n",
      "Epoch 5294, Loss: 43.44767379760742, Neurons: 53, Grad norm: 8.429e+00\n",
      "Epoch 5294, Loss: 43.44767379760742, Neurons: 53, Grad norm: 8.429e+00\n",
      "Epoch 5295, Loss: 43.369781494140625, Neurons: 53, Grad norm: 8.404e+00\n",
      "Epoch 5295, Loss: 43.369781494140625, Neurons: 53, Grad norm: 8.404e+00\n",
      "Epoch 5296, Loss: 43.29177474975586, Neurons: 53, Grad norm: 8.392e+00\n",
      "Epoch 5296, Loss: 43.29177474975586, Neurons: 53, Grad norm: 8.392e+00\n",
      "Epoch 5297, Loss: 43.21369552612305, Neurons: 53, Grad norm: 8.369e+00\n",
      "Epoch 5297, Loss: 43.21369552612305, Neurons: 53, Grad norm: 8.369e+00\n",
      "Epoch 5298, Loss: 43.135520935058594, Neurons: 53, Grad norm: 8.356e+00\n",
      "Epoch 5298, Loss: 43.135520935058594, Neurons: 53, Grad norm: 8.356e+00\n",
      "Epoch 5299, Loss: 43.05725860595703, Neurons: 53, Grad norm: 8.347e+00\n",
      "Epoch 5299, Loss: 43.05725860595703, Neurons: 53, Grad norm: 8.347e+00\n",
      "Epoch 5299, Test loss: 40.5032844543457\n",
      "Epoch 5299, Test loss: 40.5032844543457\n",
      "Added neuron to hidden layer 1 with activation tanh\n",
      "Added neuron to hidden layer 1 with activation tanh\n",
      "network shape updated to :[23, 30, 1]\n",
      "network shape updated to :[23, 30, 1]\n",
      "Epoch 5300, Loss: 51.85139083862305, Neurons: 54, Grad norm: 1.843e+02\n",
      "Epoch 5300, Loss: 51.85139083862305, Neurons: 54, Grad norm: 1.843e+02\n",
      "Epoch 5301, Loss: 51.15380096435547, Neurons: 54, Grad norm: 1.690e+02\n",
      "Epoch 5301, Loss: 51.15380096435547, Neurons: 54, Grad norm: 1.690e+02\n",
      "Epoch 5302, Loss: 50.47011947631836, Neurons: 54, Grad norm: 1.542e+02\n",
      "Epoch 5302, Loss: 50.47011947631836, Neurons: 54, Grad norm: 1.542e+02\n",
      "Epoch 5303, Loss: 49.80769348144531, Neurons: 54, Grad norm: 1.405e+02\n",
      "Epoch 5303, Loss: 49.80769348144531, Neurons: 54, Grad norm: 1.405e+02\n",
      "Epoch 5304, Loss: 49.17335510253906, Neurons: 54, Grad norm: 1.283e+02\n",
      "Epoch 5304, Loss: 49.17335510253906, Neurons: 54, Grad norm: 1.283e+02\n",
      "Epoch 5305, Loss: 48.57244110107422, Neurons: 54, Grad norm: 1.180e+02\n",
      "Epoch 5305, Loss: 48.57244110107422, Neurons: 54, Grad norm: 1.180e+02\n",
      "Epoch 5306, Loss: 48.008358001708984, Neurons: 54, Grad norm: 1.097e+02\n",
      "Epoch 5306, Loss: 48.008358001708984, Neurons: 54, Grad norm: 1.097e+02\n",
      "Epoch 5307, Loss: 47.48264694213867, Neurons: 54, Grad norm: 1.032e+02\n",
      "Epoch 5307, Loss: 47.48264694213867, Neurons: 54, Grad norm: 1.032e+02\n",
      "Epoch 5308, Loss: 46.99528503417969, Neurons: 54, Grad norm: 9.796e+01\n",
      "Epoch 5308, Loss: 46.99528503417969, Neurons: 54, Grad norm: 9.796e+01\n",
      "Epoch 5309, Loss: 46.545326232910156, Neurons: 54, Grad norm: 9.342e+01\n",
      "Epoch 5309, Loss: 46.545326232910156, Neurons: 54, Grad norm: 9.342e+01\n",
      "Epoch 5310, Loss: 46.13157653808594, Neurons: 54, Grad norm: 8.903e+01\n",
      "Epoch 5310, Loss: 46.13157653808594, Neurons: 54, Grad norm: 8.903e+01\n",
      "Epoch 5311, Loss: 45.75273132324219, Neurons: 54, Grad norm: 8.434e+01\n",
      "Epoch 5311, Loss: 45.75273132324219, Neurons: 54, Grad norm: 8.434e+01\n",
      "Epoch 5312, Loss: 45.40766525268555, Neurons: 54, Grad norm: 7.907e+01\n",
      "Epoch 5312, Loss: 45.40766525268555, Neurons: 54, Grad norm: 7.907e+01\n",
      "Epoch 5313, Loss: 45.09550857543945, Neurons: 54, Grad norm: 7.303e+01\n",
      "Epoch 5313, Loss: 45.09550857543945, Neurons: 54, Grad norm: 7.303e+01\n",
      "Epoch 5314, Loss: 44.81550979614258, Neurons: 54, Grad norm: 6.627e+01\n",
      "Epoch 5314, Loss: 44.81550979614258, Neurons: 54, Grad norm: 6.627e+01\n",
      "Epoch 5315, Loss: 44.567073822021484, Neurons: 54, Grad norm: 5.892e+01\n",
      "Epoch 5315, Loss: 44.567073822021484, Neurons: 54, Grad norm: 5.892e+01\n",
      "Epoch 5316, Loss: 44.34954071044922, Neurons: 54, Grad norm: 5.127e+01\n",
      "Epoch 5316, Loss: 44.34954071044922, Neurons: 54, Grad norm: 5.127e+01\n",
      "Epoch 5317, Loss: 44.16182327270508, Neurons: 54, Grad norm: 4.371e+01\n",
      "Epoch 5317, Loss: 44.16182327270508, Neurons: 54, Grad norm: 4.371e+01\n",
      "Epoch 5318, Loss: 44.00221252441406, Neurons: 54, Grad norm: 3.673e+01\n",
      "Epoch 5318, Loss: 44.00221252441406, Neurons: 54, Grad norm: 3.673e+01\n",
      "Epoch 5319, Loss: 43.86821365356445, Neurons: 54, Grad norm: 3.091e+01\n",
      "Epoch 5319, Loss: 43.86821365356445, Neurons: 54, Grad norm: 3.091e+01\n",
      "Epoch 5320, Loss: 43.75654220581055, Neurons: 54, Grad norm: 2.680e+01\n",
      "Epoch 5320, Loss: 43.75654220581055, Neurons: 54, Grad norm: 2.680e+01\n",
      "Epoch 5321, Loss: 43.66336441040039, Neurons: 54, Grad norm: 2.470e+01\n",
      "Epoch 5321, Loss: 43.66336441040039, Neurons: 54, Grad norm: 2.470e+01\n",
      "Epoch 5322, Loss: 43.58466339111328, Neurons: 54, Grad norm: 2.439e+01\n",
      "Epoch 5322, Loss: 43.58466339111328, Neurons: 54, Grad norm: 2.439e+01\n",
      "Epoch 5323, Loss: 43.516517639160156, Neurons: 54, Grad norm: 2.521e+01\n",
      "Epoch 5323, Loss: 43.516517639160156, Neurons: 54, Grad norm: 2.521e+01\n",
      "Epoch 5324, Loss: 43.455509185791016, Neurons: 54, Grad norm: 2.640e+01\n",
      "Epoch 5324, Loss: 43.455509185791016, Neurons: 54, Grad norm: 2.640e+01\n",
      "Epoch 5325, Loss: 43.39876174926758, Neurons: 54, Grad norm: 2.749e+01\n",
      "Epoch 5325, Loss: 43.39876174926758, Neurons: 54, Grad norm: 2.749e+01\n",
      "Epoch 5326, Loss: 43.344139099121094, Neurons: 54, Grad norm: 2.819e+01\n",
      "Epoch 5326, Loss: 43.344139099121094, Neurons: 54, Grad norm: 2.819e+01\n",
      "Epoch 5327, Loss: 43.29013442993164, Neurons: 54, Grad norm: 2.835e+01\n",
      "Epoch 5327, Loss: 43.29013442993164, Neurons: 54, Grad norm: 2.835e+01\n",
      "Epoch 5328, Loss: 43.23585510253906, Neurons: 54, Grad norm: 2.800e+01\n",
      "Epoch 5328, Loss: 43.23585510253906, Neurons: 54, Grad norm: 2.800e+01\n",
      "Epoch 5329, Loss: 43.18089294433594, Neurons: 54, Grad norm: 2.717e+01\n",
      "Epoch 5329, Loss: 43.18089294433594, Neurons: 54, Grad norm: 2.717e+01\n",
      "Epoch 5330, Loss: 43.12523651123047, Neurons: 54, Grad norm: 2.600e+01\n",
      "Epoch 5330, Loss: 43.12523651123047, Neurons: 54, Grad norm: 2.600e+01\n",
      "Epoch 5331, Loss: 43.0691032409668, Neurons: 54, Grad norm: 2.457e+01\n",
      "Epoch 5331, Loss: 43.0691032409668, Neurons: 54, Grad norm: 2.457e+01\n",
      "Epoch 5332, Loss: 43.012847900390625, Neurons: 54, Grad norm: 2.304e+01\n",
      "Epoch 5332, Loss: 43.012847900390625, Neurons: 54, Grad norm: 2.304e+01\n",
      "Epoch 5333, Loss: 42.95692825317383, Neurons: 54, Grad norm: 2.154e+01\n",
      "Epoch 5333, Loss: 42.95692825317383, Neurons: 54, Grad norm: 2.154e+01\n",
      "Epoch 5334, Loss: 42.90169906616211, Neurons: 54, Grad norm: 2.014e+01\n",
      "Epoch 5334, Loss: 42.90169906616211, Neurons: 54, Grad norm: 2.014e+01\n",
      "Epoch 5335, Loss: 42.84745407104492, Neurons: 54, Grad norm: 1.891e+01\n",
      "Epoch 5335, Loss: 42.84745407104492, Neurons: 54, Grad norm: 1.891e+01\n",
      "Epoch 5336, Loss: 42.79441452026367, Neurons: 54, Grad norm: 1.786e+01\n",
      "Epoch 5336, Loss: 42.79441452026367, Neurons: 54, Grad norm: 1.786e+01\n",
      "Epoch 5337, Loss: 42.742698669433594, Neurons: 54, Grad norm: 1.695e+01\n",
      "Epoch 5337, Loss: 42.742698669433594, Neurons: 54, Grad norm: 1.695e+01\n",
      "Epoch 5338, Loss: 42.69235610961914, Neurons: 54, Grad norm: 1.614e+01\n",
      "Epoch 5338, Loss: 42.69235610961914, Neurons: 54, Grad norm: 1.614e+01\n",
      "Epoch 5339, Loss: 42.64339828491211, Neurons: 54, Grad norm: 1.540e+01\n",
      "Epoch 5339, Loss: 42.64339828491211, Neurons: 54, Grad norm: 1.540e+01\n",
      "Epoch 5340, Loss: 42.595802307128906, Neurons: 54, Grad norm: 1.470e+01\n",
      "Epoch 5340, Loss: 42.595802307128906, Neurons: 54, Grad norm: 1.470e+01\n",
      "Epoch 5341, Loss: 42.549598693847656, Neurons: 54, Grad norm: 1.404e+01\n",
      "Epoch 5341, Loss: 42.549598693847656, Neurons: 54, Grad norm: 1.404e+01\n",
      "Epoch 5342, Loss: 42.50476837158203, Neurons: 54, Grad norm: 1.348e+01\n",
      "Epoch 5342, Loss: 42.50476837158203, Neurons: 54, Grad norm: 1.348e+01\n",
      "Epoch 5343, Loss: 42.46134948730469, Neurons: 54, Grad norm: 1.306e+01\n",
      "Epoch 5343, Loss: 42.46134948730469, Neurons: 54, Grad norm: 1.306e+01\n",
      "Epoch 5344, Loss: 42.41933822631836, Neurons: 54, Grad norm: 1.284e+01\n",
      "Epoch 5344, Loss: 42.41933822631836, Neurons: 54, Grad norm: 1.284e+01\n",
      "Epoch 5345, Loss: 42.37870407104492, Neurons: 54, Grad norm: 1.285e+01\n",
      "Epoch 5345, Loss: 42.37870407104492, Neurons: 54, Grad norm: 1.285e+01\n",
      "Epoch 5346, Loss: 42.33940124511719, Neurons: 54, Grad norm: 1.306e+01\n",
      "Epoch 5346, Loss: 42.33940124511719, Neurons: 54, Grad norm: 1.306e+01\n",
      "Epoch 5347, Loss: 42.30126953125, Neurons: 54, Grad norm: 1.341e+01\n",
      "Epoch 5347, Loss: 42.30126953125, Neurons: 54, Grad norm: 1.341e+01\n",
      "Epoch 5348, Loss: 42.26415252685547, Neurons: 54, Grad norm: 1.384e+01\n",
      "Epoch 5348, Loss: 42.26415252685547, Neurons: 54, Grad norm: 1.384e+01\n",
      "Epoch 5349, Loss: 42.22784423828125, Neurons: 54, Grad norm: 1.424e+01\n",
      "Epoch 5349, Loss: 42.22784423828125, Neurons: 54, Grad norm: 1.424e+01\n",
      "Epoch 5350, Loss: 42.19211196899414, Neurons: 54, Grad norm: 1.454e+01\n",
      "Epoch 5350, Loss: 42.19211196899414, Neurons: 54, Grad norm: 1.454e+01\n",
      "Epoch 5351, Loss: 42.156776428222656, Neurons: 54, Grad norm: 1.469e+01\n",
      "Epoch 5351, Loss: 42.156776428222656, Neurons: 54, Grad norm: 1.469e+01\n",
      "Epoch 5352, Loss: 42.12159729003906, Neurons: 54, Grad norm: 1.467e+01\n",
      "Epoch 5352, Loss: 42.12159729003906, Neurons: 54, Grad norm: 1.467e+01\n",
      "Epoch 5353, Loss: 42.086448669433594, Neurons: 54, Grad norm: 1.446e+01\n",
      "Epoch 5353, Loss: 42.086448669433594, Neurons: 54, Grad norm: 1.446e+01\n",
      "Epoch 5354, Loss: 42.05123519897461, Neurons: 54, Grad norm: 1.408e+01\n",
      "Epoch 5354, Loss: 42.05123519897461, Neurons: 54, Grad norm: 1.408e+01\n",
      "Epoch 5355, Loss: 42.01587677001953, Neurons: 54, Grad norm: 1.359e+01\n",
      "Epoch 5355, Loss: 42.01587677001953, Neurons: 54, Grad norm: 1.359e+01\n",
      "Epoch 5356, Loss: 41.980377197265625, Neurons: 54, Grad norm: 1.302e+01\n",
      "Epoch 5356, Loss: 41.980377197265625, Neurons: 54, Grad norm: 1.302e+01\n",
      "Epoch 5357, Loss: 41.94473648071289, Neurons: 54, Grad norm: 1.244e+01\n",
      "Epoch 5357, Loss: 41.94473648071289, Neurons: 54, Grad norm: 1.244e+01\n",
      "Epoch 5358, Loss: 41.90897750854492, Neurons: 54, Grad norm: 1.189e+01\n",
      "Epoch 5358, Loss: 41.90897750854492, Neurons: 54, Grad norm: 1.189e+01\n",
      "Epoch 5359, Loss: 41.87310791015625, Neurons: 54, Grad norm: 1.138e+01\n",
      "Epoch 5359, Loss: 41.87310791015625, Neurons: 54, Grad norm: 1.138e+01\n",
      "Epoch 5360, Loss: 41.837188720703125, Neurons: 54, Grad norm: 1.096e+01\n",
      "Epoch 5360, Loss: 41.837188720703125, Neurons: 54, Grad norm: 1.096e+01\n",
      "Epoch 5361, Loss: 41.801204681396484, Neurons: 54, Grad norm: 1.062e+01\n",
      "Epoch 5361, Loss: 41.801204681396484, Neurons: 54, Grad norm: 1.062e+01\n",
      "Epoch 5362, Loss: 41.765167236328125, Neurons: 54, Grad norm: 1.036e+01\n",
      "Epoch 5362, Loss: 41.765167236328125, Neurons: 54, Grad norm: 1.036e+01\n",
      "Epoch 5363, Loss: 41.72909927368164, Neurons: 54, Grad norm: 1.015e+01\n",
      "Epoch 5363, Loss: 41.72909927368164, Neurons: 54, Grad norm: 1.015e+01\n",
      "Epoch 5364, Loss: 41.69300079345703, Neurons: 54, Grad norm: 9.976e+00\n",
      "Epoch 5364, Loss: 41.69300079345703, Neurons: 54, Grad norm: 9.976e+00\n",
      "Epoch 5365, Loss: 41.65685272216797, Neurons: 54, Grad norm: 9.816e+00\n",
      "Epoch 5365, Loss: 41.65685272216797, Neurons: 54, Grad norm: 9.816e+00\n",
      "Epoch 5366, Loss: 41.62067413330078, Neurons: 54, Grad norm: 9.665e+00\n",
      "Epoch 5366, Loss: 41.62067413330078, Neurons: 54, Grad norm: 9.665e+00\n",
      "Epoch 5367, Loss: 41.584468841552734, Neurons: 54, Grad norm: 9.527e+00\n",
      "Epoch 5367, Loss: 41.584468841552734, Neurons: 54, Grad norm: 9.527e+00\n",
      "Epoch 5368, Loss: 41.54825973510742, Neurons: 54, Grad norm: 9.419e+00\n",
      "Epoch 5368, Loss: 41.54825973510742, Neurons: 54, Grad norm: 9.419e+00\n",
      "Epoch 5369, Loss: 41.51206588745117, Neurons: 54, Grad norm: 9.333e+00\n",
      "Epoch 5369, Loss: 41.51206588745117, Neurons: 54, Grad norm: 9.333e+00\n",
      "Epoch 5370, Loss: 41.475852966308594, Neurons: 54, Grad norm: 9.282e+00\n",
      "Epoch 5370, Loss: 41.475852966308594, Neurons: 54, Grad norm: 9.282e+00\n",
      "Epoch 5371, Loss: 41.439666748046875, Neurons: 54, Grad norm: 9.278e+00\n",
      "Epoch 5371, Loss: 41.439666748046875, Neurons: 54, Grad norm: 9.278e+00\n",
      "Epoch 5372, Loss: 41.403472900390625, Neurons: 54, Grad norm: 9.290e+00\n",
      "Epoch 5372, Loss: 41.403472900390625, Neurons: 54, Grad norm: 9.290e+00\n",
      "Epoch 5373, Loss: 41.36725616455078, Neurons: 54, Grad norm: 9.333e+00\n",
      "Epoch 5373, Loss: 41.36725616455078, Neurons: 54, Grad norm: 9.333e+00\n",
      "Epoch 5374, Loss: 41.33101272583008, Neurons: 54, Grad norm: 9.362e+00\n",
      "Epoch 5374, Loss: 41.33101272583008, Neurons: 54, Grad norm: 9.362e+00\n",
      "Epoch 5375, Loss: 41.29472732543945, Neurons: 54, Grad norm: 9.397e+00\n",
      "Epoch 5375, Loss: 41.29472732543945, Neurons: 54, Grad norm: 9.397e+00\n",
      "Epoch 5376, Loss: 41.25837707519531, Neurons: 54, Grad norm: 9.392e+00\n",
      "Epoch 5376, Loss: 41.25837707519531, Neurons: 54, Grad norm: 9.392e+00\n",
      "Epoch 5377, Loss: 41.22193908691406, Neurons: 54, Grad norm: 9.381e+00\n",
      "Epoch 5377, Loss: 41.22193908691406, Neurons: 54, Grad norm: 9.381e+00\n",
      "Epoch 5378, Loss: 41.1854133605957, Neurons: 54, Grad norm: 9.325e+00\n",
      "Epoch 5378, Loss: 41.1854133605957, Neurons: 54, Grad norm: 9.325e+00\n",
      "Epoch 5379, Loss: 41.14878845214844, Neurons: 54, Grad norm: 9.268e+00\n",
      "Epoch 5379, Loss: 41.14878845214844, Neurons: 54, Grad norm: 9.268e+00\n",
      "Epoch 5380, Loss: 41.112064361572266, Neurons: 54, Grad norm: 9.188e+00\n",
      "Epoch 5380, Loss: 41.112064361572266, Neurons: 54, Grad norm: 9.188e+00\n",
      "Epoch 5381, Loss: 41.07524871826172, Neurons: 54, Grad norm: 9.107e+00\n",
      "Epoch 5381, Loss: 41.07524871826172, Neurons: 54, Grad norm: 9.107e+00\n",
      "Epoch 5382, Loss: 41.0383415222168, Neurons: 54, Grad norm: 9.026e+00\n",
      "Epoch 5382, Loss: 41.0383415222168, Neurons: 54, Grad norm: 9.026e+00\n",
      "Epoch 5383, Loss: 41.0013313293457, Neurons: 54, Grad norm: 8.958e+00\n",
      "Epoch 5383, Loss: 41.0013313293457, Neurons: 54, Grad norm: 8.958e+00\n",
      "Epoch 5384, Loss: 40.964210510253906, Neurons: 54, Grad norm: 8.908e+00\n",
      "Epoch 5384, Loss: 40.964210510253906, Neurons: 54, Grad norm: 8.908e+00\n",
      "Epoch 5385, Loss: 40.92698669433594, Neurons: 54, Grad norm: 8.863e+00\n",
      "Epoch 5385, Loss: 40.92698669433594, Neurons: 54, Grad norm: 8.863e+00\n",
      "Epoch 5386, Loss: 40.88965606689453, Neurons: 54, Grad norm: 8.835e+00\n",
      "Epoch 5386, Loss: 40.88965606689453, Neurons: 54, Grad norm: 8.835e+00\n",
      "Epoch 5387, Loss: 40.852203369140625, Neurons: 54, Grad norm: 8.817e+00\n",
      "Epoch 5387, Loss: 40.852203369140625, Neurons: 54, Grad norm: 8.817e+00\n",
      "Epoch 5388, Loss: 40.81462860107422, Neurons: 54, Grad norm: 8.817e+00\n",
      "Epoch 5388, Loss: 40.81462860107422, Neurons: 54, Grad norm: 8.817e+00\n",
      "Epoch 5389, Loss: 40.77693176269531, Neurons: 54, Grad norm: 8.822e+00\n",
      "Epoch 5389, Loss: 40.77693176269531, Neurons: 54, Grad norm: 8.822e+00\n",
      "Epoch 5390, Loss: 40.73912048339844, Neurons: 54, Grad norm: 8.840e+00\n",
      "Epoch 5390, Loss: 40.73912048339844, Neurons: 54, Grad norm: 8.840e+00\n",
      "Epoch 5391, Loss: 40.701175689697266, Neurons: 54, Grad norm: 8.857e+00\n",
      "Epoch 5391, Loss: 40.701175689697266, Neurons: 54, Grad norm: 8.857e+00\n",
      "Epoch 5392, Loss: 40.66310501098633, Neurons: 54, Grad norm: 8.886e+00\n",
      "Epoch 5392, Loss: 40.66310501098633, Neurons: 54, Grad norm: 8.886e+00\n",
      "Epoch 5393, Loss: 40.62492752075195, Neurons: 54, Grad norm: 8.910e+00\n",
      "Epoch 5393, Loss: 40.62492752075195, Neurons: 54, Grad norm: 8.910e+00\n",
      "Epoch 5394, Loss: 40.586605072021484, Neurons: 54, Grad norm: 8.930e+00\n",
      "Epoch 5394, Loss: 40.586605072021484, Neurons: 54, Grad norm: 8.930e+00\n",
      "Epoch 5395, Loss: 40.54817199707031, Neurons: 54, Grad norm: 8.953e+00\n",
      "Epoch 5395, Loss: 40.54817199707031, Neurons: 54, Grad norm: 8.953e+00\n",
      "Epoch 5396, Loss: 40.50962829589844, Neurons: 54, Grad norm: 8.958e+00\n",
      "Epoch 5396, Loss: 40.50962829589844, Neurons: 54, Grad norm: 8.958e+00\n",
      "Epoch 5397, Loss: 40.47093963623047, Neurons: 54, Grad norm: 8.952e+00\n",
      "Epoch 5397, Loss: 40.47093963623047, Neurons: 54, Grad norm: 8.952e+00\n",
      "Epoch 5398, Loss: 40.43214416503906, Neurons: 54, Grad norm: 8.942e+00\n",
      "Epoch 5398, Loss: 40.43214416503906, Neurons: 54, Grad norm: 8.942e+00\n",
      "Epoch 5399, Loss: 40.393245697021484, Neurons: 54, Grad norm: 8.922e+00\n",
      "Epoch 5399, Loss: 40.393245697021484, Neurons: 54, Grad norm: 8.922e+00\n",
      "Epoch 5399, Test loss: 37.99375915527344\n",
      "Epoch 5399, Test loss: 37.99375915527344\n",
      "Added neuron to hidden layer 2 with activation sin\n",
      "Added neuron to hidden layer 2 with activation sin\n",
      "network shape updated to :[23, 31, 1]\n",
      "network shape updated to :[23, 31, 1]\n",
      "Epoch 5400, Loss: 40.4153938293457, Neurons: 55, Grad norm: 1.664e+01\n",
      "Epoch 5400, Loss: 40.4153938293457, Neurons: 55, Grad norm: 1.664e+01\n",
      "Epoch 5401, Loss: 40.344417572021484, Neurons: 55, Grad norm: 1.079e+01\n",
      "Epoch 5401, Loss: 40.344417572021484, Neurons: 55, Grad norm: 1.079e+01\n",
      "Epoch 5402, Loss: 40.31184005737305, Neurons: 55, Grad norm: 1.236e+01\n",
      "Epoch 5402, Loss: 40.31184005737305, Neurons: 55, Grad norm: 1.236e+01\n",
      "Epoch 5403, Loss: 40.29473114013672, Neurons: 55, Grad norm: 1.391e+01\n",
      "Epoch 5403, Loss: 40.29473114013672, Neurons: 55, Grad norm: 1.391e+01\n",
      "Epoch 5404, Loss: 40.274593353271484, Neurons: 55, Grad norm: 1.292e+01\n",
      "Epoch 5404, Loss: 40.274593353271484, Neurons: 55, Grad norm: 1.292e+01\n",
      "Epoch 5405, Loss: 40.24775695800781, Neurons: 55, Grad norm: 1.097e+01\n",
      "Epoch 5405, Loss: 40.24775695800781, Neurons: 55, Grad norm: 1.097e+01\n",
      "Epoch 5406, Loss: 40.217979431152344, Neurons: 55, Grad norm: 9.571e+00\n",
      "Epoch 5406, Loss: 40.217979431152344, Neurons: 55, Grad norm: 9.571e+00\n",
      "Epoch 5407, Loss: 40.18867874145508, Neurons: 55, Grad norm: 9.479e+00\n",
      "Epoch 5407, Loss: 40.18867874145508, Neurons: 55, Grad norm: 9.479e+00\n",
      "Epoch 5408, Loss: 40.16086196899414, Neurons: 55, Grad norm: 1.020e+01\n",
      "Epoch 5408, Loss: 40.16086196899414, Neurons: 55, Grad norm: 1.020e+01\n",
      "Epoch 5409, Loss: 40.1335563659668, Neurons: 55, Grad norm: 1.086e+01\n",
      "Epoch 5409, Loss: 40.1335563659668, Neurons: 55, Grad norm: 1.086e+01\n",
      "Epoch 5410, Loss: 40.105262756347656, Neurons: 55, Grad norm: 1.105e+01\n",
      "Epoch 5410, Loss: 40.105262756347656, Neurons: 55, Grad norm: 1.105e+01\n",
      "Epoch 5411, Loss: 40.075016021728516, Neurons: 55, Grad norm: 1.074e+01\n",
      "Epoch 5411, Loss: 40.075016021728516, Neurons: 55, Grad norm: 1.074e+01\n",
      "Epoch 5412, Loss: 40.042945861816406, Neurons: 55, Grad norm: 1.014e+01\n",
      "Epoch 5412, Loss: 40.042945861816406, Neurons: 55, Grad norm: 1.014e+01\n",
      "Epoch 5413, Loss: 40.00991439819336, Neurons: 55, Grad norm: 9.507e+00\n",
      "Epoch 5413, Loss: 40.00991439819336, Neurons: 55, Grad norm: 9.507e+00\n",
      "Epoch 5414, Loss: 39.97671890258789, Neurons: 55, Grad norm: 9.115e+00\n",
      "Epoch 5414, Loss: 39.97671890258789, Neurons: 55, Grad norm: 9.115e+00\n",
      "Epoch 5415, Loss: 39.943626403808594, Neurons: 55, Grad norm: 9.091e+00\n",
      "Epoch 5415, Loss: 39.943626403808594, Neurons: 55, Grad norm: 9.091e+00\n",
      "Epoch 5416, Loss: 39.91032409667969, Neurons: 55, Grad norm: 9.194e+00\n",
      "Epoch 5416, Loss: 39.91032409667969, Neurons: 55, Grad norm: 9.194e+00\n",
      "Epoch 5417, Loss: 39.87610626220703, Neurons: 55, Grad norm: 9.168e+00\n",
      "Epoch 5417, Loss: 39.87610626220703, Neurons: 55, Grad norm: 9.168e+00\n",
      "Epoch 5418, Loss: 39.8404426574707, Neurons: 55, Grad norm: 8.929e+00\n",
      "Epoch 5418, Loss: 39.8404426574707, Neurons: 55, Grad norm: 8.929e+00\n",
      "Epoch 5419, Loss: 39.80318832397461, Neurons: 55, Grad norm: 8.662e+00\n",
      "Epoch 5419, Loss: 39.80318832397461, Neurons: 55, Grad norm: 8.662e+00\n",
      "Epoch 5420, Loss: 39.76467514038086, Neurons: 55, Grad norm: 8.524e+00\n",
      "Epoch 5420, Loss: 39.76467514038086, Neurons: 55, Grad norm: 8.524e+00\n",
      "Epoch 5421, Loss: 39.725337982177734, Neurons: 55, Grad norm: 8.605e+00\n",
      "Epoch 5421, Loss: 39.725337982177734, Neurons: 55, Grad norm: 8.605e+00\n",
      "Epoch 5422, Loss: 39.68549346923828, Neurons: 55, Grad norm: 8.762e+00\n",
      "Epoch 5422, Loss: 39.68549346923828, Neurons: 55, Grad norm: 8.762e+00\n",
      "Epoch 5423, Loss: 39.645240783691406, Neurons: 55, Grad norm: 8.823e+00\n",
      "Epoch 5423, Loss: 39.645240783691406, Neurons: 55, Grad norm: 8.823e+00\n",
      "Epoch 5424, Loss: 39.60443115234375, Neurons: 55, Grad norm: 8.765e+00\n",
      "Epoch 5424, Loss: 39.60443115234375, Neurons: 55, Grad norm: 8.765e+00\n",
      "Epoch 5425, Loss: 39.56287384033203, Neurons: 55, Grad norm: 8.603e+00\n",
      "Epoch 5425, Loss: 39.56287384033203, Neurons: 55, Grad norm: 8.603e+00\n",
      "Epoch 5426, Loss: 39.52043151855469, Neurons: 55, Grad norm: 8.410e+00\n",
      "Epoch 5426, Loss: 39.52043151855469, Neurons: 55, Grad norm: 8.410e+00\n",
      "Epoch 5427, Loss: 39.47709655761719, Neurons: 55, Grad norm: 8.221e+00\n",
      "Epoch 5427, Loss: 39.47709655761719, Neurons: 55, Grad norm: 8.221e+00\n",
      "Epoch 5428, Loss: 39.43296432495117, Neurons: 55, Grad norm: 8.109e+00\n",
      "Epoch 5428, Loss: 39.43296432495117, Neurons: 55, Grad norm: 8.109e+00\n",
      "Epoch 5429, Loss: 39.38821029663086, Neurons: 55, Grad norm: 8.032e+00\n",
      "Epoch 5429, Loss: 39.38821029663086, Neurons: 55, Grad norm: 8.032e+00\n",
      "Epoch 5430, Loss: 39.34297180175781, Neurons: 55, Grad norm: 7.964e+00\n",
      "Epoch 5430, Loss: 39.34297180175781, Neurons: 55, Grad norm: 7.964e+00\n",
      "Epoch 5431, Loss: 39.297393798828125, Neurons: 55, Grad norm: 7.915e+00\n",
      "Epoch 5431, Loss: 39.297393798828125, Neurons: 55, Grad norm: 7.915e+00\n",
      "Epoch 5432, Loss: 39.25159454345703, Neurons: 55, Grad norm: 7.879e+00\n",
      "Epoch 5432, Loss: 39.25159454345703, Neurons: 55, Grad norm: 7.879e+00\n",
      "Epoch 5433, Loss: 39.20568084716797, Neurons: 55, Grad norm: 7.892e+00\n",
      "Epoch 5433, Loss: 39.20568084716797, Neurons: 55, Grad norm: 7.892e+00\n",
      "Epoch 5434, Loss: 39.15983200073242, Neurons: 55, Grad norm: 7.973e+00\n",
      "Epoch 5434, Loss: 39.15983200073242, Neurons: 55, Grad norm: 7.973e+00\n",
      "Epoch 5435, Loss: 39.11409378051758, Neurons: 55, Grad norm: 8.094e+00\n",
      "Epoch 5435, Loss: 39.11409378051758, Neurons: 55, Grad norm: 8.094e+00\n",
      "Epoch 5436, Loss: 39.06855010986328, Neurons: 55, Grad norm: 8.189e+00\n",
      "Epoch 5436, Loss: 39.06855010986328, Neurons: 55, Grad norm: 8.189e+00\n",
      "Epoch 5437, Loss: 39.02310562133789, Neurons: 55, Grad norm: 8.215e+00\n",
      "Epoch 5437, Loss: 39.02310562133789, Neurons: 55, Grad norm: 8.215e+00\n",
      "Epoch 5438, Loss: 38.97768783569336, Neurons: 55, Grad norm: 8.165e+00\n",
      "Epoch 5438, Loss: 38.97768783569336, Neurons: 55, Grad norm: 8.165e+00\n",
      "Epoch 5439, Loss: 38.93225860595703, Neurons: 55, Grad norm: 8.099e+00\n",
      "Epoch 5439, Loss: 38.93225860595703, Neurons: 55, Grad norm: 8.099e+00\n",
      "Epoch 5440, Loss: 38.88671112060547, Neurons: 55, Grad norm: 8.124e+00\n",
      "Epoch 5440, Loss: 38.88671112060547, Neurons: 55, Grad norm: 8.124e+00\n",
      "Epoch 5441, Loss: 38.84086608886719, Neurons: 55, Grad norm: 8.444e+00\n",
      "Epoch 5441, Loss: 38.84086608886719, Neurons: 55, Grad norm: 8.444e+00\n",
      "Epoch 5442, Loss: 38.79436111450195, Neurons: 55, Grad norm: 9.434e+00\n",
      "Epoch 5442, Loss: 38.79436111450195, Neurons: 55, Grad norm: 9.434e+00\n",
      "Epoch 5443, Loss: 38.7462158203125, Neurons: 55, Grad norm: 1.153e+01\n",
      "Epoch 5443, Loss: 38.7462158203125, Neurons: 55, Grad norm: 1.153e+01\n",
      "Epoch 5444, Loss: 38.69474411010742, Neurons: 55, Grad norm: 1.470e+01\n",
      "Epoch 5444, Loss: 38.69474411010742, Neurons: 55, Grad norm: 1.470e+01\n",
      "Epoch 5445, Loss: 38.63804626464844, Neurons: 55, Grad norm: 1.831e+01\n",
      "Epoch 5445, Loss: 38.63804626464844, Neurons: 55, Grad norm: 1.831e+01\n",
      "Epoch 5446, Loss: 38.57501220703125, Neurons: 55, Grad norm: 2.029e+01\n",
      "Epoch 5446, Loss: 38.57501220703125, Neurons: 55, Grad norm: 2.029e+01\n",
      "Epoch 5447, Loss: 38.505592346191406, Neurons: 55, Grad norm: 1.492e+01\n",
      "Epoch 5447, Loss: 38.505592346191406, Neurons: 55, Grad norm: 1.492e+01\n",
      "Epoch 5448, Loss: 38.435672760009766, Neurons: 55, Grad norm: 7.420e+00\n",
      "Epoch 5448, Loss: 38.435672760009766, Neurons: 55, Grad norm: 7.420e+00\n",
      "Epoch 5449, Loss: 38.3826789855957, Neurons: 55, Grad norm: 7.464e+00\n",
      "Epoch 5449, Loss: 38.3826789855957, Neurons: 55, Grad norm: 7.464e+00\n",
      "Epoch 5450, Loss: 38.33589172363281, Neurons: 55, Grad norm: 7.574e+00\n",
      "Epoch 5450, Loss: 38.33589172363281, Neurons: 55, Grad norm: 7.574e+00\n",
      "Epoch 5451, Loss: 38.289283752441406, Neurons: 55, Grad norm: 7.622e+00\n",
      "Epoch 5451, Loss: 38.289283752441406, Neurons: 55, Grad norm: 7.622e+00\n",
      "Epoch 5452, Loss: 38.242740631103516, Neurons: 55, Grad norm: 7.515e+00\n",
      "Epoch 5452, Loss: 38.242740631103516, Neurons: 55, Grad norm: 7.515e+00\n",
      "Epoch 5453, Loss: 38.19622802734375, Neurons: 55, Grad norm: 7.371e+00\n",
      "Epoch 5453, Loss: 38.19622802734375, Neurons: 55, Grad norm: 7.371e+00\n",
      "Epoch 5454, Loss: 38.14970397949219, Neurons: 55, Grad norm: 7.301e+00\n",
      "Epoch 5454, Loss: 38.14970397949219, Neurons: 55, Grad norm: 7.301e+00\n",
      "Epoch 5455, Loss: 38.10308837890625, Neurons: 55, Grad norm: 7.296e+00\n",
      "Epoch 5455, Loss: 38.10308837890625, Neurons: 55, Grad norm: 7.296e+00\n",
      "Epoch 5456, Loss: 38.05624771118164, Neurons: 55, Grad norm: 7.338e+00\n",
      "Epoch 5456, Loss: 38.05624771118164, Neurons: 55, Grad norm: 7.338e+00\n",
      "Epoch 5457, Loss: 38.00913619995117, Neurons: 55, Grad norm: 7.460e+00\n",
      "Epoch 5457, Loss: 38.00913619995117, Neurons: 55, Grad norm: 7.460e+00\n",
      "Epoch 5458, Loss: 37.961761474609375, Neurons: 55, Grad norm: 7.574e+00\n",
      "Epoch 5458, Loss: 37.961761474609375, Neurons: 55, Grad norm: 7.574e+00\n",
      "Epoch 5459, Loss: 37.91413879394531, Neurons: 55, Grad norm: 7.548e+00\n",
      "Epoch 5459, Loss: 37.91413879394531, Neurons: 55, Grad norm: 7.548e+00\n",
      "Epoch 5460, Loss: 37.86627960205078, Neurons: 55, Grad norm: 7.428e+00\n",
      "Epoch 5460, Loss: 37.86627960205078, Neurons: 55, Grad norm: 7.428e+00\n",
      "Epoch 5461, Loss: 37.81819152832031, Neurons: 55, Grad norm: 7.327e+00\n",
      "Epoch 5461, Loss: 37.81819152832031, Neurons: 55, Grad norm: 7.327e+00\n",
      "Epoch 5462, Loss: 37.7699089050293, Neurons: 55, Grad norm: 7.277e+00\n",
      "Epoch 5462, Loss: 37.7699089050293, Neurons: 55, Grad norm: 7.277e+00\n",
      "Epoch 5463, Loss: 37.72136306762695, Neurons: 55, Grad norm: 7.255e+00\n",
      "Epoch 5463, Loss: 37.72136306762695, Neurons: 55, Grad norm: 7.255e+00\n",
      "Epoch 5464, Loss: 37.67256546020508, Neurons: 55, Grad norm: 7.235e+00\n",
      "Epoch 5464, Loss: 37.67256546020508, Neurons: 55, Grad norm: 7.235e+00\n",
      "Epoch 5465, Loss: 37.62351608276367, Neurons: 55, Grad norm: 7.212e+00\n",
      "Epoch 5465, Loss: 37.62351608276367, Neurons: 55, Grad norm: 7.212e+00\n",
      "Epoch 5466, Loss: 37.57424545288086, Neurons: 55, Grad norm: 7.162e+00\n",
      "Epoch 5466, Loss: 37.57424545288086, Neurons: 55, Grad norm: 7.162e+00\n",
      "Epoch 5467, Loss: 37.52476119995117, Neurons: 55, Grad norm: 7.107e+00\n",
      "Epoch 5467, Loss: 37.52476119995117, Neurons: 55, Grad norm: 7.107e+00\n",
      "Epoch 5468, Loss: 37.47507095336914, Neurons: 55, Grad norm: 7.078e+00\n",
      "Epoch 5468, Loss: 37.47507095336914, Neurons: 55, Grad norm: 7.078e+00\n",
      "Epoch 5469, Loss: 37.42515182495117, Neurons: 55, Grad norm: 7.083e+00\n",
      "Epoch 5469, Loss: 37.42515182495117, Neurons: 55, Grad norm: 7.083e+00\n",
      "Epoch 5470, Loss: 37.375022888183594, Neurons: 55, Grad norm: 7.126e+00\n",
      "Epoch 5470, Loss: 37.375022888183594, Neurons: 55, Grad norm: 7.126e+00\n",
      "Epoch 5471, Loss: 37.32468795776367, Neurons: 55, Grad norm: 7.202e+00\n",
      "Epoch 5471, Loss: 37.32468795776367, Neurons: 55, Grad norm: 7.202e+00\n",
      "Epoch 5472, Loss: 37.274173736572266, Neurons: 55, Grad norm: 7.238e+00\n",
      "Epoch 5472, Loss: 37.274173736572266, Neurons: 55, Grad norm: 7.238e+00\n",
      "Epoch 5473, Loss: 37.22349548339844, Neurons: 55, Grad norm: 7.217e+00\n",
      "Epoch 5473, Loss: 37.22349548339844, Neurons: 55, Grad norm: 7.217e+00\n",
      "Epoch 5474, Loss: 37.17265319824219, Neurons: 55, Grad norm: 7.145e+00\n",
      "Epoch 5474, Loss: 37.17265319824219, Neurons: 55, Grad norm: 7.145e+00\n",
      "Epoch 5475, Loss: 37.12165832519531, Neurons: 55, Grad norm: 7.089e+00\n",
      "Epoch 5475, Loss: 37.12165832519531, Neurons: 55, Grad norm: 7.089e+00\n",
      "Epoch 5476, Loss: 37.07049560546875, Neurons: 55, Grad norm: 7.060e+00\n",
      "Epoch 5476, Loss: 37.07049560546875, Neurons: 55, Grad norm: 7.060e+00\n",
      "Epoch 5477, Loss: 37.0191764831543, Neurons: 55, Grad norm: 7.061e+00\n",
      "Epoch 5477, Loss: 37.0191764831543, Neurons: 55, Grad norm: 7.061e+00\n",
      "Epoch 5478, Loss: 36.967689514160156, Neurons: 55, Grad norm: 7.073e+00\n",
      "Epoch 5478, Loss: 36.967689514160156, Neurons: 55, Grad norm: 7.073e+00\n",
      "Epoch 5479, Loss: 36.91606140136719, Neurons: 55, Grad norm: 7.074e+00\n",
      "Epoch 5479, Loss: 36.91606140136719, Neurons: 55, Grad norm: 7.074e+00\n",
      "Epoch 5480, Loss: 36.86430740356445, Neurons: 55, Grad norm: 7.048e+00\n",
      "Epoch 5480, Loss: 36.86430740356445, Neurons: 55, Grad norm: 7.048e+00\n",
      "Epoch 5481, Loss: 36.81241226196289, Neurons: 55, Grad norm: 7.017e+00\n",
      "Epoch 5481, Loss: 36.81241226196289, Neurons: 55, Grad norm: 7.017e+00\n",
      "Epoch 5482, Loss: 36.76039505004883, Neurons: 55, Grad norm: 7.002e+00\n",
      "Epoch 5482, Loss: 36.76039505004883, Neurons: 55, Grad norm: 7.002e+00\n",
      "Epoch 5483, Loss: 36.70823669433594, Neurons: 55, Grad norm: 7.004e+00\n",
      "Epoch 5483, Loss: 36.70823669433594, Neurons: 55, Grad norm: 7.004e+00\n",
      "Epoch 5484, Loss: 36.655941009521484, Neurons: 55, Grad norm: 7.011e+00\n",
      "Epoch 5484, Loss: 36.655941009521484, Neurons: 55, Grad norm: 7.011e+00\n",
      "Epoch 5485, Loss: 36.60350799560547, Neurons: 55, Grad norm: 7.015e+00\n",
      "Epoch 5485, Loss: 36.60350799560547, Neurons: 55, Grad norm: 7.015e+00\n",
      "Epoch 5486, Loss: 36.55097198486328, Neurons: 55, Grad norm: 6.994e+00\n",
      "Epoch 5486, Loss: 36.55097198486328, Neurons: 55, Grad norm: 6.994e+00\n",
      "Epoch 5487, Loss: 36.4983024597168, Neurons: 55, Grad norm: 6.967e+00\n",
      "Epoch 5487, Loss: 36.4983024597168, Neurons: 55, Grad norm: 6.967e+00\n",
      "Epoch 5488, Loss: 36.445526123046875, Neurons: 55, Grad norm: 6.947e+00\n",
      "Epoch 5488, Loss: 36.445526123046875, Neurons: 55, Grad norm: 6.947e+00\n",
      "Epoch 5489, Loss: 36.39262390136719, Neurons: 55, Grad norm: 6.950e+00\n",
      "Epoch 5489, Loss: 36.39262390136719, Neurons: 55, Grad norm: 6.950e+00\n",
      "Epoch 5490, Loss: 36.3395881652832, Neurons: 55, Grad norm: 6.972e+00\n",
      "Epoch 5490, Loss: 36.3395881652832, Neurons: 55, Grad norm: 6.972e+00\n",
      "Epoch 5491, Loss: 36.28646469116211, Neurons: 55, Grad norm: 6.993e+00\n",
      "Epoch 5491, Loss: 36.28646469116211, Neurons: 55, Grad norm: 6.993e+00\n",
      "Epoch 5492, Loss: 36.233219146728516, Neurons: 55, Grad norm: 6.992e+00\n",
      "Epoch 5492, Loss: 36.233219146728516, Neurons: 55, Grad norm: 6.992e+00\n",
      "Epoch 5493, Loss: 36.17985534667969, Neurons: 55, Grad norm: 6.962e+00\n",
      "Epoch 5493, Loss: 36.17985534667969, Neurons: 55, Grad norm: 6.962e+00\n",
      "Epoch 5494, Loss: 36.12638473510742, Neurons: 55, Grad norm: 6.917e+00\n",
      "Epoch 5494, Loss: 36.12638473510742, Neurons: 55, Grad norm: 6.917e+00\n",
      "Epoch 5495, Loss: 36.072811126708984, Neurons: 55, Grad norm: 6.890e+00\n",
      "Epoch 5495, Loss: 36.072811126708984, Neurons: 55, Grad norm: 6.890e+00\n",
      "Epoch 5496, Loss: 36.019126892089844, Neurons: 55, Grad norm: 6.880e+00\n",
      "Epoch 5496, Loss: 36.019126892089844, Neurons: 55, Grad norm: 6.880e+00\n",
      "Epoch 5497, Loss: 35.965335845947266, Neurons: 55, Grad norm: 6.878e+00\n",
      "Epoch 5497, Loss: 35.965335845947266, Neurons: 55, Grad norm: 6.878e+00\n",
      "Epoch 5498, Loss: 35.911441802978516, Neurons: 55, Grad norm: 6.876e+00\n",
      "Epoch 5498, Loss: 35.911441802978516, Neurons: 55, Grad norm: 6.876e+00\n",
      "Epoch 5499, Loss: 35.85746383666992, Neurons: 55, Grad norm: 6.860e+00\n",
      "Epoch 5499, Loss: 35.85746383666992, Neurons: 55, Grad norm: 6.860e+00\n",
      "Epoch 5499, Test loss: 33.697723388671875\n",
      "Epoch 5499, Test loss: 33.697723388671875\n",
      "Added neuron to hidden layer 1 with activation sin\n",
      "Added neuron to hidden layer 1 with activation sin\n",
      "network shape updated to :[24, 31, 1]\n",
      "network shape updated to :[24, 31, 1]\n",
      "Epoch 5500, Loss: 58.8779411315918, Neurons: 56, Grad norm: 3.898e+02\n",
      "Epoch 5500, Loss: 58.8779411315918, Neurons: 56, Grad norm: 3.898e+02\n",
      "Epoch 5501, Loss: 57.69076156616211, Neurons: 56, Grad norm: 3.733e+02\n",
      "Epoch 5501, Loss: 57.69076156616211, Neurons: 56, Grad norm: 3.733e+02\n",
      "Epoch 5502, Loss: 56.499244689941406, Neurons: 56, Grad norm: 3.565e+02\n",
      "Epoch 5502, Loss: 56.499244689941406, Neurons: 56, Grad norm: 3.565e+02\n",
      "Epoch 5503, Loss: 55.31086349487305, Neurons: 56, Grad norm: 3.398e+02\n",
      "Epoch 5503, Loss: 55.31086349487305, Neurons: 56, Grad norm: 3.398e+02\n",
      "Epoch 5504, Loss: 54.133644104003906, Neurons: 56, Grad norm: 3.231e+02\n",
      "Epoch 5504, Loss: 54.133644104003906, Neurons: 56, Grad norm: 3.231e+02\n",
      "Epoch 5505, Loss: 52.97618865966797, Neurons: 56, Grad norm: 3.067e+02\n",
      "Epoch 5505, Loss: 52.97618865966797, Neurons: 56, Grad norm: 3.067e+02\n",
      "Epoch 5506, Loss: 51.846988677978516, Neurons: 56, Grad norm: 2.907e+02\n",
      "Epoch 5506, Loss: 51.846988677978516, Neurons: 56, Grad norm: 2.907e+02\n",
      "Epoch 5507, Loss: 50.75370407104492, Neurons: 56, Grad norm: 2.753e+02\n",
      "Epoch 5507, Loss: 50.75370407104492, Neurons: 56, Grad norm: 2.753e+02\n",
      "Epoch 5508, Loss: 49.70275115966797, Neurons: 56, Grad norm: 2.607e+02\n",
      "Epoch 5508, Loss: 49.70275115966797, Neurons: 56, Grad norm: 2.607e+02\n",
      "Epoch 5509, Loss: 48.69888687133789, Neurons: 56, Grad norm: 2.468e+02\n",
      "Epoch 5509, Loss: 48.69888687133789, Neurons: 56, Grad norm: 2.468e+02\n",
      "Epoch 5510, Loss: 47.745113372802734, Neurons: 56, Grad norm: 2.337e+02\n",
      "Epoch 5510, Loss: 47.745113372802734, Neurons: 56, Grad norm: 2.337e+02\n",
      "Epoch 5511, Loss: 46.84292221069336, Neurons: 56, Grad norm: 2.213e+02\n",
      "Epoch 5511, Loss: 46.84292221069336, Neurons: 56, Grad norm: 2.213e+02\n",
      "Epoch 5512, Loss: 45.992679595947266, Neurons: 56, Grad norm: 2.095e+02\n",
      "Epoch 5512, Loss: 45.992679595947266, Neurons: 56, Grad norm: 2.095e+02\n",
      "Epoch 5513, Loss: 45.19401550292969, Neurons: 56, Grad norm: 1.980e+02\n",
      "Epoch 5513, Loss: 45.19401550292969, Neurons: 56, Grad norm: 1.980e+02\n",
      "Epoch 5514, Loss: 44.44615173339844, Neurons: 56, Grad norm: 1.869e+02\n",
      "Epoch 5514, Loss: 44.44615173339844, Neurons: 56, Grad norm: 1.869e+02\n",
      "Epoch 5515, Loss: 43.74803161621094, Neurons: 56, Grad norm: 1.760e+02\n",
      "Epoch 5515, Loss: 43.74803161621094, Neurons: 56, Grad norm: 1.760e+02\n",
      "Epoch 5516, Loss: 43.09850311279297, Neurons: 56, Grad norm: 1.652e+02\n",
      "Epoch 5516, Loss: 43.09850311279297, Neurons: 56, Grad norm: 1.652e+02\n",
      "Epoch 5517, Loss: 42.49650955200195, Neurons: 56, Grad norm: 1.545e+02\n",
      "Epoch 5517, Loss: 42.49650955200195, Neurons: 56, Grad norm: 1.545e+02\n",
      "Epoch 5518, Loss: 41.94103240966797, Neurons: 56, Grad norm: 1.439e+02\n",
      "Epoch 5518, Loss: 41.94103240966797, Neurons: 56, Grad norm: 1.439e+02\n",
      "Epoch 5519, Loss: 41.431182861328125, Neurons: 56, Grad norm: 1.334e+02\n",
      "Epoch 5519, Loss: 41.431182861328125, Neurons: 56, Grad norm: 1.334e+02\n",
      "Epoch 5520, Loss: 40.96589279174805, Neurons: 56, Grad norm: 1.233e+02\n",
      "Epoch 5520, Loss: 40.96589279174805, Neurons: 56, Grad norm: 1.233e+02\n",
      "Epoch 5521, Loss: 40.5438117980957, Neurons: 56, Grad norm: 1.137e+02\n",
      "Epoch 5521, Loss: 40.5438117980957, Neurons: 56, Grad norm: 1.137e+02\n",
      "Epoch 5522, Loss: 40.163002014160156, Neurons: 56, Grad norm: 1.048e+02\n",
      "Epoch 5522, Loss: 40.163002014160156, Neurons: 56, Grad norm: 1.048e+02\n",
      "Epoch 5523, Loss: 39.8206901550293, Neurons: 56, Grad norm: 9.645e+01\n",
      "Epoch 5523, Loss: 39.8206901550293, Neurons: 56, Grad norm: 9.645e+01\n",
      "Epoch 5524, Loss: 39.51422882080078, Neurons: 56, Grad norm: 8.894e+01\n",
      "Epoch 5524, Loss: 39.51422882080078, Neurons: 56, Grad norm: 8.894e+01\n",
      "Epoch 5525, Loss: 39.240509033203125, Neurons: 56, Grad norm: 8.246e+01\n",
      "Epoch 5525, Loss: 39.240509033203125, Neurons: 56, Grad norm: 8.246e+01\n",
      "Epoch 5526, Loss: 38.99568176269531, Neurons: 56, Grad norm: 7.705e+01\n",
      "Epoch 5526, Loss: 38.99568176269531, Neurons: 56, Grad norm: 7.705e+01\n",
      "Epoch 5527, Loss: 38.77553176879883, Neurons: 56, Grad norm: 7.270e+01\n",
      "Epoch 5527, Loss: 38.77553176879883, Neurons: 56, Grad norm: 7.270e+01\n",
      "Epoch 5528, Loss: 38.575828552246094, Neurons: 56, Grad norm: 6.918e+01\n",
      "Epoch 5528, Loss: 38.575828552246094, Neurons: 56, Grad norm: 6.918e+01\n",
      "Epoch 5529, Loss: 38.392730712890625, Neurons: 56, Grad norm: 6.639e+01\n",
      "Epoch 5529, Loss: 38.392730712890625, Neurons: 56, Grad norm: 6.639e+01\n",
      "Epoch 5530, Loss: 38.222877502441406, Neurons: 56, Grad norm: 6.412e+01\n",
      "Epoch 5530, Loss: 38.222877502441406, Neurons: 56, Grad norm: 6.412e+01\n",
      "Epoch 5531, Loss: 38.063331604003906, Neurons: 56, Grad norm: 6.225e+01\n",
      "Epoch 5531, Loss: 38.063331604003906, Neurons: 56, Grad norm: 6.225e+01\n",
      "Epoch 5532, Loss: 37.911678314208984, Neurons: 56, Grad norm: 6.060e+01\n",
      "Epoch 5532, Loss: 37.911678314208984, Neurons: 56, Grad norm: 6.060e+01\n",
      "Epoch 5533, Loss: 37.765953063964844, Neurons: 56, Grad norm: 5.907e+01\n",
      "Epoch 5533, Loss: 37.765953063964844, Neurons: 56, Grad norm: 5.907e+01\n",
      "Epoch 5534, Loss: 37.62459945678711, Neurons: 56, Grad norm: 5.764e+01\n",
      "Epoch 5534, Loss: 37.62459945678711, Neurons: 56, Grad norm: 5.764e+01\n",
      "Epoch 5535, Loss: 37.486412048339844, Neurons: 56, Grad norm: 5.590e+01\n",
      "Epoch 5535, Loss: 37.486412048339844, Neurons: 56, Grad norm: 5.590e+01\n",
      "Epoch 5536, Loss: 37.350521087646484, Neurons: 56, Grad norm: 5.287e+01\n",
      "Epoch 5536, Loss: 37.350521087646484, Neurons: 56, Grad norm: 5.287e+01\n",
      "Epoch 5537, Loss: 37.2175407409668, Neurons: 56, Grad norm: 4.727e+01\n",
      "Epoch 5537, Loss: 37.2175407409668, Neurons: 56, Grad norm: 4.727e+01\n",
      "Epoch 5538, Loss: 37.0905876159668, Neurons: 56, Grad norm: 3.957e+01\n",
      "Epoch 5538, Loss: 37.0905876159668, Neurons: 56, Grad norm: 3.957e+01\n",
      "Epoch 5539, Loss: 36.97658157348633, Neurons: 56, Grad norm: 3.669e+01\n",
      "Epoch 5539, Loss: 36.97658157348633, Neurons: 56, Grad norm: 3.669e+01\n",
      "Epoch 5540, Loss: 36.87405776977539, Neurons: 56, Grad norm: 3.404e+01\n",
      "Epoch 5540, Loss: 36.87405776977539, Neurons: 56, Grad norm: 3.404e+01\n",
      "Epoch 5541, Loss: 36.776588439941406, Neurons: 56, Grad norm: 3.169e+01\n",
      "Epoch 5541, Loss: 36.776588439941406, Neurons: 56, Grad norm: 3.169e+01\n",
      "Epoch 5542, Loss: 36.68404769897461, Neurons: 56, Grad norm: 2.966e+01\n",
      "Epoch 5542, Loss: 36.68404769897461, Neurons: 56, Grad norm: 2.966e+01\n",
      "Epoch 5543, Loss: 36.59623336791992, Neurons: 56, Grad norm: 2.795e+01\n",
      "Epoch 5543, Loss: 36.59623336791992, Neurons: 56, Grad norm: 2.795e+01\n",
      "Epoch 5544, Loss: 36.512962341308594, Neurons: 56, Grad norm: 2.654e+01\n",
      "Epoch 5544, Loss: 36.512962341308594, Neurons: 56, Grad norm: 2.654e+01\n",
      "Epoch 5545, Loss: 36.4339714050293, Neurons: 56, Grad norm: 2.538e+01\n",
      "Epoch 5545, Loss: 36.4339714050293, Neurons: 56, Grad norm: 2.538e+01\n",
      "Epoch 5546, Loss: 36.35900115966797, Neurons: 56, Grad norm: 2.444e+01\n",
      "Epoch 5546, Loss: 36.35900115966797, Neurons: 56, Grad norm: 2.444e+01\n",
      "Epoch 5547, Loss: 36.2878303527832, Neurons: 56, Grad norm: 2.365e+01\n",
      "Epoch 5547, Loss: 36.2878303527832, Neurons: 56, Grad norm: 2.365e+01\n",
      "Epoch 5548, Loss: 36.22023391723633, Neurons: 56, Grad norm: 2.296e+01\n",
      "Epoch 5548, Loss: 36.22023391723633, Neurons: 56, Grad norm: 2.296e+01\n",
      "Epoch 5549, Loss: 36.1560173034668, Neurons: 56, Grad norm: 2.236e+01\n",
      "Epoch 5549, Loss: 36.1560173034668, Neurons: 56, Grad norm: 2.236e+01\n",
      "Epoch 5550, Loss: 36.094993591308594, Neurons: 56, Grad norm: 2.185e+01\n",
      "Epoch 5550, Loss: 36.094993591308594, Neurons: 56, Grad norm: 2.185e+01\n",
      "Epoch 5551, Loss: 36.03704071044922, Neurons: 56, Grad norm: 2.144e+01\n",
      "Epoch 5551, Loss: 36.03704071044922, Neurons: 56, Grad norm: 2.144e+01\n",
      "Epoch 5552, Loss: 35.98204040527344, Neurons: 56, Grad norm: 2.115e+01\n",
      "Epoch 5552, Loss: 35.98204040527344, Neurons: 56, Grad norm: 2.115e+01\n",
      "Epoch 5553, Loss: 35.92984390258789, Neurons: 56, Grad norm: 2.100e+01\n",
      "Epoch 5553, Loss: 35.92984390258789, Neurons: 56, Grad norm: 2.100e+01\n",
      "Epoch 5554, Loss: 35.880306243896484, Neurons: 56, Grad norm: 2.095e+01\n",
      "Epoch 5554, Loss: 35.880306243896484, Neurons: 56, Grad norm: 2.095e+01\n",
      "Epoch 5555, Loss: 35.8332405090332, Neurons: 56, Grad norm: 2.102e+01\n",
      "Epoch 5555, Loss: 35.8332405090332, Neurons: 56, Grad norm: 2.102e+01\n",
      "Epoch 5556, Loss: 35.78842544555664, Neurons: 56, Grad norm: 2.119e+01\n",
      "Epoch 5556, Loss: 35.78842544555664, Neurons: 56, Grad norm: 2.119e+01\n",
      "Epoch 5557, Loss: 35.745628356933594, Neurons: 56, Grad norm: 2.139e+01\n",
      "Epoch 5557, Loss: 35.745628356933594, Neurons: 56, Grad norm: 2.139e+01\n",
      "Epoch 5558, Loss: 35.7045783996582, Neurons: 56, Grad norm: 2.159e+01\n",
      "Epoch 5558, Loss: 35.7045783996582, Neurons: 56, Grad norm: 2.159e+01\n",
      "Epoch 5559, Loss: 35.665008544921875, Neurons: 56, Grad norm: 2.177e+01\n",
      "Epoch 5559, Loss: 35.665008544921875, Neurons: 56, Grad norm: 2.177e+01\n",
      "Epoch 5560, Loss: 35.626670837402344, Neurons: 56, Grad norm: 2.185e+01\n",
      "Epoch 5560, Loss: 35.626670837402344, Neurons: 56, Grad norm: 2.185e+01\n",
      "Epoch 5561, Loss: 35.58930587768555, Neurons: 56, Grad norm: 2.185e+01\n",
      "Epoch 5561, Loss: 35.58930587768555, Neurons: 56, Grad norm: 2.185e+01\n",
      "Epoch 5562, Loss: 35.552711486816406, Neurons: 56, Grad norm: 2.173e+01\n",
      "Epoch 5562, Loss: 35.552711486816406, Neurons: 56, Grad norm: 2.173e+01\n",
      "Epoch 5563, Loss: 35.51674270629883, Neurons: 56, Grad norm: 2.150e+01\n",
      "Epoch 5563, Loss: 35.51674270629883, Neurons: 56, Grad norm: 2.150e+01\n",
      "Epoch 5564, Loss: 35.48123550415039, Neurons: 56, Grad norm: 2.115e+01\n",
      "Epoch 5564, Loss: 35.48123550415039, Neurons: 56, Grad norm: 2.115e+01\n",
      "Epoch 5565, Loss: 35.44609451293945, Neurons: 56, Grad norm: 2.071e+01\n",
      "Epoch 5565, Loss: 35.44609451293945, Neurons: 56, Grad norm: 2.071e+01\n",
      "Epoch 5566, Loss: 35.41124725341797, Neurons: 56, Grad norm: 2.020e+01\n",
      "Epoch 5566, Loss: 35.41124725341797, Neurons: 56, Grad norm: 2.020e+01\n",
      "Epoch 5567, Loss: 35.37665939331055, Neurons: 56, Grad norm: 1.967e+01\n",
      "Epoch 5567, Loss: 35.37665939331055, Neurons: 56, Grad norm: 1.967e+01\n",
      "Epoch 5568, Loss: 35.342281341552734, Neurons: 56, Grad norm: 1.910e+01\n",
      "Epoch 5568, Loss: 35.342281341552734, Neurons: 56, Grad norm: 1.910e+01\n",
      "Epoch 5569, Loss: 35.30812072753906, Neurons: 56, Grad norm: 1.853e+01\n",
      "Epoch 5569, Loss: 35.30812072753906, Neurons: 56, Grad norm: 1.853e+01\n",
      "Epoch 5570, Loss: 35.27412796020508, Neurons: 56, Grad norm: 1.797e+01\n",
      "Epoch 5570, Loss: 35.27412796020508, Neurons: 56, Grad norm: 1.797e+01\n",
      "Epoch 5571, Loss: 35.24029541015625, Neurons: 56, Grad norm: 1.744e+01\n",
      "Epoch 5571, Loss: 35.24029541015625, Neurons: 56, Grad norm: 1.744e+01\n",
      "Epoch 5572, Loss: 35.20661544799805, Neurons: 56, Grad norm: 1.693e+01\n",
      "Epoch 5572, Loss: 35.20661544799805, Neurons: 56, Grad norm: 1.693e+01\n",
      "Epoch 5573, Loss: 35.17307662963867, Neurons: 56, Grad norm: 1.646e+01\n",
      "Epoch 5573, Loss: 35.17307662963867, Neurons: 56, Grad norm: 1.646e+01\n",
      "Epoch 5574, Loss: 35.13967514038086, Neurons: 56, Grad norm: 1.602e+01\n",
      "Epoch 5574, Loss: 35.13967514038086, Neurons: 56, Grad norm: 1.602e+01\n",
      "Epoch 5575, Loss: 35.106388092041016, Neurons: 56, Grad norm: 1.561e+01\n",
      "Epoch 5575, Loss: 35.106388092041016, Neurons: 56, Grad norm: 1.561e+01\n",
      "Epoch 5576, Loss: 35.07321548461914, Neurons: 56, Grad norm: 1.522e+01\n",
      "Epoch 5576, Loss: 35.07321548461914, Neurons: 56, Grad norm: 1.522e+01\n",
      "Epoch 5577, Loss: 35.040157318115234, Neurons: 56, Grad norm: 1.485e+01\n",
      "Epoch 5577, Loss: 35.040157318115234, Neurons: 56, Grad norm: 1.485e+01\n",
      "Epoch 5578, Loss: 35.00722885131836, Neurons: 56, Grad norm: 1.450e+01\n",
      "Epoch 5578, Loss: 35.00722885131836, Neurons: 56, Grad norm: 1.450e+01\n",
      "Epoch 5579, Loss: 34.974422454833984, Neurons: 56, Grad norm: 1.418e+01\n",
      "Epoch 5579, Loss: 34.974422454833984, Neurons: 56, Grad norm: 1.418e+01\n",
      "Epoch 5580, Loss: 34.94176483154297, Neurons: 56, Grad norm: 1.388e+01\n",
      "Epoch 5580, Loss: 34.94176483154297, Neurons: 56, Grad norm: 1.388e+01\n",
      "Epoch 5581, Loss: 34.90925216674805, Neurons: 56, Grad norm: 1.362e+01\n",
      "Epoch 5581, Loss: 34.90925216674805, Neurons: 56, Grad norm: 1.362e+01\n",
      "Epoch 5582, Loss: 34.87689971923828, Neurons: 56, Grad norm: 1.338e+01\n",
      "Epoch 5582, Loss: 34.87689971923828, Neurons: 56, Grad norm: 1.338e+01\n",
      "Epoch 5583, Loss: 34.8447265625, Neurons: 56, Grad norm: 1.316e+01\n",
      "Epoch 5583, Loss: 34.8447265625, Neurons: 56, Grad norm: 1.316e+01\n",
      "Epoch 5584, Loss: 34.81272506713867, Neurons: 56, Grad norm: 1.298e+01\n",
      "Epoch 5584, Loss: 34.81272506713867, Neurons: 56, Grad norm: 1.298e+01\n",
      "Epoch 5585, Loss: 34.78089904785156, Neurons: 56, Grad norm: 1.281e+01\n",
      "Epoch 5585, Loss: 34.78089904785156, Neurons: 56, Grad norm: 1.281e+01\n",
      "Epoch 5586, Loss: 34.749237060546875, Neurons: 56, Grad norm: 1.265e+01\n",
      "Epoch 5586, Loss: 34.749237060546875, Neurons: 56, Grad norm: 1.265e+01\n",
      "Epoch 5587, Loss: 34.717735290527344, Neurons: 56, Grad norm: 1.251e+01\n",
      "Epoch 5587, Loss: 34.717735290527344, Neurons: 56, Grad norm: 1.251e+01\n",
      "Epoch 5588, Loss: 34.686397552490234, Neurons: 56, Grad norm: 1.237e+01\n",
      "Epoch 5588, Loss: 34.686397552490234, Neurons: 56, Grad norm: 1.237e+01\n",
      "Epoch 5589, Loss: 34.65517807006836, Neurons: 56, Grad norm: 1.224e+01\n",
      "Epoch 5589, Loss: 34.65517807006836, Neurons: 56, Grad norm: 1.224e+01\n",
      "Epoch 5590, Loss: 34.62410354614258, Neurons: 56, Grad norm: 1.209e+01\n",
      "Epoch 5590, Loss: 34.62410354614258, Neurons: 56, Grad norm: 1.209e+01\n",
      "Epoch 5591, Loss: 34.5931396484375, Neurons: 56, Grad norm: 1.194e+01\n",
      "Epoch 5591, Loss: 34.5931396484375, Neurons: 56, Grad norm: 1.194e+01\n",
      "Epoch 5592, Loss: 34.56228256225586, Neurons: 56, Grad norm: 1.178e+01\n",
      "Epoch 5592, Loss: 34.56228256225586, Neurons: 56, Grad norm: 1.178e+01\n",
      "Epoch 5593, Loss: 34.531524658203125, Neurons: 56, Grad norm: 1.162e+01\n",
      "Epoch 5593, Loss: 34.531524658203125, Neurons: 56, Grad norm: 1.162e+01\n",
      "Epoch 5594, Loss: 34.500885009765625, Neurons: 56, Grad norm: 1.147e+01\n",
      "Epoch 5594, Loss: 34.500885009765625, Neurons: 56, Grad norm: 1.147e+01\n",
      "Epoch 5595, Loss: 34.47032165527344, Neurons: 56, Grad norm: 1.131e+01\n",
      "Epoch 5595, Loss: 34.47032165527344, Neurons: 56, Grad norm: 1.131e+01\n",
      "Epoch 5596, Loss: 34.4398307800293, Neurons: 56, Grad norm: 1.115e+01\n",
      "Epoch 5596, Loss: 34.4398307800293, Neurons: 56, Grad norm: 1.115e+01\n",
      "Epoch 5597, Loss: 34.40943145751953, Neurons: 56, Grad norm: 1.101e+01\n",
      "Epoch 5597, Loss: 34.40943145751953, Neurons: 56, Grad norm: 1.101e+01\n",
      "Epoch 5598, Loss: 34.37910461425781, Neurons: 56, Grad norm: 1.089e+01\n",
      "Epoch 5598, Loss: 34.37910461425781, Neurons: 56, Grad norm: 1.089e+01\n",
      "Epoch 5599, Loss: 34.34881591796875, Neurons: 56, Grad norm: 1.079e+01\n",
      "Epoch 5599, Loss: 34.34881591796875, Neurons: 56, Grad norm: 1.079e+01\n",
      "Epoch 5599, Test loss: 32.28813171386719\n",
      "Epoch 5599, Test loss: 32.28813171386719\n",
      "Added neuron to hidden layer 1 with activation sin\n",
      "Added neuron to hidden layer 1 with activation sin\n",
      "network shape updated to :[25, 31, 1]\n",
      "network shape updated to :[25, 31, 1]\n",
      "Epoch 5600, Loss: 90.60053253173828, Neurons: 57, Grad norm: 6.521e+02\n",
      "Epoch 5600, Loss: 90.60053253173828, Neurons: 57, Grad norm: 6.521e+02\n",
      "Epoch 5601, Loss: 88.59711456298828, Neurons: 57, Grad norm: 6.370e+02\n",
      "Epoch 5601, Loss: 88.59711456298828, Neurons: 57, Grad norm: 6.370e+02\n",
      "Epoch 5602, Loss: 86.55142974853516, Neurons: 57, Grad norm: 6.215e+02\n",
      "Epoch 5602, Loss: 86.55142974853516, Neurons: 57, Grad norm: 6.215e+02\n",
      "Epoch 5603, Loss: 84.47148895263672, Neurons: 57, Grad norm: 6.056e+02\n",
      "Epoch 5603, Loss: 84.47148895263672, Neurons: 57, Grad norm: 6.056e+02\n",
      "Epoch 5604, Loss: 82.36651611328125, Neurons: 57, Grad norm: 5.894e+02\n",
      "Epoch 5604, Loss: 82.36651611328125, Neurons: 57, Grad norm: 5.894e+02\n",
      "Epoch 5605, Loss: 80.24595642089844, Neurons: 57, Grad norm: 5.729e+02\n",
      "Epoch 5605, Loss: 80.24595642089844, Neurons: 57, Grad norm: 5.729e+02\n",
      "Epoch 5606, Loss: 78.1189193725586, Neurons: 57, Grad norm: 5.563e+02\n",
      "Epoch 5606, Loss: 78.1189193725586, Neurons: 57, Grad norm: 5.563e+02\n",
      "Epoch 5607, Loss: 75.9938735961914, Neurons: 57, Grad norm: 5.396e+02\n",
      "Epoch 5607, Loss: 75.9938735961914, Neurons: 57, Grad norm: 5.396e+02\n",
      "Epoch 5608, Loss: 73.87863159179688, Neurons: 57, Grad norm: 5.227e+02\n",
      "Epoch 5608, Loss: 73.87863159179688, Neurons: 57, Grad norm: 5.227e+02\n",
      "Epoch 5609, Loss: 71.7809066772461, Neurons: 57, Grad norm: 5.057e+02\n",
      "Epoch 5609, Loss: 71.7809066772461, Neurons: 57, Grad norm: 5.057e+02\n",
      "Epoch 5610, Loss: 69.70838928222656, Neurons: 57, Grad norm: 4.886e+02\n",
      "Epoch 5610, Loss: 69.70838928222656, Neurons: 57, Grad norm: 4.886e+02\n",
      "Epoch 5611, Loss: 67.66899108886719, Neurons: 57, Grad norm: 4.713e+02\n",
      "Epoch 5611, Loss: 67.66899108886719, Neurons: 57, Grad norm: 4.713e+02\n",
      "Epoch 5612, Loss: 65.67045593261719, Neurons: 57, Grad norm: 4.540e+02\n",
      "Epoch 5612, Loss: 65.67045593261719, Neurons: 57, Grad norm: 4.540e+02\n",
      "Epoch 5613, Loss: 63.7200813293457, Neurons: 57, Grad norm: 4.367e+02\n",
      "Epoch 5613, Loss: 63.7200813293457, Neurons: 57, Grad norm: 4.367e+02\n",
      "Epoch 5614, Loss: 61.82441711425781, Neurons: 57, Grad norm: 4.193e+02\n",
      "Epoch 5614, Loss: 61.82441711425781, Neurons: 57, Grad norm: 4.193e+02\n",
      "Epoch 5615, Loss: 59.98970413208008, Neurons: 57, Grad norm: 4.019e+02\n",
      "Epoch 5615, Loss: 59.98970413208008, Neurons: 57, Grad norm: 4.019e+02\n",
      "Epoch 5616, Loss: 58.22135543823242, Neurons: 57, Grad norm: 3.846e+02\n",
      "Epoch 5616, Loss: 58.22135543823242, Neurons: 57, Grad norm: 3.846e+02\n",
      "Epoch 5617, Loss: 56.523983001708984, Neurons: 57, Grad norm: 3.674e+02\n",
      "Epoch 5617, Loss: 56.523983001708984, Neurons: 57, Grad norm: 3.674e+02\n",
      "Epoch 5618, Loss: 54.901519775390625, Neurons: 57, Grad norm: 3.503e+02\n",
      "Epoch 5618, Loss: 54.901519775390625, Neurons: 57, Grad norm: 3.503e+02\n",
      "Epoch 5619, Loss: 53.3571891784668, Neurons: 57, Grad norm: 3.335e+02\n",
      "Epoch 5619, Loss: 53.3571891784668, Neurons: 57, Grad norm: 3.335e+02\n",
      "Epoch 5620, Loss: 51.89333724975586, Neurons: 57, Grad norm: 3.169e+02\n",
      "Epoch 5620, Loss: 51.89333724975586, Neurons: 57, Grad norm: 3.169e+02\n",
      "Epoch 5621, Loss: 50.51161193847656, Neurons: 57, Grad norm: 3.006e+02\n",
      "Epoch 5621, Loss: 50.51161193847656, Neurons: 57, Grad norm: 3.006e+02\n",
      "Epoch 5622, Loss: 49.21292495727539, Neurons: 57, Grad norm: 2.848e+02\n",
      "Epoch 5622, Loss: 49.21292495727539, Neurons: 57, Grad norm: 2.848e+02\n",
      "Epoch 5623, Loss: 47.997432708740234, Neurons: 57, Grad norm: 2.694e+02\n",
      "Epoch 5623, Loss: 47.997432708740234, Neurons: 57, Grad norm: 2.694e+02\n",
      "Epoch 5624, Loss: 46.86459732055664, Neurons: 57, Grad norm: 2.545e+02\n",
      "Epoch 5624, Loss: 46.86459732055664, Neurons: 57, Grad norm: 2.545e+02\n",
      "Epoch 5625, Loss: 45.81314468383789, Neurons: 57, Grad norm: 2.401e+02\n",
      "Epoch 5625, Loss: 45.81314468383789, Neurons: 57, Grad norm: 2.401e+02\n",
      "Epoch 5626, Loss: 44.84115219116211, Neurons: 57, Grad norm: 2.264e+02\n",
      "Epoch 5626, Loss: 44.84115219116211, Neurons: 57, Grad norm: 2.264e+02\n",
      "Epoch 5627, Loss: 43.94607162475586, Neurons: 57, Grad norm: 2.132e+02\n",
      "Epoch 5627, Loss: 43.94607162475586, Neurons: 57, Grad norm: 2.132e+02\n",
      "Epoch 5628, Loss: 43.12488555908203, Neurons: 57, Grad norm: 2.006e+02\n",
      "Epoch 5628, Loss: 43.12488555908203, Neurons: 57, Grad norm: 2.006e+02\n",
      "Epoch 5629, Loss: 42.37409591674805, Neurons: 57, Grad norm: 1.886e+02\n",
      "Epoch 5629, Loss: 42.37409591674805, Neurons: 57, Grad norm: 1.886e+02\n",
      "Epoch 5630, Loss: 41.689857482910156, Neurons: 57, Grad norm: 1.771e+02\n",
      "Epoch 5630, Loss: 41.689857482910156, Neurons: 57, Grad norm: 1.771e+02\n",
      "Epoch 5631, Loss: 41.06808853149414, Neurons: 57, Grad norm: 1.662e+02\n",
      "Epoch 5631, Loss: 41.06808853149414, Neurons: 57, Grad norm: 1.662e+02\n",
      "Epoch 5632, Loss: 40.504554748535156, Neurons: 57, Grad norm: 1.559e+02\n",
      "Epoch 5632, Loss: 40.504554748535156, Neurons: 57, Grad norm: 1.559e+02\n",
      "Epoch 5633, Loss: 39.994930267333984, Neurons: 57, Grad norm: 1.460e+02\n",
      "Epoch 5633, Loss: 39.994930267333984, Neurons: 57, Grad norm: 1.460e+02\n",
      "Epoch 5634, Loss: 39.534854888916016, Neurons: 57, Grad norm: 1.366e+02\n",
      "Epoch 5634, Loss: 39.534854888916016, Neurons: 57, Grad norm: 1.366e+02\n",
      "Epoch 5635, Loss: 39.12006378173828, Neurons: 57, Grad norm: 1.277e+02\n",
      "Epoch 5635, Loss: 39.12006378173828, Neurons: 57, Grad norm: 1.277e+02\n",
      "Epoch 5636, Loss: 38.74639129638672, Neurons: 57, Grad norm: 1.192e+02\n",
      "Epoch 5636, Loss: 38.74639129638672, Neurons: 57, Grad norm: 1.192e+02\n",
      "Epoch 5637, Loss: 38.40974426269531, Neurons: 57, Grad norm: 1.112e+02\n",
      "Epoch 5637, Loss: 38.40974426269531, Neurons: 57, Grad norm: 1.112e+02\n",
      "Epoch 5638, Loss: 38.10625457763672, Neurons: 57, Grad norm: 1.037e+02\n",
      "Epoch 5638, Loss: 38.10625457763672, Neurons: 57, Grad norm: 1.037e+02\n",
      "Epoch 5639, Loss: 37.83229064941406, Neurons: 57, Grad norm: 9.661e+01\n",
      "Epoch 5639, Loss: 37.83229064941406, Neurons: 57, Grad norm: 9.661e+01\n",
      "Epoch 5640, Loss: 37.5844612121582, Neurons: 57, Grad norm: 8.999e+01\n",
      "Epoch 5640, Loss: 37.5844612121582, Neurons: 57, Grad norm: 8.999e+01\n",
      "Epoch 5641, Loss: 37.35971450805664, Neurons: 57, Grad norm: 8.068e+01\n",
      "Epoch 5641, Loss: 37.35971450805664, Neurons: 57, Grad norm: 8.068e+01\n",
      "Epoch 5642, Loss: 37.159812927246094, Neurons: 57, Grad norm: 7.454e+01\n",
      "Epoch 5642, Loss: 37.159812927246094, Neurons: 57, Grad norm: 7.454e+01\n",
      "Epoch 5643, Loss: 36.982940673828125, Neurons: 57, Grad norm: 6.952e+01\n",
      "Epoch 5643, Loss: 36.982940673828125, Neurons: 57, Grad norm: 6.952e+01\n",
      "Epoch 5644, Loss: 36.8207893371582, Neurons: 57, Grad norm: 6.501e+01\n",
      "Epoch 5644, Loss: 36.8207893371582, Neurons: 57, Grad norm: 6.501e+01\n",
      "Epoch 5645, Loss: 36.67030715942383, Neurons: 57, Grad norm: 6.091e+01\n",
      "Epoch 5645, Loss: 36.67030715942383, Neurons: 57, Grad norm: 6.091e+01\n",
      "Epoch 5646, Loss: 36.53030776977539, Neurons: 57, Grad norm: 5.714e+01\n",
      "Epoch 5646, Loss: 36.53030776977539, Neurons: 57, Grad norm: 5.714e+01\n",
      "Epoch 5647, Loss: 36.39990234375, Neurons: 57, Grad norm: 5.370e+01\n",
      "Epoch 5647, Loss: 36.39990234375, Neurons: 57, Grad norm: 5.370e+01\n",
      "Epoch 5648, Loss: 36.27827835083008, Neurons: 57, Grad norm: 5.058e+01\n",
      "Epoch 5648, Loss: 36.27827835083008, Neurons: 57, Grad norm: 5.058e+01\n",
      "Epoch 5649, Loss: 36.16455078125, Neurons: 57, Grad norm: 4.780e+01\n",
      "Epoch 5649, Loss: 36.16455078125, Neurons: 57, Grad norm: 4.780e+01\n",
      "Epoch 5650, Loss: 36.05785369873047, Neurons: 57, Grad norm: 4.538e+01\n",
      "Epoch 5650, Loss: 36.05785369873047, Neurons: 57, Grad norm: 4.538e+01\n",
      "Epoch 5651, Loss: 35.95726013183594, Neurons: 57, Grad norm: 4.337e+01\n",
      "Epoch 5651, Loss: 35.95726013183594, Neurons: 57, Grad norm: 4.337e+01\n",
      "Epoch 5652, Loss: 35.86182403564453, Neurons: 57, Grad norm: 4.172e+01\n",
      "Epoch 5652, Loss: 35.86182403564453, Neurons: 57, Grad norm: 4.172e+01\n",
      "Epoch 5653, Loss: 35.7706413269043, Neurons: 57, Grad norm: 4.030e+01\n",
      "Epoch 5653, Loss: 35.7706413269043, Neurons: 57, Grad norm: 4.030e+01\n",
      "Epoch 5654, Loss: 35.682979583740234, Neurons: 57, Grad norm: 3.874e+01\n",
      "Epoch 5654, Loss: 35.682979583740234, Neurons: 57, Grad norm: 3.874e+01\n",
      "Epoch 5655, Loss: 35.598731994628906, Neurons: 57, Grad norm: 3.709e+01\n",
      "Epoch 5655, Loss: 35.598731994628906, Neurons: 57, Grad norm: 3.709e+01\n",
      "Epoch 5656, Loss: 35.51907730102539, Neurons: 57, Grad norm: 3.722e+01\n",
      "Epoch 5656, Loss: 35.51907730102539, Neurons: 57, Grad norm: 3.722e+01\n",
      "Epoch 5657, Loss: 35.44647216796875, Neurons: 57, Grad norm: 3.605e+01\n",
      "Epoch 5657, Loss: 35.44647216796875, Neurons: 57, Grad norm: 3.605e+01\n",
      "Epoch 5658, Loss: 35.37955093383789, Neurons: 57, Grad norm: 3.490e+01\n",
      "Epoch 5658, Loss: 35.37955093383789, Neurons: 57, Grad norm: 3.490e+01\n",
      "Epoch 5659, Loss: 35.315364837646484, Neurons: 57, Grad norm: 3.379e+01\n",
      "Epoch 5659, Loss: 35.315364837646484, Neurons: 57, Grad norm: 3.379e+01\n",
      "Epoch 5660, Loss: 35.2536506652832, Neurons: 57, Grad norm: 3.270e+01\n",
      "Epoch 5660, Loss: 35.2536506652832, Neurons: 57, Grad norm: 3.270e+01\n",
      "Epoch 5661, Loss: 35.19416427612305, Neurons: 57, Grad norm: 3.163e+01\n",
      "Epoch 5661, Loss: 35.19416427612305, Neurons: 57, Grad norm: 3.163e+01\n",
      "Epoch 5662, Loss: 35.13671875, Neurons: 57, Grad norm: 3.058e+01\n",
      "Epoch 5662, Loss: 35.13671875, Neurons: 57, Grad norm: 3.058e+01\n",
      "Epoch 5663, Loss: 35.08112716674805, Neurons: 57, Grad norm: 2.958e+01\n",
      "Epoch 5663, Loss: 35.08112716674805, Neurons: 57, Grad norm: 2.958e+01\n",
      "Epoch 5664, Loss: 35.0272216796875, Neurons: 57, Grad norm: 2.863e+01\n",
      "Epoch 5664, Loss: 35.0272216796875, Neurons: 57, Grad norm: 2.863e+01\n",
      "Epoch 5665, Loss: 34.974876403808594, Neurons: 57, Grad norm: 2.774e+01\n",
      "Epoch 5665, Loss: 34.974876403808594, Neurons: 57, Grad norm: 2.774e+01\n",
      "Epoch 5666, Loss: 34.92394256591797, Neurons: 57, Grad norm: 2.693e+01\n",
      "Epoch 5666, Loss: 34.92394256591797, Neurons: 57, Grad norm: 2.693e+01\n",
      "Epoch 5667, Loss: 34.874298095703125, Neurons: 57, Grad norm: 2.619e+01\n",
      "Epoch 5667, Loss: 34.874298095703125, Neurons: 57, Grad norm: 2.619e+01\n",
      "Epoch 5668, Loss: 34.82581329345703, Neurons: 57, Grad norm: 2.553e+01\n",
      "Epoch 5668, Loss: 34.82581329345703, Neurons: 57, Grad norm: 2.553e+01\n",
      "Epoch 5669, Loss: 34.77836990356445, Neurons: 57, Grad norm: 2.494e+01\n",
      "Epoch 5669, Loss: 34.77836990356445, Neurons: 57, Grad norm: 2.494e+01\n",
      "Epoch 5670, Loss: 34.73186111450195, Neurons: 57, Grad norm: 2.441e+01\n",
      "Epoch 5670, Loss: 34.73186111450195, Neurons: 57, Grad norm: 2.441e+01\n",
      "Epoch 5671, Loss: 34.68620300292969, Neurons: 57, Grad norm: 2.396e+01\n",
      "Epoch 5671, Loss: 34.68620300292969, Neurons: 57, Grad norm: 2.396e+01\n",
      "Epoch 5672, Loss: 34.641292572021484, Neurons: 57, Grad norm: 2.356e+01\n",
      "Epoch 5672, Loss: 34.641292572021484, Neurons: 57, Grad norm: 2.356e+01\n",
      "Epoch 5673, Loss: 34.597042083740234, Neurons: 57, Grad norm: 2.320e+01\n",
      "Epoch 5673, Loss: 34.597042083740234, Neurons: 57, Grad norm: 2.320e+01\n",
      "Epoch 5674, Loss: 34.55340576171875, Neurons: 57, Grad norm: 2.289e+01\n",
      "Epoch 5674, Loss: 34.55340576171875, Neurons: 57, Grad norm: 2.289e+01\n",
      "Epoch 5675, Loss: 34.51031494140625, Neurons: 57, Grad norm: 2.259e+01\n",
      "Epoch 5675, Loss: 34.51031494140625, Neurons: 57, Grad norm: 2.259e+01\n",
      "Epoch 5676, Loss: 34.467708587646484, Neurons: 57, Grad norm: 2.233e+01\n",
      "Epoch 5676, Loss: 34.467708587646484, Neurons: 57, Grad norm: 2.233e+01\n",
      "Epoch 5677, Loss: 34.42555618286133, Neurons: 57, Grad norm: 2.209e+01\n",
      "Epoch 5677, Loss: 34.42555618286133, Neurons: 57, Grad norm: 2.209e+01\n",
      "Epoch 5678, Loss: 34.38382339477539, Neurons: 57, Grad norm: 2.186e+01\n",
      "Epoch 5678, Loss: 34.38382339477539, Neurons: 57, Grad norm: 2.186e+01\n",
      "Epoch 5679, Loss: 34.342472076416016, Neurons: 57, Grad norm: 2.164e+01\n",
      "Epoch 5679, Loss: 34.342472076416016, Neurons: 57, Grad norm: 2.164e+01\n",
      "Epoch 5680, Loss: 34.30146408081055, Neurons: 57, Grad norm: 2.143e+01\n",
      "Epoch 5680, Loss: 34.30146408081055, Neurons: 57, Grad norm: 2.143e+01\n",
      "Epoch 5681, Loss: 34.26078414916992, Neurons: 57, Grad norm: 2.121e+01\n",
      "Epoch 5681, Loss: 34.26078414916992, Neurons: 57, Grad norm: 2.121e+01\n",
      "Epoch 5682, Loss: 34.22041702270508, Neurons: 57, Grad norm: 2.098e+01\n",
      "Epoch 5682, Loss: 34.22041702270508, Neurons: 57, Grad norm: 2.098e+01\n",
      "Epoch 5683, Loss: 34.180301666259766, Neurons: 57, Grad norm: 2.076e+01\n",
      "Epoch 5683, Loss: 34.180301666259766, Neurons: 57, Grad norm: 2.076e+01\n",
      "Epoch 5684, Loss: 34.14046096801758, Neurons: 57, Grad norm: 2.051e+01\n",
      "Epoch 5684, Loss: 34.14046096801758, Neurons: 57, Grad norm: 2.051e+01\n",
      "Epoch 5685, Loss: 34.100868225097656, Neurons: 57, Grad norm: 2.026e+01\n",
      "Epoch 5685, Loss: 34.100868225097656, Neurons: 57, Grad norm: 2.026e+01\n",
      "Epoch 5686, Loss: 34.061500549316406, Neurons: 57, Grad norm: 1.999e+01\n",
      "Epoch 5686, Loss: 34.061500549316406, Neurons: 57, Grad norm: 1.999e+01\n",
      "Epoch 5687, Loss: 34.02235412597656, Neurons: 57, Grad norm: 1.973e+01\n",
      "Epoch 5687, Loss: 34.02235412597656, Neurons: 57, Grad norm: 1.973e+01\n",
      "Epoch 5688, Loss: 33.98341751098633, Neurons: 57, Grad norm: 1.945e+01\n",
      "Epoch 5688, Loss: 33.98341751098633, Neurons: 57, Grad norm: 1.945e+01\n",
      "Epoch 5689, Loss: 33.944679260253906, Neurons: 57, Grad norm: 1.917e+01\n",
      "Epoch 5689, Loss: 33.944679260253906, Neurons: 57, Grad norm: 1.917e+01\n",
      "Epoch 5690, Loss: 33.90611267089844, Neurons: 57, Grad norm: 1.890e+01\n",
      "Epoch 5690, Loss: 33.90611267089844, Neurons: 57, Grad norm: 1.890e+01\n",
      "Epoch 5691, Loss: 33.86774826049805, Neurons: 57, Grad norm: 1.864e+01\n",
      "Epoch 5691, Loss: 33.86774826049805, Neurons: 57, Grad norm: 1.864e+01\n",
      "Epoch 5692, Loss: 33.82954406738281, Neurons: 57, Grad norm: 1.838e+01\n",
      "Epoch 5692, Loss: 33.82954406738281, Neurons: 57, Grad norm: 1.838e+01\n",
      "Epoch 5693, Loss: 33.7915153503418, Neurons: 57, Grad norm: 1.814e+01\n",
      "Epoch 5693, Loss: 33.7915153503418, Neurons: 57, Grad norm: 1.814e+01\n",
      "Epoch 5694, Loss: 33.75364303588867, Neurons: 57, Grad norm: 1.790e+01\n",
      "Epoch 5694, Loss: 33.75364303588867, Neurons: 57, Grad norm: 1.790e+01\n",
      "Epoch 5695, Loss: 33.71591567993164, Neurons: 57, Grad norm: 1.768e+01\n",
      "Epoch 5695, Loss: 33.71591567993164, Neurons: 57, Grad norm: 1.768e+01\n",
      "Epoch 5696, Loss: 33.67832946777344, Neurons: 57, Grad norm: 1.747e+01\n",
      "Epoch 5696, Loss: 33.67832946777344, Neurons: 57, Grad norm: 1.747e+01\n",
      "Epoch 5697, Loss: 33.640869140625, Neurons: 57, Grad norm: 1.728e+01\n",
      "Epoch 5697, Loss: 33.640869140625, Neurons: 57, Grad norm: 1.728e+01\n",
      "Epoch 5698, Loss: 33.6035270690918, Neurons: 57, Grad norm: 1.710e+01\n",
      "Epoch 5698, Loss: 33.6035270690918, Neurons: 57, Grad norm: 1.710e+01\n",
      "Epoch 5699, Loss: 33.566307067871094, Neurons: 57, Grad norm: 1.693e+01\n",
      "Epoch 5699, Loss: 33.566307067871094, Neurons: 57, Grad norm: 1.693e+01\n",
      "Epoch 5699, Test loss: 31.614282608032227\n",
      "Epoch 5699, Test loss: 31.614282608032227\n",
      "Added neuron to hidden layer 1 with activation relu\n",
      "Added neuron to hidden layer 1 with activation relu\n",
      "network shape updated to :[26, 31, 1]\n",
      "network shape updated to :[26, 31, 1]\n",
      "Epoch 5700, Loss: 33.6057243347168, Neurons: 58, Grad norm: 2.185e+01\n",
      "Epoch 5700, Loss: 33.6057243347168, Neurons: 58, Grad norm: 2.185e+01\n",
      "Epoch 5701, Loss: 33.53048324584961, Neurons: 58, Grad norm: 1.671e+01\n",
      "Epoch 5701, Loss: 33.53048324584961, Neurons: 58, Grad norm: 1.671e+01\n",
      "Epoch 5702, Loss: 33.46997833251953, Neurons: 58, Grad norm: 1.509e+01\n",
      "Epoch 5702, Loss: 33.46997833251953, Neurons: 58, Grad norm: 1.509e+01\n",
      "Epoch 5703, Loss: 33.420230865478516, Neurons: 58, Grad norm: 1.467e+01\n",
      "Epoch 5703, Loss: 33.420230865478516, Neurons: 58, Grad norm: 1.467e+01\n",
      "Epoch 5704, Loss: 33.371620178222656, Neurons: 58, Grad norm: 1.429e+01\n",
      "Epoch 5704, Loss: 33.371620178222656, Neurons: 58, Grad norm: 1.429e+01\n",
      "Epoch 5705, Loss: 33.322532653808594, Neurons: 58, Grad norm: 1.397e+01\n",
      "Epoch 5705, Loss: 33.322532653808594, Neurons: 58, Grad norm: 1.397e+01\n",
      "Epoch 5706, Loss: 33.27273178100586, Neurons: 58, Grad norm: 1.367e+01\n",
      "Epoch 5706, Loss: 33.27273178100586, Neurons: 58, Grad norm: 1.367e+01\n",
      "Epoch 5707, Loss: 33.22200393676758, Neurons: 58, Grad norm: 1.302e+01\n",
      "Epoch 5707, Loss: 33.22200393676758, Neurons: 58, Grad norm: 1.302e+01\n",
      "Epoch 5708, Loss: 33.170719146728516, Neurons: 58, Grad norm: 1.227e+01\n",
      "Epoch 5708, Loss: 33.170719146728516, Neurons: 58, Grad norm: 1.227e+01\n",
      "Epoch 5709, Loss: 33.11981964111328, Neurons: 58, Grad norm: 1.176e+01\n",
      "Epoch 5709, Loss: 33.11981964111328, Neurons: 58, Grad norm: 1.176e+01\n",
      "Epoch 5710, Loss: 33.06952667236328, Neurons: 58, Grad norm: 1.142e+01\n",
      "Epoch 5710, Loss: 33.06952667236328, Neurons: 58, Grad norm: 1.142e+01\n",
      "Epoch 5711, Loss: 33.01925277709961, Neurons: 58, Grad norm: 1.108e+01\n",
      "Epoch 5711, Loss: 33.01925277709961, Neurons: 58, Grad norm: 1.108e+01\n",
      "Epoch 5712, Loss: 32.96857833862305, Neurons: 58, Grad norm: 1.078e+01\n",
      "Epoch 5712, Loss: 32.96857833862305, Neurons: 58, Grad norm: 1.078e+01\n",
      "Epoch 5713, Loss: 32.917724609375, Neurons: 58, Grad norm: 1.063e+01\n",
      "Epoch 5713, Loss: 32.917724609375, Neurons: 58, Grad norm: 1.063e+01\n",
      "Epoch 5714, Loss: 32.867000579833984, Neurons: 58, Grad norm: 1.049e+01\n",
      "Epoch 5714, Loss: 32.867000579833984, Neurons: 58, Grad norm: 1.049e+01\n",
      "Epoch 5715, Loss: 32.816375732421875, Neurons: 58, Grad norm: 1.027e+01\n",
      "Epoch 5715, Loss: 32.816375732421875, Neurons: 58, Grad norm: 1.027e+01\n",
      "Epoch 5716, Loss: 32.765811920166016, Neurons: 58, Grad norm: 1.010e+01\n",
      "Epoch 5716, Loss: 32.765811920166016, Neurons: 58, Grad norm: 1.010e+01\n",
      "Epoch 5717, Loss: 32.715362548828125, Neurons: 58, Grad norm: 9.979e+00\n",
      "Epoch 5717, Loss: 32.715362548828125, Neurons: 58, Grad norm: 9.979e+00\n",
      "Epoch 5718, Loss: 32.665042877197266, Neurons: 58, Grad norm: 9.828e+00\n",
      "Epoch 5718, Loss: 32.665042877197266, Neurons: 58, Grad norm: 9.828e+00\n",
      "Epoch 5719, Loss: 32.61470413208008, Neurons: 58, Grad norm: 9.664e+00\n",
      "Epoch 5719, Loss: 32.61470413208008, Neurons: 58, Grad norm: 9.664e+00\n",
      "Epoch 5720, Loss: 32.56430435180664, Neurons: 58, Grad norm: 9.499e+00\n",
      "Epoch 5720, Loss: 32.56430435180664, Neurons: 58, Grad norm: 9.499e+00\n",
      "Epoch 5721, Loss: 32.5139274597168, Neurons: 58, Grad norm: 9.288e+00\n",
      "Epoch 5721, Loss: 32.5139274597168, Neurons: 58, Grad norm: 9.288e+00\n",
      "Epoch 5722, Loss: 32.46372604370117, Neurons: 58, Grad norm: 8.983e+00\n",
      "Epoch 5722, Loss: 32.46372604370117, Neurons: 58, Grad norm: 8.983e+00\n",
      "Epoch 5723, Loss: 32.41375732421875, Neurons: 58, Grad norm: 1.014e+01\n",
      "Epoch 5723, Loss: 32.41375732421875, Neurons: 58, Grad norm: 1.014e+01\n",
      "Epoch 5724, Loss: 32.36466979980469, Neurons: 58, Grad norm: 1.061e+01\n",
      "Epoch 5724, Loss: 32.36466979980469, Neurons: 58, Grad norm: 1.061e+01\n",
      "Epoch 5725, Loss: 32.315338134765625, Neurons: 58, Grad norm: 9.793e+00\n",
      "Epoch 5725, Loss: 32.315338134765625, Neurons: 58, Grad norm: 9.793e+00\n",
      "Epoch 5726, Loss: 32.265254974365234, Neurons: 58, Grad norm: 8.802e+00\n",
      "Epoch 5726, Loss: 32.265254974365234, Neurons: 58, Grad norm: 8.802e+00\n",
      "Epoch 5727, Loss: 32.215003967285156, Neurons: 58, Grad norm: 8.833e+00\n",
      "Epoch 5727, Loss: 32.215003967285156, Neurons: 58, Grad norm: 8.833e+00\n",
      "Epoch 5728, Loss: 32.1651611328125, Neurons: 58, Grad norm: 8.601e+00\n",
      "Epoch 5728, Loss: 32.1651611328125, Neurons: 58, Grad norm: 8.601e+00\n",
      "Epoch 5729, Loss: 32.11519241333008, Neurons: 58, Grad norm: 8.481e+00\n",
      "Epoch 5729, Loss: 32.11519241333008, Neurons: 58, Grad norm: 8.481e+00\n",
      "Epoch 5730, Loss: 32.06512451171875, Neurons: 58, Grad norm: 8.448e+00\n",
      "Epoch 5730, Loss: 32.06512451171875, Neurons: 58, Grad norm: 8.448e+00\n",
      "Epoch 5731, Loss: 32.014991760253906, Neurons: 58, Grad norm: 8.340e+00\n",
      "Epoch 5731, Loss: 32.014991760253906, Neurons: 58, Grad norm: 8.340e+00\n",
      "Epoch 5732, Loss: 31.964672088623047, Neurons: 58, Grad norm: 8.209e+00\n",
      "Epoch 5732, Loss: 31.964672088623047, Neurons: 58, Grad norm: 8.209e+00\n",
      "Epoch 5733, Loss: 31.914169311523438, Neurons: 58, Grad norm: 8.119e+00\n",
      "Epoch 5733, Loss: 31.914169311523438, Neurons: 58, Grad norm: 8.119e+00\n",
      "Epoch 5734, Loss: 31.863550186157227, Neurons: 58, Grad norm: 8.034e+00\n",
      "Epoch 5734, Loss: 31.863550186157227, Neurons: 58, Grad norm: 8.034e+00\n",
      "Epoch 5735, Loss: 31.812841415405273, Neurons: 58, Grad norm: 7.953e+00\n",
      "Epoch 5735, Loss: 31.812841415405273, Neurons: 58, Grad norm: 7.953e+00\n",
      "Epoch 5736, Loss: 31.76206398010254, Neurons: 58, Grad norm: 7.881e+00\n",
      "Epoch 5736, Loss: 31.76206398010254, Neurons: 58, Grad norm: 7.881e+00\n",
      "Epoch 5737, Loss: 31.71117401123047, Neurons: 58, Grad norm: 7.783e+00\n",
      "Epoch 5737, Loss: 31.71117401123047, Neurons: 58, Grad norm: 7.783e+00\n",
      "Epoch 5738, Loss: 31.660200119018555, Neurons: 58, Grad norm: 7.688e+00\n",
      "Epoch 5738, Loss: 31.660200119018555, Neurons: 58, Grad norm: 7.688e+00\n",
      "Epoch 5739, Loss: 31.60918426513672, Neurons: 58, Grad norm: 7.637e+00\n",
      "Epoch 5739, Loss: 31.60918426513672, Neurons: 58, Grad norm: 7.637e+00\n",
      "Epoch 5740, Loss: 31.558141708374023, Neurons: 58, Grad norm: 7.595e+00\n",
      "Epoch 5740, Loss: 31.558141708374023, Neurons: 58, Grad norm: 7.595e+00\n",
      "Epoch 5741, Loss: 31.507017135620117, Neurons: 58, Grad norm: 7.506e+00\n",
      "Epoch 5741, Loss: 31.507017135620117, Neurons: 58, Grad norm: 7.506e+00\n",
      "Epoch 5742, Loss: 31.455904006958008, Neurons: 58, Grad norm: 7.762e+00\n",
      "Epoch 5742, Loss: 31.455904006958008, Neurons: 58, Grad norm: 7.762e+00\n",
      "Epoch 5743, Loss: 31.404939651489258, Neurons: 58, Grad norm: 7.780e+00\n",
      "Epoch 5743, Loss: 31.404939651489258, Neurons: 58, Grad norm: 7.780e+00\n",
      "Epoch 5744, Loss: 31.353864669799805, Neurons: 58, Grad norm: 7.494e+00\n",
      "Epoch 5744, Loss: 31.353864669799805, Neurons: 58, Grad norm: 7.494e+00\n",
      "Epoch 5745, Loss: 31.30265998840332, Neurons: 58, Grad norm: 7.525e+00\n",
      "Epoch 5745, Loss: 31.30265998840332, Neurons: 58, Grad norm: 7.525e+00\n",
      "Epoch 5746, Loss: 31.251468658447266, Neurons: 58, Grad norm: 7.414e+00\n",
      "Epoch 5746, Loss: 31.251468658447266, Neurons: 58, Grad norm: 7.414e+00\n",
      "Epoch 5747, Loss: 31.200220108032227, Neurons: 58, Grad norm: 7.295e+00\n",
      "Epoch 5747, Loss: 31.200220108032227, Neurons: 58, Grad norm: 7.295e+00\n",
      "Epoch 5748, Loss: 31.148876190185547, Neurons: 58, Grad norm: 7.201e+00\n",
      "Epoch 5748, Loss: 31.148876190185547, Neurons: 58, Grad norm: 7.201e+00\n",
      "Epoch 5749, Loss: 31.097436904907227, Neurons: 58, Grad norm: 7.117e+00\n",
      "Epoch 5749, Loss: 31.097436904907227, Neurons: 58, Grad norm: 7.117e+00\n",
      "Epoch 5750, Loss: 31.045852661132812, Neurons: 58, Grad norm: 7.093e+00\n",
      "Epoch 5750, Loss: 31.045852661132812, Neurons: 58, Grad norm: 7.093e+00\n",
      "Epoch 5751, Loss: 30.994203567504883, Neurons: 58, Grad norm: 7.113e+00\n",
      "Epoch 5751, Loss: 30.994203567504883, Neurons: 58, Grad norm: 7.113e+00\n",
      "Epoch 5752, Loss: 30.942398071289062, Neurons: 58, Grad norm: 7.041e+00\n",
      "Epoch 5752, Loss: 30.942398071289062, Neurons: 58, Grad norm: 7.041e+00\n",
      "Epoch 5753, Loss: 30.890344619750977, Neurons: 58, Grad norm: 6.955e+00\n",
      "Epoch 5753, Loss: 30.890344619750977, Neurons: 58, Grad norm: 6.955e+00\n",
      "Epoch 5754, Loss: 30.838048934936523, Neurons: 58, Grad norm: 6.980e+00\n",
      "Epoch 5754, Loss: 30.838048934936523, Neurons: 58, Grad norm: 6.980e+00\n",
      "Epoch 5755, Loss: 30.785547256469727, Neurons: 58, Grad norm: 7.022e+00\n",
      "Epoch 5755, Loss: 30.785547256469727, Neurons: 58, Grad norm: 7.022e+00\n",
      "Epoch 5756, Loss: 30.732770919799805, Neurons: 58, Grad norm: 7.008e+00\n",
      "Epoch 5756, Loss: 30.732770919799805, Neurons: 58, Grad norm: 7.008e+00\n",
      "Epoch 5757, Loss: 30.679630279541016, Neurons: 58, Grad norm: 6.949e+00\n",
      "Epoch 5757, Loss: 30.679630279541016, Neurons: 58, Grad norm: 6.949e+00\n",
      "Epoch 5758, Loss: 30.626110076904297, Neurons: 58, Grad norm: 6.952e+00\n",
      "Epoch 5758, Loss: 30.626110076904297, Neurons: 58, Grad norm: 6.952e+00\n",
      "Epoch 5759, Loss: 30.57221794128418, Neurons: 58, Grad norm: 6.965e+00\n",
      "Epoch 5759, Loss: 30.57221794128418, Neurons: 58, Grad norm: 6.965e+00\n",
      "Epoch 5760, Loss: 30.517908096313477, Neurons: 58, Grad norm: 6.955e+00\n",
      "Epoch 5760, Loss: 30.517908096313477, Neurons: 58, Grad norm: 6.955e+00\n",
      "Epoch 5761, Loss: 30.463098526000977, Neurons: 58, Grad norm: 6.984e+00\n",
      "Epoch 5761, Loss: 30.463098526000977, Neurons: 58, Grad norm: 6.984e+00\n",
      "Epoch 5762, Loss: 30.407777786254883, Neurons: 58, Grad norm: 7.044e+00\n",
      "Epoch 5762, Loss: 30.407777786254883, Neurons: 58, Grad norm: 7.044e+00\n",
      "Epoch 5763, Loss: 30.351919174194336, Neurons: 58, Grad norm: 7.022e+00\n",
      "Epoch 5763, Loss: 30.351919174194336, Neurons: 58, Grad norm: 7.022e+00\n",
      "Epoch 5764, Loss: 30.29545783996582, Neurons: 58, Grad norm: 7.015e+00\n",
      "Epoch 5764, Loss: 30.29545783996582, Neurons: 58, Grad norm: 7.015e+00\n",
      "Epoch 5765, Loss: 30.238361358642578, Neurons: 58, Grad norm: 7.057e+00\n",
      "Epoch 5765, Loss: 30.238361358642578, Neurons: 58, Grad norm: 7.057e+00\n",
      "Epoch 5766, Loss: 30.180574417114258, Neurons: 58, Grad norm: 7.122e+00\n",
      "Epoch 5766, Loss: 30.180574417114258, Neurons: 58, Grad norm: 7.122e+00\n",
      "Epoch 5767, Loss: 30.1220645904541, Neurons: 58, Grad norm: 7.183e+00\n",
      "Epoch 5767, Loss: 30.1220645904541, Neurons: 58, Grad norm: 7.183e+00\n",
      "Epoch 5768, Loss: 30.062782287597656, Neurons: 58, Grad norm: 7.252e+00\n",
      "Epoch 5768, Loss: 30.062782287597656, Neurons: 58, Grad norm: 7.252e+00\n",
      "Epoch 5769, Loss: 30.0026912689209, Neurons: 58, Grad norm: 7.306e+00\n",
      "Epoch 5769, Loss: 30.0026912689209, Neurons: 58, Grad norm: 7.306e+00\n",
      "Epoch 5770, Loss: 29.941762924194336, Neurons: 58, Grad norm: 7.359e+00\n",
      "Epoch 5770, Loss: 29.941762924194336, Neurons: 58, Grad norm: 7.359e+00\n",
      "Epoch 5771, Loss: 29.879919052124023, Neurons: 58, Grad norm: 7.424e+00\n",
      "Epoch 5771, Loss: 29.879919052124023, Neurons: 58, Grad norm: 7.424e+00\n",
      "Epoch 5772, Loss: 29.817123413085938, Neurons: 58, Grad norm: 7.513e+00\n",
      "Epoch 5772, Loss: 29.817123413085938, Neurons: 58, Grad norm: 7.513e+00\n",
      "Epoch 5773, Loss: 29.753334045410156, Neurons: 58, Grad norm: 7.610e+00\n",
      "Epoch 5773, Loss: 29.753334045410156, Neurons: 58, Grad norm: 7.610e+00\n",
      "Epoch 5774, Loss: 29.68852424621582, Neurons: 58, Grad norm: 7.696e+00\n",
      "Epoch 5774, Loss: 29.68852424621582, Neurons: 58, Grad norm: 7.696e+00\n",
      "Epoch 5775, Loss: 29.622650146484375, Neurons: 58, Grad norm: 7.785e+00\n",
      "Epoch 5775, Loss: 29.622650146484375, Neurons: 58, Grad norm: 7.785e+00\n",
      "Epoch 5776, Loss: 29.55568504333496, Neurons: 58, Grad norm: 7.878e+00\n",
      "Epoch 5776, Loss: 29.55568504333496, Neurons: 58, Grad norm: 7.878e+00\n",
      "Epoch 5777, Loss: 29.487621307373047, Neurons: 58, Grad norm: 7.980e+00\n",
      "Epoch 5777, Loss: 29.487621307373047, Neurons: 58, Grad norm: 7.980e+00\n",
      "Epoch 5778, Loss: 29.418428421020508, Neurons: 58, Grad norm: 8.059e+00\n",
      "Epoch 5778, Loss: 29.418428421020508, Neurons: 58, Grad norm: 8.059e+00\n",
      "Epoch 5779, Loss: 29.348114013671875, Neurons: 58, Grad norm: 8.142e+00\n",
      "Epoch 5779, Loss: 29.348114013671875, Neurons: 58, Grad norm: 8.142e+00\n",
      "Epoch 5780, Loss: 29.276681900024414, Neurons: 58, Grad norm: 8.222e+00\n",
      "Epoch 5780, Loss: 29.276681900024414, Neurons: 58, Grad norm: 8.222e+00\n",
      "Epoch 5781, Loss: 29.204137802124023, Neurons: 58, Grad norm: 8.290e+00\n",
      "Epoch 5781, Loss: 29.204137802124023, Neurons: 58, Grad norm: 8.290e+00\n",
      "Epoch 5782, Loss: 29.130525588989258, Neurons: 58, Grad norm: 8.338e+00\n",
      "Epoch 5782, Loss: 29.130525588989258, Neurons: 58, Grad norm: 8.338e+00\n",
      "Epoch 5783, Loss: 29.0559139251709, Neurons: 58, Grad norm: 8.363e+00\n",
      "Epoch 5783, Loss: 29.0559139251709, Neurons: 58, Grad norm: 8.363e+00\n",
      "Epoch 5784, Loss: 28.98036766052246, Neurons: 58, Grad norm: 8.370e+00\n",
      "Epoch 5784, Loss: 28.98036766052246, Neurons: 58, Grad norm: 8.370e+00\n",
      "Epoch 5785, Loss: 28.904010772705078, Neurons: 58, Grad norm: 8.348e+00\n",
      "Epoch 5785, Loss: 28.904010772705078, Neurons: 58, Grad norm: 8.348e+00\n",
      "Epoch 5786, Loss: 28.82697868347168, Neurons: 58, Grad norm: 8.309e+00\n",
      "Epoch 5786, Loss: 28.82697868347168, Neurons: 58, Grad norm: 8.309e+00\n",
      "Epoch 5787, Loss: 28.749465942382812, Neurons: 58, Grad norm: 8.227e+00\n",
      "Epoch 5787, Loss: 28.749465942382812, Neurons: 58, Grad norm: 8.227e+00\n",
      "Epoch 5788, Loss: 28.671714782714844, Neurons: 58, Grad norm: 8.113e+00\n",
      "Epoch 5788, Loss: 28.671714782714844, Neurons: 58, Grad norm: 8.113e+00\n",
      "Epoch 5789, Loss: 28.59400749206543, Neurons: 58, Grad norm: 7.959e+00\n",
      "Epoch 5789, Loss: 28.59400749206543, Neurons: 58, Grad norm: 7.959e+00\n",
      "Epoch 5790, Loss: 28.51669692993164, Neurons: 58, Grad norm: 7.763e+00\n",
      "Epoch 5790, Loss: 28.51669692993164, Neurons: 58, Grad norm: 7.763e+00\n",
      "Epoch 5791, Loss: 28.440189361572266, Neurons: 58, Grad norm: 7.541e+00\n",
      "Epoch 5791, Loss: 28.440189361572266, Neurons: 58, Grad norm: 7.541e+00\n",
      "Epoch 5792, Loss: 28.36493492126465, Neurons: 58, Grad norm: 7.302e+00\n",
      "Epoch 5792, Loss: 28.36493492126465, Neurons: 58, Grad norm: 7.302e+00\n",
      "Epoch 5793, Loss: 28.291383743286133, Neurons: 58, Grad norm: 7.052e+00\n",
      "Epoch 5793, Loss: 28.291383743286133, Neurons: 58, Grad norm: 7.052e+00\n",
      "Epoch 5794, Loss: 28.219980239868164, Neurons: 58, Grad norm: 6.790e+00\n",
      "Epoch 5794, Loss: 28.219980239868164, Neurons: 58, Grad norm: 6.790e+00\n",
      "Epoch 5795, Loss: 28.15108299255371, Neurons: 58, Grad norm: 6.523e+00\n",
      "Epoch 5795, Loss: 28.15108299255371, Neurons: 58, Grad norm: 6.523e+00\n",
      "Epoch 5796, Loss: 28.084896087646484, Neurons: 58, Grad norm: 6.290e+00\n",
      "Epoch 5796, Loss: 28.084896087646484, Neurons: 58, Grad norm: 6.290e+00\n",
      "Epoch 5797, Loss: 28.021453857421875, Neurons: 58, Grad norm: 6.088e+00\n",
      "Epoch 5797, Loss: 28.021453857421875, Neurons: 58, Grad norm: 6.088e+00\n",
      "Epoch 5798, Loss: 27.960590362548828, Neurons: 58, Grad norm: 5.931e+00\n",
      "Epoch 5798, Loss: 27.960590362548828, Neurons: 58, Grad norm: 5.931e+00\n",
      "Epoch 5799, Loss: 27.902000427246094, Neurons: 58, Grad norm: 5.890e+00\n",
      "Epoch 5799, Loss: 27.902000427246094, Neurons: 58, Grad norm: 5.890e+00\n",
      "Epoch 5799, Test loss: 26.20977783203125\n",
      "Epoch 5799, Test loss: 26.20977783203125\n",
      "Added neuron to hidden layer 1 with activation tanh\n",
      "Added neuron to hidden layer 1 with activation tanh\n",
      "network shape updated to :[27, 31, 1]\n",
      "network shape updated to :[27, 31, 1]\n",
      "Epoch 5800, Loss: 668.8515014648438, Neurons: 59, Grad norm: 3.076e+03\n",
      "Epoch 5800, Loss: 668.8515014648438, Neurons: 59, Grad norm: 3.076e+03\n",
      "Epoch 5801, Loss: 659.4448852539062, Neurons: 59, Grad norm: 3.062e+03\n",
      "Epoch 5801, Loss: 659.4448852539062, Neurons: 59, Grad norm: 3.062e+03\n",
      "Epoch 5802, Loss: 649.6033935546875, Neurons: 59, Grad norm: 3.047e+03\n",
      "Epoch 5802, Loss: 649.6033935546875, Neurons: 59, Grad norm: 3.047e+03\n",
      "Epoch 5803, Loss: 639.3311767578125, Neurons: 59, Grad norm: 3.030e+03\n",
      "Epoch 5803, Loss: 639.3311767578125, Neurons: 59, Grad norm: 3.030e+03\n",
      "Epoch 5804, Loss: 628.6351928710938, Neurons: 59, Grad norm: 3.012e+03\n",
      "Epoch 5804, Loss: 628.6351928710938, Neurons: 59, Grad norm: 3.012e+03\n",
      "Epoch 5805, Loss: 617.525146484375, Neurons: 59, Grad norm: 2.992e+03\n",
      "Epoch 5805, Loss: 617.525146484375, Neurons: 59, Grad norm: 2.992e+03\n",
      "Epoch 5806, Loss: 606.0135498046875, Neurons: 59, Grad norm: 2.971e+03\n",
      "Epoch 5806, Loss: 606.0135498046875, Neurons: 59, Grad norm: 2.971e+03\n",
      "Epoch 5807, Loss: 594.115966796875, Neurons: 59, Grad norm: 2.950e+03\n",
      "Epoch 5807, Loss: 594.115966796875, Neurons: 59, Grad norm: 2.950e+03\n",
      "Epoch 5808, Loss: 581.8487548828125, Neurons: 59, Grad norm: 2.927e+03\n",
      "Epoch 5808, Loss: 581.8487548828125, Neurons: 59, Grad norm: 2.927e+03\n",
      "Epoch 5809, Loss: 569.2300415039062, Neurons: 59, Grad norm: 2.902e+03\n",
      "Epoch 5809, Loss: 569.2300415039062, Neurons: 59, Grad norm: 2.902e+03\n",
      "Epoch 5810, Loss: 556.2826538085938, Neurons: 59, Grad norm: 2.877e+03\n",
      "Epoch 5810, Loss: 556.2826538085938, Neurons: 59, Grad norm: 2.877e+03\n",
      "Epoch 5811, Loss: 543.0302734375, Neurons: 59, Grad norm: 2.850e+03\n",
      "Epoch 5811, Loss: 543.0302734375, Neurons: 59, Grad norm: 2.850e+03\n",
      "Epoch 5812, Loss: 529.4973754882812, Neurons: 59, Grad norm: 2.821e+03\n",
      "Epoch 5812, Loss: 529.4973754882812, Neurons: 59, Grad norm: 2.821e+03\n",
      "Epoch 5813, Loss: 515.7124633789062, Neurons: 59, Grad norm: 2.791e+03\n",
      "Epoch 5813, Loss: 515.7124633789062, Neurons: 59, Grad norm: 2.791e+03\n",
      "Epoch 5814, Loss: 501.7063293457031, Neurons: 59, Grad norm: 2.758e+03\n",
      "Epoch 5814, Loss: 501.7063293457031, Neurons: 59, Grad norm: 2.758e+03\n",
      "Epoch 5815, Loss: 487.51373291015625, Neurons: 59, Grad norm: 2.723e+03\n",
      "Epoch 5815, Loss: 487.51373291015625, Neurons: 59, Grad norm: 2.723e+03\n",
      "Epoch 5816, Loss: 473.16876220703125, Neurons: 59, Grad norm: 2.686e+03\n",
      "Epoch 5816, Loss: 473.16876220703125, Neurons: 59, Grad norm: 2.686e+03\n",
      "Epoch 5817, Loss: 458.7070617675781, Neurons: 59, Grad norm: 2.647e+03\n",
      "Epoch 5817, Loss: 458.7070617675781, Neurons: 59, Grad norm: 2.647e+03\n",
      "Epoch 5818, Loss: 444.1664733886719, Neurons: 59, Grad norm: 2.605e+03\n",
      "Epoch 5818, Loss: 444.1664733886719, Neurons: 59, Grad norm: 2.605e+03\n",
      "Epoch 5819, Loss: 429.5849304199219, Neurons: 59, Grad norm: 2.562e+03\n",
      "Epoch 5819, Loss: 429.5849304199219, Neurons: 59, Grad norm: 2.562e+03\n",
      "Epoch 5820, Loss: 415.0020751953125, Neurons: 59, Grad norm: 2.516e+03\n",
      "Epoch 5820, Loss: 415.0020751953125, Neurons: 59, Grad norm: 2.516e+03\n",
      "Epoch 5821, Loss: 400.4563903808594, Neurons: 59, Grad norm: 2.468e+03\n",
      "Epoch 5821, Loss: 400.4563903808594, Neurons: 59, Grad norm: 2.468e+03\n",
      "Epoch 5822, Loss: 385.98602294921875, Neurons: 59, Grad norm: 2.418e+03\n",
      "Epoch 5822, Loss: 385.98602294921875, Neurons: 59, Grad norm: 2.418e+03\n",
      "Epoch 5823, Loss: 371.62969970703125, Neurons: 59, Grad norm: 2.367e+03\n",
      "Epoch 5823, Loss: 371.62969970703125, Neurons: 59, Grad norm: 2.367e+03\n",
      "Epoch 5824, Loss: 357.4253845214844, Neurons: 59, Grad norm: 2.313e+03\n",
      "Epoch 5824, Loss: 357.4253845214844, Neurons: 59, Grad norm: 2.313e+03\n",
      "Epoch 5825, Loss: 343.40997314453125, Neurons: 59, Grad norm: 2.259e+03\n",
      "Epoch 5825, Loss: 343.40997314453125, Neurons: 59, Grad norm: 2.259e+03\n",
      "Epoch 5826, Loss: 329.6177062988281, Neurons: 59, Grad norm: 2.202e+03\n",
      "Epoch 5826, Loss: 329.6177062988281, Neurons: 59, Grad norm: 2.202e+03\n",
      "Epoch 5827, Loss: 316.0826721191406, Neurons: 59, Grad norm: 2.144e+03\n",
      "Epoch 5827, Loss: 316.0826721191406, Neurons: 59, Grad norm: 2.144e+03\n",
      "Epoch 5828, Loss: 302.8359375, Neurons: 59, Grad norm: 2.086e+03\n",
      "Epoch 5828, Loss: 302.8359375, Neurons: 59, Grad norm: 2.086e+03\n",
      "Epoch 5829, Loss: 289.9073486328125, Neurons: 59, Grad norm: 2.026e+03\n",
      "Epoch 5829, Loss: 289.9073486328125, Neurons: 59, Grad norm: 2.026e+03\n",
      "Epoch 5830, Loss: 277.3233947753906, Neurons: 59, Grad norm: 1.965e+03\n",
      "Epoch 5830, Loss: 277.3233947753906, Neurons: 59, Grad norm: 1.965e+03\n",
      "Epoch 5831, Loss: 265.1074523925781, Neurons: 59, Grad norm: 1.904e+03\n",
      "Epoch 5831, Loss: 265.1074523925781, Neurons: 59, Grad norm: 1.904e+03\n",
      "Epoch 5832, Loss: 253.28079223632812, Neurons: 59, Grad norm: 1.842e+03\n",
      "Epoch 5832, Loss: 253.28079223632812, Neurons: 59, Grad norm: 1.842e+03\n",
      "Epoch 5833, Loss: 241.8612060546875, Neurons: 59, Grad norm: 1.780e+03\n",
      "Epoch 5833, Loss: 241.8612060546875, Neurons: 59, Grad norm: 1.780e+03\n",
      "Epoch 5834, Loss: 230.8633575439453, Neurons: 59, Grad norm: 1.718e+03\n",
      "Epoch 5834, Loss: 230.8633575439453, Neurons: 59, Grad norm: 1.718e+03\n",
      "Epoch 5835, Loss: 220.29835510253906, Neurons: 59, Grad norm: 1.657e+03\n",
      "Epoch 5835, Loss: 220.29835510253906, Neurons: 59, Grad norm: 1.657e+03\n",
      "Epoch 5836, Loss: 210.17420959472656, Neurons: 59, Grad norm: 1.596e+03\n",
      "Epoch 5836, Loss: 210.17420959472656, Neurons: 59, Grad norm: 1.596e+03\n",
      "Epoch 5837, Loss: 200.49534606933594, Neurons: 59, Grad norm: 1.535e+03\n",
      "Epoch 5837, Loss: 200.49534606933594, Neurons: 59, Grad norm: 1.535e+03\n",
      "Epoch 5838, Loss: 191.26295471191406, Neurons: 59, Grad norm: 1.476e+03\n",
      "Epoch 5838, Loss: 191.26295471191406, Neurons: 59, Grad norm: 1.476e+03\n",
      "Epoch 5839, Loss: 182.47532653808594, Neurons: 59, Grad norm: 1.417e+03\n",
      "Epoch 5839, Loss: 182.47532653808594, Neurons: 59, Grad norm: 1.417e+03\n",
      "Epoch 5840, Loss: 174.1280059814453, Neurons: 59, Grad norm: 1.360e+03\n",
      "Epoch 5840, Loss: 174.1280059814453, Neurons: 59, Grad norm: 1.360e+03\n",
      "Epoch 5841, Loss: 166.21363830566406, Neurons: 59, Grad norm: 1.304e+03\n",
      "Epoch 5841, Loss: 166.21363830566406, Neurons: 59, Grad norm: 1.304e+03\n",
      "Epoch 5842, Loss: 158.72264099121094, Neurons: 59, Grad norm: 1.250e+03\n",
      "Epoch 5842, Loss: 158.72264099121094, Neurons: 59, Grad norm: 1.250e+03\n",
      "Epoch 5843, Loss: 151.64385986328125, Neurons: 59, Grad norm: 1.197e+03\n",
      "Epoch 5843, Loss: 151.64385986328125, Neurons: 59, Grad norm: 1.197e+03\n",
      "Epoch 5844, Loss: 144.9643096923828, Neurons: 59, Grad norm: 1.145e+03\n",
      "Epoch 5844, Loss: 144.9643096923828, Neurons: 59, Grad norm: 1.145e+03\n",
      "Epoch 5845, Loss: 138.6696014404297, Neurons: 59, Grad norm: 1.096e+03\n",
      "Epoch 5845, Loss: 138.6696014404297, Neurons: 59, Grad norm: 1.096e+03\n",
      "Epoch 5846, Loss: 132.7445068359375, Neurons: 59, Grad norm: 1.049e+03\n",
      "Epoch 5846, Loss: 132.7445068359375, Neurons: 59, Grad norm: 1.049e+03\n",
      "Epoch 5847, Loss: 127.17279052734375, Neurons: 59, Grad norm: 1.003e+03\n",
      "Epoch 5847, Loss: 127.17279052734375, Neurons: 59, Grad norm: 1.003e+03\n",
      "Epoch 5848, Loss: 121.93806457519531, Neurons: 59, Grad norm: 9.591e+02\n",
      "Epoch 5848, Loss: 121.93806457519531, Neurons: 59, Grad norm: 9.591e+02\n",
      "Epoch 5849, Loss: 117.023681640625, Neurons: 59, Grad norm: 9.172e+02\n",
      "Epoch 5849, Loss: 117.023681640625, Neurons: 59, Grad norm: 9.172e+02\n",
      "Epoch 5850, Loss: 112.41316986083984, Neurons: 59, Grad norm: 8.773e+02\n",
      "Epoch 5850, Loss: 112.41316986083984, Neurons: 59, Grad norm: 8.773e+02\n",
      "Epoch 5851, Loss: 108.09000396728516, Neurons: 59, Grad norm: 8.391e+02\n",
      "Epoch 5851, Loss: 108.09000396728516, Neurons: 59, Grad norm: 8.391e+02\n",
      "Epoch 5852, Loss: 104.03814697265625, Neurons: 59, Grad norm: 8.029e+02\n",
      "Epoch 5852, Loss: 104.03814697265625, Neurons: 59, Grad norm: 8.029e+02\n",
      "Epoch 5853, Loss: 100.24211120605469, Neurons: 59, Grad norm: 7.683e+02\n",
      "Epoch 5853, Loss: 100.24211120605469, Neurons: 59, Grad norm: 7.683e+02\n",
      "Epoch 5854, Loss: 96.686767578125, Neurons: 59, Grad norm: 7.356e+02\n",
      "Epoch 5854, Loss: 96.686767578125, Neurons: 59, Grad norm: 7.356e+02\n",
      "Epoch 5855, Loss: 93.3578872680664, Neurons: 59, Grad norm: 7.045e+02\n",
      "Epoch 5855, Loss: 93.3578872680664, Neurons: 59, Grad norm: 7.045e+02\n",
      "Epoch 5856, Loss: 90.24136352539062, Neurons: 59, Grad norm: 6.751e+02\n",
      "Epoch 5856, Loss: 90.24136352539062, Neurons: 59, Grad norm: 6.751e+02\n",
      "Epoch 5857, Loss: 87.32420349121094, Neurons: 59, Grad norm: 6.472e+02\n",
      "Epoch 5857, Loss: 87.32420349121094, Neurons: 59, Grad norm: 6.472e+02\n",
      "Epoch 5858, Loss: 84.59386444091797, Neurons: 59, Grad norm: 6.208e+02\n",
      "Epoch 5858, Loss: 84.59386444091797, Neurons: 59, Grad norm: 6.208e+02\n",
      "Epoch 5859, Loss: 82.03870391845703, Neurons: 59, Grad norm: 5.958e+02\n",
      "Epoch 5859, Loss: 82.03870391845703, Neurons: 59, Grad norm: 5.958e+02\n",
      "Epoch 5860, Loss: 79.64744567871094, Neurons: 59, Grad norm: 5.721e+02\n",
      "Epoch 5860, Loss: 79.64744567871094, Neurons: 59, Grad norm: 5.721e+02\n",
      "Epoch 5861, Loss: 77.40946960449219, Neurons: 59, Grad norm: 5.497e+02\n",
      "Epoch 5861, Loss: 77.40946960449219, Neurons: 59, Grad norm: 5.497e+02\n",
      "Epoch 5862, Loss: 75.31470489501953, Neurons: 59, Grad norm: 5.285e+02\n",
      "Epoch 5862, Loss: 75.31470489501953, Neurons: 59, Grad norm: 5.285e+02\n",
      "Epoch 5863, Loss: 73.35376739501953, Neurons: 59, Grad norm: 5.084e+02\n",
      "Epoch 5863, Loss: 73.35376739501953, Neurons: 59, Grad norm: 5.084e+02\n",
      "Epoch 5864, Loss: 71.51776885986328, Neurons: 59, Grad norm: 4.894e+02\n",
      "Epoch 5864, Loss: 71.51776885986328, Neurons: 59, Grad norm: 4.894e+02\n",
      "Epoch 5865, Loss: 69.7984390258789, Neurons: 59, Grad norm: 4.713e+02\n",
      "Epoch 5865, Loss: 69.7984390258789, Neurons: 59, Grad norm: 4.713e+02\n",
      "Epoch 5866, Loss: 68.18815612792969, Neurons: 59, Grad norm: 4.502e+02\n",
      "Epoch 5866, Loss: 68.18815612792969, Neurons: 59, Grad norm: 4.502e+02\n",
      "Epoch 5867, Loss: 66.6956558227539, Neurons: 59, Grad norm: 4.366e+02\n",
      "Epoch 5867, Loss: 66.6956558227539, Neurons: 59, Grad norm: 4.366e+02\n",
      "Epoch 5868, Loss: 65.3085708618164, Neurons: 59, Grad norm: 4.235e+02\n",
      "Epoch 5868, Loss: 65.3085708618164, Neurons: 59, Grad norm: 4.235e+02\n",
      "Epoch 5869, Loss: 63.99641799926758, Neurons: 59, Grad norm: 4.103e+02\n",
      "Epoch 5869, Loss: 63.99641799926758, Neurons: 59, Grad norm: 4.103e+02\n",
      "Epoch 5870, Loss: 62.7562370300293, Neurons: 59, Grad norm: 3.970e+02\n",
      "Epoch 5870, Loss: 62.7562370300293, Neurons: 59, Grad norm: 3.970e+02\n",
      "Epoch 5871, Loss: 61.58588409423828, Neurons: 59, Grad norm: 3.840e+02\n",
      "Epoch 5871, Loss: 61.58588409423828, Neurons: 59, Grad norm: 3.840e+02\n",
      "Epoch 5872, Loss: 60.483055114746094, Neurons: 59, Grad norm: 3.711e+02\n",
      "Epoch 5872, Loss: 60.483055114746094, Neurons: 59, Grad norm: 3.711e+02\n",
      "Epoch 5873, Loss: 59.444759368896484, Neurons: 59, Grad norm: 3.588e+02\n",
      "Epoch 5873, Loss: 59.444759368896484, Neurons: 59, Grad norm: 3.588e+02\n",
      "Epoch 5874, Loss: 58.46794509887695, Neurons: 59, Grad norm: 3.470e+02\n",
      "Epoch 5874, Loss: 58.46794509887695, Neurons: 59, Grad norm: 3.470e+02\n",
      "Epoch 5875, Loss: 57.548683166503906, Neurons: 59, Grad norm: 3.355e+02\n",
      "Epoch 5875, Loss: 57.548683166503906, Neurons: 59, Grad norm: 3.355e+02\n",
      "Epoch 5876, Loss: 56.68360900878906, Neurons: 59, Grad norm: 3.246e+02\n",
      "Epoch 5876, Loss: 56.68360900878906, Neurons: 59, Grad norm: 3.246e+02\n",
      "Epoch 5877, Loss: 55.87216567993164, Neurons: 59, Grad norm: 3.144e+02\n",
      "Epoch 5877, Loss: 55.87216567993164, Neurons: 59, Grad norm: 3.144e+02\n",
      "Epoch 5878, Loss: 55.109798431396484, Neurons: 59, Grad norm: 3.048e+02\n",
      "Epoch 5878, Loss: 55.109798431396484, Neurons: 59, Grad norm: 3.048e+02\n",
      "Epoch 5879, Loss: 54.39313888549805, Neurons: 59, Grad norm: 2.956e+02\n",
      "Epoch 5879, Loss: 54.39313888549805, Neurons: 59, Grad norm: 2.956e+02\n",
      "Epoch 5880, Loss: 53.71936798095703, Neurons: 59, Grad norm: 2.868e+02\n",
      "Epoch 5880, Loss: 53.71936798095703, Neurons: 59, Grad norm: 2.868e+02\n",
      "Epoch 5881, Loss: 53.0857048034668, Neurons: 59, Grad norm: 2.785e+02\n",
      "Epoch 5881, Loss: 53.0857048034668, Neurons: 59, Grad norm: 2.785e+02\n",
      "Epoch 5882, Loss: 52.48960876464844, Neurons: 59, Grad norm: 2.706e+02\n",
      "Epoch 5882, Loss: 52.48960876464844, Neurons: 59, Grad norm: 2.706e+02\n",
      "Epoch 5883, Loss: 51.92859649658203, Neurons: 59, Grad norm: 2.630e+02\n",
      "Epoch 5883, Loss: 51.92859649658203, Neurons: 59, Grad norm: 2.630e+02\n",
      "Epoch 5884, Loss: 51.400245666503906, Neurons: 59, Grad norm: 2.558e+02\n",
      "Epoch 5884, Loss: 51.400245666503906, Neurons: 59, Grad norm: 2.558e+02\n",
      "Epoch 5885, Loss: 50.902313232421875, Neurons: 59, Grad norm: 2.489e+02\n",
      "Epoch 5885, Loss: 50.902313232421875, Neurons: 59, Grad norm: 2.489e+02\n",
      "Epoch 5886, Loss: 50.43259048461914, Neurons: 59, Grad norm: 2.424e+02\n",
      "Epoch 5886, Loss: 50.43259048461914, Neurons: 59, Grad norm: 2.424e+02\n",
      "Epoch 5887, Loss: 49.989017486572266, Neurons: 59, Grad norm: 2.362e+02\n",
      "Epoch 5887, Loss: 49.989017486572266, Neurons: 59, Grad norm: 2.362e+02\n",
      "Epoch 5888, Loss: 49.56959915161133, Neurons: 59, Grad norm: 2.302e+02\n",
      "Epoch 5888, Loss: 49.56959915161133, Neurons: 59, Grad norm: 2.302e+02\n",
      "Epoch 5889, Loss: 49.172462463378906, Neurons: 59, Grad norm: 2.246e+02\n",
      "Epoch 5889, Loss: 49.172462463378906, Neurons: 59, Grad norm: 2.246e+02\n",
      "Epoch 5890, Loss: 48.79589080810547, Neurons: 59, Grad norm: 2.192e+02\n",
      "Epoch 5890, Loss: 48.79589080810547, Neurons: 59, Grad norm: 2.192e+02\n",
      "Epoch 5891, Loss: 48.43821334838867, Neurons: 59, Grad norm: 2.140e+02\n",
      "Epoch 5891, Loss: 48.43821334838867, Neurons: 59, Grad norm: 2.140e+02\n",
      "Epoch 5892, Loss: 48.09791564941406, Neurons: 59, Grad norm: 2.091e+02\n",
      "Epoch 5892, Loss: 48.09791564941406, Neurons: 59, Grad norm: 2.091e+02\n",
      "Epoch 5893, Loss: 47.7735710144043, Neurons: 59, Grad norm: 2.044e+02\n",
      "Epoch 5893, Loss: 47.7735710144043, Neurons: 59, Grad norm: 2.044e+02\n",
      "Epoch 5894, Loss: 47.46391677856445, Neurons: 59, Grad norm: 1.999e+02\n",
      "Epoch 5894, Loss: 47.46391677856445, Neurons: 59, Grad norm: 1.999e+02\n",
      "Epoch 5895, Loss: 47.16775894165039, Neurons: 59, Grad norm: 1.955e+02\n",
      "Epoch 5895, Loss: 47.16775894165039, Neurons: 59, Grad norm: 1.955e+02\n",
      "Epoch 5896, Loss: 46.88398742675781, Neurons: 59, Grad norm: 1.914e+02\n",
      "Epoch 5896, Loss: 46.88398742675781, Neurons: 59, Grad norm: 1.914e+02\n",
      "Epoch 5897, Loss: 46.611629486083984, Neurons: 59, Grad norm: 1.875e+02\n",
      "Epoch 5897, Loss: 46.611629486083984, Neurons: 59, Grad norm: 1.875e+02\n",
      "Epoch 5898, Loss: 46.34979248046875, Neurons: 59, Grad norm: 1.837e+02\n",
      "Epoch 5898, Loss: 46.34979248046875, Neurons: 59, Grad norm: 1.837e+02\n",
      "Epoch 5899, Loss: 46.09761047363281, Neurons: 59, Grad norm: 1.800e+02\n",
      "Epoch 5899, Loss: 46.09761047363281, Neurons: 59, Grad norm: 1.800e+02\n",
      "Epoch 5899, Test loss: 43.62379455566406\n",
      "Epoch 5899, Test loss: 43.62379455566406\n",
      "Removed neuron to hidden layer 1 at index 26\n",
      "Removed neuron to hidden layer 1 at index 26\n",
      "network shape updated to :[26, 31, 1]\n",
      "network shape updated to :[26, 31, 1]\n",
      "Epoch 5900, Loss: 234.36227416992188, Neurons: 58, Grad norm: 1.394e+03\n",
      "Epoch 5900, Loss: 234.36227416992188, Neurons: 58, Grad norm: 1.394e+03\n",
      "Epoch 5901, Loss: 230.03684997558594, Neurons: 58, Grad norm: 1.374e+03\n",
      "Epoch 5901, Loss: 230.03684997558594, Neurons: 58, Grad norm: 1.374e+03\n",
      "Epoch 5902, Loss: 225.56117248535156, Neurons: 58, Grad norm: 1.352e+03\n",
      "Epoch 5902, Loss: 225.56117248535156, Neurons: 58, Grad norm: 1.352e+03\n",
      "Epoch 5903, Loss: 220.94473266601562, Neurons: 58, Grad norm: 1.329e+03\n",
      "Epoch 5903, Loss: 220.94473266601562, Neurons: 58, Grad norm: 1.329e+03\n",
      "Epoch 5904, Loss: 216.19970703125, Neurons: 58, Grad norm: 1.306e+03\n",
      "Epoch 5904, Loss: 216.19970703125, Neurons: 58, Grad norm: 1.306e+03\n",
      "Epoch 5905, Loss: 211.33900451660156, Neurons: 58, Grad norm: 1.281e+03\n",
      "Epoch 5905, Loss: 211.33900451660156, Neurons: 58, Grad norm: 1.281e+03\n",
      "Epoch 5906, Loss: 206.37794494628906, Neurons: 58, Grad norm: 1.255e+03\n",
      "Epoch 5906, Loss: 206.37794494628906, Neurons: 58, Grad norm: 1.255e+03\n",
      "Epoch 5907, Loss: 201.33309936523438, Neurons: 58, Grad norm: 1.228e+03\n",
      "Epoch 5907, Loss: 201.33309936523438, Neurons: 58, Grad norm: 1.228e+03\n",
      "Epoch 5908, Loss: 196.22254943847656, Neurons: 58, Grad norm: 1.201e+03\n",
      "Epoch 5908, Loss: 196.22254943847656, Neurons: 58, Grad norm: 1.201e+03\n",
      "Epoch 5909, Loss: 191.06466674804688, Neurons: 58, Grad norm: 1.173e+03\n",
      "Epoch 5909, Loss: 191.06466674804688, Neurons: 58, Grad norm: 1.173e+03\n",
      "Epoch 5910, Loss: 185.87857055664062, Neurons: 58, Grad norm: 1.144e+03\n",
      "Epoch 5910, Loss: 185.87857055664062, Neurons: 58, Grad norm: 1.144e+03\n",
      "Epoch 5911, Loss: 180.683837890625, Neurons: 58, Grad norm: 1.114e+03\n",
      "Epoch 5911, Loss: 180.683837890625, Neurons: 58, Grad norm: 1.114e+03\n",
      "Epoch 5912, Loss: 175.49935913085938, Neurons: 58, Grad norm: 1.085e+03\n",
      "Epoch 5912, Loss: 175.49935913085938, Neurons: 58, Grad norm: 1.085e+03\n",
      "Epoch 5913, Loss: 170.3438720703125, Neurons: 58, Grad norm: 1.055e+03\n",
      "Epoch 5913, Loss: 170.3438720703125, Neurons: 58, Grad norm: 1.055e+03\n",
      "Epoch 5914, Loss: 165.23513793945312, Neurons: 58, Grad norm: 1.025e+03\n",
      "Epoch 5914, Loss: 165.23513793945312, Neurons: 58, Grad norm: 1.025e+03\n",
      "Epoch 5915, Loss: 160.1894073486328, Neurons: 58, Grad norm: 9.944e+02\n",
      "Epoch 5915, Loss: 160.1894073486328, Neurons: 58, Grad norm: 9.944e+02\n",
      "Epoch 5916, Loss: 155.22207641601562, Neurons: 58, Grad norm: 9.643e+02\n",
      "Epoch 5916, Loss: 155.22207641601562, Neurons: 58, Grad norm: 9.643e+02\n",
      "Epoch 5917, Loss: 150.34616088867188, Neurons: 58, Grad norm: 9.344e+02\n",
      "Epoch 5917, Loss: 150.34616088867188, Neurons: 58, Grad norm: 9.344e+02\n",
      "Epoch 5918, Loss: 145.57374572753906, Neurons: 58, Grad norm: 9.047e+02\n",
      "Epoch 5918, Loss: 145.57374572753906, Neurons: 58, Grad norm: 9.047e+02\n",
      "Epoch 5919, Loss: 140.91468811035156, Neurons: 58, Grad norm: 8.755e+02\n",
      "Epoch 5919, Loss: 140.91468811035156, Neurons: 58, Grad norm: 8.755e+02\n",
      "Epoch 5920, Loss: 136.37738037109375, Neurons: 58, Grad norm: 8.466e+02\n",
      "Epoch 5920, Loss: 136.37738037109375, Neurons: 58, Grad norm: 8.466e+02\n",
      "Epoch 5921, Loss: 131.96875, Neurons: 58, Grad norm: 8.185e+02\n",
      "Epoch 5921, Loss: 131.96875, Neurons: 58, Grad norm: 8.185e+02\n",
      "Epoch 5922, Loss: 127.69400024414062, Neurons: 58, Grad norm: 7.911e+02\n",
      "Epoch 5922, Loss: 127.69400024414062, Neurons: 58, Grad norm: 7.911e+02\n",
      "Epoch 5923, Loss: 123.55577087402344, Neurons: 58, Grad norm: 7.642e+02\n",
      "Epoch 5923, Loss: 123.55577087402344, Neurons: 58, Grad norm: 7.642e+02\n",
      "Epoch 5924, Loss: 119.55643463134766, Neurons: 58, Grad norm: 7.381e+02\n",
      "Epoch 5924, Loss: 119.55643463134766, Neurons: 58, Grad norm: 7.381e+02\n",
      "Epoch 5925, Loss: 115.696533203125, Neurons: 58, Grad norm: 7.128e+02\n",
      "Epoch 5925, Loss: 115.696533203125, Neurons: 58, Grad norm: 7.128e+02\n",
      "Epoch 5926, Loss: 111.97460174560547, Neurons: 58, Grad norm: 6.883e+02\n",
      "Epoch 5926, Loss: 111.97460174560547, Neurons: 58, Grad norm: 6.883e+02\n",
      "Epoch 5927, Loss: 108.38859558105469, Neurons: 58, Grad norm: 6.646e+02\n",
      "Epoch 5927, Loss: 108.38859558105469, Neurons: 58, Grad norm: 6.646e+02\n",
      "Epoch 5928, Loss: 104.93585205078125, Neurons: 58, Grad norm: 6.418e+02\n",
      "Epoch 5928, Loss: 104.93585205078125, Neurons: 58, Grad norm: 6.418e+02\n",
      "Epoch 5929, Loss: 101.6133041381836, Neurons: 58, Grad norm: 6.197e+02\n",
      "Epoch 5929, Loss: 101.6133041381836, Neurons: 58, Grad norm: 6.197e+02\n",
      "Epoch 5930, Loss: 98.41715240478516, Neurons: 58, Grad norm: 5.984e+02\n",
      "Epoch 5930, Loss: 98.41715240478516, Neurons: 58, Grad norm: 5.984e+02\n",
      "Epoch 5931, Loss: 95.34356689453125, Neurons: 58, Grad norm: 5.778e+02\n",
      "Epoch 5931, Loss: 95.34356689453125, Neurons: 58, Grad norm: 5.778e+02\n",
      "Epoch 5932, Loss: 92.38874053955078, Neurons: 58, Grad norm: 5.580e+02\n",
      "Epoch 5932, Loss: 92.38874053955078, Neurons: 58, Grad norm: 5.580e+02\n",
      "Epoch 5933, Loss: 89.54886627197266, Neurons: 58, Grad norm: 5.389e+02\n",
      "Epoch 5933, Loss: 89.54886627197266, Neurons: 58, Grad norm: 5.389e+02\n",
      "Epoch 5934, Loss: 86.81990814208984, Neurons: 58, Grad norm: 5.205e+02\n",
      "Epoch 5934, Loss: 86.81990814208984, Neurons: 58, Grad norm: 5.205e+02\n",
      "Epoch 5935, Loss: 84.19831848144531, Neurons: 58, Grad norm: 5.028e+02\n",
      "Epoch 5935, Loss: 84.19831848144531, Neurons: 58, Grad norm: 5.028e+02\n",
      "Epoch 5936, Loss: 81.68011474609375, Neurons: 58, Grad norm: 4.858e+02\n",
      "Epoch 5936, Loss: 81.68011474609375, Neurons: 58, Grad norm: 4.858e+02\n",
      "Epoch 5937, Loss: 79.26193237304688, Neurons: 58, Grad norm: 4.693e+02\n",
      "Epoch 5937, Loss: 79.26193237304688, Neurons: 58, Grad norm: 4.693e+02\n",
      "Epoch 5938, Loss: 76.94050598144531, Neurons: 58, Grad norm: 4.536e+02\n",
      "Epoch 5938, Loss: 76.94050598144531, Neurons: 58, Grad norm: 4.536e+02\n",
      "Epoch 5939, Loss: 74.71279907226562, Neurons: 58, Grad norm: 4.384e+02\n",
      "Epoch 5939, Loss: 74.71279907226562, Neurons: 58, Grad norm: 4.384e+02\n",
      "Epoch 5940, Loss: 72.57581329345703, Neurons: 58, Grad norm: 4.239e+02\n",
      "Epoch 5940, Loss: 72.57581329345703, Neurons: 58, Grad norm: 4.239e+02\n",
      "Epoch 5941, Loss: 70.52705383300781, Neurons: 58, Grad norm: 4.099e+02\n",
      "Epoch 5941, Loss: 70.52705383300781, Neurons: 58, Grad norm: 4.099e+02\n",
      "Epoch 5942, Loss: 68.56403350830078, Neurons: 58, Grad norm: 3.964e+02\n",
      "Epoch 5942, Loss: 68.56403350830078, Neurons: 58, Grad norm: 3.964e+02\n",
      "Epoch 5943, Loss: 66.68448638916016, Neurons: 58, Grad norm: 3.836e+02\n",
      "Epoch 5943, Loss: 66.68448638916016, Neurons: 58, Grad norm: 3.836e+02\n",
      "Epoch 5944, Loss: 64.88611602783203, Neurons: 58, Grad norm: 3.713e+02\n",
      "Epoch 5944, Loss: 64.88611602783203, Neurons: 58, Grad norm: 3.713e+02\n",
      "Epoch 5945, Loss: 63.1667366027832, Neurons: 58, Grad norm: 3.595e+02\n",
      "Epoch 5945, Loss: 63.1667366027832, Neurons: 58, Grad norm: 3.595e+02\n",
      "Epoch 5946, Loss: 61.52430725097656, Neurons: 58, Grad norm: 3.483e+02\n",
      "Epoch 5946, Loss: 61.52430725097656, Neurons: 58, Grad norm: 3.483e+02\n",
      "Epoch 5947, Loss: 59.95665740966797, Neurons: 58, Grad norm: 3.375e+02\n",
      "Epoch 5947, Loss: 59.95665740966797, Neurons: 58, Grad norm: 3.375e+02\n",
      "Epoch 5948, Loss: 58.461666107177734, Neurons: 58, Grad norm: 3.273e+02\n",
      "Epoch 5948, Loss: 58.461666107177734, Neurons: 58, Grad norm: 3.273e+02\n",
      "Epoch 5949, Loss: 57.037071228027344, Neurons: 58, Grad norm: 3.175e+02\n",
      "Epoch 5949, Loss: 57.037071228027344, Neurons: 58, Grad norm: 3.175e+02\n",
      "Epoch 5950, Loss: 55.680625915527344, Neurons: 58, Grad norm: 3.081e+02\n",
      "Epoch 5950, Loss: 55.680625915527344, Neurons: 58, Grad norm: 3.081e+02\n",
      "Epoch 5951, Loss: 54.38996124267578, Neurons: 58, Grad norm: 2.992e+02\n",
      "Epoch 5951, Loss: 54.38996124267578, Neurons: 58, Grad norm: 2.992e+02\n",
      "Epoch 5952, Loss: 53.16267776489258, Neurons: 58, Grad norm: 2.906e+02\n",
      "Epoch 5952, Loss: 53.16267776489258, Neurons: 58, Grad norm: 2.906e+02\n",
      "Epoch 5953, Loss: 51.99628829956055, Neurons: 58, Grad norm: 2.823e+02\n",
      "Epoch 5953, Loss: 51.99628829956055, Neurons: 58, Grad norm: 2.823e+02\n",
      "Epoch 5954, Loss: 50.88835906982422, Neurons: 58, Grad norm: 2.744e+02\n",
      "Epoch 5954, Loss: 50.88835906982422, Neurons: 58, Grad norm: 2.744e+02\n",
      "Epoch 5955, Loss: 49.83636474609375, Neurons: 58, Grad norm: 2.668e+02\n",
      "Epoch 5955, Loss: 49.83636474609375, Neurons: 58, Grad norm: 2.668e+02\n",
      "Epoch 5956, Loss: 48.837947845458984, Neurons: 58, Grad norm: 2.593e+02\n",
      "Epoch 5956, Loss: 48.837947845458984, Neurons: 58, Grad norm: 2.593e+02\n",
      "Epoch 5957, Loss: 47.89076614379883, Neurons: 58, Grad norm: 2.522e+02\n",
      "Epoch 5957, Loss: 47.89076614379883, Neurons: 58, Grad norm: 2.522e+02\n",
      "Epoch 5958, Loss: 46.9925651550293, Neurons: 58, Grad norm: 2.452e+02\n",
      "Epoch 5958, Loss: 46.9925651550293, Neurons: 58, Grad norm: 2.452e+02\n",
      "Epoch 5959, Loss: 46.14106750488281, Neurons: 58, Grad norm: 2.384e+02\n",
      "Epoch 5959, Loss: 46.14106750488281, Neurons: 58, Grad norm: 2.384e+02\n",
      "Epoch 5960, Loss: 45.334190368652344, Neurons: 58, Grad norm: 2.318e+02\n",
      "Epoch 5960, Loss: 45.334190368652344, Neurons: 58, Grad norm: 2.318e+02\n",
      "Epoch 5961, Loss: 44.56975173950195, Neurons: 58, Grad norm: 2.254e+02\n",
      "Epoch 5961, Loss: 44.56975173950195, Neurons: 58, Grad norm: 2.254e+02\n",
      "Epoch 5962, Loss: 43.84572219848633, Neurons: 58, Grad norm: 2.191e+02\n",
      "Epoch 5962, Loss: 43.84572219848633, Neurons: 58, Grad norm: 2.191e+02\n",
      "Epoch 5963, Loss: 43.15995407104492, Neurons: 58, Grad norm: 2.129e+02\n",
      "Epoch 5963, Loss: 43.15995407104492, Neurons: 58, Grad norm: 2.129e+02\n",
      "Epoch 5964, Loss: 42.51033020019531, Neurons: 58, Grad norm: 2.069e+02\n",
      "Epoch 5964, Loss: 42.51033020019531, Neurons: 58, Grad norm: 2.069e+02\n",
      "Epoch 5965, Loss: 41.89496994018555, Neurons: 58, Grad norm: 2.011e+02\n",
      "Epoch 5965, Loss: 41.89496994018555, Neurons: 58, Grad norm: 2.011e+02\n",
      "Epoch 5966, Loss: 41.31189727783203, Neurons: 58, Grad norm: 1.954e+02\n",
      "Epoch 5966, Loss: 41.31189727783203, Neurons: 58, Grad norm: 1.954e+02\n",
      "Epoch 5967, Loss: 40.75912094116211, Neurons: 58, Grad norm: 1.899e+02\n",
      "Epoch 5967, Loss: 40.75912094116211, Neurons: 58, Grad norm: 1.899e+02\n",
      "Epoch 5968, Loss: 40.23491668701172, Neurons: 58, Grad norm: 1.845e+02\n",
      "Epoch 5968, Loss: 40.23491668701172, Neurons: 58, Grad norm: 1.845e+02\n",
      "Epoch 5969, Loss: 39.73736572265625, Neurons: 58, Grad norm: 1.793e+02\n",
      "Epoch 5969, Loss: 39.73736572265625, Neurons: 58, Grad norm: 1.793e+02\n",
      "Epoch 5970, Loss: 39.26479721069336, Neurons: 58, Grad norm: 1.742e+02\n",
      "Epoch 5970, Loss: 39.26479721069336, Neurons: 58, Grad norm: 1.742e+02\n",
      "Epoch 5971, Loss: 38.815467834472656, Neurons: 58, Grad norm: 1.692e+02\n",
      "Epoch 5971, Loss: 38.815467834472656, Neurons: 58, Grad norm: 1.692e+02\n",
      "Epoch 5972, Loss: 38.38779067993164, Neurons: 58, Grad norm: 1.644e+02\n",
      "Epoch 5972, Loss: 38.38779067993164, Neurons: 58, Grad norm: 1.644e+02\n",
      "Epoch 5973, Loss: 37.98025131225586, Neurons: 58, Grad norm: 1.597e+02\n",
      "Epoch 5973, Loss: 37.98025131225586, Neurons: 58, Grad norm: 1.597e+02\n",
      "Epoch 5974, Loss: 37.591522216796875, Neurons: 58, Grad norm: 1.551e+02\n",
      "Epoch 5974, Loss: 37.591522216796875, Neurons: 58, Grad norm: 1.551e+02\n",
      "Epoch 5975, Loss: 37.220298767089844, Neurons: 58, Grad norm: 1.506e+02\n",
      "Epoch 5975, Loss: 37.220298767089844, Neurons: 58, Grad norm: 1.506e+02\n",
      "Epoch 5976, Loss: 36.86538314819336, Neurons: 58, Grad norm: 1.463e+02\n",
      "Epoch 5976, Loss: 36.86538314819336, Neurons: 58, Grad norm: 1.463e+02\n",
      "Epoch 5977, Loss: 36.52579116821289, Neurons: 58, Grad norm: 1.421e+02\n",
      "Epoch 5977, Loss: 36.52579116821289, Neurons: 58, Grad norm: 1.421e+02\n",
      "Epoch 5978, Loss: 36.200504302978516, Neurons: 58, Grad norm: 1.381e+02\n",
      "Epoch 5978, Loss: 36.200504302978516, Neurons: 58, Grad norm: 1.381e+02\n",
      "Epoch 5979, Loss: 35.888641357421875, Neurons: 58, Grad norm: 1.342e+02\n",
      "Epoch 5979, Loss: 35.888641357421875, Neurons: 58, Grad norm: 1.342e+02\n",
      "Epoch 5980, Loss: 35.58937072753906, Neurons: 58, Grad norm: 1.304e+02\n",
      "Epoch 5980, Loss: 35.58937072753906, Neurons: 58, Grad norm: 1.304e+02\n",
      "Epoch 5981, Loss: 35.30190658569336, Neurons: 58, Grad norm: 1.268e+02\n",
      "Epoch 5981, Loss: 35.30190658569336, Neurons: 58, Grad norm: 1.268e+02\n",
      "Epoch 5982, Loss: 35.02558135986328, Neurons: 58, Grad norm: 1.233e+02\n",
      "Epoch 5982, Loss: 35.02558135986328, Neurons: 58, Grad norm: 1.233e+02\n",
      "Epoch 5983, Loss: 34.759765625, Neurons: 58, Grad norm: 1.199e+02\n",
      "Epoch 5983, Loss: 34.759765625, Neurons: 58, Grad norm: 1.199e+02\n",
      "Epoch 5984, Loss: 34.503875732421875, Neurons: 58, Grad norm: 1.167e+02\n",
      "Epoch 5984, Loss: 34.503875732421875, Neurons: 58, Grad norm: 1.167e+02\n",
      "Epoch 5985, Loss: 34.25736999511719, Neurons: 58, Grad norm: 1.135e+02\n",
      "Epoch 5985, Loss: 34.25736999511719, Neurons: 58, Grad norm: 1.135e+02\n",
      "Epoch 5986, Loss: 34.019744873046875, Neurons: 58, Grad norm: 1.105e+02\n",
      "Epoch 5986, Loss: 34.019744873046875, Neurons: 58, Grad norm: 1.105e+02\n",
      "Epoch 5987, Loss: 33.790565490722656, Neurons: 58, Grad norm: 1.075e+02\n",
      "Epoch 5987, Loss: 33.790565490722656, Neurons: 58, Grad norm: 1.075e+02\n",
      "Epoch 5988, Loss: 33.56938552856445, Neurons: 58, Grad norm: 1.047e+02\n",
      "Epoch 5988, Loss: 33.56938552856445, Neurons: 58, Grad norm: 1.047e+02\n",
      "Epoch 5989, Loss: 33.355831146240234, Neurons: 58, Grad norm: 1.020e+02\n",
      "Epoch 5989, Loss: 33.355831146240234, Neurons: 58, Grad norm: 1.020e+02\n",
      "Epoch 5990, Loss: 33.14954376220703, Neurons: 58, Grad norm: 9.935e+01\n",
      "Epoch 5990, Loss: 33.14954376220703, Neurons: 58, Grad norm: 9.935e+01\n",
      "Epoch 5991, Loss: 32.9501953125, Neurons: 58, Grad norm: 9.682e+01\n",
      "Epoch 5991, Loss: 32.9501953125, Neurons: 58, Grad norm: 9.682e+01\n",
      "Epoch 5992, Loss: 32.75748825073242, Neurons: 58, Grad norm: 9.432e+01\n",
      "Epoch 5992, Loss: 32.75748825073242, Neurons: 58, Grad norm: 9.432e+01\n",
      "Epoch 5993, Loss: 32.571144104003906, Neurons: 58, Grad norm: 9.190e+01\n",
      "Epoch 5993, Loss: 32.571144104003906, Neurons: 58, Grad norm: 9.190e+01\n",
      "Epoch 5994, Loss: 32.390899658203125, Neurons: 58, Grad norm: 8.958e+01\n",
      "Epoch 5994, Loss: 32.390899658203125, Neurons: 58, Grad norm: 8.958e+01\n",
      "Epoch 5995, Loss: 32.21653747558594, Neurons: 58, Grad norm: 8.730e+01\n",
      "Epoch 5995, Loss: 32.21653747558594, Neurons: 58, Grad norm: 8.730e+01\n",
      "Epoch 5996, Loss: 32.047828674316406, Neurons: 58, Grad norm: 8.507e+01\n",
      "Epoch 5996, Loss: 32.047828674316406, Neurons: 58, Grad norm: 8.507e+01\n",
      "Epoch 5997, Loss: 31.884559631347656, Neurons: 58, Grad norm: 8.288e+01\n",
      "Epoch 5997, Loss: 31.884559631347656, Neurons: 58, Grad norm: 8.288e+01\n",
      "Epoch 5998, Loss: 31.726545333862305, Neurons: 58, Grad norm: 8.078e+01\n",
      "Epoch 5998, Loss: 31.726545333862305, Neurons: 58, Grad norm: 8.078e+01\n",
      "Epoch 5999, Loss: 31.5736141204834, Neurons: 58, Grad norm: 7.876e+01\n",
      "Epoch 5999, Loss: 31.5736141204834, Neurons: 58, Grad norm: 7.876e+01\n",
      "Epoch 5999, Test loss: 29.499515533447266\n",
      "Epoch 5999, Test loss: 29.499515533447266\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "network shape updated to :[26, 32, 1]\n",
      "network shape updated to :[26, 32, 1]\n",
      "Epoch 6000, Loss: 31.484220504760742, Neurons: 59, Grad norm: 7.533e+01\n",
      "Epoch 6000, Loss: 31.484220504760742, Neurons: 59, Grad norm: 7.533e+01\n",
      "Epoch 6001, Loss: 31.220746994018555, Neurons: 59, Grad norm: 6.850e+01\n",
      "Epoch 6001, Loss: 31.220746994018555, Neurons: 59, Grad norm: 6.850e+01\n",
      "Epoch 6002, Loss: 30.979629516601562, Neurons: 59, Grad norm: 6.388e+01\n",
      "Epoch 6002, Loss: 30.979629516601562, Neurons: 59, Grad norm: 6.388e+01\n",
      "Epoch 6003, Loss: 30.755821228027344, Neurons: 59, Grad norm: 5.985e+01\n",
      "Epoch 6003, Loss: 30.755821228027344, Neurons: 59, Grad norm: 5.985e+01\n",
      "Epoch 6004, Loss: 30.542123794555664, Neurons: 59, Grad norm: 5.565e+01\n",
      "Epoch 6004, Loss: 30.542123794555664, Neurons: 59, Grad norm: 5.565e+01\n",
      "Epoch 6005, Loss: 30.334657669067383, Neurons: 59, Grad norm: 5.099e+01\n",
      "Epoch 6005, Loss: 30.334657669067383, Neurons: 59, Grad norm: 5.099e+01\n",
      "Epoch 6006, Loss: 30.1326847076416, Neurons: 59, Grad norm: 4.635e+01\n",
      "Epoch 6006, Loss: 30.1326847076416, Neurons: 59, Grad norm: 4.635e+01\n",
      "Epoch 6007, Loss: 29.937747955322266, Neurons: 59, Grad norm: 4.239e+01\n",
      "Epoch 6007, Loss: 29.937747955322266, Neurons: 59, Grad norm: 4.239e+01\n",
      "Epoch 6008, Loss: 29.752235412597656, Neurons: 59, Grad norm: 3.970e+01\n",
      "Epoch 6008, Loss: 29.752235412597656, Neurons: 59, Grad norm: 3.970e+01\n",
      "Epoch 6009, Loss: 29.57791519165039, Neurons: 59, Grad norm: 3.809e+01\n",
      "Epoch 6009, Loss: 29.57791519165039, Neurons: 59, Grad norm: 3.809e+01\n",
      "Epoch 6010, Loss: 29.41495132446289, Neurons: 59, Grad norm: 3.679e+01\n",
      "Epoch 6010, Loss: 29.41495132446289, Neurons: 59, Grad norm: 3.679e+01\n",
      "Epoch 6011, Loss: 29.262229919433594, Neurons: 59, Grad norm: 3.513e+01\n",
      "Epoch 6011, Loss: 29.262229919433594, Neurons: 59, Grad norm: 3.513e+01\n",
      "Epoch 6012, Loss: 29.118459701538086, Neurons: 59, Grad norm: 3.280e+01\n",
      "Epoch 6012, Loss: 29.118459701538086, Neurons: 59, Grad norm: 3.280e+01\n",
      "Epoch 6013, Loss: 28.982852935791016, Neurons: 59, Grad norm: 2.997e+01\n",
      "Epoch 6013, Loss: 28.982852935791016, Neurons: 59, Grad norm: 2.997e+01\n",
      "Epoch 6014, Loss: 28.855117797851562, Neurons: 59, Grad norm: 2.707e+01\n",
      "Epoch 6014, Loss: 28.855117797851562, Neurons: 59, Grad norm: 2.707e+01\n",
      "Epoch 6015, Loss: 28.735082626342773, Neurons: 59, Grad norm: 2.467e+01\n",
      "Epoch 6015, Loss: 28.735082626342773, Neurons: 59, Grad norm: 2.467e+01\n",
      "Epoch 6016, Loss: 28.622373580932617, Neurons: 59, Grad norm: 2.295e+01\n",
      "Epoch 6016, Loss: 28.622373580932617, Neurons: 59, Grad norm: 2.295e+01\n",
      "Epoch 6017, Loss: 28.516311645507812, Neurons: 59, Grad norm: 2.190e+01\n",
      "Epoch 6017, Loss: 28.516311645507812, Neurons: 59, Grad norm: 2.190e+01\n",
      "Epoch 6018, Loss: 28.416067123413086, Neurons: 59, Grad norm: 2.108e+01\n",
      "Epoch 6018, Loss: 28.416067123413086, Neurons: 59, Grad norm: 2.108e+01\n",
      "Epoch 6019, Loss: 28.320859909057617, Neurons: 59, Grad norm: 2.024e+01\n",
      "Epoch 6019, Loss: 28.320859909057617, Neurons: 59, Grad norm: 2.024e+01\n",
      "Epoch 6020, Loss: 28.230331420898438, Neurons: 59, Grad norm: 1.923e+01\n",
      "Epoch 6020, Loss: 28.230331420898438, Neurons: 59, Grad norm: 1.923e+01\n",
      "Epoch 6021, Loss: 28.14440155029297, Neurons: 59, Grad norm: 1.810e+01\n",
      "Epoch 6021, Loss: 28.14440155029297, Neurons: 59, Grad norm: 1.810e+01\n",
      "Epoch 6022, Loss: 28.063270568847656, Neurons: 59, Grad norm: 1.703e+01\n",
      "Epoch 6022, Loss: 28.063270568847656, Neurons: 59, Grad norm: 1.703e+01\n",
      "Epoch 6023, Loss: 27.9870548248291, Neurons: 59, Grad norm: 1.613e+01\n",
      "Epoch 6023, Loss: 27.9870548248291, Neurons: 59, Grad norm: 1.613e+01\n",
      "Epoch 6024, Loss: 27.915700912475586, Neurons: 59, Grad norm: 1.546e+01\n",
      "Epoch 6024, Loss: 27.915700912475586, Neurons: 59, Grad norm: 1.546e+01\n",
      "Epoch 6025, Loss: 27.848876953125, Neurons: 59, Grad norm: 1.489e+01\n",
      "Epoch 6025, Loss: 27.848876953125, Neurons: 59, Grad norm: 1.489e+01\n",
      "Epoch 6026, Loss: 27.786026000976562, Neurons: 59, Grad norm: 1.431e+01\n",
      "Epoch 6026, Loss: 27.786026000976562, Neurons: 59, Grad norm: 1.431e+01\n",
      "Epoch 6027, Loss: 27.726585388183594, Neurons: 59, Grad norm: 1.359e+01\n",
      "Epoch 6027, Loss: 27.726585388183594, Neurons: 59, Grad norm: 1.359e+01\n",
      "Epoch 6028, Loss: 27.67002296447754, Neurons: 59, Grad norm: 1.281e+01\n",
      "Epoch 6028, Loss: 27.67002296447754, Neurons: 59, Grad norm: 1.281e+01\n",
      "Epoch 6029, Loss: 27.615903854370117, Neurons: 59, Grad norm: 1.208e+01\n",
      "Epoch 6029, Loss: 27.615903854370117, Neurons: 59, Grad norm: 1.208e+01\n",
      "Epoch 6030, Loss: 27.56387710571289, Neurons: 59, Grad norm: 1.146e+01\n",
      "Epoch 6030, Loss: 27.56387710571289, Neurons: 59, Grad norm: 1.146e+01\n",
      "Epoch 6031, Loss: 27.513595581054688, Neurons: 59, Grad norm: 1.101e+01\n",
      "Epoch 6031, Loss: 27.513595581054688, Neurons: 59, Grad norm: 1.101e+01\n",
      "Epoch 6032, Loss: 27.464828491210938, Neurons: 59, Grad norm: 1.069e+01\n",
      "Epoch 6032, Loss: 27.464828491210938, Neurons: 59, Grad norm: 1.069e+01\n",
      "Epoch 6033, Loss: 27.417348861694336, Neurons: 59, Grad norm: 1.047e+01\n",
      "Epoch 6033, Loss: 27.417348861694336, Neurons: 59, Grad norm: 1.047e+01\n",
      "Epoch 6034, Loss: 27.37095069885254, Neurons: 59, Grad norm: 1.023e+01\n",
      "Epoch 6034, Loss: 27.37095069885254, Neurons: 59, Grad norm: 1.023e+01\n",
      "Epoch 6035, Loss: 27.325424194335938, Neurons: 59, Grad norm: 9.942e+00\n",
      "Epoch 6035, Loss: 27.325424194335938, Neurons: 59, Grad norm: 9.942e+00\n",
      "Epoch 6036, Loss: 27.280588150024414, Neurons: 59, Grad norm: 9.702e+00\n",
      "Epoch 6036, Loss: 27.280588150024414, Neurons: 59, Grad norm: 9.702e+00\n",
      "Epoch 6037, Loss: 27.236318588256836, Neurons: 59, Grad norm: 9.513e+00\n",
      "Epoch 6037, Loss: 27.236318588256836, Neurons: 59, Grad norm: 9.513e+00\n",
      "Epoch 6038, Loss: 27.19247817993164, Neurons: 59, Grad norm: 9.399e+00\n",
      "Epoch 6038, Loss: 27.19247817993164, Neurons: 59, Grad norm: 9.399e+00\n",
      "Epoch 6039, Loss: 27.1489315032959, Neurons: 59, Grad norm: 9.357e+00\n",
      "Epoch 6039, Loss: 27.1489315032959, Neurons: 59, Grad norm: 9.357e+00\n",
      "Epoch 6040, Loss: 27.105510711669922, Neurons: 59, Grad norm: 9.320e+00\n",
      "Epoch 6040, Loss: 27.105510711669922, Neurons: 59, Grad norm: 9.320e+00\n",
      "Epoch 6041, Loss: 27.06207275390625, Neurons: 59, Grad norm: 9.277e+00\n",
      "Epoch 6041, Loss: 27.06207275390625, Neurons: 59, Grad norm: 9.277e+00\n",
      "Epoch 6042, Loss: 27.018482208251953, Neurons: 59, Grad norm: 9.219e+00\n",
      "Epoch 6042, Loss: 27.018482208251953, Neurons: 59, Grad norm: 9.219e+00\n",
      "Epoch 6043, Loss: 26.974672317504883, Neurons: 59, Grad norm: 9.161e+00\n",
      "Epoch 6043, Loss: 26.974672317504883, Neurons: 59, Grad norm: 9.161e+00\n",
      "Epoch 6044, Loss: 26.930591583251953, Neurons: 59, Grad norm: 9.115e+00\n",
      "Epoch 6044, Loss: 26.930591583251953, Neurons: 59, Grad norm: 9.115e+00\n",
      "Epoch 6045, Loss: 26.88618278503418, Neurons: 59, Grad norm: 9.129e+00\n",
      "Epoch 6045, Loss: 26.88618278503418, Neurons: 59, Grad norm: 9.129e+00\n",
      "Epoch 6046, Loss: 26.841367721557617, Neurons: 59, Grad norm: 9.140e+00\n",
      "Epoch 6046, Loss: 26.841367721557617, Neurons: 59, Grad norm: 9.140e+00\n",
      "Epoch 6047, Loss: 26.79604721069336, Neurons: 59, Grad norm: 9.192e+00\n",
      "Epoch 6047, Loss: 26.79604721069336, Neurons: 59, Grad norm: 9.192e+00\n",
      "Epoch 6048, Loss: 26.750125885009766, Neurons: 59, Grad norm: 9.259e+00\n",
      "Epoch 6048, Loss: 26.750125885009766, Neurons: 59, Grad norm: 9.259e+00\n",
      "Epoch 6049, Loss: 26.70350456237793, Neurons: 59, Grad norm: 9.332e+00\n",
      "Epoch 6049, Loss: 26.70350456237793, Neurons: 59, Grad norm: 9.332e+00\n",
      "Epoch 6050, Loss: 26.656103134155273, Neurons: 59, Grad norm: 9.432e+00\n",
      "Epoch 6050, Loss: 26.656103134155273, Neurons: 59, Grad norm: 9.432e+00\n",
      "Epoch 6051, Loss: 26.60785484313965, Neurons: 59, Grad norm: 9.544e+00\n",
      "Epoch 6051, Loss: 26.60785484313965, Neurons: 59, Grad norm: 9.544e+00\n",
      "Epoch 6052, Loss: 26.55868911743164, Neurons: 59, Grad norm: 9.666e+00\n",
      "Epoch 6052, Loss: 26.55868911743164, Neurons: 59, Grad norm: 9.666e+00\n",
      "Epoch 6053, Loss: 26.508527755737305, Neurons: 59, Grad norm: 9.786e+00\n",
      "Epoch 6053, Loss: 26.508527755737305, Neurons: 59, Grad norm: 9.786e+00\n",
      "Epoch 6054, Loss: 26.45732879638672, Neurons: 59, Grad norm: 9.867e+00\n",
      "Epoch 6054, Loss: 26.45732879638672, Neurons: 59, Grad norm: 9.867e+00\n",
      "Epoch 6055, Loss: 26.40503692626953, Neurons: 59, Grad norm: 9.956e+00\n",
      "Epoch 6055, Loss: 26.40503692626953, Neurons: 59, Grad norm: 9.956e+00\n",
      "Epoch 6056, Loss: 26.351608276367188, Neurons: 59, Grad norm: 1.002e+01\n",
      "Epoch 6056, Loss: 26.351608276367188, Neurons: 59, Grad norm: 1.002e+01\n",
      "Epoch 6057, Loss: 26.296998977661133, Neurons: 59, Grad norm: 1.010e+01\n",
      "Epoch 6057, Loss: 26.296998977661133, Neurons: 59, Grad norm: 1.010e+01\n",
      "Epoch 6058, Loss: 26.241168975830078, Neurons: 59, Grad norm: 1.020e+01\n",
      "Epoch 6058, Loss: 26.241168975830078, Neurons: 59, Grad norm: 1.020e+01\n",
      "Epoch 6059, Loss: 26.18407440185547, Neurons: 59, Grad norm: 1.032e+01\n",
      "Epoch 6059, Loss: 26.18407440185547, Neurons: 59, Grad norm: 1.032e+01\n",
      "Epoch 6060, Loss: 26.125659942626953, Neurons: 59, Grad norm: 1.045e+01\n",
      "Epoch 6060, Loss: 26.125659942626953, Neurons: 59, Grad norm: 1.045e+01\n",
      "Epoch 6061, Loss: 26.06589126586914, Neurons: 59, Grad norm: 1.060e+01\n",
      "Epoch 6061, Loss: 26.06589126586914, Neurons: 59, Grad norm: 1.060e+01\n",
      "Epoch 6062, Loss: 26.004732131958008, Neurons: 59, Grad norm: 1.075e+01\n",
      "Epoch 6062, Loss: 26.004732131958008, Neurons: 59, Grad norm: 1.075e+01\n",
      "Epoch 6063, Loss: 25.94215202331543, Neurons: 59, Grad norm: 1.095e+01\n",
      "Epoch 6063, Loss: 25.94215202331543, Neurons: 59, Grad norm: 1.095e+01\n",
      "Epoch 6064, Loss: 25.87812614440918, Neurons: 59, Grad norm: 1.116e+01\n",
      "Epoch 6064, Loss: 25.87812614440918, Neurons: 59, Grad norm: 1.116e+01\n",
      "Epoch 6065, Loss: 25.812610626220703, Neurons: 59, Grad norm: 1.136e+01\n",
      "Epoch 6065, Loss: 25.812610626220703, Neurons: 59, Grad norm: 1.136e+01\n",
      "Epoch 6066, Loss: 25.745586395263672, Neurons: 59, Grad norm: 1.153e+01\n",
      "Epoch 6066, Loss: 25.745586395263672, Neurons: 59, Grad norm: 1.153e+01\n",
      "Epoch 6067, Loss: 25.677021026611328, Neurons: 59, Grad norm: 1.167e+01\n",
      "Epoch 6067, Loss: 25.677021026611328, Neurons: 59, Grad norm: 1.167e+01\n",
      "Epoch 6068, Loss: 25.606908798217773, Neurons: 59, Grad norm: 1.180e+01\n",
      "Epoch 6068, Loss: 25.606908798217773, Neurons: 59, Grad norm: 1.180e+01\n",
      "Epoch 6069, Loss: 25.53525161743164, Neurons: 59, Grad norm: 1.192e+01\n",
      "Epoch 6069, Loss: 25.53525161743164, Neurons: 59, Grad norm: 1.192e+01\n",
      "Epoch 6070, Loss: 25.462072372436523, Neurons: 59, Grad norm: 1.203e+01\n",
      "Epoch 6070, Loss: 25.462072372436523, Neurons: 59, Grad norm: 1.203e+01\n",
      "Epoch 6071, Loss: 25.387413024902344, Neurons: 59, Grad norm: 1.217e+01\n",
      "Epoch 6071, Loss: 25.387413024902344, Neurons: 59, Grad norm: 1.217e+01\n",
      "Epoch 6072, Loss: 25.311338424682617, Neurons: 59, Grad norm: 1.226e+01\n",
      "Epoch 6072, Loss: 25.311338424682617, Neurons: 59, Grad norm: 1.226e+01\n",
      "Epoch 6073, Loss: 25.233938217163086, Neurons: 59, Grad norm: 1.232e+01\n",
      "Epoch 6073, Loss: 25.233938217163086, Neurons: 59, Grad norm: 1.232e+01\n",
      "Epoch 6074, Loss: 25.155336380004883, Neurons: 59, Grad norm: 1.234e+01\n",
      "Epoch 6074, Loss: 25.155336380004883, Neurons: 59, Grad norm: 1.234e+01\n",
      "Epoch 6075, Loss: 25.075708389282227, Neurons: 59, Grad norm: 1.232e+01\n",
      "Epoch 6075, Loss: 25.075708389282227, Neurons: 59, Grad norm: 1.232e+01\n",
      "Epoch 6076, Loss: 24.995262145996094, Neurons: 59, Grad norm: 1.226e+01\n",
      "Epoch 6076, Loss: 24.995262145996094, Neurons: 59, Grad norm: 1.226e+01\n",
      "Epoch 6077, Loss: 24.914270401000977, Neurons: 59, Grad norm: 1.213e+01\n",
      "Epoch 6077, Loss: 24.914270401000977, Neurons: 59, Grad norm: 1.213e+01\n",
      "Epoch 6078, Loss: 24.833091735839844, Neurons: 59, Grad norm: 1.191e+01\n",
      "Epoch 6078, Loss: 24.833091735839844, Neurons: 59, Grad norm: 1.191e+01\n",
      "Epoch 6079, Loss: 24.75214195251465, Neurons: 59, Grad norm: 1.159e+01\n",
      "Epoch 6079, Loss: 24.75214195251465, Neurons: 59, Grad norm: 1.159e+01\n",
      "Epoch 6080, Loss: 24.671934127807617, Neurons: 59, Grad norm: 1.123e+01\n",
      "Epoch 6080, Loss: 24.671934127807617, Neurons: 59, Grad norm: 1.123e+01\n",
      "Epoch 6081, Loss: 24.593067169189453, Neurons: 59, Grad norm: 1.083e+01\n",
      "Epoch 6081, Loss: 24.593067169189453, Neurons: 59, Grad norm: 1.083e+01\n",
      "Epoch 6082, Loss: 24.51618003845215, Neurons: 59, Grad norm: 1.036e+01\n",
      "Epoch 6082, Loss: 24.51618003845215, Neurons: 59, Grad norm: 1.036e+01\n",
      "Epoch 6083, Loss: 24.441953659057617, Neurons: 59, Grad norm: 9.856e+00\n",
      "Epoch 6083, Loss: 24.441953659057617, Neurons: 59, Grad norm: 9.856e+00\n",
      "Epoch 6084, Loss: 24.371000289916992, Neurons: 59, Grad norm: 9.330e+00\n",
      "Epoch 6084, Loss: 24.371000289916992, Neurons: 59, Grad norm: 9.330e+00\n",
      "Epoch 6085, Loss: 24.303813934326172, Neurons: 59, Grad norm: 8.785e+00\n",
      "Epoch 6085, Loss: 24.303813934326172, Neurons: 59, Grad norm: 8.785e+00\n",
      "Epoch 6086, Loss: 24.240665435791016, Neurons: 59, Grad norm: 8.274e+00\n",
      "Epoch 6086, Loss: 24.240665435791016, Neurons: 59, Grad norm: 8.274e+00\n",
      "Epoch 6087, Loss: 24.18160629272461, Neurons: 59, Grad norm: 7.807e+00\n",
      "Epoch 6087, Loss: 24.18160629272461, Neurons: 59, Grad norm: 7.807e+00\n",
      "Epoch 6088, Loss: 24.12644386291504, Neurons: 59, Grad norm: 7.374e+00\n",
      "Epoch 6088, Loss: 24.12644386291504, Neurons: 59, Grad norm: 7.374e+00\n",
      "Epoch 6089, Loss: 24.074844360351562, Neurons: 59, Grad norm: 7.000e+00\n",
      "Epoch 6089, Loss: 24.074844360351562, Neurons: 59, Grad norm: 7.000e+00\n",
      "Epoch 6090, Loss: 24.026365280151367, Neurons: 59, Grad norm: 6.688e+00\n",
      "Epoch 6090, Loss: 24.026365280151367, Neurons: 59, Grad norm: 6.688e+00\n",
      "Epoch 6091, Loss: 23.980527877807617, Neurons: 59, Grad norm: 6.468e+00\n",
      "Epoch 6091, Loss: 23.980527877807617, Neurons: 59, Grad norm: 6.468e+00\n",
      "Epoch 6092, Loss: 23.93683624267578, Neurons: 59, Grad norm: 6.318e+00\n",
      "Epoch 6092, Loss: 23.93683624267578, Neurons: 59, Grad norm: 6.318e+00\n",
      "Epoch 6093, Loss: 23.89483642578125, Neurons: 59, Grad norm: 6.215e+00\n",
      "Epoch 6093, Loss: 23.89483642578125, Neurons: 59, Grad norm: 6.215e+00\n",
      "Epoch 6094, Loss: 23.854129791259766, Neurons: 59, Grad norm: 6.148e+00\n",
      "Epoch 6094, Loss: 23.854129791259766, Neurons: 59, Grad norm: 6.148e+00\n",
      "Epoch 6095, Loss: 23.814369201660156, Neurons: 59, Grad norm: 6.107e+00\n",
      "Epoch 6095, Loss: 23.814369201660156, Neurons: 59, Grad norm: 6.107e+00\n",
      "Epoch 6096, Loss: 23.775272369384766, Neurons: 59, Grad norm: 6.080e+00\n",
      "Epoch 6096, Loss: 23.775272369384766, Neurons: 59, Grad norm: 6.080e+00\n",
      "Epoch 6097, Loss: 23.736629486083984, Neurons: 59, Grad norm: 6.058e+00\n",
      "Epoch 6097, Loss: 23.736629486083984, Neurons: 59, Grad norm: 6.058e+00\n",
      "Epoch 6098, Loss: 23.698293685913086, Neurons: 59, Grad norm: 6.032e+00\n",
      "Epoch 6098, Loss: 23.698293685913086, Neurons: 59, Grad norm: 6.032e+00\n",
      "Epoch 6099, Loss: 23.6601619720459, Neurons: 59, Grad norm: 6.006e+00\n",
      "Epoch 6099, Loss: 23.6601619720459, Neurons: 59, Grad norm: 6.006e+00\n",
      "Epoch 6099, Test loss: 22.165607452392578\n",
      "Epoch 6099, Test loss: 22.165607452392578\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "Added neuron to hidden layer 2 with activation relu\n",
      "network shape updated to :[26, 33, 1]\n",
      "network shape updated to :[26, 33, 1]\n",
      "Epoch 6100, Loss: 23.63796615600586, Neurons: 60, Grad norm: 1.260e+01\n",
      "Epoch 6100, Loss: 23.63796615600586, Neurons: 60, Grad norm: 1.260e+01\n",
      "Epoch 6101, Loss: 23.619876861572266, Neurons: 60, Grad norm: 1.052e+01\n",
      "Epoch 6101, Loss: 23.619876861572266, Neurons: 60, Grad norm: 1.052e+01\n",
      "Epoch 6102, Loss: 23.59834861755371, Neurons: 60, Grad norm: 1.347e+01\n",
      "Epoch 6102, Loss: 23.59834861755371, Neurons: 60, Grad norm: 1.347e+01\n",
      "Epoch 6103, Loss: 23.581296920776367, Neurons: 60, Grad norm: 8.700e+00\n",
      "Epoch 6103, Loss: 23.581296920776367, Neurons: 60, Grad norm: 8.700e+00\n",
      "Epoch 6104, Loss: 23.559480667114258, Neurons: 60, Grad norm: 6.073e+00\n",
      "Epoch 6104, Loss: 23.559480667114258, Neurons: 60, Grad norm: 6.073e+00\n",
      "Epoch 6105, Loss: 23.539161682128906, Neurons: 60, Grad norm: 8.766e+00\n",
      "Epoch 6105, Loss: 23.539161682128906, Neurons: 60, Grad norm: 8.766e+00\n",
      "Epoch 6106, Loss: 23.52058982849121, Neurons: 60, Grad norm: 8.025e+00\n",
      "Epoch 6106, Loss: 23.52058982849121, Neurons: 60, Grad norm: 8.025e+00\n",
      "Epoch 6107, Loss: 23.4993896484375, Neurons: 60, Grad norm: 5.776e+00\n",
      "Epoch 6107, Loss: 23.4993896484375, Neurons: 60, Grad norm: 5.776e+00\n",
      "Epoch 6108, Loss: 23.47673225402832, Neurons: 60, Grad norm: 6.521e+00\n",
      "Epoch 6108, Loss: 23.47673225402832, Neurons: 60, Grad norm: 6.521e+00\n",
      "Epoch 6109, Loss: 23.454816818237305, Neurons: 60, Grad norm: 7.526e+00\n",
      "Epoch 6109, Loss: 23.454816818237305, Neurons: 60, Grad norm: 7.526e+00\n",
      "Epoch 6110, Loss: 23.432682037353516, Neurons: 60, Grad norm: 6.786e+00\n",
      "Epoch 6110, Loss: 23.432682037353516, Neurons: 60, Grad norm: 6.786e+00\n",
      "Epoch 6111, Loss: 23.4093017578125, Neurons: 60, Grad norm: 5.838e+00\n",
      "Epoch 6111, Loss: 23.4093017578125, Neurons: 60, Grad norm: 5.838e+00\n",
      "Epoch 6112, Loss: 23.385356903076172, Neurons: 60, Grad norm: 5.817e+00\n",
      "Epoch 6112, Loss: 23.385356903076172, Neurons: 60, Grad norm: 5.817e+00\n",
      "Epoch 6113, Loss: 23.361278533935547, Neurons: 60, Grad norm: 5.742e+00\n",
      "Epoch 6113, Loss: 23.361278533935547, Neurons: 60, Grad norm: 5.742e+00\n",
      "Epoch 6114, Loss: 23.33662986755371, Neurons: 60, Grad norm: 5.664e+00\n",
      "Epoch 6114, Loss: 23.33662986755371, Neurons: 60, Grad norm: 5.664e+00\n",
      "Epoch 6115, Loss: 23.311494827270508, Neurons: 60, Grad norm: 6.068e+00\n",
      "Epoch 6115, Loss: 23.311494827270508, Neurons: 60, Grad norm: 6.068e+00\n",
      "Epoch 6116, Loss: 23.286117553710938, Neurons: 60, Grad norm: 6.221e+00\n",
      "Epoch 6116, Loss: 23.286117553710938, Neurons: 60, Grad norm: 6.221e+00\n",
      "Epoch 6117, Loss: 23.26019287109375, Neurons: 60, Grad norm: 5.728e+00\n",
      "Epoch 6117, Loss: 23.26019287109375, Neurons: 60, Grad norm: 5.728e+00\n",
      "Epoch 6118, Loss: 23.233423233032227, Neurons: 60, Grad norm: 5.248e+00\n",
      "Epoch 6118, Loss: 23.233423233032227, Neurons: 60, Grad norm: 5.248e+00\n",
      "Epoch 6119, Loss: 23.206134796142578, Neurons: 60, Grad norm: 5.279e+00\n",
      "Epoch 6119, Loss: 23.206134796142578, Neurons: 60, Grad norm: 5.279e+00\n",
      "Epoch 6120, Loss: 23.178720474243164, Neurons: 60, Grad norm: 5.419e+00\n",
      "Epoch 6120, Loss: 23.178720474243164, Neurons: 60, Grad norm: 5.419e+00\n",
      "Epoch 6121, Loss: 23.151147842407227, Neurons: 60, Grad norm: 5.421e+00\n",
      "Epoch 6121, Loss: 23.151147842407227, Neurons: 60, Grad norm: 5.421e+00\n",
      "Epoch 6122, Loss: 23.123083114624023, Neurons: 60, Grad norm: 5.352e+00\n",
      "Epoch 6122, Loss: 23.123083114624023, Neurons: 60, Grad norm: 5.352e+00\n",
      "Epoch 6123, Loss: 23.094444274902344, Neurons: 60, Grad norm: 5.258e+00\n",
      "Epoch 6123, Loss: 23.094444274902344, Neurons: 60, Grad norm: 5.258e+00\n",
      "Epoch 6124, Loss: 23.065488815307617, Neurons: 60, Grad norm: 5.144e+00\n",
      "Epoch 6124, Loss: 23.065488815307617, Neurons: 60, Grad norm: 5.144e+00\n",
      "Epoch 6125, Loss: 23.03630256652832, Neurons: 60, Grad norm: 5.081e+00\n",
      "Epoch 6125, Loss: 23.03630256652832, Neurons: 60, Grad norm: 5.081e+00\n",
      "Epoch 6126, Loss: 23.006803512573242, Neurons: 60, Grad norm: 5.105e+00\n",
      "Epoch 6126, Loss: 23.006803512573242, Neurons: 60, Grad norm: 5.105e+00\n",
      "Epoch 6127, Loss: 22.97699737548828, Neurons: 60, Grad norm: 5.133e+00\n",
      "Epoch 6127, Loss: 22.97699737548828, Neurons: 60, Grad norm: 5.133e+00\n",
      "Epoch 6128, Loss: 22.94694709777832, Neurons: 60, Grad norm: 5.143e+00\n",
      "Epoch 6128, Loss: 22.94694709777832, Neurons: 60, Grad norm: 5.143e+00\n",
      "Epoch 6129, Loss: 22.916629791259766, Neurons: 60, Grad norm: 5.216e+00\n",
      "Epoch 6129, Loss: 22.916629791259766, Neurons: 60, Grad norm: 5.216e+00\n",
      "Epoch 6130, Loss: 22.886056900024414, Neurons: 60, Grad norm: 5.312e+00\n",
      "Epoch 6130, Loss: 22.886056900024414, Neurons: 60, Grad norm: 5.312e+00\n",
      "Epoch 6131, Loss: 22.85525894165039, Neurons: 60, Grad norm: 5.293e+00\n",
      "Epoch 6131, Loss: 22.85525894165039, Neurons: 60, Grad norm: 5.293e+00\n",
      "Epoch 6132, Loss: 22.824125289916992, Neurons: 60, Grad norm: 5.124e+00\n",
      "Epoch 6132, Loss: 22.824125289916992, Neurons: 60, Grad norm: 5.124e+00\n",
      "Epoch 6133, Loss: 22.79261016845703, Neurons: 60, Grad norm: 4.978e+00\n",
      "Epoch 6133, Loss: 22.79261016845703, Neurons: 60, Grad norm: 4.978e+00\n",
      "Epoch 6134, Loss: 22.760868072509766, Neurons: 60, Grad norm: 4.977e+00\n",
      "Epoch 6134, Loss: 22.760868072509766, Neurons: 60, Grad norm: 4.977e+00\n",
      "Epoch 6135, Loss: 22.72900390625, Neurons: 60, Grad norm: 4.944e+00\n",
      "Epoch 6135, Loss: 22.72900390625, Neurons: 60, Grad norm: 4.944e+00\n",
      "Epoch 6136, Loss: 22.696884155273438, Neurons: 60, Grad norm: 5.026e+00\n",
      "Epoch 6136, Loss: 22.696884155273438, Neurons: 60, Grad norm: 5.026e+00\n",
      "Epoch 6137, Loss: 22.664634704589844, Neurons: 60, Grad norm: 5.469e+00\n",
      "Epoch 6137, Loss: 22.664634704589844, Neurons: 60, Grad norm: 5.469e+00\n",
      "Epoch 6138, Loss: 22.632410049438477, Neurons: 60, Grad norm: 5.045e+00\n",
      "Epoch 6138, Loss: 22.632410049438477, Neurons: 60, Grad norm: 5.045e+00\n",
      "Epoch 6139, Loss: 22.599353790283203, Neurons: 60, Grad norm: 5.084e+00\n",
      "Epoch 6139, Loss: 22.599353790283203, Neurons: 60, Grad norm: 5.084e+00\n",
      "Epoch 6140, Loss: 22.566516876220703, Neurons: 60, Grad norm: 4.945e+00\n",
      "Epoch 6140, Loss: 22.566516876220703, Neurons: 60, Grad norm: 4.945e+00\n",
      "Epoch 6141, Loss: 22.533411026000977, Neurons: 60, Grad norm: 4.902e+00\n",
      "Epoch 6141, Loss: 22.533411026000977, Neurons: 60, Grad norm: 4.902e+00\n",
      "Epoch 6142, Loss: 22.50014877319336, Neurons: 60, Grad norm: 4.926e+00\n",
      "Epoch 6142, Loss: 22.50014877319336, Neurons: 60, Grad norm: 4.926e+00\n",
      "Epoch 6143, Loss: 22.466651916503906, Neurons: 60, Grad norm: 5.034e+00\n",
      "Epoch 6143, Loss: 22.466651916503906, Neurons: 60, Grad norm: 5.034e+00\n",
      "Epoch 6144, Loss: 22.432920455932617, Neurons: 60, Grad norm: 5.066e+00\n",
      "Epoch 6144, Loss: 22.432920455932617, Neurons: 60, Grad norm: 5.066e+00\n",
      "Epoch 6145, Loss: 22.398996353149414, Neurons: 60, Grad norm: 4.924e+00\n",
      "Epoch 6145, Loss: 22.398996353149414, Neurons: 60, Grad norm: 4.924e+00\n",
      "Epoch 6146, Loss: 22.36482048034668, Neurons: 60, Grad norm: 4.822e+00\n",
      "Epoch 6146, Loss: 22.36482048034668, Neurons: 60, Grad norm: 4.822e+00\n",
      "Epoch 6147, Loss: 22.330398559570312, Neurons: 60, Grad norm: 4.795e+00\n",
      "Epoch 6147, Loss: 22.330398559570312, Neurons: 60, Grad norm: 4.795e+00\n",
      "Epoch 6148, Loss: 22.295785903930664, Neurons: 60, Grad norm: 4.796e+00\n",
      "Epoch 6148, Loss: 22.295785903930664, Neurons: 60, Grad norm: 4.796e+00\n",
      "Epoch 6149, Loss: 22.260971069335938, Neurons: 60, Grad norm: 4.902e+00\n",
      "Epoch 6149, Loss: 22.260971069335938, Neurons: 60, Grad norm: 4.902e+00\n",
      "Epoch 6150, Loss: 22.2259464263916, Neurons: 60, Grad norm: 5.034e+00\n",
      "Epoch 6150, Loss: 22.2259464263916, Neurons: 60, Grad norm: 5.034e+00\n",
      "Epoch 6151, Loss: 22.190868377685547, Neurons: 60, Grad norm: 4.896e+00\n",
      "Epoch 6151, Loss: 22.190868377685547, Neurons: 60, Grad norm: 4.896e+00\n",
      "Epoch 6152, Loss: 22.155431747436523, Neurons: 60, Grad norm: 4.828e+00\n",
      "Epoch 6152, Loss: 22.155431747436523, Neurons: 60, Grad norm: 4.828e+00\n",
      "Epoch 6153, Loss: 22.11979866027832, Neurons: 60, Grad norm: 4.753e+00\n",
      "Epoch 6153, Loss: 22.11979866027832, Neurons: 60, Grad norm: 4.753e+00\n",
      "Epoch 6154, Loss: 22.08403778076172, Neurons: 60, Grad norm: 4.754e+00\n",
      "Epoch 6154, Loss: 22.08403778076172, Neurons: 60, Grad norm: 4.754e+00\n",
      "Epoch 6155, Loss: 22.048097610473633, Neurons: 60, Grad norm: 4.884e+00\n",
      "Epoch 6155, Loss: 22.048097610473633, Neurons: 60, Grad norm: 4.884e+00\n",
      "Epoch 6156, Loss: 22.011932373046875, Neurons: 60, Grad norm: 4.874e+00\n",
      "Epoch 6156, Loss: 22.011932373046875, Neurons: 60, Grad norm: 4.874e+00\n",
      "Epoch 6157, Loss: 21.97552490234375, Neurons: 60, Grad norm: 4.794e+00\n",
      "Epoch 6157, Loss: 21.97552490234375, Neurons: 60, Grad norm: 4.794e+00\n",
      "Epoch 6158, Loss: 21.93899154663086, Neurons: 60, Grad norm: 4.747e+00\n",
      "Epoch 6158, Loss: 21.93899154663086, Neurons: 60, Grad norm: 4.747e+00\n",
      "Epoch 6159, Loss: 21.902263641357422, Neurons: 60, Grad norm: 4.688e+00\n",
      "Epoch 6159, Loss: 21.902263641357422, Neurons: 60, Grad norm: 4.688e+00\n",
      "Epoch 6160, Loss: 21.86531639099121, Neurons: 60, Grad norm: 4.697e+00\n",
      "Epoch 6160, Loss: 21.86531639099121, Neurons: 60, Grad norm: 4.697e+00\n",
      "Epoch 6161, Loss: 21.828216552734375, Neurons: 60, Grad norm: 4.730e+00\n",
      "Epoch 6161, Loss: 21.828216552734375, Neurons: 60, Grad norm: 4.730e+00\n",
      "Epoch 6162, Loss: 21.790935516357422, Neurons: 60, Grad norm: 4.696e+00\n",
      "Epoch 6162, Loss: 21.790935516357422, Neurons: 60, Grad norm: 4.696e+00\n",
      "Epoch 6163, Loss: 21.75342559814453, Neurons: 60, Grad norm: 4.669e+00\n",
      "Epoch 6163, Loss: 21.75342559814453, Neurons: 60, Grad norm: 4.669e+00\n",
      "Epoch 6164, Loss: 21.71575355529785, Neurons: 60, Grad norm: 4.677e+00\n",
      "Epoch 6164, Loss: 21.71575355529785, Neurons: 60, Grad norm: 4.677e+00\n",
      "Epoch 6165, Loss: 21.67792510986328, Neurons: 60, Grad norm: 4.655e+00\n",
      "Epoch 6165, Loss: 21.67792510986328, Neurons: 60, Grad norm: 4.655e+00\n",
      "Epoch 6166, Loss: 21.63987922668457, Neurons: 60, Grad norm: 4.683e+00\n",
      "Epoch 6166, Loss: 21.63987922668457, Neurons: 60, Grad norm: 4.683e+00\n",
      "Epoch 6167, Loss: 21.60167694091797, Neurons: 60, Grad norm: 4.713e+00\n",
      "Epoch 6167, Loss: 21.60167694091797, Neurons: 60, Grad norm: 4.713e+00\n",
      "Epoch 6168, Loss: 21.563297271728516, Neurons: 60, Grad norm: 4.658e+00\n",
      "Epoch 6168, Loss: 21.563297271728516, Neurons: 60, Grad norm: 4.658e+00\n",
      "Epoch 6169, Loss: 21.52471160888672, Neurons: 60, Grad norm: 4.633e+00\n",
      "Epoch 6169, Loss: 21.52471160888672, Neurons: 60, Grad norm: 4.633e+00\n",
      "Epoch 6170, Loss: 21.485973358154297, Neurons: 60, Grad norm: 4.615e+00\n",
      "Epoch 6170, Loss: 21.485973358154297, Neurons: 60, Grad norm: 4.615e+00\n",
      "Epoch 6171, Loss: 21.447053909301758, Neurons: 60, Grad norm: 4.600e+00\n",
      "Epoch 6171, Loss: 21.447053909301758, Neurons: 60, Grad norm: 4.600e+00\n",
      "Epoch 6172, Loss: 21.40795135498047, Neurons: 60, Grad norm: 4.649e+00\n",
      "Epoch 6172, Loss: 21.40795135498047, Neurons: 60, Grad norm: 4.649e+00\n",
      "Epoch 6173, Loss: 21.36870002746582, Neurons: 60, Grad norm: 4.633e+00\n",
      "Epoch 6173, Loss: 21.36870002746582, Neurons: 60, Grad norm: 4.633e+00\n",
      "Epoch 6174, Loss: 21.32927131652832, Neurons: 60, Grad norm: 4.573e+00\n",
      "Epoch 6174, Loss: 21.32927131652832, Neurons: 60, Grad norm: 4.573e+00\n",
      "Epoch 6175, Loss: 21.289663314819336, Neurons: 60, Grad norm: 4.561e+00\n",
      "Epoch 6175, Loss: 21.289663314819336, Neurons: 60, Grad norm: 4.561e+00\n",
      "Epoch 6176, Loss: 21.24989891052246, Neurons: 60, Grad norm: 4.565e+00\n",
      "Epoch 6176, Loss: 21.24989891052246, Neurons: 60, Grad norm: 4.565e+00\n",
      "Epoch 6177, Loss: 21.209957122802734, Neurons: 60, Grad norm: 4.590e+00\n",
      "Epoch 6177, Loss: 21.209957122802734, Neurons: 60, Grad norm: 4.590e+00\n",
      "Epoch 6178, Loss: 21.169858932495117, Neurons: 60, Grad norm: 4.578e+00\n",
      "Epoch 6178, Loss: 21.169858932495117, Neurons: 60, Grad norm: 4.578e+00\n",
      "Epoch 6179, Loss: 21.12959098815918, Neurons: 60, Grad norm: 4.551e+00\n",
      "Epoch 6179, Loss: 21.12959098815918, Neurons: 60, Grad norm: 4.551e+00\n",
      "Epoch 6180, Loss: 21.089160919189453, Neurons: 60, Grad norm: 4.541e+00\n",
      "Epoch 6180, Loss: 21.089160919189453, Neurons: 60, Grad norm: 4.541e+00\n",
      "Epoch 6181, Loss: 21.04856300354004, Neurons: 60, Grad norm: 4.556e+00\n",
      "Epoch 6181, Loss: 21.04856300354004, Neurons: 60, Grad norm: 4.556e+00\n",
      "Epoch 6182, Loss: 21.007808685302734, Neurons: 60, Grad norm: 4.552e+00\n",
      "Epoch 6182, Loss: 21.007808685302734, Neurons: 60, Grad norm: 4.552e+00\n",
      "Epoch 6183, Loss: 20.966899871826172, Neurons: 60, Grad norm: 4.523e+00\n",
      "Epoch 6183, Loss: 20.966899871826172, Neurons: 60, Grad norm: 4.523e+00\n",
      "Epoch 6184, Loss: 20.925825119018555, Neurons: 60, Grad norm: 4.493e+00\n",
      "Epoch 6184, Loss: 20.925825119018555, Neurons: 60, Grad norm: 4.493e+00\n",
      "Epoch 6185, Loss: 20.88458824157715, Neurons: 60, Grad norm: 4.490e+00\n",
      "Epoch 6185, Loss: 20.88458824157715, Neurons: 60, Grad norm: 4.490e+00\n",
      "Epoch 6186, Loss: 20.843198776245117, Neurons: 60, Grad norm: 4.491e+00\n",
      "Epoch 6186, Loss: 20.843198776245117, Neurons: 60, Grad norm: 4.491e+00\n",
      "Epoch 6187, Loss: 20.801651000976562, Neurons: 60, Grad norm: 4.489e+00\n",
      "Epoch 6187, Loss: 20.801651000976562, Neurons: 60, Grad norm: 4.489e+00\n",
      "Epoch 6188, Loss: 20.759946823120117, Neurons: 60, Grad norm: 4.491e+00\n",
      "Epoch 6188, Loss: 20.759946823120117, Neurons: 60, Grad norm: 4.491e+00\n",
      "Epoch 6189, Loss: 20.71808624267578, Neurons: 60, Grad norm: 4.491e+00\n",
      "Epoch 6189, Loss: 20.71808624267578, Neurons: 60, Grad norm: 4.491e+00\n",
      "Epoch 6190, Loss: 20.676074981689453, Neurons: 60, Grad norm: 4.469e+00\n",
      "Epoch 6190, Loss: 20.676074981689453, Neurons: 60, Grad norm: 4.469e+00\n",
      "Epoch 6191, Loss: 20.6339054107666, Neurons: 60, Grad norm: 4.452e+00\n",
      "Epoch 6191, Loss: 20.6339054107666, Neurons: 60, Grad norm: 4.452e+00\n",
      "Epoch 6192, Loss: 20.591575622558594, Neurons: 60, Grad norm: 4.450e+00\n",
      "Epoch 6192, Loss: 20.591575622558594, Neurons: 60, Grad norm: 4.450e+00\n",
      "Epoch 6193, Loss: 20.549095153808594, Neurons: 60, Grad norm: 4.447e+00\n",
      "Epoch 6193, Loss: 20.549095153808594, Neurons: 60, Grad norm: 4.447e+00\n",
      "Epoch 6194, Loss: 20.506460189819336, Neurons: 60, Grad norm: 4.429e+00\n",
      "Epoch 6194, Loss: 20.506460189819336, Neurons: 60, Grad norm: 4.429e+00\n",
      "Epoch 6195, Loss: 20.463680267333984, Neurons: 60, Grad norm: 4.419e+00\n",
      "Epoch 6195, Loss: 20.463680267333984, Neurons: 60, Grad norm: 4.419e+00\n",
      "Epoch 6196, Loss: 20.420738220214844, Neurons: 60, Grad norm: 4.420e+00\n",
      "Epoch 6196, Loss: 20.420738220214844, Neurons: 60, Grad norm: 4.420e+00\n",
      "Epoch 6197, Loss: 20.377639770507812, Neurons: 60, Grad norm: 4.419e+00\n",
      "Epoch 6197, Loss: 20.377639770507812, Neurons: 60, Grad norm: 4.419e+00\n",
      "Epoch 6198, Loss: 20.334388732910156, Neurons: 60, Grad norm: 4.410e+00\n",
      "Epoch 6198, Loss: 20.334388732910156, Neurons: 60, Grad norm: 4.410e+00\n",
      "Epoch 6199, Loss: 20.29098892211914, Neurons: 60, Grad norm: 4.395e+00\n",
      "Epoch 6199, Loss: 20.29098892211914, Neurons: 60, Grad norm: 4.395e+00\n",
      "Epoch 6199, Test loss: 18.978614807128906\n",
      "Epoch 6199, Test loss: 18.978614807128906\n",
      "Added neuron to hidden layer 1 with activation tanh\n",
      "Added neuron to hidden layer 1 with activation tanh\n",
      "network shape updated to :[27, 33, 1]\n",
      "network shape updated to :[27, 33, 1]\n",
      "Epoch 6200, Loss: 24.417707443237305, Neurons: 61, Grad norm: 1.539e+02\n",
      "Epoch 6200, Loss: 24.417707443237305, Neurons: 61, Grad norm: 1.539e+02\n",
      "Epoch 6201, Loss: 23.840852737426758, Neurons: 61, Grad norm: 1.374e+02\n",
      "Epoch 6201, Loss: 23.840852737426758, Neurons: 61, Grad norm: 1.374e+02\n",
      "Epoch 6202, Loss: 23.310617446899414, Neurons: 61, Grad norm: 1.227e+02\n",
      "Epoch 6202, Loss: 23.310617446899414, Neurons: 61, Grad norm: 1.227e+02\n",
      "Epoch 6203, Loss: 22.834209442138672, Neurons: 61, Grad norm: 1.097e+02\n",
      "Epoch 6203, Loss: 22.834209442138672, Neurons: 61, Grad norm: 1.097e+02\n",
      "Epoch 6204, Loss: 22.414525985717773, Neurons: 61, Grad norm: 9.789e+01\n",
      "Epoch 6204, Loss: 22.414525985717773, Neurons: 61, Grad norm: 9.789e+01\n",
      "Epoch 6205, Loss: 22.051528930664062, Neurons: 61, Grad norm: 8.685e+01\n",
      "Epoch 6205, Loss: 22.051528930664062, Neurons: 61, Grad norm: 8.685e+01\n",
      "Epoch 6206, Loss: 21.744430541992188, Neurons: 61, Grad norm: 7.627e+01\n",
      "Epoch 6206, Loss: 21.744430541992188, Neurons: 61, Grad norm: 7.627e+01\n",
      "Epoch 6207, Loss: 21.49109649658203, Neurons: 61, Grad norm: 6.596e+01\n",
      "Epoch 6207, Loss: 21.49109649658203, Neurons: 61, Grad norm: 6.596e+01\n",
      "Epoch 6208, Loss: 21.28789520263672, Neurons: 61, Grad norm: 5.591e+01\n",
      "Epoch 6208, Loss: 21.28789520263672, Neurons: 61, Grad norm: 5.591e+01\n",
      "Epoch 6209, Loss: 21.129989624023438, Neurons: 61, Grad norm: 4.644e+01\n",
      "Epoch 6209, Loss: 21.129989624023438, Neurons: 61, Grad norm: 4.644e+01\n",
      "Epoch 6210, Loss: 21.011491775512695, Neurons: 61, Grad norm: 3.827e+01\n",
      "Epoch 6210, Loss: 21.011491775512695, Neurons: 61, Grad norm: 3.827e+01\n",
      "Epoch 6211, Loss: 20.92543601989746, Neurons: 61, Grad norm: 3.229e+01\n",
      "Epoch 6211, Loss: 20.92543601989746, Neurons: 61, Grad norm: 3.229e+01\n",
      "Epoch 6212, Loss: 20.86382293701172, Neurons: 61, Grad norm: 2.914e+01\n",
      "Epoch 6212, Loss: 20.86382293701172, Neurons: 61, Grad norm: 2.914e+01\n",
      "Epoch 6213, Loss: 20.818347930908203, Neurons: 61, Grad norm: 2.852e+01\n",
      "Epoch 6213, Loss: 20.818347930908203, Neurons: 61, Grad norm: 2.852e+01\n",
      "Epoch 6214, Loss: 20.781328201293945, Neurons: 61, Grad norm: 2.928e+01\n",
      "Epoch 6214, Loss: 20.781328201293945, Neurons: 61, Grad norm: 2.928e+01\n",
      "Epoch 6215, Loss: 20.746536254882812, Neurons: 61, Grad norm: 3.027e+01\n",
      "Epoch 6215, Loss: 20.746536254882812, Neurons: 61, Grad norm: 3.027e+01\n",
      "Epoch 6216, Loss: 20.709590911865234, Neurons: 61, Grad norm: 3.076e+01\n",
      "Epoch 6216, Loss: 20.709590911865234, Neurons: 61, Grad norm: 3.076e+01\n",
      "Epoch 6217, Loss: 20.668039321899414, Neurons: 61, Grad norm: 3.043e+01\n",
      "Epoch 6217, Loss: 20.668039321899414, Neurons: 61, Grad norm: 3.043e+01\n",
      "Epoch 6218, Loss: 20.62116050720215, Neurons: 61, Grad norm: 2.924e+01\n",
      "Epoch 6218, Loss: 20.62116050720215, Neurons: 61, Grad norm: 2.924e+01\n",
      "Epoch 6219, Loss: 20.56962013244629, Neurons: 61, Grad norm: 2.730e+01\n",
      "Epoch 6219, Loss: 20.56962013244629, Neurons: 61, Grad norm: 2.730e+01\n",
      "Epoch 6220, Loss: 20.51506805419922, Neurons: 61, Grad norm: 2.483e+01\n",
      "Epoch 6220, Loss: 20.51506805419922, Neurons: 61, Grad norm: 2.483e+01\n",
      "Epoch 6221, Loss: 20.459657669067383, Neurons: 61, Grad norm: 2.209e+01\n",
      "Epoch 6221, Loss: 20.459657669067383, Neurons: 61, Grad norm: 2.209e+01\n",
      "Epoch 6222, Loss: 20.405641555786133, Neurons: 61, Grad norm: 1.934e+01\n",
      "Epoch 6222, Loss: 20.405641555786133, Neurons: 61, Grad norm: 1.934e+01\n",
      "Epoch 6223, Loss: 20.354936599731445, Neurons: 61, Grad norm: 1.676e+01\n",
      "Epoch 6223, Loss: 20.354936599731445, Neurons: 61, Grad norm: 1.676e+01\n",
      "Epoch 6224, Loss: 20.30890464782715, Neurons: 61, Grad norm: 1.446e+01\n",
      "Epoch 6224, Loss: 20.30890464782715, Neurons: 61, Grad norm: 1.446e+01\n",
      "Epoch 6225, Loss: 20.26822853088379, Neurons: 61, Grad norm: 1.252e+01\n",
      "Epoch 6225, Loss: 20.26822853088379, Neurons: 61, Grad norm: 1.252e+01\n",
      "Epoch 6226, Loss: 20.233043670654297, Neurons: 61, Grad norm: 1.105e+01\n",
      "Epoch 6226, Loss: 20.233043670654297, Neurons: 61, Grad norm: 1.105e+01\n",
      "Epoch 6227, Loss: 20.203083038330078, Neurons: 61, Grad norm: 1.030e+01\n",
      "Epoch 6227, Loss: 20.203083038330078, Neurons: 61, Grad norm: 1.030e+01\n",
      "Epoch 6228, Loss: 20.177841186523438, Neurons: 61, Grad norm: 1.048e+01\n",
      "Epoch 6228, Loss: 20.177841186523438, Neurons: 61, Grad norm: 1.048e+01\n",
      "Epoch 6229, Loss: 20.156646728515625, Neurons: 61, Grad norm: 1.150e+01\n",
      "Epoch 6229, Loss: 20.156646728515625, Neurons: 61, Grad norm: 1.150e+01\n",
      "Epoch 6230, Loss: 20.13868522644043, Neurons: 61, Grad norm: 1.303e+01\n",
      "Epoch 6230, Loss: 20.13868522644043, Neurons: 61, Grad norm: 1.303e+01\n",
      "Epoch 6231, Loss: 20.123004913330078, Neurons: 61, Grad norm: 1.461e+01\n",
      "Epoch 6231, Loss: 20.123004913330078, Neurons: 61, Grad norm: 1.461e+01\n",
      "Epoch 6232, Loss: 20.10862922668457, Neurons: 61, Grad norm: 1.593e+01\n",
      "Epoch 6232, Loss: 20.10862922668457, Neurons: 61, Grad norm: 1.593e+01\n",
      "Epoch 6233, Loss: 20.09459114074707, Neurons: 61, Grad norm: 1.674e+01\n",
      "Epoch 6233, Loss: 20.09459114074707, Neurons: 61, Grad norm: 1.674e+01\n",
      "Epoch 6234, Loss: 20.080062866210938, Neurons: 61, Grad norm: 1.697e+01\n",
      "Epoch 6234, Loss: 20.080062866210938, Neurons: 61, Grad norm: 1.697e+01\n",
      "Epoch 6235, Loss: 20.064489364624023, Neurons: 61, Grad norm: 1.660e+01\n",
      "Epoch 6235, Loss: 20.064489364624023, Neurons: 61, Grad norm: 1.660e+01\n",
      "Epoch 6236, Loss: 20.047584533691406, Neurons: 61, Grad norm: 1.571e+01\n",
      "Epoch 6236, Loss: 20.047584533691406, Neurons: 61, Grad norm: 1.571e+01\n",
      "Epoch 6237, Loss: 20.02937126159668, Neurons: 61, Grad norm: 1.446e+01\n",
      "Epoch 6237, Loss: 20.02937126159668, Neurons: 61, Grad norm: 1.446e+01\n",
      "Epoch 6238, Loss: 20.010099411010742, Neurons: 61, Grad norm: 1.303e+01\n",
      "Epoch 6238, Loss: 20.010099411010742, Neurons: 61, Grad norm: 1.303e+01\n",
      "Epoch 6239, Loss: 19.990135192871094, Neurons: 61, Grad norm: 1.163e+01\n",
      "Epoch 6239, Loss: 19.990135192871094, Neurons: 61, Grad norm: 1.163e+01\n",
      "Epoch 6240, Loss: 19.96987533569336, Neurons: 61, Grad norm: 1.040e+01\n",
      "Epoch 6240, Loss: 19.96987533569336, Neurons: 61, Grad norm: 1.040e+01\n",
      "Epoch 6241, Loss: 19.94963836669922, Neurons: 61, Grad norm: 9.408e+00\n",
      "Epoch 6241, Loss: 19.94963836669922, Neurons: 61, Grad norm: 9.408e+00\n",
      "Epoch 6242, Loss: 19.92966651916504, Neurons: 61, Grad norm: 8.621e+00\n",
      "Epoch 6242, Loss: 19.92966651916504, Neurons: 61, Grad norm: 8.621e+00\n",
      "Epoch 6243, Loss: 19.910085678100586, Neurons: 61, Grad norm: 7.954e+00\n",
      "Epoch 6243, Loss: 19.910085678100586, Neurons: 61, Grad norm: 7.954e+00\n",
      "Epoch 6244, Loss: 19.89094352722168, Neurons: 61, Grad norm: 7.341e+00\n",
      "Epoch 6244, Loss: 19.89094352722168, Neurons: 61, Grad norm: 7.341e+00\n",
      "Epoch 6245, Loss: 19.872257232666016, Neurons: 61, Grad norm: 6.792e+00\n",
      "Epoch 6245, Loss: 19.872257232666016, Neurons: 61, Grad norm: 6.792e+00\n",
      "Epoch 6246, Loss: 19.85399055480957, Neurons: 61, Grad norm: 6.373e+00\n",
      "Epoch 6246, Loss: 19.85399055480957, Neurons: 61, Grad norm: 6.373e+00\n",
      "Epoch 6247, Loss: 19.83609390258789, Neurons: 61, Grad norm: 6.171e+00\n",
      "Epoch 6247, Loss: 19.83609390258789, Neurons: 61, Grad norm: 6.171e+00\n",
      "Epoch 6248, Loss: 19.818470001220703, Neurons: 61, Grad norm: 6.203e+00\n",
      "Epoch 6248, Loss: 19.818470001220703, Neurons: 61, Grad norm: 6.203e+00\n",
      "Epoch 6249, Loss: 19.801000595092773, Neurons: 61, Grad norm: 6.399e+00\n",
      "Epoch 6249, Loss: 19.801000595092773, Neurons: 61, Grad norm: 6.399e+00\n",
      "Epoch 6250, Loss: 19.783546447753906, Neurons: 61, Grad norm: 6.621e+00\n",
      "Epoch 6250, Loss: 19.783546447753906, Neurons: 61, Grad norm: 6.621e+00\n",
      "Epoch 6251, Loss: 19.765974044799805, Neurons: 61, Grad norm: 6.752e+00\n",
      "Epoch 6251, Loss: 19.765974044799805, Neurons: 61, Grad norm: 6.752e+00\n",
      "Epoch 6252, Loss: 19.748188018798828, Neurons: 61, Grad norm: 6.723e+00\n",
      "Epoch 6252, Loss: 19.748188018798828, Neurons: 61, Grad norm: 6.723e+00\n",
      "Epoch 6253, Loss: 19.730154037475586, Neurons: 61, Grad norm: 6.522e+00\n",
      "Epoch 6253, Loss: 19.730154037475586, Neurons: 61, Grad norm: 6.522e+00\n",
      "Epoch 6254, Loss: 19.711891174316406, Neurons: 61, Grad norm: 6.207e+00\n",
      "Epoch 6254, Loss: 19.711891174316406, Neurons: 61, Grad norm: 6.207e+00\n",
      "Epoch 6255, Loss: 19.693471908569336, Neurons: 61, Grad norm: 5.851e+00\n",
      "Epoch 6255, Loss: 19.693471908569336, Neurons: 61, Grad norm: 5.851e+00\n",
      "Epoch 6256, Loss: 19.67499351501465, Neurons: 61, Grad norm: 5.536e+00\n",
      "Epoch 6256, Loss: 19.67499351501465, Neurons: 61, Grad norm: 5.536e+00\n",
      "Epoch 6257, Loss: 19.65654945373535, Neurons: 61, Grad norm: 5.313e+00\n",
      "Epoch 6257, Loss: 19.65654945373535, Neurons: 61, Grad norm: 5.313e+00\n",
      "Epoch 6258, Loss: 19.638212203979492, Neurons: 61, Grad norm: 5.193e+00\n",
      "Epoch 6258, Loss: 19.638212203979492, Neurons: 61, Grad norm: 5.193e+00\n",
      "Epoch 6259, Loss: 19.620027542114258, Neurons: 61, Grad norm: 5.155e+00\n",
      "Epoch 6259, Loss: 19.620027542114258, Neurons: 61, Grad norm: 5.155e+00\n",
      "Epoch 6260, Loss: 19.602006912231445, Neurons: 61, Grad norm: 5.177e+00\n",
      "Epoch 6260, Loss: 19.602006912231445, Neurons: 61, Grad norm: 5.177e+00\n",
      "Epoch 6261, Loss: 19.58414077758789, Neurons: 61, Grad norm: 5.248e+00\n",
      "Epoch 6261, Loss: 19.58414077758789, Neurons: 61, Grad norm: 5.248e+00\n",
      "Epoch 6262, Loss: 19.566417694091797, Neurons: 61, Grad norm: 5.377e+00\n",
      "Epoch 6262, Loss: 19.566417694091797, Neurons: 61, Grad norm: 5.377e+00\n",
      "Epoch 6263, Loss: 19.54880714416504, Neurons: 61, Grad norm: 5.562e+00\n",
      "Epoch 6263, Loss: 19.54880714416504, Neurons: 61, Grad norm: 5.562e+00\n",
      "Epoch 6264, Loss: 19.531274795532227, Neurons: 61, Grad norm: 5.803e+00\n",
      "Epoch 6264, Loss: 19.531274795532227, Neurons: 61, Grad norm: 5.803e+00\n",
      "Epoch 6265, Loss: 19.513778686523438, Neurons: 61, Grad norm: 6.037e+00\n",
      "Epoch 6265, Loss: 19.513778686523438, Neurons: 61, Grad norm: 6.037e+00\n",
      "Epoch 6266, Loss: 19.49626922607422, Neurons: 61, Grad norm: 6.244e+00\n",
      "Epoch 6266, Loss: 19.49626922607422, Neurons: 61, Grad norm: 6.244e+00\n",
      "Epoch 6267, Loss: 19.47869873046875, Neurons: 61, Grad norm: 6.354e+00\n",
      "Epoch 6267, Loss: 19.47869873046875, Neurons: 61, Grad norm: 6.354e+00\n",
      "Epoch 6268, Loss: 19.461030960083008, Neurons: 61, Grad norm: 6.375e+00\n",
      "Epoch 6268, Loss: 19.461030960083008, Neurons: 61, Grad norm: 6.375e+00\n",
      "Epoch 6269, Loss: 19.443241119384766, Neurons: 61, Grad norm: 6.296e+00\n",
      "Epoch 6269, Loss: 19.443241119384766, Neurons: 61, Grad norm: 6.296e+00\n",
      "Epoch 6270, Loss: 19.425323486328125, Neurons: 61, Grad norm: 6.162e+00\n",
      "Epoch 6270, Loss: 19.425323486328125, Neurons: 61, Grad norm: 6.162e+00\n",
      "Epoch 6271, Loss: 19.407283782958984, Neurons: 61, Grad norm: 5.980e+00\n",
      "Epoch 6271, Loss: 19.407283782958984, Neurons: 61, Grad norm: 5.980e+00\n",
      "Epoch 6272, Loss: 19.389150619506836, Neurons: 61, Grad norm: 5.779e+00\n",
      "Epoch 6272, Loss: 19.389150619506836, Neurons: 61, Grad norm: 5.779e+00\n",
      "Epoch 6273, Loss: 19.37093734741211, Neurons: 61, Grad norm: 5.587e+00\n",
      "Epoch 6273, Loss: 19.37093734741211, Neurons: 61, Grad norm: 5.587e+00\n",
      "Epoch 6274, Loss: 19.352672576904297, Neurons: 61, Grad norm: 5.409e+00\n",
      "Epoch 6274, Loss: 19.352672576904297, Neurons: 61, Grad norm: 5.409e+00\n",
      "Epoch 6275, Loss: 19.334360122680664, Neurons: 61, Grad norm: 5.249e+00\n",
      "Epoch 6275, Loss: 19.334360122680664, Neurons: 61, Grad norm: 5.249e+00\n",
      "Epoch 6276, Loss: 19.31600570678711, Neurons: 61, Grad norm: 5.097e+00\n",
      "Epoch 6276, Loss: 19.31600570678711, Neurons: 61, Grad norm: 5.097e+00\n",
      "Epoch 6277, Loss: 19.297611236572266, Neurons: 61, Grad norm: 4.973e+00\n",
      "Epoch 6277, Loss: 19.297611236572266, Neurons: 61, Grad norm: 4.973e+00\n",
      "Epoch 6278, Loss: 19.279176712036133, Neurons: 61, Grad norm: 4.874e+00\n",
      "Epoch 6278, Loss: 19.279176712036133, Neurons: 61, Grad norm: 4.874e+00\n",
      "Epoch 6279, Loss: 19.26070785522461, Neurons: 61, Grad norm: 4.806e+00\n",
      "Epoch 6279, Loss: 19.26070785522461, Neurons: 61, Grad norm: 4.806e+00\n",
      "Epoch 6280, Loss: 19.242191314697266, Neurons: 61, Grad norm: 4.771e+00\n",
      "Epoch 6280, Loss: 19.242191314697266, Neurons: 61, Grad norm: 4.771e+00\n",
      "Epoch 6281, Loss: 19.223613739013672, Neurons: 61, Grad norm: 4.753e+00\n",
      "Epoch 6281, Loss: 19.223613739013672, Neurons: 61, Grad norm: 4.753e+00\n",
      "Epoch 6282, Loss: 19.204973220825195, Neurons: 61, Grad norm: 4.727e+00\n",
      "Epoch 6282, Loss: 19.204973220825195, Neurons: 61, Grad norm: 4.727e+00\n",
      "Epoch 6283, Loss: 19.18625831604004, Neurons: 61, Grad norm: 4.703e+00\n",
      "Epoch 6283, Loss: 19.18625831604004, Neurons: 61, Grad norm: 4.703e+00\n",
      "Epoch 6284, Loss: 19.16746711730957, Neurons: 61, Grad norm: 4.655e+00\n",
      "Epoch 6284, Loss: 19.16746711730957, Neurons: 61, Grad norm: 4.655e+00\n",
      "Epoch 6285, Loss: 19.14859390258789, Neurons: 61, Grad norm: 4.608e+00\n",
      "Epoch 6285, Loss: 19.14859390258789, Neurons: 61, Grad norm: 4.608e+00\n",
      "Epoch 6286, Loss: 19.129648208618164, Neurons: 61, Grad norm: 4.567e+00\n",
      "Epoch 6286, Loss: 19.129648208618164, Neurons: 61, Grad norm: 4.567e+00\n",
      "Epoch 6287, Loss: 19.11063003540039, Neurons: 61, Grad norm: 4.544e+00\n",
      "Epoch 6287, Loss: 19.11063003540039, Neurons: 61, Grad norm: 4.544e+00\n",
      "Epoch 6288, Loss: 19.091550827026367, Neurons: 61, Grad norm: 4.533e+00\n",
      "Epoch 6288, Loss: 19.091550827026367, Neurons: 61, Grad norm: 4.533e+00\n",
      "Epoch 6289, Loss: 19.072406768798828, Neurons: 61, Grad norm: 4.534e+00\n",
      "Epoch 6289, Loss: 19.072406768798828, Neurons: 61, Grad norm: 4.534e+00\n",
      "Epoch 6290, Loss: 19.053213119506836, Neurons: 61, Grad norm: 4.548e+00\n",
      "Epoch 6290, Loss: 19.053213119506836, Neurons: 61, Grad norm: 4.548e+00\n",
      "Epoch 6291, Loss: 19.033960342407227, Neurons: 61, Grad norm: 4.571e+00\n",
      "Epoch 6291, Loss: 19.033960342407227, Neurons: 61, Grad norm: 4.571e+00\n",
      "Epoch 6292, Loss: 19.0146484375, Neurons: 61, Grad norm: 4.598e+00\n",
      "Epoch 6292, Loss: 19.0146484375, Neurons: 61, Grad norm: 4.598e+00\n",
      "Epoch 6293, Loss: 18.995281219482422, Neurons: 61, Grad norm: 4.624e+00\n",
      "Epoch 6293, Loss: 18.995281219482422, Neurons: 61, Grad norm: 4.624e+00\n",
      "Epoch 6294, Loss: 18.975860595703125, Neurons: 61, Grad norm: 4.595e+00\n",
      "Epoch 6294, Loss: 18.975860595703125, Neurons: 61, Grad norm: 4.595e+00\n",
      "Epoch 6295, Loss: 18.956375122070312, Neurons: 61, Grad norm: 4.599e+00\n",
      "Epoch 6295, Loss: 18.956375122070312, Neurons: 61, Grad norm: 4.599e+00\n",
      "Epoch 6296, Loss: 18.93691062927246, Neurons: 61, Grad norm: 4.652e+00\n",
      "Epoch 6296, Loss: 18.93691062927246, Neurons: 61, Grad norm: 4.652e+00\n",
      "Epoch 6297, Loss: 18.917415618896484, Neurons: 61, Grad norm: 4.673e+00\n",
      "Epoch 6297, Loss: 18.917415618896484, Neurons: 61, Grad norm: 4.673e+00\n",
      "Epoch 6298, Loss: 18.897802352905273, Neurons: 61, Grad norm: 4.677e+00\n",
      "Epoch 6298, Loss: 18.897802352905273, Neurons: 61, Grad norm: 4.677e+00\n",
      "Epoch 6299, Loss: 18.878080368041992, Neurons: 61, Grad norm: 4.678e+00\n",
      "Epoch 6299, Loss: 18.878080368041992, Neurons: 61, Grad norm: 4.678e+00\n",
      "Epoch 6299, Test loss: 17.65291404724121\n",
      "Epoch 6299, Test loss: 17.65291404724121\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "Added neuron to hidden layer 2 with activation tanh\n",
      "network shape updated to :[27, 34, 1]\n",
      "network shape updated to :[27, 34, 1]\n",
      "Epoch 6300, Loss: 19.14645767211914, Neurons: 62, Grad norm: 2.653e+01\n",
      "Epoch 6300, Loss: 19.14645767211914, Neurons: 62, Grad norm: 2.653e+01\n",
      "Epoch 6301, Loss: 18.981962203979492, Neurons: 62, Grad norm: 1.285e+01\n",
      "Epoch 6301, Loss: 18.981962203979492, Neurons: 62, Grad norm: 1.285e+01\n",
      "Epoch 6302, Loss: 18.905019760131836, Neurons: 62, Grad norm: 1.675e+01\n",
      "Epoch 6302, Loss: 18.905019760131836, Neurons: 62, Grad norm: 1.675e+01\n",
      "Epoch 6303, Loss: 18.89031982421875, Neurons: 62, Grad norm: 2.337e+01\n",
      "Epoch 6303, Loss: 18.89031982421875, Neurons: 62, Grad norm: 2.337e+01\n",
      "Epoch 6304, Loss: 18.896150588989258, Neurons: 62, Grad norm: 2.541e+01\n",
      "Epoch 6304, Loss: 18.896150588989258, Neurons: 62, Grad norm: 2.541e+01\n",
      "Epoch 6305, Loss: 18.894012451171875, Neurons: 62, Grad norm: 2.326e+01\n",
      "Epoch 6305, Loss: 18.894012451171875, Neurons: 62, Grad norm: 2.326e+01\n",
      "Epoch 6306, Loss: 18.877490997314453, Neurons: 62, Grad norm: 1.847e+01\n",
      "Epoch 6306, Loss: 18.877490997314453, Neurons: 62, Grad norm: 1.847e+01\n",
      "Epoch 6307, Loss: 18.85204315185547, Neurons: 62, Grad norm: 1.235e+01\n",
      "Epoch 6307, Loss: 18.85204315185547, Neurons: 62, Grad norm: 1.235e+01\n",
      "Epoch 6308, Loss: 18.826505661010742, Neurons: 62, Grad norm: 9.261e+00\n",
      "Epoch 6308, Loss: 18.826505661010742, Neurons: 62, Grad norm: 9.261e+00\n",
      "Epoch 6309, Loss: 18.806289672851562, Neurons: 62, Grad norm: 9.250e+00\n",
      "Epoch 6309, Loss: 18.806289672851562, Neurons: 62, Grad norm: 9.250e+00\n",
      "Epoch 6310, Loss: 18.791820526123047, Neurons: 62, Grad norm: 1.092e+01\n",
      "Epoch 6310, Loss: 18.791820526123047, Neurons: 62, Grad norm: 1.092e+01\n",
      "Epoch 6311, Loss: 18.781543731689453, Neurons: 62, Grad norm: 1.219e+01\n",
      "Epoch 6311, Loss: 18.781543731689453, Neurons: 62, Grad norm: 1.219e+01\n",
      "Epoch 6312, Loss: 18.772375106811523, Neurons: 62, Grad norm: 1.263e+01\n",
      "Epoch 6312, Loss: 18.772375106811523, Neurons: 62, Grad norm: 1.263e+01\n",
      "Epoch 6313, Loss: 18.761871337890625, Neurons: 62, Grad norm: 1.229e+01\n",
      "Epoch 6313, Loss: 18.761871337890625, Neurons: 62, Grad norm: 1.229e+01\n",
      "Epoch 6314, Loss: 18.74884033203125, Neurons: 62, Grad norm: 1.133e+01\n",
      "Epoch 6314, Loss: 18.74884033203125, Neurons: 62, Grad norm: 1.133e+01\n",
      "Epoch 6315, Loss: 18.733489990234375, Neurons: 62, Grad norm: 1.009e+01\n",
      "Epoch 6315, Loss: 18.733489990234375, Neurons: 62, Grad norm: 1.009e+01\n",
      "Epoch 6316, Loss: 18.716978073120117, Neurons: 62, Grad norm: 8.992e+00\n",
      "Epoch 6316, Loss: 18.716978073120117, Neurons: 62, Grad norm: 8.992e+00\n",
      "Epoch 6317, Loss: 18.700559616088867, Neurons: 62, Grad norm: 8.356e+00\n",
      "Epoch 6317, Loss: 18.700559616088867, Neurons: 62, Grad norm: 8.356e+00\n",
      "Epoch 6318, Loss: 18.684965133666992, Neurons: 62, Grad norm: 8.127e+00\n",
      "Epoch 6318, Loss: 18.684965133666992, Neurons: 62, Grad norm: 8.127e+00\n",
      "Epoch 6319, Loss: 18.670196533203125, Neurons: 62, Grad norm: 8.140e+00\n",
      "Epoch 6319, Loss: 18.670196533203125, Neurons: 62, Grad norm: 8.140e+00\n",
      "Epoch 6320, Loss: 18.655864715576172, Neurons: 62, Grad norm: 8.175e+00\n",
      "Epoch 6320, Loss: 18.655864715576172, Neurons: 62, Grad norm: 8.175e+00\n",
      "Epoch 6321, Loss: 18.6413631439209, Neurons: 62, Grad norm: 8.021e+00\n",
      "Epoch 6321, Loss: 18.6413631439209, Neurons: 62, Grad norm: 8.021e+00\n",
      "Epoch 6322, Loss: 18.626293182373047, Neurons: 62, Grad norm: 7.622e+00\n",
      "Epoch 6322, Loss: 18.626293182373047, Neurons: 62, Grad norm: 7.622e+00\n",
      "Epoch 6323, Loss: 18.610261917114258, Neurons: 62, Grad norm: 6.977e+00\n",
      "Epoch 6323, Loss: 18.610261917114258, Neurons: 62, Grad norm: 6.977e+00\n",
      "Epoch 6324, Loss: 18.593704223632812, Neurons: 62, Grad norm: 6.527e+00\n",
      "Epoch 6324, Loss: 18.593704223632812, Neurons: 62, Grad norm: 6.527e+00\n",
      "Epoch 6325, Loss: 18.577173233032227, Neurons: 62, Grad norm: 6.330e+00\n",
      "Epoch 6325, Loss: 18.577173233032227, Neurons: 62, Grad norm: 6.330e+00\n",
      "Epoch 6326, Loss: 18.560964584350586, Neurons: 62, Grad norm: 6.444e+00\n",
      "Epoch 6326, Loss: 18.560964584350586, Neurons: 62, Grad norm: 6.444e+00\n",
      "Epoch 6327, Loss: 18.545053482055664, Neurons: 62, Grad norm: 6.607e+00\n",
      "Epoch 6327, Loss: 18.545053482055664, Neurons: 62, Grad norm: 6.607e+00\n",
      "Epoch 6328, Loss: 18.52908706665039, Neurons: 62, Grad norm: 6.621e+00\n",
      "Epoch 6328, Loss: 18.52908706665039, Neurons: 62, Grad norm: 6.621e+00\n",
      "Epoch 6329, Loss: 18.51264190673828, Neurons: 62, Grad norm: 6.378e+00\n",
      "Epoch 6329, Loss: 18.51264190673828, Neurons: 62, Grad norm: 6.378e+00\n",
      "Epoch 6330, Loss: 18.495454788208008, Neurons: 62, Grad norm: 5.898e+00\n",
      "Epoch 6330, Loss: 18.495454788208008, Neurons: 62, Grad norm: 5.898e+00\n",
      "Epoch 6331, Loss: 18.477584838867188, Neurons: 62, Grad norm: 5.246e+00\n",
      "Epoch 6331, Loss: 18.477584838867188, Neurons: 62, Grad norm: 5.246e+00\n",
      "Epoch 6332, Loss: 18.459331512451172, Neurons: 62, Grad norm: 4.688e+00\n",
      "Epoch 6332, Loss: 18.459331512451172, Neurons: 62, Grad norm: 4.688e+00\n",
      "Epoch 6333, Loss: 18.441082000732422, Neurons: 62, Grad norm: 4.492e+00\n",
      "Epoch 6333, Loss: 18.441082000732422, Neurons: 62, Grad norm: 4.492e+00\n",
      "Epoch 6334, Loss: 18.423118591308594, Neurons: 62, Grad norm: 4.718e+00\n",
      "Epoch 6334, Loss: 18.423118591308594, Neurons: 62, Grad norm: 4.718e+00\n",
      "Epoch 6335, Loss: 18.405420303344727, Neurons: 62, Grad norm: 5.127e+00\n",
      "Epoch 6335, Loss: 18.405420303344727, Neurons: 62, Grad norm: 5.127e+00\n",
      "Epoch 6336, Loss: 18.387723922729492, Neurons: 62, Grad norm: 5.424e+00\n",
      "Epoch 6336, Loss: 18.387723922729492, Neurons: 62, Grad norm: 5.424e+00\n",
      "Epoch 6337, Loss: 18.36966896057129, Neurons: 62, Grad norm: 5.445e+00\n",
      "Epoch 6337, Loss: 18.36966896057129, Neurons: 62, Grad norm: 5.445e+00\n",
      "Epoch 6338, Loss: 18.351028442382812, Neurons: 62, Grad norm: 5.175e+00\n",
      "Epoch 6338, Loss: 18.351028442382812, Neurons: 62, Grad norm: 5.175e+00\n",
      "Epoch 6339, Loss: 18.331802368164062, Neurons: 62, Grad norm: 4.768e+00\n",
      "Epoch 6339, Loss: 18.331802368164062, Neurons: 62, Grad norm: 4.768e+00\n",
      "Epoch 6340, Loss: 18.31220054626465, Neurons: 62, Grad norm: 4.406e+00\n",
      "Epoch 6340, Loss: 18.31220054626465, Neurons: 62, Grad norm: 4.406e+00\n",
      "Epoch 6341, Loss: 18.29250144958496, Neurons: 62, Grad norm: 4.267e+00\n",
      "Epoch 6341, Loss: 18.29250144958496, Neurons: 62, Grad norm: 4.267e+00\n",
      "Epoch 6342, Loss: 18.272891998291016, Neurons: 62, Grad norm: 4.377e+00\n",
      "Epoch 6342, Loss: 18.272891998291016, Neurons: 62, Grad norm: 4.377e+00\n",
      "Epoch 6343, Loss: 18.25338363647461, Neurons: 62, Grad norm: 4.600e+00\n",
      "Epoch 6343, Loss: 18.25338363647461, Neurons: 62, Grad norm: 4.600e+00\n",
      "Epoch 6344, Loss: 18.233821868896484, Neurons: 62, Grad norm: 4.761e+00\n",
      "Epoch 6344, Loss: 18.233821868896484, Neurons: 62, Grad norm: 4.761e+00\n",
      "Epoch 6345, Loss: 18.213993072509766, Neurons: 62, Grad norm: 4.735e+00\n",
      "Epoch 6345, Loss: 18.213993072509766, Neurons: 62, Grad norm: 4.735e+00\n",
      "Epoch 6346, Loss: 18.193790435791016, Neurons: 62, Grad norm: 4.578e+00\n",
      "Epoch 6346, Loss: 18.193790435791016, Neurons: 62, Grad norm: 4.578e+00\n",
      "Epoch 6347, Loss: 18.173227310180664, Neurons: 62, Grad norm: 4.349e+00\n",
      "Epoch 6347, Loss: 18.173227310180664, Neurons: 62, Grad norm: 4.349e+00\n",
      "Epoch 6348, Loss: 18.152421951293945, Neurons: 62, Grad norm: 4.182e+00\n",
      "Epoch 6348, Loss: 18.152421951293945, Neurons: 62, Grad norm: 4.182e+00\n",
      "Epoch 6349, Loss: 18.131528854370117, Neurons: 62, Grad norm: 4.169e+00\n",
      "Epoch 6349, Loss: 18.131528854370117, Neurons: 62, Grad norm: 4.169e+00\n",
      "Epoch 6350, Loss: 18.110612869262695, Neurons: 62, Grad norm: 4.239e+00\n",
      "Epoch 6350, Loss: 18.110612869262695, Neurons: 62, Grad norm: 4.239e+00\n",
      "Epoch 6351, Loss: 18.089637756347656, Neurons: 62, Grad norm: 4.323e+00\n",
      "Epoch 6351, Loss: 18.089637756347656, Neurons: 62, Grad norm: 4.323e+00\n",
      "Epoch 6352, Loss: 18.068500518798828, Neurons: 62, Grad norm: 4.353e+00\n",
      "Epoch 6352, Loss: 18.068500518798828, Neurons: 62, Grad norm: 4.353e+00\n",
      "Epoch 6353, Loss: 18.04715347290039, Neurons: 62, Grad norm: 4.338e+00\n",
      "Epoch 6353, Loss: 18.04715347290039, Neurons: 62, Grad norm: 4.338e+00\n",
      "Epoch 6354, Loss: 18.025554656982422, Neurons: 62, Grad norm: 4.267e+00\n",
      "Epoch 6354, Loss: 18.025554656982422, Neurons: 62, Grad norm: 4.267e+00\n",
      "Epoch 6355, Loss: 18.00373077392578, Neurons: 62, Grad norm: 4.188e+00\n",
      "Epoch 6355, Loss: 18.00373077392578, Neurons: 62, Grad norm: 4.188e+00\n",
      "Epoch 6356, Loss: 17.98175048828125, Neurons: 62, Grad norm: 4.151e+00\n",
      "Epoch 6356, Loss: 17.98175048828125, Neurons: 62, Grad norm: 4.151e+00\n",
      "Epoch 6357, Loss: 17.959665298461914, Neurons: 62, Grad norm: 4.165e+00\n",
      "Epoch 6357, Loss: 17.959665298461914, Neurons: 62, Grad norm: 4.165e+00\n",
      "Epoch 6358, Loss: 17.937477111816406, Neurons: 62, Grad norm: 4.230e+00\n",
      "Epoch 6358, Loss: 17.937477111816406, Neurons: 62, Grad norm: 4.230e+00\n",
      "Epoch 6359, Loss: 17.915178298950195, Neurons: 62, Grad norm: 4.235e+00\n",
      "Epoch 6359, Loss: 17.915178298950195, Neurons: 62, Grad norm: 4.235e+00\n",
      "Epoch 6360, Loss: 17.89272689819336, Neurons: 62, Grad norm: 4.227e+00\n",
      "Epoch 6360, Loss: 17.89272689819336, Neurons: 62, Grad norm: 4.227e+00\n",
      "Epoch 6361, Loss: 17.87010383605957, Neurons: 62, Grad norm: 4.182e+00\n",
      "Epoch 6361, Loss: 17.87010383605957, Neurons: 62, Grad norm: 4.182e+00\n",
      "Epoch 6362, Loss: 17.847309112548828, Neurons: 62, Grad norm: 4.112e+00\n",
      "Epoch 6362, Loss: 17.847309112548828, Neurons: 62, Grad norm: 4.112e+00\n",
      "Epoch 6363, Loss: 17.82436752319336, Neurons: 62, Grad norm: 4.091e+00\n",
      "Epoch 6363, Loss: 17.82436752319336, Neurons: 62, Grad norm: 4.091e+00\n",
      "Epoch 6364, Loss: 17.801361083984375, Neurons: 62, Grad norm: 4.191e+00\n",
      "Epoch 6364, Loss: 17.801361083984375, Neurons: 62, Grad norm: 4.191e+00\n",
      "Epoch 6365, Loss: 17.77829360961914, Neurons: 62, Grad norm: 4.306e+00\n",
      "Epoch 6365, Loss: 17.77829360961914, Neurons: 62, Grad norm: 4.306e+00\n",
      "Epoch 6366, Loss: 17.75507926940918, Neurons: 62, Grad norm: 4.292e+00\n",
      "Epoch 6366, Loss: 17.75507926940918, Neurons: 62, Grad norm: 4.292e+00\n",
      "Epoch 6367, Loss: 17.73167610168457, Neurons: 62, Grad norm: 4.227e+00\n",
      "Epoch 6367, Loss: 17.73167610168457, Neurons: 62, Grad norm: 4.227e+00\n",
      "Epoch 6368, Loss: 17.708093643188477, Neurons: 62, Grad norm: 4.125e+00\n",
      "Epoch 6368, Loss: 17.708093643188477, Neurons: 62, Grad norm: 4.125e+00\n",
      "Epoch 6369, Loss: 17.68436622619629, Neurons: 62, Grad norm: 4.093e+00\n",
      "Epoch 6369, Loss: 17.68436622619629, Neurons: 62, Grad norm: 4.093e+00\n",
      "Epoch 6370, Loss: 17.660531997680664, Neurons: 62, Grad norm: 4.126e+00\n",
      "Epoch 6370, Loss: 17.660531997680664, Neurons: 62, Grad norm: 4.126e+00\n",
      "Epoch 6371, Loss: 17.636613845825195, Neurons: 62, Grad norm: 4.212e+00\n",
      "Epoch 6371, Loss: 17.636613845825195, Neurons: 62, Grad norm: 4.212e+00\n",
      "Epoch 6372, Loss: 17.612586975097656, Neurons: 62, Grad norm: 4.194e+00\n",
      "Epoch 6372, Loss: 17.612586975097656, Neurons: 62, Grad norm: 4.194e+00\n",
      "Epoch 6373, Loss: 17.58841896057129, Neurons: 62, Grad norm: 4.141e+00\n",
      "Epoch 6373, Loss: 17.58841896057129, Neurons: 62, Grad norm: 4.141e+00\n",
      "Epoch 6374, Loss: 17.564098358154297, Neurons: 62, Grad norm: 4.080e+00\n",
      "Epoch 6374, Loss: 17.564098358154297, Neurons: 62, Grad norm: 4.080e+00\n",
      "Epoch 6375, Loss: 17.539655685424805, Neurons: 62, Grad norm: 4.038e+00\n",
      "Epoch 6375, Loss: 17.539655685424805, Neurons: 62, Grad norm: 4.038e+00\n",
      "Epoch 6376, Loss: 17.515111923217773, Neurons: 62, Grad norm: 4.011e+00\n",
      "Epoch 6376, Loss: 17.515111923217773, Neurons: 62, Grad norm: 4.011e+00\n",
      "Epoch 6377, Loss: 17.490468978881836, Neurons: 62, Grad norm: 3.992e+00\n",
      "Epoch 6377, Loss: 17.490468978881836, Neurons: 62, Grad norm: 3.992e+00\n",
      "Epoch 6378, Loss: 17.465707778930664, Neurons: 62, Grad norm: 3.984e+00\n",
      "Epoch 6378, Loss: 17.465707778930664, Neurons: 62, Grad norm: 3.984e+00\n",
      "Epoch 6379, Loss: 17.44082260131836, Neurons: 62, Grad norm: 3.977e+00\n",
      "Epoch 6379, Loss: 17.44082260131836, Neurons: 62, Grad norm: 3.977e+00\n",
      "Epoch 6380, Loss: 17.415817260742188, Neurons: 62, Grad norm: 3.952e+00\n",
      "Epoch 6380, Loss: 17.415817260742188, Neurons: 62, Grad norm: 3.952e+00\n",
      "Epoch 6381, Loss: 17.390687942504883, Neurons: 62, Grad norm: 3.948e+00\n",
      "Epoch 6381, Loss: 17.390687942504883, Neurons: 62, Grad norm: 3.948e+00\n",
      "Epoch 6382, Loss: 17.36545753479004, Neurons: 62, Grad norm: 3.954e+00\n",
      "Epoch 6382, Loss: 17.36545753479004, Neurons: 62, Grad norm: 3.954e+00\n",
      "Epoch 6383, Loss: 17.340129852294922, Neurons: 62, Grad norm: 3.984e+00\n",
      "Epoch 6383, Loss: 17.340129852294922, Neurons: 62, Grad norm: 3.984e+00\n",
      "Epoch 6384, Loss: 17.314708709716797, Neurons: 62, Grad norm: 4.004e+00\n",
      "Epoch 6384, Loss: 17.314708709716797, Neurons: 62, Grad norm: 4.004e+00\n",
      "Epoch 6385, Loss: 17.28917694091797, Neurons: 62, Grad norm: 4.000e+00\n",
      "Epoch 6385, Loss: 17.28917694091797, Neurons: 62, Grad norm: 4.000e+00\n",
      "Epoch 6386, Loss: 17.26352882385254, Neurons: 62, Grad norm: 3.978e+00\n",
      "Epoch 6386, Loss: 17.26352882385254, Neurons: 62, Grad norm: 3.978e+00\n",
      "Epoch 6387, Loss: 17.237768173217773, Neurons: 62, Grad norm: 3.960e+00\n",
      "Epoch 6387, Loss: 17.237768173217773, Neurons: 62, Grad norm: 3.960e+00\n",
      "Epoch 6388, Loss: 17.2119083404541, Neurons: 62, Grad norm: 3.949e+00\n",
      "Epoch 6388, Loss: 17.2119083404541, Neurons: 62, Grad norm: 3.949e+00\n",
      "Epoch 6389, Loss: 17.18595314025879, Neurons: 62, Grad norm: 3.946e+00\n",
      "Epoch 6389, Loss: 17.18595314025879, Neurons: 62, Grad norm: 3.946e+00\n",
      "Epoch 6390, Loss: 17.15990447998047, Neurons: 62, Grad norm: 3.940e+00\n",
      "Epoch 6390, Loss: 17.15990447998047, Neurons: 62, Grad norm: 3.940e+00\n",
      "Epoch 6391, Loss: 17.133758544921875, Neurons: 62, Grad norm: 3.936e+00\n",
      "Epoch 6391, Loss: 17.133758544921875, Neurons: 62, Grad norm: 3.936e+00\n",
      "Epoch 6392, Loss: 17.107513427734375, Neurons: 62, Grad norm: 3.927e+00\n",
      "Epoch 6392, Loss: 17.107513427734375, Neurons: 62, Grad norm: 3.927e+00\n",
      "Epoch 6393, Loss: 17.081167221069336, Neurons: 62, Grad norm: 3.914e+00\n",
      "Epoch 6393, Loss: 17.081167221069336, Neurons: 62, Grad norm: 3.914e+00\n",
      "Epoch 6394, Loss: 17.054725646972656, Neurons: 62, Grad norm: 3.903e+00\n",
      "Epoch 6394, Loss: 17.054725646972656, Neurons: 62, Grad norm: 3.903e+00\n",
      "Epoch 6395, Loss: 17.02819061279297, Neurons: 62, Grad norm: 3.896e+00\n",
      "Epoch 6395, Loss: 17.02819061279297, Neurons: 62, Grad norm: 3.896e+00\n",
      "Epoch 6396, Loss: 17.001564025878906, Neurons: 62, Grad norm: 3.892e+00\n",
      "Epoch 6396, Loss: 17.001564025878906, Neurons: 62, Grad norm: 3.892e+00\n",
      "Epoch 6397, Loss: 16.97484016418457, Neurons: 62, Grad norm: 3.885e+00\n",
      "Epoch 6397, Loss: 16.97484016418457, Neurons: 62, Grad norm: 3.885e+00\n",
      "Epoch 6398, Loss: 16.948028564453125, Neurons: 62, Grad norm: 3.883e+00\n",
      "Epoch 6398, Loss: 16.948028564453125, Neurons: 62, Grad norm: 3.883e+00\n",
      "Epoch 6399, Loss: 16.921123504638672, Neurons: 62, Grad norm: 3.878e+00\n",
      "Epoch 6399, Loss: 16.921123504638672, Neurons: 62, Grad norm: 3.878e+00\n",
      "Epoch 6399, Test loss: 15.786154747009277\n",
      "Epoch 6399, Test loss: 15.786154747009277\n",
      "Added neuron to hidden layer 2 with activation sin\n",
      "Added neuron to hidden layer 2 with activation sin\n",
      "network shape updated to :[27, 35, 1]\n",
      "network shape updated to :[27, 35, 1]\n",
      "Epoch 6400, Loss: 16.89472007751465, Neurons: 63, Grad norm: 1.445e+01\n",
      "Epoch 6400, Loss: 16.89472007751465, Neurons: 63, Grad norm: 1.445e+01\n",
      "Epoch 6401, Loss: 16.889801025390625, Neurons: 63, Grad norm: 1.374e+01\n",
      "Epoch 6401, Loss: 16.889801025390625, Neurons: 63, Grad norm: 1.374e+01\n",
      "Epoch 6402, Loss: 16.877946853637695, Neurons: 63, Grad norm: 1.028e+01\n",
      "Epoch 6402, Loss: 16.877946853637695, Neurons: 63, Grad norm: 1.028e+01\n",
      "Epoch 6403, Loss: 16.865707397460938, Neurons: 63, Grad norm: 5.472e+00\n",
      "Epoch 6403, Loss: 16.865707397460938, Neurons: 63, Grad norm: 5.472e+00\n",
      "Epoch 6404, Loss: 16.85179328918457, Neurons: 63, Grad norm: 1.018e+01\n",
      "Epoch 6404, Loss: 16.85179328918457, Neurons: 63, Grad norm: 1.018e+01\n",
      "Epoch 6405, Loss: 16.842565536499023, Neurons: 63, Grad norm: 9.285e+00\n",
      "Epoch 6405, Loss: 16.842565536499023, Neurons: 63, Grad norm: 9.285e+00\n",
      "Epoch 6406, Loss: 16.83074378967285, Neurons: 63, Grad norm: 5.324e+00\n",
      "Epoch 6406, Loss: 16.83074378967285, Neurons: 63, Grad norm: 5.324e+00\n",
      "Epoch 6407, Loss: 16.816282272338867, Neurons: 63, Grad norm: 5.532e+00\n",
      "Epoch 6407, Loss: 16.816282272338867, Neurons: 63, Grad norm: 5.532e+00\n",
      "Epoch 6408, Loss: 16.80337142944336, Neurons: 63, Grad norm: 6.422e+00\n",
      "Epoch 6408, Loss: 16.80337142944336, Neurons: 63, Grad norm: 6.422e+00\n",
      "Epoch 6409, Loss: 16.790700912475586, Neurons: 63, Grad norm: 5.497e+00\n",
      "Epoch 6409, Loss: 16.790700912475586, Neurons: 63, Grad norm: 5.497e+00\n",
      "Epoch 6410, Loss: 16.776517868041992, Neurons: 63, Grad norm: 4.120e+00\n",
      "Epoch 6410, Loss: 16.776517868041992, Neurons: 63, Grad norm: 4.120e+00\n",
      "Epoch 6411, Loss: 16.761415481567383, Neurons: 63, Grad norm: 4.118e+00\n",
      "Epoch 6411, Loss: 16.761415481567383, Neurons: 63, Grad norm: 4.118e+00\n",
      "Epoch 6412, Loss: 16.746761322021484, Neurons: 63, Grad norm: 5.126e+00\n",
      "Epoch 6412, Loss: 16.746761322021484, Neurons: 63, Grad norm: 5.126e+00\n",
      "Epoch 6413, Loss: 16.732282638549805, Neurons: 63, Grad norm: 5.298e+00\n",
      "Epoch 6413, Loss: 16.732282638549805, Neurons: 63, Grad norm: 5.298e+00\n",
      "Epoch 6414, Loss: 16.716562271118164, Neurons: 63, Grad norm: 4.665e+00\n",
      "Epoch 6414, Loss: 16.716562271118164, Neurons: 63, Grad norm: 4.665e+00\n",
      "Epoch 6415, Loss: 16.699993133544922, Neurons: 63, Grad norm: 4.194e+00\n",
      "Epoch 6415, Loss: 16.699993133544922, Neurons: 63, Grad norm: 4.194e+00\n",
      "Epoch 6416, Loss: 16.68360710144043, Neurons: 63, Grad norm: 4.374e+00\n",
      "Epoch 6416, Loss: 16.68360710144043, Neurons: 63, Grad norm: 4.374e+00\n",
      "Epoch 6417, Loss: 16.667192459106445, Neurons: 63, Grad norm: 4.554e+00\n",
      "Epoch 6417, Loss: 16.667192459106445, Neurons: 63, Grad norm: 4.554e+00\n",
      "Epoch 6418, Loss: 16.64997100830078, Neurons: 63, Grad norm: 4.104e+00\n",
      "Epoch 6418, Loss: 16.64997100830078, Neurons: 63, Grad norm: 4.104e+00\n",
      "Epoch 6419, Loss: 16.631933212280273, Neurons: 63, Grad norm: 4.006e+00\n",
      "Epoch 6419, Loss: 16.631933212280273, Neurons: 63, Grad norm: 4.006e+00\n",
      "Epoch 6420, Loss: 16.61370086669922, Neurons: 63, Grad norm: 4.660e+00\n",
      "Epoch 6420, Loss: 16.61370086669922, Neurons: 63, Grad norm: 4.660e+00\n",
      "Epoch 6421, Loss: 16.595386505126953, Neurons: 63, Grad norm: 4.663e+00\n",
      "Epoch 6421, Loss: 16.595386505126953, Neurons: 63, Grad norm: 4.663e+00\n",
      "Epoch 6422, Loss: 16.57660675048828, Neurons: 63, Grad norm: 4.048e+00\n",
      "Epoch 6422, Loss: 16.57660675048828, Neurons: 63, Grad norm: 4.048e+00\n",
      "Epoch 6423, Loss: 16.557292938232422, Neurons: 63, Grad norm: 4.006e+00\n",
      "Epoch 6423, Loss: 16.557292938232422, Neurons: 63, Grad norm: 4.006e+00\n",
      "Epoch 6424, Loss: 16.537700653076172, Neurons: 63, Grad norm: 4.162e+00\n",
      "Epoch 6424, Loss: 16.537700653076172, Neurons: 63, Grad norm: 4.162e+00\n",
      "Epoch 6425, Loss: 16.517770767211914, Neurons: 63, Grad norm: 3.925e+00\n",
      "Epoch 6425, Loss: 16.517770767211914, Neurons: 63, Grad norm: 3.925e+00\n",
      "Epoch 6426, Loss: 16.497440338134766, Neurons: 63, Grad norm: 3.880e+00\n",
      "Epoch 6426, Loss: 16.497440338134766, Neurons: 63, Grad norm: 3.880e+00\n",
      "Epoch 6427, Loss: 16.4768123626709, Neurons: 63, Grad norm: 4.103e+00\n",
      "Epoch 6427, Loss: 16.4768123626709, Neurons: 63, Grad norm: 4.103e+00\n",
      "Epoch 6428, Loss: 16.45586395263672, Neurons: 63, Grad norm: 4.145e+00\n",
      "Epoch 6428, Loss: 16.45586395263672, Neurons: 63, Grad norm: 4.145e+00\n",
      "Epoch 6429, Loss: 16.434528350830078, Neurons: 63, Grad norm: 4.071e+00\n",
      "Epoch 6429, Loss: 16.434528350830078, Neurons: 63, Grad norm: 4.071e+00\n",
      "Epoch 6430, Loss: 16.412973403930664, Neurons: 63, Grad norm: 4.110e+00\n",
      "Epoch 6430, Loss: 16.412973403930664, Neurons: 63, Grad norm: 4.110e+00\n",
      "Epoch 6431, Loss: 16.39116859436035, Neurons: 63, Grad norm: 4.009e+00\n",
      "Epoch 6431, Loss: 16.39116859436035, Neurons: 63, Grad norm: 4.009e+00\n",
      "Epoch 6432, Loss: 16.36891746520996, Neurons: 63, Grad norm: 3.799e+00\n",
      "Epoch 6432, Loss: 16.36891746520996, Neurons: 63, Grad norm: 3.799e+00\n",
      "Epoch 6433, Loss: 16.346323013305664, Neurons: 63, Grad norm: 3.801e+00\n",
      "Epoch 6433, Loss: 16.346323013305664, Neurons: 63, Grad norm: 3.801e+00\n",
      "Epoch 6434, Loss: 16.323570251464844, Neurons: 63, Grad norm: 3.798e+00\n",
      "Epoch 6434, Loss: 16.323570251464844, Neurons: 63, Grad norm: 3.798e+00\n",
      "Epoch 6435, Loss: 16.30049705505371, Neurons: 63, Grad norm: 3.755e+00\n",
      "Epoch 6435, Loss: 16.30049705505371, Neurons: 63, Grad norm: 3.755e+00\n",
      "Epoch 6436, Loss: 16.27706527709961, Neurons: 63, Grad norm: 3.817e+00\n",
      "Epoch 6436, Loss: 16.27706527709961, Neurons: 63, Grad norm: 3.817e+00\n",
      "Epoch 6437, Loss: 16.253402709960938, Neurons: 63, Grad norm: 3.901e+00\n",
      "Epoch 6437, Loss: 16.253402709960938, Neurons: 63, Grad norm: 3.901e+00\n",
      "Epoch 6438, Loss: 16.229511260986328, Neurons: 63, Grad norm: 3.809e+00\n",
      "Epoch 6438, Loss: 16.229511260986328, Neurons: 63, Grad norm: 3.809e+00\n",
      "Epoch 6439, Loss: 16.205286026000977, Neurons: 63, Grad norm: 3.714e+00\n",
      "Epoch 6439, Loss: 16.205286026000977, Neurons: 63, Grad norm: 3.714e+00\n",
      "Epoch 6440, Loss: 16.180761337280273, Neurons: 63, Grad norm: 3.704e+00\n",
      "Epoch 6440, Loss: 16.180761337280273, Neurons: 63, Grad norm: 3.704e+00\n",
      "Epoch 6441, Loss: 16.156023025512695, Neurons: 63, Grad norm: 3.749e+00\n",
      "Epoch 6441, Loss: 16.156023025512695, Neurons: 63, Grad norm: 3.749e+00\n",
      "Epoch 6442, Loss: 16.131061553955078, Neurons: 63, Grad norm: 3.725e+00\n",
      "Epoch 6442, Loss: 16.131061553955078, Neurons: 63, Grad norm: 3.725e+00\n",
      "Epoch 6443, Loss: 16.105791091918945, Neurons: 63, Grad norm: 3.713e+00\n",
      "Epoch 6443, Loss: 16.105791091918945, Neurons: 63, Grad norm: 3.713e+00\n",
      "Epoch 6444, Loss: 16.08028793334961, Neurons: 63, Grad norm: 3.786e+00\n",
      "Epoch 6444, Loss: 16.08028793334961, Neurons: 63, Grad norm: 3.786e+00\n",
      "Epoch 6445, Loss: 16.054580688476562, Neurons: 63, Grad norm: 3.767e+00\n",
      "Epoch 6445, Loss: 16.054580688476562, Neurons: 63, Grad norm: 3.767e+00\n",
      "Epoch 6446, Loss: 16.028583526611328, Neurons: 63, Grad norm: 3.810e+00\n",
      "Epoch 6446, Loss: 16.028583526611328, Neurons: 63, Grad norm: 3.810e+00\n",
      "Epoch 6447, Loss: 16.00236701965332, Neurons: 63, Grad norm: 3.784e+00\n",
      "Epoch 6447, Loss: 16.00236701965332, Neurons: 63, Grad norm: 3.784e+00\n",
      "Epoch 6448, Loss: 15.975953102111816, Neurons: 63, Grad norm: 3.696e+00\n",
      "Epoch 6448, Loss: 15.975953102111816, Neurons: 63, Grad norm: 3.696e+00\n",
      "Epoch 6449, Loss: 15.949297904968262, Neurons: 63, Grad norm: 3.664e+00\n",
      "Epoch 6449, Loss: 15.949297904968262, Neurons: 63, Grad norm: 3.664e+00\n",
      "Epoch 6450, Loss: 15.922414779663086, Neurons: 63, Grad norm: 3.664e+00\n",
      "Epoch 6450, Loss: 15.922414779663086, Neurons: 63, Grad norm: 3.664e+00\n",
      "Epoch 6451, Loss: 15.895309448242188, Neurons: 63, Grad norm: 3.659e+00\n",
      "Epoch 6451, Loss: 15.895309448242188, Neurons: 63, Grad norm: 3.659e+00\n",
      "Epoch 6452, Loss: 15.86798095703125, Neurons: 63, Grad norm: 3.693e+00\n",
      "Epoch 6452, Loss: 15.86798095703125, Neurons: 63, Grad norm: 3.693e+00\n",
      "Epoch 6453, Loss: 15.840459823608398, Neurons: 63, Grad norm: 3.688e+00\n",
      "Epoch 6453, Loss: 15.840459823608398, Neurons: 63, Grad norm: 3.688e+00\n",
      "Epoch 6454, Loss: 15.812727928161621, Neurons: 63, Grad norm: 3.651e+00\n",
      "Epoch 6454, Loss: 15.812727928161621, Neurons: 63, Grad norm: 3.651e+00\n",
      "Epoch 6455, Loss: 15.784790992736816, Neurons: 63, Grad norm: 3.634e+00\n",
      "Epoch 6455, Loss: 15.784790992736816, Neurons: 63, Grad norm: 3.634e+00\n",
      "Epoch 6456, Loss: 15.756660461425781, Neurons: 63, Grad norm: 3.639e+00\n",
      "Epoch 6456, Loss: 15.756660461425781, Neurons: 63, Grad norm: 3.639e+00\n",
      "Epoch 6457, Loss: 15.728340148925781, Neurons: 63, Grad norm: 3.635e+00\n",
      "Epoch 6457, Loss: 15.728340148925781, Neurons: 63, Grad norm: 3.635e+00\n",
      "Epoch 6458, Loss: 15.699820518493652, Neurons: 63, Grad norm: 3.634e+00\n",
      "Epoch 6458, Loss: 15.699820518493652, Neurons: 63, Grad norm: 3.634e+00\n",
      "Epoch 6459, Loss: 15.671110153198242, Neurons: 63, Grad norm: 3.652e+00\n",
      "Epoch 6459, Loss: 15.671110153198242, Neurons: 63, Grad norm: 3.652e+00\n",
      "Epoch 6460, Loss: 15.642223358154297, Neurons: 63, Grad norm: 3.645e+00\n",
      "Epoch 6460, Loss: 15.642223358154297, Neurons: 63, Grad norm: 3.645e+00\n",
      "Epoch 6461, Loss: 15.613157272338867, Neurons: 63, Grad norm: 3.613e+00\n",
      "Epoch 6461, Loss: 15.613157272338867, Neurons: 63, Grad norm: 3.613e+00\n",
      "Epoch 6462, Loss: 15.58390998840332, Neurons: 63, Grad norm: 3.585e+00\n",
      "Epoch 6462, Loss: 15.58390998840332, Neurons: 63, Grad norm: 3.585e+00\n",
      "Epoch 6463, Loss: 15.554489135742188, Neurons: 63, Grad norm: 3.587e+00\n",
      "Epoch 6463, Loss: 15.554489135742188, Neurons: 63, Grad norm: 3.587e+00\n",
      "Epoch 6464, Loss: 15.52489948272705, Neurons: 63, Grad norm: 3.596e+00\n",
      "Epoch 6464, Loss: 15.52489948272705, Neurons: 63, Grad norm: 3.596e+00\n",
      "Epoch 6465, Loss: 15.495141983032227, Neurons: 63, Grad norm: 3.623e+00\n",
      "Epoch 6465, Loss: 15.495141983032227, Neurons: 63, Grad norm: 3.623e+00\n",
      "Epoch 6466, Loss: 15.465218544006348, Neurons: 63, Grad norm: 3.614e+00\n",
      "Epoch 6466, Loss: 15.465218544006348, Neurons: 63, Grad norm: 3.614e+00\n",
      "Epoch 6467, Loss: 15.435135841369629, Neurons: 63, Grad norm: 3.589e+00\n",
      "Epoch 6467, Loss: 15.435135841369629, Neurons: 63, Grad norm: 3.589e+00\n",
      "Epoch 6468, Loss: 15.404890060424805, Neurons: 63, Grad norm: 3.566e+00\n",
      "Epoch 6468, Loss: 15.404890060424805, Neurons: 63, Grad norm: 3.566e+00\n",
      "Epoch 6469, Loss: 15.374493598937988, Neurons: 63, Grad norm: 3.554e+00\n",
      "Epoch 6469, Loss: 15.374493598937988, Neurons: 63, Grad norm: 3.554e+00\n",
      "Epoch 6470, Loss: 15.343945503234863, Neurons: 63, Grad norm: 3.544e+00\n",
      "Epoch 6470, Loss: 15.343945503234863, Neurons: 63, Grad norm: 3.544e+00\n",
      "Epoch 6471, Loss: 15.313241004943848, Neurons: 63, Grad norm: 3.548e+00\n",
      "Epoch 6471, Loss: 15.313241004943848, Neurons: 63, Grad norm: 3.548e+00\n",
      "Epoch 6472, Loss: 15.282391548156738, Neurons: 63, Grad norm: 3.567e+00\n",
      "Epoch 6472, Loss: 15.282391548156738, Neurons: 63, Grad norm: 3.567e+00\n",
      "Epoch 6473, Loss: 15.251395225524902, Neurons: 63, Grad norm: 3.599e+00\n",
      "Epoch 6473, Loss: 15.251395225524902, Neurons: 63, Grad norm: 3.599e+00\n",
      "Epoch 6474, Loss: 15.220258712768555, Neurons: 63, Grad norm: 3.561e+00\n",
      "Epoch 6474, Loss: 15.220258712768555, Neurons: 63, Grad norm: 3.561e+00\n",
      "Epoch 6475, Loss: 15.188971519470215, Neurons: 63, Grad norm: 3.519e+00\n",
      "Epoch 6475, Loss: 15.188971519470215, Neurons: 63, Grad norm: 3.519e+00\n",
      "Epoch 6476, Loss: 15.157551765441895, Neurons: 63, Grad norm: 3.509e+00\n",
      "Epoch 6476, Loss: 15.157551765441895, Neurons: 63, Grad norm: 3.509e+00\n",
      "Epoch 6477, Loss: 15.125994682312012, Neurons: 63, Grad norm: 3.513e+00\n",
      "Epoch 6477, Loss: 15.125994682312012, Neurons: 63, Grad norm: 3.513e+00\n",
      "Epoch 6478, Loss: 15.0942964553833, Neurons: 63, Grad norm: 3.536e+00\n",
      "Epoch 6478, Loss: 15.0942964553833, Neurons: 63, Grad norm: 3.536e+00\n",
      "Epoch 6479, Loss: 15.062467575073242, Neurons: 63, Grad norm: 3.534e+00\n",
      "Epoch 6479, Loss: 15.062467575073242, Neurons: 63, Grad norm: 3.534e+00\n",
      "Epoch 6480, Loss: 15.030508995056152, Neurons: 63, Grad norm: 3.499e+00\n",
      "Epoch 6480, Loss: 15.030508995056152, Neurons: 63, Grad norm: 3.499e+00\n",
      "Epoch 6481, Loss: 14.9984130859375, Neurons: 63, Grad norm: 3.493e+00\n",
      "Epoch 6481, Loss: 14.9984130859375, Neurons: 63, Grad norm: 3.493e+00\n",
      "Epoch 6482, Loss: 14.966187477111816, Neurons: 63, Grad norm: 3.491e+00\n",
      "Epoch 6482, Loss: 14.966187477111816, Neurons: 63, Grad norm: 3.491e+00\n",
      "Epoch 6483, Loss: 14.93384075164795, Neurons: 63, Grad norm: 3.487e+00\n",
      "Epoch 6483, Loss: 14.93384075164795, Neurons: 63, Grad norm: 3.487e+00\n",
      "Epoch 6484, Loss: 14.901362419128418, Neurons: 63, Grad norm: 3.477e+00\n",
      "Epoch 6484, Loss: 14.901362419128418, Neurons: 63, Grad norm: 3.477e+00\n",
      "Epoch 6485, Loss: 14.868754386901855, Neurons: 63, Grad norm: 3.470e+00\n",
      "Epoch 6485, Loss: 14.868754386901855, Neurons: 63, Grad norm: 3.470e+00\n",
      "Epoch 6486, Loss: 14.836020469665527, Neurons: 63, Grad norm: 3.469e+00\n",
      "Epoch 6486, Loss: 14.836020469665527, Neurons: 63, Grad norm: 3.469e+00\n",
      "Epoch 6487, Loss: 14.803165435791016, Neurons: 63, Grad norm: 3.457e+00\n",
      "Epoch 6487, Loss: 14.803165435791016, Neurons: 63, Grad norm: 3.457e+00\n",
      "Epoch 6488, Loss: 14.770184516906738, Neurons: 63, Grad norm: 3.451e+00\n",
      "Epoch 6488, Loss: 14.770184516906738, Neurons: 63, Grad norm: 3.451e+00\n",
      "Epoch 6489, Loss: 14.737077713012695, Neurons: 63, Grad norm: 3.456e+00\n",
      "Epoch 6489, Loss: 14.737077713012695, Neurons: 63, Grad norm: 3.456e+00\n",
      "Epoch 6490, Loss: 14.703841209411621, Neurons: 63, Grad norm: 3.458e+00\n",
      "Epoch 6490, Loss: 14.703841209411621, Neurons: 63, Grad norm: 3.458e+00\n",
      "Epoch 6491, Loss: 14.670492172241211, Neurons: 63, Grad norm: 3.438e+00\n",
      "Epoch 6491, Loss: 14.670492172241211, Neurons: 63, Grad norm: 3.438e+00\n",
      "Epoch 6492, Loss: 14.637018203735352, Neurons: 63, Grad norm: 3.427e+00\n",
      "Epoch 6492, Loss: 14.637018203735352, Neurons: 63, Grad norm: 3.427e+00\n",
      "Epoch 6493, Loss: 14.603414535522461, Neurons: 63, Grad norm: 3.430e+00\n",
      "Epoch 6493, Loss: 14.603414535522461, Neurons: 63, Grad norm: 3.430e+00\n",
      "Epoch 6494, Loss: 14.569690704345703, Neurons: 63, Grad norm: 3.424e+00\n",
      "Epoch 6494, Loss: 14.569690704345703, Neurons: 63, Grad norm: 3.424e+00\n",
      "Epoch 6495, Loss: 14.535842895507812, Neurons: 63, Grad norm: 3.407e+00\n",
      "Epoch 6495, Loss: 14.535842895507812, Neurons: 63, Grad norm: 3.407e+00\n",
      "Epoch 6496, Loss: 14.501872062683105, Neurons: 63, Grad norm: 3.404e+00\n",
      "Epoch 6496, Loss: 14.501872062683105, Neurons: 63, Grad norm: 3.404e+00\n",
      "Epoch 6497, Loss: 14.467780113220215, Neurons: 63, Grad norm: 3.422e+00\n",
      "Epoch 6497, Loss: 14.467780113220215, Neurons: 63, Grad norm: 3.422e+00\n",
      "Epoch 6498, Loss: 14.433564186096191, Neurons: 63, Grad norm: 3.405e+00\n",
      "Epoch 6498, Loss: 14.433564186096191, Neurons: 63, Grad norm: 3.405e+00\n",
      "Epoch 6499, Loss: 14.399222373962402, Neurons: 63, Grad norm: 3.385e+00\n",
      "Epoch 6499, Loss: 14.399222373962402, Neurons: 63, Grad norm: 3.385e+00\n",
      "Epoch 6499, Test loss: 13.384073257446289\n",
      "Epoch 6499, Test loss: 13.384073257446289\n",
      "Added neuron to hidden layer 1 with activation tanh\n",
      "Added neuron to hidden layer 1 with activation tanh\n",
      "network shape updated to :[28, 35, 1]\n",
      "network shape updated to :[28, 35, 1]\n",
      "Epoch 6500, Loss: 15.991644859313965, Neurons: 64, Grad norm: 1.023e+02\n",
      "Epoch 6500, Loss: 15.991644859313965, Neurons: 64, Grad norm: 1.023e+02\n",
      "Epoch 6501, Loss: 15.561206817626953, Neurons: 64, Grad norm: 8.092e+01\n",
      "Epoch 6501, Loss: 15.561206817626953, Neurons: 64, Grad norm: 8.092e+01\n",
      "Epoch 6502, Loss: 15.202780723571777, Neurons: 64, Grad norm: 6.276e+01\n",
      "Epoch 6502, Loss: 15.202780723571777, Neurons: 64, Grad norm: 6.276e+01\n",
      "Epoch 6503, Loss: 14.92428207397461, Neurons: 64, Grad norm: 4.839e+01\n",
      "Epoch 6503, Loss: 14.92428207397461, Neurons: 64, Grad norm: 4.839e+01\n",
      "Epoch 6504, Loss: 14.725932121276855, Neurons: 64, Grad norm: 3.752e+01\n",
      "Epoch 6504, Loss: 14.725932121276855, Neurons: 64, Grad norm: 3.752e+01\n",
      "Epoch 6505, Loss: 14.600284576416016, Neurons: 64, Grad norm: 3.002e+01\n",
      "Epoch 6505, Loss: 14.600284576416016, Neurons: 64, Grad norm: 3.002e+01\n",
      "Epoch 6506, Loss: 14.535582542419434, Neurons: 64, Grad norm: 2.642e+01\n",
      "Epoch 6506, Loss: 14.535582542419434, Neurons: 64, Grad norm: 2.642e+01\n",
      "Epoch 6507, Loss: 14.516350746154785, Neurons: 64, Grad norm: 2.676e+01\n",
      "Epoch 6507, Loss: 14.516350746154785, Neurons: 64, Grad norm: 2.676e+01\n",
      "Epoch 6508, Loss: 14.524447441101074, Neurons: 64, Grad norm: 2.825e+01\n",
      "Epoch 6508, Loss: 14.524447441101074, Neurons: 64, Grad norm: 2.825e+01\n",
      "Epoch 6509, Loss: 14.540729522705078, Neurons: 64, Grad norm: 3.007e+01\n",
      "Epoch 6509, Loss: 14.540729522705078, Neurons: 64, Grad norm: 3.007e+01\n",
      "Epoch 6510, Loss: 14.551794052124023, Neurons: 64, Grad norm: 3.135e+01\n",
      "Epoch 6510, Loss: 14.551794052124023, Neurons: 64, Grad norm: 3.135e+01\n",
      "Epoch 6511, Loss: 14.551512718200684, Neurons: 64, Grad norm: 3.156e+01\n",
      "Epoch 6511, Loss: 14.551512718200684, Neurons: 64, Grad norm: 3.156e+01\n",
      "Epoch 6512, Loss: 14.53799819946289, Neurons: 64, Grad norm: 3.051e+01\n",
      "Epoch 6512, Loss: 14.53799819946289, Neurons: 64, Grad norm: 3.051e+01\n",
      "Epoch 6513, Loss: 14.512608528137207, Neurons: 64, Grad norm: 2.826e+01\n",
      "Epoch 6513, Loss: 14.512608528137207, Neurons: 64, Grad norm: 2.826e+01\n",
      "Epoch 6514, Loss: 14.478850364685059, Neurons: 64, Grad norm: 2.507e+01\n",
      "Epoch 6514, Loss: 14.478850364685059, Neurons: 64, Grad norm: 2.507e+01\n",
      "Epoch 6515, Loss: 14.441266059875488, Neurons: 64, Grad norm: 2.123e+01\n",
      "Epoch 6515, Loss: 14.441266059875488, Neurons: 64, Grad norm: 2.123e+01\n",
      "Epoch 6516, Loss: 14.404356002807617, Neurons: 64, Grad norm: 1.715e+01\n",
      "Epoch 6516, Loss: 14.404356002807617, Neurons: 64, Grad norm: 1.715e+01\n",
      "Epoch 6517, Loss: 14.371631622314453, Neurons: 64, Grad norm: 1.325e+01\n",
      "Epoch 6517, Loss: 14.371631622314453, Neurons: 64, Grad norm: 1.325e+01\n",
      "Epoch 6518, Loss: 14.345054626464844, Neurons: 64, Grad norm: 1.010e+01\n",
      "Epoch 6518, Loss: 14.345054626464844, Neurons: 64, Grad norm: 1.010e+01\n",
      "Epoch 6519, Loss: 14.325068473815918, Neurons: 64, Grad norm: 8.564e+00\n",
      "Epoch 6519, Loss: 14.325068473815918, Neurons: 64, Grad norm: 8.564e+00\n",
      "Epoch 6520, Loss: 14.311039924621582, Neurons: 64, Grad norm: 9.174e+00\n",
      "Epoch 6520, Loss: 14.311039924621582, Neurons: 64, Grad norm: 9.174e+00\n",
      "Epoch 6521, Loss: 14.301630020141602, Neurons: 64, Grad norm: 1.109e+01\n",
      "Epoch 6521, Loss: 14.301630020141602, Neurons: 64, Grad norm: 1.109e+01\n",
      "Epoch 6522, Loss: 14.29505729675293, Neurons: 64, Grad norm: 1.317e+01\n",
      "Epoch 6522, Loss: 14.29505729675293, Neurons: 64, Grad norm: 1.317e+01\n",
      "Epoch 6523, Loss: 14.289358139038086, Neurons: 64, Grad norm: 1.474e+01\n",
      "Epoch 6523, Loss: 14.289358139038086, Neurons: 64, Grad norm: 1.474e+01\n",
      "Epoch 6524, Loss: 14.28272533416748, Neurons: 64, Grad norm: 1.554e+01\n",
      "Epoch 6524, Loss: 14.28272533416748, Neurons: 64, Grad norm: 1.554e+01\n",
      "Epoch 6525, Loss: 14.273847579956055, Neurons: 64, Grad norm: 1.550e+01\n",
      "Epoch 6525, Loss: 14.273847579956055, Neurons: 64, Grad norm: 1.550e+01\n",
      "Epoch 6526, Loss: 14.26211166381836, Neurons: 64, Grad norm: 1.473e+01\n",
      "Epoch 6526, Loss: 14.26211166381836, Neurons: 64, Grad norm: 1.473e+01\n",
      "Epoch 6527, Loss: 14.247600555419922, Neurons: 64, Grad norm: 1.341e+01\n",
      "Epoch 6527, Loss: 14.247600555419922, Neurons: 64, Grad norm: 1.341e+01\n",
      "Epoch 6528, Loss: 14.23094367980957, Neurons: 64, Grad norm: 1.174e+01\n",
      "Epoch 6528, Loss: 14.23094367980957, Neurons: 64, Grad norm: 1.174e+01\n",
      "Epoch 6529, Loss: 14.213078498840332, Neurons: 64, Grad norm: 9.976e+00\n",
      "Epoch 6529, Loss: 14.213078498840332, Neurons: 64, Grad norm: 9.976e+00\n",
      "Epoch 6530, Loss: 14.19502067565918, Neurons: 64, Grad norm: 8.344e+00\n",
      "Epoch 6530, Loss: 14.19502067565918, Neurons: 64, Grad norm: 8.344e+00\n",
      "Epoch 6531, Loss: 14.177633285522461, Neurons: 64, Grad norm: 7.019e+00\n",
      "Epoch 6531, Loss: 14.177633285522461, Neurons: 64, Grad norm: 7.019e+00\n",
      "Epoch 6532, Loss: 14.16150951385498, Neurons: 64, Grad norm: 6.158e+00\n",
      "Epoch 6532, Loss: 14.16150951385498, Neurons: 64, Grad norm: 6.158e+00\n",
      "Epoch 6533, Loss: 14.146912574768066, Neurons: 64, Grad norm: 5.857e+00\n",
      "Epoch 6533, Loss: 14.146912574768066, Neurons: 64, Grad norm: 5.857e+00\n",
      "Epoch 6534, Loss: 14.133784294128418, Neurons: 64, Grad norm: 6.065e+00\n",
      "Epoch 6534, Loss: 14.133784294128418, Neurons: 64, Grad norm: 6.065e+00\n",
      "Epoch 6535, Loss: 14.121805191040039, Neurons: 64, Grad norm: 6.611e+00\n",
      "Epoch 6535, Loss: 14.121805191040039, Neurons: 64, Grad norm: 6.611e+00\n",
      "Epoch 6536, Loss: 14.110479354858398, Neurons: 64, Grad norm: 7.263e+00\n",
      "Epoch 6536, Loss: 14.110479354858398, Neurons: 64, Grad norm: 7.263e+00\n",
      "Epoch 6537, Loss: 14.099228858947754, Neurons: 64, Grad norm: 7.825e+00\n",
      "Epoch 6537, Loss: 14.099228858947754, Neurons: 64, Grad norm: 7.825e+00\n",
      "Epoch 6538, Loss: 14.08756160736084, Neurons: 64, Grad norm: 8.137e+00\n",
      "Epoch 6538, Loss: 14.08756160736084, Neurons: 64, Grad norm: 8.137e+00\n",
      "Epoch 6539, Loss: 14.075103759765625, Neurons: 64, Grad norm: 8.155e+00\n",
      "Epoch 6539, Loss: 14.075103759765625, Neurons: 64, Grad norm: 8.155e+00\n",
      "Epoch 6540, Loss: 14.06169319152832, Neurons: 64, Grad norm: 7.877e+00\n",
      "Epoch 6540, Loss: 14.06169319152832, Neurons: 64, Grad norm: 7.877e+00\n",
      "Epoch 6541, Loss: 14.047383308410645, Neurons: 64, Grad norm: 7.357e+00\n",
      "Epoch 6541, Loss: 14.047383308410645, Neurons: 64, Grad norm: 7.357e+00\n",
      "Epoch 6542, Loss: 14.032383918762207, Neurons: 64, Grad norm: 6.684e+00\n",
      "Epoch 6542, Loss: 14.032383918762207, Neurons: 64, Grad norm: 6.684e+00\n",
      "Epoch 6543, Loss: 14.017003059387207, Neurons: 64, Grad norm: 5.973e+00\n",
      "Epoch 6543, Loss: 14.017003059387207, Neurons: 64, Grad norm: 5.973e+00\n",
      "Epoch 6544, Loss: 14.001543998718262, Neurons: 64, Grad norm: 5.339e+00\n",
      "Epoch 6544, Loss: 14.001543998718262, Neurons: 64, Grad norm: 5.339e+00\n",
      "Epoch 6545, Loss: 13.9862642288208, Neurons: 64, Grad norm: 4.888e+00\n",
      "Epoch 6545, Loss: 13.9862642288208, Neurons: 64, Grad norm: 4.888e+00\n",
      "Epoch 6546, Loss: 13.97132396697998, Neurons: 64, Grad norm: 4.688e+00\n",
      "Epoch 6546, Loss: 13.97132396697998, Neurons: 64, Grad norm: 4.688e+00\n",
      "Epoch 6547, Loss: 13.956754684448242, Neurons: 64, Grad norm: 4.751e+00\n",
      "Epoch 6547, Loss: 13.956754684448242, Neurons: 64, Grad norm: 4.751e+00\n",
      "Epoch 6548, Loss: 13.942488670349121, Neurons: 64, Grad norm: 5.000e+00\n",
      "Epoch 6548, Loss: 13.942488670349121, Neurons: 64, Grad norm: 5.000e+00\n",
      "Epoch 6549, Loss: 13.928363800048828, Neurons: 64, Grad norm: 5.303e+00\n",
      "Epoch 6549, Loss: 13.928363800048828, Neurons: 64, Grad norm: 5.303e+00\n",
      "Epoch 6550, Loss: 13.9141845703125, Neurons: 64, Grad norm: 5.551e+00\n",
      "Epoch 6550, Loss: 13.9141845703125, Neurons: 64, Grad norm: 5.551e+00\n",
      "Epoch 6551, Loss: 13.899751663208008, Neurons: 64, Grad norm: 5.661e+00\n",
      "Epoch 6551, Loss: 13.899751663208008, Neurons: 64, Grad norm: 5.661e+00\n",
      "Epoch 6552, Loss: 13.884918212890625, Neurons: 64, Grad norm: 5.598e+00\n",
      "Epoch 6552, Loss: 13.884918212890625, Neurons: 64, Grad norm: 5.598e+00\n",
      "Epoch 6553, Loss: 13.86959457397461, Neurons: 64, Grad norm: 5.376e+00\n",
      "Epoch 6553, Loss: 13.86959457397461, Neurons: 64, Grad norm: 5.376e+00\n",
      "Epoch 6554, Loss: 13.853791236877441, Neurons: 64, Grad norm: 5.036e+00\n",
      "Epoch 6554, Loss: 13.853791236877441, Neurons: 64, Grad norm: 5.036e+00\n",
      "Epoch 6555, Loss: 13.837563514709473, Neurons: 64, Grad norm: 4.651e+00\n",
      "Epoch 6555, Loss: 13.837563514709473, Neurons: 64, Grad norm: 4.651e+00\n",
      "Epoch 6556, Loss: 13.821016311645508, Neurons: 64, Grad norm: 4.292e+00\n",
      "Epoch 6556, Loss: 13.821016311645508, Neurons: 64, Grad norm: 4.292e+00\n",
      "Epoch 6557, Loss: 13.804250717163086, Neurons: 64, Grad norm: 4.030e+00\n",
      "Epoch 6557, Loss: 13.804250717163086, Neurons: 64, Grad norm: 4.030e+00\n",
      "Epoch 6558, Loss: 13.787342071533203, Neurons: 64, Grad norm: 3.902e+00\n",
      "Epoch 6558, Loss: 13.787342071533203, Neurons: 64, Grad norm: 3.902e+00\n",
      "Epoch 6559, Loss: 13.770328521728516, Neurons: 64, Grad norm: 3.919e+00\n",
      "Epoch 6559, Loss: 13.770328521728516, Neurons: 64, Grad norm: 3.919e+00\n",
      "Epoch 6560, Loss: 13.753190040588379, Neurons: 64, Grad norm: 4.053e+00\n",
      "Epoch 6560, Loss: 13.753190040588379, Neurons: 64, Grad norm: 4.053e+00\n",
      "Epoch 6561, Loss: 13.735881805419922, Neurons: 64, Grad norm: 4.248e+00\n",
      "Epoch 6561, Loss: 13.735881805419922, Neurons: 64, Grad norm: 4.248e+00\n",
      "Epoch 6562, Loss: 13.718326568603516, Neurons: 64, Grad norm: 4.441e+00\n",
      "Epoch 6562, Loss: 13.718326568603516, Neurons: 64, Grad norm: 4.441e+00\n",
      "Epoch 6563, Loss: 13.700444221496582, Neurons: 64, Grad norm: 4.582e+00\n",
      "Epoch 6563, Loss: 13.700444221496582, Neurons: 64, Grad norm: 4.582e+00\n",
      "Epoch 6564, Loss: 13.682170867919922, Neurons: 64, Grad norm: 4.644e+00\n",
      "Epoch 6564, Loss: 13.682170867919922, Neurons: 64, Grad norm: 4.644e+00\n",
      "Epoch 6565, Loss: 13.663456916809082, Neurons: 64, Grad norm: 4.632e+00\n",
      "Epoch 6565, Loss: 13.663456916809082, Neurons: 64, Grad norm: 4.632e+00\n",
      "Epoch 6566, Loss: 13.644277572631836, Neurons: 64, Grad norm: 4.574e+00\n",
      "Epoch 6566, Loss: 13.644277572631836, Neurons: 64, Grad norm: 4.574e+00\n",
      "Epoch 6567, Loss: 13.624637603759766, Neurons: 64, Grad norm: 4.510e+00\n",
      "Epoch 6567, Loss: 13.624637603759766, Neurons: 64, Grad norm: 4.510e+00\n",
      "Epoch 6568, Loss: 13.604547500610352, Neurons: 64, Grad norm: 4.476e+00\n",
      "Epoch 6568, Loss: 13.604547500610352, Neurons: 64, Grad norm: 4.476e+00\n",
      "Epoch 6569, Loss: 13.584020614624023, Neurons: 64, Grad norm: 4.488e+00\n",
      "Epoch 6569, Loss: 13.584020614624023, Neurons: 64, Grad norm: 4.488e+00\n",
      "Epoch 6570, Loss: 13.563039779663086, Neurons: 64, Grad norm: 4.549e+00\n",
      "Epoch 6570, Loss: 13.563039779663086, Neurons: 64, Grad norm: 4.549e+00\n",
      "Epoch 6571, Loss: 13.541571617126465, Neurons: 64, Grad norm: 4.647e+00\n",
      "Epoch 6571, Loss: 13.541571617126465, Neurons: 64, Grad norm: 4.647e+00\n",
      "Epoch 6572, Loss: 13.519575119018555, Neurons: 64, Grad norm: 4.779e+00\n",
      "Epoch 6572, Loss: 13.519575119018555, Neurons: 64, Grad norm: 4.779e+00\n",
      "Epoch 6573, Loss: 13.496987342834473, Neurons: 64, Grad norm: 4.937e+00\n",
      "Epoch 6573, Loss: 13.496987342834473, Neurons: 64, Grad norm: 4.937e+00\n",
      "Epoch 6574, Loss: 13.473719596862793, Neurons: 64, Grad norm: 5.111e+00\n",
      "Epoch 6574, Loss: 13.473719596862793, Neurons: 64, Grad norm: 5.111e+00\n",
      "Epoch 6575, Loss: 13.449684143066406, Neurons: 64, Grad norm: 5.270e+00\n",
      "Epoch 6575, Loss: 13.449684143066406, Neurons: 64, Grad norm: 5.270e+00\n",
      "Epoch 6576, Loss: 13.424799919128418, Neurons: 64, Grad norm: 5.433e+00\n",
      "Epoch 6576, Loss: 13.424799919128418, Neurons: 64, Grad norm: 5.433e+00\n",
      "Epoch 6577, Loss: 13.398981094360352, Neurons: 64, Grad norm: 5.610e+00\n",
      "Epoch 6577, Loss: 13.398981094360352, Neurons: 64, Grad norm: 5.610e+00\n",
      "Epoch 6578, Loss: 13.372159004211426, Neurons: 64, Grad norm: 5.812e+00\n",
      "Epoch 6578, Loss: 13.372159004211426, Neurons: 64, Grad norm: 5.812e+00\n",
      "Epoch 6579, Loss: 13.344260215759277, Neurons: 64, Grad norm: 6.054e+00\n",
      "Epoch 6579, Loss: 13.344260215759277, Neurons: 64, Grad norm: 6.054e+00\n",
      "Epoch 6580, Loss: 13.315197944641113, Neurons: 64, Grad norm: 6.345e+00\n",
      "Epoch 6580, Loss: 13.315197944641113, Neurons: 64, Grad norm: 6.345e+00\n",
      "Epoch 6581, Loss: 13.284870147705078, Neurons: 64, Grad norm: 6.694e+00\n",
      "Epoch 6581, Loss: 13.284870147705078, Neurons: 64, Grad norm: 6.694e+00\n",
      "Epoch 6582, Loss: 13.25316047668457, Neurons: 64, Grad norm: 7.091e+00\n",
      "Epoch 6582, Loss: 13.25316047668457, Neurons: 64, Grad norm: 7.091e+00\n",
      "Epoch 6583, Loss: 13.219922065734863, Neurons: 64, Grad norm: 7.536e+00\n",
      "Epoch 6583, Loss: 13.219922065734863, Neurons: 64, Grad norm: 7.536e+00\n",
      "Epoch 6584, Loss: 13.18498706817627, Neurons: 64, Grad norm: 8.022e+00\n",
      "Epoch 6584, Loss: 13.18498706817627, Neurons: 64, Grad norm: 8.022e+00\n",
      "Epoch 6585, Loss: 13.148160934448242, Neurons: 64, Grad norm: 8.564e+00\n",
      "Epoch 6585, Loss: 13.148160934448242, Neurons: 64, Grad norm: 8.564e+00\n",
      "Epoch 6586, Loss: 13.109240531921387, Neurons: 64, Grad norm: 9.126e+00\n",
      "Epoch 6586, Loss: 13.109240531921387, Neurons: 64, Grad norm: 9.126e+00\n",
      "Epoch 6587, Loss: 13.068004608154297, Neurons: 64, Grad norm: 9.726e+00\n",
      "Epoch 6587, Loss: 13.068004608154297, Neurons: 64, Grad norm: 9.726e+00\n",
      "Epoch 6588, Loss: 13.024203300476074, Neurons: 64, Grad norm: 1.037e+01\n",
      "Epoch 6588, Loss: 13.024203300476074, Neurons: 64, Grad norm: 1.037e+01\n",
      "Epoch 6589, Loss: 12.977583885192871, Neurons: 64, Grad norm: 1.107e+01\n",
      "Epoch 6589, Loss: 12.977583885192871, Neurons: 64, Grad norm: 1.107e+01\n",
      "Epoch 6590, Loss: 12.927861213684082, Neurons: 64, Grad norm: 1.181e+01\n",
      "Epoch 6590, Loss: 12.927861213684082, Neurons: 64, Grad norm: 1.181e+01\n",
      "Epoch 6591, Loss: 12.874736785888672, Neurons: 64, Grad norm: 1.262e+01\n",
      "Epoch 6591, Loss: 12.874736785888672, Neurons: 64, Grad norm: 1.262e+01\n",
      "Epoch 6592, Loss: 12.817879676818848, Neurons: 64, Grad norm: 1.350e+01\n",
      "Epoch 6592, Loss: 12.817879676818848, Neurons: 64, Grad norm: 1.350e+01\n",
      "Epoch 6593, Loss: 12.756941795349121, Neurons: 64, Grad norm: 1.445e+01\n",
      "Epoch 6593, Loss: 12.756941795349121, Neurons: 64, Grad norm: 1.445e+01\n",
      "Epoch 6594, Loss: 12.69156265258789, Neurons: 64, Grad norm: 1.545e+01\n",
      "Epoch 6594, Loss: 12.69156265258789, Neurons: 64, Grad norm: 1.545e+01\n",
      "Epoch 6595, Loss: 12.621363639831543, Neurons: 64, Grad norm: 1.649e+01\n",
      "Epoch 6595, Loss: 12.621363639831543, Neurons: 64, Grad norm: 1.649e+01\n",
      "Epoch 6596, Loss: 12.545979499816895, Neurons: 64, Grad norm: 1.755e+01\n",
      "Epoch 6596, Loss: 12.545979499816895, Neurons: 64, Grad norm: 1.755e+01\n",
      "Epoch 6597, Loss: 12.465057373046875, Neurons: 64, Grad norm: 1.863e+01\n",
      "Epoch 6597, Loss: 12.465057373046875, Neurons: 64, Grad norm: 1.863e+01\n",
      "Epoch 6598, Loss: 12.378286361694336, Neurons: 64, Grad norm: 1.970e+01\n",
      "Epoch 6598, Loss: 12.378286361694336, Neurons: 64, Grad norm: 1.970e+01\n",
      "Epoch 6599, Loss: 12.285399436950684, Neurons: 64, Grad norm: 2.074e+01\n",
      "Epoch 6599, Loss: 12.285399436950684, Neurons: 64, Grad norm: 2.074e+01\n",
      "Epoch 6599, Test loss: 11.41337776184082\n",
      "Epoch 6599, Test loss: 11.41337776184082\n",
      "Epoch 6600, Loss: 12.186222076416016, Neurons: 64, Grad norm: 2.170e+01\n",
      "Epoch 6600, Loss: 12.186222076416016, Neurons: 64, Grad norm: 2.170e+01\n",
      "Epoch 6601, Loss: 12.080683708190918, Neurons: 64, Grad norm: 2.256e+01\n",
      "Epoch 6601, Loss: 12.080683708190918, Neurons: 64, Grad norm: 2.256e+01\n",
      "Epoch 6602, Loss: 11.968865394592285, Neurons: 64, Grad norm: 2.326e+01\n",
      "Epoch 6602, Loss: 11.968865394592285, Neurons: 64, Grad norm: 2.326e+01\n",
      "Epoch 6603, Loss: 11.851017951965332, Neurons: 64, Grad norm: 2.378e+01\n",
      "Epoch 6603, Loss: 11.851017951965332, Neurons: 64, Grad norm: 2.378e+01\n",
      "Epoch 6604, Loss: 11.727629661560059, Neurons: 64, Grad norm: 2.406e+01\n",
      "Epoch 6604, Loss: 11.727629661560059, Neurons: 64, Grad norm: 2.406e+01\n",
      "Epoch 6605, Loss: 11.599455833435059, Neurons: 64, Grad norm: 2.406e+01\n",
      "Epoch 6605, Loss: 11.599455833435059, Neurons: 64, Grad norm: 2.406e+01\n",
      "Epoch 6606, Loss: 11.46757698059082, Neurons: 64, Grad norm: 2.374e+01\n",
      "Epoch 6606, Loss: 11.46757698059082, Neurons: 64, Grad norm: 2.374e+01\n",
      "Epoch 6607, Loss: 11.333443641662598, Neurons: 64, Grad norm: 2.308e+01\n",
      "Epoch 6607, Loss: 11.333443641662598, Neurons: 64, Grad norm: 2.308e+01\n",
      "Epoch 6608, Loss: 11.19890308380127, Neurons: 64, Grad norm: 2.209e+01\n",
      "Epoch 6608, Loss: 11.19890308380127, Neurons: 64, Grad norm: 2.209e+01\n",
      "Epoch 6609, Loss: 11.066181182861328, Neurons: 64, Grad norm: 2.078e+01\n",
      "Epoch 6609, Loss: 11.066181182861328, Neurons: 64, Grad norm: 2.078e+01\n",
      "Epoch 6610, Loss: 10.937849998474121, Neurons: 64, Grad norm: 1.921e+01\n",
      "Epoch 6610, Loss: 10.937849998474121, Neurons: 64, Grad norm: 1.921e+01\n",
      "Epoch 6611, Loss: 10.816631317138672, Neurons: 64, Grad norm: 1.746e+01\n",
      "Epoch 6611, Loss: 10.816631317138672, Neurons: 64, Grad norm: 1.746e+01\n",
      "Epoch 6612, Loss: 10.705121994018555, Neurons: 64, Grad norm: 1.563e+01\n",
      "Epoch 6612, Loss: 10.705121994018555, Neurons: 64, Grad norm: 1.563e+01\n",
      "Epoch 6613, Loss: 10.605381965637207, Neurons: 64, Grad norm: 1.381e+01\n",
      "Epoch 6613, Loss: 10.605381965637207, Neurons: 64, Grad norm: 1.381e+01\n",
      "Epoch 6614, Loss: 10.518535614013672, Neurons: 64, Grad norm: 1.211e+01\n",
      "Epoch 6614, Loss: 10.518535614013672, Neurons: 64, Grad norm: 1.211e+01\n",
      "Epoch 6615, Loss: 10.444562911987305, Neurons: 64, Grad norm: 1.063e+01\n",
      "Epoch 6615, Loss: 10.444562911987305, Neurons: 64, Grad norm: 1.063e+01\n",
      "Epoch 6616, Loss: 10.38240909576416, Neurons: 64, Grad norm: 9.434e+00\n",
      "Epoch 6616, Loss: 10.38240909576416, Neurons: 64, Grad norm: 9.434e+00\n",
      "Epoch 6617, Loss: 10.330342292785645, Neurons: 64, Grad norm: 8.539e+00\n",
      "Epoch 6617, Loss: 10.330342292785645, Neurons: 64, Grad norm: 8.539e+00\n",
      "Epoch 6618, Loss: 10.286389350891113, Neurons: 64, Grad norm: 7.933e+00\n",
      "Epoch 6618, Loss: 10.286389350891113, Neurons: 64, Grad norm: 7.933e+00\n",
      "Epoch 6619, Loss: 10.248662948608398, Neurons: 64, Grad norm: 7.589e+00\n",
      "Epoch 6619, Loss: 10.248662948608398, Neurons: 64, Grad norm: 7.589e+00\n",
      "Epoch 6620, Loss: 10.215577125549316, Neurons: 64, Grad norm: 7.465e+00\n",
      "Epoch 6620, Loss: 10.215577125549316, Neurons: 64, Grad norm: 7.465e+00\n",
      "Epoch 6621, Loss: 10.185858726501465, Neurons: 64, Grad norm: 7.461e+00\n",
      "Epoch 6621, Loss: 10.185858726501465, Neurons: 64, Grad norm: 7.461e+00\n",
      "Epoch 6622, Loss: 10.158553123474121, Neurons: 64, Grad norm: 7.458e+00\n",
      "Epoch 6622, Loss: 10.158553123474121, Neurons: 64, Grad norm: 7.458e+00\n",
      "Epoch 6623, Loss: 10.132932662963867, Neurons: 64, Grad norm: 7.362e+00\n",
      "Epoch 6623, Loss: 10.132932662963867, Neurons: 64, Grad norm: 7.362e+00\n",
      "Epoch 6624, Loss: 10.108500480651855, Neurons: 64, Grad norm: 7.151e+00\n",
      "Epoch 6624, Loss: 10.108500480651855, Neurons: 64, Grad norm: 7.151e+00\n",
      "Epoch 6625, Loss: 10.08493709564209, Neurons: 64, Grad norm: 6.871e+00\n",
      "Epoch 6625, Loss: 10.08493709564209, Neurons: 64, Grad norm: 6.871e+00\n",
      "Epoch 6626, Loss: 10.062064170837402, Neurons: 64, Grad norm: 6.586e+00\n",
      "Epoch 6626, Loss: 10.062064170837402, Neurons: 64, Grad norm: 6.586e+00\n",
      "Epoch 6627, Loss: 10.039811134338379, Neurons: 64, Grad norm: 6.340e+00\n",
      "Epoch 6627, Loss: 10.039811134338379, Neurons: 64, Grad norm: 6.340e+00\n",
      "Epoch 6628, Loss: 10.018155097961426, Neurons: 64, Grad norm: 6.135e+00\n",
      "Epoch 6628, Loss: 10.018155097961426, Neurons: 64, Grad norm: 6.135e+00\n",
      "Epoch 6629, Loss: 9.997084617614746, Neurons: 64, Grad norm: 5.953e+00\n",
      "Epoch 6629, Loss: 9.997084617614746, Neurons: 64, Grad norm: 5.953e+00\n",
      "Epoch 6630, Loss: 9.976584434509277, Neurons: 64, Grad norm: 5.774e+00\n",
      "Epoch 6630, Loss: 9.976584434509277, Neurons: 64, Grad norm: 5.774e+00\n",
      "Epoch 6631, Loss: 9.956621170043945, Neurons: 64, Grad norm: 5.580e+00\n",
      "Epoch 6631, Loss: 9.956621170043945, Neurons: 64, Grad norm: 5.580e+00\n",
      "Epoch 6632, Loss: 9.937164306640625, Neurons: 64, Grad norm: 5.357e+00\n",
      "Epoch 6632, Loss: 9.937164306640625, Neurons: 64, Grad norm: 5.357e+00\n",
      "Epoch 6633, Loss: 9.918164253234863, Neurons: 64, Grad norm: 5.101e+00\n",
      "Epoch 6633, Loss: 9.918164253234863, Neurons: 64, Grad norm: 5.101e+00\n",
      "Epoch 6634, Loss: 9.89958381652832, Neurons: 64, Grad norm: 4.822e+00\n",
      "Epoch 6634, Loss: 9.89958381652832, Neurons: 64, Grad norm: 4.822e+00\n",
      "Epoch 6635, Loss: 9.881377220153809, Neurons: 64, Grad norm: 4.544e+00\n",
      "Epoch 6635, Loss: 9.881377220153809, Neurons: 64, Grad norm: 4.544e+00\n",
      "Epoch 6636, Loss: 9.863517761230469, Neurons: 64, Grad norm: 4.296e+00\n",
      "Epoch 6636, Loss: 9.863517761230469, Neurons: 64, Grad norm: 4.296e+00\n",
      "Epoch 6637, Loss: 9.845964431762695, Neurons: 64, Grad norm: 4.092e+00\n",
      "Epoch 6637, Loss: 9.845964431762695, Neurons: 64, Grad norm: 4.092e+00\n",
      "Epoch 6638, Loss: 9.828697204589844, Neurons: 64, Grad norm: 3.938e+00\n",
      "Epoch 6638, Loss: 9.828697204589844, Neurons: 64, Grad norm: 3.938e+00\n",
      "Epoch 6639, Loss: 9.811681747436523, Neurons: 64, Grad norm: 3.829e+00\n",
      "Epoch 6639, Loss: 9.811681747436523, Neurons: 64, Grad norm: 3.829e+00\n",
      "Epoch 6640, Loss: 9.79488754272461, Neurons: 64, Grad norm: 3.753e+00\n",
      "Epoch 6640, Loss: 9.79488754272461, Neurons: 64, Grad norm: 3.753e+00\n",
      "Epoch 6641, Loss: 9.778279304504395, Neurons: 64, Grad norm: 3.699e+00\n",
      "Epoch 6641, Loss: 9.778279304504395, Neurons: 64, Grad norm: 3.699e+00\n",
      "Epoch 6642, Loss: 9.761824607849121, Neurons: 64, Grad norm: 3.660e+00\n",
      "Epoch 6642, Loss: 9.761824607849121, Neurons: 64, Grad norm: 3.660e+00\n",
      "Epoch 6643, Loss: 9.745491027832031, Neurons: 64, Grad norm: 3.633e+00\n",
      "Epoch 6643, Loss: 9.745491027832031, Neurons: 64, Grad norm: 3.633e+00\n",
      "Epoch 6644, Loss: 9.729256629943848, Neurons: 64, Grad norm: 3.617e+00\n",
      "Epoch 6644, Loss: 9.729256629943848, Neurons: 64, Grad norm: 3.617e+00\n",
      "Epoch 6645, Loss: 9.713089942932129, Neurons: 64, Grad norm: 3.613e+00\n",
      "Epoch 6645, Loss: 9.713089942932129, Neurons: 64, Grad norm: 3.613e+00\n",
      "Epoch 6646, Loss: 9.696978569030762, Neurons: 64, Grad norm: 3.611e+00\n",
      "Epoch 6646, Loss: 9.696978569030762, Neurons: 64, Grad norm: 3.611e+00\n",
      "Epoch 6647, Loss: 9.680887222290039, Neurons: 64, Grad norm: 3.607e+00\n",
      "Epoch 6647, Loss: 9.680887222290039, Neurons: 64, Grad norm: 3.607e+00\n",
      "Epoch 6648, Loss: 9.664794921875, Neurons: 64, Grad norm: 3.594e+00\n",
      "Epoch 6648, Loss: 9.664794921875, Neurons: 64, Grad norm: 3.594e+00\n",
      "Epoch 6649, Loss: 9.64867877960205, Neurons: 64, Grad norm: 3.575e+00\n",
      "Epoch 6649, Loss: 9.64867877960205, Neurons: 64, Grad norm: 3.575e+00\n",
      "Epoch 6650, Loss: 9.632525444030762, Neurons: 64, Grad norm: 3.548e+00\n",
      "Epoch 6650, Loss: 9.632525444030762, Neurons: 64, Grad norm: 3.548e+00\n",
      "Epoch 6651, Loss: 9.61631965637207, Neurons: 64, Grad norm: 3.515e+00\n",
      "Epoch 6651, Loss: 9.61631965637207, Neurons: 64, Grad norm: 3.515e+00\n",
      "Epoch 6652, Loss: 9.600054740905762, Neurons: 64, Grad norm: 3.471e+00\n",
      "Epoch 6652, Loss: 9.600054740905762, Neurons: 64, Grad norm: 3.471e+00\n",
      "Epoch 6653, Loss: 9.583736419677734, Neurons: 64, Grad norm: 3.421e+00\n",
      "Epoch 6653, Loss: 9.583736419677734, Neurons: 64, Grad norm: 3.421e+00\n",
      "Epoch 6654, Loss: 9.567368507385254, Neurons: 64, Grad norm: 3.371e+00\n",
      "Epoch 6654, Loss: 9.567368507385254, Neurons: 64, Grad norm: 3.371e+00\n",
      "Epoch 6655, Loss: 9.550969123840332, Neurons: 64, Grad norm: 3.322e+00\n",
      "Epoch 6655, Loss: 9.550969123840332, Neurons: 64, Grad norm: 3.322e+00\n",
      "Epoch 6656, Loss: 9.534544944763184, Neurons: 64, Grad norm: 3.278e+00\n",
      "Epoch 6656, Loss: 9.534544944763184, Neurons: 64, Grad norm: 3.278e+00\n",
      "Epoch 6657, Loss: 9.518112182617188, Neurons: 64, Grad norm: 3.238e+00\n",
      "Epoch 6657, Loss: 9.518112182617188, Neurons: 64, Grad norm: 3.238e+00\n",
      "Epoch 6658, Loss: 9.501680374145508, Neurons: 64, Grad norm: 3.203e+00\n",
      "Epoch 6658, Loss: 9.501680374145508, Neurons: 64, Grad norm: 3.203e+00\n",
      "Epoch 6659, Loss: 9.485246658325195, Neurons: 64, Grad norm: 3.172e+00\n",
      "Epoch 6659, Loss: 9.485246658325195, Neurons: 64, Grad norm: 3.172e+00\n",
      "Epoch 6660, Loss: 9.46882438659668, Neurons: 64, Grad norm: 3.145e+00\n",
      "Epoch 6660, Loss: 9.46882438659668, Neurons: 64, Grad norm: 3.145e+00\n",
      "Epoch 6661, Loss: 9.452421188354492, Neurons: 64, Grad norm: 3.117e+00\n",
      "Epoch 6661, Loss: 9.452421188354492, Neurons: 64, Grad norm: 3.117e+00\n",
      "Epoch 6662, Loss: 9.436029434204102, Neurons: 64, Grad norm: 3.089e+00\n",
      "Epoch 6662, Loss: 9.436029434204102, Neurons: 64, Grad norm: 3.089e+00\n",
      "Epoch 6663, Loss: 9.419656753540039, Neurons: 64, Grad norm: 3.063e+00\n",
      "Epoch 6663, Loss: 9.419656753540039, Neurons: 64, Grad norm: 3.063e+00\n",
      "Epoch 6664, Loss: 9.403301239013672, Neurons: 64, Grad norm: 3.040e+00\n",
      "Epoch 6664, Loss: 9.403301239013672, Neurons: 64, Grad norm: 3.040e+00\n",
      "Epoch 6665, Loss: 9.386962890625, Neurons: 64, Grad norm: 3.019e+00\n",
      "Epoch 6665, Loss: 9.386962890625, Neurons: 64, Grad norm: 3.019e+00\n",
      "Epoch 6666, Loss: 9.37063980102539, Neurons: 64, Grad norm: 3.005e+00\n",
      "Epoch 6666, Loss: 9.37063980102539, Neurons: 64, Grad norm: 3.005e+00\n",
      "Epoch 6667, Loss: 9.35433292388916, Neurons: 64, Grad norm: 2.994e+00\n",
      "Epoch 6667, Loss: 9.35433292388916, Neurons: 64, Grad norm: 2.994e+00\n",
      "Epoch 6668, Loss: 9.338043212890625, Neurons: 64, Grad norm: 2.991e+00\n",
      "Epoch 6668, Loss: 9.338043212890625, Neurons: 64, Grad norm: 2.991e+00\n",
      "Epoch 6669, Loss: 9.321769714355469, Neurons: 64, Grad norm: 2.989e+00\n",
      "Epoch 6669, Loss: 9.321769714355469, Neurons: 64, Grad norm: 2.989e+00\n",
      "Epoch 6670, Loss: 9.305496215820312, Neurons: 64, Grad norm: 2.987e+00\n",
      "Epoch 6670, Loss: 9.305496215820312, Neurons: 64, Grad norm: 2.987e+00\n",
      "Epoch 6671, Loss: 9.289203643798828, Neurons: 64, Grad norm: 2.981e+00\n",
      "Epoch 6671, Loss: 9.289203643798828, Neurons: 64, Grad norm: 2.981e+00\n",
      "Epoch 6672, Loss: 9.272889137268066, Neurons: 64, Grad norm: 2.971e+00\n",
      "Epoch 6672, Loss: 9.272889137268066, Neurons: 64, Grad norm: 2.971e+00\n",
      "Epoch 6673, Loss: 9.25655460357666, Neurons: 64, Grad norm: 2.963e+00\n",
      "Epoch 6673, Loss: 9.25655460357666, Neurons: 64, Grad norm: 2.963e+00\n",
      "Epoch 6674, Loss: 9.240201950073242, Neurons: 64, Grad norm: 2.958e+00\n",
      "Epoch 6674, Loss: 9.240201950073242, Neurons: 64, Grad norm: 2.958e+00\n",
      "Epoch 6675, Loss: 9.223830223083496, Neurons: 64, Grad norm: 2.956e+00\n",
      "Epoch 6675, Loss: 9.223830223083496, Neurons: 64, Grad norm: 2.956e+00\n",
      "Epoch 6676, Loss: 9.207444190979004, Neurons: 64, Grad norm: 2.952e+00\n",
      "Epoch 6676, Loss: 9.207444190979004, Neurons: 64, Grad norm: 2.952e+00\n",
      "Epoch 6677, Loss: 9.19102954864502, Neurons: 64, Grad norm: 2.949e+00\n",
      "Epoch 6677, Loss: 9.19102954864502, Neurons: 64, Grad norm: 2.949e+00\n",
      "Epoch 6678, Loss: 9.174582481384277, Neurons: 64, Grad norm: 2.947e+00\n",
      "Epoch 6678, Loss: 9.174582481384277, Neurons: 64, Grad norm: 2.947e+00\n",
      "Epoch 6679, Loss: 9.158096313476562, Neurons: 64, Grad norm: 2.941e+00\n",
      "Epoch 6679, Loss: 9.158096313476562, Neurons: 64, Grad norm: 2.941e+00\n",
      "Epoch 6680, Loss: 9.141571998596191, Neurons: 64, Grad norm: 2.936e+00\n",
      "Epoch 6680, Loss: 9.141571998596191, Neurons: 64, Grad norm: 2.936e+00\n",
      "Epoch 6681, Loss: 9.125004768371582, Neurons: 64, Grad norm: 2.931e+00\n",
      "Epoch 6681, Loss: 9.125004768371582, Neurons: 64, Grad norm: 2.931e+00\n",
      "Epoch 6682, Loss: 9.108394622802734, Neurons: 64, Grad norm: 2.925e+00\n",
      "Epoch 6682, Loss: 9.108394622802734, Neurons: 64, Grad norm: 2.925e+00\n",
      "Epoch 6683, Loss: 9.091734886169434, Neurons: 64, Grad norm: 2.920e+00\n",
      "Epoch 6683, Loss: 9.091734886169434, Neurons: 64, Grad norm: 2.920e+00\n",
      "Epoch 6684, Loss: 9.075031280517578, Neurons: 64, Grad norm: 2.917e+00\n",
      "Epoch 6684, Loss: 9.075031280517578, Neurons: 64, Grad norm: 2.917e+00\n",
      "Epoch 6685, Loss: 9.058269500732422, Neurons: 64, Grad norm: 2.913e+00\n",
      "Epoch 6685, Loss: 9.058269500732422, Neurons: 64, Grad norm: 2.913e+00\n",
      "Epoch 6686, Loss: 9.041454315185547, Neurons: 64, Grad norm: 2.910e+00\n",
      "Epoch 6686, Loss: 9.041454315185547, Neurons: 64, Grad norm: 2.910e+00\n",
      "Epoch 6687, Loss: 9.024582862854004, Neurons: 64, Grad norm: 2.911e+00\n",
      "Epoch 6687, Loss: 9.024582862854004, Neurons: 64, Grad norm: 2.911e+00\n",
      "Epoch 6688, Loss: 9.007650375366211, Neurons: 64, Grad norm: 2.911e+00\n",
      "Epoch 6688, Loss: 9.007650375366211, Neurons: 64, Grad norm: 2.911e+00\n",
      "Epoch 6689, Loss: 8.990657806396484, Neurons: 64, Grad norm: 2.913e+00\n",
      "Epoch 6689, Loss: 8.990657806396484, Neurons: 64, Grad norm: 2.913e+00\n",
      "Epoch 6690, Loss: 8.973596572875977, Neurons: 64, Grad norm: 2.919e+00\n",
      "Epoch 6690, Loss: 8.973596572875977, Neurons: 64, Grad norm: 2.919e+00\n",
      "Epoch 6691, Loss: 8.956462860107422, Neurons: 64, Grad norm: 2.928e+00\n",
      "Epoch 6691, Loss: 8.956462860107422, Neurons: 64, Grad norm: 2.928e+00\n",
      "Epoch 6692, Loss: 8.939252853393555, Neurons: 64, Grad norm: 2.937e+00\n",
      "Epoch 6692, Loss: 8.939252853393555, Neurons: 64, Grad norm: 2.937e+00\n",
      "Epoch 6693, Loss: 8.921957969665527, Neurons: 64, Grad norm: 2.937e+00\n",
      "Epoch 6693, Loss: 8.921957969665527, Neurons: 64, Grad norm: 2.937e+00\n",
      "Epoch 6694, Loss: 8.904580116271973, Neurons: 64, Grad norm: 2.943e+00\n",
      "Epoch 6694, Loss: 8.904580116271973, Neurons: 64, Grad norm: 2.943e+00\n",
      "Epoch 6695, Loss: 8.887113571166992, Neurons: 64, Grad norm: 2.955e+00\n",
      "Epoch 6695, Loss: 8.887113571166992, Neurons: 64, Grad norm: 2.955e+00\n",
      "Epoch 6696, Loss: 8.869551658630371, Neurons: 64, Grad norm: 2.968e+00\n",
      "Epoch 6696, Loss: 8.869551658630371, Neurons: 64, Grad norm: 2.968e+00\n",
      "Epoch 6697, Loss: 8.851883888244629, Neurons: 64, Grad norm: 2.982e+00\n",
      "Epoch 6697, Loss: 8.851883888244629, Neurons: 64, Grad norm: 2.982e+00\n",
      "Epoch 6698, Loss: 8.834105491638184, Neurons: 64, Grad norm: 2.994e+00\n",
      "Epoch 6698, Loss: 8.834105491638184, Neurons: 64, Grad norm: 2.994e+00\n",
      "Epoch 6699, Loss: 8.816205024719238, Neurons: 64, Grad norm: 3.005e+00\n",
      "Epoch 6699, Loss: 8.816205024719238, Neurons: 64, Grad norm: 3.005e+00\n",
      "Epoch 6699, Test loss: 8.173545837402344\n",
      "Epoch 6699, Test loss: 8.173545837402344\n",
      "Epoch 6700, Loss: 8.798173904418945, Neurons: 64, Grad norm: 3.018e+00\n",
      "Epoch 6700, Loss: 8.798173904418945, Neurons: 64, Grad norm: 3.018e+00\n",
      "Epoch 6701, Loss: 8.780010223388672, Neurons: 64, Grad norm: 3.032e+00\n",
      "Epoch 6701, Loss: 8.780010223388672, Neurons: 64, Grad norm: 3.032e+00\n",
      "Epoch 6702, Loss: 8.761701583862305, Neurons: 64, Grad norm: 3.053e+00\n",
      "Epoch 6702, Loss: 8.761701583862305, Neurons: 64, Grad norm: 3.053e+00\n",
      "Epoch 6703, Loss: 8.743237495422363, Neurons: 64, Grad norm: 3.067e+00\n",
      "Epoch 6703, Loss: 8.743237495422363, Neurons: 64, Grad norm: 3.067e+00\n",
      "Epoch 6704, Loss: 8.724610328674316, Neurons: 64, Grad norm: 3.095e+00\n",
      "Epoch 6704, Loss: 8.724610328674316, Neurons: 64, Grad norm: 3.095e+00\n",
      "Epoch 6705, Loss: 8.705801963806152, Neurons: 64, Grad norm: 3.113e+00\n",
      "Epoch 6705, Loss: 8.705801963806152, Neurons: 64, Grad norm: 3.113e+00\n",
      "Epoch 6706, Loss: 8.686806678771973, Neurons: 64, Grad norm: 3.135e+00\n",
      "Epoch 6706, Loss: 8.686806678771973, Neurons: 64, Grad norm: 3.135e+00\n",
      "Epoch 6707, Loss: 8.667603492736816, Neurons: 64, Grad norm: 3.147e+00\n",
      "Epoch 6707, Loss: 8.667603492736816, Neurons: 64, Grad norm: 3.147e+00\n",
      "Epoch 6708, Loss: 8.648185729980469, Neurons: 64, Grad norm: 3.177e+00\n",
      "Epoch 6708, Loss: 8.648185729980469, Neurons: 64, Grad norm: 3.177e+00\n",
      "Epoch 6709, Loss: 8.628532409667969, Neurons: 64, Grad norm: 3.211e+00\n",
      "Epoch 6709, Loss: 8.628532409667969, Neurons: 64, Grad norm: 3.211e+00\n",
      "Epoch 6710, Loss: 8.608627319335938, Neurons: 64, Grad norm: 3.248e+00\n",
      "Epoch 6710, Loss: 8.608627319335938, Neurons: 64, Grad norm: 3.248e+00\n",
      "Epoch 6711, Loss: 8.588451385498047, Neurons: 64, Grad norm: 3.292e+00\n",
      "Epoch 6711, Loss: 8.588451385498047, Neurons: 64, Grad norm: 3.292e+00\n",
      "Epoch 6712, Loss: 8.567983627319336, Neurons: 64, Grad norm: 3.334e+00\n",
      "Epoch 6712, Loss: 8.567983627319336, Neurons: 64, Grad norm: 3.334e+00\n",
      "Epoch 6713, Loss: 8.547205924987793, Neurons: 64, Grad norm: 3.388e+00\n",
      "Epoch 6713, Loss: 8.547205924987793, Neurons: 64, Grad norm: 3.388e+00\n",
      "Epoch 6714, Loss: 8.52608871459961, Neurons: 64, Grad norm: 3.450e+00\n",
      "Epoch 6714, Loss: 8.52608871459961, Neurons: 64, Grad norm: 3.450e+00\n",
      "Epoch 6715, Loss: 8.504606246948242, Neurons: 64, Grad norm: 3.514e+00\n",
      "Epoch 6715, Loss: 8.504606246948242, Neurons: 64, Grad norm: 3.514e+00\n",
      "Epoch 6716, Loss: 8.482732772827148, Neurons: 64, Grad norm: 3.590e+00\n",
      "Epoch 6716, Loss: 8.482732772827148, Neurons: 64, Grad norm: 3.590e+00\n",
      "Epoch 6717, Loss: 8.460433959960938, Neurons: 64, Grad norm: 3.669e+00\n",
      "Epoch 6717, Loss: 8.460433959960938, Neurons: 64, Grad norm: 3.669e+00\n",
      "Epoch 6718, Loss: 8.437676429748535, Neurons: 64, Grad norm: 3.760e+00\n",
      "Epoch 6718, Loss: 8.437676429748535, Neurons: 64, Grad norm: 3.760e+00\n",
      "Epoch 6719, Loss: 8.414420127868652, Neurons: 64, Grad norm: 3.859e+00\n",
      "Epoch 6719, Loss: 8.414420127868652, Neurons: 64, Grad norm: 3.859e+00\n",
      "Epoch 6720, Loss: 8.390630722045898, Neurons: 64, Grad norm: 3.969e+00\n",
      "Epoch 6720, Loss: 8.390630722045898, Neurons: 64, Grad norm: 3.969e+00\n",
      "Epoch 6721, Loss: 8.366259574890137, Neurons: 64, Grad norm: 4.083e+00\n",
      "Epoch 6721, Loss: 8.366259574890137, Neurons: 64, Grad norm: 4.083e+00\n",
      "Epoch 6722, Loss: 8.341259002685547, Neurons: 64, Grad norm: 4.199e+00\n",
      "Epoch 6722, Loss: 8.341259002685547, Neurons: 64, Grad norm: 4.199e+00\n",
      "Epoch 6723, Loss: 8.315577507019043, Neurons: 64, Grad norm: 4.331e+00\n",
      "Epoch 6723, Loss: 8.315577507019043, Neurons: 64, Grad norm: 4.331e+00\n",
      "Epoch 6724, Loss: 8.289161682128906, Neurons: 64, Grad norm: 4.458e+00\n",
      "Epoch 6724, Loss: 8.289161682128906, Neurons: 64, Grad norm: 4.458e+00\n",
      "Epoch 6725, Loss: 8.261945724487305, Neurons: 64, Grad norm: 4.613e+00\n",
      "Epoch 6725, Loss: 8.261945724487305, Neurons: 64, Grad norm: 4.613e+00\n",
      "Epoch 6726, Loss: 8.233869552612305, Neurons: 64, Grad norm: 4.775e+00\n",
      "Epoch 6726, Loss: 8.233869552612305, Neurons: 64, Grad norm: 4.775e+00\n",
      "Epoch 6727, Loss: 8.20486068725586, Neurons: 64, Grad norm: 4.955e+00\n",
      "Epoch 6727, Loss: 8.20486068725586, Neurons: 64, Grad norm: 4.955e+00\n",
      "Epoch 6728, Loss: 8.174846649169922, Neurons: 64, Grad norm: 5.140e+00\n",
      "Epoch 6728, Loss: 8.174846649169922, Neurons: 64, Grad norm: 5.140e+00\n",
      "Epoch 6729, Loss: 8.143754005432129, Neurons: 64, Grad norm: 5.342e+00\n",
      "Epoch 6729, Loss: 8.143754005432129, Neurons: 64, Grad norm: 5.342e+00\n",
      "Epoch 6730, Loss: 8.111494064331055, Neurons: 64, Grad norm: 5.551e+00\n",
      "Epoch 6730, Loss: 8.111494064331055, Neurons: 64, Grad norm: 5.551e+00\n",
      "Epoch 6731, Loss: 8.077991485595703, Neurons: 64, Grad norm: 5.769e+00\n",
      "Epoch 6731, Loss: 8.077991485595703, Neurons: 64, Grad norm: 5.769e+00\n",
      "Epoch 6732, Loss: 8.043159484863281, Neurons: 64, Grad norm: 5.996e+00\n",
      "Epoch 6732, Loss: 8.043159484863281, Neurons: 64, Grad norm: 5.996e+00\n",
      "Epoch 6733, Loss: 8.006915092468262, Neurons: 64, Grad norm: 6.228e+00\n",
      "Epoch 6733, Loss: 8.006915092468262, Neurons: 64, Grad norm: 6.228e+00\n",
      "Epoch 6734, Loss: 7.969178199768066, Neurons: 64, Grad norm: 6.464e+00\n",
      "Epoch 6734, Loss: 7.969178199768066, Neurons: 64, Grad norm: 6.464e+00\n",
      "Epoch 6735, Loss: 7.929874897003174, Neurons: 64, Grad norm: 6.700e+00\n",
      "Epoch 6735, Loss: 7.929874897003174, Neurons: 64, Grad norm: 6.700e+00\n",
      "Epoch 6736, Loss: 7.888942718505859, Neurons: 64, Grad norm: 6.932e+00\n",
      "Epoch 6736, Loss: 7.888942718505859, Neurons: 64, Grad norm: 6.932e+00\n",
      "Epoch 6737, Loss: 7.846324443817139, Neurons: 64, Grad norm: 7.155e+00\n",
      "Epoch 6737, Loss: 7.846324443817139, Neurons: 64, Grad norm: 7.155e+00\n",
      "Epoch 6738, Loss: 7.801995277404785, Neurons: 64, Grad norm: 7.362e+00\n",
      "Epoch 6738, Loss: 7.801995277404785, Neurons: 64, Grad norm: 7.362e+00\n",
      "Epoch 6739, Loss: 7.75593900680542, Neurons: 64, Grad norm: 7.557e+00\n",
      "Epoch 6739, Loss: 7.75593900680542, Neurons: 64, Grad norm: 7.557e+00\n",
      "Epoch 6740, Loss: 7.708179950714111, Neurons: 64, Grad norm: 7.722e+00\n",
      "Epoch 6740, Loss: 7.708179950714111, Neurons: 64, Grad norm: 7.722e+00\n",
      "Epoch 6741, Loss: 7.658779621124268, Neurons: 64, Grad norm: 7.858e+00\n",
      "Epoch 6741, Loss: 7.658779621124268, Neurons: 64, Grad norm: 7.858e+00\n",
      "Epoch 6742, Loss: 7.607841968536377, Neurons: 64, Grad norm: 7.959e+00\n",
      "Epoch 6742, Loss: 7.607841968536377, Neurons: 64, Grad norm: 7.959e+00\n",
      "Epoch 6743, Loss: 7.5555219650268555, Neurons: 64, Grad norm: 8.020e+00\n",
      "Epoch 6743, Loss: 7.5555219650268555, Neurons: 64, Grad norm: 8.020e+00\n",
      "Epoch 6744, Loss: 7.502037525177002, Neurons: 64, Grad norm: 8.040e+00\n",
      "Epoch 6744, Loss: 7.502037525177002, Neurons: 64, Grad norm: 8.040e+00\n",
      "Epoch 6745, Loss: 7.4476704597473145, Neurons: 64, Grad norm: 7.994e+00\n",
      "Epoch 6745, Loss: 7.4476704597473145, Neurons: 64, Grad norm: 7.994e+00\n",
      "Epoch 6746, Loss: 7.39276647567749, Neurons: 64, Grad norm: 7.887e+00\n",
      "Epoch 6746, Loss: 7.39276647567749, Neurons: 64, Grad norm: 7.887e+00\n",
      "Epoch 6747, Loss: 7.337754726409912, Neurons: 64, Grad norm: 7.724e+00\n",
      "Epoch 6747, Loss: 7.337754726409912, Neurons: 64, Grad norm: 7.724e+00\n",
      "Epoch 6748, Loss: 7.283121585845947, Neurons: 64, Grad norm: 7.501e+00\n",
      "Epoch 6748, Loss: 7.283121585845947, Neurons: 64, Grad norm: 7.501e+00\n",
      "Epoch 6749, Loss: 7.2294182777404785, Neurons: 64, Grad norm: 7.227e+00\n",
      "Epoch 6749, Loss: 7.2294182777404785, Neurons: 64, Grad norm: 7.227e+00\n",
      "Epoch 6750, Loss: 7.177222728729248, Neurons: 64, Grad norm: 6.905e+00\n",
      "Epoch 6750, Loss: 7.177222728729248, Neurons: 64, Grad norm: 6.905e+00\n",
      "Epoch 6751, Loss: 7.127127170562744, Neurons: 64, Grad norm: 6.537e+00\n",
      "Epoch 6751, Loss: 7.127127170562744, Neurons: 64, Grad norm: 6.537e+00\n",
      "Epoch 6752, Loss: 7.079676151275635, Neurons: 64, Grad norm: 6.145e+00\n",
      "Epoch 6752, Loss: 7.079676151275635, Neurons: 64, Grad norm: 6.145e+00\n",
      "Epoch 6753, Loss: 7.0353193283081055, Neurons: 64, Grad norm: 5.726e+00\n",
      "Epoch 6753, Loss: 7.0353193283081055, Neurons: 64, Grad norm: 5.726e+00\n",
      "Epoch 6754, Loss: 6.9943623542785645, Neurons: 64, Grad norm: 5.307e+00\n",
      "Epoch 6754, Loss: 6.9943623542785645, Neurons: 64, Grad norm: 5.307e+00\n",
      "Epoch 6755, Loss: 6.956934452056885, Neurons: 64, Grad norm: 4.905e+00\n",
      "Epoch 6755, Loss: 6.956934452056885, Neurons: 64, Grad norm: 4.905e+00\n",
      "Epoch 6756, Loss: 6.922979354858398, Neurons: 64, Grad norm: 4.539e+00\n",
      "Epoch 6756, Loss: 6.922979354858398, Neurons: 64, Grad norm: 4.539e+00\n",
      "Epoch 6757, Loss: 6.8923020362854, Neurons: 64, Grad norm: 4.217e+00\n",
      "Epoch 6757, Loss: 6.8923020362854, Neurons: 64, Grad norm: 4.217e+00\n",
      "Epoch 6758, Loss: 6.864602088928223, Neurons: 64, Grad norm: 3.943e+00\n",
      "Epoch 6758, Loss: 6.864602088928223, Neurons: 64, Grad norm: 3.943e+00\n",
      "Epoch 6759, Loss: 6.839521884918213, Neurons: 64, Grad norm: 3.714e+00\n",
      "Epoch 6759, Loss: 6.839521884918213, Neurons: 64, Grad norm: 3.714e+00\n",
      "Epoch 6760, Loss: 6.816701412200928, Neurons: 64, Grad norm: 3.523e+00\n",
      "Epoch 6760, Loss: 6.816701412200928, Neurons: 64, Grad norm: 3.523e+00\n",
      "Epoch 6761, Loss: 6.795804023742676, Neurons: 64, Grad norm: 3.371e+00\n",
      "Epoch 6761, Loss: 6.795804023742676, Neurons: 64, Grad norm: 3.371e+00\n",
      "Epoch 6762, Loss: 6.776516914367676, Neurons: 64, Grad norm: 3.247e+00\n",
      "Epoch 6762, Loss: 6.776516914367676, Neurons: 64, Grad norm: 3.247e+00\n",
      "Epoch 6763, Loss: 6.75856876373291, Neurons: 64, Grad norm: 3.154e+00\n",
      "Epoch 6763, Loss: 6.75856876373291, Neurons: 64, Grad norm: 3.154e+00\n",
      "Epoch 6764, Loss: 6.741718292236328, Neurons: 64, Grad norm: 3.086e+00\n",
      "Epoch 6764, Loss: 6.741718292236328, Neurons: 64, Grad norm: 3.086e+00\n",
      "Epoch 6765, Loss: 6.725757598876953, Neurons: 64, Grad norm: 3.038e+00\n",
      "Epoch 6765, Loss: 6.725757598876953, Neurons: 64, Grad norm: 3.038e+00\n",
      "Epoch 6766, Loss: 6.7105021476745605, Neurons: 64, Grad norm: 3.004e+00\n",
      "Epoch 6766, Loss: 6.7105021476745605, Neurons: 64, Grad norm: 3.004e+00\n",
      "Epoch 6767, Loss: 6.695791721343994, Neurons: 64, Grad norm: 2.963e+00\n",
      "Epoch 6767, Loss: 6.695791721343994, Neurons: 64, Grad norm: 2.963e+00\n",
      "Epoch 6768, Loss: 6.68148946762085, Neurons: 64, Grad norm: 2.931e+00\n",
      "Epoch 6768, Loss: 6.68148946762085, Neurons: 64, Grad norm: 2.931e+00\n",
      "Epoch 6769, Loss: 6.667484760284424, Neurons: 64, Grad norm: 2.891e+00\n",
      "Epoch 6769, Loss: 6.667484760284424, Neurons: 64, Grad norm: 2.891e+00\n",
      "Epoch 6770, Loss: 6.653681755065918, Neurons: 64, Grad norm: 2.856e+00\n",
      "Epoch 6770, Loss: 6.653681755065918, Neurons: 64, Grad norm: 2.856e+00\n",
      "Epoch 6771, Loss: 6.640013217926025, Neurons: 64, Grad norm: 2.825e+00\n",
      "Epoch 6771, Loss: 6.640013217926025, Neurons: 64, Grad norm: 2.825e+00\n",
      "Epoch 6772, Loss: 6.6264262199401855, Neurons: 64, Grad norm: 2.802e+00\n",
      "Epoch 6772, Loss: 6.6264262199401855, Neurons: 64, Grad norm: 2.802e+00\n",
      "Epoch 6773, Loss: 6.612879753112793, Neurons: 64, Grad norm: 2.781e+00\n",
      "Epoch 6773, Loss: 6.612879753112793, Neurons: 64, Grad norm: 2.781e+00\n",
      "Epoch 6774, Loss: 6.5993452072143555, Neurons: 64, Grad norm: 2.759e+00\n",
      "Epoch 6774, Loss: 6.5993452072143555, Neurons: 64, Grad norm: 2.759e+00\n",
      "Epoch 6775, Loss: 6.585801124572754, Neurons: 64, Grad norm: 2.732e+00\n",
      "Epoch 6775, Loss: 6.585801124572754, Neurons: 64, Grad norm: 2.732e+00\n",
      "Epoch 6776, Loss: 6.572233200073242, Neurons: 64, Grad norm: 2.698e+00\n",
      "Epoch 6776, Loss: 6.572233200073242, Neurons: 64, Grad norm: 2.698e+00\n",
      "Epoch 6777, Loss: 6.558635711669922, Neurons: 64, Grad norm: 2.660e+00\n",
      "Epoch 6777, Loss: 6.558635711669922, Neurons: 64, Grad norm: 2.660e+00\n",
      "Epoch 6778, Loss: 6.545007228851318, Neurons: 64, Grad norm: 2.623e+00\n",
      "Epoch 6778, Loss: 6.545007228851318, Neurons: 64, Grad norm: 2.623e+00\n",
      "Epoch 6779, Loss: 6.531348705291748, Neurons: 64, Grad norm: 2.586e+00\n",
      "Epoch 6779, Loss: 6.531348705291748, Neurons: 64, Grad norm: 2.586e+00\n",
      "Epoch 6780, Loss: 6.517664432525635, Neurons: 64, Grad norm: 2.552e+00\n",
      "Epoch 6780, Loss: 6.517664432525635, Neurons: 64, Grad norm: 2.552e+00\n",
      "Epoch 6781, Loss: 6.503967761993408, Neurons: 64, Grad norm: 2.524e+00\n",
      "Epoch 6781, Loss: 6.503967761993408, Neurons: 64, Grad norm: 2.524e+00\n",
      "Epoch 6782, Loss: 6.490262985229492, Neurons: 64, Grad norm: 2.503e+00\n",
      "Epoch 6782, Loss: 6.490262985229492, Neurons: 64, Grad norm: 2.503e+00\n",
      "Epoch 6783, Loss: 6.476564884185791, Neurons: 64, Grad norm: 2.486e+00\n",
      "Epoch 6783, Loss: 6.476564884185791, Neurons: 64, Grad norm: 2.486e+00\n",
      "Epoch 6784, Loss: 6.462876796722412, Neurons: 64, Grad norm: 2.477e+00\n",
      "Epoch 6784, Loss: 6.462876796722412, Neurons: 64, Grad norm: 2.477e+00\n",
      "Epoch 6785, Loss: 6.449213027954102, Neurons: 64, Grad norm: 2.463e+00\n",
      "Epoch 6785, Loss: 6.449213027954102, Neurons: 64, Grad norm: 2.463e+00\n",
      "Epoch 6786, Loss: 6.435577869415283, Neurons: 64, Grad norm: 2.454e+00\n",
      "Epoch 6786, Loss: 6.435577869415283, Neurons: 64, Grad norm: 2.454e+00\n",
      "Epoch 6787, Loss: 6.4219770431518555, Neurons: 64, Grad norm: 2.443e+00\n",
      "Epoch 6787, Loss: 6.4219770431518555, Neurons: 64, Grad norm: 2.443e+00\n",
      "Epoch 6788, Loss: 6.408416271209717, Neurons: 64, Grad norm: 2.427e+00\n",
      "Epoch 6788, Loss: 6.408416271209717, Neurons: 64, Grad norm: 2.427e+00\n",
      "Epoch 6789, Loss: 6.394893646240234, Neurons: 64, Grad norm: 2.418e+00\n",
      "Epoch 6789, Loss: 6.394893646240234, Neurons: 64, Grad norm: 2.418e+00\n",
      "Epoch 6790, Loss: 6.381414413452148, Neurons: 64, Grad norm: 2.407e+00\n",
      "Epoch 6790, Loss: 6.381414413452148, Neurons: 64, Grad norm: 2.407e+00\n",
      "Epoch 6791, Loss: 6.367978096008301, Neurons: 64, Grad norm: 2.398e+00\n",
      "Epoch 6791, Loss: 6.367978096008301, Neurons: 64, Grad norm: 2.398e+00\n",
      "Epoch 6792, Loss: 6.354581356048584, Neurons: 64, Grad norm: 2.387e+00\n",
      "Epoch 6792, Loss: 6.354581356048584, Neurons: 64, Grad norm: 2.387e+00\n",
      "Epoch 6793, Loss: 6.3412251472473145, Neurons: 64, Grad norm: 2.377e+00\n",
      "Epoch 6793, Loss: 6.3412251472473145, Neurons: 64, Grad norm: 2.377e+00\n",
      "Epoch 6794, Loss: 6.327906608581543, Neurons: 64, Grad norm: 2.367e+00\n",
      "Epoch 6794, Loss: 6.327906608581543, Neurons: 64, Grad norm: 2.367e+00\n",
      "Epoch 6795, Loss: 6.314622402191162, Neurons: 64, Grad norm: 2.358e+00\n",
      "Epoch 6795, Loss: 6.314622402191162, Neurons: 64, Grad norm: 2.358e+00\n",
      "Epoch 6796, Loss: 6.301384925842285, Neurons: 64, Grad norm: 2.352e+00\n",
      "Epoch 6796, Loss: 6.301384925842285, Neurons: 64, Grad norm: 2.352e+00\n",
      "Epoch 6797, Loss: 6.288186550140381, Neurons: 64, Grad norm: 2.348e+00\n",
      "Epoch 6797, Loss: 6.288186550140381, Neurons: 64, Grad norm: 2.348e+00\n",
      "Epoch 6798, Loss: 6.2750163078308105, Neurons: 64, Grad norm: 2.344e+00\n",
      "Epoch 6798, Loss: 6.2750163078308105, Neurons: 64, Grad norm: 2.344e+00\n",
      "Epoch 6799, Loss: 6.261867523193359, Neurons: 64, Grad norm: 2.339e+00\n",
      "Epoch 6799, Loss: 6.261867523193359, Neurons: 64, Grad norm: 2.339e+00\n",
      "Epoch 6799, Test loss: 5.6927690505981445\n",
      "Epoch 6799, Test loss: 5.6927690505981445\n",
      "Epoch 6800, Loss: 6.248740196228027, Neurons: 64, Grad norm: 2.336e+00\n",
      "Epoch 6800, Loss: 6.248740196228027, Neurons: 64, Grad norm: 2.336e+00\n",
      "Epoch 6801, Loss: 6.23563814163208, Neurons: 64, Grad norm: 2.332e+00\n",
      "Epoch 6801, Loss: 6.23563814163208, Neurons: 64, Grad norm: 2.332e+00\n",
      "Epoch 6802, Loss: 6.222558975219727, Neurons: 64, Grad norm: 2.330e+00\n",
      "Epoch 6802, Loss: 6.222558975219727, Neurons: 64, Grad norm: 2.330e+00\n",
      "Epoch 6803, Loss: 6.209511756896973, Neurons: 64, Grad norm: 2.329e+00\n",
      "Epoch 6803, Loss: 6.209511756896973, Neurons: 64, Grad norm: 2.329e+00\n",
      "Epoch 6804, Loss: 6.196493625640869, Neurons: 64, Grad norm: 2.328e+00\n",
      "Epoch 6804, Loss: 6.196493625640869, Neurons: 64, Grad norm: 2.328e+00\n",
      "Epoch 6805, Loss: 6.183503150939941, Neurons: 64, Grad norm: 2.325e+00\n",
      "Epoch 6805, Loss: 6.183503150939941, Neurons: 64, Grad norm: 2.325e+00\n",
      "Epoch 6806, Loss: 6.170536041259766, Neurons: 64, Grad norm: 2.323e+00\n",
      "Epoch 6806, Loss: 6.170536041259766, Neurons: 64, Grad norm: 2.323e+00\n",
      "Epoch 6807, Loss: 6.157589912414551, Neurons: 64, Grad norm: 2.321e+00\n",
      "Epoch 6807, Loss: 6.157589912414551, Neurons: 64, Grad norm: 2.321e+00\n",
      "Epoch 6808, Loss: 6.14466667175293, Neurons: 64, Grad norm: 2.319e+00\n",
      "Epoch 6808, Loss: 6.14466667175293, Neurons: 64, Grad norm: 2.319e+00\n",
      "Epoch 6809, Loss: 6.131763935089111, Neurons: 64, Grad norm: 2.315e+00\n",
      "Epoch 6809, Loss: 6.131763935089111, Neurons: 64, Grad norm: 2.315e+00\n",
      "Epoch 6810, Loss: 6.11888313293457, Neurons: 64, Grad norm: 2.310e+00\n",
      "Epoch 6810, Loss: 6.11888313293457, Neurons: 64, Grad norm: 2.310e+00\n",
      "Epoch 6811, Loss: 6.106020927429199, Neurons: 64, Grad norm: 2.304e+00\n",
      "Epoch 6811, Loss: 6.106020927429199, Neurons: 64, Grad norm: 2.304e+00\n",
      "Epoch 6812, Loss: 6.093178749084473, Neurons: 64, Grad norm: 2.299e+00\n",
      "Epoch 6812, Loss: 6.093178749084473, Neurons: 64, Grad norm: 2.299e+00\n",
      "Epoch 6813, Loss: 6.080356597900391, Neurons: 64, Grad norm: 2.294e+00\n",
      "Epoch 6813, Loss: 6.080356597900391, Neurons: 64, Grad norm: 2.294e+00\n",
      "Epoch 6814, Loss: 6.067558765411377, Neurons: 64, Grad norm: 2.291e+00\n",
      "Epoch 6814, Loss: 6.067558765411377, Neurons: 64, Grad norm: 2.291e+00\n",
      "Epoch 6815, Loss: 6.054778575897217, Neurons: 64, Grad norm: 2.289e+00\n",
      "Epoch 6815, Loss: 6.054778575897217, Neurons: 64, Grad norm: 2.289e+00\n",
      "Epoch 6816, Loss: 6.042017936706543, Neurons: 64, Grad norm: 2.287e+00\n",
      "Epoch 6816, Loss: 6.042017936706543, Neurons: 64, Grad norm: 2.287e+00\n",
      "Epoch 6817, Loss: 6.02927303314209, Neurons: 64, Grad norm: 2.285e+00\n",
      "Epoch 6817, Loss: 6.02927303314209, Neurons: 64, Grad norm: 2.285e+00\n",
      "Epoch 6818, Loss: 6.016547203063965, Neurons: 64, Grad norm: 2.284e+00\n",
      "Epoch 6818, Loss: 6.016547203063965, Neurons: 64, Grad norm: 2.284e+00\n",
      "Epoch 6819, Loss: 6.003839015960693, Neurons: 64, Grad norm: 2.279e+00\n",
      "Epoch 6819, Loss: 6.003839015960693, Neurons: 64, Grad norm: 2.279e+00\n",
      "Epoch 6820, Loss: 5.991150856018066, Neurons: 64, Grad norm: 2.278e+00\n",
      "Epoch 6820, Loss: 5.991150856018066, Neurons: 64, Grad norm: 2.278e+00\n",
      "Epoch 6821, Loss: 5.978480815887451, Neurons: 64, Grad norm: 2.275e+00\n",
      "Epoch 6821, Loss: 5.978480815887451, Neurons: 64, Grad norm: 2.275e+00\n",
      "Epoch 6822, Loss: 5.965830326080322, Neurons: 64, Grad norm: 2.272e+00\n",
      "Epoch 6822, Loss: 5.965830326080322, Neurons: 64, Grad norm: 2.272e+00\n",
      "Epoch 6823, Loss: 5.9531989097595215, Neurons: 64, Grad norm: 2.272e+00\n",
      "Epoch 6823, Loss: 5.9531989097595215, Neurons: 64, Grad norm: 2.272e+00\n",
      "Epoch 6824, Loss: 5.940583229064941, Neurons: 64, Grad norm: 2.274e+00\n",
      "Epoch 6824, Loss: 5.940583229064941, Neurons: 64, Grad norm: 2.274e+00\n",
      "Epoch 6825, Loss: 5.9279866218566895, Neurons: 64, Grad norm: 2.269e+00\n",
      "Epoch 6825, Loss: 5.9279866218566895, Neurons: 64, Grad norm: 2.269e+00\n",
      "Epoch 6826, Loss: 5.915405750274658, Neurons: 64, Grad norm: 2.266e+00\n",
      "Epoch 6826, Loss: 5.915405750274658, Neurons: 64, Grad norm: 2.266e+00\n",
      "Epoch 6827, Loss: 5.902844429016113, Neurons: 64, Grad norm: 2.261e+00\n",
      "Epoch 6827, Loss: 5.902844429016113, Neurons: 64, Grad norm: 2.261e+00\n",
      "Epoch 6828, Loss: 5.89030122756958, Neurons: 64, Grad norm: 2.257e+00\n",
      "Epoch 6828, Loss: 5.89030122756958, Neurons: 64, Grad norm: 2.257e+00\n",
      "Epoch 6829, Loss: 5.877776145935059, Neurons: 64, Grad norm: 2.254e+00\n",
      "Epoch 6829, Loss: 5.877776145935059, Neurons: 64, Grad norm: 2.254e+00\n",
      "Epoch 6830, Loss: 5.865268707275391, Neurons: 64, Grad norm: 2.247e+00\n",
      "Epoch 6830, Loss: 5.865268707275391, Neurons: 64, Grad norm: 2.247e+00\n",
      "Epoch 6831, Loss: 5.852777004241943, Neurons: 64, Grad norm: 2.244e+00\n",
      "Epoch 6831, Loss: 5.852777004241943, Neurons: 64, Grad norm: 2.244e+00\n",
      "Epoch 6832, Loss: 5.840303897857666, Neurons: 64, Grad norm: 2.241e+00\n",
      "Epoch 6832, Loss: 5.840303897857666, Neurons: 64, Grad norm: 2.241e+00\n",
      "Epoch 6833, Loss: 5.827847003936768, Neurons: 64, Grad norm: 2.231e+00\n",
      "Epoch 6833, Loss: 5.827847003936768, Neurons: 64, Grad norm: 2.231e+00\n",
      "Epoch 6834, Loss: 5.815410614013672, Neurons: 64, Grad norm: 2.228e+00\n",
      "Epoch 6834, Loss: 5.815410614013672, Neurons: 64, Grad norm: 2.228e+00\n",
      "Epoch 6835, Loss: 5.802988529205322, Neurons: 64, Grad norm: 2.224e+00\n",
      "Epoch 6835, Loss: 5.802988529205322, Neurons: 64, Grad norm: 2.224e+00\n",
      "Epoch 6836, Loss: 5.790585517883301, Neurons: 64, Grad norm: 2.225e+00\n",
      "Epoch 6836, Loss: 5.790585517883301, Neurons: 64, Grad norm: 2.225e+00\n",
      "Epoch 6837, Loss: 5.778201580047607, Neurons: 64, Grad norm: 2.223e+00\n",
      "Epoch 6837, Loss: 5.778201580047607, Neurons: 64, Grad norm: 2.223e+00\n",
      "Epoch 6838, Loss: 5.76583194732666, Neurons: 64, Grad norm: 2.218e+00\n",
      "Epoch 6838, Loss: 5.76583194732666, Neurons: 64, Grad norm: 2.218e+00\n",
      "Epoch 6839, Loss: 5.753479957580566, Neurons: 64, Grad norm: 2.215e+00\n",
      "Epoch 6839, Loss: 5.753479957580566, Neurons: 64, Grad norm: 2.215e+00\n",
      "Epoch 6840, Loss: 5.741147041320801, Neurons: 64, Grad norm: 2.211e+00\n",
      "Epoch 6840, Loss: 5.741147041320801, Neurons: 64, Grad norm: 2.211e+00\n",
      "Epoch 6841, Loss: 5.728830337524414, Neurons: 64, Grad norm: 2.204e+00\n",
      "Epoch 6841, Loss: 5.728830337524414, Neurons: 64, Grad norm: 2.204e+00\n",
      "Epoch 6842, Loss: 5.7165327072143555, Neurons: 64, Grad norm: 2.202e+00\n",
      "Epoch 6842, Loss: 5.7165327072143555, Neurons: 64, Grad norm: 2.202e+00\n",
      "Epoch 6843, Loss: 5.704249382019043, Neurons: 64, Grad norm: 2.202e+00\n",
      "Epoch 6843, Loss: 5.704249382019043, Neurons: 64, Grad norm: 2.202e+00\n",
      "Epoch 6844, Loss: 5.691985607147217, Neurons: 64, Grad norm: 2.200e+00\n",
      "Epoch 6844, Loss: 5.691985607147217, Neurons: 64, Grad norm: 2.200e+00\n",
      "Epoch 6845, Loss: 5.679740905761719, Neurons: 64, Grad norm: 2.192e+00\n",
      "Epoch 6845, Loss: 5.679740905761719, Neurons: 64, Grad norm: 2.192e+00\n",
      "Epoch 6846, Loss: 5.667511940002441, Neurons: 64, Grad norm: 2.192e+00\n",
      "Epoch 6846, Loss: 5.667511940002441, Neurons: 64, Grad norm: 2.192e+00\n",
      "Epoch 6847, Loss: 5.655300140380859, Neurons: 64, Grad norm: 2.189e+00\n",
      "Epoch 6847, Loss: 5.655300140380859, Neurons: 64, Grad norm: 2.189e+00\n",
      "Epoch 6848, Loss: 5.6431097984313965, Neurons: 64, Grad norm: 2.182e+00\n",
      "Epoch 6848, Loss: 5.6431097984313965, Neurons: 64, Grad norm: 2.182e+00\n",
      "Epoch 6849, Loss: 5.63093376159668, Neurons: 64, Grad norm: 2.180e+00\n",
      "Epoch 6849, Loss: 5.63093376159668, Neurons: 64, Grad norm: 2.180e+00\n",
      "Epoch 6850, Loss: 5.618776798248291, Neurons: 64, Grad norm: 2.181e+00\n",
      "Epoch 6850, Loss: 5.618776798248291, Neurons: 64, Grad norm: 2.181e+00\n",
      "Epoch 6851, Loss: 5.606637001037598, Neurons: 64, Grad norm: 2.177e+00\n",
      "Epoch 6851, Loss: 5.606637001037598, Neurons: 64, Grad norm: 2.177e+00\n",
      "Epoch 6852, Loss: 5.594515800476074, Neurons: 64, Grad norm: 2.175e+00\n",
      "Epoch 6852, Loss: 5.594515800476074, Neurons: 64, Grad norm: 2.175e+00\n",
      "Epoch 6853, Loss: 5.582411289215088, Neurons: 64, Grad norm: 2.166e+00\n",
      "Epoch 6853, Loss: 5.582411289215088, Neurons: 64, Grad norm: 2.166e+00\n",
      "Epoch 6854, Loss: 5.570324897766113, Neurons: 64, Grad norm: 2.166e+00\n",
      "Epoch 6854, Loss: 5.570324897766113, Neurons: 64, Grad norm: 2.166e+00\n",
      "Epoch 6855, Loss: 5.558257102966309, Neurons: 64, Grad norm: 2.161e+00\n",
      "Epoch 6855, Loss: 5.558257102966309, Neurons: 64, Grad norm: 2.161e+00\n",
      "Epoch 6856, Loss: 5.546208381652832, Neurons: 64, Grad norm: 2.162e+00\n",
      "Epoch 6856, Loss: 5.546208381652832, Neurons: 64, Grad norm: 2.162e+00\n",
      "Epoch 6857, Loss: 5.534175872802734, Neurons: 64, Grad norm: 2.160e+00\n",
      "Epoch 6857, Loss: 5.534175872802734, Neurons: 64, Grad norm: 2.160e+00\n",
      "Epoch 6858, Loss: 5.522161483764648, Neurons: 64, Grad norm: 2.152e+00\n",
      "Epoch 6858, Loss: 5.522161483764648, Neurons: 64, Grad norm: 2.152e+00\n",
      "Epoch 6859, Loss: 5.510164260864258, Neurons: 64, Grad norm: 2.149e+00\n",
      "Epoch 6859, Loss: 5.510164260864258, Neurons: 64, Grad norm: 2.149e+00\n",
      "Epoch 6860, Loss: 5.498185634613037, Neurons: 64, Grad norm: 2.151e+00\n",
      "Epoch 6860, Loss: 5.498185634613037, Neurons: 64, Grad norm: 2.151e+00\n",
      "Epoch 6861, Loss: 5.486227035522461, Neurons: 64, Grad norm: 2.146e+00\n",
      "Epoch 6861, Loss: 5.486227035522461, Neurons: 64, Grad norm: 2.146e+00\n",
      "Epoch 6862, Loss: 5.474284648895264, Neurons: 64, Grad norm: 2.137e+00\n",
      "Epoch 6862, Loss: 5.474284648895264, Neurons: 64, Grad norm: 2.137e+00\n",
      "Epoch 6863, Loss: 5.462360382080078, Neurons: 64, Grad norm: 2.134e+00\n",
      "Epoch 6863, Loss: 5.462360382080078, Neurons: 64, Grad norm: 2.134e+00\n",
      "Epoch 6864, Loss: 5.450454235076904, Neurons: 64, Grad norm: 2.135e+00\n",
      "Epoch 6864, Loss: 5.450454235076904, Neurons: 64, Grad norm: 2.135e+00\n",
      "Epoch 6865, Loss: 5.438567638397217, Neurons: 64, Grad norm: 2.131e+00\n",
      "Epoch 6865, Loss: 5.438567638397217, Neurons: 64, Grad norm: 2.131e+00\n",
      "Epoch 6866, Loss: 5.42669677734375, Neurons: 64, Grad norm: 2.128e+00\n",
      "Epoch 6866, Loss: 5.42669677734375, Neurons: 64, Grad norm: 2.128e+00\n",
      "Epoch 6867, Loss: 5.414844036102295, Neurons: 64, Grad norm: 2.125e+00\n",
      "Epoch 6867, Loss: 5.414844036102295, Neurons: 64, Grad norm: 2.125e+00\n",
      "Epoch 6868, Loss: 5.403011798858643, Neurons: 64, Grad norm: 2.118e+00\n",
      "Epoch 6868, Loss: 5.403011798858643, Neurons: 64, Grad norm: 2.118e+00\n",
      "Epoch 6869, Loss: 5.391195774078369, Neurons: 64, Grad norm: 2.115e+00\n",
      "Epoch 6869, Loss: 5.391195774078369, Neurons: 64, Grad norm: 2.115e+00\n",
      "Epoch 6870, Loss: 5.37939977645874, Neurons: 64, Grad norm: 2.112e+00\n",
      "Epoch 6870, Loss: 5.37939977645874, Neurons: 64, Grad norm: 2.112e+00\n",
      "Epoch 6871, Loss: 5.367620468139648, Neurons: 64, Grad norm: 2.115e+00\n",
      "Epoch 6871, Loss: 5.367620468139648, Neurons: 64, Grad norm: 2.115e+00\n",
      "Epoch 6872, Loss: 5.355860710144043, Neurons: 64, Grad norm: 2.112e+00\n",
      "Epoch 6872, Loss: 5.355860710144043, Neurons: 64, Grad norm: 2.112e+00\n",
      "Epoch 6873, Loss: 5.344118118286133, Neurons: 64, Grad norm: 2.107e+00\n",
      "Epoch 6873, Loss: 5.344118118286133, Neurons: 64, Grad norm: 2.107e+00\n",
      "Epoch 6874, Loss: 5.332393646240234, Neurons: 64, Grad norm: 2.100e+00\n",
      "Epoch 6874, Loss: 5.332393646240234, Neurons: 64, Grad norm: 2.100e+00\n",
      "Epoch 6875, Loss: 5.320688724517822, Neurons: 64, Grad norm: 2.097e+00\n",
      "Epoch 6875, Loss: 5.320688724517822, Neurons: 64, Grad norm: 2.097e+00\n",
      "Epoch 6876, Loss: 5.30900239944458, Neurons: 64, Grad norm: 2.094e+00\n",
      "Epoch 6876, Loss: 5.30900239944458, Neurons: 64, Grad norm: 2.094e+00\n",
      "Epoch 6877, Loss: 5.297332763671875, Neurons: 64, Grad norm: 2.095e+00\n",
      "Epoch 6877, Loss: 5.297332763671875, Neurons: 64, Grad norm: 2.095e+00\n",
      "Epoch 6878, Loss: 5.28568172454834, Neurons: 64, Grad norm: 2.092e+00\n",
      "Epoch 6878, Loss: 5.28568172454834, Neurons: 64, Grad norm: 2.092e+00\n",
      "Epoch 6879, Loss: 5.27405309677124, Neurons: 64, Grad norm: 2.089e+00\n",
      "Epoch 6879, Loss: 5.27405309677124, Neurons: 64, Grad norm: 2.089e+00\n",
      "Epoch 6880, Loss: 5.26243782043457, Neurons: 64, Grad norm: 2.084e+00\n",
      "Epoch 6880, Loss: 5.26243782043457, Neurons: 64, Grad norm: 2.084e+00\n",
      "Epoch 6881, Loss: 5.2508440017700195, Neurons: 64, Grad norm: 2.077e+00\n",
      "Epoch 6881, Loss: 5.2508440017700195, Neurons: 64, Grad norm: 2.077e+00\n",
      "Epoch 6882, Loss: 5.239267826080322, Neurons: 64, Grad norm: 2.074e+00\n",
      "Epoch 6882, Loss: 5.239267826080322, Neurons: 64, Grad norm: 2.074e+00\n",
      "Epoch 6883, Loss: 5.227709770202637, Neurons: 64, Grad norm: 2.071e+00\n",
      "Epoch 6883, Loss: 5.227709770202637, Neurons: 64, Grad norm: 2.071e+00\n",
      "Epoch 6884, Loss: 5.216170310974121, Neurons: 64, Grad norm: 2.074e+00\n",
      "Epoch 6884, Loss: 5.216170310974121, Neurons: 64, Grad norm: 2.074e+00\n",
      "Epoch 6885, Loss: 5.204647541046143, Neurons: 64, Grad norm: 2.071e+00\n",
      "Epoch 6885, Loss: 5.204647541046143, Neurons: 64, Grad norm: 2.071e+00\n",
      "Epoch 6886, Loss: 5.193146705627441, Neurons: 64, Grad norm: 2.067e+00\n",
      "Epoch 6886, Loss: 5.193146705627441, Neurons: 64, Grad norm: 2.067e+00\n",
      "Epoch 6887, Loss: 5.181662559509277, Neurons: 64, Grad norm: 2.060e+00\n",
      "Epoch 6887, Loss: 5.181662559509277, Neurons: 64, Grad norm: 2.060e+00\n",
      "Epoch 6888, Loss: 5.170196533203125, Neurons: 64, Grad norm: 2.056e+00\n",
      "Epoch 6888, Loss: 5.170196533203125, Neurons: 64, Grad norm: 2.056e+00\n",
      "Epoch 6889, Loss: 5.158752918243408, Neurons: 64, Grad norm: 2.053e+00\n",
      "Epoch 6889, Loss: 5.158752918243408, Neurons: 64, Grad norm: 2.053e+00\n",
      "Epoch 6890, Loss: 5.147322654724121, Neurons: 64, Grad norm: 2.055e+00\n",
      "Epoch 6890, Loss: 5.147322654724121, Neurons: 64, Grad norm: 2.055e+00\n",
      "Epoch 6891, Loss: 5.135913372039795, Neurons: 64, Grad norm: 2.052e+00\n",
      "Epoch 6891, Loss: 5.135913372039795, Neurons: 64, Grad norm: 2.052e+00\n",
      "Epoch 6892, Loss: 5.124521732330322, Neurons: 64, Grad norm: 2.048e+00\n",
      "Epoch 6892, Loss: 5.124521732330322, Neurons: 64, Grad norm: 2.048e+00\n",
      "Epoch 6893, Loss: 5.113149166107178, Neurons: 64, Grad norm: 2.041e+00\n",
      "Epoch 6893, Loss: 5.113149166107178, Neurons: 64, Grad norm: 2.041e+00\n",
      "Epoch 6894, Loss: 5.101794242858887, Neurons: 64, Grad norm: 2.038e+00\n",
      "Epoch 6894, Loss: 5.101794242858887, Neurons: 64, Grad norm: 2.038e+00\n",
      "Epoch 6895, Loss: 5.090460300445557, Neurons: 64, Grad norm: 2.039e+00\n",
      "Epoch 6895, Loss: 5.090460300445557, Neurons: 64, Grad norm: 2.039e+00\n",
      "Epoch 6896, Loss: 5.079143047332764, Neurons: 64, Grad norm: 2.037e+00\n",
      "Epoch 6896, Loss: 5.079143047332764, Neurons: 64, Grad norm: 2.037e+00\n",
      "Epoch 6897, Loss: 5.067843914031982, Neurons: 64, Grad norm: 2.029e+00\n",
      "Epoch 6897, Loss: 5.067843914031982, Neurons: 64, Grad norm: 2.029e+00\n",
      "Epoch 6898, Loss: 5.056564807891846, Neurons: 64, Grad norm: 2.025e+00\n",
      "Epoch 6898, Loss: 5.056564807891846, Neurons: 64, Grad norm: 2.025e+00\n",
      "Epoch 6899, Loss: 5.0453033447265625, Neurons: 64, Grad norm: 2.028e+00\n",
      "Epoch 6899, Loss: 5.0453033447265625, Neurons: 64, Grad norm: 2.028e+00\n",
      "Epoch 6899, Test loss: 4.545373439788818\n",
      "Epoch 6899, Test loss: 4.545373439788818\n",
      "Epoch 6900, Loss: 5.034061908721924, Neurons: 64, Grad norm: 2.020e+00\n",
      "Epoch 6900, Loss: 5.034061908721924, Neurons: 64, Grad norm: 2.020e+00\n",
      "Epoch 6901, Loss: 5.022837162017822, Neurons: 64, Grad norm: 2.010e+00\n",
      "Epoch 6901, Loss: 5.022837162017822, Neurons: 64, Grad norm: 2.010e+00\n",
      "Epoch 6902, Loss: 5.011635780334473, Neurons: 64, Grad norm: 2.008e+00\n",
      "Epoch 6902, Loss: 5.011635780334473, Neurons: 64, Grad norm: 2.008e+00\n",
      "Epoch 6903, Loss: 5.000458240509033, Neurons: 64, Grad norm: 2.001e+00\n",
      "Epoch 6903, Loss: 5.000458240509033, Neurons: 64, Grad norm: 2.001e+00\n",
      "Epoch 6904, Loss: 4.98930025100708, Neurons: 64, Grad norm: 2.003e+00\n",
      "Epoch 6904, Loss: 4.98930025100708, Neurons: 64, Grad norm: 2.003e+00\n",
      "Epoch 6905, Loss: 4.978161334991455, Neurons: 64, Grad norm: 2.000e+00\n",
      "Epoch 6905, Loss: 4.978161334991455, Neurons: 64, Grad norm: 2.000e+00\n",
      "Epoch 6906, Loss: 4.967039108276367, Neurons: 64, Grad norm: 2.001e+00\n",
      "Epoch 6906, Loss: 4.967039108276367, Neurons: 64, Grad norm: 2.001e+00\n",
      "Epoch 6907, Loss: 4.955933570861816, Neurons: 64, Grad norm: 2.000e+00\n",
      "Epoch 6907, Loss: 4.955933570861816, Neurons: 64, Grad norm: 2.000e+00\n",
      "Epoch 6908, Loss: 4.944846153259277, Neurons: 64, Grad norm: 1.999e+00\n",
      "Epoch 6908, Loss: 4.944846153259277, Neurons: 64, Grad norm: 1.999e+00\n",
      "Epoch 6909, Loss: 4.933774471282959, Neurons: 64, Grad norm: 2.000e+00\n",
      "Epoch 6909, Loss: 4.933774471282959, Neurons: 64, Grad norm: 2.000e+00\n",
      "Epoch 6910, Loss: 4.922720909118652, Neurons: 64, Grad norm: 1.996e+00\n",
      "Epoch 6910, Loss: 4.922720909118652, Neurons: 64, Grad norm: 1.996e+00\n",
      "Epoch 6911, Loss: 4.911684989929199, Neurons: 64, Grad norm: 1.990e+00\n",
      "Epoch 6911, Loss: 4.911684989929199, Neurons: 64, Grad norm: 1.990e+00\n",
      "Epoch 6912, Loss: 4.900670051574707, Neurons: 64, Grad norm: 1.987e+00\n",
      "Epoch 6912, Loss: 4.900670051574707, Neurons: 64, Grad norm: 1.987e+00\n",
      "Epoch 6913, Loss: 4.889674186706543, Neurons: 64, Grad norm: 1.975e+00\n",
      "Epoch 6913, Loss: 4.889674186706543, Neurons: 64, Grad norm: 1.975e+00\n",
      "Epoch 6914, Loss: 4.878697872161865, Neurons: 64, Grad norm: 1.969e+00\n",
      "Epoch 6914, Loss: 4.878697872161865, Neurons: 64, Grad norm: 1.969e+00\n",
      "Epoch 6915, Loss: 4.867738723754883, Neurons: 64, Grad norm: 1.977e+00\n",
      "Epoch 6915, Loss: 4.867738723754883, Neurons: 64, Grad norm: 1.977e+00\n",
      "Epoch 6916, Loss: 4.856801509857178, Neurons: 64, Grad norm: 1.976e+00\n",
      "Epoch 6916, Loss: 4.856801509857178, Neurons: 64, Grad norm: 1.976e+00\n",
      "Epoch 6917, Loss: 4.845881938934326, Neurons: 64, Grad norm: 1.971e+00\n",
      "Epoch 6917, Loss: 4.845881938934326, Neurons: 64, Grad norm: 1.971e+00\n",
      "Epoch 6918, Loss: 4.834980487823486, Neurons: 64, Grad norm: 1.965e+00\n",
      "Epoch 6918, Loss: 4.834980487823486, Neurons: 64, Grad norm: 1.965e+00\n",
      "Epoch 6919, Loss: 4.824095249176025, Neurons: 64, Grad norm: 1.964e+00\n",
      "Epoch 6919, Loss: 4.824095249176025, Neurons: 64, Grad norm: 1.964e+00\n",
      "Epoch 6920, Loss: 4.813228130340576, Neurons: 64, Grad norm: 1.969e+00\n",
      "Epoch 6920, Loss: 4.813228130340576, Neurons: 64, Grad norm: 1.969e+00\n",
      "Epoch 6921, Loss: 4.8023810386657715, Neurons: 64, Grad norm: 1.954e+00\n",
      "Epoch 6921, Loss: 4.8023810386657715, Neurons: 64, Grad norm: 1.954e+00\n",
      "Epoch 6922, Loss: 4.791550636291504, Neurons: 64, Grad norm: 1.949e+00\n",
      "Epoch 6922, Loss: 4.791550636291504, Neurons: 64, Grad norm: 1.949e+00\n",
      "Epoch 6923, Loss: 4.780740261077881, Neurons: 64, Grad norm: 1.950e+00\n",
      "Epoch 6923, Loss: 4.780740261077881, Neurons: 64, Grad norm: 1.950e+00\n",
      "Epoch 6924, Loss: 4.7699480056762695, Neurons: 64, Grad norm: 1.950e+00\n",
      "Epoch 6924, Loss: 4.7699480056762695, Neurons: 64, Grad norm: 1.950e+00\n",
      "Epoch 6925, Loss: 4.7591776847839355, Neurons: 64, Grad norm: 1.949e+00\n",
      "Epoch 6925, Loss: 4.7591776847839355, Neurons: 64, Grad norm: 1.949e+00\n",
      "Epoch 6926, Loss: 4.748423099517822, Neurons: 64, Grad norm: 1.947e+00\n",
      "Epoch 6926, Loss: 4.748423099517822, Neurons: 64, Grad norm: 1.947e+00\n",
      "Epoch 6927, Loss: 4.737683296203613, Neurons: 64, Grad norm: 1.950e+00\n",
      "Epoch 6927, Loss: 4.737683296203613, Neurons: 64, Grad norm: 1.950e+00\n",
      "Epoch 6928, Loss: 4.726964950561523, Neurons: 64, Grad norm: 1.943e+00\n",
      "Epoch 6928, Loss: 4.726964950561523, Neurons: 64, Grad norm: 1.943e+00\n",
      "Epoch 6929, Loss: 4.716264247894287, Neurons: 64, Grad norm: 1.933e+00\n",
      "Epoch 6929, Loss: 4.716264247894287, Neurons: 64, Grad norm: 1.933e+00\n",
      "Epoch 6930, Loss: 4.705580711364746, Neurons: 64, Grad norm: 1.926e+00\n",
      "Epoch 6930, Loss: 4.705580711364746, Neurons: 64, Grad norm: 1.926e+00\n",
      "Epoch 6931, Loss: 4.694916248321533, Neurons: 64, Grad norm: 1.922e+00\n",
      "Epoch 6931, Loss: 4.694916248321533, Neurons: 64, Grad norm: 1.922e+00\n",
      "Epoch 6932, Loss: 4.68427038192749, Neurons: 64, Grad norm: 1.919e+00\n",
      "Epoch 6932, Loss: 4.68427038192749, Neurons: 64, Grad norm: 1.919e+00\n",
      "Epoch 6933, Loss: 4.673641681671143, Neurons: 64, Grad norm: 1.916e+00\n",
      "Epoch 6933, Loss: 4.673641681671143, Neurons: 64, Grad norm: 1.916e+00\n",
      "Epoch 6934, Loss: 4.663032054901123, Neurons: 64, Grad norm: 1.918e+00\n",
      "Epoch 6934, Loss: 4.663032054901123, Neurons: 64, Grad norm: 1.918e+00\n",
      "Epoch 6935, Loss: 4.652439117431641, Neurons: 64, Grad norm: 1.917e+00\n",
      "Epoch 6935, Loss: 4.652439117431641, Neurons: 64, Grad norm: 1.917e+00\n",
      "Epoch 6936, Loss: 4.641864776611328, Neurons: 64, Grad norm: 1.911e+00\n",
      "Epoch 6936, Loss: 4.641864776611328, Neurons: 64, Grad norm: 1.911e+00\n",
      "Epoch 6937, Loss: 4.631309986114502, Neurons: 64, Grad norm: 1.911e+00\n",
      "Epoch 6937, Loss: 4.631309986114502, Neurons: 64, Grad norm: 1.911e+00\n",
      "Epoch 6938, Loss: 4.6207709312438965, Neurons: 64, Grad norm: 1.911e+00\n",
      "Epoch 6938, Loss: 4.6207709312438965, Neurons: 64, Grad norm: 1.911e+00\n",
      "Epoch 6939, Loss: 4.61024808883667, Neurons: 64, Grad norm: 1.910e+00\n",
      "Epoch 6939, Loss: 4.61024808883667, Neurons: 64, Grad norm: 1.910e+00\n",
      "Epoch 6940, Loss: 4.599748134613037, Neurons: 64, Grad norm: 1.912e+00\n",
      "Epoch 6940, Loss: 4.599748134613037, Neurons: 64, Grad norm: 1.912e+00\n",
      "Epoch 6941, Loss: 4.589262962341309, Neurons: 64, Grad norm: 1.908e+00\n",
      "Epoch 6941, Loss: 4.589262962341309, Neurons: 64, Grad norm: 1.908e+00\n",
      "Epoch 6942, Loss: 4.578794002532959, Neurons: 64, Grad norm: 1.898e+00\n",
      "Epoch 6942, Loss: 4.578794002532959, Neurons: 64, Grad norm: 1.898e+00\n",
      "Epoch 6943, Loss: 4.56834602355957, Neurons: 64, Grad norm: 1.894e+00\n",
      "Epoch 6943, Loss: 4.56834602355957, Neurons: 64, Grad norm: 1.894e+00\n",
      "Epoch 6944, Loss: 4.5579142570495605, Neurons: 64, Grad norm: 1.891e+00\n",
      "Epoch 6944, Loss: 4.5579142570495605, Neurons: 64, Grad norm: 1.891e+00\n",
      "Epoch 6945, Loss: 4.547499656677246, Neurons: 64, Grad norm: 1.889e+00\n",
      "Epoch 6945, Loss: 4.547499656677246, Neurons: 64, Grad norm: 1.889e+00\n",
      "Epoch 6946, Loss: 4.537104606628418, Neurons: 64, Grad norm: 1.884e+00\n",
      "Epoch 6946, Loss: 4.537104606628418, Neurons: 64, Grad norm: 1.884e+00\n",
      "Epoch 6947, Loss: 4.526725769042969, Neurons: 64, Grad norm: 1.882e+00\n",
      "Epoch 6947, Loss: 4.526725769042969, Neurons: 64, Grad norm: 1.882e+00\n",
      "Epoch 6948, Loss: 4.516364574432373, Neurons: 64, Grad norm: 1.879e+00\n",
      "Epoch 6948, Loss: 4.516364574432373, Neurons: 64, Grad norm: 1.879e+00\n",
      "Epoch 6949, Loss: 4.506019592285156, Neurons: 64, Grad norm: 1.876e+00\n",
      "Epoch 6949, Loss: 4.506019592285156, Neurons: 64, Grad norm: 1.876e+00\n",
      "Epoch 6950, Loss: 4.495694637298584, Neurons: 64, Grad norm: 1.880e+00\n",
      "Epoch 6950, Loss: 4.495694637298584, Neurons: 64, Grad norm: 1.880e+00\n",
      "Epoch 6951, Loss: 4.485386848449707, Neurons: 64, Grad norm: 1.878e+00\n",
      "Epoch 6951, Loss: 4.485386848449707, Neurons: 64, Grad norm: 1.878e+00\n",
      "Epoch 6952, Loss: 4.475095748901367, Neurons: 64, Grad norm: 1.874e+00\n",
      "Epoch 6952, Loss: 4.475095748901367, Neurons: 64, Grad norm: 1.874e+00\n",
      "Epoch 6953, Loss: 4.464822292327881, Neurons: 64, Grad norm: 1.865e+00\n",
      "Epoch 6953, Loss: 4.464822292327881, Neurons: 64, Grad norm: 1.865e+00\n",
      "Epoch 6954, Loss: 4.454565525054932, Neurons: 64, Grad norm: 1.878e+00\n",
      "Epoch 6954, Loss: 4.454565525054932, Neurons: 64, Grad norm: 1.878e+00\n",
      "Epoch 6955, Loss: 4.444329261779785, Neurons: 64, Grad norm: 1.858e+00\n",
      "Epoch 6955, Loss: 4.444329261779785, Neurons: 64, Grad norm: 1.858e+00\n",
      "Epoch 6956, Loss: 4.434108734130859, Neurons: 64, Grad norm: 1.855e+00\n",
      "Epoch 6956, Loss: 4.434108734130859, Neurons: 64, Grad norm: 1.855e+00\n",
      "Epoch 6957, Loss: 4.423903942108154, Neurons: 64, Grad norm: 1.853e+00\n",
      "Epoch 6957, Loss: 4.423903942108154, Neurons: 64, Grad norm: 1.853e+00\n",
      "Epoch 6958, Loss: 4.413716793060303, Neurons: 64, Grad norm: 1.853e+00\n",
      "Epoch 6958, Loss: 4.413716793060303, Neurons: 64, Grad norm: 1.853e+00\n",
      "Epoch 6959, Loss: 4.403547286987305, Neurons: 64, Grad norm: 1.851e+00\n",
      "Epoch 6959, Loss: 4.403547286987305, Neurons: 64, Grad norm: 1.851e+00\n",
      "Epoch 6960, Loss: 4.393394470214844, Neurons: 64, Grad norm: 1.850e+00\n",
      "Epoch 6960, Loss: 4.393394470214844, Neurons: 64, Grad norm: 1.850e+00\n",
      "Epoch 6961, Loss: 4.383258819580078, Neurons: 64, Grad norm: 1.850e+00\n",
      "Epoch 6961, Loss: 4.383258819580078, Neurons: 64, Grad norm: 1.850e+00\n",
      "Epoch 6962, Loss: 4.373141765594482, Neurons: 64, Grad norm: 1.851e+00\n",
      "Epoch 6962, Loss: 4.373141765594482, Neurons: 64, Grad norm: 1.851e+00\n",
      "Epoch 6963, Loss: 4.363040447235107, Neurons: 64, Grad norm: 1.848e+00\n",
      "Epoch 6963, Loss: 4.363040447235107, Neurons: 64, Grad norm: 1.848e+00\n",
      "Epoch 6964, Loss: 4.352955341339111, Neurons: 64, Grad norm: 1.838e+00\n",
      "Epoch 6964, Loss: 4.352955341339111, Neurons: 64, Grad norm: 1.838e+00\n",
      "Epoch 6965, Loss: 4.342887878417969, Neurons: 64, Grad norm: 1.834e+00\n",
      "Epoch 6965, Loss: 4.342887878417969, Neurons: 64, Grad norm: 1.834e+00\n",
      "Epoch 6966, Loss: 4.332839012145996, Neurons: 64, Grad norm: 1.830e+00\n",
      "Epoch 6966, Loss: 4.332839012145996, Neurons: 64, Grad norm: 1.830e+00\n",
      "Epoch 6967, Loss: 4.322804927825928, Neurons: 64, Grad norm: 1.829e+00\n",
      "Epoch 6967, Loss: 4.322804927825928, Neurons: 64, Grad norm: 1.829e+00\n",
      "Epoch 6968, Loss: 4.312790393829346, Neurons: 64, Grad norm: 1.826e+00\n",
      "Epoch 6968, Loss: 4.312790393829346, Neurons: 64, Grad norm: 1.826e+00\n",
      "Epoch 6969, Loss: 4.302788734436035, Neurons: 64, Grad norm: 1.823e+00\n",
      "Epoch 6969, Loss: 4.302788734436035, Neurons: 64, Grad norm: 1.823e+00\n",
      "Epoch 6970, Loss: 4.292806148529053, Neurons: 64, Grad norm: 1.826e+00\n",
      "Epoch 6970, Loss: 4.292806148529053, Neurons: 64, Grad norm: 1.826e+00\n",
      "Epoch 6971, Loss: 4.282840251922607, Neurons: 64, Grad norm: 1.841e+00\n",
      "Epoch 6971, Loss: 4.282840251922607, Neurons: 64, Grad norm: 1.841e+00\n",
      "Epoch 6972, Loss: 4.272888660430908, Neurons: 64, Grad norm: 1.816e+00\n",
      "Epoch 6972, Loss: 4.272888660430908, Neurons: 64, Grad norm: 1.816e+00\n",
      "Epoch 6973, Loss: 4.262955188751221, Neurons: 64, Grad norm: 1.812e+00\n",
      "Epoch 6973, Loss: 4.262955188751221, Neurons: 64, Grad norm: 1.812e+00\n",
      "Epoch 6974, Loss: 4.25303840637207, Neurons: 64, Grad norm: 1.811e+00\n",
      "Epoch 6974, Loss: 4.25303840637207, Neurons: 64, Grad norm: 1.811e+00\n",
      "Epoch 6975, Loss: 4.243137836456299, Neurons: 64, Grad norm: 1.810e+00\n",
      "Epoch 6975, Loss: 4.243137836456299, Neurons: 64, Grad norm: 1.810e+00\n",
      "Epoch 6976, Loss: 4.23325252532959, Neurons: 64, Grad norm: 1.808e+00\n",
      "Epoch 6976, Loss: 4.23325252532959, Neurons: 64, Grad norm: 1.808e+00\n",
      "Epoch 6977, Loss: 4.223384380340576, Neurons: 64, Grad norm: 1.807e+00\n",
      "Epoch 6977, Loss: 4.223384380340576, Neurons: 64, Grad norm: 1.807e+00\n",
      "Epoch 6978, Loss: 4.213531970977783, Neurons: 64, Grad norm: 1.806e+00\n",
      "Epoch 6978, Loss: 4.213531970977783, Neurons: 64, Grad norm: 1.806e+00\n",
      "Epoch 6979, Loss: 4.203697681427002, Neurons: 64, Grad norm: 1.804e+00\n",
      "Epoch 6979, Loss: 4.203697681427002, Neurons: 64, Grad norm: 1.804e+00\n",
      "Epoch 6980, Loss: 4.193875789642334, Neurons: 64, Grad norm: 1.807e+00\n",
      "Epoch 6980, Loss: 4.193875789642334, Neurons: 64, Grad norm: 1.807e+00\n",
      "Epoch 6981, Loss: 4.184072494506836, Neurons: 64, Grad norm: 1.804e+00\n",
      "Epoch 6981, Loss: 4.184072494506836, Neurons: 64, Grad norm: 1.804e+00\n",
      "Epoch 6982, Loss: 4.1742844581604, Neurons: 64, Grad norm: 1.794e+00\n",
      "Epoch 6982, Loss: 4.1742844581604, Neurons: 64, Grad norm: 1.794e+00\n",
      "Epoch 6983, Loss: 4.164514064788818, Neurons: 64, Grad norm: 1.789e+00\n",
      "Epoch 6983, Loss: 4.164514064788818, Neurons: 64, Grad norm: 1.789e+00\n",
      "Epoch 6984, Loss: 4.154757976531982, Neurons: 64, Grad norm: 1.787e+00\n",
      "Epoch 6984, Loss: 4.154757976531982, Neurons: 64, Grad norm: 1.787e+00\n",
      "Epoch 6985, Loss: 4.145018577575684, Neurons: 64, Grad norm: 1.785e+00\n",
      "Epoch 6985, Loss: 4.145018577575684, Neurons: 64, Grad norm: 1.785e+00\n",
      "Epoch 6986, Loss: 4.135293006896973, Neurons: 64, Grad norm: 1.782e+00\n",
      "Epoch 6986, Loss: 4.135293006896973, Neurons: 64, Grad norm: 1.782e+00\n",
      "Epoch 6987, Loss: 4.125586032867432, Neurons: 64, Grad norm: 1.780e+00\n",
      "Epoch 6987, Loss: 4.125586032867432, Neurons: 64, Grad norm: 1.780e+00\n",
      "Epoch 6988, Loss: 4.115894794464111, Neurons: 64, Grad norm: 1.780e+00\n",
      "Epoch 6988, Loss: 4.115894794464111, Neurons: 64, Grad norm: 1.780e+00\n",
      "Epoch 6989, Loss: 4.106217861175537, Neurons: 64, Grad norm: 1.780e+00\n",
      "Epoch 6989, Loss: 4.106217861175537, Neurons: 64, Grad norm: 1.780e+00\n",
      "Epoch 6990, Loss: 4.096558094024658, Neurons: 64, Grad norm: 1.777e+00\n",
      "Epoch 6990, Loss: 4.096558094024658, Neurons: 64, Grad norm: 1.777e+00\n",
      "Epoch 6991, Loss: 4.086912155151367, Neurons: 64, Grad norm: 1.781e+00\n",
      "Epoch 6991, Loss: 4.086912155151367, Neurons: 64, Grad norm: 1.781e+00\n",
      "Epoch 6992, Loss: 4.077282905578613, Neurons: 64, Grad norm: 1.773e+00\n",
      "Epoch 6992, Loss: 4.077282905578613, Neurons: 64, Grad norm: 1.773e+00\n",
      "Epoch 6993, Loss: 4.067668914794922, Neurons: 64, Grad norm: 1.768e+00\n",
      "Epoch 6993, Loss: 4.067668914794922, Neurons: 64, Grad norm: 1.768e+00\n",
      "Epoch 6994, Loss: 4.058069229125977, Neurons: 64, Grad norm: 1.765e+00\n",
      "Epoch 6994, Loss: 4.058069229125977, Neurons: 64, Grad norm: 1.765e+00\n",
      "Epoch 6995, Loss: 4.048486232757568, Neurons: 64, Grad norm: 1.769e+00\n",
      "Epoch 6995, Loss: 4.048486232757568, Neurons: 64, Grad norm: 1.769e+00\n",
      "Epoch 6996, Loss: 4.038918972015381, Neurons: 64, Grad norm: 1.761e+00\n",
      "Epoch 6996, Loss: 4.038918972015381, Neurons: 64, Grad norm: 1.761e+00\n",
      "Epoch 6997, Loss: 4.0293660163879395, Neurons: 64, Grad norm: 1.757e+00\n",
      "Epoch 6997, Loss: 4.0293660163879395, Neurons: 64, Grad norm: 1.757e+00\n",
      "Epoch 6998, Loss: 4.019829750061035, Neurons: 64, Grad norm: 1.755e+00\n",
      "Epoch 6998, Loss: 4.019829750061035, Neurons: 64, Grad norm: 1.755e+00\n",
      "Epoch 6999, Loss: 4.010306358337402, Neurons: 64, Grad norm: 1.754e+00\n",
      "Epoch 6999, Loss: 4.010306358337402, Neurons: 64, Grad norm: 1.754e+00\n",
      "Epoch 6999, Test loss: 3.5733144283294678\n",
      "Epoch 6999, Test loss: 3.5733144283294678\n",
      "Epoch 7000, Loss: 4.000800609588623, Neurons: 64, Grad norm: 1.753e+00\n",
      "Epoch 7000, Loss: 4.000800609588623, Neurons: 64, Grad norm: 1.753e+00\n",
      "Epoch 7001, Loss: 3.99130916595459, Neurons: 64, Grad norm: 1.750e+00\n",
      "Epoch 7001, Loss: 3.99130916595459, Neurons: 64, Grad norm: 1.750e+00\n",
      "Epoch 7002, Loss: 3.9818317890167236, Neurons: 64, Grad norm: 1.749e+00\n",
      "Epoch 7002, Loss: 3.9818317890167236, Neurons: 64, Grad norm: 1.749e+00\n",
      "Epoch 7003, Loss: 3.972371816635132, Neurons: 64, Grad norm: 1.753e+00\n",
      "Epoch 7003, Loss: 3.972371816635132, Neurons: 64, Grad norm: 1.753e+00\n",
      "Epoch 7004, Loss: 3.9629247188568115, Neurons: 64, Grad norm: 1.744e+00\n",
      "Epoch 7004, Loss: 3.9629247188568115, Neurons: 64, Grad norm: 1.744e+00\n",
      "Epoch 7005, Loss: 3.9534928798675537, Neurons: 64, Grad norm: 1.741e+00\n",
      "Epoch 7005, Loss: 3.9534928798675537, Neurons: 64, Grad norm: 1.741e+00\n",
      "Epoch 7006, Loss: 3.9440762996673584, Neurons: 64, Grad norm: 1.739e+00\n",
      "Epoch 7006, Loss: 3.9440762996673584, Neurons: 64, Grad norm: 1.739e+00\n",
      "Epoch 7007, Loss: 3.9346752166748047, Neurons: 64, Grad norm: 1.737e+00\n",
      "Epoch 7007, Loss: 3.9346752166748047, Neurons: 64, Grad norm: 1.737e+00\n",
      "Epoch 7008, Loss: 3.9252865314483643, Neurons: 64, Grad norm: 1.734e+00\n",
      "Epoch 7008, Loss: 3.9252865314483643, Neurons: 64, Grad norm: 1.734e+00\n",
      "Epoch 7009, Loss: 3.9159162044525146, Neurons: 64, Grad norm: 1.739e+00\n",
      "Epoch 7009, Loss: 3.9159162044525146, Neurons: 64, Grad norm: 1.739e+00\n",
      "Epoch 7010, Loss: 3.9065582752227783, Neurons: 64, Grad norm: 1.731e+00\n",
      "Epoch 7010, Loss: 3.9065582752227783, Neurons: 64, Grad norm: 1.731e+00\n",
      "Epoch 7011, Loss: 3.8972160816192627, Neurons: 64, Grad norm: 1.729e+00\n",
      "Epoch 7011, Loss: 3.8972160816192627, Neurons: 64, Grad norm: 1.729e+00\n",
      "Epoch 7012, Loss: 3.8878884315490723, Neurons: 64, Grad norm: 1.726e+00\n",
      "Epoch 7012, Loss: 3.8878884315490723, Neurons: 64, Grad norm: 1.726e+00\n",
      "Epoch 7013, Loss: 3.8785743713378906, Neurons: 64, Grad norm: 1.725e+00\n",
      "Epoch 7013, Loss: 3.8785743713378906, Neurons: 64, Grad norm: 1.725e+00\n",
      "Epoch 7014, Loss: 3.869274854660034, Neurons: 64, Grad norm: 1.723e+00\n",
      "Epoch 7014, Loss: 3.869274854660034, Neurons: 64, Grad norm: 1.723e+00\n",
      "Epoch 7015, Loss: 3.8599910736083984, Neurons: 64, Grad norm: 1.723e+00\n",
      "Epoch 7015, Loss: 3.8599910736083984, Neurons: 64, Grad norm: 1.723e+00\n",
      "Epoch 7016, Loss: 3.8507213592529297, Neurons: 64, Grad norm: 1.719e+00\n",
      "Epoch 7016, Loss: 3.8507213592529297, Neurons: 64, Grad norm: 1.719e+00\n",
      "Epoch 7017, Loss: 3.841464042663574, Neurons: 64, Grad norm: 1.717e+00\n",
      "Epoch 7017, Loss: 3.841464042663574, Neurons: 64, Grad norm: 1.717e+00\n",
      "Epoch 7018, Loss: 3.8322243690490723, Neurons: 64, Grad norm: 1.721e+00\n",
      "Epoch 7018, Loss: 3.8322243690490723, Neurons: 64, Grad norm: 1.721e+00\n",
      "Epoch 7019, Loss: 3.822996139526367, Neurons: 64, Grad norm: 1.713e+00\n",
      "Epoch 7019, Loss: 3.822996139526367, Neurons: 64, Grad norm: 1.713e+00\n",
      "Epoch 7020, Loss: 3.8137829303741455, Neurons: 64, Grad norm: 1.709e+00\n",
      "Epoch 7020, Loss: 3.8137829303741455, Neurons: 64, Grad norm: 1.709e+00\n",
      "Epoch 7021, Loss: 3.804584503173828, Neurons: 64, Grad norm: 1.707e+00\n",
      "Epoch 7021, Loss: 3.804584503173828, Neurons: 64, Grad norm: 1.707e+00\n",
      "Epoch 7022, Loss: 3.795398712158203, Neurons: 64, Grad norm: 1.705e+00\n",
      "Epoch 7022, Loss: 3.795398712158203, Neurons: 64, Grad norm: 1.705e+00\n",
      "Epoch 7023, Loss: 3.786228895187378, Neurons: 64, Grad norm: 1.704e+00\n",
      "Epoch 7023, Loss: 3.786228895187378, Neurons: 64, Grad norm: 1.704e+00\n",
      "Epoch 7024, Loss: 3.7770705223083496, Neurons: 64, Grad norm: 1.702e+00\n",
      "Epoch 7024, Loss: 3.7770705223083496, Neurons: 64, Grad norm: 1.702e+00\n",
      "Epoch 7025, Loss: 3.7679264545440674, Neurons: 64, Grad norm: 1.701e+00\n",
      "Epoch 7025, Loss: 3.7679264545440674, Neurons: 64, Grad norm: 1.701e+00\n",
      "Epoch 7026, Loss: 3.758798122406006, Neurons: 64, Grad norm: 1.700e+00\n",
      "Epoch 7026, Loss: 3.758798122406006, Neurons: 64, Grad norm: 1.700e+00\n",
      "Epoch 7027, Loss: 3.7496817111968994, Neurons: 64, Grad norm: 1.705e+00\n",
      "Epoch 7027, Loss: 3.7496817111968994, Neurons: 64, Grad norm: 1.705e+00\n",
      "Epoch 7028, Loss: 3.7405803203582764, Neurons: 64, Grad norm: 1.696e+00\n",
      "Epoch 7028, Loss: 3.7405803203582764, Neurons: 64, Grad norm: 1.696e+00\n",
      "Epoch 7029, Loss: 3.7314910888671875, Neurons: 64, Grad norm: 1.693e+00\n",
      "Epoch 7029, Loss: 3.7314910888671875, Neurons: 64, Grad norm: 1.693e+00\n",
      "Epoch 7030, Loss: 3.7224161624908447, Neurons: 64, Grad norm: 1.691e+00\n",
      "Epoch 7030, Loss: 3.7224161624908447, Neurons: 64, Grad norm: 1.691e+00\n",
      "Epoch 7031, Loss: 3.7133541107177734, Neurons: 64, Grad norm: 1.689e+00\n",
      "Epoch 7031, Loss: 3.7133541107177734, Neurons: 64, Grad norm: 1.689e+00\n",
      "Epoch 7032, Loss: 3.704305410385132, Neurons: 64, Grad norm: 1.687e+00\n",
      "Epoch 7032, Loss: 3.704305410385132, Neurons: 64, Grad norm: 1.687e+00\n",
      "Epoch 7033, Loss: 3.6952712535858154, Neurons: 64, Grad norm: 1.685e+00\n",
      "Epoch 7033, Loss: 3.6952712535858154, Neurons: 64, Grad norm: 1.685e+00\n",
      "Epoch 7034, Loss: 3.6862478256225586, Neurons: 64, Grad norm: 1.685e+00\n",
      "Epoch 7034, Loss: 3.6862478256225586, Neurons: 64, Grad norm: 1.685e+00\n",
      "Epoch 7035, Loss: 3.6772403717041016, Neurons: 64, Grad norm: 1.684e+00\n",
      "Epoch 7035, Loss: 3.6772403717041016, Neurons: 64, Grad norm: 1.684e+00\n",
      "Epoch 7036, Loss: 3.6682448387145996, Neurons: 64, Grad norm: 1.682e+00\n",
      "Epoch 7036, Loss: 3.6682448387145996, Neurons: 64, Grad norm: 1.682e+00\n",
      "Epoch 7037, Loss: 3.659261703491211, Neurons: 64, Grad norm: 1.681e+00\n",
      "Epoch 7037, Loss: 3.659261703491211, Neurons: 64, Grad norm: 1.681e+00\n",
      "Epoch 7038, Loss: 3.6502933502197266, Neurons: 64, Grad norm: 1.685e+00\n",
      "Epoch 7038, Loss: 3.6502933502197266, Neurons: 64, Grad norm: 1.685e+00\n",
      "Epoch 7039, Loss: 3.6413371562957764, Neurons: 64, Grad norm: 1.676e+00\n",
      "Epoch 7039, Loss: 3.6413371562957764, Neurons: 64, Grad norm: 1.676e+00\n",
      "Epoch 7040, Loss: 3.6323938369750977, Neurons: 64, Grad norm: 1.672e+00\n",
      "Epoch 7040, Loss: 3.6323938369750977, Neurons: 64, Grad norm: 1.672e+00\n",
      "Epoch 7041, Loss: 3.6234631538391113, Neurons: 64, Grad norm: 1.662e+00\n",
      "Epoch 7041, Loss: 3.6234631538391113, Neurons: 64, Grad norm: 1.662e+00\n",
      "Epoch 7042, Loss: 3.6145455837249756, Neurons: 64, Grad norm: 1.671e+00\n",
      "Epoch 7042, Loss: 3.6145455837249756, Neurons: 64, Grad norm: 1.671e+00\n",
      "Epoch 7043, Loss: 3.605638265609741, Neurons: 64, Grad norm: 1.671e+00\n",
      "Epoch 7043, Loss: 3.605638265609741, Neurons: 64, Grad norm: 1.671e+00\n",
      "Epoch 7044, Loss: 3.5967469215393066, Neurons: 64, Grad norm: 1.670e+00\n",
      "Epoch 7044, Loss: 3.5967469215393066, Neurons: 64, Grad norm: 1.670e+00\n",
      "Epoch 7045, Loss: 3.58786678314209, Neurons: 64, Grad norm: 1.668e+00\n",
      "Epoch 7045, Loss: 3.58786678314209, Neurons: 64, Grad norm: 1.668e+00\n",
      "Epoch 7046, Loss: 3.5789997577667236, Neurons: 64, Grad norm: 1.666e+00\n",
      "Epoch 7046, Loss: 3.5789997577667236, Neurons: 64, Grad norm: 1.666e+00\n",
      "Epoch 7047, Loss: 3.5701446533203125, Neurons: 64, Grad norm: 1.663e+00\n",
      "Epoch 7047, Loss: 3.5701446533203125, Neurons: 64, Grad norm: 1.663e+00\n",
      "Epoch 7048, Loss: 3.5613021850585938, Neurons: 64, Grad norm: 1.659e+00\n",
      "Epoch 7048, Loss: 3.5613021850585938, Neurons: 64, Grad norm: 1.659e+00\n",
      "Epoch 7049, Loss: 3.5524730682373047, Neurons: 64, Grad norm: 1.657e+00\n",
      "Epoch 7049, Loss: 3.5524730682373047, Neurons: 64, Grad norm: 1.657e+00\n",
      "Epoch 7050, Loss: 3.5436534881591797, Neurons: 64, Grad norm: 1.655e+00\n",
      "Epoch 7050, Loss: 3.5436534881591797, Neurons: 64, Grad norm: 1.655e+00\n",
      "Epoch 7051, Loss: 3.5348477363586426, Neurons: 64, Grad norm: 1.653e+00\n",
      "Epoch 7051, Loss: 3.5348477363586426, Neurons: 64, Grad norm: 1.653e+00\n",
      "Epoch 7052, Loss: 3.5260543823242188, Neurons: 64, Grad norm: 1.652e+00\n",
      "Epoch 7052, Loss: 3.5260543823242188, Neurons: 64, Grad norm: 1.652e+00\n",
      "Epoch 7053, Loss: 3.51727294921875, Neurons: 64, Grad norm: 1.652e+00\n",
      "Epoch 7053, Loss: 3.51727294921875, Neurons: 64, Grad norm: 1.652e+00\n",
      "Epoch 7054, Loss: 3.5084996223449707, Neurons: 64, Grad norm: 1.652e+00\n",
      "Epoch 7054, Loss: 3.5084996223449707, Neurons: 64, Grad norm: 1.652e+00\n",
      "Epoch 7055, Loss: 3.499744176864624, Neurons: 64, Grad norm: 1.650e+00\n",
      "Epoch 7055, Loss: 3.499744176864624, Neurons: 64, Grad norm: 1.650e+00\n",
      "Epoch 7056, Loss: 3.490996837615967, Neurons: 64, Grad norm: 1.655e+00\n",
      "Epoch 7056, Loss: 3.490996837615967, Neurons: 64, Grad norm: 1.655e+00\n",
      "Epoch 7057, Loss: 3.482262372970581, Neurons: 64, Grad norm: 1.645e+00\n",
      "Epoch 7057, Loss: 3.482262372970581, Neurons: 64, Grad norm: 1.645e+00\n",
      "Epoch 7058, Loss: 3.4735403060913086, Neurons: 64, Grad norm: 1.643e+00\n",
      "Epoch 7058, Loss: 3.4735403060913086, Neurons: 64, Grad norm: 1.643e+00\n",
      "Epoch 7059, Loss: 3.464829206466675, Neurons: 64, Grad norm: 1.639e+00\n",
      "Epoch 7059, Loss: 3.464829206466675, Neurons: 64, Grad norm: 1.639e+00\n",
      "Epoch 7060, Loss: 3.4561309814453125, Neurons: 64, Grad norm: 1.638e+00\n",
      "Epoch 7060, Loss: 3.4561309814453125, Neurons: 64, Grad norm: 1.638e+00\n",
      "Epoch 7061, Loss: 3.447443962097168, Neurons: 64, Grad norm: 1.637e+00\n",
      "Epoch 7061, Loss: 3.447443962097168, Neurons: 64, Grad norm: 1.637e+00\n",
      "Epoch 7062, Loss: 3.438767910003662, Neurons: 64, Grad norm: 1.636e+00\n",
      "Epoch 7062, Loss: 3.438767910003662, Neurons: 64, Grad norm: 1.636e+00\n",
      "Epoch 7063, Loss: 3.4301037788391113, Neurons: 64, Grad norm: 1.634e+00\n",
      "Epoch 7063, Loss: 3.4301037788391113, Neurons: 64, Grad norm: 1.634e+00\n",
      "Epoch 7064, Loss: 3.4214518070220947, Neurons: 64, Grad norm: 1.633e+00\n",
      "Epoch 7064, Loss: 3.4214518070220947, Neurons: 64, Grad norm: 1.633e+00\n",
      "Epoch 7065, Loss: 3.4128098487854004, Neurons: 64, Grad norm: 1.632e+00\n",
      "Epoch 7065, Loss: 3.4128098487854004, Neurons: 64, Grad norm: 1.632e+00\n",
      "Epoch 7066, Loss: 3.4041810035705566, Neurons: 64, Grad norm: 1.621e+00\n",
      "Epoch 7066, Loss: 3.4041810035705566, Neurons: 64, Grad norm: 1.621e+00\n",
      "Epoch 7067, Loss: 3.3955631256103516, Neurons: 64, Grad norm: 1.631e+00\n",
      "Epoch 7067, Loss: 3.3955631256103516, Neurons: 64, Grad norm: 1.631e+00\n",
      "Epoch 7068, Loss: 3.386956214904785, Neurons: 64, Grad norm: 1.630e+00\n",
      "Epoch 7068, Loss: 3.386956214904785, Neurons: 64, Grad norm: 1.630e+00\n",
      "Epoch 7069, Loss: 3.378361463546753, Neurons: 64, Grad norm: 1.627e+00\n",
      "Epoch 7069, Loss: 3.378361463546753, Neurons: 64, Grad norm: 1.627e+00\n",
      "Epoch 7070, Loss: 3.3697776794433594, Neurons: 64, Grad norm: 1.624e+00\n",
      "Epoch 7070, Loss: 3.3697776794433594, Neurons: 64, Grad norm: 1.624e+00\n",
      "Epoch 7071, Loss: 3.361203670501709, Neurons: 64, Grad norm: 1.620e+00\n",
      "Epoch 7071, Loss: 3.361203670501709, Neurons: 64, Grad norm: 1.620e+00\n",
      "Epoch 7072, Loss: 3.352642774581909, Neurons: 64, Grad norm: 1.617e+00\n",
      "Epoch 7072, Loss: 3.352642774581909, Neurons: 64, Grad norm: 1.617e+00\n",
      "Epoch 7073, Loss: 3.3440914154052734, Neurons: 64, Grad norm: 1.616e+00\n",
      "Epoch 7073, Loss: 3.3440914154052734, Neurons: 64, Grad norm: 1.616e+00\n",
      "Epoch 7074, Loss: 3.3355510234832764, Neurons: 64, Grad norm: 1.616e+00\n",
      "Epoch 7074, Loss: 3.3355510234832764, Neurons: 64, Grad norm: 1.616e+00\n",
      "Epoch 7075, Loss: 3.327023506164551, Neurons: 64, Grad norm: 1.613e+00\n",
      "Epoch 7075, Loss: 3.327023506164551, Neurons: 64, Grad norm: 1.613e+00\n",
      "Epoch 7076, Loss: 3.318504571914673, Neurons: 64, Grad norm: 1.611e+00\n",
      "Epoch 7076, Loss: 3.318504571914673, Neurons: 64, Grad norm: 1.611e+00\n",
      "Epoch 7077, Loss: 3.309998035430908, Neurons: 64, Grad norm: 1.610e+00\n",
      "Epoch 7077, Loss: 3.309998035430908, Neurons: 64, Grad norm: 1.610e+00\n",
      "Epoch 7078, Loss: 3.301502227783203, Neurons: 64, Grad norm: 1.610e+00\n",
      "Epoch 7078, Loss: 3.301502227783203, Neurons: 64, Grad norm: 1.610e+00\n",
      "Epoch 7079, Loss: 3.2930169105529785, Neurons: 64, Grad norm: 1.610e+00\n",
      "Epoch 7079, Loss: 3.2930169105529785, Neurons: 64, Grad norm: 1.610e+00\n",
      "Epoch 7080, Loss: 3.28454327583313, Neurons: 64, Grad norm: 1.607e+00\n",
      "Epoch 7080, Loss: 3.28454327583313, Neurons: 64, Grad norm: 1.607e+00\n",
      "Epoch 7081, Loss: 3.2760791778564453, Neurons: 64, Grad norm: 1.606e+00\n",
      "Epoch 7081, Loss: 3.2760791778564453, Neurons: 64, Grad norm: 1.606e+00\n",
      "Epoch 7082, Loss: 3.2676267623901367, Neurons: 64, Grad norm: 1.603e+00\n",
      "Epoch 7082, Loss: 3.2676267623901367, Neurons: 64, Grad norm: 1.603e+00\n",
      "Epoch 7083, Loss: 3.259185791015625, Neurons: 64, Grad norm: 1.601e+00\n",
      "Epoch 7083, Loss: 3.259185791015625, Neurons: 64, Grad norm: 1.601e+00\n",
      "Epoch 7084, Loss: 3.250753879547119, Neurons: 64, Grad norm: 1.598e+00\n",
      "Epoch 7084, Loss: 3.250753879547119, Neurons: 64, Grad norm: 1.598e+00\n",
      "Epoch 7085, Loss: 3.2423341274261475, Neurons: 64, Grad norm: 1.597e+00\n",
      "Epoch 7085, Loss: 3.2423341274261475, Neurons: 64, Grad norm: 1.597e+00\n",
      "Epoch 7086, Loss: 3.23392391204834, Neurons: 64, Grad norm: 1.596e+00\n",
      "Epoch 7086, Loss: 3.23392391204834, Neurons: 64, Grad norm: 1.596e+00\n",
      "Epoch 7087, Loss: 3.2255239486694336, Neurons: 64, Grad norm: 1.595e+00\n",
      "Epoch 7087, Loss: 3.2255239486694336, Neurons: 64, Grad norm: 1.595e+00\n",
      "Epoch 7088, Loss: 3.217135429382324, Neurons: 64, Grad norm: 1.594e+00\n",
      "Epoch 7088, Loss: 3.217135429382324, Neurons: 64, Grad norm: 1.594e+00\n",
      "Epoch 7089, Loss: 3.2087578773498535, Neurons: 64, Grad norm: 1.591e+00\n",
      "Epoch 7089, Loss: 3.2087578773498535, Neurons: 64, Grad norm: 1.591e+00\n",
      "Epoch 7090, Loss: 3.200392007827759, Neurons: 64, Grad norm: 1.590e+00\n",
      "Epoch 7090, Loss: 3.200392007827759, Neurons: 64, Grad norm: 1.590e+00\n",
      "Epoch 7091, Loss: 3.1920342445373535, Neurons: 64, Grad norm: 1.589e+00\n",
      "Epoch 7091, Loss: 3.1920342445373535, Neurons: 64, Grad norm: 1.589e+00\n",
      "Epoch 7092, Loss: 3.1836884021759033, Neurons: 64, Grad norm: 1.588e+00\n",
      "Epoch 7092, Loss: 3.1836884021759033, Neurons: 64, Grad norm: 1.588e+00\n",
      "Epoch 7093, Loss: 3.1753532886505127, Neurons: 64, Grad norm: 1.586e+00\n",
      "Epoch 7093, Loss: 3.1753532886505127, Neurons: 64, Grad norm: 1.586e+00\n",
      "Epoch 7094, Loss: 3.1670279502868652, Neurons: 64, Grad norm: 1.585e+00\n",
      "Epoch 7094, Loss: 3.1670279502868652, Neurons: 64, Grad norm: 1.585e+00\n",
      "Epoch 7095, Loss: 3.1587135791778564, Neurons: 64, Grad norm: 1.583e+00\n",
      "Epoch 7095, Loss: 3.1587135791778564, Neurons: 64, Grad norm: 1.583e+00\n",
      "Epoch 7096, Loss: 3.1504077911376953, Neurons: 64, Grad norm: 1.582e+00\n",
      "Epoch 7096, Loss: 3.1504077911376953, Neurons: 64, Grad norm: 1.582e+00\n",
      "Epoch 7097, Loss: 3.142112970352173, Neurons: 64, Grad norm: 1.580e+00\n",
      "Epoch 7097, Loss: 3.142112970352173, Neurons: 64, Grad norm: 1.580e+00\n",
      "Epoch 7098, Loss: 3.1338303089141846, Neurons: 64, Grad norm: 1.579e+00\n",
      "Epoch 7098, Loss: 3.1338303089141846, Neurons: 64, Grad norm: 1.579e+00\n",
      "Epoch 7099, Loss: 3.1255552768707275, Neurons: 64, Grad norm: 1.578e+00\n",
      "Epoch 7099, Loss: 3.1255552768707275, Neurons: 64, Grad norm: 1.578e+00\n",
      "Epoch 7099, Test loss: 2.7438833713531494\n",
      "Epoch 7099, Test loss: 2.7438833713531494\n",
      "Epoch 7100, Loss: 3.1172921657562256, Neurons: 64, Grad norm: 1.576e+00\n",
      "Epoch 7100, Loss: 3.1172921657562256, Neurons: 64, Grad norm: 1.576e+00\n",
      "Epoch 7101, Loss: 3.109039783477783, Neurons: 64, Grad norm: 1.575e+00\n",
      "Epoch 7101, Loss: 3.109039783477783, Neurons: 64, Grad norm: 1.575e+00\n",
      "Epoch 7102, Loss: 3.100796699523926, Neurons: 64, Grad norm: 1.572e+00\n",
      "Epoch 7102, Loss: 3.100796699523926, Neurons: 64, Grad norm: 1.572e+00\n",
      "Epoch 7103, Loss: 3.0925638675689697, Neurons: 64, Grad norm: 1.571e+00\n",
      "Epoch 7103, Loss: 3.0925638675689697, Neurons: 64, Grad norm: 1.571e+00\n",
      "Epoch 7104, Loss: 3.0843420028686523, Neurons: 64, Grad norm: 1.570e+00\n",
      "Epoch 7104, Loss: 3.0843420028686523, Neurons: 64, Grad norm: 1.570e+00\n",
      "Epoch 7105, Loss: 3.0761289596557617, Neurons: 64, Grad norm: 1.569e+00\n",
      "Epoch 7105, Loss: 3.0761289596557617, Neurons: 64, Grad norm: 1.569e+00\n",
      "Epoch 7106, Loss: 3.0679268836975098, Neurons: 64, Grad norm: 1.568e+00\n",
      "Epoch 7106, Loss: 3.0679268836975098, Neurons: 64, Grad norm: 1.568e+00\n",
      "Epoch 7107, Loss: 3.059735059738159, Neurons: 64, Grad norm: 1.566e+00\n",
      "Epoch 7107, Loss: 3.059735059738159, Neurons: 64, Grad norm: 1.566e+00\n",
      "Epoch 7108, Loss: 3.051553249359131, Neurons: 64, Grad norm: 1.565e+00\n",
      "Epoch 7108, Loss: 3.051553249359131, Neurons: 64, Grad norm: 1.565e+00\n",
      "Epoch 7109, Loss: 3.043382167816162, Neurons: 64, Grad norm: 1.563e+00\n",
      "Epoch 7109, Loss: 3.043382167816162, Neurons: 64, Grad norm: 1.563e+00\n",
      "Epoch 7110, Loss: 3.0352210998535156, Neurons: 64, Grad norm: 1.561e+00\n",
      "Epoch 7110, Loss: 3.0352210998535156, Neurons: 64, Grad norm: 1.561e+00\n",
      "Epoch 7111, Loss: 3.027070999145508, Neurons: 64, Grad norm: 1.560e+00\n",
      "Epoch 7111, Loss: 3.027070999145508, Neurons: 64, Grad norm: 1.560e+00\n",
      "Epoch 7112, Loss: 3.018930673599243, Neurons: 64, Grad norm: 1.559e+00\n",
      "Epoch 7112, Loss: 3.018930673599243, Neurons: 64, Grad norm: 1.559e+00\n",
      "Epoch 7113, Loss: 3.010798692703247, Neurons: 64, Grad norm: 1.558e+00\n",
      "Epoch 7113, Loss: 3.010798692703247, Neurons: 64, Grad norm: 1.558e+00\n",
      "Epoch 7114, Loss: 3.0026798248291016, Neurons: 64, Grad norm: 1.556e+00\n",
      "Epoch 7114, Loss: 3.0026798248291016, Neurons: 64, Grad norm: 1.556e+00\n",
      "Epoch 7115, Loss: 2.994568109512329, Neurons: 64, Grad norm: 1.555e+00\n",
      "Epoch 7115, Loss: 2.994568109512329, Neurons: 64, Grad norm: 1.555e+00\n",
      "Epoch 7116, Loss: 2.9864683151245117, Neurons: 64, Grad norm: 1.553e+00\n",
      "Epoch 7116, Loss: 2.9864683151245117, Neurons: 64, Grad norm: 1.553e+00\n",
      "Epoch 7117, Loss: 2.978379011154175, Neurons: 64, Grad norm: 1.552e+00\n",
      "Epoch 7117, Loss: 2.978379011154175, Neurons: 64, Grad norm: 1.552e+00\n",
      "Epoch 7118, Loss: 2.9702999591827393, Neurons: 64, Grad norm: 1.550e+00\n",
      "Epoch 7118, Loss: 2.9702999591827393, Neurons: 64, Grad norm: 1.550e+00\n",
      "Epoch 7119, Loss: 2.962233066558838, Neurons: 64, Grad norm: 1.549e+00\n",
      "Epoch 7119, Loss: 2.962233066558838, Neurons: 64, Grad norm: 1.549e+00\n",
      "Epoch 7120, Loss: 2.954174041748047, Neurons: 64, Grad norm: 1.548e+00\n",
      "Epoch 7120, Loss: 2.954174041748047, Neurons: 64, Grad norm: 1.548e+00\n",
      "Epoch 7121, Loss: 2.9461259841918945, Neurons: 64, Grad norm: 1.546e+00\n",
      "Epoch 7121, Loss: 2.9461259841918945, Neurons: 64, Grad norm: 1.546e+00\n",
      "Epoch 7122, Loss: 2.9380879402160645, Neurons: 64, Grad norm: 1.545e+00\n",
      "Epoch 7122, Loss: 2.9380879402160645, Neurons: 64, Grad norm: 1.545e+00\n",
      "Epoch 7123, Loss: 2.9300601482391357, Neurons: 64, Grad norm: 1.544e+00\n",
      "Epoch 7123, Loss: 2.9300601482391357, Neurons: 64, Grad norm: 1.544e+00\n",
      "Epoch 7124, Loss: 2.9220430850982666, Neurons: 64, Grad norm: 1.543e+00\n",
      "Epoch 7124, Loss: 2.9220430850982666, Neurons: 64, Grad norm: 1.543e+00\n",
      "Epoch 7125, Loss: 2.9140353202819824, Neurons: 64, Grad norm: 1.541e+00\n",
      "Epoch 7125, Loss: 2.9140353202819824, Neurons: 64, Grad norm: 1.541e+00\n",
      "Epoch 7126, Loss: 2.906039237976074, Neurons: 64, Grad norm: 1.539e+00\n",
      "Epoch 7126, Loss: 2.906039237976074, Neurons: 64, Grad norm: 1.539e+00\n",
      "Epoch 7127, Loss: 2.8980538845062256, Neurons: 64, Grad norm: 1.538e+00\n",
      "Epoch 7127, Loss: 2.8980538845062256, Neurons: 64, Grad norm: 1.538e+00\n",
      "Epoch 7128, Loss: 2.890079975128174, Neurons: 64, Grad norm: 1.536e+00\n",
      "Epoch 7128, Loss: 2.890079975128174, Neurons: 64, Grad norm: 1.536e+00\n",
      "Epoch 7129, Loss: 2.882114887237549, Neurons: 64, Grad norm: 1.535e+00\n",
      "Epoch 7129, Loss: 2.882114887237549, Neurons: 64, Grad norm: 1.535e+00\n",
      "Epoch 7130, Loss: 2.874159812927246, Neurons: 64, Grad norm: 1.531e+00\n",
      "Epoch 7130, Loss: 2.874159812927246, Neurons: 64, Grad norm: 1.531e+00\n",
      "Epoch 7131, Loss: 2.8662168979644775, Neurons: 64, Grad norm: 1.534e+00\n",
      "Epoch 7131, Loss: 2.8662168979644775, Neurons: 64, Grad norm: 1.534e+00\n",
      "Epoch 7132, Loss: 2.8582842350006104, Neurons: 64, Grad norm: 1.557e+00\n",
      "Epoch 7132, Loss: 2.8582842350006104, Neurons: 64, Grad norm: 1.557e+00\n",
      "Epoch 7133, Loss: 2.8503639698028564, Neurons: 64, Grad norm: 1.528e+00\n",
      "Epoch 7133, Loss: 2.8503639698028564, Neurons: 64, Grad norm: 1.528e+00\n",
      "Epoch 7134, Loss: 2.842451810836792, Neurons: 64, Grad norm: 1.525e+00\n",
      "Epoch 7134, Loss: 2.842451810836792, Neurons: 64, Grad norm: 1.525e+00\n",
      "Epoch 7135, Loss: 2.8345518112182617, Neurons: 64, Grad norm: 1.524e+00\n",
      "Epoch 7135, Loss: 2.8345518112182617, Neurons: 64, Grad norm: 1.524e+00\n",
      "Epoch 7136, Loss: 2.826662063598633, Neurons: 64, Grad norm: 1.525e+00\n",
      "Epoch 7136, Loss: 2.826662063598633, Neurons: 64, Grad norm: 1.525e+00\n",
      "Epoch 7137, Loss: 2.818784713745117, Neurons: 64, Grad norm: 1.524e+00\n",
      "Epoch 7137, Loss: 2.818784713745117, Neurons: 64, Grad norm: 1.524e+00\n",
      "Epoch 7138, Loss: 2.8109164237976074, Neurons: 64, Grad norm: 1.522e+00\n",
      "Epoch 7138, Loss: 2.8109164237976074, Neurons: 64, Grad norm: 1.522e+00\n",
      "Epoch 7139, Loss: 2.8030598163604736, Neurons: 64, Grad norm: 1.521e+00\n",
      "Epoch 7139, Loss: 2.8030598163604736, Neurons: 64, Grad norm: 1.521e+00\n",
      "Epoch 7140, Loss: 2.7952158451080322, Neurons: 64, Grad norm: 1.521e+00\n",
      "Epoch 7140, Loss: 2.7952158451080322, Neurons: 64, Grad norm: 1.521e+00\n",
      "Epoch 7141, Loss: 2.7873806953430176, Neurons: 64, Grad norm: 1.520e+00\n",
      "Epoch 7141, Loss: 2.7873806953430176, Neurons: 64, Grad norm: 1.520e+00\n",
      "Epoch 7142, Loss: 2.7795567512512207, Neurons: 64, Grad norm: 1.519e+00\n",
      "Epoch 7142, Loss: 2.7795567512512207, Neurons: 64, Grad norm: 1.519e+00\n",
      "Epoch 7143, Loss: 2.771745204925537, Neurons: 64, Grad norm: 1.515e+00\n",
      "Epoch 7143, Loss: 2.771745204925537, Neurons: 64, Grad norm: 1.515e+00\n",
      "Epoch 7144, Loss: 2.7639453411102295, Neurons: 64, Grad norm: 1.512e+00\n",
      "Epoch 7144, Loss: 2.7639453411102295, Neurons: 64, Grad norm: 1.512e+00\n",
      "Epoch 7145, Loss: 2.7561569213867188, Neurons: 64, Grad norm: 1.534e+00\n",
      "Epoch 7145, Loss: 2.7561569213867188, Neurons: 64, Grad norm: 1.534e+00\n",
      "Epoch 7146, Loss: 2.7483792304992676, Neurons: 64, Grad norm: 1.505e+00\n",
      "Epoch 7146, Loss: 2.7483792304992676, Neurons: 64, Grad norm: 1.505e+00\n",
      "Epoch 7147, Loss: 2.740614891052246, Neurons: 64, Grad norm: 1.503e+00\n",
      "Epoch 7147, Loss: 2.740614891052246, Neurons: 64, Grad norm: 1.503e+00\n",
      "Epoch 7148, Loss: 2.7328600883483887, Neurons: 64, Grad norm: 1.505e+00\n",
      "Epoch 7148, Loss: 2.7328600883483887, Neurons: 64, Grad norm: 1.505e+00\n",
      "Epoch 7149, Loss: 2.725118398666382, Neurons: 64, Grad norm: 1.508e+00\n",
      "Epoch 7149, Loss: 2.725118398666382, Neurons: 64, Grad norm: 1.508e+00\n",
      "Epoch 7150, Loss: 2.7173876762390137, Neurons: 64, Grad norm: 1.507e+00\n",
      "Epoch 7150, Loss: 2.7173876762390137, Neurons: 64, Grad norm: 1.507e+00\n",
      "Epoch 7151, Loss: 2.7096691131591797, Neurons: 64, Grad norm: 1.503e+00\n",
      "Epoch 7151, Loss: 2.7096691131591797, Neurons: 64, Grad norm: 1.503e+00\n",
      "Epoch 7152, Loss: 2.7019639015197754, Neurons: 64, Grad norm: 1.501e+00\n",
      "Epoch 7152, Loss: 2.7019639015197754, Neurons: 64, Grad norm: 1.501e+00\n",
      "Epoch 7153, Loss: 2.6942694187164307, Neurons: 64, Grad norm: 1.501e+00\n",
      "Epoch 7153, Loss: 2.6942694187164307, Neurons: 64, Grad norm: 1.501e+00\n",
      "Epoch 7154, Loss: 2.6865880489349365, Neurons: 64, Grad norm: 1.498e+00\n",
      "Epoch 7154, Loss: 2.6865880489349365, Neurons: 64, Grad norm: 1.498e+00\n",
      "Epoch 7155, Loss: 2.6789181232452393, Neurons: 64, Grad norm: 1.501e+00\n",
      "Epoch 7155, Loss: 2.6789181232452393, Neurons: 64, Grad norm: 1.501e+00\n",
      "Epoch 7156, Loss: 2.6712613105773926, Neurons: 64, Grad norm: 1.522e+00\n",
      "Epoch 7156, Loss: 2.6712613105773926, Neurons: 64, Grad norm: 1.522e+00\n",
      "Epoch 7157, Loss: 2.663616418838501, Neurons: 64, Grad norm: 1.488e+00\n",
      "Epoch 7157, Loss: 2.663616418838501, Neurons: 64, Grad norm: 1.488e+00\n",
      "Epoch 7158, Loss: 2.6559834480285645, Neurons: 64, Grad norm: 1.485e+00\n",
      "Epoch 7158, Loss: 2.6559834480285645, Neurons: 64, Grad norm: 1.485e+00\n",
      "Epoch 7159, Loss: 2.648364305496216, Neurons: 64, Grad norm: 1.486e+00\n",
      "Epoch 7159, Loss: 2.648364305496216, Neurons: 64, Grad norm: 1.486e+00\n",
      "Epoch 7160, Loss: 2.640756845474243, Neurons: 64, Grad norm: 1.490e+00\n",
      "Epoch 7160, Loss: 2.640756845474243, Neurons: 64, Grad norm: 1.490e+00\n",
      "Epoch 7161, Loss: 2.633162498474121, Neurons: 64, Grad norm: 1.489e+00\n",
      "Epoch 7161, Loss: 2.633162498474121, Neurons: 64, Grad norm: 1.489e+00\n",
      "Epoch 7162, Loss: 2.6255810260772705, Neurons: 64, Grad norm: 1.485e+00\n",
      "Epoch 7162, Loss: 2.6255810260772705, Neurons: 64, Grad norm: 1.485e+00\n",
      "Epoch 7163, Loss: 2.6180129051208496, Neurons: 64, Grad norm: 1.483e+00\n",
      "Epoch 7163, Loss: 2.6180129051208496, Neurons: 64, Grad norm: 1.483e+00\n",
      "Epoch 7164, Loss: 2.610457181930542, Neurons: 64, Grad norm: 1.483e+00\n",
      "Epoch 7164, Loss: 2.610457181930542, Neurons: 64, Grad norm: 1.483e+00\n",
      "Epoch 7165, Loss: 2.6029140949249268, Neurons: 64, Grad norm: 1.485e+00\n",
      "Epoch 7165, Loss: 2.6029140949249268, Neurons: 64, Grad norm: 1.485e+00\n",
      "Epoch 7166, Loss: 2.595386028289795, Neurons: 64, Grad norm: 1.509e+00\n",
      "Epoch 7166, Loss: 2.595386028289795, Neurons: 64, Grad norm: 1.509e+00\n",
      "Epoch 7167, Loss: 2.587872266769409, Neurons: 64, Grad norm: 1.472e+00\n",
      "Epoch 7167, Loss: 2.587872266769409, Neurons: 64, Grad norm: 1.472e+00\n",
      "Epoch 7168, Loss: 2.580368757247925, Neurons: 64, Grad norm: 1.467e+00\n",
      "Epoch 7168, Loss: 2.580368757247925, Neurons: 64, Grad norm: 1.467e+00\n",
      "Epoch 7169, Loss: 2.572880983352661, Neurons: 64, Grad norm: 1.467e+00\n",
      "Epoch 7169, Loss: 2.572880983352661, Neurons: 64, Grad norm: 1.467e+00\n",
      "Epoch 7170, Loss: 2.5654077529907227, Neurons: 64, Grad norm: 1.472e+00\n",
      "Epoch 7170, Loss: 2.5654077529907227, Neurons: 64, Grad norm: 1.472e+00\n",
      "Epoch 7171, Loss: 2.5579466819763184, Neurons: 64, Grad norm: 1.473e+00\n",
      "Epoch 7171, Loss: 2.5579466819763184, Neurons: 64, Grad norm: 1.473e+00\n",
      "Epoch 7172, Loss: 2.5505006313323975, Neurons: 64, Grad norm: 1.495e+00\n",
      "Epoch 7172, Loss: 2.5505006313323975, Neurons: 64, Grad norm: 1.495e+00\n",
      "Epoch 7173, Loss: 2.5430681705474854, Neurons: 64, Grad norm: 1.462e+00\n",
      "Epoch 7173, Loss: 2.5430681705474854, Neurons: 64, Grad norm: 1.462e+00\n",
      "Epoch 7174, Loss: 2.5356476306915283, Neurons: 64, Grad norm: 1.461e+00\n",
      "Epoch 7174, Loss: 2.5356476306915283, Neurons: 64, Grad norm: 1.461e+00\n",
      "Epoch 7175, Loss: 2.52824330329895, Neurons: 64, Grad norm: 1.463e+00\n",
      "Epoch 7175, Loss: 2.52824330329895, Neurons: 64, Grad norm: 1.463e+00\n",
      "Epoch 7176, Loss: 2.520853281021118, Neurons: 64, Grad norm: 1.464e+00\n",
      "Epoch 7176, Loss: 2.520853281021118, Neurons: 64, Grad norm: 1.464e+00\n",
      "Epoch 7177, Loss: 2.5134758949279785, Neurons: 64, Grad norm: 1.459e+00\n",
      "Epoch 7177, Loss: 2.5134758949279785, Neurons: 64, Grad norm: 1.459e+00\n",
      "Epoch 7178, Loss: 2.506115436553955, Neurons: 64, Grad norm: 1.452e+00\n",
      "Epoch 7178, Loss: 2.506115436553955, Neurons: 64, Grad norm: 1.452e+00\n",
      "Epoch 7179, Loss: 2.4987680912017822, Neurons: 64, Grad norm: 1.452e+00\n",
      "Epoch 7179, Loss: 2.4987680912017822, Neurons: 64, Grad norm: 1.452e+00\n",
      "Epoch 7180, Loss: 2.49143648147583, Neurons: 64, Grad norm: 1.480e+00\n",
      "Epoch 7180, Loss: 2.49143648147583, Neurons: 64, Grad norm: 1.480e+00\n",
      "Epoch 7181, Loss: 2.4841196537017822, Neurons: 64, Grad norm: 1.475e+00\n",
      "Epoch 7181, Loss: 2.4841196537017822, Neurons: 64, Grad norm: 1.475e+00\n",
      "Epoch 7182, Loss: 2.4768176078796387, Neurons: 64, Grad norm: 1.441e+00\n",
      "Epoch 7182, Loss: 2.4768176078796387, Neurons: 64, Grad norm: 1.441e+00\n",
      "Epoch 7183, Loss: 2.469529628753662, Neurons: 64, Grad norm: 1.437e+00\n",
      "Epoch 7183, Loss: 2.469529628753662, Neurons: 64, Grad norm: 1.437e+00\n",
      "Epoch 7184, Loss: 2.4622583389282227, Neurons: 64, Grad norm: 1.440e+00\n",
      "Epoch 7184, Loss: 2.4622583389282227, Neurons: 64, Grad norm: 1.440e+00\n",
      "Epoch 7185, Loss: 2.4550023078918457, Neurons: 64, Grad norm: 1.443e+00\n",
      "Epoch 7185, Loss: 2.4550023078918457, Neurons: 64, Grad norm: 1.443e+00\n",
      "Epoch 7186, Loss: 2.447761297225952, Neurons: 64, Grad norm: 1.442e+00\n",
      "Epoch 7186, Loss: 2.447761297225952, Neurons: 64, Grad norm: 1.442e+00\n",
      "Epoch 7187, Loss: 2.440534830093384, Neurons: 64, Grad norm: 1.439e+00\n",
      "Epoch 7187, Loss: 2.440534830093384, Neurons: 64, Grad norm: 1.439e+00\n",
      "Epoch 7188, Loss: 2.4333250522613525, Neurons: 64, Grad norm: 1.438e+00\n",
      "Epoch 7188, Loss: 2.4333250522613525, Neurons: 64, Grad norm: 1.438e+00\n",
      "Epoch 7189, Loss: 2.4261317253112793, Neurons: 64, Grad norm: 1.438e+00\n",
      "Epoch 7189, Loss: 2.4261317253112793, Neurons: 64, Grad norm: 1.438e+00\n",
      "Epoch 7190, Loss: 2.4189531803131104, Neurons: 64, Grad norm: 1.439e+00\n",
      "Epoch 7190, Loss: 2.4189531803131104, Neurons: 64, Grad norm: 1.439e+00\n",
      "Epoch 7191, Loss: 2.4117915630340576, Neurons: 64, Grad norm: 1.432e+00\n",
      "Epoch 7191, Loss: 2.4117915630340576, Neurons: 64, Grad norm: 1.432e+00\n",
      "Epoch 7192, Loss: 2.4046459197998047, Neurons: 64, Grad norm: 1.448e+00\n",
      "Epoch 7192, Loss: 2.4046459197998047, Neurons: 64, Grad norm: 1.448e+00\n",
      "Epoch 7193, Loss: 2.397517204284668, Neurons: 64, Grad norm: 1.436e+00\n",
      "Epoch 7193, Loss: 2.397517204284668, Neurons: 64, Grad norm: 1.436e+00\n",
      "Epoch 7194, Loss: 2.39040470123291, Neurons: 64, Grad norm: 1.408e+00\n",
      "Epoch 7194, Loss: 2.39040470123291, Neurons: 64, Grad norm: 1.408e+00\n",
      "Epoch 7195, Loss: 2.383310079574585, Neurons: 64, Grad norm: 1.413e+00\n",
      "Epoch 7195, Loss: 2.383310079574585, Neurons: 64, Grad norm: 1.413e+00\n",
      "Epoch 7196, Loss: 2.3762316703796387, Neurons: 64, Grad norm: 1.423e+00\n",
      "Epoch 7196, Loss: 2.3762316703796387, Neurons: 64, Grad norm: 1.423e+00\n",
      "Epoch 7197, Loss: 2.369168996810913, Neurons: 64, Grad norm: 1.422e+00\n",
      "Epoch 7197, Loss: 2.369168996810913, Neurons: 64, Grad norm: 1.422e+00\n",
      "Epoch 7198, Loss: 2.362123489379883, Neurons: 64, Grad norm: 1.415e+00\n",
      "Epoch 7198, Loss: 2.362123489379883, Neurons: 64, Grad norm: 1.415e+00\n",
      "Epoch 7199, Loss: 2.355095386505127, Neurons: 64, Grad norm: 1.436e+00\n",
      "Epoch 7199, Loss: 2.355095386505127, Neurons: 64, Grad norm: 1.436e+00\n",
      "Epoch 7199, Test loss: 2.0257174968719482\n",
      "Epoch 7199, Test loss: 2.0257174968719482\n",
      "Epoch 7200, Loss: 2.34808349609375, Neurons: 64, Grad norm: 1.409e+00\n",
      "Epoch 7200, Loss: 2.34808349609375, Neurons: 64, Grad norm: 1.409e+00\n",
      "Epoch 7201, Loss: 2.3410913944244385, Neurons: 64, Grad norm: 1.431e+00\n",
      "Epoch 7201, Loss: 2.3410913944244385, Neurons: 64, Grad norm: 1.431e+00\n",
      "Epoch 7202, Loss: 2.334113836288452, Neurons: 64, Grad norm: 1.399e+00\n",
      "Epoch 7202, Loss: 2.334113836288452, Neurons: 64, Grad norm: 1.399e+00\n",
      "Epoch 7203, Loss: 2.3271567821502686, Neurons: 64, Grad norm: 1.393e+00\n",
      "Epoch 7203, Loss: 2.3271567821502686, Neurons: 64, Grad norm: 1.393e+00\n",
      "Epoch 7204, Loss: 2.320215940475464, Neurons: 64, Grad norm: 1.389e+00\n",
      "Epoch 7204, Loss: 2.320215940475464, Neurons: 64, Grad norm: 1.389e+00\n",
      "Epoch 7205, Loss: 2.3132920265197754, Neurons: 64, Grad norm: 1.395e+00\n",
      "Epoch 7205, Loss: 2.3132920265197754, Neurons: 64, Grad norm: 1.395e+00\n",
      "Epoch 7206, Loss: 2.3063857555389404, Neurons: 64, Grad norm: 1.393e+00\n",
      "Epoch 7206, Loss: 2.3063857555389404, Neurons: 64, Grad norm: 1.393e+00\n",
      "Epoch 7207, Loss: 2.2994985580444336, Neurons: 64, Grad norm: 1.417e+00\n",
      "Epoch 7207, Loss: 2.2994985580444336, Neurons: 64, Grad norm: 1.417e+00\n",
      "Epoch 7208, Loss: 2.292630910873413, Neurons: 64, Grad norm: 1.409e+00\n",
      "Epoch 7208, Loss: 2.292630910873413, Neurons: 64, Grad norm: 1.409e+00\n",
      "Epoch 7209, Loss: 2.2857794761657715, Neurons: 64, Grad norm: 1.376e+00\n",
      "Epoch 7209, Loss: 2.2857794761657715, Neurons: 64, Grad norm: 1.376e+00\n",
      "Epoch 7210, Loss: 2.2789478302001953, Neurons: 64, Grad norm: 1.375e+00\n",
      "Epoch 7210, Loss: 2.2789478302001953, Neurons: 64, Grad norm: 1.375e+00\n",
      "Epoch 7211, Loss: 2.272134304046631, Neurons: 64, Grad norm: 1.384e+00\n",
      "Epoch 7211, Loss: 2.272134304046631, Neurons: 64, Grad norm: 1.384e+00\n",
      "Epoch 7212, Loss: 2.26533842086792, Neurons: 64, Grad norm: 1.376e+00\n",
      "Epoch 7212, Loss: 2.26533842086792, Neurons: 64, Grad norm: 1.376e+00\n",
      "Epoch 7213, Loss: 2.258561849594116, Neurons: 64, Grad norm: 1.371e+00\n",
      "Epoch 7213, Loss: 2.258561849594116, Neurons: 64, Grad norm: 1.371e+00\n",
      "Epoch 7214, Loss: 2.251803398132324, Neurons: 64, Grad norm: 1.392e+00\n",
      "Epoch 7214, Loss: 2.251803398132324, Neurons: 64, Grad norm: 1.392e+00\n",
      "Epoch 7215, Loss: 2.245065212249756, Neurons: 64, Grad norm: 1.386e+00\n",
      "Epoch 7215, Loss: 2.245065212249756, Neurons: 64, Grad norm: 1.386e+00\n",
      "Epoch 7216, Loss: 2.238345146179199, Neurons: 64, Grad norm: 1.358e+00\n",
      "Epoch 7216, Loss: 2.238345146179199, Neurons: 64, Grad norm: 1.358e+00\n",
      "Epoch 7217, Loss: 2.2316441535949707, Neurons: 64, Grad norm: 1.358e+00\n",
      "Epoch 7217, Loss: 2.2316441535949707, Neurons: 64, Grad norm: 1.358e+00\n",
      "Epoch 7218, Loss: 2.224961519241333, Neurons: 64, Grad norm: 1.391e+00\n",
      "Epoch 7218, Loss: 2.224961519241333, Neurons: 64, Grad norm: 1.391e+00\n",
      "Epoch 7219, Loss: 2.218301296234131, Neurons: 64, Grad norm: 1.346e+00\n",
      "Epoch 7219, Loss: 2.218301296234131, Neurons: 64, Grad norm: 1.346e+00\n",
      "Epoch 7220, Loss: 2.211658239364624, Neurons: 64, Grad norm: 1.342e+00\n",
      "Epoch 7220, Loss: 2.211658239364624, Neurons: 64, Grad norm: 1.342e+00\n",
      "Epoch 7221, Loss: 2.2050347328186035, Neurons: 64, Grad norm: 1.368e+00\n",
      "Epoch 7221, Loss: 2.2050347328186035, Neurons: 64, Grad norm: 1.368e+00\n",
      "Epoch 7222, Loss: 2.198430299758911, Neurons: 64, Grad norm: 1.348e+00\n",
      "Epoch 7222, Loss: 2.198430299758911, Neurons: 64, Grad norm: 1.348e+00\n",
      "Epoch 7223, Loss: 2.1918468475341797, Neurons: 64, Grad norm: 1.365e+00\n",
      "Epoch 7223, Loss: 2.1918468475341797, Neurons: 64, Grad norm: 1.365e+00\n",
      "Epoch 7224, Loss: 2.185281991958618, Neurons: 64, Grad norm: 1.333e+00\n",
      "Epoch 7224, Loss: 2.185281991958618, Neurons: 64, Grad norm: 1.333e+00\n",
      "Epoch 7225, Loss: 2.178739309310913, Neurons: 64, Grad norm: 1.330e+00\n",
      "Epoch 7225, Loss: 2.178739309310913, Neurons: 64, Grad norm: 1.330e+00\n",
      "Epoch 7226, Loss: 2.1722140312194824, Neurons: 64, Grad norm: 1.330e+00\n",
      "Epoch 7226, Loss: 2.1722140312194824, Neurons: 64, Grad norm: 1.330e+00\n",
      "Epoch 7227, Loss: 2.1657097339630127, Neurons: 64, Grad norm: 1.360e+00\n",
      "Epoch 7227, Loss: 2.1657097339630127, Neurons: 64, Grad norm: 1.360e+00\n",
      "Epoch 7228, Loss: 2.159227132797241, Neurons: 64, Grad norm: 1.346e+00\n",
      "Epoch 7228, Loss: 2.159227132797241, Neurons: 64, Grad norm: 1.346e+00\n",
      "Epoch 7229, Loss: 2.1527633666992188, Neurons: 64, Grad norm: 1.309e+00\n",
      "Epoch 7229, Loss: 2.1527633666992188, Neurons: 64, Grad norm: 1.309e+00\n",
      "Epoch 7230, Loss: 2.14631986618042, Neurons: 64, Grad norm: 1.331e+00\n",
      "Epoch 7230, Loss: 2.14631986618042, Neurons: 64, Grad norm: 1.331e+00\n",
      "Epoch 7231, Loss: 2.139897584915161, Neurons: 64, Grad norm: 1.311e+00\n",
      "Epoch 7231, Loss: 2.139897584915161, Neurons: 64, Grad norm: 1.311e+00\n",
      "Epoch 7232, Loss: 2.133495807647705, Neurons: 64, Grad norm: 1.313e+00\n",
      "Epoch 7232, Loss: 2.133495807647705, Neurons: 64, Grad norm: 1.313e+00\n",
      "Epoch 7233, Loss: 2.1271145343780518, Neurons: 64, Grad norm: 1.333e+00\n",
      "Epoch 7233, Loss: 2.1271145343780518, Neurons: 64, Grad norm: 1.333e+00\n",
      "Epoch 7234, Loss: 2.120753526687622, Neurons: 64, Grad norm: 1.302e+00\n",
      "Epoch 7234, Loss: 2.120753526687622, Neurons: 64, Grad norm: 1.302e+00\n",
      "Epoch 7235, Loss: 2.114414691925049, Neurons: 64, Grad norm: 1.321e+00\n",
      "Epoch 7235, Loss: 2.114414691925049, Neurons: 64, Grad norm: 1.321e+00\n",
      "Epoch 7236, Loss: 2.108095407485962, Neurons: 64, Grad norm: 1.317e+00\n",
      "Epoch 7236, Loss: 2.108095407485962, Neurons: 64, Grad norm: 1.317e+00\n",
      "Epoch 7237, Loss: 2.1017963886260986, Neurons: 64, Grad norm: 1.284e+00\n",
      "Epoch 7237, Loss: 2.1017963886260986, Neurons: 64, Grad norm: 1.284e+00\n",
      "Epoch 7238, Loss: 2.095520496368408, Neurons: 64, Grad norm: 1.283e+00\n",
      "Epoch 7238, Loss: 2.095520496368408, Neurons: 64, Grad norm: 1.283e+00\n",
      "Epoch 7239, Loss: 2.089264154434204, Neurons: 64, Grad norm: 1.283e+00\n",
      "Epoch 7239, Loss: 2.089264154434204, Neurons: 64, Grad norm: 1.283e+00\n",
      "Epoch 7240, Loss: 2.0830297470092773, Neurons: 64, Grad norm: 1.304e+00\n",
      "Epoch 7240, Loss: 2.0830297470092773, Neurons: 64, Grad norm: 1.304e+00\n",
      "Epoch 7241, Loss: 2.076815605163574, Neurons: 64, Grad norm: 1.295e+00\n",
      "Epoch 7241, Loss: 2.076815605163574, Neurons: 64, Grad norm: 1.295e+00\n",
      "Epoch 7242, Loss: 2.070622682571411, Neurons: 64, Grad norm: 1.293e+00\n",
      "Epoch 7242, Loss: 2.070622682571411, Neurons: 64, Grad norm: 1.293e+00\n",
      "Epoch 7243, Loss: 2.0644516944885254, Neurons: 64, Grad norm: 1.286e+00\n",
      "Epoch 7243, Loss: 2.0644516944885254, Neurons: 64, Grad norm: 1.286e+00\n",
      "Epoch 7244, Loss: 2.0583009719848633, Neurons: 64, Grad norm: 1.260e+00\n",
      "Epoch 7244, Loss: 2.0583009719848633, Neurons: 64, Grad norm: 1.260e+00\n",
      "Epoch 7245, Loss: 2.0521724224090576, Neurons: 64, Grad norm: 1.260e+00\n",
      "Epoch 7245, Loss: 2.0521724224090576, Neurons: 64, Grad norm: 1.260e+00\n",
      "Epoch 7246, Loss: 2.046065330505371, Neurons: 64, Grad norm: 1.254e+00\n",
      "Epoch 7246, Loss: 2.046065330505371, Neurons: 64, Grad norm: 1.254e+00\n",
      "Epoch 7247, Loss: 2.0399792194366455, Neurons: 64, Grad norm: 1.271e+00\n",
      "Epoch 7247, Loss: 2.0399792194366455, Neurons: 64, Grad norm: 1.271e+00\n",
      "Epoch 7248, Loss: 2.0339133739471436, Neurons: 64, Grad norm: 1.265e+00\n",
      "Epoch 7248, Loss: 2.0339133739471436, Neurons: 64, Grad norm: 1.265e+00\n",
      "Epoch 7249, Loss: 2.027869939804077, Neurons: 64, Grad norm: 1.262e+00\n",
      "Epoch 7249, Loss: 2.027869939804077, Neurons: 64, Grad norm: 1.262e+00\n",
      "Epoch 7250, Loss: 2.02184796333313, Neurons: 64, Grad norm: 1.266e+00\n",
      "Epoch 7250, Loss: 2.02184796333313, Neurons: 64, Grad norm: 1.266e+00\n",
      "Epoch 7251, Loss: 2.0158469676971436, Neurons: 64, Grad norm: 1.238e+00\n",
      "Epoch 7251, Loss: 2.0158469676971436, Neurons: 64, Grad norm: 1.238e+00\n",
      "Epoch 7252, Loss: 2.0098679065704346, Neurons: 64, Grad norm: 1.233e+00\n",
      "Epoch 7252, Loss: 2.0098679065704346, Neurons: 64, Grad norm: 1.233e+00\n",
      "Epoch 7253, Loss: 2.0039095878601074, Neurons: 64, Grad norm: 1.225e+00\n",
      "Epoch 7253, Loss: 2.0039095878601074, Neurons: 64, Grad norm: 1.225e+00\n",
      "Epoch 7254, Loss: 1.9979726076126099, Neurons: 64, Grad norm: 1.240e+00\n",
      "Epoch 7254, Loss: 1.9979726076126099, Neurons: 64, Grad norm: 1.240e+00\n",
      "Epoch 7255, Loss: 1.9920564889907837, Neurons: 64, Grad norm: 1.230e+00\n",
      "Epoch 7255, Loss: 1.9920564889907837, Neurons: 64, Grad norm: 1.230e+00\n",
      "Epoch 7256, Loss: 1.9861624240875244, Neurons: 64, Grad norm: 1.228e+00\n",
      "Epoch 7256, Loss: 1.9861624240875244, Neurons: 64, Grad norm: 1.228e+00\n",
      "Epoch 7257, Loss: 1.9802898168563843, Neurons: 64, Grad norm: 1.229e+00\n",
      "Epoch 7257, Loss: 1.9802898168563843, Neurons: 64, Grad norm: 1.229e+00\n",
      "Epoch 7258, Loss: 1.9744385480880737, Neurons: 64, Grad norm: 1.231e+00\n",
      "Epoch 7258, Loss: 1.9744385480880737, Neurons: 64, Grad norm: 1.231e+00\n",
      "Epoch 7259, Loss: 1.9686073064804077, Neurons: 64, Grad norm: 1.220e+00\n",
      "Epoch 7259, Loss: 1.9686073064804077, Neurons: 64, Grad norm: 1.220e+00\n",
      "Epoch 7260, Loss: 1.9627975225448608, Neurons: 64, Grad norm: 1.189e+00\n",
      "Epoch 7260, Loss: 1.9627975225448608, Neurons: 64, Grad norm: 1.189e+00\n",
      "Epoch 7261, Loss: 1.95701003074646, Neurons: 64, Grad norm: 1.186e+00\n",
      "Epoch 7261, Loss: 1.95701003074646, Neurons: 64, Grad norm: 1.186e+00\n",
      "Epoch 7262, Loss: 1.9512426853179932, Neurons: 64, Grad norm: 1.214e+00\n",
      "Epoch 7262, Loss: 1.9512426853179932, Neurons: 64, Grad norm: 1.214e+00\n",
      "Epoch 7263, Loss: 1.9454965591430664, Neurons: 64, Grad norm: 1.207e+00\n",
      "Epoch 7263, Loss: 1.9454965591430664, Neurons: 64, Grad norm: 1.207e+00\n",
      "Epoch 7264, Loss: 1.939771294593811, Neurons: 64, Grad norm: 1.195e+00\n",
      "Epoch 7264, Loss: 1.939771294593811, Neurons: 64, Grad norm: 1.195e+00\n",
      "Epoch 7265, Loss: 1.9340667724609375, Neurons: 64, Grad norm: 1.184e+00\n",
      "Epoch 7265, Loss: 1.9340667724609375, Neurons: 64, Grad norm: 1.184e+00\n",
      "Epoch 7266, Loss: 1.9283840656280518, Neurons: 64, Grad norm: 1.183e+00\n",
      "Epoch 7266, Loss: 1.9283840656280518, Neurons: 64, Grad norm: 1.183e+00\n",
      "Epoch 7267, Loss: 1.9227198362350464, Neurons: 64, Grad norm: 1.187e+00\n",
      "Epoch 7267, Loss: 1.9227198362350464, Neurons: 64, Grad norm: 1.187e+00\n",
      "Epoch 7268, Loss: 1.9170770645141602, Neurons: 64, Grad norm: 1.160e+00\n",
      "Epoch 7268, Loss: 1.9170770645141602, Neurons: 64, Grad norm: 1.160e+00\n",
      "Epoch 7269, Loss: 1.911455750465393, Neurons: 64, Grad norm: 1.155e+00\n",
      "Epoch 7269, Loss: 1.911455750465393, Neurons: 64, Grad norm: 1.155e+00\n",
      "Epoch 7270, Loss: 1.9058533906936646, Neurons: 64, Grad norm: 1.175e+00\n",
      "Epoch 7270, Loss: 1.9058533906936646, Neurons: 64, Grad norm: 1.175e+00\n",
      "Epoch 7271, Loss: 1.9002705812454224, Neurons: 64, Grad norm: 1.167e+00\n",
      "Epoch 7271, Loss: 1.9002705812454224, Neurons: 64, Grad norm: 1.167e+00\n",
      "Epoch 7272, Loss: 1.894708514213562, Neurons: 64, Grad norm: 1.160e+00\n",
      "Epoch 7272, Loss: 1.894708514213562, Neurons: 64, Grad norm: 1.160e+00\n",
      "Epoch 7273, Loss: 1.8891671895980835, Neurons: 64, Grad norm: 1.154e+00\n",
      "Epoch 7273, Loss: 1.8891671895980835, Neurons: 64, Grad norm: 1.154e+00\n",
      "Epoch 7274, Loss: 1.883643388748169, Neurons: 64, Grad norm: 1.149e+00\n",
      "Epoch 7274, Loss: 1.883643388748169, Neurons: 64, Grad norm: 1.149e+00\n",
      "Epoch 7275, Loss: 1.8781414031982422, Neurons: 64, Grad norm: 1.146e+00\n",
      "Epoch 7275, Loss: 1.8781414031982422, Neurons: 64, Grad norm: 1.146e+00\n",
      "Epoch 7276, Loss: 1.8726567029953003, Neurons: 64, Grad norm: 1.137e+00\n",
      "Epoch 7276, Loss: 1.8726567029953003, Neurons: 64, Grad norm: 1.137e+00\n",
      "Epoch 7277, Loss: 1.8671919107437134, Neurons: 64, Grad norm: 1.130e+00\n",
      "Epoch 7277, Loss: 1.8671919107437134, Neurons: 64, Grad norm: 1.130e+00\n",
      "Epoch 7278, Loss: 1.861745834350586, Neurons: 64, Grad norm: 1.127e+00\n",
      "Epoch 7278, Loss: 1.861745834350586, Neurons: 64, Grad norm: 1.127e+00\n",
      "Epoch 7279, Loss: 1.8563179969787598, Neurons: 64, Grad norm: 1.127e+00\n",
      "Epoch 7279, Loss: 1.8563179969787598, Neurons: 64, Grad norm: 1.127e+00\n",
      "Epoch 7280, Loss: 1.850907325744629, Neurons: 64, Grad norm: 1.109e+00\n",
      "Epoch 7280, Loss: 1.850907325744629, Neurons: 64, Grad norm: 1.109e+00\n",
      "Epoch 7281, Loss: 1.8455166816711426, Neurons: 64, Grad norm: 1.129e+00\n",
      "Epoch 7281, Loss: 1.8455166816711426, Neurons: 64, Grad norm: 1.129e+00\n",
      "Epoch 7282, Loss: 1.840142011642456, Neurons: 64, Grad norm: 1.121e+00\n",
      "Epoch 7282, Loss: 1.840142011642456, Neurons: 64, Grad norm: 1.121e+00\n",
      "Epoch 7283, Loss: 1.834784746170044, Neurons: 64, Grad norm: 1.113e+00\n",
      "Epoch 7283, Loss: 1.834784746170044, Neurons: 64, Grad norm: 1.113e+00\n",
      "Epoch 7284, Loss: 1.8294451236724854, Neurons: 64, Grad norm: 1.107e+00\n",
      "Epoch 7284, Loss: 1.8294451236724854, Neurons: 64, Grad norm: 1.107e+00\n",
      "Epoch 7285, Loss: 1.824122428894043, Neurons: 64, Grad norm: 1.104e+00\n",
      "Epoch 7285, Loss: 1.824122428894043, Neurons: 64, Grad norm: 1.104e+00\n",
      "Epoch 7286, Loss: 1.8188155889511108, Neurons: 64, Grad norm: 1.102e+00\n",
      "Epoch 7286, Loss: 1.8188155889511108, Neurons: 64, Grad norm: 1.102e+00\n",
      "Epoch 7287, Loss: 1.8135254383087158, Neurons: 64, Grad norm: 1.095e+00\n",
      "Epoch 7287, Loss: 1.8135254383087158, Neurons: 64, Grad norm: 1.095e+00\n",
      "Epoch 7288, Loss: 1.8082515001296997, Neurons: 64, Grad norm: 1.088e+00\n",
      "Epoch 7288, Loss: 1.8082515001296997, Neurons: 64, Grad norm: 1.088e+00\n",
      "Epoch 7289, Loss: 1.8029922246932983, Neurons: 64, Grad norm: 1.086e+00\n",
      "Epoch 7289, Loss: 1.8029922246932983, Neurons: 64, Grad norm: 1.086e+00\n",
      "Epoch 7290, Loss: 1.7977478504180908, Neurons: 64, Grad norm: 1.087e+00\n",
      "Epoch 7290, Loss: 1.7977478504180908, Neurons: 64, Grad norm: 1.087e+00\n",
      "Epoch 7291, Loss: 1.7925176620483398, Neurons: 64, Grad norm: 1.094e+00\n",
      "Epoch 7291, Loss: 1.7925176620483398, Neurons: 64, Grad norm: 1.094e+00\n",
      "Epoch 7292, Loss: 1.7873013019561768, Neurons: 64, Grad norm: 1.089e+00\n",
      "Epoch 7292, Loss: 1.7873013019561768, Neurons: 64, Grad norm: 1.089e+00\n",
      "Epoch 7293, Loss: 1.7821006774902344, Neurons: 64, Grad norm: 1.082e+00\n",
      "Epoch 7293, Loss: 1.7821006774902344, Neurons: 64, Grad norm: 1.082e+00\n",
      "Epoch 7294, Loss: 1.7769131660461426, Neurons: 64, Grad norm: 1.076e+00\n",
      "Epoch 7294, Loss: 1.7769131660461426, Neurons: 64, Grad norm: 1.076e+00\n",
      "Epoch 7295, Loss: 1.7717384099960327, Neurons: 64, Grad norm: 1.069e+00\n",
      "Epoch 7295, Loss: 1.7717384099960327, Neurons: 64, Grad norm: 1.069e+00\n",
      "Epoch 7296, Loss: 1.7665770053863525, Neurons: 64, Grad norm: 1.068e+00\n",
      "Epoch 7296, Loss: 1.7665770053863525, Neurons: 64, Grad norm: 1.068e+00\n",
      "Epoch 7297, Loss: 1.7614277601242065, Neurons: 64, Grad norm: 1.069e+00\n",
      "Epoch 7297, Loss: 1.7614277601242065, Neurons: 64, Grad norm: 1.069e+00\n",
      "Epoch 7298, Loss: 1.7562897205352783, Neurons: 64, Grad norm: 1.068e+00\n",
      "Epoch 7298, Loss: 1.7562897205352783, Neurons: 64, Grad norm: 1.068e+00\n",
      "Epoch 7299, Loss: 1.7511636018753052, Neurons: 64, Grad norm: 1.069e+00\n",
      "Epoch 7299, Loss: 1.7511636018753052, Neurons: 64, Grad norm: 1.069e+00\n",
      "Epoch 7299, Test loss: 1.4724327325820923\n",
      "Epoch 7299, Test loss: 1.4724327325820923\n",
      "Epoch 7300, Loss: 1.7460501194000244, Neurons: 64, Grad norm: 1.071e+00\n",
      "Epoch 7300, Loss: 1.7460501194000244, Neurons: 64, Grad norm: 1.071e+00\n",
      "Epoch 7301, Loss: 1.740946650505066, Neurons: 64, Grad norm: 1.076e+00\n",
      "Epoch 7301, Loss: 1.740946650505066, Neurons: 64, Grad norm: 1.076e+00\n",
      "Epoch 7302, Loss: 1.7358546257019043, Neurons: 64, Grad norm: 1.074e+00\n",
      "Epoch 7302, Loss: 1.7358546257019043, Neurons: 64, Grad norm: 1.074e+00\n",
      "Epoch 7303, Loss: 1.730772852897644, Neurons: 64, Grad norm: 1.070e+00\n",
      "Epoch 7303, Loss: 1.730772852897644, Neurons: 64, Grad norm: 1.070e+00\n",
      "Epoch 7304, Loss: 1.725701928138733, Neurons: 64, Grad norm: 1.067e+00\n",
      "Epoch 7304, Loss: 1.725701928138733, Neurons: 64, Grad norm: 1.067e+00\n",
      "Epoch 7305, Loss: 1.7206404209136963, Neurons: 64, Grad norm: 1.066e+00\n",
      "Epoch 7305, Loss: 1.7206404209136963, Neurons: 64, Grad norm: 1.066e+00\n",
      "Epoch 7306, Loss: 1.7155901193618774, Neurons: 64, Grad norm: 1.064e+00\n",
      "Epoch 7306, Loss: 1.7155901193618774, Neurons: 64, Grad norm: 1.064e+00\n",
      "Epoch 7307, Loss: 1.710548996925354, Neurons: 64, Grad norm: 1.067e+00\n",
      "Epoch 7307, Loss: 1.710548996925354, Neurons: 64, Grad norm: 1.067e+00\n",
      "Epoch 7308, Loss: 1.7055187225341797, Neurons: 64, Grad norm: 1.076e+00\n",
      "Epoch 7308, Loss: 1.7055187225341797, Neurons: 64, Grad norm: 1.076e+00\n",
      "Epoch 7309, Loss: 1.7004979848861694, Neurons: 64, Grad norm: 1.079e+00\n",
      "Epoch 7309, Loss: 1.7004979848861694, Neurons: 64, Grad norm: 1.079e+00\n",
      "Epoch 7310, Loss: 1.6954888105392456, Neurons: 64, Grad norm: 1.080e+00\n",
      "Epoch 7310, Loss: 1.6954888105392456, Neurons: 64, Grad norm: 1.080e+00\n",
      "Epoch 7311, Loss: 1.690490484237671, Neurons: 64, Grad norm: 1.081e+00\n",
      "Epoch 7311, Loss: 1.690490484237671, Neurons: 64, Grad norm: 1.081e+00\n",
      "Epoch 7312, Loss: 1.6855015754699707, Neurons: 64, Grad norm: 1.079e+00\n",
      "Epoch 7312, Loss: 1.6855015754699707, Neurons: 64, Grad norm: 1.079e+00\n",
      "Epoch 7313, Loss: 1.680524230003357, Neurons: 64, Grad norm: 1.084e+00\n",
      "Epoch 7313, Loss: 1.680524230003357, Neurons: 64, Grad norm: 1.084e+00\n",
      "Epoch 7314, Loss: 1.675559639930725, Neurons: 64, Grad norm: 1.084e+00\n",
      "Epoch 7314, Loss: 1.675559639930725, Neurons: 64, Grad norm: 1.084e+00\n",
      "Epoch 7315, Loss: 1.6706076860427856, Neurons: 64, Grad norm: 1.082e+00\n",
      "Epoch 7315, Loss: 1.6706076860427856, Neurons: 64, Grad norm: 1.082e+00\n",
      "Epoch 7316, Loss: 1.6656684875488281, Neurons: 64, Grad norm: 1.082e+00\n",
      "Epoch 7316, Loss: 1.6656684875488281, Neurons: 64, Grad norm: 1.082e+00\n",
      "Epoch 7317, Loss: 1.660742163658142, Neurons: 64, Grad norm: 1.083e+00\n",
      "Epoch 7317, Loss: 1.660742163658142, Neurons: 64, Grad norm: 1.083e+00\n",
      "Epoch 7318, Loss: 1.655831217765808, Neurons: 64, Grad norm: 1.083e+00\n",
      "Epoch 7318, Loss: 1.655831217765808, Neurons: 64, Grad norm: 1.083e+00\n",
      "Epoch 7319, Loss: 1.6509349346160889, Neurons: 64, Grad norm: 1.087e+00\n",
      "Epoch 7319, Loss: 1.6509349346160889, Neurons: 64, Grad norm: 1.087e+00\n",
      "Epoch 7320, Loss: 1.6460545063018799, Neurons: 64, Grad norm: 1.085e+00\n",
      "Epoch 7320, Loss: 1.6460545063018799, Neurons: 64, Grad norm: 1.085e+00\n",
      "Epoch 7321, Loss: 1.6411906480789185, Neurons: 64, Grad norm: 1.082e+00\n",
      "Epoch 7321, Loss: 1.6411906480789185, Neurons: 64, Grad norm: 1.082e+00\n",
      "Epoch 7322, Loss: 1.636344075202942, Neurons: 64, Grad norm: 1.078e+00\n",
      "Epoch 7322, Loss: 1.636344075202942, Neurons: 64, Grad norm: 1.078e+00\n",
      "Epoch 7323, Loss: 1.631515622138977, Neurons: 64, Grad norm: 1.076e+00\n",
      "Epoch 7323, Loss: 1.631515622138977, Neurons: 64, Grad norm: 1.076e+00\n",
      "Epoch 7324, Loss: 1.6267057657241821, Neurons: 64, Grad norm: 1.073e+00\n",
      "Epoch 7324, Loss: 1.6267057657241821, Neurons: 64, Grad norm: 1.073e+00\n",
      "Epoch 7325, Loss: 1.62191641330719, Neurons: 64, Grad norm: 1.069e+00\n",
      "Epoch 7325, Loss: 1.62191641330719, Neurons: 64, Grad norm: 1.069e+00\n",
      "Epoch 7326, Loss: 1.61714506149292, Neurons: 64, Grad norm: 1.065e+00\n",
      "Epoch 7326, Loss: 1.61714506149292, Neurons: 64, Grad norm: 1.065e+00\n",
      "Epoch 7327, Loss: 1.6123952865600586, Neurons: 64, Grad norm: 1.062e+00\n",
      "Epoch 7327, Loss: 1.6123952865600586, Neurons: 64, Grad norm: 1.062e+00\n",
      "Epoch 7328, Loss: 1.607666254043579, Neurons: 64, Grad norm: 1.058e+00\n",
      "Epoch 7328, Loss: 1.607666254043579, Neurons: 64, Grad norm: 1.058e+00\n",
      "Epoch 7329, Loss: 1.6029579639434814, Neurons: 64, Grad norm: 1.062e+00\n",
      "Epoch 7329, Loss: 1.6029579639434814, Neurons: 64, Grad norm: 1.062e+00\n",
      "Epoch 7330, Loss: 1.5982728004455566, Neurons: 64, Grad norm: 1.056e+00\n",
      "Epoch 7330, Loss: 1.5982728004455566, Neurons: 64, Grad norm: 1.056e+00\n",
      "Epoch 7331, Loss: 1.59360933303833, Neurons: 64, Grad norm: 1.043e+00\n",
      "Epoch 7331, Loss: 1.59360933303833, Neurons: 64, Grad norm: 1.043e+00\n",
      "Epoch 7332, Loss: 1.5889688730239868, Neurons: 64, Grad norm: 1.038e+00\n",
      "Epoch 7332, Loss: 1.5889688730239868, Neurons: 64, Grad norm: 1.038e+00\n",
      "Epoch 7333, Loss: 1.5843507051467896, Neurons: 64, Grad norm: 1.034e+00\n",
      "Epoch 7333, Loss: 1.5843507051467896, Neurons: 64, Grad norm: 1.034e+00\n",
      "Epoch 7334, Loss: 1.5797559022903442, Neurons: 64, Grad norm: 1.030e+00\n",
      "Epoch 7334, Loss: 1.5797559022903442, Neurons: 64, Grad norm: 1.030e+00\n",
      "Epoch 7335, Loss: 1.5751830339431763, Neurons: 64, Grad norm: 1.026e+00\n",
      "Epoch 7335, Loss: 1.5751830339431763, Neurons: 64, Grad norm: 1.026e+00\n",
      "Epoch 7336, Loss: 1.570634126663208, Neurons: 64, Grad norm: 1.022e+00\n",
      "Epoch 7336, Loss: 1.570634126663208, Neurons: 64, Grad norm: 1.022e+00\n",
      "Epoch 7337, Loss: 1.5661088228225708, Neurons: 64, Grad norm: 1.023e+00\n",
      "Epoch 7337, Loss: 1.5661088228225708, Neurons: 64, Grad norm: 1.023e+00\n",
      "Epoch 7338, Loss: 1.561607003211975, Neurons: 64, Grad norm: 1.018e+00\n",
      "Epoch 7338, Loss: 1.561607003211975, Neurons: 64, Grad norm: 1.018e+00\n",
      "Epoch 7339, Loss: 1.557128667831421, Neurons: 64, Grad norm: 1.013e+00\n",
      "Epoch 7339, Loss: 1.557128667831421, Neurons: 64, Grad norm: 1.013e+00\n",
      "Epoch 7340, Loss: 1.552672028541565, Neurons: 64, Grad norm: 1.002e+00\n",
      "Epoch 7340, Loss: 1.552672028541565, Neurons: 64, Grad norm: 1.002e+00\n",
      "Epoch 7341, Loss: 1.5482405424118042, Neurons: 64, Grad norm: 9.967e-01\n",
      "Epoch 7341, Loss: 1.5482405424118042, Neurons: 64, Grad norm: 9.967e-01\n",
      "Epoch 7342, Loss: 1.5438318252563477, Neurons: 64, Grad norm: 9.915e-01\n",
      "Epoch 7342, Loss: 1.5438318252563477, Neurons: 64, Grad norm: 9.915e-01\n",
      "Epoch 7343, Loss: 1.539444923400879, Neurons: 64, Grad norm: 9.883e-01\n",
      "Epoch 7343, Loss: 1.539444923400879, Neurons: 64, Grad norm: 9.883e-01\n",
      "Epoch 7344, Loss: 1.5350821018218994, Neurons: 64, Grad norm: 9.856e-01\n",
      "Epoch 7344, Loss: 1.5350821018218994, Neurons: 64, Grad norm: 9.856e-01\n",
      "Epoch 7345, Loss: 1.530741810798645, Neurons: 64, Grad norm: 9.840e-01\n",
      "Epoch 7345, Loss: 1.530741810798645, Neurons: 64, Grad norm: 9.840e-01\n",
      "Epoch 7346, Loss: 1.526424527168274, Neurons: 64, Grad norm: 9.865e-01\n",
      "Epoch 7346, Loss: 1.526424527168274, Neurons: 64, Grad norm: 9.865e-01\n",
      "Epoch 7347, Loss: 1.5221290588378906, Neurons: 64, Grad norm: 9.816e-01\n",
      "Epoch 7347, Loss: 1.5221290588378906, Neurons: 64, Grad norm: 9.816e-01\n",
      "Epoch 7348, Loss: 1.517856478691101, Neurons: 64, Grad norm: 9.750e-01\n",
      "Epoch 7348, Loss: 1.517856478691101, Neurons: 64, Grad norm: 9.750e-01\n",
      "Epoch 7349, Loss: 1.5136055946350098, Neurons: 64, Grad norm: 9.644e-01\n",
      "Epoch 7349, Loss: 1.5136055946350098, Neurons: 64, Grad norm: 9.644e-01\n",
      "Epoch 7350, Loss: 1.5093770027160645, Neurons: 64, Grad norm: 9.597e-01\n",
      "Epoch 7350, Loss: 1.5093770027160645, Neurons: 64, Grad norm: 9.597e-01\n",
      "Epoch 7351, Loss: 1.5051711797714233, Neurons: 64, Grad norm: 9.574e-01\n",
      "Epoch 7351, Loss: 1.5051711797714233, Neurons: 64, Grad norm: 9.574e-01\n",
      "Epoch 7352, Loss: 1.5009862184524536, Neurons: 64, Grad norm: 9.597e-01\n",
      "Epoch 7352, Loss: 1.5009862184524536, Neurons: 64, Grad norm: 9.597e-01\n",
      "Epoch 7353, Loss: 1.4968223571777344, Neurons: 64, Grad norm: 9.579e-01\n",
      "Epoch 7353, Loss: 1.4968223571777344, Neurons: 64, Grad norm: 9.579e-01\n",
      "Epoch 7354, Loss: 1.492679476737976, Neurons: 64, Grad norm: 9.544e-01\n",
      "Epoch 7354, Loss: 1.492679476737976, Neurons: 64, Grad norm: 9.544e-01\n",
      "Epoch 7355, Loss: 1.4885584115982056, Neurons: 64, Grad norm: 9.469e-01\n",
      "Epoch 7355, Loss: 1.4885584115982056, Neurons: 64, Grad norm: 9.469e-01\n",
      "Epoch 7356, Loss: 1.4844568967819214, Neurons: 64, Grad norm: 9.437e-01\n",
      "Epoch 7356, Loss: 1.4844568967819214, Neurons: 64, Grad norm: 9.437e-01\n",
      "Epoch 7357, Loss: 1.4803762435913086, Neurons: 64, Grad norm: 9.413e-01\n",
      "Epoch 7357, Loss: 1.4803762435913086, Neurons: 64, Grad norm: 9.413e-01\n",
      "Epoch 7358, Loss: 1.4763171672821045, Neurons: 64, Grad norm: 9.426e-01\n",
      "Epoch 7358, Loss: 1.4763171672821045, Neurons: 64, Grad norm: 9.426e-01\n",
      "Epoch 7359, Loss: 1.4722763299942017, Neurons: 64, Grad norm: 9.395e-01\n",
      "Epoch 7359, Loss: 1.4722763299942017, Neurons: 64, Grad norm: 9.395e-01\n",
      "Epoch 7360, Loss: 1.4682557582855225, Neurons: 64, Grad norm: 9.370e-01\n",
      "Epoch 7360, Loss: 1.4682557582855225, Neurons: 64, Grad norm: 9.370e-01\n",
      "Epoch 7361, Loss: 1.46425461769104, Neurons: 64, Grad norm: 9.301e-01\n",
      "Epoch 7361, Loss: 1.46425461769104, Neurons: 64, Grad norm: 9.301e-01\n",
      "Epoch 7362, Loss: 1.460273265838623, Neurons: 64, Grad norm: 9.320e-01\n",
      "Epoch 7362, Loss: 1.460273265838623, Neurons: 64, Grad norm: 9.320e-01\n",
      "Epoch 7363, Loss: 1.4563111066818237, Neurons: 64, Grad norm: 9.243e-01\n",
      "Epoch 7363, Loss: 1.4563111066818237, Neurons: 64, Grad norm: 9.243e-01\n",
      "Epoch 7364, Loss: 1.4523662328720093, Neurons: 64, Grad norm: 9.219e-01\n",
      "Epoch 7364, Loss: 1.4523662328720093, Neurons: 64, Grad norm: 9.219e-01\n",
      "Epoch 7365, Loss: 1.4484410285949707, Neurons: 64, Grad norm: 9.242e-01\n",
      "Epoch 7365, Loss: 1.4484410285949707, Neurons: 64, Grad norm: 9.242e-01\n",
      "Epoch 7366, Loss: 1.444535255432129, Neurons: 64, Grad norm: 9.236e-01\n",
      "Epoch 7366, Loss: 1.444535255432129, Neurons: 64, Grad norm: 9.236e-01\n",
      "Epoch 7367, Loss: 1.4406465291976929, Neurons: 64, Grad norm: 9.217e-01\n",
      "Epoch 7367, Loss: 1.4406465291976929, Neurons: 64, Grad norm: 9.217e-01\n",
      "Epoch 7368, Loss: 1.436776041984558, Neurons: 64, Grad norm: 9.180e-01\n",
      "Epoch 7368, Loss: 1.436776041984558, Neurons: 64, Grad norm: 9.180e-01\n",
      "Epoch 7369, Loss: 1.4329224824905396, Neurons: 64, Grad norm: 9.109e-01\n",
      "Epoch 7369, Loss: 1.4329224824905396, Neurons: 64, Grad norm: 9.109e-01\n",
      "Epoch 7370, Loss: 1.4290863275527954, Neurons: 64, Grad norm: 9.088e-01\n",
      "Epoch 7370, Loss: 1.4290863275527954, Neurons: 64, Grad norm: 9.088e-01\n",
      "Epoch 7371, Loss: 1.4252686500549316, Neurons: 64, Grad norm: 9.082e-01\n",
      "Epoch 7371, Loss: 1.4252686500549316, Neurons: 64, Grad norm: 9.082e-01\n",
      "Epoch 7372, Loss: 1.4214675426483154, Neurons: 64, Grad norm: 9.117e-01\n",
      "Epoch 7372, Loss: 1.4214675426483154, Neurons: 64, Grad norm: 9.117e-01\n",
      "Epoch 7373, Loss: 1.4176826477050781, Neurons: 64, Grad norm: 9.095e-01\n",
      "Epoch 7373, Loss: 1.4176826477050781, Neurons: 64, Grad norm: 9.095e-01\n",
      "Epoch 7374, Loss: 1.4139143228530884, Neurons: 64, Grad norm: 9.066e-01\n",
      "Epoch 7374, Loss: 1.4139143228530884, Neurons: 64, Grad norm: 9.066e-01\n",
      "Epoch 7375, Loss: 1.4101630449295044, Neurons: 64, Grad norm: 9.032e-01\n",
      "Epoch 7375, Loss: 1.4101630449295044, Neurons: 64, Grad norm: 9.032e-01\n",
      "Epoch 7376, Loss: 1.4064278602600098, Neurons: 64, Grad norm: 8.974e-01\n",
      "Epoch 7376, Loss: 1.4064278602600098, Neurons: 64, Grad norm: 8.974e-01\n",
      "Epoch 7377, Loss: 1.4027073383331299, Neurons: 64, Grad norm: 8.966e-01\n",
      "Epoch 7377, Loss: 1.4027073383331299, Neurons: 64, Grad norm: 8.966e-01\n",
      "Epoch 7378, Loss: 1.399004578590393, Neurons: 64, Grad norm: 8.998e-01\n",
      "Epoch 7378, Loss: 1.399004578590393, Neurons: 64, Grad norm: 8.998e-01\n",
      "Epoch 7379, Loss: 1.395315170288086, Neurons: 64, Grad norm: 8.983e-01\n",
      "Epoch 7379, Loss: 1.395315170288086, Neurons: 64, Grad norm: 8.983e-01\n",
      "Epoch 7380, Loss: 1.3916422128677368, Neurons: 64, Grad norm: 8.921e-01\n",
      "Epoch 7380, Loss: 1.3916422128677368, Neurons: 64, Grad norm: 8.921e-01\n",
      "Epoch 7381, Loss: 1.387984275817871, Neurons: 64, Grad norm: 8.931e-01\n",
      "Epoch 7381, Loss: 1.387984275817871, Neurons: 64, Grad norm: 8.931e-01\n",
      "Epoch 7382, Loss: 1.3843408823013306, Neurons: 64, Grad norm: 8.923e-01\n",
      "Epoch 7382, Loss: 1.3843408823013306, Neurons: 64, Grad norm: 8.923e-01\n",
      "Epoch 7383, Loss: 1.3807127475738525, Neurons: 64, Grad norm: 8.927e-01\n",
      "Epoch 7383, Loss: 1.3807127475738525, Neurons: 64, Grad norm: 8.927e-01\n",
      "Epoch 7384, Loss: 1.377097725868225, Neurons: 64, Grad norm: 8.880e-01\n",
      "Epoch 7384, Loss: 1.377097725868225, Neurons: 64, Grad norm: 8.880e-01\n",
      "Epoch 7385, Loss: 1.373498558998108, Neurons: 64, Grad norm: 8.851e-01\n",
      "Epoch 7385, Loss: 1.373498558998108, Neurons: 64, Grad norm: 8.851e-01\n",
      "Epoch 7386, Loss: 1.3699138164520264, Neurons: 64, Grad norm: 8.863e-01\n",
      "Epoch 7386, Loss: 1.3699138164520264, Neurons: 64, Grad norm: 8.863e-01\n",
      "Epoch 7387, Loss: 1.3663426637649536, Neurons: 64, Grad norm: 8.862e-01\n",
      "Epoch 7387, Loss: 1.3663426637649536, Neurons: 64, Grad norm: 8.862e-01\n",
      "Epoch 7388, Loss: 1.3627846240997314, Neurons: 64, Grad norm: 8.862e-01\n",
      "Epoch 7388, Loss: 1.3627846240997314, Neurons: 64, Grad norm: 8.862e-01\n",
      "Epoch 7389, Loss: 1.359241247177124, Neurons: 64, Grad norm: 8.817e-01\n",
      "Epoch 7389, Loss: 1.359241247177124, Neurons: 64, Grad norm: 8.817e-01\n",
      "Epoch 7390, Loss: 1.3557103872299194, Neurons: 64, Grad norm: 8.816e-01\n",
      "Epoch 7390, Loss: 1.3557103872299194, Neurons: 64, Grad norm: 8.816e-01\n",
      "Epoch 7391, Loss: 1.3521939516067505, Neurons: 64, Grad norm: 8.763e-01\n",
      "Epoch 7391, Loss: 1.3521939516067505, Neurons: 64, Grad norm: 8.763e-01\n",
      "Epoch 7392, Loss: 1.3486897945404053, Neurons: 64, Grad norm: 8.803e-01\n",
      "Epoch 7392, Loss: 1.3486897945404053, Neurons: 64, Grad norm: 8.803e-01\n",
      "Epoch 7393, Loss: 1.345198631286621, Neurons: 64, Grad norm: 8.808e-01\n",
      "Epoch 7393, Loss: 1.345198631286621, Neurons: 64, Grad norm: 8.808e-01\n",
      "Epoch 7394, Loss: 1.3417195081710815, Neurons: 64, Grad norm: 8.782e-01\n",
      "Epoch 7394, Loss: 1.3417195081710815, Neurons: 64, Grad norm: 8.782e-01\n",
      "Epoch 7395, Loss: 1.3382542133331299, Neurons: 64, Grad norm: 8.709e-01\n",
      "Epoch 7395, Loss: 1.3382542133331299, Neurons: 64, Grad norm: 8.709e-01\n",
      "Epoch 7396, Loss: 1.3347994089126587, Neurons: 64, Grad norm: 8.740e-01\n",
      "Epoch 7396, Loss: 1.3347994089126587, Neurons: 64, Grad norm: 8.740e-01\n",
      "Epoch 7397, Loss: 1.3313591480255127, Neurons: 64, Grad norm: 8.727e-01\n",
      "Epoch 7397, Loss: 1.3313591480255127, Neurons: 64, Grad norm: 8.727e-01\n",
      "Epoch 7398, Loss: 1.327930212020874, Neurons: 64, Grad norm: 8.766e-01\n",
      "Epoch 7398, Loss: 1.327930212020874, Neurons: 64, Grad norm: 8.766e-01\n",
      "Epoch 7399, Loss: 1.3245129585266113, Neurons: 64, Grad norm: 8.742e-01\n",
      "Epoch 7399, Loss: 1.3245129585266113, Neurons: 64, Grad norm: 8.742e-01\n",
      "Epoch 7399, Test loss: 1.0940190553665161\n",
      "Epoch 7399, Test loss: 1.0940190553665161\n",
      "Epoch 7400, Loss: 1.3211071491241455, Neurons: 64, Grad norm: 8.700e-01\n",
      "Epoch 7400, Loss: 1.3211071491241455, Neurons: 64, Grad norm: 8.700e-01\n",
      "Epoch 7401, Loss: 1.317712664604187, Neurons: 64, Grad norm: 8.694e-01\n",
      "Epoch 7401, Loss: 1.317712664604187, Neurons: 64, Grad norm: 8.694e-01\n",
      "Epoch 7402, Loss: 1.314329981803894, Neurons: 64, Grad norm: 8.675e-01\n",
      "Epoch 7402, Loss: 1.314329981803894, Neurons: 64, Grad norm: 8.675e-01\n",
      "Epoch 7403, Loss: 1.3109577894210815, Neurons: 64, Grad norm: 8.675e-01\n",
      "Epoch 7403, Loss: 1.3109577894210815, Neurons: 64, Grad norm: 8.675e-01\n",
      "Epoch 7404, Loss: 1.307597279548645, Neurons: 64, Grad norm: 8.688e-01\n",
      "Epoch 7404, Loss: 1.307597279548645, Neurons: 64, Grad norm: 8.688e-01\n",
      "Epoch 7405, Loss: 1.3042471408843994, Neurons: 64, Grad norm: 8.669e-01\n",
      "Epoch 7405, Loss: 1.3042471408843994, Neurons: 64, Grad norm: 8.669e-01\n",
      "Epoch 7406, Loss: 1.300909399986267, Neurons: 64, Grad norm: 8.663e-01\n",
      "Epoch 7406, Loss: 1.300909399986267, Neurons: 64, Grad norm: 8.663e-01\n",
      "Epoch 7407, Loss: 1.2975807189941406, Neurons: 64, Grad norm: 8.669e-01\n",
      "Epoch 7407, Loss: 1.2975807189941406, Neurons: 64, Grad norm: 8.669e-01\n",
      "Epoch 7408, Loss: 1.2942640781402588, Neurons: 64, Grad norm: 8.624e-01\n",
      "Epoch 7408, Loss: 1.2942640781402588, Neurons: 64, Grad norm: 8.624e-01\n",
      "Epoch 7409, Loss: 1.2909566164016724, Neurons: 64, Grad norm: 8.611e-01\n",
      "Epoch 7409, Loss: 1.2909566164016724, Neurons: 64, Grad norm: 8.611e-01\n",
      "Epoch 7410, Loss: 1.287658929824829, Neurons: 64, Grad norm: 8.641e-01\n",
      "Epoch 7410, Loss: 1.287658929824829, Neurons: 64, Grad norm: 8.641e-01\n",
      "Epoch 7411, Loss: 1.2843724489212036, Neurons: 64, Grad norm: 8.642e-01\n",
      "Epoch 7411, Loss: 1.2843724489212036, Neurons: 64, Grad norm: 8.642e-01\n",
      "Epoch 7412, Loss: 1.2810959815979004, Neurons: 64, Grad norm: 8.628e-01\n",
      "Epoch 7412, Loss: 1.2810959815979004, Neurons: 64, Grad norm: 8.628e-01\n",
      "Epoch 7413, Loss: 1.277828335762024, Neurons: 64, Grad norm: 8.604e-01\n",
      "Epoch 7413, Loss: 1.277828335762024, Neurons: 64, Grad norm: 8.604e-01\n",
      "Epoch 7414, Loss: 1.2745720148086548, Neurons: 64, Grad norm: 8.596e-01\n",
      "Epoch 7414, Loss: 1.2745720148086548, Neurons: 64, Grad norm: 8.596e-01\n",
      "Epoch 7415, Loss: 1.2713254690170288, Neurons: 64, Grad norm: 8.593e-01\n",
      "Epoch 7415, Loss: 1.2713254690170288, Neurons: 64, Grad norm: 8.593e-01\n",
      "Epoch 7416, Loss: 1.2680869102478027, Neurons: 64, Grad norm: 8.562e-01\n",
      "Epoch 7416, Loss: 1.2680869102478027, Neurons: 64, Grad norm: 8.562e-01\n",
      "Epoch 7417, Loss: 1.2648587226867676, Neurons: 64, Grad norm: 8.542e-01\n",
      "Epoch 7417, Loss: 1.2648587226867676, Neurons: 64, Grad norm: 8.542e-01\n",
      "Epoch 7418, Loss: 1.2616404294967651, Neurons: 64, Grad norm: 8.545e-01\n",
      "Epoch 7418, Loss: 1.2616404294967651, Neurons: 64, Grad norm: 8.545e-01\n",
      "Epoch 7419, Loss: 1.2584304809570312, Neurons: 64, Grad norm: 8.610e-01\n",
      "Epoch 7419, Loss: 1.2584304809570312, Neurons: 64, Grad norm: 8.610e-01\n",
      "Epoch 7420, Loss: 1.2552300691604614, Neurons: 64, Grad norm: 8.630e-01\n",
      "Epoch 7420, Loss: 1.2552300691604614, Neurons: 64, Grad norm: 8.630e-01\n",
      "Epoch 7421, Loss: 1.2520390748977661, Neurons: 64, Grad norm: 8.597e-01\n",
      "Epoch 7421, Loss: 1.2520390748977661, Neurons: 64, Grad norm: 8.597e-01\n",
      "Epoch 7422, Loss: 1.2488572597503662, Neurons: 64, Grad norm: 8.537e-01\n",
      "Epoch 7422, Loss: 1.2488572597503662, Neurons: 64, Grad norm: 8.537e-01\n",
      "Epoch 7423, Loss: 1.2456833124160767, Neurons: 64, Grad norm: 8.516e-01\n",
      "Epoch 7423, Loss: 1.2456833124160767, Neurons: 64, Grad norm: 8.516e-01\n",
      "Epoch 7424, Loss: 1.2425198554992676, Neurons: 64, Grad norm: 8.528e-01\n",
      "Epoch 7424, Loss: 1.2425198554992676, Neurons: 64, Grad norm: 8.528e-01\n",
      "Epoch 7425, Loss: 1.2393635511398315, Neurons: 64, Grad norm: 8.530e-01\n",
      "Epoch 7425, Loss: 1.2393635511398315, Neurons: 64, Grad norm: 8.530e-01\n",
      "Epoch 7426, Loss: 1.2362165451049805, Neurons: 64, Grad norm: 8.498e-01\n",
      "Epoch 7426, Loss: 1.2362165451049805, Neurons: 64, Grad norm: 8.498e-01\n",
      "Epoch 7427, Loss: 1.2330788373947144, Neurons: 64, Grad norm: 8.492e-01\n",
      "Epoch 7427, Loss: 1.2330788373947144, Neurons: 64, Grad norm: 8.492e-01\n",
      "Epoch 7428, Loss: 1.22994863986969, Neurons: 64, Grad norm: 8.485e-01\n",
      "Epoch 7428, Loss: 1.22994863986969, Neurons: 64, Grad norm: 8.485e-01\n",
      "Epoch 7429, Loss: 1.2268277406692505, Neurons: 64, Grad norm: 8.515e-01\n",
      "Epoch 7429, Loss: 1.2268277406692505, Neurons: 64, Grad norm: 8.515e-01\n",
      "Epoch 7430, Loss: 1.2237155437469482, Neurons: 64, Grad norm: 8.521e-01\n",
      "Epoch 7430, Loss: 1.2237155437469482, Neurons: 64, Grad norm: 8.521e-01\n",
      "Epoch 7431, Loss: 1.2206119298934937, Neurons: 64, Grad norm: 8.538e-01\n",
      "Epoch 7431, Loss: 1.2206119298934937, Neurons: 64, Grad norm: 8.538e-01\n",
      "Epoch 7432, Loss: 1.2175159454345703, Neurons: 64, Grad norm: 8.509e-01\n",
      "Epoch 7432, Loss: 1.2175159454345703, Neurons: 64, Grad norm: 8.509e-01\n",
      "Epoch 7433, Loss: 1.2144290208816528, Neurons: 64, Grad norm: 8.463e-01\n",
      "Epoch 7433, Loss: 1.2144290208816528, Neurons: 64, Grad norm: 8.463e-01\n",
      "Epoch 7434, Loss: 1.2113502025604248, Neurons: 64, Grad norm: 8.450e-01\n",
      "Epoch 7434, Loss: 1.2113502025604248, Neurons: 64, Grad norm: 8.450e-01\n",
      "Epoch 7435, Loss: 1.2082799673080444, Neurons: 64, Grad norm: 8.459e-01\n",
      "Epoch 7435, Loss: 1.2082799673080444, Neurons: 64, Grad norm: 8.459e-01\n",
      "Epoch 7436, Loss: 1.2052175998687744, Neurons: 64, Grad norm: 8.449e-01\n",
      "Epoch 7436, Loss: 1.2052175998687744, Neurons: 64, Grad norm: 8.449e-01\n",
      "Epoch 7437, Loss: 1.2021642923355103, Neurons: 64, Grad norm: 8.422e-01\n",
      "Epoch 7437, Loss: 1.2021642923355103, Neurons: 64, Grad norm: 8.422e-01\n",
      "Epoch 7438, Loss: 1.199118971824646, Neurons: 64, Grad norm: 8.420e-01\n",
      "Epoch 7438, Loss: 1.199118971824646, Neurons: 64, Grad norm: 8.420e-01\n",
      "Epoch 7439, Loss: 1.1960818767547607, Neurons: 64, Grad norm: 8.439e-01\n",
      "Epoch 7439, Loss: 1.1960818767547607, Neurons: 64, Grad norm: 8.439e-01\n",
      "Epoch 7440, Loss: 1.193053960800171, Neurons: 64, Grad norm: 8.414e-01\n",
      "Epoch 7440, Loss: 1.193053960800171, Neurons: 64, Grad norm: 8.414e-01\n",
      "Epoch 7441, Loss: 1.19003427028656, Neurons: 64, Grad norm: 8.386e-01\n",
      "Epoch 7441, Loss: 1.19003427028656, Neurons: 64, Grad norm: 8.386e-01\n",
      "Epoch 7442, Loss: 1.18702232837677, Neurons: 64, Grad norm: 8.404e-01\n",
      "Epoch 7442, Loss: 1.18702232837677, Neurons: 64, Grad norm: 8.404e-01\n",
      "Epoch 7443, Loss: 1.184018850326538, Neurons: 64, Grad norm: 8.402e-01\n",
      "Epoch 7443, Loss: 1.184018850326538, Neurons: 64, Grad norm: 8.402e-01\n",
      "Epoch 7444, Loss: 1.181024193763733, Neurons: 64, Grad norm: 8.382e-01\n",
      "Epoch 7444, Loss: 1.181024193763733, Neurons: 64, Grad norm: 8.382e-01\n",
      "Epoch 7445, Loss: 1.1780381202697754, Neurons: 64, Grad norm: 8.343e-01\n",
      "Epoch 7445, Loss: 1.1780381202697754, Neurons: 64, Grad norm: 8.343e-01\n",
      "Epoch 7446, Loss: 1.1750603914260864, Neurons: 64, Grad norm: 8.332e-01\n",
      "Epoch 7446, Loss: 1.1750603914260864, Neurons: 64, Grad norm: 8.332e-01\n",
      "Epoch 7447, Loss: 1.1720913648605347, Neurons: 64, Grad norm: 8.320e-01\n",
      "Epoch 7447, Loss: 1.1720913648605347, Neurons: 64, Grad norm: 8.320e-01\n",
      "Epoch 7448, Loss: 1.1691302061080933, Neurons: 64, Grad norm: 8.334e-01\n",
      "Epoch 7448, Loss: 1.1691302061080933, Neurons: 64, Grad norm: 8.334e-01\n",
      "Epoch 7449, Loss: 1.166177749633789, Neurons: 64, Grad norm: 8.312e-01\n",
      "Epoch 7449, Loss: 1.166177749633789, Neurons: 64, Grad norm: 8.312e-01\n",
      "Epoch 7450, Loss: 1.1632338762283325, Neurons: 64, Grad norm: 8.310e-01\n",
      "Epoch 7450, Loss: 1.1632338762283325, Neurons: 64, Grad norm: 8.310e-01\n",
      "Epoch 7451, Loss: 1.1602997779846191, Neurons: 64, Grad norm: 8.272e-01\n",
      "Epoch 7451, Loss: 1.1602997779846191, Neurons: 64, Grad norm: 8.272e-01\n",
      "Epoch 7452, Loss: 1.157374620437622, Neurons: 64, Grad norm: 8.292e-01\n",
      "Epoch 7452, Loss: 1.157374620437622, Neurons: 64, Grad norm: 8.292e-01\n",
      "Epoch 7453, Loss: 1.1544578075408936, Neurons: 64, Grad norm: 8.265e-01\n",
      "Epoch 7453, Loss: 1.1544578075408936, Neurons: 64, Grad norm: 8.265e-01\n",
      "Epoch 7454, Loss: 1.15155029296875, Neurons: 64, Grad norm: 8.238e-01\n",
      "Epoch 7454, Loss: 1.15155029296875, Neurons: 64, Grad norm: 8.238e-01\n",
      "Epoch 7455, Loss: 1.148650050163269, Neurons: 64, Grad norm: 8.166e-01\n",
      "Epoch 7455, Loss: 1.148650050163269, Neurons: 64, Grad norm: 8.166e-01\n",
      "Epoch 7456, Loss: 1.145760416984558, Neurons: 64, Grad norm: 8.173e-01\n",
      "Epoch 7456, Loss: 1.145760416984558, Neurons: 64, Grad norm: 8.173e-01\n",
      "Epoch 7457, Loss: 1.1428794860839844, Neurons: 64, Grad norm: 8.208e-01\n",
      "Epoch 7457, Loss: 1.1428794860839844, Neurons: 64, Grad norm: 8.208e-01\n",
      "Epoch 7458, Loss: 1.1400080919265747, Neurons: 64, Grad norm: 8.219e-01\n",
      "Epoch 7458, Loss: 1.1400080919265747, Neurons: 64, Grad norm: 8.219e-01\n",
      "Epoch 7459, Loss: 1.1371448040008545, Neurons: 64, Grad norm: 8.130e-01\n",
      "Epoch 7459, Loss: 1.1371448040008545, Neurons: 64, Grad norm: 8.130e-01\n",
      "Epoch 7460, Loss: 1.1342908143997192, Neurons: 64, Grad norm: 8.113e-01\n",
      "Epoch 7460, Loss: 1.1342908143997192, Neurons: 64, Grad norm: 8.113e-01\n",
      "Epoch 7461, Loss: 1.1314477920532227, Neurons: 64, Grad norm: 8.134e-01\n",
      "Epoch 7461, Loss: 1.1314477920532227, Neurons: 64, Grad norm: 8.134e-01\n",
      "Epoch 7462, Loss: 1.128612995147705, Neurons: 64, Grad norm: 8.147e-01\n",
      "Epoch 7462, Loss: 1.128612995147705, Neurons: 64, Grad norm: 8.147e-01\n",
      "Epoch 7463, Loss: 1.1257879734039307, Neurons: 64, Grad norm: 8.047e-01\n",
      "Epoch 7463, Loss: 1.1257879734039307, Neurons: 64, Grad norm: 8.047e-01\n",
      "Epoch 7464, Loss: 1.1229734420776367, Neurons: 64, Grad norm: 8.010e-01\n",
      "Epoch 7464, Loss: 1.1229734420776367, Neurons: 64, Grad norm: 8.010e-01\n",
      "Epoch 7465, Loss: 1.1201668977737427, Neurons: 64, Grad norm: 8.012e-01\n",
      "Epoch 7465, Loss: 1.1201668977737427, Neurons: 64, Grad norm: 8.012e-01\n",
      "Epoch 7466, Loss: 1.1173712015151978, Neurons: 64, Grad norm: 8.028e-01\n",
      "Epoch 7466, Loss: 1.1173712015151978, Neurons: 64, Grad norm: 8.028e-01\n",
      "Epoch 7467, Loss: 1.1145845651626587, Neurons: 64, Grad norm: 7.969e-01\n",
      "Epoch 7467, Loss: 1.1145845651626587, Neurons: 64, Grad norm: 7.969e-01\n",
      "Epoch 7468, Loss: 1.111808180809021, Neurons: 64, Grad norm: 7.966e-01\n",
      "Epoch 7468, Loss: 1.111808180809021, Neurons: 64, Grad norm: 7.966e-01\n",
      "Epoch 7469, Loss: 1.1090410947799683, Neurons: 64, Grad norm: 7.948e-01\n",
      "Epoch 7469, Loss: 1.1090410947799683, Neurons: 64, Grad norm: 7.948e-01\n",
      "Epoch 7470, Loss: 1.106283187866211, Neurons: 64, Grad norm: 7.934e-01\n",
      "Epoch 7470, Loss: 1.106283187866211, Neurons: 64, Grad norm: 7.934e-01\n",
      "Epoch 7471, Loss: 1.1035369634628296, Neurons: 64, Grad norm: 7.880e-01\n",
      "Epoch 7471, Loss: 1.1035369634628296, Neurons: 64, Grad norm: 7.880e-01\n",
      "Epoch 7472, Loss: 1.100799798965454, Neurons: 64, Grad norm: 7.845e-01\n",
      "Epoch 7472, Loss: 1.100799798965454, Neurons: 64, Grad norm: 7.845e-01\n",
      "Epoch 7473, Loss: 1.0980725288391113, Neurons: 64, Grad norm: 7.858e-01\n",
      "Epoch 7473, Loss: 1.0980725288391113, Neurons: 64, Grad norm: 7.858e-01\n",
      "Epoch 7474, Loss: 1.0953556299209595, Neurons: 64, Grad norm: 7.842e-01\n",
      "Epoch 7474, Loss: 1.0953556299209595, Neurons: 64, Grad norm: 7.842e-01\n",
      "Epoch 7475, Loss: 1.0926487445831299, Neurons: 64, Grad norm: 7.822e-01\n",
      "Epoch 7475, Loss: 1.0926487445831299, Neurons: 64, Grad norm: 7.822e-01\n",
      "Epoch 7476, Loss: 1.0899524688720703, Neurons: 64, Grad norm: 7.770e-01\n",
      "Epoch 7476, Loss: 1.0899524688720703, Neurons: 64, Grad norm: 7.770e-01\n",
      "Epoch 7477, Loss: 1.0872654914855957, Neurons: 64, Grad norm: 7.725e-01\n",
      "Epoch 7477, Loss: 1.0872654914855957, Neurons: 64, Grad norm: 7.725e-01\n",
      "Epoch 7478, Loss: 1.0845893621444702, Neurons: 64, Grad norm: 7.716e-01\n",
      "Epoch 7478, Loss: 1.0845893621444702, Neurons: 64, Grad norm: 7.716e-01\n",
      "Epoch 7479, Loss: 1.0819224119186401, Neurons: 64, Grad norm: 7.681e-01\n",
      "Epoch 7479, Loss: 1.0819224119186401, Neurons: 64, Grad norm: 7.681e-01\n",
      "Epoch 7480, Loss: 1.0792659521102905, Neurons: 64, Grad norm: 7.633e-01\n",
      "Epoch 7480, Loss: 1.0792659521102905, Neurons: 64, Grad norm: 7.633e-01\n",
      "Epoch 7481, Loss: 1.0766197443008423, Neurons: 64, Grad norm: 7.598e-01\n",
      "Epoch 7481, Loss: 1.0766197443008423, Neurons: 64, Grad norm: 7.598e-01\n",
      "Epoch 7482, Loss: 1.0739836692810059, Neurons: 64, Grad norm: 7.656e-01\n",
      "Epoch 7482, Loss: 1.0739836692810059, Neurons: 64, Grad norm: 7.656e-01\n",
      "Epoch 7483, Loss: 1.071356177330017, Neurons: 64, Grad norm: 7.669e-01\n",
      "Epoch 7483, Loss: 1.071356177330017, Neurons: 64, Grad norm: 7.669e-01\n",
      "Epoch 7484, Loss: 1.0687404870986938, Neurons: 64, Grad norm: 7.607e-01\n",
      "Epoch 7484, Loss: 1.0687404870986938, Neurons: 64, Grad norm: 7.607e-01\n",
      "Epoch 7485, Loss: 1.0661343336105347, Neurons: 64, Grad norm: 7.516e-01\n",
      "Epoch 7485, Loss: 1.0661343336105347, Neurons: 64, Grad norm: 7.516e-01\n",
      "Epoch 7486, Loss: 1.0635368824005127, Neurons: 64, Grad norm: 7.495e-01\n",
      "Epoch 7486, Loss: 1.0635368824005127, Neurons: 64, Grad norm: 7.495e-01\n",
      "Epoch 7487, Loss: 1.0609500408172607, Neurons: 64, Grad norm: 7.505e-01\n",
      "Epoch 7487, Loss: 1.0609500408172607, Neurons: 64, Grad norm: 7.505e-01\n",
      "Epoch 7488, Loss: 1.0583726167678833, Neurons: 64, Grad norm: 7.447e-01\n",
      "Epoch 7488, Loss: 1.0583726167678833, Neurons: 64, Grad norm: 7.447e-01\n",
      "Epoch 7489, Loss: 1.0558050870895386, Neurons: 64, Grad norm: 7.407e-01\n",
      "Epoch 7489, Loss: 1.0558050870895386, Neurons: 64, Grad norm: 7.407e-01\n",
      "Epoch 7490, Loss: 1.0532469749450684, Neurons: 64, Grad norm: 7.398e-01\n",
      "Epoch 7490, Loss: 1.0532469749450684, Neurons: 64, Grad norm: 7.398e-01\n",
      "Epoch 7491, Loss: 1.0506988763809204, Neurons: 64, Grad norm: 7.465e-01\n",
      "Epoch 7491, Loss: 1.0506988763809204, Neurons: 64, Grad norm: 7.465e-01\n",
      "Epoch 7492, Loss: 1.0481594800949097, Neurons: 64, Grad norm: 7.461e-01\n",
      "Epoch 7492, Loss: 1.0481594800949097, Neurons: 64, Grad norm: 7.461e-01\n",
      "Epoch 7493, Loss: 1.0456302165985107, Neurons: 64, Grad norm: 7.388e-01\n",
      "Epoch 7493, Loss: 1.0456302165985107, Neurons: 64, Grad norm: 7.388e-01\n",
      "Epoch 7494, Loss: 1.0431102514266968, Neurons: 64, Grad norm: 7.313e-01\n",
      "Epoch 7494, Loss: 1.0431102514266968, Neurons: 64, Grad norm: 7.313e-01\n",
      "Epoch 7495, Loss: 1.0405992269515991, Neurons: 64, Grad norm: 7.286e-01\n",
      "Epoch 7495, Loss: 1.0405992269515991, Neurons: 64, Grad norm: 7.286e-01\n",
      "Epoch 7496, Loss: 1.0380960702896118, Neurons: 64, Grad norm: 7.261e-01\n",
      "Epoch 7496, Loss: 1.0380960702896118, Neurons: 64, Grad norm: 7.261e-01\n",
      "Epoch 7497, Loss: 1.0356040000915527, Neurons: 64, Grad norm: 7.238e-01\n",
      "Epoch 7497, Loss: 1.0356040000915527, Neurons: 64, Grad norm: 7.238e-01\n",
      "Epoch 7498, Loss: 1.0331203937530518, Neurons: 64, Grad norm: 7.249e-01\n",
      "Epoch 7498, Loss: 1.0331203937530518, Neurons: 64, Grad norm: 7.249e-01\n",
      "Epoch 7499, Loss: 1.0306445360183716, Neurons: 64, Grad norm: 7.252e-01\n",
      "Epoch 7499, Loss: 1.0306445360183716, Neurons: 64, Grad norm: 7.252e-01\n",
      "Epoch 7499, Test loss: 0.8384609818458557\n",
      "Epoch 7499, Test loss: 0.8384609818458557\n",
      "Epoch 7500, Loss: 1.028178095817566, Neurons: 64, Grad norm: 7.221e-01\n",
      "Epoch 7500, Loss: 1.028178095817566, Neurons: 64, Grad norm: 7.221e-01\n",
      "Epoch 7501, Loss: 1.025721549987793, Neurons: 64, Grad norm: 7.230e-01\n",
      "Epoch 7501, Loss: 1.025721549987793, Neurons: 64, Grad norm: 7.230e-01\n",
      "Epoch 7502, Loss: 1.0232733488082886, Neurons: 64, Grad norm: 7.184e-01\n",
      "Epoch 7502, Loss: 1.0232733488082886, Neurons: 64, Grad norm: 7.184e-01\n",
      "Epoch 7503, Loss: 1.0208334922790527, Neurons: 64, Grad norm: 7.098e-01\n",
      "Epoch 7503, Loss: 1.0208334922790527, Neurons: 64, Grad norm: 7.098e-01\n",
      "Epoch 7504, Loss: 1.018402338027954, Neurons: 64, Grad norm: 7.076e-01\n",
      "Epoch 7504, Loss: 1.018402338027954, Neurons: 64, Grad norm: 7.076e-01\n",
      "Epoch 7505, Loss: 1.0159796476364136, Neurons: 64, Grad norm: 7.106e-01\n",
      "Epoch 7505, Loss: 1.0159796476364136, Neurons: 64, Grad norm: 7.106e-01\n",
      "Epoch 7506, Loss: 1.0135654211044312, Neurons: 64, Grad norm: 7.102e-01\n",
      "Epoch 7506, Loss: 1.0135654211044312, Neurons: 64, Grad norm: 7.102e-01\n",
      "Epoch 7507, Loss: 1.0111591815948486, Neurons: 64, Grad norm: 7.084e-01\n",
      "Epoch 7507, Loss: 1.0111591815948486, Neurons: 64, Grad norm: 7.084e-01\n",
      "Epoch 7508, Loss: 1.0087615251541138, Neurons: 64, Grad norm: 7.054e-01\n",
      "Epoch 7508, Loss: 1.0087615251541138, Neurons: 64, Grad norm: 7.054e-01\n",
      "Epoch 7509, Loss: 1.0063726902008057, Neurons: 64, Grad norm: 6.998e-01\n",
      "Epoch 7509, Loss: 1.0063726902008057, Neurons: 64, Grad norm: 6.998e-01\n",
      "Epoch 7510, Loss: 1.0039907693862915, Neurons: 64, Grad norm: 6.985e-01\n",
      "Epoch 7510, Loss: 1.0039907693862915, Neurons: 64, Grad norm: 6.985e-01\n",
      "Epoch 7511, Loss: 1.001617193222046, Neurons: 64, Grad norm: 7.016e-01\n",
      "Epoch 7511, Loss: 1.001617193222046, Neurons: 64, Grad norm: 7.016e-01\n",
      "Epoch 7512, Loss: 0.9992522597312927, Neurons: 64, Grad norm: 6.988e-01\n",
      "Epoch 7512, Loss: 0.9992522597312927, Neurons: 64, Grad norm: 6.988e-01\n",
      "Epoch 7513, Loss: 0.9968951344490051, Neurons: 64, Grad norm: 6.912e-01\n",
      "Epoch 7513, Loss: 0.9968951344490051, Neurons: 64, Grad norm: 6.912e-01\n",
      "Epoch 7514, Loss: 0.9945447444915771, Neurons: 64, Grad norm: 6.932e-01\n",
      "Epoch 7514, Loss: 0.9945447444915771, Neurons: 64, Grad norm: 6.932e-01\n",
      "Epoch 7515, Loss: 0.9922031760215759, Neurons: 64, Grad norm: 6.939e-01\n",
      "Epoch 7515, Loss: 0.9922031760215759, Neurons: 64, Grad norm: 6.939e-01\n",
      "Epoch 7516, Loss: 0.9898698925971985, Neurons: 64, Grad norm: 6.888e-01\n",
      "Epoch 7516, Loss: 0.9898698925971985, Neurons: 64, Grad norm: 6.888e-01\n",
      "Epoch 7517, Loss: 0.9875442981719971, Neurons: 64, Grad norm: 6.846e-01\n",
      "Epoch 7517, Loss: 0.9875442981719971, Neurons: 64, Grad norm: 6.846e-01\n",
      "Epoch 7518, Loss: 0.9852249622344971, Neurons: 64, Grad norm: 6.865e-01\n",
      "Epoch 7518, Loss: 0.9852249622344971, Neurons: 64, Grad norm: 6.865e-01\n",
      "Epoch 7519, Loss: 0.9829148650169373, Neurons: 64, Grad norm: 6.872e-01\n",
      "Epoch 7519, Loss: 0.9829148650169373, Neurons: 64, Grad norm: 6.872e-01\n",
      "Epoch 7520, Loss: 0.9806123971939087, Neurons: 64, Grad norm: 6.856e-01\n",
      "Epoch 7520, Loss: 0.9806123971939087, Neurons: 64, Grad norm: 6.856e-01\n",
      "Epoch 7521, Loss: 0.9783167243003845, Neurons: 64, Grad norm: 6.812e-01\n",
      "Epoch 7521, Loss: 0.9783167243003845, Neurons: 64, Grad norm: 6.812e-01\n",
      "Epoch 7522, Loss: 0.9760292172431946, Neurons: 64, Grad norm: 6.749e-01\n",
      "Epoch 7522, Loss: 0.9760292172431946, Neurons: 64, Grad norm: 6.749e-01\n",
      "Epoch 7523, Loss: 0.9737480878829956, Neurons: 64, Grad norm: 6.736e-01\n",
      "Epoch 7523, Loss: 0.9737480878829956, Neurons: 64, Grad norm: 6.736e-01\n",
      "Epoch 7524, Loss: 0.9714757800102234, Neurons: 64, Grad norm: 6.779e-01\n",
      "Epoch 7524, Loss: 0.9714757800102234, Neurons: 64, Grad norm: 6.779e-01\n",
      "Epoch 7525, Loss: 0.9692108631134033, Neurons: 64, Grad norm: 6.760e-01\n",
      "Epoch 7525, Loss: 0.9692108631134033, Neurons: 64, Grad norm: 6.760e-01\n",
      "Epoch 7526, Loss: 0.9669525623321533, Neurons: 64, Grad norm: 6.689e-01\n",
      "Epoch 7526, Loss: 0.9669525623321533, Neurons: 64, Grad norm: 6.689e-01\n",
      "Epoch 7527, Loss: 0.964702308177948, Neurons: 64, Grad norm: 6.695e-01\n",
      "Epoch 7527, Loss: 0.964702308177948, Neurons: 64, Grad norm: 6.695e-01\n",
      "Epoch 7528, Loss: 0.962459921836853, Neurons: 64, Grad norm: 6.704e-01\n",
      "Epoch 7528, Loss: 0.962459921836853, Neurons: 64, Grad norm: 6.704e-01\n",
      "Epoch 7529, Loss: 0.9602243304252625, Neurons: 64, Grad norm: 6.668e-01\n",
      "Epoch 7529, Loss: 0.9602243304252625, Neurons: 64, Grad norm: 6.668e-01\n",
      "Epoch 7530, Loss: 0.9579950571060181, Neurons: 64, Grad norm: 6.652e-01\n",
      "Epoch 7530, Loss: 0.9579950571060181, Neurons: 64, Grad norm: 6.652e-01\n",
      "Epoch 7531, Loss: 0.9557740688323975, Neurons: 64, Grad norm: 6.618e-01\n",
      "Epoch 7531, Loss: 0.9557740688323975, Neurons: 64, Grad norm: 6.618e-01\n",
      "Epoch 7532, Loss: 0.9535599946975708, Neurons: 64, Grad norm: 6.594e-01\n",
      "Epoch 7532, Loss: 0.9535599946975708, Neurons: 64, Grad norm: 6.594e-01\n",
      "Epoch 7533, Loss: 0.9513529539108276, Neurons: 64, Grad norm: 6.598e-01\n",
      "Epoch 7533, Loss: 0.9513529539108276, Neurons: 64, Grad norm: 6.598e-01\n",
      "Epoch 7534, Loss: 0.9491534233093262, Neurons: 64, Grad norm: 6.618e-01\n",
      "Epoch 7534, Loss: 0.9491534233093262, Neurons: 64, Grad norm: 6.618e-01\n",
      "Epoch 7535, Loss: 0.9469607472419739, Neurons: 64, Grad norm: 6.585e-01\n",
      "Epoch 7535, Loss: 0.9469607472419739, Neurons: 64, Grad norm: 6.585e-01\n",
      "Epoch 7536, Loss: 0.9447749853134155, Neurons: 64, Grad norm: 6.550e-01\n",
      "Epoch 7536, Loss: 0.9447749853134155, Neurons: 64, Grad norm: 6.550e-01\n",
      "Epoch 7537, Loss: 0.9425962567329407, Neurons: 64, Grad norm: 6.529e-01\n",
      "Epoch 7537, Loss: 0.9425962567329407, Neurons: 64, Grad norm: 6.529e-01\n",
      "Epoch 7538, Loss: 0.9404247999191284, Neurons: 64, Grad norm: 6.488e-01\n",
      "Epoch 7538, Loss: 0.9404247999191284, Neurons: 64, Grad norm: 6.488e-01\n",
      "Epoch 7539, Loss: 0.9382607340812683, Neurons: 64, Grad norm: 6.509e-01\n",
      "Epoch 7539, Loss: 0.9382607340812683, Neurons: 64, Grad norm: 6.509e-01\n",
      "Epoch 7540, Loss: 0.9361029863357544, Neurons: 64, Grad norm: 6.461e-01\n",
      "Epoch 7540, Loss: 0.9361029863357544, Neurons: 64, Grad norm: 6.461e-01\n",
      "Epoch 7541, Loss: 0.9339525699615479, Neurons: 64, Grad norm: 6.450e-01\n",
      "Epoch 7541, Loss: 0.9339525699615479, Neurons: 64, Grad norm: 6.450e-01\n",
      "Epoch 7542, Loss: 0.9318086504936218, Neurons: 64, Grad norm: 6.473e-01\n",
      "Epoch 7542, Loss: 0.9318086504936218, Neurons: 64, Grad norm: 6.473e-01\n",
      "Epoch 7543, Loss: 0.9296719431877136, Neurons: 64, Grad norm: 6.463e-01\n",
      "Epoch 7543, Loss: 0.9296719431877136, Neurons: 64, Grad norm: 6.463e-01\n",
      "Epoch 7544, Loss: 0.9275435209274292, Neurons: 64, Grad norm: 6.446e-01\n",
      "Epoch 7544, Loss: 0.9275435209274292, Neurons: 64, Grad norm: 6.446e-01\n",
      "Epoch 7545, Loss: 0.9254197478294373, Neurons: 64, Grad norm: 6.403e-01\n",
      "Epoch 7545, Loss: 0.9254197478294373, Neurons: 64, Grad norm: 6.403e-01\n",
      "Epoch 7546, Loss: 0.9233030080795288, Neurons: 64, Grad norm: 6.367e-01\n",
      "Epoch 7546, Loss: 0.9233030080795288, Neurons: 64, Grad norm: 6.367e-01\n",
      "Epoch 7547, Loss: 0.9211934208869934, Neurons: 64, Grad norm: 6.332e-01\n",
      "Epoch 7547, Loss: 0.9211934208869934, Neurons: 64, Grad norm: 6.332e-01\n",
      "Epoch 7548, Loss: 0.9190908074378967, Neurons: 64, Grad norm: 6.331e-01\n",
      "Epoch 7548, Loss: 0.9190908074378967, Neurons: 64, Grad norm: 6.331e-01\n",
      "Epoch 7549, Loss: 0.916995108127594, Neurons: 64, Grad norm: 6.334e-01\n",
      "Epoch 7549, Loss: 0.916995108127594, Neurons: 64, Grad norm: 6.334e-01\n",
      "Epoch 7550, Loss: 0.9149054288864136, Neurons: 64, Grad norm: 6.355e-01\n",
      "Epoch 7550, Loss: 0.9149054288864136, Neurons: 64, Grad norm: 6.355e-01\n",
      "Epoch 7551, Loss: 0.9128229022026062, Neurons: 64, Grad norm: 6.331e-01\n",
      "Epoch 7551, Loss: 0.9128229022026062, Neurons: 64, Grad norm: 6.331e-01\n",
      "Epoch 7552, Loss: 0.9107468724250793, Neurons: 64, Grad norm: 6.291e-01\n",
      "Epoch 7552, Loss: 0.9107468724250793, Neurons: 64, Grad norm: 6.291e-01\n",
      "Epoch 7553, Loss: 0.9086776375770569, Neurons: 64, Grad norm: 6.261e-01\n",
      "Epoch 7553, Loss: 0.9086776375770569, Neurons: 64, Grad norm: 6.261e-01\n",
      "Epoch 7554, Loss: 0.9066146016120911, Neurons: 64, Grad norm: 6.246e-01\n",
      "Epoch 7554, Loss: 0.9066146016120911, Neurons: 64, Grad norm: 6.246e-01\n",
      "Epoch 7555, Loss: 0.9045582413673401, Neurons: 64, Grad norm: 6.216e-01\n",
      "Epoch 7555, Loss: 0.9045582413673401, Neurons: 64, Grad norm: 6.216e-01\n",
      "Epoch 7556, Loss: 0.9025081992149353, Neurons: 64, Grad norm: 6.173e-01\n",
      "Epoch 7556, Loss: 0.9025081992149353, Neurons: 64, Grad norm: 6.173e-01\n",
      "Epoch 7557, Loss: 0.9004656076431274, Neurons: 64, Grad norm: 6.180e-01\n",
      "Epoch 7557, Loss: 0.9004656076431274, Neurons: 64, Grad norm: 6.180e-01\n",
      "Epoch 7558, Loss: 0.8984286189079285, Neurons: 64, Grad norm: 6.216e-01\n",
      "Epoch 7558, Loss: 0.8984286189079285, Neurons: 64, Grad norm: 6.216e-01\n",
      "Epoch 7559, Loss: 0.8963983654975891, Neurons: 64, Grad norm: 6.266e-01\n",
      "Epoch 7559, Loss: 0.8963983654975891, Neurons: 64, Grad norm: 6.266e-01\n",
      "Epoch 7560, Loss: 0.8943747282028198, Neurons: 64, Grad norm: 6.213e-01\n",
      "Epoch 7560, Loss: 0.8943747282028198, Neurons: 64, Grad norm: 6.213e-01\n",
      "Epoch 7561, Loss: 0.8923571705818176, Neurons: 64, Grad norm: 6.140e-01\n",
      "Epoch 7561, Loss: 0.8923571705818176, Neurons: 64, Grad norm: 6.140e-01\n",
      "Epoch 7562, Loss: 0.89034503698349, Neurons: 64, Grad norm: 6.109e-01\n",
      "Epoch 7562, Loss: 0.89034503698349, Neurons: 64, Grad norm: 6.109e-01\n",
      "Epoch 7563, Loss: 0.8883398771286011, Neurons: 64, Grad norm: 6.085e-01\n",
      "Epoch 7563, Loss: 0.8883398771286011, Neurons: 64, Grad norm: 6.085e-01\n",
      "Epoch 7564, Loss: 0.8863410353660583, Neurons: 64, Grad norm: 6.087e-01\n",
      "Epoch 7564, Loss: 0.8863410353660583, Neurons: 64, Grad norm: 6.087e-01\n",
      "Epoch 7565, Loss: 0.8843491673469543, Neurons: 64, Grad norm: 6.047e-01\n",
      "Epoch 7565, Loss: 0.8843491673469543, Neurons: 64, Grad norm: 6.047e-01\n",
      "Epoch 7566, Loss: 0.8823623061180115, Neurons: 64, Grad norm: 6.076e-01\n",
      "Epoch 7566, Loss: 0.8823623061180115, Neurons: 64, Grad norm: 6.076e-01\n",
      "Epoch 7567, Loss: 0.8803829550743103, Neurons: 64, Grad norm: 6.094e-01\n",
      "Epoch 7567, Loss: 0.8803829550743103, Neurons: 64, Grad norm: 6.094e-01\n",
      "Epoch 7568, Loss: 0.8784067630767822, Neurons: 64, Grad norm: 6.090e-01\n",
      "Epoch 7568, Loss: 0.8784067630767822, Neurons: 64, Grad norm: 6.090e-01\n",
      "Epoch 7569, Loss: 0.8764399886131287, Neurons: 64, Grad norm: 6.021e-01\n",
      "Epoch 7569, Loss: 0.8764399886131287, Neurons: 64, Grad norm: 6.021e-01\n",
      "Epoch 7570, Loss: 0.8744783401489258, Neurons: 64, Grad norm: 5.979e-01\n",
      "Epoch 7570, Loss: 0.8744783401489258, Neurons: 64, Grad norm: 5.979e-01\n",
      "Epoch 7571, Loss: 0.8725227117538452, Neurons: 64, Grad norm: 5.988e-01\n",
      "Epoch 7571, Loss: 0.8725227117538452, Neurons: 64, Grad norm: 5.988e-01\n",
      "Epoch 7572, Loss: 0.8705724477767944, Neurons: 64, Grad norm: 5.989e-01\n",
      "Epoch 7572, Loss: 0.8705724477767944, Neurons: 64, Grad norm: 5.989e-01\n",
      "Epoch 7573, Loss: 0.8686293363571167, Neurons: 64, Grad norm: 5.968e-01\n",
      "Epoch 7573, Loss: 0.8686293363571167, Neurons: 64, Grad norm: 5.968e-01\n",
      "Epoch 7574, Loss: 0.866692066192627, Neurons: 64, Grad norm: 5.948e-01\n",
      "Epoch 7574, Loss: 0.866692066192627, Neurons: 64, Grad norm: 5.948e-01\n",
      "Epoch 7575, Loss: 0.8647599220275879, Neurons: 64, Grad norm: 5.931e-01\n",
      "Epoch 7575, Loss: 0.8647599220275879, Neurons: 64, Grad norm: 5.931e-01\n",
      "Epoch 7576, Loss: 0.8628343343734741, Neurons: 64, Grad norm: 5.931e-01\n",
      "Epoch 7576, Loss: 0.8628343343734741, Neurons: 64, Grad norm: 5.931e-01\n",
      "Epoch 7577, Loss: 0.8609139919281006, Neurons: 64, Grad norm: 5.915e-01\n",
      "Epoch 7577, Loss: 0.8609139919281006, Neurons: 64, Grad norm: 5.915e-01\n",
      "Epoch 7578, Loss: 0.8590008020401001, Neurons: 64, Grad norm: 5.915e-01\n",
      "Epoch 7578, Loss: 0.8590008020401001, Neurons: 64, Grad norm: 5.915e-01\n",
      "Epoch 7579, Loss: 0.8570927977561951, Neurons: 64, Grad norm: 5.887e-01\n",
      "Epoch 7579, Loss: 0.8570927977561951, Neurons: 64, Grad norm: 5.887e-01\n",
      "Epoch 7580, Loss: 0.8551903963088989, Neurons: 64, Grad norm: 5.869e-01\n",
      "Epoch 7580, Loss: 0.8551903963088989, Neurons: 64, Grad norm: 5.869e-01\n",
      "Epoch 7581, Loss: 0.853293776512146, Neurons: 64, Grad norm: 5.844e-01\n",
      "Epoch 7581, Loss: 0.853293776512146, Neurons: 64, Grad norm: 5.844e-01\n",
      "Epoch 7582, Loss: 0.851403534412384, Neurons: 64, Grad norm: 5.811e-01\n",
      "Epoch 7582, Loss: 0.851403534412384, Neurons: 64, Grad norm: 5.811e-01\n",
      "Epoch 7583, Loss: 0.8495185375213623, Neurons: 64, Grad norm: 5.800e-01\n",
      "Epoch 7583, Loss: 0.8495185375213623, Neurons: 64, Grad norm: 5.800e-01\n",
      "Epoch 7584, Loss: 0.8476394414901733, Neurons: 64, Grad norm: 5.786e-01\n",
      "Epoch 7584, Loss: 0.8476394414901733, Neurons: 64, Grad norm: 5.786e-01\n",
      "Epoch 7585, Loss: 0.845766007900238, Neurons: 64, Grad norm: 5.784e-01\n",
      "Epoch 7585, Loss: 0.845766007900238, Neurons: 64, Grad norm: 5.784e-01\n",
      "Epoch 7586, Loss: 0.8438981175422668, Neurons: 64, Grad norm: 5.820e-01\n",
      "Epoch 7586, Loss: 0.8438981175422668, Neurons: 64, Grad norm: 5.820e-01\n",
      "Epoch 7587, Loss: 0.8420355916023254, Neurons: 64, Grad norm: 5.787e-01\n",
      "Epoch 7587, Loss: 0.8420355916023254, Neurons: 64, Grad norm: 5.787e-01\n",
      "Epoch 7588, Loss: 0.8401790857315063, Neurons: 64, Grad norm: 5.786e-01\n",
      "Epoch 7588, Loss: 0.8401790857315063, Neurons: 64, Grad norm: 5.786e-01\n",
      "Epoch 7589, Loss: 0.8383285999298096, Neurons: 64, Grad norm: 5.741e-01\n",
      "Epoch 7589, Loss: 0.8383285999298096, Neurons: 64, Grad norm: 5.741e-01\n",
      "Epoch 7590, Loss: 0.8364834189414978, Neurons: 64, Grad norm: 5.715e-01\n",
      "Epoch 7590, Loss: 0.8364834189414978, Neurons: 64, Grad norm: 5.715e-01\n",
      "Epoch 7591, Loss: 0.8346433639526367, Neurons: 64, Grad norm: 5.685e-01\n",
      "Epoch 7591, Loss: 0.8346433639526367, Neurons: 64, Grad norm: 5.685e-01\n",
      "Epoch 7592, Loss: 0.8328081965446472, Neurons: 64, Grad norm: 5.683e-01\n",
      "Epoch 7592, Loss: 0.8328081965446472, Neurons: 64, Grad norm: 5.683e-01\n",
      "Epoch 7593, Loss: 0.8309803009033203, Neurons: 64, Grad norm: 5.657e-01\n",
      "Epoch 7593, Loss: 0.8309803009033203, Neurons: 64, Grad norm: 5.657e-01\n",
      "Epoch 7594, Loss: 0.8291566371917725, Neurons: 64, Grad norm: 5.689e-01\n",
      "Epoch 7594, Loss: 0.8291566371917725, Neurons: 64, Grad norm: 5.689e-01\n",
      "Epoch 7595, Loss: 0.8273381590843201, Neurons: 64, Grad norm: 5.694e-01\n",
      "Epoch 7595, Loss: 0.8273381590843201, Neurons: 64, Grad norm: 5.694e-01\n",
      "Epoch 7596, Loss: 0.8255264163017273, Neurons: 64, Grad norm: 5.671e-01\n",
      "Epoch 7596, Loss: 0.8255264163017273, Neurons: 64, Grad norm: 5.671e-01\n",
      "Epoch 7597, Loss: 0.8237190246582031, Neurons: 64, Grad norm: 5.617e-01\n",
      "Epoch 7597, Loss: 0.8237190246582031, Neurons: 64, Grad norm: 5.617e-01\n",
      "Epoch 7598, Loss: 0.8219168186187744, Neurons: 64, Grad norm: 5.596e-01\n",
      "Epoch 7598, Loss: 0.8219168186187744, Neurons: 64, Grad norm: 5.596e-01\n",
      "Epoch 7599, Loss: 0.8201203942298889, Neurons: 64, Grad norm: 5.608e-01\n",
      "Epoch 7599, Loss: 0.8201203942298889, Neurons: 64, Grad norm: 5.608e-01\n",
      "Epoch 7599, Test loss: 0.6579813957214355\n",
      "Epoch 7599, Test loss: 0.6579813957214355\n",
      "Epoch 7600, Loss: 0.8183293342590332, Neurons: 64, Grad norm: 5.596e-01\n",
      "Epoch 7600, Loss: 0.8183293342590332, Neurons: 64, Grad norm: 5.596e-01\n",
      "Epoch 7601, Loss: 0.8165431022644043, Neurons: 64, Grad norm: 5.564e-01\n",
      "Epoch 7601, Loss: 0.8165431022644043, Neurons: 64, Grad norm: 5.564e-01\n",
      "Epoch 7602, Loss: 0.8147629499435425, Neurons: 64, Grad norm: 5.527e-01\n",
      "Epoch 7602, Loss: 0.8147629499435425, Neurons: 64, Grad norm: 5.527e-01\n",
      "Epoch 7603, Loss: 0.8129873275756836, Neurons: 64, Grad norm: 5.561e-01\n",
      "Epoch 7603, Loss: 0.8129873275756836, Neurons: 64, Grad norm: 5.561e-01\n",
      "Epoch 7604, Loss: 0.8112173080444336, Neurons: 64, Grad norm: 5.553e-01\n",
      "Epoch 7604, Loss: 0.8112173080444336, Neurons: 64, Grad norm: 5.553e-01\n",
      "Epoch 7605, Loss: 0.8094522953033447, Neurons: 64, Grad norm: 5.548e-01\n",
      "Epoch 7605, Loss: 0.8094522953033447, Neurons: 64, Grad norm: 5.548e-01\n",
      "Epoch 7606, Loss: 0.8076921701431274, Neurons: 64, Grad norm: 5.510e-01\n",
      "Epoch 7606, Loss: 0.8076921701431274, Neurons: 64, Grad norm: 5.510e-01\n",
      "Epoch 7607, Loss: 0.8059375286102295, Neurons: 64, Grad norm: 5.484e-01\n",
      "Epoch 7607, Loss: 0.8059375286102295, Neurons: 64, Grad norm: 5.484e-01\n",
      "Epoch 7608, Loss: 0.8041871786117554, Neurons: 64, Grad norm: 5.515e-01\n",
      "Epoch 7608, Loss: 0.8041871786117554, Neurons: 64, Grad norm: 5.515e-01\n",
      "Epoch 7609, Loss: 0.8024425506591797, Neurons: 64, Grad norm: 5.489e-01\n",
      "Epoch 7609, Loss: 0.8024425506591797, Neurons: 64, Grad norm: 5.489e-01\n",
      "Epoch 7610, Loss: 0.8007029294967651, Neurons: 64, Grad norm: 5.429e-01\n",
      "Epoch 7610, Loss: 0.8007029294967651, Neurons: 64, Grad norm: 5.429e-01\n",
      "Epoch 7611, Loss: 0.7989681959152222, Neurons: 64, Grad norm: 5.423e-01\n",
      "Epoch 7611, Loss: 0.7989681959152222, Neurons: 64, Grad norm: 5.423e-01\n",
      "Epoch 7612, Loss: 0.797239363193512, Neurons: 64, Grad norm: 5.419e-01\n",
      "Epoch 7612, Loss: 0.797239363193512, Neurons: 64, Grad norm: 5.419e-01\n",
      "Epoch 7613, Loss: 0.7955144643783569, Neurons: 64, Grad norm: 5.456e-01\n",
      "Epoch 7613, Loss: 0.7955144643783569, Neurons: 64, Grad norm: 5.456e-01\n",
      "Epoch 7614, Loss: 0.7937954664230347, Neurons: 64, Grad norm: 5.434e-01\n",
      "Epoch 7614, Loss: 0.7937954664230347, Neurons: 64, Grad norm: 5.434e-01\n",
      "Epoch 7615, Loss: 0.7920801043510437, Neurons: 64, Grad norm: 5.396e-01\n",
      "Epoch 7615, Loss: 0.7920801043510437, Neurons: 64, Grad norm: 5.396e-01\n",
      "Epoch 7616, Loss: 0.790370523929596, Neurons: 64, Grad norm: 5.364e-01\n",
      "Epoch 7616, Loss: 0.790370523929596, Neurons: 64, Grad norm: 5.364e-01\n",
      "Epoch 7617, Loss: 0.7886655926704407, Neurons: 64, Grad norm: 5.370e-01\n",
      "Epoch 7617, Loss: 0.7886655926704407, Neurons: 64, Grad norm: 5.370e-01\n",
      "Epoch 7618, Loss: 0.7869653701782227, Neurons: 64, Grad norm: 5.391e-01\n",
      "Epoch 7618, Loss: 0.7869653701782227, Neurons: 64, Grad norm: 5.391e-01\n",
      "Epoch 7619, Loss: 0.7852697372436523, Neurons: 64, Grad norm: 5.356e-01\n",
      "Epoch 7619, Loss: 0.7852697372436523, Neurons: 64, Grad norm: 5.356e-01\n",
      "Epoch 7620, Loss: 0.7835788726806641, Neurons: 64, Grad norm: 5.327e-01\n",
      "Epoch 7620, Loss: 0.7835788726806641, Neurons: 64, Grad norm: 5.327e-01\n",
      "Epoch 7621, Loss: 0.7818931937217712, Neurons: 64, Grad norm: 5.301e-01\n",
      "Epoch 7621, Loss: 0.7818931937217712, Neurons: 64, Grad norm: 5.301e-01\n",
      "Epoch 7622, Loss: 0.7802118062973022, Neurons: 64, Grad norm: 5.318e-01\n",
      "Epoch 7622, Loss: 0.7802118062973022, Neurons: 64, Grad norm: 5.318e-01\n",
      "Epoch 7623, Loss: 0.7785353064537048, Neurons: 64, Grad norm: 5.350e-01\n",
      "Epoch 7623, Loss: 0.7785353064537048, Neurons: 64, Grad norm: 5.350e-01\n",
      "Epoch 7624, Loss: 0.7768632173538208, Neurons: 64, Grad norm: 5.311e-01\n",
      "Epoch 7624, Loss: 0.7768632173538208, Neurons: 64, Grad norm: 5.311e-01\n",
      "Epoch 7625, Loss: 0.7751961946487427, Neurons: 64, Grad norm: 5.266e-01\n",
      "Epoch 7625, Loss: 0.7751961946487427, Neurons: 64, Grad norm: 5.266e-01\n",
      "Epoch 7626, Loss: 0.7735337018966675, Neurons: 64, Grad norm: 5.251e-01\n",
      "Epoch 7626, Loss: 0.7735337018966675, Neurons: 64, Grad norm: 5.251e-01\n",
      "Epoch 7627, Loss: 0.7718751430511475, Neurons: 64, Grad norm: 5.252e-01\n",
      "Epoch 7627, Loss: 0.7718751430511475, Neurons: 64, Grad norm: 5.252e-01\n",
      "Epoch 7628, Loss: 0.7702217102050781, Neurons: 64, Grad norm: 5.245e-01\n",
      "Epoch 7628, Loss: 0.7702217102050781, Neurons: 64, Grad norm: 5.245e-01\n",
      "Epoch 7629, Loss: 0.7685728073120117, Neurons: 64, Grad norm: 5.237e-01\n",
      "Epoch 7629, Loss: 0.7685728073120117, Neurons: 64, Grad norm: 5.237e-01\n",
      "Epoch 7630, Loss: 0.7669282555580139, Neurons: 64, Grad norm: 5.228e-01\n",
      "Epoch 7630, Loss: 0.7669282555580139, Neurons: 64, Grad norm: 5.228e-01\n",
      "Epoch 7631, Loss: 0.765288233757019, Neurons: 64, Grad norm: 5.218e-01\n",
      "Epoch 7631, Loss: 0.765288233757019, Neurons: 64, Grad norm: 5.218e-01\n",
      "Epoch 7632, Loss: 0.7636525630950928, Neurons: 64, Grad norm: 5.242e-01\n",
      "Epoch 7632, Loss: 0.7636525630950928, Neurons: 64, Grad norm: 5.242e-01\n",
      "Epoch 7633, Loss: 0.762021005153656, Neurons: 64, Grad norm: 5.211e-01\n",
      "Epoch 7633, Loss: 0.762021005153656, Neurons: 64, Grad norm: 5.211e-01\n",
      "Epoch 7634, Loss: 0.7603952884674072, Neurons: 64, Grad norm: 5.152e-01\n",
      "Epoch 7634, Loss: 0.7603952884674072, Neurons: 64, Grad norm: 5.152e-01\n",
      "Epoch 7635, Loss: 0.7587726712226868, Neurons: 64, Grad norm: 5.130e-01\n",
      "Epoch 7635, Loss: 0.7587726712226868, Neurons: 64, Grad norm: 5.130e-01\n",
      "Epoch 7636, Loss: 0.7571550607681274, Neurons: 64, Grad norm: 5.160e-01\n",
      "Epoch 7636, Loss: 0.7571550607681274, Neurons: 64, Grad norm: 5.160e-01\n",
      "Epoch 7637, Loss: 0.7555415630340576, Neurons: 64, Grad norm: 5.183e-01\n",
      "Epoch 7637, Loss: 0.7555415630340576, Neurons: 64, Grad norm: 5.183e-01\n",
      "Epoch 7638, Loss: 0.7539317607879639, Neurons: 64, Grad norm: 5.167e-01\n",
      "Epoch 7638, Loss: 0.7539317607879639, Neurons: 64, Grad norm: 5.167e-01\n",
      "Epoch 7639, Loss: 0.7523269653320312, Neurons: 64, Grad norm: 5.114e-01\n",
      "Epoch 7639, Loss: 0.7523269653320312, Neurons: 64, Grad norm: 5.114e-01\n",
      "Epoch 7640, Loss: 0.7507264614105225, Neurons: 64, Grad norm: 5.089e-01\n",
      "Epoch 7640, Loss: 0.7507264614105225, Neurons: 64, Grad norm: 5.089e-01\n",
      "Epoch 7641, Loss: 0.7491301894187927, Neurons: 64, Grad norm: 5.110e-01\n",
      "Epoch 7641, Loss: 0.7491301894187927, Neurons: 64, Grad norm: 5.110e-01\n",
      "Epoch 7642, Loss: 0.7475384473800659, Neurons: 64, Grad norm: 5.124e-01\n",
      "Epoch 7642, Loss: 0.7475384473800659, Neurons: 64, Grad norm: 5.124e-01\n",
      "Epoch 7643, Loss: 0.7459502220153809, Neurons: 64, Grad norm: 5.074e-01\n",
      "Epoch 7643, Loss: 0.7459502220153809, Neurons: 64, Grad norm: 5.074e-01\n",
      "Epoch 7644, Loss: 0.7443659901618958, Neurons: 64, Grad norm: 5.040e-01\n",
      "Epoch 7644, Loss: 0.7443659901618958, Neurons: 64, Grad norm: 5.040e-01\n",
      "Epoch 7645, Loss: 0.7427870035171509, Neurons: 64, Grad norm: 5.065e-01\n",
      "Epoch 7645, Loss: 0.7427870035171509, Neurons: 64, Grad norm: 5.065e-01\n",
      "Epoch 7646, Loss: 0.7412111163139343, Neurons: 64, Grad norm: 5.083e-01\n",
      "Epoch 7646, Loss: 0.7412111163139343, Neurons: 64, Grad norm: 5.083e-01\n",
      "Epoch 7647, Loss: 0.7396393418312073, Neurons: 64, Grad norm: 5.042e-01\n",
      "Epoch 7647, Loss: 0.7396393418312073, Neurons: 64, Grad norm: 5.042e-01\n",
      "Epoch 7648, Loss: 0.7380722761154175, Neurons: 64, Grad norm: 5.005e-01\n",
      "Epoch 7648, Loss: 0.7380722761154175, Neurons: 64, Grad norm: 5.005e-01\n",
      "Epoch 7649, Loss: 0.7365086078643799, Neurons: 64, Grad norm: 5.022e-01\n",
      "Epoch 7649, Loss: 0.7365086078643799, Neurons: 64, Grad norm: 5.022e-01\n",
      "Epoch 7650, Loss: 0.7349509596824646, Neurons: 64, Grad norm: 5.044e-01\n",
      "Epoch 7650, Loss: 0.7349509596824646, Neurons: 64, Grad norm: 5.044e-01\n",
      "Epoch 7651, Loss: 0.7333948612213135, Neurons: 64, Grad norm: 5.026e-01\n",
      "Epoch 7651, Loss: 0.7333948612213135, Neurons: 64, Grad norm: 5.026e-01\n",
      "Epoch 7652, Loss: 0.7318435907363892, Neurons: 64, Grad norm: 4.966e-01\n",
      "Epoch 7652, Loss: 0.7318435907363892, Neurons: 64, Grad norm: 4.966e-01\n",
      "Epoch 7653, Loss: 0.7302966117858887, Neurons: 64, Grad norm: 4.942e-01\n",
      "Epoch 7653, Loss: 0.7302966117858887, Neurons: 64, Grad norm: 4.942e-01\n",
      "Epoch 7654, Loss: 0.7287534475326538, Neurons: 64, Grad norm: 4.966e-01\n",
      "Epoch 7654, Loss: 0.7287534475326538, Neurons: 64, Grad norm: 4.966e-01\n",
      "Epoch 7655, Loss: 0.727213978767395, Neurons: 64, Grad norm: 4.981e-01\n",
      "Epoch 7655, Loss: 0.727213978767395, Neurons: 64, Grad norm: 4.981e-01\n",
      "Epoch 7656, Loss: 0.7256789207458496, Neurons: 64, Grad norm: 4.950e-01\n",
      "Epoch 7656, Loss: 0.7256789207458496, Neurons: 64, Grad norm: 4.950e-01\n",
      "Epoch 7657, Loss: 0.7241467237472534, Neurons: 64, Grad norm: 4.921e-01\n",
      "Epoch 7657, Loss: 0.7241467237472534, Neurons: 64, Grad norm: 4.921e-01\n",
      "Epoch 7658, Loss: 0.7226192951202393, Neurons: 64, Grad norm: 4.933e-01\n",
      "Epoch 7658, Loss: 0.7226192951202393, Neurons: 64, Grad norm: 4.933e-01\n",
      "Epoch 7659, Loss: 0.7210954427719116, Neurons: 64, Grad norm: 4.926e-01\n",
      "Epoch 7659, Loss: 0.7210954427719116, Neurons: 64, Grad norm: 4.926e-01\n",
      "Epoch 7660, Loss: 0.719575822353363, Neurons: 64, Grad norm: 4.936e-01\n",
      "Epoch 7660, Loss: 0.719575822353363, Neurons: 64, Grad norm: 4.936e-01\n",
      "Epoch 7661, Loss: 0.7180597186088562, Neurons: 64, Grad norm: 4.895e-01\n",
      "Epoch 7661, Loss: 0.7180597186088562, Neurons: 64, Grad norm: 4.895e-01\n",
      "Epoch 7662, Loss: 0.716546893119812, Neurons: 64, Grad norm: 4.878e-01\n",
      "Epoch 7662, Loss: 0.716546893119812, Neurons: 64, Grad norm: 4.878e-01\n",
      "Epoch 7663, Loss: 0.7150379419326782, Neurons: 64, Grad norm: 4.865e-01\n",
      "Epoch 7663, Loss: 0.7150379419326782, Neurons: 64, Grad norm: 4.865e-01\n",
      "Epoch 7664, Loss: 0.7135337591171265, Neurons: 64, Grad norm: 4.861e-01\n",
      "Epoch 7664, Loss: 0.7135337591171265, Neurons: 64, Grad norm: 4.861e-01\n",
      "Epoch 7665, Loss: 0.7120317816734314, Neurons: 64, Grad norm: 4.875e-01\n",
      "Epoch 7665, Loss: 0.7120317816734314, Neurons: 64, Grad norm: 4.875e-01\n",
      "Epoch 7666, Loss: 0.7105340957641602, Neurons: 64, Grad norm: 4.870e-01\n",
      "Epoch 7666, Loss: 0.7105340957641602, Neurons: 64, Grad norm: 4.870e-01\n",
      "Epoch 7667, Loss: 0.7090408802032471, Neurons: 64, Grad norm: 4.825e-01\n",
      "Epoch 7667, Loss: 0.7090408802032471, Neurons: 64, Grad norm: 4.825e-01\n",
      "Epoch 7668, Loss: 0.7075507044792175, Neurons: 64, Grad norm: 4.833e-01\n",
      "Epoch 7668, Loss: 0.7075507044792175, Neurons: 64, Grad norm: 4.833e-01\n",
      "Epoch 7669, Loss: 0.7060641646385193, Neurons: 64, Grad norm: 4.854e-01\n",
      "Epoch 7669, Loss: 0.7060641646385193, Neurons: 64, Grad norm: 4.854e-01\n",
      "Epoch 7670, Loss: 0.7045806050300598, Neurons: 64, Grad norm: 4.813e-01\n",
      "Epoch 7670, Loss: 0.7045806050300598, Neurons: 64, Grad norm: 4.813e-01\n",
      "Epoch 7671, Loss: 0.7031010985374451, Neurons: 64, Grad norm: 4.774e-01\n",
      "Epoch 7671, Loss: 0.7031010985374451, Neurons: 64, Grad norm: 4.774e-01\n",
      "Epoch 7672, Loss: 0.7016254663467407, Neurons: 64, Grad norm: 4.796e-01\n",
      "Epoch 7672, Loss: 0.7016254663467407, Neurons: 64, Grad norm: 4.796e-01\n",
      "Epoch 7673, Loss: 0.7001535892486572, Neurons: 64, Grad norm: 4.827e-01\n",
      "Epoch 7673, Loss: 0.7001535892486572, Neurons: 64, Grad norm: 4.827e-01\n",
      "Epoch 7674, Loss: 0.6986849904060364, Neurons: 64, Grad norm: 4.816e-01\n",
      "Epoch 7674, Loss: 0.6986849904060364, Neurons: 64, Grad norm: 4.816e-01\n",
      "Epoch 7675, Loss: 0.6972193717956543, Neurons: 64, Grad norm: 4.748e-01\n",
      "Epoch 7675, Loss: 0.6972193717956543, Neurons: 64, Grad norm: 4.748e-01\n",
      "Epoch 7676, Loss: 0.6957576870918274, Neurons: 64, Grad norm: 4.716e-01\n",
      "Epoch 7676, Loss: 0.6957576870918274, Neurons: 64, Grad norm: 4.716e-01\n",
      "Epoch 7677, Loss: 0.6942992210388184, Neurons: 64, Grad norm: 4.742e-01\n",
      "Epoch 7677, Loss: 0.6942992210388184, Neurons: 64, Grad norm: 4.742e-01\n",
      "Epoch 7678, Loss: 0.6928448677062988, Neurons: 64, Grad norm: 4.776e-01\n",
      "Epoch 7678, Loss: 0.6928448677062988, Neurons: 64, Grad norm: 4.776e-01\n",
      "Epoch 7679, Loss: 0.6913930773735046, Neurons: 64, Grad norm: 4.734e-01\n",
      "Epoch 7679, Loss: 0.6913930773735046, Neurons: 64, Grad norm: 4.734e-01\n",
      "Epoch 7680, Loss: 0.6899454593658447, Neurons: 64, Grad norm: 4.705e-01\n",
      "Epoch 7680, Loss: 0.6899454593658447, Neurons: 64, Grad norm: 4.705e-01\n",
      "Epoch 7681, Loss: 0.6885004639625549, Neurons: 64, Grad norm: 4.729e-01\n",
      "Epoch 7681, Loss: 0.6885004639625549, Neurons: 64, Grad norm: 4.729e-01\n",
      "Epoch 7682, Loss: 0.6870594620704651, Neurons: 64, Grad norm: 4.733e-01\n",
      "Epoch 7682, Loss: 0.6870594620704651, Neurons: 64, Grad norm: 4.733e-01\n",
      "Epoch 7683, Loss: 0.6856213808059692, Neurons: 64, Grad norm: 4.678e-01\n",
      "Epoch 7683, Loss: 0.6856213808059692, Neurons: 64, Grad norm: 4.678e-01\n",
      "Epoch 7684, Loss: 0.6841870546340942, Neurons: 64, Grad norm: 4.657e-01\n",
      "Epoch 7684, Loss: 0.6841870546340942, Neurons: 64, Grad norm: 4.657e-01\n",
      "Epoch 7685, Loss: 0.6827555894851685, Neurons: 64, Grad norm: 4.680e-01\n",
      "Epoch 7685, Loss: 0.6827555894851685, Neurons: 64, Grad norm: 4.680e-01\n",
      "Epoch 7686, Loss: 0.6813280582427979, Neurons: 64, Grad norm: 4.698e-01\n",
      "Epoch 7686, Loss: 0.6813280582427979, Neurons: 64, Grad norm: 4.698e-01\n",
      "Epoch 7687, Loss: 0.6799034476280212, Neurons: 64, Grad norm: 4.675e-01\n",
      "Epoch 7687, Loss: 0.6799034476280212, Neurons: 64, Grad norm: 4.675e-01\n",
      "Epoch 7688, Loss: 0.6784821152687073, Neurons: 64, Grad norm: 4.622e-01\n",
      "Epoch 7688, Loss: 0.6784821152687073, Neurons: 64, Grad norm: 4.622e-01\n",
      "Epoch 7689, Loss: 0.6770642399787903, Neurons: 64, Grad norm: 4.627e-01\n",
      "Epoch 7689, Loss: 0.6770642399787903, Neurons: 64, Grad norm: 4.627e-01\n",
      "Epoch 7690, Loss: 0.6756492853164673, Neurons: 64, Grad norm: 4.636e-01\n",
      "Epoch 7690, Loss: 0.6756492853164673, Neurons: 64, Grad norm: 4.636e-01\n",
      "Epoch 7691, Loss: 0.6742380261421204, Neurons: 64, Grad norm: 4.631e-01\n",
      "Epoch 7691, Loss: 0.6742380261421204, Neurons: 64, Grad norm: 4.631e-01\n",
      "Epoch 7692, Loss: 0.6728296875953674, Neurons: 64, Grad norm: 4.608e-01\n",
      "Epoch 7692, Loss: 0.6728296875953674, Neurons: 64, Grad norm: 4.608e-01\n",
      "Epoch 7693, Loss: 0.6714242100715637, Neurons: 64, Grad norm: 4.598e-01\n",
      "Epoch 7693, Loss: 0.6714242100715637, Neurons: 64, Grad norm: 4.598e-01\n",
      "Epoch 7694, Loss: 0.6700223684310913, Neurons: 64, Grad norm: 4.600e-01\n",
      "Epoch 7694, Loss: 0.6700223684310913, Neurons: 64, Grad norm: 4.600e-01\n",
      "Epoch 7695, Loss: 0.6686238050460815, Neurons: 64, Grad norm: 4.611e-01\n",
      "Epoch 7695, Loss: 0.6686238050460815, Neurons: 64, Grad norm: 4.611e-01\n",
      "Epoch 7696, Loss: 0.6672278046607971, Neurons: 64, Grad norm: 4.594e-01\n",
      "Epoch 7696, Loss: 0.6672278046607971, Neurons: 64, Grad norm: 4.594e-01\n",
      "Epoch 7697, Loss: 0.6658356189727783, Neurons: 64, Grad norm: 4.577e-01\n",
      "Epoch 7697, Loss: 0.6658356189727783, Neurons: 64, Grad norm: 4.577e-01\n",
      "Epoch 7698, Loss: 0.664445161819458, Neurons: 64, Grad norm: 4.550e-01\n",
      "Epoch 7698, Loss: 0.664445161819458, Neurons: 64, Grad norm: 4.550e-01\n",
      "Epoch 7699, Loss: 0.6630592346191406, Neurons: 64, Grad norm: 4.536e-01\n",
      "Epoch 7699, Loss: 0.6630592346191406, Neurons: 64, Grad norm: 4.536e-01\n",
      "Epoch 7699, Test loss: 0.5246878862380981\n",
      "Epoch 7699, Test loss: 0.5246878862380981\n",
      "Epoch 7700, Loss: 0.6616758704185486, Neurons: 64, Grad norm: 4.537e-01\n",
      "Epoch 7700, Loss: 0.6616758704185486, Neurons: 64, Grad norm: 4.537e-01\n",
      "Epoch 7701, Loss: 0.6602957844734192, Neurons: 64, Grad norm: 4.532e-01\n",
      "Epoch 7701, Loss: 0.6602957844734192, Neurons: 64, Grad norm: 4.532e-01\n",
      "Epoch 7702, Loss: 0.6589184403419495, Neurons: 64, Grad norm: 4.552e-01\n",
      "Epoch 7702, Loss: 0.6589184403419495, Neurons: 64, Grad norm: 4.552e-01\n",
      "Epoch 7703, Loss: 0.657543957233429, Neurons: 64, Grad norm: 4.549e-01\n",
      "Epoch 7703, Loss: 0.657543957233429, Neurons: 64, Grad norm: 4.549e-01\n",
      "Epoch 7704, Loss: 0.6561728715896606, Neurons: 64, Grad norm: 4.527e-01\n",
      "Epoch 7704, Loss: 0.6561728715896606, Neurons: 64, Grad norm: 4.527e-01\n",
      "Epoch 7705, Loss: 0.6548041105270386, Neurons: 64, Grad norm: 4.500e-01\n",
      "Epoch 7705, Loss: 0.6548041105270386, Neurons: 64, Grad norm: 4.500e-01\n",
      "Epoch 7706, Loss: 0.6534395813941956, Neurons: 64, Grad norm: 4.477e-01\n",
      "Epoch 7706, Loss: 0.6534395813941956, Neurons: 64, Grad norm: 4.477e-01\n",
      "Epoch 7707, Loss: 0.6520770192146301, Neurons: 64, Grad norm: 4.459e-01\n",
      "Epoch 7707, Loss: 0.6520770192146301, Neurons: 64, Grad norm: 4.459e-01\n",
      "Epoch 7708, Loss: 0.6507174372673035, Neurons: 64, Grad norm: 4.466e-01\n",
      "Epoch 7708, Loss: 0.6507174372673035, Neurons: 64, Grad norm: 4.466e-01\n",
      "Epoch 7709, Loss: 0.649360179901123, Neurons: 64, Grad norm: 4.491e-01\n",
      "Epoch 7709, Loss: 0.649360179901123, Neurons: 64, Grad norm: 4.491e-01\n",
      "Epoch 7710, Loss: 0.6480066776275635, Neurons: 64, Grad norm: 4.513e-01\n",
      "Epoch 7710, Loss: 0.6480066776275635, Neurons: 64, Grad norm: 4.513e-01\n",
      "Epoch 7711, Loss: 0.6466565132141113, Neurons: 64, Grad norm: 4.488e-01\n",
      "Epoch 7711, Loss: 0.6466565132141113, Neurons: 64, Grad norm: 4.488e-01\n",
      "Epoch 7712, Loss: 0.6453084349632263, Neurons: 64, Grad norm: 4.443e-01\n",
      "Epoch 7712, Loss: 0.6453084349632263, Neurons: 64, Grad norm: 4.443e-01\n",
      "Epoch 7713, Loss: 0.6439633965492249, Neurons: 64, Grad norm: 4.421e-01\n",
      "Epoch 7713, Loss: 0.6439633965492249, Neurons: 64, Grad norm: 4.421e-01\n",
      "Epoch 7714, Loss: 0.6426215171813965, Neurons: 64, Grad norm: 4.413e-01\n",
      "Epoch 7714, Loss: 0.6426215171813965, Neurons: 64, Grad norm: 4.413e-01\n",
      "Epoch 7715, Loss: 0.64128178358078, Neurons: 64, Grad norm: 4.404e-01\n",
      "Epoch 7715, Loss: 0.64128178358078, Neurons: 64, Grad norm: 4.404e-01\n",
      "Epoch 7716, Loss: 0.6399454474449158, Neurons: 64, Grad norm: 4.423e-01\n",
      "Epoch 7716, Loss: 0.6399454474449158, Neurons: 64, Grad norm: 4.423e-01\n",
      "Epoch 7717, Loss: 0.6386111378669739, Neurons: 64, Grad norm: 4.443e-01\n",
      "Epoch 7717, Loss: 0.6386111378669739, Neurons: 64, Grad norm: 4.443e-01\n",
      "Epoch 7718, Loss: 0.637280285358429, Neurons: 64, Grad norm: 4.432e-01\n",
      "Epoch 7718, Loss: 0.637280285358429, Neurons: 64, Grad norm: 4.432e-01\n",
      "Epoch 7719, Loss: 0.635952353477478, Neurons: 64, Grad norm: 4.402e-01\n",
      "Epoch 7719, Loss: 0.635952353477478, Neurons: 64, Grad norm: 4.402e-01\n",
      "Epoch 7720, Loss: 0.6346272230148315, Neurons: 64, Grad norm: 4.371e-01\n",
      "Epoch 7720, Loss: 0.6346272230148315, Neurons: 64, Grad norm: 4.371e-01\n",
      "Epoch 7721, Loss: 0.6333047747612, Neurons: 64, Grad norm: 4.363e-01\n",
      "Epoch 7721, Loss: 0.6333047747612, Neurons: 64, Grad norm: 4.363e-01\n",
      "Epoch 7722, Loss: 0.631984293460846, Neurons: 64, Grad norm: 4.344e-01\n",
      "Epoch 7722, Loss: 0.631984293460846, Neurons: 64, Grad norm: 4.344e-01\n",
      "Epoch 7723, Loss: 0.6306670904159546, Neurons: 64, Grad norm: 4.368e-01\n",
      "Epoch 7723, Loss: 0.6306670904159546, Neurons: 64, Grad norm: 4.368e-01\n",
      "Epoch 7724, Loss: 0.629352331161499, Neurons: 64, Grad norm: 4.391e-01\n",
      "Epoch 7724, Loss: 0.629352331161499, Neurons: 64, Grad norm: 4.391e-01\n",
      "Epoch 7725, Loss: 0.6280412077903748, Neurons: 64, Grad norm: 4.384e-01\n",
      "Epoch 7725, Loss: 0.6280412077903748, Neurons: 64, Grad norm: 4.384e-01\n",
      "Epoch 7726, Loss: 0.6267319917678833, Neurons: 64, Grad norm: 4.341e-01\n",
      "Epoch 7726, Loss: 0.6267319917678833, Neurons: 64, Grad norm: 4.341e-01\n",
      "Epoch 7727, Loss: 0.6254253387451172, Neurons: 64, Grad norm: 4.314e-01\n",
      "Epoch 7727, Loss: 0.6254253387451172, Neurons: 64, Grad norm: 4.314e-01\n",
      "Epoch 7728, Loss: 0.6241213083267212, Neurons: 64, Grad norm: 4.319e-01\n",
      "Epoch 7728, Loss: 0.6241213083267212, Neurons: 64, Grad norm: 4.319e-01\n",
      "Epoch 7729, Loss: 0.6228206753730774, Neurons: 64, Grad norm: 4.303e-01\n",
      "Epoch 7729, Loss: 0.6228206753730774, Neurons: 64, Grad norm: 4.303e-01\n",
      "Epoch 7730, Loss: 0.6215221285820007, Neurons: 64, Grad norm: 4.303e-01\n",
      "Epoch 7730, Loss: 0.6215221285820007, Neurons: 64, Grad norm: 4.303e-01\n",
      "Epoch 7731, Loss: 0.6202260851860046, Neurons: 64, Grad norm: 4.309e-01\n",
      "Epoch 7731, Loss: 0.6202260851860046, Neurons: 64, Grad norm: 4.309e-01\n",
      "Epoch 7732, Loss: 0.6189331412315369, Neurons: 64, Grad norm: 4.315e-01\n",
      "Epoch 7732, Loss: 0.6189331412315369, Neurons: 64, Grad norm: 4.315e-01\n",
      "Epoch 7733, Loss: 0.617642343044281, Neurons: 64, Grad norm: 4.288e-01\n",
      "Epoch 7733, Loss: 0.617642343044281, Neurons: 64, Grad norm: 4.288e-01\n",
      "Epoch 7734, Loss: 0.6163547039031982, Neurons: 64, Grad norm: 4.263e-01\n",
      "Epoch 7734, Loss: 0.6163547039031982, Neurons: 64, Grad norm: 4.263e-01\n",
      "Epoch 7735, Loss: 0.6150687336921692, Neurons: 64, Grad norm: 4.253e-01\n",
      "Epoch 7735, Loss: 0.6150687336921692, Neurons: 64, Grad norm: 4.253e-01\n",
      "Epoch 7736, Loss: 0.6137860417366028, Neurons: 64, Grad norm: 4.255e-01\n",
      "Epoch 7736, Loss: 0.6137860417366028, Neurons: 64, Grad norm: 4.255e-01\n",
      "Epoch 7737, Loss: 0.6125054955482483, Neurons: 64, Grad norm: 4.271e-01\n",
      "Epoch 7737, Loss: 0.6125054955482483, Neurons: 64, Grad norm: 4.271e-01\n",
      "Epoch 7738, Loss: 0.6112276911735535, Neurons: 64, Grad norm: 4.270e-01\n",
      "Epoch 7738, Loss: 0.6112276911735535, Neurons: 64, Grad norm: 4.270e-01\n",
      "Epoch 7739, Loss: 0.6099527478218079, Neurons: 64, Grad norm: 4.252e-01\n",
      "Epoch 7739, Loss: 0.6099527478218079, Neurons: 64, Grad norm: 4.252e-01\n",
      "Epoch 7740, Loss: 0.6086799502372742, Neurons: 64, Grad norm: 4.223e-01\n",
      "Epoch 7740, Loss: 0.6086799502372742, Neurons: 64, Grad norm: 4.223e-01\n",
      "Epoch 7741, Loss: 0.6074095964431763, Neurons: 64, Grad norm: 4.234e-01\n",
      "Epoch 7741, Loss: 0.6074095964431763, Neurons: 64, Grad norm: 4.234e-01\n",
      "Epoch 7742, Loss: 0.6061417460441589, Neurons: 64, Grad norm: 4.232e-01\n",
      "Epoch 7742, Loss: 0.6061417460441589, Neurons: 64, Grad norm: 4.232e-01\n",
      "Epoch 7743, Loss: 0.6048765182495117, Neurons: 64, Grad norm: 4.207e-01\n",
      "Epoch 7743, Loss: 0.6048765182495117, Neurons: 64, Grad norm: 4.207e-01\n",
      "Epoch 7744, Loss: 0.6036136150360107, Neurons: 64, Grad norm: 4.186e-01\n",
      "Epoch 7744, Loss: 0.6036136150360107, Neurons: 64, Grad norm: 4.186e-01\n",
      "Epoch 7745, Loss: 0.6023540496826172, Neurons: 64, Grad norm: 4.188e-01\n",
      "Epoch 7745, Loss: 0.6023540496826172, Neurons: 64, Grad norm: 4.188e-01\n",
      "Epoch 7746, Loss: 0.6010954976081848, Neurons: 64, Grad norm: 4.203e-01\n",
      "Epoch 7746, Loss: 0.6010954976081848, Neurons: 64, Grad norm: 4.203e-01\n",
      "Epoch 7747, Loss: 0.5998401641845703, Neurons: 64, Grad norm: 4.197e-01\n",
      "Epoch 7747, Loss: 0.5998401641845703, Neurons: 64, Grad norm: 4.197e-01\n",
      "Epoch 7748, Loss: 0.598587691783905, Neurons: 64, Grad norm: 4.178e-01\n",
      "Epoch 7748, Loss: 0.598587691783905, Neurons: 64, Grad norm: 4.178e-01\n",
      "Epoch 7749, Loss: 0.5973373055458069, Neurons: 64, Grad norm: 4.171e-01\n",
      "Epoch 7749, Loss: 0.5973373055458069, Neurons: 64, Grad norm: 4.171e-01\n",
      "Epoch 7750, Loss: 0.5960884690284729, Neurons: 64, Grad norm: 4.152e-01\n",
      "Epoch 7750, Loss: 0.5960884690284729, Neurons: 64, Grad norm: 4.152e-01\n",
      "Epoch 7751, Loss: 0.5948433876037598, Neurons: 64, Grad norm: 4.149e-01\n",
      "Epoch 7751, Loss: 0.5948433876037598, Neurons: 64, Grad norm: 4.149e-01\n",
      "Epoch 7752, Loss: 0.5935996174812317, Neurons: 64, Grad norm: 4.154e-01\n",
      "Epoch 7752, Loss: 0.5935996174812317, Neurons: 64, Grad norm: 4.154e-01\n",
      "Epoch 7753, Loss: 0.5923588275909424, Neurons: 64, Grad norm: 4.155e-01\n",
      "Epoch 7753, Loss: 0.5923588275909424, Neurons: 64, Grad norm: 4.155e-01\n",
      "Epoch 7754, Loss: 0.5911206007003784, Neurons: 64, Grad norm: 4.135e-01\n",
      "Epoch 7754, Loss: 0.5911206007003784, Neurons: 64, Grad norm: 4.135e-01\n",
      "Epoch 7755, Loss: 0.5898840427398682, Neurons: 64, Grad norm: 4.114e-01\n",
      "Epoch 7755, Loss: 0.5898840427398682, Neurons: 64, Grad norm: 4.114e-01\n",
      "Epoch 7756, Loss: 0.5886505246162415, Neurons: 64, Grad norm: 4.119e-01\n",
      "Epoch 7756, Loss: 0.5886505246162415, Neurons: 64, Grad norm: 4.119e-01\n",
      "Epoch 7757, Loss: 0.5874188542366028, Neurons: 64, Grad norm: 4.130e-01\n",
      "Epoch 7757, Loss: 0.5874188542366028, Neurons: 64, Grad norm: 4.130e-01\n",
      "Epoch 7758, Loss: 0.5861899852752686, Neurons: 64, Grad norm: 4.105e-01\n",
      "Epoch 7758, Loss: 0.5861899852752686, Neurons: 64, Grad norm: 4.105e-01\n",
      "Epoch 7759, Loss: 0.5849629044532776, Neurons: 64, Grad norm: 4.096e-01\n",
      "Epoch 7759, Loss: 0.5849629044532776, Neurons: 64, Grad norm: 4.096e-01\n",
      "Epoch 7760, Loss: 0.5837385654449463, Neurons: 64, Grad norm: 4.104e-01\n",
      "Epoch 7760, Loss: 0.5837385654449463, Neurons: 64, Grad norm: 4.104e-01\n",
      "Epoch 7761, Loss: 0.5825165510177612, Neurons: 64, Grad norm: 4.088e-01\n",
      "Epoch 7761, Loss: 0.5825165510177612, Neurons: 64, Grad norm: 4.088e-01\n",
      "Epoch 7762, Loss: 0.5812968015670776, Neurons: 64, Grad norm: 4.057e-01\n",
      "Epoch 7762, Loss: 0.5812968015670776, Neurons: 64, Grad norm: 4.057e-01\n",
      "Epoch 7763, Loss: 0.5800790190696716, Neurons: 64, Grad norm: 4.061e-01\n",
      "Epoch 7763, Loss: 0.5800790190696716, Neurons: 64, Grad norm: 4.061e-01\n",
      "Epoch 7764, Loss: 0.5788640379905701, Neurons: 64, Grad norm: 4.082e-01\n",
      "Epoch 7764, Loss: 0.5788640379905701, Neurons: 64, Grad norm: 4.082e-01\n",
      "Epoch 7765, Loss: 0.5776511430740356, Neurons: 64, Grad norm: 4.063e-01\n",
      "Epoch 7765, Loss: 0.5776511430740356, Neurons: 64, Grad norm: 4.063e-01\n",
      "Epoch 7766, Loss: 0.5764408111572266, Neurons: 64, Grad norm: 4.053e-01\n",
      "Epoch 7766, Loss: 0.5764408111572266, Neurons: 64, Grad norm: 4.053e-01\n",
      "Epoch 7767, Loss: 0.5752323269844055, Neurons: 64, Grad norm: 4.044e-01\n",
      "Epoch 7767, Loss: 0.5752323269844055, Neurons: 64, Grad norm: 4.044e-01\n",
      "Epoch 7768, Loss: 0.5740265250205994, Neurons: 64, Grad norm: 4.052e-01\n",
      "Epoch 7768, Loss: 0.5740265250205994, Neurons: 64, Grad norm: 4.052e-01\n",
      "Epoch 7769, Loss: 0.5728223323822021, Neurons: 64, Grad norm: 4.037e-01\n",
      "Epoch 7769, Loss: 0.5728223323822021, Neurons: 64, Grad norm: 4.037e-01\n",
      "Epoch 7770, Loss: 0.5716206431388855, Neurons: 64, Grad norm: 4.023e-01\n",
      "Epoch 7770, Loss: 0.5716206431388855, Neurons: 64, Grad norm: 4.023e-01\n",
      "Epoch 7771, Loss: 0.5704221725463867, Neurons: 64, Grad norm: 4.041e-01\n",
      "Epoch 7771, Loss: 0.5704221725463867, Neurons: 64, Grad norm: 4.041e-01\n",
      "Epoch 7772, Loss: 0.5692248344421387, Neurons: 64, Grad norm: 4.020e-01\n",
      "Epoch 7772, Loss: 0.5692248344421387, Neurons: 64, Grad norm: 4.020e-01\n",
      "Epoch 7773, Loss: 0.5680299401283264, Neurons: 64, Grad norm: 3.983e-01\n",
      "Epoch 7773, Loss: 0.5680299401283264, Neurons: 64, Grad norm: 3.983e-01\n",
      "Epoch 7774, Loss: 0.566837728023529, Neurons: 64, Grad norm: 3.970e-01\n",
      "Epoch 7774, Loss: 0.566837728023529, Neurons: 64, Grad norm: 3.970e-01\n",
      "Epoch 7775, Loss: 0.5656471252441406, Neurons: 64, Grad norm: 3.978e-01\n",
      "Epoch 7775, Loss: 0.5656471252441406, Neurons: 64, Grad norm: 3.978e-01\n",
      "Epoch 7776, Loss: 0.5644588470458984, Neurons: 64, Grad norm: 3.993e-01\n",
      "Epoch 7776, Loss: 0.5644588470458984, Neurons: 64, Grad norm: 3.993e-01\n",
      "Epoch 7777, Loss: 0.5632736682891846, Neurons: 64, Grad norm: 3.993e-01\n",
      "Epoch 7777, Loss: 0.5632736682891846, Neurons: 64, Grad norm: 3.993e-01\n",
      "Epoch 7778, Loss: 0.5620899796485901, Neurons: 64, Grad norm: 3.981e-01\n",
      "Epoch 7778, Loss: 0.5620899796485901, Neurons: 64, Grad norm: 3.981e-01\n",
      "Epoch 7779, Loss: 0.5609080791473389, Neurons: 64, Grad norm: 3.969e-01\n",
      "Epoch 7779, Loss: 0.5609080791473389, Neurons: 64, Grad norm: 3.969e-01\n",
      "Epoch 7780, Loss: 0.5597290396690369, Neurons: 64, Grad norm: 3.968e-01\n",
      "Epoch 7780, Loss: 0.5597290396690369, Neurons: 64, Grad norm: 3.968e-01\n",
      "Epoch 7781, Loss: 0.558552086353302, Neurons: 64, Grad norm: 3.937e-01\n",
      "Epoch 7781, Loss: 0.558552086353302, Neurons: 64, Grad norm: 3.937e-01\n",
      "Epoch 7782, Loss: 0.5573769211769104, Neurons: 64, Grad norm: 3.938e-01\n",
      "Epoch 7782, Loss: 0.5573769211769104, Neurons: 64, Grad norm: 3.938e-01\n",
      "Epoch 7783, Loss: 0.5562043786048889, Neurons: 64, Grad norm: 3.946e-01\n",
      "Epoch 7783, Loss: 0.5562043786048889, Neurons: 64, Grad norm: 3.946e-01\n",
      "Epoch 7784, Loss: 0.5550339221954346, Neurons: 64, Grad norm: 3.947e-01\n",
      "Epoch 7784, Loss: 0.5550339221954346, Neurons: 64, Grad norm: 3.947e-01\n",
      "Epoch 7785, Loss: 0.5538654327392578, Neurons: 64, Grad norm: 3.923e-01\n",
      "Epoch 7785, Loss: 0.5538654327392578, Neurons: 64, Grad norm: 3.923e-01\n",
      "Epoch 7786, Loss: 0.5526997447013855, Neurons: 64, Grad norm: 3.906e-01\n",
      "Epoch 7786, Loss: 0.5526997447013855, Neurons: 64, Grad norm: 3.906e-01\n",
      "Epoch 7787, Loss: 0.5515354871749878, Neurons: 64, Grad norm: 3.911e-01\n",
      "Epoch 7787, Loss: 0.5515354871749878, Neurons: 64, Grad norm: 3.911e-01\n",
      "Epoch 7788, Loss: 0.5503740310668945, Neurons: 64, Grad norm: 3.913e-01\n",
      "Epoch 7788, Loss: 0.5503740310668945, Neurons: 64, Grad norm: 3.913e-01\n",
      "Epoch 7789, Loss: 0.5492146015167236, Neurons: 64, Grad norm: 3.892e-01\n",
      "Epoch 7789, Loss: 0.5492146015167236, Neurons: 64, Grad norm: 3.892e-01\n",
      "Epoch 7790, Loss: 0.5480563044548035, Neurons: 64, Grad norm: 3.881e-01\n",
      "Epoch 7790, Loss: 0.5480563044548035, Neurons: 64, Grad norm: 3.881e-01\n",
      "Epoch 7791, Loss: 0.5469014048576355, Neurons: 64, Grad norm: 3.883e-01\n",
      "Epoch 7791, Loss: 0.5469014048576355, Neurons: 64, Grad norm: 3.883e-01\n",
      "Epoch 7792, Loss: 0.545748233795166, Neurons: 64, Grad norm: 3.889e-01\n",
      "Epoch 7792, Loss: 0.545748233795166, Neurons: 64, Grad norm: 3.889e-01\n",
      "Epoch 7793, Loss: 0.5445978045463562, Neurons: 64, Grad norm: 3.893e-01\n",
      "Epoch 7793, Loss: 0.5445978045463562, Neurons: 64, Grad norm: 3.893e-01\n",
      "Epoch 7794, Loss: 0.5434484481811523, Neurons: 64, Grad norm: 3.888e-01\n",
      "Epoch 7794, Loss: 0.5434484481811523, Neurons: 64, Grad norm: 3.888e-01\n",
      "Epoch 7795, Loss: 0.5423016548156738, Neurons: 64, Grad norm: 3.860e-01\n",
      "Epoch 7795, Loss: 0.5423016548156738, Neurons: 64, Grad norm: 3.860e-01\n",
      "Epoch 7796, Loss: 0.5411571264266968, Neurons: 64, Grad norm: 3.846e-01\n",
      "Epoch 7796, Loss: 0.5411571264266968, Neurons: 64, Grad norm: 3.846e-01\n",
      "Epoch 7797, Loss: 0.5400150418281555, Neurons: 64, Grad norm: 3.840e-01\n",
      "Epoch 7797, Loss: 0.5400150418281555, Neurons: 64, Grad norm: 3.840e-01\n",
      "Epoch 7798, Loss: 0.5388744473457336, Neurons: 64, Grad norm: 3.839e-01\n",
      "Epoch 7798, Loss: 0.5388744473457336, Neurons: 64, Grad norm: 3.839e-01\n",
      "Epoch 7799, Loss: 0.5377364754676819, Neurons: 64, Grad norm: 3.821e-01\n",
      "Epoch 7799, Loss: 0.5377364754676819, Neurons: 64, Grad norm: 3.821e-01\n",
      "Epoch 7799, Test loss: 0.4194680154323578\n",
      "Epoch 7799, Test loss: 0.4194680154323578\n",
      "Epoch 7800, Loss: 0.5366003513336182, Neurons: 64, Grad norm: 3.830e-01\n",
      "Epoch 7800, Loss: 0.5366003513336182, Neurons: 64, Grad norm: 3.830e-01\n",
      "Epoch 7801, Loss: 0.5354664325714111, Neurons: 64, Grad norm: 3.870e-01\n",
      "Epoch 7801, Loss: 0.5354664325714111, Neurons: 64, Grad norm: 3.870e-01\n",
      "Epoch 7802, Loss: 0.5343344211578369, Neurons: 64, Grad norm: 3.850e-01\n",
      "Epoch 7802, Loss: 0.5343344211578369, Neurons: 64, Grad norm: 3.850e-01\n",
      "Epoch 7803, Loss: 0.5332049131393433, Neurons: 64, Grad norm: 3.801e-01\n",
      "Epoch 7803, Loss: 0.5332049131393433, Neurons: 64, Grad norm: 3.801e-01\n",
      "Epoch 7804, Loss: 0.5320776104927063, Neurons: 64, Grad norm: 3.788e-01\n",
      "Epoch 7804, Loss: 0.5320776104927063, Neurons: 64, Grad norm: 3.788e-01\n",
      "Epoch 7805, Loss: 0.5309522151947021, Neurons: 64, Grad norm: 3.806e-01\n",
      "Epoch 7805, Loss: 0.5309522151947021, Neurons: 64, Grad norm: 3.806e-01\n",
      "Epoch 7806, Loss: 0.529828667640686, Neurons: 64, Grad norm: 3.791e-01\n",
      "Epoch 7806, Loss: 0.529828667640686, Neurons: 64, Grad norm: 3.791e-01\n",
      "Epoch 7807, Loss: 0.5287076234817505, Neurons: 64, Grad norm: 3.786e-01\n",
      "Epoch 7807, Loss: 0.5287076234817505, Neurons: 64, Grad norm: 3.786e-01\n",
      "Epoch 7808, Loss: 0.527588427066803, Neurons: 64, Grad norm: 3.798e-01\n",
      "Epoch 7808, Loss: 0.527588427066803, Neurons: 64, Grad norm: 3.798e-01\n",
      "Epoch 7809, Loss: 0.5264718532562256, Neurons: 64, Grad norm: 3.806e-01\n",
      "Epoch 7809, Loss: 0.5264718532562256, Neurons: 64, Grad norm: 3.806e-01\n",
      "Epoch 7810, Loss: 0.5253572463989258, Neurons: 64, Grad norm: 3.762e-01\n",
      "Epoch 7810, Loss: 0.5253572463989258, Neurons: 64, Grad norm: 3.762e-01\n",
      "Epoch 7811, Loss: 0.5242437720298767, Neurons: 64, Grad norm: 3.737e-01\n",
      "Epoch 7811, Loss: 0.5242437720298767, Neurons: 64, Grad norm: 3.737e-01\n",
      "Epoch 7812, Loss: 0.5231334567070007, Neurons: 64, Grad norm: 3.754e-01\n",
      "Epoch 7812, Loss: 0.5231334567070007, Neurons: 64, Grad norm: 3.754e-01\n",
      "Epoch 7813, Loss: 0.5220248103141785, Neurons: 64, Grad norm: 3.763e-01\n",
      "Epoch 7813, Loss: 0.5220248103141785, Neurons: 64, Grad norm: 3.763e-01\n",
      "Epoch 7814, Loss: 0.520918607711792, Neurons: 64, Grad norm: 3.763e-01\n",
      "Epoch 7814, Loss: 0.520918607711792, Neurons: 64, Grad norm: 3.763e-01\n",
      "Epoch 7815, Loss: 0.5198140740394592, Neurons: 64, Grad norm: 3.762e-01\n",
      "Epoch 7815, Loss: 0.5198140740394592, Neurons: 64, Grad norm: 3.762e-01\n",
      "Epoch 7816, Loss: 0.5187118053436279, Neurons: 64, Grad norm: 3.742e-01\n",
      "Epoch 7816, Loss: 0.5187118053436279, Neurons: 64, Grad norm: 3.742e-01\n",
      "Epoch 7817, Loss: 0.5176118612289429, Neurons: 64, Grad norm: 3.724e-01\n",
      "Epoch 7817, Loss: 0.5176118612289429, Neurons: 64, Grad norm: 3.724e-01\n",
      "Epoch 7818, Loss: 0.5165137052536011, Neurons: 64, Grad norm: 3.710e-01\n",
      "Epoch 7818, Loss: 0.5165137052536011, Neurons: 64, Grad norm: 3.710e-01\n",
      "Epoch 7819, Loss: 0.5154175758361816, Neurons: 64, Grad norm: 3.705e-01\n",
      "Epoch 7819, Loss: 0.5154175758361816, Neurons: 64, Grad norm: 3.705e-01\n",
      "Epoch 7820, Loss: 0.5143243670463562, Neurons: 64, Grad norm: 3.700e-01\n",
      "Epoch 7820, Loss: 0.5143243670463562, Neurons: 64, Grad norm: 3.700e-01\n",
      "Epoch 7821, Loss: 0.5132322311401367, Neurons: 64, Grad norm: 3.711e-01\n",
      "Epoch 7821, Loss: 0.5132322311401367, Neurons: 64, Grad norm: 3.711e-01\n",
      "Epoch 7822, Loss: 0.5121428370475769, Neurons: 64, Grad norm: 3.718e-01\n",
      "Epoch 7822, Loss: 0.5121428370475769, Neurons: 64, Grad norm: 3.718e-01\n",
      "Epoch 7823, Loss: 0.5110553503036499, Neurons: 64, Grad norm: 3.709e-01\n",
      "Epoch 7823, Loss: 0.5110553503036499, Neurons: 64, Grad norm: 3.709e-01\n",
      "Epoch 7824, Loss: 0.5099702477455139, Neurons: 64, Grad norm: 3.683e-01\n",
      "Epoch 7824, Loss: 0.5099702477455139, Neurons: 64, Grad norm: 3.683e-01\n",
      "Epoch 7825, Loss: 0.508886992931366, Neurons: 64, Grad norm: 3.687e-01\n",
      "Epoch 7825, Loss: 0.508886992931366, Neurons: 64, Grad norm: 3.687e-01\n",
      "Epoch 7826, Loss: 0.5078056454658508, Neurons: 64, Grad norm: 3.680e-01\n",
      "Epoch 7826, Loss: 0.5078056454658508, Neurons: 64, Grad norm: 3.680e-01\n",
      "Epoch 7827, Loss: 0.5067267417907715, Neurons: 64, Grad norm: 3.652e-01\n",
      "Epoch 7827, Loss: 0.5067267417907715, Neurons: 64, Grad norm: 3.652e-01\n",
      "Epoch 7828, Loss: 0.505649983882904, Neurons: 64, Grad norm: 3.646e-01\n",
      "Epoch 7828, Loss: 0.505649983882904, Neurons: 64, Grad norm: 3.646e-01\n",
      "Epoch 7829, Loss: 0.504575252532959, Neurons: 64, Grad norm: 3.650e-01\n",
      "Epoch 7829, Loss: 0.504575252532959, Neurons: 64, Grad norm: 3.650e-01\n",
      "Epoch 7830, Loss: 0.5035025477409363, Neurons: 64, Grad norm: 3.657e-01\n",
      "Epoch 7830, Loss: 0.5035025477409363, Neurons: 64, Grad norm: 3.657e-01\n",
      "Epoch 7831, Loss: 0.5024318695068359, Neurons: 64, Grad norm: 3.665e-01\n",
      "Epoch 7831, Loss: 0.5024318695068359, Neurons: 64, Grad norm: 3.665e-01\n",
      "Epoch 7832, Loss: 0.5013623833656311, Neurons: 64, Grad norm: 3.650e-01\n",
      "Epoch 7832, Loss: 0.5013623833656311, Neurons: 64, Grad norm: 3.650e-01\n",
      "Epoch 7833, Loss: 0.5002967715263367, Neurons: 64, Grad norm: 3.638e-01\n",
      "Epoch 7833, Loss: 0.5002967715263367, Neurons: 64, Grad norm: 3.638e-01\n",
      "Epoch 7834, Loss: 0.49923259019851685, Neurons: 64, Grad norm: 3.625e-01\n",
      "Epoch 7834, Loss: 0.49923259019851685, Neurons: 64, Grad norm: 3.625e-01\n",
      "Epoch 7835, Loss: 0.49817001819610596, Neurons: 64, Grad norm: 3.615e-01\n",
      "Epoch 7835, Loss: 0.49817001819610596, Neurons: 64, Grad norm: 3.615e-01\n",
      "Epoch 7836, Loss: 0.4971100389957428, Neurons: 64, Grad norm: 3.614e-01\n",
      "Epoch 7836, Loss: 0.4971100389957428, Neurons: 64, Grad norm: 3.614e-01\n",
      "Epoch 7837, Loss: 0.4960519075393677, Neurons: 64, Grad norm: 3.623e-01\n",
      "Epoch 7837, Loss: 0.4960519075393677, Neurons: 64, Grad norm: 3.623e-01\n",
      "Epoch 7838, Loss: 0.4949961304664612, Neurons: 64, Grad norm: 3.629e-01\n",
      "Epoch 7838, Loss: 0.4949961304664612, Neurons: 64, Grad norm: 3.629e-01\n",
      "Epoch 7839, Loss: 0.493942528963089, Neurons: 64, Grad norm: 3.614e-01\n",
      "Epoch 7839, Loss: 0.493942528963089, Neurons: 64, Grad norm: 3.614e-01\n",
      "Epoch 7840, Loss: 0.49289077520370483, Neurons: 64, Grad norm: 3.575e-01\n",
      "Epoch 7840, Loss: 0.49289077520370483, Neurons: 64, Grad norm: 3.575e-01\n",
      "Epoch 7841, Loss: 0.49184155464172363, Neurons: 64, Grad norm: 3.570e-01\n",
      "Epoch 7841, Loss: 0.49184155464172363, Neurons: 64, Grad norm: 3.570e-01\n",
      "Epoch 7842, Loss: 0.4907941222190857, Neurons: 64, Grad norm: 3.583e-01\n",
      "Epoch 7842, Loss: 0.4907941222190857, Neurons: 64, Grad norm: 3.583e-01\n",
      "Epoch 7843, Loss: 0.4897487461566925, Neurons: 64, Grad norm: 3.587e-01\n",
      "Epoch 7843, Loss: 0.4897487461566925, Neurons: 64, Grad norm: 3.587e-01\n",
      "Epoch 7844, Loss: 0.4887060821056366, Neurons: 64, Grad norm: 3.594e-01\n",
      "Epoch 7844, Loss: 0.4887060821056366, Neurons: 64, Grad norm: 3.594e-01\n",
      "Epoch 7845, Loss: 0.4876650273799896, Neurons: 64, Grad norm: 3.590e-01\n",
      "Epoch 7845, Loss: 0.4876650273799896, Neurons: 64, Grad norm: 3.590e-01\n",
      "Epoch 7846, Loss: 0.4866260886192322, Neurons: 64, Grad norm: 3.556e-01\n",
      "Epoch 7846, Loss: 0.4866260886192322, Neurons: 64, Grad norm: 3.556e-01\n",
      "Epoch 7847, Loss: 0.4855888783931732, Neurons: 64, Grad norm: 3.535e-01\n",
      "Epoch 7847, Loss: 0.4855888783931732, Neurons: 64, Grad norm: 3.535e-01\n",
      "Epoch 7848, Loss: 0.4845544993877411, Neurons: 64, Grad norm: 3.526e-01\n",
      "Epoch 7848, Loss: 0.4845544993877411, Neurons: 64, Grad norm: 3.526e-01\n",
      "Epoch 7849, Loss: 0.4835219383239746, Neurons: 64, Grad norm: 3.533e-01\n",
      "Epoch 7849, Loss: 0.4835219383239746, Neurons: 64, Grad norm: 3.533e-01\n",
      "Epoch 7850, Loss: 0.48249155282974243, Neurons: 64, Grad norm: 3.567e-01\n",
      "Epoch 7850, Loss: 0.48249155282974243, Neurons: 64, Grad norm: 3.567e-01\n",
      "Epoch 7851, Loss: 0.48146340250968933, Neurons: 64, Grad norm: 3.576e-01\n",
      "Epoch 7851, Loss: 0.48146340250968933, Neurons: 64, Grad norm: 3.576e-01\n",
      "Epoch 7852, Loss: 0.4804372787475586, Neurons: 64, Grad norm: 3.539e-01\n",
      "Epoch 7852, Loss: 0.4804372787475586, Neurons: 64, Grad norm: 3.539e-01\n",
      "Epoch 7853, Loss: 0.4794134497642517, Neurons: 64, Grad norm: 3.506e-01\n",
      "Epoch 7853, Loss: 0.4794134497642517, Neurons: 64, Grad norm: 3.506e-01\n",
      "Epoch 7854, Loss: 0.47839173674583435, Neurons: 64, Grad norm: 3.507e-01\n",
      "Epoch 7854, Loss: 0.47839173674583435, Neurons: 64, Grad norm: 3.507e-01\n",
      "Epoch 7855, Loss: 0.47737154364585876, Neurons: 64, Grad norm: 3.505e-01\n",
      "Epoch 7855, Loss: 0.47737154364585876, Neurons: 64, Grad norm: 3.505e-01\n",
      "Epoch 7856, Loss: 0.4763542711734772, Neurons: 64, Grad norm: 3.497e-01\n",
      "Epoch 7856, Loss: 0.4763542711734772, Neurons: 64, Grad norm: 3.497e-01\n",
      "Epoch 7857, Loss: 0.47533926367759705, Neurons: 64, Grad norm: 3.513e-01\n",
      "Epoch 7857, Loss: 0.47533926367759705, Neurons: 64, Grad norm: 3.513e-01\n",
      "Epoch 7858, Loss: 0.47432592511177063, Neurons: 64, Grad norm: 3.536e-01\n",
      "Epoch 7858, Loss: 0.47432592511177063, Neurons: 64, Grad norm: 3.536e-01\n",
      "Epoch 7859, Loss: 0.47331497073173523, Neurons: 64, Grad norm: 3.506e-01\n",
      "Epoch 7859, Loss: 0.47331497073173523, Neurons: 64, Grad norm: 3.506e-01\n",
      "Epoch 7860, Loss: 0.47230592370033264, Neurons: 64, Grad norm: 3.470e-01\n",
      "Epoch 7860, Loss: 0.47230592370033264, Neurons: 64, Grad norm: 3.470e-01\n",
      "Epoch 7861, Loss: 0.4712992310523987, Neurons: 64, Grad norm: 3.464e-01\n",
      "Epoch 7861, Loss: 0.4712992310523987, Neurons: 64, Grad norm: 3.464e-01\n",
      "Epoch 7862, Loss: 0.4702945053577423, Neurons: 64, Grad norm: 3.478e-01\n",
      "Epoch 7862, Loss: 0.4702945053577423, Neurons: 64, Grad norm: 3.478e-01\n",
      "Epoch 7863, Loss: 0.46929195523262024, Neurons: 64, Grad norm: 3.448e-01\n",
      "Epoch 7863, Loss: 0.46929195523262024, Neurons: 64, Grad norm: 3.448e-01\n",
      "Epoch 7864, Loss: 0.4682917594909668, Neurons: 64, Grad norm: 3.459e-01\n",
      "Epoch 7864, Loss: 0.4682917594909668, Neurons: 64, Grad norm: 3.459e-01\n",
      "Epoch 7865, Loss: 0.46729350090026855, Neurons: 64, Grad norm: 3.489e-01\n",
      "Epoch 7865, Loss: 0.46729350090026855, Neurons: 64, Grad norm: 3.489e-01\n",
      "Epoch 7866, Loss: 0.4662979543209076, Neurons: 64, Grad norm: 3.479e-01\n",
      "Epoch 7866, Loss: 0.4662979543209076, Neurons: 64, Grad norm: 3.479e-01\n",
      "Epoch 7867, Loss: 0.4653034806251526, Neurons: 64, Grad norm: 3.454e-01\n",
      "Epoch 7867, Loss: 0.4653034806251526, Neurons: 64, Grad norm: 3.454e-01\n",
      "Epoch 7868, Loss: 0.46431174874305725, Neurons: 64, Grad norm: 3.450e-01\n",
      "Epoch 7868, Loss: 0.46431174874305725, Neurons: 64, Grad norm: 3.450e-01\n",
      "Epoch 7869, Loss: 0.46332305669784546, Neurons: 64, Grad norm: 3.438e-01\n",
      "Epoch 7869, Loss: 0.46332305669784546, Neurons: 64, Grad norm: 3.438e-01\n",
      "Epoch 7870, Loss: 0.46233534812927246, Neurons: 64, Grad norm: 3.409e-01\n",
      "Epoch 7870, Loss: 0.46233534812927246, Neurons: 64, Grad norm: 3.409e-01\n",
      "Epoch 7871, Loss: 0.46134984493255615, Neurons: 64, Grad norm: 3.416e-01\n",
      "Epoch 7871, Loss: 0.46134984493255615, Neurons: 64, Grad norm: 3.416e-01\n",
      "Epoch 7872, Loss: 0.4603675305843353, Neurons: 64, Grad norm: 3.456e-01\n",
      "Epoch 7872, Loss: 0.4603675305843353, Neurons: 64, Grad norm: 3.456e-01\n",
      "Epoch 7873, Loss: 0.45938608050346375, Neurons: 64, Grad norm: 3.436e-01\n",
      "Epoch 7873, Loss: 0.45938608050346375, Neurons: 64, Grad norm: 3.436e-01\n",
      "Epoch 7874, Loss: 0.4584079384803772, Neurons: 64, Grad norm: 3.404e-01\n",
      "Epoch 7874, Loss: 0.4584079384803772, Neurons: 64, Grad norm: 3.404e-01\n",
      "Epoch 7875, Loss: 0.45743054151535034, Neurons: 64, Grad norm: 3.392e-01\n",
      "Epoch 7875, Loss: 0.45743054151535034, Neurons: 64, Grad norm: 3.392e-01\n",
      "Epoch 7876, Loss: 0.45645686984062195, Neurons: 64, Grad norm: 3.387e-01\n",
      "Epoch 7876, Loss: 0.45645686984062195, Neurons: 64, Grad norm: 3.387e-01\n",
      "Epoch 7877, Loss: 0.45548486709594727, Neurons: 64, Grad norm: 3.369e-01\n",
      "Epoch 7877, Loss: 0.45548486709594727, Neurons: 64, Grad norm: 3.369e-01\n",
      "Epoch 7878, Loss: 0.454514741897583, Neurons: 64, Grad norm: 3.384e-01\n",
      "Epoch 7878, Loss: 0.454514741897583, Neurons: 64, Grad norm: 3.384e-01\n",
      "Epoch 7879, Loss: 0.45354703068733215, Neurons: 64, Grad norm: 3.440e-01\n",
      "Epoch 7879, Loss: 0.45354703068733215, Neurons: 64, Grad norm: 3.440e-01\n",
      "Epoch 7880, Loss: 0.4525813162326813, Neurons: 64, Grad norm: 3.425e-01\n",
      "Epoch 7880, Loss: 0.4525813162326813, Neurons: 64, Grad norm: 3.425e-01\n",
      "Epoch 7881, Loss: 0.45161765813827515, Neurons: 64, Grad norm: 3.375e-01\n",
      "Epoch 7881, Loss: 0.45161765813827515, Neurons: 64, Grad norm: 3.375e-01\n",
      "Epoch 7882, Loss: 0.45065635442733765, Neurons: 64, Grad norm: 3.350e-01\n",
      "Epoch 7882, Loss: 0.45065635442733765, Neurons: 64, Grad norm: 3.350e-01\n",
      "Epoch 7883, Loss: 0.44969722628593445, Neurons: 64, Grad norm: 3.347e-01\n",
      "Epoch 7883, Loss: 0.44969722628593445, Neurons: 64, Grad norm: 3.347e-01\n",
      "Epoch 7884, Loss: 0.44873982667922974, Neurons: 64, Grad norm: 3.337e-01\n",
      "Epoch 7884, Loss: 0.44873982667922974, Neurons: 64, Grad norm: 3.337e-01\n",
      "Epoch 7885, Loss: 0.44778522849082947, Neurons: 64, Grad norm: 3.356e-01\n",
      "Epoch 7885, Loss: 0.44778522849082947, Neurons: 64, Grad norm: 3.356e-01\n",
      "Epoch 7886, Loss: 0.44683316349983215, Neurons: 64, Grad norm: 3.386e-01\n",
      "Epoch 7886, Loss: 0.44683316349983215, Neurons: 64, Grad norm: 3.386e-01\n",
      "Epoch 7887, Loss: 0.4458828270435333, Neurons: 64, Grad norm: 3.367e-01\n",
      "Epoch 7887, Loss: 0.4458828270435333, Neurons: 64, Grad norm: 3.367e-01\n",
      "Epoch 7888, Loss: 0.44493457674980164, Neurons: 64, Grad norm: 3.334e-01\n",
      "Epoch 7888, Loss: 0.44493457674980164, Neurons: 64, Grad norm: 3.334e-01\n",
      "Epoch 7889, Loss: 0.44398847222328186, Neurons: 64, Grad norm: 3.315e-01\n",
      "Epoch 7889, Loss: 0.44398847222328186, Neurons: 64, Grad norm: 3.315e-01\n",
      "Epoch 7890, Loss: 0.44304484128952026, Neurons: 64, Grad norm: 3.305e-01\n",
      "Epoch 7890, Loss: 0.44304484128952026, Neurons: 64, Grad norm: 3.305e-01\n",
      "Epoch 7891, Loss: 0.4421033561229706, Neurons: 64, Grad norm: 3.298e-01\n",
      "Epoch 7891, Loss: 0.4421033561229706, Neurons: 64, Grad norm: 3.298e-01\n",
      "Epoch 7892, Loss: 0.44116395711898804, Neurons: 64, Grad norm: 3.320e-01\n",
      "Epoch 7892, Loss: 0.44116395711898804, Neurons: 64, Grad norm: 3.320e-01\n",
      "Epoch 7893, Loss: 0.4402264356613159, Neurons: 64, Grad norm: 3.360e-01\n",
      "Epoch 7893, Loss: 0.4402264356613159, Neurons: 64, Grad norm: 3.360e-01\n",
      "Epoch 7894, Loss: 0.43929147720336914, Neurons: 64, Grad norm: 3.340e-01\n",
      "Epoch 7894, Loss: 0.43929147720336914, Neurons: 64, Grad norm: 3.340e-01\n",
      "Epoch 7895, Loss: 0.4383584260940552, Neurons: 64, Grad norm: 3.301e-01\n",
      "Epoch 7895, Loss: 0.4383584260940552, Neurons: 64, Grad norm: 3.301e-01\n",
      "Epoch 7896, Loss: 0.4374280273914337, Neurons: 64, Grad norm: 3.287e-01\n",
      "Epoch 7896, Loss: 0.4374280273914337, Neurons: 64, Grad norm: 3.287e-01\n",
      "Epoch 7897, Loss: 0.43649908900260925, Neurons: 64, Grad norm: 3.280e-01\n",
      "Epoch 7897, Loss: 0.43649908900260925, Neurons: 64, Grad norm: 3.280e-01\n",
      "Epoch 7898, Loss: 0.43557295203208923, Neurons: 64, Grad norm: 3.265e-01\n",
      "Epoch 7898, Loss: 0.43557295203208923, Neurons: 64, Grad norm: 3.265e-01\n",
      "Epoch 7899, Loss: 0.4346487522125244, Neurons: 64, Grad norm: 3.293e-01\n",
      "Epoch 7899, Loss: 0.4346487522125244, Neurons: 64, Grad norm: 3.293e-01\n",
      "Epoch 7899, Test loss: 0.3340146243572235\n",
      "Epoch 7899, Test loss: 0.3340146243572235\n",
      "Epoch 7900, Loss: 0.4337270259857178, Neurons: 64, Grad norm: 3.330e-01\n",
      "Epoch 7900, Loss: 0.4337270259857178, Neurons: 64, Grad norm: 3.330e-01\n",
      "Epoch 7901, Loss: 0.4328068494796753, Neurons: 64, Grad norm: 3.289e-01\n",
      "Epoch 7901, Loss: 0.4328068494796753, Neurons: 64, Grad norm: 3.289e-01\n",
      "Epoch 7902, Loss: 0.4318893849849701, Neurons: 64, Grad norm: 3.252e-01\n",
      "Epoch 7902, Loss: 0.4318893849849701, Neurons: 64, Grad norm: 3.252e-01\n",
      "Epoch 7903, Loss: 0.430973619222641, Neurons: 64, Grad norm: 3.248e-01\n",
      "Epoch 7903, Loss: 0.430973619222641, Neurons: 64, Grad norm: 3.248e-01\n",
      "Epoch 7904, Loss: 0.430060476064682, Neurons: 64, Grad norm: 3.228e-01\n",
      "Epoch 7904, Loss: 0.430060476064682, Neurons: 64, Grad norm: 3.228e-01\n",
      "Epoch 7905, Loss: 0.429149329662323, Neurons: 64, Grad norm: 3.228e-01\n",
      "Epoch 7905, Loss: 0.429149329662323, Neurons: 64, Grad norm: 3.228e-01\n",
      "Epoch 7906, Loss: 0.4282403290271759, Neurons: 64, Grad norm: 3.263e-01\n",
      "Epoch 7906, Loss: 0.4282403290271759, Neurons: 64, Grad norm: 3.263e-01\n",
      "Epoch 7907, Loss: 0.4273335933685303, Neurons: 64, Grad norm: 3.286e-01\n",
      "Epoch 7907, Loss: 0.4273335933685303, Neurons: 64, Grad norm: 3.286e-01\n",
      "Epoch 7908, Loss: 0.42642906308174133, Neurons: 64, Grad norm: 3.264e-01\n",
      "Epoch 7908, Loss: 0.42642906308174133, Neurons: 64, Grad norm: 3.264e-01\n",
      "Epoch 7909, Loss: 0.42552661895751953, Neurons: 64, Grad norm: 3.235e-01\n",
      "Epoch 7909, Loss: 0.42552661895751953, Neurons: 64, Grad norm: 3.235e-01\n",
      "Epoch 7910, Loss: 0.4246268570423126, Neurons: 64, Grad norm: 3.228e-01\n",
      "Epoch 7910, Loss: 0.4246268570423126, Neurons: 64, Grad norm: 3.228e-01\n",
      "Epoch 7911, Loss: 0.4237287938594818, Neurons: 64, Grad norm: 3.203e-01\n",
      "Epoch 7911, Loss: 0.4237287938594818, Neurons: 64, Grad norm: 3.203e-01\n",
      "Epoch 7912, Loss: 0.4228329658508301, Neurons: 64, Grad norm: 3.201e-01\n",
      "Epoch 7912, Loss: 0.4228329658508301, Neurons: 64, Grad norm: 3.201e-01\n",
      "Epoch 7913, Loss: 0.4219391644001007, Neurons: 64, Grad norm: 3.227e-01\n",
      "Epoch 7913, Loss: 0.4219391644001007, Neurons: 64, Grad norm: 3.227e-01\n",
      "Epoch 7914, Loss: 0.4210476279258728, Neurons: 64, Grad norm: 3.233e-01\n",
      "Epoch 7914, Loss: 0.4210476279258728, Neurons: 64, Grad norm: 3.233e-01\n",
      "Epoch 7915, Loss: 0.42015859484672546, Neurons: 64, Grad norm: 3.198e-01\n",
      "Epoch 7915, Loss: 0.42015859484672546, Neurons: 64, Grad norm: 3.198e-01\n",
      "Epoch 7916, Loss: 0.4192712604999542, Neurons: 64, Grad norm: 3.206e-01\n",
      "Epoch 7916, Loss: 0.4192712604999542, Neurons: 64, Grad norm: 3.206e-01\n",
      "Epoch 7917, Loss: 0.41838619112968445, Neurons: 64, Grad norm: 3.205e-01\n",
      "Epoch 7917, Loss: 0.41838619112968445, Neurons: 64, Grad norm: 3.205e-01\n",
      "Epoch 7918, Loss: 0.417504221200943, Neurons: 64, Grad norm: 3.170e-01\n",
      "Epoch 7918, Loss: 0.417504221200943, Neurons: 64, Grad norm: 3.170e-01\n",
      "Epoch 7919, Loss: 0.4166233539581299, Neurons: 64, Grad norm: 3.174e-01\n",
      "Epoch 7919, Loss: 0.4166233539581299, Neurons: 64, Grad norm: 3.174e-01\n",
      "Epoch 7920, Loss: 0.41574448347091675, Neurons: 64, Grad norm: 3.212e-01\n",
      "Epoch 7920, Loss: 0.41574448347091675, Neurons: 64, Grad norm: 3.212e-01\n",
      "Epoch 7921, Loss: 0.4148688316345215, Neurons: 64, Grad norm: 3.193e-01\n",
      "Epoch 7921, Loss: 0.4148688316345215, Neurons: 64, Grad norm: 3.193e-01\n",
      "Epoch 7922, Loss: 0.41399508714675903, Neurons: 64, Grad norm: 3.157e-01\n",
      "Epoch 7922, Loss: 0.41399508714675903, Neurons: 64, Grad norm: 3.157e-01\n",
      "Epoch 7923, Loss: 0.4131230413913727, Neurons: 64, Grad norm: 3.166e-01\n",
      "Epoch 7923, Loss: 0.4131230413913727, Neurons: 64, Grad norm: 3.166e-01\n",
      "Epoch 7924, Loss: 0.41225317120552063, Neurons: 64, Grad norm: 3.181e-01\n",
      "Epoch 7924, Loss: 0.41225317120552063, Neurons: 64, Grad norm: 3.181e-01\n",
      "Epoch 7925, Loss: 0.4113858938217163, Neurons: 64, Grad norm: 3.141e-01\n",
      "Epoch 7925, Loss: 0.4113858938217163, Neurons: 64, Grad norm: 3.141e-01\n",
      "Epoch 7926, Loss: 0.4105207026004791, Neurons: 64, Grad norm: 3.147e-01\n",
      "Epoch 7926, Loss: 0.4105207026004791, Neurons: 64, Grad norm: 3.147e-01\n",
      "Epoch 7927, Loss: 0.40965694189071655, Neurons: 64, Grad norm: 3.169e-01\n",
      "Epoch 7927, Loss: 0.40965694189071655, Neurons: 64, Grad norm: 3.169e-01\n",
      "Epoch 7928, Loss: 0.4087959825992584, Neurons: 64, Grad norm: 3.147e-01\n",
      "Epoch 7928, Loss: 0.4087959825992584, Neurons: 64, Grad norm: 3.147e-01\n",
      "Epoch 7929, Loss: 0.40793707966804504, Neurons: 64, Grad norm: 3.119e-01\n",
      "Epoch 7929, Loss: 0.40793707966804504, Neurons: 64, Grad norm: 3.119e-01\n",
      "Epoch 7930, Loss: 0.40708065032958984, Neurons: 64, Grad norm: 3.118e-01\n",
      "Epoch 7930, Loss: 0.40708065032958984, Neurons: 64, Grad norm: 3.118e-01\n",
      "Epoch 7931, Loss: 0.4062257707118988, Neurons: 64, Grad norm: 3.124e-01\n",
      "Epoch 7931, Loss: 0.4062257707118988, Neurons: 64, Grad norm: 3.124e-01\n",
      "Epoch 7932, Loss: 0.4053734838962555, Neurons: 64, Grad norm: 3.124e-01\n",
      "Epoch 7932, Loss: 0.4053734838962555, Neurons: 64, Grad norm: 3.124e-01\n",
      "Epoch 7933, Loss: 0.4045231342315674, Neurons: 64, Grad norm: 3.131e-01\n",
      "Epoch 7933, Loss: 0.4045231342315674, Neurons: 64, Grad norm: 3.131e-01\n",
      "Epoch 7934, Loss: 0.40367552638053894, Neurons: 64, Grad norm: 3.144e-01\n",
      "Epoch 7934, Loss: 0.40367552638053894, Neurons: 64, Grad norm: 3.144e-01\n",
      "Epoch 7935, Loss: 0.4028296172618866, Neurons: 64, Grad norm: 3.115e-01\n",
      "Epoch 7935, Loss: 0.4028296172618866, Neurons: 64, Grad norm: 3.115e-01\n",
      "Epoch 7936, Loss: 0.40198567509651184, Neurons: 64, Grad norm: 3.115e-01\n",
      "Epoch 7936, Loss: 0.40198567509651184, Neurons: 64, Grad norm: 3.115e-01\n",
      "Epoch 7937, Loss: 0.40114352107048035, Neurons: 64, Grad norm: 3.110e-01\n",
      "Epoch 7937, Loss: 0.40114352107048035, Neurons: 64, Grad norm: 3.110e-01\n",
      "Epoch 7938, Loss: 0.4003041386604309, Neurons: 64, Grad norm: 3.074e-01\n",
      "Epoch 7938, Loss: 0.4003041386604309, Neurons: 64, Grad norm: 3.074e-01\n",
      "Epoch 7939, Loss: 0.39946699142456055, Neurons: 64, Grad norm: 3.095e-01\n",
      "Epoch 7939, Loss: 0.39946699142456055, Neurons: 64, Grad norm: 3.095e-01\n",
      "Epoch 7940, Loss: 0.39863160252571106, Neurons: 64, Grad norm: 3.122e-01\n",
      "Epoch 7940, Loss: 0.39863160252571106, Neurons: 64, Grad norm: 3.122e-01\n",
      "Epoch 7941, Loss: 0.39779847860336304, Neurons: 64, Grad norm: 3.086e-01\n",
      "Epoch 7941, Loss: 0.39779847860336304, Neurons: 64, Grad norm: 3.086e-01\n",
      "Epoch 7942, Loss: 0.3969673216342926, Neurons: 64, Grad norm: 3.060e-01\n",
      "Epoch 7942, Loss: 0.3969673216342926, Neurons: 64, Grad norm: 3.060e-01\n",
      "Epoch 7943, Loss: 0.39613884687423706, Neurons: 64, Grad norm: 3.079e-01\n",
      "Epoch 7943, Loss: 0.39613884687423706, Neurons: 64, Grad norm: 3.079e-01\n",
      "Epoch 7944, Loss: 0.3953120708465576, Neurons: 64, Grad norm: 3.077e-01\n",
      "Epoch 7944, Loss: 0.3953120708465576, Neurons: 64, Grad norm: 3.077e-01\n",
      "Epoch 7945, Loss: 0.3944876790046692, Neurons: 64, Grad norm: 3.057e-01\n",
      "Epoch 7945, Loss: 0.3944876790046692, Neurons: 64, Grad norm: 3.057e-01\n",
      "Epoch 7946, Loss: 0.39366480708122253, Neurons: 64, Grad norm: 3.084e-01\n",
      "Epoch 7946, Loss: 0.39366480708122253, Neurons: 64, Grad norm: 3.084e-01\n",
      "Epoch 7947, Loss: 0.3928443193435669, Neurons: 64, Grad norm: 3.080e-01\n",
      "Epoch 7947, Loss: 0.3928443193435669, Neurons: 64, Grad norm: 3.080e-01\n",
      "Epoch 7948, Loss: 0.39202582836151123, Neurons: 64, Grad norm: 3.046e-01\n",
      "Epoch 7948, Loss: 0.39202582836151123, Neurons: 64, Grad norm: 3.046e-01\n",
      "Epoch 7949, Loss: 0.39120981097221375, Neurons: 64, Grad norm: 3.032e-01\n",
      "Epoch 7949, Loss: 0.39120981097221375, Neurons: 64, Grad norm: 3.032e-01\n",
      "Epoch 7950, Loss: 0.39039576053619385, Neurons: 64, Grad norm: 3.036e-01\n",
      "Epoch 7950, Loss: 0.39039576053619385, Neurons: 64, Grad norm: 3.036e-01\n",
      "Epoch 7951, Loss: 0.38958388566970825, Neurons: 64, Grad norm: 3.020e-01\n",
      "Epoch 7951, Loss: 0.38958388566970825, Neurons: 64, Grad norm: 3.020e-01\n",
      "Epoch 7952, Loss: 0.3887738883495331, Neurons: 64, Grad norm: 3.027e-01\n",
      "Epoch 7952, Loss: 0.3887738883495331, Neurons: 64, Grad norm: 3.027e-01\n",
      "Epoch 7953, Loss: 0.3879660665988922, Neurons: 64, Grad norm: 3.040e-01\n",
      "Epoch 7953, Loss: 0.3879660665988922, Neurons: 64, Grad norm: 3.040e-01\n",
      "Epoch 7954, Loss: 0.38716018199920654, Neurons: 64, Grad norm: 3.013e-01\n",
      "Epoch 7954, Loss: 0.38716018199920654, Neurons: 64, Grad norm: 3.013e-01\n",
      "Epoch 7955, Loss: 0.3863566517829895, Neurons: 64, Grad norm: 3.023e-01\n",
      "Epoch 7955, Loss: 0.3863566517829895, Neurons: 64, Grad norm: 3.023e-01\n",
      "Epoch 7956, Loss: 0.38555464148521423, Neurons: 64, Grad norm: 3.060e-01\n",
      "Epoch 7956, Loss: 0.38555464148521423, Neurons: 64, Grad norm: 3.060e-01\n",
      "Epoch 7957, Loss: 0.38475528359413147, Neurons: 64, Grad norm: 3.012e-01\n",
      "Epoch 7957, Loss: 0.38475528359413147, Neurons: 64, Grad norm: 3.012e-01\n",
      "Epoch 7958, Loss: 0.383957177400589, Neurons: 64, Grad norm: 2.988e-01\n",
      "Epoch 7958, Loss: 0.383957177400589, Neurons: 64, Grad norm: 2.988e-01\n",
      "Epoch 7959, Loss: 0.383162260055542, Neurons: 64, Grad norm: 3.012e-01\n",
      "Epoch 7959, Loss: 0.383162260055542, Neurons: 64, Grad norm: 3.012e-01\n",
      "Epoch 7960, Loss: 0.38236910104751587, Neurons: 64, Grad norm: 2.986e-01\n",
      "Epoch 7960, Loss: 0.38236910104751587, Neurons: 64, Grad norm: 2.986e-01\n",
      "Epoch 7961, Loss: 0.38157764077186584, Neurons: 64, Grad norm: 2.969e-01\n",
      "Epoch 7961, Loss: 0.38157764077186584, Neurons: 64, Grad norm: 2.969e-01\n",
      "Epoch 7962, Loss: 0.3807883858680725, Neurons: 64, Grad norm: 2.983e-01\n",
      "Epoch 7962, Loss: 0.3807883858680725, Neurons: 64, Grad norm: 2.983e-01\n",
      "Epoch 7963, Loss: 0.3800015449523926, Neurons: 64, Grad norm: 2.994e-01\n",
      "Epoch 7963, Loss: 0.3800015449523926, Neurons: 64, Grad norm: 2.994e-01\n",
      "Epoch 7964, Loss: 0.3792160153388977, Neurons: 64, Grad norm: 2.969e-01\n",
      "Epoch 7964, Loss: 0.3792160153388977, Neurons: 64, Grad norm: 2.969e-01\n",
      "Epoch 7965, Loss: 0.37843289971351624, Neurons: 64, Grad norm: 2.954e-01\n",
      "Epoch 7965, Loss: 0.37843289971351624, Neurons: 64, Grad norm: 2.954e-01\n",
      "Epoch 7966, Loss: 0.3776514530181885, Neurons: 64, Grad norm: 2.972e-01\n",
      "Epoch 7966, Loss: 0.3776514530181885, Neurons: 64, Grad norm: 2.972e-01\n",
      "Epoch 7967, Loss: 0.3768730163574219, Neurons: 64, Grad norm: 2.966e-01\n",
      "Epoch 7967, Loss: 0.3768730163574219, Neurons: 64, Grad norm: 2.966e-01\n",
      "Epoch 7968, Loss: 0.376095712184906, Neurons: 64, Grad norm: 2.979e-01\n",
      "Epoch 7968, Loss: 0.376095712184906, Neurons: 64, Grad norm: 2.979e-01\n",
      "Epoch 7969, Loss: 0.3753211796283722, Neurons: 64, Grad norm: 2.994e-01\n",
      "Epoch 7969, Loss: 0.3753211796283722, Neurons: 64, Grad norm: 2.994e-01\n",
      "Epoch 7970, Loss: 0.3745478689670563, Neurons: 64, Grad norm: 2.951e-01\n",
      "Epoch 7970, Loss: 0.3745478689670563, Neurons: 64, Grad norm: 2.951e-01\n",
      "Epoch 7971, Loss: 0.3737768530845642, Neurons: 64, Grad norm: 2.942e-01\n",
      "Epoch 7971, Loss: 0.3737768530845642, Neurons: 64, Grad norm: 2.942e-01\n",
      "Epoch 7972, Loss: 0.3730080723762512, Neurons: 64, Grad norm: 2.943e-01\n",
      "Epoch 7972, Loss: 0.3730080723762512, Neurons: 64, Grad norm: 2.943e-01\n",
      "Epoch 7973, Loss: 0.3722406327724457, Neurons: 64, Grad norm: 2.906e-01\n",
      "Epoch 7973, Loss: 0.3722406327724457, Neurons: 64, Grad norm: 2.906e-01\n",
      "Epoch 7974, Loss: 0.37147626280784607, Neurons: 64, Grad norm: 2.912e-01\n",
      "Epoch 7974, Loss: 0.37147626280784607, Neurons: 64, Grad norm: 2.912e-01\n",
      "Epoch 7975, Loss: 0.3707130253314972, Neurons: 64, Grad norm: 2.947e-01\n",
      "Epoch 7975, Loss: 0.3707130253314972, Neurons: 64, Grad norm: 2.947e-01\n",
      "Epoch 7976, Loss: 0.3699522316455841, Neurons: 64, Grad norm: 2.959e-01\n",
      "Epoch 7976, Loss: 0.3699522316455841, Neurons: 64, Grad norm: 2.959e-01\n",
      "Epoch 7977, Loss: 0.3691931664943695, Neurons: 64, Grad norm: 2.926e-01\n",
      "Epoch 7977, Loss: 0.3691931664943695, Neurons: 64, Grad norm: 2.926e-01\n",
      "Epoch 7978, Loss: 0.3684358298778534, Neurons: 64, Grad norm: 2.906e-01\n",
      "Epoch 7978, Loss: 0.3684358298778534, Neurons: 64, Grad norm: 2.906e-01\n",
      "Epoch 7979, Loss: 0.36768099665641785, Neurons: 64, Grad norm: 2.928e-01\n",
      "Epoch 7979, Loss: 0.36768099665641785, Neurons: 64, Grad norm: 2.928e-01\n",
      "Epoch 7980, Loss: 0.3669279217720032, Neurons: 64, Grad norm: 2.889e-01\n",
      "Epoch 7980, Loss: 0.3669279217720032, Neurons: 64, Grad norm: 2.889e-01\n",
      "Epoch 7981, Loss: 0.3661767542362213, Neurons: 64, Grad norm: 2.884e-01\n",
      "Epoch 7981, Loss: 0.3661767542362213, Neurons: 64, Grad norm: 2.884e-01\n",
      "Epoch 7982, Loss: 0.36542725563049316, Neurons: 64, Grad norm: 2.909e-01\n",
      "Epoch 7982, Loss: 0.36542725563049316, Neurons: 64, Grad norm: 2.909e-01\n",
      "Epoch 7983, Loss: 0.3646802604198456, Neurons: 64, Grad norm: 2.909e-01\n",
      "Epoch 7983, Loss: 0.3646802604198456, Neurons: 64, Grad norm: 2.909e-01\n",
      "Epoch 7984, Loss: 0.36393505334854126, Neurons: 64, Grad norm: 2.893e-01\n",
      "Epoch 7984, Loss: 0.36393505334854126, Neurons: 64, Grad norm: 2.893e-01\n",
      "Epoch 7985, Loss: 0.36319151520729065, Neurons: 64, Grad norm: 2.883e-01\n",
      "Epoch 7985, Loss: 0.36319151520729065, Neurons: 64, Grad norm: 2.883e-01\n",
      "Epoch 7986, Loss: 0.36244991421699524, Neurons: 64, Grad norm: 2.893e-01\n",
      "Epoch 7986, Loss: 0.36244991421699524, Neurons: 64, Grad norm: 2.893e-01\n",
      "Epoch 7987, Loss: 0.36171063780784607, Neurons: 64, Grad norm: 2.885e-01\n",
      "Epoch 7987, Loss: 0.36171063780784607, Neurons: 64, Grad norm: 2.885e-01\n",
      "Epoch 7988, Loss: 0.36097192764282227, Neurons: 64, Grad norm: 2.857e-01\n",
      "Epoch 7988, Loss: 0.36097192764282227, Neurons: 64, Grad norm: 2.857e-01\n",
      "Epoch 7989, Loss: 0.36023688316345215, Neurons: 64, Grad norm: 2.850e-01\n",
      "Epoch 7989, Loss: 0.36023688316345215, Neurons: 64, Grad norm: 2.850e-01\n",
      "Epoch 7990, Loss: 0.35950371623039246, Neurons: 64, Grad norm: 2.857e-01\n",
      "Epoch 7990, Loss: 0.35950371623039246, Neurons: 64, Grad norm: 2.857e-01\n",
      "Epoch 7991, Loss: 0.35877174139022827, Neurons: 64, Grad norm: 2.863e-01\n",
      "Epoch 7991, Loss: 0.35877174139022827, Neurons: 64, Grad norm: 2.863e-01\n",
      "Epoch 7992, Loss: 0.35804158449172974, Neurons: 64, Grad norm: 2.847e-01\n",
      "Epoch 7992, Loss: 0.35804158449172974, Neurons: 64, Grad norm: 2.847e-01\n",
      "Epoch 7993, Loss: 0.3573136031627655, Neurons: 64, Grad norm: 2.864e-01\n",
      "Epoch 7993, Loss: 0.3573136031627655, Neurons: 64, Grad norm: 2.864e-01\n",
      "Epoch 7994, Loss: 0.35658711194992065, Neurons: 64, Grad norm: 2.867e-01\n",
      "Epoch 7994, Loss: 0.35658711194992065, Neurons: 64, Grad norm: 2.867e-01\n",
      "Epoch 7995, Loss: 0.3558625280857086, Neurons: 64, Grad norm: 2.852e-01\n",
      "Epoch 7995, Loss: 0.3558625280857086, Neurons: 64, Grad norm: 2.852e-01\n",
      "Epoch 7996, Loss: 0.35514017939567566, Neurons: 64, Grad norm: 2.845e-01\n",
      "Epoch 7996, Loss: 0.35514017939567566, Neurons: 64, Grad norm: 2.845e-01\n",
      "Epoch 7997, Loss: 0.3544198274612427, Neurons: 64, Grad norm: 2.833e-01\n",
      "Epoch 7997, Loss: 0.3544198274612427, Neurons: 64, Grad norm: 2.833e-01\n",
      "Epoch 7998, Loss: 0.3537009358406067, Neurons: 64, Grad norm: 2.838e-01\n",
      "Epoch 7998, Loss: 0.3537009358406067, Neurons: 64, Grad norm: 2.838e-01\n",
      "Epoch 7999, Loss: 0.35298413038253784, Neurons: 64, Grad norm: 2.810e-01\n",
      "Epoch 7999, Loss: 0.35298413038253784, Neurons: 64, Grad norm: 2.810e-01\n",
      "Epoch 7999, Test loss: 0.26728153228759766\n",
      "Epoch 7999, Test loss: 0.26728153228759766\n",
      "Epoch 8000, Loss: 0.3522689938545227, Neurons: 64, Grad norm: 2.813e-01\n",
      "Epoch 8000, Loss: 0.3522689938545227, Neurons: 64, Grad norm: 2.813e-01\n",
      "Epoch 8001, Loss: 0.3515561521053314, Neurons: 64, Grad norm: 2.817e-01\n",
      "Epoch 8001, Loss: 0.3515561521053314, Neurons: 64, Grad norm: 2.817e-01\n",
      "Epoch 8002, Loss: 0.3508446216583252, Neurons: 64, Grad norm: 2.807e-01\n",
      "Epoch 8002, Loss: 0.3508446216583252, Neurons: 64, Grad norm: 2.807e-01\n",
      "Epoch 8003, Loss: 0.35013508796691895, Neurons: 64, Grad norm: 2.810e-01\n",
      "Epoch 8003, Loss: 0.35013508796691895, Neurons: 64, Grad norm: 2.810e-01\n",
      "Epoch 8004, Loss: 0.349427729845047, Neurons: 64, Grad norm: 2.808e-01\n",
      "Epoch 8004, Loss: 0.349427729845047, Neurons: 64, Grad norm: 2.808e-01\n",
      "Epoch 8005, Loss: 0.3487218916416168, Neurons: 64, Grad norm: 2.801e-01\n",
      "Epoch 8005, Loss: 0.3487218916416168, Neurons: 64, Grad norm: 2.801e-01\n",
      "Epoch 8006, Loss: 0.34801769256591797, Neurons: 64, Grad norm: 2.803e-01\n",
      "Epoch 8006, Loss: 0.34801769256591797, Neurons: 64, Grad norm: 2.803e-01\n",
      "Epoch 8007, Loss: 0.3473157584667206, Neurons: 64, Grad norm: 2.791e-01\n",
      "Epoch 8007, Loss: 0.3473157584667206, Neurons: 64, Grad norm: 2.791e-01\n",
      "Epoch 8008, Loss: 0.34661513566970825, Neurons: 64, Grad norm: 2.805e-01\n",
      "Epoch 8008, Loss: 0.34661513566970825, Neurons: 64, Grad norm: 2.805e-01\n",
      "Epoch 8009, Loss: 0.3459169864654541, Neurons: 64, Grad norm: 2.799e-01\n",
      "Epoch 8009, Loss: 0.3459169864654541, Neurons: 64, Grad norm: 2.799e-01\n",
      "Epoch 8010, Loss: 0.34522026777267456, Neurons: 64, Grad norm: 2.783e-01\n",
      "Epoch 8010, Loss: 0.34522026777267456, Neurons: 64, Grad norm: 2.783e-01\n",
      "Epoch 8011, Loss: 0.34452545642852783, Neurons: 64, Grad norm: 2.772e-01\n",
      "Epoch 8011, Loss: 0.34452545642852783, Neurons: 64, Grad norm: 2.772e-01\n",
      "Epoch 8012, Loss: 0.34383219480514526, Neurons: 64, Grad norm: 2.784e-01\n",
      "Epoch 8012, Loss: 0.34383219480514526, Neurons: 64, Grad norm: 2.784e-01\n",
      "Epoch 8013, Loss: 0.3431411385536194, Neurons: 64, Grad norm: 2.760e-01\n",
      "Epoch 8013, Loss: 0.3431411385536194, Neurons: 64, Grad norm: 2.760e-01\n",
      "Epoch 8014, Loss: 0.3424513638019562, Neurons: 64, Grad norm: 2.752e-01\n",
      "Epoch 8014, Loss: 0.3424513638019562, Neurons: 64, Grad norm: 2.752e-01\n",
      "Epoch 8015, Loss: 0.3417636752128601, Neurons: 64, Grad norm: 2.791e-01\n",
      "Epoch 8015, Loss: 0.3417636752128601, Neurons: 64, Grad norm: 2.791e-01\n",
      "Epoch 8016, Loss: 0.3410775363445282, Neurons: 64, Grad norm: 2.752e-01\n",
      "Epoch 8016, Loss: 0.3410775363445282, Neurons: 64, Grad norm: 2.752e-01\n",
      "Epoch 8017, Loss: 0.34039321541786194, Neurons: 64, Grad norm: 2.751e-01\n",
      "Epoch 8017, Loss: 0.34039321541786194, Neurons: 64, Grad norm: 2.751e-01\n",
      "Epoch 8018, Loss: 0.3397105932235718, Neurons: 64, Grad norm: 2.754e-01\n",
      "Epoch 8018, Loss: 0.3397105932235718, Neurons: 64, Grad norm: 2.754e-01\n",
      "Epoch 8019, Loss: 0.33903029561042786, Neurons: 64, Grad norm: 2.752e-01\n",
      "Epoch 8019, Loss: 0.33903029561042786, Neurons: 64, Grad norm: 2.752e-01\n",
      "Epoch 8020, Loss: 0.33835098147392273, Neurons: 64, Grad norm: 2.749e-01\n",
      "Epoch 8020, Loss: 0.33835098147392273, Neurons: 64, Grad norm: 2.749e-01\n",
      "Epoch 8021, Loss: 0.33767372369766235, Neurons: 64, Grad norm: 2.754e-01\n",
      "Epoch 8021, Loss: 0.33767372369766235, Neurons: 64, Grad norm: 2.754e-01\n",
      "Epoch 8022, Loss: 0.33699825406074524, Neurons: 64, Grad norm: 2.727e-01\n",
      "Epoch 8022, Loss: 0.33699825406074524, Neurons: 64, Grad norm: 2.727e-01\n",
      "Epoch 8023, Loss: 0.33632418513298035, Neurons: 64, Grad norm: 2.723e-01\n",
      "Epoch 8023, Loss: 0.33632418513298035, Neurons: 64, Grad norm: 2.723e-01\n",
      "Epoch 8024, Loss: 0.33565232157707214, Neurons: 64, Grad norm: 2.729e-01\n",
      "Epoch 8024, Loss: 0.33565232157707214, Neurons: 64, Grad norm: 2.729e-01\n",
      "Epoch 8025, Loss: 0.3349817097187042, Neurons: 64, Grad norm: 2.718e-01\n",
      "Epoch 8025, Loss: 0.3349817097187042, Neurons: 64, Grad norm: 2.718e-01\n",
      "Epoch 8026, Loss: 0.3343132734298706, Neurons: 64, Grad norm: 2.715e-01\n",
      "Epoch 8026, Loss: 0.3343132734298706, Neurons: 64, Grad norm: 2.715e-01\n",
      "Epoch 8027, Loss: 0.3336462080478668, Neurons: 64, Grad norm: 2.722e-01\n",
      "Epoch 8027, Loss: 0.3336462080478668, Neurons: 64, Grad norm: 2.722e-01\n",
      "Epoch 8028, Loss: 0.332980751991272, Neurons: 64, Grad norm: 2.719e-01\n",
      "Epoch 8028, Loss: 0.332980751991272, Neurons: 64, Grad norm: 2.719e-01\n",
      "Epoch 8029, Loss: 0.3323170244693756, Neurons: 64, Grad norm: 2.700e-01\n",
      "Epoch 8029, Loss: 0.3323170244693756, Neurons: 64, Grad norm: 2.700e-01\n",
      "Epoch 8030, Loss: 0.33165526390075684, Neurons: 64, Grad norm: 2.697e-01\n",
      "Epoch 8030, Loss: 0.33165526390075684, Neurons: 64, Grad norm: 2.697e-01\n",
      "Epoch 8031, Loss: 0.33099454641342163, Neurons: 64, Grad norm: 2.735e-01\n",
      "Epoch 8031, Loss: 0.33099454641342163, Neurons: 64, Grad norm: 2.735e-01\n",
      "Epoch 8032, Loss: 0.3303365409374237, Neurons: 64, Grad norm: 2.687e-01\n",
      "Epoch 8032, Loss: 0.3303365409374237, Neurons: 64, Grad norm: 2.687e-01\n",
      "Epoch 8033, Loss: 0.32967934012413025, Neurons: 64, Grad norm: 2.677e-01\n",
      "Epoch 8033, Loss: 0.32967934012413025, Neurons: 64, Grad norm: 2.677e-01\n",
      "Epoch 8034, Loss: 0.32902419567108154, Neurons: 64, Grad norm: 2.697e-01\n",
      "Epoch 8034, Loss: 0.32902419567108154, Neurons: 64, Grad norm: 2.697e-01\n",
      "Epoch 8035, Loss: 0.3283705711364746, Neurons: 64, Grad norm: 2.686e-01\n",
      "Epoch 8035, Loss: 0.3283705711364746, Neurons: 64, Grad norm: 2.686e-01\n",
      "Epoch 8036, Loss: 0.327719122171402, Neurons: 64, Grad norm: 2.675e-01\n",
      "Epoch 8036, Loss: 0.327719122171402, Neurons: 64, Grad norm: 2.675e-01\n",
      "Epoch 8037, Loss: 0.3270686864852905, Neurons: 64, Grad norm: 2.688e-01\n",
      "Epoch 8037, Loss: 0.3270686864852905, Neurons: 64, Grad norm: 2.688e-01\n",
      "Epoch 8038, Loss: 0.3264203667640686, Neurons: 64, Grad norm: 2.680e-01\n",
      "Epoch 8038, Loss: 0.3264203667640686, Neurons: 64, Grad norm: 2.680e-01\n",
      "Epoch 8039, Loss: 0.3257734477519989, Neurons: 64, Grad norm: 2.663e-01\n",
      "Epoch 8039, Loss: 0.3257734477519989, Neurons: 64, Grad norm: 2.663e-01\n",
      "Epoch 8040, Loss: 0.3251279294490814, Neurons: 64, Grad norm: 2.671e-01\n",
      "Epoch 8040, Loss: 0.3251279294490814, Neurons: 64, Grad norm: 2.671e-01\n",
      "Epoch 8041, Loss: 0.32448431849479675, Neurons: 64, Grad norm: 2.647e-01\n",
      "Epoch 8041, Loss: 0.32448431849479675, Neurons: 64, Grad norm: 2.647e-01\n",
      "Epoch 8042, Loss: 0.3238425552845001, Neurons: 64, Grad norm: 2.662e-01\n",
      "Epoch 8042, Loss: 0.3238425552845001, Neurons: 64, Grad norm: 2.662e-01\n",
      "Epoch 8043, Loss: 0.3232019543647766, Neurons: 64, Grad norm: 2.669e-01\n",
      "Epoch 8043, Loss: 0.3232019543647766, Neurons: 64, Grad norm: 2.669e-01\n",
      "Epoch 8044, Loss: 0.3225632607936859, Neurons: 64, Grad norm: 2.637e-01\n",
      "Epoch 8044, Loss: 0.3225632607936859, Neurons: 64, Grad norm: 2.637e-01\n",
      "Epoch 8045, Loss: 0.3219259977340698, Neurons: 64, Grad norm: 2.665e-01\n",
      "Epoch 8045, Loss: 0.3219259977340698, Neurons: 64, Grad norm: 2.665e-01\n",
      "Epoch 8046, Loss: 0.3212905526161194, Neurons: 64, Grad norm: 2.650e-01\n",
      "Epoch 8046, Loss: 0.3212905526161194, Neurons: 64, Grad norm: 2.650e-01\n",
      "Epoch 8047, Loss: 0.32065606117248535, Neurons: 64, Grad norm: 2.640e-01\n",
      "Epoch 8047, Loss: 0.32065606117248535, Neurons: 64, Grad norm: 2.640e-01\n",
      "Epoch 8048, Loss: 0.32002371549606323, Neurons: 64, Grad norm: 2.634e-01\n",
      "Epoch 8048, Loss: 0.32002371549606323, Neurons: 64, Grad norm: 2.634e-01\n",
      "Epoch 8049, Loss: 0.3193928599357605, Neurons: 64, Grad norm: 2.637e-01\n",
      "Epoch 8049, Loss: 0.3193928599357605, Neurons: 64, Grad norm: 2.637e-01\n",
      "Epoch 8050, Loss: 0.31876376271247864, Neurons: 64, Grad norm: 2.624e-01\n",
      "Epoch 8050, Loss: 0.31876376271247864, Neurons: 64, Grad norm: 2.624e-01\n",
      "Epoch 8051, Loss: 0.31813564896583557, Neurons: 64, Grad norm: 2.616e-01\n",
      "Epoch 8051, Loss: 0.31813564896583557, Neurons: 64, Grad norm: 2.616e-01\n",
      "Epoch 8052, Loss: 0.3175094723701477, Neurons: 64, Grad norm: 2.608e-01\n",
      "Epoch 8052, Loss: 0.3175094723701477, Neurons: 64, Grad norm: 2.608e-01\n",
      "Epoch 8053, Loss: 0.3168850243091583, Neurons: 64, Grad norm: 2.621e-01\n",
      "Epoch 8053, Loss: 0.3168850243091583, Neurons: 64, Grad norm: 2.621e-01\n",
      "Epoch 8054, Loss: 0.31626173853874207, Neurons: 64, Grad norm: 2.622e-01\n",
      "Epoch 8054, Loss: 0.31626173853874207, Neurons: 64, Grad norm: 2.622e-01\n",
      "Epoch 8055, Loss: 0.315640389919281, Neurons: 64, Grad norm: 2.598e-01\n",
      "Epoch 8055, Loss: 0.315640389919281, Neurons: 64, Grad norm: 2.598e-01\n",
      "Epoch 8056, Loss: 0.31502029299736023, Neurons: 64, Grad norm: 2.623e-01\n",
      "Epoch 8056, Loss: 0.31502029299736023, Neurons: 64, Grad norm: 2.623e-01\n",
      "Epoch 8057, Loss: 0.31440144777297974, Neurons: 64, Grad norm: 2.611e-01\n",
      "Epoch 8057, Loss: 0.31440144777297974, Neurons: 64, Grad norm: 2.611e-01\n",
      "Epoch 8058, Loss: 0.3137843906879425, Neurons: 64, Grad norm: 2.600e-01\n",
      "Epoch 8058, Loss: 0.3137843906879425, Neurons: 64, Grad norm: 2.600e-01\n",
      "Epoch 8059, Loss: 0.3131694495677948, Neurons: 64, Grad norm: 2.608e-01\n",
      "Epoch 8059, Loss: 0.3131694495677948, Neurons: 64, Grad norm: 2.608e-01\n",
      "Epoch 8060, Loss: 0.3125554621219635, Neurons: 64, Grad norm: 2.592e-01\n",
      "Epoch 8060, Loss: 0.3125554621219635, Neurons: 64, Grad norm: 2.592e-01\n",
      "Epoch 8061, Loss: 0.3119426369667053, Neurons: 64, Grad norm: 2.573e-01\n",
      "Epoch 8061, Loss: 0.3119426369667053, Neurons: 64, Grad norm: 2.573e-01\n",
      "Epoch 8062, Loss: 0.3113314211368561, Neurons: 64, Grad norm: 2.586e-01\n",
      "Epoch 8062, Loss: 0.3113314211368561, Neurons: 64, Grad norm: 2.586e-01\n",
      "Epoch 8063, Loss: 0.3107216954231262, Neurons: 64, Grad norm: 2.573e-01\n",
      "Epoch 8063, Loss: 0.3107216954231262, Neurons: 64, Grad norm: 2.573e-01\n",
      "Epoch 8064, Loss: 0.31011396646499634, Neurons: 64, Grad norm: 2.582e-01\n",
      "Epoch 8064, Loss: 0.31011396646499634, Neurons: 64, Grad norm: 2.582e-01\n",
      "Epoch 8065, Loss: 0.3095071315765381, Neurons: 64, Grad norm: 2.613e-01\n",
      "Epoch 8065, Loss: 0.3095071315765381, Neurons: 64, Grad norm: 2.613e-01\n",
      "Epoch 8066, Loss: 0.30890193581581116, Neurons: 64, Grad norm: 2.584e-01\n",
      "Epoch 8066, Loss: 0.30890193581581116, Neurons: 64, Grad norm: 2.584e-01\n",
      "Epoch 8067, Loss: 0.3082983195781708, Neurons: 64, Grad norm: 2.565e-01\n",
      "Epoch 8067, Loss: 0.3082983195781708, Neurons: 64, Grad norm: 2.565e-01\n",
      "Epoch 8068, Loss: 0.30769598484039307, Neurons: 64, Grad norm: 2.584e-01\n",
      "Epoch 8068, Loss: 0.30769598484039307, Neurons: 64, Grad norm: 2.584e-01\n",
      "Epoch 8069, Loss: 0.3070952594280243, Neurons: 64, Grad norm: 2.551e-01\n",
      "Epoch 8069, Loss: 0.3070952594280243, Neurons: 64, Grad norm: 2.551e-01\n",
      "Epoch 8070, Loss: 0.3064955472946167, Neurons: 64, Grad norm: 2.544e-01\n",
      "Epoch 8070, Loss: 0.3064955472946167, Neurons: 64, Grad norm: 2.544e-01\n",
      "Epoch 8071, Loss: 0.30589741468429565, Neurons: 64, Grad norm: 2.598e-01\n",
      "Epoch 8071, Loss: 0.30589741468429565, Neurons: 64, Grad norm: 2.598e-01\n",
      "Epoch 8072, Loss: 0.3053011894226074, Neurons: 64, Grad norm: 2.540e-01\n",
      "Epoch 8072, Loss: 0.3053011894226074, Neurons: 64, Grad norm: 2.540e-01\n",
      "Epoch 8073, Loss: 0.30470624566078186, Neurons: 64, Grad norm: 2.538e-01\n",
      "Epoch 8073, Loss: 0.30470624566078186, Neurons: 64, Grad norm: 2.538e-01\n",
      "Epoch 8074, Loss: 0.30411267280578613, Neurons: 64, Grad norm: 2.546e-01\n",
      "Epoch 8074, Loss: 0.30411267280578613, Neurons: 64, Grad norm: 2.546e-01\n",
      "Epoch 8075, Loss: 0.30352067947387695, Neurons: 64, Grad norm: 2.530e-01\n",
      "Epoch 8075, Loss: 0.30352067947387695, Neurons: 64, Grad norm: 2.530e-01\n",
      "Epoch 8076, Loss: 0.30292975902557373, Neurons: 64, Grad norm: 2.540e-01\n",
      "Epoch 8076, Loss: 0.30292975902557373, Neurons: 64, Grad norm: 2.540e-01\n",
      "Epoch 8077, Loss: 0.30234047770500183, Neurons: 64, Grad norm: 2.601e-01\n",
      "Epoch 8077, Loss: 0.30234047770500183, Neurons: 64, Grad norm: 2.601e-01\n",
      "Epoch 8078, Loss: 0.30175209045410156, Neurons: 64, Grad norm: 2.534e-01\n",
      "Epoch 8078, Loss: 0.30175209045410156, Neurons: 64, Grad norm: 2.534e-01\n",
      "Epoch 8079, Loss: 0.3011658489704132, Neurons: 64, Grad norm: 2.533e-01\n",
      "Epoch 8079, Loss: 0.3011658489704132, Neurons: 64, Grad norm: 2.533e-01\n",
      "Epoch 8080, Loss: 0.30058059096336365, Neurons: 64, Grad norm: 2.515e-01\n",
      "Epoch 8080, Loss: 0.30058059096336365, Neurons: 64, Grad norm: 2.515e-01\n",
      "Epoch 8081, Loss: 0.2999972105026245, Neurons: 64, Grad norm: 2.514e-01\n",
      "Epoch 8081, Loss: 0.2999972105026245, Neurons: 64, Grad norm: 2.514e-01\n",
      "Epoch 8082, Loss: 0.2994147837162018, Neurons: 64, Grad norm: 2.488e-01\n",
      "Epoch 8082, Loss: 0.2994147837162018, Neurons: 64, Grad norm: 2.488e-01\n",
      "Epoch 8083, Loss: 0.29883283376693726, Neurons: 64, Grad norm: 2.541e-01\n",
      "Epoch 8083, Loss: 0.29883283376693726, Neurons: 64, Grad norm: 2.541e-01\n",
      "Epoch 8084, Loss: 0.2982541024684906, Neurons: 64, Grad norm: 2.515e-01\n",
      "Epoch 8084, Loss: 0.2982541024684906, Neurons: 64, Grad norm: 2.515e-01\n",
      "Epoch 8085, Loss: 0.297675222158432, Neurons: 64, Grad norm: 2.520e-01\n",
      "Epoch 8085, Loss: 0.297675222158432, Neurons: 64, Grad norm: 2.520e-01\n",
      "Epoch 8086, Loss: 0.29709839820861816, Neurons: 64, Grad norm: 2.509e-01\n",
      "Epoch 8086, Loss: 0.29709839820861816, Neurons: 64, Grad norm: 2.509e-01\n",
      "Epoch 8087, Loss: 0.2965225875377655, Neurons: 64, Grad norm: 2.487e-01\n",
      "Epoch 8087, Loss: 0.2965225875377655, Neurons: 64, Grad norm: 2.487e-01\n",
      "Epoch 8088, Loss: 0.2959481477737427, Neurons: 64, Grad norm: 2.502e-01\n",
      "Epoch 8088, Loss: 0.2959481477737427, Neurons: 64, Grad norm: 2.502e-01\n",
      "Epoch 8089, Loss: 0.29537490010261536, Neurons: 64, Grad norm: 2.497e-01\n",
      "Epoch 8089, Loss: 0.29537490010261536, Neurons: 64, Grad norm: 2.497e-01\n",
      "Epoch 8090, Loss: 0.2948039174079895, Neurons: 64, Grad norm: 2.483e-01\n",
      "Epoch 8090, Loss: 0.2948039174079895, Neurons: 64, Grad norm: 2.483e-01\n",
      "Epoch 8091, Loss: 0.29423293471336365, Neurons: 64, Grad norm: 2.488e-01\n",
      "Epoch 8091, Loss: 0.29423293471336365, Neurons: 64, Grad norm: 2.488e-01\n",
      "Epoch 8092, Loss: 0.29366394877433777, Neurons: 64, Grad norm: 2.488e-01\n",
      "Epoch 8092, Loss: 0.29366394877433777, Neurons: 64, Grad norm: 2.488e-01\n",
      "Epoch 8093, Loss: 0.293096125125885, Neurons: 64, Grad norm: 2.458e-01\n",
      "Epoch 8093, Loss: 0.293096125125885, Neurons: 64, Grad norm: 2.458e-01\n",
      "Epoch 8094, Loss: 0.29252955317497253, Neurons: 64, Grad norm: 2.493e-01\n",
      "Epoch 8094, Loss: 0.29252955317497253, Neurons: 64, Grad norm: 2.493e-01\n",
      "Epoch 8095, Loss: 0.29196444153785706, Neurons: 64, Grad norm: 2.456e-01\n",
      "Epoch 8095, Loss: 0.29196444153785706, Neurons: 64, Grad norm: 2.456e-01\n",
      "Epoch 8096, Loss: 0.2914004325866699, Neurons: 64, Grad norm: 2.478e-01\n",
      "Epoch 8096, Loss: 0.2914004325866699, Neurons: 64, Grad norm: 2.478e-01\n",
      "Epoch 8097, Loss: 0.2908380329608917, Neurons: 64, Grad norm: 2.467e-01\n",
      "Epoch 8097, Loss: 0.2908380329608917, Neurons: 64, Grad norm: 2.467e-01\n",
      "Epoch 8098, Loss: 0.29027631878852844, Neurons: 64, Grad norm: 2.480e-01\n",
      "Epoch 8098, Loss: 0.29027631878852844, Neurons: 64, Grad norm: 2.480e-01\n",
      "Epoch 8099, Loss: 0.28971680998802185, Neurons: 64, Grad norm: 2.456e-01\n",
      "Epoch 8099, Loss: 0.28971680998802185, Neurons: 64, Grad norm: 2.456e-01\n",
      "Epoch 8099, Test loss: 0.21600975096225739\n",
      "Epoch 8099, Test loss: 0.21600975096225739\n",
      "Epoch 8100, Loss: 0.2891579866409302, Neurons: 64, Grad norm: 2.473e-01\n",
      "Epoch 8100, Loss: 0.2891579866409302, Neurons: 64, Grad norm: 2.473e-01\n",
      "Epoch 8101, Loss: 0.28860050439834595, Neurons: 64, Grad norm: 2.448e-01\n",
      "Epoch 8101, Loss: 0.28860050439834595, Neurons: 64, Grad norm: 2.448e-01\n",
      "Epoch 8102, Loss: 0.2880437672138214, Neurons: 64, Grad norm: 2.469e-01\n",
      "Epoch 8102, Loss: 0.2880437672138214, Neurons: 64, Grad norm: 2.469e-01\n",
      "Epoch 8103, Loss: 0.28748902678489685, Neurons: 64, Grad norm: 2.434e-01\n",
      "Epoch 8103, Loss: 0.28748902678489685, Neurons: 64, Grad norm: 2.434e-01\n",
      "Epoch 8104, Loss: 0.2869355082511902, Neurons: 64, Grad norm: 2.463e-01\n",
      "Epoch 8104, Loss: 0.2869355082511902, Neurons: 64, Grad norm: 2.463e-01\n",
      "Epoch 8105, Loss: 0.2863830029964447, Neurons: 64, Grad norm: 2.419e-01\n",
      "Epoch 8105, Loss: 0.2863830029964447, Neurons: 64, Grad norm: 2.419e-01\n",
      "Epoch 8106, Loss: 0.2858316898345947, Neurons: 64, Grad norm: 2.446e-01\n",
      "Epoch 8106, Loss: 0.2858316898345947, Neurons: 64, Grad norm: 2.446e-01\n",
      "Epoch 8107, Loss: 0.28528183698654175, Neurons: 64, Grad norm: 2.434e-01\n",
      "Epoch 8107, Loss: 0.28528183698654175, Neurons: 64, Grad norm: 2.434e-01\n",
      "Epoch 8108, Loss: 0.2847331464290619, Neurons: 64, Grad norm: 2.516e-01\n",
      "Epoch 8108, Loss: 0.2847331464290619, Neurons: 64, Grad norm: 2.516e-01\n",
      "Epoch 8109, Loss: 0.2841857671737671, Neurons: 64, Grad norm: 2.447e-01\n",
      "Epoch 8109, Loss: 0.2841857671737671, Neurons: 64, Grad norm: 2.447e-01\n",
      "Epoch 8110, Loss: 0.283639520406723, Neurons: 64, Grad norm: 2.520e-01\n",
      "Epoch 8110, Loss: 0.283639520406723, Neurons: 64, Grad norm: 2.520e-01\n",
      "Epoch 8111, Loss: 0.28309446573257446, Neurons: 64, Grad norm: 2.434e-01\n",
      "Epoch 8111, Loss: 0.28309446573257446, Neurons: 64, Grad norm: 2.434e-01\n",
      "Epoch 8112, Loss: 0.28255078196525574, Neurons: 64, Grad norm: 2.498e-01\n",
      "Epoch 8112, Loss: 0.28255078196525574, Neurons: 64, Grad norm: 2.498e-01\n",
      "Epoch 8113, Loss: 0.28200843930244446, Neurons: 64, Grad norm: 2.470e-01\n",
      "Epoch 8113, Loss: 0.28200843930244446, Neurons: 64, Grad norm: 2.470e-01\n",
      "Epoch 8114, Loss: 0.2814667522907257, Neurons: 64, Grad norm: 2.649e-01\n",
      "Epoch 8114, Loss: 0.2814667522907257, Neurons: 64, Grad norm: 2.649e-01\n",
      "Epoch 8115, Loss: 0.2809273302555084, Neurons: 64, Grad norm: 2.590e-01\n",
      "Epoch 8115, Loss: 0.2809273302555084, Neurons: 64, Grad norm: 2.590e-01\n",
      "Epoch 8116, Loss: 0.28038835525512695, Neurons: 64, Grad norm: 2.801e-01\n",
      "Epoch 8116, Loss: 0.28038835525512695, Neurons: 64, Grad norm: 2.801e-01\n",
      "Epoch 8117, Loss: 0.2798508107662201, Neurons: 64, Grad norm: 2.669e-01\n",
      "Epoch 8117, Loss: 0.2798508107662201, Neurons: 64, Grad norm: 2.669e-01\n",
      "Epoch 8118, Loss: 0.27931439876556396, Neurons: 64, Grad norm: 2.873e-01\n",
      "Epoch 8118, Loss: 0.27931439876556396, Neurons: 64, Grad norm: 2.873e-01\n",
      "Epoch 8119, Loss: 0.2787792682647705, Neurons: 64, Grad norm: 2.868e-01\n",
      "Epoch 8119, Loss: 0.2787792682647705, Neurons: 64, Grad norm: 2.868e-01\n",
      "Epoch 8120, Loss: 0.27824610471725464, Neurons: 64, Grad norm: 3.134e-01\n",
      "Epoch 8120, Loss: 0.27824610471725464, Neurons: 64, Grad norm: 3.134e-01\n",
      "Epoch 8121, Loss: 0.27771303057670593, Neurons: 64, Grad norm: 2.920e-01\n",
      "Epoch 8121, Loss: 0.27771303057670593, Neurons: 64, Grad norm: 2.920e-01\n",
      "Epoch 8122, Loss: 0.27718138694763184, Neurons: 64, Grad norm: 3.023e-01\n",
      "Epoch 8122, Loss: 0.27718138694763184, Neurons: 64, Grad norm: 3.023e-01\n",
      "Epoch 8123, Loss: 0.2766515910625458, Neurons: 64, Grad norm: 2.687e-01\n",
      "Epoch 8123, Loss: 0.2766515910625458, Neurons: 64, Grad norm: 2.687e-01\n",
      "Epoch 8124, Loss: 0.27612224221229553, Neurons: 64, Grad norm: 2.683e-01\n",
      "Epoch 8124, Loss: 0.27612224221229553, Neurons: 64, Grad norm: 2.683e-01\n",
      "Epoch 8125, Loss: 0.27559375762939453, Neurons: 64, Grad norm: 2.487e-01\n",
      "Epoch 8125, Loss: 0.27559375762939453, Neurons: 64, Grad norm: 2.487e-01\n",
      "Epoch 8126, Loss: 0.27506691217422485, Neurons: 64, Grad norm: 2.490e-01\n",
      "Epoch 8126, Loss: 0.27506691217422485, Neurons: 64, Grad norm: 2.490e-01\n",
      "Epoch 8127, Loss: 0.2745416462421417, Neurons: 64, Grad norm: 2.352e-01\n",
      "Epoch 8127, Loss: 0.2745416462421417, Neurons: 64, Grad norm: 2.352e-01\n",
      "Epoch 8128, Loss: 0.2740173935890198, Neurons: 64, Grad norm: 2.350e-01\n",
      "Epoch 8128, Loss: 0.2740173935890198, Neurons: 64, Grad norm: 2.350e-01\n",
      "Epoch 8129, Loss: 0.27349430322647095, Neurons: 64, Grad norm: 2.487e-01\n",
      "Epoch 8129, Loss: 0.27349430322647095, Neurons: 64, Grad norm: 2.487e-01\n",
      "Epoch 8130, Loss: 0.2729724645614624, Neurons: 64, Grad norm: 2.438e-01\n",
      "Epoch 8130, Loss: 0.2729724645614624, Neurons: 64, Grad norm: 2.438e-01\n",
      "Epoch 8131, Loss: 0.2724516987800598, Neurons: 64, Grad norm: 2.545e-01\n",
      "Epoch 8131, Loss: 0.2724516987800598, Neurons: 64, Grad norm: 2.545e-01\n",
      "Epoch 8132, Loss: 0.27193233370780945, Neurons: 64, Grad norm: 2.454e-01\n",
      "Epoch 8132, Loss: 0.27193233370780945, Neurons: 64, Grad norm: 2.454e-01\n",
      "Epoch 8133, Loss: 0.2714141309261322, Neurons: 64, Grad norm: 2.593e-01\n",
      "Epoch 8133, Loss: 0.2714141309261322, Neurons: 64, Grad norm: 2.593e-01\n",
      "Epoch 8134, Loss: 0.2708969712257385, Neurons: 64, Grad norm: 2.487e-01\n",
      "Epoch 8134, Loss: 0.2708969712257385, Neurons: 64, Grad norm: 2.487e-01\n",
      "Epoch 8135, Loss: 0.2703809142112732, Neurons: 64, Grad norm: 2.619e-01\n",
      "Epoch 8135, Loss: 0.2703809142112732, Neurons: 64, Grad norm: 2.619e-01\n",
      "Epoch 8136, Loss: 0.2698661684989929, Neurons: 64, Grad norm: 2.439e-01\n",
      "Epoch 8136, Loss: 0.2698661684989929, Neurons: 64, Grad norm: 2.439e-01\n",
      "Epoch 8137, Loss: 0.26935237646102905, Neurons: 64, Grad norm: 2.471e-01\n",
      "Epoch 8137, Loss: 0.26935237646102905, Neurons: 64, Grad norm: 2.471e-01\n",
      "Epoch 8138, Loss: 0.2688397467136383, Neurons: 64, Grad norm: 2.353e-01\n",
      "Epoch 8138, Loss: 0.2688397467136383, Neurons: 64, Grad norm: 2.353e-01\n",
      "Epoch 8139, Loss: 0.2683286666870117, Neurons: 64, Grad norm: 2.368e-01\n",
      "Epoch 8139, Loss: 0.2683286666870117, Neurons: 64, Grad norm: 2.368e-01\n",
      "Epoch 8140, Loss: 0.26781827211380005, Neurons: 64, Grad norm: 2.312e-01\n",
      "Epoch 8140, Loss: 0.26781827211380005, Neurons: 64, Grad norm: 2.312e-01\n",
      "Epoch 8141, Loss: 0.2673089802265167, Neurons: 64, Grad norm: 2.314e-01\n",
      "Epoch 8141, Loss: 0.2673089802265167, Neurons: 64, Grad norm: 2.314e-01\n",
      "Epoch 8142, Loss: 0.26680105924606323, Neurons: 64, Grad norm: 2.328e-01\n",
      "Epoch 8142, Loss: 0.26680105924606323, Neurons: 64, Grad norm: 2.328e-01\n",
      "Epoch 8143, Loss: 0.26629406213760376, Neurons: 64, Grad norm: 2.292e-01\n",
      "Epoch 8143, Loss: 0.26629406213760376, Neurons: 64, Grad norm: 2.292e-01\n",
      "Epoch 8144, Loss: 0.26578840613365173, Neurons: 64, Grad norm: 2.338e-01\n",
      "Epoch 8144, Loss: 0.26578840613365173, Neurons: 64, Grad norm: 2.338e-01\n",
      "Epoch 8145, Loss: 0.265283465385437, Neurons: 64, Grad norm: 2.314e-01\n",
      "Epoch 8145, Loss: 0.265283465385437, Neurons: 64, Grad norm: 2.314e-01\n",
      "Epoch 8146, Loss: 0.2647799253463745, Neurons: 64, Grad norm: 2.378e-01\n",
      "Epoch 8146, Loss: 0.2647799253463745, Neurons: 64, Grad norm: 2.378e-01\n",
      "Epoch 8147, Loss: 0.26427748799324036, Neurons: 64, Grad norm: 2.320e-01\n",
      "Epoch 8147, Loss: 0.26427748799324036, Neurons: 64, Grad norm: 2.320e-01\n",
      "Epoch 8148, Loss: 0.2637757658958435, Neurons: 64, Grad norm: 2.407e-01\n",
      "Epoch 8148, Loss: 0.2637757658958435, Neurons: 64, Grad norm: 2.407e-01\n",
      "Epoch 8149, Loss: 0.26327595114707947, Neurons: 64, Grad norm: 2.323e-01\n",
      "Epoch 8149, Loss: 0.26327595114707947, Neurons: 64, Grad norm: 2.323e-01\n",
      "Epoch 8150, Loss: 0.26277661323547363, Neurons: 64, Grad norm: 2.354e-01\n",
      "Epoch 8150, Loss: 0.26277661323547363, Neurons: 64, Grad norm: 2.354e-01\n",
      "Epoch 8151, Loss: 0.26227882504463196, Neurons: 64, Grad norm: 2.285e-01\n",
      "Epoch 8151, Loss: 0.26227882504463196, Neurons: 64, Grad norm: 2.285e-01\n",
      "Epoch 8152, Loss: 0.2617817223072052, Neurons: 64, Grad norm: 2.320e-01\n",
      "Epoch 8152, Loss: 0.2617817223072052, Neurons: 64, Grad norm: 2.320e-01\n",
      "Epoch 8153, Loss: 0.26128578186035156, Neurons: 64, Grad norm: 2.280e-01\n",
      "Epoch 8153, Loss: 0.26128578186035156, Neurons: 64, Grad norm: 2.280e-01\n",
      "Epoch 8154, Loss: 0.2607910931110382, Neurons: 64, Grad norm: 2.328e-01\n",
      "Epoch 8154, Loss: 0.2607910931110382, Neurons: 64, Grad norm: 2.328e-01\n",
      "Epoch 8155, Loss: 0.26029762625694275, Neurons: 64, Grad norm: 2.265e-01\n",
      "Epoch 8155, Loss: 0.26029762625694275, Neurons: 64, Grad norm: 2.265e-01\n",
      "Epoch 8156, Loss: 0.25980493426322937, Neurons: 64, Grad norm: 2.299e-01\n",
      "Epoch 8156, Loss: 0.25980493426322937, Neurons: 64, Grad norm: 2.299e-01\n",
      "Epoch 8157, Loss: 0.25931376218795776, Neurons: 64, Grad norm: 2.258e-01\n",
      "Epoch 8157, Loss: 0.25931376218795776, Neurons: 64, Grad norm: 2.258e-01\n",
      "Epoch 8158, Loss: 0.25882330536842346, Neurons: 64, Grad norm: 2.270e-01\n",
      "Epoch 8158, Loss: 0.25882330536842346, Neurons: 64, Grad norm: 2.270e-01\n",
      "Epoch 8159, Loss: 0.2583342492580414, Neurons: 64, Grad norm: 2.253e-01\n",
      "Epoch 8159, Loss: 0.2583342492580414, Neurons: 64, Grad norm: 2.253e-01\n",
      "Epoch 8160, Loss: 0.2578461468219757, Neurons: 64, Grad norm: 2.282e-01\n",
      "Epoch 8160, Loss: 0.2578461468219757, Neurons: 64, Grad norm: 2.282e-01\n",
      "Epoch 8161, Loss: 0.2573587894439697, Neurons: 64, Grad norm: 2.237e-01\n",
      "Epoch 8161, Loss: 0.2573587894439697, Neurons: 64, Grad norm: 2.237e-01\n",
      "Epoch 8162, Loss: 0.2568727433681488, Neurons: 64, Grad norm: 2.263e-01\n",
      "Epoch 8162, Loss: 0.2568727433681488, Neurons: 64, Grad norm: 2.263e-01\n",
      "Epoch 8163, Loss: 0.25638777017593384, Neurons: 64, Grad norm: 2.254e-01\n",
      "Epoch 8163, Loss: 0.25638777017593384, Neurons: 64, Grad norm: 2.254e-01\n",
      "Epoch 8164, Loss: 0.2559042274951935, Neurons: 64, Grad norm: 2.254e-01\n",
      "Epoch 8164, Loss: 0.2559042274951935, Neurons: 64, Grad norm: 2.254e-01\n",
      "Epoch 8165, Loss: 0.25542113184928894, Neurons: 64, Grad norm: 2.234e-01\n",
      "Epoch 8165, Loss: 0.25542113184928894, Neurons: 64, Grad norm: 2.234e-01\n",
      "Epoch 8166, Loss: 0.25493934750556946, Neurons: 64, Grad norm: 2.232e-01\n",
      "Epoch 8166, Loss: 0.25493934750556946, Neurons: 64, Grad norm: 2.232e-01\n",
      "Epoch 8167, Loss: 0.2544589936733246, Neurons: 64, Grad norm: 2.228e-01\n",
      "Epoch 8167, Loss: 0.2544589936733246, Neurons: 64, Grad norm: 2.228e-01\n",
      "Epoch 8168, Loss: 0.25397923588752747, Neurons: 64, Grad norm: 2.224e-01\n",
      "Epoch 8168, Loss: 0.25397923588752747, Neurons: 64, Grad norm: 2.224e-01\n",
      "Epoch 8169, Loss: 0.25350067019462585, Neurons: 64, Grad norm: 2.212e-01\n",
      "Epoch 8169, Loss: 0.25350067019462585, Neurons: 64, Grad norm: 2.212e-01\n",
      "Epoch 8170, Loss: 0.2530231475830078, Neurons: 64, Grad norm: 2.233e-01\n",
      "Epoch 8170, Loss: 0.2530231475830078, Neurons: 64, Grad norm: 2.233e-01\n",
      "Epoch 8171, Loss: 0.252547025680542, Neurons: 64, Grad norm: 2.224e-01\n",
      "Epoch 8171, Loss: 0.252547025680542, Neurons: 64, Grad norm: 2.224e-01\n",
      "Epoch 8172, Loss: 0.2520713210105896, Neurons: 64, Grad norm: 2.210e-01\n",
      "Epoch 8172, Loss: 0.2520713210105896, Neurons: 64, Grad norm: 2.210e-01\n",
      "Epoch 8173, Loss: 0.25159698724746704, Neurons: 64, Grad norm: 2.210e-01\n",
      "Epoch 8173, Loss: 0.25159698724746704, Neurons: 64, Grad norm: 2.210e-01\n",
      "Epoch 8174, Loss: 0.25112342834472656, Neurons: 64, Grad norm: 2.218e-01\n",
      "Epoch 8174, Loss: 0.25112342834472656, Neurons: 64, Grad norm: 2.218e-01\n",
      "Epoch 8175, Loss: 0.2506513297557831, Neurons: 64, Grad norm: 2.196e-01\n",
      "Epoch 8175, Loss: 0.2506513297557831, Neurons: 64, Grad norm: 2.196e-01\n",
      "Epoch 8176, Loss: 0.2501799762248993, Neurons: 64, Grad norm: 2.195e-01\n",
      "Epoch 8176, Loss: 0.2501799762248993, Neurons: 64, Grad norm: 2.195e-01\n",
      "Epoch 8177, Loss: 0.2497095763683319, Neurons: 64, Grad norm: 2.219e-01\n",
      "Epoch 8177, Loss: 0.2497095763683319, Neurons: 64, Grad norm: 2.219e-01\n",
      "Epoch 8178, Loss: 0.24924051761627197, Neurons: 64, Grad norm: 2.213e-01\n",
      "Epoch 8178, Loss: 0.24924051761627197, Neurons: 64, Grad norm: 2.213e-01\n",
      "Epoch 8179, Loss: 0.2487720400094986, Neurons: 64, Grad norm: 2.204e-01\n",
      "Epoch 8179, Loss: 0.2487720400094986, Neurons: 64, Grad norm: 2.204e-01\n",
      "Epoch 8180, Loss: 0.2483050674200058, Neurons: 64, Grad norm: 2.200e-01\n",
      "Epoch 8180, Loss: 0.2483050674200058, Neurons: 64, Grad norm: 2.200e-01\n",
      "Epoch 8181, Loss: 0.24783855676651, Neurons: 64, Grad norm: 2.188e-01\n",
      "Epoch 8181, Loss: 0.24783855676651, Neurons: 64, Grad norm: 2.188e-01\n",
      "Epoch 8182, Loss: 0.2473735213279724, Neurons: 64, Grad norm: 2.185e-01\n",
      "Epoch 8182, Loss: 0.2473735213279724, Neurons: 64, Grad norm: 2.185e-01\n",
      "Epoch 8183, Loss: 0.2469090223312378, Neurons: 64, Grad norm: 2.166e-01\n",
      "Epoch 8183, Loss: 0.2469090223312378, Neurons: 64, Grad norm: 2.166e-01\n",
      "Epoch 8184, Loss: 0.2464459389448166, Neurons: 64, Grad norm: 2.174e-01\n",
      "Epoch 8184, Loss: 0.2464459389448166, Neurons: 64, Grad norm: 2.174e-01\n",
      "Epoch 8185, Loss: 0.2459840476512909, Neurons: 64, Grad norm: 2.195e-01\n",
      "Epoch 8185, Loss: 0.2459840476512909, Neurons: 64, Grad norm: 2.195e-01\n",
      "Epoch 8186, Loss: 0.2455224096775055, Neurons: 64, Grad norm: 2.181e-01\n",
      "Epoch 8186, Loss: 0.2455224096775055, Neurons: 64, Grad norm: 2.181e-01\n",
      "Epoch 8187, Loss: 0.24506260454654694, Neurons: 64, Grad norm: 2.174e-01\n",
      "Epoch 8187, Loss: 0.24506260454654694, Neurons: 64, Grad norm: 2.174e-01\n",
      "Epoch 8188, Loss: 0.24460312724113464, Neurons: 64, Grad norm: 2.177e-01\n",
      "Epoch 8188, Loss: 0.24460312724113464, Neurons: 64, Grad norm: 2.177e-01\n",
      "Epoch 8189, Loss: 0.24414455890655518, Neurons: 64, Grad norm: 2.158e-01\n",
      "Epoch 8189, Loss: 0.24414455890655518, Neurons: 64, Grad norm: 2.158e-01\n",
      "Epoch 8190, Loss: 0.24368764460086823, Neurons: 64, Grad norm: 2.148e-01\n",
      "Epoch 8190, Loss: 0.24368764460086823, Neurons: 64, Grad norm: 2.148e-01\n",
      "Epoch 8191, Loss: 0.24323119223117828, Neurons: 64, Grad norm: 2.166e-01\n",
      "Epoch 8191, Loss: 0.24323119223117828, Neurons: 64, Grad norm: 2.166e-01\n",
      "Epoch 8192, Loss: 0.24277563393115997, Neurons: 64, Grad norm: 2.158e-01\n",
      "Epoch 8192, Loss: 0.24277563393115997, Neurons: 64, Grad norm: 2.158e-01\n",
      "Epoch 8193, Loss: 0.24232123792171478, Neurons: 64, Grad norm: 2.157e-01\n",
      "Epoch 8193, Loss: 0.24232123792171478, Neurons: 64, Grad norm: 2.157e-01\n",
      "Epoch 8194, Loss: 0.24186795949935913, Neurons: 64, Grad norm: 2.148e-01\n",
      "Epoch 8194, Loss: 0.24186795949935913, Neurons: 64, Grad norm: 2.148e-01\n",
      "Epoch 8195, Loss: 0.24141569435596466, Neurons: 64, Grad norm: 2.156e-01\n",
      "Epoch 8195, Loss: 0.24141569435596466, Neurons: 64, Grad norm: 2.156e-01\n",
      "Epoch 8196, Loss: 0.24096421897411346, Neurons: 64, Grad norm: 2.149e-01\n",
      "Epoch 8196, Loss: 0.24096421897411346, Neurons: 64, Grad norm: 2.149e-01\n",
      "Epoch 8197, Loss: 0.24051377177238464, Neurons: 64, Grad norm: 2.161e-01\n",
      "Epoch 8197, Loss: 0.24051377177238464, Neurons: 64, Grad norm: 2.161e-01\n",
      "Epoch 8198, Loss: 0.2400648295879364, Neurons: 64, Grad norm: 2.134e-01\n",
      "Epoch 8198, Loss: 0.2400648295879364, Neurons: 64, Grad norm: 2.134e-01\n",
      "Epoch 8199, Loss: 0.2396160364151001, Neurons: 64, Grad norm: 2.167e-01\n",
      "Epoch 8199, Loss: 0.2396160364151001, Neurons: 64, Grad norm: 2.167e-01\n",
      "Epoch 8199, Test loss: 0.17584869265556335\n",
      "Epoch 8199, Test loss: 0.17584869265556335\n",
      "Epoch 8200, Loss: 0.23916810750961304, Neurons: 64, Grad norm: 2.130e-01\n",
      "Epoch 8200, Loss: 0.23916810750961304, Neurons: 64, Grad norm: 2.130e-01\n",
      "Epoch 8201, Loss: 0.23872219026088715, Neurons: 64, Grad norm: 2.174e-01\n",
      "Epoch 8201, Loss: 0.23872219026088715, Neurons: 64, Grad norm: 2.174e-01\n",
      "Epoch 8202, Loss: 0.23827672004699707, Neurons: 64, Grad norm: 2.164e-01\n",
      "Epoch 8202, Loss: 0.23827672004699707, Neurons: 64, Grad norm: 2.164e-01\n",
      "Epoch 8203, Loss: 0.23783238232135773, Neurons: 64, Grad norm: 2.353e-01\n",
      "Epoch 8203, Loss: 0.23783238232135773, Neurons: 64, Grad norm: 2.353e-01\n",
      "Epoch 8204, Loss: 0.23738880455493927, Neurons: 64, Grad norm: 2.418e-01\n",
      "Epoch 8204, Loss: 0.23738880455493927, Neurons: 64, Grad norm: 2.418e-01\n",
      "Epoch 8205, Loss: 0.23694641888141632, Neurons: 64, Grad norm: 2.935e-01\n",
      "Epoch 8205, Loss: 0.23694641888141632, Neurons: 64, Grad norm: 2.935e-01\n",
      "Epoch 8206, Loss: 0.236504927277565, Neurons: 64, Grad norm: 3.344e-01\n",
      "Epoch 8206, Loss: 0.236504927277565, Neurons: 64, Grad norm: 3.344e-01\n",
      "Epoch 8207, Loss: 0.23606523871421814, Neurons: 64, Grad norm: 4.475e-01\n",
      "Epoch 8207, Loss: 0.23606523871421814, Neurons: 64, Grad norm: 4.475e-01\n",
      "Epoch 8208, Loss: 0.23562704026699066, Neurons: 64, Grad norm: 5.714e-01\n",
      "Epoch 8208, Loss: 0.23562704026699066, Neurons: 64, Grad norm: 5.714e-01\n",
      "Epoch 8209, Loss: 0.23519133031368256, Neurons: 64, Grad norm: 8.230e-01\n",
      "Epoch 8209, Loss: 0.23519133031368256, Neurons: 64, Grad norm: 8.230e-01\n",
      "Epoch 8210, Loss: 0.23475950956344604, Neurons: 64, Grad norm: 1.085e+00\n",
      "Epoch 8210, Loss: 0.23475950956344604, Neurons: 64, Grad norm: 1.085e+00\n",
      "Epoch 8211, Loss: 0.23433229327201843, Neurons: 64, Grad norm: 1.457e+00\n",
      "Epoch 8211, Loss: 0.23433229327201843, Neurons: 64, Grad norm: 1.457e+00\n",
      "Epoch 8212, Loss: 0.23391062021255493, Neurons: 64, Grad norm: 1.754e+00\n",
      "Epoch 8212, Loss: 0.23391062021255493, Neurons: 64, Grad norm: 1.754e+00\n",
      "Epoch 8213, Loss: 0.23349256813526154, Neurons: 64, Grad norm: 1.988e+00\n",
      "Epoch 8213, Loss: 0.23349256813526154, Neurons: 64, Grad norm: 1.988e+00\n",
      "Epoch 8214, Loss: 0.23307082056999207, Neurons: 64, Grad norm: 1.963e+00\n",
      "Epoch 8214, Loss: 0.23307082056999207, Neurons: 64, Grad norm: 1.963e+00\n",
      "Epoch 8215, Loss: 0.23263715207576752, Neurons: 64, Grad norm: 1.736e+00\n",
      "Epoch 8215, Loss: 0.23263715207576752, Neurons: 64, Grad norm: 1.736e+00\n",
      "Epoch 8216, Loss: 0.23218916356563568, Neurons: 64, Grad norm: 1.220e+00\n",
      "Epoch 8216, Loss: 0.23218916356563568, Neurons: 64, Grad norm: 1.220e+00\n",
      "Epoch 8217, Loss: 0.23173420131206512, Neurons: 64, Grad norm: 6.074e-01\n",
      "Epoch 8217, Loss: 0.23173420131206512, Neurons: 64, Grad norm: 6.074e-01\n",
      "Epoch 8218, Loss: 0.23128530383110046, Neurons: 64, Grad norm: 2.521e-01\n",
      "Epoch 8218, Loss: 0.23128530383110046, Neurons: 64, Grad norm: 2.521e-01\n",
      "Epoch 8219, Loss: 0.23085108399391174, Neurons: 64, Grad norm: 7.351e-01\n",
      "Epoch 8219, Loss: 0.23085108399391174, Neurons: 64, Grad norm: 7.351e-01\n",
      "Epoch 8220, Loss: 0.23043091595172882, Neurons: 64, Grad norm: 1.168e+00\n",
      "Epoch 8220, Loss: 0.23043091595172882, Neurons: 64, Grad norm: 1.168e+00\n",
      "Epoch 8221, Loss: 0.23001694679260254, Neurons: 64, Grad norm: 1.318e+00\n",
      "Epoch 8221, Loss: 0.23001694679260254, Neurons: 64, Grad norm: 1.318e+00\n",
      "Epoch 8222, Loss: 0.22959791123867035, Neurons: 64, Grad norm: 1.286e+00\n",
      "Epoch 8222, Loss: 0.22959791123867035, Neurons: 64, Grad norm: 1.286e+00\n",
      "Epoch 8223, Loss: 0.2291695922613144, Neurons: 64, Grad norm: 9.843e-01\n",
      "Epoch 8223, Loss: 0.2291695922613144, Neurons: 64, Grad norm: 9.843e-01\n",
      "Epoch 8224, Loss: 0.22873464226722717, Neurons: 64, Grad norm: 5.814e-01\n",
      "Epoch 8224, Loss: 0.22873464226722717, Neurons: 64, Grad norm: 5.814e-01\n",
      "Epoch 8225, Loss: 0.22830034792423248, Neurons: 64, Grad norm: 2.066e-01\n",
      "Epoch 8225, Loss: 0.22830034792423248, Neurons: 64, Grad norm: 2.066e-01\n",
      "Epoch 8226, Loss: 0.22787342965602875, Neurons: 64, Grad norm: 4.450e-01\n",
      "Epoch 8226, Loss: 0.22787342965602875, Neurons: 64, Grad norm: 4.450e-01\n",
      "Epoch 8227, Loss: 0.22745421528816223, Neurons: 64, Grad norm: 7.754e-01\n",
      "Epoch 8227, Loss: 0.22745421528816223, Neurons: 64, Grad norm: 7.754e-01\n",
      "Epoch 8228, Loss: 0.22703947126865387, Neurons: 64, Grad norm: 9.157e-01\n",
      "Epoch 8228, Loss: 0.22703947126865387, Neurons: 64, Grad norm: 9.157e-01\n",
      "Epoch 8229, Loss: 0.22662433981895447, Neurons: 64, Grad norm: 9.353e-01\n",
      "Epoch 8229, Loss: 0.22662433981895447, Neurons: 64, Grad norm: 9.353e-01\n",
      "Epoch 8230, Loss: 0.22620505094528198, Neurons: 64, Grad norm: 7.459e-01\n",
      "Epoch 8230, Loss: 0.22620505094528198, Neurons: 64, Grad norm: 7.459e-01\n",
      "Epoch 8231, Loss: 0.22578249871730804, Neurons: 64, Grad norm: 5.083e-01\n",
      "Epoch 8231, Loss: 0.22578249871730804, Neurons: 64, Grad norm: 5.083e-01\n",
      "Epoch 8232, Loss: 0.22536060214042664, Neurons: 64, Grad norm: 2.268e-01\n",
      "Epoch 8232, Loss: 0.22536060214042664, Neurons: 64, Grad norm: 2.268e-01\n",
      "Epoch 8233, Loss: 0.22494135797023773, Neurons: 64, Grad norm: 2.805e-01\n",
      "Epoch 8233, Loss: 0.22494135797023773, Neurons: 64, Grad norm: 2.805e-01\n",
      "Epoch 8234, Loss: 0.22452658414840698, Neurons: 64, Grad norm: 5.142e-01\n",
      "Epoch 8234, Loss: 0.22452658414840698, Neurons: 64, Grad norm: 5.142e-01\n",
      "Epoch 8235, Loss: 0.22411492466926575, Neurons: 64, Grad norm: 6.357e-01\n",
      "Epoch 8235, Loss: 0.22411492466926575, Neurons: 64, Grad norm: 6.357e-01\n",
      "Epoch 8236, Loss: 0.22370415925979614, Neurons: 64, Grad norm: 6.917e-01\n",
      "Epoch 8236, Loss: 0.22370415925979614, Neurons: 64, Grad norm: 6.917e-01\n",
      "Epoch 8237, Loss: 0.22329220175743103, Neurons: 64, Grad norm: 5.975e-01\n",
      "Epoch 8237, Loss: 0.22329220175743103, Neurons: 64, Grad norm: 5.975e-01\n",
      "Epoch 8238, Loss: 0.22287923097610474, Neurons: 64, Grad norm: 4.748e-01\n",
      "Epoch 8238, Loss: 0.22287923097610474, Neurons: 64, Grad norm: 4.748e-01\n",
      "Epoch 8239, Loss: 0.2224661260843277, Neurons: 64, Grad norm: 2.751e-01\n",
      "Epoch 8239, Loss: 0.2224661260843277, Neurons: 64, Grad norm: 2.751e-01\n",
      "Epoch 8240, Loss: 0.22205384075641632, Neurons: 64, Grad norm: 2.012e-01\n",
      "Epoch 8240, Loss: 0.22205384075641632, Neurons: 64, Grad norm: 2.012e-01\n",
      "Epoch 8241, Loss: 0.22164441645145416, Neurons: 64, Grad norm: 3.080e-01\n",
      "Epoch 8241, Loss: 0.22164441645145416, Neurons: 64, Grad norm: 3.080e-01\n",
      "Epoch 8242, Loss: 0.2212371677160263, Neurons: 64, Grad norm: 4.070e-01\n",
      "Epoch 8242, Loss: 0.2212371677160263, Neurons: 64, Grad norm: 4.070e-01\n",
      "Epoch 8243, Loss: 0.22083142399787903, Neurons: 64, Grad norm: 4.931e-01\n",
      "Epoch 8243, Loss: 0.22083142399787903, Neurons: 64, Grad norm: 4.931e-01\n",
      "Epoch 8244, Loss: 0.2204265296459198, Neurons: 64, Grad norm: 4.748e-01\n",
      "Epoch 8244, Loss: 0.2204265296459198, Neurons: 64, Grad norm: 4.748e-01\n",
      "Epoch 8245, Loss: 0.22002078592777252, Neurons: 64, Grad norm: 4.444e-01\n",
      "Epoch 8245, Loss: 0.22002078592777252, Neurons: 64, Grad norm: 4.444e-01\n",
      "Epoch 8246, Loss: 0.21961569786071777, Neurons: 64, Grad norm: 3.242e-01\n",
      "Epoch 8246, Loss: 0.21961569786071777, Neurons: 64, Grad norm: 3.242e-01\n",
      "Epoch 8247, Loss: 0.21921086311340332, Neurons: 64, Grad norm: 2.459e-01\n",
      "Epoch 8247, Loss: 0.21921086311340332, Neurons: 64, Grad norm: 2.459e-01\n",
      "Epoch 8248, Loss: 0.2188071757555008, Neurons: 64, Grad norm: 1.999e-01\n",
      "Epoch 8248, Loss: 0.2188071757555008, Neurons: 64, Grad norm: 1.999e-01\n",
      "Epoch 8249, Loss: 0.21840494871139526, Neurons: 64, Grad norm: 2.325e-01\n",
      "Epoch 8249, Loss: 0.21840494871139526, Neurons: 64, Grad norm: 2.325e-01\n",
      "Epoch 8250, Loss: 0.2180042862892151, Neurons: 64, Grad norm: 3.174e-01\n",
      "Epoch 8250, Loss: 0.2180042862892151, Neurons: 64, Grad norm: 3.174e-01\n",
      "Epoch 8251, Loss: 0.21760478615760803, Neurons: 64, Grad norm: 3.432e-01\n",
      "Epoch 8251, Loss: 0.21760478615760803, Neurons: 64, Grad norm: 3.432e-01\n",
      "Epoch 8252, Loss: 0.21720585227012634, Neurons: 64, Grad norm: 3.805e-01\n",
      "Epoch 8252, Loss: 0.21720585227012634, Neurons: 64, Grad norm: 3.805e-01\n",
      "Epoch 8253, Loss: 0.21680781245231628, Neurons: 64, Grad norm: 3.461e-01\n",
      "Epoch 8253, Loss: 0.21680781245231628, Neurons: 64, Grad norm: 3.461e-01\n",
      "Epoch 8254, Loss: 0.2164103090763092, Neurons: 64, Grad norm: 3.158e-01\n",
      "Epoch 8254, Loss: 0.2164103090763092, Neurons: 64, Grad norm: 3.158e-01\n",
      "Epoch 8255, Loss: 0.21601302921772003, Neurons: 64, Grad norm: 2.408e-01\n",
      "Epoch 8255, Loss: 0.21601302921772003, Neurons: 64, Grad norm: 2.408e-01\n",
      "Epoch 8256, Loss: 0.21561689674854279, Neurons: 64, Grad norm: 2.143e-01\n",
      "Epoch 8256, Loss: 0.21561689674854279, Neurons: 64, Grad norm: 2.143e-01\n",
      "Epoch 8257, Loss: 0.2152216136455536, Neurons: 64, Grad norm: 1.980e-01\n",
      "Epoch 8257, Loss: 0.2152216136455536, Neurons: 64, Grad norm: 1.980e-01\n",
      "Epoch 8258, Loss: 0.214827299118042, Neurons: 64, Grad norm: 2.089e-01\n",
      "Epoch 8258, Loss: 0.214827299118042, Neurons: 64, Grad norm: 2.089e-01\n",
      "Epoch 8259, Loss: 0.2144346386194229, Neurons: 64, Grad norm: 2.525e-01\n",
      "Epoch 8259, Loss: 0.2144346386194229, Neurons: 64, Grad norm: 2.525e-01\n",
      "Epoch 8260, Loss: 0.21404233574867249, Neurons: 64, Grad norm: 2.637e-01\n",
      "Epoch 8260, Loss: 0.21404233574867249, Neurons: 64, Grad norm: 2.637e-01\n",
      "Epoch 8261, Loss: 0.21365118026733398, Neurons: 64, Grad norm: 2.959e-01\n",
      "Epoch 8261, Loss: 0.21365118026733398, Neurons: 64, Grad norm: 2.959e-01\n",
      "Epoch 8262, Loss: 0.21326032280921936, Neurons: 64, Grad norm: 2.729e-01\n",
      "Epoch 8262, Loss: 0.21326032280921936, Neurons: 64, Grad norm: 2.729e-01\n",
      "Epoch 8263, Loss: 0.21287064254283905, Neurons: 64, Grad norm: 2.749e-01\n",
      "Epoch 8263, Loss: 0.21287064254283905, Neurons: 64, Grad norm: 2.749e-01\n",
      "Epoch 8264, Loss: 0.21248166263103485, Neurons: 64, Grad norm: 2.370e-01\n",
      "Epoch 8264, Loss: 0.21248166263103485, Neurons: 64, Grad norm: 2.370e-01\n",
      "Epoch 8265, Loss: 0.2120933085680008, Neurons: 64, Grad norm: 2.279e-01\n",
      "Epoch 8265, Loss: 0.2120933085680008, Neurons: 64, Grad norm: 2.279e-01\n",
      "Epoch 8266, Loss: 0.2117059975862503, Neurons: 64, Grad norm: 1.998e-01\n",
      "Epoch 8266, Loss: 0.2117059975862503, Neurons: 64, Grad norm: 1.998e-01\n",
      "Epoch 8267, Loss: 0.21131965517997742, Neurons: 64, Grad norm: 1.954e-01\n",
      "Epoch 8267, Loss: 0.21131965517997742, Neurons: 64, Grad norm: 1.954e-01\n",
      "Epoch 8268, Loss: 0.21093414723873138, Neurons: 64, Grad norm: 1.975e-01\n",
      "Epoch 8268, Loss: 0.21093414723873138, Neurons: 64, Grad norm: 1.975e-01\n",
      "Epoch 8269, Loss: 0.2105495035648346, Neurons: 64, Grad norm: 1.985e-01\n",
      "Epoch 8269, Loss: 0.2105495035648346, Neurons: 64, Grad norm: 1.985e-01\n",
      "Epoch 8270, Loss: 0.2101658433675766, Neurons: 64, Grad norm: 2.170e-01\n",
      "Epoch 8270, Loss: 0.2101658433675766, Neurons: 64, Grad norm: 2.170e-01\n",
      "Epoch 8271, Loss: 0.20978285372257233, Neurons: 64, Grad norm: 2.127e-01\n",
      "Epoch 8271, Loss: 0.20978285372257233, Neurons: 64, Grad norm: 2.127e-01\n",
      "Epoch 8272, Loss: 0.20940077304840088, Neurons: 64, Grad norm: 2.306e-01\n",
      "Epoch 8272, Loss: 0.20940077304840088, Neurons: 64, Grad norm: 2.306e-01\n",
      "Epoch 8273, Loss: 0.20901960134506226, Neurons: 64, Grad norm: 2.220e-01\n",
      "Epoch 8273, Loss: 0.20901960134506226, Neurons: 64, Grad norm: 2.220e-01\n",
      "Epoch 8274, Loss: 0.20863932371139526, Neurons: 64, Grad norm: 2.345e-01\n",
      "Epoch 8274, Loss: 0.20863932371139526, Neurons: 64, Grad norm: 2.345e-01\n",
      "Epoch 8275, Loss: 0.20826002955436707, Neurons: 64, Grad norm: 2.156e-01\n",
      "Epoch 8275, Loss: 0.20826002955436707, Neurons: 64, Grad norm: 2.156e-01\n",
      "Epoch 8276, Loss: 0.20788107812404633, Neurons: 64, Grad norm: 2.225e-01\n",
      "Epoch 8276, Loss: 0.20788107812404633, Neurons: 64, Grad norm: 2.225e-01\n",
      "Epoch 8277, Loss: 0.20750316977500916, Neurons: 64, Grad norm: 2.063e-01\n",
      "Epoch 8277, Loss: 0.20750316977500916, Neurons: 64, Grad norm: 2.063e-01\n",
      "Epoch 8278, Loss: 0.20712582767009735, Neurons: 64, Grad norm: 2.102e-01\n",
      "Epoch 8278, Loss: 0.20712582767009735, Neurons: 64, Grad norm: 2.102e-01\n",
      "Epoch 8279, Loss: 0.20674945414066315, Neurons: 64, Grad norm: 1.967e-01\n",
      "Epoch 8279, Loss: 0.20674945414066315, Neurons: 64, Grad norm: 1.967e-01\n",
      "Epoch 8280, Loss: 0.20637397468090057, Neurons: 64, Grad norm: 1.971e-01\n",
      "Epoch 8280, Loss: 0.20637397468090057, Neurons: 64, Grad norm: 1.971e-01\n",
      "Epoch 8281, Loss: 0.20599940419197083, Neurons: 64, Grad norm: 1.895e-01\n",
      "Epoch 8281, Loss: 0.20599940419197083, Neurons: 64, Grad norm: 1.895e-01\n",
      "Epoch 8282, Loss: 0.2056255042552948, Neurons: 64, Grad norm: 1.908e-01\n",
      "Epoch 8282, Loss: 0.2056255042552948, Neurons: 64, Grad norm: 1.908e-01\n",
      "Epoch 8283, Loss: 0.20525199174880981, Neurons: 64, Grad norm: 1.895e-01\n",
      "Epoch 8283, Loss: 0.20525199174880981, Neurons: 64, Grad norm: 1.895e-01\n",
      "Epoch 8284, Loss: 0.204880028963089, Neurons: 64, Grad norm: 1.892e-01\n",
      "Epoch 8284, Loss: 0.204880028963089, Neurons: 64, Grad norm: 1.892e-01\n",
      "Epoch 8285, Loss: 0.20450852811336517, Neurons: 64, Grad norm: 1.906e-01\n",
      "Epoch 8285, Loss: 0.20450852811336517, Neurons: 64, Grad norm: 1.906e-01\n",
      "Epoch 8286, Loss: 0.20413769781589508, Neurons: 64, Grad norm: 1.885e-01\n",
      "Epoch 8286, Loss: 0.20413769781589508, Neurons: 64, Grad norm: 1.885e-01\n",
      "Epoch 8287, Loss: 0.2037678360939026, Neurons: 64, Grad norm: 1.903e-01\n",
      "Epoch 8287, Loss: 0.2037678360939026, Neurons: 64, Grad norm: 1.903e-01\n",
      "Epoch 8288, Loss: 0.20339903235435486, Neurons: 64, Grad norm: 1.879e-01\n",
      "Epoch 8288, Loss: 0.20339903235435486, Neurons: 64, Grad norm: 1.879e-01\n",
      "Epoch 8289, Loss: 0.2030305415391922, Neurons: 64, Grad norm: 1.930e-01\n",
      "Epoch 8289, Loss: 0.2030305415391922, Neurons: 64, Grad norm: 1.930e-01\n",
      "Epoch 8290, Loss: 0.20266306400299072, Neurons: 64, Grad norm: 1.900e-01\n",
      "Epoch 8290, Loss: 0.20266306400299072, Neurons: 64, Grad norm: 1.900e-01\n",
      "Epoch 8291, Loss: 0.20229646563529968, Neurons: 64, Grad norm: 1.948e-01\n",
      "Epoch 8291, Loss: 0.20229646563529968, Neurons: 64, Grad norm: 1.948e-01\n",
      "Epoch 8292, Loss: 0.2019307017326355, Neurons: 64, Grad norm: 1.889e-01\n",
      "Epoch 8292, Loss: 0.2019307017326355, Neurons: 64, Grad norm: 1.889e-01\n",
      "Epoch 8293, Loss: 0.2015657126903534, Neurons: 64, Grad norm: 1.949e-01\n",
      "Epoch 8293, Loss: 0.2015657126903534, Neurons: 64, Grad norm: 1.949e-01\n",
      "Epoch 8294, Loss: 0.20120154321193695, Neurons: 64, Grad norm: 1.899e-01\n",
      "Epoch 8294, Loss: 0.20120154321193695, Neurons: 64, Grad norm: 1.899e-01\n",
      "Epoch 8295, Loss: 0.20083774626255035, Neurons: 64, Grad norm: 1.984e-01\n",
      "Epoch 8295, Loss: 0.20083774626255035, Neurons: 64, Grad norm: 1.984e-01\n",
      "Epoch 8296, Loss: 0.20047520101070404, Neurons: 64, Grad norm: 1.928e-01\n",
      "Epoch 8296, Loss: 0.20047520101070404, Neurons: 64, Grad norm: 1.928e-01\n",
      "Epoch 8297, Loss: 0.20011356472969055, Neurons: 64, Grad norm: 1.997e-01\n",
      "Epoch 8297, Loss: 0.20011356472969055, Neurons: 64, Grad norm: 1.997e-01\n",
      "Epoch 8298, Loss: 0.19975221157073975, Neurons: 64, Grad norm: 1.923e-01\n",
      "Epoch 8298, Loss: 0.19975221157073975, Neurons: 64, Grad norm: 1.923e-01\n",
      "Epoch 8299, Loss: 0.1993916928768158, Neurons: 64, Grad norm: 2.040e-01\n",
      "Epoch 8299, Loss: 0.1993916928768158, Neurons: 64, Grad norm: 2.040e-01\n",
      "Epoch 8299, Test loss: 0.14407913386821747\n",
      "Epoch 8299, Test loss: 0.14407913386821747\n",
      "Epoch 8300, Loss: 0.19903230667114258, Neurons: 64, Grad norm: 1.993e-01\n",
      "Epoch 8300, Loss: 0.19903230667114258, Neurons: 64, Grad norm: 1.993e-01\n",
      "Epoch 8301, Loss: 0.19867335259914398, Neurons: 64, Grad norm: 2.185e-01\n",
      "Epoch 8301, Loss: 0.19867335259914398, Neurons: 64, Grad norm: 2.185e-01\n",
      "Epoch 8302, Loss: 0.19831576943397522, Neurons: 64, Grad norm: 2.136e-01\n",
      "Epoch 8302, Loss: 0.19831576943397522, Neurons: 64, Grad norm: 2.136e-01\n",
      "Epoch 8303, Loss: 0.19795848429203033, Neurons: 64, Grad norm: 2.343e-01\n",
      "Epoch 8303, Loss: 0.19795848429203033, Neurons: 64, Grad norm: 2.343e-01\n",
      "Epoch 8304, Loss: 0.19760248064994812, Neurons: 64, Grad norm: 2.369e-01\n",
      "Epoch 8304, Loss: 0.19760248064994812, Neurons: 64, Grad norm: 2.369e-01\n",
      "Epoch 8305, Loss: 0.1972464621067047, Neurons: 64, Grad norm: 2.815e-01\n",
      "Epoch 8305, Loss: 0.1972464621067047, Neurons: 64, Grad norm: 2.815e-01\n",
      "Epoch 8306, Loss: 0.19689200818538666, Neurons: 64, Grad norm: 2.916e-01\n",
      "Epoch 8306, Loss: 0.19689200818538666, Neurons: 64, Grad norm: 2.916e-01\n",
      "Epoch 8307, Loss: 0.1965383142232895, Neurons: 64, Grad norm: 3.536e-01\n",
      "Epoch 8307, Loss: 0.1965383142232895, Neurons: 64, Grad norm: 3.536e-01\n",
      "Epoch 8308, Loss: 0.19618545472621918, Neurons: 64, Grad norm: 3.958e-01\n",
      "Epoch 8308, Loss: 0.19618545472621918, Neurons: 64, Grad norm: 3.958e-01\n",
      "Epoch 8309, Loss: 0.19583353400230408, Neurons: 64, Grad norm: 4.909e-01\n",
      "Epoch 8309, Loss: 0.19583353400230408, Neurons: 64, Grad norm: 4.909e-01\n",
      "Epoch 8310, Loss: 0.1954827904701233, Neurons: 64, Grad norm: 5.678e-01\n",
      "Epoch 8310, Loss: 0.1954827904701233, Neurons: 64, Grad norm: 5.678e-01\n",
      "Epoch 8311, Loss: 0.19513343274593353, Neurons: 64, Grad norm: 7.271e-01\n",
      "Epoch 8311, Loss: 0.19513343274593353, Neurons: 64, Grad norm: 7.271e-01\n",
      "Epoch 8312, Loss: 0.19478580355644226, Neurons: 64, Grad norm: 8.732e-01\n",
      "Epoch 8312, Loss: 0.19478580355644226, Neurons: 64, Grad norm: 8.732e-01\n",
      "Epoch 8313, Loss: 0.19444096088409424, Neurons: 64, Grad norm: 1.113e+00\n",
      "Epoch 8313, Loss: 0.19444096088409424, Neurons: 64, Grad norm: 1.113e+00\n",
      "Epoch 8314, Loss: 0.19409897923469543, Neurons: 64, Grad norm: 1.373e+00\n",
      "Epoch 8314, Loss: 0.19409897923469543, Neurons: 64, Grad norm: 1.373e+00\n",
      "Epoch 8315, Loss: 0.19376221299171448, Neurons: 64, Grad norm: 1.745e+00\n",
      "Epoch 8315, Loss: 0.19376221299171448, Neurons: 64, Grad norm: 1.745e+00\n",
      "Epoch 8316, Loss: 0.19343261420726776, Neurons: 64, Grad norm: 2.128e+00\n",
      "Epoch 8316, Loss: 0.19343261420726776, Neurons: 64, Grad norm: 2.128e+00\n",
      "Epoch 8317, Loss: 0.19311173260211945, Neurons: 64, Grad norm: 2.616e+00\n",
      "Epoch 8317, Loss: 0.19311173260211945, Neurons: 64, Grad norm: 2.616e+00\n",
      "Epoch 8318, Loss: 0.1928006261587143, Neurons: 64, Grad norm: 3.059e+00\n",
      "Epoch 8318, Loss: 0.1928006261587143, Neurons: 64, Grad norm: 3.059e+00\n",
      "Epoch 8319, Loss: 0.19249796867370605, Neurons: 64, Grad norm: 3.470e+00\n",
      "Epoch 8319, Loss: 0.19249796867370605, Neurons: 64, Grad norm: 3.470e+00\n",
      "Epoch 8320, Loss: 0.1921941339969635, Neurons: 64, Grad norm: 3.658e+00\n",
      "Epoch 8320, Loss: 0.1921941339969635, Neurons: 64, Grad norm: 3.658e+00\n",
      "Epoch 8321, Loss: 0.1918742060661316, Neurons: 64, Grad norm: 3.599e+00\n",
      "Epoch 8321, Loss: 0.1918742060661316, Neurons: 64, Grad norm: 3.599e+00\n",
      "Epoch 8322, Loss: 0.19152134656906128, Neurons: 64, Grad norm: 3.105e+00\n",
      "Epoch 8322, Loss: 0.19152134656906128, Neurons: 64, Grad norm: 3.105e+00\n",
      "Epoch 8323, Loss: 0.191131129860878, Neurons: 64, Grad norm: 2.311e+00\n",
      "Epoch 8323, Loss: 0.191131129860878, Neurons: 64, Grad norm: 2.311e+00\n",
      "Epoch 8324, Loss: 0.19072146713733673, Neurons: 64, Grad norm: 1.231e+00\n",
      "Epoch 8324, Loss: 0.19072146713733673, Neurons: 64, Grad norm: 1.231e+00\n",
      "Epoch 8325, Loss: 0.1903231292963028, Neurons: 64, Grad norm: 2.049e-01\n",
      "Epoch 8325, Loss: 0.1903231292963028, Neurons: 64, Grad norm: 2.049e-01\n",
      "Epoch 8326, Loss: 0.1899608075618744, Neurons: 64, Grad norm: 9.779e-01\n",
      "Epoch 8326, Loss: 0.1899608075618744, Neurons: 64, Grad norm: 9.779e-01\n",
      "Epoch 8327, Loss: 0.18963679671287537, Neurons: 64, Grad norm: 1.752e+00\n",
      "Epoch 8327, Loss: 0.18963679671287537, Neurons: 64, Grad norm: 1.752e+00\n",
      "Epoch 8328, Loss: 0.18933376669883728, Neurons: 64, Grad norm: 2.245e+00\n",
      "Epoch 8328, Loss: 0.18933376669883728, Neurons: 64, Grad norm: 2.245e+00\n",
      "Epoch 8329, Loss: 0.1890265792608261, Neurons: 64, Grad norm: 2.308e+00\n",
      "Epoch 8329, Loss: 0.1890265792608261, Neurons: 64, Grad norm: 2.308e+00\n",
      "Epoch 8330, Loss: 0.18869684636592865, Neurons: 64, Grad norm: 2.053e+00\n",
      "Epoch 8330, Loss: 0.18869684636592865, Neurons: 64, Grad norm: 2.053e+00\n",
      "Epoch 8331, Loss: 0.18834277987480164, Neurons: 64, Grad norm: 1.445e+00\n",
      "Epoch 8331, Loss: 0.18834277987480164, Neurons: 64, Grad norm: 1.445e+00\n",
      "Epoch 8332, Loss: 0.18797700107097626, Neurons: 64, Grad norm: 7.172e-01\n",
      "Epoch 8332, Loss: 0.18797700107097626, Neurons: 64, Grad norm: 7.172e-01\n",
      "Epoch 8333, Loss: 0.18761801719665527, Neurons: 64, Grad norm: 2.186e-01\n",
      "Epoch 8333, Loss: 0.18761801719665527, Neurons: 64, Grad norm: 2.186e-01\n",
      "Epoch 8334, Loss: 0.18727798759937286, Neurons: 64, Grad norm: 8.248e-01\n",
      "Epoch 8334, Loss: 0.18727798759937286, Neurons: 64, Grad norm: 8.248e-01\n",
      "Epoch 8335, Loss: 0.1869562417268753, Neurons: 64, Grad norm: 1.347e+00\n",
      "Epoch 8335, Loss: 0.1869562417268753, Neurons: 64, Grad norm: 1.347e+00\n",
      "Epoch 8336, Loss: 0.1866426169872284, Neurons: 64, Grad norm: 1.568e+00\n",
      "Epoch 8336, Loss: 0.1866426169872284, Neurons: 64, Grad norm: 1.568e+00\n",
      "Epoch 8337, Loss: 0.18632274866104126, Neurons: 64, Grad norm: 1.558e+00\n",
      "Epoch 8337, Loss: 0.18632274866104126, Neurons: 64, Grad norm: 1.558e+00\n",
      "Epoch 8338, Loss: 0.18599142134189606, Neurons: 64, Grad norm: 1.261e+00\n",
      "Epoch 8338, Loss: 0.18599142134189606, Neurons: 64, Grad norm: 1.261e+00\n",
      "Epoch 8339, Loss: 0.1856502890586853, Neurons: 64, Grad norm: 8.339e-01\n",
      "Epoch 8339, Loss: 0.1856502890586853, Neurons: 64, Grad norm: 8.339e-01\n",
      "Epoch 8340, Loss: 0.1853070706129074, Neurons: 64, Grad norm: 3.046e-01\n",
      "Epoch 8340, Loss: 0.1853070706129074, Neurons: 64, Grad norm: 3.046e-01\n",
      "Epoch 8341, Loss: 0.1849701851606369, Neurons: 64, Grad norm: 3.046e-01\n",
      "Epoch 8341, Loss: 0.1849701851606369, Neurons: 64, Grad norm: 3.046e-01\n",
      "Epoch 8342, Loss: 0.18464359641075134, Neurons: 64, Grad norm: 7.311e-01\n",
      "Epoch 8342, Loss: 0.18464359641075134, Neurons: 64, Grad norm: 7.311e-01\n",
      "Epoch 8343, Loss: 0.18432381749153137, Neurons: 64, Grad norm: 9.909e-01\n",
      "Epoch 8343, Loss: 0.18432381749153137, Neurons: 64, Grad norm: 9.909e-01\n",
      "Epoch 8344, Loss: 0.1840057671070099, Neurons: 64, Grad norm: 1.122e+00\n",
      "Epoch 8344, Loss: 0.1840057671070099, Neurons: 64, Grad norm: 1.122e+00\n",
      "Epoch 8345, Loss: 0.1836847960948944, Neurons: 64, Grad norm: 1.028e+00\n",
      "Epoch 8345, Loss: 0.1836847960948944, Neurons: 64, Grad norm: 1.028e+00\n",
      "Epoch 8346, Loss: 0.18335853517055511, Neurons: 64, Grad norm: 8.328e-01\n",
      "Epoch 8346, Loss: 0.18335853517055511, Neurons: 64, Grad norm: 8.328e-01\n",
      "Epoch 8347, Loss: 0.183028906583786, Neurons: 64, Grad norm: 5.118e-01\n",
      "Epoch 8347, Loss: 0.183028906583786, Neurons: 64, Grad norm: 5.118e-01\n",
      "Epoch 8348, Loss: 0.1826997548341751, Neurons: 64, Grad norm: 2.267e-01\n",
      "Epoch 8348, Loss: 0.1826997548341751, Neurons: 64, Grad norm: 2.267e-01\n",
      "Epoch 8349, Loss: 0.18237470090389252, Neurons: 64, Grad norm: 2.740e-01\n",
      "Epoch 8349, Loss: 0.18237470090389252, Neurons: 64, Grad norm: 2.740e-01\n",
      "Epoch 8350, Loss: 0.18205374479293823, Neurons: 64, Grad norm: 4.924e-01\n",
      "Epoch 8350, Loss: 0.18205374479293823, Neurons: 64, Grad norm: 4.924e-01\n",
      "Epoch 8351, Loss: 0.18173621594905853, Neurons: 64, Grad norm: 6.987e-01\n",
      "Epoch 8351, Loss: 0.18173621594905853, Neurons: 64, Grad norm: 6.987e-01\n",
      "Epoch 8352, Loss: 0.18141968548297882, Neurons: 64, Grad norm: 7.451e-01\n",
      "Epoch 8352, Loss: 0.18141968548297882, Neurons: 64, Grad norm: 7.451e-01\n",
      "Epoch 8353, Loss: 0.1811022013425827, Neurons: 64, Grad norm: 7.369e-01\n",
      "Epoch 8353, Loss: 0.1811022013425827, Neurons: 64, Grad norm: 7.369e-01\n",
      "Epoch 8354, Loss: 0.18078328669071198, Neurons: 64, Grad norm: 6.052e-01\n",
      "Epoch 8354, Loss: 0.18078328669071198, Neurons: 64, Grad norm: 6.052e-01\n",
      "Epoch 8355, Loss: 0.18046341836452484, Neurons: 64, Grad norm: 4.496e-01\n",
      "Epoch 8355, Loss: 0.18046341836452484, Neurons: 64, Grad norm: 4.496e-01\n",
      "Epoch 8356, Loss: 0.18014319241046906, Neurons: 64, Grad norm: 2.488e-01\n",
      "Epoch 8356, Loss: 0.18014319241046906, Neurons: 64, Grad norm: 2.488e-01\n",
      "Epoch 8357, Loss: 0.17982502281665802, Neurons: 64, Grad norm: 1.706e-01\n",
      "Epoch 8357, Loss: 0.17982502281665802, Neurons: 64, Grad norm: 1.706e-01\n",
      "Epoch 8358, Loss: 0.179508775472641, Neurons: 64, Grad norm: 2.842e-01\n",
      "Epoch 8358, Loss: 0.179508775472641, Neurons: 64, Grad norm: 2.842e-01\n",
      "Epoch 8359, Loss: 0.17919445037841797, Neurons: 64, Grad norm: 3.928e-01\n",
      "Epoch 8359, Loss: 0.17919445037841797, Neurons: 64, Grad norm: 3.928e-01\n",
      "Epoch 8360, Loss: 0.17888139188289642, Neurons: 64, Grad norm: 4.991e-01\n",
      "Epoch 8360, Loss: 0.17888139188289642, Neurons: 64, Grad norm: 4.991e-01\n",
      "Epoch 8361, Loss: 0.17856921255588531, Neurons: 64, Grad norm: 5.143e-01\n",
      "Epoch 8361, Loss: 0.17856921255588531, Neurons: 64, Grad norm: 5.143e-01\n",
      "Epoch 8362, Loss: 0.1782565861940384, Neurons: 64, Grad norm: 5.177e-01\n",
      "Epoch 8362, Loss: 0.1782565861940384, Neurons: 64, Grad norm: 5.177e-01\n",
      "Epoch 8363, Loss: 0.17794425785541534, Neurons: 64, Grad norm: 4.305e-01\n",
      "Epoch 8363, Loss: 0.17794425785541534, Neurons: 64, Grad norm: 4.305e-01\n",
      "Epoch 8364, Loss: 0.17763179540634155, Neurons: 64, Grad norm: 3.552e-01\n",
      "Epoch 8364, Loss: 0.17763179540634155, Neurons: 64, Grad norm: 3.552e-01\n",
      "Epoch 8365, Loss: 0.17731961607933044, Neurons: 64, Grad norm: 2.382e-01\n",
      "Epoch 8365, Loss: 0.17731961607933044, Neurons: 64, Grad norm: 2.382e-01\n",
      "Epoch 8366, Loss: 0.17700855433940887, Neurons: 64, Grad norm: 1.797e-01\n",
      "Epoch 8366, Loss: 0.17700855433940887, Neurons: 64, Grad norm: 1.797e-01\n",
      "Epoch 8367, Loss: 0.17669826745986938, Neurons: 64, Grad norm: 1.849e-01\n",
      "Epoch 8367, Loss: 0.17669826745986938, Neurons: 64, Grad norm: 1.849e-01\n",
      "Epoch 8368, Loss: 0.17638958990573883, Neurons: 64, Grad norm: 2.308e-01\n",
      "Epoch 8368, Loss: 0.17638958990573883, Neurons: 64, Grad norm: 2.308e-01\n",
      "Epoch 8369, Loss: 0.1760818213224411, Neurons: 64, Grad norm: 3.072e-01\n",
      "Epoch 8369, Loss: 0.1760818213224411, Neurons: 64, Grad norm: 3.072e-01\n",
      "Epoch 8370, Loss: 0.17577454447746277, Neurons: 64, Grad norm: 3.261e-01\n",
      "Epoch 8370, Loss: 0.17577454447746277, Neurons: 64, Grad norm: 3.261e-01\n",
      "Epoch 8371, Loss: 0.17546780407428741, Neurons: 64, Grad norm: 3.644e-01\n",
      "Epoch 8371, Loss: 0.17546780407428741, Neurons: 64, Grad norm: 3.644e-01\n",
      "Epoch 8372, Loss: 0.17516209185123444, Neurons: 64, Grad norm: 3.370e-01\n",
      "Epoch 8372, Loss: 0.17516209185123444, Neurons: 64, Grad norm: 3.370e-01\n",
      "Epoch 8373, Loss: 0.17485633492469788, Neurons: 64, Grad norm: 3.312e-01\n",
      "Epoch 8373, Loss: 0.17485633492469788, Neurons: 64, Grad norm: 3.312e-01\n",
      "Epoch 8374, Loss: 0.17455129325389862, Neurons: 64, Grad norm: 2.753e-01\n",
      "Epoch 8374, Loss: 0.17455129325389862, Neurons: 64, Grad norm: 2.753e-01\n",
      "Epoch 8375, Loss: 0.1742466241121292, Neurons: 64, Grad norm: 2.455e-01\n",
      "Epoch 8375, Loss: 0.1742466241121292, Neurons: 64, Grad norm: 2.455e-01\n",
      "Epoch 8376, Loss: 0.17394255101680756, Neurons: 64, Grad norm: 1.948e-01\n",
      "Epoch 8376, Loss: 0.17394255101680756, Neurons: 64, Grad norm: 1.948e-01\n",
      "Epoch 8377, Loss: 0.17363929748535156, Neurons: 64, Grad norm: 1.781e-01\n",
      "Epoch 8377, Loss: 0.17363929748535156, Neurons: 64, Grad norm: 1.781e-01\n",
      "Epoch 8378, Loss: 0.17333701252937317, Neurons: 64, Grad norm: 1.673e-01\n",
      "Epoch 8378, Loss: 0.17333701252937317, Neurons: 64, Grad norm: 1.673e-01\n",
      "Epoch 8379, Loss: 0.1730349212884903, Neurons: 64, Grad norm: 1.732e-01\n",
      "Epoch 8379, Loss: 0.1730349212884903, Neurons: 64, Grad norm: 1.732e-01\n",
      "Epoch 8380, Loss: 0.17273423075675964, Neurons: 64, Grad norm: 2.008e-01\n",
      "Epoch 8380, Loss: 0.17273423075675964, Neurons: 64, Grad norm: 2.008e-01\n",
      "Epoch 8381, Loss: 0.172434002161026, Neurons: 64, Grad norm: 2.068e-01\n",
      "Epoch 8381, Loss: 0.172434002161026, Neurons: 64, Grad norm: 2.068e-01\n",
      "Epoch 8382, Loss: 0.17213426530361176, Neurons: 64, Grad norm: 2.376e-01\n",
      "Epoch 8382, Loss: 0.17213426530361176, Neurons: 64, Grad norm: 2.376e-01\n",
      "Epoch 8383, Loss: 0.1718350350856781, Neurons: 64, Grad norm: 2.364e-01\n",
      "Epoch 8383, Loss: 0.1718350350856781, Neurons: 64, Grad norm: 2.364e-01\n",
      "Epoch 8384, Loss: 0.17153656482696533, Neurons: 64, Grad norm: 2.551e-01\n",
      "Epoch 8384, Loss: 0.17153656482696533, Neurons: 64, Grad norm: 2.551e-01\n",
      "Epoch 8385, Loss: 0.17123904824256897, Neurons: 64, Grad norm: 2.369e-01\n",
      "Epoch 8385, Loss: 0.17123904824256897, Neurons: 64, Grad norm: 2.369e-01\n",
      "Epoch 8386, Loss: 0.17094182968139648, Neurons: 64, Grad norm: 2.482e-01\n",
      "Epoch 8386, Loss: 0.17094182968139648, Neurons: 64, Grad norm: 2.482e-01\n",
      "Epoch 8387, Loss: 0.1706451028585434, Neurons: 64, Grad norm: 2.175e-01\n",
      "Epoch 8387, Loss: 0.1706451028585434, Neurons: 64, Grad norm: 2.175e-01\n",
      "Epoch 8388, Loss: 0.1703489124774933, Neurons: 64, Grad norm: 2.220e-01\n",
      "Epoch 8388, Loss: 0.1703489124774933, Neurons: 64, Grad norm: 2.220e-01\n",
      "Epoch 8389, Loss: 0.1700536459684372, Neurons: 64, Grad norm: 1.953e-01\n",
      "Epoch 8389, Loss: 0.1700536459684372, Neurons: 64, Grad norm: 1.953e-01\n",
      "Epoch 8390, Loss: 0.16975900530815125, Neurons: 64, Grad norm: 1.946e-01\n",
      "Epoch 8390, Loss: 0.16975900530815125, Neurons: 64, Grad norm: 1.946e-01\n",
      "Epoch 8391, Loss: 0.16946476697921753, Neurons: 64, Grad norm: 1.760e-01\n",
      "Epoch 8391, Loss: 0.16946476697921753, Neurons: 64, Grad norm: 1.760e-01\n",
      "Epoch 8392, Loss: 0.16917121410369873, Neurons: 64, Grad norm: 1.748e-01\n",
      "Epoch 8392, Loss: 0.16917121410369873, Neurons: 64, Grad norm: 1.748e-01\n",
      "Epoch 8393, Loss: 0.16887833178043365, Neurons: 64, Grad norm: 1.633e-01\n",
      "Epoch 8393, Loss: 0.16887833178043365, Neurons: 64, Grad norm: 1.633e-01\n",
      "Epoch 8394, Loss: 0.16858622431755066, Neurons: 64, Grad norm: 1.636e-01\n",
      "Epoch 8394, Loss: 0.16858622431755066, Neurons: 64, Grad norm: 1.636e-01\n",
      "Epoch 8395, Loss: 0.1682944893836975, Neurons: 64, Grad norm: 1.612e-01\n",
      "Epoch 8395, Loss: 0.1682944893836975, Neurons: 64, Grad norm: 1.612e-01\n",
      "Epoch 8396, Loss: 0.16800354421138763, Neurons: 64, Grad norm: 1.610e-01\n",
      "Epoch 8396, Loss: 0.16800354421138763, Neurons: 64, Grad norm: 1.610e-01\n",
      "Epoch 8397, Loss: 0.16771286725997925, Neurons: 64, Grad norm: 1.655e-01\n",
      "Epoch 8397, Loss: 0.16771286725997925, Neurons: 64, Grad norm: 1.655e-01\n",
      "Epoch 8398, Loss: 0.16742335259914398, Neurons: 64, Grad norm: 1.629e-01\n",
      "Epoch 8398, Loss: 0.16742335259914398, Neurons: 64, Grad norm: 1.629e-01\n",
      "Epoch 8399, Loss: 0.16713394224643707, Neurons: 64, Grad norm: 1.698e-01\n",
      "Epoch 8399, Loss: 0.16713394224643707, Neurons: 64, Grad norm: 1.698e-01\n",
      "Epoch 8399, Test loss: 0.11897144466638565\n",
      "Epoch 8399, Test loss: 0.11897144466638565\n",
      "Epoch 8400, Loss: 0.16684585809707642, Neurons: 64, Grad norm: 1.640e-01\n",
      "Epoch 8400, Loss: 0.16684585809707642, Neurons: 64, Grad norm: 1.640e-01\n",
      "Epoch 8401, Loss: 0.1665579229593277, Neurons: 64, Grad norm: 1.721e-01\n",
      "Epoch 8401, Loss: 0.1665579229593277, Neurons: 64, Grad norm: 1.721e-01\n",
      "Epoch 8402, Loss: 0.16627036035060883, Neurons: 64, Grad norm: 1.698e-01\n",
      "Epoch 8402, Loss: 0.16627036035060883, Neurons: 64, Grad norm: 1.698e-01\n",
      "Epoch 8403, Loss: 0.16598352789878845, Neurons: 64, Grad norm: 1.830e-01\n",
      "Epoch 8403, Loss: 0.16598352789878845, Neurons: 64, Grad norm: 1.830e-01\n",
      "Epoch 8404, Loss: 0.1656976044178009, Neurons: 64, Grad norm: 1.758e-01\n",
      "Epoch 8404, Loss: 0.1656976044178009, Neurons: 64, Grad norm: 1.758e-01\n",
      "Epoch 8405, Loss: 0.16541188955307007, Neurons: 64, Grad norm: 1.944e-01\n",
      "Epoch 8405, Loss: 0.16541188955307007, Neurons: 64, Grad norm: 1.944e-01\n",
      "Epoch 8406, Loss: 0.16512702405452728, Neurons: 64, Grad norm: 1.916e-01\n",
      "Epoch 8406, Loss: 0.16512702405452728, Neurons: 64, Grad norm: 1.916e-01\n",
      "Epoch 8407, Loss: 0.16484293341636658, Neurons: 64, Grad norm: 2.148e-01\n",
      "Epoch 8407, Loss: 0.16484293341636658, Neurons: 64, Grad norm: 2.148e-01\n",
      "Epoch 8408, Loss: 0.1645590215921402, Neurons: 64, Grad norm: 2.171e-01\n",
      "Epoch 8408, Loss: 0.1645590215921402, Neurons: 64, Grad norm: 2.171e-01\n",
      "Epoch 8409, Loss: 0.16427676379680634, Neurons: 64, Grad norm: 2.539e-01\n",
      "Epoch 8409, Loss: 0.16427676379680634, Neurons: 64, Grad norm: 2.539e-01\n",
      "Epoch 8410, Loss: 0.16399389505386353, Neurons: 64, Grad norm: 2.585e-01\n",
      "Epoch 8410, Loss: 0.16399389505386353, Neurons: 64, Grad norm: 2.585e-01\n",
      "Epoch 8411, Loss: 0.16371206939220428, Neurons: 64, Grad norm: 3.025e-01\n",
      "Epoch 8411, Loss: 0.16371206939220428, Neurons: 64, Grad norm: 3.025e-01\n",
      "Epoch 8412, Loss: 0.1634315401315689, Neurons: 64, Grad norm: 3.245e-01\n",
      "Epoch 8412, Loss: 0.1634315401315689, Neurons: 64, Grad norm: 3.245e-01\n",
      "Epoch 8413, Loss: 0.16315069794654846, Neurons: 64, Grad norm: 3.896e-01\n",
      "Epoch 8413, Loss: 0.16315069794654846, Neurons: 64, Grad norm: 3.896e-01\n",
      "Epoch 8414, Loss: 0.1628710776567459, Neurons: 64, Grad norm: 4.229e-01\n",
      "Epoch 8414, Loss: 0.1628710776567459, Neurons: 64, Grad norm: 4.229e-01\n",
      "Epoch 8415, Loss: 0.1625925749540329, Neurons: 64, Grad norm: 5.113e-01\n",
      "Epoch 8415, Loss: 0.1625925749540329, Neurons: 64, Grad norm: 5.113e-01\n",
      "Epoch 8416, Loss: 0.16231484711170197, Neurons: 64, Grad norm: 5.832e-01\n",
      "Epoch 8416, Loss: 0.16231484711170197, Neurons: 64, Grad norm: 5.832e-01\n",
      "Epoch 8417, Loss: 0.16203774511814117, Neurons: 64, Grad norm: 7.140e-01\n",
      "Epoch 8417, Loss: 0.16203774511814117, Neurons: 64, Grad norm: 7.140e-01\n",
      "Epoch 8418, Loss: 0.1617622673511505, Neurons: 64, Grad norm: 8.299e-01\n",
      "Epoch 8418, Loss: 0.1617622673511505, Neurons: 64, Grad norm: 8.299e-01\n",
      "Epoch 8419, Loss: 0.16148851811885834, Neurons: 64, Grad norm: 1.028e+00\n",
      "Epoch 8419, Loss: 0.16148851811885834, Neurons: 64, Grad norm: 1.028e+00\n",
      "Epoch 8420, Loss: 0.1612168699502945, Neurons: 64, Grad norm: 1.231e+00\n",
      "Epoch 8420, Loss: 0.1612168699502945, Neurons: 64, Grad norm: 1.231e+00\n",
      "Epoch 8421, Loss: 0.16094890236854553, Neurons: 64, Grad norm: 1.521e+00\n",
      "Epoch 8421, Loss: 0.16094890236854553, Neurons: 64, Grad norm: 1.521e+00\n",
      "Epoch 8422, Loss: 0.16068512201309204, Neurons: 64, Grad norm: 1.837e+00\n",
      "Epoch 8422, Loss: 0.16068512201309204, Neurons: 64, Grad norm: 1.837e+00\n",
      "Epoch 8423, Loss: 0.16042792797088623, Neurons: 64, Grad norm: 2.263e+00\n",
      "Epoch 8423, Loss: 0.16042792797088623, Neurons: 64, Grad norm: 2.263e+00\n",
      "Epoch 8424, Loss: 0.16017945110797882, Neurons: 64, Grad norm: 2.723e+00\n",
      "Epoch 8424, Loss: 0.16017945110797882, Neurons: 64, Grad norm: 2.723e+00\n",
      "Epoch 8425, Loss: 0.1599435806274414, Neurons: 64, Grad norm: 3.297e+00\n",
      "Epoch 8425, Loss: 0.1599435806274414, Neurons: 64, Grad norm: 3.297e+00\n",
      "Epoch 8426, Loss: 0.15972144901752472, Neurons: 64, Grad norm: 3.847e+00\n",
      "Epoch 8426, Loss: 0.15972144901752472, Neurons: 64, Grad norm: 3.847e+00\n",
      "Epoch 8427, Loss: 0.15951254963874817, Neurons: 64, Grad norm: 4.394e+00\n",
      "Epoch 8427, Loss: 0.15951254963874817, Neurons: 64, Grad norm: 4.394e+00\n",
      "Epoch 8428, Loss: 0.15930844843387604, Neurons: 64, Grad norm: 4.745e+00\n",
      "Epoch 8428, Loss: 0.15930844843387604, Neurons: 64, Grad norm: 4.745e+00\n",
      "Epoch 8429, Loss: 0.15908926725387573, Neurons: 64, Grad norm: 4.830e+00\n",
      "Epoch 8429, Loss: 0.15908926725387573, Neurons: 64, Grad norm: 4.830e+00\n",
      "Epoch 8430, Loss: 0.15882816910743713, Neurons: 64, Grad norm: 4.434e+00\n",
      "Epoch 8430, Loss: 0.15882816910743713, Neurons: 64, Grad norm: 4.434e+00\n",
      "Epoch 8431, Loss: 0.15850462019443512, Neurons: 64, Grad norm: 3.594e+00\n",
      "Epoch 8431, Loss: 0.15850462019443512, Neurons: 64, Grad norm: 3.594e+00\n",
      "Epoch 8432, Loss: 0.15812906622886658, Neurons: 64, Grad norm: 2.299e+00\n",
      "Epoch 8432, Loss: 0.15812906622886658, Neurons: 64, Grad norm: 2.299e+00\n",
      "Epoch 8433, Loss: 0.15774498879909515, Neurons: 64, Grad norm: 8.464e-01\n",
      "Epoch 8433, Loss: 0.15774498879909515, Neurons: 64, Grad norm: 8.464e-01\n",
      "Epoch 8434, Loss: 0.15740559995174408, Neurons: 64, Grad norm: 6.771e-01\n",
      "Epoch 8434, Loss: 0.15740559995174408, Neurons: 64, Grad norm: 6.771e-01\n",
      "Epoch 8435, Loss: 0.1571345031261444, Neurons: 64, Grad norm: 1.863e+00\n",
      "Epoch 8435, Loss: 0.1571345031261444, Neurons: 64, Grad norm: 1.863e+00\n",
      "Epoch 8436, Loss: 0.15691541135311127, Neurons: 64, Grad norm: 2.706e+00\n",
      "Epoch 8436, Loss: 0.15691541135311127, Neurons: 64, Grad norm: 2.706e+00\n",
      "Epoch 8437, Loss: 0.15670792758464813, Neurons: 64, Grad norm: 3.028e+00\n",
      "Epoch 8437, Loss: 0.15670792758464813, Neurons: 64, Grad norm: 3.028e+00\n",
      "Epoch 8438, Loss: 0.15647217631340027, Neurons: 64, Grad norm: 2.868e+00\n",
      "Epoch 8438, Loss: 0.15647217631340027, Neurons: 64, Grad norm: 2.868e+00\n",
      "Epoch 8439, Loss: 0.15619099140167236, Neurons: 64, Grad norm: 2.209e+00\n",
      "Epoch 8439, Loss: 0.15619099140167236, Neurons: 64, Grad norm: 2.209e+00\n",
      "Epoch 8440, Loss: 0.1558765023946762, Neurons: 64, Grad norm: 1.269e+00\n",
      "Epoch 8440, Loss: 0.1558765023946762, Neurons: 64, Grad norm: 1.269e+00\n",
      "Epoch 8441, Loss: 0.15556152164936066, Neurons: 64, Grad norm: 2.144e-01\n",
      "Epoch 8441, Loss: 0.15556152164936066, Neurons: 64, Grad norm: 2.144e-01\n",
      "Epoch 8442, Loss: 0.15527477860450745, Neurons: 64, Grad norm: 8.444e-01\n",
      "Epoch 8442, Loss: 0.15527477860450745, Neurons: 64, Grad norm: 8.444e-01\n",
      "Epoch 8443, Loss: 0.15502287447452545, Neurons: 64, Grad norm: 1.619e+00\n",
      "Epoch 8443, Loss: 0.15502287447452545, Neurons: 64, Grad norm: 1.619e+00\n",
      "Epoch 8444, Loss: 0.1547892540693283, Neurons: 64, Grad norm: 2.003e+00\n",
      "Epoch 8444, Loss: 0.1547892540693283, Neurons: 64, Grad norm: 2.003e+00\n",
      "Epoch 8445, Loss: 0.1545509248971939, Neurons: 64, Grad norm: 2.049e+00\n",
      "Epoch 8445, Loss: 0.1545509248971939, Neurons: 64, Grad norm: 2.049e+00\n",
      "Epoch 8446, Loss: 0.15429142117500305, Neurons: 64, Grad norm: 1.699e+00\n",
      "Epoch 8446, Loss: 0.15429142117500305, Neurons: 64, Grad norm: 1.699e+00\n",
      "Epoch 8447, Loss: 0.15401189029216766, Neurons: 64, Grad norm: 1.123e+00\n",
      "Epoch 8447, Loss: 0.15401189029216766, Neurons: 64, Grad norm: 1.123e+00\n",
      "Epoch 8448, Loss: 0.15372629463672638, Neurons: 64, Grad norm: 3.869e-01\n",
      "Epoch 8448, Loss: 0.15372629463672638, Neurons: 64, Grad norm: 3.869e-01\n",
      "Epoch 8449, Loss: 0.15345045924186707, Neurons: 64, Grad norm: 3.785e-01\n",
      "Epoch 8449, Loss: 0.15345045924186707, Neurons: 64, Grad norm: 3.785e-01\n",
      "Epoch 8450, Loss: 0.15319165587425232, Neurons: 64, Grad norm: 9.745e-01\n",
      "Epoch 8450, Loss: 0.15319165587425232, Neurons: 64, Grad norm: 9.745e-01\n",
      "Epoch 8451, Loss: 0.1529456526041031, Neurons: 64, Grad norm: 1.325e+00\n",
      "Epoch 8451, Loss: 0.1529456526041031, Neurons: 64, Grad norm: 1.325e+00\n",
      "Epoch 8452, Loss: 0.15270112454891205, Neurons: 64, Grad norm: 1.457e+00\n",
      "Epoch 8452, Loss: 0.15270112454891205, Neurons: 64, Grad norm: 1.457e+00\n",
      "Epoch 8453, Loss: 0.1524488925933838, Neurons: 64, Grad norm: 1.297e+00\n",
      "Epoch 8453, Loss: 0.1524488925933838, Neurons: 64, Grad norm: 1.297e+00\n",
      "Epoch 8454, Loss: 0.1521862894296646, Neurons: 64, Grad norm: 9.821e-01\n",
      "Epoch 8454, Loss: 0.1521862894296646, Neurons: 64, Grad norm: 9.821e-01\n",
      "Epoch 8455, Loss: 0.15191853046417236, Neurons: 64, Grad norm: 5.077e-01\n",
      "Epoch 8455, Loss: 0.15191853046417236, Neurons: 64, Grad norm: 5.077e-01\n",
      "Epoch 8456, Loss: 0.15165235102176666, Neurons: 64, Grad norm: 1.497e-01\n",
      "Epoch 8456, Loss: 0.15165235102176666, Neurons: 64, Grad norm: 1.497e-01\n",
      "Epoch 8457, Loss: 0.15139397978782654, Neurons: 64, Grad norm: 4.841e-01\n",
      "Epoch 8457, Loss: 0.15139397978782654, Neurons: 64, Grad norm: 4.841e-01\n",
      "Epoch 8458, Loss: 0.1511428952217102, Neurons: 64, Grad norm: 7.853e-01\n",
      "Epoch 8458, Loss: 0.1511428952217102, Neurons: 64, Grad norm: 7.853e-01\n",
      "Epoch 8459, Loss: 0.15089505910873413, Neurons: 64, Grad norm: 9.841e-01\n",
      "Epoch 8459, Loss: 0.15089505910873413, Neurons: 64, Grad norm: 9.841e-01\n",
      "Epoch 8460, Loss: 0.15064628422260284, Neurons: 64, Grad norm: 9.751e-01\n",
      "Epoch 8460, Loss: 0.15064628422260284, Neurons: 64, Grad norm: 9.751e-01\n",
      "Epoch 8461, Loss: 0.15039408206939697, Neurons: 64, Grad norm: 8.557e-01\n",
      "Epoch 8461, Loss: 0.15039408206939697, Neurons: 64, Grad norm: 8.557e-01\n",
      "Epoch 8462, Loss: 0.150137796998024, Neurons: 64, Grad norm: 5.892e-01\n",
      "Epoch 8462, Loss: 0.150137796998024, Neurons: 64, Grad norm: 5.892e-01\n",
      "Epoch 8463, Loss: 0.14988034963607788, Neurons: 64, Grad norm: 3.136e-01\n",
      "Epoch 8463, Loss: 0.14988034963607788, Neurons: 64, Grad norm: 3.136e-01\n",
      "Epoch 8464, Loss: 0.1496250331401825, Neurons: 64, Grad norm: 1.596e-01\n",
      "Epoch 8464, Loss: 0.1496250331401825, Neurons: 64, Grad norm: 1.596e-01\n",
      "Epoch 8465, Loss: 0.1493733525276184, Neurons: 64, Grad norm: 3.552e-01\n",
      "Epoch 8465, Loss: 0.1493733525276184, Neurons: 64, Grad norm: 3.552e-01\n",
      "Epoch 8466, Loss: 0.14912481606006622, Neurons: 64, Grad norm: 5.682e-01\n",
      "Epoch 8466, Loss: 0.14912481606006622, Neurons: 64, Grad norm: 5.682e-01\n",
      "Epoch 8467, Loss: 0.14887776970863342, Neurons: 64, Grad norm: 6.562e-01\n",
      "Epoch 8467, Loss: 0.14887776970863342, Neurons: 64, Grad norm: 6.562e-01\n",
      "Epoch 8468, Loss: 0.14863058924674988, Neurons: 64, Grad norm: 6.899e-01\n",
      "Epoch 8468, Loss: 0.14863058924674988, Neurons: 64, Grad norm: 6.899e-01\n",
      "Epoch 8469, Loss: 0.14838257431983948, Neurons: 64, Grad norm: 5.899e-01\n",
      "Epoch 8469, Loss: 0.14838257431983948, Neurons: 64, Grad norm: 5.899e-01\n",
      "Epoch 8470, Loss: 0.1481325924396515, Neurons: 64, Grad norm: 4.685e-01\n",
      "Epoch 8470, Loss: 0.1481325924396515, Neurons: 64, Grad norm: 4.685e-01\n",
      "Epoch 8471, Loss: 0.1478826105594635, Neurons: 64, Grad norm: 2.831e-01\n",
      "Epoch 8471, Loss: 0.1478826105594635, Neurons: 64, Grad norm: 2.831e-01\n",
      "Epoch 8472, Loss: 0.1476336419582367, Neurons: 64, Grad norm: 1.593e-01\n",
      "Epoch 8472, Loss: 0.1476336419582367, Neurons: 64, Grad norm: 1.593e-01\n",
      "Epoch 8473, Loss: 0.14738617837429047, Neurons: 64, Grad norm: 2.004e-01\n",
      "Epoch 8473, Loss: 0.14738617837429047, Neurons: 64, Grad norm: 2.004e-01\n",
      "Epoch 8474, Loss: 0.14714054763317108, Neurons: 64, Grad norm: 3.045e-01\n",
      "Epoch 8474, Loss: 0.14714054763317108, Neurons: 64, Grad norm: 3.045e-01\n",
      "Epoch 8475, Loss: 0.146895632147789, Neurons: 64, Grad norm: 4.231e-01\n",
      "Epoch 8475, Loss: 0.146895632147789, Neurons: 64, Grad norm: 4.231e-01\n",
      "Epoch 8476, Loss: 0.14665144681930542, Neurons: 64, Grad norm: 4.537e-01\n",
      "Epoch 8476, Loss: 0.14665144681930542, Neurons: 64, Grad norm: 4.537e-01\n",
      "Epoch 8477, Loss: 0.1464073210954666, Neurons: 64, Grad norm: 4.625e-01\n",
      "Epoch 8477, Loss: 0.1464073210954666, Neurons: 64, Grad norm: 4.625e-01\n",
      "Epoch 8478, Loss: 0.14616362750530243, Neurons: 64, Grad norm: 3.922e-01\n",
      "Epoch 8478, Loss: 0.14616362750530243, Neurons: 64, Grad norm: 3.922e-01\n",
      "Epoch 8479, Loss: 0.14591920375823975, Neurons: 64, Grad norm: 3.319e-01\n",
      "Epoch 8479, Loss: 0.14591920375823975, Neurons: 64, Grad norm: 3.319e-01\n",
      "Epoch 8480, Loss: 0.14567512273788452, Neurons: 64, Grad norm: 2.268e-01\n",
      "Epoch 8480, Loss: 0.14567512273788452, Neurons: 64, Grad norm: 2.268e-01\n",
      "Epoch 8481, Loss: 0.14543186128139496, Neurons: 64, Grad norm: 1.642e-01\n",
      "Epoch 8481, Loss: 0.14543186128139496, Neurons: 64, Grad norm: 1.642e-01\n",
      "Epoch 8482, Loss: 0.14518897235393524, Neurons: 64, Grad norm: 1.526e-01\n",
      "Epoch 8482, Loss: 0.14518897235393524, Neurons: 64, Grad norm: 1.526e-01\n",
      "Epoch 8483, Loss: 0.14494740962982178, Neurons: 64, Grad norm: 1.873e-01\n",
      "Epoch 8483, Loss: 0.14494740962982178, Neurons: 64, Grad norm: 1.873e-01\n",
      "Epoch 8484, Loss: 0.14470666646957397, Neurons: 64, Grad norm: 2.600e-01\n",
      "Epoch 8484, Loss: 0.14470666646957397, Neurons: 64, Grad norm: 2.600e-01\n",
      "Epoch 8485, Loss: 0.1444663554430008, Neurons: 64, Grad norm: 2.850e-01\n",
      "Epoch 8485, Loss: 0.1444663554430008, Neurons: 64, Grad norm: 2.850e-01\n",
      "Epoch 8486, Loss: 0.1442268192768097, Neurons: 64, Grad norm: 3.134e-01\n",
      "Epoch 8486, Loss: 0.1442268192768097, Neurons: 64, Grad norm: 3.134e-01\n",
      "Epoch 8487, Loss: 0.14398719370365143, Neurons: 64, Grad norm: 2.945e-01\n",
      "Epoch 8487, Loss: 0.14398719370365143, Neurons: 64, Grad norm: 2.945e-01\n",
      "Epoch 8488, Loss: 0.14374783635139465, Neurons: 64, Grad norm: 2.937e-01\n",
      "Epoch 8488, Loss: 0.14374783635139465, Neurons: 64, Grad norm: 2.937e-01\n",
      "Epoch 8489, Loss: 0.1435091495513916, Neurons: 64, Grad norm: 2.372e-01\n",
      "Epoch 8489, Loss: 0.1435091495513916, Neurons: 64, Grad norm: 2.372e-01\n",
      "Epoch 8490, Loss: 0.1432706117630005, Neurons: 64, Grad norm: 2.106e-01\n",
      "Epoch 8490, Loss: 0.1432706117630005, Neurons: 64, Grad norm: 2.106e-01\n",
      "Epoch 8491, Loss: 0.1430324763059616, Neurons: 64, Grad norm: 1.660e-01\n",
      "Epoch 8491, Loss: 0.1430324763059616, Neurons: 64, Grad norm: 1.660e-01\n",
      "Epoch 8492, Loss: 0.1427951455116272, Neurons: 64, Grad norm: 1.486e-01\n",
      "Epoch 8492, Loss: 0.1427951455116272, Neurons: 64, Grad norm: 1.486e-01\n",
      "Epoch 8493, Loss: 0.14255832135677338, Neurons: 64, Grad norm: 1.446e-01\n",
      "Epoch 8493, Loss: 0.14255832135677338, Neurons: 64, Grad norm: 1.446e-01\n",
      "Epoch 8494, Loss: 0.14232221245765686, Neurons: 64, Grad norm: 1.527e-01\n",
      "Epoch 8494, Loss: 0.14232221245765686, Neurons: 64, Grad norm: 1.527e-01\n",
      "Epoch 8495, Loss: 0.14208656549453735, Neurons: 64, Grad norm: 1.813e-01\n",
      "Epoch 8495, Loss: 0.14208656549453735, Neurons: 64, Grad norm: 1.813e-01\n",
      "Epoch 8496, Loss: 0.14185114204883575, Neurons: 64, Grad norm: 1.855e-01\n",
      "Epoch 8496, Loss: 0.14185114204883575, Neurons: 64, Grad norm: 1.855e-01\n",
      "Epoch 8497, Loss: 0.1416163146495819, Neurons: 64, Grad norm: 2.138e-01\n",
      "Epoch 8497, Loss: 0.1416163146495819, Neurons: 64, Grad norm: 2.138e-01\n",
      "Epoch 8498, Loss: 0.14138199388980865, Neurons: 64, Grad norm: 2.061e-01\n",
      "Epoch 8498, Loss: 0.14138199388980865, Neurons: 64, Grad norm: 2.061e-01\n",
      "Epoch 8499, Loss: 0.14114819467067719, Neurons: 64, Grad norm: 2.225e-01\n",
      "Epoch 8499, Loss: 0.14114819467067719, Neurons: 64, Grad norm: 2.225e-01\n",
      "Epoch 8499, Test loss: 0.09907221794128418\n",
      "Epoch 8499, Test loss: 0.09907221794128418\n",
      "Epoch 8500, Loss: 0.140915185213089, Neurons: 64, Grad norm: 2.111e-01\n",
      "Epoch 8500, Loss: 0.140915185213089, Neurons: 64, Grad norm: 2.111e-01\n",
      "Epoch 8501, Loss: 0.14068198204040527, Neurons: 64, Grad norm: 2.145e-01\n",
      "Epoch 8501, Loss: 0.14068198204040527, Neurons: 64, Grad norm: 2.145e-01\n",
      "Epoch 8502, Loss: 0.1404494345188141, Neurons: 64, Grad norm: 1.859e-01\n",
      "Epoch 8502, Loss: 0.1404494345188141, Neurons: 64, Grad norm: 1.859e-01\n",
      "Epoch 8503, Loss: 0.14021728932857513, Neurons: 64, Grad norm: 1.885e-01\n",
      "Epoch 8503, Loss: 0.14021728932857513, Neurons: 64, Grad norm: 1.885e-01\n",
      "Epoch 8504, Loss: 0.13998575508594513, Neurons: 64, Grad norm: 1.647e-01\n",
      "Epoch 8504, Loss: 0.13998575508594513, Neurons: 64, Grad norm: 1.647e-01\n",
      "Epoch 8505, Loss: 0.13975471258163452, Neurons: 64, Grad norm: 1.584e-01\n",
      "Epoch 8505, Loss: 0.13975471258163452, Neurons: 64, Grad norm: 1.584e-01\n",
      "Epoch 8506, Loss: 0.13952384889125824, Neurons: 64, Grad norm: 1.442e-01\n",
      "Epoch 8506, Loss: 0.13952384889125824, Neurons: 64, Grad norm: 1.442e-01\n",
      "Epoch 8507, Loss: 0.13929374516010284, Neurons: 64, Grad norm: 1.417e-01\n",
      "Epoch 8507, Loss: 0.13929374516010284, Neurons: 64, Grad norm: 1.417e-01\n",
      "Epoch 8508, Loss: 0.13906404376029968, Neurons: 64, Grad norm: 1.388e-01\n",
      "Epoch 8508, Loss: 0.13906404376029968, Neurons: 64, Grad norm: 1.388e-01\n",
      "Epoch 8509, Loss: 0.1388346254825592, Neurons: 64, Grad norm: 1.395e-01\n",
      "Epoch 8509, Loss: 0.1388346254825592, Neurons: 64, Grad norm: 1.395e-01\n",
      "Epoch 8510, Loss: 0.13860593736171722, Neurons: 64, Grad norm: 1.476e-01\n",
      "Epoch 8510, Loss: 0.13860593736171722, Neurons: 64, Grad norm: 1.476e-01\n",
      "Epoch 8511, Loss: 0.13837772607803345, Neurons: 64, Grad norm: 1.477e-01\n",
      "Epoch 8511, Loss: 0.13837772607803345, Neurons: 64, Grad norm: 1.477e-01\n",
      "Epoch 8512, Loss: 0.13814987242221832, Neurons: 64, Grad norm: 1.622e-01\n",
      "Epoch 8512, Loss: 0.13814987242221832, Neurons: 64, Grad norm: 1.622e-01\n",
      "Epoch 8513, Loss: 0.1379227191209793, Neurons: 64, Grad norm: 1.554e-01\n",
      "Epoch 8513, Loss: 0.1379227191209793, Neurons: 64, Grad norm: 1.554e-01\n",
      "Epoch 8514, Loss: 0.13769567012786865, Neurons: 64, Grad norm: 1.643e-01\n",
      "Epoch 8514, Loss: 0.13769567012786865, Neurons: 64, Grad norm: 1.643e-01\n",
      "Epoch 8515, Loss: 0.137469083070755, Neurons: 64, Grad norm: 1.613e-01\n",
      "Epoch 8515, Loss: 0.137469083070755, Neurons: 64, Grad norm: 1.613e-01\n",
      "Epoch 8516, Loss: 0.13724324107170105, Neurons: 64, Grad norm: 1.743e-01\n",
      "Epoch 8516, Loss: 0.13724324107170105, Neurons: 64, Grad norm: 1.743e-01\n",
      "Epoch 8517, Loss: 0.1370176523923874, Neurons: 64, Grad norm: 1.614e-01\n",
      "Epoch 8517, Loss: 0.1370176523923874, Neurons: 64, Grad norm: 1.614e-01\n",
      "Epoch 8518, Loss: 0.13679242134094238, Neurons: 64, Grad norm: 1.713e-01\n",
      "Epoch 8518, Loss: 0.13679242134094238, Neurons: 64, Grad norm: 1.713e-01\n",
      "Epoch 8519, Loss: 0.13656793534755707, Neurons: 64, Grad norm: 1.634e-01\n",
      "Epoch 8519, Loss: 0.13656793534755707, Neurons: 64, Grad norm: 1.634e-01\n",
      "Epoch 8520, Loss: 0.13634341955184937, Neurons: 64, Grad norm: 1.722e-01\n",
      "Epoch 8520, Loss: 0.13634341955184937, Neurons: 64, Grad norm: 1.722e-01\n",
      "Epoch 8521, Loss: 0.1361198127269745, Neurons: 64, Grad norm: 1.652e-01\n",
      "Epoch 8521, Loss: 0.1361198127269745, Neurons: 64, Grad norm: 1.652e-01\n",
      "Epoch 8522, Loss: 0.1358964592218399, Neurons: 64, Grad norm: 1.781e-01\n",
      "Epoch 8522, Loss: 0.1358964592218399, Neurons: 64, Grad norm: 1.781e-01\n",
      "Epoch 8523, Loss: 0.1356736272573471, Neurons: 64, Grad norm: 1.645e-01\n",
      "Epoch 8523, Loss: 0.1356736272573471, Neurons: 64, Grad norm: 1.645e-01\n",
      "Epoch 8524, Loss: 0.1354510635137558, Neurons: 64, Grad norm: 1.739e-01\n",
      "Epoch 8524, Loss: 0.1354510635137558, Neurons: 64, Grad norm: 1.739e-01\n",
      "Epoch 8525, Loss: 0.13522900640964508, Neurons: 64, Grad norm: 1.635e-01\n",
      "Epoch 8525, Loss: 0.13522900640964508, Neurons: 64, Grad norm: 1.635e-01\n",
      "Epoch 8526, Loss: 0.13500751554965973, Neurons: 64, Grad norm: 1.769e-01\n",
      "Epoch 8526, Loss: 0.13500751554965973, Neurons: 64, Grad norm: 1.769e-01\n",
      "Epoch 8527, Loss: 0.13478633761405945, Neurons: 64, Grad norm: 1.752e-01\n",
      "Epoch 8527, Loss: 0.13478633761405945, Neurons: 64, Grad norm: 1.752e-01\n",
      "Epoch 8528, Loss: 0.1345655620098114, Neurons: 64, Grad norm: 1.897e-01\n",
      "Epoch 8528, Loss: 0.1345655620098114, Neurons: 64, Grad norm: 1.897e-01\n",
      "Epoch 8529, Loss: 0.13434530794620514, Neurons: 64, Grad norm: 1.851e-01\n",
      "Epoch 8529, Loss: 0.13434530794620514, Neurons: 64, Grad norm: 1.851e-01\n",
      "Epoch 8530, Loss: 0.13412562012672424, Neurons: 64, Grad norm: 2.114e-01\n",
      "Epoch 8530, Loss: 0.13412562012672424, Neurons: 64, Grad norm: 2.114e-01\n",
      "Epoch 8531, Loss: 0.13390660285949707, Neurons: 64, Grad norm: 2.159e-01\n",
      "Epoch 8531, Loss: 0.13390660285949707, Neurons: 64, Grad norm: 2.159e-01\n",
      "Epoch 8532, Loss: 0.13368771970272064, Neurons: 64, Grad norm: 2.549e-01\n",
      "Epoch 8532, Loss: 0.13368771970272064, Neurons: 64, Grad norm: 2.549e-01\n",
      "Epoch 8533, Loss: 0.13346941769123077, Neurons: 64, Grad norm: 2.714e-01\n",
      "Epoch 8533, Loss: 0.13346941769123077, Neurons: 64, Grad norm: 2.714e-01\n",
      "Epoch 8534, Loss: 0.1332515925168991, Neurons: 64, Grad norm: 3.218e-01\n",
      "Epoch 8534, Loss: 0.1332515925168991, Neurons: 64, Grad norm: 3.218e-01\n",
      "Epoch 8535, Loss: 0.13303418457508087, Neurons: 64, Grad norm: 3.551e-01\n",
      "Epoch 8535, Loss: 0.13303418457508087, Neurons: 64, Grad norm: 3.551e-01\n",
      "Epoch 8536, Loss: 0.1328175663948059, Neurons: 64, Grad norm: 4.350e-01\n",
      "Epoch 8536, Loss: 0.1328175663948059, Neurons: 64, Grad norm: 4.350e-01\n",
      "Epoch 8537, Loss: 0.13260145485401154, Neurons: 64, Grad norm: 4.993e-01\n",
      "Epoch 8537, Loss: 0.13260145485401154, Neurons: 64, Grad norm: 4.993e-01\n",
      "Epoch 8538, Loss: 0.13238629698753357, Neurons: 64, Grad norm: 6.095e-01\n",
      "Epoch 8538, Loss: 0.13238629698753357, Neurons: 64, Grad norm: 6.095e-01\n",
      "Epoch 8539, Loss: 0.13217243552207947, Neurons: 64, Grad norm: 7.166e-01\n",
      "Epoch 8539, Loss: 0.13217243552207947, Neurons: 64, Grad norm: 7.166e-01\n",
      "Epoch 8540, Loss: 0.13195914030075073, Neurons: 64, Grad norm: 8.948e-01\n",
      "Epoch 8540, Loss: 0.13195914030075073, Neurons: 64, Grad norm: 8.948e-01\n",
      "Epoch 8541, Loss: 0.13174816966056824, Neurons: 64, Grad norm: 1.074e+00\n",
      "Epoch 8541, Loss: 0.13174816966056824, Neurons: 64, Grad norm: 1.074e+00\n",
      "Epoch 8542, Loss: 0.13153958320617676, Neurons: 64, Grad norm: 1.342e+00\n",
      "Epoch 8542, Loss: 0.13153958320617676, Neurons: 64, Grad norm: 1.342e+00\n",
      "Epoch 8543, Loss: 0.13133475184440613, Neurons: 64, Grad norm: 1.646e+00\n",
      "Epoch 8543, Loss: 0.13133475184440613, Neurons: 64, Grad norm: 1.646e+00\n",
      "Epoch 8544, Loss: 0.13113555312156677, Neurons: 64, Grad norm: 2.060e+00\n",
      "Epoch 8544, Loss: 0.13113555312156677, Neurons: 64, Grad norm: 2.060e+00\n",
      "Epoch 8545, Loss: 0.13094480335712433, Neurons: 64, Grad norm: 2.542e+00\n",
      "Epoch 8545, Loss: 0.13094480335712433, Neurons: 64, Grad norm: 2.542e+00\n",
      "Epoch 8546, Loss: 0.13076698780059814, Neurons: 64, Grad norm: 3.154e+00\n",
      "Epoch 8546, Loss: 0.13076698780059814, Neurons: 64, Grad norm: 3.154e+00\n",
      "Epoch 8547, Loss: 0.13060645759105682, Neurons: 64, Grad norm: 3.832e+00\n",
      "Epoch 8547, Loss: 0.13060645759105682, Neurons: 64, Grad norm: 3.832e+00\n",
      "Epoch 8548, Loss: 0.13046881556510925, Neurons: 64, Grad norm: 4.609e+00\n",
      "Epoch 8548, Loss: 0.13046881556510925, Neurons: 64, Grad norm: 4.609e+00\n",
      "Epoch 8549, Loss: 0.13035564124584198, Neurons: 64, Grad norm: 5.330e+00\n",
      "Epoch 8549, Loss: 0.13035564124584198, Neurons: 64, Grad norm: 5.330e+00\n",
      "Epoch 8550, Loss: 0.1302575170993805, Neurons: 64, Grad norm: 5.919e+00\n",
      "Epoch 8550, Loss: 0.1302575170993805, Neurons: 64, Grad norm: 5.919e+00\n",
      "Epoch 8551, Loss: 0.13014568388462067, Neurons: 64, Grad norm: 6.094e+00\n",
      "Epoch 8551, Loss: 0.13014568388462067, Neurons: 64, Grad norm: 6.094e+00\n",
      "Epoch 8552, Loss: 0.12997084856033325, Neurons: 64, Grad norm: 5.716e+00\n",
      "Epoch 8552, Loss: 0.12997084856033325, Neurons: 64, Grad norm: 5.716e+00\n",
      "Epoch 8553, Loss: 0.12968890368938446, Neurons: 64, Grad norm: 4.597e+00\n",
      "Epoch 8553, Loss: 0.12968890368938446, Neurons: 64, Grad norm: 4.597e+00\n",
      "Epoch 8554, Loss: 0.1293066442012787, Neurons: 64, Grad norm: 2.908e+00\n",
      "Epoch 8554, Loss: 0.1293066442012787, Neurons: 64, Grad norm: 2.908e+00\n",
      "Epoch 8555, Loss: 0.12890228629112244, Neurons: 64, Grad norm: 8.698e-01\n",
      "Epoch 8555, Loss: 0.12890228629112244, Neurons: 64, Grad norm: 8.698e-01\n",
      "Epoch 8556, Loss: 0.12857753038406372, Neurons: 64, Grad norm: 1.104e+00\n",
      "Epoch 8556, Loss: 0.12857753038406372, Neurons: 64, Grad norm: 1.104e+00\n",
      "Epoch 8557, Loss: 0.1283770203590393, Neurons: 64, Grad norm: 2.706e+00\n",
      "Epoch 8557, Loss: 0.1283770203590393, Neurons: 64, Grad norm: 2.706e+00\n",
      "Epoch 8558, Loss: 0.12826214730739594, Neurons: 64, Grad norm: 3.650e+00\n",
      "Epoch 8558, Loss: 0.12826214730739594, Neurons: 64, Grad norm: 3.650e+00\n",
      "Epoch 8559, Loss: 0.12814965844154358, Neurons: 64, Grad norm: 3.877e+00\n",
      "Epoch 8559, Loss: 0.12814965844154358, Neurons: 64, Grad norm: 3.877e+00\n",
      "Epoch 8560, Loss: 0.12796756625175476, Neurons: 64, Grad norm: 3.312e+00\n",
      "Epoch 8560, Loss: 0.12796756625175476, Neurons: 64, Grad norm: 3.312e+00\n",
      "Epoch 8561, Loss: 0.1277010142803192, Neurons: 64, Grad norm: 2.179e+00\n",
      "Epoch 8561, Loss: 0.1277010142803192, Neurons: 64, Grad norm: 2.179e+00\n",
      "Epoch 8562, Loss: 0.12739866971969604, Neurons: 64, Grad norm: 6.875e-01\n",
      "Epoch 8562, Loss: 0.12739866971969604, Neurons: 64, Grad norm: 6.875e-01\n",
      "Epoch 8563, Loss: 0.12712906301021576, Neurons: 64, Grad norm: 8.037e-01\n",
      "Epoch 8563, Loss: 0.12712906301021576, Neurons: 64, Grad norm: 8.037e-01\n",
      "Epoch 8564, Loss: 0.12692730128765106, Neurons: 64, Grad norm: 1.984e+00\n",
      "Epoch 8564, Loss: 0.12692730128765106, Neurons: 64, Grad norm: 1.984e+00\n",
      "Epoch 8565, Loss: 0.1267727166414261, Neurons: 64, Grad norm: 2.616e+00\n",
      "Epoch 8565, Loss: 0.1267727166414261, Neurons: 64, Grad norm: 2.616e+00\n",
      "Epoch 8566, Loss: 0.12661480903625488, Neurons: 64, Grad norm: 2.681e+00\n",
      "Epoch 8566, Loss: 0.12661480903625488, Neurons: 64, Grad norm: 2.681e+00\n",
      "Epoch 8567, Loss: 0.12641507387161255, Neurons: 64, Grad norm: 2.147e+00\n",
      "Epoch 8567, Loss: 0.12641507387161255, Neurons: 64, Grad norm: 2.147e+00\n",
      "Epoch 8568, Loss: 0.12617427110671997, Neurons: 64, Grad norm: 1.245e+00\n",
      "Epoch 8568, Loss: 0.12617427110671997, Neurons: 64, Grad norm: 1.245e+00\n",
      "Epoch 8569, Loss: 0.12592394649982452, Neurons: 64, Grad norm: 1.814e-01\n",
      "Epoch 8569, Loss: 0.12592394649982452, Neurons: 64, Grad norm: 1.814e-01\n",
      "Epoch 8570, Loss: 0.12569890916347504, Neurons: 64, Grad norm: 8.746e-01\n",
      "Epoch 8570, Loss: 0.12569890916347504, Neurons: 64, Grad norm: 8.746e-01\n",
      "Epoch 8571, Loss: 0.12550859153270721, Neurons: 64, Grad norm: 1.613e+00\n",
      "Epoch 8571, Loss: 0.12550859153270721, Neurons: 64, Grad norm: 1.613e+00\n",
      "Epoch 8572, Loss: 0.1253349483013153, Neurons: 64, Grad norm: 1.922e+00\n",
      "Epoch 8572, Loss: 0.1253349483013153, Neurons: 64, Grad norm: 1.922e+00\n",
      "Epoch 8573, Loss: 0.12515127658843994, Neurons: 64, Grad norm: 1.824e+00\n",
      "Epoch 8573, Loss: 0.12515127658843994, Neurons: 64, Grad norm: 1.824e+00\n",
      "Epoch 8574, Loss: 0.12494412809610367, Neurons: 64, Grad norm: 1.323e+00\n",
      "Epoch 8574, Loss: 0.12494412809610367, Neurons: 64, Grad norm: 1.323e+00\n",
      "Epoch 8575, Loss: 0.12472086399793625, Neurons: 64, Grad norm: 6.418e-01\n",
      "Epoch 8575, Loss: 0.12472086399793625, Neurons: 64, Grad norm: 6.418e-01\n",
      "Epoch 8576, Loss: 0.12449979037046432, Neurons: 64, Grad norm: 2.046e-01\n",
      "Epoch 8576, Loss: 0.12449979037046432, Neurons: 64, Grad norm: 2.046e-01\n",
      "Epoch 8577, Loss: 0.12429515272378922, Neurons: 64, Grad norm: 8.120e-01\n",
      "Epoch 8577, Loss: 0.12429515272378922, Neurons: 64, Grad norm: 8.120e-01\n",
      "Epoch 8578, Loss: 0.12410573661327362, Neurons: 64, Grad norm: 1.255e+00\n",
      "Epoch 8578, Loss: 0.12410573661327362, Neurons: 64, Grad norm: 1.255e+00\n",
      "Epoch 8579, Loss: 0.12392079830169678, Neurons: 64, Grad norm: 1.385e+00\n",
      "Epoch 8579, Loss: 0.12392079830169678, Neurons: 64, Grad norm: 1.385e+00\n",
      "Epoch 8580, Loss: 0.12372824549674988, Neurons: 64, Grad norm: 1.249e+00\n",
      "Epoch 8580, Loss: 0.12372824549674988, Neurons: 64, Grad norm: 1.249e+00\n",
      "Epoch 8581, Loss: 0.12352432310581207, Neurons: 64, Grad norm: 8.574e-01\n",
      "Epoch 8581, Loss: 0.12352432310581207, Neurons: 64, Grad norm: 8.574e-01\n",
      "Epoch 8582, Loss: 0.12331497669219971, Neurons: 64, Grad norm: 3.707e-01\n",
      "Epoch 8582, Loss: 0.12331497669219971, Neurons: 64, Grad norm: 3.707e-01\n",
      "Epoch 8583, Loss: 0.12310840934515, Neurons: 64, Grad norm: 2.379e-01\n",
      "Epoch 8583, Loss: 0.12310840934515, Neurons: 64, Grad norm: 2.379e-01\n",
      "Epoch 8584, Loss: 0.12291046977043152, Neurons: 64, Grad norm: 6.297e-01\n",
      "Epoch 8584, Loss: 0.12291046977043152, Neurons: 64, Grad norm: 6.297e-01\n",
      "Epoch 8585, Loss: 0.12271961569786072, Neurons: 64, Grad norm: 9.231e-01\n",
      "Epoch 8585, Loss: 0.12271961569786072, Neurons: 64, Grad norm: 9.231e-01\n",
      "Epoch 8586, Loss: 0.12253033369779587, Neurons: 64, Grad norm: 9.875e-01\n",
      "Epoch 8586, Loss: 0.12253033369779587, Neurons: 64, Grad norm: 9.875e-01\n",
      "Epoch 8587, Loss: 0.12233724445104599, Neurons: 64, Grad norm: 8.862e-01\n",
      "Epoch 8587, Loss: 0.12233724445104599, Neurons: 64, Grad norm: 8.862e-01\n",
      "Epoch 8588, Loss: 0.12213868647813797, Neurons: 64, Grad norm: 6.193e-01\n",
      "Epoch 8588, Loss: 0.12213868647813797, Neurons: 64, Grad norm: 6.193e-01\n",
      "Epoch 8589, Loss: 0.12193796038627625, Neurons: 64, Grad norm: 3.062e-01\n",
      "Epoch 8589, Loss: 0.12193796038627625, Neurons: 64, Grad norm: 3.062e-01\n",
      "Epoch 8590, Loss: 0.12173882126808167, Neurons: 64, Grad norm: 1.619e-01\n",
      "Epoch 8590, Loss: 0.12173882126808167, Neurons: 64, Grad norm: 1.619e-01\n",
      "Epoch 8591, Loss: 0.12154383212327957, Neurons: 64, Grad norm: 4.144e-01\n",
      "Epoch 8591, Loss: 0.12154383212327957, Neurons: 64, Grad norm: 4.144e-01\n",
      "Epoch 8592, Loss: 0.12135258316993713, Neurons: 64, Grad norm: 6.302e-01\n",
      "Epoch 8592, Loss: 0.12135258316993713, Neurons: 64, Grad norm: 6.302e-01\n",
      "Epoch 8593, Loss: 0.12116257101297379, Neurons: 64, Grad norm: 6.959e-01\n",
      "Epoch 8593, Loss: 0.12116257101297379, Neurons: 64, Grad norm: 6.959e-01\n",
      "Epoch 8594, Loss: 0.12097129225730896, Neurons: 64, Grad norm: 6.707e-01\n",
      "Epoch 8594, Loss: 0.12097129225730896, Neurons: 64, Grad norm: 6.707e-01\n",
      "Epoch 8595, Loss: 0.1207776814699173, Neurons: 64, Grad norm: 5.072e-01\n",
      "Epoch 8595, Loss: 0.1207776814699173, Neurons: 64, Grad norm: 5.072e-01\n",
      "Epoch 8596, Loss: 0.12058315426111221, Neurons: 64, Grad norm: 3.126e-01\n",
      "Epoch 8596, Loss: 0.12058315426111221, Neurons: 64, Grad norm: 3.126e-01\n",
      "Epoch 8597, Loss: 0.12038863450288773, Neurons: 64, Grad norm: 1.288e-01\n",
      "Epoch 8597, Loss: 0.12038863450288773, Neurons: 64, Grad norm: 1.288e-01\n",
      "Epoch 8598, Loss: 0.1201961562037468, Neurons: 64, Grad norm: 2.129e-01\n",
      "Epoch 8598, Loss: 0.1201961562037468, Neurons: 64, Grad norm: 2.129e-01\n",
      "Epoch 8599, Loss: 0.12000536173582077, Neurons: 64, Grad norm: 3.791e-01\n",
      "Epoch 8599, Loss: 0.12000536173582077, Neurons: 64, Grad norm: 3.791e-01\n",
      "Epoch 8599, Test loss: 0.0831272155046463\n",
      "Epoch 8599, Test loss: 0.0831272155046463\n",
      "Epoch 8600, Loss: 0.1198161244392395, Neurons: 64, Grad norm: 4.511e-01\n",
      "Epoch 8600, Loss: 0.1198161244392395, Neurons: 64, Grad norm: 4.511e-01\n",
      "Epoch 8601, Loss: 0.11962702870368958, Neurons: 64, Grad norm: 4.911e-01\n",
      "Epoch 8601, Loss: 0.11962702870368958, Neurons: 64, Grad norm: 4.911e-01\n",
      "Epoch 8602, Loss: 0.11943746358156204, Neurons: 64, Grad norm: 4.300e-01\n",
      "Epoch 8602, Loss: 0.11943746358156204, Neurons: 64, Grad norm: 4.300e-01\n",
      "Epoch 8603, Loss: 0.11924713850021362, Neurons: 64, Grad norm: 3.337e-01\n",
      "Epoch 8603, Loss: 0.11924713850021362, Neurons: 64, Grad norm: 3.337e-01\n",
      "Epoch 8604, Loss: 0.1190565675497055, Neurons: 64, Grad norm: 1.929e-01\n",
      "Epoch 8604, Loss: 0.1190565675497055, Neurons: 64, Grad norm: 1.929e-01\n",
      "Epoch 8605, Loss: 0.11886709928512573, Neurons: 64, Grad norm: 1.267e-01\n",
      "Epoch 8605, Loss: 0.11886709928512573, Neurons: 64, Grad norm: 1.267e-01\n",
      "Epoch 8606, Loss: 0.11867799609899521, Neurons: 64, Grad norm: 2.003e-01\n",
      "Epoch 8606, Loss: 0.11867799609899521, Neurons: 64, Grad norm: 2.003e-01\n",
      "Epoch 8607, Loss: 0.1184900775551796, Neurons: 64, Grad norm: 2.726e-01\n",
      "Epoch 8607, Loss: 0.1184900775551796, Neurons: 64, Grad norm: 2.726e-01\n",
      "Epoch 8608, Loss: 0.11830276995897293, Neurons: 64, Grad norm: 3.437e-01\n",
      "Epoch 8608, Loss: 0.11830276995897293, Neurons: 64, Grad norm: 3.437e-01\n",
      "Epoch 8609, Loss: 0.1181163415312767, Neurons: 64, Grad norm: 3.440e-01\n",
      "Epoch 8609, Loss: 0.1181163415312767, Neurons: 64, Grad norm: 3.440e-01\n",
      "Epoch 8610, Loss: 0.1179293617606163, Neurons: 64, Grad norm: 3.321e-01\n",
      "Epoch 8610, Loss: 0.1179293617606163, Neurons: 64, Grad norm: 3.321e-01\n",
      "Epoch 8611, Loss: 0.11774235963821411, Neurons: 64, Grad norm: 2.742e-01\n",
      "Epoch 8611, Loss: 0.11774235963821411, Neurons: 64, Grad norm: 2.742e-01\n",
      "Epoch 8612, Loss: 0.11755559593439102, Neurons: 64, Grad norm: 2.127e-01\n",
      "Epoch 8612, Loss: 0.11755559593439102, Neurons: 64, Grad norm: 2.127e-01\n",
      "Epoch 8613, Loss: 0.11736924201250076, Neurons: 64, Grad norm: 1.344e-01\n",
      "Epoch 8613, Loss: 0.11736924201250076, Neurons: 64, Grad norm: 1.344e-01\n",
      "Epoch 8614, Loss: 0.11718299239873886, Neurons: 64, Grad norm: 1.252e-01\n",
      "Epoch 8614, Loss: 0.11718299239873886, Neurons: 64, Grad norm: 1.252e-01\n",
      "Epoch 8615, Loss: 0.11699789017438889, Neurons: 64, Grad norm: 1.726e-01\n",
      "Epoch 8615, Loss: 0.11699789017438889, Neurons: 64, Grad norm: 1.726e-01\n",
      "Epoch 8616, Loss: 0.11681308597326279, Neurons: 64, Grad norm: 2.026e-01\n",
      "Epoch 8616, Loss: 0.11681308597326279, Neurons: 64, Grad norm: 2.026e-01\n",
      "Epoch 8617, Loss: 0.11662864685058594, Neurons: 64, Grad norm: 2.394e-01\n",
      "Epoch 8617, Loss: 0.11662864685058594, Neurons: 64, Grad norm: 2.394e-01\n",
      "Epoch 8618, Loss: 0.11644481122493744, Neurons: 64, Grad norm: 2.329e-01\n",
      "Epoch 8618, Loss: 0.11644481122493744, Neurons: 64, Grad norm: 2.329e-01\n",
      "Epoch 8619, Loss: 0.11626103520393372, Neurons: 64, Grad norm: 2.297e-01\n",
      "Epoch 8619, Loss: 0.11626103520393372, Neurons: 64, Grad norm: 2.297e-01\n",
      "Epoch 8620, Loss: 0.11607741564512253, Neurons: 64, Grad norm: 1.951e-01\n",
      "Epoch 8620, Loss: 0.11607741564512253, Neurons: 64, Grad norm: 1.951e-01\n",
      "Epoch 8621, Loss: 0.11589410156011581, Neurons: 64, Grad norm: 1.775e-01\n",
      "Epoch 8621, Loss: 0.11589410156011581, Neurons: 64, Grad norm: 1.775e-01\n",
      "Epoch 8622, Loss: 0.11571116745471954, Neurons: 64, Grad norm: 1.353e-01\n",
      "Epoch 8622, Loss: 0.11571116745471954, Neurons: 64, Grad norm: 1.353e-01\n",
      "Epoch 8623, Loss: 0.11552871018648148, Neurons: 64, Grad norm: 1.229e-01\n",
      "Epoch 8623, Loss: 0.11552871018648148, Neurons: 64, Grad norm: 1.229e-01\n",
      "Epoch 8624, Loss: 0.11534646898508072, Neurons: 64, Grad norm: 1.296e-01\n",
      "Epoch 8624, Loss: 0.11534646898508072, Neurons: 64, Grad norm: 1.296e-01\n",
      "Epoch 8625, Loss: 0.1151650920510292, Neurons: 64, Grad norm: 1.435e-01\n",
      "Epoch 8625, Loss: 0.1151650920510292, Neurons: 64, Grad norm: 1.435e-01\n",
      "Epoch 8626, Loss: 0.11498352885246277, Neurons: 64, Grad norm: 1.664e-01\n",
      "Epoch 8626, Loss: 0.11498352885246277, Neurons: 64, Grad norm: 1.664e-01\n",
      "Epoch 8627, Loss: 0.11480239033699036, Neurons: 64, Grad norm: 1.615e-01\n",
      "Epoch 8627, Loss: 0.11480239033699036, Neurons: 64, Grad norm: 1.615e-01\n",
      "Epoch 8628, Loss: 0.11462190002202988, Neurons: 64, Grad norm: 1.704e-01\n",
      "Epoch 8628, Loss: 0.11462190002202988, Neurons: 64, Grad norm: 1.704e-01\n",
      "Epoch 8629, Loss: 0.1144414022564888, Neurons: 64, Grad norm: 1.543e-01\n",
      "Epoch 8629, Loss: 0.1144414022564888, Neurons: 64, Grad norm: 1.543e-01\n",
      "Epoch 8630, Loss: 0.11426135152578354, Neurons: 64, Grad norm: 1.552e-01\n",
      "Epoch 8630, Loss: 0.11426135152578354, Neurons: 64, Grad norm: 1.552e-01\n",
      "Epoch 8631, Loss: 0.11408178508281708, Neurons: 64, Grad norm: 1.391e-01\n",
      "Epoch 8631, Loss: 0.11408178508281708, Neurons: 64, Grad norm: 1.391e-01\n",
      "Epoch 8632, Loss: 0.11390232294797897, Neurons: 64, Grad norm: 1.358e-01\n",
      "Epoch 8632, Loss: 0.11390232294797897, Neurons: 64, Grad norm: 1.358e-01\n",
      "Epoch 8633, Loss: 0.11372342705726624, Neurons: 64, Grad norm: 1.208e-01\n",
      "Epoch 8633, Loss: 0.11372342705726624, Neurons: 64, Grad norm: 1.208e-01\n",
      "Epoch 8634, Loss: 0.11354463547468185, Neurons: 64, Grad norm: 1.192e-01\n",
      "Epoch 8634, Loss: 0.11354463547468185, Neurons: 64, Grad norm: 1.192e-01\n",
      "Epoch 8635, Loss: 0.11336611211299896, Neurons: 64, Grad norm: 1.211e-01\n",
      "Epoch 8635, Loss: 0.11336611211299896, Neurons: 64, Grad norm: 1.211e-01\n",
      "Epoch 8636, Loss: 0.11318837851285934, Neurons: 64, Grad norm: 1.231e-01\n",
      "Epoch 8636, Loss: 0.11318837851285934, Neurons: 64, Grad norm: 1.231e-01\n",
      "Epoch 8637, Loss: 0.11301085352897644, Neurons: 64, Grad norm: 1.299e-01\n",
      "Epoch 8637, Loss: 0.11301085352897644, Neurons: 64, Grad norm: 1.299e-01\n",
      "Epoch 8638, Loss: 0.11283358931541443, Neurons: 64, Grad norm: 1.299e-01\n",
      "Epoch 8638, Loss: 0.11283358931541443, Neurons: 64, Grad norm: 1.299e-01\n",
      "Epoch 8639, Loss: 0.11265671253204346, Neurons: 64, Grad norm: 1.393e-01\n",
      "Epoch 8639, Loss: 0.11265671253204346, Neurons: 64, Grad norm: 1.393e-01\n",
      "Epoch 8640, Loss: 0.11247999966144562, Neurons: 64, Grad norm: 1.345e-01\n",
      "Epoch 8640, Loss: 0.11247999966144562, Neurons: 64, Grad norm: 1.345e-01\n",
      "Epoch 8641, Loss: 0.11230368912220001, Neurons: 64, Grad norm: 1.416e-01\n",
      "Epoch 8641, Loss: 0.11230368912220001, Neurons: 64, Grad norm: 1.416e-01\n",
      "Epoch 8642, Loss: 0.11212805658578873, Neurons: 64, Grad norm: 1.300e-01\n",
      "Epoch 8642, Loss: 0.11212805658578873, Neurons: 64, Grad norm: 1.300e-01\n",
      "Epoch 8643, Loss: 0.11195225268602371, Neurons: 64, Grad norm: 1.337e-01\n",
      "Epoch 8643, Loss: 0.11195225268602371, Neurons: 64, Grad norm: 1.337e-01\n",
      "Epoch 8644, Loss: 0.11177708953619003, Neurons: 64, Grad norm: 1.243e-01\n",
      "Epoch 8644, Loss: 0.11177708953619003, Neurons: 64, Grad norm: 1.243e-01\n",
      "Epoch 8645, Loss: 0.11160215735435486, Neurons: 64, Grad norm: 1.250e-01\n",
      "Epoch 8645, Loss: 0.11160215735435486, Neurons: 64, Grad norm: 1.250e-01\n",
      "Epoch 8646, Loss: 0.11142746359109879, Neurons: 64, Grad norm: 1.197e-01\n",
      "Epoch 8646, Loss: 0.11142746359109879, Neurons: 64, Grad norm: 1.197e-01\n",
      "Epoch 8647, Loss: 0.11125317960977554, Neurons: 64, Grad norm: 1.240e-01\n",
      "Epoch 8647, Loss: 0.11125317960977554, Neurons: 64, Grad norm: 1.240e-01\n",
      "Epoch 8648, Loss: 0.11107933521270752, Neurons: 64, Grad norm: 1.193e-01\n",
      "Epoch 8648, Loss: 0.11107933521270752, Neurons: 64, Grad norm: 1.193e-01\n",
      "Epoch 8649, Loss: 0.11090560257434845, Neurons: 64, Grad norm: 1.188e-01\n",
      "Epoch 8649, Loss: 0.11090560257434845, Neurons: 64, Grad norm: 1.188e-01\n",
      "Epoch 8650, Loss: 0.1107325330376625, Neurons: 64, Grad norm: 1.168e-01\n",
      "Epoch 8650, Loss: 0.1107325330376625, Neurons: 64, Grad norm: 1.168e-01\n",
      "Epoch 8651, Loss: 0.11055965721607208, Neurons: 64, Grad norm: 1.163e-01\n",
      "Epoch 8651, Loss: 0.11055965721607208, Neurons: 64, Grad norm: 1.163e-01\n",
      "Epoch 8652, Loss: 0.11038696765899658, Neurons: 64, Grad norm: 1.158e-01\n",
      "Epoch 8652, Loss: 0.11038696765899658, Neurons: 64, Grad norm: 1.158e-01\n",
      "Epoch 8653, Loss: 0.11021468043327332, Neurons: 64, Grad norm: 1.154e-01\n",
      "Epoch 8653, Loss: 0.11021468043327332, Neurons: 64, Grad norm: 1.154e-01\n",
      "Epoch 8654, Loss: 0.11004257202148438, Neurons: 64, Grad norm: 1.177e-01\n",
      "Epoch 8654, Loss: 0.11004257202148438, Neurons: 64, Grad norm: 1.177e-01\n",
      "Epoch 8655, Loss: 0.10987114161252975, Neurons: 64, Grad norm: 1.160e-01\n",
      "Epoch 8655, Loss: 0.10987114161252975, Neurons: 64, Grad norm: 1.160e-01\n",
      "Epoch 8656, Loss: 0.10969971120357513, Neurons: 64, Grad norm: 1.166e-01\n",
      "Epoch 8656, Loss: 0.10969971120357513, Neurons: 64, Grad norm: 1.166e-01\n",
      "Epoch 8657, Loss: 0.1095287948846817, Neurons: 64, Grad norm: 1.153e-01\n",
      "Epoch 8657, Loss: 0.1095287948846817, Neurons: 64, Grad norm: 1.153e-01\n",
      "Epoch 8658, Loss: 0.1093580350279808, Neurons: 64, Grad norm: 1.161e-01\n",
      "Epoch 8658, Loss: 0.1093580350279808, Neurons: 64, Grad norm: 1.161e-01\n",
      "Epoch 8659, Loss: 0.10918790102005005, Neurons: 64, Grad norm: 1.172e-01\n",
      "Epoch 8659, Loss: 0.10918790102005005, Neurons: 64, Grad norm: 1.172e-01\n",
      "Epoch 8660, Loss: 0.1090177670121193, Neurons: 64, Grad norm: 1.191e-01\n",
      "Epoch 8660, Loss: 0.1090177670121193, Neurons: 64, Grad norm: 1.191e-01\n",
      "Epoch 8661, Loss: 0.10884809494018555, Neurons: 64, Grad norm: 1.162e-01\n",
      "Epoch 8661, Loss: 0.10884809494018555, Neurons: 64, Grad norm: 1.162e-01\n",
      "Epoch 8662, Loss: 0.10867881774902344, Neurons: 64, Grad norm: 1.173e-01\n",
      "Epoch 8662, Loss: 0.10867881774902344, Neurons: 64, Grad norm: 1.173e-01\n",
      "Epoch 8663, Loss: 0.10850980132818222, Neurons: 64, Grad norm: 1.148e-01\n",
      "Epoch 8663, Loss: 0.10850980132818222, Neurons: 64, Grad norm: 1.148e-01\n",
      "Epoch 8664, Loss: 0.10834099352359772, Neurons: 64, Grad norm: 1.160e-01\n",
      "Epoch 8664, Loss: 0.10834099352359772, Neurons: 64, Grad norm: 1.160e-01\n",
      "Epoch 8665, Loss: 0.1081726923584938, Neurons: 64, Grad norm: 1.158e-01\n",
      "Epoch 8665, Loss: 0.1081726923584938, Neurons: 64, Grad norm: 1.158e-01\n",
      "Epoch 8666, Loss: 0.10800444334745407, Neurons: 64, Grad norm: 1.189e-01\n",
      "Epoch 8666, Loss: 0.10800444334745407, Neurons: 64, Grad norm: 1.189e-01\n",
      "Epoch 8667, Loss: 0.10783670097589493, Neurons: 64, Grad norm: 1.145e-01\n",
      "Epoch 8667, Loss: 0.10783670097589493, Neurons: 64, Grad norm: 1.145e-01\n",
      "Epoch 8668, Loss: 0.10766935348510742, Neurons: 64, Grad norm: 1.181e-01\n",
      "Epoch 8668, Loss: 0.10766935348510742, Neurons: 64, Grad norm: 1.181e-01\n",
      "Epoch 8669, Loss: 0.10750241577625275, Neurons: 64, Grad norm: 1.165e-01\n",
      "Epoch 8669, Loss: 0.10750241577625275, Neurons: 64, Grad norm: 1.165e-01\n",
      "Epoch 8670, Loss: 0.10733552277088165, Neurons: 64, Grad norm: 1.231e-01\n",
      "Epoch 8670, Loss: 0.10733552277088165, Neurons: 64, Grad norm: 1.231e-01\n",
      "Epoch 8671, Loss: 0.10716889798641205, Neurons: 64, Grad norm: 1.203e-01\n",
      "Epoch 8671, Loss: 0.10716889798641205, Neurons: 64, Grad norm: 1.203e-01\n",
      "Epoch 8672, Loss: 0.10700284689664841, Neurons: 64, Grad norm: 1.287e-01\n",
      "Epoch 8672, Loss: 0.10700284689664841, Neurons: 64, Grad norm: 1.287e-01\n",
      "Epoch 8673, Loss: 0.10683693736791611, Neurons: 64, Grad norm: 1.252e-01\n",
      "Epoch 8673, Loss: 0.10683693736791611, Neurons: 64, Grad norm: 1.252e-01\n",
      "Epoch 8674, Loss: 0.10667154937982559, Neurons: 64, Grad norm: 1.280e-01\n",
      "Epoch 8674, Loss: 0.10667154937982559, Neurons: 64, Grad norm: 1.280e-01\n",
      "Epoch 8675, Loss: 0.10650641471147537, Neurons: 64, Grad norm: 1.267e-01\n",
      "Epoch 8675, Loss: 0.10650641471147537, Neurons: 64, Grad norm: 1.267e-01\n",
      "Epoch 8676, Loss: 0.10634112358093262, Neurons: 64, Grad norm: 1.398e-01\n",
      "Epoch 8676, Loss: 0.10634112358093262, Neurons: 64, Grad norm: 1.398e-01\n",
      "Epoch 8677, Loss: 0.10617677867412567, Neurons: 64, Grad norm: 1.375e-01\n",
      "Epoch 8677, Loss: 0.10617677867412567, Neurons: 64, Grad norm: 1.375e-01\n",
      "Epoch 8678, Loss: 0.10601267218589783, Neurons: 64, Grad norm: 1.569e-01\n",
      "Epoch 8678, Loss: 0.10601267218589783, Neurons: 64, Grad norm: 1.569e-01\n",
      "Epoch 8679, Loss: 0.10584836453199387, Neurons: 64, Grad norm: 1.643e-01\n",
      "Epoch 8679, Loss: 0.10584836453199387, Neurons: 64, Grad norm: 1.643e-01\n",
      "Epoch 8680, Loss: 0.10568491369485855, Neurons: 64, Grad norm: 1.863e-01\n",
      "Epoch 8680, Loss: 0.10568491369485855, Neurons: 64, Grad norm: 1.863e-01\n",
      "Epoch 8681, Loss: 0.10552168637514114, Neurons: 64, Grad norm: 1.956e-01\n",
      "Epoch 8681, Loss: 0.10552168637514114, Neurons: 64, Grad norm: 1.956e-01\n",
      "Epoch 8682, Loss: 0.10535867512226105, Neurons: 64, Grad norm: 2.358e-01\n",
      "Epoch 8682, Loss: 0.10535867512226105, Neurons: 64, Grad norm: 2.358e-01\n",
      "Epoch 8683, Loss: 0.10519631952047348, Neurons: 64, Grad norm: 2.594e-01\n",
      "Epoch 8683, Loss: 0.10519631952047348, Neurons: 64, Grad norm: 2.594e-01\n",
      "Epoch 8684, Loss: 0.10503420233726501, Neurons: 64, Grad norm: 3.251e-01\n",
      "Epoch 8684, Loss: 0.10503420233726501, Neurons: 64, Grad norm: 3.251e-01\n",
      "Epoch 8685, Loss: 0.10487247258424759, Neurons: 64, Grad norm: 3.892e-01\n",
      "Epoch 8685, Loss: 0.10487247258424759, Neurons: 64, Grad norm: 3.892e-01\n",
      "Epoch 8686, Loss: 0.10471140593290329, Neurons: 64, Grad norm: 4.886e-01\n",
      "Epoch 8686, Loss: 0.10471140593290329, Neurons: 64, Grad norm: 4.886e-01\n",
      "Epoch 8687, Loss: 0.10455097258090973, Neurons: 64, Grad norm: 5.862e-01\n",
      "Epoch 8687, Loss: 0.10455097258090973, Neurons: 64, Grad norm: 5.862e-01\n",
      "Epoch 8688, Loss: 0.10439161956310272, Neurons: 64, Grad norm: 7.375e-01\n",
      "Epoch 8688, Loss: 0.10439161956310272, Neurons: 64, Grad norm: 7.375e-01\n",
      "Epoch 8689, Loss: 0.10423364490270615, Neurons: 64, Grad norm: 9.104e-01\n",
      "Epoch 8689, Loss: 0.10423364490270615, Neurons: 64, Grad norm: 9.104e-01\n",
      "Epoch 8690, Loss: 0.10407786816358566, Neurons: 64, Grad norm: 1.172e+00\n",
      "Epoch 8690, Loss: 0.10407786816358566, Neurons: 64, Grad norm: 1.172e+00\n",
      "Epoch 8691, Loss: 0.10392537713050842, Neurons: 64, Grad norm: 1.474e+00\n",
      "Epoch 8691, Loss: 0.10392537713050842, Neurons: 64, Grad norm: 1.474e+00\n",
      "Epoch 8692, Loss: 0.10377803444862366, Neurons: 64, Grad norm: 1.897e+00\n",
      "Epoch 8692, Loss: 0.10377803444862366, Neurons: 64, Grad norm: 1.897e+00\n",
      "Epoch 8693, Loss: 0.10363908857107162, Neurons: 64, Grad norm: 2.410e+00\n",
      "Epoch 8693, Loss: 0.10363908857107162, Neurons: 64, Grad norm: 2.410e+00\n",
      "Epoch 8694, Loss: 0.10351379215717316, Neurons: 64, Grad norm: 3.071e+00\n",
      "Epoch 8694, Loss: 0.10351379215717316, Neurons: 64, Grad norm: 3.071e+00\n",
      "Epoch 8695, Loss: 0.103409044444561, Neurons: 64, Grad norm: 3.868e+00\n",
      "Epoch 8695, Loss: 0.103409044444561, Neurons: 64, Grad norm: 3.868e+00\n",
      "Epoch 8696, Loss: 0.10333627462387085, Neurons: 64, Grad norm: 4.844e+00\n",
      "Epoch 8696, Loss: 0.10333627462387085, Neurons: 64, Grad norm: 4.844e+00\n",
      "Epoch 8697, Loss: 0.10330585390329361, Neurons: 64, Grad norm: 5.889e+00\n",
      "Epoch 8697, Loss: 0.10330585390329361, Neurons: 64, Grad norm: 5.889e+00\n",
      "Epoch 8698, Loss: 0.1033216267824173, Neurons: 64, Grad norm: 6.930e+00\n",
      "Epoch 8698, Loss: 0.1033216267824173, Neurons: 64, Grad norm: 6.930e+00\n",
      "Epoch 8699, Loss: 0.10336364060640335, Neurons: 64, Grad norm: 7.635e+00\n",
      "Epoch 8699, Loss: 0.10336364060640335, Neurons: 64, Grad norm: 7.635e+00\n",
      "Epoch 8699, Test loss: 0.0707315132021904\n",
      "Epoch 8699, Test loss: 0.0707315132021904\n",
      "Epoch 8700, Loss: 0.10336581617593765, Neurons: 64, Grad norm: 7.703e+00\n",
      "Epoch 8700, Loss: 0.10336581617593765, Neurons: 64, Grad norm: 7.703e+00\n",
      "Epoch 8701, Loss: 0.1032213419675827, Neurons: 64, Grad norm: 6.755e+00\n",
      "Epoch 8701, Loss: 0.1032213419675827, Neurons: 64, Grad norm: 6.755e+00\n",
      "Epoch 8702, Loss: 0.10285975784063339, Neurons: 64, Grad norm: 4.785e+00\n",
      "Epoch 8702, Loss: 0.10285975784063339, Neurons: 64, Grad norm: 4.785e+00\n",
      "Epoch 8703, Loss: 0.10235538333654404, Neurons: 64, Grad norm: 2.062e+00\n",
      "Epoch 8703, Loss: 0.10235538333654404, Neurons: 64, Grad norm: 2.062e+00\n",
      "Epoch 8704, Loss: 0.10191714018583298, Neurons: 64, Grad norm: 7.937e-01\n",
      "Epoch 8704, Loss: 0.10191714018583298, Neurons: 64, Grad norm: 7.937e-01\n",
      "Epoch 8705, Loss: 0.10170622915029526, Neurons: 64, Grad norm: 3.219e+00\n",
      "Epoch 8705, Loss: 0.10170622915029526, Neurons: 64, Grad norm: 3.219e+00\n",
      "Epoch 8706, Loss: 0.10169859975576401, Neurons: 64, Grad norm: 4.708e+00\n",
      "Epoch 8706, Loss: 0.10169859975576401, Neurons: 64, Grad norm: 4.708e+00\n",
      "Epoch 8707, Loss: 0.10172572731971741, Neurons: 64, Grad norm: 5.048e+00\n",
      "Epoch 8707, Loss: 0.10172572731971741, Neurons: 64, Grad norm: 5.048e+00\n",
      "Epoch 8708, Loss: 0.10162006318569183, Neurons: 64, Grad norm: 4.160e+00\n",
      "Epoch 8708, Loss: 0.10162006318569183, Neurons: 64, Grad norm: 4.160e+00\n",
      "Epoch 8709, Loss: 0.10134299844503403, Neurons: 64, Grad norm: 2.366e+00\n",
      "Epoch 8709, Loss: 0.10134299844503403, Neurons: 64, Grad norm: 2.366e+00\n",
      "Epoch 8710, Loss: 0.10100924968719482, Neurons: 64, Grad norm: 1.608e-01\n",
      "Epoch 8710, Loss: 0.10100924968719482, Neurons: 64, Grad norm: 1.608e-01\n",
      "Epoch 8711, Loss: 0.1007714495062828, Neurons: 64, Grad norm: 1.914e+00\n",
      "Epoch 8711, Loss: 0.1007714495062828, Neurons: 64, Grad norm: 1.914e+00\n",
      "Epoch 8712, Loss: 0.10067421197891235, Neurons: 64, Grad norm: 3.279e+00\n",
      "Epoch 8712, Loss: 0.10067421197891235, Neurons: 64, Grad norm: 3.279e+00\n",
      "Epoch 8713, Loss: 0.10062848031520844, Neurons: 64, Grad norm: 3.653e+00\n",
      "Epoch 8713, Loss: 0.10062848031520844, Neurons: 64, Grad norm: 3.653e+00\n",
      "Epoch 8714, Loss: 0.10051651298999786, Neurons: 64, Grad norm: 3.058e+00\n",
      "Epoch 8714, Loss: 0.10051651298999786, Neurons: 64, Grad norm: 3.058e+00\n",
      "Epoch 8715, Loss: 0.10030240565538406, Neurons: 64, Grad norm: 1.685e+00\n",
      "Epoch 8715, Loss: 0.10030240565538406, Neurons: 64, Grad norm: 1.685e+00\n",
      "Epoch 8716, Loss: 0.10005223751068115, Neurons: 64, Grad norm: 1.102e-01\n",
      "Epoch 8716, Loss: 0.10005223751068115, Neurons: 64, Grad norm: 1.102e-01\n",
      "Epoch 8717, Loss: 0.0998569056391716, Neurons: 64, Grad norm: 1.505e+00\n",
      "Epoch 8717, Loss: 0.0998569056391716, Neurons: 64, Grad norm: 1.505e+00\n",
      "Epoch 8718, Loss: 0.09973959624767303, Neurons: 64, Grad norm: 2.460e+00\n",
      "Epoch 8718, Loss: 0.09973959624767303, Neurons: 64, Grad norm: 2.460e+00\n",
      "Epoch 8719, Loss: 0.09964703768491745, Neurons: 64, Grad norm: 2.689e+00\n",
      "Epoch 8719, Loss: 0.09964703768491745, Neurons: 64, Grad norm: 2.689e+00\n",
      "Epoch 8720, Loss: 0.09951314330101013, Neurons: 64, Grad norm: 2.142e+00\n",
      "Epoch 8720, Loss: 0.09951314330101013, Neurons: 64, Grad norm: 2.142e+00\n",
      "Epoch 8721, Loss: 0.09932363033294678, Neurons: 64, Grad norm: 1.103e+00\n",
      "Epoch 8721, Loss: 0.09932363033294678, Neurons: 64, Grad norm: 1.103e+00\n",
      "Epoch 8722, Loss: 0.09912116080522537, Neurons: 64, Grad norm: 1.880e-01\n",
      "Epoch 8722, Loss: 0.09912116080522537, Neurons: 64, Grad norm: 1.880e-01\n",
      "Epoch 8723, Loss: 0.09895344078540802, Neurons: 64, Grad norm: 1.229e+00\n",
      "Epoch 8723, Loss: 0.09895344078540802, Neurons: 64, Grad norm: 1.229e+00\n",
      "Epoch 8724, Loss: 0.09882654249668121, Neurons: 64, Grad norm: 1.881e+00\n",
      "Epoch 8724, Loss: 0.09882654249668121, Neurons: 64, Grad norm: 1.881e+00\n",
      "Epoch 8725, Loss: 0.09870752692222595, Neurons: 64, Grad norm: 1.941e+00\n",
      "Epoch 8725, Loss: 0.09870752692222595, Neurons: 64, Grad norm: 1.941e+00\n",
      "Epoch 8726, Loss: 0.09856316447257996, Neurons: 64, Grad norm: 1.516e+00\n",
      "Epoch 8726, Loss: 0.09856316447257996, Neurons: 64, Grad norm: 1.516e+00\n",
      "Epoch 8727, Loss: 0.09839089214801788, Neurons: 64, Grad norm: 7.116e-01\n",
      "Epoch 8727, Loss: 0.09839089214801788, Neurons: 64, Grad norm: 7.116e-01\n",
      "Epoch 8728, Loss: 0.09821561723947525, Neurons: 64, Grad norm: 2.235e-01\n",
      "Epoch 8728, Loss: 0.09821561723947525, Neurons: 64, Grad norm: 2.235e-01\n",
      "Epoch 8729, Loss: 0.09806005656719208, Neurons: 64, Grad norm: 9.796e-01\n",
      "Epoch 8729, Loss: 0.09806005656719208, Neurons: 64, Grad norm: 9.796e-01\n",
      "Epoch 8730, Loss: 0.09792580455541611, Neurons: 64, Grad norm: 1.402e+00\n",
      "Epoch 8730, Loss: 0.09792580455541611, Neurons: 64, Grad norm: 1.402e+00\n",
      "Epoch 8731, Loss: 0.09779425710439682, Neurons: 64, Grad norm: 1.448e+00\n",
      "Epoch 8731, Loss: 0.09779425710439682, Neurons: 64, Grad norm: 1.448e+00\n",
      "Epoch 8732, Loss: 0.09764780104160309, Neurons: 64, Grad norm: 1.087e+00\n",
      "Epoch 8732, Loss: 0.09764780104160309, Neurons: 64, Grad norm: 1.087e+00\n",
      "Epoch 8733, Loss: 0.09748758375644684, Neurons: 64, Grad norm: 5.122e-01\n",
      "Epoch 8733, Loss: 0.09748758375644684, Neurons: 64, Grad norm: 5.122e-01\n",
      "Epoch 8734, Loss: 0.09732622653245926, Neurons: 64, Grad norm: 1.990e-01\n",
      "Epoch 8734, Loss: 0.09732622653245926, Neurons: 64, Grad norm: 1.990e-01\n",
      "Epoch 8735, Loss: 0.0971764549612999, Neurons: 64, Grad norm: 7.199e-01\n",
      "Epoch 8735, Loss: 0.0971764549612999, Neurons: 64, Grad norm: 7.199e-01\n",
      "Epoch 8736, Loss: 0.09703748673200607, Neurons: 64, Grad norm: 1.051e+00\n",
      "Epoch 8736, Loss: 0.09703748673200607, Neurons: 64, Grad norm: 1.051e+00\n",
      "Epoch 8737, Loss: 0.09690004587173462, Neurons: 64, Grad norm: 1.065e+00\n",
      "Epoch 8737, Loss: 0.09690004587173462, Neurons: 64, Grad norm: 1.065e+00\n",
      "Epoch 8738, Loss: 0.09675513207912445, Neurons: 64, Grad norm: 8.484e-01\n",
      "Epoch 8738, Loss: 0.09675513207912445, Neurons: 64, Grad norm: 8.484e-01\n",
      "Epoch 8739, Loss: 0.09660296887159348, Neurons: 64, Grad norm: 4.323e-01\n",
      "Epoch 8739, Loss: 0.09660296887159348, Neurons: 64, Grad norm: 4.323e-01\n",
      "Epoch 8740, Loss: 0.09644994139671326, Neurons: 64, Grad norm: 1.142e-01\n",
      "Epoch 8740, Loss: 0.09644994139671326, Neurons: 64, Grad norm: 1.142e-01\n",
      "Epoch 8741, Loss: 0.09630223363637924, Neurons: 64, Grad norm: 4.865e-01\n",
      "Epoch 8741, Loss: 0.09630223363637924, Neurons: 64, Grad norm: 4.865e-01\n",
      "Epoch 8742, Loss: 0.09616071730852127, Neurons: 64, Grad norm: 7.299e-01\n",
      "Epoch 8742, Loss: 0.09616071730852127, Neurons: 64, Grad norm: 7.299e-01\n",
      "Epoch 8743, Loss: 0.09602121263742447, Neurons: 64, Grad norm: 8.005e-01\n",
      "Epoch 8743, Loss: 0.09602121263742447, Neurons: 64, Grad norm: 8.005e-01\n",
      "Epoch 8744, Loss: 0.09587851166725159, Neurons: 64, Grad norm: 6.643e-01\n",
      "Epoch 8744, Loss: 0.09587851166725159, Neurons: 64, Grad norm: 6.643e-01\n",
      "Epoch 8745, Loss: 0.09573185443878174, Neurons: 64, Grad norm: 4.120e-01\n",
      "Epoch 8745, Loss: 0.09573185443878174, Neurons: 64, Grad norm: 4.120e-01\n",
      "Epoch 8746, Loss: 0.09558366984128952, Neurons: 64, Grad norm: 1.138e-01\n",
      "Epoch 8746, Loss: 0.09558366984128952, Neurons: 64, Grad norm: 1.138e-01\n",
      "Epoch 8747, Loss: 0.0954384058713913, Neurons: 64, Grad norm: 2.704e-01\n",
      "Epoch 8747, Loss: 0.0954384058713913, Neurons: 64, Grad norm: 2.704e-01\n",
      "Epoch 8748, Loss: 0.0952962189912796, Neurons: 64, Grad norm: 4.895e-01\n",
      "Epoch 8748, Loss: 0.0952962189912796, Neurons: 64, Grad norm: 4.895e-01\n",
      "Epoch 8749, Loss: 0.0951557457447052, Neurons: 64, Grad norm: 5.754e-01\n",
      "Epoch 8749, Loss: 0.0951557457447052, Neurons: 64, Grad norm: 5.754e-01\n",
      "Epoch 8750, Loss: 0.09501489996910095, Neurons: 64, Grad norm: 5.571e-01\n",
      "Epoch 8750, Loss: 0.09501489996910095, Neurons: 64, Grad norm: 5.571e-01\n",
      "Epoch 8751, Loss: 0.09487210214138031, Neurons: 64, Grad norm: 3.943e-01\n",
      "Epoch 8751, Loss: 0.09487210214138031, Neurons: 64, Grad norm: 3.943e-01\n",
      "Epoch 8752, Loss: 0.09472785145044327, Neurons: 64, Grad norm: 2.046e-01\n",
      "Epoch 8752, Loss: 0.09472785145044327, Neurons: 64, Grad norm: 2.046e-01\n",
      "Epoch 8753, Loss: 0.09458424896001816, Neurons: 64, Grad norm: 1.190e-01\n",
      "Epoch 8753, Loss: 0.09458424896001816, Neurons: 64, Grad norm: 1.190e-01\n",
      "Epoch 8754, Loss: 0.09444254636764526, Neurons: 64, Grad norm: 2.726e-01\n",
      "Epoch 8754, Loss: 0.09444254636764526, Neurons: 64, Grad norm: 2.726e-01\n",
      "Epoch 8755, Loss: 0.09430206567049026, Neurons: 64, Grad norm: 3.994e-01\n",
      "Epoch 8755, Loss: 0.09430206567049026, Neurons: 64, Grad norm: 3.994e-01\n",
      "Epoch 8756, Loss: 0.09416229277849197, Neurons: 64, Grad norm: 4.103e-01\n",
      "Epoch 8756, Loss: 0.09416229277849197, Neurons: 64, Grad norm: 4.103e-01\n",
      "Epoch 8757, Loss: 0.09402188658714294, Neurons: 64, Grad norm: 3.723e-01\n",
      "Epoch 8757, Loss: 0.09402188658714294, Neurons: 64, Grad norm: 3.723e-01\n",
      "Epoch 8758, Loss: 0.09388087689876556, Neurons: 64, Grad norm: 2.501e-01\n",
      "Epoch 8758, Loss: 0.09388087689876556, Neurons: 64, Grad norm: 2.501e-01\n",
      "Epoch 8759, Loss: 0.09373953193426132, Neurons: 64, Grad norm: 1.334e-01\n",
      "Epoch 8759, Loss: 0.09373953193426132, Neurons: 64, Grad norm: 1.334e-01\n",
      "Epoch 8760, Loss: 0.09359882026910782, Neurons: 64, Grad norm: 1.329e-01\n",
      "Epoch 8760, Loss: 0.09359882026910782, Neurons: 64, Grad norm: 1.329e-01\n",
      "Epoch 8761, Loss: 0.09345917403697968, Neurons: 64, Grad norm: 2.196e-01\n",
      "Epoch 8761, Loss: 0.09345917403697968, Neurons: 64, Grad norm: 2.196e-01\n",
      "Epoch 8762, Loss: 0.09332022815942764, Neurons: 64, Grad norm: 3.038e-01\n",
      "Epoch 8762, Loss: 0.09332022815942764, Neurons: 64, Grad norm: 3.038e-01\n",
      "Epoch 8763, Loss: 0.09318163245916367, Neurons: 64, Grad norm: 3.038e-01\n",
      "Epoch 8763, Loss: 0.09318163245916367, Neurons: 64, Grad norm: 3.038e-01\n",
      "Epoch 8764, Loss: 0.09304302930831909, Neurons: 64, Grad norm: 2.722e-01\n",
      "Epoch 8764, Loss: 0.09304302930831909, Neurons: 64, Grad norm: 2.722e-01\n",
      "Epoch 8765, Loss: 0.09290405362844467, Neurons: 64, Grad norm: 1.916e-01\n",
      "Epoch 8765, Loss: 0.09290405362844467, Neurons: 64, Grad norm: 1.916e-01\n",
      "Epoch 8766, Loss: 0.09276492893695831, Neurons: 64, Grad norm: 1.240e-01\n",
      "Epoch 8766, Loss: 0.09276492893695831, Neurons: 64, Grad norm: 1.240e-01\n",
      "Epoch 8767, Loss: 0.09262656420469284, Neurons: 64, Grad norm: 1.136e-01\n",
      "Epoch 8767, Loss: 0.09262656420469284, Neurons: 64, Grad norm: 1.136e-01\n",
      "Epoch 8768, Loss: 0.09248871356248856, Neurons: 64, Grad norm: 1.596e-01\n",
      "Epoch 8768, Loss: 0.09248871356248856, Neurons: 64, Grad norm: 1.596e-01\n",
      "Epoch 8769, Loss: 0.09235112369060516, Neurons: 64, Grad norm: 2.163e-01\n",
      "Epoch 8769, Loss: 0.09235112369060516, Neurons: 64, Grad norm: 2.163e-01\n",
      "Epoch 8770, Loss: 0.09221399575471878, Neurons: 64, Grad norm: 2.194e-01\n",
      "Epoch 8770, Loss: 0.09221399575471878, Neurons: 64, Grad norm: 2.194e-01\n",
      "Epoch 8771, Loss: 0.09207707643508911, Neurons: 64, Grad norm: 2.121e-01\n",
      "Epoch 8771, Loss: 0.09207707643508911, Neurons: 64, Grad norm: 2.121e-01\n",
      "Epoch 8772, Loss: 0.09194012731313705, Neurons: 64, Grad norm: 1.672e-01\n",
      "Epoch 8772, Loss: 0.09194012731313705, Neurons: 64, Grad norm: 1.672e-01\n",
      "Epoch 8773, Loss: 0.09180332720279694, Neurons: 64, Grad norm: 1.296e-01\n",
      "Epoch 8773, Loss: 0.09180332720279694, Neurons: 64, Grad norm: 1.296e-01\n",
      "Epoch 8774, Loss: 0.09166676551103592, Neurons: 64, Grad norm: 1.010e-01\n",
      "Epoch 8774, Loss: 0.09166676551103592, Neurons: 64, Grad norm: 1.010e-01\n",
      "Epoch 8775, Loss: 0.09153053909540176, Neurons: 64, Grad norm: 1.127e-01\n",
      "Epoch 8775, Loss: 0.09153053909540176, Neurons: 64, Grad norm: 1.127e-01\n",
      "Epoch 8776, Loss: 0.09139467030763626, Neurons: 64, Grad norm: 1.495e-01\n",
      "Epoch 8776, Loss: 0.09139467030763626, Neurons: 64, Grad norm: 1.495e-01\n",
      "Epoch 8777, Loss: 0.09125924855470657, Neurons: 64, Grad norm: 1.607e-01\n",
      "Epoch 8777, Loss: 0.09125924855470657, Neurons: 64, Grad norm: 1.607e-01\n",
      "Epoch 8778, Loss: 0.09112395346164703, Neurons: 64, Grad norm: 1.737e-01\n",
      "Epoch 8778, Loss: 0.09112395346164703, Neurons: 64, Grad norm: 1.737e-01\n",
      "Epoch 8779, Loss: 0.0909888967871666, Neurons: 64, Grad norm: 1.455e-01\n",
      "Epoch 8779, Loss: 0.0909888967871666, Neurons: 64, Grad norm: 1.455e-01\n",
      "Epoch 8780, Loss: 0.09085385501384735, Neurons: 64, Grad norm: 1.307e-01\n",
      "Epoch 8780, Loss: 0.09085385501384735, Neurons: 64, Grad norm: 1.307e-01\n",
      "Epoch 8781, Loss: 0.09071911126375198, Neurons: 64, Grad norm: 1.067e-01\n",
      "Epoch 8781, Loss: 0.09071911126375198, Neurons: 64, Grad norm: 1.067e-01\n",
      "Epoch 8782, Loss: 0.09058468788862228, Neurons: 64, Grad norm: 9.977e-02\n",
      "Epoch 8782, Loss: 0.09058468788862228, Neurons: 64, Grad norm: 9.977e-02\n",
      "Epoch 8783, Loss: 0.0904504656791687, Neurons: 64, Grad norm: 1.083e-01\n",
      "Epoch 8783, Loss: 0.0904504656791687, Neurons: 64, Grad norm: 1.083e-01\n",
      "Epoch 8784, Loss: 0.0903167575597763, Neurons: 64, Grad norm: 1.156e-01\n",
      "Epoch 8784, Loss: 0.0903167575597763, Neurons: 64, Grad norm: 1.156e-01\n",
      "Epoch 8785, Loss: 0.09018326550722122, Neurons: 64, Grad norm: 1.325e-01\n",
      "Epoch 8785, Loss: 0.09018326550722122, Neurons: 64, Grad norm: 1.325e-01\n",
      "Epoch 8786, Loss: 0.09004976600408554, Neurons: 64, Grad norm: 1.292e-01\n",
      "Epoch 8786, Loss: 0.09004976600408554, Neurons: 64, Grad norm: 1.292e-01\n",
      "Epoch 8787, Loss: 0.08991649001836777, Neurons: 64, Grad norm: 1.361e-01\n",
      "Epoch 8787, Loss: 0.08991649001836777, Neurons: 64, Grad norm: 1.361e-01\n",
      "Epoch 8788, Loss: 0.08978365361690521, Neurons: 64, Grad norm: 1.209e-01\n",
      "Epoch 8788, Loss: 0.08978365361690521, Neurons: 64, Grad norm: 1.209e-01\n",
      "Epoch 8789, Loss: 0.08965108543634415, Neurons: 64, Grad norm: 1.145e-01\n",
      "Epoch 8789, Loss: 0.08965108543634415, Neurons: 64, Grad norm: 1.145e-01\n",
      "Epoch 8790, Loss: 0.08951856195926666, Neurons: 64, Grad norm: 1.003e-01\n",
      "Epoch 8790, Loss: 0.08951856195926666, Neurons: 64, Grad norm: 1.003e-01\n",
      "Epoch 8791, Loss: 0.08938649296760559, Neurons: 64, Grad norm: 1.009e-01\n",
      "Epoch 8791, Loss: 0.08938649296760559, Neurons: 64, Grad norm: 1.009e-01\n",
      "Epoch 8792, Loss: 0.08925455063581467, Neurons: 64, Grad norm: 1.027e-01\n",
      "Epoch 8792, Loss: 0.08925455063581467, Neurons: 64, Grad norm: 1.027e-01\n",
      "Epoch 8793, Loss: 0.08912282437086105, Neurons: 64, Grad norm: 1.052e-01\n",
      "Epoch 8793, Loss: 0.08912282437086105, Neurons: 64, Grad norm: 1.052e-01\n",
      "Epoch 8794, Loss: 0.08899129927158356, Neurons: 64, Grad norm: 1.120e-01\n",
      "Epoch 8794, Loss: 0.08899129927158356, Neurons: 64, Grad norm: 1.120e-01\n",
      "Epoch 8795, Loss: 0.08886026591062546, Neurons: 64, Grad norm: 1.091e-01\n",
      "Epoch 8795, Loss: 0.08886026591062546, Neurons: 64, Grad norm: 1.091e-01\n",
      "Epoch 8796, Loss: 0.08872934430837631, Neurons: 64, Grad norm: 1.172e-01\n",
      "Epoch 8796, Loss: 0.08872934430837631, Neurons: 64, Grad norm: 1.172e-01\n",
      "Epoch 8797, Loss: 0.08859843760728836, Neurons: 64, Grad norm: 1.078e-01\n",
      "Epoch 8797, Loss: 0.08859843760728836, Neurons: 64, Grad norm: 1.078e-01\n",
      "Epoch 8798, Loss: 0.08846815675497055, Neurons: 64, Grad norm: 1.043e-01\n",
      "Epoch 8798, Loss: 0.08846815675497055, Neurons: 64, Grad norm: 1.043e-01\n",
      "Epoch 8799, Loss: 0.08833780139684677, Neurons: 64, Grad norm: 9.930e-02\n",
      "Epoch 8799, Loss: 0.08833780139684677, Neurons: 64, Grad norm: 9.930e-02\n",
      "Epoch 8799, Test loss: 0.0597272664308548\n",
      "Epoch 8799, Test loss: 0.0597272664308548\n",
      "Epoch 8800, Loss: 0.08820772916078568, Neurons: 64, Grad norm: 9.775e-02\n",
      "Epoch 8800, Loss: 0.08820772916078568, Neurons: 64, Grad norm: 9.775e-02\n",
      "Epoch 8801, Loss: 0.08807797729969025, Neurons: 64, Grad norm: 1.011e-01\n",
      "Epoch 8801, Loss: 0.08807797729969025, Neurons: 64, Grad norm: 1.011e-01\n",
      "Epoch 8802, Loss: 0.08794845640659332, Neurons: 64, Grad norm: 1.018e-01\n",
      "Epoch 8802, Loss: 0.08794845640659332, Neurons: 64, Grad norm: 1.018e-01\n",
      "Epoch 8803, Loss: 0.08781912922859192, Neurons: 64, Grad norm: 1.101e-01\n",
      "Epoch 8803, Loss: 0.08781912922859192, Neurons: 64, Grad norm: 1.101e-01\n",
      "Epoch 8804, Loss: 0.08769021928310394, Neurons: 64, Grad norm: 1.064e-01\n",
      "Epoch 8804, Loss: 0.08769021928310394, Neurons: 64, Grad norm: 1.064e-01\n",
      "Epoch 8805, Loss: 0.08756130188703537, Neurons: 64, Grad norm: 1.101e-01\n",
      "Epoch 8805, Loss: 0.08756130188703537, Neurons: 64, Grad norm: 1.101e-01\n",
      "Epoch 8806, Loss: 0.08743274956941605, Neurons: 64, Grad norm: 1.027e-01\n",
      "Epoch 8806, Loss: 0.08743274956941605, Neurons: 64, Grad norm: 1.027e-01\n",
      "Epoch 8807, Loss: 0.08730417490005493, Neurons: 64, Grad norm: 1.020e-01\n",
      "Epoch 8807, Loss: 0.08730417490005493, Neurons: 64, Grad norm: 1.020e-01\n",
      "Epoch 8808, Loss: 0.08717619627714157, Neurons: 64, Grad norm: 9.960e-02\n",
      "Epoch 8808, Loss: 0.08717619627714157, Neurons: 64, Grad norm: 9.960e-02\n",
      "Epoch 8809, Loss: 0.08704828470945358, Neurons: 64, Grad norm: 9.969e-02\n",
      "Epoch 8809, Loss: 0.08704828470945358, Neurons: 64, Grad norm: 9.969e-02\n",
      "Epoch 8810, Loss: 0.08692075312137604, Neurons: 64, Grad norm: 1.008e-01\n",
      "Epoch 8810, Loss: 0.08692075312137604, Neurons: 64, Grad norm: 1.008e-01\n",
      "Epoch 8811, Loss: 0.08679329603910446, Neurons: 64, Grad norm: 1.006e-01\n",
      "Epoch 8811, Loss: 0.08679329603910446, Neurons: 64, Grad norm: 1.006e-01\n",
      "Epoch 8812, Loss: 0.08666592836380005, Neurons: 64, Grad norm: 1.020e-01\n",
      "Epoch 8812, Loss: 0.08666592836380005, Neurons: 64, Grad norm: 1.020e-01\n",
      "Epoch 8813, Loss: 0.08653919398784637, Neurons: 64, Grad norm: 1.015e-01\n",
      "Epoch 8813, Loss: 0.08653919398784637, Neurons: 64, Grad norm: 1.015e-01\n",
      "Epoch 8814, Loss: 0.08641255646944046, Neurons: 64, Grad norm: 1.112e-01\n",
      "Epoch 8814, Loss: 0.08641255646944046, Neurons: 64, Grad norm: 1.112e-01\n",
      "Epoch 8815, Loss: 0.0862860307097435, Neurons: 64, Grad norm: 1.049e-01\n",
      "Epoch 8815, Loss: 0.0862860307097435, Neurons: 64, Grad norm: 1.049e-01\n",
      "Epoch 8816, Loss: 0.08615975081920624, Neurons: 64, Grad norm: 1.101e-01\n",
      "Epoch 8816, Loss: 0.08615975081920624, Neurons: 64, Grad norm: 1.101e-01\n",
      "Epoch 8817, Loss: 0.08603373914957047, Neurons: 64, Grad norm: 1.085e-01\n",
      "Epoch 8817, Loss: 0.08603373914957047, Neurons: 64, Grad norm: 1.085e-01\n",
      "Epoch 8818, Loss: 0.08590786159038544, Neurons: 64, Grad norm: 1.098e-01\n",
      "Epoch 8818, Loss: 0.08590786159038544, Neurons: 64, Grad norm: 1.098e-01\n",
      "Epoch 8819, Loss: 0.08578238636255264, Neurons: 64, Grad norm: 1.016e-01\n",
      "Epoch 8819, Loss: 0.08578238636255264, Neurons: 64, Grad norm: 1.016e-01\n",
      "Epoch 8820, Loss: 0.08565688133239746, Neurons: 64, Grad norm: 1.034e-01\n",
      "Epoch 8820, Loss: 0.08565688133239746, Neurons: 64, Grad norm: 1.034e-01\n",
      "Epoch 8821, Loss: 0.08553192764520645, Neurons: 64, Grad norm: 9.733e-02\n",
      "Epoch 8821, Loss: 0.08553192764520645, Neurons: 64, Grad norm: 9.733e-02\n",
      "Epoch 8822, Loss: 0.08540686964988708, Neurons: 64, Grad norm: 9.789e-02\n",
      "Epoch 8822, Loss: 0.08540686964988708, Neurons: 64, Grad norm: 9.789e-02\n",
      "Epoch 8823, Loss: 0.08528223633766174, Neurons: 64, Grad norm: 9.492e-02\n",
      "Epoch 8823, Loss: 0.08528223633766174, Neurons: 64, Grad norm: 9.492e-02\n",
      "Epoch 8824, Loss: 0.08515799045562744, Neurons: 64, Grad norm: 9.501e-02\n",
      "Epoch 8824, Loss: 0.08515799045562744, Neurons: 64, Grad norm: 9.501e-02\n",
      "Epoch 8825, Loss: 0.08503367751836777, Neurons: 64, Grad norm: 9.446e-02\n",
      "Epoch 8825, Loss: 0.08503367751836777, Neurons: 64, Grad norm: 9.446e-02\n",
      "Epoch 8826, Loss: 0.08490964770317078, Neurons: 64, Grad norm: 9.393e-02\n",
      "Epoch 8826, Loss: 0.08490964770317078, Neurons: 64, Grad norm: 9.393e-02\n",
      "Epoch 8827, Loss: 0.08478578180074692, Neurons: 64, Grad norm: 9.534e-02\n",
      "Epoch 8827, Loss: 0.08478578180074692, Neurons: 64, Grad norm: 9.534e-02\n",
      "Epoch 8828, Loss: 0.08466266095638275, Neurons: 64, Grad norm: 9.630e-02\n",
      "Epoch 8828, Loss: 0.08466266095638275, Neurons: 64, Grad norm: 9.630e-02\n",
      "Epoch 8829, Loss: 0.08453921228647232, Neurons: 64, Grad norm: 9.814e-02\n",
      "Epoch 8829, Loss: 0.08453921228647232, Neurons: 64, Grad norm: 9.814e-02\n",
      "Epoch 8830, Loss: 0.08441606909036636, Neurons: 64, Grad norm: 9.618e-02\n",
      "Epoch 8830, Loss: 0.08441606909036636, Neurons: 64, Grad norm: 9.618e-02\n",
      "Epoch 8831, Loss: 0.08429332077503204, Neurons: 64, Grad norm: 9.667e-02\n",
      "Epoch 8831, Loss: 0.08429332077503204, Neurons: 64, Grad norm: 9.667e-02\n",
      "Epoch 8832, Loss: 0.08417081087827682, Neurons: 64, Grad norm: 9.472e-02\n",
      "Epoch 8832, Loss: 0.08417081087827682, Neurons: 64, Grad norm: 9.472e-02\n",
      "Epoch 8833, Loss: 0.08404820412397385, Neurons: 64, Grad norm: 9.512e-02\n",
      "Epoch 8833, Loss: 0.08404820412397385, Neurons: 64, Grad norm: 9.512e-02\n",
      "Epoch 8834, Loss: 0.08392583578824997, Neurons: 64, Grad norm: 9.494e-02\n",
      "Epoch 8834, Loss: 0.08392583578824997, Neurons: 64, Grad norm: 9.494e-02\n",
      "Epoch 8835, Loss: 0.08380406349897385, Neurons: 64, Grad norm: 9.684e-02\n",
      "Epoch 8835, Loss: 0.08380406349897385, Neurons: 64, Grad norm: 9.684e-02\n",
      "Epoch 8836, Loss: 0.08368239551782608, Neurons: 64, Grad norm: 9.642e-02\n",
      "Epoch 8836, Loss: 0.08368239551782608, Neurons: 64, Grad norm: 9.642e-02\n",
      "Epoch 8837, Loss: 0.0835607647895813, Neurons: 64, Grad norm: 9.703e-02\n",
      "Epoch 8837, Loss: 0.0835607647895813, Neurons: 64, Grad norm: 9.703e-02\n",
      "Epoch 8838, Loss: 0.08343949913978577, Neurons: 64, Grad norm: 9.388e-02\n",
      "Epoch 8838, Loss: 0.08343949913978577, Neurons: 64, Grad norm: 9.388e-02\n",
      "Epoch 8839, Loss: 0.08331853896379471, Neurons: 64, Grad norm: 9.605e-02\n",
      "Epoch 8839, Loss: 0.08331853896379471, Neurons: 64, Grad norm: 9.605e-02\n",
      "Epoch 8840, Loss: 0.08319777250289917, Neurons: 64, Grad norm: 9.498e-02\n",
      "Epoch 8840, Loss: 0.08319777250289917, Neurons: 64, Grad norm: 9.498e-02\n",
      "Epoch 8841, Loss: 0.08307702094316483, Neurons: 64, Grad norm: 9.658e-02\n",
      "Epoch 8841, Loss: 0.08307702094316483, Neurons: 64, Grad norm: 9.658e-02\n",
      "Epoch 8842, Loss: 0.08295655250549316, Neurons: 64, Grad norm: 9.365e-02\n",
      "Epoch 8842, Loss: 0.08295655250549316, Neurons: 64, Grad norm: 9.365e-02\n",
      "Epoch 8843, Loss: 0.08283623307943344, Neurons: 64, Grad norm: 9.498e-02\n",
      "Epoch 8843, Loss: 0.08283623307943344, Neurons: 64, Grad norm: 9.498e-02\n",
      "Epoch 8844, Loss: 0.08271650969982147, Neurons: 64, Grad norm: 9.383e-02\n",
      "Epoch 8844, Loss: 0.08271650969982147, Neurons: 64, Grad norm: 9.383e-02\n",
      "Epoch 8845, Loss: 0.08259668201208115, Neurons: 64, Grad norm: 9.833e-02\n",
      "Epoch 8845, Loss: 0.08259668201208115, Neurons: 64, Grad norm: 9.833e-02\n",
      "Epoch 8846, Loss: 0.08247710019350052, Neurons: 64, Grad norm: 9.574e-02\n",
      "Epoch 8846, Loss: 0.08247710019350052, Neurons: 64, Grad norm: 9.574e-02\n",
      "Epoch 8847, Loss: 0.08235771209001541, Neurons: 64, Grad norm: 1.031e-01\n",
      "Epoch 8847, Loss: 0.08235771209001541, Neurons: 64, Grad norm: 1.031e-01\n",
      "Epoch 8848, Loss: 0.08223874121904373, Neurons: 64, Grad norm: 1.020e-01\n",
      "Epoch 8848, Loss: 0.08223874121904373, Neurons: 64, Grad norm: 1.020e-01\n",
      "Epoch 8849, Loss: 0.08211997896432877, Neurons: 64, Grad norm: 1.082e-01\n",
      "Epoch 8849, Loss: 0.08211997896432877, Neurons: 64, Grad norm: 1.082e-01\n",
      "Epoch 8850, Loss: 0.08200118690729141, Neurons: 64, Grad norm: 1.033e-01\n",
      "Epoch 8850, Loss: 0.08200118690729141, Neurons: 64, Grad norm: 1.033e-01\n",
      "Epoch 8851, Loss: 0.08188269287347794, Neurons: 64, Grad norm: 1.064e-01\n",
      "Epoch 8851, Loss: 0.08188269287347794, Neurons: 64, Grad norm: 1.064e-01\n",
      "Epoch 8852, Loss: 0.08176436275243759, Neurons: 64, Grad norm: 1.040e-01\n",
      "Epoch 8852, Loss: 0.08176436275243759, Neurons: 64, Grad norm: 1.040e-01\n",
      "Epoch 8853, Loss: 0.08164656162261963, Neurons: 64, Grad norm: 1.152e-01\n",
      "Epoch 8853, Loss: 0.08164656162261963, Neurons: 64, Grad norm: 1.152e-01\n",
      "Epoch 8854, Loss: 0.0815286785364151, Neurons: 64, Grad norm: 1.104e-01\n",
      "Epoch 8854, Loss: 0.0815286785364151, Neurons: 64, Grad norm: 1.104e-01\n",
      "Epoch 8855, Loss: 0.08141104876995087, Neurons: 64, Grad norm: 1.249e-01\n",
      "Epoch 8855, Loss: 0.08141104876995087, Neurons: 64, Grad norm: 1.249e-01\n",
      "Epoch 8856, Loss: 0.08129372447729111, Neurons: 64, Grad norm: 1.325e-01\n",
      "Epoch 8856, Loss: 0.08129372447729111, Neurons: 64, Grad norm: 1.325e-01\n",
      "Epoch 8857, Loss: 0.0811765044927597, Neurons: 64, Grad norm: 1.446e-01\n",
      "Epoch 8857, Loss: 0.0811765044927597, Neurons: 64, Grad norm: 1.446e-01\n",
      "Epoch 8858, Loss: 0.08105960488319397, Neurons: 64, Grad norm: 1.430e-01\n",
      "Epoch 8858, Loss: 0.08105960488319397, Neurons: 64, Grad norm: 1.430e-01\n",
      "Epoch 8859, Loss: 0.08094284683465958, Neurons: 64, Grad norm: 1.676e-01\n",
      "Epoch 8859, Loss: 0.08094284683465958, Neurons: 64, Grad norm: 1.676e-01\n",
      "Epoch 8860, Loss: 0.08082637190818787, Neurons: 64, Grad norm: 1.801e-01\n",
      "Epoch 8860, Loss: 0.08082637190818787, Neurons: 64, Grad norm: 1.801e-01\n",
      "Epoch 8861, Loss: 0.08070994913578033, Neurons: 64, Grad norm: 2.190e-01\n",
      "Epoch 8861, Loss: 0.08070994913578033, Neurons: 64, Grad norm: 2.190e-01\n",
      "Epoch 8862, Loss: 0.0805940255522728, Neurons: 64, Grad norm: 2.432e-01\n",
      "Epoch 8862, Loss: 0.0805940255522728, Neurons: 64, Grad norm: 2.432e-01\n",
      "Epoch 8863, Loss: 0.08047844469547272, Neurons: 64, Grad norm: 3.033e-01\n",
      "Epoch 8863, Loss: 0.08047844469547272, Neurons: 64, Grad norm: 3.033e-01\n",
      "Epoch 8864, Loss: 0.0803632065653801, Neurons: 64, Grad norm: 3.586e-01\n",
      "Epoch 8864, Loss: 0.0803632065653801, Neurons: 64, Grad norm: 3.586e-01\n",
      "Epoch 8865, Loss: 0.08024813234806061, Neurons: 64, Grad norm: 4.367e-01\n",
      "Epoch 8865, Loss: 0.08024813234806061, Neurons: 64, Grad norm: 4.367e-01\n",
      "Epoch 8866, Loss: 0.08013379573822021, Neurons: 64, Grad norm: 5.273e-01\n",
      "Epoch 8866, Loss: 0.08013379573822021, Neurons: 64, Grad norm: 5.273e-01\n",
      "Epoch 8867, Loss: 0.08002009987831116, Neurons: 64, Grad norm: 6.648e-01\n",
      "Epoch 8867, Loss: 0.08002009987831116, Neurons: 64, Grad norm: 6.648e-01\n",
      "Epoch 8868, Loss: 0.0799073725938797, Neurons: 64, Grad norm: 8.102e-01\n",
      "Epoch 8868, Loss: 0.0799073725938797, Neurons: 64, Grad norm: 8.102e-01\n",
      "Epoch 8869, Loss: 0.07979631423950195, Neurons: 64, Grad norm: 1.024e+00\n",
      "Epoch 8869, Loss: 0.07979631423950195, Neurons: 64, Grad norm: 1.024e+00\n",
      "Epoch 8870, Loss: 0.07968758046627045, Neurons: 64, Grad norm: 1.271e+00\n",
      "Epoch 8870, Loss: 0.07968758046627045, Neurons: 64, Grad norm: 1.271e+00\n",
      "Epoch 8871, Loss: 0.07958237081766129, Neurons: 64, Grad norm: 1.612e+00\n",
      "Epoch 8871, Loss: 0.07958237081766129, Neurons: 64, Grad norm: 1.612e+00\n",
      "Epoch 8872, Loss: 0.07948271185159683, Neurons: 64, Grad norm: 2.021e+00\n",
      "Epoch 8872, Loss: 0.07948271185159683, Neurons: 64, Grad norm: 2.021e+00\n",
      "Epoch 8873, Loss: 0.07939185202121735, Neurons: 64, Grad norm: 2.558e+00\n",
      "Epoch 8873, Loss: 0.07939185202121735, Neurons: 64, Grad norm: 2.558e+00\n",
      "Epoch 8874, Loss: 0.07931520789861679, Neurons: 64, Grad norm: 3.224e+00\n",
      "Epoch 8874, Loss: 0.07931520789861679, Neurons: 64, Grad norm: 3.224e+00\n",
      "Epoch 8875, Loss: 0.07926062494516373, Neurons: 64, Grad norm: 4.058e+00\n",
      "Epoch 8875, Loss: 0.07926062494516373, Neurons: 64, Grad norm: 4.058e+00\n",
      "Epoch 8876, Loss: 0.07923802733421326, Neurons: 64, Grad norm: 5.018e+00\n",
      "Epoch 8876, Loss: 0.07923802733421326, Neurons: 64, Grad norm: 5.018e+00\n",
      "Epoch 8877, Loss: 0.07925920188426971, Neurons: 64, Grad norm: 6.114e+00\n",
      "Epoch 8877, Loss: 0.07925920188426971, Neurons: 64, Grad norm: 6.114e+00\n",
      "Epoch 8878, Loss: 0.07932966202497482, Neurons: 64, Grad norm: 7.171e+00\n",
      "Epoch 8878, Loss: 0.07932966202497482, Neurons: 64, Grad norm: 7.171e+00\n",
      "Epoch 8879, Loss: 0.07943310588598251, Neurons: 64, Grad norm: 8.001e+00\n",
      "Epoch 8879, Loss: 0.07943310588598251, Neurons: 64, Grad norm: 8.001e+00\n",
      "Epoch 8880, Loss: 0.07951098680496216, Neurons: 64, Grad norm: 8.221e+00\n",
      "Epoch 8880, Loss: 0.07951098680496216, Neurons: 64, Grad norm: 8.221e+00\n",
      "Epoch 8881, Loss: 0.07945755869150162, Neurons: 64, Grad norm: 7.542e+00\n",
      "Epoch 8881, Loss: 0.07945755869150162, Neurons: 64, Grad norm: 7.542e+00\n",
      "Epoch 8882, Loss: 0.07917999476194382, Neurons: 64, Grad norm: 5.778e+00\n",
      "Epoch 8882, Loss: 0.07917999476194382, Neurons: 64, Grad norm: 5.778e+00\n",
      "Epoch 8883, Loss: 0.07871226966381073, Neurons: 64, Grad norm: 3.169e+00\n",
      "Epoch 8883, Loss: 0.07871226966381073, Neurons: 64, Grad norm: 3.169e+00\n",
      "Epoch 8884, Loss: 0.078245148062706, Neurons: 64, Grad norm: 2.089e-01\n",
      "Epoch 8884, Loss: 0.078245148062706, Neurons: 64, Grad norm: 2.089e-01\n",
      "Epoch 8885, Loss: 0.07798367738723755, Neurons: 64, Grad norm: 2.521e+00\n",
      "Epoch 8885, Loss: 0.07798367738723755, Neurons: 64, Grad norm: 2.521e+00\n",
      "Epoch 8886, Loss: 0.07797011733055115, Neurons: 64, Grad norm: 4.489e+00\n",
      "Epoch 8886, Loss: 0.07797011733055115, Neurons: 64, Grad norm: 4.489e+00\n",
      "Epoch 8887, Loss: 0.07806700468063354, Neurons: 64, Grad norm: 5.324e+00\n",
      "Epoch 8887, Loss: 0.07806700468063354, Neurons: 64, Grad norm: 5.324e+00\n",
      "Epoch 8888, Loss: 0.07808250933885574, Neurons: 64, Grad norm: 4.945e+00\n",
      "Epoch 8888, Loss: 0.07808250933885574, Neurons: 64, Grad norm: 4.945e+00\n",
      "Epoch 8889, Loss: 0.07791212946176529, Neurons: 64, Grad norm: 3.456e+00\n",
      "Epoch 8889, Loss: 0.07791212946176529, Neurons: 64, Grad norm: 3.456e+00\n",
      "Epoch 8890, Loss: 0.07761409133672714, Neurons: 64, Grad norm: 1.313e+00\n",
      "Epoch 8890, Loss: 0.07761409133672714, Neurons: 64, Grad norm: 1.313e+00\n",
      "Epoch 8891, Loss: 0.07734901458024979, Neurons: 64, Grad norm: 9.558e-01\n",
      "Epoch 8891, Loss: 0.07734901458024979, Neurons: 64, Grad norm: 9.558e-01\n",
      "Epoch 8892, Loss: 0.07722754031419754, Neurons: 64, Grad norm: 2.746e+00\n",
      "Epoch 8892, Loss: 0.07722754031419754, Neurons: 64, Grad norm: 2.746e+00\n",
      "Epoch 8893, Loss: 0.07721942663192749, Neurons: 64, Grad norm: 3.716e+00\n",
      "Epoch 8893, Loss: 0.07721942663192749, Neurons: 64, Grad norm: 3.716e+00\n",
      "Epoch 8894, Loss: 0.07720451802015305, Neurons: 64, Grad norm: 3.656e+00\n",
      "Epoch 8894, Loss: 0.07720451802015305, Neurons: 64, Grad norm: 3.656e+00\n",
      "Epoch 8895, Loss: 0.07709100842475891, Neurons: 64, Grad norm: 2.709e+00\n",
      "Epoch 8895, Loss: 0.07709100842475891, Neurons: 64, Grad norm: 2.709e+00\n",
      "Epoch 8896, Loss: 0.07689013332128525, Neurons: 64, Grad norm: 1.152e+00\n",
      "Epoch 8896, Loss: 0.07689013332128525, Neurons: 64, Grad norm: 1.152e+00\n",
      "Epoch 8897, Loss: 0.07669127732515335, Neurons: 64, Grad norm: 5.396e-01\n",
      "Epoch 8897, Loss: 0.07669127732515335, Neurons: 64, Grad norm: 5.396e-01\n",
      "Epoch 8898, Loss: 0.07656724005937576, Neurons: 64, Grad norm: 1.931e+00\n",
      "Epoch 8898, Loss: 0.07656724005937576, Neurons: 64, Grad norm: 1.931e+00\n",
      "Epoch 8899, Loss: 0.07651109248399734, Neurons: 64, Grad norm: 2.677e+00\n",
      "Epoch 8899, Loss: 0.07651109248399734, Neurons: 64, Grad norm: 2.677e+00\n",
      "Epoch 8899, Test loss: 0.05113644525408745\n",
      "Epoch 8899, Test loss: 0.05113644525408745\n",
      "Epoch 8900, Loss: 0.07645680010318756, Neurons: 64, Grad norm: 2.693e+00\n",
      "Epoch 8900, Loss: 0.07645680010318756, Neurons: 64, Grad norm: 2.693e+00\n",
      "Epoch 8901, Loss: 0.07635024189949036, Neurons: 64, Grad norm: 1.999e+00\n",
      "Epoch 8901, Loss: 0.07635024189949036, Neurons: 64, Grad norm: 1.999e+00\n",
      "Epoch 8902, Loss: 0.07619407773017883, Neurons: 64, Grad norm: 8.920e-01\n",
      "Epoch 8902, Loss: 0.07619407773017883, Neurons: 64, Grad norm: 8.920e-01\n",
      "Epoch 8903, Loss: 0.07603751122951508, Neurons: 64, Grad norm: 3.666e-01\n",
      "Epoch 8903, Loss: 0.07603751122951508, Neurons: 64, Grad norm: 3.666e-01\n",
      "Epoch 8904, Loss: 0.0759204626083374, Neurons: 64, Grad norm: 1.375e+00\n",
      "Epoch 8904, Loss: 0.0759204626083374, Neurons: 64, Grad norm: 1.375e+00\n",
      "Epoch 8905, Loss: 0.07584087550640106, Neurons: 64, Grad norm: 1.960e+00\n",
      "Epoch 8905, Loss: 0.07584087550640106, Neurons: 64, Grad norm: 1.960e+00\n",
      "Epoch 8906, Loss: 0.07576385885477066, Neurons: 64, Grad norm: 1.982e+00\n",
      "Epoch 8906, Loss: 0.07576385885477066, Neurons: 64, Grad norm: 1.982e+00\n",
      "Epoch 8907, Loss: 0.07565897703170776, Neurons: 64, Grad norm: 1.519e+00\n",
      "Epoch 8907, Loss: 0.07565897703170776, Neurons: 64, Grad norm: 1.519e+00\n",
      "Epoch 8908, Loss: 0.07552792876958847, Neurons: 64, Grad norm: 7.052e-01\n",
      "Epoch 8908, Loss: 0.07552792876958847, Neurons: 64, Grad norm: 7.052e-01\n",
      "Epoch 8909, Loss: 0.07539483904838562, Neurons: 64, Grad norm: 2.123e-01\n",
      "Epoch 8909, Loss: 0.07539483904838562, Neurons: 64, Grad norm: 2.123e-01\n",
      "Epoch 8910, Loss: 0.07528243958950043, Neurons: 64, Grad norm: 9.725e-01\n",
      "Epoch 8910, Loss: 0.07528243958950043, Neurons: 64, Grad norm: 9.725e-01\n",
      "Epoch 8911, Loss: 0.07519012689590454, Neurons: 64, Grad norm: 1.411e+00\n",
      "Epoch 8911, Loss: 0.07519012689590454, Neurons: 64, Grad norm: 1.411e+00\n",
      "Epoch 8912, Loss: 0.07510119676589966, Neurons: 64, Grad norm: 1.484e+00\n",
      "Epoch 8912, Loss: 0.07510119676589966, Neurons: 64, Grad norm: 1.484e+00\n",
      "Epoch 8913, Loss: 0.07499853521585464, Neurons: 64, Grad norm: 1.175e+00\n",
      "Epoch 8913, Loss: 0.07499853521585464, Neurons: 64, Grad norm: 1.175e+00\n",
      "Epoch 8914, Loss: 0.07488136738538742, Neurons: 64, Grad norm: 6.326e-01\n",
      "Epoch 8914, Loss: 0.07488136738538742, Neurons: 64, Grad norm: 6.326e-01\n",
      "Epoch 8915, Loss: 0.07476162910461426, Neurons: 64, Grad norm: 9.575e-02\n",
      "Epoch 8915, Loss: 0.07476162910461426, Neurons: 64, Grad norm: 9.575e-02\n",
      "Epoch 8916, Loss: 0.07465116679668427, Neurons: 64, Grad norm: 6.199e-01\n",
      "Epoch 8916, Loss: 0.07465116679668427, Neurons: 64, Grad norm: 6.199e-01\n",
      "Epoch 8917, Loss: 0.0745525136590004, Neurons: 64, Grad norm: 1.009e+00\n",
      "Epoch 8917, Loss: 0.0745525136590004, Neurons: 64, Grad norm: 1.009e+00\n",
      "Epoch 8918, Loss: 0.07445763051509857, Neurons: 64, Grad norm: 1.104e+00\n",
      "Epoch 8918, Loss: 0.07445763051509857, Neurons: 64, Grad norm: 1.104e+00\n",
      "Epoch 8919, Loss: 0.07435695081949234, Neurons: 64, Grad norm: 9.529e-01\n",
      "Epoch 8919, Loss: 0.07435695081949234, Neurons: 64, Grad norm: 9.529e-01\n",
      "Epoch 8920, Loss: 0.07424818724393845, Neurons: 64, Grad norm: 5.890e-01\n",
      "Epoch 8920, Loss: 0.07424818724393845, Neurons: 64, Grad norm: 5.890e-01\n",
      "Epoch 8921, Loss: 0.0741361603140831, Neurons: 64, Grad norm: 1.527e-01\n",
      "Epoch 8921, Loss: 0.0741361603140831, Neurons: 64, Grad norm: 1.527e-01\n",
      "Epoch 8922, Loss: 0.07402785867452621, Neurons: 64, Grad norm: 3.403e-01\n",
      "Epoch 8922, Loss: 0.07402785867452621, Neurons: 64, Grad norm: 3.403e-01\n",
      "Epoch 8923, Loss: 0.07392570376396179, Neurons: 64, Grad norm: 6.449e-01\n",
      "Epoch 8923, Loss: 0.07392570376396179, Neurons: 64, Grad norm: 6.449e-01\n",
      "Epoch 8924, Loss: 0.07382731139659882, Neurons: 64, Grad norm: 8.025e-01\n",
      "Epoch 8924, Loss: 0.07382731139659882, Neurons: 64, Grad norm: 8.025e-01\n",
      "Epoch 8925, Loss: 0.07372770458459854, Neurons: 64, Grad norm: 7.528e-01\n",
      "Epoch 8925, Loss: 0.07372770458459854, Neurons: 64, Grad norm: 7.528e-01\n",
      "Epoch 8926, Loss: 0.07362373918294907, Neurons: 64, Grad norm: 5.604e-01\n",
      "Epoch 8926, Loss: 0.07362373918294907, Neurons: 64, Grad norm: 5.604e-01\n",
      "Epoch 8927, Loss: 0.07351745665073395, Neurons: 64, Grad norm: 2.563e-01\n",
      "Epoch 8927, Loss: 0.07351745665073395, Neurons: 64, Grad norm: 2.563e-01\n",
      "Epoch 8928, Loss: 0.07341130077838898, Neurons: 64, Grad norm: 1.143e-01\n",
      "Epoch 8928, Loss: 0.07341130077838898, Neurons: 64, Grad norm: 1.143e-01\n",
      "Epoch 8929, Loss: 0.07330822944641113, Neurons: 64, Grad norm: 3.718e-01\n",
      "Epoch 8929, Loss: 0.07330822944641113, Neurons: 64, Grad norm: 3.718e-01\n",
      "Epoch 8930, Loss: 0.07320797443389893, Neurons: 64, Grad norm: 5.377e-01\n",
      "Epoch 8930, Loss: 0.07320797443389893, Neurons: 64, Grad norm: 5.377e-01\n",
      "Epoch 8931, Loss: 0.07310844957828522, Neurons: 64, Grad norm: 5.957e-01\n",
      "Epoch 8931, Loss: 0.07310844957828522, Neurons: 64, Grad norm: 5.957e-01\n",
      "Epoch 8932, Loss: 0.07300775498151779, Neurons: 64, Grad norm: 5.085e-01\n",
      "Epoch 8932, Loss: 0.07300775498151779, Neurons: 64, Grad norm: 5.085e-01\n",
      "Epoch 8933, Loss: 0.07290510833263397, Neurons: 64, Grad norm: 3.527e-01\n",
      "Epoch 8933, Loss: 0.07290510833263397, Neurons: 64, Grad norm: 3.527e-01\n",
      "Epoch 8934, Loss: 0.07280142605304718, Neurons: 64, Grad norm: 1.367e-01\n",
      "Epoch 8934, Loss: 0.07280142605304718, Neurons: 64, Grad norm: 1.367e-01\n",
      "Epoch 8935, Loss: 0.07269873470067978, Neurons: 64, Grad norm: 1.361e-01\n",
      "Epoch 8935, Loss: 0.07269873470067978, Neurons: 64, Grad norm: 1.361e-01\n",
      "Epoch 8936, Loss: 0.07259780913591385, Neurons: 64, Grad norm: 3.047e-01\n",
      "Epoch 8936, Loss: 0.07259780913591385, Neurons: 64, Grad norm: 3.047e-01\n",
      "Epoch 8937, Loss: 0.07249805331230164, Neurons: 64, Grad norm: 4.022e-01\n",
      "Epoch 8937, Loss: 0.07249805331230164, Neurons: 64, Grad norm: 4.022e-01\n",
      "Epoch 8938, Loss: 0.07239855825901031, Neurons: 64, Grad norm: 4.341e-01\n",
      "Epoch 8938, Loss: 0.07239855825901031, Neurons: 64, Grad norm: 4.341e-01\n",
      "Epoch 8939, Loss: 0.07229823619127274, Neurons: 64, Grad norm: 3.636e-01\n",
      "Epoch 8939, Loss: 0.07229823619127274, Neurons: 64, Grad norm: 3.636e-01\n",
      "Epoch 8940, Loss: 0.07219737768173218, Neurons: 64, Grad norm: 2.619e-01\n",
      "Epoch 8940, Loss: 0.07219737768173218, Neurons: 64, Grad norm: 2.619e-01\n",
      "Epoch 8941, Loss: 0.0720963180065155, Neurons: 64, Grad norm: 1.210e-01\n",
      "Epoch 8941, Loss: 0.0720963180065155, Neurons: 64, Grad norm: 1.210e-01\n",
      "Epoch 8942, Loss: 0.07199548929929733, Neurons: 64, Grad norm: 1.018e-01\n",
      "Epoch 8942, Loss: 0.07199548929929733, Neurons: 64, Grad norm: 1.018e-01\n",
      "Epoch 8943, Loss: 0.07189566642045975, Neurons: 64, Grad norm: 2.104e-01\n",
      "Epoch 8943, Loss: 0.07189566642045975, Neurons: 64, Grad norm: 2.104e-01\n",
      "Epoch 8944, Loss: 0.07179661840200424, Neurons: 64, Grad norm: 2.737e-01\n",
      "Epoch 8944, Loss: 0.07179661840200424, Neurons: 64, Grad norm: 2.737e-01\n",
      "Epoch 8945, Loss: 0.0716976597905159, Neurons: 64, Grad norm: 3.079e-01\n",
      "Epoch 8945, Loss: 0.0716976597905159, Neurons: 64, Grad norm: 3.079e-01\n",
      "Epoch 8946, Loss: 0.07159879058599472, Neurons: 64, Grad norm: 2.750e-01\n",
      "Epoch 8946, Loss: 0.07159879058599472, Neurons: 64, Grad norm: 2.750e-01\n",
      "Epoch 8947, Loss: 0.071499302983284, Neurons: 64, Grad norm: 2.098e-01\n",
      "Epoch 8947, Loss: 0.071499302983284, Neurons: 64, Grad norm: 2.098e-01\n",
      "Epoch 8948, Loss: 0.07140010595321655, Neurons: 64, Grad norm: 1.172e-01\n",
      "Epoch 8948, Loss: 0.07140010595321655, Neurons: 64, Grad norm: 1.172e-01\n",
      "Epoch 8949, Loss: 0.07130110263824463, Neurons: 64, Grad norm: 8.506e-02\n",
      "Epoch 8949, Loss: 0.07130110263824463, Neurons: 64, Grad norm: 8.506e-02\n",
      "Epoch 8950, Loss: 0.07120238244533539, Neurons: 64, Grad norm: 1.356e-01\n",
      "Epoch 8950, Loss: 0.07120238244533539, Neurons: 64, Grad norm: 1.356e-01\n",
      "Epoch 8951, Loss: 0.07110407948493958, Neurons: 64, Grad norm: 1.823e-01\n",
      "Epoch 8951, Loss: 0.07110407948493958, Neurons: 64, Grad norm: 1.823e-01\n",
      "Epoch 8952, Loss: 0.07100624591112137, Neurons: 64, Grad norm: 2.191e-01\n",
      "Epoch 8952, Loss: 0.07100624591112137, Neurons: 64, Grad norm: 2.191e-01\n",
      "Epoch 8953, Loss: 0.07090827077627182, Neurons: 64, Grad norm: 2.070e-01\n",
      "Epoch 8953, Loss: 0.07090827077627182, Neurons: 64, Grad norm: 2.070e-01\n",
      "Epoch 8954, Loss: 0.07081049680709839, Neurons: 64, Grad norm: 1.842e-01\n",
      "Epoch 8954, Loss: 0.07081049680709839, Neurons: 64, Grad norm: 1.842e-01\n",
      "Epoch 8955, Loss: 0.07071277499198914, Neurons: 64, Grad norm: 1.301e-01\n",
      "Epoch 8955, Loss: 0.07071277499198914, Neurons: 64, Grad norm: 1.301e-01\n",
      "Epoch 8956, Loss: 0.07061505317687988, Neurons: 64, Grad norm: 9.474e-02\n",
      "Epoch 8956, Loss: 0.07061505317687988, Neurons: 64, Grad norm: 9.474e-02\n",
      "Epoch 8957, Loss: 0.07051750272512436, Neurons: 64, Grad norm: 8.728e-02\n",
      "Epoch 8957, Loss: 0.07051750272512436, Neurons: 64, Grad norm: 8.728e-02\n",
      "Epoch 8958, Loss: 0.07042036950588226, Neurons: 64, Grad norm: 1.069e-01\n",
      "Epoch 8958, Loss: 0.07042036950588226, Neurons: 64, Grad norm: 1.069e-01\n",
      "Epoch 8959, Loss: 0.07032325863838196, Neurons: 64, Grad norm: 1.373e-01\n",
      "Epoch 8959, Loss: 0.07032325863838196, Neurons: 64, Grad norm: 1.373e-01\n",
      "Epoch 8960, Loss: 0.07022646069526672, Neurons: 64, Grad norm: 1.438e-01\n",
      "Epoch 8960, Loss: 0.07022646069526672, Neurons: 64, Grad norm: 1.438e-01\n",
      "Epoch 8961, Loss: 0.07013000547885895, Neurons: 64, Grad norm: 1.555e-01\n",
      "Epoch 8961, Loss: 0.07013000547885895, Neurons: 64, Grad norm: 1.555e-01\n",
      "Epoch 8962, Loss: 0.0700334683060646, Neurons: 64, Grad norm: 1.408e-01\n",
      "Epoch 8962, Loss: 0.0700334683060646, Neurons: 64, Grad norm: 1.408e-01\n",
      "Epoch 8963, Loss: 0.06993702054023743, Neurons: 64, Grad norm: 1.312e-01\n",
      "Epoch 8963, Loss: 0.06993702054023743, Neurons: 64, Grad norm: 1.312e-01\n",
      "Epoch 8964, Loss: 0.06984079629182816, Neurons: 64, Grad norm: 9.843e-02\n",
      "Epoch 8964, Loss: 0.06984079629182816, Neurons: 64, Grad norm: 9.843e-02\n",
      "Epoch 8965, Loss: 0.069744773209095, Neurons: 64, Grad norm: 8.501e-02\n",
      "Epoch 8965, Loss: 0.069744773209095, Neurons: 64, Grad norm: 8.501e-02\n",
      "Epoch 8966, Loss: 0.06964890658855438, Neurons: 64, Grad norm: 8.546e-02\n",
      "Epoch 8966, Loss: 0.06964890658855438, Neurons: 64, Grad norm: 8.546e-02\n",
      "Epoch 8967, Loss: 0.06955330073833466, Neurons: 64, Grad norm: 9.711e-02\n",
      "Epoch 8967, Loss: 0.06955330073833466, Neurons: 64, Grad norm: 9.711e-02\n",
      "Epoch 8968, Loss: 0.06945779919624329, Neurons: 64, Grad norm: 1.150e-01\n",
      "Epoch 8968, Loss: 0.06945779919624329, Neurons: 64, Grad norm: 1.150e-01\n",
      "Epoch 8969, Loss: 0.06936247646808624, Neurons: 64, Grad norm: 1.124e-01\n",
      "Epoch 8969, Loss: 0.06936247646808624, Neurons: 64, Grad norm: 1.124e-01\n",
      "Epoch 8970, Loss: 0.06926728785037994, Neurons: 64, Grad norm: 1.202e-01\n",
      "Epoch 8970, Loss: 0.06926728785037994, Neurons: 64, Grad norm: 1.202e-01\n",
      "Epoch 8971, Loss: 0.06917241215705872, Neurons: 64, Grad norm: 1.095e-01\n",
      "Epoch 8971, Loss: 0.06917241215705872, Neurons: 64, Grad norm: 1.095e-01\n",
      "Epoch 8972, Loss: 0.0690775066614151, Neurons: 64, Grad norm: 1.022e-01\n",
      "Epoch 8972, Loss: 0.0690775066614151, Neurons: 64, Grad norm: 1.022e-01\n",
      "Epoch 8973, Loss: 0.0689828097820282, Neurons: 64, Grad norm: 8.541e-02\n",
      "Epoch 8973, Loss: 0.0689828097820282, Neurons: 64, Grad norm: 8.541e-02\n",
      "Epoch 8974, Loss: 0.06888830661773682, Neurons: 64, Grad norm: 8.095e-02\n",
      "Epoch 8974, Loss: 0.06888830661773682, Neurons: 64, Grad norm: 8.095e-02\n",
      "Epoch 8975, Loss: 0.06879391521215439, Neurons: 64, Grad norm: 8.224e-02\n",
      "Epoch 8975, Loss: 0.06879391521215439, Neurons: 64, Grad norm: 8.224e-02\n",
      "Epoch 8976, Loss: 0.06869977712631226, Neurons: 64, Grad norm: 8.403e-02\n",
      "Epoch 8976, Loss: 0.06869977712631226, Neurons: 64, Grad norm: 8.403e-02\n",
      "Epoch 8977, Loss: 0.06860589236021042, Neurons: 64, Grad norm: 9.398e-02\n",
      "Epoch 8977, Loss: 0.06860589236021042, Neurons: 64, Grad norm: 9.398e-02\n",
      "Epoch 8978, Loss: 0.068511962890625, Neurons: 64, Grad norm: 9.391e-02\n",
      "Epoch 8978, Loss: 0.068511962890625, Neurons: 64, Grad norm: 9.391e-02\n",
      "Epoch 8979, Loss: 0.06841829419136047, Neurons: 64, Grad norm: 9.703e-02\n",
      "Epoch 8979, Loss: 0.06841829419136047, Neurons: 64, Grad norm: 9.703e-02\n",
      "Epoch 8980, Loss: 0.0683247372508049, Neurons: 64, Grad norm: 9.181e-02\n",
      "Epoch 8980, Loss: 0.0683247372508049, Neurons: 64, Grad norm: 9.181e-02\n",
      "Epoch 8981, Loss: 0.06823139637708664, Neurons: 64, Grad norm: 9.273e-02\n",
      "Epoch 8981, Loss: 0.06823139637708664, Neurons: 64, Grad norm: 9.273e-02\n",
      "Epoch 8982, Loss: 0.06813806295394897, Neurons: 64, Grad norm: 8.446e-02\n",
      "Epoch 8982, Loss: 0.06813806295394897, Neurons: 64, Grad norm: 8.446e-02\n",
      "Epoch 8983, Loss: 0.06804516166448593, Neurons: 64, Grad norm: 8.192e-02\n",
      "Epoch 8983, Loss: 0.06804516166448593, Neurons: 64, Grad norm: 8.192e-02\n",
      "Epoch 8984, Loss: 0.06795207411050797, Neurons: 64, Grad norm: 7.948e-02\n",
      "Epoch 8984, Loss: 0.06795207411050797, Neurons: 64, Grad norm: 7.948e-02\n",
      "Epoch 8985, Loss: 0.06785933673381805, Neurons: 64, Grad norm: 7.884e-02\n",
      "Epoch 8985, Loss: 0.06785933673381805, Neurons: 64, Grad norm: 7.884e-02\n",
      "Epoch 8986, Loss: 0.06776683032512665, Neurons: 64, Grad norm: 8.250e-02\n",
      "Epoch 8986, Loss: 0.06776683032512665, Neurons: 64, Grad norm: 8.250e-02\n",
      "Epoch 8987, Loss: 0.06767448037862778, Neurons: 64, Grad norm: 8.380e-02\n",
      "Epoch 8987, Loss: 0.06767448037862778, Neurons: 64, Grad norm: 8.380e-02\n",
      "Epoch 8988, Loss: 0.06758234649896622, Neurons: 64, Grad norm: 8.556e-02\n",
      "Epoch 8988, Loss: 0.06758234649896622, Neurons: 64, Grad norm: 8.556e-02\n",
      "Epoch 8989, Loss: 0.06749030202627182, Neurons: 64, Grad norm: 8.166e-02\n",
      "Epoch 8989, Loss: 0.06749030202627182, Neurons: 64, Grad norm: 8.166e-02\n",
      "Epoch 8990, Loss: 0.06739823520183563, Neurons: 64, Grad norm: 8.449e-02\n",
      "Epoch 8990, Loss: 0.06739823520183563, Neurons: 64, Grad norm: 8.449e-02\n",
      "Epoch 8991, Loss: 0.06730639934539795, Neurons: 64, Grad norm: 8.191e-02\n",
      "Epoch 8991, Loss: 0.06730639934539795, Neurons: 64, Grad norm: 8.191e-02\n",
      "Epoch 8992, Loss: 0.06721489876508713, Neurons: 64, Grad norm: 8.320e-02\n",
      "Epoch 8992, Loss: 0.06721489876508713, Neurons: 64, Grad norm: 8.320e-02\n",
      "Epoch 8993, Loss: 0.06712348014116287, Neurons: 64, Grad norm: 8.155e-02\n",
      "Epoch 8993, Loss: 0.06712348014116287, Neurons: 64, Grad norm: 8.155e-02\n",
      "Epoch 8994, Loss: 0.06703206151723862, Neurons: 64, Grad norm: 8.101e-02\n",
      "Epoch 8994, Loss: 0.06703206151723862, Neurons: 64, Grad norm: 8.101e-02\n",
      "Epoch 8995, Loss: 0.06694084405899048, Neurons: 64, Grad norm: 7.788e-02\n",
      "Epoch 8995, Loss: 0.06694084405899048, Neurons: 64, Grad norm: 7.788e-02\n",
      "Epoch 8996, Loss: 0.06684983521699905, Neurons: 64, Grad norm: 8.172e-02\n",
      "Epoch 8996, Loss: 0.06684983521699905, Neurons: 64, Grad norm: 8.172e-02\n",
      "Epoch 8997, Loss: 0.06675907224416733, Neurons: 64, Grad norm: 8.046e-02\n",
      "Epoch 8997, Loss: 0.06675907224416733, Neurons: 64, Grad norm: 8.046e-02\n",
      "Epoch 8998, Loss: 0.06666834652423859, Neurons: 64, Grad norm: 8.154e-02\n",
      "Epoch 8998, Loss: 0.06666834652423859, Neurons: 64, Grad norm: 8.154e-02\n",
      "Epoch 8999, Loss: 0.06657787412405014, Neurons: 64, Grad norm: 7.865e-02\n",
      "Epoch 8999, Loss: 0.06657787412405014, Neurons: 64, Grad norm: 7.865e-02\n",
      "Epoch 8999, Test loss: 0.04414079338312149\n",
      "Epoch 8999, Test loss: 0.04414079338312149\n",
      "Epoch 9000, Loss: 0.06648760288953781, Neurons: 64, Grad norm: 7.924e-02\n",
      "Epoch 9000, Loss: 0.06648760288953781, Neurons: 64, Grad norm: 7.924e-02\n",
      "Epoch 9001, Loss: 0.06639733910560608, Neurons: 64, Grad norm: 7.728e-02\n",
      "Epoch 9001, Loss: 0.06639733910560608, Neurons: 64, Grad norm: 7.728e-02\n",
      "Epoch 9002, Loss: 0.06630738824605942, Neurons: 64, Grad norm: 7.928e-02\n",
      "Epoch 9002, Loss: 0.06630738824605942, Neurons: 64, Grad norm: 7.928e-02\n",
      "Epoch 9003, Loss: 0.06621746718883514, Neurons: 64, Grad norm: 7.959e-02\n",
      "Epoch 9003, Loss: 0.06621746718883514, Neurons: 64, Grad norm: 7.959e-02\n",
      "Epoch 9004, Loss: 0.06612758338451385, Neurons: 64, Grad norm: 7.980e-02\n",
      "Epoch 9004, Loss: 0.06612758338451385, Neurons: 64, Grad norm: 7.980e-02\n",
      "Epoch 9005, Loss: 0.06603799760341644, Neurons: 64, Grad norm: 7.886e-02\n",
      "Epoch 9005, Loss: 0.06603799760341644, Neurons: 64, Grad norm: 7.886e-02\n",
      "Epoch 9006, Loss: 0.06594868004322052, Neurons: 64, Grad norm: 7.695e-02\n",
      "Epoch 9006, Loss: 0.06594868004322052, Neurons: 64, Grad norm: 7.695e-02\n",
      "Epoch 9007, Loss: 0.06585931777954102, Neurons: 64, Grad norm: 7.798e-02\n",
      "Epoch 9007, Loss: 0.06585931777954102, Neurons: 64, Grad norm: 7.798e-02\n",
      "Epoch 9008, Loss: 0.0657702088356018, Neurons: 64, Grad norm: 7.783e-02\n",
      "Epoch 9008, Loss: 0.0657702088356018, Neurons: 64, Grad norm: 7.783e-02\n",
      "Epoch 9009, Loss: 0.06568112224340439, Neurons: 64, Grad norm: 7.960e-02\n",
      "Epoch 9009, Loss: 0.06568112224340439, Neurons: 64, Grad norm: 7.960e-02\n",
      "Epoch 9010, Loss: 0.06559235602617264, Neurons: 64, Grad norm: 7.871e-02\n",
      "Epoch 9010, Loss: 0.06559235602617264, Neurons: 64, Grad norm: 7.871e-02\n",
      "Epoch 9011, Loss: 0.06550370901823044, Neurons: 64, Grad norm: 8.151e-02\n",
      "Epoch 9011, Loss: 0.06550370901823044, Neurons: 64, Grad norm: 8.151e-02\n",
      "Epoch 9012, Loss: 0.06541524827480316, Neurons: 64, Grad norm: 7.914e-02\n",
      "Epoch 9012, Loss: 0.06541524827480316, Neurons: 64, Grad norm: 7.914e-02\n",
      "Epoch 9013, Loss: 0.06532680988311768, Neurons: 64, Grad norm: 8.270e-02\n",
      "Epoch 9013, Loss: 0.06532680988311768, Neurons: 64, Grad norm: 8.270e-02\n",
      "Epoch 9014, Loss: 0.06523873656988144, Neurons: 64, Grad norm: 8.095e-02\n",
      "Epoch 9014, Loss: 0.06523873656988144, Neurons: 64, Grad norm: 8.095e-02\n",
      "Epoch 9015, Loss: 0.06515057384967804, Neurons: 64, Grad norm: 8.171e-02\n",
      "Epoch 9015, Loss: 0.06515057384967804, Neurons: 64, Grad norm: 8.171e-02\n",
      "Epoch 9016, Loss: 0.0650627613067627, Neurons: 64, Grad norm: 7.925e-02\n",
      "Epoch 9016, Loss: 0.0650627613067627, Neurons: 64, Grad norm: 7.925e-02\n",
      "Epoch 9017, Loss: 0.06497502326965332, Neurons: 64, Grad norm: 8.294e-02\n",
      "Epoch 9017, Loss: 0.06497502326965332, Neurons: 64, Grad norm: 8.294e-02\n",
      "Epoch 9018, Loss: 0.06488730013370514, Neurons: 64, Grad norm: 7.992e-02\n",
      "Epoch 9018, Loss: 0.06488730013370514, Neurons: 64, Grad norm: 7.992e-02\n",
      "Epoch 9019, Loss: 0.06479979306459427, Neurons: 64, Grad norm: 8.396e-02\n",
      "Epoch 9019, Loss: 0.06479979306459427, Neurons: 64, Grad norm: 8.396e-02\n",
      "Epoch 9020, Loss: 0.06471250206232071, Neurons: 64, Grad norm: 8.367e-02\n",
      "Epoch 9020, Loss: 0.06471250206232071, Neurons: 64, Grad norm: 8.367e-02\n",
      "Epoch 9021, Loss: 0.06462539732456207, Neurons: 64, Grad norm: 8.892e-02\n",
      "Epoch 9021, Loss: 0.06462539732456207, Neurons: 64, Grad norm: 8.892e-02\n",
      "Epoch 9022, Loss: 0.06453819572925568, Neurons: 64, Grad norm: 8.365e-02\n",
      "Epoch 9022, Loss: 0.06453819572925568, Neurons: 64, Grad norm: 8.365e-02\n",
      "Epoch 9023, Loss: 0.06445146352052689, Neurons: 64, Grad norm: 8.732e-02\n",
      "Epoch 9023, Loss: 0.06445146352052689, Neurons: 64, Grad norm: 8.732e-02\n",
      "Epoch 9024, Loss: 0.06436470150947571, Neurons: 64, Grad norm: 8.466e-02\n",
      "Epoch 9024, Loss: 0.06436470150947571, Neurons: 64, Grad norm: 8.466e-02\n",
      "Epoch 9025, Loss: 0.06427812576293945, Neurons: 64, Grad norm: 9.025e-02\n",
      "Epoch 9025, Loss: 0.06427812576293945, Neurons: 64, Grad norm: 9.025e-02\n",
      "Epoch 9026, Loss: 0.06419160217046738, Neurons: 64, Grad norm: 8.943e-02\n",
      "Epoch 9026, Loss: 0.06419160217046738, Neurons: 64, Grad norm: 8.943e-02\n",
      "Epoch 9027, Loss: 0.0641053169965744, Neurons: 64, Grad norm: 9.371e-02\n",
      "Epoch 9027, Loss: 0.0641053169965744, Neurons: 64, Grad norm: 9.371e-02\n",
      "Epoch 9028, Loss: 0.06401912122964859, Neurons: 64, Grad norm: 9.363e-02\n",
      "Epoch 9028, Loss: 0.06401912122964859, Neurons: 64, Grad norm: 9.363e-02\n",
      "Epoch 9029, Loss: 0.06393314152956009, Neurons: 64, Grad norm: 9.949e-02\n",
      "Epoch 9029, Loss: 0.06393314152956009, Neurons: 64, Grad norm: 9.949e-02\n",
      "Epoch 9030, Loss: 0.06384731829166412, Neurons: 64, Grad norm: 9.520e-02\n",
      "Epoch 9030, Loss: 0.06384731829166412, Neurons: 64, Grad norm: 9.520e-02\n",
      "Epoch 9031, Loss: 0.06376167386770248, Neurons: 64, Grad norm: 1.043e-01\n",
      "Epoch 9031, Loss: 0.06376167386770248, Neurons: 64, Grad norm: 1.043e-01\n",
      "Epoch 9032, Loss: 0.06367599964141846, Neurons: 64, Grad norm: 1.061e-01\n",
      "Epoch 9032, Loss: 0.06367599964141846, Neurons: 64, Grad norm: 1.061e-01\n",
      "Epoch 9033, Loss: 0.06359070539474487, Neurons: 64, Grad norm: 1.207e-01\n",
      "Epoch 9033, Loss: 0.06359070539474487, Neurons: 64, Grad norm: 1.207e-01\n",
      "Epoch 9034, Loss: 0.06350544095039368, Neurons: 64, Grad norm: 1.257e-01\n",
      "Epoch 9034, Loss: 0.06350544095039368, Neurons: 64, Grad norm: 1.257e-01\n",
      "Epoch 9035, Loss: 0.0634203553199768, Neurons: 64, Grad norm: 1.487e-01\n",
      "Epoch 9035, Loss: 0.0634203553199768, Neurons: 64, Grad norm: 1.487e-01\n",
      "Epoch 9036, Loss: 0.06333550810813904, Neurons: 64, Grad norm: 1.615e-01\n",
      "Epoch 9036, Loss: 0.06333550810813904, Neurons: 64, Grad norm: 1.615e-01\n",
      "Epoch 9037, Loss: 0.06325063109397888, Neurons: 64, Grad norm: 1.902e-01\n",
      "Epoch 9037, Loss: 0.06325063109397888, Neurons: 64, Grad norm: 1.902e-01\n",
      "Epoch 9038, Loss: 0.06316602975130081, Neurons: 64, Grad norm: 2.112e-01\n",
      "Epoch 9038, Loss: 0.06316602975130081, Neurons: 64, Grad norm: 2.112e-01\n",
      "Epoch 9039, Loss: 0.063081756234169, Neurons: 64, Grad norm: 2.585e-01\n",
      "Epoch 9039, Loss: 0.063081756234169, Neurons: 64, Grad norm: 2.585e-01\n",
      "Epoch 9040, Loss: 0.06299754232168198, Neurons: 64, Grad norm: 2.973e-01\n",
      "Epoch 9040, Loss: 0.06299754232168198, Neurons: 64, Grad norm: 2.973e-01\n",
      "Epoch 9041, Loss: 0.06291362643241882, Neurons: 64, Grad norm: 3.590e-01\n",
      "Epoch 9041, Loss: 0.06291362643241882, Neurons: 64, Grad norm: 3.590e-01\n",
      "Epoch 9042, Loss: 0.06283001601696014, Neurons: 64, Grad norm: 4.189e-01\n",
      "Epoch 9042, Loss: 0.06283001601696014, Neurons: 64, Grad norm: 4.189e-01\n",
      "Epoch 9043, Loss: 0.06274701654911041, Neurons: 64, Grad norm: 5.113e-01\n",
      "Epoch 9043, Loss: 0.06274701654911041, Neurons: 64, Grad norm: 5.113e-01\n",
      "Epoch 9044, Loss: 0.06266431510448456, Neurons: 64, Grad norm: 6.109e-01\n",
      "Epoch 9044, Loss: 0.06266431510448456, Neurons: 64, Grad norm: 6.109e-01\n",
      "Epoch 9045, Loss: 0.06258236616849899, Neurons: 64, Grad norm: 7.511e-01\n",
      "Epoch 9045, Loss: 0.06258236616849899, Neurons: 64, Grad norm: 7.511e-01\n",
      "Epoch 9046, Loss: 0.06250151991844177, Neurons: 64, Grad norm: 9.147e-01\n",
      "Epoch 9046, Loss: 0.06250151991844177, Neurons: 64, Grad norm: 9.147e-01\n",
      "Epoch 9047, Loss: 0.062422577291727066, Neurons: 64, Grad norm: 1.135e+00\n",
      "Epoch 9047, Loss: 0.062422577291727066, Neurons: 64, Grad norm: 1.135e+00\n",
      "Epoch 9048, Loss: 0.06234585866332054, Neurons: 64, Grad norm: 1.394e+00\n",
      "Epoch 9048, Loss: 0.06234585866332054, Neurons: 64, Grad norm: 1.394e+00\n",
      "Epoch 9049, Loss: 0.06227283924818039, Neurons: 64, Grad norm: 1.742e+00\n",
      "Epoch 9049, Loss: 0.06227283924818039, Neurons: 64, Grad norm: 1.742e+00\n",
      "Epoch 9050, Loss: 0.06220589205622673, Neurons: 64, Grad norm: 2.161e+00\n",
      "Epoch 9050, Loss: 0.06220589205622673, Neurons: 64, Grad norm: 2.161e+00\n",
      "Epoch 9051, Loss: 0.06214814633131027, Neurons: 64, Grad norm: 2.695e+00\n",
      "Epoch 9051, Loss: 0.06214814633131027, Neurons: 64, Grad norm: 2.695e+00\n",
      "Epoch 9052, Loss: 0.06210415065288544, Neurons: 64, Grad norm: 3.342e+00\n",
      "Epoch 9052, Loss: 0.06210415065288544, Neurons: 64, Grad norm: 3.342e+00\n",
      "Epoch 9053, Loss: 0.06208142265677452, Neurons: 64, Grad norm: 4.148e+00\n",
      "Epoch 9053, Loss: 0.06208142265677452, Neurons: 64, Grad norm: 4.148e+00\n",
      "Epoch 9054, Loss: 0.062088992446660995, Neurons: 64, Grad norm: 5.071e+00\n",
      "Epoch 9054, Loss: 0.062088992446660995, Neurons: 64, Grad norm: 5.071e+00\n",
      "Epoch 9055, Loss: 0.06213705614209175, Neurons: 64, Grad norm: 6.109e+00\n",
      "Epoch 9055, Loss: 0.06213705614209175, Neurons: 64, Grad norm: 6.109e+00\n",
      "Epoch 9056, Loss: 0.06222974509000778, Neurons: 64, Grad norm: 7.131e+00\n",
      "Epoch 9056, Loss: 0.06222974509000778, Neurons: 64, Grad norm: 7.131e+00\n",
      "Epoch 9057, Loss: 0.062354542315006256, Neurons: 64, Grad norm: 7.971e+00\n",
      "Epoch 9057, Loss: 0.062354542315006256, Neurons: 64, Grad norm: 7.971e+00\n",
      "Epoch 9058, Loss: 0.06246434897184372, Neurons: 64, Grad norm: 8.311e+00\n",
      "Epoch 9058, Loss: 0.06246434897184372, Neurons: 64, Grad norm: 8.311e+00\n",
      "Epoch 9059, Loss: 0.06247063726186752, Neurons: 64, Grad norm: 7.879e+00\n",
      "Epoch 9059, Loss: 0.06247063726186752, Neurons: 64, Grad norm: 7.879e+00\n",
      "Epoch 9060, Loss: 0.06228121742606163, Neurons: 64, Grad norm: 6.465e+00\n",
      "Epoch 9060, Loss: 0.06228121742606163, Neurons: 64, Grad norm: 6.465e+00\n",
      "Epoch 9061, Loss: 0.061892762780189514, Neurons: 64, Grad norm: 4.187e+00\n",
      "Epoch 9061, Loss: 0.061892762780189514, Neurons: 64, Grad norm: 4.187e+00\n",
      "Epoch 9062, Loss: 0.06144140288233757, Neurons: 64, Grad norm: 1.390e+00\n",
      "Epoch 9062, Loss: 0.06144140288233757, Neurons: 64, Grad norm: 1.390e+00\n",
      "Epoch 9063, Loss: 0.06112589314579964, Neurons: 64, Grad norm: 1.362e+00\n",
      "Epoch 9063, Loss: 0.06112589314579964, Neurons: 64, Grad norm: 1.362e+00\n",
      "Epoch 9064, Loss: 0.06104539334774017, Neurons: 64, Grad norm: 3.611e+00\n",
      "Epoch 9064, Loss: 0.06104539334774017, Neurons: 64, Grad norm: 3.611e+00\n",
      "Epoch 9065, Loss: 0.06113447993993759, Neurons: 64, Grad norm: 4.980e+00\n",
      "Epoch 9065, Loss: 0.06113447993993759, Neurons: 64, Grad norm: 4.980e+00\n",
      "Epoch 9066, Loss: 0.06123168021440506, Neurons: 64, Grad norm: 5.278e+00\n",
      "Epoch 9066, Loss: 0.06123168021440506, Neurons: 64, Grad norm: 5.278e+00\n",
      "Epoch 9067, Loss: 0.06119585409760475, Neurons: 64, Grad norm: 4.475e+00\n",
      "Epoch 9067, Loss: 0.06119585409760475, Neurons: 64, Grad norm: 4.475e+00\n",
      "Epoch 9068, Loss: 0.060997847467660904, Neurons: 64, Grad norm: 2.823e+00\n",
      "Epoch 9068, Loss: 0.060997847467660904, Neurons: 64, Grad norm: 2.823e+00\n",
      "Epoch 9069, Loss: 0.06073480471968651, Neurons: 64, Grad norm: 7.108e-01\n",
      "Epoch 9069, Loss: 0.06073480471968651, Neurons: 64, Grad norm: 7.108e-01\n",
      "Epoch 9070, Loss: 0.060543954372406006, Neurons: 64, Grad norm: 1.350e+00\n",
      "Epoch 9070, Loss: 0.060543954372406006, Neurons: 64, Grad norm: 1.350e+00\n",
      "Epoch 9071, Loss: 0.06048507243394852, Neurons: 64, Grad norm: 2.913e+00\n",
      "Epoch 9071, Loss: 0.06048507243394852, Neurons: 64, Grad norm: 2.913e+00\n",
      "Epoch 9072, Loss: 0.06050564721226692, Neurons: 64, Grad norm: 3.677e+00\n",
      "Epoch 9072, Loss: 0.06050564721226692, Neurons: 64, Grad norm: 3.677e+00\n",
      "Epoch 9073, Loss: 0.0605025440454483, Neurons: 64, Grad norm: 3.568e+00\n",
      "Epoch 9073, Loss: 0.0605025440454483, Neurons: 64, Grad norm: 3.568e+00\n",
      "Epoch 9074, Loss: 0.060409776866436005, Neurons: 64, Grad norm: 2.645e+00\n",
      "Epoch 9074, Loss: 0.060409776866436005, Neurons: 64, Grad norm: 2.645e+00\n",
      "Epoch 9075, Loss: 0.06024545058608055, Neurons: 64, Grad norm: 1.225e+00\n",
      "Epoch 9075, Loss: 0.06024545058608055, Neurons: 64, Grad norm: 1.225e+00\n",
      "Epoch 9076, Loss: 0.060083575546741486, Neurons: 64, Grad norm: 3.629e-01\n",
      "Epoch 9076, Loss: 0.060083575546741486, Neurons: 64, Grad norm: 3.629e-01\n",
      "Epoch 9077, Loss: 0.05998465418815613, Neurons: 64, Grad norm: 1.682e+00\n",
      "Epoch 9077, Loss: 0.05998465418815613, Neurons: 64, Grad norm: 1.682e+00\n",
      "Epoch 9078, Loss: 0.05994682386517525, Neurons: 64, Grad norm: 2.512e+00\n",
      "Epoch 9078, Loss: 0.05994682386517525, Neurons: 64, Grad norm: 2.512e+00\n",
      "Epoch 9079, Loss: 0.05992010235786438, Neurons: 64, Grad norm: 2.680e+00\n",
      "Epoch 9079, Loss: 0.05992010235786438, Neurons: 64, Grad norm: 2.680e+00\n",
      "Epoch 9080, Loss: 0.05985526740550995, Neurons: 64, Grad norm: 2.229e+00\n",
      "Epoch 9080, Loss: 0.05985526740550995, Neurons: 64, Grad norm: 2.229e+00\n",
      "Epoch 9081, Loss: 0.059743624180555344, Neurons: 64, Grad norm: 1.306e+00\n",
      "Epoch 9081, Loss: 0.059743624180555344, Neurons: 64, Grad norm: 1.306e+00\n",
      "Epoch 9082, Loss: 0.059617042541503906, Neurons: 64, Grad norm: 2.012e-01\n",
      "Epoch 9082, Loss: 0.059617042541503906, Neurons: 64, Grad norm: 2.012e-01\n",
      "Epoch 9083, Loss: 0.05951407551765442, Neurons: 64, Grad norm: 8.770e-01\n",
      "Epoch 9083, Loss: 0.05951407551765442, Neurons: 64, Grad norm: 8.770e-01\n",
      "Epoch 9084, Loss: 0.059447214007377625, Neurons: 64, Grad norm: 1.618e+00\n",
      "Epoch 9084, Loss: 0.059447214007377625, Neurons: 64, Grad norm: 1.618e+00\n",
      "Epoch 9085, Loss: 0.059397414326667786, Neurons: 64, Grad norm: 1.936e+00\n",
      "Epoch 9085, Loss: 0.059397414326667786, Neurons: 64, Grad norm: 1.936e+00\n",
      "Epoch 9086, Loss: 0.05933673307299614, Neurons: 64, Grad norm: 1.776e+00\n",
      "Epoch 9086, Loss: 0.05933673307299614, Neurons: 64, Grad norm: 1.776e+00\n",
      "Epoch 9087, Loss: 0.05925087258219719, Neurons: 64, Grad norm: 1.254e+00\n",
      "Epoch 9087, Loss: 0.05925087258219719, Neurons: 64, Grad norm: 1.254e+00\n",
      "Epoch 9088, Loss: 0.05914941057562828, Neurons: 64, Grad norm: 4.960e-01\n",
      "Epoch 9088, Loss: 0.05914941057562828, Neurons: 64, Grad norm: 4.960e-01\n",
      "Epoch 9089, Loss: 0.05905270576477051, Neurons: 64, Grad norm: 2.935e-01\n",
      "Epoch 9089, Loss: 0.05905270576477051, Neurons: 64, Grad norm: 2.935e-01\n",
      "Epoch 9090, Loss: 0.058973196893930435, Neurons: 64, Grad norm: 9.356e-01\n",
      "Epoch 9090, Loss: 0.058973196893930435, Neurons: 64, Grad norm: 9.356e-01\n",
      "Epoch 9091, Loss: 0.058907926082611084, Neurons: 64, Grad norm: 1.305e+00\n",
      "Epoch 9091, Loss: 0.058907926082611084, Neurons: 64, Grad norm: 1.305e+00\n",
      "Epoch 9092, Loss: 0.05884411931037903, Neurons: 64, Grad norm: 1.374e+00\n",
      "Epoch 9092, Loss: 0.05884411931037903, Neurons: 64, Grad norm: 1.374e+00\n",
      "Epoch 9093, Loss: 0.05877005681395531, Neurons: 64, Grad norm: 1.131e+00\n",
      "Epoch 9093, Loss: 0.05877005681395531, Neurons: 64, Grad norm: 1.131e+00\n",
      "Epoch 9094, Loss: 0.05868465080857277, Neurons: 64, Grad norm: 6.860e-01\n",
      "Epoch 9094, Loss: 0.05868465080857277, Neurons: 64, Grad norm: 6.860e-01\n",
      "Epoch 9095, Loss: 0.058596011251211166, Neurons: 64, Grad norm: 1.434e-01\n",
      "Epoch 9095, Loss: 0.058596011251211166, Neurons: 64, Grad norm: 1.434e-01\n",
      "Epoch 9096, Loss: 0.05851301923394203, Neurons: 64, Grad norm: 3.985e-01\n",
      "Epoch 9096, Loss: 0.05851301923394203, Neurons: 64, Grad norm: 3.985e-01\n",
      "Epoch 9097, Loss: 0.058439113199710846, Neurons: 64, Grad norm: 7.961e-01\n",
      "Epoch 9097, Loss: 0.058439113199710846, Neurons: 64, Grad norm: 7.961e-01\n",
      "Epoch 9098, Loss: 0.05837002769112587, Neurons: 64, Grad norm: 9.776e-01\n",
      "Epoch 9098, Loss: 0.05837002769112587, Neurons: 64, Grad norm: 9.776e-01\n",
      "Epoch 9099, Loss: 0.058299217373132706, Neurons: 64, Grad norm: 9.583e-01\n",
      "Epoch 9099, Loss: 0.058299217373132706, Neurons: 64, Grad norm: 9.583e-01\n",
      "Epoch 9099, Test loss: 0.03840664401650429\n",
      "Epoch 9099, Test loss: 0.03840664401650429\n",
      "Epoch 9100, Loss: 0.05822281911969185, Neurons: 64, Grad norm: 7.399e-01\n",
      "Epoch 9100, Loss: 0.05822281911969185, Neurons: 64, Grad norm: 7.399e-01\n",
      "Epoch 9101, Loss: 0.05814189091324806, Neurons: 64, Grad norm: 4.139e-01\n",
      "Epoch 9101, Loss: 0.05814189091324806, Neurons: 64, Grad norm: 4.139e-01\n",
      "Epoch 9102, Loss: 0.0580606609582901, Neurons: 64, Grad norm: 7.277e-02\n",
      "Epoch 9102, Loss: 0.0580606609582901, Neurons: 64, Grad norm: 7.277e-02\n",
      "Epoch 9103, Loss: 0.05798285827040672, Neurons: 64, Grad norm: 3.281e-01\n",
      "Epoch 9103, Loss: 0.05798285827040672, Neurons: 64, Grad norm: 3.281e-01\n",
      "Epoch 9104, Loss: 0.05790930613875389, Neurons: 64, Grad norm: 5.835e-01\n",
      "Epoch 9104, Loss: 0.05790930613875389, Neurons: 64, Grad norm: 5.835e-01\n",
      "Epoch 9105, Loss: 0.057837486267089844, Neurons: 64, Grad norm: 6.926e-01\n",
      "Epoch 9105, Loss: 0.057837486267089844, Neurons: 64, Grad norm: 6.926e-01\n",
      "Epoch 9106, Loss: 0.05776483565568924, Neurons: 64, Grad norm: 6.752e-01\n",
      "Epoch 9106, Loss: 0.05776483565568924, Neurons: 64, Grad norm: 6.752e-01\n",
      "Epoch 9107, Loss: 0.057689469307661057, Neurons: 64, Grad norm: 5.257e-01\n",
      "Epoch 9107, Loss: 0.057689469307661057, Neurons: 64, Grad norm: 5.257e-01\n",
      "Epoch 9108, Loss: 0.05761212855577469, Neurons: 64, Grad norm: 3.143e-01\n",
      "Epoch 9108, Loss: 0.05761212855577469, Neurons: 64, Grad norm: 3.143e-01\n",
      "Epoch 9109, Loss: 0.057534705847501755, Neurons: 64, Grad norm: 8.813e-02\n",
      "Epoch 9109, Loss: 0.057534705847501755, Neurons: 64, Grad norm: 8.813e-02\n",
      "Epoch 9110, Loss: 0.05745912343263626, Neurons: 64, Grad norm: 1.955e-01\n",
      "Epoch 9110, Loss: 0.05745912343263626, Neurons: 64, Grad norm: 1.955e-01\n",
      "Epoch 9111, Loss: 0.0573851577937603, Neurons: 64, Grad norm: 3.730e-01\n",
      "Epoch 9111, Loss: 0.0573851577937603, Neurons: 64, Grad norm: 3.730e-01\n",
      "Epoch 9112, Loss: 0.057312287390232086, Neurons: 64, Grad norm: 4.595e-01\n",
      "Epoch 9112, Loss: 0.057312287390232086, Neurons: 64, Grad norm: 4.595e-01\n",
      "Epoch 9113, Loss: 0.05723942816257477, Neurons: 64, Grad norm: 4.742e-01\n",
      "Epoch 9113, Loss: 0.05723942816257477, Neurons: 64, Grad norm: 4.742e-01\n",
      "Epoch 9114, Loss: 0.05716546252369881, Neurons: 64, Grad norm: 3.961e-01\n",
      "Epoch 9114, Loss: 0.05716546252369881, Neurons: 64, Grad norm: 3.961e-01\n",
      "Epoch 9115, Loss: 0.05709066987037659, Neurons: 64, Grad norm: 2.697e-01\n",
      "Epoch 9115, Loss: 0.05709066987037659, Neurons: 64, Grad norm: 2.697e-01\n",
      "Epoch 9116, Loss: 0.0570155531167984, Neurons: 64, Grad norm: 1.114e-01\n",
      "Epoch 9116, Loss: 0.0570155531167984, Neurons: 64, Grad norm: 1.114e-01\n",
      "Epoch 9117, Loss: 0.056941088289022446, Neurons: 64, Grad norm: 9.770e-02\n",
      "Epoch 9117, Loss: 0.056941088289022446, Neurons: 64, Grad norm: 9.770e-02\n",
      "Epoch 9118, Loss: 0.05686742067337036, Neurons: 64, Grad norm: 2.229e-01\n",
      "Epoch 9118, Loss: 0.05686742067337036, Neurons: 64, Grad norm: 2.229e-01\n",
      "Epoch 9119, Loss: 0.056794673204422, Neurons: 64, Grad norm: 3.011e-01\n",
      "Epoch 9119, Loss: 0.056794673204422, Neurons: 64, Grad norm: 3.011e-01\n",
      "Epoch 9120, Loss: 0.056722093373537064, Neurons: 64, Grad norm: 3.398e-01\n",
      "Epoch 9120, Loss: 0.056722093373537064, Neurons: 64, Grad norm: 3.398e-01\n",
      "Epoch 9121, Loss: 0.05664905905723572, Neurons: 64, Grad norm: 3.123e-01\n",
      "Epoch 9121, Loss: 0.05664905905723572, Neurons: 64, Grad norm: 3.123e-01\n",
      "Epoch 9122, Loss: 0.05657583102583885, Neurons: 64, Grad norm: 2.550e-01\n",
      "Epoch 9122, Loss: 0.05657583102583885, Neurons: 64, Grad norm: 2.550e-01\n",
      "Epoch 9123, Loss: 0.056502435356378555, Neurons: 64, Grad norm: 1.634e-01\n",
      "Epoch 9123, Loss: 0.056502435356378555, Neurons: 64, Grad norm: 1.634e-01\n",
      "Epoch 9124, Loss: 0.05642910301685333, Neurons: 64, Grad norm: 8.950e-02\n",
      "Epoch 9124, Loss: 0.05642910301685333, Neurons: 64, Grad norm: 8.950e-02\n",
      "Epoch 9125, Loss: 0.05635608360171318, Neurons: 64, Grad norm: 9.447e-02\n",
      "Epoch 9125, Loss: 0.05635608360171318, Neurons: 64, Grad norm: 9.447e-02\n",
      "Epoch 9126, Loss: 0.05628356710076332, Neurons: 64, Grad norm: 1.500e-01\n",
      "Epoch 9126, Loss: 0.05628356710076332, Neurons: 64, Grad norm: 1.500e-01\n",
      "Epoch 9127, Loss: 0.05621132627129555, Neurons: 64, Grad norm: 2.062e-01\n",
      "Epoch 9127, Loss: 0.05621132627129555, Neurons: 64, Grad norm: 2.062e-01\n",
      "Epoch 9128, Loss: 0.05613912642002106, Neurons: 64, Grad norm: 2.224e-01\n",
      "Epoch 9128, Loss: 0.05613912642002106, Neurons: 64, Grad norm: 2.224e-01\n",
      "Epoch 9129, Loss: 0.05606716498732567, Neurons: 64, Grad norm: 2.219e-01\n",
      "Epoch 9129, Loss: 0.05606716498732567, Neurons: 64, Grad norm: 2.219e-01\n",
      "Epoch 9130, Loss: 0.055995095521211624, Neurons: 64, Grad norm: 1.858e-01\n",
      "Epoch 9130, Loss: 0.055995095521211624, Neurons: 64, Grad norm: 1.858e-01\n",
      "Epoch 9131, Loss: 0.05592276155948639, Neurons: 64, Grad norm: 1.519e-01\n",
      "Epoch 9131, Loss: 0.05592276155948639, Neurons: 64, Grad norm: 1.519e-01\n",
      "Epoch 9132, Loss: 0.055850785225629807, Neurons: 64, Grad norm: 1.026e-01\n",
      "Epoch 9132, Loss: 0.055850785225629807, Neurons: 64, Grad norm: 1.026e-01\n",
      "Epoch 9133, Loss: 0.05577890947461128, Neurons: 64, Grad norm: 8.091e-02\n",
      "Epoch 9133, Loss: 0.05577890947461128, Neurons: 64, Grad norm: 8.091e-02\n",
      "Epoch 9134, Loss: 0.055707283318042755, Neurons: 64, Grad norm: 9.761e-02\n",
      "Epoch 9134, Loss: 0.055707283318042755, Neurons: 64, Grad norm: 9.761e-02\n",
      "Epoch 9135, Loss: 0.055635783821344376, Neurons: 64, Grad norm: 1.220e-01\n",
      "Epoch 9135, Loss: 0.055635783821344376, Neurons: 64, Grad norm: 1.220e-01\n",
      "Epoch 9136, Loss: 0.05556434020400047, Neurons: 64, Grad norm: 1.512e-01\n",
      "Epoch 9136, Loss: 0.05556434020400047, Neurons: 64, Grad norm: 1.512e-01\n",
      "Epoch 9137, Loss: 0.05549297481775284, Neurons: 64, Grad norm: 1.559e-01\n",
      "Epoch 9137, Loss: 0.05549297481775284, Neurons: 64, Grad norm: 1.559e-01\n",
      "Epoch 9138, Loss: 0.05542181059718132, Neurons: 64, Grad norm: 1.545e-01\n",
      "Epoch 9138, Loss: 0.05542181059718132, Neurons: 64, Grad norm: 1.545e-01\n",
      "Epoch 9139, Loss: 0.055350907146930695, Neurons: 64, Grad norm: 1.260e-01\n",
      "Epoch 9139, Loss: 0.055350907146930695, Neurons: 64, Grad norm: 1.260e-01\n",
      "Epoch 9140, Loss: 0.05527980998158455, Neurons: 64, Grad norm: 1.052e-01\n",
      "Epoch 9140, Loss: 0.05527980998158455, Neurons: 64, Grad norm: 1.052e-01\n",
      "Epoch 9141, Loss: 0.05520891770720482, Neurons: 64, Grad norm: 7.592e-02\n",
      "Epoch 9141, Loss: 0.05520891770720482, Neurons: 64, Grad norm: 7.592e-02\n",
      "Epoch 9142, Loss: 0.05513809248805046, Neurons: 64, Grad norm: 6.832e-02\n",
      "Epoch 9142, Loss: 0.05513809248805046, Neurons: 64, Grad norm: 6.832e-02\n",
      "Epoch 9143, Loss: 0.05506739392876625, Neurons: 64, Grad norm: 8.348e-02\n",
      "Epoch 9143, Loss: 0.05506739392876625, Neurons: 64, Grad norm: 8.348e-02\n",
      "Epoch 9144, Loss: 0.054996952414512634, Neurons: 64, Grad norm: 1.010e-01\n",
      "Epoch 9144, Loss: 0.054996952414512634, Neurons: 64, Grad norm: 1.010e-01\n",
      "Epoch 9145, Loss: 0.05492649972438812, Neurons: 64, Grad norm: 1.256e-01\n",
      "Epoch 9145, Loss: 0.05492649972438812, Neurons: 64, Grad norm: 1.256e-01\n",
      "Epoch 9146, Loss: 0.05485641956329346, Neurons: 64, Grad norm: 1.277e-01\n",
      "Epoch 9146, Loss: 0.05485641956329346, Neurons: 64, Grad norm: 1.277e-01\n",
      "Epoch 9147, Loss: 0.05478624254465103, Neurons: 64, Grad norm: 1.308e-01\n",
      "Epoch 9147, Loss: 0.05478624254465103, Neurons: 64, Grad norm: 1.308e-01\n",
      "Epoch 9148, Loss: 0.05471615865826607, Neurons: 64, Grad norm: 1.159e-01\n",
      "Epoch 9148, Loss: 0.05471615865826607, Neurons: 64, Grad norm: 1.159e-01\n",
      "Epoch 9149, Loss: 0.05464625731110573, Neurons: 64, Grad norm: 1.059e-01\n",
      "Epoch 9149, Loss: 0.05464625731110573, Neurons: 64, Grad norm: 1.059e-01\n",
      "Epoch 9150, Loss: 0.05457642674446106, Neurons: 64, Grad norm: 8.241e-02\n",
      "Epoch 9150, Loss: 0.05457642674446106, Neurons: 64, Grad norm: 8.241e-02\n",
      "Epoch 9151, Loss: 0.0545065738260746, Neurons: 64, Grad norm: 7.153e-02\n",
      "Epoch 9151, Loss: 0.0545065738260746, Neurons: 64, Grad norm: 7.153e-02\n",
      "Epoch 9152, Loss: 0.05443708226084709, Neurons: 64, Grad norm: 6.697e-02\n",
      "Epoch 9152, Loss: 0.05443708226084709, Neurons: 64, Grad norm: 6.697e-02\n",
      "Epoch 9153, Loss: 0.05436753109097481, Neurons: 64, Grad norm: 7.013e-02\n",
      "Epoch 9153, Loss: 0.05436753109097481, Neurons: 64, Grad norm: 7.013e-02\n",
      "Epoch 9154, Loss: 0.054298218339681625, Neurons: 64, Grad norm: 8.103e-02\n",
      "Epoch 9154, Loss: 0.054298218339681625, Neurons: 64, Grad norm: 8.103e-02\n",
      "Epoch 9155, Loss: 0.054228879511356354, Neurons: 64, Grad norm: 8.413e-02\n",
      "Epoch 9155, Loss: 0.054228879511356354, Neurons: 64, Grad norm: 8.413e-02\n",
      "Epoch 9156, Loss: 0.05415985360741615, Neurons: 64, Grad norm: 9.302e-02\n",
      "Epoch 9156, Loss: 0.05415985360741615, Neurons: 64, Grad norm: 9.302e-02\n",
      "Epoch 9157, Loss: 0.05409080907702446, Neurons: 64, Grad norm: 9.106e-02\n",
      "Epoch 9157, Loss: 0.05409080907702446, Neurons: 64, Grad norm: 9.106e-02\n",
      "Epoch 9158, Loss: 0.054021745920181274, Neurons: 64, Grad norm: 9.444e-02\n",
      "Epoch 9158, Loss: 0.054021745920181274, Neurons: 64, Grad norm: 9.444e-02\n",
      "Epoch 9159, Loss: 0.05395307019352913, Neurons: 64, Grad norm: 8.655e-02\n",
      "Epoch 9159, Loss: 0.05395307019352913, Neurons: 64, Grad norm: 8.655e-02\n",
      "Epoch 9160, Loss: 0.05388417840003967, Neurons: 64, Grad norm: 8.369e-02\n",
      "Epoch 9160, Loss: 0.05388417840003967, Neurons: 64, Grad norm: 8.369e-02\n",
      "Epoch 9161, Loss: 0.05381566658616066, Neurons: 64, Grad norm: 7.316e-02\n",
      "Epoch 9161, Loss: 0.05381566658616066, Neurons: 64, Grad norm: 7.316e-02\n",
      "Epoch 9162, Loss: 0.05374718829989433, Neurons: 64, Grad norm: 7.046e-02\n",
      "Epoch 9162, Loss: 0.05374718829989433, Neurons: 64, Grad norm: 7.046e-02\n",
      "Epoch 9163, Loss: 0.05367869883775711, Neurons: 64, Grad norm: 6.853e-02\n",
      "Epoch 9163, Loss: 0.05367869883775711, Neurons: 64, Grad norm: 6.853e-02\n",
      "Epoch 9164, Loss: 0.053610507398843765, Neurons: 64, Grad norm: 7.090e-02\n",
      "Epoch 9164, Loss: 0.053610507398843765, Neurons: 64, Grad norm: 7.090e-02\n",
      "Epoch 9165, Loss: 0.05354243144392967, Neurons: 64, Grad norm: 7.364e-02\n",
      "Epoch 9165, Loss: 0.05354243144392967, Neurons: 64, Grad norm: 7.364e-02\n",
      "Epoch 9166, Loss: 0.05347452312707901, Neurons: 64, Grad norm: 7.187e-02\n",
      "Epoch 9166, Loss: 0.05347452312707901, Neurons: 64, Grad norm: 7.187e-02\n",
      "Epoch 9167, Loss: 0.053406283259391785, Neurons: 64, Grad norm: 7.573e-02\n",
      "Epoch 9167, Loss: 0.053406283259391785, Neurons: 64, Grad norm: 7.573e-02\n",
      "Epoch 9168, Loss: 0.05333876982331276, Neurons: 64, Grad norm: 7.285e-02\n",
      "Epoch 9168, Loss: 0.05333876982331276, Neurons: 64, Grad norm: 7.285e-02\n",
      "Epoch 9169, Loss: 0.053270675241947174, Neurons: 64, Grad norm: 7.553e-02\n",
      "Epoch 9169, Loss: 0.053270675241947174, Neurons: 64, Grad norm: 7.553e-02\n",
      "Epoch 9170, Loss: 0.05320302024483681, Neurons: 64, Grad norm: 7.123e-02\n",
      "Epoch 9170, Loss: 0.05320302024483681, Neurons: 64, Grad norm: 7.123e-02\n",
      "Epoch 9171, Loss: 0.05313605070114136, Neurons: 64, Grad norm: 7.462e-02\n",
      "Epoch 9171, Loss: 0.05313605070114136, Neurons: 64, Grad norm: 7.462e-02\n",
      "Epoch 9172, Loss: 0.05306844785809517, Neurons: 64, Grad norm: 7.129e-02\n",
      "Epoch 9172, Loss: 0.05306844785809517, Neurons: 64, Grad norm: 7.129e-02\n",
      "Epoch 9173, Loss: 0.05300096422433853, Neurons: 64, Grad norm: 7.201e-02\n",
      "Epoch 9173, Loss: 0.05300096422433853, Neurons: 64, Grad norm: 7.201e-02\n",
      "Epoch 9174, Loss: 0.052933625876903534, Neurons: 64, Grad norm: 7.095e-02\n",
      "Epoch 9174, Loss: 0.052933625876903534, Neurons: 64, Grad norm: 7.095e-02\n",
      "Epoch 9175, Loss: 0.05286632478237152, Neurons: 64, Grad norm: 7.015e-02\n",
      "Epoch 9175, Loss: 0.05286632478237152, Neurons: 64, Grad norm: 7.015e-02\n",
      "Epoch 9176, Loss: 0.052799273282289505, Neurons: 64, Grad norm: 6.749e-02\n",
      "Epoch 9176, Loss: 0.052799273282289505, Neurons: 64, Grad norm: 6.749e-02\n",
      "Epoch 9177, Loss: 0.052732598036527634, Neurons: 64, Grad norm: 6.970e-02\n",
      "Epoch 9177, Loss: 0.052732598036527634, Neurons: 64, Grad norm: 6.970e-02\n",
      "Epoch 9178, Loss: 0.05266605690121651, Neurons: 64, Grad norm: 7.132e-02\n",
      "Epoch 9178, Loss: 0.05266605690121651, Neurons: 64, Grad norm: 7.132e-02\n",
      "Epoch 9179, Loss: 0.052599117159843445, Neurons: 64, Grad norm: 7.223e-02\n",
      "Epoch 9179, Loss: 0.052599117159843445, Neurons: 64, Grad norm: 7.223e-02\n",
      "Epoch 9180, Loss: 0.052532874047756195, Neurons: 64, Grad norm: 7.133e-02\n",
      "Epoch 9180, Loss: 0.052532874047756195, Neurons: 64, Grad norm: 7.133e-02\n",
      "Epoch 9181, Loss: 0.05246637389063835, Neurons: 64, Grad norm: 6.971e-02\n",
      "Epoch 9181, Loss: 0.05246637389063835, Neurons: 64, Grad norm: 6.971e-02\n",
      "Epoch 9182, Loss: 0.052400026470422745, Neurons: 64, Grad norm: 6.897e-02\n",
      "Epoch 9182, Loss: 0.052400026470422745, Neurons: 64, Grad norm: 6.897e-02\n",
      "Epoch 9183, Loss: 0.05233382433652878, Neurons: 64, Grad norm: 6.845e-02\n",
      "Epoch 9183, Loss: 0.05233382433652878, Neurons: 64, Grad norm: 6.845e-02\n",
      "Epoch 9184, Loss: 0.052267562597990036, Neurons: 64, Grad norm: 7.192e-02\n",
      "Epoch 9184, Loss: 0.052267562597990036, Neurons: 64, Grad norm: 7.192e-02\n",
      "Epoch 9185, Loss: 0.052201367914676666, Neurons: 64, Grad norm: 7.080e-02\n",
      "Epoch 9185, Loss: 0.052201367914676666, Neurons: 64, Grad norm: 7.080e-02\n",
      "Epoch 9186, Loss: 0.05213562399148941, Neurons: 64, Grad norm: 7.477e-02\n",
      "Epoch 9186, Loss: 0.05213562399148941, Neurons: 64, Grad norm: 7.477e-02\n",
      "Epoch 9187, Loss: 0.0520697645843029, Neurons: 64, Grad norm: 7.271e-02\n",
      "Epoch 9187, Loss: 0.0520697645843029, Neurons: 64, Grad norm: 7.271e-02\n",
      "Epoch 9188, Loss: 0.05200410634279251, Neurons: 64, Grad norm: 7.578e-02\n",
      "Epoch 9188, Loss: 0.05200410634279251, Neurons: 64, Grad norm: 7.578e-02\n",
      "Epoch 9189, Loss: 0.051938485354185104, Neurons: 64, Grad norm: 7.502e-02\n",
      "Epoch 9189, Loss: 0.051938485354185104, Neurons: 64, Grad norm: 7.502e-02\n",
      "Epoch 9190, Loss: 0.051873061805963516, Neurons: 64, Grad norm: 7.640e-02\n",
      "Epoch 9190, Loss: 0.051873061805963516, Neurons: 64, Grad norm: 7.640e-02\n",
      "Epoch 9191, Loss: 0.0518074594438076, Neurons: 64, Grad norm: 7.729e-02\n",
      "Epoch 9191, Loss: 0.0518074594438076, Neurons: 64, Grad norm: 7.729e-02\n",
      "Epoch 9192, Loss: 0.05174229294061661, Neurons: 64, Grad norm: 8.374e-02\n",
      "Epoch 9192, Loss: 0.05174229294061661, Neurons: 64, Grad norm: 8.374e-02\n",
      "Epoch 9193, Loss: 0.05167717859148979, Neurons: 64, Grad norm: 8.534e-02\n",
      "Epoch 9193, Loss: 0.05167717859148979, Neurons: 64, Grad norm: 8.534e-02\n",
      "Epoch 9194, Loss: 0.051612138748168945, Neurons: 64, Grad norm: 9.508e-02\n",
      "Epoch 9194, Loss: 0.051612138748168945, Neurons: 64, Grad norm: 9.508e-02\n",
      "Epoch 9195, Loss: 0.051547303795814514, Neurons: 64, Grad norm: 9.545e-02\n",
      "Epoch 9195, Loss: 0.051547303795814514, Neurons: 64, Grad norm: 9.545e-02\n",
      "Epoch 9196, Loss: 0.05148223415017128, Neurons: 64, Grad norm: 9.946e-02\n",
      "Epoch 9196, Loss: 0.05148223415017128, Neurons: 64, Grad norm: 9.946e-02\n",
      "Epoch 9197, Loss: 0.051417626440525055, Neurons: 64, Grad norm: 1.061e-01\n",
      "Epoch 9197, Loss: 0.051417626440525055, Neurons: 64, Grad norm: 1.061e-01\n",
      "Epoch 9198, Loss: 0.05135272815823555, Neurons: 64, Grad norm: 1.209e-01\n",
      "Epoch 9198, Loss: 0.05135272815823555, Neurons: 64, Grad norm: 1.209e-01\n",
      "Epoch 9199, Loss: 0.05128815025091171, Neurons: 64, Grad norm: 1.298e-01\n",
      "Epoch 9199, Loss: 0.05128815025091171, Neurons: 64, Grad norm: 1.298e-01\n",
      "Epoch 9199, Test loss: 0.0335259884595871\n",
      "Epoch 9199, Test loss: 0.0335259884595871\n",
      "Epoch 9200, Loss: 0.051223840564489365, Neurons: 64, Grad norm: 1.504e-01\n",
      "Epoch 9200, Loss: 0.051223840564489365, Neurons: 64, Grad norm: 1.504e-01\n",
      "Epoch 9201, Loss: 0.05115943029522896, Neurons: 64, Grad norm: 1.648e-01\n",
      "Epoch 9201, Loss: 0.05115943029522896, Neurons: 64, Grad norm: 1.648e-01\n",
      "Epoch 9202, Loss: 0.05109531059861183, Neurons: 64, Grad norm: 1.973e-01\n",
      "Epoch 9202, Loss: 0.05109531059861183, Neurons: 64, Grad norm: 1.973e-01\n",
      "Epoch 9203, Loss: 0.05103129893541336, Neurons: 64, Grad norm: 2.140e-01\n",
      "Epoch 9203, Loss: 0.05103129893541336, Neurons: 64, Grad norm: 2.140e-01\n",
      "Epoch 9204, Loss: 0.05096723511815071, Neurons: 64, Grad norm: 2.471e-01\n",
      "Epoch 9204, Loss: 0.05096723511815071, Neurons: 64, Grad norm: 2.471e-01\n",
      "Epoch 9205, Loss: 0.050903622061014175, Neurons: 64, Grad norm: 2.822e-01\n",
      "Epoch 9205, Loss: 0.050903622061014175, Neurons: 64, Grad norm: 2.822e-01\n",
      "Epoch 9206, Loss: 0.05083978548645973, Neurons: 64, Grad norm: 3.328e-01\n",
      "Epoch 9206, Loss: 0.05083978548645973, Neurons: 64, Grad norm: 3.328e-01\n",
      "Epoch 9207, Loss: 0.050776466727256775, Neurons: 64, Grad norm: 3.795e-01\n",
      "Epoch 9207, Loss: 0.050776466727256775, Neurons: 64, Grad norm: 3.795e-01\n",
      "Epoch 9208, Loss: 0.05071359500288963, Neurons: 64, Grad norm: 4.531e-01\n",
      "Epoch 9208, Loss: 0.05071359500288963, Neurons: 64, Grad norm: 4.531e-01\n",
      "Epoch 9209, Loss: 0.05065078288316727, Neurons: 64, Grad norm: 5.270e-01\n",
      "Epoch 9209, Loss: 0.05065078288316727, Neurons: 64, Grad norm: 5.270e-01\n",
      "Epoch 9210, Loss: 0.05058832839131355, Neurons: 64, Grad norm: 6.284e-01\n",
      "Epoch 9210, Loss: 0.05058832839131355, Neurons: 64, Grad norm: 6.284e-01\n",
      "Epoch 9211, Loss: 0.05052681267261505, Neurons: 64, Grad norm: 7.397e-01\n",
      "Epoch 9211, Loss: 0.05052681267261505, Neurons: 64, Grad norm: 7.397e-01\n",
      "Epoch 9212, Loss: 0.05046578496694565, Neurons: 64, Grad norm: 8.856e-01\n",
      "Epoch 9212, Loss: 0.05046578496694565, Neurons: 64, Grad norm: 8.856e-01\n",
      "Epoch 9213, Loss: 0.050406087189912796, Neurons: 64, Grad norm: 1.057e+00\n",
      "Epoch 9213, Loss: 0.050406087189912796, Neurons: 64, Grad norm: 1.057e+00\n",
      "Epoch 9214, Loss: 0.050348177552223206, Neurons: 64, Grad norm: 1.279e+00\n",
      "Epoch 9214, Loss: 0.050348177552223206, Neurons: 64, Grad norm: 1.279e+00\n",
      "Epoch 9215, Loss: 0.05029258504509926, Neurons: 64, Grad norm: 1.529e+00\n",
      "Epoch 9215, Loss: 0.05029258504509926, Neurons: 64, Grad norm: 1.529e+00\n",
      "Epoch 9216, Loss: 0.05024082958698273, Neurons: 64, Grad norm: 1.857e+00\n",
      "Epoch 9216, Loss: 0.05024082958698273, Neurons: 64, Grad norm: 1.857e+00\n",
      "Epoch 9217, Loss: 0.05019450560212135, Neurons: 64, Grad norm: 2.248e+00\n",
      "Epoch 9217, Loss: 0.05019450560212135, Neurons: 64, Grad norm: 2.248e+00\n",
      "Epoch 9218, Loss: 0.050156429409980774, Neurons: 64, Grad norm: 2.734e+00\n",
      "Epoch 9218, Loss: 0.050156429409980774, Neurons: 64, Grad norm: 2.734e+00\n",
      "Epoch 9219, Loss: 0.05013079196214676, Neurons: 64, Grad norm: 3.323e+00\n",
      "Epoch 9219, Loss: 0.05013079196214676, Neurons: 64, Grad norm: 3.323e+00\n",
      "Epoch 9220, Loss: 0.0501229502260685, Neurons: 64, Grad norm: 4.035e+00\n",
      "Epoch 9220, Loss: 0.0501229502260685, Neurons: 64, Grad norm: 4.035e+00\n",
      "Epoch 9221, Loss: 0.050139863044023514, Neurons: 64, Grad norm: 4.847e+00\n",
      "Epoch 9221, Loss: 0.050139863044023514, Neurons: 64, Grad norm: 4.847e+00\n",
      "Epoch 9222, Loss: 0.0501888245344162, Neurons: 64, Grad norm: 5.763e+00\n",
      "Epoch 9222, Loss: 0.0501888245344162, Neurons: 64, Grad norm: 5.763e+00\n",
      "Epoch 9223, Loss: 0.05027273669838905, Neurons: 64, Grad norm: 6.669e+00\n",
      "Epoch 9223, Loss: 0.05027273669838905, Neurons: 64, Grad norm: 6.669e+00\n",
      "Epoch 9224, Loss: 0.05038382112979889, Neurons: 64, Grad norm: 7.458e+00\n",
      "Epoch 9224, Loss: 0.05038382112979889, Neurons: 64, Grad norm: 7.458e+00\n",
      "Epoch 9225, Loss: 0.05049143359065056, Neurons: 64, Grad norm: 7.913e+00\n",
      "Epoch 9225, Loss: 0.05049143359065056, Neurons: 64, Grad norm: 7.913e+00\n",
      "Epoch 9226, Loss: 0.0505366325378418, Neurons: 64, Grad norm: 7.800e+00\n",
      "Epoch 9226, Loss: 0.0505366325378418, Neurons: 64, Grad norm: 7.800e+00\n",
      "Epoch 9227, Loss: 0.05044516548514366, Neurons: 64, Grad norm: 6.904e+00\n",
      "Epoch 9227, Loss: 0.05044516548514366, Neurons: 64, Grad norm: 6.904e+00\n",
      "Epoch 9228, Loss: 0.050183869898319244, Neurons: 64, Grad norm: 5.229e+00\n",
      "Epoch 9228, Loss: 0.050183869898319244, Neurons: 64, Grad norm: 5.229e+00\n",
      "Epoch 9229, Loss: 0.04981154948472977, Neurons: 64, Grad norm: 2.952e+00\n",
      "Epoch 9229, Loss: 0.04981154948472977, Neurons: 64, Grad norm: 2.952e+00\n",
      "Epoch 9230, Loss: 0.04946913197636604, Neurons: 64, Grad norm: 4.916e-01\n",
      "Epoch 9230, Loss: 0.04946913197636604, Neurons: 64, Grad norm: 4.916e-01\n",
      "Epoch 9231, Loss: 0.049281761050224304, Neurons: 64, Grad norm: 1.874e+00\n",
      "Epoch 9231, Loss: 0.049281761050224304, Neurons: 64, Grad norm: 1.874e+00\n",
      "Epoch 9232, Loss: 0.04927373677492142, Neurons: 64, Grad norm: 3.664e+00\n",
      "Epoch 9232, Loss: 0.04927373677492142, Neurons: 64, Grad norm: 3.664e+00\n",
      "Epoch 9233, Loss: 0.049365703016519547, Neurons: 64, Grad norm: 4.704e+00\n",
      "Epoch 9233, Loss: 0.049365703016519547, Neurons: 64, Grad norm: 4.704e+00\n",
      "Epoch 9234, Loss: 0.049436625093221664, Neurons: 64, Grad norm: 4.857e+00\n",
      "Epoch 9234, Loss: 0.049436625093221664, Neurons: 64, Grad norm: 4.857e+00\n",
      "Epoch 9235, Loss: 0.049396805465221405, Neurons: 64, Grad norm: 4.167e+00\n",
      "Epoch 9235, Loss: 0.049396805465221405, Neurons: 64, Grad norm: 4.167e+00\n",
      "Epoch 9236, Loss: 0.04923750460147858, Neurons: 64, Grad norm: 2.783e+00\n",
      "Epoch 9236, Loss: 0.04923750460147858, Neurons: 64, Grad norm: 2.783e+00\n",
      "Epoch 9237, Loss: 0.04903024807572365, Neurons: 64, Grad norm: 1.044e+00\n",
      "Epoch 9237, Loss: 0.04903024807572365, Neurons: 64, Grad norm: 1.044e+00\n",
      "Epoch 9238, Loss: 0.0488705150783062, Neurons: 64, Grad norm: 7.774e-01\n",
      "Epoch 9238, Loss: 0.0488705150783062, Neurons: 64, Grad norm: 7.774e-01\n",
      "Epoch 9239, Loss: 0.048806946724653244, Neurons: 64, Grad norm: 2.196e+00\n",
      "Epoch 9239, Loss: 0.048806946724653244, Neurons: 64, Grad norm: 2.196e+00\n",
      "Epoch 9240, Loss: 0.04881472885608673, Neurons: 64, Grad norm: 3.091e+00\n",
      "Epoch 9240, Loss: 0.04881472885608673, Neurons: 64, Grad norm: 3.091e+00\n",
      "Epoch 9241, Loss: 0.048826586455106735, Neurons: 64, Grad norm: 3.308e+00\n",
      "Epoch 9241, Loss: 0.048826586455106735, Neurons: 64, Grad norm: 3.308e+00\n",
      "Epoch 9242, Loss: 0.04878615960478783, Neurons: 64, Grad norm: 2.891e+00\n",
      "Epoch 9242, Loss: 0.04878615960478783, Neurons: 64, Grad norm: 2.891e+00\n",
      "Epoch 9243, Loss: 0.04868282750248909, Neurons: 64, Grad norm: 1.953e+00\n",
      "Epoch 9243, Loss: 0.04868282750248909, Neurons: 64, Grad norm: 1.953e+00\n",
      "Epoch 9244, Loss: 0.048552583903074265, Neurons: 64, Grad norm: 7.603e-01\n",
      "Epoch 9244, Loss: 0.048552583903074265, Neurons: 64, Grad norm: 7.603e-01\n",
      "Epoch 9245, Loss: 0.048444636166095734, Neurons: 64, Grad norm: 5.345e-01\n",
      "Epoch 9245, Loss: 0.048444636166095734, Neurons: 64, Grad norm: 5.345e-01\n",
      "Epoch 9246, Loss: 0.04838389530777931, Neurons: 64, Grad norm: 1.502e+00\n",
      "Epoch 9246, Loss: 0.04838389530777931, Neurons: 64, Grad norm: 1.502e+00\n",
      "Epoch 9247, Loss: 0.04835809767246246, Neurons: 64, Grad norm: 2.116e+00\n",
      "Epoch 9247, Loss: 0.04835809767246246, Neurons: 64, Grad norm: 2.116e+00\n",
      "Epoch 9248, Loss: 0.04833342134952545, Neurons: 64, Grad norm: 2.253e+00\n",
      "Epoch 9248, Loss: 0.04833342134952545, Neurons: 64, Grad norm: 2.253e+00\n",
      "Epoch 9249, Loss: 0.04828262701630592, Neurons: 64, Grad norm: 1.954e+00\n",
      "Epoch 9249, Loss: 0.04828262701630592, Neurons: 64, Grad norm: 1.954e+00\n",
      "Epoch 9250, Loss: 0.048201121389865875, Neurons: 64, Grad norm: 1.304e+00\n",
      "Epoch 9250, Loss: 0.048201121389865875, Neurons: 64, Grad norm: 1.304e+00\n",
      "Epoch 9251, Loss: 0.048107605427503586, Neurons: 64, Grad norm: 4.825e-01\n",
      "Epoch 9251, Loss: 0.048107605427503586, Neurons: 64, Grad norm: 4.825e-01\n",
      "Epoch 9252, Loss: 0.048025649040937424, Neurons: 64, Grad norm: 3.861e-01\n",
      "Epoch 9252, Loss: 0.048025649040937424, Neurons: 64, Grad norm: 3.861e-01\n",
      "Epoch 9253, Loss: 0.04796693101525307, Neurons: 64, Grad norm: 1.050e+00\n",
      "Epoch 9253, Loss: 0.04796693101525307, Neurons: 64, Grad norm: 1.050e+00\n",
      "Epoch 9254, Loss: 0.04792500659823418, Neurons: 64, Grad norm: 1.472e+00\n",
      "Epoch 9254, Loss: 0.04792500659823418, Neurons: 64, Grad norm: 1.472e+00\n",
      "Epoch 9255, Loss: 0.04788379743695259, Neurons: 64, Grad norm: 1.566e+00\n",
      "Epoch 9255, Loss: 0.04788379743695259, Neurons: 64, Grad norm: 1.566e+00\n",
      "Epoch 9256, Loss: 0.047829799354076385, Neurons: 64, Grad norm: 1.375e+00\n",
      "Epoch 9256, Loss: 0.047829799354076385, Neurons: 64, Grad norm: 1.375e+00\n",
      "Epoch 9257, Loss: 0.047761354595422745, Neurons: 64, Grad norm: 9.423e-01\n",
      "Epoch 9257, Loss: 0.047761354595422745, Neurons: 64, Grad norm: 9.423e-01\n",
      "Epoch 9258, Loss: 0.04768628254532814, Neurons: 64, Grad norm: 3.931e-01\n",
      "Epoch 9258, Loss: 0.04768628254532814, Neurons: 64, Grad norm: 3.931e-01\n",
      "Epoch 9259, Loss: 0.04761587828397751, Neurons: 64, Grad norm: 2.010e-01\n",
      "Epoch 9259, Loss: 0.04761587828397751, Neurons: 64, Grad norm: 2.010e-01\n",
      "Epoch 9260, Loss: 0.04755641147494316, Neurons: 64, Grad norm: 6.609e-01\n",
      "Epoch 9260, Loss: 0.04755641147494316, Neurons: 64, Grad norm: 6.609e-01\n",
      "Epoch 9261, Loss: 0.04750576987862587, Neurons: 64, Grad norm: 9.748e-01\n",
      "Epoch 9261, Loss: 0.04750576987862587, Neurons: 64, Grad norm: 9.748e-01\n",
      "Epoch 9262, Loss: 0.04745691642165184, Neurons: 64, Grad norm: 1.074e+00\n",
      "Epoch 9262, Loss: 0.04745691642165184, Neurons: 64, Grad norm: 1.074e+00\n",
      "Epoch 9263, Loss: 0.04740298539400101, Neurons: 64, Grad norm: 9.854e-01\n",
      "Epoch 9263, Loss: 0.04740298539400101, Neurons: 64, Grad norm: 9.854e-01\n",
      "Epoch 9264, Loss: 0.04734199866652489, Neurons: 64, Grad norm: 7.292e-01\n",
      "Epoch 9264, Loss: 0.04734199866652489, Neurons: 64, Grad norm: 7.292e-01\n",
      "Epoch 9265, Loss: 0.04727664962410927, Neurons: 64, Grad norm: 3.790e-01\n",
      "Epoch 9265, Loss: 0.04727664962410927, Neurons: 64, Grad norm: 3.790e-01\n",
      "Epoch 9266, Loss: 0.04721207171678543, Neurons: 64, Grad norm: 6.918e-02\n",
      "Epoch 9266, Loss: 0.04721207171678543, Neurons: 64, Grad norm: 6.918e-02\n",
      "Epoch 9267, Loss: 0.04715203493833542, Neurons: 64, Grad norm: 3.602e-01\n",
      "Epoch 9267, Loss: 0.04715203493833542, Neurons: 64, Grad norm: 3.602e-01\n",
      "Epoch 9268, Loss: 0.04709694907069206, Neurons: 64, Grad norm: 6.185e-01\n",
      "Epoch 9268, Loss: 0.04709694907069206, Neurons: 64, Grad norm: 6.185e-01\n",
      "Epoch 9269, Loss: 0.04704375937581062, Neurons: 64, Grad norm: 7.425e-01\n",
      "Epoch 9269, Loss: 0.04704375937581062, Neurons: 64, Grad norm: 7.425e-01\n",
      "Epoch 9270, Loss: 0.046989765018224716, Neurons: 64, Grad norm: 7.445e-01\n",
      "Epoch 9270, Loss: 0.046989765018224716, Neurons: 64, Grad norm: 7.445e-01\n",
      "Epoch 9271, Loss: 0.0469328947365284, Neurons: 64, Grad norm: 6.189e-01\n",
      "Epoch 9271, Loss: 0.0469328947365284, Neurons: 64, Grad norm: 6.189e-01\n",
      "Epoch 9272, Loss: 0.04687334597110748, Neurons: 64, Grad norm: 4.233e-01\n",
      "Epoch 9272, Loss: 0.04687334597110748, Neurons: 64, Grad norm: 4.233e-01\n",
      "Epoch 9273, Loss: 0.0468129888176918, Neurons: 64, Grad norm: 1.786e-01\n",
      "Epoch 9273, Loss: 0.0468129888176918, Neurons: 64, Grad norm: 1.786e-01\n",
      "Epoch 9274, Loss: 0.04675348848104477, Neurons: 64, Grad norm: 1.101e-01\n",
      "Epoch 9274, Loss: 0.04675348848104477, Neurons: 64, Grad norm: 1.101e-01\n",
      "Epoch 9275, Loss: 0.04669620841741562, Neurons: 64, Grad norm: 3.105e-01\n",
      "Epoch 9275, Loss: 0.04669620841741562, Neurons: 64, Grad norm: 3.105e-01\n",
      "Epoch 9276, Loss: 0.046641092747449875, Neurons: 64, Grad norm: 4.502e-01\n",
      "Epoch 9276, Loss: 0.046641092747449875, Neurons: 64, Grad norm: 4.502e-01\n",
      "Epoch 9277, Loss: 0.046586230397224426, Neurons: 64, Grad norm: 5.262e-01\n",
      "Epoch 9277, Loss: 0.046586230397224426, Neurons: 64, Grad norm: 5.262e-01\n",
      "Epoch 9278, Loss: 0.04653117060661316, Neurons: 64, Grad norm: 5.122e-01\n",
      "Epoch 9278, Loss: 0.04653117060661316, Neurons: 64, Grad norm: 5.122e-01\n",
      "Epoch 9279, Loss: 0.046474725008010864, Neurons: 64, Grad norm: 4.399e-01\n",
      "Epoch 9279, Loss: 0.046474725008010864, Neurons: 64, Grad norm: 4.399e-01\n",
      "Epoch 9280, Loss: 0.04641727730631828, Neurons: 64, Grad norm: 3.020e-01\n",
      "Epoch 9280, Loss: 0.04641727730631828, Neurons: 64, Grad norm: 3.020e-01\n",
      "Epoch 9281, Loss: 0.04635978862643242, Neurons: 64, Grad norm: 1.552e-01\n",
      "Epoch 9281, Loss: 0.04635978862643242, Neurons: 64, Grad norm: 1.552e-01\n",
      "Epoch 9282, Loss: 0.04630252346396446, Neurons: 64, Grad norm: 8.175e-02\n",
      "Epoch 9282, Loss: 0.04630252346396446, Neurons: 64, Grad norm: 8.175e-02\n",
      "Epoch 9283, Loss: 0.046246059238910675, Neurons: 64, Grad norm: 1.868e-01\n",
      "Epoch 9283, Loss: 0.046246059238910675, Neurons: 64, Grad norm: 1.868e-01\n",
      "Epoch 9284, Loss: 0.04619079828262329, Neurons: 64, Grad norm: 3.001e-01\n",
      "Epoch 9284, Loss: 0.04619079828262329, Neurons: 64, Grad norm: 3.001e-01\n",
      "Epoch 9285, Loss: 0.046135567128658295, Neurons: 64, Grad norm: 3.626e-01\n",
      "Epoch 9285, Loss: 0.046135567128658295, Neurons: 64, Grad norm: 3.626e-01\n",
      "Epoch 9286, Loss: 0.04608050361275673, Neurons: 64, Grad norm: 3.812e-01\n",
      "Epoch 9286, Loss: 0.04608050361275673, Neurons: 64, Grad norm: 3.812e-01\n",
      "Epoch 9287, Loss: 0.04602515697479248, Neurons: 64, Grad norm: 3.462e-01\n",
      "Epoch 9287, Loss: 0.04602515697479248, Neurons: 64, Grad norm: 3.462e-01\n",
      "Epoch 9288, Loss: 0.045969292521476746, Neurons: 64, Grad norm: 2.868e-01\n",
      "Epoch 9288, Loss: 0.045969292521476746, Neurons: 64, Grad norm: 2.868e-01\n",
      "Epoch 9289, Loss: 0.04591313749551773, Neurons: 64, Grad norm: 1.960e-01\n",
      "Epoch 9289, Loss: 0.04591313749551773, Neurons: 64, Grad norm: 1.960e-01\n",
      "Epoch 9290, Loss: 0.045857302844524384, Neurons: 64, Grad norm: 1.059e-01\n",
      "Epoch 9290, Loss: 0.045857302844524384, Neurons: 64, Grad norm: 1.059e-01\n",
      "Epoch 9291, Loss: 0.045801423490047455, Neurons: 64, Grad norm: 6.493e-02\n",
      "Epoch 9291, Loss: 0.045801423490047455, Neurons: 64, Grad norm: 6.493e-02\n",
      "Epoch 9292, Loss: 0.04574613645672798, Neurons: 64, Grad norm: 1.217e-01\n",
      "Epoch 9292, Loss: 0.04574613645672798, Neurons: 64, Grad norm: 1.217e-01\n",
      "Epoch 9293, Loss: 0.045691195875406265, Neurons: 64, Grad norm: 1.901e-01\n",
      "Epoch 9293, Loss: 0.045691195875406265, Neurons: 64, Grad norm: 1.901e-01\n",
      "Epoch 9294, Loss: 0.04563659057021141, Neurons: 64, Grad norm: 2.299e-01\n",
      "Epoch 9294, Loss: 0.04563659057021141, Neurons: 64, Grad norm: 2.299e-01\n",
      "Epoch 9295, Loss: 0.04558199644088745, Neurons: 64, Grad norm: 2.533e-01\n",
      "Epoch 9295, Loss: 0.04558199644088745, Neurons: 64, Grad norm: 2.533e-01\n",
      "Epoch 9296, Loss: 0.045527372509241104, Neurons: 64, Grad norm: 2.372e-01\n",
      "Epoch 9296, Loss: 0.045527372509241104, Neurons: 64, Grad norm: 2.372e-01\n",
      "Epoch 9297, Loss: 0.04547230526804924, Neurons: 64, Grad norm: 2.161e-01\n",
      "Epoch 9297, Loss: 0.04547230526804924, Neurons: 64, Grad norm: 2.161e-01\n",
      "Epoch 9298, Loss: 0.045417703688144684, Neurons: 64, Grad norm: 1.733e-01\n",
      "Epoch 9298, Loss: 0.045417703688144684, Neurons: 64, Grad norm: 1.733e-01\n",
      "Epoch 9299, Loss: 0.04536271095275879, Neurons: 64, Grad norm: 1.236e-01\n",
      "Epoch 9299, Loss: 0.04536271095275879, Neurons: 64, Grad norm: 1.236e-01\n",
      "Epoch 9299, Test loss: 0.02951708436012268\n",
      "Epoch 9299, Test loss: 0.02951708436012268\n",
      "Epoch 9300, Loss: 0.04530804231762886, Neurons: 64, Grad norm: 7.401e-02\n",
      "Epoch 9300, Loss: 0.04530804231762886, Neurons: 64, Grad norm: 7.401e-02\n",
      "Epoch 9301, Loss: 0.04525362700223923, Neurons: 64, Grad norm: 6.132e-02\n",
      "Epoch 9301, Loss: 0.04525362700223923, Neurons: 64, Grad norm: 6.132e-02\n",
      "Epoch 9302, Loss: 0.04519934207201004, Neurons: 64, Grad norm: 8.813e-02\n",
      "Epoch 9302, Loss: 0.04519934207201004, Neurons: 64, Grad norm: 8.813e-02\n",
      "Epoch 9303, Loss: 0.04514504596590996, Neurons: 64, Grad norm: 1.130e-01\n",
      "Epoch 9303, Loss: 0.04514504596590996, Neurons: 64, Grad norm: 1.130e-01\n",
      "Epoch 9304, Loss: 0.04509089142084122, Neurons: 64, Grad norm: 1.396e-01\n",
      "Epoch 9304, Loss: 0.04509089142084122, Neurons: 64, Grad norm: 1.396e-01\n",
      "Epoch 9305, Loss: 0.045036934316158295, Neurons: 64, Grad norm: 1.523e-01\n",
      "Epoch 9305, Loss: 0.045036934316158295, Neurons: 64, Grad norm: 1.523e-01\n",
      "Epoch 9306, Loss: 0.04498310387134552, Neurons: 64, Grad norm: 1.578e-01\n",
      "Epoch 9306, Loss: 0.04498310387134552, Neurons: 64, Grad norm: 1.578e-01\n",
      "Epoch 9307, Loss: 0.044929105788469315, Neurons: 64, Grad norm: 1.416e-01\n",
      "Epoch 9307, Loss: 0.044929105788469315, Neurons: 64, Grad norm: 1.416e-01\n",
      "Epoch 9308, Loss: 0.044875368475914, Neurons: 64, Grad norm: 1.287e-01\n",
      "Epoch 9308, Loss: 0.044875368475914, Neurons: 64, Grad norm: 1.287e-01\n",
      "Epoch 9309, Loss: 0.0448216013610363, Neurons: 64, Grad norm: 1.009e-01\n",
      "Epoch 9309, Loss: 0.0448216013610363, Neurons: 64, Grad norm: 1.009e-01\n",
      "Epoch 9310, Loss: 0.044767893850803375, Neurons: 64, Grad norm: 8.263e-02\n",
      "Epoch 9310, Loss: 0.044767893850803375, Neurons: 64, Grad norm: 8.263e-02\n",
      "Epoch 9311, Loss: 0.044714268296957016, Neurons: 64, Grad norm: 6.522e-02\n",
      "Epoch 9311, Loss: 0.044714268296957016, Neurons: 64, Grad norm: 6.522e-02\n",
      "Epoch 9312, Loss: 0.044660624116659164, Neurons: 64, Grad norm: 6.780e-02\n",
      "Epoch 9312, Loss: 0.044660624116659164, Neurons: 64, Grad norm: 6.780e-02\n",
      "Epoch 9313, Loss: 0.044607289135456085, Neurons: 64, Grad norm: 8.412e-02\n",
      "Epoch 9313, Loss: 0.044607289135456085, Neurons: 64, Grad norm: 8.412e-02\n",
      "Epoch 9314, Loss: 0.04455384984612465, Neurons: 64, Grad norm: 9.734e-02\n",
      "Epoch 9314, Loss: 0.04455384984612465, Neurons: 64, Grad norm: 9.734e-02\n",
      "Epoch 9315, Loss: 0.044500816613435745, Neurons: 64, Grad norm: 1.175e-01\n",
      "Epoch 9315, Loss: 0.044500816613435745, Neurons: 64, Grad norm: 1.175e-01\n",
      "Epoch 9316, Loss: 0.044447556138038635, Neurons: 64, Grad norm: 1.265e-01\n",
      "Epoch 9316, Loss: 0.044447556138038635, Neurons: 64, Grad norm: 1.265e-01\n",
      "Epoch 9317, Loss: 0.044394586235284805, Neurons: 64, Grad norm: 1.458e-01\n",
      "Epoch 9317, Loss: 0.044394586235284805, Neurons: 64, Grad norm: 1.458e-01\n",
      "Epoch 9318, Loss: 0.044341716915369034, Neurons: 64, Grad norm: 1.413e-01\n",
      "Epoch 9318, Loss: 0.044341716915369034, Neurons: 64, Grad norm: 1.413e-01\n",
      "Epoch 9319, Loss: 0.0442887507379055, Neurons: 64, Grad norm: 1.493e-01\n",
      "Epoch 9319, Loss: 0.0442887507379055, Neurons: 64, Grad norm: 1.493e-01\n",
      "Epoch 9320, Loss: 0.04423591122031212, Neurons: 64, Grad norm: 1.465e-01\n",
      "Epoch 9320, Loss: 0.04423591122031212, Neurons: 64, Grad norm: 1.465e-01\n",
      "Epoch 9321, Loss: 0.044183384627103806, Neurons: 64, Grad norm: 1.491e-01\n",
      "Epoch 9321, Loss: 0.044183384627103806, Neurons: 64, Grad norm: 1.491e-01\n",
      "Epoch 9322, Loss: 0.04413066431879997, Neurons: 64, Grad norm: 1.391e-01\n",
      "Epoch 9322, Loss: 0.04413066431879997, Neurons: 64, Grad norm: 1.391e-01\n",
      "Epoch 9323, Loss: 0.04407832399010658, Neurons: 64, Grad norm: 1.412e-01\n",
      "Epoch 9323, Loss: 0.04407832399010658, Neurons: 64, Grad norm: 1.412e-01\n",
      "Epoch 9324, Loss: 0.044025711715221405, Neurons: 64, Grad norm: 1.407e-01\n",
      "Epoch 9324, Loss: 0.044025711715221405, Neurons: 64, Grad norm: 1.407e-01\n",
      "Epoch 9325, Loss: 0.04397331550717354, Neurons: 64, Grad norm: 1.404e-01\n",
      "Epoch 9325, Loss: 0.04397331550717354, Neurons: 64, Grad norm: 1.404e-01\n",
      "Epoch 9326, Loss: 0.043921224772930145, Neurons: 64, Grad norm: 1.384e-01\n",
      "Epoch 9326, Loss: 0.043921224772930145, Neurons: 64, Grad norm: 1.384e-01\n",
      "Epoch 9327, Loss: 0.04386908933520317, Neurons: 64, Grad norm: 1.511e-01\n",
      "Epoch 9327, Loss: 0.04386908933520317, Neurons: 64, Grad norm: 1.511e-01\n",
      "Epoch 9328, Loss: 0.04381716996431351, Neurons: 64, Grad norm: 1.551e-01\n",
      "Epoch 9328, Loss: 0.04381716996431351, Neurons: 64, Grad norm: 1.551e-01\n",
      "Epoch 9329, Loss: 0.043765321373939514, Neurons: 64, Grad norm: 1.742e-01\n",
      "Epoch 9329, Loss: 0.043765321373939514, Neurons: 64, Grad norm: 1.742e-01\n",
      "Epoch 9330, Loss: 0.04371371492743492, Neurons: 64, Grad norm: 1.871e-01\n",
      "Epoch 9330, Loss: 0.04371371492743492, Neurons: 64, Grad norm: 1.871e-01\n",
      "Epoch 9331, Loss: 0.043662186712026596, Neurons: 64, Grad norm: 2.175e-01\n",
      "Epoch 9331, Loss: 0.043662186712026596, Neurons: 64, Grad norm: 2.175e-01\n",
      "Epoch 9332, Loss: 0.04361063614487648, Neurons: 64, Grad norm: 2.401e-01\n",
      "Epoch 9332, Loss: 0.04361063614487648, Neurons: 64, Grad norm: 2.401e-01\n",
      "Epoch 9333, Loss: 0.04355942830443382, Neurons: 64, Grad norm: 2.760e-01\n",
      "Epoch 9333, Loss: 0.04355942830443382, Neurons: 64, Grad norm: 2.760e-01\n",
      "Epoch 9334, Loss: 0.04350902512669563, Neurons: 64, Grad norm: 3.137e-01\n",
      "Epoch 9334, Loss: 0.04350902512669563, Neurons: 64, Grad norm: 3.137e-01\n",
      "Epoch 9335, Loss: 0.043458376079797745, Neurons: 64, Grad norm: 3.599e-01\n",
      "Epoch 9335, Loss: 0.043458376079797745, Neurons: 64, Grad norm: 3.599e-01\n",
      "Epoch 9336, Loss: 0.04340856894850731, Neurons: 64, Grad norm: 4.084e-01\n",
      "Epoch 9336, Loss: 0.04340856894850731, Neurons: 64, Grad norm: 4.084e-01\n",
      "Epoch 9337, Loss: 0.04335896298289299, Neurons: 64, Grad norm: 4.716e-01\n",
      "Epoch 9337, Loss: 0.04335896298289299, Neurons: 64, Grad norm: 4.716e-01\n",
      "Epoch 9338, Loss: 0.043309830129146576, Neurons: 64, Grad norm: 5.367e-01\n",
      "Epoch 9338, Loss: 0.043309830129146576, Neurons: 64, Grad norm: 5.367e-01\n",
      "Epoch 9339, Loss: 0.04326207935810089, Neurons: 64, Grad norm: 6.225e-01\n",
      "Epoch 9339, Loss: 0.04326207935810089, Neurons: 64, Grad norm: 6.225e-01\n",
      "Epoch 9340, Loss: 0.043215300887823105, Neurons: 64, Grad norm: 7.110e-01\n",
      "Epoch 9340, Loss: 0.043215300887823105, Neurons: 64, Grad norm: 7.110e-01\n",
      "Epoch 9341, Loss: 0.043170005083084106, Neurons: 64, Grad norm: 8.197e-01\n",
      "Epoch 9341, Loss: 0.043170005083084106, Neurons: 64, Grad norm: 8.197e-01\n",
      "Epoch 9342, Loss: 0.04312507063150406, Neurons: 64, Grad norm: 9.277e-01\n",
      "Epoch 9342, Loss: 0.04312507063150406, Neurons: 64, Grad norm: 9.277e-01\n",
      "Epoch 9343, Loss: 0.04308256879448891, Neurons: 64, Grad norm: 1.062e+00\n",
      "Epoch 9343, Loss: 0.04308256879448891, Neurons: 64, Grad norm: 1.062e+00\n",
      "Epoch 9344, Loss: 0.04304077848792076, Neurons: 64, Grad norm: 1.192e+00\n",
      "Epoch 9344, Loss: 0.04304077848792076, Neurons: 64, Grad norm: 1.192e+00\n",
      "Epoch 9345, Loss: 0.04300054907798767, Neurons: 64, Grad norm: 1.335e+00\n",
      "Epoch 9345, Loss: 0.04300054907798767, Neurons: 64, Grad norm: 1.335e+00\n",
      "Epoch 9346, Loss: 0.042959511280059814, Neurons: 64, Grad norm: 1.469e+00\n",
      "Epoch 9346, Loss: 0.042959511280059814, Neurons: 64, Grad norm: 1.469e+00\n",
      "Epoch 9347, Loss: 0.04291806370019913, Neurons: 64, Grad norm: 1.609e+00\n",
      "Epoch 9347, Loss: 0.04291806370019913, Neurons: 64, Grad norm: 1.609e+00\n",
      "Epoch 9348, Loss: 0.04287291318178177, Neurons: 64, Grad norm: 1.738e+00\n",
      "Epoch 9348, Loss: 0.04287291318178177, Neurons: 64, Grad norm: 1.738e+00\n",
      "Epoch 9349, Loss: 0.04282413423061371, Neurons: 64, Grad norm: 1.871e+00\n",
      "Epoch 9349, Loss: 0.04282413423061371, Neurons: 64, Grad norm: 1.871e+00\n",
      "Epoch 9350, Loss: 0.04277212545275688, Neurons: 64, Grad norm: 2.000e+00\n",
      "Epoch 9350, Loss: 0.04277212545275688, Neurons: 64, Grad norm: 2.000e+00\n",
      "Epoch 9351, Loss: 0.042719561606645584, Neurons: 64, Grad norm: 2.158e+00\n",
      "Epoch 9351, Loss: 0.042719561606645584, Neurons: 64, Grad norm: 2.158e+00\n",
      "Epoch 9352, Loss: 0.042668893933296204, Neurons: 64, Grad norm: 2.328e+00\n",
      "Epoch 9352, Loss: 0.042668893933296204, Neurons: 64, Grad norm: 2.328e+00\n",
      "Epoch 9353, Loss: 0.04262370616197586, Neurons: 64, Grad norm: 2.531e+00\n",
      "Epoch 9353, Loss: 0.04262370616197586, Neurons: 64, Grad norm: 2.531e+00\n",
      "Epoch 9354, Loss: 0.04258495569229126, Neurons: 64, Grad norm: 2.734e+00\n",
      "Epoch 9354, Loss: 0.04258495569229126, Neurons: 64, Grad norm: 2.734e+00\n",
      "Epoch 9355, Loss: 0.04255237057805061, Neurons: 64, Grad norm: 2.957e+00\n",
      "Epoch 9355, Loss: 0.04255237057805061, Neurons: 64, Grad norm: 2.957e+00\n",
      "Epoch 9356, Loss: 0.04252414032816887, Neurons: 64, Grad norm: 3.162e+00\n",
      "Epoch 9356, Loss: 0.04252414032816887, Neurons: 64, Grad norm: 3.162e+00\n",
      "Epoch 9357, Loss: 0.042497117072343826, Neurons: 64, Grad norm: 3.356e+00\n",
      "Epoch 9357, Loss: 0.042497117072343826, Neurons: 64, Grad norm: 3.356e+00\n",
      "Epoch 9358, Loss: 0.04246876761317253, Neurons: 64, Grad norm: 3.507e+00\n",
      "Epoch 9358, Loss: 0.04246876761317253, Neurons: 64, Grad norm: 3.507e+00\n",
      "Epoch 9359, Loss: 0.04243655502796173, Neurons: 64, Grad norm: 3.620e+00\n",
      "Epoch 9359, Loss: 0.04243655502796173, Neurons: 64, Grad norm: 3.620e+00\n",
      "Epoch 9360, Loss: 0.04239746555685997, Neurons: 64, Grad norm: 3.662e+00\n",
      "Epoch 9360, Loss: 0.04239746555685997, Neurons: 64, Grad norm: 3.662e+00\n",
      "Epoch 9361, Loss: 0.04235079139471054, Neurons: 64, Grad norm: 3.640e+00\n",
      "Epoch 9361, Loss: 0.04235079139471054, Neurons: 64, Grad norm: 3.640e+00\n",
      "Epoch 9362, Loss: 0.04229522496461868, Neurons: 64, Grad norm: 3.530e+00\n",
      "Epoch 9362, Loss: 0.04229522496461868, Neurons: 64, Grad norm: 3.530e+00\n",
      "Epoch 9363, Loss: 0.04223164543509483, Neurons: 64, Grad norm: 3.347e+00\n",
      "Epoch 9363, Loss: 0.04223164543509483, Neurons: 64, Grad norm: 3.347e+00\n",
      "Epoch 9364, Loss: 0.04216250032186508, Neurons: 64, Grad norm: 3.075e+00\n",
      "Epoch 9364, Loss: 0.04216250032186508, Neurons: 64, Grad norm: 3.075e+00\n",
      "Epoch 9365, Loss: 0.042089372873306274, Neurons: 64, Grad norm: 2.747e+00\n",
      "Epoch 9365, Loss: 0.042089372873306274, Neurons: 64, Grad norm: 2.747e+00\n",
      "Epoch 9366, Loss: 0.04201461747288704, Neurons: 64, Grad norm: 2.350e+00\n",
      "Epoch 9366, Loss: 0.04201461747288704, Neurons: 64, Grad norm: 2.350e+00\n",
      "Epoch 9367, Loss: 0.041939981281757355, Neurons: 64, Grad norm: 1.927e+00\n",
      "Epoch 9367, Loss: 0.041939981281757355, Neurons: 64, Grad norm: 1.927e+00\n",
      "Epoch 9368, Loss: 0.04186718538403511, Neurons: 64, Grad norm: 1.475e+00\n",
      "Epoch 9368, Loss: 0.04186718538403511, Neurons: 64, Grad norm: 1.475e+00\n",
      "Epoch 9369, Loss: 0.04179738089442253, Neurons: 64, Grad norm: 1.037e+00\n",
      "Epoch 9369, Loss: 0.04179738089442253, Neurons: 64, Grad norm: 1.037e+00\n",
      "Epoch 9370, Loss: 0.041731540113687515, Neurons: 64, Grad norm: 6.140e-01\n",
      "Epoch 9370, Loss: 0.041731540113687515, Neurons: 64, Grad norm: 6.140e-01\n",
      "Epoch 9371, Loss: 0.04167044907808304, Neurons: 64, Grad norm: 3.177e-01\n",
      "Epoch 9371, Loss: 0.04167044907808304, Neurons: 64, Grad norm: 3.177e-01\n",
      "Epoch 9372, Loss: 0.041614700108766556, Neurons: 64, Grad norm: 3.901e-01\n",
      "Epoch 9372, Loss: 0.041614700108766556, Neurons: 64, Grad norm: 3.901e-01\n",
      "Epoch 9373, Loss: 0.041564445942640305, Neurons: 64, Grad norm: 6.611e-01\n",
      "Epoch 9373, Loss: 0.041564445942640305, Neurons: 64, Grad norm: 6.611e-01\n",
      "Epoch 9374, Loss: 0.04151880741119385, Neurons: 64, Grad norm: 9.362e-01\n",
      "Epoch 9374, Loss: 0.04151880741119385, Neurons: 64, Grad norm: 9.362e-01\n",
      "Epoch 9375, Loss: 0.041476476937532425, Neurons: 64, Grad norm: 1.165e+00\n",
      "Epoch 9375, Loss: 0.041476476937532425, Neurons: 64, Grad norm: 1.165e+00\n",
      "Epoch 9376, Loss: 0.041436463594436646, Neurons: 64, Grad norm: 1.357e+00\n",
      "Epoch 9376, Loss: 0.041436463594436646, Neurons: 64, Grad norm: 1.357e+00\n",
      "Epoch 9377, Loss: 0.04139697179198265, Neurons: 64, Grad norm: 1.491e+00\n",
      "Epoch 9377, Loss: 0.04139697179198265, Neurons: 64, Grad norm: 1.491e+00\n",
      "Epoch 9378, Loss: 0.041356805711984634, Neurons: 64, Grad norm: 1.592e+00\n",
      "Epoch 9378, Loss: 0.041356805711984634, Neurons: 64, Grad norm: 1.592e+00\n",
      "Epoch 9379, Loss: 0.04131464287638664, Neurons: 64, Grad norm: 1.637e+00\n",
      "Epoch 9379, Loss: 0.04131464287638664, Neurons: 64, Grad norm: 1.637e+00\n",
      "Epoch 9380, Loss: 0.041270334273576736, Neurons: 64, Grad norm: 1.651e+00\n",
      "Epoch 9380, Loss: 0.041270334273576736, Neurons: 64, Grad norm: 1.651e+00\n",
      "Epoch 9381, Loss: 0.041222985833883286, Neurons: 64, Grad norm: 1.619e+00\n",
      "Epoch 9381, Loss: 0.041222985833883286, Neurons: 64, Grad norm: 1.619e+00\n",
      "Epoch 9382, Loss: 0.041173096746206284, Neurons: 64, Grad norm: 1.567e+00\n",
      "Epoch 9382, Loss: 0.041173096746206284, Neurons: 64, Grad norm: 1.567e+00\n",
      "Epoch 9383, Loss: 0.04112131521105766, Neurons: 64, Grad norm: 1.477e+00\n",
      "Epoch 9383, Loss: 0.04112131521105766, Neurons: 64, Grad norm: 1.477e+00\n",
      "Epoch 9384, Loss: 0.0410686656832695, Neurons: 64, Grad norm: 1.383e+00\n",
      "Epoch 9384, Loss: 0.0410686656832695, Neurons: 64, Grad norm: 1.383e+00\n",
      "Epoch 9385, Loss: 0.04101598635315895, Neurons: 64, Grad norm: 1.263e+00\n",
      "Epoch 9385, Loss: 0.04101598635315895, Neurons: 64, Grad norm: 1.263e+00\n",
      "Epoch 9386, Loss: 0.040963783860206604, Neurons: 64, Grad norm: 1.155e+00\n",
      "Epoch 9386, Loss: 0.040963783860206604, Neurons: 64, Grad norm: 1.155e+00\n",
      "Epoch 9387, Loss: 0.04091249033808708, Neurons: 64, Grad norm: 1.035e+00\n",
      "Epoch 9387, Loss: 0.04091249033808708, Neurons: 64, Grad norm: 1.035e+00\n",
      "Epoch 9388, Loss: 0.0408620685338974, Neurons: 64, Grad norm: 9.212e-01\n",
      "Epoch 9388, Loss: 0.0408620685338974, Neurons: 64, Grad norm: 9.212e-01\n",
      "Epoch 9389, Loss: 0.04081230238080025, Neurons: 64, Grad norm: 7.992e-01\n",
      "Epoch 9389, Loss: 0.04081230238080025, Neurons: 64, Grad norm: 7.992e-01\n",
      "Epoch 9390, Loss: 0.040763262659311295, Neurons: 64, Grad norm: 6.977e-01\n",
      "Epoch 9390, Loss: 0.040763262659311295, Neurons: 64, Grad norm: 6.977e-01\n",
      "Epoch 9391, Loss: 0.040714483708143234, Neurons: 64, Grad norm: 5.899e-01\n",
      "Epoch 9391, Loss: 0.040714483708143234, Neurons: 64, Grad norm: 5.899e-01\n",
      "Epoch 9392, Loss: 0.04066574200987816, Neurons: 64, Grad norm: 4.887e-01\n",
      "Epoch 9392, Loss: 0.04066574200987816, Neurons: 64, Grad norm: 4.887e-01\n",
      "Epoch 9393, Loss: 0.04061714932322502, Neurons: 64, Grad norm: 3.888e-01\n",
      "Epoch 9393, Loss: 0.04061714932322502, Neurons: 64, Grad norm: 3.888e-01\n",
      "Epoch 9394, Loss: 0.04056888073682785, Neurons: 64, Grad norm: 3.051e-01\n",
      "Epoch 9394, Loss: 0.04056888073682785, Neurons: 64, Grad norm: 3.051e-01\n",
      "Epoch 9395, Loss: 0.04052077606320381, Neurons: 64, Grad norm: 2.101e-01\n",
      "Epoch 9395, Loss: 0.04052077606320381, Neurons: 64, Grad norm: 2.101e-01\n",
      "Epoch 9396, Loss: 0.04047304764389992, Neurons: 64, Grad norm: 1.349e-01\n",
      "Epoch 9396, Loss: 0.04047304764389992, Neurons: 64, Grad norm: 1.349e-01\n",
      "Epoch 9397, Loss: 0.0404258593916893, Neurons: 64, Grad norm: 6.797e-02\n",
      "Epoch 9397, Loss: 0.0404258593916893, Neurons: 64, Grad norm: 6.797e-02\n",
      "Epoch 9398, Loss: 0.040379032492637634, Neurons: 64, Grad norm: 5.933e-02\n",
      "Epoch 9398, Loss: 0.040379032492637634, Neurons: 64, Grad norm: 5.933e-02\n",
      "Epoch 9399, Loss: 0.040332578122615814, Neurons: 64, Grad norm: 1.085e-01\n",
      "Epoch 9399, Loss: 0.040332578122615814, Neurons: 64, Grad norm: 1.085e-01\n",
      "Epoch 9399, Test loss: 0.026131020858883858\n",
      "Epoch 9399, Test loss: 0.026131020858883858\n",
      "Epoch 9400, Loss: 0.040286585688591, Neurons: 64, Grad norm: 1.596e-01\n",
      "Epoch 9400, Loss: 0.040286585688591, Neurons: 64, Grad norm: 1.596e-01\n",
      "Epoch 9401, Loss: 0.04024069383740425, Neurons: 64, Grad norm: 2.088e-01\n",
      "Epoch 9401, Loss: 0.04024069383740425, Neurons: 64, Grad norm: 2.088e-01\n",
      "Epoch 9402, Loss: 0.04019499570131302, Neurons: 64, Grad norm: 2.467e-01\n",
      "Epoch 9402, Loss: 0.04019499570131302, Neurons: 64, Grad norm: 2.467e-01\n",
      "Epoch 9403, Loss: 0.04014948382973671, Neurons: 64, Grad norm: 3.039e-01\n",
      "Epoch 9403, Loss: 0.04014948382973671, Neurons: 64, Grad norm: 3.039e-01\n",
      "Epoch 9404, Loss: 0.040103983134031296, Neurons: 64, Grad norm: 3.376e-01\n",
      "Epoch 9404, Loss: 0.040103983134031296, Neurons: 64, Grad norm: 3.376e-01\n",
      "Epoch 9405, Loss: 0.04005866125226021, Neurons: 64, Grad norm: 3.904e-01\n",
      "Epoch 9405, Loss: 0.04005866125226021, Neurons: 64, Grad norm: 3.904e-01\n",
      "Epoch 9406, Loss: 0.04001328721642494, Neurons: 64, Grad norm: 4.420e-01\n",
      "Epoch 9406, Loss: 0.04001328721642494, Neurons: 64, Grad norm: 4.420e-01\n",
      "Epoch 9407, Loss: 0.03996817767620087, Neurons: 64, Grad norm: 4.930e-01\n",
      "Epoch 9407, Loss: 0.03996817767620087, Neurons: 64, Grad norm: 4.930e-01\n",
      "Epoch 9408, Loss: 0.03992315009236336, Neurons: 64, Grad norm: 5.530e-01\n",
      "Epoch 9408, Loss: 0.03992315009236336, Neurons: 64, Grad norm: 5.530e-01\n",
      "Epoch 9409, Loss: 0.039878517389297485, Neurons: 64, Grad norm: 6.358e-01\n",
      "Epoch 9409, Loss: 0.039878517389297485, Neurons: 64, Grad norm: 6.358e-01\n",
      "Epoch 9410, Loss: 0.039834197610616684, Neurons: 64, Grad norm: 6.992e-01\n",
      "Epoch 9410, Loss: 0.039834197610616684, Neurons: 64, Grad norm: 6.992e-01\n",
      "Epoch 9411, Loss: 0.03979043662548065, Neurons: 64, Grad norm: 8.064e-01\n",
      "Epoch 9411, Loss: 0.03979043662548065, Neurons: 64, Grad norm: 8.064e-01\n",
      "Epoch 9412, Loss: 0.03974732756614685, Neurons: 64, Grad norm: 9.250e-01\n",
      "Epoch 9412, Loss: 0.03974732756614685, Neurons: 64, Grad norm: 9.250e-01\n",
      "Epoch 9413, Loss: 0.03970491141080856, Neurons: 64, Grad norm: 1.065e+00\n",
      "Epoch 9413, Loss: 0.03970491141080856, Neurons: 64, Grad norm: 1.065e+00\n",
      "Epoch 9414, Loss: 0.03966381400823593, Neurons: 64, Grad norm: 1.226e+00\n",
      "Epoch 9414, Loss: 0.03966381400823593, Neurons: 64, Grad norm: 1.226e+00\n",
      "Epoch 9415, Loss: 0.03962429240345955, Neurons: 64, Grad norm: 1.441e+00\n",
      "Epoch 9415, Loss: 0.03962429240345955, Neurons: 64, Grad norm: 1.441e+00\n",
      "Epoch 9416, Loss: 0.03958720713853836, Neurons: 64, Grad norm: 1.683e+00\n",
      "Epoch 9416, Loss: 0.03958720713853836, Neurons: 64, Grad norm: 1.683e+00\n",
      "Epoch 9417, Loss: 0.03955352306365967, Neurons: 64, Grad norm: 1.991e+00\n",
      "Epoch 9417, Loss: 0.03955352306365967, Neurons: 64, Grad norm: 1.991e+00\n",
      "Epoch 9418, Loss: 0.039524830877780914, Neurons: 64, Grad norm: 2.344e+00\n",
      "Epoch 9418, Loss: 0.039524830877780914, Neurons: 64, Grad norm: 2.344e+00\n",
      "Epoch 9419, Loss: 0.039503034204244614, Neurons: 64, Grad norm: 2.778e+00\n",
      "Epoch 9419, Loss: 0.039503034204244614, Neurons: 64, Grad norm: 2.778e+00\n",
      "Epoch 9420, Loss: 0.03949093073606491, Neurons: 64, Grad norm: 3.286e+00\n",
      "Epoch 9420, Loss: 0.03949093073606491, Neurons: 64, Grad norm: 3.286e+00\n",
      "Epoch 9421, Loss: 0.03949183225631714, Neurons: 64, Grad norm: 3.878e+00\n",
      "Epoch 9421, Loss: 0.03949183225631714, Neurons: 64, Grad norm: 3.878e+00\n",
      "Epoch 9422, Loss: 0.03950947895646095, Neurons: 64, Grad norm: 4.526e+00\n",
      "Epoch 9422, Loss: 0.03950947895646095, Neurons: 64, Grad norm: 4.526e+00\n",
      "Epoch 9423, Loss: 0.03954720497131348, Neurons: 64, Grad norm: 5.250e+00\n",
      "Epoch 9423, Loss: 0.03954720497131348, Neurons: 64, Grad norm: 5.250e+00\n",
      "Epoch 9424, Loss: 0.03960626572370529, Neurons: 64, Grad norm: 5.969e+00\n",
      "Epoch 9424, Loss: 0.03960626572370529, Neurons: 64, Grad norm: 5.969e+00\n",
      "Epoch 9425, Loss: 0.039682962000370026, Neurons: 64, Grad norm: 6.623e+00\n",
      "Epoch 9425, Loss: 0.039682962000370026, Neurons: 64, Grad norm: 6.623e+00\n",
      "Epoch 9426, Loss: 0.039760470390319824, Neurons: 64, Grad norm: 7.070e+00\n",
      "Epoch 9426, Loss: 0.039760470390319824, Neurons: 64, Grad norm: 7.070e+00\n",
      "Epoch 9427, Loss: 0.039809662848711014, Neurons: 64, Grad norm: 7.194e+00\n",
      "Epoch 9427, Loss: 0.039809662848711014, Neurons: 64, Grad norm: 7.194e+00\n",
      "Epoch 9428, Loss: 0.03978954255580902, Neurons: 64, Grad norm: 6.817e+00\n",
      "Epoch 9428, Loss: 0.03978954255580902, Neurons: 64, Grad norm: 6.817e+00\n",
      "Epoch 9429, Loss: 0.03967021405696869, Neurons: 64, Grad norm: 5.898e+00\n",
      "Epoch 9429, Loss: 0.03967021405696869, Neurons: 64, Grad norm: 5.898e+00\n",
      "Epoch 9430, Loss: 0.03945047780871391, Neurons: 64, Grad norm: 4.436e+00\n",
      "Epoch 9430, Loss: 0.03945047780871391, Neurons: 64, Grad norm: 4.436e+00\n",
      "Epoch 9431, Loss: 0.039182886481285095, Neurons: 64, Grad norm: 2.614e+00\n",
      "Epoch 9431, Loss: 0.039182886481285095, Neurons: 64, Grad norm: 2.614e+00\n",
      "Epoch 9432, Loss: 0.03894706815481186, Neurons: 64, Grad norm: 6.492e-01\n",
      "Epoch 9432, Loss: 0.03894706815481186, Neurons: 64, Grad norm: 6.492e-01\n",
      "Epoch 9433, Loss: 0.03880826011300087, Neurons: 64, Grad norm: 1.193e+00\n",
      "Epoch 9433, Loss: 0.03880826011300087, Neurons: 64, Grad norm: 1.193e+00\n",
      "Epoch 9434, Loss: 0.03877978399395943, Neurons: 64, Grad norm: 2.722e+00\n",
      "Epoch 9434, Loss: 0.03877978399395943, Neurons: 64, Grad norm: 2.722e+00\n",
      "Epoch 9435, Loss: 0.03882482647895813, Neurons: 64, Grad norm: 3.757e+00\n",
      "Epoch 9435, Loss: 0.03882482647895813, Neurons: 64, Grad norm: 3.757e+00\n",
      "Epoch 9436, Loss: 0.038882363587617874, Neurons: 64, Grad norm: 4.243e+00\n",
      "Epoch 9436, Loss: 0.038882363587617874, Neurons: 64, Grad norm: 4.243e+00\n",
      "Epoch 9437, Loss: 0.03889621049165726, Neurons: 64, Grad norm: 4.128e+00\n",
      "Epoch 9437, Loss: 0.03889621049165726, Neurons: 64, Grad norm: 4.128e+00\n",
      "Epoch 9438, Loss: 0.03883959352970123, Neurons: 64, Grad norm: 3.490e+00\n",
      "Epoch 9438, Loss: 0.03883959352970123, Neurons: 64, Grad norm: 3.490e+00\n",
      "Epoch 9439, Loss: 0.03872277960181236, Neurons: 64, Grad norm: 2.416e+00\n",
      "Epoch 9439, Loss: 0.03872277960181236, Neurons: 64, Grad norm: 2.416e+00\n",
      "Epoch 9440, Loss: 0.0385855995118618, Neurons: 64, Grad norm: 1.120e+00\n",
      "Epoch 9440, Loss: 0.0385855995118618, Neurons: 64, Grad norm: 1.120e+00\n",
      "Epoch 9441, Loss: 0.03847374767065048, Neurons: 64, Grad norm: 2.215e-01\n",
      "Epoch 9441, Loss: 0.03847374767065048, Neurons: 64, Grad norm: 2.215e-01\n",
      "Epoch 9442, Loss: 0.03841262310743332, Neurons: 64, Grad norm: 1.375e+00\n",
      "Epoch 9442, Loss: 0.03841262310743332, Neurons: 64, Grad norm: 1.375e+00\n",
      "Epoch 9443, Loss: 0.03839726001024246, Neurons: 64, Grad norm: 2.250e+00\n",
      "Epoch 9443, Loss: 0.03839726001024246, Neurons: 64, Grad norm: 2.250e+00\n",
      "Epoch 9444, Loss: 0.0384008027613163, Neurons: 64, Grad norm: 2.711e+00\n",
      "Epoch 9444, Loss: 0.0384008027613163, Neurons: 64, Grad norm: 2.711e+00\n",
      "Epoch 9445, Loss: 0.038392748683691025, Neurons: 64, Grad norm: 2.768e+00\n",
      "Epoch 9445, Loss: 0.038392748683691025, Neurons: 64, Grad norm: 2.768e+00\n",
      "Epoch 9446, Loss: 0.038354285061359406, Neurons: 64, Grad norm: 2.426e+00\n",
      "Epoch 9446, Loss: 0.038354285061359406, Neurons: 64, Grad norm: 2.426e+00\n",
      "Epoch 9447, Loss: 0.03828563913702965, Neurons: 64, Grad norm: 1.794e+00\n",
      "Epoch 9447, Loss: 0.03828563913702965, Neurons: 64, Grad norm: 1.794e+00\n",
      "Epoch 9448, Loss: 0.03820263221859932, Neurons: 64, Grad norm: 9.585e-01\n",
      "Epoch 9448, Loss: 0.03820263221859932, Neurons: 64, Grad norm: 9.585e-01\n",
      "Epoch 9449, Loss: 0.03812604397535324, Neurons: 64, Grad norm: 9.702e-02\n",
      "Epoch 9449, Loss: 0.03812604397535324, Neurons: 64, Grad norm: 9.702e-02\n",
      "Epoch 9450, Loss: 0.038069870322942734, Neurons: 64, Grad norm: 7.263e-01\n",
      "Epoch 9450, Loss: 0.038069870322942734, Neurons: 64, Grad norm: 7.263e-01\n",
      "Epoch 9451, Loss: 0.038034968078136444, Neurons: 64, Grad norm: 1.339e+00\n",
      "Epoch 9451, Loss: 0.038034968078136444, Neurons: 64, Grad norm: 1.339e+00\n",
      "Epoch 9452, Loss: 0.038011860102415085, Neurons: 64, Grad norm: 1.738e+00\n",
      "Epoch 9452, Loss: 0.038011860102415085, Neurons: 64, Grad norm: 1.738e+00\n",
      "Epoch 9453, Loss: 0.03798734396696091, Neurons: 64, Grad norm: 1.848e+00\n",
      "Epoch 9453, Loss: 0.03798734396696091, Neurons: 64, Grad norm: 1.848e+00\n",
      "Epoch 9454, Loss: 0.037951402366161346, Neurons: 64, Grad norm: 1.710e+00\n",
      "Epoch 9454, Loss: 0.037951402366161346, Neurons: 64, Grad norm: 1.710e+00\n",
      "Epoch 9455, Loss: 0.03790184482932091, Neurons: 64, Grad norm: 1.363e+00\n",
      "Epoch 9455, Loss: 0.03790184482932091, Neurons: 64, Grad norm: 1.363e+00\n",
      "Epoch 9456, Loss: 0.03784365579485893, Neurons: 64, Grad norm: 8.816e-01\n",
      "Epoch 9456, Loss: 0.03784365579485893, Neurons: 64, Grad norm: 8.816e-01\n",
      "Epoch 9457, Loss: 0.03778531029820442, Neurons: 64, Grad norm: 3.222e-01\n",
      "Epoch 9457, Loss: 0.03778531029820442, Neurons: 64, Grad norm: 3.222e-01\n",
      "Epoch 9458, Loss: 0.037733472883701324, Neurons: 64, Grad norm: 2.128e-01\n",
      "Epoch 9458, Loss: 0.037733472883701324, Neurons: 64, Grad norm: 2.128e-01\n",
      "Epoch 9459, Loss: 0.037690669298172, Neurons: 64, Grad norm: 6.753e-01\n",
      "Epoch 9459, Loss: 0.037690669298172, Neurons: 64, Grad norm: 6.753e-01\n",
      "Epoch 9460, Loss: 0.03765473514795303, Neurons: 64, Grad norm: 1.004e+00\n",
      "Epoch 9460, Loss: 0.03765473514795303, Neurons: 64, Grad norm: 1.004e+00\n",
      "Epoch 9461, Loss: 0.03762110695242882, Neurons: 64, Grad norm: 1.183e+00\n",
      "Epoch 9461, Loss: 0.03762110695242882, Neurons: 64, Grad norm: 1.183e+00\n",
      "Epoch 9462, Loss: 0.03758523613214493, Neurons: 64, Grad norm: 1.198e+00\n",
      "Epoch 9462, Loss: 0.03758523613214493, Neurons: 64, Grad norm: 1.198e+00\n",
      "Epoch 9463, Loss: 0.03754420578479767, Neurons: 64, Grad norm: 1.088e+00\n",
      "Epoch 9463, Loss: 0.03754420578479767, Neurons: 64, Grad norm: 1.088e+00\n",
      "Epoch 9464, Loss: 0.03749844431877136, Neurons: 64, Grad norm: 8.370e-01\n",
      "Epoch 9464, Loss: 0.03749844431877136, Neurons: 64, Grad norm: 8.370e-01\n",
      "Epoch 9465, Loss: 0.037450097501277924, Neurons: 64, Grad norm: 5.393e-01\n",
      "Epoch 9465, Loss: 0.037450097501277924, Neurons: 64, Grad norm: 5.393e-01\n",
      "Epoch 9466, Loss: 0.03740227594971657, Neurons: 64, Grad norm: 1.994e-01\n",
      "Epoch 9466, Loss: 0.03740227594971657, Neurons: 64, Grad norm: 1.994e-01\n",
      "Epoch 9467, Loss: 0.03735710680484772, Neurons: 64, Grad norm: 1.428e-01\n",
      "Epoch 9467, Loss: 0.03735710680484772, Neurons: 64, Grad norm: 1.428e-01\n",
      "Epoch 9468, Loss: 0.03731539472937584, Neurons: 64, Grad norm: 4.253e-01\n",
      "Epoch 9468, Loss: 0.03731539472937584, Neurons: 64, Grad norm: 4.253e-01\n",
      "Epoch 9469, Loss: 0.037276461720466614, Neurons: 64, Grad norm: 6.243e-01\n",
      "Epoch 9469, Loss: 0.037276461720466614, Neurons: 64, Grad norm: 6.243e-01\n",
      "Epoch 9470, Loss: 0.03723842650651932, Neurons: 64, Grad norm: 7.505e-01\n",
      "Epoch 9470, Loss: 0.03723842650651932, Neurons: 64, Grad norm: 7.505e-01\n",
      "Epoch 9471, Loss: 0.037199705839157104, Neurons: 64, Grad norm: 7.747e-01\n",
      "Epoch 9471, Loss: 0.037199705839157104, Neurons: 64, Grad norm: 7.747e-01\n",
      "Epoch 9472, Loss: 0.03715920075774193, Neurons: 64, Grad norm: 7.358e-01\n",
      "Epoch 9472, Loss: 0.03715920075774193, Neurons: 64, Grad norm: 7.358e-01\n",
      "Epoch 9473, Loss: 0.037117090076208115, Neurons: 64, Grad norm: 6.150e-01\n",
      "Epoch 9473, Loss: 0.037117090076208115, Neurons: 64, Grad norm: 6.150e-01\n",
      "Epoch 9474, Loss: 0.03707366809248924, Neurons: 64, Grad norm: 4.582e-01\n",
      "Epoch 9474, Loss: 0.03707366809248924, Neurons: 64, Grad norm: 4.582e-01\n",
      "Epoch 9475, Loss: 0.03703024610877037, Neurons: 64, Grad norm: 2.647e-01\n",
      "Epoch 9475, Loss: 0.03703024610877037, Neurons: 64, Grad norm: 2.647e-01\n",
      "Epoch 9476, Loss: 0.03698738291859627, Neurons: 64, Grad norm: 9.166e-02\n",
      "Epoch 9476, Loss: 0.03698738291859627, Neurons: 64, Grad norm: 9.166e-02\n",
      "Epoch 9477, Loss: 0.03694547712802887, Neurons: 64, Grad norm: 1.276e-01\n",
      "Epoch 9477, Loss: 0.03694547712802887, Neurons: 64, Grad norm: 1.276e-01\n",
      "Epoch 9478, Loss: 0.036904916167259216, Neurons: 64, Grad norm: 2.669e-01\n",
      "Epoch 9478, Loss: 0.036904916167259216, Neurons: 64, Grad norm: 2.669e-01\n",
      "Epoch 9479, Loss: 0.036864954978227615, Neurons: 64, Grad norm: 3.899e-01\n",
      "Epoch 9479, Loss: 0.036864954978227615, Neurons: 64, Grad norm: 3.899e-01\n",
      "Epoch 9480, Loss: 0.036825451999902725, Neurons: 64, Grad norm: 4.569e-01\n",
      "Epoch 9480, Loss: 0.036825451999902725, Neurons: 64, Grad norm: 4.569e-01\n",
      "Epoch 9481, Loss: 0.0367860272526741, Neurons: 64, Grad norm: 4.977e-01\n",
      "Epoch 9481, Loss: 0.0367860272526741, Neurons: 64, Grad norm: 4.977e-01\n",
      "Epoch 9482, Loss: 0.03674614802002907, Neurons: 64, Grad norm: 4.822e-01\n",
      "Epoch 9482, Loss: 0.03674614802002907, Neurons: 64, Grad norm: 4.822e-01\n",
      "Epoch 9483, Loss: 0.03670557588338852, Neurons: 64, Grad norm: 4.452e-01\n",
      "Epoch 9483, Loss: 0.03670557588338852, Neurons: 64, Grad norm: 4.452e-01\n",
      "Epoch 9484, Loss: 0.036664895713329315, Neurons: 64, Grad norm: 3.762e-01\n",
      "Epoch 9484, Loss: 0.036664895713329315, Neurons: 64, Grad norm: 3.762e-01\n",
      "Epoch 9485, Loss: 0.036624111235141754, Neurons: 64, Grad norm: 3.092e-01\n",
      "Epoch 9485, Loss: 0.036624111235141754, Neurons: 64, Grad norm: 3.092e-01\n",
      "Epoch 9486, Loss: 0.03658348321914673, Neurons: 64, Grad norm: 2.448e-01\n",
      "Epoch 9486, Loss: 0.03658348321914673, Neurons: 64, Grad norm: 2.448e-01\n",
      "Epoch 9487, Loss: 0.03654320165514946, Neurons: 64, Grad norm: 2.263e-01\n",
      "Epoch 9487, Loss: 0.03654320165514946, Neurons: 64, Grad norm: 2.263e-01\n",
      "Epoch 9488, Loss: 0.03650341555476189, Neurons: 64, Grad norm: 2.601e-01\n",
      "Epoch 9488, Loss: 0.03650341555476189, Neurons: 64, Grad norm: 2.601e-01\n",
      "Epoch 9489, Loss: 0.036464542150497437, Neurons: 64, Grad norm: 3.279e-01\n",
      "Epoch 9489, Loss: 0.036464542150497437, Neurons: 64, Grad norm: 3.279e-01\n",
      "Epoch 9490, Loss: 0.03642617166042328, Neurons: 64, Grad norm: 4.050e-01\n",
      "Epoch 9490, Loss: 0.03642617166042328, Neurons: 64, Grad norm: 4.050e-01\n",
      "Epoch 9491, Loss: 0.03638872876763344, Neurons: 64, Grad norm: 4.745e-01\n",
      "Epoch 9491, Loss: 0.03638872876763344, Neurons: 64, Grad norm: 4.745e-01\n",
      "Epoch 9492, Loss: 0.03635191172361374, Neurons: 64, Grad norm: 5.563e-01\n",
      "Epoch 9492, Loss: 0.03635191172361374, Neurons: 64, Grad norm: 5.563e-01\n",
      "Epoch 9493, Loss: 0.03631574660539627, Neurons: 64, Grad norm: 6.149e-01\n",
      "Epoch 9493, Loss: 0.03631574660539627, Neurons: 64, Grad norm: 6.149e-01\n",
      "Epoch 9494, Loss: 0.03628046438097954, Neurons: 64, Grad norm: 6.861e-01\n",
      "Epoch 9494, Loss: 0.03628046438097954, Neurons: 64, Grad norm: 6.861e-01\n",
      "Epoch 9495, Loss: 0.03624625876545906, Neurons: 64, Grad norm: 7.539e-01\n",
      "Epoch 9495, Loss: 0.03624625876545906, Neurons: 64, Grad norm: 7.539e-01\n",
      "Epoch 9496, Loss: 0.036213189363479614, Neurons: 64, Grad norm: 8.278e-01\n",
      "Epoch 9496, Loss: 0.036213189363479614, Neurons: 64, Grad norm: 8.278e-01\n",
      "Epoch 9497, Loss: 0.03618216887116432, Neurons: 64, Grad norm: 9.013e-01\n",
      "Epoch 9497, Loss: 0.03618216887116432, Neurons: 64, Grad norm: 9.013e-01\n",
      "Epoch 9498, Loss: 0.036152590066194534, Neurons: 64, Grad norm: 9.853e-01\n",
      "Epoch 9498, Loss: 0.036152590066194534, Neurons: 64, Grad norm: 9.853e-01\n",
      "Epoch 9499, Loss: 0.036124445497989655, Neurons: 64, Grad norm: 1.060e+00\n",
      "Epoch 9499, Loss: 0.036124445497989655, Neurons: 64, Grad norm: 1.060e+00\n",
      "Epoch 9499, Test loss: 0.023389847949147224\n",
      "Epoch 9499, Test loss: 0.023389847949147224\n",
      "Epoch 9500, Loss: 0.03609668090939522, Neurons: 64, Grad norm: 1.123e+00\n",
      "Epoch 9500, Loss: 0.03609668090939522, Neurons: 64, Grad norm: 1.123e+00\n",
      "Epoch 9501, Loss: 0.036067839711904526, Neurons: 64, Grad norm: 1.162e+00\n",
      "Epoch 9501, Loss: 0.036067839711904526, Neurons: 64, Grad norm: 1.162e+00\n",
      "Epoch 9502, Loss: 0.036034975200891495, Neurons: 64, Grad norm: 1.166e+00\n",
      "Epoch 9502, Loss: 0.036034975200891495, Neurons: 64, Grad norm: 1.166e+00\n",
      "Epoch 9503, Loss: 0.03599658980965614, Neurons: 64, Grad norm: 1.114e+00\n",
      "Epoch 9503, Loss: 0.03599658980965614, Neurons: 64, Grad norm: 1.114e+00\n",
      "Epoch 9504, Loss: 0.03594989329576492, Neurons: 64, Grad norm: 1.016e+00\n",
      "Epoch 9504, Loss: 0.03594989329576492, Neurons: 64, Grad norm: 1.016e+00\n",
      "Epoch 9505, Loss: 0.03589560464024544, Neurons: 64, Grad norm: 8.625e-01\n",
      "Epoch 9505, Loss: 0.03589560464024544, Neurons: 64, Grad norm: 8.625e-01\n",
      "Epoch 9506, Loss: 0.035836298018693924, Neurons: 64, Grad norm: 6.818e-01\n",
      "Epoch 9506, Loss: 0.035836298018693924, Neurons: 64, Grad norm: 6.818e-01\n",
      "Epoch 9507, Loss: 0.035777002573013306, Neurons: 64, Grad norm: 4.865e-01\n",
      "Epoch 9507, Loss: 0.035777002573013306, Neurons: 64, Grad norm: 4.865e-01\n",
      "Epoch 9508, Loss: 0.03572220727801323, Neurons: 64, Grad norm: 3.582e-01\n",
      "Epoch 9508, Loss: 0.03572220727801323, Neurons: 64, Grad norm: 3.582e-01\n",
      "Epoch 9509, Loss: 0.03567530959844589, Neurons: 64, Grad norm: 3.406e-01\n",
      "Epoch 9509, Loss: 0.03567530959844589, Neurons: 64, Grad norm: 3.406e-01\n",
      "Epoch 9510, Loss: 0.03563633933663368, Neurons: 64, Grad norm: 4.308e-01\n",
      "Epoch 9510, Loss: 0.03563633933663368, Neurons: 64, Grad norm: 4.308e-01\n",
      "Epoch 9511, Loss: 0.03560305014252663, Neurons: 64, Grad norm: 5.271e-01\n",
      "Epoch 9511, Loss: 0.03560305014252663, Neurons: 64, Grad norm: 5.271e-01\n",
      "Epoch 9512, Loss: 0.03557231277227402, Neurons: 64, Grad norm: 6.026e-01\n",
      "Epoch 9512, Loss: 0.03557231277227402, Neurons: 64, Grad norm: 6.026e-01\n",
      "Epoch 9513, Loss: 0.035540755838155746, Neurons: 64, Grad norm: 6.317e-01\n",
      "Epoch 9513, Loss: 0.035540755838155746, Neurons: 64, Grad norm: 6.317e-01\n",
      "Epoch 9514, Loss: 0.03550608828663826, Neurons: 64, Grad norm: 6.219e-01\n",
      "Epoch 9514, Loss: 0.03550608828663826, Neurons: 64, Grad norm: 6.219e-01\n",
      "Epoch 9515, Loss: 0.035467781126499176, Neurons: 64, Grad norm: 5.710e-01\n",
      "Epoch 9515, Loss: 0.035467781126499176, Neurons: 64, Grad norm: 5.710e-01\n",
      "Epoch 9516, Loss: 0.0354260578751564, Neurons: 64, Grad norm: 4.946e-01\n",
      "Epoch 9516, Loss: 0.0354260578751564, Neurons: 64, Grad norm: 4.946e-01\n",
      "Epoch 9517, Loss: 0.03538237139582634, Neurons: 64, Grad norm: 4.054e-01\n",
      "Epoch 9517, Loss: 0.03538237139582634, Neurons: 64, Grad norm: 4.054e-01\n",
      "Epoch 9518, Loss: 0.03533787652850151, Neurons: 64, Grad norm: 3.224e-01\n",
      "Epoch 9518, Loss: 0.03533787652850151, Neurons: 64, Grad norm: 3.224e-01\n",
      "Epoch 9519, Loss: 0.035294778645038605, Neurons: 64, Grad norm: 2.867e-01\n",
      "Epoch 9519, Loss: 0.035294778645038605, Neurons: 64, Grad norm: 2.867e-01\n",
      "Epoch 9520, Loss: 0.03525364771485329, Neurons: 64, Grad norm: 2.987e-01\n",
      "Epoch 9520, Loss: 0.03525364771485329, Neurons: 64, Grad norm: 2.987e-01\n",
      "Epoch 9521, Loss: 0.03521471470594406, Neurons: 64, Grad norm: 3.596e-01\n",
      "Epoch 9521, Loss: 0.03521471470594406, Neurons: 64, Grad norm: 3.596e-01\n",
      "Epoch 9522, Loss: 0.03517753258347511, Neurons: 64, Grad norm: 4.132e-01\n",
      "Epoch 9522, Loss: 0.03517753258347511, Neurons: 64, Grad norm: 4.132e-01\n",
      "Epoch 9523, Loss: 0.03514149785041809, Neurons: 64, Grad norm: 4.726e-01\n",
      "Epoch 9523, Loss: 0.03514149785041809, Neurons: 64, Grad norm: 4.726e-01\n",
      "Epoch 9524, Loss: 0.03510582819581032, Neurons: 64, Grad norm: 5.083e-01\n",
      "Epoch 9524, Loss: 0.03510582819581032, Neurons: 64, Grad norm: 5.083e-01\n",
      "Epoch 9525, Loss: 0.03506988659501076, Neurons: 64, Grad norm: 5.410e-01\n",
      "Epoch 9525, Loss: 0.03506988659501076, Neurons: 64, Grad norm: 5.410e-01\n",
      "Epoch 9526, Loss: 0.03503307327628136, Neurons: 64, Grad norm: 5.396e-01\n",
      "Epoch 9526, Loss: 0.03503307327628136, Neurons: 64, Grad norm: 5.396e-01\n",
      "Epoch 9527, Loss: 0.03499576449394226, Neurons: 64, Grad norm: 5.397e-01\n",
      "Epoch 9527, Loss: 0.03499576449394226, Neurons: 64, Grad norm: 5.397e-01\n",
      "Epoch 9528, Loss: 0.03495754301548004, Neurons: 64, Grad norm: 5.201e-01\n",
      "Epoch 9528, Loss: 0.03495754301548004, Neurons: 64, Grad norm: 5.201e-01\n",
      "Epoch 9529, Loss: 0.0349188856780529, Neurons: 64, Grad norm: 5.039e-01\n",
      "Epoch 9529, Loss: 0.0349188856780529, Neurons: 64, Grad norm: 5.039e-01\n",
      "Epoch 9530, Loss: 0.034879982471466064, Neurons: 64, Grad norm: 4.767e-01\n",
      "Epoch 9530, Loss: 0.034879982471466064, Neurons: 64, Grad norm: 4.767e-01\n",
      "Epoch 9531, Loss: 0.03484140709042549, Neurons: 64, Grad norm: 4.768e-01\n",
      "Epoch 9531, Loss: 0.03484140709042549, Neurons: 64, Grad norm: 4.768e-01\n",
      "Epoch 9532, Loss: 0.03480328246951103, Neurons: 64, Grad norm: 4.715e-01\n",
      "Epoch 9532, Loss: 0.03480328246951103, Neurons: 64, Grad norm: 4.715e-01\n",
      "Epoch 9533, Loss: 0.03476577252149582, Neurons: 64, Grad norm: 4.964e-01\n",
      "Epoch 9533, Loss: 0.03476577252149582, Neurons: 64, Grad norm: 4.964e-01\n",
      "Epoch 9534, Loss: 0.03472889959812164, Neurons: 64, Grad norm: 5.174e-01\n",
      "Epoch 9534, Loss: 0.03472889959812164, Neurons: 64, Grad norm: 5.174e-01\n",
      "Epoch 9535, Loss: 0.03469246253371239, Neurons: 64, Grad norm: 5.656e-01\n",
      "Epoch 9535, Loss: 0.03469246253371239, Neurons: 64, Grad norm: 5.656e-01\n",
      "Epoch 9536, Loss: 0.0346563458442688, Neurons: 64, Grad norm: 6.080e-01\n",
      "Epoch 9536, Loss: 0.0346563458442688, Neurons: 64, Grad norm: 6.080e-01\n",
      "Epoch 9537, Loss: 0.03462051972746849, Neurons: 64, Grad norm: 6.737e-01\n",
      "Epoch 9537, Loss: 0.03462051972746849, Neurons: 64, Grad norm: 6.737e-01\n",
      "Epoch 9538, Loss: 0.03458505868911743, Neurons: 64, Grad norm: 7.432e-01\n",
      "Epoch 9538, Loss: 0.03458505868911743, Neurons: 64, Grad norm: 7.432e-01\n",
      "Epoch 9539, Loss: 0.034550029784440994, Neurons: 64, Grad norm: 8.447e-01\n",
      "Epoch 9539, Loss: 0.034550029784440994, Neurons: 64, Grad norm: 8.447e-01\n",
      "Epoch 9540, Loss: 0.03451570123434067, Neurons: 64, Grad norm: 9.402e-01\n",
      "Epoch 9540, Loss: 0.03451570123434067, Neurons: 64, Grad norm: 9.402e-01\n",
      "Epoch 9541, Loss: 0.034482136368751526, Neurons: 64, Grad norm: 1.074e+00\n",
      "Epoch 9541, Loss: 0.034482136368751526, Neurons: 64, Grad norm: 1.074e+00\n",
      "Epoch 9542, Loss: 0.034449558705091476, Neurons: 64, Grad norm: 1.218e+00\n",
      "Epoch 9542, Loss: 0.034449558705091476, Neurons: 64, Grad norm: 1.218e+00\n",
      "Epoch 9543, Loss: 0.034418292343616486, Neurons: 64, Grad norm: 1.402e+00\n",
      "Epoch 9543, Loss: 0.034418292343616486, Neurons: 64, Grad norm: 1.402e+00\n",
      "Epoch 9544, Loss: 0.034388817846775055, Neurons: 64, Grad norm: 1.607e+00\n",
      "Epoch 9544, Loss: 0.034388817846775055, Neurons: 64, Grad norm: 1.607e+00\n",
      "Epoch 9545, Loss: 0.03436175361275673, Neurons: 64, Grad norm: 1.871e+00\n",
      "Epoch 9545, Loss: 0.03436175361275673, Neurons: 64, Grad norm: 1.871e+00\n",
      "Epoch 9546, Loss: 0.034338343888521194, Neurons: 64, Grad norm: 2.159e+00\n",
      "Epoch 9546, Loss: 0.034338343888521194, Neurons: 64, Grad norm: 2.159e+00\n",
      "Epoch 9547, Loss: 0.03431987762451172, Neurons: 64, Grad norm: 2.518e+00\n",
      "Epoch 9547, Loss: 0.03431987762451172, Neurons: 64, Grad norm: 2.518e+00\n",
      "Epoch 9548, Loss: 0.03430795297026634, Neurons: 64, Grad norm: 2.921e+00\n",
      "Epoch 9548, Loss: 0.03430795297026634, Neurons: 64, Grad norm: 2.921e+00\n",
      "Epoch 9549, Loss: 0.03430486470460892, Neurons: 64, Grad norm: 3.397e+00\n",
      "Epoch 9549, Loss: 0.03430486470460892, Neurons: 64, Grad norm: 3.397e+00\n",
      "Epoch 9550, Loss: 0.03431269899010658, Neurons: 64, Grad norm: 3.919e+00\n",
      "Epoch 9550, Loss: 0.03431269899010658, Neurons: 64, Grad norm: 3.919e+00\n",
      "Epoch 9551, Loss: 0.03433423116803169, Neurons: 64, Grad norm: 4.511e+00\n",
      "Epoch 9551, Loss: 0.03433423116803169, Neurons: 64, Grad norm: 4.511e+00\n",
      "Epoch 9552, Loss: 0.03437080606818199, Neurons: 64, Grad norm: 5.111e+00\n",
      "Epoch 9552, Loss: 0.03437080606818199, Neurons: 64, Grad norm: 5.111e+00\n",
      "Epoch 9553, Loss: 0.03442161902785301, Neurons: 64, Grad norm: 5.711e+00\n",
      "Epoch 9553, Loss: 0.03442161902785301, Neurons: 64, Grad norm: 5.711e+00\n",
      "Epoch 9554, Loss: 0.03447990491986275, Neurons: 64, Grad norm: 6.204e+00\n",
      "Epoch 9554, Loss: 0.03447990491986275, Neurons: 64, Grad norm: 6.204e+00\n",
      "Epoch 9555, Loss: 0.03453247249126434, Neurons: 64, Grad norm: 6.531e+00\n",
      "Epoch 9555, Loss: 0.03453247249126434, Neurons: 64, Grad norm: 6.531e+00\n",
      "Epoch 9556, Loss: 0.034556496888399124, Neurons: 64, Grad norm: 6.557e+00\n",
      "Epoch 9556, Loss: 0.034556496888399124, Neurons: 64, Grad norm: 6.557e+00\n",
      "Epoch 9557, Loss: 0.034526992589235306, Neurons: 64, Grad norm: 6.219e+00\n",
      "Epoch 9557, Loss: 0.034526992589235306, Neurons: 64, Grad norm: 6.219e+00\n",
      "Epoch 9558, Loss: 0.034424517303705215, Neurons: 64, Grad norm: 5.433e+00\n",
      "Epoch 9558, Loss: 0.034424517303705215, Neurons: 64, Grad norm: 5.433e+00\n",
      "Epoch 9559, Loss: 0.03425419330596924, Neurons: 64, Grad norm: 4.268e+00\n",
      "Epoch 9559, Loss: 0.03425419330596924, Neurons: 64, Grad norm: 4.268e+00\n",
      "Epoch 9560, Loss: 0.03404838591814041, Neurons: 64, Grad norm: 2.787e+00\n",
      "Epoch 9560, Loss: 0.03404838591814041, Neurons: 64, Grad norm: 2.787e+00\n",
      "Epoch 9561, Loss: 0.03385920077562332, Neurons: 64, Grad norm: 1.198e+00\n",
      "Epoch 9561, Loss: 0.03385920077562332, Neurons: 64, Grad norm: 1.198e+00\n",
      "Epoch 9562, Loss: 0.0337301567196846, Neurons: 64, Grad norm: 4.518e-01\n",
      "Epoch 9562, Loss: 0.0337301567196846, Neurons: 64, Grad norm: 4.518e-01\n",
      "Epoch 9563, Loss: 0.03367789089679718, Neurons: 64, Grad norm: 1.776e+00\n",
      "Epoch 9563, Loss: 0.03367789089679718, Neurons: 64, Grad norm: 1.776e+00\n",
      "Epoch 9564, Loss: 0.03368750214576721, Neurons: 64, Grad norm: 2.833e+00\n",
      "Epoch 9564, Loss: 0.03368750214576721, Neurons: 64, Grad norm: 2.833e+00\n",
      "Epoch 9565, Loss: 0.03372450917959213, Neurons: 64, Grad norm: 3.489e+00\n",
      "Epoch 9565, Loss: 0.03372450917959213, Neurons: 64, Grad norm: 3.489e+00\n",
      "Epoch 9566, Loss: 0.03375144675374031, Neurons: 64, Grad norm: 3.742e+00\n",
      "Epoch 9566, Loss: 0.03375144675374031, Neurons: 64, Grad norm: 3.742e+00\n",
      "Epoch 9567, Loss: 0.03374101594090462, Neurons: 64, Grad norm: 3.551e+00\n",
      "Epoch 9567, Loss: 0.03374101594090462, Neurons: 64, Grad norm: 3.551e+00\n",
      "Epoch 9568, Loss: 0.0336851105093956, Neurons: 64, Grad norm: 3.006e+00\n",
      "Epoch 9568, Loss: 0.0336851105093956, Neurons: 64, Grad norm: 3.006e+00\n",
      "Epoch 9569, Loss: 0.03359515592455864, Neurons: 64, Grad norm: 2.165e+00\n",
      "Epoch 9569, Loss: 0.03359515592455864, Neurons: 64, Grad norm: 2.165e+00\n",
      "Epoch 9570, Loss: 0.03349584713578224, Neurons: 64, Grad norm: 1.190e+00\n",
      "Epoch 9570, Loss: 0.03349584713578224, Neurons: 64, Grad norm: 1.190e+00\n",
      "Epoch 9571, Loss: 0.03341206908226013, Neurons: 64, Grad norm: 2.489e-01\n",
      "Epoch 9571, Loss: 0.03341206908226013, Neurons: 64, Grad norm: 2.489e-01\n",
      "Epoch 9572, Loss: 0.03335884213447571, Neurons: 64, Grad norm: 8.242e-01\n",
      "Epoch 9572, Loss: 0.03335884213447571, Neurons: 64, Grad norm: 8.242e-01\n",
      "Epoch 9573, Loss: 0.03333473578095436, Neurons: 64, Grad norm: 1.566e+00\n",
      "Epoch 9573, Loss: 0.03333473578095436, Neurons: 64, Grad norm: 1.566e+00\n",
      "Epoch 9574, Loss: 0.033327341079711914, Neurons: 64, Grad norm: 2.059e+00\n",
      "Epoch 9574, Loss: 0.033327341079711914, Neurons: 64, Grad norm: 2.059e+00\n",
      "Epoch 9575, Loss: 0.033319853246212006, Neurons: 64, Grad norm: 2.293e+00\n",
      "Epoch 9575, Loss: 0.033319853246212006, Neurons: 64, Grad norm: 2.293e+00\n",
      "Epoch 9576, Loss: 0.03329911828041077, Neurons: 64, Grad norm: 2.235e+00\n",
      "Epoch 9576, Loss: 0.03329911828041077, Neurons: 64, Grad norm: 2.235e+00\n",
      "Epoch 9577, Loss: 0.03326012194156647, Neurons: 64, Grad norm: 1.957e+00\n",
      "Epoch 9577, Loss: 0.03326012194156647, Neurons: 64, Grad norm: 1.957e+00\n",
      "Epoch 9578, Loss: 0.033206019550561905, Neurons: 64, Grad norm: 1.473e+00\n",
      "Epoch 9578, Loss: 0.033206019550561905, Neurons: 64, Grad norm: 1.473e+00\n",
      "Epoch 9579, Loss: 0.03314617648720741, Neurons: 64, Grad norm: 9.007e-01\n",
      "Epoch 9579, Loss: 0.03314617648720741, Neurons: 64, Grad norm: 9.007e-01\n",
      "Epoch 9580, Loss: 0.033090319484472275, Neurons: 64, Grad norm: 2.732e-01\n",
      "Epoch 9580, Loss: 0.033090319484472275, Neurons: 64, Grad norm: 2.732e-01\n",
      "Epoch 9581, Loss: 0.03304512798786163, Neurons: 64, Grad norm: 3.321e-01\n",
      "Epoch 9581, Loss: 0.03304512798786163, Neurons: 64, Grad norm: 3.321e-01\n",
      "Epoch 9582, Loss: 0.0330117903649807, Neurons: 64, Grad norm: 8.238e-01\n",
      "Epoch 9582, Loss: 0.0330117903649807, Neurons: 64, Grad norm: 8.238e-01\n",
      "Epoch 9583, Loss: 0.0329865887761116, Neurons: 64, Grad norm: 1.174e+00\n",
      "Epoch 9583, Loss: 0.0329865887761116, Neurons: 64, Grad norm: 1.174e+00\n",
      "Epoch 9584, Loss: 0.032963916659355164, Neurons: 64, Grad norm: 1.392e+00\n",
      "Epoch 9584, Loss: 0.032963916659355164, Neurons: 64, Grad norm: 1.392e+00\n",
      "Epoch 9585, Loss: 0.032938066869974136, Neurons: 64, Grad norm: 1.431e+00\n",
      "Epoch 9585, Loss: 0.032938066869974136, Neurons: 64, Grad norm: 1.431e+00\n",
      "Epoch 9586, Loss: 0.03290603682398796, Neurons: 64, Grad norm: 1.338e+00\n",
      "Epoch 9586, Loss: 0.03290603682398796, Neurons: 64, Grad norm: 1.338e+00\n",
      "Epoch 9587, Loss: 0.03286759555339813, Neurons: 64, Grad norm: 1.110e+00\n",
      "Epoch 9587, Loss: 0.03286759555339813, Neurons: 64, Grad norm: 1.110e+00\n",
      "Epoch 9588, Loss: 0.03282476216554642, Neurons: 64, Grad norm: 8.129e-01\n",
      "Epoch 9588, Loss: 0.03282476216554642, Neurons: 64, Grad norm: 8.129e-01\n",
      "Epoch 9589, Loss: 0.03278117626905441, Neurons: 64, Grad norm: 4.512e-01\n",
      "Epoch 9589, Loss: 0.03278117626905441, Neurons: 64, Grad norm: 4.512e-01\n",
      "Epoch 9590, Loss: 0.03273990750312805, Neurons: 64, Grad norm: 1.179e-01\n",
      "Epoch 9590, Loss: 0.03273990750312805, Neurons: 64, Grad norm: 1.179e-01\n",
      "Epoch 9591, Loss: 0.032702602446079254, Neurons: 64, Grad norm: 2.603e-01\n",
      "Epoch 9591, Loss: 0.032702602446079254, Neurons: 64, Grad norm: 2.603e-01\n",
      "Epoch 9592, Loss: 0.03266921639442444, Neurons: 64, Grad norm: 5.249e-01\n",
      "Epoch 9592, Loss: 0.03266921639442444, Neurons: 64, Grad norm: 5.249e-01\n",
      "Epoch 9593, Loss: 0.032638534903526306, Neurons: 64, Grad norm: 7.397e-01\n",
      "Epoch 9593, Loss: 0.032638534903526306, Neurons: 64, Grad norm: 7.397e-01\n",
      "Epoch 9594, Loss: 0.032608963549137115, Neurons: 64, Grad norm: 8.618e-01\n",
      "Epoch 9594, Loss: 0.032608963549137115, Neurons: 64, Grad norm: 8.618e-01\n",
      "Epoch 9595, Loss: 0.032578397542238235, Neurons: 64, Grad norm: 9.134e-01\n",
      "Epoch 9595, Loss: 0.032578397542238235, Neurons: 64, Grad norm: 9.134e-01\n",
      "Epoch 9596, Loss: 0.03254600986838341, Neurons: 64, Grad norm: 8.677e-01\n",
      "Epoch 9596, Loss: 0.03254600986838341, Neurons: 64, Grad norm: 8.677e-01\n",
      "Epoch 9597, Loss: 0.0325116403400898, Neurons: 64, Grad norm: 7.786e-01\n",
      "Epoch 9597, Loss: 0.0325116403400898, Neurons: 64, Grad norm: 7.786e-01\n",
      "Epoch 9598, Loss: 0.032475631684064865, Neurons: 64, Grad norm: 6.260e-01\n",
      "Epoch 9598, Loss: 0.032475631684064865, Neurons: 64, Grad norm: 6.260e-01\n",
      "Epoch 9599, Loss: 0.03243914619088173, Neurons: 64, Grad norm: 4.544e-01\n",
      "Epoch 9599, Loss: 0.03243914619088173, Neurons: 64, Grad norm: 4.544e-01\n",
      "Epoch 9599, Test loss: 0.020937254652380943\n",
      "Epoch 9599, Test loss: 0.020937254652380943\n",
      "Epoch 9600, Loss: 0.0324028879404068, Neurons: 64, Grad norm: 2.570e-01\n",
      "Epoch 9600, Loss: 0.0324028879404068, Neurons: 64, Grad norm: 2.570e-01\n",
      "Epoch 9601, Loss: 0.03236747160553932, Neurons: 64, Grad norm: 1.351e-01\n",
      "Epoch 9601, Loss: 0.03236747160553932, Neurons: 64, Grad norm: 1.351e-01\n",
      "Epoch 9602, Loss: 0.03233327716588974, Neurons: 64, Grad norm: 2.067e-01\n",
      "Epoch 9602, Loss: 0.03233327716588974, Neurons: 64, Grad norm: 2.067e-01\n",
      "Epoch 9603, Loss: 0.03230013698339462, Neurons: 64, Grad norm: 3.389e-01\n",
      "Epoch 9603, Loss: 0.03230013698339462, Neurons: 64, Grad norm: 3.389e-01\n",
      "Epoch 9604, Loss: 0.03226796165108681, Neurons: 64, Grad norm: 4.748e-01\n",
      "Epoch 9604, Loss: 0.03226796165108681, Neurons: 64, Grad norm: 4.748e-01\n",
      "Epoch 9605, Loss: 0.032236017286777496, Neurons: 64, Grad norm: 5.541e-01\n",
      "Epoch 9605, Loss: 0.032236017286777496, Neurons: 64, Grad norm: 5.541e-01\n",
      "Epoch 9606, Loss: 0.03220430761575699, Neurons: 64, Grad norm: 6.133e-01\n",
      "Epoch 9606, Loss: 0.03220430761575699, Neurons: 64, Grad norm: 6.133e-01\n",
      "Epoch 9607, Loss: 0.03217215836048126, Neurons: 64, Grad norm: 6.240e-01\n",
      "Epoch 9607, Loss: 0.03217215836048126, Neurons: 64, Grad norm: 6.240e-01\n",
      "Epoch 9608, Loss: 0.032139427959918976, Neurons: 64, Grad norm: 6.210e-01\n",
      "Epoch 9608, Loss: 0.032139427959918976, Neurons: 64, Grad norm: 6.210e-01\n",
      "Epoch 9609, Loss: 0.032106317579746246, Neurons: 64, Grad norm: 5.742e-01\n",
      "Epoch 9609, Loss: 0.032106317579746246, Neurons: 64, Grad norm: 5.742e-01\n",
      "Epoch 9610, Loss: 0.032072924077510834, Neurons: 64, Grad norm: 5.298e-01\n",
      "Epoch 9610, Loss: 0.032072924077510834, Neurons: 64, Grad norm: 5.298e-01\n",
      "Epoch 9611, Loss: 0.032039545476436615, Neurons: 64, Grad norm: 4.629e-01\n",
      "Epoch 9611, Loss: 0.032039545476436615, Neurons: 64, Grad norm: 4.629e-01\n",
      "Epoch 9612, Loss: 0.03200632706284523, Neurons: 64, Grad norm: 4.152e-01\n",
      "Epoch 9612, Loss: 0.03200632706284523, Neurons: 64, Grad norm: 4.152e-01\n",
      "Epoch 9613, Loss: 0.03197329863905907, Neurons: 64, Grad norm: 3.654e-01\n",
      "Epoch 9613, Loss: 0.03197329863905907, Neurons: 64, Grad norm: 3.654e-01\n",
      "Epoch 9614, Loss: 0.031941007822752, Neurons: 64, Grad norm: 3.424e-01\n",
      "Epoch 9614, Loss: 0.031941007822752, Neurons: 64, Grad norm: 3.424e-01\n",
      "Epoch 9615, Loss: 0.03190882131457329, Neurons: 64, Grad norm: 3.369e-01\n",
      "Epoch 9615, Loss: 0.03190882131457329, Neurons: 64, Grad norm: 3.369e-01\n",
      "Epoch 9616, Loss: 0.03187711909413338, Neurons: 64, Grad norm: 3.508e-01\n",
      "Epoch 9616, Loss: 0.03187711909413338, Neurons: 64, Grad norm: 3.508e-01\n",
      "Epoch 9617, Loss: 0.03184553608298302, Neurons: 64, Grad norm: 3.837e-01\n",
      "Epoch 9617, Loss: 0.03184553608298302, Neurons: 64, Grad norm: 3.837e-01\n",
      "Epoch 9618, Loss: 0.03181438148021698, Neurons: 64, Grad norm: 4.124e-01\n",
      "Epoch 9618, Loss: 0.03181438148021698, Neurons: 64, Grad norm: 4.124e-01\n",
      "Epoch 9619, Loss: 0.0317833237349987, Neurons: 64, Grad norm: 4.506e-01\n",
      "Epoch 9619, Loss: 0.0317833237349987, Neurons: 64, Grad norm: 4.506e-01\n",
      "Epoch 9620, Loss: 0.03175264596939087, Neurons: 64, Grad norm: 4.819e-01\n",
      "Epoch 9620, Loss: 0.03175264596939087, Neurons: 64, Grad norm: 4.819e-01\n",
      "Epoch 9621, Loss: 0.03172196447849274, Neurons: 64, Grad norm: 5.195e-01\n",
      "Epoch 9621, Loss: 0.03172196447849274, Neurons: 64, Grad norm: 5.195e-01\n",
      "Epoch 9622, Loss: 0.03169212117791176, Neurons: 64, Grad norm: 5.514e-01\n",
      "Epoch 9622, Loss: 0.03169212117791176, Neurons: 64, Grad norm: 5.514e-01\n",
      "Epoch 9623, Loss: 0.03166233003139496, Neurons: 64, Grad norm: 5.890e-01\n",
      "Epoch 9623, Loss: 0.03166233003139496, Neurons: 64, Grad norm: 5.890e-01\n",
      "Epoch 9624, Loss: 0.03163321316242218, Neurons: 64, Grad norm: 6.250e-01\n",
      "Epoch 9624, Loss: 0.03163321316242218, Neurons: 64, Grad norm: 6.250e-01\n",
      "Epoch 9625, Loss: 0.031604085117578506, Neurons: 64, Grad norm: 6.634e-01\n",
      "Epoch 9625, Loss: 0.031604085117578506, Neurons: 64, Grad norm: 6.634e-01\n",
      "Epoch 9626, Loss: 0.03157572075724602, Neurons: 64, Grad norm: 6.993e-01\n",
      "Epoch 9626, Loss: 0.03157572075724602, Neurons: 64, Grad norm: 6.993e-01\n",
      "Epoch 9627, Loss: 0.03154720738530159, Neurons: 64, Grad norm: 7.365e-01\n",
      "Epoch 9627, Loss: 0.03154720738530159, Neurons: 64, Grad norm: 7.365e-01\n",
      "Epoch 9628, Loss: 0.03151823207736015, Neurons: 64, Grad norm: 7.666e-01\n",
      "Epoch 9628, Loss: 0.03151823207736015, Neurons: 64, Grad norm: 7.666e-01\n",
      "Epoch 9629, Loss: 0.03148869052529335, Neurons: 64, Grad norm: 7.962e-01\n",
      "Epoch 9629, Loss: 0.03148869052529335, Neurons: 64, Grad norm: 7.962e-01\n",
      "Epoch 9630, Loss: 0.03145865350961685, Neurons: 64, Grad norm: 8.204e-01\n",
      "Epoch 9630, Loss: 0.03145865350961685, Neurons: 64, Grad norm: 8.204e-01\n",
      "Epoch 9631, Loss: 0.03142743185162544, Neurons: 64, Grad norm: 8.345e-01\n",
      "Epoch 9631, Loss: 0.03142743185162544, Neurons: 64, Grad norm: 8.345e-01\n",
      "Epoch 9632, Loss: 0.03139573708176613, Neurons: 64, Grad norm: 8.556e-01\n",
      "Epoch 9632, Loss: 0.03139573708176613, Neurons: 64, Grad norm: 8.556e-01\n",
      "Epoch 9633, Loss: 0.03136257454752922, Neurons: 64, Grad norm: 8.632e-01\n",
      "Epoch 9633, Loss: 0.03136257454752922, Neurons: 64, Grad norm: 8.632e-01\n",
      "Epoch 9634, Loss: 0.031328897923231125, Neurons: 64, Grad norm: 8.679e-01\n",
      "Epoch 9634, Loss: 0.031328897923231125, Neurons: 64, Grad norm: 8.679e-01\n",
      "Epoch 9635, Loss: 0.03129393234848976, Neurons: 64, Grad norm: 8.610e-01\n",
      "Epoch 9635, Loss: 0.03129393234848976, Neurons: 64, Grad norm: 8.610e-01\n",
      "Epoch 9636, Loss: 0.03125805780291557, Neurons: 64, Grad norm: 8.685e-01\n",
      "Epoch 9636, Loss: 0.03125805780291557, Neurons: 64, Grad norm: 8.685e-01\n",
      "Epoch 9637, Loss: 0.031221609562635422, Neurons: 64, Grad norm: 8.662e-01\n",
      "Epoch 9637, Loss: 0.031221609562635422, Neurons: 64, Grad norm: 8.662e-01\n",
      "Epoch 9638, Loss: 0.03118533454835415, Neurons: 64, Grad norm: 8.801e-01\n",
      "Epoch 9638, Loss: 0.03118533454835415, Neurons: 64, Grad norm: 8.801e-01\n",
      "Epoch 9639, Loss: 0.03115004114806652, Neurons: 64, Grad norm: 8.965e-01\n",
      "Epoch 9639, Loss: 0.03115004114806652, Neurons: 64, Grad norm: 8.965e-01\n",
      "Epoch 9640, Loss: 0.03111586906015873, Neurons: 64, Grad norm: 9.446e-01\n",
      "Epoch 9640, Loss: 0.03111586906015873, Neurons: 64, Grad norm: 9.446e-01\n",
      "Epoch 9641, Loss: 0.031083127483725548, Neurons: 64, Grad norm: 9.831e-01\n",
      "Epoch 9641, Loss: 0.031083127483725548, Neurons: 64, Grad norm: 9.831e-01\n",
      "Epoch 9642, Loss: 0.031052004545927048, Neurons: 64, Grad norm: 1.055e+00\n",
      "Epoch 9642, Loss: 0.031052004545927048, Neurons: 64, Grad norm: 1.055e+00\n",
      "Epoch 9643, Loss: 0.031022166833281517, Neurons: 64, Grad norm: 1.119e+00\n",
      "Epoch 9643, Loss: 0.031022166833281517, Neurons: 64, Grad norm: 1.119e+00\n",
      "Epoch 9644, Loss: 0.03099343553185463, Neurons: 64, Grad norm: 1.211e+00\n",
      "Epoch 9644, Loss: 0.03099343553185463, Neurons: 64, Grad norm: 1.211e+00\n",
      "Epoch 9645, Loss: 0.03096567653119564, Neurons: 64, Grad norm: 1.296e+00\n",
      "Epoch 9645, Loss: 0.03096567653119564, Neurons: 64, Grad norm: 1.296e+00\n",
      "Epoch 9646, Loss: 0.030938688665628433, Neurons: 64, Grad norm: 1.406e+00\n",
      "Epoch 9646, Loss: 0.030938688665628433, Neurons: 64, Grad norm: 1.406e+00\n",
      "Epoch 9647, Loss: 0.030912650749087334, Neurons: 64, Grad norm: 1.504e+00\n",
      "Epoch 9647, Loss: 0.030912650749087334, Neurons: 64, Grad norm: 1.504e+00\n",
      "Epoch 9648, Loss: 0.03088705614209175, Neurons: 64, Grad norm: 1.633e+00\n",
      "Epoch 9648, Loss: 0.03088705614209175, Neurons: 64, Grad norm: 1.633e+00\n",
      "Epoch 9649, Loss: 0.030862418934702873, Neurons: 64, Grad norm: 1.757e+00\n",
      "Epoch 9649, Loss: 0.030862418934702873, Neurons: 64, Grad norm: 1.757e+00\n",
      "Epoch 9650, Loss: 0.03083839826285839, Neurons: 64, Grad norm: 1.912e+00\n",
      "Epoch 9650, Loss: 0.03083839826285839, Neurons: 64, Grad norm: 1.912e+00\n",
      "Epoch 9651, Loss: 0.0308156106621027, Neurons: 64, Grad norm: 2.061e+00\n",
      "Epoch 9651, Loss: 0.0308156106621027, Neurons: 64, Grad norm: 2.061e+00\n",
      "Epoch 9652, Loss: 0.03079392947256565, Neurons: 64, Grad norm: 2.252e+00\n",
      "Epoch 9652, Loss: 0.03079392947256565, Neurons: 64, Grad norm: 2.252e+00\n",
      "Epoch 9653, Loss: 0.030774131417274475, Neurons: 64, Grad norm: 2.442e+00\n",
      "Epoch 9653, Loss: 0.030774131417274475, Neurons: 64, Grad norm: 2.442e+00\n",
      "Epoch 9654, Loss: 0.030756352469325066, Neurons: 64, Grad norm: 2.672e+00\n",
      "Epoch 9654, Loss: 0.030756352469325066, Neurons: 64, Grad norm: 2.672e+00\n",
      "Epoch 9655, Loss: 0.030741333961486816, Neurons: 64, Grad norm: 2.899e+00\n",
      "Epoch 9655, Loss: 0.030741333961486816, Neurons: 64, Grad norm: 2.899e+00\n",
      "Epoch 9656, Loss: 0.030729664489626884, Neurons: 64, Grad norm: 3.171e+00\n",
      "Epoch 9656, Loss: 0.030729664489626884, Neurons: 64, Grad norm: 3.171e+00\n",
      "Epoch 9657, Loss: 0.030721515417099, Neurons: 64, Grad norm: 3.435e+00\n",
      "Epoch 9657, Loss: 0.030721515417099, Neurons: 64, Grad norm: 3.435e+00\n",
      "Epoch 9658, Loss: 0.03071693517267704, Neurons: 64, Grad norm: 3.719e+00\n",
      "Epoch 9658, Loss: 0.03071693517267704, Neurons: 64, Grad norm: 3.719e+00\n",
      "Epoch 9659, Loss: 0.030715608969330788, Neurons: 64, Grad norm: 3.982e+00\n",
      "Epoch 9659, Loss: 0.030715608969330788, Neurons: 64, Grad norm: 3.982e+00\n",
      "Epoch 9660, Loss: 0.030716294422745705, Neurons: 64, Grad norm: 4.241e+00\n",
      "Epoch 9660, Loss: 0.030716294422745705, Neurons: 64, Grad norm: 4.241e+00\n",
      "Epoch 9661, Loss: 0.03071722947061062, Neurons: 64, Grad norm: 4.434e+00\n",
      "Epoch 9661, Loss: 0.03071722947061062, Neurons: 64, Grad norm: 4.434e+00\n",
      "Epoch 9662, Loss: 0.03071519359946251, Neurons: 64, Grad norm: 4.575e+00\n",
      "Epoch 9662, Loss: 0.03071519359946251, Neurons: 64, Grad norm: 4.575e+00\n",
      "Epoch 9663, Loss: 0.030705802142620087, Neurons: 64, Grad norm: 4.597e+00\n",
      "Epoch 9663, Loss: 0.030705802142620087, Neurons: 64, Grad norm: 4.597e+00\n",
      "Epoch 9664, Loss: 0.030684111639857292, Neurons: 64, Grad norm: 4.513e+00\n",
      "Epoch 9664, Loss: 0.030684111639857292, Neurons: 64, Grad norm: 4.513e+00\n",
      "Epoch 9665, Loss: 0.0306457057595253, Neurons: 64, Grad norm: 4.262e+00\n",
      "Epoch 9665, Loss: 0.0306457057595253, Neurons: 64, Grad norm: 4.262e+00\n",
      "Epoch 9666, Loss: 0.030589012429118156, Neurons: 64, Grad norm: 3.875e+00\n",
      "Epoch 9666, Loss: 0.030589012429118156, Neurons: 64, Grad norm: 3.875e+00\n",
      "Epoch 9667, Loss: 0.030514560639858246, Neurons: 64, Grad norm: 3.324e+00\n",
      "Epoch 9667, Loss: 0.030514560639858246, Neurons: 64, Grad norm: 3.324e+00\n",
      "Epoch 9668, Loss: 0.030428659170866013, Neurons: 64, Grad norm: 2.673e+00\n",
      "Epoch 9668, Loss: 0.030428659170866013, Neurons: 64, Grad norm: 2.673e+00\n",
      "Epoch 9669, Loss: 0.03033909760415554, Neurons: 64, Grad norm: 1.927e+00\n",
      "Epoch 9669, Loss: 0.03033909760415554, Neurons: 64, Grad norm: 1.927e+00\n",
      "Epoch 9670, Loss: 0.030256157740950584, Neurons: 64, Grad norm: 1.185e+00\n",
      "Epoch 9670, Loss: 0.030256157740950584, Neurons: 64, Grad norm: 1.185e+00\n",
      "Epoch 9671, Loss: 0.030187005177140236, Neurons: 64, Grad norm: 5.433e-01\n",
      "Epoch 9671, Loss: 0.030187005177140236, Neurons: 64, Grad norm: 5.433e-01\n",
      "Epoch 9672, Loss: 0.030135346576571465, Neurons: 64, Grad norm: 5.875e-01\n",
      "Epoch 9672, Loss: 0.030135346576571465, Neurons: 64, Grad norm: 5.875e-01\n",
      "Epoch 9673, Loss: 0.03010118566453457, Neurons: 64, Grad norm: 1.125e+00\n",
      "Epoch 9673, Loss: 0.03010118566453457, Neurons: 64, Grad norm: 1.125e+00\n",
      "Epoch 9674, Loss: 0.030080823227763176, Neurons: 64, Grad norm: 1.605e+00\n",
      "Epoch 9674, Loss: 0.030080823227763176, Neurons: 64, Grad norm: 1.605e+00\n",
      "Epoch 9675, Loss: 0.03006870113313198, Neurons: 64, Grad norm: 2.000e+00\n",
      "Epoch 9675, Loss: 0.03006870113313198, Neurons: 64, Grad norm: 2.000e+00\n",
      "Epoch 9676, Loss: 0.03005846217274666, Neurons: 64, Grad norm: 2.239e+00\n",
      "Epoch 9676, Loss: 0.03005846217274666, Neurons: 64, Grad norm: 2.239e+00\n",
      "Epoch 9677, Loss: 0.03004477173089981, Neurons: 64, Grad norm: 2.368e+00\n",
      "Epoch 9677, Loss: 0.03004477173089981, Neurons: 64, Grad norm: 2.368e+00\n",
      "Epoch 9678, Loss: 0.030024148523807526, Neurons: 64, Grad norm: 2.351e+00\n",
      "Epoch 9678, Loss: 0.030024148523807526, Neurons: 64, Grad norm: 2.351e+00\n",
      "Epoch 9679, Loss: 0.029994994401931763, Neurons: 64, Grad norm: 2.234e+00\n",
      "Epoch 9679, Loss: 0.029994994401931763, Neurons: 64, Grad norm: 2.234e+00\n",
      "Epoch 9680, Loss: 0.029957465827465057, Neurons: 64, Grad norm: 2.000e+00\n",
      "Epoch 9680, Loss: 0.029957465827465057, Neurons: 64, Grad norm: 2.000e+00\n",
      "Epoch 9681, Loss: 0.02991432137787342, Neurons: 64, Grad norm: 1.709e+00\n",
      "Epoch 9681, Loss: 0.02991432137787342, Neurons: 64, Grad norm: 1.709e+00\n",
      "Epoch 9682, Loss: 0.029868176206946373, Neurons: 64, Grad norm: 1.340e+00\n",
      "Epoch 9682, Loss: 0.029868176206946373, Neurons: 64, Grad norm: 1.340e+00\n",
      "Epoch 9683, Loss: 0.029822275042533875, Neurons: 64, Grad norm: 9.665e-01\n",
      "Epoch 9683, Loss: 0.029822275042533875, Neurons: 64, Grad norm: 9.665e-01\n",
      "Epoch 9684, Loss: 0.029779355973005295, Neurons: 64, Grad norm: 5.710e-01\n",
      "Epoch 9684, Loss: 0.029779355973005295, Neurons: 64, Grad norm: 5.710e-01\n",
      "Epoch 9685, Loss: 0.029740571975708008, Neurons: 64, Grad norm: 2.195e-01\n",
      "Epoch 9685, Loss: 0.029740571975708008, Neurons: 64, Grad norm: 2.195e-01\n",
      "Epoch 9686, Loss: 0.029706554487347603, Neurons: 64, Grad norm: 2.297e-01\n",
      "Epoch 9686, Loss: 0.029706554487347603, Neurons: 64, Grad norm: 2.297e-01\n",
      "Epoch 9687, Loss: 0.029676953330636024, Neurons: 64, Grad norm: 4.985e-01\n",
      "Epoch 9687, Loss: 0.029676953330636024, Neurons: 64, Grad norm: 4.985e-01\n",
      "Epoch 9688, Loss: 0.029650511220097542, Neurons: 64, Grad norm: 7.619e-01\n",
      "Epoch 9688, Loss: 0.029650511220097542, Neurons: 64, Grad norm: 7.619e-01\n",
      "Epoch 9689, Loss: 0.029625890776515007, Neurons: 64, Grad norm: 9.620e-01\n",
      "Epoch 9689, Loss: 0.029625890776515007, Neurons: 64, Grad norm: 9.620e-01\n",
      "Epoch 9690, Loss: 0.029601972550153732, Neurons: 64, Grad norm: 1.123e+00\n",
      "Epoch 9690, Loss: 0.029601972550153732, Neurons: 64, Grad norm: 1.123e+00\n",
      "Epoch 9691, Loss: 0.029577698558568954, Neurons: 64, Grad norm: 1.213e+00\n",
      "Epoch 9691, Loss: 0.029577698558568954, Neurons: 64, Grad norm: 1.213e+00\n",
      "Epoch 9692, Loss: 0.029552211984992027, Neurons: 64, Grad norm: 1.277e+00\n",
      "Epoch 9692, Loss: 0.029552211984992027, Neurons: 64, Grad norm: 1.277e+00\n",
      "Epoch 9693, Loss: 0.029525140300393105, Neurons: 64, Grad norm: 1.274e+00\n",
      "Epoch 9693, Loss: 0.029525140300393105, Neurons: 64, Grad norm: 1.274e+00\n",
      "Epoch 9694, Loss: 0.02949654497206211, Neurons: 64, Grad norm: 1.260e+00\n",
      "Epoch 9694, Loss: 0.02949654497206211, Neurons: 64, Grad norm: 1.260e+00\n",
      "Epoch 9695, Loss: 0.029466580599546432, Neurons: 64, Grad norm: 1.186e+00\n",
      "Epoch 9695, Loss: 0.029466580599546432, Neurons: 64, Grad norm: 1.186e+00\n",
      "Epoch 9696, Loss: 0.029435498639941216, Neurons: 64, Grad norm: 1.107e+00\n",
      "Epoch 9696, Loss: 0.029435498639941216, Neurons: 64, Grad norm: 1.107e+00\n",
      "Epoch 9697, Loss: 0.02940378338098526, Neurons: 64, Grad norm: 9.959e-01\n",
      "Epoch 9697, Loss: 0.02940378338098526, Neurons: 64, Grad norm: 9.959e-01\n",
      "Epoch 9698, Loss: 0.0293718371540308, Neurons: 64, Grad norm: 8.925e-01\n",
      "Epoch 9698, Loss: 0.0293718371540308, Neurons: 64, Grad norm: 8.925e-01\n",
      "Epoch 9699, Loss: 0.02933984063565731, Neurons: 64, Grad norm: 7.600e-01\n",
      "Epoch 9699, Loss: 0.02933984063565731, Neurons: 64, Grad norm: 7.600e-01\n",
      "Epoch 9699, Test loss: 0.01888193003833294\n",
      "Epoch 9699, Test loss: 0.01888193003833294\n",
      "Epoch 9700, Loss: 0.029308248311281204, Neurons: 64, Grad norm: 6.484e-01\n",
      "Epoch 9700, Loss: 0.029308248311281204, Neurons: 64, Grad norm: 6.484e-01\n",
      "Epoch 9701, Loss: 0.029277123510837555, Neurons: 64, Grad norm: 5.242e-01\n",
      "Epoch 9701, Loss: 0.029277123510837555, Neurons: 64, Grad norm: 5.242e-01\n",
      "Epoch 9702, Loss: 0.029246624559164047, Neurons: 64, Grad norm: 4.268e-01\n",
      "Epoch 9702, Loss: 0.029246624559164047, Neurons: 64, Grad norm: 4.268e-01\n",
      "Epoch 9703, Loss: 0.029216600582003593, Neurons: 64, Grad norm: 3.182e-01\n",
      "Epoch 9703, Loss: 0.029216600582003593, Neurons: 64, Grad norm: 3.182e-01\n",
      "Epoch 9704, Loss: 0.029187088832259178, Neurons: 64, Grad norm: 2.486e-01\n",
      "Epoch 9704, Loss: 0.029187088832259178, Neurons: 64, Grad norm: 2.486e-01\n",
      "Epoch 9705, Loss: 0.029158223420381546, Neurons: 64, Grad norm: 1.825e-01\n",
      "Epoch 9705, Loss: 0.029158223420381546, Neurons: 64, Grad norm: 1.825e-01\n",
      "Epoch 9706, Loss: 0.029129555448889732, Neurons: 64, Grad norm: 1.684e-01\n",
      "Epoch 9706, Loss: 0.029129555448889732, Neurons: 64, Grad norm: 1.684e-01\n",
      "Epoch 9707, Loss: 0.029101276770234108, Neurons: 64, Grad norm: 1.831e-01\n",
      "Epoch 9707, Loss: 0.029101276770234108, Neurons: 64, Grad norm: 1.831e-01\n",
      "Epoch 9708, Loss: 0.029073495417833328, Neurons: 64, Grad norm: 2.215e-01\n",
      "Epoch 9708, Loss: 0.029073495417833328, Neurons: 64, Grad norm: 2.215e-01\n",
      "Epoch 9709, Loss: 0.029045941308140755, Neurons: 64, Grad norm: 2.690e-01\n",
      "Epoch 9709, Loss: 0.029045941308140755, Neurons: 64, Grad norm: 2.690e-01\n",
      "Epoch 9710, Loss: 0.029018636792898178, Neurons: 64, Grad norm: 3.120e-01\n",
      "Epoch 9710, Loss: 0.029018636792898178, Neurons: 64, Grad norm: 3.120e-01\n",
      "Epoch 9711, Loss: 0.028991466388106346, Neurons: 64, Grad norm: 3.595e-01\n",
      "Epoch 9711, Loss: 0.028991466388106346, Neurons: 64, Grad norm: 3.595e-01\n",
      "Epoch 9712, Loss: 0.028964420780539513, Neurons: 64, Grad norm: 3.950e-01\n",
      "Epoch 9712, Loss: 0.028964420780539513, Neurons: 64, Grad norm: 3.950e-01\n",
      "Epoch 9713, Loss: 0.028937825933098793, Neurons: 64, Grad norm: 4.384e-01\n",
      "Epoch 9713, Loss: 0.028937825933098793, Neurons: 64, Grad norm: 4.384e-01\n",
      "Epoch 9714, Loss: 0.02891128696501255, Neurons: 64, Grad norm: 4.692e-01\n",
      "Epoch 9714, Loss: 0.02891128696501255, Neurons: 64, Grad norm: 4.692e-01\n",
      "Epoch 9715, Loss: 0.028884990140795708, Neurons: 64, Grad norm: 5.047e-01\n",
      "Epoch 9715, Loss: 0.028884990140795708, Neurons: 64, Grad norm: 5.047e-01\n",
      "Epoch 9716, Loss: 0.02885877713561058, Neurons: 64, Grad norm: 5.362e-01\n",
      "Epoch 9716, Loss: 0.02885877713561058, Neurons: 64, Grad norm: 5.362e-01\n",
      "Epoch 9717, Loss: 0.028833279386162758, Neurons: 64, Grad norm: 5.810e-01\n",
      "Epoch 9717, Loss: 0.028833279386162758, Neurons: 64, Grad norm: 5.810e-01\n",
      "Epoch 9718, Loss: 0.028808195143938065, Neurons: 64, Grad norm: 6.176e-01\n",
      "Epoch 9718, Loss: 0.028808195143938065, Neurons: 64, Grad norm: 6.176e-01\n",
      "Epoch 9719, Loss: 0.02878406271338463, Neurons: 64, Grad norm: 6.639e-01\n",
      "Epoch 9719, Loss: 0.02878406271338463, Neurons: 64, Grad norm: 6.639e-01\n",
      "Epoch 9720, Loss: 0.028760403394699097, Neurons: 64, Grad norm: 7.084e-01\n",
      "Epoch 9720, Loss: 0.028760403394699097, Neurons: 64, Grad norm: 7.084e-01\n",
      "Epoch 9721, Loss: 0.02873723953962326, Neurons: 64, Grad norm: 7.532e-01\n",
      "Epoch 9721, Loss: 0.02873723953962326, Neurons: 64, Grad norm: 7.532e-01\n",
      "Epoch 9722, Loss: 0.028714651241898537, Neurons: 64, Grad norm: 7.962e-01\n",
      "Epoch 9722, Loss: 0.028714651241898537, Neurons: 64, Grad norm: 7.962e-01\n",
      "Epoch 9723, Loss: 0.028692372143268585, Neurons: 64, Grad norm: 8.420e-01\n",
      "Epoch 9723, Loss: 0.028692372143268585, Neurons: 64, Grad norm: 8.420e-01\n",
      "Epoch 9724, Loss: 0.028670430183410645, Neurons: 64, Grad norm: 8.917e-01\n",
      "Epoch 9724, Loss: 0.028670430183410645, Neurons: 64, Grad norm: 8.917e-01\n",
      "Epoch 9725, Loss: 0.028649697080254555, Neurons: 64, Grad norm: 9.397e-01\n",
      "Epoch 9725, Loss: 0.028649697080254555, Neurons: 64, Grad norm: 9.397e-01\n",
      "Epoch 9726, Loss: 0.02862858958542347, Neurons: 64, Grad norm: 9.886e-01\n",
      "Epoch 9726, Loss: 0.02862858958542347, Neurons: 64, Grad norm: 9.886e-01\n",
      "Epoch 9727, Loss: 0.02860788069665432, Neurons: 64, Grad norm: 1.033e+00\n",
      "Epoch 9727, Loss: 0.02860788069665432, Neurons: 64, Grad norm: 1.033e+00\n",
      "Epoch 9728, Loss: 0.028585808351635933, Neurons: 64, Grad norm: 1.073e+00\n",
      "Epoch 9728, Loss: 0.028585808351635933, Neurons: 64, Grad norm: 1.073e+00\n",
      "Epoch 9729, Loss: 0.02856198325753212, Neurons: 64, Grad norm: 1.100e+00\n",
      "Epoch 9729, Loss: 0.02856198325753212, Neurons: 64, Grad norm: 1.100e+00\n",
      "Epoch 9730, Loss: 0.02853521518409252, Neurons: 64, Grad norm: 1.139e+00\n",
      "Epoch 9730, Loss: 0.02853521518409252, Neurons: 64, Grad norm: 1.139e+00\n",
      "Epoch 9731, Loss: 0.02850501425564289, Neurons: 64, Grad norm: 1.173e+00\n",
      "Epoch 9731, Loss: 0.02850501425564289, Neurons: 64, Grad norm: 1.173e+00\n",
      "Epoch 9732, Loss: 0.028472373262047768, Neurons: 64, Grad norm: 1.260e+00\n",
      "Epoch 9732, Loss: 0.028472373262047768, Neurons: 64, Grad norm: 1.260e+00\n",
      "Epoch 9733, Loss: 0.028438249602913857, Neurons: 64, Grad norm: 1.373e+00\n",
      "Epoch 9733, Loss: 0.028438249602913857, Neurons: 64, Grad norm: 1.373e+00\n",
      "Epoch 9734, Loss: 0.02840495854616165, Neurons: 64, Grad norm: 1.576e+00\n",
      "Epoch 9734, Loss: 0.02840495854616165, Neurons: 64, Grad norm: 1.576e+00\n",
      "Epoch 9735, Loss: 0.028375880792737007, Neurons: 64, Grad norm: 1.833e+00\n",
      "Epoch 9735, Loss: 0.028375880792737007, Neurons: 64, Grad norm: 1.833e+00\n",
      "Epoch 9736, Loss: 0.028353678062558174, Neurons: 64, Grad norm: 2.193e+00\n",
      "Epoch 9736, Loss: 0.028353678062558174, Neurons: 64, Grad norm: 2.193e+00\n",
      "Epoch 9737, Loss: 0.028341729193925858, Neurons: 64, Grad norm: 2.610e+00\n",
      "Epoch 9737, Loss: 0.028341729193925858, Neurons: 64, Grad norm: 2.610e+00\n",
      "Epoch 9738, Loss: 0.02834220789372921, Neurons: 64, Grad norm: 3.123e+00\n",
      "Epoch 9738, Loss: 0.02834220789372921, Neurons: 64, Grad norm: 3.123e+00\n",
      "Epoch 9739, Loss: 0.028357548639178276, Neurons: 64, Grad norm: 3.691e+00\n",
      "Epoch 9739, Loss: 0.028357548639178276, Neurons: 64, Grad norm: 3.691e+00\n",
      "Epoch 9740, Loss: 0.02839064598083496, Neurons: 64, Grad norm: 4.359e+00\n",
      "Epoch 9740, Loss: 0.02839064598083496, Neurons: 64, Grad norm: 4.359e+00\n",
      "Epoch 9741, Loss: 0.02844354696571827, Neurons: 64, Grad norm: 5.064e+00\n",
      "Epoch 9741, Loss: 0.02844354696571827, Neurons: 64, Grad norm: 5.064e+00\n",
      "Epoch 9742, Loss: 0.028518132865428925, Neurons: 64, Grad norm: 5.813e+00\n",
      "Epoch 9742, Loss: 0.028518132865428925, Neurons: 64, Grad norm: 5.813e+00\n",
      "Epoch 9743, Loss: 0.02861160598695278, Neurons: 64, Grad norm: 6.513e+00\n",
      "Epoch 9743, Loss: 0.02861160598695278, Neurons: 64, Grad norm: 6.513e+00\n",
      "Epoch 9744, Loss: 0.028714433312416077, Neurons: 64, Grad norm: 7.110e+00\n",
      "Epoch 9744, Loss: 0.028714433312416077, Neurons: 64, Grad norm: 7.110e+00\n",
      "Epoch 9745, Loss: 0.02880415879189968, Neurons: 64, Grad norm: 7.429e+00\n",
      "Epoch 9745, Loss: 0.02880415879189968, Neurons: 64, Grad norm: 7.429e+00\n",
      "Epoch 9746, Loss: 0.028848500922322273, Neurons: 64, Grad norm: 7.378e+00\n",
      "Epoch 9746, Loss: 0.028848500922322273, Neurons: 64, Grad norm: 7.378e+00\n",
      "Epoch 9747, Loss: 0.02880815975368023, Neurons: 64, Grad norm: 6.795e+00\n",
      "Epoch 9747, Loss: 0.02880815975368023, Neurons: 64, Grad norm: 6.795e+00\n",
      "Epoch 9748, Loss: 0.0286644846200943, Neurons: 64, Grad norm: 5.686e+00\n",
      "Epoch 9748, Loss: 0.0286644846200943, Neurons: 64, Grad norm: 5.686e+00\n",
      "Epoch 9749, Loss: 0.028434835374355316, Neurons: 64, Grad norm: 4.083e+00\n",
      "Epoch 9749, Loss: 0.028434835374355316, Neurons: 64, Grad norm: 4.083e+00\n",
      "Epoch 9750, Loss: 0.02818300388753414, Neurons: 64, Grad norm: 2.238e+00\n",
      "Epoch 9750, Loss: 0.02818300388753414, Neurons: 64, Grad norm: 2.238e+00\n",
      "Epoch 9751, Loss: 0.027986329048871994, Neurons: 64, Grad norm: 6.239e-01\n",
      "Epoch 9751, Loss: 0.027986329048871994, Neurons: 64, Grad norm: 6.239e-01\n",
      "Epoch 9752, Loss: 0.027892861515283585, Neurons: 64, Grad norm: 1.673e+00\n",
      "Epoch 9752, Loss: 0.027892861515283585, Neurons: 64, Grad norm: 1.673e+00\n",
      "Epoch 9753, Loss: 0.02789979986846447, Neurons: 64, Grad norm: 3.038e+00\n",
      "Epoch 9753, Loss: 0.02789979986846447, Neurons: 64, Grad norm: 3.038e+00\n",
      "Epoch 9754, Loss: 0.02796274609863758, Neurons: 64, Grad norm: 3.923e+00\n",
      "Epoch 9754, Loss: 0.02796274609863758, Neurons: 64, Grad norm: 3.923e+00\n",
      "Epoch 9755, Loss: 0.028023675084114075, Neurons: 64, Grad norm: 4.274e+00\n",
      "Epoch 9755, Loss: 0.028023675084114075, Neurons: 64, Grad norm: 4.274e+00\n",
      "Epoch 9756, Loss: 0.028035039082169533, Neurons: 64, Grad norm: 4.045e+00\n",
      "Epoch 9756, Loss: 0.028035039082169533, Neurons: 64, Grad norm: 4.045e+00\n",
      "Epoch 9757, Loss: 0.02798144891858101, Neurons: 64, Grad norm: 3.348e+00\n",
      "Epoch 9757, Loss: 0.02798144891858101, Neurons: 64, Grad norm: 3.348e+00\n",
      "Epoch 9758, Loss: 0.027880212292075157, Neurons: 64, Grad norm: 2.273e+00\n",
      "Epoch 9758, Loss: 0.027880212292075157, Neurons: 64, Grad norm: 2.273e+00\n",
      "Epoch 9759, Loss: 0.02777024917304516, Neurons: 64, Grad norm: 1.092e+00\n",
      "Epoch 9759, Loss: 0.02777024917304516, Neurons: 64, Grad norm: 1.092e+00\n",
      "Epoch 9760, Loss: 0.027688829228281975, Neurons: 64, Grad norm: 6.051e-01\n",
      "Epoch 9760, Loss: 0.027688829228281975, Neurons: 64, Grad norm: 6.051e-01\n",
      "Epoch 9761, Loss: 0.02765279822051525, Neurons: 64, Grad norm: 1.485e+00\n",
      "Epoch 9761, Loss: 0.02765279822051525, Neurons: 64, Grad norm: 1.485e+00\n",
      "Epoch 9762, Loss: 0.02765352465212345, Neurons: 64, Grad norm: 2.247e+00\n",
      "Epoch 9762, Loss: 0.02765352465212345, Neurons: 64, Grad norm: 2.247e+00\n",
      "Epoch 9763, Loss: 0.02766592986881733, Neurons: 64, Grad norm: 2.640e+00\n",
      "Epoch 9763, Loss: 0.02766592986881733, Neurons: 64, Grad norm: 2.640e+00\n",
      "Epoch 9764, Loss: 0.027664870023727417, Neurons: 64, Grad norm: 2.676e+00\n",
      "Epoch 9764, Loss: 0.027664870023727417, Neurons: 64, Grad norm: 2.676e+00\n",
      "Epoch 9765, Loss: 0.027637051418423653, Neurons: 64, Grad norm: 2.336e+00\n",
      "Epoch 9765, Loss: 0.027637051418423653, Neurons: 64, Grad norm: 2.336e+00\n",
      "Epoch 9766, Loss: 0.02758553810417652, Neurons: 64, Grad norm: 1.756e+00\n",
      "Epoch 9766, Loss: 0.02758553810417652, Neurons: 64, Grad norm: 1.756e+00\n",
      "Epoch 9767, Loss: 0.02752484567463398, Neurons: 64, Grad norm: 1.012e+00\n",
      "Epoch 9767, Loss: 0.02752484567463398, Neurons: 64, Grad norm: 1.012e+00\n",
      "Epoch 9768, Loss: 0.027471648529171944, Neurons: 64, Grad norm: 4.043e-01\n",
      "Epoch 9768, Loss: 0.027471648529171944, Neurons: 64, Grad norm: 4.043e-01\n",
      "Epoch 9769, Loss: 0.02743621915578842, Neurons: 64, Grad norm: 7.180e-01\n",
      "Epoch 9769, Loss: 0.02743621915578842, Neurons: 64, Grad norm: 7.180e-01\n",
      "Epoch 9770, Loss: 0.02741786651313305, Neurons: 64, Grad norm: 1.241e+00\n",
      "Epoch 9770, Loss: 0.02741786651313305, Neurons: 64, Grad norm: 1.241e+00\n",
      "Epoch 9771, Loss: 0.027408242225646973, Neurons: 64, Grad norm: 1.604e+00\n",
      "Epoch 9771, Loss: 0.027408242225646973, Neurons: 64, Grad norm: 1.604e+00\n",
      "Epoch 9772, Loss: 0.02739565446972847, Neurons: 64, Grad norm: 1.713e+00\n",
      "Epoch 9772, Loss: 0.02739565446972847, Neurons: 64, Grad norm: 1.713e+00\n",
      "Epoch 9773, Loss: 0.027373241260647774, Neurons: 64, Grad norm: 1.623e+00\n",
      "Epoch 9773, Loss: 0.027373241260647774, Neurons: 64, Grad norm: 1.623e+00\n",
      "Epoch 9774, Loss: 0.02733977884054184, Neurons: 64, Grad norm: 1.322e+00\n",
      "Epoch 9774, Loss: 0.02733977884054184, Neurons: 64, Grad norm: 1.322e+00\n",
      "Epoch 9775, Loss: 0.0273001566529274, Neurons: 64, Grad norm: 9.209e-01\n",
      "Epoch 9775, Loss: 0.0273001566529274, Neurons: 64, Grad norm: 9.209e-01\n",
      "Epoch 9776, Loss: 0.02726118452847004, Neurons: 64, Grad norm: 4.630e-01\n",
      "Epoch 9776, Loss: 0.02726118452847004, Neurons: 64, Grad norm: 4.630e-01\n",
      "Epoch 9777, Loss: 0.027228299528360367, Neurons: 64, Grad norm: 2.778e-01\n",
      "Epoch 9777, Loss: 0.027228299528360367, Neurons: 64, Grad norm: 2.778e-01\n",
      "Epoch 9778, Loss: 0.02720288373529911, Neurons: 64, Grad norm: 5.771e-01\n",
      "Epoch 9778, Loss: 0.02720288373529911, Neurons: 64, Grad norm: 5.771e-01\n",
      "Epoch 9779, Loss: 0.027182839810848236, Neurons: 64, Grad norm: 8.557e-01\n",
      "Epoch 9779, Loss: 0.027182839810848236, Neurons: 64, Grad norm: 8.557e-01\n",
      "Epoch 9780, Loss: 0.02716432325541973, Neurons: 64, Grad norm: 1.039e+00\n",
      "Epoch 9780, Loss: 0.02716432325541973, Neurons: 64, Grad norm: 1.039e+00\n",
      "Epoch 9781, Loss: 0.02714352495968342, Neurons: 64, Grad norm: 1.069e+00\n",
      "Epoch 9781, Loss: 0.02714352495968342, Neurons: 64, Grad norm: 1.069e+00\n",
      "Epoch 9782, Loss: 0.027118200436234474, Neurons: 64, Grad norm: 9.953e-01\n",
      "Epoch 9782, Loss: 0.027118200436234474, Neurons: 64, Grad norm: 9.953e-01\n",
      "Epoch 9783, Loss: 0.02708866260945797, Neurons: 64, Grad norm: 8.039e-01\n",
      "Epoch 9783, Loss: 0.02708866260945797, Neurons: 64, Grad norm: 8.039e-01\n",
      "Epoch 9784, Loss: 0.02705729939043522, Neurons: 64, Grad norm: 5.679e-01\n",
      "Epoch 9784, Loss: 0.02705729939043522, Neurons: 64, Grad norm: 5.679e-01\n",
      "Epoch 9785, Loss: 0.02702636644244194, Neurons: 64, Grad norm: 2.820e-01\n",
      "Epoch 9785, Loss: 0.02702636644244194, Neurons: 64, Grad norm: 2.820e-01\n",
      "Epoch 9786, Loss: 0.026997948065400124, Neurons: 64, Grad norm: 1.190e-01\n",
      "Epoch 9786, Loss: 0.026997948065400124, Neurons: 64, Grad norm: 1.190e-01\n",
      "Epoch 9787, Loss: 0.026972411200404167, Neurons: 64, Grad norm: 3.026e-01\n",
      "Epoch 9787, Loss: 0.026972411200404167, Neurons: 64, Grad norm: 3.026e-01\n",
      "Epoch 9788, Loss: 0.02694953978061676, Neurons: 64, Grad norm: 4.802e-01\n",
      "Epoch 9788, Loss: 0.02694953978061676, Neurons: 64, Grad norm: 4.802e-01\n",
      "Epoch 9789, Loss: 0.02692749910056591, Neurons: 64, Grad norm: 6.182e-01\n",
      "Epoch 9789, Loss: 0.02692749910056591, Neurons: 64, Grad norm: 6.182e-01\n",
      "Epoch 9790, Loss: 0.026904968544840813, Neurons: 64, Grad norm: 6.610e-01\n",
      "Epoch 9790, Loss: 0.026904968544840813, Neurons: 64, Grad norm: 6.610e-01\n",
      "Epoch 9791, Loss: 0.026881128549575806, Neurons: 64, Grad norm: 6.571e-01\n",
      "Epoch 9791, Loss: 0.026881128549575806, Neurons: 64, Grad norm: 6.571e-01\n",
      "Epoch 9792, Loss: 0.026855750009417534, Neurons: 64, Grad norm: 5.722e-01\n",
      "Epoch 9792, Loss: 0.026855750009417534, Neurons: 64, Grad norm: 5.722e-01\n",
      "Epoch 9793, Loss: 0.026829084381461143, Neurons: 64, Grad norm: 4.605e-01\n",
      "Epoch 9793, Loss: 0.026829084381461143, Neurons: 64, Grad norm: 4.605e-01\n",
      "Epoch 9794, Loss: 0.02680189721286297, Neurons: 64, Grad norm: 3.031e-01\n",
      "Epoch 9794, Loss: 0.02680189721286297, Neurons: 64, Grad norm: 3.031e-01\n",
      "Epoch 9795, Loss: 0.026774857193231583, Neurons: 64, Grad norm: 1.515e-01\n",
      "Epoch 9795, Loss: 0.026774857193231583, Neurons: 64, Grad norm: 1.515e-01\n",
      "Epoch 9796, Loss: 0.026748739182949066, Neurons: 64, Grad norm: 4.360e-02\n",
      "Epoch 9796, Loss: 0.026748739182949066, Neurons: 64, Grad norm: 4.360e-02\n",
      "Epoch 9797, Loss: 0.026723651215434074, Neurons: 64, Grad norm: 1.589e-01\n",
      "Epoch 9797, Loss: 0.026723651215434074, Neurons: 64, Grad norm: 1.589e-01\n",
      "Epoch 9798, Loss: 0.026699500158429146, Neurons: 64, Grad norm: 2.794e-01\n",
      "Epoch 9798, Loss: 0.026699500158429146, Neurons: 64, Grad norm: 2.794e-01\n",
      "Epoch 9799, Loss: 0.026675773784518242, Neurons: 64, Grad norm: 3.452e-01\n",
      "Epoch 9799, Loss: 0.026675773784518242, Neurons: 64, Grad norm: 3.452e-01\n",
      "Epoch 9799, Test loss: 0.01721307449042797\n",
      "Epoch 9799, Test loss: 0.01721307449042797\n",
      "Epoch 9800, Loss: 0.02665228210389614, Neurons: 64, Grad norm: 3.990e-01\n",
      "Epoch 9800, Loss: 0.02665228210389614, Neurons: 64, Grad norm: 3.990e-01\n",
      "Epoch 9801, Loss: 0.026628412306308746, Neurons: 64, Grad norm: 3.974e-01\n",
      "Epoch 9801, Loss: 0.026628412306308746, Neurons: 64, Grad norm: 3.974e-01\n",
      "Epoch 9802, Loss: 0.02660413086414337, Neurons: 64, Grad norm: 3.857e-01\n",
      "Epoch 9802, Loss: 0.02660413086414337, Neurons: 64, Grad norm: 3.857e-01\n",
      "Epoch 9803, Loss: 0.026579396799206734, Neurons: 64, Grad norm: 3.260e-01\n",
      "Epoch 9803, Loss: 0.026579396799206734, Neurons: 64, Grad norm: 3.260e-01\n",
      "Epoch 9804, Loss: 0.026554374024271965, Neurons: 64, Grad norm: 2.681e-01\n",
      "Epoch 9804, Loss: 0.026554374024271965, Neurons: 64, Grad norm: 2.681e-01\n",
      "Epoch 9805, Loss: 0.026529153808951378, Neurons: 64, Grad norm: 1.826e-01\n",
      "Epoch 9805, Loss: 0.026529153808951378, Neurons: 64, Grad norm: 1.826e-01\n",
      "Epoch 9806, Loss: 0.026504114270210266, Neurons: 64, Grad norm: 1.142e-01\n",
      "Epoch 9806, Loss: 0.026504114270210266, Neurons: 64, Grad norm: 1.142e-01\n",
      "Epoch 9807, Loss: 0.026479272171854973, Neurons: 64, Grad norm: 6.248e-02\n",
      "Epoch 9807, Loss: 0.026479272171854973, Neurons: 64, Grad norm: 6.248e-02\n",
      "Epoch 9808, Loss: 0.0264548659324646, Neurons: 64, Grad norm: 8.036e-02\n",
      "Epoch 9808, Loss: 0.0264548659324646, Neurons: 64, Grad norm: 8.036e-02\n",
      "Epoch 9809, Loss: 0.026430660858750343, Neurons: 64, Grad norm: 1.431e-01\n",
      "Epoch 9809, Loss: 0.026430660858750343, Neurons: 64, Grad norm: 1.431e-01\n",
      "Epoch 9810, Loss: 0.026406582444906235, Neurons: 64, Grad norm: 1.810e-01\n",
      "Epoch 9810, Loss: 0.026406582444906235, Neurons: 64, Grad norm: 1.810e-01\n",
      "Epoch 9811, Loss: 0.026382608339190483, Neurons: 64, Grad norm: 2.298e-01\n",
      "Epoch 9811, Loss: 0.026382608339190483, Neurons: 64, Grad norm: 2.298e-01\n",
      "Epoch 9812, Loss: 0.02635858580470085, Neurons: 64, Grad norm: 2.410e-01\n",
      "Epoch 9812, Loss: 0.02635858580470085, Neurons: 64, Grad norm: 2.410e-01\n",
      "Epoch 9813, Loss: 0.026334840804338455, Neurons: 64, Grad norm: 2.648e-01\n",
      "Epoch 9813, Loss: 0.026334840804338455, Neurons: 64, Grad norm: 2.648e-01\n",
      "Epoch 9814, Loss: 0.026310846209526062, Neurons: 64, Grad norm: 2.534e-01\n",
      "Epoch 9814, Loss: 0.026310846209526062, Neurons: 64, Grad norm: 2.534e-01\n",
      "Epoch 9815, Loss: 0.026286844164133072, Neurons: 64, Grad norm: 2.513e-01\n",
      "Epoch 9815, Loss: 0.026286844164133072, Neurons: 64, Grad norm: 2.513e-01\n",
      "Epoch 9816, Loss: 0.026262711733579636, Neurons: 64, Grad norm: 2.152e-01\n",
      "Epoch 9816, Loss: 0.026262711733579636, Neurons: 64, Grad norm: 2.152e-01\n",
      "Epoch 9817, Loss: 0.026238616555929184, Neurons: 64, Grad norm: 1.981e-01\n",
      "Epoch 9817, Loss: 0.026238616555929184, Neurons: 64, Grad norm: 1.981e-01\n",
      "Epoch 9818, Loss: 0.026214471086859703, Neurons: 64, Grad norm: 1.580e-01\n",
      "Epoch 9818, Loss: 0.026214471086859703, Neurons: 64, Grad norm: 1.580e-01\n",
      "Epoch 9819, Loss: 0.026190370321273804, Neurons: 64, Grad norm: 1.376e-01\n",
      "Epoch 9819, Loss: 0.026190370321273804, Neurons: 64, Grad norm: 1.376e-01\n",
      "Epoch 9820, Loss: 0.02616644836962223, Neurons: 64, Grad norm: 1.056e-01\n",
      "Epoch 9820, Loss: 0.02616644836962223, Neurons: 64, Grad norm: 1.056e-01\n",
      "Epoch 9821, Loss: 0.02614259161055088, Neurons: 64, Grad norm: 9.732e-02\n",
      "Epoch 9821, Loss: 0.02614259161055088, Neurons: 64, Grad norm: 9.732e-02\n",
      "Epoch 9822, Loss: 0.026118827983736992, Neurons: 64, Grad norm: 1.032e-01\n",
      "Epoch 9822, Loss: 0.026118827983736992, Neurons: 64, Grad norm: 1.032e-01\n",
      "Epoch 9823, Loss: 0.026095081120729446, Neurons: 64, Grad norm: 1.119e-01\n",
      "Epoch 9823, Loss: 0.026095081120729446, Neurons: 64, Grad norm: 1.119e-01\n",
      "Epoch 9824, Loss: 0.02607155777513981, Neurons: 64, Grad norm: 1.434e-01\n",
      "Epoch 9824, Loss: 0.02607155777513981, Neurons: 64, Grad norm: 1.434e-01\n",
      "Epoch 9825, Loss: 0.026047928258776665, Neurons: 64, Grad norm: 1.535e-01\n",
      "Epoch 9825, Loss: 0.026047928258776665, Neurons: 64, Grad norm: 1.535e-01\n",
      "Epoch 9826, Loss: 0.026024430990219116, Neurons: 64, Grad norm: 1.859e-01\n",
      "Epoch 9826, Loss: 0.026024430990219116, Neurons: 64, Grad norm: 1.859e-01\n",
      "Epoch 9827, Loss: 0.026000946760177612, Neurons: 64, Grad norm: 2.014e-01\n",
      "Epoch 9827, Loss: 0.026000946760177612, Neurons: 64, Grad norm: 2.014e-01\n",
      "Epoch 9828, Loss: 0.025977592915296555, Neurons: 64, Grad norm: 2.341e-01\n",
      "Epoch 9828, Loss: 0.025977592915296555, Neurons: 64, Grad norm: 2.341e-01\n",
      "Epoch 9829, Loss: 0.025954170152544975, Neurons: 64, Grad norm: 2.479e-01\n",
      "Epoch 9829, Loss: 0.025954170152544975, Neurons: 64, Grad norm: 2.479e-01\n",
      "Epoch 9830, Loss: 0.025931185111403465, Neurons: 64, Grad norm: 2.860e-01\n",
      "Epoch 9830, Loss: 0.025931185111403465, Neurons: 64, Grad norm: 2.860e-01\n",
      "Epoch 9831, Loss: 0.025908127427101135, Neurons: 64, Grad norm: 3.032e-01\n",
      "Epoch 9831, Loss: 0.025908127427101135, Neurons: 64, Grad norm: 3.032e-01\n",
      "Epoch 9832, Loss: 0.025885382667183876, Neurons: 64, Grad norm: 3.461e-01\n",
      "Epoch 9832, Loss: 0.025885382667183876, Neurons: 64, Grad norm: 3.461e-01\n",
      "Epoch 9833, Loss: 0.025862939655780792, Neurons: 64, Grad norm: 3.715e-01\n",
      "Epoch 9833, Loss: 0.025862939655780792, Neurons: 64, Grad norm: 3.715e-01\n",
      "Epoch 9834, Loss: 0.02584075927734375, Neurons: 64, Grad norm: 4.202e-01\n",
      "Epoch 9834, Loss: 0.02584075927734375, Neurons: 64, Grad norm: 4.202e-01\n",
      "Epoch 9835, Loss: 0.025818798691034317, Neurons: 64, Grad norm: 4.498e-01\n",
      "Epoch 9835, Loss: 0.025818798691034317, Neurons: 64, Grad norm: 4.498e-01\n",
      "Epoch 9836, Loss: 0.025797024369239807, Neurons: 64, Grad norm: 5.119e-01\n",
      "Epoch 9836, Loss: 0.025797024369239807, Neurons: 64, Grad norm: 5.119e-01\n",
      "Epoch 9837, Loss: 0.025775542482733727, Neurons: 64, Grad norm: 5.592e-01\n",
      "Epoch 9837, Loss: 0.025775542482733727, Neurons: 64, Grad norm: 5.592e-01\n",
      "Epoch 9838, Loss: 0.025754708796739578, Neurons: 64, Grad norm: 6.343e-01\n",
      "Epoch 9838, Loss: 0.025754708796739578, Neurons: 64, Grad norm: 6.343e-01\n",
      "Epoch 9839, Loss: 0.02573481947183609, Neurons: 64, Grad norm: 7.012e-01\n",
      "Epoch 9839, Loss: 0.02573481947183609, Neurons: 64, Grad norm: 7.012e-01\n",
      "Epoch 9840, Loss: 0.025715800002217293, Neurons: 64, Grad norm: 8.028e-01\n",
      "Epoch 9840, Loss: 0.025715800002217293, Neurons: 64, Grad norm: 8.028e-01\n",
      "Epoch 9841, Loss: 0.025698354467749596, Neurons: 64, Grad norm: 9.015e-01\n",
      "Epoch 9841, Loss: 0.025698354467749596, Neurons: 64, Grad norm: 9.015e-01\n",
      "Epoch 9842, Loss: 0.025682497769594193, Neurons: 64, Grad norm: 1.037e+00\n",
      "Epoch 9842, Loss: 0.025682497769594193, Neurons: 64, Grad norm: 1.037e+00\n",
      "Epoch 9843, Loss: 0.025668947026133537, Neurons: 64, Grad norm: 1.173e+00\n",
      "Epoch 9843, Loss: 0.025668947026133537, Neurons: 64, Grad norm: 1.173e+00\n",
      "Epoch 9844, Loss: 0.025657864287495613, Neurons: 64, Grad norm: 1.347e+00\n",
      "Epoch 9844, Loss: 0.025657864287495613, Neurons: 64, Grad norm: 1.347e+00\n",
      "Epoch 9845, Loss: 0.025650063529610634, Neurons: 64, Grad norm: 1.518e+00\n",
      "Epoch 9845, Loss: 0.025650063529610634, Neurons: 64, Grad norm: 1.518e+00\n",
      "Epoch 9846, Loss: 0.025644583627581596, Neurons: 64, Grad norm: 1.730e+00\n",
      "Epoch 9846, Loss: 0.025644583627581596, Neurons: 64, Grad norm: 1.730e+00\n",
      "Epoch 9847, Loss: 0.025641251355409622, Neurons: 64, Grad norm: 1.928e+00\n",
      "Epoch 9847, Loss: 0.025641251355409622, Neurons: 64, Grad norm: 1.928e+00\n",
      "Epoch 9848, Loss: 0.02563915215432644, Neurons: 64, Grad norm: 2.164e+00\n",
      "Epoch 9848, Loss: 0.02563915215432644, Neurons: 64, Grad norm: 2.164e+00\n",
      "Epoch 9849, Loss: 0.02563687041401863, Neurons: 64, Grad norm: 2.379e+00\n",
      "Epoch 9849, Loss: 0.02563687041401863, Neurons: 64, Grad norm: 2.379e+00\n",
      "Epoch 9850, Loss: 0.025632601231336594, Neurons: 64, Grad norm: 2.621e+00\n",
      "Epoch 9850, Loss: 0.025632601231336594, Neurons: 64, Grad norm: 2.621e+00\n",
      "Epoch 9851, Loss: 0.02562437206506729, Neurons: 64, Grad norm: 2.839e+00\n",
      "Epoch 9851, Loss: 0.02562437206506729, Neurons: 64, Grad norm: 2.839e+00\n",
      "Epoch 9852, Loss: 0.02561086416244507, Neurons: 64, Grad norm: 3.073e+00\n",
      "Epoch 9852, Loss: 0.02561086416244507, Neurons: 64, Grad norm: 3.073e+00\n",
      "Epoch 9853, Loss: 0.025593290105462074, Neurons: 64, Grad norm: 3.278e+00\n",
      "Epoch 9853, Loss: 0.025593290105462074, Neurons: 64, Grad norm: 3.278e+00\n",
      "Epoch 9854, Loss: 0.025573179125785828, Neurons: 64, Grad norm: 3.505e+00\n",
      "Epoch 9854, Loss: 0.025573179125785828, Neurons: 64, Grad norm: 3.505e+00\n",
      "Epoch 9855, Loss: 0.02555403858423233, Neurons: 64, Grad norm: 3.700e+00\n",
      "Epoch 9855, Loss: 0.02555403858423233, Neurons: 64, Grad norm: 3.700e+00\n",
      "Epoch 9856, Loss: 0.02553992159664631, Neurons: 64, Grad norm: 3.907e+00\n",
      "Epoch 9856, Loss: 0.02553992159664631, Neurons: 64, Grad norm: 3.907e+00\n",
      "Epoch 9857, Loss: 0.025532396510243416, Neurons: 64, Grad norm: 4.064e+00\n",
      "Epoch 9857, Loss: 0.025532396510243416, Neurons: 64, Grad norm: 4.064e+00\n",
      "Epoch 9858, Loss: 0.02553080953657627, Neurons: 64, Grad norm: 4.200e+00\n",
      "Epoch 9858, Loss: 0.02553080953657627, Neurons: 64, Grad norm: 4.200e+00\n",
      "Epoch 9859, Loss: 0.025530915707349777, Neurons: 64, Grad norm: 4.247e+00\n",
      "Epoch 9859, Loss: 0.025530915707349777, Neurons: 64, Grad norm: 4.247e+00\n",
      "Epoch 9860, Loss: 0.02552666701376438, Neurons: 64, Grad norm: 4.229e+00\n",
      "Epoch 9860, Loss: 0.02552666701376438, Neurons: 64, Grad norm: 4.229e+00\n",
      "Epoch 9861, Loss: 0.025510190054774284, Neurons: 64, Grad norm: 4.070e+00\n",
      "Epoch 9861, Loss: 0.025510190054774284, Neurons: 64, Grad norm: 4.070e+00\n",
      "Epoch 9862, Loss: 0.025475285947322845, Neurons: 64, Grad norm: 3.801e+00\n",
      "Epoch 9862, Loss: 0.025475285947322845, Neurons: 64, Grad norm: 3.801e+00\n",
      "Epoch 9863, Loss: 0.025419309735298157, Neurons: 64, Grad norm: 3.380e+00\n",
      "Epoch 9863, Loss: 0.025419309735298157, Neurons: 64, Grad norm: 3.380e+00\n",
      "Epoch 9864, Loss: 0.025346238166093826, Neurons: 64, Grad norm: 2.864e+00\n",
      "Epoch 9864, Loss: 0.025346238166093826, Neurons: 64, Grad norm: 2.864e+00\n",
      "Epoch 9865, Loss: 0.02526475116610527, Neurons: 64, Grad norm: 2.238e+00\n",
      "Epoch 9865, Loss: 0.02526475116610527, Neurons: 64, Grad norm: 2.238e+00\n",
      "Epoch 9866, Loss: 0.025186538696289062, Neurons: 64, Grad norm: 1.593e+00\n",
      "Epoch 9866, Loss: 0.025186538696289062, Neurons: 64, Grad norm: 1.593e+00\n",
      "Epoch 9867, Loss: 0.025121228769421577, Neurons: 64, Grad norm: 9.321e-01\n",
      "Epoch 9867, Loss: 0.025121228769421577, Neurons: 64, Grad norm: 9.321e-01\n",
      "Epoch 9868, Loss: 0.025074267759919167, Neurons: 64, Grad norm: 4.180e-01\n",
      "Epoch 9868, Loss: 0.025074267759919167, Neurons: 64, Grad norm: 4.180e-01\n",
      "Epoch 9869, Loss: 0.02504519745707512, Neurons: 64, Grad norm: 4.938e-01\n",
      "Epoch 9869, Loss: 0.02504519745707512, Neurons: 64, Grad norm: 4.938e-01\n",
      "Epoch 9870, Loss: 0.025029383599758148, Neurons: 64, Grad norm: 9.091e-01\n",
      "Epoch 9870, Loss: 0.025029383599758148, Neurons: 64, Grad norm: 9.091e-01\n",
      "Epoch 9871, Loss: 0.02502097748219967, Neurons: 64, Grad norm: 1.300e+00\n",
      "Epoch 9871, Loss: 0.02502097748219967, Neurons: 64, Grad norm: 1.300e+00\n",
      "Epoch 9872, Loss: 0.025013456121087074, Neurons: 64, Grad norm: 1.578e+00\n",
      "Epoch 9872, Loss: 0.025013456121087074, Neurons: 64, Grad norm: 1.578e+00\n",
      "Epoch 9873, Loss: 0.025002842769026756, Neurons: 64, Grad norm: 1.784e+00\n",
      "Epoch 9873, Loss: 0.025002842769026756, Neurons: 64, Grad norm: 1.784e+00\n",
      "Epoch 9874, Loss: 0.02498694323003292, Neurons: 64, Grad norm: 1.885e+00\n",
      "Epoch 9874, Loss: 0.02498694323003292, Neurons: 64, Grad norm: 1.885e+00\n",
      "Epoch 9875, Loss: 0.024966606870293617, Neurons: 64, Grad norm: 1.931e+00\n",
      "Epoch 9875, Loss: 0.024966606870293617, Neurons: 64, Grad norm: 1.931e+00\n",
      "Epoch 9876, Loss: 0.024942565709352493, Neurons: 64, Grad norm: 1.887e+00\n",
      "Epoch 9876, Loss: 0.024942565709352493, Neurons: 64, Grad norm: 1.887e+00\n",
      "Epoch 9877, Loss: 0.0249167550355196, Neurons: 64, Grad norm: 1.821e+00\n",
      "Epoch 9877, Loss: 0.0249167550355196, Neurons: 64, Grad norm: 1.821e+00\n",
      "Epoch 9878, Loss: 0.024890923872590065, Neurons: 64, Grad norm: 1.689e+00\n",
      "Epoch 9878, Loss: 0.024890923872590065, Neurons: 64, Grad norm: 1.689e+00\n",
      "Epoch 9879, Loss: 0.02486538141965866, Neurons: 64, Grad norm: 1.554e+00\n",
      "Epoch 9879, Loss: 0.02486538141965866, Neurons: 64, Grad norm: 1.554e+00\n",
      "Epoch 9880, Loss: 0.024839645251631737, Neurons: 64, Grad norm: 1.372e+00\n",
      "Epoch 9880, Loss: 0.024839645251631737, Neurons: 64, Grad norm: 1.372e+00\n",
      "Epoch 9881, Loss: 0.024813421070575714, Neurons: 64, Grad norm: 1.198e+00\n",
      "Epoch 9881, Loss: 0.024813421070575714, Neurons: 64, Grad norm: 1.198e+00\n",
      "Epoch 9882, Loss: 0.024785928428173065, Neurons: 64, Grad norm: 9.844e-01\n",
      "Epoch 9882, Loss: 0.024785928428173065, Neurons: 64, Grad norm: 9.844e-01\n",
      "Epoch 9883, Loss: 0.02475731447339058, Neurons: 64, Grad norm: 7.923e-01\n",
      "Epoch 9883, Loss: 0.02475731447339058, Neurons: 64, Grad norm: 7.923e-01\n",
      "Epoch 9884, Loss: 0.0247283224016428, Neurons: 64, Grad norm: 5.717e-01\n",
      "Epoch 9884, Loss: 0.0247283224016428, Neurons: 64, Grad norm: 5.717e-01\n",
      "Epoch 9885, Loss: 0.02469993755221367, Neurons: 64, Grad norm: 3.788e-01\n",
      "Epoch 9885, Loss: 0.02469993755221367, Neurons: 64, Grad norm: 3.788e-01\n",
      "Epoch 9886, Loss: 0.024672990664839745, Neurons: 64, Grad norm: 1.800e-01\n",
      "Epoch 9886, Loss: 0.024672990664839745, Neurons: 64, Grad norm: 1.800e-01\n",
      "Epoch 9887, Loss: 0.02464812435209751, Neurons: 64, Grad norm: 7.218e-02\n",
      "Epoch 9887, Loss: 0.02464812435209751, Neurons: 64, Grad norm: 7.218e-02\n",
      "Epoch 9888, Loss: 0.024625275284051895, Neurons: 64, Grad norm: 1.947e-01\n",
      "Epoch 9888, Loss: 0.024625275284051895, Neurons: 64, Grad norm: 1.947e-01\n",
      "Epoch 9889, Loss: 0.02460421249270439, Neurons: 64, Grad norm: 3.238e-01\n",
      "Epoch 9889, Loss: 0.02460421249270439, Neurons: 64, Grad norm: 3.238e-01\n",
      "Epoch 9890, Loss: 0.024584442377090454, Neurons: 64, Grad norm: 4.606e-01\n",
      "Epoch 9890, Loss: 0.024584442377090454, Neurons: 64, Grad norm: 4.606e-01\n",
      "Epoch 9891, Loss: 0.024565262719988823, Neurons: 64, Grad norm: 5.482e-01\n",
      "Epoch 9891, Loss: 0.024565262719988823, Neurons: 64, Grad norm: 5.482e-01\n",
      "Epoch 9892, Loss: 0.024546243250370026, Neurons: 64, Grad norm: 6.505e-01\n",
      "Epoch 9892, Loss: 0.024546243250370026, Neurons: 64, Grad norm: 6.505e-01\n",
      "Epoch 9893, Loss: 0.02452695555984974, Neurons: 64, Grad norm: 7.143e-01\n",
      "Epoch 9893, Loss: 0.02452695555984974, Neurons: 64, Grad norm: 7.143e-01\n",
      "Epoch 9894, Loss: 0.024507325142621994, Neurons: 64, Grad norm: 7.879e-01\n",
      "Epoch 9894, Loss: 0.024507325142621994, Neurons: 64, Grad norm: 7.879e-01\n",
      "Epoch 9895, Loss: 0.0244873259216547, Neurons: 64, Grad norm: 8.285e-01\n",
      "Epoch 9895, Loss: 0.0244873259216547, Neurons: 64, Grad norm: 8.285e-01\n",
      "Epoch 9896, Loss: 0.024466756731271744, Neurons: 64, Grad norm: 8.943e-01\n",
      "Epoch 9896, Loss: 0.024466756731271744, Neurons: 64, Grad norm: 8.943e-01\n",
      "Epoch 9897, Loss: 0.024446221068501472, Neurons: 64, Grad norm: 9.203e-01\n",
      "Epoch 9897, Loss: 0.024446221068501472, Neurons: 64, Grad norm: 9.203e-01\n",
      "Epoch 9898, Loss: 0.024425474926829338, Neurons: 64, Grad norm: 9.795e-01\n",
      "Epoch 9898, Loss: 0.024425474926829338, Neurons: 64, Grad norm: 9.795e-01\n",
      "Epoch 9899, Loss: 0.024405092000961304, Neurons: 64, Grad norm: 1.015e+00\n",
      "Epoch 9899, Loss: 0.024405092000961304, Neurons: 64, Grad norm: 1.015e+00\n",
      "Epoch 9899, Test loss: 0.015770230442285538\n",
      "Epoch 9899, Test loss: 0.015770230442285538\n",
      "Epoch 9900, Loss: 0.02438485436141491, Neurons: 64, Grad norm: 1.065e+00\n",
      "Epoch 9900, Loss: 0.02438485436141491, Neurons: 64, Grad norm: 1.065e+00\n",
      "Epoch 9901, Loss: 0.02436491847038269, Neurons: 64, Grad norm: 1.101e+00\n",
      "Epoch 9901, Loss: 0.02436491847038269, Neurons: 64, Grad norm: 1.101e+00\n",
      "Epoch 9902, Loss: 0.02434537559747696, Neurons: 64, Grad norm: 1.170e+00\n",
      "Epoch 9902, Loss: 0.02434537559747696, Neurons: 64, Grad norm: 1.170e+00\n",
      "Epoch 9903, Loss: 0.024326276034116745, Neurons: 64, Grad norm: 1.211e+00\n",
      "Epoch 9903, Loss: 0.024326276034116745, Neurons: 64, Grad norm: 1.211e+00\n",
      "Epoch 9904, Loss: 0.024307237938046455, Neurons: 64, Grad norm: 1.278e+00\n",
      "Epoch 9904, Loss: 0.024307237938046455, Neurons: 64, Grad norm: 1.278e+00\n",
      "Epoch 9905, Loss: 0.024288533255457878, Neurons: 64, Grad norm: 1.333e+00\n",
      "Epoch 9905, Loss: 0.024288533255457878, Neurons: 64, Grad norm: 1.333e+00\n",
      "Epoch 9906, Loss: 0.024269944056868553, Neurons: 64, Grad norm: 1.421e+00\n",
      "Epoch 9906, Loss: 0.024269944056868553, Neurons: 64, Grad norm: 1.421e+00\n",
      "Epoch 9907, Loss: 0.02425195835530758, Neurons: 64, Grad norm: 1.488e+00\n",
      "Epoch 9907, Loss: 0.02425195835530758, Neurons: 64, Grad norm: 1.488e+00\n",
      "Epoch 9908, Loss: 0.024234581738710403, Neurons: 64, Grad norm: 1.598e+00\n",
      "Epoch 9908, Loss: 0.024234581738710403, Neurons: 64, Grad norm: 1.598e+00\n",
      "Epoch 9909, Loss: 0.024217946454882622, Neurons: 64, Grad norm: 1.704e+00\n",
      "Epoch 9909, Loss: 0.024217946454882622, Neurons: 64, Grad norm: 1.704e+00\n",
      "Epoch 9910, Loss: 0.024202818050980568, Neurons: 64, Grad norm: 1.854e+00\n",
      "Epoch 9910, Loss: 0.024202818050980568, Neurons: 64, Grad norm: 1.854e+00\n",
      "Epoch 9911, Loss: 0.02418912574648857, Neurons: 64, Grad norm: 1.994e+00\n",
      "Epoch 9911, Loss: 0.02418912574648857, Neurons: 64, Grad norm: 1.994e+00\n",
      "Epoch 9912, Loss: 0.02417740784585476, Neurons: 64, Grad norm: 2.188e+00\n",
      "Epoch 9912, Loss: 0.02417740784585476, Neurons: 64, Grad norm: 2.188e+00\n",
      "Epoch 9913, Loss: 0.02416776493191719, Neurons: 64, Grad norm: 2.379e+00\n",
      "Epoch 9913, Loss: 0.02416776493191719, Neurons: 64, Grad norm: 2.379e+00\n",
      "Epoch 9914, Loss: 0.024160850793123245, Neurons: 64, Grad norm: 2.614e+00\n",
      "Epoch 9914, Loss: 0.024160850793123245, Neurons: 64, Grad norm: 2.614e+00\n",
      "Epoch 9915, Loss: 0.024157095700502396, Neurons: 64, Grad norm: 2.853e+00\n",
      "Epoch 9915, Loss: 0.024157095700502396, Neurons: 64, Grad norm: 2.853e+00\n",
      "Epoch 9916, Loss: 0.024157114326953888, Neurons: 64, Grad norm: 3.139e+00\n",
      "Epoch 9916, Loss: 0.024157114326953888, Neurons: 64, Grad norm: 3.139e+00\n",
      "Epoch 9917, Loss: 0.02416110597550869, Neurons: 64, Grad norm: 3.417e+00\n",
      "Epoch 9917, Loss: 0.02416110597550869, Neurons: 64, Grad norm: 3.417e+00\n",
      "Epoch 9918, Loss: 0.024169206619262695, Neurons: 64, Grad norm: 3.734e+00\n",
      "Epoch 9918, Loss: 0.024169206619262695, Neurons: 64, Grad norm: 3.734e+00\n",
      "Epoch 9919, Loss: 0.024181317538022995, Neurons: 64, Grad norm: 4.023e+00\n",
      "Epoch 9919, Loss: 0.024181317538022995, Neurons: 64, Grad norm: 4.023e+00\n",
      "Epoch 9920, Loss: 0.024196354672312737, Neurons: 64, Grad norm: 4.322e+00\n",
      "Epoch 9920, Loss: 0.024196354672312737, Neurons: 64, Grad norm: 4.322e+00\n",
      "Epoch 9921, Loss: 0.02421168051660061, Neurons: 64, Grad norm: 4.557e+00\n",
      "Epoch 9921, Loss: 0.02421168051660061, Neurons: 64, Grad norm: 4.557e+00\n",
      "Epoch 9922, Loss: 0.024224326014518738, Neurons: 64, Grad norm: 4.750e+00\n",
      "Epoch 9922, Loss: 0.024224326014518738, Neurons: 64, Grad norm: 4.750e+00\n",
      "Epoch 9923, Loss: 0.02422880195081234, Neurons: 64, Grad norm: 4.813e+00\n",
      "Epoch 9923, Loss: 0.02422880195081234, Neurons: 64, Grad norm: 4.813e+00\n",
      "Epoch 9924, Loss: 0.02421976625919342, Neurons: 64, Grad norm: 4.773e+00\n",
      "Epoch 9924, Loss: 0.02421976625919342, Neurons: 64, Grad norm: 4.773e+00\n",
      "Epoch 9925, Loss: 0.02419162541627884, Neurons: 64, Grad norm: 4.552e+00\n",
      "Epoch 9925, Loss: 0.02419162541627884, Neurons: 64, Grad norm: 4.552e+00\n",
      "Epoch 9926, Loss: 0.024142080917954445, Neurons: 64, Grad norm: 4.188e+00\n",
      "Epoch 9926, Loss: 0.024142080917954445, Neurons: 64, Grad norm: 4.188e+00\n",
      "Epoch 9927, Loss: 0.02407223917543888, Neurons: 64, Grad norm: 3.639e+00\n",
      "Epoch 9927, Loss: 0.02407223917543888, Neurons: 64, Grad norm: 3.639e+00\n",
      "Epoch 9928, Loss: 0.023988861590623856, Neurons: 64, Grad norm: 2.982e+00\n",
      "Epoch 9928, Loss: 0.023988861590623856, Neurons: 64, Grad norm: 2.982e+00\n",
      "Epoch 9929, Loss: 0.02390139177441597, Neurons: 64, Grad norm: 2.202e+00\n",
      "Epoch 9929, Loss: 0.02390139177441597, Neurons: 64, Grad norm: 2.202e+00\n",
      "Epoch 9930, Loss: 0.02382148988544941, Neurons: 64, Grad norm: 1.406e+00\n",
      "Epoch 9930, Loss: 0.02382148988544941, Neurons: 64, Grad norm: 1.406e+00\n",
      "Epoch 9931, Loss: 0.023757418617606163, Neurons: 64, Grad norm: 5.965e-01\n",
      "Epoch 9931, Loss: 0.023757418617606163, Neurons: 64, Grad norm: 5.965e-01\n",
      "Epoch 9932, Loss: 0.023713482543826103, Neurons: 64, Grad norm: 1.754e-01\n",
      "Epoch 9932, Loss: 0.023713482543826103, Neurons: 64, Grad norm: 1.754e-01\n",
      "Epoch 9933, Loss: 0.023688888177275658, Neurons: 64, Grad norm: 8.446e-01\n",
      "Epoch 9933, Loss: 0.023688888177275658, Neurons: 64, Grad norm: 8.446e-01\n",
      "Epoch 9934, Loss: 0.023679178208112717, Neurons: 64, Grad norm: 1.388e+00\n",
      "Epoch 9934, Loss: 0.023679178208112717, Neurons: 64, Grad norm: 1.388e+00\n",
      "Epoch 9935, Loss: 0.023678461089730263, Neurons: 64, Grad norm: 1.836e+00\n",
      "Epoch 9935, Loss: 0.023678461089730263, Neurons: 64, Grad norm: 1.836e+00\n",
      "Epoch 9936, Loss: 0.02367962710559368, Neurons: 64, Grad norm: 2.130e+00\n",
      "Epoch 9936, Loss: 0.02367962710559368, Neurons: 64, Grad norm: 2.130e+00\n",
      "Epoch 9937, Loss: 0.023677758872509003, Neurons: 64, Grad norm: 2.318e+00\n",
      "Epoch 9937, Loss: 0.023677758872509003, Neurons: 64, Grad norm: 2.318e+00\n",
      "Epoch 9938, Loss: 0.02366928942501545, Neurons: 64, Grad norm: 2.348e+00\n",
      "Epoch 9938, Loss: 0.02366928942501545, Neurons: 64, Grad norm: 2.348e+00\n",
      "Epoch 9939, Loss: 0.023652497678995132, Neurons: 64, Grad norm: 2.288e+00\n",
      "Epoch 9939, Loss: 0.023652497678995132, Neurons: 64, Grad norm: 2.288e+00\n",
      "Epoch 9940, Loss: 0.023627005517482758, Neurons: 64, Grad norm: 2.100e+00\n",
      "Epoch 9940, Loss: 0.023627005517482758, Neurons: 64, Grad norm: 2.100e+00\n",
      "Epoch 9941, Loss: 0.023595266044139862, Neurons: 64, Grad norm: 1.856e+00\n",
      "Epoch 9941, Loss: 0.023595266044139862, Neurons: 64, Grad norm: 1.856e+00\n",
      "Epoch 9942, Loss: 0.02355952188372612, Neurons: 64, Grad norm: 1.519e+00\n",
      "Epoch 9942, Loss: 0.02355952188372612, Neurons: 64, Grad norm: 1.519e+00\n",
      "Epoch 9943, Loss: 0.023523030802607536, Neurons: 64, Grad norm: 1.166e+00\n",
      "Epoch 9943, Loss: 0.023523030802607536, Neurons: 64, Grad norm: 1.166e+00\n",
      "Epoch 9944, Loss: 0.02348828874528408, Neurons: 64, Grad norm: 7.767e-01\n",
      "Epoch 9944, Loss: 0.02348828874528408, Neurons: 64, Grad norm: 7.767e-01\n",
      "Epoch 9945, Loss: 0.023457322269678116, Neurons: 64, Grad norm: 4.157e-01\n",
      "Epoch 9945, Loss: 0.023457322269678116, Neurons: 64, Grad norm: 4.157e-01\n",
      "Epoch 9946, Loss: 0.023430772125720978, Neurons: 64, Grad norm: 6.035e-02\n",
      "Epoch 9946, Loss: 0.023430772125720978, Neurons: 64, Grad norm: 6.035e-02\n",
      "Epoch 9947, Loss: 0.023408597335219383, Neurons: 64, Grad norm: 2.796e-01\n",
      "Epoch 9947, Loss: 0.023408597335219383, Neurons: 64, Grad norm: 2.796e-01\n",
      "Epoch 9948, Loss: 0.023390116170048714, Neurons: 64, Grad norm: 5.713e-01\n",
      "Epoch 9948, Loss: 0.023390116170048714, Neurons: 64, Grad norm: 5.713e-01\n",
      "Epoch 9949, Loss: 0.0233740396797657, Neurons: 64, Grad norm: 7.937e-01\n",
      "Epoch 9949, Loss: 0.0233740396797657, Neurons: 64, Grad norm: 7.937e-01\n",
      "Epoch 9950, Loss: 0.023359348997473717, Neurons: 64, Grad norm: 9.989e-01\n",
      "Epoch 9950, Loss: 0.023359348997473717, Neurons: 64, Grad norm: 9.989e-01\n",
      "Epoch 9951, Loss: 0.02334478311240673, Neurons: 64, Grad norm: 1.116e+00\n",
      "Epoch 9951, Loss: 0.02334478311240673, Neurons: 64, Grad norm: 1.116e+00\n",
      "Epoch 9952, Loss: 0.02332952991127968, Neurons: 64, Grad norm: 1.216e+00\n",
      "Epoch 9952, Loss: 0.02332952991127968, Neurons: 64, Grad norm: 1.216e+00\n",
      "Epoch 9953, Loss: 0.02331298589706421, Neurons: 64, Grad norm: 1.249e+00\n",
      "Epoch 9953, Loss: 0.02331298589706421, Neurons: 64, Grad norm: 1.249e+00\n",
      "Epoch 9954, Loss: 0.02329491823911667, Neurons: 64, Grad norm: 1.263e+00\n",
      "Epoch 9954, Loss: 0.02329491823911667, Neurons: 64, Grad norm: 1.263e+00\n",
      "Epoch 9955, Loss: 0.023275533691048622, Neurons: 64, Grad norm: 1.220e+00\n",
      "Epoch 9955, Loss: 0.023275533691048622, Neurons: 64, Grad norm: 1.220e+00\n",
      "Epoch 9956, Loss: 0.0232547614723444, Neurons: 64, Grad norm: 1.176e+00\n",
      "Epoch 9956, Loss: 0.0232547614723444, Neurons: 64, Grad norm: 1.176e+00\n",
      "Epoch 9957, Loss: 0.023233087733387947, Neurons: 64, Grad norm: 1.078e+00\n",
      "Epoch 9957, Loss: 0.023233087733387947, Neurons: 64, Grad norm: 1.078e+00\n",
      "Epoch 9958, Loss: 0.023210640996694565, Neurons: 64, Grad norm: 9.922e-01\n",
      "Epoch 9958, Loss: 0.023210640996694565, Neurons: 64, Grad norm: 9.922e-01\n",
      "Epoch 9959, Loss: 0.023187939077615738, Neurons: 64, Grad norm: 8.641e-01\n",
      "Epoch 9959, Loss: 0.023187939077615738, Neurons: 64, Grad norm: 8.641e-01\n",
      "Epoch 9960, Loss: 0.023165348917245865, Neurons: 64, Grad norm: 7.592e-01\n",
      "Epoch 9960, Loss: 0.023165348917245865, Neurons: 64, Grad norm: 7.592e-01\n",
      "Epoch 9961, Loss: 0.02314295992255211, Neurons: 64, Grad norm: 6.255e-01\n",
      "Epoch 9961, Loss: 0.02314295992255211, Neurons: 64, Grad norm: 6.255e-01\n",
      "Epoch 9962, Loss: 0.023121066391468048, Neurons: 64, Grad norm: 5.241e-01\n",
      "Epoch 9962, Loss: 0.023121066391468048, Neurons: 64, Grad norm: 5.241e-01\n",
      "Epoch 9963, Loss: 0.023099632933735847, Neurons: 64, Grad norm: 4.011e-01\n",
      "Epoch 9963, Loss: 0.023099632933735847, Neurons: 64, Grad norm: 4.011e-01\n",
      "Epoch 9964, Loss: 0.023078681901097298, Neurons: 64, Grad norm: 3.061e-01\n",
      "Epoch 9964, Loss: 0.023078681901097298, Neurons: 64, Grad norm: 3.061e-01\n",
      "Epoch 9965, Loss: 0.023058252409100533, Neurons: 64, Grad norm: 1.924e-01\n",
      "Epoch 9965, Loss: 0.023058252409100533, Neurons: 64, Grad norm: 1.924e-01\n",
      "Epoch 9966, Loss: 0.023038236424326897, Neurons: 64, Grad norm: 1.172e-01\n",
      "Epoch 9966, Loss: 0.023038236424326897, Neurons: 64, Grad norm: 1.172e-01\n",
      "Epoch 9967, Loss: 0.02301843836903572, Neurons: 64, Grad norm: 3.764e-02\n",
      "Epoch 9967, Loss: 0.02301843836903572, Neurons: 64, Grad norm: 3.764e-02\n",
      "Epoch 9968, Loss: 0.02299906127154827, Neurons: 64, Grad norm: 6.762e-02\n",
      "Epoch 9968, Loss: 0.02299906127154827, Neurons: 64, Grad norm: 6.762e-02\n",
      "Epoch 9969, Loss: 0.02297980897128582, Neurons: 64, Grad norm: 1.434e-01\n",
      "Epoch 9969, Loss: 0.02297980897128582, Neurons: 64, Grad norm: 1.434e-01\n",
      "Epoch 9970, Loss: 0.022960834205150604, Neurons: 64, Grad norm: 1.938e-01\n",
      "Epoch 9970, Loss: 0.022960834205150604, Neurons: 64, Grad norm: 1.938e-01\n",
      "Epoch 9971, Loss: 0.022941954433918, Neurons: 64, Grad norm: 2.651e-01\n",
      "Epoch 9971, Loss: 0.022941954433918, Neurons: 64, Grad norm: 2.651e-01\n",
      "Epoch 9972, Loss: 0.022923141717910767, Neurons: 64, Grad norm: 3.053e-01\n",
      "Epoch 9972, Loss: 0.022923141717910767, Neurons: 64, Grad norm: 3.053e-01\n",
      "Epoch 9973, Loss: 0.022904526442289352, Neurons: 64, Grad norm: 3.737e-01\n",
      "Epoch 9973, Loss: 0.022904526442289352, Neurons: 64, Grad norm: 3.737e-01\n",
      "Epoch 9974, Loss: 0.0228860042989254, Neurons: 64, Grad norm: 4.138e-01\n",
      "Epoch 9974, Loss: 0.0228860042989254, Neurons: 64, Grad norm: 4.138e-01\n",
      "Epoch 9975, Loss: 0.022867511957883835, Neurons: 64, Grad norm: 4.811e-01\n",
      "Epoch 9975, Loss: 0.022867511957883835, Neurons: 64, Grad norm: 4.811e-01\n",
      "Epoch 9976, Loss: 0.022849202156066895, Neurons: 64, Grad norm: 5.202e-01\n",
      "Epoch 9976, Loss: 0.022849202156066895, Neurons: 64, Grad norm: 5.202e-01\n",
      "Epoch 9977, Loss: 0.022830910980701447, Neurons: 64, Grad norm: 5.879e-01\n",
      "Epoch 9977, Loss: 0.022830910980701447, Neurons: 64, Grad norm: 5.879e-01\n",
      "Epoch 9978, Loss: 0.022812867537140846, Neurons: 64, Grad norm: 6.342e-01\n",
      "Epoch 9978, Loss: 0.022812867537140846, Neurons: 64, Grad norm: 6.342e-01\n",
      "Epoch 9979, Loss: 0.022794969379901886, Neurons: 64, Grad norm: 7.145e-01\n",
      "Epoch 9979, Loss: 0.022794969379901886, Neurons: 64, Grad norm: 7.145e-01\n",
      "Epoch 9980, Loss: 0.022777337580919266, Neurons: 64, Grad norm: 7.789e-01\n",
      "Epoch 9980, Loss: 0.022777337580919266, Neurons: 64, Grad norm: 7.789e-01\n",
      "Epoch 9981, Loss: 0.022760072723031044, Neurons: 64, Grad norm: 8.792e-01\n",
      "Epoch 9981, Loss: 0.022760072723031044, Neurons: 64, Grad norm: 8.792e-01\n",
      "Epoch 9982, Loss: 0.022743452340364456, Neurons: 64, Grad norm: 9.656e-01\n",
      "Epoch 9982, Loss: 0.022743452340364456, Neurons: 64, Grad norm: 9.656e-01\n",
      "Epoch 9983, Loss: 0.022727470844984055, Neurons: 64, Grad norm: 1.101e+00\n",
      "Epoch 9983, Loss: 0.022727470844984055, Neurons: 64, Grad norm: 1.101e+00\n",
      "Epoch 9984, Loss: 0.02271246910095215, Neurons: 64, Grad norm: 1.229e+00\n",
      "Epoch 9984, Loss: 0.02271246910095215, Neurons: 64, Grad norm: 1.229e+00\n",
      "Epoch 9985, Loss: 0.022698746994137764, Neurons: 64, Grad norm: 1.401e+00\n",
      "Epoch 9985, Loss: 0.022698746994137764, Neurons: 64, Grad norm: 1.401e+00\n",
      "Epoch 9986, Loss: 0.022686850279569626, Neurons: 64, Grad norm: 1.585e+00\n",
      "Epoch 9986, Loss: 0.022686850279569626, Neurons: 64, Grad norm: 1.585e+00\n",
      "Epoch 9987, Loss: 0.022677751258015633, Neurons: 64, Grad norm: 1.840e+00\n",
      "Epoch 9987, Loss: 0.022677751258015633, Neurons: 64, Grad norm: 1.840e+00\n",
      "Epoch 9988, Loss: 0.02267223410308361, Neurons: 64, Grad norm: 2.100e+00\n",
      "Epoch 9988, Loss: 0.02267223410308361, Neurons: 64, Grad norm: 2.100e+00\n",
      "Epoch 9989, Loss: 0.022671833634376526, Neurons: 64, Grad norm: 2.433e+00\n",
      "Epoch 9989, Loss: 0.022671833634376526, Neurons: 64, Grad norm: 2.433e+00\n",
      "Epoch 9990, Loss: 0.022678161039948463, Neurons: 64, Grad norm: 2.805e+00\n",
      "Epoch 9990, Loss: 0.022678161039948463, Neurons: 64, Grad norm: 2.805e+00\n",
      "Epoch 9991, Loss: 0.02269425243139267, Neurons: 64, Grad norm: 3.258e+00\n",
      "Epoch 9991, Loss: 0.02269425243139267, Neurons: 64, Grad norm: 3.258e+00\n",
      "Epoch 9992, Loss: 0.02272222563624382, Neurons: 64, Grad norm: 3.738e+00\n",
      "Epoch 9992, Loss: 0.02272222563624382, Neurons: 64, Grad norm: 3.738e+00\n",
      "Epoch 9993, Loss: 0.022765958681702614, Neurons: 64, Grad norm: 4.295e+00\n",
      "Epoch 9993, Loss: 0.022765958681702614, Neurons: 64, Grad norm: 4.295e+00\n",
      "Epoch 9994, Loss: 0.022826874628663063, Neurons: 64, Grad norm: 4.859e+00\n",
      "Epoch 9994, Loss: 0.022826874628663063, Neurons: 64, Grad norm: 4.859e+00\n",
      "Epoch 9995, Loss: 0.02290627360343933, Neurons: 64, Grad norm: 5.438e+00\n",
      "Epoch 9995, Loss: 0.02290627360343933, Neurons: 64, Grad norm: 5.438e+00\n",
      "Epoch 9996, Loss: 0.022995591163635254, Neurons: 64, Grad norm: 5.919e+00\n",
      "Epoch 9996, Loss: 0.022995591163635254, Neurons: 64, Grad norm: 5.919e+00\n",
      "Epoch 9997, Loss: 0.023081274703145027, Neurons: 64, Grad norm: 6.263e+00\n",
      "Epoch 9997, Loss: 0.023081274703145027, Neurons: 64, Grad norm: 6.263e+00\n",
      "Epoch 9998, Loss: 0.023135431110858917, Neurons: 64, Grad norm: 6.321e+00\n",
      "Epoch 9998, Loss: 0.023135431110858917, Neurons: 64, Grad norm: 6.321e+00\n",
      "Epoch 9999, Loss: 0.023130035027861595, Neurons: 64, Grad norm: 6.048e+00\n",
      "Epoch 9999, Loss: 0.023130035027861595, Neurons: 64, Grad norm: 6.048e+00\n",
      "Epoch 9999, Test loss: 0.01558042224496603\n",
      "Epoch 9999, Test loss: 0.01558042224496603\n",
      "Epoch 10000, Loss: 0.023037370294332504, Neurons: 64, Grad norm: 5.350e+00\n",
      "Epoch 10000, Loss: 0.023037370294332504, Neurons: 64, Grad norm: 5.350e+00\n",
      "Epoch 10001, Loss: 0.022866185754537582, Neurons: 64, Grad norm: 4.306e+00\n",
      "Epoch 10001, Loss: 0.022866185754537582, Neurons: 64, Grad norm: 4.306e+00\n",
      "Epoch 10002, Loss: 0.022658050060272217, Neurons: 64, Grad norm: 2.986e+00\n",
      "Epoch 10002, Loss: 0.022658050060272217, Neurons: 64, Grad norm: 2.986e+00\n",
      "Epoch 10003, Loss: 0.022477196529507637, Neurons: 64, Grad norm: 1.665e+00\n",
      "Epoch 10003, Loss: 0.022477196529507637, Neurons: 64, Grad norm: 1.665e+00\n",
      "Epoch 10004, Loss: 0.022372975945472717, Neurons: 64, Grad norm: 8.862e-01\n",
      "Epoch 10004, Loss: 0.022372975945472717, Neurons: 64, Grad norm: 8.862e-01\n",
      "Epoch 10005, Loss: 0.022356515750288963, Neurons: 64, Grad norm: 1.480e+00\n",
      "Epoch 10005, Loss: 0.022356515750288963, Neurons: 64, Grad norm: 1.480e+00\n",
      "Epoch 10006, Loss: 0.022399932146072388, Neurons: 64, Grad norm: 2.243e+00\n",
      "Epoch 10006, Loss: 0.022399932146072388, Neurons: 64, Grad norm: 2.243e+00\n",
      "Epoch 10007, Loss: 0.022454675287008286, Neurons: 64, Grad norm: 2.682e+00\n",
      "Epoch 10007, Loss: 0.022454675287008286, Neurons: 64, Grad norm: 2.682e+00\n",
      "Epoch 10008, Loss: 0.022476326674222946, Neurons: 64, Grad norm: 2.757e+00\n",
      "Epoch 10008, Loss: 0.022476326674222946, Neurons: 64, Grad norm: 2.757e+00\n",
      "Epoch 10009, Loss: 0.022440651431679726, Neurons: 64, Grad norm: 2.456e+00\n",
      "Epoch 10009, Loss: 0.022440651431679726, Neurons: 64, Grad norm: 2.456e+00\n",
      "Epoch 10010, Loss: 0.022359652444720268, Neurons: 64, Grad norm: 1.916e+00\n",
      "Epoch 10010, Loss: 0.022359652444720268, Neurons: 64, Grad norm: 1.916e+00\n",
      "Epoch 10011, Loss: 0.022267958149313927, Neurons: 64, Grad norm: 1.252e+00\n",
      "Epoch 10011, Loss: 0.022267958149313927, Neurons: 64, Grad norm: 1.252e+00\n",
      "Epoch 10012, Loss: 0.022203750908374786, Neurons: 64, Grad norm: 8.014e-01\n",
      "Epoch 10012, Loss: 0.022203750908374786, Neurons: 64, Grad norm: 8.014e-01\n",
      "Epoch 10013, Loss: 0.022183774039149284, Neurons: 64, Grad norm: 8.797e-01\n",
      "Epoch 10013, Loss: 0.022183774039149284, Neurons: 64, Grad norm: 8.797e-01\n",
      "Epoch 10014, Loss: 0.022197457030415535, Neurons: 64, Grad norm: 1.190e+00\n",
      "Epoch 10014, Loss: 0.022197457030415535, Neurons: 64, Grad norm: 1.190e+00\n",
      "Epoch 10015, Loss: 0.022218268364667892, Neurons: 64, Grad norm: 1.364e+00\n",
      "Epoch 10015, Loss: 0.022218268364667892, Neurons: 64, Grad norm: 1.364e+00\n",
      "Epoch 10016, Loss: 0.02221888117492199, Neurons: 64, Grad norm: 1.307e+00\n",
      "Epoch 10016, Loss: 0.02221888117492199, Neurons: 64, Grad norm: 1.307e+00\n",
      "Epoch 10017, Loss: 0.02218806929886341, Neurons: 64, Grad norm: 1.041e+00\n",
      "Epoch 10017, Loss: 0.02218806929886341, Neurons: 64, Grad norm: 1.041e+00\n",
      "Epoch 10018, Loss: 0.02213355340063572, Neurons: 64, Grad norm: 6.148e-01\n",
      "Epoch 10018, Loss: 0.02213355340063572, Neurons: 64, Grad norm: 6.148e-01\n",
      "Epoch 10019, Loss: 0.02207767218351364, Neurons: 64, Grad norm: 1.463e-01\n",
      "Epoch 10019, Loss: 0.02207767218351364, Neurons: 64, Grad norm: 1.463e-01\n",
      "Epoch 10020, Loss: 0.022039638832211494, Neurons: 64, Grad norm: 3.681e-01\n",
      "Epoch 10020, Loss: 0.022039638832211494, Neurons: 64, Grad norm: 3.681e-01\n",
      "Epoch 10021, Loss: 0.022025395184755325, Neurons: 64, Grad norm: 7.171e-01\n",
      "Epoch 10021, Loss: 0.022025395184755325, Neurons: 64, Grad norm: 7.171e-01\n",
      "Epoch 10022, Loss: 0.022026512771844864, Neurons: 64, Grad norm: 9.271e-01\n",
      "Epoch 10022, Loss: 0.022026512771844864, Neurons: 64, Grad norm: 9.271e-01\n",
      "Epoch 10023, Loss: 0.022027146071195602, Neurons: 64, Grad norm: 9.512e-01\n",
      "Epoch 10023, Loss: 0.022027146071195602, Neurons: 64, Grad norm: 9.512e-01\n",
      "Epoch 10024, Loss: 0.02201499603688717, Neurons: 64, Grad norm: 8.206e-01\n",
      "Epoch 10024, Loss: 0.02201499603688717, Neurons: 64, Grad norm: 8.206e-01\n",
      "Epoch 10025, Loss: 0.021987946704030037, Neurons: 64, Grad norm: 5.727e-01\n",
      "Epoch 10025, Loss: 0.021987946704030037, Neurons: 64, Grad norm: 5.727e-01\n",
      "Epoch 10026, Loss: 0.021953724324703217, Neurons: 64, Grad norm: 3.251e-01\n",
      "Epoch 10026, Loss: 0.021953724324703217, Neurons: 64, Grad norm: 3.251e-01\n",
      "Epoch 10027, Loss: 0.02192198671400547, Neurons: 64, Grad norm: 3.906e-01\n",
      "Epoch 10027, Loss: 0.02192198671400547, Neurons: 64, Grad norm: 3.906e-01\n",
      "Epoch 10028, Loss: 0.021899990737438202, Neurons: 64, Grad norm: 6.275e-01\n",
      "Epoch 10028, Loss: 0.021899990737438202, Neurons: 64, Grad norm: 6.275e-01\n",
      "Epoch 10029, Loss: 0.02188771590590477, Neurons: 64, Grad norm: 8.473e-01\n",
      "Epoch 10029, Loss: 0.02188771590590477, Neurons: 64, Grad norm: 8.473e-01\n",
      "Epoch 10030, Loss: 0.021879658102989197, Neurons: 64, Grad norm: 9.436e-01\n",
      "Epoch 10030, Loss: 0.021879658102989197, Neurons: 64, Grad norm: 9.436e-01\n",
      "Epoch 10031, Loss: 0.021868908777832985, Neurons: 64, Grad norm: 9.428e-01\n",
      "Epoch 10031, Loss: 0.021868908777832985, Neurons: 64, Grad norm: 9.428e-01\n",
      "Epoch 10032, Loss: 0.02185172028839588, Neurons: 64, Grad norm: 8.137e-01\n",
      "Epoch 10032, Loss: 0.02185172028839588, Neurons: 64, Grad norm: 8.137e-01\n",
      "Epoch 10033, Loss: 0.021828260272741318, Neurons: 64, Grad norm: 6.273e-01\n",
      "Epoch 10033, Loss: 0.021828260272741318, Neurons: 64, Grad norm: 6.273e-01\n",
      "Epoch 10034, Loss: 0.02180263213813305, Neurons: 64, Grad norm: 3.828e-01\n",
      "Epoch 10034, Loss: 0.02180263213813305, Neurons: 64, Grad norm: 3.828e-01\n",
      "Epoch 10035, Loss: 0.02177872136235237, Neurons: 64, Grad norm: 1.957e-01\n",
      "Epoch 10035, Loss: 0.02177872136235237, Neurons: 64, Grad norm: 1.957e-01\n",
      "Epoch 10036, Loss: 0.021759407594799995, Neurons: 64, Grad norm: 1.922e-01\n",
      "Epoch 10036, Loss: 0.021759407594799995, Neurons: 64, Grad norm: 1.922e-01\n",
      "Epoch 10037, Loss: 0.02174392156302929, Neurons: 64, Grad norm: 3.223e-01\n",
      "Epoch 10037, Loss: 0.02174392156302929, Neurons: 64, Grad norm: 3.223e-01\n",
      "Epoch 10038, Loss: 0.021730244159698486, Neurons: 64, Grad norm: 4.181e-01\n",
      "Epoch 10038, Loss: 0.021730244159698486, Neurons: 64, Grad norm: 4.181e-01\n",
      "Epoch 10039, Loss: 0.02171599678695202, Neurons: 64, Grad norm: 4.358e-01\n",
      "Epoch 10039, Loss: 0.02171599678695202, Neurons: 64, Grad norm: 4.358e-01\n",
      "Epoch 10040, Loss: 0.02169911377131939, Neurons: 64, Grad norm: 3.946e-01\n",
      "Epoch 10040, Loss: 0.02169911377131939, Neurons: 64, Grad norm: 3.946e-01\n",
      "Epoch 10041, Loss: 0.021679680794477463, Neurons: 64, Grad norm: 2.964e-01\n",
      "Epoch 10041, Loss: 0.021679680794477463, Neurons: 64, Grad norm: 2.964e-01\n",
      "Epoch 10042, Loss: 0.021659215912222862, Neurons: 64, Grad norm: 1.817e-01\n",
      "Epoch 10042, Loss: 0.021659215912222862, Neurons: 64, Grad norm: 1.817e-01\n",
      "Epoch 10043, Loss: 0.021639354526996613, Neurons: 64, Grad norm: 6.306e-02\n",
      "Epoch 10043, Loss: 0.021639354526996613, Neurons: 64, Grad norm: 6.306e-02\n",
      "Epoch 10044, Loss: 0.021621357649564743, Neurons: 64, Grad norm: 1.231e-01\n",
      "Epoch 10044, Loss: 0.021621357649564743, Neurons: 64, Grad norm: 1.231e-01\n",
      "Epoch 10045, Loss: 0.02160514146089554, Neurons: 64, Grad norm: 2.051e-01\n",
      "Epoch 10045, Loss: 0.02160514146089554, Neurons: 64, Grad norm: 2.051e-01\n",
      "Epoch 10046, Loss: 0.02158983424305916, Neurons: 64, Grad norm: 2.571e-01\n",
      "Epoch 10046, Loss: 0.02158983424305916, Neurons: 64, Grad norm: 2.571e-01\n",
      "Epoch 10047, Loss: 0.02157420478761196, Neurons: 64, Grad norm: 2.750e-01\n",
      "Epoch 10047, Loss: 0.02157420478761196, Neurons: 64, Grad norm: 2.750e-01\n",
      "Epoch 10048, Loss: 0.021557873114943504, Neurons: 64, Grad norm: 2.548e-01\n",
      "Epoch 10048, Loss: 0.021557873114943504, Neurons: 64, Grad norm: 2.548e-01\n",
      "Epoch 10049, Loss: 0.02154037170112133, Neurons: 64, Grad norm: 2.128e-01\n",
      "Epoch 10049, Loss: 0.02154037170112133, Neurons: 64, Grad norm: 2.128e-01\n",
      "Epoch 10050, Loss: 0.021522266790270805, Neurons: 64, Grad norm: 1.867e-01\n",
      "Epoch 10050, Loss: 0.021522266790270805, Neurons: 64, Grad norm: 1.867e-01\n",
      "Epoch 10051, Loss: 0.02150413766503334, Neurons: 64, Grad norm: 1.883e-01\n",
      "Epoch 10051, Loss: 0.02150413766503334, Neurons: 64, Grad norm: 1.883e-01\n",
      "Epoch 10052, Loss: 0.021486535668373108, Neurons: 64, Grad norm: 2.591e-01\n",
      "Epoch 10052, Loss: 0.021486535668373108, Neurons: 64, Grad norm: 2.591e-01\n",
      "Epoch 10053, Loss: 0.02146945334970951, Neurons: 64, Grad norm: 3.197e-01\n",
      "Epoch 10053, Loss: 0.02146945334970951, Neurons: 64, Grad norm: 3.197e-01\n",
      "Epoch 10054, Loss: 0.021453065797686577, Neurons: 64, Grad norm: 4.091e-01\n",
      "Epoch 10054, Loss: 0.021453065797686577, Neurons: 64, Grad norm: 4.091e-01\n",
      "Epoch 10055, Loss: 0.021437058225274086, Neurons: 64, Grad norm: 4.639e-01\n",
      "Epoch 10055, Loss: 0.021437058225274086, Neurons: 64, Grad norm: 4.639e-01\n",
      "Epoch 10056, Loss: 0.021421238780021667, Neurons: 64, Grad norm: 5.357e-01\n",
      "Epoch 10056, Loss: 0.021421238780021667, Neurons: 64, Grad norm: 5.357e-01\n",
      "Epoch 10057, Loss: 0.02140531688928604, Neurons: 64, Grad norm: 5.695e-01\n",
      "Epoch 10057, Loss: 0.02140531688928604, Neurons: 64, Grad norm: 5.695e-01\n",
      "Epoch 10058, Loss: 0.02138921245932579, Neurons: 64, Grad norm: 6.202e-01\n",
      "Epoch 10058, Loss: 0.02138921245932579, Neurons: 64, Grad norm: 6.202e-01\n",
      "Epoch 10059, Loss: 0.021373149007558823, Neurons: 64, Grad norm: 6.439e-01\n",
      "Epoch 10059, Loss: 0.021373149007558823, Neurons: 64, Grad norm: 6.439e-01\n",
      "Epoch 10060, Loss: 0.02135699987411499, Neurons: 64, Grad norm: 7.027e-01\n",
      "Epoch 10060, Loss: 0.02135699987411499, Neurons: 64, Grad norm: 7.027e-01\n",
      "Epoch 10061, Loss: 0.021341398358345032, Neurons: 64, Grad norm: 7.481e-01\n",
      "Epoch 10061, Loss: 0.021341398358345032, Neurons: 64, Grad norm: 7.481e-01\n",
      "Epoch 10062, Loss: 0.021326443180441856, Neurons: 64, Grad norm: 8.458e-01\n",
      "Epoch 10062, Loss: 0.021326443180441856, Neurons: 64, Grad norm: 8.458e-01\n",
      "Epoch 10063, Loss: 0.021312570199370384, Neurons: 64, Grad norm: 9.398e-01\n",
      "Epoch 10063, Loss: 0.021312570199370384, Neurons: 64, Grad norm: 9.398e-01\n",
      "Epoch 10064, Loss: 0.021300269290804863, Neurons: 64, Grad norm: 1.090e+00\n",
      "Epoch 10064, Loss: 0.021300269290804863, Neurons: 64, Grad norm: 1.090e+00\n",
      "Epoch 10065, Loss: 0.021289821714162827, Neurons: 64, Grad norm: 1.253e+00\n",
      "Epoch 10065, Loss: 0.021289821714162827, Neurons: 64, Grad norm: 1.253e+00\n",
      "Epoch 10066, Loss: 0.021281704306602478, Neurons: 64, Grad norm: 1.492e+00\n",
      "Epoch 10066, Loss: 0.021281704306602478, Neurons: 64, Grad norm: 1.492e+00\n",
      "Epoch 10067, Loss: 0.021276772022247314, Neurons: 64, Grad norm: 1.755e+00\n",
      "Epoch 10067, Loss: 0.021276772022247314, Neurons: 64, Grad norm: 1.755e+00\n",
      "Epoch 10068, Loss: 0.021276075392961502, Neurons: 64, Grad norm: 2.105e+00\n",
      "Epoch 10068, Loss: 0.021276075392961502, Neurons: 64, Grad norm: 2.105e+00\n",
      "Epoch 10069, Loss: 0.02128160558640957, Neurons: 64, Grad norm: 2.495e+00\n",
      "Epoch 10069, Loss: 0.02128160558640957, Neurons: 64, Grad norm: 2.495e+00\n",
      "Epoch 10070, Loss: 0.021295946091413498, Neurons: 64, Grad norm: 2.992e+00\n",
      "Epoch 10070, Loss: 0.021295946091413498, Neurons: 64, Grad norm: 2.992e+00\n",
      "Epoch 10071, Loss: 0.021322915330529213, Neurons: 64, Grad norm: 3.539e+00\n",
      "Epoch 10071, Loss: 0.021322915330529213, Neurons: 64, Grad norm: 3.539e+00\n",
      "Epoch 10072, Loss: 0.021366123110055923, Neurons: 64, Grad norm: 4.190e+00\n",
      "Epoch 10072, Loss: 0.021366123110055923, Neurons: 64, Grad norm: 4.190e+00\n",
      "Epoch 10073, Loss: 0.021430062130093575, Neurons: 64, Grad norm: 4.878e+00\n",
      "Epoch 10073, Loss: 0.021430062130093575, Neurons: 64, Grad norm: 4.878e+00\n",
      "Epoch 10074, Loss: 0.021517086774110794, Neurons: 64, Grad norm: 5.633e+00\n",
      "Epoch 10074, Loss: 0.021517086774110794, Neurons: 64, Grad norm: 5.633e+00\n",
      "Epoch 10075, Loss: 0.021625250577926636, Neurons: 64, Grad norm: 6.333e+00\n",
      "Epoch 10075, Loss: 0.021625250577926636, Neurons: 64, Grad norm: 6.333e+00\n",
      "Epoch 10076, Loss: 0.021744467318058014, Neurons: 64, Grad norm: 6.935e+00\n",
      "Epoch 10076, Loss: 0.021744467318058014, Neurons: 64, Grad norm: 6.935e+00\n",
      "Epoch 10077, Loss: 0.021851113066077232, Neurons: 64, Grad norm: 7.263e+00\n",
      "Epoch 10077, Loss: 0.021851113066077232, Neurons: 64, Grad norm: 7.263e+00\n",
      "Epoch 10078, Loss: 0.021907230839133263, Neurons: 64, Grad norm: 7.233e+00\n",
      "Epoch 10078, Loss: 0.021907230839133263, Neurons: 64, Grad norm: 7.233e+00\n",
      "Epoch 10079, Loss: 0.02187150903046131, Neurons: 64, Grad norm: 6.667e+00\n",
      "Epoch 10079, Loss: 0.02187150903046131, Neurons: 64, Grad norm: 6.667e+00\n",
      "Epoch 10080, Loss: 0.021723909303545952, Neurons: 64, Grad norm: 5.584e+00\n",
      "Epoch 10080, Loss: 0.021723909303545952, Neurons: 64, Grad norm: 5.584e+00\n",
      "Epoch 10081, Loss: 0.021487900987267494, Neurons: 64, Grad norm: 4.005e+00\n",
      "Epoch 10081, Loss: 0.021487900987267494, Neurons: 64, Grad norm: 4.005e+00\n",
      "Epoch 10082, Loss: 0.02123391442000866, Neurons: 64, Grad norm: 2.174e+00\n",
      "Epoch 10082, Loss: 0.02123391442000866, Neurons: 64, Grad norm: 2.174e+00\n",
      "Epoch 10083, Loss: 0.021042685955762863, Neurons: 64, Grad norm: 3.900e-01\n",
      "Epoch 10083, Loss: 0.021042685955762863, Neurons: 64, Grad norm: 3.900e-01\n",
      "Epoch 10084, Loss: 0.02096325345337391, Neurons: 64, Grad norm: 1.557e+00\n",
      "Epoch 10084, Loss: 0.02096325345337391, Neurons: 64, Grad norm: 1.557e+00\n",
      "Epoch 10085, Loss: 0.020989837124943733, Neurons: 64, Grad norm: 2.970e+00\n",
      "Epoch 10085, Loss: 0.020989837124943733, Neurons: 64, Grad norm: 2.970e+00\n",
      "Epoch 10086, Loss: 0.0210740864276886, Neurons: 64, Grad norm: 3.887e+00\n",
      "Epoch 10086, Loss: 0.0210740864276886, Neurons: 64, Grad norm: 3.887e+00\n",
      "Epoch 10087, Loss: 0.02115417644381523, Neurons: 64, Grad norm: 4.294e+00\n",
      "Epoch 10087, Loss: 0.02115417644381523, Neurons: 64, Grad norm: 4.294e+00\n",
      "Epoch 10088, Loss: 0.02118164487183094, Neurons: 64, Grad norm: 4.125e+00\n",
      "Epoch 10088, Loss: 0.02118164487183094, Neurons: 64, Grad norm: 4.125e+00\n",
      "Epoch 10089, Loss: 0.021138817071914673, Neurons: 64, Grad norm: 3.485e+00\n",
      "Epoch 10089, Loss: 0.021138817071914673, Neurons: 64, Grad norm: 3.485e+00\n",
      "Epoch 10090, Loss: 0.021042877808213234, Neurons: 64, Grad norm: 2.437e+00\n",
      "Epoch 10090, Loss: 0.021042877808213234, Neurons: 64, Grad norm: 2.437e+00\n",
      "Epoch 10091, Loss: 0.020934218540787697, Neurons: 64, Grad norm: 1.217e+00\n",
      "Epoch 10091, Loss: 0.020934218540787697, Neurons: 64, Grad norm: 1.217e+00\n",
      "Epoch 10092, Loss: 0.02085314877331257, Neurons: 64, Grad norm: 3.388e-01\n",
      "Epoch 10092, Loss: 0.02085314877331257, Neurons: 64, Grad norm: 3.388e-01\n",
      "Epoch 10093, Loss: 0.020820453763008118, Neurons: 64, Grad norm: 1.277e+00\n",
      "Epoch 10093, Loss: 0.020820453763008118, Neurons: 64, Grad norm: 1.277e+00\n",
      "Epoch 10094, Loss: 0.020829830318689346, Neurons: 64, Grad norm: 2.145e+00\n",
      "Epoch 10094, Loss: 0.020829830318689346, Neurons: 64, Grad norm: 2.145e+00\n",
      "Epoch 10095, Loss: 0.0208571907132864, Neurons: 64, Grad norm: 2.634e+00\n",
      "Epoch 10095, Loss: 0.0208571907132864, Neurons: 64, Grad norm: 2.634e+00\n",
      "Epoch 10096, Loss: 0.02087504230439663, Neurons: 64, Grad norm: 2.772e+00\n",
      "Epoch 10096, Loss: 0.02087504230439663, Neurons: 64, Grad norm: 2.772e+00\n",
      "Epoch 10097, Loss: 0.020866243168711662, Neurons: 64, Grad norm: 2.520e+00\n",
      "Epoch 10097, Loss: 0.020866243168711662, Neurons: 64, Grad norm: 2.520e+00\n",
      "Epoch 10098, Loss: 0.020829997956752777, Neurons: 64, Grad norm: 2.001e+00\n",
      "Epoch 10098, Loss: 0.020829997956752777, Neurons: 64, Grad norm: 2.001e+00\n",
      "Epoch 10099, Loss: 0.020778287202119827, Neurons: 64, Grad norm: 1.262e+00\n",
      "Epoch 10099, Loss: 0.020778287202119827, Neurons: 64, Grad norm: 1.262e+00\n",
      "Epoch 10099, Test loss: 0.013517233543097973\n",
      "Epoch 10099, Test loss: 0.013517233543097973\n",
      "Epoch 10100, Loss: 0.020728375762701035, Neurons: 64, Grad norm: 4.990e-01\n",
      "Epoch 10100, Loss: 0.020728375762701035, Neurons: 64, Grad norm: 4.990e-01\n",
      "Epoch 10101, Loss: 0.020693683996796608, Neurons: 64, Grad norm: 4.549e-01\n",
      "Epoch 10101, Loss: 0.020693683996796608, Neurons: 64, Grad norm: 4.549e-01\n",
      "Epoch 10102, Loss: 0.020678116008639336, Neurons: 64, Grad norm: 1.058e+00\n",
      "Epoch 10102, Loss: 0.020678116008639336, Neurons: 64, Grad norm: 1.058e+00\n",
      "Epoch 10103, Loss: 0.0206760223954916, Neurons: 64, Grad norm: 1.532e+00\n",
      "Epoch 10103, Loss: 0.0206760223954916, Neurons: 64, Grad norm: 1.532e+00\n",
      "Epoch 10104, Loss: 0.020677125081419945, Neurons: 64, Grad norm: 1.754e+00\n",
      "Epoch 10104, Loss: 0.020677125081419945, Neurons: 64, Grad norm: 1.754e+00\n",
      "Epoch 10105, Loss: 0.020671868696808815, Neurons: 64, Grad norm: 1.776e+00\n",
      "Epoch 10105, Loss: 0.020671868696808815, Neurons: 64, Grad norm: 1.776e+00\n",
      "Epoch 10106, Loss: 0.020655851811170578, Neurons: 64, Grad norm: 1.558e+00\n",
      "Epoch 10106, Loss: 0.020655851811170578, Neurons: 64, Grad norm: 1.558e+00\n",
      "Epoch 10107, Loss: 0.02063017338514328, Neurons: 64, Grad norm: 1.206e+00\n",
      "Epoch 10107, Loss: 0.02063017338514328, Neurons: 64, Grad norm: 1.206e+00\n",
      "Epoch 10108, Loss: 0.020600127056241035, Neurons: 64, Grad norm: 7.354e-01\n",
      "Epoch 10108, Loss: 0.020600127056241035, Neurons: 64, Grad norm: 7.354e-01\n",
      "Epoch 10109, Loss: 0.020571870729327202, Neurons: 64, Grad norm: 2.784e-01\n",
      "Epoch 10109, Loss: 0.020571870729327202, Neurons: 64, Grad norm: 2.784e-01\n",
      "Epoch 10110, Loss: 0.020549457520246506, Neurons: 64, Grad norm: 3.166e-01\n",
      "Epoch 10110, Loss: 0.020549457520246506, Neurons: 64, Grad norm: 3.166e-01\n",
      "Epoch 10111, Loss: 0.0205340925604105, Neurons: 64, Grad norm: 6.761e-01\n",
      "Epoch 10111, Loss: 0.0205340925604105, Neurons: 64, Grad norm: 6.761e-01\n",
      "Epoch 10112, Loss: 0.02052363008260727, Neurons: 64, Grad norm: 9.724e-01\n",
      "Epoch 10112, Loss: 0.02052363008260727, Neurons: 64, Grad norm: 9.724e-01\n",
      "Epoch 10113, Loss: 0.02051481045782566, Neurons: 64, Grad norm: 1.111e+00\n",
      "Epoch 10113, Loss: 0.02051481045782566, Neurons: 64, Grad norm: 1.111e+00\n",
      "Epoch 10114, Loss: 0.02050379291176796, Neurons: 64, Grad norm: 1.149e+00\n",
      "Epoch 10114, Loss: 0.02050379291176796, Neurons: 64, Grad norm: 1.149e+00\n",
      "Epoch 10115, Loss: 0.0204891636967659, Neurons: 64, Grad norm: 1.038e+00\n",
      "Epoch 10115, Loss: 0.0204891636967659, Neurons: 64, Grad norm: 1.038e+00\n",
      "Epoch 10116, Loss: 0.02047063410282135, Neurons: 64, Grad norm: 8.583e-01\n",
      "Epoch 10116, Loss: 0.02047063410282135, Neurons: 64, Grad norm: 8.583e-01\n",
      "Epoch 10117, Loss: 0.020450107753276825, Neurons: 64, Grad norm: 5.877e-01\n",
      "Epoch 10117, Loss: 0.020450107753276825, Neurons: 64, Grad norm: 5.877e-01\n",
      "Epoch 10118, Loss: 0.020429566502571106, Neurons: 64, Grad norm: 3.176e-01\n",
      "Epoch 10118, Loss: 0.020429566502571106, Neurons: 64, Grad norm: 3.176e-01\n",
      "Epoch 10119, Loss: 0.020410390570759773, Neurons: 64, Grad norm: 1.155e-01\n",
      "Epoch 10119, Loss: 0.020410390570759773, Neurons: 64, Grad norm: 1.155e-01\n",
      "Epoch 10120, Loss: 0.02039358764886856, Neurons: 64, Grad norm: 2.792e-01\n",
      "Epoch 10120, Loss: 0.02039358764886856, Neurons: 64, Grad norm: 2.792e-01\n",
      "Epoch 10121, Loss: 0.020379014313220978, Neurons: 64, Grad norm: 5.002e-01\n",
      "Epoch 10121, Loss: 0.020379014313220978, Neurons: 64, Grad norm: 5.002e-01\n",
      "Epoch 10122, Loss: 0.020366113632917404, Neurons: 64, Grad norm: 6.312e-01\n",
      "Epoch 10122, Loss: 0.020366113632917404, Neurons: 64, Grad norm: 6.312e-01\n",
      "Epoch 10123, Loss: 0.020352987572550774, Neurons: 64, Grad norm: 7.217e-01\n",
      "Epoch 10123, Loss: 0.020352987572550774, Neurons: 64, Grad norm: 7.217e-01\n",
      "Epoch 10124, Loss: 0.02033935859799385, Neurons: 64, Grad norm: 7.146e-01\n",
      "Epoch 10124, Loss: 0.02033935859799385, Neurons: 64, Grad norm: 7.146e-01\n",
      "Epoch 10125, Loss: 0.02032424882054329, Neurons: 64, Grad norm: 6.765e-01\n",
      "Epoch 10125, Loss: 0.02032424882054329, Neurons: 64, Grad norm: 6.765e-01\n",
      "Epoch 10126, Loss: 0.020308170467615128, Neurons: 64, Grad norm: 5.595e-01\n",
      "Epoch 10126, Loss: 0.020308170467615128, Neurons: 64, Grad norm: 5.595e-01\n",
      "Epoch 10127, Loss: 0.020291076973080635, Neurons: 64, Grad norm: 4.314e-01\n",
      "Epoch 10127, Loss: 0.020291076973080635, Neurons: 64, Grad norm: 4.314e-01\n",
      "Epoch 10128, Loss: 0.020273838192224503, Neurons: 64, Grad norm: 2.587e-01\n",
      "Epoch 10128, Loss: 0.020273838192224503, Neurons: 64, Grad norm: 2.587e-01\n",
      "Epoch 10129, Loss: 0.0202568881213665, Neurons: 64, Grad norm: 1.149e-01\n",
      "Epoch 10129, Loss: 0.0202568881213665, Neurons: 64, Grad norm: 1.149e-01\n",
      "Epoch 10130, Loss: 0.020240815356373787, Neurons: 64, Grad norm: 8.642e-02\n",
      "Epoch 10130, Loss: 0.020240815356373787, Neurons: 64, Grad norm: 8.642e-02\n",
      "Epoch 10131, Loss: 0.020225515589118004, Neurons: 64, Grad norm: 1.956e-01\n",
      "Epoch 10131, Loss: 0.020225515589118004, Neurons: 64, Grad norm: 1.956e-01\n",
      "Epoch 10132, Loss: 0.020210854709148407, Neurons: 64, Grad norm: 3.154e-01\n",
      "Epoch 10132, Loss: 0.020210854709148407, Neurons: 64, Grad norm: 3.154e-01\n",
      "Epoch 10133, Loss: 0.020196476951241493, Neurons: 64, Grad norm: 3.718e-01\n",
      "Epoch 10133, Loss: 0.020196476951241493, Neurons: 64, Grad norm: 3.718e-01\n",
      "Epoch 10134, Loss: 0.020182177424430847, Neurons: 64, Grad norm: 4.247e-01\n",
      "Epoch 10134, Loss: 0.020182177424430847, Neurons: 64, Grad norm: 4.247e-01\n",
      "Epoch 10135, Loss: 0.02016764134168625, Neurons: 64, Grad norm: 4.210e-01\n",
      "Epoch 10135, Loss: 0.02016764134168625, Neurons: 64, Grad norm: 4.210e-01\n",
      "Epoch 10136, Loss: 0.02015274576842785, Neurons: 64, Grad norm: 4.150e-01\n",
      "Epoch 10136, Loss: 0.02015274576842785, Neurons: 64, Grad norm: 4.150e-01\n",
      "Epoch 10137, Loss: 0.02013757824897766, Neurons: 64, Grad norm: 3.553e-01\n",
      "Epoch 10137, Loss: 0.02013757824897766, Neurons: 64, Grad norm: 3.553e-01\n",
      "Epoch 10138, Loss: 0.020122099667787552, Neurons: 64, Grad norm: 3.116e-01\n",
      "Epoch 10138, Loss: 0.020122099667787552, Neurons: 64, Grad norm: 3.116e-01\n",
      "Epoch 10139, Loss: 0.020106449723243713, Neurons: 64, Grad norm: 2.288e-01\n",
      "Epoch 10139, Loss: 0.020106449723243713, Neurons: 64, Grad norm: 2.288e-01\n",
      "Epoch 10140, Loss: 0.02009093202650547, Neurons: 64, Grad norm: 1.625e-01\n",
      "Epoch 10140, Loss: 0.02009093202650547, Neurons: 64, Grad norm: 1.625e-01\n",
      "Epoch 10141, Loss: 0.020075419917702675, Neurons: 64, Grad norm: 7.379e-02\n",
      "Epoch 10141, Loss: 0.020075419917702675, Neurons: 64, Grad norm: 7.379e-02\n",
      "Epoch 10142, Loss: 0.020060263574123383, Neurons: 64, Grad norm: 2.998e-02\n",
      "Epoch 10142, Loss: 0.020060263574123383, Neurons: 64, Grad norm: 2.998e-02\n",
      "Epoch 10143, Loss: 0.020045170560479164, Neurons: 64, Grad norm: 8.461e-02\n",
      "Epoch 10143, Loss: 0.020045170560479164, Neurons: 64, Grad norm: 8.461e-02\n",
      "Epoch 10144, Loss: 0.020030410960316658, Neurons: 64, Grad norm: 1.307e-01\n",
      "Epoch 10144, Loss: 0.020030410960316658, Neurons: 64, Grad norm: 1.307e-01\n",
      "Epoch 10145, Loss: 0.020015668123960495, Neurons: 64, Grad norm: 1.952e-01\n",
      "Epoch 10145, Loss: 0.020015668123960495, Neurons: 64, Grad norm: 1.952e-01\n",
      "Epoch 10146, Loss: 0.020001104101538658, Neurons: 64, Grad norm: 2.197e-01\n",
      "Epoch 10146, Loss: 0.020001104101538658, Neurons: 64, Grad norm: 2.197e-01\n",
      "Epoch 10147, Loss: 0.019986506551504135, Neurons: 64, Grad norm: 2.592e-01\n",
      "Epoch 10147, Loss: 0.019986506551504135, Neurons: 64, Grad norm: 2.592e-01\n",
      "Epoch 10148, Loss: 0.01997194066643715, Neurons: 64, Grad norm: 2.602e-01\n",
      "Epoch 10148, Loss: 0.01997194066643715, Neurons: 64, Grad norm: 2.602e-01\n",
      "Epoch 10149, Loss: 0.019957318902015686, Neurons: 64, Grad norm: 2.814e-01\n",
      "Epoch 10149, Loss: 0.019957318902015686, Neurons: 64, Grad norm: 2.814e-01\n",
      "Epoch 10150, Loss: 0.01994263008236885, Neurons: 64, Grad norm: 2.622e-01\n",
      "Epoch 10150, Loss: 0.01994263008236885, Neurons: 64, Grad norm: 2.622e-01\n",
      "Epoch 10151, Loss: 0.019927840679883957, Neurons: 64, Grad norm: 2.588e-01\n",
      "Epoch 10151, Loss: 0.019927840679883957, Neurons: 64, Grad norm: 2.588e-01\n",
      "Epoch 10152, Loss: 0.01991296373307705, Neurons: 64, Grad norm: 2.273e-01\n",
      "Epoch 10152, Loss: 0.01991296373307705, Neurons: 64, Grad norm: 2.273e-01\n",
      "Epoch 10153, Loss: 0.019898133352398872, Neurons: 64, Grad norm: 2.149e-01\n",
      "Epoch 10153, Loss: 0.019898133352398872, Neurons: 64, Grad norm: 2.149e-01\n",
      "Epoch 10154, Loss: 0.01988324150443077, Neurons: 64, Grad norm: 1.744e-01\n",
      "Epoch 10154, Loss: 0.01988324150443077, Neurons: 64, Grad norm: 1.744e-01\n",
      "Epoch 10155, Loss: 0.01986829936504364, Neurons: 64, Grad norm: 1.538e-01\n",
      "Epoch 10155, Loss: 0.01986829936504364, Neurons: 64, Grad norm: 1.538e-01\n",
      "Epoch 10156, Loss: 0.019853295758366585, Neurons: 64, Grad norm: 1.151e-01\n",
      "Epoch 10156, Loss: 0.019853295758366585, Neurons: 64, Grad norm: 1.151e-01\n",
      "Epoch 10157, Loss: 0.019838517531752586, Neurons: 64, Grad norm: 1.004e-01\n",
      "Epoch 10157, Loss: 0.019838517531752586, Neurons: 64, Grad norm: 1.004e-01\n",
      "Epoch 10158, Loss: 0.01982378214597702, Neurons: 64, Grad norm: 6.085e-02\n",
      "Epoch 10158, Loss: 0.01982378214597702, Neurons: 64, Grad norm: 6.085e-02\n",
      "Epoch 10159, Loss: 0.019809052348136902, Neurons: 64, Grad norm: 4.827e-02\n",
      "Epoch 10159, Loss: 0.019809052348136902, Neurons: 64, Grad norm: 4.827e-02\n",
      "Epoch 10160, Loss: 0.019794417545199394, Neurons: 64, Grad norm: 3.100e-02\n",
      "Epoch 10160, Loss: 0.019794417545199394, Neurons: 64, Grad norm: 3.100e-02\n",
      "Epoch 10161, Loss: 0.019779741764068604, Neurons: 64, Grad norm: 3.175e-02\n",
      "Epoch 10161, Loss: 0.019779741764068604, Neurons: 64, Grad norm: 3.175e-02\n",
      "Epoch 10162, Loss: 0.019765187054872513, Neurons: 64, Grad norm: 4.754e-02\n",
      "Epoch 10162, Loss: 0.019765187054872513, Neurons: 64, Grad norm: 4.754e-02\n",
      "Epoch 10163, Loss: 0.01975071430206299, Neurons: 64, Grad norm: 6.083e-02\n",
      "Epoch 10163, Loss: 0.01975071430206299, Neurons: 64, Grad norm: 6.083e-02\n",
      "Epoch 10164, Loss: 0.01973620615899563, Neurons: 64, Grad norm: 8.656e-02\n",
      "Epoch 10164, Loss: 0.01973620615899563, Neurons: 64, Grad norm: 8.656e-02\n",
      "Epoch 10165, Loss: 0.019721783697605133, Neurons: 64, Grad norm: 8.826e-02\n",
      "Epoch 10165, Loss: 0.019721783697605133, Neurons: 64, Grad norm: 8.826e-02\n",
      "Epoch 10166, Loss: 0.019707253202795982, Neurons: 64, Grad norm: 1.199e-01\n",
      "Epoch 10166, Loss: 0.019707253202795982, Neurons: 64, Grad norm: 1.199e-01\n",
      "Epoch 10167, Loss: 0.019692888483405113, Neurons: 64, Grad norm: 1.231e-01\n",
      "Epoch 10167, Loss: 0.019692888483405113, Neurons: 64, Grad norm: 1.231e-01\n",
      "Epoch 10168, Loss: 0.019678408280014992, Neurons: 64, Grad norm: 1.387e-01\n",
      "Epoch 10168, Loss: 0.019678408280014992, Neurons: 64, Grad norm: 1.387e-01\n",
      "Epoch 10169, Loss: 0.019664056599140167, Neurons: 64, Grad norm: 1.347e-01\n",
      "Epoch 10169, Loss: 0.019664056599140167, Neurons: 64, Grad norm: 1.347e-01\n",
      "Epoch 10170, Loss: 0.019649704918265343, Neurons: 64, Grad norm: 1.648e-01\n",
      "Epoch 10170, Loss: 0.019649704918265343, Neurons: 64, Grad norm: 1.648e-01\n",
      "Epoch 10171, Loss: 0.019635334610939026, Neurons: 64, Grad norm: 1.573e-01\n",
      "Epoch 10171, Loss: 0.019635334610939026, Neurons: 64, Grad norm: 1.573e-01\n",
      "Epoch 10172, Loss: 0.01962096430361271, Neurons: 64, Grad norm: 1.721e-01\n",
      "Epoch 10172, Loss: 0.01962096430361271, Neurons: 64, Grad norm: 1.721e-01\n",
      "Epoch 10173, Loss: 0.01960669457912445, Neurons: 64, Grad norm: 1.760e-01\n",
      "Epoch 10173, Loss: 0.01960669457912445, Neurons: 64, Grad norm: 1.760e-01\n",
      "Epoch 10174, Loss: 0.01959230564534664, Neurons: 64, Grad norm: 1.983e-01\n",
      "Epoch 10174, Loss: 0.01959230564534664, Neurons: 64, Grad norm: 1.983e-01\n",
      "Epoch 10175, Loss: 0.01957804337143898, Neurons: 64, Grad norm: 1.951e-01\n",
      "Epoch 10175, Loss: 0.01957804337143898, Neurons: 64, Grad norm: 1.951e-01\n",
      "Epoch 10176, Loss: 0.01956372894346714, Neurons: 64, Grad norm: 2.184e-01\n",
      "Epoch 10176, Loss: 0.01956372894346714, Neurons: 64, Grad norm: 2.184e-01\n",
      "Epoch 10177, Loss: 0.01954948715865612, Neurons: 64, Grad norm: 2.165e-01\n",
      "Epoch 10177, Loss: 0.01954948715865612, Neurons: 64, Grad norm: 2.165e-01\n",
      "Epoch 10178, Loss: 0.019535237923264503, Neurons: 64, Grad norm: 2.468e-01\n",
      "Epoch 10178, Loss: 0.019535237923264503, Neurons: 64, Grad norm: 2.468e-01\n",
      "Epoch 10179, Loss: 0.019521057605743408, Neurons: 64, Grad norm: 2.563e-01\n",
      "Epoch 10179, Loss: 0.019521057605743408, Neurons: 64, Grad norm: 2.563e-01\n",
      "Epoch 10180, Loss: 0.019506989046931267, Neurons: 64, Grad norm: 2.977e-01\n",
      "Epoch 10180, Loss: 0.019506989046931267, Neurons: 64, Grad norm: 2.977e-01\n",
      "Epoch 10181, Loss: 0.019492950290441513, Neurons: 64, Grad norm: 3.159e-01\n",
      "Epoch 10181, Loss: 0.019492950290441513, Neurons: 64, Grad norm: 3.159e-01\n",
      "Epoch 10182, Loss: 0.01947898417711258, Neurons: 64, Grad norm: 3.703e-01\n",
      "Epoch 10182, Loss: 0.01947898417711258, Neurons: 64, Grad norm: 3.703e-01\n",
      "Epoch 10183, Loss: 0.019465293735265732, Neurons: 64, Grad norm: 4.027e-01\n",
      "Epoch 10183, Loss: 0.019465293735265732, Neurons: 64, Grad norm: 4.027e-01\n",
      "Epoch 10184, Loss: 0.0194516833871603, Neurons: 64, Grad norm: 4.676e-01\n",
      "Epoch 10184, Loss: 0.0194516833871603, Neurons: 64, Grad norm: 4.676e-01\n",
      "Epoch 10185, Loss: 0.019438186660408974, Neurons: 64, Grad norm: 5.201e-01\n",
      "Epoch 10185, Loss: 0.019438186660408974, Neurons: 64, Grad norm: 5.201e-01\n",
      "Epoch 10186, Loss: 0.01942513883113861, Neurons: 64, Grad norm: 6.062e-01\n",
      "Epoch 10186, Loss: 0.01942513883113861, Neurons: 64, Grad norm: 6.062e-01\n",
      "Epoch 10187, Loss: 0.019412273541092873, Neurons: 64, Grad norm: 6.817e-01\n",
      "Epoch 10187, Loss: 0.019412273541092873, Neurons: 64, Grad norm: 6.817e-01\n",
      "Epoch 10188, Loss: 0.01940022222697735, Neurons: 64, Grad norm: 8.080e-01\n",
      "Epoch 10188, Loss: 0.01940022222697735, Neurons: 64, Grad norm: 8.080e-01\n",
      "Epoch 10189, Loss: 0.019388550892472267, Neurons: 64, Grad norm: 9.167e-01\n",
      "Epoch 10189, Loss: 0.019388550892472267, Neurons: 64, Grad norm: 9.167e-01\n",
      "Epoch 10190, Loss: 0.01937798038125038, Neurons: 64, Grad norm: 1.080e+00\n",
      "Epoch 10190, Loss: 0.01937798038125038, Neurons: 64, Grad norm: 1.080e+00\n",
      "Epoch 10191, Loss: 0.019368529319763184, Neurons: 64, Grad norm: 1.254e+00\n",
      "Epoch 10191, Loss: 0.019368529319763184, Neurons: 64, Grad norm: 1.254e+00\n",
      "Epoch 10192, Loss: 0.019360996782779694, Neurons: 64, Grad norm: 1.493e+00\n",
      "Epoch 10192, Loss: 0.019360996782779694, Neurons: 64, Grad norm: 1.493e+00\n",
      "Epoch 10193, Loss: 0.01935613714158535, Neurons: 64, Grad norm: 1.745e+00\n",
      "Epoch 10193, Loss: 0.01935613714158535, Neurons: 64, Grad norm: 1.745e+00\n",
      "Epoch 10194, Loss: 0.01935533992946148, Neurons: 64, Grad norm: 2.089e+00\n",
      "Epoch 10194, Loss: 0.01935533992946148, Neurons: 64, Grad norm: 2.089e+00\n",
      "Epoch 10195, Loss: 0.019360531121492386, Neurons: 64, Grad norm: 2.479e+00\n",
      "Epoch 10195, Loss: 0.019360531121492386, Neurons: 64, Grad norm: 2.479e+00\n",
      "Epoch 10196, Loss: 0.019373947754502296, Neurons: 64, Grad norm: 2.972e+00\n",
      "Epoch 10196, Loss: 0.019373947754502296, Neurons: 64, Grad norm: 2.972e+00\n",
      "Epoch 10197, Loss: 0.019399216398596764, Neurons: 64, Grad norm: 3.528e+00\n",
      "Epoch 10197, Loss: 0.019399216398596764, Neurons: 64, Grad norm: 3.528e+00\n",
      "Epoch 10198, Loss: 0.019441109150648117, Neurons: 64, Grad norm: 4.214e+00\n",
      "Epoch 10198, Loss: 0.019441109150648117, Neurons: 64, Grad norm: 4.214e+00\n",
      "Epoch 10199, Loss: 0.019504809752106667, Neurons: 64, Grad norm: 4.974e+00\n",
      "Epoch 10199, Loss: 0.019504809752106667, Neurons: 64, Grad norm: 4.974e+00\n",
      "Epoch 10199, Test loss: 0.012756253592669964\n",
      "Epoch 10199, Test loss: 0.012756253592669964\n",
      "Epoch 10200, Loss: 0.019596589729189873, Neurons: 64, Grad norm: 5.848e+00\n",
      "Epoch 10200, Loss: 0.019596589729189873, Neurons: 64, Grad norm: 5.848e+00\n",
      "Epoch 10201, Loss: 0.01972062885761261, Neurons: 64, Grad norm: 6.732e+00\n",
      "Epoch 10201, Loss: 0.01972062885761261, Neurons: 64, Grad norm: 6.732e+00\n",
      "Epoch 10202, Loss: 0.01987638510763645, Neurons: 64, Grad norm: 7.607e+00\n",
      "Epoch 10202, Loss: 0.01987638510763645, Neurons: 64, Grad norm: 7.607e+00\n",
      "Epoch 10203, Loss: 0.020046433433890343, Neurons: 64, Grad norm: 8.272e+00\n",
      "Epoch 10203, Loss: 0.020046433433890343, Neurons: 64, Grad norm: 8.272e+00\n",
      "Epoch 10204, Loss: 0.020195290446281433, Neurons: 64, Grad norm: 8.598e+00\n",
      "Epoch 10204, Loss: 0.020195290446281433, Neurons: 64, Grad norm: 8.598e+00\n",
      "Epoch 10205, Loss: 0.02026183530688286, Neurons: 64, Grad norm: 8.331e+00\n",
      "Epoch 10205, Loss: 0.02026183530688286, Neurons: 64, Grad norm: 8.331e+00\n",
      "Epoch 10206, Loss: 0.020189115777611732, Neurons: 64, Grad norm: 7.392e+00\n",
      "Epoch 10206, Loss: 0.020189115777611732, Neurons: 64, Grad norm: 7.392e+00\n",
      "Epoch 10207, Loss: 0.01995605230331421, Neurons: 64, Grad norm: 5.716e+00\n",
      "Epoch 10207, Loss: 0.01995605230331421, Neurons: 64, Grad norm: 5.716e+00\n",
      "Epoch 10208, Loss: 0.01962389424443245, Neurons: 64, Grad norm: 3.553e+00\n",
      "Epoch 10208, Loss: 0.01962389424443245, Neurons: 64, Grad norm: 3.553e+00\n",
      "Epoch 10209, Loss: 0.019314076751470566, Neurons: 64, Grad norm: 1.266e+00\n",
      "Epoch 10209, Loss: 0.019314076751470566, Neurons: 64, Grad norm: 1.266e+00\n",
      "Epoch 10210, Loss: 0.019141091033816338, Neurons: 64, Grad norm: 1.516e+00\n",
      "Epoch 10210, Loss: 0.019141091033816338, Neurons: 64, Grad norm: 1.516e+00\n",
      "Epoch 10211, Loss: 0.019139766693115234, Neurons: 64, Grad norm: 3.350e+00\n",
      "Epoch 10211, Loss: 0.019139766693115234, Neurons: 64, Grad norm: 3.350e+00\n",
      "Epoch 10212, Loss: 0.01925724186003208, Neurons: 64, Grad norm: 4.606e+00\n",
      "Epoch 10212, Loss: 0.01925724186003208, Neurons: 64, Grad norm: 4.606e+00\n",
      "Epoch 10213, Loss: 0.01939118653535843, Neurons: 64, Grad norm: 5.141e+00\n",
      "Epoch 10213, Loss: 0.01939118653535843, Neurons: 64, Grad norm: 5.141e+00\n",
      "Epoch 10214, Loss: 0.019447507336735725, Neurons: 64, Grad norm: 4.862e+00\n",
      "Epoch 10214, Loss: 0.019447507336735725, Neurons: 64, Grad norm: 4.862e+00\n",
      "Epoch 10215, Loss: 0.01938602514564991, Neurons: 64, Grad norm: 3.894e+00\n",
      "Epoch 10215, Loss: 0.01938602514564991, Neurons: 64, Grad norm: 3.894e+00\n",
      "Epoch 10216, Loss: 0.01923663355410099, Neurons: 64, Grad norm: 2.382e+00\n",
      "Epoch 10216, Loss: 0.01923663355410099, Neurons: 64, Grad norm: 2.382e+00\n",
      "Epoch 10217, Loss: 0.019078636541962624, Neurons: 64, Grad norm: 6.819e-01\n",
      "Epoch 10217, Loss: 0.019078636541962624, Neurons: 64, Grad norm: 6.819e-01\n",
      "Epoch 10218, Loss: 0.018986158072948456, Neurons: 64, Grad norm: 1.016e+00\n",
      "Epoch 10218, Loss: 0.018986158072948456, Neurons: 64, Grad norm: 1.016e+00\n",
      "Epoch 10219, Loss: 0.018983891233801842, Neurons: 64, Grad norm: 2.331e+00\n",
      "Epoch 10219, Loss: 0.018983891233801842, Neurons: 64, Grad norm: 2.331e+00\n",
      "Epoch 10220, Loss: 0.01904170773923397, Neurons: 64, Grad norm: 3.184e+00\n",
      "Epoch 10220, Loss: 0.01904170773923397, Neurons: 64, Grad norm: 3.184e+00\n",
      "Epoch 10221, Loss: 0.019101183861494064, Neurons: 64, Grad norm: 3.421e+00\n",
      "Epoch 10221, Loss: 0.019101183861494064, Neurons: 64, Grad norm: 3.421e+00\n",
      "Epoch 10222, Loss: 0.019114991649985313, Neurons: 64, Grad norm: 3.108e+00\n",
      "Epoch 10222, Loss: 0.019114991649985313, Neurons: 64, Grad norm: 3.108e+00\n",
      "Epoch 10223, Loss: 0.019068920984864235, Neurons: 64, Grad norm: 2.297e+00\n",
      "Epoch 10223, Loss: 0.019068920984864235, Neurons: 64, Grad norm: 2.297e+00\n",
      "Epoch 10224, Loss: 0.018988411873579025, Neurons: 64, Grad norm: 1.225e+00\n",
      "Epoch 10224, Loss: 0.018988411873579025, Neurons: 64, Grad norm: 1.225e+00\n",
      "Epoch 10225, Loss: 0.018913650885224342, Neurons: 64, Grad norm: 2.238e-01\n",
      "Epoch 10225, Loss: 0.018913650885224342, Neurons: 64, Grad norm: 2.238e-01\n",
      "Epoch 10226, Loss: 0.018875541165471077, Neurons: 64, Grad norm: 1.082e+00\n",
      "Epoch 10226, Loss: 0.018875541165471077, Neurons: 64, Grad norm: 1.082e+00\n",
      "Epoch 10227, Loss: 0.018877381458878517, Neurons: 64, Grad norm: 1.892e+00\n",
      "Epoch 10227, Loss: 0.018877381458878517, Neurons: 64, Grad norm: 1.892e+00\n",
      "Epoch 10228, Loss: 0.018898889422416687, Neurons: 64, Grad norm: 2.299e+00\n",
      "Epoch 10228, Loss: 0.018898889422416687, Neurons: 64, Grad norm: 2.299e+00\n",
      "Epoch 10229, Loss: 0.018912628293037415, Neurons: 64, Grad norm: 2.333e+00\n",
      "Epoch 10229, Loss: 0.018912628293037415, Neurons: 64, Grad norm: 2.333e+00\n",
      "Epoch 10230, Loss: 0.018901672214269638, Neurons: 64, Grad norm: 1.972e+00\n",
      "Epoch 10230, Loss: 0.018901672214269638, Neurons: 64, Grad norm: 1.972e+00\n",
      "Epoch 10231, Loss: 0.018866421654820442, Neurons: 64, Grad norm: 1.369e+00\n",
      "Epoch 10231, Loss: 0.018866421654820442, Neurons: 64, Grad norm: 1.369e+00\n",
      "Epoch 10232, Loss: 0.018822025507688522, Neurons: 64, Grad norm: 5.886e-01\n",
      "Epoch 10232, Loss: 0.018822025507688522, Neurons: 64, Grad norm: 5.886e-01\n",
      "Epoch 10233, Loss: 0.01878616027534008, Neurons: 64, Grad norm: 2.529e-01\n",
      "Epoch 10233, Loss: 0.01878616027534008, Neurons: 64, Grad norm: 2.529e-01\n",
      "Epoch 10234, Loss: 0.01876833289861679, Neurons: 64, Grad norm: 9.182e-01\n",
      "Epoch 10234, Loss: 0.01876833289861679, Neurons: 64, Grad norm: 9.182e-01\n",
      "Epoch 10235, Loss: 0.018766243010759354, Neurons: 64, Grad norm: 1.378e+00\n",
      "Epoch 10235, Loss: 0.018766243010759354, Neurons: 64, Grad norm: 1.378e+00\n",
      "Epoch 10236, Loss: 0.01876932941377163, Neurons: 64, Grad norm: 1.624e+00\n",
      "Epoch 10236, Loss: 0.01876932941377163, Neurons: 64, Grad norm: 1.624e+00\n",
      "Epoch 10237, Loss: 0.01876666583120823, Neurons: 64, Grad norm: 1.583e+00\n",
      "Epoch 10237, Loss: 0.01876666583120823, Neurons: 64, Grad norm: 1.583e+00\n",
      "Epoch 10238, Loss: 0.018752172589302063, Neurons: 64, Grad norm: 1.344e+00\n",
      "Epoch 10238, Loss: 0.018752172589302063, Neurons: 64, Grad norm: 1.344e+00\n",
      "Epoch 10239, Loss: 0.018727904185652733, Neurons: 64, Grad norm: 9.091e-01\n",
      "Epoch 10239, Loss: 0.018727904185652733, Neurons: 64, Grad norm: 9.091e-01\n",
      "Epoch 10240, Loss: 0.01870063506066799, Neurons: 64, Grad norm: 4.267e-01\n",
      "Epoch 10240, Loss: 0.01870063506066799, Neurons: 64, Grad norm: 4.267e-01\n",
      "Epoch 10241, Loss: 0.018677644431591034, Neurons: 64, Grad norm: 1.417e-01\n",
      "Epoch 10241, Loss: 0.018677644431591034, Neurons: 64, Grad norm: 1.417e-01\n",
      "Epoch 10242, Loss: 0.01866237074136734, Neurons: 64, Grad norm: 5.376e-01\n",
      "Epoch 10242, Loss: 0.01866237074136734, Neurons: 64, Grad norm: 5.376e-01\n",
      "Epoch 10243, Loss: 0.01865350268781185, Neurons: 64, Grad norm: 8.672e-01\n",
      "Epoch 10243, Loss: 0.01865350268781185, Neurons: 64, Grad norm: 8.672e-01\n",
      "Epoch 10244, Loss: 0.01864711008965969, Neurons: 64, Grad norm: 1.023e+00\n",
      "Epoch 10244, Loss: 0.01864711008965969, Neurons: 64, Grad norm: 1.023e+00\n",
      "Epoch 10245, Loss: 0.018638737499713898, Neurons: 64, Grad norm: 1.045e+00\n",
      "Epoch 10245, Loss: 0.018638737499713898, Neurons: 64, Grad norm: 1.045e+00\n",
      "Epoch 10246, Loss: 0.018625982105731964, Neurons: 64, Grad norm: 8.971e-01\n",
      "Epoch 10246, Loss: 0.018625982105731964, Neurons: 64, Grad norm: 8.971e-01\n",
      "Epoch 10247, Loss: 0.018609018996357918, Neurons: 64, Grad norm: 6.831e-01\n",
      "Epoch 10247, Loss: 0.018609018996357918, Neurons: 64, Grad norm: 6.831e-01\n",
      "Epoch 10248, Loss: 0.018590394407510757, Neurons: 64, Grad norm: 3.702e-01\n",
      "Epoch 10248, Loss: 0.018590394407510757, Neurons: 64, Grad norm: 3.702e-01\n",
      "Epoch 10249, Loss: 0.01857275515794754, Neurons: 64, Grad norm: 7.911e-02\n",
      "Epoch 10249, Loss: 0.01857275515794754, Neurons: 64, Grad norm: 7.911e-02\n",
      "Epoch 10250, Loss: 0.018557926639914513, Neurons: 64, Grad norm: 2.546e-01\n",
      "Epoch 10250, Loss: 0.018557926639914513, Neurons: 64, Grad norm: 2.546e-01\n",
      "Epoch 10251, Loss: 0.01854589954018593, Neurons: 64, Grad norm: 4.655e-01\n",
      "Epoch 10251, Loss: 0.01854589954018593, Neurons: 64, Grad norm: 4.655e-01\n",
      "Epoch 10252, Loss: 0.018535584211349487, Neurons: 64, Grad norm: 6.300e-01\n",
      "Epoch 10252, Loss: 0.018535584211349487, Neurons: 64, Grad norm: 6.300e-01\n",
      "Epoch 10253, Loss: 0.01852540485560894, Neurons: 64, Grad norm: 6.775e-01\n",
      "Epoch 10253, Loss: 0.01852540485560894, Neurons: 64, Grad norm: 6.775e-01\n",
      "Epoch 10254, Loss: 0.01851392537355423, Neurons: 64, Grad norm: 6.632e-01\n",
      "Epoch 10254, Loss: 0.01851392537355423, Neurons: 64, Grad norm: 6.632e-01\n",
      "Epoch 10255, Loss: 0.018500518053770065, Neurons: 64, Grad norm: 5.544e-01\n",
      "Epoch 10255, Loss: 0.018500518053770065, Neurons: 64, Grad norm: 5.544e-01\n",
      "Epoch 10256, Loss: 0.01848602294921875, Neurons: 64, Grad norm: 4.176e-01\n",
      "Epoch 10256, Loss: 0.01848602294921875, Neurons: 64, Grad norm: 4.176e-01\n",
      "Epoch 10257, Loss: 0.018471108749508858, Neurons: 64, Grad norm: 2.320e-01\n",
      "Epoch 10257, Loss: 0.018471108749508858, Neurons: 64, Grad norm: 2.320e-01\n",
      "Epoch 10258, Loss: 0.01845661550760269, Neurons: 64, Grad norm: 1.339e-01\n",
      "Epoch 10258, Loss: 0.01845661550760269, Neurons: 64, Grad norm: 1.339e-01\n",
      "Epoch 10259, Loss: 0.0184431504458189, Neurons: 64, Grad norm: 2.275e-01\n",
      "Epoch 10259, Loss: 0.0184431504458189, Neurons: 64, Grad norm: 2.275e-01\n",
      "Epoch 10260, Loss: 0.01843095012009144, Neurons: 64, Grad norm: 3.426e-01\n",
      "Epoch 10260, Loss: 0.01843095012009144, Neurons: 64, Grad norm: 3.426e-01\n",
      "Epoch 10261, Loss: 0.01841912977397442, Neurons: 64, Grad norm: 4.549e-01\n",
      "Epoch 10261, Loss: 0.01841912977397442, Neurons: 64, Grad norm: 4.549e-01\n",
      "Epoch 10262, Loss: 0.018407700583338737, Neurons: 64, Grad norm: 4.908e-01\n",
      "Epoch 10262, Loss: 0.018407700583338737, Neurons: 64, Grad norm: 4.908e-01\n",
      "Epoch 10263, Loss: 0.01839585229754448, Neurons: 64, Grad norm: 5.174e-01\n",
      "Epoch 10263, Loss: 0.01839585229754448, Neurons: 64, Grad norm: 5.174e-01\n",
      "Epoch 10264, Loss: 0.018383800983428955, Neurons: 64, Grad norm: 4.754e-01\n",
      "Epoch 10264, Loss: 0.018383800983428955, Neurons: 64, Grad norm: 4.754e-01\n",
      "Epoch 10265, Loss: 0.018371056765317917, Neurons: 64, Grad norm: 4.418e-01\n",
      "Epoch 10265, Loss: 0.018371056765317917, Neurons: 64, Grad norm: 4.418e-01\n",
      "Epoch 10266, Loss: 0.018358251079916954, Neurons: 64, Grad norm: 3.707e-01\n",
      "Epoch 10266, Loss: 0.018358251079916954, Neurons: 64, Grad norm: 3.707e-01\n",
      "Epoch 10267, Loss: 0.018345585092902184, Neurons: 64, Grad norm: 3.429e-01\n",
      "Epoch 10267, Loss: 0.018345585092902184, Neurons: 64, Grad norm: 3.429e-01\n",
      "Epoch 10268, Loss: 0.018333595246076584, Neurons: 64, Grad norm: 3.325e-01\n",
      "Epoch 10268, Loss: 0.018333595246076584, Neurons: 64, Grad norm: 3.325e-01\n",
      "Epoch 10269, Loss: 0.01832214742898941, Neurons: 64, Grad norm: 3.723e-01\n",
      "Epoch 10269, Loss: 0.01832214742898941, Neurons: 64, Grad norm: 3.723e-01\n",
      "Epoch 10270, Loss: 0.018311364576220512, Neurons: 64, Grad norm: 4.229e-01\n",
      "Epoch 10270, Loss: 0.018311364576220512, Neurons: 64, Grad norm: 4.229e-01\n",
      "Epoch 10271, Loss: 0.018301231786608696, Neurons: 64, Grad norm: 4.794e-01\n",
      "Epoch 10271, Loss: 0.018301231786608696, Neurons: 64, Grad norm: 4.794e-01\n",
      "Epoch 10272, Loss: 0.018291939049959183, Neurons: 64, Grad norm: 5.307e-01\n",
      "Epoch 10272, Loss: 0.018291939049959183, Neurons: 64, Grad norm: 5.307e-01\n",
      "Epoch 10273, Loss: 0.018282711505889893, Neurons: 64, Grad norm: 5.770e-01\n",
      "Epoch 10273, Loss: 0.018282711505889893, Neurons: 64, Grad norm: 5.770e-01\n",
      "Epoch 10274, Loss: 0.018273839727044106, Neurons: 64, Grad norm: 6.161e-01\n",
      "Epoch 10274, Loss: 0.018273839727044106, Neurons: 64, Grad norm: 6.161e-01\n",
      "Epoch 10275, Loss: 0.018265249207615852, Neurons: 64, Grad norm: 6.694e-01\n",
      "Epoch 10275, Loss: 0.018265249207615852, Neurons: 64, Grad norm: 6.694e-01\n",
      "Epoch 10276, Loss: 0.01825711876153946, Neurons: 64, Grad norm: 7.214e-01\n",
      "Epoch 10276, Loss: 0.01825711876153946, Neurons: 64, Grad norm: 7.214e-01\n",
      "Epoch 10277, Loss: 0.018249668180942535, Neurons: 64, Grad norm: 7.975e-01\n",
      "Epoch 10277, Loss: 0.018249668180942535, Neurons: 64, Grad norm: 7.975e-01\n",
      "Epoch 10278, Loss: 0.01824384368956089, Neurons: 64, Grad norm: 8.754e-01\n",
      "Epoch 10278, Loss: 0.01824384368956089, Neurons: 64, Grad norm: 8.754e-01\n",
      "Epoch 10279, Loss: 0.01823880337178707, Neurons: 64, Grad norm: 9.745e-01\n",
      "Epoch 10279, Loss: 0.01823880337178707, Neurons: 64, Grad norm: 9.745e-01\n",
      "Epoch 10280, Loss: 0.018235182389616966, Neurons: 64, Grad norm: 1.055e+00\n",
      "Epoch 10280, Loss: 0.018235182389616966, Neurons: 64, Grad norm: 1.055e+00\n",
      "Epoch 10281, Loss: 0.018231825903058052, Neurons: 64, Grad norm: 1.152e+00\n",
      "Epoch 10281, Loss: 0.018231825903058052, Neurons: 64, Grad norm: 1.152e+00\n",
      "Epoch 10282, Loss: 0.018229113891720772, Neurons: 64, Grad norm: 1.218e+00\n",
      "Epoch 10282, Loss: 0.018229113891720772, Neurons: 64, Grad norm: 1.218e+00\n",
      "Epoch 10283, Loss: 0.018224989995360374, Neurons: 64, Grad norm: 1.283e+00\n",
      "Epoch 10283, Loss: 0.018224989995360374, Neurons: 64, Grad norm: 1.283e+00\n",
      "Epoch 10284, Loss: 0.01821964792907238, Neurons: 64, Grad norm: 1.304e+00\n",
      "Epoch 10284, Loss: 0.01821964792907238, Neurons: 64, Grad norm: 1.304e+00\n",
      "Epoch 10285, Loss: 0.018210403621196747, Neurons: 64, Grad norm: 1.317e+00\n",
      "Epoch 10285, Loss: 0.018210403621196747, Neurons: 64, Grad norm: 1.317e+00\n",
      "Epoch 10286, Loss: 0.018196508288383484, Neurons: 64, Grad norm: 1.268e+00\n",
      "Epoch 10286, Loss: 0.018196508288383484, Neurons: 64, Grad norm: 1.268e+00\n",
      "Epoch 10287, Loss: 0.01817723549902439, Neurons: 64, Grad norm: 1.206e+00\n",
      "Epoch 10287, Loss: 0.01817723549902439, Neurons: 64, Grad norm: 1.206e+00\n",
      "Epoch 10288, Loss: 0.018153123557567596, Neurons: 64, Grad norm: 1.082e+00\n",
      "Epoch 10288, Loss: 0.018153123557567596, Neurons: 64, Grad norm: 1.082e+00\n",
      "Epoch 10289, Loss: 0.018125319853425026, Neurons: 64, Grad norm: 9.549e-01\n",
      "Epoch 10289, Loss: 0.018125319853425026, Neurons: 64, Grad norm: 9.549e-01\n",
      "Epoch 10290, Loss: 0.018096206709742546, Neurons: 64, Grad norm: 7.777e-01\n",
      "Epoch 10290, Loss: 0.018096206709742546, Neurons: 64, Grad norm: 7.777e-01\n",
      "Epoch 10291, Loss: 0.01806802488863468, Neurons: 64, Grad norm: 6.149e-01\n",
      "Epoch 10291, Loss: 0.01806802488863468, Neurons: 64, Grad norm: 6.149e-01\n",
      "Epoch 10292, Loss: 0.018042704090476036, Neurons: 64, Grad norm: 4.264e-01\n",
      "Epoch 10292, Loss: 0.018042704090476036, Neurons: 64, Grad norm: 4.264e-01\n",
      "Epoch 10293, Loss: 0.018021613359451294, Neurons: 64, Grad norm: 2.931e-01\n",
      "Epoch 10293, Loss: 0.018021613359451294, Neurons: 64, Grad norm: 2.931e-01\n",
      "Epoch 10294, Loss: 0.018005112186074257, Neurons: 64, Grad norm: 2.032e-01\n",
      "Epoch 10294, Loss: 0.018005112186074257, Neurons: 64, Grad norm: 2.032e-01\n",
      "Epoch 10295, Loss: 0.017992600798606873, Neurons: 64, Grad norm: 2.528e-01\n",
      "Epoch 10295, Loss: 0.017992600798606873, Neurons: 64, Grad norm: 2.528e-01\n",
      "Epoch 10296, Loss: 0.017983093857765198, Neurons: 64, Grad norm: 3.539e-01\n",
      "Epoch 10296, Loss: 0.017983093857765198, Neurons: 64, Grad norm: 3.539e-01\n",
      "Epoch 10297, Loss: 0.017975525930523872, Neurons: 64, Grad norm: 4.551e-01\n",
      "Epoch 10297, Loss: 0.017975525930523872, Neurons: 64, Grad norm: 4.551e-01\n",
      "Epoch 10298, Loss: 0.017968975007534027, Neurons: 64, Grad norm: 5.574e-01\n",
      "Epoch 10298, Loss: 0.017968975007534027, Neurons: 64, Grad norm: 5.574e-01\n",
      "Epoch 10299, Loss: 0.017961733043193817, Neurons: 64, Grad norm: 6.221e-01\n",
      "Epoch 10299, Loss: 0.017961733043193817, Neurons: 64, Grad norm: 6.221e-01\n",
      "Epoch 10299, Test loss: 0.011953520588576794\n",
      "Epoch 10299, Test loss: 0.011953520588576794\n",
      "Epoch 10300, Loss: 0.017954053357243538, Neurons: 64, Grad norm: 6.893e-01\n",
      "Epoch 10300, Loss: 0.017954053357243538, Neurons: 64, Grad norm: 6.893e-01\n",
      "Epoch 10301, Loss: 0.017944369465112686, Neurons: 64, Grad norm: 7.167e-01\n",
      "Epoch 10301, Loss: 0.017944369465112686, Neurons: 64, Grad norm: 7.167e-01\n",
      "Epoch 10302, Loss: 0.017933623865246773, Neurons: 64, Grad norm: 7.464e-01\n",
      "Epoch 10302, Loss: 0.017933623865246773, Neurons: 64, Grad norm: 7.464e-01\n",
      "Epoch 10303, Loss: 0.01792077347636223, Neurons: 64, Grad norm: 7.360e-01\n",
      "Epoch 10303, Loss: 0.01792077347636223, Neurons: 64, Grad norm: 7.360e-01\n",
      "Epoch 10304, Loss: 0.017906777560710907, Neurons: 64, Grad norm: 7.380e-01\n",
      "Epoch 10304, Loss: 0.017906777560710907, Neurons: 64, Grad norm: 7.380e-01\n",
      "Epoch 10305, Loss: 0.017891597002744675, Neurons: 64, Grad norm: 6.998e-01\n",
      "Epoch 10305, Loss: 0.017891597002744675, Neurons: 64, Grad norm: 6.998e-01\n",
      "Epoch 10306, Loss: 0.01787632890045643, Neurons: 64, Grad norm: 6.878e-01\n",
      "Epoch 10306, Loss: 0.01787632890045643, Neurons: 64, Grad norm: 6.878e-01\n",
      "Epoch 10307, Loss: 0.017860714346170425, Neurons: 64, Grad norm: 6.404e-01\n",
      "Epoch 10307, Loss: 0.017860714346170425, Neurons: 64, Grad norm: 6.404e-01\n",
      "Epoch 10308, Loss: 0.01784556172788143, Neurons: 64, Grad norm: 6.166e-01\n",
      "Epoch 10308, Loss: 0.01784556172788143, Neurons: 64, Grad norm: 6.166e-01\n",
      "Epoch 10309, Loss: 0.01783103309571743, Neurons: 64, Grad norm: 5.625e-01\n",
      "Epoch 10309, Loss: 0.01783103309571743, Neurons: 64, Grad norm: 5.625e-01\n",
      "Epoch 10310, Loss: 0.017816783860325813, Neurons: 64, Grad norm: 5.420e-01\n",
      "Epoch 10310, Loss: 0.017816783860325813, Neurons: 64, Grad norm: 5.420e-01\n",
      "Epoch 10311, Loss: 0.017803262919187546, Neurons: 64, Grad norm: 4.884e-01\n",
      "Epoch 10311, Loss: 0.017803262919187546, Neurons: 64, Grad norm: 4.884e-01\n",
      "Epoch 10312, Loss: 0.017790112644433975, Neurons: 64, Grad norm: 4.674e-01\n",
      "Epoch 10312, Loss: 0.017790112644433975, Neurons: 64, Grad norm: 4.674e-01\n",
      "Epoch 10313, Loss: 0.017777403816580772, Neurons: 64, Grad norm: 4.165e-01\n",
      "Epoch 10313, Loss: 0.017777403816580772, Neurons: 64, Grad norm: 4.165e-01\n",
      "Epoch 10314, Loss: 0.01776498556137085, Neurons: 64, Grad norm: 3.960e-01\n",
      "Epoch 10314, Loss: 0.01776498556137085, Neurons: 64, Grad norm: 3.960e-01\n",
      "Epoch 10315, Loss: 0.017752865329384804, Neurons: 64, Grad norm: 3.495e-01\n",
      "Epoch 10315, Loss: 0.017752865329384804, Neurons: 64, Grad norm: 3.495e-01\n",
      "Epoch 10316, Loss: 0.01774068921804428, Neurons: 64, Grad norm: 3.308e-01\n",
      "Epoch 10316, Loss: 0.01774068921804428, Neurons: 64, Grad norm: 3.308e-01\n",
      "Epoch 10317, Loss: 0.017728833481669426, Neurons: 64, Grad norm: 2.855e-01\n",
      "Epoch 10317, Loss: 0.017728833481669426, Neurons: 64, Grad norm: 2.855e-01\n",
      "Epoch 10318, Loss: 0.017716778442263603, Neurons: 64, Grad norm: 2.694e-01\n",
      "Epoch 10318, Loss: 0.017716778442263603, Neurons: 64, Grad norm: 2.694e-01\n",
      "Epoch 10319, Loss: 0.01770501583814621, Neurons: 64, Grad norm: 2.341e-01\n",
      "Epoch 10319, Loss: 0.01770501583814621, Neurons: 64, Grad norm: 2.341e-01\n",
      "Epoch 10320, Loss: 0.017693080008029938, Neurons: 64, Grad norm: 2.200e-01\n",
      "Epoch 10320, Loss: 0.017693080008029938, Neurons: 64, Grad norm: 2.200e-01\n",
      "Epoch 10321, Loss: 0.017681259661912918, Neurons: 64, Grad norm: 1.995e-01\n",
      "Epoch 10321, Loss: 0.017681259661912918, Neurons: 64, Grad norm: 1.995e-01\n",
      "Epoch 10322, Loss: 0.017669403925538063, Neurons: 64, Grad norm: 1.949e-01\n",
      "Epoch 10322, Loss: 0.017669403925538063, Neurons: 64, Grad norm: 1.949e-01\n",
      "Epoch 10323, Loss: 0.017657771706581116, Neurons: 64, Grad norm: 1.968e-01\n",
      "Epoch 10323, Loss: 0.017657771706581116, Neurons: 64, Grad norm: 1.968e-01\n",
      "Epoch 10324, Loss: 0.017646122723817825, Neurons: 64, Grad norm: 2.007e-01\n",
      "Epoch 10324, Loss: 0.017646122723817825, Neurons: 64, Grad norm: 2.007e-01\n",
      "Epoch 10325, Loss: 0.017634643241763115, Neurons: 64, Grad norm: 2.211e-01\n",
      "Epoch 10325, Loss: 0.017634643241763115, Neurons: 64, Grad norm: 2.211e-01\n",
      "Epoch 10326, Loss: 0.01762308180332184, Neurons: 64, Grad norm: 2.299e-01\n",
      "Epoch 10326, Loss: 0.01762308180332184, Neurons: 64, Grad norm: 2.299e-01\n",
      "Epoch 10327, Loss: 0.01761169731616974, Neurons: 64, Grad norm: 2.617e-01\n",
      "Epoch 10327, Loss: 0.01761169731616974, Neurons: 64, Grad norm: 2.617e-01\n",
      "Epoch 10328, Loss: 0.01760021597146988, Neurons: 64, Grad norm: 2.761e-01\n",
      "Epoch 10328, Loss: 0.01760021597146988, Neurons: 64, Grad norm: 2.761e-01\n",
      "Epoch 10329, Loss: 0.017588822171092033, Neurons: 64, Grad norm: 3.225e-01\n",
      "Epoch 10329, Loss: 0.017588822171092033, Neurons: 64, Grad norm: 3.225e-01\n",
      "Epoch 10330, Loss: 0.017577728256583214, Neurons: 64, Grad norm: 3.465e-01\n",
      "Epoch 10330, Loss: 0.017577728256583214, Neurons: 64, Grad norm: 3.465e-01\n",
      "Epoch 10331, Loss: 0.017566660419106483, Neurons: 64, Grad norm: 4.044e-01\n",
      "Epoch 10331, Loss: 0.017566660419106483, Neurons: 64, Grad norm: 4.044e-01\n",
      "Epoch 10332, Loss: 0.01755617931485176, Neurons: 64, Grad norm: 4.473e-01\n",
      "Epoch 10332, Loss: 0.01755617931485176, Neurons: 64, Grad norm: 4.473e-01\n",
      "Epoch 10333, Loss: 0.01754588447511196, Neurons: 64, Grad norm: 5.261e-01\n",
      "Epoch 10333, Loss: 0.01754588447511196, Neurons: 64, Grad norm: 5.261e-01\n",
      "Epoch 10334, Loss: 0.017535926774144173, Neurons: 64, Grad norm: 5.825e-01\n",
      "Epoch 10334, Loss: 0.017535926774144173, Neurons: 64, Grad norm: 5.825e-01\n",
      "Epoch 10335, Loss: 0.017526401206851006, Neurons: 64, Grad norm: 6.828e-01\n",
      "Epoch 10335, Loss: 0.017526401206851006, Neurons: 64, Grad norm: 6.828e-01\n",
      "Epoch 10336, Loss: 0.017517562955617905, Neurons: 64, Grad norm: 7.709e-01\n",
      "Epoch 10336, Loss: 0.017517562955617905, Neurons: 64, Grad norm: 7.709e-01\n",
      "Epoch 10337, Loss: 0.01750955358147621, Neurons: 64, Grad norm: 9.097e-01\n",
      "Epoch 10337, Loss: 0.01750955358147621, Neurons: 64, Grad norm: 9.097e-01\n",
      "Epoch 10338, Loss: 0.01750289276242256, Neurons: 64, Grad norm: 1.038e+00\n",
      "Epoch 10338, Loss: 0.01750289276242256, Neurons: 64, Grad norm: 1.038e+00\n",
      "Epoch 10339, Loss: 0.017498092725872993, Neurons: 64, Grad norm: 1.224e+00\n",
      "Epoch 10339, Loss: 0.017498092725872993, Neurons: 64, Grad norm: 1.224e+00\n",
      "Epoch 10340, Loss: 0.017495721578598022, Neurons: 64, Grad norm: 1.409e+00\n",
      "Epoch 10340, Loss: 0.017495721578598022, Neurons: 64, Grad norm: 1.409e+00\n",
      "Epoch 10341, Loss: 0.01749611645936966, Neurons: 64, Grad norm: 1.666e+00\n",
      "Epoch 10341, Loss: 0.01749611645936966, Neurons: 64, Grad norm: 1.666e+00\n",
      "Epoch 10342, Loss: 0.017500894144177437, Neurons: 64, Grad norm: 1.934e+00\n",
      "Epoch 10342, Loss: 0.017500894144177437, Neurons: 64, Grad norm: 1.934e+00\n",
      "Epoch 10343, Loss: 0.017510659992694855, Neurons: 64, Grad norm: 2.276e+00\n",
      "Epoch 10343, Loss: 0.017510659992694855, Neurons: 64, Grad norm: 2.276e+00\n",
      "Epoch 10344, Loss: 0.017527762800455093, Neurons: 64, Grad norm: 2.647e+00\n",
      "Epoch 10344, Loss: 0.017527762800455093, Neurons: 64, Grad norm: 2.647e+00\n",
      "Epoch 10345, Loss: 0.017552930861711502, Neurons: 64, Grad norm: 3.107e+00\n",
      "Epoch 10345, Loss: 0.017552930861711502, Neurons: 64, Grad norm: 3.107e+00\n",
      "Epoch 10346, Loss: 0.017588861286640167, Neurons: 64, Grad norm: 3.589e+00\n",
      "Epoch 10346, Loss: 0.017588861286640167, Neurons: 64, Grad norm: 3.589e+00\n",
      "Epoch 10347, Loss: 0.017635824158787727, Neurons: 64, Grad norm: 4.158e+00\n",
      "Epoch 10347, Loss: 0.017635824158787727, Neurons: 64, Grad norm: 4.158e+00\n",
      "Epoch 10348, Loss: 0.017694339156150818, Neurons: 64, Grad norm: 4.734e+00\n",
      "Epoch 10348, Loss: 0.017694339156150818, Neurons: 64, Grad norm: 4.734e+00\n",
      "Epoch 10349, Loss: 0.017762569710612297, Neurons: 64, Grad norm: 5.353e+00\n",
      "Epoch 10349, Loss: 0.017762569710612297, Neurons: 64, Grad norm: 5.353e+00\n",
      "Epoch 10350, Loss: 0.01783682405948639, Neurons: 64, Grad norm: 5.912e+00\n",
      "Epoch 10350, Loss: 0.01783682405948639, Neurons: 64, Grad norm: 5.912e+00\n",
      "Epoch 10351, Loss: 0.01790909469127655, Neurons: 64, Grad norm: 6.415e+00\n",
      "Epoch 10351, Loss: 0.01790909469127655, Neurons: 64, Grad norm: 6.415e+00\n",
      "Epoch 10352, Loss: 0.017968693748116493, Neurons: 64, Grad norm: 6.728e+00\n",
      "Epoch 10352, Loss: 0.017968693748116493, Neurons: 64, Grad norm: 6.728e+00\n",
      "Epoch 10353, Loss: 0.018002614378929138, Neurons: 64, Grad norm: 6.836e+00\n",
      "Epoch 10353, Loss: 0.018002614378929138, Neurons: 64, Grad norm: 6.836e+00\n",
      "Epoch 10354, Loss: 0.017996637150645256, Neurons: 64, Grad norm: 6.611e+00\n",
      "Epoch 10354, Loss: 0.017996637150645256, Neurons: 64, Grad norm: 6.611e+00\n",
      "Epoch 10355, Loss: 0.017944222316145897, Neurons: 64, Grad norm: 6.081e+00\n",
      "Epoch 10355, Loss: 0.017944222316145897, Neurons: 64, Grad norm: 6.081e+00\n",
      "Epoch 10356, Loss: 0.017846249043941498, Neurons: 64, Grad norm: 5.194e+00\n",
      "Epoch 10356, Loss: 0.017846249043941498, Neurons: 64, Grad norm: 5.194e+00\n",
      "Epoch 10357, Loss: 0.017719337716698647, Neurons: 64, Grad norm: 4.080e+00\n",
      "Epoch 10357, Loss: 0.017719337716698647, Neurons: 64, Grad norm: 4.080e+00\n",
      "Epoch 10358, Loss: 0.017584923654794693, Neurons: 64, Grad norm: 2.825e+00\n",
      "Epoch 10358, Loss: 0.017584923654794693, Neurons: 64, Grad norm: 2.825e+00\n",
      "Epoch 10359, Loss: 0.017468029633164406, Neurons: 64, Grad norm: 1.723e+00\n",
      "Epoch 10359, Loss: 0.017468029633164406, Neurons: 64, Grad norm: 1.723e+00\n",
      "Epoch 10360, Loss: 0.017382431775331497, Neurons: 64, Grad norm: 1.347e+00\n",
      "Epoch 10360, Loss: 0.017382431775331497, Neurons: 64, Grad norm: 1.347e+00\n",
      "Epoch 10361, Loss: 0.01733211800456047, Neurons: 64, Grad norm: 1.892e+00\n",
      "Epoch 10361, Loss: 0.01733211800456047, Neurons: 64, Grad norm: 1.892e+00\n",
      "Epoch 10362, Loss: 0.017312606796622276, Neurons: 64, Grad norm: 2.606e+00\n",
      "Epoch 10362, Loss: 0.017312606796622276, Neurons: 64, Grad norm: 2.606e+00\n",
      "Epoch 10363, Loss: 0.017315678298473358, Neurons: 64, Grad norm: 3.092e+00\n",
      "Epoch 10363, Loss: 0.017315678298473358, Neurons: 64, Grad norm: 3.092e+00\n",
      "Epoch 10364, Loss: 0.01733044907450676, Neurons: 64, Grad norm: 3.328e+00\n",
      "Epoch 10364, Loss: 0.01733044907450676, Neurons: 64, Grad norm: 3.328e+00\n",
      "Epoch 10365, Loss: 0.017344070598483086, Neurons: 64, Grad norm: 3.246e+00\n",
      "Epoch 10365, Loss: 0.017344070598483086, Neurons: 64, Grad norm: 3.246e+00\n",
      "Epoch 10366, Loss: 0.01734575815498829, Neurons: 64, Grad norm: 2.929e+00\n",
      "Epoch 10366, Loss: 0.01734575815498829, Neurons: 64, Grad norm: 2.929e+00\n",
      "Epoch 10367, Loss: 0.01732625998556614, Neurons: 64, Grad norm: 2.374e+00\n",
      "Epoch 10367, Loss: 0.01732625998556614, Neurons: 64, Grad norm: 2.374e+00\n",
      "Epoch 10368, Loss: 0.017285451292991638, Neurons: 64, Grad norm: 1.707e+00\n",
      "Epoch 10368, Loss: 0.017285451292991638, Neurons: 64, Grad norm: 1.707e+00\n",
      "Epoch 10369, Loss: 0.017229493707418442, Neurons: 64, Grad norm: 1.009e+00\n",
      "Epoch 10369, Loss: 0.017229493707418442, Neurons: 64, Grad norm: 1.009e+00\n",
      "Epoch 10370, Loss: 0.017173631116747856, Neurons: 64, Grad norm: 6.203e-01\n",
      "Epoch 10370, Loss: 0.017173631116747856, Neurons: 64, Grad norm: 6.203e-01\n",
      "Epoch 10371, Loss: 0.01713215559720993, Neurons: 64, Grad norm: 9.600e-01\n",
      "Epoch 10371, Loss: 0.01713215559720993, Neurons: 64, Grad norm: 9.600e-01\n",
      "Epoch 10372, Loss: 0.01711415685713291, Neurons: 64, Grad norm: 1.432e+00\n",
      "Epoch 10372, Loss: 0.01711415685713291, Neurons: 64, Grad norm: 1.432e+00\n",
      "Epoch 10373, Loss: 0.01711810752749443, Neurons: 64, Grad norm: 1.809e+00\n",
      "Epoch 10373, Loss: 0.01711810752749443, Neurons: 64, Grad norm: 1.809e+00\n",
      "Epoch 10374, Loss: 0.01713261753320694, Neurons: 64, Grad norm: 1.976e+00\n",
      "Epoch 10374, Loss: 0.01713261753320694, Neurons: 64, Grad norm: 1.976e+00\n",
      "Epoch 10375, Loss: 0.017143262550234795, Neurons: 64, Grad norm: 1.972e+00\n",
      "Epoch 10375, Loss: 0.017143262550234795, Neurons: 64, Grad norm: 1.972e+00\n",
      "Epoch 10376, Loss: 0.017138458788394928, Neurons: 64, Grad norm: 1.755e+00\n",
      "Epoch 10376, Loss: 0.017138458788394928, Neurons: 64, Grad norm: 1.755e+00\n",
      "Epoch 10377, Loss: 0.017115533351898193, Neurons: 64, Grad norm: 1.408e+00\n",
      "Epoch 10377, Loss: 0.017115533351898193, Neurons: 64, Grad norm: 1.408e+00\n",
      "Epoch 10378, Loss: 0.017080189660191536, Neurons: 64, Grad norm: 9.279e-01\n",
      "Epoch 10378, Loss: 0.017080189660191536, Neurons: 64, Grad norm: 9.279e-01\n",
      "Epoch 10379, Loss: 0.01704324409365654, Neurons: 64, Grad norm: 4.286e-01\n",
      "Epoch 10379, Loss: 0.01704324409365654, Neurons: 64, Grad norm: 4.286e-01\n",
      "Epoch 10380, Loss: 0.017014920711517334, Neurons: 64, Grad norm: 8.970e-02\n",
      "Epoch 10380, Loss: 0.017014920711517334, Neurons: 64, Grad norm: 8.970e-02\n",
      "Epoch 10381, Loss: 0.016999930143356323, Neurons: 64, Grad norm: 5.231e-01\n",
      "Epoch 10381, Loss: 0.016999930143356323, Neurons: 64, Grad norm: 5.231e-01\n",
      "Epoch 10382, Loss: 0.01699637994170189, Neurons: 64, Grad norm: 8.873e-01\n",
      "Epoch 10382, Loss: 0.01699637994170189, Neurons: 64, Grad norm: 8.873e-01\n",
      "Epoch 10383, Loss: 0.016998590901494026, Neurons: 64, Grad norm: 1.112e+00\n",
      "Epoch 10383, Loss: 0.016998590901494026, Neurons: 64, Grad norm: 1.112e+00\n",
      "Epoch 10384, Loss: 0.01699884608387947, Neurons: 64, Grad norm: 1.234e+00\n",
      "Epoch 10384, Loss: 0.01699884608387947, Neurons: 64, Grad norm: 1.234e+00\n",
      "Epoch 10385, Loss: 0.01699262112379074, Neurons: 64, Grad norm: 1.214e+00\n",
      "Epoch 10385, Loss: 0.01699262112379074, Neurons: 64, Grad norm: 1.214e+00\n",
      "Epoch 10386, Loss: 0.01697862707078457, Neurons: 64, Grad norm: 1.119e+00\n",
      "Epoch 10386, Loss: 0.01697862707078457, Neurons: 64, Grad norm: 1.119e+00\n",
      "Epoch 10387, Loss: 0.01695961505174637, Neurons: 64, Grad norm: 9.222e-01\n",
      "Epoch 10387, Loss: 0.01695961505174637, Neurons: 64, Grad norm: 9.222e-01\n",
      "Epoch 10388, Loss: 0.01693924143910408, Neurons: 64, Grad norm: 7.087e-01\n",
      "Epoch 10388, Loss: 0.01693924143910408, Neurons: 64, Grad norm: 7.087e-01\n",
      "Epoch 10389, Loss: 0.016920998692512512, Neurons: 64, Grad norm: 4.639e-01\n",
      "Epoch 10389, Loss: 0.016920998692512512, Neurons: 64, Grad norm: 4.639e-01\n",
      "Epoch 10390, Loss: 0.016906751319766045, Neurons: 64, Grad norm: 3.089e-01\n",
      "Epoch 10390, Loss: 0.016906751319766045, Neurons: 64, Grad norm: 3.089e-01\n",
      "Epoch 10391, Loss: 0.016895940527319908, Neurons: 64, Grad norm: 2.909e-01\n",
      "Epoch 10391, Loss: 0.016895940527319908, Neurons: 64, Grad norm: 2.909e-01\n",
      "Epoch 10392, Loss: 0.016887325793504715, Neurons: 64, Grad norm: 4.037e-01\n",
      "Epoch 10392, Loss: 0.016887325793504715, Neurons: 64, Grad norm: 4.037e-01\n",
      "Epoch 10393, Loss: 0.016879020258784294, Neurons: 64, Grad norm: 5.284e-01\n",
      "Epoch 10393, Loss: 0.016879020258784294, Neurons: 64, Grad norm: 5.284e-01\n",
      "Epoch 10394, Loss: 0.01686966046690941, Neurons: 64, Grad norm: 6.023e-01\n",
      "Epoch 10394, Loss: 0.01686966046690941, Neurons: 64, Grad norm: 6.023e-01\n",
      "Epoch 10395, Loss: 0.016858898103237152, Neurons: 64, Grad norm: 6.625e-01\n",
      "Epoch 10395, Loss: 0.016858898103237152, Neurons: 64, Grad norm: 6.625e-01\n",
      "Epoch 10396, Loss: 0.016847340390086174, Neurons: 64, Grad norm: 6.623e-01\n",
      "Epoch 10396, Loss: 0.016847340390086174, Neurons: 64, Grad norm: 6.623e-01\n",
      "Epoch 10397, Loss: 0.016835493966937065, Neurons: 64, Grad norm: 6.608e-01\n",
      "Epoch 10397, Loss: 0.016835493966937065, Neurons: 64, Grad norm: 6.608e-01\n",
      "Epoch 10398, Loss: 0.01682395488023758, Neurons: 64, Grad norm: 6.060e-01\n",
      "Epoch 10398, Loss: 0.01682395488023758, Neurons: 64, Grad norm: 6.060e-01\n",
      "Epoch 10399, Loss: 0.016813144087791443, Neurons: 64, Grad norm: 5.606e-01\n",
      "Epoch 10399, Loss: 0.016813144087791443, Neurons: 64, Grad norm: 5.606e-01\n",
      "Epoch 10399, Test loss: 0.01129355188459158\n",
      "Epoch 10399, Test loss: 0.01129355188459158\n",
      "Epoch 10400, Loss: 0.016802450641989708, Neurons: 64, Grad norm: 4.687e-01\n",
      "Epoch 10400, Loss: 0.016802450641989708, Neurons: 64, Grad norm: 4.687e-01\n",
      "Epoch 10401, Loss: 0.01679164171218872, Neurons: 64, Grad norm: 4.010e-01\n",
      "Epoch 10401, Loss: 0.01679164171218872, Neurons: 64, Grad norm: 4.010e-01\n",
      "Epoch 10402, Loss: 0.016780473291873932, Neurons: 64, Grad norm: 2.993e-01\n",
      "Epoch 10402, Loss: 0.016780473291873932, Neurons: 64, Grad norm: 2.993e-01\n",
      "Epoch 10403, Loss: 0.016768986359238625, Neurons: 64, Grad norm: 2.267e-01\n",
      "Epoch 10403, Loss: 0.016768986359238625, Neurons: 64, Grad norm: 2.267e-01\n",
      "Epoch 10404, Loss: 0.01675734855234623, Neurons: 64, Grad norm: 1.668e-01\n",
      "Epoch 10404, Loss: 0.01675734855234623, Neurons: 64, Grad norm: 1.668e-01\n",
      "Epoch 10405, Loss: 0.016745539382100105, Neurons: 64, Grad norm: 1.622e-01\n",
      "Epoch 10405, Loss: 0.016745539382100105, Neurons: 64, Grad norm: 1.622e-01\n",
      "Epoch 10406, Loss: 0.01673414371907711, Neurons: 64, Grad norm: 2.195e-01\n",
      "Epoch 10406, Loss: 0.01673414371907711, Neurons: 64, Grad norm: 2.195e-01\n",
      "Epoch 10407, Loss: 0.016723524779081345, Neurons: 64, Grad norm: 2.660e-01\n",
      "Epoch 10407, Loss: 0.016723524779081345, Neurons: 64, Grad norm: 2.660e-01\n",
      "Epoch 10408, Loss: 0.016713276505470276, Neurons: 64, Grad norm: 3.347e-01\n",
      "Epoch 10408, Loss: 0.016713276505470276, Neurons: 64, Grad norm: 3.347e-01\n",
      "Epoch 10409, Loss: 0.01670341193675995, Neurons: 64, Grad norm: 3.581e-01\n",
      "Epoch 10409, Loss: 0.01670341193675995, Neurons: 64, Grad norm: 3.581e-01\n",
      "Epoch 10410, Loss: 0.016693726181983948, Neurons: 64, Grad norm: 3.949e-01\n",
      "Epoch 10410, Loss: 0.016693726181983948, Neurons: 64, Grad norm: 3.949e-01\n",
      "Epoch 10411, Loss: 0.01668383926153183, Neurons: 64, Grad norm: 3.810e-01\n",
      "Epoch 10411, Loss: 0.01668383926153183, Neurons: 64, Grad norm: 3.810e-01\n",
      "Epoch 10412, Loss: 0.016673581674695015, Neurons: 64, Grad norm: 3.870e-01\n",
      "Epoch 10412, Loss: 0.016673581674695015, Neurons: 64, Grad norm: 3.870e-01\n",
      "Epoch 10413, Loss: 0.016663145273923874, Neurons: 64, Grad norm: 3.430e-01\n",
      "Epoch 10413, Loss: 0.016663145273923874, Neurons: 64, Grad norm: 3.430e-01\n",
      "Epoch 10414, Loss: 0.016652299091219902, Neurons: 64, Grad norm: 3.214e-01\n",
      "Epoch 10414, Loss: 0.016652299091219902, Neurons: 64, Grad norm: 3.214e-01\n",
      "Epoch 10415, Loss: 0.016641397029161453, Neurons: 64, Grad norm: 2.673e-01\n",
      "Epoch 10415, Loss: 0.016641397029161453, Neurons: 64, Grad norm: 2.673e-01\n",
      "Epoch 10416, Loss: 0.016630331054329872, Neurons: 64, Grad norm: 2.372e-01\n",
      "Epoch 10416, Loss: 0.016630331054329872, Neurons: 64, Grad norm: 2.372e-01\n",
      "Epoch 10417, Loss: 0.016619356349110603, Neurons: 64, Grad norm: 1.743e-01\n",
      "Epoch 10417, Loss: 0.016619356349110603, Neurons: 64, Grad norm: 1.743e-01\n",
      "Epoch 10418, Loss: 0.01660836488008499, Neurons: 64, Grad norm: 1.488e-01\n",
      "Epoch 10418, Loss: 0.01660836488008499, Neurons: 64, Grad norm: 1.488e-01\n",
      "Epoch 10419, Loss: 0.016597721725702286, Neurons: 64, Grad norm: 1.015e-01\n",
      "Epoch 10419, Loss: 0.016597721725702286, Neurons: 64, Grad norm: 1.015e-01\n",
      "Epoch 10420, Loss: 0.01658713072538376, Neurons: 64, Grad norm: 8.799e-02\n",
      "Epoch 10420, Loss: 0.01658713072538376, Neurons: 64, Grad norm: 8.799e-02\n",
      "Epoch 10421, Loss: 0.016576780006289482, Neurons: 64, Grad norm: 7.015e-02\n",
      "Epoch 10421, Loss: 0.016576780006289482, Neurons: 64, Grad norm: 7.015e-02\n",
      "Epoch 10422, Loss: 0.01656646467745304, Neurons: 64, Grad norm: 7.671e-02\n",
      "Epoch 10422, Loss: 0.01656646467745304, Neurons: 64, Grad norm: 7.671e-02\n",
      "Epoch 10423, Loss: 0.016556335613131523, Neurons: 64, Grad norm: 9.423e-02\n",
      "Epoch 10423, Loss: 0.016556335613131523, Neurons: 64, Grad norm: 9.423e-02\n",
      "Epoch 10424, Loss: 0.01654617302119732, Neurons: 64, Grad norm: 1.002e-01\n",
      "Epoch 10424, Loss: 0.01654617302119732, Neurons: 64, Grad norm: 1.002e-01\n",
      "Epoch 10425, Loss: 0.016535824164748192, Neurons: 64, Grad norm: 1.178e-01\n",
      "Epoch 10425, Loss: 0.016535824164748192, Neurons: 64, Grad norm: 1.178e-01\n",
      "Epoch 10426, Loss: 0.016525818035006523, Neurons: 64, Grad norm: 1.132e-01\n",
      "Epoch 10426, Loss: 0.016525818035006523, Neurons: 64, Grad norm: 1.132e-01\n",
      "Epoch 10427, Loss: 0.0165154580026865, Neurons: 64, Grad norm: 1.299e-01\n",
      "Epoch 10427, Loss: 0.0165154580026865, Neurons: 64, Grad norm: 1.299e-01\n",
      "Epoch 10428, Loss: 0.01650516502559185, Neurons: 64, Grad norm: 1.149e-01\n",
      "Epoch 10428, Loss: 0.01650516502559185, Neurons: 64, Grad norm: 1.149e-01\n",
      "Epoch 10429, Loss: 0.01649468205869198, Neurons: 64, Grad norm: 1.270e-01\n",
      "Epoch 10429, Loss: 0.01649468205869198, Neurons: 64, Grad norm: 1.270e-01\n",
      "Epoch 10430, Loss: 0.016484413295984268, Neurons: 64, Grad norm: 1.164e-01\n",
      "Epoch 10430, Loss: 0.016484413295984268, Neurons: 64, Grad norm: 1.164e-01\n",
      "Epoch 10431, Loss: 0.016474144533276558, Neurons: 64, Grad norm: 1.411e-01\n",
      "Epoch 10431, Loss: 0.016474144533276558, Neurons: 64, Grad norm: 1.411e-01\n",
      "Epoch 10432, Loss: 0.016463827341794968, Neurons: 64, Grad norm: 1.293e-01\n",
      "Epoch 10432, Loss: 0.016463827341794968, Neurons: 64, Grad norm: 1.293e-01\n",
      "Epoch 10433, Loss: 0.016453564167022705, Neurons: 64, Grad norm: 1.476e-01\n",
      "Epoch 10433, Loss: 0.016453564167022705, Neurons: 64, Grad norm: 1.476e-01\n",
      "Epoch 10434, Loss: 0.016443420201539993, Neurons: 64, Grad norm: 1.455e-01\n",
      "Epoch 10434, Loss: 0.016443420201539993, Neurons: 64, Grad norm: 1.455e-01\n",
      "Epoch 10435, Loss: 0.01643313653767109, Neurons: 64, Grad norm: 1.762e-01\n",
      "Epoch 10435, Loss: 0.01643313653767109, Neurons: 64, Grad norm: 1.762e-01\n",
      "Epoch 10436, Loss: 0.016422992572188377, Neurons: 64, Grad norm: 1.672e-01\n",
      "Epoch 10436, Loss: 0.016422992572188377, Neurons: 64, Grad norm: 1.672e-01\n",
      "Epoch 10437, Loss: 0.016412930563092232, Neurons: 64, Grad norm: 1.904e-01\n",
      "Epoch 10437, Loss: 0.016412930563092232, Neurons: 64, Grad norm: 1.904e-01\n",
      "Epoch 10438, Loss: 0.016402821987867355, Neurons: 64, Grad norm: 1.931e-01\n",
      "Epoch 10438, Loss: 0.016402821987867355, Neurons: 64, Grad norm: 1.931e-01\n",
      "Epoch 10439, Loss: 0.016392717137932777, Neurons: 64, Grad norm: 2.260e-01\n",
      "Epoch 10439, Loss: 0.016392717137932777, Neurons: 64, Grad norm: 2.260e-01\n",
      "Epoch 10440, Loss: 0.016382655128836632, Neurons: 64, Grad norm: 2.260e-01\n",
      "Epoch 10440, Loss: 0.016382655128836632, Neurons: 64, Grad norm: 2.260e-01\n",
      "Epoch 10441, Loss: 0.016372686251997948, Neurons: 64, Grad norm: 2.606e-01\n",
      "Epoch 10441, Loss: 0.016372686251997948, Neurons: 64, Grad norm: 2.606e-01\n",
      "Epoch 10442, Loss: 0.016362743452191353, Neurons: 64, Grad norm: 2.751e-01\n",
      "Epoch 10442, Loss: 0.016362743452191353, Neurons: 64, Grad norm: 2.751e-01\n",
      "Epoch 10443, Loss: 0.0163528174161911, Neurons: 64, Grad norm: 3.304e-01\n",
      "Epoch 10443, Loss: 0.0163528174161911, Neurons: 64, Grad norm: 3.304e-01\n",
      "Epoch 10444, Loss: 0.01634307950735092, Neurons: 64, Grad norm: 3.554e-01\n",
      "Epoch 10444, Loss: 0.01634307950735092, Neurons: 64, Grad norm: 3.554e-01\n",
      "Epoch 10445, Loss: 0.01633346639573574, Neurons: 64, Grad norm: 4.117e-01\n",
      "Epoch 10445, Loss: 0.01633346639573574, Neurons: 64, Grad norm: 4.117e-01\n",
      "Epoch 10446, Loss: 0.016323959454894066, Neurons: 64, Grad norm: 4.586e-01\n",
      "Epoch 10446, Loss: 0.016323959454894066, Neurons: 64, Grad norm: 4.586e-01\n",
      "Epoch 10447, Loss: 0.016314780339598656, Neurons: 64, Grad norm: 5.519e-01\n",
      "Epoch 10447, Loss: 0.016314780339598656, Neurons: 64, Grad norm: 5.519e-01\n",
      "Epoch 10448, Loss: 0.01630585826933384, Neurons: 64, Grad norm: 6.269e-01\n",
      "Epoch 10448, Loss: 0.01630585826933384, Neurons: 64, Grad norm: 6.269e-01\n",
      "Epoch 10449, Loss: 0.01629754714667797, Neurons: 64, Grad norm: 7.410e-01\n",
      "Epoch 10449, Loss: 0.01629754714667797, Neurons: 64, Grad norm: 7.410e-01\n",
      "Epoch 10450, Loss: 0.016289664432406425, Neurons: 64, Grad norm: 8.521e-01\n",
      "Epoch 10450, Loss: 0.016289664432406425, Neurons: 64, Grad norm: 8.521e-01\n",
      "Epoch 10451, Loss: 0.016282815486192703, Neurons: 64, Grad norm: 1.027e+00\n",
      "Epoch 10451, Loss: 0.016282815486192703, Neurons: 64, Grad norm: 1.027e+00\n",
      "Epoch 10452, Loss: 0.016277188435196877, Neurons: 64, Grad norm: 1.203e+00\n",
      "Epoch 10452, Loss: 0.016277188435196877, Neurons: 64, Grad norm: 1.203e+00\n",
      "Epoch 10453, Loss: 0.016273709014058113, Neurons: 64, Grad norm: 1.447e+00\n",
      "Epoch 10453, Loss: 0.016273709014058113, Neurons: 64, Grad norm: 1.447e+00\n",
      "Epoch 10454, Loss: 0.01627282239496708, Neurons: 64, Grad norm: 1.714e+00\n",
      "Epoch 10454, Loss: 0.01627282239496708, Neurons: 64, Grad norm: 1.714e+00\n",
      "Epoch 10455, Loss: 0.016276370733976364, Neurons: 64, Grad norm: 2.076e+00\n",
      "Epoch 10455, Loss: 0.016276370733976364, Neurons: 64, Grad norm: 2.076e+00\n",
      "Epoch 10456, Loss: 0.01628587767481804, Neurons: 64, Grad norm: 2.482e+00\n",
      "Epoch 10456, Loss: 0.01628587767481804, Neurons: 64, Grad norm: 2.482e+00\n",
      "Epoch 10457, Loss: 0.016304731369018555, Neurons: 64, Grad norm: 3.006e+00\n",
      "Epoch 10457, Loss: 0.016304731369018555, Neurons: 64, Grad norm: 3.006e+00\n",
      "Epoch 10458, Loss: 0.016336651518940926, Neurons: 64, Grad norm: 3.605e+00\n",
      "Epoch 10458, Loss: 0.016336651518940926, Neurons: 64, Grad norm: 3.605e+00\n",
      "Epoch 10459, Loss: 0.01638765074312687, Neurons: 64, Grad norm: 4.350e+00\n",
      "Epoch 10459, Loss: 0.01638765074312687, Neurons: 64, Grad norm: 4.350e+00\n",
      "Epoch 10460, Loss: 0.01646455004811287, Neurons: 64, Grad norm: 5.181e+00\n",
      "Epoch 10460, Loss: 0.01646455004811287, Neurons: 64, Grad norm: 5.181e+00\n",
      "Epoch 10461, Loss: 0.016575442627072334, Neurons: 64, Grad norm: 6.145e+00\n",
      "Epoch 10461, Loss: 0.016575442627072334, Neurons: 64, Grad norm: 6.145e+00\n",
      "Epoch 10462, Loss: 0.01672608032822609, Neurons: 64, Grad norm: 7.133e+00\n",
      "Epoch 10462, Loss: 0.01672608032822609, Neurons: 64, Grad norm: 7.133e+00\n",
      "Epoch 10463, Loss: 0.016916828230023384, Neurons: 64, Grad norm: 8.111e+00\n",
      "Epoch 10463, Loss: 0.016916828230023384, Neurons: 64, Grad norm: 8.111e+00\n",
      "Epoch 10464, Loss: 0.017127377912402153, Neurons: 64, Grad norm: 8.861e+00\n",
      "Epoch 10464, Loss: 0.017127377912402153, Neurons: 64, Grad norm: 8.861e+00\n",
      "Epoch 10465, Loss: 0.017313523218035698, Neurons: 64, Grad norm: 9.209e+00\n",
      "Epoch 10465, Loss: 0.017313523218035698, Neurons: 64, Grad norm: 9.209e+00\n",
      "Epoch 10466, Loss: 0.017394905909895897, Neurons: 64, Grad norm: 8.858e+00\n",
      "Epoch 10466, Loss: 0.017394905909895897, Neurons: 64, Grad norm: 8.858e+00\n",
      "Epoch 10467, Loss: 0.017297979444265366, Neurons: 64, Grad norm: 7.720e+00\n",
      "Epoch 10467, Loss: 0.017297979444265366, Neurons: 64, Grad norm: 7.720e+00\n",
      "Epoch 10468, Loss: 0.017002083361148834, Neurons: 64, Grad norm: 5.747e+00\n",
      "Epoch 10468, Loss: 0.017002083361148834, Neurons: 64, Grad norm: 5.747e+00\n",
      "Epoch 10469, Loss: 0.01659812033176422, Neurons: 64, Grad norm: 3.234e+00\n",
      "Epoch 10469, Loss: 0.01659812033176422, Neurons: 64, Grad norm: 3.234e+00\n",
      "Epoch 10470, Loss: 0.016248542815446854, Neurons: 64, Grad norm: 6.172e-01\n",
      "Epoch 10470, Loss: 0.016248542815446854, Neurons: 64, Grad norm: 6.172e-01\n",
      "Epoch 10471, Loss: 0.01608874648809433, Neurons: 64, Grad norm: 2.103e+00\n",
      "Epoch 10471, Loss: 0.01608874648809433, Neurons: 64, Grad norm: 2.103e+00\n",
      "Epoch 10472, Loss: 0.016140075400471687, Neurons: 64, Grad norm: 4.082e+00\n",
      "Epoch 10472, Loss: 0.016140075400471687, Neurons: 64, Grad norm: 4.082e+00\n",
      "Epoch 10473, Loss: 0.016311632469296455, Neurons: 64, Grad norm: 5.260e+00\n",
      "Epoch 10473, Loss: 0.016311632469296455, Neurons: 64, Grad norm: 5.260e+00\n",
      "Epoch 10474, Loss: 0.01646822690963745, Neurons: 64, Grad norm: 5.566e+00\n",
      "Epoch 10474, Loss: 0.01646822690963745, Neurons: 64, Grad norm: 5.566e+00\n",
      "Epoch 10475, Loss: 0.01650368422269821, Neurons: 64, Grad norm: 4.942e+00\n",
      "Epoch 10475, Loss: 0.01650368422269821, Neurons: 64, Grad norm: 4.942e+00\n",
      "Epoch 10476, Loss: 0.016395388171076775, Neurons: 64, Grad norm: 3.588e+00\n",
      "Epoch 10476, Loss: 0.016395388171076775, Neurons: 64, Grad norm: 3.588e+00\n",
      "Epoch 10477, Loss: 0.016208957880735397, Neurons: 64, Grad norm: 1.739e+00\n",
      "Epoch 10477, Loss: 0.016208957880735397, Neurons: 64, Grad norm: 1.739e+00\n",
      "Epoch 10478, Loss: 0.01605263166129589, Neurons: 64, Grad norm: 2.622e-01\n",
      "Epoch 10478, Loss: 0.01605263166129589, Neurons: 64, Grad norm: 2.622e-01\n",
      "Epoch 10479, Loss: 0.01599925197660923, Neurons: 64, Grad norm: 1.943e+00\n",
      "Epoch 10479, Loss: 0.01599925197660923, Neurons: 64, Grad norm: 1.943e+00\n",
      "Epoch 10480, Loss: 0.016046687960624695, Neurons: 64, Grad norm: 3.153e+00\n",
      "Epoch 10480, Loss: 0.016046687960624695, Neurons: 64, Grad norm: 3.153e+00\n",
      "Epoch 10481, Loss: 0.016132257878780365, Neurons: 64, Grad norm: 3.734e+00\n",
      "Epoch 10481, Loss: 0.016132257878780365, Neurons: 64, Grad norm: 3.734e+00\n",
      "Epoch 10482, Loss: 0.01618196628987789, Neurons: 64, Grad norm: 3.586e+00\n",
      "Epoch 10482, Loss: 0.01618196628987789, Neurons: 64, Grad norm: 3.586e+00\n",
      "Epoch 10483, Loss: 0.016157880425453186, Neurons: 64, Grad norm: 2.862e+00\n",
      "Epoch 10483, Loss: 0.016157880425453186, Neurons: 64, Grad norm: 2.862e+00\n",
      "Epoch 10484, Loss: 0.016074754297733307, Neurons: 64, Grad norm: 1.680e+00\n",
      "Epoch 10484, Loss: 0.016074754297733307, Neurons: 64, Grad norm: 1.680e+00\n",
      "Epoch 10485, Loss: 0.015983883291482925, Neurons: 64, Grad norm: 3.526e-01\n",
      "Epoch 10485, Loss: 0.015983883291482925, Neurons: 64, Grad norm: 3.526e-01\n",
      "Epoch 10486, Loss: 0.015932152047753334, Neurons: 64, Grad norm: 9.532e-01\n",
      "Epoch 10486, Loss: 0.015932152047753334, Neurons: 64, Grad norm: 9.532e-01\n",
      "Epoch 10487, Loss: 0.015933958813548088, Neurons: 64, Grad norm: 1.925e+00\n",
      "Epoch 10487, Loss: 0.015933958813548088, Neurons: 64, Grad norm: 1.925e+00\n",
      "Epoch 10488, Loss: 0.015967190265655518, Neurons: 64, Grad norm: 2.493e+00\n",
      "Epoch 10488, Loss: 0.015967190265655518, Neurons: 64, Grad norm: 2.493e+00\n",
      "Epoch 10489, Loss: 0.01599508710205555, Neurons: 64, Grad norm: 2.549e+00\n",
      "Epoch 10489, Loss: 0.01599508710205555, Neurons: 64, Grad norm: 2.549e+00\n",
      "Epoch 10490, Loss: 0.015991544350981712, Neurons: 64, Grad norm: 2.196e+00\n",
      "Epoch 10490, Loss: 0.015991544350981712, Neurons: 64, Grad norm: 2.196e+00\n",
      "Epoch 10491, Loss: 0.015955526381731033, Neurons: 64, Grad norm: 1.471e+00\n",
      "Epoch 10491, Loss: 0.015955526381731033, Neurons: 64, Grad norm: 1.471e+00\n",
      "Epoch 10492, Loss: 0.015906689688563347, Neurons: 64, Grad norm: 5.950e-01\n",
      "Epoch 10492, Loss: 0.015906689688563347, Neurons: 64, Grad norm: 5.950e-01\n",
      "Epoch 10493, Loss: 0.01586928591132164, Neurons: 64, Grad norm: 3.435e-01\n",
      "Epoch 10493, Loss: 0.01586928591132164, Neurons: 64, Grad norm: 3.435e-01\n",
      "Epoch 10494, Loss: 0.01585610955953598, Neurons: 64, Grad norm: 1.080e+00\n",
      "Epoch 10494, Loss: 0.01585610955953598, Neurons: 64, Grad norm: 1.080e+00\n",
      "Epoch 10495, Loss: 0.01586279645562172, Neurons: 64, Grad norm: 1.597e+00\n",
      "Epoch 10495, Loss: 0.01586279645562172, Neurons: 64, Grad norm: 1.597e+00\n",
      "Epoch 10496, Loss: 0.015873698517680168, Neurons: 64, Grad norm: 1.776e+00\n",
      "Epoch 10496, Loss: 0.015873698517680168, Neurons: 64, Grad norm: 1.776e+00\n",
      "Epoch 10497, Loss: 0.015874020755290985, Neurons: 64, Grad norm: 1.677e+00\n",
      "Epoch 10497, Loss: 0.015874020755290985, Neurons: 64, Grad norm: 1.677e+00\n",
      "Epoch 10498, Loss: 0.015858490020036697, Neurons: 64, Grad norm: 1.284e+00\n",
      "Epoch 10498, Loss: 0.015858490020036697, Neurons: 64, Grad norm: 1.284e+00\n",
      "Epoch 10499, Loss: 0.015832405537366867, Neurons: 64, Grad norm: 7.524e-01\n",
      "Epoch 10499, Loss: 0.015832405537366867, Neurons: 64, Grad norm: 7.524e-01\n",
      "Epoch 10499, Test loss: 0.010738725773990154\n",
      "Epoch 10499, Test loss: 0.010738725773990154\n",
      "Epoch 10500, Loss: 0.01580635830760002, Neurons: 64, Grad norm: 1.379e-01\n",
      "Epoch 10500, Loss: 0.01580635830760002, Neurons: 64, Grad norm: 1.379e-01\n",
      "Epoch 10501, Loss: 0.015788892284035683, Neurons: 64, Grad norm: 4.170e-01\n",
      "Epoch 10501, Loss: 0.015788892284035683, Neurons: 64, Grad norm: 4.170e-01\n",
      "Epoch 10502, Loss: 0.01578202098608017, Neurons: 64, Grad norm: 8.778e-01\n",
      "Epoch 10502, Loss: 0.01578202098608017, Neurons: 64, Grad norm: 8.778e-01\n",
      "Epoch 10503, Loss: 0.015781361609697342, Neurons: 64, Grad norm: 1.128e+00\n",
      "Epoch 10503, Loss: 0.015781361609697342, Neurons: 64, Grad norm: 1.128e+00\n",
      "Epoch 10504, Loss: 0.015779919922351837, Neurons: 64, Grad norm: 1.201e+00\n",
      "Epoch 10504, Loss: 0.015779919922351837, Neurons: 64, Grad norm: 1.201e+00\n",
      "Epoch 10505, Loss: 0.015772705897688866, Neurons: 64, Grad norm: 1.054e+00\n",
      "Epoch 10505, Loss: 0.015772705897688866, Neurons: 64, Grad norm: 1.054e+00\n",
      "Epoch 10506, Loss: 0.01575906202197075, Neurons: 64, Grad norm: 8.036e-01\n",
      "Epoch 10506, Loss: 0.01575906202197075, Neurons: 64, Grad norm: 8.036e-01\n",
      "Epoch 10507, Loss: 0.015742097049951553, Neurons: 64, Grad norm: 4.283e-01\n",
      "Epoch 10507, Loss: 0.015742097049951553, Neurons: 64, Grad norm: 4.283e-01\n",
      "Epoch 10508, Loss: 0.015726106241345406, Neurons: 64, Grad norm: 6.839e-02\n",
      "Epoch 10508, Loss: 0.015726106241345406, Neurons: 64, Grad norm: 6.839e-02\n",
      "Epoch 10509, Loss: 0.015714121982455254, Neurons: 64, Grad norm: 3.298e-01\n",
      "Epoch 10509, Loss: 0.015714121982455254, Neurons: 64, Grad norm: 3.298e-01\n",
      "Epoch 10510, Loss: 0.01570640131831169, Neurons: 64, Grad norm: 5.905e-01\n",
      "Epoch 10510, Loss: 0.01570640131831169, Neurons: 64, Grad norm: 5.905e-01\n",
      "Epoch 10511, Loss: 0.01570100709795952, Neurons: 64, Grad norm: 7.691e-01\n",
      "Epoch 10511, Loss: 0.01570100709795952, Neurons: 64, Grad norm: 7.691e-01\n",
      "Epoch 10512, Loss: 0.015695273876190186, Neurons: 64, Grad norm: 7.970e-01\n",
      "Epoch 10512, Loss: 0.015695273876190186, Neurons: 64, Grad norm: 7.970e-01\n",
      "Epoch 10513, Loss: 0.01568722538650036, Neurons: 64, Grad norm: 7.488e-01\n",
      "Epoch 10513, Loss: 0.01568722538650036, Neurons: 64, Grad norm: 7.488e-01\n",
      "Epoch 10514, Loss: 0.015676410868763924, Neurons: 64, Grad norm: 5.748e-01\n",
      "Epoch 10514, Loss: 0.015676410868763924, Neurons: 64, Grad norm: 5.748e-01\n",
      "Epoch 10515, Loss: 0.015664147213101387, Neurons: 64, Grad norm: 3.673e-01\n",
      "Epoch 10515, Loss: 0.015664147213101387, Neurons: 64, Grad norm: 3.673e-01\n",
      "Epoch 10516, Loss: 0.015651846304535866, Neurons: 64, Grad norm: 1.393e-01\n",
      "Epoch 10516, Loss: 0.015651846304535866, Neurons: 64, Grad norm: 1.393e-01\n",
      "Epoch 10517, Loss: 0.015641000121831894, Neurons: 64, Grad norm: 1.638e-01\n",
      "Epoch 10517, Loss: 0.015641000121831894, Neurons: 64, Grad norm: 1.638e-01\n",
      "Epoch 10518, Loss: 0.015631908550858498, Neurons: 64, Grad norm: 3.589e-01\n",
      "Epoch 10518, Loss: 0.015631908550858498, Neurons: 64, Grad norm: 3.589e-01\n",
      "Epoch 10519, Loss: 0.015624167397618294, Neurons: 64, Grad norm: 4.816e-01\n",
      "Epoch 10519, Loss: 0.015624167397618294, Neurons: 64, Grad norm: 4.816e-01\n",
      "Epoch 10520, Loss: 0.015616674907505512, Neurons: 64, Grad norm: 5.687e-01\n",
      "Epoch 10520, Loss: 0.015616674907505512, Neurons: 64, Grad norm: 5.687e-01\n",
      "Epoch 10521, Loss: 0.015608562156558037, Neurons: 64, Grad norm: 5.451e-01\n",
      "Epoch 10521, Loss: 0.015608562156558037, Neurons: 64, Grad norm: 5.451e-01\n",
      "Epoch 10522, Loss: 0.01559932716190815, Neurons: 64, Grad norm: 4.957e-01\n",
      "Epoch 10522, Loss: 0.01559932716190815, Neurons: 64, Grad norm: 4.957e-01\n",
      "Epoch 10523, Loss: 0.015589251182973385, Neurons: 64, Grad norm: 3.719e-01\n",
      "Epoch 10523, Loss: 0.015589251182973385, Neurons: 64, Grad norm: 3.719e-01\n",
      "Epoch 10524, Loss: 0.015578890219330788, Neurons: 64, Grad norm: 2.666e-01\n",
      "Epoch 10524, Loss: 0.015578890219330788, Neurons: 64, Grad norm: 2.666e-01\n",
      "Epoch 10525, Loss: 0.015568884089589119, Neurons: 64, Grad norm: 1.716e-01\n",
      "Epoch 10525, Loss: 0.015568884089589119, Neurons: 64, Grad norm: 1.716e-01\n",
      "Epoch 10526, Loss: 0.015559506602585316, Neurons: 64, Grad norm: 2.040e-01\n",
      "Epoch 10526, Loss: 0.015559506602585316, Neurons: 64, Grad norm: 2.040e-01\n",
      "Epoch 10527, Loss: 0.015551000833511353, Neurons: 64, Grad norm: 2.957e-01\n",
      "Epoch 10527, Loss: 0.015551000833511353, Neurons: 64, Grad norm: 2.957e-01\n",
      "Epoch 10528, Loss: 0.015542969107627869, Neurons: 64, Grad norm: 3.586e-01\n",
      "Epoch 10528, Loss: 0.015542969107627869, Neurons: 64, Grad norm: 3.586e-01\n",
      "Epoch 10529, Loss: 0.015535365790128708, Neurons: 64, Grad norm: 4.102e-01\n",
      "Epoch 10529, Loss: 0.015535365790128708, Neurons: 64, Grad norm: 4.102e-01\n",
      "Epoch 10530, Loss: 0.01552759762853384, Neurons: 64, Grad norm: 4.162e-01\n",
      "Epoch 10530, Loss: 0.01552759762853384, Neurons: 64, Grad norm: 4.162e-01\n",
      "Epoch 10531, Loss: 0.015519295819103718, Neurons: 64, Grad norm: 4.110e-01\n",
      "Epoch 10531, Loss: 0.015519295819103718, Neurons: 64, Grad norm: 4.110e-01\n",
      "Epoch 10532, Loss: 0.015510719269514084, Neurons: 64, Grad norm: 3.777e-01\n",
      "Epoch 10532, Loss: 0.015510719269514084, Neurons: 64, Grad norm: 3.777e-01\n",
      "Epoch 10533, Loss: 0.01550198532640934, Neurons: 64, Grad norm: 3.590e-01\n",
      "Epoch 10533, Loss: 0.01550198532640934, Neurons: 64, Grad norm: 3.590e-01\n",
      "Epoch 10534, Loss: 0.01549331471323967, Neurons: 64, Grad norm: 3.661e-01\n",
      "Epoch 10534, Loss: 0.01549331471323967, Neurons: 64, Grad norm: 3.661e-01\n",
      "Epoch 10535, Loss: 0.015485091134905815, Neurons: 64, Grad norm: 3.949e-01\n",
      "Epoch 10535, Loss: 0.015485091134905815, Neurons: 64, Grad norm: 3.949e-01\n",
      "Epoch 10536, Loss: 0.01547724287956953, Neurons: 64, Grad norm: 4.620e-01\n",
      "Epoch 10536, Loss: 0.01547724287956953, Neurons: 64, Grad norm: 4.620e-01\n",
      "Epoch 10537, Loss: 0.015470406040549278, Neurons: 64, Grad norm: 5.180e-01\n",
      "Epoch 10537, Loss: 0.015470406040549278, Neurons: 64, Grad norm: 5.180e-01\n",
      "Epoch 10538, Loss: 0.0154641792178154, Neurons: 64, Grad norm: 5.969e-01\n",
      "Epoch 10538, Loss: 0.0154641792178154, Neurons: 64, Grad norm: 5.969e-01\n",
      "Epoch 10539, Loss: 0.015458866953849792, Neurons: 64, Grad norm: 6.489e-01\n",
      "Epoch 10539, Loss: 0.015458866953849792, Neurons: 64, Grad norm: 6.489e-01\n",
      "Epoch 10540, Loss: 0.01545419916510582, Neurons: 64, Grad norm: 7.214e-01\n",
      "Epoch 10540, Loss: 0.01545419916510582, Neurons: 64, Grad norm: 7.214e-01\n",
      "Epoch 10541, Loss: 0.015450794249773026, Neurons: 64, Grad norm: 7.723e-01\n",
      "Epoch 10541, Loss: 0.015450794249773026, Neurons: 64, Grad norm: 7.723e-01\n",
      "Epoch 10542, Loss: 0.015448332764208317, Neurons: 64, Grad norm: 8.487e-01\n",
      "Epoch 10542, Loss: 0.015448332764208317, Neurons: 64, Grad norm: 8.487e-01\n",
      "Epoch 10543, Loss: 0.015447758138179779, Neurons: 64, Grad norm: 9.128e-01\n",
      "Epoch 10543, Loss: 0.015447758138179779, Neurons: 64, Grad norm: 9.128e-01\n",
      "Epoch 10544, Loss: 0.015448580496013165, Neurons: 64, Grad norm: 1.002e+00\n",
      "Epoch 10544, Loss: 0.015448580496013165, Neurons: 64, Grad norm: 1.002e+00\n",
      "Epoch 10545, Loss: 0.01545155979692936, Neurons: 64, Grad norm: 1.080e+00\n",
      "Epoch 10545, Loss: 0.01545155979692936, Neurons: 64, Grad norm: 1.080e+00\n",
      "Epoch 10546, Loss: 0.015455585904419422, Neurons: 64, Grad norm: 1.176e+00\n",
      "Epoch 10546, Loss: 0.015455585904419422, Neurons: 64, Grad norm: 1.176e+00\n",
      "Epoch 10547, Loss: 0.015461177565157413, Neurons: 64, Grad norm: 1.247e+00\n",
      "Epoch 10547, Loss: 0.015461177565157413, Neurons: 64, Grad norm: 1.247e+00\n",
      "Epoch 10548, Loss: 0.01546564418822527, Neurons: 64, Grad norm: 1.311e+00\n",
      "Epoch 10548, Loss: 0.01546564418822527, Neurons: 64, Grad norm: 1.311e+00\n",
      "Epoch 10549, Loss: 0.015466952696442604, Neurons: 64, Grad norm: 1.331e+00\n",
      "Epoch 10549, Loss: 0.015466952696442604, Neurons: 64, Grad norm: 1.331e+00\n",
      "Epoch 10550, Loss: 0.015462992712855339, Neurons: 64, Grad norm: 1.328e+00\n",
      "Epoch 10550, Loss: 0.015462992712855339, Neurons: 64, Grad norm: 1.328e+00\n",
      "Epoch 10551, Loss: 0.015451787039637566, Neurons: 64, Grad norm: 1.264e+00\n",
      "Epoch 10551, Loss: 0.015451787039637566, Neurons: 64, Grad norm: 1.264e+00\n",
      "Epoch 10552, Loss: 0.015432648360729218, Neurons: 64, Grad norm: 1.168e+00\n",
      "Epoch 10552, Loss: 0.015432648360729218, Neurons: 64, Grad norm: 1.168e+00\n",
      "Epoch 10553, Loss: 0.015405934303998947, Neurons: 64, Grad norm: 1.012e+00\n",
      "Epoch 10553, Loss: 0.015405934303998947, Neurons: 64, Grad norm: 1.012e+00\n",
      "Epoch 10554, Loss: 0.015374512411653996, Neurons: 64, Grad norm: 8.403e-01\n",
      "Epoch 10554, Loss: 0.015374512411653996, Neurons: 64, Grad norm: 8.403e-01\n",
      "Epoch 10555, Loss: 0.01534215733408928, Neurons: 64, Grad norm: 6.286e-01\n",
      "Epoch 10555, Loss: 0.01534215733408928, Neurons: 64, Grad norm: 6.286e-01\n",
      "Epoch 10556, Loss: 0.015312722884118557, Neurons: 64, Grad norm: 4.446e-01\n",
      "Epoch 10556, Loss: 0.015312722884118557, Neurons: 64, Grad norm: 4.446e-01\n",
      "Epoch 10557, Loss: 0.015289511531591415, Neurons: 64, Grad norm: 2.775e-01\n",
      "Epoch 10557, Loss: 0.015289511531591415, Neurons: 64, Grad norm: 2.775e-01\n",
      "Epoch 10558, Loss: 0.015273630619049072, Neurons: 64, Grad norm: 2.583e-01\n",
      "Epoch 10558, Loss: 0.015273630619049072, Neurons: 64, Grad norm: 2.583e-01\n",
      "Epoch 10559, Loss: 0.015264485962688923, Neurons: 64, Grad norm: 3.376e-01\n",
      "Epoch 10559, Loss: 0.015264485962688923, Neurons: 64, Grad norm: 3.376e-01\n",
      "Epoch 10560, Loss: 0.015260221436619759, Neurons: 64, Grad norm: 4.559e-01\n",
      "Epoch 10560, Loss: 0.015260221436619759, Neurons: 64, Grad norm: 4.559e-01\n",
      "Epoch 10561, Loss: 0.015258612111210823, Neurons: 64, Grad norm: 5.588e-01\n",
      "Epoch 10561, Loss: 0.015258612111210823, Neurons: 64, Grad norm: 5.588e-01\n",
      "Epoch 10562, Loss: 0.015257823280990124, Neurons: 64, Grad norm: 6.336e-01\n",
      "Epoch 10562, Loss: 0.015257823280990124, Neurons: 64, Grad norm: 6.336e-01\n",
      "Epoch 10563, Loss: 0.015255969017744064, Neurons: 64, Grad norm: 6.886e-01\n",
      "Epoch 10563, Loss: 0.015255969017744064, Neurons: 64, Grad norm: 6.886e-01\n",
      "Epoch 10564, Loss: 0.015251549892127514, Neurons: 64, Grad norm: 7.000e-01\n",
      "Epoch 10564, Loss: 0.015251549892127514, Neurons: 64, Grad norm: 7.000e-01\n",
      "Epoch 10565, Loss: 0.01524405088275671, Neurons: 64, Grad norm: 7.000e-01\n",
      "Epoch 10565, Loss: 0.01524405088275671, Neurons: 64, Grad norm: 7.000e-01\n",
      "Epoch 10566, Loss: 0.015233312733471394, Neurons: 64, Grad norm: 6.623e-01\n",
      "Epoch 10566, Loss: 0.015233312733471394, Neurons: 64, Grad norm: 6.623e-01\n",
      "Epoch 10567, Loss: 0.015220613218843937, Neurons: 64, Grad norm: 6.276e-01\n",
      "Epoch 10567, Loss: 0.015220613218843937, Neurons: 64, Grad norm: 6.276e-01\n",
      "Epoch 10568, Loss: 0.01520643662661314, Neurons: 64, Grad norm: 5.628e-01\n",
      "Epoch 10568, Loss: 0.01520643662661314, Neurons: 64, Grad norm: 5.628e-01\n",
      "Epoch 10569, Loss: 0.0151921221986413, Neurons: 64, Grad norm: 5.194e-01\n",
      "Epoch 10569, Loss: 0.0151921221986413, Neurons: 64, Grad norm: 5.194e-01\n",
      "Epoch 10570, Loss: 0.015178360976278782, Neurons: 64, Grad norm: 4.456e-01\n",
      "Epoch 10570, Loss: 0.015178360976278782, Neurons: 64, Grad norm: 4.456e-01\n",
      "Epoch 10571, Loss: 0.015165622346103191, Neurons: 64, Grad norm: 4.165e-01\n",
      "Epoch 10571, Loss: 0.015165622346103191, Neurons: 64, Grad norm: 4.165e-01\n",
      "Epoch 10572, Loss: 0.015154249966144562, Neurons: 64, Grad norm: 3.669e-01\n",
      "Epoch 10572, Loss: 0.015154249966144562, Neurons: 64, Grad norm: 3.669e-01\n",
      "Epoch 10573, Loss: 0.015144195407629013, Neurons: 64, Grad norm: 3.612e-01\n",
      "Epoch 10573, Loss: 0.015144195407629013, Neurons: 64, Grad norm: 3.612e-01\n",
      "Epoch 10574, Loss: 0.015135378576815128, Neurons: 64, Grad norm: 3.351e-01\n",
      "Epoch 10574, Loss: 0.015135378576815128, Neurons: 64, Grad norm: 3.351e-01\n",
      "Epoch 10575, Loss: 0.015127327293157578, Neurons: 64, Grad norm: 3.394e-01\n",
      "Epoch 10575, Loss: 0.015127327293157578, Neurons: 64, Grad norm: 3.394e-01\n",
      "Epoch 10576, Loss: 0.015119749121367931, Neurons: 64, Grad norm: 3.263e-01\n",
      "Epoch 10576, Loss: 0.015119749121367931, Neurons: 64, Grad norm: 3.263e-01\n",
      "Epoch 10577, Loss: 0.015112199820578098, Neurons: 64, Grad norm: 3.287e-01\n",
      "Epoch 10577, Loss: 0.015112199820578098, Neurons: 64, Grad norm: 3.287e-01\n",
      "Epoch 10578, Loss: 0.01510452851653099, Neurons: 64, Grad norm: 3.192e-01\n",
      "Epoch 10578, Loss: 0.01510452851653099, Neurons: 64, Grad norm: 3.192e-01\n",
      "Epoch 10579, Loss: 0.015096759423613548, Neurons: 64, Grad norm: 3.183e-01\n",
      "Epoch 10579, Loss: 0.015096759423613548, Neurons: 64, Grad norm: 3.183e-01\n",
      "Epoch 10580, Loss: 0.015088709071278572, Neurons: 64, Grad norm: 3.181e-01\n",
      "Epoch 10580, Loss: 0.015088709071278572, Neurons: 64, Grad norm: 3.181e-01\n",
      "Epoch 10581, Loss: 0.015080343931913376, Neurons: 64, Grad norm: 3.139e-01\n",
      "Epoch 10581, Loss: 0.015080343931913376, Neurons: 64, Grad norm: 3.139e-01\n",
      "Epoch 10582, Loss: 0.015071826055645943, Neurons: 64, Grad norm: 3.243e-01\n",
      "Epoch 10582, Loss: 0.015071826055645943, Neurons: 64, Grad norm: 3.243e-01\n",
      "Epoch 10583, Loss: 0.0150631507858634, Neurons: 64, Grad norm: 3.224e-01\n",
      "Epoch 10583, Loss: 0.0150631507858634, Neurons: 64, Grad norm: 3.224e-01\n",
      "Epoch 10584, Loss: 0.015054387040436268, Neurons: 64, Grad norm: 3.452e-01\n",
      "Epoch 10584, Loss: 0.015054387040436268, Neurons: 64, Grad norm: 3.452e-01\n",
      "Epoch 10585, Loss: 0.015045691281557083, Neurons: 64, Grad norm: 3.417e-01\n",
      "Epoch 10585, Loss: 0.015045691281557083, Neurons: 64, Grad norm: 3.417e-01\n",
      "Epoch 10586, Loss: 0.015036831609904766, Neurons: 64, Grad norm: 3.671e-01\n",
      "Epoch 10586, Loss: 0.015036831609904766, Neurons: 64, Grad norm: 3.671e-01\n",
      "Epoch 10587, Loss: 0.015027947723865509, Neurons: 64, Grad norm: 3.660e-01\n",
      "Epoch 10587, Loss: 0.015027947723865509, Neurons: 64, Grad norm: 3.660e-01\n",
      "Epoch 10588, Loss: 0.015018995851278305, Neurons: 64, Grad norm: 3.991e-01\n",
      "Epoch 10588, Loss: 0.015018995851278305, Neurons: 64, Grad norm: 3.991e-01\n",
      "Epoch 10589, Loss: 0.015010287053883076, Neurons: 64, Grad norm: 3.987e-01\n",
      "Epoch 10589, Loss: 0.015010287053883076, Neurons: 64, Grad norm: 3.987e-01\n",
      "Epoch 10590, Loss: 0.015001538209617138, Neurons: 64, Grad norm: 4.357e-01\n",
      "Epoch 10590, Loss: 0.015001538209617138, Neurons: 64, Grad norm: 4.357e-01\n",
      "Epoch 10591, Loss: 0.01499286387115717, Neurons: 64, Grad norm: 4.414e-01\n",
      "Epoch 10591, Loss: 0.01499286387115717, Neurons: 64, Grad norm: 4.414e-01\n",
      "Epoch 10592, Loss: 0.014984305016696453, Neurons: 64, Grad norm: 4.778e-01\n",
      "Epoch 10592, Loss: 0.014984305016696453, Neurons: 64, Grad norm: 4.778e-01\n",
      "Epoch 10593, Loss: 0.014975887723267078, Neurons: 64, Grad norm: 4.848e-01\n",
      "Epoch 10593, Loss: 0.014975887723267078, Neurons: 64, Grad norm: 4.848e-01\n",
      "Epoch 10594, Loss: 0.014967660419642925, Neurons: 64, Grad norm: 5.272e-01\n",
      "Epoch 10594, Loss: 0.014967660419642925, Neurons: 64, Grad norm: 5.272e-01\n",
      "Epoch 10595, Loss: 0.014959541149437428, Neurons: 64, Grad norm: 5.412e-01\n",
      "Epoch 10595, Loss: 0.014959541149437428, Neurons: 64, Grad norm: 5.412e-01\n",
      "Epoch 10596, Loss: 0.014951500110328197, Neurons: 64, Grad norm: 5.901e-01\n",
      "Epoch 10596, Loss: 0.014951500110328197, Neurons: 64, Grad norm: 5.901e-01\n",
      "Epoch 10597, Loss: 0.014943665824830532, Neurons: 64, Grad norm: 6.125e-01\n",
      "Epoch 10597, Loss: 0.014943665824830532, Neurons: 64, Grad norm: 6.125e-01\n",
      "Epoch 10598, Loss: 0.014935947954654694, Neurons: 64, Grad norm: 6.716e-01\n",
      "Epoch 10598, Loss: 0.014935947954654694, Neurons: 64, Grad norm: 6.716e-01\n",
      "Epoch 10599, Loss: 0.014928475953638554, Neurons: 64, Grad norm: 7.069e-01\n",
      "Epoch 10599, Loss: 0.014928475953638554, Neurons: 64, Grad norm: 7.069e-01\n",
      "Epoch 10599, Test loss: 0.010156311094760895\n",
      "Epoch 10599, Test loss: 0.010156311094760895\n",
      "Epoch 10600, Loss: 0.014921072870492935, Neurons: 64, Grad norm: 7.834e-01\n",
      "Epoch 10600, Loss: 0.014921072870492935, Neurons: 64, Grad norm: 7.834e-01\n",
      "Epoch 10601, Loss: 0.01491412054747343, Neurons: 64, Grad norm: 8.379e-01\n",
      "Epoch 10601, Loss: 0.01491412054747343, Neurons: 64, Grad norm: 8.379e-01\n",
      "Epoch 10602, Loss: 0.01490751188248396, Neurons: 64, Grad norm: 9.352e-01\n",
      "Epoch 10602, Loss: 0.01490751188248396, Neurons: 64, Grad norm: 9.352e-01\n",
      "Epoch 10603, Loss: 0.014901421032845974, Neurons: 64, Grad norm: 1.014e+00\n",
      "Epoch 10603, Loss: 0.014901421032845974, Neurons: 64, Grad norm: 1.014e+00\n",
      "Epoch 10604, Loss: 0.014896050095558167, Neurons: 64, Grad norm: 1.144e+00\n",
      "Epoch 10604, Loss: 0.014896050095558167, Neurons: 64, Grad norm: 1.144e+00\n",
      "Epoch 10605, Loss: 0.014891517348587513, Neurons: 64, Grad norm: 1.260e+00\n",
      "Epoch 10605, Loss: 0.014891517348587513, Neurons: 64, Grad norm: 1.260e+00\n",
      "Epoch 10606, Loss: 0.014888329431414604, Neurons: 64, Grad norm: 1.428e+00\n",
      "Epoch 10606, Loss: 0.014888329431414604, Neurons: 64, Grad norm: 1.428e+00\n",
      "Epoch 10607, Loss: 0.01488658506423235, Neurons: 64, Grad norm: 1.593e+00\n",
      "Epoch 10607, Loss: 0.01488658506423235, Neurons: 64, Grad norm: 1.593e+00\n",
      "Epoch 10608, Loss: 0.014887099154293537, Neurons: 64, Grad norm: 1.824e+00\n",
      "Epoch 10608, Loss: 0.014887099154293537, Neurons: 64, Grad norm: 1.824e+00\n",
      "Epoch 10609, Loss: 0.014890666119754314, Neurons: 64, Grad norm: 2.060e+00\n",
      "Epoch 10609, Loss: 0.014890666119754314, Neurons: 64, Grad norm: 2.060e+00\n",
      "Epoch 10610, Loss: 0.014898267574608326, Neurons: 64, Grad norm: 2.371e+00\n",
      "Epoch 10610, Loss: 0.014898267574608326, Neurons: 64, Grad norm: 2.371e+00\n",
      "Epoch 10611, Loss: 0.01491116639226675, Neurons: 64, Grad norm: 2.701e+00\n",
      "Epoch 10611, Loss: 0.01491116639226675, Neurons: 64, Grad norm: 2.701e+00\n",
      "Epoch 10612, Loss: 0.014931246638298035, Neurons: 64, Grad norm: 3.111e+00\n",
      "Epoch 10612, Loss: 0.014931246638298035, Neurons: 64, Grad norm: 3.111e+00\n",
      "Epoch 10613, Loss: 0.01496036909520626, Neurons: 64, Grad norm: 3.546e+00\n",
      "Epoch 10613, Loss: 0.01496036909520626, Neurons: 64, Grad norm: 3.546e+00\n",
      "Epoch 10614, Loss: 0.015001106075942516, Neurons: 64, Grad norm: 4.071e+00\n",
      "Epoch 10614, Loss: 0.015001106075942516, Neurons: 64, Grad norm: 4.071e+00\n",
      "Epoch 10615, Loss: 0.015055648982524872, Neurons: 64, Grad norm: 4.598e+00\n",
      "Epoch 10615, Loss: 0.015055648982524872, Neurons: 64, Grad norm: 4.598e+00\n",
      "Epoch 10616, Loss: 0.015124871395528316, Neurons: 64, Grad norm: 5.180e+00\n",
      "Epoch 10616, Loss: 0.015124871395528316, Neurons: 64, Grad norm: 5.180e+00\n",
      "Epoch 10617, Loss: 0.01520786713808775, Neurons: 64, Grad norm: 5.722e+00\n",
      "Epoch 10617, Loss: 0.01520786713808775, Neurons: 64, Grad norm: 5.722e+00\n",
      "Epoch 10618, Loss: 0.015298400074243546, Neurons: 64, Grad norm: 6.218e+00\n",
      "Epoch 10618, Loss: 0.015298400074243546, Neurons: 64, Grad norm: 6.218e+00\n",
      "Epoch 10619, Loss: 0.015383669175207615, Neurons: 64, Grad norm: 6.534e+00\n",
      "Epoch 10619, Loss: 0.015383669175207615, Neurons: 64, Grad norm: 6.534e+00\n",
      "Epoch 10620, Loss: 0.015443249605596066, Neurons: 64, Grad norm: 6.643e+00\n",
      "Epoch 10620, Loss: 0.015443249605596066, Neurons: 64, Grad norm: 6.643e+00\n",
      "Epoch 10621, Loss: 0.015452823601663113, Neurons: 64, Grad norm: 6.404e+00\n",
      "Epoch 10621, Loss: 0.015452823601663113, Neurons: 64, Grad norm: 6.404e+00\n",
      "Epoch 10622, Loss: 0.015392164699733257, Neurons: 64, Grad norm: 5.818e+00\n",
      "Epoch 10622, Loss: 0.015392164699733257, Neurons: 64, Grad norm: 5.818e+00\n",
      "Epoch 10623, Loss: 0.015259591862559319, Neurons: 64, Grad norm: 4.829e+00\n",
      "Epoch 10623, Loss: 0.015259591862559319, Neurons: 64, Grad norm: 4.829e+00\n",
      "Epoch 10624, Loss: 0.01508116815239191, Neurons: 64, Grad norm: 3.579e+00\n",
      "Epoch 10624, Loss: 0.01508116815239191, Neurons: 64, Grad norm: 3.579e+00\n",
      "Epoch 10625, Loss: 0.01490189041942358, Neurons: 64, Grad norm: 2.133e+00\n",
      "Epoch 10625, Loss: 0.01490189041942358, Neurons: 64, Grad norm: 2.133e+00\n",
      "Epoch 10626, Loss: 0.014768819324672222, Neurons: 64, Grad norm: 7.844e-01\n",
      "Epoch 10626, Loss: 0.014768819324672222, Neurons: 64, Grad norm: 7.844e-01\n",
      "Epoch 10627, Loss: 0.01470786239951849, Neurons: 64, Grad norm: 9.155e-01\n",
      "Epoch 10627, Loss: 0.01470786239951849, Neurons: 64, Grad norm: 9.155e-01\n",
      "Epoch 10628, Loss: 0.014716194011271, Neurons: 64, Grad norm: 1.962e+00\n",
      "Epoch 10628, Loss: 0.014716194011271, Neurons: 64, Grad norm: 1.962e+00\n",
      "Epoch 10629, Loss: 0.014768299646675587, Neurons: 64, Grad norm: 2.795e+00\n",
      "Epoch 10629, Loss: 0.014768299646675587, Neurons: 64, Grad norm: 2.795e+00\n",
      "Epoch 10630, Loss: 0.01482939999550581, Neurons: 64, Grad norm: 3.259e+00\n",
      "Epoch 10630, Loss: 0.01482939999550581, Neurons: 64, Grad norm: 3.259e+00\n",
      "Epoch 10631, Loss: 0.014867606572806835, Neurons: 64, Grad norm: 3.393e+00\n",
      "Epoch 10631, Loss: 0.014867606572806835, Neurons: 64, Grad norm: 3.393e+00\n",
      "Epoch 10632, Loss: 0.01486534159630537, Neurons: 64, Grad norm: 3.150e+00\n",
      "Epoch 10632, Loss: 0.01486534159630537, Neurons: 64, Grad norm: 3.150e+00\n",
      "Epoch 10633, Loss: 0.01482201274484396, Neurons: 64, Grad norm: 2.645e+00\n",
      "Epoch 10633, Loss: 0.01482201274484396, Neurons: 64, Grad norm: 2.645e+00\n",
      "Epoch 10634, Loss: 0.014754226431250572, Neurons: 64, Grad norm: 1.900e+00\n",
      "Epoch 10634, Loss: 0.014754226431250572, Neurons: 64, Grad norm: 1.900e+00\n",
      "Epoch 10635, Loss: 0.014685779809951782, Neurons: 64, Grad norm: 1.094e+00\n",
      "Epoch 10635, Loss: 0.014685779809951782, Neurons: 64, Grad norm: 1.094e+00\n",
      "Epoch 10636, Loss: 0.01463744230568409, Neurons: 64, Grad norm: 3.950e-01\n",
      "Epoch 10636, Loss: 0.01463744230568409, Neurons: 64, Grad norm: 3.950e-01\n",
      "Epoch 10637, Loss: 0.014618609100580215, Neurons: 64, Grad norm: 6.887e-01\n",
      "Epoch 10637, Loss: 0.014618609100580215, Neurons: 64, Grad norm: 6.887e-01\n",
      "Epoch 10638, Loss: 0.014625286683440208, Neurons: 64, Grad norm: 1.273e+00\n",
      "Epoch 10638, Loss: 0.014625286683440208, Neurons: 64, Grad norm: 1.273e+00\n",
      "Epoch 10639, Loss: 0.014644681476056576, Neurons: 64, Grad norm: 1.656e+00\n",
      "Epoch 10639, Loss: 0.014644681476056576, Neurons: 64, Grad norm: 1.656e+00\n",
      "Epoch 10640, Loss: 0.014661619439721107, Neurons: 64, Grad norm: 1.859e+00\n",
      "Epoch 10640, Loss: 0.014661619439721107, Neurons: 64, Grad norm: 1.859e+00\n",
      "Epoch 10641, Loss: 0.014665348455309868, Neurons: 64, Grad norm: 1.815e+00\n",
      "Epoch 10641, Loss: 0.014665348455309868, Neurons: 64, Grad norm: 1.815e+00\n",
      "Epoch 10642, Loss: 0.014651339501142502, Neurons: 64, Grad norm: 1.611e+00\n",
      "Epoch 10642, Loss: 0.014651339501142502, Neurons: 64, Grad norm: 1.611e+00\n",
      "Epoch 10643, Loss: 0.014623734168708324, Neurons: 64, Grad norm: 1.230e+00\n",
      "Epoch 10643, Loss: 0.014623734168708324, Neurons: 64, Grad norm: 1.230e+00\n",
      "Epoch 10644, Loss: 0.014590561389923096, Neurons: 64, Grad norm: 7.895e-01\n",
      "Epoch 10644, Loss: 0.014590561389923096, Neurons: 64, Grad norm: 7.895e-01\n",
      "Epoch 10645, Loss: 0.014561280608177185, Neurons: 64, Grad norm: 2.886e-01\n",
      "Epoch 10645, Loss: 0.014561280608177185, Neurons: 64, Grad norm: 2.886e-01\n",
      "Epoch 10646, Loss: 0.014542236924171448, Neurons: 64, Grad norm: 1.877e-01\n",
      "Epoch 10646, Loss: 0.014542236924171448, Neurons: 64, Grad norm: 1.877e-01\n",
      "Epoch 10647, Loss: 0.014534605666995049, Neurons: 64, Grad norm: 5.898e-01\n",
      "Epoch 10647, Loss: 0.014534605666995049, Neurons: 64, Grad norm: 5.898e-01\n",
      "Epoch 10648, Loss: 0.014535164460539818, Neurons: 64, Grad norm: 8.683e-01\n",
      "Epoch 10648, Loss: 0.014535164460539818, Neurons: 64, Grad norm: 8.683e-01\n",
      "Epoch 10649, Loss: 0.014538601972162724, Neurons: 64, Grad norm: 1.064e+00\n",
      "Epoch 10649, Loss: 0.014538601972162724, Neurons: 64, Grad norm: 1.064e+00\n",
      "Epoch 10650, Loss: 0.014539798721671104, Neurons: 64, Grad norm: 1.103e+00\n",
      "Epoch 10650, Loss: 0.014539798721671104, Neurons: 64, Grad norm: 1.103e+00\n",
      "Epoch 10651, Loss: 0.014535300433635712, Neurons: 64, Grad norm: 1.057e+00\n",
      "Epoch 10651, Loss: 0.014535300433635712, Neurons: 64, Grad norm: 1.057e+00\n",
      "Epoch 10652, Loss: 0.01452457532286644, Neurons: 64, Grad norm: 8.863e-01\n",
      "Epoch 10652, Loss: 0.01452457532286644, Neurons: 64, Grad norm: 8.863e-01\n",
      "Epoch 10653, Loss: 0.014509281143546104, Neurons: 64, Grad norm: 6.737e-01\n",
      "Epoch 10653, Loss: 0.014509281143546104, Neurons: 64, Grad norm: 6.737e-01\n",
      "Epoch 10654, Loss: 0.014492341317236423, Neurons: 64, Grad norm: 3.943e-01\n",
      "Epoch 10654, Loss: 0.014492341317236423, Neurons: 64, Grad norm: 3.943e-01\n",
      "Epoch 10655, Loss: 0.01447682362049818, Neurons: 64, Grad norm: 1.588e-01\n",
      "Epoch 10655, Loss: 0.01447682362049818, Neurons: 64, Grad norm: 1.588e-01\n",
      "Epoch 10656, Loss: 0.014464445412158966, Neurons: 64, Grad norm: 2.184e-01\n",
      "Epoch 10656, Loss: 0.014464445412158966, Neurons: 64, Grad norm: 2.184e-01\n",
      "Epoch 10657, Loss: 0.014455876313149929, Neurons: 64, Grad norm: 4.236e-01\n",
      "Epoch 10657, Loss: 0.014455876313149929, Neurons: 64, Grad norm: 4.236e-01\n",
      "Epoch 10658, Loss: 0.014450489543378353, Neurons: 64, Grad norm: 6.200e-01\n",
      "Epoch 10658, Loss: 0.014450489543378353, Neurons: 64, Grad norm: 6.200e-01\n",
      "Epoch 10659, Loss: 0.014446552842855453, Neurons: 64, Grad norm: 7.255e-01\n",
      "Epoch 10659, Loss: 0.014446552842855453, Neurons: 64, Grad norm: 7.255e-01\n",
      "Epoch 10660, Loss: 0.014442373998463154, Neurons: 64, Grad norm: 8.042e-01\n",
      "Epoch 10660, Loss: 0.014442373998463154, Neurons: 64, Grad norm: 8.042e-01\n",
      "Epoch 10661, Loss: 0.014436972327530384, Neurons: 64, Grad norm: 7.871e-01\n",
      "Epoch 10661, Loss: 0.014436972327530384, Neurons: 64, Grad norm: 7.871e-01\n",
      "Epoch 10662, Loss: 0.014429564587771893, Neurons: 64, Grad norm: 7.468e-01\n",
      "Epoch 10662, Loss: 0.014429564587771893, Neurons: 64, Grad norm: 7.468e-01\n",
      "Epoch 10663, Loss: 0.01442051026970148, Neurons: 64, Grad norm: 6.282e-01\n",
      "Epoch 10663, Loss: 0.01442051026970148, Neurons: 64, Grad norm: 6.282e-01\n",
      "Epoch 10664, Loss: 0.014410099945962429, Neurons: 64, Grad norm: 5.091e-01\n",
      "Epoch 10664, Loss: 0.014410099945962429, Neurons: 64, Grad norm: 5.091e-01\n",
      "Epoch 10665, Loss: 0.014399147592484951, Neurons: 64, Grad norm: 3.378e-01\n",
      "Epoch 10665, Loss: 0.014399147592484951, Neurons: 64, Grad norm: 3.378e-01\n",
      "Epoch 10666, Loss: 0.014388619922101498, Neurons: 64, Grad norm: 1.904e-01\n",
      "Epoch 10666, Loss: 0.014388619922101498, Neurons: 64, Grad norm: 1.904e-01\n",
      "Epoch 10667, Loss: 0.014378960244357586, Neurons: 64, Grad norm: 3.497e-02\n",
      "Epoch 10667, Loss: 0.014378960244357586, Neurons: 64, Grad norm: 3.497e-02\n",
      "Epoch 10668, Loss: 0.01437055692076683, Neurons: 64, Grad norm: 1.210e-01\n",
      "Epoch 10668, Loss: 0.01437055692076683, Neurons: 64, Grad norm: 1.210e-01\n",
      "Epoch 10669, Loss: 0.01436309702694416, Neurons: 64, Grad norm: 2.631e-01\n",
      "Epoch 10669, Loss: 0.01436309702694416, Neurons: 64, Grad norm: 2.631e-01\n",
      "Epoch 10670, Loss: 0.014356354251503944, Neurons: 64, Grad norm: 3.474e-01\n",
      "Epoch 10670, Loss: 0.014356354251503944, Neurons: 64, Grad norm: 3.474e-01\n",
      "Epoch 10671, Loss: 0.014349937438964844, Neurons: 64, Grad norm: 4.365e-01\n",
      "Epoch 10671, Loss: 0.014349937438964844, Neurons: 64, Grad norm: 4.365e-01\n",
      "Epoch 10672, Loss: 0.014343473128974438, Neurons: 64, Grad norm: 4.627e-01\n",
      "Epoch 10672, Loss: 0.014343473128974438, Neurons: 64, Grad norm: 4.627e-01\n",
      "Epoch 10673, Loss: 0.014336605556309223, Neurons: 64, Grad norm: 4.934e-01\n",
      "Epoch 10673, Loss: 0.014336605556309223, Neurons: 64, Grad norm: 4.934e-01\n",
      "Epoch 10674, Loss: 0.014329250901937485, Neurons: 64, Grad norm: 4.672e-01\n",
      "Epoch 10674, Loss: 0.014329250901937485, Neurons: 64, Grad norm: 4.672e-01\n",
      "Epoch 10675, Loss: 0.014321409165859222, Neurons: 64, Grad norm: 4.511e-01\n",
      "Epoch 10675, Loss: 0.014321409165859222, Neurons: 64, Grad norm: 4.511e-01\n",
      "Epoch 10676, Loss: 0.014313136227428913, Neurons: 64, Grad norm: 3.909e-01\n",
      "Epoch 10676, Loss: 0.014313136227428913, Neurons: 64, Grad norm: 3.909e-01\n",
      "Epoch 10677, Loss: 0.014304746873676777, Neurons: 64, Grad norm: 3.524e-01\n",
      "Epoch 10677, Loss: 0.014304746873676777, Neurons: 64, Grad norm: 3.524e-01\n",
      "Epoch 10678, Loss: 0.014296349138021469, Neurons: 64, Grad norm: 2.755e-01\n",
      "Epoch 10678, Loss: 0.014296349138021469, Neurons: 64, Grad norm: 2.755e-01\n",
      "Epoch 10679, Loss: 0.014288010075688362, Neurons: 64, Grad norm: 2.381e-01\n",
      "Epoch 10679, Loss: 0.014288010075688362, Neurons: 64, Grad norm: 2.381e-01\n",
      "Epoch 10680, Loss: 0.014279915951192379, Neurons: 64, Grad norm: 1.718e-01\n",
      "Epoch 10680, Loss: 0.014279915951192379, Neurons: 64, Grad norm: 1.718e-01\n",
      "Epoch 10681, Loss: 0.014272090047597885, Neurons: 64, Grad norm: 1.509e-01\n",
      "Epoch 10681, Loss: 0.014272090047597885, Neurons: 64, Grad norm: 1.509e-01\n",
      "Epoch 10682, Loss: 0.01426458265632391, Neurons: 64, Grad norm: 1.360e-01\n",
      "Epoch 10682, Loss: 0.01426458265632391, Neurons: 64, Grad norm: 1.360e-01\n",
      "Epoch 10683, Loss: 0.014257250353693962, Neurons: 64, Grad norm: 1.572e-01\n",
      "Epoch 10683, Loss: 0.014257250353693962, Neurons: 64, Grad norm: 1.572e-01\n",
      "Epoch 10684, Loss: 0.014250309206545353, Neurons: 64, Grad norm: 1.843e-01\n",
      "Epoch 10684, Loss: 0.014250309206545353, Neurons: 64, Grad norm: 1.843e-01\n",
      "Epoch 10685, Loss: 0.014243514277040958, Neurons: 64, Grad norm: 2.238e-01\n",
      "Epoch 10685, Loss: 0.014243514277040958, Neurons: 64, Grad norm: 2.238e-01\n",
      "Epoch 10686, Loss: 0.014237012714147568, Neurons: 64, Grad norm: 2.695e-01\n",
      "Epoch 10686, Loss: 0.014237012714147568, Neurons: 64, Grad norm: 2.695e-01\n",
      "Epoch 10687, Loss: 0.014230865985155106, Neurons: 64, Grad norm: 3.256e-01\n",
      "Epoch 10687, Loss: 0.014230865985155106, Neurons: 64, Grad norm: 3.256e-01\n",
      "Epoch 10688, Loss: 0.014225050806999207, Neurons: 64, Grad norm: 3.895e-01\n",
      "Epoch 10688, Loss: 0.014225050806999207, Neurons: 64, Grad norm: 3.895e-01\n",
      "Epoch 10689, Loss: 0.014219965785741806, Neurons: 64, Grad norm: 4.807e-01\n",
      "Epoch 10689, Loss: 0.014219965785741806, Neurons: 64, Grad norm: 4.807e-01\n",
      "Epoch 10690, Loss: 0.014215521514415741, Neurons: 64, Grad norm: 5.868e-01\n",
      "Epoch 10690, Loss: 0.014215521514415741, Neurons: 64, Grad norm: 5.868e-01\n",
      "Epoch 10691, Loss: 0.014212558977305889, Neurons: 64, Grad norm: 7.287e-01\n",
      "Epoch 10691, Loss: 0.014212558977305889, Neurons: 64, Grad norm: 7.287e-01\n",
      "Epoch 10692, Loss: 0.014211038127541542, Neurons: 64, Grad norm: 8.859e-01\n",
      "Epoch 10692, Loss: 0.014211038127541542, Neurons: 64, Grad norm: 8.859e-01\n",
      "Epoch 10693, Loss: 0.014211909845471382, Neurons: 64, Grad norm: 1.100e+00\n",
      "Epoch 10693, Loss: 0.014211909845471382, Neurons: 64, Grad norm: 1.100e+00\n",
      "Epoch 10694, Loss: 0.014215667732059956, Neurons: 64, Grad norm: 1.339e+00\n",
      "Epoch 10694, Loss: 0.014215667732059956, Neurons: 64, Grad norm: 1.339e+00\n",
      "Epoch 10695, Loss: 0.014223940670490265, Neurons: 64, Grad norm: 1.652e+00\n",
      "Epoch 10695, Loss: 0.014223940670490265, Neurons: 64, Grad norm: 1.652e+00\n",
      "Epoch 10696, Loss: 0.014238538220524788, Neurons: 64, Grad norm: 2.007e+00\n",
      "Epoch 10696, Loss: 0.014238538220524788, Neurons: 64, Grad norm: 2.007e+00\n",
      "Epoch 10697, Loss: 0.014263068325817585, Neurons: 64, Grad norm: 2.454e+00\n",
      "Epoch 10697, Loss: 0.014263068325817585, Neurons: 64, Grad norm: 2.454e+00\n",
      "Epoch 10698, Loss: 0.014299558475613594, Neurons: 64, Grad norm: 2.951e+00\n",
      "Epoch 10698, Loss: 0.014299558475613594, Neurons: 64, Grad norm: 2.951e+00\n",
      "Epoch 10699, Loss: 0.014353076927363873, Neurons: 64, Grad norm: 3.546e+00\n",
      "Epoch 10699, Loss: 0.014353076927363873, Neurons: 64, Grad norm: 3.546e+00\n",
      "Epoch 10699, Test loss: 0.010248961858451366\n",
      "Epoch 10699, Test loss: 0.010248961858451366\n",
      "Epoch 10700, Loss: 0.014424851164221764, Neurons: 64, Grad norm: 4.182e+00\n",
      "Epoch 10700, Loss: 0.014424851164221764, Neurons: 64, Grad norm: 4.182e+00\n",
      "Epoch 10701, Loss: 0.014517756178975105, Neurons: 64, Grad norm: 4.881e+00\n",
      "Epoch 10701, Loss: 0.014517756178975105, Neurons: 64, Grad norm: 4.881e+00\n",
      "Epoch 10702, Loss: 0.01462497841566801, Neurons: 64, Grad norm: 5.546e+00\n",
      "Epoch 10702, Loss: 0.01462497841566801, Neurons: 64, Grad norm: 5.546e+00\n",
      "Epoch 10703, Loss: 0.014736720360815525, Neurons: 64, Grad norm: 6.153e+00\n",
      "Epoch 10703, Loss: 0.014736720360815525, Neurons: 64, Grad norm: 6.153e+00\n",
      "Epoch 10704, Loss: 0.014827204868197441, Neurons: 64, Grad norm: 6.556e+00\n",
      "Epoch 10704, Loss: 0.014827204868197441, Neurons: 64, Grad norm: 6.556e+00\n",
      "Epoch 10705, Loss: 0.014872822910547256, Neurons: 64, Grad norm: 6.707e+00\n",
      "Epoch 10705, Loss: 0.014872822910547256, Neurons: 64, Grad norm: 6.707e+00\n",
      "Epoch 10706, Loss: 0.014845912344753742, Neurons: 64, Grad norm: 6.468e+00\n",
      "Epoch 10706, Loss: 0.014845912344753742, Neurons: 64, Grad norm: 6.468e+00\n",
      "Epoch 10707, Loss: 0.014745871536433697, Neurons: 64, Grad norm: 5.868e+00\n",
      "Epoch 10707, Loss: 0.014745871536433697, Neurons: 64, Grad norm: 5.868e+00\n",
      "Epoch 10708, Loss: 0.014593071304261684, Neurons: 64, Grad norm: 4.890e+00\n",
      "Epoch 10708, Loss: 0.014593071304261684, Neurons: 64, Grad norm: 4.890e+00\n",
      "Epoch 10709, Loss: 0.014429260976612568, Neurons: 64, Grad norm: 3.697e+00\n",
      "Epoch 10709, Loss: 0.014429260976612568, Neurons: 64, Grad norm: 3.697e+00\n",
      "Epoch 10710, Loss: 0.014292353764176369, Neurons: 64, Grad norm: 2.409e+00\n",
      "Epoch 10710, Loss: 0.014292353764176369, Neurons: 64, Grad norm: 2.409e+00\n",
      "Epoch 10711, Loss: 0.0142032690346241, Neurons: 64, Grad norm: 1.440e+00\n",
      "Epoch 10711, Loss: 0.0142032690346241, Neurons: 64, Grad norm: 1.440e+00\n",
      "Epoch 10712, Loss: 0.014160308055579662, Neurons: 64, Grad norm: 1.440e+00\n",
      "Epoch 10712, Loss: 0.014160308055579662, Neurons: 64, Grad norm: 1.440e+00\n",
      "Epoch 10713, Loss: 0.014148355461657047, Neurons: 64, Grad norm: 2.133e+00\n",
      "Epoch 10713, Loss: 0.014148355461657047, Neurons: 64, Grad norm: 2.133e+00\n",
      "Epoch 10714, Loss: 0.014151468873023987, Neurons: 64, Grad norm: 2.812e+00\n",
      "Epoch 10714, Loss: 0.014151468873023987, Neurons: 64, Grad norm: 2.812e+00\n",
      "Epoch 10715, Loss: 0.014160588383674622, Neurons: 64, Grad norm: 3.224e+00\n",
      "Epoch 10715, Loss: 0.014160588383674622, Neurons: 64, Grad norm: 3.224e+00\n",
      "Epoch 10716, Loss: 0.01417247299104929, Neurons: 64, Grad norm: 3.384e+00\n",
      "Epoch 10716, Loss: 0.01417247299104929, Neurons: 64, Grad norm: 3.384e+00\n",
      "Epoch 10717, Loss: 0.01418229378759861, Neurons: 64, Grad norm: 3.239e+00\n",
      "Epoch 10717, Loss: 0.01418229378759861, Neurons: 64, Grad norm: 3.239e+00\n",
      "Epoch 10718, Loss: 0.01418140809983015, Neurons: 64, Grad norm: 2.873e+00\n",
      "Epoch 10718, Loss: 0.01418140809983015, Neurons: 64, Grad norm: 2.873e+00\n",
      "Epoch 10719, Loss: 0.014160342514514923, Neurons: 64, Grad norm: 2.274e+00\n",
      "Epoch 10719, Loss: 0.014160342514514923, Neurons: 64, Grad norm: 2.274e+00\n",
      "Epoch 10720, Loss: 0.014117042534053326, Neurons: 64, Grad norm: 1.575e+00\n",
      "Epoch 10720, Loss: 0.014117042534053326, Neurons: 64, Grad norm: 1.575e+00\n",
      "Epoch 10721, Loss: 0.014061219058930874, Neurons: 64, Grad norm: 8.328e-01\n",
      "Epoch 10721, Loss: 0.014061219058930874, Neurons: 64, Grad norm: 8.328e-01\n",
      "Epoch 10722, Loss: 0.014008223079144955, Neurons: 64, Grad norm: 5.185e-01\n",
      "Epoch 10722, Loss: 0.014008223079144955, Neurons: 64, Grad norm: 5.185e-01\n",
      "Epoch 10723, Loss: 0.01397610828280449, Neurons: 64, Grad norm: 1.003e+00\n",
      "Epoch 10723, Loss: 0.01397610828280449, Neurons: 64, Grad norm: 1.003e+00\n",
      "Epoch 10724, Loss: 0.013971512205898762, Neurons: 64, Grad norm: 1.519e+00\n",
      "Epoch 10724, Loss: 0.013971512205898762, Neurons: 64, Grad norm: 1.519e+00\n",
      "Epoch 10725, Loss: 0.013988527469336987, Neurons: 64, Grad norm: 1.901e+00\n",
      "Epoch 10725, Loss: 0.013988527469336987, Neurons: 64, Grad norm: 1.901e+00\n",
      "Epoch 10726, Loss: 0.014011395163834095, Neurons: 64, Grad norm: 2.046e+00\n",
      "Epoch 10726, Loss: 0.014011395163834095, Neurons: 64, Grad norm: 2.046e+00\n",
      "Epoch 10727, Loss: 0.014023242518305779, Neurons: 64, Grad norm: 2.015e+00\n",
      "Epoch 10727, Loss: 0.014023242518305779, Neurons: 64, Grad norm: 2.015e+00\n",
      "Epoch 10728, Loss: 0.014015301130712032, Neurons: 64, Grad norm: 1.766e+00\n",
      "Epoch 10728, Loss: 0.014015301130712032, Neurons: 64, Grad norm: 1.766e+00\n",
      "Epoch 10729, Loss: 0.013988625258207321, Neurons: 64, Grad norm: 1.402e+00\n",
      "Epoch 10729, Loss: 0.013988625258207321, Neurons: 64, Grad norm: 1.402e+00\n",
      "Epoch 10730, Loss: 0.01395352277904749, Neurons: 64, Grad norm: 9.160e-01\n",
      "Epoch 10730, Loss: 0.01395352277904749, Neurons: 64, Grad norm: 9.160e-01\n",
      "Epoch 10731, Loss: 0.013922165147960186, Neurons: 64, Grad norm: 4.510e-01\n",
      "Epoch 10731, Loss: 0.013922165147960186, Neurons: 64, Grad norm: 4.510e-01\n",
      "Epoch 10732, Loss: 0.013903027400374413, Neurons: 64, Grad norm: 2.413e-01\n",
      "Epoch 10732, Loss: 0.013903027400374413, Neurons: 64, Grad norm: 2.413e-01\n",
      "Epoch 10733, Loss: 0.013896807096898556, Neurons: 64, Grad norm: 5.566e-01\n",
      "Epoch 10733, Loss: 0.013896807096898556, Neurons: 64, Grad norm: 5.566e-01\n",
      "Epoch 10734, Loss: 0.013898628763854504, Neurons: 64, Grad norm: 8.813e-01\n",
      "Epoch 10734, Loss: 0.013898628763854504, Neurons: 64, Grad norm: 8.813e-01\n",
      "Epoch 10735, Loss: 0.013901975937187672, Neurons: 64, Grad norm: 1.084e+00\n",
      "Epoch 10735, Loss: 0.013901975937187672, Neurons: 64, Grad norm: 1.084e+00\n",
      "Epoch 10736, Loss: 0.013901223428547382, Neurons: 64, Grad norm: 1.207e+00\n",
      "Epoch 10736, Loss: 0.013901223428547382, Neurons: 64, Grad norm: 1.207e+00\n",
      "Epoch 10737, Loss: 0.01389466505497694, Neurons: 64, Grad norm: 1.193e+00\n",
      "Epoch 10737, Loss: 0.01389466505497694, Neurons: 64, Grad norm: 1.193e+00\n",
      "Epoch 10738, Loss: 0.01388352271169424, Neurons: 64, Grad norm: 1.137e+00\n",
      "Epoch 10738, Loss: 0.01388352271169424, Neurons: 64, Grad norm: 1.137e+00\n",
      "Epoch 10739, Loss: 0.013870957307517529, Neurons: 64, Grad norm: 9.920e-01\n",
      "Epoch 10739, Loss: 0.013870957307517529, Neurons: 64, Grad norm: 9.920e-01\n",
      "Epoch 10740, Loss: 0.013859142549335957, Neurons: 64, Grad norm: 8.373e-01\n",
      "Epoch 10740, Loss: 0.013859142549335957, Neurons: 64, Grad norm: 8.373e-01\n",
      "Epoch 10741, Loss: 0.013848983682692051, Neurons: 64, Grad norm: 6.399e-01\n",
      "Epoch 10741, Loss: 0.013848983682692051, Neurons: 64, Grad norm: 6.399e-01\n",
      "Epoch 10742, Loss: 0.013840332627296448, Neurons: 64, Grad norm: 4.704e-01\n",
      "Epoch 10742, Loss: 0.013840332627296448, Neurons: 64, Grad norm: 4.704e-01\n",
      "Epoch 10743, Loss: 0.01383176539093256, Neurons: 64, Grad norm: 3.340e-01\n",
      "Epoch 10743, Loss: 0.01383176539093256, Neurons: 64, Grad norm: 3.340e-01\n",
      "Epoch 10744, Loss: 0.013823252171278, Neurons: 64, Grad norm: 2.964e-01\n",
      "Epoch 10744, Loss: 0.013823252171278, Neurons: 64, Grad norm: 2.964e-01\n",
      "Epoch 10745, Loss: 0.01381454337388277, Neurons: 64, Grad norm: 3.893e-01\n",
      "Epoch 10745, Loss: 0.01381454337388277, Neurons: 64, Grad norm: 3.893e-01\n",
      "Epoch 10746, Loss: 0.01380630861967802, Neurons: 64, Grad norm: 4.897e-01\n",
      "Epoch 10746, Loss: 0.01380630861967802, Neurons: 64, Grad norm: 4.897e-01\n",
      "Epoch 10747, Loss: 0.01379945408552885, Neurons: 64, Grad norm: 6.054e-01\n",
      "Epoch 10747, Loss: 0.01379945408552885, Neurons: 64, Grad norm: 6.054e-01\n",
      "Epoch 10748, Loss: 0.013793879188597202, Neurons: 64, Grad norm: 6.619e-01\n",
      "Epoch 10748, Loss: 0.013793879188597202, Neurons: 64, Grad norm: 6.619e-01\n",
      "Epoch 10749, Loss: 0.013788875192403793, Neurons: 64, Grad norm: 7.075e-01\n",
      "Epoch 10749, Loss: 0.013788875192403793, Neurons: 64, Grad norm: 7.075e-01\n",
      "Epoch 10750, Loss: 0.01378367654979229, Neurons: 64, Grad norm: 6.835e-01\n",
      "Epoch 10750, Loss: 0.01378367654979229, Neurons: 64, Grad norm: 6.835e-01\n",
      "Epoch 10751, Loss: 0.013777094893157482, Neurons: 64, Grad norm: 6.444e-01\n",
      "Epoch 10751, Loss: 0.013777094893157482, Neurons: 64, Grad norm: 6.444e-01\n",
      "Epoch 10752, Loss: 0.01376932580024004, Neurons: 64, Grad norm: 5.447e-01\n",
      "Epoch 10752, Loss: 0.01376932580024004, Neurons: 64, Grad norm: 5.447e-01\n",
      "Epoch 10753, Loss: 0.013760363683104515, Neurons: 64, Grad norm: 4.521e-01\n",
      "Epoch 10753, Loss: 0.013760363683104515, Neurons: 64, Grad norm: 4.521e-01\n",
      "Epoch 10754, Loss: 0.013751184567809105, Neurons: 64, Grad norm: 3.201e-01\n",
      "Epoch 10754, Loss: 0.013751184567809105, Neurons: 64, Grad norm: 3.201e-01\n",
      "Epoch 10755, Loss: 0.01374222245067358, Neurons: 64, Grad norm: 2.066e-01\n",
      "Epoch 10755, Loss: 0.01374222245067358, Neurons: 64, Grad norm: 2.066e-01\n",
      "Epoch 10756, Loss: 0.013733921572566032, Neurons: 64, Grad norm: 7.899e-02\n",
      "Epoch 10756, Loss: 0.013733921572566032, Neurons: 64, Grad norm: 7.899e-02\n",
      "Epoch 10757, Loss: 0.0137265520170331, Neurons: 64, Grad norm: 6.661e-02\n",
      "Epoch 10757, Loss: 0.0137265520170331, Neurons: 64, Grad norm: 6.661e-02\n",
      "Epoch 10758, Loss: 0.013719804584980011, Neurons: 64, Grad norm: 1.464e-01\n",
      "Epoch 10758, Loss: 0.013719804584980011, Neurons: 64, Grad norm: 1.464e-01\n",
      "Epoch 10759, Loss: 0.013713437132537365, Neurons: 64, Grad norm: 2.073e-01\n",
      "Epoch 10759, Loss: 0.013713437132537365, Neurons: 64, Grad norm: 2.073e-01\n",
      "Epoch 10760, Loss: 0.013707131147384644, Neurons: 64, Grad norm: 2.773e-01\n",
      "Epoch 10760, Loss: 0.013707131147384644, Neurons: 64, Grad norm: 2.773e-01\n",
      "Epoch 10761, Loss: 0.01370068360120058, Neurons: 64, Grad norm: 3.038e-01\n",
      "Epoch 10761, Loss: 0.01370068360120058, Neurons: 64, Grad norm: 3.038e-01\n",
      "Epoch 10762, Loss: 0.013694132678210735, Neurons: 64, Grad norm: 3.407e-01\n",
      "Epoch 10762, Loss: 0.013694132678210735, Neurons: 64, Grad norm: 3.407e-01\n",
      "Epoch 10763, Loss: 0.013687420636415482, Neurons: 64, Grad norm: 3.389e-01\n",
      "Epoch 10763, Loss: 0.013687420636415482, Neurons: 64, Grad norm: 3.389e-01\n",
      "Epoch 10764, Loss: 0.013680495321750641, Neurons: 64, Grad norm: 3.528e-01\n",
      "Epoch 10764, Loss: 0.013680495321750641, Neurons: 64, Grad norm: 3.528e-01\n",
      "Epoch 10765, Loss: 0.013673502951860428, Neurons: 64, Grad norm: 3.304e-01\n",
      "Epoch 10765, Loss: 0.013673502951860428, Neurons: 64, Grad norm: 3.304e-01\n",
      "Epoch 10766, Loss: 0.013666580431163311, Neurons: 64, Grad norm: 3.341e-01\n",
      "Epoch 10766, Loss: 0.013666580431163311, Neurons: 64, Grad norm: 3.341e-01\n",
      "Epoch 10767, Loss: 0.013659665361046791, Neurons: 64, Grad norm: 3.052e-01\n",
      "Epoch 10767, Loss: 0.013659665361046791, Neurons: 64, Grad norm: 3.052e-01\n",
      "Epoch 10768, Loss: 0.013652767986059189, Neurons: 64, Grad norm: 3.004e-01\n",
      "Epoch 10768, Loss: 0.013652767986059189, Neurons: 64, Grad norm: 3.004e-01\n",
      "Epoch 10769, Loss: 0.013645912520587444, Neurons: 64, Grad norm: 2.627e-01\n",
      "Epoch 10769, Loss: 0.013645912520587444, Neurons: 64, Grad norm: 2.627e-01\n",
      "Epoch 10770, Loss: 0.01363897044211626, Neurons: 64, Grad norm: 2.582e-01\n",
      "Epoch 10770, Loss: 0.01363897044211626, Neurons: 64, Grad norm: 2.582e-01\n",
      "Epoch 10771, Loss: 0.013632075861096382, Neurons: 64, Grad norm: 2.179e-01\n",
      "Epoch 10771, Loss: 0.013632075861096382, Neurons: 64, Grad norm: 2.179e-01\n",
      "Epoch 10772, Loss: 0.013625060208141804, Neurons: 64, Grad norm: 2.070e-01\n",
      "Epoch 10772, Loss: 0.013625060208141804, Neurons: 64, Grad norm: 2.070e-01\n",
      "Epoch 10773, Loss: 0.01361803524196148, Neurons: 64, Grad norm: 1.661e-01\n",
      "Epoch 10773, Loss: 0.01361803524196148, Neurons: 64, Grad norm: 1.661e-01\n",
      "Epoch 10774, Loss: 0.013611099682748318, Neurons: 64, Grad norm: 1.573e-01\n",
      "Epoch 10774, Loss: 0.013611099682748318, Neurons: 64, Grad norm: 1.573e-01\n",
      "Epoch 10775, Loss: 0.013604089617729187, Neurons: 64, Grad norm: 1.223e-01\n",
      "Epoch 10775, Loss: 0.013604089617729187, Neurons: 64, Grad norm: 1.223e-01\n",
      "Epoch 10776, Loss: 0.013597269542515278, Neurons: 64, Grad norm: 1.225e-01\n",
      "Epoch 10776, Loss: 0.013597269542515278, Neurons: 64, Grad norm: 1.225e-01\n",
      "Epoch 10777, Loss: 0.013590455986559391, Neurons: 64, Grad norm: 9.384e-02\n",
      "Epoch 10777, Loss: 0.013590455986559391, Neurons: 64, Grad norm: 9.384e-02\n",
      "Epoch 10778, Loss: 0.013583697378635406, Neurons: 64, Grad norm: 9.421e-02\n",
      "Epoch 10778, Loss: 0.013583697378635406, Neurons: 64, Grad norm: 9.421e-02\n",
      "Epoch 10779, Loss: 0.013577005825936794, Neurons: 64, Grad norm: 7.679e-02\n",
      "Epoch 10779, Loss: 0.013577005825936794, Neurons: 64, Grad norm: 7.679e-02\n",
      "Epoch 10780, Loss: 0.013570277951657772, Neurons: 64, Grad norm: 7.678e-02\n",
      "Epoch 10780, Loss: 0.013570277951657772, Neurons: 64, Grad norm: 7.678e-02\n",
      "Epoch 10781, Loss: 0.013563570566475391, Neurons: 64, Grad norm: 6.172e-02\n",
      "Epoch 10781, Loss: 0.013563570566475391, Neurons: 64, Grad norm: 6.172e-02\n",
      "Epoch 10782, Loss: 0.01355679053813219, Neurons: 64, Grad norm: 5.897e-02\n",
      "Epoch 10782, Loss: 0.01355679053813219, Neurons: 64, Grad norm: 5.897e-02\n",
      "Epoch 10783, Loss: 0.013550138100981712, Neurons: 64, Grad norm: 4.831e-02\n",
      "Epoch 10783, Loss: 0.013550138100981712, Neurons: 64, Grad norm: 4.831e-02\n",
      "Epoch 10784, Loss: 0.013543295674026012, Neurons: 64, Grad norm: 4.170e-02\n",
      "Epoch 10784, Loss: 0.013543295674026012, Neurons: 64, Grad norm: 4.170e-02\n",
      "Epoch 10785, Loss: 0.013536587357521057, Neurons: 64, Grad norm: 2.817e-02\n",
      "Epoch 10785, Loss: 0.013536587357521057, Neurons: 64, Grad norm: 2.817e-02\n",
      "Epoch 10786, Loss: 0.013529798947274685, Neurons: 64, Grad norm: 1.797e-02\n",
      "Epoch 10786, Loss: 0.013529798947274685, Neurons: 64, Grad norm: 1.797e-02\n",
      "Epoch 10787, Loss: 0.013523075729608536, Neurons: 64, Grad norm: 2.901e-02\n",
      "Epoch 10787, Loss: 0.013523075729608536, Neurons: 64, Grad norm: 2.901e-02\n",
      "Epoch 10788, Loss: 0.01351640373468399, Neurons: 64, Grad norm: 3.124e-02\n",
      "Epoch 10788, Loss: 0.01351640373468399, Neurons: 64, Grad norm: 3.124e-02\n",
      "Epoch 10789, Loss: 0.013509790413081646, Neurons: 64, Grad norm: 5.296e-02\n",
      "Epoch 10789, Loss: 0.013509790413081646, Neurons: 64, Grad norm: 5.296e-02\n",
      "Epoch 10790, Loss: 0.013503125868737698, Neurons: 64, Grad norm: 5.727e-02\n",
      "Epoch 10790, Loss: 0.013503125868737698, Neurons: 64, Grad norm: 5.727e-02\n",
      "Epoch 10791, Loss: 0.013496536761522293, Neurons: 64, Grad norm: 7.615e-02\n",
      "Epoch 10791, Loss: 0.013496536761522293, Neurons: 64, Grad norm: 7.615e-02\n",
      "Epoch 10792, Loss: 0.013489942066371441, Neurons: 64, Grad norm: 8.496e-02\n",
      "Epoch 10792, Loss: 0.013489942066371441, Neurons: 64, Grad norm: 8.496e-02\n",
      "Epoch 10793, Loss: 0.013483453541994095, Neurons: 64, Grad norm: 1.079e-01\n",
      "Epoch 10793, Loss: 0.013483453541994095, Neurons: 64, Grad norm: 1.079e-01\n",
      "Epoch 10794, Loss: 0.013476796448230743, Neurons: 64, Grad norm: 1.061e-01\n",
      "Epoch 10794, Loss: 0.013476796448230743, Neurons: 64, Grad norm: 1.061e-01\n",
      "Epoch 10795, Loss: 0.013470252975821495, Neurons: 64, Grad norm: 1.152e-01\n",
      "Epoch 10795, Loss: 0.013470252975821495, Neurons: 64, Grad norm: 1.152e-01\n",
      "Epoch 10796, Loss: 0.013463583774864674, Neurons: 64, Grad norm: 1.127e-01\n",
      "Epoch 10796, Loss: 0.013463583774864674, Neurons: 64, Grad norm: 1.127e-01\n",
      "Epoch 10797, Loss: 0.013456924818456173, Neurons: 64, Grad norm: 1.327e-01\n",
      "Epoch 10797, Loss: 0.013456924818456173, Neurons: 64, Grad norm: 1.327e-01\n",
      "Epoch 10798, Loss: 0.01345022115856409, Neurons: 64, Grad norm: 1.304e-01\n",
      "Epoch 10798, Loss: 0.01345022115856409, Neurons: 64, Grad norm: 1.304e-01\n",
      "Epoch 10799, Loss: 0.013443672098219395, Neurons: 64, Grad norm: 1.526e-01\n",
      "Epoch 10799, Loss: 0.013443672098219395, Neurons: 64, Grad norm: 1.526e-01\n",
      "Epoch 10799, Test loss: 0.009352692402899265\n",
      "Epoch 10799, Test loss: 0.009352692402899265\n",
      "Epoch 10800, Loss: 0.013437032699584961, Neurons: 64, Grad norm: 1.584e-01\n",
      "Epoch 10800, Loss: 0.013437032699584961, Neurons: 64, Grad norm: 1.584e-01\n",
      "Epoch 10801, Loss: 0.01343047060072422, Neurons: 64, Grad norm: 1.983e-01\n",
      "Epoch 10801, Loss: 0.01343047060072422, Neurons: 64, Grad norm: 1.983e-01\n",
      "Epoch 10802, Loss: 0.013423971831798553, Neurons: 64, Grad norm: 2.157e-01\n",
      "Epoch 10802, Loss: 0.013423971831798553, Neurons: 64, Grad norm: 2.157e-01\n",
      "Epoch 10803, Loss: 0.013417568989098072, Neurons: 64, Grad norm: 2.657e-01\n",
      "Epoch 10803, Loss: 0.013417568989098072, Neurons: 64, Grad norm: 2.657e-01\n",
      "Epoch 10804, Loss: 0.013411203399300575, Neurons: 64, Grad norm: 3.054e-01\n",
      "Epoch 10804, Loss: 0.013411203399300575, Neurons: 64, Grad norm: 3.054e-01\n",
      "Epoch 10805, Loss: 0.013405120000243187, Neurons: 64, Grad norm: 3.851e-01\n",
      "Epoch 10805, Loss: 0.013405120000243187, Neurons: 64, Grad norm: 3.851e-01\n",
      "Epoch 10806, Loss: 0.013399201445281506, Neurons: 64, Grad norm: 4.464e-01\n",
      "Epoch 10806, Loss: 0.013399201445281506, Neurons: 64, Grad norm: 4.464e-01\n",
      "Epoch 10807, Loss: 0.013393531553447247, Neurons: 64, Grad norm: 5.596e-01\n",
      "Epoch 10807, Loss: 0.013393531553447247, Neurons: 64, Grad norm: 5.596e-01\n",
      "Epoch 10808, Loss: 0.013388409279286861, Neurons: 64, Grad norm: 6.616e-01\n",
      "Epoch 10808, Loss: 0.013388409279286861, Neurons: 64, Grad norm: 6.616e-01\n",
      "Epoch 10809, Loss: 0.013384041376411915, Neurons: 64, Grad norm: 8.202e-01\n",
      "Epoch 10809, Loss: 0.013384041376411915, Neurons: 64, Grad norm: 8.202e-01\n",
      "Epoch 10810, Loss: 0.013380642980337143, Neurons: 64, Grad norm: 9.943e-01\n",
      "Epoch 10810, Loss: 0.013380642980337143, Neurons: 64, Grad norm: 9.943e-01\n",
      "Epoch 10811, Loss: 0.01337914913892746, Neurons: 64, Grad norm: 1.244e+00\n",
      "Epoch 10811, Loss: 0.01337914913892746, Neurons: 64, Grad norm: 1.244e+00\n",
      "Epoch 10812, Loss: 0.013380434364080429, Neurons: 64, Grad norm: 1.518e+00\n",
      "Epoch 10812, Loss: 0.013380434364080429, Neurons: 64, Grad norm: 1.518e+00\n",
      "Epoch 10813, Loss: 0.013386116363108158, Neurons: 64, Grad norm: 1.899e+00\n",
      "Epoch 10813, Loss: 0.013386116363108158, Neurons: 64, Grad norm: 1.899e+00\n",
      "Epoch 10814, Loss: 0.013398476876318455, Neurons: 64, Grad norm: 2.348e+00\n",
      "Epoch 10814, Loss: 0.013398476876318455, Neurons: 64, Grad norm: 2.348e+00\n",
      "Epoch 10815, Loss: 0.013421374373137951, Neurons: 64, Grad norm: 2.940e+00\n",
      "Epoch 10815, Loss: 0.013421374373137951, Neurons: 64, Grad norm: 2.940e+00\n",
      "Epoch 10816, Loss: 0.013460617512464523, Neurons: 64, Grad norm: 3.638e+00\n",
      "Epoch 10816, Loss: 0.013460617512464523, Neurons: 64, Grad norm: 3.638e+00\n",
      "Epoch 10817, Loss: 0.013525344431400299, Neurons: 64, Grad norm: 4.538e+00\n",
      "Epoch 10817, Loss: 0.013525344431400299, Neurons: 64, Grad norm: 4.538e+00\n",
      "Epoch 10818, Loss: 0.01362807210534811, Neurons: 64, Grad norm: 5.603e+00\n",
      "Epoch 10818, Loss: 0.01362807210534811, Neurons: 64, Grad norm: 5.603e+00\n",
      "Epoch 10819, Loss: 0.013785998336970806, Neurons: 64, Grad norm: 6.874e+00\n",
      "Epoch 10819, Loss: 0.013785998336970806, Neurons: 64, Grad norm: 6.874e+00\n",
      "Epoch 10820, Loss: 0.014015774242579937, Neurons: 64, Grad norm: 8.242e+00\n",
      "Epoch 10820, Loss: 0.014015774242579937, Neurons: 64, Grad norm: 8.242e+00\n",
      "Epoch 10821, Loss: 0.014326906763017178, Neurons: 64, Grad norm: 9.640e+00\n",
      "Epoch 10821, Loss: 0.014326906763017178, Neurons: 64, Grad norm: 9.640e+00\n",
      "Epoch 10822, Loss: 0.014694267883896828, Neurons: 64, Grad norm: 1.074e+01\n",
      "Epoch 10822, Loss: 0.014694267883896828, Neurons: 64, Grad norm: 1.074e+01\n",
      "Epoch 10823, Loss: 0.015034805983304977, Neurons: 64, Grad norm: 1.121e+01\n",
      "Epoch 10823, Loss: 0.015034805983304977, Neurons: 64, Grad norm: 1.121e+01\n",
      "Epoch 10824, Loss: 0.01518204715102911, Neurons: 64, Grad norm: 1.057e+01\n",
      "Epoch 10824, Loss: 0.01518204715102911, Neurons: 64, Grad norm: 1.057e+01\n",
      "Epoch 10825, Loss: 0.014974946156144142, Neurons: 64, Grad norm: 8.638e+00\n",
      "Epoch 10825, Loss: 0.014974946156144142, Neurons: 64, Grad norm: 8.638e+00\n",
      "Epoch 10826, Loss: 0.014401956461369991, Neurons: 64, Grad norm: 5.483e+00\n",
      "Epoch 10826, Loss: 0.014401956461369991, Neurons: 64, Grad norm: 5.483e+00\n",
      "Epoch 10827, Loss: 0.013723562471568584, Neurons: 64, Grad norm: 1.714e+00\n",
      "Epoch 10827, Loss: 0.013723562471568584, Neurons: 64, Grad norm: 1.714e+00\n",
      "Epoch 10828, Loss: 0.013302774168550968, Neurons: 64, Grad norm: 2.068e+00\n",
      "Epoch 10828, Loss: 0.013302774168550968, Neurons: 64, Grad norm: 2.068e+00\n",
      "Epoch 10829, Loss: 0.013314777985215187, Neurons: 64, Grad norm: 5.029e+00\n",
      "Epoch 10829, Loss: 0.013314777985215187, Neurons: 64, Grad norm: 5.029e+00\n",
      "Epoch 10830, Loss: 0.013627073727548122, Neurons: 64, Grad norm: 6.795e+00\n",
      "Epoch 10830, Loss: 0.013627073727548122, Neurons: 64, Grad norm: 6.795e+00\n",
      "Epoch 10831, Loss: 0.013933150097727776, Neurons: 64, Grad norm: 7.028e+00\n",
      "Epoch 10831, Loss: 0.013933150097727776, Neurons: 64, Grad norm: 7.028e+00\n",
      "Epoch 10832, Loss: 0.013979922980070114, Neurons: 64, Grad norm: 5.800e+00\n",
      "Epoch 10832, Loss: 0.013979922980070114, Neurons: 64, Grad norm: 5.800e+00\n",
      "Epoch 10833, Loss: 0.013732431456446648, Neurons: 64, Grad norm: 3.401e+00\n",
      "Epoch 10833, Loss: 0.013732431456446648, Neurons: 64, Grad norm: 3.401e+00\n",
      "Epoch 10834, Loss: 0.013393621891736984, Neurons: 64, Grad norm: 5.238e-01\n",
      "Epoch 10834, Loss: 0.013393621891736984, Neurons: 64, Grad norm: 5.238e-01\n",
      "Epoch 10835, Loss: 0.01321555394679308, Neurons: 64, Grad norm: 2.265e+00\n",
      "Epoch 10835, Loss: 0.01321555394679308, Neurons: 64, Grad norm: 2.265e+00\n",
      "Epoch 10836, Loss: 0.01328273955732584, Neurons: 64, Grad norm: 4.206e+00\n",
      "Epoch 10836, Loss: 0.01328273955732584, Neurons: 64, Grad norm: 4.206e+00\n",
      "Epoch 10837, Loss: 0.013468441553413868, Neurons: 64, Grad norm: 5.027e+00\n",
      "Epoch 10837, Loss: 0.013468441553413868, Neurons: 64, Grad norm: 5.027e+00\n",
      "Epoch 10838, Loss: 0.013574591837823391, Neurons: 64, Grad norm: 4.571e+00\n",
      "Epoch 10838, Loss: 0.013574591837823391, Neurons: 64, Grad norm: 4.571e+00\n",
      "Epoch 10839, Loss: 0.01350417360663414, Neurons: 64, Grad norm: 3.110e+00\n",
      "Epoch 10839, Loss: 0.01350417360663414, Neurons: 64, Grad norm: 3.110e+00\n",
      "Epoch 10840, Loss: 0.013325054198503494, Neurons: 64, Grad norm: 1.024e+00\n",
      "Epoch 10840, Loss: 0.013325054198503494, Neurons: 64, Grad norm: 1.024e+00\n",
      "Epoch 10841, Loss: 0.01318878773599863, Neurons: 64, Grad norm: 1.072e+00\n",
      "Epoch 10841, Loss: 0.01318878773599863, Neurons: 64, Grad norm: 1.072e+00\n",
      "Epoch 10842, Loss: 0.013184075243771076, Neurons: 64, Grad norm: 2.731e+00\n",
      "Epoch 10842, Loss: 0.013184075243771076, Neurons: 64, Grad norm: 2.731e+00\n",
      "Epoch 10843, Loss: 0.013272933661937714, Neurons: 64, Grad norm: 3.547e+00\n",
      "Epoch 10843, Loss: 0.013272933661937714, Neurons: 64, Grad norm: 3.547e+00\n",
      "Epoch 10844, Loss: 0.013346103951334953, Neurons: 64, Grad norm: 3.458e+00\n",
      "Epoch 10844, Loss: 0.013346103951334953, Neurons: 64, Grad norm: 3.458e+00\n",
      "Epoch 10845, Loss: 0.013328781351447105, Neurons: 64, Grad norm: 2.515e+00\n",
      "Epoch 10845, Loss: 0.013328781351447105, Neurons: 64, Grad norm: 2.515e+00\n",
      "Epoch 10846, Loss: 0.013238634914159775, Neurons: 64, Grad norm: 1.085e+00\n",
      "Epoch 10846, Loss: 0.013238634914159775, Neurons: 64, Grad norm: 1.085e+00\n",
      "Epoch 10847, Loss: 0.013153250329196453, Neurons: 64, Grad norm: 4.959e-01\n",
      "Epoch 10847, Loss: 0.013153250329196453, Neurons: 64, Grad norm: 4.959e-01\n",
      "Epoch 10848, Loss: 0.013132870197296143, Neurons: 64, Grad norm: 1.768e+00\n",
      "Epoch 10848, Loss: 0.013132870197296143, Neurons: 64, Grad norm: 1.768e+00\n",
      "Epoch 10849, Loss: 0.013170945458114147, Neurons: 64, Grad norm: 2.523e+00\n",
      "Epoch 10849, Loss: 0.013170945458114147, Neurons: 64, Grad norm: 2.523e+00\n",
      "Epoch 10850, Loss: 0.013212704099714756, Neurons: 64, Grad norm: 2.571e+00\n",
      "Epoch 10850, Loss: 0.013212704099714756, Neurons: 64, Grad norm: 2.571e+00\n",
      "Epoch 10851, Loss: 0.013211567886173725, Neurons: 64, Grad norm: 2.027e+00\n",
      "Epoch 10851, Loss: 0.013211567886173725, Neurons: 64, Grad norm: 2.027e+00\n",
      "Epoch 10852, Loss: 0.013166559860110283, Neurons: 64, Grad norm: 1.030e+00\n",
      "Epoch 10852, Loss: 0.013166559860110283, Neurons: 64, Grad norm: 1.030e+00\n",
      "Epoch 10853, Loss: 0.013114861212670803, Neurons: 64, Grad norm: 1.030e-01\n",
      "Epoch 10853, Loss: 0.013114861212670803, Neurons: 64, Grad norm: 1.030e-01\n",
      "Epoch 10854, Loss: 0.013092514127492905, Neurons: 64, Grad norm: 1.098e+00\n",
      "Epoch 10854, Loss: 0.013092514127492905, Neurons: 64, Grad norm: 1.098e+00\n",
      "Epoch 10855, Loss: 0.013104219920933247, Neurons: 64, Grad norm: 1.725e+00\n",
      "Epoch 10855, Loss: 0.013104219920933247, Neurons: 64, Grad norm: 1.725e+00\n",
      "Epoch 10856, Loss: 0.01312557514756918, Neurons: 64, Grad norm: 1.916e+00\n",
      "Epoch 10856, Loss: 0.01312557514756918, Neurons: 64, Grad norm: 1.916e+00\n",
      "Epoch 10857, Loss: 0.013129163533449173, Neurons: 64, Grad norm: 1.619e+00\n",
      "Epoch 10857, Loss: 0.013129163533449173, Neurons: 64, Grad norm: 1.619e+00\n",
      "Epoch 10858, Loss: 0.013107857666909695, Neurons: 64, Grad norm: 1.006e+00\n",
      "Epoch 10858, Loss: 0.013107857666909695, Neurons: 64, Grad norm: 1.006e+00\n",
      "Epoch 10859, Loss: 0.0130766611546278, Neurons: 64, Grad norm: 1.995e-01\n",
      "Epoch 10859, Loss: 0.0130766611546278, Neurons: 64, Grad norm: 1.995e-01\n",
      "Epoch 10860, Loss: 0.013055922463536263, Neurons: 64, Grad norm: 5.493e-01\n",
      "Epoch 10860, Loss: 0.013055922463536263, Neurons: 64, Grad norm: 5.493e-01\n",
      "Epoch 10861, Loss: 0.013053886592388153, Neurons: 64, Grad norm: 1.127e+00\n",
      "Epoch 10861, Loss: 0.013053886592388153, Neurons: 64, Grad norm: 1.127e+00\n",
      "Epoch 10862, Loss: 0.013061970472335815, Neurons: 64, Grad norm: 1.365e+00\n",
      "Epoch 10862, Loss: 0.013061970472335815, Neurons: 64, Grad norm: 1.365e+00\n",
      "Epoch 10863, Loss: 0.013065449893474579, Neurons: 64, Grad norm: 1.298e+00\n",
      "Epoch 10863, Loss: 0.013065449893474579, Neurons: 64, Grad norm: 1.298e+00\n",
      "Epoch 10864, Loss: 0.013056023046374321, Neurons: 64, Grad norm: 9.242e-01\n",
      "Epoch 10864, Loss: 0.013056023046374321, Neurons: 64, Grad norm: 9.242e-01\n",
      "Epoch 10865, Loss: 0.013037829659879208, Neurons: 64, Grad norm: 4.098e-01\n",
      "Epoch 10865, Loss: 0.013037829659879208, Neurons: 64, Grad norm: 4.098e-01\n",
      "Epoch 10866, Loss: 0.013021006248891354, Neurons: 64, Grad norm: 1.696e-01\n",
      "Epoch 10866, Loss: 0.013021006248891354, Neurons: 64, Grad norm: 1.696e-01\n",
      "Epoch 10867, Loss: 0.013012905605137348, Neurons: 64, Grad norm: 6.271e-01\n",
      "Epoch 10867, Loss: 0.013012905605137348, Neurons: 64, Grad norm: 6.271e-01\n",
      "Epoch 10868, Loss: 0.013012531213462353, Neurons: 64, Grad norm: 9.328e-01\n",
      "Epoch 10868, Loss: 0.013012531213462353, Neurons: 64, Grad norm: 9.328e-01\n",
      "Epoch 10869, Loss: 0.013013237155973911, Neurons: 64, Grad norm: 9.758e-01\n",
      "Epoch 10869, Loss: 0.013013237155973911, Neurons: 64, Grad norm: 9.758e-01\n",
      "Epoch 10870, Loss: 0.013009021058678627, Neurons: 64, Grad norm: 8.395e-01\n",
      "Epoch 10870, Loss: 0.013009021058678627, Neurons: 64, Grad norm: 8.395e-01\n",
      "Epoch 10871, Loss: 0.012998655438423157, Neurons: 64, Grad norm: 5.137e-01\n",
      "Epoch 10871, Loss: 0.012998655438423157, Neurons: 64, Grad norm: 5.137e-01\n",
      "Epoch 10872, Loss: 0.012986088171601295, Neurons: 64, Grad norm: 1.396e-01\n",
      "Epoch 10872, Loss: 0.012986088171601295, Neurons: 64, Grad norm: 1.396e-01\n",
      "Epoch 10873, Loss: 0.01297624222934246, Neurons: 64, Grad norm: 2.555e-01\n",
      "Epoch 10873, Loss: 0.01297624222934246, Neurons: 64, Grad norm: 2.555e-01\n",
      "Epoch 10874, Loss: 0.012970831245183945, Neurons: 64, Grad norm: 5.269e-01\n",
      "Epoch 10874, Loss: 0.012970831245183945, Neurons: 64, Grad norm: 5.269e-01\n",
      "Epoch 10875, Loss: 0.012968172319233418, Neurons: 64, Grad norm: 6.916e-01\n",
      "Epoch 10875, Loss: 0.012968172319233418, Neurons: 64, Grad norm: 6.916e-01\n",
      "Epoch 10876, Loss: 0.012964872643351555, Neurons: 64, Grad norm: 6.736e-01\n",
      "Epoch 10876, Loss: 0.012964872643351555, Neurons: 64, Grad norm: 6.736e-01\n",
      "Epoch 10877, Loss: 0.012958822771906853, Neurons: 64, Grad norm: 5.521e-01\n",
      "Epoch 10877, Loss: 0.012958822771906853, Neurons: 64, Grad norm: 5.521e-01\n",
      "Epoch 10878, Loss: 0.012950154021382332, Neurons: 64, Grad norm: 3.058e-01\n",
      "Epoch 10878, Loss: 0.012950154021382332, Neurons: 64, Grad norm: 3.058e-01\n",
      "Epoch 10879, Loss: 0.012941107153892517, Neurons: 64, Grad norm: 6.041e-02\n",
      "Epoch 10879, Loss: 0.012941107153892517, Neurons: 64, Grad norm: 6.041e-02\n",
      "Epoch 10880, Loss: 0.012933628633618355, Neurons: 64, Grad norm: 2.194e-01\n",
      "Epoch 10880, Loss: 0.012933628633618355, Neurons: 64, Grad norm: 2.194e-01\n",
      "Epoch 10881, Loss: 0.012928228825330734, Neurons: 64, Grad norm: 3.861e-01\n",
      "Epoch 10881, Loss: 0.012928228825330734, Neurons: 64, Grad norm: 3.861e-01\n",
      "Epoch 10882, Loss: 0.012923882342875004, Neurons: 64, Grad norm: 4.911e-01\n",
      "Epoch 10882, Loss: 0.012923882342875004, Neurons: 64, Grad norm: 4.911e-01\n",
      "Epoch 10883, Loss: 0.012919007800519466, Neurons: 64, Grad norm: 4.683e-01\n",
      "Epoch 10883, Loss: 0.012919007800519466, Neurons: 64, Grad norm: 4.683e-01\n",
      "Epoch 10884, Loss: 0.012912902049720287, Neurons: 64, Grad norm: 3.853e-01\n",
      "Epoch 10884, Loss: 0.012912902049720287, Neurons: 64, Grad norm: 3.853e-01\n",
      "Epoch 10885, Loss: 0.012905617244541645, Neurons: 64, Grad norm: 2.146e-01\n",
      "Epoch 10885, Loss: 0.012905617244541645, Neurons: 64, Grad norm: 2.146e-01\n",
      "Epoch 10886, Loss: 0.012898175977170467, Neurons: 64, Grad norm: 5.229e-02\n",
      "Epoch 10886, Loss: 0.012898175977170467, Neurons: 64, Grad norm: 5.229e-02\n",
      "Epoch 10887, Loss: 0.012891463004052639, Neurons: 64, Grad norm: 1.407e-01\n",
      "Epoch 10887, Loss: 0.012891463004052639, Neurons: 64, Grad norm: 1.407e-01\n",
      "Epoch 10888, Loss: 0.012885712087154388, Neurons: 64, Grad norm: 2.501e-01\n",
      "Epoch 10888, Loss: 0.012885712087154388, Neurons: 64, Grad norm: 2.501e-01\n",
      "Epoch 10889, Loss: 0.01288040354847908, Neurons: 64, Grad norm: 3.369e-01\n",
      "Epoch 10889, Loss: 0.01288040354847908, Neurons: 64, Grad norm: 3.369e-01\n",
      "Epoch 10890, Loss: 0.012875082902610302, Neurons: 64, Grad norm: 3.301e-01\n",
      "Epoch 10890, Loss: 0.012875082902610302, Neurons: 64, Grad norm: 3.301e-01\n",
      "Epoch 10891, Loss: 0.012869171798229218, Neurons: 64, Grad norm: 2.916e-01\n",
      "Epoch 10891, Loss: 0.012869171798229218, Neurons: 64, Grad norm: 2.916e-01\n",
      "Epoch 10892, Loss: 0.012862698175013065, Neurons: 64, Grad norm: 1.820e-01\n",
      "Epoch 10892, Loss: 0.012862698175013065, Neurons: 64, Grad norm: 1.820e-01\n",
      "Epoch 10893, Loss: 0.012856035493314266, Neurons: 64, Grad norm: 8.158e-02\n",
      "Epoch 10893, Loss: 0.012856035493314266, Neurons: 64, Grad norm: 8.158e-02\n",
      "Epoch 10894, Loss: 0.0128496577963233, Neurons: 64, Grad norm: 5.919e-02\n",
      "Epoch 10894, Loss: 0.0128496577963233, Neurons: 64, Grad norm: 5.919e-02\n",
      "Epoch 10895, Loss: 0.012843596749007702, Neurons: 64, Grad norm: 1.386e-01\n",
      "Epoch 10895, Loss: 0.012843596749007702, Neurons: 64, Grad norm: 1.386e-01\n",
      "Epoch 10896, Loss: 0.012837939895689487, Neurons: 64, Grad norm: 2.199e-01\n",
      "Epoch 10896, Loss: 0.012837939895689487, Neurons: 64, Grad norm: 2.199e-01\n",
      "Epoch 10897, Loss: 0.012832386419177055, Neurons: 64, Grad norm: 2.299e-01\n",
      "Epoch 10897, Loss: 0.012832386419177055, Neurons: 64, Grad norm: 2.299e-01\n",
      "Epoch 10898, Loss: 0.01282665878534317, Neurons: 64, Grad norm: 2.365e-01\n",
      "Epoch 10898, Loss: 0.01282665878534317, Neurons: 64, Grad norm: 2.365e-01\n",
      "Epoch 10899, Loss: 0.012820692732930183, Neurons: 64, Grad norm: 1.830e-01\n",
      "Epoch 10899, Loss: 0.012820692732930183, Neurons: 64, Grad norm: 1.830e-01\n",
      "Epoch 10899, Test loss: 0.008982837200164795\n",
      "Epoch 10899, Test loss: 0.008982837200164795\n",
      "Epoch 10900, Loss: 0.012814619578421116, Neurons: 64, Grad norm: 1.468e-01\n",
      "Epoch 10900, Loss: 0.012814619578421116, Neurons: 64, Grad norm: 1.468e-01\n",
      "Epoch 10901, Loss: 0.012808567844331264, Neurons: 64, Grad norm: 1.049e-01\n",
      "Epoch 10901, Loss: 0.012808567844331264, Neurons: 64, Grad norm: 1.049e-01\n",
      "Epoch 10902, Loss: 0.01280271913856268, Neurons: 64, Grad norm: 1.271e-01\n",
      "Epoch 10902, Loss: 0.01280271913856268, Neurons: 64, Grad norm: 1.271e-01\n",
      "Epoch 10903, Loss: 0.01279705110937357, Neurons: 64, Grad norm: 1.695e-01\n",
      "Epoch 10903, Loss: 0.01279705110937357, Neurons: 64, Grad norm: 1.695e-01\n",
      "Epoch 10904, Loss: 0.012791479006409645, Neurons: 64, Grad norm: 1.980e-01\n",
      "Epoch 10904, Loss: 0.012791479006409645, Neurons: 64, Grad norm: 1.980e-01\n",
      "Epoch 10905, Loss: 0.012786026112735271, Neurons: 64, Grad norm: 2.241e-01\n",
      "Epoch 10905, Loss: 0.012786026112735271, Neurons: 64, Grad norm: 2.241e-01\n",
      "Epoch 10906, Loss: 0.01278054341673851, Neurons: 64, Grad norm: 2.281e-01\n",
      "Epoch 10906, Loss: 0.01278054341673851, Neurons: 64, Grad norm: 2.281e-01\n",
      "Epoch 10907, Loss: 0.012775029055774212, Neurons: 64, Grad norm: 2.378e-01\n",
      "Epoch 10907, Loss: 0.012775029055774212, Neurons: 64, Grad norm: 2.378e-01\n",
      "Epoch 10908, Loss: 0.012769611552357674, Neurons: 64, Grad norm: 2.460e-01\n",
      "Epoch 10908, Loss: 0.012769611552357674, Neurons: 64, Grad norm: 2.460e-01\n",
      "Epoch 10909, Loss: 0.01276449766010046, Neurons: 64, Grad norm: 2.670e-01\n",
      "Epoch 10909, Loss: 0.01276449766010046, Neurons: 64, Grad norm: 2.670e-01\n",
      "Epoch 10910, Loss: 0.012759455479681492, Neurons: 64, Grad norm: 3.083e-01\n",
      "Epoch 10910, Loss: 0.012759455479681492, Neurons: 64, Grad norm: 3.083e-01\n",
      "Epoch 10911, Loss: 0.01275502610951662, Neurons: 64, Grad norm: 3.431e-01\n",
      "Epoch 10911, Loss: 0.01275502610951662, Neurons: 64, Grad norm: 3.431e-01\n",
      "Epoch 10912, Loss: 0.012750834226608276, Neurons: 64, Grad norm: 3.968e-01\n",
      "Epoch 10912, Loss: 0.012750834226608276, Neurons: 64, Grad norm: 3.968e-01\n",
      "Epoch 10913, Loss: 0.012746972031891346, Neurons: 64, Grad norm: 4.325e-01\n",
      "Epoch 10913, Loss: 0.012746972031891346, Neurons: 64, Grad norm: 4.325e-01\n",
      "Epoch 10914, Loss: 0.012743488885462284, Neurons: 64, Grad norm: 4.866e-01\n",
      "Epoch 10914, Loss: 0.012743488885462284, Neurons: 64, Grad norm: 4.866e-01\n",
      "Epoch 10915, Loss: 0.012740418314933777, Neurons: 64, Grad norm: 5.250e-01\n",
      "Epoch 10915, Loss: 0.012740418314933777, Neurons: 64, Grad norm: 5.250e-01\n",
      "Epoch 10916, Loss: 0.012737938202917576, Neurons: 64, Grad norm: 5.854e-01\n",
      "Epoch 10916, Loss: 0.012737938202917576, Neurons: 64, Grad norm: 5.854e-01\n",
      "Epoch 10917, Loss: 0.01273622177541256, Neurons: 64, Grad norm: 6.376e-01\n",
      "Epoch 10917, Loss: 0.01273622177541256, Neurons: 64, Grad norm: 6.376e-01\n",
      "Epoch 10918, Loss: 0.01273547112941742, Neurons: 64, Grad norm: 7.143e-01\n",
      "Epoch 10918, Loss: 0.01273547112941742, Neurons: 64, Grad norm: 7.143e-01\n",
      "Epoch 10919, Loss: 0.012736368924379349, Neurons: 64, Grad norm: 7.900e-01\n",
      "Epoch 10919, Loss: 0.012736368924379349, Neurons: 64, Grad norm: 7.900e-01\n",
      "Epoch 10920, Loss: 0.012738918885588646, Neurons: 64, Grad norm: 8.831e-01\n",
      "Epoch 10920, Loss: 0.012738918885588646, Neurons: 64, Grad norm: 8.831e-01\n",
      "Epoch 10921, Loss: 0.0127435103058815, Neurons: 64, Grad norm: 9.759e-01\n",
      "Epoch 10921, Loss: 0.0127435103058815, Neurons: 64, Grad norm: 9.759e-01\n",
      "Epoch 10922, Loss: 0.012749831192195415, Neurons: 64, Grad norm: 1.080e+00\n",
      "Epoch 10922, Loss: 0.012749831192195415, Neurons: 64, Grad norm: 1.080e+00\n",
      "Epoch 10923, Loss: 0.01275838166475296, Neurons: 64, Grad norm: 1.177e+00\n",
      "Epoch 10923, Loss: 0.01275838166475296, Neurons: 64, Grad norm: 1.177e+00\n",
      "Epoch 10924, Loss: 0.012768037617206573, Neurons: 64, Grad norm: 1.279e+00\n",
      "Epoch 10924, Loss: 0.012768037617206573, Neurons: 64, Grad norm: 1.279e+00\n",
      "Epoch 10925, Loss: 0.012778891250491142, Neurons: 64, Grad norm: 1.359e+00\n",
      "Epoch 10925, Loss: 0.012778891250491142, Neurons: 64, Grad norm: 1.359e+00\n",
      "Epoch 10926, Loss: 0.012788000516593456, Neurons: 64, Grad norm: 1.425e+00\n",
      "Epoch 10926, Loss: 0.012788000516593456, Neurons: 64, Grad norm: 1.425e+00\n",
      "Epoch 10927, Loss: 0.012794186361134052, Neurons: 64, Grad norm: 1.447e+00\n",
      "Epoch 10927, Loss: 0.012794186361134052, Neurons: 64, Grad norm: 1.447e+00\n",
      "Epoch 10928, Loss: 0.012793087400496006, Neurons: 64, Grad norm: 1.433e+00\n",
      "Epoch 10928, Loss: 0.012793087400496006, Neurons: 64, Grad norm: 1.433e+00\n",
      "Epoch 10929, Loss: 0.01278346125036478, Neurons: 64, Grad norm: 1.349e+00\n",
      "Epoch 10929, Loss: 0.01278346125036478, Neurons: 64, Grad norm: 1.349e+00\n",
      "Epoch 10930, Loss: 0.012762780301272869, Neurons: 64, Grad norm: 1.218e+00\n",
      "Epoch 10930, Loss: 0.012762780301272869, Neurons: 64, Grad norm: 1.218e+00\n",
      "Epoch 10931, Loss: 0.012732551433146, Neurons: 64, Grad norm: 1.017e+00\n",
      "Epoch 10931, Loss: 0.012732551433146, Neurons: 64, Grad norm: 1.017e+00\n",
      "Epoch 10932, Loss: 0.01269693486392498, Neurons: 64, Grad norm: 7.871e-01\n",
      "Epoch 10932, Loss: 0.01269693486392498, Neurons: 64, Grad norm: 7.871e-01\n",
      "Epoch 10933, Loss: 0.012661857530474663, Neurons: 64, Grad norm: 5.152e-01\n",
      "Epoch 10933, Loss: 0.012661857530474663, Neurons: 64, Grad norm: 5.152e-01\n",
      "Epoch 10934, Loss: 0.012632875703275204, Neurons: 64, Grad norm: 2.597e-01\n",
      "Epoch 10934, Loss: 0.012632875703275204, Neurons: 64, Grad norm: 2.597e-01\n",
      "Epoch 10935, Loss: 0.012613394297659397, Neurons: 64, Grad norm: 8.649e-02\n",
      "Epoch 10935, Loss: 0.012613394297659397, Neurons: 64, Grad norm: 8.649e-02\n",
      "Epoch 10936, Loss: 0.012604090385138988, Neurons: 64, Grad norm: 2.717e-01\n",
      "Epoch 10936, Loss: 0.012604090385138988, Neurons: 64, Grad norm: 2.717e-01\n",
      "Epoch 10937, Loss: 0.012603132985532284, Neurons: 64, Grad norm: 4.633e-01\n",
      "Epoch 10937, Loss: 0.012603132985532284, Neurons: 64, Grad norm: 4.633e-01\n",
      "Epoch 10938, Loss: 0.012607060372829437, Neurons: 64, Grad norm: 6.042e-01\n",
      "Epoch 10938, Loss: 0.012607060372829437, Neurons: 64, Grad norm: 6.042e-01\n",
      "Epoch 10939, Loss: 0.012612051330506802, Neurons: 64, Grad norm: 7.074e-01\n",
      "Epoch 10939, Loss: 0.012612051330506802, Neurons: 64, Grad norm: 7.074e-01\n",
      "Epoch 10940, Loss: 0.012614870443940163, Neurons: 64, Grad norm: 7.464e-01\n",
      "Epoch 10940, Loss: 0.012614870443940163, Neurons: 64, Grad norm: 7.464e-01\n",
      "Epoch 10941, Loss: 0.012613573111593723, Neurons: 64, Grad norm: 7.495e-01\n",
      "Epoch 10941, Loss: 0.012613573111593723, Neurons: 64, Grad norm: 7.495e-01\n",
      "Epoch 10942, Loss: 0.012607216835021973, Neurons: 64, Grad norm: 6.935e-01\n",
      "Epoch 10942, Loss: 0.012607216835021973, Neurons: 64, Grad norm: 6.935e-01\n",
      "Epoch 10943, Loss: 0.012596541084349155, Neurons: 64, Grad norm: 6.157e-01\n",
      "Epoch 10943, Loss: 0.012596541084349155, Neurons: 64, Grad norm: 6.157e-01\n",
      "Epoch 10944, Loss: 0.012582891620695591, Neurons: 64, Grad norm: 4.924e-01\n",
      "Epoch 10944, Loss: 0.012582891620695591, Neurons: 64, Grad norm: 4.924e-01\n",
      "Epoch 10945, Loss: 0.012568500824272633, Neurons: 64, Grad norm: 3.733e-01\n",
      "Epoch 10945, Loss: 0.012568500824272633, Neurons: 64, Grad norm: 3.733e-01\n",
      "Epoch 10946, Loss: 0.012555181980133057, Neurons: 64, Grad norm: 2.335e-01\n",
      "Epoch 10946, Loss: 0.012555181980133057, Neurons: 64, Grad norm: 2.335e-01\n",
      "Epoch 10947, Loss: 0.012544305063784122, Neurons: 64, Grad norm: 1.382e-01\n",
      "Epoch 10947, Loss: 0.012544305063784122, Neurons: 64, Grad norm: 1.382e-01\n",
      "Epoch 10948, Loss: 0.012536216527223587, Neurons: 64, Grad norm: 1.015e-01\n",
      "Epoch 10948, Loss: 0.012536216527223587, Neurons: 64, Grad norm: 1.015e-01\n",
      "Epoch 10949, Loss: 0.012530475854873657, Neurons: 64, Grad norm: 1.746e-01\n",
      "Epoch 10949, Loss: 0.012530475854873657, Neurons: 64, Grad norm: 1.746e-01\n",
      "Epoch 10950, Loss: 0.012526587583124638, Neurons: 64, Grad norm: 2.561e-01\n",
      "Epoch 10950, Loss: 0.012526587583124638, Neurons: 64, Grad norm: 2.561e-01\n",
      "Epoch 10951, Loss: 0.012523308396339417, Neurons: 64, Grad norm: 3.225e-01\n",
      "Epoch 10951, Loss: 0.012523308396339417, Neurons: 64, Grad norm: 3.225e-01\n",
      "Epoch 10952, Loss: 0.0125204399228096, Neurons: 64, Grad norm: 3.826e-01\n",
      "Epoch 10952, Loss: 0.0125204399228096, Neurons: 64, Grad norm: 3.826e-01\n",
      "Epoch 10953, Loss: 0.01251736655831337, Neurons: 64, Grad norm: 4.123e-01\n",
      "Epoch 10953, Loss: 0.01251736655831337, Neurons: 64, Grad norm: 4.123e-01\n",
      "Epoch 10954, Loss: 0.012513522990047932, Neurons: 64, Grad norm: 4.384e-01\n",
      "Epoch 10954, Loss: 0.012513522990047932, Neurons: 64, Grad norm: 4.384e-01\n",
      "Epoch 10955, Loss: 0.012508808635175228, Neurons: 64, Grad norm: 4.295e-01\n",
      "Epoch 10955, Loss: 0.012508808635175228, Neurons: 64, Grad norm: 4.295e-01\n",
      "Epoch 10956, Loss: 0.012502985075116158, Neurons: 64, Grad norm: 4.208e-01\n",
      "Epoch 10956, Loss: 0.012502985075116158, Neurons: 64, Grad norm: 4.208e-01\n",
      "Epoch 10957, Loss: 0.012496103532612324, Neurons: 64, Grad norm: 3.776e-01\n",
      "Epoch 10957, Loss: 0.012496103532612324, Neurons: 64, Grad norm: 3.776e-01\n",
      "Epoch 10958, Loss: 0.01248870324343443, Neurons: 64, Grad norm: 3.431e-01\n",
      "Epoch 10958, Loss: 0.01248870324343443, Neurons: 64, Grad norm: 3.431e-01\n",
      "Epoch 10959, Loss: 0.012480898760259151, Neurons: 64, Grad norm: 2.758e-01\n",
      "Epoch 10959, Loss: 0.012480898760259151, Neurons: 64, Grad norm: 2.758e-01\n",
      "Epoch 10960, Loss: 0.012473084963858128, Neurons: 64, Grad norm: 2.270e-01\n",
      "Epoch 10960, Loss: 0.012473084963858128, Neurons: 64, Grad norm: 2.270e-01\n",
      "Epoch 10961, Loss: 0.012465584091842175, Neurons: 64, Grad norm: 1.564e-01\n",
      "Epoch 10961, Loss: 0.012465584091842175, Neurons: 64, Grad norm: 1.564e-01\n",
      "Epoch 10962, Loss: 0.012458436191082, Neurons: 64, Grad norm: 1.177e-01\n",
      "Epoch 10962, Loss: 0.012458436191082, Neurons: 64, Grad norm: 1.177e-01\n",
      "Epoch 10963, Loss: 0.012452132999897003, Neurons: 64, Grad norm: 6.549e-02\n",
      "Epoch 10963, Loss: 0.012452132999897003, Neurons: 64, Grad norm: 6.549e-02\n",
      "Epoch 10964, Loss: 0.012446277774870396, Neurons: 64, Grad norm: 7.637e-02\n",
      "Epoch 10964, Loss: 0.012446277774870396, Neurons: 64, Grad norm: 7.637e-02\n",
      "Epoch 10965, Loss: 0.01244080625474453, Neurons: 64, Grad norm: 9.875e-02\n",
      "Epoch 10965, Loss: 0.01244080625474453, Neurons: 64, Grad norm: 9.875e-02\n",
      "Epoch 10966, Loss: 0.01243568304926157, Neurons: 64, Grad norm: 1.268e-01\n",
      "Epoch 10966, Loss: 0.01243568304926157, Neurons: 64, Grad norm: 1.268e-01\n",
      "Epoch 10967, Loss: 0.012430645525455475, Neurons: 64, Grad norm: 1.596e-01\n",
      "Epoch 10967, Loss: 0.012430645525455475, Neurons: 64, Grad norm: 1.596e-01\n",
      "Epoch 10968, Loss: 0.012425640597939491, Neurons: 64, Grad norm: 1.800e-01\n",
      "Epoch 10968, Loss: 0.012425640597939491, Neurons: 64, Grad norm: 1.800e-01\n",
      "Epoch 10969, Loss: 0.012420594692230225, Neurons: 64, Grad norm: 2.119e-01\n",
      "Epoch 10969, Loss: 0.012420594692230225, Neurons: 64, Grad norm: 2.119e-01\n",
      "Epoch 10970, Loss: 0.012415695935487747, Neurons: 64, Grad norm: 2.255e-01\n",
      "Epoch 10970, Loss: 0.012415695935487747, Neurons: 64, Grad norm: 2.255e-01\n",
      "Epoch 10971, Loss: 0.012410721741616726, Neurons: 64, Grad norm: 2.503e-01\n",
      "Epoch 10971, Loss: 0.012410721741616726, Neurons: 64, Grad norm: 2.503e-01\n",
      "Epoch 10972, Loss: 0.012405717745423317, Neurons: 64, Grad norm: 2.551e-01\n",
      "Epoch 10972, Loss: 0.012405717745423317, Neurons: 64, Grad norm: 2.551e-01\n",
      "Epoch 10973, Loss: 0.012400523759424686, Neurons: 64, Grad norm: 2.730e-01\n",
      "Epoch 10973, Loss: 0.012400523759424686, Neurons: 64, Grad norm: 2.730e-01\n",
      "Epoch 10974, Loss: 0.01239528227597475, Neurons: 64, Grad norm: 2.663e-01\n",
      "Epoch 10974, Loss: 0.01239528227597475, Neurons: 64, Grad norm: 2.663e-01\n",
      "Epoch 10975, Loss: 0.012389845214784145, Neurons: 64, Grad norm: 2.775e-01\n",
      "Epoch 10975, Loss: 0.012389845214784145, Neurons: 64, Grad norm: 2.775e-01\n",
      "Epoch 10976, Loss: 0.012384312227368355, Neurons: 64, Grad norm: 2.667e-01\n",
      "Epoch 10976, Loss: 0.012384312227368355, Neurons: 64, Grad norm: 2.667e-01\n",
      "Epoch 10977, Loss: 0.012378733605146408, Neurons: 64, Grad norm: 2.756e-01\n",
      "Epoch 10977, Loss: 0.012378733605146408, Neurons: 64, Grad norm: 2.756e-01\n",
      "Epoch 10978, Loss: 0.012373175472021103, Neurons: 64, Grad norm: 2.615e-01\n",
      "Epoch 10978, Loss: 0.012373175472021103, Neurons: 64, Grad norm: 2.615e-01\n",
      "Epoch 10979, Loss: 0.01236743200570345, Neurons: 64, Grad norm: 2.684e-01\n",
      "Epoch 10979, Loss: 0.01236743200570345, Neurons: 64, Grad norm: 2.684e-01\n",
      "Epoch 10980, Loss: 0.012361742556095123, Neurons: 64, Grad norm: 2.550e-01\n",
      "Epoch 10980, Loss: 0.012361742556095123, Neurons: 64, Grad norm: 2.550e-01\n",
      "Epoch 10981, Loss: 0.012356113642454147, Neurons: 64, Grad norm: 2.637e-01\n",
      "Epoch 10981, Loss: 0.012356113642454147, Neurons: 64, Grad norm: 2.637e-01\n",
      "Epoch 10982, Loss: 0.012350664474070072, Neurons: 64, Grad norm: 2.545e-01\n",
      "Epoch 10982, Loss: 0.012350664474070072, Neurons: 64, Grad norm: 2.545e-01\n",
      "Epoch 10983, Loss: 0.012345201335847378, Neurons: 64, Grad norm: 2.660e-01\n",
      "Epoch 10983, Loss: 0.012345201335847378, Neurons: 64, Grad norm: 2.660e-01\n",
      "Epoch 10984, Loss: 0.01233980804681778, Neurons: 64, Grad norm: 2.629e-01\n",
      "Epoch 10984, Loss: 0.01233980804681778, Neurons: 64, Grad norm: 2.629e-01\n",
      "Epoch 10985, Loss: 0.01233461033552885, Neurons: 64, Grad norm: 2.836e-01\n",
      "Epoch 10985, Loss: 0.01233461033552885, Neurons: 64, Grad norm: 2.836e-01\n",
      "Epoch 10986, Loss: 0.012329556979238987, Neurons: 64, Grad norm: 2.868e-01\n",
      "Epoch 10986, Loss: 0.012329556979238987, Neurons: 64, Grad norm: 2.868e-01\n",
      "Epoch 10987, Loss: 0.012324642390012741, Neurons: 64, Grad norm: 3.094e-01\n",
      "Epoch 10987, Loss: 0.012324642390012741, Neurons: 64, Grad norm: 3.094e-01\n",
      "Epoch 10988, Loss: 0.012319658882915974, Neurons: 64, Grad norm: 3.134e-01\n",
      "Epoch 10988, Loss: 0.012319658882915974, Neurons: 64, Grad norm: 3.134e-01\n",
      "Epoch 10989, Loss: 0.012314749881625175, Neurons: 64, Grad norm: 3.395e-01\n",
      "Epoch 10989, Loss: 0.012314749881625175, Neurons: 64, Grad norm: 3.395e-01\n",
      "Epoch 10990, Loss: 0.01230992004275322, Neurons: 64, Grad norm: 3.508e-01\n",
      "Epoch 10990, Loss: 0.01230992004275322, Neurons: 64, Grad norm: 3.508e-01\n",
      "Epoch 10991, Loss: 0.012305285781621933, Neurons: 64, Grad norm: 3.841e-01\n",
      "Epoch 10991, Loss: 0.012305285781621933, Neurons: 64, Grad norm: 3.841e-01\n",
      "Epoch 10992, Loss: 0.012300985865294933, Neurons: 64, Grad norm: 4.051e-01\n",
      "Epoch 10992, Loss: 0.012300985865294933, Neurons: 64, Grad norm: 4.051e-01\n",
      "Epoch 10993, Loss: 0.0122969476506114, Neurons: 64, Grad norm: 4.529e-01\n",
      "Epoch 10993, Loss: 0.0122969476506114, Neurons: 64, Grad norm: 4.529e-01\n",
      "Epoch 10994, Loss: 0.012293645180761814, Neurons: 64, Grad norm: 4.882e-01\n",
      "Epoch 10994, Loss: 0.012293645180761814, Neurons: 64, Grad norm: 4.882e-01\n",
      "Epoch 10995, Loss: 0.012290882878005505, Neurons: 64, Grad norm: 5.479e-01\n",
      "Epoch 10995, Loss: 0.012290882878005505, Neurons: 64, Grad norm: 5.479e-01\n",
      "Epoch 10996, Loss: 0.01228842418640852, Neurons: 64, Grad norm: 5.959e-01\n",
      "Epoch 10996, Loss: 0.01228842418640852, Neurons: 64, Grad norm: 5.959e-01\n",
      "Epoch 10997, Loss: 0.012286812998354435, Neurons: 64, Grad norm: 6.714e-01\n",
      "Epoch 10997, Loss: 0.012286812998354435, Neurons: 64, Grad norm: 6.714e-01\n",
      "Epoch 10998, Loss: 0.012286516837775707, Neurons: 64, Grad norm: 7.375e-01\n",
      "Epoch 10998, Loss: 0.012286516837775707, Neurons: 64, Grad norm: 7.375e-01\n",
      "Epoch 10999, Loss: 0.012287202291190624, Neurons: 64, Grad norm: 8.332e-01\n",
      "Epoch 10999, Loss: 0.012287202291190624, Neurons: 64, Grad norm: 8.332e-01\n",
      "Epoch 10999, Test loss: 0.008698694407939911\n",
      "Epoch 10999, Test loss: 0.008698694407939911\n",
      "Epoch 11000, Loss: 0.01229013316333294, Neurons: 64, Grad norm: 9.185e-01\n",
      "Epoch 11000, Loss: 0.01229013316333294, Neurons: 64, Grad norm: 9.185e-01\n",
      "Epoch 11001, Loss: 0.012294174171984196, Neurons: 64, Grad norm: 1.030e+00\n",
      "Epoch 11001, Loss: 0.012294174171984196, Neurons: 64, Grad norm: 1.030e+00\n",
      "Epoch 11002, Loss: 0.01229950413107872, Neurons: 64, Grad norm: 1.126e+00\n",
      "Epoch 11002, Loss: 0.01229950413107872, Neurons: 64, Grad norm: 1.126e+00\n",
      "Epoch 11003, Loss: 0.012306309305131435, Neurons: 64, Grad norm: 1.252e+00\n",
      "Epoch 11003, Loss: 0.012306309305131435, Neurons: 64, Grad norm: 1.252e+00\n",
      "Epoch 11004, Loss: 0.012315305881202221, Neurons: 64, Grad norm: 1.365e+00\n",
      "Epoch 11004, Loss: 0.012315305881202221, Neurons: 64, Grad norm: 1.365e+00\n",
      "Epoch 11005, Loss: 0.012324941344559193, Neurons: 64, Grad norm: 1.499e+00\n",
      "Epoch 11005, Loss: 0.012324941344559193, Neurons: 64, Grad norm: 1.499e+00\n",
      "Epoch 11006, Loss: 0.01233575027436018, Neurons: 64, Grad norm: 1.606e+00\n",
      "Epoch 11006, Loss: 0.01233575027436018, Neurons: 64, Grad norm: 1.606e+00\n",
      "Epoch 11007, Loss: 0.012344606220722198, Neurons: 64, Grad norm: 1.730e+00\n",
      "Epoch 11007, Loss: 0.012344606220722198, Neurons: 64, Grad norm: 1.730e+00\n",
      "Epoch 11008, Loss: 0.012349965050816536, Neurons: 64, Grad norm: 1.816e+00\n",
      "Epoch 11008, Loss: 0.012349965050816536, Neurons: 64, Grad norm: 1.816e+00\n",
      "Epoch 11009, Loss: 0.012349697761237621, Neurons: 64, Grad norm: 1.917e+00\n",
      "Epoch 11009, Loss: 0.012349697761237621, Neurons: 64, Grad norm: 1.917e+00\n",
      "Epoch 11010, Loss: 0.012342710979282856, Neurons: 64, Grad norm: 1.990e+00\n",
      "Epoch 11010, Loss: 0.012342710979282856, Neurons: 64, Grad norm: 1.990e+00\n",
      "Epoch 11011, Loss: 0.012329403311014175, Neurons: 64, Grad norm: 2.099e+00\n",
      "Epoch 11011, Loss: 0.012329403311014175, Neurons: 64, Grad norm: 2.099e+00\n",
      "Epoch 11012, Loss: 0.01231200248003006, Neurons: 64, Grad norm: 2.208e+00\n",
      "Epoch 11012, Loss: 0.01231200248003006, Neurons: 64, Grad norm: 2.208e+00\n",
      "Epoch 11013, Loss: 0.012294906191527843, Neurons: 64, Grad norm: 2.402e+00\n",
      "Epoch 11013, Loss: 0.012294906191527843, Neurons: 64, Grad norm: 2.402e+00\n",
      "Epoch 11014, Loss: 0.012283355928957462, Neurons: 64, Grad norm: 2.631e+00\n",
      "Epoch 11014, Loss: 0.012283355928957462, Neurons: 64, Grad norm: 2.631e+00\n",
      "Epoch 11015, Loss: 0.012282500974833965, Neurons: 64, Grad norm: 2.961e+00\n",
      "Epoch 11015, Loss: 0.012282500974833965, Neurons: 64, Grad norm: 2.961e+00\n",
      "Epoch 11016, Loss: 0.012296277098357677, Neurons: 64, Grad norm: 3.337e+00\n",
      "Epoch 11016, Loss: 0.012296277098357677, Neurons: 64, Grad norm: 3.337e+00\n",
      "Epoch 11017, Loss: 0.012327524833381176, Neurons: 64, Grad norm: 3.808e+00\n",
      "Epoch 11017, Loss: 0.012327524833381176, Neurons: 64, Grad norm: 3.808e+00\n",
      "Epoch 11018, Loss: 0.012376631610095501, Neurons: 64, Grad norm: 4.306e+00\n",
      "Epoch 11018, Loss: 0.012376631610095501, Neurons: 64, Grad norm: 4.306e+00\n",
      "Epoch 11019, Loss: 0.012443228624761105, Neurons: 64, Grad norm: 4.866e+00\n",
      "Epoch 11019, Loss: 0.012443228624761105, Neurons: 64, Grad norm: 4.866e+00\n",
      "Epoch 11020, Loss: 0.012523860670626163, Neurons: 64, Grad norm: 5.405e+00\n",
      "Epoch 11020, Loss: 0.012523860670626163, Neurons: 64, Grad norm: 5.405e+00\n",
      "Epoch 11021, Loss: 0.012613693252205849, Neurons: 64, Grad norm: 5.934e+00\n",
      "Epoch 11021, Loss: 0.012613693252205849, Neurons: 64, Grad norm: 5.934e+00\n",
      "Epoch 11022, Loss: 0.012700931169092655, Neurons: 64, Grad norm: 6.329e+00\n",
      "Epoch 11022, Loss: 0.012700931169092655, Neurons: 64, Grad norm: 6.329e+00\n",
      "Epoch 11023, Loss: 0.012770897708833218, Neurons: 64, Grad norm: 6.571e+00\n",
      "Epoch 11023, Loss: 0.012770897708833218, Neurons: 64, Grad norm: 6.571e+00\n",
      "Epoch 11024, Loss: 0.012802079319953918, Neurons: 64, Grad norm: 6.528e+00\n",
      "Epoch 11024, Loss: 0.012802079319953918, Neurons: 64, Grad norm: 6.528e+00\n",
      "Epoch 11025, Loss: 0.012779943645000458, Neurons: 64, Grad norm: 6.192e+00\n",
      "Epoch 11025, Loss: 0.012779943645000458, Neurons: 64, Grad norm: 6.192e+00\n",
      "Epoch 11026, Loss: 0.012695900164544582, Neurons: 64, Grad norm: 5.487e+00\n",
      "Epoch 11026, Loss: 0.012695900164544582, Neurons: 64, Grad norm: 5.487e+00\n",
      "Epoch 11027, Loss: 0.012563287280499935, Neurons: 64, Grad norm: 4.501e+00\n",
      "Epoch 11027, Loss: 0.012563287280499935, Neurons: 64, Grad norm: 4.501e+00\n",
      "Epoch 11028, Loss: 0.012409592047333717, Neurons: 64, Grad norm: 3.273e+00\n",
      "Epoch 11028, Loss: 0.012409592047333717, Neurons: 64, Grad norm: 3.273e+00\n",
      "Epoch 11029, Loss: 0.012272009626030922, Neurons: 64, Grad norm: 2.010e+00\n",
      "Epoch 11029, Loss: 0.012272009626030922, Neurons: 64, Grad norm: 2.010e+00\n",
      "Epoch 11030, Loss: 0.012178334407508373, Neurons: 64, Grad norm: 9.765e-01\n",
      "Epoch 11030, Loss: 0.012178334407508373, Neurons: 64, Grad norm: 9.765e-01\n",
      "Epoch 11031, Loss: 0.012137890793383121, Neurons: 64, Grad norm: 1.164e+00\n",
      "Epoch 11031, Loss: 0.012137890793383121, Neurons: 64, Grad norm: 1.164e+00\n",
      "Epoch 11032, Loss: 0.012142349034547806, Neurons: 64, Grad norm: 1.992e+00\n",
      "Epoch 11032, Loss: 0.012142349034547806, Neurons: 64, Grad norm: 1.992e+00\n",
      "Epoch 11033, Loss: 0.012170922011137009, Neurons: 64, Grad norm: 2.665e+00\n",
      "Epoch 11033, Loss: 0.012170922011137009, Neurons: 64, Grad norm: 2.665e+00\n",
      "Epoch 11034, Loss: 0.012202408164739609, Neurons: 64, Grad norm: 3.098e+00\n",
      "Epoch 11034, Loss: 0.012202408164739609, Neurons: 64, Grad norm: 3.098e+00\n",
      "Epoch 11035, Loss: 0.012220349162817001, Neurons: 64, Grad norm: 3.219e+00\n",
      "Epoch 11035, Loss: 0.012220349162817001, Neurons: 64, Grad norm: 3.219e+00\n",
      "Epoch 11036, Loss: 0.012219063937664032, Neurons: 64, Grad norm: 3.104e+00\n",
      "Epoch 11036, Loss: 0.012219063937664032, Neurons: 64, Grad norm: 3.104e+00\n",
      "Epoch 11037, Loss: 0.01220022700726986, Neurons: 64, Grad norm: 2.744e+00\n",
      "Epoch 11037, Loss: 0.01220022700726986, Neurons: 64, Grad norm: 2.744e+00\n",
      "Epoch 11038, Loss: 0.012171342968940735, Neurons: 64, Grad norm: 2.258e+00\n",
      "Epoch 11038, Loss: 0.012171342968940735, Neurons: 64, Grad norm: 2.258e+00\n",
      "Epoch 11039, Loss: 0.012139925733208656, Neurons: 64, Grad norm: 1.673e+00\n",
      "Epoch 11039, Loss: 0.012139925733208656, Neurons: 64, Grad norm: 1.673e+00\n",
      "Epoch 11040, Loss: 0.012111716903746128, Neurons: 64, Grad norm: 1.153e+00\n",
      "Epoch 11040, Loss: 0.012111716903746128, Neurons: 64, Grad norm: 1.153e+00\n",
      "Epoch 11041, Loss: 0.01208971906453371, Neurons: 64, Grad norm: 8.100e-01\n",
      "Epoch 11041, Loss: 0.01208971906453371, Neurons: 64, Grad norm: 8.100e-01\n",
      "Epoch 11042, Loss: 0.012073053047060966, Neurons: 64, Grad norm: 8.501e-01\n",
      "Epoch 11042, Loss: 0.012073053047060966, Neurons: 64, Grad norm: 8.501e-01\n",
      "Epoch 11043, Loss: 0.012061069719493389, Neurons: 64, Grad norm: 1.104e+00\n",
      "Epoch 11043, Loss: 0.012061069719493389, Neurons: 64, Grad norm: 1.104e+00\n",
      "Epoch 11044, Loss: 0.012052033096551895, Neurons: 64, Grad norm: 1.329e+00\n",
      "Epoch 11044, Loss: 0.012052033096551895, Neurons: 64, Grad norm: 1.329e+00\n",
      "Epoch 11045, Loss: 0.012045774608850479, Neurons: 64, Grad norm: 1.500e+00\n",
      "Epoch 11045, Loss: 0.012045774608850479, Neurons: 64, Grad norm: 1.500e+00\n",
      "Epoch 11046, Loss: 0.012042530812323093, Neurons: 64, Grad norm: 1.552e+00\n",
      "Epoch 11046, Loss: 0.012042530812323093, Neurons: 64, Grad norm: 1.552e+00\n",
      "Epoch 11047, Loss: 0.012041657231748104, Neurons: 64, Grad norm: 1.538e+00\n",
      "Epoch 11047, Loss: 0.012041657231748104, Neurons: 64, Grad norm: 1.538e+00\n",
      "Epoch 11048, Loss: 0.012041235342621803, Neurons: 64, Grad norm: 1.417e+00\n",
      "Epoch 11048, Loss: 0.012041235342621803, Neurons: 64, Grad norm: 1.417e+00\n",
      "Epoch 11049, Loss: 0.012038851156830788, Neurons: 64, Grad norm: 1.268e+00\n",
      "Epoch 11049, Loss: 0.012038851156830788, Neurons: 64, Grad norm: 1.268e+00\n",
      "Epoch 11050, Loss: 0.012032429687678814, Neurons: 64, Grad norm: 1.041e+00\n",
      "Epoch 11050, Loss: 0.012032429687678814, Neurons: 64, Grad norm: 1.041e+00\n",
      "Epoch 11051, Loss: 0.012021506205201149, Neurons: 64, Grad norm: 8.195e-01\n",
      "Epoch 11051, Loss: 0.012021506205201149, Neurons: 64, Grad norm: 8.195e-01\n",
      "Epoch 11052, Loss: 0.012007251381874084, Neurons: 64, Grad norm: 5.703e-01\n",
      "Epoch 11052, Loss: 0.012007251381874084, Neurons: 64, Grad norm: 5.703e-01\n",
      "Epoch 11053, Loss: 0.011991642415523529, Neurons: 64, Grad norm: 3.771e-01\n",
      "Epoch 11053, Loss: 0.011991642415523529, Neurons: 64, Grad norm: 3.771e-01\n",
      "Epoch 11054, Loss: 0.011977515183389187, Neurons: 64, Grad norm: 3.066e-01\n",
      "Epoch 11054, Loss: 0.011977515183389187, Neurons: 64, Grad norm: 3.066e-01\n",
      "Epoch 11055, Loss: 0.011966734193265438, Neurons: 64, Grad norm: 3.941e-01\n",
      "Epoch 11055, Loss: 0.011966734193265438, Neurons: 64, Grad norm: 3.941e-01\n",
      "Epoch 11056, Loss: 0.011960442177951336, Neurons: 64, Grad norm: 5.560e-01\n",
      "Epoch 11056, Loss: 0.011960442177951336, Neurons: 64, Grad norm: 5.560e-01\n",
      "Epoch 11057, Loss: 0.011957989074289799, Neurons: 64, Grad norm: 6.732e-01\n",
      "Epoch 11057, Loss: 0.011957989074289799, Neurons: 64, Grad norm: 6.732e-01\n",
      "Epoch 11058, Loss: 0.011957889422774315, Neurons: 64, Grad norm: 7.799e-01\n",
      "Epoch 11058, Loss: 0.011957889422774315, Neurons: 64, Grad norm: 7.799e-01\n",
      "Epoch 11059, Loss: 0.011958317831158638, Neurons: 64, Grad norm: 8.128e-01\n",
      "Epoch 11059, Loss: 0.011958317831158638, Neurons: 64, Grad norm: 8.128e-01\n",
      "Epoch 11060, Loss: 0.011957182548940182, Neurons: 64, Grad norm: 8.346e-01\n",
      "Epoch 11060, Loss: 0.011957182548940182, Neurons: 64, Grad norm: 8.346e-01\n",
      "Epoch 11061, Loss: 0.011953688226640224, Neurons: 64, Grad norm: 7.839e-01\n",
      "Epoch 11061, Loss: 0.011953688226640224, Neurons: 64, Grad norm: 7.839e-01\n",
      "Epoch 11062, Loss: 0.011947277933359146, Neurons: 64, Grad norm: 7.242e-01\n",
      "Epoch 11062, Loss: 0.011947277933359146, Neurons: 64, Grad norm: 7.242e-01\n",
      "Epoch 11063, Loss: 0.011938896961510181, Neurons: 64, Grad norm: 6.121e-01\n",
      "Epoch 11063, Loss: 0.011938896961510181, Neurons: 64, Grad norm: 6.121e-01\n",
      "Epoch 11064, Loss: 0.011929280124604702, Neurons: 64, Grad norm: 5.119e-01\n",
      "Epoch 11064, Loss: 0.011929280124604702, Neurons: 64, Grad norm: 5.119e-01\n",
      "Epoch 11065, Loss: 0.01191949937492609, Neurons: 64, Grad norm: 3.742e-01\n",
      "Epoch 11065, Loss: 0.01191949937492609, Neurons: 64, Grad norm: 3.742e-01\n",
      "Epoch 11066, Loss: 0.01191084086894989, Neurons: 64, Grad norm: 2.712e-01\n",
      "Epoch 11066, Loss: 0.01191084086894989, Neurons: 64, Grad norm: 2.712e-01\n",
      "Epoch 11067, Loss: 0.011903774924576283, Neurons: 64, Grad norm: 1.721e-01\n",
      "Epoch 11067, Loss: 0.011903774924576283, Neurons: 64, Grad norm: 1.721e-01\n",
      "Epoch 11068, Loss: 0.011898249387741089, Neurons: 64, Grad norm: 1.589e-01\n",
      "Epoch 11068, Loss: 0.011898249387741089, Neurons: 64, Grad norm: 1.589e-01\n",
      "Epoch 11069, Loss: 0.011894017457962036, Neurons: 64, Grad norm: 1.969e-01\n",
      "Epoch 11069, Loss: 0.011894017457962036, Neurons: 64, Grad norm: 1.969e-01\n",
      "Epoch 11070, Loss: 0.011890161782503128, Neurons: 64, Grad norm: 2.422e-01\n",
      "Epoch 11070, Loss: 0.011890161782503128, Neurons: 64, Grad norm: 2.422e-01\n",
      "Epoch 11071, Loss: 0.011886419728398323, Neurons: 64, Grad norm: 3.054e-01\n",
      "Epoch 11071, Loss: 0.011886419728398323, Neurons: 64, Grad norm: 3.054e-01\n",
      "Epoch 11072, Loss: 0.011882237158715725, Neurons: 64, Grad norm: 3.367e-01\n",
      "Epoch 11072, Loss: 0.011882237158715725, Neurons: 64, Grad norm: 3.367e-01\n",
      "Epoch 11073, Loss: 0.011877649463713169, Neurons: 64, Grad norm: 3.867e-01\n",
      "Epoch 11073, Loss: 0.011877649463713169, Neurons: 64, Grad norm: 3.867e-01\n",
      "Epoch 11074, Loss: 0.011872767470777035, Neurons: 64, Grad norm: 4.038e-01\n",
      "Epoch 11074, Loss: 0.011872767470777035, Neurons: 64, Grad norm: 4.038e-01\n",
      "Epoch 11075, Loss: 0.011867593973875046, Neurons: 64, Grad norm: 4.391e-01\n",
      "Epoch 11075, Loss: 0.011867593973875046, Neurons: 64, Grad norm: 4.391e-01\n",
      "Epoch 11076, Loss: 0.011862304992973804, Neurons: 64, Grad norm: 4.388e-01\n",
      "Epoch 11076, Loss: 0.011862304992973804, Neurons: 64, Grad norm: 4.388e-01\n",
      "Epoch 11077, Loss: 0.011856895871460438, Neurons: 64, Grad norm: 4.589e-01\n",
      "Epoch 11077, Loss: 0.011856895871460438, Neurons: 64, Grad norm: 4.589e-01\n",
      "Epoch 11078, Loss: 0.01185162179172039, Neurons: 64, Grad norm: 4.461e-01\n",
      "Epoch 11078, Loss: 0.01185162179172039, Neurons: 64, Grad norm: 4.461e-01\n",
      "Epoch 11079, Loss: 0.011846293695271015, Neurons: 64, Grad norm: 4.601e-01\n",
      "Epoch 11079, Loss: 0.011846293695271015, Neurons: 64, Grad norm: 4.601e-01\n",
      "Epoch 11080, Loss: 0.011841089464724064, Neurons: 64, Grad norm: 4.376e-01\n",
      "Epoch 11080, Loss: 0.011841089464724064, Neurons: 64, Grad norm: 4.376e-01\n",
      "Epoch 11081, Loss: 0.011835996061563492, Neurons: 64, Grad norm: 4.393e-01\n",
      "Epoch 11081, Loss: 0.011835996061563492, Neurons: 64, Grad norm: 4.393e-01\n",
      "Epoch 11082, Loss: 0.011830855160951614, Neurons: 64, Grad norm: 4.082e-01\n",
      "Epoch 11082, Loss: 0.011830855160951614, Neurons: 64, Grad norm: 4.082e-01\n",
      "Epoch 11083, Loss: 0.011825785972177982, Neurons: 64, Grad norm: 4.039e-01\n",
      "Epoch 11083, Loss: 0.011825785972177982, Neurons: 64, Grad norm: 4.039e-01\n",
      "Epoch 11084, Loss: 0.011820650659501553, Neurons: 64, Grad norm: 3.690e-01\n",
      "Epoch 11084, Loss: 0.011820650659501553, Neurons: 64, Grad norm: 3.690e-01\n",
      "Epoch 11085, Loss: 0.011815558187663555, Neurons: 64, Grad norm: 3.549e-01\n",
      "Epoch 11085, Loss: 0.011815558187663555, Neurons: 64, Grad norm: 3.549e-01\n",
      "Epoch 11086, Loss: 0.011810329742729664, Neurons: 64, Grad norm: 3.149e-01\n",
      "Epoch 11086, Loss: 0.011810329742729664, Neurons: 64, Grad norm: 3.149e-01\n",
      "Epoch 11087, Loss: 0.01180526427924633, Neurons: 64, Grad norm: 3.003e-01\n",
      "Epoch 11087, Loss: 0.01180526427924633, Neurons: 64, Grad norm: 3.003e-01\n",
      "Epoch 11088, Loss: 0.011800093576312065, Neurons: 64, Grad norm: 2.618e-01\n",
      "Epoch 11088, Loss: 0.011800093576312065, Neurons: 64, Grad norm: 2.618e-01\n",
      "Epoch 11089, Loss: 0.011794911697506905, Neurons: 64, Grad norm: 2.477e-01\n",
      "Epoch 11089, Loss: 0.011794911697506905, Neurons: 64, Grad norm: 2.477e-01\n",
      "Epoch 11090, Loss: 0.011789700016379356, Neurons: 64, Grad norm: 2.085e-01\n",
      "Epoch 11090, Loss: 0.011789700016379356, Neurons: 64, Grad norm: 2.085e-01\n",
      "Epoch 11091, Loss: 0.011784621514379978, Neurons: 64, Grad norm: 1.941e-01\n",
      "Epoch 11091, Loss: 0.011784621514379978, Neurons: 64, Grad norm: 1.941e-01\n",
      "Epoch 11092, Loss: 0.011779426597058773, Neurons: 64, Grad norm: 1.606e-01\n",
      "Epoch 11092, Loss: 0.011779426597058773, Neurons: 64, Grad norm: 1.606e-01\n",
      "Epoch 11093, Loss: 0.011774317361414433, Neurons: 64, Grad norm: 1.567e-01\n",
      "Epoch 11093, Loss: 0.011774317361414433, Neurons: 64, Grad norm: 1.567e-01\n",
      "Epoch 11094, Loss: 0.011769255623221397, Neurons: 64, Grad norm: 1.246e-01\n",
      "Epoch 11094, Loss: 0.011769255623221397, Neurons: 64, Grad norm: 1.246e-01\n",
      "Epoch 11095, Loss: 0.011764276772737503, Neurons: 64, Grad norm: 1.250e-01\n",
      "Epoch 11095, Loss: 0.011764276772737503, Neurons: 64, Grad norm: 1.250e-01\n",
      "Epoch 11096, Loss: 0.011759367771446705, Neurons: 64, Grad norm: 1.005e-01\n",
      "Epoch 11096, Loss: 0.011759367771446705, Neurons: 64, Grad norm: 1.005e-01\n",
      "Epoch 11097, Loss: 0.011754370294511318, Neurons: 64, Grad norm: 1.083e-01\n",
      "Epoch 11097, Loss: 0.011754370294511318, Neurons: 64, Grad norm: 1.083e-01\n",
      "Epoch 11098, Loss: 0.011749518103897572, Neurons: 64, Grad norm: 9.226e-02\n",
      "Epoch 11098, Loss: 0.011749518103897572, Neurons: 64, Grad norm: 9.226e-02\n",
      "Epoch 11099, Loss: 0.011744593270123005, Neurons: 64, Grad norm: 1.046e-01\n",
      "Epoch 11099, Loss: 0.011744593270123005, Neurons: 64, Grad norm: 1.046e-01\n",
      "Epoch 11099, Test loss: 0.00838397815823555\n",
      "Epoch 11099, Test loss: 0.00838397815823555\n",
      "Epoch 11100, Loss: 0.0117396991699934, Neurons: 64, Grad norm: 9.070e-02\n",
      "Epoch 11100, Loss: 0.0117396991699934, Neurons: 64, Grad norm: 9.070e-02\n",
      "Epoch 11101, Loss: 0.01173481810837984, Neurons: 64, Grad norm: 1.074e-01\n",
      "Epoch 11101, Loss: 0.01173481810837984, Neurons: 64, Grad norm: 1.074e-01\n",
      "Epoch 11102, Loss: 0.011729949153959751, Neurons: 64, Grad norm: 9.716e-02\n",
      "Epoch 11102, Loss: 0.011729949153959751, Neurons: 64, Grad norm: 9.716e-02\n",
      "Epoch 11103, Loss: 0.011725128628313541, Neurons: 64, Grad norm: 1.188e-01\n",
      "Epoch 11103, Loss: 0.011725128628313541, Neurons: 64, Grad norm: 1.188e-01\n",
      "Epoch 11104, Loss: 0.011720217764377594, Neurons: 64, Grad norm: 1.086e-01\n",
      "Epoch 11104, Loss: 0.011720217764377594, Neurons: 64, Grad norm: 1.086e-01\n",
      "Epoch 11105, Loss: 0.011715477332472801, Neurons: 64, Grad norm: 1.376e-01\n",
      "Epoch 11105, Loss: 0.011715477332472801, Neurons: 64, Grad norm: 1.376e-01\n",
      "Epoch 11106, Loss: 0.011710639111697674, Neurons: 64, Grad norm: 1.441e-01\n",
      "Epoch 11106, Loss: 0.011710639111697674, Neurons: 64, Grad norm: 1.441e-01\n",
      "Epoch 11107, Loss: 0.011705883778631687, Neurons: 64, Grad norm: 1.809e-01\n",
      "Epoch 11107, Loss: 0.011705883778631687, Neurons: 64, Grad norm: 1.809e-01\n",
      "Epoch 11108, Loss: 0.01170110609382391, Neurons: 64, Grad norm: 1.978e-01\n",
      "Epoch 11108, Loss: 0.01170110609382391, Neurons: 64, Grad norm: 1.978e-01\n",
      "Epoch 11109, Loss: 0.01169650349766016, Neurons: 64, Grad norm: 2.519e-01\n",
      "Epoch 11109, Loss: 0.01169650349766016, Neurons: 64, Grad norm: 2.519e-01\n",
      "Epoch 11110, Loss: 0.011691956780850887, Neurons: 64, Grad norm: 2.855e-01\n",
      "Epoch 11110, Loss: 0.011691956780850887, Neurons: 64, Grad norm: 2.855e-01\n",
      "Epoch 11111, Loss: 0.011687607504427433, Neurons: 64, Grad norm: 3.556e-01\n",
      "Epoch 11111, Loss: 0.011687607504427433, Neurons: 64, Grad norm: 3.556e-01\n",
      "Epoch 11112, Loss: 0.011683414690196514, Neurons: 64, Grad norm: 4.083e-01\n",
      "Epoch 11112, Loss: 0.011683414690196514, Neurons: 64, Grad norm: 4.083e-01\n",
      "Epoch 11113, Loss: 0.011679519899189472, Neurons: 64, Grad norm: 5.086e-01\n",
      "Epoch 11113, Loss: 0.011679519899189472, Neurons: 64, Grad norm: 5.086e-01\n",
      "Epoch 11114, Loss: 0.011675993911921978, Neurons: 64, Grad norm: 5.967e-01\n",
      "Epoch 11114, Loss: 0.011675993911921978, Neurons: 64, Grad norm: 5.967e-01\n",
      "Epoch 11115, Loss: 0.01167306024581194, Neurons: 64, Grad norm: 7.367e-01\n",
      "Epoch 11115, Loss: 0.01167306024581194, Neurons: 64, Grad norm: 7.367e-01\n",
      "Epoch 11116, Loss: 0.011671032756567001, Neurons: 64, Grad norm: 8.787e-01\n",
      "Epoch 11116, Loss: 0.011671032756567001, Neurons: 64, Grad norm: 8.787e-01\n",
      "Epoch 11117, Loss: 0.011670395731925964, Neurons: 64, Grad norm: 1.093e+00\n",
      "Epoch 11117, Loss: 0.011670395731925964, Neurons: 64, Grad norm: 1.093e+00\n",
      "Epoch 11118, Loss: 0.011671949177980423, Neurons: 64, Grad norm: 1.320e+00\n",
      "Epoch 11118, Loss: 0.011671949177980423, Neurons: 64, Grad norm: 1.320e+00\n",
      "Epoch 11119, Loss: 0.011676682159304619, Neurons: 64, Grad norm: 1.634e+00\n",
      "Epoch 11119, Loss: 0.011676682159304619, Neurons: 64, Grad norm: 1.634e+00\n",
      "Epoch 11120, Loss: 0.011686422862112522, Neurons: 64, Grad norm: 1.997e+00\n",
      "Epoch 11120, Loss: 0.011686422862112522, Neurons: 64, Grad norm: 1.997e+00\n",
      "Epoch 11121, Loss: 0.011703956872224808, Neurons: 64, Grad norm: 2.473e+00\n",
      "Epoch 11121, Loss: 0.011703956872224808, Neurons: 64, Grad norm: 2.473e+00\n",
      "Epoch 11122, Loss: 0.01173307653516531, Neurons: 64, Grad norm: 3.031e+00\n",
      "Epoch 11122, Loss: 0.01173307653516531, Neurons: 64, Grad norm: 3.031e+00\n",
      "Epoch 11123, Loss: 0.011779846623539925, Neurons: 64, Grad norm: 3.750e+00\n",
      "Epoch 11123, Loss: 0.011779846623539925, Neurons: 64, Grad norm: 3.750e+00\n",
      "Epoch 11124, Loss: 0.011852789670228958, Neurons: 64, Grad norm: 4.586e+00\n",
      "Epoch 11124, Loss: 0.011852789670228958, Neurons: 64, Grad norm: 4.586e+00\n",
      "Epoch 11125, Loss: 0.01196327805519104, Neurons: 64, Grad norm: 5.608e+00\n",
      "Epoch 11125, Loss: 0.01196327805519104, Neurons: 64, Grad norm: 5.608e+00\n",
      "Epoch 11126, Loss: 0.012124786153435707, Neurons: 64, Grad norm: 6.743e+00\n",
      "Epoch 11126, Loss: 0.012124786153435707, Neurons: 64, Grad norm: 6.743e+00\n",
      "Epoch 11127, Loss: 0.01234845258295536, Neurons: 64, Grad norm: 7.990e+00\n",
      "Epoch 11127, Loss: 0.01234845258295536, Neurons: 64, Grad norm: 7.990e+00\n",
      "Epoch 11128, Loss: 0.01263324823230505, Neurons: 64, Grad norm: 9.152e+00\n",
      "Epoch 11128, Loss: 0.01263324823230505, Neurons: 64, Grad norm: 9.152e+00\n",
      "Epoch 11129, Loss: 0.012946388684213161, Neurons: 64, Grad norm: 1.005e+01\n",
      "Epoch 11129, Loss: 0.012946388684213161, Neurons: 64, Grad norm: 1.005e+01\n",
      "Epoch 11130, Loss: 0.013202358968555927, Neurons: 64, Grad norm: 1.031e+01\n",
      "Epoch 11130, Loss: 0.013202358968555927, Neurons: 64, Grad norm: 1.031e+01\n",
      "Epoch 11131, Loss: 0.013271269388496876, Neurons: 64, Grad norm: 9.665e+00\n",
      "Epoch 11131, Loss: 0.013271269388496876, Neurons: 64, Grad norm: 9.665e+00\n",
      "Epoch 11132, Loss: 0.013041052035987377, Neurons: 64, Grad norm: 7.903e+00\n",
      "Epoch 11132, Loss: 0.013041052035987377, Neurons: 64, Grad norm: 7.903e+00\n",
      "Epoch 11133, Loss: 0.012543469667434692, Neurons: 64, Grad norm: 5.221e+00\n",
      "Epoch 11133, Loss: 0.012543469667434692, Neurons: 64, Grad norm: 5.221e+00\n",
      "Epoch 11134, Loss: 0.011988695710897446, Neurons: 64, Grad norm: 2.051e+00\n",
      "Epoch 11134, Loss: 0.011988695710897446, Neurons: 64, Grad norm: 2.051e+00\n",
      "Epoch 11135, Loss: 0.011646972969174385, Neurons: 64, Grad norm: 1.460e+00\n",
      "Epoch 11135, Loss: 0.011646972969174385, Neurons: 64, Grad norm: 1.460e+00\n",
      "Epoch 11136, Loss: 0.011640540324151516, Neurons: 64, Grad norm: 3.987e+00\n",
      "Epoch 11136, Loss: 0.011640540324151516, Neurons: 64, Grad norm: 3.987e+00\n",
      "Epoch 11137, Loss: 0.011874351650476456, Neurons: 64, Grad norm: 5.648e+00\n",
      "Epoch 11137, Loss: 0.011874351650476456, Neurons: 64, Grad norm: 5.648e+00\n",
      "Epoch 11138, Loss: 0.01212545856833458, Neurons: 64, Grad norm: 6.181e+00\n",
      "Epoch 11138, Loss: 0.01212545856833458, Neurons: 64, Grad norm: 6.181e+00\n",
      "Epoch 11139, Loss: 0.012198138050734997, Neurons: 64, Grad norm: 5.493e+00\n",
      "Epoch 11139, Loss: 0.012198138050734997, Neurons: 64, Grad norm: 5.493e+00\n",
      "Epoch 11140, Loss: 0.012040117755532265, Neurons: 64, Grad norm: 3.849e+00\n",
      "Epoch 11140, Loss: 0.012040117755532265, Neurons: 64, Grad norm: 3.849e+00\n",
      "Epoch 11141, Loss: 0.011772362515330315, Neurons: 64, Grad norm: 1.649e+00\n",
      "Epoch 11141, Loss: 0.011772362515330315, Neurons: 64, Grad norm: 1.649e+00\n",
      "Epoch 11142, Loss: 0.011583476327359676, Neurons: 64, Grad norm: 9.460e-01\n",
      "Epoch 11142, Loss: 0.011583476327359676, Neurons: 64, Grad norm: 9.460e-01\n",
      "Epoch 11143, Loss: 0.011575310491025448, Neurons: 64, Grad norm: 2.719e+00\n",
      "Epoch 11143, Loss: 0.011575310491025448, Neurons: 64, Grad norm: 2.719e+00\n",
      "Epoch 11144, Loss: 0.01169921737164259, Neurons: 64, Grad norm: 3.817e+00\n",
      "Epoch 11144, Loss: 0.01169921737164259, Neurons: 64, Grad norm: 3.817e+00\n",
      "Epoch 11145, Loss: 0.011818517930805683, Neurons: 64, Grad norm: 4.040e+00\n",
      "Epoch 11145, Loss: 0.011818517930805683, Neurons: 64, Grad norm: 4.040e+00\n",
      "Epoch 11146, Loss: 0.011825714260339737, Neurons: 64, Grad norm: 3.357e+00\n",
      "Epoch 11146, Loss: 0.011825714260339737, Neurons: 64, Grad norm: 3.357e+00\n",
      "Epoch 11147, Loss: 0.011716438457369804, Neurons: 64, Grad norm: 2.065e+00\n",
      "Epoch 11147, Loss: 0.011716438457369804, Neurons: 64, Grad norm: 2.065e+00\n",
      "Epoch 11148, Loss: 0.011579904705286026, Neurons: 64, Grad norm: 5.313e-01\n",
      "Epoch 11148, Loss: 0.011579904705286026, Neurons: 64, Grad norm: 5.313e-01\n",
      "Epoch 11149, Loss: 0.011513537727296352, Neurons: 64, Grad norm: 1.149e+00\n",
      "Epoch 11149, Loss: 0.011513537727296352, Neurons: 64, Grad norm: 1.149e+00\n",
      "Epoch 11150, Loss: 0.011543302796781063, Neurons: 64, Grad norm: 2.249e+00\n",
      "Epoch 11150, Loss: 0.011543302796781063, Neurons: 64, Grad norm: 2.249e+00\n",
      "Epoch 11151, Loss: 0.011616096831858158, Neurons: 64, Grad norm: 2.729e+00\n",
      "Epoch 11151, Loss: 0.011616096831858158, Neurons: 64, Grad norm: 2.729e+00\n",
      "Epoch 11152, Loss: 0.011656055226922035, Neurons: 64, Grad norm: 2.583e+00\n",
      "Epoch 11152, Loss: 0.011656055226922035, Neurons: 64, Grad norm: 2.583e+00\n",
      "Epoch 11153, Loss: 0.0116270175203681, Neurons: 64, Grad norm: 1.853e+00\n",
      "Epoch 11153, Loss: 0.0116270175203681, Neurons: 64, Grad norm: 1.853e+00\n",
      "Epoch 11154, Loss: 0.011553321033716202, Neurons: 64, Grad norm: 8.204e-01\n",
      "Epoch 11154, Loss: 0.011553321033716202, Neurons: 64, Grad norm: 8.204e-01\n",
      "Epoch 11155, Loss: 0.011491581797599792, Neurons: 64, Grad norm: 3.361e-01\n",
      "Epoch 11155, Loss: 0.011491581797599792, Neurons: 64, Grad norm: 3.361e-01\n",
      "Epoch 11156, Loss: 0.011478670872747898, Neurons: 64, Grad norm: 1.251e+00\n",
      "Epoch 11156, Loss: 0.011478670872747898, Neurons: 64, Grad norm: 1.251e+00\n",
      "Epoch 11157, Loss: 0.01150752417743206, Neurons: 64, Grad norm: 1.828e+00\n",
      "Epoch 11157, Loss: 0.01150752417743206, Neurons: 64, Grad norm: 1.828e+00\n",
      "Epoch 11158, Loss: 0.011540341190993786, Neurons: 64, Grad norm: 1.921e+00\n",
      "Epoch 11158, Loss: 0.011540341190993786, Neurons: 64, Grad norm: 1.921e+00\n",
      "Epoch 11159, Loss: 0.011543861590325832, Neurons: 64, Grad norm: 1.611e+00\n",
      "Epoch 11159, Loss: 0.011543861590325832, Neurons: 64, Grad norm: 1.611e+00\n",
      "Epoch 11160, Loss: 0.011514351703226566, Neurons: 64, Grad norm: 9.507e-01\n",
      "Epoch 11160, Loss: 0.011514351703226566, Neurons: 64, Grad norm: 9.507e-01\n",
      "Epoch 11161, Loss: 0.011473621241748333, Neurons: 64, Grad norm: 1.779e-01\n",
      "Epoch 11161, Loss: 0.011473621241748333, Neurons: 64, Grad norm: 1.779e-01\n",
      "Epoch 11162, Loss: 0.01144898496568203, Neurons: 64, Grad norm: 5.963e-01\n",
      "Epoch 11162, Loss: 0.01144898496568203, Neurons: 64, Grad norm: 5.963e-01\n",
      "Epoch 11163, Loss: 0.011450217105448246, Neurons: 64, Grad norm: 1.132e+00\n",
      "Epoch 11163, Loss: 0.011450217105448246, Neurons: 64, Grad norm: 1.132e+00\n",
      "Epoch 11164, Loss: 0.011465798132121563, Neurons: 64, Grad norm: 1.407e+00\n",
      "Epoch 11164, Loss: 0.011465798132121563, Neurons: 64, Grad norm: 1.407e+00\n",
      "Epoch 11165, Loss: 0.01147579587996006, Neurons: 64, Grad norm: 1.333e+00\n",
      "Epoch 11165, Loss: 0.01147579587996006, Neurons: 64, Grad norm: 1.333e+00\n",
      "Epoch 11166, Loss: 0.011468742042779922, Neurons: 64, Grad norm: 1.009e+00\n",
      "Epoch 11166, Loss: 0.011468742042779922, Neurons: 64, Grad norm: 1.009e+00\n",
      "Epoch 11167, Loss: 0.011448428966104984, Neurons: 64, Grad norm: 4.839e-01\n",
      "Epoch 11167, Loss: 0.011448428966104984, Neurons: 64, Grad norm: 4.839e-01\n",
      "Epoch 11168, Loss: 0.011427461169660091, Neurons: 64, Grad norm: 1.123e-01\n",
      "Epoch 11168, Loss: 0.011427461169660091, Neurons: 64, Grad norm: 1.123e-01\n",
      "Epoch 11169, Loss: 0.011417006142437458, Neurons: 64, Grad norm: 5.967e-01\n",
      "Epoch 11169, Loss: 0.011417006142437458, Neurons: 64, Grad norm: 5.967e-01\n",
      "Epoch 11170, Loss: 0.011417986825108528, Neurons: 64, Grad norm: 9.190e-01\n",
      "Epoch 11170, Loss: 0.011417986825108528, Neurons: 64, Grad norm: 9.190e-01\n",
      "Epoch 11171, Loss: 0.011423230171203613, Neurons: 64, Grad norm: 1.057e+00\n",
      "Epoch 11171, Loss: 0.011423230171203613, Neurons: 64, Grad norm: 1.057e+00\n",
      "Epoch 11172, Loss: 0.011423876509070396, Neurons: 64, Grad norm: 9.533e-01\n",
      "Epoch 11172, Loss: 0.011423876509070396, Neurons: 64, Grad norm: 9.533e-01\n",
      "Epoch 11173, Loss: 0.011416466906666756, Neurons: 64, Grad norm: 7.021e-01\n",
      "Epoch 11173, Loss: 0.011416466906666756, Neurons: 64, Grad norm: 7.021e-01\n",
      "Epoch 11174, Loss: 0.011403909884393215, Neurons: 64, Grad norm: 3.127e-01\n",
      "Epoch 11174, Loss: 0.011403909884393215, Neurons: 64, Grad norm: 3.127e-01\n",
      "Epoch 11175, Loss: 0.011392057873308659, Neurons: 64, Grad norm: 8.593e-02\n",
      "Epoch 11175, Loss: 0.011392057873308659, Neurons: 64, Grad norm: 8.593e-02\n",
      "Epoch 11176, Loss: 0.011385531164705753, Neurons: 64, Grad norm: 4.447e-01\n",
      "Epoch 11176, Loss: 0.011385531164705753, Neurons: 64, Grad norm: 4.447e-01\n",
      "Epoch 11177, Loss: 0.011384153738617897, Neurons: 64, Grad norm: 6.641e-01\n",
      "Epoch 11177, Loss: 0.011384153738617897, Neurons: 64, Grad norm: 6.641e-01\n",
      "Epoch 11178, Loss: 0.011384584940969944, Neurons: 64, Grad norm: 7.737e-01\n",
      "Epoch 11178, Loss: 0.011384584940969944, Neurons: 64, Grad norm: 7.737e-01\n",
      "Epoch 11179, Loss: 0.011382611468434334, Neurons: 64, Grad norm: 7.088e-01\n",
      "Epoch 11179, Loss: 0.011382611468434334, Neurons: 64, Grad norm: 7.088e-01\n",
      "Epoch 11180, Loss: 0.011376856826245785, Neurons: 64, Grad norm: 5.497e-01\n",
      "Epoch 11180, Loss: 0.011376856826245785, Neurons: 64, Grad norm: 5.497e-01\n",
      "Epoch 11181, Loss: 0.01136846374720335, Neurons: 64, Grad norm: 2.846e-01\n",
      "Epoch 11181, Loss: 0.01136846374720335, Neurons: 64, Grad norm: 2.846e-01\n",
      "Epoch 11182, Loss: 0.011360293254256248, Neurons: 64, Grad norm: 3.040e-02\n",
      "Epoch 11182, Loss: 0.011360293254256248, Neurons: 64, Grad norm: 3.040e-02\n",
      "Epoch 11183, Loss: 0.011354220099747181, Neurons: 64, Grad norm: 2.409e-01\n",
      "Epoch 11183, Loss: 0.011354220099747181, Neurons: 64, Grad norm: 2.409e-01\n",
      "Epoch 11184, Loss: 0.011350725777447224, Neurons: 64, Grad norm: 4.137e-01\n",
      "Epoch 11184, Loss: 0.011350725777447224, Neurons: 64, Grad norm: 4.137e-01\n",
      "Epoch 11185, Loss: 0.01134841050952673, Neurons: 64, Grad norm: 5.273e-01\n",
      "Epoch 11185, Loss: 0.01134841050952673, Neurons: 64, Grad norm: 5.273e-01\n",
      "Epoch 11186, Loss: 0.011345633305609226, Neurons: 64, Grad norm: 5.175e-01\n",
      "Epoch 11186, Loss: 0.011345633305609226, Neurons: 64, Grad norm: 5.175e-01\n",
      "Epoch 11187, Loss: 0.011341234669089317, Neurons: 64, Grad norm: 4.541e-01\n",
      "Epoch 11187, Loss: 0.011341234669089317, Neurons: 64, Grad norm: 4.541e-01\n",
      "Epoch 11188, Loss: 0.011335459537804127, Neurons: 64, Grad norm: 3.038e-01\n",
      "Epoch 11188, Loss: 0.011335459537804127, Neurons: 64, Grad norm: 3.038e-01\n",
      "Epoch 11189, Loss: 0.011329231783747673, Neurons: 64, Grad norm: 1.529e-01\n",
      "Epoch 11189, Loss: 0.011329231783747673, Neurons: 64, Grad norm: 1.529e-01\n",
      "Epoch 11190, Loss: 0.011323678307235241, Neurons: 64, Grad norm: 7.216e-02\n",
      "Epoch 11190, Loss: 0.011323678307235241, Neurons: 64, Grad norm: 7.216e-02\n",
      "Epoch 11191, Loss: 0.011319151148200035, Neurons: 64, Grad norm: 1.832e-01\n",
      "Epoch 11191, Loss: 0.011319151148200035, Neurons: 64, Grad norm: 1.832e-01\n",
      "Epoch 11192, Loss: 0.011315514333546162, Neurons: 64, Grad norm: 2.907e-01\n",
      "Epoch 11192, Loss: 0.011315514333546162, Neurons: 64, Grad norm: 2.907e-01\n",
      "Epoch 11193, Loss: 0.011311872862279415, Neurons: 64, Grad norm: 3.166e-01\n",
      "Epoch 11193, Loss: 0.011311872862279415, Neurons: 64, Grad norm: 3.166e-01\n",
      "Epoch 11194, Loss: 0.011307850480079651, Neurons: 64, Grad norm: 3.139e-01\n",
      "Epoch 11194, Loss: 0.011307850480079651, Neurons: 64, Grad norm: 3.139e-01\n",
      "Epoch 11195, Loss: 0.011303216218948364, Neurons: 64, Grad norm: 2.369e-01\n",
      "Epoch 11195, Loss: 0.011303216218948364, Neurons: 64, Grad norm: 2.369e-01\n",
      "Epoch 11196, Loss: 0.011297867633402348, Neurons: 64, Grad norm: 1.590e-01\n",
      "Epoch 11196, Loss: 0.011297867633402348, Neurons: 64, Grad norm: 1.590e-01\n",
      "Epoch 11197, Loss: 0.011292786337435246, Neurons: 64, Grad norm: 4.922e-02\n",
      "Epoch 11197, Loss: 0.011292786337435246, Neurons: 64, Grad norm: 4.922e-02\n",
      "Epoch 11198, Loss: 0.011288132518529892, Neurons: 64, Grad norm: 5.992e-02\n",
      "Epoch 11198, Loss: 0.011288132518529892, Neurons: 64, Grad norm: 5.992e-02\n",
      "Epoch 11199, Loss: 0.011283867061138153, Neurons: 64, Grad norm: 1.476e-01\n",
      "Epoch 11199, Loss: 0.011283867061138153, Neurons: 64, Grad norm: 1.476e-01\n",
      "Epoch 11199, Test loss: 0.00812595896422863\n",
      "Epoch 11199, Test loss: 0.00812595896422863\n",
      "Epoch 11200, Loss: 0.011279831640422344, Neurons: 64, Grad norm: 1.773e-01\n",
      "Epoch 11200, Loss: 0.011279831640422344, Neurons: 64, Grad norm: 1.773e-01\n",
      "Epoch 11201, Loss: 0.011275858618319035, Neurons: 64, Grad norm: 2.034e-01\n",
      "Epoch 11201, Loss: 0.011275858618319035, Neurons: 64, Grad norm: 2.034e-01\n",
      "Epoch 11202, Loss: 0.011271616443991661, Neurons: 64, Grad norm: 1.740e-01\n",
      "Epoch 11202, Loss: 0.011271616443991661, Neurons: 64, Grad norm: 1.740e-01\n",
      "Epoch 11203, Loss: 0.011266935616731644, Neurons: 64, Grad norm: 1.447e-01\n",
      "Epoch 11203, Loss: 0.011266935616731644, Neurons: 64, Grad norm: 1.447e-01\n",
      "Epoch 11204, Loss: 0.011262254789471626, Neurons: 64, Grad norm: 7.105e-02\n",
      "Epoch 11204, Loss: 0.011262254789471626, Neurons: 64, Grad norm: 7.105e-02\n",
      "Epoch 11205, Loss: 0.01125757023692131, Neurons: 64, Grad norm: 3.074e-02\n",
      "Epoch 11205, Loss: 0.01125757023692131, Neurons: 64, Grad norm: 3.074e-02\n",
      "Epoch 11206, Loss: 0.01125301793217659, Neurons: 64, Grad norm: 6.794e-02\n",
      "Epoch 11206, Loss: 0.01125301793217659, Neurons: 64, Grad norm: 6.794e-02\n",
      "Epoch 11207, Loss: 0.011248628608882427, Neurons: 64, Grad norm: 1.008e-01\n",
      "Epoch 11207, Loss: 0.011248628608882427, Neurons: 64, Grad norm: 1.008e-01\n",
      "Epoch 11208, Loss: 0.011244358494877815, Neurons: 64, Grad norm: 1.501e-01\n",
      "Epoch 11208, Loss: 0.011244358494877815, Neurons: 64, Grad norm: 1.501e-01\n",
      "Epoch 11209, Loss: 0.011240258812904358, Neurons: 64, Grad norm: 1.456e-01\n",
      "Epoch 11209, Loss: 0.011240258812904358, Neurons: 64, Grad norm: 1.456e-01\n",
      "Epoch 11210, Loss: 0.011235891841351986, Neurons: 64, Grad norm: 1.478e-01\n",
      "Epoch 11210, Loss: 0.011235891841351986, Neurons: 64, Grad norm: 1.478e-01\n",
      "Epoch 11211, Loss: 0.011231508105993271, Neurons: 64, Grad norm: 1.091e-01\n",
      "Epoch 11211, Loss: 0.011231508105993271, Neurons: 64, Grad norm: 1.091e-01\n",
      "Epoch 11212, Loss: 0.011226968839764595, Neurons: 64, Grad norm: 8.787e-02\n",
      "Epoch 11212, Loss: 0.011226968839764595, Neurons: 64, Grad norm: 8.787e-02\n",
      "Epoch 11213, Loss: 0.011222575791180134, Neurons: 64, Grad norm: 3.195e-02\n",
      "Epoch 11213, Loss: 0.011222575791180134, Neurons: 64, Grad norm: 3.195e-02\n",
      "Epoch 11214, Loss: 0.011218096129596233, Neurons: 64, Grad norm: 2.259e-02\n",
      "Epoch 11214, Loss: 0.011218096129596233, Neurons: 64, Grad norm: 2.259e-02\n",
      "Epoch 11215, Loss: 0.011213680729269981, Neurons: 64, Grad norm: 6.305e-02\n",
      "Epoch 11215, Loss: 0.011213680729269981, Neurons: 64, Grad norm: 6.305e-02\n",
      "Epoch 11216, Loss: 0.011209356598556042, Neurons: 64, Grad norm: 7.745e-02\n",
      "Epoch 11216, Loss: 0.011209356598556042, Neurons: 64, Grad norm: 7.745e-02\n",
      "Epoch 11217, Loss: 0.011205127462744713, Neurons: 64, Grad norm: 1.147e-01\n",
      "Epoch 11217, Loss: 0.011205127462744713, Neurons: 64, Grad norm: 1.147e-01\n",
      "Epoch 11218, Loss: 0.011200802400708199, Neurons: 64, Grad norm: 1.126e-01\n",
      "Epoch 11218, Loss: 0.011200802400708199, Neurons: 64, Grad norm: 1.126e-01\n",
      "Epoch 11219, Loss: 0.011196481995284557, Neurons: 64, Grad norm: 1.248e-01\n",
      "Epoch 11219, Loss: 0.011196481995284557, Neurons: 64, Grad norm: 1.248e-01\n",
      "Epoch 11220, Loss: 0.011192184872925282, Neurons: 64, Grad norm: 1.059e-01\n",
      "Epoch 11220, Loss: 0.011192184872925282, Neurons: 64, Grad norm: 1.059e-01\n",
      "Epoch 11221, Loss: 0.011187747120857239, Neurons: 64, Grad norm: 1.107e-01\n",
      "Epoch 11221, Loss: 0.011187747120857239, Neurons: 64, Grad norm: 1.107e-01\n",
      "Epoch 11222, Loss: 0.011183436028659344, Neurons: 64, Grad norm: 7.799e-02\n",
      "Epoch 11222, Loss: 0.011183436028659344, Neurons: 64, Grad norm: 7.799e-02\n",
      "Epoch 11223, Loss: 0.01117908675223589, Neurons: 64, Grad norm: 6.778e-02\n",
      "Epoch 11223, Loss: 0.01117908675223589, Neurons: 64, Grad norm: 6.778e-02\n",
      "Epoch 11224, Loss: 0.011174751445651054, Neurons: 64, Grad norm: 4.965e-02\n",
      "Epoch 11224, Loss: 0.011174751445651054, Neurons: 64, Grad norm: 4.965e-02\n",
      "Epoch 11225, Loss: 0.011170374229550362, Neurons: 64, Grad norm: 5.963e-02\n",
      "Epoch 11225, Loss: 0.011170374229550362, Neurons: 64, Grad norm: 5.963e-02\n",
      "Epoch 11226, Loss: 0.011166069656610489, Neurons: 64, Grad norm: 6.514e-02\n",
      "Epoch 11226, Loss: 0.011166069656610489, Neurons: 64, Grad norm: 6.514e-02\n",
      "Epoch 11227, Loss: 0.011161796748638153, Neurons: 64, Grad norm: 7.354e-02\n",
      "Epoch 11227, Loss: 0.011161796748638153, Neurons: 64, Grad norm: 7.354e-02\n",
      "Epoch 11228, Loss: 0.01115779671818018, Neurons: 64, Grad norm: 8.814e-02\n",
      "Epoch 11228, Loss: 0.01115779671818018, Neurons: 64, Grad norm: 8.814e-02\n",
      "Epoch 11229, Loss: 0.011153561063110828, Neurons: 64, Grad norm: 9.436e-02\n",
      "Epoch 11229, Loss: 0.011153561063110828, Neurons: 64, Grad norm: 9.436e-02\n",
      "Epoch 11230, Loss: 0.011149297468364239, Neurons: 64, Grad norm: 1.027e-01\n",
      "Epoch 11230, Loss: 0.011149297468364239, Neurons: 64, Grad norm: 1.027e-01\n",
      "Epoch 11231, Loss: 0.011145040392875671, Neurons: 64, Grad norm: 1.185e-01\n",
      "Epoch 11231, Loss: 0.011145040392875671, Neurons: 64, Grad norm: 1.185e-01\n",
      "Epoch 11232, Loss: 0.011140703223645687, Neurons: 64, Grad norm: 1.397e-01\n",
      "Epoch 11232, Loss: 0.011140703223645687, Neurons: 64, Grad norm: 1.397e-01\n",
      "Epoch 11233, Loss: 0.011136744171380997, Neurons: 64, Grad norm: 1.753e-01\n",
      "Epoch 11233, Loss: 0.011136744171380997, Neurons: 64, Grad norm: 1.753e-01\n",
      "Epoch 11234, Loss: 0.011132604442536831, Neurons: 64, Grad norm: 1.990e-01\n",
      "Epoch 11234, Loss: 0.011132604442536831, Neurons: 64, Grad norm: 1.990e-01\n",
      "Epoch 11235, Loss: 0.011128745041787624, Neurons: 64, Grad norm: 2.475e-01\n",
      "Epoch 11235, Loss: 0.011128745041787624, Neurons: 64, Grad norm: 2.475e-01\n",
      "Epoch 11236, Loss: 0.011124745942652225, Neurons: 64, Grad norm: 2.834e-01\n",
      "Epoch 11236, Loss: 0.011124745942652225, Neurons: 64, Grad norm: 2.834e-01\n",
      "Epoch 11237, Loss: 0.011121134273707867, Neurons: 64, Grad norm: 3.389e-01\n",
      "Epoch 11237, Loss: 0.011121134273707867, Neurons: 64, Grad norm: 3.389e-01\n",
      "Epoch 11238, Loss: 0.011117691174149513, Neurons: 64, Grad norm: 3.839e-01\n",
      "Epoch 11238, Loss: 0.011117691174149513, Neurons: 64, Grad norm: 3.839e-01\n",
      "Epoch 11239, Loss: 0.011114653199911118, Neurons: 64, Grad norm: 4.538e-01\n",
      "Epoch 11239, Loss: 0.011114653199911118, Neurons: 64, Grad norm: 4.538e-01\n",
      "Epoch 11240, Loss: 0.011111870408058167, Neurons: 64, Grad norm: 5.113e-01\n",
      "Epoch 11240, Loss: 0.011111870408058167, Neurons: 64, Grad norm: 5.113e-01\n",
      "Epoch 11241, Loss: 0.011109646409749985, Neurons: 64, Grad norm: 5.952e-01\n",
      "Epoch 11241, Loss: 0.011109646409749985, Neurons: 64, Grad norm: 5.952e-01\n",
      "Epoch 11242, Loss: 0.011108064092695713, Neurons: 64, Grad norm: 6.715e-01\n",
      "Epoch 11242, Loss: 0.011108064092695713, Neurons: 64, Grad norm: 6.715e-01\n",
      "Epoch 11243, Loss: 0.011107231490314007, Neurons: 64, Grad norm: 7.822e-01\n",
      "Epoch 11243, Loss: 0.011107231490314007, Neurons: 64, Grad norm: 7.822e-01\n",
      "Epoch 11244, Loss: 0.011107541620731354, Neurons: 64, Grad norm: 8.969e-01\n",
      "Epoch 11244, Loss: 0.011107541620731354, Neurons: 64, Grad norm: 8.969e-01\n",
      "Epoch 11245, Loss: 0.011109820567071438, Neurons: 64, Grad norm: 1.053e+00\n",
      "Epoch 11245, Loss: 0.011109820567071438, Neurons: 64, Grad norm: 1.053e+00\n",
      "Epoch 11246, Loss: 0.011114425957202911, Neurons: 64, Grad norm: 1.216e+00\n",
      "Epoch 11246, Loss: 0.011114425957202911, Neurons: 64, Grad norm: 1.216e+00\n",
      "Epoch 11247, Loss: 0.011122786439955235, Neurons: 64, Grad norm: 1.430e+00\n",
      "Epoch 11247, Loss: 0.011122786439955235, Neurons: 64, Grad norm: 1.430e+00\n",
      "Epoch 11248, Loss: 0.011135326698422432, Neurons: 64, Grad norm: 1.662e+00\n",
      "Epoch 11248, Loss: 0.011135326698422432, Neurons: 64, Grad norm: 1.662e+00\n",
      "Epoch 11249, Loss: 0.011154338717460632, Neurons: 64, Grad norm: 1.951e+00\n",
      "Epoch 11249, Loss: 0.011154338717460632, Neurons: 64, Grad norm: 1.951e+00\n",
      "Epoch 11250, Loss: 0.011180367320775986, Neurons: 64, Grad norm: 2.260e+00\n",
      "Epoch 11250, Loss: 0.011180367320775986, Neurons: 64, Grad norm: 2.260e+00\n",
      "Epoch 11251, Loss: 0.011215968988835812, Neurons: 64, Grad norm: 2.623e+00\n",
      "Epoch 11251, Loss: 0.011215968988835812, Neurons: 64, Grad norm: 2.623e+00\n",
      "Epoch 11252, Loss: 0.011260585859417915, Neurons: 64, Grad norm: 2.998e+00\n",
      "Epoch 11252, Loss: 0.011260585859417915, Neurons: 64, Grad norm: 2.998e+00\n",
      "Epoch 11253, Loss: 0.011314531788229942, Neurons: 64, Grad norm: 3.406e+00\n",
      "Epoch 11253, Loss: 0.011314531788229942, Neurons: 64, Grad norm: 3.406e+00\n",
      "Epoch 11254, Loss: 0.011372593231499195, Neurons: 64, Grad norm: 3.781e+00\n",
      "Epoch 11254, Loss: 0.011372593231499195, Neurons: 64, Grad norm: 3.781e+00\n",
      "Epoch 11255, Loss: 0.011428547091782093, Neurons: 64, Grad norm: 4.124e+00\n",
      "Epoch 11255, Loss: 0.011428547091782093, Neurons: 64, Grad norm: 4.124e+00\n",
      "Epoch 11256, Loss: 0.011468685232102871, Neurons: 64, Grad norm: 4.347e+00\n",
      "Epoch 11256, Loss: 0.011468685232102871, Neurons: 64, Grad norm: 4.347e+00\n",
      "Epoch 11257, Loss: 0.01148235984146595, Neurons: 64, Grad norm: 4.452e+00\n",
      "Epoch 11257, Loss: 0.01148235984146595, Neurons: 64, Grad norm: 4.452e+00\n",
      "Epoch 11258, Loss: 0.011458218097686768, Neurons: 64, Grad norm: 4.358e+00\n",
      "Epoch 11258, Loss: 0.011458218097686768, Neurons: 64, Grad norm: 4.358e+00\n",
      "Epoch 11259, Loss: 0.011398411355912685, Neurons: 64, Grad norm: 4.097e+00\n",
      "Epoch 11259, Loss: 0.011398411355912685, Neurons: 64, Grad norm: 4.097e+00\n",
      "Epoch 11260, Loss: 0.011315282434225082, Neurons: 64, Grad norm: 3.640e+00\n",
      "Epoch 11260, Loss: 0.011315282434225082, Neurons: 64, Grad norm: 3.640e+00\n",
      "Epoch 11261, Loss: 0.011228733696043491, Neurons: 64, Grad norm: 3.066e+00\n",
      "Epoch 11261, Loss: 0.011228733696043491, Neurons: 64, Grad norm: 3.066e+00\n",
      "Epoch 11262, Loss: 0.011154689826071262, Neurons: 64, Grad norm: 2.375e+00\n",
      "Epoch 11262, Loss: 0.011154689826071262, Neurons: 64, Grad norm: 2.375e+00\n",
      "Epoch 11263, Loss: 0.011101740412414074, Neurons: 64, Grad norm: 1.692e+00\n",
      "Epoch 11263, Loss: 0.011101740412414074, Neurons: 64, Grad norm: 1.692e+00\n",
      "Epoch 11264, Loss: 0.011069477535784245, Neurons: 64, Grad norm: 1.071e+00\n",
      "Epoch 11264, Loss: 0.011069477535784245, Neurons: 64, Grad norm: 1.071e+00\n",
      "Epoch 11265, Loss: 0.011052355170249939, Neurons: 64, Grad norm: 8.514e-01\n",
      "Epoch 11265, Loss: 0.011052355170249939, Neurons: 64, Grad norm: 8.514e-01\n",
      "Epoch 11266, Loss: 0.011044954881072044, Neurons: 64, Grad norm: 1.159e+00\n",
      "Epoch 11266, Loss: 0.011044954881072044, Neurons: 64, Grad norm: 1.159e+00\n",
      "Epoch 11267, Loss: 0.011043735779821873, Neurons: 64, Grad norm: 1.618e+00\n",
      "Epoch 11267, Loss: 0.011043735779821873, Neurons: 64, Grad norm: 1.618e+00\n",
      "Epoch 11268, Loss: 0.011047417297959328, Neurons: 64, Grad norm: 2.048e+00\n",
      "Epoch 11268, Loss: 0.011047417297959328, Neurons: 64, Grad norm: 2.048e+00\n",
      "Epoch 11269, Loss: 0.01105496659874916, Neurons: 64, Grad norm: 2.338e+00\n",
      "Epoch 11269, Loss: 0.01105496659874916, Neurons: 64, Grad norm: 2.338e+00\n",
      "Epoch 11270, Loss: 0.01106415968388319, Neurons: 64, Grad norm: 2.507e+00\n",
      "Epoch 11270, Loss: 0.01106415968388319, Neurons: 64, Grad norm: 2.507e+00\n",
      "Epoch 11271, Loss: 0.011070680804550648, Neurons: 64, Grad norm: 2.496e+00\n",
      "Epoch 11271, Loss: 0.011070680804550648, Neurons: 64, Grad norm: 2.496e+00\n",
      "Epoch 11272, Loss: 0.011069953441619873, Neurons: 64, Grad norm: 2.360e+00\n",
      "Epoch 11272, Loss: 0.011069953441619873, Neurons: 64, Grad norm: 2.360e+00\n",
      "Epoch 11273, Loss: 0.011058743111789227, Neurons: 64, Grad norm: 2.058e+00\n",
      "Epoch 11273, Loss: 0.011058743111789227, Neurons: 64, Grad norm: 2.058e+00\n",
      "Epoch 11274, Loss: 0.011037363670766354, Neurons: 64, Grad norm: 1.676e+00\n",
      "Epoch 11274, Loss: 0.011037363670766354, Neurons: 64, Grad norm: 1.676e+00\n",
      "Epoch 11275, Loss: 0.011009879410266876, Neurons: 64, Grad norm: 1.188e+00\n",
      "Epoch 11275, Loss: 0.011009879410266876, Neurons: 64, Grad norm: 1.188e+00\n",
      "Epoch 11276, Loss: 0.010982307605445385, Neurons: 64, Grad norm: 6.898e-01\n",
      "Epoch 11276, Loss: 0.010982307605445385, Neurons: 64, Grad norm: 6.898e-01\n",
      "Epoch 11277, Loss: 0.0109604112803936, Neurons: 64, Grad norm: 1.704e-01\n",
      "Epoch 11277, Loss: 0.0109604112803936, Neurons: 64, Grad norm: 1.704e-01\n",
      "Epoch 11278, Loss: 0.010947630740702152, Neurons: 64, Grad norm: 2.878e-01\n",
      "Epoch 11278, Loss: 0.010947630740702152, Neurons: 64, Grad norm: 2.878e-01\n",
      "Epoch 11279, Loss: 0.010944214649498463, Neurons: 64, Grad norm: 7.041e-01\n",
      "Epoch 11279, Loss: 0.010944214649498463, Neurons: 64, Grad norm: 7.041e-01\n",
      "Epoch 11280, Loss: 0.01094741653650999, Neurons: 64, Grad norm: 1.009e+00\n",
      "Epoch 11280, Loss: 0.01094741653650999, Neurons: 64, Grad norm: 1.009e+00\n",
      "Epoch 11281, Loss: 0.010953276418149471, Neurons: 64, Grad norm: 1.249e+00\n",
      "Epoch 11281, Loss: 0.010953276418149471, Neurons: 64, Grad norm: 1.249e+00\n",
      "Epoch 11282, Loss: 0.010957826860249043, Neurons: 64, Grad norm: 1.365e+00\n",
      "Epoch 11282, Loss: 0.010957826860249043, Neurons: 64, Grad norm: 1.365e+00\n",
      "Epoch 11283, Loss: 0.010958809405565262, Neurons: 64, Grad norm: 1.421e+00\n",
      "Epoch 11283, Loss: 0.010958809405565262, Neurons: 64, Grad norm: 1.421e+00\n",
      "Epoch 11284, Loss: 0.010955448262393475, Neurons: 64, Grad norm: 1.374e+00\n",
      "Epoch 11284, Loss: 0.010955448262393475, Neurons: 64, Grad norm: 1.374e+00\n",
      "Epoch 11285, Loss: 0.010948547162115574, Neurons: 64, Grad norm: 1.295e+00\n",
      "Epoch 11285, Loss: 0.010948547162115574, Neurons: 64, Grad norm: 1.295e+00\n",
      "Epoch 11286, Loss: 0.010939552448689938, Neurons: 64, Grad norm: 1.142e+00\n",
      "Epoch 11286, Loss: 0.010939552448689938, Neurons: 64, Grad norm: 1.142e+00\n",
      "Epoch 11287, Loss: 0.010930053889751434, Neurons: 64, Grad norm: 9.919e-01\n",
      "Epoch 11287, Loss: 0.010930053889751434, Neurons: 64, Grad norm: 9.919e-01\n",
      "Epoch 11288, Loss: 0.010921429842710495, Neurons: 64, Grad norm: 8.078e-01\n",
      "Epoch 11288, Loss: 0.010921429842710495, Neurons: 64, Grad norm: 8.078e-01\n",
      "Epoch 11289, Loss: 0.010914075188338757, Neurons: 64, Grad norm: 6.511e-01\n",
      "Epoch 11289, Loss: 0.010914075188338757, Neurons: 64, Grad norm: 6.511e-01\n",
      "Epoch 11290, Loss: 0.010907718911767006, Neurons: 64, Grad norm: 4.912e-01\n",
      "Epoch 11290, Loss: 0.010907718911767006, Neurons: 64, Grad norm: 4.912e-01\n",
      "Epoch 11291, Loss: 0.010901980102062225, Neurons: 64, Grad norm: 3.674e-01\n",
      "Epoch 11291, Loss: 0.010901980102062225, Neurons: 64, Grad norm: 3.674e-01\n",
      "Epoch 11292, Loss: 0.010896299034357071, Neurons: 64, Grad norm: 2.745e-01\n",
      "Epoch 11292, Loss: 0.010896299034357071, Neurons: 64, Grad norm: 2.745e-01\n",
      "Epoch 11293, Loss: 0.01089064497500658, Neurons: 64, Grad norm: 2.315e-01\n",
      "Epoch 11293, Loss: 0.01089064497500658, Neurons: 64, Grad norm: 2.315e-01\n",
      "Epoch 11294, Loss: 0.010885018855333328, Neurons: 64, Grad norm: 2.641e-01\n",
      "Epoch 11294, Loss: 0.010885018855333328, Neurons: 64, Grad norm: 2.641e-01\n",
      "Epoch 11295, Loss: 0.01087983138859272, Neurons: 64, Grad norm: 3.081e-01\n",
      "Epoch 11295, Loss: 0.01087983138859272, Neurons: 64, Grad norm: 3.081e-01\n",
      "Epoch 11296, Loss: 0.010875350795686245, Neurons: 64, Grad norm: 3.901e-01\n",
      "Epoch 11296, Loss: 0.010875350795686245, Neurons: 64, Grad norm: 3.901e-01\n",
      "Epoch 11297, Loss: 0.010871732607483864, Neurons: 64, Grad norm: 4.453e-01\n",
      "Epoch 11297, Loss: 0.010871732607483864, Neurons: 64, Grad norm: 4.453e-01\n",
      "Epoch 11298, Loss: 0.010868769139051437, Neurons: 64, Grad norm: 5.178e-01\n",
      "Epoch 11298, Loss: 0.010868769139051437, Neurons: 64, Grad norm: 5.178e-01\n",
      "Epoch 11299, Loss: 0.010866215452551842, Neurons: 64, Grad norm: 5.547e-01\n",
      "Epoch 11299, Loss: 0.010866215452551842, Neurons: 64, Grad norm: 5.547e-01\n",
      "Epoch 11299, Test loss: 0.007856449112296104\n",
      "Epoch 11299, Test loss: 0.007856449112296104\n",
      "Epoch 11300, Loss: 0.010863693431019783, Neurons: 64, Grad norm: 6.029e-01\n",
      "Epoch 11300, Loss: 0.010863693431019783, Neurons: 64, Grad norm: 6.029e-01\n",
      "Epoch 11301, Loss: 0.010860947892069817, Neurons: 64, Grad norm: 6.229e-01\n",
      "Epoch 11301, Loss: 0.010860947892069817, Neurons: 64, Grad norm: 6.229e-01\n",
      "Epoch 11302, Loss: 0.010857870802283287, Neurons: 64, Grad norm: 6.596e-01\n",
      "Epoch 11302, Loss: 0.010857870802283287, Neurons: 64, Grad norm: 6.596e-01\n",
      "Epoch 11303, Loss: 0.010854395106434822, Neurons: 64, Grad norm: 6.625e-01\n",
      "Epoch 11303, Loss: 0.010854395106434822, Neurons: 64, Grad norm: 6.625e-01\n",
      "Epoch 11304, Loss: 0.010850559920072556, Neurons: 64, Grad norm: 6.854e-01\n",
      "Epoch 11304, Loss: 0.010850559920072556, Neurons: 64, Grad norm: 6.854e-01\n",
      "Epoch 11305, Loss: 0.010846384800970554, Neurons: 64, Grad norm: 6.842e-01\n",
      "Epoch 11305, Loss: 0.010846384800970554, Neurons: 64, Grad norm: 6.842e-01\n",
      "Epoch 11306, Loss: 0.010842075571417809, Neurons: 64, Grad norm: 7.004e-01\n",
      "Epoch 11306, Loss: 0.010842075571417809, Neurons: 64, Grad norm: 7.004e-01\n",
      "Epoch 11307, Loss: 0.010837653651833534, Neurons: 64, Grad norm: 6.899e-01\n",
      "Epoch 11307, Loss: 0.010837653651833534, Neurons: 64, Grad norm: 6.899e-01\n",
      "Epoch 11308, Loss: 0.010833224281668663, Neurons: 64, Grad norm: 7.056e-01\n",
      "Epoch 11308, Loss: 0.010833224281668663, Neurons: 64, Grad norm: 7.056e-01\n",
      "Epoch 11309, Loss: 0.010828886181116104, Neurons: 64, Grad norm: 6.980e-01\n",
      "Epoch 11309, Loss: 0.010828886181116104, Neurons: 64, Grad norm: 6.980e-01\n",
      "Epoch 11310, Loss: 0.010824776254594326, Neurons: 64, Grad norm: 7.208e-01\n",
      "Epoch 11310, Loss: 0.010824776254594326, Neurons: 64, Grad norm: 7.208e-01\n",
      "Epoch 11311, Loss: 0.010820846073329449, Neurons: 64, Grad norm: 7.153e-01\n",
      "Epoch 11311, Loss: 0.010820846073329449, Neurons: 64, Grad norm: 7.153e-01\n",
      "Epoch 11312, Loss: 0.010817032307386398, Neurons: 64, Grad norm: 7.369e-01\n",
      "Epoch 11312, Loss: 0.010817032307386398, Neurons: 64, Grad norm: 7.369e-01\n",
      "Epoch 11313, Loss: 0.010813255794346333, Neurons: 64, Grad norm: 7.334e-01\n",
      "Epoch 11313, Loss: 0.010813255794346333, Neurons: 64, Grad norm: 7.334e-01\n",
      "Epoch 11314, Loss: 0.01080953050404787, Neurons: 64, Grad norm: 7.624e-01\n",
      "Epoch 11314, Loss: 0.01080953050404787, Neurons: 64, Grad norm: 7.624e-01\n",
      "Epoch 11315, Loss: 0.01080582570284605, Neurons: 64, Grad norm: 7.648e-01\n",
      "Epoch 11315, Loss: 0.01080582570284605, Neurons: 64, Grad norm: 7.648e-01\n",
      "Epoch 11316, Loss: 0.01080225221812725, Neurons: 64, Grad norm: 7.984e-01\n",
      "Epoch 11316, Loss: 0.01080225221812725, Neurons: 64, Grad norm: 7.984e-01\n",
      "Epoch 11317, Loss: 0.010798752307891846, Neurons: 64, Grad norm: 8.145e-01\n",
      "Epoch 11317, Loss: 0.010798752307891846, Neurons: 64, Grad norm: 8.145e-01\n",
      "Epoch 11318, Loss: 0.01079536508768797, Neurons: 64, Grad norm: 8.647e-01\n",
      "Epoch 11318, Loss: 0.01079536508768797, Neurons: 64, Grad norm: 8.647e-01\n",
      "Epoch 11319, Loss: 0.010792268440127373, Neurons: 64, Grad norm: 8.960e-01\n",
      "Epoch 11319, Loss: 0.010792268440127373, Neurons: 64, Grad norm: 8.960e-01\n",
      "Epoch 11320, Loss: 0.010789521969854832, Neurons: 64, Grad norm: 9.653e-01\n",
      "Epoch 11320, Loss: 0.010789521969854832, Neurons: 64, Grad norm: 9.653e-01\n",
      "Epoch 11321, Loss: 0.010787039063870907, Neurons: 64, Grad norm: 1.020e+00\n",
      "Epoch 11321, Loss: 0.010787039063870907, Neurons: 64, Grad norm: 1.020e+00\n",
      "Epoch 11322, Loss: 0.010785160586237907, Neurons: 64, Grad norm: 1.117e+00\n",
      "Epoch 11322, Loss: 0.010785160586237907, Neurons: 64, Grad norm: 1.117e+00\n",
      "Epoch 11323, Loss: 0.01078400295227766, Neurons: 64, Grad norm: 1.205e+00\n",
      "Epoch 11323, Loss: 0.01078400295227766, Neurons: 64, Grad norm: 1.205e+00\n",
      "Epoch 11324, Loss: 0.010783735662698746, Neurons: 64, Grad norm: 1.338e+00\n",
      "Epoch 11324, Loss: 0.010783735662698746, Neurons: 64, Grad norm: 1.338e+00\n",
      "Epoch 11325, Loss: 0.01078455988317728, Neurons: 64, Grad norm: 1.468e+00\n",
      "Epoch 11325, Loss: 0.01078455988317728, Neurons: 64, Grad norm: 1.468e+00\n",
      "Epoch 11326, Loss: 0.01078704558312893, Neurons: 64, Grad norm: 1.654e+00\n",
      "Epoch 11326, Loss: 0.01078704558312893, Neurons: 64, Grad norm: 1.654e+00\n",
      "Epoch 11327, Loss: 0.010791510343551636, Neurons: 64, Grad norm: 1.843e+00\n",
      "Epoch 11327, Loss: 0.010791510343551636, Neurons: 64, Grad norm: 1.843e+00\n",
      "Epoch 11328, Loss: 0.010798657312989235, Neurons: 64, Grad norm: 2.093e+00\n",
      "Epoch 11328, Loss: 0.010798657312989235, Neurons: 64, Grad norm: 2.093e+00\n",
      "Epoch 11329, Loss: 0.010809497907757759, Neurons: 64, Grad norm: 2.362e+00\n",
      "Epoch 11329, Loss: 0.010809497907757759, Neurons: 64, Grad norm: 2.362e+00\n",
      "Epoch 11330, Loss: 0.010825064033269882, Neurons: 64, Grad norm: 2.698e+00\n",
      "Epoch 11330, Loss: 0.010825064033269882, Neurons: 64, Grad norm: 2.698e+00\n",
      "Epoch 11331, Loss: 0.010846616700291634, Neurons: 64, Grad norm: 3.056e+00\n",
      "Epoch 11331, Loss: 0.010846616700291634, Neurons: 64, Grad norm: 3.056e+00\n",
      "Epoch 11332, Loss: 0.01087616290897131, Neurons: 64, Grad norm: 3.488e+00\n",
      "Epoch 11332, Loss: 0.01087616290897131, Neurons: 64, Grad norm: 3.488e+00\n",
      "Epoch 11333, Loss: 0.010915168561041355, Neurons: 64, Grad norm: 3.944e+00\n",
      "Epoch 11333, Loss: 0.010915168561041355, Neurons: 64, Grad norm: 3.944e+00\n",
      "Epoch 11334, Loss: 0.010965678840875626, Neurons: 64, Grad norm: 4.466e+00\n",
      "Epoch 11334, Loss: 0.010965678840875626, Neurons: 64, Grad norm: 4.466e+00\n",
      "Epoch 11335, Loss: 0.011028158478438854, Neurons: 64, Grad norm: 4.985e+00\n",
      "Epoch 11335, Loss: 0.011028158478438854, Neurons: 64, Grad norm: 4.985e+00\n",
      "Epoch 11336, Loss: 0.011102652177214622, Neurons: 64, Grad norm: 5.527e+00\n",
      "Epoch 11336, Loss: 0.011102652177214622, Neurons: 64, Grad norm: 5.527e+00\n",
      "Epoch 11337, Loss: 0.011184114031493664, Neurons: 64, Grad norm: 5.997e+00\n",
      "Epoch 11337, Loss: 0.011184114031493664, Neurons: 64, Grad norm: 5.997e+00\n",
      "Epoch 11338, Loss: 0.011265614069998264, Neurons: 64, Grad norm: 6.377e+00\n",
      "Epoch 11338, Loss: 0.011265614069998264, Neurons: 64, Grad norm: 6.377e+00\n",
      "Epoch 11339, Loss: 0.011330042034387589, Neurons: 64, Grad norm: 6.542e+00\n",
      "Epoch 11339, Loss: 0.011330042034387589, Neurons: 64, Grad norm: 6.542e+00\n",
      "Epoch 11340, Loss: 0.011360258795320988, Neurons: 64, Grad norm: 6.473e+00\n",
      "Epoch 11340, Loss: 0.011360258795320988, Neurons: 64, Grad norm: 6.473e+00\n",
      "Epoch 11341, Loss: 0.011336618103086948, Neurons: 64, Grad norm: 6.057e+00\n",
      "Epoch 11341, Loss: 0.011336618103086948, Neurons: 64, Grad norm: 6.057e+00\n",
      "Epoch 11342, Loss: 0.011252966709434986, Neurons: 64, Grad norm: 5.325e+00\n",
      "Epoch 11342, Loss: 0.011252966709434986, Neurons: 64, Grad norm: 5.325e+00\n",
      "Epoch 11343, Loss: 0.011117275804281235, Neurons: 64, Grad norm: 4.261e+00\n",
      "Epoch 11343, Loss: 0.011117275804281235, Neurons: 64, Grad norm: 4.261e+00\n",
      "Epoch 11344, Loss: 0.010959584265947342, Neurons: 64, Grad norm: 3.005e+00\n",
      "Epoch 11344, Loss: 0.010959584265947342, Neurons: 64, Grad norm: 3.005e+00\n",
      "Epoch 11345, Loss: 0.010816925205290318, Neurons: 64, Grad norm: 1.630e+00\n",
      "Epoch 11345, Loss: 0.010816925205290318, Neurons: 64, Grad norm: 1.630e+00\n",
      "Epoch 11346, Loss: 0.010720920749008656, Neurons: 64, Grad norm: 4.955e-01\n",
      "Epoch 11346, Loss: 0.010720920749008656, Neurons: 64, Grad norm: 4.955e-01\n",
      "Epoch 11347, Loss: 0.0106843626126647, Neurons: 64, Grad norm: 1.139e+00\n",
      "Epoch 11347, Loss: 0.0106843626126647, Neurons: 64, Grad norm: 1.139e+00\n",
      "Epoch 11348, Loss: 0.01070012804120779, Neurons: 64, Grad norm: 2.114e+00\n",
      "Epoch 11348, Loss: 0.01070012804120779, Neurons: 64, Grad norm: 2.114e+00\n",
      "Epoch 11349, Loss: 0.010746821761131287, Neurons: 64, Grad norm: 2.866e+00\n",
      "Epoch 11349, Loss: 0.010746821761131287, Neurons: 64, Grad norm: 2.866e+00\n",
      "Epoch 11350, Loss: 0.0107980752363801, Neurons: 64, Grad norm: 3.290e+00\n",
      "Epoch 11350, Loss: 0.0107980752363801, Neurons: 64, Grad norm: 3.290e+00\n",
      "Epoch 11351, Loss: 0.010832047089934349, Neurons: 64, Grad norm: 3.427e+00\n",
      "Epoch 11351, Loss: 0.010832047089934349, Neurons: 64, Grad norm: 3.427e+00\n",
      "Epoch 11352, Loss: 0.010836423374712467, Neurons: 64, Grad norm: 3.244e+00\n",
      "Epoch 11352, Loss: 0.010836423374712467, Neurons: 64, Grad norm: 3.244e+00\n",
      "Epoch 11353, Loss: 0.010811331681907177, Neurons: 64, Grad norm: 2.830e+00\n",
      "Epoch 11353, Loss: 0.010811331681907177, Neurons: 64, Grad norm: 2.830e+00\n",
      "Epoch 11354, Loss: 0.010765261016786098, Neurons: 64, Grad norm: 2.195e+00\n",
      "Epoch 11354, Loss: 0.010765261016786098, Neurons: 64, Grad norm: 2.195e+00\n",
      "Epoch 11355, Loss: 0.010713770054280758, Neurons: 64, Grad norm: 1.478e+00\n",
      "Epoch 11355, Loss: 0.010713770054280758, Neurons: 64, Grad norm: 1.478e+00\n",
      "Epoch 11356, Loss: 0.010671457275748253, Neurons: 64, Grad norm: 7.469e-01\n",
      "Epoch 11356, Loss: 0.010671457275748253, Neurons: 64, Grad norm: 7.469e-01\n",
      "Epoch 11357, Loss: 0.010647238232195377, Neurons: 64, Grad norm: 4.666e-01\n",
      "Epoch 11357, Loss: 0.010647238232195377, Neurons: 64, Grad norm: 4.666e-01\n",
      "Epoch 11358, Loss: 0.010642658919095993, Neurons: 64, Grad norm: 9.250e-01\n",
      "Epoch 11358, Loss: 0.010642658919095993, Neurons: 64, Grad norm: 9.250e-01\n",
      "Epoch 11359, Loss: 0.010652163065969944, Neurons: 64, Grad norm: 1.393e+00\n",
      "Epoch 11359, Loss: 0.010652163065969944, Neurons: 64, Grad norm: 1.393e+00\n",
      "Epoch 11360, Loss: 0.010667155496776104, Neurons: 64, Grad norm: 1.733e+00\n",
      "Epoch 11360, Loss: 0.010667155496776104, Neurons: 64, Grad norm: 1.733e+00\n",
      "Epoch 11361, Loss: 0.010678663849830627, Neurons: 64, Grad norm: 1.875e+00\n",
      "Epoch 11361, Loss: 0.010678663849830627, Neurons: 64, Grad norm: 1.875e+00\n",
      "Epoch 11362, Loss: 0.010681060142815113, Neurons: 64, Grad norm: 1.875e+00\n",
      "Epoch 11362, Loss: 0.010681060142815113, Neurons: 64, Grad norm: 1.875e+00\n",
      "Epoch 11363, Loss: 0.010672356002032757, Neurons: 64, Grad norm: 1.702e+00\n",
      "Epoch 11363, Loss: 0.010672356002032757, Neurons: 64, Grad norm: 1.702e+00\n",
      "Epoch 11364, Loss: 0.010655409656465054, Neurons: 64, Grad norm: 1.426e+00\n",
      "Epoch 11364, Loss: 0.010655409656465054, Neurons: 64, Grad norm: 1.426e+00\n",
      "Epoch 11365, Loss: 0.010634491220116615, Neurons: 64, Grad norm: 1.047e+00\n",
      "Epoch 11365, Loss: 0.010634491220116615, Neurons: 64, Grad norm: 1.047e+00\n",
      "Epoch 11366, Loss: 0.010614820756018162, Neurons: 64, Grad norm: 6.652e-01\n",
      "Epoch 11366, Loss: 0.010614820756018162, Neurons: 64, Grad norm: 6.652e-01\n",
      "Epoch 11367, Loss: 0.010600540786981583, Neurons: 64, Grad norm: 3.054e-01\n",
      "Epoch 11367, Loss: 0.010600540786981583, Neurons: 64, Grad norm: 3.054e-01\n",
      "Epoch 11368, Loss: 0.010593107901513577, Neurons: 64, Grad norm: 3.041e-01\n",
      "Epoch 11368, Loss: 0.010593107901513577, Neurons: 64, Grad norm: 3.041e-01\n",
      "Epoch 11369, Loss: 0.010591788217425346, Neurons: 64, Grad norm: 5.638e-01\n",
      "Epoch 11369, Loss: 0.010591788217425346, Neurons: 64, Grad norm: 5.638e-01\n",
      "Epoch 11370, Loss: 0.010593937709927559, Neurons: 64, Grad norm: 7.832e-01\n",
      "Epoch 11370, Loss: 0.010593937709927559, Neurons: 64, Grad norm: 7.832e-01\n",
      "Epoch 11371, Loss: 0.010596835054457188, Neurons: 64, Grad norm: 9.453e-01\n",
      "Epoch 11371, Loss: 0.010596835054457188, Neurons: 64, Grad norm: 9.453e-01\n",
      "Epoch 11372, Loss: 0.010597930289804935, Neurons: 64, Grad norm: 1.003e+00\n",
      "Epoch 11372, Loss: 0.010597930289804935, Neurons: 64, Grad norm: 1.003e+00\n",
      "Epoch 11373, Loss: 0.01059588510543108, Neurons: 64, Grad norm: 1.001e+00\n",
      "Epoch 11373, Loss: 0.01059588510543108, Neurons: 64, Grad norm: 1.001e+00\n",
      "Epoch 11374, Loss: 0.010590325109660625, Neurons: 64, Grad norm: 9.128e-01\n",
      "Epoch 11374, Loss: 0.010590325109660625, Neurons: 64, Grad norm: 9.128e-01\n",
      "Epoch 11375, Loss: 0.010582470335066319, Neurons: 64, Grad norm: 7.877e-01\n",
      "Epoch 11375, Loss: 0.010582470335066319, Neurons: 64, Grad norm: 7.877e-01\n",
      "Epoch 11376, Loss: 0.010573051869869232, Neurons: 64, Grad norm: 5.975e-01\n",
      "Epoch 11376, Loss: 0.010573051869869232, Neurons: 64, Grad norm: 5.975e-01\n",
      "Epoch 11377, Loss: 0.010563526302576065, Neurons: 64, Grad norm: 4.049e-01\n",
      "Epoch 11377, Loss: 0.010563526302576065, Neurons: 64, Grad norm: 4.049e-01\n",
      "Epoch 11378, Loss: 0.010555210523307323, Neurons: 64, Grad norm: 1.862e-01\n",
      "Epoch 11378, Loss: 0.010555210523307323, Neurons: 64, Grad norm: 1.862e-01\n",
      "Epoch 11379, Loss: 0.010548694059252739, Neurons: 64, Grad norm: 2.812e-02\n",
      "Epoch 11379, Loss: 0.010548694059252739, Neurons: 64, Grad norm: 2.812e-02\n",
      "Epoch 11380, Loss: 0.010544217191636562, Neurons: 64, Grad norm: 1.947e-01\n",
      "Epoch 11380, Loss: 0.010544217191636562, Neurons: 64, Grad norm: 1.947e-01\n",
      "Epoch 11381, Loss: 0.010541394352912903, Neurons: 64, Grad norm: 3.372e-01\n",
      "Epoch 11381, Loss: 0.010541394352912903, Neurons: 64, Grad norm: 3.372e-01\n",
      "Epoch 11382, Loss: 0.010539614595472813, Neurons: 64, Grad norm: 4.667e-01\n",
      "Epoch 11382, Loss: 0.010539614595472813, Neurons: 64, Grad norm: 4.667e-01\n",
      "Epoch 11383, Loss: 0.010538313537836075, Neurons: 64, Grad norm: 5.378e-01\n",
      "Epoch 11383, Loss: 0.010538313537836075, Neurons: 64, Grad norm: 5.378e-01\n",
      "Epoch 11384, Loss: 0.01053672842681408, Neurons: 64, Grad norm: 5.947e-01\n",
      "Epoch 11384, Loss: 0.01053672842681408, Neurons: 64, Grad norm: 5.947e-01\n",
      "Epoch 11385, Loss: 0.010534604080021381, Neurons: 64, Grad norm: 6.003e-01\n",
      "Epoch 11385, Loss: 0.010534604080021381, Neurons: 64, Grad norm: 6.003e-01\n",
      "Epoch 11386, Loss: 0.010531692765653133, Neurons: 64, Grad norm: 5.924e-01\n",
      "Epoch 11386, Loss: 0.010531692765653133, Neurons: 64, Grad norm: 5.924e-01\n",
      "Epoch 11387, Loss: 0.010527980513870716, Neurons: 64, Grad norm: 5.404e-01\n",
      "Epoch 11387, Loss: 0.010527980513870716, Neurons: 64, Grad norm: 5.404e-01\n",
      "Epoch 11388, Loss: 0.01052369549870491, Neurons: 64, Grad norm: 4.854e-01\n",
      "Epoch 11388, Loss: 0.01052369549870491, Neurons: 64, Grad norm: 4.854e-01\n",
      "Epoch 11389, Loss: 0.010518750175833702, Neurons: 64, Grad norm: 4.058e-01\n",
      "Epoch 11389, Loss: 0.010518750175833702, Neurons: 64, Grad norm: 4.058e-01\n",
      "Epoch 11390, Loss: 0.010513527318835258, Neurons: 64, Grad norm: 3.325e-01\n",
      "Epoch 11390, Loss: 0.010513527318835258, Neurons: 64, Grad norm: 3.325e-01\n",
      "Epoch 11391, Loss: 0.010508276522159576, Neurons: 64, Grad norm: 2.623e-01\n",
      "Epoch 11391, Loss: 0.010508276522159576, Neurons: 64, Grad norm: 2.623e-01\n",
      "Epoch 11392, Loss: 0.01050319243222475, Neurons: 64, Grad norm: 2.230e-01\n",
      "Epoch 11392, Loss: 0.01050319243222475, Neurons: 64, Grad norm: 2.230e-01\n",
      "Epoch 11393, Loss: 0.010498532094061375, Neurons: 64, Grad norm: 2.431e-01\n",
      "Epoch 11393, Loss: 0.010498532094061375, Neurons: 64, Grad norm: 2.431e-01\n",
      "Epoch 11394, Loss: 0.010494276881217957, Neurons: 64, Grad norm: 2.796e-01\n",
      "Epoch 11394, Loss: 0.010494276881217957, Neurons: 64, Grad norm: 2.796e-01\n",
      "Epoch 11395, Loss: 0.010490399785339832, Neurons: 64, Grad norm: 3.590e-01\n",
      "Epoch 11395, Loss: 0.010490399785339832, Neurons: 64, Grad norm: 3.590e-01\n",
      "Epoch 11396, Loss: 0.010486995801329613, Neurons: 64, Grad norm: 4.149e-01\n",
      "Epoch 11396, Loss: 0.010486995801329613, Neurons: 64, Grad norm: 4.149e-01\n",
      "Epoch 11397, Loss: 0.010483741760253906, Neurons: 64, Grad norm: 4.955e-01\n",
      "Epoch 11397, Loss: 0.010483741760253906, Neurons: 64, Grad norm: 4.955e-01\n",
      "Epoch 11398, Loss: 0.010480721481144428, Neurons: 64, Grad norm: 5.390e-01\n",
      "Epoch 11398, Loss: 0.010480721481144428, Neurons: 64, Grad norm: 5.390e-01\n",
      "Epoch 11399, Loss: 0.010477729141712189, Neurons: 64, Grad norm: 6.019e-01\n",
      "Epoch 11399, Loss: 0.010477729141712189, Neurons: 64, Grad norm: 6.019e-01\n",
      "Epoch 11399, Test loss: 0.007693035528063774\n",
      "Epoch 11399, Test loss: 0.007693035528063774\n",
      "Epoch 11400, Loss: 0.010474825277924538, Neurons: 64, Grad norm: 6.342e-01\n",
      "Epoch 11400, Loss: 0.010474825277924538, Neurons: 64, Grad norm: 6.342e-01\n",
      "Epoch 11401, Loss: 0.010471991263329983, Neurons: 64, Grad norm: 6.910e-01\n",
      "Epoch 11401, Loss: 0.010471991263329983, Neurons: 64, Grad norm: 6.910e-01\n",
      "Epoch 11402, Loss: 0.010469192638993263, Neurons: 64, Grad norm: 7.161e-01\n",
      "Epoch 11402, Loss: 0.010469192638993263, Neurons: 64, Grad norm: 7.161e-01\n",
      "Epoch 11403, Loss: 0.01046666782349348, Neurons: 64, Grad norm: 7.695e-01\n",
      "Epoch 11403, Loss: 0.01046666782349348, Neurons: 64, Grad norm: 7.695e-01\n",
      "Epoch 11404, Loss: 0.010464339517056942, Neurons: 64, Grad norm: 7.974e-01\n",
      "Epoch 11404, Loss: 0.010464339517056942, Neurons: 64, Grad norm: 7.974e-01\n",
      "Epoch 11405, Loss: 0.010462511330842972, Neurons: 64, Grad norm: 8.601e-01\n",
      "Epoch 11405, Loss: 0.010462511330842972, Neurons: 64, Grad norm: 8.601e-01\n",
      "Epoch 11406, Loss: 0.010461256839334965, Neurons: 64, Grad norm: 9.051e-01\n",
      "Epoch 11406, Loss: 0.010461256839334965, Neurons: 64, Grad norm: 9.051e-01\n",
      "Epoch 11407, Loss: 0.01046078372746706, Neurons: 64, Grad norm: 9.897e-01\n",
      "Epoch 11407, Loss: 0.01046078372746706, Neurons: 64, Grad norm: 9.897e-01\n",
      "Epoch 11408, Loss: 0.010461762547492981, Neurons: 64, Grad norm: 1.063e+00\n",
      "Epoch 11408, Loss: 0.010461762547492981, Neurons: 64, Grad norm: 1.063e+00\n",
      "Epoch 11409, Loss: 0.010464264079928398, Neurons: 64, Grad norm: 1.184e+00\n",
      "Epoch 11409, Loss: 0.010464264079928398, Neurons: 64, Grad norm: 1.184e+00\n",
      "Epoch 11410, Loss: 0.010468750260770321, Neurons: 64, Grad norm: 1.300e+00\n",
      "Epoch 11410, Loss: 0.010468750260770321, Neurons: 64, Grad norm: 1.300e+00\n",
      "Epoch 11411, Loss: 0.0104757621884346, Neurons: 64, Grad norm: 1.470e+00\n",
      "Epoch 11411, Loss: 0.0104757621884346, Neurons: 64, Grad norm: 1.470e+00\n",
      "Epoch 11412, Loss: 0.010486245155334473, Neurons: 64, Grad norm: 1.639e+00\n",
      "Epoch 11412, Loss: 0.010486245155334473, Neurons: 64, Grad norm: 1.639e+00\n",
      "Epoch 11413, Loss: 0.010500844568014145, Neurons: 64, Grad norm: 1.867e+00\n",
      "Epoch 11413, Loss: 0.010500844568014145, Neurons: 64, Grad norm: 1.867e+00\n",
      "Epoch 11414, Loss: 0.010521121323108673, Neurons: 64, Grad norm: 2.099e+00\n",
      "Epoch 11414, Loss: 0.010521121323108673, Neurons: 64, Grad norm: 2.099e+00\n",
      "Epoch 11415, Loss: 0.010547470301389694, Neurons: 64, Grad norm: 2.388e+00\n",
      "Epoch 11415, Loss: 0.010547470301389694, Neurons: 64, Grad norm: 2.388e+00\n",
      "Epoch 11416, Loss: 0.010580934584140778, Neurons: 64, Grad norm: 2.674e+00\n",
      "Epoch 11416, Loss: 0.010580934584140778, Neurons: 64, Grad norm: 2.674e+00\n",
      "Epoch 11417, Loss: 0.010620289482176304, Neurons: 64, Grad norm: 3.002e+00\n",
      "Epoch 11417, Loss: 0.010620289482176304, Neurons: 64, Grad norm: 3.002e+00\n",
      "Epoch 11418, Loss: 0.010664358735084534, Neurons: 64, Grad norm: 3.310e+00\n",
      "Epoch 11418, Loss: 0.010664358735084534, Neurons: 64, Grad norm: 3.310e+00\n",
      "Epoch 11419, Loss: 0.010707853361964226, Neurons: 64, Grad norm: 3.625e+00\n",
      "Epoch 11419, Loss: 0.010707853361964226, Neurons: 64, Grad norm: 3.625e+00\n",
      "Epoch 11420, Loss: 0.010745701380074024, Neurons: 64, Grad norm: 3.876e+00\n",
      "Epoch 11420, Loss: 0.010745701380074024, Neurons: 64, Grad norm: 3.876e+00\n",
      "Epoch 11421, Loss: 0.010768100619316101, Neurons: 64, Grad norm: 4.095e+00\n",
      "Epoch 11421, Loss: 0.010768100619316101, Neurons: 64, Grad norm: 4.095e+00\n",
      "Epoch 11422, Loss: 0.010768980719149113, Neurons: 64, Grad norm: 4.210e+00\n",
      "Epoch 11422, Loss: 0.010768980719149113, Neurons: 64, Grad norm: 4.210e+00\n",
      "Epoch 11423, Loss: 0.010747785679996014, Neurons: 64, Grad norm: 4.270e+00\n",
      "Epoch 11423, Loss: 0.010747785679996014, Neurons: 64, Grad norm: 4.270e+00\n",
      "Epoch 11424, Loss: 0.01071093138307333, Neurons: 64, Grad norm: 4.229e+00\n",
      "Epoch 11424, Loss: 0.01071093138307333, Neurons: 64, Grad norm: 4.229e+00\n",
      "Epoch 11425, Loss: 0.010669793002307415, Neurons: 64, Grad norm: 4.153e+00\n",
      "Epoch 11425, Loss: 0.010669793002307415, Neurons: 64, Grad norm: 4.153e+00\n",
      "Epoch 11426, Loss: 0.010635389015078545, Neurons: 64, Grad norm: 3.991e+00\n",
      "Epoch 11426, Loss: 0.010635389015078545, Neurons: 64, Grad norm: 3.991e+00\n",
      "Epoch 11427, Loss: 0.010613727383315563, Neurons: 64, Grad norm: 3.800e+00\n",
      "Epoch 11427, Loss: 0.010613727383315563, Neurons: 64, Grad norm: 3.800e+00\n",
      "Epoch 11428, Loss: 0.010602129623293877, Neurons: 64, Grad norm: 3.528e+00\n",
      "Epoch 11428, Loss: 0.010602129623293877, Neurons: 64, Grad norm: 3.528e+00\n",
      "Epoch 11429, Loss: 0.010593170300126076, Neurons: 64, Grad norm: 3.212e+00\n",
      "Epoch 11429, Loss: 0.010593170300126076, Neurons: 64, Grad norm: 3.212e+00\n",
      "Epoch 11430, Loss: 0.010576238855719566, Neurons: 64, Grad norm: 2.800e+00\n",
      "Epoch 11430, Loss: 0.010576238855719566, Neurons: 64, Grad norm: 2.800e+00\n",
      "Epoch 11431, Loss: 0.01054428331553936, Neurons: 64, Grad norm: 2.328e+00\n",
      "Epoch 11431, Loss: 0.01054428331553936, Neurons: 64, Grad norm: 2.328e+00\n",
      "Epoch 11432, Loss: 0.010496450588107109, Neurons: 64, Grad norm: 1.768e+00\n",
      "Epoch 11432, Loss: 0.010496450588107109, Neurons: 64, Grad norm: 1.768e+00\n",
      "Epoch 11433, Loss: 0.010440285317599773, Neurons: 64, Grad norm: 1.178e+00\n",
      "Epoch 11433, Loss: 0.010440285317599773, Neurons: 64, Grad norm: 1.178e+00\n",
      "Epoch 11434, Loss: 0.010388088412582874, Neurons: 64, Grad norm: 5.601e-01\n",
      "Epoch 11434, Loss: 0.010388088412582874, Neurons: 64, Grad norm: 5.601e-01\n",
      "Epoch 11435, Loss: 0.010351605713367462, Neurons: 64, Grad norm: 5.886e-02\n",
      "Epoch 11435, Loss: 0.010351605713367462, Neurons: 64, Grad norm: 5.886e-02\n",
      "Epoch 11436, Loss: 0.010336712002754211, Neurons: 64, Grad norm: 5.685e-01\n",
      "Epoch 11436, Loss: 0.010336712002754211, Neurons: 64, Grad norm: 5.685e-01\n",
      "Epoch 11437, Loss: 0.010341444052755833, Neurons: 64, Grad norm: 1.006e+00\n",
      "Epoch 11437, Loss: 0.010341444052755833, Neurons: 64, Grad norm: 1.006e+00\n",
      "Epoch 11438, Loss: 0.010357893072068691, Neurons: 64, Grad norm: 1.367e+00\n",
      "Epoch 11438, Loss: 0.010357893072068691, Neurons: 64, Grad norm: 1.367e+00\n",
      "Epoch 11439, Loss: 0.010376334190368652, Neurons: 64, Grad norm: 1.609e+00\n",
      "Epoch 11439, Loss: 0.010376334190368652, Neurons: 64, Grad norm: 1.609e+00\n",
      "Epoch 11440, Loss: 0.010389639995992184, Neurons: 64, Grad norm: 1.774e+00\n",
      "Epoch 11440, Loss: 0.010389639995992184, Neurons: 64, Grad norm: 1.774e+00\n",
      "Epoch 11441, Loss: 0.010392631404101849, Neurons: 64, Grad norm: 1.829e+00\n",
      "Epoch 11441, Loss: 0.010392631404101849, Neurons: 64, Grad norm: 1.829e+00\n",
      "Epoch 11442, Loss: 0.010386571288108826, Neurons: 64, Grad norm: 1.835e+00\n",
      "Epoch 11442, Loss: 0.010386571288108826, Neurons: 64, Grad norm: 1.835e+00\n",
      "Epoch 11443, Loss: 0.01037392858415842, Neurons: 64, Grad norm: 1.770e+00\n",
      "Epoch 11443, Loss: 0.01037392858415842, Neurons: 64, Grad norm: 1.770e+00\n",
      "Epoch 11444, Loss: 0.010359815321862698, Neurons: 64, Grad norm: 1.695e+00\n",
      "Epoch 11444, Loss: 0.010359815321862698, Neurons: 64, Grad norm: 1.695e+00\n",
      "Epoch 11445, Loss: 0.010347876697778702, Neurons: 64, Grad norm: 1.581e+00\n",
      "Epoch 11445, Loss: 0.010347876697778702, Neurons: 64, Grad norm: 1.581e+00\n",
      "Epoch 11446, Loss: 0.010339874774217606, Neurons: 64, Grad norm: 1.487e+00\n",
      "Epoch 11446, Loss: 0.010339874774217606, Neurons: 64, Grad norm: 1.487e+00\n",
      "Epoch 11447, Loss: 0.010335001163184643, Neurons: 64, Grad norm: 1.354e+00\n",
      "Epoch 11447, Loss: 0.010335001163184643, Neurons: 64, Grad norm: 1.354e+00\n",
      "Epoch 11448, Loss: 0.01033098716288805, Neurons: 64, Grad norm: 1.238e+00\n",
      "Epoch 11448, Loss: 0.01033098716288805, Neurons: 64, Grad norm: 1.238e+00\n",
      "Epoch 11449, Loss: 0.010325862094759941, Neurons: 64, Grad norm: 1.079e+00\n",
      "Epoch 11449, Loss: 0.010325862094759941, Neurons: 64, Grad norm: 1.079e+00\n",
      "Epoch 11450, Loss: 0.010318148881196976, Neurons: 64, Grad norm: 9.300e-01\n",
      "Epoch 11450, Loss: 0.010318148881196976, Neurons: 64, Grad norm: 9.300e-01\n",
      "Epoch 11451, Loss: 0.010308083146810532, Neurons: 64, Grad norm: 7.354e-01\n",
      "Epoch 11451, Loss: 0.010308083146810532, Neurons: 64, Grad norm: 7.354e-01\n",
      "Epoch 11452, Loss: 0.010296494700014591, Neurons: 64, Grad norm: 5.549e-01\n",
      "Epoch 11452, Loss: 0.010296494700014591, Neurons: 64, Grad norm: 5.549e-01\n",
      "Epoch 11453, Loss: 0.010285133495926857, Neurons: 64, Grad norm: 3.497e-01\n",
      "Epoch 11453, Loss: 0.010285133495926857, Neurons: 64, Grad norm: 3.497e-01\n",
      "Epoch 11454, Loss: 0.010275832377374172, Neurons: 64, Grad norm: 1.871e-01\n",
      "Epoch 11454, Loss: 0.010275832377374172, Neurons: 64, Grad norm: 1.871e-01\n",
      "Epoch 11455, Loss: 0.010269415564835072, Neurons: 64, Grad norm: 9.916e-02\n",
      "Epoch 11455, Loss: 0.010269415564835072, Neurons: 64, Grad norm: 9.916e-02\n",
      "Epoch 11456, Loss: 0.010265839286148548, Neurons: 64, Grad norm: 1.927e-01\n",
      "Epoch 11456, Loss: 0.010265839286148548, Neurons: 64, Grad norm: 1.927e-01\n",
      "Epoch 11457, Loss: 0.010264242067933083, Neurons: 64, Grad norm: 3.175e-01\n",
      "Epoch 11457, Loss: 0.010264242067933083, Neurons: 64, Grad norm: 3.175e-01\n",
      "Epoch 11458, Loss: 0.010263355448842049, Neurons: 64, Grad norm: 3.976e-01\n",
      "Epoch 11458, Loss: 0.010263355448842049, Neurons: 64, Grad norm: 3.976e-01\n",
      "Epoch 11459, Loss: 0.01026211492717266, Neurons: 64, Grad norm: 4.803e-01\n",
      "Epoch 11459, Loss: 0.01026211492717266, Neurons: 64, Grad norm: 4.803e-01\n",
      "Epoch 11460, Loss: 0.010260139591991901, Neurons: 64, Grad norm: 5.234e-01\n",
      "Epoch 11460, Loss: 0.010260139591991901, Neurons: 64, Grad norm: 5.234e-01\n",
      "Epoch 11461, Loss: 0.01025714073330164, Neurons: 64, Grad norm: 5.795e-01\n",
      "Epoch 11461, Loss: 0.01025714073330164, Neurons: 64, Grad norm: 5.795e-01\n",
      "Epoch 11462, Loss: 0.010253439657390118, Neurons: 64, Grad norm: 6.039e-01\n",
      "Epoch 11462, Loss: 0.010253439657390118, Neurons: 64, Grad norm: 6.039e-01\n",
      "Epoch 11463, Loss: 0.010249183513224125, Neurons: 64, Grad norm: 6.547e-01\n",
      "Epoch 11463, Loss: 0.010249183513224125, Neurons: 64, Grad norm: 6.547e-01\n",
      "Epoch 11464, Loss: 0.010245127603411674, Neurons: 64, Grad norm: 6.801e-01\n",
      "Epoch 11464, Loss: 0.010245127603411674, Neurons: 64, Grad norm: 6.801e-01\n",
      "Epoch 11465, Loss: 0.010241436772048473, Neurons: 64, Grad norm: 7.410e-01\n",
      "Epoch 11465, Loss: 0.010241436772048473, Neurons: 64, Grad norm: 7.410e-01\n",
      "Epoch 11466, Loss: 0.010238416492938995, Neurons: 64, Grad norm: 7.865e-01\n",
      "Epoch 11466, Loss: 0.010238416492938995, Neurons: 64, Grad norm: 7.865e-01\n",
      "Epoch 11467, Loss: 0.01023613940924406, Neurons: 64, Grad norm: 8.620e-01\n",
      "Epoch 11467, Loss: 0.01023613940924406, Neurons: 64, Grad norm: 8.620e-01\n",
      "Epoch 11468, Loss: 0.010234334506094456, Neurons: 64, Grad norm: 9.134e-01\n",
      "Epoch 11468, Loss: 0.010234334506094456, Neurons: 64, Grad norm: 9.134e-01\n",
      "Epoch 11469, Loss: 0.01023311447352171, Neurons: 64, Grad norm: 9.960e-01\n",
      "Epoch 11469, Loss: 0.01023311447352171, Neurons: 64, Grad norm: 9.960e-01\n",
      "Epoch 11470, Loss: 0.010231969878077507, Neurons: 64, Grad norm: 1.058e+00\n",
      "Epoch 11470, Loss: 0.010231969878077507, Neurons: 64, Grad norm: 1.058e+00\n",
      "Epoch 11471, Loss: 0.010231020860373974, Neurons: 64, Grad norm: 1.153e+00\n",
      "Epoch 11471, Loss: 0.010231020860373974, Neurons: 64, Grad norm: 1.153e+00\n",
      "Epoch 11472, Loss: 0.010230247862637043, Neurons: 64, Grad norm: 1.233e+00\n",
      "Epoch 11472, Loss: 0.010230247862637043, Neurons: 64, Grad norm: 1.233e+00\n",
      "Epoch 11473, Loss: 0.010229882784187794, Neurons: 64, Grad norm: 1.350e+00\n",
      "Epoch 11473, Loss: 0.010229882784187794, Neurons: 64, Grad norm: 1.350e+00\n",
      "Epoch 11474, Loss: 0.010230154730379581, Neurons: 64, Grad norm: 1.462e+00\n",
      "Epoch 11474, Loss: 0.010230154730379581, Neurons: 64, Grad norm: 1.462e+00\n",
      "Epoch 11475, Loss: 0.010231755673885345, Neurons: 64, Grad norm: 1.620e+00\n",
      "Epoch 11475, Loss: 0.010231755673885345, Neurons: 64, Grad norm: 1.620e+00\n",
      "Epoch 11476, Loss: 0.010234693996608257, Neurons: 64, Grad norm: 1.779e+00\n",
      "Epoch 11476, Loss: 0.010234693996608257, Neurons: 64, Grad norm: 1.779e+00\n",
      "Epoch 11477, Loss: 0.010239969938993454, Neurons: 64, Grad norm: 1.993e+00\n",
      "Epoch 11477, Loss: 0.010239969938993454, Neurons: 64, Grad norm: 1.993e+00\n",
      "Epoch 11478, Loss: 0.010247779078781605, Neurons: 64, Grad norm: 2.208e+00\n",
      "Epoch 11478, Loss: 0.010247779078781605, Neurons: 64, Grad norm: 2.208e+00\n",
      "Epoch 11479, Loss: 0.010259014554321766, Neurons: 64, Grad norm: 2.487e+00\n",
      "Epoch 11479, Loss: 0.010259014554321766, Neurons: 64, Grad norm: 2.487e+00\n",
      "Epoch 11480, Loss: 0.010274526663124561, Neurons: 64, Grad norm: 2.778e+00\n",
      "Epoch 11480, Loss: 0.010274526663124561, Neurons: 64, Grad norm: 2.778e+00\n",
      "Epoch 11481, Loss: 0.010295448824763298, Neurons: 64, Grad norm: 3.131e+00\n",
      "Epoch 11481, Loss: 0.010295448824763298, Neurons: 64, Grad norm: 3.131e+00\n",
      "Epoch 11482, Loss: 0.01032285112887621, Neurons: 64, Grad norm: 3.500e+00\n",
      "Epoch 11482, Loss: 0.01032285112887621, Neurons: 64, Grad norm: 3.500e+00\n",
      "Epoch 11483, Loss: 0.010358192026615143, Neurons: 64, Grad norm: 3.931e+00\n",
      "Epoch 11483, Loss: 0.010358192026615143, Neurons: 64, Grad norm: 3.931e+00\n",
      "Epoch 11484, Loss: 0.01040219608694315, Neurons: 64, Grad norm: 4.365e+00\n",
      "Epoch 11484, Loss: 0.01040219608694315, Neurons: 64, Grad norm: 4.365e+00\n",
      "Epoch 11485, Loss: 0.010455512441694736, Neurons: 64, Grad norm: 4.842e+00\n",
      "Epoch 11485, Loss: 0.010455512441694736, Neurons: 64, Grad norm: 4.842e+00\n",
      "Epoch 11486, Loss: 0.01051658857613802, Neurons: 64, Grad norm: 5.281e+00\n",
      "Epoch 11486, Loss: 0.01051658857613802, Neurons: 64, Grad norm: 5.281e+00\n",
      "Epoch 11487, Loss: 0.010582606308162212, Neurons: 64, Grad norm: 5.695e+00\n",
      "Epoch 11487, Loss: 0.010582606308162212, Neurons: 64, Grad norm: 5.695e+00\n",
      "Epoch 11488, Loss: 0.010646137408912182, Neurons: 64, Grad norm: 5.990e+00\n",
      "Epoch 11488, Loss: 0.010646137408912182, Neurons: 64, Grad norm: 5.990e+00\n",
      "Epoch 11489, Loss: 0.01069736760109663, Neurons: 64, Grad norm: 6.157e+00\n",
      "Epoch 11489, Loss: 0.01069736760109663, Neurons: 64, Grad norm: 6.157e+00\n",
      "Epoch 11490, Loss: 0.010721943341195583, Neurons: 64, Grad norm: 6.087e+00\n",
      "Epoch 11490, Loss: 0.010721943341195583, Neurons: 64, Grad norm: 6.087e+00\n",
      "Epoch 11491, Loss: 0.010708167217671871, Neurons: 64, Grad norm: 5.784e+00\n",
      "Epoch 11491, Loss: 0.010708167217671871, Neurons: 64, Grad norm: 5.784e+00\n",
      "Epoch 11492, Loss: 0.010647439397871494, Neurons: 64, Grad norm: 5.176e+00\n",
      "Epoch 11492, Loss: 0.010647439397871494, Neurons: 64, Grad norm: 5.176e+00\n",
      "Epoch 11493, Loss: 0.010544991120696068, Neurons: 64, Grad norm: 4.330e+00\n",
      "Epoch 11493, Loss: 0.010544991120696068, Neurons: 64, Grad norm: 4.330e+00\n",
      "Epoch 11494, Loss: 0.01041695661842823, Neurons: 64, Grad norm: 3.244e+00\n",
      "Epoch 11494, Loss: 0.01041695661842823, Neurons: 64, Grad norm: 3.244e+00\n",
      "Epoch 11495, Loss: 0.010290134698152542, Neurons: 64, Grad norm: 2.059e+00\n",
      "Epoch 11495, Loss: 0.010290134698152542, Neurons: 64, Grad norm: 2.059e+00\n",
      "Epoch 11496, Loss: 0.010189934633672237, Neurons: 64, Grad norm: 8.198e-01\n",
      "Epoch 11496, Loss: 0.010189934633672237, Neurons: 64, Grad norm: 8.198e-01\n",
      "Epoch 11497, Loss: 0.01013270765542984, Neurons: 64, Grad norm: 3.338e-01\n",
      "Epoch 11497, Loss: 0.01013270765542984, Neurons: 64, Grad norm: 3.338e-01\n",
      "Epoch 11498, Loss: 0.010120609775185585, Neurons: 64, Grad norm: 1.369e+00\n",
      "Epoch 11498, Loss: 0.010120609775185585, Neurons: 64, Grad norm: 1.369e+00\n",
      "Epoch 11499, Loss: 0.010143631137907505, Neurons: 64, Grad norm: 2.181e+00\n",
      "Epoch 11499, Loss: 0.010143631137907505, Neurons: 64, Grad norm: 2.181e+00\n",
      "Epoch 11499, Test loss: 0.007421667221933603\n",
      "Epoch 11499, Test loss: 0.007421667221933603\n",
      "Epoch 11500, Loss: 0.010184935294091702, Neurons: 64, Grad norm: 2.791e+00\n",
      "Epoch 11500, Loss: 0.010184935294091702, Neurons: 64, Grad norm: 2.791e+00\n",
      "Epoch 11501, Loss: 0.010226585902273655, Neurons: 64, Grad norm: 3.127e+00\n",
      "Epoch 11501, Loss: 0.010226585902273655, Neurons: 64, Grad norm: 3.127e+00\n",
      "Epoch 11502, Loss: 0.010254459455609322, Neurons: 64, Grad norm: 3.234e+00\n",
      "Epoch 11502, Loss: 0.010254459455609322, Neurons: 64, Grad norm: 3.234e+00\n",
      "Epoch 11503, Loss: 0.010260174050927162, Neurons: 64, Grad norm: 3.075e+00\n",
      "Epoch 11503, Loss: 0.010260174050927162, Neurons: 64, Grad norm: 3.075e+00\n",
      "Epoch 11504, Loss: 0.010243047028779984, Neurons: 64, Grad norm: 2.733e+00\n",
      "Epoch 11504, Loss: 0.010243047028779984, Neurons: 64, Grad norm: 2.733e+00\n",
      "Epoch 11505, Loss: 0.01020821463316679, Neurons: 64, Grad norm: 2.202e+00\n",
      "Epoch 11505, Loss: 0.01020821463316679, Neurons: 64, Grad norm: 2.202e+00\n",
      "Epoch 11506, Loss: 0.010165839456021786, Neurons: 64, Grad norm: 1.584e+00\n",
      "Epoch 11506, Loss: 0.010165839456021786, Neurons: 64, Grad norm: 1.584e+00\n",
      "Epoch 11507, Loss: 0.01012616790831089, Neurons: 64, Grad norm: 8.863e-01\n",
      "Epoch 11507, Loss: 0.01012616790831089, Neurons: 64, Grad norm: 8.863e-01\n",
      "Epoch 11508, Loss: 0.010097120888531208, Neurons: 64, Grad norm: 2.305e-01\n",
      "Epoch 11508, Loss: 0.010097120888531208, Neurons: 64, Grad norm: 2.305e-01\n",
      "Epoch 11509, Loss: 0.010082344524562359, Neurons: 64, Grad norm: 4.282e-01\n",
      "Epoch 11509, Loss: 0.010082344524562359, Neurons: 64, Grad norm: 4.282e-01\n",
      "Epoch 11510, Loss: 0.010080946609377861, Neurons: 64, Grad norm: 9.491e-01\n",
      "Epoch 11510, Loss: 0.010080946609377861, Neurons: 64, Grad norm: 9.491e-01\n",
      "Epoch 11511, Loss: 0.010088776238262653, Neurons: 64, Grad norm: 1.383e+00\n",
      "Epoch 11511, Loss: 0.010088776238262653, Neurons: 64, Grad norm: 1.383e+00\n",
      "Epoch 11512, Loss: 0.010100280866026878, Neurons: 64, Grad norm: 1.661e+00\n",
      "Epoch 11512, Loss: 0.010100280866026878, Neurons: 64, Grad norm: 1.661e+00\n",
      "Epoch 11513, Loss: 0.010110264644026756, Neurons: 64, Grad norm: 1.826e+00\n",
      "Epoch 11513, Loss: 0.010110264644026756, Neurons: 64, Grad norm: 1.826e+00\n",
      "Epoch 11514, Loss: 0.010114911012351513, Neurons: 64, Grad norm: 1.834e+00\n",
      "Epoch 11514, Loss: 0.010114911012351513, Neurons: 64, Grad norm: 1.834e+00\n",
      "Epoch 11515, Loss: 0.010112719610333443, Neurons: 64, Grad norm: 1.750e+00\n",
      "Epoch 11515, Loss: 0.010112719610333443, Neurons: 64, Grad norm: 1.750e+00\n",
      "Epoch 11516, Loss: 0.010103963315486908, Neurons: 64, Grad norm: 1.544e+00\n",
      "Epoch 11516, Loss: 0.010103963315486908, Neurons: 64, Grad norm: 1.544e+00\n",
      "Epoch 11517, Loss: 0.010090856812894344, Neurons: 64, Grad norm: 1.287e+00\n",
      "Epoch 11517, Loss: 0.010090856812894344, Neurons: 64, Grad norm: 1.287e+00\n",
      "Epoch 11518, Loss: 0.010075748898088932, Neurons: 64, Grad norm: 9.553e-01\n",
      "Epoch 11518, Loss: 0.010075748898088932, Neurons: 64, Grad norm: 9.553e-01\n",
      "Epoch 11519, Loss: 0.01006150059401989, Neurons: 64, Grad norm: 6.256e-01\n",
      "Epoch 11519, Loss: 0.01006150059401989, Neurons: 64, Grad norm: 6.256e-01\n",
      "Epoch 11520, Loss: 0.010049981065094471, Neurons: 64, Grad norm: 2.732e-01\n",
      "Epoch 11520, Loss: 0.010049981065094471, Neurons: 64, Grad norm: 2.732e-01\n",
      "Epoch 11521, Loss: 0.01004200428724289, Neurons: 64, Grad norm: 7.689e-02\n",
      "Epoch 11521, Loss: 0.01004200428724289, Neurons: 64, Grad norm: 7.689e-02\n",
      "Epoch 11522, Loss: 0.010037640109658241, Neurons: 64, Grad norm: 3.482e-01\n",
      "Epoch 11522, Loss: 0.010037640109658241, Neurons: 64, Grad norm: 3.482e-01\n",
      "Epoch 11523, Loss: 0.010036001913249493, Neurons: 64, Grad norm: 5.785e-01\n",
      "Epoch 11523, Loss: 0.010036001913249493, Neurons: 64, Grad norm: 5.785e-01\n",
      "Epoch 11524, Loss: 0.010036102496087551, Neurons: 64, Grad norm: 7.792e-01\n",
      "Epoch 11524, Loss: 0.010036102496087551, Neurons: 64, Grad norm: 7.792e-01\n",
      "Epoch 11525, Loss: 0.010036633349955082, Neurons: 64, Grad norm: 8.999e-01\n",
      "Epoch 11525, Loss: 0.010036633349955082, Neurons: 64, Grad norm: 8.999e-01\n",
      "Epoch 11526, Loss: 0.010036783292889595, Neurons: 64, Grad norm: 9.940e-01\n",
      "Epoch 11526, Loss: 0.010036783292889595, Neurons: 64, Grad norm: 9.940e-01\n",
      "Epoch 11527, Loss: 0.010035756044089794, Neurons: 64, Grad norm: 1.017e+00\n",
      "Epoch 11527, Loss: 0.010035756044089794, Neurons: 64, Grad norm: 1.017e+00\n",
      "Epoch 11528, Loss: 0.010033458471298218, Neurons: 64, Grad norm: 1.017e+00\n",
      "Epoch 11528, Loss: 0.010033458471298218, Neurons: 64, Grad norm: 1.017e+00\n",
      "Epoch 11529, Loss: 0.010029670782387257, Neurons: 64, Grad norm: 9.497e-01\n",
      "Epoch 11529, Loss: 0.010029670782387257, Neurons: 64, Grad norm: 9.497e-01\n",
      "Epoch 11530, Loss: 0.01002467144280672, Neurons: 64, Grad norm: 8.752e-01\n",
      "Epoch 11530, Loss: 0.01002467144280672, Neurons: 64, Grad norm: 8.752e-01\n",
      "Epoch 11531, Loss: 0.010018852539360523, Neurons: 64, Grad norm: 7.538e-01\n",
      "Epoch 11531, Loss: 0.010018852539360523, Neurons: 64, Grad norm: 7.538e-01\n",
      "Epoch 11532, Loss: 0.010012706741690636, Neurons: 64, Grad norm: 6.388e-01\n",
      "Epoch 11532, Loss: 0.010012706741690636, Neurons: 64, Grad norm: 6.388e-01\n",
      "Epoch 11533, Loss: 0.010006549768149853, Neurons: 64, Grad norm: 4.871e-01\n",
      "Epoch 11533, Loss: 0.010006549768149853, Neurons: 64, Grad norm: 4.871e-01\n",
      "Epoch 11534, Loss: 0.010000750422477722, Neurons: 64, Grad norm: 3.586e-01\n",
      "Epoch 11534, Loss: 0.010000750422477722, Neurons: 64, Grad norm: 3.586e-01\n",
      "Epoch 11535, Loss: 0.009995526634156704, Neurons: 64, Grad norm: 2.111e-01\n",
      "Epoch 11535, Loss: 0.009995526634156704, Neurons: 64, Grad norm: 2.111e-01\n",
      "Epoch 11536, Loss: 0.009991011582314968, Neurons: 64, Grad norm: 9.905e-02\n",
      "Epoch 11536, Loss: 0.009991011582314968, Neurons: 64, Grad norm: 9.905e-02\n",
      "Epoch 11537, Loss: 0.00998699851334095, Neurons: 64, Grad norm: 4.738e-02\n",
      "Epoch 11537, Loss: 0.00998699851334095, Neurons: 64, Grad norm: 4.738e-02\n",
      "Epoch 11538, Loss: 0.009983586147427559, Neurons: 64, Grad norm: 1.337e-01\n",
      "Epoch 11538, Loss: 0.009983586147427559, Neurons: 64, Grad norm: 1.337e-01\n",
      "Epoch 11539, Loss: 0.009980526752769947, Neurons: 64, Grad norm: 2.376e-01\n",
      "Epoch 11539, Loss: 0.009980526752769947, Neurons: 64, Grad norm: 2.376e-01\n",
      "Epoch 11540, Loss: 0.00997766014188528, Neurons: 64, Grad norm: 3.017e-01\n",
      "Epoch 11540, Loss: 0.00997766014188528, Neurons: 64, Grad norm: 3.017e-01\n",
      "Epoch 11541, Loss: 0.009974958375096321, Neurons: 64, Grad norm: 3.791e-01\n",
      "Epoch 11541, Loss: 0.009974958375096321, Neurons: 64, Grad norm: 3.791e-01\n",
      "Epoch 11542, Loss: 0.009972317144274712, Neurons: 64, Grad norm: 4.180e-01\n",
      "Epoch 11542, Loss: 0.009972317144274712, Neurons: 64, Grad norm: 4.180e-01\n",
      "Epoch 11543, Loss: 0.009969599545001984, Neurons: 64, Grad norm: 4.719e-01\n",
      "Epoch 11543, Loss: 0.009969599545001984, Neurons: 64, Grad norm: 4.719e-01\n",
      "Epoch 11544, Loss: 0.009966908022761345, Neurons: 64, Grad norm: 4.894e-01\n",
      "Epoch 11544, Loss: 0.009966908022761345, Neurons: 64, Grad norm: 4.894e-01\n",
      "Epoch 11545, Loss: 0.009964058175683022, Neurons: 64, Grad norm: 5.317e-01\n",
      "Epoch 11545, Loss: 0.009964058175683022, Neurons: 64, Grad norm: 5.317e-01\n",
      "Epoch 11546, Loss: 0.009961182251572609, Neurons: 64, Grad norm: 5.396e-01\n",
      "Epoch 11546, Loss: 0.009961182251572609, Neurons: 64, Grad norm: 5.396e-01\n",
      "Epoch 11547, Loss: 0.00995827466249466, Neurons: 64, Grad norm: 5.654e-01\n",
      "Epoch 11547, Loss: 0.00995827466249466, Neurons: 64, Grad norm: 5.654e-01\n",
      "Epoch 11548, Loss: 0.009955307468771935, Neurons: 64, Grad norm: 5.644e-01\n",
      "Epoch 11548, Loss: 0.009955307468771935, Neurons: 64, Grad norm: 5.644e-01\n",
      "Epoch 11549, Loss: 0.009952299296855927, Neurons: 64, Grad norm: 5.895e-01\n",
      "Epoch 11549, Loss: 0.009952299296855927, Neurons: 64, Grad norm: 5.895e-01\n",
      "Epoch 11550, Loss: 0.009949356317520142, Neurons: 64, Grad norm: 5.859e-01\n",
      "Epoch 11550, Loss: 0.009949356317520142, Neurons: 64, Grad norm: 5.859e-01\n",
      "Epoch 11551, Loss: 0.009946540929377079, Neurons: 64, Grad norm: 6.106e-01\n",
      "Epoch 11551, Loss: 0.009946540929377079, Neurons: 64, Grad norm: 6.106e-01\n",
      "Epoch 11552, Loss: 0.00994379073381424, Neurons: 64, Grad norm: 6.143e-01\n",
      "Epoch 11552, Loss: 0.00994379073381424, Neurons: 64, Grad norm: 6.143e-01\n",
      "Epoch 11553, Loss: 0.009941251948475838, Neurons: 64, Grad norm: 6.536e-01\n",
      "Epoch 11553, Loss: 0.009941251948475838, Neurons: 64, Grad norm: 6.536e-01\n",
      "Epoch 11554, Loss: 0.009939022362232208, Neurons: 64, Grad norm: 6.701e-01\n",
      "Epoch 11554, Loss: 0.009939022362232208, Neurons: 64, Grad norm: 6.701e-01\n",
      "Epoch 11555, Loss: 0.009937166236341, Neurons: 64, Grad norm: 7.180e-01\n",
      "Epoch 11555, Loss: 0.009937166236341, Neurons: 64, Grad norm: 7.180e-01\n",
      "Epoch 11556, Loss: 0.009935627691447735, Neurons: 64, Grad norm: 7.458e-01\n",
      "Epoch 11556, Loss: 0.009935627691447735, Neurons: 64, Grad norm: 7.458e-01\n",
      "Epoch 11557, Loss: 0.00993462186306715, Neurons: 64, Grad norm: 8.160e-01\n",
      "Epoch 11557, Loss: 0.00993462186306715, Neurons: 64, Grad norm: 8.160e-01\n",
      "Epoch 11558, Loss: 0.009934375993907452, Neurons: 64, Grad norm: 8.679e-01\n",
      "Epoch 11558, Loss: 0.009934375993907452, Neurons: 64, Grad norm: 8.679e-01\n",
      "Epoch 11559, Loss: 0.009935067035257816, Neurons: 64, Grad norm: 9.581e-01\n",
      "Epoch 11559, Loss: 0.009935067035257816, Neurons: 64, Grad norm: 9.581e-01\n",
      "Epoch 11560, Loss: 0.00993696041405201, Neurons: 64, Grad norm: 1.041e+00\n",
      "Epoch 11560, Loss: 0.00993696041405201, Neurons: 64, Grad norm: 1.041e+00\n",
      "Epoch 11561, Loss: 0.00994059443473816, Neurons: 64, Grad norm: 1.169e+00\n",
      "Epoch 11561, Loss: 0.00994059443473816, Neurons: 64, Grad norm: 1.169e+00\n",
      "Epoch 11562, Loss: 0.009946919046342373, Neurons: 64, Grad norm: 1.294e+00\n",
      "Epoch 11562, Loss: 0.009946919046342373, Neurons: 64, Grad norm: 1.294e+00\n",
      "Epoch 11563, Loss: 0.009956453926861286, Neurons: 64, Grad norm: 1.469e+00\n",
      "Epoch 11563, Loss: 0.009956453926861286, Neurons: 64, Grad norm: 1.469e+00\n",
      "Epoch 11564, Loss: 0.0099704684689641, Neurons: 64, Grad norm: 1.644e+00\n",
      "Epoch 11564, Loss: 0.0099704684689641, Neurons: 64, Grad norm: 1.644e+00\n",
      "Epoch 11565, Loss: 0.009989644400775433, Neurons: 64, Grad norm: 1.871e+00\n",
      "Epoch 11565, Loss: 0.009989644400775433, Neurons: 64, Grad norm: 1.871e+00\n",
      "Epoch 11566, Loss: 0.010015762411057949, Neurons: 64, Grad norm: 2.095e+00\n",
      "Epoch 11566, Loss: 0.010015762411057949, Neurons: 64, Grad norm: 2.095e+00\n",
      "Epoch 11567, Loss: 0.010048647411167622, Neurons: 64, Grad norm: 2.366e+00\n",
      "Epoch 11567, Loss: 0.010048647411167622, Neurons: 64, Grad norm: 2.366e+00\n",
      "Epoch 11568, Loss: 0.010088610462844372, Neurons: 64, Grad norm: 2.622e+00\n",
      "Epoch 11568, Loss: 0.010088610462844372, Neurons: 64, Grad norm: 2.622e+00\n",
      "Epoch 11569, Loss: 0.010132514871656895, Neurons: 64, Grad norm: 2.893e+00\n",
      "Epoch 11569, Loss: 0.010132514871656895, Neurons: 64, Grad norm: 2.893e+00\n",
      "Epoch 11570, Loss: 0.010176323354244232, Neurons: 64, Grad norm: 3.113e+00\n",
      "Epoch 11570, Loss: 0.010176323354244232, Neurons: 64, Grad norm: 3.113e+00\n",
      "Epoch 11571, Loss: 0.01021029707044363, Neurons: 64, Grad norm: 3.311e+00\n",
      "Epoch 11571, Loss: 0.01021029707044363, Neurons: 64, Grad norm: 3.311e+00\n",
      "Epoch 11572, Loss: 0.010225972160696983, Neurons: 64, Grad norm: 3.414e+00\n",
      "Epoch 11572, Loss: 0.010225972160696983, Neurons: 64, Grad norm: 3.414e+00\n",
      "Epoch 11573, Loss: 0.010213474743068218, Neurons: 64, Grad norm: 3.471e+00\n",
      "Epoch 11573, Loss: 0.010213474743068218, Neurons: 64, Grad norm: 3.471e+00\n",
      "Epoch 11574, Loss: 0.01017344743013382, Neurons: 64, Grad norm: 3.453e+00\n",
      "Epoch 11574, Loss: 0.01017344743013382, Neurons: 64, Grad norm: 3.453e+00\n",
      "Epoch 11575, Loss: 0.010118026286363602, Neurons: 64, Grad norm: 3.452e+00\n",
      "Epoch 11575, Loss: 0.010118026286363602, Neurons: 64, Grad norm: 3.452e+00\n",
      "Epoch 11576, Loss: 0.010067171417176723, Neurons: 64, Grad norm: 3.462e+00\n",
      "Epoch 11576, Loss: 0.010067171417176723, Neurons: 64, Grad norm: 3.462e+00\n",
      "Epoch 11577, Loss: 0.0100404629483819, Neurons: 64, Grad norm: 3.568e+00\n",
      "Epoch 11577, Loss: 0.0100404629483819, Neurons: 64, Grad norm: 3.568e+00\n",
      "Epoch 11578, Loss: 0.010047943331301212, Neurons: 64, Grad norm: 3.715e+00\n",
      "Epoch 11578, Loss: 0.010047943331301212, Neurons: 64, Grad norm: 3.715e+00\n",
      "Epoch 11579, Loss: 0.010087203234434128, Neurons: 64, Grad norm: 3.923e+00\n",
      "Epoch 11579, Loss: 0.010087203234434128, Neurons: 64, Grad norm: 3.923e+00\n",
      "Epoch 11580, Loss: 0.010143624618649483, Neurons: 64, Grad norm: 4.098e+00\n",
      "Epoch 11580, Loss: 0.010143624618649483, Neurons: 64, Grad norm: 4.098e+00\n",
      "Epoch 11581, Loss: 0.010197283700108528, Neurons: 64, Grad norm: 4.237e+00\n",
      "Epoch 11581, Loss: 0.010197283700108528, Neurons: 64, Grad norm: 4.237e+00\n",
      "Epoch 11582, Loss: 0.01022659707814455, Neurons: 64, Grad norm: 4.260e+00\n",
      "Epoch 11582, Loss: 0.01022659707814455, Neurons: 64, Grad norm: 4.260e+00\n",
      "Epoch 11583, Loss: 0.010219180025160313, Neurons: 64, Grad norm: 4.178e+00\n",
      "Epoch 11583, Loss: 0.010219180025160313, Neurons: 64, Grad norm: 4.178e+00\n",
      "Epoch 11584, Loss: 0.010173986665904522, Neurons: 64, Grad norm: 3.958e+00\n",
      "Epoch 11584, Loss: 0.010173986665904522, Neurons: 64, Grad norm: 3.958e+00\n",
      "Epoch 11585, Loss: 0.010106897912919521, Neurons: 64, Grad norm: 3.665e+00\n",
      "Epoch 11585, Loss: 0.010106897912919521, Neurons: 64, Grad norm: 3.665e+00\n",
      "Epoch 11586, Loss: 0.010039072483778, Neurons: 64, Grad norm: 3.286e+00\n",
      "Epoch 11586, Loss: 0.010039072483778, Neurons: 64, Grad norm: 3.286e+00\n",
      "Epoch 11587, Loss: 0.009987909346818924, Neurons: 64, Grad norm: 2.900e+00\n",
      "Epoch 11587, Loss: 0.009987909346818924, Neurons: 64, Grad norm: 2.900e+00\n",
      "Epoch 11588, Loss: 0.009957090020179749, Neurons: 64, Grad norm: 2.469e+00\n",
      "Epoch 11588, Loss: 0.009957090020179749, Neurons: 64, Grad norm: 2.469e+00\n",
      "Epoch 11589, Loss: 0.009939041920006275, Neurons: 64, Grad norm: 2.044e+00\n",
      "Epoch 11589, Loss: 0.009939041920006275, Neurons: 64, Grad norm: 2.044e+00\n",
      "Epoch 11590, Loss: 0.009921091608703136, Neurons: 64, Grad norm: 1.566e+00\n",
      "Epoch 11590, Loss: 0.009921091608703136, Neurons: 64, Grad norm: 1.566e+00\n",
      "Epoch 11591, Loss: 0.009895054623484612, Neurons: 64, Grad norm: 1.093e+00\n",
      "Epoch 11591, Loss: 0.009895054623484612, Neurons: 64, Grad norm: 1.093e+00\n",
      "Epoch 11592, Loss: 0.009861663915216923, Neurons: 64, Grad norm: 6.256e-01\n",
      "Epoch 11592, Loss: 0.009861663915216923, Neurons: 64, Grad norm: 6.256e-01\n",
      "Epoch 11593, Loss: 0.009829571470618248, Neurons: 64, Grad norm: 4.374e-01\n",
      "Epoch 11593, Loss: 0.009829571470618248, Neurons: 64, Grad norm: 4.374e-01\n",
      "Epoch 11594, Loss: 0.009809271432459354, Neurons: 64, Grad norm: 7.406e-01\n",
      "Epoch 11594, Loss: 0.009809271432459354, Neurons: 64, Grad norm: 7.406e-01\n",
      "Epoch 11595, Loss: 0.009806100279092789, Neurons: 64, Grad norm: 1.120e+00\n",
      "Epoch 11595, Loss: 0.009806100279092789, Neurons: 64, Grad norm: 1.120e+00\n",
      "Epoch 11596, Loss: 0.009817961603403091, Neurons: 64, Grad norm: 1.472e+00\n",
      "Epoch 11596, Loss: 0.009817961603403091, Neurons: 64, Grad norm: 1.472e+00\n",
      "Epoch 11597, Loss: 0.0098365293815732, Neurons: 64, Grad norm: 1.707e+00\n",
      "Epoch 11597, Loss: 0.0098365293815732, Neurons: 64, Grad norm: 1.707e+00\n",
      "Epoch 11598, Loss: 0.00985224824398756, Neurons: 64, Grad norm: 1.869e+00\n",
      "Epoch 11598, Loss: 0.00985224824398756, Neurons: 64, Grad norm: 1.869e+00\n",
      "Epoch 11599, Loss: 0.00985910464078188, Neurons: 64, Grad norm: 1.911e+00\n",
      "Epoch 11599, Loss: 0.00985910464078188, Neurons: 64, Grad norm: 1.911e+00\n",
      "Epoch 11599, Test loss: 0.007270467467606068\n",
      "Epoch 11599, Test loss: 0.007270467467606068\n",
      "Epoch 11600, Loss: 0.009855091571807861, Neurons: 64, Grad norm: 1.905e+00\n",
      "Epoch 11600, Loss: 0.009855091571807861, Neurons: 64, Grad norm: 1.905e+00\n",
      "Epoch 11601, Loss: 0.009843739680945873, Neurons: 64, Grad norm: 1.820e+00\n",
      "Epoch 11601, Loss: 0.009843739680945873, Neurons: 64, Grad norm: 1.820e+00\n",
      "Epoch 11602, Loss: 0.009829901158809662, Neurons: 64, Grad norm: 1.732e+00\n",
      "Epoch 11602, Loss: 0.009829901158809662, Neurons: 64, Grad norm: 1.732e+00\n",
      "Epoch 11603, Loss: 0.00981829408556223, Neurons: 64, Grad norm: 1.609e+00\n",
      "Epoch 11603, Loss: 0.00981829408556223, Neurons: 64, Grad norm: 1.609e+00\n",
      "Epoch 11604, Loss: 0.009810512885451317, Neurons: 64, Grad norm: 1.502e+00\n",
      "Epoch 11604, Loss: 0.009810512885451317, Neurons: 64, Grad norm: 1.502e+00\n",
      "Epoch 11605, Loss: 0.009805533103644848, Neurons: 64, Grad norm: 1.364e+00\n",
      "Epoch 11605, Loss: 0.009805533103644848, Neurons: 64, Grad norm: 1.364e+00\n",
      "Epoch 11606, Loss: 0.009800983592867851, Neurons: 64, Grad norm: 1.230e+00\n",
      "Epoch 11606, Loss: 0.009800983592867851, Neurons: 64, Grad norm: 1.230e+00\n",
      "Epoch 11607, Loss: 0.009794207289814949, Neurons: 64, Grad norm: 1.053e+00\n",
      "Epoch 11607, Loss: 0.009794207289814949, Neurons: 64, Grad norm: 1.053e+00\n",
      "Epoch 11608, Loss: 0.00978465098887682, Neurons: 64, Grad norm: 8.773e-01\n",
      "Epoch 11608, Loss: 0.00978465098887682, Neurons: 64, Grad norm: 8.773e-01\n",
      "Epoch 11609, Loss: 0.009773069992661476, Neurons: 64, Grad norm: 6.690e-01\n",
      "Epoch 11609, Loss: 0.009773069992661476, Neurons: 64, Grad norm: 6.690e-01\n",
      "Epoch 11610, Loss: 0.009761570952832699, Neurons: 64, Grad norm: 4.826e-01\n",
      "Epoch 11610, Loss: 0.009761570952832699, Neurons: 64, Grad norm: 4.826e-01\n",
      "Epoch 11611, Loss: 0.009752347134053707, Neurons: 64, Grad norm: 3.049e-01\n",
      "Epoch 11611, Loss: 0.009752347134053707, Neurons: 64, Grad norm: 3.049e-01\n",
      "Epoch 11612, Loss: 0.009746345691382885, Neurons: 64, Grad norm: 2.240e-01\n",
      "Epoch 11612, Loss: 0.009746345691382885, Neurons: 64, Grad norm: 2.240e-01\n",
      "Epoch 11613, Loss: 0.009743452072143555, Neurons: 64, Grad norm: 2.273e-01\n",
      "Epoch 11613, Loss: 0.009743452072143555, Neurons: 64, Grad norm: 2.273e-01\n",
      "Epoch 11614, Loss: 0.00974215753376484, Neurons: 64, Grad norm: 2.914e-01\n",
      "Epoch 11614, Loss: 0.00974215753376484, Neurons: 64, Grad norm: 2.914e-01\n",
      "Epoch 11615, Loss: 0.009741025976836681, Neurons: 64, Grad norm: 3.466e-01\n",
      "Epoch 11615, Loss: 0.009741025976836681, Neurons: 64, Grad norm: 3.466e-01\n",
      "Epoch 11616, Loss: 0.009738936088979244, Neurons: 64, Grad norm: 3.818e-01\n",
      "Epoch 11616, Loss: 0.009738936088979244, Neurons: 64, Grad norm: 3.818e-01\n",
      "Epoch 11617, Loss: 0.009735583327710629, Neurons: 64, Grad norm: 4.223e-01\n",
      "Epoch 11617, Loss: 0.009735583327710629, Neurons: 64, Grad norm: 4.223e-01\n",
      "Epoch 11618, Loss: 0.009731556288897991, Neurons: 64, Grad norm: 4.529e-01\n",
      "Epoch 11618, Loss: 0.009731556288897991, Neurons: 64, Grad norm: 4.529e-01\n",
      "Epoch 11619, Loss: 0.009727590717375278, Neurons: 64, Grad norm: 5.126e-01\n",
      "Epoch 11619, Loss: 0.009727590717375278, Neurons: 64, Grad norm: 5.126e-01\n",
      "Epoch 11620, Loss: 0.009724310599267483, Neurons: 64, Grad norm: 5.607e-01\n",
      "Epoch 11620, Loss: 0.009724310599267483, Neurons: 64, Grad norm: 5.607e-01\n",
      "Epoch 11621, Loss: 0.00972181186079979, Neurons: 64, Grad norm: 6.406e-01\n",
      "Epoch 11621, Loss: 0.00972181186079979, Neurons: 64, Grad norm: 6.406e-01\n",
      "Epoch 11622, Loss: 0.009720159694552422, Neurons: 64, Grad norm: 6.950e-01\n",
      "Epoch 11622, Loss: 0.009720159694552422, Neurons: 64, Grad norm: 6.950e-01\n",
      "Epoch 11623, Loss: 0.009719016030430794, Neurons: 64, Grad norm: 7.746e-01\n",
      "Epoch 11623, Loss: 0.009719016030430794, Neurons: 64, Grad norm: 7.746e-01\n",
      "Epoch 11624, Loss: 0.009717963635921478, Neurons: 64, Grad norm: 8.251e-01\n",
      "Epoch 11624, Loss: 0.009717963635921478, Neurons: 64, Grad norm: 8.251e-01\n",
      "Epoch 11625, Loss: 0.009716730564832687, Neurons: 64, Grad norm: 9.025e-01\n",
      "Epoch 11625, Loss: 0.009716730564832687, Neurons: 64, Grad norm: 9.025e-01\n",
      "Epoch 11626, Loss: 0.009715322405099869, Neurons: 64, Grad norm: 9.545e-01\n",
      "Epoch 11626, Loss: 0.009715322405099869, Neurons: 64, Grad norm: 9.545e-01\n",
      "Epoch 11627, Loss: 0.009713814593851566, Neurons: 64, Grad norm: 1.038e+00\n",
      "Epoch 11627, Loss: 0.009713814593851566, Neurons: 64, Grad norm: 1.038e+00\n",
      "Epoch 11628, Loss: 0.009712357074022293, Neurons: 64, Grad norm: 1.103e+00\n",
      "Epoch 11628, Loss: 0.009712357074022293, Neurons: 64, Grad norm: 1.103e+00\n",
      "Epoch 11629, Loss: 0.009711413644254208, Neurons: 64, Grad norm: 1.207e+00\n",
      "Epoch 11629, Loss: 0.009711413644254208, Neurons: 64, Grad norm: 1.207e+00\n",
      "Epoch 11630, Loss: 0.009711233898997307, Neurons: 64, Grad norm: 1.305e+00\n",
      "Epoch 11630, Loss: 0.009711233898997307, Neurons: 64, Grad norm: 1.305e+00\n",
      "Epoch 11631, Loss: 0.00971210841089487, Neurons: 64, Grad norm: 1.446e+00\n",
      "Epoch 11631, Loss: 0.00971210841089487, Neurons: 64, Grad norm: 1.446e+00\n",
      "Epoch 11632, Loss: 0.00971442461013794, Neurons: 64, Grad norm: 1.582e+00\n",
      "Epoch 11632, Loss: 0.00971442461013794, Neurons: 64, Grad norm: 1.582e+00\n",
      "Epoch 11633, Loss: 0.009718426503241062, Neurons: 64, Grad norm: 1.766e+00\n",
      "Epoch 11633, Loss: 0.009718426503241062, Neurons: 64, Grad norm: 1.766e+00\n",
      "Epoch 11634, Loss: 0.009724423289299011, Neurons: 64, Grad norm: 1.951e+00\n",
      "Epoch 11634, Loss: 0.009724423289299011, Neurons: 64, Grad norm: 1.951e+00\n",
      "Epoch 11635, Loss: 0.009733017534017563, Neurons: 64, Grad norm: 2.192e+00\n",
      "Epoch 11635, Loss: 0.009733017534017563, Neurons: 64, Grad norm: 2.192e+00\n",
      "Epoch 11636, Loss: 0.009744398295879364, Neurons: 64, Grad norm: 2.438e+00\n",
      "Epoch 11636, Loss: 0.009744398295879364, Neurons: 64, Grad norm: 2.438e+00\n",
      "Epoch 11637, Loss: 0.009759495034813881, Neurons: 64, Grad norm: 2.743e+00\n",
      "Epoch 11637, Loss: 0.009759495034813881, Neurons: 64, Grad norm: 2.743e+00\n",
      "Epoch 11638, Loss: 0.00977935642004013, Neurons: 64, Grad norm: 3.063e+00\n",
      "Epoch 11638, Loss: 0.00977935642004013, Neurons: 64, Grad norm: 3.063e+00\n",
      "Epoch 11639, Loss: 0.009805265814065933, Neurons: 64, Grad norm: 3.445e+00\n",
      "Epoch 11639, Loss: 0.009805265814065933, Neurons: 64, Grad norm: 3.445e+00\n",
      "Epoch 11640, Loss: 0.009838332422077656, Neurons: 64, Grad norm: 3.839e+00\n",
      "Epoch 11640, Loss: 0.009838332422077656, Neurons: 64, Grad norm: 3.839e+00\n",
      "Epoch 11641, Loss: 0.009879924356937408, Neurons: 64, Grad norm: 4.286e+00\n",
      "Epoch 11641, Loss: 0.009879924356937408, Neurons: 64, Grad norm: 4.286e+00\n",
      "Epoch 11642, Loss: 0.009930207394063473, Neurons: 64, Grad norm: 4.720e+00\n",
      "Epoch 11642, Loss: 0.009930207394063473, Neurons: 64, Grad norm: 4.720e+00\n",
      "Epoch 11643, Loss: 0.00998867116868496, Neurons: 64, Grad norm: 5.174e+00\n",
      "Epoch 11643, Loss: 0.00998867116868496, Neurons: 64, Grad norm: 5.174e+00\n",
      "Epoch 11644, Loss: 0.010052090510725975, Neurons: 64, Grad norm: 5.564e+00\n",
      "Epoch 11644, Loss: 0.010052090510725975, Neurons: 64, Grad norm: 5.564e+00\n",
      "Epoch 11645, Loss: 0.010115181095898151, Neurons: 64, Grad norm: 5.894e+00\n",
      "Epoch 11645, Loss: 0.010115181095898151, Neurons: 64, Grad norm: 5.894e+00\n",
      "Epoch 11646, Loss: 0.010167370550334454, Neurons: 64, Grad norm: 6.062e+00\n",
      "Epoch 11646, Loss: 0.010167370550334454, Neurons: 64, Grad norm: 6.062e+00\n",
      "Epoch 11647, Loss: 0.010197562165558338, Neurons: 64, Grad norm: 6.062e+00\n",
      "Epoch 11647, Loss: 0.010197562165558338, Neurons: 64, Grad norm: 6.062e+00\n",
      "Epoch 11648, Loss: 0.010192126035690308, Neurons: 64, Grad norm: 5.797e+00\n",
      "Epoch 11648, Loss: 0.010192126035690308, Neurons: 64, Grad norm: 5.797e+00\n",
      "Epoch 11649, Loss: 0.010143945924937725, Neurons: 64, Grad norm: 5.288e+00\n",
      "Epoch 11649, Loss: 0.010143945924937725, Neurons: 64, Grad norm: 5.288e+00\n",
      "Epoch 11650, Loss: 0.010052813217043877, Neurons: 64, Grad norm: 4.493e+00\n",
      "Epoch 11650, Loss: 0.010052813217043877, Neurons: 64, Grad norm: 4.493e+00\n",
      "Epoch 11651, Loss: 0.009933358058333397, Neurons: 64, Grad norm: 3.504e+00\n",
      "Epoch 11651, Loss: 0.009933358058333397, Neurons: 64, Grad norm: 3.504e+00\n",
      "Epoch 11652, Loss: 0.009808046743273735, Neurons: 64, Grad norm: 2.342e+00\n",
      "Epoch 11652, Loss: 0.009808046743273735, Neurons: 64, Grad norm: 2.342e+00\n",
      "Epoch 11653, Loss: 0.009702825918793678, Neurons: 64, Grad norm: 1.154e+00\n",
      "Epoch 11653, Loss: 0.009702825918793678, Neurons: 64, Grad norm: 1.154e+00\n",
      "Epoch 11654, Loss: 0.009635891765356064, Neurons: 64, Grad norm: 2.572e-02\n",
      "Epoch 11654, Loss: 0.009635891765356064, Neurons: 64, Grad norm: 2.572e-02\n",
      "Epoch 11655, Loss: 0.009612787514925003, Neurons: 64, Grad norm: 1.052e+00\n",
      "Epoch 11655, Loss: 0.009612787514925003, Neurons: 64, Grad norm: 1.052e+00\n",
      "Epoch 11656, Loss: 0.00962686724960804, Neurons: 64, Grad norm: 1.935e+00\n",
      "Epoch 11656, Loss: 0.00962686724960804, Neurons: 64, Grad norm: 1.935e+00\n",
      "Epoch 11657, Loss: 0.009663439355790615, Neurons: 64, Grad norm: 2.577e+00\n",
      "Epoch 11657, Loss: 0.009663439355790615, Neurons: 64, Grad norm: 2.577e+00\n",
      "Epoch 11658, Loss: 0.00970548577606678, Neurons: 64, Grad norm: 3.007e+00\n",
      "Epoch 11658, Loss: 0.00970548577606678, Neurons: 64, Grad norm: 3.007e+00\n",
      "Epoch 11659, Loss: 0.009738042950630188, Neurons: 64, Grad norm: 3.171e+00\n",
      "Epoch 11659, Loss: 0.009738042950630188, Neurons: 64, Grad norm: 3.171e+00\n",
      "Epoch 11660, Loss: 0.00975157879292965, Neurons: 64, Grad norm: 3.125e+00\n",
      "Epoch 11660, Loss: 0.00975157879292965, Neurons: 64, Grad norm: 3.125e+00\n",
      "Epoch 11661, Loss: 0.009742953814566135, Neurons: 64, Grad norm: 2.843e+00\n",
      "Epoch 11661, Loss: 0.009742953814566135, Neurons: 64, Grad norm: 2.843e+00\n",
      "Epoch 11662, Loss: 0.009715363383293152, Neurons: 64, Grad norm: 2.410e+00\n",
      "Epoch 11662, Loss: 0.009715363383293152, Neurons: 64, Grad norm: 2.410e+00\n",
      "Epoch 11663, Loss: 0.009676727466285229, Neurons: 64, Grad norm: 1.825e+00\n",
      "Epoch 11663, Loss: 0.009676727466285229, Neurons: 64, Grad norm: 1.825e+00\n",
      "Epoch 11664, Loss: 0.009636645205318928, Neurons: 64, Grad norm: 1.191e+00\n",
      "Epoch 11664, Loss: 0.009636645205318928, Neurons: 64, Grad norm: 1.191e+00\n",
      "Epoch 11665, Loss: 0.00960415881127119, Neurons: 64, Grad norm: 5.143e-01\n",
      "Epoch 11665, Loss: 0.00960415881127119, Neurons: 64, Grad norm: 5.143e-01\n",
      "Epoch 11666, Loss: 0.009583751671016216, Neurons: 64, Grad norm: 1.113e-01\n",
      "Epoch 11666, Loss: 0.009583751671016216, Neurons: 64, Grad norm: 1.113e-01\n",
      "Epoch 11667, Loss: 0.00957694835960865, Neurons: 64, Grad norm: 6.850e-01\n",
      "Epoch 11667, Loss: 0.00957694835960865, Neurons: 64, Grad norm: 6.850e-01\n",
      "Epoch 11668, Loss: 0.009580669924616814, Neurons: 64, Grad norm: 1.133e+00\n",
      "Epoch 11668, Loss: 0.009580669924616814, Neurons: 64, Grad norm: 1.133e+00\n",
      "Epoch 11669, Loss: 0.009590554982423782, Neurons: 64, Grad norm: 1.490e+00\n",
      "Epoch 11669, Loss: 0.009590554982423782, Neurons: 64, Grad norm: 1.490e+00\n",
      "Epoch 11670, Loss: 0.009601257741451263, Neurons: 64, Grad norm: 1.697e+00\n",
      "Epoch 11670, Loss: 0.009601257741451263, Neurons: 64, Grad norm: 1.697e+00\n",
      "Epoch 11671, Loss: 0.00960899144411087, Neurons: 64, Grad norm: 1.807e+00\n",
      "Epoch 11671, Loss: 0.00960899144411087, Neurons: 64, Grad norm: 1.807e+00\n",
      "Epoch 11672, Loss: 0.009611147455871105, Neurons: 64, Grad norm: 1.774e+00\n",
      "Epoch 11672, Loss: 0.009611147455871105, Neurons: 64, Grad norm: 1.774e+00\n",
      "Epoch 11673, Loss: 0.009607172571122646, Neurons: 64, Grad norm: 1.664e+00\n",
      "Epoch 11673, Loss: 0.009607172571122646, Neurons: 64, Grad norm: 1.664e+00\n",
      "Epoch 11674, Loss: 0.009597663767635822, Neurons: 64, Grad norm: 1.444e+00\n",
      "Epoch 11674, Loss: 0.009597663767635822, Neurons: 64, Grad norm: 1.444e+00\n",
      "Epoch 11675, Loss: 0.009584899991750717, Neurons: 64, Grad norm: 1.187e+00\n",
      "Epoch 11675, Loss: 0.009584899991750717, Neurons: 64, Grad norm: 1.187e+00\n",
      "Epoch 11676, Loss: 0.009571216069161892, Neurons: 64, Grad norm: 8.700e-01\n",
      "Epoch 11676, Loss: 0.009571216069161892, Neurons: 64, Grad norm: 8.700e-01\n",
      "Epoch 11677, Loss: 0.009558633901178837, Neurons: 64, Grad norm: 5.643e-01\n",
      "Epoch 11677, Loss: 0.009558633901178837, Neurons: 64, Grad norm: 5.643e-01\n",
      "Epoch 11678, Loss: 0.009548503905534744, Neurons: 64, Grad norm: 2.339e-01\n",
      "Epoch 11678, Loss: 0.009548503905534744, Neurons: 64, Grad norm: 2.339e-01\n",
      "Epoch 11679, Loss: 0.009541704319417477, Neurons: 64, Grad norm: 5.794e-02\n",
      "Epoch 11679, Loss: 0.009541704319417477, Neurons: 64, Grad norm: 5.794e-02\n",
      "Epoch 11680, Loss: 0.009537911042571068, Neurons: 64, Grad norm: 3.290e-01\n",
      "Epoch 11680, Loss: 0.009537911042571068, Neurons: 64, Grad norm: 3.290e-01\n",
      "Epoch 11681, Loss: 0.0095365010201931, Neurons: 64, Grad norm: 5.377e-01\n",
      "Epoch 11681, Loss: 0.0095365010201931, Neurons: 64, Grad norm: 5.377e-01\n",
      "Epoch 11682, Loss: 0.009536436758935452, Neurons: 64, Grad norm: 7.274e-01\n",
      "Epoch 11682, Loss: 0.009536436758935452, Neurons: 64, Grad norm: 7.274e-01\n",
      "Epoch 11683, Loss: 0.009536895900964737, Neurons: 64, Grad norm: 8.460e-01\n",
      "Epoch 11683, Loss: 0.009536895900964737, Neurons: 64, Grad norm: 8.460e-01\n",
      "Epoch 11684, Loss: 0.009537015110254288, Neurons: 64, Grad norm: 9.397e-01\n",
      "Epoch 11684, Loss: 0.009537015110254288, Neurons: 64, Grad norm: 9.397e-01\n",
      "Epoch 11685, Loss: 0.009536202065646648, Neurons: 64, Grad norm: 9.618e-01\n",
      "Epoch 11685, Loss: 0.009536202065646648, Neurons: 64, Grad norm: 9.618e-01\n",
      "Epoch 11686, Loss: 0.009534361772239208, Neurons: 64, Grad norm: 9.750e-01\n",
      "Epoch 11686, Loss: 0.009534361772239208, Neurons: 64, Grad norm: 9.750e-01\n",
      "Epoch 11687, Loss: 0.009531360119581223, Neurons: 64, Grad norm: 9.261e-01\n",
      "Epoch 11687, Loss: 0.009531360119581223, Neurons: 64, Grad norm: 9.261e-01\n",
      "Epoch 11688, Loss: 0.009527343325316906, Neurons: 64, Grad norm: 8.700e-01\n",
      "Epoch 11688, Loss: 0.009527343325316906, Neurons: 64, Grad norm: 8.700e-01\n",
      "Epoch 11689, Loss: 0.009522524662315845, Neurons: 64, Grad norm: 7.703e-01\n",
      "Epoch 11689, Loss: 0.009522524662315845, Neurons: 64, Grad norm: 7.703e-01\n",
      "Epoch 11690, Loss: 0.009517400525510311, Neurons: 64, Grad norm: 6.789e-01\n",
      "Epoch 11690, Loss: 0.009517400525510311, Neurons: 64, Grad norm: 6.789e-01\n",
      "Epoch 11691, Loss: 0.00951206311583519, Neurons: 64, Grad norm: 5.506e-01\n",
      "Epoch 11691, Loss: 0.00951206311583519, Neurons: 64, Grad norm: 5.506e-01\n",
      "Epoch 11692, Loss: 0.009506943635642529, Neurons: 64, Grad norm: 4.443e-01\n",
      "Epoch 11692, Loss: 0.009506943635642529, Neurons: 64, Grad norm: 4.443e-01\n",
      "Epoch 11693, Loss: 0.009502212516963482, Neurons: 64, Grad norm: 3.152e-01\n",
      "Epoch 11693, Loss: 0.009502212516963482, Neurons: 64, Grad norm: 3.152e-01\n",
      "Epoch 11694, Loss: 0.009497863240540028, Neurons: 64, Grad norm: 2.148e-01\n",
      "Epoch 11694, Loss: 0.009497863240540028, Neurons: 64, Grad norm: 2.148e-01\n",
      "Epoch 11695, Loss: 0.009493987075984478, Neurons: 64, Grad norm: 9.388e-02\n",
      "Epoch 11695, Loss: 0.009493987075984478, Neurons: 64, Grad norm: 9.388e-02\n",
      "Epoch 11696, Loss: 0.009490548633038998, Neurons: 64, Grad norm: 1.367e-02\n",
      "Epoch 11696, Loss: 0.009490548633038998, Neurons: 64, Grad norm: 1.367e-02\n",
      "Epoch 11697, Loss: 0.009487437084317207, Neurons: 64, Grad norm: 9.420e-02\n",
      "Epoch 11697, Loss: 0.009487437084317207, Neurons: 64, Grad norm: 9.420e-02\n",
      "Epoch 11698, Loss: 0.009484545327723026, Neurons: 64, Grad norm: 1.569e-01\n",
      "Epoch 11698, Loss: 0.009484545327723026, Neurons: 64, Grad norm: 1.569e-01\n",
      "Epoch 11699, Loss: 0.00948191899806261, Neurons: 64, Grad norm: 2.342e-01\n",
      "Epoch 11699, Loss: 0.00948191899806261, Neurons: 64, Grad norm: 2.342e-01\n",
      "Epoch 11699, Test loss: 0.007101146969944239\n",
      "Epoch 11699, Test loss: 0.007101146969944239\n",
      "Epoch 11700, Loss: 0.009479316882789135, Neurons: 64, Grad norm: 2.748e-01\n",
      "Epoch 11700, Loss: 0.009479316882789135, Neurons: 64, Grad norm: 2.748e-01\n",
      "Epoch 11701, Loss: 0.009476836770772934, Neurons: 64, Grad norm: 3.308e-01\n",
      "Epoch 11701, Loss: 0.009476836770772934, Neurons: 64, Grad norm: 3.308e-01\n",
      "Epoch 11702, Loss: 0.009474257007241249, Neurons: 64, Grad norm: 3.542e-01\n",
      "Epoch 11702, Loss: 0.009474257007241249, Neurons: 64, Grad norm: 3.542e-01\n",
      "Epoch 11703, Loss: 0.009471714496612549, Neurons: 64, Grad norm: 3.953e-01\n",
      "Epoch 11703, Loss: 0.009471714496612549, Neurons: 64, Grad norm: 3.953e-01\n",
      "Epoch 11704, Loss: 0.009469143114984035, Neurons: 64, Grad norm: 4.071e-01\n",
      "Epoch 11704, Loss: 0.009469143114984035, Neurons: 64, Grad norm: 4.071e-01\n",
      "Epoch 11705, Loss: 0.009466531686484814, Neurons: 64, Grad norm: 4.431e-01\n",
      "Epoch 11705, Loss: 0.009466531686484814, Neurons: 64, Grad norm: 4.431e-01\n",
      "Epoch 11706, Loss: 0.00946394819766283, Neurons: 64, Grad norm: 4.542e-01\n",
      "Epoch 11706, Loss: 0.00946394819766283, Neurons: 64, Grad norm: 4.542e-01\n",
      "Epoch 11707, Loss: 0.009461422450840473, Neurons: 64, Grad norm: 4.886e-01\n",
      "Epoch 11707, Loss: 0.009461422450840473, Neurons: 64, Grad norm: 4.886e-01\n",
      "Epoch 11708, Loss: 0.009458839893341064, Neurons: 64, Grad norm: 4.909e-01\n",
      "Epoch 11708, Loss: 0.009458839893341064, Neurons: 64, Grad norm: 4.909e-01\n",
      "Epoch 11709, Loss: 0.009456230327486992, Neurons: 64, Grad norm: 5.225e-01\n",
      "Epoch 11709, Loss: 0.009456230327486992, Neurons: 64, Grad norm: 5.225e-01\n",
      "Epoch 11710, Loss: 0.009453731589019299, Neurons: 64, Grad norm: 5.317e-01\n",
      "Epoch 11710, Loss: 0.009453731589019299, Neurons: 64, Grad norm: 5.317e-01\n",
      "Epoch 11711, Loss: 0.009451263584196568, Neurons: 64, Grad norm: 5.665e-01\n",
      "Epoch 11711, Loss: 0.009451263584196568, Neurons: 64, Grad norm: 5.665e-01\n",
      "Epoch 11712, Loss: 0.009448829106986523, Neurons: 64, Grad norm: 5.774e-01\n",
      "Epoch 11712, Loss: 0.009448829106986523, Neurons: 64, Grad norm: 5.774e-01\n",
      "Epoch 11713, Loss: 0.00944656040519476, Neurons: 64, Grad norm: 6.223e-01\n",
      "Epoch 11713, Loss: 0.00944656040519476, Neurons: 64, Grad norm: 6.223e-01\n",
      "Epoch 11714, Loss: 0.009444372728466988, Neurons: 64, Grad norm: 6.470e-01\n",
      "Epoch 11714, Loss: 0.009444372728466988, Neurons: 64, Grad norm: 6.470e-01\n",
      "Epoch 11715, Loss: 0.00944241601973772, Neurons: 64, Grad norm: 6.998e-01\n",
      "Epoch 11715, Loss: 0.00944241601973772, Neurons: 64, Grad norm: 6.998e-01\n",
      "Epoch 11716, Loss: 0.009440705180168152, Neurons: 64, Grad norm: 7.383e-01\n",
      "Epoch 11716, Loss: 0.009440705180168152, Neurons: 64, Grad norm: 7.383e-01\n",
      "Epoch 11717, Loss: 0.00943935289978981, Neurons: 64, Grad norm: 8.167e-01\n",
      "Epoch 11717, Loss: 0.00943935289978981, Neurons: 64, Grad norm: 8.167e-01\n",
      "Epoch 11718, Loss: 0.00943844486027956, Neurons: 64, Grad norm: 8.741e-01\n",
      "Epoch 11718, Loss: 0.00943844486027956, Neurons: 64, Grad norm: 8.741e-01\n",
      "Epoch 11719, Loss: 0.009438104927539825, Neurons: 64, Grad norm: 9.709e-01\n",
      "Epoch 11719, Loss: 0.009438104927539825, Neurons: 64, Grad norm: 9.709e-01\n",
      "Epoch 11720, Loss: 0.009438405744731426, Neurons: 64, Grad norm: 1.062e+00\n",
      "Epoch 11720, Loss: 0.009438405744731426, Neurons: 64, Grad norm: 1.062e+00\n",
      "Epoch 11721, Loss: 0.009439502842724323, Neurons: 64, Grad norm: 1.197e+00\n",
      "Epoch 11721, Loss: 0.009439502842724323, Neurons: 64, Grad norm: 1.197e+00\n",
      "Epoch 11722, Loss: 0.00944172777235508, Neurons: 64, Grad norm: 1.323e+00\n",
      "Epoch 11722, Loss: 0.00944172777235508, Neurons: 64, Grad norm: 1.323e+00\n",
      "Epoch 11723, Loss: 0.009445586241781712, Neurons: 64, Grad norm: 1.499e+00\n",
      "Epoch 11723, Loss: 0.009445586241781712, Neurons: 64, Grad norm: 1.499e+00\n",
      "Epoch 11724, Loss: 0.009451408870518208, Neurons: 64, Grad norm: 1.681e+00\n",
      "Epoch 11724, Loss: 0.009451408870518208, Neurons: 64, Grad norm: 1.681e+00\n",
      "Epoch 11725, Loss: 0.009459774009883404, Neurons: 64, Grad norm: 1.925e+00\n",
      "Epoch 11725, Loss: 0.009459774009883404, Neurons: 64, Grad norm: 1.925e+00\n",
      "Epoch 11726, Loss: 0.009471883997321129, Neurons: 64, Grad norm: 2.178e+00\n",
      "Epoch 11726, Loss: 0.009471883997321129, Neurons: 64, Grad norm: 2.178e+00\n",
      "Epoch 11727, Loss: 0.009488645941019058, Neurons: 64, Grad norm: 2.500e+00\n",
      "Epoch 11727, Loss: 0.009488645941019058, Neurons: 64, Grad norm: 2.500e+00\n",
      "Epoch 11728, Loss: 0.009511686861515045, Neurons: 64, Grad norm: 2.843e+00\n",
      "Epoch 11728, Loss: 0.009511686861515045, Neurons: 64, Grad norm: 2.843e+00\n",
      "Epoch 11729, Loss: 0.00954239908605814, Neurons: 64, Grad norm: 3.256e+00\n",
      "Epoch 11729, Loss: 0.00954239908605814, Neurons: 64, Grad norm: 3.256e+00\n",
      "Epoch 11730, Loss: 0.009582729078829288, Neurons: 64, Grad norm: 3.694e+00\n",
      "Epoch 11730, Loss: 0.009582729078829288, Neurons: 64, Grad norm: 3.694e+00\n",
      "Epoch 11731, Loss: 0.009633934125304222, Neurons: 64, Grad norm: 4.203e+00\n",
      "Epoch 11731, Loss: 0.009633934125304222, Neurons: 64, Grad norm: 4.203e+00\n",
      "Epoch 11732, Loss: 0.00969741865992546, Neurons: 64, Grad norm: 4.713e+00\n",
      "Epoch 11732, Loss: 0.00969741865992546, Neurons: 64, Grad norm: 4.713e+00\n",
      "Epoch 11733, Loss: 0.009771858341991901, Neurons: 64, Grad norm: 5.255e+00\n",
      "Epoch 11733, Loss: 0.009771858341991901, Neurons: 64, Grad norm: 5.255e+00\n",
      "Epoch 11734, Loss: 0.00985411461442709, Neurons: 64, Grad norm: 5.749e+00\n",
      "Epoch 11734, Loss: 0.00985411461442709, Neurons: 64, Grad norm: 5.749e+00\n",
      "Epoch 11735, Loss: 0.009936418384313583, Neurons: 64, Grad norm: 6.189e+00\n",
      "Epoch 11735, Loss: 0.009936418384313583, Neurons: 64, Grad norm: 6.189e+00\n",
      "Epoch 11736, Loss: 0.010006017982959747, Neurons: 64, Grad norm: 6.456e+00\n",
      "Epoch 11736, Loss: 0.010006017982959747, Neurons: 64, Grad norm: 6.456e+00\n",
      "Epoch 11737, Loss: 0.01004726067185402, Neurons: 64, Grad norm: 6.536e+00\n",
      "Epoch 11737, Loss: 0.01004726067185402, Neurons: 64, Grad norm: 6.536e+00\n",
      "Epoch 11738, Loss: 0.010043547488749027, Neurons: 64, Grad norm: 6.323e+00\n",
      "Epoch 11738, Loss: 0.010043547488749027, Neurons: 64, Grad norm: 6.323e+00\n",
      "Epoch 11739, Loss: 0.009986412711441517, Neurons: 64, Grad norm: 5.834e+00\n",
      "Epoch 11739, Loss: 0.009986412711441517, Neurons: 64, Grad norm: 5.834e+00\n",
      "Epoch 11740, Loss: 0.009879959747195244, Neurons: 64, Grad norm: 5.028e+00\n",
      "Epoch 11740, Loss: 0.009879959747195244, Neurons: 64, Grad norm: 5.028e+00\n",
      "Epoch 11741, Loss: 0.009746326133608818, Neurons: 64, Grad norm: 4.021e+00\n",
      "Epoch 11741, Loss: 0.009746326133608818, Neurons: 64, Grad norm: 4.021e+00\n",
      "Epoch 11742, Loss: 0.00961566437035799, Neurons: 64, Grad norm: 2.890e+00\n",
      "Epoch 11742, Loss: 0.00961566437035799, Neurons: 64, Grad norm: 2.890e+00\n",
      "Epoch 11743, Loss: 0.00951846782118082, Neurons: 64, Grad norm: 1.881e+00\n",
      "Epoch 11743, Loss: 0.00951846782118082, Neurons: 64, Grad norm: 1.881e+00\n",
      "Epoch 11744, Loss: 0.009470627643167973, Neurons: 64, Grad norm: 1.367e+00\n",
      "Epoch 11744, Loss: 0.009470627643167973, Neurons: 64, Grad norm: 1.367e+00\n",
      "Epoch 11745, Loss: 0.009470081888139248, Neurons: 64, Grad norm: 1.637e+00\n",
      "Epoch 11745, Loss: 0.009470081888139248, Neurons: 64, Grad norm: 1.637e+00\n",
      "Epoch 11746, Loss: 0.009497182443737984, Neurons: 64, Grad norm: 2.183e+00\n",
      "Epoch 11746, Loss: 0.009497182443737984, Neurons: 64, Grad norm: 2.183e+00\n",
      "Epoch 11747, Loss: 0.009527396410703659, Neurons: 64, Grad norm: 2.578e+00\n",
      "Epoch 11747, Loss: 0.009527396410703659, Neurons: 64, Grad norm: 2.578e+00\n",
      "Epoch 11748, Loss: 0.009537559933960438, Neurons: 64, Grad norm: 2.756e+00\n",
      "Epoch 11748, Loss: 0.009537559933960438, Neurons: 64, Grad norm: 2.756e+00\n",
      "Epoch 11749, Loss: 0.009518928825855255, Neurons: 64, Grad norm: 2.659e+00\n",
      "Epoch 11749, Loss: 0.009518928825855255, Neurons: 64, Grad norm: 2.659e+00\n",
      "Epoch 11750, Loss: 0.00947610940784216, Neurons: 64, Grad norm: 2.384e+00\n",
      "Epoch 11750, Loss: 0.00947610940784216, Neurons: 64, Grad norm: 2.384e+00\n",
      "Epoch 11751, Loss: 0.009425968863070011, Neurons: 64, Grad norm: 1.959e+00\n",
      "Epoch 11751, Loss: 0.009425968863070011, Neurons: 64, Grad norm: 1.959e+00\n",
      "Epoch 11752, Loss: 0.009386483579874039, Neurons: 64, Grad norm: 1.531e+00\n",
      "Epoch 11752, Loss: 0.009386483579874039, Neurons: 64, Grad norm: 1.531e+00\n",
      "Epoch 11753, Loss: 0.009368441067636013, Neurons: 64, Grad norm: 1.182e+00\n",
      "Epoch 11753, Loss: 0.009368441067636013, Neurons: 64, Grad norm: 1.182e+00\n",
      "Epoch 11754, Loss: 0.009371515363454819, Neurons: 64, Grad norm: 1.059e+00\n",
      "Epoch 11754, Loss: 0.009371515363454819, Neurons: 64, Grad norm: 1.059e+00\n",
      "Epoch 11755, Loss: 0.00938643142580986, Neurons: 64, Grad norm: 1.111e+00\n",
      "Epoch 11755, Loss: 0.00938643142580986, Neurons: 64, Grad norm: 1.111e+00\n",
      "Epoch 11756, Loss: 0.00940027367323637, Neurons: 64, Grad norm: 1.190e+00\n",
      "Epoch 11756, Loss: 0.00940027367323637, Neurons: 64, Grad norm: 1.190e+00\n",
      "Epoch 11757, Loss: 0.009402414783835411, Neurons: 64, Grad norm: 1.216e+00\n",
      "Epoch 11757, Loss: 0.009402414783835411, Neurons: 64, Grad norm: 1.216e+00\n",
      "Epoch 11758, Loss: 0.00938990619033575, Neurons: 64, Grad norm: 1.124e+00\n",
      "Epoch 11758, Loss: 0.00938990619033575, Neurons: 64, Grad norm: 1.124e+00\n",
      "Epoch 11759, Loss: 0.009364955127239227, Neurons: 64, Grad norm: 9.699e-01\n",
      "Epoch 11759, Loss: 0.009364955127239227, Neurons: 64, Grad norm: 9.699e-01\n",
      "Epoch 11760, Loss: 0.009336781688034534, Neurons: 64, Grad norm: 7.579e-01\n",
      "Epoch 11760, Loss: 0.009336781688034534, Neurons: 64, Grad norm: 7.579e-01\n",
      "Epoch 11761, Loss: 0.009315035305917263, Neurons: 64, Grad norm: 6.136e-01\n",
      "Epoch 11761, Loss: 0.009315035305917263, Neurons: 64, Grad norm: 6.136e-01\n",
      "Epoch 11762, Loss: 0.009305647574365139, Neurons: 64, Grad norm: 5.711e-01\n",
      "Epoch 11762, Loss: 0.009305647574365139, Neurons: 64, Grad norm: 5.711e-01\n",
      "Epoch 11763, Loss: 0.00930819846689701, Neurons: 64, Grad norm: 6.535e-01\n",
      "Epoch 11763, Loss: 0.00930819846689701, Neurons: 64, Grad norm: 6.535e-01\n",
      "Epoch 11764, Loss: 0.009317575953900814, Neurons: 64, Grad norm: 7.456e-01\n",
      "Epoch 11764, Loss: 0.009317575953900814, Neurons: 64, Grad norm: 7.456e-01\n",
      "Epoch 11765, Loss: 0.009326883591711521, Neurons: 64, Grad norm: 7.896e-01\n",
      "Epoch 11765, Loss: 0.009326883591711521, Neurons: 64, Grad norm: 7.896e-01\n",
      "Epoch 11766, Loss: 0.00933043472468853, Neurons: 64, Grad norm: 7.701e-01\n",
      "Epoch 11766, Loss: 0.00933043472468853, Neurons: 64, Grad norm: 7.701e-01\n",
      "Epoch 11767, Loss: 0.009325842373073101, Neurons: 64, Grad norm: 6.753e-01\n",
      "Epoch 11767, Loss: 0.009325842373073101, Neurons: 64, Grad norm: 6.753e-01\n",
      "Epoch 11768, Loss: 0.009314088150858879, Neurons: 64, Grad norm: 5.316e-01\n",
      "Epoch 11768, Loss: 0.009314088150858879, Neurons: 64, Grad norm: 5.316e-01\n",
      "Epoch 11769, Loss: 0.009299119934439659, Neurons: 64, Grad norm: 3.535e-01\n",
      "Epoch 11769, Loss: 0.009299119934439659, Neurons: 64, Grad norm: 3.535e-01\n",
      "Epoch 11770, Loss: 0.009285444393754005, Neurons: 64, Grad norm: 2.004e-01\n",
      "Epoch 11770, Loss: 0.009285444393754005, Neurons: 64, Grad norm: 2.004e-01\n",
      "Epoch 11771, Loss: 0.009276359342038631, Neurons: 64, Grad norm: 2.046e-01\n",
      "Epoch 11771, Loss: 0.009276359342038631, Neurons: 64, Grad norm: 2.046e-01\n",
      "Epoch 11772, Loss: 0.009272784925997257, Neurons: 64, Grad norm: 3.018e-01\n",
      "Epoch 11772, Loss: 0.009272784925997257, Neurons: 64, Grad norm: 3.018e-01\n",
      "Epoch 11773, Loss: 0.009273304603993893, Neurons: 64, Grad norm: 4.167e-01\n",
      "Epoch 11773, Loss: 0.009273304603993893, Neurons: 64, Grad norm: 4.167e-01\n",
      "Epoch 11774, Loss: 0.009275752119719982, Neurons: 64, Grad norm: 4.729e-01\n",
      "Epoch 11774, Loss: 0.009275752119719982, Neurons: 64, Grad norm: 4.729e-01\n",
      "Epoch 11775, Loss: 0.009277491830289364, Neurons: 64, Grad norm: 5.002e-01\n",
      "Epoch 11775, Loss: 0.009277491830289364, Neurons: 64, Grad norm: 5.002e-01\n",
      "Epoch 11776, Loss: 0.009276911616325378, Neurons: 64, Grad norm: 4.737e-01\n",
      "Epoch 11776, Loss: 0.009276911616325378, Neurons: 64, Grad norm: 4.737e-01\n",
      "Epoch 11777, Loss: 0.009273422881960869, Neurons: 64, Grad norm: 4.313e-01\n",
      "Epoch 11777, Loss: 0.009273422881960869, Neurons: 64, Grad norm: 4.313e-01\n",
      "Epoch 11778, Loss: 0.009267781861126423, Neurons: 64, Grad norm: 3.812e-01\n",
      "Epoch 11778, Loss: 0.009267781861126423, Neurons: 64, Grad norm: 3.812e-01\n",
      "Epoch 11779, Loss: 0.009261254221200943, Neurons: 64, Grad norm: 3.555e-01\n",
      "Epoch 11779, Loss: 0.009261254221200943, Neurons: 64, Grad norm: 3.555e-01\n",
      "Epoch 11780, Loss: 0.00925526674836874, Neurons: 64, Grad norm: 3.827e-01\n",
      "Epoch 11780, Loss: 0.00925526674836874, Neurons: 64, Grad norm: 3.827e-01\n",
      "Epoch 11781, Loss: 0.00925049465149641, Neurons: 64, Grad norm: 4.244e-01\n",
      "Epoch 11781, Loss: 0.00925049465149641, Neurons: 64, Grad norm: 4.244e-01\n",
      "Epoch 11782, Loss: 0.009247283451259136, Neurons: 64, Grad norm: 4.972e-01\n",
      "Epoch 11782, Loss: 0.009247283451259136, Neurons: 64, Grad norm: 4.972e-01\n",
      "Epoch 11783, Loss: 0.009245346300303936, Neurons: 64, Grad norm: 5.316e-01\n",
      "Epoch 11783, Loss: 0.009245346300303936, Neurons: 64, Grad norm: 5.316e-01\n",
      "Epoch 11784, Loss: 0.009243912994861603, Neurons: 64, Grad norm: 5.729e-01\n",
      "Epoch 11784, Loss: 0.009243912994861603, Neurons: 64, Grad norm: 5.729e-01\n",
      "Epoch 11785, Loss: 0.009242476895451546, Neurons: 64, Grad norm: 5.646e-01\n",
      "Epoch 11785, Loss: 0.009242476895451546, Neurons: 64, Grad norm: 5.646e-01\n",
      "Epoch 11786, Loss: 0.009240387007594109, Neurons: 64, Grad norm: 5.574e-01\n",
      "Epoch 11786, Loss: 0.009240387007594109, Neurons: 64, Grad norm: 5.574e-01\n",
      "Epoch 11787, Loss: 0.009237438440322876, Neurons: 64, Grad norm: 4.995e-01\n",
      "Epoch 11787, Loss: 0.009237438440322876, Neurons: 64, Grad norm: 4.995e-01\n",
      "Epoch 11788, Loss: 0.009233667515218258, Neurons: 64, Grad norm: 4.519e-01\n",
      "Epoch 11788, Loss: 0.009233667515218258, Neurons: 64, Grad norm: 4.519e-01\n",
      "Epoch 11789, Loss: 0.009229395538568497, Neurons: 64, Grad norm: 3.642e-01\n",
      "Epoch 11789, Loss: 0.009229395538568497, Neurons: 64, Grad norm: 3.642e-01\n",
      "Epoch 11790, Loss: 0.009225094690918922, Neurons: 64, Grad norm: 2.928e-01\n",
      "Epoch 11790, Loss: 0.009225094690918922, Neurons: 64, Grad norm: 2.928e-01\n",
      "Epoch 11791, Loss: 0.009220997802913189, Neurons: 64, Grad norm: 2.053e-01\n",
      "Epoch 11791, Loss: 0.009220997802913189, Neurons: 64, Grad norm: 2.053e-01\n",
      "Epoch 11792, Loss: 0.009217456914484501, Neurons: 64, Grad norm: 1.613e-01\n",
      "Epoch 11792, Loss: 0.009217456914484501, Neurons: 64, Grad norm: 1.613e-01\n",
      "Epoch 11793, Loss: 0.009214409627020359, Neurons: 64, Grad norm: 1.225e-01\n",
      "Epoch 11793, Loss: 0.009214409627020359, Neurons: 64, Grad norm: 1.225e-01\n",
      "Epoch 11794, Loss: 0.009211836382746696, Neurons: 64, Grad norm: 1.282e-01\n",
      "Epoch 11794, Loss: 0.009211836382746696, Neurons: 64, Grad norm: 1.282e-01\n",
      "Epoch 11795, Loss: 0.009209510870277882, Neurons: 64, Grad norm: 1.481e-01\n",
      "Epoch 11795, Loss: 0.009209510870277882, Neurons: 64, Grad norm: 1.481e-01\n",
      "Epoch 11796, Loss: 0.009207186289131641, Neurons: 64, Grad norm: 1.619e-01\n",
      "Epoch 11796, Loss: 0.009207186289131641, Neurons: 64, Grad norm: 1.619e-01\n",
      "Epoch 11797, Loss: 0.00920479279011488, Neurons: 64, Grad norm: 1.800e-01\n",
      "Epoch 11797, Loss: 0.00920479279011488, Neurons: 64, Grad norm: 1.800e-01\n",
      "Epoch 11798, Loss: 0.009202287532389164, Neurons: 64, Grad norm: 1.779e-01\n",
      "Epoch 11798, Loss: 0.009202287532389164, Neurons: 64, Grad norm: 1.779e-01\n",
      "Epoch 11799, Loss: 0.009199665859341621, Neurons: 64, Grad norm: 1.794e-01\n",
      "Epoch 11799, Loss: 0.009199665859341621, Neurons: 64, Grad norm: 1.794e-01\n",
      "Epoch 11799, Test loss: 0.0069196345284581184\n",
      "Epoch 11799, Test loss: 0.0069196345284581184\n",
      "Epoch 11800, Loss: 0.009196796454489231, Neurons: 64, Grad norm: 1.648e-01\n",
      "Epoch 11800, Loss: 0.009196796454489231, Neurons: 64, Grad norm: 1.648e-01\n",
      "Epoch 11801, Loss: 0.00919388234615326, Neurons: 64, Grad norm: 1.572e-01\n",
      "Epoch 11801, Loss: 0.00919388234615326, Neurons: 64, Grad norm: 1.572e-01\n",
      "Epoch 11802, Loss: 0.00919095054268837, Neurons: 64, Grad norm: 1.442e-01\n",
      "Epoch 11802, Loss: 0.00919095054268837, Neurons: 64, Grad norm: 1.442e-01\n",
      "Epoch 11803, Loss: 0.0091878492385149, Neurons: 64, Grad norm: 1.380e-01\n",
      "Epoch 11803, Loss: 0.0091878492385149, Neurons: 64, Grad norm: 1.380e-01\n",
      "Epoch 11804, Loss: 0.009184816852211952, Neurons: 64, Grad norm: 1.459e-01\n",
      "Epoch 11804, Loss: 0.009184816852211952, Neurons: 64, Grad norm: 1.459e-01\n",
      "Epoch 11805, Loss: 0.009181895293295383, Neurons: 64, Grad norm: 1.578e-01\n",
      "Epoch 11805, Loss: 0.009181895293295383, Neurons: 64, Grad norm: 1.578e-01\n",
      "Epoch 11806, Loss: 0.009179018437862396, Neurons: 64, Grad norm: 1.990e-01\n",
      "Epoch 11806, Loss: 0.009179018437862396, Neurons: 64, Grad norm: 1.990e-01\n",
      "Epoch 11807, Loss: 0.009176273830235004, Neurons: 64, Grad norm: 2.242e-01\n",
      "Epoch 11807, Loss: 0.009176273830235004, Neurons: 64, Grad norm: 2.242e-01\n",
      "Epoch 11808, Loss: 0.009173736907541752, Neurons: 64, Grad norm: 2.780e-01\n",
      "Epoch 11808, Loss: 0.009173736907541752, Neurons: 64, Grad norm: 2.780e-01\n",
      "Epoch 11809, Loss: 0.00917123258113861, Neurons: 64, Grad norm: 3.129e-01\n",
      "Epoch 11809, Loss: 0.00917123258113861, Neurons: 64, Grad norm: 3.129e-01\n",
      "Epoch 11810, Loss: 0.009168904274702072, Neurons: 64, Grad norm: 3.770e-01\n",
      "Epoch 11810, Loss: 0.009168904274702072, Neurons: 64, Grad norm: 3.770e-01\n",
      "Epoch 11811, Loss: 0.009166755713522434, Neurons: 64, Grad norm: 4.204e-01\n",
      "Epoch 11811, Loss: 0.009166755713522434, Neurons: 64, Grad norm: 4.204e-01\n",
      "Epoch 11812, Loss: 0.009164688177406788, Neurons: 64, Grad norm: 4.965e-01\n",
      "Epoch 11812, Loss: 0.009164688177406788, Neurons: 64, Grad norm: 4.965e-01\n",
      "Epoch 11813, Loss: 0.009162796661257744, Neurons: 64, Grad norm: 5.609e-01\n",
      "Epoch 11813, Loss: 0.009162796661257744, Neurons: 64, Grad norm: 5.609e-01\n",
      "Epoch 11814, Loss: 0.00916124228388071, Neurons: 64, Grad norm: 6.559e-01\n",
      "Epoch 11814, Loss: 0.00916124228388071, Neurons: 64, Grad norm: 6.559e-01\n",
      "Epoch 11815, Loss: 0.009160072542726994, Neurons: 64, Grad norm: 7.419e-01\n",
      "Epoch 11815, Loss: 0.009160072542726994, Neurons: 64, Grad norm: 7.419e-01\n",
      "Epoch 11816, Loss: 0.00915949884802103, Neurons: 64, Grad norm: 8.765e-01\n",
      "Epoch 11816, Loss: 0.00915949884802103, Neurons: 64, Grad norm: 8.765e-01\n",
      "Epoch 11817, Loss: 0.00915985181927681, Neurons: 64, Grad norm: 1.012e+00\n",
      "Epoch 11817, Loss: 0.00915985181927681, Neurons: 64, Grad norm: 1.012e+00\n",
      "Epoch 11818, Loss: 0.009161480702459812, Neurons: 64, Grad norm: 1.201e+00\n",
      "Epoch 11818, Loss: 0.009161480702459812, Neurons: 64, Grad norm: 1.201e+00\n",
      "Epoch 11819, Loss: 0.009165004827082157, Neurons: 64, Grad norm: 1.404e+00\n",
      "Epoch 11819, Loss: 0.009165004827082157, Neurons: 64, Grad norm: 1.404e+00\n",
      "Epoch 11820, Loss: 0.009171429090201855, Neurons: 64, Grad norm: 1.681e+00\n",
      "Epoch 11820, Loss: 0.009171429090201855, Neurons: 64, Grad norm: 1.681e+00\n",
      "Epoch 11821, Loss: 0.009182026609778404, Neurons: 64, Grad norm: 1.998e+00\n",
      "Epoch 11821, Loss: 0.009182026609778404, Neurons: 64, Grad norm: 1.998e+00\n",
      "Epoch 11822, Loss: 0.00919915921986103, Neurons: 64, Grad norm: 2.408e+00\n",
      "Epoch 11822, Loss: 0.00919915921986103, Neurons: 64, Grad norm: 2.408e+00\n",
      "Epoch 11823, Loss: 0.009225445799529552, Neurons: 64, Grad norm: 2.878e+00\n",
      "Epoch 11823, Loss: 0.009225445799529552, Neurons: 64, Grad norm: 2.878e+00\n",
      "Epoch 11824, Loss: 0.009265565313398838, Neurons: 64, Grad norm: 3.473e+00\n",
      "Epoch 11824, Loss: 0.009265565313398838, Neurons: 64, Grad norm: 3.473e+00\n",
      "Epoch 11825, Loss: 0.009324515238404274, Neurons: 64, Grad norm: 4.155e+00\n",
      "Epoch 11825, Loss: 0.009324515238404274, Neurons: 64, Grad norm: 4.155e+00\n",
      "Epoch 11826, Loss: 0.00941028818488121, Neurons: 64, Grad norm: 4.968e+00\n",
      "Epoch 11826, Loss: 0.00941028818488121, Neurons: 64, Grad norm: 4.968e+00\n",
      "Epoch 11827, Loss: 0.00952959805727005, Neurons: 64, Grad norm: 5.860e+00\n",
      "Epoch 11827, Loss: 0.00952959805727005, Neurons: 64, Grad norm: 5.860e+00\n",
      "Epoch 11828, Loss: 0.009690426290035248, Neurons: 64, Grad norm: 6.834e+00\n",
      "Epoch 11828, Loss: 0.009690426290035248, Neurons: 64, Grad norm: 6.834e+00\n",
      "Epoch 11829, Loss: 0.009888865053653717, Neurons: 64, Grad norm: 7.755e+00\n",
      "Epoch 11829, Loss: 0.009888865053653717, Neurons: 64, Grad norm: 7.755e+00\n",
      "Epoch 11830, Loss: 0.010109420865774155, Neurons: 64, Grad norm: 8.519e+00\n",
      "Epoch 11830, Loss: 0.010109420865774155, Neurons: 64, Grad norm: 8.519e+00\n",
      "Epoch 11831, Loss: 0.01029971707612276, Neurons: 64, Grad norm: 8.874e+00\n",
      "Epoch 11831, Loss: 0.01029971707612276, Neurons: 64, Grad norm: 8.874e+00\n",
      "Epoch 11832, Loss: 0.010391424410045147, Neurons: 64, Grad norm: 8.645e+00\n",
      "Epoch 11832, Loss: 0.010391424410045147, Neurons: 64, Grad norm: 8.645e+00\n",
      "Epoch 11833, Loss: 0.010302337817847729, Neurons: 64, Grad norm: 7.642e+00\n",
      "Epoch 11833, Loss: 0.010302337817847729, Neurons: 64, Grad norm: 7.642e+00\n",
      "Epoch 11834, Loss: 0.010023604147136211, Neurons: 64, Grad norm: 5.922e+00\n",
      "Epoch 11834, Loss: 0.010023604147136211, Neurons: 64, Grad norm: 5.922e+00\n",
      "Epoch 11835, Loss: 0.009638319723308086, Neurons: 64, Grad norm: 3.664e+00\n",
      "Epoch 11835, Loss: 0.009638319723308086, Neurons: 64, Grad norm: 3.664e+00\n",
      "Epoch 11836, Loss: 0.009305531159043312, Neurons: 64, Grad norm: 1.394e+00\n",
      "Epoch 11836, Loss: 0.009305531159043312, Neurons: 64, Grad norm: 1.394e+00\n",
      "Epoch 11837, Loss: 0.009150534868240356, Neurons: 64, Grad norm: 1.580e+00\n",
      "Epoch 11837, Loss: 0.009150534868240356, Neurons: 64, Grad norm: 1.580e+00\n",
      "Epoch 11838, Loss: 0.009191690944135189, Neurons: 64, Grad norm: 3.302e+00\n",
      "Epoch 11838, Loss: 0.009191690944135189, Neurons: 64, Grad norm: 3.302e+00\n",
      "Epoch 11839, Loss: 0.00934331864118576, Neurons: 64, Grad norm: 4.485e+00\n",
      "Epoch 11839, Loss: 0.00934331864118576, Neurons: 64, Grad norm: 4.485e+00\n",
      "Epoch 11840, Loss: 0.00947923120111227, Neurons: 64, Grad norm: 4.880e+00\n",
      "Epoch 11840, Loss: 0.00947923120111227, Neurons: 64, Grad norm: 4.880e+00\n",
      "Epoch 11841, Loss: 0.009507792070508003, Neurons: 64, Grad norm: 4.522e+00\n",
      "Epoch 11841, Loss: 0.009507792070508003, Neurons: 64, Grad norm: 4.522e+00\n",
      "Epoch 11842, Loss: 0.009415201842784882, Neurons: 64, Grad norm: 3.513e+00\n",
      "Epoch 11842, Loss: 0.009415201842784882, Neurons: 64, Grad norm: 3.513e+00\n",
      "Epoch 11843, Loss: 0.009268389083445072, Neurons: 64, Grad norm: 2.177e+00\n",
      "Epoch 11843, Loss: 0.009268389083445072, Neurons: 64, Grad norm: 2.177e+00\n",
      "Epoch 11844, Loss: 0.00915757566690445, Neurons: 64, Grad norm: 1.078e+00\n",
      "Epoch 11844, Loss: 0.00915757566690445, Neurons: 64, Grad norm: 1.078e+00\n",
      "Epoch 11845, Loss: 0.009134145453572273, Neurons: 64, Grad norm: 1.450e+00\n",
      "Epoch 11845, Loss: 0.009134145453572273, Neurons: 64, Grad norm: 1.450e+00\n",
      "Epoch 11846, Loss: 0.009181617759168148, Neurons: 64, Grad norm: 2.272e+00\n",
      "Epoch 11846, Loss: 0.009181617759168148, Neurons: 64, Grad norm: 2.272e+00\n",
      "Epoch 11847, Loss: 0.009239775128662586, Neurons: 64, Grad norm: 2.693e+00\n",
      "Epoch 11847, Loss: 0.009239775128662586, Neurons: 64, Grad norm: 2.693e+00\n",
      "Epoch 11848, Loss: 0.009253201074898243, Neurons: 64, Grad norm: 2.634e+00\n",
      "Epoch 11848, Loss: 0.009253201074898243, Neurons: 64, Grad norm: 2.634e+00\n",
      "Epoch 11849, Loss: 0.009208595380187035, Neurons: 64, Grad norm: 2.136e+00\n",
      "Epoch 11849, Loss: 0.009208595380187035, Neurons: 64, Grad norm: 2.136e+00\n",
      "Epoch 11850, Loss: 0.009138554334640503, Neurons: 64, Grad norm: 1.435e+00\n",
      "Epoch 11850, Loss: 0.009138554334640503, Neurons: 64, Grad norm: 1.435e+00\n",
      "Epoch 11851, Loss: 0.009089767932891846, Neurons: 64, Grad norm: 8.674e-01\n",
      "Epoch 11851, Loss: 0.009089767932891846, Neurons: 64, Grad norm: 8.674e-01\n",
      "Epoch 11852, Loss: 0.009086664766073227, Neurons: 64, Grad norm: 9.829e-01\n",
      "Epoch 11852, Loss: 0.009086664766073227, Neurons: 64, Grad norm: 9.829e-01\n",
      "Epoch 11853, Loss: 0.009117048233747482, Neurons: 64, Grad norm: 1.358e+00\n",
      "Epoch 11853, Loss: 0.009117048233747482, Neurons: 64, Grad norm: 1.358e+00\n",
      "Epoch 11854, Loss: 0.009146862663328648, Neurons: 64, Grad norm: 1.526e+00\n",
      "Epoch 11854, Loss: 0.009146862663328648, Neurons: 64, Grad norm: 1.526e+00\n",
      "Epoch 11855, Loss: 0.009148746728897095, Neurons: 64, Grad norm: 1.418e+00\n",
      "Epoch 11855, Loss: 0.009148746728897095, Neurons: 64, Grad norm: 1.418e+00\n",
      "Epoch 11856, Loss: 0.00911741890013218, Neurons: 64, Grad norm: 1.048e+00\n",
      "Epoch 11856, Loss: 0.00911741890013218, Neurons: 64, Grad norm: 1.048e+00\n",
      "Epoch 11857, Loss: 0.009073715656995773, Neurons: 64, Grad norm: 5.715e-01\n",
      "Epoch 11857, Loss: 0.009073715656995773, Neurons: 64, Grad norm: 5.715e-01\n",
      "Epoch 11858, Loss: 0.009044813923537731, Neurons: 64, Grad norm: 3.479e-01\n",
      "Epoch 11858, Loss: 0.009044813923537731, Neurons: 64, Grad norm: 3.479e-01\n",
      "Epoch 11859, Loss: 0.009043844416737556, Neurons: 64, Grad norm: 6.688e-01\n",
      "Epoch 11859, Loss: 0.009043844416737556, Neurons: 64, Grad norm: 6.688e-01\n",
      "Epoch 11860, Loss: 0.00906275399029255, Neurons: 64, Grad norm: 9.374e-01\n",
      "Epoch 11860, Loss: 0.00906275399029255, Neurons: 64, Grad norm: 9.374e-01\n",
      "Epoch 11861, Loss: 0.009081532247364521, Neurons: 64, Grad norm: 1.006e+00\n",
      "Epoch 11861, Loss: 0.009081532247364521, Neurons: 64, Grad norm: 1.006e+00\n",
      "Epoch 11862, Loss: 0.009084583260118961, Neurons: 64, Grad norm: 8.788e-01\n",
      "Epoch 11862, Loss: 0.009084583260118961, Neurons: 64, Grad norm: 8.788e-01\n",
      "Epoch 11863, Loss: 0.009068470448255539, Neurons: 64, Grad norm: 5.902e-01\n",
      "Epoch 11863, Loss: 0.009068470448255539, Neurons: 64, Grad norm: 5.902e-01\n",
      "Epoch 11864, Loss: 0.009044220671057701, Neurons: 64, Grad norm: 2.402e-01\n",
      "Epoch 11864, Loss: 0.009044220671057701, Neurons: 64, Grad norm: 2.402e-01\n",
      "Epoch 11865, Loss: 0.009025249630212784, Neurons: 64, Grad norm: 2.519e-01\n",
      "Epoch 11865, Loss: 0.009025249630212784, Neurons: 64, Grad norm: 2.519e-01\n",
      "Epoch 11866, Loss: 0.009019787423312664, Neurons: 64, Grad norm: 5.309e-01\n",
      "Epoch 11866, Loss: 0.009019787423312664, Neurons: 64, Grad norm: 5.309e-01\n",
      "Epoch 11867, Loss: 0.009025669656693935, Neurons: 64, Grad norm: 7.145e-01\n",
      "Epoch 11867, Loss: 0.009025669656693935, Neurons: 64, Grad norm: 7.145e-01\n",
      "Epoch 11868, Loss: 0.009033914655447006, Neurons: 64, Grad norm: 7.387e-01\n",
      "Epoch 11868, Loss: 0.009033914655447006, Neurons: 64, Grad norm: 7.387e-01\n",
      "Epoch 11869, Loss: 0.009036030620336533, Neurons: 64, Grad norm: 6.373e-01\n",
      "Epoch 11869, Loss: 0.009036030620336533, Neurons: 64, Grad norm: 6.373e-01\n",
      "Epoch 11870, Loss: 0.009029342792928219, Neurons: 64, Grad norm: 4.385e-01\n",
      "Epoch 11870, Loss: 0.009029342792928219, Neurons: 64, Grad norm: 4.385e-01\n",
      "Epoch 11871, Loss: 0.00901784747838974, Neurons: 64, Grad norm: 2.676e-01\n",
      "Epoch 11871, Loss: 0.00901784747838974, Neurons: 64, Grad norm: 2.676e-01\n",
      "Epoch 11872, Loss: 0.009007555432617664, Neurons: 64, Grad norm: 3.585e-01\n",
      "Epoch 11872, Loss: 0.009007555432617664, Neurons: 64, Grad norm: 3.585e-01\n",
      "Epoch 11873, Loss: 0.009002632461488247, Neurons: 64, Grad norm: 5.309e-01\n",
      "Epoch 11873, Loss: 0.009002632461488247, Neurons: 64, Grad norm: 5.309e-01\n",
      "Epoch 11874, Loss: 0.009002947248518467, Neurons: 64, Grad norm: 6.590e-01\n",
      "Epoch 11874, Loss: 0.009002947248518467, Neurons: 64, Grad norm: 6.590e-01\n",
      "Epoch 11875, Loss: 0.009004911407828331, Neurons: 64, Grad norm: 6.733e-01\n",
      "Epoch 11875, Loss: 0.009004911407828331, Neurons: 64, Grad norm: 6.733e-01\n",
      "Epoch 11876, Loss: 0.009004720486700535, Neurons: 64, Grad norm: 6.033e-01\n",
      "Epoch 11876, Loss: 0.009004720486700535, Neurons: 64, Grad norm: 6.033e-01\n",
      "Epoch 11877, Loss: 0.009000727906823158, Neurons: 64, Grad norm: 4.295e-01\n",
      "Epoch 11877, Loss: 0.009000727906823158, Neurons: 64, Grad norm: 4.295e-01\n",
      "Epoch 11878, Loss: 0.008994278497993946, Neurons: 64, Grad norm: 2.288e-01\n",
      "Epoch 11878, Loss: 0.008994278497993946, Neurons: 64, Grad norm: 2.288e-01\n",
      "Epoch 11879, Loss: 0.008987655863165855, Neurons: 64, Grad norm: 1.327e-01\n",
      "Epoch 11879, Loss: 0.008987655863165855, Neurons: 64, Grad norm: 1.327e-01\n",
      "Epoch 11880, Loss: 0.00898315105587244, Neurons: 64, Grad norm: 2.827e-01\n",
      "Epoch 11880, Loss: 0.00898315105587244, Neurons: 64, Grad norm: 2.827e-01\n",
      "Epoch 11881, Loss: 0.008981271646916866, Neurons: 64, Grad norm: 4.465e-01\n",
      "Epoch 11881, Loss: 0.008981271646916866, Neurons: 64, Grad norm: 4.465e-01\n",
      "Epoch 11882, Loss: 0.008980747312307358, Neurons: 64, Grad norm: 5.298e-01\n",
      "Epoch 11882, Loss: 0.008980747312307358, Neurons: 64, Grad norm: 5.298e-01\n",
      "Epoch 11883, Loss: 0.00898018293082714, Neurons: 64, Grad norm: 5.599e-01\n",
      "Epoch 11883, Loss: 0.00898018293082714, Neurons: 64, Grad norm: 5.599e-01\n",
      "Epoch 11884, Loss: 0.008978166617453098, Neurons: 64, Grad norm: 4.996e-01\n",
      "Epoch 11884, Loss: 0.008978166617453098, Neurons: 64, Grad norm: 4.996e-01\n",
      "Epoch 11885, Loss: 0.008974695578217506, Neurons: 64, Grad norm: 4.051e-01\n",
      "Epoch 11885, Loss: 0.008974695578217506, Neurons: 64, Grad norm: 4.051e-01\n",
      "Epoch 11886, Loss: 0.008970193564891815, Neurons: 64, Grad norm: 2.504e-01\n",
      "Epoch 11886, Loss: 0.008970193564891815, Neurons: 64, Grad norm: 2.504e-01\n",
      "Epoch 11887, Loss: 0.008965710178017616, Neurons: 64, Grad norm: 1.088e-01\n",
      "Epoch 11887, Loss: 0.008965710178017616, Neurons: 64, Grad norm: 1.088e-01\n",
      "Epoch 11888, Loss: 0.008962160907685757, Neurons: 64, Grad norm: 7.005e-02\n",
      "Epoch 11888, Loss: 0.008962160907685757, Neurons: 64, Grad norm: 7.005e-02\n",
      "Epoch 11889, Loss: 0.008959662169218063, Neurons: 64, Grad norm: 1.801e-01\n",
      "Epoch 11889, Loss: 0.008959662169218063, Neurons: 64, Grad norm: 1.801e-01\n",
      "Epoch 11890, Loss: 0.008957886137068272, Neurons: 64, Grad norm: 2.696e-01\n",
      "Epoch 11890, Loss: 0.008957886137068272, Neurons: 64, Grad norm: 2.696e-01\n",
      "Epoch 11891, Loss: 0.0089561240747571, Neurons: 64, Grad norm: 3.006e-01\n",
      "Epoch 11891, Loss: 0.0089561240747571, Neurons: 64, Grad norm: 3.006e-01\n",
      "Epoch 11892, Loss: 0.00895395502448082, Neurons: 64, Grad norm: 3.090e-01\n",
      "Epoch 11892, Loss: 0.00895395502448082, Neurons: 64, Grad norm: 3.090e-01\n",
      "Epoch 11893, Loss: 0.008951188065111637, Neurons: 64, Grad norm: 2.606e-01\n",
      "Epoch 11893, Loss: 0.008951188065111637, Neurons: 64, Grad norm: 2.606e-01\n",
      "Epoch 11894, Loss: 0.008948002010583878, Neurons: 64, Grad norm: 2.157e-01\n",
      "Epoch 11894, Loss: 0.008948002010583878, Neurons: 64, Grad norm: 2.157e-01\n",
      "Epoch 11895, Loss: 0.008944811299443245, Neurons: 64, Grad norm: 1.409e-01\n",
      "Epoch 11895, Loss: 0.008944811299443245, Neurons: 64, Grad norm: 1.409e-01\n",
      "Epoch 11896, Loss: 0.008941779844462872, Neurons: 64, Grad norm: 9.816e-02\n",
      "Epoch 11896, Loss: 0.008941779844462872, Neurons: 64, Grad norm: 9.816e-02\n",
      "Epoch 11897, Loss: 0.008939134888350964, Neurons: 64, Grad norm: 8.238e-02\n",
      "Epoch 11897, Loss: 0.008939134888350964, Neurons: 64, Grad norm: 8.238e-02\n",
      "Epoch 11898, Loss: 0.008936814032495022, Neurons: 64, Grad norm: 1.147e-01\n",
      "Epoch 11898, Loss: 0.008936814032495022, Neurons: 64, Grad norm: 1.147e-01\n",
      "Epoch 11899, Loss: 0.00893468875437975, Neurons: 64, Grad norm: 1.421e-01\n",
      "Epoch 11899, Loss: 0.00893468875437975, Neurons: 64, Grad norm: 1.421e-01\n",
      "Epoch 11899, Test loss: 0.0067734248004853725\n",
      "Epoch 11899, Test loss: 0.0067734248004853725\n",
      "Epoch 11900, Loss: 0.008932390250265598, Neurons: 64, Grad norm: 1.519e-01\n",
      "Epoch 11900, Loss: 0.008932390250265598, Neurons: 64, Grad norm: 1.519e-01\n",
      "Epoch 11901, Loss: 0.00892995297908783, Neurons: 64, Grad norm: 1.467e-01\n",
      "Epoch 11901, Loss: 0.00892995297908783, Neurons: 64, Grad norm: 1.467e-01\n",
      "Epoch 11902, Loss: 0.008927286602556705, Neurons: 64, Grad norm: 1.153e-01\n",
      "Epoch 11902, Loss: 0.008927286602556705, Neurons: 64, Grad norm: 1.153e-01\n",
      "Epoch 11903, Loss: 0.008924335241317749, Neurons: 64, Grad norm: 7.897e-02\n",
      "Epoch 11903, Loss: 0.008924335241317749, Neurons: 64, Grad norm: 7.897e-02\n",
      "Epoch 11904, Loss: 0.008921471424400806, Neurons: 64, Grad norm: 3.864e-02\n",
      "Epoch 11904, Loss: 0.008921471424400806, Neurons: 64, Grad norm: 3.864e-02\n",
      "Epoch 11905, Loss: 0.008918607607483864, Neurons: 64, Grad norm: 3.092e-02\n",
      "Epoch 11905, Loss: 0.008918607607483864, Neurons: 64, Grad norm: 3.092e-02\n",
      "Epoch 11906, Loss: 0.008916054852306843, Neurons: 64, Grad norm: 7.854e-02\n",
      "Epoch 11906, Loss: 0.008916054852306843, Neurons: 64, Grad norm: 7.854e-02\n",
      "Epoch 11907, Loss: 0.00891350582242012, Neurons: 64, Grad norm: 9.892e-02\n",
      "Epoch 11907, Loss: 0.00891350582242012, Neurons: 64, Grad norm: 9.892e-02\n",
      "Epoch 11908, Loss: 0.008911172859370708, Neurons: 64, Grad norm: 1.249e-01\n",
      "Epoch 11908, Loss: 0.008911172859370708, Neurons: 64, Grad norm: 1.249e-01\n",
      "Epoch 11909, Loss: 0.008908728137612343, Neurons: 64, Grad norm: 1.214e-01\n",
      "Epoch 11909, Loss: 0.008908728137612343, Neurons: 64, Grad norm: 1.214e-01\n",
      "Epoch 11910, Loss: 0.008906273171305656, Neurons: 64, Grad norm: 1.152e-01\n",
      "Epoch 11910, Loss: 0.008906273171305656, Neurons: 64, Grad norm: 1.152e-01\n",
      "Epoch 11911, Loss: 0.008903730660676956, Neurons: 64, Grad norm: 8.836e-02\n",
      "Epoch 11911, Loss: 0.008903730660676956, Neurons: 64, Grad norm: 8.836e-02\n",
      "Epoch 11912, Loss: 0.00890100933611393, Neurons: 64, Grad norm: 6.653e-02\n",
      "Epoch 11912, Loss: 0.00890100933611393, Neurons: 64, Grad norm: 6.653e-02\n",
      "Epoch 11913, Loss: 0.008898346684873104, Neurons: 64, Grad norm: 4.352e-02\n",
      "Epoch 11913, Loss: 0.008898346684873104, Neurons: 64, Grad norm: 4.352e-02\n",
      "Epoch 11914, Loss: 0.008895658887922764, Neurons: 64, Grad norm: 3.042e-02\n",
      "Epoch 11914, Loss: 0.008895658887922764, Neurons: 64, Grad norm: 3.042e-02\n",
      "Epoch 11915, Loss: 0.008893030695617199, Neurons: 64, Grad norm: 6.095e-02\n",
      "Epoch 11915, Loss: 0.008893030695617199, Neurons: 64, Grad norm: 6.095e-02\n",
      "Epoch 11916, Loss: 0.00889051053673029, Neurons: 64, Grad norm: 7.255e-02\n",
      "Epoch 11916, Loss: 0.00889051053673029, Neurons: 64, Grad norm: 7.255e-02\n",
      "Epoch 11917, Loss: 0.008888095617294312, Neurons: 64, Grad norm: 1.024e-01\n",
      "Epoch 11917, Loss: 0.008888095617294312, Neurons: 64, Grad norm: 1.024e-01\n",
      "Epoch 11918, Loss: 0.00888561736792326, Neurons: 64, Grad norm: 1.039e-01\n",
      "Epoch 11918, Loss: 0.00888561736792326, Neurons: 64, Grad norm: 1.039e-01\n",
      "Epoch 11919, Loss: 0.008883143775165081, Neurons: 64, Grad norm: 1.181e-01\n",
      "Epoch 11919, Loss: 0.008883143775165081, Neurons: 64, Grad norm: 1.181e-01\n",
      "Epoch 11920, Loss: 0.00888063944876194, Neurons: 64, Grad norm: 1.086e-01\n",
      "Epoch 11920, Loss: 0.00888063944876194, Neurons: 64, Grad norm: 1.086e-01\n",
      "Epoch 11921, Loss: 0.008878032676875591, Neurons: 64, Grad norm: 1.105e-01\n",
      "Epoch 11921, Loss: 0.008878032676875591, Neurons: 64, Grad norm: 1.105e-01\n",
      "Epoch 11922, Loss: 0.008875447325408459, Neurons: 64, Grad norm: 8.586e-02\n",
      "Epoch 11922, Loss: 0.008875447325408459, Neurons: 64, Grad norm: 8.586e-02\n",
      "Epoch 11923, Loss: 0.008872871287167072, Neurons: 64, Grad norm: 8.953e-02\n",
      "Epoch 11923, Loss: 0.008872871287167072, Neurons: 64, Grad norm: 8.953e-02\n",
      "Epoch 11924, Loss: 0.008870357647538185, Neurons: 64, Grad norm: 7.004e-02\n",
      "Epoch 11924, Loss: 0.008870357647538185, Neurons: 64, Grad norm: 7.004e-02\n",
      "Epoch 11925, Loss: 0.008867794647812843, Neurons: 64, Grad norm: 7.273e-02\n",
      "Epoch 11925, Loss: 0.008867794647812843, Neurons: 64, Grad norm: 7.273e-02\n",
      "Epoch 11926, Loss: 0.008865256793797016, Neurons: 64, Grad norm: 5.743e-02\n",
      "Epoch 11926, Loss: 0.008865256793797016, Neurons: 64, Grad norm: 5.743e-02\n",
      "Epoch 11927, Loss: 0.008862742222845554, Neurons: 64, Grad norm: 7.073e-02\n",
      "Epoch 11927, Loss: 0.008862742222845554, Neurons: 64, Grad norm: 7.073e-02\n",
      "Epoch 11928, Loss: 0.008860228583216667, Neurons: 64, Grad norm: 6.386e-02\n",
      "Epoch 11928, Loss: 0.008860228583216667, Neurons: 64, Grad norm: 6.386e-02\n",
      "Epoch 11929, Loss: 0.008857776410877705, Neurons: 64, Grad norm: 8.346e-02\n",
      "Epoch 11929, Loss: 0.008857776410877705, Neurons: 64, Grad norm: 8.346e-02\n",
      "Epoch 11930, Loss: 0.008855276741087437, Neurons: 64, Grad norm: 8.054e-02\n",
      "Epoch 11930, Loss: 0.008855276741087437, Neurons: 64, Grad norm: 8.054e-02\n",
      "Epoch 11931, Loss: 0.008852813392877579, Neurons: 64, Grad norm: 1.008e-01\n",
      "Epoch 11931, Loss: 0.008852813392877579, Neurons: 64, Grad norm: 1.008e-01\n",
      "Epoch 11932, Loss: 0.00885032955557108, Neurons: 64, Grad norm: 1.035e-01\n",
      "Epoch 11932, Loss: 0.00885032955557108, Neurons: 64, Grad norm: 1.035e-01\n",
      "Epoch 11933, Loss: 0.008847878314554691, Neurons: 64, Grad norm: 1.387e-01\n",
      "Epoch 11933, Loss: 0.008847878314554691, Neurons: 64, Grad norm: 1.387e-01\n",
      "Epoch 11934, Loss: 0.008845433592796326, Neurons: 64, Grad norm: 1.502e-01\n",
      "Epoch 11934, Loss: 0.008845433592796326, Neurons: 64, Grad norm: 1.502e-01\n",
      "Epoch 11935, Loss: 0.008843041025102139, Neurons: 64, Grad norm: 1.901e-01\n",
      "Epoch 11935, Loss: 0.008843041025102139, Neurons: 64, Grad norm: 1.901e-01\n",
      "Epoch 11936, Loss: 0.008840713649988174, Neurons: 64, Grad norm: 2.170e-01\n",
      "Epoch 11936, Loss: 0.008840713649988174, Neurons: 64, Grad norm: 2.170e-01\n",
      "Epoch 11937, Loss: 0.00883858185261488, Neurons: 64, Grad norm: 2.775e-01\n",
      "Epoch 11937, Loss: 0.00883858185261488, Neurons: 64, Grad norm: 2.775e-01\n",
      "Epoch 11938, Loss: 0.008836541324853897, Neurons: 64, Grad norm: 3.217e-01\n",
      "Epoch 11938, Loss: 0.008836541324853897, Neurons: 64, Grad norm: 3.217e-01\n",
      "Epoch 11939, Loss: 0.008834776468575, Neurons: 64, Grad norm: 4.029e-01\n",
      "Epoch 11939, Loss: 0.008834776468575, Neurons: 64, Grad norm: 4.029e-01\n",
      "Epoch 11940, Loss: 0.008833305910229683, Neurons: 64, Grad norm: 4.750e-01\n",
      "Epoch 11940, Loss: 0.008833305910229683, Neurons: 64, Grad norm: 4.750e-01\n",
      "Epoch 11941, Loss: 0.008832347579300404, Neurons: 64, Grad norm: 5.867e-01\n",
      "Epoch 11941, Loss: 0.008832347579300404, Neurons: 64, Grad norm: 5.867e-01\n",
      "Epoch 11942, Loss: 0.008831958286464214, Neurons: 64, Grad norm: 6.942e-01\n",
      "Epoch 11942, Loss: 0.008831958286464214, Neurons: 64, Grad norm: 6.942e-01\n",
      "Epoch 11943, Loss: 0.008832556195557117, Neurons: 64, Grad norm: 8.558e-01\n",
      "Epoch 11943, Loss: 0.008832556195557117, Neurons: 64, Grad norm: 8.558e-01\n",
      "Epoch 11944, Loss: 0.00883452594280243, Neurons: 64, Grad norm: 1.020e+00\n",
      "Epoch 11944, Loss: 0.00883452594280243, Neurons: 64, Grad norm: 1.020e+00\n",
      "Epoch 11945, Loss: 0.00883866660296917, Neurons: 64, Grad norm: 1.252e+00\n",
      "Epoch 11945, Loss: 0.00883866660296917, Neurons: 64, Grad norm: 1.252e+00\n",
      "Epoch 11946, Loss: 0.008846397511661053, Neurons: 64, Grad norm: 1.513e+00\n",
      "Epoch 11946, Loss: 0.008846397511661053, Neurons: 64, Grad norm: 1.513e+00\n",
      "Epoch 11947, Loss: 0.00885900016874075, Neurons: 64, Grad norm: 1.861e+00\n",
      "Epoch 11947, Loss: 0.00885900016874075, Neurons: 64, Grad norm: 1.861e+00\n",
      "Epoch 11948, Loss: 0.008879467844963074, Neurons: 64, Grad norm: 2.263e+00\n",
      "Epoch 11948, Loss: 0.008879467844963074, Neurons: 64, Grad norm: 2.263e+00\n",
      "Epoch 11949, Loss: 0.00891136284917593, Neurons: 64, Grad norm: 2.779e+00\n",
      "Epoch 11949, Loss: 0.00891136284917593, Neurons: 64, Grad norm: 2.779e+00\n",
      "Epoch 11950, Loss: 0.008960625156760216, Neurons: 64, Grad norm: 3.384e+00\n",
      "Epoch 11950, Loss: 0.008960625156760216, Neurons: 64, Grad norm: 3.384e+00\n",
      "Epoch 11951, Loss: 0.009034151211380959, Neurons: 64, Grad norm: 4.137e+00\n",
      "Epoch 11951, Loss: 0.009034151211380959, Neurons: 64, Grad norm: 4.137e+00\n",
      "Epoch 11952, Loss: 0.009142088703811169, Neurons: 64, Grad norm: 4.988e+00\n",
      "Epoch 11952, Loss: 0.009142088703811169, Neurons: 64, Grad norm: 4.988e+00\n",
      "Epoch 11953, Loss: 0.009292780421674252, Neurons: 64, Grad norm: 5.968e+00\n",
      "Epoch 11953, Loss: 0.009292780421674252, Neurons: 64, Grad norm: 5.968e+00\n",
      "Epoch 11954, Loss: 0.009493076242506504, Neurons: 64, Grad norm: 6.977e+00\n",
      "Epoch 11954, Loss: 0.009493076242506504, Neurons: 64, Grad norm: 6.977e+00\n",
      "Epoch 11955, Loss: 0.009733377955853939, Neurons: 64, Grad norm: 7.951e+00\n",
      "Epoch 11955, Loss: 0.009733377955853939, Neurons: 64, Grad norm: 7.951e+00\n",
      "Epoch 11956, Loss: 0.009980037808418274, Neurons: 64, Grad norm: 8.662e+00\n",
      "Epoch 11956, Loss: 0.009980037808418274, Neurons: 64, Grad norm: 8.662e+00\n",
      "Epoch 11957, Loss: 0.010158955119550228, Neurons: 64, Grad norm: 8.925e+00\n",
      "Epoch 11957, Loss: 0.010158955119550228, Neurons: 64, Grad norm: 8.925e+00\n",
      "Epoch 11958, Loss: 0.01017899252474308, Neurons: 64, Grad norm: 8.478e+00\n",
      "Epoch 11958, Loss: 0.01017899252474308, Neurons: 64, Grad norm: 8.478e+00\n",
      "Epoch 11959, Loss: 0.0099832434207201, Neurons: 64, Grad norm: 7.263e+00\n",
      "Epoch 11959, Loss: 0.0099832434207201, Neurons: 64, Grad norm: 7.263e+00\n",
      "Epoch 11960, Loss: 0.009612169116735458, Neurons: 64, Grad norm: 5.334e+00\n",
      "Epoch 11960, Loss: 0.009612169116735458, Neurons: 64, Grad norm: 5.334e+00\n",
      "Epoch 11961, Loss: 0.009211622178554535, Neurons: 64, Grad norm: 3.054e+00\n",
      "Epoch 11961, Loss: 0.009211622178554535, Neurons: 64, Grad norm: 3.054e+00\n",
      "Epoch 11962, Loss: 0.008940829895436764, Neurons: 64, Grad norm: 1.283e+00\n",
      "Epoch 11962, Loss: 0.008940829895436764, Neurons: 64, Grad norm: 1.283e+00\n",
      "Epoch 11963, Loss: 0.008873315528035164, Neurons: 64, Grad norm: 2.329e+00\n",
      "Epoch 11963, Loss: 0.008873315528035164, Neurons: 64, Grad norm: 2.329e+00\n",
      "Epoch 11964, Loss: 0.008964557200670242, Neurons: 64, Grad norm: 3.902e+00\n",
      "Epoch 11964, Loss: 0.008964557200670242, Neurons: 64, Grad norm: 3.902e+00\n",
      "Epoch 11965, Loss: 0.009102756157517433, Neurons: 64, Grad norm: 4.858e+00\n",
      "Epoch 11965, Loss: 0.009102756157517433, Neurons: 64, Grad norm: 4.858e+00\n",
      "Epoch 11966, Loss: 0.009185793809592724, Neurons: 64, Grad norm: 5.096e+00\n",
      "Epoch 11966, Loss: 0.009185793809592724, Neurons: 64, Grad norm: 5.096e+00\n",
      "Epoch 11967, Loss: 0.009171796962618828, Neurons: 64, Grad norm: 4.597e+00\n",
      "Epoch 11967, Loss: 0.009171796962618828, Neurons: 64, Grad norm: 4.597e+00\n",
      "Epoch 11968, Loss: 0.009083672426640987, Neurons: 64, Grad norm: 3.565e+00\n",
      "Epoch 11968, Loss: 0.009083672426640987, Neurons: 64, Grad norm: 3.565e+00\n",
      "Epoch 11969, Loss: 0.008975178003311157, Neurons: 64, Grad norm: 2.249e+00\n",
      "Epoch 11969, Loss: 0.008975178003311157, Neurons: 64, Grad norm: 2.249e+00\n",
      "Epoch 11970, Loss: 0.008893954567611217, Neurons: 64, Grad norm: 1.264e+00\n",
      "Epoch 11970, Loss: 0.008893954567611217, Neurons: 64, Grad norm: 1.264e+00\n",
      "Epoch 11971, Loss: 0.008856249041855335, Neurons: 64, Grad norm: 1.598e+00\n",
      "Epoch 11971, Loss: 0.008856249041855335, Neurons: 64, Grad norm: 1.598e+00\n",
      "Epoch 11972, Loss: 0.008852730505168438, Neurons: 64, Grad norm: 2.415e+00\n",
      "Epoch 11972, Loss: 0.008852730505168438, Neurons: 64, Grad norm: 2.415e+00\n",
      "Epoch 11973, Loss: 0.008866802789270878, Neurons: 64, Grad norm: 2.990e+00\n",
      "Epoch 11973, Loss: 0.008866802789270878, Neurons: 64, Grad norm: 2.990e+00\n",
      "Epoch 11974, Loss: 0.008884855546057224, Neurons: 64, Grad norm: 3.115e+00\n",
      "Epoch 11974, Loss: 0.008884855546057224, Neurons: 64, Grad norm: 3.115e+00\n",
      "Epoch 11975, Loss: 0.00889604538679123, Neurons: 64, Grad norm: 2.845e+00\n",
      "Epoch 11975, Loss: 0.00889604538679123, Neurons: 64, Grad norm: 2.845e+00\n",
      "Epoch 11976, Loss: 0.008889890275895596, Neurons: 64, Grad norm: 2.226e+00\n",
      "Epoch 11976, Loss: 0.008889890275895596, Neurons: 64, Grad norm: 2.226e+00\n",
      "Epoch 11977, Loss: 0.008861267939209938, Neurons: 64, Grad norm: 1.440e+00\n",
      "Epoch 11977, Loss: 0.008861267939209938, Neurons: 64, Grad norm: 1.440e+00\n",
      "Epoch 11978, Loss: 0.008816637098789215, Neurons: 64, Grad norm: 7.721e-01\n",
      "Epoch 11978, Loss: 0.008816637098789215, Neurons: 64, Grad norm: 7.721e-01\n",
      "Epoch 11979, Loss: 0.008774756453931332, Neurons: 64, Grad norm: 9.337e-01\n",
      "Epoch 11979, Loss: 0.008774756453931332, Neurons: 64, Grad norm: 9.337e-01\n",
      "Epoch 11980, Loss: 0.008755333721637726, Neurons: 64, Grad norm: 1.523e+00\n",
      "Epoch 11980, Loss: 0.008755333721637726, Neurons: 64, Grad norm: 1.523e+00\n",
      "Epoch 11981, Loss: 0.008764847181737423, Neurons: 64, Grad norm: 1.926e+00\n",
      "Epoch 11981, Loss: 0.008764847181737423, Neurons: 64, Grad norm: 1.926e+00\n",
      "Epoch 11982, Loss: 0.00879079382866621, Neurons: 64, Grad norm: 2.063e+00\n",
      "Epoch 11982, Loss: 0.00879079382866621, Neurons: 64, Grad norm: 2.063e+00\n",
      "Epoch 11983, Loss: 0.00881014671176672, Neurons: 64, Grad norm: 1.877e+00\n",
      "Epoch 11983, Loss: 0.00881014671176672, Neurons: 64, Grad norm: 1.877e+00\n",
      "Epoch 11984, Loss: 0.008805139921605587, Neurons: 64, Grad norm: 1.453e+00\n",
      "Epoch 11984, Loss: 0.008805139921605587, Neurons: 64, Grad norm: 1.453e+00\n",
      "Epoch 11985, Loss: 0.00877653993666172, Neurons: 64, Grad norm: 8.421e-01\n",
      "Epoch 11985, Loss: 0.00877653993666172, Neurons: 64, Grad norm: 8.421e-01\n",
      "Epoch 11986, Loss: 0.008741326630115509, Neurons: 64, Grad norm: 2.192e-01\n",
      "Epoch 11986, Loss: 0.008741326630115509, Neurons: 64, Grad norm: 2.192e-01\n",
      "Epoch 11987, Loss: 0.008718617260456085, Neurons: 64, Grad norm: 5.235e-01\n",
      "Epoch 11987, Loss: 0.008718617260456085, Neurons: 64, Grad norm: 5.235e-01\n",
      "Epoch 11988, Loss: 0.008717771619558334, Neurons: 64, Grad norm: 1.009e+00\n",
      "Epoch 11988, Loss: 0.008717771619558334, Neurons: 64, Grad norm: 1.009e+00\n",
      "Epoch 11989, Loss: 0.008732401765882969, Neurons: 64, Grad norm: 1.323e+00\n",
      "Epoch 11989, Loss: 0.008732401765882969, Neurons: 64, Grad norm: 1.323e+00\n",
      "Epoch 11990, Loss: 0.008747673593461514, Neurons: 64, Grad norm: 1.399e+00\n",
      "Epoch 11990, Loss: 0.008747673593461514, Neurons: 64, Grad norm: 1.399e+00\n",
      "Epoch 11991, Loss: 0.00875126663595438, Neurons: 64, Grad norm: 1.285e+00\n",
      "Epoch 11991, Loss: 0.00875126663595438, Neurons: 64, Grad norm: 1.285e+00\n",
      "Epoch 11992, Loss: 0.00873998086899519, Neurons: 64, Grad norm: 9.860e-01\n",
      "Epoch 11992, Loss: 0.00873998086899519, Neurons: 64, Grad norm: 9.860e-01\n",
      "Epoch 11993, Loss: 0.008721226826310158, Neurons: 64, Grad norm: 6.006e-01\n",
      "Epoch 11993, Loss: 0.008721226826310158, Neurons: 64, Grad norm: 6.006e-01\n",
      "Epoch 11994, Loss: 0.008705032989382744, Neurons: 64, Grad norm: 2.034e-01\n",
      "Epoch 11994, Loss: 0.008705032989382744, Neurons: 64, Grad norm: 2.034e-01\n",
      "Epoch 11995, Loss: 0.008697922341525555, Neurons: 64, Grad norm: 3.246e-01\n",
      "Epoch 11995, Loss: 0.008697922341525555, Neurons: 64, Grad norm: 3.246e-01\n",
      "Epoch 11996, Loss: 0.008699524216353893, Neurons: 64, Grad norm: 6.294e-01\n",
      "Epoch 11996, Loss: 0.008699524216353893, Neurons: 64, Grad norm: 6.294e-01\n",
      "Epoch 11997, Loss: 0.008704489096999168, Neurons: 64, Grad norm: 8.266e-01\n",
      "Epoch 11997, Loss: 0.008704489096999168, Neurons: 64, Grad norm: 8.266e-01\n",
      "Epoch 11998, Loss: 0.008707401342689991, Neurons: 64, Grad norm: 9.174e-01\n",
      "Epoch 11998, Loss: 0.008707401342689991, Neurons: 64, Grad norm: 9.174e-01\n",
      "Epoch 11999, Loss: 0.00870500784367323, Neurons: 64, Grad norm: 8.699e-01\n",
      "Epoch 11999, Loss: 0.00870500784367323, Neurons: 64, Grad norm: 8.699e-01\n",
      "Epoch 11999, Test loss: 0.006586179137229919\n",
      "Epoch 11999, Test loss: 0.006586179137229919\n",
      "Epoch 12000, Loss: 0.008698579855263233, Neurons: 64, Grad norm: 7.516e-01\n",
      "Epoch 12000, Loss: 0.008698579855263233, Neurons: 64, Grad norm: 7.516e-01\n",
      "Epoch 12001, Loss: 0.008691267110407352, Neurons: 64, Grad norm: 5.528e-01\n",
      "Epoch 12001, Loss: 0.008691267110407352, Neurons: 64, Grad norm: 5.528e-01\n",
      "Epoch 12002, Loss: 0.008685411885380745, Neurons: 64, Grad norm: 3.702e-01\n",
      "Epoch 12002, Loss: 0.008685411885380745, Neurons: 64, Grad norm: 3.702e-01\n",
      "Epoch 12003, Loss: 0.008681811392307281, Neurons: 64, Grad norm: 2.482e-01\n",
      "Epoch 12003, Loss: 0.008681811392307281, Neurons: 64, Grad norm: 2.482e-01\n",
      "Epoch 12004, Loss: 0.008679665625095367, Neurons: 64, Grad norm: 3.039e-01\n",
      "Epoch 12004, Loss: 0.008679665625095367, Neurons: 64, Grad norm: 3.039e-01\n",
      "Epoch 12005, Loss: 0.008677862584590912, Neurons: 64, Grad norm: 4.297e-01\n",
      "Epoch 12005, Loss: 0.008677862584590912, Neurons: 64, Grad norm: 4.297e-01\n",
      "Epoch 12006, Loss: 0.008675696328282356, Neurons: 64, Grad norm: 5.175e-01\n",
      "Epoch 12006, Loss: 0.008675696328282356, Neurons: 64, Grad norm: 5.175e-01\n",
      "Epoch 12007, Loss: 0.008673456497490406, Neurons: 64, Grad norm: 5.809e-01\n",
      "Epoch 12007, Loss: 0.008673456497490406, Neurons: 64, Grad norm: 5.809e-01\n",
      "Epoch 12008, Loss: 0.008671202696859837, Neurons: 64, Grad norm: 5.669e-01\n",
      "Epoch 12008, Loss: 0.008671202696859837, Neurons: 64, Grad norm: 5.669e-01\n",
      "Epoch 12009, Loss: 0.008669057860970497, Neurons: 64, Grad norm: 5.229e-01\n",
      "Epoch 12009, Loss: 0.008669057860970497, Neurons: 64, Grad norm: 5.229e-01\n",
      "Epoch 12010, Loss: 0.008666401728987694, Neurons: 64, Grad norm: 4.119e-01\n",
      "Epoch 12010, Loss: 0.008666401728987694, Neurons: 64, Grad norm: 4.119e-01\n",
      "Epoch 12011, Loss: 0.008663313463330269, Neurons: 64, Grad norm: 2.980e-01\n",
      "Epoch 12011, Loss: 0.008663313463330269, Neurons: 64, Grad norm: 2.980e-01\n",
      "Epoch 12012, Loss: 0.00865965150296688, Neurons: 64, Grad norm: 1.634e-01\n",
      "Epoch 12012, Loss: 0.00865965150296688, Neurons: 64, Grad norm: 1.634e-01\n",
      "Epoch 12013, Loss: 0.008656053803861141, Neurons: 64, Grad norm: 1.313e-01\n",
      "Epoch 12013, Loss: 0.008656053803861141, Neurons: 64, Grad norm: 1.313e-01\n",
      "Epoch 12014, Loss: 0.008652999997138977, Neurons: 64, Grad norm: 2.249e-01\n",
      "Epoch 12014, Loss: 0.008652999997138977, Neurons: 64, Grad norm: 2.249e-01\n",
      "Epoch 12015, Loss: 0.008650634437799454, Neurons: 64, Grad norm: 3.034e-01\n",
      "Epoch 12015, Loss: 0.008650634437799454, Neurons: 64, Grad norm: 3.034e-01\n",
      "Epoch 12016, Loss: 0.008648895658552647, Neurons: 64, Grad norm: 3.781e-01\n",
      "Epoch 12016, Loss: 0.008648895658552647, Neurons: 64, Grad norm: 3.781e-01\n",
      "Epoch 12017, Loss: 0.00864733662456274, Neurons: 64, Grad norm: 3.914e-01\n",
      "Epoch 12017, Loss: 0.00864733662456274, Neurons: 64, Grad norm: 3.914e-01\n",
      "Epoch 12018, Loss: 0.008645474910736084, Neurons: 64, Grad norm: 3.864e-01\n",
      "Epoch 12018, Loss: 0.008645474910736084, Neurons: 64, Grad norm: 3.864e-01\n",
      "Epoch 12019, Loss: 0.008643089793622494, Neurons: 64, Grad norm: 3.226e-01\n",
      "Epoch 12019, Loss: 0.008643089793622494, Neurons: 64, Grad norm: 3.226e-01\n",
      "Epoch 12020, Loss: 0.008640184067189693, Neurons: 64, Grad norm: 2.590e-01\n",
      "Epoch 12020, Loss: 0.008640184067189693, Neurons: 64, Grad norm: 2.590e-01\n",
      "Epoch 12021, Loss: 0.008636952377855778, Neurons: 64, Grad norm: 1.501e-01\n",
      "Epoch 12021, Loss: 0.008636952377855778, Neurons: 64, Grad norm: 1.501e-01\n",
      "Epoch 12022, Loss: 0.008633886463940144, Neurons: 64, Grad norm: 6.389e-02\n",
      "Epoch 12022, Loss: 0.008633886463940144, Neurons: 64, Grad norm: 6.389e-02\n",
      "Epoch 12023, Loss: 0.008631066419184208, Neurons: 64, Grad norm: 4.895e-02\n",
      "Epoch 12023, Loss: 0.008631066419184208, Neurons: 64, Grad norm: 4.895e-02\n",
      "Epoch 12024, Loss: 0.008628814481198788, Neurons: 64, Grad norm: 1.148e-01\n",
      "Epoch 12024, Loss: 0.008628814481198788, Neurons: 64, Grad norm: 1.148e-01\n",
      "Epoch 12025, Loss: 0.008626753464341164, Neurons: 64, Grad norm: 1.916e-01\n",
      "Epoch 12025, Loss: 0.008626753464341164, Neurons: 64, Grad norm: 1.916e-01\n",
      "Epoch 12026, Loss: 0.008624792098999023, Neurons: 64, Grad norm: 2.191e-01\n",
      "Epoch 12026, Loss: 0.008624792098999023, Neurons: 64, Grad norm: 2.191e-01\n",
      "Epoch 12027, Loss: 0.008622700348496437, Neurons: 64, Grad norm: 2.438e-01\n",
      "Epoch 12027, Loss: 0.008622700348496437, Neurons: 64, Grad norm: 2.438e-01\n",
      "Epoch 12028, Loss: 0.008620438165962696, Neurons: 64, Grad norm: 2.272e-01\n",
      "Epoch 12028, Loss: 0.008620438165962696, Neurons: 64, Grad norm: 2.272e-01\n",
      "Epoch 12029, Loss: 0.008617994375526905, Neurons: 64, Grad norm: 2.225e-01\n",
      "Epoch 12029, Loss: 0.008617994375526905, Neurons: 64, Grad norm: 2.225e-01\n",
      "Epoch 12030, Loss: 0.008615444414317608, Neurons: 64, Grad norm: 1.788e-01\n",
      "Epoch 12030, Loss: 0.008615444414317608, Neurons: 64, Grad norm: 1.788e-01\n",
      "Epoch 12031, Loss: 0.00861289817839861, Neurons: 64, Grad norm: 1.521e-01\n",
      "Epoch 12031, Loss: 0.00861289817839861, Neurons: 64, Grad norm: 1.521e-01\n",
      "Epoch 12032, Loss: 0.008610446937382221, Neurons: 64, Grad norm: 1.038e-01\n",
      "Epoch 12032, Loss: 0.008610446937382221, Neurons: 64, Grad norm: 1.038e-01\n",
      "Epoch 12033, Loss: 0.008608020842075348, Neurons: 64, Grad norm: 7.704e-02\n",
      "Epoch 12033, Loss: 0.008608020842075348, Neurons: 64, Grad norm: 7.704e-02\n",
      "Epoch 12034, Loss: 0.008605622686445713, Neurons: 64, Grad norm: 5.664e-02\n",
      "Epoch 12034, Loss: 0.008605622686445713, Neurons: 64, Grad norm: 5.664e-02\n",
      "Epoch 12035, Loss: 0.008603320457041264, Neurons: 64, Grad norm: 5.184e-02\n",
      "Epoch 12035, Loss: 0.008603320457041264, Neurons: 64, Grad norm: 5.184e-02\n",
      "Epoch 12036, Loss: 0.008600950241088867, Neurons: 64, Grad norm: 7.846e-02\n",
      "Epoch 12036, Loss: 0.008600950241088867, Neurons: 64, Grad norm: 7.846e-02\n",
      "Epoch 12037, Loss: 0.008598590269684792, Neurons: 64, Grad norm: 8.814e-02\n",
      "Epoch 12037, Loss: 0.008598590269684792, Neurons: 64, Grad norm: 8.814e-02\n",
      "Epoch 12038, Loss: 0.008596262894570827, Neurons: 64, Grad norm: 1.185e-01\n",
      "Epoch 12038, Loss: 0.008596262894570827, Neurons: 64, Grad norm: 1.185e-01\n",
      "Epoch 12039, Loss: 0.008593973703682423, Neurons: 64, Grad norm: 1.146e-01\n",
      "Epoch 12039, Loss: 0.008593973703682423, Neurons: 64, Grad norm: 1.146e-01\n",
      "Epoch 12040, Loss: 0.008591686375439167, Neurons: 64, Grad norm: 1.317e-01\n",
      "Epoch 12040, Loss: 0.008591686375439167, Neurons: 64, Grad norm: 1.317e-01\n",
      "Epoch 12041, Loss: 0.00858947355300188, Neurons: 64, Grad norm: 1.276e-01\n",
      "Epoch 12041, Loss: 0.00858947355300188, Neurons: 64, Grad norm: 1.276e-01\n",
      "Epoch 12042, Loss: 0.008587157353758812, Neurons: 64, Grad norm: 1.332e-01\n",
      "Epoch 12042, Loss: 0.008587157353758812, Neurons: 64, Grad norm: 1.332e-01\n",
      "Epoch 12043, Loss: 0.00858482625335455, Neurons: 64, Grad norm: 1.068e-01\n",
      "Epoch 12043, Loss: 0.00858482625335455, Neurons: 64, Grad norm: 1.068e-01\n",
      "Epoch 12044, Loss: 0.008582456037402153, Neurons: 64, Grad norm: 9.760e-02\n",
      "Epoch 12044, Loss: 0.008582456037402153, Neurons: 64, Grad norm: 9.760e-02\n",
      "Epoch 12045, Loss: 0.008580043911933899, Neurons: 64, Grad norm: 7.311e-02\n",
      "Epoch 12045, Loss: 0.008580043911933899, Neurons: 64, Grad norm: 7.311e-02\n",
      "Epoch 12046, Loss: 0.00857771746814251, Neurons: 64, Grad norm: 6.751e-02\n",
      "Epoch 12046, Loss: 0.00857771746814251, Neurons: 64, Grad norm: 6.751e-02\n",
      "Epoch 12047, Loss: 0.008575295098125935, Neurons: 64, Grad norm: 3.753e-02\n",
      "Epoch 12047, Loss: 0.008575295098125935, Neurons: 64, Grad norm: 3.753e-02\n",
      "Epoch 12048, Loss: 0.008572939783334732, Neurons: 64, Grad norm: 3.435e-02\n",
      "Epoch 12048, Loss: 0.008572939783334732, Neurons: 64, Grad norm: 3.435e-02\n",
      "Epoch 12049, Loss: 0.008570599369704723, Neurons: 64, Grad norm: 2.313e-02\n",
      "Epoch 12049, Loss: 0.008570599369704723, Neurons: 64, Grad norm: 2.313e-02\n",
      "Epoch 12050, Loss: 0.008568339049816132, Neurons: 64, Grad norm: 3.225e-02\n",
      "Epoch 12050, Loss: 0.008568339049816132, Neurons: 64, Grad norm: 3.225e-02\n",
      "Epoch 12051, Loss: 0.008566003292798996, Neurons: 64, Grad norm: 3.776e-02\n",
      "Epoch 12051, Loss: 0.008566003292798996, Neurons: 64, Grad norm: 3.776e-02\n",
      "Epoch 12052, Loss: 0.008563724346458912, Neurons: 64, Grad norm: 3.878e-02\n",
      "Epoch 12052, Loss: 0.008563724346458912, Neurons: 64, Grad norm: 3.878e-02\n",
      "Epoch 12053, Loss: 0.00856137927621603, Neurons: 64, Grad norm: 4.912e-02\n",
      "Epoch 12053, Loss: 0.00856137927621603, Neurons: 64, Grad norm: 4.912e-02\n",
      "Epoch 12054, Loss: 0.008559080772101879, Neurons: 64, Grad norm: 4.575e-02\n",
      "Epoch 12054, Loss: 0.008559080772101879, Neurons: 64, Grad norm: 4.575e-02\n",
      "Epoch 12055, Loss: 0.008556745015084743, Neurons: 64, Grad norm: 6.020e-02\n",
      "Epoch 12055, Loss: 0.008556745015084743, Neurons: 64, Grad norm: 6.020e-02\n",
      "Epoch 12056, Loss: 0.008554439060389996, Neurons: 64, Grad norm: 5.420e-02\n",
      "Epoch 12056, Loss: 0.008554439060389996, Neurons: 64, Grad norm: 5.420e-02\n",
      "Epoch 12057, Loss: 0.008552099578082561, Neurons: 64, Grad norm: 7.031e-02\n",
      "Epoch 12057, Loss: 0.008552099578082561, Neurons: 64, Grad norm: 7.031e-02\n",
      "Epoch 12058, Loss: 0.008549833670258522, Neurons: 64, Grad norm: 6.411e-02\n",
      "Epoch 12058, Loss: 0.008549833670258522, Neurons: 64, Grad norm: 6.411e-02\n",
      "Epoch 12059, Loss: 0.008547542616724968, Neurons: 64, Grad norm: 8.186e-02\n",
      "Epoch 12059, Loss: 0.008547542616724968, Neurons: 64, Grad norm: 8.186e-02\n",
      "Epoch 12060, Loss: 0.008545181713998318, Neurons: 64, Grad norm: 7.182e-02\n",
      "Epoch 12060, Loss: 0.008545181713998318, Neurons: 64, Grad norm: 7.182e-02\n",
      "Epoch 12061, Loss: 0.008542940951883793, Neurons: 64, Grad norm: 8.521e-02\n",
      "Epoch 12061, Loss: 0.008542940951883793, Neurons: 64, Grad norm: 8.521e-02\n",
      "Epoch 12062, Loss: 0.008540615439414978, Neurons: 64, Grad norm: 7.609e-02\n",
      "Epoch 12062, Loss: 0.008540615439414978, Neurons: 64, Grad norm: 7.609e-02\n",
      "Epoch 12063, Loss: 0.00853831134736538, Neurons: 64, Grad norm: 9.039e-02\n",
      "Epoch 12063, Loss: 0.00853831134736538, Neurons: 64, Grad norm: 9.039e-02\n",
      "Epoch 12064, Loss: 0.00853594671934843, Neurons: 64, Grad norm: 7.579e-02\n",
      "Epoch 12064, Loss: 0.00853594671934843, Neurons: 64, Grad norm: 7.579e-02\n",
      "Epoch 12065, Loss: 0.008533722721040249, Neurons: 64, Grad norm: 8.990e-02\n",
      "Epoch 12065, Loss: 0.008533722721040249, Neurons: 64, Grad norm: 8.990e-02\n",
      "Epoch 12066, Loss: 0.008531395345926285, Neurons: 64, Grad norm: 8.013e-02\n",
      "Epoch 12066, Loss: 0.008531395345926285, Neurons: 64, Grad norm: 8.013e-02\n",
      "Epoch 12067, Loss: 0.008529076352715492, Neurons: 64, Grad norm: 8.687e-02\n",
      "Epoch 12067, Loss: 0.008529076352715492, Neurons: 64, Grad norm: 8.687e-02\n",
      "Epoch 12068, Loss: 0.008526772260665894, Neurons: 64, Grad norm: 7.115e-02\n",
      "Epoch 12068, Loss: 0.008526772260665894, Neurons: 64, Grad norm: 7.115e-02\n",
      "Epoch 12069, Loss: 0.008524450473487377, Neurons: 64, Grad norm: 8.461e-02\n",
      "Epoch 12069, Loss: 0.008524450473487377, Neurons: 64, Grad norm: 8.461e-02\n",
      "Epoch 12070, Loss: 0.008522124961018562, Neurons: 64, Grad norm: 7.071e-02\n",
      "Epoch 12070, Loss: 0.008522124961018562, Neurons: 64, Grad norm: 7.071e-02\n",
      "Epoch 12071, Loss: 0.008519838564097881, Neurons: 64, Grad norm: 7.904e-02\n",
      "Epoch 12071, Loss: 0.008519838564097881, Neurons: 64, Grad norm: 7.904e-02\n",
      "Epoch 12072, Loss: 0.00851755402982235, Neurons: 64, Grad norm: 6.540e-02\n",
      "Epoch 12072, Loss: 0.00851755402982235, Neurons: 64, Grad norm: 6.540e-02\n",
      "Epoch 12073, Loss: 0.00851519126445055, Neurons: 64, Grad norm: 8.091e-02\n",
      "Epoch 12073, Loss: 0.00851519126445055, Neurons: 64, Grad norm: 8.091e-02\n",
      "Epoch 12074, Loss: 0.008512956090271473, Neurons: 64, Grad norm: 6.893e-02\n",
      "Epoch 12074, Loss: 0.008512956090271473, Neurons: 64, Grad norm: 6.893e-02\n",
      "Epoch 12075, Loss: 0.008510630577802658, Neurons: 64, Grad norm: 8.473e-02\n",
      "Epoch 12075, Loss: 0.008510630577802658, Neurons: 64, Grad norm: 8.473e-02\n",
      "Epoch 12076, Loss: 0.008508323691785336, Neurons: 64, Grad norm: 8.223e-02\n",
      "Epoch 12076, Loss: 0.008508323691785336, Neurons: 64, Grad norm: 8.223e-02\n",
      "Epoch 12077, Loss: 0.008506069891154766, Neurons: 64, Grad norm: 1.016e-01\n",
      "Epoch 12077, Loss: 0.008506069891154766, Neurons: 64, Grad norm: 1.016e-01\n",
      "Epoch 12078, Loss: 0.008503761142492294, Neurons: 64, Grad norm: 9.821e-02\n",
      "Epoch 12078, Loss: 0.008503761142492294, Neurons: 64, Grad norm: 9.821e-02\n",
      "Epoch 12079, Loss: 0.008501514792442322, Neurons: 64, Grad norm: 1.247e-01\n",
      "Epoch 12079, Loss: 0.008501514792442322, Neurons: 64, Grad norm: 1.247e-01\n",
      "Epoch 12080, Loss: 0.00849930103868246, Neurons: 64, Grad norm: 1.337e-01\n",
      "Epoch 12080, Loss: 0.00849930103868246, Neurons: 64, Grad norm: 1.337e-01\n",
      "Epoch 12081, Loss: 0.008497114293277264, Neurons: 64, Grad norm: 1.623e-01\n",
      "Epoch 12081, Loss: 0.008497114293277264, Neurons: 64, Grad norm: 1.623e-01\n",
      "Epoch 12082, Loss: 0.00849493220448494, Neurons: 64, Grad norm: 1.754e-01\n",
      "Epoch 12082, Loss: 0.00849493220448494, Neurons: 64, Grad norm: 1.754e-01\n",
      "Epoch 12083, Loss: 0.008492829278111458, Neurons: 64, Grad norm: 2.160e-01\n",
      "Epoch 12083, Loss: 0.008492829278111458, Neurons: 64, Grad norm: 2.160e-01\n",
      "Epoch 12084, Loss: 0.008490709587931633, Neurons: 64, Grad norm: 2.413e-01\n",
      "Epoch 12084, Loss: 0.008490709587931633, Neurons: 64, Grad norm: 2.413e-01\n",
      "Epoch 12085, Loss: 0.008488665334880352, Neurons: 64, Grad norm: 2.840e-01\n",
      "Epoch 12085, Loss: 0.008488665334880352, Neurons: 64, Grad norm: 2.840e-01\n",
      "Epoch 12086, Loss: 0.008486654609441757, Neurons: 64, Grad norm: 3.121e-01\n",
      "Epoch 12086, Loss: 0.008486654609441757, Neurons: 64, Grad norm: 3.121e-01\n",
      "Epoch 12087, Loss: 0.008484752848744392, Neurons: 64, Grad norm: 3.786e-01\n",
      "Epoch 12087, Loss: 0.008484752848744392, Neurons: 64, Grad norm: 3.786e-01\n",
      "Epoch 12088, Loss: 0.00848300103098154, Neurons: 64, Grad norm: 4.303e-01\n",
      "Epoch 12088, Loss: 0.00848300103098154, Neurons: 64, Grad norm: 4.303e-01\n",
      "Epoch 12089, Loss: 0.008481422439217567, Neurons: 64, Grad norm: 5.119e-01\n",
      "Epoch 12089, Loss: 0.008481422439217567, Neurons: 64, Grad norm: 5.119e-01\n",
      "Epoch 12090, Loss: 0.0084801334887743, Neurons: 64, Grad norm: 5.911e-01\n",
      "Epoch 12090, Loss: 0.0084801334887743, Neurons: 64, Grad norm: 5.911e-01\n",
      "Epoch 12091, Loss: 0.008479347452521324, Neurons: 64, Grad norm: 7.144e-01\n",
      "Epoch 12091, Loss: 0.008479347452521324, Neurons: 64, Grad norm: 7.144e-01\n",
      "Epoch 12092, Loss: 0.00847917515784502, Neurons: 64, Grad norm: 8.366e-01\n",
      "Epoch 12092, Loss: 0.00847917515784502, Neurons: 64, Grad norm: 8.366e-01\n",
      "Epoch 12093, Loss: 0.008480078540742397, Neurons: 64, Grad norm: 1.013e+00\n",
      "Epoch 12093, Loss: 0.008480078540742397, Neurons: 64, Grad norm: 1.013e+00\n",
      "Epoch 12094, Loss: 0.008482475765049458, Neurons: 64, Grad norm: 1.210e+00\n",
      "Epoch 12094, Loss: 0.008482475765049458, Neurons: 64, Grad norm: 1.210e+00\n",
      "Epoch 12095, Loss: 0.00848727859556675, Neurons: 64, Grad norm: 1.477e+00\n",
      "Epoch 12095, Loss: 0.00848727859556675, Neurons: 64, Grad norm: 1.477e+00\n",
      "Epoch 12096, Loss: 0.008495405316352844, Neurons: 64, Grad norm: 1.774e+00\n",
      "Epoch 12096, Loss: 0.008495405316352844, Neurons: 64, Grad norm: 1.774e+00\n",
      "Epoch 12097, Loss: 0.008508576080203056, Neurons: 64, Grad norm: 2.168e+00\n",
      "Epoch 12097, Loss: 0.008508576080203056, Neurons: 64, Grad norm: 2.168e+00\n",
      "Epoch 12098, Loss: 0.00852928962558508, Neurons: 64, Grad norm: 2.631e+00\n",
      "Epoch 12098, Loss: 0.00852928962558508, Neurons: 64, Grad norm: 2.631e+00\n",
      "Epoch 12099, Loss: 0.008561419323086739, Neurons: 64, Grad norm: 3.217e+00\n",
      "Epoch 12099, Loss: 0.008561419323086739, Neurons: 64, Grad norm: 3.217e+00\n",
      "Epoch 12099, Test loss: 0.006775896530598402\n",
      "Epoch 12099, Test loss: 0.006775896530598402\n",
      "Epoch 12100, Loss: 0.008610431104898453, Neurons: 64, Grad norm: 3.906e+00\n",
      "Epoch 12100, Loss: 0.008610431104898453, Neurons: 64, Grad norm: 3.906e+00\n",
      "Epoch 12101, Loss: 0.008684719912707806, Neurons: 64, Grad norm: 4.763e+00\n",
      "Epoch 12101, Loss: 0.008684719912707806, Neurons: 64, Grad norm: 4.763e+00\n",
      "Epoch 12102, Loss: 0.008793733082711697, Neurons: 64, Grad norm: 5.742e+00\n",
      "Epoch 12102, Loss: 0.008793733082711697, Neurons: 64, Grad norm: 5.742e+00\n",
      "Epoch 12103, Loss: 0.008950380608439445, Neurons: 64, Grad norm: 6.870e+00\n",
      "Epoch 12103, Loss: 0.008950380608439445, Neurons: 64, Grad norm: 6.870e+00\n",
      "Epoch 12104, Loss: 0.00916243251413107, Neurons: 64, Grad norm: 8.035e+00\n",
      "Epoch 12104, Loss: 0.00916243251413107, Neurons: 64, Grad norm: 8.035e+00\n",
      "Epoch 12105, Loss: 0.009429010562598705, Neurons: 64, Grad norm: 9.157e+00\n",
      "Epoch 12105, Loss: 0.009429010562598705, Neurons: 64, Grad norm: 9.157e+00\n",
      "Epoch 12106, Loss: 0.009717432782053947, Neurons: 64, Grad norm: 9.975e+00\n",
      "Epoch 12106, Loss: 0.009717432782053947, Neurons: 64, Grad norm: 9.975e+00\n",
      "Epoch 12107, Loss: 0.009957957081496716, Neurons: 64, Grad norm: 1.023e+01\n",
      "Epoch 12107, Loss: 0.009957957081496716, Neurons: 64, Grad norm: 1.023e+01\n",
      "Epoch 12108, Loss: 0.010031195357441902, Neurons: 64, Grad norm: 9.601e+00\n",
      "Epoch 12108, Loss: 0.010031195357441902, Neurons: 64, Grad norm: 9.601e+00\n",
      "Epoch 12109, Loss: 0.009843927808105946, Neurons: 64, Grad norm: 7.975e+00\n",
      "Epoch 12109, Loss: 0.009843927808105946, Neurons: 64, Grad norm: 7.975e+00\n",
      "Epoch 12110, Loss: 0.009402815252542496, Neurons: 64, Grad norm: 5.413e+00\n",
      "Epoch 12110, Loss: 0.009402815252542496, Neurons: 64, Grad norm: 5.413e+00\n",
      "Epoch 12111, Loss: 0.008883202448487282, Neurons: 64, Grad norm: 2.359e+00\n",
      "Epoch 12111, Loss: 0.008883202448487282, Neurons: 64, Grad norm: 2.359e+00\n",
      "Epoch 12112, Loss: 0.00852149073034525, Neurons: 64, Grad norm: 1.001e+00\n",
      "Epoch 12112, Loss: 0.00852149073034525, Neurons: 64, Grad norm: 1.001e+00\n",
      "Epoch 12113, Loss: 0.008455093950033188, Neurons: 64, Grad norm: 3.571e+00\n",
      "Epoch 12113, Loss: 0.008455093950033188, Neurons: 64, Grad norm: 3.571e+00\n",
      "Epoch 12114, Loss: 0.008635256439447403, Neurons: 64, Grad norm: 5.429e+00\n",
      "Epoch 12114, Loss: 0.008635256439447403, Neurons: 64, Grad norm: 5.429e+00\n",
      "Epoch 12115, Loss: 0.00888451375067234, Neurons: 64, Grad norm: 6.207e+00\n",
      "Epoch 12115, Loss: 0.00888451375067234, Neurons: 64, Grad norm: 6.207e+00\n",
      "Epoch 12116, Loss: 0.009018069133162498, Neurons: 64, Grad norm: 5.869e+00\n",
      "Epoch 12116, Loss: 0.009018069133162498, Neurons: 64, Grad norm: 5.869e+00\n",
      "Epoch 12117, Loss: 0.008944929577410221, Neurons: 64, Grad norm: 4.498e+00\n",
      "Epoch 12117, Loss: 0.008944929577410221, Neurons: 64, Grad norm: 4.498e+00\n",
      "Epoch 12118, Loss: 0.008723888546228409, Neurons: 64, Grad norm: 2.469e+00\n",
      "Epoch 12118, Loss: 0.008723888546228409, Neurons: 64, Grad norm: 2.469e+00\n",
      "Epoch 12119, Loss: 0.0085055623203516, Neurons: 64, Grad norm: 4.360e-01\n",
      "Epoch 12119, Loss: 0.0085055623203516, Neurons: 64, Grad norm: 4.360e-01\n",
      "Epoch 12120, Loss: 0.008420377038419247, Neurons: 64, Grad norm: 2.004e+00\n",
      "Epoch 12120, Loss: 0.008420377038419247, Neurons: 64, Grad norm: 2.004e+00\n",
      "Epoch 12121, Loss: 0.008484947495162487, Neurons: 64, Grad norm: 3.491e+00\n",
      "Epoch 12121, Loss: 0.008484947495162487, Neurons: 64, Grad norm: 3.491e+00\n",
      "Epoch 12122, Loss: 0.008610899560153484, Neurons: 64, Grad norm: 4.152e+00\n",
      "Epoch 12122, Loss: 0.008610899560153484, Neurons: 64, Grad norm: 4.152e+00\n",
      "Epoch 12123, Loss: 0.008685925044119358, Neurons: 64, Grad norm: 3.961e+00\n",
      "Epoch 12123, Loss: 0.008685925044119358, Neurons: 64, Grad norm: 3.961e+00\n",
      "Epoch 12124, Loss: 0.008651853539049625, Neurons: 64, Grad norm: 2.989e+00\n",
      "Epoch 12124, Loss: 0.008651853539049625, Neurons: 64, Grad norm: 2.989e+00\n",
      "Epoch 12125, Loss: 0.008539522998034954, Neurons: 64, Grad norm: 1.544e+00\n",
      "Epoch 12125, Loss: 0.008539522998034954, Neurons: 64, Grad norm: 1.544e+00\n",
      "Epoch 12126, Loss: 0.008431605063378811, Neurons: 64, Grad norm: 1.810e-01\n",
      "Epoch 12126, Loss: 0.008431605063378811, Neurons: 64, Grad norm: 1.810e-01\n",
      "Epoch 12127, Loss: 0.00839501153677702, Neurons: 64, Grad norm: 1.525e+00\n",
      "Epoch 12127, Loss: 0.00839501153677702, Neurons: 64, Grad norm: 1.525e+00\n",
      "Epoch 12128, Loss: 0.008433429524302483, Neurons: 64, Grad norm: 2.514e+00\n",
      "Epoch 12128, Loss: 0.008433429524302483, Neurons: 64, Grad norm: 2.514e+00\n",
      "Epoch 12129, Loss: 0.008497179485857487, Neurons: 64, Grad norm: 2.888e+00\n",
      "Epoch 12129, Loss: 0.008497179485857487, Neurons: 64, Grad norm: 2.888e+00\n",
      "Epoch 12130, Loss: 0.00852887611836195, Neurons: 64, Grad norm: 2.668e+00\n",
      "Epoch 12130, Loss: 0.00852887611836195, Neurons: 64, Grad norm: 2.668e+00\n",
      "Epoch 12131, Loss: 0.008504428900778294, Neurons: 64, Grad norm: 1.914e+00\n",
      "Epoch 12131, Loss: 0.008504428900778294, Neurons: 64, Grad norm: 1.914e+00\n",
      "Epoch 12132, Loss: 0.008445222862064838, Neurons: 64, Grad norm: 8.745e-01\n",
      "Epoch 12132, Loss: 0.008445222862064838, Neurons: 64, Grad norm: 8.745e-01\n",
      "Epoch 12133, Loss: 0.008393347263336182, Neurons: 64, Grad norm: 2.649e-01\n",
      "Epoch 12133, Loss: 0.008393347263336182, Neurons: 64, Grad norm: 2.649e-01\n",
      "Epoch 12134, Loss: 0.008378603495657444, Neurons: 64, Grad norm: 1.209e+00\n",
      "Epoch 12134, Loss: 0.008378603495657444, Neurons: 64, Grad norm: 1.209e+00\n",
      "Epoch 12135, Loss: 0.008399016223847866, Neurons: 64, Grad norm: 1.850e+00\n",
      "Epoch 12135, Loss: 0.008399016223847866, Neurons: 64, Grad norm: 1.850e+00\n",
      "Epoch 12136, Loss: 0.008428436703979969, Neurons: 64, Grad norm: 2.049e+00\n",
      "Epoch 12136, Loss: 0.008428436703979969, Neurons: 64, Grad norm: 2.049e+00\n",
      "Epoch 12137, Loss: 0.008440814912319183, Neurons: 64, Grad norm: 1.851e+00\n",
      "Epoch 12137, Loss: 0.008440814912319183, Neurons: 64, Grad norm: 1.851e+00\n",
      "Epoch 12138, Loss: 0.008426381275057793, Neurons: 64, Grad norm: 1.299e+00\n",
      "Epoch 12138, Loss: 0.008426381275057793, Neurons: 64, Grad norm: 1.299e+00\n",
      "Epoch 12139, Loss: 0.008397026918828487, Neurons: 64, Grad norm: 5.766e-01\n",
      "Epoch 12139, Loss: 0.008397026918828487, Neurons: 64, Grad norm: 5.766e-01\n",
      "Epoch 12140, Loss: 0.00837173592299223, Neurons: 64, Grad norm: 2.781e-01\n",
      "Epoch 12140, Loss: 0.00837173592299223, Neurons: 64, Grad norm: 2.781e-01\n",
      "Epoch 12141, Loss: 0.00836403388530016, Neurons: 64, Grad norm: 9.001e-01\n",
      "Epoch 12141, Loss: 0.00836403388530016, Neurons: 64, Grad norm: 9.001e-01\n",
      "Epoch 12142, Loss: 0.008372446522116661, Neurons: 64, Grad norm: 1.348e+00\n",
      "Epoch 12142, Loss: 0.008372446522116661, Neurons: 64, Grad norm: 1.348e+00\n",
      "Epoch 12143, Loss: 0.00838565919548273, Neurons: 64, Grad norm: 1.492e+00\n",
      "Epoch 12143, Loss: 0.00838565919548273, Neurons: 64, Grad norm: 1.492e+00\n",
      "Epoch 12144, Loss: 0.008390302769839764, Neurons: 64, Grad norm: 1.372e+00\n",
      "Epoch 12144, Loss: 0.008390302769839764, Neurons: 64, Grad norm: 1.372e+00\n",
      "Epoch 12145, Loss: 0.008382595144212246, Neurons: 64, Grad norm: 9.956e-01\n",
      "Epoch 12145, Loss: 0.008382595144212246, Neurons: 64, Grad norm: 9.956e-01\n",
      "Epoch 12146, Loss: 0.008367139846086502, Neurons: 64, Grad norm: 5.011e-01\n",
      "Epoch 12146, Loss: 0.008367139846086502, Neurons: 64, Grad norm: 5.011e-01\n",
      "Epoch 12147, Loss: 0.008353013545274734, Neurons: 64, Grad norm: 7.090e-02\n",
      "Epoch 12147, Loss: 0.008353013545274734, Neurons: 64, Grad norm: 7.090e-02\n",
      "Epoch 12148, Loss: 0.00834696739912033, Neurons: 64, Grad norm: 5.349e-01\n",
      "Epoch 12148, Loss: 0.00834696739912033, Neurons: 64, Grad norm: 5.349e-01\n",
      "Epoch 12149, Loss: 0.008349182084202766, Neurons: 64, Grad norm: 8.906e-01\n",
      "Epoch 12149, Loss: 0.008349182084202766, Neurons: 64, Grad norm: 8.906e-01\n",
      "Epoch 12150, Loss: 0.008354419842362404, Neurons: 64, Grad norm: 1.041e+00\n",
      "Epoch 12150, Loss: 0.008354419842362404, Neurons: 64, Grad norm: 1.041e+00\n",
      "Epoch 12151, Loss: 0.008357134647667408, Neurons: 64, Grad norm: 1.022e+00\n",
      "Epoch 12151, Loss: 0.008357134647667408, Neurons: 64, Grad norm: 1.022e+00\n",
      "Epoch 12152, Loss: 0.008354010060429573, Neurons: 64, Grad norm: 8.138e-01\n",
      "Epoch 12152, Loss: 0.008354010060429573, Neurons: 64, Grad norm: 8.138e-01\n",
      "Epoch 12153, Loss: 0.008346269838511944, Neurons: 64, Grad norm: 5.159e-01\n",
      "Epoch 12153, Loss: 0.008346269838511944, Neurons: 64, Grad norm: 5.159e-01\n",
      "Epoch 12154, Loss: 0.008337721228599548, Neurons: 64, Grad norm: 1.450e-01\n",
      "Epoch 12154, Loss: 0.008337721228599548, Neurons: 64, Grad norm: 1.450e-01\n",
      "Epoch 12155, Loss: 0.00833194050937891, Neurons: 64, Grad norm: 2.006e-01\n",
      "Epoch 12155, Loss: 0.00833194050937891, Neurons: 64, Grad norm: 2.006e-01\n",
      "Epoch 12156, Loss: 0.008330140262842178, Neurons: 64, Grad norm: 4.904e-01\n",
      "Epoch 12156, Loss: 0.008330140262842178, Neurons: 64, Grad norm: 4.904e-01\n",
      "Epoch 12157, Loss: 0.008331005461513996, Neurons: 64, Grad norm: 6.515e-01\n",
      "Epoch 12157, Loss: 0.008331005461513996, Neurons: 64, Grad norm: 6.515e-01\n",
      "Epoch 12158, Loss: 0.00833176914602518, Neurons: 64, Grad norm: 7.107e-01\n",
      "Epoch 12158, Loss: 0.00833176914602518, Neurons: 64, Grad norm: 7.107e-01\n",
      "Epoch 12159, Loss: 0.008330672979354858, Neurons: 64, Grad norm: 6.341e-01\n",
      "Epoch 12159, Loss: 0.008330672979354858, Neurons: 64, Grad norm: 6.341e-01\n",
      "Epoch 12160, Loss: 0.008326967246830463, Neurons: 64, Grad norm: 4.921e-01\n",
      "Epoch 12160, Loss: 0.008326967246830463, Neurons: 64, Grad norm: 4.921e-01\n",
      "Epoch 12161, Loss: 0.008322055451571941, Neurons: 64, Grad norm: 2.690e-01\n",
      "Epoch 12161, Loss: 0.008322055451571941, Neurons: 64, Grad norm: 2.690e-01\n",
      "Epoch 12162, Loss: 0.008317424915730953, Neurons: 64, Grad norm: 7.672e-02\n",
      "Epoch 12162, Loss: 0.008317424915730953, Neurons: 64, Grad norm: 7.672e-02\n",
      "Epoch 12163, Loss: 0.00831434316933155, Neurons: 64, Grad norm: 1.965e-01\n",
      "Epoch 12163, Loss: 0.00831434316933155, Neurons: 64, Grad norm: 1.965e-01\n",
      "Epoch 12164, Loss: 0.008312905207276344, Neurons: 64, Grad norm: 3.463e-01\n",
      "Epoch 12164, Loss: 0.008312905207276344, Neurons: 64, Grad norm: 3.463e-01\n",
      "Epoch 12165, Loss: 0.00831227470189333, Neurons: 64, Grad norm: 4.497e-01\n",
      "Epoch 12165, Loss: 0.00831227470189333, Neurons: 64, Grad norm: 4.497e-01\n",
      "Epoch 12166, Loss: 0.00831158272922039, Neurons: 64, Grad norm: 4.600e-01\n",
      "Epoch 12166, Loss: 0.00831158272922039, Neurons: 64, Grad norm: 4.600e-01\n",
      "Epoch 12167, Loss: 0.008309761993587017, Neurons: 64, Grad norm: 4.186e-01\n",
      "Epoch 12167, Loss: 0.008309761993587017, Neurons: 64, Grad norm: 4.186e-01\n",
      "Epoch 12168, Loss: 0.008306780830025673, Neurons: 64, Grad norm: 3.041e-01\n",
      "Epoch 12168, Loss: 0.008306780830025673, Neurons: 64, Grad norm: 3.041e-01\n",
      "Epoch 12169, Loss: 0.008303320966660976, Neurons: 64, Grad norm: 1.804e-01\n",
      "Epoch 12169, Loss: 0.008303320966660976, Neurons: 64, Grad norm: 1.804e-01\n",
      "Epoch 12170, Loss: 0.008299917913973331, Neurons: 64, Grad norm: 8.976e-02\n",
      "Epoch 12170, Loss: 0.008299917913973331, Neurons: 64, Grad norm: 8.976e-02\n",
      "Epoch 12171, Loss: 0.008297075517475605, Neurons: 64, Grad norm: 1.570e-01\n",
      "Epoch 12171, Loss: 0.008297075517475605, Neurons: 64, Grad norm: 1.570e-01\n",
      "Epoch 12172, Loss: 0.008295131847262383, Neurons: 64, Grad norm: 2.705e-01\n",
      "Epoch 12172, Loss: 0.008295131847262383, Neurons: 64, Grad norm: 2.705e-01\n",
      "Epoch 12173, Loss: 0.008293533697724342, Neurons: 64, Grad norm: 3.245e-01\n",
      "Epoch 12173, Loss: 0.008293533697724342, Neurons: 64, Grad norm: 3.245e-01\n",
      "Epoch 12174, Loss: 0.008291799575090408, Neurons: 64, Grad norm: 3.587e-01\n",
      "Epoch 12174, Loss: 0.008291799575090408, Neurons: 64, Grad norm: 3.587e-01\n",
      "Epoch 12175, Loss: 0.008289946243166924, Neurons: 64, Grad norm: 3.273e-01\n",
      "Epoch 12175, Loss: 0.008289946243166924, Neurons: 64, Grad norm: 3.273e-01\n",
      "Epoch 12176, Loss: 0.008287493139505386, Neurons: 64, Grad norm: 2.799e-01\n",
      "Epoch 12176, Loss: 0.008287493139505386, Neurons: 64, Grad norm: 2.799e-01\n",
      "Epoch 12177, Loss: 0.008284750394523144, Neurons: 64, Grad norm: 1.827e-01\n",
      "Epoch 12177, Loss: 0.008284750394523144, Neurons: 64, Grad norm: 1.827e-01\n",
      "Epoch 12178, Loss: 0.008281984366476536, Neurons: 64, Grad norm: 1.018e-01\n",
      "Epoch 12178, Loss: 0.008281984366476536, Neurons: 64, Grad norm: 1.018e-01\n",
      "Epoch 12179, Loss: 0.008279381319880486, Neurons: 64, Grad norm: 2.699e-02\n",
      "Epoch 12179, Loss: 0.008279381319880486, Neurons: 64, Grad norm: 2.699e-02\n",
      "Epoch 12180, Loss: 0.008277099579572678, Neurons: 64, Grad norm: 8.623e-02\n",
      "Epoch 12180, Loss: 0.008277099579572678, Neurons: 64, Grad norm: 8.623e-02\n",
      "Epoch 12181, Loss: 0.008275067433714867, Neurons: 64, Grad norm: 1.597e-01\n",
      "Epoch 12181, Loss: 0.008275067433714867, Neurons: 64, Grad norm: 1.597e-01\n",
      "Epoch 12182, Loss: 0.00827315915375948, Neurons: 64, Grad norm: 1.876e-01\n",
      "Epoch 12182, Loss: 0.00827315915375948, Neurons: 64, Grad norm: 1.876e-01\n",
      "Epoch 12183, Loss: 0.008271191269159317, Neurons: 64, Grad norm: 2.097e-01\n",
      "Epoch 12183, Loss: 0.008271191269159317, Neurons: 64, Grad norm: 2.097e-01\n",
      "Epoch 12184, Loss: 0.008269103243947029, Neurons: 64, Grad norm: 1.874e-01\n",
      "Epoch 12184, Loss: 0.008269103243947029, Neurons: 64, Grad norm: 1.874e-01\n",
      "Epoch 12185, Loss: 0.008266839198768139, Neurons: 64, Grad norm: 1.710e-01\n",
      "Epoch 12185, Loss: 0.008266839198768139, Neurons: 64, Grad norm: 1.710e-01\n",
      "Epoch 12186, Loss: 0.008264523930847645, Neurons: 64, Grad norm: 1.129e-01\n",
      "Epoch 12186, Loss: 0.008264523930847645, Neurons: 64, Grad norm: 1.129e-01\n",
      "Epoch 12187, Loss: 0.00826212763786316, Neurons: 64, Grad norm: 6.961e-02\n",
      "Epoch 12187, Loss: 0.00826212763786316, Neurons: 64, Grad norm: 6.961e-02\n",
      "Epoch 12188, Loss: 0.008259845897555351, Neurons: 64, Grad norm: 1.589e-02\n",
      "Epoch 12188, Loss: 0.008259845897555351, Neurons: 64, Grad norm: 1.589e-02\n",
      "Epoch 12189, Loss: 0.008257539011538029, Neurons: 64, Grad norm: 4.562e-02\n",
      "Epoch 12189, Loss: 0.008257539011538029, Neurons: 64, Grad norm: 4.562e-02\n",
      "Epoch 12190, Loss: 0.008255483582615852, Neurons: 64, Grad norm: 9.592e-02\n",
      "Epoch 12190, Loss: 0.008255483582615852, Neurons: 64, Grad norm: 9.592e-02\n",
      "Epoch 12191, Loss: 0.008253425359725952, Neurons: 64, Grad norm: 1.192e-01\n",
      "Epoch 12191, Loss: 0.008253425359725952, Neurons: 64, Grad norm: 1.192e-01\n",
      "Epoch 12192, Loss: 0.008251446299254894, Neurons: 64, Grad norm: 1.457e-01\n",
      "Epoch 12192, Loss: 0.008251446299254894, Neurons: 64, Grad norm: 1.457e-01\n",
      "Epoch 12193, Loss: 0.00824950821697712, Neurons: 64, Grad norm: 1.434e-01\n",
      "Epoch 12193, Loss: 0.00824950821697712, Neurons: 64, Grad norm: 1.434e-01\n",
      "Epoch 12194, Loss: 0.008247526362538338, Neurons: 64, Grad norm: 1.440e-01\n",
      "Epoch 12194, Loss: 0.008247526362538338, Neurons: 64, Grad norm: 1.440e-01\n",
      "Epoch 12195, Loss: 0.00824542436748743, Neurons: 64, Grad norm: 1.319e-01\n",
      "Epoch 12195, Loss: 0.00824542436748743, Neurons: 64, Grad norm: 1.319e-01\n",
      "Epoch 12196, Loss: 0.008243399672210217, Neurons: 64, Grad norm: 1.295e-01\n",
      "Epoch 12196, Loss: 0.008243399672210217, Neurons: 64, Grad norm: 1.295e-01\n",
      "Epoch 12197, Loss: 0.008241399191319942, Neurons: 64, Grad norm: 1.491e-01\n",
      "Epoch 12197, Loss: 0.008241399191319942, Neurons: 64, Grad norm: 1.491e-01\n",
      "Epoch 12198, Loss: 0.00823953840881586, Neurons: 64, Grad norm: 1.723e-01\n",
      "Epoch 12198, Loss: 0.00823953840881586, Neurons: 64, Grad norm: 1.723e-01\n",
      "Epoch 12199, Loss: 0.00823775865137577, Neurons: 64, Grad norm: 2.260e-01\n",
      "Epoch 12199, Loss: 0.00823775865137577, Neurons: 64, Grad norm: 2.260e-01\n",
      "Epoch 12199, Test loss: 0.006347580347210169\n",
      "Epoch 12199, Test loss: 0.006347580347210169\n",
      "Epoch 12200, Loss: 0.008236266672611237, Neurons: 64, Grad norm: 2.634e-01\n",
      "Epoch 12200, Loss: 0.008236266672611237, Neurons: 64, Grad norm: 2.634e-01\n",
      "Epoch 12201, Loss: 0.00823512114584446, Neurons: 64, Grad norm: 3.240e-01\n",
      "Epoch 12201, Loss: 0.00823512114584446, Neurons: 64, Grad norm: 3.240e-01\n",
      "Epoch 12202, Loss: 0.008234299719333649, Neurons: 64, Grad norm: 3.701e-01\n",
      "Epoch 12202, Loss: 0.008234299719333649, Neurons: 64, Grad norm: 3.701e-01\n",
      "Epoch 12203, Loss: 0.008233937434852123, Neurons: 64, Grad norm: 4.439e-01\n",
      "Epoch 12203, Loss: 0.008233937434852123, Neurons: 64, Grad norm: 4.439e-01\n",
      "Epoch 12204, Loss: 0.008234561420977116, Neurons: 64, Grad norm: 5.051e-01\n",
      "Epoch 12204, Loss: 0.008234561420977116, Neurons: 64, Grad norm: 5.051e-01\n",
      "Epoch 12205, Loss: 0.008236178196966648, Neurons: 64, Grad norm: 5.989e-01\n",
      "Epoch 12205, Loss: 0.008236178196966648, Neurons: 64, Grad norm: 5.989e-01\n",
      "Epoch 12206, Loss: 0.008239645510911942, Neurons: 64, Grad norm: 6.913e-01\n",
      "Epoch 12206, Loss: 0.008239645510911942, Neurons: 64, Grad norm: 6.913e-01\n",
      "Epoch 12207, Loss: 0.008245234377682209, Neurons: 64, Grad norm: 8.237e-01\n",
      "Epoch 12207, Loss: 0.008245234377682209, Neurons: 64, Grad norm: 8.237e-01\n",
      "Epoch 12208, Loss: 0.008254303596913815, Neurons: 64, Grad norm: 9.585e-01\n",
      "Epoch 12208, Loss: 0.008254303596913815, Neurons: 64, Grad norm: 9.585e-01\n",
      "Epoch 12209, Loss: 0.008267573080956936, Neurons: 64, Grad norm: 1.141e+00\n",
      "Epoch 12209, Loss: 0.008267573080956936, Neurons: 64, Grad norm: 1.141e+00\n",
      "Epoch 12210, Loss: 0.008286703377962112, Neurons: 64, Grad norm: 1.337e+00\n",
      "Epoch 12210, Loss: 0.008286703377962112, Neurons: 64, Grad norm: 1.337e+00\n",
      "Epoch 12211, Loss: 0.008313290774822235, Neurons: 64, Grad norm: 1.581e+00\n",
      "Epoch 12211, Loss: 0.008313290774822235, Neurons: 64, Grad norm: 1.581e+00\n",
      "Epoch 12212, Loss: 0.008350281976163387, Neurons: 64, Grad norm: 1.833e+00\n",
      "Epoch 12212, Loss: 0.008350281976163387, Neurons: 64, Grad norm: 1.833e+00\n",
      "Epoch 12213, Loss: 0.00839739665389061, Neurons: 64, Grad norm: 2.123e+00\n",
      "Epoch 12213, Loss: 0.00839739665389061, Neurons: 64, Grad norm: 2.123e+00\n",
      "Epoch 12214, Loss: 0.008455032482743263, Neurons: 64, Grad norm: 2.393e+00\n",
      "Epoch 12214, Loss: 0.008455032482743263, Neurons: 64, Grad norm: 2.393e+00\n",
      "Epoch 12215, Loss: 0.008516212925314903, Neurons: 64, Grad norm: 2.645e+00\n",
      "Epoch 12215, Loss: 0.008516212925314903, Neurons: 64, Grad norm: 2.645e+00\n",
      "Epoch 12216, Loss: 0.008571121841669083, Neurons: 64, Grad norm: 2.807e+00\n",
      "Epoch 12216, Loss: 0.008571121841669083, Neurons: 64, Grad norm: 2.807e+00\n",
      "Epoch 12217, Loss: 0.008600513450801373, Neurons: 64, Grad norm: 2.875e+00\n",
      "Epoch 12217, Loss: 0.008600513450801373, Neurons: 64, Grad norm: 2.875e+00\n",
      "Epoch 12218, Loss: 0.008588828146457672, Neurons: 64, Grad norm: 2.781e+00\n",
      "Epoch 12218, Loss: 0.008588828146457672, Neurons: 64, Grad norm: 2.781e+00\n",
      "Epoch 12219, Loss: 0.008527111262083054, Neurons: 64, Grad norm: 2.568e+00\n",
      "Epoch 12219, Loss: 0.008527111262083054, Neurons: 64, Grad norm: 2.568e+00\n",
      "Epoch 12220, Loss: 0.008428898639976978, Neurons: 64, Grad norm: 2.246e+00\n",
      "Epoch 12220, Loss: 0.008428898639976978, Neurons: 64, Grad norm: 2.246e+00\n",
      "Epoch 12221, Loss: 0.008327010087668896, Neurons: 64, Grad norm: 1.935e+00\n",
      "Epoch 12221, Loss: 0.008327010087668896, Neurons: 64, Grad norm: 1.935e+00\n",
      "Epoch 12222, Loss: 0.008254840970039368, Neurons: 64, Grad norm: 1.661e+00\n",
      "Epoch 12222, Loss: 0.008254840970039368, Neurons: 64, Grad norm: 1.661e+00\n",
      "Epoch 12223, Loss: 0.008228166028857231, Neurons: 64, Grad norm: 1.510e+00\n",
      "Epoch 12223, Loss: 0.008228166028857231, Neurons: 64, Grad norm: 1.510e+00\n",
      "Epoch 12224, Loss: 0.008239380083978176, Neurons: 64, Grad norm: 1.418e+00\n",
      "Epoch 12224, Loss: 0.008239380083978176, Neurons: 64, Grad norm: 1.418e+00\n",
      "Epoch 12225, Loss: 0.008265908807516098, Neurons: 64, Grad norm: 1.343e+00\n",
      "Epoch 12225, Loss: 0.008265908807516098, Neurons: 64, Grad norm: 1.343e+00\n",
      "Epoch 12226, Loss: 0.008284107781946659, Neurons: 64, Grad norm: 1.242e+00\n",
      "Epoch 12226, Loss: 0.008284107781946659, Neurons: 64, Grad norm: 1.242e+00\n",
      "Epoch 12227, Loss: 0.00828047189861536, Neurons: 64, Grad norm: 1.131e+00\n",
      "Epoch 12227, Loss: 0.00828047189861536, Neurons: 64, Grad norm: 1.131e+00\n",
      "Epoch 12228, Loss: 0.008256196975708008, Neurons: 64, Grad norm: 1.101e+00\n",
      "Epoch 12228, Loss: 0.008256196975708008, Neurons: 64, Grad norm: 1.101e+00\n",
      "Epoch 12229, Loss: 0.008224619552493095, Neurons: 64, Grad norm: 1.179e+00\n",
      "Epoch 12229, Loss: 0.008224619552493095, Neurons: 64, Grad norm: 1.179e+00\n",
      "Epoch 12230, Loss: 0.008201980963349342, Neurons: 64, Grad norm: 1.379e+00\n",
      "Epoch 12230, Loss: 0.008201980963349342, Neurons: 64, Grad norm: 1.379e+00\n",
      "Epoch 12231, Loss: 0.00819710548967123, Neurons: 64, Grad norm: 1.560e+00\n",
      "Epoch 12231, Loss: 0.00819710548967123, Neurons: 64, Grad norm: 1.560e+00\n",
      "Epoch 12232, Loss: 0.008207728154957294, Neurons: 64, Grad norm: 1.693e+00\n",
      "Epoch 12232, Loss: 0.008207728154957294, Neurons: 64, Grad norm: 1.693e+00\n",
      "Epoch 12233, Loss: 0.008223186247050762, Neurons: 64, Grad norm: 1.697e+00\n",
      "Epoch 12233, Loss: 0.008223186247050762, Neurons: 64, Grad norm: 1.697e+00\n",
      "Epoch 12234, Loss: 0.00823144894093275, Neurons: 64, Grad norm: 1.592e+00\n",
      "Epoch 12234, Loss: 0.00823144894093275, Neurons: 64, Grad norm: 1.592e+00\n",
      "Epoch 12235, Loss: 0.008225774392485619, Neurons: 64, Grad norm: 1.350e+00\n",
      "Epoch 12235, Loss: 0.008225774392485619, Neurons: 64, Grad norm: 1.350e+00\n",
      "Epoch 12236, Loss: 0.008207238279283047, Neurons: 64, Grad norm: 1.032e+00\n",
      "Epoch 12236, Loss: 0.008207238279283047, Neurons: 64, Grad norm: 1.032e+00\n",
      "Epoch 12237, Loss: 0.008183302357792854, Neurons: 64, Grad norm: 6.467e-01\n",
      "Epoch 12237, Loss: 0.008183302357792854, Neurons: 64, Grad norm: 6.467e-01\n",
      "Epoch 12238, Loss: 0.00816325843334198, Neurons: 64, Grad norm: 2.955e-01\n",
      "Epoch 12238, Loss: 0.00816325843334198, Neurons: 64, Grad norm: 2.955e-01\n",
      "Epoch 12239, Loss: 0.00815299991518259, Neurons: 64, Grad norm: 2.194e-01\n",
      "Epoch 12239, Loss: 0.00815299991518259, Neurons: 64, Grad norm: 2.194e-01\n",
      "Epoch 12240, Loss: 0.008152952417731285, Neurons: 64, Grad norm: 4.696e-01\n",
      "Epoch 12240, Loss: 0.008152952417731285, Neurons: 64, Grad norm: 4.696e-01\n",
      "Epoch 12241, Loss: 0.008158911019563675, Neurons: 64, Grad norm: 6.847e-01\n",
      "Epoch 12241, Loss: 0.008158911019563675, Neurons: 64, Grad norm: 6.847e-01\n",
      "Epoch 12242, Loss: 0.00816505216062069, Neurons: 64, Grad norm: 8.100e-01\n",
      "Epoch 12242, Loss: 0.00816505216062069, Neurons: 64, Grad norm: 8.100e-01\n",
      "Epoch 12243, Loss: 0.008167054504156113, Neurons: 64, Grad norm: 8.691e-01\n",
      "Epoch 12243, Loss: 0.008167054504156113, Neurons: 64, Grad norm: 8.691e-01\n",
      "Epoch 12244, Loss: 0.008163681253790855, Neurons: 64, Grad norm: 8.513e-01\n",
      "Epoch 12244, Loss: 0.008163681253790855, Neurons: 64, Grad norm: 8.513e-01\n",
      "Epoch 12245, Loss: 0.008156754076480865, Neurons: 64, Grad norm: 8.154e-01\n",
      "Epoch 12245, Loss: 0.008156754076480865, Neurons: 64, Grad norm: 8.154e-01\n",
      "Epoch 12246, Loss: 0.008149275556206703, Neurons: 64, Grad norm: 7.527e-01\n",
      "Epoch 12246, Loss: 0.008149275556206703, Neurons: 64, Grad norm: 7.527e-01\n",
      "Epoch 12247, Loss: 0.008144065737724304, Neurons: 64, Grad norm: 7.281e-01\n",
      "Epoch 12247, Loss: 0.008144065737724304, Neurons: 64, Grad norm: 7.281e-01\n",
      "Epoch 12248, Loss: 0.0081419562920928, Neurons: 64, Grad norm: 6.958e-01\n",
      "Epoch 12248, Loss: 0.0081419562920928, Neurons: 64, Grad norm: 6.958e-01\n",
      "Epoch 12249, Loss: 0.008142153732478619, Neurons: 64, Grad norm: 6.915e-01\n",
      "Epoch 12249, Loss: 0.008142153732478619, Neurons: 64, Grad norm: 6.915e-01\n",
      "Epoch 12250, Loss: 0.0081428661942482, Neurons: 64, Grad norm: 6.581e-01\n",
      "Epoch 12250, Loss: 0.0081428661942482, Neurons: 64, Grad norm: 6.581e-01\n",
      "Epoch 12251, Loss: 0.008142239414155483, Neurons: 64, Grad norm: 6.310e-01\n",
      "Epoch 12251, Loss: 0.008142239414155483, Neurons: 64, Grad norm: 6.310e-01\n",
      "Epoch 12252, Loss: 0.008139307610690594, Neurons: 64, Grad norm: 5.587e-01\n",
      "Epoch 12252, Loss: 0.008139307610690594, Neurons: 64, Grad norm: 5.587e-01\n",
      "Epoch 12253, Loss: 0.008134418167173862, Neurons: 64, Grad norm: 4.964e-01\n",
      "Epoch 12253, Loss: 0.008134418167173862, Neurons: 64, Grad norm: 4.964e-01\n",
      "Epoch 12254, Loss: 0.008128556422889233, Neurons: 64, Grad norm: 4.094e-01\n",
      "Epoch 12254, Loss: 0.008128556422889233, Neurons: 64, Grad norm: 4.094e-01\n",
      "Epoch 12255, Loss: 0.008123115636408329, Neurons: 64, Grad norm: 3.620e-01\n",
      "Epoch 12255, Loss: 0.008123115636408329, Neurons: 64, Grad norm: 3.620e-01\n",
      "Epoch 12256, Loss: 0.008118916302919388, Neurons: 64, Grad norm: 3.194e-01\n",
      "Epoch 12256, Loss: 0.008118916302919388, Neurons: 64, Grad norm: 3.194e-01\n",
      "Epoch 12257, Loss: 0.00811623316258192, Neurons: 64, Grad norm: 3.214e-01\n",
      "Epoch 12257, Loss: 0.00811623316258192, Neurons: 64, Grad norm: 3.214e-01\n",
      "Epoch 12258, Loss: 0.008114807307720184, Neurons: 64, Grad norm: 3.133e-01\n",
      "Epoch 12258, Loss: 0.008114807307720184, Neurons: 64, Grad norm: 3.133e-01\n",
      "Epoch 12259, Loss: 0.008113711141049862, Neurons: 64, Grad norm: 3.138e-01\n",
      "Epoch 12259, Loss: 0.008113711141049862, Neurons: 64, Grad norm: 3.138e-01\n",
      "Epoch 12260, Loss: 0.008112411946058273, Neurons: 64, Grad norm: 2.900e-01\n",
      "Epoch 12260, Loss: 0.008112411946058273, Neurons: 64, Grad norm: 2.900e-01\n",
      "Epoch 12261, Loss: 0.008110417053103447, Neurons: 64, Grad norm: 2.590e-01\n",
      "Epoch 12261, Loss: 0.008110417053103447, Neurons: 64, Grad norm: 2.590e-01\n",
      "Epoch 12262, Loss: 0.008107984438538551, Neurons: 64, Grad norm: 2.086e-01\n",
      "Epoch 12262, Loss: 0.008107984438538551, Neurons: 64, Grad norm: 2.086e-01\n",
      "Epoch 12263, Loss: 0.008104952983558178, Neurons: 64, Grad norm: 1.526e-01\n",
      "Epoch 12263, Loss: 0.008104952983558178, Neurons: 64, Grad norm: 1.526e-01\n",
      "Epoch 12264, Loss: 0.008101820014417171, Neurons: 64, Grad norm: 1.083e-01\n",
      "Epoch 12264, Loss: 0.008101820014417171, Neurons: 64, Grad norm: 1.083e-01\n",
      "Epoch 12265, Loss: 0.008098947815597057, Neurons: 64, Grad norm: 8.722e-02\n",
      "Epoch 12265, Loss: 0.008098947815597057, Neurons: 64, Grad norm: 8.722e-02\n",
      "Epoch 12266, Loss: 0.008096481673419476, Neurons: 64, Grad norm: 1.309e-01\n",
      "Epoch 12266, Loss: 0.008096481673419476, Neurons: 64, Grad norm: 1.309e-01\n",
      "Epoch 12267, Loss: 0.00809443835169077, Neurons: 64, Grad norm: 1.674e-01\n",
      "Epoch 12267, Loss: 0.00809443835169077, Neurons: 64, Grad norm: 1.674e-01\n",
      "Epoch 12268, Loss: 0.008092619478702545, Neurons: 64, Grad norm: 2.241e-01\n",
      "Epoch 12268, Loss: 0.008092619478702545, Neurons: 64, Grad norm: 2.241e-01\n",
      "Epoch 12269, Loss: 0.008091060444712639, Neurons: 64, Grad norm: 2.545e-01\n",
      "Epoch 12269, Loss: 0.008091060444712639, Neurons: 64, Grad norm: 2.545e-01\n",
      "Epoch 12270, Loss: 0.008089417591691017, Neurons: 64, Grad norm: 2.980e-01\n",
      "Epoch 12270, Loss: 0.008089417591691017, Neurons: 64, Grad norm: 2.980e-01\n",
      "Epoch 12271, Loss: 0.008087792433798313, Neurons: 64, Grad norm: 3.167e-01\n",
      "Epoch 12271, Loss: 0.008087792433798313, Neurons: 64, Grad norm: 3.167e-01\n",
      "Epoch 12272, Loss: 0.008085948415100574, Neurons: 64, Grad norm: 3.522e-01\n",
      "Epoch 12272, Loss: 0.008085948415100574, Neurons: 64, Grad norm: 3.522e-01\n",
      "Epoch 12273, Loss: 0.00808405689895153, Neurons: 64, Grad norm: 3.671e-01\n",
      "Epoch 12273, Loss: 0.00808405689895153, Neurons: 64, Grad norm: 3.671e-01\n",
      "Epoch 12274, Loss: 0.008082130923867226, Neurons: 64, Grad norm: 4.040e-01\n",
      "Epoch 12274, Loss: 0.008082130923867226, Neurons: 64, Grad norm: 4.040e-01\n",
      "Epoch 12275, Loss: 0.008080300875008106, Neurons: 64, Grad norm: 4.242e-01\n",
      "Epoch 12275, Loss: 0.008080300875008106, Neurons: 64, Grad norm: 4.242e-01\n",
      "Epoch 12276, Loss: 0.008078555576503277, Neurons: 64, Grad norm: 4.756e-01\n",
      "Epoch 12276, Loss: 0.008078555576503277, Neurons: 64, Grad norm: 4.756e-01\n",
      "Epoch 12277, Loss: 0.0080771055072546, Neurons: 64, Grad norm: 5.165e-01\n",
      "Epoch 12277, Loss: 0.0080771055072546, Neurons: 64, Grad norm: 5.165e-01\n",
      "Epoch 12278, Loss: 0.008075959980487823, Neurons: 64, Grad norm: 5.909e-01\n",
      "Epoch 12278, Loss: 0.008075959980487823, Neurons: 64, Grad norm: 5.909e-01\n",
      "Epoch 12279, Loss: 0.008075140416622162, Neurons: 64, Grad norm: 6.528e-01\n",
      "Epoch 12279, Loss: 0.008075140416622162, Neurons: 64, Grad norm: 6.528e-01\n",
      "Epoch 12280, Loss: 0.0080748051404953, Neurons: 64, Grad norm: 7.545e-01\n",
      "Epoch 12280, Loss: 0.0080748051404953, Neurons: 64, Grad norm: 7.545e-01\n",
      "Epoch 12281, Loss: 0.008074869401752949, Neurons: 64, Grad norm: 8.514e-01\n",
      "Epoch 12281, Loss: 0.008074869401752949, Neurons: 64, Grad norm: 8.514e-01\n",
      "Epoch 12282, Loss: 0.008075697347521782, Neurons: 64, Grad norm: 9.943e-01\n",
      "Epoch 12282, Loss: 0.008075697347521782, Neurons: 64, Grad norm: 9.943e-01\n",
      "Epoch 12283, Loss: 0.0080774687230587, Neurons: 64, Grad norm: 1.139e+00\n",
      "Epoch 12283, Loss: 0.0080774687230587, Neurons: 64, Grad norm: 1.139e+00\n",
      "Epoch 12284, Loss: 0.008080821484327316, Neurons: 64, Grad norm: 1.343e+00\n",
      "Epoch 12284, Loss: 0.008080821484327316, Neurons: 64, Grad norm: 1.343e+00\n",
      "Epoch 12285, Loss: 0.00808632466942072, Neurons: 64, Grad norm: 1.562e+00\n",
      "Epoch 12285, Loss: 0.00808632466942072, Neurons: 64, Grad norm: 1.562e+00\n",
      "Epoch 12286, Loss: 0.008094809018075466, Neurons: 64, Grad norm: 1.849e+00\n",
      "Epoch 12286, Loss: 0.008094809018075466, Neurons: 64, Grad norm: 1.849e+00\n",
      "Epoch 12287, Loss: 0.008107475936412811, Neurons: 64, Grad norm: 2.167e+00\n",
      "Epoch 12287, Loss: 0.008107475936412811, Neurons: 64, Grad norm: 2.167e+00\n",
      "Epoch 12288, Loss: 0.008126173168420792, Neurons: 64, Grad norm: 2.571e+00\n",
      "Epoch 12288, Loss: 0.008126173168420792, Neurons: 64, Grad norm: 2.571e+00\n",
      "Epoch 12289, Loss: 0.008153161965310574, Neurons: 64, Grad norm: 3.025e+00\n",
      "Epoch 12289, Loss: 0.008153161965310574, Neurons: 64, Grad norm: 3.025e+00\n",
      "Epoch 12290, Loss: 0.008191617205739021, Neurons: 64, Grad norm: 3.587e+00\n",
      "Epoch 12290, Loss: 0.008191617205739021, Neurons: 64, Grad norm: 3.587e+00\n",
      "Epoch 12291, Loss: 0.008245882578194141, Neurons: 64, Grad norm: 4.216e+00\n",
      "Epoch 12291, Loss: 0.008245882578194141, Neurons: 64, Grad norm: 4.216e+00\n",
      "Epoch 12292, Loss: 0.008321312256157398, Neurons: 64, Grad norm: 4.960e+00\n",
      "Epoch 12292, Loss: 0.008321312256157398, Neurons: 64, Grad norm: 4.960e+00\n",
      "Epoch 12293, Loss: 0.0084231523796916, Neurons: 64, Grad norm: 5.755e+00\n",
      "Epoch 12293, Loss: 0.0084231523796916, Neurons: 64, Grad norm: 5.755e+00\n",
      "Epoch 12294, Loss: 0.008555624634027481, Neurons: 64, Grad norm: 6.618e+00\n",
      "Epoch 12294, Loss: 0.008555624634027481, Neurons: 64, Grad norm: 6.618e+00\n",
      "Epoch 12295, Loss: 0.008716811425983906, Neurons: 64, Grad norm: 7.431e+00\n",
      "Epoch 12295, Loss: 0.008716811425983906, Neurons: 64, Grad norm: 7.431e+00\n",
      "Epoch 12296, Loss: 0.00889513734728098, Neurons: 64, Grad norm: 8.128e+00\n",
      "Epoch 12296, Loss: 0.00889513734728098, Neurons: 64, Grad norm: 8.128e+00\n",
      "Epoch 12297, Loss: 0.009059102274477482, Neurons: 64, Grad norm: 8.515e+00\n",
      "Epoch 12297, Loss: 0.009059102274477482, Neurons: 64, Grad norm: 8.515e+00\n",
      "Epoch 12298, Loss: 0.009161052294075489, Neurons: 64, Grad norm: 8.459e+00\n",
      "Epoch 12298, Loss: 0.009161052294075489, Neurons: 64, Grad norm: 8.459e+00\n",
      "Epoch 12299, Loss: 0.009142233058810234, Neurons: 64, Grad norm: 7.775e+00\n",
      "Epoch 12299, Loss: 0.009142233058810234, Neurons: 64, Grad norm: 7.775e+00\n",
      "Epoch 12299, Test loss: 0.006806320510804653\n",
      "Epoch 12299, Test loss: 0.006806320510804653\n",
      "Epoch 12300, Loss: 0.008972309529781342, Neurons: 64, Grad norm: 6.461e+00\n",
      "Epoch 12300, Loss: 0.008972309529781342, Neurons: 64, Grad norm: 6.461e+00\n",
      "Epoch 12301, Loss: 0.008676704950630665, Neurons: 64, Grad norm: 4.561e+00\n",
      "Epoch 12301, Loss: 0.008676704950630665, Neurons: 64, Grad norm: 4.561e+00\n",
      "Epoch 12302, Loss: 0.0083504943177104, Neurons: 64, Grad norm: 2.339e+00\n",
      "Epoch 12302, Loss: 0.0083504943177104, Neurons: 64, Grad norm: 2.339e+00\n",
      "Epoch 12303, Loss: 0.008107561618089676, Neurons: 64, Grad norm: 8.205e-02\n",
      "Epoch 12303, Loss: 0.008107561618089676, Neurons: 64, Grad norm: 8.205e-02\n",
      "Epoch 12304, Loss: 0.008019665256142616, Neurons: 64, Grad norm: 2.028e+00\n",
      "Epoch 12304, Loss: 0.008019665256142616, Neurons: 64, Grad norm: 2.028e+00\n",
      "Epoch 12305, Loss: 0.008080627769231796, Neurons: 64, Grad norm: 3.657e+00\n",
      "Epoch 12305, Loss: 0.008080627769231796, Neurons: 64, Grad norm: 3.657e+00\n",
      "Epoch 12306, Loss: 0.008221711032092571, Neurons: 64, Grad norm: 4.673e+00\n",
      "Epoch 12306, Loss: 0.008221711032092571, Neurons: 64, Grad norm: 4.673e+00\n",
      "Epoch 12307, Loss: 0.008353140205144882, Neurons: 64, Grad norm: 5.034e+00\n",
      "Epoch 12307, Loss: 0.008353140205144882, Neurons: 64, Grad norm: 5.034e+00\n",
      "Epoch 12308, Loss: 0.008404327556490898, Neurons: 64, Grad norm: 4.688e+00\n",
      "Epoch 12308, Loss: 0.008404327556490898, Neurons: 64, Grad norm: 4.688e+00\n",
      "Epoch 12309, Loss: 0.00835314579308033, Neurons: 64, Grad norm: 3.767e+00\n",
      "Epoch 12309, Loss: 0.00835314579308033, Neurons: 64, Grad norm: 3.767e+00\n",
      "Epoch 12310, Loss: 0.008229401893913746, Neurons: 64, Grad norm: 2.400e+00\n",
      "Epoch 12310, Loss: 0.008229401893913746, Neurons: 64, Grad norm: 2.400e+00\n",
      "Epoch 12311, Loss: 0.00809710007160902, Neurons: 64, Grad norm: 8.569e-01\n",
      "Epoch 12311, Loss: 0.00809710007160902, Neurons: 64, Grad norm: 8.569e-01\n",
      "Epoch 12312, Loss: 0.008015677332878113, Neurons: 64, Grad norm: 6.904e-01\n",
      "Epoch 12312, Loss: 0.008015677332878113, Neurons: 64, Grad norm: 6.904e-01\n",
      "Epoch 12313, Loss: 0.008008655160665512, Neurons: 64, Grad norm: 1.950e+00\n",
      "Epoch 12313, Loss: 0.008008655160665512, Neurons: 64, Grad norm: 1.950e+00\n",
      "Epoch 12314, Loss: 0.008057937026023865, Neurons: 64, Grad norm: 2.843e+00\n",
      "Epoch 12314, Loss: 0.008057937026023865, Neurons: 64, Grad norm: 2.843e+00\n",
      "Epoch 12315, Loss: 0.008121390827000141, Neurons: 64, Grad norm: 3.240e+00\n",
      "Epoch 12315, Loss: 0.008121390827000141, Neurons: 64, Grad norm: 3.240e+00\n",
      "Epoch 12316, Loss: 0.008158370852470398, Neurons: 64, Grad norm: 3.174e+00\n",
      "Epoch 12316, Loss: 0.008158370852470398, Neurons: 64, Grad norm: 3.174e+00\n",
      "Epoch 12317, Loss: 0.008149181492626667, Neurons: 64, Grad norm: 2.652e+00\n",
      "Epoch 12317, Loss: 0.008149181492626667, Neurons: 64, Grad norm: 2.652e+00\n",
      "Epoch 12318, Loss: 0.008101841434836388, Neurons: 64, Grad norm: 1.832e+00\n",
      "Epoch 12318, Loss: 0.008101841434836388, Neurons: 64, Grad norm: 1.832e+00\n",
      "Epoch 12319, Loss: 0.008042469620704651, Neurons: 64, Grad norm: 8.220e-01\n",
      "Epoch 12319, Loss: 0.008042469620704651, Neurons: 64, Grad norm: 8.220e-01\n",
      "Epoch 12320, Loss: 0.007999202236533165, Neurons: 64, Grad norm: 2.228e-01\n",
      "Epoch 12320, Loss: 0.007999202236533165, Neurons: 64, Grad norm: 2.228e-01\n",
      "Epoch 12321, Loss: 0.007986965589225292, Neurons: 64, Grad norm: 1.107e+00\n",
      "Epoch 12321, Loss: 0.007986965589225292, Neurons: 64, Grad norm: 1.107e+00\n",
      "Epoch 12322, Loss: 0.008002214133739471, Neurons: 64, Grad norm: 1.752e+00\n",
      "Epoch 12322, Loss: 0.008002214133739471, Neurons: 64, Grad norm: 1.752e+00\n",
      "Epoch 12323, Loss: 0.008028732612729073, Neurons: 64, Grad norm: 2.117e+00\n",
      "Epoch 12323, Loss: 0.008028732612729073, Neurons: 64, Grad norm: 2.117e+00\n",
      "Epoch 12324, Loss: 0.00804797001183033, Neurons: 64, Grad norm: 2.146e+00\n",
      "Epoch 12324, Loss: 0.00804797001183033, Neurons: 64, Grad norm: 2.146e+00\n",
      "Epoch 12325, Loss: 0.008048885501921177, Neurons: 64, Grad norm: 1.911e+00\n",
      "Epoch 12325, Loss: 0.008048885501921177, Neurons: 64, Grad norm: 1.911e+00\n",
      "Epoch 12326, Loss: 0.008031613193452358, Neurons: 64, Grad norm: 1.425e+00\n",
      "Epoch 12326, Loss: 0.008031613193452358, Neurons: 64, Grad norm: 1.425e+00\n",
      "Epoch 12327, Loss: 0.008005522191524506, Neurons: 64, Grad norm: 8.205e-01\n",
      "Epoch 12327, Loss: 0.008005522191524506, Neurons: 64, Grad norm: 8.205e-01\n",
      "Epoch 12328, Loss: 0.007982409559190273, Neurons: 64, Grad norm: 1.581e-01\n",
      "Epoch 12328, Loss: 0.007982409559190273, Neurons: 64, Grad norm: 1.581e-01\n",
      "Epoch 12329, Loss: 0.007970592938363552, Neurons: 64, Grad norm: 4.624e-01\n",
      "Epoch 12329, Loss: 0.007970592938363552, Neurons: 64, Grad norm: 4.624e-01\n",
      "Epoch 12330, Loss: 0.007971446961164474, Neurons: 64, Grad norm: 9.669e-01\n",
      "Epoch 12330, Loss: 0.007971446961164474, Neurons: 64, Grad norm: 9.669e-01\n",
      "Epoch 12331, Loss: 0.00798014085739851, Neurons: 64, Grad norm: 1.285e+00\n",
      "Epoch 12331, Loss: 0.00798014085739851, Neurons: 64, Grad norm: 1.285e+00\n",
      "Epoch 12332, Loss: 0.007989373989403248, Neurons: 64, Grad norm: 1.431e+00\n",
      "Epoch 12332, Loss: 0.007989373989403248, Neurons: 64, Grad norm: 1.431e+00\n",
      "Epoch 12333, Loss: 0.00799307320266962, Neurons: 64, Grad norm: 1.370e+00\n",
      "Epoch 12333, Loss: 0.00799307320266962, Neurons: 64, Grad norm: 1.370e+00\n",
      "Epoch 12334, Loss: 0.00798903126269579, Neurons: 64, Grad norm: 1.176e+00\n",
      "Epoch 12334, Loss: 0.00798903126269579, Neurons: 64, Grad norm: 1.176e+00\n",
      "Epoch 12335, Loss: 0.007979003712534904, Neurons: 64, Grad norm: 8.397e-01\n",
      "Epoch 12335, Loss: 0.007979003712534904, Neurons: 64, Grad norm: 8.397e-01\n",
      "Epoch 12336, Loss: 0.007967022247612476, Neurons: 64, Grad norm: 4.612e-01\n",
      "Epoch 12336, Loss: 0.007967022247612476, Neurons: 64, Grad norm: 4.612e-01\n",
      "Epoch 12337, Loss: 0.007957345806062222, Neurons: 64, Grad norm: 4.993e-02\n",
      "Epoch 12337, Loss: 0.007957345806062222, Neurons: 64, Grad norm: 4.993e-02\n",
      "Epoch 12338, Loss: 0.007952230982482433, Neurons: 64, Grad norm: 3.077e-01\n",
      "Epoch 12338, Loss: 0.007952230982482433, Neurons: 64, Grad norm: 3.077e-01\n",
      "Epoch 12339, Loss: 0.00795177835971117, Neurons: 64, Grad norm: 6.148e-01\n",
      "Epoch 12339, Loss: 0.00795177835971117, Neurons: 64, Grad norm: 6.148e-01\n",
      "Epoch 12340, Loss: 0.007953994907438755, Neurons: 64, Grad norm: 8.039e-01\n",
      "Epoch 12340, Loss: 0.007953994907438755, Neurons: 64, Grad norm: 8.039e-01\n",
      "Epoch 12341, Loss: 0.00795635674148798, Neurons: 64, Grad norm: 9.065e-01\n",
      "Epoch 12341, Loss: 0.00795635674148798, Neurons: 64, Grad norm: 9.065e-01\n",
      "Epoch 12342, Loss: 0.007956800051033497, Neurons: 64, Grad norm: 8.812e-01\n",
      "Epoch 12342, Loss: 0.007956800051033497, Neurons: 64, Grad norm: 8.812e-01\n",
      "Epoch 12343, Loss: 0.007954453118145466, Neurons: 64, Grad norm: 7.913e-01\n",
      "Epoch 12343, Loss: 0.007954453118145466, Neurons: 64, Grad norm: 7.913e-01\n",
      "Epoch 12344, Loss: 0.007949918508529663, Neurons: 64, Grad norm: 6.049e-01\n",
      "Epoch 12344, Loss: 0.007949918508529663, Neurons: 64, Grad norm: 6.049e-01\n",
      "Epoch 12345, Loss: 0.007944222539663315, Neurons: 64, Grad norm: 3.967e-01\n",
      "Epoch 12345, Loss: 0.007944222539663315, Neurons: 64, Grad norm: 3.967e-01\n",
      "Epoch 12346, Loss: 0.00793890468776226, Neurons: 64, Grad norm: 1.534e-01\n",
      "Epoch 12346, Loss: 0.00793890468776226, Neurons: 64, Grad norm: 1.534e-01\n",
      "Epoch 12347, Loss: 0.007934986613690853, Neurons: 64, Grad norm: 6.367e-02\n",
      "Epoch 12347, Loss: 0.007934986613690853, Neurons: 64, Grad norm: 6.367e-02\n",
      "Epoch 12348, Loss: 0.007932700216770172, Neurons: 64, Grad norm: 2.680e-01\n",
      "Epoch 12348, Loss: 0.007932700216770172, Neurons: 64, Grad norm: 2.680e-01\n",
      "Epoch 12349, Loss: 0.007931754924356937, Neurons: 64, Grad norm: 4.070e-01\n",
      "Epoch 12349, Loss: 0.007931754924356937, Neurons: 64, Grad norm: 4.070e-01\n",
      "Epoch 12350, Loss: 0.007931346073746681, Neurons: 64, Grad norm: 5.173e-01\n",
      "Epoch 12350, Loss: 0.007931346073746681, Neurons: 64, Grad norm: 5.173e-01\n",
      "Epoch 12351, Loss: 0.007930788211524487, Neurons: 64, Grad norm: 5.473e-01\n",
      "Epoch 12351, Loss: 0.007930788211524487, Neurons: 64, Grad norm: 5.473e-01\n",
      "Epoch 12352, Loss: 0.007929558865725994, Neurons: 64, Grad norm: 5.493e-01\n",
      "Epoch 12352, Loss: 0.007929558865725994, Neurons: 64, Grad norm: 5.493e-01\n",
      "Epoch 12353, Loss: 0.007927397266030312, Neurons: 64, Grad norm: 4.832e-01\n",
      "Epoch 12353, Loss: 0.007927397266030312, Neurons: 64, Grad norm: 4.832e-01\n",
      "Epoch 12354, Loss: 0.007924576289951801, Neurons: 64, Grad norm: 4.012e-01\n",
      "Epoch 12354, Loss: 0.007924576289951801, Neurons: 64, Grad norm: 4.012e-01\n",
      "Epoch 12355, Loss: 0.007921341806650162, Neurons: 64, Grad norm: 2.704e-01\n",
      "Epoch 12355, Loss: 0.007921341806650162, Neurons: 64, Grad norm: 2.704e-01\n",
      "Epoch 12356, Loss: 0.007918182760477066, Neurons: 64, Grad norm: 1.568e-01\n",
      "Epoch 12356, Loss: 0.007918182760477066, Neurons: 64, Grad norm: 1.568e-01\n",
      "Epoch 12357, Loss: 0.007915407419204712, Neurons: 64, Grad norm: 2.314e-02\n",
      "Epoch 12357, Loss: 0.007915407419204712, Neurons: 64, Grad norm: 2.314e-02\n",
      "Epoch 12358, Loss: 0.007913123816251755, Neurons: 64, Grad norm: 9.012e-02\n",
      "Epoch 12358, Loss: 0.007913123816251755, Neurons: 64, Grad norm: 9.012e-02\n",
      "Epoch 12359, Loss: 0.007911229506134987, Neurons: 64, Grad norm: 1.995e-01\n",
      "Epoch 12359, Loss: 0.007911229506134987, Neurons: 64, Grad norm: 1.995e-01\n",
      "Epoch 12360, Loss: 0.00790976732969284, Neurons: 64, Grad norm: 2.605e-01\n",
      "Epoch 12360, Loss: 0.00790976732969284, Neurons: 64, Grad norm: 2.605e-01\n",
      "Epoch 12361, Loss: 0.007908319123089314, Neurons: 64, Grad norm: 3.198e-01\n",
      "Epoch 12361, Loss: 0.007908319123089314, Neurons: 64, Grad norm: 3.198e-01\n",
      "Epoch 12362, Loss: 0.007906767539680004, Neurons: 64, Grad norm: 3.277e-01\n",
      "Epoch 12362, Loss: 0.007906767539680004, Neurons: 64, Grad norm: 3.277e-01\n",
      "Epoch 12363, Loss: 0.007905034348368645, Neurons: 64, Grad norm: 3.319e-01\n",
      "Epoch 12363, Loss: 0.007905034348368645, Neurons: 64, Grad norm: 3.319e-01\n",
      "Epoch 12364, Loss: 0.007903000339865685, Neurons: 64, Grad norm: 2.928e-01\n",
      "Epoch 12364, Loss: 0.007903000339865685, Neurons: 64, Grad norm: 2.928e-01\n",
      "Epoch 12365, Loss: 0.00790076982229948, Neurons: 64, Grad norm: 2.631e-01\n",
      "Epoch 12365, Loss: 0.00790076982229948, Neurons: 64, Grad norm: 2.631e-01\n",
      "Epoch 12366, Loss: 0.007898520678281784, Neurons: 64, Grad norm: 1.976e-01\n",
      "Epoch 12366, Loss: 0.007898520678281784, Neurons: 64, Grad norm: 1.976e-01\n",
      "Epoch 12367, Loss: 0.007896159775555134, Neurons: 64, Grad norm: 1.457e-01\n",
      "Epoch 12367, Loss: 0.007896159775555134, Neurons: 64, Grad norm: 1.457e-01\n",
      "Epoch 12368, Loss: 0.007893865928053856, Neurons: 64, Grad norm: 6.988e-02\n",
      "Epoch 12368, Loss: 0.007893865928053856, Neurons: 64, Grad norm: 6.988e-02\n",
      "Epoch 12369, Loss: 0.007891741581261158, Neurons: 64, Grad norm: 2.532e-02\n",
      "Epoch 12369, Loss: 0.007891741581261158, Neurons: 64, Grad norm: 2.532e-02\n",
      "Epoch 12370, Loss: 0.00788966566324234, Neurons: 64, Grad norm: 5.548e-02\n",
      "Epoch 12370, Loss: 0.00788966566324234, Neurons: 64, Grad norm: 5.548e-02\n",
      "Epoch 12371, Loss: 0.00788772664964199, Neurons: 64, Grad norm: 9.811e-02\n",
      "Epoch 12371, Loss: 0.00788772664964199, Neurons: 64, Grad norm: 9.811e-02\n",
      "Epoch 12372, Loss: 0.007885925471782684, Neurons: 64, Grad norm: 1.510e-01\n",
      "Epoch 12372, Loss: 0.007885925471782684, Neurons: 64, Grad norm: 1.510e-01\n",
      "Epoch 12373, Loss: 0.007884137332439423, Neurons: 64, Grad norm: 1.738e-01\n",
      "Epoch 12373, Loss: 0.007884137332439423, Neurons: 64, Grad norm: 1.738e-01\n",
      "Epoch 12374, Loss: 0.007882390171289444, Neurons: 64, Grad norm: 2.114e-01\n",
      "Epoch 12374, Loss: 0.007882390171289444, Neurons: 64, Grad norm: 2.114e-01\n",
      "Epoch 12375, Loss: 0.00788054894655943, Neurons: 64, Grad norm: 2.145e-01\n",
      "Epoch 12375, Loss: 0.00788054894655943, Neurons: 64, Grad norm: 2.145e-01\n",
      "Epoch 12376, Loss: 0.00787873100489378, Neurons: 64, Grad norm: 2.272e-01\n",
      "Epoch 12376, Loss: 0.00787873100489378, Neurons: 64, Grad norm: 2.272e-01\n",
      "Epoch 12377, Loss: 0.007876843214035034, Neurons: 64, Grad norm: 2.137e-01\n",
      "Epoch 12377, Loss: 0.007876843214035034, Neurons: 64, Grad norm: 2.137e-01\n",
      "Epoch 12378, Loss: 0.007874960079789162, Neurons: 64, Grad norm: 2.169e-01\n",
      "Epoch 12378, Loss: 0.007874960079789162, Neurons: 64, Grad norm: 2.169e-01\n",
      "Epoch 12379, Loss: 0.007872961461544037, Neurons: 64, Grad norm: 1.939e-01\n",
      "Epoch 12379, Loss: 0.007872961461544037, Neurons: 64, Grad norm: 1.939e-01\n",
      "Epoch 12380, Loss: 0.00787101499736309, Neurons: 64, Grad norm: 1.829e-01\n",
      "Epoch 12380, Loss: 0.00787101499736309, Neurons: 64, Grad norm: 1.829e-01\n",
      "Epoch 12381, Loss: 0.007869004271924496, Neurons: 64, Grad norm: 1.587e-01\n",
      "Epoch 12381, Loss: 0.007869004271924496, Neurons: 64, Grad norm: 1.587e-01\n",
      "Epoch 12382, Loss: 0.007867060601711273, Neurons: 64, Grad norm: 1.547e-01\n",
      "Epoch 12382, Loss: 0.007867060601711273, Neurons: 64, Grad norm: 1.547e-01\n",
      "Epoch 12383, Loss: 0.00786514114588499, Neurons: 64, Grad norm: 1.365e-01\n",
      "Epoch 12383, Loss: 0.00786514114588499, Neurons: 64, Grad norm: 1.365e-01\n",
      "Epoch 12384, Loss: 0.007863256148993969, Neurons: 64, Grad norm: 1.353e-01\n",
      "Epoch 12384, Loss: 0.007863256148993969, Neurons: 64, Grad norm: 1.353e-01\n",
      "Epoch 12385, Loss: 0.007861410267651081, Neurons: 64, Grad norm: 1.408e-01\n",
      "Epoch 12385, Loss: 0.007861410267651081, Neurons: 64, Grad norm: 1.408e-01\n",
      "Epoch 12386, Loss: 0.007859746925532818, Neurons: 64, Grad norm: 1.534e-01\n",
      "Epoch 12386, Loss: 0.007859746925532818, Neurons: 64, Grad norm: 1.534e-01\n",
      "Epoch 12387, Loss: 0.007858139462769032, Neurons: 64, Grad norm: 1.807e-01\n",
      "Epoch 12387, Loss: 0.007858139462769032, Neurons: 64, Grad norm: 1.807e-01\n",
      "Epoch 12388, Loss: 0.00785677321255207, Neurons: 64, Grad norm: 2.054e-01\n",
      "Epoch 12388, Loss: 0.00785677321255207, Neurons: 64, Grad norm: 2.054e-01\n",
      "Epoch 12389, Loss: 0.00785558670759201, Neurons: 64, Grad norm: 2.433e-01\n",
      "Epoch 12389, Loss: 0.00785558670759201, Neurons: 64, Grad norm: 2.433e-01\n",
      "Epoch 12390, Loss: 0.00785459391772747, Neurons: 64, Grad norm: 2.752e-01\n",
      "Epoch 12390, Loss: 0.00785459391772747, Neurons: 64, Grad norm: 2.752e-01\n",
      "Epoch 12391, Loss: 0.007853951305150986, Neurons: 64, Grad norm: 3.237e-01\n",
      "Epoch 12391, Loss: 0.007853951305150986, Neurons: 64, Grad norm: 3.237e-01\n",
      "Epoch 12392, Loss: 0.007853643037378788, Neurons: 64, Grad norm: 3.653e-01\n",
      "Epoch 12392, Loss: 0.007853643037378788, Neurons: 64, Grad norm: 3.653e-01\n",
      "Epoch 12393, Loss: 0.007853847928345203, Neurons: 64, Grad norm: 4.280e-01\n",
      "Epoch 12393, Loss: 0.007853847928345203, Neurons: 64, Grad norm: 4.280e-01\n",
      "Epoch 12394, Loss: 0.007855054922401905, Neurons: 64, Grad norm: 4.869e-01\n",
      "Epoch 12394, Loss: 0.007855054922401905, Neurons: 64, Grad norm: 4.869e-01\n",
      "Epoch 12395, Loss: 0.007857121527194977, Neurons: 64, Grad norm: 5.657e-01\n",
      "Epoch 12395, Loss: 0.007857121527194977, Neurons: 64, Grad norm: 5.657e-01\n",
      "Epoch 12396, Loss: 0.007860465906560421, Neurons: 64, Grad norm: 6.476e-01\n",
      "Epoch 12396, Loss: 0.007860465906560421, Neurons: 64, Grad norm: 6.476e-01\n",
      "Epoch 12397, Loss: 0.0078656617552042, Neurons: 64, Grad norm: 7.557e-01\n",
      "Epoch 12397, Loss: 0.0078656617552042, Neurons: 64, Grad norm: 7.557e-01\n",
      "Epoch 12398, Loss: 0.007873814553022385, Neurons: 64, Grad norm: 8.734e-01\n",
      "Epoch 12398, Loss: 0.007873814553022385, Neurons: 64, Grad norm: 8.734e-01\n",
      "Epoch 12399, Loss: 0.00788521021604538, Neurons: 64, Grad norm: 1.019e+00\n",
      "Epoch 12399, Loss: 0.00788521021604538, Neurons: 64, Grad norm: 1.019e+00\n",
      "Epoch 12399, Test loss: 0.0061371708288788795\n",
      "Epoch 12399, Test loss: 0.0061371708288788795\n",
      "Epoch 12400, Loss: 0.007901737466454506, Neurons: 64, Grad norm: 1.176e+00\n",
      "Epoch 12400, Loss: 0.007901737466454506, Neurons: 64, Grad norm: 1.176e+00\n",
      "Epoch 12401, Loss: 0.00792353879660368, Neurons: 64, Grad norm: 1.359e+00\n",
      "Epoch 12401, Loss: 0.00792353879660368, Neurons: 64, Grad norm: 1.359e+00\n",
      "Epoch 12402, Loss: 0.007952642627060413, Neurons: 64, Grad norm: 1.547e+00\n",
      "Epoch 12402, Loss: 0.007952642627060413, Neurons: 64, Grad norm: 1.547e+00\n",
      "Epoch 12403, Loss: 0.007987759076058865, Neurons: 64, Grad norm: 1.744e+00\n",
      "Epoch 12403, Loss: 0.007987759076058865, Neurons: 64, Grad norm: 1.744e+00\n",
      "Epoch 12404, Loss: 0.008028733544051647, Neurons: 64, Grad norm: 1.917e+00\n",
      "Epoch 12404, Loss: 0.008028733544051647, Neurons: 64, Grad norm: 1.917e+00\n",
      "Epoch 12405, Loss: 0.00806931871920824, Neurons: 64, Grad norm: 2.055e+00\n",
      "Epoch 12405, Loss: 0.00806931871920824, Neurons: 64, Grad norm: 2.055e+00\n",
      "Epoch 12406, Loss: 0.008102944120764732, Neurons: 64, Grad norm: 2.116e+00\n",
      "Epoch 12406, Loss: 0.008102944120764732, Neurons: 64, Grad norm: 2.116e+00\n",
      "Epoch 12407, Loss: 0.008116464130580425, Neurons: 64, Grad norm: 2.077e+00\n",
      "Epoch 12407, Loss: 0.008116464130580425, Neurons: 64, Grad norm: 2.077e+00\n",
      "Epoch 12408, Loss: 0.008101379498839378, Neurons: 64, Grad norm: 1.909e+00\n",
      "Epoch 12408, Loss: 0.008101379498839378, Neurons: 64, Grad norm: 1.909e+00\n",
      "Epoch 12409, Loss: 0.008052360266447067, Neurons: 64, Grad norm: 1.617e+00\n",
      "Epoch 12409, Loss: 0.008052360266447067, Neurons: 64, Grad norm: 1.617e+00\n",
      "Epoch 12410, Loss: 0.007978198118507862, Neurons: 64, Grad norm: 1.226e+00\n",
      "Epoch 12410, Loss: 0.007978198118507862, Neurons: 64, Grad norm: 1.226e+00\n",
      "Epoch 12411, Loss: 0.007899387739598751, Neurons: 64, Grad norm: 8.085e-01\n",
      "Epoch 12411, Loss: 0.007899387739598751, Neurons: 64, Grad norm: 8.085e-01\n",
      "Epoch 12412, Loss: 0.007839133962988853, Neurons: 64, Grad norm: 5.544e-01\n",
      "Epoch 12412, Loss: 0.007839133962988853, Neurons: 64, Grad norm: 5.544e-01\n",
      "Epoch 12413, Loss: 0.007811916526407003, Neurons: 64, Grad norm: 6.577e-01\n",
      "Epoch 12413, Loss: 0.007811916526407003, Neurons: 64, Grad norm: 6.577e-01\n",
      "Epoch 12414, Loss: 0.007818082347512245, Neurons: 64, Grad norm: 9.540e-01\n",
      "Epoch 12414, Loss: 0.007818082347512245, Neurons: 64, Grad norm: 9.540e-01\n",
      "Epoch 12415, Loss: 0.007845827378332615, Neurons: 64, Grad norm: 1.191e+00\n",
      "Epoch 12415, Loss: 0.007845827378332615, Neurons: 64, Grad norm: 1.191e+00\n",
      "Epoch 12416, Loss: 0.0078780772164464, Neurons: 64, Grad norm: 1.351e+00\n",
      "Epoch 12416, Loss: 0.0078780772164464, Neurons: 64, Grad norm: 1.351e+00\n",
      "Epoch 12417, Loss: 0.007899323478341103, Neurons: 64, Grad norm: 1.380e+00\n",
      "Epoch 12417, Loss: 0.007899323478341103, Neurons: 64, Grad norm: 1.380e+00\n",
      "Epoch 12418, Loss: 0.00790072325617075, Neurons: 64, Grad norm: 1.324e+00\n",
      "Epoch 12418, Loss: 0.00790072325617075, Neurons: 64, Grad norm: 1.324e+00\n",
      "Epoch 12419, Loss: 0.00788264349102974, Neurons: 64, Grad norm: 1.185e+00\n",
      "Epoch 12419, Loss: 0.00788264349102974, Neurons: 64, Grad norm: 1.185e+00\n",
      "Epoch 12420, Loss: 0.007853413932025433, Neurons: 64, Grad norm: 1.066e+00\n",
      "Epoch 12420, Loss: 0.007853413932025433, Neurons: 64, Grad norm: 1.066e+00\n",
      "Epoch 12421, Loss: 0.007825056090950966, Neurons: 64, Grad norm: 9.999e-01\n",
      "Epoch 12421, Loss: 0.007825056090950966, Neurons: 64, Grad norm: 9.999e-01\n",
      "Epoch 12422, Loss: 0.007807859219610691, Neurons: 64, Grad norm: 1.077e+00\n",
      "Epoch 12422, Loss: 0.007807859219610691, Neurons: 64, Grad norm: 1.077e+00\n",
      "Epoch 12423, Loss: 0.007805741857737303, Neurons: 64, Grad norm: 1.223e+00\n",
      "Epoch 12423, Loss: 0.007805741857737303, Neurons: 64, Grad norm: 1.223e+00\n",
      "Epoch 12424, Loss: 0.007816257886588573, Neurons: 64, Grad norm: 1.417e+00\n",
      "Epoch 12424, Loss: 0.007816257886588573, Neurons: 64, Grad norm: 1.417e+00\n",
      "Epoch 12425, Loss: 0.0078324805945158, Neurons: 64, Grad norm: 1.581e+00\n",
      "Epoch 12425, Loss: 0.0078324805945158, Neurons: 64, Grad norm: 1.581e+00\n",
      "Epoch 12426, Loss: 0.007847168482840061, Neurons: 64, Grad norm: 1.739e+00\n",
      "Epoch 12426, Loss: 0.007847168482840061, Neurons: 64, Grad norm: 1.739e+00\n",
      "Epoch 12427, Loss: 0.007855485193431377, Neurons: 64, Grad norm: 1.868e+00\n",
      "Epoch 12427, Loss: 0.007855485193431377, Neurons: 64, Grad norm: 1.868e+00\n",
      "Epoch 12428, Loss: 0.007857163436710835, Neurons: 64, Grad norm: 2.018e+00\n",
      "Epoch 12428, Loss: 0.007857163436710835, Neurons: 64, Grad norm: 2.018e+00\n",
      "Epoch 12429, Loss: 0.00785518903285265, Neurons: 64, Grad norm: 2.178e+00\n",
      "Epoch 12429, Loss: 0.00785518903285265, Neurons: 64, Grad norm: 2.178e+00\n",
      "Epoch 12430, Loss: 0.007855238392949104, Neurons: 64, Grad norm: 2.412e+00\n",
      "Epoch 12430, Loss: 0.007855238392949104, Neurons: 64, Grad norm: 2.412e+00\n",
      "Epoch 12431, Loss: 0.007862664759159088, Neurons: 64, Grad norm: 2.683e+00\n",
      "Epoch 12431, Loss: 0.007862664759159088, Neurons: 64, Grad norm: 2.683e+00\n",
      "Epoch 12432, Loss: 0.007880916818976402, Neurons: 64, Grad norm: 3.030e+00\n",
      "Epoch 12432, Loss: 0.007880916818976402, Neurons: 64, Grad norm: 3.030e+00\n",
      "Epoch 12433, Loss: 0.00791088119149208, Neurons: 64, Grad norm: 3.401e+00\n",
      "Epoch 12433, Loss: 0.00791088119149208, Neurons: 64, Grad norm: 3.401e+00\n",
      "Epoch 12434, Loss: 0.007951430045068264, Neurons: 64, Grad norm: 3.833e+00\n",
      "Epoch 12434, Loss: 0.007951430045068264, Neurons: 64, Grad norm: 3.833e+00\n",
      "Epoch 12435, Loss: 0.0080006318166852, Neurons: 64, Grad norm: 4.270e+00\n",
      "Epoch 12435, Loss: 0.0080006318166852, Neurons: 64, Grad norm: 4.270e+00\n",
      "Epoch 12436, Loss: 0.008056750521063805, Neurons: 64, Grad norm: 4.744e+00\n",
      "Epoch 12436, Loss: 0.008056750521063805, Neurons: 64, Grad norm: 4.744e+00\n",
      "Epoch 12437, Loss: 0.008117791265249252, Neurons: 64, Grad norm: 5.192e+00\n",
      "Epoch 12437, Loss: 0.008117791265249252, Neurons: 64, Grad norm: 5.192e+00\n",
      "Epoch 12438, Loss: 0.008181887678802013, Neurons: 64, Grad norm: 5.627e+00\n",
      "Epoch 12438, Loss: 0.008181887678802013, Neurons: 64, Grad norm: 5.627e+00\n",
      "Epoch 12439, Loss: 0.008244863711297512, Neurons: 64, Grad norm: 5.963e+00\n",
      "Epoch 12439, Loss: 0.008244863711297512, Neurons: 64, Grad norm: 5.963e+00\n",
      "Epoch 12440, Loss: 0.00830040592700243, Neurons: 64, Grad norm: 6.192e+00\n",
      "Epoch 12440, Loss: 0.00830040592700243, Neurons: 64, Grad norm: 6.192e+00\n",
      "Epoch 12441, Loss: 0.008336721919476986, Neurons: 64, Grad norm: 6.213e+00\n",
      "Epoch 12441, Loss: 0.008336721919476986, Neurons: 64, Grad norm: 6.213e+00\n",
      "Epoch 12442, Loss: 0.008341604843735695, Neurons: 64, Grad norm: 6.015e+00\n",
      "Epoch 12442, Loss: 0.008341604843735695, Neurons: 64, Grad norm: 6.015e+00\n",
      "Epoch 12443, Loss: 0.008302390575408936, Neurons: 64, Grad norm: 5.517e+00\n",
      "Epoch 12443, Loss: 0.008302390575408936, Neurons: 64, Grad norm: 5.517e+00\n",
      "Epoch 12444, Loss: 0.008217383176088333, Neurons: 64, Grad norm: 4.758e+00\n",
      "Epoch 12444, Loss: 0.008217383176088333, Neurons: 64, Grad norm: 4.758e+00\n",
      "Epoch 12445, Loss: 0.008095869794487953, Neurons: 64, Grad norm: 3.736e+00\n",
      "Epoch 12445, Loss: 0.008095869794487953, Neurons: 64, Grad norm: 3.736e+00\n",
      "Epoch 12446, Loss: 0.007962478324770927, Neurons: 64, Grad norm: 2.564e+00\n",
      "Epoch 12446, Loss: 0.007962478324770927, Neurons: 64, Grad norm: 2.564e+00\n",
      "Epoch 12447, Loss: 0.007845308631658554, Neurons: 64, Grad norm: 1.297e+00\n",
      "Epoch 12447, Loss: 0.007845308631658554, Neurons: 64, Grad norm: 1.297e+00\n",
      "Epoch 12448, Loss: 0.007767914794385433, Neurons: 64, Grad norm: 8.012e-02\n",
      "Epoch 12448, Loss: 0.007767914794385433, Neurons: 64, Grad norm: 8.012e-02\n",
      "Epoch 12449, Loss: 0.00773964449763298, Neurons: 64, Grad norm: 1.044e+00\n",
      "Epoch 12449, Loss: 0.00773964449763298, Neurons: 64, Grad norm: 1.044e+00\n",
      "Epoch 12450, Loss: 0.0077546644024550915, Neurons: 64, Grad norm: 1.962e+00\n",
      "Epoch 12450, Loss: 0.0077546644024550915, Neurons: 64, Grad norm: 1.962e+00\n",
      "Epoch 12451, Loss: 0.007796308025717735, Neurons: 64, Grad norm: 2.674e+00\n",
      "Epoch 12451, Loss: 0.007796308025717735, Neurons: 64, Grad norm: 2.674e+00\n",
      "Epoch 12452, Loss: 0.007844720967113972, Neurons: 64, Grad norm: 3.108e+00\n",
      "Epoch 12452, Loss: 0.007844720967113972, Neurons: 64, Grad norm: 3.108e+00\n",
      "Epoch 12453, Loss: 0.007882309146225452, Neurons: 64, Grad norm: 3.300e+00\n",
      "Epoch 12453, Loss: 0.007882309146225452, Neurons: 64, Grad norm: 3.300e+00\n",
      "Epoch 12454, Loss: 0.007897556759417057, Neurons: 64, Grad norm: 3.213e+00\n",
      "Epoch 12454, Loss: 0.007897556759417057, Neurons: 64, Grad norm: 3.213e+00\n",
      "Epoch 12455, Loss: 0.007887451909482479, Neurons: 64, Grad norm: 2.921e+00\n",
      "Epoch 12455, Loss: 0.007887451909482479, Neurons: 64, Grad norm: 2.921e+00\n",
      "Epoch 12456, Loss: 0.00785650871694088, Neurons: 64, Grad norm: 2.422e+00\n",
      "Epoch 12456, Loss: 0.00785650871694088, Neurons: 64, Grad norm: 2.422e+00\n",
      "Epoch 12457, Loss: 0.007814769633114338, Neurons: 64, Grad norm: 1.814e+00\n",
      "Epoch 12457, Loss: 0.007814769633114338, Neurons: 64, Grad norm: 1.814e+00\n",
      "Epoch 12458, Loss: 0.007773541379719973, Neurons: 64, Grad norm: 1.118e+00\n",
      "Epoch 12458, Loss: 0.007773541379719973, Neurons: 64, Grad norm: 1.118e+00\n",
      "Epoch 12459, Loss: 0.0077420854941010475, Neurons: 64, Grad norm: 4.652e-01\n",
      "Epoch 12459, Loss: 0.0077420854941010475, Neurons: 64, Grad norm: 4.652e-01\n",
      "Epoch 12460, Loss: 0.007725021801888943, Neurons: 64, Grad norm: 3.348e-01\n",
      "Epoch 12460, Loss: 0.007725021801888943, Neurons: 64, Grad norm: 3.348e-01\n",
      "Epoch 12461, Loss: 0.007721930276602507, Neurons: 64, Grad norm: 8.374e-01\n",
      "Epoch 12461, Loss: 0.007721930276602507, Neurons: 64, Grad norm: 8.374e-01\n",
      "Epoch 12462, Loss: 0.00772893289104104, Neurons: 64, Grad norm: 1.288e+00\n",
      "Epoch 12462, Loss: 0.00772893289104104, Neurons: 64, Grad norm: 1.288e+00\n",
      "Epoch 12463, Loss: 0.007740502245724201, Neurons: 64, Grad norm: 1.590e+00\n",
      "Epoch 12463, Loss: 0.007740502245724201, Neurons: 64, Grad norm: 1.590e+00\n",
      "Epoch 12464, Loss: 0.007751540746539831, Neurons: 64, Grad norm: 1.780e+00\n",
      "Epoch 12464, Loss: 0.007751540746539831, Neurons: 64, Grad norm: 1.780e+00\n",
      "Epoch 12465, Loss: 0.007758354768157005, Neurons: 64, Grad norm: 1.815e+00\n",
      "Epoch 12465, Loss: 0.007758354768157005, Neurons: 64, Grad norm: 1.815e+00\n",
      "Epoch 12466, Loss: 0.007759259548038244, Neurons: 64, Grad norm: 1.757e+00\n",
      "Epoch 12466, Loss: 0.007759259548038244, Neurons: 64, Grad norm: 1.757e+00\n",
      "Epoch 12467, Loss: 0.007754241582006216, Neurons: 64, Grad norm: 1.580e+00\n",
      "Epoch 12467, Loss: 0.007754241582006216, Neurons: 64, Grad norm: 1.580e+00\n",
      "Epoch 12468, Loss: 0.007744853384792805, Neurons: 64, Grad norm: 1.349e+00\n",
      "Epoch 12468, Loss: 0.007744853384792805, Neurons: 64, Grad norm: 1.349e+00\n",
      "Epoch 12469, Loss: 0.007733105216175318, Neurons: 64, Grad norm: 1.044e+00\n",
      "Epoch 12469, Loss: 0.007733105216175318, Neurons: 64, Grad norm: 1.044e+00\n",
      "Epoch 12470, Loss: 0.007721148896962404, Neurons: 64, Grad norm: 7.422e-01\n",
      "Epoch 12470, Loss: 0.007721148896962404, Neurons: 64, Grad norm: 7.422e-01\n",
      "Epoch 12471, Loss: 0.007710850331932306, Neurons: 64, Grad norm: 4.229e-01\n",
      "Epoch 12471, Loss: 0.007710850331932306, Neurons: 64, Grad norm: 4.229e-01\n",
      "Epoch 12472, Loss: 0.007703213486820459, Neurons: 64, Grad norm: 2.093e-01\n",
      "Epoch 12472, Loss: 0.007703213486820459, Neurons: 64, Grad norm: 2.093e-01\n",
      "Epoch 12473, Loss: 0.007698535453528166, Neurons: 64, Grad norm: 2.926e-01\n",
      "Epoch 12473, Loss: 0.007698535453528166, Neurons: 64, Grad norm: 2.926e-01\n",
      "Epoch 12474, Loss: 0.007696531713008881, Neurons: 64, Grad norm: 4.903e-01\n",
      "Epoch 12474, Loss: 0.007696531713008881, Neurons: 64, Grad norm: 4.903e-01\n",
      "Epoch 12475, Loss: 0.007696512155234814, Neurons: 64, Grad norm: 6.829e-01\n",
      "Epoch 12475, Loss: 0.007696512155234814, Neurons: 64, Grad norm: 6.829e-01\n",
      "Epoch 12476, Loss: 0.007697456516325474, Neurons: 64, Grad norm: 8.071e-01\n",
      "Epoch 12476, Loss: 0.007697456516325474, Neurons: 64, Grad norm: 8.071e-01\n",
      "Epoch 12477, Loss: 0.007698598317801952, Neurons: 64, Grad norm: 9.049e-01\n",
      "Epoch 12477, Loss: 0.007698598317801952, Neurons: 64, Grad norm: 9.049e-01\n",
      "Epoch 12478, Loss: 0.007699309848248959, Neurons: 64, Grad norm: 9.402e-01\n",
      "Epoch 12478, Loss: 0.007699309848248959, Neurons: 64, Grad norm: 9.402e-01\n",
      "Epoch 12479, Loss: 0.007699166890233755, Neurons: 64, Grad norm: 9.554e-01\n",
      "Epoch 12479, Loss: 0.007699166890233755, Neurons: 64, Grad norm: 9.554e-01\n",
      "Epoch 12480, Loss: 0.007697926834225655, Neurons: 64, Grad norm: 9.068e-01\n",
      "Epoch 12480, Loss: 0.007697926834225655, Neurons: 64, Grad norm: 9.068e-01\n",
      "Epoch 12481, Loss: 0.007695485837757587, Neurons: 64, Grad norm: 8.534e-01\n",
      "Epoch 12481, Loss: 0.007695485837757587, Neurons: 64, Grad norm: 8.534e-01\n",
      "Epoch 12482, Loss: 0.007692134473472834, Neurons: 64, Grad norm: 7.545e-01\n",
      "Epoch 12482, Loss: 0.007692134473472834, Neurons: 64, Grad norm: 7.545e-01\n",
      "Epoch 12483, Loss: 0.007688106037676334, Neurons: 64, Grad norm: 6.626e-01\n",
      "Epoch 12483, Loss: 0.007688106037676334, Neurons: 64, Grad norm: 6.626e-01\n",
      "Epoch 12484, Loss: 0.007683760020881891, Neurons: 64, Grad norm: 5.332e-01\n",
      "Epoch 12484, Loss: 0.007683760020881891, Neurons: 64, Grad norm: 5.332e-01\n",
      "Epoch 12485, Loss: 0.007679434958845377, Neurons: 64, Grad norm: 4.193e-01\n",
      "Epoch 12485, Loss: 0.007679434958845377, Neurons: 64, Grad norm: 4.193e-01\n",
      "Epoch 12486, Loss: 0.0076753366738557816, Neurons: 64, Grad norm: 2.812e-01\n",
      "Epoch 12486, Loss: 0.0076753366738557816, Neurons: 64, Grad norm: 2.812e-01\n",
      "Epoch 12487, Loss: 0.007671811617910862, Neurons: 64, Grad norm: 1.713e-01\n",
      "Epoch 12487, Loss: 0.007671811617910862, Neurons: 64, Grad norm: 1.713e-01\n",
      "Epoch 12488, Loss: 0.007669028360396624, Neurons: 64, Grad norm: 5.016e-02\n",
      "Epoch 12488, Loss: 0.007669028360396624, Neurons: 64, Grad norm: 5.016e-02\n",
      "Epoch 12489, Loss: 0.0076667205430567265, Neurons: 64, Grad norm: 4.534e-02\n",
      "Epoch 12489, Loss: 0.0076667205430567265, Neurons: 64, Grad norm: 4.534e-02\n",
      "Epoch 12490, Loss: 0.007664922624826431, Neurons: 64, Grad norm: 1.474e-01\n",
      "Epoch 12490, Loss: 0.007664922624826431, Neurons: 64, Grad norm: 1.474e-01\n",
      "Epoch 12491, Loss: 0.007663490250706673, Neurons: 64, Grad norm: 2.122e-01\n",
      "Epoch 12491, Loss: 0.007663490250706673, Neurons: 64, Grad norm: 2.122e-01\n",
      "Epoch 12492, Loss: 0.007662225980311632, Neurons: 64, Grad norm: 2.900e-01\n",
      "Epoch 12492, Loss: 0.007662225980311632, Neurons: 64, Grad norm: 2.900e-01\n",
      "Epoch 12493, Loss: 0.007661091163754463, Neurons: 64, Grad norm: 3.335e-01\n",
      "Epoch 12493, Loss: 0.007661091163754463, Neurons: 64, Grad norm: 3.335e-01\n",
      "Epoch 12494, Loss: 0.007659994065761566, Neurons: 64, Grad norm: 3.901e-01\n",
      "Epoch 12494, Loss: 0.007659994065761566, Neurons: 64, Grad norm: 3.901e-01\n",
      "Epoch 12495, Loss: 0.007658833172172308, Neurons: 64, Grad norm: 4.184e-01\n",
      "Epoch 12495, Loss: 0.007658833172172308, Neurons: 64, Grad norm: 4.184e-01\n",
      "Epoch 12496, Loss: 0.007657588459551334, Neurons: 64, Grad norm: 4.590e-01\n",
      "Epoch 12496, Loss: 0.007657588459551334, Neurons: 64, Grad norm: 4.590e-01\n",
      "Epoch 12497, Loss: 0.007656219881027937, Neurons: 64, Grad norm: 4.664e-01\n",
      "Epoch 12497, Loss: 0.007656219881027937, Neurons: 64, Grad norm: 4.664e-01\n",
      "Epoch 12498, Loss: 0.007654738146811724, Neurons: 64, Grad norm: 4.964e-01\n",
      "Epoch 12498, Loss: 0.007654738146811724, Neurons: 64, Grad norm: 4.964e-01\n",
      "Epoch 12499, Loss: 0.007653106469660997, Neurons: 64, Grad norm: 5.000e-01\n",
      "Epoch 12499, Loss: 0.007653106469660997, Neurons: 64, Grad norm: 5.000e-01\n",
      "Epoch 12499, Test loss: 0.005967454984784126\n",
      "Epoch 12499, Test loss: 0.005967454984784126\n",
      "Epoch 12500, Loss: 0.007651417050510645, Neurons: 64, Grad norm: 5.254e-01\n",
      "Epoch 12500, Loss: 0.007651417050510645, Neurons: 64, Grad norm: 5.254e-01\n",
      "Epoch 12501, Loss: 0.007649644743651152, Neurons: 64, Grad norm: 5.247e-01\n",
      "Epoch 12501, Loss: 0.007649644743651152, Neurons: 64, Grad norm: 5.247e-01\n",
      "Epoch 12502, Loss: 0.0076478514820337296, Neurons: 64, Grad norm: 5.471e-01\n",
      "Epoch 12502, Loss: 0.0076478514820337296, Neurons: 64, Grad norm: 5.471e-01\n",
      "Epoch 12503, Loss: 0.007646127603948116, Neurons: 64, Grad norm: 5.502e-01\n",
      "Epoch 12503, Loss: 0.007646127603948116, Neurons: 64, Grad norm: 5.502e-01\n",
      "Epoch 12504, Loss: 0.007644371595233679, Neurons: 64, Grad norm: 5.784e-01\n",
      "Epoch 12504, Loss: 0.007644371595233679, Neurons: 64, Grad norm: 5.784e-01\n",
      "Epoch 12505, Loss: 0.007642799988389015, Neurons: 64, Grad norm: 5.848e-01\n",
      "Epoch 12505, Loss: 0.007642799988389015, Neurons: 64, Grad norm: 5.848e-01\n",
      "Epoch 12506, Loss: 0.007641243748366833, Neurons: 64, Grad norm: 6.178e-01\n",
      "Epoch 12506, Loss: 0.007641243748366833, Neurons: 64, Grad norm: 6.178e-01\n",
      "Epoch 12507, Loss: 0.007639741059392691, Neurons: 64, Grad norm: 6.313e-01\n",
      "Epoch 12507, Loss: 0.007639741059392691, Neurons: 64, Grad norm: 6.313e-01\n",
      "Epoch 12508, Loss: 0.007638370152562857, Neurons: 64, Grad norm: 6.694e-01\n",
      "Epoch 12508, Loss: 0.007638370152562857, Neurons: 64, Grad norm: 6.694e-01\n",
      "Epoch 12509, Loss: 0.007637163158506155, Neurons: 64, Grad norm: 6.921e-01\n",
      "Epoch 12509, Loss: 0.007637163158506155, Neurons: 64, Grad norm: 6.921e-01\n",
      "Epoch 12510, Loss: 0.007635990623384714, Neurons: 64, Grad norm: 7.426e-01\n",
      "Epoch 12510, Loss: 0.007635990623384714, Neurons: 64, Grad norm: 7.426e-01\n",
      "Epoch 12511, Loss: 0.0076350197196006775, Neurons: 64, Grad norm: 7.781e-01\n",
      "Epoch 12511, Loss: 0.0076350197196006775, Neurons: 64, Grad norm: 7.781e-01\n",
      "Epoch 12512, Loss: 0.007634281646460295, Neurons: 64, Grad norm: 8.439e-01\n",
      "Epoch 12512, Loss: 0.007634281646460295, Neurons: 64, Grad norm: 8.439e-01\n",
      "Epoch 12513, Loss: 0.007633865345269442, Neurons: 64, Grad norm: 8.966e-01\n",
      "Epoch 12513, Loss: 0.007633865345269442, Neurons: 64, Grad norm: 8.966e-01\n",
      "Epoch 12514, Loss: 0.007633797358721495, Neurons: 64, Grad norm: 9.885e-01\n",
      "Epoch 12514, Loss: 0.007633797358721495, Neurons: 64, Grad norm: 9.885e-01\n",
      "Epoch 12515, Loss: 0.007634243927896023, Neurons: 64, Grad norm: 1.072e+00\n",
      "Epoch 12515, Loss: 0.007634243927896023, Neurons: 64, Grad norm: 1.072e+00\n",
      "Epoch 12516, Loss: 0.007635355461388826, Neurons: 64, Grad norm: 1.190e+00\n",
      "Epoch 12516, Loss: 0.007635355461388826, Neurons: 64, Grad norm: 1.190e+00\n",
      "Epoch 12517, Loss: 0.007637359667569399, Neurons: 64, Grad norm: 1.310e+00\n",
      "Epoch 12517, Loss: 0.007637359667569399, Neurons: 64, Grad norm: 1.310e+00\n",
      "Epoch 12518, Loss: 0.00764051266014576, Neurons: 64, Grad norm: 1.475e+00\n",
      "Epoch 12518, Loss: 0.00764051266014576, Neurons: 64, Grad norm: 1.475e+00\n",
      "Epoch 12519, Loss: 0.0076452395878732204, Neurons: 64, Grad norm: 1.641e+00\n",
      "Epoch 12519, Loss: 0.0076452395878732204, Neurons: 64, Grad norm: 1.641e+00\n",
      "Epoch 12520, Loss: 0.007652018219232559, Neurons: 64, Grad norm: 1.862e+00\n",
      "Epoch 12520, Loss: 0.007652018219232559, Neurons: 64, Grad norm: 1.862e+00\n",
      "Epoch 12521, Loss: 0.007661596871912479, Neurons: 64, Grad norm: 2.096e+00\n",
      "Epoch 12521, Loss: 0.007661596871912479, Neurons: 64, Grad norm: 2.096e+00\n",
      "Epoch 12522, Loss: 0.007674780674278736, Neurons: 64, Grad norm: 2.394e+00\n",
      "Epoch 12522, Loss: 0.007674780674278736, Neurons: 64, Grad norm: 2.394e+00\n",
      "Epoch 12523, Loss: 0.007692831102758646, Neurons: 64, Grad norm: 2.713e+00\n",
      "Epoch 12523, Loss: 0.007692831102758646, Neurons: 64, Grad norm: 2.713e+00\n",
      "Epoch 12524, Loss: 0.007717371918261051, Neurons: 64, Grad norm: 3.106e+00\n",
      "Epoch 12524, Loss: 0.007717371918261051, Neurons: 64, Grad norm: 3.106e+00\n",
      "Epoch 12525, Loss: 0.007750194054096937, Neurons: 64, Grad norm: 3.533e+00\n",
      "Epoch 12525, Loss: 0.007750194054096937, Neurons: 64, Grad norm: 3.533e+00\n",
      "Epoch 12526, Loss: 0.007793716620653868, Neurons: 64, Grad norm: 4.033e+00\n",
      "Epoch 12526, Loss: 0.007793716620653868, Neurons: 64, Grad norm: 4.033e+00\n",
      "Epoch 12527, Loss: 0.0078498600050807, Neurons: 64, Grad norm: 4.558e+00\n",
      "Epoch 12527, Loss: 0.0078498600050807, Neurons: 64, Grad norm: 4.558e+00\n",
      "Epoch 12528, Loss: 0.007920519448816776, Neurons: 64, Grad norm: 5.141e+00\n",
      "Epoch 12528, Loss: 0.007920519448816776, Neurons: 64, Grad norm: 5.141e+00\n",
      "Epoch 12529, Loss: 0.008005769923329353, Neurons: 64, Grad norm: 5.709e+00\n",
      "Epoch 12529, Loss: 0.008005769923329353, Neurons: 64, Grad norm: 5.709e+00\n",
      "Epoch 12530, Loss: 0.008103079162538052, Neurons: 64, Grad norm: 6.262e+00\n",
      "Epoch 12530, Loss: 0.008103079162538052, Neurons: 64, Grad norm: 6.262e+00\n",
      "Epoch 12531, Loss: 0.008203433826565742, Neurons: 64, Grad norm: 6.688e+00\n",
      "Epoch 12531, Loss: 0.008203433826565742, Neurons: 64, Grad norm: 6.688e+00\n",
      "Epoch 12532, Loss: 0.00829219352453947, Neurons: 64, Grad norm: 6.952e+00\n",
      "Epoch 12532, Loss: 0.00829219352453947, Neurons: 64, Grad norm: 6.952e+00\n",
      "Epoch 12533, Loss: 0.008346602320671082, Neurons: 64, Grad norm: 6.930e+00\n",
      "Epoch 12533, Loss: 0.008346602320671082, Neurons: 64, Grad norm: 6.930e+00\n",
      "Epoch 12534, Loss: 0.008344313129782677, Neurons: 64, Grad norm: 6.586e+00\n",
      "Epoch 12534, Loss: 0.008344313129782677, Neurons: 64, Grad norm: 6.586e+00\n",
      "Epoch 12535, Loss: 0.008268097415566444, Neurons: 64, Grad norm: 5.826e+00\n",
      "Epoch 12535, Loss: 0.008268097415566444, Neurons: 64, Grad norm: 5.826e+00\n",
      "Epoch 12536, Loss: 0.008122656494379044, Neurons: 64, Grad norm: 4.721e+00\n",
      "Epoch 12536, Loss: 0.008122656494379044, Neurons: 64, Grad norm: 4.721e+00\n",
      "Epoch 12537, Loss: 0.00793663039803505, Neurons: 64, Grad norm: 3.317e+00\n",
      "Epoch 12537, Loss: 0.00793663039803505, Neurons: 64, Grad norm: 3.317e+00\n",
      "Epoch 12538, Loss: 0.007757703773677349, Neurons: 64, Grad norm: 1.786e+00\n",
      "Epoch 12538, Loss: 0.007757703773677349, Neurons: 64, Grad norm: 1.786e+00\n",
      "Epoch 12539, Loss: 0.007630194071680307, Neurons: 64, Grad norm: 2.668e-01\n",
      "Epoch 12539, Loss: 0.007630194071680307, Neurons: 64, Grad norm: 2.668e-01\n",
      "Epoch 12540, Loss: 0.007577488664537668, Neurons: 64, Grad norm: 1.197e+00\n",
      "Epoch 12540, Loss: 0.007577488664537668, Neurons: 64, Grad norm: 1.197e+00\n",
      "Epoch 12541, Loss: 0.007595133502036333, Neurons: 64, Grad norm: 2.376e+00\n",
      "Epoch 12541, Loss: 0.007595133502036333, Neurons: 64, Grad norm: 2.376e+00\n",
      "Epoch 12542, Loss: 0.00765734538435936, Neurons: 64, Grad norm: 3.220e+00\n",
      "Epoch 12542, Loss: 0.00765734538435936, Neurons: 64, Grad norm: 3.220e+00\n",
      "Epoch 12543, Loss: 0.0077301631681621075, Neurons: 64, Grad norm: 3.729e+00\n",
      "Epoch 12543, Loss: 0.0077301631681621075, Neurons: 64, Grad norm: 3.729e+00\n",
      "Epoch 12544, Loss: 0.0077825612388551235, Neurons: 64, Grad norm: 3.838e+00\n",
      "Epoch 12544, Loss: 0.0077825612388551235, Neurons: 64, Grad norm: 3.838e+00\n",
      "Epoch 12545, Loss: 0.007796083111315966, Neurons: 64, Grad norm: 3.613e+00\n",
      "Epoch 12545, Loss: 0.007796083111315966, Neurons: 64, Grad norm: 3.613e+00\n",
      "Epoch 12546, Loss: 0.007767532020807266, Neurons: 64, Grad norm: 3.057e+00\n",
      "Epoch 12546, Loss: 0.007767532020807266, Neurons: 64, Grad norm: 3.057e+00\n",
      "Epoch 12547, Loss: 0.007709309924393892, Neurons: 64, Grad norm: 2.284e+00\n",
      "Epoch 12547, Loss: 0.007709309924393892, Neurons: 64, Grad norm: 2.284e+00\n",
      "Epoch 12548, Loss: 0.007642460986971855, Neurons: 64, Grad norm: 1.346e+00\n",
      "Epoch 12548, Loss: 0.007642460986971855, Neurons: 64, Grad norm: 1.346e+00\n",
      "Epoch 12549, Loss: 0.007588234264403582, Neurons: 64, Grad norm: 4.002e-01\n",
      "Epoch 12549, Loss: 0.007588234264403582, Neurons: 64, Grad norm: 4.002e-01\n",
      "Epoch 12550, Loss: 0.007560045458376408, Neurons: 64, Grad norm: 5.252e-01\n",
      "Epoch 12550, Loss: 0.007560045458376408, Neurons: 64, Grad norm: 5.252e-01\n",
      "Epoch 12551, Loss: 0.007559625431895256, Neurons: 64, Grad norm: 1.279e+00\n",
      "Epoch 12551, Loss: 0.007559625431895256, Neurons: 64, Grad norm: 1.279e+00\n",
      "Epoch 12552, Loss: 0.007578869815915823, Neurons: 64, Grad norm: 1.869e+00\n",
      "Epoch 12552, Loss: 0.007578869815915823, Neurons: 64, Grad norm: 1.869e+00\n",
      "Epoch 12553, Loss: 0.00760489609092474, Neurons: 64, Grad norm: 2.213e+00\n",
      "Epoch 12553, Loss: 0.00760489609092474, Neurons: 64, Grad norm: 2.213e+00\n",
      "Epoch 12554, Loss: 0.007625453174114227, Neurons: 64, Grad norm: 2.348e+00\n",
      "Epoch 12554, Loss: 0.007625453174114227, Neurons: 64, Grad norm: 2.348e+00\n",
      "Epoch 12555, Loss: 0.007632517255842686, Neurons: 64, Grad norm: 2.245e+00\n",
      "Epoch 12555, Loss: 0.007632517255842686, Neurons: 64, Grad norm: 2.245e+00\n",
      "Epoch 12556, Loss: 0.007624246180057526, Neurons: 64, Grad norm: 1.976e+00\n",
      "Epoch 12556, Loss: 0.007624246180057526, Neurons: 64, Grad norm: 1.976e+00\n",
      "Epoch 12557, Loss: 0.007604333106428385, Neurons: 64, Grad norm: 1.541e+00\n",
      "Epoch 12557, Loss: 0.007604333106428385, Neurons: 64, Grad norm: 1.541e+00\n",
      "Epoch 12558, Loss: 0.007579714525490999, Neurons: 64, Grad norm: 1.040e+00\n",
      "Epoch 12558, Loss: 0.007579714525490999, Neurons: 64, Grad norm: 1.040e+00\n",
      "Epoch 12559, Loss: 0.007557617034763098, Neurons: 64, Grad norm: 4.787e-01\n",
      "Epoch 12559, Loss: 0.007557617034763098, Neurons: 64, Grad norm: 4.787e-01\n",
      "Epoch 12560, Loss: 0.007543215062469244, Neurons: 64, Grad norm: 7.041e-02\n",
      "Epoch 12560, Loss: 0.007543215062469244, Neurons: 64, Grad norm: 7.041e-02\n",
      "Epoch 12561, Loss: 0.007538096513599157, Neurons: 64, Grad norm: 5.384e-01\n",
      "Epoch 12561, Loss: 0.007538096513599157, Neurons: 64, Grad norm: 5.384e-01\n",
      "Epoch 12562, Loss: 0.007540709804743528, Neurons: 64, Grad norm: 9.096e-01\n",
      "Epoch 12562, Loss: 0.007540709804743528, Neurons: 64, Grad norm: 9.096e-01\n",
      "Epoch 12563, Loss: 0.007547627668827772, Neurons: 64, Grad norm: 1.194e+00\n",
      "Epoch 12563, Loss: 0.007547627668827772, Neurons: 64, Grad norm: 1.194e+00\n",
      "Epoch 12564, Loss: 0.007554801646620035, Neurons: 64, Grad norm: 1.337e+00\n",
      "Epoch 12564, Loss: 0.007554801646620035, Neurons: 64, Grad norm: 1.337e+00\n",
      "Epoch 12565, Loss: 0.007559118326753378, Neurons: 64, Grad norm: 1.387e+00\n",
      "Epoch 12565, Loss: 0.007559118326753378, Neurons: 64, Grad norm: 1.387e+00\n",
      "Epoch 12566, Loss: 0.007559071760624647, Neurons: 64, Grad norm: 1.303e+00\n",
      "Epoch 12566, Loss: 0.007559071760624647, Neurons: 64, Grad norm: 1.303e+00\n",
      "Epoch 12567, Loss: 0.0075544798746705055, Neurons: 64, Grad norm: 1.157e+00\n",
      "Epoch 12567, Loss: 0.0075544798746705055, Neurons: 64, Grad norm: 1.157e+00\n",
      "Epoch 12568, Loss: 0.007546679116785526, Neurons: 64, Grad norm: 9.222e-01\n",
      "Epoch 12568, Loss: 0.007546679116785526, Neurons: 64, Grad norm: 9.222e-01\n",
      "Epoch 12569, Loss: 0.00753760663792491, Neurons: 64, Grad norm: 6.653e-01\n",
      "Epoch 12569, Loss: 0.00753760663792491, Neurons: 64, Grad norm: 6.653e-01\n",
      "Epoch 12570, Loss: 0.007529194466769695, Neurons: 64, Grad norm: 3.680e-01\n",
      "Epoch 12570, Loss: 0.007529194466769695, Neurons: 64, Grad norm: 3.680e-01\n",
      "Epoch 12571, Loss: 0.0075227078050374985, Neurons: 64, Grad norm: 1.064e-01\n",
      "Epoch 12571, Loss: 0.0075227078050374985, Neurons: 64, Grad norm: 1.064e-01\n",
      "Epoch 12572, Loss: 0.0075188432820141315, Neurons: 64, Grad norm: 1.950e-01\n",
      "Epoch 12572, Loss: 0.0075188432820141315, Neurons: 64, Grad norm: 1.950e-01\n",
      "Epoch 12573, Loss: 0.007517397403717041, Neurons: 64, Grad norm: 4.041e-01\n",
      "Epoch 12573, Loss: 0.007517397403717041, Neurons: 64, Grad norm: 4.041e-01\n",
      "Epoch 12574, Loss: 0.007517602294683456, Neurons: 64, Grad norm: 5.948e-01\n",
      "Epoch 12574, Loss: 0.007517602294683456, Neurons: 64, Grad norm: 5.948e-01\n",
      "Epoch 12575, Loss: 0.007518559694290161, Neurons: 64, Grad norm: 7.117e-01\n",
      "Epoch 12575, Loss: 0.007518559694290161, Neurons: 64, Grad norm: 7.117e-01\n",
      "Epoch 12576, Loss: 0.007519358769059181, Neurons: 64, Grad norm: 7.957e-01\n",
      "Epoch 12576, Loss: 0.007519358769059181, Neurons: 64, Grad norm: 7.957e-01\n",
      "Epoch 12577, Loss: 0.007519282400608063, Neurons: 64, Grad norm: 8.110e-01\n",
      "Epoch 12577, Loss: 0.007519282400608063, Neurons: 64, Grad norm: 8.110e-01\n",
      "Epoch 12578, Loss: 0.007518134079873562, Neurons: 64, Grad norm: 8.007e-01\n",
      "Epoch 12578, Loss: 0.007518134079873562, Neurons: 64, Grad norm: 8.007e-01\n",
      "Epoch 12579, Loss: 0.007515969220548868, Neurons: 64, Grad norm: 7.318e-01\n",
      "Epoch 12579, Loss: 0.007515969220548868, Neurons: 64, Grad norm: 7.318e-01\n",
      "Epoch 12580, Loss: 0.007512902840971947, Neurons: 64, Grad norm: 6.594e-01\n",
      "Epoch 12580, Loss: 0.007512902840971947, Neurons: 64, Grad norm: 6.594e-01\n",
      "Epoch 12581, Loss: 0.007509416900575161, Neurons: 64, Grad norm: 5.432e-01\n",
      "Epoch 12581, Loss: 0.007509416900575161, Neurons: 64, Grad norm: 5.432e-01\n",
      "Epoch 12582, Loss: 0.007505873218178749, Neurons: 64, Grad norm: 4.410e-01\n",
      "Epoch 12582, Loss: 0.007505873218178749, Neurons: 64, Grad norm: 4.410e-01\n",
      "Epoch 12583, Loss: 0.007502654101699591, Neurons: 64, Grad norm: 3.219e-01\n",
      "Epoch 12583, Loss: 0.007502654101699591, Neurons: 64, Grad norm: 3.219e-01\n",
      "Epoch 12584, Loss: 0.007499870844185352, Neurons: 64, Grad norm: 2.344e-01\n",
      "Epoch 12584, Loss: 0.007499870844185352, Neurons: 64, Grad norm: 2.344e-01\n",
      "Epoch 12585, Loss: 0.007497709710150957, Neurons: 64, Grad norm: 1.873e-01\n",
      "Epoch 12585, Loss: 0.007497709710150957, Neurons: 64, Grad norm: 1.873e-01\n",
      "Epoch 12586, Loss: 0.007496132981032133, Neurons: 64, Grad norm: 2.053e-01\n",
      "Epoch 12586, Loss: 0.007496132981032133, Neurons: 64, Grad norm: 2.053e-01\n",
      "Epoch 12587, Loss: 0.007495046127587557, Neurons: 64, Grad norm: 2.728e-01\n",
      "Epoch 12587, Loss: 0.007495046127587557, Neurons: 64, Grad norm: 2.728e-01\n",
      "Epoch 12588, Loss: 0.007494654040783644, Neurons: 64, Grad norm: 3.323e-01\n",
      "Epoch 12588, Loss: 0.007494654040783644, Neurons: 64, Grad norm: 3.323e-01\n",
      "Epoch 12589, Loss: 0.007494647987186909, Neurons: 64, Grad norm: 4.076e-01\n",
      "Epoch 12589, Loss: 0.007494647987186909, Neurons: 64, Grad norm: 4.076e-01\n",
      "Epoch 12590, Loss: 0.007495408412069082, Neurons: 64, Grad norm: 4.596e-01\n",
      "Epoch 12590, Loss: 0.007495408412069082, Neurons: 64, Grad norm: 4.596e-01\n",
      "Epoch 12591, Loss: 0.007496586535125971, Neurons: 64, Grad norm: 5.251e-01\n",
      "Epoch 12591, Loss: 0.007496586535125971, Neurons: 64, Grad norm: 5.251e-01\n",
      "Epoch 12592, Loss: 0.00749838026240468, Neurons: 64, Grad norm: 5.735e-01\n",
      "Epoch 12592, Loss: 0.00749838026240468, Neurons: 64, Grad norm: 5.735e-01\n",
      "Epoch 12593, Loss: 0.0075009604915976524, Neurons: 64, Grad norm: 6.421e-01\n",
      "Epoch 12593, Loss: 0.0075009604915976524, Neurons: 64, Grad norm: 6.421e-01\n",
      "Epoch 12594, Loss: 0.007504692301154137, Neurons: 64, Grad norm: 7.049e-01\n",
      "Epoch 12594, Loss: 0.007504692301154137, Neurons: 64, Grad norm: 7.049e-01\n",
      "Epoch 12595, Loss: 0.007509979419410229, Neurons: 64, Grad norm: 7.966e-01\n",
      "Epoch 12595, Loss: 0.007509979419410229, Neurons: 64, Grad norm: 7.966e-01\n",
      "Epoch 12596, Loss: 0.007518014870584011, Neurons: 64, Grad norm: 8.959e-01\n",
      "Epoch 12596, Loss: 0.007518014870584011, Neurons: 64, Grad norm: 8.959e-01\n",
      "Epoch 12597, Loss: 0.007528941612690687, Neurons: 64, Grad norm: 1.029e+00\n",
      "Epoch 12597, Loss: 0.007528941612690687, Neurons: 64, Grad norm: 1.029e+00\n",
      "Epoch 12598, Loss: 0.007544724736362696, Neurons: 64, Grad norm: 1.177e+00\n",
      "Epoch 12598, Loss: 0.007544724736362696, Neurons: 64, Grad norm: 1.177e+00\n",
      "Epoch 12599, Loss: 0.0075652408413589, Neurons: 64, Grad norm: 1.353e+00\n",
      "Epoch 12599, Loss: 0.0075652408413589, Neurons: 64, Grad norm: 1.353e+00\n",
      "Epoch 12599, Test loss: 0.0059467218816280365\n",
      "Epoch 12599, Test loss: 0.0059467218816280365\n",
      "Epoch 12600, Loss: 0.007592291571199894, Neurons: 64, Grad norm: 1.540e+00\n",
      "Epoch 12600, Loss: 0.007592291571199894, Neurons: 64, Grad norm: 1.540e+00\n",
      "Epoch 12601, Loss: 0.007624499499797821, Neurons: 64, Grad norm: 1.736e+00\n",
      "Epoch 12601, Loss: 0.007624499499797821, Neurons: 64, Grad norm: 1.736e+00\n",
      "Epoch 12602, Loss: 0.007661639712750912, Neurons: 64, Grad norm: 1.920e+00\n",
      "Epoch 12602, Loss: 0.007661639712750912, Neurons: 64, Grad norm: 1.920e+00\n",
      "Epoch 12603, Loss: 0.007698128931224346, Neurons: 64, Grad norm: 2.073e+00\n",
      "Epoch 12603, Loss: 0.007698128931224346, Neurons: 64, Grad norm: 2.073e+00\n",
      "Epoch 12604, Loss: 0.007728717289865017, Neurons: 64, Grad norm: 2.172e+00\n",
      "Epoch 12604, Loss: 0.007728717289865017, Neurons: 64, Grad norm: 2.172e+00\n",
      "Epoch 12605, Loss: 0.007742336485534906, Neurons: 64, Grad norm: 2.190e+00\n",
      "Epoch 12605, Loss: 0.007742336485534906, Neurons: 64, Grad norm: 2.190e+00\n",
      "Epoch 12606, Loss: 0.007732474710792303, Neurons: 64, Grad norm: 2.117e+00\n",
      "Epoch 12606, Loss: 0.007732474710792303, Neurons: 64, Grad norm: 2.117e+00\n",
      "Epoch 12607, Loss: 0.00769365020096302, Neurons: 64, Grad norm: 1.950e+00\n",
      "Epoch 12607, Loss: 0.00769365020096302, Neurons: 64, Grad norm: 1.950e+00\n",
      "Epoch 12608, Loss: 0.007632476277649403, Neurons: 64, Grad norm: 1.739e+00\n",
      "Epoch 12608, Loss: 0.007632476277649403, Neurons: 64, Grad norm: 1.739e+00\n",
      "Epoch 12609, Loss: 0.007565333042293787, Neurons: 64, Grad norm: 1.533e+00\n",
      "Epoch 12609, Loss: 0.007565333042293787, Neurons: 64, Grad norm: 1.533e+00\n",
      "Epoch 12610, Loss: 0.0075114113278687, Neurons: 64, Grad norm: 1.435e+00\n",
      "Epoch 12610, Loss: 0.0075114113278687, Neurons: 64, Grad norm: 1.435e+00\n",
      "Epoch 12611, Loss: 0.00748374592512846, Neurons: 64, Grad norm: 1.439e+00\n",
      "Epoch 12611, Loss: 0.00748374592512846, Neurons: 64, Grad norm: 1.439e+00\n",
      "Epoch 12612, Loss: 0.007484193425625563, Neurons: 64, Grad norm: 1.548e+00\n",
      "Epoch 12612, Loss: 0.007484193425625563, Neurons: 64, Grad norm: 1.548e+00\n",
      "Epoch 12613, Loss: 0.0075044212862849236, Neurons: 64, Grad norm: 1.645e+00\n",
      "Epoch 12613, Loss: 0.0075044212862849236, Neurons: 64, Grad norm: 1.645e+00\n",
      "Epoch 12614, Loss: 0.007530622649937868, Neurons: 64, Grad norm: 1.719e+00\n",
      "Epoch 12614, Loss: 0.007530622649937868, Neurons: 64, Grad norm: 1.719e+00\n",
      "Epoch 12615, Loss: 0.007549392990767956, Neurons: 64, Grad norm: 1.695e+00\n",
      "Epoch 12615, Loss: 0.007549392990767956, Neurons: 64, Grad norm: 1.695e+00\n",
      "Epoch 12616, Loss: 0.007552135735750198, Neurons: 64, Grad norm: 1.610e+00\n",
      "Epoch 12616, Loss: 0.007552135735750198, Neurons: 64, Grad norm: 1.610e+00\n",
      "Epoch 12617, Loss: 0.007537208031862974, Neurons: 64, Grad norm: 1.433e+00\n",
      "Epoch 12617, Loss: 0.007537208031862974, Neurons: 64, Grad norm: 1.433e+00\n",
      "Epoch 12618, Loss: 0.0075102257542312145, Neurons: 64, Grad norm: 1.239e+00\n",
      "Epoch 12618, Loss: 0.0075102257542312145, Neurons: 64, Grad norm: 1.239e+00\n",
      "Epoch 12619, Loss: 0.007480474654585123, Neurons: 64, Grad norm: 1.032e+00\n",
      "Epoch 12619, Loss: 0.007480474654585123, Neurons: 64, Grad norm: 1.032e+00\n",
      "Epoch 12620, Loss: 0.007457477040588856, Neurons: 64, Grad norm: 9.097e-01\n",
      "Epoch 12620, Loss: 0.007457477040588856, Neurons: 64, Grad norm: 9.097e-01\n",
      "Epoch 12621, Loss: 0.007446311414241791, Neurons: 64, Grad norm: 8.582e-01\n",
      "Epoch 12621, Loss: 0.007446311414241791, Neurons: 64, Grad norm: 8.582e-01\n",
      "Epoch 12622, Loss: 0.007446794304996729, Neurons: 64, Grad norm: 8.958e-01\n",
      "Epoch 12622, Loss: 0.007446794304996729, Neurons: 64, Grad norm: 8.958e-01\n",
      "Epoch 12623, Loss: 0.00745426444336772, Neurons: 64, Grad norm: 9.342e-01\n",
      "Epoch 12623, Loss: 0.00745426444336772, Neurons: 64, Grad norm: 9.342e-01\n",
      "Epoch 12624, Loss: 0.007462702225893736, Neurons: 64, Grad norm: 9.566e-01\n",
      "Epoch 12624, Loss: 0.007462702225893736, Neurons: 64, Grad norm: 9.566e-01\n",
      "Epoch 12625, Loss: 0.007466838229447603, Neurons: 64, Grad norm: 9.245e-01\n",
      "Epoch 12625, Loss: 0.007466838229447603, Neurons: 64, Grad norm: 9.245e-01\n",
      "Epoch 12626, Loss: 0.007464242167770863, Neurons: 64, Grad norm: 8.554e-01\n",
      "Epoch 12626, Loss: 0.007464242167770863, Neurons: 64, Grad norm: 8.554e-01\n",
      "Epoch 12627, Loss: 0.007455505896359682, Neurons: 64, Grad norm: 7.438e-01\n",
      "Epoch 12627, Loss: 0.007455505896359682, Neurons: 64, Grad norm: 7.438e-01\n",
      "Epoch 12628, Loss: 0.007443675771355629, Neurons: 64, Grad norm: 6.380e-01\n",
      "Epoch 12628, Loss: 0.007443675771355629, Neurons: 64, Grad norm: 6.380e-01\n",
      "Epoch 12629, Loss: 0.007432392332702875, Neurons: 64, Grad norm: 5.482e-01\n",
      "Epoch 12629, Loss: 0.007432392332702875, Neurons: 64, Grad norm: 5.482e-01\n",
      "Epoch 12630, Loss: 0.00742453383281827, Neurons: 64, Grad norm: 5.358e-01\n",
      "Epoch 12630, Loss: 0.00742453383281827, Neurons: 64, Grad norm: 5.358e-01\n",
      "Epoch 12631, Loss: 0.00742129934951663, Neurons: 64, Grad norm: 5.600e-01\n",
      "Epoch 12631, Loss: 0.00742129934951663, Neurons: 64, Grad norm: 5.600e-01\n",
      "Epoch 12632, Loss: 0.007421898655593395, Neurons: 64, Grad norm: 6.357e-01\n",
      "Epoch 12632, Loss: 0.007421898655593395, Neurons: 64, Grad norm: 6.357e-01\n",
      "Epoch 12633, Loss: 0.007424653507769108, Neurons: 64, Grad norm: 6.872e-01\n",
      "Epoch 12633, Loss: 0.007424653507769108, Neurons: 64, Grad norm: 6.872e-01\n",
      "Epoch 12634, Loss: 0.007427282631397247, Neurons: 64, Grad norm: 7.429e-01\n",
      "Epoch 12634, Loss: 0.007427282631397247, Neurons: 64, Grad norm: 7.429e-01\n",
      "Epoch 12635, Loss: 0.00742826284840703, Neurons: 64, Grad norm: 7.560e-01\n",
      "Epoch 12635, Loss: 0.00742826284840703, Neurons: 64, Grad norm: 7.560e-01\n",
      "Epoch 12636, Loss: 0.00742692407220602, Neurons: 64, Grad norm: 7.815e-01\n",
      "Epoch 12636, Loss: 0.00742692407220602, Neurons: 64, Grad norm: 7.815e-01\n",
      "Epoch 12637, Loss: 0.007423681672662497, Neurons: 64, Grad norm: 7.860e-01\n",
      "Epoch 12637, Loss: 0.007423681672662497, Neurons: 64, Grad norm: 7.860e-01\n",
      "Epoch 12638, Loss: 0.007419706787914038, Neurons: 64, Grad norm: 8.279e-01\n",
      "Epoch 12638, Loss: 0.007419706787914038, Neurons: 64, Grad norm: 8.279e-01\n",
      "Epoch 12639, Loss: 0.007416189648211002, Neurons: 64, Grad norm: 8.729e-01\n",
      "Epoch 12639, Loss: 0.007416189648211002, Neurons: 64, Grad norm: 8.729e-01\n",
      "Epoch 12640, Loss: 0.00741417333483696, Neurons: 64, Grad norm: 9.732e-01\n",
      "Epoch 12640, Loss: 0.00741417333483696, Neurons: 64, Grad norm: 9.732e-01\n",
      "Epoch 12641, Loss: 0.007414362393319607, Neurons: 64, Grad norm: 1.081e+00\n",
      "Epoch 12641, Loss: 0.007414362393319607, Neurons: 64, Grad norm: 1.081e+00\n",
      "Epoch 12642, Loss: 0.007416778709739447, Neurons: 64, Grad norm: 1.237e+00\n",
      "Epoch 12642, Loss: 0.007416778709739447, Neurons: 64, Grad norm: 1.237e+00\n",
      "Epoch 12643, Loss: 0.007421323098242283, Neurons: 64, Grad norm: 1.399e+00\n",
      "Epoch 12643, Loss: 0.007421323098242283, Neurons: 64, Grad norm: 1.399e+00\n",
      "Epoch 12644, Loss: 0.007427709177136421, Neurons: 64, Grad norm: 1.610e+00\n",
      "Epoch 12644, Loss: 0.007427709177136421, Neurons: 64, Grad norm: 1.610e+00\n",
      "Epoch 12645, Loss: 0.007436222396790981, Neurons: 64, Grad norm: 1.837e+00\n",
      "Epoch 12645, Loss: 0.007436222396790981, Neurons: 64, Grad norm: 1.837e+00\n",
      "Epoch 12646, Loss: 0.00744730606675148, Neurons: 64, Grad norm: 2.126e+00\n",
      "Epoch 12646, Loss: 0.00744730606675148, Neurons: 64, Grad norm: 2.126e+00\n",
      "Epoch 12647, Loss: 0.007462207227945328, Neurons: 64, Grad norm: 2.442e+00\n",
      "Epoch 12647, Loss: 0.007462207227945328, Neurons: 64, Grad norm: 2.442e+00\n",
      "Epoch 12648, Loss: 0.007482522167265415, Neurons: 64, Grad norm: 2.836e+00\n",
      "Epoch 12648, Loss: 0.007482522167265415, Neurons: 64, Grad norm: 2.836e+00\n",
      "Epoch 12649, Loss: 0.007510617841035128, Neurons: 64, Grad norm: 3.276e+00\n",
      "Epoch 12649, Loss: 0.007510617841035128, Neurons: 64, Grad norm: 3.276e+00\n",
      "Epoch 12650, Loss: 0.0075501371175050735, Neurons: 64, Grad norm: 3.809e+00\n",
      "Epoch 12650, Loss: 0.0075501371175050735, Neurons: 64, Grad norm: 3.809e+00\n",
      "Epoch 12651, Loss: 0.007603649515658617, Neurons: 64, Grad norm: 4.389e+00\n",
      "Epoch 12651, Loss: 0.007603649515658617, Neurons: 64, Grad norm: 4.389e+00\n",
      "Epoch 12652, Loss: 0.007675547152757645, Neurons: 64, Grad norm: 5.053e+00\n",
      "Epoch 12652, Loss: 0.007675547152757645, Neurons: 64, Grad norm: 5.053e+00\n",
      "Epoch 12653, Loss: 0.007767656352370977, Neurons: 64, Grad norm: 5.739e+00\n",
      "Epoch 12653, Loss: 0.007767656352370977, Neurons: 64, Grad norm: 5.739e+00\n",
      "Epoch 12654, Loss: 0.007880814373493195, Neurons: 64, Grad norm: 6.447e+00\n",
      "Epoch 12654, Loss: 0.007880814373493195, Neurons: 64, Grad norm: 6.447e+00\n",
      "Epoch 12655, Loss: 0.008008414879441261, Neurons: 64, Grad norm: 7.065e+00\n",
      "Epoch 12655, Loss: 0.008008414879441261, Neurons: 64, Grad norm: 7.065e+00\n",
      "Epoch 12656, Loss: 0.008137024939060211, Neurons: 64, Grad norm: 7.537e+00\n",
      "Epoch 12656, Loss: 0.008137024939060211, Neurons: 64, Grad norm: 7.537e+00\n",
      "Epoch 12657, Loss: 0.008239032700657845, Neurons: 64, Grad norm: 7.712e+00\n",
      "Epoch 12657, Loss: 0.008239032700657845, Neurons: 64, Grad norm: 7.712e+00\n",
      "Epoch 12658, Loss: 0.008281954564154148, Neurons: 64, Grad norm: 7.512e+00\n",
      "Epoch 12658, Loss: 0.008281954564154148, Neurons: 64, Grad norm: 7.512e+00\n",
      "Epoch 12659, Loss: 0.00823129341006279, Neurons: 64, Grad norm: 6.808e+00\n",
      "Epoch 12659, Loss: 0.00823129341006279, Neurons: 64, Grad norm: 6.808e+00\n",
      "Epoch 12660, Loss: 0.008079287596046925, Neurons: 64, Grad norm: 5.632e+00\n",
      "Epoch 12660, Loss: 0.008079287596046925, Neurons: 64, Grad norm: 5.632e+00\n",
      "Epoch 12661, Loss: 0.007852490060031414, Neurons: 64, Grad norm: 4.030e+00\n",
      "Epoch 12661, Loss: 0.007852490060031414, Neurons: 64, Grad norm: 4.030e+00\n",
      "Epoch 12662, Loss: 0.007615968119353056, Neurons: 64, Grad norm: 2.213e+00\n",
      "Epoch 12662, Loss: 0.007615968119353056, Neurons: 64, Grad norm: 2.213e+00\n",
      "Epoch 12663, Loss: 0.007439291104674339, Neurons: 64, Grad norm: 3.504e-01\n",
      "Epoch 12663, Loss: 0.007439291104674339, Neurons: 64, Grad norm: 3.504e-01\n",
      "Epoch 12664, Loss: 0.007364597637206316, Neurons: 64, Grad norm: 1.381e+00\n",
      "Epoch 12664, Loss: 0.007364597637206316, Neurons: 64, Grad norm: 1.381e+00\n",
      "Epoch 12665, Loss: 0.007389688864350319, Neurons: 64, Grad norm: 2.796e+00\n",
      "Epoch 12665, Loss: 0.007389688864350319, Neurons: 64, Grad norm: 2.796e+00\n",
      "Epoch 12666, Loss: 0.00747712841257453, Neurons: 64, Grad norm: 3.775e+00\n",
      "Epoch 12666, Loss: 0.00747712841257453, Neurons: 64, Grad norm: 3.775e+00\n",
      "Epoch 12667, Loss: 0.00757495267316699, Neurons: 64, Grad norm: 4.298e+00\n",
      "Epoch 12667, Loss: 0.00757495267316699, Neurons: 64, Grad norm: 4.298e+00\n",
      "Epoch 12668, Loss: 0.007636719848960638, Neurons: 64, Grad norm: 4.303e+00\n",
      "Epoch 12668, Loss: 0.007636719848960638, Neurons: 64, Grad norm: 4.303e+00\n",
      "Epoch 12669, Loss: 0.007637901231646538, Neurons: 64, Grad norm: 3.865e+00\n",
      "Epoch 12669, Loss: 0.007637901231646538, Neurons: 64, Grad norm: 3.865e+00\n",
      "Epoch 12670, Loss: 0.007580526173114777, Neurons: 64, Grad norm: 3.021e+00\n",
      "Epoch 12670, Loss: 0.007580526173114777, Neurons: 64, Grad norm: 3.021e+00\n",
      "Epoch 12671, Loss: 0.007491610944271088, Neurons: 64, Grad norm: 1.940e+00\n",
      "Epoch 12671, Loss: 0.007491610944271088, Neurons: 64, Grad norm: 1.940e+00\n",
      "Epoch 12672, Loss: 0.007407207973301411, Neurons: 64, Grad norm: 7.317e-01\n",
      "Epoch 12672, Loss: 0.007407207973301411, Neurons: 64, Grad norm: 7.317e-01\n",
      "Epoch 12673, Loss: 0.007356570567935705, Neurons: 64, Grad norm: 4.637e-01\n",
      "Epoch 12673, Loss: 0.007356570567935705, Neurons: 64, Grad norm: 4.637e-01\n",
      "Epoch 12674, Loss: 0.007349641062319279, Neurons: 64, Grad norm: 1.459e+00\n",
      "Epoch 12674, Loss: 0.007349641062319279, Neurons: 64, Grad norm: 1.459e+00\n",
      "Epoch 12675, Loss: 0.007376465480774641, Neurons: 64, Grad norm: 2.190e+00\n",
      "Epoch 12675, Loss: 0.007376465480774641, Neurons: 64, Grad norm: 2.190e+00\n",
      "Epoch 12676, Loss: 0.007415838539600372, Neurons: 64, Grad norm: 2.631e+00\n",
      "Epoch 12676, Loss: 0.007415838539600372, Neurons: 64, Grad norm: 2.631e+00\n",
      "Epoch 12677, Loss: 0.007445706985890865, Neurons: 64, Grad norm: 2.720e+00\n",
      "Epoch 12677, Loss: 0.007445706985890865, Neurons: 64, Grad norm: 2.720e+00\n",
      "Epoch 12678, Loss: 0.007452189922332764, Neurons: 64, Grad norm: 2.521e+00\n",
      "Epoch 12678, Loss: 0.007452189922332764, Neurons: 64, Grad norm: 2.521e+00\n",
      "Epoch 12679, Loss: 0.007434007711708546, Neurons: 64, Grad norm: 2.050e+00\n",
      "Epoch 12679, Loss: 0.007434007711708546, Neurons: 64, Grad norm: 2.050e+00\n",
      "Epoch 12680, Loss: 0.007400483824312687, Neurons: 64, Grad norm: 1.422e+00\n",
      "Epoch 12680, Loss: 0.007400483824312687, Neurons: 64, Grad norm: 1.422e+00\n",
      "Epoch 12681, Loss: 0.0073654139414429665, Neurons: 64, Grad norm: 6.904e-01\n",
      "Epoch 12681, Loss: 0.0073654139414429665, Neurons: 64, Grad norm: 6.904e-01\n",
      "Epoch 12682, Loss: 0.007340831682085991, Neurons: 64, Grad norm: 1.591e-01\n",
      "Epoch 12682, Loss: 0.007340831682085991, Neurons: 64, Grad norm: 1.591e-01\n",
      "Epoch 12683, Loss: 0.007332194596529007, Neurons: 64, Grad norm: 7.125e-01\n",
      "Epoch 12683, Loss: 0.007332194596529007, Neurons: 64, Grad norm: 7.125e-01\n",
      "Epoch 12684, Loss: 0.007337701506912708, Neurons: 64, Grad norm: 1.205e+00\n",
      "Epoch 12684, Loss: 0.007337701506912708, Neurons: 64, Grad norm: 1.205e+00\n",
      "Epoch 12685, Loss: 0.007350367959588766, Neurons: 64, Grad norm: 1.547e+00\n",
      "Epoch 12685, Loss: 0.007350367959588766, Neurons: 64, Grad norm: 1.547e+00\n",
      "Epoch 12686, Loss: 0.007362292613834143, Neurons: 64, Grad norm: 1.677e+00\n",
      "Epoch 12686, Loss: 0.007362292613834143, Neurons: 64, Grad norm: 1.677e+00\n",
      "Epoch 12687, Loss: 0.007367409765720367, Neurons: 64, Grad norm: 1.647e+00\n",
      "Epoch 12687, Loss: 0.007367409765720367, Neurons: 64, Grad norm: 1.647e+00\n",
      "Epoch 12688, Loss: 0.0073636313900351524, Neurons: 64, Grad norm: 1.439e+00\n",
      "Epoch 12688, Loss: 0.0073636313900351524, Neurons: 64, Grad norm: 1.439e+00\n",
      "Epoch 12689, Loss: 0.007352759130299091, Neurons: 64, Grad norm: 1.134e+00\n",
      "Epoch 12689, Loss: 0.007352759130299091, Neurons: 64, Grad norm: 1.134e+00\n",
      "Epoch 12690, Loss: 0.007338749244809151, Neurons: 64, Grad norm: 7.307e-01\n",
      "Epoch 12690, Loss: 0.007338749244809151, Neurons: 64, Grad norm: 7.307e-01\n",
      "Epoch 12691, Loss: 0.007326145190745592, Neurons: 64, Grad norm: 3.297e-01\n",
      "Epoch 12691, Loss: 0.007326145190745592, Neurons: 64, Grad norm: 3.297e-01\n",
      "Epoch 12692, Loss: 0.007317977957427502, Neurons: 64, Grad norm: 1.570e-01\n",
      "Epoch 12692, Loss: 0.007317977957427502, Neurons: 64, Grad norm: 1.570e-01\n",
      "Epoch 12693, Loss: 0.007315251510590315, Neurons: 64, Grad norm: 4.735e-01\n",
      "Epoch 12693, Loss: 0.007315251510590315, Neurons: 64, Grad norm: 4.735e-01\n",
      "Epoch 12694, Loss: 0.0073167709633708, Neurons: 64, Grad norm: 7.573e-01\n",
      "Epoch 12694, Loss: 0.0073167709633708, Neurons: 64, Grad norm: 7.573e-01\n",
      "Epoch 12695, Loss: 0.00732035655528307, Neurons: 64, Grad norm: 9.318e-01\n",
      "Epoch 12695, Loss: 0.00732035655528307, Neurons: 64, Grad norm: 9.318e-01\n",
      "Epoch 12696, Loss: 0.0073234341107308865, Neurons: 64, Grad norm: 1.029e+00\n",
      "Epoch 12696, Loss: 0.0073234341107308865, Neurons: 64, Grad norm: 1.029e+00\n",
      "Epoch 12697, Loss: 0.007324194069951773, Neurons: 64, Grad norm: 1.008e+00\n",
      "Epoch 12697, Loss: 0.007324194069951773, Neurons: 64, Grad norm: 1.008e+00\n",
      "Epoch 12698, Loss: 0.0073220874182879925, Neurons: 64, Grad norm: 9.248e-01\n",
      "Epoch 12698, Loss: 0.0073220874182879925, Neurons: 64, Grad norm: 9.248e-01\n",
      "Epoch 12699, Loss: 0.007317503914237022, Neurons: 64, Grad norm: 7.532e-01\n",
      "Epoch 12699, Loss: 0.007317503914237022, Neurons: 64, Grad norm: 7.532e-01\n",
      "Epoch 12699, Test loss: 0.005738358478993177\n",
      "Epoch 12699, Test loss: 0.005738358478993177\n",
      "Epoch 12700, Loss: 0.007311641238629818, Neurons: 64, Grad norm: 5.587e-01\n",
      "Epoch 12700, Loss: 0.007311641238629818, Neurons: 64, Grad norm: 5.587e-01\n",
      "Epoch 12701, Loss: 0.007305886130779982, Neurons: 64, Grad norm: 3.235e-01\n",
      "Epoch 12701, Loss: 0.007305886130779982, Neurons: 64, Grad norm: 3.235e-01\n",
      "Epoch 12702, Loss: 0.007301238365471363, Neurons: 64, Grad norm: 1.175e-01\n",
      "Epoch 12702, Loss: 0.007301238365471363, Neurons: 64, Grad norm: 1.175e-01\n",
      "Epoch 12703, Loss: 0.007298255804926157, Neurons: 64, Grad norm: 1.360e-01\n",
      "Epoch 12703, Loss: 0.007298255804926157, Neurons: 64, Grad norm: 1.360e-01\n",
      "Epoch 12704, Loss: 0.007296781055629253, Neurons: 64, Grad norm: 3.075e-01\n",
      "Epoch 12704, Loss: 0.007296781055629253, Neurons: 64, Grad norm: 3.075e-01\n",
      "Epoch 12705, Loss: 0.007296486757695675, Neurons: 64, Grad norm: 4.621e-01\n",
      "Epoch 12705, Loss: 0.007296486757695675, Neurons: 64, Grad norm: 4.621e-01\n",
      "Epoch 12706, Loss: 0.007296591065824032, Neurons: 64, Grad norm: 5.498e-01\n",
      "Epoch 12706, Loss: 0.007296591065824032, Neurons: 64, Grad norm: 5.498e-01\n",
      "Epoch 12707, Loss: 0.007296551018953323, Neurons: 64, Grad norm: 6.100e-01\n",
      "Epoch 12707, Loss: 0.007296551018953323, Neurons: 64, Grad norm: 6.100e-01\n",
      "Epoch 12708, Loss: 0.007295811083167791, Neurons: 64, Grad norm: 6.061e-01\n",
      "Epoch 12708, Loss: 0.007295811083167791, Neurons: 64, Grad norm: 6.061e-01\n",
      "Epoch 12709, Loss: 0.007294157519936562, Neurons: 64, Grad norm: 5.835e-01\n",
      "Epoch 12709, Loss: 0.007294157519936562, Neurons: 64, Grad norm: 5.835e-01\n",
      "Epoch 12710, Loss: 0.007291820831596851, Neurons: 64, Grad norm: 5.080e-01\n",
      "Epoch 12710, Loss: 0.007291820831596851, Neurons: 64, Grad norm: 5.080e-01\n",
      "Epoch 12711, Loss: 0.007289123721420765, Neurons: 64, Grad norm: 4.309e-01\n",
      "Epoch 12711, Loss: 0.007289123721420765, Neurons: 64, Grad norm: 4.309e-01\n",
      "Epoch 12712, Loss: 0.007286133244633675, Neurons: 64, Grad norm: 3.183e-01\n",
      "Epoch 12712, Loss: 0.007286133244633675, Neurons: 64, Grad norm: 3.183e-01\n",
      "Epoch 12713, Loss: 0.007283322978764772, Neurons: 64, Grad norm: 2.206e-01\n",
      "Epoch 12713, Loss: 0.007283322978764772, Neurons: 64, Grad norm: 2.206e-01\n",
      "Epoch 12714, Loss: 0.007280764169991016, Neurons: 64, Grad norm: 1.048e-01\n",
      "Epoch 12714, Loss: 0.007280764169991016, Neurons: 64, Grad norm: 1.048e-01\n",
      "Epoch 12715, Loss: 0.007278584875166416, Neurons: 64, Grad norm: 2.464e-02\n",
      "Epoch 12715, Loss: 0.007278584875166416, Neurons: 64, Grad norm: 2.464e-02\n",
      "Epoch 12716, Loss: 0.007276774384081364, Neurons: 64, Grad norm: 9.889e-02\n",
      "Epoch 12716, Loss: 0.007276774384081364, Neurons: 64, Grad norm: 9.889e-02\n",
      "Epoch 12717, Loss: 0.0072752307169139385, Neurons: 64, Grad norm: 1.656e-01\n",
      "Epoch 12717, Loss: 0.0072752307169139385, Neurons: 64, Grad norm: 1.656e-01\n",
      "Epoch 12718, Loss: 0.007273932918906212, Neurons: 64, Grad norm: 2.369e-01\n",
      "Epoch 12718, Loss: 0.007273932918906212, Neurons: 64, Grad norm: 2.369e-01\n",
      "Epoch 12719, Loss: 0.007272688206285238, Neurons: 64, Grad norm: 2.705e-01\n",
      "Epoch 12719, Loss: 0.007272688206285238, Neurons: 64, Grad norm: 2.705e-01\n",
      "Epoch 12720, Loss: 0.0072713932022452354, Neurons: 64, Grad norm: 3.141e-01\n",
      "Epoch 12720, Loss: 0.0072713932022452354, Neurons: 64, Grad norm: 3.141e-01\n",
      "Epoch 12721, Loss: 0.0072700390592217445, Neurons: 64, Grad norm: 3.190e-01\n",
      "Epoch 12721, Loss: 0.0072700390592217445, Neurons: 64, Grad norm: 3.190e-01\n",
      "Epoch 12722, Loss: 0.007268556859344244, Neurons: 64, Grad norm: 3.309e-01\n",
      "Epoch 12722, Loss: 0.007268556859344244, Neurons: 64, Grad norm: 3.309e-01\n",
      "Epoch 12723, Loss: 0.007266932167112827, Neurons: 64, Grad norm: 3.084e-01\n",
      "Epoch 12723, Loss: 0.007266932167112827, Neurons: 64, Grad norm: 3.084e-01\n",
      "Epoch 12724, Loss: 0.007265216205269098, Neurons: 64, Grad norm: 2.983e-01\n",
      "Epoch 12724, Loss: 0.007265216205269098, Neurons: 64, Grad norm: 2.983e-01\n",
      "Epoch 12725, Loss: 0.007263416424393654, Neurons: 64, Grad norm: 2.626e-01\n",
      "Epoch 12725, Loss: 0.007263416424393654, Neurons: 64, Grad norm: 2.626e-01\n",
      "Epoch 12726, Loss: 0.007261601276695728, Neurons: 64, Grad norm: 2.421e-01\n",
      "Epoch 12726, Loss: 0.007261601276695728, Neurons: 64, Grad norm: 2.421e-01\n",
      "Epoch 12727, Loss: 0.00725973304361105, Neurons: 64, Grad norm: 1.978e-01\n",
      "Epoch 12727, Loss: 0.00725973304361105, Neurons: 64, Grad norm: 1.978e-01\n",
      "Epoch 12728, Loss: 0.007257925346493721, Neurons: 64, Grad norm: 1.722e-01\n",
      "Epoch 12728, Loss: 0.007257925346493721, Neurons: 64, Grad norm: 1.722e-01\n",
      "Epoch 12729, Loss: 0.007256147917360067, Neurons: 64, Grad norm: 1.277e-01\n",
      "Epoch 12729, Loss: 0.007256147917360067, Neurons: 64, Grad norm: 1.277e-01\n",
      "Epoch 12730, Loss: 0.007254377938807011, Neurons: 64, Grad norm: 1.018e-01\n",
      "Epoch 12730, Loss: 0.007254377938807011, Neurons: 64, Grad norm: 1.018e-01\n",
      "Epoch 12731, Loss: 0.007252667099237442, Neurons: 64, Grad norm: 7.551e-02\n",
      "Epoch 12731, Loss: 0.007252667099237442, Neurons: 64, Grad norm: 7.551e-02\n",
      "Epoch 12732, Loss: 0.007250997703522444, Neurons: 64, Grad norm: 6.881e-02\n",
      "Epoch 12732, Loss: 0.007250997703522444, Neurons: 64, Grad norm: 6.881e-02\n",
      "Epoch 12733, Loss: 0.007249398622661829, Neurons: 64, Grad norm: 8.202e-02\n",
      "Epoch 12733, Loss: 0.007249398622661829, Neurons: 64, Grad norm: 8.202e-02\n",
      "Epoch 12734, Loss: 0.00724782794713974, Neurons: 64, Grad norm: 9.613e-02\n",
      "Epoch 12734, Loss: 0.00724782794713974, Neurons: 64, Grad norm: 9.613e-02\n",
      "Epoch 12735, Loss: 0.0072462838143110275, Neurons: 64, Grad norm: 1.301e-01\n",
      "Epoch 12735, Loss: 0.0072462838143110275, Neurons: 64, Grad norm: 1.301e-01\n",
      "Epoch 12736, Loss: 0.007244836073368788, Neurons: 64, Grad norm: 1.401e-01\n",
      "Epoch 12736, Loss: 0.007244836073368788, Neurons: 64, Grad norm: 1.401e-01\n",
      "Epoch 12737, Loss: 0.007243465632200241, Neurons: 64, Grad norm: 1.743e-01\n",
      "Epoch 12737, Loss: 0.007243465632200241, Neurons: 64, Grad norm: 1.743e-01\n",
      "Epoch 12738, Loss: 0.0072420742362737656, Neurons: 64, Grad norm: 1.881e-01\n",
      "Epoch 12738, Loss: 0.0072420742362737656, Neurons: 64, Grad norm: 1.881e-01\n",
      "Epoch 12739, Loss: 0.007240723818540573, Neurons: 64, Grad norm: 2.202e-01\n",
      "Epoch 12739, Loss: 0.007240723818540573, Neurons: 64, Grad norm: 2.202e-01\n",
      "Epoch 12740, Loss: 0.007239487953484058, Neurons: 64, Grad norm: 2.313e-01\n",
      "Epoch 12740, Loss: 0.007239487953484058, Neurons: 64, Grad norm: 2.313e-01\n",
      "Epoch 12741, Loss: 0.007238250691443682, Neurons: 64, Grad norm: 2.654e-01\n",
      "Epoch 12741, Loss: 0.007238250691443682, Neurons: 64, Grad norm: 2.654e-01\n",
      "Epoch 12742, Loss: 0.007237287238240242, Neurons: 64, Grad norm: 2.820e-01\n",
      "Epoch 12742, Loss: 0.007237287238240242, Neurons: 64, Grad norm: 2.820e-01\n",
      "Epoch 12743, Loss: 0.0072364239022135735, Neurons: 64, Grad norm: 3.240e-01\n",
      "Epoch 12743, Loss: 0.0072364239022135735, Neurons: 64, Grad norm: 3.240e-01\n",
      "Epoch 12744, Loss: 0.007235940545797348, Neurons: 64, Grad norm: 3.508e-01\n",
      "Epoch 12744, Loss: 0.007235940545797348, Neurons: 64, Grad norm: 3.508e-01\n",
      "Epoch 12745, Loss: 0.007235776167362928, Neurons: 64, Grad norm: 4.028e-01\n",
      "Epoch 12745, Loss: 0.007235776167362928, Neurons: 64, Grad norm: 4.028e-01\n",
      "Epoch 12746, Loss: 0.0072359926998615265, Neurons: 64, Grad norm: 4.431e-01\n",
      "Epoch 12746, Loss: 0.0072359926998615265, Neurons: 64, Grad norm: 4.431e-01\n",
      "Epoch 12747, Loss: 0.007236796896904707, Neurons: 64, Grad norm: 5.095e-01\n",
      "Epoch 12747, Loss: 0.007236796896904707, Neurons: 64, Grad norm: 5.095e-01\n",
      "Epoch 12748, Loss: 0.007238350342959166, Neurons: 64, Grad norm: 5.679e-01\n",
      "Epoch 12748, Loss: 0.007238350342959166, Neurons: 64, Grad norm: 5.679e-01\n",
      "Epoch 12749, Loss: 0.007240806706249714, Neurons: 64, Grad norm: 6.555e-01\n",
      "Epoch 12749, Loss: 0.007240806706249714, Neurons: 64, Grad norm: 6.555e-01\n",
      "Epoch 12750, Loss: 0.007244621869176626, Neurons: 64, Grad norm: 7.386e-01\n",
      "Epoch 12750, Loss: 0.007244621869176626, Neurons: 64, Grad norm: 7.386e-01\n",
      "Epoch 12751, Loss: 0.00725028570741415, Neurons: 64, Grad norm: 8.585e-01\n",
      "Epoch 12751, Loss: 0.00725028570741415, Neurons: 64, Grad norm: 8.585e-01\n",
      "Epoch 12752, Loss: 0.007258984725922346, Neurons: 64, Grad norm: 9.822e-01\n",
      "Epoch 12752, Loss: 0.007258984725922346, Neurons: 64, Grad norm: 9.822e-01\n",
      "Epoch 12753, Loss: 0.0072711617685854435, Neurons: 64, Grad norm: 1.146e+00\n",
      "Epoch 12753, Loss: 0.0072711617685854435, Neurons: 64, Grad norm: 1.146e+00\n",
      "Epoch 12754, Loss: 0.007288389373570681, Neurons: 64, Grad norm: 1.315e+00\n",
      "Epoch 12754, Loss: 0.007288389373570681, Neurons: 64, Grad norm: 1.315e+00\n",
      "Epoch 12755, Loss: 0.007311252877116203, Neurons: 64, Grad norm: 1.520e+00\n",
      "Epoch 12755, Loss: 0.007311252877116203, Neurons: 64, Grad norm: 1.520e+00\n",
      "Epoch 12756, Loss: 0.007341308053582907, Neurons: 64, Grad norm: 1.728e+00\n",
      "Epoch 12756, Loss: 0.007341308053582907, Neurons: 64, Grad norm: 1.728e+00\n",
      "Epoch 12757, Loss: 0.007377905771136284, Neurons: 64, Grad norm: 1.961e+00\n",
      "Epoch 12757, Loss: 0.007377905771136284, Neurons: 64, Grad norm: 1.961e+00\n",
      "Epoch 12758, Loss: 0.007420829962939024, Neurons: 64, Grad norm: 2.171e+00\n",
      "Epoch 12758, Loss: 0.007420829962939024, Neurons: 64, Grad norm: 2.171e+00\n",
      "Epoch 12759, Loss: 0.007464678958058357, Neurons: 64, Grad norm: 2.373e+00\n",
      "Epoch 12759, Loss: 0.007464678958058357, Neurons: 64, Grad norm: 2.373e+00\n",
      "Epoch 12760, Loss: 0.007503593806177378, Neurons: 64, Grad norm: 2.509e+00\n",
      "Epoch 12760, Loss: 0.007503593806177378, Neurons: 64, Grad norm: 2.509e+00\n",
      "Epoch 12761, Loss: 0.007525617256760597, Neurons: 64, Grad norm: 2.593e+00\n",
      "Epoch 12761, Loss: 0.007525617256760597, Neurons: 64, Grad norm: 2.593e+00\n",
      "Epoch 12762, Loss: 0.0075220828875899315, Neurons: 64, Grad norm: 2.579e+00\n",
      "Epoch 12762, Loss: 0.0075220828875899315, Neurons: 64, Grad norm: 2.579e+00\n",
      "Epoch 12763, Loss: 0.007486471440643072, Neurons: 64, Grad norm: 2.523e+00\n",
      "Epoch 12763, Loss: 0.007486471440643072, Neurons: 64, Grad norm: 2.523e+00\n",
      "Epoch 12764, Loss: 0.00742578087374568, Neurons: 64, Grad norm: 2.439e+00\n",
      "Epoch 12764, Loss: 0.00742578087374568, Neurons: 64, Grad norm: 2.439e+00\n",
      "Epoch 12765, Loss: 0.0073590087704360485, Neurons: 64, Grad norm: 2.440e+00\n",
      "Epoch 12765, Loss: 0.0073590087704360485, Neurons: 64, Grad norm: 2.440e+00\n",
      "Epoch 12766, Loss: 0.007309419102966785, Neurons: 64, Grad norm: 2.540e+00\n",
      "Epoch 12766, Loss: 0.007309419102966785, Neurons: 64, Grad norm: 2.540e+00\n",
      "Epoch 12767, Loss: 0.007294117473065853, Neurons: 64, Grad norm: 2.788e+00\n",
      "Epoch 12767, Loss: 0.007294117473065853, Neurons: 64, Grad norm: 2.788e+00\n",
      "Epoch 12768, Loss: 0.00731683848425746, Neurons: 64, Grad norm: 3.103e+00\n",
      "Epoch 12768, Loss: 0.00731683848425746, Neurons: 64, Grad norm: 3.103e+00\n",
      "Epoch 12769, Loss: 0.007368727121502161, Neurons: 64, Grad norm: 3.470e+00\n",
      "Epoch 12769, Loss: 0.007368727121502161, Neurons: 64, Grad norm: 3.470e+00\n",
      "Epoch 12770, Loss: 0.007432662881910801, Neurons: 64, Grad norm: 3.807e+00\n",
      "Epoch 12770, Loss: 0.007432662881910801, Neurons: 64, Grad norm: 3.807e+00\n",
      "Epoch 12771, Loss: 0.0074911522679030895, Neurons: 64, Grad norm: 4.123e+00\n",
      "Epoch 12771, Loss: 0.0074911522679030895, Neurons: 64, Grad norm: 4.123e+00\n",
      "Epoch 12772, Loss: 0.007530018221586943, Neurons: 64, Grad norm: 4.367e+00\n",
      "Epoch 12772, Loss: 0.007530018221586943, Neurons: 64, Grad norm: 4.367e+00\n",
      "Epoch 12773, Loss: 0.00754536222666502, Neurons: 64, Grad norm: 4.568e+00\n",
      "Epoch 12773, Loss: 0.00754536222666502, Neurons: 64, Grad norm: 4.568e+00\n",
      "Epoch 12774, Loss: 0.007541778963059187, Neurons: 64, Grad norm: 4.692e+00\n",
      "Epoch 12774, Loss: 0.007541778963059187, Neurons: 64, Grad norm: 4.692e+00\n",
      "Epoch 12775, Loss: 0.007532445248216391, Neurons: 64, Grad norm: 4.777e+00\n",
      "Epoch 12775, Loss: 0.007532445248216391, Neurons: 64, Grad norm: 4.777e+00\n",
      "Epoch 12776, Loss: 0.00752754183486104, Neurons: 64, Grad norm: 4.776e+00\n",
      "Epoch 12776, Loss: 0.00752754183486104, Neurons: 64, Grad norm: 4.776e+00\n",
      "Epoch 12777, Loss: 0.007531096693128347, Neurons: 64, Grad norm: 4.712e+00\n",
      "Epoch 12777, Loss: 0.007531096693128347, Neurons: 64, Grad norm: 4.712e+00\n",
      "Epoch 12778, Loss: 0.007535592187196016, Neurons: 64, Grad norm: 4.516e+00\n",
      "Epoch 12778, Loss: 0.007535592187196016, Neurons: 64, Grad norm: 4.516e+00\n",
      "Epoch 12779, Loss: 0.007527912966907024, Neurons: 64, Grad norm: 4.206e+00\n",
      "Epoch 12779, Loss: 0.007527912966907024, Neurons: 64, Grad norm: 4.206e+00\n",
      "Epoch 12780, Loss: 0.007495495956391096, Neurons: 64, Grad norm: 3.729e+00\n",
      "Epoch 12780, Loss: 0.007495495956391096, Neurons: 64, Grad norm: 3.729e+00\n",
      "Epoch 12781, Loss: 0.007435116916894913, Neurons: 64, Grad norm: 3.140e+00\n",
      "Epoch 12781, Loss: 0.007435116916894913, Neurons: 64, Grad norm: 3.140e+00\n",
      "Epoch 12782, Loss: 0.007355883251875639, Neurons: 64, Grad norm: 2.427e+00\n",
      "Epoch 12782, Loss: 0.007355883251875639, Neurons: 64, Grad norm: 2.427e+00\n",
      "Epoch 12783, Loss: 0.007276075892150402, Neurons: 64, Grad norm: 1.690e+00\n",
      "Epoch 12783, Loss: 0.007276075892150402, Neurons: 64, Grad norm: 1.690e+00\n",
      "Epoch 12784, Loss: 0.007214264012873173, Neurons: 64, Grad norm: 9.573e-01\n",
      "Epoch 12784, Loss: 0.007214264012873173, Neurons: 64, Grad norm: 9.573e-01\n",
      "Epoch 12785, Loss: 0.007180898915976286, Neurons: 64, Grad norm: 4.513e-01\n",
      "Epoch 12785, Loss: 0.007180898915976286, Neurons: 64, Grad norm: 4.513e-01\n",
      "Epoch 12786, Loss: 0.0071746292524039745, Neurons: 64, Grad norm: 6.570e-01\n",
      "Epoch 12786, Loss: 0.0071746292524039745, Neurons: 64, Grad norm: 6.570e-01\n",
      "Epoch 12787, Loss: 0.007185826078057289, Neurons: 64, Grad norm: 1.103e+00\n",
      "Epoch 12787, Loss: 0.007185826078057289, Neurons: 64, Grad norm: 1.103e+00\n",
      "Epoch 12788, Loss: 0.007202731445431709, Neurons: 64, Grad norm: 1.512e+00\n",
      "Epoch 12788, Loss: 0.007202731445431709, Neurons: 64, Grad norm: 1.512e+00\n",
      "Epoch 12789, Loss: 0.0072166332975029945, Neurons: 64, Grad norm: 1.806e+00\n",
      "Epoch 12789, Loss: 0.0072166332975029945, Neurons: 64, Grad norm: 1.806e+00\n",
      "Epoch 12790, Loss: 0.0072243413887917995, Neurons: 64, Grad norm: 2.029e+00\n",
      "Epoch 12790, Loss: 0.0072243413887917995, Neurons: 64, Grad norm: 2.029e+00\n",
      "Epoch 12791, Loss: 0.00722707761451602, Neurons: 64, Grad norm: 2.148e+00\n",
      "Epoch 12791, Loss: 0.00722707761451602, Neurons: 64, Grad norm: 2.148e+00\n",
      "Epoch 12792, Loss: 0.007227908819913864, Neurons: 64, Grad norm: 2.217e+00\n",
      "Epoch 12792, Loss: 0.007227908819913864, Neurons: 64, Grad norm: 2.217e+00\n",
      "Epoch 12793, Loss: 0.007228612434118986, Neurons: 64, Grad norm: 2.192e+00\n",
      "Epoch 12793, Loss: 0.007228612434118986, Neurons: 64, Grad norm: 2.192e+00\n",
      "Epoch 12794, Loss: 0.007228562142699957, Neurons: 64, Grad norm: 2.117e+00\n",
      "Epoch 12794, Loss: 0.007228562142699957, Neurons: 64, Grad norm: 2.117e+00\n",
      "Epoch 12795, Loss: 0.007225433364510536, Neurons: 64, Grad norm: 1.953e+00\n",
      "Epoch 12795, Loss: 0.007225433364510536, Neurons: 64, Grad norm: 1.953e+00\n",
      "Epoch 12796, Loss: 0.0072173490189015865, Neurons: 64, Grad norm: 1.747e+00\n",
      "Epoch 12796, Loss: 0.0072173490189015865, Neurons: 64, Grad norm: 1.747e+00\n",
      "Epoch 12797, Loss: 0.0072038802318274975, Neurons: 64, Grad norm: 1.473e+00\n",
      "Epoch 12797, Loss: 0.0072038802318274975, Neurons: 64, Grad norm: 1.473e+00\n",
      "Epoch 12798, Loss: 0.00718696229159832, Neurons: 64, Grad norm: 1.180e+00\n",
      "Epoch 12798, Loss: 0.00718696229159832, Neurons: 64, Grad norm: 1.180e+00\n",
      "Epoch 12799, Loss: 0.0071698506362736225, Neurons: 64, Grad norm: 8.525e-01\n",
      "Epoch 12799, Loss: 0.0071698506362736225, Neurons: 64, Grad norm: 8.525e-01\n",
      "Epoch 12799, Test loss: 0.00563270365819335\n",
      "Epoch 12799, Test loss: 0.00563270365819335\n",
      "Epoch 12800, Loss: 0.007155644707381725, Neurons: 64, Grad norm: 5.566e-01\n",
      "Epoch 12800, Loss: 0.007155644707381725, Neurons: 64, Grad norm: 5.566e-01\n",
      "Epoch 12801, Loss: 0.007146455347537994, Neurons: 64, Grad norm: 2.900e-01\n",
      "Epoch 12801, Loss: 0.007146455347537994, Neurons: 64, Grad norm: 2.900e-01\n",
      "Epoch 12802, Loss: 0.007142419461160898, Neurons: 64, Grad norm: 2.205e-01\n",
      "Epoch 12802, Loss: 0.007142419461160898, Neurons: 64, Grad norm: 2.205e-01\n",
      "Epoch 12803, Loss: 0.007142001297324896, Neurons: 64, Grad norm: 3.551e-01\n",
      "Epoch 12803, Loss: 0.007142001297324896, Neurons: 64, Grad norm: 3.551e-01\n",
      "Epoch 12804, Loss: 0.007143163587898016, Neurons: 64, Grad norm: 5.108e-01\n",
      "Epoch 12804, Loss: 0.007143163587898016, Neurons: 64, Grad norm: 5.108e-01\n",
      "Epoch 12805, Loss: 0.007144314236938953, Neurons: 64, Grad norm: 6.565e-01\n",
      "Epoch 12805, Loss: 0.007144314236938953, Neurons: 64, Grad norm: 6.565e-01\n",
      "Epoch 12806, Loss: 0.007144507020711899, Neurons: 64, Grad norm: 7.588e-01\n",
      "Epoch 12806, Loss: 0.007144507020711899, Neurons: 64, Grad norm: 7.588e-01\n",
      "Epoch 12807, Loss: 0.007144169416278601, Neurons: 64, Grad norm: 8.590e-01\n",
      "Epoch 12807, Loss: 0.007144169416278601, Neurons: 64, Grad norm: 8.590e-01\n",
      "Epoch 12808, Loss: 0.0071434201672673225, Neurons: 64, Grad norm: 9.244e-01\n",
      "Epoch 12808, Loss: 0.0071434201672673225, Neurons: 64, Grad norm: 9.244e-01\n",
      "Epoch 12809, Loss: 0.007143005263060331, Neurons: 64, Grad norm: 9.952e-01\n",
      "Epoch 12809, Loss: 0.007143005263060331, Neurons: 64, Grad norm: 9.952e-01\n",
      "Epoch 12810, Loss: 0.007142964284867048, Neurons: 64, Grad norm: 1.028e+00\n",
      "Epoch 12810, Loss: 0.007142964284867048, Neurons: 64, Grad norm: 1.028e+00\n",
      "Epoch 12811, Loss: 0.007143130525946617, Neurons: 64, Grad norm: 1.070e+00\n",
      "Epoch 12811, Loss: 0.007143130525946617, Neurons: 64, Grad norm: 1.070e+00\n",
      "Epoch 12812, Loss: 0.0071432157419621944, Neurons: 64, Grad norm: 1.077e+00\n",
      "Epoch 12812, Loss: 0.0071432157419621944, Neurons: 64, Grad norm: 1.077e+00\n",
      "Epoch 12813, Loss: 0.007142883725464344, Neurons: 64, Grad norm: 1.091e+00\n",
      "Epoch 12813, Loss: 0.007142883725464344, Neurons: 64, Grad norm: 1.091e+00\n",
      "Epoch 12814, Loss: 0.007141744252294302, Neurons: 64, Grad norm: 1.070e+00\n",
      "Epoch 12814, Loss: 0.007141744252294302, Neurons: 64, Grad norm: 1.070e+00\n",
      "Epoch 12815, Loss: 0.007139743305742741, Neurons: 64, Grad norm: 1.065e+00\n",
      "Epoch 12815, Loss: 0.007139743305742741, Neurons: 64, Grad norm: 1.065e+00\n",
      "Epoch 12816, Loss: 0.007137168198823929, Neurons: 64, Grad norm: 1.031e+00\n",
      "Epoch 12816, Loss: 0.007137168198823929, Neurons: 64, Grad norm: 1.031e+00\n",
      "Epoch 12817, Loss: 0.007134388200938702, Neurons: 64, Grad norm: 1.019e+00\n",
      "Epoch 12817, Loss: 0.007134388200938702, Neurons: 64, Grad norm: 1.019e+00\n",
      "Epoch 12818, Loss: 0.007131678983569145, Neurons: 64, Grad norm: 9.893e-01\n",
      "Epoch 12818, Loss: 0.007131678983569145, Neurons: 64, Grad norm: 9.893e-01\n",
      "Epoch 12819, Loss: 0.007129363249987364, Neurons: 64, Grad norm: 9.825e-01\n",
      "Epoch 12819, Loss: 0.007129363249987364, Neurons: 64, Grad norm: 9.825e-01\n",
      "Epoch 12820, Loss: 0.0071273064240813255, Neurons: 64, Grad norm: 9.601e-01\n",
      "Epoch 12820, Loss: 0.0071273064240813255, Neurons: 64, Grad norm: 9.601e-01\n",
      "Epoch 12821, Loss: 0.007125584874302149, Neurons: 64, Grad norm: 9.657e-01\n",
      "Epoch 12821, Loss: 0.007125584874302149, Neurons: 64, Grad norm: 9.657e-01\n",
      "Epoch 12822, Loss: 0.007124205585569143, Neurons: 64, Grad norm: 9.554e-01\n",
      "Epoch 12822, Loss: 0.007124205585569143, Neurons: 64, Grad norm: 9.554e-01\n",
      "Epoch 12823, Loss: 0.007122901268303394, Neurons: 64, Grad norm: 9.700e-01\n",
      "Epoch 12823, Loss: 0.007122901268303394, Neurons: 64, Grad norm: 9.700e-01\n",
      "Epoch 12824, Loss: 0.007121682167053223, Neurons: 64, Grad norm: 9.727e-01\n",
      "Epoch 12824, Loss: 0.007121682167053223, Neurons: 64, Grad norm: 9.727e-01\n",
      "Epoch 12825, Loss: 0.007120508700609207, Neurons: 64, Grad norm: 1.006e+00\n",
      "Epoch 12825, Loss: 0.007120508700609207, Neurons: 64, Grad norm: 1.006e+00\n",
      "Epoch 12826, Loss: 0.0071195438504219055, Neurons: 64, Grad norm: 1.024e+00\n",
      "Epoch 12826, Loss: 0.0071195438504219055, Neurons: 64, Grad norm: 1.024e+00\n",
      "Epoch 12827, Loss: 0.007118645124137402, Neurons: 64, Grad norm: 1.068e+00\n",
      "Epoch 12827, Loss: 0.007118645124137402, Neurons: 64, Grad norm: 1.068e+00\n",
      "Epoch 12828, Loss: 0.007118064910173416, Neurons: 64, Grad norm: 1.106e+00\n",
      "Epoch 12828, Loss: 0.007118064910173416, Neurons: 64, Grad norm: 1.106e+00\n",
      "Epoch 12829, Loss: 0.007117874920368195, Neurons: 64, Grad norm: 1.176e+00\n",
      "Epoch 12829, Loss: 0.007117874920368195, Neurons: 64, Grad norm: 1.176e+00\n",
      "Epoch 12830, Loss: 0.007118285167962313, Neurons: 64, Grad norm: 1.235e+00\n",
      "Epoch 12830, Loss: 0.007118285167962313, Neurons: 64, Grad norm: 1.235e+00\n",
      "Epoch 12831, Loss: 0.007119413930922747, Neurons: 64, Grad norm: 1.334e+00\n",
      "Epoch 12831, Loss: 0.007119413930922747, Neurons: 64, Grad norm: 1.334e+00\n",
      "Epoch 12832, Loss: 0.007121524307876825, Neurons: 64, Grad norm: 1.432e+00\n",
      "Epoch 12832, Loss: 0.007121524307876825, Neurons: 64, Grad norm: 1.432e+00\n",
      "Epoch 12833, Loss: 0.007124672178179026, Neurons: 64, Grad norm: 1.573e+00\n",
      "Epoch 12833, Loss: 0.007124672178179026, Neurons: 64, Grad norm: 1.573e+00\n",
      "Epoch 12834, Loss: 0.007129125762730837, Neurons: 64, Grad norm: 1.709e+00\n",
      "Epoch 12834, Loss: 0.007129125762730837, Neurons: 64, Grad norm: 1.709e+00\n",
      "Epoch 12835, Loss: 0.007135157007724047, Neurons: 64, Grad norm: 1.891e+00\n",
      "Epoch 12835, Loss: 0.007135157007724047, Neurons: 64, Grad norm: 1.891e+00\n",
      "Epoch 12836, Loss: 0.007143119350075722, Neurons: 64, Grad norm: 2.081e+00\n",
      "Epoch 12836, Loss: 0.007143119350075722, Neurons: 64, Grad norm: 2.081e+00\n",
      "Epoch 12837, Loss: 0.007153662852942944, Neurons: 64, Grad norm: 2.325e+00\n",
      "Epoch 12837, Loss: 0.007153662852942944, Neurons: 64, Grad norm: 2.325e+00\n",
      "Epoch 12838, Loss: 0.007167626637965441, Neurons: 64, Grad norm: 2.583e+00\n",
      "Epoch 12838, Loss: 0.007167626637965441, Neurons: 64, Grad norm: 2.583e+00\n",
      "Epoch 12839, Loss: 0.007186044007539749, Neurons: 64, Grad norm: 2.901e+00\n",
      "Epoch 12839, Loss: 0.007186044007539749, Neurons: 64, Grad norm: 2.901e+00\n",
      "Epoch 12840, Loss: 0.00720999576151371, Neurons: 64, Grad norm: 3.236e+00\n",
      "Epoch 12840, Loss: 0.00720999576151371, Neurons: 64, Grad norm: 3.236e+00\n",
      "Epoch 12841, Loss: 0.007240874692797661, Neurons: 64, Grad norm: 3.631e+00\n",
      "Epoch 12841, Loss: 0.007240874692797661, Neurons: 64, Grad norm: 3.631e+00\n",
      "Epoch 12842, Loss: 0.007279450539499521, Neurons: 64, Grad norm: 4.038e+00\n",
      "Epoch 12842, Loss: 0.007279450539499521, Neurons: 64, Grad norm: 4.038e+00\n",
      "Epoch 12843, Loss: 0.007326819933950901, Neurons: 64, Grad norm: 4.494e+00\n",
      "Epoch 12843, Loss: 0.007326819933950901, Neurons: 64, Grad norm: 4.494e+00\n",
      "Epoch 12844, Loss: 0.007382628042250872, Neurons: 64, Grad norm: 4.934e+00\n",
      "Epoch 12844, Loss: 0.007382628042250872, Neurons: 64, Grad norm: 4.934e+00\n",
      "Epoch 12845, Loss: 0.007445945870131254, Neurons: 64, Grad norm: 5.373e+00\n",
      "Epoch 12845, Loss: 0.007445945870131254, Neurons: 64, Grad norm: 5.373e+00\n",
      "Epoch 12846, Loss: 0.007511985022574663, Neurons: 64, Grad norm: 5.739e+00\n",
      "Epoch 12846, Loss: 0.007511985022574663, Neurons: 64, Grad norm: 5.739e+00\n",
      "Epoch 12847, Loss: 0.007574554067105055, Neurons: 64, Grad norm: 6.027e+00\n",
      "Epoch 12847, Loss: 0.007574554067105055, Neurons: 64, Grad norm: 6.027e+00\n",
      "Epoch 12848, Loss: 0.00762205570936203, Neurons: 64, Grad norm: 6.134e+00\n",
      "Epoch 12848, Loss: 0.00762205570936203, Neurons: 64, Grad norm: 6.134e+00\n",
      "Epoch 12849, Loss: 0.007642694748938084, Neurons: 64, Grad norm: 6.044e+00\n",
      "Epoch 12849, Loss: 0.007642694748938084, Neurons: 64, Grad norm: 6.044e+00\n",
      "Epoch 12850, Loss: 0.007623500656336546, Neurons: 64, Grad norm: 5.682e+00\n",
      "Epoch 12850, Loss: 0.007623500656336546, Neurons: 64, Grad norm: 5.682e+00\n",
      "Epoch 12851, Loss: 0.007560037076473236, Neurons: 64, Grad norm: 5.076e+00\n",
      "Epoch 12851, Loss: 0.007560037076473236, Neurons: 64, Grad norm: 5.076e+00\n",
      "Epoch 12852, Loss: 0.007457513362169266, Neurons: 64, Grad norm: 4.199e+00\n",
      "Epoch 12852, Loss: 0.007457513362169266, Neurons: 64, Grad norm: 4.199e+00\n",
      "Epoch 12853, Loss: 0.007334402296692133, Neurons: 64, Grad norm: 3.151e+00\n",
      "Epoch 12853, Loss: 0.007334402296692133, Neurons: 64, Grad norm: 3.151e+00\n",
      "Epoch 12854, Loss: 0.007214904297143221, Neurons: 64, Grad norm: 1.971e+00\n",
      "Epoch 12854, Loss: 0.007214904297143221, Neurons: 64, Grad norm: 1.971e+00\n",
      "Epoch 12855, Loss: 0.007122519891709089, Neurons: 64, Grad norm: 8.107e-01\n",
      "Epoch 12855, Loss: 0.007122519891709089, Neurons: 64, Grad norm: 8.107e-01\n",
      "Epoch 12856, Loss: 0.007071106694638729, Neurons: 64, Grad norm: 4.269e-01\n",
      "Epoch 12856, Loss: 0.007071106694638729, Neurons: 64, Grad norm: 4.269e-01\n",
      "Epoch 12857, Loss: 0.0070618814788758755, Neurons: 64, Grad norm: 1.363e+00\n",
      "Epoch 12857, Loss: 0.0070618814788758755, Neurons: 64, Grad norm: 1.363e+00\n",
      "Epoch 12858, Loss: 0.007085271179676056, Neurons: 64, Grad norm: 2.167e+00\n",
      "Epoch 12858, Loss: 0.007085271179676056, Neurons: 64, Grad norm: 2.167e+00\n",
      "Epoch 12859, Loss: 0.007125637028366327, Neurons: 64, Grad norm: 2.735e+00\n",
      "Epoch 12859, Loss: 0.007125637028366327, Neurons: 64, Grad norm: 2.735e+00\n",
      "Epoch 12860, Loss: 0.007166803348809481, Neurons: 64, Grad norm: 3.090e+00\n",
      "Epoch 12860, Loss: 0.007166803348809481, Neurons: 64, Grad norm: 3.090e+00\n",
      "Epoch 12861, Loss: 0.007195545360445976, Neurons: 64, Grad norm: 3.182e+00\n",
      "Epoch 12861, Loss: 0.007195545360445976, Neurons: 64, Grad norm: 3.182e+00\n",
      "Epoch 12862, Loss: 0.00720457686111331, Neurons: 64, Grad norm: 3.074e+00\n",
      "Epoch 12862, Loss: 0.00720457686111331, Neurons: 64, Grad norm: 3.074e+00\n",
      "Epoch 12863, Loss: 0.007192515768110752, Neurons: 64, Grad norm: 2.745e+00\n",
      "Epoch 12863, Loss: 0.007192515768110752, Neurons: 64, Grad norm: 2.745e+00\n",
      "Epoch 12864, Loss: 0.007163905538618565, Neurons: 64, Grad norm: 2.280e+00\n",
      "Epoch 12864, Loss: 0.007163905538618565, Neurons: 64, Grad norm: 2.280e+00\n",
      "Epoch 12865, Loss: 0.007127018179744482, Neurons: 64, Grad norm: 1.686e+00\n",
      "Epoch 12865, Loss: 0.007127018179744482, Neurons: 64, Grad norm: 1.686e+00\n",
      "Epoch 12866, Loss: 0.007091205567121506, Neurons: 64, Grad norm: 1.065e+00\n",
      "Epoch 12866, Loss: 0.007091205567121506, Neurons: 64, Grad norm: 1.065e+00\n",
      "Epoch 12867, Loss: 0.007063755765557289, Neurons: 64, Grad norm: 4.669e-01\n",
      "Epoch 12867, Loss: 0.007063755765557289, Neurons: 64, Grad norm: 4.669e-01\n",
      "Epoch 12868, Loss: 0.0070482646115124226, Neurons: 64, Grad norm: 3.682e-01\n",
      "Epoch 12868, Loss: 0.0070482646115124226, Neurons: 64, Grad norm: 3.682e-01\n",
      "Epoch 12869, Loss: 0.007044842001050711, Neurons: 64, Grad norm: 8.142e-01\n",
      "Epoch 12869, Loss: 0.007044842001050711, Neurons: 64, Grad norm: 8.142e-01\n",
      "Epoch 12870, Loss: 0.007050121668726206, Neurons: 64, Grad norm: 1.207e+00\n",
      "Epoch 12870, Loss: 0.007050121668726206, Neurons: 64, Grad norm: 1.207e+00\n",
      "Epoch 12871, Loss: 0.007059757597744465, Neurons: 64, Grad norm: 1.511e+00\n",
      "Epoch 12871, Loss: 0.007059757597744465, Neurons: 64, Grad norm: 1.511e+00\n",
      "Epoch 12872, Loss: 0.007069464772939682, Neurons: 64, Grad norm: 1.677e+00\n",
      "Epoch 12872, Loss: 0.007069464772939682, Neurons: 64, Grad norm: 1.677e+00\n",
      "Epoch 12873, Loss: 0.007075896952301264, Neurons: 64, Grad norm: 1.747e+00\n",
      "Epoch 12873, Loss: 0.007075896952301264, Neurons: 64, Grad norm: 1.747e+00\n",
      "Epoch 12874, Loss: 0.0070774368941783905, Neurons: 64, Grad norm: 1.690e+00\n",
      "Epoch 12874, Loss: 0.0070774368941783905, Neurons: 64, Grad norm: 1.690e+00\n",
      "Epoch 12875, Loss: 0.0070739551447331905, Neurons: 64, Grad norm: 1.567e+00\n",
      "Epoch 12875, Loss: 0.0070739551447331905, Neurons: 64, Grad norm: 1.567e+00\n",
      "Epoch 12876, Loss: 0.0070665497332811356, Neurons: 64, Grad norm: 1.349e+00\n",
      "Epoch 12876, Loss: 0.0070665497332811356, Neurons: 64, Grad norm: 1.349e+00\n",
      "Epoch 12877, Loss: 0.007056915666908026, Neurons: 64, Grad norm: 1.110e+00\n",
      "Epoch 12877, Loss: 0.007056915666908026, Neurons: 64, Grad norm: 1.110e+00\n",
      "Epoch 12878, Loss: 0.007046835497021675, Neurons: 64, Grad norm: 8.245e-01\n",
      "Epoch 12878, Loss: 0.007046835497021675, Neurons: 64, Grad norm: 8.245e-01\n",
      "Epoch 12879, Loss: 0.007037804462015629, Neurons: 64, Grad norm: 5.604e-01\n",
      "Epoch 12879, Loss: 0.007037804462015629, Neurons: 64, Grad norm: 5.604e-01\n",
      "Epoch 12880, Loss: 0.007030788343399763, Neurons: 64, Grad norm: 3.237e-01\n",
      "Epoch 12880, Loss: 0.007030788343399763, Neurons: 64, Grad norm: 3.237e-01\n",
      "Epoch 12881, Loss: 0.007026049308478832, Neurons: 64, Grad norm: 2.584e-01\n",
      "Epoch 12881, Loss: 0.007026049308478832, Neurons: 64, Grad norm: 2.584e-01\n",
      "Epoch 12882, Loss: 0.007023404352366924, Neurons: 64, Grad norm: 3.837e-01\n",
      "Epoch 12882, Loss: 0.007023404352366924, Neurons: 64, Grad norm: 3.837e-01\n",
      "Epoch 12883, Loss: 0.007022320292890072, Neurons: 64, Grad norm: 5.335e-01\n",
      "Epoch 12883, Loss: 0.007022320292890072, Neurons: 64, Grad norm: 5.335e-01\n",
      "Epoch 12884, Loss: 0.0070222122594714165, Neurons: 64, Grad norm: 6.779e-01\n",
      "Epoch 12884, Loss: 0.0070222122594714165, Neurons: 64, Grad norm: 6.779e-01\n",
      "Epoch 12885, Loss: 0.007022455800324678, Neurons: 64, Grad norm: 7.648e-01\n",
      "Epoch 12885, Loss: 0.007022455800324678, Neurons: 64, Grad norm: 7.648e-01\n",
      "Epoch 12886, Loss: 0.007022672798484564, Neurons: 64, Grad norm: 8.356e-01\n",
      "Epoch 12886, Loss: 0.007022672798484564, Neurons: 64, Grad norm: 8.356e-01\n",
      "Epoch 12887, Loss: 0.007022340316325426, Neurons: 64, Grad norm: 8.512e-01\n",
      "Epoch 12887, Loss: 0.007022340316325426, Neurons: 64, Grad norm: 8.512e-01\n",
      "Epoch 12888, Loss: 0.007021341472864151, Neurons: 64, Grad norm: 8.523e-01\n",
      "Epoch 12888, Loss: 0.007021341472864151, Neurons: 64, Grad norm: 8.523e-01\n",
      "Epoch 12889, Loss: 0.0070197926834225655, Neurons: 64, Grad norm: 8.080e-01\n",
      "Epoch 12889, Loss: 0.0070197926834225655, Neurons: 64, Grad norm: 8.080e-01\n",
      "Epoch 12890, Loss: 0.007017746102064848, Neurons: 64, Grad norm: 7.666e-01\n",
      "Epoch 12890, Loss: 0.007017746102064848, Neurons: 64, Grad norm: 7.666e-01\n",
      "Epoch 12891, Loss: 0.0070153712294995785, Neurons: 64, Grad norm: 6.872e-01\n",
      "Epoch 12891, Loss: 0.0070153712294995785, Neurons: 64, Grad norm: 6.872e-01\n",
      "Epoch 12892, Loss: 0.007012769114226103, Neurons: 64, Grad norm: 6.210e-01\n",
      "Epoch 12892, Loss: 0.007012769114226103, Neurons: 64, Grad norm: 6.210e-01\n",
      "Epoch 12893, Loss: 0.007010204717516899, Neurons: 64, Grad norm: 5.299e-01\n",
      "Epoch 12893, Loss: 0.007010204717516899, Neurons: 64, Grad norm: 5.299e-01\n",
      "Epoch 12894, Loss: 0.007007801439613104, Neurons: 64, Grad norm: 4.659e-01\n",
      "Epoch 12894, Loss: 0.007007801439613104, Neurons: 64, Grad norm: 4.659e-01\n",
      "Epoch 12895, Loss: 0.007005573716014624, Neurons: 64, Grad norm: 3.860e-01\n",
      "Epoch 12895, Loss: 0.007005573716014624, Neurons: 64, Grad norm: 3.860e-01\n",
      "Epoch 12896, Loss: 0.007003497332334518, Neurons: 64, Grad norm: 3.377e-01\n",
      "Epoch 12896, Loss: 0.007003497332334518, Neurons: 64, Grad norm: 3.377e-01\n",
      "Epoch 12897, Loss: 0.007001692429184914, Neurons: 64, Grad norm: 2.857e-01\n",
      "Epoch 12897, Loss: 0.007001692429184914, Neurons: 64, Grad norm: 2.857e-01\n",
      "Epoch 12898, Loss: 0.0069998824037611485, Neurons: 64, Grad norm: 2.630e-01\n",
      "Epoch 12898, Loss: 0.0069998824037611485, Neurons: 64, Grad norm: 2.630e-01\n",
      "Epoch 12899, Loss: 0.006998099386692047, Neurons: 64, Grad norm: 2.378e-01\n",
      "Epoch 12899, Loss: 0.006998099386692047, Neurons: 64, Grad norm: 2.378e-01\n",
      "Epoch 12899, Test loss: 0.005571889225393534\n",
      "Epoch 12899, Test loss: 0.005571889225393534\n",
      "Epoch 12900, Loss: 0.006996281910687685, Neurons: 64, Grad norm: 2.327e-01\n",
      "Epoch 12900, Loss: 0.006996281910687685, Neurons: 64, Grad norm: 2.327e-01\n",
      "Epoch 12901, Loss: 0.006994363386183977, Neurons: 64, Grad norm: 2.310e-01\n",
      "Epoch 12901, Loss: 0.006994363386183977, Neurons: 64, Grad norm: 2.310e-01\n",
      "Epoch 12902, Loss: 0.006992510054260492, Neurons: 64, Grad norm: 2.325e-01\n",
      "Epoch 12902, Loss: 0.006992510054260492, Neurons: 64, Grad norm: 2.325e-01\n",
      "Epoch 12903, Loss: 0.006990722380578518, Neurons: 64, Grad norm: 2.417e-01\n",
      "Epoch 12903, Loss: 0.006990722380578518, Neurons: 64, Grad norm: 2.417e-01\n",
      "Epoch 12904, Loss: 0.006988882552832365, Neurons: 64, Grad norm: 2.408e-01\n",
      "Epoch 12904, Loss: 0.006988882552832365, Neurons: 64, Grad norm: 2.408e-01\n",
      "Epoch 12905, Loss: 0.006987139116972685, Neurons: 64, Grad norm: 2.515e-01\n",
      "Epoch 12905, Loss: 0.006987139116972685, Neurons: 64, Grad norm: 2.515e-01\n",
      "Epoch 12906, Loss: 0.0069853696040809155, Neurons: 64, Grad norm: 2.491e-01\n",
      "Epoch 12906, Loss: 0.0069853696040809155, Neurons: 64, Grad norm: 2.491e-01\n",
      "Epoch 12907, Loss: 0.006983636412769556, Neurons: 64, Grad norm: 2.592e-01\n",
      "Epoch 12907, Loss: 0.006983636412769556, Neurons: 64, Grad norm: 2.592e-01\n",
      "Epoch 12908, Loss: 0.0069819348864257336, Neurons: 64, Grad norm: 2.542e-01\n",
      "Epoch 12908, Loss: 0.0069819348864257336, Neurons: 64, Grad norm: 2.542e-01\n",
      "Epoch 12909, Loss: 0.006980293430387974, Neurons: 64, Grad norm: 2.671e-01\n",
      "Epoch 12909, Loss: 0.006980293430387974, Neurons: 64, Grad norm: 2.671e-01\n",
      "Epoch 12910, Loss: 0.006978715304285288, Neurons: 64, Grad norm: 2.608e-01\n",
      "Epoch 12910, Loss: 0.006978715304285288, Neurons: 64, Grad norm: 2.608e-01\n",
      "Epoch 12911, Loss: 0.006977153941988945, Neurons: 64, Grad norm: 2.744e-01\n",
      "Epoch 12911, Loss: 0.006977153941988945, Neurons: 64, Grad norm: 2.744e-01\n",
      "Epoch 12912, Loss: 0.00697563961148262, Neurons: 64, Grad norm: 2.716e-01\n",
      "Epoch 12912, Loss: 0.00697563961148262, Neurons: 64, Grad norm: 2.716e-01\n",
      "Epoch 12913, Loss: 0.006974182557314634, Neurons: 64, Grad norm: 2.961e-01\n",
      "Epoch 12913, Loss: 0.006974182557314634, Neurons: 64, Grad norm: 2.961e-01\n",
      "Epoch 12914, Loss: 0.006972754839807749, Neurons: 64, Grad norm: 2.981e-01\n",
      "Epoch 12914, Loss: 0.006972754839807749, Neurons: 64, Grad norm: 2.981e-01\n",
      "Epoch 12915, Loss: 0.006971394643187523, Neurons: 64, Grad norm: 3.271e-01\n",
      "Epoch 12915, Loss: 0.006971394643187523, Neurons: 64, Grad norm: 3.271e-01\n",
      "Epoch 12916, Loss: 0.006970175076276064, Neurons: 64, Grad norm: 3.423e-01\n",
      "Epoch 12916, Loss: 0.006970175076276064, Neurons: 64, Grad norm: 3.423e-01\n",
      "Epoch 12917, Loss: 0.006968987639993429, Neurons: 64, Grad norm: 3.828e-01\n",
      "Epoch 12917, Loss: 0.006968987639993429, Neurons: 64, Grad norm: 3.828e-01\n",
      "Epoch 12918, Loss: 0.006967896595597267, Neurons: 64, Grad norm: 4.071e-01\n",
      "Epoch 12918, Loss: 0.006967896595597267, Neurons: 64, Grad norm: 4.071e-01\n",
      "Epoch 12919, Loss: 0.006966898217797279, Neurons: 64, Grad norm: 4.617e-01\n",
      "Epoch 12919, Loss: 0.006966898217797279, Neurons: 64, Grad norm: 4.617e-01\n",
      "Epoch 12920, Loss: 0.006966040935367346, Neurons: 64, Grad norm: 5.009e-01\n",
      "Epoch 12920, Loss: 0.006966040935367346, Neurons: 64, Grad norm: 5.009e-01\n",
      "Epoch 12921, Loss: 0.006965507287532091, Neurons: 64, Grad norm: 5.707e-01\n",
      "Epoch 12921, Loss: 0.006965507287532091, Neurons: 64, Grad norm: 5.707e-01\n",
      "Epoch 12922, Loss: 0.00696515990421176, Neurons: 64, Grad norm: 6.304e-01\n",
      "Epoch 12922, Loss: 0.00696515990421176, Neurons: 64, Grad norm: 6.304e-01\n",
      "Epoch 12923, Loss: 0.006965226493775845, Neurons: 64, Grad norm: 7.264e-01\n",
      "Epoch 12923, Loss: 0.006965226493775845, Neurons: 64, Grad norm: 7.264e-01\n",
      "Epoch 12924, Loss: 0.006965809501707554, Neurons: 64, Grad norm: 8.160e-01\n",
      "Epoch 12924, Loss: 0.006965809501707554, Neurons: 64, Grad norm: 8.160e-01\n",
      "Epoch 12925, Loss: 0.006967212073504925, Neurons: 64, Grad norm: 9.460e-01\n",
      "Epoch 12925, Loss: 0.006967212073504925, Neurons: 64, Grad norm: 9.460e-01\n",
      "Epoch 12926, Loss: 0.00696970708668232, Neurons: 64, Grad norm: 1.076e+00\n",
      "Epoch 12926, Loss: 0.00696970708668232, Neurons: 64, Grad norm: 1.076e+00\n",
      "Epoch 12927, Loss: 0.006973658688366413, Neurons: 64, Grad norm: 1.260e+00\n",
      "Epoch 12927, Loss: 0.006973658688366413, Neurons: 64, Grad norm: 1.260e+00\n",
      "Epoch 12928, Loss: 0.006979680620133877, Neurons: 64, Grad norm: 1.448e+00\n",
      "Epoch 12928, Loss: 0.006979680620133877, Neurons: 64, Grad norm: 1.448e+00\n",
      "Epoch 12929, Loss: 0.006988512352108955, Neurons: 64, Grad norm: 1.697e+00\n",
      "Epoch 12929, Loss: 0.006988512352108955, Neurons: 64, Grad norm: 1.697e+00\n",
      "Epoch 12930, Loss: 0.007001177873462439, Neurons: 64, Grad norm: 1.974e+00\n",
      "Epoch 12930, Loss: 0.007001177873462439, Neurons: 64, Grad norm: 1.974e+00\n",
      "Epoch 12931, Loss: 0.007019374519586563, Neurons: 64, Grad norm: 2.324e+00\n",
      "Epoch 12931, Loss: 0.007019374519586563, Neurons: 64, Grad norm: 2.324e+00\n",
      "Epoch 12932, Loss: 0.00704549252986908, Neurons: 64, Grad norm: 2.713e+00\n",
      "Epoch 12932, Loss: 0.00704549252986908, Neurons: 64, Grad norm: 2.713e+00\n",
      "Epoch 12933, Loss: 0.007082273717969656, Neurons: 64, Grad norm: 3.200e+00\n",
      "Epoch 12933, Loss: 0.007082273717969656, Neurons: 64, Grad norm: 3.200e+00\n",
      "Epoch 12934, Loss: 0.007133952807635069, Neurons: 64, Grad norm: 3.740e+00\n",
      "Epoch 12934, Loss: 0.007133952807635069, Neurons: 64, Grad norm: 3.740e+00\n",
      "Epoch 12935, Loss: 0.007204140070825815, Neurons: 64, Grad norm: 4.379e+00\n",
      "Epoch 12935, Loss: 0.007204140070825815, Neurons: 64, Grad norm: 4.379e+00\n",
      "Epoch 12936, Loss: 0.007298053242266178, Neurons: 64, Grad norm: 5.064e+00\n",
      "Epoch 12936, Loss: 0.007298053242266178, Neurons: 64, Grad norm: 5.064e+00\n",
      "Epoch 12937, Loss: 0.007417112588882446, Neurons: 64, Grad norm: 5.809e+00\n",
      "Epoch 12937, Loss: 0.007417112588882446, Neurons: 64, Grad norm: 5.809e+00\n",
      "Epoch 12938, Loss: 0.007559905294328928, Neurons: 64, Grad norm: 6.523e+00\n",
      "Epoch 12938, Loss: 0.007559905294328928, Neurons: 64, Grad norm: 6.523e+00\n",
      "Epoch 12939, Loss: 0.007713026367127895, Neurons: 64, Grad norm: 7.162e+00\n",
      "Epoch 12939, Loss: 0.007713026367127895, Neurons: 64, Grad norm: 7.162e+00\n",
      "Epoch 12940, Loss: 0.007850482128560543, Neurons: 64, Grad norm: 7.572e+00\n",
      "Epoch 12940, Loss: 0.007850482128560543, Neurons: 64, Grad norm: 7.572e+00\n",
      "Epoch 12941, Loss: 0.007933463901281357, Neurons: 64, Grad norm: 7.671e+00\n",
      "Epoch 12941, Loss: 0.007933463901281357, Neurons: 64, Grad norm: 7.671e+00\n",
      "Epoch 12942, Loss: 0.007921230979263783, Neurons: 64, Grad norm: 7.307e+00\n",
      "Epoch 12942, Loss: 0.007921230979263783, Neurons: 64, Grad norm: 7.307e+00\n",
      "Epoch 12943, Loss: 0.007795980665832758, Neurons: 64, Grad norm: 6.486e+00\n",
      "Epoch 12943, Loss: 0.007795980665832758, Neurons: 64, Grad norm: 6.486e+00\n",
      "Epoch 12944, Loss: 0.007580993231385946, Neurons: 64, Grad norm: 5.233e+00\n",
      "Epoch 12944, Loss: 0.007580993231385946, Neurons: 64, Grad norm: 5.233e+00\n",
      "Epoch 12945, Loss: 0.007343866862356663, Neurons: 64, Grad norm: 3.756e+00\n",
      "Epoch 12945, Loss: 0.007343866862356663, Neurons: 64, Grad norm: 3.756e+00\n",
      "Epoch 12946, Loss: 0.007161082699894905, Neurons: 64, Grad norm: 2.335e+00\n",
      "Epoch 12946, Loss: 0.007161082699894905, Neurons: 64, Grad norm: 2.335e+00\n",
      "Epoch 12947, Loss: 0.007081218995153904, Neurons: 64, Grad norm: 1.653e+00\n",
      "Epoch 12947, Loss: 0.007081218995153904, Neurons: 64, Grad norm: 1.653e+00\n",
      "Epoch 12948, Loss: 0.0070991525426507, Neurons: 64, Grad norm: 2.103e+00\n",
      "Epoch 12948, Loss: 0.0070991525426507, Neurons: 64, Grad norm: 2.103e+00\n",
      "Epoch 12949, Loss: 0.007165425457060337, Neurons: 64, Grad norm: 2.766e+00\n",
      "Epoch 12949, Loss: 0.007165425457060337, Neurons: 64, Grad norm: 2.766e+00\n",
      "Epoch 12950, Loss: 0.0072156204842031, Neurons: 64, Grad norm: 3.159e+00\n",
      "Epoch 12950, Loss: 0.0072156204842031, Neurons: 64, Grad norm: 3.159e+00\n",
      "Epoch 12951, Loss: 0.007206920068711042, Neurons: 64, Grad norm: 3.141e+00\n",
      "Epoch 12951, Loss: 0.007206920068711042, Neurons: 64, Grad norm: 3.141e+00\n",
      "Epoch 12952, Loss: 0.00713864341378212, Neurons: 64, Grad norm: 2.815e+00\n",
      "Epoch 12952, Loss: 0.00713864341378212, Neurons: 64, Grad norm: 2.815e+00\n",
      "Epoch 12953, Loss: 0.007051124703139067, Neurons: 64, Grad norm: 2.293e+00\n",
      "Epoch 12953, Loss: 0.007051124703139067, Neurons: 64, Grad norm: 2.293e+00\n",
      "Epoch 12954, Loss: 0.006993881892412901, Neurons: 64, Grad norm: 1.825e+00\n",
      "Epoch 12954, Loss: 0.006993881892412901, Neurons: 64, Grad norm: 1.825e+00\n",
      "Epoch 12955, Loss: 0.006989818066358566, Neurons: 64, Grad norm: 1.570e+00\n",
      "Epoch 12955, Loss: 0.006989818066358566, Neurons: 64, Grad norm: 1.570e+00\n",
      "Epoch 12956, Loss: 0.007025900296866894, Neurons: 64, Grad norm: 1.552e+00\n",
      "Epoch 12956, Loss: 0.007025900296866894, Neurons: 64, Grad norm: 1.552e+00\n",
      "Epoch 12957, Loss: 0.007064685225486755, Neurons: 64, Grad norm: 1.558e+00\n",
      "Epoch 12957, Loss: 0.007064685225486755, Neurons: 64, Grad norm: 1.558e+00\n",
      "Epoch 12958, Loss: 0.007070734165608883, Neurons: 64, Grad norm: 1.418e+00\n",
      "Epoch 12958, Loss: 0.007070734165608883, Neurons: 64, Grad norm: 1.418e+00\n",
      "Epoch 12959, Loss: 0.007033194415271282, Neurons: 64, Grad norm: 1.126e+00\n",
      "Epoch 12959, Loss: 0.007033194415271282, Neurons: 64, Grad norm: 1.126e+00\n",
      "Epoch 12960, Loss: 0.006971648428589106, Neurons: 64, Grad norm: 7.427e-01\n",
      "Epoch 12960, Loss: 0.006971648428589106, Neurons: 64, Grad norm: 7.427e-01\n",
      "Epoch 12961, Loss: 0.006921418011188507, Neurons: 64, Grad norm: 5.606e-01\n",
      "Epoch 12961, Loss: 0.006921418011188507, Neurons: 64, Grad norm: 5.606e-01\n",
      "Epoch 12962, Loss: 0.006907172966748476, Neurons: 64, Grad norm: 7.483e-01\n",
      "Epoch 12962, Loss: 0.006907172966748476, Neurons: 64, Grad norm: 7.483e-01\n",
      "Epoch 12963, Loss: 0.006928199902176857, Neurons: 64, Grad norm: 1.016e+00\n",
      "Epoch 12963, Loss: 0.006928199902176857, Neurons: 64, Grad norm: 1.016e+00\n",
      "Epoch 12964, Loss: 0.006962318904697895, Neurons: 64, Grad norm: 1.156e+00\n",
      "Epoch 12964, Loss: 0.006962318904697895, Neurons: 64, Grad norm: 1.156e+00\n",
      "Epoch 12965, Loss: 0.006983164697885513, Neurons: 64, Grad norm: 1.124e+00\n",
      "Epoch 12965, Loss: 0.006983164697885513, Neurons: 64, Grad norm: 1.124e+00\n",
      "Epoch 12966, Loss: 0.0069768354296684265, Neurons: 64, Grad norm: 9.443e-01\n",
      "Epoch 12966, Loss: 0.0069768354296684265, Neurons: 64, Grad norm: 9.443e-01\n",
      "Epoch 12967, Loss: 0.006948490627110004, Neurons: 64, Grad norm: 6.943e-01\n",
      "Epoch 12967, Loss: 0.006948490627110004, Neurons: 64, Grad norm: 6.943e-01\n",
      "Epoch 12968, Loss: 0.006916163023561239, Neurons: 64, Grad norm: 5.129e-01\n",
      "Epoch 12968, Loss: 0.006916163023561239, Neurons: 64, Grad norm: 5.129e-01\n",
      "Epoch 12969, Loss: 0.0068973032757639885, Neurons: 64, Grad norm: 5.676e-01\n",
      "Epoch 12969, Loss: 0.0068973032757639885, Neurons: 64, Grad norm: 5.676e-01\n",
      "Epoch 12970, Loss: 0.0068973940797150135, Neurons: 64, Grad norm: 6.970e-01\n",
      "Epoch 12970, Loss: 0.0068973940797150135, Neurons: 64, Grad norm: 6.970e-01\n",
      "Epoch 12971, Loss: 0.006909161806106567, Neurons: 64, Grad norm: 7.820e-01\n",
      "Epoch 12971, Loss: 0.006909161806106567, Neurons: 64, Grad norm: 7.820e-01\n",
      "Epoch 12972, Loss: 0.0069198221899569035, Neurons: 64, Grad norm: 7.399e-01\n",
      "Epoch 12972, Loss: 0.0069198221899569035, Neurons: 64, Grad norm: 7.399e-01\n",
      "Epoch 12973, Loss: 0.006920312996953726, Neurons: 64, Grad norm: 6.179e-01\n",
      "Epoch 12973, Loss: 0.006920312996953726, Neurons: 64, Grad norm: 6.179e-01\n",
      "Epoch 12974, Loss: 0.006910305470228195, Neurons: 64, Grad norm: 4.684e-01\n",
      "Epoch 12974, Loss: 0.006910305470228195, Neurons: 64, Grad norm: 4.684e-01\n",
      "Epoch 12975, Loss: 0.006896641105413437, Neurons: 64, Grad norm: 4.436e-01\n",
      "Epoch 12975, Loss: 0.006896641105413437, Neurons: 64, Grad norm: 4.436e-01\n",
      "Epoch 12976, Loss: 0.006887187249958515, Neurons: 64, Grad norm: 5.875e-01\n",
      "Epoch 12976, Loss: 0.006887187249958515, Neurons: 64, Grad norm: 5.875e-01\n",
      "Epoch 12977, Loss: 0.0068858107551932335, Neurons: 64, Grad norm: 7.364e-01\n",
      "Epoch 12977, Loss: 0.0068858107551932335, Neurons: 64, Grad norm: 7.364e-01\n",
      "Epoch 12978, Loss: 0.006890380755066872, Neurons: 64, Grad norm: 8.454e-01\n",
      "Epoch 12978, Loss: 0.006890380755066872, Neurons: 64, Grad norm: 8.454e-01\n",
      "Epoch 12979, Loss: 0.006895384751260281, Neurons: 64, Grad norm: 8.356e-01\n",
      "Epoch 12979, Loss: 0.006895384751260281, Neurons: 64, Grad norm: 8.356e-01\n",
      "Epoch 12980, Loss: 0.006895977538079023, Neurons: 64, Grad norm: 7.493e-01\n",
      "Epoch 12980, Loss: 0.006895977538079023, Neurons: 64, Grad norm: 7.493e-01\n",
      "Epoch 12981, Loss: 0.006891241297125816, Neurons: 64, Grad norm: 5.620e-01\n",
      "Epoch 12981, Loss: 0.006891241297125816, Neurons: 64, Grad norm: 5.620e-01\n",
      "Epoch 12982, Loss: 0.006883027032017708, Neurons: 64, Grad norm: 3.477e-01\n",
      "Epoch 12982, Loss: 0.006883027032017708, Neurons: 64, Grad norm: 3.477e-01\n",
      "Epoch 12983, Loss: 0.006875389255583286, Neurons: 64, Grad norm: 1.030e-01\n",
      "Epoch 12983, Loss: 0.006875389255583286, Neurons: 64, Grad norm: 1.030e-01\n",
      "Epoch 12984, Loss: 0.0068709757179021835, Neurons: 64, Grad norm: 1.357e-01\n",
      "Epoch 12984, Loss: 0.0068709757179021835, Neurons: 64, Grad norm: 1.357e-01\n",
      "Epoch 12985, Loss: 0.006870432756841183, Neurons: 64, Grad norm: 3.230e-01\n",
      "Epoch 12985, Loss: 0.006870432756841183, Neurons: 64, Grad norm: 3.230e-01\n",
      "Epoch 12986, Loss: 0.00687210401520133, Neurons: 64, Grad norm: 4.328e-01\n",
      "Epoch 12986, Loss: 0.00687210401520133, Neurons: 64, Grad norm: 4.328e-01\n",
      "Epoch 12987, Loss: 0.006873628124594688, Neurons: 64, Grad norm: 4.968e-01\n",
      "Epoch 12987, Loss: 0.006873628124594688, Neurons: 64, Grad norm: 4.968e-01\n",
      "Epoch 12988, Loss: 0.006873103324323893, Neurons: 64, Grad norm: 4.788e-01\n",
      "Epoch 12988, Loss: 0.006873103324323893, Neurons: 64, Grad norm: 4.788e-01\n",
      "Epoch 12989, Loss: 0.006870451383292675, Neurons: 64, Grad norm: 4.391e-01\n",
      "Epoch 12989, Loss: 0.006870451383292675, Neurons: 64, Grad norm: 4.391e-01\n",
      "Epoch 12990, Loss: 0.00686665391549468, Neurons: 64, Grad norm: 3.563e-01\n",
      "Epoch 12990, Loss: 0.00686665391549468, Neurons: 64, Grad norm: 3.563e-01\n",
      "Epoch 12991, Loss: 0.00686316704377532, Neurons: 64, Grad norm: 3.060e-01\n",
      "Epoch 12991, Loss: 0.00686316704377532, Neurons: 64, Grad norm: 3.060e-01\n",
      "Epoch 12992, Loss: 0.006861055735498667, Neurons: 64, Grad norm: 2.696e-01\n",
      "Epoch 12992, Loss: 0.006861055735498667, Neurons: 64, Grad norm: 2.696e-01\n",
      "Epoch 12993, Loss: 0.006860277149826288, Neurons: 64, Grad norm: 2.778e-01\n",
      "Epoch 12993, Loss: 0.006860277149826288, Neurons: 64, Grad norm: 2.778e-01\n",
      "Epoch 12994, Loss: 0.0068601821549236774, Neurons: 64, Grad norm: 2.862e-01\n",
      "Epoch 12994, Loss: 0.0068601821549236774, Neurons: 64, Grad norm: 2.862e-01\n",
      "Epoch 12995, Loss: 0.006859905086457729, Neurons: 64, Grad norm: 2.882e-01\n",
      "Epoch 12995, Loss: 0.006859905086457729, Neurons: 64, Grad norm: 2.882e-01\n",
      "Epoch 12996, Loss: 0.006858746986836195, Neurons: 64, Grad norm: 2.685e-01\n",
      "Epoch 12996, Loss: 0.006858746986836195, Neurons: 64, Grad norm: 2.685e-01\n",
      "Epoch 12997, Loss: 0.006856780964881182, Neurons: 64, Grad norm: 2.351e-01\n",
      "Epoch 12997, Loss: 0.006856780964881182, Neurons: 64, Grad norm: 2.351e-01\n",
      "Epoch 12998, Loss: 0.006854091305285692, Neurons: 64, Grad norm: 1.932e-01\n",
      "Epoch 12998, Loss: 0.006854091305285692, Neurons: 64, Grad norm: 1.932e-01\n",
      "Epoch 12999, Loss: 0.006851347628980875, Neurons: 64, Grad norm: 1.788e-01\n",
      "Epoch 12999, Loss: 0.006851347628980875, Neurons: 64, Grad norm: 1.788e-01\n",
      "Epoch 12999, Test loss: 0.005476400721818209\n",
      "Epoch 12999, Test loss: 0.005476400721818209\n",
      "Epoch 13000, Loss: 0.006849048193544149, Neurons: 64, Grad norm: 1.773e-01\n",
      "Epoch 13000, Loss: 0.006849048193544149, Neurons: 64, Grad norm: 1.773e-01\n",
      "Epoch 13001, Loss: 0.00684752594679594, Neurons: 64, Grad norm: 2.125e-01\n",
      "Epoch 13001, Loss: 0.00684752594679594, Neurons: 64, Grad norm: 2.125e-01\n",
      "Epoch 13002, Loss: 0.006846510339528322, Neurons: 64, Grad norm: 2.234e-01\n",
      "Epoch 13002, Loss: 0.006846510339528322, Neurons: 64, Grad norm: 2.234e-01\n",
      "Epoch 13003, Loss: 0.006845693103969097, Neurons: 64, Grad norm: 2.418e-01\n",
      "Epoch 13003, Loss: 0.006845693103969097, Neurons: 64, Grad norm: 2.418e-01\n",
      "Epoch 13004, Loss: 0.006844578310847282, Neurons: 64, Grad norm: 2.169e-01\n",
      "Epoch 13004, Loss: 0.006844578310847282, Neurons: 64, Grad norm: 2.169e-01\n",
      "Epoch 13005, Loss: 0.006843159906566143, Neurons: 64, Grad norm: 1.960e-01\n",
      "Epoch 13005, Loss: 0.006843159906566143, Neurons: 64, Grad norm: 1.960e-01\n",
      "Epoch 13006, Loss: 0.0068413205444812775, Neurons: 64, Grad norm: 1.410e-01\n",
      "Epoch 13006, Loss: 0.0068413205444812775, Neurons: 64, Grad norm: 1.410e-01\n",
      "Epoch 13007, Loss: 0.006839344277977943, Neurons: 64, Grad norm: 9.896e-02\n",
      "Epoch 13007, Loss: 0.006839344277977943, Neurons: 64, Grad norm: 9.896e-02\n",
      "Epoch 13008, Loss: 0.006837473250925541, Neurons: 64, Grad norm: 3.754e-02\n",
      "Epoch 13008, Loss: 0.006837473250925541, Neurons: 64, Grad norm: 3.754e-02\n",
      "Epoch 13009, Loss: 0.00683584064245224, Neurons: 64, Grad norm: 3.466e-02\n",
      "Epoch 13009, Loss: 0.00683584064245224, Neurons: 64, Grad norm: 3.466e-02\n",
      "Epoch 13010, Loss: 0.006834532134234905, Neurons: 64, Grad norm: 7.149e-02\n",
      "Epoch 13010, Loss: 0.006834532134234905, Neurons: 64, Grad norm: 7.149e-02\n",
      "Epoch 13011, Loss: 0.006833337247371674, Neurons: 64, Grad norm: 9.238e-02\n",
      "Epoch 13011, Loss: 0.006833337247371674, Neurons: 64, Grad norm: 9.238e-02\n",
      "Epoch 13012, Loss: 0.006832170765846968, Neurons: 64, Grad norm: 1.178e-01\n",
      "Epoch 13012, Loss: 0.006832170765846968, Neurons: 64, Grad norm: 1.178e-01\n",
      "Epoch 13013, Loss: 0.006831008475273848, Neurons: 64, Grad norm: 1.154e-01\n",
      "Epoch 13013, Loss: 0.006831008475273848, Neurons: 64, Grad norm: 1.154e-01\n",
      "Epoch 13014, Loss: 0.006829672958701849, Neurons: 64, Grad norm: 1.181e-01\n",
      "Epoch 13014, Loss: 0.006829672958701849, Neurons: 64, Grad norm: 1.181e-01\n",
      "Epoch 13015, Loss: 0.006828220095485449, Neurons: 64, Grad norm: 9.664e-02\n",
      "Epoch 13015, Loss: 0.006828220095485449, Neurons: 64, Grad norm: 9.664e-02\n",
      "Epoch 13016, Loss: 0.006826637778431177, Neurons: 64, Grad norm: 8.034e-02\n",
      "Epoch 13016, Loss: 0.006826637778431177, Neurons: 64, Grad norm: 8.034e-02\n",
      "Epoch 13017, Loss: 0.006825014483183622, Neurons: 64, Grad norm: 4.578e-02\n",
      "Epoch 13017, Loss: 0.006825014483183622, Neurons: 64, Grad norm: 4.578e-02\n",
      "Epoch 13018, Loss: 0.006823424715548754, Neurons: 64, Grad norm: 2.343e-02\n",
      "Epoch 13018, Loss: 0.006823424715548754, Neurons: 64, Grad norm: 2.343e-02\n",
      "Epoch 13019, Loss: 0.006821917835623026, Neurons: 64, Grad norm: 3.035e-02\n",
      "Epoch 13019, Loss: 0.006821917835623026, Neurons: 64, Grad norm: 3.035e-02\n",
      "Epoch 13020, Loss: 0.0068204705603420734, Neurons: 64, Grad norm: 4.433e-02\n",
      "Epoch 13020, Loss: 0.0068204705603420734, Neurons: 64, Grad norm: 4.433e-02\n",
      "Epoch 13021, Loss: 0.006819180212914944, Neurons: 64, Grad norm: 7.661e-02\n",
      "Epoch 13021, Loss: 0.006819180212914944, Neurons: 64, Grad norm: 7.661e-02\n",
      "Epoch 13022, Loss: 0.006817884277552366, Neurons: 64, Grad norm: 7.946e-02\n",
      "Epoch 13022, Loss: 0.006817884277552366, Neurons: 64, Grad norm: 7.946e-02\n",
      "Epoch 13023, Loss: 0.006816605571657419, Neurons: 64, Grad norm: 9.938e-02\n",
      "Epoch 13023, Loss: 0.006816605571657419, Neurons: 64, Grad norm: 9.938e-02\n",
      "Epoch 13024, Loss: 0.006815216038376093, Neurons: 64, Grad norm: 9.310e-02\n",
      "Epoch 13024, Loss: 0.006815216038376093, Neurons: 64, Grad norm: 9.310e-02\n",
      "Epoch 13025, Loss: 0.006813810206949711, Neurons: 64, Grad norm: 9.815e-02\n",
      "Epoch 13025, Loss: 0.006813810206949711, Neurons: 64, Grad norm: 9.815e-02\n",
      "Epoch 13026, Loss: 0.006812409497797489, Neurons: 64, Grad norm: 7.998e-02\n",
      "Epoch 13026, Loss: 0.006812409497797489, Neurons: 64, Grad norm: 7.998e-02\n",
      "Epoch 13027, Loss: 0.0068109240382909775, Neurons: 64, Grad norm: 8.334e-02\n",
      "Epoch 13027, Loss: 0.0068109240382909775, Neurons: 64, Grad norm: 8.334e-02\n",
      "Epoch 13028, Loss: 0.006809439975768328, Neurons: 64, Grad norm: 6.622e-02\n",
      "Epoch 13028, Loss: 0.006809439975768328, Neurons: 64, Grad norm: 6.622e-02\n",
      "Epoch 13029, Loss: 0.00680798664689064, Neurons: 64, Grad norm: 7.218e-02\n",
      "Epoch 13029, Loss: 0.00680798664689064, Neurons: 64, Grad norm: 7.218e-02\n",
      "Epoch 13030, Loss: 0.006806571502238512, Neurons: 64, Grad norm: 6.160e-02\n",
      "Epoch 13030, Loss: 0.006806571502238512, Neurons: 64, Grad norm: 6.160e-02\n",
      "Epoch 13031, Loss: 0.006805183831602335, Neurons: 64, Grad norm: 8.009e-02\n",
      "Epoch 13031, Loss: 0.006805183831602335, Neurons: 64, Grad norm: 8.009e-02\n",
      "Epoch 13032, Loss: 0.006803849712014198, Neurons: 64, Grad norm: 8.679e-02\n",
      "Epoch 13032, Loss: 0.006803849712014198, Neurons: 64, Grad norm: 8.679e-02\n",
      "Epoch 13033, Loss: 0.006802517920732498, Neurons: 64, Grad norm: 1.095e-01\n",
      "Epoch 13033, Loss: 0.006802517920732498, Neurons: 64, Grad norm: 1.095e-01\n",
      "Epoch 13034, Loss: 0.0068012410774827, Neurons: 64, Grad norm: 1.235e-01\n",
      "Epoch 13034, Loss: 0.0068012410774827, Neurons: 64, Grad norm: 1.235e-01\n",
      "Epoch 13035, Loss: 0.006799967959523201, Neurons: 64, Grad norm: 1.558e-01\n",
      "Epoch 13035, Loss: 0.006799967959523201, Neurons: 64, Grad norm: 1.558e-01\n",
      "Epoch 13036, Loss: 0.006798706483095884, Neurons: 64, Grad norm: 1.812e-01\n",
      "Epoch 13036, Loss: 0.006798706483095884, Neurons: 64, Grad norm: 1.812e-01\n",
      "Epoch 13037, Loss: 0.006797500886023045, Neurons: 64, Grad norm: 2.346e-01\n",
      "Epoch 13037, Loss: 0.006797500886023045, Neurons: 64, Grad norm: 2.346e-01\n",
      "Epoch 13038, Loss: 0.006796420551836491, Neurons: 64, Grad norm: 2.774e-01\n",
      "Epoch 13038, Loss: 0.006796420551836491, Neurons: 64, Grad norm: 2.774e-01\n",
      "Epoch 13039, Loss: 0.006795419845730066, Neurons: 64, Grad norm: 3.541e-01\n",
      "Epoch 13039, Loss: 0.006795419845730066, Neurons: 64, Grad norm: 3.541e-01\n",
      "Epoch 13040, Loss: 0.006794700864702463, Neurons: 64, Grad norm: 4.286e-01\n",
      "Epoch 13040, Loss: 0.006794700864702463, Neurons: 64, Grad norm: 4.286e-01\n",
      "Epoch 13041, Loss: 0.006794299464672804, Neurons: 64, Grad norm: 5.407e-01\n",
      "Epoch 13041, Loss: 0.006794299464672804, Neurons: 64, Grad norm: 5.407e-01\n",
      "Epoch 13042, Loss: 0.006794569548219442, Neurons: 64, Grad norm: 6.649e-01\n",
      "Epoch 13042, Loss: 0.006794569548219442, Neurons: 64, Grad norm: 6.649e-01\n",
      "Epoch 13043, Loss: 0.00679568899795413, Neurons: 64, Grad norm: 8.428e-01\n",
      "Epoch 13043, Loss: 0.00679568899795413, Neurons: 64, Grad norm: 8.428e-01\n",
      "Epoch 13044, Loss: 0.0067982859909534454, Neurons: 64, Grad norm: 1.043e+00\n",
      "Epoch 13044, Loss: 0.0067982859909534454, Neurons: 64, Grad norm: 1.043e+00\n",
      "Epoch 13045, Loss: 0.0068033114075660706, Neurons: 64, Grad norm: 1.322e+00\n",
      "Epoch 13045, Loss: 0.0068033114075660706, Neurons: 64, Grad norm: 1.322e+00\n",
      "Epoch 13046, Loss: 0.006812188308686018, Neurons: 64, Grad norm: 1.654e+00\n",
      "Epoch 13046, Loss: 0.006812188308686018, Neurons: 64, Grad norm: 1.654e+00\n",
      "Epoch 13047, Loss: 0.0068272920325398445, Neurons: 64, Grad norm: 2.098e+00\n",
      "Epoch 13047, Loss: 0.0068272920325398445, Neurons: 64, Grad norm: 2.098e+00\n",
      "Epoch 13048, Loss: 0.006852129939943552, Neurons: 64, Grad norm: 2.636e+00\n",
      "Epoch 13048, Loss: 0.006852129939943552, Neurons: 64, Grad norm: 2.636e+00\n",
      "Epoch 13049, Loss: 0.006892948877066374, Neurons: 64, Grad norm: 3.338e+00\n",
      "Epoch 13049, Loss: 0.006892948877066374, Neurons: 64, Grad norm: 3.338e+00\n",
      "Epoch 13050, Loss: 0.00695844879373908, Neurons: 64, Grad norm: 4.200e+00\n",
      "Epoch 13050, Loss: 0.00695844879373908, Neurons: 64, Grad norm: 4.200e+00\n",
      "Epoch 13051, Loss: 0.007063513156026602, Neurons: 64, Grad norm: 5.285e+00\n",
      "Epoch 13051, Loss: 0.007063513156026602, Neurons: 64, Grad norm: 5.285e+00\n",
      "Epoch 13052, Loss: 0.0072264340706169605, Neurons: 64, Grad norm: 6.562e+00\n",
      "Epoch 13052, Loss: 0.0072264340706169605, Neurons: 64, Grad norm: 6.562e+00\n",
      "Epoch 13053, Loss: 0.007471899036318064, Neurons: 64, Grad norm: 8.043e+00\n",
      "Epoch 13053, Loss: 0.007471899036318064, Neurons: 64, Grad norm: 8.043e+00\n",
      "Epoch 13054, Loss: 0.007814259268343449, Neurons: 64, Grad norm: 9.567e+00\n",
      "Epoch 13054, Loss: 0.007814259268343449, Neurons: 64, Grad norm: 9.567e+00\n",
      "Epoch 13055, Loss: 0.008245375007390976, Neurons: 64, Grad norm: 1.092e+01\n",
      "Epoch 13055, Loss: 0.008245375007390976, Neurons: 64, Grad norm: 1.092e+01\n",
      "Epoch 13056, Loss: 0.00867432076483965, Neurons: 64, Grad norm: 1.165e+01\n",
      "Epoch 13056, Loss: 0.00867432076483965, Neurons: 64, Grad norm: 1.165e+01\n",
      "Epoch 13057, Loss: 0.008929429575800896, Neurons: 64, Grad norm: 1.131e+01\n",
      "Epoch 13057, Loss: 0.008929429575800896, Neurons: 64, Grad norm: 1.131e+01\n",
      "Epoch 13058, Loss: 0.008776569738984108, Neurons: 64, Grad norm: 9.521e+00\n",
      "Epoch 13058, Loss: 0.008776569738984108, Neurons: 64, Grad norm: 9.521e+00\n",
      "Epoch 13059, Loss: 0.008174656890332699, Neurons: 64, Grad norm: 6.399e+00\n",
      "Epoch 13059, Loss: 0.008174656890332699, Neurons: 64, Grad norm: 6.399e+00\n",
      "Epoch 13060, Loss: 0.0073910066857934, Neurons: 64, Grad norm: 2.527e+00\n",
      "Epoch 13060, Loss: 0.0073910066857934, Neurons: 64, Grad norm: 2.527e+00\n",
      "Epoch 13061, Loss: 0.006881010718643665, Neurons: 64, Grad norm: 1.850e+00\n",
      "Epoch 13061, Loss: 0.006881010718643665, Neurons: 64, Grad norm: 1.850e+00\n",
      "Epoch 13062, Loss: 0.006878086365759373, Neurons: 64, Grad norm: 4.918e+00\n",
      "Epoch 13062, Loss: 0.006878086365759373, Neurons: 64, Grad norm: 4.918e+00\n",
      "Epoch 13063, Loss: 0.007225364446640015, Neurons: 64, Grad norm: 6.782e+00\n",
      "Epoch 13063, Loss: 0.007225364446640015, Neurons: 64, Grad norm: 6.782e+00\n",
      "Epoch 13064, Loss: 0.007549889385700226, Neurons: 64, Grad norm: 7.060e+00\n",
      "Epoch 13064, Loss: 0.007549889385700226, Neurons: 64, Grad norm: 7.060e+00\n",
      "Epoch 13065, Loss: 0.0075600906275212765, Neurons: 64, Grad norm: 5.752e+00\n",
      "Epoch 13065, Loss: 0.0075600906275212765, Neurons: 64, Grad norm: 5.752e+00\n",
      "Epoch 13066, Loss: 0.007268152665346861, Neurons: 64, Grad norm: 3.376e+00\n",
      "Epoch 13066, Loss: 0.007268152665346861, Neurons: 64, Grad norm: 3.376e+00\n",
      "Epoch 13067, Loss: 0.006941583938896656, Neurons: 64, Grad norm: 1.177e+00\n",
      "Epoch 13067, Loss: 0.006941583938896656, Neurons: 64, Grad norm: 1.177e+00\n",
      "Epoch 13068, Loss: 0.0068382504396140575, Neurons: 64, Grad norm: 2.590e+00\n",
      "Epoch 13068, Loss: 0.0068382504396140575, Neurons: 64, Grad norm: 2.590e+00\n",
      "Epoch 13069, Loss: 0.0069669862277805805, Neurons: 64, Grad norm: 4.158e+00\n",
      "Epoch 13069, Loss: 0.0069669862277805805, Neurons: 64, Grad norm: 4.158e+00\n",
      "Epoch 13070, Loss: 0.007126520853489637, Neurons: 64, Grad norm: 4.571e+00\n",
      "Epoch 13070, Loss: 0.007126520853489637, Neurons: 64, Grad norm: 4.571e+00\n",
      "Epoch 13071, Loss: 0.007131478749215603, Neurons: 64, Grad norm: 3.836e+00\n",
      "Epoch 13071, Loss: 0.007131478749215603, Neurons: 64, Grad norm: 3.836e+00\n",
      "Epoch 13072, Loss: 0.006982381455600262, Neurons: 64, Grad norm: 2.305e+00\n",
      "Epoch 13072, Loss: 0.006982381455600262, Neurons: 64, Grad norm: 2.305e+00\n",
      "Epoch 13073, Loss: 0.0068356916308403015, Neurons: 64, Grad norm: 1.085e+00\n",
      "Epoch 13073, Loss: 0.0068356916308403015, Neurons: 64, Grad norm: 1.085e+00\n",
      "Epoch 13074, Loss: 0.006817616056650877, Neurons: 64, Grad norm: 1.899e+00\n",
      "Epoch 13074, Loss: 0.006817616056650877, Neurons: 64, Grad norm: 1.899e+00\n",
      "Epoch 13075, Loss: 0.006902444176375866, Neurons: 64, Grad norm: 2.752e+00\n",
      "Epoch 13075, Loss: 0.006902444176375866, Neurons: 64, Grad norm: 2.752e+00\n",
      "Epoch 13076, Loss: 0.006965354084968567, Neurons: 64, Grad norm: 2.851e+00\n",
      "Epoch 13076, Loss: 0.006965354084968567, Neurons: 64, Grad norm: 2.851e+00\n",
      "Epoch 13077, Loss: 0.0069256615824997425, Neurons: 64, Grad norm: 2.197e+00\n",
      "Epoch 13077, Loss: 0.0069256615824997425, Neurons: 64, Grad norm: 2.197e+00\n",
      "Epoch 13078, Loss: 0.006825239397585392, Neurons: 64, Grad norm: 1.194e+00\n",
      "Epoch 13078, Loss: 0.006825239397585392, Neurons: 64, Grad norm: 1.194e+00\n",
      "Epoch 13079, Loss: 0.006765295285731554, Neurons: 64, Grad norm: 8.736e-01\n",
      "Epoch 13079, Loss: 0.006765295285731554, Neurons: 64, Grad norm: 8.736e-01\n",
      "Epoch 13080, Loss: 0.00679076137021184, Neurons: 64, Grad norm: 1.537e+00\n",
      "Epoch 13080, Loss: 0.00679076137021184, Neurons: 64, Grad norm: 1.537e+00\n",
      "Epoch 13081, Loss: 0.006851683836430311, Neurons: 64, Grad norm: 1.887e+00\n",
      "Epoch 13081, Loss: 0.006851683836430311, Neurons: 64, Grad norm: 1.887e+00\n",
      "Epoch 13082, Loss: 0.006869171280413866, Neurons: 64, Grad norm: 1.675e+00\n",
      "Epoch 13082, Loss: 0.006869171280413866, Neurons: 64, Grad norm: 1.675e+00\n",
      "Epoch 13083, Loss: 0.006821180693805218, Neurons: 64, Grad norm: 1.043e+00\n",
      "Epoch 13083, Loss: 0.006821180693805218, Neurons: 64, Grad norm: 1.043e+00\n",
      "Epoch 13084, Loss: 0.006757122464478016, Neurons: 64, Grad norm: 3.725e-01\n",
      "Epoch 13084, Loss: 0.006757122464478016, Neurons: 64, Grad norm: 3.725e-01\n",
      "Epoch 13085, Loss: 0.0067368620075285435, Neurons: 64, Grad norm: 7.901e-01\n",
      "Epoch 13085, Loss: 0.0067368620075285435, Neurons: 64, Grad norm: 7.901e-01\n",
      "Epoch 13086, Loss: 0.00676710857078433, Neurons: 64, Grad norm: 1.244e+00\n",
      "Epoch 13086, Loss: 0.00676710857078433, Neurons: 64, Grad norm: 1.244e+00\n",
      "Epoch 13087, Loss: 0.006803322117775679, Neurons: 64, Grad norm: 1.293e+00\n",
      "Epoch 13087, Loss: 0.006803322117775679, Neurons: 64, Grad norm: 1.293e+00\n",
      "Epoch 13088, Loss: 0.0068026394583284855, Neurons: 64, Grad norm: 9.532e-01\n",
      "Epoch 13088, Loss: 0.0068026394583284855, Neurons: 64, Grad norm: 9.532e-01\n",
      "Epoch 13089, Loss: 0.006766485515981913, Neurons: 64, Grad norm: 3.539e-01\n",
      "Epoch 13089, Loss: 0.006766485515981913, Neurons: 64, Grad norm: 3.539e-01\n",
      "Epoch 13090, Loss: 0.006731604691594839, Neurons: 64, Grad norm: 2.933e-01\n",
      "Epoch 13090, Loss: 0.006731604691594839, Neurons: 64, Grad norm: 2.933e-01\n",
      "Epoch 13091, Loss: 0.006727159954607487, Neurons: 64, Grad norm: 7.923e-01\n",
      "Epoch 13091, Loss: 0.006727159954607487, Neurons: 64, Grad norm: 7.923e-01\n",
      "Epoch 13092, Loss: 0.006747424136847258, Neurons: 64, Grad norm: 1.002e+00\n",
      "Epoch 13092, Loss: 0.006747424136847258, Neurons: 64, Grad norm: 1.002e+00\n",
      "Epoch 13093, Loss: 0.006764027290046215, Neurons: 64, Grad norm: 9.085e-01\n",
      "Epoch 13093, Loss: 0.006764027290046215, Neurons: 64, Grad norm: 9.085e-01\n",
      "Epoch 13094, Loss: 0.006758119910955429, Neurons: 64, Grad norm: 5.656e-01\n",
      "Epoch 13094, Loss: 0.006758119910955429, Neurons: 64, Grad norm: 5.656e-01\n",
      "Epoch 13095, Loss: 0.006737125106155872, Neurons: 64, Grad norm: 2.394e-01\n",
      "Epoch 13095, Loss: 0.006737125106155872, Neurons: 64, Grad norm: 2.394e-01\n",
      "Epoch 13096, Loss: 0.006720779929310083, Neurons: 64, Grad norm: 5.058e-01\n",
      "Epoch 13096, Loss: 0.006720779929310083, Neurons: 64, Grad norm: 5.058e-01\n",
      "Epoch 13097, Loss: 0.006720884703099728, Neurons: 64, Grad norm: 7.715e-01\n",
      "Epoch 13097, Loss: 0.006720884703099728, Neurons: 64, Grad norm: 7.715e-01\n",
      "Epoch 13098, Loss: 0.006730837281793356, Neurons: 64, Grad norm: 8.329e-01\n",
      "Epoch 13098, Loss: 0.006730837281793356, Neurons: 64, Grad norm: 8.329e-01\n",
      "Epoch 13099, Loss: 0.0067360796965658665, Neurons: 64, Grad norm: 6.573e-01\n",
      "Epoch 13099, Loss: 0.0067360796965658665, Neurons: 64, Grad norm: 6.573e-01\n",
      "Epoch 13099, Test loss: 0.005364058539271355\n",
      "Epoch 13099, Test loss: 0.005364058539271355\n",
      "Epoch 13100, Loss: 0.006729966029524803, Neurons: 64, Grad norm: 3.516e-01\n",
      "Epoch 13100, Loss: 0.006729966029524803, Neurons: 64, Grad norm: 3.516e-01\n",
      "Epoch 13101, Loss: 0.00671847490593791, Neurons: 64, Grad norm: 2.603e-01\n",
      "Epoch 13101, Loss: 0.00671847490593791, Neurons: 64, Grad norm: 2.603e-01\n",
      "Epoch 13102, Loss: 0.006711711175739765, Neurons: 64, Grad norm: 5.284e-01\n",
      "Epoch 13102, Loss: 0.006711711175739765, Neurons: 64, Grad norm: 5.284e-01\n",
      "Epoch 13103, Loss: 0.006713235285133123, Neurons: 64, Grad norm: 7.270e-01\n",
      "Epoch 13103, Loss: 0.006713235285133123, Neurons: 64, Grad norm: 7.270e-01\n",
      "Epoch 13104, Loss: 0.006717906333506107, Neurons: 64, Grad norm: 7.208e-01\n",
      "Epoch 13104, Loss: 0.006717906333506107, Neurons: 64, Grad norm: 7.208e-01\n",
      "Epoch 13105, Loss: 0.006718556396663189, Neurons: 64, Grad norm: 5.523e-01\n",
      "Epoch 13105, Loss: 0.006718556396663189, Neurons: 64, Grad norm: 5.523e-01\n",
      "Epoch 13106, Loss: 0.006713170558214188, Neurons: 64, Grad norm: 2.605e-01\n",
      "Epoch 13106, Loss: 0.006713170558214188, Neurons: 64, Grad norm: 2.605e-01\n",
      "Epoch 13107, Loss: 0.0067062778398394585, Neurons: 64, Grad norm: 1.439e-01\n",
      "Epoch 13107, Loss: 0.0067062778398394585, Neurons: 64, Grad norm: 1.439e-01\n",
      "Epoch 13108, Loss: 0.006702724378556013, Neurons: 64, Grad norm: 4.127e-01\n",
      "Epoch 13108, Loss: 0.006702724378556013, Neurons: 64, Grad norm: 4.127e-01\n",
      "Epoch 13109, Loss: 0.006703488528728485, Neurons: 64, Grad norm: 5.769e-01\n",
      "Epoch 13109, Loss: 0.006703488528728485, Neurons: 64, Grad norm: 5.769e-01\n",
      "Epoch 13110, Loss: 0.006705664098262787, Neurons: 64, Grad norm: 6.143e-01\n",
      "Epoch 13110, Loss: 0.006705664098262787, Neurons: 64, Grad norm: 6.143e-01\n",
      "Epoch 13111, Loss: 0.006705466657876968, Neurons: 64, Grad norm: 4.931e-01\n",
      "Epoch 13111, Loss: 0.006705466657876968, Neurons: 64, Grad norm: 4.931e-01\n",
      "Epoch 13112, Loss: 0.006701933220028877, Neurons: 64, Grad norm: 2.885e-01\n",
      "Epoch 13112, Loss: 0.006701933220028877, Neurons: 64, Grad norm: 2.885e-01\n",
      "Epoch 13113, Loss: 0.0066973199136555195, Neurons: 64, Grad norm: 2.540e-02\n",
      "Epoch 13113, Loss: 0.0066973199136555195, Neurons: 64, Grad norm: 2.540e-02\n",
      "Epoch 13114, Loss: 0.006694321054965258, Neurons: 64, Grad norm: 2.101e-01\n",
      "Epoch 13114, Loss: 0.006694321054965258, Neurons: 64, Grad norm: 2.101e-01\n",
      "Epoch 13115, Loss: 0.006693908013403416, Neurons: 64, Grad norm: 3.918e-01\n",
      "Epoch 13115, Loss: 0.006693908013403416, Neurons: 64, Grad norm: 3.918e-01\n",
      "Epoch 13116, Loss: 0.006694699637591839, Neurons: 64, Grad norm: 4.528e-01\n",
      "Epoch 13116, Loss: 0.006694699637591839, Neurons: 64, Grad norm: 4.528e-01\n",
      "Epoch 13117, Loss: 0.006694421172142029, Neurons: 64, Grad norm: 4.265e-01\n",
      "Epoch 13117, Loss: 0.006694421172142029, Neurons: 64, Grad norm: 4.265e-01\n",
      "Epoch 13118, Loss: 0.006692374125123024, Neurons: 64, Grad norm: 3.005e-01\n",
      "Epoch 13118, Loss: 0.006692374125123024, Neurons: 64, Grad norm: 3.005e-01\n",
      "Epoch 13119, Loss: 0.006689360830932856, Neurons: 64, Grad norm: 1.480e-01\n",
      "Epoch 13119, Loss: 0.006689360830932856, Neurons: 64, Grad norm: 1.480e-01\n",
      "Epoch 13120, Loss: 0.00668686255812645, Neurons: 64, Grad norm: 6.952e-02\n",
      "Epoch 13120, Loss: 0.00668686255812645, Neurons: 64, Grad norm: 6.952e-02\n",
      "Epoch 13121, Loss: 0.006685527041554451, Neurons: 64, Grad norm: 1.880e-01\n",
      "Epoch 13121, Loss: 0.006685527041554451, Neurons: 64, Grad norm: 1.880e-01\n",
      "Epoch 13122, Loss: 0.006685038562864065, Neurons: 64, Grad norm: 2.734e-01\n",
      "Epoch 13122, Loss: 0.006685038562864065, Neurons: 64, Grad norm: 2.734e-01\n",
      "Epoch 13123, Loss: 0.006684424355626106, Neurons: 64, Grad norm: 2.798e-01\n",
      "Epoch 13123, Loss: 0.006684424355626106, Neurons: 64, Grad norm: 2.798e-01\n",
      "Epoch 13124, Loss: 0.006683070678263903, Neurons: 64, Grad norm: 2.420e-01\n",
      "Epoch 13124, Loss: 0.006683070678263903, Neurons: 64, Grad norm: 2.420e-01\n",
      "Epoch 13125, Loss: 0.00668103015050292, Neurons: 64, Grad norm: 1.450e-01\n",
      "Epoch 13125, Loss: 0.00668103015050292, Neurons: 64, Grad norm: 1.450e-01\n",
      "Epoch 13126, Loss: 0.00667909299954772, Neurons: 64, Grad norm: 8.008e-02\n",
      "Epoch 13126, Loss: 0.00667909299954772, Neurons: 64, Grad norm: 8.008e-02\n",
      "Epoch 13127, Loss: 0.006677677389234304, Neurons: 64, Grad norm: 9.700e-02\n",
      "Epoch 13127, Loss: 0.006677677389234304, Neurons: 64, Grad norm: 9.700e-02\n",
      "Epoch 13128, Loss: 0.006676738150417805, Neurons: 64, Grad norm: 1.469e-01\n",
      "Epoch 13128, Loss: 0.006676738150417805, Neurons: 64, Grad norm: 1.469e-01\n",
      "Epoch 13129, Loss: 0.00667586037889123, Neurons: 64, Grad norm: 1.752e-01\n",
      "Epoch 13129, Loss: 0.00667586037889123, Neurons: 64, Grad norm: 1.752e-01\n",
      "Epoch 13130, Loss: 0.0066746873781085014, Neurons: 64, Grad norm: 1.557e-01\n",
      "Epoch 13130, Loss: 0.0066746873781085014, Neurons: 64, Grad norm: 1.557e-01\n",
      "Epoch 13131, Loss: 0.006673131138086319, Neurons: 64, Grad norm: 1.160e-01\n",
      "Epoch 13131, Loss: 0.006673131138086319, Neurons: 64, Grad norm: 1.160e-01\n",
      "Epoch 13132, Loss: 0.006671321112662554, Neurons: 64, Grad norm: 4.473e-02\n",
      "Epoch 13132, Loss: 0.006671321112662554, Neurons: 64, Grad norm: 4.473e-02\n",
      "Epoch 13133, Loss: 0.006669724825769663, Neurons: 64, Grad norm: 3.424e-02\n",
      "Epoch 13133, Loss: 0.006669724825769663, Neurons: 64, Grad norm: 3.424e-02\n",
      "Epoch 13134, Loss: 0.006668423768132925, Neurons: 64, Grad norm: 8.420e-02\n",
      "Epoch 13134, Loss: 0.006668423768132925, Neurons: 64, Grad norm: 8.420e-02\n",
      "Epoch 13135, Loss: 0.00666740583255887, Neurons: 64, Grad norm: 1.093e-01\n",
      "Epoch 13135, Loss: 0.00666740583255887, Neurons: 64, Grad norm: 1.093e-01\n",
      "Epoch 13136, Loss: 0.006666374858468771, Neurons: 64, Grad norm: 1.141e-01\n",
      "Epoch 13136, Loss: 0.006666374858468771, Neurons: 64, Grad norm: 1.141e-01\n",
      "Epoch 13137, Loss: 0.006665050983428955, Neurons: 64, Grad norm: 8.752e-02\n",
      "Epoch 13137, Loss: 0.006665050983428955, Neurons: 64, Grad norm: 8.752e-02\n",
      "Epoch 13138, Loss: 0.006663578096777201, Neurons: 64, Grad norm: 5.106e-02\n",
      "Epoch 13138, Loss: 0.006663578096777201, Neurons: 64, Grad norm: 5.106e-02\n",
      "Epoch 13139, Loss: 0.006662043742835522, Neurons: 64, Grad norm: 3.049e-02\n",
      "Epoch 13139, Loss: 0.006662043742835522, Neurons: 64, Grad norm: 3.049e-02\n",
      "Epoch 13140, Loss: 0.00666062580421567, Neurons: 64, Grad norm: 5.419e-02\n",
      "Epoch 13140, Loss: 0.00666062580421567, Neurons: 64, Grad norm: 5.419e-02\n",
      "Epoch 13141, Loss: 0.006659348960965872, Neurons: 64, Grad norm: 9.168e-02\n",
      "Epoch 13141, Loss: 0.006659348960965872, Neurons: 64, Grad norm: 9.168e-02\n",
      "Epoch 13142, Loss: 0.006658179685473442, Neurons: 64, Grad norm: 9.593e-02\n",
      "Epoch 13142, Loss: 0.006658179685473442, Neurons: 64, Grad norm: 9.593e-02\n",
      "Epoch 13143, Loss: 0.006656975019723177, Neurons: 64, Grad norm: 9.387e-02\n",
      "Epoch 13143, Loss: 0.006656975019723177, Neurons: 64, Grad norm: 9.387e-02\n",
      "Epoch 13144, Loss: 0.006655662786215544, Neurons: 64, Grad norm: 6.386e-02\n",
      "Epoch 13144, Loss: 0.006655662786215544, Neurons: 64, Grad norm: 6.386e-02\n",
      "Epoch 13145, Loss: 0.00665424857288599, Neurons: 64, Grad norm: 3.703e-02\n",
      "Epoch 13145, Loss: 0.00665424857288599, Neurons: 64, Grad norm: 3.703e-02\n",
      "Epoch 13146, Loss: 0.006652857642620802, Neurons: 64, Grad norm: 3.411e-02\n",
      "Epoch 13146, Loss: 0.006652857642620802, Neurons: 64, Grad norm: 3.411e-02\n",
      "Epoch 13147, Loss: 0.006651564035564661, Neurons: 64, Grad norm: 4.877e-02\n",
      "Epoch 13147, Loss: 0.006651564035564661, Neurons: 64, Grad norm: 4.877e-02\n",
      "Epoch 13148, Loss: 0.006650266703218222, Neurons: 64, Grad norm: 8.049e-02\n",
      "Epoch 13148, Loss: 0.006650266703218222, Neurons: 64, Grad norm: 8.049e-02\n",
      "Epoch 13149, Loss: 0.00664902338758111, Neurons: 64, Grad norm: 8.459e-02\n",
      "Epoch 13149, Loss: 0.00664902338758111, Neurons: 64, Grad norm: 8.459e-02\n",
      "Epoch 13150, Loss: 0.006647751200944185, Neurons: 64, Grad norm: 9.624e-02\n",
      "Epoch 13150, Loss: 0.006647751200944185, Neurons: 64, Grad norm: 9.624e-02\n",
      "Epoch 13151, Loss: 0.006646513473242521, Neurons: 64, Grad norm: 7.626e-02\n",
      "Epoch 13151, Loss: 0.006646513473242521, Neurons: 64, Grad norm: 7.626e-02\n",
      "Epoch 13152, Loss: 0.006645196117460728, Neurons: 64, Grad norm: 6.209e-02\n",
      "Epoch 13152, Loss: 0.006645196117460728, Neurons: 64, Grad norm: 6.209e-02\n",
      "Epoch 13153, Loss: 0.006643825210630894, Neurons: 64, Grad norm: 2.518e-02\n",
      "Epoch 13153, Loss: 0.006643825210630894, Neurons: 64, Grad norm: 2.518e-02\n",
      "Epoch 13154, Loss: 0.006642456166446209, Neurons: 64, Grad norm: 9.575e-03\n",
      "Epoch 13154, Loss: 0.006642456166446209, Neurons: 64, Grad norm: 9.575e-03\n",
      "Epoch 13155, Loss: 0.006641131825745106, Neurons: 64, Grad norm: 3.987e-02\n",
      "Epoch 13155, Loss: 0.006641131825745106, Neurons: 64, Grad norm: 3.987e-02\n",
      "Epoch 13156, Loss: 0.006639902945607901, Neurons: 64, Grad norm: 5.200e-02\n",
      "Epoch 13156, Loss: 0.006639902945607901, Neurons: 64, Grad norm: 5.200e-02\n",
      "Epoch 13157, Loss: 0.006638618651777506, Neurons: 64, Grad norm: 7.125e-02\n",
      "Epoch 13157, Loss: 0.006638618651777506, Neurons: 64, Grad norm: 7.125e-02\n",
      "Epoch 13158, Loss: 0.006637335289269686, Neurons: 64, Grad norm: 6.385e-02\n",
      "Epoch 13158, Loss: 0.006637335289269686, Neurons: 64, Grad norm: 6.385e-02\n",
      "Epoch 13159, Loss: 0.006636057049036026, Neurons: 64, Grad norm: 6.697e-02\n",
      "Epoch 13159, Loss: 0.006636057049036026, Neurons: 64, Grad norm: 6.697e-02\n",
      "Epoch 13160, Loss: 0.006634750869125128, Neurons: 64, Grad norm: 4.379e-02\n",
      "Epoch 13160, Loss: 0.006634750869125128, Neurons: 64, Grad norm: 4.379e-02\n",
      "Epoch 13161, Loss: 0.006633443292230368, Neurons: 64, Grad norm: 3.359e-02\n",
      "Epoch 13161, Loss: 0.006633443292230368, Neurons: 64, Grad norm: 3.359e-02\n",
      "Epoch 13162, Loss: 0.0066321189515292645, Neurons: 64, Grad norm: 1.056e-02\n",
      "Epoch 13162, Loss: 0.0066321189515292645, Neurons: 64, Grad norm: 1.056e-02\n",
      "Epoch 13163, Loss: 0.006630783900618553, Neurons: 64, Grad norm: 9.857e-03\n",
      "Epoch 13163, Loss: 0.006630783900618553, Neurons: 64, Grad norm: 9.857e-03\n",
      "Epoch 13164, Loss: 0.006629479583352804, Neurons: 64, Grad norm: 3.217e-02\n",
      "Epoch 13164, Loss: 0.006629479583352804, Neurons: 64, Grad norm: 3.217e-02\n",
      "Epoch 13165, Loss: 0.006628198083490133, Neurons: 64, Grad norm: 3.754e-02\n",
      "Epoch 13165, Loss: 0.006628198083490133, Neurons: 64, Grad norm: 3.754e-02\n",
      "Epoch 13166, Loss: 0.006626910995692015, Neurons: 64, Grad norm: 5.585e-02\n",
      "Epoch 13166, Loss: 0.006626910995692015, Neurons: 64, Grad norm: 5.585e-02\n",
      "Epoch 13167, Loss: 0.006625697482377291, Neurons: 64, Grad norm: 4.842e-02\n",
      "Epoch 13167, Loss: 0.006625697482377291, Neurons: 64, Grad norm: 4.842e-02\n",
      "Epoch 13168, Loss: 0.006624375469982624, Neurons: 64, Grad norm: 4.904e-02\n",
      "Epoch 13168, Loss: 0.006624375469982624, Neurons: 64, Grad norm: 4.904e-02\n",
      "Epoch 13169, Loss: 0.00662310142070055, Neurons: 64, Grad norm: 2.687e-02\n",
      "Epoch 13169, Loss: 0.00662310142070055, Neurons: 64, Grad norm: 2.687e-02\n",
      "Epoch 13170, Loss: 0.00662183715030551, Neurons: 64, Grad norm: 2.159e-02\n",
      "Epoch 13170, Loss: 0.00662183715030551, Neurons: 64, Grad norm: 2.159e-02\n",
      "Epoch 13171, Loss: 0.006620440166443586, Neurons: 64, Grad norm: 7.837e-03\n",
      "Epoch 13171, Loss: 0.006620440166443586, Neurons: 64, Grad norm: 7.837e-03\n",
      "Epoch 13172, Loss: 0.00661913538351655, Neurons: 64, Grad norm: 1.403e-02\n",
      "Epoch 13172, Loss: 0.00661913538351655, Neurons: 64, Grad norm: 1.403e-02\n",
      "Epoch 13173, Loss: 0.006617882288992405, Neurons: 64, Grad norm: 2.974e-02\n",
      "Epoch 13173, Loss: 0.006617882288992405, Neurons: 64, Grad norm: 2.974e-02\n",
      "Epoch 13174, Loss: 0.006616560276597738, Neurons: 64, Grad norm: 2.501e-02\n",
      "Epoch 13174, Loss: 0.006616560276597738, Neurons: 64, Grad norm: 2.501e-02\n",
      "Epoch 13175, Loss: 0.006615271791815758, Neurons: 64, Grad norm: 2.975e-02\n",
      "Epoch 13175, Loss: 0.006615271791815758, Neurons: 64, Grad norm: 2.975e-02\n",
      "Epoch 13176, Loss: 0.0066139958798885345, Neurons: 64, Grad norm: 1.815e-02\n",
      "Epoch 13176, Loss: 0.0066139958798885345, Neurons: 64, Grad norm: 1.815e-02\n",
      "Epoch 13177, Loss: 0.006612705532461405, Neurons: 64, Grad norm: 2.460e-02\n",
      "Epoch 13177, Loss: 0.006612705532461405, Neurons: 64, Grad norm: 2.460e-02\n",
      "Epoch 13178, Loss: 0.006611404940485954, Neurons: 64, Grad norm: 1.308e-02\n",
      "Epoch 13178, Loss: 0.006611404940485954, Neurons: 64, Grad norm: 1.308e-02\n",
      "Epoch 13179, Loss: 0.006610095500946045, Neurons: 64, Grad norm: 2.300e-02\n",
      "Epoch 13179, Loss: 0.006610095500946045, Neurons: 64, Grad norm: 2.300e-02\n",
      "Epoch 13180, Loss: 0.006608778145164251, Neurons: 64, Grad norm: 1.908e-02\n",
      "Epoch 13180, Loss: 0.006608778145164251, Neurons: 64, Grad norm: 1.908e-02\n",
      "Epoch 13181, Loss: 0.006607563700526953, Neurons: 64, Grad norm: 3.040e-02\n",
      "Epoch 13181, Loss: 0.006607563700526953, Neurons: 64, Grad norm: 3.040e-02\n",
      "Epoch 13182, Loss: 0.006606210023164749, Neurons: 64, Grad norm: 3.176e-02\n",
      "Epoch 13182, Loss: 0.006606210023164749, Neurons: 64, Grad norm: 3.176e-02\n",
      "Epoch 13183, Loss: 0.006604988593608141, Neurons: 64, Grad norm: 4.336e-02\n",
      "Epoch 13183, Loss: 0.006604988593608141, Neurons: 64, Grad norm: 4.336e-02\n",
      "Epoch 13184, Loss: 0.006603727117180824, Neurons: 64, Grad norm: 3.911e-02\n",
      "Epoch 13184, Loss: 0.006603727117180824, Neurons: 64, Grad norm: 3.911e-02\n",
      "Epoch 13185, Loss: 0.006602488923817873, Neurons: 64, Grad norm: 5.171e-02\n",
      "Epoch 13185, Loss: 0.006602488923817873, Neurons: 64, Grad norm: 5.171e-02\n",
      "Epoch 13186, Loss: 0.006601130589842796, Neurons: 64, Grad norm: 5.054e-02\n",
      "Epoch 13186, Loss: 0.006601130589842796, Neurons: 64, Grad norm: 5.054e-02\n",
      "Epoch 13187, Loss: 0.006599874701350927, Neurons: 64, Grad norm: 7.213e-02\n",
      "Epoch 13187, Loss: 0.006599874701350927, Neurons: 64, Grad norm: 7.213e-02\n",
      "Epoch 13188, Loss: 0.006598583422601223, Neurons: 64, Grad norm: 7.393e-02\n",
      "Epoch 13188, Loss: 0.006598583422601223, Neurons: 64, Grad norm: 7.393e-02\n",
      "Epoch 13189, Loss: 0.006597328465431929, Neurons: 64, Grad norm: 9.591e-02\n",
      "Epoch 13189, Loss: 0.006597328465431929, Neurons: 64, Grad norm: 9.591e-02\n",
      "Epoch 13190, Loss: 0.006596032530069351, Neurons: 64, Grad norm: 9.378e-02\n",
      "Epoch 13190, Loss: 0.006596032530069351, Neurons: 64, Grad norm: 9.378e-02\n",
      "Epoch 13191, Loss: 0.006594771984964609, Neurons: 64, Grad norm: 1.140e-01\n",
      "Epoch 13191, Loss: 0.006594771984964609, Neurons: 64, Grad norm: 1.140e-01\n",
      "Epoch 13192, Loss: 0.006593548692762852, Neurons: 64, Grad norm: 1.137e-01\n",
      "Epoch 13192, Loss: 0.006593548692762852, Neurons: 64, Grad norm: 1.137e-01\n",
      "Epoch 13193, Loss: 0.006592308171093464, Neurons: 64, Grad norm: 1.357e-01\n",
      "Epoch 13193, Loss: 0.006592308171093464, Neurons: 64, Grad norm: 1.357e-01\n",
      "Epoch 13194, Loss: 0.006591069512069225, Neurons: 64, Grad norm: 1.333e-01\n",
      "Epoch 13194, Loss: 0.006591069512069225, Neurons: 64, Grad norm: 1.333e-01\n",
      "Epoch 13195, Loss: 0.006589845754206181, Neurons: 64, Grad norm: 1.505e-01\n",
      "Epoch 13195, Loss: 0.006589845754206181, Neurons: 64, Grad norm: 1.505e-01\n",
      "Epoch 13196, Loss: 0.0065885912626981735, Neurons: 64, Grad norm: 1.527e-01\n",
      "Epoch 13196, Loss: 0.0065885912626981735, Neurons: 64, Grad norm: 1.527e-01\n",
      "Epoch 13197, Loss: 0.006587428506463766, Neurons: 64, Grad norm: 1.796e-01\n",
      "Epoch 13197, Loss: 0.006587428506463766, Neurons: 64, Grad norm: 1.796e-01\n",
      "Epoch 13198, Loss: 0.006586258765310049, Neurons: 64, Grad norm: 1.847e-01\n",
      "Epoch 13198, Loss: 0.006586258765310049, Neurons: 64, Grad norm: 1.847e-01\n",
      "Epoch 13199, Loss: 0.006585190072655678, Neurons: 64, Grad norm: 2.210e-01\n",
      "Epoch 13199, Loss: 0.006585190072655678, Neurons: 64, Grad norm: 2.210e-01\n",
      "Epoch 13199, Test loss: 0.005297590512782335\n",
      "Epoch 13199, Test loss: 0.005297590512782335\n",
      "Epoch 13200, Loss: 0.006584220565855503, Neurons: 64, Grad norm: 2.443e-01\n",
      "Epoch 13200, Loss: 0.006584220565855503, Neurons: 64, Grad norm: 2.443e-01\n",
      "Epoch 13201, Loss: 0.006583377253264189, Neurons: 64, Grad norm: 2.944e-01\n",
      "Epoch 13201, Loss: 0.006583377253264189, Neurons: 64, Grad norm: 2.944e-01\n",
      "Epoch 13202, Loss: 0.0065826657228171825, Neurons: 64, Grad norm: 3.318e-01\n",
      "Epoch 13202, Loss: 0.0065826657228171825, Neurons: 64, Grad norm: 3.318e-01\n",
      "Epoch 13203, Loss: 0.006582122296094894, Neurons: 64, Grad norm: 4.003e-01\n",
      "Epoch 13203, Loss: 0.006582122296094894, Neurons: 64, Grad norm: 4.003e-01\n",
      "Epoch 13204, Loss: 0.006581737659871578, Neurons: 64, Grad norm: 4.566e-01\n",
      "Epoch 13204, Loss: 0.006581737659871578, Neurons: 64, Grad norm: 4.566e-01\n",
      "Epoch 13205, Loss: 0.0065816654823720455, Neurons: 64, Grad norm: 5.448e-01\n",
      "Epoch 13205, Loss: 0.0065816654823720455, Neurons: 64, Grad norm: 5.448e-01\n",
      "Epoch 13206, Loss: 0.006582055706530809, Neurons: 64, Grad norm: 6.269e-01\n",
      "Epoch 13206, Loss: 0.006582055706530809, Neurons: 64, Grad norm: 6.269e-01\n",
      "Epoch 13207, Loss: 0.006583020556718111, Neurons: 64, Grad norm: 7.513e-01\n",
      "Epoch 13207, Loss: 0.006583020556718111, Neurons: 64, Grad norm: 7.513e-01\n",
      "Epoch 13208, Loss: 0.006584872491657734, Neurons: 64, Grad norm: 8.687e-01\n",
      "Epoch 13208, Loss: 0.006584872491657734, Neurons: 64, Grad norm: 8.687e-01\n",
      "Epoch 13209, Loss: 0.006588003132492304, Neurons: 64, Grad norm: 1.029e+00\n",
      "Epoch 13209, Loss: 0.006588003132492304, Neurons: 64, Grad norm: 1.029e+00\n",
      "Epoch 13210, Loss: 0.006592790596187115, Neurons: 64, Grad norm: 1.199e+00\n",
      "Epoch 13210, Loss: 0.006592790596187115, Neurons: 64, Grad norm: 1.199e+00\n",
      "Epoch 13211, Loss: 0.006600170861929655, Neurons: 64, Grad norm: 1.427e+00\n",
      "Epoch 13211, Loss: 0.006600170861929655, Neurons: 64, Grad norm: 1.427e+00\n",
      "Epoch 13212, Loss: 0.006611192133277655, Neurons: 64, Grad norm: 1.674e+00\n",
      "Epoch 13212, Loss: 0.006611192133277655, Neurons: 64, Grad norm: 1.674e+00\n",
      "Epoch 13213, Loss: 0.006627664901316166, Neurons: 64, Grad norm: 1.996e+00\n",
      "Epoch 13213, Loss: 0.006627664901316166, Neurons: 64, Grad norm: 1.996e+00\n",
      "Epoch 13214, Loss: 0.0066519202664494514, Neurons: 64, Grad norm: 2.362e+00\n",
      "Epoch 13214, Loss: 0.0066519202664494514, Neurons: 64, Grad norm: 2.362e+00\n",
      "Epoch 13215, Loss: 0.006686992011964321, Neurons: 64, Grad norm: 2.822e+00\n",
      "Epoch 13215, Loss: 0.006686992011964321, Neurons: 64, Grad norm: 2.822e+00\n",
      "Epoch 13216, Loss: 0.006737418472766876, Neurons: 64, Grad norm: 3.341e+00\n",
      "Epoch 13216, Loss: 0.006737418472766876, Neurons: 64, Grad norm: 3.341e+00\n",
      "Epoch 13217, Loss: 0.006807452533394098, Neurons: 64, Grad norm: 3.965e+00\n",
      "Epoch 13217, Loss: 0.006807452533394098, Neurons: 64, Grad norm: 3.965e+00\n",
      "Epoch 13218, Loss: 0.00690287072211504, Neurons: 64, Grad norm: 4.648e+00\n",
      "Epoch 13218, Loss: 0.00690287072211504, Neurons: 64, Grad norm: 4.648e+00\n",
      "Epoch 13219, Loss: 0.00702608423307538, Neurons: 64, Grad norm: 5.399e+00\n",
      "Epoch 13219, Loss: 0.00702608423307538, Neurons: 64, Grad norm: 5.399e+00\n",
      "Epoch 13220, Loss: 0.0071753328666090965, Neurons: 64, Grad norm: 6.123e+00\n",
      "Epoch 13220, Loss: 0.0071753328666090965, Neurons: 64, Grad norm: 6.123e+00\n",
      "Epoch 13221, Loss: 0.007335033733397722, Neurons: 64, Grad norm: 6.778e+00\n",
      "Epoch 13221, Loss: 0.007335033733397722, Neurons: 64, Grad norm: 6.778e+00\n",
      "Epoch 13222, Loss: 0.007476269267499447, Neurons: 64, Grad norm: 7.200e+00\n",
      "Epoch 13222, Loss: 0.007476269267499447, Neurons: 64, Grad norm: 7.200e+00\n",
      "Epoch 13223, Loss: 0.0075533948838710785, Neurons: 64, Grad norm: 7.288e+00\n",
      "Epoch 13223, Loss: 0.0075533948838710785, Neurons: 64, Grad norm: 7.288e+00\n",
      "Epoch 13224, Loss: 0.0075236037373542786, Neurons: 64, Grad norm: 6.893e+00\n",
      "Epoch 13224, Loss: 0.0075236037373542786, Neurons: 64, Grad norm: 6.893e+00\n",
      "Epoch 13225, Loss: 0.007372023072093725, Neurons: 64, Grad norm: 6.011e+00\n",
      "Epoch 13225, Loss: 0.007372023072093725, Neurons: 64, Grad norm: 6.011e+00\n",
      "Epoch 13226, Loss: 0.0071329353377223015, Neurons: 64, Grad norm: 4.655e+00\n",
      "Epoch 13226, Loss: 0.0071329353377223015, Neurons: 64, Grad norm: 4.655e+00\n",
      "Epoch 13227, Loss: 0.006881368812173605, Neurons: 64, Grad norm: 3.028e+00\n",
      "Epoch 13227, Loss: 0.006881368812173605, Neurons: 64, Grad norm: 3.028e+00\n",
      "Epoch 13228, Loss: 0.006692694034427404, Neurons: 64, Grad norm: 1.414e+00\n",
      "Epoch 13228, Loss: 0.006692694034427404, Neurons: 64, Grad norm: 1.414e+00\n",
      "Epoch 13229, Loss: 0.0066081201657652855, Neurons: 64, Grad norm: 1.173e+00\n",
      "Epoch 13229, Loss: 0.0066081201657652855, Neurons: 64, Grad norm: 1.173e+00\n",
      "Epoch 13230, Loss: 0.006620660424232483, Neurons: 64, Grad norm: 2.404e+00\n",
      "Epoch 13230, Loss: 0.006620660424232483, Neurons: 64, Grad norm: 2.404e+00\n",
      "Epoch 13231, Loss: 0.006690889596939087, Neurons: 64, Grad norm: 3.467e+00\n",
      "Epoch 13231, Loss: 0.006690889596939087, Neurons: 64, Grad norm: 3.467e+00\n",
      "Epoch 13232, Loss: 0.006770761217921972, Neurons: 64, Grad norm: 4.133e+00\n",
      "Epoch 13232, Loss: 0.006770761217921972, Neurons: 64, Grad norm: 4.133e+00\n",
      "Epoch 13233, Loss: 0.006822055671364069, Neurons: 64, Grad norm: 4.298e+00\n",
      "Epoch 13233, Loss: 0.006822055671364069, Neurons: 64, Grad norm: 4.298e+00\n",
      "Epoch 13234, Loss: 0.006825791671872139, Neurons: 64, Grad norm: 4.004e+00\n",
      "Epoch 13234, Loss: 0.006825791671872139, Neurons: 64, Grad norm: 4.004e+00\n",
      "Epoch 13235, Loss: 0.006782157812267542, Neurons: 64, Grad norm: 3.276e+00\n",
      "Epoch 13235, Loss: 0.006782157812267542, Neurons: 64, Grad norm: 3.276e+00\n",
      "Epoch 13236, Loss: 0.0067090196534991264, Neurons: 64, Grad norm: 2.273e+00\n",
      "Epoch 13236, Loss: 0.0067090196534991264, Neurons: 64, Grad norm: 2.273e+00\n",
      "Epoch 13237, Loss: 0.006631758529692888, Neurons: 64, Grad norm: 1.150e+00\n",
      "Epoch 13237, Loss: 0.006631758529692888, Neurons: 64, Grad norm: 1.150e+00\n",
      "Epoch 13238, Loss: 0.006576081737875938, Neurons: 64, Grad norm: 6.213e-01\n",
      "Epoch 13238, Loss: 0.006576081737875938, Neurons: 64, Grad norm: 6.213e-01\n",
      "Epoch 13239, Loss: 0.006556415930390358, Neurons: 64, Grad norm: 1.423e+00\n",
      "Epoch 13239, Loss: 0.006556415930390358, Neurons: 64, Grad norm: 1.423e+00\n",
      "Epoch 13240, Loss: 0.006571460980921984, Neurons: 64, Grad norm: 2.190e+00\n",
      "Epoch 13240, Loss: 0.006571460980921984, Neurons: 64, Grad norm: 2.190e+00\n",
      "Epoch 13241, Loss: 0.006606233771890402, Neurons: 64, Grad norm: 2.680e+00\n",
      "Epoch 13241, Loss: 0.006606233771890402, Neurons: 64, Grad norm: 2.680e+00\n",
      "Epoch 13242, Loss: 0.006638966966420412, Neurons: 64, Grad norm: 2.803e+00\n",
      "Epoch 13242, Loss: 0.006638966966420412, Neurons: 64, Grad norm: 2.803e+00\n",
      "Epoch 13243, Loss: 0.0066513740457594395, Neurons: 64, Grad norm: 2.607e+00\n",
      "Epoch 13243, Loss: 0.0066513740457594395, Neurons: 64, Grad norm: 2.607e+00\n",
      "Epoch 13244, Loss: 0.006636389065533876, Neurons: 64, Grad norm: 2.101e+00\n",
      "Epoch 13244, Loss: 0.006636389065533876, Neurons: 64, Grad norm: 2.101e+00\n",
      "Epoch 13245, Loss: 0.006600757595151663, Neurons: 64, Grad norm: 1.407e+00\n",
      "Epoch 13245, Loss: 0.006600757595151663, Neurons: 64, Grad norm: 1.407e+00\n",
      "Epoch 13246, Loss: 0.006560350302606821, Neurons: 64, Grad norm: 5.965e-01\n",
      "Epoch 13246, Loss: 0.006560350302606821, Neurons: 64, Grad norm: 5.965e-01\n",
      "Epoch 13247, Loss: 0.006531762424856424, Neurons: 64, Grad norm: 2.431e-01\n",
      "Epoch 13247, Loss: 0.006531762424856424, Neurons: 64, Grad norm: 2.431e-01\n",
      "Epoch 13248, Loss: 0.006523818243294954, Neurons: 64, Grad norm: 9.312e-01\n",
      "Epoch 13248, Loss: 0.006523818243294954, Neurons: 64, Grad norm: 9.312e-01\n",
      "Epoch 13249, Loss: 0.0065344879403710365, Neurons: 64, Grad norm: 1.444e+00\n",
      "Epoch 13249, Loss: 0.0065344879403710365, Neurons: 64, Grad norm: 1.444e+00\n",
      "Epoch 13250, Loss: 0.006553377024829388, Neurons: 64, Grad norm: 1.759e+00\n",
      "Epoch 13250, Loss: 0.006553377024829388, Neurons: 64, Grad norm: 1.759e+00\n",
      "Epoch 13251, Loss: 0.006568367592990398, Neurons: 64, Grad norm: 1.826e+00\n",
      "Epoch 13251, Loss: 0.006568367592990398, Neurons: 64, Grad norm: 1.826e+00\n",
      "Epoch 13252, Loss: 0.006571575533598661, Neurons: 64, Grad norm: 1.699e+00\n",
      "Epoch 13252, Loss: 0.006571575533598661, Neurons: 64, Grad norm: 1.699e+00\n",
      "Epoch 13253, Loss: 0.006562025286257267, Neurons: 64, Grad norm: 1.375e+00\n",
      "Epoch 13253, Loss: 0.006562025286257267, Neurons: 64, Grad norm: 1.375e+00\n",
      "Epoch 13254, Loss: 0.00654486333951354, Neurons: 64, Grad norm: 9.551e-01\n",
      "Epoch 13254, Loss: 0.00654486333951354, Neurons: 64, Grad norm: 9.551e-01\n",
      "Epoch 13255, Loss: 0.006527668796479702, Neurons: 64, Grad norm: 4.678e-01\n",
      "Epoch 13255, Loss: 0.006527668796479702, Neurons: 64, Grad norm: 4.678e-01\n",
      "Epoch 13256, Loss: 0.006516319699585438, Neurons: 64, Grad norm: 1.474e-01\n",
      "Epoch 13256, Loss: 0.006516319699585438, Neurons: 64, Grad norm: 1.474e-01\n",
      "Epoch 13257, Loss: 0.0065128616988658905, Neurons: 64, Grad norm: 4.832e-01\n",
      "Epoch 13257, Loss: 0.0065128616988658905, Neurons: 64, Grad norm: 4.832e-01\n",
      "Epoch 13258, Loss: 0.0065155974589288235, Neurons: 64, Grad norm: 7.971e-01\n",
      "Epoch 13258, Loss: 0.0065155974589288235, Neurons: 64, Grad norm: 7.971e-01\n",
      "Epoch 13259, Loss: 0.00652082497254014, Neurons: 64, Grad norm: 1.018e+00\n",
      "Epoch 13259, Loss: 0.00652082497254014, Neurons: 64, Grad norm: 1.018e+00\n",
      "Epoch 13260, Loss: 0.006524910684674978, Neurons: 64, Grad norm: 1.097e+00\n",
      "Epoch 13260, Loss: 0.006524910684674978, Neurons: 64, Grad norm: 1.097e+00\n",
      "Epoch 13261, Loss: 0.006525708828121424, Neurons: 64, Grad norm: 1.083e+00\n",
      "Epoch 13261, Loss: 0.006525708828121424, Neurons: 64, Grad norm: 1.083e+00\n",
      "Epoch 13262, Loss: 0.006523060146719217, Neurons: 64, Grad norm: 9.532e-01\n",
      "Epoch 13262, Loss: 0.006523060146719217, Neurons: 64, Grad norm: 9.532e-01\n",
      "Epoch 13263, Loss: 0.006518099922686815, Neurons: 64, Grad norm: 7.739e-01\n",
      "Epoch 13263, Loss: 0.006518099922686815, Neurons: 64, Grad norm: 7.739e-01\n",
      "Epoch 13264, Loss: 0.006512351334095001, Neurons: 64, Grad norm: 5.370e-01\n",
      "Epoch 13264, Loss: 0.006512351334095001, Neurons: 64, Grad norm: 5.370e-01\n",
      "Epoch 13265, Loss: 0.006507303100079298, Neurons: 64, Grad norm: 3.229e-01\n",
      "Epoch 13265, Loss: 0.006507303100079298, Neurons: 64, Grad norm: 3.229e-01\n",
      "Epoch 13266, Loss: 0.006503693293780088, Neurons: 64, Grad norm: 1.900e-01\n",
      "Epoch 13266, Loss: 0.006503693293780088, Neurons: 64, Grad norm: 1.900e-01\n",
      "Epoch 13267, Loss: 0.006501543335616589, Neurons: 64, Grad norm: 2.807e-01\n",
      "Epoch 13267, Loss: 0.006501543335616589, Neurons: 64, Grad norm: 2.807e-01\n",
      "Epoch 13268, Loss: 0.006500618997961283, Neurons: 64, Grad norm: 4.332e-01\n",
      "Epoch 13268, Loss: 0.006500618997961283, Neurons: 64, Grad norm: 4.332e-01\n",
      "Epoch 13269, Loss: 0.006500277668237686, Neurons: 64, Grad norm: 5.371e-01\n",
      "Epoch 13269, Loss: 0.006500277668237686, Neurons: 64, Grad norm: 5.371e-01\n",
      "Epoch 13270, Loss: 0.006500157527625561, Neurons: 64, Grad norm: 6.123e-01\n",
      "Epoch 13270, Loss: 0.006500157527625561, Neurons: 64, Grad norm: 6.123e-01\n",
      "Epoch 13271, Loss: 0.006499817129224539, Neurons: 64, Grad norm: 6.188e-01\n",
      "Epoch 13271, Loss: 0.006499817129224539, Neurons: 64, Grad norm: 6.188e-01\n",
      "Epoch 13272, Loss: 0.006498937029391527, Neurons: 64, Grad norm: 6.002e-01\n",
      "Epoch 13272, Loss: 0.006498937029391527, Neurons: 64, Grad norm: 6.002e-01\n",
      "Epoch 13273, Loss: 0.006497592199593782, Neurons: 64, Grad norm: 5.253e-01\n",
      "Epoch 13273, Loss: 0.006497592199593782, Neurons: 64, Grad norm: 5.253e-01\n",
      "Epoch 13274, Loss: 0.006495663896203041, Neurons: 64, Grad norm: 4.468e-01\n",
      "Epoch 13274, Loss: 0.006495663896203041, Neurons: 64, Grad norm: 4.468e-01\n",
      "Epoch 13275, Loss: 0.0064933630637824535, Neurons: 64, Grad norm: 3.278e-01\n",
      "Epoch 13275, Loss: 0.0064933630637824535, Neurons: 64, Grad norm: 3.278e-01\n",
      "Epoch 13276, Loss: 0.006490846164524555, Neurons: 64, Grad norm: 2.228e-01\n",
      "Epoch 13276, Loss: 0.006490846164524555, Neurons: 64, Grad norm: 2.228e-01\n",
      "Epoch 13277, Loss: 0.006488361861556768, Neurons: 64, Grad norm: 1.079e-01\n",
      "Epoch 13277, Loss: 0.006488361861556768, Neurons: 64, Grad norm: 1.079e-01\n",
      "Epoch 13278, Loss: 0.006486203521490097, Neurons: 64, Grad norm: 7.372e-02\n",
      "Epoch 13278, Loss: 0.006486203521490097, Neurons: 64, Grad norm: 7.372e-02\n",
      "Epoch 13279, Loss: 0.006484572775661945, Neurons: 64, Grad norm: 1.469e-01\n",
      "Epoch 13279, Loss: 0.006484572775661945, Neurons: 64, Grad norm: 1.469e-01\n",
      "Epoch 13280, Loss: 0.006483414676040411, Neurons: 64, Grad norm: 2.097e-01\n",
      "Epoch 13280, Loss: 0.006483414676040411, Neurons: 64, Grad norm: 2.097e-01\n",
      "Epoch 13281, Loss: 0.006482588592916727, Neurons: 64, Grad norm: 2.748e-01\n",
      "Epoch 13281, Loss: 0.006482588592916727, Neurons: 64, Grad norm: 2.748e-01\n",
      "Epoch 13282, Loss: 0.006481948308646679, Neurons: 64, Grad norm: 3.002e-01\n",
      "Epoch 13282, Loss: 0.006481948308646679, Neurons: 64, Grad norm: 3.002e-01\n",
      "Epoch 13283, Loss: 0.006481200456619263, Neurons: 64, Grad norm: 3.279e-01\n",
      "Epoch 13283, Loss: 0.006481200456619263, Neurons: 64, Grad norm: 3.279e-01\n",
      "Epoch 13284, Loss: 0.006480260286480188, Neurons: 64, Grad norm: 3.125e-01\n",
      "Epoch 13284, Loss: 0.006480260286480188, Neurons: 64, Grad norm: 3.125e-01\n",
      "Epoch 13285, Loss: 0.0064790393225848675, Neurons: 64, Grad norm: 3.033e-01\n",
      "Epoch 13285, Loss: 0.0064790393225848675, Neurons: 64, Grad norm: 3.033e-01\n",
      "Epoch 13286, Loss: 0.006477572955191135, Neurons: 64, Grad norm: 2.610e-01\n",
      "Epoch 13286, Loss: 0.006477572955191135, Neurons: 64, Grad norm: 2.610e-01\n",
      "Epoch 13287, Loss: 0.006475901696830988, Neurons: 64, Grad norm: 2.310e-01\n",
      "Epoch 13287, Loss: 0.006475901696830988, Neurons: 64, Grad norm: 2.310e-01\n",
      "Epoch 13288, Loss: 0.00647424440830946, Neurons: 64, Grad norm: 1.732e-01\n",
      "Epoch 13288, Loss: 0.00647424440830946, Neurons: 64, Grad norm: 1.732e-01\n",
      "Epoch 13289, Loss: 0.006472593639045954, Neurons: 64, Grad norm: 1.349e-01\n",
      "Epoch 13289, Loss: 0.006472593639045954, Neurons: 64, Grad norm: 1.349e-01\n",
      "Epoch 13290, Loss: 0.006471060216426849, Neurons: 64, Grad norm: 7.793e-02\n",
      "Epoch 13290, Loss: 0.006471060216426849, Neurons: 64, Grad norm: 7.793e-02\n",
      "Epoch 13291, Loss: 0.006469619460403919, Neurons: 64, Grad norm: 4.637e-02\n",
      "Epoch 13291, Loss: 0.006469619460403919, Neurons: 64, Grad norm: 4.637e-02\n",
      "Epoch 13292, Loss: 0.006468350067734718, Neurons: 64, Grad norm: 4.044e-02\n",
      "Epoch 13292, Loss: 0.006468350067734718, Neurons: 64, Grad norm: 4.044e-02\n",
      "Epoch 13293, Loss: 0.0064671882428228855, Neurons: 64, Grad norm: 6.288e-02\n",
      "Epoch 13293, Loss: 0.0064671882428228855, Neurons: 64, Grad norm: 6.288e-02\n",
      "Epoch 13294, Loss: 0.006466090679168701, Neurons: 64, Grad norm: 1.005e-01\n",
      "Epoch 13294, Loss: 0.006466090679168701, Neurons: 64, Grad norm: 1.005e-01\n",
      "Epoch 13295, Loss: 0.006464945152401924, Neurons: 64, Grad norm: 1.139e-01\n",
      "Epoch 13295, Loss: 0.006464945152401924, Neurons: 64, Grad norm: 1.139e-01\n",
      "Epoch 13296, Loss: 0.0064638168551027775, Neurons: 64, Grad norm: 1.447e-01\n",
      "Epoch 13296, Loss: 0.0064638168551027775, Neurons: 64, Grad norm: 1.447e-01\n",
      "Epoch 13297, Loss: 0.006462651304900646, Neurons: 64, Grad norm: 1.459e-01\n",
      "Epoch 13297, Loss: 0.006462651304900646, Neurons: 64, Grad norm: 1.459e-01\n",
      "Epoch 13298, Loss: 0.0064614214934408665, Neurons: 64, Grad norm: 1.616e-01\n",
      "Epoch 13298, Loss: 0.0064614214934408665, Neurons: 64, Grad norm: 1.616e-01\n",
      "Epoch 13299, Loss: 0.006460167467594147, Neurons: 64, Grad norm: 1.571e-01\n",
      "Epoch 13299, Loss: 0.006460167467594147, Neurons: 64, Grad norm: 1.571e-01\n",
      "Epoch 13299, Test loss: 0.00520272646099329\n",
      "Epoch 13299, Test loss: 0.00520272646099329\n",
      "Epoch 13300, Loss: 0.006458913441747427, Neurons: 64, Grad norm: 1.718e-01\n",
      "Epoch 13300, Loss: 0.006458913441747427, Neurons: 64, Grad norm: 1.718e-01\n",
      "Epoch 13301, Loss: 0.006457652896642685, Neurons: 64, Grad norm: 1.581e-01\n",
      "Epoch 13301, Loss: 0.006457652896642685, Neurons: 64, Grad norm: 1.581e-01\n",
      "Epoch 13302, Loss: 0.006456408184021711, Neurons: 64, Grad norm: 1.675e-01\n",
      "Epoch 13302, Loss: 0.006456408184021711, Neurons: 64, Grad norm: 1.675e-01\n",
      "Epoch 13303, Loss: 0.0064551918767392635, Neurons: 64, Grad norm: 1.592e-01\n",
      "Epoch 13303, Loss: 0.0064551918767392635, Neurons: 64, Grad norm: 1.592e-01\n",
      "Epoch 13304, Loss: 0.006453982554376125, Neurons: 64, Grad norm: 1.627e-01\n",
      "Epoch 13304, Loss: 0.006453982554376125, Neurons: 64, Grad norm: 1.627e-01\n",
      "Epoch 13305, Loss: 0.0064527601934969425, Neurons: 64, Grad norm: 1.463e-01\n",
      "Epoch 13305, Loss: 0.0064527601934969425, Neurons: 64, Grad norm: 1.463e-01\n",
      "Epoch 13306, Loss: 0.006451496388763189, Neurons: 64, Grad norm: 1.483e-01\n",
      "Epoch 13306, Loss: 0.006451496388763189, Neurons: 64, Grad norm: 1.483e-01\n",
      "Epoch 13307, Loss: 0.006450226064771414, Neurons: 64, Grad norm: 1.317e-01\n",
      "Epoch 13307, Loss: 0.006450226064771414, Neurons: 64, Grad norm: 1.317e-01\n",
      "Epoch 13308, Loss: 0.006449018605053425, Neurons: 64, Grad norm: 1.282e-01\n",
      "Epoch 13308, Loss: 0.006449018605053425, Neurons: 64, Grad norm: 1.282e-01\n",
      "Epoch 13309, Loss: 0.006447714753448963, Neurons: 64, Grad norm: 1.077e-01\n",
      "Epoch 13309, Loss: 0.006447714753448963, Neurons: 64, Grad norm: 1.077e-01\n",
      "Epoch 13310, Loss: 0.0064463987946510315, Neurons: 64, Grad norm: 1.066e-01\n",
      "Epoch 13310, Loss: 0.0064463987946510315, Neurons: 64, Grad norm: 1.066e-01\n",
      "Epoch 13311, Loss: 0.006445149891078472, Neurons: 64, Grad norm: 8.809e-02\n",
      "Epoch 13311, Loss: 0.006445149891078472, Neurons: 64, Grad norm: 8.809e-02\n",
      "Epoch 13312, Loss: 0.006443856284022331, Neurons: 64, Grad norm: 8.582e-02\n",
      "Epoch 13312, Loss: 0.006443856284022331, Neurons: 64, Grad norm: 8.582e-02\n",
      "Epoch 13313, Loss: 0.006442609708756208, Neurons: 64, Grad norm: 6.918e-02\n",
      "Epoch 13313, Loss: 0.006442609708756208, Neurons: 64, Grad norm: 6.918e-02\n",
      "Epoch 13314, Loss: 0.0064413296058773994, Neurons: 64, Grad norm: 7.612e-02\n",
      "Epoch 13314, Loss: 0.0064413296058773994, Neurons: 64, Grad norm: 7.612e-02\n",
      "Epoch 13315, Loss: 0.0064400541596114635, Neurons: 64, Grad norm: 6.172e-02\n",
      "Epoch 13315, Loss: 0.0064400541596114635, Neurons: 64, Grad norm: 6.172e-02\n",
      "Epoch 13316, Loss: 0.006438858341425657, Neurons: 64, Grad norm: 7.189e-02\n",
      "Epoch 13316, Loss: 0.006438858341425657, Neurons: 64, Grad norm: 7.189e-02\n",
      "Epoch 13317, Loss: 0.006437635514885187, Neurons: 64, Grad norm: 6.352e-02\n",
      "Epoch 13317, Loss: 0.006437635514885187, Neurons: 64, Grad norm: 6.352e-02\n",
      "Epoch 13318, Loss: 0.006436474155634642, Neurons: 64, Grad norm: 7.603e-02\n",
      "Epoch 13318, Loss: 0.006436474155634642, Neurons: 64, Grad norm: 7.603e-02\n",
      "Epoch 13319, Loss: 0.006435234099626541, Neurons: 64, Grad norm: 6.991e-02\n",
      "Epoch 13319, Loss: 0.006435234099626541, Neurons: 64, Grad norm: 6.991e-02\n",
      "Epoch 13320, Loss: 0.006434066221117973, Neurons: 64, Grad norm: 8.828e-02\n",
      "Epoch 13320, Loss: 0.006434066221117973, Neurons: 64, Grad norm: 8.828e-02\n",
      "Epoch 13321, Loss: 0.006432943977415562, Neurons: 64, Grad norm: 9.031e-02\n",
      "Epoch 13321, Loss: 0.006432943977415562, Neurons: 64, Grad norm: 9.031e-02\n",
      "Epoch 13322, Loss: 0.0064318012446165085, Neurons: 64, Grad norm: 1.096e-01\n",
      "Epoch 13322, Loss: 0.0064318012446165085, Neurons: 64, Grad norm: 1.096e-01\n",
      "Epoch 13323, Loss: 0.006430646870285273, Neurons: 64, Grad norm: 1.103e-01\n",
      "Epoch 13323, Loss: 0.006430646870285273, Neurons: 64, Grad norm: 1.103e-01\n",
      "Epoch 13324, Loss: 0.006429470144212246, Neurons: 64, Grad norm: 1.354e-01\n",
      "Epoch 13324, Loss: 0.006429470144212246, Neurons: 64, Grad norm: 1.354e-01\n",
      "Epoch 13325, Loss: 0.006428316235542297, Neurons: 64, Grad norm: 1.413e-01\n",
      "Epoch 13325, Loss: 0.006428316235542297, Neurons: 64, Grad norm: 1.413e-01\n",
      "Epoch 13326, Loss: 0.006427117623388767, Neurons: 64, Grad norm: 1.711e-01\n",
      "Epoch 13326, Loss: 0.006427117623388767, Neurons: 64, Grad norm: 1.711e-01\n",
      "Epoch 13327, Loss: 0.006425946485251188, Neurons: 64, Grad norm: 1.825e-01\n",
      "Epoch 13327, Loss: 0.006425946485251188, Neurons: 64, Grad norm: 1.825e-01\n",
      "Epoch 13328, Loss: 0.006424812600016594, Neurons: 64, Grad norm: 2.211e-01\n",
      "Epoch 13328, Loss: 0.006424812600016594, Neurons: 64, Grad norm: 2.211e-01\n",
      "Epoch 13329, Loss: 0.0064236861653625965, Neurons: 64, Grad norm: 2.414e-01\n",
      "Epoch 13329, Loss: 0.0064236861653625965, Neurons: 64, Grad norm: 2.414e-01\n",
      "Epoch 13330, Loss: 0.0064226477406919, Neurons: 64, Grad norm: 2.908e-01\n",
      "Epoch 13330, Loss: 0.0064226477406919, Neurons: 64, Grad norm: 2.908e-01\n",
      "Epoch 13331, Loss: 0.006421748548746109, Neurons: 64, Grad norm: 3.322e-01\n",
      "Epoch 13331, Loss: 0.006421748548746109, Neurons: 64, Grad norm: 3.322e-01\n",
      "Epoch 13332, Loss: 0.0064209760166704655, Neurons: 64, Grad norm: 4.001e-01\n",
      "Epoch 13332, Loss: 0.0064209760166704655, Neurons: 64, Grad norm: 4.001e-01\n",
      "Epoch 13333, Loss: 0.006420339923352003, Neurons: 64, Grad norm: 4.593e-01\n",
      "Epoch 13333, Loss: 0.006420339923352003, Neurons: 64, Grad norm: 4.593e-01\n",
      "Epoch 13334, Loss: 0.00642003770917654, Neurons: 64, Grad norm: 5.546e-01\n",
      "Epoch 13334, Loss: 0.00642003770917654, Neurons: 64, Grad norm: 5.546e-01\n",
      "Epoch 13335, Loss: 0.0064201136119663715, Neurons: 64, Grad norm: 6.446e-01\n",
      "Epoch 13335, Loss: 0.0064201136119663715, Neurons: 64, Grad norm: 6.446e-01\n",
      "Epoch 13336, Loss: 0.006420772988349199, Neurons: 64, Grad norm: 7.778e-01\n",
      "Epoch 13336, Loss: 0.006420772988349199, Neurons: 64, Grad norm: 7.778e-01\n",
      "Epoch 13337, Loss: 0.006422279868274927, Neurons: 64, Grad norm: 9.151e-01\n",
      "Epoch 13337, Loss: 0.006422279868274927, Neurons: 64, Grad norm: 9.151e-01\n",
      "Epoch 13338, Loss: 0.0064249481074512005, Neurons: 64, Grad norm: 1.106e+00\n",
      "Epoch 13338, Loss: 0.0064249481074512005, Neurons: 64, Grad norm: 1.106e+00\n",
      "Epoch 13339, Loss: 0.006429329048842192, Neurons: 64, Grad norm: 1.316e+00\n",
      "Epoch 13339, Loss: 0.006429329048842192, Neurons: 64, Grad norm: 1.316e+00\n",
      "Epoch 13340, Loss: 0.0064364150166511536, Neurons: 64, Grad norm: 1.595e+00\n",
      "Epoch 13340, Loss: 0.0064364150166511536, Neurons: 64, Grad norm: 1.595e+00\n",
      "Epoch 13341, Loss: 0.006447590887546539, Neurons: 64, Grad norm: 1.918e+00\n",
      "Epoch 13341, Loss: 0.006447590887546539, Neurons: 64, Grad norm: 1.918e+00\n",
      "Epoch 13342, Loss: 0.006464697420597076, Neurons: 64, Grad norm: 2.336e+00\n",
      "Epoch 13342, Loss: 0.006464697420597076, Neurons: 64, Grad norm: 2.336e+00\n",
      "Epoch 13343, Loss: 0.006490679923444986, Neurons: 64, Grad norm: 2.821e+00\n",
      "Epoch 13343, Loss: 0.006490679923444986, Neurons: 64, Grad norm: 2.821e+00\n",
      "Epoch 13344, Loss: 0.006529776379466057, Neurons: 64, Grad norm: 3.440e+00\n",
      "Epoch 13344, Loss: 0.006529776379466057, Neurons: 64, Grad norm: 3.440e+00\n",
      "Epoch 13345, Loss: 0.006588211748749018, Neurons: 64, Grad norm: 4.165e+00\n",
      "Epoch 13345, Loss: 0.006588211748749018, Neurons: 64, Grad norm: 4.165e+00\n",
      "Epoch 13346, Loss: 0.006674626842141151, Neurons: 64, Grad norm: 5.045e+00\n",
      "Epoch 13346, Loss: 0.006674626842141151, Neurons: 64, Grad norm: 5.045e+00\n",
      "Epoch 13347, Loss: 0.006799354683607817, Neurons: 64, Grad norm: 6.043e+00\n",
      "Epoch 13347, Loss: 0.006799354683607817, Neurons: 64, Grad norm: 6.043e+00\n",
      "Epoch 13348, Loss: 0.0069739785976707935, Neurons: 64, Grad norm: 7.172e+00\n",
      "Epoch 13348, Loss: 0.0069739785976707935, Neurons: 64, Grad norm: 7.172e+00\n",
      "Epoch 13349, Loss: 0.007204902358353138, Neurons: 64, Grad norm: 8.316e+00\n",
      "Epoch 13349, Loss: 0.007204902358353138, Neurons: 64, Grad norm: 8.316e+00\n",
      "Epoch 13350, Loss: 0.007485092617571354, Neurons: 64, Grad norm: 9.369e+00\n",
      "Epoch 13350, Loss: 0.007485092617571354, Neurons: 64, Grad norm: 9.369e+00\n",
      "Epoch 13351, Loss: 0.007772588171064854, Neurons: 64, Grad norm: 1.006e+01\n",
      "Epoch 13351, Loss: 0.007772588171064854, Neurons: 64, Grad norm: 1.006e+01\n",
      "Epoch 13352, Loss: 0.007984635420143604, Neurons: 64, Grad norm: 1.013e+01\n",
      "Epoch 13352, Loss: 0.007984635420143604, Neurons: 64, Grad norm: 1.013e+01\n",
      "Epoch 13353, Loss: 0.00800106767565012, Neurons: 64, Grad norm: 9.280e+00\n",
      "Epoch 13353, Loss: 0.00800106767565012, Neurons: 64, Grad norm: 9.280e+00\n",
      "Epoch 13354, Loss: 0.007744768168777227, Neurons: 64, Grad norm: 7.448e+00\n",
      "Epoch 13354, Loss: 0.007744768168777227, Neurons: 64, Grad norm: 7.448e+00\n",
      "Epoch 13355, Loss: 0.00725959800183773, Neurons: 64, Grad norm: 4.762e+00\n",
      "Epoch 13355, Loss: 0.00725959800183773, Neurons: 64, Grad norm: 4.762e+00\n",
      "Epoch 13356, Loss: 0.006745495833456516, Neurons: 64, Grad norm: 1.656e+00\n",
      "Epoch 13356, Loss: 0.006745495833456516, Neurons: 64, Grad norm: 1.656e+00\n",
      "Epoch 13357, Loss: 0.006431002169847488, Neurons: 64, Grad norm: 1.416e+00\n",
      "Epoch 13357, Loss: 0.006431002169847488, Neurons: 64, Grad norm: 1.416e+00\n",
      "Epoch 13358, Loss: 0.00641902070492506, Neurons: 64, Grad norm: 3.944e+00\n",
      "Epoch 13358, Loss: 0.00641902070492506, Neurons: 64, Grad norm: 3.944e+00\n",
      "Epoch 13359, Loss: 0.006631971336901188, Neurons: 64, Grad norm: 5.637e+00\n",
      "Epoch 13359, Loss: 0.006631971336901188, Neurons: 64, Grad norm: 5.637e+00\n",
      "Epoch 13360, Loss: 0.006884409114718437, Neurons: 64, Grad norm: 6.258e+00\n",
      "Epoch 13360, Loss: 0.006884409114718437, Neurons: 64, Grad norm: 6.258e+00\n",
      "Epoch 13361, Loss: 0.007000845856964588, Neurons: 64, Grad norm: 5.792e+00\n",
      "Epoch 13361, Loss: 0.007000845856964588, Neurons: 64, Grad norm: 5.792e+00\n",
      "Epoch 13362, Loss: 0.006908951327204704, Neurons: 64, Grad norm: 4.338e+00\n",
      "Epoch 13362, Loss: 0.006908951327204704, Neurons: 64, Grad norm: 4.338e+00\n",
      "Epoch 13363, Loss: 0.006677844561636448, Neurons: 64, Grad norm: 2.259e+00\n",
      "Epoch 13363, Loss: 0.006677844561636448, Neurons: 64, Grad norm: 2.259e+00\n",
      "Epoch 13364, Loss: 0.006460139527916908, Neurons: 64, Grad norm: 4.959e-02\n",
      "Epoch 13364, Loss: 0.006460139527916908, Neurons: 64, Grad norm: 4.959e-02\n",
      "Epoch 13365, Loss: 0.006379233207553625, Neurons: 64, Grad norm: 2.096e+00\n",
      "Epoch 13365, Loss: 0.006379233207553625, Neurons: 64, Grad norm: 2.096e+00\n",
      "Epoch 13366, Loss: 0.006447478197515011, Neurons: 64, Grad norm: 3.577e+00\n",
      "Epoch 13366, Loss: 0.006447478197515011, Neurons: 64, Grad norm: 3.577e+00\n",
      "Epoch 13367, Loss: 0.0065774195827543736, Neurons: 64, Grad norm: 4.236e+00\n",
      "Epoch 13367, Loss: 0.0065774195827543736, Neurons: 64, Grad norm: 4.236e+00\n",
      "Epoch 13368, Loss: 0.0066586146131157875, Neurons: 64, Grad norm: 4.061e+00\n",
      "Epoch 13368, Loss: 0.0066586146131157875, Neurons: 64, Grad norm: 4.061e+00\n",
      "Epoch 13369, Loss: 0.00663352245464921, Neurons: 64, Grad norm: 3.119e+00\n",
      "Epoch 13369, Loss: 0.00663352245464921, Neurons: 64, Grad norm: 3.119e+00\n",
      "Epoch 13370, Loss: 0.006527197081595659, Neurons: 64, Grad norm: 1.689e+00\n",
      "Epoch 13370, Loss: 0.006527197081595659, Neurons: 64, Grad norm: 1.689e+00\n",
      "Epoch 13371, Loss: 0.006417301017791033, Neurons: 64, Grad norm: 7.458e-02\n",
      "Epoch 13371, Loss: 0.006417301017791033, Neurons: 64, Grad norm: 7.458e-02\n",
      "Epoch 13372, Loss: 0.0063711837865412235, Neurons: 64, Grad norm: 1.399e+00\n",
      "Epoch 13372, Loss: 0.0063711837865412235, Neurons: 64, Grad norm: 1.399e+00\n",
      "Epoch 13373, Loss: 0.00640023173764348, Neurons: 64, Grad norm: 2.467e+00\n",
      "Epoch 13373, Loss: 0.00640023173764348, Neurons: 64, Grad norm: 2.467e+00\n",
      "Epoch 13374, Loss: 0.006462793331593275, Neurons: 64, Grad norm: 2.948e+00\n",
      "Epoch 13374, Loss: 0.006462793331593275, Neurons: 64, Grad norm: 2.948e+00\n",
      "Epoch 13375, Loss: 0.006503380835056305, Neurons: 64, Grad norm: 2.848e+00\n",
      "Epoch 13375, Loss: 0.006503380835056305, Neurons: 64, Grad norm: 2.848e+00\n",
      "Epoch 13376, Loss: 0.006492339540272951, Neurons: 64, Grad norm: 2.203e+00\n",
      "Epoch 13376, Loss: 0.006492339540272951, Neurons: 64, Grad norm: 2.203e+00\n",
      "Epoch 13377, Loss: 0.00644118245691061, Neurons: 64, Grad norm: 1.224e+00\n",
      "Epoch 13377, Loss: 0.00644118245691061, Neurons: 64, Grad norm: 1.224e+00\n",
      "Epoch 13378, Loss: 0.006387203000485897, Neurons: 64, Grad norm: 9.436e-02\n",
      "Epoch 13378, Loss: 0.006387203000485897, Neurons: 64, Grad norm: 9.436e-02\n",
      "Epoch 13379, Loss: 0.006362900137901306, Neurons: 64, Grad norm: 9.220e-01\n",
      "Epoch 13379, Loss: 0.006362900137901306, Neurons: 64, Grad norm: 9.220e-01\n",
      "Epoch 13380, Loss: 0.006374872289597988, Neurons: 64, Grad norm: 1.687e+00\n",
      "Epoch 13380, Loss: 0.006374872289597988, Neurons: 64, Grad norm: 1.687e+00\n",
      "Epoch 13381, Loss: 0.006404382176697254, Neurons: 64, Grad norm: 2.049e+00\n",
      "Epoch 13381, Loss: 0.006404382176697254, Neurons: 64, Grad norm: 2.049e+00\n",
      "Epoch 13382, Loss: 0.006424849387258291, Neurons: 64, Grad norm: 2.019e+00\n",
      "Epoch 13382, Loss: 0.006424849387258291, Neurons: 64, Grad norm: 2.019e+00\n",
      "Epoch 13383, Loss: 0.006421124562621117, Neurons: 64, Grad norm: 1.608e+00\n",
      "Epoch 13383, Loss: 0.006421124562621117, Neurons: 64, Grad norm: 1.608e+00\n",
      "Epoch 13384, Loss: 0.006397242657840252, Neurons: 64, Grad norm: 9.645e-01\n",
      "Epoch 13384, Loss: 0.006397242657840252, Neurons: 64, Grad norm: 9.645e-01\n",
      "Epoch 13385, Loss: 0.006369918584823608, Neurons: 64, Grad norm: 1.931e-01\n",
      "Epoch 13385, Loss: 0.006369918584823608, Neurons: 64, Grad norm: 1.931e-01\n",
      "Epoch 13386, Loss: 0.006355095189064741, Neurons: 64, Grad norm: 5.177e-01\n",
      "Epoch 13386, Loss: 0.006355095189064741, Neurons: 64, Grad norm: 5.177e-01\n",
      "Epoch 13387, Loss: 0.0063576530665159225, Neurons: 64, Grad norm: 1.086e+00\n",
      "Epoch 13387, Loss: 0.0063576530665159225, Neurons: 64, Grad norm: 1.086e+00\n",
      "Epoch 13388, Loss: 0.006370403338223696, Neurons: 64, Grad norm: 1.385e+00\n",
      "Epoch 13388, Loss: 0.006370403338223696, Neurons: 64, Grad norm: 1.385e+00\n",
      "Epoch 13389, Loss: 0.006381154526025057, Neurons: 64, Grad norm: 1.432e+00\n",
      "Epoch 13389, Loss: 0.006381154526025057, Neurons: 64, Grad norm: 1.432e+00\n",
      "Epoch 13390, Loss: 0.006381637882441282, Neurons: 64, Grad norm: 1.211e+00\n",
      "Epoch 13390, Loss: 0.006381637882441282, Neurons: 64, Grad norm: 1.211e+00\n",
      "Epoch 13391, Loss: 0.006371719762682915, Neurons: 64, Grad norm: 8.261e-01\n",
      "Epoch 13391, Loss: 0.006371719762682915, Neurons: 64, Grad norm: 8.261e-01\n",
      "Epoch 13392, Loss: 0.0063579026609659195, Neurons: 64, Grad norm: 3.195e-01\n",
      "Epoch 13392, Loss: 0.0063579026609659195, Neurons: 64, Grad norm: 3.195e-01\n",
      "Epoch 13393, Loss: 0.006347861606627703, Neurons: 64, Grad norm: 1.739e-01\n",
      "Epoch 13393, Loss: 0.006347861606627703, Neurons: 64, Grad norm: 1.739e-01\n",
      "Epoch 13394, Loss: 0.006345574278384447, Neurons: 64, Grad norm: 6.075e-01\n",
      "Epoch 13394, Loss: 0.006345574278384447, Neurons: 64, Grad norm: 6.075e-01\n",
      "Epoch 13395, Loss: 0.006349578034132719, Neurons: 64, Grad norm: 8.758e-01\n",
      "Epoch 13395, Loss: 0.006349578034132719, Neurons: 64, Grad norm: 8.758e-01\n",
      "Epoch 13396, Loss: 0.006354974117130041, Neurons: 64, Grad norm: 9.970e-01\n",
      "Epoch 13396, Loss: 0.006354974117130041, Neurons: 64, Grad norm: 9.970e-01\n",
      "Epoch 13397, Loss: 0.006357030477374792, Neurons: 64, Grad norm: 9.279e-01\n",
      "Epoch 13397, Loss: 0.006357030477374792, Neurons: 64, Grad norm: 9.279e-01\n",
      "Epoch 13398, Loss: 0.006354034878313541, Neurons: 64, Grad norm: 7.335e-01\n",
      "Epoch 13398, Loss: 0.006354034878313541, Neurons: 64, Grad norm: 7.335e-01\n",
      "Epoch 13399, Loss: 0.0063475375063717365, Neurons: 64, Grad norm: 4.228e-01\n",
      "Epoch 13399, Loss: 0.0063475375063717365, Neurons: 64, Grad norm: 4.228e-01\n",
      "Epoch 13399, Test loss: 0.005113438703119755\n",
      "Epoch 13399, Test loss: 0.005113438703119755\n",
      "Epoch 13400, Loss: 0.006340909283608198, Neurons: 64, Grad norm: 9.755e-02\n",
      "Epoch 13400, Loss: 0.006340909283608198, Neurons: 64, Grad norm: 9.755e-02\n",
      "Epoch 13401, Loss: 0.006336988415569067, Neurons: 64, Grad norm: 2.298e-01\n",
      "Epoch 13401, Loss: 0.006336988415569067, Neurons: 64, Grad norm: 2.298e-01\n",
      "Epoch 13402, Loss: 0.006336458958685398, Neurons: 64, Grad norm: 4.695e-01\n",
      "Epoch 13402, Loss: 0.006336458958685398, Neurons: 64, Grad norm: 4.695e-01\n",
      "Epoch 13403, Loss: 0.006338028237223625, Neurons: 64, Grad norm: 6.299e-01\n",
      "Epoch 13403, Loss: 0.006338028237223625, Neurons: 64, Grad norm: 6.299e-01\n",
      "Epoch 13404, Loss: 0.006339562125504017, Neurons: 64, Grad norm: 6.590e-01\n",
      "Epoch 13404, Loss: 0.006339562125504017, Neurons: 64, Grad norm: 6.590e-01\n",
      "Epoch 13405, Loss: 0.006339315790683031, Neurons: 64, Grad norm: 6.090e-01\n",
      "Epoch 13405, Loss: 0.006339315790683031, Neurons: 64, Grad norm: 6.090e-01\n",
      "Epoch 13406, Loss: 0.006336991209536791, Neurons: 64, Grad norm: 4.545e-01\n",
      "Epoch 13406, Loss: 0.006336991209536791, Neurons: 64, Grad norm: 4.545e-01\n",
      "Epoch 13407, Loss: 0.006333403754979372, Neurons: 64, Grad norm: 2.672e-01\n",
      "Epoch 13407, Loss: 0.006333403754979372, Neurons: 64, Grad norm: 2.672e-01\n",
      "Epoch 13408, Loss: 0.006329918745905161, Neurons: 64, Grad norm: 6.026e-02\n",
      "Epoch 13408, Loss: 0.006329918745905161, Neurons: 64, Grad norm: 6.026e-02\n",
      "Epoch 13409, Loss: 0.006327636074274778, Neurons: 64, Grad norm: 1.640e-01\n",
      "Epoch 13409, Loss: 0.006327636074274778, Neurons: 64, Grad norm: 1.640e-01\n",
      "Epoch 13410, Loss: 0.0063267843797802925, Neurons: 64, Grad norm: 3.300e-01\n",
      "Epoch 13410, Loss: 0.0063267843797802925, Neurons: 64, Grad norm: 3.300e-01\n",
      "Epoch 13411, Loss: 0.006326738744974136, Neurons: 64, Grad norm: 4.227e-01\n",
      "Epoch 13411, Loss: 0.006326738744974136, Neurons: 64, Grad norm: 4.227e-01\n",
      "Epoch 13412, Loss: 0.0063266814686357975, Neurons: 64, Grad norm: 4.686e-01\n",
      "Epoch 13412, Loss: 0.0063266814686357975, Neurons: 64, Grad norm: 4.686e-01\n",
      "Epoch 13413, Loss: 0.006325969006866217, Neurons: 64, Grad norm: 4.313e-01\n",
      "Epoch 13413, Loss: 0.006325969006866217, Neurons: 64, Grad norm: 4.313e-01\n",
      "Epoch 13414, Loss: 0.006324421148747206, Neurons: 64, Grad norm: 3.615e-01\n",
      "Epoch 13414, Loss: 0.006324421148747206, Neurons: 64, Grad norm: 3.615e-01\n",
      "Epoch 13415, Loss: 0.006322297267615795, Neurons: 64, Grad norm: 2.359e-01\n",
      "Epoch 13415, Loss: 0.006322297267615795, Neurons: 64, Grad norm: 2.359e-01\n",
      "Epoch 13416, Loss: 0.006320066284388304, Neurons: 64, Grad norm: 1.137e-01\n",
      "Epoch 13416, Loss: 0.006320066284388304, Neurons: 64, Grad norm: 1.137e-01\n",
      "Epoch 13417, Loss: 0.006318151485174894, Neurons: 64, Grad norm: 4.132e-02\n",
      "Epoch 13417, Loss: 0.006318151485174894, Neurons: 64, Grad norm: 4.132e-02\n",
      "Epoch 13418, Loss: 0.006316828075796366, Neurons: 64, Grad norm: 1.372e-01\n",
      "Epoch 13418, Loss: 0.006316828075796366, Neurons: 64, Grad norm: 1.372e-01\n",
      "Epoch 13419, Loss: 0.006315982900559902, Neurons: 64, Grad norm: 2.323e-01\n",
      "Epoch 13419, Loss: 0.006315982900559902, Neurons: 64, Grad norm: 2.323e-01\n",
      "Epoch 13420, Loss: 0.006315369624644518, Neurons: 64, Grad norm: 2.716e-01\n",
      "Epoch 13420, Loss: 0.006315369624644518, Neurons: 64, Grad norm: 2.716e-01\n",
      "Epoch 13421, Loss: 0.006314648315310478, Neurons: 64, Grad norm: 2.912e-01\n",
      "Epoch 13421, Loss: 0.006314648315310478, Neurons: 64, Grad norm: 2.912e-01\n",
      "Epoch 13422, Loss: 0.006313605699688196, Neurons: 64, Grad norm: 2.568e-01\n",
      "Epoch 13422, Loss: 0.006313605699688196, Neurons: 64, Grad norm: 2.568e-01\n",
      "Epoch 13423, Loss: 0.006312259007245302, Neurons: 64, Grad norm: 2.157e-01\n",
      "Epoch 13423, Loss: 0.006312259007245302, Neurons: 64, Grad norm: 2.157e-01\n",
      "Epoch 13424, Loss: 0.006310689728707075, Neurons: 64, Grad norm: 1.328e-01\n",
      "Epoch 13424, Loss: 0.006310689728707075, Neurons: 64, Grad norm: 1.328e-01\n",
      "Epoch 13425, Loss: 0.006309173535555601, Neurons: 64, Grad norm: 8.186e-02\n",
      "Epoch 13425, Loss: 0.006309173535555601, Neurons: 64, Grad norm: 8.186e-02\n",
      "Epoch 13426, Loss: 0.006307739764451981, Neurons: 64, Grad norm: 8.520e-02\n",
      "Epoch 13426, Loss: 0.006307739764451981, Neurons: 64, Grad norm: 8.520e-02\n",
      "Epoch 13427, Loss: 0.006306551396846771, Neurons: 64, Grad norm: 1.320e-01\n",
      "Epoch 13427, Loss: 0.006306551396846771, Neurons: 64, Grad norm: 1.320e-01\n",
      "Epoch 13428, Loss: 0.006305508781224489, Neurons: 64, Grad norm: 1.888e-01\n",
      "Epoch 13428, Loss: 0.006305508781224489, Neurons: 64, Grad norm: 1.888e-01\n",
      "Epoch 13429, Loss: 0.006304614245891571, Neurons: 64, Grad norm: 2.152e-01\n",
      "Epoch 13429, Loss: 0.006304614245891571, Neurons: 64, Grad norm: 2.152e-01\n",
      "Epoch 13430, Loss: 0.006303655914962292, Neurons: 64, Grad norm: 2.402e-01\n",
      "Epoch 13430, Loss: 0.006303655914962292, Neurons: 64, Grad norm: 2.402e-01\n",
      "Epoch 13431, Loss: 0.006302672903984785, Neurons: 64, Grad norm: 2.292e-01\n",
      "Epoch 13431, Loss: 0.006302672903984785, Neurons: 64, Grad norm: 2.292e-01\n",
      "Epoch 13432, Loss: 0.006301526911556721, Neurons: 64, Grad norm: 2.211e-01\n",
      "Epoch 13432, Loss: 0.006301526911556721, Neurons: 64, Grad norm: 2.211e-01\n",
      "Epoch 13433, Loss: 0.006300319451838732, Neurons: 64, Grad norm: 1.937e-01\n",
      "Epoch 13433, Loss: 0.006300319451838732, Neurons: 64, Grad norm: 1.937e-01\n",
      "Epoch 13434, Loss: 0.006299206987023354, Neurons: 64, Grad norm: 1.826e-01\n",
      "Epoch 13434, Loss: 0.006299206987023354, Neurons: 64, Grad norm: 1.826e-01\n",
      "Epoch 13435, Loss: 0.0062981839291751385, Neurons: 64, Grad norm: 1.763e-01\n",
      "Epoch 13435, Loss: 0.0062981839291751385, Neurons: 64, Grad norm: 1.763e-01\n",
      "Epoch 13436, Loss: 0.006297368556261063, Neurons: 64, Grad norm: 1.917e-01\n",
      "Epoch 13436, Loss: 0.006297368556261063, Neurons: 64, Grad norm: 1.917e-01\n",
      "Epoch 13437, Loss: 0.006296776235103607, Neurons: 64, Grad norm: 2.229e-01\n",
      "Epoch 13437, Loss: 0.006296776235103607, Neurons: 64, Grad norm: 2.229e-01\n",
      "Epoch 13438, Loss: 0.006296579726040363, Neurons: 64, Grad norm: 2.578e-01\n",
      "Epoch 13438, Loss: 0.006296579726040363, Neurons: 64, Grad norm: 2.578e-01\n",
      "Epoch 13439, Loss: 0.006296619772911072, Neurons: 64, Grad norm: 3.032e-01\n",
      "Epoch 13439, Loss: 0.006296619772911072, Neurons: 64, Grad norm: 3.032e-01\n",
      "Epoch 13440, Loss: 0.006297015119343996, Neurons: 64, Grad norm: 3.445e-01\n",
      "Epoch 13440, Loss: 0.006297015119343996, Neurons: 64, Grad norm: 3.445e-01\n",
      "Epoch 13441, Loss: 0.006297882180660963, Neurons: 64, Grad norm: 3.995e-01\n",
      "Epoch 13441, Loss: 0.006297882180660963, Neurons: 64, Grad norm: 3.995e-01\n",
      "Epoch 13442, Loss: 0.006299299653619528, Neurons: 64, Grad norm: 4.571e-01\n",
      "Epoch 13442, Loss: 0.006299299653619528, Neurons: 64, Grad norm: 4.571e-01\n",
      "Epoch 13443, Loss: 0.0063014342449605465, Neurons: 64, Grad norm: 5.310e-01\n",
      "Epoch 13443, Loss: 0.0063014342449605465, Neurons: 64, Grad norm: 5.310e-01\n",
      "Epoch 13444, Loss: 0.006304675713181496, Neurons: 64, Grad norm: 6.182e-01\n",
      "Epoch 13444, Loss: 0.006304675713181496, Neurons: 64, Grad norm: 6.182e-01\n",
      "Epoch 13445, Loss: 0.006309497635811567, Neurons: 64, Grad norm: 7.256e-01\n",
      "Epoch 13445, Loss: 0.006309497635811567, Neurons: 64, Grad norm: 7.256e-01\n",
      "Epoch 13446, Loss: 0.006316890008747578, Neurons: 64, Grad norm: 8.535e-01\n",
      "Epoch 13446, Loss: 0.006316890008747578, Neurons: 64, Grad norm: 8.535e-01\n",
      "Epoch 13447, Loss: 0.006327121984213591, Neurons: 64, Grad norm: 1.000e+00\n",
      "Epoch 13447, Loss: 0.006327121984213591, Neurons: 64, Grad norm: 1.000e+00\n",
      "Epoch 13448, Loss: 0.0063417511992156506, Neurons: 64, Grad norm: 1.167e+00\n",
      "Epoch 13448, Loss: 0.0063417511992156506, Neurons: 64, Grad norm: 1.167e+00\n",
      "Epoch 13449, Loss: 0.006361105479300022, Neurons: 64, Grad norm: 1.352e+00\n",
      "Epoch 13449, Loss: 0.006361105479300022, Neurons: 64, Grad norm: 1.352e+00\n",
      "Epoch 13450, Loss: 0.006387175992131233, Neurons: 64, Grad norm: 1.554e+00\n",
      "Epoch 13450, Loss: 0.006387175992131233, Neurons: 64, Grad norm: 1.554e+00\n",
      "Epoch 13451, Loss: 0.0064195687882602215, Neurons: 64, Grad norm: 1.763e+00\n",
      "Epoch 13451, Loss: 0.0064195687882602215, Neurons: 64, Grad norm: 1.763e+00\n",
      "Epoch 13452, Loss: 0.006458963267505169, Neurons: 64, Grad norm: 1.970e+00\n",
      "Epoch 13452, Loss: 0.006458963267505169, Neurons: 64, Grad norm: 1.970e+00\n",
      "Epoch 13453, Loss: 0.006501465104520321, Neurons: 64, Grad norm: 2.150e+00\n",
      "Epoch 13453, Loss: 0.006501465104520321, Neurons: 64, Grad norm: 2.150e+00\n",
      "Epoch 13454, Loss: 0.006542634218931198, Neurons: 64, Grad norm: 2.282e+00\n",
      "Epoch 13454, Loss: 0.006542634218931198, Neurons: 64, Grad norm: 2.282e+00\n",
      "Epoch 13455, Loss: 0.006571508944034576, Neurons: 64, Grad norm: 2.329e+00\n",
      "Epoch 13455, Loss: 0.006571508944034576, Neurons: 64, Grad norm: 2.329e+00\n",
      "Epoch 13456, Loss: 0.006578347645699978, Neurons: 64, Grad norm: 2.266e+00\n",
      "Epoch 13456, Loss: 0.006578347645699978, Neurons: 64, Grad norm: 2.266e+00\n",
      "Epoch 13457, Loss: 0.006552258040755987, Neurons: 64, Grad norm: 2.072e+00\n",
      "Epoch 13457, Loss: 0.006552258040755987, Neurons: 64, Grad norm: 2.072e+00\n",
      "Epoch 13458, Loss: 0.00649379612877965, Neurons: 64, Grad norm: 1.760e+00\n",
      "Epoch 13458, Loss: 0.00649379612877965, Neurons: 64, Grad norm: 1.760e+00\n",
      "Epoch 13459, Loss: 0.006416058633476496, Neurons: 64, Grad norm: 1.362e+00\n",
      "Epoch 13459, Loss: 0.006416058633476496, Neurons: 64, Grad norm: 1.362e+00\n",
      "Epoch 13460, Loss: 0.006341411732137203, Neurons: 64, Grad norm: 9.705e-01\n",
      "Epoch 13460, Loss: 0.006341411732137203, Neurons: 64, Grad norm: 9.705e-01\n",
      "Epoch 13461, Loss: 0.006290488410741091, Neurons: 64, Grad norm: 6.936e-01\n",
      "Epoch 13461, Loss: 0.006290488410741091, Neurons: 64, Grad norm: 6.936e-01\n",
      "Epoch 13462, Loss: 0.006272996310144663, Neurons: 64, Grad norm: 7.066e-01\n",
      "Epoch 13462, Loss: 0.006272996310144663, Neurons: 64, Grad norm: 7.066e-01\n",
      "Epoch 13463, Loss: 0.006284461356699467, Neurons: 64, Grad norm: 8.774e-01\n",
      "Epoch 13463, Loss: 0.006284461356699467, Neurons: 64, Grad norm: 8.774e-01\n",
      "Epoch 13464, Loss: 0.006311261560767889, Neurons: 64, Grad norm: 1.059e+00\n",
      "Epoch 13464, Loss: 0.006311261560767889, Neurons: 64, Grad norm: 1.059e+00\n",
      "Epoch 13465, Loss: 0.0063373311422765255, Neurons: 64, Grad norm: 1.154e+00\n",
      "Epoch 13465, Loss: 0.0063373311422765255, Neurons: 64, Grad norm: 1.154e+00\n",
      "Epoch 13466, Loss: 0.006349986419081688, Neurons: 64, Grad norm: 1.162e+00\n",
      "Epoch 13466, Loss: 0.006349986419081688, Neurons: 64, Grad norm: 1.162e+00\n",
      "Epoch 13467, Loss: 0.006344430614262819, Neurons: 64, Grad norm: 1.089e+00\n",
      "Epoch 13467, Loss: 0.006344430614262819, Neurons: 64, Grad norm: 1.089e+00\n",
      "Epoch 13468, Loss: 0.0063240863382816315, Neurons: 64, Grad norm: 9.717e-01\n",
      "Epoch 13468, Loss: 0.0063240863382816315, Neurons: 64, Grad norm: 9.717e-01\n",
      "Epoch 13469, Loss: 0.006297982297837734, Neurons: 64, Grad norm: 8.736e-01\n",
      "Epoch 13469, Loss: 0.006297982297837734, Neurons: 64, Grad norm: 8.736e-01\n",
      "Epoch 13470, Loss: 0.006276461761444807, Neurons: 64, Grad norm: 8.229e-01\n",
      "Epoch 13470, Loss: 0.006276461761444807, Neurons: 64, Grad norm: 8.229e-01\n",
      "Epoch 13471, Loss: 0.0062659201212227345, Neurons: 64, Grad norm: 8.611e-01\n",
      "Epoch 13471, Loss: 0.0062659201212227345, Neurons: 64, Grad norm: 8.611e-01\n",
      "Epoch 13472, Loss: 0.006267067976295948, Neurons: 64, Grad norm: 9.056e-01\n",
      "Epoch 13472, Loss: 0.006267067976295948, Neurons: 64, Grad norm: 9.056e-01\n",
      "Epoch 13473, Loss: 0.006275401450693607, Neurons: 64, Grad norm: 9.516e-01\n",
      "Epoch 13473, Loss: 0.006275401450693607, Neurons: 64, Grad norm: 9.516e-01\n",
      "Epoch 13474, Loss: 0.006284327711910009, Neurons: 64, Grad norm: 9.232e-01\n",
      "Epoch 13474, Loss: 0.006284327711910009, Neurons: 64, Grad norm: 9.232e-01\n",
      "Epoch 13475, Loss: 0.00628825044259429, Neurons: 64, Grad norm: 8.519e-01\n",
      "Epoch 13475, Loss: 0.00628825044259429, Neurons: 64, Grad norm: 8.519e-01\n",
      "Epoch 13476, Loss: 0.006284920033067465, Neurons: 64, Grad norm: 7.038e-01\n",
      "Epoch 13476, Loss: 0.006284920033067465, Neurons: 64, Grad norm: 7.038e-01\n",
      "Epoch 13477, Loss: 0.00627531111240387, Neurons: 64, Grad norm: 5.214e-01\n",
      "Epoch 13477, Loss: 0.00627531111240387, Neurons: 64, Grad norm: 5.214e-01\n",
      "Epoch 13478, Loss: 0.006263048388063908, Neurons: 64, Grad norm: 3.065e-01\n",
      "Epoch 13478, Loss: 0.006263048388063908, Neurons: 64, Grad norm: 3.065e-01\n",
      "Epoch 13479, Loss: 0.0062521654181182384, Neurons: 64, Grad norm: 1.397e-01\n",
      "Epoch 13479, Loss: 0.0062521654181182384, Neurons: 64, Grad norm: 1.397e-01\n",
      "Epoch 13480, Loss: 0.006245795637369156, Neurons: 64, Grad norm: 2.221e-01\n",
      "Epoch 13480, Loss: 0.006245795637369156, Neurons: 64, Grad norm: 2.221e-01\n",
      "Epoch 13481, Loss: 0.006244552321732044, Neurons: 64, Grad norm: 3.781e-01\n",
      "Epoch 13481, Loss: 0.006244552321732044, Neurons: 64, Grad norm: 3.781e-01\n",
      "Epoch 13482, Loss: 0.006247255485504866, Neurons: 64, Grad norm: 5.275e-01\n",
      "Epoch 13482, Loss: 0.006247255485504866, Neurons: 64, Grad norm: 5.275e-01\n",
      "Epoch 13483, Loss: 0.006251469254493713, Neurons: 64, Grad norm: 6.122e-01\n",
      "Epoch 13483, Loss: 0.006251469254493713, Neurons: 64, Grad norm: 6.122e-01\n",
      "Epoch 13484, Loss: 0.0062546818517148495, Neurons: 64, Grad norm: 6.645e-01\n",
      "Epoch 13484, Loss: 0.0062546818517148495, Neurons: 64, Grad norm: 6.645e-01\n",
      "Epoch 13485, Loss: 0.006255474407225847, Neurons: 64, Grad norm: 6.539e-01\n",
      "Epoch 13485, Loss: 0.006255474407225847, Neurons: 64, Grad norm: 6.539e-01\n",
      "Epoch 13486, Loss: 0.006253378465771675, Neurons: 64, Grad norm: 6.291e-01\n",
      "Epoch 13486, Loss: 0.006253378465771675, Neurons: 64, Grad norm: 6.291e-01\n",
      "Epoch 13487, Loss: 0.006249079946428537, Neurons: 64, Grad norm: 5.572e-01\n",
      "Epoch 13487, Loss: 0.006249079946428537, Neurons: 64, Grad norm: 5.572e-01\n",
      "Epoch 13488, Loss: 0.0062439925968647, Neurons: 64, Grad norm: 5.012e-01\n",
      "Epoch 13488, Loss: 0.0062439925968647, Neurons: 64, Grad norm: 5.012e-01\n",
      "Epoch 13489, Loss: 0.006239468697458506, Neurons: 64, Grad norm: 4.332e-01\n",
      "Epoch 13489, Loss: 0.006239468697458506, Neurons: 64, Grad norm: 4.332e-01\n",
      "Epoch 13490, Loss: 0.0062363771721720695, Neurons: 64, Grad norm: 4.032e-01\n",
      "Epoch 13490, Loss: 0.0062363771721720695, Neurons: 64, Grad norm: 4.032e-01\n",
      "Epoch 13491, Loss: 0.006234806030988693, Neurons: 64, Grad norm: 3.820e-01\n",
      "Epoch 13491, Loss: 0.006234806030988693, Neurons: 64, Grad norm: 3.820e-01\n",
      "Epoch 13492, Loss: 0.006234451197087765, Neurons: 64, Grad norm: 3.883e-01\n",
      "Epoch 13492, Loss: 0.006234451197087765, Neurons: 64, Grad norm: 3.883e-01\n",
      "Epoch 13493, Loss: 0.006234655622392893, Neurons: 64, Grad norm: 3.823e-01\n",
      "Epoch 13493, Loss: 0.006234655622392893, Neurons: 64, Grad norm: 3.823e-01\n",
      "Epoch 13494, Loss: 0.006234611850231886, Neurons: 64, Grad norm: 3.811e-01\n",
      "Epoch 13494, Loss: 0.006234611850231886, Neurons: 64, Grad norm: 3.811e-01\n",
      "Epoch 13495, Loss: 0.006233958527445793, Neurons: 64, Grad norm: 3.584e-01\n",
      "Epoch 13495, Loss: 0.006233958527445793, Neurons: 64, Grad norm: 3.584e-01\n",
      "Epoch 13496, Loss: 0.006232410669326782, Neurons: 64, Grad norm: 3.301e-01\n",
      "Epoch 13496, Loss: 0.006232410669326782, Neurons: 64, Grad norm: 3.301e-01\n",
      "Epoch 13497, Loss: 0.006230320781469345, Neurons: 64, Grad norm: 2.847e-01\n",
      "Epoch 13497, Loss: 0.006230320781469345, Neurons: 64, Grad norm: 2.847e-01\n",
      "Epoch 13498, Loss: 0.006227754056453705, Neurons: 64, Grad norm: 2.432e-01\n",
      "Epoch 13498, Loss: 0.006227754056453705, Neurons: 64, Grad norm: 2.432e-01\n",
      "Epoch 13499, Loss: 0.006225223187357187, Neurons: 64, Grad norm: 1.959e-01\n",
      "Epoch 13499, Loss: 0.006225223187357187, Neurons: 64, Grad norm: 1.959e-01\n",
      "Epoch 13499, Test loss: 0.005038338713347912\n",
      "Epoch 13499, Test loss: 0.005038338713347912\n",
      "Epoch 13500, Loss: 0.006223008036613464, Neurons: 64, Grad norm: 1.759e-01\n",
      "Epoch 13500, Loss: 0.006223008036613464, Neurons: 64, Grad norm: 1.759e-01\n",
      "Epoch 13501, Loss: 0.006221286952495575, Neurons: 64, Grad norm: 1.571e-01\n",
      "Epoch 13501, Loss: 0.006221286952495575, Neurons: 64, Grad norm: 1.571e-01\n",
      "Epoch 13502, Loss: 0.006220078095793724, Neurons: 64, Grad norm: 1.759e-01\n",
      "Epoch 13502, Loss: 0.006220078095793724, Neurons: 64, Grad norm: 1.759e-01\n",
      "Epoch 13503, Loss: 0.006219140719622374, Neurons: 64, Grad norm: 1.799e-01\n",
      "Epoch 13503, Loss: 0.006219140719622374, Neurons: 64, Grad norm: 1.799e-01\n",
      "Epoch 13504, Loss: 0.006218398455530405, Neurons: 64, Grad norm: 2.043e-01\n",
      "Epoch 13504, Loss: 0.006218398455530405, Neurons: 64, Grad norm: 2.043e-01\n",
      "Epoch 13505, Loss: 0.006217744201421738, Neurons: 64, Grad norm: 2.064e-01\n",
      "Epoch 13505, Loss: 0.006217744201421738, Neurons: 64, Grad norm: 2.064e-01\n",
      "Epoch 13506, Loss: 0.006216846872121096, Neurons: 64, Grad norm: 2.193e-01\n",
      "Epoch 13506, Loss: 0.006216846872121096, Neurons: 64, Grad norm: 2.193e-01\n",
      "Epoch 13507, Loss: 0.006215956993401051, Neurons: 64, Grad norm: 2.087e-01\n",
      "Epoch 13507, Loss: 0.006215956993401051, Neurons: 64, Grad norm: 2.087e-01\n",
      "Epoch 13508, Loss: 0.0062147811986505985, Neurons: 64, Grad norm: 2.125e-01\n",
      "Epoch 13508, Loss: 0.0062147811986505985, Neurons: 64, Grad norm: 2.125e-01\n",
      "Epoch 13509, Loss: 0.006213589105755091, Neurons: 64, Grad norm: 1.921e-01\n",
      "Epoch 13509, Loss: 0.006213589105755091, Neurons: 64, Grad norm: 1.921e-01\n",
      "Epoch 13510, Loss: 0.006212194450199604, Neurons: 64, Grad norm: 1.889e-01\n",
      "Epoch 13510, Loss: 0.006212194450199604, Neurons: 64, Grad norm: 1.889e-01\n",
      "Epoch 13511, Loss: 0.006210677325725555, Neurons: 64, Grad norm: 1.673e-01\n",
      "Epoch 13511, Loss: 0.006210677325725555, Neurons: 64, Grad norm: 1.673e-01\n",
      "Epoch 13512, Loss: 0.006209270562976599, Neurons: 64, Grad norm: 1.656e-01\n",
      "Epoch 13512, Loss: 0.006209270562976599, Neurons: 64, Grad norm: 1.656e-01\n",
      "Epoch 13513, Loss: 0.006207787897437811, Neurons: 64, Grad norm: 1.508e-01\n",
      "Epoch 13513, Loss: 0.006207787897437811, Neurons: 64, Grad norm: 1.508e-01\n",
      "Epoch 13514, Loss: 0.006206430960446596, Neurons: 64, Grad norm: 1.656e-01\n",
      "Epoch 13514, Loss: 0.006206430960446596, Neurons: 64, Grad norm: 1.656e-01\n",
      "Epoch 13515, Loss: 0.006205232813954353, Neurons: 64, Grad norm: 1.668e-01\n",
      "Epoch 13515, Loss: 0.006205232813954353, Neurons: 64, Grad norm: 1.668e-01\n",
      "Epoch 13516, Loss: 0.006204115226864815, Neurons: 64, Grad norm: 1.971e-01\n",
      "Epoch 13516, Loss: 0.006204115226864815, Neurons: 64, Grad norm: 1.971e-01\n",
      "Epoch 13517, Loss: 0.00620314572006464, Neurons: 64, Grad norm: 2.139e-01\n",
      "Epoch 13517, Loss: 0.00620314572006464, Neurons: 64, Grad norm: 2.139e-01\n",
      "Epoch 13518, Loss: 0.006202284712344408, Neurons: 64, Grad norm: 2.554e-01\n",
      "Epoch 13518, Loss: 0.006202284712344408, Neurons: 64, Grad norm: 2.554e-01\n",
      "Epoch 13519, Loss: 0.006201426964253187, Neurons: 64, Grad norm: 2.895e-01\n",
      "Epoch 13519, Loss: 0.006201426964253187, Neurons: 64, Grad norm: 2.895e-01\n",
      "Epoch 13520, Loss: 0.006200727075338364, Neurons: 64, Grad norm: 3.481e-01\n",
      "Epoch 13520, Loss: 0.006200727075338364, Neurons: 64, Grad norm: 3.481e-01\n",
      "Epoch 13521, Loss: 0.006200282834470272, Neurons: 64, Grad norm: 3.994e-01\n",
      "Epoch 13521, Loss: 0.006200282834470272, Neurons: 64, Grad norm: 3.994e-01\n",
      "Epoch 13522, Loss: 0.006199979223310947, Neurons: 64, Grad norm: 4.815e-01\n",
      "Epoch 13522, Loss: 0.006199979223310947, Neurons: 64, Grad norm: 4.815e-01\n",
      "Epoch 13523, Loss: 0.006199976895004511, Neurons: 64, Grad norm: 5.628e-01\n",
      "Epoch 13523, Loss: 0.006199976895004511, Neurons: 64, Grad norm: 5.628e-01\n",
      "Epoch 13524, Loss: 0.006200586911290884, Neurons: 64, Grad norm: 6.815e-01\n",
      "Epoch 13524, Loss: 0.006200586911290884, Neurons: 64, Grad norm: 6.815e-01\n",
      "Epoch 13525, Loss: 0.006201640237122774, Neurons: 64, Grad norm: 8.048e-01\n",
      "Epoch 13525, Loss: 0.006201640237122774, Neurons: 64, Grad norm: 8.048e-01\n",
      "Epoch 13526, Loss: 0.006203606724739075, Neurons: 64, Grad norm: 9.746e-01\n",
      "Epoch 13526, Loss: 0.006203606724739075, Neurons: 64, Grad norm: 9.746e-01\n",
      "Epoch 13527, Loss: 0.00620694924145937, Neurons: 64, Grad norm: 1.165e+00\n",
      "Epoch 13527, Loss: 0.00620694924145937, Neurons: 64, Grad norm: 1.165e+00\n",
      "Epoch 13528, Loss: 0.006212390027940273, Neurons: 64, Grad norm: 1.421e+00\n",
      "Epoch 13528, Loss: 0.006212390027940273, Neurons: 64, Grad norm: 1.421e+00\n",
      "Epoch 13529, Loss: 0.006221007090061903, Neurons: 64, Grad norm: 1.715e+00\n",
      "Epoch 13529, Loss: 0.006221007090061903, Neurons: 64, Grad norm: 1.715e+00\n",
      "Epoch 13530, Loss: 0.006234341766685247, Neurons: 64, Grad norm: 2.097e+00\n",
      "Epoch 13530, Loss: 0.006234341766685247, Neurons: 64, Grad norm: 2.097e+00\n",
      "Epoch 13531, Loss: 0.006254812236875296, Neurons: 64, Grad norm: 2.549e+00\n",
      "Epoch 13531, Loss: 0.006254812236875296, Neurons: 64, Grad norm: 2.549e+00\n",
      "Epoch 13532, Loss: 0.0062863705679774284, Neurons: 64, Grad norm: 3.125e+00\n",
      "Epoch 13532, Loss: 0.0062863705679774284, Neurons: 64, Grad norm: 3.125e+00\n",
      "Epoch 13533, Loss: 0.006334108766168356, Neurons: 64, Grad norm: 3.807e+00\n",
      "Epoch 13533, Loss: 0.006334108766168356, Neurons: 64, Grad norm: 3.807e+00\n",
      "Epoch 13534, Loss: 0.006406071130186319, Neurons: 64, Grad norm: 4.647e+00\n",
      "Epoch 13534, Loss: 0.006406071130186319, Neurons: 64, Grad norm: 4.647e+00\n",
      "Epoch 13535, Loss: 0.006511942017823458, Neurons: 64, Grad norm: 5.620e+00\n",
      "Epoch 13535, Loss: 0.006511942017823458, Neurons: 64, Grad norm: 5.620e+00\n",
      "Epoch 13536, Loss: 0.006664591375738382, Neurons: 64, Grad norm: 6.750e+00\n",
      "Epoch 13536, Loss: 0.006664591375738382, Neurons: 64, Grad norm: 6.750e+00\n",
      "Epoch 13537, Loss: 0.006873840466141701, Neurons: 64, Grad norm: 7.942e+00\n",
      "Epoch 13537, Loss: 0.006873840466141701, Neurons: 64, Grad norm: 7.942e+00\n",
      "Epoch 13538, Loss: 0.007142974995076656, Neurons: 64, Grad norm: 9.121e+00\n",
      "Epoch 13538, Loss: 0.007142974995076656, Neurons: 64, Grad norm: 9.121e+00\n",
      "Epoch 13539, Loss: 0.007444721646606922, Neurons: 64, Grad norm: 1.004e+01\n",
      "Epoch 13539, Loss: 0.007444721646606922, Neurons: 64, Grad norm: 1.004e+01\n",
      "Epoch 13540, Loss: 0.007716770749539137, Neurons: 64, Grad norm: 1.045e+01\n",
      "Epoch 13540, Loss: 0.007716770749539137, Neurons: 64, Grad norm: 1.045e+01\n",
      "Epoch 13541, Loss: 0.00783891323953867, Neurons: 64, Grad norm: 9.997e+00\n",
      "Epoch 13541, Loss: 0.00783891323953867, Neurons: 64, Grad norm: 9.997e+00\n",
      "Epoch 13542, Loss: 0.007703053764998913, Neurons: 64, Grad norm: 8.528e+00\n",
      "Epoch 13542, Loss: 0.007703053764998913, Neurons: 64, Grad norm: 8.528e+00\n",
      "Epoch 13543, Loss: 0.007285046856850386, Neurons: 64, Grad norm: 6.066e+00\n",
      "Epoch 13543, Loss: 0.007285046856850386, Neurons: 64, Grad norm: 6.066e+00\n",
      "Epoch 13544, Loss: 0.006741789169609547, Neurons: 64, Grad norm: 2.996e+00\n",
      "Epoch 13544, Loss: 0.006741789169609547, Neurons: 64, Grad norm: 2.996e+00\n",
      "Epoch 13545, Loss: 0.006321525201201439, Neurons: 64, Grad norm: 7.068e-01\n",
      "Epoch 13545, Loss: 0.006321525201201439, Neurons: 64, Grad norm: 7.068e-01\n",
      "Epoch 13546, Loss: 0.006198808550834656, Neurons: 64, Grad norm: 3.236e+00\n",
      "Epoch 13546, Loss: 0.006198808550834656, Neurons: 64, Grad norm: 3.236e+00\n",
      "Epoch 13547, Loss: 0.0063547431491315365, Neurons: 64, Grad norm: 5.282e+00\n",
      "Epoch 13547, Loss: 0.0063547431491315365, Neurons: 64, Grad norm: 5.282e+00\n",
      "Epoch 13548, Loss: 0.006616280879825354, Neurons: 64, Grad norm: 6.256e+00\n",
      "Epoch 13548, Loss: 0.006616280879825354, Neurons: 64, Grad norm: 6.256e+00\n",
      "Epoch 13549, Loss: 0.006781804375350475, Neurons: 64, Grad norm: 6.075e+00\n",
      "Epoch 13549, Loss: 0.006781804375350475, Neurons: 64, Grad norm: 6.075e+00\n",
      "Epoch 13550, Loss: 0.006735737901180983, Neurons: 64, Grad norm: 4.805e+00\n",
      "Epoch 13550, Loss: 0.006735737901180983, Neurons: 64, Grad norm: 4.805e+00\n",
      "Epoch 13551, Loss: 0.006519177928566933, Neurons: 64, Grad norm: 2.798e+00\n",
      "Epoch 13551, Loss: 0.006519177928566933, Neurons: 64, Grad norm: 2.798e+00\n",
      "Epoch 13552, Loss: 0.006284739822149277, Neurons: 64, Grad norm: 6.391e-01\n",
      "Epoch 13552, Loss: 0.006284739822149277, Neurons: 64, Grad norm: 6.391e-01\n",
      "Epoch 13553, Loss: 0.006179824471473694, Neurons: 64, Grad norm: 1.848e+00\n",
      "Epoch 13553, Loss: 0.006179824471473694, Neurons: 64, Grad norm: 1.848e+00\n",
      "Epoch 13554, Loss: 0.006236754823476076, Neurons: 64, Grad norm: 3.429e+00\n",
      "Epoch 13554, Loss: 0.006236754823476076, Neurons: 64, Grad norm: 3.429e+00\n",
      "Epoch 13555, Loss: 0.006369657814502716, Neurons: 64, Grad norm: 4.187e+00\n",
      "Epoch 13555, Loss: 0.006369657814502716, Neurons: 64, Grad norm: 4.187e+00\n",
      "Epoch 13556, Loss: 0.006456304807215929, Neurons: 64, Grad norm: 4.056e+00\n",
      "Epoch 13556, Loss: 0.006456304807215929, Neurons: 64, Grad norm: 4.056e+00\n",
      "Epoch 13557, Loss: 0.0064282226376235485, Neurons: 64, Grad norm: 3.112e+00\n",
      "Epoch 13557, Loss: 0.0064282226376235485, Neurons: 64, Grad norm: 3.112e+00\n",
      "Epoch 13558, Loss: 0.0063127935864031315, Neurons: 64, Grad norm: 1.651e+00\n",
      "Epoch 13558, Loss: 0.0063127935864031315, Neurons: 64, Grad norm: 1.651e+00\n",
      "Epoch 13559, Loss: 0.006197557784616947, Neurons: 64, Grad norm: 1.858e-01\n",
      "Epoch 13559, Loss: 0.006197557784616947, Neurons: 64, Grad norm: 1.858e-01\n",
      "Epoch 13560, Loss: 0.006156831979751587, Neurons: 64, Grad norm: 1.507e+00\n",
      "Epoch 13560, Loss: 0.006156831979751587, Neurons: 64, Grad norm: 1.507e+00\n",
      "Epoch 13561, Loss: 0.00619778735563159, Neurons: 64, Grad norm: 2.537e+00\n",
      "Epoch 13561, Loss: 0.00619778735563159, Neurons: 64, Grad norm: 2.537e+00\n",
      "Epoch 13562, Loss: 0.006267715711146593, Neurons: 64, Grad norm: 2.935e+00\n",
      "Epoch 13562, Loss: 0.006267715711146593, Neurons: 64, Grad norm: 2.935e+00\n",
      "Epoch 13563, Loss: 0.00630353344604373, Neurons: 64, Grad norm: 2.706e+00\n",
      "Epoch 13563, Loss: 0.00630353344604373, Neurons: 64, Grad norm: 2.706e+00\n",
      "Epoch 13564, Loss: 0.006278573535382748, Neurons: 64, Grad norm: 1.933e+00\n",
      "Epoch 13564, Loss: 0.006278573535382748, Neurons: 64, Grad norm: 1.933e+00\n",
      "Epoch 13565, Loss: 0.006216100882738829, Neurons: 64, Grad norm: 8.543e-01\n",
      "Epoch 13565, Loss: 0.006216100882738829, Neurons: 64, Grad norm: 8.543e-01\n",
      "Epoch 13566, Loss: 0.006161937490105629, Neurons: 64, Grad norm: 3.285e-01\n",
      "Epoch 13566, Loss: 0.006161937490105629, Neurons: 64, Grad norm: 3.285e-01\n",
      "Epoch 13567, Loss: 0.006148465443402529, Neurons: 64, Grad norm: 1.291e+00\n",
      "Epoch 13567, Loss: 0.006148465443402529, Neurons: 64, Grad norm: 1.291e+00\n",
      "Epoch 13568, Loss: 0.006172811612486839, Neurons: 64, Grad norm: 1.929e+00\n",
      "Epoch 13568, Loss: 0.006172811612486839, Neurons: 64, Grad norm: 1.929e+00\n",
      "Epoch 13569, Loss: 0.006205752957612276, Neurons: 64, Grad norm: 2.101e+00\n",
      "Epoch 13569, Loss: 0.006205752957612276, Neurons: 64, Grad norm: 2.101e+00\n",
      "Epoch 13570, Loss: 0.006218130234628916, Neurons: 64, Grad norm: 1.851e+00\n",
      "Epoch 13570, Loss: 0.006218130234628916, Neurons: 64, Grad norm: 1.851e+00\n",
      "Epoch 13571, Loss: 0.006201366428285837, Neurons: 64, Grad norm: 1.248e+00\n",
      "Epoch 13571, Loss: 0.006201366428285837, Neurons: 64, Grad norm: 1.248e+00\n",
      "Epoch 13572, Loss: 0.0061698006466031075, Neurons: 64, Grad norm: 4.783e-01\n",
      "Epoch 13572, Loss: 0.0061698006466031075, Neurons: 64, Grad norm: 4.783e-01\n",
      "Epoch 13573, Loss: 0.0061456598341465, Neurons: 64, Grad norm: 3.785e-01\n",
      "Epoch 13573, Loss: 0.0061456598341465, Neurons: 64, Grad norm: 3.785e-01\n",
      "Epoch 13574, Loss: 0.006141665857285261, Neurons: 64, Grad norm: 1.014e+00\n",
      "Epoch 13574, Loss: 0.006141665857285261, Neurons: 64, Grad norm: 1.014e+00\n",
      "Epoch 13575, Loss: 0.00615404499694705, Neurons: 64, Grad norm: 1.428e+00\n",
      "Epoch 13575, Loss: 0.00615404499694705, Neurons: 64, Grad norm: 1.428e+00\n",
      "Epoch 13576, Loss: 0.006168626248836517, Neurons: 64, Grad norm: 1.520e+00\n",
      "Epoch 13576, Loss: 0.006168626248836517, Neurons: 64, Grad norm: 1.520e+00\n",
      "Epoch 13577, Loss: 0.0061727468855679035, Neurons: 64, Grad norm: 1.337e+00\n",
      "Epoch 13577, Loss: 0.0061727468855679035, Neurons: 64, Grad norm: 1.337e+00\n",
      "Epoch 13578, Loss: 0.006163305137306452, Neurons: 64, Grad norm: 9.079e-01\n",
      "Epoch 13578, Loss: 0.006163305137306452, Neurons: 64, Grad norm: 9.079e-01\n",
      "Epoch 13579, Loss: 0.006147495470941067, Neurons: 64, Grad norm: 3.723e-01\n",
      "Epoch 13579, Loss: 0.006147495470941067, Neurons: 64, Grad norm: 3.723e-01\n",
      "Epoch 13580, Loss: 0.0061352550983428955, Neurons: 64, Grad norm: 2.169e-01\n",
      "Epoch 13580, Loss: 0.0061352550983428955, Neurons: 64, Grad norm: 2.169e-01\n",
      "Epoch 13581, Loss: 0.006132402457296848, Neurons: 64, Grad norm: 6.722e-01\n",
      "Epoch 13581, Loss: 0.006132402457296848, Neurons: 64, Grad norm: 6.722e-01\n",
      "Epoch 13582, Loss: 0.006137518212199211, Neurons: 64, Grad norm: 9.911e-01\n",
      "Epoch 13582, Loss: 0.006137518212199211, Neurons: 64, Grad norm: 9.911e-01\n",
      "Epoch 13583, Loss: 0.006144286599010229, Neurons: 64, Grad norm: 1.088e+00\n",
      "Epoch 13583, Loss: 0.006144286599010229, Neurons: 64, Grad norm: 1.088e+00\n",
      "Epoch 13584, Loss: 0.006146678701043129, Neurons: 64, Grad norm: 1.006e+00\n",
      "Epoch 13584, Loss: 0.006146678701043129, Neurons: 64, Grad norm: 1.006e+00\n",
      "Epoch 13585, Loss: 0.006142625119537115, Neurons: 64, Grad norm: 7.481e-01\n",
      "Epoch 13585, Loss: 0.006142625119537115, Neurons: 64, Grad norm: 7.481e-01\n",
      "Epoch 13586, Loss: 0.006134812720119953, Neurons: 64, Grad norm: 4.125e-01\n",
      "Epoch 13586, Loss: 0.006134812720119953, Neurons: 64, Grad norm: 4.125e-01\n",
      "Epoch 13587, Loss: 0.0061275833286345005, Neurons: 64, Grad norm: 6.771e-02\n",
      "Epoch 13587, Loss: 0.0061275833286345005, Neurons: 64, Grad norm: 6.771e-02\n",
      "Epoch 13588, Loss: 0.006124230567365885, Neurons: 64, Grad norm: 3.191e-01\n",
      "Epoch 13588, Loss: 0.006124230567365885, Neurons: 64, Grad norm: 3.191e-01\n",
      "Epoch 13589, Loss: 0.006124880164861679, Neurons: 64, Grad norm: 5.748e-01\n",
      "Epoch 13589, Loss: 0.006124880164861679, Neurons: 64, Grad norm: 5.748e-01\n",
      "Epoch 13590, Loss: 0.006127330008894205, Neurons: 64, Grad norm: 6.934e-01\n",
      "Epoch 13590, Loss: 0.006127330008894205, Neurons: 64, Grad norm: 6.934e-01\n",
      "Epoch 13591, Loss: 0.006128763779997826, Neurons: 64, Grad norm: 7.020e-01\n",
      "Epoch 13591, Loss: 0.006128763779997826, Neurons: 64, Grad norm: 7.020e-01\n",
      "Epoch 13592, Loss: 0.006127525586634874, Neurons: 64, Grad norm: 5.804e-01\n",
      "Epoch 13592, Loss: 0.006127525586634874, Neurons: 64, Grad norm: 5.804e-01\n",
      "Epoch 13593, Loss: 0.006124034523963928, Neurons: 64, Grad norm: 3.939e-01\n",
      "Epoch 13593, Loss: 0.006124034523963928, Neurons: 64, Grad norm: 3.939e-01\n",
      "Epoch 13594, Loss: 0.006119824014604092, Neurons: 64, Grad norm: 1.475e-01\n",
      "Epoch 13594, Loss: 0.006119824014604092, Neurons: 64, Grad norm: 1.475e-01\n",
      "Epoch 13595, Loss: 0.006116678472608328, Neurons: 64, Grad norm: 8.328e-02\n",
      "Epoch 13595, Loss: 0.006116678472608328, Neurons: 64, Grad norm: 8.328e-02\n",
      "Epoch 13596, Loss: 0.00611539650708437, Neurons: 64, Grad norm: 2.895e-01\n",
      "Epoch 13596, Loss: 0.00611539650708437, Neurons: 64, Grad norm: 2.895e-01\n",
      "Epoch 13597, Loss: 0.00611557113006711, Neurons: 64, Grad norm: 4.134e-01\n",
      "Epoch 13597, Loss: 0.00611557113006711, Neurons: 64, Grad norm: 4.134e-01\n",
      "Epoch 13598, Loss: 0.006116059608757496, Neurons: 64, Grad norm: 4.768e-01\n",
      "Epoch 13598, Loss: 0.006116059608757496, Neurons: 64, Grad norm: 4.768e-01\n",
      "Epoch 13599, Loss: 0.0061157518066465855, Neurons: 64, Grad norm: 4.431e-01\n",
      "Epoch 13599, Loss: 0.0061157518066465855, Neurons: 64, Grad norm: 4.431e-01\n",
      "Epoch 13599, Test loss: 0.004955470096319914\n",
      "Epoch 13599, Test loss: 0.004955470096319914\n",
      "Epoch 13600, Loss: 0.006114298012107611, Neurons: 64, Grad norm: 3.630e-01\n",
      "Epoch 13600, Loss: 0.006114298012107611, Neurons: 64, Grad norm: 3.630e-01\n",
      "Epoch 13601, Loss: 0.00611204095184803, Neurons: 64, Grad norm: 2.198e-01\n",
      "Epoch 13601, Loss: 0.00611204095184803, Neurons: 64, Grad norm: 2.198e-01\n",
      "Epoch 13602, Loss: 0.006109582260251045, Neurons: 64, Grad norm: 7.439e-02\n",
      "Epoch 13602, Loss: 0.006109582260251045, Neurons: 64, Grad norm: 7.439e-02\n",
      "Epoch 13603, Loss: 0.006107719149440527, Neurons: 64, Grad norm: 8.793e-02\n",
      "Epoch 13603, Loss: 0.006107719149440527, Neurons: 64, Grad norm: 8.793e-02\n",
      "Epoch 13604, Loss: 0.006106603424996138, Neurons: 64, Grad norm: 1.986e-01\n",
      "Epoch 13604, Loss: 0.006106603424996138, Neurons: 64, Grad norm: 1.986e-01\n",
      "Epoch 13605, Loss: 0.006106059066951275, Neurons: 64, Grad norm: 2.915e-01\n",
      "Epoch 13605, Loss: 0.006106059066951275, Neurons: 64, Grad norm: 2.915e-01\n",
      "Epoch 13606, Loss: 0.006105669774115086, Neurons: 64, Grad norm: 3.218e-01\n",
      "Epoch 13606, Loss: 0.006105669774115086, Neurons: 64, Grad norm: 3.218e-01\n",
      "Epoch 13607, Loss: 0.0061049796640872955, Neurons: 64, Grad norm: 3.213e-01\n",
      "Epoch 13607, Loss: 0.0061049796640872955, Neurons: 64, Grad norm: 3.213e-01\n",
      "Epoch 13608, Loss: 0.0061037857085466385, Neurons: 64, Grad norm: 2.594e-01\n",
      "Epoch 13608, Loss: 0.0061037857085466385, Neurons: 64, Grad norm: 2.594e-01\n",
      "Epoch 13609, Loss: 0.006102296058088541, Neurons: 64, Grad norm: 1.874e-01\n",
      "Epoch 13609, Loss: 0.006102296058088541, Neurons: 64, Grad norm: 1.874e-01\n",
      "Epoch 13610, Loss: 0.0061006429605185986, Neurons: 64, Grad norm: 8.679e-02\n",
      "Epoch 13610, Loss: 0.0061006429605185986, Neurons: 64, Grad norm: 8.679e-02\n",
      "Epoch 13611, Loss: 0.006099172402173281, Neurons: 64, Grad norm: 4.664e-02\n",
      "Epoch 13611, Loss: 0.006099172402173281, Neurons: 64, Grad norm: 4.664e-02\n",
      "Epoch 13612, Loss: 0.006097937002778053, Neurons: 64, Grad norm: 1.304e-01\n",
      "Epoch 13612, Loss: 0.006097937002778053, Neurons: 64, Grad norm: 1.304e-01\n",
      "Epoch 13613, Loss: 0.006097018718719482, Neurons: 64, Grad norm: 1.888e-01\n",
      "Epoch 13613, Loss: 0.006097018718719482, Neurons: 64, Grad norm: 1.888e-01\n",
      "Epoch 13614, Loss: 0.006096255499869585, Neurons: 64, Grad norm: 2.446e-01\n",
      "Epoch 13614, Loss: 0.006096255499869585, Neurons: 64, Grad norm: 2.446e-01\n",
      "Epoch 13615, Loss: 0.006095465738326311, Neurons: 64, Grad norm: 2.502e-01\n",
      "Epoch 13615, Loss: 0.006095465738326311, Neurons: 64, Grad norm: 2.502e-01\n",
      "Epoch 13616, Loss: 0.006094517186284065, Neurons: 64, Grad norm: 2.503e-01\n",
      "Epoch 13616, Loss: 0.006094517186284065, Neurons: 64, Grad norm: 2.503e-01\n",
      "Epoch 13617, Loss: 0.006093376316130161, Neurons: 64, Grad norm: 2.082e-01\n",
      "Epoch 13617, Loss: 0.006093376316130161, Neurons: 64, Grad norm: 2.082e-01\n",
      "Epoch 13618, Loss: 0.00609208457171917, Neurons: 64, Grad norm: 1.750e-01\n",
      "Epoch 13618, Loss: 0.00609208457171917, Neurons: 64, Grad norm: 1.750e-01\n",
      "Epoch 13619, Loss: 0.006090804468840361, Neurons: 64, Grad norm: 1.214e-01\n",
      "Epoch 13619, Loss: 0.006090804468840361, Neurons: 64, Grad norm: 1.214e-01\n",
      "Epoch 13620, Loss: 0.006089614704251289, Neurons: 64, Grad norm: 1.040e-01\n",
      "Epoch 13620, Loss: 0.006089614704251289, Neurons: 64, Grad norm: 1.040e-01\n",
      "Epoch 13621, Loss: 0.006088570691645145, Neurons: 64, Grad norm: 1.097e-01\n",
      "Epoch 13621, Loss: 0.006088570691645145, Neurons: 64, Grad norm: 1.097e-01\n",
      "Epoch 13622, Loss: 0.006087713409215212, Neurons: 64, Grad norm: 1.396e-01\n",
      "Epoch 13622, Loss: 0.006087713409215212, Neurons: 64, Grad norm: 1.396e-01\n",
      "Epoch 13623, Loss: 0.006086993031203747, Neurons: 64, Grad norm: 1.672e-01\n",
      "Epoch 13623, Loss: 0.006086993031203747, Neurons: 64, Grad norm: 1.672e-01\n",
      "Epoch 13624, Loss: 0.006086350884288549, Neurons: 64, Grad norm: 1.838e-01\n",
      "Epoch 13624, Loss: 0.006086350884288549, Neurons: 64, Grad norm: 1.838e-01\n",
      "Epoch 13625, Loss: 0.006085623521357775, Neurons: 64, Grad norm: 1.938e-01\n",
      "Epoch 13625, Loss: 0.006085623521357775, Neurons: 64, Grad norm: 1.938e-01\n",
      "Epoch 13626, Loss: 0.006084893364459276, Neurons: 64, Grad norm: 2.002e-01\n",
      "Epoch 13626, Loss: 0.006084893364459276, Neurons: 64, Grad norm: 2.002e-01\n",
      "Epoch 13627, Loss: 0.006084069609642029, Neurons: 64, Grad norm: 2.073e-01\n",
      "Epoch 13627, Loss: 0.006084069609642029, Neurons: 64, Grad norm: 2.073e-01\n",
      "Epoch 13628, Loss: 0.006083357147872448, Neurons: 64, Grad norm: 2.345e-01\n",
      "Epoch 13628, Loss: 0.006083357147872448, Neurons: 64, Grad norm: 2.345e-01\n",
      "Epoch 13629, Loss: 0.0060827285051345825, Neurons: 64, Grad norm: 2.624e-01\n",
      "Epoch 13629, Loss: 0.0060827285051345825, Neurons: 64, Grad norm: 2.624e-01\n",
      "Epoch 13630, Loss: 0.00608226889744401, Neurons: 64, Grad norm: 3.152e-01\n",
      "Epoch 13630, Loss: 0.00608226889744401, Neurons: 64, Grad norm: 3.152e-01\n",
      "Epoch 13631, Loss: 0.0060821170918643475, Neurons: 64, Grad norm: 3.602e-01\n",
      "Epoch 13631, Loss: 0.0060821170918643475, Neurons: 64, Grad norm: 3.602e-01\n",
      "Epoch 13632, Loss: 0.006082231644541025, Neurons: 64, Grad norm: 4.245e-01\n",
      "Epoch 13632, Loss: 0.006082231644541025, Neurons: 64, Grad norm: 4.245e-01\n",
      "Epoch 13633, Loss: 0.00608289148658514, Neurons: 64, Grad norm: 4.754e-01\n",
      "Epoch 13633, Loss: 0.00608289148658514, Neurons: 64, Grad norm: 4.754e-01\n",
      "Epoch 13634, Loss: 0.006084080785512924, Neurons: 64, Grad norm: 5.480e-01\n",
      "Epoch 13634, Loss: 0.006084080785512924, Neurons: 64, Grad norm: 5.480e-01\n",
      "Epoch 13635, Loss: 0.006086241919547319, Neurons: 64, Grad norm: 6.092e-01\n",
      "Epoch 13635, Loss: 0.006086241919547319, Neurons: 64, Grad norm: 6.092e-01\n",
      "Epoch 13636, Loss: 0.00608928594738245, Neurons: 64, Grad norm: 6.980e-01\n",
      "Epoch 13636, Loss: 0.00608928594738245, Neurons: 64, Grad norm: 6.980e-01\n",
      "Epoch 13637, Loss: 0.006094177719205618, Neurons: 64, Grad norm: 7.830e-01\n",
      "Epoch 13637, Loss: 0.006094177719205618, Neurons: 64, Grad norm: 7.830e-01\n",
      "Epoch 13638, Loss: 0.006100825499743223, Neurons: 64, Grad norm: 9.033e-01\n",
      "Epoch 13638, Loss: 0.006100825499743223, Neurons: 64, Grad norm: 9.033e-01\n",
      "Epoch 13639, Loss: 0.006110602989792824, Neurons: 64, Grad norm: 1.027e+00\n",
      "Epoch 13639, Loss: 0.006110602989792824, Neurons: 64, Grad norm: 1.027e+00\n",
      "Epoch 13640, Loss: 0.006123748142272234, Neurons: 64, Grad norm: 1.186e+00\n",
      "Epoch 13640, Loss: 0.006123748142272234, Neurons: 64, Grad norm: 1.186e+00\n",
      "Epoch 13641, Loss: 0.006141167599707842, Neurons: 64, Grad norm: 1.352e+00\n",
      "Epoch 13641, Loss: 0.006141167599707842, Neurons: 64, Grad norm: 1.352e+00\n",
      "Epoch 13642, Loss: 0.006163593381643295, Neurons: 64, Grad norm: 1.556e+00\n",
      "Epoch 13642, Loss: 0.006163593381643295, Neurons: 64, Grad norm: 1.556e+00\n",
      "Epoch 13643, Loss: 0.0061927312053740025, Neurons: 64, Grad norm: 1.759e+00\n",
      "Epoch 13643, Loss: 0.0061927312053740025, Neurons: 64, Grad norm: 1.759e+00\n",
      "Epoch 13644, Loss: 0.0062276339158415794, Neurons: 64, Grad norm: 1.990e+00\n",
      "Epoch 13644, Loss: 0.0062276339158415794, Neurons: 64, Grad norm: 1.990e+00\n",
      "Epoch 13645, Loss: 0.006267970893532038, Neurons: 64, Grad norm: 2.201e+00\n",
      "Epoch 13645, Loss: 0.006267970893532038, Neurons: 64, Grad norm: 2.201e+00\n",
      "Epoch 13646, Loss: 0.0063088443130254745, Neurons: 64, Grad norm: 2.402e+00\n",
      "Epoch 13646, Loss: 0.0063088443130254745, Neurons: 64, Grad norm: 2.402e+00\n",
      "Epoch 13647, Loss: 0.006345221307128668, Neurons: 64, Grad norm: 2.538e+00\n",
      "Epoch 13647, Loss: 0.006345221307128668, Neurons: 64, Grad norm: 2.538e+00\n",
      "Epoch 13648, Loss: 0.006366445682942867, Neurons: 64, Grad norm: 2.618e+00\n",
      "Epoch 13648, Loss: 0.006366445682942867, Neurons: 64, Grad norm: 2.618e+00\n",
      "Epoch 13649, Loss: 0.006363560911267996, Neurons: 64, Grad norm: 2.586e+00\n",
      "Epoch 13649, Loss: 0.006363560911267996, Neurons: 64, Grad norm: 2.586e+00\n",
      "Epoch 13650, Loss: 0.0063316249288618565, Neurons: 64, Grad norm: 2.469e+00\n",
      "Epoch 13650, Loss: 0.0063316249288618565, Neurons: 64, Grad norm: 2.469e+00\n",
      "Epoch 13651, Loss: 0.006274617742747068, Neurons: 64, Grad norm: 2.241e+00\n",
      "Epoch 13651, Loss: 0.006274617742747068, Neurons: 64, Grad norm: 2.241e+00\n",
      "Epoch 13652, Loss: 0.006205935962498188, Neurons: 64, Grad norm: 1.972e+00\n",
      "Epoch 13652, Loss: 0.006205935962498188, Neurons: 64, Grad norm: 1.972e+00\n",
      "Epoch 13653, Loss: 0.006143144331872463, Neurons: 64, Grad norm: 1.659e+00\n",
      "Epoch 13653, Loss: 0.006143144331872463, Neurons: 64, Grad norm: 1.659e+00\n",
      "Epoch 13654, Loss: 0.006099815480411053, Neurons: 64, Grad norm: 1.381e+00\n",
      "Epoch 13654, Loss: 0.006099815480411053, Neurons: 64, Grad norm: 1.381e+00\n",
      "Epoch 13655, Loss: 0.00608065677806735, Neurons: 64, Grad norm: 1.137e+00\n",
      "Epoch 13655, Loss: 0.00608065677806735, Neurons: 64, Grad norm: 1.137e+00\n",
      "Epoch 13656, Loss: 0.00608103908598423, Neurons: 64, Grad norm: 9.864e-01\n",
      "Epoch 13656, Loss: 0.00608103908598423, Neurons: 64, Grad norm: 9.864e-01\n",
      "Epoch 13657, Loss: 0.00609162449836731, Neurons: 64, Grad norm: 9.260e-01\n",
      "Epoch 13657, Loss: 0.00609162449836731, Neurons: 64, Grad norm: 9.260e-01\n",
      "Epoch 13658, Loss: 0.006102739833295345, Neurons: 64, Grad norm: 9.580e-01\n",
      "Epoch 13658, Loss: 0.006102739833295345, Neurons: 64, Grad norm: 9.580e-01\n",
      "Epoch 13659, Loss: 0.006108002737164497, Neurons: 64, Grad norm: 1.071e+00\n",
      "Epoch 13659, Loss: 0.006108002737164497, Neurons: 64, Grad norm: 1.071e+00\n",
      "Epoch 13660, Loss: 0.0061057936400175095, Neurons: 64, Grad norm: 1.208e+00\n",
      "Epoch 13660, Loss: 0.0061057936400175095, Neurons: 64, Grad norm: 1.208e+00\n",
      "Epoch 13661, Loss: 0.00609835097566247, Neurons: 64, Grad norm: 1.374e+00\n",
      "Epoch 13661, Loss: 0.00609835097566247, Neurons: 64, Grad norm: 1.374e+00\n",
      "Epoch 13662, Loss: 0.006090003531426191, Neurons: 64, Grad norm: 1.501e+00\n",
      "Epoch 13662, Loss: 0.006090003531426191, Neurons: 64, Grad norm: 1.501e+00\n",
      "Epoch 13663, Loss: 0.006084025837481022, Neurons: 64, Grad norm: 1.605e+00\n",
      "Epoch 13663, Loss: 0.006084025837481022, Neurons: 64, Grad norm: 1.605e+00\n",
      "Epoch 13664, Loss: 0.006081621162593365, Neurons: 64, Grad norm: 1.625e+00\n",
      "Epoch 13664, Loss: 0.006081621162593365, Neurons: 64, Grad norm: 1.625e+00\n",
      "Epoch 13665, Loss: 0.006081343162804842, Neurons: 64, Grad norm: 1.593e+00\n",
      "Epoch 13665, Loss: 0.006081343162804842, Neurons: 64, Grad norm: 1.593e+00\n",
      "Epoch 13666, Loss: 0.006080783903598785, Neurons: 64, Grad norm: 1.467e+00\n",
      "Epoch 13666, Loss: 0.006080783903598785, Neurons: 64, Grad norm: 1.467e+00\n",
      "Epoch 13667, Loss: 0.006077521480619907, Neurons: 64, Grad norm: 1.283e+00\n",
      "Epoch 13667, Loss: 0.006077521480619907, Neurons: 64, Grad norm: 1.283e+00\n",
      "Epoch 13668, Loss: 0.006070578005164862, Neurons: 64, Grad norm: 1.023e+00\n",
      "Epoch 13668, Loss: 0.006070578005164862, Neurons: 64, Grad norm: 1.023e+00\n",
      "Epoch 13669, Loss: 0.0060606966726481915, Neurons: 64, Grad norm: 7.373e-01\n",
      "Epoch 13669, Loss: 0.0060606966726481915, Neurons: 64, Grad norm: 7.373e-01\n",
      "Epoch 13670, Loss: 0.006049965042620897, Neurons: 64, Grad norm: 4.216e-01\n",
      "Epoch 13670, Loss: 0.006049965042620897, Neurons: 64, Grad norm: 4.216e-01\n",
      "Epoch 13671, Loss: 0.006040864158421755, Neurons: 64, Grad norm: 1.690e-01\n",
      "Epoch 13671, Loss: 0.006040864158421755, Neurons: 64, Grad norm: 1.690e-01\n",
      "Epoch 13672, Loss: 0.00603514676913619, Neurons: 64, Grad norm: 2.854e-01\n",
      "Epoch 13672, Loss: 0.00603514676913619, Neurons: 64, Grad norm: 2.854e-01\n",
      "Epoch 13673, Loss: 0.006033529061824083, Neurons: 64, Grad norm: 5.215e-01\n",
      "Epoch 13673, Loss: 0.006033529061824083, Neurons: 64, Grad norm: 5.215e-01\n",
      "Epoch 13674, Loss: 0.006035360507667065, Neurons: 64, Grad norm: 7.437e-01\n",
      "Epoch 13674, Loss: 0.006035360507667065, Neurons: 64, Grad norm: 7.437e-01\n",
      "Epoch 13675, Loss: 0.00603901594877243, Neurons: 64, Grad norm: 8.930e-01\n",
      "Epoch 13675, Loss: 0.00603901594877243, Neurons: 64, Grad norm: 8.930e-01\n",
      "Epoch 13676, Loss: 0.00604280224069953, Neurons: 64, Grad norm: 9.987e-01\n",
      "Epoch 13676, Loss: 0.00604280224069953, Neurons: 64, Grad norm: 9.987e-01\n",
      "Epoch 13677, Loss: 0.006045134738087654, Neurons: 64, Grad norm: 1.031e+00\n",
      "Epoch 13677, Loss: 0.006045134738087654, Neurons: 64, Grad norm: 1.031e+00\n",
      "Epoch 13678, Loss: 0.006045362912118435, Neurons: 64, Grad norm: 1.033e+00\n",
      "Epoch 13678, Loss: 0.006045362912118435, Neurons: 64, Grad norm: 1.033e+00\n",
      "Epoch 13679, Loss: 0.006043513771146536, Neurons: 64, Grad norm: 9.751e-01\n",
      "Epoch 13679, Loss: 0.006043513771146536, Neurons: 64, Grad norm: 9.751e-01\n",
      "Epoch 13680, Loss: 0.006040218751877546, Neurons: 64, Grad norm: 9.047e-01\n",
      "Epoch 13680, Loss: 0.006040218751877546, Neurons: 64, Grad norm: 9.047e-01\n",
      "Epoch 13681, Loss: 0.0060362196527421474, Neurons: 64, Grad norm: 7.969e-01\n",
      "Epoch 13681, Loss: 0.0060362196527421474, Neurons: 64, Grad norm: 7.969e-01\n",
      "Epoch 13682, Loss: 0.006032376084476709, Neurons: 64, Grad norm: 7.019e-01\n",
      "Epoch 13682, Loss: 0.006032376084476709, Neurons: 64, Grad norm: 7.019e-01\n",
      "Epoch 13683, Loss: 0.006029151380062103, Neurons: 64, Grad norm: 5.932e-01\n",
      "Epoch 13683, Loss: 0.006029151380062103, Neurons: 64, Grad norm: 5.932e-01\n",
      "Epoch 13684, Loss: 0.0060267881490290165, Neurons: 64, Grad norm: 5.173e-01\n",
      "Epoch 13684, Loss: 0.0060267881490290165, Neurons: 64, Grad norm: 5.173e-01\n",
      "Epoch 13685, Loss: 0.006025068461894989, Neurons: 64, Grad norm: 4.337e-01\n",
      "Epoch 13685, Loss: 0.006025068461894989, Neurons: 64, Grad norm: 4.337e-01\n",
      "Epoch 13686, Loss: 0.006023773457854986, Neurons: 64, Grad norm: 3.825e-01\n",
      "Epoch 13686, Loss: 0.006023773457854986, Neurons: 64, Grad norm: 3.825e-01\n",
      "Epoch 13687, Loss: 0.006022525019943714, Neurons: 64, Grad norm: 3.246e-01\n",
      "Epoch 13687, Loss: 0.006022525019943714, Neurons: 64, Grad norm: 3.246e-01\n",
      "Epoch 13688, Loss: 0.006021140608936548, Neurons: 64, Grad norm: 2.908e-01\n",
      "Epoch 13688, Loss: 0.006021140608936548, Neurons: 64, Grad norm: 2.908e-01\n",
      "Epoch 13689, Loss: 0.006019501015543938, Neurons: 64, Grad norm: 2.427e-01\n",
      "Epoch 13689, Loss: 0.006019501015543938, Neurons: 64, Grad norm: 2.427e-01\n",
      "Epoch 13690, Loss: 0.0060175745747983456, Neurons: 64, Grad norm: 2.088e-01\n",
      "Epoch 13690, Loss: 0.0060175745747983456, Neurons: 64, Grad norm: 2.088e-01\n",
      "Epoch 13691, Loss: 0.006015692837536335, Neurons: 64, Grad norm: 1.634e-01\n",
      "Epoch 13691, Loss: 0.006015692837536335, Neurons: 64, Grad norm: 1.634e-01\n",
      "Epoch 13692, Loss: 0.006013754289597273, Neurons: 64, Grad norm: 1.301e-01\n",
      "Epoch 13692, Loss: 0.006013754289597273, Neurons: 64, Grad norm: 1.301e-01\n",
      "Epoch 13693, Loss: 0.006012008525431156, Neurons: 64, Grad norm: 8.759e-02\n",
      "Epoch 13693, Loss: 0.006012008525431156, Neurons: 64, Grad norm: 8.759e-02\n",
      "Epoch 13694, Loss: 0.006010395474731922, Neurons: 64, Grad norm: 5.299e-02\n",
      "Epoch 13694, Loss: 0.006010395474731922, Neurons: 64, Grad norm: 5.299e-02\n",
      "Epoch 13695, Loss: 0.006009014789015055, Neurons: 64, Grad norm: 1.583e-02\n",
      "Epoch 13695, Loss: 0.006009014789015055, Neurons: 64, Grad norm: 1.583e-02\n",
      "Epoch 13696, Loss: 0.00600776169449091, Neurons: 64, Grad norm: 2.051e-02\n",
      "Epoch 13696, Loss: 0.00600776169449091, Neurons: 64, Grad norm: 2.051e-02\n",
      "Epoch 13697, Loss: 0.006006712093949318, Neurons: 64, Grad norm: 5.453e-02\n",
      "Epoch 13697, Loss: 0.006006712093949318, Neurons: 64, Grad norm: 5.453e-02\n",
      "Epoch 13698, Loss: 0.006005801260471344, Neurons: 64, Grad norm: 7.455e-02\n",
      "Epoch 13698, Loss: 0.006005801260471344, Neurons: 64, Grad norm: 7.455e-02\n",
      "Epoch 13699, Loss: 0.006004959344863892, Neurons: 64, Grad norm: 9.908e-02\n",
      "Epoch 13699, Loss: 0.006004959344863892, Neurons: 64, Grad norm: 9.908e-02\n",
      "Epoch 13699, Test loss: 0.004896063823252916\n",
      "Epoch 13699, Test loss: 0.004896063823252916\n",
      "Epoch 13700, Loss: 0.006004126276820898, Neurons: 64, Grad norm: 1.106e-01\n",
      "Epoch 13700, Loss: 0.006004126276820898, Neurons: 64, Grad norm: 1.106e-01\n",
      "Epoch 13701, Loss: 0.006003282032907009, Neurons: 64, Grad norm: 1.305e-01\n",
      "Epoch 13701, Loss: 0.006003282032907009, Neurons: 64, Grad norm: 1.305e-01\n",
      "Epoch 13702, Loss: 0.006002465728670359, Neurons: 64, Grad norm: 1.356e-01\n",
      "Epoch 13702, Loss: 0.006002465728670359, Neurons: 64, Grad norm: 1.356e-01\n",
      "Epoch 13703, Loss: 0.006001533940434456, Neurons: 64, Grad norm: 1.505e-01\n",
      "Epoch 13703, Loss: 0.006001533940434456, Neurons: 64, Grad norm: 1.505e-01\n",
      "Epoch 13704, Loss: 0.006000541150569916, Neurons: 64, Grad norm: 1.523e-01\n",
      "Epoch 13704, Loss: 0.006000541150569916, Neurons: 64, Grad norm: 1.523e-01\n",
      "Epoch 13705, Loss: 0.005999492481350899, Neurons: 64, Grad norm: 1.725e-01\n",
      "Epoch 13705, Loss: 0.005999492481350899, Neurons: 64, Grad norm: 1.725e-01\n",
      "Epoch 13706, Loss: 0.005998377222567797, Neurons: 64, Grad norm: 1.775e-01\n",
      "Epoch 13706, Loss: 0.005998377222567797, Neurons: 64, Grad norm: 1.775e-01\n",
      "Epoch 13707, Loss: 0.00599728524684906, Neurons: 64, Grad norm: 2.076e-01\n",
      "Epoch 13707, Loss: 0.00599728524684906, Neurons: 64, Grad norm: 2.076e-01\n",
      "Epoch 13708, Loss: 0.005996247753500938, Neurons: 64, Grad norm: 2.276e-01\n",
      "Epoch 13708, Loss: 0.005996247753500938, Neurons: 64, Grad norm: 2.276e-01\n",
      "Epoch 13709, Loss: 0.005995301064103842, Neurons: 64, Grad norm: 2.784e-01\n",
      "Epoch 13709, Loss: 0.005995301064103842, Neurons: 64, Grad norm: 2.784e-01\n",
      "Epoch 13710, Loss: 0.005994487088173628, Neurons: 64, Grad norm: 3.112e-01\n",
      "Epoch 13710, Loss: 0.005994487088173628, Neurons: 64, Grad norm: 3.112e-01\n",
      "Epoch 13711, Loss: 0.005993799772113562, Neurons: 64, Grad norm: 3.732e-01\n",
      "Epoch 13711, Loss: 0.005993799772113562, Neurons: 64, Grad norm: 3.732e-01\n",
      "Epoch 13712, Loss: 0.005993280094116926, Neurons: 64, Grad norm: 4.288e-01\n",
      "Epoch 13712, Loss: 0.005993280094116926, Neurons: 64, Grad norm: 4.288e-01\n",
      "Epoch 13713, Loss: 0.005993015598505735, Neurons: 64, Grad norm: 5.109e-01\n",
      "Epoch 13713, Loss: 0.005993015598505735, Neurons: 64, Grad norm: 5.109e-01\n",
      "Epoch 13714, Loss: 0.005993025843054056, Neurons: 64, Grad norm: 5.876e-01\n",
      "Epoch 13714, Loss: 0.005993025843054056, Neurons: 64, Grad norm: 5.876e-01\n",
      "Epoch 13715, Loss: 0.005993525963276625, Neurons: 64, Grad norm: 7.034e-01\n",
      "Epoch 13715, Loss: 0.005993525963276625, Neurons: 64, Grad norm: 7.034e-01\n",
      "Epoch 13716, Loss: 0.005994605366140604, Neurons: 64, Grad norm: 8.172e-01\n",
      "Epoch 13716, Loss: 0.005994605366140604, Neurons: 64, Grad norm: 8.172e-01\n",
      "Epoch 13717, Loss: 0.005996577441692352, Neurons: 64, Grad norm: 9.751e-01\n",
      "Epoch 13717, Loss: 0.005996577441692352, Neurons: 64, Grad norm: 9.751e-01\n",
      "Epoch 13718, Loss: 0.005999925080686808, Neurons: 64, Grad norm: 1.143e+00\n",
      "Epoch 13718, Loss: 0.005999925080686808, Neurons: 64, Grad norm: 1.143e+00\n",
      "Epoch 13719, Loss: 0.0060050697065889835, Neurons: 64, Grad norm: 1.368e+00\n",
      "Epoch 13719, Loss: 0.0060050697065889835, Neurons: 64, Grad norm: 1.368e+00\n",
      "Epoch 13720, Loss: 0.006013008300215006, Neurons: 64, Grad norm: 1.623e+00\n",
      "Epoch 13720, Loss: 0.006013008300215006, Neurons: 64, Grad norm: 1.623e+00\n",
      "Epoch 13721, Loss: 0.006024899892508984, Neurons: 64, Grad norm: 1.953e+00\n",
      "Epoch 13721, Loss: 0.006024899892508984, Neurons: 64, Grad norm: 1.953e+00\n",
      "Epoch 13722, Loss: 0.0060428353026509285, Neurons: 64, Grad norm: 2.330e+00\n",
      "Epoch 13722, Loss: 0.0060428353026509285, Neurons: 64, Grad norm: 2.330e+00\n",
      "Epoch 13723, Loss: 0.006069537252187729, Neurons: 64, Grad norm: 2.813e+00\n",
      "Epoch 13723, Loss: 0.006069537252187729, Neurons: 64, Grad norm: 2.813e+00\n",
      "Epoch 13724, Loss: 0.00610897084698081, Neurons: 64, Grad norm: 3.376e+00\n",
      "Epoch 13724, Loss: 0.00610897084698081, Neurons: 64, Grad norm: 3.376e+00\n",
      "Epoch 13725, Loss: 0.006166498642414808, Neurons: 64, Grad norm: 4.066e+00\n",
      "Epoch 13725, Loss: 0.006166498642414808, Neurons: 64, Grad norm: 4.066e+00\n",
      "Epoch 13726, Loss: 0.006249662023037672, Neurons: 64, Grad norm: 4.854e+00\n",
      "Epoch 13726, Loss: 0.006249662023037672, Neurons: 64, Grad norm: 4.854e+00\n",
      "Epoch 13727, Loss: 0.006367036607116461, Neurons: 64, Grad norm: 5.779e+00\n",
      "Epoch 13727, Loss: 0.006367036607116461, Neurons: 64, Grad norm: 5.779e+00\n",
      "Epoch 13728, Loss: 0.006527489051222801, Neurons: 64, Grad norm: 6.774e+00\n",
      "Epoch 13728, Loss: 0.006527489051222801, Neurons: 64, Grad norm: 6.774e+00\n",
      "Epoch 13729, Loss: 0.006734172347933054, Neurons: 64, Grad norm: 7.801e+00\n",
      "Epoch 13729, Loss: 0.006734172347933054, Neurons: 64, Grad norm: 7.801e+00\n",
      "Epoch 13730, Loss: 0.006976485718041658, Neurons: 64, Grad norm: 8.698e+00\n",
      "Epoch 13730, Loss: 0.006976485718041658, Neurons: 64, Grad norm: 8.698e+00\n",
      "Epoch 13731, Loss: 0.007218656130135059, Neurons: 64, Grad norm: 9.314e+00\n",
      "Epoch 13731, Loss: 0.007218656130135059, Neurons: 64, Grad norm: 9.314e+00\n",
      "Epoch 13732, Loss: 0.007388859987258911, Neurons: 64, Grad norm: 9.377e+00\n",
      "Epoch 13732, Loss: 0.007388859987258911, Neurons: 64, Grad norm: 9.377e+00\n",
      "Epoch 13733, Loss: 0.007396970875561237, Neurons: 64, Grad norm: 8.697e+00\n",
      "Epoch 13733, Loss: 0.007396970875561237, Neurons: 64, Grad norm: 8.697e+00\n",
      "Epoch 13734, Loss: 0.007180155720561743, Neurons: 64, Grad norm: 7.159e+00\n",
      "Epoch 13734, Loss: 0.007180155720561743, Neurons: 64, Grad norm: 7.159e+00\n",
      "Epoch 13735, Loss: 0.0067777023650705814, Neurons: 64, Grad norm: 4.918e+00\n",
      "Epoch 13735, Loss: 0.0067777023650705814, Neurons: 64, Grad norm: 4.918e+00\n",
      "Epoch 13736, Loss: 0.006338123697787523, Neurons: 64, Grad norm: 2.258e+00\n",
      "Epoch 13736, Loss: 0.006338123697787523, Neurons: 64, Grad norm: 2.258e+00\n",
      "Epoch 13737, Loss: 0.006043771281838417, Neurons: 64, Grad norm: 7.069e-01\n",
      "Epoch 13737, Loss: 0.006043771281838417, Neurons: 64, Grad norm: 7.069e-01\n",
      "Epoch 13738, Loss: 0.0059887426905334, Neurons: 64, Grad norm: 2.893e+00\n",
      "Epoch 13738, Loss: 0.0059887426905334, Neurons: 64, Grad norm: 2.893e+00\n",
      "Epoch 13739, Loss: 0.006131339352577925, Neurons: 64, Grad norm: 4.564e+00\n",
      "Epoch 13739, Loss: 0.006131339352577925, Neurons: 64, Grad norm: 4.564e+00\n",
      "Epoch 13740, Loss: 0.006338541395962238, Neurons: 64, Grad norm: 5.444e+00\n",
      "Epoch 13740, Loss: 0.006338541395962238, Neurons: 64, Grad norm: 5.444e+00\n",
      "Epoch 13741, Loss: 0.006468826439231634, Neurons: 64, Grad norm: 5.412e+00\n",
      "Epoch 13741, Loss: 0.006468826439231634, Neurons: 64, Grad norm: 5.412e+00\n",
      "Epoch 13742, Loss: 0.006445104721933603, Neurons: 64, Grad norm: 4.558e+00\n",
      "Epoch 13742, Loss: 0.006445104721933603, Neurons: 64, Grad norm: 4.558e+00\n",
      "Epoch 13743, Loss: 0.006289120763540268, Neurons: 64, Grad norm: 3.056e+00\n",
      "Epoch 13743, Loss: 0.006289120763540268, Neurons: 64, Grad norm: 3.056e+00\n",
      "Epoch 13744, Loss: 0.00610103365033865, Neurons: 64, Grad norm: 1.301e+00\n",
      "Epoch 13744, Loss: 0.00610103365033865, Neurons: 64, Grad norm: 1.301e+00\n",
      "Epoch 13745, Loss: 0.005986812990158796, Neurons: 64, Grad norm: 8.573e-01\n",
      "Epoch 13745, Loss: 0.005986812990158796, Neurons: 64, Grad norm: 8.573e-01\n",
      "Epoch 13746, Loss: 0.005989431403577328, Neurons: 64, Grad norm: 2.226e+00\n",
      "Epoch 13746, Loss: 0.005989431403577328, Neurons: 64, Grad norm: 2.226e+00\n",
      "Epoch 13747, Loss: 0.006072575226426125, Neurons: 64, Grad norm: 3.194e+00\n",
      "Epoch 13747, Loss: 0.006072575226426125, Neurons: 64, Grad norm: 3.194e+00\n",
      "Epoch 13748, Loss: 0.0061582112684845924, Neurons: 64, Grad norm: 3.519e+00\n",
      "Epoch 13748, Loss: 0.0061582112684845924, Neurons: 64, Grad norm: 3.519e+00\n",
      "Epoch 13749, Loss: 0.006182324606925249, Neurons: 64, Grad norm: 3.234e+00\n",
      "Epoch 13749, Loss: 0.006182324606925249, Neurons: 64, Grad norm: 3.234e+00\n",
      "Epoch 13750, Loss: 0.006131760776042938, Neurons: 64, Grad norm: 2.418e+00\n",
      "Epoch 13750, Loss: 0.006131760776042938, Neurons: 64, Grad norm: 2.418e+00\n",
      "Epoch 13751, Loss: 0.006044473964720964, Neurons: 64, Grad norm: 1.328e+00\n",
      "Epoch 13751, Loss: 0.006044473964720964, Neurons: 64, Grad norm: 1.328e+00\n",
      "Epoch 13752, Loss: 0.0059763710014522076, Neurons: 64, Grad norm: 4.540e-01\n",
      "Epoch 13752, Loss: 0.0059763710014522076, Neurons: 64, Grad norm: 4.540e-01\n",
      "Epoch 13753, Loss: 0.005961271934211254, Neurons: 64, Grad norm: 1.142e+00\n",
      "Epoch 13753, Loss: 0.005961271934211254, Neurons: 64, Grad norm: 1.142e+00\n",
      "Epoch 13754, Loss: 0.005992635618895292, Neurons: 64, Grad norm: 1.877e+00\n",
      "Epoch 13754, Loss: 0.005992635618895292, Neurons: 64, Grad norm: 1.877e+00\n",
      "Epoch 13755, Loss: 0.0060358052141964436, Neurons: 64, Grad norm: 2.212e+00\n",
      "Epoch 13755, Loss: 0.0060358052141964436, Neurons: 64, Grad norm: 2.212e+00\n",
      "Epoch 13756, Loss: 0.006055542267858982, Neurons: 64, Grad norm: 2.152e+00\n",
      "Epoch 13756, Loss: 0.006055542267858982, Neurons: 64, Grad norm: 2.152e+00\n",
      "Epoch 13757, Loss: 0.006038902793079615, Neurons: 64, Grad norm: 1.711e+00\n",
      "Epoch 13757, Loss: 0.006038902793079615, Neurons: 64, Grad norm: 1.711e+00\n",
      "Epoch 13758, Loss: 0.0059982710517942905, Neurons: 64, Grad norm: 1.051e+00\n",
      "Epoch 13758, Loss: 0.0059982710517942905, Neurons: 64, Grad norm: 1.051e+00\n",
      "Epoch 13759, Loss: 0.00596002908423543, Neurons: 64, Grad norm: 3.485e-01\n",
      "Epoch 13759, Loss: 0.00596002908423543, Neurons: 64, Grad norm: 3.485e-01\n",
      "Epoch 13760, Loss: 0.0059445686638355255, Neurons: 64, Grad norm: 5.582e-01\n",
      "Epoch 13760, Loss: 0.0059445686638355255, Neurons: 64, Grad norm: 5.582e-01\n",
      "Epoch 13761, Loss: 0.005954365245997906, Neurons: 64, Grad norm: 1.091e+00\n",
      "Epoch 13761, Loss: 0.005954365245997906, Neurons: 64, Grad norm: 1.091e+00\n",
      "Epoch 13762, Loss: 0.005975724663585424, Neurons: 64, Grad norm: 1.385e+00\n",
      "Epoch 13762, Loss: 0.005975724663585424, Neurons: 64, Grad norm: 1.385e+00\n",
      "Epoch 13763, Loss: 0.005990557372570038, Neurons: 64, Grad norm: 1.428e+00\n",
      "Epoch 13763, Loss: 0.005990557372570038, Neurons: 64, Grad norm: 1.428e+00\n",
      "Epoch 13764, Loss: 0.005988612771034241, Neurons: 64, Grad norm: 1.204e+00\n",
      "Epoch 13764, Loss: 0.005988612771034241, Neurons: 64, Grad norm: 1.204e+00\n",
      "Epoch 13765, Loss: 0.0059714228846132755, Neurons: 64, Grad norm: 8.185e-01\n",
      "Epoch 13765, Loss: 0.0059714228846132755, Neurons: 64, Grad norm: 8.185e-01\n",
      "Epoch 13766, Loss: 0.005950048565864563, Neurons: 64, Grad norm: 3.199e-01\n",
      "Epoch 13766, Loss: 0.005950048565864563, Neurons: 64, Grad norm: 3.199e-01\n",
      "Epoch 13767, Loss: 0.00593616021797061, Neurons: 64, Grad norm: 1.879e-01\n",
      "Epoch 13767, Loss: 0.00593616021797061, Neurons: 64, Grad norm: 1.879e-01\n",
      "Epoch 13768, Loss: 0.00593487499281764, Neurons: 64, Grad norm: 5.991e-01\n",
      "Epoch 13768, Loss: 0.00593487499281764, Neurons: 64, Grad norm: 5.991e-01\n",
      "Epoch 13769, Loss: 0.00594288669526577, Neurons: 64, Grad norm: 8.579e-01\n",
      "Epoch 13769, Loss: 0.00594288669526577, Neurons: 64, Grad norm: 8.579e-01\n",
      "Epoch 13770, Loss: 0.005952275358140469, Neurons: 64, Grad norm: 9.683e-01\n",
      "Epoch 13770, Loss: 0.005952275358140469, Neurons: 64, Grad norm: 9.683e-01\n",
      "Epoch 13771, Loss: 0.005955889355391264, Neurons: 64, Grad norm: 8.912e-01\n",
      "Epoch 13771, Loss: 0.005955889355391264, Neurons: 64, Grad norm: 8.912e-01\n",
      "Epoch 13772, Loss: 0.005951356142759323, Neurons: 64, Grad norm: 6.974e-01\n",
      "Epoch 13772, Loss: 0.005951356142759323, Neurons: 64, Grad norm: 6.974e-01\n",
      "Epoch 13773, Loss: 0.005941851530224085, Neurons: 64, Grad norm: 3.928e-01\n",
      "Epoch 13773, Loss: 0.005941851530224085, Neurons: 64, Grad norm: 3.928e-01\n",
      "Epoch 13774, Loss: 0.005932158790528774, Neurons: 64, Grad norm: 8.674e-02\n",
      "Epoch 13774, Loss: 0.005932158790528774, Neurons: 64, Grad norm: 8.674e-02\n",
      "Epoch 13775, Loss: 0.0059265554882586, Neurons: 64, Grad norm: 2.558e-01\n",
      "Epoch 13775, Loss: 0.0059265554882586, Neurons: 64, Grad norm: 2.558e-01\n",
      "Epoch 13776, Loss: 0.0059262970462441444, Neurons: 64, Grad norm: 4.872e-01\n",
      "Epoch 13776, Loss: 0.0059262970462441444, Neurons: 64, Grad norm: 4.872e-01\n",
      "Epoch 13777, Loss: 0.0059294807724654675, Neurons: 64, Grad norm: 6.460e-01\n",
      "Epoch 13777, Loss: 0.0059294807724654675, Neurons: 64, Grad norm: 6.460e-01\n",
      "Epoch 13778, Loss: 0.005932801403105259, Neurons: 64, Grad norm: 6.748e-01\n",
      "Epoch 13778, Loss: 0.005932801403105259, Neurons: 64, Grad norm: 6.748e-01\n",
      "Epoch 13779, Loss: 0.005933517124503851, Neurons: 64, Grad norm: 6.186e-01\n",
      "Epoch 13779, Loss: 0.005933517124503851, Neurons: 64, Grad norm: 6.186e-01\n",
      "Epoch 13780, Loss: 0.00593096436932683, Neurons: 64, Grad norm: 4.569e-01\n",
      "Epoch 13780, Loss: 0.00593096436932683, Neurons: 64, Grad norm: 4.569e-01\n",
      "Epoch 13781, Loss: 0.005926230922341347, Neurons: 64, Grad norm: 2.704e-01\n",
      "Epoch 13781, Loss: 0.005926230922341347, Neurons: 64, Grad norm: 2.704e-01\n",
      "Epoch 13782, Loss: 0.005921564530581236, Neurons: 64, Grad norm: 8.093e-02\n",
      "Epoch 13782, Loss: 0.005921564530581236, Neurons: 64, Grad norm: 8.093e-02\n",
      "Epoch 13783, Loss: 0.005918512586504221, Neurons: 64, Grad norm: 1.914e-01\n",
      "Epoch 13783, Loss: 0.005918512586504221, Neurons: 64, Grad norm: 1.914e-01\n",
      "Epoch 13784, Loss: 0.005917627830058336, Neurons: 64, Grad norm: 3.614e-01\n",
      "Epoch 13784, Loss: 0.005917627830058336, Neurons: 64, Grad norm: 3.614e-01\n",
      "Epoch 13785, Loss: 0.005918211303651333, Neurons: 64, Grad norm: 4.610e-01\n",
      "Epoch 13785, Loss: 0.005918211303651333, Neurons: 64, Grad norm: 4.610e-01\n",
      "Epoch 13786, Loss: 0.0059191398322582245, Neurons: 64, Grad norm: 5.136e-01\n",
      "Epoch 13786, Loss: 0.0059191398322582245, Neurons: 64, Grad norm: 5.136e-01\n",
      "Epoch 13787, Loss: 0.005919206887483597, Neurons: 64, Grad norm: 4.749e-01\n",
      "Epoch 13787, Loss: 0.005919206887483597, Neurons: 64, Grad norm: 4.749e-01\n",
      "Epoch 13788, Loss: 0.005917953327298164, Neurons: 64, Grad norm: 4.014e-01\n",
      "Epoch 13788, Loss: 0.005917953327298164, Neurons: 64, Grad norm: 4.014e-01\n",
      "Epoch 13789, Loss: 0.005915615241974592, Neurons: 64, Grad norm: 2.672e-01\n",
      "Epoch 13789, Loss: 0.005915615241974592, Neurons: 64, Grad norm: 2.672e-01\n",
      "Epoch 13790, Loss: 0.005912933498620987, Neurons: 64, Grad norm: 1.351e-01\n",
      "Epoch 13790, Loss: 0.005912933498620987, Neurons: 64, Grad norm: 1.351e-01\n",
      "Epoch 13791, Loss: 0.005910646170377731, Neurons: 64, Grad norm: 6.815e-02\n",
      "Epoch 13791, Loss: 0.005910646170377731, Neurons: 64, Grad norm: 6.815e-02\n",
      "Epoch 13792, Loss: 0.005909128114581108, Neurons: 64, Grad norm: 1.712e-01\n",
      "Epoch 13792, Loss: 0.005909128114581108, Neurons: 64, Grad norm: 1.712e-01\n",
      "Epoch 13793, Loss: 0.005908410530537367, Neurons: 64, Grad norm: 2.812e-01\n",
      "Epoch 13793, Loss: 0.005908410530537367, Neurons: 64, Grad norm: 2.812e-01\n",
      "Epoch 13794, Loss: 0.005908140446990728, Neurons: 64, Grad norm: 3.321e-01\n",
      "Epoch 13794, Loss: 0.005908140446990728, Neurons: 64, Grad norm: 3.321e-01\n",
      "Epoch 13795, Loss: 0.005907836835831404, Neurons: 64, Grad norm: 3.657e-01\n",
      "Epoch 13795, Loss: 0.005907836835831404, Neurons: 64, Grad norm: 3.657e-01\n",
      "Epoch 13796, Loss: 0.005907140672206879, Neurons: 64, Grad norm: 3.414e-01\n",
      "Epoch 13796, Loss: 0.005907140672206879, Neurons: 64, Grad norm: 3.414e-01\n",
      "Epoch 13797, Loss: 0.005906003061681986, Neurons: 64, Grad norm: 3.035e-01\n",
      "Epoch 13797, Loss: 0.005906003061681986, Neurons: 64, Grad norm: 3.035e-01\n",
      "Epoch 13798, Loss: 0.005904491059482098, Neurons: 64, Grad norm: 2.203e-01\n",
      "Epoch 13798, Loss: 0.005904491059482098, Neurons: 64, Grad norm: 2.203e-01\n",
      "Epoch 13799, Loss: 0.005902760662138462, Neurons: 64, Grad norm: 1.398e-01\n",
      "Epoch 13799, Loss: 0.005902760662138462, Neurons: 64, Grad norm: 1.398e-01\n",
      "Epoch 13799, Test loss: 0.004831166006624699\n",
      "Epoch 13799, Test loss: 0.004831166006624699\n",
      "Epoch 13800, Loss: 0.005901169963181019, Neurons: 64, Grad norm: 3.711e-02\n",
      "Epoch 13800, Loss: 0.005901169963181019, Neurons: 64, Grad norm: 3.711e-02\n",
      "Epoch 13801, Loss: 0.005899855867028236, Neurons: 64, Grad norm: 4.468e-02\n",
      "Epoch 13801, Loss: 0.005899855867028236, Neurons: 64, Grad norm: 4.468e-02\n",
      "Epoch 13802, Loss: 0.0058988602831959724, Neurons: 64, Grad norm: 1.269e-01\n",
      "Epoch 13802, Loss: 0.0058988602831959724, Neurons: 64, Grad norm: 1.269e-01\n",
      "Epoch 13803, Loss: 0.00589811522513628, Neurons: 64, Grad norm: 1.693e-01\n",
      "Epoch 13803, Loss: 0.00589811522513628, Neurons: 64, Grad norm: 1.693e-01\n",
      "Epoch 13804, Loss: 0.005897463299334049, Neurons: 64, Grad norm: 2.110e-01\n",
      "Epoch 13804, Loss: 0.005897463299334049, Neurons: 64, Grad norm: 2.110e-01\n",
      "Epoch 13805, Loss: 0.005896752700209618, Neurons: 64, Grad norm: 2.112e-01\n",
      "Epoch 13805, Loss: 0.005896752700209618, Neurons: 64, Grad norm: 2.112e-01\n",
      "Epoch 13806, Loss: 0.005895824637264013, Neurons: 64, Grad norm: 2.067e-01\n",
      "Epoch 13806, Loss: 0.005895824637264013, Neurons: 64, Grad norm: 2.067e-01\n",
      "Epoch 13807, Loss: 0.005894721485674381, Neurons: 64, Grad norm: 1.619e-01\n",
      "Epoch 13807, Loss: 0.005894721485674381, Neurons: 64, Grad norm: 1.619e-01\n",
      "Epoch 13808, Loss: 0.005893498659133911, Neurons: 64, Grad norm: 1.271e-01\n",
      "Epoch 13808, Loss: 0.005893498659133911, Neurons: 64, Grad norm: 1.271e-01\n",
      "Epoch 13809, Loss: 0.005892208311706781, Neurons: 64, Grad norm: 6.885e-02\n",
      "Epoch 13809, Loss: 0.005892208311706781, Neurons: 64, Grad norm: 6.885e-02\n",
      "Epoch 13810, Loss: 0.005890904925763607, Neurons: 64, Grad norm: 3.134e-02\n",
      "Epoch 13810, Loss: 0.005890904925763607, Neurons: 64, Grad norm: 3.134e-02\n",
      "Epoch 13811, Loss: 0.00588974030688405, Neurons: 64, Grad norm: 4.431e-02\n",
      "Epoch 13811, Loss: 0.00588974030688405, Neurons: 64, Grad norm: 4.431e-02\n",
      "Epoch 13812, Loss: 0.00588870607316494, Neurons: 64, Grad norm: 7.782e-02\n",
      "Epoch 13812, Loss: 0.00588870607316494, Neurons: 64, Grad norm: 7.782e-02\n",
      "Epoch 13813, Loss: 0.0058877719566226006, Neurons: 64, Grad norm: 1.235e-01\n",
      "Epoch 13813, Loss: 0.0058877719566226006, Neurons: 64, Grad norm: 1.235e-01\n",
      "Epoch 13814, Loss: 0.0058870259672403336, Neurons: 64, Grad norm: 1.377e-01\n",
      "Epoch 13814, Loss: 0.0058870259672403336, Neurons: 64, Grad norm: 1.377e-01\n",
      "Epoch 13815, Loss: 0.005885979160666466, Neurons: 64, Grad norm: 1.603e-01\n",
      "Epoch 13815, Loss: 0.005885979160666466, Neurons: 64, Grad norm: 1.603e-01\n",
      "Epoch 13816, Loss: 0.005885045509785414, Neurons: 64, Grad norm: 1.531e-01\n",
      "Epoch 13816, Loss: 0.005885045509785414, Neurons: 64, Grad norm: 1.531e-01\n",
      "Epoch 13817, Loss: 0.005884118378162384, Neurons: 64, Grad norm: 1.565e-01\n",
      "Epoch 13817, Loss: 0.005884118378162384, Neurons: 64, Grad norm: 1.565e-01\n",
      "Epoch 13818, Loss: 0.005883035250008106, Neurons: 64, Grad norm: 1.289e-01\n",
      "Epoch 13818, Loss: 0.005883035250008106, Neurons: 64, Grad norm: 1.289e-01\n",
      "Epoch 13819, Loss: 0.005881937686353922, Neurons: 64, Grad norm: 1.143e-01\n",
      "Epoch 13819, Loss: 0.005881937686353922, Neurons: 64, Grad norm: 1.143e-01\n",
      "Epoch 13820, Loss: 0.0058808051981031895, Neurons: 64, Grad norm: 7.918e-02\n",
      "Epoch 13820, Loss: 0.0058808051981031895, Neurons: 64, Grad norm: 7.918e-02\n",
      "Epoch 13821, Loss: 0.005879671312868595, Neurons: 64, Grad norm: 6.529e-02\n",
      "Epoch 13821, Loss: 0.005879671312868595, Neurons: 64, Grad norm: 6.529e-02\n",
      "Epoch 13822, Loss: 0.005878765601664782, Neurons: 64, Grad norm: 3.159e-02\n",
      "Epoch 13822, Loss: 0.005878765601664782, Neurons: 64, Grad norm: 3.159e-02\n",
      "Epoch 13823, Loss: 0.005877638701349497, Neurons: 64, Grad norm: 2.406e-02\n",
      "Epoch 13823, Loss: 0.005877638701349497, Neurons: 64, Grad norm: 2.406e-02\n",
      "Epoch 13824, Loss: 0.005876568146049976, Neurons: 64, Grad norm: 4.139e-02\n",
      "Epoch 13824, Loss: 0.005876568146049976, Neurons: 64, Grad norm: 4.139e-02\n",
      "Epoch 13825, Loss: 0.005875583738088608, Neurons: 64, Grad norm: 5.612e-02\n",
      "Epoch 13825, Loss: 0.005875583738088608, Neurons: 64, Grad norm: 5.612e-02\n",
      "Epoch 13826, Loss: 0.005874596536159515, Neurons: 64, Grad norm: 8.320e-02\n",
      "Epoch 13826, Loss: 0.005874596536159515, Neurons: 64, Grad norm: 8.320e-02\n",
      "Epoch 13827, Loss: 0.005873683374375105, Neurons: 64, Grad norm: 9.185e-02\n",
      "Epoch 13827, Loss: 0.005873683374375105, Neurons: 64, Grad norm: 9.185e-02\n",
      "Epoch 13828, Loss: 0.005872687324881554, Neurons: 64, Grad norm: 1.204e-01\n",
      "Epoch 13828, Loss: 0.005872687324881554, Neurons: 64, Grad norm: 1.204e-01\n",
      "Epoch 13829, Loss: 0.005871760658919811, Neurons: 64, Grad norm: 1.276e-01\n",
      "Epoch 13829, Loss: 0.005871760658919811, Neurons: 64, Grad norm: 1.276e-01\n",
      "Epoch 13830, Loss: 0.005870772060006857, Neurons: 64, Grad norm: 1.476e-01\n",
      "Epoch 13830, Loss: 0.005870772060006857, Neurons: 64, Grad norm: 1.476e-01\n",
      "Epoch 13831, Loss: 0.005869844928383827, Neurons: 64, Grad norm: 1.475e-01\n",
      "Epoch 13831, Loss: 0.005869844928383827, Neurons: 64, Grad norm: 1.475e-01\n",
      "Epoch 13832, Loss: 0.005868903826922178, Neurons: 64, Grad norm: 1.625e-01\n",
      "Epoch 13832, Loss: 0.005868903826922178, Neurons: 64, Grad norm: 1.625e-01\n",
      "Epoch 13833, Loss: 0.005867913365364075, Neurons: 64, Grad norm: 1.620e-01\n",
      "Epoch 13833, Loss: 0.005867913365364075, Neurons: 64, Grad norm: 1.620e-01\n",
      "Epoch 13834, Loss: 0.005866984836757183, Neurons: 64, Grad norm: 1.815e-01\n",
      "Epoch 13834, Loss: 0.005866984836757183, Neurons: 64, Grad norm: 1.815e-01\n",
      "Epoch 13835, Loss: 0.005866129882633686, Neurons: 64, Grad norm: 1.896e-01\n",
      "Epoch 13835, Loss: 0.005866129882633686, Neurons: 64, Grad norm: 1.896e-01\n",
      "Epoch 13836, Loss: 0.005865326151251793, Neurons: 64, Grad norm: 2.192e-01\n",
      "Epoch 13836, Loss: 0.005865326151251793, Neurons: 64, Grad norm: 2.192e-01\n",
      "Epoch 13837, Loss: 0.005864690989255905, Neurons: 64, Grad norm: 2.418e-01\n",
      "Epoch 13837, Loss: 0.005864690989255905, Neurons: 64, Grad norm: 2.418e-01\n",
      "Epoch 13838, Loss: 0.005864202044904232, Neurons: 64, Grad norm: 2.888e-01\n",
      "Epoch 13838, Loss: 0.005864202044904232, Neurons: 64, Grad norm: 2.888e-01\n",
      "Epoch 13839, Loss: 0.005863920319825411, Neurons: 64, Grad norm: 3.358e-01\n",
      "Epoch 13839, Loss: 0.005863920319825411, Neurons: 64, Grad norm: 3.358e-01\n",
      "Epoch 13840, Loss: 0.0058640786446630955, Neurons: 64, Grad norm: 4.040e-01\n",
      "Epoch 13840, Loss: 0.0058640786446630955, Neurons: 64, Grad norm: 4.040e-01\n",
      "Epoch 13841, Loss: 0.005864676088094711, Neurons: 64, Grad norm: 4.731e-01\n",
      "Epoch 13841, Loss: 0.005864676088094711, Neurons: 64, Grad norm: 4.731e-01\n",
      "Epoch 13842, Loss: 0.005865897051990032, Neurons: 64, Grad norm: 5.668e-01\n",
      "Epoch 13842, Loss: 0.005865897051990032, Neurons: 64, Grad norm: 5.668e-01\n",
      "Epoch 13843, Loss: 0.005867939908057451, Neurons: 64, Grad norm: 6.705e-01\n",
      "Epoch 13843, Loss: 0.005867939908057451, Neurons: 64, Grad norm: 6.705e-01\n",
      "Epoch 13844, Loss: 0.005871147383004427, Neurons: 64, Grad norm: 8.137e-01\n",
      "Epoch 13844, Loss: 0.005871147383004427, Neurons: 64, Grad norm: 8.137e-01\n",
      "Epoch 13845, Loss: 0.0058760750107467175, Neurons: 64, Grad norm: 9.724e-01\n",
      "Epoch 13845, Loss: 0.0058760750107467175, Neurons: 64, Grad norm: 9.724e-01\n",
      "Epoch 13846, Loss: 0.005883917212486267, Neurons: 64, Grad norm: 1.177e+00\n",
      "Epoch 13846, Loss: 0.005883917212486267, Neurons: 64, Grad norm: 1.177e+00\n",
      "Epoch 13847, Loss: 0.005895362235605717, Neurons: 64, Grad norm: 1.413e+00\n",
      "Epoch 13847, Loss: 0.005895362235605717, Neurons: 64, Grad norm: 1.413e+00\n",
      "Epoch 13848, Loss: 0.005912751890718937, Neurons: 64, Grad norm: 1.716e+00\n",
      "Epoch 13848, Loss: 0.005912751890718937, Neurons: 64, Grad norm: 1.716e+00\n",
      "Epoch 13849, Loss: 0.005937769077718258, Neurons: 64, Grad norm: 2.066e+00\n",
      "Epoch 13849, Loss: 0.005937769077718258, Neurons: 64, Grad norm: 2.066e+00\n",
      "Epoch 13850, Loss: 0.005974234081804752, Neurons: 64, Grad norm: 2.491e+00\n",
      "Epoch 13850, Loss: 0.005974234081804752, Neurons: 64, Grad norm: 2.491e+00\n",
      "Epoch 13851, Loss: 0.006024859845638275, Neurons: 64, Grad norm: 2.975e+00\n",
      "Epoch 13851, Loss: 0.006024859845638275, Neurons: 64, Grad norm: 2.975e+00\n",
      "Epoch 13852, Loss: 0.006094734650105238, Neurons: 64, Grad norm: 3.540e+00\n",
      "Epoch 13852, Loss: 0.006094734650105238, Neurons: 64, Grad norm: 3.540e+00\n",
      "Epoch 13853, Loss: 0.006184730678796768, Neurons: 64, Grad norm: 4.140e+00\n",
      "Epoch 13853, Loss: 0.006184730678796768, Neurons: 64, Grad norm: 4.140e+00\n",
      "Epoch 13854, Loss: 0.006295160856097937, Neurons: 64, Grad norm: 4.776e+00\n",
      "Epoch 13854, Loss: 0.006295160856097937, Neurons: 64, Grad norm: 4.776e+00\n",
      "Epoch 13855, Loss: 0.006414521485567093, Neurons: 64, Grad norm: 5.352e+00\n",
      "Epoch 13855, Loss: 0.006414521485567093, Neurons: 64, Grad norm: 5.352e+00\n",
      "Epoch 13856, Loss: 0.006524393334984779, Neurons: 64, Grad norm: 5.820e+00\n",
      "Epoch 13856, Loss: 0.006524393334984779, Neurons: 64, Grad norm: 5.820e+00\n",
      "Epoch 13857, Loss: 0.006590908393263817, Neurons: 64, Grad norm: 6.065e+00\n",
      "Epoch 13857, Loss: 0.006590908393263817, Neurons: 64, Grad norm: 6.065e+00\n",
      "Epoch 13858, Loss: 0.0065896655432879925, Neurons: 64, Grad norm: 6.037e+00\n",
      "Epoch 13858, Loss: 0.0065896655432879925, Neurons: 64, Grad norm: 6.037e+00\n",
      "Epoch 13859, Loss: 0.006507555954158306, Neurons: 64, Grad norm: 5.674e+00\n",
      "Epoch 13859, Loss: 0.006507555954158306, Neurons: 64, Grad norm: 5.674e+00\n",
      "Epoch 13860, Loss: 0.006371716968715191, Neurons: 64, Grad norm: 5.044e+00\n",
      "Epoch 13860, Loss: 0.006371716968715191, Neurons: 64, Grad norm: 5.044e+00\n",
      "Epoch 13861, Loss: 0.006227679084986448, Neurons: 64, Grad norm: 4.203e+00\n",
      "Epoch 13861, Loss: 0.006227679084986448, Neurons: 64, Grad norm: 4.203e+00\n",
      "Epoch 13862, Loss: 0.00612013740465045, Neurons: 64, Grad norm: 3.312e+00\n",
      "Epoch 13862, Loss: 0.00612013740465045, Neurons: 64, Grad norm: 3.312e+00\n",
      "Epoch 13863, Loss: 0.006063253618776798, Neurons: 64, Grad norm: 2.466e+00\n",
      "Epoch 13863, Loss: 0.006063253618776798, Neurons: 64, Grad norm: 2.466e+00\n",
      "Epoch 13864, Loss: 0.00604123342782259, Neurons: 64, Grad norm: 1.836e+00\n",
      "Epoch 13864, Loss: 0.00604123342782259, Neurons: 64, Grad norm: 1.836e+00\n",
      "Epoch 13865, Loss: 0.006024142261594534, Neurons: 64, Grad norm: 1.530e+00\n",
      "Epoch 13865, Loss: 0.006024142261594534, Neurons: 64, Grad norm: 1.530e+00\n",
      "Epoch 13866, Loss: 0.005991090089082718, Neurons: 64, Grad norm: 1.592e+00\n",
      "Epoch 13866, Loss: 0.005991090089082718, Neurons: 64, Grad norm: 1.592e+00\n",
      "Epoch 13867, Loss: 0.005945137701928616, Neurons: 64, Grad norm: 1.876e+00\n",
      "Epoch 13867, Loss: 0.005945137701928616, Neurons: 64, Grad norm: 1.876e+00\n",
      "Epoch 13868, Loss: 0.005909442435950041, Neurons: 64, Grad norm: 2.202e+00\n",
      "Epoch 13868, Loss: 0.005909442435950041, Neurons: 64, Grad norm: 2.202e+00\n",
      "Epoch 13869, Loss: 0.005906017031520605, Neurons: 64, Grad norm: 2.499e+00\n",
      "Epoch 13869, Loss: 0.005906017031520605, Neurons: 64, Grad norm: 2.499e+00\n",
      "Epoch 13870, Loss: 0.005936709698289633, Neurons: 64, Grad norm: 2.661e+00\n",
      "Epoch 13870, Loss: 0.005936709698289633, Neurons: 64, Grad norm: 2.661e+00\n",
      "Epoch 13871, Loss: 0.005980649031698704, Neurons: 64, Grad norm: 2.670e+00\n",
      "Epoch 13871, Loss: 0.005980649031698704, Neurons: 64, Grad norm: 2.670e+00\n",
      "Epoch 13872, Loss: 0.006007596384733915, Neurons: 64, Grad norm: 2.464e+00\n",
      "Epoch 13872, Loss: 0.006007596384733915, Neurons: 64, Grad norm: 2.464e+00\n",
      "Epoch 13873, Loss: 0.0059969257563352585, Neurons: 64, Grad norm: 2.086e+00\n",
      "Epoch 13873, Loss: 0.0059969257563352585, Neurons: 64, Grad norm: 2.086e+00\n",
      "Epoch 13874, Loss: 0.005950205028057098, Neurons: 64, Grad norm: 1.540e+00\n",
      "Epoch 13874, Loss: 0.005950205028057098, Neurons: 64, Grad norm: 1.540e+00\n",
      "Epoch 13875, Loss: 0.005889671389013529, Neurons: 64, Grad norm: 9.487e-01\n",
      "Epoch 13875, Loss: 0.005889671389013529, Neurons: 64, Grad norm: 9.487e-01\n",
      "Epoch 13876, Loss: 0.005843323189765215, Neurons: 64, Grad norm: 4.214e-01\n",
      "Epoch 13876, Loss: 0.005843323189765215, Neurons: 64, Grad norm: 4.214e-01\n",
      "Epoch 13877, Loss: 0.005827342160046101, Neurons: 64, Grad norm: 4.823e-01\n",
      "Epoch 13877, Loss: 0.005827342160046101, Neurons: 64, Grad norm: 4.823e-01\n",
      "Epoch 13878, Loss: 0.005838549695909023, Neurons: 64, Grad norm: 8.734e-01\n",
      "Epoch 13878, Loss: 0.005838549695909023, Neurons: 64, Grad norm: 8.734e-01\n",
      "Epoch 13879, Loss: 0.005860594101250172, Neurons: 64, Grad norm: 1.170e+00\n",
      "Epoch 13879, Loss: 0.005860594101250172, Neurons: 64, Grad norm: 1.170e+00\n",
      "Epoch 13880, Loss: 0.005876295734196901, Neurons: 64, Grad norm: 1.365e+00\n",
      "Epoch 13880, Loss: 0.005876295734196901, Neurons: 64, Grad norm: 1.365e+00\n",
      "Epoch 13881, Loss: 0.005877612624317408, Neurons: 64, Grad norm: 1.443e+00\n",
      "Epoch 13881, Loss: 0.005877612624317408, Neurons: 64, Grad norm: 1.443e+00\n",
      "Epoch 13882, Loss: 0.005867644678801298, Neurons: 64, Grad norm: 1.472e+00\n",
      "Epoch 13882, Loss: 0.005867644678801298, Neurons: 64, Grad norm: 1.472e+00\n",
      "Epoch 13883, Loss: 0.0058555519208312035, Neurons: 64, Grad norm: 1.438e+00\n",
      "Epoch 13883, Loss: 0.0058555519208312035, Neurons: 64, Grad norm: 1.438e+00\n",
      "Epoch 13884, Loss: 0.005848710425198078, Neurons: 64, Grad norm: 1.385e+00\n",
      "Epoch 13884, Loss: 0.005848710425198078, Neurons: 64, Grad norm: 1.385e+00\n",
      "Epoch 13885, Loss: 0.005847932305186987, Neurons: 64, Grad norm: 1.267e+00\n",
      "Epoch 13885, Loss: 0.005847932305186987, Neurons: 64, Grad norm: 1.267e+00\n",
      "Epoch 13886, Loss: 0.005848792381584644, Neurons: 64, Grad norm: 1.103e+00\n",
      "Epoch 13886, Loss: 0.005848792381584644, Neurons: 64, Grad norm: 1.103e+00\n",
      "Epoch 13887, Loss: 0.005845807958394289, Neurons: 64, Grad norm: 8.625e-01\n",
      "Epoch 13887, Loss: 0.005845807958394289, Neurons: 64, Grad norm: 8.625e-01\n",
      "Epoch 13888, Loss: 0.005837159231305122, Neurons: 64, Grad norm: 5.805e-01\n",
      "Epoch 13888, Loss: 0.005837159231305122, Neurons: 64, Grad norm: 5.805e-01\n",
      "Epoch 13889, Loss: 0.005825241561979055, Neurons: 64, Grad norm: 2.675e-01\n",
      "Epoch 13889, Loss: 0.005825241561979055, Neurons: 64, Grad norm: 2.675e-01\n",
      "Epoch 13890, Loss: 0.00581522099673748, Neurons: 64, Grad norm: 1.366e-01\n",
      "Epoch 13890, Loss: 0.00581522099673748, Neurons: 64, Grad norm: 1.366e-01\n",
      "Epoch 13891, Loss: 0.005810762755572796, Neurons: 64, Grad norm: 3.942e-01\n",
      "Epoch 13891, Loss: 0.005810762755572796, Neurons: 64, Grad norm: 3.942e-01\n",
      "Epoch 13892, Loss: 0.005812536459416151, Neurons: 64, Grad norm: 6.153e-01\n",
      "Epoch 13892, Loss: 0.005812536459416151, Neurons: 64, Grad norm: 6.153e-01\n",
      "Epoch 13893, Loss: 0.005817696917802095, Neurons: 64, Grad norm: 7.825e-01\n",
      "Epoch 13893, Loss: 0.005817696917802095, Neurons: 64, Grad norm: 7.825e-01\n",
      "Epoch 13894, Loss: 0.005822460632771254, Neurons: 64, Grad norm: 8.601e-01\n",
      "Epoch 13894, Loss: 0.005822460632771254, Neurons: 64, Grad norm: 8.601e-01\n",
      "Epoch 13895, Loss: 0.005823906511068344, Neurons: 64, Grad norm: 8.850e-01\n",
      "Epoch 13895, Loss: 0.005823906511068344, Neurons: 64, Grad norm: 8.850e-01\n",
      "Epoch 13896, Loss: 0.005821733269840479, Neurons: 64, Grad norm: 8.445e-01\n",
      "Epoch 13896, Loss: 0.005821733269840479, Neurons: 64, Grad norm: 8.445e-01\n",
      "Epoch 13897, Loss: 0.005817452911287546, Neurons: 64, Grad norm: 7.916e-01\n",
      "Epoch 13897, Loss: 0.005817452911287546, Neurons: 64, Grad norm: 7.916e-01\n",
      "Epoch 13898, Loss: 0.00581329083070159, Neurons: 64, Grad norm: 7.090e-01\n",
      "Epoch 13898, Loss: 0.00581329083070159, Neurons: 64, Grad norm: 7.090e-01\n",
      "Epoch 13899, Loss: 0.0058105080388486385, Neurons: 64, Grad norm: 6.448e-01\n",
      "Epoch 13899, Loss: 0.0058105080388486385, Neurons: 64, Grad norm: 6.448e-01\n",
      "Epoch 13899, Test loss: 0.004784075077623129\n",
      "Epoch 13899, Test loss: 0.004784075077623129\n",
      "Epoch 13900, Loss: 0.005809239577502012, Neurons: 64, Grad norm: 5.644e-01\n",
      "Epoch 13900, Loss: 0.005809239577502012, Neurons: 64, Grad norm: 5.644e-01\n",
      "Epoch 13901, Loss: 0.005808476824313402, Neurons: 64, Grad norm: 4.987e-01\n",
      "Epoch 13901, Loss: 0.005808476824313402, Neurons: 64, Grad norm: 4.987e-01\n",
      "Epoch 13902, Loss: 0.005807167384773493, Neurons: 64, Grad norm: 4.020e-01\n",
      "Epoch 13902, Loss: 0.005807167384773493, Neurons: 64, Grad norm: 4.020e-01\n",
      "Epoch 13903, Loss: 0.005804819520562887, Neurons: 64, Grad norm: 3.122e-01\n",
      "Epoch 13903, Loss: 0.005804819520562887, Neurons: 64, Grad norm: 3.122e-01\n",
      "Epoch 13904, Loss: 0.005801677238196135, Neurons: 64, Grad norm: 1.937e-01\n",
      "Epoch 13904, Loss: 0.005801677238196135, Neurons: 64, Grad norm: 1.937e-01\n",
      "Epoch 13905, Loss: 0.005798545200377703, Neurons: 64, Grad norm: 8.731e-02\n",
      "Epoch 13905, Loss: 0.005798545200377703, Neurons: 64, Grad norm: 8.731e-02\n",
      "Epoch 13906, Loss: 0.005796180572360754, Neurons: 64, Grad norm: 3.290e-02\n",
      "Epoch 13906, Loss: 0.005796180572360754, Neurons: 64, Grad norm: 3.290e-02\n",
      "Epoch 13907, Loss: 0.005794972646981478, Neurons: 64, Grad norm: 1.194e-01\n",
      "Epoch 13907, Loss: 0.005794972646981478, Neurons: 64, Grad norm: 1.194e-01\n",
      "Epoch 13908, Loss: 0.00579466437920928, Neurons: 64, Grad norm: 2.037e-01\n",
      "Epoch 13908, Loss: 0.00579466437920928, Neurons: 64, Grad norm: 2.037e-01\n",
      "Epoch 13909, Loss: 0.00579476822167635, Neurons: 64, Grad norm: 2.510e-01\n",
      "Epoch 13909, Loss: 0.00579476822167635, Neurons: 64, Grad norm: 2.510e-01\n",
      "Epoch 13910, Loss: 0.00579463317990303, Neurons: 64, Grad norm: 2.979e-01\n",
      "Epoch 13910, Loss: 0.00579463317990303, Neurons: 64, Grad norm: 2.979e-01\n",
      "Epoch 13911, Loss: 0.005794020835310221, Neurons: 64, Grad norm: 3.144e-01\n",
      "Epoch 13911, Loss: 0.005794020835310221, Neurons: 64, Grad norm: 3.144e-01\n",
      "Epoch 13912, Loss: 0.005792923271656036, Neurons: 64, Grad norm: 3.438e-01\n",
      "Epoch 13912, Loss: 0.005792923271656036, Neurons: 64, Grad norm: 3.438e-01\n",
      "Epoch 13913, Loss: 0.005791679490357637, Neurons: 64, Grad norm: 3.525e-01\n",
      "Epoch 13913, Loss: 0.005791679490357637, Neurons: 64, Grad norm: 3.525e-01\n",
      "Epoch 13914, Loss: 0.005790399853140116, Neurons: 64, Grad norm: 3.812e-01\n",
      "Epoch 13914, Loss: 0.005790399853140116, Neurons: 64, Grad norm: 3.812e-01\n",
      "Epoch 13915, Loss: 0.005789380520582199, Neurons: 64, Grad norm: 3.923e-01\n",
      "Epoch 13915, Loss: 0.005789380520582199, Neurons: 64, Grad norm: 3.923e-01\n",
      "Epoch 13916, Loss: 0.005788575392216444, Neurons: 64, Grad norm: 4.213e-01\n",
      "Epoch 13916, Loss: 0.005788575392216444, Neurons: 64, Grad norm: 4.213e-01\n",
      "Epoch 13917, Loss: 0.005787928123027086, Neurons: 64, Grad norm: 4.304e-01\n",
      "Epoch 13917, Loss: 0.005787928123027086, Neurons: 64, Grad norm: 4.304e-01\n",
      "Epoch 13918, Loss: 0.005787374917417765, Neurons: 64, Grad norm: 4.523e-01\n",
      "Epoch 13918, Loss: 0.005787374917417765, Neurons: 64, Grad norm: 4.523e-01\n",
      "Epoch 13919, Loss: 0.005786688532680273, Neurons: 64, Grad norm: 4.573e-01\n",
      "Epoch 13919, Loss: 0.005786688532680273, Neurons: 64, Grad norm: 4.573e-01\n",
      "Epoch 13920, Loss: 0.005785847082734108, Neurons: 64, Grad norm: 4.769e-01\n",
      "Epoch 13920, Loss: 0.005785847082734108, Neurons: 64, Grad norm: 4.769e-01\n",
      "Epoch 13921, Loss: 0.005784936714917421, Neurons: 64, Grad norm: 4.754e-01\n",
      "Epoch 13921, Loss: 0.005784936714917421, Neurons: 64, Grad norm: 4.754e-01\n",
      "Epoch 13922, Loss: 0.005784024018794298, Neurons: 64, Grad norm: 4.989e-01\n",
      "Epoch 13922, Loss: 0.005784024018794298, Neurons: 64, Grad norm: 4.989e-01\n",
      "Epoch 13923, Loss: 0.005783220287412405, Neurons: 64, Grad norm: 5.057e-01\n",
      "Epoch 13923, Loss: 0.005783220287412405, Neurons: 64, Grad norm: 5.057e-01\n",
      "Epoch 13924, Loss: 0.005782437045127153, Neurons: 64, Grad norm: 5.341e-01\n",
      "Epoch 13924, Loss: 0.005782437045127153, Neurons: 64, Grad norm: 5.341e-01\n",
      "Epoch 13925, Loss: 0.005781854502856731, Neurons: 64, Grad norm: 5.540e-01\n",
      "Epoch 13925, Loss: 0.005781854502856731, Neurons: 64, Grad norm: 5.540e-01\n",
      "Epoch 13926, Loss: 0.00578137906268239, Neurons: 64, Grad norm: 5.952e-01\n",
      "Epoch 13926, Loss: 0.00578137906268239, Neurons: 64, Grad norm: 5.952e-01\n",
      "Epoch 13927, Loss: 0.0057810950092971325, Neurons: 64, Grad norm: 6.265e-01\n",
      "Epoch 13927, Loss: 0.0057810950092971325, Neurons: 64, Grad norm: 6.265e-01\n",
      "Epoch 13928, Loss: 0.005781020503491163, Neurons: 64, Grad norm: 6.884e-01\n",
      "Epoch 13928, Loss: 0.005781020503491163, Neurons: 64, Grad norm: 6.884e-01\n",
      "Epoch 13929, Loss: 0.005781153216958046, Neurons: 64, Grad norm: 7.373e-01\n",
      "Epoch 13929, Loss: 0.005781153216958046, Neurons: 64, Grad norm: 7.373e-01\n",
      "Epoch 13930, Loss: 0.005781513638794422, Neurons: 64, Grad norm: 8.181e-01\n",
      "Epoch 13930, Loss: 0.005781513638794422, Neurons: 64, Grad norm: 8.181e-01\n",
      "Epoch 13931, Loss: 0.00578212970867753, Neurons: 64, Grad norm: 8.922e-01\n",
      "Epoch 13931, Loss: 0.00578212970867753, Neurons: 64, Grad norm: 8.922e-01\n",
      "Epoch 13932, Loss: 0.005783278960734606, Neurons: 64, Grad norm: 9.968e-01\n",
      "Epoch 13932, Loss: 0.005783278960734606, Neurons: 64, Grad norm: 9.968e-01\n",
      "Epoch 13933, Loss: 0.0057850671000778675, Neurons: 64, Grad norm: 1.102e+00\n",
      "Epoch 13933, Loss: 0.0057850671000778675, Neurons: 64, Grad norm: 1.102e+00\n",
      "Epoch 13934, Loss: 0.005787659902125597, Neurons: 64, Grad norm: 1.245e+00\n",
      "Epoch 13934, Loss: 0.005787659902125597, Neurons: 64, Grad norm: 1.245e+00\n",
      "Epoch 13935, Loss: 0.005791386589407921, Neurons: 64, Grad norm: 1.391e+00\n",
      "Epoch 13935, Loss: 0.005791386589407921, Neurons: 64, Grad norm: 1.391e+00\n",
      "Epoch 13936, Loss: 0.005796585697680712, Neurons: 64, Grad norm: 1.584e+00\n",
      "Epoch 13936, Loss: 0.005796585697680712, Neurons: 64, Grad norm: 1.584e+00\n",
      "Epoch 13937, Loss: 0.005803868640214205, Neurons: 64, Grad norm: 1.789e+00\n",
      "Epoch 13937, Loss: 0.005803868640214205, Neurons: 64, Grad norm: 1.789e+00\n",
      "Epoch 13938, Loss: 0.005813960451632738, Neurons: 64, Grad norm: 2.052e+00\n",
      "Epoch 13938, Loss: 0.005813960451632738, Neurons: 64, Grad norm: 2.052e+00\n",
      "Epoch 13939, Loss: 0.005827806424349546, Neurons: 64, Grad norm: 2.339e+00\n",
      "Epoch 13939, Loss: 0.005827806424349546, Neurons: 64, Grad norm: 2.339e+00\n",
      "Epoch 13940, Loss: 0.005846505984663963, Neurons: 64, Grad norm: 2.690e+00\n",
      "Epoch 13940, Loss: 0.005846505984663963, Neurons: 64, Grad norm: 2.690e+00\n",
      "Epoch 13941, Loss: 0.005871683359146118, Neurons: 64, Grad norm: 3.074e+00\n",
      "Epoch 13941, Loss: 0.005871683359146118, Neurons: 64, Grad norm: 3.074e+00\n",
      "Epoch 13942, Loss: 0.005905471742153168, Neurons: 64, Grad norm: 3.537e+00\n",
      "Epoch 13942, Loss: 0.005905471742153168, Neurons: 64, Grad norm: 3.537e+00\n",
      "Epoch 13943, Loss: 0.005950115621089935, Neurons: 64, Grad norm: 4.039e+00\n",
      "Epoch 13943, Loss: 0.005950115621089935, Neurons: 64, Grad norm: 4.039e+00\n",
      "Epoch 13944, Loss: 0.006008489988744259, Neurons: 64, Grad norm: 4.614e+00\n",
      "Epoch 13944, Loss: 0.006008489988744259, Neurons: 64, Grad norm: 4.614e+00\n",
      "Epoch 13945, Loss: 0.006082422100007534, Neurons: 64, Grad norm: 5.217e+00\n",
      "Epoch 13945, Loss: 0.006082422100007534, Neurons: 64, Grad norm: 5.217e+00\n",
      "Epoch 13946, Loss: 0.006173567846417427, Neurons: 64, Grad norm: 5.856e+00\n",
      "Epoch 13946, Loss: 0.006173567846417427, Neurons: 64, Grad norm: 5.856e+00\n",
      "Epoch 13947, Loss: 0.006279308814555407, Neurons: 64, Grad norm: 6.451e+00\n",
      "Epoch 13947, Loss: 0.006279308814555407, Neurons: 64, Grad norm: 6.451e+00\n",
      "Epoch 13948, Loss: 0.006392913870513439, Neurons: 64, Grad norm: 6.969e+00\n",
      "Epoch 13948, Loss: 0.006392913870513439, Neurons: 64, Grad norm: 6.969e+00\n",
      "Epoch 13949, Loss: 0.006497312802821398, Neurons: 64, Grad norm: 7.287e+00\n",
      "Epoch 13949, Loss: 0.006497312802821398, Neurons: 64, Grad norm: 7.287e+00\n",
      "Epoch 13950, Loss: 0.006568884942680597, Neurons: 64, Grad norm: 7.335e+00\n",
      "Epoch 13950, Loss: 0.006568884942680597, Neurons: 64, Grad norm: 7.335e+00\n",
      "Epoch 13951, Loss: 0.006577381398528814, Neurons: 64, Grad norm: 6.987e+00\n",
      "Epoch 13951, Loss: 0.006577381398528814, Neurons: 64, Grad norm: 6.987e+00\n",
      "Epoch 13952, Loss: 0.006504019722342491, Neurons: 64, Grad norm: 6.235e+00\n",
      "Epoch 13952, Loss: 0.006504019722342491, Neurons: 64, Grad norm: 6.235e+00\n",
      "Epoch 13953, Loss: 0.00634909700602293, Neurons: 64, Grad norm: 5.055e+00\n",
      "Epoch 13953, Loss: 0.00634909700602293, Neurons: 64, Grad norm: 5.055e+00\n",
      "Epoch 13954, Loss: 0.006145732942968607, Neurons: 64, Grad norm: 3.567e+00\n",
      "Epoch 13954, Loss: 0.006145732942968607, Neurons: 64, Grad norm: 3.567e+00\n",
      "Epoch 13955, Loss: 0.0059467195533216, Neurons: 64, Grad norm: 1.886e+00\n",
      "Epoch 13955, Loss: 0.0059467195533216, Neurons: 64, Grad norm: 1.886e+00\n",
      "Epoch 13956, Loss: 0.005805057007819414, Neurons: 64, Grad norm: 2.519e-01\n",
      "Epoch 13956, Loss: 0.005805057007819414, Neurons: 64, Grad norm: 2.519e-01\n",
      "Epoch 13957, Loss: 0.005748886149376631, Neurons: 64, Grad norm: 1.339e+00\n",
      "Epoch 13957, Loss: 0.005748886149376631, Neurons: 64, Grad norm: 1.339e+00\n",
      "Epoch 13958, Loss: 0.00577319273725152, Neurons: 64, Grad norm: 2.586e+00\n",
      "Epoch 13958, Loss: 0.00577319273725152, Neurons: 64, Grad norm: 2.586e+00\n",
      "Epoch 13959, Loss: 0.005847183056175709, Neurons: 64, Grad norm: 3.494e+00\n",
      "Epoch 13959, Loss: 0.005847183056175709, Neurons: 64, Grad norm: 3.494e+00\n",
      "Epoch 13960, Loss: 0.0059300255961716175, Neurons: 64, Grad norm: 3.978e+00\n",
      "Epoch 13960, Loss: 0.0059300255961716175, Neurons: 64, Grad norm: 3.978e+00\n",
      "Epoch 13961, Loss: 0.005986394826322794, Neurons: 64, Grad norm: 4.059e+00\n",
      "Epoch 13961, Loss: 0.005986394826322794, Neurons: 64, Grad norm: 4.059e+00\n",
      "Epoch 13962, Loss: 0.005995402578264475, Neurons: 64, Grad norm: 3.721e+00\n",
      "Epoch 13962, Loss: 0.005995402578264475, Neurons: 64, Grad norm: 3.721e+00\n",
      "Epoch 13963, Loss: 0.005956494715064764, Neurons: 64, Grad norm: 3.065e+00\n",
      "Epoch 13963, Loss: 0.005956494715064764, Neurons: 64, Grad norm: 3.065e+00\n",
      "Epoch 13964, Loss: 0.005886978469789028, Neurons: 64, Grad norm: 2.150e+00\n",
      "Epoch 13964, Loss: 0.005886978469789028, Neurons: 64, Grad norm: 2.150e+00\n",
      "Epoch 13965, Loss: 0.005813539493829012, Neurons: 64, Grad norm: 1.132e+00\n",
      "Epoch 13965, Loss: 0.005813539493829012, Neurons: 64, Grad norm: 1.132e+00\n",
      "Epoch 13966, Loss: 0.00576007878407836, Neurons: 64, Grad norm: 1.645e-01\n",
      "Epoch 13966, Loss: 0.00576007878407836, Neurons: 64, Grad norm: 1.645e-01\n",
      "Epoch 13967, Loss: 0.005739070009440184, Neurons: 64, Grad norm: 8.843e-01\n",
      "Epoch 13967, Loss: 0.005739070009440184, Neurons: 64, Grad norm: 8.843e-01\n",
      "Epoch 13968, Loss: 0.005748796742409468, Neurons: 64, Grad norm: 1.654e+00\n",
      "Epoch 13968, Loss: 0.005748796742409468, Neurons: 64, Grad norm: 1.654e+00\n",
      "Epoch 13969, Loss: 0.005776865407824516, Neurons: 64, Grad norm: 2.171e+00\n",
      "Epoch 13969, Loss: 0.005776865407824516, Neurons: 64, Grad norm: 2.171e+00\n",
      "Epoch 13970, Loss: 0.0058069429360330105, Neurons: 64, Grad norm: 2.446e+00\n",
      "Epoch 13970, Loss: 0.0058069429360330105, Neurons: 64, Grad norm: 2.446e+00\n",
      "Epoch 13971, Loss: 0.005825335625559092, Neurons: 64, Grad norm: 2.445e+00\n",
      "Epoch 13971, Loss: 0.005825335625559092, Neurons: 64, Grad norm: 2.445e+00\n",
      "Epoch 13972, Loss: 0.005825660191476345, Neurons: 64, Grad norm: 2.229e+00\n",
      "Epoch 13972, Loss: 0.005825660191476345, Neurons: 64, Grad norm: 2.229e+00\n",
      "Epoch 13973, Loss: 0.005809196271002293, Neurons: 64, Grad norm: 1.802e+00\n",
      "Epoch 13973, Loss: 0.005809196271002293, Neurons: 64, Grad norm: 1.802e+00\n",
      "Epoch 13974, Loss: 0.005782891530543566, Neurons: 64, Grad norm: 1.267e+00\n",
      "Epoch 13974, Loss: 0.005782891530543566, Neurons: 64, Grad norm: 1.267e+00\n",
      "Epoch 13975, Loss: 0.005756480619311333, Neurons: 64, Grad norm: 6.591e-01\n",
      "Epoch 13975, Loss: 0.005756480619311333, Neurons: 64, Grad norm: 6.591e-01\n",
      "Epoch 13976, Loss: 0.0057375007309019566, Neurons: 64, Grad norm: 1.555e-01\n",
      "Epoch 13976, Loss: 0.0057375007309019566, Neurons: 64, Grad norm: 1.555e-01\n",
      "Epoch 13977, Loss: 0.005729534197598696, Neurons: 64, Grad norm: 5.299e-01\n",
      "Epoch 13977, Loss: 0.005729534197598696, Neurons: 64, Grad norm: 5.299e-01\n",
      "Epoch 13978, Loss: 0.005731836427003145, Neurons: 64, Grad norm: 9.597e-01\n",
      "Epoch 13978, Loss: 0.005731836427003145, Neurons: 64, Grad norm: 9.597e-01\n",
      "Epoch 13979, Loss: 0.005740388762205839, Neurons: 64, Grad norm: 1.285e+00\n",
      "Epoch 13979, Loss: 0.005740388762205839, Neurons: 64, Grad norm: 1.285e+00\n",
      "Epoch 13980, Loss: 0.005750115029513836, Neurons: 64, Grad norm: 1.450e+00\n",
      "Epoch 13980, Loss: 0.005750115029513836, Neurons: 64, Grad norm: 1.450e+00\n",
      "Epoch 13981, Loss: 0.0057567027397453785, Neurons: 64, Grad norm: 1.499e+00\n",
      "Epoch 13981, Loss: 0.0057567027397453785, Neurons: 64, Grad norm: 1.499e+00\n",
      "Epoch 13982, Loss: 0.00575773511081934, Neurons: 64, Grad norm: 1.401e+00\n",
      "Epoch 13982, Loss: 0.00575773511081934, Neurons: 64, Grad norm: 1.401e+00\n",
      "Epoch 13983, Loss: 0.005753253120929003, Neurons: 64, Grad norm: 1.212e+00\n",
      "Epoch 13983, Loss: 0.005753253120929003, Neurons: 64, Grad norm: 1.212e+00\n",
      "Epoch 13984, Loss: 0.0057449135929346085, Neurons: 64, Grad norm: 9.323e-01\n",
      "Epoch 13984, Loss: 0.0057449135929346085, Neurons: 64, Grad norm: 9.323e-01\n",
      "Epoch 13985, Loss: 0.005735248792916536, Neurons: 64, Grad norm: 6.311e-01\n",
      "Epoch 13985, Loss: 0.005735248792916536, Neurons: 64, Grad norm: 6.311e-01\n",
      "Epoch 13986, Loss: 0.005726851522922516, Neurons: 64, Grad norm: 3.053e-01\n",
      "Epoch 13986, Loss: 0.005726851522922516, Neurons: 64, Grad norm: 3.053e-01\n",
      "Epoch 13987, Loss: 0.00572128826752305, Neurons: 64, Grad norm: 1.496e-01\n",
      "Epoch 13987, Loss: 0.00572128826752305, Neurons: 64, Grad norm: 1.496e-01\n",
      "Epoch 13988, Loss: 0.00571899488568306, Neurons: 64, Grad norm: 3.623e-01\n",
      "Epoch 13988, Loss: 0.00571899488568306, Neurons: 64, Grad norm: 3.623e-01\n",
      "Epoch 13989, Loss: 0.005719369743019342, Neurons: 64, Grad norm: 5.684e-01\n",
      "Epoch 13989, Loss: 0.005719369743019342, Neurons: 64, Grad norm: 5.684e-01\n",
      "Epoch 13990, Loss: 0.005721133667975664, Neurons: 64, Grad norm: 7.393e-01\n",
      "Epoch 13990, Loss: 0.005721133667975664, Neurons: 64, Grad norm: 7.393e-01\n",
      "Epoch 13991, Loss: 0.005723189562559128, Neurons: 64, Grad norm: 8.293e-01\n",
      "Epoch 13991, Loss: 0.005723189562559128, Neurons: 64, Grad norm: 8.293e-01\n",
      "Epoch 13992, Loss: 0.005724447313696146, Neurons: 64, Grad norm: 8.726e-01\n",
      "Epoch 13992, Loss: 0.005724447313696146, Neurons: 64, Grad norm: 8.726e-01\n",
      "Epoch 13993, Loss: 0.005724464543163776, Neurons: 64, Grad norm: 8.416e-01\n",
      "Epoch 13993, Loss: 0.005724464543163776, Neurons: 64, Grad norm: 8.416e-01\n",
      "Epoch 13994, Loss: 0.0057230680249631405, Neurons: 64, Grad norm: 7.817e-01\n",
      "Epoch 13994, Loss: 0.0057230680249631405, Neurons: 64, Grad norm: 7.817e-01\n",
      "Epoch 13995, Loss: 0.0057205683551728725, Neurons: 64, Grad norm: 6.605e-01\n",
      "Epoch 13995, Loss: 0.0057205683551728725, Neurons: 64, Grad norm: 6.605e-01\n",
      "Epoch 13996, Loss: 0.0057173981331288815, Neurons: 64, Grad norm: 5.336e-01\n",
      "Epoch 13996, Loss: 0.0057173981331288815, Neurons: 64, Grad norm: 5.336e-01\n",
      "Epoch 13997, Loss: 0.005714098457247019, Neurons: 64, Grad norm: 3.765e-01\n",
      "Epoch 13997, Loss: 0.005714098457247019, Neurons: 64, Grad norm: 3.765e-01\n",
      "Epoch 13998, Loss: 0.005711181089282036, Neurons: 64, Grad norm: 2.386e-01\n",
      "Epoch 13998, Loss: 0.005711181089282036, Neurons: 64, Grad norm: 2.386e-01\n",
      "Epoch 13999, Loss: 0.0057088579051196575, Neurons: 64, Grad norm: 1.190e-01\n",
      "Epoch 13999, Loss: 0.0057088579051196575, Neurons: 64, Grad norm: 1.190e-01\n",
      "Epoch 13999, Test loss: 0.00469408230856061\n",
      "Epoch 13999, Test loss: 0.00469408230856061\n",
      "Epoch 14000, Loss: 0.00570721086114645, Neurons: 64, Grad norm: 1.373e-01\n",
      "Epoch 14000, Loss: 0.00570721086114645, Neurons: 64, Grad norm: 1.373e-01\n",
      "Epoch 14001, Loss: 0.005706270225346088, Neurons: 64, Grad norm: 2.390e-01\n",
      "Epoch 14001, Loss: 0.005706270225346088, Neurons: 64, Grad norm: 2.390e-01\n",
      "Epoch 14002, Loss: 0.005705732386559248, Neurons: 64, Grad norm: 3.219e-01\n",
      "Epoch 14002, Loss: 0.005705732386559248, Neurons: 64, Grad norm: 3.219e-01\n",
      "Epoch 14003, Loss: 0.005705477204173803, Neurons: 64, Grad norm: 4.031e-01\n",
      "Epoch 14003, Loss: 0.005705477204173803, Neurons: 64, Grad norm: 4.031e-01\n",
      "Epoch 14004, Loss: 0.005705212242901325, Neurons: 64, Grad norm: 4.417e-01\n",
      "Epoch 14004, Loss: 0.005705212242901325, Neurons: 64, Grad norm: 4.417e-01\n",
      "Epoch 14005, Loss: 0.005704787094146013, Neurons: 64, Grad norm: 4.734e-01\n",
      "Epoch 14005, Loss: 0.005704787094146013, Neurons: 64, Grad norm: 4.734e-01\n",
      "Epoch 14006, Loss: 0.005704118870198727, Neurons: 64, Grad norm: 4.660e-01\n",
      "Epoch 14006, Loss: 0.005704118870198727, Neurons: 64, Grad norm: 4.660e-01\n",
      "Epoch 14007, Loss: 0.005703132599592209, Neurons: 64, Grad norm: 4.542e-01\n",
      "Epoch 14007, Loss: 0.005703132599592209, Neurons: 64, Grad norm: 4.542e-01\n",
      "Epoch 14008, Loss: 0.0057019018568098545, Neurons: 64, Grad norm: 4.104e-01\n",
      "Epoch 14008, Loss: 0.0057019018568098545, Neurons: 64, Grad norm: 4.104e-01\n",
      "Epoch 14009, Loss: 0.0057005444541573524, Neurons: 64, Grad norm: 3.783e-01\n",
      "Epoch 14009, Loss: 0.0057005444541573524, Neurons: 64, Grad norm: 3.783e-01\n",
      "Epoch 14010, Loss: 0.005699144676327705, Neurons: 64, Grad norm: 3.178e-01\n",
      "Epoch 14010, Loss: 0.005699144676327705, Neurons: 64, Grad norm: 3.178e-01\n",
      "Epoch 14011, Loss: 0.005697731394320726, Neurons: 64, Grad norm: 2.730e-01\n",
      "Epoch 14011, Loss: 0.005697731394320726, Neurons: 64, Grad norm: 2.730e-01\n",
      "Epoch 14012, Loss: 0.005696412175893784, Neurons: 64, Grad norm: 2.086e-01\n",
      "Epoch 14012, Loss: 0.005696412175893784, Neurons: 64, Grad norm: 2.086e-01\n",
      "Epoch 14013, Loss: 0.0056950682774186134, Neurons: 64, Grad norm: 1.644e-01\n",
      "Epoch 14013, Loss: 0.0056950682774186134, Neurons: 64, Grad norm: 1.644e-01\n",
      "Epoch 14014, Loss: 0.005693904124200344, Neurons: 64, Grad norm: 1.125e-01\n",
      "Epoch 14014, Loss: 0.005693904124200344, Neurons: 64, Grad norm: 1.125e-01\n",
      "Epoch 14015, Loss: 0.00569282379001379, Neurons: 64, Grad norm: 9.571e-02\n",
      "Epoch 14015, Loss: 0.00569282379001379, Neurons: 64, Grad norm: 9.571e-02\n",
      "Epoch 14016, Loss: 0.005691809114068747, Neurons: 64, Grad norm: 9.823e-02\n",
      "Epoch 14016, Loss: 0.005691809114068747, Neurons: 64, Grad norm: 9.823e-02\n",
      "Epoch 14017, Loss: 0.005690948572009802, Neurons: 64, Grad norm: 1.220e-01\n",
      "Epoch 14017, Loss: 0.005690948572009802, Neurons: 64, Grad norm: 1.220e-01\n",
      "Epoch 14018, Loss: 0.005690122023224831, Neurons: 64, Grad norm: 1.541e-01\n",
      "Epoch 14018, Loss: 0.005690122023224831, Neurons: 64, Grad norm: 1.541e-01\n",
      "Epoch 14019, Loss: 0.0056893425062298775, Neurons: 64, Grad norm: 1.732e-01\n",
      "Epoch 14019, Loss: 0.0056893425062298775, Neurons: 64, Grad norm: 1.732e-01\n",
      "Epoch 14020, Loss: 0.005688550882041454, Neurons: 64, Grad norm: 2.012e-01\n",
      "Epoch 14020, Loss: 0.005688550882041454, Neurons: 64, Grad norm: 2.012e-01\n",
      "Epoch 14021, Loss: 0.005687745753675699, Neurons: 64, Grad norm: 2.135e-01\n",
      "Epoch 14021, Loss: 0.005687745753675699, Neurons: 64, Grad norm: 2.135e-01\n",
      "Epoch 14022, Loss: 0.005686858668923378, Neurons: 64, Grad norm: 2.299e-01\n",
      "Epoch 14022, Loss: 0.005686858668923378, Neurons: 64, Grad norm: 2.299e-01\n",
      "Epoch 14023, Loss: 0.005685929208993912, Neurons: 64, Grad norm: 2.290e-01\n",
      "Epoch 14023, Loss: 0.005685929208993912, Neurons: 64, Grad norm: 2.290e-01\n",
      "Epoch 14024, Loss: 0.005685033742338419, Neurons: 64, Grad norm: 2.446e-01\n",
      "Epoch 14024, Loss: 0.005685033742338419, Neurons: 64, Grad norm: 2.446e-01\n",
      "Epoch 14025, Loss: 0.005684074945747852, Neurons: 64, Grad norm: 2.428e-01\n",
      "Epoch 14025, Loss: 0.005684074945747852, Neurons: 64, Grad norm: 2.428e-01\n",
      "Epoch 14026, Loss: 0.005683078896254301, Neurons: 64, Grad norm: 2.532e-01\n",
      "Epoch 14026, Loss: 0.005683078896254301, Neurons: 64, Grad norm: 2.532e-01\n",
      "Epoch 14027, Loss: 0.0056821261532604694, Neurons: 64, Grad norm: 2.459e-01\n",
      "Epoch 14027, Loss: 0.0056821261532604694, Neurons: 64, Grad norm: 2.459e-01\n",
      "Epoch 14028, Loss: 0.005681114736944437, Neurons: 64, Grad norm: 2.546e-01\n",
      "Epoch 14028, Loss: 0.005681114736944437, Neurons: 64, Grad norm: 2.546e-01\n",
      "Epoch 14029, Loss: 0.005680179223418236, Neurons: 64, Grad norm: 2.502e-01\n",
      "Epoch 14029, Loss: 0.005680179223418236, Neurons: 64, Grad norm: 2.502e-01\n",
      "Epoch 14030, Loss: 0.005679230205714703, Neurons: 64, Grad norm: 2.635e-01\n",
      "Epoch 14030, Loss: 0.005679230205714703, Neurons: 64, Grad norm: 2.635e-01\n",
      "Epoch 14031, Loss: 0.00567834684625268, Neurons: 64, Grad norm: 2.588e-01\n",
      "Epoch 14031, Loss: 0.00567834684625268, Neurons: 64, Grad norm: 2.588e-01\n",
      "Epoch 14032, Loss: 0.0056774127297103405, Neurons: 64, Grad norm: 2.696e-01\n",
      "Epoch 14032, Loss: 0.0056774127297103405, Neurons: 64, Grad norm: 2.696e-01\n",
      "Epoch 14033, Loss: 0.005676497705280781, Neurons: 64, Grad norm: 2.636e-01\n",
      "Epoch 14033, Loss: 0.005676497705280781, Neurons: 64, Grad norm: 2.636e-01\n",
      "Epoch 14034, Loss: 0.005675618536770344, Neurons: 64, Grad norm: 2.770e-01\n",
      "Epoch 14034, Loss: 0.005675618536770344, Neurons: 64, Grad norm: 2.770e-01\n",
      "Epoch 14035, Loss: 0.005674631334841251, Neurons: 64, Grad norm: 2.758e-01\n",
      "Epoch 14035, Loss: 0.005674631334841251, Neurons: 64, Grad norm: 2.758e-01\n",
      "Epoch 14036, Loss: 0.005673815030604601, Neurons: 64, Grad norm: 2.922e-01\n",
      "Epoch 14036, Loss: 0.005673815030604601, Neurons: 64, Grad norm: 2.922e-01\n",
      "Epoch 14037, Loss: 0.005672990344464779, Neurons: 64, Grad norm: 2.955e-01\n",
      "Epoch 14037, Loss: 0.005672990344464779, Neurons: 64, Grad norm: 2.955e-01\n",
      "Epoch 14038, Loss: 0.005672177765518427, Neurons: 64, Grad norm: 3.217e-01\n",
      "Epoch 14038, Loss: 0.005672177765518427, Neurons: 64, Grad norm: 3.217e-01\n",
      "Epoch 14039, Loss: 0.005671401508152485, Neurons: 64, Grad norm: 3.349e-01\n",
      "Epoch 14039, Loss: 0.005671401508152485, Neurons: 64, Grad norm: 3.349e-01\n",
      "Epoch 14040, Loss: 0.005670752841979265, Neurons: 64, Grad norm: 3.667e-01\n",
      "Epoch 14040, Loss: 0.005670752841979265, Neurons: 64, Grad norm: 3.667e-01\n",
      "Epoch 14041, Loss: 0.005670107435435057, Neurons: 64, Grad norm: 3.904e-01\n",
      "Epoch 14041, Loss: 0.005670107435435057, Neurons: 64, Grad norm: 3.904e-01\n",
      "Epoch 14042, Loss: 0.005669649224728346, Neurons: 64, Grad norm: 4.382e-01\n",
      "Epoch 14042, Loss: 0.005669649224728346, Neurons: 64, Grad norm: 4.382e-01\n",
      "Epoch 14043, Loss: 0.005669386591762304, Neurons: 64, Grad norm: 4.755e-01\n",
      "Epoch 14043, Loss: 0.005669386591762304, Neurons: 64, Grad norm: 4.755e-01\n",
      "Epoch 14044, Loss: 0.005669280420988798, Neurons: 64, Grad norm: 5.370e-01\n",
      "Epoch 14044, Loss: 0.005669280420988798, Neurons: 64, Grad norm: 5.370e-01\n",
      "Epoch 14045, Loss: 0.00566934235394001, Neurons: 64, Grad norm: 5.924e-01\n",
      "Epoch 14045, Loss: 0.00566934235394001, Neurons: 64, Grad norm: 5.924e-01\n",
      "Epoch 14046, Loss: 0.005669774487614632, Neurons: 64, Grad norm: 6.768e-01\n",
      "Epoch 14046, Loss: 0.005669774487614632, Neurons: 64, Grad norm: 6.768e-01\n",
      "Epoch 14047, Loss: 0.005670646671205759, Neurons: 64, Grad norm: 7.600e-01\n",
      "Epoch 14047, Loss: 0.005670646671205759, Neurons: 64, Grad norm: 7.600e-01\n",
      "Epoch 14048, Loss: 0.005672362633049488, Neurons: 64, Grad norm: 8.783e-01\n",
      "Epoch 14048, Loss: 0.005672362633049488, Neurons: 64, Grad norm: 8.783e-01\n",
      "Epoch 14049, Loss: 0.005674885120242834, Neurons: 64, Grad norm: 1.004e+00\n",
      "Epoch 14049, Loss: 0.005674885120242834, Neurons: 64, Grad norm: 1.004e+00\n",
      "Epoch 14050, Loss: 0.0056789037771523, Neurons: 64, Grad norm: 1.173e+00\n",
      "Epoch 14050, Loss: 0.0056789037771523, Neurons: 64, Grad norm: 1.173e+00\n",
      "Epoch 14051, Loss: 0.005684684030711651, Neurons: 64, Grad norm: 1.353e+00\n",
      "Epoch 14051, Loss: 0.005684684030711651, Neurons: 64, Grad norm: 1.353e+00\n",
      "Epoch 14052, Loss: 0.005692883860319853, Neurons: 64, Grad norm: 1.585e+00\n",
      "Epoch 14052, Loss: 0.005692883860319853, Neurons: 64, Grad norm: 1.585e+00\n",
      "Epoch 14053, Loss: 0.0057045393623411655, Neurons: 64, Grad norm: 1.847e+00\n",
      "Epoch 14053, Loss: 0.0057045393623411655, Neurons: 64, Grad norm: 1.847e+00\n",
      "Epoch 14054, Loss: 0.00572138000279665, Neurons: 64, Grad norm: 2.175e+00\n",
      "Epoch 14054, Loss: 0.00572138000279665, Neurons: 64, Grad norm: 2.175e+00\n",
      "Epoch 14055, Loss: 0.005744678899645805, Neurons: 64, Grad norm: 2.543e+00\n",
      "Epoch 14055, Loss: 0.005744678899645805, Neurons: 64, Grad norm: 2.543e+00\n",
      "Epoch 14056, Loss: 0.005777512211352587, Neurons: 64, Grad norm: 2.994e+00\n",
      "Epoch 14056, Loss: 0.005777512211352587, Neurons: 64, Grad norm: 2.994e+00\n",
      "Epoch 14057, Loss: 0.005822016857564449, Neurons: 64, Grad norm: 3.497e+00\n",
      "Epoch 14057, Loss: 0.005822016857564449, Neurons: 64, Grad norm: 3.497e+00\n",
      "Epoch 14058, Loss: 0.005882875062525272, Neurons: 64, Grad norm: 4.089e+00\n",
      "Epoch 14058, Loss: 0.005882875062525272, Neurons: 64, Grad norm: 4.089e+00\n",
      "Epoch 14059, Loss: 0.0059617687948048115, Neurons: 64, Grad norm: 4.729e+00\n",
      "Epoch 14059, Loss: 0.0059617687948048115, Neurons: 64, Grad norm: 4.729e+00\n",
      "Epoch 14060, Loss: 0.006062340922653675, Neurons: 64, Grad norm: 5.422e+00\n",
      "Epoch 14060, Loss: 0.006062340922653675, Neurons: 64, Grad norm: 5.422e+00\n",
      "Epoch 14061, Loss: 0.006180081516504288, Neurons: 64, Grad norm: 6.096e+00\n",
      "Epoch 14061, Loss: 0.006180081516504288, Neurons: 64, Grad norm: 6.096e+00\n",
      "Epoch 14062, Loss: 0.006308391690254211, Neurons: 64, Grad norm: 6.714e+00\n",
      "Epoch 14062, Loss: 0.006308391690254211, Neurons: 64, Grad norm: 6.714e+00\n",
      "Epoch 14063, Loss: 0.006424420513212681, Neurons: 64, Grad norm: 7.148e+00\n",
      "Epoch 14063, Loss: 0.006424420513212681, Neurons: 64, Grad norm: 7.148e+00\n",
      "Epoch 14064, Loss: 0.006503224838525057, Neurons: 64, Grad norm: 7.331e+00\n",
      "Epoch 14064, Loss: 0.006503224838525057, Neurons: 64, Grad norm: 7.331e+00\n",
      "Epoch 14065, Loss: 0.0065130689181387424, Neurons: 64, Grad norm: 7.154e+00\n",
      "Epoch 14065, Loss: 0.0065130689181387424, Neurons: 64, Grad norm: 7.154e+00\n",
      "Epoch 14066, Loss: 0.006444885395467281, Neurons: 64, Grad norm: 6.618e+00\n",
      "Epoch 14066, Loss: 0.006444885395467281, Neurons: 64, Grad norm: 6.618e+00\n",
      "Epoch 14067, Loss: 0.006311745382845402, Neurons: 64, Grad norm: 5.741e+00\n",
      "Epoch 14067, Loss: 0.006311745382845402, Neurons: 64, Grad norm: 5.741e+00\n",
      "Epoch 14068, Loss: 0.0061633046716451645, Neurons: 64, Grad norm: 4.707e+00\n",
      "Epoch 14068, Loss: 0.0061633046716451645, Neurons: 64, Grad norm: 4.707e+00\n",
      "Epoch 14069, Loss: 0.006055389530956745, Neurons: 64, Grad norm: 3.707e+00\n",
      "Epoch 14069, Loss: 0.006055389530956745, Neurons: 64, Grad norm: 3.707e+00\n",
      "Epoch 14070, Loss: 0.006024938076734543, Neurons: 64, Grad norm: 3.031e+00\n",
      "Epoch 14070, Loss: 0.006024938076734543, Neurons: 64, Grad norm: 3.031e+00\n",
      "Epoch 14071, Loss: 0.006064513698220253, Neurons: 64, Grad norm: 2.747e+00\n",
      "Epoch 14071, Loss: 0.006064513698220253, Neurons: 64, Grad norm: 2.747e+00\n",
      "Epoch 14072, Loss: 0.006120012607425451, Neurons: 64, Grad norm: 2.669e+00\n",
      "Epoch 14072, Loss: 0.006120012607425451, Neurons: 64, Grad norm: 2.669e+00\n",
      "Epoch 14073, Loss: 0.006118420977145433, Neurons: 64, Grad norm: 2.459e+00\n",
      "Epoch 14073, Loss: 0.006118420977145433, Neurons: 64, Grad norm: 2.459e+00\n",
      "Epoch 14074, Loss: 0.006014546845108271, Neurons: 64, Grad norm: 1.986e+00\n",
      "Epoch 14074, Loss: 0.006014546845108271, Neurons: 64, Grad norm: 1.986e+00\n",
      "Epoch 14075, Loss: 0.005842593498528004, Neurons: 64, Grad norm: 1.354e+00\n",
      "Epoch 14075, Loss: 0.005842593498528004, Neurons: 64, Grad norm: 1.354e+00\n",
      "Epoch 14076, Loss: 0.005694746505469084, Neurons: 64, Grad norm: 9.748e-01\n",
      "Epoch 14076, Loss: 0.005694746505469084, Neurons: 64, Grad norm: 9.748e-01\n",
      "Epoch 14077, Loss: 0.005650779232382774, Neurons: 64, Grad norm: 1.283e+00\n",
      "Epoch 14077, Loss: 0.005650779232382774, Neurons: 64, Grad norm: 1.283e+00\n",
      "Epoch 14078, Loss: 0.005714231636375189, Neurons: 64, Grad norm: 1.729e+00\n",
      "Epoch 14078, Loss: 0.005714231636375189, Neurons: 64, Grad norm: 1.729e+00\n",
      "Epoch 14079, Loss: 0.005817587487399578, Neurons: 64, Grad norm: 1.957e+00\n",
      "Epoch 14079, Loss: 0.005817587487399578, Neurons: 64, Grad norm: 1.957e+00\n",
      "Epoch 14080, Loss: 0.005876433104276657, Neurons: 64, Grad norm: 1.846e+00\n",
      "Epoch 14080, Loss: 0.005876433104276657, Neurons: 64, Grad norm: 1.846e+00\n",
      "Epoch 14081, Loss: 0.005847366526722908, Neurons: 64, Grad norm: 1.473e+00\n",
      "Epoch 14081, Loss: 0.005847366526722908, Neurons: 64, Grad norm: 1.473e+00\n",
      "Epoch 14082, Loss: 0.005754681304097176, Neurons: 64, Grad norm: 1.018e+00\n",
      "Epoch 14082, Loss: 0.005754681304097176, Neurons: 64, Grad norm: 1.018e+00\n",
      "Epoch 14083, Loss: 0.005667777266353369, Neurons: 64, Grad norm: 9.018e-01\n",
      "Epoch 14083, Loss: 0.005667777266353369, Neurons: 64, Grad norm: 9.018e-01\n",
      "Epoch 14084, Loss: 0.005640738178044558, Neurons: 64, Grad norm: 1.139e+00\n",
      "Epoch 14084, Loss: 0.005640738178044558, Neurons: 64, Grad norm: 1.139e+00\n",
      "Epoch 14085, Loss: 0.005671840161085129, Neurons: 64, Grad norm: 1.347e+00\n",
      "Epoch 14085, Loss: 0.005671840161085129, Neurons: 64, Grad norm: 1.347e+00\n",
      "Epoch 14086, Loss: 0.0057160742580890656, Neurons: 64, Grad norm: 1.321e+00\n",
      "Epoch 14086, Loss: 0.0057160742580890656, Neurons: 64, Grad norm: 1.321e+00\n",
      "Epoch 14087, Loss: 0.005728776101022959, Neurons: 64, Grad norm: 1.064e+00\n",
      "Epoch 14087, Loss: 0.005728776101022959, Neurons: 64, Grad norm: 1.064e+00\n",
      "Epoch 14088, Loss: 0.005699919071048498, Neurons: 64, Grad norm: 7.320e-01\n",
      "Epoch 14088, Loss: 0.005699919071048498, Neurons: 64, Grad norm: 7.320e-01\n",
      "Epoch 14089, Loss: 0.005656273569911718, Neurons: 64, Grad norm: 7.041e-01\n",
      "Epoch 14089, Loss: 0.005656273569911718, Neurons: 64, Grad norm: 7.041e-01\n",
      "Epoch 14090, Loss: 0.0056327590718865395, Neurons: 64, Grad norm: 1.052e+00\n",
      "Epoch 14090, Loss: 0.0056327590718865395, Neurons: 64, Grad norm: 1.052e+00\n",
      "Epoch 14091, Loss: 0.005642186850309372, Neurons: 64, Grad norm: 1.356e+00\n",
      "Epoch 14091, Loss: 0.005642186850309372, Neurons: 64, Grad norm: 1.356e+00\n",
      "Epoch 14092, Loss: 0.005667907185852528, Neurons: 64, Grad norm: 1.474e+00\n",
      "Epoch 14092, Loss: 0.005667907185852528, Neurons: 64, Grad norm: 1.474e+00\n",
      "Epoch 14093, Loss: 0.005683104507625103, Neurons: 64, Grad norm: 1.340e+00\n",
      "Epoch 14093, Loss: 0.005683104507625103, Neurons: 64, Grad norm: 1.340e+00\n",
      "Epoch 14094, Loss: 0.005673709325492382, Neurons: 64, Grad norm: 1.019e+00\n",
      "Epoch 14094, Loss: 0.005673709325492382, Neurons: 64, Grad norm: 1.019e+00\n",
      "Epoch 14095, Loss: 0.005647654179483652, Neurons: 64, Grad norm: 5.779e-01\n",
      "Epoch 14095, Loss: 0.005647654179483652, Neurons: 64, Grad norm: 5.779e-01\n",
      "Epoch 14096, Loss: 0.005624637007713318, Neurons: 64, Grad norm: 2.422e-01\n",
      "Epoch 14096, Loss: 0.005624637007713318, Neurons: 64, Grad norm: 2.422e-01\n",
      "Epoch 14097, Loss: 0.005618595518171787, Neurons: 64, Grad norm: 4.364e-01\n",
      "Epoch 14097, Loss: 0.005618595518171787, Neurons: 64, Grad norm: 4.364e-01\n",
      "Epoch 14098, Loss: 0.0056277671828866005, Neurons: 64, Grad norm: 6.872e-01\n",
      "Epoch 14098, Loss: 0.0056277671828866005, Neurons: 64, Grad norm: 6.872e-01\n",
      "Epoch 14099, Loss: 0.005639340728521347, Neurons: 64, Grad norm: 7.950e-01\n",
      "Epoch 14099, Loss: 0.005639340728521347, Neurons: 64, Grad norm: 7.950e-01\n",
      "Epoch 14099, Test loss: 0.004689150955528021\n",
      "Epoch 14099, Test loss: 0.004689150955528021\n",
      "Epoch 14100, Loss: 0.005641759838908911, Neurons: 64, Grad norm: 7.451e-01\n",
      "Epoch 14100, Loss: 0.005641759838908911, Neurons: 64, Grad norm: 7.451e-01\n",
      "Epoch 14101, Loss: 0.005633321590721607, Neurons: 64, Grad norm: 6.116e-01\n",
      "Epoch 14101, Loss: 0.005633321590721607, Neurons: 64, Grad norm: 6.116e-01\n",
      "Epoch 14102, Loss: 0.005621395539492369, Neurons: 64, Grad norm: 4.669e-01\n",
      "Epoch 14102, Loss: 0.005621395539492369, Neurons: 64, Grad norm: 4.669e-01\n",
      "Epoch 14103, Loss: 0.005614798050373793, Neurons: 64, Grad norm: 4.444e-01\n",
      "Epoch 14103, Loss: 0.005614798050373793, Neurons: 64, Grad norm: 4.444e-01\n",
      "Epoch 14104, Loss: 0.0056164381094276905, Neurons: 64, Grad norm: 4.933e-01\n",
      "Epoch 14104, Loss: 0.0056164381094276905, Neurons: 64, Grad norm: 4.933e-01\n",
      "Epoch 14105, Loss: 0.005622303579002619, Neurons: 64, Grad norm: 5.388e-01\n",
      "Epoch 14105, Loss: 0.005622303579002619, Neurons: 64, Grad norm: 5.388e-01\n",
      "Epoch 14106, Loss: 0.0056257834658026695, Neurons: 64, Grad norm: 5.016e-01\n",
      "Epoch 14106, Loss: 0.0056257834658026695, Neurons: 64, Grad norm: 5.016e-01\n",
      "Epoch 14107, Loss: 0.005623288918286562, Neurons: 64, Grad norm: 4.121e-01\n",
      "Epoch 14107, Loss: 0.005623288918286562, Neurons: 64, Grad norm: 4.121e-01\n",
      "Epoch 14108, Loss: 0.005616307724267244, Neurons: 64, Grad norm: 2.874e-01\n",
      "Epoch 14108, Loss: 0.005616307724267244, Neurons: 64, Grad norm: 2.874e-01\n",
      "Epoch 14109, Loss: 0.005609373562037945, Neurons: 64, Grad norm: 2.493e-01\n",
      "Epoch 14109, Loss: 0.005609373562037945, Neurons: 64, Grad norm: 2.493e-01\n",
      "Epoch 14110, Loss: 0.005606121849268675, Neurons: 64, Grad norm: 2.972e-01\n",
      "Epoch 14110, Loss: 0.005606121849268675, Neurons: 64, Grad norm: 2.972e-01\n",
      "Epoch 14111, Loss: 0.00560687156394124, Neurons: 64, Grad norm: 3.630e-01\n",
      "Epoch 14111, Loss: 0.00560687156394124, Neurons: 64, Grad norm: 3.630e-01\n",
      "Epoch 14112, Loss: 0.005609086249023676, Neurons: 64, Grad norm: 3.689e-01\n",
      "Epoch 14112, Loss: 0.005609086249023676, Neurons: 64, Grad norm: 3.689e-01\n",
      "Epoch 14113, Loss: 0.005609672982245684, Neurons: 64, Grad norm: 3.169e-01\n",
      "Epoch 14113, Loss: 0.005609672982245684, Neurons: 64, Grad norm: 3.169e-01\n",
      "Epoch 14114, Loss: 0.005607605446130037, Neurons: 64, Grad norm: 2.187e-01\n",
      "Epoch 14114, Loss: 0.005607605446130037, Neurons: 64, Grad norm: 2.187e-01\n",
      "Epoch 14115, Loss: 0.005603902507573366, Neurons: 64, Grad norm: 1.297e-01\n",
      "Epoch 14115, Loss: 0.005603902507573366, Neurons: 64, Grad norm: 1.297e-01\n",
      "Epoch 14116, Loss: 0.005600760690867901, Neurons: 64, Grad norm: 1.845e-01\n",
      "Epoch 14116, Loss: 0.005600760690867901, Neurons: 64, Grad norm: 1.845e-01\n",
      "Epoch 14117, Loss: 0.005599522031843662, Neurons: 64, Grad norm: 2.820e-01\n",
      "Epoch 14117, Loss: 0.005599522031843662, Neurons: 64, Grad norm: 2.820e-01\n",
      "Epoch 14118, Loss: 0.0055999308824539185, Neurons: 64, Grad norm: 3.699e-01\n",
      "Epoch 14118, Loss: 0.0055999308824539185, Neurons: 64, Grad norm: 3.699e-01\n",
      "Epoch 14119, Loss: 0.005600850097835064, Neurons: 64, Grad norm: 4.030e-01\n",
      "Epoch 14119, Loss: 0.005600850097835064, Neurons: 64, Grad norm: 4.030e-01\n",
      "Epoch 14120, Loss: 0.005600881762802601, Neurons: 64, Grad norm: 4.057e-01\n",
      "Epoch 14120, Loss: 0.005600881762802601, Neurons: 64, Grad norm: 4.057e-01\n",
      "Epoch 14121, Loss: 0.005599676165729761, Neurons: 64, Grad norm: 3.569e-01\n",
      "Epoch 14121, Loss: 0.005599676165729761, Neurons: 64, Grad norm: 3.569e-01\n",
      "Epoch 14122, Loss: 0.005597463343292475, Neurons: 64, Grad norm: 3.064e-01\n",
      "Epoch 14122, Loss: 0.005597463343292475, Neurons: 64, Grad norm: 3.064e-01\n",
      "Epoch 14123, Loss: 0.005595250520855188, Neurons: 64, Grad norm: 2.468e-01\n",
      "Epoch 14123, Loss: 0.005595250520855188, Neurons: 64, Grad norm: 2.468e-01\n",
      "Epoch 14124, Loss: 0.005593813024461269, Neurons: 64, Grad norm: 2.329e-01\n",
      "Epoch 14124, Loss: 0.005593813024461269, Neurons: 64, Grad norm: 2.329e-01\n",
      "Epoch 14125, Loss: 0.005593201145529747, Neurons: 64, Grad norm: 2.244e-01\n",
      "Epoch 14125, Loss: 0.005593201145529747, Neurons: 64, Grad norm: 2.244e-01\n",
      "Epoch 14126, Loss: 0.005593022797256708, Neurons: 64, Grad norm: 2.332e-01\n",
      "Epoch 14126, Loss: 0.005593022797256708, Neurons: 64, Grad norm: 2.332e-01\n",
      "Epoch 14127, Loss: 0.0055925799533724785, Neurons: 64, Grad norm: 2.166e-01\n",
      "Epoch 14127, Loss: 0.0055925799533724785, Neurons: 64, Grad norm: 2.166e-01\n",
      "Epoch 14128, Loss: 0.0055915359407663345, Neurons: 64, Grad norm: 2.079e-01\n",
      "Epoch 14128, Loss: 0.0055915359407663345, Neurons: 64, Grad norm: 2.079e-01\n",
      "Epoch 14129, Loss: 0.005590109154582024, Neurons: 64, Grad norm: 1.827e-01\n",
      "Epoch 14129, Loss: 0.005590109154582024, Neurons: 64, Grad norm: 1.827e-01\n",
      "Epoch 14130, Loss: 0.005588557571172714, Neurons: 64, Grad norm: 1.925e-01\n",
      "Epoch 14130, Loss: 0.005588557571172714, Neurons: 64, Grad norm: 1.925e-01\n",
      "Epoch 14131, Loss: 0.005587264895439148, Neurons: 64, Grad norm: 2.019e-01\n",
      "Epoch 14131, Loss: 0.005587264895439148, Neurons: 64, Grad norm: 2.019e-01\n",
      "Epoch 14132, Loss: 0.0055863880552351475, Neurons: 64, Grad norm: 2.360e-01\n",
      "Epoch 14132, Loss: 0.0055863880552351475, Neurons: 64, Grad norm: 2.360e-01\n",
      "Epoch 14133, Loss: 0.005585863254964352, Neurons: 64, Grad norm: 2.517e-01\n",
      "Epoch 14133, Loss: 0.005585863254964352, Neurons: 64, Grad norm: 2.517e-01\n",
      "Epoch 14134, Loss: 0.005585296545177698, Neurons: 64, Grad norm: 2.694e-01\n",
      "Epoch 14134, Loss: 0.005585296545177698, Neurons: 64, Grad norm: 2.694e-01\n",
      "Epoch 14135, Loss: 0.005584506783634424, Neurons: 64, Grad norm: 2.594e-01\n",
      "Epoch 14135, Loss: 0.005584506783634424, Neurons: 64, Grad norm: 2.594e-01\n",
      "Epoch 14136, Loss: 0.005583599675446749, Neurons: 64, Grad norm: 2.557e-01\n",
      "Epoch 14136, Loss: 0.005583599675446749, Neurons: 64, Grad norm: 2.557e-01\n",
      "Epoch 14137, Loss: 0.005582441575825214, Neurons: 64, Grad norm: 2.328e-01\n",
      "Epoch 14137, Loss: 0.005582441575825214, Neurons: 64, Grad norm: 2.328e-01\n",
      "Epoch 14138, Loss: 0.005581349600106478, Neurons: 64, Grad norm: 2.337e-01\n",
      "Epoch 14138, Loss: 0.005581349600106478, Neurons: 64, Grad norm: 2.337e-01\n",
      "Epoch 14139, Loss: 0.005580416880548, Neurons: 64, Grad norm: 2.294e-01\n",
      "Epoch 14139, Loss: 0.005580416880548, Neurons: 64, Grad norm: 2.294e-01\n",
      "Epoch 14140, Loss: 0.005579682532697916, Neurons: 64, Grad norm: 2.532e-01\n",
      "Epoch 14140, Loss: 0.005579682532697916, Neurons: 64, Grad norm: 2.532e-01\n",
      "Epoch 14141, Loss: 0.005579100921750069, Neurons: 64, Grad norm: 2.604e-01\n",
      "Epoch 14141, Loss: 0.005579100921750069, Neurons: 64, Grad norm: 2.604e-01\n",
      "Epoch 14142, Loss: 0.005578567739576101, Neurons: 64, Grad norm: 2.927e-01\n",
      "Epoch 14142, Loss: 0.005578567739576101, Neurons: 64, Grad norm: 2.927e-01\n",
      "Epoch 14143, Loss: 0.0055779945105314255, Neurons: 64, Grad norm: 3.152e-01\n",
      "Epoch 14143, Loss: 0.0055779945105314255, Neurons: 64, Grad norm: 3.152e-01\n",
      "Epoch 14144, Loss: 0.005577404517680407, Neurons: 64, Grad norm: 3.633e-01\n",
      "Epoch 14144, Loss: 0.005577404517680407, Neurons: 64, Grad norm: 3.633e-01\n",
      "Epoch 14145, Loss: 0.00557686435058713, Neurons: 64, Grad norm: 4.030e-01\n",
      "Epoch 14145, Loss: 0.00557686435058713, Neurons: 64, Grad norm: 4.030e-01\n",
      "Epoch 14146, Loss: 0.005576420109719038, Neurons: 64, Grad norm: 4.742e-01\n",
      "Epoch 14146, Loss: 0.005576420109719038, Neurons: 64, Grad norm: 4.742e-01\n",
      "Epoch 14147, Loss: 0.005576225463300943, Neurons: 64, Grad norm: 5.398e-01\n",
      "Epoch 14147, Loss: 0.005576225463300943, Neurons: 64, Grad norm: 5.398e-01\n",
      "Epoch 14148, Loss: 0.0055763390846550465, Neurons: 64, Grad norm: 6.340e-01\n",
      "Epoch 14148, Loss: 0.0055763390846550465, Neurons: 64, Grad norm: 6.340e-01\n",
      "Epoch 14149, Loss: 0.005576868541538715, Neurons: 64, Grad norm: 7.237e-01\n",
      "Epoch 14149, Loss: 0.005576868541538715, Neurons: 64, Grad norm: 7.237e-01\n",
      "Epoch 14150, Loss: 0.005577958654612303, Neurons: 64, Grad norm: 8.474e-01\n",
      "Epoch 14150, Loss: 0.005577958654612303, Neurons: 64, Grad norm: 8.474e-01\n",
      "Epoch 14151, Loss: 0.005579827353358269, Neurons: 64, Grad norm: 9.685e-01\n",
      "Epoch 14151, Loss: 0.005579827353358269, Neurons: 64, Grad norm: 9.685e-01\n",
      "Epoch 14152, Loss: 0.005582664627581835, Neurons: 64, Grad norm: 1.131e+00\n",
      "Epoch 14152, Loss: 0.005582664627581835, Neurons: 64, Grad norm: 1.131e+00\n",
      "Epoch 14153, Loss: 0.005586766637861729, Neurons: 64, Grad norm: 1.301e+00\n",
      "Epoch 14153, Loss: 0.005586766637861729, Neurons: 64, Grad norm: 1.301e+00\n",
      "Epoch 14154, Loss: 0.005592865403741598, Neurons: 64, Grad norm: 1.526e+00\n",
      "Epoch 14154, Loss: 0.005592865403741598, Neurons: 64, Grad norm: 1.526e+00\n",
      "Epoch 14155, Loss: 0.005601874552667141, Neurons: 64, Grad norm: 1.784e+00\n",
      "Epoch 14155, Loss: 0.005601874552667141, Neurons: 64, Grad norm: 1.784e+00\n",
      "Epoch 14156, Loss: 0.005615281406790018, Neurons: 64, Grad norm: 2.116e+00\n",
      "Epoch 14156, Loss: 0.005615281406790018, Neurons: 64, Grad norm: 2.116e+00\n",
      "Epoch 14157, Loss: 0.005634884350001812, Neurons: 64, Grad norm: 2.496e+00\n",
      "Epoch 14157, Loss: 0.005634884350001812, Neurons: 64, Grad norm: 2.496e+00\n",
      "Epoch 14158, Loss: 0.005663361866027117, Neurons: 64, Grad norm: 2.977e+00\n",
      "Epoch 14158, Loss: 0.005663361866027117, Neurons: 64, Grad norm: 2.977e+00\n",
      "Epoch 14159, Loss: 0.005704513750970364, Neurons: 64, Grad norm: 3.534e+00\n",
      "Epoch 14159, Loss: 0.005704513750970364, Neurons: 64, Grad norm: 3.534e+00\n",
      "Epoch 14160, Loss: 0.005763196852058172, Neurons: 64, Grad norm: 4.212e+00\n",
      "Epoch 14160, Loss: 0.005763196852058172, Neurons: 64, Grad norm: 4.212e+00\n",
      "Epoch 14161, Loss: 0.0058454107493162155, Neurons: 64, Grad norm: 4.975e+00\n",
      "Epoch 14161, Loss: 0.0058454107493162155, Neurons: 64, Grad norm: 4.975e+00\n",
      "Epoch 14162, Loss: 0.005957969930022955, Neurons: 64, Grad norm: 5.852e+00\n",
      "Epoch 14162, Loss: 0.005957969930022955, Neurons: 64, Grad norm: 5.852e+00\n",
      "Epoch 14163, Loss: 0.0061068106442689896, Neurons: 64, Grad norm: 6.776e+00\n",
      "Epoch 14163, Loss: 0.0061068106442689896, Neurons: 64, Grad norm: 6.776e+00\n",
      "Epoch 14164, Loss: 0.006292513106018305, Neurons: 64, Grad norm: 7.707e+00\n",
      "Epoch 14164, Loss: 0.006292513106018305, Neurons: 64, Grad norm: 7.707e+00\n",
      "Epoch 14165, Loss: 0.006501215510070324, Neurons: 64, Grad norm: 8.488e+00\n",
      "Epoch 14165, Loss: 0.006501215510070324, Neurons: 64, Grad norm: 8.488e+00\n",
      "Epoch 14166, Loss: 0.006699927616864443, Neurons: 64, Grad norm: 8.976e+00\n",
      "Epoch 14166, Loss: 0.006699927616864443, Neurons: 64, Grad norm: 8.976e+00\n",
      "Epoch 14167, Loss: 0.006827010773122311, Neurons: 64, Grad norm: 8.933e+00\n",
      "Epoch 14167, Loss: 0.006827010773122311, Neurons: 64, Grad norm: 8.933e+00\n",
      "Epoch 14168, Loss: 0.006813574116677046, Neurons: 64, Grad norm: 8.220e+00\n",
      "Epoch 14168, Loss: 0.006813574116677046, Neurons: 64, Grad norm: 8.220e+00\n",
      "Epoch 14169, Loss: 0.00661434093490243, Neurons: 64, Grad norm: 6.750e+00\n",
      "Epoch 14169, Loss: 0.00661434093490243, Neurons: 64, Grad norm: 6.750e+00\n",
      "Epoch 14170, Loss: 0.006267119664698839, Neurons: 64, Grad norm: 4.659e+00\n",
      "Epoch 14170, Loss: 0.006267119664698839, Neurons: 64, Grad norm: 4.659e+00\n",
      "Epoch 14171, Loss: 0.005889113526791334, Neurons: 64, Grad norm: 2.174e+00\n",
      "Epoch 14171, Loss: 0.005889113526791334, Neurons: 64, Grad norm: 2.174e+00\n",
      "Epoch 14172, Loss: 0.005623998586088419, Neurons: 64, Grad norm: 3.292e-01\n",
      "Epoch 14172, Loss: 0.005623998586088419, Neurons: 64, Grad norm: 3.292e-01\n",
      "Epoch 14173, Loss: 0.005551868584007025, Neurons: 64, Grad norm: 2.546e+00\n",
      "Epoch 14173, Loss: 0.005551868584007025, Neurons: 64, Grad norm: 2.546e+00\n",
      "Epoch 14174, Loss: 0.005651811137795448, Neurons: 64, Grad norm: 4.211e+00\n",
      "Epoch 14174, Loss: 0.005651811137795448, Neurons: 64, Grad norm: 4.211e+00\n",
      "Epoch 14175, Loss: 0.005828611087054014, Neurons: 64, Grad norm: 5.187e+00\n",
      "Epoch 14175, Loss: 0.005828611087054014, Neurons: 64, Grad norm: 5.187e+00\n",
      "Epoch 14176, Loss: 0.005969240330159664, Neurons: 64, Grad norm: 5.354e+00\n",
      "Epoch 14176, Loss: 0.005969240330159664, Neurons: 64, Grad norm: 5.354e+00\n",
      "Epoch 14177, Loss: 0.005996576510369778, Neurons: 64, Grad norm: 4.768e+00\n",
      "Epoch 14177, Loss: 0.005996576510369778, Neurons: 64, Grad norm: 4.768e+00\n",
      "Epoch 14178, Loss: 0.005900617688894272, Neurons: 64, Grad norm: 3.527e+00\n",
      "Epoch 14178, Loss: 0.005900617688894272, Neurons: 64, Grad norm: 3.527e+00\n",
      "Epoch 14179, Loss: 0.005739323794841766, Neurons: 64, Grad norm: 1.893e+00\n",
      "Epoch 14179, Loss: 0.005739323794841766, Neurons: 64, Grad norm: 1.893e+00\n",
      "Epoch 14180, Loss: 0.005599248223006725, Neurons: 64, Grad norm: 1.186e-01\n",
      "Epoch 14180, Loss: 0.005599248223006725, Neurons: 64, Grad norm: 1.186e-01\n",
      "Epoch 14181, Loss: 0.005543101578950882, Neurons: 64, Grad norm: 1.482e+00\n",
      "Epoch 14181, Loss: 0.005543101578950882, Neurons: 64, Grad norm: 1.482e+00\n",
      "Epoch 14182, Loss: 0.00557688856497407, Neurons: 64, Grad norm: 2.720e+00\n",
      "Epoch 14182, Loss: 0.00557688856497407, Neurons: 64, Grad norm: 2.720e+00\n",
      "Epoch 14183, Loss: 0.00565697718411684, Neurons: 64, Grad norm: 3.417e+00\n",
      "Epoch 14183, Loss: 0.00565697718411684, Neurons: 64, Grad norm: 3.417e+00\n",
      "Epoch 14184, Loss: 0.0057236491702497005, Neurons: 64, Grad norm: 3.549e+00\n",
      "Epoch 14184, Loss: 0.0057236491702497005, Neurons: 64, Grad norm: 3.549e+00\n",
      "Epoch 14185, Loss: 0.005736037623137236, Neurons: 64, Grad norm: 3.114e+00\n",
      "Epoch 14185, Loss: 0.005736037623137236, Neurons: 64, Grad norm: 3.114e+00\n",
      "Epoch 14186, Loss: 0.005690712947398424, Neurons: 64, Grad norm: 2.259e+00\n",
      "Epoch 14186, Loss: 0.005690712947398424, Neurons: 64, Grad norm: 2.259e+00\n",
      "Epoch 14187, Loss: 0.005617343820631504, Neurons: 64, Grad norm: 1.126e+00\n",
      "Epoch 14187, Loss: 0.005617343820631504, Neurons: 64, Grad norm: 1.126e+00\n",
      "Epoch 14188, Loss: 0.005556939169764519, Neurons: 64, Grad norm: 4.796e-02\n",
      "Epoch 14188, Loss: 0.005556939169764519, Neurons: 64, Grad norm: 4.796e-02\n",
      "Epoch 14189, Loss: 0.005536036565899849, Neurons: 64, Grad norm: 1.116e+00\n",
      "Epoch 14189, Loss: 0.005536036565899849, Neurons: 64, Grad norm: 1.116e+00\n",
      "Epoch 14190, Loss: 0.005554459989070892, Neurons: 64, Grad norm: 1.896e+00\n",
      "Epoch 14190, Loss: 0.005554459989070892, Neurons: 64, Grad norm: 1.896e+00\n",
      "Epoch 14191, Loss: 0.005591006018221378, Neurons: 64, Grad norm: 2.334e+00\n",
      "Epoch 14191, Loss: 0.005591006018221378, Neurons: 64, Grad norm: 2.334e+00\n",
      "Epoch 14192, Loss: 0.005618812050670385, Neurons: 64, Grad norm: 2.367e+00\n",
      "Epoch 14192, Loss: 0.005618812050670385, Neurons: 64, Grad norm: 2.367e+00\n",
      "Epoch 14193, Loss: 0.005621182732284069, Neurons: 64, Grad norm: 2.062e+00\n",
      "Epoch 14193, Loss: 0.005621182732284069, Neurons: 64, Grad norm: 2.062e+00\n",
      "Epoch 14194, Loss: 0.005598713178187609, Neurons: 64, Grad norm: 1.468e+00\n",
      "Epoch 14194, Loss: 0.005598713178187609, Neurons: 64, Grad norm: 1.468e+00\n",
      "Epoch 14195, Loss: 0.005565405357629061, Neurons: 64, Grad norm: 7.363e-01\n",
      "Epoch 14195, Loss: 0.005565405357629061, Neurons: 64, Grad norm: 7.363e-01\n",
      "Epoch 14196, Loss: 0.005538718309253454, Neurons: 64, Grad norm: 5.278e-02\n",
      "Epoch 14196, Loss: 0.005538718309253454, Neurons: 64, Grad norm: 5.278e-02\n",
      "Epoch 14197, Loss: 0.005529196001589298, Neurons: 64, Grad norm: 7.254e-01\n",
      "Epoch 14197, Loss: 0.005529196001589298, Neurons: 64, Grad norm: 7.254e-01\n",
      "Epoch 14198, Loss: 0.005536578595638275, Neurons: 64, Grad norm: 1.256e+00\n",
      "Epoch 14198, Loss: 0.005536578595638275, Neurons: 64, Grad norm: 1.256e+00\n",
      "Epoch 14199, Loss: 0.005551911890506744, Neurons: 64, Grad norm: 1.542e+00\n",
      "Epoch 14199, Loss: 0.005551911890506744, Neurons: 64, Grad norm: 1.542e+00\n",
      "Epoch 14199, Test loss: 0.004552413243800402\n",
      "Epoch 14199, Test loss: 0.004552413243800402\n",
      "Epoch 14200, Loss: 0.005564132705330849, Neurons: 64, Grad norm: 1.602e+00\n",
      "Epoch 14200, Loss: 0.005564132705330849, Neurons: 64, Grad norm: 1.602e+00\n",
      "Epoch 14201, Loss: 0.005566072650253773, Neurons: 64, Grad norm: 1.418e+00\n",
      "Epoch 14201, Loss: 0.005566072650253773, Neurons: 64, Grad norm: 1.418e+00\n",
      "Epoch 14202, Loss: 0.005557102616876364, Neurons: 64, Grad norm: 1.079e+00\n",
      "Epoch 14202, Loss: 0.005557102616876364, Neurons: 64, Grad norm: 1.079e+00\n",
      "Epoch 14203, Loss: 0.005542546510696411, Neurons: 64, Grad norm: 6.107e-01\n",
      "Epoch 14203, Loss: 0.005542546510696411, Neurons: 64, Grad norm: 6.107e-01\n",
      "Epoch 14204, Loss: 0.005529377143830061, Neurons: 64, Grad norm: 1.268e-01\n",
      "Epoch 14204, Loss: 0.005529377143830061, Neurons: 64, Grad norm: 1.268e-01\n",
      "Epoch 14205, Loss: 0.005522588733583689, Neurons: 64, Grad norm: 3.478e-01\n",
      "Epoch 14205, Loss: 0.005522588733583689, Neurons: 64, Grad norm: 3.478e-01\n",
      "Epoch 14206, Loss: 0.005523259285837412, Neurons: 64, Grad norm: 7.091e-01\n",
      "Epoch 14206, Loss: 0.005523259285837412, Neurons: 64, Grad norm: 7.091e-01\n",
      "Epoch 14207, Loss: 0.005528525914996862, Neurons: 64, Grad norm: 9.608e-01\n",
      "Epoch 14207, Loss: 0.005528525914996862, Neurons: 64, Grad norm: 9.608e-01\n",
      "Epoch 14208, Loss: 0.0055340989492833614, Neurons: 64, Grad norm: 1.047e+00\n",
      "Epoch 14208, Loss: 0.0055340989492833614, Neurons: 64, Grad norm: 1.047e+00\n",
      "Epoch 14209, Loss: 0.005536395590752363, Neurons: 64, Grad norm: 1.010e+00\n",
      "Epoch 14209, Loss: 0.005536395590752363, Neurons: 64, Grad norm: 1.010e+00\n",
      "Epoch 14210, Loss: 0.005534208845347166, Neurons: 64, Grad norm: 8.349e-01\n",
      "Epoch 14210, Loss: 0.005534208845347166, Neurons: 64, Grad norm: 8.349e-01\n",
      "Epoch 14211, Loss: 0.005528624635189772, Neurons: 64, Grad norm: 5.939e-01\n",
      "Epoch 14211, Loss: 0.005528624635189772, Neurons: 64, Grad norm: 5.939e-01\n",
      "Epoch 14212, Loss: 0.005522139836102724, Neurons: 64, Grad norm: 2.883e-01\n",
      "Epoch 14212, Loss: 0.005522139836102724, Neurons: 64, Grad norm: 2.883e-01\n",
      "Epoch 14213, Loss: 0.005517077632248402, Neurons: 64, Grad norm: 4.565e-02\n",
      "Epoch 14213, Loss: 0.005517077632248402, Neurons: 64, Grad norm: 4.565e-02\n",
      "Epoch 14214, Loss: 0.005514725111424923, Neurons: 64, Grad norm: 2.927e-01\n",
      "Epoch 14214, Loss: 0.005514725111424923, Neurons: 64, Grad norm: 2.927e-01\n",
      "Epoch 14215, Loss: 0.005514985881745815, Neurons: 64, Grad norm: 4.934e-01\n",
      "Epoch 14215, Loss: 0.005514985881745815, Neurons: 64, Grad norm: 4.934e-01\n",
      "Epoch 14216, Loss: 0.005516734439879656, Neurons: 64, Grad norm: 6.369e-01\n",
      "Epoch 14216, Loss: 0.005516734439879656, Neurons: 64, Grad norm: 6.369e-01\n",
      "Epoch 14217, Loss: 0.0055183288641273975, Neurons: 64, Grad norm: 6.807e-01\n",
      "Epoch 14217, Loss: 0.0055183288641273975, Neurons: 64, Grad norm: 6.807e-01\n",
      "Epoch 14218, Loss: 0.005518636200577021, Neurons: 64, Grad norm: 6.643e-01\n",
      "Epoch 14218, Loss: 0.005518636200577021, Neurons: 64, Grad norm: 6.643e-01\n",
      "Epoch 14219, Loss: 0.005517327226698399, Neurons: 64, Grad norm: 5.587e-01\n",
      "Epoch 14219, Loss: 0.005517327226698399, Neurons: 64, Grad norm: 5.587e-01\n",
      "Epoch 14220, Loss: 0.005514680873602629, Neurons: 64, Grad norm: 4.247e-01\n",
      "Epoch 14220, Loss: 0.005514680873602629, Neurons: 64, Grad norm: 4.247e-01\n",
      "Epoch 14221, Loss: 0.005511607974767685, Neurons: 64, Grad norm: 2.474e-01\n",
      "Epoch 14221, Loss: 0.005511607974767685, Neurons: 64, Grad norm: 2.474e-01\n",
      "Epoch 14222, Loss: 0.005508899223059416, Neurons: 64, Grad norm: 8.336e-02\n",
      "Epoch 14222, Loss: 0.005508899223059416, Neurons: 64, Grad norm: 8.336e-02\n",
      "Epoch 14223, Loss: 0.005507044494152069, Neurons: 64, Grad norm: 1.045e-01\n",
      "Epoch 14223, Loss: 0.005507044494152069, Neurons: 64, Grad norm: 1.045e-01\n",
      "Epoch 14224, Loss: 0.005506210494786501, Neurons: 64, Grad norm: 2.344e-01\n",
      "Epoch 14224, Loss: 0.005506210494786501, Neurons: 64, Grad norm: 2.344e-01\n",
      "Epoch 14225, Loss: 0.005506048910319805, Neurons: 64, Grad norm: 3.458e-01\n",
      "Epoch 14225, Loss: 0.005506048910319805, Neurons: 64, Grad norm: 3.458e-01\n",
      "Epoch 14226, Loss: 0.005506128538399935, Neurons: 64, Grad norm: 3.976e-01\n",
      "Epoch 14226, Loss: 0.005506128538399935, Neurons: 64, Grad norm: 3.976e-01\n",
      "Epoch 14227, Loss: 0.005506016314029694, Neurons: 64, Grad norm: 4.267e-01\n",
      "Epoch 14227, Loss: 0.005506016314029694, Neurons: 64, Grad norm: 4.267e-01\n",
      "Epoch 14228, Loss: 0.005505454260855913, Neurons: 64, Grad norm: 3.981e-01\n",
      "Epoch 14228, Loss: 0.005505454260855913, Neurons: 64, Grad norm: 3.981e-01\n",
      "Epoch 14229, Loss: 0.005504422355443239, Neurons: 64, Grad norm: 3.555e-01\n",
      "Epoch 14229, Loss: 0.005504422355443239, Neurons: 64, Grad norm: 3.555e-01\n",
      "Epoch 14230, Loss: 0.0055029685609042645, Neurons: 64, Grad norm: 2.671e-01\n",
      "Epoch 14230, Loss: 0.0055029685609042645, Neurons: 64, Grad norm: 2.671e-01\n",
      "Epoch 14231, Loss: 0.005501366686075926, Neurons: 64, Grad norm: 1.840e-01\n",
      "Epoch 14231, Loss: 0.005501366686075926, Neurons: 64, Grad norm: 1.840e-01\n",
      "Epoch 14232, Loss: 0.005499866791069508, Neurons: 64, Grad norm: 8.231e-02\n",
      "Epoch 14232, Loss: 0.005499866791069508, Neurons: 64, Grad norm: 8.231e-02\n",
      "Epoch 14233, Loss: 0.005498605314642191, Neurons: 64, Grad norm: 4.784e-02\n",
      "Epoch 14233, Loss: 0.005498605314642191, Neurons: 64, Grad norm: 4.784e-02\n",
      "Epoch 14234, Loss: 0.005497593432664871, Neurons: 64, Grad norm: 1.159e-01\n",
      "Epoch 14234, Loss: 0.005497593432664871, Neurons: 64, Grad norm: 1.159e-01\n",
      "Epoch 14235, Loss: 0.005496876314282417, Neurons: 64, Grad norm: 1.727e-01\n",
      "Epoch 14235, Loss: 0.005496876314282417, Neurons: 64, Grad norm: 1.727e-01\n",
      "Epoch 14236, Loss: 0.005496284458786249, Neurons: 64, Grad norm: 2.268e-01\n",
      "Epoch 14236, Loss: 0.005496284458786249, Neurons: 64, Grad norm: 2.268e-01\n",
      "Epoch 14237, Loss: 0.005495633464306593, Neurons: 64, Grad norm: 2.407e-01\n",
      "Epoch 14237, Loss: 0.005495633464306593, Neurons: 64, Grad norm: 2.407e-01\n",
      "Epoch 14238, Loss: 0.005495015531778336, Neurons: 64, Grad norm: 2.557e-01\n",
      "Epoch 14238, Loss: 0.005495015531778336, Neurons: 64, Grad norm: 2.557e-01\n",
      "Epoch 14239, Loss: 0.005494269542396069, Neurons: 64, Grad norm: 2.344e-01\n",
      "Epoch 14239, Loss: 0.005494269542396069, Neurons: 64, Grad norm: 2.344e-01\n",
      "Epoch 14240, Loss: 0.00549329025670886, Neurons: 64, Grad norm: 2.191e-01\n",
      "Epoch 14240, Loss: 0.00549329025670886, Neurons: 64, Grad norm: 2.191e-01\n",
      "Epoch 14241, Loss: 0.005492297001183033, Neurons: 64, Grad norm: 1.732e-01\n",
      "Epoch 14241, Loss: 0.005492297001183033, Neurons: 64, Grad norm: 1.732e-01\n",
      "Epoch 14242, Loss: 0.0054912269115448, Neurons: 64, Grad norm: 1.374e-01\n",
      "Epoch 14242, Loss: 0.0054912269115448, Neurons: 64, Grad norm: 1.374e-01\n",
      "Epoch 14243, Loss: 0.005490136332809925, Neurons: 64, Grad norm: 8.238e-02\n",
      "Epoch 14243, Loss: 0.005490136332809925, Neurons: 64, Grad norm: 8.238e-02\n",
      "Epoch 14244, Loss: 0.0054891216568648815, Neurons: 64, Grad norm: 4.693e-02\n",
      "Epoch 14244, Loss: 0.0054891216568648815, Neurons: 64, Grad norm: 4.693e-02\n",
      "Epoch 14245, Loss: 0.005488142371177673, Neurons: 64, Grad norm: 3.287e-02\n",
      "Epoch 14245, Loss: 0.005488142371177673, Neurons: 64, Grad norm: 3.287e-02\n",
      "Epoch 14246, Loss: 0.005487275309860706, Neurons: 64, Grad norm: 5.804e-02\n",
      "Epoch 14246, Loss: 0.005487275309860706, Neurons: 64, Grad norm: 5.804e-02\n",
      "Epoch 14247, Loss: 0.0054864599369466305, Neurons: 64, Grad norm: 9.918e-02\n",
      "Epoch 14247, Loss: 0.0054864599369466305, Neurons: 64, Grad norm: 9.918e-02\n",
      "Epoch 14248, Loss: 0.0054855952039361, Neurons: 64, Grad norm: 1.157e-01\n",
      "Epoch 14248, Loss: 0.0054855952039361, Neurons: 64, Grad norm: 1.157e-01\n",
      "Epoch 14249, Loss: 0.005484853871166706, Neurons: 64, Grad norm: 1.417e-01\n",
      "Epoch 14249, Loss: 0.005484853871166706, Neurons: 64, Grad norm: 1.417e-01\n",
      "Epoch 14250, Loss: 0.005484072957187891, Neurons: 64, Grad norm: 1.402e-01\n",
      "Epoch 14250, Loss: 0.005484072957187891, Neurons: 64, Grad norm: 1.402e-01\n",
      "Epoch 14251, Loss: 0.0054832748137414455, Neurons: 64, Grad norm: 1.498e-01\n",
      "Epoch 14251, Loss: 0.0054832748137414455, Neurons: 64, Grad norm: 1.498e-01\n",
      "Epoch 14252, Loss: 0.005482413340359926, Neurons: 64, Grad norm: 1.351e-01\n",
      "Epoch 14252, Loss: 0.005482413340359926, Neurons: 64, Grad norm: 1.351e-01\n",
      "Epoch 14253, Loss: 0.00548155652359128, Neurons: 64, Grad norm: 1.333e-01\n",
      "Epoch 14253, Loss: 0.00548155652359128, Neurons: 64, Grad norm: 1.333e-01\n",
      "Epoch 14254, Loss: 0.0054806494154036045, Neurons: 64, Grad norm: 1.108e-01\n",
      "Epoch 14254, Loss: 0.0054806494154036045, Neurons: 64, Grad norm: 1.108e-01\n",
      "Epoch 14255, Loss: 0.005479736719280481, Neurons: 64, Grad norm: 1.037e-01\n",
      "Epoch 14255, Loss: 0.005479736719280481, Neurons: 64, Grad norm: 1.037e-01\n",
      "Epoch 14256, Loss: 0.0054788123816251755, Neurons: 64, Grad norm: 7.794e-02\n",
      "Epoch 14256, Loss: 0.0054788123816251755, Neurons: 64, Grad norm: 7.794e-02\n",
      "Epoch 14257, Loss: 0.005477895028889179, Neurons: 64, Grad norm: 7.269e-02\n",
      "Epoch 14257, Loss: 0.005477895028889179, Neurons: 64, Grad norm: 7.269e-02\n",
      "Epoch 14258, Loss: 0.005476964637637138, Neurons: 64, Grad norm: 4.817e-02\n",
      "Epoch 14258, Loss: 0.005476964637637138, Neurons: 64, Grad norm: 4.817e-02\n",
      "Epoch 14259, Loss: 0.005476097576320171, Neurons: 64, Grad norm: 4.064e-02\n",
      "Epoch 14259, Loss: 0.005476097576320171, Neurons: 64, Grad norm: 4.064e-02\n",
      "Epoch 14260, Loss: 0.005475200712680817, Neurons: 64, Grad norm: 1.889e-02\n",
      "Epoch 14260, Loss: 0.005475200712680817, Neurons: 64, Grad norm: 1.889e-02\n",
      "Epoch 14261, Loss: 0.00547434389591217, Neurons: 64, Grad norm: 1.922e-02\n",
      "Epoch 14261, Loss: 0.00547434389591217, Neurons: 64, Grad norm: 1.922e-02\n",
      "Epoch 14262, Loss: 0.005473429802805185, Neurons: 64, Grad norm: 1.024e-02\n",
      "Epoch 14262, Loss: 0.005473429802805185, Neurons: 64, Grad norm: 1.024e-02\n",
      "Epoch 14263, Loss: 0.005472569260746241, Neurons: 64, Grad norm: 1.248e-02\n",
      "Epoch 14263, Loss: 0.005472569260746241, Neurons: 64, Grad norm: 1.248e-02\n",
      "Epoch 14264, Loss: 0.0054717096500098705, Neurons: 64, Grad norm: 2.699e-02\n",
      "Epoch 14264, Loss: 0.0054717096500098705, Neurons: 64, Grad norm: 2.699e-02\n",
      "Epoch 14265, Loss: 0.005470902658998966, Neurons: 64, Grad norm: 2.489e-02\n",
      "Epoch 14265, Loss: 0.005470902658998966, Neurons: 64, Grad norm: 2.489e-02\n",
      "Epoch 14266, Loss: 0.005470062606036663, Neurons: 64, Grad norm: 4.345e-02\n",
      "Epoch 14266, Loss: 0.005470062606036663, Neurons: 64, Grad norm: 4.345e-02\n",
      "Epoch 14267, Loss: 0.005469201132655144, Neurons: 64, Grad norm: 3.741e-02\n",
      "Epoch 14267, Loss: 0.005469201132655144, Neurons: 64, Grad norm: 3.741e-02\n",
      "Epoch 14268, Loss: 0.005468349903821945, Neurons: 64, Grad norm: 4.798e-02\n",
      "Epoch 14268, Loss: 0.005468349903821945, Neurons: 64, Grad norm: 4.798e-02\n",
      "Epoch 14269, Loss: 0.005467462819069624, Neurons: 64, Grad norm: 4.229e-02\n",
      "Epoch 14269, Loss: 0.005467462819069624, Neurons: 64, Grad norm: 4.229e-02\n",
      "Epoch 14270, Loss: 0.0054665920324623585, Neurons: 64, Grad norm: 5.425e-02\n",
      "Epoch 14270, Loss: 0.0054665920324623585, Neurons: 64, Grad norm: 5.425e-02\n",
      "Epoch 14271, Loss: 0.005465732887387276, Neurons: 64, Grad norm: 4.458e-02\n",
      "Epoch 14271, Loss: 0.005465732887387276, Neurons: 64, Grad norm: 4.458e-02\n",
      "Epoch 14272, Loss: 0.005464859772473574, Neurons: 64, Grad norm: 5.243e-02\n",
      "Epoch 14272, Loss: 0.005464859772473574, Neurons: 64, Grad norm: 5.243e-02\n",
      "Epoch 14273, Loss: 0.00546399038285017, Neurons: 64, Grad norm: 4.476e-02\n",
      "Epoch 14273, Loss: 0.00546399038285017, Neurons: 64, Grad norm: 4.476e-02\n",
      "Epoch 14274, Loss: 0.005463196896016598, Neurons: 64, Grad norm: 5.952e-02\n",
      "Epoch 14274, Loss: 0.005463196896016598, Neurons: 64, Grad norm: 5.952e-02\n",
      "Epoch 14275, Loss: 0.005462306551635265, Neurons: 64, Grad norm: 5.242e-02\n",
      "Epoch 14275, Loss: 0.005462306551635265, Neurons: 64, Grad norm: 5.242e-02\n",
      "Epoch 14276, Loss: 0.005461428314447403, Neurons: 64, Grad norm: 5.971e-02\n",
      "Epoch 14276, Loss: 0.005461428314447403, Neurons: 64, Grad norm: 5.971e-02\n",
      "Epoch 14277, Loss: 0.005460590589791536, Neurons: 64, Grad norm: 5.205e-02\n",
      "Epoch 14277, Loss: 0.005460590589791536, Neurons: 64, Grad norm: 5.205e-02\n",
      "Epoch 14278, Loss: 0.005459742620587349, Neurons: 64, Grad norm: 6.579e-02\n",
      "Epoch 14278, Loss: 0.005459742620587349, Neurons: 64, Grad norm: 6.579e-02\n",
      "Epoch 14279, Loss: 0.005458909552544355, Neurons: 64, Grad norm: 6.484e-02\n",
      "Epoch 14279, Loss: 0.005458909552544355, Neurons: 64, Grad norm: 6.484e-02\n",
      "Epoch 14280, Loss: 0.005458130035549402, Neurons: 64, Grad norm: 8.188e-02\n",
      "Epoch 14280, Loss: 0.005458130035549402, Neurons: 64, Grad norm: 8.188e-02\n",
      "Epoch 14281, Loss: 0.005457301624119282, Neurons: 64, Grad norm: 8.009e-02\n",
      "Epoch 14281, Loss: 0.005457301624119282, Neurons: 64, Grad norm: 8.009e-02\n",
      "Epoch 14282, Loss: 0.005456491839140654, Neurons: 64, Grad norm: 9.635e-02\n",
      "Epoch 14282, Loss: 0.005456491839140654, Neurons: 64, Grad norm: 9.635e-02\n",
      "Epoch 14283, Loss: 0.005455703940242529, Neurons: 64, Grad norm: 9.451e-02\n",
      "Epoch 14283, Loss: 0.005455703940242529, Neurons: 64, Grad norm: 9.451e-02\n",
      "Epoch 14284, Loss: 0.005454890429973602, Neurons: 64, Grad norm: 1.098e-01\n",
      "Epoch 14284, Loss: 0.005454890429973602, Neurons: 64, Grad norm: 1.098e-01\n",
      "Epoch 14285, Loss: 0.005454046186059713, Neurons: 64, Grad norm: 1.083e-01\n",
      "Epoch 14285, Loss: 0.005454046186059713, Neurons: 64, Grad norm: 1.083e-01\n",
      "Epoch 14286, Loss: 0.005453229416161776, Neurons: 64, Grad norm: 1.237e-01\n",
      "Epoch 14286, Loss: 0.005453229416161776, Neurons: 64, Grad norm: 1.237e-01\n",
      "Epoch 14287, Loss: 0.005452398210763931, Neurons: 64, Grad norm: 1.225e-01\n",
      "Epoch 14287, Loss: 0.005452398210763931, Neurons: 64, Grad norm: 1.225e-01\n",
      "Epoch 14288, Loss: 0.005451577249914408, Neurons: 64, Grad norm: 1.444e-01\n",
      "Epoch 14288, Loss: 0.005451577249914408, Neurons: 64, Grad norm: 1.444e-01\n",
      "Epoch 14289, Loss: 0.005450807046145201, Neurons: 64, Grad norm: 1.525e-01\n",
      "Epoch 14289, Loss: 0.005450807046145201, Neurons: 64, Grad norm: 1.525e-01\n",
      "Epoch 14290, Loss: 0.005450008437037468, Neurons: 64, Grad norm: 1.810e-01\n",
      "Epoch 14290, Loss: 0.005450008437037468, Neurons: 64, Grad norm: 1.810e-01\n",
      "Epoch 14291, Loss: 0.005449316464364529, Neurons: 64, Grad norm: 1.952e-01\n",
      "Epoch 14291, Loss: 0.005449316464364529, Neurons: 64, Grad norm: 1.952e-01\n",
      "Epoch 14292, Loss: 0.005448705982416868, Neurons: 64, Grad norm: 2.311e-01\n",
      "Epoch 14292, Loss: 0.005448705982416868, Neurons: 64, Grad norm: 2.311e-01\n",
      "Epoch 14293, Loss: 0.005448146257549524, Neurons: 64, Grad norm: 2.539e-01\n",
      "Epoch 14293, Loss: 0.005448146257549524, Neurons: 64, Grad norm: 2.539e-01\n",
      "Epoch 14294, Loss: 0.005447718780487776, Neurons: 64, Grad norm: 3.022e-01\n",
      "Epoch 14294, Loss: 0.005447718780487776, Neurons: 64, Grad norm: 3.022e-01\n",
      "Epoch 14295, Loss: 0.005447375122457743, Neurons: 64, Grad norm: 3.399e-01\n",
      "Epoch 14295, Loss: 0.005447375122457743, Neurons: 64, Grad norm: 3.399e-01\n",
      "Epoch 14296, Loss: 0.005447226110845804, Neurons: 64, Grad norm: 4.056e-01\n",
      "Epoch 14296, Loss: 0.005447226110845804, Neurons: 64, Grad norm: 4.056e-01\n",
      "Epoch 14297, Loss: 0.0054473248310387135, Neurons: 64, Grad norm: 4.630e-01\n",
      "Epoch 14297, Loss: 0.0054473248310387135, Neurons: 64, Grad norm: 4.630e-01\n",
      "Epoch 14298, Loss: 0.0054476698860526085, Neurons: 64, Grad norm: 5.524e-01\n",
      "Epoch 14298, Loss: 0.0054476698860526085, Neurons: 64, Grad norm: 5.524e-01\n",
      "Epoch 14299, Loss: 0.005448548123240471, Neurons: 64, Grad norm: 6.422e-01\n",
      "Epoch 14299, Loss: 0.005448548123240471, Neurons: 64, Grad norm: 6.422e-01\n",
      "Epoch 14299, Test loss: 0.004500760231167078\n",
      "Epoch 14299, Test loss: 0.004500760231167078\n",
      "Epoch 14300, Loss: 0.005450102966278791, Neurons: 64, Grad norm: 7.755e-01\n",
      "Epoch 14300, Loss: 0.005450102966278791, Neurons: 64, Grad norm: 7.755e-01\n",
      "Epoch 14301, Loss: 0.005452828481793404, Neurons: 64, Grad norm: 9.167e-01\n",
      "Epoch 14301, Loss: 0.005452828481793404, Neurons: 64, Grad norm: 9.167e-01\n",
      "Epoch 14302, Loss: 0.005457028746604919, Neurons: 64, Grad norm: 1.106e+00\n",
      "Epoch 14302, Loss: 0.005457028746604919, Neurons: 64, Grad norm: 1.106e+00\n",
      "Epoch 14303, Loss: 0.005463591776788235, Neurons: 64, Grad norm: 1.315e+00\n",
      "Epoch 14303, Loss: 0.005463591776788235, Neurons: 64, Grad norm: 1.315e+00\n",
      "Epoch 14304, Loss: 0.005473226774483919, Neurons: 64, Grad norm: 1.594e+00\n",
      "Epoch 14304, Loss: 0.005473226774483919, Neurons: 64, Grad norm: 1.594e+00\n",
      "Epoch 14305, Loss: 0.005487474612891674, Neurons: 64, Grad norm: 1.913e+00\n",
      "Epoch 14305, Loss: 0.005487474612891674, Neurons: 64, Grad norm: 1.913e+00\n",
      "Epoch 14306, Loss: 0.005508346017450094, Neurons: 64, Grad norm: 2.324e+00\n",
      "Epoch 14306, Loss: 0.005508346017450094, Neurons: 64, Grad norm: 2.324e+00\n",
      "Epoch 14307, Loss: 0.005539140198379755, Neurons: 64, Grad norm: 2.806e+00\n",
      "Epoch 14307, Loss: 0.005539140198379755, Neurons: 64, Grad norm: 2.806e+00\n",
      "Epoch 14308, Loss: 0.005584025755524635, Neurons: 64, Grad norm: 3.410e+00\n",
      "Epoch 14308, Loss: 0.005584025755524635, Neurons: 64, Grad norm: 3.410e+00\n",
      "Epoch 14309, Loss: 0.005649690516293049, Neurons: 64, Grad norm: 4.109e+00\n",
      "Epoch 14309, Loss: 0.005649690516293049, Neurons: 64, Grad norm: 4.109e+00\n",
      "Epoch 14310, Loss: 0.005743109155446291, Neurons: 64, Grad norm: 4.952e+00\n",
      "Epoch 14310, Loss: 0.005743109155446291, Neurons: 64, Grad norm: 4.952e+00\n",
      "Epoch 14311, Loss: 0.005873455666005611, Neurons: 64, Grad norm: 5.897e+00\n",
      "Epoch 14311, Loss: 0.005873455666005611, Neurons: 64, Grad norm: 5.897e+00\n",
      "Epoch 14312, Loss: 0.006047129165381193, Neurons: 64, Grad norm: 6.941e+00\n",
      "Epoch 14312, Loss: 0.006047129165381193, Neurons: 64, Grad norm: 6.941e+00\n",
      "Epoch 14313, Loss: 0.006264983210712671, Neurons: 64, Grad norm: 7.974e+00\n",
      "Epoch 14313, Loss: 0.006264983210712671, Neurons: 64, Grad norm: 7.974e+00\n",
      "Epoch 14314, Loss: 0.0065104286186397076, Neurons: 64, Grad norm: 8.892e+00\n",
      "Epoch 14314, Loss: 0.0065104286186397076, Neurons: 64, Grad norm: 8.892e+00\n",
      "Epoch 14315, Loss: 0.006738689728081226, Neurons: 64, Grad norm: 9.468e+00\n",
      "Epoch 14315, Loss: 0.006738689728081226, Neurons: 64, Grad norm: 9.468e+00\n",
      "Epoch 14316, Loss: 0.006877579260617495, Neurons: 64, Grad norm: 9.498e+00\n",
      "Epoch 14316, Loss: 0.006877579260617495, Neurons: 64, Grad norm: 9.498e+00\n",
      "Epoch 14317, Loss: 0.006844089832156897, Neurons: 64, Grad norm: 8.763e+00\n",
      "Epoch 14317, Loss: 0.006844089832156897, Neurons: 64, Grad norm: 8.763e+00\n",
      "Epoch 14318, Loss: 0.006606457754969597, Neurons: 64, Grad norm: 7.251e+00\n",
      "Epoch 14318, Loss: 0.006606457754969597, Neurons: 64, Grad norm: 7.251e+00\n",
      "Epoch 14319, Loss: 0.006222790572792292, Neurons: 64, Grad norm: 5.100e+00\n",
      "Epoch 14319, Loss: 0.006222790572792292, Neurons: 64, Grad norm: 5.100e+00\n",
      "Epoch 14320, Loss: 0.0058452412486076355, Neurons: 64, Grad norm: 2.782e+00\n",
      "Epoch 14320, Loss: 0.0058452412486076355, Neurons: 64, Grad norm: 2.782e+00\n",
      "Epoch 14321, Loss: 0.0056223091669380665, Neurons: 64, Grad norm: 1.667e+00\n",
      "Epoch 14321, Loss: 0.0056223091669380665, Neurons: 64, Grad norm: 1.667e+00\n",
      "Epoch 14322, Loss: 0.0056089842692017555, Neurons: 64, Grad norm: 2.968e+00\n",
      "Epoch 14322, Loss: 0.0056089842692017555, Neurons: 64, Grad norm: 2.968e+00\n",
      "Epoch 14323, Loss: 0.005737256724387407, Neurons: 64, Grad norm: 4.313e+00\n",
      "Epoch 14323, Loss: 0.005737256724387407, Neurons: 64, Grad norm: 4.313e+00\n",
      "Epoch 14324, Loss: 0.005873600021004677, Neurons: 64, Grad norm: 4.941e+00\n",
      "Epoch 14324, Loss: 0.005873600021004677, Neurons: 64, Grad norm: 4.941e+00\n",
      "Epoch 14325, Loss: 0.005904548801481724, Neurons: 64, Grad norm: 4.783e+00\n",
      "Epoch 14325, Loss: 0.005904548801481724, Neurons: 64, Grad norm: 4.783e+00\n",
      "Epoch 14326, Loss: 0.005807517096400261, Neurons: 64, Grad norm: 3.916e+00\n",
      "Epoch 14326, Loss: 0.005807517096400261, Neurons: 64, Grad norm: 3.916e+00\n",
      "Epoch 14327, Loss: 0.00565290404483676, Neurons: 64, Grad norm: 2.674e+00\n",
      "Epoch 14327, Loss: 0.00565290404483676, Neurons: 64, Grad norm: 2.674e+00\n",
      "Epoch 14328, Loss: 0.005541004240512848, Neurons: 64, Grad norm: 1.592e+00\n",
      "Epoch 14328, Loss: 0.005541004240512848, Neurons: 64, Grad norm: 1.592e+00\n",
      "Epoch 14329, Loss: 0.005525519140064716, Neurons: 64, Grad norm: 1.603e+00\n",
      "Epoch 14329, Loss: 0.005525519140064716, Neurons: 64, Grad norm: 1.603e+00\n",
      "Epoch 14330, Loss: 0.005581942852586508, Neurons: 64, Grad norm: 2.268e+00\n",
      "Epoch 14330, Loss: 0.005581942852586508, Neurons: 64, Grad norm: 2.268e+00\n",
      "Epoch 14331, Loss: 0.0056395381689071655, Neurons: 64, Grad norm: 2.666e+00\n",
      "Epoch 14331, Loss: 0.0056395381689071655, Neurons: 64, Grad norm: 2.666e+00\n",
      "Epoch 14332, Loss: 0.005637019407004118, Neurons: 64, Grad norm: 2.630e+00\n",
      "Epoch 14332, Loss: 0.005637019407004118, Neurons: 64, Grad norm: 2.630e+00\n",
      "Epoch 14333, Loss: 0.0055714878253638744, Neurons: 64, Grad norm: 2.193e+00\n",
      "Epoch 14333, Loss: 0.0055714878253638744, Neurons: 64, Grad norm: 2.193e+00\n",
      "Epoch 14334, Loss: 0.005492562428116798, Neurons: 64, Grad norm: 1.604e+00\n",
      "Epoch 14334, Loss: 0.005492562428116798, Neurons: 64, Grad norm: 1.604e+00\n",
      "Epoch 14335, Loss: 0.005454971455037594, Neurons: 64, Grad norm: 1.207e+00\n",
      "Epoch 14335, Loss: 0.005454971455037594, Neurons: 64, Grad norm: 1.207e+00\n",
      "Epoch 14336, Loss: 0.005473639350384474, Neurons: 64, Grad norm: 1.266e+00\n",
      "Epoch 14336, Loss: 0.005473639350384474, Neurons: 64, Grad norm: 1.266e+00\n",
      "Epoch 14337, Loss: 0.005517577286809683, Neurons: 64, Grad norm: 1.461e+00\n",
      "Epoch 14337, Loss: 0.005517577286809683, Neurons: 64, Grad norm: 1.461e+00\n",
      "Epoch 14338, Loss: 0.005540413316339254, Neurons: 64, Grad norm: 1.470e+00\n",
      "Epoch 14338, Loss: 0.005540413316339254, Neurons: 64, Grad norm: 1.470e+00\n",
      "Epoch 14339, Loss: 0.005518261808902025, Neurons: 64, Grad norm: 1.257e+00\n",
      "Epoch 14339, Loss: 0.005518261808902025, Neurons: 64, Grad norm: 1.257e+00\n",
      "Epoch 14340, Loss: 0.005466441158205271, Neurons: 64, Grad norm: 8.885e-01\n",
      "Epoch 14340, Loss: 0.005466441158205271, Neurons: 64, Grad norm: 8.885e-01\n",
      "Epoch 14341, Loss: 0.005423099733889103, Neurons: 64, Grad norm: 6.626e-01\n",
      "Epoch 14341, Loss: 0.005423099733889103, Neurons: 64, Grad norm: 6.626e-01\n",
      "Epoch 14342, Loss: 0.005415564868599176, Neurons: 64, Grad norm: 7.798e-01\n",
      "Epoch 14342, Loss: 0.005415564868599176, Neurons: 64, Grad norm: 7.798e-01\n",
      "Epoch 14343, Loss: 0.005440115462988615, Neurons: 64, Grad norm: 9.878e-01\n",
      "Epoch 14343, Loss: 0.005440115462988615, Neurons: 64, Grad norm: 9.878e-01\n",
      "Epoch 14344, Loss: 0.005469546653330326, Neurons: 64, Grad norm: 1.052e+00\n",
      "Epoch 14344, Loss: 0.005469546653330326, Neurons: 64, Grad norm: 1.052e+00\n",
      "Epoch 14345, Loss: 0.005477179307490587, Neurons: 64, Grad norm: 9.050e-01\n",
      "Epoch 14345, Loss: 0.005477179307490587, Neurons: 64, Grad norm: 9.050e-01\n",
      "Epoch 14346, Loss: 0.005456988699734211, Neurons: 64, Grad norm: 5.953e-01\n",
      "Epoch 14346, Loss: 0.005456988699734211, Neurons: 64, Grad norm: 5.953e-01\n",
      "Epoch 14347, Loss: 0.005424720235168934, Neurons: 64, Grad norm: 1.839e-01\n",
      "Epoch 14347, Loss: 0.005424720235168934, Neurons: 64, Grad norm: 1.839e-01\n",
      "Epoch 14348, Loss: 0.00540304696187377, Neurons: 64, Grad norm: 2.199e-01\n",
      "Epoch 14348, Loss: 0.00540304696187377, Neurons: 64, Grad norm: 2.199e-01\n",
      "Epoch 14349, Loss: 0.005403066053986549, Neurons: 64, Grad norm: 5.442e-01\n",
      "Epoch 14349, Loss: 0.005403066053986549, Neurons: 64, Grad norm: 5.442e-01\n",
      "Epoch 14350, Loss: 0.005418052896857262, Neurons: 64, Grad norm: 7.143e-01\n",
      "Epoch 14350, Loss: 0.005418052896857262, Neurons: 64, Grad norm: 7.143e-01\n",
      "Epoch 14351, Loss: 0.0054320949129760265, Neurons: 64, Grad norm: 7.321e-01\n",
      "Epoch 14351, Loss: 0.0054320949129760265, Neurons: 64, Grad norm: 7.321e-01\n",
      "Epoch 14352, Loss: 0.005433307494968176, Neurons: 64, Grad norm: 6.089e-01\n",
      "Epoch 14352, Loss: 0.005433307494968176, Neurons: 64, Grad norm: 6.089e-01\n",
      "Epoch 14353, Loss: 0.005421536974608898, Neurons: 64, Grad norm: 4.337e-01\n",
      "Epoch 14353, Loss: 0.005421536974608898, Neurons: 64, Grad norm: 4.337e-01\n",
      "Epoch 14354, Loss: 0.005406308453530073, Neurons: 64, Grad norm: 3.608e-01\n",
      "Epoch 14354, Loss: 0.005406308453530073, Neurons: 64, Grad norm: 3.608e-01\n",
      "Epoch 14355, Loss: 0.00539762806147337, Neurons: 64, Grad norm: 4.473e-01\n",
      "Epoch 14355, Loss: 0.00539762806147337, Neurons: 64, Grad norm: 4.473e-01\n",
      "Epoch 14356, Loss: 0.0053985873237252235, Neurons: 64, Grad norm: 5.667e-01\n",
      "Epoch 14356, Loss: 0.0053985873237252235, Neurons: 64, Grad norm: 5.667e-01\n",
      "Epoch 14357, Loss: 0.005404695402830839, Neurons: 64, Grad norm: 5.872e-01\n",
      "Epoch 14357, Loss: 0.005404695402830839, Neurons: 64, Grad norm: 5.872e-01\n",
      "Epoch 14358, Loss: 0.005408862140029669, Neurons: 64, Grad norm: 5.267e-01\n",
      "Epoch 14358, Loss: 0.005408862140029669, Neurons: 64, Grad norm: 5.267e-01\n",
      "Epoch 14359, Loss: 0.005407361779361963, Neurons: 64, Grad norm: 3.887e-01\n",
      "Epoch 14359, Loss: 0.005407361779361963, Neurons: 64, Grad norm: 3.887e-01\n",
      "Epoch 14360, Loss: 0.005401058122515678, Neurons: 64, Grad norm: 2.864e-01\n",
      "Epoch 14360, Loss: 0.005401058122515678, Neurons: 64, Grad norm: 2.864e-01\n",
      "Epoch 14361, Loss: 0.005394579377025366, Neurons: 64, Grad norm: 3.444e-01\n",
      "Epoch 14361, Loss: 0.005394579377025366, Neurons: 64, Grad norm: 3.444e-01\n",
      "Epoch 14362, Loss: 0.005391458980739117, Neurons: 64, Grad norm: 4.687e-01\n",
      "Epoch 14362, Loss: 0.005391458980739117, Neurons: 64, Grad norm: 4.687e-01\n",
      "Epoch 14363, Loss: 0.005392334423959255, Neurons: 64, Grad norm: 5.741e-01\n",
      "Epoch 14363, Loss: 0.005392334423959255, Neurons: 64, Grad norm: 5.741e-01\n",
      "Epoch 14364, Loss: 0.005394892301410437, Neurons: 64, Grad norm: 5.825e-01\n",
      "Epoch 14364, Loss: 0.005394892301410437, Neurons: 64, Grad norm: 5.825e-01\n",
      "Epoch 14365, Loss: 0.0053960043005645275, Neurons: 64, Grad norm: 5.194e-01\n",
      "Epoch 14365, Loss: 0.0053960043005645275, Neurons: 64, Grad norm: 5.194e-01\n",
      "Epoch 14366, Loss: 0.005394036415964365, Neurons: 64, Grad norm: 3.639e-01\n",
      "Epoch 14366, Loss: 0.005394036415964365, Neurons: 64, Grad norm: 3.639e-01\n",
      "Epoch 14367, Loss: 0.00538992416113615, Neurons: 64, Grad norm: 1.829e-01\n",
      "Epoch 14367, Loss: 0.00538992416113615, Neurons: 64, Grad norm: 1.829e-01\n",
      "Epoch 14368, Loss: 0.005385852884501219, Neurons: 64, Grad norm: 6.665e-02\n",
      "Epoch 14368, Loss: 0.005385852884501219, Neurons: 64, Grad norm: 6.665e-02\n",
      "Epoch 14369, Loss: 0.005383756943047047, Neurons: 64, Grad norm: 2.236e-01\n",
      "Epoch 14369, Loss: 0.005383756943047047, Neurons: 64, Grad norm: 2.236e-01\n",
      "Epoch 14370, Loss: 0.005383952986449003, Neurons: 64, Grad norm: 3.678e-01\n",
      "Epoch 14370, Loss: 0.005383952986449003, Neurons: 64, Grad norm: 3.678e-01\n",
      "Epoch 14371, Loss: 0.005385151132941246, Neurons: 64, Grad norm: 4.331e-01\n",
      "Epoch 14371, Loss: 0.005385151132941246, Neurons: 64, Grad norm: 4.331e-01\n",
      "Epoch 14372, Loss: 0.005385848227888346, Neurons: 64, Grad norm: 4.478e-01\n",
      "Epoch 14372, Loss: 0.005385848227888346, Neurons: 64, Grad norm: 4.478e-01\n",
      "Epoch 14373, Loss: 0.005385057535022497, Neurons: 64, Grad norm: 3.850e-01\n",
      "Epoch 14373, Loss: 0.005385057535022497, Neurons: 64, Grad norm: 3.850e-01\n",
      "Epoch 14374, Loss: 0.005382921546697617, Neurons: 64, Grad norm: 3.004e-01\n",
      "Epoch 14374, Loss: 0.005382921546697617, Neurons: 64, Grad norm: 3.004e-01\n",
      "Epoch 14375, Loss: 0.005380456335842609, Neurons: 64, Grad norm: 1.775e-01\n",
      "Epoch 14375, Loss: 0.005380456335842609, Neurons: 64, Grad norm: 1.775e-01\n",
      "Epoch 14376, Loss: 0.005378517787903547, Neurons: 64, Grad norm: 9.323e-02\n",
      "Epoch 14376, Loss: 0.005378517787903547, Neurons: 64, Grad norm: 9.323e-02\n",
      "Epoch 14377, Loss: 0.005377443972975016, Neurons: 64, Grad norm: 1.156e-01\n",
      "Epoch 14377, Loss: 0.005377443972975016, Neurons: 64, Grad norm: 1.156e-01\n",
      "Epoch 14378, Loss: 0.005377194844186306, Neurons: 64, Grad norm: 1.741e-01\n",
      "Epoch 14378, Loss: 0.005377194844186306, Neurons: 64, Grad norm: 1.741e-01\n",
      "Epoch 14379, Loss: 0.005377011373639107, Neurons: 64, Grad norm: 2.226e-01\n",
      "Epoch 14379, Loss: 0.005377011373639107, Neurons: 64, Grad norm: 2.226e-01\n",
      "Epoch 14380, Loss: 0.005376617889851332, Neurons: 64, Grad norm: 2.217e-01\n",
      "Epoch 14380, Loss: 0.005376617889851332, Neurons: 64, Grad norm: 2.217e-01\n",
      "Epoch 14381, Loss: 0.005375612527132034, Neurons: 64, Grad norm: 2.080e-01\n",
      "Epoch 14381, Loss: 0.005375612527132034, Neurons: 64, Grad norm: 2.080e-01\n",
      "Epoch 14382, Loss: 0.005374276079237461, Neurons: 64, Grad norm: 1.562e-01\n",
      "Epoch 14382, Loss: 0.005374276079237461, Neurons: 64, Grad norm: 1.562e-01\n",
      "Epoch 14383, Loss: 0.0053728679195046425, Neurons: 64, Grad norm: 1.212e-01\n",
      "Epoch 14383, Loss: 0.0053728679195046425, Neurons: 64, Grad norm: 1.212e-01\n",
      "Epoch 14384, Loss: 0.0053716991096735, Neurons: 64, Grad norm: 8.882e-02\n",
      "Epoch 14384, Loss: 0.0053716991096735, Neurons: 64, Grad norm: 8.882e-02\n",
      "Epoch 14385, Loss: 0.0053708916530013084, Neurons: 64, Grad norm: 9.689e-02\n",
      "Epoch 14385, Loss: 0.0053708916530013084, Neurons: 64, Grad norm: 9.689e-02\n",
      "Epoch 14386, Loss: 0.005370422266423702, Neurons: 64, Grad norm: 1.147e-01\n",
      "Epoch 14386, Loss: 0.005370422266423702, Neurons: 64, Grad norm: 1.147e-01\n",
      "Epoch 14387, Loss: 0.0053699021227657795, Neurons: 64, Grad norm: 1.183e-01\n",
      "Epoch 14387, Loss: 0.0053699021227657795, Neurons: 64, Grad norm: 1.183e-01\n",
      "Epoch 14388, Loss: 0.005369239021092653, Neurons: 64, Grad norm: 1.129e-01\n",
      "Epoch 14388, Loss: 0.005369239021092653, Neurons: 64, Grad norm: 1.129e-01\n",
      "Epoch 14389, Loss: 0.005368236918002367, Neurons: 64, Grad norm: 8.474e-02\n",
      "Epoch 14389, Loss: 0.005368236918002367, Neurons: 64, Grad norm: 8.474e-02\n",
      "Epoch 14390, Loss: 0.005367096979171038, Neurons: 64, Grad norm: 5.517e-02\n",
      "Epoch 14390, Loss: 0.005367096979171038, Neurons: 64, Grad norm: 5.517e-02\n",
      "Epoch 14391, Loss: 0.0053659346885979176, Neurons: 64, Grad norm: 2.648e-02\n",
      "Epoch 14391, Loss: 0.0053659346885979176, Neurons: 64, Grad norm: 2.648e-02\n",
      "Epoch 14392, Loss: 0.005364989396184683, Neurons: 64, Grad norm: 3.365e-02\n",
      "Epoch 14392, Loss: 0.005364989396184683, Neurons: 64, Grad norm: 3.365e-02\n",
      "Epoch 14393, Loss: 0.0053641777485609055, Neurons: 64, Grad norm: 6.912e-02\n",
      "Epoch 14393, Loss: 0.0053641777485609055, Neurons: 64, Grad norm: 6.912e-02\n",
      "Epoch 14394, Loss: 0.005363506730645895, Neurons: 64, Grad norm: 7.878e-02\n",
      "Epoch 14394, Loss: 0.005363506730645895, Neurons: 64, Grad norm: 7.878e-02\n",
      "Epoch 14395, Loss: 0.005362876690924168, Neurons: 64, Grad norm: 9.164e-02\n",
      "Epoch 14395, Loss: 0.005362876690924168, Neurons: 64, Grad norm: 9.164e-02\n",
      "Epoch 14396, Loss: 0.005362104624509811, Neurons: 64, Grad norm: 7.803e-02\n",
      "Epoch 14396, Loss: 0.005362104624509811, Neurons: 64, Grad norm: 7.803e-02\n",
      "Epoch 14397, Loss: 0.005361223127692938, Neurons: 64, Grad norm: 6.821e-02\n",
      "Epoch 14397, Loss: 0.005361223127692938, Neurons: 64, Grad norm: 6.821e-02\n",
      "Epoch 14398, Loss: 0.005360308103263378, Neurons: 64, Grad norm: 4.394e-02\n",
      "Epoch 14398, Loss: 0.005360308103263378, Neurons: 64, Grad norm: 4.394e-02\n",
      "Epoch 14399, Loss: 0.005359376315027475, Neurons: 64, Grad norm: 3.388e-02\n",
      "Epoch 14399, Loss: 0.005359376315027475, Neurons: 64, Grad norm: 3.388e-02\n",
      "Epoch 14399, Test loss: 0.004447425715625286\n",
      "Epoch 14399, Test loss: 0.004447425715625286\n",
      "Epoch 14400, Loss: 0.0053584882989525795, Neurons: 64, Grad norm: 4.798e-02\n",
      "Epoch 14400, Loss: 0.0053584882989525795, Neurons: 64, Grad norm: 4.798e-02\n",
      "Epoch 14401, Loss: 0.005357649177312851, Neurons: 64, Grad norm: 5.716e-02\n",
      "Epoch 14401, Loss: 0.005357649177312851, Neurons: 64, Grad norm: 5.716e-02\n",
      "Epoch 14402, Loss: 0.005356828216463327, Neurons: 64, Grad norm: 8.026e-02\n",
      "Epoch 14402, Loss: 0.005356828216463327, Neurons: 64, Grad norm: 8.026e-02\n",
      "Epoch 14403, Loss: 0.005356080364435911, Neurons: 64, Grad norm: 8.169e-02\n",
      "Epoch 14403, Loss: 0.005356080364435911, Neurons: 64, Grad norm: 8.169e-02\n",
      "Epoch 14404, Loss: 0.0053552924655377865, Neurons: 64, Grad norm: 9.756e-02\n",
      "Epoch 14404, Loss: 0.0053552924655377865, Neurons: 64, Grad norm: 9.756e-02\n",
      "Epoch 14405, Loss: 0.005354498513042927, Neurons: 64, Grad norm: 9.219e-02\n",
      "Epoch 14405, Loss: 0.005354498513042927, Neurons: 64, Grad norm: 9.219e-02\n",
      "Epoch 14406, Loss: 0.0053536961786448956, Neurons: 64, Grad norm: 1.003e-01\n",
      "Epoch 14406, Loss: 0.0053536961786448956, Neurons: 64, Grad norm: 1.003e-01\n",
      "Epoch 14407, Loss: 0.005352826789021492, Neurons: 64, Grad norm: 8.489e-02\n",
      "Epoch 14407, Loss: 0.005352826789021492, Neurons: 64, Grad norm: 8.489e-02\n",
      "Epoch 14408, Loss: 0.005352028179913759, Neurons: 64, Grad norm: 8.512e-02\n",
      "Epoch 14408, Loss: 0.005352028179913759, Neurons: 64, Grad norm: 8.512e-02\n",
      "Epoch 14409, Loss: 0.005351162049919367, Neurons: 64, Grad norm: 7.012e-02\n",
      "Epoch 14409, Loss: 0.005351162049919367, Neurons: 64, Grad norm: 7.012e-02\n",
      "Epoch 14410, Loss: 0.005350316409021616, Neurons: 64, Grad norm: 7.188e-02\n",
      "Epoch 14410, Loss: 0.005350316409021616, Neurons: 64, Grad norm: 7.188e-02\n",
      "Epoch 14411, Loss: 0.005349482409656048, Neurons: 64, Grad norm: 5.761e-02\n",
      "Epoch 14411, Loss: 0.005349482409656048, Neurons: 64, Grad norm: 5.761e-02\n",
      "Epoch 14412, Loss: 0.005348654463887215, Neurons: 64, Grad norm: 6.143e-02\n",
      "Epoch 14412, Loss: 0.005348654463887215, Neurons: 64, Grad norm: 6.143e-02\n",
      "Epoch 14413, Loss: 0.005347887519747019, Neurons: 64, Grad norm: 5.620e-02\n",
      "Epoch 14413, Loss: 0.005347887519747019, Neurons: 64, Grad norm: 5.620e-02\n",
      "Epoch 14414, Loss: 0.005347074940800667, Neurons: 64, Grad norm: 6.284e-02\n",
      "Epoch 14414, Loss: 0.005347074940800667, Neurons: 64, Grad norm: 6.284e-02\n",
      "Epoch 14415, Loss: 0.005346299614757299, Neurons: 64, Grad norm: 6.584e-02\n",
      "Epoch 14415, Loss: 0.005346299614757299, Neurons: 64, Grad norm: 6.584e-02\n",
      "Epoch 14416, Loss: 0.0053455219604074955, Neurons: 64, Grad norm: 7.416e-02\n",
      "Epoch 14416, Loss: 0.0053455219604074955, Neurons: 64, Grad norm: 7.416e-02\n",
      "Epoch 14417, Loss: 0.005344718229025602, Neurons: 64, Grad norm: 7.327e-02\n",
      "Epoch 14417, Loss: 0.005344718229025602, Neurons: 64, Grad norm: 7.327e-02\n",
      "Epoch 14418, Loss: 0.005343967583030462, Neurons: 64, Grad norm: 8.398e-02\n",
      "Epoch 14418, Loss: 0.005343967583030462, Neurons: 64, Grad norm: 8.398e-02\n",
      "Epoch 14419, Loss: 0.005343147087842226, Neurons: 64, Grad norm: 8.701e-02\n",
      "Epoch 14419, Loss: 0.005343147087842226, Neurons: 64, Grad norm: 8.701e-02\n",
      "Epoch 14420, Loss: 0.005342273972928524, Neurons: 64, Grad norm: 1.037e-01\n",
      "Epoch 14420, Loss: 0.005342273972928524, Neurons: 64, Grad norm: 1.037e-01\n",
      "Epoch 14421, Loss: 0.005341439042240381, Neurons: 64, Grad norm: 1.090e-01\n",
      "Epoch 14421, Loss: 0.005341439042240381, Neurons: 64, Grad norm: 1.090e-01\n",
      "Epoch 14422, Loss: 0.005340675823390484, Neurons: 64, Grad norm: 1.304e-01\n",
      "Epoch 14422, Loss: 0.005340675823390484, Neurons: 64, Grad norm: 1.304e-01\n",
      "Epoch 14423, Loss: 0.005339907016605139, Neurons: 64, Grad norm: 1.382e-01\n",
      "Epoch 14423, Loss: 0.005339907016605139, Neurons: 64, Grad norm: 1.382e-01\n",
      "Epoch 14424, Loss: 0.0053391288965940475, Neurons: 64, Grad norm: 1.661e-01\n",
      "Epoch 14424, Loss: 0.0053391288965940475, Neurons: 64, Grad norm: 1.661e-01\n",
      "Epoch 14425, Loss: 0.005338391754776239, Neurons: 64, Grad norm: 1.785e-01\n",
      "Epoch 14425, Loss: 0.005338391754776239, Neurons: 64, Grad norm: 1.785e-01\n",
      "Epoch 14426, Loss: 0.0053376867435872555, Neurons: 64, Grad norm: 2.071e-01\n",
      "Epoch 14426, Loss: 0.0053376867435872555, Neurons: 64, Grad norm: 2.071e-01\n",
      "Epoch 14427, Loss: 0.0053369733504951, Neurons: 64, Grad norm: 2.193e-01\n",
      "Epoch 14427, Loss: 0.0053369733504951, Neurons: 64, Grad norm: 2.193e-01\n",
      "Epoch 14428, Loss: 0.005336317699402571, Neurons: 64, Grad norm: 2.524e-01\n",
      "Epoch 14428, Loss: 0.005336317699402571, Neurons: 64, Grad norm: 2.524e-01\n",
      "Epoch 14429, Loss: 0.00533567788079381, Neurons: 64, Grad norm: 2.748e-01\n",
      "Epoch 14429, Loss: 0.00533567788079381, Neurons: 64, Grad norm: 2.748e-01\n",
      "Epoch 14430, Loss: 0.00533508462831378, Neurons: 64, Grad norm: 3.154e-01\n",
      "Epoch 14430, Loss: 0.00533508462831378, Neurons: 64, Grad norm: 3.154e-01\n",
      "Epoch 14431, Loss: 0.0053346301428973675, Neurons: 64, Grad norm: 3.461e-01\n",
      "Epoch 14431, Loss: 0.0053346301428973675, Neurons: 64, Grad norm: 3.461e-01\n",
      "Epoch 14432, Loss: 0.0053343079052865505, Neurons: 64, Grad norm: 4.064e-01\n",
      "Epoch 14432, Loss: 0.0053343079052865505, Neurons: 64, Grad norm: 4.064e-01\n",
      "Epoch 14433, Loss: 0.0053342171013355255, Neurons: 64, Grad norm: 4.643e-01\n",
      "Epoch 14433, Loss: 0.0053342171013355255, Neurons: 64, Grad norm: 4.643e-01\n",
      "Epoch 14434, Loss: 0.005334487650543451, Neurons: 64, Grad norm: 5.537e-01\n",
      "Epoch 14434, Loss: 0.005334487650543451, Neurons: 64, Grad norm: 5.537e-01\n",
      "Epoch 14435, Loss: 0.0053352611139416695, Neurons: 64, Grad norm: 6.463e-01\n",
      "Epoch 14435, Loss: 0.0053352611139416695, Neurons: 64, Grad norm: 6.463e-01\n",
      "Epoch 14436, Loss: 0.005336718633770943, Neurons: 64, Grad norm: 7.756e-01\n",
      "Epoch 14436, Loss: 0.005336718633770943, Neurons: 64, Grad norm: 7.756e-01\n",
      "Epoch 14437, Loss: 0.005339094903320074, Neurons: 64, Grad norm: 9.170e-01\n",
      "Epoch 14437, Loss: 0.005339094903320074, Neurons: 64, Grad norm: 9.170e-01\n",
      "Epoch 14438, Loss: 0.005342862568795681, Neurons: 64, Grad norm: 1.106e+00\n",
      "Epoch 14438, Loss: 0.005342862568795681, Neurons: 64, Grad norm: 1.106e+00\n",
      "Epoch 14439, Loss: 0.005348502192646265, Neurons: 64, Grad norm: 1.321e+00\n",
      "Epoch 14439, Loss: 0.005348502192646265, Neurons: 64, Grad norm: 1.321e+00\n",
      "Epoch 14440, Loss: 0.005356987938284874, Neurons: 64, Grad norm: 1.603e+00\n",
      "Epoch 14440, Loss: 0.005356987938284874, Neurons: 64, Grad norm: 1.603e+00\n",
      "Epoch 14441, Loss: 0.005369610618799925, Neurons: 64, Grad norm: 1.926e+00\n",
      "Epoch 14441, Loss: 0.005369610618799925, Neurons: 64, Grad norm: 1.926e+00\n",
      "Epoch 14442, Loss: 0.005388611927628517, Neurons: 64, Grad norm: 2.338e+00\n",
      "Epoch 14442, Loss: 0.005388611927628517, Neurons: 64, Grad norm: 2.338e+00\n",
      "Epoch 14443, Loss: 0.005416671745479107, Neurons: 64, Grad norm: 2.821e+00\n",
      "Epoch 14443, Loss: 0.005416671745479107, Neurons: 64, Grad norm: 2.821e+00\n",
      "Epoch 14444, Loss: 0.0054583423770964146, Neurons: 64, Grad norm: 3.417e+00\n",
      "Epoch 14444, Loss: 0.0054583423770964146, Neurons: 64, Grad norm: 3.417e+00\n",
      "Epoch 14445, Loss: 0.005518767982721329, Neurons: 64, Grad norm: 4.106e+00\n",
      "Epoch 14445, Loss: 0.005518767982721329, Neurons: 64, Grad norm: 4.106e+00\n",
      "Epoch 14446, Loss: 0.005605827551335096, Neurons: 64, Grad norm: 4.922e+00\n",
      "Epoch 14446, Loss: 0.005605827551335096, Neurons: 64, Grad norm: 4.922e+00\n",
      "Epoch 14447, Loss: 0.0057263909839093685, Neurons: 64, Grad norm: 5.828e+00\n",
      "Epoch 14447, Loss: 0.0057263909839093685, Neurons: 64, Grad norm: 5.828e+00\n",
      "Epoch 14448, Loss: 0.005888661369681358, Neurons: 64, Grad norm: 6.811e+00\n",
      "Epoch 14448, Loss: 0.005888661369681358, Neurons: 64, Grad norm: 6.811e+00\n",
      "Epoch 14449, Loss: 0.006089096888899803, Neurons: 64, Grad norm: 7.751e+00\n",
      "Epoch 14449, Loss: 0.006089096888899803, Neurons: 64, Grad norm: 7.751e+00\n",
      "Epoch 14450, Loss: 0.006313444580882788, Neurons: 64, Grad norm: 8.535e+00\n",
      "Epoch 14450, Loss: 0.006313444580882788, Neurons: 64, Grad norm: 8.535e+00\n",
      "Epoch 14451, Loss: 0.006510836072266102, Neurons: 64, Grad norm: 8.931e+00\n",
      "Epoch 14451, Loss: 0.006510836072266102, Neurons: 64, Grad norm: 8.931e+00\n",
      "Epoch 14452, Loss: 0.006613483652472496, Neurons: 64, Grad norm: 8.748e+00\n",
      "Epoch 14452, Loss: 0.006613483652472496, Neurons: 64, Grad norm: 8.748e+00\n",
      "Epoch 14453, Loss: 0.006538384594023228, Neurons: 64, Grad norm: 7.797e+00\n",
      "Epoch 14453, Loss: 0.006538384594023228, Neurons: 64, Grad norm: 7.797e+00\n",
      "Epoch 14454, Loss: 0.006271963473409414, Neurons: 64, Grad norm: 6.109e+00\n",
      "Epoch 14454, Loss: 0.006271963473409414, Neurons: 64, Grad norm: 6.109e+00\n",
      "Epoch 14455, Loss: 0.005887030158191919, Neurons: 64, Grad norm: 3.853e+00\n",
      "Epoch 14455, Loss: 0.005887030158191919, Neurons: 64, Grad norm: 3.853e+00\n",
      "Epoch 14456, Loss: 0.005540746729820967, Neurons: 64, Grad norm: 1.485e+00\n",
      "Epoch 14456, Loss: 0.005540746729820967, Neurons: 64, Grad norm: 1.485e+00\n",
      "Epoch 14457, Loss: 0.0053641414269804955, Neurons: 64, Grad norm: 1.408e+00\n",
      "Epoch 14457, Loss: 0.0053641414269804955, Neurons: 64, Grad norm: 1.408e+00\n",
      "Epoch 14458, Loss: 0.005386857315897942, Neurons: 64, Grad norm: 3.235e+00\n",
      "Epoch 14458, Loss: 0.005386857315897942, Neurons: 64, Grad norm: 3.235e+00\n",
      "Epoch 14459, Loss: 0.005533422343432903, Neurons: 64, Grad norm: 4.540e+00\n",
      "Epoch 14459, Loss: 0.005533422343432903, Neurons: 64, Grad norm: 4.540e+00\n",
      "Epoch 14460, Loss: 0.00568263977766037, Neurons: 64, Grad norm: 5.076e+00\n",
      "Epoch 14460, Loss: 0.00568263977766037, Neurons: 64, Grad norm: 5.076e+00\n",
      "Epoch 14461, Loss: 0.005738958716392517, Neurons: 64, Grad norm: 4.840e+00\n",
      "Epoch 14461, Loss: 0.005738958716392517, Neurons: 64, Grad norm: 4.840e+00\n",
      "Epoch 14462, Loss: 0.005675415974110365, Neurons: 64, Grad norm: 3.919e+00\n",
      "Epoch 14462, Loss: 0.005675415974110365, Neurons: 64, Grad norm: 3.919e+00\n",
      "Epoch 14463, Loss: 0.005542280618101358, Neurons: 64, Grad norm: 2.593e+00\n",
      "Epoch 14463, Loss: 0.005542280618101358, Neurons: 64, Grad norm: 2.593e+00\n",
      "Epoch 14464, Loss: 0.005421006586402655, Neurons: 64, Grad norm: 1.279e+00\n",
      "Epoch 14464, Loss: 0.005421006586402655, Neurons: 64, Grad norm: 1.279e+00\n",
      "Epoch 14465, Loss: 0.005369996186345816, Neurons: 64, Grad norm: 1.236e+00\n",
      "Epoch 14465, Loss: 0.005369996186345816, Neurons: 64, Grad norm: 1.236e+00\n",
      "Epoch 14466, Loss: 0.005390596576035023, Neurons: 64, Grad norm: 2.141e+00\n",
      "Epoch 14466, Loss: 0.005390596576035023, Neurons: 64, Grad norm: 2.141e+00\n",
      "Epoch 14467, Loss: 0.0054392884485423565, Neurons: 64, Grad norm: 2.771e+00\n",
      "Epoch 14467, Loss: 0.0054392884485423565, Neurons: 64, Grad norm: 2.771e+00\n",
      "Epoch 14468, Loss: 0.005467199720442295, Neurons: 64, Grad norm: 2.941e+00\n",
      "Epoch 14468, Loss: 0.005467199720442295, Neurons: 64, Grad norm: 2.941e+00\n",
      "Epoch 14469, Loss: 0.005452852230519056, Neurons: 64, Grad norm: 2.650e+00\n",
      "Epoch 14469, Loss: 0.005452852230519056, Neurons: 64, Grad norm: 2.650e+00\n",
      "Epoch 14470, Loss: 0.005410445854067802, Neurons: 64, Grad norm: 2.069e+00\n",
      "Epoch 14470, Loss: 0.005410445854067802, Neurons: 64, Grad norm: 2.069e+00\n",
      "Epoch 14471, Loss: 0.005370961502194405, Neurons: 64, Grad norm: 1.395e+00\n",
      "Epoch 14471, Loss: 0.005370961502194405, Neurons: 64, Grad norm: 1.395e+00\n",
      "Epoch 14472, Loss: 0.005356017500162125, Neurons: 64, Grad norm: 1.020e+00\n",
      "Epoch 14472, Loss: 0.005356017500162125, Neurons: 64, Grad norm: 1.020e+00\n",
      "Epoch 14473, Loss: 0.00536374794319272, Neurons: 64, Grad norm: 1.143e+00\n",
      "Epoch 14473, Loss: 0.00536374794319272, Neurons: 64, Grad norm: 1.143e+00\n",
      "Epoch 14474, Loss: 0.005375976674258709, Neurons: 64, Grad norm: 1.404e+00\n",
      "Epoch 14474, Loss: 0.005375976674258709, Neurons: 64, Grad norm: 1.404e+00\n",
      "Epoch 14475, Loss: 0.0053747063502669334, Neurons: 64, Grad norm: 1.520e+00\n",
      "Epoch 14475, Loss: 0.0053747063502669334, Neurons: 64, Grad norm: 1.520e+00\n",
      "Epoch 14476, Loss: 0.00535636255517602, Neurons: 64, Grad norm: 1.430e+00\n",
      "Epoch 14476, Loss: 0.00535636255517602, Neurons: 64, Grad norm: 1.430e+00\n",
      "Epoch 14477, Loss: 0.005332659464329481, Neurons: 64, Grad norm: 1.225e+00\n",
      "Epoch 14477, Loss: 0.005332659464329481, Neurons: 64, Grad norm: 1.225e+00\n",
      "Epoch 14478, Loss: 0.0053187585435807705, Neurons: 64, Grad norm: 9.966e-01\n",
      "Epoch 14478, Loss: 0.0053187585435807705, Neurons: 64, Grad norm: 9.966e-01\n",
      "Epoch 14479, Loss: 0.005321226082742214, Neurons: 64, Grad norm: 8.884e-01\n",
      "Epoch 14479, Loss: 0.005321226082742214, Neurons: 64, Grad norm: 8.884e-01\n",
      "Epoch 14480, Loss: 0.005333833862096071, Neurons: 64, Grad norm: 8.655e-01\n",
      "Epoch 14480, Loss: 0.005333833862096071, Neurons: 64, Grad norm: 8.655e-01\n",
      "Epoch 14481, Loss: 0.005343244411051273, Neurons: 64, Grad norm: 8.537e-01\n",
      "Epoch 14481, Loss: 0.005343244411051273, Neurons: 64, Grad norm: 8.537e-01\n",
      "Epoch 14482, Loss: 0.005340063478797674, Neurons: 64, Grad norm: 7.682e-01\n",
      "Epoch 14482, Loss: 0.005340063478797674, Neurons: 64, Grad norm: 7.682e-01\n",
      "Epoch 14483, Loss: 0.0053245993331074715, Neurons: 64, Grad norm: 6.071e-01\n",
      "Epoch 14483, Loss: 0.0053245993331074715, Neurons: 64, Grad norm: 6.071e-01\n",
      "Epoch 14484, Loss: 0.005305578466504812, Neurons: 64, Grad norm: 4.488e-01\n",
      "Epoch 14484, Loss: 0.005305578466504812, Neurons: 64, Grad norm: 4.488e-01\n",
      "Epoch 14485, Loss: 0.005293759051710367, Neurons: 64, Grad norm: 4.040e-01\n",
      "Epoch 14485, Loss: 0.005293759051710367, Neurons: 64, Grad norm: 4.040e-01\n",
      "Epoch 14486, Loss: 0.005293893162161112, Neurons: 64, Grad norm: 5.144e-01\n",
      "Epoch 14486, Loss: 0.005293893162161112, Neurons: 64, Grad norm: 5.144e-01\n",
      "Epoch 14487, Loss: 0.005302779376506805, Neurons: 64, Grad norm: 6.145e-01\n",
      "Epoch 14487, Loss: 0.005302779376506805, Neurons: 64, Grad norm: 6.145e-01\n",
      "Epoch 14488, Loss: 0.005312156397849321, Neurons: 64, Grad norm: 6.510e-01\n",
      "Epoch 14488, Loss: 0.005312156397849321, Neurons: 64, Grad norm: 6.510e-01\n",
      "Epoch 14489, Loss: 0.005314952228218317, Neurons: 64, Grad norm: 5.836e-01\n",
      "Epoch 14489, Loss: 0.005314952228218317, Neurons: 64, Grad norm: 5.836e-01\n",
      "Epoch 14490, Loss: 0.005309229250997305, Neurons: 64, Grad norm: 4.433e-01\n",
      "Epoch 14490, Loss: 0.005309229250997305, Neurons: 64, Grad norm: 4.433e-01\n",
      "Epoch 14491, Loss: 0.005298402160406113, Neurons: 64, Grad norm: 2.494e-01\n",
      "Epoch 14491, Loss: 0.005298402160406113, Neurons: 64, Grad norm: 2.494e-01\n",
      "Epoch 14492, Loss: 0.005288601387292147, Neurons: 64, Grad norm: 1.147e-01\n",
      "Epoch 14492, Loss: 0.005288601387292147, Neurons: 64, Grad norm: 1.147e-01\n",
      "Epoch 14493, Loss: 0.005284108687192202, Neurons: 64, Grad norm: 2.091e-01\n",
      "Epoch 14493, Loss: 0.005284108687192202, Neurons: 64, Grad norm: 2.091e-01\n",
      "Epoch 14494, Loss: 0.0052853538654744625, Neurons: 64, Grad norm: 3.400e-01\n",
      "Epoch 14494, Loss: 0.0052853538654744625, Neurons: 64, Grad norm: 3.400e-01\n",
      "Epoch 14495, Loss: 0.005289546214044094, Neurons: 64, Grad norm: 4.165e-01\n",
      "Epoch 14495, Loss: 0.005289546214044094, Neurons: 64, Grad norm: 4.165e-01\n",
      "Epoch 14496, Loss: 0.005293062888085842, Neurons: 64, Grad norm: 4.296e-01\n",
      "Epoch 14496, Loss: 0.005293062888085842, Neurons: 64, Grad norm: 4.296e-01\n",
      "Epoch 14497, Loss: 0.005293273366987705, Neurons: 64, Grad norm: 4.034e-01\n",
      "Epoch 14497, Loss: 0.005293273366987705, Neurons: 64, Grad norm: 4.034e-01\n",
      "Epoch 14498, Loss: 0.005290239118039608, Neurons: 64, Grad norm: 3.537e-01\n",
      "Epoch 14498, Loss: 0.005290239118039608, Neurons: 64, Grad norm: 3.537e-01\n",
      "Epoch 14499, Loss: 0.00528565002605319, Neurons: 64, Grad norm: 3.400e-01\n",
      "Epoch 14499, Loss: 0.00528565002605319, Neurons: 64, Grad norm: 3.400e-01\n",
      "Epoch 14499, Test loss: 0.004401598125696182\n",
      "Epoch 14499, Test loss: 0.004401598125696182\n",
      "Epoch 14500, Loss: 0.005281729158014059, Neurons: 64, Grad norm: 3.435e-01\n",
      "Epoch 14500, Loss: 0.005281729158014059, Neurons: 64, Grad norm: 3.435e-01\n",
      "Epoch 14501, Loss: 0.005279604345560074, Neurons: 64, Grad norm: 3.757e-01\n",
      "Epoch 14501, Loss: 0.005279604345560074, Neurons: 64, Grad norm: 3.757e-01\n",
      "Epoch 14502, Loss: 0.005279284901916981, Neurons: 64, Grad norm: 3.774e-01\n",
      "Epoch 14502, Loss: 0.005279284901916981, Neurons: 64, Grad norm: 3.774e-01\n",
      "Epoch 14503, Loss: 0.005279697012156248, Neurons: 64, Grad norm: 3.576e-01\n",
      "Epoch 14503, Loss: 0.005279697012156248, Neurons: 64, Grad norm: 3.576e-01\n",
      "Epoch 14504, Loss: 0.005279694218188524, Neurons: 64, Grad norm: 2.928e-01\n",
      "Epoch 14504, Loss: 0.005279694218188524, Neurons: 64, Grad norm: 2.928e-01\n",
      "Epoch 14505, Loss: 0.005278643686324358, Neurons: 64, Grad norm: 2.197e-01\n",
      "Epoch 14505, Loss: 0.005278643686324358, Neurons: 64, Grad norm: 2.197e-01\n",
      "Epoch 14506, Loss: 0.005276819691061974, Neurons: 64, Grad norm: 1.822e-01\n",
      "Epoch 14506, Loss: 0.005276819691061974, Neurons: 64, Grad norm: 1.822e-01\n",
      "Epoch 14507, Loss: 0.005274912342429161, Neurons: 64, Grad norm: 2.101e-01\n",
      "Epoch 14507, Loss: 0.005274912342429161, Neurons: 64, Grad norm: 2.101e-01\n",
      "Epoch 14508, Loss: 0.005273463670164347, Neurons: 64, Grad norm: 2.940e-01\n",
      "Epoch 14508, Loss: 0.005273463670164347, Neurons: 64, Grad norm: 2.940e-01\n",
      "Epoch 14509, Loss: 0.0052727824077010155, Neurons: 64, Grad norm: 3.520e-01\n",
      "Epoch 14509, Loss: 0.0052727824077010155, Neurons: 64, Grad norm: 3.520e-01\n",
      "Epoch 14510, Loss: 0.005272593814879656, Neurons: 64, Grad norm: 3.917e-01\n",
      "Epoch 14510, Loss: 0.005272593814879656, Neurons: 64, Grad norm: 3.917e-01\n",
      "Epoch 14511, Loss: 0.005272376351058483, Neurons: 64, Grad norm: 3.773e-01\n",
      "Epoch 14511, Loss: 0.005272376351058483, Neurons: 64, Grad norm: 3.773e-01\n",
      "Epoch 14512, Loss: 0.005271815229207277, Neurons: 64, Grad norm: 3.410e-01\n",
      "Epoch 14512, Loss: 0.005271815229207277, Neurons: 64, Grad norm: 3.410e-01\n",
      "Epoch 14513, Loss: 0.005270583555102348, Neurons: 64, Grad norm: 2.589e-01\n",
      "Epoch 14513, Loss: 0.005270583555102348, Neurons: 64, Grad norm: 2.589e-01\n",
      "Epoch 14514, Loss: 0.005269027315080166, Neurons: 64, Grad norm: 1.699e-01\n",
      "Epoch 14514, Loss: 0.005269027315080166, Neurons: 64, Grad norm: 1.699e-01\n",
      "Epoch 14515, Loss: 0.005267442669719458, Neurons: 64, Grad norm: 5.991e-02\n",
      "Epoch 14515, Loss: 0.005267442669719458, Neurons: 64, Grad norm: 5.991e-02\n",
      "Epoch 14516, Loss: 0.005266091786324978, Neurons: 64, Grad norm: 4.391e-02\n",
      "Epoch 14516, Loss: 0.005266091786324978, Neurons: 64, Grad norm: 4.391e-02\n",
      "Epoch 14517, Loss: 0.005265234969556332, Neurons: 64, Grad norm: 1.422e-01\n",
      "Epoch 14517, Loss: 0.005265234969556332, Neurons: 64, Grad norm: 1.422e-01\n",
      "Epoch 14518, Loss: 0.005264775361865759, Neurons: 64, Grad norm: 2.036e-01\n",
      "Epoch 14518, Loss: 0.005264775361865759, Neurons: 64, Grad norm: 2.036e-01\n",
      "Epoch 14519, Loss: 0.005264410749077797, Neurons: 64, Grad norm: 2.536e-01\n",
      "Epoch 14519, Loss: 0.005264410749077797, Neurons: 64, Grad norm: 2.536e-01\n",
      "Epoch 14520, Loss: 0.005264069885015488, Neurons: 64, Grad norm: 2.666e-01\n",
      "Epoch 14520, Loss: 0.005264069885015488, Neurons: 64, Grad norm: 2.666e-01\n",
      "Epoch 14521, Loss: 0.005263451486825943, Neurons: 64, Grad norm: 2.719e-01\n",
      "Epoch 14521, Loss: 0.005263451486825943, Neurons: 64, Grad norm: 2.719e-01\n",
      "Epoch 14522, Loss: 0.00526261143386364, Neurons: 64, Grad norm: 2.400e-01\n",
      "Epoch 14522, Loss: 0.00526261143386364, Neurons: 64, Grad norm: 2.400e-01\n",
      "Epoch 14523, Loss: 0.00526155112311244, Neurons: 64, Grad norm: 2.067e-01\n",
      "Epoch 14523, Loss: 0.00526155112311244, Neurons: 64, Grad norm: 2.067e-01\n",
      "Epoch 14524, Loss: 0.005260391626507044, Neurons: 64, Grad norm: 1.482e-01\n",
      "Epoch 14524, Loss: 0.005260391626507044, Neurons: 64, Grad norm: 1.482e-01\n",
      "Epoch 14525, Loss: 0.005259322468191385, Neurons: 64, Grad norm: 1.017e-01\n",
      "Epoch 14525, Loss: 0.005259322468191385, Neurons: 64, Grad norm: 1.017e-01\n",
      "Epoch 14526, Loss: 0.005258344579488039, Neurons: 64, Grad norm: 4.391e-02\n",
      "Epoch 14526, Loss: 0.005258344579488039, Neurons: 64, Grad norm: 4.391e-02\n",
      "Epoch 14527, Loss: 0.005257462617009878, Neurons: 64, Grad norm: 3.508e-02\n",
      "Epoch 14527, Loss: 0.005257462617009878, Neurons: 64, Grad norm: 3.508e-02\n",
      "Epoch 14528, Loss: 0.005256704520434141, Neurons: 64, Grad norm: 6.372e-02\n",
      "Epoch 14528, Loss: 0.005256704520434141, Neurons: 64, Grad norm: 6.372e-02\n",
      "Epoch 14529, Loss: 0.005255978088825941, Neurons: 64, Grad norm: 8.577e-02\n",
      "Epoch 14529, Loss: 0.005255978088825941, Neurons: 64, Grad norm: 8.577e-02\n",
      "Epoch 14530, Loss: 0.005255312193185091, Neurons: 64, Grad norm: 1.101e-01\n",
      "Epoch 14530, Loss: 0.005255312193185091, Neurons: 64, Grad norm: 1.101e-01\n",
      "Epoch 14531, Loss: 0.005254569463431835, Neurons: 64, Grad norm: 1.122e-01\n",
      "Epoch 14531, Loss: 0.005254569463431835, Neurons: 64, Grad norm: 1.122e-01\n",
      "Epoch 14532, Loss: 0.0052538178861141205, Neurons: 64, Grad norm: 1.192e-01\n",
      "Epoch 14532, Loss: 0.0052538178861141205, Neurons: 64, Grad norm: 1.192e-01\n",
      "Epoch 14533, Loss: 0.0052529689855873585, Neurons: 64, Grad norm: 1.052e-01\n",
      "Epoch 14533, Loss: 0.0052529689855873585, Neurons: 64, Grad norm: 1.052e-01\n",
      "Epoch 14534, Loss: 0.005252135451883078, Neurons: 64, Grad norm: 1.051e-01\n",
      "Epoch 14534, Loss: 0.005252135451883078, Neurons: 64, Grad norm: 1.051e-01\n",
      "Epoch 14535, Loss: 0.005251344759017229, Neurons: 64, Grad norm: 8.976e-02\n",
      "Epoch 14535, Loss: 0.005251344759017229, Neurons: 64, Grad norm: 8.976e-02\n",
      "Epoch 14536, Loss: 0.0052505419589579105, Neurons: 64, Grad norm: 9.194e-02\n",
      "Epoch 14536, Loss: 0.0052505419589579105, Neurons: 64, Grad norm: 9.194e-02\n",
      "Epoch 14537, Loss: 0.005249757319688797, Neurons: 64, Grad norm: 7.967e-02\n",
      "Epoch 14537, Loss: 0.005249757319688797, Neurons: 64, Grad norm: 7.967e-02\n",
      "Epoch 14538, Loss: 0.005249022506177425, Neurons: 64, Grad norm: 8.774e-02\n",
      "Epoch 14538, Loss: 0.005249022506177425, Neurons: 64, Grad norm: 8.774e-02\n",
      "Epoch 14539, Loss: 0.005248307250440121, Neurons: 64, Grad norm: 7.958e-02\n",
      "Epoch 14539, Loss: 0.005248307250440121, Neurons: 64, Grad norm: 7.958e-02\n",
      "Epoch 14540, Loss: 0.005247532390058041, Neurons: 64, Grad norm: 8.785e-02\n",
      "Epoch 14540, Loss: 0.005247532390058041, Neurons: 64, Grad norm: 8.785e-02\n",
      "Epoch 14541, Loss: 0.005246839020401239, Neurons: 64, Grad norm: 8.139e-02\n",
      "Epoch 14541, Loss: 0.005246839020401239, Neurons: 64, Grad norm: 8.139e-02\n",
      "Epoch 14542, Loss: 0.00524608138948679, Neurons: 64, Grad norm: 9.101e-02\n",
      "Epoch 14542, Loss: 0.00524608138948679, Neurons: 64, Grad norm: 9.101e-02\n",
      "Epoch 14543, Loss: 0.005245302338153124, Neurons: 64, Grad norm: 8.728e-02\n",
      "Epoch 14543, Loss: 0.005245302338153124, Neurons: 64, Grad norm: 8.728e-02\n",
      "Epoch 14544, Loss: 0.0052445512264966965, Neurons: 64, Grad norm: 9.476e-02\n",
      "Epoch 14544, Loss: 0.0052445512264966965, Neurons: 64, Grad norm: 9.476e-02\n",
      "Epoch 14545, Loss: 0.005243709776550531, Neurons: 64, Grad norm: 8.717e-02\n",
      "Epoch 14545, Loss: 0.005243709776550531, Neurons: 64, Grad norm: 8.717e-02\n",
      "Epoch 14546, Loss: 0.005242892540991306, Neurons: 64, Grad norm: 9.883e-02\n",
      "Epoch 14546, Loss: 0.005242892540991306, Neurons: 64, Grad norm: 9.883e-02\n",
      "Epoch 14547, Loss: 0.005242038983851671, Neurons: 64, Grad norm: 9.569e-02\n",
      "Epoch 14547, Loss: 0.005242038983851671, Neurons: 64, Grad norm: 9.569e-02\n",
      "Epoch 14548, Loss: 0.005241240840405226, Neurons: 64, Grad norm: 1.121e-01\n",
      "Epoch 14548, Loss: 0.005241240840405226, Neurons: 64, Grad norm: 1.121e-01\n",
      "Epoch 14549, Loss: 0.005240441299974918, Neurons: 64, Grad norm: 1.127e-01\n",
      "Epoch 14549, Loss: 0.005240441299974918, Neurons: 64, Grad norm: 1.127e-01\n",
      "Epoch 14550, Loss: 0.005239685997366905, Neurons: 64, Grad norm: 1.324e-01\n",
      "Epoch 14550, Loss: 0.005239685997366905, Neurons: 64, Grad norm: 1.324e-01\n",
      "Epoch 14551, Loss: 0.005238919984549284, Neurons: 64, Grad norm: 1.330e-01\n",
      "Epoch 14551, Loss: 0.005238919984549284, Neurons: 64, Grad norm: 1.330e-01\n",
      "Epoch 14552, Loss: 0.005238180514425039, Neurons: 64, Grad norm: 1.518e-01\n",
      "Epoch 14552, Loss: 0.005238180514425039, Neurons: 64, Grad norm: 1.518e-01\n",
      "Epoch 14553, Loss: 0.005237447563558817, Neurons: 64, Grad norm: 1.563e-01\n",
      "Epoch 14553, Loss: 0.005237447563558817, Neurons: 64, Grad norm: 1.563e-01\n",
      "Epoch 14554, Loss: 0.005236704368144274, Neurons: 64, Grad norm: 1.744e-01\n",
      "Epoch 14554, Loss: 0.005236704368144274, Neurons: 64, Grad norm: 1.744e-01\n",
      "Epoch 14555, Loss: 0.005235976539552212, Neurons: 64, Grad norm: 1.735e-01\n",
      "Epoch 14555, Loss: 0.005235976539552212, Neurons: 64, Grad norm: 1.735e-01\n",
      "Epoch 14556, Loss: 0.0052352347411215305, Neurons: 64, Grad norm: 1.943e-01\n",
      "Epoch 14556, Loss: 0.0052352347411215305, Neurons: 64, Grad norm: 1.943e-01\n",
      "Epoch 14557, Loss: 0.005234533455222845, Neurons: 64, Grad norm: 2.005e-01\n",
      "Epoch 14557, Loss: 0.005234533455222845, Neurons: 64, Grad norm: 2.005e-01\n",
      "Epoch 14558, Loss: 0.0052338712848722935, Neurons: 64, Grad norm: 2.222e-01\n",
      "Epoch 14558, Loss: 0.0052338712848722935, Neurons: 64, Grad norm: 2.222e-01\n",
      "Epoch 14559, Loss: 0.005233158357441425, Neurons: 64, Grad norm: 2.284e-01\n",
      "Epoch 14559, Loss: 0.005233158357441425, Neurons: 64, Grad norm: 2.284e-01\n",
      "Epoch 14560, Loss: 0.005232571624219418, Neurons: 64, Grad norm: 2.606e-01\n",
      "Epoch 14560, Loss: 0.005232571624219418, Neurons: 64, Grad norm: 2.606e-01\n",
      "Epoch 14561, Loss: 0.005232047289609909, Neurons: 64, Grad norm: 2.818e-01\n",
      "Epoch 14561, Loss: 0.005232047289609909, Neurons: 64, Grad norm: 2.818e-01\n",
      "Epoch 14562, Loss: 0.005231574177742004, Neurons: 64, Grad norm: 3.239e-01\n",
      "Epoch 14562, Loss: 0.005231574177742004, Neurons: 64, Grad norm: 3.239e-01\n",
      "Epoch 14563, Loss: 0.005231218412518501, Neurons: 64, Grad norm: 3.537e-01\n",
      "Epoch 14563, Loss: 0.005231218412518501, Neurons: 64, Grad norm: 3.537e-01\n",
      "Epoch 14564, Loss: 0.005230969749391079, Neurons: 64, Grad norm: 4.138e-01\n",
      "Epoch 14564, Loss: 0.005230969749391079, Neurons: 64, Grad norm: 4.138e-01\n",
      "Epoch 14565, Loss: 0.005230916664004326, Neurons: 64, Grad norm: 4.678e-01\n",
      "Epoch 14565, Loss: 0.005230916664004326, Neurons: 64, Grad norm: 4.678e-01\n",
      "Epoch 14566, Loss: 0.005231217015534639, Neurons: 64, Grad norm: 5.507e-01\n",
      "Epoch 14566, Loss: 0.005231217015534639, Neurons: 64, Grad norm: 5.507e-01\n",
      "Epoch 14567, Loss: 0.005231883376836777, Neurons: 64, Grad norm: 6.351e-01\n",
      "Epoch 14567, Loss: 0.005231883376836777, Neurons: 64, Grad norm: 6.351e-01\n",
      "Epoch 14568, Loss: 0.005233220290392637, Neurons: 64, Grad norm: 7.581e-01\n",
      "Epoch 14568, Loss: 0.005233220290392637, Neurons: 64, Grad norm: 7.581e-01\n",
      "Epoch 14569, Loss: 0.0052354102954268456, Neurons: 64, Grad norm: 8.865e-01\n",
      "Epoch 14569, Loss: 0.0052354102954268456, Neurons: 64, Grad norm: 8.865e-01\n",
      "Epoch 14570, Loss: 0.0052389404736459255, Neurons: 64, Grad norm: 1.062e+00\n",
      "Epoch 14570, Loss: 0.0052389404736459255, Neurons: 64, Grad norm: 1.062e+00\n",
      "Epoch 14571, Loss: 0.0052445558831095695, Neurons: 64, Grad norm: 1.255e+00\n",
      "Epoch 14571, Loss: 0.0052445558831095695, Neurons: 64, Grad norm: 1.255e+00\n",
      "Epoch 14572, Loss: 0.005252715200185776, Neurons: 64, Grad norm: 1.510e+00\n",
      "Epoch 14572, Loss: 0.005252715200185776, Neurons: 64, Grad norm: 1.510e+00\n",
      "Epoch 14573, Loss: 0.00526491878554225, Neurons: 64, Grad norm: 1.798e+00\n",
      "Epoch 14573, Loss: 0.00526491878554225, Neurons: 64, Grad norm: 1.798e+00\n",
      "Epoch 14574, Loss: 0.00528277363628149, Neurons: 64, Grad norm: 2.163e+00\n",
      "Epoch 14574, Loss: 0.00528277363628149, Neurons: 64, Grad norm: 2.163e+00\n",
      "Epoch 14575, Loss: 0.0053092120215296745, Neurons: 64, Grad norm: 2.590e+00\n",
      "Epoch 14575, Loss: 0.0053092120215296745, Neurons: 64, Grad norm: 2.590e+00\n",
      "Epoch 14576, Loss: 0.005347405094653368, Neurons: 64, Grad norm: 3.123e+00\n",
      "Epoch 14576, Loss: 0.005347405094653368, Neurons: 64, Grad norm: 3.123e+00\n",
      "Epoch 14577, Loss: 0.005402283743023872, Neurons: 64, Grad norm: 3.738e+00\n",
      "Epoch 14577, Loss: 0.005402283743023872, Neurons: 64, Grad norm: 3.738e+00\n",
      "Epoch 14578, Loss: 0.005480004474520683, Neurons: 64, Grad norm: 4.477e+00\n",
      "Epoch 14578, Loss: 0.005480004474520683, Neurons: 64, Grad norm: 4.477e+00\n",
      "Epoch 14579, Loss: 0.0055879512801766396, Neurons: 64, Grad norm: 5.304e+00\n",
      "Epoch 14579, Loss: 0.0055879512801766396, Neurons: 64, Grad norm: 5.304e+00\n",
      "Epoch 14580, Loss: 0.005732516758143902, Neurons: 64, Grad norm: 6.225e+00\n",
      "Epoch 14580, Loss: 0.005732516758143902, Neurons: 64, Grad norm: 6.225e+00\n",
      "Epoch 14581, Loss: 0.005916206631809473, Neurons: 64, Grad norm: 7.145e+00\n",
      "Epoch 14581, Loss: 0.005916206631809473, Neurons: 64, Grad norm: 7.145e+00\n",
      "Epoch 14582, Loss: 0.006127601023763418, Neurons: 64, Grad norm: 7.997e+00\n",
      "Epoch 14582, Loss: 0.006127601023763418, Neurons: 64, Grad norm: 7.997e+00\n",
      "Epoch 14583, Loss: 0.006335726007819176, Neurons: 64, Grad norm: 8.588e+00\n",
      "Epoch 14583, Loss: 0.006335726007819176, Neurons: 64, Grad norm: 8.588e+00\n",
      "Epoch 14584, Loss: 0.006482147146016359, Neurons: 64, Grad norm: 8.752e+00\n",
      "Epoch 14584, Loss: 0.006482147146016359, Neurons: 64, Grad norm: 8.752e+00\n",
      "Epoch 14585, Loss: 0.00649474561214447, Neurons: 64, Grad norm: 8.284e+00\n",
      "Epoch 14585, Loss: 0.00649474561214447, Neurons: 64, Grad norm: 8.284e+00\n",
      "Epoch 14586, Loss: 0.006328170653432608, Neurons: 64, Grad norm: 7.123e+00\n",
      "Epoch 14586, Loss: 0.006328170653432608, Neurons: 64, Grad norm: 7.123e+00\n",
      "Epoch 14587, Loss: 0.006006976589560509, Neurons: 64, Grad norm: 5.315e+00\n",
      "Epoch 14587, Loss: 0.006006976589560509, Neurons: 64, Grad norm: 5.315e+00\n",
      "Epoch 14588, Loss: 0.0056413100101053715, Neurons: 64, Grad norm: 3.140e+00\n",
      "Epoch 14588, Loss: 0.0056413100101053715, Neurons: 64, Grad norm: 3.140e+00\n",
      "Epoch 14589, Loss: 0.005366697441786528, Neurons: 64, Grad norm: 1.146e+00\n",
      "Epoch 14589, Loss: 0.005366697441786528, Neurons: 64, Grad norm: 1.146e+00\n",
      "Epoch 14590, Loss: 0.005266861990094185, Neurons: 64, Grad norm: 1.830e+00\n",
      "Epoch 14590, Loss: 0.005266861990094185, Neurons: 64, Grad norm: 1.830e+00\n",
      "Epoch 14591, Loss: 0.0053295595571398735, Neurons: 64, Grad norm: 3.433e+00\n",
      "Epoch 14591, Loss: 0.0053295595571398735, Neurons: 64, Grad norm: 3.433e+00\n",
      "Epoch 14592, Loss: 0.00546986423432827, Neurons: 64, Grad norm: 4.506e+00\n",
      "Epoch 14592, Loss: 0.00546986423432827, Neurons: 64, Grad norm: 4.506e+00\n",
      "Epoch 14593, Loss: 0.005586105398833752, Neurons: 64, Grad norm: 4.922e+00\n",
      "Epoch 14593, Loss: 0.005586105398833752, Neurons: 64, Grad norm: 4.922e+00\n",
      "Epoch 14594, Loss: 0.005611743312329054, Neurons: 64, Grad norm: 4.641e+00\n",
      "Epoch 14594, Loss: 0.005611743312329054, Neurons: 64, Grad norm: 4.641e+00\n",
      "Epoch 14595, Loss: 0.005541493650525808, Neurons: 64, Grad norm: 3.802e+00\n",
      "Epoch 14595, Loss: 0.005541493650525808, Neurons: 64, Grad norm: 3.802e+00\n",
      "Epoch 14596, Loss: 0.005423086229711771, Neurons: 64, Grad norm: 2.587e+00\n",
      "Epoch 14596, Loss: 0.005423086229711771, Neurons: 64, Grad norm: 2.587e+00\n",
      "Epoch 14597, Loss: 0.005321067292243242, Neurons: 64, Grad norm: 1.404e+00\n",
      "Epoch 14597, Loss: 0.005321067292243242, Neurons: 64, Grad norm: 1.404e+00\n",
      "Epoch 14598, Loss: 0.005275677889585495, Neurons: 64, Grad norm: 1.165e+00\n",
      "Epoch 14598, Loss: 0.005275677889585495, Neurons: 64, Grad norm: 1.165e+00\n",
      "Epoch 14599, Loss: 0.005285641178488731, Neurons: 64, Grad norm: 1.911e+00\n",
      "Epoch 14599, Loss: 0.005285641178488731, Neurons: 64, Grad norm: 1.911e+00\n",
      "Epoch 14599, Test loss: 0.004428933374583721\n",
      "Epoch 14599, Test loss: 0.004428933374583721\n",
      "Epoch 14600, Loss: 0.005319360177963972, Neurons: 64, Grad norm: 2.569e+00\n",
      "Epoch 14600, Loss: 0.005319360177963972, Neurons: 64, Grad norm: 2.569e+00\n",
      "Epoch 14601, Loss: 0.005342211574316025, Neurons: 64, Grad norm: 2.838e+00\n",
      "Epoch 14601, Loss: 0.005342211574316025, Neurons: 64, Grad norm: 2.838e+00\n",
      "Epoch 14602, Loss: 0.005338058806955814, Neurons: 64, Grad norm: 2.741e+00\n",
      "Epoch 14602, Loss: 0.005338058806955814, Neurons: 64, Grad norm: 2.741e+00\n",
      "Epoch 14603, Loss: 0.00531308026984334, Neurons: 64, Grad norm: 2.321e+00\n",
      "Epoch 14603, Loss: 0.00531308026984334, Neurons: 64, Grad norm: 2.321e+00\n",
      "Epoch 14604, Loss: 0.005284817889332771, Neurons: 64, Grad norm: 1.749e+00\n",
      "Epoch 14604, Loss: 0.005284817889332771, Neurons: 64, Grad norm: 1.749e+00\n",
      "Epoch 14605, Loss: 0.005266285967081785, Neurons: 64, Grad norm: 1.192e+00\n",
      "Epoch 14605, Loss: 0.005266285967081785, Neurons: 64, Grad norm: 1.192e+00\n",
      "Epoch 14606, Loss: 0.005259215831756592, Neurons: 64, Grad norm: 9.508e-01\n",
      "Epoch 14606, Loss: 0.005259215831756592, Neurons: 64, Grad norm: 9.508e-01\n",
      "Epoch 14607, Loss: 0.0052566551603376865, Neurons: 64, Grad norm: 1.111e+00\n",
      "Epoch 14607, Loss: 0.0052566551603376865, Neurons: 64, Grad norm: 1.111e+00\n",
      "Epoch 14608, Loss: 0.005251697730273008, Neurons: 64, Grad norm: 1.347e+00\n",
      "Epoch 14608, Loss: 0.005251697730273008, Neurons: 64, Grad norm: 1.347e+00\n",
      "Epoch 14609, Loss: 0.005241899751126766, Neurons: 64, Grad norm: 1.500e+00\n",
      "Epoch 14609, Loss: 0.005241899751126766, Neurons: 64, Grad norm: 1.500e+00\n",
      "Epoch 14610, Loss: 0.005231811664998531, Neurons: 64, Grad norm: 1.500e+00\n",
      "Epoch 14610, Loss: 0.005231811664998531, Neurons: 64, Grad norm: 1.500e+00\n",
      "Epoch 14611, Loss: 0.00522728031501174, Neurons: 64, Grad norm: 1.402e+00\n",
      "Epoch 14611, Loss: 0.00522728031501174, Neurons: 64, Grad norm: 1.402e+00\n",
      "Epoch 14612, Loss: 0.005229575093835592, Neurons: 64, Grad norm: 1.208e+00\n",
      "Epoch 14612, Loss: 0.005229575093835592, Neurons: 64, Grad norm: 1.208e+00\n",
      "Epoch 14613, Loss: 0.005234073847532272, Neurons: 64, Grad norm: 9.911e-01\n",
      "Epoch 14613, Loss: 0.005234073847532272, Neurons: 64, Grad norm: 9.911e-01\n",
      "Epoch 14614, Loss: 0.005234379321336746, Neurons: 64, Grad norm: 7.760e-01\n",
      "Epoch 14614, Loss: 0.005234379321336746, Neurons: 64, Grad norm: 7.760e-01\n",
      "Epoch 14615, Loss: 0.0052269501611590385, Neurons: 64, Grad norm: 6.090e-01\n",
      "Epoch 14615, Loss: 0.0052269501611590385, Neurons: 64, Grad norm: 6.090e-01\n",
      "Epoch 14616, Loss: 0.005213641561567783, Neurons: 64, Grad norm: 5.584e-01\n",
      "Epoch 14616, Loss: 0.005213641561567783, Neurons: 64, Grad norm: 5.584e-01\n",
      "Epoch 14617, Loss: 0.005200604908168316, Neurons: 64, Grad norm: 6.096e-01\n",
      "Epoch 14617, Loss: 0.005200604908168316, Neurons: 64, Grad norm: 6.096e-01\n",
      "Epoch 14618, Loss: 0.005193978548049927, Neurons: 64, Grad norm: 7.216e-01\n",
      "Epoch 14618, Loss: 0.005193978548049927, Neurons: 64, Grad norm: 7.216e-01\n",
      "Epoch 14619, Loss: 0.005195646081119776, Neurons: 64, Grad norm: 8.002e-01\n",
      "Epoch 14619, Loss: 0.005195646081119776, Neurons: 64, Grad norm: 8.002e-01\n",
      "Epoch 14620, Loss: 0.005202587228268385, Neurons: 64, Grad norm: 8.346e-01\n",
      "Epoch 14620, Loss: 0.005202587228268385, Neurons: 64, Grad norm: 8.346e-01\n",
      "Epoch 14621, Loss: 0.005209038965404034, Neurons: 64, Grad norm: 7.866e-01\n",
      "Epoch 14621, Loss: 0.005209038965404034, Neurons: 64, Grad norm: 7.866e-01\n",
      "Epoch 14622, Loss: 0.005210539326071739, Neurons: 64, Grad norm: 6.755e-01\n",
      "Epoch 14622, Loss: 0.005210539326071739, Neurons: 64, Grad norm: 6.755e-01\n",
      "Epoch 14623, Loss: 0.005205368157476187, Neurons: 64, Grad norm: 4.986e-01\n",
      "Epoch 14623, Loss: 0.005205368157476187, Neurons: 64, Grad norm: 4.986e-01\n",
      "Epoch 14624, Loss: 0.005196295212954283, Neurons: 64, Grad norm: 2.873e-01\n",
      "Epoch 14624, Loss: 0.005196295212954283, Neurons: 64, Grad norm: 2.873e-01\n",
      "Epoch 14625, Loss: 0.005187273491173983, Neurons: 64, Grad norm: 9.103e-02\n",
      "Epoch 14625, Loss: 0.005187273491173983, Neurons: 64, Grad norm: 9.103e-02\n",
      "Epoch 14626, Loss: 0.005182044114917517, Neurons: 64, Grad norm: 1.771e-01\n",
      "Epoch 14626, Loss: 0.005182044114917517, Neurons: 64, Grad norm: 1.771e-01\n",
      "Epoch 14627, Loss: 0.0051818531937897205, Neurons: 64, Grad norm: 3.472e-01\n",
      "Epoch 14627, Loss: 0.0051818531937897205, Neurons: 64, Grad norm: 3.472e-01\n",
      "Epoch 14628, Loss: 0.005185084417462349, Neurons: 64, Grad norm: 4.613e-01\n",
      "Epoch 14628, Loss: 0.005185084417462349, Neurons: 64, Grad norm: 4.613e-01\n",
      "Epoch 14629, Loss: 0.005188739392906427, Neurons: 64, Grad norm: 5.199e-01\n",
      "Epoch 14629, Loss: 0.005188739392906427, Neurons: 64, Grad norm: 5.199e-01\n",
      "Epoch 14630, Loss: 0.005190243944525719, Neurons: 64, Grad norm: 5.084e-01\n",
      "Epoch 14630, Loss: 0.005190243944525719, Neurons: 64, Grad norm: 5.084e-01\n",
      "Epoch 14631, Loss: 0.005188636016100645, Neurons: 64, Grad norm: 4.555e-01\n",
      "Epoch 14631, Loss: 0.005188636016100645, Neurons: 64, Grad norm: 4.555e-01\n",
      "Epoch 14632, Loss: 0.005184757988899946, Neurons: 64, Grad norm: 3.610e-01\n",
      "Epoch 14632, Loss: 0.005184757988899946, Neurons: 64, Grad norm: 3.610e-01\n",
      "Epoch 14633, Loss: 0.005180345848202705, Neurons: 64, Grad norm: 2.678e-01\n",
      "Epoch 14633, Loss: 0.005180345848202705, Neurons: 64, Grad norm: 2.678e-01\n",
      "Epoch 14634, Loss: 0.00517698610201478, Neurons: 64, Grad norm: 1.812e-01\n",
      "Epoch 14634, Loss: 0.00517698610201478, Neurons: 64, Grad norm: 1.812e-01\n",
      "Epoch 14635, Loss: 0.005175489466637373, Neurons: 64, Grad norm: 1.704e-01\n",
      "Epoch 14635, Loss: 0.005175489466637373, Neurons: 64, Grad norm: 1.704e-01\n",
      "Epoch 14636, Loss: 0.0051755039021372795, Neurons: 64, Grad norm: 2.008e-01\n",
      "Epoch 14636, Loss: 0.0051755039021372795, Neurons: 64, Grad norm: 2.008e-01\n",
      "Epoch 14637, Loss: 0.00517613859847188, Neurons: 64, Grad norm: 2.462e-01\n",
      "Epoch 14637, Loss: 0.00517613859847188, Neurons: 64, Grad norm: 2.462e-01\n",
      "Epoch 14638, Loss: 0.005176462233066559, Neurons: 64, Grad norm: 2.799e-01\n",
      "Epoch 14638, Loss: 0.005176462233066559, Neurons: 64, Grad norm: 2.799e-01\n",
      "Epoch 14639, Loss: 0.00517594488337636, Neurons: 64, Grad norm: 2.964e-01\n",
      "Epoch 14639, Loss: 0.00517594488337636, Neurons: 64, Grad norm: 2.964e-01\n",
      "Epoch 14640, Loss: 0.005174661986529827, Neurons: 64, Grad norm: 3.105e-01\n",
      "Epoch 14640, Loss: 0.005174661986529827, Neurons: 64, Grad norm: 3.105e-01\n",
      "Epoch 14641, Loss: 0.005173041485249996, Neurons: 64, Grad norm: 3.064e-01\n",
      "Epoch 14641, Loss: 0.005173041485249996, Neurons: 64, Grad norm: 3.064e-01\n",
      "Epoch 14642, Loss: 0.005171560682356358, Neurons: 64, Grad norm: 3.109e-01\n",
      "Epoch 14642, Loss: 0.005171560682356358, Neurons: 64, Grad norm: 3.109e-01\n",
      "Epoch 14643, Loss: 0.005170398857444525, Neurons: 64, Grad norm: 2.894e-01\n",
      "Epoch 14643, Loss: 0.005170398857444525, Neurons: 64, Grad norm: 2.894e-01\n",
      "Epoch 14644, Loss: 0.0051695420406758785, Neurons: 64, Grad norm: 2.725e-01\n",
      "Epoch 14644, Loss: 0.0051695420406758785, Neurons: 64, Grad norm: 2.725e-01\n",
      "Epoch 14645, Loss: 0.005168819800019264, Neurons: 64, Grad norm: 2.294e-01\n",
      "Epoch 14645, Loss: 0.005168819800019264, Neurons: 64, Grad norm: 2.294e-01\n",
      "Epoch 14646, Loss: 0.005168113857507706, Neurons: 64, Grad norm: 1.962e-01\n",
      "Epoch 14646, Loss: 0.005168113857507706, Neurons: 64, Grad norm: 1.962e-01\n",
      "Epoch 14647, Loss: 0.005167341325432062, Neurons: 64, Grad norm: 1.428e-01\n",
      "Epoch 14647, Loss: 0.005167341325432062, Neurons: 64, Grad norm: 1.428e-01\n",
      "Epoch 14648, Loss: 0.005166381131857634, Neurons: 64, Grad norm: 1.146e-01\n",
      "Epoch 14648, Loss: 0.005166381131857634, Neurons: 64, Grad norm: 1.146e-01\n",
      "Epoch 14649, Loss: 0.0051653203554451466, Neurons: 64, Grad norm: 1.150e-01\n",
      "Epoch 14649, Loss: 0.0051653203554451466, Neurons: 64, Grad norm: 1.150e-01\n",
      "Epoch 14650, Loss: 0.005164274480193853, Neurons: 64, Grad norm: 1.417e-01\n",
      "Epoch 14650, Loss: 0.005164274480193853, Neurons: 64, Grad norm: 1.417e-01\n",
      "Epoch 14651, Loss: 0.005163433030247688, Neurons: 64, Grad norm: 1.917e-01\n",
      "Epoch 14651, Loss: 0.005163433030247688, Neurons: 64, Grad norm: 1.917e-01\n",
      "Epoch 14652, Loss: 0.005162776913493872, Neurons: 64, Grad norm: 2.205e-01\n",
      "Epoch 14652, Loss: 0.005162776913493872, Neurons: 64, Grad norm: 2.205e-01\n",
      "Epoch 14653, Loss: 0.00516219437122345, Neurons: 64, Grad norm: 2.521e-01\n",
      "Epoch 14653, Loss: 0.00516219437122345, Neurons: 64, Grad norm: 2.521e-01\n",
      "Epoch 14654, Loss: 0.005161728244274855, Neurons: 64, Grad norm: 2.513e-01\n",
      "Epoch 14654, Loss: 0.005161728244274855, Neurons: 64, Grad norm: 2.513e-01\n",
      "Epoch 14655, Loss: 0.005161144305020571, Neurons: 64, Grad norm: 2.539e-01\n",
      "Epoch 14655, Loss: 0.005161144305020571, Neurons: 64, Grad norm: 2.539e-01\n",
      "Epoch 14656, Loss: 0.005160393659025431, Neurons: 64, Grad norm: 2.218e-01\n",
      "Epoch 14656, Loss: 0.005160393659025431, Neurons: 64, Grad norm: 2.218e-01\n",
      "Epoch 14657, Loss: 0.005159485619515181, Neurons: 64, Grad norm: 1.966e-01\n",
      "Epoch 14657, Loss: 0.005159485619515181, Neurons: 64, Grad norm: 1.966e-01\n",
      "Epoch 14658, Loss: 0.00515852402895689, Neurons: 64, Grad norm: 1.472e-01\n",
      "Epoch 14658, Loss: 0.00515852402895689, Neurons: 64, Grad norm: 1.472e-01\n",
      "Epoch 14659, Loss: 0.005157460458576679, Neurons: 64, Grad norm: 1.083e-01\n",
      "Epoch 14659, Loss: 0.005157460458576679, Neurons: 64, Grad norm: 1.083e-01\n",
      "Epoch 14660, Loss: 0.005156483966857195, Neurons: 64, Grad norm: 4.959e-02\n",
      "Epoch 14660, Loss: 0.005156483966857195, Neurons: 64, Grad norm: 4.959e-02\n",
      "Epoch 14661, Loss: 0.0051555573008954525, Neurons: 64, Grad norm: 1.706e-02\n",
      "Epoch 14661, Loss: 0.0051555573008954525, Neurons: 64, Grad norm: 1.706e-02\n",
      "Epoch 14662, Loss: 0.005154758226126432, Neurons: 64, Grad norm: 4.551e-02\n",
      "Epoch 14662, Loss: 0.005154758226126432, Neurons: 64, Grad norm: 4.551e-02\n",
      "Epoch 14663, Loss: 0.005154029931873083, Neurons: 64, Grad norm: 7.272e-02\n",
      "Epoch 14663, Loss: 0.005154029931873083, Neurons: 64, Grad norm: 7.272e-02\n",
      "Epoch 14664, Loss: 0.005153354723006487, Neurons: 64, Grad norm: 1.161e-01\n",
      "Epoch 14664, Loss: 0.005153354723006487, Neurons: 64, Grad norm: 1.161e-01\n",
      "Epoch 14665, Loss: 0.005152716301381588, Neurons: 64, Grad norm: 1.323e-01\n",
      "Epoch 14665, Loss: 0.005152716301381588, Neurons: 64, Grad norm: 1.323e-01\n",
      "Epoch 14666, Loss: 0.005152119789272547, Neurons: 64, Grad norm: 1.576e-01\n",
      "Epoch 14666, Loss: 0.005152119789272547, Neurons: 64, Grad norm: 1.576e-01\n",
      "Epoch 14667, Loss: 0.005151432007551193, Neurons: 64, Grad norm: 1.570e-01\n",
      "Epoch 14667, Loss: 0.005151432007551193, Neurons: 64, Grad norm: 1.570e-01\n",
      "Epoch 14668, Loss: 0.005150729324668646, Neurons: 64, Grad norm: 1.679e-01\n",
      "Epoch 14668, Loss: 0.005150729324668646, Neurons: 64, Grad norm: 1.679e-01\n",
      "Epoch 14669, Loss: 0.00514996750280261, Neurons: 64, Grad norm: 1.564e-01\n",
      "Epoch 14669, Loss: 0.00514996750280261, Neurons: 64, Grad norm: 1.564e-01\n",
      "Epoch 14670, Loss: 0.0051491823978722095, Neurons: 64, Grad norm: 1.554e-01\n",
      "Epoch 14670, Loss: 0.0051491823978722095, Neurons: 64, Grad norm: 1.554e-01\n",
      "Epoch 14671, Loss: 0.005148382857441902, Neurons: 64, Grad norm: 1.339e-01\n",
      "Epoch 14671, Loss: 0.005148382857441902, Neurons: 64, Grad norm: 1.339e-01\n",
      "Epoch 14672, Loss: 0.005147553980350494, Neurons: 64, Grad norm: 1.277e-01\n",
      "Epoch 14672, Loss: 0.005147553980350494, Neurons: 64, Grad norm: 1.277e-01\n",
      "Epoch 14673, Loss: 0.005146759562194347, Neurons: 64, Grad norm: 1.026e-01\n",
      "Epoch 14673, Loss: 0.005146759562194347, Neurons: 64, Grad norm: 1.026e-01\n",
      "Epoch 14674, Loss: 0.00514596002176404, Neurons: 64, Grad norm: 9.449e-02\n",
      "Epoch 14674, Loss: 0.00514596002176404, Neurons: 64, Grad norm: 9.449e-02\n",
      "Epoch 14675, Loss: 0.005145184695720673, Neurons: 64, Grad norm: 7.382e-02\n",
      "Epoch 14675, Loss: 0.005145184695720673, Neurons: 64, Grad norm: 7.382e-02\n",
      "Epoch 14676, Loss: 0.005144419614225626, Neurons: 64, Grad norm: 6.795e-02\n",
      "Epoch 14676, Loss: 0.005144419614225626, Neurons: 64, Grad norm: 6.795e-02\n",
      "Epoch 14677, Loss: 0.00514362333342433, Neurons: 64, Grad norm: 5.338e-02\n",
      "Epoch 14677, Loss: 0.00514362333342433, Neurons: 64, Grad norm: 5.338e-02\n",
      "Epoch 14678, Loss: 0.005142890382558107, Neurons: 64, Grad norm: 4.957e-02\n",
      "Epoch 14678, Loss: 0.005142890382558107, Neurons: 64, Grad norm: 4.957e-02\n",
      "Epoch 14679, Loss: 0.005142116919159889, Neurons: 64, Grad norm: 4.347e-02\n",
      "Epoch 14679, Loss: 0.005142116919159889, Neurons: 64, Grad norm: 4.347e-02\n",
      "Epoch 14680, Loss: 0.005141394678503275, Neurons: 64, Grad norm: 3.993e-02\n",
      "Epoch 14680, Loss: 0.005141394678503275, Neurons: 64, Grad norm: 3.993e-02\n",
      "Epoch 14681, Loss: 0.005140573717653751, Neurons: 64, Grad norm: 3.624e-02\n",
      "Epoch 14681, Loss: 0.005140573717653751, Neurons: 64, Grad norm: 3.624e-02\n",
      "Epoch 14682, Loss: 0.005139871034771204, Neurons: 64, Grad norm: 2.910e-02\n",
      "Epoch 14682, Loss: 0.005139871034771204, Neurons: 64, Grad norm: 2.910e-02\n",
      "Epoch 14683, Loss: 0.005139080807566643, Neurons: 64, Grad norm: 2.407e-02\n",
      "Epoch 14683, Loss: 0.005139080807566643, Neurons: 64, Grad norm: 2.407e-02\n",
      "Epoch 14684, Loss: 0.005138316657394171, Neurons: 64, Grad norm: 1.691e-02\n",
      "Epoch 14684, Loss: 0.005138316657394171, Neurons: 64, Grad norm: 1.691e-02\n",
      "Epoch 14685, Loss: 0.0051375278271734715, Neurons: 64, Grad norm: 1.142e-02\n",
      "Epoch 14685, Loss: 0.0051375278271734715, Neurons: 64, Grad norm: 1.142e-02\n",
      "Epoch 14686, Loss: 0.005136758554726839, Neurons: 64, Grad norm: 1.283e-02\n",
      "Epoch 14686, Loss: 0.005136758554726839, Neurons: 64, Grad norm: 1.283e-02\n",
      "Epoch 14687, Loss: 0.005136019084602594, Neurons: 64, Grad norm: 7.884e-03\n",
      "Epoch 14687, Loss: 0.005136019084602594, Neurons: 64, Grad norm: 7.884e-03\n",
      "Epoch 14688, Loss: 0.005135285668075085, Neurons: 64, Grad norm: 1.690e-02\n",
      "Epoch 14688, Loss: 0.005135285668075085, Neurons: 64, Grad norm: 1.690e-02\n",
      "Epoch 14689, Loss: 0.005134545732289553, Neurons: 64, Grad norm: 1.213e-02\n",
      "Epoch 14689, Loss: 0.005134545732289553, Neurons: 64, Grad norm: 1.213e-02\n",
      "Epoch 14690, Loss: 0.00513380067422986, Neurons: 64, Grad norm: 1.665e-02\n",
      "Epoch 14690, Loss: 0.00513380067422986, Neurons: 64, Grad norm: 1.665e-02\n",
      "Epoch 14691, Loss: 0.005133006721735001, Neurons: 64, Grad norm: 1.786e-02\n",
      "Epoch 14691, Loss: 0.005133006721735001, Neurons: 64, Grad norm: 1.786e-02\n",
      "Epoch 14692, Loss: 0.005132278427481651, Neurons: 64, Grad norm: 1.949e-02\n",
      "Epoch 14692, Loss: 0.005132278427481651, Neurons: 64, Grad norm: 1.949e-02\n",
      "Epoch 14693, Loss: 0.005131556652486324, Neurons: 64, Grad norm: 3.034e-02\n",
      "Epoch 14693, Loss: 0.005131556652486324, Neurons: 64, Grad norm: 3.034e-02\n",
      "Epoch 14694, Loss: 0.00513080507516861, Neurons: 64, Grad norm: 3.236e-02\n",
      "Epoch 14694, Loss: 0.00513080507516861, Neurons: 64, Grad norm: 3.236e-02\n",
      "Epoch 14695, Loss: 0.005130042787641287, Neurons: 64, Grad norm: 4.365e-02\n",
      "Epoch 14695, Loss: 0.005130042787641287, Neurons: 64, Grad norm: 4.365e-02\n",
      "Epoch 14696, Loss: 0.005129310768097639, Neurons: 64, Grad norm: 4.594e-02\n",
      "Epoch 14696, Loss: 0.005129310768097639, Neurons: 64, Grad norm: 4.594e-02\n",
      "Epoch 14697, Loss: 0.005128593649715185, Neurons: 64, Grad norm: 6.123e-02\n",
      "Epoch 14697, Loss: 0.005128593649715185, Neurons: 64, Grad norm: 6.123e-02\n",
      "Epoch 14698, Loss: 0.005127882584929466, Neurons: 64, Grad norm: 6.698e-02\n",
      "Epoch 14698, Loss: 0.005127882584929466, Neurons: 64, Grad norm: 6.698e-02\n",
      "Epoch 14699, Loss: 0.0051271189004182816, Neurons: 64, Grad norm: 8.391e-02\n",
      "Epoch 14699, Loss: 0.0051271189004182816, Neurons: 64, Grad norm: 8.391e-02\n",
      "Epoch 14699, Test loss: 0.0042862980626523495\n",
      "Epoch 14699, Test loss: 0.0042862980626523495\n",
      "Epoch 14700, Loss: 0.0051263924688100815, Neurons: 64, Grad norm: 8.831e-02\n",
      "Epoch 14700, Loss: 0.0051263924688100815, Neurons: 64, Grad norm: 8.831e-02\n",
      "Epoch 14701, Loss: 0.005125689785927534, Neurons: 64, Grad norm: 1.105e-01\n",
      "Epoch 14701, Loss: 0.005125689785927534, Neurons: 64, Grad norm: 1.105e-01\n",
      "Epoch 14702, Loss: 0.005124938674271107, Neurons: 64, Grad norm: 1.183e-01\n",
      "Epoch 14702, Loss: 0.005124938674271107, Neurons: 64, Grad norm: 1.183e-01\n",
      "Epoch 14703, Loss: 0.005124296527355909, Neurons: 64, Grad norm: 1.448e-01\n",
      "Epoch 14703, Loss: 0.005124296527355909, Neurons: 64, Grad norm: 1.448e-01\n",
      "Epoch 14704, Loss: 0.005123632028698921, Neurons: 64, Grad norm: 1.632e-01\n",
      "Epoch 14704, Loss: 0.005123632028698921, Neurons: 64, Grad norm: 1.632e-01\n",
      "Epoch 14705, Loss: 0.005122995004057884, Neurons: 64, Grad norm: 2.004e-01\n",
      "Epoch 14705, Loss: 0.005122995004057884, Neurons: 64, Grad norm: 2.004e-01\n",
      "Epoch 14706, Loss: 0.005122387316077948, Neurons: 64, Grad norm: 2.316e-01\n",
      "Epoch 14706, Loss: 0.005122387316077948, Neurons: 64, Grad norm: 2.316e-01\n",
      "Epoch 14707, Loss: 0.0051219468005001545, Neurons: 64, Grad norm: 2.895e-01\n",
      "Epoch 14707, Loss: 0.0051219468005001545, Neurons: 64, Grad norm: 2.895e-01\n",
      "Epoch 14708, Loss: 0.0051216548308730125, Neurons: 64, Grad norm: 3.412e-01\n",
      "Epoch 14708, Loss: 0.0051216548308730125, Neurons: 64, Grad norm: 3.412e-01\n",
      "Epoch 14709, Loss: 0.005121552385389805, Neurons: 64, Grad norm: 4.238e-01\n",
      "Epoch 14709, Loss: 0.005121552385389805, Neurons: 64, Grad norm: 4.238e-01\n",
      "Epoch 14710, Loss: 0.005121884401887655, Neurons: 64, Grad norm: 5.081e-01\n",
      "Epoch 14710, Loss: 0.005121884401887655, Neurons: 64, Grad norm: 5.081e-01\n",
      "Epoch 14711, Loss: 0.005122613627463579, Neurons: 64, Grad norm: 6.286e-01\n",
      "Epoch 14711, Loss: 0.005122613627463579, Neurons: 64, Grad norm: 6.286e-01\n",
      "Epoch 14712, Loss: 0.00512410793453455, Neurons: 64, Grad norm: 7.667e-01\n",
      "Epoch 14712, Loss: 0.00512410793453455, Neurons: 64, Grad norm: 7.667e-01\n",
      "Epoch 14713, Loss: 0.005126790143549442, Neurons: 64, Grad norm: 9.549e-01\n",
      "Epoch 14713, Loss: 0.005126790143549442, Neurons: 64, Grad norm: 9.549e-01\n",
      "Epoch 14714, Loss: 0.005131206009536982, Neurons: 64, Grad norm: 1.172e+00\n",
      "Epoch 14714, Loss: 0.005131206009536982, Neurons: 64, Grad norm: 1.172e+00\n",
      "Epoch 14715, Loss: 0.005138522945344448, Neurons: 64, Grad norm: 1.467e+00\n",
      "Epoch 14715, Loss: 0.005138522945344448, Neurons: 64, Grad norm: 1.467e+00\n",
      "Epoch 14716, Loss: 0.005150258541107178, Neurons: 64, Grad norm: 1.820e+00\n",
      "Epoch 14716, Loss: 0.005150258541107178, Neurons: 64, Grad norm: 1.820e+00\n",
      "Epoch 14717, Loss: 0.0051692514680325985, Neurons: 64, Grad norm: 2.282e+00\n",
      "Epoch 14717, Loss: 0.0051692514680325985, Neurons: 64, Grad norm: 2.282e+00\n",
      "Epoch 14718, Loss: 0.0051991138607263565, Neurons: 64, Grad norm: 2.843e+00\n",
      "Epoch 14718, Loss: 0.0051991138607263565, Neurons: 64, Grad norm: 2.843e+00\n",
      "Epoch 14719, Loss: 0.005246223881840706, Neurons: 64, Grad norm: 3.557e+00\n",
      "Epoch 14719, Loss: 0.005246223881840706, Neurons: 64, Grad norm: 3.557e+00\n",
      "Epoch 14720, Loss: 0.005319472402334213, Neurons: 64, Grad norm: 4.419e+00\n",
      "Epoch 14720, Loss: 0.005319472402334213, Neurons: 64, Grad norm: 4.419e+00\n",
      "Epoch 14721, Loss: 0.0054322765208780766, Neurons: 64, Grad norm: 5.478e+00\n",
      "Epoch 14721, Loss: 0.0054322765208780766, Neurons: 64, Grad norm: 5.478e+00\n",
      "Epoch 14722, Loss: 0.005600069183856249, Neurons: 64, Grad norm: 6.699e+00\n",
      "Epoch 14722, Loss: 0.005600069183856249, Neurons: 64, Grad norm: 6.699e+00\n",
      "Epoch 14723, Loss: 0.005841254722326994, Neurons: 64, Grad norm: 8.066e+00\n",
      "Epoch 14723, Loss: 0.005841254722326994, Neurons: 64, Grad norm: 8.066e+00\n",
      "Epoch 14724, Loss: 0.0061599258333444595, Neurons: 64, Grad norm: 9.420e+00\n",
      "Epoch 14724, Loss: 0.0061599258333444595, Neurons: 64, Grad norm: 9.420e+00\n",
      "Epoch 14725, Loss: 0.006536449305713177, Neurons: 64, Grad norm: 1.054e+01\n",
      "Epoch 14725, Loss: 0.006536449305713177, Neurons: 64, Grad norm: 1.054e+01\n",
      "Epoch 14726, Loss: 0.006876568775624037, Neurons: 64, Grad norm: 1.105e+01\n",
      "Epoch 14726, Loss: 0.006876568775624037, Neurons: 64, Grad norm: 1.105e+01\n",
      "Epoch 14727, Loss: 0.007035027723759413, Neurons: 64, Grad norm: 1.058e+01\n",
      "Epoch 14727, Loss: 0.007035027723759413, Neurons: 64, Grad norm: 1.058e+01\n",
      "Epoch 14728, Loss: 0.006844786927103996, Neurons: 64, Grad norm: 8.880e+00\n",
      "Epoch 14728, Loss: 0.006844786927103996, Neurons: 64, Grad norm: 8.880e+00\n",
      "Epoch 14729, Loss: 0.0063156080432236195, Neurons: 64, Grad norm: 6.103e+00\n",
      "Epoch 14729, Loss: 0.0063156080432236195, Neurons: 64, Grad norm: 6.103e+00\n",
      "Epoch 14730, Loss: 0.005678737536072731, Neurons: 64, Grad norm: 2.812e+00\n",
      "Epoch 14730, Loss: 0.005678737536072731, Neurons: 64, Grad norm: 2.812e+00\n",
      "Epoch 14731, Loss: 0.005275404080748558, Neurons: 64, Grad norm: 1.721e+00\n",
      "Epoch 14731, Loss: 0.005275404080748558, Neurons: 64, Grad norm: 1.721e+00\n",
      "Epoch 14732, Loss: 0.005267238710075617, Neurons: 64, Grad norm: 4.121e+00\n",
      "Epoch 14732, Loss: 0.005267238710075617, Neurons: 64, Grad norm: 4.121e+00\n",
      "Epoch 14733, Loss: 0.005530162248760462, Neurons: 64, Grad norm: 5.803e+00\n",
      "Epoch 14733, Loss: 0.005530162248760462, Neurons: 64, Grad norm: 5.803e+00\n",
      "Epoch 14734, Loss: 0.005781358107924461, Neurons: 64, Grad norm: 6.207e+00\n",
      "Epoch 14734, Loss: 0.005781358107924461, Neurons: 64, Grad norm: 6.207e+00\n",
      "Epoch 14735, Loss: 0.005790501832962036, Neurons: 64, Grad norm: 5.292e+00\n",
      "Epoch 14735, Loss: 0.005790501832962036, Neurons: 64, Grad norm: 5.292e+00\n",
      "Epoch 14736, Loss: 0.005555754993110895, Neurons: 64, Grad norm: 3.433e+00\n",
      "Epoch 14736, Loss: 0.005555754993110895, Neurons: 64, Grad norm: 3.433e+00\n",
      "Epoch 14737, Loss: 0.005279581993818283, Neurons: 64, Grad norm: 1.459e+00\n",
      "Epoch 14737, Loss: 0.005279581993818283, Neurons: 64, Grad norm: 1.459e+00\n",
      "Epoch 14738, Loss: 0.005176592152565718, Neurons: 64, Grad norm: 1.878e+00\n",
      "Epoch 14738, Loss: 0.005176592152565718, Neurons: 64, Grad norm: 1.878e+00\n",
      "Epoch 14739, Loss: 0.005278089549392462, Neurons: 64, Grad norm: 3.226e+00\n",
      "Epoch 14739, Loss: 0.005278089549392462, Neurons: 64, Grad norm: 3.226e+00\n",
      "Epoch 14740, Loss: 0.005432916805148125, Neurons: 64, Grad norm: 3.767e+00\n",
      "Epoch 14740, Loss: 0.005432916805148125, Neurons: 64, Grad norm: 3.767e+00\n",
      "Epoch 14741, Loss: 0.005466710776090622, Neurons: 64, Grad norm: 3.350e+00\n",
      "Epoch 14741, Loss: 0.005466710776090622, Neurons: 64, Grad norm: 3.350e+00\n",
      "Epoch 14742, Loss: 0.0053406888619065285, Neurons: 64, Grad norm: 2.158e+00\n",
      "Epoch 14742, Loss: 0.0053406888619065285, Neurons: 64, Grad norm: 2.158e+00\n",
      "Epoch 14743, Loss: 0.005175167229026556, Neurons: 64, Grad norm: 8.366e-01\n",
      "Epoch 14743, Loss: 0.005175167229026556, Neurons: 64, Grad norm: 8.366e-01\n",
      "Epoch 14744, Loss: 0.0051137232221663, Neurons: 64, Grad norm: 1.276e+00\n",
      "Epoch 14744, Loss: 0.0051137232221663, Neurons: 64, Grad norm: 1.276e+00\n",
      "Epoch 14745, Loss: 0.0051825037226080894, Neurons: 64, Grad norm: 2.178e+00\n",
      "Epoch 14745, Loss: 0.0051825037226080894, Neurons: 64, Grad norm: 2.178e+00\n",
      "Epoch 14746, Loss: 0.00528356060385704, Neurons: 64, Grad norm: 2.452e+00\n",
      "Epoch 14746, Loss: 0.00528356060385704, Neurons: 64, Grad norm: 2.452e+00\n",
      "Epoch 14747, Loss: 0.005304405465722084, Neurons: 64, Grad norm: 2.023e+00\n",
      "Epoch 14747, Loss: 0.005304405465722084, Neurons: 64, Grad norm: 2.023e+00\n",
      "Epoch 14748, Loss: 0.005225002765655518, Neurons: 64, Grad norm: 1.088e+00\n",
      "Epoch 14748, Loss: 0.005225002765655518, Neurons: 64, Grad norm: 1.088e+00\n",
      "Epoch 14749, Loss: 0.005124527961015701, Neurons: 64, Grad norm: 1.380e-01\n",
      "Epoch 14749, Loss: 0.005124527961015701, Neurons: 64, Grad norm: 1.380e-01\n",
      "Epoch 14750, Loss: 0.005091176368296146, Neurons: 64, Grad norm: 1.091e+00\n",
      "Epoch 14750, Loss: 0.005091176368296146, Neurons: 64, Grad norm: 1.091e+00\n",
      "Epoch 14751, Loss: 0.005135484971106052, Neurons: 64, Grad norm: 1.692e+00\n",
      "Epoch 14751, Loss: 0.005135484971106052, Neurons: 64, Grad norm: 1.692e+00\n",
      "Epoch 14752, Loss: 0.005194189492613077, Neurons: 64, Grad norm: 1.741e+00\n",
      "Epoch 14752, Loss: 0.005194189492613077, Neurons: 64, Grad norm: 1.741e+00\n",
      "Epoch 14753, Loss: 0.005202768836170435, Neurons: 64, Grad norm: 1.299e+00\n",
      "Epoch 14753, Loss: 0.005202768836170435, Neurons: 64, Grad norm: 1.299e+00\n",
      "Epoch 14754, Loss: 0.0051560974679887295, Neurons: 64, Grad norm: 5.476e-01\n",
      "Epoch 14754, Loss: 0.0051560974679887295, Neurons: 64, Grad norm: 5.476e-01\n",
      "Epoch 14755, Loss: 0.005102654919028282, Neurons: 64, Grad norm: 4.206e-01\n",
      "Epoch 14755, Loss: 0.005102654919028282, Neurons: 64, Grad norm: 4.206e-01\n",
      "Epoch 14756, Loss: 0.005088451784104109, Neurons: 64, Grad norm: 1.073e+00\n",
      "Epoch 14756, Loss: 0.005088451784104109, Neurons: 64, Grad norm: 1.073e+00\n",
      "Epoch 14757, Loss: 0.0051137241534888744, Neurons: 64, Grad norm: 1.407e+00\n",
      "Epoch 14757, Loss: 0.0051137241534888744, Neurons: 64, Grad norm: 1.407e+00\n",
      "Epoch 14758, Loss: 0.0051419539377093315, Neurons: 64, Grad norm: 1.341e+00\n",
      "Epoch 14758, Loss: 0.0051419539377093315, Neurons: 64, Grad norm: 1.341e+00\n",
      "Epoch 14759, Loss: 0.005141562782227993, Neurons: 64, Grad norm: 9.064e-01\n",
      "Epoch 14759, Loss: 0.005141562782227993, Neurons: 64, Grad norm: 9.064e-01\n",
      "Epoch 14760, Loss: 0.00511480588465929, Neurons: 64, Grad norm: 3.260e-01\n",
      "Epoch 14760, Loss: 0.00511480588465929, Neurons: 64, Grad norm: 3.260e-01\n",
      "Epoch 14761, Loss: 0.0050889840349555016, Neurons: 64, Grad norm: 5.091e-01\n",
      "Epoch 14761, Loss: 0.0050889840349555016, Neurons: 64, Grad norm: 5.091e-01\n",
      "Epoch 14762, Loss: 0.005085378885269165, Neurons: 64, Grad norm: 9.790e-01\n",
      "Epoch 14762, Loss: 0.005085378885269165, Neurons: 64, Grad norm: 9.790e-01\n",
      "Epoch 14763, Loss: 0.00510020088404417, Neurons: 64, Grad norm: 1.205e+00\n",
      "Epoch 14763, Loss: 0.00510020088404417, Neurons: 64, Grad norm: 1.205e+00\n",
      "Epoch 14764, Loss: 0.005113174673169851, Neurons: 64, Grad norm: 1.109e+00\n",
      "Epoch 14764, Loss: 0.005113174673169851, Neurons: 64, Grad norm: 1.109e+00\n",
      "Epoch 14765, Loss: 0.00510991970077157, Neurons: 64, Grad norm: 7.563e-01\n",
      "Epoch 14765, Loss: 0.00510991970077157, Neurons: 64, Grad norm: 7.563e-01\n",
      "Epoch 14766, Loss: 0.0050938911736011505, Neurons: 64, Grad norm: 2.383e-01\n",
      "Epoch 14766, Loss: 0.0050938911736011505, Neurons: 64, Grad norm: 2.383e-01\n",
      "Epoch 14767, Loss: 0.005080107599496841, Neurons: 64, Grad norm: 3.053e-01\n",
      "Epoch 14767, Loss: 0.005080107599496841, Neurons: 64, Grad norm: 3.053e-01\n",
      "Epoch 14768, Loss: 0.00507890060544014, Neurons: 64, Grad norm: 7.222e-01\n",
      "Epoch 14768, Loss: 0.00507890060544014, Neurons: 64, Grad norm: 7.222e-01\n",
      "Epoch 14769, Loss: 0.005087321624159813, Neurons: 64, Grad norm: 9.189e-01\n",
      "Epoch 14769, Loss: 0.005087321624159813, Neurons: 64, Grad norm: 9.189e-01\n",
      "Epoch 14770, Loss: 0.005094279535114765, Neurons: 64, Grad norm: 8.915e-01\n",
      "Epoch 14770, Loss: 0.005094279535114765, Neurons: 64, Grad norm: 8.915e-01\n",
      "Epoch 14771, Loss: 0.005092285573482513, Neurons: 64, Grad norm: 6.547e-01\n",
      "Epoch 14771, Loss: 0.005092285573482513, Neurons: 64, Grad norm: 6.547e-01\n",
      "Epoch 14772, Loss: 0.005083379801362753, Neurons: 64, Grad norm: 3.103e-01\n",
      "Epoch 14772, Loss: 0.005083379801362753, Neurons: 64, Grad norm: 3.103e-01\n",
      "Epoch 14773, Loss: 0.005075358785688877, Neurons: 64, Grad norm: 1.132e-01\n",
      "Epoch 14773, Loss: 0.005075358785688877, Neurons: 64, Grad norm: 1.132e-01\n",
      "Epoch 14774, Loss: 0.005073787644505501, Neurons: 64, Grad norm: 4.074e-01\n",
      "Epoch 14774, Loss: 0.005073787644505501, Neurons: 64, Grad norm: 4.074e-01\n",
      "Epoch 14775, Loss: 0.005077485926449299, Neurons: 64, Grad norm: 5.935e-01\n",
      "Epoch 14775, Loss: 0.005077485926449299, Neurons: 64, Grad norm: 5.935e-01\n",
      "Epoch 14776, Loss: 0.005080943927168846, Neurons: 64, Grad norm: 6.087e-01\n",
      "Epoch 14776, Loss: 0.005080943927168846, Neurons: 64, Grad norm: 6.087e-01\n",
      "Epoch 14777, Loss: 0.0050801560282707214, Neurons: 64, Grad norm: 4.927e-01\n",
      "Epoch 14777, Loss: 0.0050801560282707214, Neurons: 64, Grad norm: 4.927e-01\n",
      "Epoch 14778, Loss: 0.005075546447187662, Neurons: 64, Grad norm: 2.745e-01\n",
      "Epoch 14778, Loss: 0.005075546447187662, Neurons: 64, Grad norm: 2.745e-01\n",
      "Epoch 14779, Loss: 0.00507091311737895, Neurons: 64, Grad norm: 9.428e-02\n",
      "Epoch 14779, Loss: 0.00507091311737895, Neurons: 64, Grad norm: 9.428e-02\n",
      "Epoch 14780, Loss: 0.005069240927696228, Neurons: 64, Grad norm: 2.276e-01\n",
      "Epoch 14780, Loss: 0.005069240927696228, Neurons: 64, Grad norm: 2.276e-01\n",
      "Epoch 14781, Loss: 0.005070579703897238, Neurons: 64, Grad norm: 3.552e-01\n",
      "Epoch 14781, Loss: 0.005070579703897238, Neurons: 64, Grad norm: 3.552e-01\n",
      "Epoch 14782, Loss: 0.005072253756225109, Neurons: 64, Grad norm: 3.944e-01\n",
      "Epoch 14782, Loss: 0.005072253756225109, Neurons: 64, Grad norm: 3.944e-01\n",
      "Epoch 14783, Loss: 0.005071958992630243, Neurons: 64, Grad norm: 3.268e-01\n",
      "Epoch 14783, Loss: 0.005071958992630243, Neurons: 64, Grad norm: 3.268e-01\n",
      "Epoch 14784, Loss: 0.005069597624242306, Neurons: 64, Grad norm: 1.983e-01\n",
      "Epoch 14784, Loss: 0.005069597624242306, Neurons: 64, Grad norm: 1.983e-01\n",
      "Epoch 14785, Loss: 0.005066526588052511, Neurons: 64, Grad norm: 3.056e-02\n",
      "Epoch 14785, Loss: 0.005066526588052511, Neurons: 64, Grad norm: 3.056e-02\n",
      "Epoch 14786, Loss: 0.005064662080258131, Neurons: 64, Grad norm: 1.237e-01\n",
      "Epoch 14786, Loss: 0.005064662080258131, Neurons: 64, Grad norm: 1.237e-01\n",
      "Epoch 14787, Loss: 0.00506461039185524, Neurons: 64, Grad norm: 2.372e-01\n",
      "Epoch 14787, Loss: 0.00506461039185524, Neurons: 64, Grad norm: 2.372e-01\n",
      "Epoch 14788, Loss: 0.005065286066383123, Neurons: 64, Grad norm: 2.762e-01\n",
      "Epoch 14788, Loss: 0.005065286066383123, Neurons: 64, Grad norm: 2.762e-01\n",
      "Epoch 14789, Loss: 0.005065461620688438, Neurons: 64, Grad norm: 2.554e-01\n",
      "Epoch 14789, Loss: 0.005065461620688438, Neurons: 64, Grad norm: 2.554e-01\n",
      "Epoch 14790, Loss: 0.005064390599727631, Neurons: 64, Grad norm: 1.726e-01\n",
      "Epoch 14790, Loss: 0.005064390599727631, Neurons: 64, Grad norm: 1.726e-01\n",
      "Epoch 14791, Loss: 0.005062578711658716, Neurons: 64, Grad norm: 7.550e-02\n",
      "Epoch 14791, Loss: 0.005062578711658716, Neurons: 64, Grad norm: 7.550e-02\n",
      "Epoch 14792, Loss: 0.0050608632154762745, Neurons: 64, Grad norm: 1.047e-01\n",
      "Epoch 14792, Loss: 0.0050608632154762745, Neurons: 64, Grad norm: 1.047e-01\n",
      "Epoch 14793, Loss: 0.005059938877820969, Neurons: 64, Grad norm: 1.873e-01\n",
      "Epoch 14793, Loss: 0.005059938877820969, Neurons: 64, Grad norm: 1.873e-01\n",
      "Epoch 14794, Loss: 0.005059726070612669, Neurons: 64, Grad norm: 2.476e-01\n",
      "Epoch 14794, Loss: 0.005059726070612669, Neurons: 64, Grad norm: 2.476e-01\n",
      "Epoch 14795, Loss: 0.0050596809014678, Neurons: 64, Grad norm: 2.464e-01\n",
      "Epoch 14795, Loss: 0.0050596809014678, Neurons: 64, Grad norm: 2.464e-01\n",
      "Epoch 14796, Loss: 0.005059138406068087, Neurons: 64, Grad norm: 2.099e-01\n",
      "Epoch 14796, Loss: 0.005059138406068087, Neurons: 64, Grad norm: 2.099e-01\n",
      "Epoch 14797, Loss: 0.005058037117123604, Neurons: 64, Grad norm: 1.228e-01\n",
      "Epoch 14797, Loss: 0.005058037117123604, Neurons: 64, Grad norm: 1.228e-01\n",
      "Epoch 14798, Loss: 0.005056712776422501, Neurons: 64, Grad norm: 3.101e-02\n",
      "Epoch 14798, Loss: 0.005056712776422501, Neurons: 64, Grad norm: 3.101e-02\n",
      "Epoch 14799, Loss: 0.005055626854300499, Neurons: 64, Grad norm: 7.665e-02\n",
      "Epoch 14799, Loss: 0.005055626854300499, Neurons: 64, Grad norm: 7.665e-02\n",
      "Epoch 14799, Test loss: 0.004233988467603922\n",
      "Epoch 14799, Test loss: 0.004233988467603922\n",
      "Epoch 14800, Loss: 0.005054986570030451, Neurons: 64, Grad norm: 1.447e-01\n",
      "Epoch 14800, Loss: 0.005054986570030451, Neurons: 64, Grad norm: 1.447e-01\n",
      "Epoch 14801, Loss: 0.00505462009459734, Neurons: 64, Grad norm: 1.920e-01\n",
      "Epoch 14801, Loss: 0.00505462009459734, Neurons: 64, Grad norm: 1.920e-01\n",
      "Epoch 14802, Loss: 0.005054234527051449, Neurons: 64, Grad norm: 1.898e-01\n",
      "Epoch 14802, Loss: 0.005054234527051449, Neurons: 64, Grad norm: 1.898e-01\n",
      "Epoch 14803, Loss: 0.005053532775491476, Neurons: 64, Grad norm: 1.672e-01\n",
      "Epoch 14803, Loss: 0.005053532775491476, Neurons: 64, Grad norm: 1.672e-01\n",
      "Epoch 14804, Loss: 0.005052600987255573, Neurons: 64, Grad norm: 1.097e-01\n",
      "Epoch 14804, Loss: 0.005052600987255573, Neurons: 64, Grad norm: 1.097e-01\n",
      "Epoch 14805, Loss: 0.005051597021520138, Neurons: 64, Grad norm: 6.007e-02\n",
      "Epoch 14805, Loss: 0.005051597021520138, Neurons: 64, Grad norm: 6.007e-02\n",
      "Epoch 14806, Loss: 0.005050754640251398, Neurons: 64, Grad norm: 3.684e-02\n",
      "Epoch 14806, Loss: 0.005050754640251398, Neurons: 64, Grad norm: 3.684e-02\n",
      "Epoch 14807, Loss: 0.0050500668585300446, Neurons: 64, Grad norm: 7.614e-02\n",
      "Epoch 14807, Loss: 0.0050500668585300446, Neurons: 64, Grad norm: 7.614e-02\n",
      "Epoch 14808, Loss: 0.005049578845500946, Neurons: 64, Grad norm: 1.092e-01\n",
      "Epoch 14808, Loss: 0.005049578845500946, Neurons: 64, Grad norm: 1.092e-01\n",
      "Epoch 14809, Loss: 0.005049016326665878, Neurons: 64, Grad norm: 1.112e-01\n",
      "Epoch 14809, Loss: 0.005049016326665878, Neurons: 64, Grad norm: 1.112e-01\n",
      "Epoch 14810, Loss: 0.005048395600169897, Neurons: 64, Grad norm: 9.809e-02\n",
      "Epoch 14810, Loss: 0.005048395600169897, Neurons: 64, Grad norm: 9.809e-02\n",
      "Epoch 14811, Loss: 0.0050475457683205605, Neurons: 64, Grad norm: 6.088e-02\n",
      "Epoch 14811, Loss: 0.0050475457683205605, Neurons: 64, Grad norm: 6.088e-02\n",
      "Epoch 14812, Loss: 0.005046680103987455, Neurons: 64, Grad norm: 2.400e-02\n",
      "Epoch 14812, Loss: 0.005046680103987455, Neurons: 64, Grad norm: 2.400e-02\n",
      "Epoch 14813, Loss: 0.005045810714364052, Neurons: 64, Grad norm: 4.697e-02\n",
      "Epoch 14813, Loss: 0.005045810714364052, Neurons: 64, Grad norm: 4.697e-02\n",
      "Epoch 14814, Loss: 0.005045147147029638, Neurons: 64, Grad norm: 7.417e-02\n",
      "Epoch 14814, Loss: 0.005045147147029638, Neurons: 64, Grad norm: 7.417e-02\n",
      "Epoch 14815, Loss: 0.005044487304985523, Neurons: 64, Grad norm: 1.019e-01\n",
      "Epoch 14815, Loss: 0.005044487304985523, Neurons: 64, Grad norm: 1.019e-01\n",
      "Epoch 14816, Loss: 0.0050438931211829185, Neurons: 64, Grad norm: 9.919e-02\n",
      "Epoch 14816, Loss: 0.0050438931211829185, Neurons: 64, Grad norm: 9.919e-02\n",
      "Epoch 14817, Loss: 0.00504320627078414, Neurons: 64, Grad norm: 9.512e-02\n",
      "Epoch 14817, Loss: 0.00504320627078414, Neurons: 64, Grad norm: 9.512e-02\n",
      "Epoch 14818, Loss: 0.005042503587901592, Neurons: 64, Grad norm: 6.405e-02\n",
      "Epoch 14818, Loss: 0.005042503587901592, Neurons: 64, Grad norm: 6.405e-02\n",
      "Epoch 14819, Loss: 0.005041690077632666, Neurons: 64, Grad norm: 3.716e-02\n",
      "Epoch 14819, Loss: 0.005041690077632666, Neurons: 64, Grad norm: 3.716e-02\n",
      "Epoch 14820, Loss: 0.005040917545557022, Neurons: 64, Grad norm: 8.279e-03\n",
      "Epoch 14820, Loss: 0.005040917545557022, Neurons: 64, Grad norm: 8.279e-03\n",
      "Epoch 14821, Loss: 0.005040174815803766, Neurons: 64, Grad norm: 3.084e-02\n",
      "Epoch 14821, Loss: 0.005040174815803766, Neurons: 64, Grad norm: 3.084e-02\n",
      "Epoch 14822, Loss: 0.005039487034082413, Neurons: 64, Grad norm: 6.067e-02\n",
      "Epoch 14822, Loss: 0.005039487034082413, Neurons: 64, Grad norm: 6.067e-02\n",
      "Epoch 14823, Loss: 0.00503884069621563, Neurons: 64, Grad norm: 6.925e-02\n",
      "Epoch 14823, Loss: 0.00503884069621563, Neurons: 64, Grad norm: 6.925e-02\n",
      "Epoch 14824, Loss: 0.005038179457187653, Neurons: 64, Grad norm: 8.016e-02\n",
      "Epoch 14824, Loss: 0.005038179457187653, Neurons: 64, Grad norm: 8.016e-02\n",
      "Epoch 14825, Loss: 0.005037529394030571, Neurons: 64, Grad norm: 6.846e-02\n",
      "Epoch 14825, Loss: 0.005037529394030571, Neurons: 64, Grad norm: 6.846e-02\n",
      "Epoch 14826, Loss: 0.0050367978401482105, Neurons: 64, Grad norm: 5.926e-02\n",
      "Epoch 14826, Loss: 0.0050367978401482105, Neurons: 64, Grad norm: 5.926e-02\n",
      "Epoch 14827, Loss: 0.005036084447056055, Neurons: 64, Grad norm: 3.444e-02\n",
      "Epoch 14827, Loss: 0.005036084447056055, Neurons: 64, Grad norm: 3.444e-02\n",
      "Epoch 14828, Loss: 0.005035310983657837, Neurons: 64, Grad norm: 1.808e-02\n",
      "Epoch 14828, Loss: 0.005035310983657837, Neurons: 64, Grad norm: 1.808e-02\n",
      "Epoch 14829, Loss: 0.005034581292420626, Neurons: 64, Grad norm: 3.643e-02\n",
      "Epoch 14829, Loss: 0.005034581292420626, Neurons: 64, Grad norm: 3.643e-02\n",
      "Epoch 14830, Loss: 0.005033868830651045, Neurons: 64, Grad norm: 4.913e-02\n",
      "Epoch 14830, Loss: 0.005033868830651045, Neurons: 64, Grad norm: 4.913e-02\n",
      "Epoch 14831, Loss: 0.005033190827816725, Neurons: 64, Grad norm: 7.473e-02\n",
      "Epoch 14831, Loss: 0.005033190827816725, Neurons: 64, Grad norm: 7.473e-02\n",
      "Epoch 14832, Loss: 0.005032503046095371, Neurons: 64, Grad norm: 7.639e-02\n",
      "Epoch 14832, Loss: 0.005032503046095371, Neurons: 64, Grad norm: 7.639e-02\n",
      "Epoch 14833, Loss: 0.005031854845583439, Neurons: 64, Grad norm: 8.729e-02\n",
      "Epoch 14833, Loss: 0.005031854845583439, Neurons: 64, Grad norm: 8.729e-02\n",
      "Epoch 14834, Loss: 0.0050311461091041565, Neurons: 64, Grad norm: 7.545e-02\n",
      "Epoch 14834, Loss: 0.0050311461091041565, Neurons: 64, Grad norm: 7.545e-02\n",
      "Epoch 14835, Loss: 0.0050304243341088295, Neurons: 64, Grad norm: 7.651e-02\n",
      "Epoch 14835, Loss: 0.0050304243341088295, Neurons: 64, Grad norm: 7.651e-02\n",
      "Epoch 14836, Loss: 0.00502969091758132, Neurons: 64, Grad norm: 5.991e-02\n",
      "Epoch 14836, Loss: 0.00502969091758132, Neurons: 64, Grad norm: 5.991e-02\n",
      "Epoch 14837, Loss: 0.005029006395488977, Neurons: 64, Grad norm: 6.140e-02\n",
      "Epoch 14837, Loss: 0.005029006395488977, Neurons: 64, Grad norm: 6.140e-02\n",
      "Epoch 14838, Loss: 0.005028322339057922, Neurons: 64, Grad norm: 5.203e-02\n",
      "Epoch 14838, Loss: 0.005028322339057922, Neurons: 64, Grad norm: 5.203e-02\n",
      "Epoch 14839, Loss: 0.005027662497013807, Neurons: 64, Grad norm: 6.386e-02\n",
      "Epoch 14839, Loss: 0.005027662497013807, Neurons: 64, Grad norm: 6.386e-02\n",
      "Epoch 14840, Loss: 0.005026991944760084, Neurons: 64, Grad norm: 6.725e-02\n",
      "Epoch 14840, Loss: 0.005026991944760084, Neurons: 64, Grad norm: 6.725e-02\n",
      "Epoch 14841, Loss: 0.005026356317102909, Neurons: 64, Grad norm: 8.539e-02\n",
      "Epoch 14841, Loss: 0.005026356317102909, Neurons: 64, Grad norm: 8.539e-02\n",
      "Epoch 14842, Loss: 0.0050257183611392975, Neurons: 64, Grad norm: 9.527e-02\n",
      "Epoch 14842, Loss: 0.0050257183611392975, Neurons: 64, Grad norm: 9.527e-02\n",
      "Epoch 14843, Loss: 0.0050251237116754055, Neurons: 64, Grad norm: 1.251e-01\n",
      "Epoch 14843, Loss: 0.0050251237116754055, Neurons: 64, Grad norm: 1.251e-01\n",
      "Epoch 14844, Loss: 0.005024563986808062, Neurons: 64, Grad norm: 1.427e-01\n",
      "Epoch 14844, Loss: 0.005024563986808062, Neurons: 64, Grad norm: 1.427e-01\n",
      "Epoch 14845, Loss: 0.005024016834795475, Neurons: 64, Grad norm: 1.826e-01\n",
      "Epoch 14845, Loss: 0.005024016834795475, Neurons: 64, Grad norm: 1.826e-01\n",
      "Epoch 14846, Loss: 0.005023464560508728, Neurons: 64, Grad norm: 2.130e-01\n",
      "Epoch 14846, Loss: 0.005023464560508728, Neurons: 64, Grad norm: 2.130e-01\n",
      "Epoch 14847, Loss: 0.005023052450269461, Neurons: 64, Grad norm: 2.634e-01\n",
      "Epoch 14847, Loss: 0.005023052450269461, Neurons: 64, Grad norm: 2.634e-01\n",
      "Epoch 14848, Loss: 0.005022669676691294, Neurons: 64, Grad norm: 3.031e-01\n",
      "Epoch 14848, Loss: 0.005022669676691294, Neurons: 64, Grad norm: 3.031e-01\n",
      "Epoch 14849, Loss: 0.0050224000588059425, Neurons: 64, Grad norm: 3.652e-01\n",
      "Epoch 14849, Loss: 0.0050224000588059425, Neurons: 64, Grad norm: 3.652e-01\n",
      "Epoch 14850, Loss: 0.005022333934903145, Neurons: 64, Grad norm: 4.135e-01\n",
      "Epoch 14850, Loss: 0.005022333934903145, Neurons: 64, Grad norm: 4.135e-01\n",
      "Epoch 14851, Loss: 0.005022489000111818, Neurons: 64, Grad norm: 4.838e-01\n",
      "Epoch 14851, Loss: 0.005022489000111818, Neurons: 64, Grad norm: 4.838e-01\n",
      "Epoch 14852, Loss: 0.005022891331464052, Neurons: 64, Grad norm: 5.435e-01\n",
      "Epoch 14852, Loss: 0.005022891331464052, Neurons: 64, Grad norm: 5.435e-01\n",
      "Epoch 14853, Loss: 0.005023670382797718, Neurons: 64, Grad norm: 6.329e-01\n",
      "Epoch 14853, Loss: 0.005023670382797718, Neurons: 64, Grad norm: 6.329e-01\n",
      "Epoch 14854, Loss: 0.005025108344852924, Neurons: 64, Grad norm: 7.245e-01\n",
      "Epoch 14854, Loss: 0.005025108344852924, Neurons: 64, Grad norm: 7.245e-01\n",
      "Epoch 14855, Loss: 0.005027383100241423, Neurons: 64, Grad norm: 8.496e-01\n",
      "Epoch 14855, Loss: 0.005027383100241423, Neurons: 64, Grad norm: 8.496e-01\n",
      "Epoch 14856, Loss: 0.005030874162912369, Neurons: 64, Grad norm: 9.836e-01\n",
      "Epoch 14856, Loss: 0.005030874162912369, Neurons: 64, Grad norm: 9.836e-01\n",
      "Epoch 14857, Loss: 0.0050361063331365585, Neurons: 64, Grad norm: 1.170e+00\n",
      "Epoch 14857, Loss: 0.0050361063331365585, Neurons: 64, Grad norm: 1.170e+00\n",
      "Epoch 14858, Loss: 0.0050441427156329155, Neurons: 64, Grad norm: 1.376e+00\n",
      "Epoch 14858, Loss: 0.0050441427156329155, Neurons: 64, Grad norm: 1.376e+00\n",
      "Epoch 14859, Loss: 0.005055998917669058, Neurons: 64, Grad norm: 1.648e+00\n",
      "Epoch 14859, Loss: 0.005055998917669058, Neurons: 64, Grad norm: 1.648e+00\n",
      "Epoch 14860, Loss: 0.005073591601103544, Neurons: 64, Grad norm: 1.964e+00\n",
      "Epoch 14860, Loss: 0.005073591601103544, Neurons: 64, Grad norm: 1.964e+00\n",
      "Epoch 14861, Loss: 0.005099110305309296, Neurons: 64, Grad norm: 2.366e+00\n",
      "Epoch 14861, Loss: 0.005099110305309296, Neurons: 64, Grad norm: 2.366e+00\n",
      "Epoch 14862, Loss: 0.005136412568390369, Neurons: 64, Grad norm: 2.829e+00\n",
      "Epoch 14862, Loss: 0.005136412568390369, Neurons: 64, Grad norm: 2.829e+00\n",
      "Epoch 14863, Loss: 0.005189459305256605, Neurons: 64, Grad norm: 3.396e+00\n",
      "Epoch 14863, Loss: 0.005189459305256605, Neurons: 64, Grad norm: 3.396e+00\n",
      "Epoch 14864, Loss: 0.005264282692223787, Neurons: 64, Grad norm: 4.045e+00\n",
      "Epoch 14864, Loss: 0.005264282692223787, Neurons: 64, Grad norm: 4.045e+00\n",
      "Epoch 14865, Loss: 0.0053662750869989395, Neurons: 64, Grad norm: 4.794e+00\n",
      "Epoch 14865, Loss: 0.0053662750869989395, Neurons: 64, Grad norm: 4.794e+00\n",
      "Epoch 14866, Loss: 0.005500349216163158, Neurons: 64, Grad norm: 5.579e+00\n",
      "Epoch 14866, Loss: 0.005500349216163158, Neurons: 64, Grad norm: 5.579e+00\n",
      "Epoch 14867, Loss: 0.005663236603140831, Neurons: 64, Grad norm: 6.380e+00\n",
      "Epoch 14867, Loss: 0.005663236603140831, Neurons: 64, Grad norm: 6.380e+00\n",
      "Epoch 14868, Loss: 0.005841337610036135, Neurons: 64, Grad norm: 7.068e+00\n",
      "Epoch 14868, Loss: 0.005841337610036135, Neurons: 64, Grad norm: 7.068e+00\n",
      "Epoch 14869, Loss: 0.0059998552314937115, Neurons: 64, Grad norm: 7.526e+00\n",
      "Epoch 14869, Loss: 0.0059998552314937115, Neurons: 64, Grad norm: 7.526e+00\n",
      "Epoch 14870, Loss: 0.006088235881179571, Neurons: 64, Grad norm: 7.574e+00\n",
      "Epoch 14870, Loss: 0.006088235881179571, Neurons: 64, Grad norm: 7.574e+00\n",
      "Epoch 14871, Loss: 0.006053437478840351, Neurons: 64, Grad norm: 7.111e+00\n",
      "Epoch 14871, Loss: 0.006053437478840351, Neurons: 64, Grad norm: 7.111e+00\n",
      "Epoch 14872, Loss: 0.0058770389296114445, Neurons: 64, Grad norm: 6.057e+00\n",
      "Epoch 14872, Loss: 0.0058770389296114445, Neurons: 64, Grad norm: 6.057e+00\n",
      "Epoch 14873, Loss: 0.00560100469738245, Neurons: 64, Grad norm: 4.516e+00\n",
      "Epoch 14873, Loss: 0.00560100469738245, Neurons: 64, Grad norm: 4.516e+00\n",
      "Epoch 14874, Loss: 0.005315851885825396, Neurons: 64, Grad norm: 2.659e+00\n",
      "Epoch 14874, Loss: 0.005315851885825396, Neurons: 64, Grad norm: 2.659e+00\n",
      "Epoch 14875, Loss: 0.005114282947033644, Neurons: 64, Grad norm: 9.646e-01\n",
      "Epoch 14875, Loss: 0.005114282947033644, Neurons: 64, Grad norm: 9.646e-01\n",
      "Epoch 14876, Loss: 0.005042096599936485, Neurons: 64, Grad norm: 1.578e+00\n",
      "Epoch 14876, Loss: 0.005042096599936485, Neurons: 64, Grad norm: 1.578e+00\n",
      "Epoch 14877, Loss: 0.00508587621152401, Neurons: 64, Grad norm: 3.022e+00\n",
      "Epoch 14877, Loss: 0.00508587621152401, Neurons: 64, Grad norm: 3.022e+00\n",
      "Epoch 14878, Loss: 0.005191074684262276, Neurons: 64, Grad norm: 4.098e+00\n",
      "Epoch 14878, Loss: 0.005191074684262276, Neurons: 64, Grad norm: 4.098e+00\n",
      "Epoch 14879, Loss: 0.005292649380862713, Neurons: 64, Grad norm: 4.613e+00\n",
      "Epoch 14879, Loss: 0.005292649380862713, Neurons: 64, Grad norm: 4.613e+00\n",
      "Epoch 14880, Loss: 0.005341100972145796, Neurons: 64, Grad norm: 4.556e+00\n",
      "Epoch 14880, Loss: 0.005341100972145796, Neurons: 64, Grad norm: 4.556e+00\n",
      "Epoch 14881, Loss: 0.005316457245498896, Neurons: 64, Grad norm: 3.931e+00\n",
      "Epoch 14881, Loss: 0.005316457245498896, Neurons: 64, Grad norm: 3.931e+00\n",
      "Epoch 14882, Loss: 0.0052325851283967495, Neurons: 64, Grad norm: 2.882e+00\n",
      "Epoch 14882, Loss: 0.0052325851283967495, Neurons: 64, Grad norm: 2.882e+00\n",
      "Epoch 14883, Loss: 0.005126939155161381, Neurons: 64, Grad norm: 1.565e+00\n",
      "Epoch 14883, Loss: 0.005126939155161381, Neurons: 64, Grad norm: 1.565e+00\n",
      "Epoch 14884, Loss: 0.005043550860136747, Neurons: 64, Grad norm: 4.763e-01\n",
      "Epoch 14884, Loss: 0.005043550860136747, Neurons: 64, Grad norm: 4.763e-01\n",
      "Epoch 14885, Loss: 0.005010646767914295, Neurons: 64, Grad norm: 1.323e+00\n",
      "Epoch 14885, Loss: 0.005010646767914295, Neurons: 64, Grad norm: 1.323e+00\n",
      "Epoch 14886, Loss: 0.00502997450530529, Neurons: 64, Grad norm: 2.304e+00\n",
      "Epoch 14886, Loss: 0.00502997450530529, Neurons: 64, Grad norm: 2.304e+00\n",
      "Epoch 14887, Loss: 0.005079043563455343, Neurons: 64, Grad norm: 2.942e+00\n",
      "Epoch 14887, Loss: 0.005079043563455343, Neurons: 64, Grad norm: 2.942e+00\n",
      "Epoch 14888, Loss: 0.005125094670802355, Neurons: 64, Grad norm: 3.127e+00\n",
      "Epoch 14888, Loss: 0.005125094670802355, Neurons: 64, Grad norm: 3.127e+00\n",
      "Epoch 14889, Loss: 0.005141580477356911, Neurons: 64, Grad norm: 2.897e+00\n",
      "Epoch 14889, Loss: 0.005141580477356911, Neurons: 64, Grad norm: 2.897e+00\n",
      "Epoch 14890, Loss: 0.0051201749593019485, Neurons: 64, Grad norm: 2.291e+00\n",
      "Epoch 14890, Loss: 0.0051201749593019485, Neurons: 64, Grad norm: 2.291e+00\n",
      "Epoch 14891, Loss: 0.005073035601526499, Neurons: 64, Grad norm: 1.447e+00\n",
      "Epoch 14891, Loss: 0.005073035601526499, Neurons: 64, Grad norm: 1.447e+00\n",
      "Epoch 14892, Loss: 0.005023868754506111, Neurons: 64, Grad norm: 4.777e-01\n",
      "Epoch 14892, Loss: 0.005023868754506111, Neurons: 64, Grad norm: 4.777e-01\n",
      "Epoch 14893, Loss: 0.004994361195713282, Neurons: 64, Grad norm: 4.680e-01\n",
      "Epoch 14893, Loss: 0.004994361195713282, Neurons: 64, Grad norm: 4.680e-01\n",
      "Epoch 14894, Loss: 0.004992942325770855, Neurons: 64, Grad norm: 1.256e+00\n",
      "Epoch 14894, Loss: 0.004992942325770855, Neurons: 64, Grad norm: 1.256e+00\n",
      "Epoch 14895, Loss: 0.005012575536966324, Neurons: 64, Grad norm: 1.792e+00\n",
      "Epoch 14895, Loss: 0.005012575536966324, Neurons: 64, Grad norm: 1.792e+00\n",
      "Epoch 14896, Loss: 0.005037326831370592, Neurons: 64, Grad norm: 2.059e+00\n",
      "Epoch 14896, Loss: 0.005037326831370592, Neurons: 64, Grad norm: 2.059e+00\n",
      "Epoch 14897, Loss: 0.005051888525485992, Neurons: 64, Grad norm: 2.021e+00\n",
      "Epoch 14897, Loss: 0.005051888525485992, Neurons: 64, Grad norm: 2.021e+00\n",
      "Epoch 14898, Loss: 0.005049160681664944, Neurons: 64, Grad norm: 1.741e+00\n",
      "Epoch 14898, Loss: 0.005049160681664944, Neurons: 64, Grad norm: 1.741e+00\n",
      "Epoch 14899, Loss: 0.005031897686421871, Neurons: 64, Grad norm: 1.256e+00\n",
      "Epoch 14899, Loss: 0.005031897686421871, Neurons: 64, Grad norm: 1.256e+00\n",
      "Epoch 14899, Test loss: 0.004162121098488569\n",
      "Epoch 14899, Test loss: 0.004162121098488569\n",
      "Epoch 14900, Loss: 0.005009505432099104, Neurons: 64, Grad norm: 6.831e-01\n",
      "Epoch 14900, Loss: 0.005009505432099104, Neurons: 64, Grad norm: 6.831e-01\n",
      "Epoch 14901, Loss: 0.0049920943565666676, Neurons: 64, Grad norm: 1.385e-01\n",
      "Epoch 14901, Loss: 0.0049920943565666676, Neurons: 64, Grad norm: 1.385e-01\n",
      "Epoch 14902, Loss: 0.004985097795724869, Neurons: 64, Grad norm: 5.007e-01\n",
      "Epoch 14902, Loss: 0.004985097795724869, Neurons: 64, Grad norm: 5.007e-01\n",
      "Epoch 14903, Loss: 0.004988191649317741, Neurons: 64, Grad norm: 9.301e-01\n",
      "Epoch 14903, Loss: 0.004988191649317741, Neurons: 64, Grad norm: 9.301e-01\n",
      "Epoch 14904, Loss: 0.004996448755264282, Neurons: 64, Grad norm: 1.197e+00\n",
      "Epoch 14904, Loss: 0.004996448755264282, Neurons: 64, Grad norm: 1.197e+00\n",
      "Epoch 14905, Loss: 0.0050042010843753815, Neurons: 64, Grad norm: 1.315e+00\n",
      "Epoch 14905, Loss: 0.0050042010843753815, Neurons: 64, Grad norm: 1.315e+00\n",
      "Epoch 14906, Loss: 0.00500732334330678, Neurons: 64, Grad norm: 1.256e+00\n",
      "Epoch 14906, Loss: 0.00500732334330678, Neurons: 64, Grad norm: 1.256e+00\n",
      "Epoch 14907, Loss: 0.005004813428968191, Neurons: 64, Grad norm: 1.083e+00\n",
      "Epoch 14907, Loss: 0.005004813428968191, Neurons: 64, Grad norm: 1.083e+00\n",
      "Epoch 14908, Loss: 0.0049982513301074505, Neurons: 64, Grad norm: 8.001e-01\n",
      "Epoch 14908, Loss: 0.0049982513301074505, Neurons: 64, Grad norm: 8.001e-01\n",
      "Epoch 14909, Loss: 0.004990408197045326, Neurons: 64, Grad norm: 4.898e-01\n",
      "Epoch 14909, Loss: 0.004990408197045326, Neurons: 64, Grad norm: 4.898e-01\n",
      "Epoch 14910, Loss: 0.004983846098184586, Neurons: 64, Grad norm: 1.980e-01\n",
      "Epoch 14910, Loss: 0.004983846098184586, Neurons: 64, Grad norm: 1.980e-01\n",
      "Epoch 14911, Loss: 0.004980057943612337, Neurons: 64, Grad norm: 2.557e-01\n",
      "Epoch 14911, Loss: 0.004980057943612337, Neurons: 64, Grad norm: 2.557e-01\n",
      "Epoch 14912, Loss: 0.004979212302714586, Neurons: 64, Grad norm: 4.893e-01\n",
      "Epoch 14912, Loss: 0.004979212302714586, Neurons: 64, Grad norm: 4.893e-01\n",
      "Epoch 14913, Loss: 0.004980431869626045, Neurons: 64, Grad norm: 6.568e-01\n",
      "Epoch 14913, Loss: 0.004980431869626045, Neurons: 64, Grad norm: 6.568e-01\n",
      "Epoch 14914, Loss: 0.004982438404113054, Neurons: 64, Grad norm: 7.629e-01\n",
      "Epoch 14914, Loss: 0.004982438404113054, Neurons: 64, Grad norm: 7.629e-01\n",
      "Epoch 14915, Loss: 0.00498397508636117, Neurons: 64, Grad norm: 7.715e-01\n",
      "Epoch 14915, Loss: 0.00498397508636117, Neurons: 64, Grad norm: 7.715e-01\n",
      "Epoch 14916, Loss: 0.004984254017472267, Neurons: 64, Grad norm: 7.275e-01\n",
      "Epoch 14916, Loss: 0.004984254017472267, Neurons: 64, Grad norm: 7.275e-01\n",
      "Epoch 14917, Loss: 0.004982977174222469, Neurons: 64, Grad norm: 6.142e-01\n",
      "Epoch 14917, Loss: 0.004982977174222469, Neurons: 64, Grad norm: 6.142e-01\n",
      "Epoch 14918, Loss: 0.004980400670319796, Neurons: 64, Grad norm: 4.749e-01\n",
      "Epoch 14918, Loss: 0.004980400670319796, Neurons: 64, Grad norm: 4.749e-01\n",
      "Epoch 14919, Loss: 0.004977329634130001, Neurons: 64, Grad norm: 2.974e-01\n",
      "Epoch 14919, Loss: 0.004977329634130001, Neurons: 64, Grad norm: 2.974e-01\n",
      "Epoch 14920, Loss: 0.004974346607923508, Neurons: 64, Grad norm: 1.466e-01\n",
      "Epoch 14920, Loss: 0.004974346607923508, Neurons: 64, Grad norm: 1.466e-01\n",
      "Epoch 14921, Loss: 0.004972121212631464, Neurons: 64, Grad norm: 1.129e-01\n",
      "Epoch 14921, Loss: 0.004972121212631464, Neurons: 64, Grad norm: 1.129e-01\n",
      "Epoch 14922, Loss: 0.004970797803252935, Neurons: 64, Grad norm: 2.172e-01\n",
      "Epoch 14922, Loss: 0.004970797803252935, Neurons: 64, Grad norm: 2.172e-01\n",
      "Epoch 14923, Loss: 0.00497043039649725, Neurons: 64, Grad norm: 3.310e-01\n",
      "Epoch 14923, Loss: 0.00497043039649725, Neurons: 64, Grad norm: 3.310e-01\n",
      "Epoch 14924, Loss: 0.0049706450663506985, Neurons: 64, Grad norm: 3.963e-01\n",
      "Epoch 14924, Loss: 0.0049706450663506985, Neurons: 64, Grad norm: 3.963e-01\n",
      "Epoch 14925, Loss: 0.004971105605363846, Neurons: 64, Grad norm: 4.450e-01\n",
      "Epoch 14925, Loss: 0.004971105605363846, Neurons: 64, Grad norm: 4.450e-01\n",
      "Epoch 14926, Loss: 0.004971230868250132, Neurons: 64, Grad norm: 4.459e-01\n",
      "Epoch 14926, Loss: 0.004971230868250132, Neurons: 64, Grad norm: 4.459e-01\n",
      "Epoch 14927, Loss: 0.004970867186784744, Neurons: 64, Grad norm: 4.283e-01\n",
      "Epoch 14927, Loss: 0.004970867186784744, Neurons: 64, Grad norm: 4.283e-01\n",
      "Epoch 14928, Loss: 0.004969913512468338, Neurons: 64, Grad norm: 3.678e-01\n",
      "Epoch 14928, Loss: 0.004969913512468338, Neurons: 64, Grad norm: 3.678e-01\n",
      "Epoch 14929, Loss: 0.004968456458300352, Neurons: 64, Grad norm: 3.093e-01\n",
      "Epoch 14929, Loss: 0.004968456458300352, Neurons: 64, Grad norm: 3.093e-01\n",
      "Epoch 14930, Loss: 0.0049668666906654835, Neurons: 64, Grad norm: 2.182e-01\n",
      "Epoch 14930, Loss: 0.0049668666906654835, Neurons: 64, Grad norm: 2.182e-01\n",
      "Epoch 14931, Loss: 0.004965252708643675, Neurons: 64, Grad norm: 1.378e-01\n",
      "Epoch 14931, Loss: 0.004965252708643675, Neurons: 64, Grad norm: 1.378e-01\n",
      "Epoch 14932, Loss: 0.004963892977684736, Neurons: 64, Grad norm: 4.255e-02\n",
      "Epoch 14932, Loss: 0.004963892977684736, Neurons: 64, Grad norm: 4.255e-02\n",
      "Epoch 14933, Loss: 0.004962868057191372, Neurons: 64, Grad norm: 3.664e-02\n",
      "Epoch 14933, Loss: 0.004962868057191372, Neurons: 64, Grad norm: 3.664e-02\n",
      "Epoch 14934, Loss: 0.004962174221873283, Neurons: 64, Grad norm: 1.165e-01\n",
      "Epoch 14934, Loss: 0.004962174221873283, Neurons: 64, Grad norm: 1.165e-01\n",
      "Epoch 14935, Loss: 0.004961773287504911, Neurons: 64, Grad norm: 1.667e-01\n",
      "Epoch 14935, Loss: 0.004961773287504911, Neurons: 64, Grad norm: 1.667e-01\n",
      "Epoch 14936, Loss: 0.004961465019732714, Neurons: 64, Grad norm: 2.208e-01\n",
      "Epoch 14936, Loss: 0.004961465019732714, Neurons: 64, Grad norm: 2.208e-01\n",
      "Epoch 14937, Loss: 0.004961115308105946, Neurons: 64, Grad norm: 2.415e-01\n",
      "Epoch 14937, Loss: 0.004961115308105946, Neurons: 64, Grad norm: 2.415e-01\n",
      "Epoch 14938, Loss: 0.004960649646818638, Neurons: 64, Grad norm: 2.666e-01\n",
      "Epoch 14938, Loss: 0.004960649646818638, Neurons: 64, Grad norm: 2.666e-01\n",
      "Epoch 14939, Loss: 0.004960073158144951, Neurons: 64, Grad norm: 2.580e-01\n",
      "Epoch 14939, Loss: 0.004960073158144951, Neurons: 64, Grad norm: 2.580e-01\n",
      "Epoch 14940, Loss: 0.004959306214004755, Neurons: 64, Grad norm: 2.518e-01\n",
      "Epoch 14940, Loss: 0.004959306214004755, Neurons: 64, Grad norm: 2.518e-01\n",
      "Epoch 14941, Loss: 0.004958487115800381, Neurons: 64, Grad norm: 2.246e-01\n",
      "Epoch 14941, Loss: 0.004958487115800381, Neurons: 64, Grad norm: 2.246e-01\n",
      "Epoch 14942, Loss: 0.004957552533596754, Neurons: 64, Grad norm: 2.058e-01\n",
      "Epoch 14942, Loss: 0.004957552533596754, Neurons: 64, Grad norm: 2.058e-01\n",
      "Epoch 14943, Loss: 0.004956639371812344, Neurons: 64, Grad norm: 1.632e-01\n",
      "Epoch 14943, Loss: 0.004956639371812344, Neurons: 64, Grad norm: 1.632e-01\n",
      "Epoch 14944, Loss: 0.004955722950398922, Neurons: 64, Grad norm: 1.343e-01\n",
      "Epoch 14944, Loss: 0.004955722950398922, Neurons: 64, Grad norm: 1.343e-01\n",
      "Epoch 14945, Loss: 0.004954878240823746, Neurons: 64, Grad norm: 9.084e-02\n",
      "Epoch 14945, Loss: 0.004954878240823746, Neurons: 64, Grad norm: 9.084e-02\n",
      "Epoch 14946, Loss: 0.0049540819600224495, Neurons: 64, Grad norm: 6.543e-02\n",
      "Epoch 14946, Loss: 0.0049540819600224495, Neurons: 64, Grad norm: 6.543e-02\n",
      "Epoch 14947, Loss: 0.004953362513333559, Neurons: 64, Grad norm: 3.852e-02\n",
      "Epoch 14947, Loss: 0.004953362513333559, Neurons: 64, Grad norm: 3.852e-02\n",
      "Epoch 14948, Loss: 0.004952644929289818, Neurons: 64, Grad norm: 4.055e-02\n",
      "Epoch 14948, Loss: 0.004952644929289818, Neurons: 64, Grad norm: 4.055e-02\n",
      "Epoch 14949, Loss: 0.004952023737132549, Neurons: 64, Grad norm: 6.739e-02\n",
      "Epoch 14949, Loss: 0.004952023737132549, Neurons: 64, Grad norm: 6.739e-02\n",
      "Epoch 14950, Loss: 0.004951363895088434, Neurons: 64, Grad norm: 8.327e-02\n",
      "Epoch 14950, Loss: 0.004951363895088434, Neurons: 64, Grad norm: 8.327e-02\n",
      "Epoch 14951, Loss: 0.004950739908963442, Neurons: 64, Grad norm: 1.120e-01\n",
      "Epoch 14951, Loss: 0.004950739908963442, Neurons: 64, Grad norm: 1.120e-01\n",
      "Epoch 14952, Loss: 0.0049501140601933, Neurons: 64, Grad norm: 1.193e-01\n",
      "Epoch 14952, Loss: 0.0049501140601933, Neurons: 64, Grad norm: 1.193e-01\n",
      "Epoch 14953, Loss: 0.004949457477778196, Neurons: 64, Grad norm: 1.406e-01\n",
      "Epoch 14953, Loss: 0.004949457477778196, Neurons: 64, Grad norm: 1.406e-01\n",
      "Epoch 14954, Loss: 0.004948786925524473, Neurons: 64, Grad norm: 1.427e-01\n",
      "Epoch 14954, Loss: 0.004948786925524473, Neurons: 64, Grad norm: 1.427e-01\n",
      "Epoch 14955, Loss: 0.004948127549141645, Neurons: 64, Grad norm: 1.573e-01\n",
      "Epoch 14955, Loss: 0.004948127549141645, Neurons: 64, Grad norm: 1.573e-01\n",
      "Epoch 14956, Loss: 0.004947481211274862, Neurons: 64, Grad norm: 1.514e-01\n",
      "Epoch 14956, Loss: 0.004947481211274862, Neurons: 64, Grad norm: 1.514e-01\n",
      "Epoch 14957, Loss: 0.004946785978972912, Neurons: 64, Grad norm: 1.610e-01\n",
      "Epoch 14957, Loss: 0.004946785978972912, Neurons: 64, Grad norm: 1.610e-01\n",
      "Epoch 14958, Loss: 0.004946117755025625, Neurons: 64, Grad norm: 1.501e-01\n",
      "Epoch 14958, Loss: 0.004946117755025625, Neurons: 64, Grad norm: 1.501e-01\n",
      "Epoch 14959, Loss: 0.004945399239659309, Neurons: 64, Grad norm: 1.519e-01\n",
      "Epoch 14959, Loss: 0.004945399239659309, Neurons: 64, Grad norm: 1.519e-01\n",
      "Epoch 14960, Loss: 0.004944693297147751, Neurons: 64, Grad norm: 1.376e-01\n",
      "Epoch 14960, Loss: 0.004944693297147751, Neurons: 64, Grad norm: 1.376e-01\n",
      "Epoch 14961, Loss: 0.004944015759974718, Neurons: 64, Grad norm: 1.370e-01\n",
      "Epoch 14961, Loss: 0.004944015759974718, Neurons: 64, Grad norm: 1.370e-01\n",
      "Epoch 14962, Loss: 0.0049432613886892796, Neurons: 64, Grad norm: 1.241e-01\n",
      "Epoch 14962, Loss: 0.0049432613886892796, Neurons: 64, Grad norm: 1.241e-01\n",
      "Epoch 14963, Loss: 0.004942566156387329, Neurons: 64, Grad norm: 1.257e-01\n",
      "Epoch 14963, Loss: 0.004942566156387329, Neurons: 64, Grad norm: 1.257e-01\n",
      "Epoch 14964, Loss: 0.004941878374665976, Neurons: 64, Grad norm: 1.111e-01\n",
      "Epoch 14964, Loss: 0.004941878374665976, Neurons: 64, Grad norm: 1.111e-01\n",
      "Epoch 14965, Loss: 0.004941141232848167, Neurons: 64, Grad norm: 1.146e-01\n",
      "Epoch 14965, Loss: 0.004941141232848167, Neurons: 64, Grad norm: 1.146e-01\n",
      "Epoch 14966, Loss: 0.004940416663885117, Neurons: 64, Grad norm: 1.006e-01\n",
      "Epoch 14966, Loss: 0.004940416663885117, Neurons: 64, Grad norm: 1.006e-01\n",
      "Epoch 14967, Loss: 0.0049397205002605915, Neurons: 64, Grad norm: 1.022e-01\n",
      "Epoch 14967, Loss: 0.0049397205002605915, Neurons: 64, Grad norm: 1.022e-01\n",
      "Epoch 14968, Loss: 0.004939017351716757, Neurons: 64, Grad norm: 9.225e-02\n",
      "Epoch 14968, Loss: 0.004939017351716757, Neurons: 64, Grad norm: 9.225e-02\n",
      "Epoch 14969, Loss: 0.004938327707350254, Neurons: 64, Grad norm: 9.902e-02\n",
      "Epoch 14969, Loss: 0.004938327707350254, Neurons: 64, Grad norm: 9.902e-02\n",
      "Epoch 14970, Loss: 0.0049376105889678, Neurons: 64, Grad norm: 8.997e-02\n",
      "Epoch 14970, Loss: 0.0049376105889678, Neurons: 64, Grad norm: 8.997e-02\n",
      "Epoch 14971, Loss: 0.0049369605258107185, Neurons: 64, Grad norm: 9.532e-02\n",
      "Epoch 14971, Loss: 0.0049369605258107185, Neurons: 64, Grad norm: 9.532e-02\n",
      "Epoch 14972, Loss: 0.004936284385621548, Neurons: 64, Grad norm: 8.644e-02\n",
      "Epoch 14972, Loss: 0.004936284385621548, Neurons: 64, Grad norm: 8.644e-02\n",
      "Epoch 14973, Loss: 0.00493557658046484, Neurons: 64, Grad norm: 9.740e-02\n",
      "Epoch 14973, Loss: 0.00493557658046484, Neurons: 64, Grad norm: 9.740e-02\n",
      "Epoch 14974, Loss: 0.004934900905936956, Neurons: 64, Grad norm: 9.236e-02\n",
      "Epoch 14974, Loss: 0.004934900905936956, Neurons: 64, Grad norm: 9.236e-02\n",
      "Epoch 14975, Loss: 0.0049342140555381775, Neurons: 64, Grad norm: 1.033e-01\n",
      "Epoch 14975, Loss: 0.0049342140555381775, Neurons: 64, Grad norm: 1.033e-01\n",
      "Epoch 14976, Loss: 0.0049335286021232605, Neurons: 64, Grad norm: 1.045e-01\n",
      "Epoch 14976, Loss: 0.0049335286021232605, Neurons: 64, Grad norm: 1.045e-01\n",
      "Epoch 14977, Loss: 0.004932904615998268, Neurons: 64, Grad norm: 1.210e-01\n",
      "Epoch 14977, Loss: 0.004932904615998268, Neurons: 64, Grad norm: 1.210e-01\n",
      "Epoch 14978, Loss: 0.0049322303384542465, Neurons: 64, Grad norm: 1.216e-01\n",
      "Epoch 14978, Loss: 0.0049322303384542465, Neurons: 64, Grad norm: 1.216e-01\n",
      "Epoch 14979, Loss: 0.004931597970426083, Neurons: 64, Grad norm: 1.461e-01\n",
      "Epoch 14979, Loss: 0.004931597970426083, Neurons: 64, Grad norm: 1.461e-01\n",
      "Epoch 14980, Loss: 0.004930989351123571, Neurons: 64, Grad norm: 1.553e-01\n",
      "Epoch 14980, Loss: 0.004930989351123571, Neurons: 64, Grad norm: 1.553e-01\n",
      "Epoch 14981, Loss: 0.004930370952934027, Neurons: 64, Grad norm: 1.822e-01\n",
      "Epoch 14981, Loss: 0.004930370952934027, Neurons: 64, Grad norm: 1.822e-01\n",
      "Epoch 14982, Loss: 0.004929795395582914, Neurons: 64, Grad norm: 2.019e-01\n",
      "Epoch 14982, Loss: 0.004929795395582914, Neurons: 64, Grad norm: 2.019e-01\n",
      "Epoch 14983, Loss: 0.004929348360747099, Neurons: 64, Grad norm: 2.441e-01\n",
      "Epoch 14983, Loss: 0.004929348360747099, Neurons: 64, Grad norm: 2.441e-01\n",
      "Epoch 14984, Loss: 0.004928885493427515, Neurons: 64, Grad norm: 2.746e-01\n",
      "Epoch 14984, Loss: 0.004928885493427515, Neurons: 64, Grad norm: 2.746e-01\n",
      "Epoch 14985, Loss: 0.0049285804852843285, Neurons: 64, Grad norm: 3.300e-01\n",
      "Epoch 14985, Loss: 0.0049285804852843285, Neurons: 64, Grad norm: 3.300e-01\n",
      "Epoch 14986, Loss: 0.004928424954414368, Neurons: 64, Grad norm: 3.790e-01\n",
      "Epoch 14986, Loss: 0.004928424954414368, Neurons: 64, Grad norm: 3.790e-01\n",
      "Epoch 14987, Loss: 0.004928407724946737, Neurons: 64, Grad norm: 4.577e-01\n",
      "Epoch 14987, Loss: 0.004928407724946737, Neurons: 64, Grad norm: 4.577e-01\n",
      "Epoch 14988, Loss: 0.004928711336106062, Neurons: 64, Grad norm: 5.318e-01\n",
      "Epoch 14988, Loss: 0.004928711336106062, Neurons: 64, Grad norm: 5.318e-01\n",
      "Epoch 14989, Loss: 0.004929438699036837, Neurons: 64, Grad norm: 6.402e-01\n",
      "Epoch 14989, Loss: 0.004929438699036837, Neurons: 64, Grad norm: 6.402e-01\n",
      "Epoch 14990, Loss: 0.00493073184043169, Neurons: 64, Grad norm: 7.549e-01\n",
      "Epoch 14990, Loss: 0.00493073184043169, Neurons: 64, Grad norm: 7.549e-01\n",
      "Epoch 14991, Loss: 0.004932804964482784, Neurons: 64, Grad norm: 9.072e-01\n",
      "Epoch 14991, Loss: 0.004932804964482784, Neurons: 64, Grad norm: 9.072e-01\n",
      "Epoch 14992, Loss: 0.004936083219945431, Neurons: 64, Grad norm: 1.077e+00\n",
      "Epoch 14992, Loss: 0.004936083219945431, Neurons: 64, Grad norm: 1.077e+00\n",
      "Epoch 14993, Loss: 0.004941146355122328, Neurons: 64, Grad norm: 1.306e+00\n",
      "Epoch 14993, Loss: 0.004941146355122328, Neurons: 64, Grad norm: 1.306e+00\n",
      "Epoch 14994, Loss: 0.004948978312313557, Neurons: 64, Grad norm: 1.564e+00\n",
      "Epoch 14994, Loss: 0.004948978312313557, Neurons: 64, Grad norm: 1.564e+00\n",
      "Epoch 14995, Loss: 0.004960724152624607, Neurons: 64, Grad norm: 1.899e+00\n",
      "Epoch 14995, Loss: 0.004960724152624607, Neurons: 64, Grad norm: 1.899e+00\n",
      "Epoch 14996, Loss: 0.004978599958121777, Neurons: 64, Grad norm: 2.297e+00\n",
      "Epoch 14996, Loss: 0.004978599958121777, Neurons: 64, Grad norm: 2.297e+00\n",
      "Epoch 14997, Loss: 0.005005553364753723, Neurons: 64, Grad norm: 2.802e+00\n",
      "Epoch 14997, Loss: 0.005005553364753723, Neurons: 64, Grad norm: 2.802e+00\n",
      "Epoch 14998, Loss: 0.005045768804848194, Neurons: 64, Grad norm: 3.399e+00\n",
      "Epoch 14998, Loss: 0.005045768804848194, Neurons: 64, Grad norm: 3.399e+00\n",
      "Epoch 14999, Loss: 0.005105557851493359, Neurons: 64, Grad norm: 4.134e+00\n",
      "Epoch 14999, Loss: 0.005105557851493359, Neurons: 64, Grad norm: 4.134e+00\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    start = time.time()\n",
    "    train_loss, mlp, opt_state = train_step(mlp, x_train, y_train, opt_state, opt.update)\n",
    "    _, grads  = compute_loss(mlp, x_train, y_train)\n",
    "    grad_norm_val = grad_norm(grads)\n",
    "    n_neurons = sum(mlp.get_shape())\n",
    "\n",
    "    logging.info(f\"Epoch {epoch :03d}, Loss: {train_loss.item()}, Neurons: {n_neurons}, Grad norm: {grad_norm_val :.3e}\")\n",
    "    wandb.log({\"train_loss\": train_loss.item(), \"neurons\": n_neurons, \"grad_norm\": grad_norm_val})\n",
    "    train_loss_history.append((epoch, train_loss))\n",
    "    grad_norm_history.append((epoch,grad_norm_val))\n",
    "    node_history.append((epoch, n_neurons))\n",
    "\n",
    "    if test_loss < threshold: # stop training if test loss is below threshold\n",
    "        logging.info(f\"Threshold reached, stopping training at epoch {epoch}\")\n",
    "        wandb.log({\"threshold reached\": epoch})\n",
    "        break\n",
    "\n",
    "    if grad_norm_val < grad_norm_threshold/10: # stop training if gradient norm is very low\n",
    "        logging.info(f\"Gradient norm below threshold, stopping training at epoch {epoch}\")\n",
    "        wandb.log({\"grad_norm_threshold\": epoch})\n",
    "        break\n",
    "\n",
    "    key, add_key, sub_key = jax.random.split(key,3)\n",
    "\n",
    "    if ((epoch + 1) % intervene_every*int(n_neurons/init_neurons) == 0 # scale intervention period linearly with number of neurons\n",
    "        or grad_norm_val < grad_norm_threshold) and epoch!=num_epochs-1: # intervene if gradient norm is below threshold, but not at last epoch\n",
    "        test_loss = test_step(mlp, x_test, y_test)\n",
    "        logging.info(f\"Epoch {epoch :03d}, Test loss: {test_loss.item()}\")\n",
    "        wandb.log({\"test_loss\": test_loss.item()})\n",
    "        test_loss_history.append((epoch,test_loss))\n",
    "\n",
    "        # Neuron Addition criteria\n",
    "        if ((len(update_history) == 0    # if no previous addition\n",
    "            or update_history[-1][3] > test_loss) # if last addition was accepted\n",
    "            and n_neurons<max_neurons): # neuron ceiling\n",
    "\n",
    "            add_key, act_key = jax.random.split(add_key)\n",
    "            activation = activation_list[jax.random.choice(key, jnp.arange(len(activation_list)))]\n",
    "            layers = len(mlp.get_shape()) - 1\n",
    "            layer = jax.random.randint(act_key, (1,), 0, layers)[0] # randomly select a layer to add neuron to\n",
    "            mlp.add_neuron(layer_index=layer, activation=activation, bias = bias, key=add_key)\n",
    "            opt_state = initialize_optimizer_state(mlp, opt)\n",
    "\n",
    "            update_history.append((epoch, n_neurons, train_loss, test_loss, activation.__name__, layer))\n",
    "            logging.info(f\"Added neuron to hidden layer {layer+1} with activation {activation.__name__}\")\n",
    "            wandb.log({\"added neuron\": activation.__name__})\n",
    "            logging.info(f\"network shape updated to :{mlp.get_shape()}\")\n",
    "        \n",
    "        # Neuron Removal criteria\n",
    "        elif ((update_history[-1][-2] == \"removed\" and update_history[-2][3] < test_loss) # if last addition was removed check loss against value before that\n",
    "            or (update_history[-1][-2] != \"removed\" and update_history[-1][3] < test_loss) # if loss is worse than last accepted addition, reject it\n",
    "            and n_neurons>min_neurons): # neuron floor\n",
    "\n",
    "            layer_key, neuron_key, sub_key = jax.random.split(sub_key,3)\n",
    "            layer = update_history[-1][-1] # get the layer of last addition\n",
    "            neuron_idx = len(mlp.layers[layer]) -1\n",
    "\n",
    "            if len(mlp.layers[layer]) <= 1:\n",
    "                logging.info(f\"Cannot remove neuron from layer {layer+1}, only one neuron left\")\n",
    "                update_history.append((epoch, n_neurons, train_loss, test_loss, \"single_node_layer\", layer))\n",
    "                continue\n",
    "\n",
    "            mlp.remove_neuron(layer_index=layer, neuron_index=neuron_idx)\n",
    "            opt_state = initialize_optimizer_state(mlp, opt)\n",
    "            update_history.append((epoch, n_neurons, train_loss, test_loss, \"removed\", layer))\n",
    "\n",
    "            logging.info(f\"Removed neuron to hidden layer {layer+1} at index {neuron_idx}\")\n",
    "            wandb.log({\"removed neuron\": neuron_idx})\n",
    "            logging.info(f\"network shape updated to :{mlp.get_shape()}\")\n",
    "    \n",
    "    stop = time.time()\n",
    "    time_history.append((epoch, stop-start, n_neurons))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f\"{out_folder}/neurons.txt\", node_history)\n",
    "np.savetxt(f\"{out_folder}/train_loss.txt\", train_loss_history)\n",
    "np.savetxt(f\"{out_folder}/test_loss.txt\", test_loss_history)\n",
    "np.savetxt(f\"{out_folder}/grad_norm.txt\", grad_norm_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = jax.vmap(mlp)(x_test)\n",
    "test_mse = jnp.mean((y_pred - y_test) ** 2)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x_test, y_test, \"b.\", alpha=0.2, label=\"True Poly Function\")\n",
    "plt.plot(x_test, y_pred, \"r.\", alpha=0.2, label=\"MLP Predictions\\n Test MSE: {:.4f}\".format(test_mse))\n",
    "plt.legend()\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.title(\"MLP Approximation of polynomial Function\")\n",
    "plt.savefig(f\"{fig_folder}/polynomial_approximation.png\")\n",
    "wandb.log({\"polynomial approximation\": wandb.Image(plt, caption=\"polynomial approximation\")})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(99,\n",
       "  11,\n",
       "  Array(1485.7893, dtype=float32),\n",
       "  Array(1515.2196, dtype=float32),\n",
       "  'tanh',\n",
       "  Array(1, dtype=int32)),\n",
       " (199,\n",
       "  12,\n",
       "  Array(1450.7047, dtype=float32),\n",
       "  Array(1479.4166, dtype=float32),\n",
       "  'tanh',\n",
       "  Array(0, dtype=int32)),\n",
       " (299,\n",
       "  13,\n",
       "  Array(1416.8864, dtype=float32),\n",
       "  Array(1444.81, dtype=float32),\n",
       "  'relu',\n",
       "  Array(1, dtype=int32)),\n",
       " (399,\n",
       "  14,\n",
       "  Array(1381.7533, dtype=float32),\n",
       "  Array(1408.5634, dtype=float32),\n",
       "  'tanh',\n",
       "  Array(0, dtype=int32)),\n",
       " (499,\n",
       "  15,\n",
       "  Array(1347.3591, dtype=float32),\n",
       "  Array(1372.8965, dtype=float32),\n",
       "  'relu',\n",
       "  Array(0, dtype=int32)),\n",
       " (599,\n",
       "  16,\n",
       "  Array(1302.9243, dtype=float32),\n",
       "  Array(1326.5009, dtype=float32),\n",
       "  'sin',\n",
       "  Array(1, dtype=int32)),\n",
       " (699,\n",
       "  17,\n",
       "  Array(1260.9032, dtype=float32),\n",
       "  Array(1282.4039, dtype=float32),\n",
       "  'sin',\n",
       "  Array(0, dtype=int32)),\n",
       " (799,\n",
       "  18,\n",
       "  Array(1225.0275, dtype=float32),\n",
       "  Array(1244.0577, dtype=float32),\n",
       "  'relu',\n",
       "  Array(1, dtype=int32)),\n",
       " (899,\n",
       "  19,\n",
       "  Array(1190.3467, dtype=float32),\n",
       "  Array(1207.3724, dtype=float32),\n",
       "  'tanh',\n",
       "  Array(0, dtype=int32)),\n",
       " (999,\n",
       "  20,\n",
       "  Array(1163.2277, dtype=float32),\n",
       "  Array(1178.5518, dtype=float32),\n",
       "  'tanh',\n",
       "  Array(1, dtype=int32)),\n",
       " (1099,\n",
       "  21,\n",
       "  Array(1133.4429, dtype=float32),\n",
       "  Array(1147.1686, dtype=float32),\n",
       "  'sin',\n",
       "  Array(1, dtype=int32)),\n",
       " (1199,\n",
       "  22,\n",
       "  Array(1098.8988, dtype=float32),\n",
       "  Array(1111.4043, dtype=float32),\n",
       "  'tanh',\n",
       "  Array(1, dtype=int32)),\n",
       " (1299,\n",
       "  23,\n",
       "  Array(1061.0616, dtype=float32),\n",
       "  Array(1072.5431, dtype=float32),\n",
       "  'tanh',\n",
       "  Array(1, dtype=int32)),\n",
       " (1399,\n",
       "  24,\n",
       "  Array(1019.011, dtype=float32),\n",
       "  Array(1029.6815, dtype=float32),\n",
       "  'sin',\n",
       "  Array(1, dtype=int32)),\n",
       " (1499,\n",
       "  25,\n",
       "  Array(968.75854, dtype=float32),\n",
       "  Array(978.4578, dtype=float32),\n",
       "  'relu',\n",
       "  Array(0, dtype=int32)),\n",
       " (1599,\n",
       "  26,\n",
       "  Array(947.84827, dtype=float32),\n",
       "  Array(957.7379, dtype=float32),\n",
       "  'relu',\n",
       "  Array(1, dtype=int32)),\n",
       " (1699,\n",
       "  27,\n",
       "  Array(906.5623, dtype=float32),\n",
       "  Array(914.83295, dtype=float32),\n",
       "  'tanh',\n",
       "  Array(1, dtype=int32)),\n",
       " (1799,\n",
       "  28,\n",
       "  Array(823.2787, dtype=float32),\n",
       "  Array(829.59955, dtype=float32),\n",
       "  'relu',\n",
       "  Array(1, dtype=int32)),\n",
       " (1899,\n",
       "  29,\n",
       "  Array(766.6147, dtype=float32),\n",
       "  Array(772.3659, dtype=float32),\n",
       "  'relu',\n",
       "  Array(0, dtype=int32)),\n",
       " (1999,\n",
       "  30,\n",
       "  Array(845.65454, dtype=float32),\n",
       "  Array(847.8163, dtype=float32),\n",
       "  'removed',\n",
       "  Array(0, dtype=int32)),\n",
       " (2099,\n",
       "  29,\n",
       "  Array(696.7855, dtype=float32),\n",
       "  Array(701.5415, dtype=float32),\n",
       "  'relu',\n",
       "  Array(0, dtype=int32)),\n",
       " (2199,\n",
       "  30,\n",
       "  Array(664.9319, dtype=float32),\n",
       "  Array(668.5367, dtype=float32),\n",
       "  'tanh',\n",
       "  Array(1, dtype=int32)),\n",
       " (2299,\n",
       "  31,\n",
       "  Array(614.1548, dtype=float32),\n",
       "  Array(617.1214, dtype=float32),\n",
       "  'sin',\n",
       "  Array(0, dtype=int32)),\n",
       " (2399,\n",
       "  32,\n",
       "  Array(574.9905, dtype=float32),\n",
       "  Array(576.95575, dtype=float32),\n",
       "  'tanh',\n",
       "  Array(1, dtype=int32)),\n",
       " (2499,\n",
       "  33,\n",
       "  Array(530.9135, dtype=float32),\n",
       "  Array(532.12714, dtype=float32),\n",
       "  'tanh',\n",
       "  Array(1, dtype=int32)),\n",
       " (2599,\n",
       "  34,\n",
       "  Array(490.85352, dtype=float32),\n",
       "  Array(491.22504, dtype=float32),\n",
       "  'relu',\n",
       "  Array(1, dtype=int32)),\n",
       " (2699,\n",
       "  35,\n",
       "  Array(450.05847, dtype=float32),\n",
       "  Array(449.6422, dtype=float32),\n",
       "  'tanh',\n",
       "  Array(0, dtype=int32)),\n",
       " (2799,\n",
       "  36,\n",
       "  Array(407.79068, dtype=float32),\n",
       "  Array(406.66537, dtype=float32),\n",
       "  'relu',\n",
       "  Array(0, dtype=int32)),\n",
       " (2899,\n",
       "  37,\n",
       "  Array(365.76202, dtype=float32),\n",
       "  Array(363.9951, dtype=float32),\n",
       "  'relu',\n",
       "  Array(1, dtype=int32)),\n",
       " (2999,\n",
       "  38,\n",
       "  Array(323.84213, dtype=float32),\n",
       "  Array(321.51932, dtype=float32),\n",
       "  'tanh',\n",
       "  Array(1, dtype=int32)),\n",
       " (3099,\n",
       "  39,\n",
       "  Array(282.52725, dtype=float32),\n",
       "  Array(279.61276, dtype=float32),\n",
       "  'tanh',\n",
       "  Array(0, dtype=int32)),\n",
       " (3199,\n",
       "  40,\n",
       "  Array(259.00653, dtype=float32),\n",
       "  Array(255.7978, dtype=float32),\n",
       "  'sin',\n",
       "  Array(1, dtype=int32)),\n",
       " (3299,\n",
       "  41,\n",
       "  Array(222.15067, dtype=float32),\n",
       "  Array(218.58224, dtype=float32),\n",
       "  'sin',\n",
       "  Array(1, dtype=int32)),\n",
       " (3399,\n",
       "  42,\n",
       "  Array(193.20743, dtype=float32),\n",
       "  Array(189.05939, dtype=float32),\n",
       "  'sin',\n",
       "  Array(0, dtype=int32)),\n",
       " (3499,\n",
       "  43,\n",
       "  Array(225.01445, dtype=float32),\n",
       "  Array(220.68079, dtype=float32),\n",
       "  'removed',\n",
       "  Array(0, dtype=int32)),\n",
       " (3599,\n",
       "  42,\n",
       "  Array(190.8811, dtype=float32),\n",
       "  Array(186.31268, dtype=float32),\n",
       "  'tanh',\n",
       "  Array(0, dtype=int32)),\n",
       " (3699,\n",
       "  43,\n",
       "  Array(201.3818, dtype=float32),\n",
       "  Array(196.1843, dtype=float32),\n",
       "  'removed',\n",
       "  Array(0, dtype=int32)),\n",
       " (3799,\n",
       "  42,\n",
       "  Array(167.95238, dtype=float32),\n",
       "  Array(163.50941, dtype=float32),\n",
       "  'tanh',\n",
       "  Array(0, dtype=int32)),\n",
       " (3899,\n",
       "  43,\n",
       "  Array(156.34663, dtype=float32),\n",
       "  Array(151.63231, dtype=float32),\n",
       "  'sin',\n",
       "  Array(0, dtype=int32)),\n",
       " (3999,\n",
       "  44,\n",
       "  Array(157.09413, dtype=float32),\n",
       "  Array(152.98361, dtype=float32),\n",
       "  'removed',\n",
       "  Array(0, dtype=int32)),\n",
       " (4099,\n",
       "  43,\n",
       "  Array(145.36316, dtype=float32),\n",
       "  Array(140.64757, dtype=float32),\n",
       "  'relu',\n",
       "  Array(1, dtype=int32)),\n",
       " (4199,\n",
       "  44,\n",
       "  Array(129.11209, dtype=float32),\n",
       "  Array(124.25107, dtype=float32),\n",
       "  'sin',\n",
       "  Array(0, dtype=int32)),\n",
       " (4299,\n",
       "  45,\n",
       "  Array(120.355415, dtype=float32),\n",
       "  Array(115.43459, dtype=float32),\n",
       "  'sin',\n",
       "  Array(1, dtype=int32)),\n",
       " (4399,\n",
       "  46,\n",
       "  Array(110.09701, dtype=float32),\n",
       "  Array(105.20346, dtype=float32),\n",
       "  'sin',\n",
       "  Array(0, dtype=int32)),\n",
       " (4499,\n",
       "  47,\n",
       "  Array(96.96477, dtype=float32),\n",
       "  Array(92.254585, dtype=float32),\n",
       "  'relu',\n",
       "  Array(0, dtype=int32)),\n",
       " (4599,\n",
       "  48,\n",
       "  Array(91.06635, dtype=float32),\n",
       "  Array(86.48246, dtype=float32),\n",
       "  'relu',\n",
       "  Array(0, dtype=int32)),\n",
       " (4699,\n",
       "  49,\n",
       "  Array(96.69173, dtype=float32),\n",
       "  Array(92.105934, dtype=float32),\n",
       "  'removed',\n",
       "  Array(0, dtype=int32)),\n",
       " (4799,\n",
       "  48,\n",
       "  Array(86.63716, dtype=float32),\n",
       "  Array(82.43829, dtype=float32),\n",
       "  'relu',\n",
       "  Array(1, dtype=int32)),\n",
       " (4899,\n",
       "  49,\n",
       "  Array(73.95224, dtype=float32),\n",
       "  Array(70.11596, dtype=float32),\n",
       "  'tanh',\n",
       "  Array(0, dtype=int32)),\n",
       " (4999,\n",
       "  50,\n",
       "  Array(66.13357, dtype=float32),\n",
       "  Array(62.614037, dtype=float32),\n",
       "  'relu',\n",
       "  Array(1, dtype=int32)),\n",
       " (5099,\n",
       "  51,\n",
       "  Array(57.025814, dtype=float32),\n",
       "  Array(53.841908, dtype=float32),\n",
       "  'tanh',\n",
       "  Array(1, dtype=int32)),\n",
       " (5199,\n",
       "  52,\n",
       "  Array(49.045353, dtype=float32),\n",
       "  Array(46.217094, dtype=float32),\n",
       "  'relu',\n",
       "  Array(0, dtype=int32)),\n",
       " (5299,\n",
       "  53,\n",
       "  Array(43.05726, dtype=float32),\n",
       "  Array(40.503284, dtype=float32),\n",
       "  'tanh',\n",
       "  Array(0, dtype=int32)),\n",
       " (5399,\n",
       "  54,\n",
       "  Array(40.393246, dtype=float32),\n",
       "  Array(37.99376, dtype=float32),\n",
       "  'sin',\n",
       "  Array(1, dtype=int32)),\n",
       " (5499,\n",
       "  55,\n",
       "  Array(35.857464, dtype=float32),\n",
       "  Array(33.697723, dtype=float32),\n",
       "  'sin',\n",
       "  Array(0, dtype=int32)),\n",
       " (5599,\n",
       "  56,\n",
       "  Array(34.348816, dtype=float32),\n",
       "  Array(32.28813, dtype=float32),\n",
       "  'sin',\n",
       "  Array(0, dtype=int32)),\n",
       " (5699,\n",
       "  57,\n",
       "  Array(33.566307, dtype=float32),\n",
       "  Array(31.614283, dtype=float32),\n",
       "  'relu',\n",
       "  Array(0, dtype=int32)),\n",
       " (5799,\n",
       "  58,\n",
       "  Array(27.902, dtype=float32),\n",
       "  Array(26.209778, dtype=float32),\n",
       "  'tanh',\n",
       "  Array(0, dtype=int32)),\n",
       " (5899,\n",
       "  59,\n",
       "  Array(46.09761, dtype=float32),\n",
       "  Array(43.623795, dtype=float32),\n",
       "  'removed',\n",
       "  Array(0, dtype=int32)),\n",
       " (5999,\n",
       "  58,\n",
       "  Array(31.573614, dtype=float32),\n",
       "  Array(29.499516, dtype=float32),\n",
       "  'tanh',\n",
       "  Array(1, dtype=int32)),\n",
       " (6099,\n",
       "  59,\n",
       "  Array(23.660162, dtype=float32),\n",
       "  Array(22.165607, dtype=float32),\n",
       "  'relu',\n",
       "  Array(1, dtype=int32)),\n",
       " (6199,\n",
       "  60,\n",
       "  Array(20.290989, dtype=float32),\n",
       "  Array(18.978615, dtype=float32),\n",
       "  'tanh',\n",
       "  Array(0, dtype=int32)),\n",
       " (6299,\n",
       "  61,\n",
       "  Array(18.87808, dtype=float32),\n",
       "  Array(17.652914, dtype=float32),\n",
       "  'tanh',\n",
       "  Array(1, dtype=int32)),\n",
       " (6399,\n",
       "  62,\n",
       "  Array(16.921124, dtype=float32),\n",
       "  Array(15.786155, dtype=float32),\n",
       "  'sin',\n",
       "  Array(1, dtype=int32)),\n",
       " (6499,\n",
       "  63,\n",
       "  Array(14.399222, dtype=float32),\n",
       "  Array(13.384073, dtype=float32),\n",
       "  'tanh',\n",
       "  Array(0, dtype=int32))]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_adjacency_matrix = mlp.adjacency_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f\"{out_folder}/final_adjacency_matrix.txt\", final_adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_wt = np.max(np.abs(final_adjacency_matrix))\n",
    "norm = MidpointNormalize(vmin=-max_wt, vmax=max_wt, midpoint=0)\n",
    "cmap = plt.get_cmap('coolwarm')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "cax = ax.matshow(final_adjacency_matrix, cmap=cmap, norm=norm)\n",
    "cbar = fig.colorbar(cax, ticks=[-max_wt,\n",
    "                                -max_wt/2, \n",
    "                                0,\n",
    "                                max_wt/2,\n",
    "                                max_wt])\n",
    "\n",
    "# plt.colorbar()\n",
    "plt.title(\"final adjacency matrix\")\n",
    "plt.savefig(f\"{fig_folder}/final_adjacency_matrix.png\")\n",
    "wandb.log({\"final adjacency matrix\": wandb.Image(plt, caption=\"final adjacency matrix\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_matrices = np.split(final_adjacency_matrix, np.cumsum(mlp.get_shape())[:-1])[:-1]\n",
    "\n",
    "fig, axs = plt.subplots(1, len(sub_matrices), figsize=(20, 5))\n",
    "\n",
    "for i, (sub_matrix, ax) in enumerate(zip(sub_matrices, axs), start=1):\n",
    "    weights = sub_matrix.flatten()\n",
    "    weights = weights[weights != 0]\n",
    "    ax.hist(weights, bins=\"auto\", density=False, alpha=0.6, color='g')\n",
    "    ax.set_xlabel('Weights')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'Layer {i}-Layer {i+1} ')\n",
    "\n",
    "# Display the figure with its subplots\n",
    "plt.suptitle('Final Weight Distribution (excluding zero weights)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epochs, train_loss = zip(*train_loss_history)\n",
    "test_epochs, test_loss = zip(*test_loss_history)\n",
    "grad_epochs, grad_norm_val = zip(*grad_norm_history)\n",
    "node_epochs, n_neurons = zip(*node_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss', color=color)\n",
    "ax1.plot(train_epochs, train_loss, \"-.\", color=color, label=\"Train Loss\")\n",
    "ax1.plot(test_epochs, test_loss, \"*\", color=\"darkred\", label=\"Test Loss\")\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.legend()\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Number of Nodes', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(node_epochs, n_neurons, \"-.\", color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.spines['right'].set_color(color)\n",
    "\n",
    "\n",
    "ax3 = ax1.twinx()\n",
    "\n",
    "color = 'tab:green'\n",
    "ax3.spines['right'].set_position(('outward', 60))  # Offset the third y-axis\n",
    "ax3.plot(grad_epochs, grad_norm_val, '.', color=color, alpha = 0.1, label=\"Gradient Norm\")\n",
    "ax3.set_ylabel('Gradient norm', color=color)\n",
    "ax3.tick_params(axis='y', labelcolor=color)\n",
    "ax3.set_yscale(\"log\")\n",
    "ax3.spines['right'].set_color(color)\n",
    "\n",
    "# ax1.set_xscale(\"log\")\n",
    "\n",
    "plt.suptitle(f\"Heterogenous {act_string} Neural Network with capped loss linear strategic Node Addition and Removal\")\n",
    "fig.tight_layout()\n",
    "plt.savefig(f\"{fig_folder}/loss_curve.png\")\n",
    "wandb.log({\"loss and nodes\": wandb.Image(plt, caption=\"loss and nodes\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss', color=color)\n",
    "ax1.plot(train_epochs, train_loss, \"-.\", color=color, label=\"Train Loss\")\n",
    "ax1.plot(test_epochs, test_loss, \"*\", color=\"darkred\", label=\"Test Loss\")\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.legend()\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Number of Nodes', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(node_epochs, n_neurons, \"-.\", color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.spines['right'].set_color(color)\n",
    "\n",
    "\n",
    "ax3 = ax1.twinx()\n",
    "\n",
    "color = 'tab:green'\n",
    "ax3.spines['right'].set_position(('outward', 60))  # Offset the third y-axis\n",
    "ax3.plot(grad_epochs, grad_norm_val, '.', color=color, alpha = 0.1, label=\"Gradient Norm\")\n",
    "ax3.set_ylabel('Gradient norm', color=color)\n",
    "ax3.tick_params(axis='y', labelcolor=color)\n",
    "ax3.set_yscale(\"log\")\n",
    "ax3.spines['right'].set_color(color)\n",
    "\n",
    "ax1.set_xscale(\"log\")\n",
    "\n",
    "plt.suptitle(f\"Heterogenous {act_string} Neural Network with capped loss linear strategic Node Addition and Removal\")\n",
    "fig.tight_layout()\n",
    "plt.savefig(f\"{fig_folder}/loss_curve_loglog.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G, neuron_labels, neuron_importances = mlp.visualize_graph()\n",
    "fig = mlp_plot(G, neuron_labels, neuron_importances)\n",
    "plt.savefig(f\"{fig_folder}/final_graph.png\")\n",
    "wandb.log({\"final neural network\": wandb.Image(plt, caption=\"final neural network\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "colors = []\n",
    "epochs, times, n_neurons = zip(*time_history)\n",
    "\n",
    "diffs = np.diff(n_neurons, prepend=n_neurons[0])\n",
    "\n",
    "colors = ['tab:green' if diff > 0 else\n",
    "            'tab:red' if diff < 0 else\n",
    "            'tab:orange' if (i+1)% intervene_every*int(n_neurons[i]/init_neurons) == 0 else\n",
    "            'k' for i,diff in enumerate(diffs)]\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# color = 'tab:red'\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Time(s)')\n",
    "for epoch, time, color in zip(epochs, times, colors):\n",
    "    ax1.plot(epoch, time, \".\", color=color, alpha=0.5)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.set_yscale(\"log\")\n",
    "\n",
    "patches = [\n",
    "    mpatches.Patch(color='tab:green', label='Increase in n_neurons'),\n",
    "    mpatches.Patch(color='tab:red', label='Decrease in n_neurons'),\n",
    "    mpatches.Patch(color='tab:orange', label='Intervening')\n",
    "]\n",
    "\n",
    "ax1.legend(handles=patches)\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Number of Nodes', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(epochs, n_neurons, \".\", color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.spines['right'].set_color(color)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
